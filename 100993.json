{"path":"lucene/contrib/misc/src/test/org/apache/lucene/index/TestNRTManager#testNRTManager().mjava","commits":[{"id":"39d69912999d6e0acfb6eb6be558fcc165eee0b2","date":1308066875,"type":0,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/contrib/misc/src/test/org/apache/lucene/index/TestNRTManager#testNRTManager().mjava","pathOld":"/dev/null","sourceNew":"  @Test\n  public void testNRTManager() throws Exception {\n\n    final long t0 = System.currentTimeMillis();\n\n    if (CodecProvider.getDefault().getDefaultFieldCodec().equals(\"SimpleText\")) {\n      // no\n      CodecProvider.getDefault().setDefaultFieldCodec(\"Standard\");\n    }\n\n    final LineFileDocs docs = new LineFileDocs(random);\n    final File tempDir = _TestUtil.getTempDir(\"nrtopenfiles\");\n    final MockDirectoryWrapper _dir = newFSDirectory(tempDir);\n    _dir.setCheckIndexOnClose(false);  // don't double-checkIndex, we do it ourselves\n    Directory dir = _dir;\n    final IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).setOpenMode(IndexWriterConfig.OpenMode.CREATE);\n\n    // newIWConfig makes smallish max seg size, which\n    // results in tons and tons of segments for this test\n    // when run nightly:\n    MergePolicy mp = conf.getMergePolicy();\n    if (mp instanceof TieredMergePolicy) {\n      ((TieredMergePolicy) mp).setMaxMergedSegmentMB(5000.);\n    } else if (mp instanceof LogByteSizeMergePolicy) {\n      ((LogByteSizeMergePolicy) mp).setMaxMergeMB(1000.);\n    } else if (mp instanceof LogMergePolicy) {\n      ((LogMergePolicy) mp).setMaxMergeDocs(100000);\n    }\n\n    conf.setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n      @Override\n      public void warm(IndexReader reader) throws IOException {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now warm merged reader=\" + reader);\n        }\n        final int maxDoc = reader.maxDoc();\n        final Bits delDocs = reader.getDeletedDocs();\n        int sum = 0;\n        final int inc = Math.max(1, maxDoc/50);\n        for(int docID=0;docID<maxDoc;docID += inc) {\n          if (delDocs == null || !delDocs.get(docID)) {\n            final Document doc = reader.document(docID);\n            sum += doc.getFields().size();\n          }\n        }\n\n        IndexSearcher searcher = newSearcher(reader);\n        sum += searcher.search(new TermQuery(new Term(\"body\", \"united\")), 10).totalHits;\n        searcher.close();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: warm visited \" + sum + \" fields\");\n        }\n      }\n      });\n\n    if (random.nextBoolean()) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: wrap NRTCachingDir\");\n      }\n\n      NRTCachingDirectory nrtDir = new NRTCachingDirectory(dir, 5.0, 60.0);\n      conf.setMergeScheduler(nrtDir.getMergeScheduler());\n      dir = nrtDir;\n    }\n    \n    final IndexWriter writer = new IndexWriter(dir, conf);\n    \n    if (VERBOSE) {\n      writer.setInfoStream(System.out);\n    }\n    _TestUtil.reduceOpenFiles(writer);\n    //System.out.println(\"TEST: conf=\" + writer.getConfig());\n\n    final ExecutorService es = random.nextBoolean() ? null : Executors.newCachedThreadPool(new NamedThreadFactory(\"NRT search threads\"));\n\n    final double minReopenSec = 0.01 + 0.05 * random.nextDouble();\n    final double maxReopenSec = minReopenSec * (1.0 + 10 * random.nextDouble());\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: make NRTManager maxReopenSec=\" + maxReopenSec + \" minReopenSec=\" + minReopenSec);\n    }\n\n    final NRTManager nrt = new NRTManager(writer, es);\n    final NRTManagerReopenThread nrtThread = new NRTManagerReopenThread(nrt, maxReopenSec, minReopenSec);\n    nrtThread.setName(\"NRT Reopen Thread\");\n    nrtThread.setPriority(Math.min(Thread.currentThread().getPriority()+2, Thread.MAX_PRIORITY));\n    nrtThread.setDaemon(true);\n    nrtThread.start();\n\n    final int NUM_INDEX_THREADS = _TestUtil.nextInt(random, 1, 3);\n    final int NUM_SEARCH_THREADS = _TestUtil.nextInt(random, 1, 3);\n    //final int NUM_INDEX_THREADS = 1;\n    //final int NUM_SEARCH_THREADS = 1;\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + NUM_INDEX_THREADS + \" index threads; \" + NUM_SEARCH_THREADS + \" search threads\");\n    }\n\n    final int RUN_TIME_SEC = LuceneTestCase.TEST_NIGHTLY ? 300 : 5;\n\n    final AtomicBoolean failed = new AtomicBoolean();\n    final AtomicInteger addCount = new AtomicInteger();\n    final AtomicInteger delCount = new AtomicInteger();\n    final AtomicInteger packCount = new AtomicInteger();\n    final List<Long> lastGens = new ArrayList<Long>();\n\n    final Set<String> delIDs = Collections.synchronizedSet(new HashSet<String>());\n    final List<SubDocs> allSubDocs = Collections.synchronizedList(new ArrayList<SubDocs>());\n\n    final long stopTime = System.currentTimeMillis() + RUN_TIME_SEC*1000;\n    Thread[] threads = new Thread[NUM_INDEX_THREADS];\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread] = new Thread() {\n          @Override\n          public void run() {\n            // TODO: would be better if this were cross thread, so that we make sure one thread deleting anothers added docs works:\n            final List<String> toDeleteIDs = new ArrayList<String>();\n            final List<SubDocs> toDeleteSubDocs = new ArrayList<SubDocs>();\n\n            long gen = 0;\n            while(System.currentTimeMillis() < stopTime && !failed.get()) {\n\n              //System.out.println(Thread.currentThread().getName() + \": cycle\");\n              try {\n                // Occassional longish pause if running\n                // nightly\n                if (LuceneTestCase.TEST_NIGHTLY && random.nextInt(6) == 3) {\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": now long sleep\");\n                  }\n                  Thread.sleep(_TestUtil.nextInt(random, 50, 500));\n                }\n\n                // Rate limit ingest rate:\n                Thread.sleep(_TestUtil.nextInt(random, 1, 10));\n                if (VERBOSE) {\n                  System.out.println(Thread.currentThread() + \": done sleep\");\n                }\n\n                Document doc = docs.nextDoc();\n                if (doc == null) {\n                  break;\n                }\n                final String addedField;\n                if (random.nextBoolean()) {\n                  addedField = \"extra\" + random.nextInt(10);\n                  doc.add(new Field(addedField, \"a random field\", Field.Store.NO, Field.Index.ANALYZED));\n                } else {\n                  addedField = null;\n                }\n                if (random.nextBoolean()) {\n\n                  if (random.nextBoolean()) {\n                    // Add a pack of adjacent sub-docs\n                    final String packID;\n                    final SubDocs delSubDocs;\n                    if (toDeleteSubDocs.size() > 0 && random.nextBoolean()) {\n                      delSubDocs = toDeleteSubDocs.get(random.nextInt(toDeleteSubDocs.size()));\n                      assert !delSubDocs.deleted;\n                      toDeleteSubDocs.remove(delSubDocs);\n                      // reuse prior packID\n                      packID = delSubDocs.packID;\n                    } else {\n                      delSubDocs = null;\n                      // make new packID\n                      packID = packCount.getAndIncrement() + \"\";\n                    }\n\n                    final Field packIDField = newField(\"packID\", packID, Field.Store.YES, Field.Index.NOT_ANALYZED);\n                    final List<String> docIDs = new ArrayList<String>();\n                    final SubDocs subDocs = new SubDocs(packID, docIDs);\n                    final List<Document> docsList = new ArrayList<Document>();\n\n                    allSubDocs.add(subDocs);\n                    doc.add(packIDField);\n                    docsList.add(cloneDoc(doc));\n                    docIDs.add(doc.get(\"docid\"));\n\n                    final int maxDocCount = _TestUtil.nextInt(random, 1, 10);\n                    while(docsList.size() < maxDocCount) {\n                      doc = docs.nextDoc();\n                      if (doc == null) {\n                        break;\n                      }\n                      docsList.add(cloneDoc(doc));\n                      docIDs.add(doc.get(\"docid\"));\n                    }\n                    addCount.addAndGet(docsList.size());\n\n                    if (delSubDocs != null) {\n                      delSubDocs.deleted = true;\n                      delIDs.addAll(delSubDocs.subIDs);\n                      delCount.addAndGet(delSubDocs.subIDs.size());\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: update pack packID=\" + delSubDocs.packID + \" count=\" + docsList.size() + \" docs=\" + docIDs);\n                      }\n                      gen = nrt.updateDocuments(new Term(\"packID\", delSubDocs.packID), docsList);\n                      /*\n                      // non-atomic:\n                      nrt.deleteDocuments(new Term(\"packID\", delSubDocs.packID));\n                      for(Document subDoc : docsList) {\n                        nrt.addDocument(subDoc);\n                      }\n                      */\n                    } else {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: add pack packID=\" + packID + \" count=\" + docsList.size() + \" docs=\" + docIDs);\n                      }\n                      gen = nrt.addDocuments(docsList);\n                      \n                      /*\n                      // non-atomic:\n                      for(Document subDoc : docsList) {\n                        nrt.addDocument(subDoc);\n                      }\n                      */\n                    }\n                    doc.removeField(\"packID\");\n\n                    if (random.nextInt(5) == 2) {\n                      if (VERBOSE) {\n                        System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + packID);\n                      }\n                      toDeleteSubDocs.add(subDocs);\n                    }\n\n                    // randomly verify the add/update \"took\":\n                    if (random.nextInt(20) == 2) {\n                      final boolean applyDeletes = delSubDocs != null;\n                      final IndexSearcher s = nrt.get(gen, applyDeletes);\n                      try {\n                        assertEquals(docsList.size(), s.search(new TermQuery(new Term(\"packID\", packID)), 10).totalHits);\n                      } finally {\n                        nrt.release(s);\n                      }\n                    }\n\n                  } else {\n                    if (VERBOSE) {\n                      System.out.println(Thread.currentThread().getName() + \": add doc docid:\" + doc.get(\"docid\"));\n                    }\n\n                    gen = nrt.addDocument(doc);\n                    addCount.getAndIncrement();\n\n                    // randomly verify the add \"took\":\n                    if (random.nextInt(20) == 2) {\n                      //System.out.println(Thread.currentThread().getName() + \": verify\");\n                      final IndexSearcher s = nrt.get(gen, false);\n                      //System.out.println(Thread.currentThread().getName() + \": got s=\" + s);\n                      try {\n                        assertEquals(1, s.search(new TermQuery(new Term(\"docid\", doc.get(\"docid\"))), 10).totalHits);\n                      } finally {\n                        nrt.release(s);\n                      }\n                      //System.out.println(Thread.currentThread().getName() + \": done verify\");\n                    }\n\n                    if (random.nextInt(5) == 3) {\n                      if (VERBOSE) {\n                        System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                      }\n                      toDeleteIDs.add(doc.get(\"docid\"));\n                    }\n                  }\n                } else {\n                  // we use update but it never replaces a\n                  // prior doc\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": update doc id:\" + doc.get(\"docid\"));\n                  }\n                  gen = nrt.updateDocument(new Term(\"docid\", doc.get(\"docid\")), doc);\n                  addCount.getAndIncrement();\n\n                  // randomly verify the add \"took\":\n                  if (random.nextInt(20) == 2) {\n                    final IndexSearcher s = nrt.get(gen, true);\n                    try {\n                      assertEquals(1, s.search(new TermQuery(new Term(\"docid\", doc.get(\"docid\"))), 10).totalHits);\n                    } finally {\n                      nrt.release(s);\n                    }\n                  }\n\n                  if (random.nextInt(5) == 3) {\n                    if (VERBOSE) {\n                      System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                    }\n                    toDeleteIDs.add(doc.get(\"docid\"));\n                  }\n                }\n\n                if (random.nextInt(30) == 17) {\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": apply \" + toDeleteIDs.size() + \" deletes\");\n                  }\n                  for(String id : toDeleteIDs) {\n                    if (VERBOSE) {\n                      System.out.println(Thread.currentThread().getName() + \": del term=id:\" + id);\n                    }\n                    gen = nrt.deleteDocuments(new Term(\"docid\", id));\n\n                    // randomly verify the delete \"took\":\n                    if (random.nextInt(20) == 7) {\n                      final IndexSearcher s = nrt.get(gen, true);\n                      try {\n                        assertEquals(0, s.search(new TermQuery(new Term(\"docid\", id)), 10).totalHits);\n                      } finally {\n                        nrt.release(s);\n                      }\n                    }\n                  }\n\n                  final int count = delCount.addAndGet(toDeleteIDs.size());\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": tot \" + count + \" deletes\");\n                  }\n                  delIDs.addAll(toDeleteIDs);\n                  toDeleteIDs.clear();\n\n                  for(SubDocs subDocs : toDeleteSubDocs) {\n                    assertTrue(!subDocs.deleted);\n                    gen = nrt.deleteDocuments(new Term(\"packID\", subDocs.packID));\n                    subDocs.deleted = true;\n                    if (VERBOSE) {\n                      System.out.println(\"  del subs: \" + subDocs.subIDs + \" packID=\" + subDocs.packID);\n                    }\n                    delIDs.addAll(subDocs.subIDs);\n                    delCount.addAndGet(subDocs.subIDs.size());\n\n                    // randomly verify the delete \"took\":\n                    if (random.nextInt(20) == 7) {\n                      final IndexSearcher s = nrt.get(gen, true);\n                      try {\n                        assertEquals(0, s.search(new TermQuery(new Term(\"packID\", subDocs.packID)), 1).totalHits);\n                      } finally {\n                        nrt.release(s);\n                      }\n                    }\n                  }\n                  toDeleteSubDocs.clear();\n                }\n                if (addedField != null) {\n                  doc.removeField(addedField);\n                }\n              } catch (Throwable t) {\n                System.out.println(Thread.currentThread().getName() + \": FAILED: hit exc\");\n                t.printStackTrace();\n                failed.set(true);\n                throw new RuntimeException(t);\n              }\n            }\n\n            lastGens.add(gen);\n            if (VERBOSE) {\n              System.out.println(Thread.currentThread().getName() + \": indexing done\");\n            }\n          }\n        };\n      threads[thread].setDaemon(true);\n      threads[thread].start();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: DONE start indexing threads [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    // let index build up a bit\n    Thread.sleep(100);\n\n    // silly starting guess:\n    final AtomicInteger totTermCount = new AtomicInteger(100);\n\n    // run search threads\n    final Thread[] searchThreads = new Thread[NUM_SEARCH_THREADS];\n    final AtomicInteger totHits = new AtomicInteger();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: start search threads\");\n    }\n\n    for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n      searchThreads[thread] = new Thread() {\n          @Override\n          public void run() {\n            while(System.currentTimeMillis() < stopTime && !failed.get()) {\n              final IndexSearcher s = nrt.get(random.nextBoolean());\n              try {\n                try {\n                  smokeTestSearcher(s);\n                  if (s.getIndexReader().numDocs() > 0) {\n                    Fields fields = MultiFields.getFields(s.getIndexReader());\n                    if (fields == null) {\n                      continue;\n                    }\n                    Terms terms = fields.terms(\"body\");\n                    if (terms == null) {\n                      continue;\n                    }\n\n                    TermsEnum termsEnum = terms.iterator();\n                    int seenTermCount = 0;\n                    int shift;\n                    int trigger;\n                    if (totTermCount.get() == 0) {\n                      shift = 0;\n                      trigger = 1;\n                    } else {\n                      shift = random.nextInt(totTermCount.get()/10);\n                      trigger = totTermCount.get()/10;\n                    }\n\n                    while(System.currentTimeMillis() < stopTime) {\n                      BytesRef term = termsEnum.next();\n                      if (term == null) {\n                        if (seenTermCount == 0) {\n                          break;\n                        }\n                        totTermCount.set(seenTermCount);\n                        seenTermCount = 0;\n                        if (totTermCount.get() == 0) {\n                          shift = 0;\n                          trigger = 1;\n                        } else {\n                          trigger = totTermCount.get()/10;\n                          //System.out.println(\"trigger \" + trigger);\n                          shift = random.nextInt(totTermCount.get()/10);\n                        }\n                        termsEnum.seek(new BytesRef(\"\"));\n                        continue;\n                      }\n                      seenTermCount++;\n                      // search 10 terms\n                      if (trigger == 0) {\n                        trigger = 1;\n                      }\n                      if ((seenTermCount + shift) % trigger == 0) {\n                        //if (VERBOSE) {\n                        //System.out.println(Thread.currentThread().getName() + \" now search body:\" + term.utf8ToString());\n                        //}\n                        totHits.addAndGet(runQuery(s, new TermQuery(new Term(\"body\", term))));\n                      }\n                    }\n                    if (VERBOSE) {\n                      System.out.println(Thread.currentThread().getName() + \": search done\");\n                    }\n                  }\n                } finally {\n                  nrt.release(s);\n                }\n              } catch (Throwable t) {\n                System.out.println(Thread.currentThread().getName() + \": FAILED: hit exc\");\n                failed.set(true);\n                t.printStackTrace(System.out);\n                throw new RuntimeException(t);\n              }\n            }\n          }\n        };\n      searchThreads[thread].setDaemon(true);\n      searchThreads[thread].start();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now join\");\n    }\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread].join();\n    }\n    for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n      searchThreads[thread].join();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: done join [\" + (System.currentTimeMillis()-t0) + \" ms]; addCount=\" + addCount + \" delCount=\" + delCount);\n      System.out.println(\"TEST: search totHits=\" + totHits);\n    }\n\n    long maxGen = 0;\n    for(long gen : lastGens) {\n      maxGen = Math.max(maxGen, gen);\n    }\n\n    final IndexSearcher s = nrt.get(maxGen, true);\n\n    boolean doFail = false;\n    for(String id : delIDs) {\n      final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", id)), 1);\n      if (hits.totalHits != 0) {\n        System.out.println(\"doc id=\" + id + \" is supposed to be deleted, but got docID=\" + hits.scoreDocs[0].doc);\n        doFail = true;\n      }\n    }\n\n    // Make sure each group of sub-docs are still in docID order:\n    for(SubDocs subDocs : allSubDocs) {\n      if (!subDocs.deleted) {\n        // We sort by relevance but the scores should be identical so sort falls back to by docID:\n        TopDocs hits = s.search(new TermQuery(new Term(\"packID\", subDocs.packID)), 20);\n        assertEquals(subDocs.subIDs.size(), hits.totalHits);\n        int lastDocID = -1;\n        int startDocID = -1;\n        for(ScoreDoc scoreDoc : hits.scoreDocs) {\n          final int docID = scoreDoc.doc;\n          if (lastDocID != -1) {\n            assertEquals(1+lastDocID, docID);\n          } else {\n            startDocID = docID;\n          }\n          lastDocID = docID;\n          final Document doc = s.doc(docID);\n          assertEquals(subDocs.packID, doc.get(\"packID\"));\n        }\n\n        lastDocID = startDocID - 1;\n        for(String subID : subDocs.subIDs) {\n          hits = s.search(new TermQuery(new Term(\"docid\", subID)), 1);\n          assertEquals(1, hits.totalHits);\n          final int docID = hits.scoreDocs[0].doc;\n          if (lastDocID != -1) {\n            assertEquals(1+lastDocID, docID);\n          }\n          lastDocID = docID;\n        }          \n      } else {\n        for(String subID : subDocs.subIDs) {\n          assertEquals(0, s.search(new TermQuery(new Term(\"docid\", subID)), 1).totalHits);\n        }\n      }\n    }\n    \n    final int endID = Integer.parseInt(docs.nextDoc().get(\"docid\"));\n    for(int id=0;id<endID;id++) {\n      String stringID = \"\"+id;\n      if (!delIDs.contains(stringID)) {\n        final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", stringID)), 1);\n        if (hits.totalHits != 1) {\n          System.out.println(\"doc id=\" + stringID + \" is not supposed to be deleted, but got hitCount=\" + hits.totalHits);\n          doFail = true;\n        }\n      }\n    }\n    assertFalse(doFail);\n\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), s.getIndexReader().numDocs());\n    nrt.release(s);\n\n    if (es != null) {\n      es.shutdown();\n      es.awaitTermination(1, TimeUnit.SECONDS);\n    }\n\n    writer.commit();\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), writer.numDocs());\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now close NRTManager\");\n    }\n    nrtThread.close();\n    nrt.close();\n    assertFalse(writer.anyNonBulkMerges);\n    writer.close(false);\n    _TestUtil.checkIndex(dir);\n    dir.close();\n    _TestUtil.rmDir(tempDir);\n    docs.close();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b8502a95cc8b8718b499be061845747cc3c3a3c4","date":1308067759,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/contrib/misc/src/test/org/apache/lucene/index/TestNRTManager#testNRTManager().mjava","pathOld":"lucene/contrib/misc/src/test/org/apache/lucene/index/TestNRTManager#testNRTManager().mjava","sourceNew":"  @Test\n  public void testNRTManager() throws Exception {\n\n    final long t0 = System.currentTimeMillis();\n\n    if (CodecProvider.getDefault().getDefaultFieldCodec().equals(\"SimpleText\")) {\n      // no\n      CodecProvider.getDefault().setDefaultFieldCodec(\"Standard\");\n    }\n\n    final LineFileDocs docs = new LineFileDocs(random);\n    final File tempDir = _TestUtil.getTempDir(\"nrtopenfiles\");\n    final MockDirectoryWrapper _dir = newFSDirectory(tempDir);\n    _dir.setCheckIndexOnClose(false);  // don't double-checkIndex, we do it ourselves\n    Directory dir = _dir;\n    final IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).setOpenMode(IndexWriterConfig.OpenMode.CREATE);\n\n    if (LuceneTestCase.TEST_NIGHTLY) {\n      // newIWConfig makes smallish max seg size, which\n      // results in tons and tons of segments for this test\n      // when run nightly:\n      MergePolicy mp = conf.getMergePolicy();\n      if (mp instanceof TieredMergePolicy) {\n        ((TieredMergePolicy) mp).setMaxMergedSegmentMB(5000.);\n      } else if (mp instanceof LogByteSizeMergePolicy) {\n        ((LogByteSizeMergePolicy) mp).setMaxMergeMB(1000.);\n      } else if (mp instanceof LogMergePolicy) {\n        ((LogMergePolicy) mp).setMaxMergeDocs(100000);\n      }\n    }\n\n    conf.setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n      @Override\n      public void warm(IndexReader reader) throws IOException {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now warm merged reader=\" + reader);\n        }\n        final int maxDoc = reader.maxDoc();\n        final Bits delDocs = reader.getDeletedDocs();\n        int sum = 0;\n        final int inc = Math.max(1, maxDoc/50);\n        for(int docID=0;docID<maxDoc;docID += inc) {\n          if (delDocs == null || !delDocs.get(docID)) {\n            final Document doc = reader.document(docID);\n            sum += doc.getFields().size();\n          }\n        }\n\n        IndexSearcher searcher = newSearcher(reader);\n        sum += searcher.search(new TermQuery(new Term(\"body\", \"united\")), 10).totalHits;\n        searcher.close();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: warm visited \" + sum + \" fields\");\n        }\n      }\n      });\n\n    if (random.nextBoolean()) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: wrap NRTCachingDir\");\n      }\n\n      NRTCachingDirectory nrtDir = new NRTCachingDirectory(dir, 5.0, 60.0);\n      conf.setMergeScheduler(nrtDir.getMergeScheduler());\n      dir = nrtDir;\n    }\n    \n    final IndexWriter writer = new IndexWriter(dir, conf);\n    \n    if (VERBOSE) {\n      writer.setInfoStream(System.out);\n    }\n    _TestUtil.reduceOpenFiles(writer);\n    //System.out.println(\"TEST: conf=\" + writer.getConfig());\n\n    final ExecutorService es = random.nextBoolean() ? null : Executors.newCachedThreadPool(new NamedThreadFactory(\"NRT search threads\"));\n\n    final double minReopenSec = 0.01 + 0.05 * random.nextDouble();\n    final double maxReopenSec = minReopenSec * (1.0 + 10 * random.nextDouble());\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: make NRTManager maxReopenSec=\" + maxReopenSec + \" minReopenSec=\" + minReopenSec);\n    }\n\n    final NRTManager nrt = new NRTManager(writer, es);\n    final NRTManagerReopenThread nrtThread = new NRTManagerReopenThread(nrt, maxReopenSec, minReopenSec);\n    nrtThread.setName(\"NRT Reopen Thread\");\n    nrtThread.setPriority(Math.min(Thread.currentThread().getPriority()+2, Thread.MAX_PRIORITY));\n    nrtThread.setDaemon(true);\n    nrtThread.start();\n\n    final int NUM_INDEX_THREADS = _TestUtil.nextInt(random, 1, 3);\n    final int NUM_SEARCH_THREADS = _TestUtil.nextInt(random, 1, 3);\n    //final int NUM_INDEX_THREADS = 1;\n    //final int NUM_SEARCH_THREADS = 1;\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + NUM_INDEX_THREADS + \" index threads; \" + NUM_SEARCH_THREADS + \" search threads\");\n    }\n\n    final int RUN_TIME_SEC = LuceneTestCase.TEST_NIGHTLY ? 300 : RANDOM_MULTIPLIER;\n\n    final AtomicBoolean failed = new AtomicBoolean();\n    final AtomicInteger addCount = new AtomicInteger();\n    final AtomicInteger delCount = new AtomicInteger();\n    final AtomicInteger packCount = new AtomicInteger();\n    final List<Long> lastGens = new ArrayList<Long>();\n\n    final Set<String> delIDs = Collections.synchronizedSet(new HashSet<String>());\n    final List<SubDocs> allSubDocs = Collections.synchronizedList(new ArrayList<SubDocs>());\n\n    final long stopTime = System.currentTimeMillis() + RUN_TIME_SEC*1000;\n    Thread[] threads = new Thread[NUM_INDEX_THREADS];\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread] = new Thread() {\n          @Override\n          public void run() {\n            // TODO: would be better if this were cross thread, so that we make sure one thread deleting anothers added docs works:\n            final List<String> toDeleteIDs = new ArrayList<String>();\n            final List<SubDocs> toDeleteSubDocs = new ArrayList<SubDocs>();\n\n            long gen = 0;\n            while(System.currentTimeMillis() < stopTime && !failed.get()) {\n\n              //System.out.println(Thread.currentThread().getName() + \": cycle\");\n              try {\n                // Occassional longish pause if running\n                // nightly\n                if (LuceneTestCase.TEST_NIGHTLY && random.nextInt(6) == 3) {\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": now long sleep\");\n                  }\n                  Thread.sleep(_TestUtil.nextInt(random, 50, 500));\n                }\n\n                // Rate limit ingest rate:\n                Thread.sleep(_TestUtil.nextInt(random, 1, 10));\n                if (VERBOSE) {\n                  System.out.println(Thread.currentThread() + \": done sleep\");\n                }\n\n                Document doc = docs.nextDoc();\n                if (doc == null) {\n                  break;\n                }\n                final String addedField;\n                if (random.nextBoolean()) {\n                  addedField = \"extra\" + random.nextInt(10);\n                  doc.add(new Field(addedField, \"a random field\", Field.Store.NO, Field.Index.ANALYZED));\n                } else {\n                  addedField = null;\n                }\n                if (random.nextBoolean()) {\n\n                  if (random.nextBoolean()) {\n                    // Add a pack of adjacent sub-docs\n                    final String packID;\n                    final SubDocs delSubDocs;\n                    if (toDeleteSubDocs.size() > 0 && random.nextBoolean()) {\n                      delSubDocs = toDeleteSubDocs.get(random.nextInt(toDeleteSubDocs.size()));\n                      assert !delSubDocs.deleted;\n                      toDeleteSubDocs.remove(delSubDocs);\n                      // reuse prior packID\n                      packID = delSubDocs.packID;\n                    } else {\n                      delSubDocs = null;\n                      // make new packID\n                      packID = packCount.getAndIncrement() + \"\";\n                    }\n\n                    final Field packIDField = newField(\"packID\", packID, Field.Store.YES, Field.Index.NOT_ANALYZED);\n                    final List<String> docIDs = new ArrayList<String>();\n                    final SubDocs subDocs = new SubDocs(packID, docIDs);\n                    final List<Document> docsList = new ArrayList<Document>();\n\n                    allSubDocs.add(subDocs);\n                    doc.add(packIDField);\n                    docsList.add(cloneDoc(doc));\n                    docIDs.add(doc.get(\"docid\"));\n\n                    final int maxDocCount = _TestUtil.nextInt(random, 1, 10);\n                    while(docsList.size() < maxDocCount) {\n                      doc = docs.nextDoc();\n                      if (doc == null) {\n                        break;\n                      }\n                      docsList.add(cloneDoc(doc));\n                      docIDs.add(doc.get(\"docid\"));\n                    }\n                    addCount.addAndGet(docsList.size());\n\n                    if (delSubDocs != null) {\n                      delSubDocs.deleted = true;\n                      delIDs.addAll(delSubDocs.subIDs);\n                      delCount.addAndGet(delSubDocs.subIDs.size());\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: update pack packID=\" + delSubDocs.packID + \" count=\" + docsList.size() + \" docs=\" + docIDs);\n                      }\n                      gen = nrt.updateDocuments(new Term(\"packID\", delSubDocs.packID), docsList);\n                      /*\n                      // non-atomic:\n                      nrt.deleteDocuments(new Term(\"packID\", delSubDocs.packID));\n                      for(Document subDoc : docsList) {\n                        nrt.addDocument(subDoc);\n                      }\n                      */\n                    } else {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: add pack packID=\" + packID + \" count=\" + docsList.size() + \" docs=\" + docIDs);\n                      }\n                      gen = nrt.addDocuments(docsList);\n                      \n                      /*\n                      // non-atomic:\n                      for(Document subDoc : docsList) {\n                        nrt.addDocument(subDoc);\n                      }\n                      */\n                    }\n                    doc.removeField(\"packID\");\n\n                    if (random.nextInt(5) == 2) {\n                      if (VERBOSE) {\n                        System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + packID);\n                      }\n                      toDeleteSubDocs.add(subDocs);\n                    }\n\n                    // randomly verify the add/update \"took\":\n                    if (random.nextInt(20) == 2) {\n                      final boolean applyDeletes = delSubDocs != null;\n                      final IndexSearcher s = nrt.get(gen, applyDeletes);\n                      try {\n                        assertEquals(docsList.size(), s.search(new TermQuery(new Term(\"packID\", packID)), 10).totalHits);\n                      } finally {\n                        nrt.release(s);\n                      }\n                    }\n\n                  } else {\n                    if (VERBOSE) {\n                      System.out.println(Thread.currentThread().getName() + \": add doc docid:\" + doc.get(\"docid\"));\n                    }\n\n                    gen = nrt.addDocument(doc);\n                    addCount.getAndIncrement();\n\n                    // randomly verify the add \"took\":\n                    if (random.nextInt(20) == 2) {\n                      //System.out.println(Thread.currentThread().getName() + \": verify\");\n                      final IndexSearcher s = nrt.get(gen, false);\n                      //System.out.println(Thread.currentThread().getName() + \": got s=\" + s);\n                      try {\n                        assertEquals(1, s.search(new TermQuery(new Term(\"docid\", doc.get(\"docid\"))), 10).totalHits);\n                      } finally {\n                        nrt.release(s);\n                      }\n                      //System.out.println(Thread.currentThread().getName() + \": done verify\");\n                    }\n\n                    if (random.nextInt(5) == 3) {\n                      if (VERBOSE) {\n                        System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                      }\n                      toDeleteIDs.add(doc.get(\"docid\"));\n                    }\n                  }\n                } else {\n                  // we use update but it never replaces a\n                  // prior doc\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": update doc id:\" + doc.get(\"docid\"));\n                  }\n                  gen = nrt.updateDocument(new Term(\"docid\", doc.get(\"docid\")), doc);\n                  addCount.getAndIncrement();\n\n                  // randomly verify the add \"took\":\n                  if (random.nextInt(20) == 2) {\n                    final IndexSearcher s = nrt.get(gen, true);\n                    try {\n                      assertEquals(1, s.search(new TermQuery(new Term(\"docid\", doc.get(\"docid\"))), 10).totalHits);\n                    } finally {\n                      nrt.release(s);\n                    }\n                  }\n\n                  if (random.nextInt(5) == 3) {\n                    if (VERBOSE) {\n                      System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                    }\n                    toDeleteIDs.add(doc.get(\"docid\"));\n                  }\n                }\n\n                if (random.nextInt(30) == 17) {\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": apply \" + toDeleteIDs.size() + \" deletes\");\n                  }\n                  for(String id : toDeleteIDs) {\n                    if (VERBOSE) {\n                      System.out.println(Thread.currentThread().getName() + \": del term=id:\" + id);\n                    }\n                    gen = nrt.deleteDocuments(new Term(\"docid\", id));\n\n                    // randomly verify the delete \"took\":\n                    if (random.nextInt(20) == 7) {\n                      final IndexSearcher s = nrt.get(gen, true);\n                      try {\n                        assertEquals(0, s.search(new TermQuery(new Term(\"docid\", id)), 10).totalHits);\n                      } finally {\n                        nrt.release(s);\n                      }\n                    }\n                  }\n\n                  final int count = delCount.addAndGet(toDeleteIDs.size());\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": tot \" + count + \" deletes\");\n                  }\n                  delIDs.addAll(toDeleteIDs);\n                  toDeleteIDs.clear();\n\n                  for(SubDocs subDocs : toDeleteSubDocs) {\n                    assertTrue(!subDocs.deleted);\n                    gen = nrt.deleteDocuments(new Term(\"packID\", subDocs.packID));\n                    subDocs.deleted = true;\n                    if (VERBOSE) {\n                      System.out.println(\"  del subs: \" + subDocs.subIDs + \" packID=\" + subDocs.packID);\n                    }\n                    delIDs.addAll(subDocs.subIDs);\n                    delCount.addAndGet(subDocs.subIDs.size());\n\n                    // randomly verify the delete \"took\":\n                    if (random.nextInt(20) == 7) {\n                      final IndexSearcher s = nrt.get(gen, true);\n                      try {\n                        assertEquals(0, s.search(new TermQuery(new Term(\"packID\", subDocs.packID)), 1).totalHits);\n                      } finally {\n                        nrt.release(s);\n                      }\n                    }\n                  }\n                  toDeleteSubDocs.clear();\n                }\n                if (addedField != null) {\n                  doc.removeField(addedField);\n                }\n              } catch (Throwable t) {\n                System.out.println(Thread.currentThread().getName() + \": FAILED: hit exc\");\n                t.printStackTrace();\n                failed.set(true);\n                throw new RuntimeException(t);\n              }\n            }\n\n            lastGens.add(gen);\n            if (VERBOSE) {\n              System.out.println(Thread.currentThread().getName() + \": indexing done\");\n            }\n          }\n        };\n      threads[thread].setDaemon(true);\n      threads[thread].start();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: DONE start indexing threads [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    // let index build up a bit\n    Thread.sleep(100);\n\n    // silly starting guess:\n    final AtomicInteger totTermCount = new AtomicInteger(100);\n\n    // run search threads\n    final Thread[] searchThreads = new Thread[NUM_SEARCH_THREADS];\n    final AtomicInteger totHits = new AtomicInteger();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: start search threads\");\n    }\n\n    for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n      searchThreads[thread] = new Thread() {\n          @Override\n          public void run() {\n            while(System.currentTimeMillis() < stopTime && !failed.get()) {\n              final IndexSearcher s = nrt.get(random.nextBoolean());\n              try {\n                try {\n                  smokeTestSearcher(s);\n                  if (s.getIndexReader().numDocs() > 0) {\n                    Fields fields = MultiFields.getFields(s.getIndexReader());\n                    if (fields == null) {\n                      continue;\n                    }\n                    Terms terms = fields.terms(\"body\");\n                    if (terms == null) {\n                      continue;\n                    }\n\n                    TermsEnum termsEnum = terms.iterator();\n                    int seenTermCount = 0;\n                    int shift;\n                    int trigger;\n                    if (totTermCount.get() == 0) {\n                      shift = 0;\n                      trigger = 1;\n                    } else {\n                      shift = random.nextInt(totTermCount.get()/10);\n                      trigger = totTermCount.get()/10;\n                    }\n\n                    while(System.currentTimeMillis() < stopTime) {\n                      BytesRef term = termsEnum.next();\n                      if (term == null) {\n                        if (seenTermCount == 0) {\n                          break;\n                        }\n                        totTermCount.set(seenTermCount);\n                        seenTermCount = 0;\n                        if (totTermCount.get() == 0) {\n                          shift = 0;\n                          trigger = 1;\n                        } else {\n                          trigger = totTermCount.get()/10;\n                          //System.out.println(\"trigger \" + trigger);\n                          shift = random.nextInt(totTermCount.get()/10);\n                        }\n                        termsEnum.seek(new BytesRef(\"\"));\n                        continue;\n                      }\n                      seenTermCount++;\n                      // search 10 terms\n                      if (trigger == 0) {\n                        trigger = 1;\n                      }\n                      if ((seenTermCount + shift) % trigger == 0) {\n                        //if (VERBOSE) {\n                        //System.out.println(Thread.currentThread().getName() + \" now search body:\" + term.utf8ToString());\n                        //}\n                        totHits.addAndGet(runQuery(s, new TermQuery(new Term(\"body\", term))));\n                      }\n                    }\n                    if (VERBOSE) {\n                      System.out.println(Thread.currentThread().getName() + \": search done\");\n                    }\n                  }\n                } finally {\n                  nrt.release(s);\n                }\n              } catch (Throwable t) {\n                System.out.println(Thread.currentThread().getName() + \": FAILED: hit exc\");\n                failed.set(true);\n                t.printStackTrace(System.out);\n                throw new RuntimeException(t);\n              }\n            }\n          }\n        };\n      searchThreads[thread].setDaemon(true);\n      searchThreads[thread].start();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now join\");\n    }\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread].join();\n    }\n    for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n      searchThreads[thread].join();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: done join [\" + (System.currentTimeMillis()-t0) + \" ms]; addCount=\" + addCount + \" delCount=\" + delCount);\n      System.out.println(\"TEST: search totHits=\" + totHits);\n    }\n\n    long maxGen = 0;\n    for(long gen : lastGens) {\n      maxGen = Math.max(maxGen, gen);\n    }\n\n    final IndexSearcher s = nrt.get(maxGen, true);\n\n    boolean doFail = false;\n    for(String id : delIDs) {\n      final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", id)), 1);\n      if (hits.totalHits != 0) {\n        System.out.println(\"doc id=\" + id + \" is supposed to be deleted, but got docID=\" + hits.scoreDocs[0].doc);\n        doFail = true;\n      }\n    }\n\n    // Make sure each group of sub-docs are still in docID order:\n    for(SubDocs subDocs : allSubDocs) {\n      if (!subDocs.deleted) {\n        // We sort by relevance but the scores should be identical so sort falls back to by docID:\n        TopDocs hits = s.search(new TermQuery(new Term(\"packID\", subDocs.packID)), 20);\n        assertEquals(subDocs.subIDs.size(), hits.totalHits);\n        int lastDocID = -1;\n        int startDocID = -1;\n        for(ScoreDoc scoreDoc : hits.scoreDocs) {\n          final int docID = scoreDoc.doc;\n          if (lastDocID != -1) {\n            assertEquals(1+lastDocID, docID);\n          } else {\n            startDocID = docID;\n          }\n          lastDocID = docID;\n          final Document doc = s.doc(docID);\n          assertEquals(subDocs.packID, doc.get(\"packID\"));\n        }\n\n        lastDocID = startDocID - 1;\n        for(String subID : subDocs.subIDs) {\n          hits = s.search(new TermQuery(new Term(\"docid\", subID)), 1);\n          assertEquals(1, hits.totalHits);\n          final int docID = hits.scoreDocs[0].doc;\n          if (lastDocID != -1) {\n            assertEquals(1+lastDocID, docID);\n          }\n          lastDocID = docID;\n        }          \n      } else {\n        for(String subID : subDocs.subIDs) {\n          assertEquals(0, s.search(new TermQuery(new Term(\"docid\", subID)), 1).totalHits);\n        }\n      }\n    }\n    \n    final int endID = Integer.parseInt(docs.nextDoc().get(\"docid\"));\n    for(int id=0;id<endID;id++) {\n      String stringID = \"\"+id;\n      if (!delIDs.contains(stringID)) {\n        final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", stringID)), 1);\n        if (hits.totalHits != 1) {\n          System.out.println(\"doc id=\" + stringID + \" is not supposed to be deleted, but got hitCount=\" + hits.totalHits);\n          doFail = true;\n        }\n      }\n    }\n    assertFalse(doFail);\n\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), s.getIndexReader().numDocs());\n    nrt.release(s);\n\n    if (es != null) {\n      es.shutdown();\n      es.awaitTermination(1, TimeUnit.SECONDS);\n    }\n\n    writer.commit();\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), writer.numDocs());\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now close NRTManager\");\n    }\n    nrtThread.close();\n    nrt.close();\n    assertFalse(writer.anyNonBulkMerges);\n    writer.close(false);\n    _TestUtil.checkIndex(dir);\n    dir.close();\n    _TestUtil.rmDir(tempDir);\n    docs.close();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testNRTManager() throws Exception {\n\n    final long t0 = System.currentTimeMillis();\n\n    if (CodecProvider.getDefault().getDefaultFieldCodec().equals(\"SimpleText\")) {\n      // no\n      CodecProvider.getDefault().setDefaultFieldCodec(\"Standard\");\n    }\n\n    final LineFileDocs docs = new LineFileDocs(random);\n    final File tempDir = _TestUtil.getTempDir(\"nrtopenfiles\");\n    final MockDirectoryWrapper _dir = newFSDirectory(tempDir);\n    _dir.setCheckIndexOnClose(false);  // don't double-checkIndex, we do it ourselves\n    Directory dir = _dir;\n    final IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).setOpenMode(IndexWriterConfig.OpenMode.CREATE);\n\n    // newIWConfig makes smallish max seg size, which\n    // results in tons and tons of segments for this test\n    // when run nightly:\n    MergePolicy mp = conf.getMergePolicy();\n    if (mp instanceof TieredMergePolicy) {\n      ((TieredMergePolicy) mp).setMaxMergedSegmentMB(5000.);\n    } else if (mp instanceof LogByteSizeMergePolicy) {\n      ((LogByteSizeMergePolicy) mp).setMaxMergeMB(1000.);\n    } else if (mp instanceof LogMergePolicy) {\n      ((LogMergePolicy) mp).setMaxMergeDocs(100000);\n    }\n\n    conf.setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n      @Override\n      public void warm(IndexReader reader) throws IOException {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now warm merged reader=\" + reader);\n        }\n        final int maxDoc = reader.maxDoc();\n        final Bits delDocs = reader.getDeletedDocs();\n        int sum = 0;\n        final int inc = Math.max(1, maxDoc/50);\n        for(int docID=0;docID<maxDoc;docID += inc) {\n          if (delDocs == null || !delDocs.get(docID)) {\n            final Document doc = reader.document(docID);\n            sum += doc.getFields().size();\n          }\n        }\n\n        IndexSearcher searcher = newSearcher(reader);\n        sum += searcher.search(new TermQuery(new Term(\"body\", \"united\")), 10).totalHits;\n        searcher.close();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: warm visited \" + sum + \" fields\");\n        }\n      }\n      });\n\n    if (random.nextBoolean()) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: wrap NRTCachingDir\");\n      }\n\n      NRTCachingDirectory nrtDir = new NRTCachingDirectory(dir, 5.0, 60.0);\n      conf.setMergeScheduler(nrtDir.getMergeScheduler());\n      dir = nrtDir;\n    }\n    \n    final IndexWriter writer = new IndexWriter(dir, conf);\n    \n    if (VERBOSE) {\n      writer.setInfoStream(System.out);\n    }\n    _TestUtil.reduceOpenFiles(writer);\n    //System.out.println(\"TEST: conf=\" + writer.getConfig());\n\n    final ExecutorService es = random.nextBoolean() ? null : Executors.newCachedThreadPool(new NamedThreadFactory(\"NRT search threads\"));\n\n    final double minReopenSec = 0.01 + 0.05 * random.nextDouble();\n    final double maxReopenSec = minReopenSec * (1.0 + 10 * random.nextDouble());\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: make NRTManager maxReopenSec=\" + maxReopenSec + \" minReopenSec=\" + minReopenSec);\n    }\n\n    final NRTManager nrt = new NRTManager(writer, es);\n    final NRTManagerReopenThread nrtThread = new NRTManagerReopenThread(nrt, maxReopenSec, minReopenSec);\n    nrtThread.setName(\"NRT Reopen Thread\");\n    nrtThread.setPriority(Math.min(Thread.currentThread().getPriority()+2, Thread.MAX_PRIORITY));\n    nrtThread.setDaemon(true);\n    nrtThread.start();\n\n    final int NUM_INDEX_THREADS = _TestUtil.nextInt(random, 1, 3);\n    final int NUM_SEARCH_THREADS = _TestUtil.nextInt(random, 1, 3);\n    //final int NUM_INDEX_THREADS = 1;\n    //final int NUM_SEARCH_THREADS = 1;\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + NUM_INDEX_THREADS + \" index threads; \" + NUM_SEARCH_THREADS + \" search threads\");\n    }\n\n    final int RUN_TIME_SEC = LuceneTestCase.TEST_NIGHTLY ? 300 : 5;\n\n    final AtomicBoolean failed = new AtomicBoolean();\n    final AtomicInteger addCount = new AtomicInteger();\n    final AtomicInteger delCount = new AtomicInteger();\n    final AtomicInteger packCount = new AtomicInteger();\n    final List<Long> lastGens = new ArrayList<Long>();\n\n    final Set<String> delIDs = Collections.synchronizedSet(new HashSet<String>());\n    final List<SubDocs> allSubDocs = Collections.synchronizedList(new ArrayList<SubDocs>());\n\n    final long stopTime = System.currentTimeMillis() + RUN_TIME_SEC*1000;\n    Thread[] threads = new Thread[NUM_INDEX_THREADS];\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread] = new Thread() {\n          @Override\n          public void run() {\n            // TODO: would be better if this were cross thread, so that we make sure one thread deleting anothers added docs works:\n            final List<String> toDeleteIDs = new ArrayList<String>();\n            final List<SubDocs> toDeleteSubDocs = new ArrayList<SubDocs>();\n\n            long gen = 0;\n            while(System.currentTimeMillis() < stopTime && !failed.get()) {\n\n              //System.out.println(Thread.currentThread().getName() + \": cycle\");\n              try {\n                // Occassional longish pause if running\n                // nightly\n                if (LuceneTestCase.TEST_NIGHTLY && random.nextInt(6) == 3) {\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": now long sleep\");\n                  }\n                  Thread.sleep(_TestUtil.nextInt(random, 50, 500));\n                }\n\n                // Rate limit ingest rate:\n                Thread.sleep(_TestUtil.nextInt(random, 1, 10));\n                if (VERBOSE) {\n                  System.out.println(Thread.currentThread() + \": done sleep\");\n                }\n\n                Document doc = docs.nextDoc();\n                if (doc == null) {\n                  break;\n                }\n                final String addedField;\n                if (random.nextBoolean()) {\n                  addedField = \"extra\" + random.nextInt(10);\n                  doc.add(new Field(addedField, \"a random field\", Field.Store.NO, Field.Index.ANALYZED));\n                } else {\n                  addedField = null;\n                }\n                if (random.nextBoolean()) {\n\n                  if (random.nextBoolean()) {\n                    // Add a pack of adjacent sub-docs\n                    final String packID;\n                    final SubDocs delSubDocs;\n                    if (toDeleteSubDocs.size() > 0 && random.nextBoolean()) {\n                      delSubDocs = toDeleteSubDocs.get(random.nextInt(toDeleteSubDocs.size()));\n                      assert !delSubDocs.deleted;\n                      toDeleteSubDocs.remove(delSubDocs);\n                      // reuse prior packID\n                      packID = delSubDocs.packID;\n                    } else {\n                      delSubDocs = null;\n                      // make new packID\n                      packID = packCount.getAndIncrement() + \"\";\n                    }\n\n                    final Field packIDField = newField(\"packID\", packID, Field.Store.YES, Field.Index.NOT_ANALYZED);\n                    final List<String> docIDs = new ArrayList<String>();\n                    final SubDocs subDocs = new SubDocs(packID, docIDs);\n                    final List<Document> docsList = new ArrayList<Document>();\n\n                    allSubDocs.add(subDocs);\n                    doc.add(packIDField);\n                    docsList.add(cloneDoc(doc));\n                    docIDs.add(doc.get(\"docid\"));\n\n                    final int maxDocCount = _TestUtil.nextInt(random, 1, 10);\n                    while(docsList.size() < maxDocCount) {\n                      doc = docs.nextDoc();\n                      if (doc == null) {\n                        break;\n                      }\n                      docsList.add(cloneDoc(doc));\n                      docIDs.add(doc.get(\"docid\"));\n                    }\n                    addCount.addAndGet(docsList.size());\n\n                    if (delSubDocs != null) {\n                      delSubDocs.deleted = true;\n                      delIDs.addAll(delSubDocs.subIDs);\n                      delCount.addAndGet(delSubDocs.subIDs.size());\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: update pack packID=\" + delSubDocs.packID + \" count=\" + docsList.size() + \" docs=\" + docIDs);\n                      }\n                      gen = nrt.updateDocuments(new Term(\"packID\", delSubDocs.packID), docsList);\n                      /*\n                      // non-atomic:\n                      nrt.deleteDocuments(new Term(\"packID\", delSubDocs.packID));\n                      for(Document subDoc : docsList) {\n                        nrt.addDocument(subDoc);\n                      }\n                      */\n                    } else {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: add pack packID=\" + packID + \" count=\" + docsList.size() + \" docs=\" + docIDs);\n                      }\n                      gen = nrt.addDocuments(docsList);\n                      \n                      /*\n                      // non-atomic:\n                      for(Document subDoc : docsList) {\n                        nrt.addDocument(subDoc);\n                      }\n                      */\n                    }\n                    doc.removeField(\"packID\");\n\n                    if (random.nextInt(5) == 2) {\n                      if (VERBOSE) {\n                        System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + packID);\n                      }\n                      toDeleteSubDocs.add(subDocs);\n                    }\n\n                    // randomly verify the add/update \"took\":\n                    if (random.nextInt(20) == 2) {\n                      final boolean applyDeletes = delSubDocs != null;\n                      final IndexSearcher s = nrt.get(gen, applyDeletes);\n                      try {\n                        assertEquals(docsList.size(), s.search(new TermQuery(new Term(\"packID\", packID)), 10).totalHits);\n                      } finally {\n                        nrt.release(s);\n                      }\n                    }\n\n                  } else {\n                    if (VERBOSE) {\n                      System.out.println(Thread.currentThread().getName() + \": add doc docid:\" + doc.get(\"docid\"));\n                    }\n\n                    gen = nrt.addDocument(doc);\n                    addCount.getAndIncrement();\n\n                    // randomly verify the add \"took\":\n                    if (random.nextInt(20) == 2) {\n                      //System.out.println(Thread.currentThread().getName() + \": verify\");\n                      final IndexSearcher s = nrt.get(gen, false);\n                      //System.out.println(Thread.currentThread().getName() + \": got s=\" + s);\n                      try {\n                        assertEquals(1, s.search(new TermQuery(new Term(\"docid\", doc.get(\"docid\"))), 10).totalHits);\n                      } finally {\n                        nrt.release(s);\n                      }\n                      //System.out.println(Thread.currentThread().getName() + \": done verify\");\n                    }\n\n                    if (random.nextInt(5) == 3) {\n                      if (VERBOSE) {\n                        System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                      }\n                      toDeleteIDs.add(doc.get(\"docid\"));\n                    }\n                  }\n                } else {\n                  // we use update but it never replaces a\n                  // prior doc\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": update doc id:\" + doc.get(\"docid\"));\n                  }\n                  gen = nrt.updateDocument(new Term(\"docid\", doc.get(\"docid\")), doc);\n                  addCount.getAndIncrement();\n\n                  // randomly verify the add \"took\":\n                  if (random.nextInt(20) == 2) {\n                    final IndexSearcher s = nrt.get(gen, true);\n                    try {\n                      assertEquals(1, s.search(new TermQuery(new Term(\"docid\", doc.get(\"docid\"))), 10).totalHits);\n                    } finally {\n                      nrt.release(s);\n                    }\n                  }\n\n                  if (random.nextInt(5) == 3) {\n                    if (VERBOSE) {\n                      System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                    }\n                    toDeleteIDs.add(doc.get(\"docid\"));\n                  }\n                }\n\n                if (random.nextInt(30) == 17) {\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": apply \" + toDeleteIDs.size() + \" deletes\");\n                  }\n                  for(String id : toDeleteIDs) {\n                    if (VERBOSE) {\n                      System.out.println(Thread.currentThread().getName() + \": del term=id:\" + id);\n                    }\n                    gen = nrt.deleteDocuments(new Term(\"docid\", id));\n\n                    // randomly verify the delete \"took\":\n                    if (random.nextInt(20) == 7) {\n                      final IndexSearcher s = nrt.get(gen, true);\n                      try {\n                        assertEquals(0, s.search(new TermQuery(new Term(\"docid\", id)), 10).totalHits);\n                      } finally {\n                        nrt.release(s);\n                      }\n                    }\n                  }\n\n                  final int count = delCount.addAndGet(toDeleteIDs.size());\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": tot \" + count + \" deletes\");\n                  }\n                  delIDs.addAll(toDeleteIDs);\n                  toDeleteIDs.clear();\n\n                  for(SubDocs subDocs : toDeleteSubDocs) {\n                    assertTrue(!subDocs.deleted);\n                    gen = nrt.deleteDocuments(new Term(\"packID\", subDocs.packID));\n                    subDocs.deleted = true;\n                    if (VERBOSE) {\n                      System.out.println(\"  del subs: \" + subDocs.subIDs + \" packID=\" + subDocs.packID);\n                    }\n                    delIDs.addAll(subDocs.subIDs);\n                    delCount.addAndGet(subDocs.subIDs.size());\n\n                    // randomly verify the delete \"took\":\n                    if (random.nextInt(20) == 7) {\n                      final IndexSearcher s = nrt.get(gen, true);\n                      try {\n                        assertEquals(0, s.search(new TermQuery(new Term(\"packID\", subDocs.packID)), 1).totalHits);\n                      } finally {\n                        nrt.release(s);\n                      }\n                    }\n                  }\n                  toDeleteSubDocs.clear();\n                }\n                if (addedField != null) {\n                  doc.removeField(addedField);\n                }\n              } catch (Throwable t) {\n                System.out.println(Thread.currentThread().getName() + \": FAILED: hit exc\");\n                t.printStackTrace();\n                failed.set(true);\n                throw new RuntimeException(t);\n              }\n            }\n\n            lastGens.add(gen);\n            if (VERBOSE) {\n              System.out.println(Thread.currentThread().getName() + \": indexing done\");\n            }\n          }\n        };\n      threads[thread].setDaemon(true);\n      threads[thread].start();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: DONE start indexing threads [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    // let index build up a bit\n    Thread.sleep(100);\n\n    // silly starting guess:\n    final AtomicInteger totTermCount = new AtomicInteger(100);\n\n    // run search threads\n    final Thread[] searchThreads = new Thread[NUM_SEARCH_THREADS];\n    final AtomicInteger totHits = new AtomicInteger();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: start search threads\");\n    }\n\n    for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n      searchThreads[thread] = new Thread() {\n          @Override\n          public void run() {\n            while(System.currentTimeMillis() < stopTime && !failed.get()) {\n              final IndexSearcher s = nrt.get(random.nextBoolean());\n              try {\n                try {\n                  smokeTestSearcher(s);\n                  if (s.getIndexReader().numDocs() > 0) {\n                    Fields fields = MultiFields.getFields(s.getIndexReader());\n                    if (fields == null) {\n                      continue;\n                    }\n                    Terms terms = fields.terms(\"body\");\n                    if (terms == null) {\n                      continue;\n                    }\n\n                    TermsEnum termsEnum = terms.iterator();\n                    int seenTermCount = 0;\n                    int shift;\n                    int trigger;\n                    if (totTermCount.get() == 0) {\n                      shift = 0;\n                      trigger = 1;\n                    } else {\n                      shift = random.nextInt(totTermCount.get()/10);\n                      trigger = totTermCount.get()/10;\n                    }\n\n                    while(System.currentTimeMillis() < stopTime) {\n                      BytesRef term = termsEnum.next();\n                      if (term == null) {\n                        if (seenTermCount == 0) {\n                          break;\n                        }\n                        totTermCount.set(seenTermCount);\n                        seenTermCount = 0;\n                        if (totTermCount.get() == 0) {\n                          shift = 0;\n                          trigger = 1;\n                        } else {\n                          trigger = totTermCount.get()/10;\n                          //System.out.println(\"trigger \" + trigger);\n                          shift = random.nextInt(totTermCount.get()/10);\n                        }\n                        termsEnum.seek(new BytesRef(\"\"));\n                        continue;\n                      }\n                      seenTermCount++;\n                      // search 10 terms\n                      if (trigger == 0) {\n                        trigger = 1;\n                      }\n                      if ((seenTermCount + shift) % trigger == 0) {\n                        //if (VERBOSE) {\n                        //System.out.println(Thread.currentThread().getName() + \" now search body:\" + term.utf8ToString());\n                        //}\n                        totHits.addAndGet(runQuery(s, new TermQuery(new Term(\"body\", term))));\n                      }\n                    }\n                    if (VERBOSE) {\n                      System.out.println(Thread.currentThread().getName() + \": search done\");\n                    }\n                  }\n                } finally {\n                  nrt.release(s);\n                }\n              } catch (Throwable t) {\n                System.out.println(Thread.currentThread().getName() + \": FAILED: hit exc\");\n                failed.set(true);\n                t.printStackTrace(System.out);\n                throw new RuntimeException(t);\n              }\n            }\n          }\n        };\n      searchThreads[thread].setDaemon(true);\n      searchThreads[thread].start();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now join\");\n    }\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread].join();\n    }\n    for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n      searchThreads[thread].join();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: done join [\" + (System.currentTimeMillis()-t0) + \" ms]; addCount=\" + addCount + \" delCount=\" + delCount);\n      System.out.println(\"TEST: search totHits=\" + totHits);\n    }\n\n    long maxGen = 0;\n    for(long gen : lastGens) {\n      maxGen = Math.max(maxGen, gen);\n    }\n\n    final IndexSearcher s = nrt.get(maxGen, true);\n\n    boolean doFail = false;\n    for(String id : delIDs) {\n      final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", id)), 1);\n      if (hits.totalHits != 0) {\n        System.out.println(\"doc id=\" + id + \" is supposed to be deleted, but got docID=\" + hits.scoreDocs[0].doc);\n        doFail = true;\n      }\n    }\n\n    // Make sure each group of sub-docs are still in docID order:\n    for(SubDocs subDocs : allSubDocs) {\n      if (!subDocs.deleted) {\n        // We sort by relevance but the scores should be identical so sort falls back to by docID:\n        TopDocs hits = s.search(new TermQuery(new Term(\"packID\", subDocs.packID)), 20);\n        assertEquals(subDocs.subIDs.size(), hits.totalHits);\n        int lastDocID = -1;\n        int startDocID = -1;\n        for(ScoreDoc scoreDoc : hits.scoreDocs) {\n          final int docID = scoreDoc.doc;\n          if (lastDocID != -1) {\n            assertEquals(1+lastDocID, docID);\n          } else {\n            startDocID = docID;\n          }\n          lastDocID = docID;\n          final Document doc = s.doc(docID);\n          assertEquals(subDocs.packID, doc.get(\"packID\"));\n        }\n\n        lastDocID = startDocID - 1;\n        for(String subID : subDocs.subIDs) {\n          hits = s.search(new TermQuery(new Term(\"docid\", subID)), 1);\n          assertEquals(1, hits.totalHits);\n          final int docID = hits.scoreDocs[0].doc;\n          if (lastDocID != -1) {\n            assertEquals(1+lastDocID, docID);\n          }\n          lastDocID = docID;\n        }          \n      } else {\n        for(String subID : subDocs.subIDs) {\n          assertEquals(0, s.search(new TermQuery(new Term(\"docid\", subID)), 1).totalHits);\n        }\n      }\n    }\n    \n    final int endID = Integer.parseInt(docs.nextDoc().get(\"docid\"));\n    for(int id=0;id<endID;id++) {\n      String stringID = \"\"+id;\n      if (!delIDs.contains(stringID)) {\n        final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", stringID)), 1);\n        if (hits.totalHits != 1) {\n          System.out.println(\"doc id=\" + stringID + \" is not supposed to be deleted, but got hitCount=\" + hits.totalHits);\n          doFail = true;\n        }\n      }\n    }\n    assertFalse(doFail);\n\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), s.getIndexReader().numDocs());\n    nrt.release(s);\n\n    if (es != null) {\n      es.shutdown();\n      es.awaitTermination(1, TimeUnit.SECONDS);\n    }\n\n    writer.commit();\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), writer.numDocs());\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now close NRTManager\");\n    }\n    nrtThread.close();\n    nrt.close();\n    assertFalse(writer.anyNonBulkMerges);\n    writer.close(false);\n    _TestUtil.checkIndex(dir);\n    dir.close();\n    _TestUtil.rmDir(tempDir);\n    docs.close();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9ed208afa1e7aa98899ddb1dedfddedddf898253","date":1308079587,"type":0,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/contrib/misc/src/test/org/apache/lucene/index/TestNRTManager#testNRTManager().mjava","pathOld":"/dev/null","sourceNew":"  @Test\n  public void testNRTManager() throws Exception {\n\n    final long t0 = System.currentTimeMillis();\n\n    if (CodecProvider.getDefault().getDefaultFieldCodec().equals(\"SimpleText\")) {\n      // no\n      CodecProvider.getDefault().setDefaultFieldCodec(\"Standard\");\n    }\n\n    final LineFileDocs docs = new LineFileDocs(random);\n    final File tempDir = _TestUtil.getTempDir(\"nrtopenfiles\");\n    final MockDirectoryWrapper _dir = newFSDirectory(tempDir);\n    _dir.setCheckIndexOnClose(false);  // don't double-checkIndex, we do it ourselves\n    Directory dir = _dir;\n    final IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).setOpenMode(IndexWriterConfig.OpenMode.CREATE);\n\n    if (LuceneTestCase.TEST_NIGHTLY) {\n      // newIWConfig makes smallish max seg size, which\n      // results in tons and tons of segments for this test\n      // when run nightly:\n      MergePolicy mp = conf.getMergePolicy();\n      if (mp instanceof TieredMergePolicy) {\n        ((TieredMergePolicy) mp).setMaxMergedSegmentMB(5000.);\n      } else if (mp instanceof LogByteSizeMergePolicy) {\n        ((LogByteSizeMergePolicy) mp).setMaxMergeMB(1000.);\n      } else if (mp instanceof LogMergePolicy) {\n        ((LogMergePolicy) mp).setMaxMergeDocs(100000);\n      }\n    }\n\n    conf.setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n      @Override\n      public void warm(IndexReader reader) throws IOException {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now warm merged reader=\" + reader);\n        }\n        final int maxDoc = reader.maxDoc();\n        final Bits delDocs = reader.getDeletedDocs();\n        int sum = 0;\n        final int inc = Math.max(1, maxDoc/50);\n        for(int docID=0;docID<maxDoc;docID += inc) {\n          if (delDocs == null || !delDocs.get(docID)) {\n            final Document doc = reader.document(docID);\n            sum += doc.getFields().size();\n          }\n        }\n\n        IndexSearcher searcher = newSearcher(reader);\n        sum += searcher.search(new TermQuery(new Term(\"body\", \"united\")), 10).totalHits;\n        searcher.close();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: warm visited \" + sum + \" fields\");\n        }\n      }\n      });\n\n    if (random.nextBoolean()) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: wrap NRTCachingDir\");\n      }\n\n      NRTCachingDirectory nrtDir = new NRTCachingDirectory(dir, 5.0, 60.0);\n      conf.setMergeScheduler(nrtDir.getMergeScheduler());\n      dir = nrtDir;\n    }\n    \n    final IndexWriter writer = new IndexWriter(dir, conf);\n    \n    if (VERBOSE) {\n      writer.setInfoStream(System.out);\n    }\n    _TestUtil.reduceOpenFiles(writer);\n    //System.out.println(\"TEST: conf=\" + writer.getConfig());\n\n    final ExecutorService es = random.nextBoolean() ? null : Executors.newCachedThreadPool(new NamedThreadFactory(\"NRT search threads\"));\n\n    final double minReopenSec = 0.01 + 0.05 * random.nextDouble();\n    final double maxReopenSec = minReopenSec * (1.0 + 10 * random.nextDouble());\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: make NRTManager maxReopenSec=\" + maxReopenSec + \" minReopenSec=\" + minReopenSec);\n    }\n\n    final NRTManager nrt = new NRTManager(writer, es);\n    final NRTManagerReopenThread nrtThread = new NRTManagerReopenThread(nrt, maxReopenSec, minReopenSec);\n    nrtThread.setName(\"NRT Reopen Thread\");\n    nrtThread.setPriority(Math.min(Thread.currentThread().getPriority()+2, Thread.MAX_PRIORITY));\n    nrtThread.setDaemon(true);\n    nrtThread.start();\n\n    final int NUM_INDEX_THREADS = _TestUtil.nextInt(random, 1, 3);\n    final int NUM_SEARCH_THREADS = _TestUtil.nextInt(random, 1, 3);\n    //final int NUM_INDEX_THREADS = 1;\n    //final int NUM_SEARCH_THREADS = 1;\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + NUM_INDEX_THREADS + \" index threads; \" + NUM_SEARCH_THREADS + \" search threads\");\n    }\n\n    final int RUN_TIME_SEC = LuceneTestCase.TEST_NIGHTLY ? 300 : RANDOM_MULTIPLIER;\n\n    final AtomicBoolean failed = new AtomicBoolean();\n    final AtomicInteger addCount = new AtomicInteger();\n    final AtomicInteger delCount = new AtomicInteger();\n    final AtomicInteger packCount = new AtomicInteger();\n    final List<Long> lastGens = new ArrayList<Long>();\n\n    final Set<String> delIDs = Collections.synchronizedSet(new HashSet<String>());\n    final List<SubDocs> allSubDocs = Collections.synchronizedList(new ArrayList<SubDocs>());\n\n    final long stopTime = System.currentTimeMillis() + RUN_TIME_SEC*1000;\n    Thread[] threads = new Thread[NUM_INDEX_THREADS];\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread] = new Thread() {\n          @Override\n          public void run() {\n            // TODO: would be better if this were cross thread, so that we make sure one thread deleting anothers added docs works:\n            final List<String> toDeleteIDs = new ArrayList<String>();\n            final List<SubDocs> toDeleteSubDocs = new ArrayList<SubDocs>();\n\n            long gen = 0;\n            while(System.currentTimeMillis() < stopTime && !failed.get()) {\n\n              //System.out.println(Thread.currentThread().getName() + \": cycle\");\n              try {\n                // Occassional longish pause if running\n                // nightly\n                if (LuceneTestCase.TEST_NIGHTLY && random.nextInt(6) == 3) {\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": now long sleep\");\n                  }\n                  Thread.sleep(_TestUtil.nextInt(random, 50, 500));\n                }\n\n                // Rate limit ingest rate:\n                Thread.sleep(_TestUtil.nextInt(random, 1, 10));\n                if (VERBOSE) {\n                  System.out.println(Thread.currentThread() + \": done sleep\");\n                }\n\n                Document doc = docs.nextDoc();\n                if (doc == null) {\n                  break;\n                }\n                final String addedField;\n                if (random.nextBoolean()) {\n                  addedField = \"extra\" + random.nextInt(10);\n                  doc.add(new Field(addedField, \"a random field\", Field.Store.NO, Field.Index.ANALYZED));\n                } else {\n                  addedField = null;\n                }\n                if (random.nextBoolean()) {\n\n                  if (random.nextBoolean()) {\n                    // Add a pack of adjacent sub-docs\n                    final String packID;\n                    final SubDocs delSubDocs;\n                    if (toDeleteSubDocs.size() > 0 && random.nextBoolean()) {\n                      delSubDocs = toDeleteSubDocs.get(random.nextInt(toDeleteSubDocs.size()));\n                      assert !delSubDocs.deleted;\n                      toDeleteSubDocs.remove(delSubDocs);\n                      // reuse prior packID\n                      packID = delSubDocs.packID;\n                    } else {\n                      delSubDocs = null;\n                      // make new packID\n                      packID = packCount.getAndIncrement() + \"\";\n                    }\n\n                    final Field packIDField = newField(\"packID\", packID, Field.Store.YES, Field.Index.NOT_ANALYZED);\n                    final List<String> docIDs = new ArrayList<String>();\n                    final SubDocs subDocs = new SubDocs(packID, docIDs);\n                    final List<Document> docsList = new ArrayList<Document>();\n\n                    allSubDocs.add(subDocs);\n                    doc.add(packIDField);\n                    docsList.add(cloneDoc(doc));\n                    docIDs.add(doc.get(\"docid\"));\n\n                    final int maxDocCount = _TestUtil.nextInt(random, 1, 10);\n                    while(docsList.size() < maxDocCount) {\n                      doc = docs.nextDoc();\n                      if (doc == null) {\n                        break;\n                      }\n                      docsList.add(cloneDoc(doc));\n                      docIDs.add(doc.get(\"docid\"));\n                    }\n                    addCount.addAndGet(docsList.size());\n\n                    if (delSubDocs != null) {\n                      delSubDocs.deleted = true;\n                      delIDs.addAll(delSubDocs.subIDs);\n                      delCount.addAndGet(delSubDocs.subIDs.size());\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: update pack packID=\" + delSubDocs.packID + \" count=\" + docsList.size() + \" docs=\" + docIDs);\n                      }\n                      gen = nrt.updateDocuments(new Term(\"packID\", delSubDocs.packID), docsList);\n                      /*\n                      // non-atomic:\n                      nrt.deleteDocuments(new Term(\"packID\", delSubDocs.packID));\n                      for(Document subDoc : docsList) {\n                        nrt.addDocument(subDoc);\n                      }\n                      */\n                    } else {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: add pack packID=\" + packID + \" count=\" + docsList.size() + \" docs=\" + docIDs);\n                      }\n                      gen = nrt.addDocuments(docsList);\n                      \n                      /*\n                      // non-atomic:\n                      for(Document subDoc : docsList) {\n                        nrt.addDocument(subDoc);\n                      }\n                      */\n                    }\n                    doc.removeField(\"packID\");\n\n                    if (random.nextInt(5) == 2) {\n                      if (VERBOSE) {\n                        System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + packID);\n                      }\n                      toDeleteSubDocs.add(subDocs);\n                    }\n\n                    // randomly verify the add/update \"took\":\n                    if (random.nextInt(20) == 2) {\n                      final boolean applyDeletes = delSubDocs != null;\n                      final IndexSearcher s = nrt.get(gen, applyDeletes);\n                      try {\n                        assertEquals(docsList.size(), s.search(new TermQuery(new Term(\"packID\", packID)), 10).totalHits);\n                      } finally {\n                        nrt.release(s);\n                      }\n                    }\n\n                  } else {\n                    if (VERBOSE) {\n                      System.out.println(Thread.currentThread().getName() + \": add doc docid:\" + doc.get(\"docid\"));\n                    }\n\n                    gen = nrt.addDocument(doc);\n                    addCount.getAndIncrement();\n\n                    // randomly verify the add \"took\":\n                    if (random.nextInt(20) == 2) {\n                      //System.out.println(Thread.currentThread().getName() + \": verify\");\n                      final IndexSearcher s = nrt.get(gen, false);\n                      //System.out.println(Thread.currentThread().getName() + \": got s=\" + s);\n                      try {\n                        assertEquals(1, s.search(new TermQuery(new Term(\"docid\", doc.get(\"docid\"))), 10).totalHits);\n                      } finally {\n                        nrt.release(s);\n                      }\n                      //System.out.println(Thread.currentThread().getName() + \": done verify\");\n                    }\n\n                    if (random.nextInt(5) == 3) {\n                      if (VERBOSE) {\n                        System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                      }\n                      toDeleteIDs.add(doc.get(\"docid\"));\n                    }\n                  }\n                } else {\n                  // we use update but it never replaces a\n                  // prior doc\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": update doc id:\" + doc.get(\"docid\"));\n                  }\n                  gen = nrt.updateDocument(new Term(\"docid\", doc.get(\"docid\")), doc);\n                  addCount.getAndIncrement();\n\n                  // randomly verify the add \"took\":\n                  if (random.nextInt(20) == 2) {\n                    final IndexSearcher s = nrt.get(gen, true);\n                    try {\n                      assertEquals(1, s.search(new TermQuery(new Term(\"docid\", doc.get(\"docid\"))), 10).totalHits);\n                    } finally {\n                      nrt.release(s);\n                    }\n                  }\n\n                  if (random.nextInt(5) == 3) {\n                    if (VERBOSE) {\n                      System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                    }\n                    toDeleteIDs.add(doc.get(\"docid\"));\n                  }\n                }\n\n                if (random.nextInt(30) == 17) {\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": apply \" + toDeleteIDs.size() + \" deletes\");\n                  }\n                  for(String id : toDeleteIDs) {\n                    if (VERBOSE) {\n                      System.out.println(Thread.currentThread().getName() + \": del term=id:\" + id);\n                    }\n                    gen = nrt.deleteDocuments(new Term(\"docid\", id));\n\n                    // randomly verify the delete \"took\":\n                    if (random.nextInt(20) == 7) {\n                      final IndexSearcher s = nrt.get(gen, true);\n                      try {\n                        assertEquals(0, s.search(new TermQuery(new Term(\"docid\", id)), 10).totalHits);\n                      } finally {\n                        nrt.release(s);\n                      }\n                    }\n                  }\n\n                  final int count = delCount.addAndGet(toDeleteIDs.size());\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": tot \" + count + \" deletes\");\n                  }\n                  delIDs.addAll(toDeleteIDs);\n                  toDeleteIDs.clear();\n\n                  for(SubDocs subDocs : toDeleteSubDocs) {\n                    assertTrue(!subDocs.deleted);\n                    gen = nrt.deleteDocuments(new Term(\"packID\", subDocs.packID));\n                    subDocs.deleted = true;\n                    if (VERBOSE) {\n                      System.out.println(\"  del subs: \" + subDocs.subIDs + \" packID=\" + subDocs.packID);\n                    }\n                    delIDs.addAll(subDocs.subIDs);\n                    delCount.addAndGet(subDocs.subIDs.size());\n\n                    // randomly verify the delete \"took\":\n                    if (random.nextInt(20) == 7) {\n                      final IndexSearcher s = nrt.get(gen, true);\n                      try {\n                        assertEquals(0, s.search(new TermQuery(new Term(\"packID\", subDocs.packID)), 1).totalHits);\n                      } finally {\n                        nrt.release(s);\n                      }\n                    }\n                  }\n                  toDeleteSubDocs.clear();\n                }\n                if (addedField != null) {\n                  doc.removeField(addedField);\n                }\n              } catch (Throwable t) {\n                System.out.println(Thread.currentThread().getName() + \": FAILED: hit exc\");\n                t.printStackTrace();\n                failed.set(true);\n                throw new RuntimeException(t);\n              }\n            }\n\n            lastGens.add(gen);\n            if (VERBOSE) {\n              System.out.println(Thread.currentThread().getName() + \": indexing done\");\n            }\n          }\n        };\n      threads[thread].setDaemon(true);\n      threads[thread].start();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: DONE start indexing threads [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    // let index build up a bit\n    Thread.sleep(100);\n\n    // silly starting guess:\n    final AtomicInteger totTermCount = new AtomicInteger(100);\n\n    // run search threads\n    final Thread[] searchThreads = new Thread[NUM_SEARCH_THREADS];\n    final AtomicInteger totHits = new AtomicInteger();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: start search threads\");\n    }\n\n    for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n      searchThreads[thread] = new Thread() {\n          @Override\n          public void run() {\n            while(System.currentTimeMillis() < stopTime && !failed.get()) {\n              final IndexSearcher s = nrt.get(random.nextBoolean());\n              try {\n                try {\n                  smokeTestSearcher(s);\n                  if (s.getIndexReader().numDocs() > 0) {\n                    Fields fields = MultiFields.getFields(s.getIndexReader());\n                    if (fields == null) {\n                      continue;\n                    }\n                    Terms terms = fields.terms(\"body\");\n                    if (terms == null) {\n                      continue;\n                    }\n\n                    TermsEnum termsEnum = terms.iterator();\n                    int seenTermCount = 0;\n                    int shift;\n                    int trigger;\n                    if (totTermCount.get() == 0) {\n                      shift = 0;\n                      trigger = 1;\n                    } else {\n                      shift = random.nextInt(totTermCount.get()/10);\n                      trigger = totTermCount.get()/10;\n                    }\n\n                    while(System.currentTimeMillis() < stopTime) {\n                      BytesRef term = termsEnum.next();\n                      if (term == null) {\n                        if (seenTermCount == 0) {\n                          break;\n                        }\n                        totTermCount.set(seenTermCount);\n                        seenTermCount = 0;\n                        if (totTermCount.get() == 0) {\n                          shift = 0;\n                          trigger = 1;\n                        } else {\n                          trigger = totTermCount.get()/10;\n                          //System.out.println(\"trigger \" + trigger);\n                          shift = random.nextInt(totTermCount.get()/10);\n                        }\n                        termsEnum.seek(new BytesRef(\"\"));\n                        continue;\n                      }\n                      seenTermCount++;\n                      // search 10 terms\n                      if (trigger == 0) {\n                        trigger = 1;\n                      }\n                      if ((seenTermCount + shift) % trigger == 0) {\n                        //if (VERBOSE) {\n                        //System.out.println(Thread.currentThread().getName() + \" now search body:\" + term.utf8ToString());\n                        //}\n                        totHits.addAndGet(runQuery(s, new TermQuery(new Term(\"body\", term))));\n                      }\n                    }\n                    if (VERBOSE) {\n                      System.out.println(Thread.currentThread().getName() + \": search done\");\n                    }\n                  }\n                } finally {\n                  nrt.release(s);\n                }\n              } catch (Throwable t) {\n                System.out.println(Thread.currentThread().getName() + \": FAILED: hit exc\");\n                failed.set(true);\n                t.printStackTrace(System.out);\n                throw new RuntimeException(t);\n              }\n            }\n          }\n        };\n      searchThreads[thread].setDaemon(true);\n      searchThreads[thread].start();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now join\");\n    }\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread].join();\n    }\n    for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n      searchThreads[thread].join();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: done join [\" + (System.currentTimeMillis()-t0) + \" ms]; addCount=\" + addCount + \" delCount=\" + delCount);\n      System.out.println(\"TEST: search totHits=\" + totHits);\n    }\n\n    long maxGen = 0;\n    for(long gen : lastGens) {\n      maxGen = Math.max(maxGen, gen);\n    }\n\n    final IndexSearcher s = nrt.get(maxGen, true);\n\n    boolean doFail = false;\n    for(String id : delIDs) {\n      final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", id)), 1);\n      if (hits.totalHits != 0) {\n        System.out.println(\"doc id=\" + id + \" is supposed to be deleted, but got docID=\" + hits.scoreDocs[0].doc);\n        doFail = true;\n      }\n    }\n\n    // Make sure each group of sub-docs are still in docID order:\n    for(SubDocs subDocs : allSubDocs) {\n      if (!subDocs.deleted) {\n        // We sort by relevance but the scores should be identical so sort falls back to by docID:\n        TopDocs hits = s.search(new TermQuery(new Term(\"packID\", subDocs.packID)), 20);\n        assertEquals(subDocs.subIDs.size(), hits.totalHits);\n        int lastDocID = -1;\n        int startDocID = -1;\n        for(ScoreDoc scoreDoc : hits.scoreDocs) {\n          final int docID = scoreDoc.doc;\n          if (lastDocID != -1) {\n            assertEquals(1+lastDocID, docID);\n          } else {\n            startDocID = docID;\n          }\n          lastDocID = docID;\n          final Document doc = s.doc(docID);\n          assertEquals(subDocs.packID, doc.get(\"packID\"));\n        }\n\n        lastDocID = startDocID - 1;\n        for(String subID : subDocs.subIDs) {\n          hits = s.search(new TermQuery(new Term(\"docid\", subID)), 1);\n          assertEquals(1, hits.totalHits);\n          final int docID = hits.scoreDocs[0].doc;\n          if (lastDocID != -1) {\n            assertEquals(1+lastDocID, docID);\n          }\n          lastDocID = docID;\n        }          \n      } else {\n        for(String subID : subDocs.subIDs) {\n          assertEquals(0, s.search(new TermQuery(new Term(\"docid\", subID)), 1).totalHits);\n        }\n      }\n    }\n    \n    final int endID = Integer.parseInt(docs.nextDoc().get(\"docid\"));\n    for(int id=0;id<endID;id++) {\n      String stringID = \"\"+id;\n      if (!delIDs.contains(stringID)) {\n        final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", stringID)), 1);\n        if (hits.totalHits != 1) {\n          System.out.println(\"doc id=\" + stringID + \" is not supposed to be deleted, but got hitCount=\" + hits.totalHits);\n          doFail = true;\n        }\n      }\n    }\n    assertFalse(doFail);\n\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), s.getIndexReader().numDocs());\n    nrt.release(s);\n\n    if (es != null) {\n      es.shutdown();\n      es.awaitTermination(1, TimeUnit.SECONDS);\n    }\n\n    writer.commit();\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), writer.numDocs());\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now close NRTManager\");\n    }\n    nrtThread.close();\n    nrt.close();\n    assertFalse(writer.anyNonBulkMerges);\n    writer.close(false);\n    _TestUtil.checkIndex(dir);\n    dir.close();\n    _TestUtil.rmDir(tempDir);\n    docs.close();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3d5626fd077eba69371a29616badd26143fea2fa","date":1308219320,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/contrib/misc/src/test/org/apache/lucene/index/TestNRTManager#testNRTManager().mjava","pathOld":"lucene/contrib/misc/src/test/org/apache/lucene/index/TestNRTManager#testNRTManager().mjava","sourceNew":"  @Test\n  public void testNRTManager() throws Exception {\n\n    final long t0 = System.currentTimeMillis();\n\n    if (CodecProvider.getDefault().getDefaultFieldCodec().equals(\"SimpleText\")) {\n      // no\n      CodecProvider.getDefault().setDefaultFieldCodec(\"Standard\");\n    }\n\n    final LineFileDocs docs = new LineFileDocs(random);\n    final File tempDir = _TestUtil.getTempDir(\"nrtopenfiles\");\n    final MockDirectoryWrapper _dir = newFSDirectory(tempDir);\n    _dir.setCheckIndexOnClose(false);  // don't double-checkIndex, we do it ourselves\n    Directory dir = _dir;\n    final IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).setOpenMode(IndexWriterConfig.OpenMode.CREATE);\n\n    if (LuceneTestCase.TEST_NIGHTLY) {\n      // newIWConfig makes smallish max seg size, which\n      // results in tons and tons of segments for this test\n      // when run nightly:\n      MergePolicy mp = conf.getMergePolicy();\n      if (mp instanceof TieredMergePolicy) {\n        ((TieredMergePolicy) mp).setMaxMergedSegmentMB(5000.);\n      } else if (mp instanceof LogByteSizeMergePolicy) {\n        ((LogByteSizeMergePolicy) mp).setMaxMergeMB(1000.);\n      } else if (mp instanceof LogMergePolicy) {\n        ((LogMergePolicy) mp).setMaxMergeDocs(100000);\n      }\n    }\n\n    conf.setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n      @Override\n      public void warm(IndexReader reader) throws IOException {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now warm merged reader=\" + reader);\n        }\n        final int maxDoc = reader.maxDoc();\n        final Bits delDocs = reader.getDeletedDocs();\n        int sum = 0;\n        final int inc = Math.max(1, maxDoc/50);\n        for(int docID=0;docID<maxDoc;docID += inc) {\n          if (delDocs == null || !delDocs.get(docID)) {\n            final Document doc = reader.document(docID);\n            sum += doc.getFields().size();\n          }\n        }\n\n        IndexSearcher searcher = newSearcher(reader);\n        sum += searcher.search(new TermQuery(new Term(\"body\", \"united\")), 10).totalHits;\n        searcher.close();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: warm visited \" + sum + \" fields\");\n        }\n      }\n      });\n\n    if (random.nextBoolean()) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: wrap NRTCachingDir\");\n      }\n\n      NRTCachingDirectory nrtDir = new NRTCachingDirectory(dir, 5.0, 60.0);\n      conf.setMergeScheduler(nrtDir.getMergeScheduler());\n      dir = nrtDir;\n    }\n    \n    final IndexWriter writer = new IndexWriter(dir, conf);\n    \n    if (VERBOSE) {\n      writer.setInfoStream(System.out);\n    }\n    _TestUtil.reduceOpenFiles(writer);\n    //System.out.println(\"TEST: conf=\" + writer.getConfig());\n\n    final ExecutorService es = random.nextBoolean() ? null : Executors.newCachedThreadPool(new NamedThreadFactory(\"NRT search threads\"));\n\n    final double minReopenSec = 0.01 + 0.05 * random.nextDouble();\n    final double maxReopenSec = minReopenSec * (1.0 + 10 * random.nextDouble());\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: make NRTManager maxReopenSec=\" + maxReopenSec + \" minReopenSec=\" + minReopenSec);\n    }\n\n    final NRTManager nrt = new NRTManager(writer, es);\n    final NRTManagerReopenThread nrtThread = new NRTManagerReopenThread(nrt, maxReopenSec, minReopenSec);\n    nrtThread.setName(\"NRT Reopen Thread\");\n    nrtThread.setPriority(Math.min(Thread.currentThread().getPriority()+2, Thread.MAX_PRIORITY));\n    nrtThread.setDaemon(true);\n    nrtThread.start();\n\n    final int NUM_INDEX_THREADS = _TestUtil.nextInt(random, 1, 3);\n    final int NUM_SEARCH_THREADS = _TestUtil.nextInt(random, 1, 3);\n    //final int NUM_INDEX_THREADS = 1;\n    //final int NUM_SEARCH_THREADS = 1;\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + NUM_INDEX_THREADS + \" index threads; \" + NUM_SEARCH_THREADS + \" search threads\");\n    }\n\n    final int RUN_TIME_SEC = LuceneTestCase.TEST_NIGHTLY ? 300 : RANDOM_MULTIPLIER;\n\n    final AtomicBoolean failed = new AtomicBoolean();\n    final AtomicInteger addCount = new AtomicInteger();\n    final AtomicInteger delCount = new AtomicInteger();\n    final AtomicInteger packCount = new AtomicInteger();\n    final List<Long> lastGens = new ArrayList<Long>();\n\n    final Set<String> delIDs = Collections.synchronizedSet(new HashSet<String>());\n    final List<SubDocs> allSubDocs = Collections.synchronizedList(new ArrayList<SubDocs>());\n\n    final long stopTime = System.currentTimeMillis() + RUN_TIME_SEC*1000;\n    Thread[] threads = new Thread[NUM_INDEX_THREADS];\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread] = new Thread() {\n          @Override\n          public void run() {\n            // TODO: would be better if this were cross thread, so that we make sure one thread deleting anothers added docs works:\n            final List<String> toDeleteIDs = new ArrayList<String>();\n            final List<SubDocs> toDeleteSubDocs = new ArrayList<SubDocs>();\n\n            long gen = 0;\n            while(System.currentTimeMillis() < stopTime && !failed.get()) {\n\n              //System.out.println(Thread.currentThread().getName() + \": cycle\");\n              try {\n                // Occassional longish pause if running\n                // nightly\n                if (LuceneTestCase.TEST_NIGHTLY && random.nextInt(6) == 3) {\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": now long sleep\");\n                  }\n                  Thread.sleep(_TestUtil.nextInt(random, 50, 500));\n                }\n\n                // Rate limit ingest rate:\n                Thread.sleep(_TestUtil.nextInt(random, 1, 10));\n                if (VERBOSE) {\n                  System.out.println(Thread.currentThread() + \": done sleep\");\n                }\n\n                Document doc = docs.nextDoc();\n                if (doc == null) {\n                  break;\n                }\n                final String addedField;\n                if (random.nextBoolean()) {\n                  addedField = \"extra\" + random.nextInt(10);\n                  doc.add(new Field(addedField, \"a random field\", Field.Store.NO, Field.Index.ANALYZED));\n                } else {\n                  addedField = null;\n                }\n                if (random.nextBoolean()) {\n\n                  if (random.nextBoolean()) {\n                    // Add a pack of adjacent sub-docs\n                    final String packID;\n                    final SubDocs delSubDocs;\n                    if (toDeleteSubDocs.size() > 0 && random.nextBoolean()) {\n                      delSubDocs = toDeleteSubDocs.get(random.nextInt(toDeleteSubDocs.size()));\n                      assert !delSubDocs.deleted;\n                      toDeleteSubDocs.remove(delSubDocs);\n                      // reuse prior packID\n                      packID = delSubDocs.packID;\n                    } else {\n                      delSubDocs = null;\n                      // make new packID\n                      packID = packCount.getAndIncrement() + \"\";\n                    }\n\n                    final Field packIDField = newField(\"packID\", packID, Field.Store.YES, Field.Index.NOT_ANALYZED);\n                    final List<String> docIDs = new ArrayList<String>();\n                    final SubDocs subDocs = new SubDocs(packID, docIDs);\n                    final List<Document> docsList = new ArrayList<Document>();\n\n                    allSubDocs.add(subDocs);\n                    doc.add(packIDField);\n                    docsList.add(cloneDoc(doc));\n                    docIDs.add(doc.get(\"docid\"));\n\n                    final int maxDocCount = _TestUtil.nextInt(random, 1, 10);\n                    while(docsList.size() < maxDocCount) {\n                      doc = docs.nextDoc();\n                      if (doc == null) {\n                        break;\n                      }\n                      docsList.add(cloneDoc(doc));\n                      docIDs.add(doc.get(\"docid\"));\n                    }\n                    addCount.addAndGet(docsList.size());\n\n                    if (delSubDocs != null) {\n                      delSubDocs.deleted = true;\n                      delIDs.addAll(delSubDocs.subIDs);\n                      delCount.addAndGet(delSubDocs.subIDs.size());\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: update pack packID=\" + delSubDocs.packID + \" count=\" + docsList.size() + \" docs=\" + docIDs);\n                      }\n                      gen = nrt.updateDocuments(new Term(\"packID\", delSubDocs.packID), docsList);\n                      /*\n                      // non-atomic:\n                      nrt.deleteDocuments(new Term(\"packID\", delSubDocs.packID));\n                      for(Document subDoc : docsList) {\n                        nrt.addDocument(subDoc);\n                      }\n                      */\n                    } else {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: add pack packID=\" + packID + \" count=\" + docsList.size() + \" docs=\" + docIDs);\n                      }\n                      gen = nrt.addDocuments(docsList);\n                      \n                      /*\n                      // non-atomic:\n                      for(Document subDoc : docsList) {\n                        nrt.addDocument(subDoc);\n                      }\n                      */\n                    }\n                    doc.removeField(\"packID\");\n\n                    if (random.nextInt(5) == 2) {\n                      if (VERBOSE) {\n                        System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + packID);\n                      }\n                      toDeleteSubDocs.add(subDocs);\n                    }\n\n                    // randomly verify the add/update \"took\":\n                    if (random.nextInt(20) == 2) {\n                      final boolean applyDeletes = delSubDocs != null;\n                      final IndexSearcher s = nrt.get(gen, applyDeletes);\n                      try {\n                        assertEquals(docsList.size(), s.search(new TermQuery(new Term(\"packID\", packID)), 10).totalHits);\n                      } finally {\n                        nrt.release(s);\n                      }\n                    }\n\n                  } else {\n                    if (VERBOSE) {\n                      System.out.println(Thread.currentThread().getName() + \": add doc docid:\" + doc.get(\"docid\"));\n                    }\n\n                    gen = nrt.addDocument(doc);\n                    addCount.getAndIncrement();\n\n                    // randomly verify the add \"took\":\n                    if (random.nextInt(20) == 2) {\n                      //System.out.println(Thread.currentThread().getName() + \": verify\");\n                      final IndexSearcher s = nrt.get(gen, false);\n                      //System.out.println(Thread.currentThread().getName() + \": got s=\" + s);\n                      try {\n                        assertEquals(1, s.search(new TermQuery(new Term(\"docid\", doc.get(\"docid\"))), 10).totalHits);\n                      } finally {\n                        nrt.release(s);\n                      }\n                      //System.out.println(Thread.currentThread().getName() + \": done verify\");\n                    }\n\n                    if (random.nextInt(5) == 3) {\n                      if (VERBOSE) {\n                        System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                      }\n                      toDeleteIDs.add(doc.get(\"docid\"));\n                    }\n                  }\n                } else {\n                  // we use update but it never replaces a\n                  // prior doc\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": update doc id:\" + doc.get(\"docid\"));\n                  }\n                  gen = nrt.updateDocument(new Term(\"docid\", doc.get(\"docid\")), doc);\n                  addCount.getAndIncrement();\n\n                  // randomly verify the add \"took\":\n                  if (random.nextInt(20) == 2) {\n                    final IndexSearcher s = nrt.get(gen, true);\n                    try {\n                      assertEquals(1, s.search(new TermQuery(new Term(\"docid\", doc.get(\"docid\"))), 10).totalHits);\n                    } finally {\n                      nrt.release(s);\n                    }\n                  }\n\n                  if (random.nextInt(5) == 3) {\n                    if (VERBOSE) {\n                      System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                    }\n                    toDeleteIDs.add(doc.get(\"docid\"));\n                  }\n                }\n\n                if (random.nextInt(30) == 17) {\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": apply \" + toDeleteIDs.size() + \" deletes\");\n                  }\n                  for(String id : toDeleteIDs) {\n                    if (VERBOSE) {\n                      System.out.println(Thread.currentThread().getName() + \": del term=id:\" + id);\n                    }\n                    gen = nrt.deleteDocuments(new Term(\"docid\", id));\n\n                    // randomly verify the delete \"took\":\n                    if (random.nextInt(20) == 7) {\n                      final IndexSearcher s = nrt.get(gen, true);\n                      try {\n                        assertEquals(0, s.search(new TermQuery(new Term(\"docid\", id)), 10).totalHits);\n                      } finally {\n                        nrt.release(s);\n                      }\n                    }\n                  }\n\n                  final int count = delCount.addAndGet(toDeleteIDs.size());\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": tot \" + count + \" deletes\");\n                  }\n                  delIDs.addAll(toDeleteIDs);\n                  toDeleteIDs.clear();\n\n                  for(SubDocs subDocs : toDeleteSubDocs) {\n                    assertTrue(!subDocs.deleted);\n                    gen = nrt.deleteDocuments(new Term(\"packID\", subDocs.packID));\n                    subDocs.deleted = true;\n                    if (VERBOSE) {\n                      System.out.println(\"  del subs: \" + subDocs.subIDs + \" packID=\" + subDocs.packID);\n                    }\n                    delIDs.addAll(subDocs.subIDs);\n                    delCount.addAndGet(subDocs.subIDs.size());\n\n                    // randomly verify the delete \"took\":\n                    if (random.nextInt(20) == 7) {\n                      final IndexSearcher s = nrt.get(gen, true);\n                      try {\n                        assertEquals(0, s.search(new TermQuery(new Term(\"packID\", subDocs.packID)), 1).totalHits);\n                      } finally {\n                        nrt.release(s);\n                      }\n                    }\n                  }\n                  toDeleteSubDocs.clear();\n                }\n                if (addedField != null) {\n                  doc.removeField(addedField);\n                }\n              } catch (Throwable t) {\n                System.out.println(Thread.currentThread().getName() + \": FAILED: hit exc\");\n                t.printStackTrace();\n                failed.set(true);\n                throw new RuntimeException(t);\n              }\n            }\n\n            lastGens.add(gen);\n            if (VERBOSE) {\n              System.out.println(Thread.currentThread().getName() + \": indexing done\");\n            }\n          }\n        };\n      threads[thread].setDaemon(true);\n      threads[thread].start();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: DONE start indexing threads [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    // let index build up a bit\n    Thread.sleep(100);\n\n    // silly starting guess:\n    final AtomicInteger totTermCount = new AtomicInteger(100);\n\n    // run search threads\n    final Thread[] searchThreads = new Thread[NUM_SEARCH_THREADS];\n    final AtomicInteger totHits = new AtomicInteger();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: start search threads\");\n    }\n\n    for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n      searchThreads[thread] = new Thread() {\n          @Override\n          public void run() {\n            while(System.currentTimeMillis() < stopTime && !failed.get()) {\n              final IndexSearcher s = nrt.get(random.nextBoolean());\n              try {\n                try {\n                  smokeTestSearcher(s);\n                  if (s.getIndexReader().numDocs() > 0) {\n                    Fields fields = MultiFields.getFields(s.getIndexReader());\n                    if (fields == null) {\n                      continue;\n                    }\n                    Terms terms = fields.terms(\"body\");\n                    if (terms == null) {\n                      continue;\n                    }\n\n                    TermsEnum termsEnum = terms.iterator();\n                    int seenTermCount = 0;\n                    int shift;\n                    int trigger;\n                    if (totTermCount.get() < 10) {\n                      shift = 0;\n                      trigger = 1;\n                    } else {\n                      trigger = totTermCount.get()/10;\n                      shift = random.nextInt(trigger);\n                    }\n\n                    while(System.currentTimeMillis() < stopTime) {\n                      BytesRef term = termsEnum.next();\n                      if (term == null) {\n                        if (seenTermCount == 0) {\n                          break;\n                        }\n                        totTermCount.set(seenTermCount);\n                        seenTermCount = 0;\n                        if (totTermCount.get() < 10) {\n                          shift = 0;\n                          trigger = 1;\n                        } else {\n                          trigger = totTermCount.get()/10;\n                          //System.out.println(\"trigger \" + trigger);\n                          shift = random.nextInt(trigger);\n                        }\n                        termsEnum.seek(new BytesRef(\"\"));\n                        continue;\n                      }\n                      seenTermCount++;\n                      // search 10 terms\n                      if (trigger == 0) {\n                        trigger = 1;\n                      }\n                      if ((seenTermCount + shift) % trigger == 0) {\n                        //if (VERBOSE) {\n                        //System.out.println(Thread.currentThread().getName() + \" now search body:\" + term.utf8ToString());\n                        //}\n                        totHits.addAndGet(runQuery(s, new TermQuery(new Term(\"body\", term))));\n                      }\n                    }\n                    if (VERBOSE) {\n                      System.out.println(Thread.currentThread().getName() + \": search done\");\n                    }\n                  }\n                } finally {\n                  nrt.release(s);\n                }\n              } catch (Throwable t) {\n                System.out.println(Thread.currentThread().getName() + \": FAILED: hit exc\");\n                failed.set(true);\n                t.printStackTrace(System.out);\n                throw new RuntimeException(t);\n              }\n            }\n          }\n        };\n      searchThreads[thread].setDaemon(true);\n      searchThreads[thread].start();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now join\");\n    }\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread].join();\n    }\n    for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n      searchThreads[thread].join();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: done join [\" + (System.currentTimeMillis()-t0) + \" ms]; addCount=\" + addCount + \" delCount=\" + delCount);\n      System.out.println(\"TEST: search totHits=\" + totHits);\n    }\n\n    long maxGen = 0;\n    for(long gen : lastGens) {\n      maxGen = Math.max(maxGen, gen);\n    }\n\n    final IndexSearcher s = nrt.get(maxGen, true);\n\n    boolean doFail = false;\n    for(String id : delIDs) {\n      final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", id)), 1);\n      if (hits.totalHits != 0) {\n        System.out.println(\"doc id=\" + id + \" is supposed to be deleted, but got docID=\" + hits.scoreDocs[0].doc);\n        doFail = true;\n      }\n    }\n\n    // Make sure each group of sub-docs are still in docID order:\n    for(SubDocs subDocs : allSubDocs) {\n      if (!subDocs.deleted) {\n        // We sort by relevance but the scores should be identical so sort falls back to by docID:\n        TopDocs hits = s.search(new TermQuery(new Term(\"packID\", subDocs.packID)), 20);\n        assertEquals(subDocs.subIDs.size(), hits.totalHits);\n        int lastDocID = -1;\n        int startDocID = -1;\n        for(ScoreDoc scoreDoc : hits.scoreDocs) {\n          final int docID = scoreDoc.doc;\n          if (lastDocID != -1) {\n            assertEquals(1+lastDocID, docID);\n          } else {\n            startDocID = docID;\n          }\n          lastDocID = docID;\n          final Document doc = s.doc(docID);\n          assertEquals(subDocs.packID, doc.get(\"packID\"));\n        }\n\n        lastDocID = startDocID - 1;\n        for(String subID : subDocs.subIDs) {\n          hits = s.search(new TermQuery(new Term(\"docid\", subID)), 1);\n          assertEquals(1, hits.totalHits);\n          final int docID = hits.scoreDocs[0].doc;\n          if (lastDocID != -1) {\n            assertEquals(1+lastDocID, docID);\n          }\n          lastDocID = docID;\n        }          \n      } else {\n        for(String subID : subDocs.subIDs) {\n          assertEquals(0, s.search(new TermQuery(new Term(\"docid\", subID)), 1).totalHits);\n        }\n      }\n    }\n    \n    final int endID = Integer.parseInt(docs.nextDoc().get(\"docid\"));\n    for(int id=0;id<endID;id++) {\n      String stringID = \"\"+id;\n      if (!delIDs.contains(stringID)) {\n        final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", stringID)), 1);\n        if (hits.totalHits != 1) {\n          System.out.println(\"doc id=\" + stringID + \" is not supposed to be deleted, but got hitCount=\" + hits.totalHits);\n          doFail = true;\n        }\n      }\n    }\n    assertFalse(doFail);\n\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), s.getIndexReader().numDocs());\n    nrt.release(s);\n\n    if (es != null) {\n      es.shutdown();\n      es.awaitTermination(1, TimeUnit.SECONDS);\n    }\n\n    writer.commit();\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), writer.numDocs());\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now close NRTManager\");\n    }\n    nrtThread.close();\n    nrt.close();\n    assertFalse(writer.anyNonBulkMerges);\n    writer.close(false);\n    _TestUtil.checkIndex(dir);\n    dir.close();\n    _TestUtil.rmDir(tempDir);\n    docs.close();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testNRTManager() throws Exception {\n\n    final long t0 = System.currentTimeMillis();\n\n    if (CodecProvider.getDefault().getDefaultFieldCodec().equals(\"SimpleText\")) {\n      // no\n      CodecProvider.getDefault().setDefaultFieldCodec(\"Standard\");\n    }\n\n    final LineFileDocs docs = new LineFileDocs(random);\n    final File tempDir = _TestUtil.getTempDir(\"nrtopenfiles\");\n    final MockDirectoryWrapper _dir = newFSDirectory(tempDir);\n    _dir.setCheckIndexOnClose(false);  // don't double-checkIndex, we do it ourselves\n    Directory dir = _dir;\n    final IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).setOpenMode(IndexWriterConfig.OpenMode.CREATE);\n\n    if (LuceneTestCase.TEST_NIGHTLY) {\n      // newIWConfig makes smallish max seg size, which\n      // results in tons and tons of segments for this test\n      // when run nightly:\n      MergePolicy mp = conf.getMergePolicy();\n      if (mp instanceof TieredMergePolicy) {\n        ((TieredMergePolicy) mp).setMaxMergedSegmentMB(5000.);\n      } else if (mp instanceof LogByteSizeMergePolicy) {\n        ((LogByteSizeMergePolicy) mp).setMaxMergeMB(1000.);\n      } else if (mp instanceof LogMergePolicy) {\n        ((LogMergePolicy) mp).setMaxMergeDocs(100000);\n      }\n    }\n\n    conf.setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n      @Override\n      public void warm(IndexReader reader) throws IOException {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now warm merged reader=\" + reader);\n        }\n        final int maxDoc = reader.maxDoc();\n        final Bits delDocs = reader.getDeletedDocs();\n        int sum = 0;\n        final int inc = Math.max(1, maxDoc/50);\n        for(int docID=0;docID<maxDoc;docID += inc) {\n          if (delDocs == null || !delDocs.get(docID)) {\n            final Document doc = reader.document(docID);\n            sum += doc.getFields().size();\n          }\n        }\n\n        IndexSearcher searcher = newSearcher(reader);\n        sum += searcher.search(new TermQuery(new Term(\"body\", \"united\")), 10).totalHits;\n        searcher.close();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: warm visited \" + sum + \" fields\");\n        }\n      }\n      });\n\n    if (random.nextBoolean()) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: wrap NRTCachingDir\");\n      }\n\n      NRTCachingDirectory nrtDir = new NRTCachingDirectory(dir, 5.0, 60.0);\n      conf.setMergeScheduler(nrtDir.getMergeScheduler());\n      dir = nrtDir;\n    }\n    \n    final IndexWriter writer = new IndexWriter(dir, conf);\n    \n    if (VERBOSE) {\n      writer.setInfoStream(System.out);\n    }\n    _TestUtil.reduceOpenFiles(writer);\n    //System.out.println(\"TEST: conf=\" + writer.getConfig());\n\n    final ExecutorService es = random.nextBoolean() ? null : Executors.newCachedThreadPool(new NamedThreadFactory(\"NRT search threads\"));\n\n    final double minReopenSec = 0.01 + 0.05 * random.nextDouble();\n    final double maxReopenSec = minReopenSec * (1.0 + 10 * random.nextDouble());\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: make NRTManager maxReopenSec=\" + maxReopenSec + \" minReopenSec=\" + minReopenSec);\n    }\n\n    final NRTManager nrt = new NRTManager(writer, es);\n    final NRTManagerReopenThread nrtThread = new NRTManagerReopenThread(nrt, maxReopenSec, minReopenSec);\n    nrtThread.setName(\"NRT Reopen Thread\");\n    nrtThread.setPriority(Math.min(Thread.currentThread().getPriority()+2, Thread.MAX_PRIORITY));\n    nrtThread.setDaemon(true);\n    nrtThread.start();\n\n    final int NUM_INDEX_THREADS = _TestUtil.nextInt(random, 1, 3);\n    final int NUM_SEARCH_THREADS = _TestUtil.nextInt(random, 1, 3);\n    //final int NUM_INDEX_THREADS = 1;\n    //final int NUM_SEARCH_THREADS = 1;\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + NUM_INDEX_THREADS + \" index threads; \" + NUM_SEARCH_THREADS + \" search threads\");\n    }\n\n    final int RUN_TIME_SEC = LuceneTestCase.TEST_NIGHTLY ? 300 : RANDOM_MULTIPLIER;\n\n    final AtomicBoolean failed = new AtomicBoolean();\n    final AtomicInteger addCount = new AtomicInteger();\n    final AtomicInteger delCount = new AtomicInteger();\n    final AtomicInteger packCount = new AtomicInteger();\n    final List<Long> lastGens = new ArrayList<Long>();\n\n    final Set<String> delIDs = Collections.synchronizedSet(new HashSet<String>());\n    final List<SubDocs> allSubDocs = Collections.synchronizedList(new ArrayList<SubDocs>());\n\n    final long stopTime = System.currentTimeMillis() + RUN_TIME_SEC*1000;\n    Thread[] threads = new Thread[NUM_INDEX_THREADS];\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread] = new Thread() {\n          @Override\n          public void run() {\n            // TODO: would be better if this were cross thread, so that we make sure one thread deleting anothers added docs works:\n            final List<String> toDeleteIDs = new ArrayList<String>();\n            final List<SubDocs> toDeleteSubDocs = new ArrayList<SubDocs>();\n\n            long gen = 0;\n            while(System.currentTimeMillis() < stopTime && !failed.get()) {\n\n              //System.out.println(Thread.currentThread().getName() + \": cycle\");\n              try {\n                // Occassional longish pause if running\n                // nightly\n                if (LuceneTestCase.TEST_NIGHTLY && random.nextInt(6) == 3) {\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": now long sleep\");\n                  }\n                  Thread.sleep(_TestUtil.nextInt(random, 50, 500));\n                }\n\n                // Rate limit ingest rate:\n                Thread.sleep(_TestUtil.nextInt(random, 1, 10));\n                if (VERBOSE) {\n                  System.out.println(Thread.currentThread() + \": done sleep\");\n                }\n\n                Document doc = docs.nextDoc();\n                if (doc == null) {\n                  break;\n                }\n                final String addedField;\n                if (random.nextBoolean()) {\n                  addedField = \"extra\" + random.nextInt(10);\n                  doc.add(new Field(addedField, \"a random field\", Field.Store.NO, Field.Index.ANALYZED));\n                } else {\n                  addedField = null;\n                }\n                if (random.nextBoolean()) {\n\n                  if (random.nextBoolean()) {\n                    // Add a pack of adjacent sub-docs\n                    final String packID;\n                    final SubDocs delSubDocs;\n                    if (toDeleteSubDocs.size() > 0 && random.nextBoolean()) {\n                      delSubDocs = toDeleteSubDocs.get(random.nextInt(toDeleteSubDocs.size()));\n                      assert !delSubDocs.deleted;\n                      toDeleteSubDocs.remove(delSubDocs);\n                      // reuse prior packID\n                      packID = delSubDocs.packID;\n                    } else {\n                      delSubDocs = null;\n                      // make new packID\n                      packID = packCount.getAndIncrement() + \"\";\n                    }\n\n                    final Field packIDField = newField(\"packID\", packID, Field.Store.YES, Field.Index.NOT_ANALYZED);\n                    final List<String> docIDs = new ArrayList<String>();\n                    final SubDocs subDocs = new SubDocs(packID, docIDs);\n                    final List<Document> docsList = new ArrayList<Document>();\n\n                    allSubDocs.add(subDocs);\n                    doc.add(packIDField);\n                    docsList.add(cloneDoc(doc));\n                    docIDs.add(doc.get(\"docid\"));\n\n                    final int maxDocCount = _TestUtil.nextInt(random, 1, 10);\n                    while(docsList.size() < maxDocCount) {\n                      doc = docs.nextDoc();\n                      if (doc == null) {\n                        break;\n                      }\n                      docsList.add(cloneDoc(doc));\n                      docIDs.add(doc.get(\"docid\"));\n                    }\n                    addCount.addAndGet(docsList.size());\n\n                    if (delSubDocs != null) {\n                      delSubDocs.deleted = true;\n                      delIDs.addAll(delSubDocs.subIDs);\n                      delCount.addAndGet(delSubDocs.subIDs.size());\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: update pack packID=\" + delSubDocs.packID + \" count=\" + docsList.size() + \" docs=\" + docIDs);\n                      }\n                      gen = nrt.updateDocuments(new Term(\"packID\", delSubDocs.packID), docsList);\n                      /*\n                      // non-atomic:\n                      nrt.deleteDocuments(new Term(\"packID\", delSubDocs.packID));\n                      for(Document subDoc : docsList) {\n                        nrt.addDocument(subDoc);\n                      }\n                      */\n                    } else {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: add pack packID=\" + packID + \" count=\" + docsList.size() + \" docs=\" + docIDs);\n                      }\n                      gen = nrt.addDocuments(docsList);\n                      \n                      /*\n                      // non-atomic:\n                      for(Document subDoc : docsList) {\n                        nrt.addDocument(subDoc);\n                      }\n                      */\n                    }\n                    doc.removeField(\"packID\");\n\n                    if (random.nextInt(5) == 2) {\n                      if (VERBOSE) {\n                        System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + packID);\n                      }\n                      toDeleteSubDocs.add(subDocs);\n                    }\n\n                    // randomly verify the add/update \"took\":\n                    if (random.nextInt(20) == 2) {\n                      final boolean applyDeletes = delSubDocs != null;\n                      final IndexSearcher s = nrt.get(gen, applyDeletes);\n                      try {\n                        assertEquals(docsList.size(), s.search(new TermQuery(new Term(\"packID\", packID)), 10).totalHits);\n                      } finally {\n                        nrt.release(s);\n                      }\n                    }\n\n                  } else {\n                    if (VERBOSE) {\n                      System.out.println(Thread.currentThread().getName() + \": add doc docid:\" + doc.get(\"docid\"));\n                    }\n\n                    gen = nrt.addDocument(doc);\n                    addCount.getAndIncrement();\n\n                    // randomly verify the add \"took\":\n                    if (random.nextInt(20) == 2) {\n                      //System.out.println(Thread.currentThread().getName() + \": verify\");\n                      final IndexSearcher s = nrt.get(gen, false);\n                      //System.out.println(Thread.currentThread().getName() + \": got s=\" + s);\n                      try {\n                        assertEquals(1, s.search(new TermQuery(new Term(\"docid\", doc.get(\"docid\"))), 10).totalHits);\n                      } finally {\n                        nrt.release(s);\n                      }\n                      //System.out.println(Thread.currentThread().getName() + \": done verify\");\n                    }\n\n                    if (random.nextInt(5) == 3) {\n                      if (VERBOSE) {\n                        System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                      }\n                      toDeleteIDs.add(doc.get(\"docid\"));\n                    }\n                  }\n                } else {\n                  // we use update but it never replaces a\n                  // prior doc\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": update doc id:\" + doc.get(\"docid\"));\n                  }\n                  gen = nrt.updateDocument(new Term(\"docid\", doc.get(\"docid\")), doc);\n                  addCount.getAndIncrement();\n\n                  // randomly verify the add \"took\":\n                  if (random.nextInt(20) == 2) {\n                    final IndexSearcher s = nrt.get(gen, true);\n                    try {\n                      assertEquals(1, s.search(new TermQuery(new Term(\"docid\", doc.get(\"docid\"))), 10).totalHits);\n                    } finally {\n                      nrt.release(s);\n                    }\n                  }\n\n                  if (random.nextInt(5) == 3) {\n                    if (VERBOSE) {\n                      System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                    }\n                    toDeleteIDs.add(doc.get(\"docid\"));\n                  }\n                }\n\n                if (random.nextInt(30) == 17) {\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": apply \" + toDeleteIDs.size() + \" deletes\");\n                  }\n                  for(String id : toDeleteIDs) {\n                    if (VERBOSE) {\n                      System.out.println(Thread.currentThread().getName() + \": del term=id:\" + id);\n                    }\n                    gen = nrt.deleteDocuments(new Term(\"docid\", id));\n\n                    // randomly verify the delete \"took\":\n                    if (random.nextInt(20) == 7) {\n                      final IndexSearcher s = nrt.get(gen, true);\n                      try {\n                        assertEquals(0, s.search(new TermQuery(new Term(\"docid\", id)), 10).totalHits);\n                      } finally {\n                        nrt.release(s);\n                      }\n                    }\n                  }\n\n                  final int count = delCount.addAndGet(toDeleteIDs.size());\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": tot \" + count + \" deletes\");\n                  }\n                  delIDs.addAll(toDeleteIDs);\n                  toDeleteIDs.clear();\n\n                  for(SubDocs subDocs : toDeleteSubDocs) {\n                    assertTrue(!subDocs.deleted);\n                    gen = nrt.deleteDocuments(new Term(\"packID\", subDocs.packID));\n                    subDocs.deleted = true;\n                    if (VERBOSE) {\n                      System.out.println(\"  del subs: \" + subDocs.subIDs + \" packID=\" + subDocs.packID);\n                    }\n                    delIDs.addAll(subDocs.subIDs);\n                    delCount.addAndGet(subDocs.subIDs.size());\n\n                    // randomly verify the delete \"took\":\n                    if (random.nextInt(20) == 7) {\n                      final IndexSearcher s = nrt.get(gen, true);\n                      try {\n                        assertEquals(0, s.search(new TermQuery(new Term(\"packID\", subDocs.packID)), 1).totalHits);\n                      } finally {\n                        nrt.release(s);\n                      }\n                    }\n                  }\n                  toDeleteSubDocs.clear();\n                }\n                if (addedField != null) {\n                  doc.removeField(addedField);\n                }\n              } catch (Throwable t) {\n                System.out.println(Thread.currentThread().getName() + \": FAILED: hit exc\");\n                t.printStackTrace();\n                failed.set(true);\n                throw new RuntimeException(t);\n              }\n            }\n\n            lastGens.add(gen);\n            if (VERBOSE) {\n              System.out.println(Thread.currentThread().getName() + \": indexing done\");\n            }\n          }\n        };\n      threads[thread].setDaemon(true);\n      threads[thread].start();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: DONE start indexing threads [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    // let index build up a bit\n    Thread.sleep(100);\n\n    // silly starting guess:\n    final AtomicInteger totTermCount = new AtomicInteger(100);\n\n    // run search threads\n    final Thread[] searchThreads = new Thread[NUM_SEARCH_THREADS];\n    final AtomicInteger totHits = new AtomicInteger();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: start search threads\");\n    }\n\n    for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n      searchThreads[thread] = new Thread() {\n          @Override\n          public void run() {\n            while(System.currentTimeMillis() < stopTime && !failed.get()) {\n              final IndexSearcher s = nrt.get(random.nextBoolean());\n              try {\n                try {\n                  smokeTestSearcher(s);\n                  if (s.getIndexReader().numDocs() > 0) {\n                    Fields fields = MultiFields.getFields(s.getIndexReader());\n                    if (fields == null) {\n                      continue;\n                    }\n                    Terms terms = fields.terms(\"body\");\n                    if (terms == null) {\n                      continue;\n                    }\n\n                    TermsEnum termsEnum = terms.iterator();\n                    int seenTermCount = 0;\n                    int shift;\n                    int trigger;\n                    if (totTermCount.get() == 0) {\n                      shift = 0;\n                      trigger = 1;\n                    } else {\n                      shift = random.nextInt(totTermCount.get()/10);\n                      trigger = totTermCount.get()/10;\n                    }\n\n                    while(System.currentTimeMillis() < stopTime) {\n                      BytesRef term = termsEnum.next();\n                      if (term == null) {\n                        if (seenTermCount == 0) {\n                          break;\n                        }\n                        totTermCount.set(seenTermCount);\n                        seenTermCount = 0;\n                        if (totTermCount.get() == 0) {\n                          shift = 0;\n                          trigger = 1;\n                        } else {\n                          trigger = totTermCount.get()/10;\n                          //System.out.println(\"trigger \" + trigger);\n                          shift = random.nextInt(totTermCount.get()/10);\n                        }\n                        termsEnum.seek(new BytesRef(\"\"));\n                        continue;\n                      }\n                      seenTermCount++;\n                      // search 10 terms\n                      if (trigger == 0) {\n                        trigger = 1;\n                      }\n                      if ((seenTermCount + shift) % trigger == 0) {\n                        //if (VERBOSE) {\n                        //System.out.println(Thread.currentThread().getName() + \" now search body:\" + term.utf8ToString());\n                        //}\n                        totHits.addAndGet(runQuery(s, new TermQuery(new Term(\"body\", term))));\n                      }\n                    }\n                    if (VERBOSE) {\n                      System.out.println(Thread.currentThread().getName() + \": search done\");\n                    }\n                  }\n                } finally {\n                  nrt.release(s);\n                }\n              } catch (Throwable t) {\n                System.out.println(Thread.currentThread().getName() + \": FAILED: hit exc\");\n                failed.set(true);\n                t.printStackTrace(System.out);\n                throw new RuntimeException(t);\n              }\n            }\n          }\n        };\n      searchThreads[thread].setDaemon(true);\n      searchThreads[thread].start();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now join\");\n    }\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread].join();\n    }\n    for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n      searchThreads[thread].join();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: done join [\" + (System.currentTimeMillis()-t0) + \" ms]; addCount=\" + addCount + \" delCount=\" + delCount);\n      System.out.println(\"TEST: search totHits=\" + totHits);\n    }\n\n    long maxGen = 0;\n    for(long gen : lastGens) {\n      maxGen = Math.max(maxGen, gen);\n    }\n\n    final IndexSearcher s = nrt.get(maxGen, true);\n\n    boolean doFail = false;\n    for(String id : delIDs) {\n      final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", id)), 1);\n      if (hits.totalHits != 0) {\n        System.out.println(\"doc id=\" + id + \" is supposed to be deleted, but got docID=\" + hits.scoreDocs[0].doc);\n        doFail = true;\n      }\n    }\n\n    // Make sure each group of sub-docs are still in docID order:\n    for(SubDocs subDocs : allSubDocs) {\n      if (!subDocs.deleted) {\n        // We sort by relevance but the scores should be identical so sort falls back to by docID:\n        TopDocs hits = s.search(new TermQuery(new Term(\"packID\", subDocs.packID)), 20);\n        assertEquals(subDocs.subIDs.size(), hits.totalHits);\n        int lastDocID = -1;\n        int startDocID = -1;\n        for(ScoreDoc scoreDoc : hits.scoreDocs) {\n          final int docID = scoreDoc.doc;\n          if (lastDocID != -1) {\n            assertEquals(1+lastDocID, docID);\n          } else {\n            startDocID = docID;\n          }\n          lastDocID = docID;\n          final Document doc = s.doc(docID);\n          assertEquals(subDocs.packID, doc.get(\"packID\"));\n        }\n\n        lastDocID = startDocID - 1;\n        for(String subID : subDocs.subIDs) {\n          hits = s.search(new TermQuery(new Term(\"docid\", subID)), 1);\n          assertEquals(1, hits.totalHits);\n          final int docID = hits.scoreDocs[0].doc;\n          if (lastDocID != -1) {\n            assertEquals(1+lastDocID, docID);\n          }\n          lastDocID = docID;\n        }          \n      } else {\n        for(String subID : subDocs.subIDs) {\n          assertEquals(0, s.search(new TermQuery(new Term(\"docid\", subID)), 1).totalHits);\n        }\n      }\n    }\n    \n    final int endID = Integer.parseInt(docs.nextDoc().get(\"docid\"));\n    for(int id=0;id<endID;id++) {\n      String stringID = \"\"+id;\n      if (!delIDs.contains(stringID)) {\n        final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", stringID)), 1);\n        if (hits.totalHits != 1) {\n          System.out.println(\"doc id=\" + stringID + \" is not supposed to be deleted, but got hitCount=\" + hits.totalHits);\n          doFail = true;\n        }\n      }\n    }\n    assertFalse(doFail);\n\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), s.getIndexReader().numDocs());\n    nrt.release(s);\n\n    if (es != null) {\n      es.shutdown();\n      es.awaitTermination(1, TimeUnit.SECONDS);\n    }\n\n    writer.commit();\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), writer.numDocs());\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now close NRTManager\");\n    }\n    nrtThread.close();\n    nrt.close();\n    assertFalse(writer.anyNonBulkMerges);\n    writer.close(false);\n    _TestUtil.checkIndex(dir);\n    dir.close();\n    _TestUtil.rmDir(tempDir);\n    docs.close();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0a2903ea38ae3e636b93a08c52a5e37ae939cf6b","date":1308291005,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/contrib/misc/src/test/org/apache/lucene/index/TestNRTManager#testNRTManager().mjava","pathOld":"lucene/contrib/misc/src/test/org/apache/lucene/index/TestNRTManager#testNRTManager().mjava","sourceNew":"  @Test\n  public void testNRTManager() throws Exception {\n\n    final long t0 = System.currentTimeMillis();\n\n    if (CodecProvider.getDefault().getDefaultFieldCodec().equals(\"SimpleText\")) {\n      // no\n      CodecProvider.getDefault().setDefaultFieldCodec(\"Standard\");\n    }\n\n    final LineFileDocs docs = new LineFileDocs(random);\n    final File tempDir = _TestUtil.getTempDir(\"nrtopenfiles\");\n    final MockDirectoryWrapper _dir = newFSDirectory(tempDir);\n    _dir.setCheckIndexOnClose(false);  // don't double-checkIndex, we do it ourselves\n    Directory dir = _dir;\n    final IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).setOpenMode(IndexWriterConfig.OpenMode.CREATE);\n\n    if (LuceneTestCase.TEST_NIGHTLY) {\n      // newIWConfig makes smallish max seg size, which\n      // results in tons and tons of segments for this test\n      // when run nightly:\n      MergePolicy mp = conf.getMergePolicy();\n      if (mp instanceof TieredMergePolicy) {\n        ((TieredMergePolicy) mp).setMaxMergedSegmentMB(5000.);\n      } else if (mp instanceof LogByteSizeMergePolicy) {\n        ((LogByteSizeMergePolicy) mp).setMaxMergeMB(1000.);\n      } else if (mp instanceof LogMergePolicy) {\n        ((LogMergePolicy) mp).setMaxMergeDocs(100000);\n      }\n    }\n\n    conf.setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n      @Override\n      public void warm(IndexReader reader) throws IOException {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now warm merged reader=\" + reader);\n        }\n        final int maxDoc = reader.maxDoc();\n        final Bits delDocs = reader.getDeletedDocs();\n        int sum = 0;\n        final int inc = Math.max(1, maxDoc/50);\n        for(int docID=0;docID<maxDoc;docID += inc) {\n          if (delDocs == null || !delDocs.get(docID)) {\n            final Document doc = reader.document(docID);\n            sum += doc.getFields().size();\n          }\n        }\n\n        IndexSearcher searcher = newSearcher(reader);\n        sum += searcher.search(new TermQuery(new Term(\"body\", \"united\")), 10).totalHits;\n        searcher.close();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: warm visited \" + sum + \" fields\");\n        }\n      }\n      });\n\n    if (random.nextBoolean()) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: wrap NRTCachingDir\");\n      }\n\n      NRTCachingDirectory nrtDir = new NRTCachingDirectory(dir, 5.0, 60.0);\n      conf.setMergeScheduler(nrtDir.getMergeScheduler());\n      dir = nrtDir;\n    }\n    \n    final IndexWriter writer = new IndexWriter(dir, conf);\n    \n    if (VERBOSE) {\n      writer.setInfoStream(System.out);\n    }\n    _TestUtil.reduceOpenFiles(writer);\n    //System.out.println(\"TEST: conf=\" + writer.getConfig());\n\n    final ExecutorService es = random.nextBoolean() ? null : Executors.newCachedThreadPool(new NamedThreadFactory(\"NRT search threads\"));\n\n    final double minReopenSec = 0.01 + 0.05 * random.nextDouble();\n    final double maxReopenSec = minReopenSec * (1.0 + 10 * random.nextDouble());\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: make NRTManager maxReopenSec=\" + maxReopenSec + \" minReopenSec=\" + minReopenSec);\n    }\n\n    final NRTManager nrt = new NRTManager(writer, es);\n    final NRTManagerReopenThread nrtThread = new NRTManagerReopenThread(nrt, maxReopenSec, minReopenSec);\n    nrtThread.setName(\"NRT Reopen Thread\");\n    nrtThread.setPriority(Math.min(Thread.currentThread().getPriority()+2, Thread.MAX_PRIORITY));\n    nrtThread.setDaemon(true);\n    nrtThread.start();\n\n    final int NUM_INDEX_THREADS = _TestUtil.nextInt(random, 1, 3);\n    final int NUM_SEARCH_THREADS = _TestUtil.nextInt(random, 1, 3);\n    //final int NUM_INDEX_THREADS = 1;\n    //final int NUM_SEARCH_THREADS = 1;\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + NUM_INDEX_THREADS + \" index threads; \" + NUM_SEARCH_THREADS + \" search threads\");\n    }\n\n    final int RUN_TIME_SEC = LuceneTestCase.TEST_NIGHTLY ? 300 : RANDOM_MULTIPLIER;\n\n    final AtomicBoolean failed = new AtomicBoolean();\n    final AtomicInteger addCount = new AtomicInteger();\n    final AtomicInteger delCount = new AtomicInteger();\n    final AtomicInteger packCount = new AtomicInteger();\n    final List<Long> lastGens = new ArrayList<Long>();\n\n    final Set<String> delIDs = Collections.synchronizedSet(new HashSet<String>());\n    final List<SubDocs> allSubDocs = Collections.synchronizedList(new ArrayList<SubDocs>());\n\n    final long stopTime = System.currentTimeMillis() + RUN_TIME_SEC*1000;\n    Thread[] threads = new Thread[NUM_INDEX_THREADS];\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread] = new Thread() {\n          @Override\n          public void run() {\n            // TODO: would be better if this were cross thread, so that we make sure one thread deleting anothers added docs works:\n            final List<String> toDeleteIDs = new ArrayList<String>();\n            final List<SubDocs> toDeleteSubDocs = new ArrayList<SubDocs>();\n\n            long gen = 0;\n            while(System.currentTimeMillis() < stopTime && !failed.get()) {\n\n              //System.out.println(Thread.currentThread().getName() + \": cycle\");\n              try {\n                // Occassional longish pause if running\n                // nightly\n                if (LuceneTestCase.TEST_NIGHTLY && random.nextInt(6) == 3) {\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": now long sleep\");\n                  }\n                  Thread.sleep(_TestUtil.nextInt(random, 50, 500));\n                }\n\n                // Rate limit ingest rate:\n                Thread.sleep(_TestUtil.nextInt(random, 1, 10));\n                if (VERBOSE) {\n                  System.out.println(Thread.currentThread() + \": done sleep\");\n                }\n\n                Document doc = docs.nextDoc();\n                if (doc == null) {\n                  break;\n                }\n                final String addedField;\n                if (random.nextBoolean()) {\n                  addedField = \"extra\" + random.nextInt(10);\n                  doc.add(new Field(addedField, \"a random field\", Field.Store.NO, Field.Index.ANALYZED));\n                } else {\n                  addedField = null;\n                }\n                if (random.nextBoolean()) {\n\n                  if (random.nextBoolean()) {\n                    // Add a pack of adjacent sub-docs\n                    final String packID;\n                    final SubDocs delSubDocs;\n                    if (toDeleteSubDocs.size() > 0 && random.nextBoolean()) {\n                      delSubDocs = toDeleteSubDocs.get(random.nextInt(toDeleteSubDocs.size()));\n                      assert !delSubDocs.deleted;\n                      toDeleteSubDocs.remove(delSubDocs);\n                      // reuse prior packID\n                      packID = delSubDocs.packID;\n                    } else {\n                      delSubDocs = null;\n                      // make new packID\n                      packID = packCount.getAndIncrement() + \"\";\n                    }\n\n                    final Field packIDField = newField(\"packID\", packID, Field.Store.YES, Field.Index.NOT_ANALYZED);\n                    final List<String> docIDs = new ArrayList<String>();\n                    final SubDocs subDocs = new SubDocs(packID, docIDs);\n                    final List<Document> docsList = new ArrayList<Document>();\n\n                    allSubDocs.add(subDocs);\n                    doc.add(packIDField);\n                    docsList.add(cloneDoc(doc));\n                    docIDs.add(doc.get(\"docid\"));\n\n                    final int maxDocCount = _TestUtil.nextInt(random, 1, 10);\n                    while(docsList.size() < maxDocCount) {\n                      doc = docs.nextDoc();\n                      if (doc == null) {\n                        break;\n                      }\n                      docsList.add(cloneDoc(doc));\n                      docIDs.add(doc.get(\"docid\"));\n                    }\n                    addCount.addAndGet(docsList.size());\n\n                    if (delSubDocs != null) {\n                      delSubDocs.deleted = true;\n                      delIDs.addAll(delSubDocs.subIDs);\n                      delCount.addAndGet(delSubDocs.subIDs.size());\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: update pack packID=\" + delSubDocs.packID + \" count=\" + docsList.size() + \" docs=\" + docIDs);\n                      }\n                      gen = nrt.updateDocuments(new Term(\"packID\", delSubDocs.packID), docsList);\n                      /*\n                      // non-atomic:\n                      nrt.deleteDocuments(new Term(\"packID\", delSubDocs.packID));\n                      for(Document subDoc : docsList) {\n                        nrt.addDocument(subDoc);\n                      }\n                      */\n                    } else {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: add pack packID=\" + packID + \" count=\" + docsList.size() + \" docs=\" + docIDs);\n                      }\n                      gen = nrt.addDocuments(docsList);\n                      \n                      /*\n                      // non-atomic:\n                      for(Document subDoc : docsList) {\n                        nrt.addDocument(subDoc);\n                      }\n                      */\n                    }\n                    doc.removeField(\"packID\");\n\n                    if (random.nextInt(5) == 2) {\n                      if (VERBOSE) {\n                        System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + packID);\n                      }\n                      toDeleteSubDocs.add(subDocs);\n                    }\n\n                    // randomly verify the add/update \"took\":\n                    if (random.nextInt(20) == 2) {\n                      final boolean applyDeletes = delSubDocs != null;\n                      final IndexSearcher s = nrt.get(gen, applyDeletes);\n                      try {\n                        assertEquals(docsList.size(), s.search(new TermQuery(new Term(\"packID\", packID)), 10).totalHits);\n                      } finally {\n                        nrt.release(s);\n                      }\n                    }\n\n                  } else {\n                    if (VERBOSE) {\n                      System.out.println(Thread.currentThread().getName() + \": add doc docid:\" + doc.get(\"docid\"));\n                    }\n\n                    gen = nrt.addDocument(doc);\n                    addCount.getAndIncrement();\n\n                    // randomly verify the add \"took\":\n                    if (random.nextInt(20) == 2) {\n                      //System.out.println(Thread.currentThread().getName() + \": verify\");\n                      final IndexSearcher s = nrt.get(gen, false);\n                      //System.out.println(Thread.currentThread().getName() + \": got s=\" + s);\n                      try {\n                        assertEquals(1, s.search(new TermQuery(new Term(\"docid\", doc.get(\"docid\"))), 10).totalHits);\n                      } finally {\n                        nrt.release(s);\n                      }\n                      //System.out.println(Thread.currentThread().getName() + \": done verify\");\n                    }\n\n                    if (random.nextInt(5) == 3) {\n                      if (VERBOSE) {\n                        System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                      }\n                      toDeleteIDs.add(doc.get(\"docid\"));\n                    }\n                  }\n                } else {\n                  // we use update but it never replaces a\n                  // prior doc\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": update doc id:\" + doc.get(\"docid\"));\n                  }\n                  gen = nrt.updateDocument(new Term(\"docid\", doc.get(\"docid\")), doc);\n                  addCount.getAndIncrement();\n\n                  // randomly verify the add \"took\":\n                  if (random.nextInt(20) == 2) {\n                    final IndexSearcher s = nrt.get(gen, true);\n                    try {\n                      assertEquals(1, s.search(new TermQuery(new Term(\"docid\", doc.get(\"docid\"))), 10).totalHits);\n                    } finally {\n                      nrt.release(s);\n                    }\n                  }\n\n                  if (random.nextInt(5) == 3) {\n                    if (VERBOSE) {\n                      System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                    }\n                    toDeleteIDs.add(doc.get(\"docid\"));\n                  }\n                }\n\n                if (random.nextInt(30) == 17) {\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": apply \" + toDeleteIDs.size() + \" deletes\");\n                  }\n                  for(String id : toDeleteIDs) {\n                    if (VERBOSE) {\n                      System.out.println(Thread.currentThread().getName() + \": del term=id:\" + id);\n                    }\n                    gen = nrt.deleteDocuments(new Term(\"docid\", id));\n\n                    // randomly verify the delete \"took\":\n                    if (random.nextInt(20) == 7) {\n                      final IndexSearcher s = nrt.get(gen, true);\n                      try {\n                        assertEquals(0, s.search(new TermQuery(new Term(\"docid\", id)), 10).totalHits);\n                      } finally {\n                        nrt.release(s);\n                      }\n                    }\n                  }\n\n                  final int count = delCount.addAndGet(toDeleteIDs.size());\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": tot \" + count + \" deletes\");\n                  }\n                  delIDs.addAll(toDeleteIDs);\n                  toDeleteIDs.clear();\n\n                  for(SubDocs subDocs : toDeleteSubDocs) {\n                    assertTrue(!subDocs.deleted);\n                    gen = nrt.deleteDocuments(new Term(\"packID\", subDocs.packID));\n                    subDocs.deleted = true;\n                    if (VERBOSE) {\n                      System.out.println(\"  del subs: \" + subDocs.subIDs + \" packID=\" + subDocs.packID);\n                    }\n                    delIDs.addAll(subDocs.subIDs);\n                    delCount.addAndGet(subDocs.subIDs.size());\n\n                    // randomly verify the delete \"took\":\n                    if (random.nextInt(20) == 7) {\n                      final IndexSearcher s = nrt.get(gen, true);\n                      try {\n                        assertEquals(0, s.search(new TermQuery(new Term(\"packID\", subDocs.packID)), 1).totalHits);\n                      } finally {\n                        nrt.release(s);\n                      }\n                    }\n                  }\n                  toDeleteSubDocs.clear();\n                }\n                if (addedField != null) {\n                  doc.removeField(addedField);\n                }\n              } catch (Throwable t) {\n                System.out.println(Thread.currentThread().getName() + \": FAILED: hit exc\");\n                t.printStackTrace();\n                failed.set(true);\n                throw new RuntimeException(t);\n              }\n            }\n\n            lastGens.add(gen);\n            if (VERBOSE) {\n              System.out.println(Thread.currentThread().getName() + \": indexing done\");\n            }\n          }\n        };\n      threads[thread].setDaemon(true);\n      threads[thread].start();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: DONE start indexing threads [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    // let index build up a bit\n    Thread.sleep(100);\n\n    // silly starting guess:\n    final AtomicInteger totTermCount = new AtomicInteger(100);\n\n    // run search threads\n    final Thread[] searchThreads = new Thread[NUM_SEARCH_THREADS];\n    final AtomicInteger totHits = new AtomicInteger();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: start search threads\");\n    }\n\n    for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n      searchThreads[thread] = new Thread() {\n          @Override\n          public void run() {\n            while(System.currentTimeMillis() < stopTime && !failed.get()) {\n              final IndexSearcher s = nrt.get(random.nextBoolean());\n              try {\n                try {\n                  smokeTestSearcher(s);\n                  if (s.getIndexReader().numDocs() > 0) {\n                    Fields fields = MultiFields.getFields(s.getIndexReader());\n                    if (fields == null) {\n                      continue;\n                    }\n                    Terms terms = fields.terms(\"body\");\n                    if (terms == null) {\n                      continue;\n                    }\n\n                    TermsEnum termsEnum = terms.iterator();\n                    int seenTermCount = 0;\n                    int shift;\n                    int trigger;\n                    if (totTermCount.get() < 10) {\n                      shift = 0;\n                      trigger = 1;\n                    } else {\n                      trigger = totTermCount.get()/10;\n                      shift = random.nextInt(trigger);\n                    }\n\n                    while(System.currentTimeMillis() < stopTime) {\n                      BytesRef term = termsEnum.next();\n                      if (term == null) {\n                        if (seenTermCount == 0) {\n                          break;\n                        }\n                        totTermCount.set(seenTermCount);\n                        seenTermCount = 0;\n                        if (totTermCount.get() < 10) {\n                          shift = 0;\n                          trigger = 1;\n                        } else {\n                          trigger = totTermCount.get()/10;\n                          //System.out.println(\"trigger \" + trigger);\n                          shift = random.nextInt(trigger);\n                        }\n                        termsEnum.seek(new BytesRef(\"\"));\n                        continue;\n                      }\n                      seenTermCount++;\n                      // search 10 terms\n                      if (trigger == 0) {\n                        trigger = 1;\n                      }\n                      if ((seenTermCount + shift) % trigger == 0) {\n                        //if (VERBOSE) {\n                        //System.out.println(Thread.currentThread().getName() + \" now search body:\" + term.utf8ToString());\n                        //}\n                        totHits.addAndGet(runQuery(s, new TermQuery(new Term(\"body\", term))));\n                      }\n                    }\n                    if (VERBOSE) {\n                      System.out.println(Thread.currentThread().getName() + \": search done\");\n                    }\n                  }\n                } finally {\n                  nrt.release(s);\n                }\n              } catch (Throwable t) {\n                System.out.println(Thread.currentThread().getName() + \": FAILED: hit exc\");\n                failed.set(true);\n                t.printStackTrace(System.out);\n                throw new RuntimeException(t);\n              }\n            }\n          }\n        };\n      searchThreads[thread].setDaemon(true);\n      searchThreads[thread].start();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now join\");\n    }\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread].join();\n    }\n    for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n      searchThreads[thread].join();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: done join [\" + (System.currentTimeMillis()-t0) + \" ms]; addCount=\" + addCount + \" delCount=\" + delCount);\n      System.out.println(\"TEST: search totHits=\" + totHits);\n    }\n\n    long maxGen = 0;\n    for(long gen : lastGens) {\n      maxGen = Math.max(maxGen, gen);\n    }\n\n    final IndexSearcher s = nrt.get(maxGen, true);\n\n    boolean doFail = false;\n    for(String id : delIDs) {\n      final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", id)), 1);\n      if (hits.totalHits != 0) {\n        System.out.println(\"doc id=\" + id + \" is supposed to be deleted, but got docID=\" + hits.scoreDocs[0].doc);\n        doFail = true;\n      }\n    }\n\n    // Make sure each group of sub-docs are still in docID order:\n    for(SubDocs subDocs : allSubDocs) {\n      if (!subDocs.deleted) {\n        // We sort by relevance but the scores should be identical so sort falls back to by docID:\n        TopDocs hits = s.search(new TermQuery(new Term(\"packID\", subDocs.packID)), 20);\n        assertEquals(subDocs.subIDs.size(), hits.totalHits);\n        int lastDocID = -1;\n        int startDocID = -1;\n        for(ScoreDoc scoreDoc : hits.scoreDocs) {\n          final int docID = scoreDoc.doc;\n          if (lastDocID != -1) {\n            assertEquals(1+lastDocID, docID);\n          } else {\n            startDocID = docID;\n          }\n          lastDocID = docID;\n          final Document doc = s.doc(docID);\n          assertEquals(subDocs.packID, doc.get(\"packID\"));\n        }\n\n        lastDocID = startDocID - 1;\n        for(String subID : subDocs.subIDs) {\n          hits = s.search(new TermQuery(new Term(\"docid\", subID)), 1);\n          assertEquals(1, hits.totalHits);\n          final int docID = hits.scoreDocs[0].doc;\n          if (lastDocID != -1) {\n            assertEquals(1+lastDocID, docID);\n          }\n          lastDocID = docID;\n        }          \n      } else {\n        for(String subID : subDocs.subIDs) {\n          assertEquals(0, s.search(new TermQuery(new Term(\"docid\", subID)), 1).totalHits);\n        }\n      }\n    }\n    \n    final int endID = Integer.parseInt(docs.nextDoc().get(\"docid\"));\n    for(int id=0;id<endID;id++) {\n      String stringID = \"\"+id;\n      if (!delIDs.contains(stringID)) {\n        final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", stringID)), 1);\n        if (hits.totalHits != 1) {\n          System.out.println(\"doc id=\" + stringID + \" is not supposed to be deleted, but got hitCount=\" + hits.totalHits);\n          doFail = true;\n        }\n      }\n    }\n    assertFalse(doFail);\n\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), s.getIndexReader().numDocs());\n    nrt.release(s);\n\n    if (es != null) {\n      es.shutdown();\n      es.awaitTermination(1, TimeUnit.SECONDS);\n    }\n\n    writer.commit();\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), writer.numDocs());\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now close NRTManager\");\n    }\n    nrtThread.close();\n    nrt.close();\n    assertFalse(writer.anyNonBulkMerges);\n    writer.close(false);\n    _TestUtil.checkIndex(dir);\n    dir.close();\n    _TestUtil.rmDir(tempDir);\n    docs.close();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testNRTManager() throws Exception {\n\n    final long t0 = System.currentTimeMillis();\n\n    if (CodecProvider.getDefault().getDefaultFieldCodec().equals(\"SimpleText\")) {\n      // no\n      CodecProvider.getDefault().setDefaultFieldCodec(\"Standard\");\n    }\n\n    final LineFileDocs docs = new LineFileDocs(random);\n    final File tempDir = _TestUtil.getTempDir(\"nrtopenfiles\");\n    final MockDirectoryWrapper _dir = newFSDirectory(tempDir);\n    _dir.setCheckIndexOnClose(false);  // don't double-checkIndex, we do it ourselves\n    Directory dir = _dir;\n    final IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).setOpenMode(IndexWriterConfig.OpenMode.CREATE);\n\n    if (LuceneTestCase.TEST_NIGHTLY) {\n      // newIWConfig makes smallish max seg size, which\n      // results in tons and tons of segments for this test\n      // when run nightly:\n      MergePolicy mp = conf.getMergePolicy();\n      if (mp instanceof TieredMergePolicy) {\n        ((TieredMergePolicy) mp).setMaxMergedSegmentMB(5000.);\n      } else if (mp instanceof LogByteSizeMergePolicy) {\n        ((LogByteSizeMergePolicy) mp).setMaxMergeMB(1000.);\n      } else if (mp instanceof LogMergePolicy) {\n        ((LogMergePolicy) mp).setMaxMergeDocs(100000);\n      }\n    }\n\n    conf.setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n      @Override\n      public void warm(IndexReader reader) throws IOException {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now warm merged reader=\" + reader);\n        }\n        final int maxDoc = reader.maxDoc();\n        final Bits delDocs = reader.getDeletedDocs();\n        int sum = 0;\n        final int inc = Math.max(1, maxDoc/50);\n        for(int docID=0;docID<maxDoc;docID += inc) {\n          if (delDocs == null || !delDocs.get(docID)) {\n            final Document doc = reader.document(docID);\n            sum += doc.getFields().size();\n          }\n        }\n\n        IndexSearcher searcher = newSearcher(reader);\n        sum += searcher.search(new TermQuery(new Term(\"body\", \"united\")), 10).totalHits;\n        searcher.close();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: warm visited \" + sum + \" fields\");\n        }\n      }\n      });\n\n    if (random.nextBoolean()) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: wrap NRTCachingDir\");\n      }\n\n      NRTCachingDirectory nrtDir = new NRTCachingDirectory(dir, 5.0, 60.0);\n      conf.setMergeScheduler(nrtDir.getMergeScheduler());\n      dir = nrtDir;\n    }\n    \n    final IndexWriter writer = new IndexWriter(dir, conf);\n    \n    if (VERBOSE) {\n      writer.setInfoStream(System.out);\n    }\n    _TestUtil.reduceOpenFiles(writer);\n    //System.out.println(\"TEST: conf=\" + writer.getConfig());\n\n    final ExecutorService es = random.nextBoolean() ? null : Executors.newCachedThreadPool(new NamedThreadFactory(\"NRT search threads\"));\n\n    final double minReopenSec = 0.01 + 0.05 * random.nextDouble();\n    final double maxReopenSec = minReopenSec * (1.0 + 10 * random.nextDouble());\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: make NRTManager maxReopenSec=\" + maxReopenSec + \" minReopenSec=\" + minReopenSec);\n    }\n\n    final NRTManager nrt = new NRTManager(writer, es);\n    final NRTManagerReopenThread nrtThread = new NRTManagerReopenThread(nrt, maxReopenSec, minReopenSec);\n    nrtThread.setName(\"NRT Reopen Thread\");\n    nrtThread.setPriority(Math.min(Thread.currentThread().getPriority()+2, Thread.MAX_PRIORITY));\n    nrtThread.setDaemon(true);\n    nrtThread.start();\n\n    final int NUM_INDEX_THREADS = _TestUtil.nextInt(random, 1, 3);\n    final int NUM_SEARCH_THREADS = _TestUtil.nextInt(random, 1, 3);\n    //final int NUM_INDEX_THREADS = 1;\n    //final int NUM_SEARCH_THREADS = 1;\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + NUM_INDEX_THREADS + \" index threads; \" + NUM_SEARCH_THREADS + \" search threads\");\n    }\n\n    final int RUN_TIME_SEC = LuceneTestCase.TEST_NIGHTLY ? 300 : RANDOM_MULTIPLIER;\n\n    final AtomicBoolean failed = new AtomicBoolean();\n    final AtomicInteger addCount = new AtomicInteger();\n    final AtomicInteger delCount = new AtomicInteger();\n    final AtomicInteger packCount = new AtomicInteger();\n    final List<Long> lastGens = new ArrayList<Long>();\n\n    final Set<String> delIDs = Collections.synchronizedSet(new HashSet<String>());\n    final List<SubDocs> allSubDocs = Collections.synchronizedList(new ArrayList<SubDocs>());\n\n    final long stopTime = System.currentTimeMillis() + RUN_TIME_SEC*1000;\n    Thread[] threads = new Thread[NUM_INDEX_THREADS];\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread] = new Thread() {\n          @Override\n          public void run() {\n            // TODO: would be better if this were cross thread, so that we make sure one thread deleting anothers added docs works:\n            final List<String> toDeleteIDs = new ArrayList<String>();\n            final List<SubDocs> toDeleteSubDocs = new ArrayList<SubDocs>();\n\n            long gen = 0;\n            while(System.currentTimeMillis() < stopTime && !failed.get()) {\n\n              //System.out.println(Thread.currentThread().getName() + \": cycle\");\n              try {\n                // Occassional longish pause if running\n                // nightly\n                if (LuceneTestCase.TEST_NIGHTLY && random.nextInt(6) == 3) {\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": now long sleep\");\n                  }\n                  Thread.sleep(_TestUtil.nextInt(random, 50, 500));\n                }\n\n                // Rate limit ingest rate:\n                Thread.sleep(_TestUtil.nextInt(random, 1, 10));\n                if (VERBOSE) {\n                  System.out.println(Thread.currentThread() + \": done sleep\");\n                }\n\n                Document doc = docs.nextDoc();\n                if (doc == null) {\n                  break;\n                }\n                final String addedField;\n                if (random.nextBoolean()) {\n                  addedField = \"extra\" + random.nextInt(10);\n                  doc.add(new Field(addedField, \"a random field\", Field.Store.NO, Field.Index.ANALYZED));\n                } else {\n                  addedField = null;\n                }\n                if (random.nextBoolean()) {\n\n                  if (random.nextBoolean()) {\n                    // Add a pack of adjacent sub-docs\n                    final String packID;\n                    final SubDocs delSubDocs;\n                    if (toDeleteSubDocs.size() > 0 && random.nextBoolean()) {\n                      delSubDocs = toDeleteSubDocs.get(random.nextInt(toDeleteSubDocs.size()));\n                      assert !delSubDocs.deleted;\n                      toDeleteSubDocs.remove(delSubDocs);\n                      // reuse prior packID\n                      packID = delSubDocs.packID;\n                    } else {\n                      delSubDocs = null;\n                      // make new packID\n                      packID = packCount.getAndIncrement() + \"\";\n                    }\n\n                    final Field packIDField = newField(\"packID\", packID, Field.Store.YES, Field.Index.NOT_ANALYZED);\n                    final List<String> docIDs = new ArrayList<String>();\n                    final SubDocs subDocs = new SubDocs(packID, docIDs);\n                    final List<Document> docsList = new ArrayList<Document>();\n\n                    allSubDocs.add(subDocs);\n                    doc.add(packIDField);\n                    docsList.add(cloneDoc(doc));\n                    docIDs.add(doc.get(\"docid\"));\n\n                    final int maxDocCount = _TestUtil.nextInt(random, 1, 10);\n                    while(docsList.size() < maxDocCount) {\n                      doc = docs.nextDoc();\n                      if (doc == null) {\n                        break;\n                      }\n                      docsList.add(cloneDoc(doc));\n                      docIDs.add(doc.get(\"docid\"));\n                    }\n                    addCount.addAndGet(docsList.size());\n\n                    if (delSubDocs != null) {\n                      delSubDocs.deleted = true;\n                      delIDs.addAll(delSubDocs.subIDs);\n                      delCount.addAndGet(delSubDocs.subIDs.size());\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: update pack packID=\" + delSubDocs.packID + \" count=\" + docsList.size() + \" docs=\" + docIDs);\n                      }\n                      gen = nrt.updateDocuments(new Term(\"packID\", delSubDocs.packID), docsList);\n                      /*\n                      // non-atomic:\n                      nrt.deleteDocuments(new Term(\"packID\", delSubDocs.packID));\n                      for(Document subDoc : docsList) {\n                        nrt.addDocument(subDoc);\n                      }\n                      */\n                    } else {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: add pack packID=\" + packID + \" count=\" + docsList.size() + \" docs=\" + docIDs);\n                      }\n                      gen = nrt.addDocuments(docsList);\n                      \n                      /*\n                      // non-atomic:\n                      for(Document subDoc : docsList) {\n                        nrt.addDocument(subDoc);\n                      }\n                      */\n                    }\n                    doc.removeField(\"packID\");\n\n                    if (random.nextInt(5) == 2) {\n                      if (VERBOSE) {\n                        System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + packID);\n                      }\n                      toDeleteSubDocs.add(subDocs);\n                    }\n\n                    // randomly verify the add/update \"took\":\n                    if (random.nextInt(20) == 2) {\n                      final boolean applyDeletes = delSubDocs != null;\n                      final IndexSearcher s = nrt.get(gen, applyDeletes);\n                      try {\n                        assertEquals(docsList.size(), s.search(new TermQuery(new Term(\"packID\", packID)), 10).totalHits);\n                      } finally {\n                        nrt.release(s);\n                      }\n                    }\n\n                  } else {\n                    if (VERBOSE) {\n                      System.out.println(Thread.currentThread().getName() + \": add doc docid:\" + doc.get(\"docid\"));\n                    }\n\n                    gen = nrt.addDocument(doc);\n                    addCount.getAndIncrement();\n\n                    // randomly verify the add \"took\":\n                    if (random.nextInt(20) == 2) {\n                      //System.out.println(Thread.currentThread().getName() + \": verify\");\n                      final IndexSearcher s = nrt.get(gen, false);\n                      //System.out.println(Thread.currentThread().getName() + \": got s=\" + s);\n                      try {\n                        assertEquals(1, s.search(new TermQuery(new Term(\"docid\", doc.get(\"docid\"))), 10).totalHits);\n                      } finally {\n                        nrt.release(s);\n                      }\n                      //System.out.println(Thread.currentThread().getName() + \": done verify\");\n                    }\n\n                    if (random.nextInt(5) == 3) {\n                      if (VERBOSE) {\n                        System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                      }\n                      toDeleteIDs.add(doc.get(\"docid\"));\n                    }\n                  }\n                } else {\n                  // we use update but it never replaces a\n                  // prior doc\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": update doc id:\" + doc.get(\"docid\"));\n                  }\n                  gen = nrt.updateDocument(new Term(\"docid\", doc.get(\"docid\")), doc);\n                  addCount.getAndIncrement();\n\n                  // randomly verify the add \"took\":\n                  if (random.nextInt(20) == 2) {\n                    final IndexSearcher s = nrt.get(gen, true);\n                    try {\n                      assertEquals(1, s.search(new TermQuery(new Term(\"docid\", doc.get(\"docid\"))), 10).totalHits);\n                    } finally {\n                      nrt.release(s);\n                    }\n                  }\n\n                  if (random.nextInt(5) == 3) {\n                    if (VERBOSE) {\n                      System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                    }\n                    toDeleteIDs.add(doc.get(\"docid\"));\n                  }\n                }\n\n                if (random.nextInt(30) == 17) {\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": apply \" + toDeleteIDs.size() + \" deletes\");\n                  }\n                  for(String id : toDeleteIDs) {\n                    if (VERBOSE) {\n                      System.out.println(Thread.currentThread().getName() + \": del term=id:\" + id);\n                    }\n                    gen = nrt.deleteDocuments(new Term(\"docid\", id));\n\n                    // randomly verify the delete \"took\":\n                    if (random.nextInt(20) == 7) {\n                      final IndexSearcher s = nrt.get(gen, true);\n                      try {\n                        assertEquals(0, s.search(new TermQuery(new Term(\"docid\", id)), 10).totalHits);\n                      } finally {\n                        nrt.release(s);\n                      }\n                    }\n                  }\n\n                  final int count = delCount.addAndGet(toDeleteIDs.size());\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": tot \" + count + \" deletes\");\n                  }\n                  delIDs.addAll(toDeleteIDs);\n                  toDeleteIDs.clear();\n\n                  for(SubDocs subDocs : toDeleteSubDocs) {\n                    assertTrue(!subDocs.deleted);\n                    gen = nrt.deleteDocuments(new Term(\"packID\", subDocs.packID));\n                    subDocs.deleted = true;\n                    if (VERBOSE) {\n                      System.out.println(\"  del subs: \" + subDocs.subIDs + \" packID=\" + subDocs.packID);\n                    }\n                    delIDs.addAll(subDocs.subIDs);\n                    delCount.addAndGet(subDocs.subIDs.size());\n\n                    // randomly verify the delete \"took\":\n                    if (random.nextInt(20) == 7) {\n                      final IndexSearcher s = nrt.get(gen, true);\n                      try {\n                        assertEquals(0, s.search(new TermQuery(new Term(\"packID\", subDocs.packID)), 1).totalHits);\n                      } finally {\n                        nrt.release(s);\n                      }\n                    }\n                  }\n                  toDeleteSubDocs.clear();\n                }\n                if (addedField != null) {\n                  doc.removeField(addedField);\n                }\n              } catch (Throwable t) {\n                System.out.println(Thread.currentThread().getName() + \": FAILED: hit exc\");\n                t.printStackTrace();\n                failed.set(true);\n                throw new RuntimeException(t);\n              }\n            }\n\n            lastGens.add(gen);\n            if (VERBOSE) {\n              System.out.println(Thread.currentThread().getName() + \": indexing done\");\n            }\n          }\n        };\n      threads[thread].setDaemon(true);\n      threads[thread].start();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: DONE start indexing threads [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    // let index build up a bit\n    Thread.sleep(100);\n\n    // silly starting guess:\n    final AtomicInteger totTermCount = new AtomicInteger(100);\n\n    // run search threads\n    final Thread[] searchThreads = new Thread[NUM_SEARCH_THREADS];\n    final AtomicInteger totHits = new AtomicInteger();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: start search threads\");\n    }\n\n    for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n      searchThreads[thread] = new Thread() {\n          @Override\n          public void run() {\n            while(System.currentTimeMillis() < stopTime && !failed.get()) {\n              final IndexSearcher s = nrt.get(random.nextBoolean());\n              try {\n                try {\n                  smokeTestSearcher(s);\n                  if (s.getIndexReader().numDocs() > 0) {\n                    Fields fields = MultiFields.getFields(s.getIndexReader());\n                    if (fields == null) {\n                      continue;\n                    }\n                    Terms terms = fields.terms(\"body\");\n                    if (terms == null) {\n                      continue;\n                    }\n\n                    TermsEnum termsEnum = terms.iterator();\n                    int seenTermCount = 0;\n                    int shift;\n                    int trigger;\n                    if (totTermCount.get() == 0) {\n                      shift = 0;\n                      trigger = 1;\n                    } else {\n                      shift = random.nextInt(totTermCount.get()/10);\n                      trigger = totTermCount.get()/10;\n                    }\n\n                    while(System.currentTimeMillis() < stopTime) {\n                      BytesRef term = termsEnum.next();\n                      if (term == null) {\n                        if (seenTermCount == 0) {\n                          break;\n                        }\n                        totTermCount.set(seenTermCount);\n                        seenTermCount = 0;\n                        if (totTermCount.get() == 0) {\n                          shift = 0;\n                          trigger = 1;\n                        } else {\n                          trigger = totTermCount.get()/10;\n                          //System.out.println(\"trigger \" + trigger);\n                          shift = random.nextInt(totTermCount.get()/10);\n                        }\n                        termsEnum.seek(new BytesRef(\"\"));\n                        continue;\n                      }\n                      seenTermCount++;\n                      // search 10 terms\n                      if (trigger == 0) {\n                        trigger = 1;\n                      }\n                      if ((seenTermCount + shift) % trigger == 0) {\n                        //if (VERBOSE) {\n                        //System.out.println(Thread.currentThread().getName() + \" now search body:\" + term.utf8ToString());\n                        //}\n                        totHits.addAndGet(runQuery(s, new TermQuery(new Term(\"body\", term))));\n                      }\n                    }\n                    if (VERBOSE) {\n                      System.out.println(Thread.currentThread().getName() + \": search done\");\n                    }\n                  }\n                } finally {\n                  nrt.release(s);\n                }\n              } catch (Throwable t) {\n                System.out.println(Thread.currentThread().getName() + \": FAILED: hit exc\");\n                failed.set(true);\n                t.printStackTrace(System.out);\n                throw new RuntimeException(t);\n              }\n            }\n          }\n        };\n      searchThreads[thread].setDaemon(true);\n      searchThreads[thread].start();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now join\");\n    }\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread].join();\n    }\n    for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n      searchThreads[thread].join();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: done join [\" + (System.currentTimeMillis()-t0) + \" ms]; addCount=\" + addCount + \" delCount=\" + delCount);\n      System.out.println(\"TEST: search totHits=\" + totHits);\n    }\n\n    long maxGen = 0;\n    for(long gen : lastGens) {\n      maxGen = Math.max(maxGen, gen);\n    }\n\n    final IndexSearcher s = nrt.get(maxGen, true);\n\n    boolean doFail = false;\n    for(String id : delIDs) {\n      final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", id)), 1);\n      if (hits.totalHits != 0) {\n        System.out.println(\"doc id=\" + id + \" is supposed to be deleted, but got docID=\" + hits.scoreDocs[0].doc);\n        doFail = true;\n      }\n    }\n\n    // Make sure each group of sub-docs are still in docID order:\n    for(SubDocs subDocs : allSubDocs) {\n      if (!subDocs.deleted) {\n        // We sort by relevance but the scores should be identical so sort falls back to by docID:\n        TopDocs hits = s.search(new TermQuery(new Term(\"packID\", subDocs.packID)), 20);\n        assertEquals(subDocs.subIDs.size(), hits.totalHits);\n        int lastDocID = -1;\n        int startDocID = -1;\n        for(ScoreDoc scoreDoc : hits.scoreDocs) {\n          final int docID = scoreDoc.doc;\n          if (lastDocID != -1) {\n            assertEquals(1+lastDocID, docID);\n          } else {\n            startDocID = docID;\n          }\n          lastDocID = docID;\n          final Document doc = s.doc(docID);\n          assertEquals(subDocs.packID, doc.get(\"packID\"));\n        }\n\n        lastDocID = startDocID - 1;\n        for(String subID : subDocs.subIDs) {\n          hits = s.search(new TermQuery(new Term(\"docid\", subID)), 1);\n          assertEquals(1, hits.totalHits);\n          final int docID = hits.scoreDocs[0].doc;\n          if (lastDocID != -1) {\n            assertEquals(1+lastDocID, docID);\n          }\n          lastDocID = docID;\n        }          \n      } else {\n        for(String subID : subDocs.subIDs) {\n          assertEquals(0, s.search(new TermQuery(new Term(\"docid\", subID)), 1).totalHits);\n        }\n      }\n    }\n    \n    final int endID = Integer.parseInt(docs.nextDoc().get(\"docid\"));\n    for(int id=0;id<endID;id++) {\n      String stringID = \"\"+id;\n      if (!delIDs.contains(stringID)) {\n        final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", stringID)), 1);\n        if (hits.totalHits != 1) {\n          System.out.println(\"doc id=\" + stringID + \" is not supposed to be deleted, but got hitCount=\" + hits.totalHits);\n          doFail = true;\n        }\n      }\n    }\n    assertFalse(doFail);\n\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), s.getIndexReader().numDocs());\n    nrt.release(s);\n\n    if (es != null) {\n      es.shutdown();\n      es.awaitTermination(1, TimeUnit.SECONDS);\n    }\n\n    writer.commit();\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), writer.numDocs());\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now close NRTManager\");\n    }\n    nrtThread.close();\n    nrt.close();\n    assertFalse(writer.anyNonBulkMerges);\n    writer.close(false);\n    _TestUtil.checkIndex(dir);\n    dir.close();\n    _TestUtil.rmDir(tempDir);\n    docs.close();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fd9cc9d77712aba3662f24632df7539ab75e3667","date":1309095238,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/contrib/misc/src/test/org/apache/lucene/index/TestNRTManager#testNRTManager().mjava","pathOld":"lucene/contrib/misc/src/test/org/apache/lucene/index/TestNRTManager#testNRTManager().mjava","sourceNew":"  @Test\n  public void testNRTManager() throws Exception {\n\n    final long t0 = System.currentTimeMillis();\n\n    if (CodecProvider.getDefault().getDefaultFieldCodec().equals(\"SimpleText\")) {\n      // no\n      CodecProvider.getDefault().setDefaultFieldCodec(\"Standard\");\n    }\n\n    final LineFileDocs docs = new LineFileDocs(random);\n    final File tempDir = _TestUtil.getTempDir(\"nrtopenfiles\");\n    final MockDirectoryWrapper _dir = newFSDirectory(tempDir);\n    _dir.setCheckIndexOnClose(false);  // don't double-checkIndex, we do it ourselves\n    Directory dir = _dir;\n    final IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).setOpenMode(IndexWriterConfig.OpenMode.CREATE);\n\n    if (LuceneTestCase.TEST_NIGHTLY) {\n      // newIWConfig makes smallish max seg size, which\n      // results in tons and tons of segments for this test\n      // when run nightly:\n      MergePolicy mp = conf.getMergePolicy();\n      if (mp instanceof TieredMergePolicy) {\n        ((TieredMergePolicy) mp).setMaxMergedSegmentMB(5000.);\n      } else if (mp instanceof LogByteSizeMergePolicy) {\n        ((LogByteSizeMergePolicy) mp).setMaxMergeMB(1000.);\n      } else if (mp instanceof LogMergePolicy) {\n        ((LogMergePolicy) mp).setMaxMergeDocs(100000);\n      }\n    }\n\n    conf.setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n      @Override\n      public void warm(IndexReader reader) throws IOException {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now warm merged reader=\" + reader);\n        }\n        final int maxDoc = reader.maxDoc();\n        final Bits delDocs = reader.getDeletedDocs();\n        int sum = 0;\n        final int inc = Math.max(1, maxDoc/50);\n        for(int docID=0;docID<maxDoc;docID += inc) {\n          if (delDocs == null || !delDocs.get(docID)) {\n            final Document doc = reader.document(docID);\n            sum += doc.getFields().size();\n          }\n        }\n\n        IndexSearcher searcher = newSearcher(reader);\n        sum += searcher.search(new TermQuery(new Term(\"body\", \"united\")), 10).totalHits;\n        searcher.close();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: warm visited \" + sum + \" fields\");\n        }\n      }\n      });\n\n    if (random.nextBoolean()) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: wrap NRTCachingDir\");\n      }\n\n      NRTCachingDirectory nrtDir = new NRTCachingDirectory(dir, 5.0, 60.0);\n      conf.setMergeScheduler(nrtDir.getMergeScheduler());\n      dir = nrtDir;\n    }\n    \n    final IndexWriter writer = new IndexWriter(dir, conf);\n    \n    if (VERBOSE) {\n      writer.setInfoStream(System.out);\n    }\n    _TestUtil.reduceOpenFiles(writer);\n    //System.out.println(\"TEST: conf=\" + writer.getConfig());\n\n    final ExecutorService es = random.nextBoolean() ? null : Executors.newCachedThreadPool(new NamedThreadFactory(\"NRT search threads\"));\n\n    final double minReopenSec = 0.01 + 0.05 * random.nextDouble();\n    final double maxReopenSec = minReopenSec * (1.0 + 10 * random.nextDouble());\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: make NRTManager maxReopenSec=\" + maxReopenSec + \" minReopenSec=\" + minReopenSec);\n    }\n\n    final NRTManager nrt = new NRTManager(writer, es);\n    final NRTManagerReopenThread nrtThread = new NRTManagerReopenThread(nrt, maxReopenSec, minReopenSec);\n    nrtThread.setName(\"NRT Reopen Thread\");\n    nrtThread.setPriority(Math.min(Thread.currentThread().getPriority()+2, Thread.MAX_PRIORITY));\n    nrtThread.setDaemon(true);\n    nrtThread.start();\n\n    final int NUM_INDEX_THREADS = _TestUtil.nextInt(random, 1, 3);\n    final int NUM_SEARCH_THREADS = _TestUtil.nextInt(random, 1, 3);\n    //final int NUM_INDEX_THREADS = 1;\n    //final int NUM_SEARCH_THREADS = 1;\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + NUM_INDEX_THREADS + \" index threads; \" + NUM_SEARCH_THREADS + \" search threads\");\n    }\n\n    final int RUN_TIME_SEC = LuceneTestCase.TEST_NIGHTLY ? 300 : RANDOM_MULTIPLIER;\n\n    final AtomicBoolean failed = new AtomicBoolean();\n    final AtomicInteger addCount = new AtomicInteger();\n    final AtomicInteger delCount = new AtomicInteger();\n    final AtomicInteger packCount = new AtomicInteger();\n    final List<Long> lastGens = new ArrayList<Long>();\n\n    final Set<String> delIDs = Collections.synchronizedSet(new HashSet<String>());\n    final List<SubDocs> allSubDocs = Collections.synchronizedList(new ArrayList<SubDocs>());\n\n    final long stopTime = System.currentTimeMillis() + RUN_TIME_SEC*1000;\n    Thread[] threads = new Thread[NUM_INDEX_THREADS];\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread] = new Thread() {\n          @Override\n          public void run() {\n            // TODO: would be better if this were cross thread, so that we make sure one thread deleting anothers added docs works:\n            final List<String> toDeleteIDs = new ArrayList<String>();\n            final List<SubDocs> toDeleteSubDocs = new ArrayList<SubDocs>();\n\n            long gen = 0;\n            while(System.currentTimeMillis() < stopTime && !failed.get()) {\n\n              //System.out.println(Thread.currentThread().getName() + \": cycle\");\n              try {\n                // Occassional longish pause if running\n                // nightly\n                if (LuceneTestCase.TEST_NIGHTLY && random.nextInt(6) == 3) {\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": now long sleep\");\n                  }\n                  Thread.sleep(_TestUtil.nextInt(random, 50, 500));\n                }\n\n                // Rate limit ingest rate:\n                Thread.sleep(_TestUtil.nextInt(random, 1, 10));\n                if (VERBOSE) {\n                  System.out.println(Thread.currentThread() + \": done sleep\");\n                }\n\n                Document doc = docs.nextDoc();\n                if (doc == null) {\n                  break;\n                }\n                final String addedField;\n                if (random.nextBoolean()) {\n                  addedField = \"extra\" + random.nextInt(10);\n                  doc.add(new Field(addedField, \"a random field\", Field.Store.NO, Field.Index.ANALYZED));\n                } else {\n                  addedField = null;\n                }\n                if (random.nextBoolean()) {\n\n                  if (random.nextBoolean()) {\n                    // Add a pack of adjacent sub-docs\n                    final String packID;\n                    final SubDocs delSubDocs;\n                    if (toDeleteSubDocs.size() > 0 && random.nextBoolean()) {\n                      delSubDocs = toDeleteSubDocs.get(random.nextInt(toDeleteSubDocs.size()));\n                      assert !delSubDocs.deleted;\n                      toDeleteSubDocs.remove(delSubDocs);\n                      // reuse prior packID\n                      packID = delSubDocs.packID;\n                    } else {\n                      delSubDocs = null;\n                      // make new packID\n                      packID = packCount.getAndIncrement() + \"\";\n                    }\n\n                    final Field packIDField = newField(\"packID\", packID, Field.Store.YES, Field.Index.NOT_ANALYZED);\n                    final List<String> docIDs = new ArrayList<String>();\n                    final SubDocs subDocs = new SubDocs(packID, docIDs);\n                    final List<Document> docsList = new ArrayList<Document>();\n\n                    allSubDocs.add(subDocs);\n                    doc.add(packIDField);\n                    docsList.add(cloneDoc(doc));\n                    docIDs.add(doc.get(\"docid\"));\n\n                    final int maxDocCount = _TestUtil.nextInt(random, 1, 10);\n                    while(docsList.size() < maxDocCount) {\n                      doc = docs.nextDoc();\n                      if (doc == null) {\n                        break;\n                      }\n                      docsList.add(cloneDoc(doc));\n                      docIDs.add(doc.get(\"docid\"));\n                    }\n                    addCount.addAndGet(docsList.size());\n\n                    if (delSubDocs != null) {\n                      delSubDocs.deleted = true;\n                      delIDs.addAll(delSubDocs.subIDs);\n                      delCount.addAndGet(delSubDocs.subIDs.size());\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: update pack packID=\" + delSubDocs.packID + \" count=\" + docsList.size() + \" docs=\" + docIDs);\n                      }\n                      gen = nrt.updateDocuments(new Term(\"packID\", delSubDocs.packID), docsList);\n                      /*\n                      // non-atomic:\n                      nrt.deleteDocuments(new Term(\"packID\", delSubDocs.packID));\n                      for(Document subDoc : docsList) {\n                        nrt.addDocument(subDoc);\n                      }\n                      */\n                    } else {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: add pack packID=\" + packID + \" count=\" + docsList.size() + \" docs=\" + docIDs);\n                      }\n                      gen = nrt.addDocuments(docsList);\n                      \n                      /*\n                      // non-atomic:\n                      for(Document subDoc : docsList) {\n                        nrt.addDocument(subDoc);\n                      }\n                      */\n                    }\n                    doc.removeField(\"packID\");\n\n                    if (random.nextInt(5) == 2) {\n                      if (VERBOSE) {\n                        System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + packID);\n                      }\n                      toDeleteSubDocs.add(subDocs);\n                    }\n\n                    // randomly verify the add/update \"took\":\n                    if (random.nextInt(20) == 2) {\n                      final boolean applyDeletes = delSubDocs != null;\n                      final IndexSearcher s = nrt.get(gen, applyDeletes);\n                      try {\n                        assertEquals(docsList.size(), s.search(new TermQuery(new Term(\"packID\", packID)), 10).totalHits);\n                      } finally {\n                        nrt.release(s);\n                      }\n                    }\n\n                  } else {\n                    if (VERBOSE) {\n                      System.out.println(Thread.currentThread().getName() + \": add doc docid:\" + doc.get(\"docid\"));\n                    }\n\n                    gen = nrt.addDocument(doc);\n                    addCount.getAndIncrement();\n\n                    // randomly verify the add \"took\":\n                    if (random.nextInt(20) == 2) {\n                      //System.out.println(Thread.currentThread().getName() + \": verify\");\n                      final IndexSearcher s = nrt.get(gen, false);\n                      //System.out.println(Thread.currentThread().getName() + \": got s=\" + s);\n                      try {\n                        assertEquals(1, s.search(new TermQuery(new Term(\"docid\", doc.get(\"docid\"))), 10).totalHits);\n                      } finally {\n                        nrt.release(s);\n                      }\n                      //System.out.println(Thread.currentThread().getName() + \": done verify\");\n                    }\n\n                    if (random.nextInt(5) == 3) {\n                      if (VERBOSE) {\n                        System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                      }\n                      toDeleteIDs.add(doc.get(\"docid\"));\n                    }\n                  }\n                } else {\n                  // we use update but it never replaces a\n                  // prior doc\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": update doc id:\" + doc.get(\"docid\"));\n                  }\n                  gen = nrt.updateDocument(new Term(\"docid\", doc.get(\"docid\")), doc);\n                  addCount.getAndIncrement();\n\n                  // randomly verify the add \"took\":\n                  if (random.nextInt(20) == 2) {\n                    final IndexSearcher s = nrt.get(gen, true);\n                    try {\n                      assertEquals(1, s.search(new TermQuery(new Term(\"docid\", doc.get(\"docid\"))), 10).totalHits);\n                    } finally {\n                      nrt.release(s);\n                    }\n                  }\n\n                  if (random.nextInt(5) == 3) {\n                    if (VERBOSE) {\n                      System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                    }\n                    toDeleteIDs.add(doc.get(\"docid\"));\n                  }\n                }\n\n                if (random.nextInt(30) == 17) {\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": apply \" + toDeleteIDs.size() + \" deletes\");\n                  }\n                  for(String id : toDeleteIDs) {\n                    if (VERBOSE) {\n                      System.out.println(Thread.currentThread().getName() + \": del term=id:\" + id);\n                    }\n                    gen = nrt.deleteDocuments(new Term(\"docid\", id));\n\n                    // randomly verify the delete \"took\":\n                    if (random.nextInt(20) == 7) {\n                      final IndexSearcher s = nrt.get(gen, true);\n                      try {\n                        assertEquals(0, s.search(new TermQuery(new Term(\"docid\", id)), 10).totalHits);\n                      } finally {\n                        nrt.release(s);\n                      }\n                    }\n                  }\n\n                  final int count = delCount.addAndGet(toDeleteIDs.size());\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": tot \" + count + \" deletes\");\n                  }\n                  delIDs.addAll(toDeleteIDs);\n                  toDeleteIDs.clear();\n\n                  for(SubDocs subDocs : toDeleteSubDocs) {\n                    assertTrue(!subDocs.deleted);\n                    gen = nrt.deleteDocuments(new Term(\"packID\", subDocs.packID));\n                    subDocs.deleted = true;\n                    if (VERBOSE) {\n                      System.out.println(\"  del subs: \" + subDocs.subIDs + \" packID=\" + subDocs.packID);\n                    }\n                    delIDs.addAll(subDocs.subIDs);\n                    delCount.addAndGet(subDocs.subIDs.size());\n\n                    // randomly verify the delete \"took\":\n                    if (random.nextInt(20) == 7) {\n                      final IndexSearcher s = nrt.get(gen, true);\n                      try {\n                        assertEquals(0, s.search(new TermQuery(new Term(\"packID\", subDocs.packID)), 1).totalHits);\n                      } finally {\n                        nrt.release(s);\n                      }\n                    }\n                  }\n                  toDeleteSubDocs.clear();\n                }\n                if (addedField != null) {\n                  doc.removeField(addedField);\n                }\n              } catch (Throwable t) {\n                System.out.println(Thread.currentThread().getName() + \": FAILED: hit exc\");\n                t.printStackTrace();\n                failed.set(true);\n                throw new RuntimeException(t);\n              }\n            }\n\n            lastGens.add(gen);\n            if (VERBOSE) {\n              System.out.println(Thread.currentThread().getName() + \": indexing done\");\n            }\n          }\n        };\n      threads[thread].setDaemon(true);\n      threads[thread].start();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: DONE start indexing threads [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    // let index build up a bit\n    Thread.sleep(100);\n\n    // silly starting guess:\n    final AtomicInteger totTermCount = new AtomicInteger(100);\n\n    // run search threads\n    final Thread[] searchThreads = new Thread[NUM_SEARCH_THREADS];\n    final AtomicInteger totHits = new AtomicInteger();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: start search threads\");\n    }\n\n    for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n      searchThreads[thread] = new Thread() {\n          @Override\n          public void run() {\n            while(System.currentTimeMillis() < stopTime && !failed.get()) {\n              final IndexSearcher s = nrt.get(random.nextBoolean());\n              try {\n                try {\n                  smokeTestSearcher(s);\n                  if (s.getIndexReader().numDocs() > 0) {\n                    Fields fields = MultiFields.getFields(s.getIndexReader());\n                    if (fields == null) {\n                      continue;\n                    }\n                    Terms terms = fields.terms(\"body\");\n                    if (terms == null) {\n                      continue;\n                    }\n\n                    TermsEnum termsEnum = terms.iterator();\n                    int seenTermCount = 0;\n                    int shift;\n                    int trigger;\n                    if (totTermCount.get() < 10) {\n                      shift = 0;\n                      trigger = 1;\n                    } else {\n                      trigger = totTermCount.get()/10;\n                      shift = random.nextInt(trigger);\n                    }\n\n                    while(System.currentTimeMillis() < stopTime) {\n                      BytesRef term = termsEnum.next();\n                      if (term == null) {\n                        if (seenTermCount == 0) {\n                          break;\n                        }\n                        totTermCount.set(seenTermCount);\n                        seenTermCount = 0;\n                        if (totTermCount.get() < 10) {\n                          shift = 0;\n                          trigger = 1;\n                        } else {\n                          trigger = totTermCount.get()/10;\n                          //System.out.println(\"trigger \" + trigger);\n                          shift = random.nextInt(trigger);\n                        }\n                        termsEnum.seekCeil(new BytesRef(\"\"));\n                        continue;\n                      }\n                      seenTermCount++;\n                      // search 10 terms\n                      if (trigger == 0) {\n                        trigger = 1;\n                      }\n                      if ((seenTermCount + shift) % trigger == 0) {\n                        //if (VERBOSE) {\n                        //System.out.println(Thread.currentThread().getName() + \" now search body:\" + term.utf8ToString());\n                        //}\n                        totHits.addAndGet(runQuery(s, new TermQuery(new Term(\"body\", term))));\n                      }\n                    }\n                    if (VERBOSE) {\n                      System.out.println(Thread.currentThread().getName() + \": search done\");\n                    }\n                  }\n                } finally {\n                  nrt.release(s);\n                }\n              } catch (Throwable t) {\n                System.out.println(Thread.currentThread().getName() + \": FAILED: hit exc\");\n                failed.set(true);\n                t.printStackTrace(System.out);\n                throw new RuntimeException(t);\n              }\n            }\n          }\n        };\n      searchThreads[thread].setDaemon(true);\n      searchThreads[thread].start();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now join\");\n    }\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread].join();\n    }\n    for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n      searchThreads[thread].join();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: done join [\" + (System.currentTimeMillis()-t0) + \" ms]; addCount=\" + addCount + \" delCount=\" + delCount);\n      System.out.println(\"TEST: search totHits=\" + totHits);\n    }\n\n    long maxGen = 0;\n    for(long gen : lastGens) {\n      maxGen = Math.max(maxGen, gen);\n    }\n\n    final IndexSearcher s = nrt.get(maxGen, true);\n\n    boolean doFail = false;\n    for(String id : delIDs) {\n      final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", id)), 1);\n      if (hits.totalHits != 0) {\n        System.out.println(\"doc id=\" + id + \" is supposed to be deleted, but got docID=\" + hits.scoreDocs[0].doc);\n        doFail = true;\n      }\n    }\n\n    // Make sure each group of sub-docs are still in docID order:\n    for(SubDocs subDocs : allSubDocs) {\n      if (!subDocs.deleted) {\n        // We sort by relevance but the scores should be identical so sort falls back to by docID:\n        TopDocs hits = s.search(new TermQuery(new Term(\"packID\", subDocs.packID)), 20);\n        assertEquals(subDocs.subIDs.size(), hits.totalHits);\n        int lastDocID = -1;\n        int startDocID = -1;\n        for(ScoreDoc scoreDoc : hits.scoreDocs) {\n          final int docID = scoreDoc.doc;\n          if (lastDocID != -1) {\n            assertEquals(1+lastDocID, docID);\n          } else {\n            startDocID = docID;\n          }\n          lastDocID = docID;\n          final Document doc = s.doc(docID);\n          assertEquals(subDocs.packID, doc.get(\"packID\"));\n        }\n\n        lastDocID = startDocID - 1;\n        for(String subID : subDocs.subIDs) {\n          hits = s.search(new TermQuery(new Term(\"docid\", subID)), 1);\n          assertEquals(1, hits.totalHits);\n          final int docID = hits.scoreDocs[0].doc;\n          if (lastDocID != -1) {\n            assertEquals(1+lastDocID, docID);\n          }\n          lastDocID = docID;\n        }          \n      } else {\n        for(String subID : subDocs.subIDs) {\n          assertEquals(0, s.search(new TermQuery(new Term(\"docid\", subID)), 1).totalHits);\n        }\n      }\n    }\n    \n    final int endID = Integer.parseInt(docs.nextDoc().get(\"docid\"));\n    for(int id=0;id<endID;id++) {\n      String stringID = \"\"+id;\n      if (!delIDs.contains(stringID)) {\n        final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", stringID)), 1);\n        if (hits.totalHits != 1) {\n          System.out.println(\"doc id=\" + stringID + \" is not supposed to be deleted, but got hitCount=\" + hits.totalHits);\n          doFail = true;\n        }\n      }\n    }\n    assertFalse(doFail);\n\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), s.getIndexReader().numDocs());\n    nrt.release(s);\n\n    if (es != null) {\n      es.shutdown();\n      es.awaitTermination(1, TimeUnit.SECONDS);\n    }\n\n    writer.commit();\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), writer.numDocs());\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now close NRTManager\");\n    }\n    nrtThread.close();\n    nrt.close();\n    assertFalse(writer.anyNonBulkMerges);\n    writer.close(false);\n    _TestUtil.checkIndex(dir);\n    dir.close();\n    _TestUtil.rmDir(tempDir);\n    docs.close();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testNRTManager() throws Exception {\n\n    final long t0 = System.currentTimeMillis();\n\n    if (CodecProvider.getDefault().getDefaultFieldCodec().equals(\"SimpleText\")) {\n      // no\n      CodecProvider.getDefault().setDefaultFieldCodec(\"Standard\");\n    }\n\n    final LineFileDocs docs = new LineFileDocs(random);\n    final File tempDir = _TestUtil.getTempDir(\"nrtopenfiles\");\n    final MockDirectoryWrapper _dir = newFSDirectory(tempDir);\n    _dir.setCheckIndexOnClose(false);  // don't double-checkIndex, we do it ourselves\n    Directory dir = _dir;\n    final IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).setOpenMode(IndexWriterConfig.OpenMode.CREATE);\n\n    if (LuceneTestCase.TEST_NIGHTLY) {\n      // newIWConfig makes smallish max seg size, which\n      // results in tons and tons of segments for this test\n      // when run nightly:\n      MergePolicy mp = conf.getMergePolicy();\n      if (mp instanceof TieredMergePolicy) {\n        ((TieredMergePolicy) mp).setMaxMergedSegmentMB(5000.);\n      } else if (mp instanceof LogByteSizeMergePolicy) {\n        ((LogByteSizeMergePolicy) mp).setMaxMergeMB(1000.);\n      } else if (mp instanceof LogMergePolicy) {\n        ((LogMergePolicy) mp).setMaxMergeDocs(100000);\n      }\n    }\n\n    conf.setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n      @Override\n      public void warm(IndexReader reader) throws IOException {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now warm merged reader=\" + reader);\n        }\n        final int maxDoc = reader.maxDoc();\n        final Bits delDocs = reader.getDeletedDocs();\n        int sum = 0;\n        final int inc = Math.max(1, maxDoc/50);\n        for(int docID=0;docID<maxDoc;docID += inc) {\n          if (delDocs == null || !delDocs.get(docID)) {\n            final Document doc = reader.document(docID);\n            sum += doc.getFields().size();\n          }\n        }\n\n        IndexSearcher searcher = newSearcher(reader);\n        sum += searcher.search(new TermQuery(new Term(\"body\", \"united\")), 10).totalHits;\n        searcher.close();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: warm visited \" + sum + \" fields\");\n        }\n      }\n      });\n\n    if (random.nextBoolean()) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: wrap NRTCachingDir\");\n      }\n\n      NRTCachingDirectory nrtDir = new NRTCachingDirectory(dir, 5.0, 60.0);\n      conf.setMergeScheduler(nrtDir.getMergeScheduler());\n      dir = nrtDir;\n    }\n    \n    final IndexWriter writer = new IndexWriter(dir, conf);\n    \n    if (VERBOSE) {\n      writer.setInfoStream(System.out);\n    }\n    _TestUtil.reduceOpenFiles(writer);\n    //System.out.println(\"TEST: conf=\" + writer.getConfig());\n\n    final ExecutorService es = random.nextBoolean() ? null : Executors.newCachedThreadPool(new NamedThreadFactory(\"NRT search threads\"));\n\n    final double minReopenSec = 0.01 + 0.05 * random.nextDouble();\n    final double maxReopenSec = minReopenSec * (1.0 + 10 * random.nextDouble());\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: make NRTManager maxReopenSec=\" + maxReopenSec + \" minReopenSec=\" + minReopenSec);\n    }\n\n    final NRTManager nrt = new NRTManager(writer, es);\n    final NRTManagerReopenThread nrtThread = new NRTManagerReopenThread(nrt, maxReopenSec, minReopenSec);\n    nrtThread.setName(\"NRT Reopen Thread\");\n    nrtThread.setPriority(Math.min(Thread.currentThread().getPriority()+2, Thread.MAX_PRIORITY));\n    nrtThread.setDaemon(true);\n    nrtThread.start();\n\n    final int NUM_INDEX_THREADS = _TestUtil.nextInt(random, 1, 3);\n    final int NUM_SEARCH_THREADS = _TestUtil.nextInt(random, 1, 3);\n    //final int NUM_INDEX_THREADS = 1;\n    //final int NUM_SEARCH_THREADS = 1;\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + NUM_INDEX_THREADS + \" index threads; \" + NUM_SEARCH_THREADS + \" search threads\");\n    }\n\n    final int RUN_TIME_SEC = LuceneTestCase.TEST_NIGHTLY ? 300 : RANDOM_MULTIPLIER;\n\n    final AtomicBoolean failed = new AtomicBoolean();\n    final AtomicInteger addCount = new AtomicInteger();\n    final AtomicInteger delCount = new AtomicInteger();\n    final AtomicInteger packCount = new AtomicInteger();\n    final List<Long> lastGens = new ArrayList<Long>();\n\n    final Set<String> delIDs = Collections.synchronizedSet(new HashSet<String>());\n    final List<SubDocs> allSubDocs = Collections.synchronizedList(new ArrayList<SubDocs>());\n\n    final long stopTime = System.currentTimeMillis() + RUN_TIME_SEC*1000;\n    Thread[] threads = new Thread[NUM_INDEX_THREADS];\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread] = new Thread() {\n          @Override\n          public void run() {\n            // TODO: would be better if this were cross thread, so that we make sure one thread deleting anothers added docs works:\n            final List<String> toDeleteIDs = new ArrayList<String>();\n            final List<SubDocs> toDeleteSubDocs = new ArrayList<SubDocs>();\n\n            long gen = 0;\n            while(System.currentTimeMillis() < stopTime && !failed.get()) {\n\n              //System.out.println(Thread.currentThread().getName() + \": cycle\");\n              try {\n                // Occassional longish pause if running\n                // nightly\n                if (LuceneTestCase.TEST_NIGHTLY && random.nextInt(6) == 3) {\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": now long sleep\");\n                  }\n                  Thread.sleep(_TestUtil.nextInt(random, 50, 500));\n                }\n\n                // Rate limit ingest rate:\n                Thread.sleep(_TestUtil.nextInt(random, 1, 10));\n                if (VERBOSE) {\n                  System.out.println(Thread.currentThread() + \": done sleep\");\n                }\n\n                Document doc = docs.nextDoc();\n                if (doc == null) {\n                  break;\n                }\n                final String addedField;\n                if (random.nextBoolean()) {\n                  addedField = \"extra\" + random.nextInt(10);\n                  doc.add(new Field(addedField, \"a random field\", Field.Store.NO, Field.Index.ANALYZED));\n                } else {\n                  addedField = null;\n                }\n                if (random.nextBoolean()) {\n\n                  if (random.nextBoolean()) {\n                    // Add a pack of adjacent sub-docs\n                    final String packID;\n                    final SubDocs delSubDocs;\n                    if (toDeleteSubDocs.size() > 0 && random.nextBoolean()) {\n                      delSubDocs = toDeleteSubDocs.get(random.nextInt(toDeleteSubDocs.size()));\n                      assert !delSubDocs.deleted;\n                      toDeleteSubDocs.remove(delSubDocs);\n                      // reuse prior packID\n                      packID = delSubDocs.packID;\n                    } else {\n                      delSubDocs = null;\n                      // make new packID\n                      packID = packCount.getAndIncrement() + \"\";\n                    }\n\n                    final Field packIDField = newField(\"packID\", packID, Field.Store.YES, Field.Index.NOT_ANALYZED);\n                    final List<String> docIDs = new ArrayList<String>();\n                    final SubDocs subDocs = new SubDocs(packID, docIDs);\n                    final List<Document> docsList = new ArrayList<Document>();\n\n                    allSubDocs.add(subDocs);\n                    doc.add(packIDField);\n                    docsList.add(cloneDoc(doc));\n                    docIDs.add(doc.get(\"docid\"));\n\n                    final int maxDocCount = _TestUtil.nextInt(random, 1, 10);\n                    while(docsList.size() < maxDocCount) {\n                      doc = docs.nextDoc();\n                      if (doc == null) {\n                        break;\n                      }\n                      docsList.add(cloneDoc(doc));\n                      docIDs.add(doc.get(\"docid\"));\n                    }\n                    addCount.addAndGet(docsList.size());\n\n                    if (delSubDocs != null) {\n                      delSubDocs.deleted = true;\n                      delIDs.addAll(delSubDocs.subIDs);\n                      delCount.addAndGet(delSubDocs.subIDs.size());\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: update pack packID=\" + delSubDocs.packID + \" count=\" + docsList.size() + \" docs=\" + docIDs);\n                      }\n                      gen = nrt.updateDocuments(new Term(\"packID\", delSubDocs.packID), docsList);\n                      /*\n                      // non-atomic:\n                      nrt.deleteDocuments(new Term(\"packID\", delSubDocs.packID));\n                      for(Document subDoc : docsList) {\n                        nrt.addDocument(subDoc);\n                      }\n                      */\n                    } else {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: add pack packID=\" + packID + \" count=\" + docsList.size() + \" docs=\" + docIDs);\n                      }\n                      gen = nrt.addDocuments(docsList);\n                      \n                      /*\n                      // non-atomic:\n                      for(Document subDoc : docsList) {\n                        nrt.addDocument(subDoc);\n                      }\n                      */\n                    }\n                    doc.removeField(\"packID\");\n\n                    if (random.nextInt(5) == 2) {\n                      if (VERBOSE) {\n                        System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + packID);\n                      }\n                      toDeleteSubDocs.add(subDocs);\n                    }\n\n                    // randomly verify the add/update \"took\":\n                    if (random.nextInt(20) == 2) {\n                      final boolean applyDeletes = delSubDocs != null;\n                      final IndexSearcher s = nrt.get(gen, applyDeletes);\n                      try {\n                        assertEquals(docsList.size(), s.search(new TermQuery(new Term(\"packID\", packID)), 10).totalHits);\n                      } finally {\n                        nrt.release(s);\n                      }\n                    }\n\n                  } else {\n                    if (VERBOSE) {\n                      System.out.println(Thread.currentThread().getName() + \": add doc docid:\" + doc.get(\"docid\"));\n                    }\n\n                    gen = nrt.addDocument(doc);\n                    addCount.getAndIncrement();\n\n                    // randomly verify the add \"took\":\n                    if (random.nextInt(20) == 2) {\n                      //System.out.println(Thread.currentThread().getName() + \": verify\");\n                      final IndexSearcher s = nrt.get(gen, false);\n                      //System.out.println(Thread.currentThread().getName() + \": got s=\" + s);\n                      try {\n                        assertEquals(1, s.search(new TermQuery(new Term(\"docid\", doc.get(\"docid\"))), 10).totalHits);\n                      } finally {\n                        nrt.release(s);\n                      }\n                      //System.out.println(Thread.currentThread().getName() + \": done verify\");\n                    }\n\n                    if (random.nextInt(5) == 3) {\n                      if (VERBOSE) {\n                        System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                      }\n                      toDeleteIDs.add(doc.get(\"docid\"));\n                    }\n                  }\n                } else {\n                  // we use update but it never replaces a\n                  // prior doc\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": update doc id:\" + doc.get(\"docid\"));\n                  }\n                  gen = nrt.updateDocument(new Term(\"docid\", doc.get(\"docid\")), doc);\n                  addCount.getAndIncrement();\n\n                  // randomly verify the add \"took\":\n                  if (random.nextInt(20) == 2) {\n                    final IndexSearcher s = nrt.get(gen, true);\n                    try {\n                      assertEquals(1, s.search(new TermQuery(new Term(\"docid\", doc.get(\"docid\"))), 10).totalHits);\n                    } finally {\n                      nrt.release(s);\n                    }\n                  }\n\n                  if (random.nextInt(5) == 3) {\n                    if (VERBOSE) {\n                      System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                    }\n                    toDeleteIDs.add(doc.get(\"docid\"));\n                  }\n                }\n\n                if (random.nextInt(30) == 17) {\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": apply \" + toDeleteIDs.size() + \" deletes\");\n                  }\n                  for(String id : toDeleteIDs) {\n                    if (VERBOSE) {\n                      System.out.println(Thread.currentThread().getName() + \": del term=id:\" + id);\n                    }\n                    gen = nrt.deleteDocuments(new Term(\"docid\", id));\n\n                    // randomly verify the delete \"took\":\n                    if (random.nextInt(20) == 7) {\n                      final IndexSearcher s = nrt.get(gen, true);\n                      try {\n                        assertEquals(0, s.search(new TermQuery(new Term(\"docid\", id)), 10).totalHits);\n                      } finally {\n                        nrt.release(s);\n                      }\n                    }\n                  }\n\n                  final int count = delCount.addAndGet(toDeleteIDs.size());\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": tot \" + count + \" deletes\");\n                  }\n                  delIDs.addAll(toDeleteIDs);\n                  toDeleteIDs.clear();\n\n                  for(SubDocs subDocs : toDeleteSubDocs) {\n                    assertTrue(!subDocs.deleted);\n                    gen = nrt.deleteDocuments(new Term(\"packID\", subDocs.packID));\n                    subDocs.deleted = true;\n                    if (VERBOSE) {\n                      System.out.println(\"  del subs: \" + subDocs.subIDs + \" packID=\" + subDocs.packID);\n                    }\n                    delIDs.addAll(subDocs.subIDs);\n                    delCount.addAndGet(subDocs.subIDs.size());\n\n                    // randomly verify the delete \"took\":\n                    if (random.nextInt(20) == 7) {\n                      final IndexSearcher s = nrt.get(gen, true);\n                      try {\n                        assertEquals(0, s.search(new TermQuery(new Term(\"packID\", subDocs.packID)), 1).totalHits);\n                      } finally {\n                        nrt.release(s);\n                      }\n                    }\n                  }\n                  toDeleteSubDocs.clear();\n                }\n                if (addedField != null) {\n                  doc.removeField(addedField);\n                }\n              } catch (Throwable t) {\n                System.out.println(Thread.currentThread().getName() + \": FAILED: hit exc\");\n                t.printStackTrace();\n                failed.set(true);\n                throw new RuntimeException(t);\n              }\n            }\n\n            lastGens.add(gen);\n            if (VERBOSE) {\n              System.out.println(Thread.currentThread().getName() + \": indexing done\");\n            }\n          }\n        };\n      threads[thread].setDaemon(true);\n      threads[thread].start();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: DONE start indexing threads [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    // let index build up a bit\n    Thread.sleep(100);\n\n    // silly starting guess:\n    final AtomicInteger totTermCount = new AtomicInteger(100);\n\n    // run search threads\n    final Thread[] searchThreads = new Thread[NUM_SEARCH_THREADS];\n    final AtomicInteger totHits = new AtomicInteger();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: start search threads\");\n    }\n\n    for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n      searchThreads[thread] = new Thread() {\n          @Override\n          public void run() {\n            while(System.currentTimeMillis() < stopTime && !failed.get()) {\n              final IndexSearcher s = nrt.get(random.nextBoolean());\n              try {\n                try {\n                  smokeTestSearcher(s);\n                  if (s.getIndexReader().numDocs() > 0) {\n                    Fields fields = MultiFields.getFields(s.getIndexReader());\n                    if (fields == null) {\n                      continue;\n                    }\n                    Terms terms = fields.terms(\"body\");\n                    if (terms == null) {\n                      continue;\n                    }\n\n                    TermsEnum termsEnum = terms.iterator();\n                    int seenTermCount = 0;\n                    int shift;\n                    int trigger;\n                    if (totTermCount.get() < 10) {\n                      shift = 0;\n                      trigger = 1;\n                    } else {\n                      trigger = totTermCount.get()/10;\n                      shift = random.nextInt(trigger);\n                    }\n\n                    while(System.currentTimeMillis() < stopTime) {\n                      BytesRef term = termsEnum.next();\n                      if (term == null) {\n                        if (seenTermCount == 0) {\n                          break;\n                        }\n                        totTermCount.set(seenTermCount);\n                        seenTermCount = 0;\n                        if (totTermCount.get() < 10) {\n                          shift = 0;\n                          trigger = 1;\n                        } else {\n                          trigger = totTermCount.get()/10;\n                          //System.out.println(\"trigger \" + trigger);\n                          shift = random.nextInt(trigger);\n                        }\n                        termsEnum.seek(new BytesRef(\"\"));\n                        continue;\n                      }\n                      seenTermCount++;\n                      // search 10 terms\n                      if (trigger == 0) {\n                        trigger = 1;\n                      }\n                      if ((seenTermCount + shift) % trigger == 0) {\n                        //if (VERBOSE) {\n                        //System.out.println(Thread.currentThread().getName() + \" now search body:\" + term.utf8ToString());\n                        //}\n                        totHits.addAndGet(runQuery(s, new TermQuery(new Term(\"body\", term))));\n                      }\n                    }\n                    if (VERBOSE) {\n                      System.out.println(Thread.currentThread().getName() + \": search done\");\n                    }\n                  }\n                } finally {\n                  nrt.release(s);\n                }\n              } catch (Throwable t) {\n                System.out.println(Thread.currentThread().getName() + \": FAILED: hit exc\");\n                failed.set(true);\n                t.printStackTrace(System.out);\n                throw new RuntimeException(t);\n              }\n            }\n          }\n        };\n      searchThreads[thread].setDaemon(true);\n      searchThreads[thread].start();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now join\");\n    }\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread].join();\n    }\n    for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n      searchThreads[thread].join();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: done join [\" + (System.currentTimeMillis()-t0) + \" ms]; addCount=\" + addCount + \" delCount=\" + delCount);\n      System.out.println(\"TEST: search totHits=\" + totHits);\n    }\n\n    long maxGen = 0;\n    for(long gen : lastGens) {\n      maxGen = Math.max(maxGen, gen);\n    }\n\n    final IndexSearcher s = nrt.get(maxGen, true);\n\n    boolean doFail = false;\n    for(String id : delIDs) {\n      final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", id)), 1);\n      if (hits.totalHits != 0) {\n        System.out.println(\"doc id=\" + id + \" is supposed to be deleted, but got docID=\" + hits.scoreDocs[0].doc);\n        doFail = true;\n      }\n    }\n\n    // Make sure each group of sub-docs are still in docID order:\n    for(SubDocs subDocs : allSubDocs) {\n      if (!subDocs.deleted) {\n        // We sort by relevance but the scores should be identical so sort falls back to by docID:\n        TopDocs hits = s.search(new TermQuery(new Term(\"packID\", subDocs.packID)), 20);\n        assertEquals(subDocs.subIDs.size(), hits.totalHits);\n        int lastDocID = -1;\n        int startDocID = -1;\n        for(ScoreDoc scoreDoc : hits.scoreDocs) {\n          final int docID = scoreDoc.doc;\n          if (lastDocID != -1) {\n            assertEquals(1+lastDocID, docID);\n          } else {\n            startDocID = docID;\n          }\n          lastDocID = docID;\n          final Document doc = s.doc(docID);\n          assertEquals(subDocs.packID, doc.get(\"packID\"));\n        }\n\n        lastDocID = startDocID - 1;\n        for(String subID : subDocs.subIDs) {\n          hits = s.search(new TermQuery(new Term(\"docid\", subID)), 1);\n          assertEquals(1, hits.totalHits);\n          final int docID = hits.scoreDocs[0].doc;\n          if (lastDocID != -1) {\n            assertEquals(1+lastDocID, docID);\n          }\n          lastDocID = docID;\n        }          \n      } else {\n        for(String subID : subDocs.subIDs) {\n          assertEquals(0, s.search(new TermQuery(new Term(\"docid\", subID)), 1).totalHits);\n        }\n      }\n    }\n    \n    final int endID = Integer.parseInt(docs.nextDoc().get(\"docid\"));\n    for(int id=0;id<endID;id++) {\n      String stringID = \"\"+id;\n      if (!delIDs.contains(stringID)) {\n        final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", stringID)), 1);\n        if (hits.totalHits != 1) {\n          System.out.println(\"doc id=\" + stringID + \" is not supposed to be deleted, but got hitCount=\" + hits.totalHits);\n          doFail = true;\n        }\n      }\n    }\n    assertFalse(doFail);\n\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), s.getIndexReader().numDocs());\n    nrt.release(s);\n\n    if (es != null) {\n      es.shutdown();\n      es.awaitTermination(1, TimeUnit.SECONDS);\n    }\n\n    writer.commit();\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), writer.numDocs());\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now close NRTManager\");\n    }\n    nrtThread.close();\n    nrt.close();\n    assertFalse(writer.anyNonBulkMerges);\n    writer.close(false);\n    _TestUtil.checkIndex(dir);\n    dir.close();\n    _TestUtil.rmDir(tempDir);\n    docs.close();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a40a638d82918f2d8a40500c22745ec76b1aac5d","date":1309097847,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/contrib/misc/src/test/org/apache/lucene/index/TestNRTManager#testNRTManager().mjava","pathOld":"lucene/contrib/misc/src/test/org/apache/lucene/index/TestNRTManager#testNRTManager().mjava","sourceNew":"  @Test\n  public void testNRTManager() throws Exception {\n\n    final long t0 = System.currentTimeMillis();\n\n    if (CodecProvider.getDefault().getDefaultFieldCodec().equals(\"SimpleText\")) {\n      // no\n      CodecProvider.getDefault().setDefaultFieldCodec(\"Standard\");\n    }\n\n    final LineFileDocs docs = new LineFileDocs(random);\n    final File tempDir = _TestUtil.getTempDir(\"nrtopenfiles\");\n    final MockDirectoryWrapper _dir = newFSDirectory(tempDir);\n    _dir.setCheckIndexOnClose(false);  // don't double-checkIndex, we do it ourselves\n    Directory dir = _dir;\n    final IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).setOpenMode(IndexWriterConfig.OpenMode.CREATE);\n\n    if (LuceneTestCase.TEST_NIGHTLY) {\n      // newIWConfig makes smallish max seg size, which\n      // results in tons and tons of segments for this test\n      // when run nightly:\n      MergePolicy mp = conf.getMergePolicy();\n      if (mp instanceof TieredMergePolicy) {\n        ((TieredMergePolicy) mp).setMaxMergedSegmentMB(5000.);\n      } else if (mp instanceof LogByteSizeMergePolicy) {\n        ((LogByteSizeMergePolicy) mp).setMaxMergeMB(1000.);\n      } else if (mp instanceof LogMergePolicy) {\n        ((LogMergePolicy) mp).setMaxMergeDocs(100000);\n      }\n    }\n\n    conf.setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n      @Override\n      public void warm(IndexReader reader) throws IOException {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now warm merged reader=\" + reader);\n        }\n        final int maxDoc = reader.maxDoc();\n        final Bits delDocs = reader.getDeletedDocs();\n        int sum = 0;\n        final int inc = Math.max(1, maxDoc/50);\n        for(int docID=0;docID<maxDoc;docID += inc) {\n          if (delDocs == null || !delDocs.get(docID)) {\n            final Document doc = reader.document(docID);\n            sum += doc.getFields().size();\n          }\n        }\n\n        IndexSearcher searcher = newSearcher(reader);\n        sum += searcher.search(new TermQuery(new Term(\"body\", \"united\")), 10).totalHits;\n        searcher.close();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: warm visited \" + sum + \" fields\");\n        }\n      }\n      });\n\n    if (random.nextBoolean()) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: wrap NRTCachingDir\");\n      }\n\n      dir = new NRTCachingDirectory(dir, 5.0, 60.0);\n    }\n    \n    final IndexWriter writer = new IndexWriter(dir, conf);\n    \n    if (VERBOSE) {\n      writer.setInfoStream(System.out);\n    }\n    _TestUtil.reduceOpenFiles(writer);\n    //System.out.println(\"TEST: conf=\" + writer.getConfig());\n\n    final ExecutorService es = random.nextBoolean() ? null : Executors.newCachedThreadPool(new NamedThreadFactory(\"NRT search threads\"));\n\n    final double minReopenSec = 0.01 + 0.05 * random.nextDouble();\n    final double maxReopenSec = minReopenSec * (1.0 + 10 * random.nextDouble());\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: make NRTManager maxReopenSec=\" + maxReopenSec + \" minReopenSec=\" + minReopenSec);\n    }\n\n    final NRTManager nrt = new NRTManager(writer, es);\n    final NRTManagerReopenThread nrtThread = new NRTManagerReopenThread(nrt, maxReopenSec, minReopenSec);\n    nrtThread.setName(\"NRT Reopen Thread\");\n    nrtThread.setPriority(Math.min(Thread.currentThread().getPriority()+2, Thread.MAX_PRIORITY));\n    nrtThread.setDaemon(true);\n    nrtThread.start();\n\n    final int NUM_INDEX_THREADS = _TestUtil.nextInt(random, 1, 3);\n    final int NUM_SEARCH_THREADS = _TestUtil.nextInt(random, 1, 3);\n    //final int NUM_INDEX_THREADS = 1;\n    //final int NUM_SEARCH_THREADS = 1;\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + NUM_INDEX_THREADS + \" index threads; \" + NUM_SEARCH_THREADS + \" search threads\");\n    }\n\n    final int RUN_TIME_SEC = LuceneTestCase.TEST_NIGHTLY ? 300 : RANDOM_MULTIPLIER;\n\n    final AtomicBoolean failed = new AtomicBoolean();\n    final AtomicInteger addCount = new AtomicInteger();\n    final AtomicInteger delCount = new AtomicInteger();\n    final AtomicInteger packCount = new AtomicInteger();\n    final List<Long> lastGens = new ArrayList<Long>();\n\n    final Set<String> delIDs = Collections.synchronizedSet(new HashSet<String>());\n    final List<SubDocs> allSubDocs = Collections.synchronizedList(new ArrayList<SubDocs>());\n\n    final long stopTime = System.currentTimeMillis() + RUN_TIME_SEC*1000;\n    Thread[] threads = new Thread[NUM_INDEX_THREADS];\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread] = new Thread() {\n          @Override\n          public void run() {\n            // TODO: would be better if this were cross thread, so that we make sure one thread deleting anothers added docs works:\n            final List<String> toDeleteIDs = new ArrayList<String>();\n            final List<SubDocs> toDeleteSubDocs = new ArrayList<SubDocs>();\n\n            long gen = 0;\n            while(System.currentTimeMillis() < stopTime && !failed.get()) {\n\n              //System.out.println(Thread.currentThread().getName() + \": cycle\");\n              try {\n                // Occassional longish pause if running\n                // nightly\n                if (LuceneTestCase.TEST_NIGHTLY && random.nextInt(6) == 3) {\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": now long sleep\");\n                  }\n                  Thread.sleep(_TestUtil.nextInt(random, 50, 500));\n                }\n\n                // Rate limit ingest rate:\n                Thread.sleep(_TestUtil.nextInt(random, 1, 10));\n                if (VERBOSE) {\n                  System.out.println(Thread.currentThread() + \": done sleep\");\n                }\n\n                Document doc = docs.nextDoc();\n                if (doc == null) {\n                  break;\n                }\n                final String addedField;\n                if (random.nextBoolean()) {\n                  addedField = \"extra\" + random.nextInt(10);\n                  doc.add(new Field(addedField, \"a random field\", Field.Store.NO, Field.Index.ANALYZED));\n                } else {\n                  addedField = null;\n                }\n                if (random.nextBoolean()) {\n\n                  if (random.nextBoolean()) {\n                    // Add a pack of adjacent sub-docs\n                    final String packID;\n                    final SubDocs delSubDocs;\n                    if (toDeleteSubDocs.size() > 0 && random.nextBoolean()) {\n                      delSubDocs = toDeleteSubDocs.get(random.nextInt(toDeleteSubDocs.size()));\n                      assert !delSubDocs.deleted;\n                      toDeleteSubDocs.remove(delSubDocs);\n                      // reuse prior packID\n                      packID = delSubDocs.packID;\n                    } else {\n                      delSubDocs = null;\n                      // make new packID\n                      packID = packCount.getAndIncrement() + \"\";\n                    }\n\n                    final Field packIDField = newField(\"packID\", packID, Field.Store.YES, Field.Index.NOT_ANALYZED);\n                    final List<String> docIDs = new ArrayList<String>();\n                    final SubDocs subDocs = new SubDocs(packID, docIDs);\n                    final List<Document> docsList = new ArrayList<Document>();\n\n                    allSubDocs.add(subDocs);\n                    doc.add(packIDField);\n                    docsList.add(cloneDoc(doc));\n                    docIDs.add(doc.get(\"docid\"));\n\n                    final int maxDocCount = _TestUtil.nextInt(random, 1, 10);\n                    while(docsList.size() < maxDocCount) {\n                      doc = docs.nextDoc();\n                      if (doc == null) {\n                        break;\n                      }\n                      docsList.add(cloneDoc(doc));\n                      docIDs.add(doc.get(\"docid\"));\n                    }\n                    addCount.addAndGet(docsList.size());\n\n                    if (delSubDocs != null) {\n                      delSubDocs.deleted = true;\n                      delIDs.addAll(delSubDocs.subIDs);\n                      delCount.addAndGet(delSubDocs.subIDs.size());\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: update pack packID=\" + delSubDocs.packID + \" count=\" + docsList.size() + \" docs=\" + docIDs);\n                      }\n                      gen = nrt.updateDocuments(new Term(\"packID\", delSubDocs.packID), docsList);\n                      /*\n                      // non-atomic:\n                      nrt.deleteDocuments(new Term(\"packID\", delSubDocs.packID));\n                      for(Document subDoc : docsList) {\n                        nrt.addDocument(subDoc);\n                      }\n                      */\n                    } else {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: add pack packID=\" + packID + \" count=\" + docsList.size() + \" docs=\" + docIDs);\n                      }\n                      gen = nrt.addDocuments(docsList);\n                      \n                      /*\n                      // non-atomic:\n                      for(Document subDoc : docsList) {\n                        nrt.addDocument(subDoc);\n                      }\n                      */\n                    }\n                    doc.removeField(\"packID\");\n\n                    if (random.nextInt(5) == 2) {\n                      if (VERBOSE) {\n                        System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + packID);\n                      }\n                      toDeleteSubDocs.add(subDocs);\n                    }\n\n                    // randomly verify the add/update \"took\":\n                    if (random.nextInt(20) == 2) {\n                      final boolean applyDeletes = delSubDocs != null;\n                      final IndexSearcher s = nrt.get(gen, applyDeletes);\n                      try {\n                        assertEquals(docsList.size(), s.search(new TermQuery(new Term(\"packID\", packID)), 10).totalHits);\n                      } finally {\n                        nrt.release(s);\n                      }\n                    }\n\n                  } else {\n                    if (VERBOSE) {\n                      System.out.println(Thread.currentThread().getName() + \": add doc docid:\" + doc.get(\"docid\"));\n                    }\n\n                    gen = nrt.addDocument(doc);\n                    addCount.getAndIncrement();\n\n                    // randomly verify the add \"took\":\n                    if (random.nextInt(20) == 2) {\n                      //System.out.println(Thread.currentThread().getName() + \": verify\");\n                      final IndexSearcher s = nrt.get(gen, false);\n                      //System.out.println(Thread.currentThread().getName() + \": got s=\" + s);\n                      try {\n                        assertEquals(1, s.search(new TermQuery(new Term(\"docid\", doc.get(\"docid\"))), 10).totalHits);\n                      } finally {\n                        nrt.release(s);\n                      }\n                      //System.out.println(Thread.currentThread().getName() + \": done verify\");\n                    }\n\n                    if (random.nextInt(5) == 3) {\n                      if (VERBOSE) {\n                        System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                      }\n                      toDeleteIDs.add(doc.get(\"docid\"));\n                    }\n                  }\n                } else {\n                  // we use update but it never replaces a\n                  // prior doc\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": update doc id:\" + doc.get(\"docid\"));\n                  }\n                  gen = nrt.updateDocument(new Term(\"docid\", doc.get(\"docid\")), doc);\n                  addCount.getAndIncrement();\n\n                  // randomly verify the add \"took\":\n                  if (random.nextInt(20) == 2) {\n                    final IndexSearcher s = nrt.get(gen, true);\n                    try {\n                      assertEquals(1, s.search(new TermQuery(new Term(\"docid\", doc.get(\"docid\"))), 10).totalHits);\n                    } finally {\n                      nrt.release(s);\n                    }\n                  }\n\n                  if (random.nextInt(5) == 3) {\n                    if (VERBOSE) {\n                      System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                    }\n                    toDeleteIDs.add(doc.get(\"docid\"));\n                  }\n                }\n\n                if (random.nextInt(30) == 17) {\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": apply \" + toDeleteIDs.size() + \" deletes\");\n                  }\n                  for(String id : toDeleteIDs) {\n                    if (VERBOSE) {\n                      System.out.println(Thread.currentThread().getName() + \": del term=id:\" + id);\n                    }\n                    gen = nrt.deleteDocuments(new Term(\"docid\", id));\n\n                    // randomly verify the delete \"took\":\n                    if (random.nextInt(20) == 7) {\n                      final IndexSearcher s = nrt.get(gen, true);\n                      try {\n                        assertEquals(0, s.search(new TermQuery(new Term(\"docid\", id)), 10).totalHits);\n                      } finally {\n                        nrt.release(s);\n                      }\n                    }\n                  }\n\n                  final int count = delCount.addAndGet(toDeleteIDs.size());\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": tot \" + count + \" deletes\");\n                  }\n                  delIDs.addAll(toDeleteIDs);\n                  toDeleteIDs.clear();\n\n                  for(SubDocs subDocs : toDeleteSubDocs) {\n                    assertTrue(!subDocs.deleted);\n                    gen = nrt.deleteDocuments(new Term(\"packID\", subDocs.packID));\n                    subDocs.deleted = true;\n                    if (VERBOSE) {\n                      System.out.println(\"  del subs: \" + subDocs.subIDs + \" packID=\" + subDocs.packID);\n                    }\n                    delIDs.addAll(subDocs.subIDs);\n                    delCount.addAndGet(subDocs.subIDs.size());\n\n                    // randomly verify the delete \"took\":\n                    if (random.nextInt(20) == 7) {\n                      final IndexSearcher s = nrt.get(gen, true);\n                      try {\n                        assertEquals(0, s.search(new TermQuery(new Term(\"packID\", subDocs.packID)), 1).totalHits);\n                      } finally {\n                        nrt.release(s);\n                      }\n                    }\n                  }\n                  toDeleteSubDocs.clear();\n                }\n                if (addedField != null) {\n                  doc.removeField(addedField);\n                }\n              } catch (Throwable t) {\n                System.out.println(Thread.currentThread().getName() + \": FAILED: hit exc\");\n                t.printStackTrace();\n                failed.set(true);\n                throw new RuntimeException(t);\n              }\n            }\n\n            lastGens.add(gen);\n            if (VERBOSE) {\n              System.out.println(Thread.currentThread().getName() + \": indexing done\");\n            }\n          }\n        };\n      threads[thread].setDaemon(true);\n      threads[thread].start();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: DONE start indexing threads [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    // let index build up a bit\n    Thread.sleep(100);\n\n    // silly starting guess:\n    final AtomicInteger totTermCount = new AtomicInteger(100);\n\n    // run search threads\n    final Thread[] searchThreads = new Thread[NUM_SEARCH_THREADS];\n    final AtomicInteger totHits = new AtomicInteger();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: start search threads\");\n    }\n\n    for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n      searchThreads[thread] = new Thread() {\n          @Override\n          public void run() {\n            while(System.currentTimeMillis() < stopTime && !failed.get()) {\n              final IndexSearcher s = nrt.get(random.nextBoolean());\n              try {\n                try {\n                  smokeTestSearcher(s);\n                  if (s.getIndexReader().numDocs() > 0) {\n                    Fields fields = MultiFields.getFields(s.getIndexReader());\n                    if (fields == null) {\n                      continue;\n                    }\n                    Terms terms = fields.terms(\"body\");\n                    if (terms == null) {\n                      continue;\n                    }\n\n                    TermsEnum termsEnum = terms.iterator();\n                    int seenTermCount = 0;\n                    int shift;\n                    int trigger;\n                    if (totTermCount.get() < 10) {\n                      shift = 0;\n                      trigger = 1;\n                    } else {\n                      trigger = totTermCount.get()/10;\n                      shift = random.nextInt(trigger);\n                    }\n\n                    while(System.currentTimeMillis() < stopTime) {\n                      BytesRef term = termsEnum.next();\n                      if (term == null) {\n                        if (seenTermCount == 0) {\n                          break;\n                        }\n                        totTermCount.set(seenTermCount);\n                        seenTermCount = 0;\n                        if (totTermCount.get() < 10) {\n                          shift = 0;\n                          trigger = 1;\n                        } else {\n                          trigger = totTermCount.get()/10;\n                          //System.out.println(\"trigger \" + trigger);\n                          shift = random.nextInt(trigger);\n                        }\n                        termsEnum.seek(new BytesRef(\"\"));\n                        continue;\n                      }\n                      seenTermCount++;\n                      // search 10 terms\n                      if (trigger == 0) {\n                        trigger = 1;\n                      }\n                      if ((seenTermCount + shift) % trigger == 0) {\n                        //if (VERBOSE) {\n                        //System.out.println(Thread.currentThread().getName() + \" now search body:\" + term.utf8ToString());\n                        //}\n                        totHits.addAndGet(runQuery(s, new TermQuery(new Term(\"body\", term))));\n                      }\n                    }\n                    if (VERBOSE) {\n                      System.out.println(Thread.currentThread().getName() + \": search done\");\n                    }\n                  }\n                } finally {\n                  nrt.release(s);\n                }\n              } catch (Throwable t) {\n                System.out.println(Thread.currentThread().getName() + \": FAILED: hit exc\");\n                failed.set(true);\n                t.printStackTrace(System.out);\n                throw new RuntimeException(t);\n              }\n            }\n          }\n        };\n      searchThreads[thread].setDaemon(true);\n      searchThreads[thread].start();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now join\");\n    }\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread].join();\n    }\n    for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n      searchThreads[thread].join();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: done join [\" + (System.currentTimeMillis()-t0) + \" ms]; addCount=\" + addCount + \" delCount=\" + delCount);\n      System.out.println(\"TEST: search totHits=\" + totHits);\n    }\n\n    long maxGen = 0;\n    for(long gen : lastGens) {\n      maxGen = Math.max(maxGen, gen);\n    }\n\n    final IndexSearcher s = nrt.get(maxGen, true);\n\n    boolean doFail = false;\n    for(String id : delIDs) {\n      final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", id)), 1);\n      if (hits.totalHits != 0) {\n        System.out.println(\"doc id=\" + id + \" is supposed to be deleted, but got docID=\" + hits.scoreDocs[0].doc);\n        doFail = true;\n      }\n    }\n\n    // Make sure each group of sub-docs are still in docID order:\n    for(SubDocs subDocs : allSubDocs) {\n      if (!subDocs.deleted) {\n        // We sort by relevance but the scores should be identical so sort falls back to by docID:\n        TopDocs hits = s.search(new TermQuery(new Term(\"packID\", subDocs.packID)), 20);\n        assertEquals(subDocs.subIDs.size(), hits.totalHits);\n        int lastDocID = -1;\n        int startDocID = -1;\n        for(ScoreDoc scoreDoc : hits.scoreDocs) {\n          final int docID = scoreDoc.doc;\n          if (lastDocID != -1) {\n            assertEquals(1+lastDocID, docID);\n          } else {\n            startDocID = docID;\n          }\n          lastDocID = docID;\n          final Document doc = s.doc(docID);\n          assertEquals(subDocs.packID, doc.get(\"packID\"));\n        }\n\n        lastDocID = startDocID - 1;\n        for(String subID : subDocs.subIDs) {\n          hits = s.search(new TermQuery(new Term(\"docid\", subID)), 1);\n          assertEquals(1, hits.totalHits);\n          final int docID = hits.scoreDocs[0].doc;\n          if (lastDocID != -1) {\n            assertEquals(1+lastDocID, docID);\n          }\n          lastDocID = docID;\n        }          \n      } else {\n        for(String subID : subDocs.subIDs) {\n          assertEquals(0, s.search(new TermQuery(new Term(\"docid\", subID)), 1).totalHits);\n        }\n      }\n    }\n    \n    final int endID = Integer.parseInt(docs.nextDoc().get(\"docid\"));\n    for(int id=0;id<endID;id++) {\n      String stringID = \"\"+id;\n      if (!delIDs.contains(stringID)) {\n        final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", stringID)), 1);\n        if (hits.totalHits != 1) {\n          System.out.println(\"doc id=\" + stringID + \" is not supposed to be deleted, but got hitCount=\" + hits.totalHits);\n          doFail = true;\n        }\n      }\n    }\n    assertFalse(doFail);\n\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), s.getIndexReader().numDocs());\n    nrt.release(s);\n\n    if (es != null) {\n      es.shutdown();\n      es.awaitTermination(1, TimeUnit.SECONDS);\n    }\n\n    writer.commit();\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), writer.numDocs());\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now close NRTManager\");\n    }\n    nrtThread.close();\n    nrt.close();\n    assertFalse(writer.anyNonBulkMerges);\n    writer.close(false);\n    _TestUtil.checkIndex(dir);\n    dir.close();\n    _TestUtil.rmDir(tempDir);\n    docs.close();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testNRTManager() throws Exception {\n\n    final long t0 = System.currentTimeMillis();\n\n    if (CodecProvider.getDefault().getDefaultFieldCodec().equals(\"SimpleText\")) {\n      // no\n      CodecProvider.getDefault().setDefaultFieldCodec(\"Standard\");\n    }\n\n    final LineFileDocs docs = new LineFileDocs(random);\n    final File tempDir = _TestUtil.getTempDir(\"nrtopenfiles\");\n    final MockDirectoryWrapper _dir = newFSDirectory(tempDir);\n    _dir.setCheckIndexOnClose(false);  // don't double-checkIndex, we do it ourselves\n    Directory dir = _dir;\n    final IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).setOpenMode(IndexWriterConfig.OpenMode.CREATE);\n\n    if (LuceneTestCase.TEST_NIGHTLY) {\n      // newIWConfig makes smallish max seg size, which\n      // results in tons and tons of segments for this test\n      // when run nightly:\n      MergePolicy mp = conf.getMergePolicy();\n      if (mp instanceof TieredMergePolicy) {\n        ((TieredMergePolicy) mp).setMaxMergedSegmentMB(5000.);\n      } else if (mp instanceof LogByteSizeMergePolicy) {\n        ((LogByteSizeMergePolicy) mp).setMaxMergeMB(1000.);\n      } else if (mp instanceof LogMergePolicy) {\n        ((LogMergePolicy) mp).setMaxMergeDocs(100000);\n      }\n    }\n\n    conf.setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n      @Override\n      public void warm(IndexReader reader) throws IOException {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now warm merged reader=\" + reader);\n        }\n        final int maxDoc = reader.maxDoc();\n        final Bits delDocs = reader.getDeletedDocs();\n        int sum = 0;\n        final int inc = Math.max(1, maxDoc/50);\n        for(int docID=0;docID<maxDoc;docID += inc) {\n          if (delDocs == null || !delDocs.get(docID)) {\n            final Document doc = reader.document(docID);\n            sum += doc.getFields().size();\n          }\n        }\n\n        IndexSearcher searcher = newSearcher(reader);\n        sum += searcher.search(new TermQuery(new Term(\"body\", \"united\")), 10).totalHits;\n        searcher.close();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: warm visited \" + sum + \" fields\");\n        }\n      }\n      });\n\n    if (random.nextBoolean()) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: wrap NRTCachingDir\");\n      }\n\n      NRTCachingDirectory nrtDir = new NRTCachingDirectory(dir, 5.0, 60.0);\n      conf.setMergeScheduler(nrtDir.getMergeScheduler());\n      dir = nrtDir;\n    }\n    \n    final IndexWriter writer = new IndexWriter(dir, conf);\n    \n    if (VERBOSE) {\n      writer.setInfoStream(System.out);\n    }\n    _TestUtil.reduceOpenFiles(writer);\n    //System.out.println(\"TEST: conf=\" + writer.getConfig());\n\n    final ExecutorService es = random.nextBoolean() ? null : Executors.newCachedThreadPool(new NamedThreadFactory(\"NRT search threads\"));\n\n    final double minReopenSec = 0.01 + 0.05 * random.nextDouble();\n    final double maxReopenSec = minReopenSec * (1.0 + 10 * random.nextDouble());\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: make NRTManager maxReopenSec=\" + maxReopenSec + \" minReopenSec=\" + minReopenSec);\n    }\n\n    final NRTManager nrt = new NRTManager(writer, es);\n    final NRTManagerReopenThread nrtThread = new NRTManagerReopenThread(nrt, maxReopenSec, minReopenSec);\n    nrtThread.setName(\"NRT Reopen Thread\");\n    nrtThread.setPriority(Math.min(Thread.currentThread().getPriority()+2, Thread.MAX_PRIORITY));\n    nrtThread.setDaemon(true);\n    nrtThread.start();\n\n    final int NUM_INDEX_THREADS = _TestUtil.nextInt(random, 1, 3);\n    final int NUM_SEARCH_THREADS = _TestUtil.nextInt(random, 1, 3);\n    //final int NUM_INDEX_THREADS = 1;\n    //final int NUM_SEARCH_THREADS = 1;\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + NUM_INDEX_THREADS + \" index threads; \" + NUM_SEARCH_THREADS + \" search threads\");\n    }\n\n    final int RUN_TIME_SEC = LuceneTestCase.TEST_NIGHTLY ? 300 : RANDOM_MULTIPLIER;\n\n    final AtomicBoolean failed = new AtomicBoolean();\n    final AtomicInteger addCount = new AtomicInteger();\n    final AtomicInteger delCount = new AtomicInteger();\n    final AtomicInteger packCount = new AtomicInteger();\n    final List<Long> lastGens = new ArrayList<Long>();\n\n    final Set<String> delIDs = Collections.synchronizedSet(new HashSet<String>());\n    final List<SubDocs> allSubDocs = Collections.synchronizedList(new ArrayList<SubDocs>());\n\n    final long stopTime = System.currentTimeMillis() + RUN_TIME_SEC*1000;\n    Thread[] threads = new Thread[NUM_INDEX_THREADS];\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread] = new Thread() {\n          @Override\n          public void run() {\n            // TODO: would be better if this were cross thread, so that we make sure one thread deleting anothers added docs works:\n            final List<String> toDeleteIDs = new ArrayList<String>();\n            final List<SubDocs> toDeleteSubDocs = new ArrayList<SubDocs>();\n\n            long gen = 0;\n            while(System.currentTimeMillis() < stopTime && !failed.get()) {\n\n              //System.out.println(Thread.currentThread().getName() + \": cycle\");\n              try {\n                // Occassional longish pause if running\n                // nightly\n                if (LuceneTestCase.TEST_NIGHTLY && random.nextInt(6) == 3) {\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": now long sleep\");\n                  }\n                  Thread.sleep(_TestUtil.nextInt(random, 50, 500));\n                }\n\n                // Rate limit ingest rate:\n                Thread.sleep(_TestUtil.nextInt(random, 1, 10));\n                if (VERBOSE) {\n                  System.out.println(Thread.currentThread() + \": done sleep\");\n                }\n\n                Document doc = docs.nextDoc();\n                if (doc == null) {\n                  break;\n                }\n                final String addedField;\n                if (random.nextBoolean()) {\n                  addedField = \"extra\" + random.nextInt(10);\n                  doc.add(new Field(addedField, \"a random field\", Field.Store.NO, Field.Index.ANALYZED));\n                } else {\n                  addedField = null;\n                }\n                if (random.nextBoolean()) {\n\n                  if (random.nextBoolean()) {\n                    // Add a pack of adjacent sub-docs\n                    final String packID;\n                    final SubDocs delSubDocs;\n                    if (toDeleteSubDocs.size() > 0 && random.nextBoolean()) {\n                      delSubDocs = toDeleteSubDocs.get(random.nextInt(toDeleteSubDocs.size()));\n                      assert !delSubDocs.deleted;\n                      toDeleteSubDocs.remove(delSubDocs);\n                      // reuse prior packID\n                      packID = delSubDocs.packID;\n                    } else {\n                      delSubDocs = null;\n                      // make new packID\n                      packID = packCount.getAndIncrement() + \"\";\n                    }\n\n                    final Field packIDField = newField(\"packID\", packID, Field.Store.YES, Field.Index.NOT_ANALYZED);\n                    final List<String> docIDs = new ArrayList<String>();\n                    final SubDocs subDocs = new SubDocs(packID, docIDs);\n                    final List<Document> docsList = new ArrayList<Document>();\n\n                    allSubDocs.add(subDocs);\n                    doc.add(packIDField);\n                    docsList.add(cloneDoc(doc));\n                    docIDs.add(doc.get(\"docid\"));\n\n                    final int maxDocCount = _TestUtil.nextInt(random, 1, 10);\n                    while(docsList.size() < maxDocCount) {\n                      doc = docs.nextDoc();\n                      if (doc == null) {\n                        break;\n                      }\n                      docsList.add(cloneDoc(doc));\n                      docIDs.add(doc.get(\"docid\"));\n                    }\n                    addCount.addAndGet(docsList.size());\n\n                    if (delSubDocs != null) {\n                      delSubDocs.deleted = true;\n                      delIDs.addAll(delSubDocs.subIDs);\n                      delCount.addAndGet(delSubDocs.subIDs.size());\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: update pack packID=\" + delSubDocs.packID + \" count=\" + docsList.size() + \" docs=\" + docIDs);\n                      }\n                      gen = nrt.updateDocuments(new Term(\"packID\", delSubDocs.packID), docsList);\n                      /*\n                      // non-atomic:\n                      nrt.deleteDocuments(new Term(\"packID\", delSubDocs.packID));\n                      for(Document subDoc : docsList) {\n                        nrt.addDocument(subDoc);\n                      }\n                      */\n                    } else {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: add pack packID=\" + packID + \" count=\" + docsList.size() + \" docs=\" + docIDs);\n                      }\n                      gen = nrt.addDocuments(docsList);\n                      \n                      /*\n                      // non-atomic:\n                      for(Document subDoc : docsList) {\n                        nrt.addDocument(subDoc);\n                      }\n                      */\n                    }\n                    doc.removeField(\"packID\");\n\n                    if (random.nextInt(5) == 2) {\n                      if (VERBOSE) {\n                        System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + packID);\n                      }\n                      toDeleteSubDocs.add(subDocs);\n                    }\n\n                    // randomly verify the add/update \"took\":\n                    if (random.nextInt(20) == 2) {\n                      final boolean applyDeletes = delSubDocs != null;\n                      final IndexSearcher s = nrt.get(gen, applyDeletes);\n                      try {\n                        assertEquals(docsList.size(), s.search(new TermQuery(new Term(\"packID\", packID)), 10).totalHits);\n                      } finally {\n                        nrt.release(s);\n                      }\n                    }\n\n                  } else {\n                    if (VERBOSE) {\n                      System.out.println(Thread.currentThread().getName() + \": add doc docid:\" + doc.get(\"docid\"));\n                    }\n\n                    gen = nrt.addDocument(doc);\n                    addCount.getAndIncrement();\n\n                    // randomly verify the add \"took\":\n                    if (random.nextInt(20) == 2) {\n                      //System.out.println(Thread.currentThread().getName() + \": verify\");\n                      final IndexSearcher s = nrt.get(gen, false);\n                      //System.out.println(Thread.currentThread().getName() + \": got s=\" + s);\n                      try {\n                        assertEquals(1, s.search(new TermQuery(new Term(\"docid\", doc.get(\"docid\"))), 10).totalHits);\n                      } finally {\n                        nrt.release(s);\n                      }\n                      //System.out.println(Thread.currentThread().getName() + \": done verify\");\n                    }\n\n                    if (random.nextInt(5) == 3) {\n                      if (VERBOSE) {\n                        System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                      }\n                      toDeleteIDs.add(doc.get(\"docid\"));\n                    }\n                  }\n                } else {\n                  // we use update but it never replaces a\n                  // prior doc\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": update doc id:\" + doc.get(\"docid\"));\n                  }\n                  gen = nrt.updateDocument(new Term(\"docid\", doc.get(\"docid\")), doc);\n                  addCount.getAndIncrement();\n\n                  // randomly verify the add \"took\":\n                  if (random.nextInt(20) == 2) {\n                    final IndexSearcher s = nrt.get(gen, true);\n                    try {\n                      assertEquals(1, s.search(new TermQuery(new Term(\"docid\", doc.get(\"docid\"))), 10).totalHits);\n                    } finally {\n                      nrt.release(s);\n                    }\n                  }\n\n                  if (random.nextInt(5) == 3) {\n                    if (VERBOSE) {\n                      System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                    }\n                    toDeleteIDs.add(doc.get(\"docid\"));\n                  }\n                }\n\n                if (random.nextInt(30) == 17) {\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": apply \" + toDeleteIDs.size() + \" deletes\");\n                  }\n                  for(String id : toDeleteIDs) {\n                    if (VERBOSE) {\n                      System.out.println(Thread.currentThread().getName() + \": del term=id:\" + id);\n                    }\n                    gen = nrt.deleteDocuments(new Term(\"docid\", id));\n\n                    // randomly verify the delete \"took\":\n                    if (random.nextInt(20) == 7) {\n                      final IndexSearcher s = nrt.get(gen, true);\n                      try {\n                        assertEquals(0, s.search(new TermQuery(new Term(\"docid\", id)), 10).totalHits);\n                      } finally {\n                        nrt.release(s);\n                      }\n                    }\n                  }\n\n                  final int count = delCount.addAndGet(toDeleteIDs.size());\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": tot \" + count + \" deletes\");\n                  }\n                  delIDs.addAll(toDeleteIDs);\n                  toDeleteIDs.clear();\n\n                  for(SubDocs subDocs : toDeleteSubDocs) {\n                    assertTrue(!subDocs.deleted);\n                    gen = nrt.deleteDocuments(new Term(\"packID\", subDocs.packID));\n                    subDocs.deleted = true;\n                    if (VERBOSE) {\n                      System.out.println(\"  del subs: \" + subDocs.subIDs + \" packID=\" + subDocs.packID);\n                    }\n                    delIDs.addAll(subDocs.subIDs);\n                    delCount.addAndGet(subDocs.subIDs.size());\n\n                    // randomly verify the delete \"took\":\n                    if (random.nextInt(20) == 7) {\n                      final IndexSearcher s = nrt.get(gen, true);\n                      try {\n                        assertEquals(0, s.search(new TermQuery(new Term(\"packID\", subDocs.packID)), 1).totalHits);\n                      } finally {\n                        nrt.release(s);\n                      }\n                    }\n                  }\n                  toDeleteSubDocs.clear();\n                }\n                if (addedField != null) {\n                  doc.removeField(addedField);\n                }\n              } catch (Throwable t) {\n                System.out.println(Thread.currentThread().getName() + \": FAILED: hit exc\");\n                t.printStackTrace();\n                failed.set(true);\n                throw new RuntimeException(t);\n              }\n            }\n\n            lastGens.add(gen);\n            if (VERBOSE) {\n              System.out.println(Thread.currentThread().getName() + \": indexing done\");\n            }\n          }\n        };\n      threads[thread].setDaemon(true);\n      threads[thread].start();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: DONE start indexing threads [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    // let index build up a bit\n    Thread.sleep(100);\n\n    // silly starting guess:\n    final AtomicInteger totTermCount = new AtomicInteger(100);\n\n    // run search threads\n    final Thread[] searchThreads = new Thread[NUM_SEARCH_THREADS];\n    final AtomicInteger totHits = new AtomicInteger();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: start search threads\");\n    }\n\n    for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n      searchThreads[thread] = new Thread() {\n          @Override\n          public void run() {\n            while(System.currentTimeMillis() < stopTime && !failed.get()) {\n              final IndexSearcher s = nrt.get(random.nextBoolean());\n              try {\n                try {\n                  smokeTestSearcher(s);\n                  if (s.getIndexReader().numDocs() > 0) {\n                    Fields fields = MultiFields.getFields(s.getIndexReader());\n                    if (fields == null) {\n                      continue;\n                    }\n                    Terms terms = fields.terms(\"body\");\n                    if (terms == null) {\n                      continue;\n                    }\n\n                    TermsEnum termsEnum = terms.iterator();\n                    int seenTermCount = 0;\n                    int shift;\n                    int trigger;\n                    if (totTermCount.get() < 10) {\n                      shift = 0;\n                      trigger = 1;\n                    } else {\n                      trigger = totTermCount.get()/10;\n                      shift = random.nextInt(trigger);\n                    }\n\n                    while(System.currentTimeMillis() < stopTime) {\n                      BytesRef term = termsEnum.next();\n                      if (term == null) {\n                        if (seenTermCount == 0) {\n                          break;\n                        }\n                        totTermCount.set(seenTermCount);\n                        seenTermCount = 0;\n                        if (totTermCount.get() < 10) {\n                          shift = 0;\n                          trigger = 1;\n                        } else {\n                          trigger = totTermCount.get()/10;\n                          //System.out.println(\"trigger \" + trigger);\n                          shift = random.nextInt(trigger);\n                        }\n                        termsEnum.seek(new BytesRef(\"\"));\n                        continue;\n                      }\n                      seenTermCount++;\n                      // search 10 terms\n                      if (trigger == 0) {\n                        trigger = 1;\n                      }\n                      if ((seenTermCount + shift) % trigger == 0) {\n                        //if (VERBOSE) {\n                        //System.out.println(Thread.currentThread().getName() + \" now search body:\" + term.utf8ToString());\n                        //}\n                        totHits.addAndGet(runQuery(s, new TermQuery(new Term(\"body\", term))));\n                      }\n                    }\n                    if (VERBOSE) {\n                      System.out.println(Thread.currentThread().getName() + \": search done\");\n                    }\n                  }\n                } finally {\n                  nrt.release(s);\n                }\n              } catch (Throwable t) {\n                System.out.println(Thread.currentThread().getName() + \": FAILED: hit exc\");\n                failed.set(true);\n                t.printStackTrace(System.out);\n                throw new RuntimeException(t);\n              }\n            }\n          }\n        };\n      searchThreads[thread].setDaemon(true);\n      searchThreads[thread].start();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now join\");\n    }\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread].join();\n    }\n    for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n      searchThreads[thread].join();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: done join [\" + (System.currentTimeMillis()-t0) + \" ms]; addCount=\" + addCount + \" delCount=\" + delCount);\n      System.out.println(\"TEST: search totHits=\" + totHits);\n    }\n\n    long maxGen = 0;\n    for(long gen : lastGens) {\n      maxGen = Math.max(maxGen, gen);\n    }\n\n    final IndexSearcher s = nrt.get(maxGen, true);\n\n    boolean doFail = false;\n    for(String id : delIDs) {\n      final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", id)), 1);\n      if (hits.totalHits != 0) {\n        System.out.println(\"doc id=\" + id + \" is supposed to be deleted, but got docID=\" + hits.scoreDocs[0].doc);\n        doFail = true;\n      }\n    }\n\n    // Make sure each group of sub-docs are still in docID order:\n    for(SubDocs subDocs : allSubDocs) {\n      if (!subDocs.deleted) {\n        // We sort by relevance but the scores should be identical so sort falls back to by docID:\n        TopDocs hits = s.search(new TermQuery(new Term(\"packID\", subDocs.packID)), 20);\n        assertEquals(subDocs.subIDs.size(), hits.totalHits);\n        int lastDocID = -1;\n        int startDocID = -1;\n        for(ScoreDoc scoreDoc : hits.scoreDocs) {\n          final int docID = scoreDoc.doc;\n          if (lastDocID != -1) {\n            assertEquals(1+lastDocID, docID);\n          } else {\n            startDocID = docID;\n          }\n          lastDocID = docID;\n          final Document doc = s.doc(docID);\n          assertEquals(subDocs.packID, doc.get(\"packID\"));\n        }\n\n        lastDocID = startDocID - 1;\n        for(String subID : subDocs.subIDs) {\n          hits = s.search(new TermQuery(new Term(\"docid\", subID)), 1);\n          assertEquals(1, hits.totalHits);\n          final int docID = hits.scoreDocs[0].doc;\n          if (lastDocID != -1) {\n            assertEquals(1+lastDocID, docID);\n          }\n          lastDocID = docID;\n        }          \n      } else {\n        for(String subID : subDocs.subIDs) {\n          assertEquals(0, s.search(new TermQuery(new Term(\"docid\", subID)), 1).totalHits);\n        }\n      }\n    }\n    \n    final int endID = Integer.parseInt(docs.nextDoc().get(\"docid\"));\n    for(int id=0;id<endID;id++) {\n      String stringID = \"\"+id;\n      if (!delIDs.contains(stringID)) {\n        final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", stringID)), 1);\n        if (hits.totalHits != 1) {\n          System.out.println(\"doc id=\" + stringID + \" is not supposed to be deleted, but got hitCount=\" + hits.totalHits);\n          doFail = true;\n        }\n      }\n    }\n    assertFalse(doFail);\n\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), s.getIndexReader().numDocs());\n    nrt.release(s);\n\n    if (es != null) {\n      es.shutdown();\n      es.awaitTermination(1, TimeUnit.SECONDS);\n    }\n\n    writer.commit();\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), writer.numDocs());\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now close NRTManager\");\n    }\n    nrtThread.close();\n    nrt.close();\n    assertFalse(writer.anyNonBulkMerges);\n    writer.close(false);\n    _TestUtil.checkIndex(dir);\n    dir.close();\n    _TestUtil.rmDir(tempDir);\n    docs.close();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2553b00f699380c64959ccb27991289aae87be2e","date":1309290151,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/contrib/misc/src/test/org/apache/lucene/index/TestNRTManager#testNRTManager().mjava","pathOld":"lucene/contrib/misc/src/test/org/apache/lucene/index/TestNRTManager#testNRTManager().mjava","sourceNew":"  @Test\n  public void testNRTManager() throws Exception {\n\n    final long t0 = System.currentTimeMillis();\n\n    if (CodecProvider.getDefault().getDefaultFieldCodec().equals(\"SimpleText\")) {\n      // no\n      CodecProvider.getDefault().setDefaultFieldCodec(\"Standard\");\n    }\n\n    final LineFileDocs docs = new LineFileDocs(random);\n    final File tempDir = _TestUtil.getTempDir(\"nrtopenfiles\");\n    final MockDirectoryWrapper _dir = newFSDirectory(tempDir);\n    _dir.setCheckIndexOnClose(false);  // don't double-checkIndex, we do it ourselves\n    Directory dir = _dir;\n    final IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).setOpenMode(IndexWriterConfig.OpenMode.CREATE);\n\n    if (LuceneTestCase.TEST_NIGHTLY) {\n      // newIWConfig makes smallish max seg size, which\n      // results in tons and tons of segments for this test\n      // when run nightly:\n      MergePolicy mp = conf.getMergePolicy();\n      if (mp instanceof TieredMergePolicy) {\n        ((TieredMergePolicy) mp).setMaxMergedSegmentMB(5000.);\n      } else if (mp instanceof LogByteSizeMergePolicy) {\n        ((LogByteSizeMergePolicy) mp).setMaxMergeMB(1000.);\n      } else if (mp instanceof LogMergePolicy) {\n        ((LogMergePolicy) mp).setMaxMergeDocs(100000);\n      }\n    }\n\n    conf.setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n      @Override\n      public void warm(IndexReader reader) throws IOException {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now warm merged reader=\" + reader);\n        }\n        final int maxDoc = reader.maxDoc();\n        final Bits delDocs = reader.getDeletedDocs();\n        int sum = 0;\n        final int inc = Math.max(1, maxDoc/50);\n        for(int docID=0;docID<maxDoc;docID += inc) {\n          if (delDocs == null || !delDocs.get(docID)) {\n            final Document doc = reader.document(docID);\n            sum += doc.getFields().size();\n          }\n        }\n\n        IndexSearcher searcher = newSearcher(reader);\n        sum += searcher.search(new TermQuery(new Term(\"body\", \"united\")), 10).totalHits;\n        searcher.close();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: warm visited \" + sum + \" fields\");\n        }\n      }\n      });\n\n    if (random.nextBoolean()) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: wrap NRTCachingDir\");\n      }\n\n      NRTCachingDirectory nrtDir = new NRTCachingDirectory(dir, 5.0, 60.0);\n      conf.setMergeScheduler(nrtDir.getMergeScheduler());\n      dir = nrtDir;\n    }\n    \n    final IndexWriter writer = new IndexWriter(dir, conf);\n    \n    if (VERBOSE) {\n      writer.setInfoStream(System.out);\n    }\n    _TestUtil.reduceOpenFiles(writer);\n    //System.out.println(\"TEST: conf=\" + writer.getConfig());\n\n    final ExecutorService es = random.nextBoolean() ? null : Executors.newCachedThreadPool(new NamedThreadFactory(\"NRT search threads\"));\n\n    final double minReopenSec = 0.01 + 0.05 * random.nextDouble();\n    final double maxReopenSec = minReopenSec * (1.0 + 10 * random.nextDouble());\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: make NRTManager maxReopenSec=\" + maxReopenSec + \" minReopenSec=\" + minReopenSec);\n    }\n\n    final NRTManager nrt = new NRTManager(writer, es);\n    final NRTManagerReopenThread nrtThread = new NRTManagerReopenThread(nrt, maxReopenSec, minReopenSec);\n    nrtThread.setName(\"NRT Reopen Thread\");\n    nrtThread.setPriority(Math.min(Thread.currentThread().getPriority()+2, Thread.MAX_PRIORITY));\n    nrtThread.setDaemon(true);\n    nrtThread.start();\n\n    final int NUM_INDEX_THREADS = _TestUtil.nextInt(random, 1, 3);\n    final int NUM_SEARCH_THREADS = _TestUtil.nextInt(random, 1, 3);\n    //final int NUM_INDEX_THREADS = 1;\n    //final int NUM_SEARCH_THREADS = 1;\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + NUM_INDEX_THREADS + \" index threads; \" + NUM_SEARCH_THREADS + \" search threads\");\n    }\n\n    final int RUN_TIME_SEC = LuceneTestCase.TEST_NIGHTLY ? 300 : RANDOM_MULTIPLIER;\n\n    final AtomicBoolean failed = new AtomicBoolean();\n    final AtomicInteger addCount = new AtomicInteger();\n    final AtomicInteger delCount = new AtomicInteger();\n    final AtomicInteger packCount = new AtomicInteger();\n    final List<Long> lastGens = new ArrayList<Long>();\n\n    final Set<String> delIDs = Collections.synchronizedSet(new HashSet<String>());\n    final List<SubDocs> allSubDocs = Collections.synchronizedList(new ArrayList<SubDocs>());\n\n    final long stopTime = System.currentTimeMillis() + RUN_TIME_SEC*1000;\n    Thread[] threads = new Thread[NUM_INDEX_THREADS];\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread] = new Thread() {\n          @Override\n          public void run() {\n            // TODO: would be better if this were cross thread, so that we make sure one thread deleting anothers added docs works:\n            final List<String> toDeleteIDs = new ArrayList<String>();\n            final List<SubDocs> toDeleteSubDocs = new ArrayList<SubDocs>();\n\n            long gen = 0;\n            while(System.currentTimeMillis() < stopTime && !failed.get()) {\n\n              //System.out.println(Thread.currentThread().getName() + \": cycle\");\n              try {\n                // Occassional longish pause if running\n                // nightly\n                if (LuceneTestCase.TEST_NIGHTLY && random.nextInt(6) == 3) {\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": now long sleep\");\n                  }\n                  Thread.sleep(_TestUtil.nextInt(random, 50, 500));\n                }\n\n                // Rate limit ingest rate:\n                Thread.sleep(_TestUtil.nextInt(random, 1, 10));\n                if (VERBOSE) {\n                  System.out.println(Thread.currentThread() + \": done sleep\");\n                }\n\n                Document doc = docs.nextDoc();\n                if (doc == null) {\n                  break;\n                }\n                final String addedField;\n                if (random.nextBoolean()) {\n                  addedField = \"extra\" + random.nextInt(10);\n                  doc.add(new Field(addedField, \"a random field\", Field.Store.NO, Field.Index.ANALYZED));\n                } else {\n                  addedField = null;\n                }\n                if (random.nextBoolean()) {\n\n                  if (random.nextBoolean()) {\n                    // Add a pack of adjacent sub-docs\n                    final String packID;\n                    final SubDocs delSubDocs;\n                    if (toDeleteSubDocs.size() > 0 && random.nextBoolean()) {\n                      delSubDocs = toDeleteSubDocs.get(random.nextInt(toDeleteSubDocs.size()));\n                      assert !delSubDocs.deleted;\n                      toDeleteSubDocs.remove(delSubDocs);\n                      // reuse prior packID\n                      packID = delSubDocs.packID;\n                    } else {\n                      delSubDocs = null;\n                      // make new packID\n                      packID = packCount.getAndIncrement() + \"\";\n                    }\n\n                    final Field packIDField = newField(\"packID\", packID, Field.Store.YES, Field.Index.NOT_ANALYZED);\n                    final List<String> docIDs = new ArrayList<String>();\n                    final SubDocs subDocs = new SubDocs(packID, docIDs);\n                    final List<Document> docsList = new ArrayList<Document>();\n\n                    allSubDocs.add(subDocs);\n                    doc.add(packIDField);\n                    docsList.add(cloneDoc(doc));\n                    docIDs.add(doc.get(\"docid\"));\n\n                    final int maxDocCount = _TestUtil.nextInt(random, 1, 10);\n                    while(docsList.size() < maxDocCount) {\n                      doc = docs.nextDoc();\n                      if (doc == null) {\n                        break;\n                      }\n                      docsList.add(cloneDoc(doc));\n                      docIDs.add(doc.get(\"docid\"));\n                    }\n                    addCount.addAndGet(docsList.size());\n\n                    if (delSubDocs != null) {\n                      delSubDocs.deleted = true;\n                      delIDs.addAll(delSubDocs.subIDs);\n                      delCount.addAndGet(delSubDocs.subIDs.size());\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: update pack packID=\" + delSubDocs.packID + \" count=\" + docsList.size() + \" docs=\" + docIDs);\n                      }\n                      gen = nrt.updateDocuments(new Term(\"packID\", delSubDocs.packID), docsList);\n                      /*\n                      // non-atomic:\n                      nrt.deleteDocuments(new Term(\"packID\", delSubDocs.packID));\n                      for(Document subDoc : docsList) {\n                        nrt.addDocument(subDoc);\n                      }\n                      */\n                    } else {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: add pack packID=\" + packID + \" count=\" + docsList.size() + \" docs=\" + docIDs);\n                      }\n                      gen = nrt.addDocuments(docsList);\n                      \n                      /*\n                      // non-atomic:\n                      for(Document subDoc : docsList) {\n                        nrt.addDocument(subDoc);\n                      }\n                      */\n                    }\n                    doc.removeField(\"packID\");\n\n                    if (random.nextInt(5) == 2) {\n                      if (VERBOSE) {\n                        System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + packID);\n                      }\n                      toDeleteSubDocs.add(subDocs);\n                    }\n\n                    // randomly verify the add/update \"took\":\n                    if (random.nextInt(20) == 2) {\n                      final boolean applyDeletes = delSubDocs != null;\n                      final IndexSearcher s = nrt.get(gen, applyDeletes);\n                      try {\n                        assertEquals(docsList.size(), s.search(new TermQuery(new Term(\"packID\", packID)), 10).totalHits);\n                      } finally {\n                        nrt.release(s);\n                      }\n                    }\n\n                  } else {\n                    if (VERBOSE) {\n                      System.out.println(Thread.currentThread().getName() + \": add doc docid:\" + doc.get(\"docid\"));\n                    }\n\n                    gen = nrt.addDocument(doc);\n                    addCount.getAndIncrement();\n\n                    // randomly verify the add \"took\":\n                    if (random.nextInt(20) == 2) {\n                      //System.out.println(Thread.currentThread().getName() + \": verify\");\n                      final IndexSearcher s = nrt.get(gen, false);\n                      //System.out.println(Thread.currentThread().getName() + \": got s=\" + s);\n                      try {\n                        assertEquals(1, s.search(new TermQuery(new Term(\"docid\", doc.get(\"docid\"))), 10).totalHits);\n                      } finally {\n                        nrt.release(s);\n                      }\n                      //System.out.println(Thread.currentThread().getName() + \": done verify\");\n                    }\n\n                    if (random.nextInt(5) == 3) {\n                      if (VERBOSE) {\n                        System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                      }\n                      toDeleteIDs.add(doc.get(\"docid\"));\n                    }\n                  }\n                } else {\n                  // we use update but it never replaces a\n                  // prior doc\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": update doc id:\" + doc.get(\"docid\"));\n                  }\n                  gen = nrt.updateDocument(new Term(\"docid\", doc.get(\"docid\")), doc);\n                  addCount.getAndIncrement();\n\n                  // randomly verify the add \"took\":\n                  if (random.nextInt(20) == 2) {\n                    final IndexSearcher s = nrt.get(gen, true);\n                    try {\n                      assertEquals(1, s.search(new TermQuery(new Term(\"docid\", doc.get(\"docid\"))), 10).totalHits);\n                    } finally {\n                      nrt.release(s);\n                    }\n                  }\n\n                  if (random.nextInt(5) == 3) {\n                    if (VERBOSE) {\n                      System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                    }\n                    toDeleteIDs.add(doc.get(\"docid\"));\n                  }\n                }\n\n                if (random.nextInt(30) == 17) {\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": apply \" + toDeleteIDs.size() + \" deletes\");\n                  }\n                  for(String id : toDeleteIDs) {\n                    if (VERBOSE) {\n                      System.out.println(Thread.currentThread().getName() + \": del term=id:\" + id);\n                    }\n                    gen = nrt.deleteDocuments(new Term(\"docid\", id));\n\n                    // randomly verify the delete \"took\":\n                    if (random.nextInt(20) == 7) {\n                      final IndexSearcher s = nrt.get(gen, true);\n                      try {\n                        assertEquals(0, s.search(new TermQuery(new Term(\"docid\", id)), 10).totalHits);\n                      } finally {\n                        nrt.release(s);\n                      }\n                    }\n                  }\n\n                  final int count = delCount.addAndGet(toDeleteIDs.size());\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": tot \" + count + \" deletes\");\n                  }\n                  delIDs.addAll(toDeleteIDs);\n                  toDeleteIDs.clear();\n\n                  for(SubDocs subDocs : toDeleteSubDocs) {\n                    assertTrue(!subDocs.deleted);\n                    gen = nrt.deleteDocuments(new Term(\"packID\", subDocs.packID));\n                    subDocs.deleted = true;\n                    if (VERBOSE) {\n                      System.out.println(\"  del subs: \" + subDocs.subIDs + \" packID=\" + subDocs.packID);\n                    }\n                    delIDs.addAll(subDocs.subIDs);\n                    delCount.addAndGet(subDocs.subIDs.size());\n\n                    // randomly verify the delete \"took\":\n                    if (random.nextInt(20) == 7) {\n                      final IndexSearcher s = nrt.get(gen, true);\n                      try {\n                        assertEquals(0, s.search(new TermQuery(new Term(\"packID\", subDocs.packID)), 1).totalHits);\n                      } finally {\n                        nrt.release(s);\n                      }\n                    }\n                  }\n                  toDeleteSubDocs.clear();\n                }\n                if (addedField != null) {\n                  doc.removeField(addedField);\n                }\n              } catch (Throwable t) {\n                System.out.println(Thread.currentThread().getName() + \": FAILED: hit exc\");\n                t.printStackTrace();\n                failed.set(true);\n                throw new RuntimeException(t);\n              }\n            }\n\n            lastGens.add(gen);\n            if (VERBOSE) {\n              System.out.println(Thread.currentThread().getName() + \": indexing done\");\n            }\n          }\n        };\n      threads[thread].setDaemon(true);\n      threads[thread].start();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: DONE start indexing threads [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    // let index build up a bit\n    Thread.sleep(100);\n\n    // silly starting guess:\n    final AtomicInteger totTermCount = new AtomicInteger(100);\n\n    // run search threads\n    final Thread[] searchThreads = new Thread[NUM_SEARCH_THREADS];\n    final AtomicInteger totHits = new AtomicInteger();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: start search threads\");\n    }\n\n    for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n      searchThreads[thread] = new Thread() {\n          @Override\n          public void run() {\n            while(System.currentTimeMillis() < stopTime && !failed.get()) {\n              final IndexSearcher s = nrt.get(random.nextBoolean());\n              try {\n                try {\n                  smokeTestSearcher(s);\n                  if (s.getIndexReader().numDocs() > 0) {\n                    Fields fields = MultiFields.getFields(s.getIndexReader());\n                    if (fields == null) {\n                      continue;\n                    }\n                    Terms terms = fields.terms(\"body\");\n                    if (terms == null) {\n                      continue;\n                    }\n\n                    TermsEnum termsEnum = terms.iterator();\n                    int seenTermCount = 0;\n                    int shift;\n                    int trigger;\n                    if (totTermCount.get() < 10) {\n                      shift = 0;\n                      trigger = 1;\n                    } else {\n                      trigger = totTermCount.get()/10;\n                      shift = random.nextInt(trigger);\n                    }\n\n                    while(System.currentTimeMillis() < stopTime) {\n                      BytesRef term = termsEnum.next();\n                      if (term == null) {\n                        if (seenTermCount == 0) {\n                          break;\n                        }\n                        totTermCount.set(seenTermCount);\n                        seenTermCount = 0;\n                        if (totTermCount.get() < 10) {\n                          shift = 0;\n                          trigger = 1;\n                        } else {\n                          trigger = totTermCount.get()/10;\n                          //System.out.println(\"trigger \" + trigger);\n                          shift = random.nextInt(trigger);\n                        }\n                        termsEnum.seekCeil(new BytesRef(\"\"));\n                        continue;\n                      }\n                      seenTermCount++;\n                      // search 10 terms\n                      if (trigger == 0) {\n                        trigger = 1;\n                      }\n                      if ((seenTermCount + shift) % trigger == 0) {\n                        //if (VERBOSE) {\n                        //System.out.println(Thread.currentThread().getName() + \" now search body:\" + term.utf8ToString());\n                        //}\n                        totHits.addAndGet(runQuery(s, new TermQuery(new Term(\"body\", term))));\n                      }\n                    }\n                    if (VERBOSE) {\n                      System.out.println(Thread.currentThread().getName() + \": search done\");\n                    }\n                  }\n                } finally {\n                  nrt.release(s);\n                }\n              } catch (Throwable t) {\n                System.out.println(Thread.currentThread().getName() + \": FAILED: hit exc\");\n                failed.set(true);\n                t.printStackTrace(System.out);\n                throw new RuntimeException(t);\n              }\n            }\n          }\n        };\n      searchThreads[thread].setDaemon(true);\n      searchThreads[thread].start();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now join\");\n    }\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread].join();\n    }\n    for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n      searchThreads[thread].join();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: done join [\" + (System.currentTimeMillis()-t0) + \" ms]; addCount=\" + addCount + \" delCount=\" + delCount);\n      System.out.println(\"TEST: search totHits=\" + totHits);\n    }\n\n    long maxGen = 0;\n    for(long gen : lastGens) {\n      maxGen = Math.max(maxGen, gen);\n    }\n\n    final IndexSearcher s = nrt.get(maxGen, true);\n\n    boolean doFail = false;\n    for(String id : delIDs) {\n      final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", id)), 1);\n      if (hits.totalHits != 0) {\n        System.out.println(\"doc id=\" + id + \" is supposed to be deleted, but got docID=\" + hits.scoreDocs[0].doc);\n        doFail = true;\n      }\n    }\n\n    // Make sure each group of sub-docs are still in docID order:\n    for(SubDocs subDocs : allSubDocs) {\n      if (!subDocs.deleted) {\n        // We sort by relevance but the scores should be identical so sort falls back to by docID:\n        TopDocs hits = s.search(new TermQuery(new Term(\"packID\", subDocs.packID)), 20);\n        assertEquals(subDocs.subIDs.size(), hits.totalHits);\n        int lastDocID = -1;\n        int startDocID = -1;\n        for(ScoreDoc scoreDoc : hits.scoreDocs) {\n          final int docID = scoreDoc.doc;\n          if (lastDocID != -1) {\n            assertEquals(1+lastDocID, docID);\n          } else {\n            startDocID = docID;\n          }\n          lastDocID = docID;\n          final Document doc = s.doc(docID);\n          assertEquals(subDocs.packID, doc.get(\"packID\"));\n        }\n\n        lastDocID = startDocID - 1;\n        for(String subID : subDocs.subIDs) {\n          hits = s.search(new TermQuery(new Term(\"docid\", subID)), 1);\n          assertEquals(1, hits.totalHits);\n          final int docID = hits.scoreDocs[0].doc;\n          if (lastDocID != -1) {\n            assertEquals(1+lastDocID, docID);\n          }\n          lastDocID = docID;\n        }          \n      } else {\n        for(String subID : subDocs.subIDs) {\n          assertEquals(0, s.search(new TermQuery(new Term(\"docid\", subID)), 1).totalHits);\n        }\n      }\n    }\n    \n    final int endID = Integer.parseInt(docs.nextDoc().get(\"docid\"));\n    for(int id=0;id<endID;id++) {\n      String stringID = \"\"+id;\n      if (!delIDs.contains(stringID)) {\n        final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", stringID)), 1);\n        if (hits.totalHits != 1) {\n          System.out.println(\"doc id=\" + stringID + \" is not supposed to be deleted, but got hitCount=\" + hits.totalHits);\n          doFail = true;\n        }\n      }\n    }\n    assertFalse(doFail);\n\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), s.getIndexReader().numDocs());\n    nrt.release(s);\n\n    if (es != null) {\n      es.shutdown();\n      es.awaitTermination(1, TimeUnit.SECONDS);\n    }\n\n    writer.commit();\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), writer.numDocs());\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now close NRTManager\");\n    }\n    nrtThread.close();\n    nrt.close();\n    assertFalse(writer.anyNonBulkMerges);\n    writer.close(false);\n    _TestUtil.checkIndex(dir);\n    dir.close();\n    _TestUtil.rmDir(tempDir);\n    docs.close();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testNRTManager() throws Exception {\n\n    final long t0 = System.currentTimeMillis();\n\n    if (CodecProvider.getDefault().getDefaultFieldCodec().equals(\"SimpleText\")) {\n      // no\n      CodecProvider.getDefault().setDefaultFieldCodec(\"Standard\");\n    }\n\n    final LineFileDocs docs = new LineFileDocs(random);\n    final File tempDir = _TestUtil.getTempDir(\"nrtopenfiles\");\n    final MockDirectoryWrapper _dir = newFSDirectory(tempDir);\n    _dir.setCheckIndexOnClose(false);  // don't double-checkIndex, we do it ourselves\n    Directory dir = _dir;\n    final IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).setOpenMode(IndexWriterConfig.OpenMode.CREATE);\n\n    if (LuceneTestCase.TEST_NIGHTLY) {\n      // newIWConfig makes smallish max seg size, which\n      // results in tons and tons of segments for this test\n      // when run nightly:\n      MergePolicy mp = conf.getMergePolicy();\n      if (mp instanceof TieredMergePolicy) {\n        ((TieredMergePolicy) mp).setMaxMergedSegmentMB(5000.);\n      } else if (mp instanceof LogByteSizeMergePolicy) {\n        ((LogByteSizeMergePolicy) mp).setMaxMergeMB(1000.);\n      } else if (mp instanceof LogMergePolicy) {\n        ((LogMergePolicy) mp).setMaxMergeDocs(100000);\n      }\n    }\n\n    conf.setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n      @Override\n      public void warm(IndexReader reader) throws IOException {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now warm merged reader=\" + reader);\n        }\n        final int maxDoc = reader.maxDoc();\n        final Bits delDocs = reader.getDeletedDocs();\n        int sum = 0;\n        final int inc = Math.max(1, maxDoc/50);\n        for(int docID=0;docID<maxDoc;docID += inc) {\n          if (delDocs == null || !delDocs.get(docID)) {\n            final Document doc = reader.document(docID);\n            sum += doc.getFields().size();\n          }\n        }\n\n        IndexSearcher searcher = newSearcher(reader);\n        sum += searcher.search(new TermQuery(new Term(\"body\", \"united\")), 10).totalHits;\n        searcher.close();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: warm visited \" + sum + \" fields\");\n        }\n      }\n      });\n\n    if (random.nextBoolean()) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: wrap NRTCachingDir\");\n      }\n\n      NRTCachingDirectory nrtDir = new NRTCachingDirectory(dir, 5.0, 60.0);\n      conf.setMergeScheduler(nrtDir.getMergeScheduler());\n      dir = nrtDir;\n    }\n    \n    final IndexWriter writer = new IndexWriter(dir, conf);\n    \n    if (VERBOSE) {\n      writer.setInfoStream(System.out);\n    }\n    _TestUtil.reduceOpenFiles(writer);\n    //System.out.println(\"TEST: conf=\" + writer.getConfig());\n\n    final ExecutorService es = random.nextBoolean() ? null : Executors.newCachedThreadPool(new NamedThreadFactory(\"NRT search threads\"));\n\n    final double minReopenSec = 0.01 + 0.05 * random.nextDouble();\n    final double maxReopenSec = minReopenSec * (1.0 + 10 * random.nextDouble());\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: make NRTManager maxReopenSec=\" + maxReopenSec + \" minReopenSec=\" + minReopenSec);\n    }\n\n    final NRTManager nrt = new NRTManager(writer, es);\n    final NRTManagerReopenThread nrtThread = new NRTManagerReopenThread(nrt, maxReopenSec, minReopenSec);\n    nrtThread.setName(\"NRT Reopen Thread\");\n    nrtThread.setPriority(Math.min(Thread.currentThread().getPriority()+2, Thread.MAX_PRIORITY));\n    nrtThread.setDaemon(true);\n    nrtThread.start();\n\n    final int NUM_INDEX_THREADS = _TestUtil.nextInt(random, 1, 3);\n    final int NUM_SEARCH_THREADS = _TestUtil.nextInt(random, 1, 3);\n    //final int NUM_INDEX_THREADS = 1;\n    //final int NUM_SEARCH_THREADS = 1;\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + NUM_INDEX_THREADS + \" index threads; \" + NUM_SEARCH_THREADS + \" search threads\");\n    }\n\n    final int RUN_TIME_SEC = LuceneTestCase.TEST_NIGHTLY ? 300 : RANDOM_MULTIPLIER;\n\n    final AtomicBoolean failed = new AtomicBoolean();\n    final AtomicInteger addCount = new AtomicInteger();\n    final AtomicInteger delCount = new AtomicInteger();\n    final AtomicInteger packCount = new AtomicInteger();\n    final List<Long> lastGens = new ArrayList<Long>();\n\n    final Set<String> delIDs = Collections.synchronizedSet(new HashSet<String>());\n    final List<SubDocs> allSubDocs = Collections.synchronizedList(new ArrayList<SubDocs>());\n\n    final long stopTime = System.currentTimeMillis() + RUN_TIME_SEC*1000;\n    Thread[] threads = new Thread[NUM_INDEX_THREADS];\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread] = new Thread() {\n          @Override\n          public void run() {\n            // TODO: would be better if this were cross thread, so that we make sure one thread deleting anothers added docs works:\n            final List<String> toDeleteIDs = new ArrayList<String>();\n            final List<SubDocs> toDeleteSubDocs = new ArrayList<SubDocs>();\n\n            long gen = 0;\n            while(System.currentTimeMillis() < stopTime && !failed.get()) {\n\n              //System.out.println(Thread.currentThread().getName() + \": cycle\");\n              try {\n                // Occassional longish pause if running\n                // nightly\n                if (LuceneTestCase.TEST_NIGHTLY && random.nextInt(6) == 3) {\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": now long sleep\");\n                  }\n                  Thread.sleep(_TestUtil.nextInt(random, 50, 500));\n                }\n\n                // Rate limit ingest rate:\n                Thread.sleep(_TestUtil.nextInt(random, 1, 10));\n                if (VERBOSE) {\n                  System.out.println(Thread.currentThread() + \": done sleep\");\n                }\n\n                Document doc = docs.nextDoc();\n                if (doc == null) {\n                  break;\n                }\n                final String addedField;\n                if (random.nextBoolean()) {\n                  addedField = \"extra\" + random.nextInt(10);\n                  doc.add(new Field(addedField, \"a random field\", Field.Store.NO, Field.Index.ANALYZED));\n                } else {\n                  addedField = null;\n                }\n                if (random.nextBoolean()) {\n\n                  if (random.nextBoolean()) {\n                    // Add a pack of adjacent sub-docs\n                    final String packID;\n                    final SubDocs delSubDocs;\n                    if (toDeleteSubDocs.size() > 0 && random.nextBoolean()) {\n                      delSubDocs = toDeleteSubDocs.get(random.nextInt(toDeleteSubDocs.size()));\n                      assert !delSubDocs.deleted;\n                      toDeleteSubDocs.remove(delSubDocs);\n                      // reuse prior packID\n                      packID = delSubDocs.packID;\n                    } else {\n                      delSubDocs = null;\n                      // make new packID\n                      packID = packCount.getAndIncrement() + \"\";\n                    }\n\n                    final Field packIDField = newField(\"packID\", packID, Field.Store.YES, Field.Index.NOT_ANALYZED);\n                    final List<String> docIDs = new ArrayList<String>();\n                    final SubDocs subDocs = new SubDocs(packID, docIDs);\n                    final List<Document> docsList = new ArrayList<Document>();\n\n                    allSubDocs.add(subDocs);\n                    doc.add(packIDField);\n                    docsList.add(cloneDoc(doc));\n                    docIDs.add(doc.get(\"docid\"));\n\n                    final int maxDocCount = _TestUtil.nextInt(random, 1, 10);\n                    while(docsList.size() < maxDocCount) {\n                      doc = docs.nextDoc();\n                      if (doc == null) {\n                        break;\n                      }\n                      docsList.add(cloneDoc(doc));\n                      docIDs.add(doc.get(\"docid\"));\n                    }\n                    addCount.addAndGet(docsList.size());\n\n                    if (delSubDocs != null) {\n                      delSubDocs.deleted = true;\n                      delIDs.addAll(delSubDocs.subIDs);\n                      delCount.addAndGet(delSubDocs.subIDs.size());\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: update pack packID=\" + delSubDocs.packID + \" count=\" + docsList.size() + \" docs=\" + docIDs);\n                      }\n                      gen = nrt.updateDocuments(new Term(\"packID\", delSubDocs.packID), docsList);\n                      /*\n                      // non-atomic:\n                      nrt.deleteDocuments(new Term(\"packID\", delSubDocs.packID));\n                      for(Document subDoc : docsList) {\n                        nrt.addDocument(subDoc);\n                      }\n                      */\n                    } else {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: add pack packID=\" + packID + \" count=\" + docsList.size() + \" docs=\" + docIDs);\n                      }\n                      gen = nrt.addDocuments(docsList);\n                      \n                      /*\n                      // non-atomic:\n                      for(Document subDoc : docsList) {\n                        nrt.addDocument(subDoc);\n                      }\n                      */\n                    }\n                    doc.removeField(\"packID\");\n\n                    if (random.nextInt(5) == 2) {\n                      if (VERBOSE) {\n                        System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + packID);\n                      }\n                      toDeleteSubDocs.add(subDocs);\n                    }\n\n                    // randomly verify the add/update \"took\":\n                    if (random.nextInt(20) == 2) {\n                      final boolean applyDeletes = delSubDocs != null;\n                      final IndexSearcher s = nrt.get(gen, applyDeletes);\n                      try {\n                        assertEquals(docsList.size(), s.search(new TermQuery(new Term(\"packID\", packID)), 10).totalHits);\n                      } finally {\n                        nrt.release(s);\n                      }\n                    }\n\n                  } else {\n                    if (VERBOSE) {\n                      System.out.println(Thread.currentThread().getName() + \": add doc docid:\" + doc.get(\"docid\"));\n                    }\n\n                    gen = nrt.addDocument(doc);\n                    addCount.getAndIncrement();\n\n                    // randomly verify the add \"took\":\n                    if (random.nextInt(20) == 2) {\n                      //System.out.println(Thread.currentThread().getName() + \": verify\");\n                      final IndexSearcher s = nrt.get(gen, false);\n                      //System.out.println(Thread.currentThread().getName() + \": got s=\" + s);\n                      try {\n                        assertEquals(1, s.search(new TermQuery(new Term(\"docid\", doc.get(\"docid\"))), 10).totalHits);\n                      } finally {\n                        nrt.release(s);\n                      }\n                      //System.out.println(Thread.currentThread().getName() + \": done verify\");\n                    }\n\n                    if (random.nextInt(5) == 3) {\n                      if (VERBOSE) {\n                        System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                      }\n                      toDeleteIDs.add(doc.get(\"docid\"));\n                    }\n                  }\n                } else {\n                  // we use update but it never replaces a\n                  // prior doc\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": update doc id:\" + doc.get(\"docid\"));\n                  }\n                  gen = nrt.updateDocument(new Term(\"docid\", doc.get(\"docid\")), doc);\n                  addCount.getAndIncrement();\n\n                  // randomly verify the add \"took\":\n                  if (random.nextInt(20) == 2) {\n                    final IndexSearcher s = nrt.get(gen, true);\n                    try {\n                      assertEquals(1, s.search(new TermQuery(new Term(\"docid\", doc.get(\"docid\"))), 10).totalHits);\n                    } finally {\n                      nrt.release(s);\n                    }\n                  }\n\n                  if (random.nextInt(5) == 3) {\n                    if (VERBOSE) {\n                      System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                    }\n                    toDeleteIDs.add(doc.get(\"docid\"));\n                  }\n                }\n\n                if (random.nextInt(30) == 17) {\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": apply \" + toDeleteIDs.size() + \" deletes\");\n                  }\n                  for(String id : toDeleteIDs) {\n                    if (VERBOSE) {\n                      System.out.println(Thread.currentThread().getName() + \": del term=id:\" + id);\n                    }\n                    gen = nrt.deleteDocuments(new Term(\"docid\", id));\n\n                    // randomly verify the delete \"took\":\n                    if (random.nextInt(20) == 7) {\n                      final IndexSearcher s = nrt.get(gen, true);\n                      try {\n                        assertEquals(0, s.search(new TermQuery(new Term(\"docid\", id)), 10).totalHits);\n                      } finally {\n                        nrt.release(s);\n                      }\n                    }\n                  }\n\n                  final int count = delCount.addAndGet(toDeleteIDs.size());\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": tot \" + count + \" deletes\");\n                  }\n                  delIDs.addAll(toDeleteIDs);\n                  toDeleteIDs.clear();\n\n                  for(SubDocs subDocs : toDeleteSubDocs) {\n                    assertTrue(!subDocs.deleted);\n                    gen = nrt.deleteDocuments(new Term(\"packID\", subDocs.packID));\n                    subDocs.deleted = true;\n                    if (VERBOSE) {\n                      System.out.println(\"  del subs: \" + subDocs.subIDs + \" packID=\" + subDocs.packID);\n                    }\n                    delIDs.addAll(subDocs.subIDs);\n                    delCount.addAndGet(subDocs.subIDs.size());\n\n                    // randomly verify the delete \"took\":\n                    if (random.nextInt(20) == 7) {\n                      final IndexSearcher s = nrt.get(gen, true);\n                      try {\n                        assertEquals(0, s.search(new TermQuery(new Term(\"packID\", subDocs.packID)), 1).totalHits);\n                      } finally {\n                        nrt.release(s);\n                      }\n                    }\n                  }\n                  toDeleteSubDocs.clear();\n                }\n                if (addedField != null) {\n                  doc.removeField(addedField);\n                }\n              } catch (Throwable t) {\n                System.out.println(Thread.currentThread().getName() + \": FAILED: hit exc\");\n                t.printStackTrace();\n                failed.set(true);\n                throw new RuntimeException(t);\n              }\n            }\n\n            lastGens.add(gen);\n            if (VERBOSE) {\n              System.out.println(Thread.currentThread().getName() + \": indexing done\");\n            }\n          }\n        };\n      threads[thread].setDaemon(true);\n      threads[thread].start();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: DONE start indexing threads [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    // let index build up a bit\n    Thread.sleep(100);\n\n    // silly starting guess:\n    final AtomicInteger totTermCount = new AtomicInteger(100);\n\n    // run search threads\n    final Thread[] searchThreads = new Thread[NUM_SEARCH_THREADS];\n    final AtomicInteger totHits = new AtomicInteger();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: start search threads\");\n    }\n\n    for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n      searchThreads[thread] = new Thread() {\n          @Override\n          public void run() {\n            while(System.currentTimeMillis() < stopTime && !failed.get()) {\n              final IndexSearcher s = nrt.get(random.nextBoolean());\n              try {\n                try {\n                  smokeTestSearcher(s);\n                  if (s.getIndexReader().numDocs() > 0) {\n                    Fields fields = MultiFields.getFields(s.getIndexReader());\n                    if (fields == null) {\n                      continue;\n                    }\n                    Terms terms = fields.terms(\"body\");\n                    if (terms == null) {\n                      continue;\n                    }\n\n                    TermsEnum termsEnum = terms.iterator();\n                    int seenTermCount = 0;\n                    int shift;\n                    int trigger;\n                    if (totTermCount.get() < 10) {\n                      shift = 0;\n                      trigger = 1;\n                    } else {\n                      trigger = totTermCount.get()/10;\n                      shift = random.nextInt(trigger);\n                    }\n\n                    while(System.currentTimeMillis() < stopTime) {\n                      BytesRef term = termsEnum.next();\n                      if (term == null) {\n                        if (seenTermCount == 0) {\n                          break;\n                        }\n                        totTermCount.set(seenTermCount);\n                        seenTermCount = 0;\n                        if (totTermCount.get() < 10) {\n                          shift = 0;\n                          trigger = 1;\n                        } else {\n                          trigger = totTermCount.get()/10;\n                          //System.out.println(\"trigger \" + trigger);\n                          shift = random.nextInt(trigger);\n                        }\n                        termsEnum.seek(new BytesRef(\"\"));\n                        continue;\n                      }\n                      seenTermCount++;\n                      // search 10 terms\n                      if (trigger == 0) {\n                        trigger = 1;\n                      }\n                      if ((seenTermCount + shift) % trigger == 0) {\n                        //if (VERBOSE) {\n                        //System.out.println(Thread.currentThread().getName() + \" now search body:\" + term.utf8ToString());\n                        //}\n                        totHits.addAndGet(runQuery(s, new TermQuery(new Term(\"body\", term))));\n                      }\n                    }\n                    if (VERBOSE) {\n                      System.out.println(Thread.currentThread().getName() + \": search done\");\n                    }\n                  }\n                } finally {\n                  nrt.release(s);\n                }\n              } catch (Throwable t) {\n                System.out.println(Thread.currentThread().getName() + \": FAILED: hit exc\");\n                failed.set(true);\n                t.printStackTrace(System.out);\n                throw new RuntimeException(t);\n              }\n            }\n          }\n        };\n      searchThreads[thread].setDaemon(true);\n      searchThreads[thread].start();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now join\");\n    }\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread].join();\n    }\n    for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n      searchThreads[thread].join();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: done join [\" + (System.currentTimeMillis()-t0) + \" ms]; addCount=\" + addCount + \" delCount=\" + delCount);\n      System.out.println(\"TEST: search totHits=\" + totHits);\n    }\n\n    long maxGen = 0;\n    for(long gen : lastGens) {\n      maxGen = Math.max(maxGen, gen);\n    }\n\n    final IndexSearcher s = nrt.get(maxGen, true);\n\n    boolean doFail = false;\n    for(String id : delIDs) {\n      final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", id)), 1);\n      if (hits.totalHits != 0) {\n        System.out.println(\"doc id=\" + id + \" is supposed to be deleted, but got docID=\" + hits.scoreDocs[0].doc);\n        doFail = true;\n      }\n    }\n\n    // Make sure each group of sub-docs are still in docID order:\n    for(SubDocs subDocs : allSubDocs) {\n      if (!subDocs.deleted) {\n        // We sort by relevance but the scores should be identical so sort falls back to by docID:\n        TopDocs hits = s.search(new TermQuery(new Term(\"packID\", subDocs.packID)), 20);\n        assertEquals(subDocs.subIDs.size(), hits.totalHits);\n        int lastDocID = -1;\n        int startDocID = -1;\n        for(ScoreDoc scoreDoc : hits.scoreDocs) {\n          final int docID = scoreDoc.doc;\n          if (lastDocID != -1) {\n            assertEquals(1+lastDocID, docID);\n          } else {\n            startDocID = docID;\n          }\n          lastDocID = docID;\n          final Document doc = s.doc(docID);\n          assertEquals(subDocs.packID, doc.get(\"packID\"));\n        }\n\n        lastDocID = startDocID - 1;\n        for(String subID : subDocs.subIDs) {\n          hits = s.search(new TermQuery(new Term(\"docid\", subID)), 1);\n          assertEquals(1, hits.totalHits);\n          final int docID = hits.scoreDocs[0].doc;\n          if (lastDocID != -1) {\n            assertEquals(1+lastDocID, docID);\n          }\n          lastDocID = docID;\n        }          \n      } else {\n        for(String subID : subDocs.subIDs) {\n          assertEquals(0, s.search(new TermQuery(new Term(\"docid\", subID)), 1).totalHits);\n        }\n      }\n    }\n    \n    final int endID = Integer.parseInt(docs.nextDoc().get(\"docid\"));\n    for(int id=0;id<endID;id++) {\n      String stringID = \"\"+id;\n      if (!delIDs.contains(stringID)) {\n        final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", stringID)), 1);\n        if (hits.totalHits != 1) {\n          System.out.println(\"doc id=\" + stringID + \" is not supposed to be deleted, but got hitCount=\" + hits.totalHits);\n          doFail = true;\n        }\n      }\n    }\n    assertFalse(doFail);\n\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), s.getIndexReader().numDocs());\n    nrt.release(s);\n\n    if (es != null) {\n      es.shutdown();\n      es.awaitTermination(1, TimeUnit.SECONDS);\n    }\n\n    writer.commit();\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), writer.numDocs());\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now close NRTManager\");\n    }\n    nrtThread.close();\n    nrt.close();\n    assertFalse(writer.anyNonBulkMerges);\n    writer.close(false);\n    _TestUtil.checkIndex(dir);\n    dir.close();\n    _TestUtil.rmDir(tempDir);\n    docs.close();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e7bd246bb7bc35ac22edfee9157e034dfc4e65eb","date":1309960478,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/contrib/misc/src/test/org/apache/lucene/index/TestNRTManager#testNRTManager().mjava","pathOld":"lucene/contrib/misc/src/test/org/apache/lucene/index/TestNRTManager#testNRTManager().mjava","sourceNew":"  @Test\n  public void testNRTManager() throws Exception {\n\n    final long t0 = System.currentTimeMillis();\n\n    if (CodecProvider.getDefault().getDefaultFieldCodec().equals(\"SimpleText\")) {\n      // no\n      CodecProvider.getDefault().setDefaultFieldCodec(\"Standard\");\n    }\n\n    final LineFileDocs docs = new LineFileDocs(random);\n    final File tempDir = _TestUtil.getTempDir(\"nrtopenfiles\");\n    final MockDirectoryWrapper _dir = newFSDirectory(tempDir);\n    _dir.setCheckIndexOnClose(false);  // don't double-checkIndex, we do it ourselves\n    Directory dir = _dir;\n    final IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).setOpenMode(IndexWriterConfig.OpenMode.CREATE);\n\n    if (LuceneTestCase.TEST_NIGHTLY) {\n      // newIWConfig makes smallish max seg size, which\n      // results in tons and tons of segments for this test\n      // when run nightly:\n      MergePolicy mp = conf.getMergePolicy();\n      if (mp instanceof TieredMergePolicy) {\n        ((TieredMergePolicy) mp).setMaxMergedSegmentMB(5000.);\n      } else if (mp instanceof LogByteSizeMergePolicy) {\n        ((LogByteSizeMergePolicy) mp).setMaxMergeMB(1000.);\n      } else if (mp instanceof LogMergePolicy) {\n        ((LogMergePolicy) mp).setMaxMergeDocs(100000);\n      }\n    }\n\n    conf.setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n      @Override\n      public void warm(IndexReader reader) throws IOException {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now warm merged reader=\" + reader);\n        }\n        final int maxDoc = reader.maxDoc();\n        final Bits liveDocs = reader.getLiveDocs();\n        int sum = 0;\n        final int inc = Math.max(1, maxDoc/50);\n        for(int docID=0;docID<maxDoc;docID += inc) {\n          if (liveDocs == null || liveDocs.get(docID)) {\n            final Document doc = reader.document(docID);\n            sum += doc.getFields().size();\n          }\n        }\n\n        IndexSearcher searcher = newSearcher(reader);\n        sum += searcher.search(new TermQuery(new Term(\"body\", \"united\")), 10).totalHits;\n        searcher.close();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: warm visited \" + sum + \" fields\");\n        }\n      }\n      });\n\n    if (random.nextBoolean()) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: wrap NRTCachingDir\");\n      }\n\n      NRTCachingDirectory nrtDir = new NRTCachingDirectory(dir, 5.0, 60.0);\n      conf.setMergeScheduler(nrtDir.getMergeScheduler());\n      dir = nrtDir;\n    }\n    \n    final IndexWriter writer = new IndexWriter(dir, conf);\n    \n    if (VERBOSE) {\n      writer.setInfoStream(System.out);\n    }\n    _TestUtil.reduceOpenFiles(writer);\n    //System.out.println(\"TEST: conf=\" + writer.getConfig());\n\n    final ExecutorService es = random.nextBoolean() ? null : Executors.newCachedThreadPool(new NamedThreadFactory(\"NRT search threads\"));\n\n    final double minReopenSec = 0.01 + 0.05 * random.nextDouble();\n    final double maxReopenSec = minReopenSec * (1.0 + 10 * random.nextDouble());\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: make NRTManager maxReopenSec=\" + maxReopenSec + \" minReopenSec=\" + minReopenSec);\n    }\n\n    final NRTManager nrt = new NRTManager(writer, es);\n    final NRTManagerReopenThread nrtThread = new NRTManagerReopenThread(nrt, maxReopenSec, minReopenSec);\n    nrtThread.setName(\"NRT Reopen Thread\");\n    nrtThread.setPriority(Math.min(Thread.currentThread().getPriority()+2, Thread.MAX_PRIORITY));\n    nrtThread.setDaemon(true);\n    nrtThread.start();\n\n    final int NUM_INDEX_THREADS = _TestUtil.nextInt(random, 1, 3);\n    final int NUM_SEARCH_THREADS = _TestUtil.nextInt(random, 1, 3);\n    //final int NUM_INDEX_THREADS = 1;\n    //final int NUM_SEARCH_THREADS = 1;\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + NUM_INDEX_THREADS + \" index threads; \" + NUM_SEARCH_THREADS + \" search threads\");\n    }\n\n    final int RUN_TIME_SEC = LuceneTestCase.TEST_NIGHTLY ? 300 : RANDOM_MULTIPLIER;\n\n    final AtomicBoolean failed = new AtomicBoolean();\n    final AtomicInteger addCount = new AtomicInteger();\n    final AtomicInteger delCount = new AtomicInteger();\n    final AtomicInteger packCount = new AtomicInteger();\n    final List<Long> lastGens = new ArrayList<Long>();\n\n    final Set<String> delIDs = Collections.synchronizedSet(new HashSet<String>());\n    final List<SubDocs> allSubDocs = Collections.synchronizedList(new ArrayList<SubDocs>());\n\n    final long stopTime = System.currentTimeMillis() + RUN_TIME_SEC*1000;\n    Thread[] threads = new Thread[NUM_INDEX_THREADS];\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread] = new Thread() {\n          @Override\n          public void run() {\n            // TODO: would be better if this were cross thread, so that we make sure one thread deleting anothers added docs works:\n            final List<String> toDeleteIDs = new ArrayList<String>();\n            final List<SubDocs> toDeleteSubDocs = new ArrayList<SubDocs>();\n\n            long gen = 0;\n            while(System.currentTimeMillis() < stopTime && !failed.get()) {\n\n              //System.out.println(Thread.currentThread().getName() + \": cycle\");\n              try {\n                // Occassional longish pause if running\n                // nightly\n                if (LuceneTestCase.TEST_NIGHTLY && random.nextInt(6) == 3) {\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": now long sleep\");\n                  }\n                  Thread.sleep(_TestUtil.nextInt(random, 50, 500));\n                }\n\n                // Rate limit ingest rate:\n                Thread.sleep(_TestUtil.nextInt(random, 1, 10));\n                if (VERBOSE) {\n                  System.out.println(Thread.currentThread() + \": done sleep\");\n                }\n\n                Document doc = docs.nextDoc();\n                if (doc == null) {\n                  break;\n                }\n                final String addedField;\n                if (random.nextBoolean()) {\n                  addedField = \"extra\" + random.nextInt(10);\n                  doc.add(new Field(addedField, \"a random field\", Field.Store.NO, Field.Index.ANALYZED));\n                } else {\n                  addedField = null;\n                }\n                if (random.nextBoolean()) {\n\n                  if (random.nextBoolean()) {\n                    // Add a pack of adjacent sub-docs\n                    final String packID;\n                    final SubDocs delSubDocs;\n                    if (toDeleteSubDocs.size() > 0 && random.nextBoolean()) {\n                      delSubDocs = toDeleteSubDocs.get(random.nextInt(toDeleteSubDocs.size()));\n                      assert !delSubDocs.deleted;\n                      toDeleteSubDocs.remove(delSubDocs);\n                      // reuse prior packID\n                      packID = delSubDocs.packID;\n                    } else {\n                      delSubDocs = null;\n                      // make new packID\n                      packID = packCount.getAndIncrement() + \"\";\n                    }\n\n                    final Field packIDField = newField(\"packID\", packID, Field.Store.YES, Field.Index.NOT_ANALYZED);\n                    final List<String> docIDs = new ArrayList<String>();\n                    final SubDocs subDocs = new SubDocs(packID, docIDs);\n                    final List<Document> docsList = new ArrayList<Document>();\n\n                    allSubDocs.add(subDocs);\n                    doc.add(packIDField);\n                    docsList.add(cloneDoc(doc));\n                    docIDs.add(doc.get(\"docid\"));\n\n                    final int maxDocCount = _TestUtil.nextInt(random, 1, 10);\n                    while(docsList.size() < maxDocCount) {\n                      doc = docs.nextDoc();\n                      if (doc == null) {\n                        break;\n                      }\n                      docsList.add(cloneDoc(doc));\n                      docIDs.add(doc.get(\"docid\"));\n                    }\n                    addCount.addAndGet(docsList.size());\n\n                    if (delSubDocs != null) {\n                      delSubDocs.deleted = true;\n                      delIDs.addAll(delSubDocs.subIDs);\n                      delCount.addAndGet(delSubDocs.subIDs.size());\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: update pack packID=\" + delSubDocs.packID + \" count=\" + docsList.size() + \" docs=\" + docIDs);\n                      }\n                      gen = nrt.updateDocuments(new Term(\"packID\", delSubDocs.packID), docsList);\n                      /*\n                      // non-atomic:\n                      nrt.deleteDocuments(new Term(\"packID\", delSubDocs.packID));\n                      for(Document subDoc : docsList) {\n                        nrt.addDocument(subDoc);\n                      }\n                      */\n                    } else {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: add pack packID=\" + packID + \" count=\" + docsList.size() + \" docs=\" + docIDs);\n                      }\n                      gen = nrt.addDocuments(docsList);\n                      \n                      /*\n                      // non-atomic:\n                      for(Document subDoc : docsList) {\n                        nrt.addDocument(subDoc);\n                      }\n                      */\n                    }\n                    doc.removeField(\"packID\");\n\n                    if (random.nextInt(5) == 2) {\n                      if (VERBOSE) {\n                        System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + packID);\n                      }\n                      toDeleteSubDocs.add(subDocs);\n                    }\n\n                    // randomly verify the add/update \"took\":\n                    if (random.nextInt(20) == 2) {\n                      final boolean applyDeletes = delSubDocs != null;\n                      final IndexSearcher s = nrt.get(gen, applyDeletes);\n                      try {\n                        assertEquals(docsList.size(), s.search(new TermQuery(new Term(\"packID\", packID)), 10).totalHits);\n                      } finally {\n                        nrt.release(s);\n                      }\n                    }\n\n                  } else {\n                    if (VERBOSE) {\n                      System.out.println(Thread.currentThread().getName() + \": add doc docid:\" + doc.get(\"docid\"));\n                    }\n\n                    gen = nrt.addDocument(doc);\n                    addCount.getAndIncrement();\n\n                    // randomly verify the add \"took\":\n                    if (random.nextInt(20) == 2) {\n                      //System.out.println(Thread.currentThread().getName() + \": verify\");\n                      final IndexSearcher s = nrt.get(gen, false);\n                      //System.out.println(Thread.currentThread().getName() + \": got s=\" + s);\n                      try {\n                        assertEquals(1, s.search(new TermQuery(new Term(\"docid\", doc.get(\"docid\"))), 10).totalHits);\n                      } finally {\n                        nrt.release(s);\n                      }\n                      //System.out.println(Thread.currentThread().getName() + \": done verify\");\n                    }\n\n                    if (random.nextInt(5) == 3) {\n                      if (VERBOSE) {\n                        System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                      }\n                      toDeleteIDs.add(doc.get(\"docid\"));\n                    }\n                  }\n                } else {\n                  // we use update but it never replaces a\n                  // prior doc\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": update doc id:\" + doc.get(\"docid\"));\n                  }\n                  gen = nrt.updateDocument(new Term(\"docid\", doc.get(\"docid\")), doc);\n                  addCount.getAndIncrement();\n\n                  // randomly verify the add \"took\":\n                  if (random.nextInt(20) == 2) {\n                    final IndexSearcher s = nrt.get(gen, true);\n                    try {\n                      assertEquals(1, s.search(new TermQuery(new Term(\"docid\", doc.get(\"docid\"))), 10).totalHits);\n                    } finally {\n                      nrt.release(s);\n                    }\n                  }\n\n                  if (random.nextInt(5) == 3) {\n                    if (VERBOSE) {\n                      System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                    }\n                    toDeleteIDs.add(doc.get(\"docid\"));\n                  }\n                }\n\n                if (random.nextInt(30) == 17) {\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": apply \" + toDeleteIDs.size() + \" deletes\");\n                  }\n                  for(String id : toDeleteIDs) {\n                    if (VERBOSE) {\n                      System.out.println(Thread.currentThread().getName() + \": del term=id:\" + id);\n                    }\n                    gen = nrt.deleteDocuments(new Term(\"docid\", id));\n\n                    // randomly verify the delete \"took\":\n                    if (random.nextInt(20) == 7) {\n                      final IndexSearcher s = nrt.get(gen, true);\n                      try {\n                        assertEquals(0, s.search(new TermQuery(new Term(\"docid\", id)), 10).totalHits);\n                      } finally {\n                        nrt.release(s);\n                      }\n                    }\n                  }\n\n                  final int count = delCount.addAndGet(toDeleteIDs.size());\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": tot \" + count + \" deletes\");\n                  }\n                  delIDs.addAll(toDeleteIDs);\n                  toDeleteIDs.clear();\n\n                  for(SubDocs subDocs : toDeleteSubDocs) {\n                    assertTrue(!subDocs.deleted);\n                    gen = nrt.deleteDocuments(new Term(\"packID\", subDocs.packID));\n                    subDocs.deleted = true;\n                    if (VERBOSE) {\n                      System.out.println(\"  del subs: \" + subDocs.subIDs + \" packID=\" + subDocs.packID);\n                    }\n                    delIDs.addAll(subDocs.subIDs);\n                    delCount.addAndGet(subDocs.subIDs.size());\n\n                    // randomly verify the delete \"took\":\n                    if (random.nextInt(20) == 7) {\n                      final IndexSearcher s = nrt.get(gen, true);\n                      try {\n                        assertEquals(0, s.search(new TermQuery(new Term(\"packID\", subDocs.packID)), 1).totalHits);\n                      } finally {\n                        nrt.release(s);\n                      }\n                    }\n                  }\n                  toDeleteSubDocs.clear();\n                }\n                if (addedField != null) {\n                  doc.removeField(addedField);\n                }\n              } catch (Throwable t) {\n                System.out.println(Thread.currentThread().getName() + \": FAILED: hit exc\");\n                t.printStackTrace();\n                failed.set(true);\n                throw new RuntimeException(t);\n              }\n            }\n\n            lastGens.add(gen);\n            if (VERBOSE) {\n              System.out.println(Thread.currentThread().getName() + \": indexing done\");\n            }\n          }\n        };\n      threads[thread].setDaemon(true);\n      threads[thread].start();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: DONE start indexing threads [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    // let index build up a bit\n    Thread.sleep(100);\n\n    // silly starting guess:\n    final AtomicInteger totTermCount = new AtomicInteger(100);\n\n    // run search threads\n    final Thread[] searchThreads = new Thread[NUM_SEARCH_THREADS];\n    final AtomicInteger totHits = new AtomicInteger();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: start search threads\");\n    }\n\n    for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n      searchThreads[thread] = new Thread() {\n          @Override\n          public void run() {\n            while(System.currentTimeMillis() < stopTime && !failed.get()) {\n              final IndexSearcher s = nrt.get(random.nextBoolean());\n              try {\n                try {\n                  smokeTestSearcher(s);\n                  if (s.getIndexReader().numDocs() > 0) {\n                    Fields fields = MultiFields.getFields(s.getIndexReader());\n                    if (fields == null) {\n                      continue;\n                    }\n                    Terms terms = fields.terms(\"body\");\n                    if (terms == null) {\n                      continue;\n                    }\n\n                    TermsEnum termsEnum = terms.iterator();\n                    int seenTermCount = 0;\n                    int shift;\n                    int trigger;\n                    if (totTermCount.get() < 10) {\n                      shift = 0;\n                      trigger = 1;\n                    } else {\n                      trigger = totTermCount.get()/10;\n                      shift = random.nextInt(trigger);\n                    }\n\n                    while(System.currentTimeMillis() < stopTime) {\n                      BytesRef term = termsEnum.next();\n                      if (term == null) {\n                        if (seenTermCount == 0) {\n                          break;\n                        }\n                        totTermCount.set(seenTermCount);\n                        seenTermCount = 0;\n                        if (totTermCount.get() < 10) {\n                          shift = 0;\n                          trigger = 1;\n                        } else {\n                          trigger = totTermCount.get()/10;\n                          //System.out.println(\"trigger \" + trigger);\n                          shift = random.nextInt(trigger);\n                        }\n                        termsEnum.seekCeil(new BytesRef(\"\"));\n                        continue;\n                      }\n                      seenTermCount++;\n                      // search 10 terms\n                      if (trigger == 0) {\n                        trigger = 1;\n                      }\n                      if ((seenTermCount + shift) % trigger == 0) {\n                        //if (VERBOSE) {\n                        //System.out.println(Thread.currentThread().getName() + \" now search body:\" + term.utf8ToString());\n                        //}\n                        totHits.addAndGet(runQuery(s, new TermQuery(new Term(\"body\", term))));\n                      }\n                    }\n                    if (VERBOSE) {\n                      System.out.println(Thread.currentThread().getName() + \": search done\");\n                    }\n                  }\n                } finally {\n                  nrt.release(s);\n                }\n              } catch (Throwable t) {\n                System.out.println(Thread.currentThread().getName() + \": FAILED: hit exc\");\n                failed.set(true);\n                t.printStackTrace(System.out);\n                throw new RuntimeException(t);\n              }\n            }\n          }\n        };\n      searchThreads[thread].setDaemon(true);\n      searchThreads[thread].start();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now join\");\n    }\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread].join();\n    }\n    for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n      searchThreads[thread].join();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: done join [\" + (System.currentTimeMillis()-t0) + \" ms]; addCount=\" + addCount + \" delCount=\" + delCount);\n      System.out.println(\"TEST: search totHits=\" + totHits);\n    }\n\n    long maxGen = 0;\n    for(long gen : lastGens) {\n      maxGen = Math.max(maxGen, gen);\n    }\n\n    final IndexSearcher s = nrt.get(maxGen, true);\n\n    boolean doFail = false;\n    for(String id : delIDs) {\n      final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", id)), 1);\n      if (hits.totalHits != 0) {\n        System.out.println(\"doc id=\" + id + \" is supposed to be deleted, but got docID=\" + hits.scoreDocs[0].doc);\n        doFail = true;\n      }\n    }\n\n    // Make sure each group of sub-docs are still in docID order:\n    for(SubDocs subDocs : allSubDocs) {\n      if (!subDocs.deleted) {\n        // We sort by relevance but the scores should be identical so sort falls back to by docID:\n        TopDocs hits = s.search(new TermQuery(new Term(\"packID\", subDocs.packID)), 20);\n        assertEquals(subDocs.subIDs.size(), hits.totalHits);\n        int lastDocID = -1;\n        int startDocID = -1;\n        for(ScoreDoc scoreDoc : hits.scoreDocs) {\n          final int docID = scoreDoc.doc;\n          if (lastDocID != -1) {\n            assertEquals(1+lastDocID, docID);\n          } else {\n            startDocID = docID;\n          }\n          lastDocID = docID;\n          final Document doc = s.doc(docID);\n          assertEquals(subDocs.packID, doc.get(\"packID\"));\n        }\n\n        lastDocID = startDocID - 1;\n        for(String subID : subDocs.subIDs) {\n          hits = s.search(new TermQuery(new Term(\"docid\", subID)), 1);\n          assertEquals(1, hits.totalHits);\n          final int docID = hits.scoreDocs[0].doc;\n          if (lastDocID != -1) {\n            assertEquals(1+lastDocID, docID);\n          }\n          lastDocID = docID;\n        }          \n      } else {\n        for(String subID : subDocs.subIDs) {\n          assertEquals(0, s.search(new TermQuery(new Term(\"docid\", subID)), 1).totalHits);\n        }\n      }\n    }\n    \n    final int endID = Integer.parseInt(docs.nextDoc().get(\"docid\"));\n    for(int id=0;id<endID;id++) {\n      String stringID = \"\"+id;\n      if (!delIDs.contains(stringID)) {\n        final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", stringID)), 1);\n        if (hits.totalHits != 1) {\n          System.out.println(\"doc id=\" + stringID + \" is not supposed to be deleted, but got hitCount=\" + hits.totalHits);\n          doFail = true;\n        }\n      }\n    }\n    assertFalse(doFail);\n\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), s.getIndexReader().numDocs());\n    nrt.release(s);\n\n    if (es != null) {\n      es.shutdown();\n      es.awaitTermination(1, TimeUnit.SECONDS);\n    }\n\n    writer.commit();\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), writer.numDocs());\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now close NRTManager\");\n    }\n    nrtThread.close();\n    nrt.close();\n    assertFalse(writer.anyNonBulkMerges);\n    writer.close(false);\n    _TestUtil.checkIndex(dir);\n    dir.close();\n    _TestUtil.rmDir(tempDir);\n    docs.close();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testNRTManager() throws Exception {\n\n    final long t0 = System.currentTimeMillis();\n\n    if (CodecProvider.getDefault().getDefaultFieldCodec().equals(\"SimpleText\")) {\n      // no\n      CodecProvider.getDefault().setDefaultFieldCodec(\"Standard\");\n    }\n\n    final LineFileDocs docs = new LineFileDocs(random);\n    final File tempDir = _TestUtil.getTempDir(\"nrtopenfiles\");\n    final MockDirectoryWrapper _dir = newFSDirectory(tempDir);\n    _dir.setCheckIndexOnClose(false);  // don't double-checkIndex, we do it ourselves\n    Directory dir = _dir;\n    final IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).setOpenMode(IndexWriterConfig.OpenMode.CREATE);\n\n    if (LuceneTestCase.TEST_NIGHTLY) {\n      // newIWConfig makes smallish max seg size, which\n      // results in tons and tons of segments for this test\n      // when run nightly:\n      MergePolicy mp = conf.getMergePolicy();\n      if (mp instanceof TieredMergePolicy) {\n        ((TieredMergePolicy) mp).setMaxMergedSegmentMB(5000.);\n      } else if (mp instanceof LogByteSizeMergePolicy) {\n        ((LogByteSizeMergePolicy) mp).setMaxMergeMB(1000.);\n      } else if (mp instanceof LogMergePolicy) {\n        ((LogMergePolicy) mp).setMaxMergeDocs(100000);\n      }\n    }\n\n    conf.setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n      @Override\n      public void warm(IndexReader reader) throws IOException {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now warm merged reader=\" + reader);\n        }\n        final int maxDoc = reader.maxDoc();\n        final Bits delDocs = reader.getDeletedDocs();\n        int sum = 0;\n        final int inc = Math.max(1, maxDoc/50);\n        for(int docID=0;docID<maxDoc;docID += inc) {\n          if (delDocs == null || !delDocs.get(docID)) {\n            final Document doc = reader.document(docID);\n            sum += doc.getFields().size();\n          }\n        }\n\n        IndexSearcher searcher = newSearcher(reader);\n        sum += searcher.search(new TermQuery(new Term(\"body\", \"united\")), 10).totalHits;\n        searcher.close();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: warm visited \" + sum + \" fields\");\n        }\n      }\n      });\n\n    if (random.nextBoolean()) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: wrap NRTCachingDir\");\n      }\n\n      NRTCachingDirectory nrtDir = new NRTCachingDirectory(dir, 5.0, 60.0);\n      conf.setMergeScheduler(nrtDir.getMergeScheduler());\n      dir = nrtDir;\n    }\n    \n    final IndexWriter writer = new IndexWriter(dir, conf);\n    \n    if (VERBOSE) {\n      writer.setInfoStream(System.out);\n    }\n    _TestUtil.reduceOpenFiles(writer);\n    //System.out.println(\"TEST: conf=\" + writer.getConfig());\n\n    final ExecutorService es = random.nextBoolean() ? null : Executors.newCachedThreadPool(new NamedThreadFactory(\"NRT search threads\"));\n\n    final double minReopenSec = 0.01 + 0.05 * random.nextDouble();\n    final double maxReopenSec = minReopenSec * (1.0 + 10 * random.nextDouble());\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: make NRTManager maxReopenSec=\" + maxReopenSec + \" minReopenSec=\" + minReopenSec);\n    }\n\n    final NRTManager nrt = new NRTManager(writer, es);\n    final NRTManagerReopenThread nrtThread = new NRTManagerReopenThread(nrt, maxReopenSec, minReopenSec);\n    nrtThread.setName(\"NRT Reopen Thread\");\n    nrtThread.setPriority(Math.min(Thread.currentThread().getPriority()+2, Thread.MAX_PRIORITY));\n    nrtThread.setDaemon(true);\n    nrtThread.start();\n\n    final int NUM_INDEX_THREADS = _TestUtil.nextInt(random, 1, 3);\n    final int NUM_SEARCH_THREADS = _TestUtil.nextInt(random, 1, 3);\n    //final int NUM_INDEX_THREADS = 1;\n    //final int NUM_SEARCH_THREADS = 1;\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + NUM_INDEX_THREADS + \" index threads; \" + NUM_SEARCH_THREADS + \" search threads\");\n    }\n\n    final int RUN_TIME_SEC = LuceneTestCase.TEST_NIGHTLY ? 300 : RANDOM_MULTIPLIER;\n\n    final AtomicBoolean failed = new AtomicBoolean();\n    final AtomicInteger addCount = new AtomicInteger();\n    final AtomicInteger delCount = new AtomicInteger();\n    final AtomicInteger packCount = new AtomicInteger();\n    final List<Long> lastGens = new ArrayList<Long>();\n\n    final Set<String> delIDs = Collections.synchronizedSet(new HashSet<String>());\n    final List<SubDocs> allSubDocs = Collections.synchronizedList(new ArrayList<SubDocs>());\n\n    final long stopTime = System.currentTimeMillis() + RUN_TIME_SEC*1000;\n    Thread[] threads = new Thread[NUM_INDEX_THREADS];\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread] = new Thread() {\n          @Override\n          public void run() {\n            // TODO: would be better if this were cross thread, so that we make sure one thread deleting anothers added docs works:\n            final List<String> toDeleteIDs = new ArrayList<String>();\n            final List<SubDocs> toDeleteSubDocs = new ArrayList<SubDocs>();\n\n            long gen = 0;\n            while(System.currentTimeMillis() < stopTime && !failed.get()) {\n\n              //System.out.println(Thread.currentThread().getName() + \": cycle\");\n              try {\n                // Occassional longish pause if running\n                // nightly\n                if (LuceneTestCase.TEST_NIGHTLY && random.nextInt(6) == 3) {\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": now long sleep\");\n                  }\n                  Thread.sleep(_TestUtil.nextInt(random, 50, 500));\n                }\n\n                // Rate limit ingest rate:\n                Thread.sleep(_TestUtil.nextInt(random, 1, 10));\n                if (VERBOSE) {\n                  System.out.println(Thread.currentThread() + \": done sleep\");\n                }\n\n                Document doc = docs.nextDoc();\n                if (doc == null) {\n                  break;\n                }\n                final String addedField;\n                if (random.nextBoolean()) {\n                  addedField = \"extra\" + random.nextInt(10);\n                  doc.add(new Field(addedField, \"a random field\", Field.Store.NO, Field.Index.ANALYZED));\n                } else {\n                  addedField = null;\n                }\n                if (random.nextBoolean()) {\n\n                  if (random.nextBoolean()) {\n                    // Add a pack of adjacent sub-docs\n                    final String packID;\n                    final SubDocs delSubDocs;\n                    if (toDeleteSubDocs.size() > 0 && random.nextBoolean()) {\n                      delSubDocs = toDeleteSubDocs.get(random.nextInt(toDeleteSubDocs.size()));\n                      assert !delSubDocs.deleted;\n                      toDeleteSubDocs.remove(delSubDocs);\n                      // reuse prior packID\n                      packID = delSubDocs.packID;\n                    } else {\n                      delSubDocs = null;\n                      // make new packID\n                      packID = packCount.getAndIncrement() + \"\";\n                    }\n\n                    final Field packIDField = newField(\"packID\", packID, Field.Store.YES, Field.Index.NOT_ANALYZED);\n                    final List<String> docIDs = new ArrayList<String>();\n                    final SubDocs subDocs = new SubDocs(packID, docIDs);\n                    final List<Document> docsList = new ArrayList<Document>();\n\n                    allSubDocs.add(subDocs);\n                    doc.add(packIDField);\n                    docsList.add(cloneDoc(doc));\n                    docIDs.add(doc.get(\"docid\"));\n\n                    final int maxDocCount = _TestUtil.nextInt(random, 1, 10);\n                    while(docsList.size() < maxDocCount) {\n                      doc = docs.nextDoc();\n                      if (doc == null) {\n                        break;\n                      }\n                      docsList.add(cloneDoc(doc));\n                      docIDs.add(doc.get(\"docid\"));\n                    }\n                    addCount.addAndGet(docsList.size());\n\n                    if (delSubDocs != null) {\n                      delSubDocs.deleted = true;\n                      delIDs.addAll(delSubDocs.subIDs);\n                      delCount.addAndGet(delSubDocs.subIDs.size());\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: update pack packID=\" + delSubDocs.packID + \" count=\" + docsList.size() + \" docs=\" + docIDs);\n                      }\n                      gen = nrt.updateDocuments(new Term(\"packID\", delSubDocs.packID), docsList);\n                      /*\n                      // non-atomic:\n                      nrt.deleteDocuments(new Term(\"packID\", delSubDocs.packID));\n                      for(Document subDoc : docsList) {\n                        nrt.addDocument(subDoc);\n                      }\n                      */\n                    } else {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: add pack packID=\" + packID + \" count=\" + docsList.size() + \" docs=\" + docIDs);\n                      }\n                      gen = nrt.addDocuments(docsList);\n                      \n                      /*\n                      // non-atomic:\n                      for(Document subDoc : docsList) {\n                        nrt.addDocument(subDoc);\n                      }\n                      */\n                    }\n                    doc.removeField(\"packID\");\n\n                    if (random.nextInt(5) == 2) {\n                      if (VERBOSE) {\n                        System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + packID);\n                      }\n                      toDeleteSubDocs.add(subDocs);\n                    }\n\n                    // randomly verify the add/update \"took\":\n                    if (random.nextInt(20) == 2) {\n                      final boolean applyDeletes = delSubDocs != null;\n                      final IndexSearcher s = nrt.get(gen, applyDeletes);\n                      try {\n                        assertEquals(docsList.size(), s.search(new TermQuery(new Term(\"packID\", packID)), 10).totalHits);\n                      } finally {\n                        nrt.release(s);\n                      }\n                    }\n\n                  } else {\n                    if (VERBOSE) {\n                      System.out.println(Thread.currentThread().getName() + \": add doc docid:\" + doc.get(\"docid\"));\n                    }\n\n                    gen = nrt.addDocument(doc);\n                    addCount.getAndIncrement();\n\n                    // randomly verify the add \"took\":\n                    if (random.nextInt(20) == 2) {\n                      //System.out.println(Thread.currentThread().getName() + \": verify\");\n                      final IndexSearcher s = nrt.get(gen, false);\n                      //System.out.println(Thread.currentThread().getName() + \": got s=\" + s);\n                      try {\n                        assertEquals(1, s.search(new TermQuery(new Term(\"docid\", doc.get(\"docid\"))), 10).totalHits);\n                      } finally {\n                        nrt.release(s);\n                      }\n                      //System.out.println(Thread.currentThread().getName() + \": done verify\");\n                    }\n\n                    if (random.nextInt(5) == 3) {\n                      if (VERBOSE) {\n                        System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                      }\n                      toDeleteIDs.add(doc.get(\"docid\"));\n                    }\n                  }\n                } else {\n                  // we use update but it never replaces a\n                  // prior doc\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": update doc id:\" + doc.get(\"docid\"));\n                  }\n                  gen = nrt.updateDocument(new Term(\"docid\", doc.get(\"docid\")), doc);\n                  addCount.getAndIncrement();\n\n                  // randomly verify the add \"took\":\n                  if (random.nextInt(20) == 2) {\n                    final IndexSearcher s = nrt.get(gen, true);\n                    try {\n                      assertEquals(1, s.search(new TermQuery(new Term(\"docid\", doc.get(\"docid\"))), 10).totalHits);\n                    } finally {\n                      nrt.release(s);\n                    }\n                  }\n\n                  if (random.nextInt(5) == 3) {\n                    if (VERBOSE) {\n                      System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                    }\n                    toDeleteIDs.add(doc.get(\"docid\"));\n                  }\n                }\n\n                if (random.nextInt(30) == 17) {\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": apply \" + toDeleteIDs.size() + \" deletes\");\n                  }\n                  for(String id : toDeleteIDs) {\n                    if (VERBOSE) {\n                      System.out.println(Thread.currentThread().getName() + \": del term=id:\" + id);\n                    }\n                    gen = nrt.deleteDocuments(new Term(\"docid\", id));\n\n                    // randomly verify the delete \"took\":\n                    if (random.nextInt(20) == 7) {\n                      final IndexSearcher s = nrt.get(gen, true);\n                      try {\n                        assertEquals(0, s.search(new TermQuery(new Term(\"docid\", id)), 10).totalHits);\n                      } finally {\n                        nrt.release(s);\n                      }\n                    }\n                  }\n\n                  final int count = delCount.addAndGet(toDeleteIDs.size());\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": tot \" + count + \" deletes\");\n                  }\n                  delIDs.addAll(toDeleteIDs);\n                  toDeleteIDs.clear();\n\n                  for(SubDocs subDocs : toDeleteSubDocs) {\n                    assertTrue(!subDocs.deleted);\n                    gen = nrt.deleteDocuments(new Term(\"packID\", subDocs.packID));\n                    subDocs.deleted = true;\n                    if (VERBOSE) {\n                      System.out.println(\"  del subs: \" + subDocs.subIDs + \" packID=\" + subDocs.packID);\n                    }\n                    delIDs.addAll(subDocs.subIDs);\n                    delCount.addAndGet(subDocs.subIDs.size());\n\n                    // randomly verify the delete \"took\":\n                    if (random.nextInt(20) == 7) {\n                      final IndexSearcher s = nrt.get(gen, true);\n                      try {\n                        assertEquals(0, s.search(new TermQuery(new Term(\"packID\", subDocs.packID)), 1).totalHits);\n                      } finally {\n                        nrt.release(s);\n                      }\n                    }\n                  }\n                  toDeleteSubDocs.clear();\n                }\n                if (addedField != null) {\n                  doc.removeField(addedField);\n                }\n              } catch (Throwable t) {\n                System.out.println(Thread.currentThread().getName() + \": FAILED: hit exc\");\n                t.printStackTrace();\n                failed.set(true);\n                throw new RuntimeException(t);\n              }\n            }\n\n            lastGens.add(gen);\n            if (VERBOSE) {\n              System.out.println(Thread.currentThread().getName() + \": indexing done\");\n            }\n          }\n        };\n      threads[thread].setDaemon(true);\n      threads[thread].start();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: DONE start indexing threads [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    // let index build up a bit\n    Thread.sleep(100);\n\n    // silly starting guess:\n    final AtomicInteger totTermCount = new AtomicInteger(100);\n\n    // run search threads\n    final Thread[] searchThreads = new Thread[NUM_SEARCH_THREADS];\n    final AtomicInteger totHits = new AtomicInteger();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: start search threads\");\n    }\n\n    for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n      searchThreads[thread] = new Thread() {\n          @Override\n          public void run() {\n            while(System.currentTimeMillis() < stopTime && !failed.get()) {\n              final IndexSearcher s = nrt.get(random.nextBoolean());\n              try {\n                try {\n                  smokeTestSearcher(s);\n                  if (s.getIndexReader().numDocs() > 0) {\n                    Fields fields = MultiFields.getFields(s.getIndexReader());\n                    if (fields == null) {\n                      continue;\n                    }\n                    Terms terms = fields.terms(\"body\");\n                    if (terms == null) {\n                      continue;\n                    }\n\n                    TermsEnum termsEnum = terms.iterator();\n                    int seenTermCount = 0;\n                    int shift;\n                    int trigger;\n                    if (totTermCount.get() < 10) {\n                      shift = 0;\n                      trigger = 1;\n                    } else {\n                      trigger = totTermCount.get()/10;\n                      shift = random.nextInt(trigger);\n                    }\n\n                    while(System.currentTimeMillis() < stopTime) {\n                      BytesRef term = termsEnum.next();\n                      if (term == null) {\n                        if (seenTermCount == 0) {\n                          break;\n                        }\n                        totTermCount.set(seenTermCount);\n                        seenTermCount = 0;\n                        if (totTermCount.get() < 10) {\n                          shift = 0;\n                          trigger = 1;\n                        } else {\n                          trigger = totTermCount.get()/10;\n                          //System.out.println(\"trigger \" + trigger);\n                          shift = random.nextInt(trigger);\n                        }\n                        termsEnum.seekCeil(new BytesRef(\"\"));\n                        continue;\n                      }\n                      seenTermCount++;\n                      // search 10 terms\n                      if (trigger == 0) {\n                        trigger = 1;\n                      }\n                      if ((seenTermCount + shift) % trigger == 0) {\n                        //if (VERBOSE) {\n                        //System.out.println(Thread.currentThread().getName() + \" now search body:\" + term.utf8ToString());\n                        //}\n                        totHits.addAndGet(runQuery(s, new TermQuery(new Term(\"body\", term))));\n                      }\n                    }\n                    if (VERBOSE) {\n                      System.out.println(Thread.currentThread().getName() + \": search done\");\n                    }\n                  }\n                } finally {\n                  nrt.release(s);\n                }\n              } catch (Throwable t) {\n                System.out.println(Thread.currentThread().getName() + \": FAILED: hit exc\");\n                failed.set(true);\n                t.printStackTrace(System.out);\n                throw new RuntimeException(t);\n              }\n            }\n          }\n        };\n      searchThreads[thread].setDaemon(true);\n      searchThreads[thread].start();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now join\");\n    }\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread].join();\n    }\n    for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n      searchThreads[thread].join();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: done join [\" + (System.currentTimeMillis()-t0) + \" ms]; addCount=\" + addCount + \" delCount=\" + delCount);\n      System.out.println(\"TEST: search totHits=\" + totHits);\n    }\n\n    long maxGen = 0;\n    for(long gen : lastGens) {\n      maxGen = Math.max(maxGen, gen);\n    }\n\n    final IndexSearcher s = nrt.get(maxGen, true);\n\n    boolean doFail = false;\n    for(String id : delIDs) {\n      final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", id)), 1);\n      if (hits.totalHits != 0) {\n        System.out.println(\"doc id=\" + id + \" is supposed to be deleted, but got docID=\" + hits.scoreDocs[0].doc);\n        doFail = true;\n      }\n    }\n\n    // Make sure each group of sub-docs are still in docID order:\n    for(SubDocs subDocs : allSubDocs) {\n      if (!subDocs.deleted) {\n        // We sort by relevance but the scores should be identical so sort falls back to by docID:\n        TopDocs hits = s.search(new TermQuery(new Term(\"packID\", subDocs.packID)), 20);\n        assertEquals(subDocs.subIDs.size(), hits.totalHits);\n        int lastDocID = -1;\n        int startDocID = -1;\n        for(ScoreDoc scoreDoc : hits.scoreDocs) {\n          final int docID = scoreDoc.doc;\n          if (lastDocID != -1) {\n            assertEquals(1+lastDocID, docID);\n          } else {\n            startDocID = docID;\n          }\n          lastDocID = docID;\n          final Document doc = s.doc(docID);\n          assertEquals(subDocs.packID, doc.get(\"packID\"));\n        }\n\n        lastDocID = startDocID - 1;\n        for(String subID : subDocs.subIDs) {\n          hits = s.search(new TermQuery(new Term(\"docid\", subID)), 1);\n          assertEquals(1, hits.totalHits);\n          final int docID = hits.scoreDocs[0].doc;\n          if (lastDocID != -1) {\n            assertEquals(1+lastDocID, docID);\n          }\n          lastDocID = docID;\n        }          \n      } else {\n        for(String subID : subDocs.subIDs) {\n          assertEquals(0, s.search(new TermQuery(new Term(\"docid\", subID)), 1).totalHits);\n        }\n      }\n    }\n    \n    final int endID = Integer.parseInt(docs.nextDoc().get(\"docid\"));\n    for(int id=0;id<endID;id++) {\n      String stringID = \"\"+id;\n      if (!delIDs.contains(stringID)) {\n        final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", stringID)), 1);\n        if (hits.totalHits != 1) {\n          System.out.println(\"doc id=\" + stringID + \" is not supposed to be deleted, but got hitCount=\" + hits.totalHits);\n          doFail = true;\n        }\n      }\n    }\n    assertFalse(doFail);\n\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), s.getIndexReader().numDocs());\n    nrt.release(s);\n\n    if (es != null) {\n      es.shutdown();\n      es.awaitTermination(1, TimeUnit.SECONDS);\n    }\n\n    writer.commit();\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), writer.numDocs());\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now close NRTManager\");\n    }\n    nrtThread.close();\n    nrt.close();\n    assertFalse(writer.anyNonBulkMerges);\n    writer.close(false);\n    _TestUtil.checkIndex(dir);\n    dir.close();\n    _TestUtil.rmDir(tempDir);\n    docs.close();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"817d8435e9135b756f08ce6710ab0baac51bdf88","date":1309986993,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/contrib/misc/src/test/org/apache/lucene/index/TestNRTManager#testNRTManager().mjava","pathOld":"lucene/contrib/misc/src/test/org/apache/lucene/index/TestNRTManager#testNRTManager().mjava","sourceNew":"  @Test\n  public void testNRTManager() throws Exception {\n\n    final long t0 = System.currentTimeMillis();\n\n    if (CodecProvider.getDefault().getDefaultFieldCodec().equals(\"SimpleText\")) {\n      // no\n      CodecProvider.getDefault().setDefaultFieldCodec(\"Standard\");\n    }\n\n    final LineFileDocs docs = new LineFileDocs(random);\n    final File tempDir = _TestUtil.getTempDir(\"nrtopenfiles\");\n    final MockDirectoryWrapper _dir = newFSDirectory(tempDir);\n    _dir.setCheckIndexOnClose(false);  // don't double-checkIndex, we do it ourselves\n    Directory dir = _dir;\n    final IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).setOpenMode(IndexWriterConfig.OpenMode.CREATE);\n\n    if (LuceneTestCase.TEST_NIGHTLY) {\n      // newIWConfig makes smallish max seg size, which\n      // results in tons and tons of segments for this test\n      // when run nightly:\n      MergePolicy mp = conf.getMergePolicy();\n      if (mp instanceof TieredMergePolicy) {\n        ((TieredMergePolicy) mp).setMaxMergedSegmentMB(5000.);\n      } else if (mp instanceof LogByteSizeMergePolicy) {\n        ((LogByteSizeMergePolicy) mp).setMaxMergeMB(1000.);\n      } else if (mp instanceof LogMergePolicy) {\n        ((LogMergePolicy) mp).setMaxMergeDocs(100000);\n      }\n    }\n\n    conf.setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n      @Override\n      public void warm(IndexReader reader) throws IOException {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now warm merged reader=\" + reader);\n        }\n        final int maxDoc = reader.maxDoc();\n        final Bits liveDocs = reader.getLiveDocs();\n        int sum = 0;\n        final int inc = Math.max(1, maxDoc/50);\n        for(int docID=0;docID<maxDoc;docID += inc) {\n          if (liveDocs == null || liveDocs.get(docID)) {\n            final Document doc = reader.document(docID);\n            sum += doc.getFields().size();\n          }\n        }\n\n        IndexSearcher searcher = newSearcher(reader);\n        sum += searcher.search(new TermQuery(new Term(\"body\", \"united\")), 10).totalHits;\n        searcher.close();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: warm visited \" + sum + \" fields\");\n        }\n      }\n      });\n\n    if (random.nextBoolean()) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: wrap NRTCachingDir\");\n      }\n\n      NRTCachingDirectory nrtDir = new NRTCachingDirectory(dir, 5.0, 60.0);\n      conf.setMergeScheduler(nrtDir.getMergeScheduler());\n      dir = nrtDir;\n    }\n    \n    final IndexWriter writer = new IndexWriter(dir, conf);\n    \n    if (VERBOSE) {\n      writer.setInfoStream(System.out);\n    }\n    _TestUtil.reduceOpenFiles(writer);\n    //System.out.println(\"TEST: conf=\" + writer.getConfig());\n\n    final ExecutorService es = random.nextBoolean() ? null : Executors.newCachedThreadPool(new NamedThreadFactory(\"NRT search threads\"));\n\n    final double minReopenSec = 0.01 + 0.05 * random.nextDouble();\n    final double maxReopenSec = minReopenSec * (1.0 + 10 * random.nextDouble());\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: make NRTManager maxReopenSec=\" + maxReopenSec + \" minReopenSec=\" + minReopenSec);\n    }\n\n    final NRTManager nrt = new NRTManager(writer, es);\n    final NRTManagerReopenThread nrtThread = new NRTManagerReopenThread(nrt, maxReopenSec, minReopenSec);\n    nrtThread.setName(\"NRT Reopen Thread\");\n    nrtThread.setPriority(Math.min(Thread.currentThread().getPriority()+2, Thread.MAX_PRIORITY));\n    nrtThread.setDaemon(true);\n    nrtThread.start();\n\n    final int NUM_INDEX_THREADS = _TestUtil.nextInt(random, 1, 3);\n    final int NUM_SEARCH_THREADS = _TestUtil.nextInt(random, 1, 3);\n    //final int NUM_INDEX_THREADS = 1;\n    //final int NUM_SEARCH_THREADS = 1;\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + NUM_INDEX_THREADS + \" index threads; \" + NUM_SEARCH_THREADS + \" search threads\");\n    }\n\n    final int RUN_TIME_SEC = LuceneTestCase.TEST_NIGHTLY ? 300 : RANDOM_MULTIPLIER;\n\n    final AtomicBoolean failed = new AtomicBoolean();\n    final AtomicInteger addCount = new AtomicInteger();\n    final AtomicInteger delCount = new AtomicInteger();\n    final AtomicInteger packCount = new AtomicInteger();\n    final List<Long> lastGens = new ArrayList<Long>();\n\n    final Set<String> delIDs = Collections.synchronizedSet(new HashSet<String>());\n    final List<SubDocs> allSubDocs = Collections.synchronizedList(new ArrayList<SubDocs>());\n\n    final long stopTime = System.currentTimeMillis() + RUN_TIME_SEC*1000;\n    Thread[] threads = new Thread[NUM_INDEX_THREADS];\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread] = new Thread() {\n          @Override\n          public void run() {\n            // TODO: would be better if this were cross thread, so that we make sure one thread deleting anothers added docs works:\n            final List<String> toDeleteIDs = new ArrayList<String>();\n            final List<SubDocs> toDeleteSubDocs = new ArrayList<SubDocs>();\n\n            long gen = 0;\n            while(System.currentTimeMillis() < stopTime && !failed.get()) {\n\n              //System.out.println(Thread.currentThread().getName() + \": cycle\");\n              try {\n                // Occassional longish pause if running\n                // nightly\n                if (LuceneTestCase.TEST_NIGHTLY && random.nextInt(6) == 3) {\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": now long sleep\");\n                  }\n                  Thread.sleep(_TestUtil.nextInt(random, 50, 500));\n                }\n\n                // Rate limit ingest rate:\n                Thread.sleep(_TestUtil.nextInt(random, 1, 10));\n                if (VERBOSE) {\n                  System.out.println(Thread.currentThread() + \": done sleep\");\n                }\n\n                Document doc = docs.nextDoc();\n                if (doc == null) {\n                  break;\n                }\n                final String addedField;\n                if (random.nextBoolean()) {\n                  addedField = \"extra\" + random.nextInt(10);\n                  doc.add(new Field(addedField, \"a random field\", Field.Store.NO, Field.Index.ANALYZED));\n                } else {\n                  addedField = null;\n                }\n                if (random.nextBoolean()) {\n\n                  if (random.nextBoolean()) {\n                    // Add a pack of adjacent sub-docs\n                    final String packID;\n                    final SubDocs delSubDocs;\n                    if (toDeleteSubDocs.size() > 0 && random.nextBoolean()) {\n                      delSubDocs = toDeleteSubDocs.get(random.nextInt(toDeleteSubDocs.size()));\n                      assert !delSubDocs.deleted;\n                      toDeleteSubDocs.remove(delSubDocs);\n                      // reuse prior packID\n                      packID = delSubDocs.packID;\n                    } else {\n                      delSubDocs = null;\n                      // make new packID\n                      packID = packCount.getAndIncrement() + \"\";\n                    }\n\n                    final Field packIDField = newField(\"packID\", packID, Field.Store.YES, Field.Index.NOT_ANALYZED);\n                    final List<String> docIDs = new ArrayList<String>();\n                    final SubDocs subDocs = new SubDocs(packID, docIDs);\n                    final List<Document> docsList = new ArrayList<Document>();\n\n                    allSubDocs.add(subDocs);\n                    doc.add(packIDField);\n                    docsList.add(cloneDoc(doc));\n                    docIDs.add(doc.get(\"docid\"));\n\n                    final int maxDocCount = _TestUtil.nextInt(random, 1, 10);\n                    while(docsList.size() < maxDocCount) {\n                      doc = docs.nextDoc();\n                      if (doc == null) {\n                        break;\n                      }\n                      docsList.add(cloneDoc(doc));\n                      docIDs.add(doc.get(\"docid\"));\n                    }\n                    addCount.addAndGet(docsList.size());\n\n                    if (delSubDocs != null) {\n                      delSubDocs.deleted = true;\n                      delIDs.addAll(delSubDocs.subIDs);\n                      delCount.addAndGet(delSubDocs.subIDs.size());\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: update pack packID=\" + delSubDocs.packID + \" count=\" + docsList.size() + \" docs=\" + docIDs);\n                      }\n                      gen = nrt.updateDocuments(new Term(\"packID\", delSubDocs.packID), docsList);\n                      /*\n                      // non-atomic:\n                      nrt.deleteDocuments(new Term(\"packID\", delSubDocs.packID));\n                      for(Document subDoc : docsList) {\n                        nrt.addDocument(subDoc);\n                      }\n                      */\n                    } else {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: add pack packID=\" + packID + \" count=\" + docsList.size() + \" docs=\" + docIDs);\n                      }\n                      gen = nrt.addDocuments(docsList);\n                      \n                      /*\n                      // non-atomic:\n                      for(Document subDoc : docsList) {\n                        nrt.addDocument(subDoc);\n                      }\n                      */\n                    }\n                    doc.removeField(\"packID\");\n\n                    if (random.nextInt(5) == 2) {\n                      if (VERBOSE) {\n                        System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + packID);\n                      }\n                      toDeleteSubDocs.add(subDocs);\n                    }\n\n                    // randomly verify the add/update \"took\":\n                    if (random.nextInt(20) == 2) {\n                      final boolean applyDeletes = delSubDocs != null;\n                      final IndexSearcher s = nrt.get(gen, applyDeletes);\n                      try {\n                        assertEquals(docsList.size(), s.search(new TermQuery(new Term(\"packID\", packID)), 10).totalHits);\n                      } finally {\n                        nrt.release(s);\n                      }\n                    }\n\n                  } else {\n                    if (VERBOSE) {\n                      System.out.println(Thread.currentThread().getName() + \": add doc docid:\" + doc.get(\"docid\"));\n                    }\n\n                    gen = nrt.addDocument(doc);\n                    addCount.getAndIncrement();\n\n                    // randomly verify the add \"took\":\n                    if (random.nextInt(20) == 2) {\n                      //System.out.println(Thread.currentThread().getName() + \": verify\");\n                      final IndexSearcher s = nrt.get(gen, false);\n                      //System.out.println(Thread.currentThread().getName() + \": got s=\" + s);\n                      try {\n                        assertEquals(1, s.search(new TermQuery(new Term(\"docid\", doc.get(\"docid\"))), 10).totalHits);\n                      } finally {\n                        nrt.release(s);\n                      }\n                      //System.out.println(Thread.currentThread().getName() + \": done verify\");\n                    }\n\n                    if (random.nextInt(5) == 3) {\n                      if (VERBOSE) {\n                        System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                      }\n                      toDeleteIDs.add(doc.get(\"docid\"));\n                    }\n                  }\n                } else {\n                  // we use update but it never replaces a\n                  // prior doc\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": update doc id:\" + doc.get(\"docid\"));\n                  }\n                  gen = nrt.updateDocument(new Term(\"docid\", doc.get(\"docid\")), doc);\n                  addCount.getAndIncrement();\n\n                  // randomly verify the add \"took\":\n                  if (random.nextInt(20) == 2) {\n                    final IndexSearcher s = nrt.get(gen, true);\n                    try {\n                      assertEquals(1, s.search(new TermQuery(new Term(\"docid\", doc.get(\"docid\"))), 10).totalHits);\n                    } finally {\n                      nrt.release(s);\n                    }\n                  }\n\n                  if (random.nextInt(5) == 3) {\n                    if (VERBOSE) {\n                      System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                    }\n                    toDeleteIDs.add(doc.get(\"docid\"));\n                  }\n                }\n\n                if (random.nextInt(30) == 17) {\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": apply \" + toDeleteIDs.size() + \" deletes\");\n                  }\n                  for(String id : toDeleteIDs) {\n                    if (VERBOSE) {\n                      System.out.println(Thread.currentThread().getName() + \": del term=id:\" + id);\n                    }\n                    gen = nrt.deleteDocuments(new Term(\"docid\", id));\n\n                    // randomly verify the delete \"took\":\n                    if (random.nextInt(20) == 7) {\n                      final IndexSearcher s = nrt.get(gen, true);\n                      try {\n                        assertEquals(0, s.search(new TermQuery(new Term(\"docid\", id)), 10).totalHits);\n                      } finally {\n                        nrt.release(s);\n                      }\n                    }\n                  }\n\n                  final int count = delCount.addAndGet(toDeleteIDs.size());\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": tot \" + count + \" deletes\");\n                  }\n                  delIDs.addAll(toDeleteIDs);\n                  toDeleteIDs.clear();\n\n                  for(SubDocs subDocs : toDeleteSubDocs) {\n                    assertTrue(!subDocs.deleted);\n                    gen = nrt.deleteDocuments(new Term(\"packID\", subDocs.packID));\n                    subDocs.deleted = true;\n                    if (VERBOSE) {\n                      System.out.println(\"  del subs: \" + subDocs.subIDs + \" packID=\" + subDocs.packID);\n                    }\n                    delIDs.addAll(subDocs.subIDs);\n                    delCount.addAndGet(subDocs.subIDs.size());\n\n                    // randomly verify the delete \"took\":\n                    if (random.nextInt(20) == 7) {\n                      final IndexSearcher s = nrt.get(gen, true);\n                      try {\n                        assertEquals(0, s.search(new TermQuery(new Term(\"packID\", subDocs.packID)), 1).totalHits);\n                      } finally {\n                        nrt.release(s);\n                      }\n                    }\n                  }\n                  toDeleteSubDocs.clear();\n                }\n                if (addedField != null) {\n                  doc.removeField(addedField);\n                }\n              } catch (Throwable t) {\n                System.out.println(Thread.currentThread().getName() + \": FAILED: hit exc\");\n                t.printStackTrace();\n                failed.set(true);\n                throw new RuntimeException(t);\n              }\n            }\n\n            lastGens.add(gen);\n            if (VERBOSE) {\n              System.out.println(Thread.currentThread().getName() + \": indexing done\");\n            }\n          }\n        };\n      threads[thread].setDaemon(true);\n      threads[thread].start();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: DONE start indexing threads [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    // let index build up a bit\n    Thread.sleep(100);\n\n    // silly starting guess:\n    final AtomicInteger totTermCount = new AtomicInteger(100);\n\n    // run search threads\n    final Thread[] searchThreads = new Thread[NUM_SEARCH_THREADS];\n    final AtomicInteger totHits = new AtomicInteger();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: start search threads\");\n    }\n\n    for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n      searchThreads[thread] = new Thread() {\n          @Override\n          public void run() {\n            while(System.currentTimeMillis() < stopTime && !failed.get()) {\n              final IndexSearcher s = nrt.get(random.nextBoolean());\n              try {\n                try {\n                  smokeTestSearcher(s);\n                  if (s.getIndexReader().numDocs() > 0) {\n                    Fields fields = MultiFields.getFields(s.getIndexReader());\n                    if (fields == null) {\n                      continue;\n                    }\n                    Terms terms = fields.terms(\"body\");\n                    if (terms == null) {\n                      continue;\n                    }\n\n                    TermsEnum termsEnum = terms.iterator();\n                    int seenTermCount = 0;\n                    int shift;\n                    int trigger;\n                    if (totTermCount.get() < 10) {\n                      shift = 0;\n                      trigger = 1;\n                    } else {\n                      trigger = totTermCount.get()/10;\n                      shift = random.nextInt(trigger);\n                    }\n\n                    while(System.currentTimeMillis() < stopTime) {\n                      BytesRef term = termsEnum.next();\n                      if (term == null) {\n                        if (seenTermCount == 0) {\n                          break;\n                        }\n                        totTermCount.set(seenTermCount);\n                        seenTermCount = 0;\n                        if (totTermCount.get() < 10) {\n                          shift = 0;\n                          trigger = 1;\n                        } else {\n                          trigger = totTermCount.get()/10;\n                          //System.out.println(\"trigger \" + trigger);\n                          shift = random.nextInt(trigger);\n                        }\n                        termsEnum.seekCeil(new BytesRef(\"\"));\n                        continue;\n                      }\n                      seenTermCount++;\n                      // search 10 terms\n                      if (trigger == 0) {\n                        trigger = 1;\n                      }\n                      if ((seenTermCount + shift) % trigger == 0) {\n                        //if (VERBOSE) {\n                        //System.out.println(Thread.currentThread().getName() + \" now search body:\" + term.utf8ToString());\n                        //}\n                        totHits.addAndGet(runQuery(s, new TermQuery(new Term(\"body\", term))));\n                      }\n                    }\n                    if (VERBOSE) {\n                      System.out.println(Thread.currentThread().getName() + \": search done\");\n                    }\n                  }\n                } finally {\n                  nrt.release(s);\n                }\n              } catch (Throwable t) {\n                System.out.println(Thread.currentThread().getName() + \": FAILED: hit exc\");\n                failed.set(true);\n                t.printStackTrace(System.out);\n                throw new RuntimeException(t);\n              }\n            }\n          }\n        };\n      searchThreads[thread].setDaemon(true);\n      searchThreads[thread].start();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now join\");\n    }\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread].join();\n    }\n    for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n      searchThreads[thread].join();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: done join [\" + (System.currentTimeMillis()-t0) + \" ms]; addCount=\" + addCount + \" delCount=\" + delCount);\n      System.out.println(\"TEST: search totHits=\" + totHits);\n    }\n\n    long maxGen = 0;\n    for(long gen : lastGens) {\n      maxGen = Math.max(maxGen, gen);\n    }\n\n    final IndexSearcher s = nrt.get(maxGen, true);\n\n    boolean doFail = false;\n    for(String id : delIDs) {\n      final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", id)), 1);\n      if (hits.totalHits != 0) {\n        System.out.println(\"doc id=\" + id + \" is supposed to be deleted, but got docID=\" + hits.scoreDocs[0].doc);\n        doFail = true;\n      }\n    }\n\n    // Make sure each group of sub-docs are still in docID order:\n    for(SubDocs subDocs : allSubDocs) {\n      if (!subDocs.deleted) {\n        // We sort by relevance but the scores should be identical so sort falls back to by docID:\n        TopDocs hits = s.search(new TermQuery(new Term(\"packID\", subDocs.packID)), 20);\n        assertEquals(subDocs.subIDs.size(), hits.totalHits);\n        int lastDocID = -1;\n        int startDocID = -1;\n        for(ScoreDoc scoreDoc : hits.scoreDocs) {\n          final int docID = scoreDoc.doc;\n          if (lastDocID != -1) {\n            assertEquals(1+lastDocID, docID);\n          } else {\n            startDocID = docID;\n          }\n          lastDocID = docID;\n          final Document doc = s.doc(docID);\n          assertEquals(subDocs.packID, doc.get(\"packID\"));\n        }\n\n        lastDocID = startDocID - 1;\n        for(String subID : subDocs.subIDs) {\n          hits = s.search(new TermQuery(new Term(\"docid\", subID)), 1);\n          assertEquals(1, hits.totalHits);\n          final int docID = hits.scoreDocs[0].doc;\n          if (lastDocID != -1) {\n            assertEquals(1+lastDocID, docID);\n          }\n          lastDocID = docID;\n        }          \n      } else {\n        for(String subID : subDocs.subIDs) {\n          assertEquals(0, s.search(new TermQuery(new Term(\"docid\", subID)), 1).totalHits);\n        }\n      }\n    }\n    \n    final int endID = Integer.parseInt(docs.nextDoc().get(\"docid\"));\n    for(int id=0;id<endID;id++) {\n      String stringID = \"\"+id;\n      if (!delIDs.contains(stringID)) {\n        final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", stringID)), 1);\n        if (hits.totalHits != 1) {\n          System.out.println(\"doc id=\" + stringID + \" is not supposed to be deleted, but got hitCount=\" + hits.totalHits);\n          doFail = true;\n        }\n      }\n    }\n    assertFalse(doFail);\n\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), s.getIndexReader().numDocs());\n    nrt.release(s);\n\n    if (es != null) {\n      es.shutdown();\n      es.awaitTermination(1, TimeUnit.SECONDS);\n    }\n\n    writer.commit();\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), writer.numDocs());\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now close NRTManager\");\n    }\n    nrtThread.close();\n    nrt.close();\n    assertFalse(writer.anyNonBulkMerges);\n    writer.close(false);\n    _TestUtil.checkIndex(dir);\n    dir.close();\n    _TestUtil.rmDir(tempDir);\n    docs.close();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testNRTManager() throws Exception {\n\n    final long t0 = System.currentTimeMillis();\n\n    if (CodecProvider.getDefault().getDefaultFieldCodec().equals(\"SimpleText\")) {\n      // no\n      CodecProvider.getDefault().setDefaultFieldCodec(\"Standard\");\n    }\n\n    final LineFileDocs docs = new LineFileDocs(random);\n    final File tempDir = _TestUtil.getTempDir(\"nrtopenfiles\");\n    final MockDirectoryWrapper _dir = newFSDirectory(tempDir);\n    _dir.setCheckIndexOnClose(false);  // don't double-checkIndex, we do it ourselves\n    Directory dir = _dir;\n    final IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).setOpenMode(IndexWriterConfig.OpenMode.CREATE);\n\n    if (LuceneTestCase.TEST_NIGHTLY) {\n      // newIWConfig makes smallish max seg size, which\n      // results in tons and tons of segments for this test\n      // when run nightly:\n      MergePolicy mp = conf.getMergePolicy();\n      if (mp instanceof TieredMergePolicy) {\n        ((TieredMergePolicy) mp).setMaxMergedSegmentMB(5000.);\n      } else if (mp instanceof LogByteSizeMergePolicy) {\n        ((LogByteSizeMergePolicy) mp).setMaxMergeMB(1000.);\n      } else if (mp instanceof LogMergePolicy) {\n        ((LogMergePolicy) mp).setMaxMergeDocs(100000);\n      }\n    }\n\n    conf.setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n      @Override\n      public void warm(IndexReader reader) throws IOException {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now warm merged reader=\" + reader);\n        }\n        final int maxDoc = reader.maxDoc();\n        final Bits delDocs = reader.getDeletedDocs();\n        int sum = 0;\n        final int inc = Math.max(1, maxDoc/50);\n        for(int docID=0;docID<maxDoc;docID += inc) {\n          if (delDocs == null || !delDocs.get(docID)) {\n            final Document doc = reader.document(docID);\n            sum += doc.getFields().size();\n          }\n        }\n\n        IndexSearcher searcher = newSearcher(reader);\n        sum += searcher.search(new TermQuery(new Term(\"body\", \"united\")), 10).totalHits;\n        searcher.close();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: warm visited \" + sum + \" fields\");\n        }\n      }\n      });\n\n    if (random.nextBoolean()) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: wrap NRTCachingDir\");\n      }\n\n      NRTCachingDirectory nrtDir = new NRTCachingDirectory(dir, 5.0, 60.0);\n      conf.setMergeScheduler(nrtDir.getMergeScheduler());\n      dir = nrtDir;\n    }\n    \n    final IndexWriter writer = new IndexWriter(dir, conf);\n    \n    if (VERBOSE) {\n      writer.setInfoStream(System.out);\n    }\n    _TestUtil.reduceOpenFiles(writer);\n    //System.out.println(\"TEST: conf=\" + writer.getConfig());\n\n    final ExecutorService es = random.nextBoolean() ? null : Executors.newCachedThreadPool(new NamedThreadFactory(\"NRT search threads\"));\n\n    final double minReopenSec = 0.01 + 0.05 * random.nextDouble();\n    final double maxReopenSec = minReopenSec * (1.0 + 10 * random.nextDouble());\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: make NRTManager maxReopenSec=\" + maxReopenSec + \" minReopenSec=\" + minReopenSec);\n    }\n\n    final NRTManager nrt = new NRTManager(writer, es);\n    final NRTManagerReopenThread nrtThread = new NRTManagerReopenThread(nrt, maxReopenSec, minReopenSec);\n    nrtThread.setName(\"NRT Reopen Thread\");\n    nrtThread.setPriority(Math.min(Thread.currentThread().getPriority()+2, Thread.MAX_PRIORITY));\n    nrtThread.setDaemon(true);\n    nrtThread.start();\n\n    final int NUM_INDEX_THREADS = _TestUtil.nextInt(random, 1, 3);\n    final int NUM_SEARCH_THREADS = _TestUtil.nextInt(random, 1, 3);\n    //final int NUM_INDEX_THREADS = 1;\n    //final int NUM_SEARCH_THREADS = 1;\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + NUM_INDEX_THREADS + \" index threads; \" + NUM_SEARCH_THREADS + \" search threads\");\n    }\n\n    final int RUN_TIME_SEC = LuceneTestCase.TEST_NIGHTLY ? 300 : RANDOM_MULTIPLIER;\n\n    final AtomicBoolean failed = new AtomicBoolean();\n    final AtomicInteger addCount = new AtomicInteger();\n    final AtomicInteger delCount = new AtomicInteger();\n    final AtomicInteger packCount = new AtomicInteger();\n    final List<Long> lastGens = new ArrayList<Long>();\n\n    final Set<String> delIDs = Collections.synchronizedSet(new HashSet<String>());\n    final List<SubDocs> allSubDocs = Collections.synchronizedList(new ArrayList<SubDocs>());\n\n    final long stopTime = System.currentTimeMillis() + RUN_TIME_SEC*1000;\n    Thread[] threads = new Thread[NUM_INDEX_THREADS];\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread] = new Thread() {\n          @Override\n          public void run() {\n            // TODO: would be better if this were cross thread, so that we make sure one thread deleting anothers added docs works:\n            final List<String> toDeleteIDs = new ArrayList<String>();\n            final List<SubDocs> toDeleteSubDocs = new ArrayList<SubDocs>();\n\n            long gen = 0;\n            while(System.currentTimeMillis() < stopTime && !failed.get()) {\n\n              //System.out.println(Thread.currentThread().getName() + \": cycle\");\n              try {\n                // Occassional longish pause if running\n                // nightly\n                if (LuceneTestCase.TEST_NIGHTLY && random.nextInt(6) == 3) {\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": now long sleep\");\n                  }\n                  Thread.sleep(_TestUtil.nextInt(random, 50, 500));\n                }\n\n                // Rate limit ingest rate:\n                Thread.sleep(_TestUtil.nextInt(random, 1, 10));\n                if (VERBOSE) {\n                  System.out.println(Thread.currentThread() + \": done sleep\");\n                }\n\n                Document doc = docs.nextDoc();\n                if (doc == null) {\n                  break;\n                }\n                final String addedField;\n                if (random.nextBoolean()) {\n                  addedField = \"extra\" + random.nextInt(10);\n                  doc.add(new Field(addedField, \"a random field\", Field.Store.NO, Field.Index.ANALYZED));\n                } else {\n                  addedField = null;\n                }\n                if (random.nextBoolean()) {\n\n                  if (random.nextBoolean()) {\n                    // Add a pack of adjacent sub-docs\n                    final String packID;\n                    final SubDocs delSubDocs;\n                    if (toDeleteSubDocs.size() > 0 && random.nextBoolean()) {\n                      delSubDocs = toDeleteSubDocs.get(random.nextInt(toDeleteSubDocs.size()));\n                      assert !delSubDocs.deleted;\n                      toDeleteSubDocs.remove(delSubDocs);\n                      // reuse prior packID\n                      packID = delSubDocs.packID;\n                    } else {\n                      delSubDocs = null;\n                      // make new packID\n                      packID = packCount.getAndIncrement() + \"\";\n                    }\n\n                    final Field packIDField = newField(\"packID\", packID, Field.Store.YES, Field.Index.NOT_ANALYZED);\n                    final List<String> docIDs = new ArrayList<String>();\n                    final SubDocs subDocs = new SubDocs(packID, docIDs);\n                    final List<Document> docsList = new ArrayList<Document>();\n\n                    allSubDocs.add(subDocs);\n                    doc.add(packIDField);\n                    docsList.add(cloneDoc(doc));\n                    docIDs.add(doc.get(\"docid\"));\n\n                    final int maxDocCount = _TestUtil.nextInt(random, 1, 10);\n                    while(docsList.size() < maxDocCount) {\n                      doc = docs.nextDoc();\n                      if (doc == null) {\n                        break;\n                      }\n                      docsList.add(cloneDoc(doc));\n                      docIDs.add(doc.get(\"docid\"));\n                    }\n                    addCount.addAndGet(docsList.size());\n\n                    if (delSubDocs != null) {\n                      delSubDocs.deleted = true;\n                      delIDs.addAll(delSubDocs.subIDs);\n                      delCount.addAndGet(delSubDocs.subIDs.size());\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: update pack packID=\" + delSubDocs.packID + \" count=\" + docsList.size() + \" docs=\" + docIDs);\n                      }\n                      gen = nrt.updateDocuments(new Term(\"packID\", delSubDocs.packID), docsList);\n                      /*\n                      // non-atomic:\n                      nrt.deleteDocuments(new Term(\"packID\", delSubDocs.packID));\n                      for(Document subDoc : docsList) {\n                        nrt.addDocument(subDoc);\n                      }\n                      */\n                    } else {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: add pack packID=\" + packID + \" count=\" + docsList.size() + \" docs=\" + docIDs);\n                      }\n                      gen = nrt.addDocuments(docsList);\n                      \n                      /*\n                      // non-atomic:\n                      for(Document subDoc : docsList) {\n                        nrt.addDocument(subDoc);\n                      }\n                      */\n                    }\n                    doc.removeField(\"packID\");\n\n                    if (random.nextInt(5) == 2) {\n                      if (VERBOSE) {\n                        System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + packID);\n                      }\n                      toDeleteSubDocs.add(subDocs);\n                    }\n\n                    // randomly verify the add/update \"took\":\n                    if (random.nextInt(20) == 2) {\n                      final boolean applyDeletes = delSubDocs != null;\n                      final IndexSearcher s = nrt.get(gen, applyDeletes);\n                      try {\n                        assertEquals(docsList.size(), s.search(new TermQuery(new Term(\"packID\", packID)), 10).totalHits);\n                      } finally {\n                        nrt.release(s);\n                      }\n                    }\n\n                  } else {\n                    if (VERBOSE) {\n                      System.out.println(Thread.currentThread().getName() + \": add doc docid:\" + doc.get(\"docid\"));\n                    }\n\n                    gen = nrt.addDocument(doc);\n                    addCount.getAndIncrement();\n\n                    // randomly verify the add \"took\":\n                    if (random.nextInt(20) == 2) {\n                      //System.out.println(Thread.currentThread().getName() + \": verify\");\n                      final IndexSearcher s = nrt.get(gen, false);\n                      //System.out.println(Thread.currentThread().getName() + \": got s=\" + s);\n                      try {\n                        assertEquals(1, s.search(new TermQuery(new Term(\"docid\", doc.get(\"docid\"))), 10).totalHits);\n                      } finally {\n                        nrt.release(s);\n                      }\n                      //System.out.println(Thread.currentThread().getName() + \": done verify\");\n                    }\n\n                    if (random.nextInt(5) == 3) {\n                      if (VERBOSE) {\n                        System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                      }\n                      toDeleteIDs.add(doc.get(\"docid\"));\n                    }\n                  }\n                } else {\n                  // we use update but it never replaces a\n                  // prior doc\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": update doc id:\" + doc.get(\"docid\"));\n                  }\n                  gen = nrt.updateDocument(new Term(\"docid\", doc.get(\"docid\")), doc);\n                  addCount.getAndIncrement();\n\n                  // randomly verify the add \"took\":\n                  if (random.nextInt(20) == 2) {\n                    final IndexSearcher s = nrt.get(gen, true);\n                    try {\n                      assertEquals(1, s.search(new TermQuery(new Term(\"docid\", doc.get(\"docid\"))), 10).totalHits);\n                    } finally {\n                      nrt.release(s);\n                    }\n                  }\n\n                  if (random.nextInt(5) == 3) {\n                    if (VERBOSE) {\n                      System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                    }\n                    toDeleteIDs.add(doc.get(\"docid\"));\n                  }\n                }\n\n                if (random.nextInt(30) == 17) {\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": apply \" + toDeleteIDs.size() + \" deletes\");\n                  }\n                  for(String id : toDeleteIDs) {\n                    if (VERBOSE) {\n                      System.out.println(Thread.currentThread().getName() + \": del term=id:\" + id);\n                    }\n                    gen = nrt.deleteDocuments(new Term(\"docid\", id));\n\n                    // randomly verify the delete \"took\":\n                    if (random.nextInt(20) == 7) {\n                      final IndexSearcher s = nrt.get(gen, true);\n                      try {\n                        assertEquals(0, s.search(new TermQuery(new Term(\"docid\", id)), 10).totalHits);\n                      } finally {\n                        nrt.release(s);\n                      }\n                    }\n                  }\n\n                  final int count = delCount.addAndGet(toDeleteIDs.size());\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": tot \" + count + \" deletes\");\n                  }\n                  delIDs.addAll(toDeleteIDs);\n                  toDeleteIDs.clear();\n\n                  for(SubDocs subDocs : toDeleteSubDocs) {\n                    assertTrue(!subDocs.deleted);\n                    gen = nrt.deleteDocuments(new Term(\"packID\", subDocs.packID));\n                    subDocs.deleted = true;\n                    if (VERBOSE) {\n                      System.out.println(\"  del subs: \" + subDocs.subIDs + \" packID=\" + subDocs.packID);\n                    }\n                    delIDs.addAll(subDocs.subIDs);\n                    delCount.addAndGet(subDocs.subIDs.size());\n\n                    // randomly verify the delete \"took\":\n                    if (random.nextInt(20) == 7) {\n                      final IndexSearcher s = nrt.get(gen, true);\n                      try {\n                        assertEquals(0, s.search(new TermQuery(new Term(\"packID\", subDocs.packID)), 1).totalHits);\n                      } finally {\n                        nrt.release(s);\n                      }\n                    }\n                  }\n                  toDeleteSubDocs.clear();\n                }\n                if (addedField != null) {\n                  doc.removeField(addedField);\n                }\n              } catch (Throwable t) {\n                System.out.println(Thread.currentThread().getName() + \": FAILED: hit exc\");\n                t.printStackTrace();\n                failed.set(true);\n                throw new RuntimeException(t);\n              }\n            }\n\n            lastGens.add(gen);\n            if (VERBOSE) {\n              System.out.println(Thread.currentThread().getName() + \": indexing done\");\n            }\n          }\n        };\n      threads[thread].setDaemon(true);\n      threads[thread].start();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: DONE start indexing threads [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    // let index build up a bit\n    Thread.sleep(100);\n\n    // silly starting guess:\n    final AtomicInteger totTermCount = new AtomicInteger(100);\n\n    // run search threads\n    final Thread[] searchThreads = new Thread[NUM_SEARCH_THREADS];\n    final AtomicInteger totHits = new AtomicInteger();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: start search threads\");\n    }\n\n    for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n      searchThreads[thread] = new Thread() {\n          @Override\n          public void run() {\n            while(System.currentTimeMillis() < stopTime && !failed.get()) {\n              final IndexSearcher s = nrt.get(random.nextBoolean());\n              try {\n                try {\n                  smokeTestSearcher(s);\n                  if (s.getIndexReader().numDocs() > 0) {\n                    Fields fields = MultiFields.getFields(s.getIndexReader());\n                    if (fields == null) {\n                      continue;\n                    }\n                    Terms terms = fields.terms(\"body\");\n                    if (terms == null) {\n                      continue;\n                    }\n\n                    TermsEnum termsEnum = terms.iterator();\n                    int seenTermCount = 0;\n                    int shift;\n                    int trigger;\n                    if (totTermCount.get() < 10) {\n                      shift = 0;\n                      trigger = 1;\n                    } else {\n                      trigger = totTermCount.get()/10;\n                      shift = random.nextInt(trigger);\n                    }\n\n                    while(System.currentTimeMillis() < stopTime) {\n                      BytesRef term = termsEnum.next();\n                      if (term == null) {\n                        if (seenTermCount == 0) {\n                          break;\n                        }\n                        totTermCount.set(seenTermCount);\n                        seenTermCount = 0;\n                        if (totTermCount.get() < 10) {\n                          shift = 0;\n                          trigger = 1;\n                        } else {\n                          trigger = totTermCount.get()/10;\n                          //System.out.println(\"trigger \" + trigger);\n                          shift = random.nextInt(trigger);\n                        }\n                        termsEnum.seekCeil(new BytesRef(\"\"));\n                        continue;\n                      }\n                      seenTermCount++;\n                      // search 10 terms\n                      if (trigger == 0) {\n                        trigger = 1;\n                      }\n                      if ((seenTermCount + shift) % trigger == 0) {\n                        //if (VERBOSE) {\n                        //System.out.println(Thread.currentThread().getName() + \" now search body:\" + term.utf8ToString());\n                        //}\n                        totHits.addAndGet(runQuery(s, new TermQuery(new Term(\"body\", term))));\n                      }\n                    }\n                    if (VERBOSE) {\n                      System.out.println(Thread.currentThread().getName() + \": search done\");\n                    }\n                  }\n                } finally {\n                  nrt.release(s);\n                }\n              } catch (Throwable t) {\n                System.out.println(Thread.currentThread().getName() + \": FAILED: hit exc\");\n                failed.set(true);\n                t.printStackTrace(System.out);\n                throw new RuntimeException(t);\n              }\n            }\n          }\n        };\n      searchThreads[thread].setDaemon(true);\n      searchThreads[thread].start();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now join\");\n    }\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread].join();\n    }\n    for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n      searchThreads[thread].join();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: done join [\" + (System.currentTimeMillis()-t0) + \" ms]; addCount=\" + addCount + \" delCount=\" + delCount);\n      System.out.println(\"TEST: search totHits=\" + totHits);\n    }\n\n    long maxGen = 0;\n    for(long gen : lastGens) {\n      maxGen = Math.max(maxGen, gen);\n    }\n\n    final IndexSearcher s = nrt.get(maxGen, true);\n\n    boolean doFail = false;\n    for(String id : delIDs) {\n      final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", id)), 1);\n      if (hits.totalHits != 0) {\n        System.out.println(\"doc id=\" + id + \" is supposed to be deleted, but got docID=\" + hits.scoreDocs[0].doc);\n        doFail = true;\n      }\n    }\n\n    // Make sure each group of sub-docs are still in docID order:\n    for(SubDocs subDocs : allSubDocs) {\n      if (!subDocs.deleted) {\n        // We sort by relevance but the scores should be identical so sort falls back to by docID:\n        TopDocs hits = s.search(new TermQuery(new Term(\"packID\", subDocs.packID)), 20);\n        assertEquals(subDocs.subIDs.size(), hits.totalHits);\n        int lastDocID = -1;\n        int startDocID = -1;\n        for(ScoreDoc scoreDoc : hits.scoreDocs) {\n          final int docID = scoreDoc.doc;\n          if (lastDocID != -1) {\n            assertEquals(1+lastDocID, docID);\n          } else {\n            startDocID = docID;\n          }\n          lastDocID = docID;\n          final Document doc = s.doc(docID);\n          assertEquals(subDocs.packID, doc.get(\"packID\"));\n        }\n\n        lastDocID = startDocID - 1;\n        for(String subID : subDocs.subIDs) {\n          hits = s.search(new TermQuery(new Term(\"docid\", subID)), 1);\n          assertEquals(1, hits.totalHits);\n          final int docID = hits.scoreDocs[0].doc;\n          if (lastDocID != -1) {\n            assertEquals(1+lastDocID, docID);\n          }\n          lastDocID = docID;\n        }          \n      } else {\n        for(String subID : subDocs.subIDs) {\n          assertEquals(0, s.search(new TermQuery(new Term(\"docid\", subID)), 1).totalHits);\n        }\n      }\n    }\n    \n    final int endID = Integer.parseInt(docs.nextDoc().get(\"docid\"));\n    for(int id=0;id<endID;id++) {\n      String stringID = \"\"+id;\n      if (!delIDs.contains(stringID)) {\n        final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", stringID)), 1);\n        if (hits.totalHits != 1) {\n          System.out.println(\"doc id=\" + stringID + \" is not supposed to be deleted, but got hitCount=\" + hits.totalHits);\n          doFail = true;\n        }\n      }\n    }\n    assertFalse(doFail);\n\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), s.getIndexReader().numDocs());\n    nrt.release(s);\n\n    if (es != null) {\n      es.shutdown();\n      es.awaitTermination(1, TimeUnit.SECONDS);\n    }\n\n    writer.commit();\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), writer.numDocs());\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now close NRTManager\");\n    }\n    nrtThread.close();\n    nrt.close();\n    assertFalse(writer.anyNonBulkMerges);\n    writer.close(false);\n    _TestUtil.checkIndex(dir);\n    dir.close();\n    _TestUtil.rmDir(tempDir);\n    docs.close();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d083e83f225b11e5fdd900e83d26ddb385b6955c","date":1310029438,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/contrib/misc/src/test/org/apache/lucene/index/TestNRTManager#testNRTManager().mjava","pathOld":"lucene/contrib/misc/src/test/org/apache/lucene/index/TestNRTManager#testNRTManager().mjava","sourceNew":"  @Test\n  public void testNRTManager() throws Exception {\n\n    final long t0 = System.currentTimeMillis();\n\n    if (CodecProvider.getDefault().getDefaultFieldCodec().equals(\"SimpleText\")) {\n      // no\n      CodecProvider.getDefault().setDefaultFieldCodec(\"Standard\");\n    }\n\n    final LineFileDocs docs = new LineFileDocs(random);\n    final File tempDir = _TestUtil.getTempDir(\"nrtopenfiles\");\n    final MockDirectoryWrapper _dir = newFSDirectory(tempDir);\n    _dir.setCheckIndexOnClose(false);  // don't double-checkIndex, we do it ourselves\n    Directory dir = _dir;\n    final IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).setOpenMode(IndexWriterConfig.OpenMode.CREATE);\n\n    if (LuceneTestCase.TEST_NIGHTLY) {\n      // newIWConfig makes smallish max seg size, which\n      // results in tons and tons of segments for this test\n      // when run nightly:\n      MergePolicy mp = conf.getMergePolicy();\n      if (mp instanceof TieredMergePolicy) {\n        ((TieredMergePolicy) mp).setMaxMergedSegmentMB(5000.);\n      } else if (mp instanceof LogByteSizeMergePolicy) {\n        ((LogByteSizeMergePolicy) mp).setMaxMergeMB(1000.);\n      } else if (mp instanceof LogMergePolicy) {\n        ((LogMergePolicy) mp).setMaxMergeDocs(100000);\n      }\n    }\n\n    conf.setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n      @Override\n      public void warm(IndexReader reader) throws IOException {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now warm merged reader=\" + reader);\n        }\n        final int maxDoc = reader.maxDoc();\n        final Bits liveDocs = reader.getLiveDocs();\n        int sum = 0;\n        final int inc = Math.max(1, maxDoc/50);\n        for(int docID=0;docID<maxDoc;docID += inc) {\n          if (liveDocs == null || liveDocs.get(docID)) {\n            final Document doc = reader.document(docID);\n            sum += doc.getFields().size();\n          }\n        }\n\n        IndexSearcher searcher = newSearcher(reader);\n        sum += searcher.search(new TermQuery(new Term(\"body\", \"united\")), 10).totalHits;\n        searcher.close();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: warm visited \" + sum + \" fields\");\n        }\n      }\n      });\n\n    if (random.nextBoolean()) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: wrap NRTCachingDir\");\n      }\n\n      dir = new NRTCachingDirectory(dir, 5.0, 60.0);\n    }\n    \n    final IndexWriter writer = new IndexWriter(dir, conf);\n    \n    if (VERBOSE) {\n      writer.setInfoStream(System.out);\n    }\n    _TestUtil.reduceOpenFiles(writer);\n    //System.out.println(\"TEST: conf=\" + writer.getConfig());\n\n    final ExecutorService es = random.nextBoolean() ? null : Executors.newCachedThreadPool(new NamedThreadFactory(\"NRT search threads\"));\n\n    final double minReopenSec = 0.01 + 0.05 * random.nextDouble();\n    final double maxReopenSec = minReopenSec * (1.0 + 10 * random.nextDouble());\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: make NRTManager maxReopenSec=\" + maxReopenSec + \" minReopenSec=\" + minReopenSec);\n    }\n\n    final NRTManager nrt = new NRTManager(writer, es);\n    final NRTManagerReopenThread nrtThread = new NRTManagerReopenThread(nrt, maxReopenSec, minReopenSec);\n    nrtThread.setName(\"NRT Reopen Thread\");\n    nrtThread.setPriority(Math.min(Thread.currentThread().getPriority()+2, Thread.MAX_PRIORITY));\n    nrtThread.setDaemon(true);\n    nrtThread.start();\n\n    final int NUM_INDEX_THREADS = _TestUtil.nextInt(random, 1, 3);\n    final int NUM_SEARCH_THREADS = _TestUtil.nextInt(random, 1, 3);\n    //final int NUM_INDEX_THREADS = 1;\n    //final int NUM_SEARCH_THREADS = 1;\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + NUM_INDEX_THREADS + \" index threads; \" + NUM_SEARCH_THREADS + \" search threads\");\n    }\n\n    final int RUN_TIME_SEC = LuceneTestCase.TEST_NIGHTLY ? 300 : RANDOM_MULTIPLIER;\n\n    final AtomicBoolean failed = new AtomicBoolean();\n    final AtomicInteger addCount = new AtomicInteger();\n    final AtomicInteger delCount = new AtomicInteger();\n    final AtomicInteger packCount = new AtomicInteger();\n    final List<Long> lastGens = new ArrayList<Long>();\n\n    final Set<String> delIDs = Collections.synchronizedSet(new HashSet<String>());\n    final List<SubDocs> allSubDocs = Collections.synchronizedList(new ArrayList<SubDocs>());\n\n    final long stopTime = System.currentTimeMillis() + RUN_TIME_SEC*1000;\n    Thread[] threads = new Thread[NUM_INDEX_THREADS];\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread] = new Thread() {\n          @Override\n          public void run() {\n            // TODO: would be better if this were cross thread, so that we make sure one thread deleting anothers added docs works:\n            final List<String> toDeleteIDs = new ArrayList<String>();\n            final List<SubDocs> toDeleteSubDocs = new ArrayList<SubDocs>();\n\n            long gen = 0;\n            while(System.currentTimeMillis() < stopTime && !failed.get()) {\n\n              //System.out.println(Thread.currentThread().getName() + \": cycle\");\n              try {\n                // Occassional longish pause if running\n                // nightly\n                if (LuceneTestCase.TEST_NIGHTLY && random.nextInt(6) == 3) {\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": now long sleep\");\n                  }\n                  Thread.sleep(_TestUtil.nextInt(random, 50, 500));\n                }\n\n                // Rate limit ingest rate:\n                Thread.sleep(_TestUtil.nextInt(random, 1, 10));\n                if (VERBOSE) {\n                  System.out.println(Thread.currentThread() + \": done sleep\");\n                }\n\n                Document doc = docs.nextDoc();\n                if (doc == null) {\n                  break;\n                }\n                final String addedField;\n                if (random.nextBoolean()) {\n                  addedField = \"extra\" + random.nextInt(10);\n                  doc.add(new Field(addedField, \"a random field\", Field.Store.NO, Field.Index.ANALYZED));\n                } else {\n                  addedField = null;\n                }\n                if (random.nextBoolean()) {\n\n                  if (random.nextBoolean()) {\n                    // Add a pack of adjacent sub-docs\n                    final String packID;\n                    final SubDocs delSubDocs;\n                    if (toDeleteSubDocs.size() > 0 && random.nextBoolean()) {\n                      delSubDocs = toDeleteSubDocs.get(random.nextInt(toDeleteSubDocs.size()));\n                      assert !delSubDocs.deleted;\n                      toDeleteSubDocs.remove(delSubDocs);\n                      // reuse prior packID\n                      packID = delSubDocs.packID;\n                    } else {\n                      delSubDocs = null;\n                      // make new packID\n                      packID = packCount.getAndIncrement() + \"\";\n                    }\n\n                    final Field packIDField = newField(\"packID\", packID, Field.Store.YES, Field.Index.NOT_ANALYZED);\n                    final List<String> docIDs = new ArrayList<String>();\n                    final SubDocs subDocs = new SubDocs(packID, docIDs);\n                    final List<Document> docsList = new ArrayList<Document>();\n\n                    allSubDocs.add(subDocs);\n                    doc.add(packIDField);\n                    docsList.add(cloneDoc(doc));\n                    docIDs.add(doc.get(\"docid\"));\n\n                    final int maxDocCount = _TestUtil.nextInt(random, 1, 10);\n                    while(docsList.size() < maxDocCount) {\n                      doc = docs.nextDoc();\n                      if (doc == null) {\n                        break;\n                      }\n                      docsList.add(cloneDoc(doc));\n                      docIDs.add(doc.get(\"docid\"));\n                    }\n                    addCount.addAndGet(docsList.size());\n\n                    if (delSubDocs != null) {\n                      delSubDocs.deleted = true;\n                      delIDs.addAll(delSubDocs.subIDs);\n                      delCount.addAndGet(delSubDocs.subIDs.size());\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: update pack packID=\" + delSubDocs.packID + \" count=\" + docsList.size() + \" docs=\" + docIDs);\n                      }\n                      gen = nrt.updateDocuments(new Term(\"packID\", delSubDocs.packID), docsList);\n                      /*\n                      // non-atomic:\n                      nrt.deleteDocuments(new Term(\"packID\", delSubDocs.packID));\n                      for(Document subDoc : docsList) {\n                        nrt.addDocument(subDoc);\n                      }\n                      */\n                    } else {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: add pack packID=\" + packID + \" count=\" + docsList.size() + \" docs=\" + docIDs);\n                      }\n                      gen = nrt.addDocuments(docsList);\n                      \n                      /*\n                      // non-atomic:\n                      for(Document subDoc : docsList) {\n                        nrt.addDocument(subDoc);\n                      }\n                      */\n                    }\n                    doc.removeField(\"packID\");\n\n                    if (random.nextInt(5) == 2) {\n                      if (VERBOSE) {\n                        System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + packID);\n                      }\n                      toDeleteSubDocs.add(subDocs);\n                    }\n\n                    // randomly verify the add/update \"took\":\n                    if (random.nextInt(20) == 2) {\n                      final boolean applyDeletes = delSubDocs != null;\n                      final IndexSearcher s = nrt.get(gen, applyDeletes);\n                      try {\n                        assertEquals(docsList.size(), s.search(new TermQuery(new Term(\"packID\", packID)), 10).totalHits);\n                      } finally {\n                        nrt.release(s);\n                      }\n                    }\n\n                  } else {\n                    if (VERBOSE) {\n                      System.out.println(Thread.currentThread().getName() + \": add doc docid:\" + doc.get(\"docid\"));\n                    }\n\n                    gen = nrt.addDocument(doc);\n                    addCount.getAndIncrement();\n\n                    // randomly verify the add \"took\":\n                    if (random.nextInt(20) == 2) {\n                      //System.out.println(Thread.currentThread().getName() + \": verify\");\n                      final IndexSearcher s = nrt.get(gen, false);\n                      //System.out.println(Thread.currentThread().getName() + \": got s=\" + s);\n                      try {\n                        assertEquals(1, s.search(new TermQuery(new Term(\"docid\", doc.get(\"docid\"))), 10).totalHits);\n                      } finally {\n                        nrt.release(s);\n                      }\n                      //System.out.println(Thread.currentThread().getName() + \": done verify\");\n                    }\n\n                    if (random.nextInt(5) == 3) {\n                      if (VERBOSE) {\n                        System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                      }\n                      toDeleteIDs.add(doc.get(\"docid\"));\n                    }\n                  }\n                } else {\n                  // we use update but it never replaces a\n                  // prior doc\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": update doc id:\" + doc.get(\"docid\"));\n                  }\n                  gen = nrt.updateDocument(new Term(\"docid\", doc.get(\"docid\")), doc);\n                  addCount.getAndIncrement();\n\n                  // randomly verify the add \"took\":\n                  if (random.nextInt(20) == 2) {\n                    final IndexSearcher s = nrt.get(gen, true);\n                    try {\n                      assertEquals(1, s.search(new TermQuery(new Term(\"docid\", doc.get(\"docid\"))), 10).totalHits);\n                    } finally {\n                      nrt.release(s);\n                    }\n                  }\n\n                  if (random.nextInt(5) == 3) {\n                    if (VERBOSE) {\n                      System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                    }\n                    toDeleteIDs.add(doc.get(\"docid\"));\n                  }\n                }\n\n                if (random.nextInt(30) == 17) {\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": apply \" + toDeleteIDs.size() + \" deletes\");\n                  }\n                  for(String id : toDeleteIDs) {\n                    if (VERBOSE) {\n                      System.out.println(Thread.currentThread().getName() + \": del term=id:\" + id);\n                    }\n                    gen = nrt.deleteDocuments(new Term(\"docid\", id));\n\n                    // randomly verify the delete \"took\":\n                    if (random.nextInt(20) == 7) {\n                      final IndexSearcher s = nrt.get(gen, true);\n                      try {\n                        assertEquals(0, s.search(new TermQuery(new Term(\"docid\", id)), 10).totalHits);\n                      } finally {\n                        nrt.release(s);\n                      }\n                    }\n                  }\n\n                  final int count = delCount.addAndGet(toDeleteIDs.size());\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": tot \" + count + \" deletes\");\n                  }\n                  delIDs.addAll(toDeleteIDs);\n                  toDeleteIDs.clear();\n\n                  for(SubDocs subDocs : toDeleteSubDocs) {\n                    assertTrue(!subDocs.deleted);\n                    gen = nrt.deleteDocuments(new Term(\"packID\", subDocs.packID));\n                    subDocs.deleted = true;\n                    if (VERBOSE) {\n                      System.out.println(\"  del subs: \" + subDocs.subIDs + \" packID=\" + subDocs.packID);\n                    }\n                    delIDs.addAll(subDocs.subIDs);\n                    delCount.addAndGet(subDocs.subIDs.size());\n\n                    // randomly verify the delete \"took\":\n                    if (random.nextInt(20) == 7) {\n                      final IndexSearcher s = nrt.get(gen, true);\n                      try {\n                        assertEquals(0, s.search(new TermQuery(new Term(\"packID\", subDocs.packID)), 1).totalHits);\n                      } finally {\n                        nrt.release(s);\n                      }\n                    }\n                  }\n                  toDeleteSubDocs.clear();\n                }\n                if (addedField != null) {\n                  doc.removeField(addedField);\n                }\n              } catch (Throwable t) {\n                System.out.println(Thread.currentThread().getName() + \": FAILED: hit exc\");\n                t.printStackTrace();\n                failed.set(true);\n                throw new RuntimeException(t);\n              }\n            }\n\n            lastGens.add(gen);\n            if (VERBOSE) {\n              System.out.println(Thread.currentThread().getName() + \": indexing done\");\n            }\n          }\n        };\n      threads[thread].setDaemon(true);\n      threads[thread].start();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: DONE start indexing threads [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    // let index build up a bit\n    Thread.sleep(100);\n\n    // silly starting guess:\n    final AtomicInteger totTermCount = new AtomicInteger(100);\n\n    // run search threads\n    final Thread[] searchThreads = new Thread[NUM_SEARCH_THREADS];\n    final AtomicInteger totHits = new AtomicInteger();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: start search threads\");\n    }\n\n    for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n      searchThreads[thread] = new Thread() {\n          @Override\n          public void run() {\n            while(System.currentTimeMillis() < stopTime && !failed.get()) {\n              final IndexSearcher s = nrt.get(random.nextBoolean());\n              try {\n                try {\n                  smokeTestSearcher(s);\n                  if (s.getIndexReader().numDocs() > 0) {\n                    Fields fields = MultiFields.getFields(s.getIndexReader());\n                    if (fields == null) {\n                      continue;\n                    }\n                    Terms terms = fields.terms(\"body\");\n                    if (terms == null) {\n                      continue;\n                    }\n\n                    TermsEnum termsEnum = terms.iterator();\n                    int seenTermCount = 0;\n                    int shift;\n                    int trigger;\n                    if (totTermCount.get() < 10) {\n                      shift = 0;\n                      trigger = 1;\n                    } else {\n                      trigger = totTermCount.get()/10;\n                      shift = random.nextInt(trigger);\n                    }\n\n                    while(System.currentTimeMillis() < stopTime) {\n                      BytesRef term = termsEnum.next();\n                      if (term == null) {\n                        if (seenTermCount == 0) {\n                          break;\n                        }\n                        totTermCount.set(seenTermCount);\n                        seenTermCount = 0;\n                        if (totTermCount.get() < 10) {\n                          shift = 0;\n                          trigger = 1;\n                        } else {\n                          trigger = totTermCount.get()/10;\n                          //System.out.println(\"trigger \" + trigger);\n                          shift = random.nextInt(trigger);\n                        }\n                        termsEnum.seekCeil(new BytesRef(\"\"));\n                        continue;\n                      }\n                      seenTermCount++;\n                      // search 10 terms\n                      if (trigger == 0) {\n                        trigger = 1;\n                      }\n                      if ((seenTermCount + shift) % trigger == 0) {\n                        //if (VERBOSE) {\n                        //System.out.println(Thread.currentThread().getName() + \" now search body:\" + term.utf8ToString());\n                        //}\n                        totHits.addAndGet(runQuery(s, new TermQuery(new Term(\"body\", term))));\n                      }\n                    }\n                    if (VERBOSE) {\n                      System.out.println(Thread.currentThread().getName() + \": search done\");\n                    }\n                  }\n                } finally {\n                  nrt.release(s);\n                }\n              } catch (Throwable t) {\n                System.out.println(Thread.currentThread().getName() + \": FAILED: hit exc\");\n                failed.set(true);\n                t.printStackTrace(System.out);\n                throw new RuntimeException(t);\n              }\n            }\n          }\n        };\n      searchThreads[thread].setDaemon(true);\n      searchThreads[thread].start();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now join\");\n    }\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread].join();\n    }\n    for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n      searchThreads[thread].join();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: done join [\" + (System.currentTimeMillis()-t0) + \" ms]; addCount=\" + addCount + \" delCount=\" + delCount);\n      System.out.println(\"TEST: search totHits=\" + totHits);\n    }\n\n    long maxGen = 0;\n    for(long gen : lastGens) {\n      maxGen = Math.max(maxGen, gen);\n    }\n\n    final IndexSearcher s = nrt.get(maxGen, true);\n\n    boolean doFail = false;\n    for(String id : delIDs) {\n      final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", id)), 1);\n      if (hits.totalHits != 0) {\n        System.out.println(\"doc id=\" + id + \" is supposed to be deleted, but got docID=\" + hits.scoreDocs[0].doc);\n        doFail = true;\n      }\n    }\n\n    // Make sure each group of sub-docs are still in docID order:\n    for(SubDocs subDocs : allSubDocs) {\n      if (!subDocs.deleted) {\n        // We sort by relevance but the scores should be identical so sort falls back to by docID:\n        TopDocs hits = s.search(new TermQuery(new Term(\"packID\", subDocs.packID)), 20);\n        assertEquals(subDocs.subIDs.size(), hits.totalHits);\n        int lastDocID = -1;\n        int startDocID = -1;\n        for(ScoreDoc scoreDoc : hits.scoreDocs) {\n          final int docID = scoreDoc.doc;\n          if (lastDocID != -1) {\n            assertEquals(1+lastDocID, docID);\n          } else {\n            startDocID = docID;\n          }\n          lastDocID = docID;\n          final Document doc = s.doc(docID);\n          assertEquals(subDocs.packID, doc.get(\"packID\"));\n        }\n\n        lastDocID = startDocID - 1;\n        for(String subID : subDocs.subIDs) {\n          hits = s.search(new TermQuery(new Term(\"docid\", subID)), 1);\n          assertEquals(1, hits.totalHits);\n          final int docID = hits.scoreDocs[0].doc;\n          if (lastDocID != -1) {\n            assertEquals(1+lastDocID, docID);\n          }\n          lastDocID = docID;\n        }          \n      } else {\n        for(String subID : subDocs.subIDs) {\n          assertEquals(0, s.search(new TermQuery(new Term(\"docid\", subID)), 1).totalHits);\n        }\n      }\n    }\n    \n    final int endID = Integer.parseInt(docs.nextDoc().get(\"docid\"));\n    for(int id=0;id<endID;id++) {\n      String stringID = \"\"+id;\n      if (!delIDs.contains(stringID)) {\n        final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", stringID)), 1);\n        if (hits.totalHits != 1) {\n          System.out.println(\"doc id=\" + stringID + \" is not supposed to be deleted, but got hitCount=\" + hits.totalHits);\n          doFail = true;\n        }\n      }\n    }\n    assertFalse(doFail);\n\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), s.getIndexReader().numDocs());\n    nrt.release(s);\n\n    if (es != null) {\n      es.shutdown();\n      es.awaitTermination(1, TimeUnit.SECONDS);\n    }\n\n    writer.commit();\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), writer.numDocs());\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now close NRTManager\");\n    }\n    nrtThread.close();\n    nrt.close();\n    assertFalse(writer.anyNonBulkMerges);\n    writer.close(false);\n    _TestUtil.checkIndex(dir);\n    dir.close();\n    _TestUtil.rmDir(tempDir);\n    docs.close();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testNRTManager() throws Exception {\n\n    final long t0 = System.currentTimeMillis();\n\n    if (CodecProvider.getDefault().getDefaultFieldCodec().equals(\"SimpleText\")) {\n      // no\n      CodecProvider.getDefault().setDefaultFieldCodec(\"Standard\");\n    }\n\n    final LineFileDocs docs = new LineFileDocs(random);\n    final File tempDir = _TestUtil.getTempDir(\"nrtopenfiles\");\n    final MockDirectoryWrapper _dir = newFSDirectory(tempDir);\n    _dir.setCheckIndexOnClose(false);  // don't double-checkIndex, we do it ourselves\n    Directory dir = _dir;\n    final IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).setOpenMode(IndexWriterConfig.OpenMode.CREATE);\n\n    if (LuceneTestCase.TEST_NIGHTLY) {\n      // newIWConfig makes smallish max seg size, which\n      // results in tons and tons of segments for this test\n      // when run nightly:\n      MergePolicy mp = conf.getMergePolicy();\n      if (mp instanceof TieredMergePolicy) {\n        ((TieredMergePolicy) mp).setMaxMergedSegmentMB(5000.);\n      } else if (mp instanceof LogByteSizeMergePolicy) {\n        ((LogByteSizeMergePolicy) mp).setMaxMergeMB(1000.);\n      } else if (mp instanceof LogMergePolicy) {\n        ((LogMergePolicy) mp).setMaxMergeDocs(100000);\n      }\n    }\n\n    conf.setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n      @Override\n      public void warm(IndexReader reader) throws IOException {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now warm merged reader=\" + reader);\n        }\n        final int maxDoc = reader.maxDoc();\n        final Bits delDocs = reader.getDeletedDocs();\n        int sum = 0;\n        final int inc = Math.max(1, maxDoc/50);\n        for(int docID=0;docID<maxDoc;docID += inc) {\n          if (delDocs == null || !delDocs.get(docID)) {\n            final Document doc = reader.document(docID);\n            sum += doc.getFields().size();\n          }\n        }\n\n        IndexSearcher searcher = newSearcher(reader);\n        sum += searcher.search(new TermQuery(new Term(\"body\", \"united\")), 10).totalHits;\n        searcher.close();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: warm visited \" + sum + \" fields\");\n        }\n      }\n      });\n\n    if (random.nextBoolean()) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: wrap NRTCachingDir\");\n      }\n\n      dir = new NRTCachingDirectory(dir, 5.0, 60.0);\n    }\n    \n    final IndexWriter writer = new IndexWriter(dir, conf);\n    \n    if (VERBOSE) {\n      writer.setInfoStream(System.out);\n    }\n    _TestUtil.reduceOpenFiles(writer);\n    //System.out.println(\"TEST: conf=\" + writer.getConfig());\n\n    final ExecutorService es = random.nextBoolean() ? null : Executors.newCachedThreadPool(new NamedThreadFactory(\"NRT search threads\"));\n\n    final double minReopenSec = 0.01 + 0.05 * random.nextDouble();\n    final double maxReopenSec = minReopenSec * (1.0 + 10 * random.nextDouble());\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: make NRTManager maxReopenSec=\" + maxReopenSec + \" minReopenSec=\" + minReopenSec);\n    }\n\n    final NRTManager nrt = new NRTManager(writer, es);\n    final NRTManagerReopenThread nrtThread = new NRTManagerReopenThread(nrt, maxReopenSec, minReopenSec);\n    nrtThread.setName(\"NRT Reopen Thread\");\n    nrtThread.setPriority(Math.min(Thread.currentThread().getPriority()+2, Thread.MAX_PRIORITY));\n    nrtThread.setDaemon(true);\n    nrtThread.start();\n\n    final int NUM_INDEX_THREADS = _TestUtil.nextInt(random, 1, 3);\n    final int NUM_SEARCH_THREADS = _TestUtil.nextInt(random, 1, 3);\n    //final int NUM_INDEX_THREADS = 1;\n    //final int NUM_SEARCH_THREADS = 1;\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + NUM_INDEX_THREADS + \" index threads; \" + NUM_SEARCH_THREADS + \" search threads\");\n    }\n\n    final int RUN_TIME_SEC = LuceneTestCase.TEST_NIGHTLY ? 300 : RANDOM_MULTIPLIER;\n\n    final AtomicBoolean failed = new AtomicBoolean();\n    final AtomicInteger addCount = new AtomicInteger();\n    final AtomicInteger delCount = new AtomicInteger();\n    final AtomicInteger packCount = new AtomicInteger();\n    final List<Long> lastGens = new ArrayList<Long>();\n\n    final Set<String> delIDs = Collections.synchronizedSet(new HashSet<String>());\n    final List<SubDocs> allSubDocs = Collections.synchronizedList(new ArrayList<SubDocs>());\n\n    final long stopTime = System.currentTimeMillis() + RUN_TIME_SEC*1000;\n    Thread[] threads = new Thread[NUM_INDEX_THREADS];\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread] = new Thread() {\n          @Override\n          public void run() {\n            // TODO: would be better if this were cross thread, so that we make sure one thread deleting anothers added docs works:\n            final List<String> toDeleteIDs = new ArrayList<String>();\n            final List<SubDocs> toDeleteSubDocs = new ArrayList<SubDocs>();\n\n            long gen = 0;\n            while(System.currentTimeMillis() < stopTime && !failed.get()) {\n\n              //System.out.println(Thread.currentThread().getName() + \": cycle\");\n              try {\n                // Occassional longish pause if running\n                // nightly\n                if (LuceneTestCase.TEST_NIGHTLY && random.nextInt(6) == 3) {\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": now long sleep\");\n                  }\n                  Thread.sleep(_TestUtil.nextInt(random, 50, 500));\n                }\n\n                // Rate limit ingest rate:\n                Thread.sleep(_TestUtil.nextInt(random, 1, 10));\n                if (VERBOSE) {\n                  System.out.println(Thread.currentThread() + \": done sleep\");\n                }\n\n                Document doc = docs.nextDoc();\n                if (doc == null) {\n                  break;\n                }\n                final String addedField;\n                if (random.nextBoolean()) {\n                  addedField = \"extra\" + random.nextInt(10);\n                  doc.add(new Field(addedField, \"a random field\", Field.Store.NO, Field.Index.ANALYZED));\n                } else {\n                  addedField = null;\n                }\n                if (random.nextBoolean()) {\n\n                  if (random.nextBoolean()) {\n                    // Add a pack of adjacent sub-docs\n                    final String packID;\n                    final SubDocs delSubDocs;\n                    if (toDeleteSubDocs.size() > 0 && random.nextBoolean()) {\n                      delSubDocs = toDeleteSubDocs.get(random.nextInt(toDeleteSubDocs.size()));\n                      assert !delSubDocs.deleted;\n                      toDeleteSubDocs.remove(delSubDocs);\n                      // reuse prior packID\n                      packID = delSubDocs.packID;\n                    } else {\n                      delSubDocs = null;\n                      // make new packID\n                      packID = packCount.getAndIncrement() + \"\";\n                    }\n\n                    final Field packIDField = newField(\"packID\", packID, Field.Store.YES, Field.Index.NOT_ANALYZED);\n                    final List<String> docIDs = new ArrayList<String>();\n                    final SubDocs subDocs = new SubDocs(packID, docIDs);\n                    final List<Document> docsList = new ArrayList<Document>();\n\n                    allSubDocs.add(subDocs);\n                    doc.add(packIDField);\n                    docsList.add(cloneDoc(doc));\n                    docIDs.add(doc.get(\"docid\"));\n\n                    final int maxDocCount = _TestUtil.nextInt(random, 1, 10);\n                    while(docsList.size() < maxDocCount) {\n                      doc = docs.nextDoc();\n                      if (doc == null) {\n                        break;\n                      }\n                      docsList.add(cloneDoc(doc));\n                      docIDs.add(doc.get(\"docid\"));\n                    }\n                    addCount.addAndGet(docsList.size());\n\n                    if (delSubDocs != null) {\n                      delSubDocs.deleted = true;\n                      delIDs.addAll(delSubDocs.subIDs);\n                      delCount.addAndGet(delSubDocs.subIDs.size());\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: update pack packID=\" + delSubDocs.packID + \" count=\" + docsList.size() + \" docs=\" + docIDs);\n                      }\n                      gen = nrt.updateDocuments(new Term(\"packID\", delSubDocs.packID), docsList);\n                      /*\n                      // non-atomic:\n                      nrt.deleteDocuments(new Term(\"packID\", delSubDocs.packID));\n                      for(Document subDoc : docsList) {\n                        nrt.addDocument(subDoc);\n                      }\n                      */\n                    } else {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: add pack packID=\" + packID + \" count=\" + docsList.size() + \" docs=\" + docIDs);\n                      }\n                      gen = nrt.addDocuments(docsList);\n                      \n                      /*\n                      // non-atomic:\n                      for(Document subDoc : docsList) {\n                        nrt.addDocument(subDoc);\n                      }\n                      */\n                    }\n                    doc.removeField(\"packID\");\n\n                    if (random.nextInt(5) == 2) {\n                      if (VERBOSE) {\n                        System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + packID);\n                      }\n                      toDeleteSubDocs.add(subDocs);\n                    }\n\n                    // randomly verify the add/update \"took\":\n                    if (random.nextInt(20) == 2) {\n                      final boolean applyDeletes = delSubDocs != null;\n                      final IndexSearcher s = nrt.get(gen, applyDeletes);\n                      try {\n                        assertEquals(docsList.size(), s.search(new TermQuery(new Term(\"packID\", packID)), 10).totalHits);\n                      } finally {\n                        nrt.release(s);\n                      }\n                    }\n\n                  } else {\n                    if (VERBOSE) {\n                      System.out.println(Thread.currentThread().getName() + \": add doc docid:\" + doc.get(\"docid\"));\n                    }\n\n                    gen = nrt.addDocument(doc);\n                    addCount.getAndIncrement();\n\n                    // randomly verify the add \"took\":\n                    if (random.nextInt(20) == 2) {\n                      //System.out.println(Thread.currentThread().getName() + \": verify\");\n                      final IndexSearcher s = nrt.get(gen, false);\n                      //System.out.println(Thread.currentThread().getName() + \": got s=\" + s);\n                      try {\n                        assertEquals(1, s.search(new TermQuery(new Term(\"docid\", doc.get(\"docid\"))), 10).totalHits);\n                      } finally {\n                        nrt.release(s);\n                      }\n                      //System.out.println(Thread.currentThread().getName() + \": done verify\");\n                    }\n\n                    if (random.nextInt(5) == 3) {\n                      if (VERBOSE) {\n                        System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                      }\n                      toDeleteIDs.add(doc.get(\"docid\"));\n                    }\n                  }\n                } else {\n                  // we use update but it never replaces a\n                  // prior doc\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": update doc id:\" + doc.get(\"docid\"));\n                  }\n                  gen = nrt.updateDocument(new Term(\"docid\", doc.get(\"docid\")), doc);\n                  addCount.getAndIncrement();\n\n                  // randomly verify the add \"took\":\n                  if (random.nextInt(20) == 2) {\n                    final IndexSearcher s = nrt.get(gen, true);\n                    try {\n                      assertEquals(1, s.search(new TermQuery(new Term(\"docid\", doc.get(\"docid\"))), 10).totalHits);\n                    } finally {\n                      nrt.release(s);\n                    }\n                  }\n\n                  if (random.nextInt(5) == 3) {\n                    if (VERBOSE) {\n                      System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                    }\n                    toDeleteIDs.add(doc.get(\"docid\"));\n                  }\n                }\n\n                if (random.nextInt(30) == 17) {\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": apply \" + toDeleteIDs.size() + \" deletes\");\n                  }\n                  for(String id : toDeleteIDs) {\n                    if (VERBOSE) {\n                      System.out.println(Thread.currentThread().getName() + \": del term=id:\" + id);\n                    }\n                    gen = nrt.deleteDocuments(new Term(\"docid\", id));\n\n                    // randomly verify the delete \"took\":\n                    if (random.nextInt(20) == 7) {\n                      final IndexSearcher s = nrt.get(gen, true);\n                      try {\n                        assertEquals(0, s.search(new TermQuery(new Term(\"docid\", id)), 10).totalHits);\n                      } finally {\n                        nrt.release(s);\n                      }\n                    }\n                  }\n\n                  final int count = delCount.addAndGet(toDeleteIDs.size());\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": tot \" + count + \" deletes\");\n                  }\n                  delIDs.addAll(toDeleteIDs);\n                  toDeleteIDs.clear();\n\n                  for(SubDocs subDocs : toDeleteSubDocs) {\n                    assertTrue(!subDocs.deleted);\n                    gen = nrt.deleteDocuments(new Term(\"packID\", subDocs.packID));\n                    subDocs.deleted = true;\n                    if (VERBOSE) {\n                      System.out.println(\"  del subs: \" + subDocs.subIDs + \" packID=\" + subDocs.packID);\n                    }\n                    delIDs.addAll(subDocs.subIDs);\n                    delCount.addAndGet(subDocs.subIDs.size());\n\n                    // randomly verify the delete \"took\":\n                    if (random.nextInt(20) == 7) {\n                      final IndexSearcher s = nrt.get(gen, true);\n                      try {\n                        assertEquals(0, s.search(new TermQuery(new Term(\"packID\", subDocs.packID)), 1).totalHits);\n                      } finally {\n                        nrt.release(s);\n                      }\n                    }\n                  }\n                  toDeleteSubDocs.clear();\n                }\n                if (addedField != null) {\n                  doc.removeField(addedField);\n                }\n              } catch (Throwable t) {\n                System.out.println(Thread.currentThread().getName() + \": FAILED: hit exc\");\n                t.printStackTrace();\n                failed.set(true);\n                throw new RuntimeException(t);\n              }\n            }\n\n            lastGens.add(gen);\n            if (VERBOSE) {\n              System.out.println(Thread.currentThread().getName() + \": indexing done\");\n            }\n          }\n        };\n      threads[thread].setDaemon(true);\n      threads[thread].start();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: DONE start indexing threads [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    // let index build up a bit\n    Thread.sleep(100);\n\n    // silly starting guess:\n    final AtomicInteger totTermCount = new AtomicInteger(100);\n\n    // run search threads\n    final Thread[] searchThreads = new Thread[NUM_SEARCH_THREADS];\n    final AtomicInteger totHits = new AtomicInteger();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: start search threads\");\n    }\n\n    for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n      searchThreads[thread] = new Thread() {\n          @Override\n          public void run() {\n            while(System.currentTimeMillis() < stopTime && !failed.get()) {\n              final IndexSearcher s = nrt.get(random.nextBoolean());\n              try {\n                try {\n                  smokeTestSearcher(s);\n                  if (s.getIndexReader().numDocs() > 0) {\n                    Fields fields = MultiFields.getFields(s.getIndexReader());\n                    if (fields == null) {\n                      continue;\n                    }\n                    Terms terms = fields.terms(\"body\");\n                    if (terms == null) {\n                      continue;\n                    }\n\n                    TermsEnum termsEnum = terms.iterator();\n                    int seenTermCount = 0;\n                    int shift;\n                    int trigger;\n                    if (totTermCount.get() < 10) {\n                      shift = 0;\n                      trigger = 1;\n                    } else {\n                      trigger = totTermCount.get()/10;\n                      shift = random.nextInt(trigger);\n                    }\n\n                    while(System.currentTimeMillis() < stopTime) {\n                      BytesRef term = termsEnum.next();\n                      if (term == null) {\n                        if (seenTermCount == 0) {\n                          break;\n                        }\n                        totTermCount.set(seenTermCount);\n                        seenTermCount = 0;\n                        if (totTermCount.get() < 10) {\n                          shift = 0;\n                          trigger = 1;\n                        } else {\n                          trigger = totTermCount.get()/10;\n                          //System.out.println(\"trigger \" + trigger);\n                          shift = random.nextInt(trigger);\n                        }\n                        termsEnum.seek(new BytesRef(\"\"));\n                        continue;\n                      }\n                      seenTermCount++;\n                      // search 10 terms\n                      if (trigger == 0) {\n                        trigger = 1;\n                      }\n                      if ((seenTermCount + shift) % trigger == 0) {\n                        //if (VERBOSE) {\n                        //System.out.println(Thread.currentThread().getName() + \" now search body:\" + term.utf8ToString());\n                        //}\n                        totHits.addAndGet(runQuery(s, new TermQuery(new Term(\"body\", term))));\n                      }\n                    }\n                    if (VERBOSE) {\n                      System.out.println(Thread.currentThread().getName() + \": search done\");\n                    }\n                  }\n                } finally {\n                  nrt.release(s);\n                }\n              } catch (Throwable t) {\n                System.out.println(Thread.currentThread().getName() + \": FAILED: hit exc\");\n                failed.set(true);\n                t.printStackTrace(System.out);\n                throw new RuntimeException(t);\n              }\n            }\n          }\n        };\n      searchThreads[thread].setDaemon(true);\n      searchThreads[thread].start();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now join\");\n    }\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread].join();\n    }\n    for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n      searchThreads[thread].join();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: done join [\" + (System.currentTimeMillis()-t0) + \" ms]; addCount=\" + addCount + \" delCount=\" + delCount);\n      System.out.println(\"TEST: search totHits=\" + totHits);\n    }\n\n    long maxGen = 0;\n    for(long gen : lastGens) {\n      maxGen = Math.max(maxGen, gen);\n    }\n\n    final IndexSearcher s = nrt.get(maxGen, true);\n\n    boolean doFail = false;\n    for(String id : delIDs) {\n      final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", id)), 1);\n      if (hits.totalHits != 0) {\n        System.out.println(\"doc id=\" + id + \" is supposed to be deleted, but got docID=\" + hits.scoreDocs[0].doc);\n        doFail = true;\n      }\n    }\n\n    // Make sure each group of sub-docs are still in docID order:\n    for(SubDocs subDocs : allSubDocs) {\n      if (!subDocs.deleted) {\n        // We sort by relevance but the scores should be identical so sort falls back to by docID:\n        TopDocs hits = s.search(new TermQuery(new Term(\"packID\", subDocs.packID)), 20);\n        assertEquals(subDocs.subIDs.size(), hits.totalHits);\n        int lastDocID = -1;\n        int startDocID = -1;\n        for(ScoreDoc scoreDoc : hits.scoreDocs) {\n          final int docID = scoreDoc.doc;\n          if (lastDocID != -1) {\n            assertEquals(1+lastDocID, docID);\n          } else {\n            startDocID = docID;\n          }\n          lastDocID = docID;\n          final Document doc = s.doc(docID);\n          assertEquals(subDocs.packID, doc.get(\"packID\"));\n        }\n\n        lastDocID = startDocID - 1;\n        for(String subID : subDocs.subIDs) {\n          hits = s.search(new TermQuery(new Term(\"docid\", subID)), 1);\n          assertEquals(1, hits.totalHits);\n          final int docID = hits.scoreDocs[0].doc;\n          if (lastDocID != -1) {\n            assertEquals(1+lastDocID, docID);\n          }\n          lastDocID = docID;\n        }          \n      } else {\n        for(String subID : subDocs.subIDs) {\n          assertEquals(0, s.search(new TermQuery(new Term(\"docid\", subID)), 1).totalHits);\n        }\n      }\n    }\n    \n    final int endID = Integer.parseInt(docs.nextDoc().get(\"docid\"));\n    for(int id=0;id<endID;id++) {\n      String stringID = \"\"+id;\n      if (!delIDs.contains(stringID)) {\n        final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", stringID)), 1);\n        if (hits.totalHits != 1) {\n          System.out.println(\"doc id=\" + stringID + \" is not supposed to be deleted, but got hitCount=\" + hits.totalHits);\n          doFail = true;\n        }\n      }\n    }\n    assertFalse(doFail);\n\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), s.getIndexReader().numDocs());\n    nrt.release(s);\n\n    if (es != null) {\n      es.shutdown();\n      es.awaitTermination(1, TimeUnit.SECONDS);\n    }\n\n    writer.commit();\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), writer.numDocs());\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now close NRTManager\");\n    }\n    nrtThread.close();\n    nrt.close();\n    assertFalse(writer.anyNonBulkMerges);\n    writer.close(false);\n    _TestUtil.checkIndex(dir);\n    dir.close();\n    _TestUtil.rmDir(tempDir);\n    docs.close();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ddc4c914be86e34b54f70023f45a60fa7f04e929","date":1310115160,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/contrib/misc/src/test/org/apache/lucene/index/TestNRTManager#testNRTManager().mjava","pathOld":"lucene/contrib/misc/src/test/org/apache/lucene/index/TestNRTManager#testNRTManager().mjava","sourceNew":"  @Test\n  public void testNRTManager() throws Exception {\n\n    final long t0 = System.currentTimeMillis();\n\n    if (CodecProvider.getDefault().getDefaultFieldCodec().equals(\"SimpleText\")) {\n      // no\n      CodecProvider.getDefault().setDefaultFieldCodec(\"Standard\");\n    }\n\n    final LineFileDocs docs = new LineFileDocs(random);\n    final File tempDir = _TestUtil.getTempDir(\"nrtopenfiles\");\n    final MockDirectoryWrapper _dir = newFSDirectory(tempDir);\n    _dir.setCheckIndexOnClose(false);  // don't double-checkIndex, we do it ourselves\n    Directory dir = _dir;\n    final IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).setOpenMode(IndexWriterConfig.OpenMode.CREATE);\n\n    if (LuceneTestCase.TEST_NIGHTLY) {\n      // newIWConfig makes smallish max seg size, which\n      // results in tons and tons of segments for this test\n      // when run nightly:\n      MergePolicy mp = conf.getMergePolicy();\n      if (mp instanceof TieredMergePolicy) {\n        ((TieredMergePolicy) mp).setMaxMergedSegmentMB(5000.);\n      } else if (mp instanceof LogByteSizeMergePolicy) {\n        ((LogByteSizeMergePolicy) mp).setMaxMergeMB(1000.);\n      } else if (mp instanceof LogMergePolicy) {\n        ((LogMergePolicy) mp).setMaxMergeDocs(100000);\n      }\n    }\n\n    conf.setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n      @Override\n      public void warm(IndexReader reader) throws IOException {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now warm merged reader=\" + reader);\n        }\n        final int maxDoc = reader.maxDoc();\n        final Bits liveDocs = reader.getLiveDocs();\n        int sum = 0;\n        final int inc = Math.max(1, maxDoc/50);\n        for(int docID=0;docID<maxDoc;docID += inc) {\n          if (liveDocs == null || liveDocs.get(docID)) {\n            final Document doc = reader.document(docID);\n            sum += doc.getFields().size();\n          }\n        }\n\n        IndexSearcher searcher = newSearcher(reader);\n        sum += searcher.search(new TermQuery(new Term(\"body\", \"united\")), 10).totalHits;\n        searcher.close();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: warm visited \" + sum + \" fields\");\n        }\n      }\n      });\n\n    if (random.nextBoolean()) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: wrap NRTCachingDir\");\n      }\n\n      dir = new NRTCachingDirectory(dir, 5.0, 60.0);\n    }\n    \n    final IndexWriter writer = new IndexWriter(dir, conf);\n    \n    if (VERBOSE) {\n      writer.setInfoStream(System.out);\n    }\n    _TestUtil.reduceOpenFiles(writer);\n    //System.out.println(\"TEST: conf=\" + writer.getConfig());\n\n    final ExecutorService es = random.nextBoolean() ? null : Executors.newCachedThreadPool(new NamedThreadFactory(\"NRT search threads\"));\n\n    final double minReopenSec = 0.01 + 0.05 * random.nextDouble();\n    final double maxReopenSec = minReopenSec * (1.0 + 10 * random.nextDouble());\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: make NRTManager maxReopenSec=\" + maxReopenSec + \" minReopenSec=\" + minReopenSec);\n    }\n\n    final NRTManager nrt = new NRTManager(writer, es);\n    final NRTManagerReopenThread nrtThread = new NRTManagerReopenThread(nrt, maxReopenSec, minReopenSec);\n    nrtThread.setName(\"NRT Reopen Thread\");\n    nrtThread.setPriority(Math.min(Thread.currentThread().getPriority()+2, Thread.MAX_PRIORITY));\n    nrtThread.setDaemon(true);\n    nrtThread.start();\n\n    final int NUM_INDEX_THREADS = _TestUtil.nextInt(random, 1, 3);\n    final int NUM_SEARCH_THREADS = _TestUtil.nextInt(random, 1, 3);\n    //final int NUM_INDEX_THREADS = 1;\n    //final int NUM_SEARCH_THREADS = 1;\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + NUM_INDEX_THREADS + \" index threads; \" + NUM_SEARCH_THREADS + \" search threads\");\n    }\n\n    final int RUN_TIME_SEC = LuceneTestCase.TEST_NIGHTLY ? 300 : RANDOM_MULTIPLIER;\n\n    final AtomicBoolean failed = new AtomicBoolean();\n    final AtomicInteger addCount = new AtomicInteger();\n    final AtomicInteger delCount = new AtomicInteger();\n    final AtomicInteger packCount = new AtomicInteger();\n    final List<Long> lastGens = new ArrayList<Long>();\n\n    final Set<String> delIDs = Collections.synchronizedSet(new HashSet<String>());\n    final List<SubDocs> allSubDocs = Collections.synchronizedList(new ArrayList<SubDocs>());\n\n    final long stopTime = System.currentTimeMillis() + RUN_TIME_SEC*1000;\n    Thread[] threads = new Thread[NUM_INDEX_THREADS];\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread] = new Thread() {\n          @Override\n          public void run() {\n            // TODO: would be better if this were cross thread, so that we make sure one thread deleting anothers added docs works:\n            final List<String> toDeleteIDs = new ArrayList<String>();\n            final List<SubDocs> toDeleteSubDocs = new ArrayList<SubDocs>();\n\n            long gen = 0;\n            while(System.currentTimeMillis() < stopTime && !failed.get()) {\n\n              //System.out.println(Thread.currentThread().getName() + \": cycle\");\n              try {\n                // Occassional longish pause if running\n                // nightly\n                if (LuceneTestCase.TEST_NIGHTLY && random.nextInt(6) == 3) {\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": now long sleep\");\n                  }\n                  Thread.sleep(_TestUtil.nextInt(random, 50, 500));\n                }\n\n                // Rate limit ingest rate:\n                Thread.sleep(_TestUtil.nextInt(random, 1, 10));\n                if (VERBOSE) {\n                  System.out.println(Thread.currentThread() + \": done sleep\");\n                }\n\n                Document doc = docs.nextDoc();\n                if (doc == null) {\n                  break;\n                }\n                final String addedField;\n                if (random.nextBoolean()) {\n                  addedField = \"extra\" + random.nextInt(10);\n                  doc.add(new Field(addedField, \"a random field\", Field.Store.NO, Field.Index.ANALYZED));\n                } else {\n                  addedField = null;\n                }\n                if (random.nextBoolean()) {\n\n                  if (random.nextBoolean()) {\n                    // Add a pack of adjacent sub-docs\n                    final String packID;\n                    final SubDocs delSubDocs;\n                    if (toDeleteSubDocs.size() > 0 && random.nextBoolean()) {\n                      delSubDocs = toDeleteSubDocs.get(random.nextInt(toDeleteSubDocs.size()));\n                      assert !delSubDocs.deleted;\n                      toDeleteSubDocs.remove(delSubDocs);\n                      // reuse prior packID\n                      packID = delSubDocs.packID;\n                    } else {\n                      delSubDocs = null;\n                      // make new packID\n                      packID = packCount.getAndIncrement() + \"\";\n                    }\n\n                    final Field packIDField = newField(\"packID\", packID, Field.Store.YES, Field.Index.NOT_ANALYZED);\n                    final List<String> docIDs = new ArrayList<String>();\n                    final SubDocs subDocs = new SubDocs(packID, docIDs);\n                    final List<Document> docsList = new ArrayList<Document>();\n\n                    allSubDocs.add(subDocs);\n                    doc.add(packIDField);\n                    docsList.add(cloneDoc(doc));\n                    docIDs.add(doc.get(\"docid\"));\n\n                    final int maxDocCount = _TestUtil.nextInt(random, 1, 10);\n                    while(docsList.size() < maxDocCount) {\n                      doc = docs.nextDoc();\n                      if (doc == null) {\n                        break;\n                      }\n                      docsList.add(cloneDoc(doc));\n                      docIDs.add(doc.get(\"docid\"));\n                    }\n                    addCount.addAndGet(docsList.size());\n\n                    if (delSubDocs != null) {\n                      delSubDocs.deleted = true;\n                      delIDs.addAll(delSubDocs.subIDs);\n                      delCount.addAndGet(delSubDocs.subIDs.size());\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: update pack packID=\" + delSubDocs.packID + \" count=\" + docsList.size() + \" docs=\" + docIDs);\n                      }\n                      gen = nrt.updateDocuments(new Term(\"packID\", delSubDocs.packID), docsList);\n                      /*\n                      // non-atomic:\n                      nrt.deleteDocuments(new Term(\"packID\", delSubDocs.packID));\n                      for(Document subDoc : docsList) {\n                        nrt.addDocument(subDoc);\n                      }\n                      */\n                    } else {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: add pack packID=\" + packID + \" count=\" + docsList.size() + \" docs=\" + docIDs);\n                      }\n                      gen = nrt.addDocuments(docsList);\n                      \n                      /*\n                      // non-atomic:\n                      for(Document subDoc : docsList) {\n                        nrt.addDocument(subDoc);\n                      }\n                      */\n                    }\n                    doc.removeField(\"packID\");\n\n                    if (random.nextInt(5) == 2) {\n                      if (VERBOSE) {\n                        System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + packID);\n                      }\n                      toDeleteSubDocs.add(subDocs);\n                    }\n\n                    // randomly verify the add/update \"took\":\n                    if (random.nextInt(20) == 2) {\n                      final boolean applyDeletes = delSubDocs != null;\n                      final IndexSearcher s = nrt.get(gen, applyDeletes);\n                      try {\n                        assertEquals(docsList.size(), s.search(new TermQuery(new Term(\"packID\", packID)), 10).totalHits);\n                      } finally {\n                        nrt.release(s);\n                      }\n                    }\n\n                  } else {\n                    if (VERBOSE) {\n                      System.out.println(Thread.currentThread().getName() + \": add doc docid:\" + doc.get(\"docid\"));\n                    }\n\n                    gen = nrt.addDocument(doc);\n                    addCount.getAndIncrement();\n\n                    // randomly verify the add \"took\":\n                    if (random.nextInt(20) == 2) {\n                      //System.out.println(Thread.currentThread().getName() + \": verify\");\n                      final IndexSearcher s = nrt.get(gen, false);\n                      //System.out.println(Thread.currentThread().getName() + \": got s=\" + s);\n                      try {\n                        assertEquals(1, s.search(new TermQuery(new Term(\"docid\", doc.get(\"docid\"))), 10).totalHits);\n                      } finally {\n                        nrt.release(s);\n                      }\n                      //System.out.println(Thread.currentThread().getName() + \": done verify\");\n                    }\n\n                    if (random.nextInt(5) == 3) {\n                      if (VERBOSE) {\n                        System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                      }\n                      toDeleteIDs.add(doc.get(\"docid\"));\n                    }\n                  }\n                } else {\n                  // we use update but it never replaces a\n                  // prior doc\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": update doc id:\" + doc.get(\"docid\"));\n                  }\n                  gen = nrt.updateDocument(new Term(\"docid\", doc.get(\"docid\")), doc);\n                  addCount.getAndIncrement();\n\n                  // randomly verify the add \"took\":\n                  if (random.nextInt(20) == 2) {\n                    final IndexSearcher s = nrt.get(gen, true);\n                    try {\n                      assertEquals(1, s.search(new TermQuery(new Term(\"docid\", doc.get(\"docid\"))), 10).totalHits);\n                    } finally {\n                      nrt.release(s);\n                    }\n                  }\n\n                  if (random.nextInt(5) == 3) {\n                    if (VERBOSE) {\n                      System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                    }\n                    toDeleteIDs.add(doc.get(\"docid\"));\n                  }\n                }\n\n                if (random.nextInt(30) == 17) {\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": apply \" + toDeleteIDs.size() + \" deletes\");\n                  }\n                  for(String id : toDeleteIDs) {\n                    if (VERBOSE) {\n                      System.out.println(Thread.currentThread().getName() + \": del term=id:\" + id);\n                    }\n                    gen = nrt.deleteDocuments(new Term(\"docid\", id));\n\n                    // randomly verify the delete \"took\":\n                    if (random.nextInt(20) == 7) {\n                      final IndexSearcher s = nrt.get(gen, true);\n                      try {\n                        assertEquals(0, s.search(new TermQuery(new Term(\"docid\", id)), 10).totalHits);\n                      } finally {\n                        nrt.release(s);\n                      }\n                    }\n                  }\n\n                  final int count = delCount.addAndGet(toDeleteIDs.size());\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": tot \" + count + \" deletes\");\n                  }\n                  delIDs.addAll(toDeleteIDs);\n                  toDeleteIDs.clear();\n\n                  for(SubDocs subDocs : toDeleteSubDocs) {\n                    assertTrue(!subDocs.deleted);\n                    gen = nrt.deleteDocuments(new Term(\"packID\", subDocs.packID));\n                    subDocs.deleted = true;\n                    if (VERBOSE) {\n                      System.out.println(\"  del subs: \" + subDocs.subIDs + \" packID=\" + subDocs.packID);\n                    }\n                    delIDs.addAll(subDocs.subIDs);\n                    delCount.addAndGet(subDocs.subIDs.size());\n\n                    // randomly verify the delete \"took\":\n                    if (random.nextInt(20) == 7) {\n                      final IndexSearcher s = nrt.get(gen, true);\n                      try {\n                        assertEquals(0, s.search(new TermQuery(new Term(\"packID\", subDocs.packID)), 1).totalHits);\n                      } finally {\n                        nrt.release(s);\n                      }\n                    }\n                  }\n                  toDeleteSubDocs.clear();\n                }\n                if (addedField != null) {\n                  doc.removeField(addedField);\n                }\n              } catch (Throwable t) {\n                System.out.println(Thread.currentThread().getName() + \": FAILED: hit exc\");\n                t.printStackTrace();\n                failed.set(true);\n                throw new RuntimeException(t);\n              }\n            }\n\n            lastGens.add(gen);\n            if (VERBOSE) {\n              System.out.println(Thread.currentThread().getName() + \": indexing done\");\n            }\n          }\n        };\n      threads[thread].setDaemon(true);\n      threads[thread].start();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: DONE start indexing threads [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    // let index build up a bit\n    Thread.sleep(100);\n\n    // silly starting guess:\n    final AtomicInteger totTermCount = new AtomicInteger(100);\n\n    // run search threads\n    final Thread[] searchThreads = new Thread[NUM_SEARCH_THREADS];\n    final AtomicInteger totHits = new AtomicInteger();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: start search threads\");\n    }\n\n    for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n      searchThreads[thread] = new Thread() {\n          @Override\n          public void run() {\n            while(System.currentTimeMillis() < stopTime && !failed.get()) {\n              final IndexSearcher s = nrt.get(random.nextBoolean());\n              try {\n                try {\n                  smokeTestSearcher(s);\n                  if (s.getIndexReader().numDocs() > 0) {\n                    Fields fields = MultiFields.getFields(s.getIndexReader());\n                    if (fields == null) {\n                      continue;\n                    }\n                    Terms terms = fields.terms(\"body\");\n                    if (terms == null) {\n                      continue;\n                    }\n\n                    TermsEnum termsEnum = terms.iterator();\n                    int seenTermCount = 0;\n                    int shift;\n                    int trigger;\n                    if (totTermCount.get() < 10) {\n                      shift = 0;\n                      trigger = 1;\n                    } else {\n                      trigger = totTermCount.get()/10;\n                      shift = random.nextInt(trigger);\n                    }\n\n                    while(System.currentTimeMillis() < stopTime) {\n                      BytesRef term = termsEnum.next();\n                      if (term == null) {\n                        if (seenTermCount == 0) {\n                          break;\n                        }\n                        totTermCount.set(seenTermCount);\n                        seenTermCount = 0;\n                        if (totTermCount.get() < 10) {\n                          shift = 0;\n                          trigger = 1;\n                        } else {\n                          trigger = totTermCount.get()/10;\n                          //System.out.println(\"trigger \" + trigger);\n                          shift = random.nextInt(trigger);\n                        }\n                        termsEnum.seekCeil(new BytesRef(\"\"));\n                        continue;\n                      }\n                      seenTermCount++;\n                      // search 10 terms\n                      if (trigger == 0) {\n                        trigger = 1;\n                      }\n                      if ((seenTermCount + shift) % trigger == 0) {\n                        //if (VERBOSE) {\n                        //System.out.println(Thread.currentThread().getName() + \" now search body:\" + term.utf8ToString());\n                        //}\n                        totHits.addAndGet(runQuery(s, new TermQuery(new Term(\"body\", term))));\n                      }\n                    }\n                    if (VERBOSE) {\n                      System.out.println(Thread.currentThread().getName() + \": search done\");\n                    }\n                  }\n                } finally {\n                  nrt.release(s);\n                }\n              } catch (Throwable t) {\n                System.out.println(Thread.currentThread().getName() + \": FAILED: hit exc\");\n                failed.set(true);\n                t.printStackTrace(System.out);\n                throw new RuntimeException(t);\n              }\n            }\n          }\n        };\n      searchThreads[thread].setDaemon(true);\n      searchThreads[thread].start();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now join\");\n    }\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread].join();\n    }\n    for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n      searchThreads[thread].join();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: done join [\" + (System.currentTimeMillis()-t0) + \" ms]; addCount=\" + addCount + \" delCount=\" + delCount);\n      System.out.println(\"TEST: search totHits=\" + totHits);\n    }\n\n    long maxGen = 0;\n    for(long gen : lastGens) {\n      maxGen = Math.max(maxGen, gen);\n    }\n\n    final IndexSearcher s = nrt.get(maxGen, true);\n\n    boolean doFail = false;\n    for(String id : delIDs) {\n      final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", id)), 1);\n      if (hits.totalHits != 0) {\n        System.out.println(\"doc id=\" + id + \" is supposed to be deleted, but got docID=\" + hits.scoreDocs[0].doc);\n        doFail = true;\n      }\n    }\n\n    // Make sure each group of sub-docs are still in docID order:\n    for(SubDocs subDocs : allSubDocs) {\n      if (!subDocs.deleted) {\n        // We sort by relevance but the scores should be identical so sort falls back to by docID:\n        TopDocs hits = s.search(new TermQuery(new Term(\"packID\", subDocs.packID)), 20);\n        assertEquals(subDocs.subIDs.size(), hits.totalHits);\n        int lastDocID = -1;\n        int startDocID = -1;\n        for(ScoreDoc scoreDoc : hits.scoreDocs) {\n          final int docID = scoreDoc.doc;\n          if (lastDocID != -1) {\n            assertEquals(1+lastDocID, docID);\n          } else {\n            startDocID = docID;\n          }\n          lastDocID = docID;\n          final Document doc = s.doc(docID);\n          assertEquals(subDocs.packID, doc.get(\"packID\"));\n        }\n\n        lastDocID = startDocID - 1;\n        for(String subID : subDocs.subIDs) {\n          hits = s.search(new TermQuery(new Term(\"docid\", subID)), 1);\n          assertEquals(1, hits.totalHits);\n          final int docID = hits.scoreDocs[0].doc;\n          if (lastDocID != -1) {\n            assertEquals(1+lastDocID, docID);\n          }\n          lastDocID = docID;\n        }          \n      } else {\n        for(String subID : subDocs.subIDs) {\n          assertEquals(0, s.search(new TermQuery(new Term(\"docid\", subID)), 1).totalHits);\n        }\n      }\n    }\n    \n    final int endID = Integer.parseInt(docs.nextDoc().get(\"docid\"));\n    for(int id=0;id<endID;id++) {\n      String stringID = \"\"+id;\n      if (!delIDs.contains(stringID)) {\n        final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", stringID)), 1);\n        if (hits.totalHits != 1) {\n          System.out.println(\"doc id=\" + stringID + \" is not supposed to be deleted, but got hitCount=\" + hits.totalHits);\n          doFail = true;\n        }\n      }\n    }\n    assertFalse(doFail);\n\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), s.getIndexReader().numDocs());\n    nrt.release(s);\n\n    if (es != null) {\n      es.shutdown();\n      es.awaitTermination(1, TimeUnit.SECONDS);\n    }\n\n    writer.commit();\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), writer.numDocs());\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now close NRTManager\");\n    }\n    nrtThread.close();\n    nrt.close();\n    assertFalse(writer.anyNonBulkMerges);\n    writer.close(false);\n    _TestUtil.checkIndex(dir);\n    dir.close();\n    _TestUtil.rmDir(tempDir);\n    docs.close();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testNRTManager() throws Exception {\n\n    final long t0 = System.currentTimeMillis();\n\n    if (CodecProvider.getDefault().getDefaultFieldCodec().equals(\"SimpleText\")) {\n      // no\n      CodecProvider.getDefault().setDefaultFieldCodec(\"Standard\");\n    }\n\n    final LineFileDocs docs = new LineFileDocs(random);\n    final File tempDir = _TestUtil.getTempDir(\"nrtopenfiles\");\n    final MockDirectoryWrapper _dir = newFSDirectory(tempDir);\n    _dir.setCheckIndexOnClose(false);  // don't double-checkIndex, we do it ourselves\n    Directory dir = _dir;\n    final IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).setOpenMode(IndexWriterConfig.OpenMode.CREATE);\n\n    if (LuceneTestCase.TEST_NIGHTLY) {\n      // newIWConfig makes smallish max seg size, which\n      // results in tons and tons of segments for this test\n      // when run nightly:\n      MergePolicy mp = conf.getMergePolicy();\n      if (mp instanceof TieredMergePolicy) {\n        ((TieredMergePolicy) mp).setMaxMergedSegmentMB(5000.);\n      } else if (mp instanceof LogByteSizeMergePolicy) {\n        ((LogByteSizeMergePolicy) mp).setMaxMergeMB(1000.);\n      } else if (mp instanceof LogMergePolicy) {\n        ((LogMergePolicy) mp).setMaxMergeDocs(100000);\n      }\n    }\n\n    conf.setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n      @Override\n      public void warm(IndexReader reader) throws IOException {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now warm merged reader=\" + reader);\n        }\n        final int maxDoc = reader.maxDoc();\n        final Bits liveDocs = reader.getLiveDocs();\n        int sum = 0;\n        final int inc = Math.max(1, maxDoc/50);\n        for(int docID=0;docID<maxDoc;docID += inc) {\n          if (liveDocs == null || liveDocs.get(docID)) {\n            final Document doc = reader.document(docID);\n            sum += doc.getFields().size();\n          }\n        }\n\n        IndexSearcher searcher = newSearcher(reader);\n        sum += searcher.search(new TermQuery(new Term(\"body\", \"united\")), 10).totalHits;\n        searcher.close();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: warm visited \" + sum + \" fields\");\n        }\n      }\n      });\n\n    if (random.nextBoolean()) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: wrap NRTCachingDir\");\n      }\n\n      NRTCachingDirectory nrtDir = new NRTCachingDirectory(dir, 5.0, 60.0);\n      conf.setMergeScheduler(nrtDir.getMergeScheduler());\n      dir = nrtDir;\n    }\n    \n    final IndexWriter writer = new IndexWriter(dir, conf);\n    \n    if (VERBOSE) {\n      writer.setInfoStream(System.out);\n    }\n    _TestUtil.reduceOpenFiles(writer);\n    //System.out.println(\"TEST: conf=\" + writer.getConfig());\n\n    final ExecutorService es = random.nextBoolean() ? null : Executors.newCachedThreadPool(new NamedThreadFactory(\"NRT search threads\"));\n\n    final double minReopenSec = 0.01 + 0.05 * random.nextDouble();\n    final double maxReopenSec = minReopenSec * (1.0 + 10 * random.nextDouble());\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: make NRTManager maxReopenSec=\" + maxReopenSec + \" minReopenSec=\" + minReopenSec);\n    }\n\n    final NRTManager nrt = new NRTManager(writer, es);\n    final NRTManagerReopenThread nrtThread = new NRTManagerReopenThread(nrt, maxReopenSec, minReopenSec);\n    nrtThread.setName(\"NRT Reopen Thread\");\n    nrtThread.setPriority(Math.min(Thread.currentThread().getPriority()+2, Thread.MAX_PRIORITY));\n    nrtThread.setDaemon(true);\n    nrtThread.start();\n\n    final int NUM_INDEX_THREADS = _TestUtil.nextInt(random, 1, 3);\n    final int NUM_SEARCH_THREADS = _TestUtil.nextInt(random, 1, 3);\n    //final int NUM_INDEX_THREADS = 1;\n    //final int NUM_SEARCH_THREADS = 1;\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + NUM_INDEX_THREADS + \" index threads; \" + NUM_SEARCH_THREADS + \" search threads\");\n    }\n\n    final int RUN_TIME_SEC = LuceneTestCase.TEST_NIGHTLY ? 300 : RANDOM_MULTIPLIER;\n\n    final AtomicBoolean failed = new AtomicBoolean();\n    final AtomicInteger addCount = new AtomicInteger();\n    final AtomicInteger delCount = new AtomicInteger();\n    final AtomicInteger packCount = new AtomicInteger();\n    final List<Long> lastGens = new ArrayList<Long>();\n\n    final Set<String> delIDs = Collections.synchronizedSet(new HashSet<String>());\n    final List<SubDocs> allSubDocs = Collections.synchronizedList(new ArrayList<SubDocs>());\n\n    final long stopTime = System.currentTimeMillis() + RUN_TIME_SEC*1000;\n    Thread[] threads = new Thread[NUM_INDEX_THREADS];\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread] = new Thread() {\n          @Override\n          public void run() {\n            // TODO: would be better if this were cross thread, so that we make sure one thread deleting anothers added docs works:\n            final List<String> toDeleteIDs = new ArrayList<String>();\n            final List<SubDocs> toDeleteSubDocs = new ArrayList<SubDocs>();\n\n            long gen = 0;\n            while(System.currentTimeMillis() < stopTime && !failed.get()) {\n\n              //System.out.println(Thread.currentThread().getName() + \": cycle\");\n              try {\n                // Occassional longish pause if running\n                // nightly\n                if (LuceneTestCase.TEST_NIGHTLY && random.nextInt(6) == 3) {\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": now long sleep\");\n                  }\n                  Thread.sleep(_TestUtil.nextInt(random, 50, 500));\n                }\n\n                // Rate limit ingest rate:\n                Thread.sleep(_TestUtil.nextInt(random, 1, 10));\n                if (VERBOSE) {\n                  System.out.println(Thread.currentThread() + \": done sleep\");\n                }\n\n                Document doc = docs.nextDoc();\n                if (doc == null) {\n                  break;\n                }\n                final String addedField;\n                if (random.nextBoolean()) {\n                  addedField = \"extra\" + random.nextInt(10);\n                  doc.add(new Field(addedField, \"a random field\", Field.Store.NO, Field.Index.ANALYZED));\n                } else {\n                  addedField = null;\n                }\n                if (random.nextBoolean()) {\n\n                  if (random.nextBoolean()) {\n                    // Add a pack of adjacent sub-docs\n                    final String packID;\n                    final SubDocs delSubDocs;\n                    if (toDeleteSubDocs.size() > 0 && random.nextBoolean()) {\n                      delSubDocs = toDeleteSubDocs.get(random.nextInt(toDeleteSubDocs.size()));\n                      assert !delSubDocs.deleted;\n                      toDeleteSubDocs.remove(delSubDocs);\n                      // reuse prior packID\n                      packID = delSubDocs.packID;\n                    } else {\n                      delSubDocs = null;\n                      // make new packID\n                      packID = packCount.getAndIncrement() + \"\";\n                    }\n\n                    final Field packIDField = newField(\"packID\", packID, Field.Store.YES, Field.Index.NOT_ANALYZED);\n                    final List<String> docIDs = new ArrayList<String>();\n                    final SubDocs subDocs = new SubDocs(packID, docIDs);\n                    final List<Document> docsList = new ArrayList<Document>();\n\n                    allSubDocs.add(subDocs);\n                    doc.add(packIDField);\n                    docsList.add(cloneDoc(doc));\n                    docIDs.add(doc.get(\"docid\"));\n\n                    final int maxDocCount = _TestUtil.nextInt(random, 1, 10);\n                    while(docsList.size() < maxDocCount) {\n                      doc = docs.nextDoc();\n                      if (doc == null) {\n                        break;\n                      }\n                      docsList.add(cloneDoc(doc));\n                      docIDs.add(doc.get(\"docid\"));\n                    }\n                    addCount.addAndGet(docsList.size());\n\n                    if (delSubDocs != null) {\n                      delSubDocs.deleted = true;\n                      delIDs.addAll(delSubDocs.subIDs);\n                      delCount.addAndGet(delSubDocs.subIDs.size());\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: update pack packID=\" + delSubDocs.packID + \" count=\" + docsList.size() + \" docs=\" + docIDs);\n                      }\n                      gen = nrt.updateDocuments(new Term(\"packID\", delSubDocs.packID), docsList);\n                      /*\n                      // non-atomic:\n                      nrt.deleteDocuments(new Term(\"packID\", delSubDocs.packID));\n                      for(Document subDoc : docsList) {\n                        nrt.addDocument(subDoc);\n                      }\n                      */\n                    } else {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: add pack packID=\" + packID + \" count=\" + docsList.size() + \" docs=\" + docIDs);\n                      }\n                      gen = nrt.addDocuments(docsList);\n                      \n                      /*\n                      // non-atomic:\n                      for(Document subDoc : docsList) {\n                        nrt.addDocument(subDoc);\n                      }\n                      */\n                    }\n                    doc.removeField(\"packID\");\n\n                    if (random.nextInt(5) == 2) {\n                      if (VERBOSE) {\n                        System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + packID);\n                      }\n                      toDeleteSubDocs.add(subDocs);\n                    }\n\n                    // randomly verify the add/update \"took\":\n                    if (random.nextInt(20) == 2) {\n                      final boolean applyDeletes = delSubDocs != null;\n                      final IndexSearcher s = nrt.get(gen, applyDeletes);\n                      try {\n                        assertEquals(docsList.size(), s.search(new TermQuery(new Term(\"packID\", packID)), 10).totalHits);\n                      } finally {\n                        nrt.release(s);\n                      }\n                    }\n\n                  } else {\n                    if (VERBOSE) {\n                      System.out.println(Thread.currentThread().getName() + \": add doc docid:\" + doc.get(\"docid\"));\n                    }\n\n                    gen = nrt.addDocument(doc);\n                    addCount.getAndIncrement();\n\n                    // randomly verify the add \"took\":\n                    if (random.nextInt(20) == 2) {\n                      //System.out.println(Thread.currentThread().getName() + \": verify\");\n                      final IndexSearcher s = nrt.get(gen, false);\n                      //System.out.println(Thread.currentThread().getName() + \": got s=\" + s);\n                      try {\n                        assertEquals(1, s.search(new TermQuery(new Term(\"docid\", doc.get(\"docid\"))), 10).totalHits);\n                      } finally {\n                        nrt.release(s);\n                      }\n                      //System.out.println(Thread.currentThread().getName() + \": done verify\");\n                    }\n\n                    if (random.nextInt(5) == 3) {\n                      if (VERBOSE) {\n                        System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                      }\n                      toDeleteIDs.add(doc.get(\"docid\"));\n                    }\n                  }\n                } else {\n                  // we use update but it never replaces a\n                  // prior doc\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": update doc id:\" + doc.get(\"docid\"));\n                  }\n                  gen = nrt.updateDocument(new Term(\"docid\", doc.get(\"docid\")), doc);\n                  addCount.getAndIncrement();\n\n                  // randomly verify the add \"took\":\n                  if (random.nextInt(20) == 2) {\n                    final IndexSearcher s = nrt.get(gen, true);\n                    try {\n                      assertEquals(1, s.search(new TermQuery(new Term(\"docid\", doc.get(\"docid\"))), 10).totalHits);\n                    } finally {\n                      nrt.release(s);\n                    }\n                  }\n\n                  if (random.nextInt(5) == 3) {\n                    if (VERBOSE) {\n                      System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                    }\n                    toDeleteIDs.add(doc.get(\"docid\"));\n                  }\n                }\n\n                if (random.nextInt(30) == 17) {\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": apply \" + toDeleteIDs.size() + \" deletes\");\n                  }\n                  for(String id : toDeleteIDs) {\n                    if (VERBOSE) {\n                      System.out.println(Thread.currentThread().getName() + \": del term=id:\" + id);\n                    }\n                    gen = nrt.deleteDocuments(new Term(\"docid\", id));\n\n                    // randomly verify the delete \"took\":\n                    if (random.nextInt(20) == 7) {\n                      final IndexSearcher s = nrt.get(gen, true);\n                      try {\n                        assertEquals(0, s.search(new TermQuery(new Term(\"docid\", id)), 10).totalHits);\n                      } finally {\n                        nrt.release(s);\n                      }\n                    }\n                  }\n\n                  final int count = delCount.addAndGet(toDeleteIDs.size());\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": tot \" + count + \" deletes\");\n                  }\n                  delIDs.addAll(toDeleteIDs);\n                  toDeleteIDs.clear();\n\n                  for(SubDocs subDocs : toDeleteSubDocs) {\n                    assertTrue(!subDocs.deleted);\n                    gen = nrt.deleteDocuments(new Term(\"packID\", subDocs.packID));\n                    subDocs.deleted = true;\n                    if (VERBOSE) {\n                      System.out.println(\"  del subs: \" + subDocs.subIDs + \" packID=\" + subDocs.packID);\n                    }\n                    delIDs.addAll(subDocs.subIDs);\n                    delCount.addAndGet(subDocs.subIDs.size());\n\n                    // randomly verify the delete \"took\":\n                    if (random.nextInt(20) == 7) {\n                      final IndexSearcher s = nrt.get(gen, true);\n                      try {\n                        assertEquals(0, s.search(new TermQuery(new Term(\"packID\", subDocs.packID)), 1).totalHits);\n                      } finally {\n                        nrt.release(s);\n                      }\n                    }\n                  }\n                  toDeleteSubDocs.clear();\n                }\n                if (addedField != null) {\n                  doc.removeField(addedField);\n                }\n              } catch (Throwable t) {\n                System.out.println(Thread.currentThread().getName() + \": FAILED: hit exc\");\n                t.printStackTrace();\n                failed.set(true);\n                throw new RuntimeException(t);\n              }\n            }\n\n            lastGens.add(gen);\n            if (VERBOSE) {\n              System.out.println(Thread.currentThread().getName() + \": indexing done\");\n            }\n          }\n        };\n      threads[thread].setDaemon(true);\n      threads[thread].start();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: DONE start indexing threads [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    // let index build up a bit\n    Thread.sleep(100);\n\n    // silly starting guess:\n    final AtomicInteger totTermCount = new AtomicInteger(100);\n\n    // run search threads\n    final Thread[] searchThreads = new Thread[NUM_SEARCH_THREADS];\n    final AtomicInteger totHits = new AtomicInteger();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: start search threads\");\n    }\n\n    for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n      searchThreads[thread] = new Thread() {\n          @Override\n          public void run() {\n            while(System.currentTimeMillis() < stopTime && !failed.get()) {\n              final IndexSearcher s = nrt.get(random.nextBoolean());\n              try {\n                try {\n                  smokeTestSearcher(s);\n                  if (s.getIndexReader().numDocs() > 0) {\n                    Fields fields = MultiFields.getFields(s.getIndexReader());\n                    if (fields == null) {\n                      continue;\n                    }\n                    Terms terms = fields.terms(\"body\");\n                    if (terms == null) {\n                      continue;\n                    }\n\n                    TermsEnum termsEnum = terms.iterator();\n                    int seenTermCount = 0;\n                    int shift;\n                    int trigger;\n                    if (totTermCount.get() < 10) {\n                      shift = 0;\n                      trigger = 1;\n                    } else {\n                      trigger = totTermCount.get()/10;\n                      shift = random.nextInt(trigger);\n                    }\n\n                    while(System.currentTimeMillis() < stopTime) {\n                      BytesRef term = termsEnum.next();\n                      if (term == null) {\n                        if (seenTermCount == 0) {\n                          break;\n                        }\n                        totTermCount.set(seenTermCount);\n                        seenTermCount = 0;\n                        if (totTermCount.get() < 10) {\n                          shift = 0;\n                          trigger = 1;\n                        } else {\n                          trigger = totTermCount.get()/10;\n                          //System.out.println(\"trigger \" + trigger);\n                          shift = random.nextInt(trigger);\n                        }\n                        termsEnum.seekCeil(new BytesRef(\"\"));\n                        continue;\n                      }\n                      seenTermCount++;\n                      // search 10 terms\n                      if (trigger == 0) {\n                        trigger = 1;\n                      }\n                      if ((seenTermCount + shift) % trigger == 0) {\n                        //if (VERBOSE) {\n                        //System.out.println(Thread.currentThread().getName() + \" now search body:\" + term.utf8ToString());\n                        //}\n                        totHits.addAndGet(runQuery(s, new TermQuery(new Term(\"body\", term))));\n                      }\n                    }\n                    if (VERBOSE) {\n                      System.out.println(Thread.currentThread().getName() + \": search done\");\n                    }\n                  }\n                } finally {\n                  nrt.release(s);\n                }\n              } catch (Throwable t) {\n                System.out.println(Thread.currentThread().getName() + \": FAILED: hit exc\");\n                failed.set(true);\n                t.printStackTrace(System.out);\n                throw new RuntimeException(t);\n              }\n            }\n          }\n        };\n      searchThreads[thread].setDaemon(true);\n      searchThreads[thread].start();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now join\");\n    }\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread].join();\n    }\n    for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n      searchThreads[thread].join();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: done join [\" + (System.currentTimeMillis()-t0) + \" ms]; addCount=\" + addCount + \" delCount=\" + delCount);\n      System.out.println(\"TEST: search totHits=\" + totHits);\n    }\n\n    long maxGen = 0;\n    for(long gen : lastGens) {\n      maxGen = Math.max(maxGen, gen);\n    }\n\n    final IndexSearcher s = nrt.get(maxGen, true);\n\n    boolean doFail = false;\n    for(String id : delIDs) {\n      final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", id)), 1);\n      if (hits.totalHits != 0) {\n        System.out.println(\"doc id=\" + id + \" is supposed to be deleted, but got docID=\" + hits.scoreDocs[0].doc);\n        doFail = true;\n      }\n    }\n\n    // Make sure each group of sub-docs are still in docID order:\n    for(SubDocs subDocs : allSubDocs) {\n      if (!subDocs.deleted) {\n        // We sort by relevance but the scores should be identical so sort falls back to by docID:\n        TopDocs hits = s.search(new TermQuery(new Term(\"packID\", subDocs.packID)), 20);\n        assertEquals(subDocs.subIDs.size(), hits.totalHits);\n        int lastDocID = -1;\n        int startDocID = -1;\n        for(ScoreDoc scoreDoc : hits.scoreDocs) {\n          final int docID = scoreDoc.doc;\n          if (lastDocID != -1) {\n            assertEquals(1+lastDocID, docID);\n          } else {\n            startDocID = docID;\n          }\n          lastDocID = docID;\n          final Document doc = s.doc(docID);\n          assertEquals(subDocs.packID, doc.get(\"packID\"));\n        }\n\n        lastDocID = startDocID - 1;\n        for(String subID : subDocs.subIDs) {\n          hits = s.search(new TermQuery(new Term(\"docid\", subID)), 1);\n          assertEquals(1, hits.totalHits);\n          final int docID = hits.scoreDocs[0].doc;\n          if (lastDocID != -1) {\n            assertEquals(1+lastDocID, docID);\n          }\n          lastDocID = docID;\n        }          \n      } else {\n        for(String subID : subDocs.subIDs) {\n          assertEquals(0, s.search(new TermQuery(new Term(\"docid\", subID)), 1).totalHits);\n        }\n      }\n    }\n    \n    final int endID = Integer.parseInt(docs.nextDoc().get(\"docid\"));\n    for(int id=0;id<endID;id++) {\n      String stringID = \"\"+id;\n      if (!delIDs.contains(stringID)) {\n        final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", stringID)), 1);\n        if (hits.totalHits != 1) {\n          System.out.println(\"doc id=\" + stringID + \" is not supposed to be deleted, but got hitCount=\" + hits.totalHits);\n          doFail = true;\n        }\n      }\n    }\n    assertFalse(doFail);\n\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), s.getIndexReader().numDocs());\n    nrt.release(s);\n\n    if (es != null) {\n      es.shutdown();\n      es.awaitTermination(1, TimeUnit.SECONDS);\n    }\n\n    writer.commit();\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), writer.numDocs());\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now close NRTManager\");\n    }\n    nrtThread.close();\n    nrt.close();\n    assertFalse(writer.anyNonBulkMerges);\n    writer.close(false);\n    _TestUtil.checkIndex(dir);\n    dir.close();\n    _TestUtil.rmDir(tempDir);\n    docs.close();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5d004d0e0b3f65bb40da76d476d659d7888270e8","date":1310158940,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/contrib/misc/src/test/org/apache/lucene/index/TestNRTManager#testNRTManager().mjava","pathOld":"lucene/contrib/misc/src/test/org/apache/lucene/index/TestNRTManager#testNRTManager().mjava","sourceNew":"  @Test\n  public void testNRTManager() throws Exception {\n\n    final long t0 = System.currentTimeMillis();\n\n    if (CodecProvider.getDefault().getDefaultFieldCodec().equals(\"SimpleText\")) {\n      // no\n      CodecProvider.getDefault().setDefaultFieldCodec(\"Standard\");\n    }\n\n    final LineFileDocs docs = new LineFileDocs(random);\n    final File tempDir = _TestUtil.getTempDir(\"nrtopenfiles\");\n    final MockDirectoryWrapper _dir = newFSDirectory(tempDir);\n    _dir.setCheckIndexOnClose(false);  // don't double-checkIndex, we do it ourselves\n    Directory dir = _dir;\n    final IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).setOpenMode(IndexWriterConfig.OpenMode.CREATE);\n\n    if (LuceneTestCase.TEST_NIGHTLY) {\n      // newIWConfig makes smallish max seg size, which\n      // results in tons and tons of segments for this test\n      // when run nightly:\n      MergePolicy mp = conf.getMergePolicy();\n      if (mp instanceof TieredMergePolicy) {\n        ((TieredMergePolicy) mp).setMaxMergedSegmentMB(5000.);\n      } else if (mp instanceof LogByteSizeMergePolicy) {\n        ((LogByteSizeMergePolicy) mp).setMaxMergeMB(1000.);\n      } else if (mp instanceof LogMergePolicy) {\n        ((LogMergePolicy) mp).setMaxMergeDocs(100000);\n      }\n    }\n\n    conf.setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n      @Override\n      public void warm(IndexReader reader) throws IOException {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now warm merged reader=\" + reader);\n        }\n        final int maxDoc = reader.maxDoc();\n        final Bits liveDocs = reader.getLiveDocs();\n        int sum = 0;\n        final int inc = Math.max(1, maxDoc/50);\n        for(int docID=0;docID<maxDoc;docID += inc) {\n          if (liveDocs == null || liveDocs.get(docID)) {\n            final Document doc = reader.document(docID);\n            sum += doc.getFields().size();\n          }\n        }\n\n        IndexSearcher searcher = newSearcher(reader);\n        sum += searcher.search(new TermQuery(new Term(\"body\", \"united\")), 10).totalHits;\n        searcher.close();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: warm visited \" + sum + \" fields\");\n        }\n      }\n      });\n\n    if (random.nextBoolean()) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: wrap NRTCachingDir\");\n      }\n\n      dir = new NRTCachingDirectory(dir, 5.0, 60.0);\n    }\n    \n    final IndexWriter writer = new IndexWriter(dir, conf);\n    \n    if (VERBOSE) {\n      writer.setInfoStream(System.out);\n    }\n    _TestUtil.reduceOpenFiles(writer);\n    //System.out.println(\"TEST: conf=\" + writer.getConfig());\n\n    final ExecutorService es = random.nextBoolean() ? null : Executors.newCachedThreadPool(new NamedThreadFactory(\"NRT search threads\"));\n\n    final double minReopenSec = 0.01 + 0.05 * random.nextDouble();\n    final double maxReopenSec = minReopenSec * (1.0 + 10 * random.nextDouble());\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: make NRTManager maxReopenSec=\" + maxReopenSec + \" minReopenSec=\" + minReopenSec);\n    }\n\n    final NRTManager nrt = new NRTManager(writer, es);\n    final NRTManagerReopenThread nrtThread = new NRTManagerReopenThread(nrt, maxReopenSec, minReopenSec);\n    nrtThread.setName(\"NRT Reopen Thread\");\n    nrtThread.setPriority(Math.min(Thread.currentThread().getPriority()+2, Thread.MAX_PRIORITY));\n    nrtThread.setDaemon(true);\n    nrtThread.start();\n\n    final int NUM_INDEX_THREADS = _TestUtil.nextInt(random, 1, 3);\n    final int NUM_SEARCH_THREADS = _TestUtil.nextInt(random, 1, 3);\n    //final int NUM_INDEX_THREADS = 1;\n    //final int NUM_SEARCH_THREADS = 1;\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + NUM_INDEX_THREADS + \" index threads; \" + NUM_SEARCH_THREADS + \" search threads\");\n    }\n\n    final int RUN_TIME_SEC = LuceneTestCase.TEST_NIGHTLY ? 300 : RANDOM_MULTIPLIER;\n\n    final AtomicBoolean failed = new AtomicBoolean();\n    final AtomicInteger addCount = new AtomicInteger();\n    final AtomicInteger delCount = new AtomicInteger();\n    final AtomicInteger packCount = new AtomicInteger();\n    final List<Long> lastGens = new ArrayList<Long>();\n\n    final Set<String> delIDs = Collections.synchronizedSet(new HashSet<String>());\n    final List<SubDocs> allSubDocs = Collections.synchronizedList(new ArrayList<SubDocs>());\n\n    final long stopTime = System.currentTimeMillis() + RUN_TIME_SEC*1000;\n    Thread[] threads = new Thread[NUM_INDEX_THREADS];\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread] = new Thread() {\n          @Override\n          public void run() {\n            // TODO: would be better if this were cross thread, so that we make sure one thread deleting anothers added docs works:\n            final List<String> toDeleteIDs = new ArrayList<String>();\n            final List<SubDocs> toDeleteSubDocs = new ArrayList<SubDocs>();\n\n            long gen = 0;\n            while(System.currentTimeMillis() < stopTime && !failed.get()) {\n\n              //System.out.println(Thread.currentThread().getName() + \": cycle\");\n              try {\n                // Occassional longish pause if running\n                // nightly\n                if (LuceneTestCase.TEST_NIGHTLY && random.nextInt(6) == 3) {\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": now long sleep\");\n                  }\n                  Thread.sleep(_TestUtil.nextInt(random, 50, 500));\n                }\n\n                // Rate limit ingest rate:\n                Thread.sleep(_TestUtil.nextInt(random, 1, 10));\n                if (VERBOSE) {\n                  System.out.println(Thread.currentThread() + \": done sleep\");\n                }\n\n                Document doc = docs.nextDoc();\n                if (doc == null) {\n                  break;\n                }\n                final String addedField;\n                if (random.nextBoolean()) {\n                  addedField = \"extra\" + random.nextInt(10);\n                  doc.add(new Field(addedField, \"a random field\", Field.Store.NO, Field.Index.ANALYZED));\n                } else {\n                  addedField = null;\n                }\n                if (random.nextBoolean()) {\n\n                  if (random.nextBoolean()) {\n                    // Add a pack of adjacent sub-docs\n                    final String packID;\n                    final SubDocs delSubDocs;\n                    if (toDeleteSubDocs.size() > 0 && random.nextBoolean()) {\n                      delSubDocs = toDeleteSubDocs.get(random.nextInt(toDeleteSubDocs.size()));\n                      assert !delSubDocs.deleted;\n                      toDeleteSubDocs.remove(delSubDocs);\n                      // reuse prior packID\n                      packID = delSubDocs.packID;\n                    } else {\n                      delSubDocs = null;\n                      // make new packID\n                      packID = packCount.getAndIncrement() + \"\";\n                    }\n\n                    final Field packIDField = newField(\"packID\", packID, Field.Store.YES, Field.Index.NOT_ANALYZED);\n                    final List<String> docIDs = new ArrayList<String>();\n                    final SubDocs subDocs = new SubDocs(packID, docIDs);\n                    final List<Document> docsList = new ArrayList<Document>();\n\n                    allSubDocs.add(subDocs);\n                    doc.add(packIDField);\n                    docsList.add(cloneDoc(doc));\n                    docIDs.add(doc.get(\"docid\"));\n\n                    final int maxDocCount = _TestUtil.nextInt(random, 1, 10);\n                    while(docsList.size() < maxDocCount) {\n                      doc = docs.nextDoc();\n                      if (doc == null) {\n                        break;\n                      }\n                      docsList.add(cloneDoc(doc));\n                      docIDs.add(doc.get(\"docid\"));\n                    }\n                    addCount.addAndGet(docsList.size());\n\n                    if (delSubDocs != null) {\n                      delSubDocs.deleted = true;\n                      delIDs.addAll(delSubDocs.subIDs);\n                      delCount.addAndGet(delSubDocs.subIDs.size());\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: update pack packID=\" + delSubDocs.packID + \" count=\" + docsList.size() + \" docs=\" + docIDs);\n                      }\n                      gen = nrt.updateDocuments(new Term(\"packID\", delSubDocs.packID), docsList);\n                      /*\n                      // non-atomic:\n                      nrt.deleteDocuments(new Term(\"packID\", delSubDocs.packID));\n                      for(Document subDoc : docsList) {\n                        nrt.addDocument(subDoc);\n                      }\n                      */\n                    } else {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: add pack packID=\" + packID + \" count=\" + docsList.size() + \" docs=\" + docIDs);\n                      }\n                      gen = nrt.addDocuments(docsList);\n                      \n                      /*\n                      // non-atomic:\n                      for(Document subDoc : docsList) {\n                        nrt.addDocument(subDoc);\n                      }\n                      */\n                    }\n                    doc.removeField(\"packID\");\n\n                    if (random.nextInt(5) == 2) {\n                      if (VERBOSE) {\n                        System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + packID);\n                      }\n                      toDeleteSubDocs.add(subDocs);\n                    }\n\n                    // randomly verify the add/update \"took\":\n                    if (random.nextInt(20) == 2) {\n                      final boolean applyDeletes = delSubDocs != null;\n                      final IndexSearcher s = nrt.get(gen, applyDeletes);\n                      try {\n                        assertEquals(docsList.size(), s.search(new TermQuery(new Term(\"packID\", packID)), 10).totalHits);\n                      } finally {\n                        nrt.release(s);\n                      }\n                    }\n\n                  } else {\n                    if (VERBOSE) {\n                      System.out.println(Thread.currentThread().getName() + \": add doc docid:\" + doc.get(\"docid\"));\n                    }\n\n                    gen = nrt.addDocument(doc);\n                    addCount.getAndIncrement();\n\n                    // randomly verify the add \"took\":\n                    if (random.nextInt(20) == 2) {\n                      //System.out.println(Thread.currentThread().getName() + \": verify\");\n                      final IndexSearcher s = nrt.get(gen, false);\n                      //System.out.println(Thread.currentThread().getName() + \": got s=\" + s);\n                      try {\n                        assertEquals(1, s.search(new TermQuery(new Term(\"docid\", doc.get(\"docid\"))), 10).totalHits);\n                      } finally {\n                        nrt.release(s);\n                      }\n                      //System.out.println(Thread.currentThread().getName() + \": done verify\");\n                    }\n\n                    if (random.nextInt(5) == 3) {\n                      if (VERBOSE) {\n                        System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                      }\n                      toDeleteIDs.add(doc.get(\"docid\"));\n                    }\n                  }\n                } else {\n                  // we use update but it never replaces a\n                  // prior doc\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": update doc id:\" + doc.get(\"docid\"));\n                  }\n                  gen = nrt.updateDocument(new Term(\"docid\", doc.get(\"docid\")), doc);\n                  addCount.getAndIncrement();\n\n                  // randomly verify the add \"took\":\n                  if (random.nextInt(20) == 2) {\n                    final IndexSearcher s = nrt.get(gen, true);\n                    try {\n                      assertEquals(1, s.search(new TermQuery(new Term(\"docid\", doc.get(\"docid\"))), 10).totalHits);\n                    } finally {\n                      nrt.release(s);\n                    }\n                  }\n\n                  if (random.nextInt(5) == 3) {\n                    if (VERBOSE) {\n                      System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                    }\n                    toDeleteIDs.add(doc.get(\"docid\"));\n                  }\n                }\n\n                if (random.nextInt(30) == 17) {\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": apply \" + toDeleteIDs.size() + \" deletes\");\n                  }\n                  for(String id : toDeleteIDs) {\n                    if (VERBOSE) {\n                      System.out.println(Thread.currentThread().getName() + \": del term=id:\" + id);\n                    }\n                    gen = nrt.deleteDocuments(new Term(\"docid\", id));\n\n                    // randomly verify the delete \"took\":\n                    if (random.nextInt(20) == 7) {\n                      final IndexSearcher s = nrt.get(gen, true);\n                      try {\n                        assertEquals(0, s.search(new TermQuery(new Term(\"docid\", id)), 10).totalHits);\n                      } finally {\n                        nrt.release(s);\n                      }\n                    }\n                  }\n\n                  final int count = delCount.addAndGet(toDeleteIDs.size());\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": tot \" + count + \" deletes\");\n                  }\n                  delIDs.addAll(toDeleteIDs);\n                  toDeleteIDs.clear();\n\n                  for(SubDocs subDocs : toDeleteSubDocs) {\n                    assertTrue(!subDocs.deleted);\n                    gen = nrt.deleteDocuments(new Term(\"packID\", subDocs.packID));\n                    subDocs.deleted = true;\n                    if (VERBOSE) {\n                      System.out.println(\"  del subs: \" + subDocs.subIDs + \" packID=\" + subDocs.packID);\n                    }\n                    delIDs.addAll(subDocs.subIDs);\n                    delCount.addAndGet(subDocs.subIDs.size());\n\n                    // randomly verify the delete \"took\":\n                    if (random.nextInt(20) == 7) {\n                      final IndexSearcher s = nrt.get(gen, true);\n                      try {\n                        assertEquals(0, s.search(new TermQuery(new Term(\"packID\", subDocs.packID)), 1).totalHits);\n                      } finally {\n                        nrt.release(s);\n                      }\n                    }\n                  }\n                  toDeleteSubDocs.clear();\n                }\n                if (addedField != null) {\n                  doc.removeField(addedField);\n                }\n              } catch (Throwable t) {\n                System.out.println(Thread.currentThread().getName() + \": FAILED: hit exc\");\n                t.printStackTrace();\n                failed.set(true);\n                throw new RuntimeException(t);\n              }\n            }\n\n            lastGens.add(gen);\n            if (VERBOSE) {\n              System.out.println(Thread.currentThread().getName() + \": indexing done\");\n            }\n          }\n        };\n      threads[thread].setDaemon(true);\n      threads[thread].start();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: DONE start indexing threads [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    // let index build up a bit\n    Thread.sleep(100);\n\n    // silly starting guess:\n    final AtomicInteger totTermCount = new AtomicInteger(100);\n\n    // run search threads\n    final Thread[] searchThreads = new Thread[NUM_SEARCH_THREADS];\n    final AtomicInteger totHits = new AtomicInteger();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: start search threads\");\n    }\n\n    for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n      searchThreads[thread] = new Thread() {\n          @Override\n          public void run() {\n            while(System.currentTimeMillis() < stopTime && !failed.get()) {\n              final IndexSearcher s = nrt.get(random.nextBoolean());\n              try {\n                try {\n                  smokeTestSearcher(s);\n                  if (s.getIndexReader().numDocs() > 0) {\n                    Fields fields = MultiFields.getFields(s.getIndexReader());\n                    if (fields == null) {\n                      continue;\n                    }\n                    Terms terms = fields.terms(\"body\");\n                    if (terms == null) {\n                      continue;\n                    }\n\n                    TermsEnum termsEnum = terms.iterator();\n                    int seenTermCount = 0;\n                    int shift;\n                    int trigger;\n                    if (totTermCount.get() < 10) {\n                      shift = 0;\n                      trigger = 1;\n                    } else {\n                      trigger = totTermCount.get()/10;\n                      shift = random.nextInt(trigger);\n                    }\n\n                    while(System.currentTimeMillis() < stopTime) {\n                      BytesRef term = termsEnum.next();\n                      if (term == null) {\n                        if (seenTermCount == 0) {\n                          break;\n                        }\n                        totTermCount.set(seenTermCount);\n                        seenTermCount = 0;\n                        if (totTermCount.get() < 10) {\n                          shift = 0;\n                          trigger = 1;\n                        } else {\n                          trigger = totTermCount.get()/10;\n                          //System.out.println(\"trigger \" + trigger);\n                          shift = random.nextInt(trigger);\n                        }\n                        termsEnum.seekCeil(new BytesRef(\"\"));\n                        continue;\n                      }\n                      seenTermCount++;\n                      // search 10 terms\n                      if (trigger == 0) {\n                        trigger = 1;\n                      }\n                      if ((seenTermCount + shift) % trigger == 0) {\n                        //if (VERBOSE) {\n                        //System.out.println(Thread.currentThread().getName() + \" now search body:\" + term.utf8ToString());\n                        //}\n                        totHits.addAndGet(runQuery(s, new TermQuery(new Term(\"body\", term))));\n                      }\n                    }\n                    if (VERBOSE) {\n                      System.out.println(Thread.currentThread().getName() + \": search done\");\n                    }\n                  }\n                } finally {\n                  nrt.release(s);\n                }\n              } catch (Throwable t) {\n                System.out.println(Thread.currentThread().getName() + \": FAILED: hit exc\");\n                failed.set(true);\n                t.printStackTrace(System.out);\n                throw new RuntimeException(t);\n              }\n            }\n          }\n        };\n      searchThreads[thread].setDaemon(true);\n      searchThreads[thread].start();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now join\");\n    }\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread].join();\n    }\n    for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n      searchThreads[thread].join();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: done join [\" + (System.currentTimeMillis()-t0) + \" ms]; addCount=\" + addCount + \" delCount=\" + delCount);\n      System.out.println(\"TEST: search totHits=\" + totHits);\n    }\n\n    long maxGen = 0;\n    for(long gen : lastGens) {\n      maxGen = Math.max(maxGen, gen);\n    }\n\n    final IndexSearcher s = nrt.get(maxGen, true);\n\n    boolean doFail = false;\n    for(String id : delIDs) {\n      final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", id)), 1);\n      if (hits.totalHits != 0) {\n        System.out.println(\"doc id=\" + id + \" is supposed to be deleted, but got docID=\" + hits.scoreDocs[0].doc);\n        doFail = true;\n      }\n    }\n\n    // Make sure each group of sub-docs are still in docID order:\n    for(SubDocs subDocs : allSubDocs) {\n      if (!subDocs.deleted) {\n        // We sort by relevance but the scores should be identical so sort falls back to by docID:\n        TopDocs hits = s.search(new TermQuery(new Term(\"packID\", subDocs.packID)), 20);\n        assertEquals(subDocs.subIDs.size(), hits.totalHits);\n        int lastDocID = -1;\n        int startDocID = -1;\n        for(ScoreDoc scoreDoc : hits.scoreDocs) {\n          final int docID = scoreDoc.doc;\n          if (lastDocID != -1) {\n            assertEquals(1+lastDocID, docID);\n          } else {\n            startDocID = docID;\n          }\n          lastDocID = docID;\n          final Document doc = s.doc(docID);\n          assertEquals(subDocs.packID, doc.get(\"packID\"));\n        }\n\n        lastDocID = startDocID - 1;\n        for(String subID : subDocs.subIDs) {\n          hits = s.search(new TermQuery(new Term(\"docid\", subID)), 1);\n          assertEquals(1, hits.totalHits);\n          final int docID = hits.scoreDocs[0].doc;\n          if (lastDocID != -1) {\n            assertEquals(1+lastDocID, docID);\n          }\n          lastDocID = docID;\n        }          \n      } else {\n        for(String subID : subDocs.subIDs) {\n          assertEquals(0, s.search(new TermQuery(new Term(\"docid\", subID)), 1).totalHits);\n        }\n      }\n    }\n    \n    final int endID = Integer.parseInt(docs.nextDoc().get(\"docid\"));\n    for(int id=0;id<endID;id++) {\n      String stringID = \"\"+id;\n      if (!delIDs.contains(stringID)) {\n        final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", stringID)), 1);\n        if (hits.totalHits != 1) {\n          System.out.println(\"doc id=\" + stringID + \" is not supposed to be deleted, but got hitCount=\" + hits.totalHits);\n          doFail = true;\n        }\n      }\n    }\n    assertFalse(doFail);\n\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), s.getIndexReader().numDocs());\n    nrt.release(s);\n\n    if (es != null) {\n      es.shutdown();\n      es.awaitTermination(1, TimeUnit.SECONDS);\n    }\n\n    writer.commit();\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), writer.numDocs());\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now close NRTManager\");\n    }\n    nrtThread.close();\n    nrt.close();\n    assertFalse(writer.anyNonBulkMerges);\n    writer.close(false);\n    _TestUtil.checkIndex(dir);\n    dir.close();\n    _TestUtil.rmDir(tempDir);\n    docs.close();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testNRTManager() throws Exception {\n\n    final long t0 = System.currentTimeMillis();\n\n    if (CodecProvider.getDefault().getDefaultFieldCodec().equals(\"SimpleText\")) {\n      // no\n      CodecProvider.getDefault().setDefaultFieldCodec(\"Standard\");\n    }\n\n    final LineFileDocs docs = new LineFileDocs(random);\n    final File tempDir = _TestUtil.getTempDir(\"nrtopenfiles\");\n    final MockDirectoryWrapper _dir = newFSDirectory(tempDir);\n    _dir.setCheckIndexOnClose(false);  // don't double-checkIndex, we do it ourselves\n    Directory dir = _dir;\n    final IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).setOpenMode(IndexWriterConfig.OpenMode.CREATE);\n\n    if (LuceneTestCase.TEST_NIGHTLY) {\n      // newIWConfig makes smallish max seg size, which\n      // results in tons and tons of segments for this test\n      // when run nightly:\n      MergePolicy mp = conf.getMergePolicy();\n      if (mp instanceof TieredMergePolicy) {\n        ((TieredMergePolicy) mp).setMaxMergedSegmentMB(5000.);\n      } else if (mp instanceof LogByteSizeMergePolicy) {\n        ((LogByteSizeMergePolicy) mp).setMaxMergeMB(1000.);\n      } else if (mp instanceof LogMergePolicy) {\n        ((LogMergePolicy) mp).setMaxMergeDocs(100000);\n      }\n    }\n\n    conf.setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n      @Override\n      public void warm(IndexReader reader) throws IOException {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now warm merged reader=\" + reader);\n        }\n        final int maxDoc = reader.maxDoc();\n        final Bits liveDocs = reader.getLiveDocs();\n        int sum = 0;\n        final int inc = Math.max(1, maxDoc/50);\n        for(int docID=0;docID<maxDoc;docID += inc) {\n          if (liveDocs == null || liveDocs.get(docID)) {\n            final Document doc = reader.document(docID);\n            sum += doc.getFields().size();\n          }\n        }\n\n        IndexSearcher searcher = newSearcher(reader);\n        sum += searcher.search(new TermQuery(new Term(\"body\", \"united\")), 10).totalHits;\n        searcher.close();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: warm visited \" + sum + \" fields\");\n        }\n      }\n      });\n\n    if (random.nextBoolean()) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: wrap NRTCachingDir\");\n      }\n\n      NRTCachingDirectory nrtDir = new NRTCachingDirectory(dir, 5.0, 60.0);\n      conf.setMergeScheduler(nrtDir.getMergeScheduler());\n      dir = nrtDir;\n    }\n    \n    final IndexWriter writer = new IndexWriter(dir, conf);\n    \n    if (VERBOSE) {\n      writer.setInfoStream(System.out);\n    }\n    _TestUtil.reduceOpenFiles(writer);\n    //System.out.println(\"TEST: conf=\" + writer.getConfig());\n\n    final ExecutorService es = random.nextBoolean() ? null : Executors.newCachedThreadPool(new NamedThreadFactory(\"NRT search threads\"));\n\n    final double minReopenSec = 0.01 + 0.05 * random.nextDouble();\n    final double maxReopenSec = minReopenSec * (1.0 + 10 * random.nextDouble());\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: make NRTManager maxReopenSec=\" + maxReopenSec + \" minReopenSec=\" + minReopenSec);\n    }\n\n    final NRTManager nrt = new NRTManager(writer, es);\n    final NRTManagerReopenThread nrtThread = new NRTManagerReopenThread(nrt, maxReopenSec, minReopenSec);\n    nrtThread.setName(\"NRT Reopen Thread\");\n    nrtThread.setPriority(Math.min(Thread.currentThread().getPriority()+2, Thread.MAX_PRIORITY));\n    nrtThread.setDaemon(true);\n    nrtThread.start();\n\n    final int NUM_INDEX_THREADS = _TestUtil.nextInt(random, 1, 3);\n    final int NUM_SEARCH_THREADS = _TestUtil.nextInt(random, 1, 3);\n    //final int NUM_INDEX_THREADS = 1;\n    //final int NUM_SEARCH_THREADS = 1;\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + NUM_INDEX_THREADS + \" index threads; \" + NUM_SEARCH_THREADS + \" search threads\");\n    }\n\n    final int RUN_TIME_SEC = LuceneTestCase.TEST_NIGHTLY ? 300 : RANDOM_MULTIPLIER;\n\n    final AtomicBoolean failed = new AtomicBoolean();\n    final AtomicInteger addCount = new AtomicInteger();\n    final AtomicInteger delCount = new AtomicInteger();\n    final AtomicInteger packCount = new AtomicInteger();\n    final List<Long> lastGens = new ArrayList<Long>();\n\n    final Set<String> delIDs = Collections.synchronizedSet(new HashSet<String>());\n    final List<SubDocs> allSubDocs = Collections.synchronizedList(new ArrayList<SubDocs>());\n\n    final long stopTime = System.currentTimeMillis() + RUN_TIME_SEC*1000;\n    Thread[] threads = new Thread[NUM_INDEX_THREADS];\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread] = new Thread() {\n          @Override\n          public void run() {\n            // TODO: would be better if this were cross thread, so that we make sure one thread deleting anothers added docs works:\n            final List<String> toDeleteIDs = new ArrayList<String>();\n            final List<SubDocs> toDeleteSubDocs = new ArrayList<SubDocs>();\n\n            long gen = 0;\n            while(System.currentTimeMillis() < stopTime && !failed.get()) {\n\n              //System.out.println(Thread.currentThread().getName() + \": cycle\");\n              try {\n                // Occassional longish pause if running\n                // nightly\n                if (LuceneTestCase.TEST_NIGHTLY && random.nextInt(6) == 3) {\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": now long sleep\");\n                  }\n                  Thread.sleep(_TestUtil.nextInt(random, 50, 500));\n                }\n\n                // Rate limit ingest rate:\n                Thread.sleep(_TestUtil.nextInt(random, 1, 10));\n                if (VERBOSE) {\n                  System.out.println(Thread.currentThread() + \": done sleep\");\n                }\n\n                Document doc = docs.nextDoc();\n                if (doc == null) {\n                  break;\n                }\n                final String addedField;\n                if (random.nextBoolean()) {\n                  addedField = \"extra\" + random.nextInt(10);\n                  doc.add(new Field(addedField, \"a random field\", Field.Store.NO, Field.Index.ANALYZED));\n                } else {\n                  addedField = null;\n                }\n                if (random.nextBoolean()) {\n\n                  if (random.nextBoolean()) {\n                    // Add a pack of adjacent sub-docs\n                    final String packID;\n                    final SubDocs delSubDocs;\n                    if (toDeleteSubDocs.size() > 0 && random.nextBoolean()) {\n                      delSubDocs = toDeleteSubDocs.get(random.nextInt(toDeleteSubDocs.size()));\n                      assert !delSubDocs.deleted;\n                      toDeleteSubDocs.remove(delSubDocs);\n                      // reuse prior packID\n                      packID = delSubDocs.packID;\n                    } else {\n                      delSubDocs = null;\n                      // make new packID\n                      packID = packCount.getAndIncrement() + \"\";\n                    }\n\n                    final Field packIDField = newField(\"packID\", packID, Field.Store.YES, Field.Index.NOT_ANALYZED);\n                    final List<String> docIDs = new ArrayList<String>();\n                    final SubDocs subDocs = new SubDocs(packID, docIDs);\n                    final List<Document> docsList = new ArrayList<Document>();\n\n                    allSubDocs.add(subDocs);\n                    doc.add(packIDField);\n                    docsList.add(cloneDoc(doc));\n                    docIDs.add(doc.get(\"docid\"));\n\n                    final int maxDocCount = _TestUtil.nextInt(random, 1, 10);\n                    while(docsList.size() < maxDocCount) {\n                      doc = docs.nextDoc();\n                      if (doc == null) {\n                        break;\n                      }\n                      docsList.add(cloneDoc(doc));\n                      docIDs.add(doc.get(\"docid\"));\n                    }\n                    addCount.addAndGet(docsList.size());\n\n                    if (delSubDocs != null) {\n                      delSubDocs.deleted = true;\n                      delIDs.addAll(delSubDocs.subIDs);\n                      delCount.addAndGet(delSubDocs.subIDs.size());\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: update pack packID=\" + delSubDocs.packID + \" count=\" + docsList.size() + \" docs=\" + docIDs);\n                      }\n                      gen = nrt.updateDocuments(new Term(\"packID\", delSubDocs.packID), docsList);\n                      /*\n                      // non-atomic:\n                      nrt.deleteDocuments(new Term(\"packID\", delSubDocs.packID));\n                      for(Document subDoc : docsList) {\n                        nrt.addDocument(subDoc);\n                      }\n                      */\n                    } else {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: add pack packID=\" + packID + \" count=\" + docsList.size() + \" docs=\" + docIDs);\n                      }\n                      gen = nrt.addDocuments(docsList);\n                      \n                      /*\n                      // non-atomic:\n                      for(Document subDoc : docsList) {\n                        nrt.addDocument(subDoc);\n                      }\n                      */\n                    }\n                    doc.removeField(\"packID\");\n\n                    if (random.nextInt(5) == 2) {\n                      if (VERBOSE) {\n                        System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + packID);\n                      }\n                      toDeleteSubDocs.add(subDocs);\n                    }\n\n                    // randomly verify the add/update \"took\":\n                    if (random.nextInt(20) == 2) {\n                      final boolean applyDeletes = delSubDocs != null;\n                      final IndexSearcher s = nrt.get(gen, applyDeletes);\n                      try {\n                        assertEquals(docsList.size(), s.search(new TermQuery(new Term(\"packID\", packID)), 10).totalHits);\n                      } finally {\n                        nrt.release(s);\n                      }\n                    }\n\n                  } else {\n                    if (VERBOSE) {\n                      System.out.println(Thread.currentThread().getName() + \": add doc docid:\" + doc.get(\"docid\"));\n                    }\n\n                    gen = nrt.addDocument(doc);\n                    addCount.getAndIncrement();\n\n                    // randomly verify the add \"took\":\n                    if (random.nextInt(20) == 2) {\n                      //System.out.println(Thread.currentThread().getName() + \": verify\");\n                      final IndexSearcher s = nrt.get(gen, false);\n                      //System.out.println(Thread.currentThread().getName() + \": got s=\" + s);\n                      try {\n                        assertEquals(1, s.search(new TermQuery(new Term(\"docid\", doc.get(\"docid\"))), 10).totalHits);\n                      } finally {\n                        nrt.release(s);\n                      }\n                      //System.out.println(Thread.currentThread().getName() + \": done verify\");\n                    }\n\n                    if (random.nextInt(5) == 3) {\n                      if (VERBOSE) {\n                        System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                      }\n                      toDeleteIDs.add(doc.get(\"docid\"));\n                    }\n                  }\n                } else {\n                  // we use update but it never replaces a\n                  // prior doc\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": update doc id:\" + doc.get(\"docid\"));\n                  }\n                  gen = nrt.updateDocument(new Term(\"docid\", doc.get(\"docid\")), doc);\n                  addCount.getAndIncrement();\n\n                  // randomly verify the add \"took\":\n                  if (random.nextInt(20) == 2) {\n                    final IndexSearcher s = nrt.get(gen, true);\n                    try {\n                      assertEquals(1, s.search(new TermQuery(new Term(\"docid\", doc.get(\"docid\"))), 10).totalHits);\n                    } finally {\n                      nrt.release(s);\n                    }\n                  }\n\n                  if (random.nextInt(5) == 3) {\n                    if (VERBOSE) {\n                      System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                    }\n                    toDeleteIDs.add(doc.get(\"docid\"));\n                  }\n                }\n\n                if (random.nextInt(30) == 17) {\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": apply \" + toDeleteIDs.size() + \" deletes\");\n                  }\n                  for(String id : toDeleteIDs) {\n                    if (VERBOSE) {\n                      System.out.println(Thread.currentThread().getName() + \": del term=id:\" + id);\n                    }\n                    gen = nrt.deleteDocuments(new Term(\"docid\", id));\n\n                    // randomly verify the delete \"took\":\n                    if (random.nextInt(20) == 7) {\n                      final IndexSearcher s = nrt.get(gen, true);\n                      try {\n                        assertEquals(0, s.search(new TermQuery(new Term(\"docid\", id)), 10).totalHits);\n                      } finally {\n                        nrt.release(s);\n                      }\n                    }\n                  }\n\n                  final int count = delCount.addAndGet(toDeleteIDs.size());\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": tot \" + count + \" deletes\");\n                  }\n                  delIDs.addAll(toDeleteIDs);\n                  toDeleteIDs.clear();\n\n                  for(SubDocs subDocs : toDeleteSubDocs) {\n                    assertTrue(!subDocs.deleted);\n                    gen = nrt.deleteDocuments(new Term(\"packID\", subDocs.packID));\n                    subDocs.deleted = true;\n                    if (VERBOSE) {\n                      System.out.println(\"  del subs: \" + subDocs.subIDs + \" packID=\" + subDocs.packID);\n                    }\n                    delIDs.addAll(subDocs.subIDs);\n                    delCount.addAndGet(subDocs.subIDs.size());\n\n                    // randomly verify the delete \"took\":\n                    if (random.nextInt(20) == 7) {\n                      final IndexSearcher s = nrt.get(gen, true);\n                      try {\n                        assertEquals(0, s.search(new TermQuery(new Term(\"packID\", subDocs.packID)), 1).totalHits);\n                      } finally {\n                        nrt.release(s);\n                      }\n                    }\n                  }\n                  toDeleteSubDocs.clear();\n                }\n                if (addedField != null) {\n                  doc.removeField(addedField);\n                }\n              } catch (Throwable t) {\n                System.out.println(Thread.currentThread().getName() + \": FAILED: hit exc\");\n                t.printStackTrace();\n                failed.set(true);\n                throw new RuntimeException(t);\n              }\n            }\n\n            lastGens.add(gen);\n            if (VERBOSE) {\n              System.out.println(Thread.currentThread().getName() + \": indexing done\");\n            }\n          }\n        };\n      threads[thread].setDaemon(true);\n      threads[thread].start();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: DONE start indexing threads [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    // let index build up a bit\n    Thread.sleep(100);\n\n    // silly starting guess:\n    final AtomicInteger totTermCount = new AtomicInteger(100);\n\n    // run search threads\n    final Thread[] searchThreads = new Thread[NUM_SEARCH_THREADS];\n    final AtomicInteger totHits = new AtomicInteger();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: start search threads\");\n    }\n\n    for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n      searchThreads[thread] = new Thread() {\n          @Override\n          public void run() {\n            while(System.currentTimeMillis() < stopTime && !failed.get()) {\n              final IndexSearcher s = nrt.get(random.nextBoolean());\n              try {\n                try {\n                  smokeTestSearcher(s);\n                  if (s.getIndexReader().numDocs() > 0) {\n                    Fields fields = MultiFields.getFields(s.getIndexReader());\n                    if (fields == null) {\n                      continue;\n                    }\n                    Terms terms = fields.terms(\"body\");\n                    if (terms == null) {\n                      continue;\n                    }\n\n                    TermsEnum termsEnum = terms.iterator();\n                    int seenTermCount = 0;\n                    int shift;\n                    int trigger;\n                    if (totTermCount.get() < 10) {\n                      shift = 0;\n                      trigger = 1;\n                    } else {\n                      trigger = totTermCount.get()/10;\n                      shift = random.nextInt(trigger);\n                    }\n\n                    while(System.currentTimeMillis() < stopTime) {\n                      BytesRef term = termsEnum.next();\n                      if (term == null) {\n                        if (seenTermCount == 0) {\n                          break;\n                        }\n                        totTermCount.set(seenTermCount);\n                        seenTermCount = 0;\n                        if (totTermCount.get() < 10) {\n                          shift = 0;\n                          trigger = 1;\n                        } else {\n                          trigger = totTermCount.get()/10;\n                          //System.out.println(\"trigger \" + trigger);\n                          shift = random.nextInt(trigger);\n                        }\n                        termsEnum.seekCeil(new BytesRef(\"\"));\n                        continue;\n                      }\n                      seenTermCount++;\n                      // search 10 terms\n                      if (trigger == 0) {\n                        trigger = 1;\n                      }\n                      if ((seenTermCount + shift) % trigger == 0) {\n                        //if (VERBOSE) {\n                        //System.out.println(Thread.currentThread().getName() + \" now search body:\" + term.utf8ToString());\n                        //}\n                        totHits.addAndGet(runQuery(s, new TermQuery(new Term(\"body\", term))));\n                      }\n                    }\n                    if (VERBOSE) {\n                      System.out.println(Thread.currentThread().getName() + \": search done\");\n                    }\n                  }\n                } finally {\n                  nrt.release(s);\n                }\n              } catch (Throwable t) {\n                System.out.println(Thread.currentThread().getName() + \": FAILED: hit exc\");\n                failed.set(true);\n                t.printStackTrace(System.out);\n                throw new RuntimeException(t);\n              }\n            }\n          }\n        };\n      searchThreads[thread].setDaemon(true);\n      searchThreads[thread].start();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now join\");\n    }\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread].join();\n    }\n    for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n      searchThreads[thread].join();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: done join [\" + (System.currentTimeMillis()-t0) + \" ms]; addCount=\" + addCount + \" delCount=\" + delCount);\n      System.out.println(\"TEST: search totHits=\" + totHits);\n    }\n\n    long maxGen = 0;\n    for(long gen : lastGens) {\n      maxGen = Math.max(maxGen, gen);\n    }\n\n    final IndexSearcher s = nrt.get(maxGen, true);\n\n    boolean doFail = false;\n    for(String id : delIDs) {\n      final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", id)), 1);\n      if (hits.totalHits != 0) {\n        System.out.println(\"doc id=\" + id + \" is supposed to be deleted, but got docID=\" + hits.scoreDocs[0].doc);\n        doFail = true;\n      }\n    }\n\n    // Make sure each group of sub-docs are still in docID order:\n    for(SubDocs subDocs : allSubDocs) {\n      if (!subDocs.deleted) {\n        // We sort by relevance but the scores should be identical so sort falls back to by docID:\n        TopDocs hits = s.search(new TermQuery(new Term(\"packID\", subDocs.packID)), 20);\n        assertEquals(subDocs.subIDs.size(), hits.totalHits);\n        int lastDocID = -1;\n        int startDocID = -1;\n        for(ScoreDoc scoreDoc : hits.scoreDocs) {\n          final int docID = scoreDoc.doc;\n          if (lastDocID != -1) {\n            assertEquals(1+lastDocID, docID);\n          } else {\n            startDocID = docID;\n          }\n          lastDocID = docID;\n          final Document doc = s.doc(docID);\n          assertEquals(subDocs.packID, doc.get(\"packID\"));\n        }\n\n        lastDocID = startDocID - 1;\n        for(String subID : subDocs.subIDs) {\n          hits = s.search(new TermQuery(new Term(\"docid\", subID)), 1);\n          assertEquals(1, hits.totalHits);\n          final int docID = hits.scoreDocs[0].doc;\n          if (lastDocID != -1) {\n            assertEquals(1+lastDocID, docID);\n          }\n          lastDocID = docID;\n        }          \n      } else {\n        for(String subID : subDocs.subIDs) {\n          assertEquals(0, s.search(new TermQuery(new Term(\"docid\", subID)), 1).totalHits);\n        }\n      }\n    }\n    \n    final int endID = Integer.parseInt(docs.nextDoc().get(\"docid\"));\n    for(int id=0;id<endID;id++) {\n      String stringID = \"\"+id;\n      if (!delIDs.contains(stringID)) {\n        final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", stringID)), 1);\n        if (hits.totalHits != 1) {\n          System.out.println(\"doc id=\" + stringID + \" is not supposed to be deleted, but got hitCount=\" + hits.totalHits);\n          doFail = true;\n        }\n      }\n    }\n    assertFalse(doFail);\n\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), s.getIndexReader().numDocs());\n    nrt.release(s);\n\n    if (es != null) {\n      es.shutdown();\n      es.awaitTermination(1, TimeUnit.SECONDS);\n    }\n\n    writer.commit();\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), writer.numDocs());\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now close NRTManager\");\n    }\n    nrtThread.close();\n    nrt.close();\n    assertFalse(writer.anyNonBulkMerges);\n    writer.close(false);\n    _TestUtil.checkIndex(dir);\n    dir.close();\n    _TestUtil.rmDir(tempDir);\n    docs.close();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1509f151d7692d84fae414b2b799ac06ba60fcb4","date":1314451621,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/contrib/misc/src/test/org/apache/lucene/index/TestNRTManager#testNRTManager().mjava","pathOld":"lucene/contrib/misc/src/test/org/apache/lucene/index/TestNRTManager#testNRTManager().mjava","sourceNew":"  @Test\n  public void testNRTManager() throws Exception {\n\n    final long t0 = System.currentTimeMillis();\n\n    if (CodecProvider.getDefault().getDefaultFieldCodec().equals(\"SimpleText\")) {\n      // no\n      CodecProvider.getDefault().setDefaultFieldCodec(\"Standard\");\n    }\n\n    final LineFileDocs docs = new LineFileDocs(random);\n    final File tempDir = _TestUtil.getTempDir(\"nrtopenfiles\");\n    final MockDirectoryWrapper _dir = newFSDirectory(tempDir);\n    _dir.setCheckIndexOnClose(false);  // don't double-checkIndex, we do it ourselves\n    Directory dir = _dir;\n    final IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).setOpenMode(IndexWriterConfig.OpenMode.CREATE);\n\n    if (LuceneTestCase.TEST_NIGHTLY) {\n      // newIWConfig makes smallish max seg size, which\n      // results in tons and tons of segments for this test\n      // when run nightly:\n      MergePolicy mp = conf.getMergePolicy();\n      if (mp instanceof TieredMergePolicy) {\n        ((TieredMergePolicy) mp).setMaxMergedSegmentMB(5000.);\n      } else if (mp instanceof LogByteSizeMergePolicy) {\n        ((LogByteSizeMergePolicy) mp).setMaxMergeMB(1000.);\n      } else if (mp instanceof LogMergePolicy) {\n        ((LogMergePolicy) mp).setMaxMergeDocs(100000);\n      }\n    }\n\n    conf.setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n      @Override\n      public void warm(IndexReader reader) throws IOException {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now warm merged reader=\" + reader);\n        }\n        final int maxDoc = reader.maxDoc();\n        final Bits liveDocs = reader.getLiveDocs();\n        int sum = 0;\n        final int inc = Math.max(1, maxDoc/50);\n        for(int docID=0;docID<maxDoc;docID += inc) {\n          if (liveDocs == null || liveDocs.get(docID)) {\n            final Document doc = reader.document(docID);\n            sum += doc.getFields().size();\n          }\n        }\n\n        IndexSearcher searcher = newSearcher(reader);\n        sum += searcher.search(new TermQuery(new Term(\"body\", \"united\")), 10).totalHits;\n        searcher.close();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: warm visited \" + sum + \" fields\");\n        }\n      }\n      });\n\n    if (random.nextBoolean()) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: wrap NRTCachingDir\");\n      }\n\n      dir = new NRTCachingDirectory(dir, 5.0, 60.0);\n    }\n    \n    final IndexWriter writer = new IndexWriter(dir, conf);\n    \n    if (VERBOSE) {\n      writer.setInfoStream(System.out);\n    }\n    _TestUtil.reduceOpenFiles(writer);\n    //System.out.println(\"TEST: conf=\" + writer.getConfig());\n\n    final ExecutorService es = random.nextBoolean() ? null : Executors.newCachedThreadPool(new NamedThreadFactory(\"NRT search threads\"));\n\n    final double minReopenSec = 0.01 + 0.05 * random.nextDouble();\n    final double maxReopenSec = minReopenSec * (1.0 + 10 * random.nextDouble());\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: make NRTManager maxReopenSec=\" + maxReopenSec + \" minReopenSec=\" + minReopenSec);\n    }\n\n    final NRTManager nrt = new NRTManager(writer, es);\n    final NRTManagerReopenThread nrtThread = new NRTManagerReopenThread(nrt, maxReopenSec, minReopenSec);\n    nrtThread.setName(\"NRT Reopen Thread\");\n    nrtThread.setPriority(Math.min(Thread.currentThread().getPriority()+2, Thread.MAX_PRIORITY));\n    nrtThread.setDaemon(true);\n    nrtThread.start();\n\n    final int NUM_INDEX_THREADS = _TestUtil.nextInt(random, 1, 3);\n    final int NUM_SEARCH_THREADS = _TestUtil.nextInt(random, 1, 3);\n    //final int NUM_INDEX_THREADS = 1;\n    //final int NUM_SEARCH_THREADS = 1;\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + NUM_INDEX_THREADS + \" index threads; \" + NUM_SEARCH_THREADS + \" search threads\");\n    }\n\n    final int RUN_TIME_SEC = LuceneTestCase.TEST_NIGHTLY ? 300 : RANDOM_MULTIPLIER;\n\n    final AtomicBoolean failed = new AtomicBoolean();\n    final AtomicInteger addCount = new AtomicInteger();\n    final AtomicInteger delCount = new AtomicInteger();\n    final AtomicInteger packCount = new AtomicInteger();\n    final List<Long> lastGens = new ArrayList<Long>();\n\n    final Set<String> delIDs = Collections.synchronizedSet(new HashSet<String>());\n    final List<SubDocs> allSubDocs = Collections.synchronizedList(new ArrayList<SubDocs>());\n\n    final long stopTime = System.currentTimeMillis() + RUN_TIME_SEC*1000;\n    Thread[] threads = new Thread[NUM_INDEX_THREADS];\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread] = new Thread() {\n          @Override\n          public void run() {\n            // TODO: would be better if this were cross thread, so that we make sure one thread deleting anothers added docs works:\n            final List<String> toDeleteIDs = new ArrayList<String>();\n            final List<SubDocs> toDeleteSubDocs = new ArrayList<SubDocs>();\n\n            long gen = 0;\n            while(System.currentTimeMillis() < stopTime && !failed.get()) {\n\n              //System.out.println(Thread.currentThread().getName() + \": cycle\");\n              try {\n                // Occassional longish pause if running\n                // nightly\n                if (LuceneTestCase.TEST_NIGHTLY && random.nextInt(6) == 3) {\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": now long sleep\");\n                  }\n                  Thread.sleep(_TestUtil.nextInt(random, 50, 500));\n                }\n\n                // Rate limit ingest rate:\n                Thread.sleep(_TestUtil.nextInt(random, 1, 10));\n                if (VERBOSE) {\n                  System.out.println(Thread.currentThread() + \": done sleep\");\n                }\n\n                Document doc = docs.nextDoc();\n                if (doc == null) {\n                  break;\n                }\n                final String addedField;\n                if (random.nextBoolean()) {\n                  addedField = \"extra\" + random.nextInt(10);\n                  doc.add(new TextField(addedField, \"a random field\"));\n                } else {\n                  addedField = null;\n                }\n                if (random.nextBoolean()) {\n\n                  if (random.nextBoolean()) {\n                    // Add a pack of adjacent sub-docs\n                    final String packID;\n                    final SubDocs delSubDocs;\n                    if (toDeleteSubDocs.size() > 0 && random.nextBoolean()) {\n                      delSubDocs = toDeleteSubDocs.get(random.nextInt(toDeleteSubDocs.size()));\n                      assert !delSubDocs.deleted;\n                      toDeleteSubDocs.remove(delSubDocs);\n                      // reuse prior packID\n                      packID = delSubDocs.packID;\n                    } else {\n                      delSubDocs = null;\n                      // make new packID\n                      packID = packCount.getAndIncrement() + \"\";\n                    }\n\n                    final Field packIDField = newField(\"packID\", packID, StringField.TYPE_STORED);\n                    final List<String> docIDs = new ArrayList<String>();\n                    final SubDocs subDocs = new SubDocs(packID, docIDs);\n                    final List<Document> docsList = new ArrayList<Document>();\n\n                    allSubDocs.add(subDocs);\n                    doc.add(packIDField);\n                    docsList.add(cloneDoc(doc));\n                    docIDs.add(doc.get(\"docid\"));\n\n                    final int maxDocCount = _TestUtil.nextInt(random, 1, 10);\n                    while(docsList.size() < maxDocCount) {\n                      doc = docs.nextDoc();\n                      if (doc == null) {\n                        break;\n                      }\n                      docsList.add(cloneDoc(doc));\n                      docIDs.add(doc.get(\"docid\"));\n                    }\n                    addCount.addAndGet(docsList.size());\n\n                    if (delSubDocs != null) {\n                      delSubDocs.deleted = true;\n                      delIDs.addAll(delSubDocs.subIDs);\n                      delCount.addAndGet(delSubDocs.subIDs.size());\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: update pack packID=\" + delSubDocs.packID + \" count=\" + docsList.size() + \" docs=\" + docIDs);\n                      }\n                      gen = nrt.updateDocuments(new Term(\"packID\", delSubDocs.packID), docsList);\n                      /*\n                      // non-atomic:\n                      nrt.deleteDocuments(new Term(\"packID\", delSubDocs.packID));\n                      for(Document subDoc : docsList) {\n                        nrt.addDocument(subDoc);\n                      }\n                      */\n                    } else {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: add pack packID=\" + packID + \" count=\" + docsList.size() + \" docs=\" + docIDs);\n                      }\n                      gen = nrt.addDocuments(docsList);\n                      \n                      /*\n                      // non-atomic:\n                      for(Document subDoc : docsList) {\n                        nrt.addDocument(subDoc);\n                      }\n                      */\n                    }\n                    doc.removeField(\"packID\");\n\n                    if (random.nextInt(5) == 2) {\n                      if (VERBOSE) {\n                        System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + packID);\n                      }\n                      toDeleteSubDocs.add(subDocs);\n                    }\n\n                    // randomly verify the add/update \"took\":\n                    if (random.nextInt(20) == 2) {\n                      final boolean applyDeletes = delSubDocs != null;\n                      final IndexSearcher s = nrt.get(gen, applyDeletes);\n                      try {\n                        assertEquals(docsList.size(), s.search(new TermQuery(new Term(\"packID\", packID)), 10).totalHits);\n                      } finally {\n                        nrt.release(s);\n                      }\n                    }\n\n                  } else {\n                    if (VERBOSE) {\n                      System.out.println(Thread.currentThread().getName() + \": add doc docid:\" + doc.get(\"docid\"));\n                    }\n\n                    gen = nrt.addDocument(doc);\n                    addCount.getAndIncrement();\n\n                    // randomly verify the add \"took\":\n                    if (random.nextInt(20) == 2) {\n                      //System.out.println(Thread.currentThread().getName() + \": verify\");\n                      final IndexSearcher s = nrt.get(gen, false);\n                      //System.out.println(Thread.currentThread().getName() + \": got s=\" + s);\n                      try {\n                        assertEquals(1, s.search(new TermQuery(new Term(\"docid\", doc.get(\"docid\"))), 10).totalHits);\n                      } finally {\n                        nrt.release(s);\n                      }\n                      //System.out.println(Thread.currentThread().getName() + \": done verify\");\n                    }\n\n                    if (random.nextInt(5) == 3) {\n                      if (VERBOSE) {\n                        System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                      }\n                      toDeleteIDs.add(doc.get(\"docid\"));\n                    }\n                  }\n                } else {\n                  // we use update but it never replaces a\n                  // prior doc\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": update doc id:\" + doc.get(\"docid\"));\n                  }\n                  gen = nrt.updateDocument(new Term(\"docid\", doc.get(\"docid\")), doc);\n                  addCount.getAndIncrement();\n\n                  // randomly verify the add \"took\":\n                  if (random.nextInt(20) == 2) {\n                    final IndexSearcher s = nrt.get(gen, true);\n                    try {\n                      assertEquals(1, s.search(new TermQuery(new Term(\"docid\", doc.get(\"docid\"))), 10).totalHits);\n                    } finally {\n                      nrt.release(s);\n                    }\n                  }\n\n                  if (random.nextInt(5) == 3) {\n                    if (VERBOSE) {\n                      System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                    }\n                    toDeleteIDs.add(doc.get(\"docid\"));\n                  }\n                }\n\n                if (random.nextInt(30) == 17) {\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": apply \" + toDeleteIDs.size() + \" deletes\");\n                  }\n                  for(String id : toDeleteIDs) {\n                    if (VERBOSE) {\n                      System.out.println(Thread.currentThread().getName() + \": del term=id:\" + id);\n                    }\n                    gen = nrt.deleteDocuments(new Term(\"docid\", id));\n\n                    // randomly verify the delete \"took\":\n                    if (random.nextInt(20) == 7) {\n                      final IndexSearcher s = nrt.get(gen, true);\n                      try {\n                        assertEquals(0, s.search(new TermQuery(new Term(\"docid\", id)), 10).totalHits);\n                      } finally {\n                        nrt.release(s);\n                      }\n                    }\n                  }\n\n                  final int count = delCount.addAndGet(toDeleteIDs.size());\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": tot \" + count + \" deletes\");\n                  }\n                  delIDs.addAll(toDeleteIDs);\n                  toDeleteIDs.clear();\n\n                  for(SubDocs subDocs : toDeleteSubDocs) {\n                    assertTrue(!subDocs.deleted);\n                    gen = nrt.deleteDocuments(new Term(\"packID\", subDocs.packID));\n                    subDocs.deleted = true;\n                    if (VERBOSE) {\n                      System.out.println(\"  del subs: \" + subDocs.subIDs + \" packID=\" + subDocs.packID);\n                    }\n                    delIDs.addAll(subDocs.subIDs);\n                    delCount.addAndGet(subDocs.subIDs.size());\n\n                    // randomly verify the delete \"took\":\n                    if (random.nextInt(20) == 7) {\n                      final IndexSearcher s = nrt.get(gen, true);\n                      try {\n                        assertEquals(0, s.search(new TermQuery(new Term(\"packID\", subDocs.packID)), 1).totalHits);\n                      } finally {\n                        nrt.release(s);\n                      }\n                    }\n                  }\n                  toDeleteSubDocs.clear();\n                }\n                if (addedField != null) {\n                  doc.removeField(addedField);\n                }\n              } catch (Throwable t) {\n                System.out.println(Thread.currentThread().getName() + \": FAILED: hit exc\");\n                t.printStackTrace();\n                failed.set(true);\n                throw new RuntimeException(t);\n              }\n            }\n\n            lastGens.add(gen);\n            if (VERBOSE) {\n              System.out.println(Thread.currentThread().getName() + \": indexing done\");\n            }\n          }\n        };\n      threads[thread].setDaemon(true);\n      threads[thread].start();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: DONE start indexing threads [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    // let index build up a bit\n    Thread.sleep(100);\n\n    // silly starting guess:\n    final AtomicInteger totTermCount = new AtomicInteger(100);\n\n    // run search threads\n    final Thread[] searchThreads = new Thread[NUM_SEARCH_THREADS];\n    final AtomicInteger totHits = new AtomicInteger();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: start search threads\");\n    }\n\n    for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n      searchThreads[thread] = new Thread() {\n          @Override\n          public void run() {\n            while(System.currentTimeMillis() < stopTime && !failed.get()) {\n              final IndexSearcher s = nrt.get(random.nextBoolean());\n              try {\n                try {\n                  smokeTestSearcher(s);\n                  if (s.getIndexReader().numDocs() > 0) {\n                    Fields fields = MultiFields.getFields(s.getIndexReader());\n                    if (fields == null) {\n                      continue;\n                    }\n                    Terms terms = fields.terms(\"body\");\n                    if (terms == null) {\n                      continue;\n                    }\n\n                    TermsEnum termsEnum = terms.iterator();\n                    int seenTermCount = 0;\n                    int shift;\n                    int trigger;\n                    if (totTermCount.get() < 10) {\n                      shift = 0;\n                      trigger = 1;\n                    } else {\n                      trigger = totTermCount.get()/10;\n                      shift = random.nextInt(trigger);\n                    }\n\n                    while(System.currentTimeMillis() < stopTime) {\n                      BytesRef term = termsEnum.next();\n                      if (term == null) {\n                        if (seenTermCount == 0) {\n                          break;\n                        }\n                        totTermCount.set(seenTermCount);\n                        seenTermCount = 0;\n                        if (totTermCount.get() < 10) {\n                          shift = 0;\n                          trigger = 1;\n                        } else {\n                          trigger = totTermCount.get()/10;\n                          //System.out.println(\"trigger \" + trigger);\n                          shift = random.nextInt(trigger);\n                        }\n                        termsEnum.seekCeil(new BytesRef(\"\"));\n                        continue;\n                      }\n                      seenTermCount++;\n                      // search 10 terms\n                      if (trigger == 0) {\n                        trigger = 1;\n                      }\n                      if ((seenTermCount + shift) % trigger == 0) {\n                        //if (VERBOSE) {\n                        //System.out.println(Thread.currentThread().getName() + \" now search body:\" + term.utf8ToString());\n                        //}\n                        totHits.addAndGet(runQuery(s, new TermQuery(new Term(\"body\", term))));\n                      }\n                    }\n                    if (VERBOSE) {\n                      System.out.println(Thread.currentThread().getName() + \": search done\");\n                    }\n                  }\n                } finally {\n                  nrt.release(s);\n                }\n              } catch (Throwable t) {\n                System.out.println(Thread.currentThread().getName() + \": FAILED: hit exc\");\n                failed.set(true);\n                t.printStackTrace(System.out);\n                throw new RuntimeException(t);\n              }\n            }\n          }\n        };\n      searchThreads[thread].setDaemon(true);\n      searchThreads[thread].start();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now join\");\n    }\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread].join();\n    }\n    for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n      searchThreads[thread].join();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: done join [\" + (System.currentTimeMillis()-t0) + \" ms]; addCount=\" + addCount + \" delCount=\" + delCount);\n      System.out.println(\"TEST: search totHits=\" + totHits);\n    }\n\n    long maxGen = 0;\n    for(long gen : lastGens) {\n      maxGen = Math.max(maxGen, gen);\n    }\n\n    final IndexSearcher s = nrt.get(maxGen, true);\n\n    boolean doFail = false;\n    for(String id : delIDs) {\n      final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", id)), 1);\n      if (hits.totalHits != 0) {\n        System.out.println(\"doc id=\" + id + \" is supposed to be deleted, but got docID=\" + hits.scoreDocs[0].doc);\n        doFail = true;\n      }\n    }\n\n    // Make sure each group of sub-docs are still in docID order:\n    for(SubDocs subDocs : allSubDocs) {\n      if (!subDocs.deleted) {\n        // We sort by relevance but the scores should be identical so sort falls back to by docID:\n        TopDocs hits = s.search(new TermQuery(new Term(\"packID\", subDocs.packID)), 20);\n        assertEquals(subDocs.subIDs.size(), hits.totalHits);\n        int lastDocID = -1;\n        int startDocID = -1;\n        for(ScoreDoc scoreDoc : hits.scoreDocs) {\n          final int docID = scoreDoc.doc;\n          if (lastDocID != -1) {\n            assertEquals(1+lastDocID, docID);\n          } else {\n            startDocID = docID;\n          }\n          lastDocID = docID;\n          final Document doc = s.doc(docID);\n          assertEquals(subDocs.packID, doc.get(\"packID\"));\n        }\n\n        lastDocID = startDocID - 1;\n        for(String subID : subDocs.subIDs) {\n          hits = s.search(new TermQuery(new Term(\"docid\", subID)), 1);\n          assertEquals(1, hits.totalHits);\n          final int docID = hits.scoreDocs[0].doc;\n          if (lastDocID != -1) {\n            assertEquals(1+lastDocID, docID);\n          }\n          lastDocID = docID;\n        }          \n      } else {\n        for(String subID : subDocs.subIDs) {\n          assertEquals(0, s.search(new TermQuery(new Term(\"docid\", subID)), 1).totalHits);\n        }\n      }\n    }\n    \n    final int endID = Integer.parseInt(docs.nextDoc().get(\"docid\"));\n    for(int id=0;id<endID;id++) {\n      String stringID = \"\"+id;\n      if (!delIDs.contains(stringID)) {\n        final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", stringID)), 1);\n        if (hits.totalHits != 1) {\n          System.out.println(\"doc id=\" + stringID + \" is not supposed to be deleted, but got hitCount=\" + hits.totalHits);\n          doFail = true;\n        }\n      }\n    }\n    assertFalse(doFail);\n\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), s.getIndexReader().numDocs());\n    nrt.release(s);\n\n    if (es != null) {\n      es.shutdown();\n      es.awaitTermination(1, TimeUnit.SECONDS);\n    }\n\n    writer.commit();\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), writer.numDocs());\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now close NRTManager\");\n    }\n    nrtThread.close();\n    nrt.close();\n    assertFalse(writer.anyNonBulkMerges);\n    writer.close(false);\n    _TestUtil.checkIndex(dir);\n    dir.close();\n    _TestUtil.rmDir(tempDir);\n    docs.close();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testNRTManager() throws Exception {\n\n    final long t0 = System.currentTimeMillis();\n\n    if (CodecProvider.getDefault().getDefaultFieldCodec().equals(\"SimpleText\")) {\n      // no\n      CodecProvider.getDefault().setDefaultFieldCodec(\"Standard\");\n    }\n\n    final LineFileDocs docs = new LineFileDocs(random);\n    final File tempDir = _TestUtil.getTempDir(\"nrtopenfiles\");\n    final MockDirectoryWrapper _dir = newFSDirectory(tempDir);\n    _dir.setCheckIndexOnClose(false);  // don't double-checkIndex, we do it ourselves\n    Directory dir = _dir;\n    final IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).setOpenMode(IndexWriterConfig.OpenMode.CREATE);\n\n    if (LuceneTestCase.TEST_NIGHTLY) {\n      // newIWConfig makes smallish max seg size, which\n      // results in tons and tons of segments for this test\n      // when run nightly:\n      MergePolicy mp = conf.getMergePolicy();\n      if (mp instanceof TieredMergePolicy) {\n        ((TieredMergePolicy) mp).setMaxMergedSegmentMB(5000.);\n      } else if (mp instanceof LogByteSizeMergePolicy) {\n        ((LogByteSizeMergePolicy) mp).setMaxMergeMB(1000.);\n      } else if (mp instanceof LogMergePolicy) {\n        ((LogMergePolicy) mp).setMaxMergeDocs(100000);\n      }\n    }\n\n    conf.setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n      @Override\n      public void warm(IndexReader reader) throws IOException {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now warm merged reader=\" + reader);\n        }\n        final int maxDoc = reader.maxDoc();\n        final Bits liveDocs = reader.getLiveDocs();\n        int sum = 0;\n        final int inc = Math.max(1, maxDoc/50);\n        for(int docID=0;docID<maxDoc;docID += inc) {\n          if (liveDocs == null || liveDocs.get(docID)) {\n            final Document doc = reader.document(docID);\n            sum += doc.getFields().size();\n          }\n        }\n\n        IndexSearcher searcher = newSearcher(reader);\n        sum += searcher.search(new TermQuery(new Term(\"body\", \"united\")), 10).totalHits;\n        searcher.close();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: warm visited \" + sum + \" fields\");\n        }\n      }\n      });\n\n    if (random.nextBoolean()) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: wrap NRTCachingDir\");\n      }\n\n      dir = new NRTCachingDirectory(dir, 5.0, 60.0);\n    }\n    \n    final IndexWriter writer = new IndexWriter(dir, conf);\n    \n    if (VERBOSE) {\n      writer.setInfoStream(System.out);\n    }\n    _TestUtil.reduceOpenFiles(writer);\n    //System.out.println(\"TEST: conf=\" + writer.getConfig());\n\n    final ExecutorService es = random.nextBoolean() ? null : Executors.newCachedThreadPool(new NamedThreadFactory(\"NRT search threads\"));\n\n    final double minReopenSec = 0.01 + 0.05 * random.nextDouble();\n    final double maxReopenSec = minReopenSec * (1.0 + 10 * random.nextDouble());\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: make NRTManager maxReopenSec=\" + maxReopenSec + \" minReopenSec=\" + minReopenSec);\n    }\n\n    final NRTManager nrt = new NRTManager(writer, es);\n    final NRTManagerReopenThread nrtThread = new NRTManagerReopenThread(nrt, maxReopenSec, minReopenSec);\n    nrtThread.setName(\"NRT Reopen Thread\");\n    nrtThread.setPriority(Math.min(Thread.currentThread().getPriority()+2, Thread.MAX_PRIORITY));\n    nrtThread.setDaemon(true);\n    nrtThread.start();\n\n    final int NUM_INDEX_THREADS = _TestUtil.nextInt(random, 1, 3);\n    final int NUM_SEARCH_THREADS = _TestUtil.nextInt(random, 1, 3);\n    //final int NUM_INDEX_THREADS = 1;\n    //final int NUM_SEARCH_THREADS = 1;\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + NUM_INDEX_THREADS + \" index threads; \" + NUM_SEARCH_THREADS + \" search threads\");\n    }\n\n    final int RUN_TIME_SEC = LuceneTestCase.TEST_NIGHTLY ? 300 : RANDOM_MULTIPLIER;\n\n    final AtomicBoolean failed = new AtomicBoolean();\n    final AtomicInteger addCount = new AtomicInteger();\n    final AtomicInteger delCount = new AtomicInteger();\n    final AtomicInteger packCount = new AtomicInteger();\n    final List<Long> lastGens = new ArrayList<Long>();\n\n    final Set<String> delIDs = Collections.synchronizedSet(new HashSet<String>());\n    final List<SubDocs> allSubDocs = Collections.synchronizedList(new ArrayList<SubDocs>());\n\n    final long stopTime = System.currentTimeMillis() + RUN_TIME_SEC*1000;\n    Thread[] threads = new Thread[NUM_INDEX_THREADS];\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread] = new Thread() {\n          @Override\n          public void run() {\n            // TODO: would be better if this were cross thread, so that we make sure one thread deleting anothers added docs works:\n            final List<String> toDeleteIDs = new ArrayList<String>();\n            final List<SubDocs> toDeleteSubDocs = new ArrayList<SubDocs>();\n\n            long gen = 0;\n            while(System.currentTimeMillis() < stopTime && !failed.get()) {\n\n              //System.out.println(Thread.currentThread().getName() + \": cycle\");\n              try {\n                // Occassional longish pause if running\n                // nightly\n                if (LuceneTestCase.TEST_NIGHTLY && random.nextInt(6) == 3) {\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": now long sleep\");\n                  }\n                  Thread.sleep(_TestUtil.nextInt(random, 50, 500));\n                }\n\n                // Rate limit ingest rate:\n                Thread.sleep(_TestUtil.nextInt(random, 1, 10));\n                if (VERBOSE) {\n                  System.out.println(Thread.currentThread() + \": done sleep\");\n                }\n\n                Document doc = docs.nextDoc();\n                if (doc == null) {\n                  break;\n                }\n                final String addedField;\n                if (random.nextBoolean()) {\n                  addedField = \"extra\" + random.nextInt(10);\n                  doc.add(new Field(addedField, \"a random field\", Field.Store.NO, Field.Index.ANALYZED));\n                } else {\n                  addedField = null;\n                }\n                if (random.nextBoolean()) {\n\n                  if (random.nextBoolean()) {\n                    // Add a pack of adjacent sub-docs\n                    final String packID;\n                    final SubDocs delSubDocs;\n                    if (toDeleteSubDocs.size() > 0 && random.nextBoolean()) {\n                      delSubDocs = toDeleteSubDocs.get(random.nextInt(toDeleteSubDocs.size()));\n                      assert !delSubDocs.deleted;\n                      toDeleteSubDocs.remove(delSubDocs);\n                      // reuse prior packID\n                      packID = delSubDocs.packID;\n                    } else {\n                      delSubDocs = null;\n                      // make new packID\n                      packID = packCount.getAndIncrement() + \"\";\n                    }\n\n                    final Field packIDField = newField(\"packID\", packID, Field.Store.YES, Field.Index.NOT_ANALYZED);\n                    final List<String> docIDs = new ArrayList<String>();\n                    final SubDocs subDocs = new SubDocs(packID, docIDs);\n                    final List<Document> docsList = new ArrayList<Document>();\n\n                    allSubDocs.add(subDocs);\n                    doc.add(packIDField);\n                    docsList.add(cloneDoc(doc));\n                    docIDs.add(doc.get(\"docid\"));\n\n                    final int maxDocCount = _TestUtil.nextInt(random, 1, 10);\n                    while(docsList.size() < maxDocCount) {\n                      doc = docs.nextDoc();\n                      if (doc == null) {\n                        break;\n                      }\n                      docsList.add(cloneDoc(doc));\n                      docIDs.add(doc.get(\"docid\"));\n                    }\n                    addCount.addAndGet(docsList.size());\n\n                    if (delSubDocs != null) {\n                      delSubDocs.deleted = true;\n                      delIDs.addAll(delSubDocs.subIDs);\n                      delCount.addAndGet(delSubDocs.subIDs.size());\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: update pack packID=\" + delSubDocs.packID + \" count=\" + docsList.size() + \" docs=\" + docIDs);\n                      }\n                      gen = nrt.updateDocuments(new Term(\"packID\", delSubDocs.packID), docsList);\n                      /*\n                      // non-atomic:\n                      nrt.deleteDocuments(new Term(\"packID\", delSubDocs.packID));\n                      for(Document subDoc : docsList) {\n                        nrt.addDocument(subDoc);\n                      }\n                      */\n                    } else {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: add pack packID=\" + packID + \" count=\" + docsList.size() + \" docs=\" + docIDs);\n                      }\n                      gen = nrt.addDocuments(docsList);\n                      \n                      /*\n                      // non-atomic:\n                      for(Document subDoc : docsList) {\n                        nrt.addDocument(subDoc);\n                      }\n                      */\n                    }\n                    doc.removeField(\"packID\");\n\n                    if (random.nextInt(5) == 2) {\n                      if (VERBOSE) {\n                        System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + packID);\n                      }\n                      toDeleteSubDocs.add(subDocs);\n                    }\n\n                    // randomly verify the add/update \"took\":\n                    if (random.nextInt(20) == 2) {\n                      final boolean applyDeletes = delSubDocs != null;\n                      final IndexSearcher s = nrt.get(gen, applyDeletes);\n                      try {\n                        assertEquals(docsList.size(), s.search(new TermQuery(new Term(\"packID\", packID)), 10).totalHits);\n                      } finally {\n                        nrt.release(s);\n                      }\n                    }\n\n                  } else {\n                    if (VERBOSE) {\n                      System.out.println(Thread.currentThread().getName() + \": add doc docid:\" + doc.get(\"docid\"));\n                    }\n\n                    gen = nrt.addDocument(doc);\n                    addCount.getAndIncrement();\n\n                    // randomly verify the add \"took\":\n                    if (random.nextInt(20) == 2) {\n                      //System.out.println(Thread.currentThread().getName() + \": verify\");\n                      final IndexSearcher s = nrt.get(gen, false);\n                      //System.out.println(Thread.currentThread().getName() + \": got s=\" + s);\n                      try {\n                        assertEquals(1, s.search(new TermQuery(new Term(\"docid\", doc.get(\"docid\"))), 10).totalHits);\n                      } finally {\n                        nrt.release(s);\n                      }\n                      //System.out.println(Thread.currentThread().getName() + \": done verify\");\n                    }\n\n                    if (random.nextInt(5) == 3) {\n                      if (VERBOSE) {\n                        System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                      }\n                      toDeleteIDs.add(doc.get(\"docid\"));\n                    }\n                  }\n                } else {\n                  // we use update but it never replaces a\n                  // prior doc\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": update doc id:\" + doc.get(\"docid\"));\n                  }\n                  gen = nrt.updateDocument(new Term(\"docid\", doc.get(\"docid\")), doc);\n                  addCount.getAndIncrement();\n\n                  // randomly verify the add \"took\":\n                  if (random.nextInt(20) == 2) {\n                    final IndexSearcher s = nrt.get(gen, true);\n                    try {\n                      assertEquals(1, s.search(new TermQuery(new Term(\"docid\", doc.get(\"docid\"))), 10).totalHits);\n                    } finally {\n                      nrt.release(s);\n                    }\n                  }\n\n                  if (random.nextInt(5) == 3) {\n                    if (VERBOSE) {\n                      System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                    }\n                    toDeleteIDs.add(doc.get(\"docid\"));\n                  }\n                }\n\n                if (random.nextInt(30) == 17) {\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": apply \" + toDeleteIDs.size() + \" deletes\");\n                  }\n                  for(String id : toDeleteIDs) {\n                    if (VERBOSE) {\n                      System.out.println(Thread.currentThread().getName() + \": del term=id:\" + id);\n                    }\n                    gen = nrt.deleteDocuments(new Term(\"docid\", id));\n\n                    // randomly verify the delete \"took\":\n                    if (random.nextInt(20) == 7) {\n                      final IndexSearcher s = nrt.get(gen, true);\n                      try {\n                        assertEquals(0, s.search(new TermQuery(new Term(\"docid\", id)), 10).totalHits);\n                      } finally {\n                        nrt.release(s);\n                      }\n                    }\n                  }\n\n                  final int count = delCount.addAndGet(toDeleteIDs.size());\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": tot \" + count + \" deletes\");\n                  }\n                  delIDs.addAll(toDeleteIDs);\n                  toDeleteIDs.clear();\n\n                  for(SubDocs subDocs : toDeleteSubDocs) {\n                    assertTrue(!subDocs.deleted);\n                    gen = nrt.deleteDocuments(new Term(\"packID\", subDocs.packID));\n                    subDocs.deleted = true;\n                    if (VERBOSE) {\n                      System.out.println(\"  del subs: \" + subDocs.subIDs + \" packID=\" + subDocs.packID);\n                    }\n                    delIDs.addAll(subDocs.subIDs);\n                    delCount.addAndGet(subDocs.subIDs.size());\n\n                    // randomly verify the delete \"took\":\n                    if (random.nextInt(20) == 7) {\n                      final IndexSearcher s = nrt.get(gen, true);\n                      try {\n                        assertEquals(0, s.search(new TermQuery(new Term(\"packID\", subDocs.packID)), 1).totalHits);\n                      } finally {\n                        nrt.release(s);\n                      }\n                    }\n                  }\n                  toDeleteSubDocs.clear();\n                }\n                if (addedField != null) {\n                  doc.removeField(addedField);\n                }\n              } catch (Throwable t) {\n                System.out.println(Thread.currentThread().getName() + \": FAILED: hit exc\");\n                t.printStackTrace();\n                failed.set(true);\n                throw new RuntimeException(t);\n              }\n            }\n\n            lastGens.add(gen);\n            if (VERBOSE) {\n              System.out.println(Thread.currentThread().getName() + \": indexing done\");\n            }\n          }\n        };\n      threads[thread].setDaemon(true);\n      threads[thread].start();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: DONE start indexing threads [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    // let index build up a bit\n    Thread.sleep(100);\n\n    // silly starting guess:\n    final AtomicInteger totTermCount = new AtomicInteger(100);\n\n    // run search threads\n    final Thread[] searchThreads = new Thread[NUM_SEARCH_THREADS];\n    final AtomicInteger totHits = new AtomicInteger();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: start search threads\");\n    }\n\n    for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n      searchThreads[thread] = new Thread() {\n          @Override\n          public void run() {\n            while(System.currentTimeMillis() < stopTime && !failed.get()) {\n              final IndexSearcher s = nrt.get(random.nextBoolean());\n              try {\n                try {\n                  smokeTestSearcher(s);\n                  if (s.getIndexReader().numDocs() > 0) {\n                    Fields fields = MultiFields.getFields(s.getIndexReader());\n                    if (fields == null) {\n                      continue;\n                    }\n                    Terms terms = fields.terms(\"body\");\n                    if (terms == null) {\n                      continue;\n                    }\n\n                    TermsEnum termsEnum = terms.iterator();\n                    int seenTermCount = 0;\n                    int shift;\n                    int trigger;\n                    if (totTermCount.get() < 10) {\n                      shift = 0;\n                      trigger = 1;\n                    } else {\n                      trigger = totTermCount.get()/10;\n                      shift = random.nextInt(trigger);\n                    }\n\n                    while(System.currentTimeMillis() < stopTime) {\n                      BytesRef term = termsEnum.next();\n                      if (term == null) {\n                        if (seenTermCount == 0) {\n                          break;\n                        }\n                        totTermCount.set(seenTermCount);\n                        seenTermCount = 0;\n                        if (totTermCount.get() < 10) {\n                          shift = 0;\n                          trigger = 1;\n                        } else {\n                          trigger = totTermCount.get()/10;\n                          //System.out.println(\"trigger \" + trigger);\n                          shift = random.nextInt(trigger);\n                        }\n                        termsEnum.seekCeil(new BytesRef(\"\"));\n                        continue;\n                      }\n                      seenTermCount++;\n                      // search 10 terms\n                      if (trigger == 0) {\n                        trigger = 1;\n                      }\n                      if ((seenTermCount + shift) % trigger == 0) {\n                        //if (VERBOSE) {\n                        //System.out.println(Thread.currentThread().getName() + \" now search body:\" + term.utf8ToString());\n                        //}\n                        totHits.addAndGet(runQuery(s, new TermQuery(new Term(\"body\", term))));\n                      }\n                    }\n                    if (VERBOSE) {\n                      System.out.println(Thread.currentThread().getName() + \": search done\");\n                    }\n                  }\n                } finally {\n                  nrt.release(s);\n                }\n              } catch (Throwable t) {\n                System.out.println(Thread.currentThread().getName() + \": FAILED: hit exc\");\n                failed.set(true);\n                t.printStackTrace(System.out);\n                throw new RuntimeException(t);\n              }\n            }\n          }\n        };\n      searchThreads[thread].setDaemon(true);\n      searchThreads[thread].start();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now join\");\n    }\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread].join();\n    }\n    for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n      searchThreads[thread].join();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: done join [\" + (System.currentTimeMillis()-t0) + \" ms]; addCount=\" + addCount + \" delCount=\" + delCount);\n      System.out.println(\"TEST: search totHits=\" + totHits);\n    }\n\n    long maxGen = 0;\n    for(long gen : lastGens) {\n      maxGen = Math.max(maxGen, gen);\n    }\n\n    final IndexSearcher s = nrt.get(maxGen, true);\n\n    boolean doFail = false;\n    for(String id : delIDs) {\n      final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", id)), 1);\n      if (hits.totalHits != 0) {\n        System.out.println(\"doc id=\" + id + \" is supposed to be deleted, but got docID=\" + hits.scoreDocs[0].doc);\n        doFail = true;\n      }\n    }\n\n    // Make sure each group of sub-docs are still in docID order:\n    for(SubDocs subDocs : allSubDocs) {\n      if (!subDocs.deleted) {\n        // We sort by relevance but the scores should be identical so sort falls back to by docID:\n        TopDocs hits = s.search(new TermQuery(new Term(\"packID\", subDocs.packID)), 20);\n        assertEquals(subDocs.subIDs.size(), hits.totalHits);\n        int lastDocID = -1;\n        int startDocID = -1;\n        for(ScoreDoc scoreDoc : hits.scoreDocs) {\n          final int docID = scoreDoc.doc;\n          if (lastDocID != -1) {\n            assertEquals(1+lastDocID, docID);\n          } else {\n            startDocID = docID;\n          }\n          lastDocID = docID;\n          final Document doc = s.doc(docID);\n          assertEquals(subDocs.packID, doc.get(\"packID\"));\n        }\n\n        lastDocID = startDocID - 1;\n        for(String subID : subDocs.subIDs) {\n          hits = s.search(new TermQuery(new Term(\"docid\", subID)), 1);\n          assertEquals(1, hits.totalHits);\n          final int docID = hits.scoreDocs[0].doc;\n          if (lastDocID != -1) {\n            assertEquals(1+lastDocID, docID);\n          }\n          lastDocID = docID;\n        }          \n      } else {\n        for(String subID : subDocs.subIDs) {\n          assertEquals(0, s.search(new TermQuery(new Term(\"docid\", subID)), 1).totalHits);\n        }\n      }\n    }\n    \n    final int endID = Integer.parseInt(docs.nextDoc().get(\"docid\"));\n    for(int id=0;id<endID;id++) {\n      String stringID = \"\"+id;\n      if (!delIDs.contains(stringID)) {\n        final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", stringID)), 1);\n        if (hits.totalHits != 1) {\n          System.out.println(\"doc id=\" + stringID + \" is not supposed to be deleted, but got hitCount=\" + hits.totalHits);\n          doFail = true;\n        }\n      }\n    }\n    assertFalse(doFail);\n\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), s.getIndexReader().numDocs());\n    nrt.release(s);\n\n    if (es != null) {\n      es.shutdown();\n      es.awaitTermination(1, TimeUnit.SECONDS);\n    }\n\n    writer.commit();\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), writer.numDocs());\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now close NRTManager\");\n    }\n    nrtThread.close();\n    nrt.close();\n    assertFalse(writer.anyNonBulkMerges);\n    writer.close(false);\n    _TestUtil.checkIndex(dir);\n    dir.close();\n    _TestUtil.rmDir(tempDir);\n    docs.close();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"edcc2c2cbab6bf89ea584169ffb3ca83a31827f9","date":1316963893,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/contrib/misc/src/test/org/apache/lucene/index/TestNRTManager#testNRTManager().mjava","pathOld":"lucene/contrib/misc/src/test/org/apache/lucene/index/TestNRTManager#testNRTManager().mjava","sourceNew":"  public void testNRTManager() throws Exception {\n    runTest(\"TestNRTManager\");\n  }\n\n","sourceOld":"  @Test\n  public void testNRTManager() throws Exception {\n\n    final long t0 = System.currentTimeMillis();\n\n    if (CodecProvider.getDefault().getDefaultFieldCodec().equals(\"SimpleText\")) {\n      // no\n      CodecProvider.getDefault().setDefaultFieldCodec(\"Standard\");\n    }\n\n    final LineFileDocs docs = new LineFileDocs(random);\n    final File tempDir = _TestUtil.getTempDir(\"nrtopenfiles\");\n    final MockDirectoryWrapper _dir = newFSDirectory(tempDir);\n    _dir.setCheckIndexOnClose(false);  // don't double-checkIndex, we do it ourselves\n    Directory dir = _dir;\n    final IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).setOpenMode(IndexWriterConfig.OpenMode.CREATE);\n\n    if (LuceneTestCase.TEST_NIGHTLY) {\n      // newIWConfig makes smallish max seg size, which\n      // results in tons and tons of segments for this test\n      // when run nightly:\n      MergePolicy mp = conf.getMergePolicy();\n      if (mp instanceof TieredMergePolicy) {\n        ((TieredMergePolicy) mp).setMaxMergedSegmentMB(5000.);\n      } else if (mp instanceof LogByteSizeMergePolicy) {\n        ((LogByteSizeMergePolicy) mp).setMaxMergeMB(1000.);\n      } else if (mp instanceof LogMergePolicy) {\n        ((LogMergePolicy) mp).setMaxMergeDocs(100000);\n      }\n    }\n\n    conf.setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {\n      @Override\n      public void warm(IndexReader reader) throws IOException {\n        if (VERBOSE) {\n          System.out.println(\"TEST: now warm merged reader=\" + reader);\n        }\n        final int maxDoc = reader.maxDoc();\n        final Bits liveDocs = reader.getLiveDocs();\n        int sum = 0;\n        final int inc = Math.max(1, maxDoc/50);\n        for(int docID=0;docID<maxDoc;docID += inc) {\n          if (liveDocs == null || liveDocs.get(docID)) {\n            final Document doc = reader.document(docID);\n            sum += doc.getFields().size();\n          }\n        }\n\n        IndexSearcher searcher = newSearcher(reader);\n        sum += searcher.search(new TermQuery(new Term(\"body\", \"united\")), 10).totalHits;\n        searcher.close();\n\n        if (VERBOSE) {\n          System.out.println(\"TEST: warm visited \" + sum + \" fields\");\n        }\n      }\n      });\n\n    if (random.nextBoolean()) {\n      if (VERBOSE) {\n        System.out.println(\"TEST: wrap NRTCachingDir\");\n      }\n\n      dir = new NRTCachingDirectory(dir, 5.0, 60.0);\n    }\n    \n    final IndexWriter writer = new IndexWriter(dir, conf);\n    \n    if (VERBOSE) {\n      writer.setInfoStream(System.out);\n    }\n    _TestUtil.reduceOpenFiles(writer);\n    //System.out.println(\"TEST: conf=\" + writer.getConfig());\n\n    final ExecutorService es = random.nextBoolean() ? null : Executors.newCachedThreadPool(new NamedThreadFactory(\"NRT search threads\"));\n\n    final double minReopenSec = 0.01 + 0.05 * random.nextDouble();\n    final double maxReopenSec = minReopenSec * (1.0 + 10 * random.nextDouble());\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: make NRTManager maxReopenSec=\" + maxReopenSec + \" minReopenSec=\" + minReopenSec);\n    }\n\n    final NRTManager nrt = new NRTManager(writer, es);\n    final NRTManagerReopenThread nrtThread = new NRTManagerReopenThread(nrt, maxReopenSec, minReopenSec);\n    nrtThread.setName(\"NRT Reopen Thread\");\n    nrtThread.setPriority(Math.min(Thread.currentThread().getPriority()+2, Thread.MAX_PRIORITY));\n    nrtThread.setDaemon(true);\n    nrtThread.start();\n\n    final int NUM_INDEX_THREADS = _TestUtil.nextInt(random, 1, 3);\n    final int NUM_SEARCH_THREADS = _TestUtil.nextInt(random, 1, 3);\n    //final int NUM_INDEX_THREADS = 1;\n    //final int NUM_SEARCH_THREADS = 1;\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + NUM_INDEX_THREADS + \" index threads; \" + NUM_SEARCH_THREADS + \" search threads\");\n    }\n\n    final int RUN_TIME_SEC = LuceneTestCase.TEST_NIGHTLY ? 300 : RANDOM_MULTIPLIER;\n\n    final AtomicBoolean failed = new AtomicBoolean();\n    final AtomicInteger addCount = new AtomicInteger();\n    final AtomicInteger delCount = new AtomicInteger();\n    final AtomicInteger packCount = new AtomicInteger();\n    final List<Long> lastGens = new ArrayList<Long>();\n\n    final Set<String> delIDs = Collections.synchronizedSet(new HashSet<String>());\n    final List<SubDocs> allSubDocs = Collections.synchronizedList(new ArrayList<SubDocs>());\n\n    final long stopTime = System.currentTimeMillis() + RUN_TIME_SEC*1000;\n    Thread[] threads = new Thread[NUM_INDEX_THREADS];\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread] = new Thread() {\n          @Override\n          public void run() {\n            // TODO: would be better if this were cross thread, so that we make sure one thread deleting anothers added docs works:\n            final List<String> toDeleteIDs = new ArrayList<String>();\n            final List<SubDocs> toDeleteSubDocs = new ArrayList<SubDocs>();\n\n            long gen = 0;\n            while(System.currentTimeMillis() < stopTime && !failed.get()) {\n\n              //System.out.println(Thread.currentThread().getName() + \": cycle\");\n              try {\n                // Occassional longish pause if running\n                // nightly\n                if (LuceneTestCase.TEST_NIGHTLY && random.nextInt(6) == 3) {\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": now long sleep\");\n                  }\n                  Thread.sleep(_TestUtil.nextInt(random, 50, 500));\n                }\n\n                // Rate limit ingest rate:\n                Thread.sleep(_TestUtil.nextInt(random, 1, 10));\n                if (VERBOSE) {\n                  System.out.println(Thread.currentThread() + \": done sleep\");\n                }\n\n                Document doc = docs.nextDoc();\n                if (doc == null) {\n                  break;\n                }\n                final String addedField;\n                if (random.nextBoolean()) {\n                  addedField = \"extra\" + random.nextInt(10);\n                  doc.add(new TextField(addedField, \"a random field\"));\n                } else {\n                  addedField = null;\n                }\n                if (random.nextBoolean()) {\n\n                  if (random.nextBoolean()) {\n                    // Add a pack of adjacent sub-docs\n                    final String packID;\n                    final SubDocs delSubDocs;\n                    if (toDeleteSubDocs.size() > 0 && random.nextBoolean()) {\n                      delSubDocs = toDeleteSubDocs.get(random.nextInt(toDeleteSubDocs.size()));\n                      assert !delSubDocs.deleted;\n                      toDeleteSubDocs.remove(delSubDocs);\n                      // reuse prior packID\n                      packID = delSubDocs.packID;\n                    } else {\n                      delSubDocs = null;\n                      // make new packID\n                      packID = packCount.getAndIncrement() + \"\";\n                    }\n\n                    final Field packIDField = newField(\"packID\", packID, StringField.TYPE_STORED);\n                    final List<String> docIDs = new ArrayList<String>();\n                    final SubDocs subDocs = new SubDocs(packID, docIDs);\n                    final List<Document> docsList = new ArrayList<Document>();\n\n                    allSubDocs.add(subDocs);\n                    doc.add(packIDField);\n                    docsList.add(cloneDoc(doc));\n                    docIDs.add(doc.get(\"docid\"));\n\n                    final int maxDocCount = _TestUtil.nextInt(random, 1, 10);\n                    while(docsList.size() < maxDocCount) {\n                      doc = docs.nextDoc();\n                      if (doc == null) {\n                        break;\n                      }\n                      docsList.add(cloneDoc(doc));\n                      docIDs.add(doc.get(\"docid\"));\n                    }\n                    addCount.addAndGet(docsList.size());\n\n                    if (delSubDocs != null) {\n                      delSubDocs.deleted = true;\n                      delIDs.addAll(delSubDocs.subIDs);\n                      delCount.addAndGet(delSubDocs.subIDs.size());\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: update pack packID=\" + delSubDocs.packID + \" count=\" + docsList.size() + \" docs=\" + docIDs);\n                      }\n                      gen = nrt.updateDocuments(new Term(\"packID\", delSubDocs.packID), docsList);\n                      /*\n                      // non-atomic:\n                      nrt.deleteDocuments(new Term(\"packID\", delSubDocs.packID));\n                      for(Document subDoc : docsList) {\n                        nrt.addDocument(subDoc);\n                      }\n                      */\n                    } else {\n                      if (VERBOSE) {\n                        System.out.println(\"TEST: add pack packID=\" + packID + \" count=\" + docsList.size() + \" docs=\" + docIDs);\n                      }\n                      gen = nrt.addDocuments(docsList);\n                      \n                      /*\n                      // non-atomic:\n                      for(Document subDoc : docsList) {\n                        nrt.addDocument(subDoc);\n                      }\n                      */\n                    }\n                    doc.removeField(\"packID\");\n\n                    if (random.nextInt(5) == 2) {\n                      if (VERBOSE) {\n                        System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + packID);\n                      }\n                      toDeleteSubDocs.add(subDocs);\n                    }\n\n                    // randomly verify the add/update \"took\":\n                    if (random.nextInt(20) == 2) {\n                      final boolean applyDeletes = delSubDocs != null;\n                      final IndexSearcher s = nrt.get(gen, applyDeletes);\n                      try {\n                        assertEquals(docsList.size(), s.search(new TermQuery(new Term(\"packID\", packID)), 10).totalHits);\n                      } finally {\n                        nrt.release(s);\n                      }\n                    }\n\n                  } else {\n                    if (VERBOSE) {\n                      System.out.println(Thread.currentThread().getName() + \": add doc docid:\" + doc.get(\"docid\"));\n                    }\n\n                    gen = nrt.addDocument(doc);\n                    addCount.getAndIncrement();\n\n                    // randomly verify the add \"took\":\n                    if (random.nextInt(20) == 2) {\n                      //System.out.println(Thread.currentThread().getName() + \": verify\");\n                      final IndexSearcher s = nrt.get(gen, false);\n                      //System.out.println(Thread.currentThread().getName() + \": got s=\" + s);\n                      try {\n                        assertEquals(1, s.search(new TermQuery(new Term(\"docid\", doc.get(\"docid\"))), 10).totalHits);\n                      } finally {\n                        nrt.release(s);\n                      }\n                      //System.out.println(Thread.currentThread().getName() + \": done verify\");\n                    }\n\n                    if (random.nextInt(5) == 3) {\n                      if (VERBOSE) {\n                        System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                      }\n                      toDeleteIDs.add(doc.get(\"docid\"));\n                    }\n                  }\n                } else {\n                  // we use update but it never replaces a\n                  // prior doc\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": update doc id:\" + doc.get(\"docid\"));\n                  }\n                  gen = nrt.updateDocument(new Term(\"docid\", doc.get(\"docid\")), doc);\n                  addCount.getAndIncrement();\n\n                  // randomly verify the add \"took\":\n                  if (random.nextInt(20) == 2) {\n                    final IndexSearcher s = nrt.get(gen, true);\n                    try {\n                      assertEquals(1, s.search(new TermQuery(new Term(\"docid\", doc.get(\"docid\"))), 10).totalHits);\n                    } finally {\n                      nrt.release(s);\n                    }\n                  }\n\n                  if (random.nextInt(5) == 3) {\n                    if (VERBOSE) {\n                      System.out.println(Thread.currentThread().getName() + \": buffer del id:\" + doc.get(\"docid\"));\n                    }\n                    toDeleteIDs.add(doc.get(\"docid\"));\n                  }\n                }\n\n                if (random.nextInt(30) == 17) {\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": apply \" + toDeleteIDs.size() + \" deletes\");\n                  }\n                  for(String id : toDeleteIDs) {\n                    if (VERBOSE) {\n                      System.out.println(Thread.currentThread().getName() + \": del term=id:\" + id);\n                    }\n                    gen = nrt.deleteDocuments(new Term(\"docid\", id));\n\n                    // randomly verify the delete \"took\":\n                    if (random.nextInt(20) == 7) {\n                      final IndexSearcher s = nrt.get(gen, true);\n                      try {\n                        assertEquals(0, s.search(new TermQuery(new Term(\"docid\", id)), 10).totalHits);\n                      } finally {\n                        nrt.release(s);\n                      }\n                    }\n                  }\n\n                  final int count = delCount.addAndGet(toDeleteIDs.size());\n                  if (VERBOSE) {\n                    System.out.println(Thread.currentThread().getName() + \": tot \" + count + \" deletes\");\n                  }\n                  delIDs.addAll(toDeleteIDs);\n                  toDeleteIDs.clear();\n\n                  for(SubDocs subDocs : toDeleteSubDocs) {\n                    assertTrue(!subDocs.deleted);\n                    gen = nrt.deleteDocuments(new Term(\"packID\", subDocs.packID));\n                    subDocs.deleted = true;\n                    if (VERBOSE) {\n                      System.out.println(\"  del subs: \" + subDocs.subIDs + \" packID=\" + subDocs.packID);\n                    }\n                    delIDs.addAll(subDocs.subIDs);\n                    delCount.addAndGet(subDocs.subIDs.size());\n\n                    // randomly verify the delete \"took\":\n                    if (random.nextInt(20) == 7) {\n                      final IndexSearcher s = nrt.get(gen, true);\n                      try {\n                        assertEquals(0, s.search(new TermQuery(new Term(\"packID\", subDocs.packID)), 1).totalHits);\n                      } finally {\n                        nrt.release(s);\n                      }\n                    }\n                  }\n                  toDeleteSubDocs.clear();\n                }\n                if (addedField != null) {\n                  doc.removeField(addedField);\n                }\n              } catch (Throwable t) {\n                System.out.println(Thread.currentThread().getName() + \": FAILED: hit exc\");\n                t.printStackTrace();\n                failed.set(true);\n                throw new RuntimeException(t);\n              }\n            }\n\n            lastGens.add(gen);\n            if (VERBOSE) {\n              System.out.println(Thread.currentThread().getName() + \": indexing done\");\n            }\n          }\n        };\n      threads[thread].setDaemon(true);\n      threads[thread].start();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: DONE start indexing threads [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n\n    // let index build up a bit\n    Thread.sleep(100);\n\n    // silly starting guess:\n    final AtomicInteger totTermCount = new AtomicInteger(100);\n\n    // run search threads\n    final Thread[] searchThreads = new Thread[NUM_SEARCH_THREADS];\n    final AtomicInteger totHits = new AtomicInteger();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: start search threads\");\n    }\n\n    for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n      searchThreads[thread] = new Thread() {\n          @Override\n          public void run() {\n            while(System.currentTimeMillis() < stopTime && !failed.get()) {\n              final IndexSearcher s = nrt.get(random.nextBoolean());\n              try {\n                try {\n                  smokeTestSearcher(s);\n                  if (s.getIndexReader().numDocs() > 0) {\n                    Fields fields = MultiFields.getFields(s.getIndexReader());\n                    if (fields == null) {\n                      continue;\n                    }\n                    Terms terms = fields.terms(\"body\");\n                    if (terms == null) {\n                      continue;\n                    }\n\n                    TermsEnum termsEnum = terms.iterator();\n                    int seenTermCount = 0;\n                    int shift;\n                    int trigger;\n                    if (totTermCount.get() < 10) {\n                      shift = 0;\n                      trigger = 1;\n                    } else {\n                      trigger = totTermCount.get()/10;\n                      shift = random.nextInt(trigger);\n                    }\n\n                    while(System.currentTimeMillis() < stopTime) {\n                      BytesRef term = termsEnum.next();\n                      if (term == null) {\n                        if (seenTermCount == 0) {\n                          break;\n                        }\n                        totTermCount.set(seenTermCount);\n                        seenTermCount = 0;\n                        if (totTermCount.get() < 10) {\n                          shift = 0;\n                          trigger = 1;\n                        } else {\n                          trigger = totTermCount.get()/10;\n                          //System.out.println(\"trigger \" + trigger);\n                          shift = random.nextInt(trigger);\n                        }\n                        termsEnum.seekCeil(new BytesRef(\"\"));\n                        continue;\n                      }\n                      seenTermCount++;\n                      // search 10 terms\n                      if (trigger == 0) {\n                        trigger = 1;\n                      }\n                      if ((seenTermCount + shift) % trigger == 0) {\n                        //if (VERBOSE) {\n                        //System.out.println(Thread.currentThread().getName() + \" now search body:\" + term.utf8ToString());\n                        //}\n                        totHits.addAndGet(runQuery(s, new TermQuery(new Term(\"body\", term))));\n                      }\n                    }\n                    if (VERBOSE) {\n                      System.out.println(Thread.currentThread().getName() + \": search done\");\n                    }\n                  }\n                } finally {\n                  nrt.release(s);\n                }\n              } catch (Throwable t) {\n                System.out.println(Thread.currentThread().getName() + \": FAILED: hit exc\");\n                failed.set(true);\n                t.printStackTrace(System.out);\n                throw new RuntimeException(t);\n              }\n            }\n          }\n        };\n      searchThreads[thread].setDaemon(true);\n      searchThreads[thread].start();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now join\");\n    }\n    for(int thread=0;thread<NUM_INDEX_THREADS;thread++) {\n      threads[thread].join();\n    }\n    for(int thread=0;thread<NUM_SEARCH_THREADS;thread++) {\n      searchThreads[thread].join();\n    }\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: done join [\" + (System.currentTimeMillis()-t0) + \" ms]; addCount=\" + addCount + \" delCount=\" + delCount);\n      System.out.println(\"TEST: search totHits=\" + totHits);\n    }\n\n    long maxGen = 0;\n    for(long gen : lastGens) {\n      maxGen = Math.max(maxGen, gen);\n    }\n\n    final IndexSearcher s = nrt.get(maxGen, true);\n\n    boolean doFail = false;\n    for(String id : delIDs) {\n      final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", id)), 1);\n      if (hits.totalHits != 0) {\n        System.out.println(\"doc id=\" + id + \" is supposed to be deleted, but got docID=\" + hits.scoreDocs[0].doc);\n        doFail = true;\n      }\n    }\n\n    // Make sure each group of sub-docs are still in docID order:\n    for(SubDocs subDocs : allSubDocs) {\n      if (!subDocs.deleted) {\n        // We sort by relevance but the scores should be identical so sort falls back to by docID:\n        TopDocs hits = s.search(new TermQuery(new Term(\"packID\", subDocs.packID)), 20);\n        assertEquals(subDocs.subIDs.size(), hits.totalHits);\n        int lastDocID = -1;\n        int startDocID = -1;\n        for(ScoreDoc scoreDoc : hits.scoreDocs) {\n          final int docID = scoreDoc.doc;\n          if (lastDocID != -1) {\n            assertEquals(1+lastDocID, docID);\n          } else {\n            startDocID = docID;\n          }\n          lastDocID = docID;\n          final Document doc = s.doc(docID);\n          assertEquals(subDocs.packID, doc.get(\"packID\"));\n        }\n\n        lastDocID = startDocID - 1;\n        for(String subID : subDocs.subIDs) {\n          hits = s.search(new TermQuery(new Term(\"docid\", subID)), 1);\n          assertEquals(1, hits.totalHits);\n          final int docID = hits.scoreDocs[0].doc;\n          if (lastDocID != -1) {\n            assertEquals(1+lastDocID, docID);\n          }\n          lastDocID = docID;\n        }          \n      } else {\n        for(String subID : subDocs.subIDs) {\n          assertEquals(0, s.search(new TermQuery(new Term(\"docid\", subID)), 1).totalHits);\n        }\n      }\n    }\n    \n    final int endID = Integer.parseInt(docs.nextDoc().get(\"docid\"));\n    for(int id=0;id<endID;id++) {\n      String stringID = \"\"+id;\n      if (!delIDs.contains(stringID)) {\n        final TopDocs hits = s.search(new TermQuery(new Term(\"docid\", stringID)), 1);\n        if (hits.totalHits != 1) {\n          System.out.println(\"doc id=\" + stringID + \" is not supposed to be deleted, but got hitCount=\" + hits.totalHits);\n          doFail = true;\n        }\n      }\n    }\n    assertFalse(doFail);\n\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), s.getIndexReader().numDocs());\n    nrt.release(s);\n\n    if (es != null) {\n      es.shutdown();\n      es.awaitTermination(1, TimeUnit.SECONDS);\n    }\n\n    writer.commit();\n    assertEquals(\"index=\" + writer.segString() + \" addCount=\" + addCount + \" delCount=\" + delCount, addCount.get() - delCount.get(), writer.numDocs());\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: now close NRTManager\");\n    }\n    nrtThread.close();\n    nrt.close();\n    assertFalse(writer.anyNonBulkMerges);\n    writer.close(false);\n    _TestUtil.checkIndex(dir);\n    dir.close();\n    _TestUtil.rmDir(tempDir);\n    docs.close();\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: done [\" + (System.currentTimeMillis()-t0) + \" ms]\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"df16fc2e9b615e0138edac46655ae628f5d098ad","date":1320876869,"type":5,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/search/TestNRTManager#testNRTManager().mjava","pathOld":"lucene/contrib/misc/src/test/org/apache/lucene/index/TestNRTManager#testNRTManager().mjava","sourceNew":"  public void testNRTManager() throws Exception {\n    runTest(\"TestNRTManager\");\n  }\n\n","sourceOld":"  public void testNRTManager() throws Exception {\n    runTest(\"TestNRTManager\");\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"b8502a95cc8b8718b499be061845747cc3c3a3c4":["39d69912999d6e0acfb6eb6be558fcc165eee0b2"],"df16fc2e9b615e0138edac46655ae628f5d098ad":["edcc2c2cbab6bf89ea584169ffb3ca83a31827f9"],"e7bd246bb7bc35ac22edfee9157e034dfc4e65eb":["fd9cc9d77712aba3662f24632df7539ab75e3667"],"39d69912999d6e0acfb6eb6be558fcc165eee0b2":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a40a638d82918f2d8a40500c22745ec76b1aac5d":["3d5626fd077eba69371a29616badd26143fea2fa"],"2553b00f699380c64959ccb27991289aae87be2e":["0a2903ea38ae3e636b93a08c52a5e37ae939cf6b","fd9cc9d77712aba3662f24632df7539ab75e3667"],"d083e83f225b11e5fdd900e83d26ddb385b6955c":["a40a638d82918f2d8a40500c22745ec76b1aac5d","e7bd246bb7bc35ac22edfee9157e034dfc4e65eb"],"9ed208afa1e7aa98899ddb1dedfddedddf898253":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","b8502a95cc8b8718b499be061845747cc3c3a3c4"],"817d8435e9135b756f08ce6710ab0baac51bdf88":["2553b00f699380c64959ccb27991289aae87be2e","e7bd246bb7bc35ac22edfee9157e034dfc4e65eb"],"0a2903ea38ae3e636b93a08c52a5e37ae939cf6b":["9ed208afa1e7aa98899ddb1dedfddedddf898253","3d5626fd077eba69371a29616badd26143fea2fa"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"edcc2c2cbab6bf89ea584169ffb3ca83a31827f9":["1509f151d7692d84fae414b2b799ac06ba60fcb4"],"3d5626fd077eba69371a29616badd26143fea2fa":["b8502a95cc8b8718b499be061845747cc3c3a3c4"],"5d004d0e0b3f65bb40da76d476d659d7888270e8":["817d8435e9135b756f08ce6710ab0baac51bdf88","ddc4c914be86e34b54f70023f45a60fa7f04e929"],"ddc4c914be86e34b54f70023f45a60fa7f04e929":["e7bd246bb7bc35ac22edfee9157e034dfc4e65eb","d083e83f225b11e5fdd900e83d26ddb385b6955c"],"1509f151d7692d84fae414b2b799ac06ba60fcb4":["ddc4c914be86e34b54f70023f45a60fa7f04e929"],"fd9cc9d77712aba3662f24632df7539ab75e3667":["3d5626fd077eba69371a29616badd26143fea2fa"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["df16fc2e9b615e0138edac46655ae628f5d098ad"]},"commit2Childs":{"b8502a95cc8b8718b499be061845747cc3c3a3c4":["9ed208afa1e7aa98899ddb1dedfddedddf898253","3d5626fd077eba69371a29616badd26143fea2fa"],"df16fc2e9b615e0138edac46655ae628f5d098ad":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"39d69912999d6e0acfb6eb6be558fcc165eee0b2":["b8502a95cc8b8718b499be061845747cc3c3a3c4"],"e7bd246bb7bc35ac22edfee9157e034dfc4e65eb":["d083e83f225b11e5fdd900e83d26ddb385b6955c","817d8435e9135b756f08ce6710ab0baac51bdf88","ddc4c914be86e34b54f70023f45a60fa7f04e929"],"a40a638d82918f2d8a40500c22745ec76b1aac5d":["d083e83f225b11e5fdd900e83d26ddb385b6955c"],"2553b00f699380c64959ccb27991289aae87be2e":["817d8435e9135b756f08ce6710ab0baac51bdf88"],"d083e83f225b11e5fdd900e83d26ddb385b6955c":["ddc4c914be86e34b54f70023f45a60fa7f04e929"],"9ed208afa1e7aa98899ddb1dedfddedddf898253":["0a2903ea38ae3e636b93a08c52a5e37ae939cf6b"],"817d8435e9135b756f08ce6710ab0baac51bdf88":["5d004d0e0b3f65bb40da76d476d659d7888270e8"],"0a2903ea38ae3e636b93a08c52a5e37ae939cf6b":["2553b00f699380c64959ccb27991289aae87be2e"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["39d69912999d6e0acfb6eb6be558fcc165eee0b2","9ed208afa1e7aa98899ddb1dedfddedddf898253"],"edcc2c2cbab6bf89ea584169ffb3ca83a31827f9":["df16fc2e9b615e0138edac46655ae628f5d098ad"],"3d5626fd077eba69371a29616badd26143fea2fa":["a40a638d82918f2d8a40500c22745ec76b1aac5d","0a2903ea38ae3e636b93a08c52a5e37ae939cf6b","fd9cc9d77712aba3662f24632df7539ab75e3667"],"5d004d0e0b3f65bb40da76d476d659d7888270e8":[],"ddc4c914be86e34b54f70023f45a60fa7f04e929":["5d004d0e0b3f65bb40da76d476d659d7888270e8","1509f151d7692d84fae414b2b799ac06ba60fcb4"],"1509f151d7692d84fae414b2b799ac06ba60fcb4":["edcc2c2cbab6bf89ea584169ffb3ca83a31827f9"],"fd9cc9d77712aba3662f24632df7539ab75e3667":["e7bd246bb7bc35ac22edfee9157e034dfc4e65eb","2553b00f699380c64959ccb27991289aae87be2e"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["5d004d0e0b3f65bb40da76d476d659d7888270e8","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}