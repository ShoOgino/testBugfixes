{"path":"lucene/highlighter/src/java/org/apache/lucene/search/vectorhighlight/FieldPhraseList.WeightedPhraseInfo#WeightedPhraseInfo(Collection[WeightedPhraseInfo]).mjava","commits":[{"id":"050e6201c3a7d4c351ebc06cbe4822e26e028117","date":1382375603,"type":0,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/highlighter/src/java/org/apache/lucene/search/vectorhighlight/FieldPhraseList.WeightedPhraseInfo#WeightedPhraseInfo(Collection[WeightedPhraseInfo]).mjava","pathOld":"/dev/null","sourceNew":"    /**\n     * Merging constructor.  Note that this just grabs seqnum from the first info.\n     */\n    public WeightedPhraseInfo( Collection< WeightedPhraseInfo > toMerge ) {\n      // Pretty much the same idea as merging FieldPhraseLists:\n      // Step 1.  Sort by startOffset, endOffset\n      //          While we are here merge the boosts and termInfos\n      Iterator< WeightedPhraseInfo > toMergeItr = toMerge.iterator();\n      if ( !toMergeItr.hasNext() ) {\n        throw new IllegalArgumentException( \"toMerge must contain at least one WeightedPhraseInfo.\" );\n      }\n      WeightedPhraseInfo first = toMergeItr.next();\n      @SuppressWarnings( { \"rawtypes\", \"unchecked\" } )\n      Iterator< Toffs >[] allToffs = new Iterator[ toMerge.size() ];\n      termsInfos = new ArrayList< TermInfo >();\n      seqnum = first.seqnum;\n      boost = first.boost;\n      allToffs[ 0 ] = first.termsOffsets.iterator();\n      int index = 1;\n      while ( toMergeItr.hasNext() ) {\n        WeightedPhraseInfo info = toMergeItr.next();\n        boost += info.boost;\n        termsInfos.addAll( info.termsInfos );\n        allToffs[ index++ ] = info.termsOffsets.iterator();\n      }\n      // Step 2.  Walk the sorted list merging overlaps\n      MergedIterator< Toffs > itr = new MergedIterator< Toffs >( false, allToffs );\n      termsOffsets = new ArrayList< Toffs >();\n      if ( !itr.hasNext() ) {\n        return;\n      }\n      Toffs work = itr.next();\n      while ( itr.hasNext() ) {\n        Toffs current = itr.next();\n        if ( current.startOffset <= work.endOffset ) {\n          work.endOffset = Math.max( work.endOffset, current.endOffset );\n        } else {\n          termsOffsets.add( work );\n          work = current;\n        }\n      }\n      termsOffsets.add( work );\n    }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"634f330c54fd3f9f491d52036dc3f40b4f4d8934","date":1394635157,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/highlighter/src/java/org/apache/lucene/search/vectorhighlight/FieldPhraseList.WeightedPhraseInfo#WeightedPhraseInfo(Collection[WeightedPhraseInfo]).mjava","pathOld":"lucene/highlighter/src/java/org/apache/lucene/search/vectorhighlight/FieldPhraseList.WeightedPhraseInfo#WeightedPhraseInfo(Collection[WeightedPhraseInfo]).mjava","sourceNew":"    /**\n     * Merging constructor.  Note that this just grabs seqnum from the first info.\n     */\n    public WeightedPhraseInfo( Collection< WeightedPhraseInfo > toMerge ) {\n      // Pretty much the same idea as merging FieldPhraseLists:\n      // Step 1.  Sort by startOffset, endOffset\n      //          While we are here merge the boosts and termInfos\n      Iterator< WeightedPhraseInfo > toMergeItr = toMerge.iterator();\n      if ( !toMergeItr.hasNext() ) {\n        throw new IllegalArgumentException( \"toMerge must contain at least one WeightedPhraseInfo.\" );\n      }\n      WeightedPhraseInfo first = toMergeItr.next();\n      @SuppressWarnings( { \"rawtypes\", \"unchecked\" } )\n      Iterator< Toffs >[] allToffs = new Iterator[ toMerge.size() ];\n      termsInfos = new ArrayList<>();\n      seqnum = first.seqnum;\n      boost = first.boost;\n      allToffs[ 0 ] = first.termsOffsets.iterator();\n      int index = 1;\n      while ( toMergeItr.hasNext() ) {\n        WeightedPhraseInfo info = toMergeItr.next();\n        boost += info.boost;\n        termsInfos.addAll( info.termsInfos );\n        allToffs[ index++ ] = info.termsOffsets.iterator();\n      }\n      // Step 2.  Walk the sorted list merging overlaps\n      MergedIterator< Toffs > itr = new MergedIterator<>( false, allToffs );\n      termsOffsets = new ArrayList<>();\n      if ( !itr.hasNext() ) {\n        return;\n      }\n      Toffs work = itr.next();\n      while ( itr.hasNext() ) {\n        Toffs current = itr.next();\n        if ( current.startOffset <= work.endOffset ) {\n          work.endOffset = Math.max( work.endOffset, current.endOffset );\n        } else {\n          termsOffsets.add( work );\n          work = current;\n        }\n      }\n      termsOffsets.add( work );\n    }\n\n","sourceOld":"    /**\n     * Merging constructor.  Note that this just grabs seqnum from the first info.\n     */\n    public WeightedPhraseInfo( Collection< WeightedPhraseInfo > toMerge ) {\n      // Pretty much the same idea as merging FieldPhraseLists:\n      // Step 1.  Sort by startOffset, endOffset\n      //          While we are here merge the boosts and termInfos\n      Iterator< WeightedPhraseInfo > toMergeItr = toMerge.iterator();\n      if ( !toMergeItr.hasNext() ) {\n        throw new IllegalArgumentException( \"toMerge must contain at least one WeightedPhraseInfo.\" );\n      }\n      WeightedPhraseInfo first = toMergeItr.next();\n      @SuppressWarnings( { \"rawtypes\", \"unchecked\" } )\n      Iterator< Toffs >[] allToffs = new Iterator[ toMerge.size() ];\n      termsInfos = new ArrayList< TermInfo >();\n      seqnum = first.seqnum;\n      boost = first.boost;\n      allToffs[ 0 ] = first.termsOffsets.iterator();\n      int index = 1;\n      while ( toMergeItr.hasNext() ) {\n        WeightedPhraseInfo info = toMergeItr.next();\n        boost += info.boost;\n        termsInfos.addAll( info.termsInfos );\n        allToffs[ index++ ] = info.termsOffsets.iterator();\n      }\n      // Step 2.  Walk the sorted list merging overlaps\n      MergedIterator< Toffs > itr = new MergedIterator< Toffs >( false, allToffs );\n      termsOffsets = new ArrayList< Toffs >();\n      if ( !itr.hasNext() ) {\n        return;\n      }\n      Toffs work = itr.next();\n      while ( itr.hasNext() ) {\n        Toffs current = itr.next();\n        if ( current.startOffset <= work.endOffset ) {\n          work.endOffset = Math.max( work.endOffset, current.endOffset );\n        } else {\n          termsOffsets.add( work );\n          work = current;\n        }\n      }\n      termsOffsets.add( work );\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["050e6201c3a7d4c351ebc06cbe4822e26e028117"],"050e6201c3a7d4c351ebc06cbe4822e26e028117":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["634f330c54fd3f9f491d52036dc3f40b4f4d8934"]},"commit2Childs":{"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"050e6201c3a7d4c351ebc06cbe4822e26e028117":["634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["050e6201c3a7d4c351ebc06cbe4822e26e028117"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}