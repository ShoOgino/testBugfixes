{"path":"lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestConcatenateGraphFilter#testValidNumberOfExpansions().mjava","commits":[{"id":"9e45ad199e1b1a4bbc15c1c08dcd73dc08fa927a","date":1528168051,"type":1,"author":"David Smiley","isMerge":false,"pathNew":"lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestConcatenateGraphFilter#testValidNumberOfExpansions().mjava","pathOld":"lucene/suggest/src/test/org/apache/lucene/search/suggest/document/CompletionTokenStreamTest#testValidNumberOfExpansions().mjava","sourceNew":"  @Test\n  public void testValidNumberOfExpansions() throws IOException {\n    SynonymMap.Builder builder = new SynonymMap.Builder(true);\n    for (int i = 0; i < 256; i++) {\n      builder.add(new CharsRef(\"\" + (i+1)), new CharsRef(\"\" + (1000 + (i+1))), true);\n    }\n    StringBuilder valueBuilder = new StringBuilder();\n    for (int i = 0 ; i < 8 ; i++) {\n      valueBuilder.append(i+1);\n      valueBuilder.append(\" \");\n    }\n    MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, true);\n    tokenizer.setReader(new StringReader(valueBuilder.toString()));\n    SynonymFilter filter = new SynonymFilter(tokenizer, builder.build(), true);\n\n    int count;\n    try (ConcatenateGraphFilter stream = new ConcatenateGraphFilter(filter)) {\n      stream.reset();\n      ConcatenateGraphFilter.BytesRefBuilderTermAttribute attr = stream.addAttribute(ConcatenateGraphFilter.BytesRefBuilderTermAttribute.class);\n      count = 0;\n      while (stream.incrementToken()) {\n        count++;\n        assertNotNull(attr.getBytesRef());\n        assertTrue(attr.getBytesRef().length > 0);\n      }\n    }\n    assertEquals(count, 256);\n  }\n\n","sourceOld":"  @Test\n  public void testValidNumberOfExpansions() throws IOException {\n    SynonymMap.Builder builder = new SynonymMap.Builder(true);\n    for (int i = 0; i < 256; i++) {\n      builder.add(new CharsRef(\"\" + (i+1)), new CharsRef(\"\" + (1000 + (i+1))), true);\n    }\n    StringBuilder valueBuilder = new StringBuilder();\n    for (int i = 0 ; i < 8 ; i++) {\n      valueBuilder.append(i+1);\n      valueBuilder.append(\" \");\n    }\n    MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, true);\n    tokenizer.setReader(new StringReader(valueBuilder.toString()));\n    SynonymFilter filter = new SynonymFilter(tokenizer, builder.build(), true);\n\n    CompletionTokenStream completionTokenStream = new CompletionTokenStream(filter);\n    completionTokenStream.setPayload(new BytesRef());\n    PayloadAttrToTypeAttrFilter stream = new PayloadAttrToTypeAttrFilter(completionTokenStream);\n    stream.reset();\n    CompletionTokenStream.BytesRefBuilderTermAttribute attr = stream.addAttribute(CompletionTokenStream.BytesRefBuilderTermAttribute.class);\n    PositionIncrementAttribute posAttr = stream.addAttribute(PositionIncrementAttribute.class);\n    int maxPos = 0;\n    int count = 0;\n    while(stream.incrementToken()) {\n      count++;\n      assertNotNull(attr.getBytesRef());\n      assertTrue(attr.getBytesRef().length > 0);\n      maxPos += posAttr.getPositionIncrement();\n    }\n    stream.close();\n    assertEquals(count, 256);\n    assertEquals(count, maxPos);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f592209545c71895260367152601e9200399776d","date":1528238935,"type":1,"author":"Michael Braun","isMerge":true,"pathNew":"lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestConcatenateGraphFilter#testValidNumberOfExpansions().mjava","pathOld":"lucene/suggest/src/test/org/apache/lucene/search/suggest/document/CompletionTokenStreamTest#testValidNumberOfExpansions().mjava","sourceNew":"  @Test\n  public void testValidNumberOfExpansions() throws IOException {\n    SynonymMap.Builder builder = new SynonymMap.Builder(true);\n    for (int i = 0; i < 256; i++) {\n      builder.add(new CharsRef(\"\" + (i+1)), new CharsRef(\"\" + (1000 + (i+1))), true);\n    }\n    StringBuilder valueBuilder = new StringBuilder();\n    for (int i = 0 ; i < 8 ; i++) {\n      valueBuilder.append(i+1);\n      valueBuilder.append(\" \");\n    }\n    MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, true);\n    tokenizer.setReader(new StringReader(valueBuilder.toString()));\n    SynonymFilter filter = new SynonymFilter(tokenizer, builder.build(), true);\n\n    int count;\n    try (ConcatenateGraphFilter stream = new ConcatenateGraphFilter(filter)) {\n      stream.reset();\n      ConcatenateGraphFilter.BytesRefBuilderTermAttribute attr = stream.addAttribute(ConcatenateGraphFilter.BytesRefBuilderTermAttribute.class);\n      count = 0;\n      while (stream.incrementToken()) {\n        count++;\n        assertNotNull(attr.getBytesRef());\n        assertTrue(attr.getBytesRef().length > 0);\n      }\n    }\n    assertEquals(count, 256);\n  }\n\n","sourceOld":"  @Test\n  public void testValidNumberOfExpansions() throws IOException {\n    SynonymMap.Builder builder = new SynonymMap.Builder(true);\n    for (int i = 0; i < 256; i++) {\n      builder.add(new CharsRef(\"\" + (i+1)), new CharsRef(\"\" + (1000 + (i+1))), true);\n    }\n    StringBuilder valueBuilder = new StringBuilder();\n    for (int i = 0 ; i < 8 ; i++) {\n      valueBuilder.append(i+1);\n      valueBuilder.append(\" \");\n    }\n    MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, true);\n    tokenizer.setReader(new StringReader(valueBuilder.toString()));\n    SynonymFilter filter = new SynonymFilter(tokenizer, builder.build(), true);\n\n    CompletionTokenStream completionTokenStream = new CompletionTokenStream(filter);\n    completionTokenStream.setPayload(new BytesRef());\n    PayloadAttrToTypeAttrFilter stream = new PayloadAttrToTypeAttrFilter(completionTokenStream);\n    stream.reset();\n    CompletionTokenStream.BytesRefBuilderTermAttribute attr = stream.addAttribute(CompletionTokenStream.BytesRefBuilderTermAttribute.class);\n    PositionIncrementAttribute posAttr = stream.addAttribute(PositionIncrementAttribute.class);\n    int maxPos = 0;\n    int count = 0;\n    while(stream.incrementToken()) {\n      count++;\n      assertNotNull(attr.getBytesRef());\n      assertTrue(attr.getBytesRef().length > 0);\n      maxPos += posAttr.getPositionIncrement();\n    }\n    stream.close();\n    assertEquals(count, 256);\n    assertEquals(count, maxPos);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b70042a8a492f7054d480ccdd2be9796510d4327","date":1528386658,"type":1,"author":"Alessandro Benedetti","isMerge":true,"pathNew":"lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestConcatenateGraphFilter#testValidNumberOfExpansions().mjava","pathOld":"lucene/suggest/src/test/org/apache/lucene/search/suggest/document/CompletionTokenStreamTest#testValidNumberOfExpansions().mjava","sourceNew":"  @Test\n  public void testValidNumberOfExpansions() throws IOException {\n    SynonymMap.Builder builder = new SynonymMap.Builder(true);\n    for (int i = 0; i < 256; i++) {\n      builder.add(new CharsRef(\"\" + (i+1)), new CharsRef(\"\" + (1000 + (i+1))), true);\n    }\n    StringBuilder valueBuilder = new StringBuilder();\n    for (int i = 0 ; i < 8 ; i++) {\n      valueBuilder.append(i+1);\n      valueBuilder.append(\" \");\n    }\n    MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, true);\n    tokenizer.setReader(new StringReader(valueBuilder.toString()));\n    SynonymFilter filter = new SynonymFilter(tokenizer, builder.build(), true);\n\n    int count;\n    try (ConcatenateGraphFilter stream = new ConcatenateGraphFilter(filter)) {\n      stream.reset();\n      ConcatenateGraphFilter.BytesRefBuilderTermAttribute attr = stream.addAttribute(ConcatenateGraphFilter.BytesRefBuilderTermAttribute.class);\n      count = 0;\n      while (stream.incrementToken()) {\n        count++;\n        assertNotNull(attr.getBytesRef());\n        assertTrue(attr.getBytesRef().length > 0);\n      }\n    }\n    assertEquals(count, 256);\n  }\n\n","sourceOld":"  @Test\n  public void testValidNumberOfExpansions() throws IOException {\n    SynonymMap.Builder builder = new SynonymMap.Builder(true);\n    for (int i = 0; i < 256; i++) {\n      builder.add(new CharsRef(\"\" + (i+1)), new CharsRef(\"\" + (1000 + (i+1))), true);\n    }\n    StringBuilder valueBuilder = new StringBuilder();\n    for (int i = 0 ; i < 8 ; i++) {\n      valueBuilder.append(i+1);\n      valueBuilder.append(\" \");\n    }\n    MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, true);\n    tokenizer.setReader(new StringReader(valueBuilder.toString()));\n    SynonymFilter filter = new SynonymFilter(tokenizer, builder.build(), true);\n\n    CompletionTokenStream completionTokenStream = new CompletionTokenStream(filter);\n    completionTokenStream.setPayload(new BytesRef());\n    PayloadAttrToTypeAttrFilter stream = new PayloadAttrToTypeAttrFilter(completionTokenStream);\n    stream.reset();\n    CompletionTokenStream.BytesRefBuilderTermAttribute attr = stream.addAttribute(CompletionTokenStream.BytesRefBuilderTermAttribute.class);\n    PositionIncrementAttribute posAttr = stream.addAttribute(PositionIncrementAttribute.class);\n    int maxPos = 0;\n    int count = 0;\n    while(stream.incrementToken()) {\n      count++;\n      assertNotNull(attr.getBytesRef());\n      assertTrue(attr.getBytesRef().length > 0);\n      maxPos += posAttr.getPositionIncrement();\n    }\n    stream.close();\n    assertEquals(count, 256);\n    assertEquals(count, maxPos);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a5df378a6155dcc1f4d4ecdcbd8ea5bc058560e9","date":1574619880,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestConcatenateGraphFilter#testValidNumberOfExpansions().mjava","pathOld":"lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestConcatenateGraphFilter#testValidNumberOfExpansions().mjava","sourceNew":"  @SuppressWarnings(\"deprecation\")\n  @Test\n  public void testValidNumberOfExpansions() throws IOException {\n    SynonymMap.Builder builder = new SynonymMap.Builder(true);\n    for (int i = 0; i < 256; i++) {\n      builder.add(new CharsRef(\"\" + (i+1)), new CharsRef(\"\" + (1000 + (i+1))), true);\n    }\n    StringBuilder valueBuilder = new StringBuilder();\n    for (int i = 0 ; i < 8 ; i++) {\n      valueBuilder.append(i+1);\n      valueBuilder.append(\" \");\n    }\n    MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, true);\n    tokenizer.setReader(new StringReader(valueBuilder.toString()));\n    org.apache.lucene.analysis.synonym.SynonymFilter filter = new org.apache.lucene.analysis.synonym.SynonymFilter(tokenizer, builder.build(), true);\n\n    int count;\n    try (ConcatenateGraphFilter stream = new ConcatenateGraphFilter(filter)) {\n      stream.reset();\n      ConcatenateGraphFilter.BytesRefBuilderTermAttribute attr = stream.addAttribute(ConcatenateGraphFilter.BytesRefBuilderTermAttribute.class);\n      count = 0;\n      while (stream.incrementToken()) {\n        count++;\n        assertNotNull(attr.getBytesRef());\n        assertTrue(attr.getBytesRef().length > 0);\n      }\n    }\n    assertEquals(count, 256);\n  }\n\n","sourceOld":"  @Test\n  public void testValidNumberOfExpansions() throws IOException {\n    SynonymMap.Builder builder = new SynonymMap.Builder(true);\n    for (int i = 0; i < 256; i++) {\n      builder.add(new CharsRef(\"\" + (i+1)), new CharsRef(\"\" + (1000 + (i+1))), true);\n    }\n    StringBuilder valueBuilder = new StringBuilder();\n    for (int i = 0 ; i < 8 ; i++) {\n      valueBuilder.append(i+1);\n      valueBuilder.append(\" \");\n    }\n    MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, true);\n    tokenizer.setReader(new StringReader(valueBuilder.toString()));\n    SynonymFilter filter = new SynonymFilter(tokenizer, builder.build(), true);\n\n    int count;\n    try (ConcatenateGraphFilter stream = new ConcatenateGraphFilter(filter)) {\n      stream.reset();\n      ConcatenateGraphFilter.BytesRefBuilderTermAttribute attr = stream.addAttribute(ConcatenateGraphFilter.BytesRefBuilderTermAttribute.class);\n      count = 0;\n      while (stream.incrementToken()) {\n        count++;\n        assertNotNull(attr.getBytesRef());\n        assertTrue(attr.getBytesRef().length > 0);\n      }\n    }\n    assertEquals(count, 256);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"bb9c3baacabd473e8ecd6c4948aabacead49b88e","date":1574700980,"type":3,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestConcatenateGraphFilter#testValidNumberOfExpansions().mjava","pathOld":"lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestConcatenateGraphFilter#testValidNumberOfExpansions().mjava","sourceNew":"  @Test\n  public void testValidNumberOfExpansions() throws IOException {\n    SynonymMap.Builder builder = new SynonymMap.Builder(true);\n    for (int i = 0; i < 256; i++) {\n      builder.add(new CharsRef(\"\" + (i+1)), new CharsRef(\"\" + (1000 + (i+1))), true);\n    }\n    StringBuilder valueBuilder = new StringBuilder();\n    for (int i = 0 ; i < 8 ; i++) {\n      valueBuilder.append(i+1);\n      valueBuilder.append(\" \");\n    }\n    MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, true);\n    tokenizer.setReader(new StringReader(valueBuilder.toString()));\n    SynonymFilter filter = new SynonymFilter(tokenizer, builder.build(), true);\n\n    int count;\n    try (ConcatenateGraphFilter stream = new ConcatenateGraphFilter(filter)) {\n      stream.reset();\n      ConcatenateGraphFilter.BytesRefBuilderTermAttribute attr = stream.addAttribute(ConcatenateGraphFilter.BytesRefBuilderTermAttribute.class);\n      count = 0;\n      while (stream.incrementToken()) {\n        count++;\n        assertNotNull(attr.getBytesRef());\n        assertTrue(attr.getBytesRef().length > 0);\n      }\n    }\n    assertEquals(count, 256);\n  }\n\n","sourceOld":"  @SuppressWarnings(\"deprecation\")\n  @Test\n  public void testValidNumberOfExpansions() throws IOException {\n    SynonymMap.Builder builder = new SynonymMap.Builder(true);\n    for (int i = 0; i < 256; i++) {\n      builder.add(new CharsRef(\"\" + (i+1)), new CharsRef(\"\" + (1000 + (i+1))), true);\n    }\n    StringBuilder valueBuilder = new StringBuilder();\n    for (int i = 0 ; i < 8 ; i++) {\n      valueBuilder.append(i+1);\n      valueBuilder.append(\" \");\n    }\n    MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, true);\n    tokenizer.setReader(new StringReader(valueBuilder.toString()));\n    org.apache.lucene.analysis.synonym.SynonymFilter filter = new org.apache.lucene.analysis.synonym.SynonymFilter(tokenizer, builder.build(), true);\n\n    int count;\n    try (ConcatenateGraphFilter stream = new ConcatenateGraphFilter(filter)) {\n      stream.reset();\n      ConcatenateGraphFilter.BytesRefBuilderTermAttribute attr = stream.addAttribute(ConcatenateGraphFilter.BytesRefBuilderTermAttribute.class);\n      count = 0;\n      while (stream.incrementToken()) {\n        count++;\n        assertNotNull(attr.getBytesRef());\n        assertTrue(attr.getBytesRef().length > 0);\n      }\n    }\n    assertEquals(count, 256);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f95c0e33e58652b2a4d8560c8297dbe86ff5b1f2","date":1591961131,"type":3,"author":"Michael Sokolov","isMerge":false,"pathNew":"lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestConcatenateGraphFilter#testValidNumberOfExpansions().mjava","pathOld":"lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestConcatenateGraphFilter#testValidNumberOfExpansions().mjava","sourceNew":"  @Test\n  public void testValidNumberOfExpansions() throws IOException {\n    SynonymMap.Builder builder = new SynonymMap.Builder(true);\n    for (int i = 0; i < 256; i++) {\n      builder.add(new CharsRef(\"\" + (i+1)), new CharsRef(\"\" + (1000 + (i+1))), true);\n    }\n    StringBuilder valueBuilder = new StringBuilder();\n    for (int i = 0 ; i < 8 ; i++) {\n      valueBuilder.append(i+1);\n      valueBuilder.append(\" \");\n    }\n    MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, true);\n    tokenizer.setReader(new StringReader(valueBuilder.toString()));\n    @SuppressWarnings(\"deprecation\")\n    SynonymFilter filter = new SynonymFilter(tokenizer, builder.build(), true);\n\n    int count;\n    try (ConcatenateGraphFilter stream = new ConcatenateGraphFilter(filter)) {\n      stream.reset();\n      ConcatenateGraphFilter.BytesRefBuilderTermAttribute attr = stream.addAttribute(ConcatenateGraphFilter.BytesRefBuilderTermAttribute.class);\n      count = 0;\n      while (stream.incrementToken()) {\n        count++;\n        assertNotNull(attr.getBytesRef());\n        assertTrue(attr.getBytesRef().length > 0);\n      }\n    }\n    assertEquals(count, 256);\n  }\n\n","sourceOld":"  @Test\n  public void testValidNumberOfExpansions() throws IOException {\n    SynonymMap.Builder builder = new SynonymMap.Builder(true);\n    for (int i = 0; i < 256; i++) {\n      builder.add(new CharsRef(\"\" + (i+1)), new CharsRef(\"\" + (1000 + (i+1))), true);\n    }\n    StringBuilder valueBuilder = new StringBuilder();\n    for (int i = 0 ; i < 8 ; i++) {\n      valueBuilder.append(i+1);\n      valueBuilder.append(\" \");\n    }\n    MockTokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, true);\n    tokenizer.setReader(new StringReader(valueBuilder.toString()));\n    SynonymFilter filter = new SynonymFilter(tokenizer, builder.build(), true);\n\n    int count;\n    try (ConcatenateGraphFilter stream = new ConcatenateGraphFilter(filter)) {\n      stream.reset();\n      ConcatenateGraphFilter.BytesRefBuilderTermAttribute attr = stream.addAttribute(ConcatenateGraphFilter.BytesRefBuilderTermAttribute.class);\n      count = 0;\n      while (stream.incrementToken()) {\n        count++;\n        assertNotNull(attr.getBytesRef());\n        assertTrue(attr.getBytesRef().length > 0);\n      }\n    }\n    assertEquals(count, 256);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"a5df378a6155dcc1f4d4ecdcbd8ea5bc058560e9":["9e45ad199e1b1a4bbc15c1c08dcd73dc08fa927a"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"b70042a8a492f7054d480ccdd2be9796510d4327":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","9e45ad199e1b1a4bbc15c1c08dcd73dc08fa927a"],"bb9c3baacabd473e8ecd6c4948aabacead49b88e":["a5df378a6155dcc1f4d4ecdcbd8ea5bc058560e9"],"f95c0e33e58652b2a4d8560c8297dbe86ff5b1f2":["bb9c3baacabd473e8ecd6c4948aabacead49b88e"],"9e45ad199e1b1a4bbc15c1c08dcd73dc08fa927a":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"f592209545c71895260367152601e9200399776d":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","9e45ad199e1b1a4bbc15c1c08dcd73dc08fa927a"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["f95c0e33e58652b2a4d8560c8297dbe86ff5b1f2"]},"commit2Childs":{"a5df378a6155dcc1f4d4ecdcbd8ea5bc058560e9":["bb9c3baacabd473e8ecd6c4948aabacead49b88e"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["b70042a8a492f7054d480ccdd2be9796510d4327","9e45ad199e1b1a4bbc15c1c08dcd73dc08fa927a","f592209545c71895260367152601e9200399776d"],"b70042a8a492f7054d480ccdd2be9796510d4327":[],"bb9c3baacabd473e8ecd6c4948aabacead49b88e":["f95c0e33e58652b2a4d8560c8297dbe86ff5b1f2"],"f95c0e33e58652b2a4d8560c8297dbe86ff5b1f2":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"9e45ad199e1b1a4bbc15c1c08dcd73dc08fa927a":["a5df378a6155dcc1f4d4ecdcbd8ea5bc058560e9","b70042a8a492f7054d480ccdd2be9796510d4327","f592209545c71895260367152601e9200399776d"],"f592209545c71895260367152601e9200399776d":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["b70042a8a492f7054d480ccdd2be9796510d4327","f592209545c71895260367152601e9200399776d","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}