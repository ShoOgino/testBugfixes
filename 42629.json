{"path":"contrib/analyzers/common/src/test/org/apache/lucene/analysis/th/TestThaiAnalyzer#testBuggyTokenType().mjava","commits":[{"id":"dd745d580729e528151b58aeda87ef82f1b95c9b","date":1248369082,"type":1,"author":"Simon Willnauer","isMerge":false,"pathNew":"contrib/analyzers/common/src/test/org/apache/lucene/analysis/th/TestThaiAnalyzer#testBuggyTokenType().mjava","pathOld":"contrib/analyzers/src/test/org/apache/lucene/analysis/th/TestThaiAnalyzer#testBuggyTokenType().mjava","sourceNew":"\t/*\n\t * Thai numeric tokens are typed as <ALPHANUM> instead of <NUM>.\n\t * This is really a problem with the interaction w/ StandardTokenizer, which is used by ThaiAnalyzer.\n\t * \n\t * The issue is this: in StandardTokenizer the entire [:Thai:] block is specified in ALPHANUM (including punctuation, digits, etc)\n\t * Fix is easy: refine this spec to exclude thai punctuation and digits.\n\t * \n\t * A better fix, that would also fix quite a few other languages would be to remove the thai hack.\n\t * Instead, allow the definition of alphanum to include relevant categories like nonspacing marks!\n\t */\n\tpublic void testBuggyTokenType() throws Exception {\n\t\tassertAnalyzesTo(new ThaiAnalyzer(), \"เดอะนิวยอร์กไทมส์ ๑๒๓\", \n\t\t\t\tnew String[] { \"เด\", \"อะนิว\", \"ยอ\", \"ร์ก\", \"ไทมส์\", \"๑๒๓\" },\n\t\t\t\tnew String[] { \"<ALPHANUM>\", \"<ALPHANUM>\", \"<ALPHANUM>\", \"<ALPHANUM>\", \"<ALPHANUM>\", \"<ALPHANUM>\" });\n\t}\n\n","sourceOld":"\t/*\n\t * Thai numeric tokens are typed as <ALPHANUM> instead of <NUM>.\n\t * This is really a problem with the interaction w/ StandardTokenizer, which is used by ThaiAnalyzer.\n\t * \n\t * The issue is this: in StandardTokenizer the entire [:Thai:] block is specified in ALPHANUM (including punctuation, digits, etc)\n\t * Fix is easy: refine this spec to exclude thai punctuation and digits.\n\t * \n\t * A better fix, that would also fix quite a few other languages would be to remove the thai hack.\n\t * Instead, allow the definition of alphanum to include relevant categories like nonspacing marks!\n\t */\n\tpublic void testBuggyTokenType() throws Exception {\n\t\tassertAnalyzesTo(new ThaiAnalyzer(), \"เดอะนิวยอร์กไทมส์ ๑๒๓\", \n\t\t\t\tnew String[] { \"เด\", \"อะนิว\", \"ยอ\", \"ร์ก\", \"ไทมส์\", \"๑๒๓\" },\n\t\t\t\tnew String[] { \"<ALPHANUM>\", \"<ALPHANUM>\", \"<ALPHANUM>\", \"<ALPHANUM>\", \"<ALPHANUM>\", \"<ALPHANUM>\" });\n\t}\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ba1116b3450a9c1642c89445d131b37344055245","date":1256329517,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"contrib/analyzers/common/src/test/org/apache/lucene/analysis/th/TestThaiAnalyzer#testBuggyTokenType().mjava","pathOld":"contrib/analyzers/common/src/test/org/apache/lucene/analysis/th/TestThaiAnalyzer#testBuggyTokenType().mjava","sourceNew":"\t/*\n\t * Thai numeric tokens are typed as <ALPHANUM> instead of <NUM>.\n\t * This is really a problem with the interaction w/ StandardTokenizer, which is used by ThaiAnalyzer.\n\t * \n\t * The issue is this: in StandardTokenizer the entire [:Thai:] block is specified in ALPHANUM (including punctuation, digits, etc)\n\t * Fix is easy: refine this spec to exclude thai punctuation and digits.\n\t * \n\t * A better fix, that would also fix quite a few other languages would be to remove the thai hack.\n\t * Instead, allow the definition of alphanum to include relevant categories like nonspacing marks!\n\t */\n\tpublic void testBuggyTokenType() throws Exception {\n\t\tassertAnalyzesTo(new ThaiAnalyzer(Version.LUCENE_CURRENT), \"เดอะนิวยอร์กไทมส์ ๑๒๓\", \n\t\t\t\tnew String[] { \"เด\", \"อะนิว\", \"ยอ\", \"ร์ก\", \"ไทมส์\", \"๑๒๓\" },\n\t\t\t\tnew String[] { \"<ALPHANUM>\", \"<ALPHANUM>\", \"<ALPHANUM>\", \"<ALPHANUM>\", \"<ALPHANUM>\", \"<ALPHANUM>\" });\n\t}\n\n","sourceOld":"\t/*\n\t * Thai numeric tokens are typed as <ALPHANUM> instead of <NUM>.\n\t * This is really a problem with the interaction w/ StandardTokenizer, which is used by ThaiAnalyzer.\n\t * \n\t * The issue is this: in StandardTokenizer the entire [:Thai:] block is specified in ALPHANUM (including punctuation, digits, etc)\n\t * Fix is easy: refine this spec to exclude thai punctuation and digits.\n\t * \n\t * A better fix, that would also fix quite a few other languages would be to remove the thai hack.\n\t * Instead, allow the definition of alphanum to include relevant categories like nonspacing marks!\n\t */\n\tpublic void testBuggyTokenType() throws Exception {\n\t\tassertAnalyzesTo(new ThaiAnalyzer(), \"เดอะนิวยอร์กไทมส์ ๑๒๓\", \n\t\t\t\tnew String[] { \"เด\", \"อะนิว\", \"ยอ\", \"ร์ก\", \"ไทมส์\", \"๑๒๓\" },\n\t\t\t\tnew String[] { \"<ALPHANUM>\", \"<ALPHANUM>\", \"<ALPHANUM>\", \"<ALPHANUM>\", \"<ALPHANUM>\", \"<ALPHANUM>\" });\n\t}\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a9ac13b5f0ce5ef1b2ce168367d993a79594b23a","date":1267298041,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"contrib/analyzers/common/src/test/org/apache/lucene/analysis/th/TestThaiAnalyzer#testBuggyTokenType().mjava","pathOld":"contrib/analyzers/common/src/test/org/apache/lucene/analysis/th/TestThaiAnalyzer#testBuggyTokenType().mjava","sourceNew":"\t/*\n\t * Thai numeric tokens are typed as <ALPHANUM> instead of <NUM>.\n\t * This is really a problem with the interaction w/ StandardTokenizer, which is used by ThaiAnalyzer.\n\t * \n\t * The issue is this: in StandardTokenizer the entire [:Thai:] block is specified in ALPHANUM (including punctuation, digits, etc)\n\t * Fix is easy: refine this spec to exclude thai punctuation and digits.\n\t * \n\t * A better fix, that would also fix quite a few other languages would be to remove the thai hack.\n\t * Instead, allow the definition of alphanum to include relevant categories like nonspacing marks!\n\t */\n\tpublic void testBuggyTokenType() throws Exception {\n\t\tassertAnalyzesTo(new ThaiAnalyzer(TEST_VERSION_CURRENT), \"เดอะนิวยอร์กไทมส์ ๑๒๓\", \n\t\t\t\tnew String[] { \"เด\", \"อะนิว\", \"ยอ\", \"ร์ก\", \"ไทมส์\", \"๑๒๓\" },\n\t\t\t\tnew String[] { \"<ALPHANUM>\", \"<ALPHANUM>\", \"<ALPHANUM>\", \"<ALPHANUM>\", \"<ALPHANUM>\", \"<ALPHANUM>\" });\n\t}\n\n","sourceOld":"\t/*\n\t * Thai numeric tokens are typed as <ALPHANUM> instead of <NUM>.\n\t * This is really a problem with the interaction w/ StandardTokenizer, which is used by ThaiAnalyzer.\n\t * \n\t * The issue is this: in StandardTokenizer the entire [:Thai:] block is specified in ALPHANUM (including punctuation, digits, etc)\n\t * Fix is easy: refine this spec to exclude thai punctuation and digits.\n\t * \n\t * A better fix, that would also fix quite a few other languages would be to remove the thai hack.\n\t * Instead, allow the definition of alphanum to include relevant categories like nonspacing marks!\n\t */\n\tpublic void testBuggyTokenType() throws Exception {\n\t\tassertAnalyzesTo(new ThaiAnalyzer(Version.LUCENE_CURRENT), \"เดอะนิวยอร์กไทมส์ ๑๒๓\", \n\t\t\t\tnew String[] { \"เด\", \"อะนิว\", \"ยอ\", \"ร์ก\", \"ไทมส์\", \"๑๒๓\" },\n\t\t\t\tnew String[] { \"<ALPHANUM>\", \"<ALPHANUM>\", \"<ALPHANUM>\", \"<ALPHANUM>\", \"<ALPHANUM>\", \"<ALPHANUM>\" });\n\t}\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9454a6510e2db155fb01faa5c049b06ece95fab9","date":1453508333,"type":5,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/contrib/analyzers/common/src/test/org/apache/lucene/analysis/th/TestThaiAnalyzer#testBuggyTokenType().mjava","pathOld":"contrib/analyzers/common/src/test/org/apache/lucene/analysis/th/TestThaiAnalyzer#testBuggyTokenType().mjava","sourceNew":"\t/*\n\t * Thai numeric tokens are typed as <ALPHANUM> instead of <NUM>.\n\t * This is really a problem with the interaction w/ StandardTokenizer, which is used by ThaiAnalyzer.\n\t * \n\t * The issue is this: in StandardTokenizer the entire [:Thai:] block is specified in ALPHANUM (including punctuation, digits, etc)\n\t * Fix is easy: refine this spec to exclude thai punctuation and digits.\n\t * \n\t * A better fix, that would also fix quite a few other languages would be to remove the thai hack.\n\t * Instead, allow the definition of alphanum to include relevant categories like nonspacing marks!\n\t */\n\tpublic void testBuggyTokenType() throws Exception {\n\t\tassertAnalyzesTo(new ThaiAnalyzer(TEST_VERSION_CURRENT), \"เดอะนิวยอร์กไทมส์ ๑๒๓\", \n\t\t\t\tnew String[] { \"เด\", \"อะนิว\", \"ยอ\", \"ร์ก\", \"ไทมส์\", \"๑๒๓\" },\n\t\t\t\tnew String[] { \"<ALPHANUM>\", \"<ALPHANUM>\", \"<ALPHANUM>\", \"<ALPHANUM>\", \"<ALPHANUM>\", \"<ALPHANUM>\" });\n\t}\n\n","sourceOld":"\t/*\n\t * Thai numeric tokens are typed as <ALPHANUM> instead of <NUM>.\n\t * This is really a problem with the interaction w/ StandardTokenizer, which is used by ThaiAnalyzer.\n\t * \n\t * The issue is this: in StandardTokenizer the entire [:Thai:] block is specified in ALPHANUM (including punctuation, digits, etc)\n\t * Fix is easy: refine this spec to exclude thai punctuation and digits.\n\t * \n\t * A better fix, that would also fix quite a few other languages would be to remove the thai hack.\n\t * Instead, allow the definition of alphanum to include relevant categories like nonspacing marks!\n\t */\n\tpublic void testBuggyTokenType() throws Exception {\n\t\tassertAnalyzesTo(new ThaiAnalyzer(TEST_VERSION_CURRENT), \"เดอะนิวยอร์กไทมส์ ๑๒๓\", \n\t\t\t\tnew String[] { \"เด\", \"อะนิว\", \"ยอ\", \"ร์ก\", \"ไทมส์\", \"๑๒๓\" },\n\t\t\t\tnew String[] { \"<ALPHANUM>\", \"<ALPHANUM>\", \"<ALPHANUM>\", \"<ALPHANUM>\", \"<ALPHANUM>\", \"<ALPHANUM>\" });\n\t}\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"dd745d580729e528151b58aeda87ef82f1b95c9b":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"a9ac13b5f0ce5ef1b2ce168367d993a79594b23a":["ba1116b3450a9c1642c89445d131b37344055245"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["a9ac13b5f0ce5ef1b2ce168367d993a79594b23a"],"ba1116b3450a9c1642c89445d131b37344055245":["dd745d580729e528151b58aeda87ef82f1b95c9b"]},"commit2Childs":{"dd745d580729e528151b58aeda87ef82f1b95c9b":["ba1116b3450a9c1642c89445d131b37344055245"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["dd745d580729e528151b58aeda87ef82f1b95c9b"],"a9ac13b5f0ce5ef1b2ce168367d993a79594b23a":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"ba1116b3450a9c1642c89445d131b37344055245":["a9ac13b5f0ce5ef1b2ce168367d993a79594b23a"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"9454a6510e2db155fb01faa5c049b06ece95fab9":["cd5edd1f2b162a5cfa08efd17851a07373a96817"]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}