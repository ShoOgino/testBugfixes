{"path":"src/test/org/apache/lucene/index/TestStressIndexing2#indexRandomIWReader(int,int,int,Directory).mjava","commits":[{"id":"c4ff8864209d2e972cb4393600c26082f9a6533d","date":1239297466,"type":0,"author":"Michael McCandless","isMerge":false,"pathNew":"src/test/org/apache/lucene/index/TestStressIndexing2#indexRandomIWReader(int,int,int,Directory).mjava","pathOld":"/dev/null","sourceNew":"  public DocsAndWriter indexRandomIWReader(int nThreads, int iterations, int range, Directory dir) throws IOException, InterruptedException {\n    Map docs = new HashMap();\n    IndexWriter w = new MockIndexWriter(dir, autoCommit, new WhitespaceAnalyzer(), true);\n    w.setUseCompoundFile(false);\n\n    /***\n        w.setMaxMergeDocs(Integer.MAX_VALUE);\n        w.setMaxFieldLength(10000);\n        w.setRAMBufferSizeMB(1);\n        w.setMergeFactor(10);\n    ***/\n\n    // force many merges\n    w.setMergeFactor(mergeFactor);\n    w.setRAMBufferSizeMB(.1);\n    w.setMaxBufferedDocs(maxBufferedDocs);\n\n    threads = new IndexingThread[nThreads];\n    for (int i=0; i<threads.length; i++) {\n      IndexingThread th = new IndexingThread();\n      th.w = w;\n      th.base = 1000000*i;\n      th.range = range;\n      th.iterations = iterations;\n      threads[i] = th;\n    }\n\n    for (int i=0; i<threads.length; i++) {\n      threads[i].start();\n    }\n    for (int i=0; i<threads.length; i++) {\n      threads[i].join();\n    }\n\n    // w.optimize();\n    //w.close();    \n\n    for (int i=0; i<threads.length; i++) {\n      IndexingThread th = threads[i];\n      synchronized(th) {\n        docs.putAll(th.docs);\n      }\n    }\n\n    _TestUtil.checkIndex(dir);\n    DocsAndWriter dw = new DocsAndWriter();\n    dw.docs = docs;\n    dw.writer = w;\n    return dw;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"87c966e9308847938a7c905c2e46a56d8df788b8","date":1255035452,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/test/org/apache/lucene/index/TestStressIndexing2#indexRandomIWReader(int,int,int,Directory).mjava","pathOld":"src/test/org/apache/lucene/index/TestStressIndexing2#indexRandomIWReader(int,int,int,Directory).mjava","sourceNew":"  public DocsAndWriter indexRandomIWReader(int nThreads, int iterations, int range, Directory dir) throws IOException, InterruptedException {\n    Map docs = new HashMap();\n    IndexWriter w = new MockIndexWriter(dir, new WhitespaceAnalyzer(), true, IndexWriter.MaxFieldLength.UNLIMITED);\n    w.setUseCompoundFile(false);\n\n    /***\n        w.setMaxMergeDocs(Integer.MAX_VALUE);\n        w.setMaxFieldLength(10000);\n        w.setRAMBufferSizeMB(1);\n        w.setMergeFactor(10);\n    ***/\n\n    // force many merges\n    w.setMergeFactor(mergeFactor);\n    w.setRAMBufferSizeMB(.1);\n    w.setMaxBufferedDocs(maxBufferedDocs);\n\n    threads = new IndexingThread[nThreads];\n    for (int i=0; i<threads.length; i++) {\n      IndexingThread th = new IndexingThread();\n      th.w = w;\n      th.base = 1000000*i;\n      th.range = range;\n      th.iterations = iterations;\n      threads[i] = th;\n    }\n\n    for (int i=0; i<threads.length; i++) {\n      threads[i].start();\n    }\n    for (int i=0; i<threads.length; i++) {\n      threads[i].join();\n    }\n\n    // w.optimize();\n    //w.close();    \n\n    for (int i=0; i<threads.length; i++) {\n      IndexingThread th = threads[i];\n      synchronized(th) {\n        docs.putAll(th.docs);\n      }\n    }\n\n    _TestUtil.checkIndex(dir);\n    DocsAndWriter dw = new DocsAndWriter();\n    dw.docs = docs;\n    dw.writer = w;\n    return dw;\n  }\n\n","sourceOld":"  public DocsAndWriter indexRandomIWReader(int nThreads, int iterations, int range, Directory dir) throws IOException, InterruptedException {\n    Map docs = new HashMap();\n    IndexWriter w = new MockIndexWriter(dir, autoCommit, new WhitespaceAnalyzer(), true);\n    w.setUseCompoundFile(false);\n\n    /***\n        w.setMaxMergeDocs(Integer.MAX_VALUE);\n        w.setMaxFieldLength(10000);\n        w.setRAMBufferSizeMB(1);\n        w.setMergeFactor(10);\n    ***/\n\n    // force many merges\n    w.setMergeFactor(mergeFactor);\n    w.setRAMBufferSizeMB(.1);\n    w.setMaxBufferedDocs(maxBufferedDocs);\n\n    threads = new IndexingThread[nThreads];\n    for (int i=0; i<threads.length; i++) {\n      IndexingThread th = new IndexingThread();\n      th.w = w;\n      th.base = 1000000*i;\n      th.range = range;\n      th.iterations = iterations;\n      threads[i] = th;\n    }\n\n    for (int i=0; i<threads.length; i++) {\n      threads[i].start();\n    }\n    for (int i=0; i<threads.length; i++) {\n      threads[i].join();\n    }\n\n    // w.optimize();\n    //w.close();    \n\n    for (int i=0; i<threads.length; i++) {\n      IndexingThread th = threads[i];\n      synchronized(th) {\n        docs.putAll(th.docs);\n      }\n    }\n\n    _TestUtil.checkIndex(dir);\n    DocsAndWriter dw = new DocsAndWriter();\n    dw.docs = docs;\n    dw.writer = w;\n    return dw;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e450c7d50c2fc84c963d0d7ade9d3217d868064d","date":1259932067,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/test/org/apache/lucene/index/TestStressIndexing2#indexRandomIWReader(int,int,int,Directory).mjava","pathOld":"src/test/org/apache/lucene/index/TestStressIndexing2#indexRandomIWReader(int,int,int,Directory).mjava","sourceNew":"  public DocsAndWriter indexRandomIWReader(int nThreads, int iterations, int range, Directory dir) throws IOException, InterruptedException {\n    Map<String,Document> docs = new HashMap<String,Document>();\n    IndexWriter w = new MockIndexWriter(dir, new WhitespaceAnalyzer(), true, IndexWriter.MaxFieldLength.UNLIMITED);\n    w.setUseCompoundFile(false);\n\n    /***\n        w.setMaxMergeDocs(Integer.MAX_VALUE);\n        w.setMaxFieldLength(10000);\n        w.setRAMBufferSizeMB(1);\n        w.setMergeFactor(10);\n    ***/\n\n    // force many merges\n    w.setMergeFactor(mergeFactor);\n    w.setRAMBufferSizeMB(.1);\n    w.setMaxBufferedDocs(maxBufferedDocs);\n\n    threads = new IndexingThread[nThreads];\n    for (int i=0; i<threads.length; i++) {\n      IndexingThread th = new IndexingThread();\n      th.w = w;\n      th.base = 1000000*i;\n      th.range = range;\n      th.iterations = iterations;\n      threads[i] = th;\n    }\n\n    for (int i=0; i<threads.length; i++) {\n      threads[i].start();\n    }\n    for (int i=0; i<threads.length; i++) {\n      threads[i].join();\n    }\n\n    // w.optimize();\n    //w.close();    \n\n    for (int i=0; i<threads.length; i++) {\n      IndexingThread th = threads[i];\n      synchronized(th) {\n        docs.putAll(th.docs);\n      }\n    }\n\n    _TestUtil.checkIndex(dir);\n    DocsAndWriter dw = new DocsAndWriter();\n    dw.docs = docs;\n    dw.writer = w;\n    return dw;\n  }\n\n","sourceOld":"  public DocsAndWriter indexRandomIWReader(int nThreads, int iterations, int range, Directory dir) throws IOException, InterruptedException {\n    Map docs = new HashMap();\n    IndexWriter w = new MockIndexWriter(dir, new WhitespaceAnalyzer(), true, IndexWriter.MaxFieldLength.UNLIMITED);\n    w.setUseCompoundFile(false);\n\n    /***\n        w.setMaxMergeDocs(Integer.MAX_VALUE);\n        w.setMaxFieldLength(10000);\n        w.setRAMBufferSizeMB(1);\n        w.setMergeFactor(10);\n    ***/\n\n    // force many merges\n    w.setMergeFactor(mergeFactor);\n    w.setRAMBufferSizeMB(.1);\n    w.setMaxBufferedDocs(maxBufferedDocs);\n\n    threads = new IndexingThread[nThreads];\n    for (int i=0; i<threads.length; i++) {\n      IndexingThread th = new IndexingThread();\n      th.w = w;\n      th.base = 1000000*i;\n      th.range = range;\n      th.iterations = iterations;\n      threads[i] = th;\n    }\n\n    for (int i=0; i<threads.length; i++) {\n      threads[i].start();\n    }\n    for (int i=0; i<threads.length; i++) {\n      threads[i].join();\n    }\n\n    // w.optimize();\n    //w.close();    \n\n    for (int i=0; i<threads.length; i++) {\n      IndexingThread th = threads[i];\n      synchronized(th) {\n        docs.putAll(th.docs);\n      }\n    }\n\n    _TestUtil.checkIndex(dir);\n    DocsAndWriter dw = new DocsAndWriter();\n    dw.docs = docs;\n    dw.writer = w;\n    return dw;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fe0932c1d340f83fb0a611e5829b3046a1cc1152","date":1264946739,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"src/test/org/apache/lucene/index/TestStressIndexing2#indexRandomIWReader(int,int,int,Directory).mjava","pathOld":"src/test/org/apache/lucene/index/TestStressIndexing2#indexRandomIWReader(int,int,int,Directory).mjava","sourceNew":"  public DocsAndWriter indexRandomIWReader(int nThreads, int iterations, int range, Directory dir) throws IOException, InterruptedException {\n    Map<String,Document> docs = new HashMap<String,Document>();\n    IndexWriter w = new MockIndexWriter(dir, new WhitespaceAnalyzer(Version.LUCENE_CURRENT), true, IndexWriter.MaxFieldLength.UNLIMITED);\n    w.setUseCompoundFile(false);\n\n    /***\n        w.setMaxMergeDocs(Integer.MAX_VALUE);\n        w.setMaxFieldLength(10000);\n        w.setRAMBufferSizeMB(1);\n        w.setMergeFactor(10);\n    ***/\n\n    // force many merges\n    w.setMergeFactor(mergeFactor);\n    w.setRAMBufferSizeMB(.1);\n    w.setMaxBufferedDocs(maxBufferedDocs);\n\n    threads = new IndexingThread[nThreads];\n    for (int i=0; i<threads.length; i++) {\n      IndexingThread th = new IndexingThread();\n      th.w = w;\n      th.base = 1000000*i;\n      th.range = range;\n      th.iterations = iterations;\n      threads[i] = th;\n    }\n\n    for (int i=0; i<threads.length; i++) {\n      threads[i].start();\n    }\n    for (int i=0; i<threads.length; i++) {\n      threads[i].join();\n    }\n\n    // w.optimize();\n    //w.close();    \n\n    for (int i=0; i<threads.length; i++) {\n      IndexingThread th = threads[i];\n      synchronized(th) {\n        docs.putAll(th.docs);\n      }\n    }\n\n    _TestUtil.checkIndex(dir);\n    DocsAndWriter dw = new DocsAndWriter();\n    dw.docs = docs;\n    dw.writer = w;\n    return dw;\n  }\n\n","sourceOld":"  public DocsAndWriter indexRandomIWReader(int nThreads, int iterations, int range, Directory dir) throws IOException, InterruptedException {\n    Map<String,Document> docs = new HashMap<String,Document>();\n    IndexWriter w = new MockIndexWriter(dir, new WhitespaceAnalyzer(), true, IndexWriter.MaxFieldLength.UNLIMITED);\n    w.setUseCompoundFile(false);\n\n    /***\n        w.setMaxMergeDocs(Integer.MAX_VALUE);\n        w.setMaxFieldLength(10000);\n        w.setRAMBufferSizeMB(1);\n        w.setMergeFactor(10);\n    ***/\n\n    // force many merges\n    w.setMergeFactor(mergeFactor);\n    w.setRAMBufferSizeMB(.1);\n    w.setMaxBufferedDocs(maxBufferedDocs);\n\n    threads = new IndexingThread[nThreads];\n    for (int i=0; i<threads.length; i++) {\n      IndexingThread th = new IndexingThread();\n      th.w = w;\n      th.base = 1000000*i;\n      th.range = range;\n      th.iterations = iterations;\n      threads[i] = th;\n    }\n\n    for (int i=0; i<threads.length; i++) {\n      threads[i].start();\n    }\n    for (int i=0; i<threads.length; i++) {\n      threads[i].join();\n    }\n\n    // w.optimize();\n    //w.close();    \n\n    for (int i=0; i<threads.length; i++) {\n      IndexingThread th = threads[i];\n      synchronized(th) {\n        docs.putAll(th.docs);\n      }\n    }\n\n    _TestUtil.checkIndex(dir);\n    DocsAndWriter dw = new DocsAndWriter();\n    dw.docs = docs;\n    dw.writer = w;\n    return dw;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"55f083e91bb056b57de136da1dfc3b9b6ecc4ef6","date":1265808957,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"src/test/org/apache/lucene/index/TestStressIndexing2#indexRandomIWReader(int,int,int,Directory).mjava","pathOld":"src/test/org/apache/lucene/index/TestStressIndexing2#indexRandomIWReader(int,int,int,Directory).mjava","sourceNew":"  public DocsAndWriter indexRandomIWReader(int nThreads, int iterations, int range, Directory dir) throws IOException, InterruptedException {\n    Map<String,Document> docs = new HashMap<String,Document>();\n    IndexWriter w = new MockIndexWriter(dir, new WhitespaceAnalyzer(TEST_VERSION_CURRENT), true, IndexWriter.MaxFieldLength.UNLIMITED);\n    w.setUseCompoundFile(false);\n\n    /***\n        w.setMaxMergeDocs(Integer.MAX_VALUE);\n        w.setMaxFieldLength(10000);\n        w.setRAMBufferSizeMB(1);\n        w.setMergeFactor(10);\n    ***/\n\n    // force many merges\n    w.setMergeFactor(mergeFactor);\n    w.setRAMBufferSizeMB(.1);\n    w.setMaxBufferedDocs(maxBufferedDocs);\n\n    threads = new IndexingThread[nThreads];\n    for (int i=0; i<threads.length; i++) {\n      IndexingThread th = new IndexingThread();\n      th.w = w;\n      th.base = 1000000*i;\n      th.range = range;\n      th.iterations = iterations;\n      threads[i] = th;\n    }\n\n    for (int i=0; i<threads.length; i++) {\n      threads[i].start();\n    }\n    for (int i=0; i<threads.length; i++) {\n      threads[i].join();\n    }\n\n    // w.optimize();\n    //w.close();    \n\n    for (int i=0; i<threads.length; i++) {\n      IndexingThread th = threads[i];\n      synchronized(th) {\n        docs.putAll(th.docs);\n      }\n    }\n\n    _TestUtil.checkIndex(dir);\n    DocsAndWriter dw = new DocsAndWriter();\n    dw.docs = docs;\n    dw.writer = w;\n    return dw;\n  }\n\n","sourceOld":"  public DocsAndWriter indexRandomIWReader(int nThreads, int iterations, int range, Directory dir) throws IOException, InterruptedException {\n    Map<String,Document> docs = new HashMap<String,Document>();\n    IndexWriter w = new MockIndexWriter(dir, new WhitespaceAnalyzer(Version.LUCENE_CURRENT), true, IndexWriter.MaxFieldLength.UNLIMITED);\n    w.setUseCompoundFile(false);\n\n    /***\n        w.setMaxMergeDocs(Integer.MAX_VALUE);\n        w.setMaxFieldLength(10000);\n        w.setRAMBufferSizeMB(1);\n        w.setMergeFactor(10);\n    ***/\n\n    // force many merges\n    w.setMergeFactor(mergeFactor);\n    w.setRAMBufferSizeMB(.1);\n    w.setMaxBufferedDocs(maxBufferedDocs);\n\n    threads = new IndexingThread[nThreads];\n    for (int i=0; i<threads.length; i++) {\n      IndexingThread th = new IndexingThread();\n      th.w = w;\n      th.base = 1000000*i;\n      th.range = range;\n      th.iterations = iterations;\n      threads[i] = th;\n    }\n\n    for (int i=0; i<threads.length; i++) {\n      threads[i].start();\n    }\n    for (int i=0; i<threads.length; i++) {\n      threads[i].join();\n    }\n\n    // w.optimize();\n    //w.close();    \n\n    for (int i=0; i<threads.length; i++) {\n      IndexingThread th = threads[i];\n      synchronized(th) {\n        docs.putAll(th.docs);\n      }\n    }\n\n    _TestUtil.checkIndex(dir);\n    DocsAndWriter dw = new DocsAndWriter();\n    dw.docs = docs;\n    dw.writer = w;\n    return dw;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1cedb00d2dd44640194401179358a2e3ba6051bf","date":1268243626,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/test/org/apache/lucene/index/TestStressIndexing2#indexRandomIWReader(int,int,int,Directory).mjava","pathOld":"src/test/org/apache/lucene/index/TestStressIndexing2#indexRandomIWReader(int,int,int,Directory).mjava","sourceNew":"  public DocsAndWriter indexRandomIWReader(int nThreads, int iterations, int range, Directory dir) throws IOException, InterruptedException {\n    Map<String,Document> docs = new HashMap<String,Document>();\n    IndexWriter w = new MockIndexWriter(dir, new IndexWriterConfig(\n        TEST_VERSION_CURRENT).setOpenMode(OpenMode.CREATE).setRAMBufferSizeMB(\n        0.1).setMaxBufferedDocs(maxBufferedDocs));\n    LogMergePolicy lmp = (LogMergePolicy) w.getMergePolicy();\n    lmp.setUseCompoundFile(false);\n    lmp.setUseCompoundDocStore(false);\n    lmp.setMergeFactor(mergeFactor);\n    /***\n        w.setMaxMergeDocs(Integer.MAX_VALUE);\n        w.setMaxFieldLength(10000);\n        w.setRAMBufferSizeMB(1);\n        w.setMergeFactor(10);\n    ***/\n\n    threads = new IndexingThread[nThreads];\n    for (int i=0; i<threads.length; i++) {\n      IndexingThread th = new IndexingThread();\n      th.w = w;\n      th.base = 1000000*i;\n      th.range = range;\n      th.iterations = iterations;\n      threads[i] = th;\n    }\n\n    for (int i=0; i<threads.length; i++) {\n      threads[i].start();\n    }\n    for (int i=0; i<threads.length; i++) {\n      threads[i].join();\n    }\n\n    // w.optimize();\n    //w.close();    \n\n    for (int i=0; i<threads.length; i++) {\n      IndexingThread th = threads[i];\n      synchronized(th) {\n        docs.putAll(th.docs);\n      }\n    }\n\n    _TestUtil.checkIndex(dir);\n    DocsAndWriter dw = new DocsAndWriter();\n    dw.docs = docs;\n    dw.writer = w;\n    return dw;\n  }\n\n","sourceOld":"  public DocsAndWriter indexRandomIWReader(int nThreads, int iterations, int range, Directory dir) throws IOException, InterruptedException {\n    Map<String,Document> docs = new HashMap<String,Document>();\n    IndexWriter w = new MockIndexWriter(dir, new WhitespaceAnalyzer(TEST_VERSION_CURRENT), true, IndexWriter.MaxFieldLength.UNLIMITED);\n    w.setUseCompoundFile(false);\n\n    /***\n        w.setMaxMergeDocs(Integer.MAX_VALUE);\n        w.setMaxFieldLength(10000);\n        w.setRAMBufferSizeMB(1);\n        w.setMergeFactor(10);\n    ***/\n\n    // force many merges\n    w.setMergeFactor(mergeFactor);\n    w.setRAMBufferSizeMB(.1);\n    w.setMaxBufferedDocs(maxBufferedDocs);\n\n    threads = new IndexingThread[nThreads];\n    for (int i=0; i<threads.length; i++) {\n      IndexingThread th = new IndexingThread();\n      th.w = w;\n      th.base = 1000000*i;\n      th.range = range;\n      th.iterations = iterations;\n      threads[i] = th;\n    }\n\n    for (int i=0; i<threads.length; i++) {\n      threads[i].start();\n    }\n    for (int i=0; i<threads.length; i++) {\n      threads[i].join();\n    }\n\n    // w.optimize();\n    //w.close();    \n\n    for (int i=0; i<threads.length; i++) {\n      IndexingThread th = threads[i];\n      synchronized(th) {\n        docs.putAll(th.docs);\n      }\n    }\n\n    _TestUtil.checkIndex(dir);\n    DocsAndWriter dw = new DocsAndWriter();\n    dw.docs = docs;\n    dw.writer = w;\n    return dw;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e52fea2c4081a1e552b98506691990be59503168","date":1268250331,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/test/org/apache/lucene/index/TestStressIndexing2#indexRandomIWReader(int,int,int,Directory).mjava","pathOld":"src/test/org/apache/lucene/index/TestStressIndexing2#indexRandomIWReader(int,int,int,Directory).mjava","sourceNew":"  public DocsAndWriter indexRandomIWReader(int nThreads, int iterations, int range, Directory dir) throws IOException, InterruptedException {\n    Map<String,Document> docs = new HashMap<String,Document>();\n    IndexWriter w = new MockIndexWriter(dir, new WhitespaceAnalyzer(TEST_VERSION_CURRENT), true, IndexWriter.MaxFieldLength.UNLIMITED);\n    w.setUseCompoundFile(false);\n\n    /***\n        w.setMaxMergeDocs(Integer.MAX_VALUE);\n        w.setMaxFieldLength(10000);\n        w.setRAMBufferSizeMB(1);\n        w.setMergeFactor(10);\n    ***/\n\n    // force many merges\n    w.setMergeFactor(mergeFactor);\n    w.setRAMBufferSizeMB(.1);\n    w.setMaxBufferedDocs(maxBufferedDocs);\n\n    threads = new IndexingThread[nThreads];\n    for (int i=0; i<threads.length; i++) {\n      IndexingThread th = new IndexingThread();\n      th.w = w;\n      th.base = 1000000*i;\n      th.range = range;\n      th.iterations = iterations;\n      threads[i] = th;\n    }\n\n    for (int i=0; i<threads.length; i++) {\n      threads[i].start();\n    }\n    for (int i=0; i<threads.length; i++) {\n      threads[i].join();\n    }\n\n    // w.optimize();\n    //w.close();    \n\n    for (int i=0; i<threads.length; i++) {\n      IndexingThread th = threads[i];\n      synchronized(th) {\n        docs.putAll(th.docs);\n      }\n    }\n\n    _TestUtil.checkIndex(dir);\n    DocsAndWriter dw = new DocsAndWriter();\n    dw.docs = docs;\n    dw.writer = w;\n    return dw;\n  }\n\n","sourceOld":"  public DocsAndWriter indexRandomIWReader(int nThreads, int iterations, int range, Directory dir) throws IOException, InterruptedException {\n    Map<String,Document> docs = new HashMap<String,Document>();\n    IndexWriter w = new MockIndexWriter(dir, new IndexWriterConfig(\n        TEST_VERSION_CURRENT).setOpenMode(OpenMode.CREATE).setRAMBufferSizeMB(\n        0.1).setMaxBufferedDocs(maxBufferedDocs));\n    LogMergePolicy lmp = (LogMergePolicy) w.getMergePolicy();\n    lmp.setUseCompoundFile(false);\n    lmp.setUseCompoundDocStore(false);\n    lmp.setMergeFactor(mergeFactor);\n    /***\n        w.setMaxMergeDocs(Integer.MAX_VALUE);\n        w.setMaxFieldLength(10000);\n        w.setRAMBufferSizeMB(1);\n        w.setMergeFactor(10);\n    ***/\n\n    threads = new IndexingThread[nThreads];\n    for (int i=0; i<threads.length; i++) {\n      IndexingThread th = new IndexingThread();\n      th.w = w;\n      th.base = 1000000*i;\n      th.range = range;\n      th.iterations = iterations;\n      threads[i] = th;\n    }\n\n    for (int i=0; i<threads.length; i++) {\n      threads[i].start();\n    }\n    for (int i=0; i<threads.length; i++) {\n      threads[i].join();\n    }\n\n    // w.optimize();\n    //w.close();    \n\n    for (int i=0; i<threads.length; i++) {\n      IndexingThread th = threads[i];\n      synchronized(th) {\n        docs.putAll(th.docs);\n      }\n    }\n\n    _TestUtil.checkIndex(dir);\n    DocsAndWriter dw = new DocsAndWriter();\n    dw.docs = docs;\n    dw.writer = w;\n    return dw;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"84080a7d7dbdaa3e6a4a1c9f1bb6221be40f47e8","date":1268494368,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/test/org/apache/lucene/index/TestStressIndexing2#indexRandomIWReader(int,int,int,Directory).mjava","pathOld":"src/test/org/apache/lucene/index/TestStressIndexing2#indexRandomIWReader(int,int,int,Directory).mjava","sourceNew":"  public DocsAndWriter indexRandomIWReader(int nThreads, int iterations, int range, Directory dir) throws IOException, InterruptedException {\n    Map<String,Document> docs = new HashMap<String,Document>();\n    IndexWriter w = new MockIndexWriter(dir, new IndexWriterConfig(\n        TEST_VERSION_CURRENT, new WhitespaceAnalyzer(TEST_VERSION_CURRENT)).setOpenMode(OpenMode.CREATE).setRAMBufferSizeMB(\n        0.1).setMaxBufferedDocs(maxBufferedDocs));\n    LogMergePolicy lmp = (LogMergePolicy) w.getMergePolicy();\n    lmp.setUseCompoundFile(false);\n    lmp.setUseCompoundDocStore(false);\n    lmp.setMergeFactor(mergeFactor);\n    /***\n        w.setMaxMergeDocs(Integer.MAX_VALUE);\n        w.setMaxFieldLength(10000);\n        w.setRAMBufferSizeMB(1);\n        w.setMergeFactor(10);\n    ***/\n\n    threads = new IndexingThread[nThreads];\n    for (int i=0; i<threads.length; i++) {\n      IndexingThread th = new IndexingThread();\n      th.w = w;\n      th.base = 1000000*i;\n      th.range = range;\n      th.iterations = iterations;\n      threads[i] = th;\n    }\n\n    for (int i=0; i<threads.length; i++) {\n      threads[i].start();\n    }\n    for (int i=0; i<threads.length; i++) {\n      threads[i].join();\n    }\n\n    // w.optimize();\n    //w.close();    \n\n    for (int i=0; i<threads.length; i++) {\n      IndexingThread th = threads[i];\n      synchronized(th) {\n        docs.putAll(th.docs);\n      }\n    }\n\n    _TestUtil.checkIndex(dir);\n    DocsAndWriter dw = new DocsAndWriter();\n    dw.docs = docs;\n    dw.writer = w;\n    return dw;\n  }\n\n","sourceOld":"  public DocsAndWriter indexRandomIWReader(int nThreads, int iterations, int range, Directory dir) throws IOException, InterruptedException {\n    Map<String,Document> docs = new HashMap<String,Document>();\n    IndexWriter w = new MockIndexWriter(dir, new WhitespaceAnalyzer(TEST_VERSION_CURRENT), true, IndexWriter.MaxFieldLength.UNLIMITED);\n    w.setUseCompoundFile(false);\n\n    /***\n        w.setMaxMergeDocs(Integer.MAX_VALUE);\n        w.setMaxFieldLength(10000);\n        w.setRAMBufferSizeMB(1);\n        w.setMergeFactor(10);\n    ***/\n\n    // force many merges\n    w.setMergeFactor(mergeFactor);\n    w.setRAMBufferSizeMB(.1);\n    w.setMaxBufferedDocs(maxBufferedDocs);\n\n    threads = new IndexingThread[nThreads];\n    for (int i=0; i<threads.length; i++) {\n      IndexingThread th = new IndexingThread();\n      th.w = w;\n      th.base = 1000000*i;\n      th.range = range;\n      th.iterations = iterations;\n      threads[i] = th;\n    }\n\n    for (int i=0; i<threads.length; i++) {\n      threads[i].start();\n    }\n    for (int i=0; i<threads.length; i++) {\n      threads[i].join();\n    }\n\n    // w.optimize();\n    //w.close();    \n\n    for (int i=0; i<threads.length; i++) {\n      IndexingThread th = threads[i];\n      synchronized(th) {\n        docs.putAll(th.docs);\n      }\n    }\n\n    _TestUtil.checkIndex(dir);\n    DocsAndWriter dw = new DocsAndWriter();\n    dw.docs = docs;\n    dw.writer = w;\n    return dw;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9454a6510e2db155fb01faa5c049b06ece95fab9","date":1453508333,"type":5,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestStressIndexing2#indexRandomIWReader(int,int,int,Directory).mjava","pathOld":"src/test/org/apache/lucene/index/TestStressIndexing2#indexRandomIWReader(int,int,int,Directory).mjava","sourceNew":"  public DocsAndWriter indexRandomIWReader(int nThreads, int iterations, int range, Directory dir) throws IOException, InterruptedException {\n    Map<String,Document> docs = new HashMap<String,Document>();\n    IndexWriter w = new MockIndexWriter(dir, new IndexWriterConfig(\n        TEST_VERSION_CURRENT, new WhitespaceAnalyzer(TEST_VERSION_CURRENT)).setOpenMode(OpenMode.CREATE).setRAMBufferSizeMB(\n        0.1).setMaxBufferedDocs(maxBufferedDocs));\n    LogMergePolicy lmp = (LogMergePolicy) w.getMergePolicy();\n    lmp.setUseCompoundFile(false);\n    lmp.setUseCompoundDocStore(false);\n    lmp.setMergeFactor(mergeFactor);\n    /***\n        w.setMaxMergeDocs(Integer.MAX_VALUE);\n        w.setMaxFieldLength(10000);\n        w.setRAMBufferSizeMB(1);\n        w.setMergeFactor(10);\n    ***/\n\n    threads = new IndexingThread[nThreads];\n    for (int i=0; i<threads.length; i++) {\n      IndexingThread th = new IndexingThread();\n      th.w = w;\n      th.base = 1000000*i;\n      th.range = range;\n      th.iterations = iterations;\n      threads[i] = th;\n    }\n\n    for (int i=0; i<threads.length; i++) {\n      threads[i].start();\n    }\n    for (int i=0; i<threads.length; i++) {\n      threads[i].join();\n    }\n\n    // w.optimize();\n    //w.close();    \n\n    for (int i=0; i<threads.length; i++) {\n      IndexingThread th = threads[i];\n      synchronized(th) {\n        docs.putAll(th.docs);\n      }\n    }\n\n    _TestUtil.checkIndex(dir);\n    DocsAndWriter dw = new DocsAndWriter();\n    dw.docs = docs;\n    dw.writer = w;\n    return dw;\n  }\n\n","sourceOld":"  public DocsAndWriter indexRandomIWReader(int nThreads, int iterations, int range, Directory dir) throws IOException, InterruptedException {\n    Map<String,Document> docs = new HashMap<String,Document>();\n    IndexWriter w = new MockIndexWriter(dir, new IndexWriterConfig(\n        TEST_VERSION_CURRENT, new WhitespaceAnalyzer(TEST_VERSION_CURRENT)).setOpenMode(OpenMode.CREATE).setRAMBufferSizeMB(\n        0.1).setMaxBufferedDocs(maxBufferedDocs));\n    LogMergePolicy lmp = (LogMergePolicy) w.getMergePolicy();\n    lmp.setUseCompoundFile(false);\n    lmp.setUseCompoundDocStore(false);\n    lmp.setMergeFactor(mergeFactor);\n    /***\n        w.setMaxMergeDocs(Integer.MAX_VALUE);\n        w.setMaxFieldLength(10000);\n        w.setRAMBufferSizeMB(1);\n        w.setMergeFactor(10);\n    ***/\n\n    threads = new IndexingThread[nThreads];\n    for (int i=0; i<threads.length; i++) {\n      IndexingThread th = new IndexingThread();\n      th.w = w;\n      th.base = 1000000*i;\n      th.range = range;\n      th.iterations = iterations;\n      threads[i] = th;\n    }\n\n    for (int i=0; i<threads.length; i++) {\n      threads[i].start();\n    }\n    for (int i=0; i<threads.length; i++) {\n      threads[i].join();\n    }\n\n    // w.optimize();\n    //w.close();    \n\n    for (int i=0; i<threads.length; i++) {\n      IndexingThread th = threads[i];\n      synchronized(th) {\n        docs.putAll(th.docs);\n      }\n    }\n\n    _TestUtil.checkIndex(dir);\n    DocsAndWriter dw = new DocsAndWriter();\n    dw.docs = docs;\n    dw.writer = w;\n    return dw;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"84080a7d7dbdaa3e6a4a1c9f1bb6221be40f47e8":["e52fea2c4081a1e552b98506691990be59503168"],"fe0932c1d340f83fb0a611e5829b3046a1cc1152":["e450c7d50c2fc84c963d0d7ade9d3217d868064d"],"55f083e91bb056b57de136da1dfc3b9b6ecc4ef6":["fe0932c1d340f83fb0a611e5829b3046a1cc1152"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"1cedb00d2dd44640194401179358a2e3ba6051bf":["55f083e91bb056b57de136da1dfc3b9b6ecc4ef6"],"c4ff8864209d2e972cb4393600c26082f9a6533d":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"e52fea2c4081a1e552b98506691990be59503168":["1cedb00d2dd44640194401179358a2e3ba6051bf"],"87c966e9308847938a7c905c2e46a56d8df788b8":["c4ff8864209d2e972cb4393600c26082f9a6533d"],"e450c7d50c2fc84c963d0d7ade9d3217d868064d":["87c966e9308847938a7c905c2e46a56d8df788b8"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["84080a7d7dbdaa3e6a4a1c9f1bb6221be40f47e8"]},"commit2Childs":{"84080a7d7dbdaa3e6a4a1c9f1bb6221be40f47e8":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"fe0932c1d340f83fb0a611e5829b3046a1cc1152":["55f083e91bb056b57de136da1dfc3b9b6ecc4ef6"],"55f083e91bb056b57de136da1dfc3b9b6ecc4ef6":["1cedb00d2dd44640194401179358a2e3ba6051bf"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["c4ff8864209d2e972cb4393600c26082f9a6533d"],"1cedb00d2dd44640194401179358a2e3ba6051bf":["e52fea2c4081a1e552b98506691990be59503168"],"c4ff8864209d2e972cb4393600c26082f9a6533d":["87c966e9308847938a7c905c2e46a56d8df788b8"],"e52fea2c4081a1e552b98506691990be59503168":["84080a7d7dbdaa3e6a4a1c9f1bb6221be40f47e8"],"87c966e9308847938a7c905c2e46a56d8df788b8":["e450c7d50c2fc84c963d0d7ade9d3217d868064d"],"e450c7d50c2fc84c963d0d7ade9d3217d868064d":["fe0932c1d340f83fb0a611e5829b3046a1cc1152"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"9454a6510e2db155fb01faa5c049b06ece95fab9":["cd5edd1f2b162a5cfa08efd17851a07373a96817"]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}