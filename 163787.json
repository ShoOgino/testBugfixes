{"path":"lucene/codecs/src/test/org/apache/lucene/codecs/block/TestBlockPostingsFormat3#test().mjava","commits":[{"id":"746d604154f8744382434608bf4f14fd4892ae36","date":1349102351,"type":0,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/codecs/src/test/org/apache/lucene/codecs/block/TestBlockPostingsFormat3#test().mjava","pathOld":"/dev/null","sourceNew":"  // creates 6 fields with different options and does \"duels\" of fields against each other\n  public void test() throws Exception {\n    Directory dir = newDirectory();\n    Analyzer analyzer = new Analyzer(new Analyzer.PerFieldReuseStrategy()) {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName, Reader reader) {\n        Tokenizer tokenizer = new MockTokenizer(reader);\n        if (fieldName.contains(\"payloadsFixed\")) {\n          TokenFilter filter = new MockFixedLengthPayloadFilter(new Random(0), tokenizer, 1);\n          return new TokenStreamComponents(tokenizer, filter);\n        } else if (fieldName.contains(\"payloadsVariable\")) {\n          TokenFilter filter = new MockVariableLengthPayloadFilter(new Random(0), tokenizer);\n          return new TokenStreamComponents(tokenizer, filter);\n        } else {\n          return new TokenStreamComponents(tokenizer);\n        }\n      }\n    };\n    IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n    iwc.setCodec(new Lucene40Codec() {\n      @Override\n      public PostingsFormat getPostingsFormatForField(String field) {\n        return PostingsFormat.forName(\"Block\");\n        // TODO: we could actually add more fields implemented with different PFs\n      }\n    });\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n    Document doc = new Document();\n    FieldType bareType = new FieldType(TextField.TYPE_NOT_STORED);\n    // turn these on for a cross-check\n    bareType.setStoreTermVectors(true);\n    bareType.setStoreTermVectorPositions(true);\n    bareType.setStoreTermVectorOffsets(true);\n    bareType.setStoreTermVectorPayloads(true);\n    FieldType offsetsType = new FieldType(bareType);\n    offsetsType.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    Field field1 = new Field(\"field1bare\", \"\", bareType);\n    Field field2 = new Field(\"field2offsets\", \"\", offsetsType);\n    Field field3 = new Field(\"field3payloadsFixed\", \"\", bareType);\n    Field field4 = new Field(\"field4payloadsVariable\", \"\", bareType);\n    Field field5 = new Field(\"field5payloadsFixedOffsets\", \"\", offsetsType);\n    Field field6 = new Field(\"field6payloadsVariableOffsets\", \"\", offsetsType);\n    doc.add(field1);\n    doc.add(field2);\n    doc.add(field3);\n    doc.add(field4);\n    doc.add(field5);\n    doc.add(field6);\n    for (int i = 0; i < MAXDOC; i++) {\n      String stringValue = Integer.toString(i) + \" verycommon \" + English.intToEnglish(i).replace('-', ' ') + \" \" + _TestUtil.randomSimpleString(random());\n      field1.setStringValue(stringValue);\n      field2.setStringValue(stringValue);\n      field3.setStringValue(stringValue);\n      field4.setStringValue(stringValue);\n      field5.setStringValue(stringValue);\n      field6.setStringValue(stringValue);\n      iw.addDocument(doc);\n    }\n    iw.close();\n    verify(dir);\n    _TestUtil.checkIndex(dir); // for some extra coverage, checkIndex before we forceMerge\n    iwc.setOpenMode(OpenMode.APPEND);\n    IndexWriter iw2 = new IndexWriter(dir, iwc);\n    iw2.forceMerge(1);\n    iw2.close();\n    verify(dir);\n    dir.close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["4ce24aa081e44190692bbebc8aead342ad7060e8","4ce24aa081e44190692bbebc8aead342ad7060e8","4ce24aa081e44190692bbebc8aead342ad7060e8"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"cf8086c7e11dc41303ef1b8050bd355ddfaee76d","date":1350007219,"type":5,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/lucene41/TestBlockPostingsFormat3#test().mjava","pathOld":"lucene/codecs/src/test/org/apache/lucene/codecs/block/TestBlockPostingsFormat3#test().mjava","sourceNew":"  // creates 6 fields with different options and does \"duels\" of fields against each other\n  public void test() throws Exception {\n    Directory dir = newDirectory();\n    Analyzer analyzer = new Analyzer(new Analyzer.PerFieldReuseStrategy()) {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName, Reader reader) {\n        Tokenizer tokenizer = new MockTokenizer(reader);\n        if (fieldName.contains(\"payloadsFixed\")) {\n          TokenFilter filter = new MockFixedLengthPayloadFilter(new Random(0), tokenizer, 1);\n          return new TokenStreamComponents(tokenizer, filter);\n        } else if (fieldName.contains(\"payloadsVariable\")) {\n          TokenFilter filter = new MockVariableLengthPayloadFilter(new Random(0), tokenizer);\n          return new TokenStreamComponents(tokenizer, filter);\n        } else {\n          return new TokenStreamComponents(tokenizer);\n        }\n      }\n    };\n    IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n    iwc.setCodec(new Lucene41Codec() {\n      @Override\n      public PostingsFormat getPostingsFormatForField(String field) {\n        return PostingsFormat.forName(\"Lucene41\");\n        // TODO: we could actually add more fields implemented with different PFs\n      }\n    });\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n    Document doc = new Document();\n    FieldType bareType = new FieldType(TextField.TYPE_NOT_STORED);\n    // turn these on for a cross-check\n    bareType.setStoreTermVectors(true);\n    bareType.setStoreTermVectorPositions(true);\n    bareType.setStoreTermVectorOffsets(true);\n    bareType.setStoreTermVectorPayloads(true);\n    FieldType offsetsType = new FieldType(bareType);\n    offsetsType.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    Field field1 = new Field(\"field1bare\", \"\", bareType);\n    Field field2 = new Field(\"field2offsets\", \"\", offsetsType);\n    Field field3 = new Field(\"field3payloadsFixed\", \"\", bareType);\n    Field field4 = new Field(\"field4payloadsVariable\", \"\", bareType);\n    Field field5 = new Field(\"field5payloadsFixedOffsets\", \"\", offsetsType);\n    Field field6 = new Field(\"field6payloadsVariableOffsets\", \"\", offsetsType);\n    doc.add(field1);\n    doc.add(field2);\n    doc.add(field3);\n    doc.add(field4);\n    doc.add(field5);\n    doc.add(field6);\n    for (int i = 0; i < MAXDOC; i++) {\n      String stringValue = Integer.toString(i) + \" verycommon \" + English.intToEnglish(i).replace('-', ' ') + \" \" + _TestUtil.randomSimpleString(random());\n      field1.setStringValue(stringValue);\n      field2.setStringValue(stringValue);\n      field3.setStringValue(stringValue);\n      field4.setStringValue(stringValue);\n      field5.setStringValue(stringValue);\n      field6.setStringValue(stringValue);\n      iw.addDocument(doc);\n    }\n    iw.close();\n    verify(dir);\n    _TestUtil.checkIndex(dir); // for some extra coverage, checkIndex before we forceMerge\n    iwc.setOpenMode(OpenMode.APPEND);\n    IndexWriter iw2 = new IndexWriter(dir, iwc);\n    iw2.forceMerge(1);\n    iw2.close();\n    verify(dir);\n    dir.close();\n  }\n\n","sourceOld":"  // creates 6 fields with different options and does \"duels\" of fields against each other\n  public void test() throws Exception {\n    Directory dir = newDirectory();\n    Analyzer analyzer = new Analyzer(new Analyzer.PerFieldReuseStrategy()) {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName, Reader reader) {\n        Tokenizer tokenizer = new MockTokenizer(reader);\n        if (fieldName.contains(\"payloadsFixed\")) {\n          TokenFilter filter = new MockFixedLengthPayloadFilter(new Random(0), tokenizer, 1);\n          return new TokenStreamComponents(tokenizer, filter);\n        } else if (fieldName.contains(\"payloadsVariable\")) {\n          TokenFilter filter = new MockVariableLengthPayloadFilter(new Random(0), tokenizer);\n          return new TokenStreamComponents(tokenizer, filter);\n        } else {\n          return new TokenStreamComponents(tokenizer);\n        }\n      }\n    };\n    IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n    iwc.setCodec(new Lucene40Codec() {\n      @Override\n      public PostingsFormat getPostingsFormatForField(String field) {\n        return PostingsFormat.forName(\"Block\");\n        // TODO: we could actually add more fields implemented with different PFs\n      }\n    });\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n    Document doc = new Document();\n    FieldType bareType = new FieldType(TextField.TYPE_NOT_STORED);\n    // turn these on for a cross-check\n    bareType.setStoreTermVectors(true);\n    bareType.setStoreTermVectorPositions(true);\n    bareType.setStoreTermVectorOffsets(true);\n    bareType.setStoreTermVectorPayloads(true);\n    FieldType offsetsType = new FieldType(bareType);\n    offsetsType.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    Field field1 = new Field(\"field1bare\", \"\", bareType);\n    Field field2 = new Field(\"field2offsets\", \"\", offsetsType);\n    Field field3 = new Field(\"field3payloadsFixed\", \"\", bareType);\n    Field field4 = new Field(\"field4payloadsVariable\", \"\", bareType);\n    Field field5 = new Field(\"field5payloadsFixedOffsets\", \"\", offsetsType);\n    Field field6 = new Field(\"field6payloadsVariableOffsets\", \"\", offsetsType);\n    doc.add(field1);\n    doc.add(field2);\n    doc.add(field3);\n    doc.add(field4);\n    doc.add(field5);\n    doc.add(field6);\n    for (int i = 0; i < MAXDOC; i++) {\n      String stringValue = Integer.toString(i) + \" verycommon \" + English.intToEnglish(i).replace('-', ' ') + \" \" + _TestUtil.randomSimpleString(random());\n      field1.setStringValue(stringValue);\n      field2.setStringValue(stringValue);\n      field3.setStringValue(stringValue);\n      field4.setStringValue(stringValue);\n      field5.setStringValue(stringValue);\n      field6.setStringValue(stringValue);\n      iw.addDocument(doc);\n    }\n    iw.close();\n    verify(dir);\n    _TestUtil.checkIndex(dir); // for some extra coverage, checkIndex before we forceMerge\n    iwc.setOpenMode(OpenMode.APPEND);\n    IndexWriter iw2 = new IndexWriter(dir, iwc);\n    iw2.forceMerge(1);\n    iw2.close();\n    verify(dir);\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"c7492bcb52be51e55d596134b95b2e53cc4ffb91","date":1350223278,"type":5,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/lucene41/TestBlockPostingsFormat3#test().mjava","pathOld":"lucene/codecs/src/test/org/apache/lucene/codecs/block/TestBlockPostingsFormat3#test().mjava","sourceNew":"  // creates 6 fields with different options and does \"duels\" of fields against each other\n  public void test() throws Exception {\n    Directory dir = newDirectory();\n    Analyzer analyzer = new Analyzer(new Analyzer.PerFieldReuseStrategy()) {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName, Reader reader) {\n        Tokenizer tokenizer = new MockTokenizer(reader);\n        if (fieldName.contains(\"payloadsFixed\")) {\n          TokenFilter filter = new MockFixedLengthPayloadFilter(new Random(0), tokenizer, 1);\n          return new TokenStreamComponents(tokenizer, filter);\n        } else if (fieldName.contains(\"payloadsVariable\")) {\n          TokenFilter filter = new MockVariableLengthPayloadFilter(new Random(0), tokenizer);\n          return new TokenStreamComponents(tokenizer, filter);\n        } else {\n          return new TokenStreamComponents(tokenizer);\n        }\n      }\n    };\n    IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n    iwc.setCodec(new Lucene41Codec() {\n      @Override\n      public PostingsFormat getPostingsFormatForField(String field) {\n        return PostingsFormat.forName(\"Lucene41\");\n        // TODO: we could actually add more fields implemented with different PFs\n      }\n    });\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n    Document doc = new Document();\n    FieldType bareType = new FieldType(TextField.TYPE_NOT_STORED);\n    // turn these on for a cross-check\n    bareType.setStoreTermVectors(true);\n    bareType.setStoreTermVectorPositions(true);\n    bareType.setStoreTermVectorOffsets(true);\n    bareType.setStoreTermVectorPayloads(true);\n    FieldType offsetsType = new FieldType(bareType);\n    offsetsType.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    Field field1 = new Field(\"field1bare\", \"\", bareType);\n    Field field2 = new Field(\"field2offsets\", \"\", offsetsType);\n    Field field3 = new Field(\"field3payloadsFixed\", \"\", bareType);\n    Field field4 = new Field(\"field4payloadsVariable\", \"\", bareType);\n    Field field5 = new Field(\"field5payloadsFixedOffsets\", \"\", offsetsType);\n    Field field6 = new Field(\"field6payloadsVariableOffsets\", \"\", offsetsType);\n    doc.add(field1);\n    doc.add(field2);\n    doc.add(field3);\n    doc.add(field4);\n    doc.add(field5);\n    doc.add(field6);\n    for (int i = 0; i < MAXDOC; i++) {\n      String stringValue = Integer.toString(i) + \" verycommon \" + English.intToEnglish(i).replace('-', ' ') + \" \" + _TestUtil.randomSimpleString(random());\n      field1.setStringValue(stringValue);\n      field2.setStringValue(stringValue);\n      field3.setStringValue(stringValue);\n      field4.setStringValue(stringValue);\n      field5.setStringValue(stringValue);\n      field6.setStringValue(stringValue);\n      iw.addDocument(doc);\n    }\n    iw.close();\n    verify(dir);\n    _TestUtil.checkIndex(dir); // for some extra coverage, checkIndex before we forceMerge\n    iwc.setOpenMode(OpenMode.APPEND);\n    IndexWriter iw2 = new IndexWriter(dir, iwc);\n    iw2.forceMerge(1);\n    iw2.close();\n    verify(dir);\n    dir.close();\n  }\n\n","sourceOld":"  // creates 6 fields with different options and does \"duels\" of fields against each other\n  public void test() throws Exception {\n    Directory dir = newDirectory();\n    Analyzer analyzer = new Analyzer(new Analyzer.PerFieldReuseStrategy()) {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName, Reader reader) {\n        Tokenizer tokenizer = new MockTokenizer(reader);\n        if (fieldName.contains(\"payloadsFixed\")) {\n          TokenFilter filter = new MockFixedLengthPayloadFilter(new Random(0), tokenizer, 1);\n          return new TokenStreamComponents(tokenizer, filter);\n        } else if (fieldName.contains(\"payloadsVariable\")) {\n          TokenFilter filter = new MockVariableLengthPayloadFilter(new Random(0), tokenizer);\n          return new TokenStreamComponents(tokenizer, filter);\n        } else {\n          return new TokenStreamComponents(tokenizer);\n        }\n      }\n    };\n    IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n    iwc.setCodec(new Lucene40Codec() {\n      @Override\n      public PostingsFormat getPostingsFormatForField(String field) {\n        return PostingsFormat.forName(\"Block\");\n        // TODO: we could actually add more fields implemented with different PFs\n      }\n    });\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n    Document doc = new Document();\n    FieldType bareType = new FieldType(TextField.TYPE_NOT_STORED);\n    // turn these on for a cross-check\n    bareType.setStoreTermVectors(true);\n    bareType.setStoreTermVectorPositions(true);\n    bareType.setStoreTermVectorOffsets(true);\n    bareType.setStoreTermVectorPayloads(true);\n    FieldType offsetsType = new FieldType(bareType);\n    offsetsType.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    Field field1 = new Field(\"field1bare\", \"\", bareType);\n    Field field2 = new Field(\"field2offsets\", \"\", offsetsType);\n    Field field3 = new Field(\"field3payloadsFixed\", \"\", bareType);\n    Field field4 = new Field(\"field4payloadsVariable\", \"\", bareType);\n    Field field5 = new Field(\"field5payloadsFixedOffsets\", \"\", offsetsType);\n    Field field6 = new Field(\"field6payloadsVariableOffsets\", \"\", offsetsType);\n    doc.add(field1);\n    doc.add(field2);\n    doc.add(field3);\n    doc.add(field4);\n    doc.add(field5);\n    doc.add(field6);\n    for (int i = 0; i < MAXDOC; i++) {\n      String stringValue = Integer.toString(i) + \" verycommon \" + English.intToEnglish(i).replace('-', ' ') + \" \" + _TestUtil.randomSimpleString(random());\n      field1.setStringValue(stringValue);\n      field2.setStringValue(stringValue);\n      field3.setStringValue(stringValue);\n      field4.setStringValue(stringValue);\n      field5.setStringValue(stringValue);\n      field6.setStringValue(stringValue);\n      iw.addDocument(doc);\n    }\n    iw.close();\n    verify(dir);\n    _TestUtil.checkIndex(dir); // for some extra coverage, checkIndex before we forceMerge\n    iwc.setOpenMode(OpenMode.APPEND);\n    IndexWriter iw2 = new IndexWriter(dir, iwc);\n    iw2.forceMerge(1);\n    iw2.close();\n    verify(dir);\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"db4fdbf3d262768eabc027cd8321edca0cd11fa8","date":1350574784,"type":5,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/lucene41/TestBlockPostingsFormat3#test().mjava","pathOld":"lucene/codecs/src/test/org/apache/lucene/codecs/block/TestBlockPostingsFormat3#test().mjava","sourceNew":"  // creates 6 fields with different options and does \"duels\" of fields against each other\n  public void test() throws Exception {\n    Directory dir = newDirectory();\n    Analyzer analyzer = new Analyzer(new Analyzer.PerFieldReuseStrategy()) {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName, Reader reader) {\n        Tokenizer tokenizer = new MockTokenizer(reader);\n        if (fieldName.contains(\"payloadsFixed\")) {\n          TokenFilter filter = new MockFixedLengthPayloadFilter(new Random(0), tokenizer, 1);\n          return new TokenStreamComponents(tokenizer, filter);\n        } else if (fieldName.contains(\"payloadsVariable\")) {\n          TokenFilter filter = new MockVariableLengthPayloadFilter(new Random(0), tokenizer);\n          return new TokenStreamComponents(tokenizer, filter);\n        } else {\n          return new TokenStreamComponents(tokenizer);\n        }\n      }\n    };\n    IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n    iwc.setCodec(new Lucene41Codec() {\n      @Override\n      public PostingsFormat getPostingsFormatForField(String field) {\n        return PostingsFormat.forName(\"Lucene41\");\n        // TODO: we could actually add more fields implemented with different PFs\n      }\n    });\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n    Document doc = new Document();\n    FieldType bareType = new FieldType(TextField.TYPE_NOT_STORED);\n    // turn these on for a cross-check\n    bareType.setStoreTermVectors(true);\n    bareType.setStoreTermVectorPositions(true);\n    bareType.setStoreTermVectorOffsets(true);\n    bareType.setStoreTermVectorPayloads(true);\n    FieldType offsetsType = new FieldType(bareType);\n    offsetsType.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    Field field1 = new Field(\"field1bare\", \"\", bareType);\n    Field field2 = new Field(\"field2offsets\", \"\", offsetsType);\n    Field field3 = new Field(\"field3payloadsFixed\", \"\", bareType);\n    Field field4 = new Field(\"field4payloadsVariable\", \"\", bareType);\n    Field field5 = new Field(\"field5payloadsFixedOffsets\", \"\", offsetsType);\n    Field field6 = new Field(\"field6payloadsVariableOffsets\", \"\", offsetsType);\n    doc.add(field1);\n    doc.add(field2);\n    doc.add(field3);\n    doc.add(field4);\n    doc.add(field5);\n    doc.add(field6);\n    for (int i = 0; i < MAXDOC; i++) {\n      String stringValue = Integer.toString(i) + \" verycommon \" + English.intToEnglish(i).replace('-', ' ') + \" \" + _TestUtil.randomSimpleString(random());\n      field1.setStringValue(stringValue);\n      field2.setStringValue(stringValue);\n      field3.setStringValue(stringValue);\n      field4.setStringValue(stringValue);\n      field5.setStringValue(stringValue);\n      field6.setStringValue(stringValue);\n      iw.addDocument(doc);\n    }\n    iw.close();\n    verify(dir);\n    _TestUtil.checkIndex(dir); // for some extra coverage, checkIndex before we forceMerge\n    iwc.setOpenMode(OpenMode.APPEND);\n    IndexWriter iw2 = new IndexWriter(dir, iwc);\n    iw2.forceMerge(1);\n    iw2.close();\n    verify(dir);\n    dir.close();\n  }\n\n","sourceOld":"  // creates 6 fields with different options and does \"duels\" of fields against each other\n  public void test() throws Exception {\n    Directory dir = newDirectory();\n    Analyzer analyzer = new Analyzer(new Analyzer.PerFieldReuseStrategy()) {\n      @Override\n      protected TokenStreamComponents createComponents(String fieldName, Reader reader) {\n        Tokenizer tokenizer = new MockTokenizer(reader);\n        if (fieldName.contains(\"payloadsFixed\")) {\n          TokenFilter filter = new MockFixedLengthPayloadFilter(new Random(0), tokenizer, 1);\n          return new TokenStreamComponents(tokenizer, filter);\n        } else if (fieldName.contains(\"payloadsVariable\")) {\n          TokenFilter filter = new MockVariableLengthPayloadFilter(new Random(0), tokenizer);\n          return new TokenStreamComponents(tokenizer, filter);\n        } else {\n          return new TokenStreamComponents(tokenizer);\n        }\n      }\n    };\n    IndexWriterConfig iwc = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n    iwc.setCodec(new Lucene40Codec() {\n      @Override\n      public PostingsFormat getPostingsFormatForField(String field) {\n        return PostingsFormat.forName(\"Block\");\n        // TODO: we could actually add more fields implemented with different PFs\n      }\n    });\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n    Document doc = new Document();\n    FieldType bareType = new FieldType(TextField.TYPE_NOT_STORED);\n    // turn these on for a cross-check\n    bareType.setStoreTermVectors(true);\n    bareType.setStoreTermVectorPositions(true);\n    bareType.setStoreTermVectorOffsets(true);\n    bareType.setStoreTermVectorPayloads(true);\n    FieldType offsetsType = new FieldType(bareType);\n    offsetsType.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    Field field1 = new Field(\"field1bare\", \"\", bareType);\n    Field field2 = new Field(\"field2offsets\", \"\", offsetsType);\n    Field field3 = new Field(\"field3payloadsFixed\", \"\", bareType);\n    Field field4 = new Field(\"field4payloadsVariable\", \"\", bareType);\n    Field field5 = new Field(\"field5payloadsFixedOffsets\", \"\", offsetsType);\n    Field field6 = new Field(\"field6payloadsVariableOffsets\", \"\", offsetsType);\n    doc.add(field1);\n    doc.add(field2);\n    doc.add(field3);\n    doc.add(field4);\n    doc.add(field5);\n    doc.add(field6);\n    for (int i = 0; i < MAXDOC; i++) {\n      String stringValue = Integer.toString(i) + \" verycommon \" + English.intToEnglish(i).replace('-', ' ') + \" \" + _TestUtil.randomSimpleString(random());\n      field1.setStringValue(stringValue);\n      field2.setStringValue(stringValue);\n      field3.setStringValue(stringValue);\n      field4.setStringValue(stringValue);\n      field5.setStringValue(stringValue);\n      field6.setStringValue(stringValue);\n      iw.addDocument(doc);\n    }\n    iw.close();\n    verify(dir);\n    _TestUtil.checkIndex(dir); // for some extra coverage, checkIndex before we forceMerge\n    iwc.setOpenMode(OpenMode.APPEND);\n    IndexWriter iw2 = new IndexWriter(dir, iwc);\n    iw2.forceMerge(1);\n    iw2.close();\n    verify(dir);\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"c7492bcb52be51e55d596134b95b2e53cc4ffb91":["746d604154f8744382434608bf4f14fd4892ae36","cf8086c7e11dc41303ef1b8050bd355ddfaee76d"],"cf8086c7e11dc41303ef1b8050bd355ddfaee76d":["746d604154f8744382434608bf4f14fd4892ae36"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"db4fdbf3d262768eabc027cd8321edca0cd11fa8":["746d604154f8744382434608bf4f14fd4892ae36","c7492bcb52be51e55d596134b95b2e53cc4ffb91"],"746d604154f8744382434608bf4f14fd4892ae36":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["c7492bcb52be51e55d596134b95b2e53cc4ffb91"]},"commit2Childs":{"c7492bcb52be51e55d596134b95b2e53cc4ffb91":["db4fdbf3d262768eabc027cd8321edca0cd11fa8","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"cf8086c7e11dc41303ef1b8050bd355ddfaee76d":["c7492bcb52be51e55d596134b95b2e53cc4ffb91"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["746d604154f8744382434608bf4f14fd4892ae36"],"db4fdbf3d262768eabc027cd8321edca0cd11fa8":[],"746d604154f8744382434608bf4f14fd4892ae36":["c7492bcb52be51e55d596134b95b2e53cc4ffb91","cf8086c7e11dc41303ef1b8050bd355ddfaee76d","db4fdbf3d262768eabc027cd8321edca0cd11fa8"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["db4fdbf3d262768eabc027cd8321edca0cd11fa8","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}