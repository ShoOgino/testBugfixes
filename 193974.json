{"path":"lucene/analysis/common/src/java/org/apache/lucene/analysis/synonym/SynonymMap.Parser#analyze(String,CharsRef).mjava","commits":[{"id":"85f3a2d749715373feb8529516e92d3538103525","date":1379624134,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/synonym/SynonymMap.Parser#analyze(String,CharsRef).mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/synonym/SynonymMap.Builder#analyze(Analyzer,String,CharsRef).mjava","sourceNew":"    /** Sugar: analyzes the text with the analyzer and\n     *  separates by {@link SynonymMap#WORD_SEPARATOR}.\n     *  reuse and its chars must not be null. */\n    public CharsRef analyze(String text, CharsRef reuse) throws IOException {\n      TokenStream ts = analyzer.tokenStream(\"\", text);\n      CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n      PositionIncrementAttribute posIncAtt = ts.addAttribute(PositionIncrementAttribute.class);\n      ts.reset();\n      reuse.length = 0;\n      while (ts.incrementToken()) {\n        int length = termAtt.length();\n        if (length == 0) {\n          throw new IllegalArgumentException(\"term: \" + text + \" analyzed to a zero-length token\");\n        }\n        if (posIncAtt.getPositionIncrement() != 1) {\n          throw new IllegalArgumentException(\"term: \" + text + \" analyzed to a token with posinc != 1\");\n        }\n        reuse.grow(reuse.length + length + 1); /* current + word + separator */\n        int end = reuse.offset + reuse.length;\n        if (reuse.length > 0) {\n          reuse.chars[end++] = SynonymMap.WORD_SEPARATOR;\n          reuse.length++;\n        }\n        System.arraycopy(termAtt.buffer(), 0, reuse.chars, end, length);\n        reuse.length += length;\n      }\n      ts.end();\n      ts.close();\n      if (reuse.length == 0) {\n        throw new IllegalArgumentException(\"term: \" + text + \" was completely eliminated by analyzer\");\n      }\n      return reuse;\n    }\n\n","sourceOld":"    /** Sugar: analyzes the text with the analyzer and\n     *  separates by {@link SynonymMap#WORD_SEPARATOR}.\n     *  reuse and its chars must not be null. */\n    public static CharsRef analyze(Analyzer analyzer, String text, CharsRef reuse) throws IOException {\n      TokenStream ts = analyzer.tokenStream(\"\", text);\n      CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n      PositionIncrementAttribute posIncAtt = ts.addAttribute(PositionIncrementAttribute.class);\n      ts.reset();\n      reuse.length = 0;\n      while (ts.incrementToken()) {\n        int length = termAtt.length();\n        if (length == 0) {\n          throw new IllegalArgumentException(\"term: \" + text + \" analyzed to a zero-length token\");\n        }\n        if (posIncAtt.getPositionIncrement() != 1) {\n          throw new IllegalArgumentException(\"term: \" + text + \" analyzed to a token with posinc != 1\");\n        }\n        reuse.grow(reuse.length + length + 1); /* current + word + separator */\n        int end = reuse.offset + reuse.length;\n        if (reuse.length > 0) {\n          reuse.chars[end++] = SynonymMap.WORD_SEPARATOR;\n          reuse.length++;\n        }\n        System.arraycopy(termAtt.buffer(), 0, reuse.chars, end, length);\n        reuse.length += length;\n      }\n      ts.end();\n      ts.close();\n      if (reuse.length == 0) {\n        throw new IllegalArgumentException(\"term: \" + text + \" was completely eliminated by analyzer\");\n      }\n      return reuse;\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"782ed6a4b4ba50ec19734fc8db4e570ee193d627","date":1381127065,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/synonym/SynonymMap.Parser#analyze(String,CharsRef).mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/synonym/SynonymMap.Parser#analyze(String,CharsRef).mjava","sourceNew":"    /** Sugar: analyzes the text with the analyzer and\n     *  separates by {@link SynonymMap#WORD_SEPARATOR}.\n     *  reuse and its chars must not be null. */\n    public CharsRef analyze(String text, CharsRef reuse) throws IOException {\n      try (TokenStream ts = analyzer.tokenStream(\"\", text)) {\n        CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n        PositionIncrementAttribute posIncAtt = ts.addAttribute(PositionIncrementAttribute.class);\n        ts.reset();\n        reuse.length = 0;\n        while (ts.incrementToken()) {\n          int length = termAtt.length();\n          if (length == 0) {\n            throw new IllegalArgumentException(\"term: \" + text + \" analyzed to a zero-length token\");\n          }\n          if (posIncAtt.getPositionIncrement() != 1) {\n            throw new IllegalArgumentException(\"term: \" + text + \" analyzed to a token with posinc != 1\");\n          }\n          reuse.grow(reuse.length + length + 1); /* current + word + separator */\n          int end = reuse.offset + reuse.length;\n          if (reuse.length > 0) {\n            reuse.chars[end++] = SynonymMap.WORD_SEPARATOR;\n            reuse.length++;\n          }\n          System.arraycopy(termAtt.buffer(), 0, reuse.chars, end, length);\n          reuse.length += length;\n        }\n        ts.end();\n      }\n      if (reuse.length == 0) {\n        throw new IllegalArgumentException(\"term: \" + text + \" was completely eliminated by analyzer\");\n      }\n      return reuse;\n    }\n\n","sourceOld":"    /** Sugar: analyzes the text with the analyzer and\n     *  separates by {@link SynonymMap#WORD_SEPARATOR}.\n     *  reuse and its chars must not be null. */\n    public CharsRef analyze(String text, CharsRef reuse) throws IOException {\n      TokenStream ts = analyzer.tokenStream(\"\", text);\n      CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n      PositionIncrementAttribute posIncAtt = ts.addAttribute(PositionIncrementAttribute.class);\n      ts.reset();\n      reuse.length = 0;\n      while (ts.incrementToken()) {\n        int length = termAtt.length();\n        if (length == 0) {\n          throw new IllegalArgumentException(\"term: \" + text + \" analyzed to a zero-length token\");\n        }\n        if (posIncAtt.getPositionIncrement() != 1) {\n          throw new IllegalArgumentException(\"term: \" + text + \" analyzed to a token with posinc != 1\");\n        }\n        reuse.grow(reuse.length + length + 1); /* current + word + separator */\n        int end = reuse.offset + reuse.length;\n        if (reuse.length > 0) {\n          reuse.chars[end++] = SynonymMap.WORD_SEPARATOR;\n          reuse.length++;\n        }\n        System.arraycopy(termAtt.buffer(), 0, reuse.chars, end, length);\n        reuse.length += length;\n      }\n      ts.end();\n      ts.close();\n      if (reuse.length == 0) {\n        throw new IllegalArgumentException(\"term: \" + text + \" was completely eliminated by analyzer\");\n      }\n      return reuse;\n    }\n\n","bugFix":["44d6f0ab53c1962856b9f48dedb7a2a6cc18905c","c83d6c4335f31cae14f625a222bc842f20073dcd"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7dc6ea5fd38ce7aa8f36b3bac8b757da77f31d50","date":1407854805,"type":5,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/synonym/SynonymMap.Parser#analyze(String,CharsRefBuilder).mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/synonym/SynonymMap.Parser#analyze(String,CharsRef).mjava","sourceNew":"    /** Sugar: analyzes the text with the analyzer and\n     *  separates by {@link SynonymMap#WORD_SEPARATOR}.\n     *  reuse and its chars must not be null. */\n    public CharsRef analyze(String text, CharsRefBuilder reuse) throws IOException {\n      try (TokenStream ts = analyzer.tokenStream(\"\", text)) {\n        CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n        PositionIncrementAttribute posIncAtt = ts.addAttribute(PositionIncrementAttribute.class);\n        ts.reset();\n        reuse.clear();\n        while (ts.incrementToken()) {\n          int length = termAtt.length();\n          if (length == 0) {\n            throw new IllegalArgumentException(\"term: \" + text + \" analyzed to a zero-length token\");\n          }\n          if (posIncAtt.getPositionIncrement() != 1) {\n            throw new IllegalArgumentException(\"term: \" + text + \" analyzed to a token with posinc != 1\");\n          }\n          reuse.grow(reuse.length() + length + 1); /* current + word + separator */\n          int end = reuse.length();\n          if (reuse.length() > 0) {\n            reuse.setCharAt(end++, SynonymMap.WORD_SEPARATOR);\n            reuse.setLength(reuse.length() + 1);\n          }\n          System.arraycopy(termAtt.buffer(), 0, reuse.chars(), end, length);\n          reuse.setLength(reuse.length() + length);\n        }\n        ts.end();\n      }\n      if (reuse.length() == 0) {\n        throw new IllegalArgumentException(\"term: \" + text + \" was completely eliminated by analyzer\");\n      }\n      return reuse.get();\n    }\n\n","sourceOld":"    /** Sugar: analyzes the text with the analyzer and\n     *  separates by {@link SynonymMap#WORD_SEPARATOR}.\n     *  reuse and its chars must not be null. */\n    public CharsRef analyze(String text, CharsRef reuse) throws IOException {\n      try (TokenStream ts = analyzer.tokenStream(\"\", text)) {\n        CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);\n        PositionIncrementAttribute posIncAtt = ts.addAttribute(PositionIncrementAttribute.class);\n        ts.reset();\n        reuse.length = 0;\n        while (ts.incrementToken()) {\n          int length = termAtt.length();\n          if (length == 0) {\n            throw new IllegalArgumentException(\"term: \" + text + \" analyzed to a zero-length token\");\n          }\n          if (posIncAtt.getPositionIncrement() != 1) {\n            throw new IllegalArgumentException(\"term: \" + text + \" analyzed to a token with posinc != 1\");\n          }\n          reuse.grow(reuse.length + length + 1); /* current + word + separator */\n          int end = reuse.offset + reuse.length;\n          if (reuse.length > 0) {\n            reuse.chars[end++] = SynonymMap.WORD_SEPARATOR;\n            reuse.length++;\n          }\n          System.arraycopy(termAtt.buffer(), 0, reuse.chars, end, length);\n          reuse.length += length;\n        }\n        ts.end();\n      }\n      if (reuse.length == 0) {\n        throw new IllegalArgumentException(\"term: \" + text + \" was completely eliminated by analyzer\");\n      }\n      return reuse;\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"7dc6ea5fd38ce7aa8f36b3bac8b757da77f31d50":["782ed6a4b4ba50ec19734fc8db4e570ee193d627"],"782ed6a4b4ba50ec19734fc8db4e570ee193d627":["85f3a2d749715373feb8529516e92d3538103525"],"85f3a2d749715373feb8529516e92d3538103525":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["7dc6ea5fd38ce7aa8f36b3bac8b757da77f31d50"]},"commit2Childs":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["85f3a2d749715373feb8529516e92d3538103525"],"7dc6ea5fd38ce7aa8f36b3bac8b757da77f31d50":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"782ed6a4b4ba50ec19734fc8db4e570ee193d627":["7dc6ea5fd38ce7aa8f36b3bac8b757da77f31d50"],"85f3a2d749715373feb8529516e92d3538103525":["782ed6a4b4ba50ec19734fc8db4e570ee193d627"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}