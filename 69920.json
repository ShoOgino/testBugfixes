{"path":"contrib/ant/src/main/org/apache/lucene/ant/IndexTask#indexDocs().mjava","commits":[{"id":"043c298cb215f13ba7b9b81d20760704e8f93d66","date":1107566743,"type":1,"author":"Erik Hatcher","isMerge":false,"pathNew":"contrib/ant/src/main/org/apache/lucene/ant/IndexTask#indexDocs().mjava","pathOld":"sandbox/contributions/ant/src/main/org/apache/lucene/ant/IndexTask#indexDocs().mjava","sourceNew":"  /**\n   * Index the fileset.\n   *\n   *@exception  IOException if Lucene I/O exception\n   *@todo refactor!!!!!\n   */\n  private void indexDocs() throws IOException {\n    Date start = new Date();\n\n    boolean create = overwrite;\n    // If the index directory doesn't exist,\n    // create it and force create mode\n    if (indexDir.mkdirs() && !overwrite) {\n      create = true;\n    }\n\n    Searcher searcher = null;\n    boolean checkLastModified = false;\n    if (!create) {\n      try {\n        searcher = new IndexSearcher(indexDir.getAbsolutePath());\n        checkLastModified = true;\n      } catch (IOException ioe) {\n        log(\"IOException: \" + ioe.getMessage());\n        // Empty - ignore, which indicates to index all\n        // documents\n      }\n    }\n\n    log(\"checkLastModified = \" + checkLastModified, Project.MSG_VERBOSE);\n\n    IndexWriter writer =\n      new IndexWriter(indexDir, analyzer, create);\n\n    writer.setUseCompoundFile(useCompoundIndex);\n    int totalFiles = 0;\n    int totalIndexed = 0;\n    int totalIgnored = 0;\n    try {\n      writer.mergeFactor = mergeFactor;\n\n      for (int i = 0; i < filesets.size(); i++) {\n        FileSet fs = (FileSet) filesets.get(i);\n        if (fs != null) {\n          DirectoryScanner ds =\n            fs.getDirectoryScanner(getProject());\n          String[] dsfiles = ds.getIncludedFiles();\n          File baseDir = ds.getBasedir();\n\n          for (int j = 0; j < dsfiles.length; j++) {\n            File file = new File(baseDir, dsfiles[j]);\n            totalFiles++;\n\n            if (!file.exists() || !file.canRead()) {\n              throw new BuildException(\"File \\\"\" +\n                                       file.getAbsolutePath()\n                                       + \"\\\" does not exist or is not readable.\");\n            }\n\n            boolean indexIt = true;\n\n            if (checkLastModified) {\n              Term pathTerm =\n                new Term(\"path\", file.getPath());\n              TermQuery query =\n                new TermQuery(pathTerm);\n              Hits hits = searcher.search(query);\n\n              // if document is found, compare the\n              // indexed last modified time with the\n              // current file\n              // - don't index if up to date\n              if (hits.length() > 0) {\n                Document doc = hits.doc(0);\n                String indexModified =\n                  doc.get(\"modified\").trim();\n                if (indexModified != null) {\n                  if (DateField.stringToTime(indexModified)\n                    == file.lastModified()) {\n                    // TODO: remove existing document\n                    indexIt = false;\n                  }\n                }\n              }\n            }\n\n            if (indexIt) {\n              try {\n                log(\"Indexing \" + file.getPath(),\n                    Project.MSG_VERBOSE);\n                Document doc =\n                  handler.getDocument(file);\n\n                if (doc == null) {\n                  totalIgnored++;\n                } else {\n                  // Add the path of the file as a field named \"path\".  Use a Keyword field, so\n                  // that the index stores the path, and so that the path is searchable\n                  doc.add(Field.Keyword(\"path\", file.getPath()));\n\n                  // Add the last modified date of the file a field named \"modified\".  Use a\n                  // Keyword field, so that it's searchable, but so that no attempt is made\n                  // to tokenize the field into words.\n                  doc.add(Field.Keyword(\"modified\",\n                                        DateField.timeToString(file.lastModified())));\n\n                  writer.addDocument(doc);\n                  totalIndexed++;\n                }\n              } catch (DocumentHandlerException e) {\n                throw new BuildException(e);\n              }\n            }\n          }\n          // for j\n        }\n        // if (fs != null)\n      }\n      // for i\n\n      writer.optimize();\n    }\n      //try\n    finally {\n      // always make sure everything gets closed,\n      // no matter how we exit.\n      writer.close();\n      if (searcher != null) {\n        searcher.close();\n      }\n    }\n\n    Date end = new Date();\n\n    log(totalIndexed + \" out of \" + totalFiles + \" indexed (\" +\n        totalIgnored + \" ignored) in \" + (end.getTime() - start.getTime()) +\n        \" milliseconds\");\n  }\n\n","sourceOld":"  /**\n   * Index the fileset.\n   *\n   *@exception  IOException if Lucene I/O exception\n   *@todo refactor!!!!!\n   */\n  private void indexDocs() throws IOException {\n    Date start = new Date();\n\n    boolean create = overwrite;\n    // If the index directory doesn't exist,\n    // create it and force create mode\n    if (indexDir.mkdirs() && !overwrite) {\n      create = true;\n    }\n\n    Searcher searcher = null;\n    boolean checkLastModified = false;\n    if (!create) {\n      try {\n        searcher = new IndexSearcher(indexDir.getAbsolutePath());\n        checkLastModified = true;\n      } catch (IOException ioe) {\n        log(\"IOException: \" + ioe.getMessage());\n        // Empty - ignore, which indicates to index all\n        // documents\n      }\n    }\n\n    log(\"checkLastModified = \" + checkLastModified, Project.MSG_VERBOSE);\n\n    IndexWriter writer =\n      new IndexWriter(indexDir, analyzer, create);\n\n    writer.setUseCompoundFile(useCompoundIndex);\n    int totalFiles = 0;\n    int totalIndexed = 0;\n    int totalIgnored = 0;\n    try {\n      writer.mergeFactor = mergeFactor;\n\n      for (int i = 0; i < filesets.size(); i++) {\n        FileSet fs = (FileSet) filesets.get(i);\n        if (fs != null) {\n          DirectoryScanner ds =\n            fs.getDirectoryScanner(getProject());\n          String[] dsfiles = ds.getIncludedFiles();\n          File baseDir = ds.getBasedir();\n\n          for (int j = 0; j < dsfiles.length; j++) {\n            File file = new File(baseDir, dsfiles[j]);\n            totalFiles++;\n\n            if (!file.exists() || !file.canRead()) {\n              throw new BuildException(\"File \\\"\" +\n                                       file.getAbsolutePath()\n                                       + \"\\\" does not exist or is not readable.\");\n            }\n\n            boolean indexIt = true;\n\n            if (checkLastModified) {\n              Term pathTerm =\n                new Term(\"path\", file.getPath());\n              TermQuery query =\n                new TermQuery(pathTerm);\n              Hits hits = searcher.search(query);\n\n              // if document is found, compare the\n              // indexed last modified time with the\n              // current file\n              // - don't index if up to date\n              if (hits.length() > 0) {\n                Document doc = hits.doc(0);\n                String indexModified =\n                  doc.get(\"modified\").trim();\n                if (indexModified != null) {\n                  if (DateField.stringToTime(indexModified)\n                    == file.lastModified()) {\n                    // TODO: remove existing document\n                    indexIt = false;\n                  }\n                }\n              }\n            }\n\n            if (indexIt) {\n              try {\n                log(\"Indexing \" + file.getPath(),\n                    Project.MSG_VERBOSE);\n                Document doc =\n                  handler.getDocument(file);\n\n                if (doc == null) {\n                  totalIgnored++;\n                } else {\n                  // Add the path of the file as a field named \"path\".  Use a Keyword field, so\n                  // that the index stores the path, and so that the path is searchable\n                  doc.add(Field.Keyword(\"path\", file.getPath()));\n\n                  // Add the last modified date of the file a field named \"modified\".  Use a\n                  // Keyword field, so that it's searchable, but so that no attempt is made\n                  // to tokenize the field into words.\n                  doc.add(Field.Keyword(\"modified\",\n                                        DateField.timeToString(file.lastModified())));\n\n                  writer.addDocument(doc);\n                  totalIndexed++;\n                }\n              } catch (DocumentHandlerException e) {\n                throw new BuildException(e);\n              }\n            }\n          }\n          // for j\n        }\n        // if (fs != null)\n      }\n      // for i\n\n      writer.optimize();\n    }\n      //try\n    finally {\n      // always make sure everything gets closed,\n      // no matter how we exit.\n      writer.close();\n      if (searcher != null) {\n        searcher.close();\n      }\n    }\n\n    Date end = new Date();\n\n    log(totalIndexed + \" out of \" + totalFiles + \" indexed (\" +\n        totalIgnored + \" ignored) in \" + (end.getTime() - start.getTime()) +\n        \" milliseconds\");\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1202f7724a155557e02e24b0dc4209f41b2f25ae","date":1107570099,"type":3,"author":"Erik Hatcher","isMerge":false,"pathNew":"contrib/ant/src/main/org/apache/lucene/ant/IndexTask#indexDocs().mjava","pathOld":"contrib/ant/src/main/org/apache/lucene/ant/IndexTask#indexDocs().mjava","sourceNew":"  /**\n   * Index the fileset.\n   *\n   *@exception  IOException if Lucene I/O exception\n   *@todo refactor!!!!!\n   */\n  private void indexDocs() throws IOException {\n    Date start = new Date();\n\n    boolean create = overwrite;\n    // If the index directory doesn't exist,\n    // create it and force create mode\n    if (indexDir.mkdirs() && !overwrite) {\n      create = true;\n    }\n\n    Searcher searcher = null;\n    boolean checkLastModified = false;\n    if (!create) {\n      try {\n        searcher = new IndexSearcher(indexDir.getAbsolutePath());\n        checkLastModified = true;\n      } catch (IOException ioe) {\n        log(\"IOException: \" + ioe.getMessage());\n        // Empty - ignore, which indicates to index all\n        // documents\n      }\n    }\n\n    log(\"checkLastModified = \" + checkLastModified, Project.MSG_VERBOSE);\n\n    IndexWriter writer =\n      new IndexWriter(indexDir, analyzer, create);\n\n    writer.setUseCompoundFile(useCompoundIndex);\n    int totalFiles = 0;\n    int totalIndexed = 0;\n    int totalIgnored = 0;\n    try {\n      writer.setMergeFactor(mergeFactor);\n\n      for (int i = 0; i < filesets.size(); i++) {\n        FileSet fs = (FileSet) filesets.get(i);\n        if (fs != null) {\n          DirectoryScanner ds =\n            fs.getDirectoryScanner(getProject());\n          String[] dsfiles = ds.getIncludedFiles();\n          File baseDir = ds.getBasedir();\n\n          for (int j = 0; j < dsfiles.length; j++) {\n            File file = new File(baseDir, dsfiles[j]);\n            totalFiles++;\n\n            if (!file.exists() || !file.canRead()) {\n              throw new BuildException(\"File \\\"\" +\n                                       file.getAbsolutePath()\n                                       + \"\\\" does not exist or is not readable.\");\n            }\n\n            boolean indexIt = true;\n\n            if (checkLastModified) {\n              Term pathTerm =\n                new Term(\"path\", file.getPath());\n              TermQuery query =\n                new TermQuery(pathTerm);\n              Hits hits = searcher.search(query);\n\n              // if document is found, compare the\n              // indexed last modified time with the\n              // current file\n              // - don't index if up to date\n              if (hits.length() > 0) {\n                Document doc = hits.doc(0);\n                String indexModified =\n                  doc.get(\"modified\").trim();\n                if (indexModified != null) {\n                  if (DateField.stringToTime(indexModified)\n                    == file.lastModified()) {\n                    // TODO: remove existing document\n                    indexIt = false;\n                  }\n                }\n              }\n            }\n\n            if (indexIt) {\n              try {\n                log(\"Indexing \" + file.getPath(),\n                    Project.MSG_VERBOSE);\n                Document doc =\n                  handler.getDocument(file);\n\n                if (doc == null) {\n                  totalIgnored++;\n                } else {\n                  // Add the path of the file as a field named \"path\".  Use a Keyword field, so\n                  // that the index stores the path, and so that the path is searchable\n                  doc.add(new Field(\"path\", file.getPath(), Field.Store.YES, Field.Index.UN_TOKENIZED));\n\n                  // Add the last modified date of the file a field named \"modified\".  Use a\n                  // Keyword field, so that it's searchable, but so that no attempt is made\n                  // to tokenize the field into words.\n                  doc.add(new Field(\"modified\", DateField.timeToString(file.lastModified()), Field.Store.YES, Field.Index.UN_TOKENIZED));\n\n                  writer.addDocument(doc);\n                  totalIndexed++;\n                }\n              } catch (DocumentHandlerException e) {\n                throw new BuildException(e);\n              }\n            }\n          }\n          // for j\n        }\n        // if (fs != null)\n      }\n      // for i\n\n      writer.optimize();\n    }\n      //try\n    finally {\n      // always make sure everything gets closed,\n      // no matter how we exit.\n      writer.close();\n      if (searcher != null) {\n        searcher.close();\n      }\n    }\n\n    Date end = new Date();\n\n    log(totalIndexed + \" out of \" + totalFiles + \" indexed (\" +\n        totalIgnored + \" ignored) in \" + (end.getTime() - start.getTime()) +\n        \" milliseconds\");\n  }\n\n","sourceOld":"  /**\n   * Index the fileset.\n   *\n   *@exception  IOException if Lucene I/O exception\n   *@todo refactor!!!!!\n   */\n  private void indexDocs() throws IOException {\n    Date start = new Date();\n\n    boolean create = overwrite;\n    // If the index directory doesn't exist,\n    // create it and force create mode\n    if (indexDir.mkdirs() && !overwrite) {\n      create = true;\n    }\n\n    Searcher searcher = null;\n    boolean checkLastModified = false;\n    if (!create) {\n      try {\n        searcher = new IndexSearcher(indexDir.getAbsolutePath());\n        checkLastModified = true;\n      } catch (IOException ioe) {\n        log(\"IOException: \" + ioe.getMessage());\n        // Empty - ignore, which indicates to index all\n        // documents\n      }\n    }\n\n    log(\"checkLastModified = \" + checkLastModified, Project.MSG_VERBOSE);\n\n    IndexWriter writer =\n      new IndexWriter(indexDir, analyzer, create);\n\n    writer.setUseCompoundFile(useCompoundIndex);\n    int totalFiles = 0;\n    int totalIndexed = 0;\n    int totalIgnored = 0;\n    try {\n      writer.mergeFactor = mergeFactor;\n\n      for (int i = 0; i < filesets.size(); i++) {\n        FileSet fs = (FileSet) filesets.get(i);\n        if (fs != null) {\n          DirectoryScanner ds =\n            fs.getDirectoryScanner(getProject());\n          String[] dsfiles = ds.getIncludedFiles();\n          File baseDir = ds.getBasedir();\n\n          for (int j = 0; j < dsfiles.length; j++) {\n            File file = new File(baseDir, dsfiles[j]);\n            totalFiles++;\n\n            if (!file.exists() || !file.canRead()) {\n              throw new BuildException(\"File \\\"\" +\n                                       file.getAbsolutePath()\n                                       + \"\\\" does not exist or is not readable.\");\n            }\n\n            boolean indexIt = true;\n\n            if (checkLastModified) {\n              Term pathTerm =\n                new Term(\"path\", file.getPath());\n              TermQuery query =\n                new TermQuery(pathTerm);\n              Hits hits = searcher.search(query);\n\n              // if document is found, compare the\n              // indexed last modified time with the\n              // current file\n              // - don't index if up to date\n              if (hits.length() > 0) {\n                Document doc = hits.doc(0);\n                String indexModified =\n                  doc.get(\"modified\").trim();\n                if (indexModified != null) {\n                  if (DateField.stringToTime(indexModified)\n                    == file.lastModified()) {\n                    // TODO: remove existing document\n                    indexIt = false;\n                  }\n                }\n              }\n            }\n\n            if (indexIt) {\n              try {\n                log(\"Indexing \" + file.getPath(),\n                    Project.MSG_VERBOSE);\n                Document doc =\n                  handler.getDocument(file);\n\n                if (doc == null) {\n                  totalIgnored++;\n                } else {\n                  // Add the path of the file as a field named \"path\".  Use a Keyword field, so\n                  // that the index stores the path, and so that the path is searchable\n                  doc.add(Field.Keyword(\"path\", file.getPath()));\n\n                  // Add the last modified date of the file a field named \"modified\".  Use a\n                  // Keyword field, so that it's searchable, but so that no attempt is made\n                  // to tokenize the field into words.\n                  doc.add(Field.Keyword(\"modified\",\n                                        DateField.timeToString(file.lastModified())));\n\n                  writer.addDocument(doc);\n                  totalIndexed++;\n                }\n              } catch (DocumentHandlerException e) {\n                throw new BuildException(e);\n              }\n            }\n          }\n          // for j\n        }\n        // if (fs != null)\n      }\n      // for i\n\n      writer.optimize();\n    }\n      //try\n    finally {\n      // always make sure everything gets closed,\n      // no matter how we exit.\n      writer.close();\n      if (searcher != null) {\n        searcher.close();\n      }\n    }\n\n    Date end = new Date();\n\n    log(totalIndexed + \" out of \" + totalFiles + \" indexed (\" +\n        totalIgnored + \" ignored) in \" + (end.getTime() - start.getTime()) +\n        \" milliseconds\");\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d37a93776a91f5c653f7975d29bdb028d643790c","date":1107701519,"type":5,"author":"Erik Hatcher","isMerge":false,"pathNew":"contrib/ant/src/java/org/apache/lucene/ant/IndexTask#indexDocs().mjava","pathOld":"contrib/ant/src/main/org/apache/lucene/ant/IndexTask#indexDocs().mjava","sourceNew":"  /**\n   * Index the fileset.\n   *\n   *@exception  IOException if Lucene I/O exception\n   *@todo refactor!!!!!\n   */\n  private void indexDocs() throws IOException {\n    Date start = new Date();\n\n    boolean create = overwrite;\n    // If the index directory doesn't exist,\n    // create it and force create mode\n    if (indexDir.mkdirs() && !overwrite) {\n      create = true;\n    }\n\n    Searcher searcher = null;\n    boolean checkLastModified = false;\n    if (!create) {\n      try {\n        searcher = new IndexSearcher(indexDir.getAbsolutePath());\n        checkLastModified = true;\n      } catch (IOException ioe) {\n        log(\"IOException: \" + ioe.getMessage());\n        // Empty - ignore, which indicates to index all\n        // documents\n      }\n    }\n\n    log(\"checkLastModified = \" + checkLastModified, Project.MSG_VERBOSE);\n\n    IndexWriter writer =\n      new IndexWriter(indexDir, analyzer, create);\n\n    writer.setUseCompoundFile(useCompoundIndex);\n    int totalFiles = 0;\n    int totalIndexed = 0;\n    int totalIgnored = 0;\n    try {\n      writer.setMergeFactor(mergeFactor);\n\n      for (int i = 0; i < filesets.size(); i++) {\n        FileSet fs = (FileSet) filesets.get(i);\n        if (fs != null) {\n          DirectoryScanner ds =\n            fs.getDirectoryScanner(getProject());\n          String[] dsfiles = ds.getIncludedFiles();\n          File baseDir = ds.getBasedir();\n\n          for (int j = 0; j < dsfiles.length; j++) {\n            File file = new File(baseDir, dsfiles[j]);\n            totalFiles++;\n\n            if (!file.exists() || !file.canRead()) {\n              throw new BuildException(\"File \\\"\" +\n                                       file.getAbsolutePath()\n                                       + \"\\\" does not exist or is not readable.\");\n            }\n\n            boolean indexIt = true;\n\n            if (checkLastModified) {\n              Term pathTerm =\n                new Term(\"path\", file.getPath());\n              TermQuery query =\n                new TermQuery(pathTerm);\n              Hits hits = searcher.search(query);\n\n              // if document is found, compare the\n              // indexed last modified time with the\n              // current file\n              // - don't index if up to date\n              if (hits.length() > 0) {\n                Document doc = hits.doc(0);\n                String indexModified =\n                  doc.get(\"modified\").trim();\n                if (indexModified != null) {\n                  if (DateField.stringToTime(indexModified)\n                    == file.lastModified()) {\n                    // TODO: remove existing document\n                    indexIt = false;\n                  }\n                }\n              }\n            }\n\n            if (indexIt) {\n              try {\n                log(\"Indexing \" + file.getPath(),\n                    Project.MSG_VERBOSE);\n                Document doc =\n                  handler.getDocument(file);\n\n                if (doc == null) {\n                  totalIgnored++;\n                } else {\n                  // Add the path of the file as a field named \"path\".  Use a Keyword field, so\n                  // that the index stores the path, and so that the path is searchable\n                  doc.add(new Field(\"path\", file.getPath(), Field.Store.YES, Field.Index.UN_TOKENIZED));\n\n                  // Add the last modified date of the file a field named \"modified\".  Use a\n                  // Keyword field, so that it's searchable, but so that no attempt is made\n                  // to tokenize the field into words.\n                  doc.add(new Field(\"modified\", DateField.timeToString(file.lastModified()), Field.Store.YES, Field.Index.UN_TOKENIZED));\n\n                  writer.addDocument(doc);\n                  totalIndexed++;\n                }\n              } catch (DocumentHandlerException e) {\n                throw new BuildException(e);\n              }\n            }\n          }\n          // for j\n        }\n        // if (fs != null)\n      }\n      // for i\n\n      writer.optimize();\n    }\n      //try\n    finally {\n      // always make sure everything gets closed,\n      // no matter how we exit.\n      writer.close();\n      if (searcher != null) {\n        searcher.close();\n      }\n    }\n\n    Date end = new Date();\n\n    log(totalIndexed + \" out of \" + totalFiles + \" indexed (\" +\n        totalIgnored + \" ignored) in \" + (end.getTime() - start.getTime()) +\n        \" milliseconds\");\n  }\n\n","sourceOld":"  /**\n   * Index the fileset.\n   *\n   *@exception  IOException if Lucene I/O exception\n   *@todo refactor!!!!!\n   */\n  private void indexDocs() throws IOException {\n    Date start = new Date();\n\n    boolean create = overwrite;\n    // If the index directory doesn't exist,\n    // create it and force create mode\n    if (indexDir.mkdirs() && !overwrite) {\n      create = true;\n    }\n\n    Searcher searcher = null;\n    boolean checkLastModified = false;\n    if (!create) {\n      try {\n        searcher = new IndexSearcher(indexDir.getAbsolutePath());\n        checkLastModified = true;\n      } catch (IOException ioe) {\n        log(\"IOException: \" + ioe.getMessage());\n        // Empty - ignore, which indicates to index all\n        // documents\n      }\n    }\n\n    log(\"checkLastModified = \" + checkLastModified, Project.MSG_VERBOSE);\n\n    IndexWriter writer =\n      new IndexWriter(indexDir, analyzer, create);\n\n    writer.setUseCompoundFile(useCompoundIndex);\n    int totalFiles = 0;\n    int totalIndexed = 0;\n    int totalIgnored = 0;\n    try {\n      writer.setMergeFactor(mergeFactor);\n\n      for (int i = 0; i < filesets.size(); i++) {\n        FileSet fs = (FileSet) filesets.get(i);\n        if (fs != null) {\n          DirectoryScanner ds =\n            fs.getDirectoryScanner(getProject());\n          String[] dsfiles = ds.getIncludedFiles();\n          File baseDir = ds.getBasedir();\n\n          for (int j = 0; j < dsfiles.length; j++) {\n            File file = new File(baseDir, dsfiles[j]);\n            totalFiles++;\n\n            if (!file.exists() || !file.canRead()) {\n              throw new BuildException(\"File \\\"\" +\n                                       file.getAbsolutePath()\n                                       + \"\\\" does not exist or is not readable.\");\n            }\n\n            boolean indexIt = true;\n\n            if (checkLastModified) {\n              Term pathTerm =\n                new Term(\"path\", file.getPath());\n              TermQuery query =\n                new TermQuery(pathTerm);\n              Hits hits = searcher.search(query);\n\n              // if document is found, compare the\n              // indexed last modified time with the\n              // current file\n              // - don't index if up to date\n              if (hits.length() > 0) {\n                Document doc = hits.doc(0);\n                String indexModified =\n                  doc.get(\"modified\").trim();\n                if (indexModified != null) {\n                  if (DateField.stringToTime(indexModified)\n                    == file.lastModified()) {\n                    // TODO: remove existing document\n                    indexIt = false;\n                  }\n                }\n              }\n            }\n\n            if (indexIt) {\n              try {\n                log(\"Indexing \" + file.getPath(),\n                    Project.MSG_VERBOSE);\n                Document doc =\n                  handler.getDocument(file);\n\n                if (doc == null) {\n                  totalIgnored++;\n                } else {\n                  // Add the path of the file as a field named \"path\".  Use a Keyword field, so\n                  // that the index stores the path, and so that the path is searchable\n                  doc.add(new Field(\"path\", file.getPath(), Field.Store.YES, Field.Index.UN_TOKENIZED));\n\n                  // Add the last modified date of the file a field named \"modified\".  Use a\n                  // Keyword field, so that it's searchable, but so that no attempt is made\n                  // to tokenize the field into words.\n                  doc.add(new Field(\"modified\", DateField.timeToString(file.lastModified()), Field.Store.YES, Field.Index.UN_TOKENIZED));\n\n                  writer.addDocument(doc);\n                  totalIndexed++;\n                }\n              } catch (DocumentHandlerException e) {\n                throw new BuildException(e);\n              }\n            }\n          }\n          // for j\n        }\n        // if (fs != null)\n      }\n      // for i\n\n      writer.optimize();\n    }\n      //try\n    finally {\n      // always make sure everything gets closed,\n      // no matter how we exit.\n      writer.close();\n      if (searcher != null) {\n        searcher.close();\n      }\n    }\n\n    Date end = new Date();\n\n    log(totalIndexed + \" out of \" + totalFiles + \" indexed (\" +\n        totalIgnored + \" ignored) in \" + (end.getTime() - start.getTime()) +\n        \" milliseconds\");\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"043c298cb215f13ba7b9b81d20760704e8f93d66":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"1202f7724a155557e02e24b0dc4209f41b2f25ae":["043c298cb215f13ba7b9b81d20760704e8f93d66"],"d37a93776a91f5c653f7975d29bdb028d643790c":["1202f7724a155557e02e24b0dc4209f41b2f25ae"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["d37a93776a91f5c653f7975d29bdb028d643790c"]},"commit2Childs":{"043c298cb215f13ba7b9b81d20760704e8f93d66":["1202f7724a155557e02e24b0dc4209f41b2f25ae"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["043c298cb215f13ba7b9b81d20760704e8f93d66"],"1202f7724a155557e02e24b0dc4209f41b2f25ae":["d37a93776a91f5c653f7975d29bdb028d643790c"],"d37a93776a91f5c653f7975d29bdb028d643790c":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}