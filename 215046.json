{"path":"lucene/src/test/org/apache/lucene/index/TestTermVectorsReader#testMapper().mjava","commits":[{"id":"9454a6510e2db155fb01faa5c049b06ece95fab9","date":1453508333,"type":1,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestTermVectorsReader#testMapper().mjava","pathOld":"src/test/org/apache/lucene/index/TestTermVectorsReader#testMapper().mjava","sourceNew":"  public void testMapper() throws IOException {\n    TermVectorsReader reader = new TermVectorsReader(dir, seg, fieldInfos);\n    SortedTermVectorMapper mapper = new SortedTermVectorMapper(new TermVectorEntryFreqSortedComparator());\n    reader.get(0, mapper);\n    SortedSet<TermVectorEntry> set = mapper.getTermVectorEntrySet();\n    assertTrue(\"set is null and it shouldn't be\", set != null);\n    //three fields, 4 terms, all terms are the same\n    assertTrue(\"set Size: \" + set.size() + \" is not: \" + 4, set.size() == 4);\n    //Check offsets and positions\n    for (Iterator<TermVectorEntry> iterator = set.iterator(); iterator.hasNext();) {\n      TermVectorEntry tve =  iterator.next();\n      assertTrue(\"tve is null and it shouldn't be\", tve != null);\n      assertTrue(\"tve.getOffsets() is null and it shouldn't be\", tve.getOffsets() != null);\n      assertTrue(\"tve.getPositions() is null and it shouldn't be\", tve.getPositions() != null);\n\n    }\n\n    mapper = new SortedTermVectorMapper(new TermVectorEntryFreqSortedComparator());\n    reader.get(1, mapper);\n    set = mapper.getTermVectorEntrySet();\n    assertTrue(\"set is null and it shouldn't be\", set != null);\n    //three fields, 4 terms, all terms are the same\n    assertTrue(\"set Size: \" + set.size() + \" is not: \" + 4, set.size() == 4);\n    //Should have offsets and positions b/c we are munging all the fields together\n    for (Iterator<TermVectorEntry> iterator = set.iterator(); iterator.hasNext();) {\n      TermVectorEntry tve = iterator.next();\n      assertTrue(\"tve is null and it shouldn't be\", tve != null);\n      assertTrue(\"tve.getOffsets() is null and it shouldn't be\", tve.getOffsets() != null);\n      assertTrue(\"tve.getPositions() is null and it shouldn't be\", tve.getPositions() != null);\n\n    }\n\n\n    FieldSortedTermVectorMapper fsMapper = new FieldSortedTermVectorMapper(new TermVectorEntryFreqSortedComparator());\n    reader.get(0, fsMapper);\n    Map<String,SortedSet<TermVectorEntry>> map = fsMapper.getFieldToTerms();\n    assertTrue(\"map Size: \" + map.size() + \" is not: \" + testFields.length, map.size() == testFields.length);\n    for (Map.Entry<String,SortedSet<TermVectorEntry>> entry : map.entrySet()) {\n      SortedSet<TermVectorEntry> sortedSet =  entry.getValue();\n      assertTrue(\"sortedSet Size: \" + sortedSet.size() + \" is not: \" + 4, sortedSet.size() == 4);\n      for (final TermVectorEntry tve : sortedSet) {\n        assertTrue(\"tve is null and it shouldn't be\", tve != null);\n        //Check offsets and positions.\n        assertTrue(\"tve is null and it shouldn't be\", tve != null);\n        String field = tve.getField();\n        if (field.equals(testFields[0])) {\n          //should have offsets\n\n          assertTrue(\"tve.getOffsets() is null and it shouldn't be\", tve.getOffsets() != null);\n          assertTrue(\"tve.getPositions() is null and it shouldn't be\", tve.getPositions() != null);\n        }\n        else if (field.equals(testFields[1])) {\n          //should not have offsets\n\n          assertTrue(\"tve.getOffsets() is not null and it shouldn't be\", tve.getOffsets() == null);\n          assertTrue(\"tve.getPositions() is not null and it shouldn't be\", tve.getPositions() == null);\n        }\n      }\n    }\n    //Try mapper that ignores offs and positions\n    fsMapper = new FieldSortedTermVectorMapper(true, true, new TermVectorEntryFreqSortedComparator());\n    reader.get(0, fsMapper);\n    map = fsMapper.getFieldToTerms();\n    assertTrue(\"map Size: \" + map.size() + \" is not: \" + testFields.length, map.size() == testFields.length);\n    for (final Map.Entry<String,SortedSet<TermVectorEntry>> entry : map.entrySet()) {\n      SortedSet<TermVectorEntry> sortedSet =  entry.getValue();\n      assertTrue(\"sortedSet Size: \" + sortedSet.size() + \" is not: \" + 4, sortedSet.size() == 4);\n      for (final TermVectorEntry tve : sortedSet) {\n        assertTrue(\"tve is null and it shouldn't be\", tve != null);\n        //Check offsets and positions.\n        assertTrue(\"tve is null and it shouldn't be\", tve != null);\n        String field = tve.getField();\n        if (field.equals(testFields[0])) {\n          //should have offsets\n\n          assertTrue(\"tve.getOffsets() is null and it shouldn't be\", tve.getOffsets() == null);\n          assertTrue(\"tve.getPositions() is null and it shouldn't be\", tve.getPositions() == null);\n        }\n        else if (field.equals(testFields[1])) {\n          //should not have offsets\n\n          assertTrue(\"tve.getOffsets() is not null and it shouldn't be\", tve.getOffsets() == null);\n          assertTrue(\"tve.getPositions() is not null and it shouldn't be\", tve.getPositions() == null);\n        }\n      }\n    }\n\n    // test setDocumentNumber()\n    IndexReader ir = IndexReader.open(dir, true);\n    DocNumAwareMapper docNumAwareMapper = new DocNumAwareMapper();\n    assertEquals(-1, docNumAwareMapper.getDocumentNumber());\n\n    ir.getTermFreqVector(0, docNumAwareMapper);\n    assertEquals(0, docNumAwareMapper.getDocumentNumber());\n    docNumAwareMapper.setDocumentNumber(-1);\n\n    ir.getTermFreqVector(1, docNumAwareMapper);\n    assertEquals(1, docNumAwareMapper.getDocumentNumber());\n    docNumAwareMapper.setDocumentNumber(-1);\n\n    ir.getTermFreqVector(0, \"f1\", docNumAwareMapper);\n    assertEquals(0, docNumAwareMapper.getDocumentNumber());\n    docNumAwareMapper.setDocumentNumber(-1);\n\n    ir.getTermFreqVector(1, \"f2\", docNumAwareMapper);\n    assertEquals(1, docNumAwareMapper.getDocumentNumber());\n    docNumAwareMapper.setDocumentNumber(-1);\n\n    ir.getTermFreqVector(0, \"f1\", docNumAwareMapper);\n    assertEquals(0, docNumAwareMapper.getDocumentNumber());\n\n    ir.close();\n\n  }\n\n","sourceOld":"  public void testMapper() throws IOException {\n    TermVectorsReader reader = new TermVectorsReader(dir, seg, fieldInfos);\n    SortedTermVectorMapper mapper = new SortedTermVectorMapper(new TermVectorEntryFreqSortedComparator());\n    reader.get(0, mapper);\n    SortedSet<TermVectorEntry> set = mapper.getTermVectorEntrySet();\n    assertTrue(\"set is null and it shouldn't be\", set != null);\n    //three fields, 4 terms, all terms are the same\n    assertTrue(\"set Size: \" + set.size() + \" is not: \" + 4, set.size() == 4);\n    //Check offsets and positions\n    for (Iterator<TermVectorEntry> iterator = set.iterator(); iterator.hasNext();) {\n      TermVectorEntry tve =  iterator.next();\n      assertTrue(\"tve is null and it shouldn't be\", tve != null);\n      assertTrue(\"tve.getOffsets() is null and it shouldn't be\", tve.getOffsets() != null);\n      assertTrue(\"tve.getPositions() is null and it shouldn't be\", tve.getPositions() != null);\n\n    }\n\n    mapper = new SortedTermVectorMapper(new TermVectorEntryFreqSortedComparator());\n    reader.get(1, mapper);\n    set = mapper.getTermVectorEntrySet();\n    assertTrue(\"set is null and it shouldn't be\", set != null);\n    //three fields, 4 terms, all terms are the same\n    assertTrue(\"set Size: \" + set.size() + \" is not: \" + 4, set.size() == 4);\n    //Should have offsets and positions b/c we are munging all the fields together\n    for (Iterator<TermVectorEntry> iterator = set.iterator(); iterator.hasNext();) {\n      TermVectorEntry tve = iterator.next();\n      assertTrue(\"tve is null and it shouldn't be\", tve != null);\n      assertTrue(\"tve.getOffsets() is null and it shouldn't be\", tve.getOffsets() != null);\n      assertTrue(\"tve.getPositions() is null and it shouldn't be\", tve.getPositions() != null);\n\n    }\n\n\n    FieldSortedTermVectorMapper fsMapper = new FieldSortedTermVectorMapper(new TermVectorEntryFreqSortedComparator());\n    reader.get(0, fsMapper);\n    Map<String,SortedSet<TermVectorEntry>> map = fsMapper.getFieldToTerms();\n    assertTrue(\"map Size: \" + map.size() + \" is not: \" + testFields.length, map.size() == testFields.length);\n    for (Map.Entry<String,SortedSet<TermVectorEntry>> entry : map.entrySet()) {\n      SortedSet<TermVectorEntry> sortedSet =  entry.getValue();\n      assertTrue(\"sortedSet Size: \" + sortedSet.size() + \" is not: \" + 4, sortedSet.size() == 4);\n      for (final TermVectorEntry tve : sortedSet) {\n        assertTrue(\"tve is null and it shouldn't be\", tve != null);\n        //Check offsets and positions.\n        assertTrue(\"tve is null and it shouldn't be\", tve != null);\n        String field = tve.getField();\n        if (field.equals(testFields[0])) {\n          //should have offsets\n\n          assertTrue(\"tve.getOffsets() is null and it shouldn't be\", tve.getOffsets() != null);\n          assertTrue(\"tve.getPositions() is null and it shouldn't be\", tve.getPositions() != null);\n        }\n        else if (field.equals(testFields[1])) {\n          //should not have offsets\n\n          assertTrue(\"tve.getOffsets() is not null and it shouldn't be\", tve.getOffsets() == null);\n          assertTrue(\"tve.getPositions() is not null and it shouldn't be\", tve.getPositions() == null);\n        }\n      }\n    }\n    //Try mapper that ignores offs and positions\n    fsMapper = new FieldSortedTermVectorMapper(true, true, new TermVectorEntryFreqSortedComparator());\n    reader.get(0, fsMapper);\n    map = fsMapper.getFieldToTerms();\n    assertTrue(\"map Size: \" + map.size() + \" is not: \" + testFields.length, map.size() == testFields.length);\n    for (final Map.Entry<String,SortedSet<TermVectorEntry>> entry : map.entrySet()) {\n      SortedSet<TermVectorEntry> sortedSet =  entry.getValue();\n      assertTrue(\"sortedSet Size: \" + sortedSet.size() + \" is not: \" + 4, sortedSet.size() == 4);\n      for (final TermVectorEntry tve : sortedSet) {\n        assertTrue(\"tve is null and it shouldn't be\", tve != null);\n        //Check offsets and positions.\n        assertTrue(\"tve is null and it shouldn't be\", tve != null);\n        String field = tve.getField();\n        if (field.equals(testFields[0])) {\n          //should have offsets\n\n          assertTrue(\"tve.getOffsets() is null and it shouldn't be\", tve.getOffsets() == null);\n          assertTrue(\"tve.getPositions() is null and it shouldn't be\", tve.getPositions() == null);\n        }\n        else if (field.equals(testFields[1])) {\n          //should not have offsets\n\n          assertTrue(\"tve.getOffsets() is not null and it shouldn't be\", tve.getOffsets() == null);\n          assertTrue(\"tve.getPositions() is not null and it shouldn't be\", tve.getPositions() == null);\n        }\n      }\n    }\n\n    // test setDocumentNumber()\n    IndexReader ir = IndexReader.open(dir, true);\n    DocNumAwareMapper docNumAwareMapper = new DocNumAwareMapper();\n    assertEquals(-1, docNumAwareMapper.getDocumentNumber());\n\n    ir.getTermFreqVector(0, docNumAwareMapper);\n    assertEquals(0, docNumAwareMapper.getDocumentNumber());\n    docNumAwareMapper.setDocumentNumber(-1);\n\n    ir.getTermFreqVector(1, docNumAwareMapper);\n    assertEquals(1, docNumAwareMapper.getDocumentNumber());\n    docNumAwareMapper.setDocumentNumber(-1);\n\n    ir.getTermFreqVector(0, \"f1\", docNumAwareMapper);\n    assertEquals(0, docNumAwareMapper.getDocumentNumber());\n    docNumAwareMapper.setDocumentNumber(-1);\n\n    ir.getTermFreqVector(1, \"f2\", docNumAwareMapper);\n    assertEquals(1, docNumAwareMapper.getDocumentNumber());\n    docNumAwareMapper.setDocumentNumber(-1);\n\n    ir.getTermFreqVector(0, \"f1\", docNumAwareMapper);\n    assertEquals(0, docNumAwareMapper.getDocumentNumber());\n\n    ir.close();\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ab9633cb67e3c0aec3c066147a23a957d6e7ad8c","date":1281646583,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestTermVectorsReader#testMapper().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestTermVectorsReader#testMapper().mjava","sourceNew":"  public void testMapper() throws IOException {\n    TermVectorsReader reader = new TermVectorsReader(dir, seg, fieldInfos);\n    SortedTermVectorMapper mapper = new SortedTermVectorMapper(new TermVectorEntryFreqSortedComparator());\n    reader.get(0, mapper);\n    SortedSet<TermVectorEntry> set = mapper.getTermVectorEntrySet();\n    assertTrue(\"set is null and it shouldn't be\", set != null);\n    //three fields, 4 terms, all terms are the same\n    assertTrue(\"set Size: \" + set.size() + \" is not: \" + 4, set.size() == 4);\n    //Check offsets and positions\n    for (Iterator<TermVectorEntry> iterator = set.iterator(); iterator.hasNext();) {\n      TermVectorEntry tve =  iterator.next();\n      assertTrue(\"tve is null and it shouldn't be\", tve != null);\n      assertTrue(\"tve.getOffsets() is null and it shouldn't be\", tve.getOffsets() != null);\n      assertTrue(\"tve.getPositions() is null and it shouldn't be\", tve.getPositions() != null);\n\n    }\n\n    mapper = new SortedTermVectorMapper(new TermVectorEntryFreqSortedComparator());\n    reader.get(1, mapper);\n    set = mapper.getTermVectorEntrySet();\n    assertTrue(\"set is null and it shouldn't be\", set != null);\n    //three fields, 4 terms, all terms are the same\n    assertTrue(\"set Size: \" + set.size() + \" is not: \" + 4, set.size() == 4);\n    //Should have offsets and positions b/c we are munging all the fields together\n    for (Iterator<TermVectorEntry> iterator = set.iterator(); iterator.hasNext();) {\n      TermVectorEntry tve = iterator.next();\n      assertTrue(\"tve is null and it shouldn't be\", tve != null);\n      assertTrue(\"tve.getOffsets() is null and it shouldn't be\", tve.getOffsets() != null);\n      assertTrue(\"tve.getPositions() is null and it shouldn't be\", tve.getPositions() != null);\n\n    }\n\n\n    FieldSortedTermVectorMapper fsMapper = new FieldSortedTermVectorMapper(new TermVectorEntryFreqSortedComparator());\n    reader.get(0, fsMapper);\n    Map<String,SortedSet<TermVectorEntry>> map = fsMapper.getFieldToTerms();\n    assertTrue(\"map Size: \" + map.size() + \" is not: \" + testFields.length, map.size() == testFields.length);\n    for (Map.Entry<String,SortedSet<TermVectorEntry>> entry : map.entrySet()) {\n      SortedSet<TermVectorEntry> sortedSet =  entry.getValue();\n      assertTrue(\"sortedSet Size: \" + sortedSet.size() + \" is not: \" + 4, sortedSet.size() == 4);\n      for (final TermVectorEntry tve : sortedSet) {\n        assertTrue(\"tve is null and it shouldn't be\", tve != null);\n        //Check offsets and positions.\n        assertTrue(\"tve is null and it shouldn't be\", tve != null);\n        String field = tve.getField();\n        if (field.equals(testFields[0])) {\n          //should have offsets\n\n          assertTrue(\"tve.getOffsets() is null and it shouldn't be\", tve.getOffsets() != null);\n          assertTrue(\"tve.getPositions() is null and it shouldn't be\", tve.getPositions() != null);\n        }\n        else if (field.equals(testFields[1])) {\n          //should not have offsets\n\n          assertTrue(\"tve.getOffsets() is not null and it shouldn't be\", tve.getOffsets() == null);\n          assertTrue(\"tve.getPositions() is not null and it shouldn't be\", tve.getPositions() == null);\n        }\n      }\n    }\n    //Try mapper that ignores offs and positions\n    fsMapper = new FieldSortedTermVectorMapper(true, true, new TermVectorEntryFreqSortedComparator());\n    reader.get(0, fsMapper);\n    map = fsMapper.getFieldToTerms();\n    assertTrue(\"map Size: \" + map.size() + \" is not: \" + testFields.length, map.size() == testFields.length);\n    for (final Map.Entry<String,SortedSet<TermVectorEntry>> entry : map.entrySet()) {\n      SortedSet<TermVectorEntry> sortedSet =  entry.getValue();\n      assertTrue(\"sortedSet Size: \" + sortedSet.size() + \" is not: \" + 4, sortedSet.size() == 4);\n      for (final TermVectorEntry tve : sortedSet) {\n        assertTrue(\"tve is null and it shouldn't be\", tve != null);\n        //Check offsets and positions.\n        assertTrue(\"tve is null and it shouldn't be\", tve != null);\n        String field = tve.getField();\n        if (field.equals(testFields[0])) {\n          //should have offsets\n\n          assertTrue(\"tve.getOffsets() is null and it shouldn't be\", tve.getOffsets() == null);\n          assertTrue(\"tve.getPositions() is null and it shouldn't be\", tve.getPositions() == null);\n        }\n        else if (field.equals(testFields[1])) {\n          //should not have offsets\n\n          assertTrue(\"tve.getOffsets() is not null and it shouldn't be\", tve.getOffsets() == null);\n          assertTrue(\"tve.getPositions() is not null and it shouldn't be\", tve.getPositions() == null);\n        }\n      }\n    }\n\n    // test setDocumentNumber()\n    IndexReader ir = IndexReader.open(dir, true);\n    DocNumAwareMapper docNumAwareMapper = new DocNumAwareMapper();\n    assertEquals(-1, docNumAwareMapper.getDocumentNumber());\n\n    ir.getTermFreqVector(0, docNumAwareMapper);\n    assertEquals(0, docNumAwareMapper.getDocumentNumber());\n    docNumAwareMapper.setDocumentNumber(-1);\n\n    ir.getTermFreqVector(1, docNumAwareMapper);\n    assertEquals(1, docNumAwareMapper.getDocumentNumber());\n    docNumAwareMapper.setDocumentNumber(-1);\n\n    ir.getTermFreqVector(0, \"f1\", docNumAwareMapper);\n    assertEquals(0, docNumAwareMapper.getDocumentNumber());\n    docNumAwareMapper.setDocumentNumber(-1);\n\n    ir.getTermFreqVector(1, \"f2\", docNumAwareMapper);\n    assertEquals(1, docNumAwareMapper.getDocumentNumber());\n    docNumAwareMapper.setDocumentNumber(-1);\n\n    ir.getTermFreqVector(0, \"f1\", docNumAwareMapper);\n    assertEquals(0, docNumAwareMapper.getDocumentNumber());\n\n    ir.close();\n    reader.close();\n  }\n\n","sourceOld":"  public void testMapper() throws IOException {\n    TermVectorsReader reader = new TermVectorsReader(dir, seg, fieldInfos);\n    SortedTermVectorMapper mapper = new SortedTermVectorMapper(new TermVectorEntryFreqSortedComparator());\n    reader.get(0, mapper);\n    SortedSet<TermVectorEntry> set = mapper.getTermVectorEntrySet();\n    assertTrue(\"set is null and it shouldn't be\", set != null);\n    //three fields, 4 terms, all terms are the same\n    assertTrue(\"set Size: \" + set.size() + \" is not: \" + 4, set.size() == 4);\n    //Check offsets and positions\n    for (Iterator<TermVectorEntry> iterator = set.iterator(); iterator.hasNext();) {\n      TermVectorEntry tve =  iterator.next();\n      assertTrue(\"tve is null and it shouldn't be\", tve != null);\n      assertTrue(\"tve.getOffsets() is null and it shouldn't be\", tve.getOffsets() != null);\n      assertTrue(\"tve.getPositions() is null and it shouldn't be\", tve.getPositions() != null);\n\n    }\n\n    mapper = new SortedTermVectorMapper(new TermVectorEntryFreqSortedComparator());\n    reader.get(1, mapper);\n    set = mapper.getTermVectorEntrySet();\n    assertTrue(\"set is null and it shouldn't be\", set != null);\n    //three fields, 4 terms, all terms are the same\n    assertTrue(\"set Size: \" + set.size() + \" is not: \" + 4, set.size() == 4);\n    //Should have offsets and positions b/c we are munging all the fields together\n    for (Iterator<TermVectorEntry> iterator = set.iterator(); iterator.hasNext();) {\n      TermVectorEntry tve = iterator.next();\n      assertTrue(\"tve is null and it shouldn't be\", tve != null);\n      assertTrue(\"tve.getOffsets() is null and it shouldn't be\", tve.getOffsets() != null);\n      assertTrue(\"tve.getPositions() is null and it shouldn't be\", tve.getPositions() != null);\n\n    }\n\n\n    FieldSortedTermVectorMapper fsMapper = new FieldSortedTermVectorMapper(new TermVectorEntryFreqSortedComparator());\n    reader.get(0, fsMapper);\n    Map<String,SortedSet<TermVectorEntry>> map = fsMapper.getFieldToTerms();\n    assertTrue(\"map Size: \" + map.size() + \" is not: \" + testFields.length, map.size() == testFields.length);\n    for (Map.Entry<String,SortedSet<TermVectorEntry>> entry : map.entrySet()) {\n      SortedSet<TermVectorEntry> sortedSet =  entry.getValue();\n      assertTrue(\"sortedSet Size: \" + sortedSet.size() + \" is not: \" + 4, sortedSet.size() == 4);\n      for (final TermVectorEntry tve : sortedSet) {\n        assertTrue(\"tve is null and it shouldn't be\", tve != null);\n        //Check offsets and positions.\n        assertTrue(\"tve is null and it shouldn't be\", tve != null);\n        String field = tve.getField();\n        if (field.equals(testFields[0])) {\n          //should have offsets\n\n          assertTrue(\"tve.getOffsets() is null and it shouldn't be\", tve.getOffsets() != null);\n          assertTrue(\"tve.getPositions() is null and it shouldn't be\", tve.getPositions() != null);\n        }\n        else if (field.equals(testFields[1])) {\n          //should not have offsets\n\n          assertTrue(\"tve.getOffsets() is not null and it shouldn't be\", tve.getOffsets() == null);\n          assertTrue(\"tve.getPositions() is not null and it shouldn't be\", tve.getPositions() == null);\n        }\n      }\n    }\n    //Try mapper that ignores offs and positions\n    fsMapper = new FieldSortedTermVectorMapper(true, true, new TermVectorEntryFreqSortedComparator());\n    reader.get(0, fsMapper);\n    map = fsMapper.getFieldToTerms();\n    assertTrue(\"map Size: \" + map.size() + \" is not: \" + testFields.length, map.size() == testFields.length);\n    for (final Map.Entry<String,SortedSet<TermVectorEntry>> entry : map.entrySet()) {\n      SortedSet<TermVectorEntry> sortedSet =  entry.getValue();\n      assertTrue(\"sortedSet Size: \" + sortedSet.size() + \" is not: \" + 4, sortedSet.size() == 4);\n      for (final TermVectorEntry tve : sortedSet) {\n        assertTrue(\"tve is null and it shouldn't be\", tve != null);\n        //Check offsets and positions.\n        assertTrue(\"tve is null and it shouldn't be\", tve != null);\n        String field = tve.getField();\n        if (field.equals(testFields[0])) {\n          //should have offsets\n\n          assertTrue(\"tve.getOffsets() is null and it shouldn't be\", tve.getOffsets() == null);\n          assertTrue(\"tve.getPositions() is null and it shouldn't be\", tve.getPositions() == null);\n        }\n        else if (field.equals(testFields[1])) {\n          //should not have offsets\n\n          assertTrue(\"tve.getOffsets() is not null and it shouldn't be\", tve.getOffsets() == null);\n          assertTrue(\"tve.getPositions() is not null and it shouldn't be\", tve.getPositions() == null);\n        }\n      }\n    }\n\n    // test setDocumentNumber()\n    IndexReader ir = IndexReader.open(dir, true);\n    DocNumAwareMapper docNumAwareMapper = new DocNumAwareMapper();\n    assertEquals(-1, docNumAwareMapper.getDocumentNumber());\n\n    ir.getTermFreqVector(0, docNumAwareMapper);\n    assertEquals(0, docNumAwareMapper.getDocumentNumber());\n    docNumAwareMapper.setDocumentNumber(-1);\n\n    ir.getTermFreqVector(1, docNumAwareMapper);\n    assertEquals(1, docNumAwareMapper.getDocumentNumber());\n    docNumAwareMapper.setDocumentNumber(-1);\n\n    ir.getTermFreqVector(0, \"f1\", docNumAwareMapper);\n    assertEquals(0, docNumAwareMapper.getDocumentNumber());\n    docNumAwareMapper.setDocumentNumber(-1);\n\n    ir.getTermFreqVector(1, \"f2\", docNumAwareMapper);\n    assertEquals(1, docNumAwareMapper.getDocumentNumber());\n    docNumAwareMapper.setDocumentNumber(-1);\n\n    ir.getTermFreqVector(0, \"f1\", docNumAwareMapper);\n    assertEquals(0, docNumAwareMapper.getDocumentNumber());\n\n    ir.close();\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","date":1292920096,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestTermVectorsReader#testMapper().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestTermVectorsReader#testMapper().mjava","sourceNew":"  public void testMapper() throws IOException {\n    TermVectorsReader reader = new TermVectorsReader(dir, seg, fieldInfos);\n    SortedTermVectorMapper mapper = new SortedTermVectorMapper(new TermVectorEntryFreqSortedComparator());\n    reader.get(0, mapper);\n    SortedSet<TermVectorEntry> set = mapper.getTermVectorEntrySet();\n    assertTrue(\"set is null and it shouldn't be\", set != null);\n    //three fields, 4 terms, all terms are the same\n    assertTrue(\"set Size: \" + set.size() + \" is not: \" + 4, set.size() == 4);\n    //Check offsets and positions\n    for (Iterator<TermVectorEntry> iterator = set.iterator(); iterator.hasNext();) {\n      TermVectorEntry tve =  iterator.next();\n      assertTrue(\"tve is null and it shouldn't be\", tve != null);\n      assertTrue(\"tve.getOffsets() is null and it shouldn't be\", tve.getOffsets() != null);\n      assertTrue(\"tve.getPositions() is null and it shouldn't be\", tve.getPositions() != null);\n\n    }\n\n    mapper = new SortedTermVectorMapper(new TermVectorEntryFreqSortedComparator());\n    reader.get(1, mapper);\n    set = mapper.getTermVectorEntrySet();\n    assertTrue(\"set is null and it shouldn't be\", set != null);\n    //three fields, 4 terms, all terms are the same\n    assertTrue(\"set Size: \" + set.size() + \" is not: \" + 4, set.size() == 4);\n    //Should have offsets and positions b/c we are munging all the fields together\n    for (Iterator<TermVectorEntry> iterator = set.iterator(); iterator.hasNext();) {\n      TermVectorEntry tve = iterator.next();\n      assertTrue(\"tve is null and it shouldn't be\", tve != null);\n      assertTrue(\"tve.getOffsets() is null and it shouldn't be\", tve.getOffsets() != null);\n      assertTrue(\"tve.getPositions() is null and it shouldn't be\", tve.getPositions() != null);\n\n    }\n\n\n    FieldSortedTermVectorMapper fsMapper = new FieldSortedTermVectorMapper(new TermVectorEntryFreqSortedComparator());\n    reader.get(0, fsMapper);\n    Map<String,SortedSet<TermVectorEntry>> map = fsMapper.getFieldToTerms();\n    assertTrue(\"map Size: \" + map.size() + \" is not: \" + testFields.length, map.size() == testFields.length);\n    for (Map.Entry<String,SortedSet<TermVectorEntry>> entry : map.entrySet()) {\n      SortedSet<TermVectorEntry> sortedSet =  entry.getValue();\n      assertTrue(\"sortedSet Size: \" + sortedSet.size() + \" is not: \" + 4, sortedSet.size() == 4);\n      for (final TermVectorEntry tve : sortedSet) {\n        assertTrue(\"tve is null and it shouldn't be\", tve != null);\n        //Check offsets and positions.\n        assertTrue(\"tve is null and it shouldn't be\", tve != null);\n        String field = tve.getField();\n        if (field.equals(testFields[0])) {\n          //should have offsets\n\n          assertTrue(\"tve.getOffsets() is null and it shouldn't be\", tve.getOffsets() != null);\n          assertTrue(\"tve.getPositions() is null and it shouldn't be\", tve.getPositions() != null);\n        }\n        else if (field.equals(testFields[1])) {\n          //should not have offsets\n\n          assertTrue(\"tve.getOffsets() is not null and it shouldn't be\", tve.getOffsets() == null);\n          assertTrue(\"tve.getPositions() is not null and it shouldn't be\", tve.getPositions() == null);\n        }\n      }\n    }\n    //Try mapper that ignores offs and positions\n    fsMapper = new FieldSortedTermVectorMapper(true, true, new TermVectorEntryFreqSortedComparator());\n    reader.get(0, fsMapper);\n    map = fsMapper.getFieldToTerms();\n    assertTrue(\"map Size: \" + map.size() + \" is not: \" + testFields.length, map.size() == testFields.length);\n    for (final Map.Entry<String,SortedSet<TermVectorEntry>> entry : map.entrySet()) {\n      SortedSet<TermVectorEntry> sortedSet =  entry.getValue();\n      assertTrue(\"sortedSet Size: \" + sortedSet.size() + \" is not: \" + 4, sortedSet.size() == 4);\n      for (final TermVectorEntry tve : sortedSet) {\n        assertTrue(\"tve is null and it shouldn't be\", tve != null);\n        //Check offsets and positions.\n        assertTrue(\"tve is null and it shouldn't be\", tve != null);\n        String field = tve.getField();\n        if (field.equals(testFields[0])) {\n          //should have offsets\n\n          assertTrue(\"tve.getOffsets() is null and it shouldn't be\", tve.getOffsets() == null);\n          assertTrue(\"tve.getPositions() is null and it shouldn't be\", tve.getPositions() == null);\n        }\n        else if (field.equals(testFields[1])) {\n          //should not have offsets\n\n          assertTrue(\"tve.getOffsets() is not null and it shouldn't be\", tve.getOffsets() == null);\n          assertTrue(\"tve.getPositions() is not null and it shouldn't be\", tve.getPositions() == null);\n        }\n      }\n    }\n\n    // test setDocumentNumber()\n    IndexReader ir = IndexReader.open(dir, true);\n    DocNumAwareMapper docNumAwareMapper = new DocNumAwareMapper();\n    assertEquals(-1, docNumAwareMapper.getDocumentNumber());\n\n    ir.getTermFreqVector(0, docNumAwareMapper);\n    assertEquals(0, docNumAwareMapper.getDocumentNumber());\n    docNumAwareMapper.setDocumentNumber(-1);\n\n    ir.getTermFreqVector(1, docNumAwareMapper);\n    assertEquals(1, docNumAwareMapper.getDocumentNumber());\n    docNumAwareMapper.setDocumentNumber(-1);\n\n    ir.getTermFreqVector(0, \"f1\", docNumAwareMapper);\n    assertEquals(0, docNumAwareMapper.getDocumentNumber());\n    docNumAwareMapper.setDocumentNumber(-1);\n\n    ir.getTermFreqVector(1, \"f2\", docNumAwareMapper);\n    assertEquals(1, docNumAwareMapper.getDocumentNumber());\n    docNumAwareMapper.setDocumentNumber(-1);\n\n    ir.getTermFreqVector(0, \"f1\", docNumAwareMapper);\n    assertEquals(0, docNumAwareMapper.getDocumentNumber());\n\n    ir.close();\n    reader.close();\n  }\n\n","sourceOld":"  public void testMapper() throws IOException {\n    TermVectorsReader reader = new TermVectorsReader(dir, seg, fieldInfos);\n    SortedTermVectorMapper mapper = new SortedTermVectorMapper(new TermVectorEntryFreqSortedComparator());\n    reader.get(0, mapper);\n    SortedSet<TermVectorEntry> set = mapper.getTermVectorEntrySet();\n    assertTrue(\"set is null and it shouldn't be\", set != null);\n    //three fields, 4 terms, all terms are the same\n    assertTrue(\"set Size: \" + set.size() + \" is not: \" + 4, set.size() == 4);\n    //Check offsets and positions\n    for (Iterator<TermVectorEntry> iterator = set.iterator(); iterator.hasNext();) {\n      TermVectorEntry tve =  iterator.next();\n      assertTrue(\"tve is null and it shouldn't be\", tve != null);\n      assertTrue(\"tve.getOffsets() is null and it shouldn't be\", tve.getOffsets() != null);\n      assertTrue(\"tve.getPositions() is null and it shouldn't be\", tve.getPositions() != null);\n\n    }\n\n    mapper = new SortedTermVectorMapper(new TermVectorEntryFreqSortedComparator());\n    reader.get(1, mapper);\n    set = mapper.getTermVectorEntrySet();\n    assertTrue(\"set is null and it shouldn't be\", set != null);\n    //three fields, 4 terms, all terms are the same\n    assertTrue(\"set Size: \" + set.size() + \" is not: \" + 4, set.size() == 4);\n    //Should have offsets and positions b/c we are munging all the fields together\n    for (Iterator<TermVectorEntry> iterator = set.iterator(); iterator.hasNext();) {\n      TermVectorEntry tve = iterator.next();\n      assertTrue(\"tve is null and it shouldn't be\", tve != null);\n      assertTrue(\"tve.getOffsets() is null and it shouldn't be\", tve.getOffsets() != null);\n      assertTrue(\"tve.getPositions() is null and it shouldn't be\", tve.getPositions() != null);\n\n    }\n\n\n    FieldSortedTermVectorMapper fsMapper = new FieldSortedTermVectorMapper(new TermVectorEntryFreqSortedComparator());\n    reader.get(0, fsMapper);\n    Map<String,SortedSet<TermVectorEntry>> map = fsMapper.getFieldToTerms();\n    assertTrue(\"map Size: \" + map.size() + \" is not: \" + testFields.length, map.size() == testFields.length);\n    for (Map.Entry<String,SortedSet<TermVectorEntry>> entry : map.entrySet()) {\n      SortedSet<TermVectorEntry> sortedSet =  entry.getValue();\n      assertTrue(\"sortedSet Size: \" + sortedSet.size() + \" is not: \" + 4, sortedSet.size() == 4);\n      for (final TermVectorEntry tve : sortedSet) {\n        assertTrue(\"tve is null and it shouldn't be\", tve != null);\n        //Check offsets and positions.\n        assertTrue(\"tve is null and it shouldn't be\", tve != null);\n        String field = tve.getField();\n        if (field.equals(testFields[0])) {\n          //should have offsets\n\n          assertTrue(\"tve.getOffsets() is null and it shouldn't be\", tve.getOffsets() != null);\n          assertTrue(\"tve.getPositions() is null and it shouldn't be\", tve.getPositions() != null);\n        }\n        else if (field.equals(testFields[1])) {\n          //should not have offsets\n\n          assertTrue(\"tve.getOffsets() is not null and it shouldn't be\", tve.getOffsets() == null);\n          assertTrue(\"tve.getPositions() is not null and it shouldn't be\", tve.getPositions() == null);\n        }\n      }\n    }\n    //Try mapper that ignores offs and positions\n    fsMapper = new FieldSortedTermVectorMapper(true, true, new TermVectorEntryFreqSortedComparator());\n    reader.get(0, fsMapper);\n    map = fsMapper.getFieldToTerms();\n    assertTrue(\"map Size: \" + map.size() + \" is not: \" + testFields.length, map.size() == testFields.length);\n    for (final Map.Entry<String,SortedSet<TermVectorEntry>> entry : map.entrySet()) {\n      SortedSet<TermVectorEntry> sortedSet =  entry.getValue();\n      assertTrue(\"sortedSet Size: \" + sortedSet.size() + \" is not: \" + 4, sortedSet.size() == 4);\n      for (final TermVectorEntry tve : sortedSet) {\n        assertTrue(\"tve is null and it shouldn't be\", tve != null);\n        //Check offsets and positions.\n        assertTrue(\"tve is null and it shouldn't be\", tve != null);\n        String field = tve.getField();\n        if (field.equals(testFields[0])) {\n          //should have offsets\n\n          assertTrue(\"tve.getOffsets() is null and it shouldn't be\", tve.getOffsets() == null);\n          assertTrue(\"tve.getPositions() is null and it shouldn't be\", tve.getPositions() == null);\n        }\n        else if (field.equals(testFields[1])) {\n          //should not have offsets\n\n          assertTrue(\"tve.getOffsets() is not null and it shouldn't be\", tve.getOffsets() == null);\n          assertTrue(\"tve.getPositions() is not null and it shouldn't be\", tve.getPositions() == null);\n        }\n      }\n    }\n\n    // test setDocumentNumber()\n    IndexReader ir = IndexReader.open(dir, true);\n    DocNumAwareMapper docNumAwareMapper = new DocNumAwareMapper();\n    assertEquals(-1, docNumAwareMapper.getDocumentNumber());\n\n    ir.getTermFreqVector(0, docNumAwareMapper);\n    assertEquals(0, docNumAwareMapper.getDocumentNumber());\n    docNumAwareMapper.setDocumentNumber(-1);\n\n    ir.getTermFreqVector(1, docNumAwareMapper);\n    assertEquals(1, docNumAwareMapper.getDocumentNumber());\n    docNumAwareMapper.setDocumentNumber(-1);\n\n    ir.getTermFreqVector(0, \"f1\", docNumAwareMapper);\n    assertEquals(0, docNumAwareMapper.getDocumentNumber());\n    docNumAwareMapper.setDocumentNumber(-1);\n\n    ir.getTermFreqVector(1, \"f2\", docNumAwareMapper);\n    assertEquals(1, docNumAwareMapper.getDocumentNumber());\n    docNumAwareMapper.setDocumentNumber(-1);\n\n    ir.getTermFreqVector(0, \"f1\", docNumAwareMapper);\n    assertEquals(0, docNumAwareMapper.getDocumentNumber());\n\n    ir.close();\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"639c36565ce03aed5b0fce7c9e4448e53a1f7efd","date":1308580104,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestTermVectorsReader#testMapper().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestTermVectorsReader#testMapper().mjava","sourceNew":"  public void testMapper() throws IOException {\n    TermVectorsReader reader = new TermVectorsReader(dir, seg, fieldInfos, IOContext.READ);\n    SortedTermVectorMapper mapper = new SortedTermVectorMapper(new TermVectorEntryFreqSortedComparator());\n    reader.get(0, mapper);\n    SortedSet<TermVectorEntry> set = mapper.getTermVectorEntrySet();\n    assertTrue(\"set is null and it shouldn't be\", set != null);\n    //three fields, 4 terms, all terms are the same\n    assertTrue(\"set Size: \" + set.size() + \" is not: \" + 4, set.size() == 4);\n    //Check offsets and positions\n    for (Iterator<TermVectorEntry> iterator = set.iterator(); iterator.hasNext();) {\n      TermVectorEntry tve =  iterator.next();\n      assertTrue(\"tve is null and it shouldn't be\", tve != null);\n      assertTrue(\"tve.getOffsets() is null and it shouldn't be\", tve.getOffsets() != null);\n      assertTrue(\"tve.getPositions() is null and it shouldn't be\", tve.getPositions() != null);\n\n    }\n\n    mapper = new SortedTermVectorMapper(new TermVectorEntryFreqSortedComparator());\n    reader.get(1, mapper);\n    set = mapper.getTermVectorEntrySet();\n    assertTrue(\"set is null and it shouldn't be\", set != null);\n    //three fields, 4 terms, all terms are the same\n    assertTrue(\"set Size: \" + set.size() + \" is not: \" + 4, set.size() == 4);\n    //Should have offsets and positions b/c we are munging all the fields together\n    for (Iterator<TermVectorEntry> iterator = set.iterator(); iterator.hasNext();) {\n      TermVectorEntry tve = iterator.next();\n      assertTrue(\"tve is null and it shouldn't be\", tve != null);\n      assertTrue(\"tve.getOffsets() is null and it shouldn't be\", tve.getOffsets() != null);\n      assertTrue(\"tve.getPositions() is null and it shouldn't be\", tve.getPositions() != null);\n\n    }\n\n\n    FieldSortedTermVectorMapper fsMapper = new FieldSortedTermVectorMapper(new TermVectorEntryFreqSortedComparator());\n    reader.get(0, fsMapper);\n    Map<String,SortedSet<TermVectorEntry>> map = fsMapper.getFieldToTerms();\n    assertTrue(\"map Size: \" + map.size() + \" is not: \" + testFields.length, map.size() == testFields.length);\n    for (Map.Entry<String,SortedSet<TermVectorEntry>> entry : map.entrySet()) {\n      SortedSet<TermVectorEntry> sortedSet =  entry.getValue();\n      assertTrue(\"sortedSet Size: \" + sortedSet.size() + \" is not: \" + 4, sortedSet.size() == 4);\n      for (final TermVectorEntry tve : sortedSet) {\n        assertTrue(\"tve is null and it shouldn't be\", tve != null);\n        //Check offsets and positions.\n        assertTrue(\"tve is null and it shouldn't be\", tve != null);\n        String field = tve.getField();\n        if (field.equals(testFields[0])) {\n          //should have offsets\n\n          assertTrue(\"tve.getOffsets() is null and it shouldn't be\", tve.getOffsets() != null);\n          assertTrue(\"tve.getPositions() is null and it shouldn't be\", tve.getPositions() != null);\n        }\n        else if (field.equals(testFields[1])) {\n          //should not have offsets\n\n          assertTrue(\"tve.getOffsets() is not null and it shouldn't be\", tve.getOffsets() == null);\n          assertTrue(\"tve.getPositions() is not null and it shouldn't be\", tve.getPositions() == null);\n        }\n      }\n    }\n    //Try mapper that ignores offs and positions\n    fsMapper = new FieldSortedTermVectorMapper(true, true, new TermVectorEntryFreqSortedComparator());\n    reader.get(0, fsMapper);\n    map = fsMapper.getFieldToTerms();\n    assertTrue(\"map Size: \" + map.size() + \" is not: \" + testFields.length, map.size() == testFields.length);\n    for (final Map.Entry<String,SortedSet<TermVectorEntry>> entry : map.entrySet()) {\n      SortedSet<TermVectorEntry> sortedSet =  entry.getValue();\n      assertTrue(\"sortedSet Size: \" + sortedSet.size() + \" is not: \" + 4, sortedSet.size() == 4);\n      for (final TermVectorEntry tve : sortedSet) {\n        assertTrue(\"tve is null and it shouldn't be\", tve != null);\n        //Check offsets and positions.\n        assertTrue(\"tve is null and it shouldn't be\", tve != null);\n        String field = tve.getField();\n        if (field.equals(testFields[0])) {\n          //should have offsets\n\n          assertTrue(\"tve.getOffsets() is null and it shouldn't be\", tve.getOffsets() == null);\n          assertTrue(\"tve.getPositions() is null and it shouldn't be\", tve.getPositions() == null);\n        }\n        else if (field.equals(testFields[1])) {\n          //should not have offsets\n\n          assertTrue(\"tve.getOffsets() is not null and it shouldn't be\", tve.getOffsets() == null);\n          assertTrue(\"tve.getPositions() is not null and it shouldn't be\", tve.getPositions() == null);\n        }\n      }\n    }\n\n    // test setDocumentNumber()\n    IndexReader ir = IndexReader.open(dir, true);\n    DocNumAwareMapper docNumAwareMapper = new DocNumAwareMapper();\n    assertEquals(-1, docNumAwareMapper.getDocumentNumber());\n\n    ir.getTermFreqVector(0, docNumAwareMapper);\n    assertEquals(0, docNumAwareMapper.getDocumentNumber());\n    docNumAwareMapper.setDocumentNumber(-1);\n\n    ir.getTermFreqVector(1, docNumAwareMapper);\n    assertEquals(1, docNumAwareMapper.getDocumentNumber());\n    docNumAwareMapper.setDocumentNumber(-1);\n\n    ir.getTermFreqVector(0, \"f1\", docNumAwareMapper);\n    assertEquals(0, docNumAwareMapper.getDocumentNumber());\n    docNumAwareMapper.setDocumentNumber(-1);\n\n    ir.getTermFreqVector(1, \"f2\", docNumAwareMapper);\n    assertEquals(1, docNumAwareMapper.getDocumentNumber());\n    docNumAwareMapper.setDocumentNumber(-1);\n\n    ir.getTermFreqVector(0, \"f1\", docNumAwareMapper);\n    assertEquals(0, docNumAwareMapper.getDocumentNumber());\n\n    ir.close();\n    reader.close();\n  }\n\n","sourceOld":"  public void testMapper() throws IOException {\n    TermVectorsReader reader = new TermVectorsReader(dir, seg, fieldInfos);\n    SortedTermVectorMapper mapper = new SortedTermVectorMapper(new TermVectorEntryFreqSortedComparator());\n    reader.get(0, mapper);\n    SortedSet<TermVectorEntry> set = mapper.getTermVectorEntrySet();\n    assertTrue(\"set is null and it shouldn't be\", set != null);\n    //three fields, 4 terms, all terms are the same\n    assertTrue(\"set Size: \" + set.size() + \" is not: \" + 4, set.size() == 4);\n    //Check offsets and positions\n    for (Iterator<TermVectorEntry> iterator = set.iterator(); iterator.hasNext();) {\n      TermVectorEntry tve =  iterator.next();\n      assertTrue(\"tve is null and it shouldn't be\", tve != null);\n      assertTrue(\"tve.getOffsets() is null and it shouldn't be\", tve.getOffsets() != null);\n      assertTrue(\"tve.getPositions() is null and it shouldn't be\", tve.getPositions() != null);\n\n    }\n\n    mapper = new SortedTermVectorMapper(new TermVectorEntryFreqSortedComparator());\n    reader.get(1, mapper);\n    set = mapper.getTermVectorEntrySet();\n    assertTrue(\"set is null and it shouldn't be\", set != null);\n    //three fields, 4 terms, all terms are the same\n    assertTrue(\"set Size: \" + set.size() + \" is not: \" + 4, set.size() == 4);\n    //Should have offsets and positions b/c we are munging all the fields together\n    for (Iterator<TermVectorEntry> iterator = set.iterator(); iterator.hasNext();) {\n      TermVectorEntry tve = iterator.next();\n      assertTrue(\"tve is null and it shouldn't be\", tve != null);\n      assertTrue(\"tve.getOffsets() is null and it shouldn't be\", tve.getOffsets() != null);\n      assertTrue(\"tve.getPositions() is null and it shouldn't be\", tve.getPositions() != null);\n\n    }\n\n\n    FieldSortedTermVectorMapper fsMapper = new FieldSortedTermVectorMapper(new TermVectorEntryFreqSortedComparator());\n    reader.get(0, fsMapper);\n    Map<String,SortedSet<TermVectorEntry>> map = fsMapper.getFieldToTerms();\n    assertTrue(\"map Size: \" + map.size() + \" is not: \" + testFields.length, map.size() == testFields.length);\n    for (Map.Entry<String,SortedSet<TermVectorEntry>> entry : map.entrySet()) {\n      SortedSet<TermVectorEntry> sortedSet =  entry.getValue();\n      assertTrue(\"sortedSet Size: \" + sortedSet.size() + \" is not: \" + 4, sortedSet.size() == 4);\n      for (final TermVectorEntry tve : sortedSet) {\n        assertTrue(\"tve is null and it shouldn't be\", tve != null);\n        //Check offsets and positions.\n        assertTrue(\"tve is null and it shouldn't be\", tve != null);\n        String field = tve.getField();\n        if (field.equals(testFields[0])) {\n          //should have offsets\n\n          assertTrue(\"tve.getOffsets() is null and it shouldn't be\", tve.getOffsets() != null);\n          assertTrue(\"tve.getPositions() is null and it shouldn't be\", tve.getPositions() != null);\n        }\n        else if (field.equals(testFields[1])) {\n          //should not have offsets\n\n          assertTrue(\"tve.getOffsets() is not null and it shouldn't be\", tve.getOffsets() == null);\n          assertTrue(\"tve.getPositions() is not null and it shouldn't be\", tve.getPositions() == null);\n        }\n      }\n    }\n    //Try mapper that ignores offs and positions\n    fsMapper = new FieldSortedTermVectorMapper(true, true, new TermVectorEntryFreqSortedComparator());\n    reader.get(0, fsMapper);\n    map = fsMapper.getFieldToTerms();\n    assertTrue(\"map Size: \" + map.size() + \" is not: \" + testFields.length, map.size() == testFields.length);\n    for (final Map.Entry<String,SortedSet<TermVectorEntry>> entry : map.entrySet()) {\n      SortedSet<TermVectorEntry> sortedSet =  entry.getValue();\n      assertTrue(\"sortedSet Size: \" + sortedSet.size() + \" is not: \" + 4, sortedSet.size() == 4);\n      for (final TermVectorEntry tve : sortedSet) {\n        assertTrue(\"tve is null and it shouldn't be\", tve != null);\n        //Check offsets and positions.\n        assertTrue(\"tve is null and it shouldn't be\", tve != null);\n        String field = tve.getField();\n        if (field.equals(testFields[0])) {\n          //should have offsets\n\n          assertTrue(\"tve.getOffsets() is null and it shouldn't be\", tve.getOffsets() == null);\n          assertTrue(\"tve.getPositions() is null and it shouldn't be\", tve.getPositions() == null);\n        }\n        else if (field.equals(testFields[1])) {\n          //should not have offsets\n\n          assertTrue(\"tve.getOffsets() is not null and it shouldn't be\", tve.getOffsets() == null);\n          assertTrue(\"tve.getPositions() is not null and it shouldn't be\", tve.getPositions() == null);\n        }\n      }\n    }\n\n    // test setDocumentNumber()\n    IndexReader ir = IndexReader.open(dir, true);\n    DocNumAwareMapper docNumAwareMapper = new DocNumAwareMapper();\n    assertEquals(-1, docNumAwareMapper.getDocumentNumber());\n\n    ir.getTermFreqVector(0, docNumAwareMapper);\n    assertEquals(0, docNumAwareMapper.getDocumentNumber());\n    docNumAwareMapper.setDocumentNumber(-1);\n\n    ir.getTermFreqVector(1, docNumAwareMapper);\n    assertEquals(1, docNumAwareMapper.getDocumentNumber());\n    docNumAwareMapper.setDocumentNumber(-1);\n\n    ir.getTermFreqVector(0, \"f1\", docNumAwareMapper);\n    assertEquals(0, docNumAwareMapper.getDocumentNumber());\n    docNumAwareMapper.setDocumentNumber(-1);\n\n    ir.getTermFreqVector(1, \"f2\", docNumAwareMapper);\n    assertEquals(1, docNumAwareMapper.getDocumentNumber());\n    docNumAwareMapper.setDocumentNumber(-1);\n\n    ir.getTermFreqVector(0, \"f1\", docNumAwareMapper);\n    assertEquals(0, docNumAwareMapper.getDocumentNumber());\n\n    ir.close();\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b6f9be74ca7baaef11857ad002cad40419979516","date":1309449808,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestTermVectorsReader#testMapper().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestTermVectorsReader#testMapper().mjava","sourceNew":"  public void testMapper() throws IOException {\n    TermVectorsReader reader = new TermVectorsReader(dir, seg, fieldInfos, newIOContext(random));\n    SortedTermVectorMapper mapper = new SortedTermVectorMapper(new TermVectorEntryFreqSortedComparator());\n    reader.get(0, mapper);\n    SortedSet<TermVectorEntry> set = mapper.getTermVectorEntrySet();\n    assertTrue(\"set is null and it shouldn't be\", set != null);\n    //three fields, 4 terms, all terms are the same\n    assertTrue(\"set Size: \" + set.size() + \" is not: \" + 4, set.size() == 4);\n    //Check offsets and positions\n    for (Iterator<TermVectorEntry> iterator = set.iterator(); iterator.hasNext();) {\n      TermVectorEntry tve =  iterator.next();\n      assertTrue(\"tve is null and it shouldn't be\", tve != null);\n      assertTrue(\"tve.getOffsets() is null and it shouldn't be\", tve.getOffsets() != null);\n      assertTrue(\"tve.getPositions() is null and it shouldn't be\", tve.getPositions() != null);\n\n    }\n\n    mapper = new SortedTermVectorMapper(new TermVectorEntryFreqSortedComparator());\n    reader.get(1, mapper);\n    set = mapper.getTermVectorEntrySet();\n    assertTrue(\"set is null and it shouldn't be\", set != null);\n    //three fields, 4 terms, all terms are the same\n    assertTrue(\"set Size: \" + set.size() + \" is not: \" + 4, set.size() == 4);\n    //Should have offsets and positions b/c we are munging all the fields together\n    for (Iterator<TermVectorEntry> iterator = set.iterator(); iterator.hasNext();) {\n      TermVectorEntry tve = iterator.next();\n      assertTrue(\"tve is null and it shouldn't be\", tve != null);\n      assertTrue(\"tve.getOffsets() is null and it shouldn't be\", tve.getOffsets() != null);\n      assertTrue(\"tve.getPositions() is null and it shouldn't be\", tve.getPositions() != null);\n\n    }\n\n\n    FieldSortedTermVectorMapper fsMapper = new FieldSortedTermVectorMapper(new TermVectorEntryFreqSortedComparator());\n    reader.get(0, fsMapper);\n    Map<String,SortedSet<TermVectorEntry>> map = fsMapper.getFieldToTerms();\n    assertTrue(\"map Size: \" + map.size() + \" is not: \" + testFields.length, map.size() == testFields.length);\n    for (Map.Entry<String,SortedSet<TermVectorEntry>> entry : map.entrySet()) {\n      SortedSet<TermVectorEntry> sortedSet =  entry.getValue();\n      assertTrue(\"sortedSet Size: \" + sortedSet.size() + \" is not: \" + 4, sortedSet.size() == 4);\n      for (final TermVectorEntry tve : sortedSet) {\n        assertTrue(\"tve is null and it shouldn't be\", tve != null);\n        //Check offsets and positions.\n        assertTrue(\"tve is null and it shouldn't be\", tve != null);\n        String field = tve.getField();\n        if (field.equals(testFields[0])) {\n          //should have offsets\n\n          assertTrue(\"tve.getOffsets() is null and it shouldn't be\", tve.getOffsets() != null);\n          assertTrue(\"tve.getPositions() is null and it shouldn't be\", tve.getPositions() != null);\n        }\n        else if (field.equals(testFields[1])) {\n          //should not have offsets\n\n          assertTrue(\"tve.getOffsets() is not null and it shouldn't be\", tve.getOffsets() == null);\n          assertTrue(\"tve.getPositions() is not null and it shouldn't be\", tve.getPositions() == null);\n        }\n      }\n    }\n    //Try mapper that ignores offs and positions\n    fsMapper = new FieldSortedTermVectorMapper(true, true, new TermVectorEntryFreqSortedComparator());\n    reader.get(0, fsMapper);\n    map = fsMapper.getFieldToTerms();\n    assertTrue(\"map Size: \" + map.size() + \" is not: \" + testFields.length, map.size() == testFields.length);\n    for (final Map.Entry<String,SortedSet<TermVectorEntry>> entry : map.entrySet()) {\n      SortedSet<TermVectorEntry> sortedSet =  entry.getValue();\n      assertTrue(\"sortedSet Size: \" + sortedSet.size() + \" is not: \" + 4, sortedSet.size() == 4);\n      for (final TermVectorEntry tve : sortedSet) {\n        assertTrue(\"tve is null and it shouldn't be\", tve != null);\n        //Check offsets and positions.\n        assertTrue(\"tve is null and it shouldn't be\", tve != null);\n        String field = tve.getField();\n        if (field.equals(testFields[0])) {\n          //should have offsets\n\n          assertTrue(\"tve.getOffsets() is null and it shouldn't be\", tve.getOffsets() == null);\n          assertTrue(\"tve.getPositions() is null and it shouldn't be\", tve.getPositions() == null);\n        }\n        else if (field.equals(testFields[1])) {\n          //should not have offsets\n\n          assertTrue(\"tve.getOffsets() is not null and it shouldn't be\", tve.getOffsets() == null);\n          assertTrue(\"tve.getPositions() is not null and it shouldn't be\", tve.getPositions() == null);\n        }\n      }\n    }\n\n    // test setDocumentNumber()\n    IndexReader ir = IndexReader.open(dir, true);\n    DocNumAwareMapper docNumAwareMapper = new DocNumAwareMapper();\n    assertEquals(-1, docNumAwareMapper.getDocumentNumber());\n\n    ir.getTermFreqVector(0, docNumAwareMapper);\n    assertEquals(0, docNumAwareMapper.getDocumentNumber());\n    docNumAwareMapper.setDocumentNumber(-1);\n\n    ir.getTermFreqVector(1, docNumAwareMapper);\n    assertEquals(1, docNumAwareMapper.getDocumentNumber());\n    docNumAwareMapper.setDocumentNumber(-1);\n\n    ir.getTermFreqVector(0, \"f1\", docNumAwareMapper);\n    assertEquals(0, docNumAwareMapper.getDocumentNumber());\n    docNumAwareMapper.setDocumentNumber(-1);\n\n    ir.getTermFreqVector(1, \"f2\", docNumAwareMapper);\n    assertEquals(1, docNumAwareMapper.getDocumentNumber());\n    docNumAwareMapper.setDocumentNumber(-1);\n\n    ir.getTermFreqVector(0, \"f1\", docNumAwareMapper);\n    assertEquals(0, docNumAwareMapper.getDocumentNumber());\n\n    ir.close();\n    reader.close();\n  }\n\n","sourceOld":"  public void testMapper() throws IOException {\n    TermVectorsReader reader = new TermVectorsReader(dir, seg, fieldInfos, IOContext.READ);\n    SortedTermVectorMapper mapper = new SortedTermVectorMapper(new TermVectorEntryFreqSortedComparator());\n    reader.get(0, mapper);\n    SortedSet<TermVectorEntry> set = mapper.getTermVectorEntrySet();\n    assertTrue(\"set is null and it shouldn't be\", set != null);\n    //three fields, 4 terms, all terms are the same\n    assertTrue(\"set Size: \" + set.size() + \" is not: \" + 4, set.size() == 4);\n    //Check offsets and positions\n    for (Iterator<TermVectorEntry> iterator = set.iterator(); iterator.hasNext();) {\n      TermVectorEntry tve =  iterator.next();\n      assertTrue(\"tve is null and it shouldn't be\", tve != null);\n      assertTrue(\"tve.getOffsets() is null and it shouldn't be\", tve.getOffsets() != null);\n      assertTrue(\"tve.getPositions() is null and it shouldn't be\", tve.getPositions() != null);\n\n    }\n\n    mapper = new SortedTermVectorMapper(new TermVectorEntryFreqSortedComparator());\n    reader.get(1, mapper);\n    set = mapper.getTermVectorEntrySet();\n    assertTrue(\"set is null and it shouldn't be\", set != null);\n    //three fields, 4 terms, all terms are the same\n    assertTrue(\"set Size: \" + set.size() + \" is not: \" + 4, set.size() == 4);\n    //Should have offsets and positions b/c we are munging all the fields together\n    for (Iterator<TermVectorEntry> iterator = set.iterator(); iterator.hasNext();) {\n      TermVectorEntry tve = iterator.next();\n      assertTrue(\"tve is null and it shouldn't be\", tve != null);\n      assertTrue(\"tve.getOffsets() is null and it shouldn't be\", tve.getOffsets() != null);\n      assertTrue(\"tve.getPositions() is null and it shouldn't be\", tve.getPositions() != null);\n\n    }\n\n\n    FieldSortedTermVectorMapper fsMapper = new FieldSortedTermVectorMapper(new TermVectorEntryFreqSortedComparator());\n    reader.get(0, fsMapper);\n    Map<String,SortedSet<TermVectorEntry>> map = fsMapper.getFieldToTerms();\n    assertTrue(\"map Size: \" + map.size() + \" is not: \" + testFields.length, map.size() == testFields.length);\n    for (Map.Entry<String,SortedSet<TermVectorEntry>> entry : map.entrySet()) {\n      SortedSet<TermVectorEntry> sortedSet =  entry.getValue();\n      assertTrue(\"sortedSet Size: \" + sortedSet.size() + \" is not: \" + 4, sortedSet.size() == 4);\n      for (final TermVectorEntry tve : sortedSet) {\n        assertTrue(\"tve is null and it shouldn't be\", tve != null);\n        //Check offsets and positions.\n        assertTrue(\"tve is null and it shouldn't be\", tve != null);\n        String field = tve.getField();\n        if (field.equals(testFields[0])) {\n          //should have offsets\n\n          assertTrue(\"tve.getOffsets() is null and it shouldn't be\", tve.getOffsets() != null);\n          assertTrue(\"tve.getPositions() is null and it shouldn't be\", tve.getPositions() != null);\n        }\n        else if (field.equals(testFields[1])) {\n          //should not have offsets\n\n          assertTrue(\"tve.getOffsets() is not null and it shouldn't be\", tve.getOffsets() == null);\n          assertTrue(\"tve.getPositions() is not null and it shouldn't be\", tve.getPositions() == null);\n        }\n      }\n    }\n    //Try mapper that ignores offs and positions\n    fsMapper = new FieldSortedTermVectorMapper(true, true, new TermVectorEntryFreqSortedComparator());\n    reader.get(0, fsMapper);\n    map = fsMapper.getFieldToTerms();\n    assertTrue(\"map Size: \" + map.size() + \" is not: \" + testFields.length, map.size() == testFields.length);\n    for (final Map.Entry<String,SortedSet<TermVectorEntry>> entry : map.entrySet()) {\n      SortedSet<TermVectorEntry> sortedSet =  entry.getValue();\n      assertTrue(\"sortedSet Size: \" + sortedSet.size() + \" is not: \" + 4, sortedSet.size() == 4);\n      for (final TermVectorEntry tve : sortedSet) {\n        assertTrue(\"tve is null and it shouldn't be\", tve != null);\n        //Check offsets and positions.\n        assertTrue(\"tve is null and it shouldn't be\", tve != null);\n        String field = tve.getField();\n        if (field.equals(testFields[0])) {\n          //should have offsets\n\n          assertTrue(\"tve.getOffsets() is null and it shouldn't be\", tve.getOffsets() == null);\n          assertTrue(\"tve.getPositions() is null and it shouldn't be\", tve.getPositions() == null);\n        }\n        else if (field.equals(testFields[1])) {\n          //should not have offsets\n\n          assertTrue(\"tve.getOffsets() is not null and it shouldn't be\", tve.getOffsets() == null);\n          assertTrue(\"tve.getPositions() is not null and it shouldn't be\", tve.getPositions() == null);\n        }\n      }\n    }\n\n    // test setDocumentNumber()\n    IndexReader ir = IndexReader.open(dir, true);\n    DocNumAwareMapper docNumAwareMapper = new DocNumAwareMapper();\n    assertEquals(-1, docNumAwareMapper.getDocumentNumber());\n\n    ir.getTermFreqVector(0, docNumAwareMapper);\n    assertEquals(0, docNumAwareMapper.getDocumentNumber());\n    docNumAwareMapper.setDocumentNumber(-1);\n\n    ir.getTermFreqVector(1, docNumAwareMapper);\n    assertEquals(1, docNumAwareMapper.getDocumentNumber());\n    docNumAwareMapper.setDocumentNumber(-1);\n\n    ir.getTermFreqVector(0, \"f1\", docNumAwareMapper);\n    assertEquals(0, docNumAwareMapper.getDocumentNumber());\n    docNumAwareMapper.setDocumentNumber(-1);\n\n    ir.getTermFreqVector(1, \"f2\", docNumAwareMapper);\n    assertEquals(1, docNumAwareMapper.getDocumentNumber());\n    docNumAwareMapper.setDocumentNumber(-1);\n\n    ir.getTermFreqVector(0, \"f1\", docNumAwareMapper);\n    assertEquals(0, docNumAwareMapper.getDocumentNumber());\n\n    ir.close();\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ddc4c914be86e34b54f70023f45a60fa7f04e929","date":1310115160,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestTermVectorsReader#testMapper().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestTermVectorsReader#testMapper().mjava","sourceNew":"  public void testMapper() throws IOException {\n    TermVectorsReader reader = new TermVectorsReader(dir, seg, fieldInfos, newIOContext(random));\n    SortedTermVectorMapper mapper = new SortedTermVectorMapper(new TermVectorEntryFreqSortedComparator());\n    reader.get(0, mapper);\n    SortedSet<TermVectorEntry> set = mapper.getTermVectorEntrySet();\n    assertTrue(\"set is null and it shouldn't be\", set != null);\n    //three fields, 4 terms, all terms are the same\n    assertTrue(\"set Size: \" + set.size() + \" is not: \" + 4, set.size() == 4);\n    //Check offsets and positions\n    for (Iterator<TermVectorEntry> iterator = set.iterator(); iterator.hasNext();) {\n      TermVectorEntry tve =  iterator.next();\n      assertTrue(\"tve is null and it shouldn't be\", tve != null);\n      assertTrue(\"tve.getOffsets() is null and it shouldn't be\", tve.getOffsets() != null);\n      assertTrue(\"tve.getPositions() is null and it shouldn't be\", tve.getPositions() != null);\n\n    }\n\n    mapper = new SortedTermVectorMapper(new TermVectorEntryFreqSortedComparator());\n    reader.get(1, mapper);\n    set = mapper.getTermVectorEntrySet();\n    assertTrue(\"set is null and it shouldn't be\", set != null);\n    //three fields, 4 terms, all terms are the same\n    assertTrue(\"set Size: \" + set.size() + \" is not: \" + 4, set.size() == 4);\n    //Should have offsets and positions b/c we are munging all the fields together\n    for (Iterator<TermVectorEntry> iterator = set.iterator(); iterator.hasNext();) {\n      TermVectorEntry tve = iterator.next();\n      assertTrue(\"tve is null and it shouldn't be\", tve != null);\n      assertTrue(\"tve.getOffsets() is null and it shouldn't be\", tve.getOffsets() != null);\n      assertTrue(\"tve.getPositions() is null and it shouldn't be\", tve.getPositions() != null);\n\n    }\n\n\n    FieldSortedTermVectorMapper fsMapper = new FieldSortedTermVectorMapper(new TermVectorEntryFreqSortedComparator());\n    reader.get(0, fsMapper);\n    Map<String,SortedSet<TermVectorEntry>> map = fsMapper.getFieldToTerms();\n    assertTrue(\"map Size: \" + map.size() + \" is not: \" + testFields.length, map.size() == testFields.length);\n    for (Map.Entry<String,SortedSet<TermVectorEntry>> entry : map.entrySet()) {\n      SortedSet<TermVectorEntry> sortedSet =  entry.getValue();\n      assertTrue(\"sortedSet Size: \" + sortedSet.size() + \" is not: \" + 4, sortedSet.size() == 4);\n      for (final TermVectorEntry tve : sortedSet) {\n        assertTrue(\"tve is null and it shouldn't be\", tve != null);\n        //Check offsets and positions.\n        assertTrue(\"tve is null and it shouldn't be\", tve != null);\n        String field = tve.getField();\n        if (field.equals(testFields[0])) {\n          //should have offsets\n\n          assertTrue(\"tve.getOffsets() is null and it shouldn't be\", tve.getOffsets() != null);\n          assertTrue(\"tve.getPositions() is null and it shouldn't be\", tve.getPositions() != null);\n        }\n        else if (field.equals(testFields[1])) {\n          //should not have offsets\n\n          assertTrue(\"tve.getOffsets() is not null and it shouldn't be\", tve.getOffsets() == null);\n          assertTrue(\"tve.getPositions() is not null and it shouldn't be\", tve.getPositions() == null);\n        }\n      }\n    }\n    //Try mapper that ignores offs and positions\n    fsMapper = new FieldSortedTermVectorMapper(true, true, new TermVectorEntryFreqSortedComparator());\n    reader.get(0, fsMapper);\n    map = fsMapper.getFieldToTerms();\n    assertTrue(\"map Size: \" + map.size() + \" is not: \" + testFields.length, map.size() == testFields.length);\n    for (final Map.Entry<String,SortedSet<TermVectorEntry>> entry : map.entrySet()) {\n      SortedSet<TermVectorEntry> sortedSet =  entry.getValue();\n      assertTrue(\"sortedSet Size: \" + sortedSet.size() + \" is not: \" + 4, sortedSet.size() == 4);\n      for (final TermVectorEntry tve : sortedSet) {\n        assertTrue(\"tve is null and it shouldn't be\", tve != null);\n        //Check offsets and positions.\n        assertTrue(\"tve is null and it shouldn't be\", tve != null);\n        String field = tve.getField();\n        if (field.equals(testFields[0])) {\n          //should have offsets\n\n          assertTrue(\"tve.getOffsets() is null and it shouldn't be\", tve.getOffsets() == null);\n          assertTrue(\"tve.getPositions() is null and it shouldn't be\", tve.getPositions() == null);\n        }\n        else if (field.equals(testFields[1])) {\n          //should not have offsets\n\n          assertTrue(\"tve.getOffsets() is not null and it shouldn't be\", tve.getOffsets() == null);\n          assertTrue(\"tve.getPositions() is not null and it shouldn't be\", tve.getPositions() == null);\n        }\n      }\n    }\n\n    // test setDocumentNumber()\n    IndexReader ir = IndexReader.open(dir, true);\n    DocNumAwareMapper docNumAwareMapper = new DocNumAwareMapper();\n    assertEquals(-1, docNumAwareMapper.getDocumentNumber());\n\n    ir.getTermFreqVector(0, docNumAwareMapper);\n    assertEquals(0, docNumAwareMapper.getDocumentNumber());\n    docNumAwareMapper.setDocumentNumber(-1);\n\n    ir.getTermFreqVector(1, docNumAwareMapper);\n    assertEquals(1, docNumAwareMapper.getDocumentNumber());\n    docNumAwareMapper.setDocumentNumber(-1);\n\n    ir.getTermFreqVector(0, \"f1\", docNumAwareMapper);\n    assertEquals(0, docNumAwareMapper.getDocumentNumber());\n    docNumAwareMapper.setDocumentNumber(-1);\n\n    ir.getTermFreqVector(1, \"f2\", docNumAwareMapper);\n    assertEquals(1, docNumAwareMapper.getDocumentNumber());\n    docNumAwareMapper.setDocumentNumber(-1);\n\n    ir.getTermFreqVector(0, \"f1\", docNumAwareMapper);\n    assertEquals(0, docNumAwareMapper.getDocumentNumber());\n\n    ir.close();\n    reader.close();\n  }\n\n","sourceOld":"  public void testMapper() throws IOException {\n    TermVectorsReader reader = new TermVectorsReader(dir, seg, fieldInfos);\n    SortedTermVectorMapper mapper = new SortedTermVectorMapper(new TermVectorEntryFreqSortedComparator());\n    reader.get(0, mapper);\n    SortedSet<TermVectorEntry> set = mapper.getTermVectorEntrySet();\n    assertTrue(\"set is null and it shouldn't be\", set != null);\n    //three fields, 4 terms, all terms are the same\n    assertTrue(\"set Size: \" + set.size() + \" is not: \" + 4, set.size() == 4);\n    //Check offsets and positions\n    for (Iterator<TermVectorEntry> iterator = set.iterator(); iterator.hasNext();) {\n      TermVectorEntry tve =  iterator.next();\n      assertTrue(\"tve is null and it shouldn't be\", tve != null);\n      assertTrue(\"tve.getOffsets() is null and it shouldn't be\", tve.getOffsets() != null);\n      assertTrue(\"tve.getPositions() is null and it shouldn't be\", tve.getPositions() != null);\n\n    }\n\n    mapper = new SortedTermVectorMapper(new TermVectorEntryFreqSortedComparator());\n    reader.get(1, mapper);\n    set = mapper.getTermVectorEntrySet();\n    assertTrue(\"set is null and it shouldn't be\", set != null);\n    //three fields, 4 terms, all terms are the same\n    assertTrue(\"set Size: \" + set.size() + \" is not: \" + 4, set.size() == 4);\n    //Should have offsets and positions b/c we are munging all the fields together\n    for (Iterator<TermVectorEntry> iterator = set.iterator(); iterator.hasNext();) {\n      TermVectorEntry tve = iterator.next();\n      assertTrue(\"tve is null and it shouldn't be\", tve != null);\n      assertTrue(\"tve.getOffsets() is null and it shouldn't be\", tve.getOffsets() != null);\n      assertTrue(\"tve.getPositions() is null and it shouldn't be\", tve.getPositions() != null);\n\n    }\n\n\n    FieldSortedTermVectorMapper fsMapper = new FieldSortedTermVectorMapper(new TermVectorEntryFreqSortedComparator());\n    reader.get(0, fsMapper);\n    Map<String,SortedSet<TermVectorEntry>> map = fsMapper.getFieldToTerms();\n    assertTrue(\"map Size: \" + map.size() + \" is not: \" + testFields.length, map.size() == testFields.length);\n    for (Map.Entry<String,SortedSet<TermVectorEntry>> entry : map.entrySet()) {\n      SortedSet<TermVectorEntry> sortedSet =  entry.getValue();\n      assertTrue(\"sortedSet Size: \" + sortedSet.size() + \" is not: \" + 4, sortedSet.size() == 4);\n      for (final TermVectorEntry tve : sortedSet) {\n        assertTrue(\"tve is null and it shouldn't be\", tve != null);\n        //Check offsets and positions.\n        assertTrue(\"tve is null and it shouldn't be\", tve != null);\n        String field = tve.getField();\n        if (field.equals(testFields[0])) {\n          //should have offsets\n\n          assertTrue(\"tve.getOffsets() is null and it shouldn't be\", tve.getOffsets() != null);\n          assertTrue(\"tve.getPositions() is null and it shouldn't be\", tve.getPositions() != null);\n        }\n        else if (field.equals(testFields[1])) {\n          //should not have offsets\n\n          assertTrue(\"tve.getOffsets() is not null and it shouldn't be\", tve.getOffsets() == null);\n          assertTrue(\"tve.getPositions() is not null and it shouldn't be\", tve.getPositions() == null);\n        }\n      }\n    }\n    //Try mapper that ignores offs and positions\n    fsMapper = new FieldSortedTermVectorMapper(true, true, new TermVectorEntryFreqSortedComparator());\n    reader.get(0, fsMapper);\n    map = fsMapper.getFieldToTerms();\n    assertTrue(\"map Size: \" + map.size() + \" is not: \" + testFields.length, map.size() == testFields.length);\n    for (final Map.Entry<String,SortedSet<TermVectorEntry>> entry : map.entrySet()) {\n      SortedSet<TermVectorEntry> sortedSet =  entry.getValue();\n      assertTrue(\"sortedSet Size: \" + sortedSet.size() + \" is not: \" + 4, sortedSet.size() == 4);\n      for (final TermVectorEntry tve : sortedSet) {\n        assertTrue(\"tve is null and it shouldn't be\", tve != null);\n        //Check offsets and positions.\n        assertTrue(\"tve is null and it shouldn't be\", tve != null);\n        String field = tve.getField();\n        if (field.equals(testFields[0])) {\n          //should have offsets\n\n          assertTrue(\"tve.getOffsets() is null and it shouldn't be\", tve.getOffsets() == null);\n          assertTrue(\"tve.getPositions() is null and it shouldn't be\", tve.getPositions() == null);\n        }\n        else if (field.equals(testFields[1])) {\n          //should not have offsets\n\n          assertTrue(\"tve.getOffsets() is not null and it shouldn't be\", tve.getOffsets() == null);\n          assertTrue(\"tve.getPositions() is not null and it shouldn't be\", tve.getPositions() == null);\n        }\n      }\n    }\n\n    // test setDocumentNumber()\n    IndexReader ir = IndexReader.open(dir, true);\n    DocNumAwareMapper docNumAwareMapper = new DocNumAwareMapper();\n    assertEquals(-1, docNumAwareMapper.getDocumentNumber());\n\n    ir.getTermFreqVector(0, docNumAwareMapper);\n    assertEquals(0, docNumAwareMapper.getDocumentNumber());\n    docNumAwareMapper.setDocumentNumber(-1);\n\n    ir.getTermFreqVector(1, docNumAwareMapper);\n    assertEquals(1, docNumAwareMapper.getDocumentNumber());\n    docNumAwareMapper.setDocumentNumber(-1);\n\n    ir.getTermFreqVector(0, \"f1\", docNumAwareMapper);\n    assertEquals(0, docNumAwareMapper.getDocumentNumber());\n    docNumAwareMapper.setDocumentNumber(-1);\n\n    ir.getTermFreqVector(1, \"f2\", docNumAwareMapper);\n    assertEquals(1, docNumAwareMapper.getDocumentNumber());\n    docNumAwareMapper.setDocumentNumber(-1);\n\n    ir.getTermFreqVector(0, \"f1\", docNumAwareMapper);\n    assertEquals(0, docNumAwareMapper.getDocumentNumber());\n\n    ir.close();\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5d004d0e0b3f65bb40da76d476d659d7888270e8","date":1310158940,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestTermVectorsReader#testMapper().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestTermVectorsReader#testMapper().mjava","sourceNew":"  public void testMapper() throws IOException {\n    TermVectorsReader reader = new TermVectorsReader(dir, seg, fieldInfos, newIOContext(random));\n    SortedTermVectorMapper mapper = new SortedTermVectorMapper(new TermVectorEntryFreqSortedComparator());\n    reader.get(0, mapper);\n    SortedSet<TermVectorEntry> set = mapper.getTermVectorEntrySet();\n    assertTrue(\"set is null and it shouldn't be\", set != null);\n    //three fields, 4 terms, all terms are the same\n    assertTrue(\"set Size: \" + set.size() + \" is not: \" + 4, set.size() == 4);\n    //Check offsets and positions\n    for (Iterator<TermVectorEntry> iterator = set.iterator(); iterator.hasNext();) {\n      TermVectorEntry tve =  iterator.next();\n      assertTrue(\"tve is null and it shouldn't be\", tve != null);\n      assertTrue(\"tve.getOffsets() is null and it shouldn't be\", tve.getOffsets() != null);\n      assertTrue(\"tve.getPositions() is null and it shouldn't be\", tve.getPositions() != null);\n\n    }\n\n    mapper = new SortedTermVectorMapper(new TermVectorEntryFreqSortedComparator());\n    reader.get(1, mapper);\n    set = mapper.getTermVectorEntrySet();\n    assertTrue(\"set is null and it shouldn't be\", set != null);\n    //three fields, 4 terms, all terms are the same\n    assertTrue(\"set Size: \" + set.size() + \" is not: \" + 4, set.size() == 4);\n    //Should have offsets and positions b/c we are munging all the fields together\n    for (Iterator<TermVectorEntry> iterator = set.iterator(); iterator.hasNext();) {\n      TermVectorEntry tve = iterator.next();\n      assertTrue(\"tve is null and it shouldn't be\", tve != null);\n      assertTrue(\"tve.getOffsets() is null and it shouldn't be\", tve.getOffsets() != null);\n      assertTrue(\"tve.getPositions() is null and it shouldn't be\", tve.getPositions() != null);\n\n    }\n\n\n    FieldSortedTermVectorMapper fsMapper = new FieldSortedTermVectorMapper(new TermVectorEntryFreqSortedComparator());\n    reader.get(0, fsMapper);\n    Map<String,SortedSet<TermVectorEntry>> map = fsMapper.getFieldToTerms();\n    assertTrue(\"map Size: \" + map.size() + \" is not: \" + testFields.length, map.size() == testFields.length);\n    for (Map.Entry<String,SortedSet<TermVectorEntry>> entry : map.entrySet()) {\n      SortedSet<TermVectorEntry> sortedSet =  entry.getValue();\n      assertTrue(\"sortedSet Size: \" + sortedSet.size() + \" is not: \" + 4, sortedSet.size() == 4);\n      for (final TermVectorEntry tve : sortedSet) {\n        assertTrue(\"tve is null and it shouldn't be\", tve != null);\n        //Check offsets and positions.\n        assertTrue(\"tve is null and it shouldn't be\", tve != null);\n        String field = tve.getField();\n        if (field.equals(testFields[0])) {\n          //should have offsets\n\n          assertTrue(\"tve.getOffsets() is null and it shouldn't be\", tve.getOffsets() != null);\n          assertTrue(\"tve.getPositions() is null and it shouldn't be\", tve.getPositions() != null);\n        }\n        else if (field.equals(testFields[1])) {\n          //should not have offsets\n\n          assertTrue(\"tve.getOffsets() is not null and it shouldn't be\", tve.getOffsets() == null);\n          assertTrue(\"tve.getPositions() is not null and it shouldn't be\", tve.getPositions() == null);\n        }\n      }\n    }\n    //Try mapper that ignores offs and positions\n    fsMapper = new FieldSortedTermVectorMapper(true, true, new TermVectorEntryFreqSortedComparator());\n    reader.get(0, fsMapper);\n    map = fsMapper.getFieldToTerms();\n    assertTrue(\"map Size: \" + map.size() + \" is not: \" + testFields.length, map.size() == testFields.length);\n    for (final Map.Entry<String,SortedSet<TermVectorEntry>> entry : map.entrySet()) {\n      SortedSet<TermVectorEntry> sortedSet =  entry.getValue();\n      assertTrue(\"sortedSet Size: \" + sortedSet.size() + \" is not: \" + 4, sortedSet.size() == 4);\n      for (final TermVectorEntry tve : sortedSet) {\n        assertTrue(\"tve is null and it shouldn't be\", tve != null);\n        //Check offsets and positions.\n        assertTrue(\"tve is null and it shouldn't be\", tve != null);\n        String field = tve.getField();\n        if (field.equals(testFields[0])) {\n          //should have offsets\n\n          assertTrue(\"tve.getOffsets() is null and it shouldn't be\", tve.getOffsets() == null);\n          assertTrue(\"tve.getPositions() is null and it shouldn't be\", tve.getPositions() == null);\n        }\n        else if (field.equals(testFields[1])) {\n          //should not have offsets\n\n          assertTrue(\"tve.getOffsets() is not null and it shouldn't be\", tve.getOffsets() == null);\n          assertTrue(\"tve.getPositions() is not null and it shouldn't be\", tve.getPositions() == null);\n        }\n      }\n    }\n\n    // test setDocumentNumber()\n    IndexReader ir = IndexReader.open(dir, true);\n    DocNumAwareMapper docNumAwareMapper = new DocNumAwareMapper();\n    assertEquals(-1, docNumAwareMapper.getDocumentNumber());\n\n    ir.getTermFreqVector(0, docNumAwareMapper);\n    assertEquals(0, docNumAwareMapper.getDocumentNumber());\n    docNumAwareMapper.setDocumentNumber(-1);\n\n    ir.getTermFreqVector(1, docNumAwareMapper);\n    assertEquals(1, docNumAwareMapper.getDocumentNumber());\n    docNumAwareMapper.setDocumentNumber(-1);\n\n    ir.getTermFreqVector(0, \"f1\", docNumAwareMapper);\n    assertEquals(0, docNumAwareMapper.getDocumentNumber());\n    docNumAwareMapper.setDocumentNumber(-1);\n\n    ir.getTermFreqVector(1, \"f2\", docNumAwareMapper);\n    assertEquals(1, docNumAwareMapper.getDocumentNumber());\n    docNumAwareMapper.setDocumentNumber(-1);\n\n    ir.getTermFreqVector(0, \"f1\", docNumAwareMapper);\n    assertEquals(0, docNumAwareMapper.getDocumentNumber());\n\n    ir.close();\n    reader.close();\n  }\n\n","sourceOld":"  public void testMapper() throws IOException {\n    TermVectorsReader reader = new TermVectorsReader(dir, seg, fieldInfos);\n    SortedTermVectorMapper mapper = new SortedTermVectorMapper(new TermVectorEntryFreqSortedComparator());\n    reader.get(0, mapper);\n    SortedSet<TermVectorEntry> set = mapper.getTermVectorEntrySet();\n    assertTrue(\"set is null and it shouldn't be\", set != null);\n    //three fields, 4 terms, all terms are the same\n    assertTrue(\"set Size: \" + set.size() + \" is not: \" + 4, set.size() == 4);\n    //Check offsets and positions\n    for (Iterator<TermVectorEntry> iterator = set.iterator(); iterator.hasNext();) {\n      TermVectorEntry tve =  iterator.next();\n      assertTrue(\"tve is null and it shouldn't be\", tve != null);\n      assertTrue(\"tve.getOffsets() is null and it shouldn't be\", tve.getOffsets() != null);\n      assertTrue(\"tve.getPositions() is null and it shouldn't be\", tve.getPositions() != null);\n\n    }\n\n    mapper = new SortedTermVectorMapper(new TermVectorEntryFreqSortedComparator());\n    reader.get(1, mapper);\n    set = mapper.getTermVectorEntrySet();\n    assertTrue(\"set is null and it shouldn't be\", set != null);\n    //three fields, 4 terms, all terms are the same\n    assertTrue(\"set Size: \" + set.size() + \" is not: \" + 4, set.size() == 4);\n    //Should have offsets and positions b/c we are munging all the fields together\n    for (Iterator<TermVectorEntry> iterator = set.iterator(); iterator.hasNext();) {\n      TermVectorEntry tve = iterator.next();\n      assertTrue(\"tve is null and it shouldn't be\", tve != null);\n      assertTrue(\"tve.getOffsets() is null and it shouldn't be\", tve.getOffsets() != null);\n      assertTrue(\"tve.getPositions() is null and it shouldn't be\", tve.getPositions() != null);\n\n    }\n\n\n    FieldSortedTermVectorMapper fsMapper = new FieldSortedTermVectorMapper(new TermVectorEntryFreqSortedComparator());\n    reader.get(0, fsMapper);\n    Map<String,SortedSet<TermVectorEntry>> map = fsMapper.getFieldToTerms();\n    assertTrue(\"map Size: \" + map.size() + \" is not: \" + testFields.length, map.size() == testFields.length);\n    for (Map.Entry<String,SortedSet<TermVectorEntry>> entry : map.entrySet()) {\n      SortedSet<TermVectorEntry> sortedSet =  entry.getValue();\n      assertTrue(\"sortedSet Size: \" + sortedSet.size() + \" is not: \" + 4, sortedSet.size() == 4);\n      for (final TermVectorEntry tve : sortedSet) {\n        assertTrue(\"tve is null and it shouldn't be\", tve != null);\n        //Check offsets and positions.\n        assertTrue(\"tve is null and it shouldn't be\", tve != null);\n        String field = tve.getField();\n        if (field.equals(testFields[0])) {\n          //should have offsets\n\n          assertTrue(\"tve.getOffsets() is null and it shouldn't be\", tve.getOffsets() != null);\n          assertTrue(\"tve.getPositions() is null and it shouldn't be\", tve.getPositions() != null);\n        }\n        else if (field.equals(testFields[1])) {\n          //should not have offsets\n\n          assertTrue(\"tve.getOffsets() is not null and it shouldn't be\", tve.getOffsets() == null);\n          assertTrue(\"tve.getPositions() is not null and it shouldn't be\", tve.getPositions() == null);\n        }\n      }\n    }\n    //Try mapper that ignores offs and positions\n    fsMapper = new FieldSortedTermVectorMapper(true, true, new TermVectorEntryFreqSortedComparator());\n    reader.get(0, fsMapper);\n    map = fsMapper.getFieldToTerms();\n    assertTrue(\"map Size: \" + map.size() + \" is not: \" + testFields.length, map.size() == testFields.length);\n    for (final Map.Entry<String,SortedSet<TermVectorEntry>> entry : map.entrySet()) {\n      SortedSet<TermVectorEntry> sortedSet =  entry.getValue();\n      assertTrue(\"sortedSet Size: \" + sortedSet.size() + \" is not: \" + 4, sortedSet.size() == 4);\n      for (final TermVectorEntry tve : sortedSet) {\n        assertTrue(\"tve is null and it shouldn't be\", tve != null);\n        //Check offsets and positions.\n        assertTrue(\"tve is null and it shouldn't be\", tve != null);\n        String field = tve.getField();\n        if (field.equals(testFields[0])) {\n          //should have offsets\n\n          assertTrue(\"tve.getOffsets() is null and it shouldn't be\", tve.getOffsets() == null);\n          assertTrue(\"tve.getPositions() is null and it shouldn't be\", tve.getPositions() == null);\n        }\n        else if (field.equals(testFields[1])) {\n          //should not have offsets\n\n          assertTrue(\"tve.getOffsets() is not null and it shouldn't be\", tve.getOffsets() == null);\n          assertTrue(\"tve.getPositions() is not null and it shouldn't be\", tve.getPositions() == null);\n        }\n      }\n    }\n\n    // test setDocumentNumber()\n    IndexReader ir = IndexReader.open(dir, true);\n    DocNumAwareMapper docNumAwareMapper = new DocNumAwareMapper();\n    assertEquals(-1, docNumAwareMapper.getDocumentNumber());\n\n    ir.getTermFreqVector(0, docNumAwareMapper);\n    assertEquals(0, docNumAwareMapper.getDocumentNumber());\n    docNumAwareMapper.setDocumentNumber(-1);\n\n    ir.getTermFreqVector(1, docNumAwareMapper);\n    assertEquals(1, docNumAwareMapper.getDocumentNumber());\n    docNumAwareMapper.setDocumentNumber(-1);\n\n    ir.getTermFreqVector(0, \"f1\", docNumAwareMapper);\n    assertEquals(0, docNumAwareMapper.getDocumentNumber());\n    docNumAwareMapper.setDocumentNumber(-1);\n\n    ir.getTermFreqVector(1, \"f2\", docNumAwareMapper);\n    assertEquals(1, docNumAwareMapper.getDocumentNumber());\n    docNumAwareMapper.setDocumentNumber(-1);\n\n    ir.getTermFreqVector(0, \"f1\", docNumAwareMapper);\n    assertEquals(0, docNumAwareMapper.getDocumentNumber());\n\n    ir.close();\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3cc749c053615f5871f3b95715fe292f34e70a53","date":1321470575,"type":4,"author":"Robert Muir","isMerge":false,"pathNew":"/dev/null","pathOld":"lucene/src/test/org/apache/lucene/index/TestTermVectorsReader#testMapper().mjava","sourceNew":null,"sourceOld":"  public void testMapper() throws IOException {\n    TermVectorsReader reader = new TermVectorsReader(dir, seg, fieldInfos, newIOContext(random));\n    SortedTermVectorMapper mapper = new SortedTermVectorMapper(new TermVectorEntryFreqSortedComparator());\n    reader.get(0, mapper);\n    SortedSet<TermVectorEntry> set = mapper.getTermVectorEntrySet();\n    assertTrue(\"set is null and it shouldn't be\", set != null);\n    //three fields, 4 terms, all terms are the same\n    assertTrue(\"set Size: \" + set.size() + \" is not: \" + 4, set.size() == 4);\n    //Check offsets and positions\n    for (Iterator<TermVectorEntry> iterator = set.iterator(); iterator.hasNext();) {\n      TermVectorEntry tve =  iterator.next();\n      assertTrue(\"tve is null and it shouldn't be\", tve != null);\n      assertTrue(\"tve.getOffsets() is null and it shouldn't be\", tve.getOffsets() != null);\n      assertTrue(\"tve.getPositions() is null and it shouldn't be\", tve.getPositions() != null);\n\n    }\n\n    mapper = new SortedTermVectorMapper(new TermVectorEntryFreqSortedComparator());\n    reader.get(1, mapper);\n    set = mapper.getTermVectorEntrySet();\n    assertTrue(\"set is null and it shouldn't be\", set != null);\n    //three fields, 4 terms, all terms are the same\n    assertTrue(\"set Size: \" + set.size() + \" is not: \" + 4, set.size() == 4);\n    //Should have offsets and positions b/c we are munging all the fields together\n    for (Iterator<TermVectorEntry> iterator = set.iterator(); iterator.hasNext();) {\n      TermVectorEntry tve = iterator.next();\n      assertTrue(\"tve is null and it shouldn't be\", tve != null);\n      assertTrue(\"tve.getOffsets() is null and it shouldn't be\", tve.getOffsets() != null);\n      assertTrue(\"tve.getPositions() is null and it shouldn't be\", tve.getPositions() != null);\n\n    }\n\n\n    FieldSortedTermVectorMapper fsMapper = new FieldSortedTermVectorMapper(new TermVectorEntryFreqSortedComparator());\n    reader.get(0, fsMapper);\n    Map<String,SortedSet<TermVectorEntry>> map = fsMapper.getFieldToTerms();\n    assertTrue(\"map Size: \" + map.size() + \" is not: \" + testFields.length, map.size() == testFields.length);\n    for (Map.Entry<String,SortedSet<TermVectorEntry>> entry : map.entrySet()) {\n      SortedSet<TermVectorEntry> sortedSet =  entry.getValue();\n      assertTrue(\"sortedSet Size: \" + sortedSet.size() + \" is not: \" + 4, sortedSet.size() == 4);\n      for (final TermVectorEntry tve : sortedSet) {\n        assertTrue(\"tve is null and it shouldn't be\", tve != null);\n        //Check offsets and positions.\n        assertTrue(\"tve is null and it shouldn't be\", tve != null);\n        String field = tve.getField();\n        if (field.equals(testFields[0])) {\n          //should have offsets\n\n          assertTrue(\"tve.getOffsets() is null and it shouldn't be\", tve.getOffsets() != null);\n          assertTrue(\"tve.getPositions() is null and it shouldn't be\", tve.getPositions() != null);\n        }\n        else if (field.equals(testFields[1])) {\n          //should not have offsets\n\n          assertTrue(\"tve.getOffsets() is not null and it shouldn't be\", tve.getOffsets() == null);\n          assertTrue(\"tve.getPositions() is not null and it shouldn't be\", tve.getPositions() == null);\n        }\n      }\n    }\n    //Try mapper that ignores offs and positions\n    fsMapper = new FieldSortedTermVectorMapper(true, true, new TermVectorEntryFreqSortedComparator());\n    reader.get(0, fsMapper);\n    map = fsMapper.getFieldToTerms();\n    assertTrue(\"map Size: \" + map.size() + \" is not: \" + testFields.length, map.size() == testFields.length);\n    for (final Map.Entry<String,SortedSet<TermVectorEntry>> entry : map.entrySet()) {\n      SortedSet<TermVectorEntry> sortedSet =  entry.getValue();\n      assertTrue(\"sortedSet Size: \" + sortedSet.size() + \" is not: \" + 4, sortedSet.size() == 4);\n      for (final TermVectorEntry tve : sortedSet) {\n        assertTrue(\"tve is null and it shouldn't be\", tve != null);\n        //Check offsets and positions.\n        assertTrue(\"tve is null and it shouldn't be\", tve != null);\n        String field = tve.getField();\n        if (field.equals(testFields[0])) {\n          //should have offsets\n\n          assertTrue(\"tve.getOffsets() is null and it shouldn't be\", tve.getOffsets() == null);\n          assertTrue(\"tve.getPositions() is null and it shouldn't be\", tve.getPositions() == null);\n        }\n        else if (field.equals(testFields[1])) {\n          //should not have offsets\n\n          assertTrue(\"tve.getOffsets() is not null and it shouldn't be\", tve.getOffsets() == null);\n          assertTrue(\"tve.getPositions() is not null and it shouldn't be\", tve.getPositions() == null);\n        }\n      }\n    }\n\n    // test setDocumentNumber()\n    IndexReader ir = IndexReader.open(dir, true);\n    DocNumAwareMapper docNumAwareMapper = new DocNumAwareMapper();\n    assertEquals(-1, docNumAwareMapper.getDocumentNumber());\n\n    ir.getTermFreqVector(0, docNumAwareMapper);\n    assertEquals(0, docNumAwareMapper.getDocumentNumber());\n    docNumAwareMapper.setDocumentNumber(-1);\n\n    ir.getTermFreqVector(1, docNumAwareMapper);\n    assertEquals(1, docNumAwareMapper.getDocumentNumber());\n    docNumAwareMapper.setDocumentNumber(-1);\n\n    ir.getTermFreqVector(0, \"f1\", docNumAwareMapper);\n    assertEquals(0, docNumAwareMapper.getDocumentNumber());\n    docNumAwareMapper.setDocumentNumber(-1);\n\n    ir.getTermFreqVector(1, \"f2\", docNumAwareMapper);\n    assertEquals(1, docNumAwareMapper.getDocumentNumber());\n    docNumAwareMapper.setDocumentNumber(-1);\n\n    ir.getTermFreqVector(0, \"f1\", docNumAwareMapper);\n    assertEquals(0, docNumAwareMapper.getDocumentNumber());\n\n    ir.close();\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"ab9633cb67e3c0aec3c066147a23a957d6e7ad8c":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"b6f9be74ca7baaef11857ad002cad40419979516":["639c36565ce03aed5b0fce7c9e4448e53a1f7efd"],"3cc749c053615f5871f3b95715fe292f34e70a53":["ddc4c914be86e34b54f70023f45a60fa7f04e929"],"639c36565ce03aed5b0fce7c9e4448e53a1f7efd":["ab9633cb67e3c0aec3c066147a23a957d6e7ad8c"],"5d004d0e0b3f65bb40da76d476d659d7888270e8":["ab9633cb67e3c0aec3c066147a23a957d6e7ad8c","ddc4c914be86e34b54f70023f45a60fa7f04e929"],"ddc4c914be86e34b54f70023f45a60fa7f04e929":["ab9633cb67e3c0aec3c066147a23a957d6e7ad8c","b6f9be74ca7baaef11857ad002cad40419979516"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":["9454a6510e2db155fb01faa5c049b06ece95fab9","ab9633cb67e3c0aec3c066147a23a957d6e7ad8c"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["3cc749c053615f5871f3b95715fe292f34e70a53"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"ab9633cb67e3c0aec3c066147a23a957d6e7ad8c":["639c36565ce03aed5b0fce7c9e4448e53a1f7efd","5d004d0e0b3f65bb40da76d476d659d7888270e8","ddc4c914be86e34b54f70023f45a60fa7f04e929","7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"b6f9be74ca7baaef11857ad002cad40419979516":["ddc4c914be86e34b54f70023f45a60fa7f04e929"],"639c36565ce03aed5b0fce7c9e4448e53a1f7efd":["b6f9be74ca7baaef11857ad002cad40419979516"],"3cc749c053615f5871f3b95715fe292f34e70a53":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"5d004d0e0b3f65bb40da76d476d659d7888270e8":[],"ddc4c914be86e34b54f70023f45a60fa7f04e929":["3cc749c053615f5871f3b95715fe292f34e70a53","5d004d0e0b3f65bb40da76d476d659d7888270e8"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":[],"9454a6510e2db155fb01faa5c049b06ece95fab9":["ab9633cb67e3c0aec3c066147a23a957d6e7ad8c","7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["5d004d0e0b3f65bb40da76d476d659d7888270e8","7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}