{"path":"solr/core/src/java/org/apache/solr/uninverting/UninvertingReader#wrap(LeafReader,Function[String,Type]).mjava","commits":[{"id":"a07eeba66d4090af0095b50cbd1795a3d6182c1d","date":1538797239,"type":1,"author":"David Smiley","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/uninverting/UninvertingReader#wrap(LeafReader,Function[String,Type]).mjava","pathOld":"solr/core/src/java/org/apache/solr/uninverting/UninvertingReader#UninvertingReader(LeafReader,Map[String,Type]).mjava","sourceNew":"  /**\n   * Create a new UninvertingReader with the specified mapping, wrapped around the input.  It may be deemed that there\n   * is no mapping to do, in which case the input is returned.\n   * <p>\n   * Expert: This should almost never be used. Use {@link #wrap(DirectoryReader, Function)} instead.\n   *\n   * @lucene.internal\n   */\n  public static LeafReader wrap(LeafReader in, Function<String, Type> mapping) {\n    boolean wrap = false;\n\n    // Calculate a new FieldInfos that has DocValuesType where we didn't before\n    ArrayList<FieldInfo> newFieldInfos = new ArrayList<>(in.getFieldInfos().size());\n    for (FieldInfo fi : in.getFieldInfos()) {\n      DocValuesType type = fi.getDocValuesType();\n      // fields which currently don't have docValues, but are uninvertable (indexed or points data present)\n      if (type == DocValuesType.NONE &&\n          (fi.getIndexOptions() != IndexOptions.NONE || (fi.getPointNumBytes() > 0 && fi.getPointDimensionCount() == 1))) {\n        Type t = mapping.apply(fi.name); // could definitely return null, thus still can't uninvert it\n        if (t != null) {\n          if (t == Type.INTEGER_POINT || t == Type.LONG_POINT || t == Type.FLOAT_POINT || t == Type.DOUBLE_POINT) {\n            // type uses points\n            if (fi.getPointDimensionCount() == 0) {\n              continue;\n            }\n          } else {\n            // type uses inverted index\n            if (fi.getIndexOptions() == IndexOptions.NONE) {\n              continue;\n            }\n          }\n          switch(t) {\n            case INTEGER_POINT:\n            case LONG_POINT:\n            case FLOAT_POINT:\n            case DOUBLE_POINT:\n            case LEGACY_INTEGER:\n            case LEGACY_LONG:\n            case LEGACY_FLOAT:\n            case LEGACY_DOUBLE:\n              type = DocValuesType.NUMERIC;\n              break;\n            case BINARY:\n              type = DocValuesType.BINARY;\n              break;\n            case SORTED:\n              type = DocValuesType.SORTED;\n              break;\n            case SORTED_SET_BINARY:\n            case SORTED_SET_INTEGER:\n            case SORTED_SET_FLOAT:\n            case SORTED_SET_LONG:\n            case SORTED_SET_DOUBLE:\n              type = DocValuesType.SORTED_SET;\n              break;\n            default:\n              throw new AssertionError();\n          }\n        }\n      }\n      if (type != fi.getDocValuesType()) { // we changed it\n        wrap = true;\n        newFieldInfos.add(new FieldInfo(fi.name, fi.number, fi.hasVectors(), fi.omitsNorms(),\n            fi.hasPayloads(), fi.getIndexOptions(), type, fi.getDocValuesGen(), fi.attributes(),\n            fi.getPointDimensionCount(), fi.getPointNumBytes(), fi.isSoftDeletesField()));\n      } else {\n        newFieldInfos.add(fi);\n      }\n    }\n    if (!wrap) {\n      return in;\n    } else {\n      FieldInfos fieldInfos = new FieldInfos(newFieldInfos.toArray(new FieldInfo[newFieldInfos.size()]));\n      return new UninvertingReader(in, mapping, fieldInfos);\n    }\n  }\n\n","sourceOld":"  /** \n   * Create a new UninvertingReader with the specified mapping \n   * <p>\n   * Expert: This should almost never be used. Use {@link #wrap(DirectoryReader, Function)}\n   * instead.\n   *  \n   * @lucene.internal\n   */\n  public UninvertingReader(LeafReader in, Map<String,Type> mapping) {\n    super(in);\n    this.mapping = mapping;\n    ArrayList<FieldInfo> filteredInfos = new ArrayList<>();\n    for (FieldInfo fi : in.getFieldInfos()) {\n      DocValuesType type = fi.getDocValuesType();\n      if (type == DocValuesType.NONE) {        \n        Type t = mapping.get(fi.name);\n        if (t != null) {\n          if (t == Type.INTEGER_POINT || t == Type.LONG_POINT || t == Type.FLOAT_POINT || t == Type.DOUBLE_POINT) {\n            // type uses points\n            if (fi.getPointDimensionCount() == 0) {\n              continue;\n            }\n          } else {\n            // type uses inverted index\n            if (fi.getIndexOptions() == IndexOptions.NONE) {\n              continue;\n            }\n          }\n          switch(t) {\n            case INTEGER_POINT:\n            case LONG_POINT:\n            case FLOAT_POINT:\n            case DOUBLE_POINT:\n            case LEGACY_INTEGER:\n            case LEGACY_LONG:\n            case LEGACY_FLOAT:\n            case LEGACY_DOUBLE:\n              type = DocValuesType.NUMERIC;\n              break;\n            case BINARY:\n              type = DocValuesType.BINARY;\n              break;\n            case SORTED:\n              type = DocValuesType.SORTED;\n              break;\n            case SORTED_SET_BINARY:\n            case SORTED_SET_INTEGER:\n            case SORTED_SET_FLOAT:\n            case SORTED_SET_LONG:\n            case SORTED_SET_DOUBLE:\n              type = DocValuesType.SORTED_SET;\n              break;\n            default:\n              throw new AssertionError();\n          }\n        }\n      }\n      filteredInfos.add(new FieldInfo(fi.name, fi.number, fi.hasVectors(), fi.omitsNorms(),\n          fi.hasPayloads(), fi.getIndexOptions(), type, fi.getDocValuesGen(), fi.attributes(),\n          fi.getPointDimensionCount(), fi.getPointNumBytes(), fi.isSoftDeletesField()));\n    }\n    fieldInfos = new FieldInfos(filteredInfos.toArray(new FieldInfo[filteredInfos.size()]));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f6652c943595e92c187ee904c382863013eae28f","date":1539042663,"type":3,"author":"Nicholas Knize","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/uninverting/UninvertingReader#wrap(LeafReader,Function[String,Type]).mjava","pathOld":"solr/core/src/java/org/apache/solr/uninverting/UninvertingReader#wrap(LeafReader,Function[String,Type]).mjava","sourceNew":"  /**\n   * Create a new UninvertingReader with the specified mapping, wrapped around the input.  It may be deemed that there\n   * is no mapping to do, in which case the input is returned.\n   * <p>\n   * Expert: This should almost never be used. Use {@link #wrap(DirectoryReader, Function)} instead.\n   *\n   * @lucene.internal\n   */\n  public static LeafReader wrap(LeafReader in, Function<String, Type> mapping) {\n    boolean wrap = false;\n\n    // Calculate a new FieldInfos that has DocValuesType where we didn't before\n    ArrayList<FieldInfo> newFieldInfos = new ArrayList<>(in.getFieldInfos().size());\n    for (FieldInfo fi : in.getFieldInfos()) {\n      DocValuesType type = fi.getDocValuesType();\n      // fields which currently don't have docValues, but are uninvertable (indexed or points data present)\n      if (type == DocValuesType.NONE &&\n          (fi.getIndexOptions() != IndexOptions.NONE || (fi.getPointNumBytes() > 0 && fi.getPointDataDimensionCount() == 1))) {\n        Type t = mapping.apply(fi.name); // could definitely return null, thus still can't uninvert it\n        if (t != null) {\n          if (t == Type.INTEGER_POINT || t == Type.LONG_POINT || t == Type.FLOAT_POINT || t == Type.DOUBLE_POINT) {\n            // type uses points\n            if (fi.getPointDataDimensionCount() == 0) {\n              continue;\n            }\n          } else {\n            // type uses inverted index\n            if (fi.getIndexOptions() == IndexOptions.NONE) {\n              continue;\n            }\n          }\n          switch(t) {\n            case INTEGER_POINT:\n            case LONG_POINT:\n            case FLOAT_POINT:\n            case DOUBLE_POINT:\n            case LEGACY_INTEGER:\n            case LEGACY_LONG:\n            case LEGACY_FLOAT:\n            case LEGACY_DOUBLE:\n              type = DocValuesType.NUMERIC;\n              break;\n            case BINARY:\n              type = DocValuesType.BINARY;\n              break;\n            case SORTED:\n              type = DocValuesType.SORTED;\n              break;\n            case SORTED_SET_BINARY:\n            case SORTED_SET_INTEGER:\n            case SORTED_SET_FLOAT:\n            case SORTED_SET_LONG:\n            case SORTED_SET_DOUBLE:\n              type = DocValuesType.SORTED_SET;\n              break;\n            default:\n              throw new AssertionError();\n          }\n        }\n      }\n      if (type != fi.getDocValuesType()) { // we changed it\n        wrap = true;\n        newFieldInfos.add(new FieldInfo(fi.name, fi.number, fi.hasVectors(), fi.omitsNorms(),\n            fi.hasPayloads(), fi.getIndexOptions(), type, fi.getDocValuesGen(), fi.attributes(),\n            fi.getPointDataDimensionCount(), fi.getPointIndexDimensionCount(), fi.getPointNumBytes(), fi.isSoftDeletesField()));\n      } else {\n        newFieldInfos.add(fi);\n      }\n    }\n    if (!wrap) {\n      return in;\n    } else {\n      FieldInfos fieldInfos = new FieldInfos(newFieldInfos.toArray(new FieldInfo[newFieldInfos.size()]));\n      return new UninvertingReader(in, mapping, fieldInfos);\n    }\n  }\n\n","sourceOld":"  /**\n   * Create a new UninvertingReader with the specified mapping, wrapped around the input.  It may be deemed that there\n   * is no mapping to do, in which case the input is returned.\n   * <p>\n   * Expert: This should almost never be used. Use {@link #wrap(DirectoryReader, Function)} instead.\n   *\n   * @lucene.internal\n   */\n  public static LeafReader wrap(LeafReader in, Function<String, Type> mapping) {\n    boolean wrap = false;\n\n    // Calculate a new FieldInfos that has DocValuesType where we didn't before\n    ArrayList<FieldInfo> newFieldInfos = new ArrayList<>(in.getFieldInfos().size());\n    for (FieldInfo fi : in.getFieldInfos()) {\n      DocValuesType type = fi.getDocValuesType();\n      // fields which currently don't have docValues, but are uninvertable (indexed or points data present)\n      if (type == DocValuesType.NONE &&\n          (fi.getIndexOptions() != IndexOptions.NONE || (fi.getPointNumBytes() > 0 && fi.getPointDimensionCount() == 1))) {\n        Type t = mapping.apply(fi.name); // could definitely return null, thus still can't uninvert it\n        if (t != null) {\n          if (t == Type.INTEGER_POINT || t == Type.LONG_POINT || t == Type.FLOAT_POINT || t == Type.DOUBLE_POINT) {\n            // type uses points\n            if (fi.getPointDimensionCount() == 0) {\n              continue;\n            }\n          } else {\n            // type uses inverted index\n            if (fi.getIndexOptions() == IndexOptions.NONE) {\n              continue;\n            }\n          }\n          switch(t) {\n            case INTEGER_POINT:\n            case LONG_POINT:\n            case FLOAT_POINT:\n            case DOUBLE_POINT:\n            case LEGACY_INTEGER:\n            case LEGACY_LONG:\n            case LEGACY_FLOAT:\n            case LEGACY_DOUBLE:\n              type = DocValuesType.NUMERIC;\n              break;\n            case BINARY:\n              type = DocValuesType.BINARY;\n              break;\n            case SORTED:\n              type = DocValuesType.SORTED;\n              break;\n            case SORTED_SET_BINARY:\n            case SORTED_SET_INTEGER:\n            case SORTED_SET_FLOAT:\n            case SORTED_SET_LONG:\n            case SORTED_SET_DOUBLE:\n              type = DocValuesType.SORTED_SET;\n              break;\n            default:\n              throw new AssertionError();\n          }\n        }\n      }\n      if (type != fi.getDocValuesType()) { // we changed it\n        wrap = true;\n        newFieldInfos.add(new FieldInfo(fi.name, fi.number, fi.hasVectors(), fi.omitsNorms(),\n            fi.hasPayloads(), fi.getIndexOptions(), type, fi.getDocValuesGen(), fi.attributes(),\n            fi.getPointDimensionCount(), fi.getPointNumBytes(), fi.isSoftDeletesField()));\n      } else {\n        newFieldInfos.add(fi);\n      }\n    }\n    if (!wrap) {\n      return in;\n    } else {\n      FieldInfos fieldInfos = new FieldInfos(newFieldInfos.toArray(new FieldInfo[newFieldInfos.size()]));\n      return new UninvertingReader(in, mapping, fieldInfos);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"59ed8c026ba85e3c42fb89605b2032dc6f9cc241","date":1581113294,"type":3,"author":"Nicholas Knize","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/uninverting/UninvertingReader#wrap(LeafReader,Function[String,Type]).mjava","pathOld":"solr/core/src/java/org/apache/solr/uninverting/UninvertingReader#wrap(LeafReader,Function[String,Type]).mjava","sourceNew":"  /**\n   * Create a new UninvertingReader with the specified mapping, wrapped around the input.  It may be deemed that there\n   * is no mapping to do, in which case the input is returned.\n   * <p>\n   * Expert: This should almost never be used. Use {@link #wrap(DirectoryReader, Function)} instead.\n   *\n   * @lucene.internal\n   */\n  public static LeafReader wrap(LeafReader in, Function<String, Type> mapping) {\n    boolean wrap = false;\n\n    // Calculate a new FieldInfos that has DocValuesType where we didn't before\n    ArrayList<FieldInfo> newFieldInfos = new ArrayList<>(in.getFieldInfos().size());\n    for (FieldInfo fi : in.getFieldInfos()) {\n      DocValuesType type = fi.getDocValuesType();\n      // fields which currently don't have docValues, but are uninvertable (indexed or points data present)\n      if (type == DocValuesType.NONE &&\n          (fi.getIndexOptions() != IndexOptions.NONE || (fi.getPointNumBytes() > 0 && fi.getPointDimensionCount() == 1))) {\n        Type t = mapping.apply(fi.name); // could definitely return null, thus still can't uninvert it\n        if (t != null) {\n          if (t == Type.INTEGER_POINT || t == Type.LONG_POINT || t == Type.FLOAT_POINT || t == Type.DOUBLE_POINT) {\n            // type uses points\n            if (fi.getPointDimensionCount() == 0) {\n              continue;\n            }\n          } else {\n            // type uses inverted index\n            if (fi.getIndexOptions() == IndexOptions.NONE) {\n              continue;\n            }\n          }\n          switch(t) {\n            case INTEGER_POINT:\n            case LONG_POINT:\n            case FLOAT_POINT:\n            case DOUBLE_POINT:\n            case LEGACY_INTEGER:\n            case LEGACY_LONG:\n            case LEGACY_FLOAT:\n            case LEGACY_DOUBLE:\n              type = DocValuesType.NUMERIC;\n              break;\n            case BINARY:\n              type = DocValuesType.BINARY;\n              break;\n            case SORTED:\n              type = DocValuesType.SORTED;\n              break;\n            case SORTED_SET_BINARY:\n            case SORTED_SET_INTEGER:\n            case SORTED_SET_FLOAT:\n            case SORTED_SET_LONG:\n            case SORTED_SET_DOUBLE:\n              type = DocValuesType.SORTED_SET;\n              break;\n            default:\n              throw new AssertionError();\n          }\n        }\n      }\n      if (type != fi.getDocValuesType()) { // we changed it\n        wrap = true;\n        newFieldInfos.add(new FieldInfo(fi.name, fi.number, fi.hasVectors(), fi.omitsNorms(),\n            fi.hasPayloads(), fi.getIndexOptions(), type, fi.getDocValuesGen(), fi.attributes(),\n            fi.getPointDimensionCount(), fi.getPointIndexDimensionCount(), fi.getPointNumBytes(), fi.isSoftDeletesField()));\n      } else {\n        newFieldInfos.add(fi);\n      }\n    }\n    if (!wrap) {\n      return in;\n    } else {\n      FieldInfos fieldInfos = new FieldInfos(newFieldInfos.toArray(new FieldInfo[newFieldInfos.size()]));\n      return new UninvertingReader(in, mapping, fieldInfos);\n    }\n  }\n\n","sourceOld":"  /**\n   * Create a new UninvertingReader with the specified mapping, wrapped around the input.  It may be deemed that there\n   * is no mapping to do, in which case the input is returned.\n   * <p>\n   * Expert: This should almost never be used. Use {@link #wrap(DirectoryReader, Function)} instead.\n   *\n   * @lucene.internal\n   */\n  public static LeafReader wrap(LeafReader in, Function<String, Type> mapping) {\n    boolean wrap = false;\n\n    // Calculate a new FieldInfos that has DocValuesType where we didn't before\n    ArrayList<FieldInfo> newFieldInfos = new ArrayList<>(in.getFieldInfos().size());\n    for (FieldInfo fi : in.getFieldInfos()) {\n      DocValuesType type = fi.getDocValuesType();\n      // fields which currently don't have docValues, but are uninvertable (indexed or points data present)\n      if (type == DocValuesType.NONE &&\n          (fi.getIndexOptions() != IndexOptions.NONE || (fi.getPointNumBytes() > 0 && fi.getPointDataDimensionCount() == 1))) {\n        Type t = mapping.apply(fi.name); // could definitely return null, thus still can't uninvert it\n        if (t != null) {\n          if (t == Type.INTEGER_POINT || t == Type.LONG_POINT || t == Type.FLOAT_POINT || t == Type.DOUBLE_POINT) {\n            // type uses points\n            if (fi.getPointDataDimensionCount() == 0) {\n              continue;\n            }\n          } else {\n            // type uses inverted index\n            if (fi.getIndexOptions() == IndexOptions.NONE) {\n              continue;\n            }\n          }\n          switch(t) {\n            case INTEGER_POINT:\n            case LONG_POINT:\n            case FLOAT_POINT:\n            case DOUBLE_POINT:\n            case LEGACY_INTEGER:\n            case LEGACY_LONG:\n            case LEGACY_FLOAT:\n            case LEGACY_DOUBLE:\n              type = DocValuesType.NUMERIC;\n              break;\n            case BINARY:\n              type = DocValuesType.BINARY;\n              break;\n            case SORTED:\n              type = DocValuesType.SORTED;\n              break;\n            case SORTED_SET_BINARY:\n            case SORTED_SET_INTEGER:\n            case SORTED_SET_FLOAT:\n            case SORTED_SET_LONG:\n            case SORTED_SET_DOUBLE:\n              type = DocValuesType.SORTED_SET;\n              break;\n            default:\n              throw new AssertionError();\n          }\n        }\n      }\n      if (type != fi.getDocValuesType()) { // we changed it\n        wrap = true;\n        newFieldInfos.add(new FieldInfo(fi.name, fi.number, fi.hasVectors(), fi.omitsNorms(),\n            fi.hasPayloads(), fi.getIndexOptions(), type, fi.getDocValuesGen(), fi.attributes(),\n            fi.getPointDataDimensionCount(), fi.getPointIndexDimensionCount(), fi.getPointNumBytes(), fi.isSoftDeletesField()));\n      } else {\n        newFieldInfos.add(fi);\n      }\n    }\n    if (!wrap) {\n      return in;\n    } else {\n      FieldInfos fieldInfos = new FieldInfos(newFieldInfos.toArray(new FieldInfo[newFieldInfos.size()]));\n      return new UninvertingReader(in, mapping, fieldInfos);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"59ed8c026ba85e3c42fb89605b2032dc6f9cc241":["f6652c943595e92c187ee904c382863013eae28f"],"f6652c943595e92c187ee904c382863013eae28f":["a07eeba66d4090af0095b50cbd1795a3d6182c1d"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"a07eeba66d4090af0095b50cbd1795a3d6182c1d":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["59ed8c026ba85e3c42fb89605b2032dc6f9cc241"]},"commit2Childs":{"59ed8c026ba85e3c42fb89605b2032dc6f9cc241":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"f6652c943595e92c187ee904c382863013eae28f":["59ed8c026ba85e3c42fb89605b2032dc6f9cc241"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["a07eeba66d4090af0095b50cbd1795a3d6182c1d"],"a07eeba66d4090af0095b50cbd1795a3d6182c1d":["f6652c943595e92c187ee904c382863013eae28f"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}