{"path":"lucene/queries/src/test/org/apache/lucene/queries/mlt/TestMoreLikeThis#testTopN().mjava","commits":[{"id":"2f73cfcb38e83bad8ad6dce5dd4f021d44efe73d","date":1405005344,"type":0,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/queries/src/test/org/apache/lucene/queries/mlt/TestMoreLikeThis#testTopN().mjava","pathOld":"/dev/null","sourceNew":"  public void testTopN() throws Exception {\n    int numDocs = 100;\n    int topN = 25;\n\n    // add series of docs with terms of decreasing df\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir);\n    for (int i = 0; i < numDocs; i++) {\n      addDoc(writer, generateStrSeq(0, i + 1));\n    }\n    IndexReader reader = writer.getReader();\n    writer.shutdown();\n\n    // setup MLT query\n    MoreLikeThis mlt = new MoreLikeThis(reader);\n    mlt.setAnalyzer(new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false));\n    mlt.setMaxQueryTerms(topN);\n    mlt.setMinDocFreq(1);\n    mlt.setMinTermFreq(1);\n    mlt.setMinWordLen(1);\n    mlt.setFieldNames(new String[]{\"text\"});\n\n    // perform MLT query\n    String likeText = \"\";\n    for (String text : generateStrSeq(0, numDocs)) {\n      likeText += text + \" \";\n    }\n    BooleanQuery query = (BooleanQuery) mlt.like(\"text\", new StringReader(likeText));\n\n    // check best terms are topN of highest idf\n    List<BooleanClause> clauses = query.clauses();\n    assertEquals(\"Expected\" + topN + \"clauses only!\", topN, clauses.size());\n\n    Term[] expectedTerms = new Term[topN];\n    int idx = 0;\n    for (String text : generateStrSeq(numDocs - topN, topN)) {\n      expectedTerms[idx++] = new Term(\"text\", text);\n    }\n    for (BooleanClause clause : clauses) {\n      Term term = ((TermQuery) clause.getQuery()).getTerm();\n      assertTrue(Arrays.asList(expectedTerms).contains(term));\n    }\n\n    // clean up\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["303eba9db32cde4e6fbc4e51a44361ef1c302e6c"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d0ef034a4f10871667ae75181537775ddcf8ade4","date":1407610475,"type":3,"author":"Ryan Ernst","isMerge":false,"pathNew":"lucene/queries/src/test/org/apache/lucene/queries/mlt/TestMoreLikeThis#testTopN().mjava","pathOld":"lucene/queries/src/test/org/apache/lucene/queries/mlt/TestMoreLikeThis#testTopN().mjava","sourceNew":"  public void testTopN() throws Exception {\n    int numDocs = 100;\n    int topN = 25;\n\n    // add series of docs with terms of decreasing df\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir);\n    for (int i = 0; i < numDocs; i++) {\n      addDoc(writer, generateStrSeq(0, i + 1));\n    }\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    // setup MLT query\n    MoreLikeThis mlt = new MoreLikeThis(reader);\n    mlt.setAnalyzer(new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false));\n    mlt.setMaxQueryTerms(topN);\n    mlt.setMinDocFreq(1);\n    mlt.setMinTermFreq(1);\n    mlt.setMinWordLen(1);\n    mlt.setFieldNames(new String[]{\"text\"});\n\n    // perform MLT query\n    String likeText = \"\";\n    for (String text : generateStrSeq(0, numDocs)) {\n      likeText += text + \" \";\n    }\n    BooleanQuery query = (BooleanQuery) mlt.like(\"text\", new StringReader(likeText));\n\n    // check best terms are topN of highest idf\n    List<BooleanClause> clauses = query.clauses();\n    assertEquals(\"Expected\" + topN + \"clauses only!\", topN, clauses.size());\n\n    Term[] expectedTerms = new Term[topN];\n    int idx = 0;\n    for (String text : generateStrSeq(numDocs - topN, topN)) {\n      expectedTerms[idx++] = new Term(\"text\", text);\n    }\n    for (BooleanClause clause : clauses) {\n      Term term = ((TermQuery) clause.getQuery()).getTerm();\n      assertTrue(Arrays.asList(expectedTerms).contains(term));\n    }\n\n    // clean up\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testTopN() throws Exception {\n    int numDocs = 100;\n    int topN = 25;\n\n    // add series of docs with terms of decreasing df\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir);\n    for (int i = 0; i < numDocs; i++) {\n      addDoc(writer, generateStrSeq(0, i + 1));\n    }\n    IndexReader reader = writer.getReader();\n    writer.shutdown();\n\n    // setup MLT query\n    MoreLikeThis mlt = new MoreLikeThis(reader);\n    mlt.setAnalyzer(new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false));\n    mlt.setMaxQueryTerms(topN);\n    mlt.setMinDocFreq(1);\n    mlt.setMinTermFreq(1);\n    mlt.setMinWordLen(1);\n    mlt.setFieldNames(new String[]{\"text\"});\n\n    // perform MLT query\n    String likeText = \"\";\n    for (String text : generateStrSeq(0, numDocs)) {\n      likeText += text + \" \";\n    }\n    BooleanQuery query = (BooleanQuery) mlt.like(\"text\", new StringReader(likeText));\n\n    // check best terms are topN of highest idf\n    List<BooleanClause> clauses = query.clauses();\n    assertEquals(\"Expected\" + topN + \"clauses only!\", topN, clauses.size());\n\n    Term[] expectedTerms = new Term[topN];\n    int idx = 0;\n    for (String text : generateStrSeq(numDocs - topN, topN)) {\n      expectedTerms[idx++] = new Term(\"text\", text);\n    }\n    for (BooleanClause clause : clauses) {\n      Term term = ((TermQuery) clause.getQuery()).getTerm();\n      assertTrue(Arrays.asList(expectedTerms).contains(term));\n    }\n\n    // clean up\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"a56958d7f71a28824f20031ffbb2e13502a0274e","date":1425573902,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/queries/src/test/org/apache/lucene/queries/mlt/TestMoreLikeThis#testTopN().mjava","pathOld":"lucene/queries/src/test/org/apache/lucene/queries/mlt/TestMoreLikeThis#testTopN().mjava","sourceNew":"  public void testTopN() throws Exception {\n    int numDocs = 100;\n    int topN = 25;\n\n    // add series of docs with terms of decreasing df\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir);\n    for (int i = 0; i < numDocs; i++) {\n      addDoc(writer, generateStrSeq(0, i + 1));\n    }\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    // setup MLT query\n    MoreLikeThis mlt = new MoreLikeThis(reader);\n    Analyzer analyzer = new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false);\n    mlt.setAnalyzer(analyzer);\n    mlt.setMaxQueryTerms(topN);\n    mlt.setMinDocFreq(1);\n    mlt.setMinTermFreq(1);\n    mlt.setMinWordLen(1);\n    mlt.setFieldNames(new String[]{\"text\"});\n\n    // perform MLT query\n    String likeText = \"\";\n    for (String text : generateStrSeq(0, numDocs)) {\n      likeText += text + \" \";\n    }\n    BooleanQuery query = (BooleanQuery) mlt.like(\"text\", new StringReader(likeText));\n\n    // check best terms are topN of highest idf\n    List<BooleanClause> clauses = query.clauses();\n    assertEquals(\"Expected\" + topN + \"clauses only!\", topN, clauses.size());\n\n    Term[] expectedTerms = new Term[topN];\n    int idx = 0;\n    for (String text : generateStrSeq(numDocs - topN, topN)) {\n      expectedTerms[idx++] = new Term(\"text\", text);\n    }\n    for (BooleanClause clause : clauses) {\n      Term term = ((TermQuery) clause.getQuery()).getTerm();\n      assertTrue(Arrays.asList(expectedTerms).contains(term));\n    }\n\n    // clean up\n    reader.close();\n    dir.close();\n    analyzer.close();\n  }\n\n","sourceOld":"  public void testTopN() throws Exception {\n    int numDocs = 100;\n    int topN = 25;\n\n    // add series of docs with terms of decreasing df\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir);\n    for (int i = 0; i < numDocs; i++) {\n      addDoc(writer, generateStrSeq(0, i + 1));\n    }\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    // setup MLT query\n    MoreLikeThis mlt = new MoreLikeThis(reader);\n    mlt.setAnalyzer(new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false));\n    mlt.setMaxQueryTerms(topN);\n    mlt.setMinDocFreq(1);\n    mlt.setMinTermFreq(1);\n    mlt.setMinWordLen(1);\n    mlt.setFieldNames(new String[]{\"text\"});\n\n    // perform MLT query\n    String likeText = \"\";\n    for (String text : generateStrSeq(0, numDocs)) {\n      likeText += text + \" \";\n    }\n    BooleanQuery query = (BooleanQuery) mlt.like(\"text\", new StringReader(likeText));\n\n    // check best terms are topN of highest idf\n    List<BooleanClause> clauses = query.clauses();\n    assertEquals(\"Expected\" + topN + \"clauses only!\", topN, clauses.size());\n\n    Term[] expectedTerms = new Term[topN];\n    int idx = 0;\n    for (String text : generateStrSeq(numDocs - topN, topN)) {\n      expectedTerms[idx++] = new Term(\"text\", text);\n    }\n    for (BooleanClause clause : clauses) {\n      Term term = ((TermQuery) clause.getQuery()).getTerm();\n      assertTrue(Arrays.asList(expectedTerms).contains(term));\n    }\n\n    // clean up\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":["303eba9db32cde4e6fbc4e51a44361ef1c302e6c"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","date":1427779360,"type":3,"author":"Ryan Ernst","isMerge":true,"pathNew":"lucene/queries/src/test/org/apache/lucene/queries/mlt/TestMoreLikeThis#testTopN().mjava","pathOld":"lucene/queries/src/test/org/apache/lucene/queries/mlt/TestMoreLikeThis#testTopN().mjava","sourceNew":"  public void testTopN() throws Exception {\n    int numDocs = 100;\n    int topN = 25;\n\n    // add series of docs with terms of decreasing df\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir);\n    for (int i = 0; i < numDocs; i++) {\n      addDoc(writer, generateStrSeq(0, i + 1));\n    }\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    // setup MLT query\n    MoreLikeThis mlt = new MoreLikeThis(reader);\n    Analyzer analyzer = new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false);\n    mlt.setAnalyzer(analyzer);\n    mlt.setMaxQueryTerms(topN);\n    mlt.setMinDocFreq(1);\n    mlt.setMinTermFreq(1);\n    mlt.setMinWordLen(1);\n    mlt.setFieldNames(new String[]{\"text\"});\n\n    // perform MLT query\n    String likeText = \"\";\n    for (String text : generateStrSeq(0, numDocs)) {\n      likeText += text + \" \";\n    }\n    BooleanQuery query = (BooleanQuery) mlt.like(\"text\", new StringReader(likeText));\n\n    // check best terms are topN of highest idf\n    List<BooleanClause> clauses = query.clauses();\n    assertEquals(\"Expected\" + topN + \"clauses only!\", topN, clauses.size());\n\n    Term[] expectedTerms = new Term[topN];\n    int idx = 0;\n    for (String text : generateStrSeq(numDocs - topN, topN)) {\n      expectedTerms[idx++] = new Term(\"text\", text);\n    }\n    for (BooleanClause clause : clauses) {\n      Term term = ((TermQuery) clause.getQuery()).getTerm();\n      assertTrue(Arrays.asList(expectedTerms).contains(term));\n    }\n\n    // clean up\n    reader.close();\n    dir.close();\n    analyzer.close();\n  }\n\n","sourceOld":"  public void testTopN() throws Exception {\n    int numDocs = 100;\n    int topN = 25;\n\n    // add series of docs with terms of decreasing df\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir);\n    for (int i = 0; i < numDocs; i++) {\n      addDoc(writer, generateStrSeq(0, i + 1));\n    }\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    // setup MLT query\n    MoreLikeThis mlt = new MoreLikeThis(reader);\n    mlt.setAnalyzer(new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false));\n    mlt.setMaxQueryTerms(topN);\n    mlt.setMinDocFreq(1);\n    mlt.setMinTermFreq(1);\n    mlt.setMinWordLen(1);\n    mlt.setFieldNames(new String[]{\"text\"});\n\n    // perform MLT query\n    String likeText = \"\";\n    for (String text : generateStrSeq(0, numDocs)) {\n      likeText += text + \" \";\n    }\n    BooleanQuery query = (BooleanQuery) mlt.like(\"text\", new StringReader(likeText));\n\n    // check best terms are topN of highest idf\n    List<BooleanClause> clauses = query.clauses();\n    assertEquals(\"Expected\" + topN + \"clauses only!\", topN, clauses.size());\n\n    Term[] expectedTerms = new Term[topN];\n    int idx = 0;\n    for (String text : generateStrSeq(numDocs - topN, topN)) {\n      expectedTerms[idx++] = new Term(\"text\", text);\n    }\n    for (BooleanClause clause : clauses) {\n      Term term = ((TermQuery) clause.getQuery()).getTerm();\n      assertTrue(Arrays.asList(expectedTerms).contains(term));\n    }\n\n    // clean up\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3f68d01cf19df971dcdcb05e30247f4ad7ec9747","date":1434611645,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/queries/src/test/org/apache/lucene/queries/mlt/TestMoreLikeThis#testTopN().mjava","pathOld":"lucene/queries/src/test/org/apache/lucene/queries/mlt/TestMoreLikeThis#testTopN().mjava","sourceNew":"  public void testTopN() throws Exception {\n    int numDocs = 100;\n    int topN = 25;\n\n    // add series of docs with terms of decreasing df\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir);\n    for (int i = 0; i < numDocs; i++) {\n      addDoc(writer, generateStrSeq(0, i + 1));\n    }\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    // setup MLT query\n    MoreLikeThis mlt = new MoreLikeThis(reader);\n    Analyzer analyzer = new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false);\n    mlt.setAnalyzer(analyzer);\n    mlt.setMaxQueryTerms(topN);\n    mlt.setMinDocFreq(1);\n    mlt.setMinTermFreq(1);\n    mlt.setMinWordLen(1);\n    mlt.setFieldNames(new String[]{\"text\"});\n\n    // perform MLT query\n    String likeText = \"\";\n    for (String text : generateStrSeq(0, numDocs)) {\n      likeText += text + \" \";\n    }\n    BooleanQuery query = (BooleanQuery) mlt.like(\"text\", new StringReader(likeText));\n\n    // check best terms are topN of highest idf\n    Collection<BooleanClause> clauses = query.clauses();\n    assertEquals(\"Expected\" + topN + \"clauses only!\", topN, clauses.size());\n\n    Term[] expectedTerms = new Term[topN];\n    int idx = 0;\n    for (String text : generateStrSeq(numDocs - topN, topN)) {\n      expectedTerms[idx++] = new Term(\"text\", text);\n    }\n    for (BooleanClause clause : clauses) {\n      Term term = ((TermQuery) clause.getQuery()).getTerm();\n      assertTrue(Arrays.asList(expectedTerms).contains(term));\n    }\n\n    // clean up\n    reader.close();\n    dir.close();\n    analyzer.close();\n  }\n\n","sourceOld":"  public void testTopN() throws Exception {\n    int numDocs = 100;\n    int topN = 25;\n\n    // add series of docs with terms of decreasing df\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir);\n    for (int i = 0; i < numDocs; i++) {\n      addDoc(writer, generateStrSeq(0, i + 1));\n    }\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    // setup MLT query\n    MoreLikeThis mlt = new MoreLikeThis(reader);\n    Analyzer analyzer = new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false);\n    mlt.setAnalyzer(analyzer);\n    mlt.setMaxQueryTerms(topN);\n    mlt.setMinDocFreq(1);\n    mlt.setMinTermFreq(1);\n    mlt.setMinWordLen(1);\n    mlt.setFieldNames(new String[]{\"text\"});\n\n    // perform MLT query\n    String likeText = \"\";\n    for (String text : generateStrSeq(0, numDocs)) {\n      likeText += text + \" \";\n    }\n    BooleanQuery query = (BooleanQuery) mlt.like(\"text\", new StringReader(likeText));\n\n    // check best terms are topN of highest idf\n    List<BooleanClause> clauses = query.clauses();\n    assertEquals(\"Expected\" + topN + \"clauses only!\", topN, clauses.size());\n\n    Term[] expectedTerms = new Term[topN];\n    int idx = 0;\n    for (String text : generateStrSeq(numDocs - topN, topN)) {\n      expectedTerms[idx++] = new Term(\"text\", text);\n    }\n    for (BooleanClause clause : clauses) {\n      Term term = ((TermQuery) clause.getQuery()).getTerm();\n      assertTrue(Arrays.asList(expectedTerms).contains(term));\n    }\n\n    // clean up\n    reader.close();\n    dir.close();\n    analyzer.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"303eba9db32cde4e6fbc4e51a44361ef1c302e6c","date":1553596029,"type":3,"author":"Tommaso Teofili","isMerge":false,"pathNew":"lucene/queries/src/test/org/apache/lucene/queries/mlt/TestMoreLikeThis#testTopN().mjava","pathOld":"lucene/queries/src/test/org/apache/lucene/queries/mlt/TestMoreLikeThis#testTopN().mjava","sourceNew":"  public void testTopN() throws Exception {\n    int numDocs = 100;\n    int topN = 25;\n\n    // add series of docs with terms of decreasing df\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir);\n    for (int i = 0; i < numDocs; i++) {\n      addDoc(writer, \"text\", generateStrSeq(0, i + 1));\n    }\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    // setup MLT query\n    mlt = this.getDefaultMoreLikeThis(reader);\n    mlt.setMaxQueryTerms(topN);\n    mlt.setFieldNames(new String[]{\"text\"});\n\n    // perform MLT query\n    String likeText = \"\";\n    for (String text : generateStrSeq(0, numDocs)) {\n      likeText += text + \" \";\n    }\n    BooleanQuery query = (BooleanQuery) mlt.like(\"text\", new StringReader(likeText));\n\n    // check best terms are topN of highest idf\n    Collection<BooleanClause> clauses = query.clauses();\n    assertEquals(\"Expected\" + topN + \"clauses only!\", topN, clauses.size());\n\n    Term[] expectedTerms = new Term[topN];\n    int idx = 0;\n    for (String text : generateStrSeq(numDocs - topN, topN)) {\n      expectedTerms[idx++] = new Term(\"text\", text);\n    }\n    for (BooleanClause clause : clauses) {\n      Term term = ((TermQuery) clause.getQuery()).getTerm();\n      assertTrue(Arrays.asList(expectedTerms).contains(term));\n    }\n\n    // clean up\n    reader.close();\n    dir.close();\n    analyzer.close();\n  }\n\n","sourceOld":"  public void testTopN() throws Exception {\n    int numDocs = 100;\n    int topN = 25;\n\n    // add series of docs with terms of decreasing df\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir);\n    for (int i = 0; i < numDocs; i++) {\n      addDoc(writer, generateStrSeq(0, i + 1));\n    }\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    // setup MLT query\n    MoreLikeThis mlt = new MoreLikeThis(reader);\n    Analyzer analyzer = new MockAnalyzer(random(), MockTokenizer.WHITESPACE, false);\n    mlt.setAnalyzer(analyzer);\n    mlt.setMaxQueryTerms(topN);\n    mlt.setMinDocFreq(1);\n    mlt.setMinTermFreq(1);\n    mlt.setMinWordLen(1);\n    mlt.setFieldNames(new String[]{\"text\"});\n\n    // perform MLT query\n    String likeText = \"\";\n    for (String text : generateStrSeq(0, numDocs)) {\n      likeText += text + \" \";\n    }\n    BooleanQuery query = (BooleanQuery) mlt.like(\"text\", new StringReader(likeText));\n\n    // check best terms are topN of highest idf\n    Collection<BooleanClause> clauses = query.clauses();\n    assertEquals(\"Expected\" + topN + \"clauses only!\", topN, clauses.size());\n\n    Term[] expectedTerms = new Term[topN];\n    int idx = 0;\n    for (String text : generateStrSeq(numDocs - topN, topN)) {\n      expectedTerms[idx++] = new Term(\"text\", text);\n    }\n    for (BooleanClause clause : clauses) {\n      Term term = ((TermQuery) clause.getQuery()).getTerm();\n      assertTrue(Arrays.asList(expectedTerms).contains(term));\n    }\n\n    // clean up\n    reader.close();\n    dir.close();\n    analyzer.close();\n  }\n\n","bugFix":["2f73cfcb38e83bad8ad6dce5dd4f021d44efe73d","a56958d7f71a28824f20031ffbb2e13502a0274e"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"3f68d01cf19df971dcdcb05e30247f4ad7ec9747":["a56958d7f71a28824f20031ffbb2e13502a0274e"],"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae":["d0ef034a4f10871667ae75181537775ddcf8ade4","a56958d7f71a28824f20031ffbb2e13502a0274e"],"303eba9db32cde4e6fbc4e51a44361ef1c302e6c":["3f68d01cf19df971dcdcb05e30247f4ad7ec9747"],"2f73cfcb38e83bad8ad6dce5dd4f021d44efe73d":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"d0ef034a4f10871667ae75181537775ddcf8ade4":["2f73cfcb38e83bad8ad6dce5dd4f021d44efe73d"],"a56958d7f71a28824f20031ffbb2e13502a0274e":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["303eba9db32cde4e6fbc4e51a44361ef1c302e6c"]},"commit2Childs":{"3f68d01cf19df971dcdcb05e30247f4ad7ec9747":["303eba9db32cde4e6fbc4e51a44361ef1c302e6c"],"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae":[],"303eba9db32cde4e6fbc4e51a44361ef1c302e6c":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"2f73cfcb38e83bad8ad6dce5dd4f021d44efe73d":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["2f73cfcb38e83bad8ad6dce5dd4f021d44efe73d"],"d0ef034a4f10871667ae75181537775ddcf8ade4":["a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","a56958d7f71a28824f20031ffbb2e13502a0274e"],"a56958d7f71a28824f20031ffbb2e13502a0274e":["3f68d01cf19df971dcdcb05e30247f4ad7ec9747","a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}