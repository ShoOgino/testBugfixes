{"path":"lucene/core/src/java/org/apache/lucene/codecs/lucene60/Lucene60DimensionalWriter#merge(MergeState).mjava","commits":[{"id":"1786be6a11f9cf5e48ce84869d1bb71e9c02f966","date":1448381196,"type":0,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene60/Lucene60DimensionalWriter#merge(MergeState).mjava","pathOld":"/dev/null","sourceNew":"  @Override\n  public void merge(MergeState mergeState) throws IOException {\n    for(DimensionalReader reader : mergeState.dimensionalReaders) {\n      if (reader instanceof Lucene60DimensionalReader == false) {\n        // We can only bulk merge when all to-be-merged segments use our format:\n        super.merge(mergeState);\n        return;\n      }\n    }\n\n    for (FieldInfo fieldInfo : mergeState.mergeFieldInfos) {\n      if (fieldInfo.getDimensionCount() != 0) {\n        if (fieldInfo.getDimensionCount() == 1) {\n          //System.out.println(\"MERGE: field=\" + fieldInfo.name);\n          // Optimize the 1D case to use BKDWriter.merge, which does a single merge sort of the\n          // already sorted incoming segments, instead of trying to sort all points again as if\n          // we were simply reindexing them:\n          try (BKDWriter writer = new BKDWriter(writeState.directory,\n                                                writeState.segmentInfo.name,\n                                                fieldInfo.getDimensionCount(),\n                                                fieldInfo.getDimensionNumBytes(),\n                                                maxPointsInLeafNode,\n                                                maxMBSortInHeap)) {\n            List<BKDReader> bkdReaders = new ArrayList<>();\n            List<MergeState.DocMap> docMaps = new ArrayList<>();\n            List<Integer> docIDBases = new ArrayList<>();\n            for(int i=0;i<mergeState.dimensionalReaders.length;i++) {\n              DimensionalReader reader = mergeState.dimensionalReaders[i];\n\n              Lucene60DimensionalReader reader60 = (Lucene60DimensionalReader) reader;\n              if (reader60 != null) {\n                // TODO: I could just use the merged fieldInfo.number instead of resolving to this\n                // reader's FieldInfo, right?  Field numbers are always consistent across segments,\n                // since when?\n                FieldInfos readerFieldInfos = mergeState.fieldInfos[i];\n                FieldInfo readerFieldInfo = readerFieldInfos.fieldInfo(fieldInfo.name);\n                if (readerFieldInfo != null) {\n                  BKDReader bkdReader = reader60.readers.get(readerFieldInfo.number);\n                  if (bkdReader != null) {\n                    docIDBases.add(mergeState.docBase[i]);\n                    bkdReaders.add(bkdReader);\n                    docMaps.add(mergeState.docMaps[i]);\n                  }\n                }\n              }\n            }\n\n            indexFPs.put(fieldInfo.name, writer.merge(dataOut, docMaps, bkdReaders, docIDBases));\n          }\n        } else {\n          mergeOneField(mergeState, fieldInfo);\n        }\n      }\n    } \n  }  \n\n","sourceOld":null,"bugFix":null,"bugIntro":["85ca0e073c286ebb2c89364ada6dd2740fc18880"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d53f98721d7cda12df9fd4b2e8e2c235be9ac494","date":1450448699,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene60/Lucene60DimensionalWriter#merge(MergeState).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene60/Lucene60DimensionalWriter#merge(MergeState).mjava","sourceNew":"  @Override\n  public void merge(MergeState mergeState) throws IOException {\n    for(DimensionalReader reader : mergeState.dimensionalReaders) {\n      if (reader instanceof Lucene60DimensionalReader == false) {\n        // We can only bulk merge when all to-be-merged segments use our format:\n        super.merge(mergeState);\n        return;\n      }\n    }\n\n    for (FieldInfo fieldInfo : mergeState.mergeFieldInfos) {\n      if (fieldInfo.getDimensionCount() != 0) {\n        if (fieldInfo.getDimensionCount() == 1) {\n          //System.out.println(\"MERGE: field=\" + fieldInfo.name);\n          // Optimize the 1D case to use BKDWriter.merge, which does a single merge sort of the\n          // already sorted incoming segments, instead of trying to sort all points again as if\n          // we were simply reindexing them:\n          try (BKDWriter writer = new BKDWriter(writeState.directory,\n                                                writeState.segmentInfo.name,\n                                                fieldInfo.getDimensionCount(),\n                                                fieldInfo.getDimensionNumBytes(),\n                                                maxPointsInLeafNode,\n                                                maxMBSortInHeap)) {\n            List<BKDReader> bkdReaders = new ArrayList<>();\n            List<MergeState.DocMap> docMaps = new ArrayList<>();\n            List<Integer> docIDBases = new ArrayList<>();\n            for(int i=0;i<mergeState.dimensionalReaders.length;i++) {\n              DimensionalReader reader = mergeState.dimensionalReaders[i];\n\n              Lucene60DimensionalReader reader60 = (Lucene60DimensionalReader) reader;\n              if (reader60 != null) {\n                // TODO: I could just use the merged fieldInfo.number instead of resolving to this\n                // reader's FieldInfo, right?  Field numbers are always consistent across segments,\n                // since when?\n                FieldInfos readerFieldInfos = mergeState.fieldInfos[i];\n                FieldInfo readerFieldInfo = readerFieldInfos.fieldInfo(fieldInfo.name);\n                if (readerFieldInfo != null) {\n                  BKDReader bkdReader = reader60.readers.get(readerFieldInfo.number);\n                  if (bkdReader != null) {\n                    docIDBases.add(mergeState.docBase[i]);\n                    bkdReaders.add(bkdReader);\n                    docMaps.add(mergeState.docMaps[i]);\n                  }\n                }\n              }\n            }\n\n            if (writer.getPointCount() > 0) {\n              indexFPs.put(fieldInfo.name, writer.merge(dataOut, docMaps, bkdReaders, docIDBases));\n            }\n          }\n        } else {\n          mergeOneField(mergeState, fieldInfo);\n        }\n      }\n    } \n  }  \n\n","sourceOld":"  @Override\n  public void merge(MergeState mergeState) throws IOException {\n    for(DimensionalReader reader : mergeState.dimensionalReaders) {\n      if (reader instanceof Lucene60DimensionalReader == false) {\n        // We can only bulk merge when all to-be-merged segments use our format:\n        super.merge(mergeState);\n        return;\n      }\n    }\n\n    for (FieldInfo fieldInfo : mergeState.mergeFieldInfos) {\n      if (fieldInfo.getDimensionCount() != 0) {\n        if (fieldInfo.getDimensionCount() == 1) {\n          //System.out.println(\"MERGE: field=\" + fieldInfo.name);\n          // Optimize the 1D case to use BKDWriter.merge, which does a single merge sort of the\n          // already sorted incoming segments, instead of trying to sort all points again as if\n          // we were simply reindexing them:\n          try (BKDWriter writer = new BKDWriter(writeState.directory,\n                                                writeState.segmentInfo.name,\n                                                fieldInfo.getDimensionCount(),\n                                                fieldInfo.getDimensionNumBytes(),\n                                                maxPointsInLeafNode,\n                                                maxMBSortInHeap)) {\n            List<BKDReader> bkdReaders = new ArrayList<>();\n            List<MergeState.DocMap> docMaps = new ArrayList<>();\n            List<Integer> docIDBases = new ArrayList<>();\n            for(int i=0;i<mergeState.dimensionalReaders.length;i++) {\n              DimensionalReader reader = mergeState.dimensionalReaders[i];\n\n              Lucene60DimensionalReader reader60 = (Lucene60DimensionalReader) reader;\n              if (reader60 != null) {\n                // TODO: I could just use the merged fieldInfo.number instead of resolving to this\n                // reader's FieldInfo, right?  Field numbers are always consistent across segments,\n                // since when?\n                FieldInfos readerFieldInfos = mergeState.fieldInfos[i];\n                FieldInfo readerFieldInfo = readerFieldInfos.fieldInfo(fieldInfo.name);\n                if (readerFieldInfo != null) {\n                  BKDReader bkdReader = reader60.readers.get(readerFieldInfo.number);\n                  if (bkdReader != null) {\n                    docIDBases.add(mergeState.docBase[i]);\n                    bkdReaders.add(bkdReader);\n                    docMaps.add(mergeState.docMaps[i]);\n                  }\n                }\n              }\n            }\n\n            indexFPs.put(fieldInfo.name, writer.merge(dataOut, docMaps, bkdReaders, docIDBases));\n          }\n        } else {\n          mergeOneField(mergeState, fieldInfo);\n        }\n      }\n    } \n  }  \n\n","bugFix":null,"bugIntro":["b6d206ce7675894027133736953dbb79a81351c5"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b6d206ce7675894027133736953dbb79a81351c5","date":1450463132,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene60/Lucene60DimensionalWriter#merge(MergeState).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene60/Lucene60DimensionalWriter#merge(MergeState).mjava","sourceNew":"  @Override\n  public void merge(MergeState mergeState) throws IOException {\n    for(DimensionalReader reader : mergeState.dimensionalReaders) {\n      if (reader instanceof Lucene60DimensionalReader == false) {\n        // We can only bulk merge when all to-be-merged segments use our format:\n        super.merge(mergeState);\n        return;\n      }\n    }\n\n    for (FieldInfo fieldInfo : mergeState.mergeFieldInfos) {\n      if (fieldInfo.getDimensionCount() != 0) {\n        if (fieldInfo.getDimensionCount() == 1) {\n          //System.out.println(\"MERGE: field=\" + fieldInfo.name);\n          // Optimize the 1D case to use BKDWriter.merge, which does a single merge sort of the\n          // already sorted incoming segments, instead of trying to sort all points again as if\n          // we were simply reindexing them:\n          try (BKDWriter writer = new BKDWriter(writeState.directory,\n                                                writeState.segmentInfo.name,\n                                                fieldInfo.getDimensionCount(),\n                                                fieldInfo.getDimensionNumBytes(),\n                                                maxPointsInLeafNode,\n                                                maxMBSortInHeap)) {\n            List<BKDReader> bkdReaders = new ArrayList<>();\n            List<MergeState.DocMap> docMaps = new ArrayList<>();\n            List<Integer> docIDBases = new ArrayList<>();\n            for(int i=0;i<mergeState.dimensionalReaders.length;i++) {\n              DimensionalReader reader = mergeState.dimensionalReaders[i];\n\n              Lucene60DimensionalReader reader60 = (Lucene60DimensionalReader) reader;\n              if (reader60 != null) {\n                // TODO: I could just use the merged fieldInfo.number instead of resolving to this\n                // reader's FieldInfo, right?  Field numbers are always consistent across segments,\n                // since when?\n                FieldInfos readerFieldInfos = mergeState.fieldInfos[i];\n                FieldInfo readerFieldInfo = readerFieldInfos.fieldInfo(fieldInfo.name);\n                if (readerFieldInfo != null) {\n                  BKDReader bkdReader = reader60.readers.get(readerFieldInfo.number);\n                  if (bkdReader != null) {\n                    docIDBases.add(mergeState.docBase[i]);\n                    bkdReaders.add(bkdReader);\n                    docMaps.add(mergeState.docMaps[i]);\n                  }\n                }\n              }\n            }\n\n            long fp = writer.merge(dataOut, docMaps, bkdReaders, docIDBases);\n            if (fp != -1) {\n              indexFPs.put(fieldInfo.name, fp);\n            }\n          }\n        } else {\n          mergeOneField(mergeState, fieldInfo);\n        }\n      }\n    } \n  }  \n\n","sourceOld":"  @Override\n  public void merge(MergeState mergeState) throws IOException {\n    for(DimensionalReader reader : mergeState.dimensionalReaders) {\n      if (reader instanceof Lucene60DimensionalReader == false) {\n        // We can only bulk merge when all to-be-merged segments use our format:\n        super.merge(mergeState);\n        return;\n      }\n    }\n\n    for (FieldInfo fieldInfo : mergeState.mergeFieldInfos) {\n      if (fieldInfo.getDimensionCount() != 0) {\n        if (fieldInfo.getDimensionCount() == 1) {\n          //System.out.println(\"MERGE: field=\" + fieldInfo.name);\n          // Optimize the 1D case to use BKDWriter.merge, which does a single merge sort of the\n          // already sorted incoming segments, instead of trying to sort all points again as if\n          // we were simply reindexing them:\n          try (BKDWriter writer = new BKDWriter(writeState.directory,\n                                                writeState.segmentInfo.name,\n                                                fieldInfo.getDimensionCount(),\n                                                fieldInfo.getDimensionNumBytes(),\n                                                maxPointsInLeafNode,\n                                                maxMBSortInHeap)) {\n            List<BKDReader> bkdReaders = new ArrayList<>();\n            List<MergeState.DocMap> docMaps = new ArrayList<>();\n            List<Integer> docIDBases = new ArrayList<>();\n            for(int i=0;i<mergeState.dimensionalReaders.length;i++) {\n              DimensionalReader reader = mergeState.dimensionalReaders[i];\n\n              Lucene60DimensionalReader reader60 = (Lucene60DimensionalReader) reader;\n              if (reader60 != null) {\n                // TODO: I could just use the merged fieldInfo.number instead of resolving to this\n                // reader's FieldInfo, right?  Field numbers are always consistent across segments,\n                // since when?\n                FieldInfos readerFieldInfos = mergeState.fieldInfos[i];\n                FieldInfo readerFieldInfo = readerFieldInfos.fieldInfo(fieldInfo.name);\n                if (readerFieldInfo != null) {\n                  BKDReader bkdReader = reader60.readers.get(readerFieldInfo.number);\n                  if (bkdReader != null) {\n                    docIDBases.add(mergeState.docBase[i]);\n                    bkdReaders.add(bkdReader);\n                    docMaps.add(mergeState.docMaps[i]);\n                  }\n                }\n              }\n            }\n\n            if (writer.getPointCount() > 0) {\n              indexFPs.put(fieldInfo.name, writer.merge(dataOut, docMaps, bkdReaders, docIDBases));\n            }\n          }\n        } else {\n          mergeOneField(mergeState, fieldInfo);\n        }\n      }\n    } \n  }  \n\n","bugFix":["d53f98721d7cda12df9fd4b2e8e2c235be9ac494"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"cab7a79353f33d1a94cd307bf33aa5148601ebe6","date":1453391888,"type":5,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene60/Lucene60PointWriter#merge(MergeState).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene60/Lucene60DimensionalWriter#merge(MergeState).mjava","sourceNew":"  @Override\n  public void merge(MergeState mergeState) throws IOException {\n    for(PointReader reader : mergeState.pointReaders) {\n      if (reader instanceof Lucene60PointReader == false) {\n        // We can only bulk merge when all to-be-merged segments use our format:\n        super.merge(mergeState);\n        return;\n      }\n    }\n\n    for (FieldInfo fieldInfo : mergeState.mergeFieldInfos) {\n      if (fieldInfo.getPointDimensionCount() != 0) {\n        if (fieldInfo.getPointDimensionCount() == 1) {\n          //System.out.println(\"MERGE: field=\" + fieldInfo.name);\n          // Optimize the 1D case to use BKDWriter.merge, which does a single merge sort of the\n          // already sorted incoming segments, instead of trying to sort all points again as if\n          // we were simply reindexing them:\n          try (BKDWriter writer = new BKDWriter(writeState.directory,\n                                                writeState.segmentInfo.name,\n                                                fieldInfo.getPointDimensionCount(),\n                                                fieldInfo.getPointNumBytes(),\n                                                maxPointsInLeafNode,\n                                                maxMBSortInHeap)) {\n            List<BKDReader> bkdReaders = new ArrayList<>();\n            List<MergeState.DocMap> docMaps = new ArrayList<>();\n            List<Integer> docIDBases = new ArrayList<>();\n            for(int i=0;i<mergeState.pointReaders.length;i++) {\n              PointReader reader = mergeState.pointReaders[i];\n\n              Lucene60PointReader reader60 = (Lucene60PointReader) reader;\n              if (reader60 != null) {\n                // TODO: I could just use the merged fieldInfo.number instead of resolving to this\n                // reader's FieldInfo, right?  Field numbers are always consistent across segments,\n                // since when?\n                FieldInfos readerFieldInfos = mergeState.fieldInfos[i];\n                FieldInfo readerFieldInfo = readerFieldInfos.fieldInfo(fieldInfo.name);\n                if (readerFieldInfo != null) {\n                  BKDReader bkdReader = reader60.readers.get(readerFieldInfo.number);\n                  if (bkdReader != null) {\n                    docIDBases.add(mergeState.docBase[i]);\n                    bkdReaders.add(bkdReader);\n                    docMaps.add(mergeState.docMaps[i]);\n                  }\n                }\n              }\n            }\n\n            long fp = writer.merge(dataOut, docMaps, bkdReaders, docIDBases);\n            if (fp != -1) {\n              indexFPs.put(fieldInfo.name, fp);\n            }\n          }\n        } else {\n          mergeOneField(mergeState, fieldInfo);\n        }\n      }\n    } \n  }  \n\n","sourceOld":"  @Override\n  public void merge(MergeState mergeState) throws IOException {\n    for(DimensionalReader reader : mergeState.dimensionalReaders) {\n      if (reader instanceof Lucene60DimensionalReader == false) {\n        // We can only bulk merge when all to-be-merged segments use our format:\n        super.merge(mergeState);\n        return;\n      }\n    }\n\n    for (FieldInfo fieldInfo : mergeState.mergeFieldInfos) {\n      if (fieldInfo.getDimensionCount() != 0) {\n        if (fieldInfo.getDimensionCount() == 1) {\n          //System.out.println(\"MERGE: field=\" + fieldInfo.name);\n          // Optimize the 1D case to use BKDWriter.merge, which does a single merge sort of the\n          // already sorted incoming segments, instead of trying to sort all points again as if\n          // we were simply reindexing them:\n          try (BKDWriter writer = new BKDWriter(writeState.directory,\n                                                writeState.segmentInfo.name,\n                                                fieldInfo.getDimensionCount(),\n                                                fieldInfo.getDimensionNumBytes(),\n                                                maxPointsInLeafNode,\n                                                maxMBSortInHeap)) {\n            List<BKDReader> bkdReaders = new ArrayList<>();\n            List<MergeState.DocMap> docMaps = new ArrayList<>();\n            List<Integer> docIDBases = new ArrayList<>();\n            for(int i=0;i<mergeState.dimensionalReaders.length;i++) {\n              DimensionalReader reader = mergeState.dimensionalReaders[i];\n\n              Lucene60DimensionalReader reader60 = (Lucene60DimensionalReader) reader;\n              if (reader60 != null) {\n                // TODO: I could just use the merged fieldInfo.number instead of resolving to this\n                // reader's FieldInfo, right?  Field numbers are always consistent across segments,\n                // since when?\n                FieldInfos readerFieldInfos = mergeState.fieldInfos[i];\n                FieldInfo readerFieldInfo = readerFieldInfos.fieldInfo(fieldInfo.name);\n                if (readerFieldInfo != null) {\n                  BKDReader bkdReader = reader60.readers.get(readerFieldInfo.number);\n                  if (bkdReader != null) {\n                    docIDBases.add(mergeState.docBase[i]);\n                    bkdReaders.add(bkdReader);\n                    docMaps.add(mergeState.docMaps[i]);\n                  }\n                }\n              }\n            }\n\n            long fp = writer.merge(dataOut, docMaps, bkdReaders, docIDBases);\n            if (fp != -1) {\n              indexFPs.put(fieldInfo.name, fp);\n            }\n          }\n        } else {\n          mergeOneField(mergeState, fieldInfo);\n        }\n      }\n    } \n  }  \n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"cab7a79353f33d1a94cd307bf33aa5148601ebe6":["b6d206ce7675894027133736953dbb79a81351c5"],"1786be6a11f9cf5e48ce84869d1bb71e9c02f966":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"d53f98721d7cda12df9fd4b2e8e2c235be9ac494":["1786be6a11f9cf5e48ce84869d1bb71e9c02f966"],"b6d206ce7675894027133736953dbb79a81351c5":["d53f98721d7cda12df9fd4b2e8e2c235be9ac494"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["cab7a79353f33d1a94cd307bf33aa5148601ebe6"]},"commit2Childs":{"cab7a79353f33d1a94cd307bf33aa5148601ebe6":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"1786be6a11f9cf5e48ce84869d1bb71e9c02f966":["d53f98721d7cda12df9fd4b2e8e2c235be9ac494"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["1786be6a11f9cf5e48ce84869d1bb71e9c02f966"],"d53f98721d7cda12df9fd4b2e8e2c235be9ac494":["b6d206ce7675894027133736953dbb79a81351c5"],"b6d206ce7675894027133736953dbb79a81351c5":["cab7a79353f33d1a94cd307bf33aa5148601ebe6"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}