{"path":"contrib/memory/src/java/org/apache/lucene/index/memory/PatternAnalyzer#tokenStream(String,Reader).mjava","commits":[{"id":"50e7972fe4865715af8951d4ba15555e3426fc5d","date":1115024647,"type":0,"author":"Erik Hatcher","isMerge":false,"pathNew":"contrib/memory/src/java/org/apache/lucene/index/memory/PatternAnalyzer#tokenStream(String,Reader).mjava","pathOld":"/dev/null","sourceNew":"\t/**\n\t * Creates a token stream that tokenizes all the text in the given Reader;\n\t * This implementation forwards to <code>tokenStream(String, String)</code> and is\n\t * less efficient than <code>tokenStream(String, String)</code>.\n\t */\n\tpublic TokenStream tokenStream(String fieldName, Reader reader) {\n\t\ttry {\n\t\t\tString text = toString(reader);\n\t\t\treturn tokenStream(fieldName, text);\n\t\t} catch (IOException e) {\n\t\t\tthrow new RuntimeException(e);\n\t\t}\n\t}\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c8f14489323057ef6de92ba5ea2d0cfe6e34755f","date":1120167605,"type":3,"author":"Mark Harwood","isMerge":false,"pathNew":"contrib/memory/src/java/org/apache/lucene/index/memory/PatternAnalyzer#tokenStream(String,Reader).mjava","pathOld":"contrib/memory/src/java/org/apache/lucene/index/memory/PatternAnalyzer#tokenStream(String,Reader).mjava","sourceNew":"\t/**\r\n\t * Creates a token stream that tokenizes all the text in the given Reader;\r\n\t * This implementation forwards to <code>tokenStream(String, String)</code> and is\r\n\t * less efficient than <code>tokenStream(String, String)</code>.\r\n\t */\r\n\tpublic TokenStream tokenStream(String fieldName, Reader reader) {\r\n\t\tif (reader instanceof FastStringReader) { // fast path\r\n\t\t\treturn tokenStream(fieldName, ((FastStringReader)reader).getString());\r\n\t\t}\r\n\t\t\r\n\t\ttry {\r\n\t\t\tString text = toString(reader);\r\n\t\t\treturn tokenStream(fieldName, text);\r\n\t\t} catch (IOException e) {\r\n\t\t\tthrow new RuntimeException(e);\r\n\t\t}\r\n\t}\r\n\n","sourceOld":"\t/**\n\t * Creates a token stream that tokenizes all the text in the given Reader;\n\t * This implementation forwards to <code>tokenStream(String, String)</code> and is\n\t * less efficient than <code>tokenStream(String, String)</code>.\n\t */\n\tpublic TokenStream tokenStream(String fieldName, Reader reader) {\n\t\ttry {\n\t\t\tString text = toString(reader);\n\t\t\treturn tokenStream(fieldName, text);\n\t\t} catch (IOException e) {\n\t\t\tthrow new RuntimeException(e);\n\t\t}\n\t}\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2542e236e1661f6d0e8e4aa8f09dd1495e58e35a","date":1133587576,"type":4,"author":"Wolfgang Hoschek","isMerge":false,"pathNew":"/dev/null","pathOld":"contrib/memory/src/java/org/apache/lucene/index/memory/PatternAnalyzer#tokenStream(String,Reader).mjava","sourceNew":null,"sourceOld":"\t/**\r\n\t * Creates a token stream that tokenizes all the text in the given Reader;\r\n\t * This implementation forwards to <code>tokenStream(String, String)</code> and is\r\n\t * less efficient than <code>tokenStream(String, String)</code>.\r\n\t */\r\n\tpublic TokenStream tokenStream(String fieldName, Reader reader) {\r\n\t\tif (reader instanceof FastStringReader) { // fast path\r\n\t\t\treturn tokenStream(fieldName, ((FastStringReader)reader).getString());\r\n\t\t}\r\n\t\t\r\n\t\ttry {\r\n\t\t\tString text = toString(reader);\r\n\t\t\treturn tokenStream(fieldName, text);\r\n\t\t} catch (IOException e) {\r\n\t\t\tthrow new RuntimeException(e);\r\n\t\t}\r\n\t}\r\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"29bb5af2486a9a013c0a0daffdb51dce2a3adb8e","date":1133587670,"type":0,"author":"Wolfgang Hoschek","isMerge":false,"pathNew":"contrib/memory/src/java/org/apache/lucene/index/memory/PatternAnalyzer#tokenStream(String,Reader).mjava","pathOld":"/dev/null","sourceNew":"\t/**\n\t * Creates a token stream that tokenizes all the text in the given Reader;\n\t * This implementation forwards to <code>tokenStream(String, String)</code> and is\n\t * less efficient than <code>tokenStream(String, String)</code>.\n\t */\n\tpublic TokenStream tokenStream(String fieldName, Reader reader) {\n\t\tif (reader instanceof FastStringReader) { // fast path\n\t\t\treturn tokenStream(fieldName, ((FastStringReader)reader).getString());\n\t\t}\n\t\t\n\t\ttry {\n\t\t\tString text = toString(reader);\n\t\t\treturn tokenStream(fieldName, text);\n\t\t} catch (IOException e) {\n\t\t\tthrow new RuntimeException(e);\n\t\t}\n\t}\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b08308242cb802f3a154e260d3881c2ed523c52b","date":1133766662,"type":3,"author":"Wolfgang Hoschek","isMerge":false,"pathNew":"contrib/memory/src/java/org/apache/lucene/index/memory/PatternAnalyzer#tokenStream(String,Reader).mjava","pathOld":"contrib/memory/src/java/org/apache/lucene/index/memory/PatternAnalyzer#tokenStream(String,Reader).mjava","sourceNew":"\t/**\n\t * Creates a token stream that tokenizes all the text in the given Reader;\n\t * This implementation forwards to <code>tokenStream(String, String)</code> and is\n\t * less efficient than <code>tokenStream(String, String)</code>.\n\t * \n\t * @param fieldName\n\t *            the name of the field to tokenize (currently ignored).\n\t * @param reader\n\t *            the reader delivering the text\n\t * @return a new token stream\n\t */\n\tpublic TokenStream tokenStream(String fieldName, Reader reader) {\n\t\tif (reader instanceof FastStringReader) { // fast path\n\t\t\treturn tokenStream(fieldName, ((FastStringReader)reader).getString());\n\t\t}\n\t\t\n\t\ttry {\n\t\t\tString text = toString(reader);\n\t\t\treturn tokenStream(fieldName, text);\n\t\t} catch (IOException e) {\n\t\t\tthrow new RuntimeException(e);\n\t\t}\n\t}\n\n","sourceOld":"\t/**\n\t * Creates a token stream that tokenizes all the text in the given Reader;\n\t * This implementation forwards to <code>tokenStream(String, String)</code> and is\n\t * less efficient than <code>tokenStream(String, String)</code>.\n\t */\n\tpublic TokenStream tokenStream(String fieldName, Reader reader) {\n\t\tif (reader instanceof FastStringReader) { // fast path\n\t\t\treturn tokenStream(fieldName, ((FastStringReader)reader).getString());\n\t\t}\n\t\t\n\t\ttry {\n\t\t\tString text = toString(reader);\n\t\t\treturn tokenStream(fieldName, text);\n\t\t} catch (IOException e) {\n\t\t\tthrow new RuntimeException(e);\n\t\t}\n\t}\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7f68e24227d5556d33ee6d586fd9010cd9ff8bec","date":1150091176,"type":3,"author":"Otis Gospodnetic","isMerge":false,"pathNew":"contrib/memory/src/java/org/apache/lucene/index/memory/PatternAnalyzer#tokenStream(String,Reader).mjava","pathOld":"contrib/memory/src/java/org/apache/lucene/index/memory/PatternAnalyzer#tokenStream(String,Reader).mjava","sourceNew":"  /**\n   * Creates a token stream that tokenizes all the text in the given Reader;\n   * This implementation forwards to <code>tokenStream(String, String)</code> and is\n   * less efficient than <code>tokenStream(String, String)</code>.\n   * \n   * @param fieldName\n   *            the name of the field to tokenize (currently ignored).\n   * @param reader\n   *            the reader delivering the text\n   * @return a new token stream\n   */\n  public TokenStream tokenStream(String fieldName, Reader reader) {\n    if (reader instanceof FastStringReader) { // fast path\n      return tokenStream(fieldName, ((FastStringReader)reader).getString());\n    }\n    \n    try {\n      String text = toString(reader);\n      return tokenStream(fieldName, text);\n    } catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n  }\n\n","sourceOld":"\t/**\n\t * Creates a token stream that tokenizes all the text in the given Reader;\n\t * This implementation forwards to <code>tokenStream(String, String)</code> and is\n\t * less efficient than <code>tokenStream(String, String)</code>.\n\t * \n\t * @param fieldName\n\t *            the name of the field to tokenize (currently ignored).\n\t * @param reader\n\t *            the reader delivering the text\n\t * @return a new token stream\n\t */\n\tpublic TokenStream tokenStream(String fieldName, Reader reader) {\n\t\tif (reader instanceof FastStringReader) { // fast path\n\t\t\treturn tokenStream(fieldName, ((FastStringReader)reader).getString());\n\t\t}\n\t\t\n\t\ttry {\n\t\t\tString text = toString(reader);\n\t\t\treturn tokenStream(fieldName, text);\n\t\t} catch (IOException e) {\n\t\t\tthrow new RuntimeException(e);\n\t\t}\n\t}\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0d8c222875ac4ef7e08f3e25d40508b821d711ff","date":1257374221,"type":5,"author":"Robert Muir","isMerge":false,"pathNew":"contrib/analyzers/common/src/java/org/apache/lucene/analysis/miscellaneous/PatternAnalyzer#tokenStream(String,Reader).mjava","pathOld":"contrib/memory/src/java/org/apache/lucene/index/memory/PatternAnalyzer#tokenStream(String,Reader).mjava","sourceNew":"  /**\n   * Creates a token stream that tokenizes all the text in the given Reader;\n   * This implementation forwards to <code>tokenStream(String, String)</code> and is\n   * less efficient than <code>tokenStream(String, String)</code>.\n   * \n   * @param fieldName\n   *            the name of the field to tokenize (currently ignored).\n   * @param reader\n   *            the reader delivering the text\n   * @return a new token stream\n   */\n  public TokenStream tokenStream(String fieldName, Reader reader) {\n    if (reader instanceof FastStringReader) { // fast path\n      return tokenStream(fieldName, ((FastStringReader)reader).getString());\n    }\n    \n    try {\n      String text = toString(reader);\n      return tokenStream(fieldName, text);\n    } catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n  }\n\n","sourceOld":"  /**\n   * Creates a token stream that tokenizes all the text in the given Reader;\n   * This implementation forwards to <code>tokenStream(String, String)</code> and is\n   * less efficient than <code>tokenStream(String, String)</code>.\n   * \n   * @param fieldName\n   *            the name of the field to tokenize (currently ignored).\n   * @param reader\n   *            the reader delivering the text\n   * @return a new token stream\n   */\n  public TokenStream tokenStream(String fieldName, Reader reader) {\n    if (reader instanceof FastStringReader) { // fast path\n      return tokenStream(fieldName, ((FastStringReader)reader).getString());\n    }\n    \n    try {\n      String text = toString(reader);\n      return tokenStream(fieldName, text);\n    } catch (IOException e) {\n      throw new RuntimeException(e);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"2542e236e1661f6d0e8e4aa8f09dd1495e58e35a":["c8f14489323057ef6de92ba5ea2d0cfe6e34755f"],"0d8c222875ac4ef7e08f3e25d40508b821d711ff":["7f68e24227d5556d33ee6d586fd9010cd9ff8bec"],"b08308242cb802f3a154e260d3881c2ed523c52b":["29bb5af2486a9a013c0a0daffdb51dce2a3adb8e"],"29bb5af2486a9a013c0a0daffdb51dce2a3adb8e":["2542e236e1661f6d0e8e4aa8f09dd1495e58e35a"],"c8f14489323057ef6de92ba5ea2d0cfe6e34755f":["50e7972fe4865715af8951d4ba15555e3426fc5d"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"7f68e24227d5556d33ee6d586fd9010cd9ff8bec":["b08308242cb802f3a154e260d3881c2ed523c52b"],"50e7972fe4865715af8951d4ba15555e3426fc5d":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["0d8c222875ac4ef7e08f3e25d40508b821d711ff"]},"commit2Childs":{"2542e236e1661f6d0e8e4aa8f09dd1495e58e35a":["29bb5af2486a9a013c0a0daffdb51dce2a3adb8e"],"0d8c222875ac4ef7e08f3e25d40508b821d711ff":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"b08308242cb802f3a154e260d3881c2ed523c52b":["7f68e24227d5556d33ee6d586fd9010cd9ff8bec"],"29bb5af2486a9a013c0a0daffdb51dce2a3adb8e":["b08308242cb802f3a154e260d3881c2ed523c52b"],"c8f14489323057ef6de92ba5ea2d0cfe6e34755f":["2542e236e1661f6d0e8e4aa8f09dd1495e58e35a"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["50e7972fe4865715af8951d4ba15555e3426fc5d"],"7f68e24227d5556d33ee6d586fd9010cd9ff8bec":["0d8c222875ac4ef7e08f3e25d40508b821d711ff"],"50e7972fe4865715af8951d4ba15555e3426fc5d":["c8f14489323057ef6de92ba5ea2d0cfe6e34755f"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}