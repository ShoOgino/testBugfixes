{"path":"lucene/src/test/org/apache/lucene/search/TestTermVectors#testTermVectors().mjava","commits":[{"id":"9454a6510e2db155fb01faa5c049b06ece95fab9","date":1453508333,"type":1,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/search/TestTermVectors#testTermVectors().mjava","pathOld":"src/test/org/apache/lucene/search/TestTermVectors#testTermVectors().mjava","sourceNew":"  public void testTermVectors() {\n    Query query = new TermQuery(new Term(\"field\", \"seventy\"));\n    try {\n      ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;\n      assertEquals(100, hits.length);\n      \n      for (int i = 0; i < hits.length; i++)\n      {\n        TermFreqVector [] vector = searcher.reader.getTermFreqVectors(hits[i].doc);\n        assertTrue(vector != null);\n        assertTrue(vector.length == 1);\n      }\n    } catch (IOException e) {\n      assertTrue(false);\n    }\n  }\n\n","sourceOld":"  public void testTermVectors() {\n    Query query = new TermQuery(new Term(\"field\", \"seventy\"));\n    try {\n      ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;\n      assertEquals(100, hits.length);\n      \n      for (int i = 0; i < hits.length; i++)\n      {\n        TermFreqVector [] vector = searcher.reader.getTermFreqVectors(hits[i].doc);\n        assertTrue(vector != null);\n        assertTrue(vector.length == 1);\n      }\n    } catch (IOException e) {\n      assertTrue(false);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4a636e9259fc0c14adb97c8fcc3914f24902599d","date":1278120088,"type":3,"author":"Grant Ingersoll","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/search/TestTermVectors#testTermVectors().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestTermVectors#testTermVectors().mjava","sourceNew":"  public void testTermVectors() {\n    Query query = new TermQuery(new Term(\"field\", \"seventy\"));\n    try {\n      ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;\n      assertEquals(100, hits.length);\n      \n      for (int i = 0; i < hits.length; i++)\n      {\n        TermFreqVector [] vector = searcher.reader.getTermFreqVectors(hits[i].doc);\n        assertTrue(vector != null);\n        assertTrue(vector.length == 1);\n      }\n      TermFreqVector vector;\n      vector = searcher.reader.getTermFreqVector(hits[0].doc, \"noTV\");\n      assertNull(vector);\n\n      TestTermVectorMapper mapper = new TestTermVectorMapper();\n      searcher.reader.getTermFreqVector(hits[0].doc, \"noTV\", mapper);\n      assertNull(mapper.field);\n\n    } catch (IOException e) {\n      assertTrue(false);\n    }\n  }\n\n","sourceOld":"  public void testTermVectors() {\n    Query query = new TermQuery(new Term(\"field\", \"seventy\"));\n    try {\n      ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;\n      assertEquals(100, hits.length);\n      \n      for (int i = 0; i < hits.length; i++)\n      {\n        TermFreqVector [] vector = searcher.reader.getTermFreqVectors(hits[i].doc);\n        assertTrue(vector != null);\n        assertTrue(vector.length == 1);\n      }\n    } catch (IOException e) {\n      assertTrue(false);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c084e47df29de3330311d69dabf515ceaa989512","date":1279030906,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/search/TestTermVectors#testTermVectors().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestTermVectors#testTermVectors().mjava","sourceNew":"  public void testTermVectors() throws IOException {\n    Query query = new TermQuery(new Term(\"field\", \"seventy\"));\n    ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;\n    assertEquals(100, hits.length);\n      \n    for (int i = 0; i < hits.length; i++)\n    {\n      TermFreqVector [] vector = searcher.reader.getTermFreqVectors(hits[i].doc);\n      assertTrue(vector != null);\n      assertTrue(vector.length == 1);\n    }\n    TermFreqVector vector;\n    vector = searcher.reader.getTermFreqVector(hits[0].doc, \"noTV\");\n    assertNull(vector);\n\n    TestTermVectorMapper mapper = new TestTermVectorMapper();\n    searcher.reader.getTermFreqVector(hits[0].doc, \"noTV\", mapper);\n    assertNull(mapper.field);\n  }\n\n","sourceOld":"  public void testTermVectors() {\n    Query query = new TermQuery(new Term(\"field\", \"seventy\"));\n    try {\n      ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;\n      assertEquals(100, hits.length);\n      \n      for (int i = 0; i < hits.length; i++)\n      {\n        TermFreqVector [] vector = searcher.reader.getTermFreqVectors(hits[i].doc);\n        assertTrue(vector != null);\n        assertTrue(vector.length == 1);\n      }\n      TermFreqVector vector;\n      vector = searcher.reader.getTermFreqVector(hits[0].doc, \"noTV\");\n      assertNull(vector);\n\n      TestTermVectorMapper mapper = new TestTermVectorMapper();\n      searcher.reader.getTermFreqVector(hits[0].doc, \"noTV\", mapper);\n      assertNull(mapper.field);\n\n    } catch (IOException e) {\n      assertTrue(false);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5f4e87790277826a2aea119328600dfb07761f32","date":1279827275,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/search/TestTermVectors#testTermVectors().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestTermVectors#testTermVectors().mjava","sourceNew":"  public void testTermVectors() throws IOException {\n    Query query = new TermQuery(new Term(\"field\", \"seventy\"));\n    ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;\n    assertEquals(100, hits.length);\n      \n    for (int i = 0; i < hits.length; i++)\n    {\n      TermFreqVector [] vector = searcher.reader.getTermFreqVectors(hits[i].doc);\n      assertTrue(vector != null);\n      assertTrue(vector.length == 1);\n    }\n    TermFreqVector vector;\n    vector = searcher.reader.getTermFreqVector(hits[0].doc, \"noTV\");\n    assertNull(vector);\n\n    TestTermVectorMapper mapper = new TestTermVectorMapper();\n    searcher.reader.getTermFreqVector(hits[0].doc, \"noTV\", mapper);\n    assertNull(mapper.field);\n  }\n\n","sourceOld":"  public void testTermVectors() {\n    Query query = new TermQuery(new Term(\"field\", \"seventy\"));\n    try {\n      ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;\n      assertEquals(100, hits.length);\n      \n      for (int i = 0; i < hits.length; i++)\n      {\n        TermFreqVector [] vector = searcher.reader.getTermFreqVectors(hits[i].doc);\n        assertTrue(vector != null);\n        assertTrue(vector.length == 1);\n      }\n    } catch (IOException e) {\n      assertTrue(false);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1509f151d7692d84fae414b2b799ac06ba60fcb4","date":1314451621,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/search/TestTermVectors#testTermVectors().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestTermVectors#testTermVectors().mjava","sourceNew":"  public void testTermVectors() throws IOException {\n    Query query = new TermQuery(new Term(\"field\", \"seventy\"));\n    ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;\n    assertEquals(100, hits.length);\n      \n    for (int i = 0; i < hits.length; i++) {\n      TermFreqVector [] vector = searcher.reader.getTermFreqVectors(hits[i].doc);\n      assertTrue(vector != null);\n      assertEquals(\"doc=\" + hits[i].doc + \" tv=\" + vector, 1, vector.length);\n    }\n    TermFreqVector vector;\n    vector = searcher.reader.getTermFreqVector(hits[0].doc, \"noTV\");\n    assertNull(vector);\n\n    TestTermVectorMapper mapper = new TestTermVectorMapper();\n    searcher.reader.getTermFreqVector(hits[0].doc, \"noTV\", mapper);\n    assertNull(mapper.field);\n  }\n\n","sourceOld":"  public void testTermVectors() throws IOException {\n    Query query = new TermQuery(new Term(\"field\", \"seventy\"));\n    ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;\n    assertEquals(100, hits.length);\n      \n    for (int i = 0; i < hits.length; i++)\n    {\n      TermFreqVector [] vector = searcher.reader.getTermFreqVectors(hits[i].doc);\n      assertTrue(vector != null);\n      assertTrue(vector.length == 1);\n    }\n    TermFreqVector vector;\n    vector = searcher.reader.getTermFreqVector(hits[0].doc, \"noTV\");\n    assertNull(vector);\n\n    TestTermVectorMapper mapper = new TestTermVectorMapper();\n    searcher.reader.getTermFreqVector(hits[0].doc, \"noTV\", mapper);\n    assertNull(mapper.field);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3cc749c053615f5871f3b95715fe292f34e70a53","date":1321470575,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/search/TestTermVectors#testTermVectors().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestTermVectors#testTermVectors().mjava","sourceNew":"  public void testTermVectors() throws IOException {\n    Query query = new TermQuery(new Term(\"field\", \"seventy\"));\n    ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;\n    assertEquals(100, hits.length);\n      \n    for (int i = 0; i < hits.length; i++) {\n      Fields vectors = searcher.reader.getTermVectors(hits[i].doc);\n      assertNotNull(vectors);\n      assertEquals(\"doc=\" + hits[i].doc + \" tv=\" + vectors, 1, vectors.getUniqueFieldCount());\n    }\n    Terms vector;\n    vector = searcher.reader.getTermVectors(hits[0].doc).terms(\"noTV\");\n    assertNull(vector);\n  }\n\n","sourceOld":"  public void testTermVectors() throws IOException {\n    Query query = new TermQuery(new Term(\"field\", \"seventy\"));\n    ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;\n    assertEquals(100, hits.length);\n      \n    for (int i = 0; i < hits.length; i++) {\n      TermFreqVector [] vector = searcher.reader.getTermFreqVectors(hits[i].doc);\n      assertTrue(vector != null);\n      assertEquals(\"doc=\" + hits[i].doc + \" tv=\" + vector, 1, vector.length);\n    }\n    TermFreqVector vector;\n    vector = searcher.reader.getTermFreqVector(hits[0].doc, \"noTV\");\n    assertNull(vector);\n\n    TestTermVectorMapper mapper = new TestTermVectorMapper();\n    searcher.reader.getTermFreqVector(hits[0].doc, \"noTV\", mapper);\n    assertNull(mapper.field);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":5,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestTermVectors#testTermVectors().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestTermVectors#testTermVectors().mjava","sourceNew":"  public void testTermVectors() throws IOException {\n    Query query = new TermQuery(new Term(\"field\", \"seventy\"));\n    ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;\n    assertEquals(100, hits.length);\n      \n    for (int i = 0; i < hits.length; i++) {\n      Fields vectors = searcher.reader.getTermVectors(hits[i].doc);\n      assertNotNull(vectors);\n      assertEquals(\"doc=\" + hits[i].doc + \" tv=\" + vectors, 1, vectors.getUniqueFieldCount());\n    }\n    Terms vector;\n    vector = searcher.reader.getTermVectors(hits[0].doc).terms(\"noTV\");\n    assertNull(vector);\n  }\n\n","sourceOld":"  public void testTermVectors() throws IOException {\n    Query query = new TermQuery(new Term(\"field\", \"seventy\"));\n    ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;\n    assertEquals(100, hits.length);\n      \n    for (int i = 0; i < hits.length; i++) {\n      Fields vectors = searcher.reader.getTermVectors(hits[i].doc);\n      assertNotNull(vectors);\n      assertEquals(\"doc=\" + hits[i].doc + \" tv=\" + vectors, 1, vectors.getUniqueFieldCount());\n    }\n    Terms vector;\n    vector = searcher.reader.getTermVectors(hits[0].doc).terms(\"noTV\");\n    assertNull(vector);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"c084e47df29de3330311d69dabf515ceaa989512":["4a636e9259fc0c14adb97c8fcc3914f24902599d"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["3cc749c053615f5871f3b95715fe292f34e70a53"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"3cc749c053615f5871f3b95715fe292f34e70a53":["1509f151d7692d84fae414b2b799ac06ba60fcb4"],"5f4e87790277826a2aea119328600dfb07761f32":["9454a6510e2db155fb01faa5c049b06ece95fab9","c084e47df29de3330311d69dabf515ceaa989512"],"1509f151d7692d84fae414b2b799ac06ba60fcb4":["c084e47df29de3330311d69dabf515ceaa989512"],"4a636e9259fc0c14adb97c8fcc3914f24902599d":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"c084e47df29de3330311d69dabf515ceaa989512":["5f4e87790277826a2aea119328600dfb07761f32","1509f151d7692d84fae414b2b799ac06ba60fcb4"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"3cc749c053615f5871f3b95715fe292f34e70a53":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"5f4e87790277826a2aea119328600dfb07761f32":[],"4a636e9259fc0c14adb97c8fcc3914f24902599d":["c084e47df29de3330311d69dabf515ceaa989512"],"1509f151d7692d84fae414b2b799ac06ba60fcb4":["3cc749c053615f5871f3b95715fe292f34e70a53"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["5f4e87790277826a2aea119328600dfb07761f32","4a636e9259fc0c14adb97c8fcc3914f24902599d"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["5f4e87790277826a2aea119328600dfb07761f32","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}