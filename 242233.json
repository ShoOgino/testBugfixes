{"path":"contrib/benchmark/src/java/org/apache/lucene/benchmark/stats/TestData#getTestDataMinMaxMergeAndMaxBuffered(File[],Analyzer[]).mjava","commits":[{"id":"226abb667f503323e0d9473af1883fa03ef3a3fd","date":1163596173,"type":0,"author":"Grant Ingersoll","isMerge":false,"pathNew":"contrib/benchmark/src/java/org/apache/lucene/benchmark/stats/TestData#getTestDataMinMaxMergeAndMaxBuffered(File[],Analyzer[]).mjava","pathOld":"/dev/null","sourceNew":"    /**\r\n     * Similar to {@link #getAll(java.io.File[], org.apache.lucene.analysis.Analyzer[])} but only uses\r\n     * maxBufferedDocs of 10 and 100 and same for mergeFactor, thus reducing the number of permutations significantly.\r\n     * It also only uses compund file and optimize is always true.\r\n     *\r\n     * @param sources\r\n     * @param analyzers\r\n     * @return An Array of {@link TestData}\r\n     */\r\n    public static TestData[] getTestDataMinMaxMergeAndMaxBuffered(File[] sources, Analyzer[] analyzers)\r\n    {\r\n        List res = new ArrayList(50);\r\n        TestData ref = new TestData();\r\n        for (int q = 0; q < analyzers.length; q++)\r\n        {\r\n            for (int m = 0; m < sources.length; m++)\r\n            {\r\n                ref.id = \"td-\" + q + m + \"_\" + 10 + \"_\" + 10;\r\n                ref.source = sources[m];\r\n                ref.analyzer = analyzers[q];\r\n                ref.maxBufferedDocs = 10;\r\n                ref.mergeFactor = 10;//MERGEFACTOR_COUNTS[k];\r\n                ref.compound = true;\r\n                ref.optimize = true;\r\n                try\r\n                {\r\n                    res.add(ref.clone());\r\n                }\r\n                catch (Exception e)\r\n                {\r\n                    e.printStackTrace();\r\n                }\r\n                ref.id = \"td-\" + q + m  + \"_\" + 10 + \"_\" + 100;\r\n                ref.source = sources[m];\r\n                ref.analyzer = analyzers[q];\r\n                ref.maxBufferedDocs = 10;\r\n                ref.mergeFactor = 100;//MERGEFACTOR_COUNTS[k];\r\n                ref.compound = true;\r\n                ref.optimize = true;\r\n                try\r\n                {\r\n                    res.add(ref.clone());\r\n                }\r\n                catch (Exception e)\r\n                {\r\n                    e.printStackTrace();\r\n                }\r\n                ref.id = \"td-\" + q + m + \"_\" + 100 + \"_\" + 10;\r\n                ref.source = sources[m];\r\n                ref.analyzer = analyzers[q];\r\n                ref.maxBufferedDocs = 100;\r\n                ref.mergeFactor = 10;//MERGEFACTOR_COUNTS[k];\r\n                ref.compound = true;\r\n                ref.optimize = true;\r\n                try\r\n                {\r\n                    res.add(ref.clone());\r\n                }\r\n                catch (Exception e)\r\n                {\r\n                    e.printStackTrace();\r\n                }\r\n                ref.id = \"td-\" + q + m + \"_\" + 100 + \"_\" + 100;\r\n                ref.source = sources[m];\r\n                ref.analyzer = analyzers[q];\r\n                ref.maxBufferedDocs = 100;\r\n                ref.mergeFactor = 100;//MERGEFACTOR_COUNTS[k];\r\n                ref.compound = true;\r\n                ref.optimize = true;\r\n                try\r\n                {\r\n                    res.add(ref.clone());\r\n                }\r\n                catch (Exception e)\r\n                {\r\n                    e.printStackTrace();\r\n                }\r\n            }\r\n        }\r\n        return (TestData[]) res.toArray(new TestData[0]);\r\n    }\r\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3738fa43eaa87dc7b393fe98b04cde1019e20bac","date":1175557034,"type":3,"author":"Otis Gospodnetic","isMerge":false,"pathNew":"contrib/benchmark/src/java/org/apache/lucene/benchmark/stats/TestData#getTestDataMinMaxMergeAndMaxBuffered(File[],Analyzer[]).mjava","pathOld":"contrib/benchmark/src/java/org/apache/lucene/benchmark/stats/TestData#getTestDataMinMaxMergeAndMaxBuffered(File[],Analyzer[]).mjava","sourceNew":"    /**\n     * Similar to {@link #getAll(java.io.File[], org.apache.lucene.analysis.Analyzer[])} but only uses\n     * maxBufferedDocs of 10 and 100 and same for mergeFactor, thus reducing the number of permutations significantly.\n     * It also only uses compund file and optimize is always true.\n     *\n     * @param sources\n     * @param analyzers\n     * @return An Array of {@link TestData}\n     */\n    public static TestData[] getTestDataMinMaxMergeAndMaxBuffered(File[] sources, Analyzer[] analyzers)\n    {\n        List res = new ArrayList(50);\n        TestData ref = new TestData();\n        for (int q = 0; q < analyzers.length; q++)\n        {\n            for (int m = 0; m < sources.length; m++)\n            {\n                ref.id = \"td-\" + q + m + \"_\" + 10 + \"_\" + 10;\n                ref.source = sources[m];\n                ref.analyzer = analyzers[q];\n                ref.maxBufferedDocs = 10;\n                ref.mergeFactor = 10;//MERGEFACTOR_COUNTS[k];\n                ref.compound = true;\n                ref.optimize = true;\n                try\n                {\n                    res.add(ref.clone());\n                }\n                catch (Exception e)\n                {\n                    e.printStackTrace();\n                }\n                ref.id = \"td-\" + q + m  + \"_\" + 10 + \"_\" + 100;\n                ref.source = sources[m];\n                ref.analyzer = analyzers[q];\n                ref.maxBufferedDocs = 10;\n                ref.mergeFactor = 100;//MERGEFACTOR_COUNTS[k];\n                ref.compound = true;\n                ref.optimize = true;\n                try\n                {\n                    res.add(ref.clone());\n                }\n                catch (Exception e)\n                {\n                    e.printStackTrace();\n                }\n                ref.id = \"td-\" + q + m + \"_\" + 100 + \"_\" + 10;\n                ref.source = sources[m];\n                ref.analyzer = analyzers[q];\n                ref.maxBufferedDocs = 100;\n                ref.mergeFactor = 10;//MERGEFACTOR_COUNTS[k];\n                ref.compound = true;\n                ref.optimize = true;\n                try\n                {\n                    res.add(ref.clone());\n                }\n                catch (Exception e)\n                {\n                    e.printStackTrace();\n                }\n                ref.id = \"td-\" + q + m + \"_\" + 100 + \"_\" + 100;\n                ref.source = sources[m];\n                ref.analyzer = analyzers[q];\n                ref.maxBufferedDocs = 100;\n                ref.mergeFactor = 100;//MERGEFACTOR_COUNTS[k];\n                ref.compound = true;\n                ref.optimize = true;\n                try\n                {\n                    res.add(ref.clone());\n                }\n                catch (Exception e)\n                {\n                    e.printStackTrace();\n                }\n            }\n        }\n        return (TestData[]) res.toArray(new TestData[0]);\n    }\n\n","sourceOld":"    /**\r\n     * Similar to {@link #getAll(java.io.File[], org.apache.lucene.analysis.Analyzer[])} but only uses\r\n     * maxBufferedDocs of 10 and 100 and same for mergeFactor, thus reducing the number of permutations significantly.\r\n     * It also only uses compund file and optimize is always true.\r\n     *\r\n     * @param sources\r\n     * @param analyzers\r\n     * @return An Array of {@link TestData}\r\n     */\r\n    public static TestData[] getTestDataMinMaxMergeAndMaxBuffered(File[] sources, Analyzer[] analyzers)\r\n    {\r\n        List res = new ArrayList(50);\r\n        TestData ref = new TestData();\r\n        for (int q = 0; q < analyzers.length; q++)\r\n        {\r\n            for (int m = 0; m < sources.length; m++)\r\n            {\r\n                ref.id = \"td-\" + q + m + \"_\" + 10 + \"_\" + 10;\r\n                ref.source = sources[m];\r\n                ref.analyzer = analyzers[q];\r\n                ref.maxBufferedDocs = 10;\r\n                ref.mergeFactor = 10;//MERGEFACTOR_COUNTS[k];\r\n                ref.compound = true;\r\n                ref.optimize = true;\r\n                try\r\n                {\r\n                    res.add(ref.clone());\r\n                }\r\n                catch (Exception e)\r\n                {\r\n                    e.printStackTrace();\r\n                }\r\n                ref.id = \"td-\" + q + m  + \"_\" + 10 + \"_\" + 100;\r\n                ref.source = sources[m];\r\n                ref.analyzer = analyzers[q];\r\n                ref.maxBufferedDocs = 10;\r\n                ref.mergeFactor = 100;//MERGEFACTOR_COUNTS[k];\r\n                ref.compound = true;\r\n                ref.optimize = true;\r\n                try\r\n                {\r\n                    res.add(ref.clone());\r\n                }\r\n                catch (Exception e)\r\n                {\r\n                    e.printStackTrace();\r\n                }\r\n                ref.id = \"td-\" + q + m + \"_\" + 100 + \"_\" + 10;\r\n                ref.source = sources[m];\r\n                ref.analyzer = analyzers[q];\r\n                ref.maxBufferedDocs = 100;\r\n                ref.mergeFactor = 10;//MERGEFACTOR_COUNTS[k];\r\n                ref.compound = true;\r\n                ref.optimize = true;\r\n                try\r\n                {\r\n                    res.add(ref.clone());\r\n                }\r\n                catch (Exception e)\r\n                {\r\n                    e.printStackTrace();\r\n                }\r\n                ref.id = \"td-\" + q + m + \"_\" + 100 + \"_\" + 100;\r\n                ref.source = sources[m];\r\n                ref.analyzer = analyzers[q];\r\n                ref.maxBufferedDocs = 100;\r\n                ref.mergeFactor = 100;//MERGEFACTOR_COUNTS[k];\r\n                ref.compound = true;\r\n                ref.optimize = true;\r\n                try\r\n                {\r\n                    res.add(ref.clone());\r\n                }\r\n                catch (Exception e)\r\n                {\r\n                    e.printStackTrace();\r\n                }\r\n            }\r\n        }\r\n        return (TestData[]) res.toArray(new TestData[0]);\r\n    }\r\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"add7d922e63099fbce8f0a1b31216df7ef5067f1","date":1252002701,"type":3,"author":"Chris M. Hostetter","isMerge":false,"pathNew":"contrib/benchmark/src/java/org/apache/lucene/benchmark/stats/TestData#getTestDataMinMaxMergeAndMaxBuffered(File[],Analyzer[]).mjava","pathOld":"contrib/benchmark/src/java/org/apache/lucene/benchmark/stats/TestData#getTestDataMinMaxMergeAndMaxBuffered(File[],Analyzer[]).mjava","sourceNew":"    /**\n     * Similar to {@link #getAll(java.io.File[], org.apache.lucene.analysis.Analyzer[])} but only uses\n     * maxBufferedDocs of 10 and 100 and same for mergeFactor, thus reducing the number of permutations significantly.\n     * It also only uses compound file and optimize is always true.\n     *\n     * @param sources\n     * @param analyzers\n     * @return An Array of {@link TestData}\n     */\n    public static TestData[] getTestDataMinMaxMergeAndMaxBuffered(File[] sources, Analyzer[] analyzers)\n    {\n        List res = new ArrayList(50);\n        TestData ref = new TestData();\n        for (int q = 0; q < analyzers.length; q++)\n        {\n            for (int m = 0; m < sources.length; m++)\n            {\n                ref.id = \"td-\" + q + m + \"_\" + 10 + \"_\" + 10;\n                ref.source = sources[m];\n                ref.analyzer = analyzers[q];\n                ref.maxBufferedDocs = 10;\n                ref.mergeFactor = 10;//MERGEFACTOR_COUNTS[k];\n                ref.compound = true;\n                ref.optimize = true;\n                try\n                {\n                    res.add(ref.clone());\n                }\n                catch (Exception e)\n                {\n                    e.printStackTrace();\n                }\n                ref.id = \"td-\" + q + m  + \"_\" + 10 + \"_\" + 100;\n                ref.source = sources[m];\n                ref.analyzer = analyzers[q];\n                ref.maxBufferedDocs = 10;\n                ref.mergeFactor = 100;//MERGEFACTOR_COUNTS[k];\n                ref.compound = true;\n                ref.optimize = true;\n                try\n                {\n                    res.add(ref.clone());\n                }\n                catch (Exception e)\n                {\n                    e.printStackTrace();\n                }\n                ref.id = \"td-\" + q + m + \"_\" + 100 + \"_\" + 10;\n                ref.source = sources[m];\n                ref.analyzer = analyzers[q];\n                ref.maxBufferedDocs = 100;\n                ref.mergeFactor = 10;//MERGEFACTOR_COUNTS[k];\n                ref.compound = true;\n                ref.optimize = true;\n                try\n                {\n                    res.add(ref.clone());\n                }\n                catch (Exception e)\n                {\n                    e.printStackTrace();\n                }\n                ref.id = \"td-\" + q + m + \"_\" + 100 + \"_\" + 100;\n                ref.source = sources[m];\n                ref.analyzer = analyzers[q];\n                ref.maxBufferedDocs = 100;\n                ref.mergeFactor = 100;//MERGEFACTOR_COUNTS[k];\n                ref.compound = true;\n                ref.optimize = true;\n                try\n                {\n                    res.add(ref.clone());\n                }\n                catch (Exception e)\n                {\n                    e.printStackTrace();\n                }\n            }\n        }\n        return (TestData[]) res.toArray(new TestData[0]);\n    }\n\n","sourceOld":"    /**\n     * Similar to {@link #getAll(java.io.File[], org.apache.lucene.analysis.Analyzer[])} but only uses\n     * maxBufferedDocs of 10 and 100 and same for mergeFactor, thus reducing the number of permutations significantly.\n     * It also only uses compund file and optimize is always true.\n     *\n     * @param sources\n     * @param analyzers\n     * @return An Array of {@link TestData}\n     */\n    public static TestData[] getTestDataMinMaxMergeAndMaxBuffered(File[] sources, Analyzer[] analyzers)\n    {\n        List res = new ArrayList(50);\n        TestData ref = new TestData();\n        for (int q = 0; q < analyzers.length; q++)\n        {\n            for (int m = 0; m < sources.length; m++)\n            {\n                ref.id = \"td-\" + q + m + \"_\" + 10 + \"_\" + 10;\n                ref.source = sources[m];\n                ref.analyzer = analyzers[q];\n                ref.maxBufferedDocs = 10;\n                ref.mergeFactor = 10;//MERGEFACTOR_COUNTS[k];\n                ref.compound = true;\n                ref.optimize = true;\n                try\n                {\n                    res.add(ref.clone());\n                }\n                catch (Exception e)\n                {\n                    e.printStackTrace();\n                }\n                ref.id = \"td-\" + q + m  + \"_\" + 10 + \"_\" + 100;\n                ref.source = sources[m];\n                ref.analyzer = analyzers[q];\n                ref.maxBufferedDocs = 10;\n                ref.mergeFactor = 100;//MERGEFACTOR_COUNTS[k];\n                ref.compound = true;\n                ref.optimize = true;\n                try\n                {\n                    res.add(ref.clone());\n                }\n                catch (Exception e)\n                {\n                    e.printStackTrace();\n                }\n                ref.id = \"td-\" + q + m + \"_\" + 100 + \"_\" + 10;\n                ref.source = sources[m];\n                ref.analyzer = analyzers[q];\n                ref.maxBufferedDocs = 100;\n                ref.mergeFactor = 10;//MERGEFACTOR_COUNTS[k];\n                ref.compound = true;\n                ref.optimize = true;\n                try\n                {\n                    res.add(ref.clone());\n                }\n                catch (Exception e)\n                {\n                    e.printStackTrace();\n                }\n                ref.id = \"td-\" + q + m + \"_\" + 100 + \"_\" + 100;\n                ref.source = sources[m];\n                ref.analyzer = analyzers[q];\n                ref.maxBufferedDocs = 100;\n                ref.mergeFactor = 100;//MERGEFACTOR_COUNTS[k];\n                ref.compound = true;\n                ref.optimize = true;\n                try\n                {\n                    res.add(ref.clone());\n                }\n                catch (Exception e)\n                {\n                    e.printStackTrace();\n                }\n            }\n        }\n        return (TestData[]) res.toArray(new TestData[0]);\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4e1ce9be74263e9659aad8a6ee1f213193710b71","date":1256298843,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"contrib/benchmark/src/java/org/apache/lucene/benchmark/stats/TestData#getTestDataMinMaxMergeAndMaxBuffered(File[],Analyzer[]).mjava","pathOld":"contrib/benchmark/src/java/org/apache/lucene/benchmark/stats/TestData#getTestDataMinMaxMergeAndMaxBuffered(File[],Analyzer[]).mjava","sourceNew":"    /**\n     * Similar to {@link #getAll(java.io.File[], org.apache.lucene.analysis.Analyzer[])} but only uses\n     * maxBufferedDocs of 10 and 100 and same for mergeFactor, thus reducing the number of permutations significantly.\n     * It also only uses compound file and optimize is always true.\n     *\n     * @param sources\n     * @param analyzers\n     * @return An Array of {@link TestData}\n     */\n    public static TestData[] getTestDataMinMaxMergeAndMaxBuffered(File[] sources, Analyzer[] analyzers)\n    {\n        List<TestData> res = new ArrayList<TestData>(50);\n        TestData ref = new TestData();\n        for (int q = 0; q < analyzers.length; q++)\n        {\n            for (int m = 0; m < sources.length; m++)\n            {\n                ref.id = \"td-\" + q + m + \"_\" + 10 + \"_\" + 10;\n                ref.source = sources[m];\n                ref.analyzer = analyzers[q];\n                ref.maxBufferedDocs = 10;\n                ref.mergeFactor = 10;//MERGEFACTOR_COUNTS[k];\n                ref.compound = true;\n                ref.optimize = true;\n                try\n                {\n                    res.add((TestData)ref.clone());\n                }\n                catch (Exception e)\n                {\n                    e.printStackTrace();\n                }\n                ref.id = \"td-\" + q + m  + \"_\" + 10 + \"_\" + 100;\n                ref.source = sources[m];\n                ref.analyzer = analyzers[q];\n                ref.maxBufferedDocs = 10;\n                ref.mergeFactor = 100;//MERGEFACTOR_COUNTS[k];\n                ref.compound = true;\n                ref.optimize = true;\n                try\n                {\n                    res.add((TestData)ref.clone());\n                }\n                catch (Exception e)\n                {\n                    e.printStackTrace();\n                }\n                ref.id = \"td-\" + q + m + \"_\" + 100 + \"_\" + 10;\n                ref.source = sources[m];\n                ref.analyzer = analyzers[q];\n                ref.maxBufferedDocs = 100;\n                ref.mergeFactor = 10;//MERGEFACTOR_COUNTS[k];\n                ref.compound = true;\n                ref.optimize = true;\n                try\n                {\n                    res.add((TestData)ref.clone());\n                }\n                catch (Exception e)\n                {\n                    e.printStackTrace();\n                }\n                ref.id = \"td-\" + q + m + \"_\" + 100 + \"_\" + 100;\n                ref.source = sources[m];\n                ref.analyzer = analyzers[q];\n                ref.maxBufferedDocs = 100;\n                ref.mergeFactor = 100;//MERGEFACTOR_COUNTS[k];\n                ref.compound = true;\n                ref.optimize = true;\n                try\n                {\n                    res.add((TestData)ref.clone());\n                }\n                catch (Exception e)\n                {\n                    e.printStackTrace();\n                }\n            }\n        }\n        return res.toArray(new TestData[0]);\n    }\n\n","sourceOld":"    /**\n     * Similar to {@link #getAll(java.io.File[], org.apache.lucene.analysis.Analyzer[])} but only uses\n     * maxBufferedDocs of 10 and 100 and same for mergeFactor, thus reducing the number of permutations significantly.\n     * It also only uses compound file and optimize is always true.\n     *\n     * @param sources\n     * @param analyzers\n     * @return An Array of {@link TestData}\n     */\n    public static TestData[] getTestDataMinMaxMergeAndMaxBuffered(File[] sources, Analyzer[] analyzers)\n    {\n        List res = new ArrayList(50);\n        TestData ref = new TestData();\n        for (int q = 0; q < analyzers.length; q++)\n        {\n            for (int m = 0; m < sources.length; m++)\n            {\n                ref.id = \"td-\" + q + m + \"_\" + 10 + \"_\" + 10;\n                ref.source = sources[m];\n                ref.analyzer = analyzers[q];\n                ref.maxBufferedDocs = 10;\n                ref.mergeFactor = 10;//MERGEFACTOR_COUNTS[k];\n                ref.compound = true;\n                ref.optimize = true;\n                try\n                {\n                    res.add(ref.clone());\n                }\n                catch (Exception e)\n                {\n                    e.printStackTrace();\n                }\n                ref.id = \"td-\" + q + m  + \"_\" + 10 + \"_\" + 100;\n                ref.source = sources[m];\n                ref.analyzer = analyzers[q];\n                ref.maxBufferedDocs = 10;\n                ref.mergeFactor = 100;//MERGEFACTOR_COUNTS[k];\n                ref.compound = true;\n                ref.optimize = true;\n                try\n                {\n                    res.add(ref.clone());\n                }\n                catch (Exception e)\n                {\n                    e.printStackTrace();\n                }\n                ref.id = \"td-\" + q + m + \"_\" + 100 + \"_\" + 10;\n                ref.source = sources[m];\n                ref.analyzer = analyzers[q];\n                ref.maxBufferedDocs = 100;\n                ref.mergeFactor = 10;//MERGEFACTOR_COUNTS[k];\n                ref.compound = true;\n                ref.optimize = true;\n                try\n                {\n                    res.add(ref.clone());\n                }\n                catch (Exception e)\n                {\n                    e.printStackTrace();\n                }\n                ref.id = \"td-\" + q + m + \"_\" + 100 + \"_\" + 100;\n                ref.source = sources[m];\n                ref.analyzer = analyzers[q];\n                ref.maxBufferedDocs = 100;\n                ref.mergeFactor = 100;//MERGEFACTOR_COUNTS[k];\n                ref.compound = true;\n                ref.optimize = true;\n                try\n                {\n                    res.add(ref.clone());\n                }\n                catch (Exception e)\n                {\n                    e.printStackTrace();\n                }\n            }\n        }\n        return (TestData[]) res.toArray(new TestData[0]);\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9454a6510e2db155fb01faa5c049b06ece95fab9","date":1453508333,"type":5,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/contrib/benchmark/src/java/org/apache/lucene/benchmark/stats/TestData#getTestDataMinMaxMergeAndMaxBuffered(File[],Analyzer[]).mjava","pathOld":"contrib/benchmark/src/java/org/apache/lucene/benchmark/stats/TestData#getTestDataMinMaxMergeAndMaxBuffered(File[],Analyzer[]).mjava","sourceNew":"    /**\n     * Similar to {@link #getAll(java.io.File[], org.apache.lucene.analysis.Analyzer[])} but only uses\n     * maxBufferedDocs of 10 and 100 and same for mergeFactor, thus reducing the number of permutations significantly.\n     * It also only uses compound file and optimize is always true.\n     *\n     * @param sources\n     * @param analyzers\n     * @return An Array of {@link TestData}\n     */\n    public static TestData[] getTestDataMinMaxMergeAndMaxBuffered(File[] sources, Analyzer[] analyzers)\n    {\n        List<TestData> res = new ArrayList<TestData>(50);\n        TestData ref = new TestData();\n        for (int q = 0; q < analyzers.length; q++)\n        {\n            for (int m = 0; m < sources.length; m++)\n            {\n                ref.id = \"td-\" + q + m + \"_\" + 10 + \"_\" + 10;\n                ref.source = sources[m];\n                ref.analyzer = analyzers[q];\n                ref.maxBufferedDocs = 10;\n                ref.mergeFactor = 10;//MERGEFACTOR_COUNTS[k];\n                ref.compound = true;\n                ref.optimize = true;\n                try\n                {\n                    res.add((TestData)ref.clone());\n                }\n                catch (Exception e)\n                {\n                    e.printStackTrace();\n                }\n                ref.id = \"td-\" + q + m  + \"_\" + 10 + \"_\" + 100;\n                ref.source = sources[m];\n                ref.analyzer = analyzers[q];\n                ref.maxBufferedDocs = 10;\n                ref.mergeFactor = 100;//MERGEFACTOR_COUNTS[k];\n                ref.compound = true;\n                ref.optimize = true;\n                try\n                {\n                    res.add((TestData)ref.clone());\n                }\n                catch (Exception e)\n                {\n                    e.printStackTrace();\n                }\n                ref.id = \"td-\" + q + m + \"_\" + 100 + \"_\" + 10;\n                ref.source = sources[m];\n                ref.analyzer = analyzers[q];\n                ref.maxBufferedDocs = 100;\n                ref.mergeFactor = 10;//MERGEFACTOR_COUNTS[k];\n                ref.compound = true;\n                ref.optimize = true;\n                try\n                {\n                    res.add((TestData)ref.clone());\n                }\n                catch (Exception e)\n                {\n                    e.printStackTrace();\n                }\n                ref.id = \"td-\" + q + m + \"_\" + 100 + \"_\" + 100;\n                ref.source = sources[m];\n                ref.analyzer = analyzers[q];\n                ref.maxBufferedDocs = 100;\n                ref.mergeFactor = 100;//MERGEFACTOR_COUNTS[k];\n                ref.compound = true;\n                ref.optimize = true;\n                try\n                {\n                    res.add((TestData)ref.clone());\n                }\n                catch (Exception e)\n                {\n                    e.printStackTrace();\n                }\n            }\n        }\n        return res.toArray(new TestData[0]);\n    }\n\n","sourceOld":"    /**\n     * Similar to {@link #getAll(java.io.File[], org.apache.lucene.analysis.Analyzer[])} but only uses\n     * maxBufferedDocs of 10 and 100 and same for mergeFactor, thus reducing the number of permutations significantly.\n     * It also only uses compound file and optimize is always true.\n     *\n     * @param sources\n     * @param analyzers\n     * @return An Array of {@link TestData}\n     */\n    public static TestData[] getTestDataMinMaxMergeAndMaxBuffered(File[] sources, Analyzer[] analyzers)\n    {\n        List<TestData> res = new ArrayList<TestData>(50);\n        TestData ref = new TestData();\n        for (int q = 0; q < analyzers.length; q++)\n        {\n            for (int m = 0; m < sources.length; m++)\n            {\n                ref.id = \"td-\" + q + m + \"_\" + 10 + \"_\" + 10;\n                ref.source = sources[m];\n                ref.analyzer = analyzers[q];\n                ref.maxBufferedDocs = 10;\n                ref.mergeFactor = 10;//MERGEFACTOR_COUNTS[k];\n                ref.compound = true;\n                ref.optimize = true;\n                try\n                {\n                    res.add((TestData)ref.clone());\n                }\n                catch (Exception e)\n                {\n                    e.printStackTrace();\n                }\n                ref.id = \"td-\" + q + m  + \"_\" + 10 + \"_\" + 100;\n                ref.source = sources[m];\n                ref.analyzer = analyzers[q];\n                ref.maxBufferedDocs = 10;\n                ref.mergeFactor = 100;//MERGEFACTOR_COUNTS[k];\n                ref.compound = true;\n                ref.optimize = true;\n                try\n                {\n                    res.add((TestData)ref.clone());\n                }\n                catch (Exception e)\n                {\n                    e.printStackTrace();\n                }\n                ref.id = \"td-\" + q + m + \"_\" + 100 + \"_\" + 10;\n                ref.source = sources[m];\n                ref.analyzer = analyzers[q];\n                ref.maxBufferedDocs = 100;\n                ref.mergeFactor = 10;//MERGEFACTOR_COUNTS[k];\n                ref.compound = true;\n                ref.optimize = true;\n                try\n                {\n                    res.add((TestData)ref.clone());\n                }\n                catch (Exception e)\n                {\n                    e.printStackTrace();\n                }\n                ref.id = \"td-\" + q + m + \"_\" + 100 + \"_\" + 100;\n                ref.source = sources[m];\n                ref.analyzer = analyzers[q];\n                ref.maxBufferedDocs = 100;\n                ref.mergeFactor = 100;//MERGEFACTOR_COUNTS[k];\n                ref.compound = true;\n                ref.optimize = true;\n                try\n                {\n                    res.add((TestData)ref.clone());\n                }\n                catch (Exception e)\n                {\n                    e.printStackTrace();\n                }\n            }\n        }\n        return res.toArray(new TestData[0]);\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"226abb667f503323e0d9473af1883fa03ef3a3fd":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"4e1ce9be74263e9659aad8a6ee1f213193710b71":["add7d922e63099fbce8f0a1b31216df7ef5067f1"],"add7d922e63099fbce8f0a1b31216df7ef5067f1":["3738fa43eaa87dc7b393fe98b04cde1019e20bac"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"3738fa43eaa87dc7b393fe98b04cde1019e20bac":["226abb667f503323e0d9473af1883fa03ef3a3fd"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["4e1ce9be74263e9659aad8a6ee1f213193710b71"]},"commit2Childs":{"226abb667f503323e0d9473af1883fa03ef3a3fd":["3738fa43eaa87dc7b393fe98b04cde1019e20bac"],"4e1ce9be74263e9659aad8a6ee1f213193710b71":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["226abb667f503323e0d9473af1883fa03ef3a3fd"],"add7d922e63099fbce8f0a1b31216df7ef5067f1":["4e1ce9be74263e9659aad8a6ee1f213193710b71"],"3738fa43eaa87dc7b393fe98b04cde1019e20bac":["add7d922e63099fbce8f0a1b31216df7ef5067f1"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"9454a6510e2db155fb01faa5c049b06ece95fab9":["cd5edd1f2b162a5cfa08efd17851a07373a96817"]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}