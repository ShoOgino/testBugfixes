{"path":"lucene/src/test/org/apache/lucene/codecs/lucene40/TestReuseDocsEnum#testReuseDocsEnumSameBitsOrNull().mjava","commits":[{"id":"a0ae5e3ed1232483b7b8a014f175a5fe43595982","date":1324062192,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/codecs/lucene40/TestReuseDocsEnum#testReuseDocsEnumSameBitsOrNull().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/codecs/lucene40/TestReuseDocsEnum#testReuseDocsEnumSameBitsOrNull().mjava","sourceNew":"  // tests for reuse only if bits are the same either null or the same instance\n  public void testReuseDocsEnumSameBitsOrNull() throws IOException {\n    Directory dir = newDirectory();\n    Codec cp = _TestUtil.alwaysPostingsFormat(new Lucene40PostingsFormat());\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).setCodec(cp));\n    int numdocs = atLeast(20);\n    createRandomIndex(numdocs, writer, random);\n    writer.commit();\n\n    IndexReader open = IndexReader.open(dir);\n    IndexReader[] sequentialSubReaders = open.getSequentialSubReaders();\n    for (IndexReader indexReader : sequentialSubReaders) {\n      Terms terms = indexReader.terms(\"body\");\n      TermsEnum iterator = terms.iterator(null);\n      IdentityHashMap<DocsEnum, Boolean> enums = new IdentityHashMap<DocsEnum, Boolean>();\n      MatchNoBits bits = new Bits.MatchNoBits(open.maxDoc());\n      DocsEnum docs = null;\n      while ((iterator.next()) != null) {\n        docs = iterator.docs(bits, docs, random.nextBoolean());\n        enums.put(docs, true);\n      }\n      \n      assertEquals(1, enums.size());\n      enums.clear();\n      iterator = terms.iterator(null);\n      docs = null;\n      while ((iterator.next()) != null) {\n        docs = iterator.docs(new Bits.MatchNoBits(open.maxDoc()), docs, random.nextBoolean());\n        enums.put(docs, true);\n      }\n      assertEquals(terms.getUniqueTermCount(), enums.size());  \n      \n      enums.clear();\n      iterator = terms.iterator(null);\n      docs = null;\n      while ((iterator.next()) != null) {\n        docs = iterator.docs(null, docs, random.nextBoolean());\n        enums.put(docs, true);\n      }\n      assertEquals(1, enums.size());  \n    }\n    IOUtils.close(writer, open, dir);\n  }\n\n","sourceOld":"  // tests for reuse only if bits are the same either null or the same instance\n  public void testReuseDocsEnumSameBitsOrNull() throws IOException {\n    Directory dir = newDirectory();\n    Codec cp = _TestUtil.alwaysPostingsFormat(new Lucene40PostingsFormat());\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).setCodec(cp));\n    int numdocs = atLeast(20);\n    createRandomIndex(numdocs, writer, random);\n    writer.commit();\n\n    IndexReader open = IndexReader.open(dir);\n    IndexReader[] sequentialSubReaders = open.getSequentialSubReaders();\n    for (IndexReader indexReader : sequentialSubReaders) {\n      Terms terms = indexReader.terms(\"body\");\n      TermsEnum iterator = terms.iterator(null);\n      IdentityHashMap<DocsEnum, Boolean> enums = new IdentityHashMap<DocsEnum, Boolean>();\n      MatchNoBits bits = new Bits.MatchNoBits(open.maxDoc());\n      DocsEnum docs = null;\n      while ((iterator.next()) != null) {\n        docs = iterator.docs(bits, docs, random.nextBoolean());\n        enums.put(docs, true);\n      }\n      \n      assertEquals(1, enums.size());\n      enums.clear();\n      iterator = terms.iterator(null);\n      docs = null;\n      while ((iterator.next()) != null) {\n        docs = iterator.docs(new Bits.MatchNoBits(open.maxDoc()), docs, random.nextBoolean());\n        enums.put(docs, true);\n      }\n      assertEquals(terms.getUniqueTermCount(), enums.size());  \n      \n      enums.clear();\n      iterator = terms.iterator(null);\n      docs = null;\n      while ((iterator.next()) != null) {\n        docs = iterator.docs(null, docs, random.nextBoolean());\n        enums.put(docs, true);\n      }\n      assertEquals(1, enums.size());  \n    }\n    IOUtils.close(writer, open, dir);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d40b62adb64d8f7b2f85ee849349cfb0bef03f45","date":1327855938,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/codecs/lucene40/TestReuseDocsEnum#testReuseDocsEnumSameBitsOrNull().mjava","pathOld":"lucene/src/test/org/apache/lucene/codecs/lucene40/TestReuseDocsEnum#testReuseDocsEnumSameBitsOrNull().mjava","sourceNew":"  // tests for reuse only if bits are the same either null or the same instance\n  public void testReuseDocsEnumSameBitsOrNull() throws IOException {\n    Directory dir = newDirectory();\n    Codec cp = _TestUtil.alwaysPostingsFormat(new Lucene40PostingsFormat());\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).setCodec(cp));\n    int numdocs = atLeast(20);\n    createRandomIndex(numdocs, writer, random);\n    writer.commit();\n\n    DirectoryReader open = DirectoryReader.open(dir);\n    IndexReader[] sequentialSubReaders = open.getSequentialSubReaders();\n    for (IndexReader indexReader : sequentialSubReaders) {\n      Terms terms = ((AtomicIndexReader) indexReader).terms(\"body\");\n      TermsEnum iterator = terms.iterator(null);\n      IdentityHashMap<DocsEnum, Boolean> enums = new IdentityHashMap<DocsEnum, Boolean>();\n      MatchNoBits bits = new Bits.MatchNoBits(open.maxDoc());\n      DocsEnum docs = null;\n      while ((iterator.next()) != null) {\n        docs = iterator.docs(bits, docs, random.nextBoolean());\n        enums.put(docs, true);\n      }\n      \n      assertEquals(1, enums.size());\n      enums.clear();\n      iterator = terms.iterator(null);\n      docs = null;\n      while ((iterator.next()) != null) {\n        docs = iterator.docs(new Bits.MatchNoBits(open.maxDoc()), docs, random.nextBoolean());\n        enums.put(docs, true);\n      }\n      assertEquals(terms.getUniqueTermCount(), enums.size());  \n      \n      enums.clear();\n      iterator = terms.iterator(null);\n      docs = null;\n      while ((iterator.next()) != null) {\n        docs = iterator.docs(null, docs, random.nextBoolean());\n        enums.put(docs, true);\n      }\n      assertEquals(1, enums.size());  \n    }\n    IOUtils.close(writer, open, dir);\n  }\n\n","sourceOld":"  // tests for reuse only if bits are the same either null or the same instance\n  public void testReuseDocsEnumSameBitsOrNull() throws IOException {\n    Directory dir = newDirectory();\n    Codec cp = _TestUtil.alwaysPostingsFormat(new Lucene40PostingsFormat());\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).setCodec(cp));\n    int numdocs = atLeast(20);\n    createRandomIndex(numdocs, writer, random);\n    writer.commit();\n\n    IndexReader open = IndexReader.open(dir);\n    IndexReader[] sequentialSubReaders = open.getSequentialSubReaders();\n    for (IndexReader indexReader : sequentialSubReaders) {\n      Terms terms = indexReader.terms(\"body\");\n      TermsEnum iterator = terms.iterator(null);\n      IdentityHashMap<DocsEnum, Boolean> enums = new IdentityHashMap<DocsEnum, Boolean>();\n      MatchNoBits bits = new Bits.MatchNoBits(open.maxDoc());\n      DocsEnum docs = null;\n      while ((iterator.next()) != null) {\n        docs = iterator.docs(bits, docs, random.nextBoolean());\n        enums.put(docs, true);\n      }\n      \n      assertEquals(1, enums.size());\n      enums.clear();\n      iterator = terms.iterator(null);\n      docs = null;\n      while ((iterator.next()) != null) {\n        docs = iterator.docs(new Bits.MatchNoBits(open.maxDoc()), docs, random.nextBoolean());\n        enums.put(docs, true);\n      }\n      assertEquals(terms.getUniqueTermCount(), enums.size());  \n      \n      enums.clear();\n      iterator = terms.iterator(null);\n      docs = null;\n      while ((iterator.next()) != null) {\n        docs = iterator.docs(null, docs, random.nextBoolean());\n        enums.put(docs, true);\n      }\n      assertEquals(1, enums.size());  \n    }\n    IOUtils.close(writer, open, dir);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"da6d5ac19a80d65b1e864251f155d30960353b7e","date":1327881054,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/codecs/lucene40/TestReuseDocsEnum#testReuseDocsEnumSameBitsOrNull().mjava","pathOld":"lucene/src/test/org/apache/lucene/codecs/lucene40/TestReuseDocsEnum#testReuseDocsEnumSameBitsOrNull().mjava","sourceNew":"  // tests for reuse only if bits are the same either null or the same instance\n  public void testReuseDocsEnumSameBitsOrNull() throws IOException {\n    Directory dir = newDirectory();\n    Codec cp = _TestUtil.alwaysPostingsFormat(new Lucene40PostingsFormat());\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).setCodec(cp));\n    int numdocs = atLeast(20);\n    createRandomIndex(numdocs, writer, random);\n    writer.commit();\n\n    DirectoryReader open = DirectoryReader.open(dir);\n    IndexReader[] sequentialSubReaders = open.getSequentialSubReaders();\n    for (IndexReader indexReader : sequentialSubReaders) {\n      Terms terms = ((AtomicReader) indexReader).terms(\"body\");\n      TermsEnum iterator = terms.iterator(null);\n      IdentityHashMap<DocsEnum, Boolean> enums = new IdentityHashMap<DocsEnum, Boolean>();\n      MatchNoBits bits = new Bits.MatchNoBits(open.maxDoc());\n      DocsEnum docs = null;\n      while ((iterator.next()) != null) {\n        docs = iterator.docs(bits, docs, random.nextBoolean());\n        enums.put(docs, true);\n      }\n      \n      assertEquals(1, enums.size());\n      enums.clear();\n      iterator = terms.iterator(null);\n      docs = null;\n      while ((iterator.next()) != null) {\n        docs = iterator.docs(new Bits.MatchNoBits(open.maxDoc()), docs, random.nextBoolean());\n        enums.put(docs, true);\n      }\n      assertEquals(terms.getUniqueTermCount(), enums.size());  \n      \n      enums.clear();\n      iterator = terms.iterator(null);\n      docs = null;\n      while ((iterator.next()) != null) {\n        docs = iterator.docs(null, docs, random.nextBoolean());\n        enums.put(docs, true);\n      }\n      assertEquals(1, enums.size());  \n    }\n    IOUtils.close(writer, open, dir);\n  }\n\n","sourceOld":"  // tests for reuse only if bits are the same either null or the same instance\n  public void testReuseDocsEnumSameBitsOrNull() throws IOException {\n    Directory dir = newDirectory();\n    Codec cp = _TestUtil.alwaysPostingsFormat(new Lucene40PostingsFormat());\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).setCodec(cp));\n    int numdocs = atLeast(20);\n    createRandomIndex(numdocs, writer, random);\n    writer.commit();\n\n    DirectoryReader open = DirectoryReader.open(dir);\n    IndexReader[] sequentialSubReaders = open.getSequentialSubReaders();\n    for (IndexReader indexReader : sequentialSubReaders) {\n      Terms terms = ((AtomicIndexReader) indexReader).terms(\"body\");\n      TermsEnum iterator = terms.iterator(null);\n      IdentityHashMap<DocsEnum, Boolean> enums = new IdentityHashMap<DocsEnum, Boolean>();\n      MatchNoBits bits = new Bits.MatchNoBits(open.maxDoc());\n      DocsEnum docs = null;\n      while ((iterator.next()) != null) {\n        docs = iterator.docs(bits, docs, random.nextBoolean());\n        enums.put(docs, true);\n      }\n      \n      assertEquals(1, enums.size());\n      enums.clear();\n      iterator = terms.iterator(null);\n      docs = null;\n      while ((iterator.next()) != null) {\n        docs = iterator.docs(new Bits.MatchNoBits(open.maxDoc()), docs, random.nextBoolean());\n        enums.put(docs, true);\n      }\n      assertEquals(terms.getUniqueTermCount(), enums.size());  \n      \n      enums.clear();\n      iterator = terms.iterator(null);\n      docs = null;\n      while ((iterator.next()) != null) {\n        docs = iterator.docs(null, docs, random.nextBoolean());\n        enums.put(docs, true);\n      }\n      assertEquals(1, enums.size());  \n    }\n    IOUtils.close(writer, open, dir);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5cab9a86bd67202d20b6adc463008c8e982b070a","date":1327966443,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/codecs/lucene40/TestReuseDocsEnum#testReuseDocsEnumSameBitsOrNull().mjava","pathOld":"lucene/src/test/org/apache/lucene/codecs/lucene40/TestReuseDocsEnum#testReuseDocsEnumSameBitsOrNull().mjava","sourceNew":"  // tests for reuse only if bits are the same either null or the same instance\n  public void testReuseDocsEnumSameBitsOrNull() throws IOException {\n    Directory dir = newDirectory();\n    Codec cp = _TestUtil.alwaysPostingsFormat(new Lucene40PostingsFormat());\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).setCodec(cp));\n    int numdocs = atLeast(20);\n    createRandomIndex(numdocs, writer, random);\n    writer.commit();\n\n    DirectoryReader open = DirectoryReader.open(dir);\n    IndexReader[] sequentialSubReaders = open.getSequentialSubReaders();\n    for (IndexReader indexReader : sequentialSubReaders) {\n      Terms terms = ((AtomicReader) indexReader).terms(\"body\");\n      TermsEnum iterator = terms.iterator(null);\n      IdentityHashMap<DocsEnum, Boolean> enums = new IdentityHashMap<DocsEnum, Boolean>();\n      MatchNoBits bits = new Bits.MatchNoBits(open.maxDoc());\n      DocsEnum docs = null;\n      while ((iterator.next()) != null) {\n        docs = iterator.docs(bits, docs, random.nextBoolean());\n        enums.put(docs, true);\n      }\n      \n      assertEquals(1, enums.size());\n      enums.clear();\n      iterator = terms.iterator(null);\n      docs = null;\n      while ((iterator.next()) != null) {\n        docs = iterator.docs(new Bits.MatchNoBits(open.maxDoc()), docs, random.nextBoolean());\n        enums.put(docs, true);\n      }\n      assertEquals(terms.getUniqueTermCount(), enums.size());  \n      \n      enums.clear();\n      iterator = terms.iterator(null);\n      docs = null;\n      while ((iterator.next()) != null) {\n        docs = iterator.docs(null, docs, random.nextBoolean());\n        enums.put(docs, true);\n      }\n      assertEquals(1, enums.size());  \n    }\n    IOUtils.close(writer, open, dir);\n  }\n\n","sourceOld":"  // tests for reuse only if bits are the same either null or the same instance\n  public void testReuseDocsEnumSameBitsOrNull() throws IOException {\n    Directory dir = newDirectory();\n    Codec cp = _TestUtil.alwaysPostingsFormat(new Lucene40PostingsFormat());\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).setCodec(cp));\n    int numdocs = atLeast(20);\n    createRandomIndex(numdocs, writer, random);\n    writer.commit();\n\n    IndexReader open = IndexReader.open(dir);\n    IndexReader[] sequentialSubReaders = open.getSequentialSubReaders();\n    for (IndexReader indexReader : sequentialSubReaders) {\n      Terms terms = indexReader.terms(\"body\");\n      TermsEnum iterator = terms.iterator(null);\n      IdentityHashMap<DocsEnum, Boolean> enums = new IdentityHashMap<DocsEnum, Boolean>();\n      MatchNoBits bits = new Bits.MatchNoBits(open.maxDoc());\n      DocsEnum docs = null;\n      while ((iterator.next()) != null) {\n        docs = iterator.docs(bits, docs, random.nextBoolean());\n        enums.put(docs, true);\n      }\n      \n      assertEquals(1, enums.size());\n      enums.clear();\n      iterator = terms.iterator(null);\n      docs = null;\n      while ((iterator.next()) != null) {\n        docs = iterator.docs(new Bits.MatchNoBits(open.maxDoc()), docs, random.nextBoolean());\n        enums.put(docs, true);\n      }\n      assertEquals(terms.getUniqueTermCount(), enums.size());  \n      \n      enums.clear();\n      iterator = terms.iterator(null);\n      docs = null;\n      while ((iterator.next()) != null) {\n        docs = iterator.docs(null, docs, random.nextBoolean());\n        enums.put(docs, true);\n      }\n      assertEquals(1, enums.size());  \n    }\n    IOUtils.close(writer, open, dir);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":5,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/lucene40/TestReuseDocsEnum#testReuseDocsEnumSameBitsOrNull().mjava","pathOld":"lucene/src/test/org/apache/lucene/codecs/lucene40/TestReuseDocsEnum#testReuseDocsEnumSameBitsOrNull().mjava","sourceNew":"  // tests for reuse only if bits are the same either null or the same instance\n  public void testReuseDocsEnumSameBitsOrNull() throws IOException {\n    Directory dir = newDirectory();\n    Codec cp = _TestUtil.alwaysPostingsFormat(new Lucene40PostingsFormat());\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).setCodec(cp));\n    int numdocs = atLeast(20);\n    createRandomIndex(numdocs, writer, random);\n    writer.commit();\n\n    DirectoryReader open = DirectoryReader.open(dir);\n    IndexReader[] sequentialSubReaders = open.getSequentialSubReaders();\n    for (IndexReader indexReader : sequentialSubReaders) {\n      Terms terms = ((AtomicReader) indexReader).terms(\"body\");\n      TermsEnum iterator = terms.iterator(null);\n      IdentityHashMap<DocsEnum, Boolean> enums = new IdentityHashMap<DocsEnum, Boolean>();\n      MatchNoBits bits = new Bits.MatchNoBits(open.maxDoc());\n      DocsEnum docs = null;\n      while ((iterator.next()) != null) {\n        docs = iterator.docs(bits, docs, random.nextBoolean());\n        enums.put(docs, true);\n      }\n      \n      assertEquals(1, enums.size());\n      enums.clear();\n      iterator = terms.iterator(null);\n      docs = null;\n      while ((iterator.next()) != null) {\n        docs = iterator.docs(new Bits.MatchNoBits(open.maxDoc()), docs, random.nextBoolean());\n        enums.put(docs, true);\n      }\n      assertEquals(terms.getUniqueTermCount(), enums.size());  \n      \n      enums.clear();\n      iterator = terms.iterator(null);\n      docs = null;\n      while ((iterator.next()) != null) {\n        docs = iterator.docs(null, docs, random.nextBoolean());\n        enums.put(docs, true);\n      }\n      assertEquals(1, enums.size());  \n    }\n    IOUtils.close(writer, open, dir);\n  }\n\n","sourceOld":"  // tests for reuse only if bits are the same either null or the same instance\n  public void testReuseDocsEnumSameBitsOrNull() throws IOException {\n    Directory dir = newDirectory();\n    Codec cp = _TestUtil.alwaysPostingsFormat(new Lucene40PostingsFormat());\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).setCodec(cp));\n    int numdocs = atLeast(20);\n    createRandomIndex(numdocs, writer, random);\n    writer.commit();\n\n    DirectoryReader open = DirectoryReader.open(dir);\n    IndexReader[] sequentialSubReaders = open.getSequentialSubReaders();\n    for (IndexReader indexReader : sequentialSubReaders) {\n      Terms terms = ((AtomicReader) indexReader).terms(\"body\");\n      TermsEnum iterator = terms.iterator(null);\n      IdentityHashMap<DocsEnum, Boolean> enums = new IdentityHashMap<DocsEnum, Boolean>();\n      MatchNoBits bits = new Bits.MatchNoBits(open.maxDoc());\n      DocsEnum docs = null;\n      while ((iterator.next()) != null) {\n        docs = iterator.docs(bits, docs, random.nextBoolean());\n        enums.put(docs, true);\n      }\n      \n      assertEquals(1, enums.size());\n      enums.clear();\n      iterator = terms.iterator(null);\n      docs = null;\n      while ((iterator.next()) != null) {\n        docs = iterator.docs(new Bits.MatchNoBits(open.maxDoc()), docs, random.nextBoolean());\n        enums.put(docs, true);\n      }\n      assertEquals(terms.getUniqueTermCount(), enums.size());  \n      \n      enums.clear();\n      iterator = terms.iterator(null);\n      docs = null;\n      while ((iterator.next()) != null) {\n        docs = iterator.docs(null, docs, random.nextBoolean());\n        enums.put(docs, true);\n      }\n      assertEquals(1, enums.size());  \n    }\n    IOUtils.close(writer, open, dir);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"da6d5ac19a80d65b1e864251f155d30960353b7e":["d40b62adb64d8f7b2f85ee849349cfb0bef03f45"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["5cab9a86bd67202d20b6adc463008c8e982b070a"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"d40b62adb64d8f7b2f85ee849349cfb0bef03f45":["a0ae5e3ed1232483b7b8a014f175a5fe43595982"],"a0ae5e3ed1232483b7b8a014f175a5fe43595982":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"5cab9a86bd67202d20b6adc463008c8e982b070a":["a0ae5e3ed1232483b7b8a014f175a5fe43595982","da6d5ac19a80d65b1e864251f155d30960353b7e"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"]},"commit2Childs":{"da6d5ac19a80d65b1e864251f155d30960353b7e":["5cab9a86bd67202d20b6adc463008c8e982b070a"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["a0ae5e3ed1232483b7b8a014f175a5fe43595982"],"d40b62adb64d8f7b2f85ee849349cfb0bef03f45":["da6d5ac19a80d65b1e864251f155d30960353b7e"],"a0ae5e3ed1232483b7b8a014f175a5fe43595982":["d40b62adb64d8f7b2f85ee849349cfb0bef03f45","5cab9a86bd67202d20b6adc463008c8e982b070a"],"5cab9a86bd67202d20b6adc463008c8e982b070a":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}