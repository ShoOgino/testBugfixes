{"path":"lucene/test-framework/src/java/org/apache/lucene/codecs/lucene42/Lucene42DocValuesConsumer#addNumericField(FieldInfo,Iterable[Number],boolean).mjava","commits":[{"id":"09a42395865f791464f0bd5f6118a4abbfa3eb8a","date":1376920143,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/codecs/lucene42/Lucene42DocValuesConsumer#addNumericField(FieldInfo,Iterable[Number],boolean).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene42/Lucene42DocValuesConsumer#addNumericField(FieldInfo,Iterable[Number],boolean).mjava","sourceNew":"  void addNumericField(FieldInfo field, Iterable<Number> values, boolean optimizeStorage) throws IOException {\n    meta.writeVInt(field.number);\n    meta.writeByte(NUMBER);\n    meta.writeLong(data.getFilePointer());\n    long minValue = Long.MAX_VALUE;\n    long maxValue = Long.MIN_VALUE;\n    long gcd = 0;\n    // TODO: more efficient?\n    HashSet<Long> uniqueValues = null;\n    if (optimizeStorage) {\n      uniqueValues = new HashSet<>();\n\n      long count = 0;\n      for (Number nv : values) {\n        // TODO: support this as MemoryDVFormat (and be smart about missing maybe)\n        final long v = nv == null ? 0 : nv.longValue();\n\n        if (gcd != 1) {\n          if (v < Long.MIN_VALUE / 2 || v > Long.MAX_VALUE / 2) {\n            // in that case v - minValue might overflow and make the GCD computation return\n            // wrong results. Since these extreme values are unlikely, we just discard\n            // GCD computation for them\n            gcd = 1;\n          } else if (count != 0) { // minValue needs to be set first\n            gcd = MathUtil.gcd(gcd, v - minValue);\n          }\n        }\n\n        minValue = Math.min(minValue, v);\n        maxValue = Math.max(maxValue, v);\n\n        if (uniqueValues != null) {\n          if (uniqueValues.add(v)) {\n            if (uniqueValues.size() > 256) {\n              uniqueValues = null;\n            }\n          }\n        }\n\n        ++count;\n      }\n      assert count == maxDoc;\n    }\n\n    if (uniqueValues != null) {\n      // small number of unique values\n      final int bitsPerValue = PackedInts.bitsRequired(uniqueValues.size()-1);\n      FormatAndBits formatAndBits = PackedInts.fastestFormatAndBits(maxDoc, bitsPerValue, acceptableOverheadRatio);\n      if (formatAndBits.bitsPerValue == 8 && minValue >= Byte.MIN_VALUE && maxValue <= Byte.MAX_VALUE) {\n        meta.writeByte(UNCOMPRESSED); // uncompressed\n        for (Number nv : values) {\n          data.writeByte(nv == null ? 0 : (byte) nv.longValue());\n        }\n      } else {\n        meta.writeByte(TABLE_COMPRESSED); // table-compressed\n        Long[] decode = uniqueValues.toArray(new Long[uniqueValues.size()]);\n        final HashMap<Long,Integer> encode = new HashMap<Long,Integer>();\n        data.writeVInt(decode.length);\n        for (int i = 0; i < decode.length; i++) {\n          data.writeLong(decode[i]);\n          encode.put(decode[i], i);\n        }\n\n        meta.writeVInt(PackedInts.VERSION_CURRENT);\n        data.writeVInt(formatAndBits.format.getId());\n        data.writeVInt(formatAndBits.bitsPerValue);\n\n        final PackedInts.Writer writer = PackedInts.getWriterNoHeader(data, formatAndBits.format, maxDoc, formatAndBits.bitsPerValue, PackedInts.DEFAULT_BUFFER_SIZE);\n        for(Number nv : values) {\n          writer.add(encode.get(nv == null ? 0 : nv.longValue()));\n        }\n        writer.finish();\n      }\n    } else if (gcd != 0 && gcd != 1) {\n      meta.writeByte(GCD_COMPRESSED);\n      meta.writeVInt(PackedInts.VERSION_CURRENT);\n      data.writeLong(minValue);\n      data.writeLong(gcd);\n      data.writeVInt(BLOCK_SIZE);\n\n      final BlockPackedWriter writer = new BlockPackedWriter(data, BLOCK_SIZE);\n      for (Number nv : values) {\n        long value = nv == null ? 0 : nv.longValue();\n        writer.add((value - minValue) / gcd);\n      }\n      writer.finish();\n    } else {\n      meta.writeByte(DELTA_COMPRESSED); // delta-compressed\n\n      meta.writeVInt(PackedInts.VERSION_CURRENT);\n      data.writeVInt(BLOCK_SIZE);\n\n      final BlockPackedWriter writer = new BlockPackedWriter(data, BLOCK_SIZE);\n      for (Number nv : values) {\n        writer.add(nv == null ? 0 : nv.longValue());\n      }\n      writer.finish();\n    }\n  }\n\n","sourceOld":"  void addNumericField(FieldInfo field, Iterable<Number> values, boolean optimizeStorage) throws IOException {\n    meta.writeVInt(field.number);\n    meta.writeByte(NUMBER);\n    meta.writeLong(data.getFilePointer());\n    long minValue = Long.MAX_VALUE;\n    long maxValue = Long.MIN_VALUE;\n    long gcd = 0;\n    // TODO: more efficient?\n    HashSet<Long> uniqueValues = null;\n    if (optimizeStorage) {\n      uniqueValues = new HashSet<>();\n\n      long count = 0;\n      for (Number nv : values) {\n        // TODO: support this as MemoryDVFormat (and be smart about missing maybe)\n        final long v = nv == null ? 0 : nv.longValue();\n\n        if (gcd != 1) {\n          if (v < Long.MIN_VALUE / 2 || v > Long.MAX_VALUE / 2) {\n            // in that case v - minValue might overflow and make the GCD computation return\n            // wrong results. Since these extreme values are unlikely, we just discard\n            // GCD computation for them\n            gcd = 1;\n          } else if (count != 0) { // minValue needs to be set first\n            gcd = MathUtil.gcd(gcd, v - minValue);\n          }\n        }\n\n        minValue = Math.min(minValue, v);\n        maxValue = Math.max(maxValue, v);\n\n        if (uniqueValues != null) {\n          if (uniqueValues.add(v)) {\n            if (uniqueValues.size() > 256) {\n              uniqueValues = null;\n            }\n          }\n        }\n\n        ++count;\n      }\n      assert count == maxDoc;\n    }\n\n    if (uniqueValues != null) {\n      // small number of unique values\n      final int bitsPerValue = PackedInts.bitsRequired(uniqueValues.size()-1);\n      FormatAndBits formatAndBits = PackedInts.fastestFormatAndBits(maxDoc, bitsPerValue, acceptableOverheadRatio);\n      if (formatAndBits.bitsPerValue == 8 && minValue >= Byte.MIN_VALUE && maxValue <= Byte.MAX_VALUE) {\n        meta.writeByte(UNCOMPRESSED); // uncompressed\n        for (Number nv : values) {\n          data.writeByte(nv == null ? 0 : (byte) nv.longValue());\n        }\n      } else {\n        meta.writeByte(TABLE_COMPRESSED); // table-compressed\n        Long[] decode = uniqueValues.toArray(new Long[uniqueValues.size()]);\n        final HashMap<Long,Integer> encode = new HashMap<Long,Integer>();\n        data.writeVInt(decode.length);\n        for (int i = 0; i < decode.length; i++) {\n          data.writeLong(decode[i]);\n          encode.put(decode[i], i);\n        }\n\n        meta.writeVInt(PackedInts.VERSION_CURRENT);\n        data.writeVInt(formatAndBits.format.getId());\n        data.writeVInt(formatAndBits.bitsPerValue);\n\n        final PackedInts.Writer writer = PackedInts.getWriterNoHeader(data, formatAndBits.format, maxDoc, formatAndBits.bitsPerValue, PackedInts.DEFAULT_BUFFER_SIZE);\n        for(Number nv : values) {\n          writer.add(encode.get(nv == null ? 0 : nv.longValue()));\n        }\n        writer.finish();\n      }\n    } else if (gcd != 0 && gcd != 1) {\n      meta.writeByte(GCD_COMPRESSED);\n      meta.writeVInt(PackedInts.VERSION_CURRENT);\n      data.writeLong(minValue);\n      data.writeLong(gcd);\n      data.writeVInt(BLOCK_SIZE);\n\n      final BlockPackedWriter writer = new BlockPackedWriter(data, BLOCK_SIZE);\n      for (Number nv : values) {\n        long value = nv == null ? 0 : nv.longValue();\n        writer.add((value - minValue) / gcd);\n      }\n      writer.finish();\n    } else {\n      meta.writeByte(DELTA_COMPRESSED); // delta-compressed\n\n      meta.writeVInt(PackedInts.VERSION_CURRENT);\n      data.writeVInt(BLOCK_SIZE);\n\n      final BlockPackedWriter writer = new BlockPackedWriter(data, BLOCK_SIZE);\n      for (Number nv : values) {\n        writer.add(nv == null ? 0 : nv.longValue());\n      }\n      writer.finish();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e70ec9cf78e14cbbf13fd0e1a9aefa8081c325ff","date":1377034255,"type":1,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/codecs/lucene42/Lucene42DocValuesConsumer#addNumericField(FieldInfo,Iterable[Number],boolean).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene42/Lucene42DocValuesConsumer#addNumericField(FieldInfo,Iterable[Number],boolean).mjava","sourceNew":"  void addNumericField(FieldInfo field, Iterable<Number> values, boolean optimizeStorage) throws IOException {\n    meta.writeVInt(field.number);\n    meta.writeByte(NUMBER);\n    meta.writeLong(data.getFilePointer());\n    long minValue = Long.MAX_VALUE;\n    long maxValue = Long.MIN_VALUE;\n    long gcd = 0;\n    // TODO: more efficient?\n    HashSet<Long> uniqueValues = null;\n    if (optimizeStorage) {\n      uniqueValues = new HashSet<>();\n\n      long count = 0;\n      for (Number nv : values) {\n        // TODO: support this as MemoryDVFormat (and be smart about missing maybe)\n        final long v = nv == null ? 0 : nv.longValue();\n\n        if (gcd != 1) {\n          if (v < Long.MIN_VALUE / 2 || v > Long.MAX_VALUE / 2) {\n            // in that case v - minValue might overflow and make the GCD computation return\n            // wrong results. Since these extreme values are unlikely, we just discard\n            // GCD computation for them\n            gcd = 1;\n          } else if (count != 0) { // minValue needs to be set first\n            gcd = MathUtil.gcd(gcd, v - minValue);\n          }\n        }\n\n        minValue = Math.min(minValue, v);\n        maxValue = Math.max(maxValue, v);\n\n        if (uniqueValues != null) {\n          if (uniqueValues.add(v)) {\n            if (uniqueValues.size() > 256) {\n              uniqueValues = null;\n            }\n          }\n        }\n\n        ++count;\n      }\n      assert count == maxDoc;\n    }\n\n    if (uniqueValues != null) {\n      // small number of unique values\n      final int bitsPerValue = PackedInts.bitsRequired(uniqueValues.size()-1);\n      FormatAndBits formatAndBits = PackedInts.fastestFormatAndBits(maxDoc, bitsPerValue, acceptableOverheadRatio);\n      if (formatAndBits.bitsPerValue == 8 && minValue >= Byte.MIN_VALUE && maxValue <= Byte.MAX_VALUE) {\n        meta.writeByte(UNCOMPRESSED); // uncompressed\n        for (Number nv : values) {\n          data.writeByte(nv == null ? 0 : (byte) nv.longValue());\n        }\n      } else {\n        meta.writeByte(TABLE_COMPRESSED); // table-compressed\n        Long[] decode = uniqueValues.toArray(new Long[uniqueValues.size()]);\n        final HashMap<Long,Integer> encode = new HashMap<Long,Integer>();\n        data.writeVInt(decode.length);\n        for (int i = 0; i < decode.length; i++) {\n          data.writeLong(decode[i]);\n          encode.put(decode[i], i);\n        }\n\n        meta.writeVInt(PackedInts.VERSION_CURRENT);\n        data.writeVInt(formatAndBits.format.getId());\n        data.writeVInt(formatAndBits.bitsPerValue);\n\n        final PackedInts.Writer writer = PackedInts.getWriterNoHeader(data, formatAndBits.format, maxDoc, formatAndBits.bitsPerValue, PackedInts.DEFAULT_BUFFER_SIZE);\n        for(Number nv : values) {\n          writer.add(encode.get(nv == null ? 0 : nv.longValue()));\n        }\n        writer.finish();\n      }\n    } else if (gcd != 0 && gcd != 1) {\n      meta.writeByte(GCD_COMPRESSED);\n      meta.writeVInt(PackedInts.VERSION_CURRENT);\n      data.writeLong(minValue);\n      data.writeLong(gcd);\n      data.writeVInt(BLOCK_SIZE);\n\n      final BlockPackedWriter writer = new BlockPackedWriter(data, BLOCK_SIZE);\n      for (Number nv : values) {\n        long value = nv == null ? 0 : nv.longValue();\n        writer.add((value - minValue) / gcd);\n      }\n      writer.finish();\n    } else {\n      meta.writeByte(DELTA_COMPRESSED); // delta-compressed\n\n      meta.writeVInt(PackedInts.VERSION_CURRENT);\n      data.writeVInt(BLOCK_SIZE);\n\n      final BlockPackedWriter writer = new BlockPackedWriter(data, BLOCK_SIZE);\n      for (Number nv : values) {\n        writer.add(nv == null ? 0 : nv.longValue());\n      }\n      writer.finish();\n    }\n  }\n\n","sourceOld":"  void addNumericField(FieldInfo field, Iterable<Number> values, boolean optimizeStorage) throws IOException {\n    meta.writeVInt(field.number);\n    meta.writeByte(NUMBER);\n    meta.writeLong(data.getFilePointer());\n    long minValue = Long.MAX_VALUE;\n    long maxValue = Long.MIN_VALUE;\n    long gcd = 0;\n    // TODO: more efficient?\n    HashSet<Long> uniqueValues = null;\n    if (optimizeStorage) {\n      uniqueValues = new HashSet<>();\n\n      long count = 0;\n      for (Number nv : values) {\n        final long v = nv.longValue();\n\n        if (gcd != 1) {\n          if (v < Long.MIN_VALUE / 2 || v > Long.MAX_VALUE / 2) {\n            // in that case v - minValue might overflow and make the GCD computation return\n            // wrong results. Since these extreme values are unlikely, we just discard\n            // GCD computation for them\n            gcd = 1;\n          } else if (count != 0) { // minValue needs to be set first\n            gcd = MathUtil.gcd(gcd, v - minValue);\n          }\n        }\n\n        minValue = Math.min(minValue, v);\n        maxValue = Math.max(maxValue, v);\n\n        if (uniqueValues != null) {\n          if (uniqueValues.add(v)) {\n            if (uniqueValues.size() > 256) {\n              uniqueValues = null;\n            }\n          }\n        }\n\n        ++count;\n      }\n      assert count == maxDoc;\n    }\n\n    if (uniqueValues != null) {\n      // small number of unique values\n      final int bitsPerValue = PackedInts.bitsRequired(uniqueValues.size()-1);\n      FormatAndBits formatAndBits = PackedInts.fastestFormatAndBits(maxDoc, bitsPerValue, acceptableOverheadRatio);\n      if (formatAndBits.bitsPerValue == 8 && minValue >= Byte.MIN_VALUE && maxValue <= Byte.MAX_VALUE) {\n        meta.writeByte(UNCOMPRESSED); // uncompressed\n        for (Number nv : values) {\n          data.writeByte((byte) nv.longValue());\n        }\n      } else {\n        meta.writeByte(TABLE_COMPRESSED); // table-compressed\n        Long[] decode = uniqueValues.toArray(new Long[uniqueValues.size()]);\n        final HashMap<Long,Integer> encode = new HashMap<Long,Integer>();\n        data.writeVInt(decode.length);\n        for (int i = 0; i < decode.length; i++) {\n          data.writeLong(decode[i]);\n          encode.put(decode[i], i);\n        }\n\n        meta.writeVInt(PackedInts.VERSION_CURRENT);\n        data.writeVInt(formatAndBits.format.getId());\n        data.writeVInt(formatAndBits.bitsPerValue);\n\n        final PackedInts.Writer writer = PackedInts.getWriterNoHeader(data, formatAndBits.format, maxDoc, formatAndBits.bitsPerValue, PackedInts.DEFAULT_BUFFER_SIZE);\n        for(Number nv : values) {\n          writer.add(encode.get(nv.longValue()));\n        }\n        writer.finish();\n      }\n    } else if (gcd != 0 && gcd != 1) {\n      meta.writeByte(GCD_COMPRESSED);\n      meta.writeVInt(PackedInts.VERSION_CURRENT);\n      data.writeLong(minValue);\n      data.writeLong(gcd);\n      data.writeVInt(BLOCK_SIZE);\n\n      final BlockPackedWriter writer = new BlockPackedWriter(data, BLOCK_SIZE);\n      for (Number nv : values) {\n        writer.add((nv.longValue() - minValue) / gcd);\n      }\n      writer.finish();\n    } else {\n      meta.writeByte(DELTA_COMPRESSED); // delta-compressed\n\n      meta.writeVInt(PackedInts.VERSION_CURRENT);\n      data.writeVInt(BLOCK_SIZE);\n\n      final BlockPackedWriter writer = new BlockPackedWriter(data, BLOCK_SIZE);\n      for (Number nv : values) {\n        writer.add(nv.longValue());\n      }\n      writer.finish();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3dffec77fb8f7d0e9ca4869dddd6af94528b4576","date":1377875202,"type":0,"author":"Han Jiang","isMerge":true,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/codecs/lucene42/Lucene42DocValuesConsumer#addNumericField(FieldInfo,Iterable[Number],boolean).mjava","pathOld":"/dev/null","sourceNew":"  void addNumericField(FieldInfo field, Iterable<Number> values, boolean optimizeStorage) throws IOException {\n    meta.writeVInt(field.number);\n    meta.writeByte(NUMBER);\n    meta.writeLong(data.getFilePointer());\n    long minValue = Long.MAX_VALUE;\n    long maxValue = Long.MIN_VALUE;\n    long gcd = 0;\n    // TODO: more efficient?\n    HashSet<Long> uniqueValues = null;\n    if (optimizeStorage) {\n      uniqueValues = new HashSet<>();\n\n      long count = 0;\n      for (Number nv : values) {\n        // TODO: support this as MemoryDVFormat (and be smart about missing maybe)\n        final long v = nv == null ? 0 : nv.longValue();\n\n        if (gcd != 1) {\n          if (v < Long.MIN_VALUE / 2 || v > Long.MAX_VALUE / 2) {\n            // in that case v - minValue might overflow and make the GCD computation return\n            // wrong results. Since these extreme values are unlikely, we just discard\n            // GCD computation for them\n            gcd = 1;\n          } else if (count != 0) { // minValue needs to be set first\n            gcd = MathUtil.gcd(gcd, v - minValue);\n          }\n        }\n\n        minValue = Math.min(minValue, v);\n        maxValue = Math.max(maxValue, v);\n\n        if (uniqueValues != null) {\n          if (uniqueValues.add(v)) {\n            if (uniqueValues.size() > 256) {\n              uniqueValues = null;\n            }\n          }\n        }\n\n        ++count;\n      }\n      assert count == maxDoc;\n    }\n\n    if (uniqueValues != null) {\n      // small number of unique values\n      final int bitsPerValue = PackedInts.bitsRequired(uniqueValues.size()-1);\n      FormatAndBits formatAndBits = PackedInts.fastestFormatAndBits(maxDoc, bitsPerValue, acceptableOverheadRatio);\n      if (formatAndBits.bitsPerValue == 8 && minValue >= Byte.MIN_VALUE && maxValue <= Byte.MAX_VALUE) {\n        meta.writeByte(UNCOMPRESSED); // uncompressed\n        for (Number nv : values) {\n          data.writeByte(nv == null ? 0 : (byte) nv.longValue());\n        }\n      } else {\n        meta.writeByte(TABLE_COMPRESSED); // table-compressed\n        Long[] decode = uniqueValues.toArray(new Long[uniqueValues.size()]);\n        final HashMap<Long,Integer> encode = new HashMap<Long,Integer>();\n        data.writeVInt(decode.length);\n        for (int i = 0; i < decode.length; i++) {\n          data.writeLong(decode[i]);\n          encode.put(decode[i], i);\n        }\n\n        meta.writeVInt(PackedInts.VERSION_CURRENT);\n        data.writeVInt(formatAndBits.format.getId());\n        data.writeVInt(formatAndBits.bitsPerValue);\n\n        final PackedInts.Writer writer = PackedInts.getWriterNoHeader(data, formatAndBits.format, maxDoc, formatAndBits.bitsPerValue, PackedInts.DEFAULT_BUFFER_SIZE);\n        for(Number nv : values) {\n          writer.add(encode.get(nv == null ? 0 : nv.longValue()));\n        }\n        writer.finish();\n      }\n    } else if (gcd != 0 && gcd != 1) {\n      meta.writeByte(GCD_COMPRESSED);\n      meta.writeVInt(PackedInts.VERSION_CURRENT);\n      data.writeLong(minValue);\n      data.writeLong(gcd);\n      data.writeVInt(BLOCK_SIZE);\n\n      final BlockPackedWriter writer = new BlockPackedWriter(data, BLOCK_SIZE);\n      for (Number nv : values) {\n        long value = nv == null ? 0 : nv.longValue();\n        writer.add((value - minValue) / gcd);\n      }\n      writer.finish();\n    } else {\n      meta.writeByte(DELTA_COMPRESSED); // delta-compressed\n\n      meta.writeVInt(PackedInts.VERSION_CURRENT);\n      data.writeVInt(BLOCK_SIZE);\n\n      final BlockPackedWriter writer = new BlockPackedWriter(data, BLOCK_SIZE);\n      for (Number nv : values) {\n        writer.add(nv == null ? 0 : nv.longValue());\n      }\n      writer.finish();\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"634f330c54fd3f9f491d52036dc3f40b4f4d8934","date":1394635157,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/codecs/lucene42/Lucene42DocValuesConsumer#addNumericField(FieldInfo,Iterable[Number],boolean).mjava","pathOld":"lucene/test-framework/src/java/org/apache/lucene/codecs/lucene42/Lucene42DocValuesConsumer#addNumericField(FieldInfo,Iterable[Number],boolean).mjava","sourceNew":"  void addNumericField(FieldInfo field, Iterable<Number> values, boolean optimizeStorage) throws IOException {\n    meta.writeVInt(field.number);\n    meta.writeByte(NUMBER);\n    meta.writeLong(data.getFilePointer());\n    long minValue = Long.MAX_VALUE;\n    long maxValue = Long.MIN_VALUE;\n    long gcd = 0;\n    // TODO: more efficient?\n    HashSet<Long> uniqueValues = null;\n    if (optimizeStorage) {\n      uniqueValues = new HashSet<>();\n\n      long count = 0;\n      for (Number nv : values) {\n        // TODO: support this as MemoryDVFormat (and be smart about missing maybe)\n        final long v = nv == null ? 0 : nv.longValue();\n\n        if (gcd != 1) {\n          if (v < Long.MIN_VALUE / 2 || v > Long.MAX_VALUE / 2) {\n            // in that case v - minValue might overflow and make the GCD computation return\n            // wrong results. Since these extreme values are unlikely, we just discard\n            // GCD computation for them\n            gcd = 1;\n          } else if (count != 0) { // minValue needs to be set first\n            gcd = MathUtil.gcd(gcd, v - minValue);\n          }\n        }\n\n        minValue = Math.min(minValue, v);\n        maxValue = Math.max(maxValue, v);\n\n        if (uniqueValues != null) {\n          if (uniqueValues.add(v)) {\n            if (uniqueValues.size() > 256) {\n              uniqueValues = null;\n            }\n          }\n        }\n\n        ++count;\n      }\n      assert count == maxDoc;\n    }\n\n    if (uniqueValues != null) {\n      // small number of unique values\n      final int bitsPerValue = PackedInts.bitsRequired(uniqueValues.size()-1);\n      FormatAndBits formatAndBits = PackedInts.fastestFormatAndBits(maxDoc, bitsPerValue, acceptableOverheadRatio);\n      if (formatAndBits.bitsPerValue == 8 && minValue >= Byte.MIN_VALUE && maxValue <= Byte.MAX_VALUE) {\n        meta.writeByte(UNCOMPRESSED); // uncompressed\n        for (Number nv : values) {\n          data.writeByte(nv == null ? 0 : (byte) nv.longValue());\n        }\n      } else {\n        meta.writeByte(TABLE_COMPRESSED); // table-compressed\n        Long[] decode = uniqueValues.toArray(new Long[uniqueValues.size()]);\n        final HashMap<Long,Integer> encode = new HashMap<>();\n        data.writeVInt(decode.length);\n        for (int i = 0; i < decode.length; i++) {\n          data.writeLong(decode[i]);\n          encode.put(decode[i], i);\n        }\n\n        meta.writeVInt(PackedInts.VERSION_CURRENT);\n        data.writeVInt(formatAndBits.format.getId());\n        data.writeVInt(formatAndBits.bitsPerValue);\n\n        final PackedInts.Writer writer = PackedInts.getWriterNoHeader(data, formatAndBits.format, maxDoc, formatAndBits.bitsPerValue, PackedInts.DEFAULT_BUFFER_SIZE);\n        for(Number nv : values) {\n          writer.add(encode.get(nv == null ? 0 : nv.longValue()));\n        }\n        writer.finish();\n      }\n    } else if (gcd != 0 && gcd != 1) {\n      meta.writeByte(GCD_COMPRESSED);\n      meta.writeVInt(PackedInts.VERSION_CURRENT);\n      data.writeLong(minValue);\n      data.writeLong(gcd);\n      data.writeVInt(BLOCK_SIZE);\n\n      final BlockPackedWriter writer = new BlockPackedWriter(data, BLOCK_SIZE);\n      for (Number nv : values) {\n        long value = nv == null ? 0 : nv.longValue();\n        writer.add((value - minValue) / gcd);\n      }\n      writer.finish();\n    } else {\n      meta.writeByte(DELTA_COMPRESSED); // delta-compressed\n\n      meta.writeVInt(PackedInts.VERSION_CURRENT);\n      data.writeVInt(BLOCK_SIZE);\n\n      final BlockPackedWriter writer = new BlockPackedWriter(data, BLOCK_SIZE);\n      for (Number nv : values) {\n        writer.add(nv == null ? 0 : nv.longValue());\n      }\n      writer.finish();\n    }\n  }\n\n","sourceOld":"  void addNumericField(FieldInfo field, Iterable<Number> values, boolean optimizeStorage) throws IOException {\n    meta.writeVInt(field.number);\n    meta.writeByte(NUMBER);\n    meta.writeLong(data.getFilePointer());\n    long minValue = Long.MAX_VALUE;\n    long maxValue = Long.MIN_VALUE;\n    long gcd = 0;\n    // TODO: more efficient?\n    HashSet<Long> uniqueValues = null;\n    if (optimizeStorage) {\n      uniqueValues = new HashSet<>();\n\n      long count = 0;\n      for (Number nv : values) {\n        // TODO: support this as MemoryDVFormat (and be smart about missing maybe)\n        final long v = nv == null ? 0 : nv.longValue();\n\n        if (gcd != 1) {\n          if (v < Long.MIN_VALUE / 2 || v > Long.MAX_VALUE / 2) {\n            // in that case v - minValue might overflow and make the GCD computation return\n            // wrong results. Since these extreme values are unlikely, we just discard\n            // GCD computation for them\n            gcd = 1;\n          } else if (count != 0) { // minValue needs to be set first\n            gcd = MathUtil.gcd(gcd, v - minValue);\n          }\n        }\n\n        minValue = Math.min(minValue, v);\n        maxValue = Math.max(maxValue, v);\n\n        if (uniqueValues != null) {\n          if (uniqueValues.add(v)) {\n            if (uniqueValues.size() > 256) {\n              uniqueValues = null;\n            }\n          }\n        }\n\n        ++count;\n      }\n      assert count == maxDoc;\n    }\n\n    if (uniqueValues != null) {\n      // small number of unique values\n      final int bitsPerValue = PackedInts.bitsRequired(uniqueValues.size()-1);\n      FormatAndBits formatAndBits = PackedInts.fastestFormatAndBits(maxDoc, bitsPerValue, acceptableOverheadRatio);\n      if (formatAndBits.bitsPerValue == 8 && minValue >= Byte.MIN_VALUE && maxValue <= Byte.MAX_VALUE) {\n        meta.writeByte(UNCOMPRESSED); // uncompressed\n        for (Number nv : values) {\n          data.writeByte(nv == null ? 0 : (byte) nv.longValue());\n        }\n      } else {\n        meta.writeByte(TABLE_COMPRESSED); // table-compressed\n        Long[] decode = uniqueValues.toArray(new Long[uniqueValues.size()]);\n        final HashMap<Long,Integer> encode = new HashMap<Long,Integer>();\n        data.writeVInt(decode.length);\n        for (int i = 0; i < decode.length; i++) {\n          data.writeLong(decode[i]);\n          encode.put(decode[i], i);\n        }\n\n        meta.writeVInt(PackedInts.VERSION_CURRENT);\n        data.writeVInt(formatAndBits.format.getId());\n        data.writeVInt(formatAndBits.bitsPerValue);\n\n        final PackedInts.Writer writer = PackedInts.getWriterNoHeader(data, formatAndBits.format, maxDoc, formatAndBits.bitsPerValue, PackedInts.DEFAULT_BUFFER_SIZE);\n        for(Number nv : values) {\n          writer.add(encode.get(nv == null ? 0 : nv.longValue()));\n        }\n        writer.finish();\n      }\n    } else if (gcd != 0 && gcd != 1) {\n      meta.writeByte(GCD_COMPRESSED);\n      meta.writeVInt(PackedInts.VERSION_CURRENT);\n      data.writeLong(minValue);\n      data.writeLong(gcd);\n      data.writeVInt(BLOCK_SIZE);\n\n      final BlockPackedWriter writer = new BlockPackedWriter(data, BLOCK_SIZE);\n      for (Number nv : values) {\n        long value = nv == null ? 0 : nv.longValue();\n        writer.add((value - minValue) / gcd);\n      }\n      writer.finish();\n    } else {\n      meta.writeByte(DELTA_COMPRESSED); // delta-compressed\n\n      meta.writeVInt(PackedInts.VERSION_CURRENT);\n      data.writeVInt(BLOCK_SIZE);\n\n      final BlockPackedWriter writer = new BlockPackedWriter(data, BLOCK_SIZE);\n      for (Number nv : values) {\n        writer.add(nv == null ? 0 : nv.longValue());\n      }\n      writer.finish();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d36ccb9a1c11aeb91962e89bda4a2e643c8629b3","date":1401710950,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/codecs/lucene42/Lucene42DocValuesConsumer#addNumericField(FieldInfo,Iterable[Number],boolean).mjava","pathOld":"lucene/test-framework/src/java/org/apache/lucene/codecs/lucene42/Lucene42DocValuesConsumer#addNumericField(FieldInfo,Iterable[Number],boolean).mjava","sourceNew":"  void addNumericField(FieldInfo field, Iterable<Number> values, boolean optimizeStorage) throws IOException {\n    meta.writeVInt(field.number);\n    meta.writeByte(NUMBER);\n    meta.writeLong(data.getFilePointer());\n    long minValue = Long.MAX_VALUE;\n    long maxValue = Long.MIN_VALUE;\n    long gcd = 0;\n    // TODO: more efficient?\n    HashSet<Long> uniqueValues = null;\n    if (optimizeStorage) {\n      uniqueValues = new HashSet<>();\n\n      long count = 0;\n      for (Number nv : values) {\n        // TODO: support this as MemoryDVFormat (and be smart about missing maybe)\n        final long v = nv == null ? 0 : nv.longValue();\n\n        if (gcd != 1) {\n          if (v < Long.MIN_VALUE / 2 || v > Long.MAX_VALUE / 2) {\n            // in that case v - minValue might overflow and make the GCD computation return\n            // wrong results. Since these extreme values are unlikely, we just discard\n            // GCD computation for them\n            gcd = 1;\n          } else if (count != 0) { // minValue needs to be set first\n            gcd = MathUtil.gcd(gcd, v - minValue);\n          }\n        }\n\n        minValue = Math.min(minValue, v);\n        maxValue = Math.max(maxValue, v);\n\n        if (uniqueValues != null) {\n          if (uniqueValues.add(v)) {\n            if (uniqueValues.size() > 256) {\n              uniqueValues = null;\n            }\n          }\n        }\n\n        ++count;\n      }\n      assert count == maxDoc;\n    }\n\n    if (uniqueValues != null) {\n      // small number of unique values\n      final int bitsPerValue = PackedInts.bitsRequired(uniqueValues.size()-1);\n      FormatAndBits formatAndBits = PackedInts.fastestFormatAndBits(maxDoc, bitsPerValue, acceptableOverheadRatio);\n      if (formatAndBits.bitsPerValue == 8 && minValue >= Byte.MIN_VALUE && maxValue <= Byte.MAX_VALUE) {\n        meta.writeByte(UNCOMPRESSED); // uncompressed\n        for (Number nv : values) {\n          data.writeByte(nv == null ? 0 : (byte) nv.longValue());\n        }\n      } else {\n        meta.writeByte(TABLE_COMPRESSED); // table-compressed\n        Long[] decode = uniqueValues.toArray(new Long[uniqueValues.size()]);\n        final HashMap<Long,Integer> encode = new HashMap<>();\n        data.writeVInt(decode.length);\n        for (int i = 0; i < decode.length; i++) {\n          data.writeLong(decode[i]);\n          encode.put(decode[i], i);\n        }\n\n        meta.writeVInt(PackedInts.VERSION_CURRENT);\n        data.writeVInt(formatAndBits.format.getId());\n        data.writeVInt(formatAndBits.bitsPerValue);\n\n        final PackedInts.Writer writer = PackedInts.getWriterNoHeader(data, formatAndBits.format, maxDoc, formatAndBits.bitsPerValue, PackedInts.DEFAULT_BUFFER_SIZE);\n        for(Number nv : values) {\n          writer.add(encode.get(nv == null ? 0 : nv.longValue()));\n        }\n        writer.finish();\n      }\n    } else if (gcd != 0 && gcd != 1) {\n      meta.writeByte(GCD_COMPRESSED);\n      meta.writeVInt(PackedInts.VERSION_CURRENT);\n      data.writeLong(minValue);\n      data.writeLong(gcd);\n      data.writeVInt(BLOCK_SIZE);\n\n      final BlockPackedWriter writer = new BlockPackedWriter(data, BLOCK_SIZE, PackedInts.COMPACT);\n      for (Number nv : values) {\n        long value = nv == null ? 0 : nv.longValue();\n        writer.add((value - minValue) / gcd);\n      }\n      writer.finish();\n    } else {\n      meta.writeByte(DELTA_COMPRESSED); // delta-compressed\n\n      meta.writeVInt(PackedInts.VERSION_CURRENT);\n      data.writeVInt(BLOCK_SIZE);\n\n      final BlockPackedWriter writer = new BlockPackedWriter(data, BLOCK_SIZE, PackedInts.COMPACT);\n      for (Number nv : values) {\n        writer.add(nv == null ? 0 : nv.longValue());\n      }\n      writer.finish();\n    }\n  }\n\n","sourceOld":"  void addNumericField(FieldInfo field, Iterable<Number> values, boolean optimizeStorage) throws IOException {\n    meta.writeVInt(field.number);\n    meta.writeByte(NUMBER);\n    meta.writeLong(data.getFilePointer());\n    long minValue = Long.MAX_VALUE;\n    long maxValue = Long.MIN_VALUE;\n    long gcd = 0;\n    // TODO: more efficient?\n    HashSet<Long> uniqueValues = null;\n    if (optimizeStorage) {\n      uniqueValues = new HashSet<>();\n\n      long count = 0;\n      for (Number nv : values) {\n        // TODO: support this as MemoryDVFormat (and be smart about missing maybe)\n        final long v = nv == null ? 0 : nv.longValue();\n\n        if (gcd != 1) {\n          if (v < Long.MIN_VALUE / 2 || v > Long.MAX_VALUE / 2) {\n            // in that case v - minValue might overflow and make the GCD computation return\n            // wrong results. Since these extreme values are unlikely, we just discard\n            // GCD computation for them\n            gcd = 1;\n          } else if (count != 0) { // minValue needs to be set first\n            gcd = MathUtil.gcd(gcd, v - minValue);\n          }\n        }\n\n        minValue = Math.min(minValue, v);\n        maxValue = Math.max(maxValue, v);\n\n        if (uniqueValues != null) {\n          if (uniqueValues.add(v)) {\n            if (uniqueValues.size() > 256) {\n              uniqueValues = null;\n            }\n          }\n        }\n\n        ++count;\n      }\n      assert count == maxDoc;\n    }\n\n    if (uniqueValues != null) {\n      // small number of unique values\n      final int bitsPerValue = PackedInts.bitsRequired(uniqueValues.size()-1);\n      FormatAndBits formatAndBits = PackedInts.fastestFormatAndBits(maxDoc, bitsPerValue, acceptableOverheadRatio);\n      if (formatAndBits.bitsPerValue == 8 && minValue >= Byte.MIN_VALUE && maxValue <= Byte.MAX_VALUE) {\n        meta.writeByte(UNCOMPRESSED); // uncompressed\n        for (Number nv : values) {\n          data.writeByte(nv == null ? 0 : (byte) nv.longValue());\n        }\n      } else {\n        meta.writeByte(TABLE_COMPRESSED); // table-compressed\n        Long[] decode = uniqueValues.toArray(new Long[uniqueValues.size()]);\n        final HashMap<Long,Integer> encode = new HashMap<>();\n        data.writeVInt(decode.length);\n        for (int i = 0; i < decode.length; i++) {\n          data.writeLong(decode[i]);\n          encode.put(decode[i], i);\n        }\n\n        meta.writeVInt(PackedInts.VERSION_CURRENT);\n        data.writeVInt(formatAndBits.format.getId());\n        data.writeVInt(formatAndBits.bitsPerValue);\n\n        final PackedInts.Writer writer = PackedInts.getWriterNoHeader(data, formatAndBits.format, maxDoc, formatAndBits.bitsPerValue, PackedInts.DEFAULT_BUFFER_SIZE);\n        for(Number nv : values) {\n          writer.add(encode.get(nv == null ? 0 : nv.longValue()));\n        }\n        writer.finish();\n      }\n    } else if (gcd != 0 && gcd != 1) {\n      meta.writeByte(GCD_COMPRESSED);\n      meta.writeVInt(PackedInts.VERSION_CURRENT);\n      data.writeLong(minValue);\n      data.writeLong(gcd);\n      data.writeVInt(BLOCK_SIZE);\n\n      final BlockPackedWriter writer = new BlockPackedWriter(data, BLOCK_SIZE);\n      for (Number nv : values) {\n        long value = nv == null ? 0 : nv.longValue();\n        writer.add((value - minValue) / gcd);\n      }\n      writer.finish();\n    } else {\n      meta.writeByte(DELTA_COMPRESSED); // delta-compressed\n\n      meta.writeVInt(PackedInts.VERSION_CURRENT);\n      data.writeVInt(BLOCK_SIZE);\n\n      final BlockPackedWriter writer = new BlockPackedWriter(data, BLOCK_SIZE);\n      for (Number nv : values) {\n        writer.add(nv == null ? 0 : nv.longValue());\n      }\n      writer.finish();\n    }\n  }\n\n","bugFix":null,"bugIntro":["8106bc60c7452250f84c65cdb43ab6b1d8eb1534"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"8106bc60c7452250f84c65cdb43ab6b1d8eb1534","date":1401906364,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/codecs/lucene42/Lucene42DocValuesConsumer#addNumericField(FieldInfo,Iterable[Number],boolean).mjava","pathOld":"lucene/test-framework/src/java/org/apache/lucene/codecs/lucene42/Lucene42DocValuesConsumer#addNumericField(FieldInfo,Iterable[Number],boolean).mjava","sourceNew":"  void addNumericField(FieldInfo field, Iterable<Number> values, boolean optimizeStorage) throws IOException {\n    meta.writeVInt(field.number);\n    meta.writeByte(NUMBER);\n    meta.writeLong(data.getFilePointer());\n    long minValue = Long.MAX_VALUE;\n    long maxValue = Long.MIN_VALUE;\n    long gcd = 0;\n    // TODO: more efficient?\n    HashSet<Long> uniqueValues = null;\n    if (optimizeStorage) {\n      uniqueValues = new HashSet<>();\n\n      long count = 0;\n      for (Number nv : values) {\n        // TODO: support this as MemoryDVFormat (and be smart about missing maybe)\n        final long v = nv == null ? 0 : nv.longValue();\n\n        if (gcd != 1) {\n          if (v < Long.MIN_VALUE / 2 || v > Long.MAX_VALUE / 2) {\n            // in that case v - minValue might overflow and make the GCD computation return\n            // wrong results. Since these extreme values are unlikely, we just discard\n            // GCD computation for them\n            gcd = 1;\n          } else if (count != 0) { // minValue needs to be set first\n            gcd = MathUtil.gcd(gcd, v - minValue);\n          }\n        }\n\n        minValue = Math.min(minValue, v);\n        maxValue = Math.max(maxValue, v);\n\n        if (uniqueValues != null) {\n          if (uniqueValues.add(v)) {\n            if (uniqueValues.size() > 256) {\n              uniqueValues = null;\n            }\n          }\n        }\n\n        ++count;\n      }\n      assert count == maxDoc;\n    }\n\n    if (uniqueValues != null) {\n      // small number of unique values\n      final int bitsPerValue = PackedInts.bitsRequired(uniqueValues.size()-1);\n      FormatAndBits formatAndBits = PackedInts.fastestFormatAndBits(maxDoc, bitsPerValue, acceptableOverheadRatio);\n      if (formatAndBits.bitsPerValue == 8 && minValue >= Byte.MIN_VALUE && maxValue <= Byte.MAX_VALUE) {\n        meta.writeByte(UNCOMPRESSED); // uncompressed\n        for (Number nv : values) {\n          data.writeByte(nv == null ? 0 : (byte) nv.longValue());\n        }\n      } else {\n        meta.writeByte(TABLE_COMPRESSED); // table-compressed\n        Long[] decode = uniqueValues.toArray(new Long[uniqueValues.size()]);\n        final HashMap<Long,Integer> encode = new HashMap<>();\n        data.writeVInt(decode.length);\n        for (int i = 0; i < decode.length; i++) {\n          data.writeLong(decode[i]);\n          encode.put(decode[i], i);\n        }\n\n        meta.writeVInt(PackedInts.VERSION_CURRENT);\n        data.writeVInt(formatAndBits.format.getId());\n        data.writeVInt(formatAndBits.bitsPerValue);\n\n        final PackedInts.Writer writer = PackedInts.getWriterNoHeader(data, formatAndBits.format, maxDoc, formatAndBits.bitsPerValue, PackedInts.DEFAULT_BUFFER_SIZE);\n        for(Number nv : values) {\n          writer.add(encode.get(nv == null ? 0 : nv.longValue()));\n        }\n        writer.finish();\n      }\n    } else if (gcd != 0 && gcd != 1) {\n      meta.writeByte(GCD_COMPRESSED);\n      meta.writeVInt(PackedInts.VERSION_CURRENT);\n      data.writeLong(minValue);\n      data.writeLong(gcd);\n      data.writeVInt(BLOCK_SIZE);\n\n      final BlockPackedWriter writer = new BlockPackedWriter(data, BLOCK_SIZE);\n      for (Number nv : values) {\n        long value = nv == null ? 0 : nv.longValue();\n        writer.add((value - minValue) / gcd);\n      }\n      writer.finish();\n    } else {\n      meta.writeByte(DELTA_COMPRESSED); // delta-compressed\n\n      meta.writeVInt(PackedInts.VERSION_CURRENT);\n      data.writeVInt(BLOCK_SIZE);\n\n      final BlockPackedWriter writer = new BlockPackedWriter(data, BLOCK_SIZE);\n      for (Number nv : values) {\n        writer.add(nv == null ? 0 : nv.longValue());\n      }\n      writer.finish();\n    }\n  }\n\n","sourceOld":"  void addNumericField(FieldInfo field, Iterable<Number> values, boolean optimizeStorage) throws IOException {\n    meta.writeVInt(field.number);\n    meta.writeByte(NUMBER);\n    meta.writeLong(data.getFilePointer());\n    long minValue = Long.MAX_VALUE;\n    long maxValue = Long.MIN_VALUE;\n    long gcd = 0;\n    // TODO: more efficient?\n    HashSet<Long> uniqueValues = null;\n    if (optimizeStorage) {\n      uniqueValues = new HashSet<>();\n\n      long count = 0;\n      for (Number nv : values) {\n        // TODO: support this as MemoryDVFormat (and be smart about missing maybe)\n        final long v = nv == null ? 0 : nv.longValue();\n\n        if (gcd != 1) {\n          if (v < Long.MIN_VALUE / 2 || v > Long.MAX_VALUE / 2) {\n            // in that case v - minValue might overflow and make the GCD computation return\n            // wrong results. Since these extreme values are unlikely, we just discard\n            // GCD computation for them\n            gcd = 1;\n          } else if (count != 0) { // minValue needs to be set first\n            gcd = MathUtil.gcd(gcd, v - minValue);\n          }\n        }\n\n        minValue = Math.min(minValue, v);\n        maxValue = Math.max(maxValue, v);\n\n        if (uniqueValues != null) {\n          if (uniqueValues.add(v)) {\n            if (uniqueValues.size() > 256) {\n              uniqueValues = null;\n            }\n          }\n        }\n\n        ++count;\n      }\n      assert count == maxDoc;\n    }\n\n    if (uniqueValues != null) {\n      // small number of unique values\n      final int bitsPerValue = PackedInts.bitsRequired(uniqueValues.size()-1);\n      FormatAndBits formatAndBits = PackedInts.fastestFormatAndBits(maxDoc, bitsPerValue, acceptableOverheadRatio);\n      if (formatAndBits.bitsPerValue == 8 && minValue >= Byte.MIN_VALUE && maxValue <= Byte.MAX_VALUE) {\n        meta.writeByte(UNCOMPRESSED); // uncompressed\n        for (Number nv : values) {\n          data.writeByte(nv == null ? 0 : (byte) nv.longValue());\n        }\n      } else {\n        meta.writeByte(TABLE_COMPRESSED); // table-compressed\n        Long[] decode = uniqueValues.toArray(new Long[uniqueValues.size()]);\n        final HashMap<Long,Integer> encode = new HashMap<>();\n        data.writeVInt(decode.length);\n        for (int i = 0; i < decode.length; i++) {\n          data.writeLong(decode[i]);\n          encode.put(decode[i], i);\n        }\n\n        meta.writeVInt(PackedInts.VERSION_CURRENT);\n        data.writeVInt(formatAndBits.format.getId());\n        data.writeVInt(formatAndBits.bitsPerValue);\n\n        final PackedInts.Writer writer = PackedInts.getWriterNoHeader(data, formatAndBits.format, maxDoc, formatAndBits.bitsPerValue, PackedInts.DEFAULT_BUFFER_SIZE);\n        for(Number nv : values) {\n          writer.add(encode.get(nv == null ? 0 : nv.longValue()));\n        }\n        writer.finish();\n      }\n    } else if (gcd != 0 && gcd != 1) {\n      meta.writeByte(GCD_COMPRESSED);\n      meta.writeVInt(PackedInts.VERSION_CURRENT);\n      data.writeLong(minValue);\n      data.writeLong(gcd);\n      data.writeVInt(BLOCK_SIZE);\n\n      final BlockPackedWriter writer = new BlockPackedWriter(data, BLOCK_SIZE, PackedInts.COMPACT);\n      for (Number nv : values) {\n        long value = nv == null ? 0 : nv.longValue();\n        writer.add((value - minValue) / gcd);\n      }\n      writer.finish();\n    } else {\n      meta.writeByte(DELTA_COMPRESSED); // delta-compressed\n\n      meta.writeVInt(PackedInts.VERSION_CURRENT);\n      data.writeVInt(BLOCK_SIZE);\n\n      final BlockPackedWriter writer = new BlockPackedWriter(data, BLOCK_SIZE, PackedInts.COMPACT);\n      for (Number nv : values) {\n        writer.add(nv == null ? 0 : nv.longValue());\n      }\n      writer.finish();\n    }\n  }\n\n","bugFix":["d36ccb9a1c11aeb91962e89bda4a2e643c8629b3"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4cc45c615dbb82bf79d5f9550286098367874fbf","date":1409571423,"type":5,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/backward-codecs/src/test/org/apache/lucene/codecs/lucene42/Lucene42DocValuesConsumer#addNumericField(FieldInfo,Iterable[Number],boolean).mjava","pathOld":"lucene/test-framework/src/java/org/apache/lucene/codecs/lucene42/Lucene42DocValuesConsumer#addNumericField(FieldInfo,Iterable[Number],boolean).mjava","sourceNew":"  void addNumericField(FieldInfo field, Iterable<Number> values, boolean optimizeStorage) throws IOException {\n    meta.writeVInt(field.number);\n    meta.writeByte(NUMBER);\n    meta.writeLong(data.getFilePointer());\n    long minValue = Long.MAX_VALUE;\n    long maxValue = Long.MIN_VALUE;\n    long gcd = 0;\n    // TODO: more efficient?\n    HashSet<Long> uniqueValues = null;\n    if (optimizeStorage) {\n      uniqueValues = new HashSet<>();\n\n      long count = 0;\n      for (Number nv : values) {\n        // TODO: support this as MemoryDVFormat (and be smart about missing maybe)\n        final long v = nv == null ? 0 : nv.longValue();\n\n        if (gcd != 1) {\n          if (v < Long.MIN_VALUE / 2 || v > Long.MAX_VALUE / 2) {\n            // in that case v - minValue might overflow and make the GCD computation return\n            // wrong results. Since these extreme values are unlikely, we just discard\n            // GCD computation for them\n            gcd = 1;\n          } else if (count != 0) { // minValue needs to be set first\n            gcd = MathUtil.gcd(gcd, v - minValue);\n          }\n        }\n\n        minValue = Math.min(minValue, v);\n        maxValue = Math.max(maxValue, v);\n\n        if (uniqueValues != null) {\n          if (uniqueValues.add(v)) {\n            if (uniqueValues.size() > 256) {\n              uniqueValues = null;\n            }\n          }\n        }\n\n        ++count;\n      }\n      assert count == maxDoc;\n    }\n\n    if (uniqueValues != null) {\n      // small number of unique values\n      final int bitsPerValue = PackedInts.bitsRequired(uniqueValues.size()-1);\n      FormatAndBits formatAndBits = PackedInts.fastestFormatAndBits(maxDoc, bitsPerValue, acceptableOverheadRatio);\n      if (formatAndBits.bitsPerValue == 8 && minValue >= Byte.MIN_VALUE && maxValue <= Byte.MAX_VALUE) {\n        meta.writeByte(UNCOMPRESSED); // uncompressed\n        for (Number nv : values) {\n          data.writeByte(nv == null ? 0 : (byte) nv.longValue());\n        }\n      } else {\n        meta.writeByte(TABLE_COMPRESSED); // table-compressed\n        Long[] decode = uniqueValues.toArray(new Long[uniqueValues.size()]);\n        final HashMap<Long,Integer> encode = new HashMap<>();\n        data.writeVInt(decode.length);\n        for (int i = 0; i < decode.length; i++) {\n          data.writeLong(decode[i]);\n          encode.put(decode[i], i);\n        }\n\n        meta.writeVInt(PackedInts.VERSION_CURRENT);\n        data.writeVInt(formatAndBits.format.getId());\n        data.writeVInt(formatAndBits.bitsPerValue);\n\n        final PackedInts.Writer writer = PackedInts.getWriterNoHeader(data, formatAndBits.format, maxDoc, formatAndBits.bitsPerValue, PackedInts.DEFAULT_BUFFER_SIZE);\n        for(Number nv : values) {\n          writer.add(encode.get(nv == null ? 0 : nv.longValue()));\n        }\n        writer.finish();\n      }\n    } else if (gcd != 0 && gcd != 1) {\n      meta.writeByte(GCD_COMPRESSED);\n      meta.writeVInt(PackedInts.VERSION_CURRENT);\n      data.writeLong(minValue);\n      data.writeLong(gcd);\n      data.writeVInt(BLOCK_SIZE);\n\n      final BlockPackedWriter writer = new BlockPackedWriter(data, BLOCK_SIZE);\n      for (Number nv : values) {\n        long value = nv == null ? 0 : nv.longValue();\n        writer.add((value - minValue) / gcd);\n      }\n      writer.finish();\n    } else {\n      meta.writeByte(DELTA_COMPRESSED); // delta-compressed\n\n      meta.writeVInt(PackedInts.VERSION_CURRENT);\n      data.writeVInt(BLOCK_SIZE);\n\n      final BlockPackedWriter writer = new BlockPackedWriter(data, BLOCK_SIZE);\n      for (Number nv : values) {\n        writer.add(nv == null ? 0 : nv.longValue());\n      }\n      writer.finish();\n    }\n  }\n\n","sourceOld":"  void addNumericField(FieldInfo field, Iterable<Number> values, boolean optimizeStorage) throws IOException {\n    meta.writeVInt(field.number);\n    meta.writeByte(NUMBER);\n    meta.writeLong(data.getFilePointer());\n    long minValue = Long.MAX_VALUE;\n    long maxValue = Long.MIN_VALUE;\n    long gcd = 0;\n    // TODO: more efficient?\n    HashSet<Long> uniqueValues = null;\n    if (optimizeStorage) {\n      uniqueValues = new HashSet<>();\n\n      long count = 0;\n      for (Number nv : values) {\n        // TODO: support this as MemoryDVFormat (and be smart about missing maybe)\n        final long v = nv == null ? 0 : nv.longValue();\n\n        if (gcd != 1) {\n          if (v < Long.MIN_VALUE / 2 || v > Long.MAX_VALUE / 2) {\n            // in that case v - minValue might overflow and make the GCD computation return\n            // wrong results. Since these extreme values are unlikely, we just discard\n            // GCD computation for them\n            gcd = 1;\n          } else if (count != 0) { // minValue needs to be set first\n            gcd = MathUtil.gcd(gcd, v - minValue);\n          }\n        }\n\n        minValue = Math.min(minValue, v);\n        maxValue = Math.max(maxValue, v);\n\n        if (uniqueValues != null) {\n          if (uniqueValues.add(v)) {\n            if (uniqueValues.size() > 256) {\n              uniqueValues = null;\n            }\n          }\n        }\n\n        ++count;\n      }\n      assert count == maxDoc;\n    }\n\n    if (uniqueValues != null) {\n      // small number of unique values\n      final int bitsPerValue = PackedInts.bitsRequired(uniqueValues.size()-1);\n      FormatAndBits formatAndBits = PackedInts.fastestFormatAndBits(maxDoc, bitsPerValue, acceptableOverheadRatio);\n      if (formatAndBits.bitsPerValue == 8 && minValue >= Byte.MIN_VALUE && maxValue <= Byte.MAX_VALUE) {\n        meta.writeByte(UNCOMPRESSED); // uncompressed\n        for (Number nv : values) {\n          data.writeByte(nv == null ? 0 : (byte) nv.longValue());\n        }\n      } else {\n        meta.writeByte(TABLE_COMPRESSED); // table-compressed\n        Long[] decode = uniqueValues.toArray(new Long[uniqueValues.size()]);\n        final HashMap<Long,Integer> encode = new HashMap<>();\n        data.writeVInt(decode.length);\n        for (int i = 0; i < decode.length; i++) {\n          data.writeLong(decode[i]);\n          encode.put(decode[i], i);\n        }\n\n        meta.writeVInt(PackedInts.VERSION_CURRENT);\n        data.writeVInt(formatAndBits.format.getId());\n        data.writeVInt(formatAndBits.bitsPerValue);\n\n        final PackedInts.Writer writer = PackedInts.getWriterNoHeader(data, formatAndBits.format, maxDoc, formatAndBits.bitsPerValue, PackedInts.DEFAULT_BUFFER_SIZE);\n        for(Number nv : values) {\n          writer.add(encode.get(nv == null ? 0 : nv.longValue()));\n        }\n        writer.finish();\n      }\n    } else if (gcd != 0 && gcd != 1) {\n      meta.writeByte(GCD_COMPRESSED);\n      meta.writeVInt(PackedInts.VERSION_CURRENT);\n      data.writeLong(minValue);\n      data.writeLong(gcd);\n      data.writeVInt(BLOCK_SIZE);\n\n      final BlockPackedWriter writer = new BlockPackedWriter(data, BLOCK_SIZE);\n      for (Number nv : values) {\n        long value = nv == null ? 0 : nv.longValue();\n        writer.add((value - minValue) / gcd);\n      }\n      writer.finish();\n    } else {\n      meta.writeByte(DELTA_COMPRESSED); // delta-compressed\n\n      meta.writeVInt(PackedInts.VERSION_CURRENT);\n      data.writeVInt(BLOCK_SIZE);\n\n      final BlockPackedWriter writer = new BlockPackedWriter(data, BLOCK_SIZE);\n      for (Number nv : values) {\n        writer.add(nv == null ? 0 : nv.longValue());\n      }\n      writer.finish();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"402ad3ddc9da7b70da1b167667a60ece6a1381fb","date":1409656478,"type":5,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/backward-codecs/src/test/org/apache/lucene/codecs/lucene42/Lucene42DocValuesConsumer#addNumericField(FieldInfo,Iterable[Number],boolean).mjava","pathOld":"lucene/test-framework/src/java/org/apache/lucene/codecs/lucene42/Lucene42DocValuesConsumer#addNumericField(FieldInfo,Iterable[Number],boolean).mjava","sourceNew":"  void addNumericField(FieldInfo field, Iterable<Number> values, boolean optimizeStorage) throws IOException {\n    meta.writeVInt(field.number);\n    meta.writeByte(NUMBER);\n    meta.writeLong(data.getFilePointer());\n    long minValue = Long.MAX_VALUE;\n    long maxValue = Long.MIN_VALUE;\n    long gcd = 0;\n    // TODO: more efficient?\n    HashSet<Long> uniqueValues = null;\n    if (optimizeStorage) {\n      uniqueValues = new HashSet<>();\n\n      long count = 0;\n      for (Number nv : values) {\n        // TODO: support this as MemoryDVFormat (and be smart about missing maybe)\n        final long v = nv == null ? 0 : nv.longValue();\n\n        if (gcd != 1) {\n          if (v < Long.MIN_VALUE / 2 || v > Long.MAX_VALUE / 2) {\n            // in that case v - minValue might overflow and make the GCD computation return\n            // wrong results. Since these extreme values are unlikely, we just discard\n            // GCD computation for them\n            gcd = 1;\n          } else if (count != 0) { // minValue needs to be set first\n            gcd = MathUtil.gcd(gcd, v - minValue);\n          }\n        }\n\n        minValue = Math.min(minValue, v);\n        maxValue = Math.max(maxValue, v);\n\n        if (uniqueValues != null) {\n          if (uniqueValues.add(v)) {\n            if (uniqueValues.size() > 256) {\n              uniqueValues = null;\n            }\n          }\n        }\n\n        ++count;\n      }\n      assert count == maxDoc;\n    }\n\n    if (uniqueValues != null) {\n      // small number of unique values\n      final int bitsPerValue = PackedInts.bitsRequired(uniqueValues.size()-1);\n      FormatAndBits formatAndBits = PackedInts.fastestFormatAndBits(maxDoc, bitsPerValue, acceptableOverheadRatio);\n      if (formatAndBits.bitsPerValue == 8 && minValue >= Byte.MIN_VALUE && maxValue <= Byte.MAX_VALUE) {\n        meta.writeByte(UNCOMPRESSED); // uncompressed\n        for (Number nv : values) {\n          data.writeByte(nv == null ? 0 : (byte) nv.longValue());\n        }\n      } else {\n        meta.writeByte(TABLE_COMPRESSED); // table-compressed\n        Long[] decode = uniqueValues.toArray(new Long[uniqueValues.size()]);\n        final HashMap<Long,Integer> encode = new HashMap<>();\n        data.writeVInt(decode.length);\n        for (int i = 0; i < decode.length; i++) {\n          data.writeLong(decode[i]);\n          encode.put(decode[i], i);\n        }\n\n        meta.writeVInt(PackedInts.VERSION_CURRENT);\n        data.writeVInt(formatAndBits.format.getId());\n        data.writeVInt(formatAndBits.bitsPerValue);\n\n        final PackedInts.Writer writer = PackedInts.getWriterNoHeader(data, formatAndBits.format, maxDoc, formatAndBits.bitsPerValue, PackedInts.DEFAULT_BUFFER_SIZE);\n        for(Number nv : values) {\n          writer.add(encode.get(nv == null ? 0 : nv.longValue()));\n        }\n        writer.finish();\n      }\n    } else if (gcd != 0 && gcd != 1) {\n      meta.writeByte(GCD_COMPRESSED);\n      meta.writeVInt(PackedInts.VERSION_CURRENT);\n      data.writeLong(minValue);\n      data.writeLong(gcd);\n      data.writeVInt(BLOCK_SIZE);\n\n      final BlockPackedWriter writer = new BlockPackedWriter(data, BLOCK_SIZE);\n      for (Number nv : values) {\n        long value = nv == null ? 0 : nv.longValue();\n        writer.add((value - minValue) / gcd);\n      }\n      writer.finish();\n    } else {\n      meta.writeByte(DELTA_COMPRESSED); // delta-compressed\n\n      meta.writeVInt(PackedInts.VERSION_CURRENT);\n      data.writeVInt(BLOCK_SIZE);\n\n      final BlockPackedWriter writer = new BlockPackedWriter(data, BLOCK_SIZE);\n      for (Number nv : values) {\n        writer.add(nv == null ? 0 : nv.longValue());\n      }\n      writer.finish();\n    }\n  }\n\n","sourceOld":"  void addNumericField(FieldInfo field, Iterable<Number> values, boolean optimizeStorage) throws IOException {\n    meta.writeVInt(field.number);\n    meta.writeByte(NUMBER);\n    meta.writeLong(data.getFilePointer());\n    long minValue = Long.MAX_VALUE;\n    long maxValue = Long.MIN_VALUE;\n    long gcd = 0;\n    // TODO: more efficient?\n    HashSet<Long> uniqueValues = null;\n    if (optimizeStorage) {\n      uniqueValues = new HashSet<>();\n\n      long count = 0;\n      for (Number nv : values) {\n        // TODO: support this as MemoryDVFormat (and be smart about missing maybe)\n        final long v = nv == null ? 0 : nv.longValue();\n\n        if (gcd != 1) {\n          if (v < Long.MIN_VALUE / 2 || v > Long.MAX_VALUE / 2) {\n            // in that case v - minValue might overflow and make the GCD computation return\n            // wrong results. Since these extreme values are unlikely, we just discard\n            // GCD computation for them\n            gcd = 1;\n          } else if (count != 0) { // minValue needs to be set first\n            gcd = MathUtil.gcd(gcd, v - minValue);\n          }\n        }\n\n        minValue = Math.min(minValue, v);\n        maxValue = Math.max(maxValue, v);\n\n        if (uniqueValues != null) {\n          if (uniqueValues.add(v)) {\n            if (uniqueValues.size() > 256) {\n              uniqueValues = null;\n            }\n          }\n        }\n\n        ++count;\n      }\n      assert count == maxDoc;\n    }\n\n    if (uniqueValues != null) {\n      // small number of unique values\n      final int bitsPerValue = PackedInts.bitsRequired(uniqueValues.size()-1);\n      FormatAndBits formatAndBits = PackedInts.fastestFormatAndBits(maxDoc, bitsPerValue, acceptableOverheadRatio);\n      if (formatAndBits.bitsPerValue == 8 && minValue >= Byte.MIN_VALUE && maxValue <= Byte.MAX_VALUE) {\n        meta.writeByte(UNCOMPRESSED); // uncompressed\n        for (Number nv : values) {\n          data.writeByte(nv == null ? 0 : (byte) nv.longValue());\n        }\n      } else {\n        meta.writeByte(TABLE_COMPRESSED); // table-compressed\n        Long[] decode = uniqueValues.toArray(new Long[uniqueValues.size()]);\n        final HashMap<Long,Integer> encode = new HashMap<>();\n        data.writeVInt(decode.length);\n        for (int i = 0; i < decode.length; i++) {\n          data.writeLong(decode[i]);\n          encode.put(decode[i], i);\n        }\n\n        meta.writeVInt(PackedInts.VERSION_CURRENT);\n        data.writeVInt(formatAndBits.format.getId());\n        data.writeVInt(formatAndBits.bitsPerValue);\n\n        final PackedInts.Writer writer = PackedInts.getWriterNoHeader(data, formatAndBits.format, maxDoc, formatAndBits.bitsPerValue, PackedInts.DEFAULT_BUFFER_SIZE);\n        for(Number nv : values) {\n          writer.add(encode.get(nv == null ? 0 : nv.longValue()));\n        }\n        writer.finish();\n      }\n    } else if (gcd != 0 && gcd != 1) {\n      meta.writeByte(GCD_COMPRESSED);\n      meta.writeVInt(PackedInts.VERSION_CURRENT);\n      data.writeLong(minValue);\n      data.writeLong(gcd);\n      data.writeVInt(BLOCK_SIZE);\n\n      final BlockPackedWriter writer = new BlockPackedWriter(data, BLOCK_SIZE);\n      for (Number nv : values) {\n        long value = nv == null ? 0 : nv.longValue();\n        writer.add((value - minValue) / gcd);\n      }\n      writer.finish();\n    } else {\n      meta.writeByte(DELTA_COMPRESSED); // delta-compressed\n\n      meta.writeVInt(PackedInts.VERSION_CURRENT);\n      data.writeVInt(BLOCK_SIZE);\n\n      final BlockPackedWriter writer = new BlockPackedWriter(data, BLOCK_SIZE);\n      for (Number nv : values) {\n        writer.add(nv == null ? 0 : nv.longValue());\n      }\n      writer.finish();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["e70ec9cf78e14cbbf13fd0e1a9aefa8081c325ff"],"d36ccb9a1c11aeb91962e89bda4a2e643c8629b3":["634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"3dffec77fb8f7d0e9ca4869dddd6af94528b4576":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","e70ec9cf78e14cbbf13fd0e1a9aefa8081c325ff"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"4cc45c615dbb82bf79d5f9550286098367874fbf":["8106bc60c7452250f84c65cdb43ab6b1d8eb1534"],"8106bc60c7452250f84c65cdb43ab6b1d8eb1534":["d36ccb9a1c11aeb91962e89bda4a2e643c8629b3"],"e70ec9cf78e14cbbf13fd0e1a9aefa8081c325ff":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","09a42395865f791464f0bd5f6118a4abbfa3eb8a"],"09a42395865f791464f0bd5f6118a4abbfa3eb8a":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["402ad3ddc9da7b70da1b167667a60ece6a1381fb"],"402ad3ddc9da7b70da1b167667a60ece6a1381fb":["8106bc60c7452250f84c65cdb43ab6b1d8eb1534","4cc45c615dbb82bf79d5f9550286098367874fbf"]},"commit2Childs":{"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["d36ccb9a1c11aeb91962e89bda4a2e643c8629b3"],"d36ccb9a1c11aeb91962e89bda4a2e643c8629b3":["8106bc60c7452250f84c65cdb43ab6b1d8eb1534"],"3dffec77fb8f7d0e9ca4869dddd6af94528b4576":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["3dffec77fb8f7d0e9ca4869dddd6af94528b4576","e70ec9cf78e14cbbf13fd0e1a9aefa8081c325ff","09a42395865f791464f0bd5f6118a4abbfa3eb8a"],"4cc45c615dbb82bf79d5f9550286098367874fbf":["402ad3ddc9da7b70da1b167667a60ece6a1381fb"],"8106bc60c7452250f84c65cdb43ab6b1d8eb1534":["4cc45c615dbb82bf79d5f9550286098367874fbf","402ad3ddc9da7b70da1b167667a60ece6a1381fb"],"e70ec9cf78e14cbbf13fd0e1a9aefa8081c325ff":["634f330c54fd3f9f491d52036dc3f40b4f4d8934","3dffec77fb8f7d0e9ca4869dddd6af94528b4576"],"09a42395865f791464f0bd5f6118a4abbfa3eb8a":["e70ec9cf78e14cbbf13fd0e1a9aefa8081c325ff"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"402ad3ddc9da7b70da1b167667a60ece6a1381fb":["cd5edd1f2b162a5cfa08efd17851a07373a96817"]},"heads":["3dffec77fb8f7d0e9ca4869dddd6af94528b4576","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}