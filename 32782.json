{"path":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/BlendedInfixSuggester#createResults(IndexSearcher,TopFieldDocs,int,CharSequence,boolean,Set[String],String).mjava","commits":[{"id":"a371aa649cc243e82cb8677ca960a1e0232ecedf","date":1393605574,"type":1,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/BlendedInfixSuggester#createResults(IndexSearcher,TopFieldDocs,int,CharSequence,boolean,Set[String],String).mjava","pathOld":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/BlendedInfixSuggester#createResults(TopDocs,int,CharSequence,boolean,Set[String],String).mjava","sourceNew":"  @Override\n  protected List<Lookup.LookupResult> createResults(IndexSearcher searcher, TopFieldDocs hits, int num, CharSequence key,\n                                                    boolean doHighlight, Set<String> matchedTokens, String prefixToken)\n      throws IOException {\n\n    BinaryDocValues textDV = MultiDocValues.getBinaryValues(searcher.getIndexReader(), TEXT_FIELD_NAME);\n    assert textDV != null;\n\n    // This will just be null if app didn't pass payloads to build():\n    // TODO: maybe just stored fields?  they compress...\n    BinaryDocValues payloadsDV = MultiDocValues.getBinaryValues(searcher.getIndexReader(), \"payloads\");\n\n    TreeSet<Lookup.LookupResult> results = new TreeSet<>(LOOKUP_COMP);\n\n    // we reduce the num to the one initially requested\n    int actualNum = num / numFactor;\n\n    BytesRef scratch = new BytesRef();\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      FieldDoc fd = (FieldDoc) hits.scoreDocs[i];\n\n      textDV.get(fd.doc, scratch);\n      String text = scratch.utf8ToString();\n      long weight = (Long) fd.fields[0];\n\n      BytesRef payload;\n      if (payloadsDV != null) {\n        payload = new BytesRef();\n        payloadsDV.get(fd.doc, payload);\n      } else {\n        payload = null;\n      }\n\n      double coefficient;\n      if (text.startsWith(key.toString())) {\n        // if hit starts with the key, we don't change the score\n        coefficient = 1;\n      } else {\n        coefficient = createCoefficient(searcher, fd.doc, matchedTokens, prefixToken);\n      }\n\n      long score = (long) (weight * coefficient);\n\n      LookupResult result;\n      if (doHighlight) {\n        Object highlightKey = highlight(text, matchedTokens, prefixToken);\n        result = new LookupResult(highlightKey.toString(), highlightKey, score, payload);\n      } else {\n        result = new LookupResult(text, score, payload);\n      }\n\n      boundedTreeAdd(results, result, actualNum);\n    }\n\n    return new ArrayList<>(results.descendingSet());\n  }\n\n","sourceOld":"  @Override\n  protected List<Lookup.LookupResult> createResults(TopDocs hits, int num, CharSequence key,\n                                                    boolean doHighlight, Set<String> matchedTokens, String prefixToken)\n      throws IOException {\n\n    TreeSet<Lookup.LookupResult> results = new TreeSet<>(LOOKUP_COMP);\n\n    // we reduce the num to the one initially requested\n    int actualNum = num / numFactor;\n\n    BytesRef scratch = new BytesRef();\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n\n      ScoreDoc sd = hits.scoreDocs[i];\n      textDV.get(sd.doc, scratch);\n      String text = scratch.utf8ToString();\n      long weight = weightsDV.get(sd.doc);\n\n      BytesRef payload;\n      if (payloadsDV != null) {\n        payload = new BytesRef();\n        payloadsDV.get(sd.doc, payload);\n      } else {\n        payload = null;\n      }\n\n      double coefficient;\n      if (text.startsWith(key.toString())) {\n        // if hit starts with the key, we don't change the score\n        coefficient = 1;\n      } else {\n        coefficient = createCoefficient(sd.doc, matchedTokens, prefixToken);\n      }\n\n      long score = (long) (weight * coefficient);\n\n      LookupResult result;\n      if (doHighlight) {\n        Object highlightKey = highlight(text, matchedTokens, prefixToken);\n        result = new LookupResult(highlightKey.toString(), highlightKey, score, payload);\n      } else {\n        result = new LookupResult(text, score, payload);\n      }\n\n      boundedTreeAdd(results, result, actualNum);\n    }\n\n    return new ArrayList<>(results.descendingSet());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"53fc2f4c5ce4f2053be3d5f5d14d79129ebb4bbf","date":1401983689,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/BlendedInfixSuggester#createResults(IndexSearcher,TopFieldDocs,int,CharSequence,boolean,Set[String],String).mjava","pathOld":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/BlendedInfixSuggester#createResults(IndexSearcher,TopFieldDocs,int,CharSequence,boolean,Set[String],String).mjava","sourceNew":"  @Override\n  protected List<Lookup.LookupResult> createResults(IndexSearcher searcher, TopFieldDocs hits, int num, CharSequence key,\n                                                    boolean doHighlight, Set<String> matchedTokens, String prefixToken)\n      throws IOException {\n\n    BinaryDocValues textDV = MultiDocValues.getBinaryValues(searcher.getIndexReader(), TEXT_FIELD_NAME);\n    assert textDV != null;\n\n    // This will just be null if app didn't pass payloads to build():\n    // TODO: maybe just stored fields?  they compress...\n    BinaryDocValues payloadsDV = MultiDocValues.getBinaryValues(searcher.getIndexReader(), \"payloads\");\n\n    TreeSet<Lookup.LookupResult> results = new TreeSet<>(LOOKUP_COMP);\n\n    // we reduce the num to the one initially requested\n    int actualNum = num / numFactor;\n\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      FieldDoc fd = (FieldDoc) hits.scoreDocs[i];\n\n      final String text = textDV.get(fd.doc).utf8ToString();\n      long weight = (Long) fd.fields[0];\n\n      BytesRef payload;\n      if (payloadsDV != null) {\n        payload = BytesRef.deepCopyOf(payloadsDV.get(fd.doc));\n      } else {\n        payload = null;\n      }\n\n      double coefficient;\n      if (text.startsWith(key.toString())) {\n        // if hit starts with the key, we don't change the score\n        coefficient = 1;\n      } else {\n        coefficient = createCoefficient(searcher, fd.doc, matchedTokens, prefixToken);\n      }\n\n      long score = (long) (weight * coefficient);\n\n      LookupResult result;\n      if (doHighlight) {\n        Object highlightKey = highlight(text, matchedTokens, prefixToken);\n        result = new LookupResult(highlightKey.toString(), highlightKey, score, payload);\n      } else {\n        result = new LookupResult(text, score, payload);\n      }\n\n      boundedTreeAdd(results, result, actualNum);\n    }\n\n    return new ArrayList<>(results.descendingSet());\n  }\n\n","sourceOld":"  @Override\n  protected List<Lookup.LookupResult> createResults(IndexSearcher searcher, TopFieldDocs hits, int num, CharSequence key,\n                                                    boolean doHighlight, Set<String> matchedTokens, String prefixToken)\n      throws IOException {\n\n    BinaryDocValues textDV = MultiDocValues.getBinaryValues(searcher.getIndexReader(), TEXT_FIELD_NAME);\n    assert textDV != null;\n\n    // This will just be null if app didn't pass payloads to build():\n    // TODO: maybe just stored fields?  they compress...\n    BinaryDocValues payloadsDV = MultiDocValues.getBinaryValues(searcher.getIndexReader(), \"payloads\");\n\n    TreeSet<Lookup.LookupResult> results = new TreeSet<>(LOOKUP_COMP);\n\n    // we reduce the num to the one initially requested\n    int actualNum = num / numFactor;\n\n    BytesRef scratch = new BytesRef();\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      FieldDoc fd = (FieldDoc) hits.scoreDocs[i];\n\n      textDV.get(fd.doc, scratch);\n      String text = scratch.utf8ToString();\n      long weight = (Long) fd.fields[0];\n\n      BytesRef payload;\n      if (payloadsDV != null) {\n        payload = new BytesRef();\n        payloadsDV.get(fd.doc, payload);\n      } else {\n        payload = null;\n      }\n\n      double coefficient;\n      if (text.startsWith(key.toString())) {\n        // if hit starts with the key, we don't change the score\n        coefficient = 1;\n      } else {\n        coefficient = createCoefficient(searcher, fd.doc, matchedTokens, prefixToken);\n      }\n\n      long score = (long) (weight * coefficient);\n\n      LookupResult result;\n      if (doHighlight) {\n        Object highlightKey = highlight(text, matchedTokens, prefixToken);\n        result = new LookupResult(highlightKey.toString(), highlightKey, score, payload);\n      } else {\n        result = new LookupResult(text, score, payload);\n      }\n\n      boundedTreeAdd(results, result, actualNum);\n    }\n\n    return new ArrayList<>(results.descendingSet());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"ec083aa3f3ecd55f91c47009d49e45553f99bd77","date":1416002645,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/BlendedInfixSuggester#createResults(IndexSearcher,TopFieldDocs,int,CharSequence,boolean,Set[String],String).mjava","pathOld":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/BlendedInfixSuggester#createResults(IndexSearcher,TopFieldDocs,int,CharSequence,boolean,Set[String],String).mjava","sourceNew":"  @Override\n  protected List<Lookup.LookupResult> createResults(IndexSearcher searcher, TopFieldDocs hits, int num, CharSequence key,\n                                                    boolean doHighlight, Set<String> matchedTokens, String prefixToken)\n      throws IOException {\n\n    BinaryDocValues textDV = MultiDocValues.getBinaryValues(searcher.getIndexReader(), TEXT_FIELD_NAME);\n    assert textDV != null;\n\n    // This will just be null if app didn't pass payloads to build():\n    // TODO: maybe just stored fields?  they compress...\n    BinaryDocValues payloadsDV = MultiDocValues.getBinaryValues(searcher.getIndexReader(), \"payloads\");\n\n    TreeSet<Lookup.LookupResult> results = new TreeSet<>(LOOKUP_COMP);\n\n    // we reduce the num to the one initially requested\n    int actualNum = num / numFactor;\n\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      FieldDoc fd = (FieldDoc) hits.scoreDocs[i];\n\n      final String text = textDV.get(fd.doc).utf8ToString();\n      long weight = (Long) fd.fields[0];\n\n      BytesRef payload;\n      if (payloadsDV != null) {\n        payload = BytesRef.deepCopyOf(payloadsDV.get(fd.doc));\n      } else {\n        payload = null;\n      }\n\n      double coefficient;\n      if (text.startsWith(key.toString())) {\n        // if hit starts with the key, we don't change the score\n        coefficient = 1;\n      } else {\n        coefficient = createCoefficient(searcher, fd.doc, matchedTokens, prefixToken);\n      }\n\n      long score = (long) (weight * coefficient);\n\n      LookupResult result;\n      if (doHighlight) {\n        result = new LookupResult(text, highlight(text, matchedTokens, prefixToken), score, payload);\n      } else {\n        result = new LookupResult(text, score, payload);\n      }\n\n      boundedTreeAdd(results, result, actualNum);\n    }\n\n    return new ArrayList<>(results.descendingSet());\n  }\n\n","sourceOld":"  @Override\n  protected List<Lookup.LookupResult> createResults(IndexSearcher searcher, TopFieldDocs hits, int num, CharSequence key,\n                                                    boolean doHighlight, Set<String> matchedTokens, String prefixToken)\n      throws IOException {\n\n    BinaryDocValues textDV = MultiDocValues.getBinaryValues(searcher.getIndexReader(), TEXT_FIELD_NAME);\n    assert textDV != null;\n\n    // This will just be null if app didn't pass payloads to build():\n    // TODO: maybe just stored fields?  they compress...\n    BinaryDocValues payloadsDV = MultiDocValues.getBinaryValues(searcher.getIndexReader(), \"payloads\");\n\n    TreeSet<Lookup.LookupResult> results = new TreeSet<>(LOOKUP_COMP);\n\n    // we reduce the num to the one initially requested\n    int actualNum = num / numFactor;\n\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      FieldDoc fd = (FieldDoc) hits.scoreDocs[i];\n\n      final String text = textDV.get(fd.doc).utf8ToString();\n      long weight = (Long) fd.fields[0];\n\n      BytesRef payload;\n      if (payloadsDV != null) {\n        payload = BytesRef.deepCopyOf(payloadsDV.get(fd.doc));\n      } else {\n        payload = null;\n      }\n\n      double coefficient;\n      if (text.startsWith(key.toString())) {\n        // if hit starts with the key, we don't change the score\n        coefficient = 1;\n      } else {\n        coefficient = createCoefficient(searcher, fd.doc, matchedTokens, prefixToken);\n      }\n\n      long score = (long) (weight * coefficient);\n\n      LookupResult result;\n      if (doHighlight) {\n        Object highlightKey = highlight(text, matchedTokens, prefixToken);\n        result = new LookupResult(highlightKey.toString(), highlightKey, score, payload);\n      } else {\n        result = new LookupResult(text, score, payload);\n      }\n\n      boundedTreeAdd(results, result, actualNum);\n    }\n\n    return new ArrayList<>(results.descendingSet());\n  }\n\n","bugFix":["f13ec1b606a28789743a563929e7c556e8218297"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6652c74b2358a0b13223817a6a793bf1c9d0749d","date":1474465301,"type":3,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/BlendedInfixSuggester#createResults(IndexSearcher,TopFieldDocs,int,CharSequence,boolean,Set[String],String).mjava","pathOld":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/BlendedInfixSuggester#createResults(IndexSearcher,TopFieldDocs,int,CharSequence,boolean,Set[String],String).mjava","sourceNew":"  @Override\n  protected List<Lookup.LookupResult> createResults(IndexSearcher searcher, TopFieldDocs hits, int num, CharSequence key,\n                                                    boolean doHighlight, Set<String> matchedTokens, String prefixToken)\n      throws IOException {\n\n    TreeSet<Lookup.LookupResult> results = new TreeSet<>(LOOKUP_COMP);\n\n    // we reduce the num to the one initially requested\n    int actualNum = num / numFactor;\n\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      FieldDoc fd = (FieldDoc) hits.scoreDocs[i];\n\n      BinaryDocValues textDV = MultiDocValues.getBinaryValues(searcher.getIndexReader(), TEXT_FIELD_NAME);\n      assert textDV != null;\n\n      textDV.advance(fd.doc);\n\n      final String text = textDV.binaryValue().utf8ToString();\n      long weight = (Long) fd.fields[0];\n\n      // This will just be null if app didn't pass payloads to build():\n      // TODO: maybe just stored fields?  they compress...\n      BinaryDocValues payloadsDV = MultiDocValues.getBinaryValues(searcher.getIndexReader(), \"payloads\");\n\n      BytesRef payload;\n      if (payloadsDV != null) {\n        if (payloadsDV.advance(fd.doc) == fd.doc) {\n          payload = BytesRef.deepCopyOf(payloadsDV.binaryValue());\n        } else {\n          payload = new BytesRef(BytesRef.EMPTY_BYTES);\n        }\n      } else {\n        payload = null;\n      }\n\n      double coefficient;\n      if (text.startsWith(key.toString())) {\n        // if hit starts with the key, we don't change the score\n        coefficient = 1;\n      } else {\n        coefficient = createCoefficient(searcher, fd.doc, matchedTokens, prefixToken);\n      }\n\n      long score = (long) (weight * coefficient);\n\n      LookupResult result;\n      if (doHighlight) {\n        result = new LookupResult(text, highlight(text, matchedTokens, prefixToken), score, payload);\n      } else {\n        result = new LookupResult(text, score, payload);\n      }\n\n      boundedTreeAdd(results, result, actualNum);\n    }\n\n    return new ArrayList<>(results.descendingSet());\n  }\n\n","sourceOld":"  @Override\n  protected List<Lookup.LookupResult> createResults(IndexSearcher searcher, TopFieldDocs hits, int num, CharSequence key,\n                                                    boolean doHighlight, Set<String> matchedTokens, String prefixToken)\n      throws IOException {\n\n    BinaryDocValues textDV = MultiDocValues.getBinaryValues(searcher.getIndexReader(), TEXT_FIELD_NAME);\n    assert textDV != null;\n\n    // This will just be null if app didn't pass payloads to build():\n    // TODO: maybe just stored fields?  they compress...\n    BinaryDocValues payloadsDV = MultiDocValues.getBinaryValues(searcher.getIndexReader(), \"payloads\");\n\n    TreeSet<Lookup.LookupResult> results = new TreeSet<>(LOOKUP_COMP);\n\n    // we reduce the num to the one initially requested\n    int actualNum = num / numFactor;\n\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      FieldDoc fd = (FieldDoc) hits.scoreDocs[i];\n\n      final String text = textDV.get(fd.doc).utf8ToString();\n      long weight = (Long) fd.fields[0];\n\n      BytesRef payload;\n      if (payloadsDV != null) {\n        payload = BytesRef.deepCopyOf(payloadsDV.get(fd.doc));\n      } else {\n        payload = null;\n      }\n\n      double coefficient;\n      if (text.startsWith(key.toString())) {\n        // if hit starts with the key, we don't change the score\n        coefficient = 1;\n      } else {\n        coefficient = createCoefficient(searcher, fd.doc, matchedTokens, prefixToken);\n      }\n\n      long score = (long) (weight * coefficient);\n\n      LookupResult result;\n      if (doHighlight) {\n        result = new LookupResult(text, highlight(text, matchedTokens, prefixToken), score, payload);\n      } else {\n        result = new LookupResult(text, score, payload);\n      }\n\n      boundedTreeAdd(results, result, actualNum);\n    }\n\n    return new ArrayList<>(results.descendingSet());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"17e5da53e4e5bd659e22add9bba1cfa222e7e30d","date":1475435902,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/BlendedInfixSuggester#createResults(IndexSearcher,TopFieldDocs,int,CharSequence,boolean,Set[String],String).mjava","pathOld":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/BlendedInfixSuggester#createResults(IndexSearcher,TopFieldDocs,int,CharSequence,boolean,Set[String],String).mjava","sourceNew":"  @Override\n  protected List<Lookup.LookupResult> createResults(IndexSearcher searcher, TopFieldDocs hits, int num, CharSequence key,\n                                                    boolean doHighlight, Set<String> matchedTokens, String prefixToken)\n      throws IOException {\n\n    TreeSet<Lookup.LookupResult> results = new TreeSet<>(LOOKUP_COMP);\n\n    // we reduce the num to the one initially requested\n    int actualNum = num / numFactor;\n\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      FieldDoc fd = (FieldDoc) hits.scoreDocs[i];\n\n      BinaryDocValues textDV = MultiDocValues.getBinaryValues(searcher.getIndexReader(), TEXT_FIELD_NAME);\n      assert textDV != null;\n\n      textDV.advance(fd.doc);\n\n      final String text = textDV.binaryValue().utf8ToString();\n      long weight = (Long) fd.fields[0];\n\n      // This will just be null if app didn't pass payloads to build():\n      // TODO: maybe just stored fields?  they compress...\n      BinaryDocValues payloadsDV = MultiDocValues.getBinaryValues(searcher.getIndexReader(), \"payloads\");\n\n      BytesRef payload;\n      if (payloadsDV != null) {\n        if (payloadsDV.advance(fd.doc) == fd.doc) {\n          payload = BytesRef.deepCopyOf(payloadsDV.binaryValue());\n        } else {\n          payload = new BytesRef(BytesRef.EMPTY_BYTES);\n        }\n      } else {\n        payload = null;\n      }\n\n      double coefficient;\n      if (text.startsWith(key.toString())) {\n        // if hit starts with the key, we don't change the score\n        coefficient = 1;\n      } else {\n        coefficient = createCoefficient(searcher, fd.doc, matchedTokens, prefixToken);\n      }\n\n      long score = (long) (weight * coefficient);\n\n      LookupResult result;\n      if (doHighlight) {\n        result = new LookupResult(text, highlight(text, matchedTokens, prefixToken), score, payload);\n      } else {\n        result = new LookupResult(text, score, payload);\n      }\n\n      boundedTreeAdd(results, result, actualNum);\n    }\n\n    return new ArrayList<>(results.descendingSet());\n  }\n\n","sourceOld":"  @Override\n  protected List<Lookup.LookupResult> createResults(IndexSearcher searcher, TopFieldDocs hits, int num, CharSequence key,\n                                                    boolean doHighlight, Set<String> matchedTokens, String prefixToken)\n      throws IOException {\n\n    BinaryDocValues textDV = MultiDocValues.getBinaryValues(searcher.getIndexReader(), TEXT_FIELD_NAME);\n    assert textDV != null;\n\n    // This will just be null if app didn't pass payloads to build():\n    // TODO: maybe just stored fields?  they compress...\n    BinaryDocValues payloadsDV = MultiDocValues.getBinaryValues(searcher.getIndexReader(), \"payloads\");\n\n    TreeSet<Lookup.LookupResult> results = new TreeSet<>(LOOKUP_COMP);\n\n    // we reduce the num to the one initially requested\n    int actualNum = num / numFactor;\n\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      FieldDoc fd = (FieldDoc) hits.scoreDocs[i];\n\n      final String text = textDV.get(fd.doc).utf8ToString();\n      long weight = (Long) fd.fields[0];\n\n      BytesRef payload;\n      if (payloadsDV != null) {\n        payload = BytesRef.deepCopyOf(payloadsDV.get(fd.doc));\n      } else {\n        payload = null;\n      }\n\n      double coefficient;\n      if (text.startsWith(key.toString())) {\n        // if hit starts with the key, we don't change the score\n        coefficient = 1;\n      } else {\n        coefficient = createCoefficient(searcher, fd.doc, matchedTokens, prefixToken);\n      }\n\n      long score = (long) (weight * coefficient);\n\n      LookupResult result;\n      if (doHighlight) {\n        result = new LookupResult(text, highlight(text, matchedTokens, prefixToken), score, payload);\n      } else {\n        result = new LookupResult(text, score, payload);\n      }\n\n      boundedTreeAdd(results, result, actualNum);\n    }\n\n    return new ArrayList<>(results.descendingSet());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4cce5816ef15a48a0bc11e5d400497ee4301dd3b","date":1476991456,"type":3,"author":"Kevin Risden","isMerge":true,"pathNew":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/BlendedInfixSuggester#createResults(IndexSearcher,TopFieldDocs,int,CharSequence,boolean,Set[String],String).mjava","pathOld":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/BlendedInfixSuggester#createResults(IndexSearcher,TopFieldDocs,int,CharSequence,boolean,Set[String],String).mjava","sourceNew":"  @Override\n  protected List<Lookup.LookupResult> createResults(IndexSearcher searcher, TopFieldDocs hits, int num, CharSequence key,\n                                                    boolean doHighlight, Set<String> matchedTokens, String prefixToken)\n      throws IOException {\n\n    TreeSet<Lookup.LookupResult> results = new TreeSet<>(LOOKUP_COMP);\n\n    // we reduce the num to the one initially requested\n    int actualNum = num / numFactor;\n\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      FieldDoc fd = (FieldDoc) hits.scoreDocs[i];\n\n      BinaryDocValues textDV = MultiDocValues.getBinaryValues(searcher.getIndexReader(), TEXT_FIELD_NAME);\n      assert textDV != null;\n\n      textDV.advance(fd.doc);\n\n      final String text = textDV.binaryValue().utf8ToString();\n      long weight = (Long) fd.fields[0];\n\n      // This will just be null if app didn't pass payloads to build():\n      // TODO: maybe just stored fields?  they compress...\n      BinaryDocValues payloadsDV = MultiDocValues.getBinaryValues(searcher.getIndexReader(), \"payloads\");\n\n      BytesRef payload;\n      if (payloadsDV != null) {\n        if (payloadsDV.advance(fd.doc) == fd.doc) {\n          payload = BytesRef.deepCopyOf(payloadsDV.binaryValue());\n        } else {\n          payload = new BytesRef(BytesRef.EMPTY_BYTES);\n        }\n      } else {\n        payload = null;\n      }\n\n      double coefficient;\n      if (text.startsWith(key.toString())) {\n        // if hit starts with the key, we don't change the score\n        coefficient = 1;\n      } else {\n        coefficient = createCoefficient(searcher, fd.doc, matchedTokens, prefixToken);\n      }\n\n      long score = (long) (weight * coefficient);\n\n      LookupResult result;\n      if (doHighlight) {\n        result = new LookupResult(text, highlight(text, matchedTokens, prefixToken), score, payload);\n      } else {\n        result = new LookupResult(text, score, payload);\n      }\n\n      boundedTreeAdd(results, result, actualNum);\n    }\n\n    return new ArrayList<>(results.descendingSet());\n  }\n\n","sourceOld":"  @Override\n  protected List<Lookup.LookupResult> createResults(IndexSearcher searcher, TopFieldDocs hits, int num, CharSequence key,\n                                                    boolean doHighlight, Set<String> matchedTokens, String prefixToken)\n      throws IOException {\n\n    BinaryDocValues textDV = MultiDocValues.getBinaryValues(searcher.getIndexReader(), TEXT_FIELD_NAME);\n    assert textDV != null;\n\n    // This will just be null if app didn't pass payloads to build():\n    // TODO: maybe just stored fields?  they compress...\n    BinaryDocValues payloadsDV = MultiDocValues.getBinaryValues(searcher.getIndexReader(), \"payloads\");\n\n    TreeSet<Lookup.LookupResult> results = new TreeSet<>(LOOKUP_COMP);\n\n    // we reduce the num to the one initially requested\n    int actualNum = num / numFactor;\n\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      FieldDoc fd = (FieldDoc) hits.scoreDocs[i];\n\n      final String text = textDV.get(fd.doc).utf8ToString();\n      long weight = (Long) fd.fields[0];\n\n      BytesRef payload;\n      if (payloadsDV != null) {\n        payload = BytesRef.deepCopyOf(payloadsDV.get(fd.doc));\n      } else {\n        payload = null;\n      }\n\n      double coefficient;\n      if (text.startsWith(key.toString())) {\n        // if hit starts with the key, we don't change the score\n        coefficient = 1;\n      } else {\n        coefficient = createCoefficient(searcher, fd.doc, matchedTokens, prefixToken);\n      }\n\n      long score = (long) (weight * coefficient);\n\n      LookupResult result;\n      if (doHighlight) {\n        result = new LookupResult(text, highlight(text, matchedTokens, prefixToken), score, payload);\n      } else {\n        result = new LookupResult(text, score, payload);\n      }\n\n      boundedTreeAdd(results, result, actualNum);\n    }\n\n    return new ArrayList<>(results.descendingSet());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8712eb1280636aa9e2103ef8ad56ec19641709ea","date":1527853961,"type":3,"author":"Alessandro Benedetti","isMerge":false,"pathNew":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/BlendedInfixSuggester#createResults(IndexSearcher,TopFieldDocs,int,CharSequence,boolean,Set[String],String).mjava","pathOld":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/BlendedInfixSuggester#createResults(IndexSearcher,TopFieldDocs,int,CharSequence,boolean,Set[String],String).mjava","sourceNew":"  @Override\n  protected List<Lookup.LookupResult> createResults(IndexSearcher searcher, TopFieldDocs hits, int num, CharSequence key,\n                                                    boolean doHighlight, Set<String> matchedTokens, String prefixToken)\n      throws IOException {\n\n    TreeSet<Lookup.LookupResult> results = new TreeSet<>(LOOKUP_COMP);\n\n    // we reduce the num to the one initially requested\n    int actualNum = num / numFactor;\n\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      FieldDoc fd = (FieldDoc) hits.scoreDocs[i];\n\n      BinaryDocValues textDV = MultiDocValues.getBinaryValues(searcher.getIndexReader(), TEXT_FIELD_NAME);\n      assert textDV != null;\n\n      textDV.advance(fd.doc);\n\n      final String text = textDV.binaryValue().utf8ToString();\n      long weight = (Long) fd.fields[0];\n\n      // This will just be null if app didn't pass payloads to build():\n      // TODO: maybe just stored fields?  they compress...\n      BinaryDocValues payloadsDV = MultiDocValues.getBinaryValues(searcher.getIndexReader(), \"payloads\");\n\n      BytesRef payload;\n      if (payloadsDV != null) {\n        if (payloadsDV.advance(fd.doc) == fd.doc) {\n          payload = BytesRef.deepCopyOf(payloadsDV.binaryValue());\n        } else {\n          payload = new BytesRef(BytesRef.EMPTY_BYTES);\n        }\n      } else {\n        payload = null;\n      }\n\n      double coefficient;\n      if (text.startsWith(key.toString())) {\n        // if hit starts with the key, we don't change the score\n        coefficient = 1;\n      } else {\n        coefficient = createCoefficient(searcher, fd.doc, matchedTokens, prefixToken);\n      }\n      if (weight == 0) {\n        weight = 1;\n      }\n      long scaledCoefficient = (long) (coefficient * 10);\n      long score = weight * scaledCoefficient;\n\n      LookupResult result;\n      if (doHighlight) {\n        result = new LookupResult(text, highlight(text, matchedTokens, prefixToken), score, payload);\n      } else {\n        result = new LookupResult(text, score, payload);\n      }\n\n      boundedTreeAdd(results, result, actualNum);\n    }\n\n    return new ArrayList<>(results.descendingSet());\n  }\n\n","sourceOld":"  @Override\n  protected List<Lookup.LookupResult> createResults(IndexSearcher searcher, TopFieldDocs hits, int num, CharSequence key,\n                                                    boolean doHighlight, Set<String> matchedTokens, String prefixToken)\n      throws IOException {\n\n    TreeSet<Lookup.LookupResult> results = new TreeSet<>(LOOKUP_COMP);\n\n    // we reduce the num to the one initially requested\n    int actualNum = num / numFactor;\n\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      FieldDoc fd = (FieldDoc) hits.scoreDocs[i];\n\n      BinaryDocValues textDV = MultiDocValues.getBinaryValues(searcher.getIndexReader(), TEXT_FIELD_NAME);\n      assert textDV != null;\n\n      textDV.advance(fd.doc);\n\n      final String text = textDV.binaryValue().utf8ToString();\n      long weight = (Long) fd.fields[0];\n\n      // This will just be null if app didn't pass payloads to build():\n      // TODO: maybe just stored fields?  they compress...\n      BinaryDocValues payloadsDV = MultiDocValues.getBinaryValues(searcher.getIndexReader(), \"payloads\");\n\n      BytesRef payload;\n      if (payloadsDV != null) {\n        if (payloadsDV.advance(fd.doc) == fd.doc) {\n          payload = BytesRef.deepCopyOf(payloadsDV.binaryValue());\n        } else {\n          payload = new BytesRef(BytesRef.EMPTY_BYTES);\n        }\n      } else {\n        payload = null;\n      }\n\n      double coefficient;\n      if (text.startsWith(key.toString())) {\n        // if hit starts with the key, we don't change the score\n        coefficient = 1;\n      } else {\n        coefficient = createCoefficient(searcher, fd.doc, matchedTokens, prefixToken);\n      }\n\n      long score = (long) (weight * coefficient);\n\n      LookupResult result;\n      if (doHighlight) {\n        result = new LookupResult(text, highlight(text, matchedTokens, prefixToken), score, payload);\n      } else {\n        result = new LookupResult(text, score, payload);\n      }\n\n      boundedTreeAdd(results, result, actualNum);\n    }\n\n    return new ArrayList<>(results.descendingSet());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0f85ab7c9984664325c8d83527d0c5828b1a06b1","date":1528394250,"type":3,"author":"Alessandro Benedetti","isMerge":false,"pathNew":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/BlendedInfixSuggester#createResults(IndexSearcher,TopFieldDocs,int,CharSequence,boolean,Set[String],String).mjava","pathOld":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/BlendedInfixSuggester#createResults(IndexSearcher,TopFieldDocs,int,CharSequence,boolean,Set[String],String).mjava","sourceNew":"  @Override\n  protected List<Lookup.LookupResult> createResults(IndexSearcher searcher, TopFieldDocs hits, int num, CharSequence key,\n                                                    boolean doHighlight, Set<String> matchedTokens, String prefixToken)\n      throws IOException {\n\n    TreeSet<Lookup.LookupResult> results = new TreeSet<>(LOOKUP_COMP);\n\n    // we reduce the num to the one initially requested\n    int actualNum = num / numFactor;\n\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      FieldDoc fd = (FieldDoc) hits.scoreDocs[i];\n\n      BinaryDocValues textDV = MultiDocValues.getBinaryValues(searcher.getIndexReader(), TEXT_FIELD_NAME);\n      assert textDV != null;\n\n      textDV.advance(fd.doc);\n\n      final String text = textDV.binaryValue().utf8ToString();\n      long weight = (Long) fd.fields[0];\n\n      // This will just be null if app didn't pass payloads to build():\n      // TODO: maybe just stored fields?  they compress...\n      BinaryDocValues payloadsDV = MultiDocValues.getBinaryValues(searcher.getIndexReader(), \"payloads\");\n\n      BytesRef payload;\n      if (payloadsDV != null) {\n        if (payloadsDV.advance(fd.doc) == fd.doc) {\n          payload = BytesRef.deepCopyOf(payloadsDV.binaryValue());\n        } else {\n          payload = new BytesRef(BytesRef.EMPTY_BYTES);\n        }\n      } else {\n        payload = null;\n      }\n\n      double coefficient;\n      if (text.startsWith(key.toString())) {\n        // if hit starts with the key, we don't change the score\n        coefficient = 1;\n      } else {\n        coefficient = createCoefficient(searcher, fd.doc, matchedTokens, prefixToken);\n      }\n      if (weight == 0) {\n        weight = 1;\n      }\n      if (weight < 1 / LINEAR_COEF && weight > -1 / LINEAR_COEF) {\n        weight *= 1 / LINEAR_COEF;\n      }\n      long score = (long) (weight * coefficient);\n\n      LookupResult result;\n      if (doHighlight) {\n        result = new LookupResult(text, highlight(text, matchedTokens, prefixToken), score, payload);\n      } else {\n        result = new LookupResult(text, score, payload);\n      }\n\n      boundedTreeAdd(results, result, actualNum);\n    }\n\n    return new ArrayList<>(results.descendingSet());\n  }\n\n","sourceOld":"  @Override\n  protected List<Lookup.LookupResult> createResults(IndexSearcher searcher, TopFieldDocs hits, int num, CharSequence key,\n                                                    boolean doHighlight, Set<String> matchedTokens, String prefixToken)\n      throws IOException {\n\n    TreeSet<Lookup.LookupResult> results = new TreeSet<>(LOOKUP_COMP);\n\n    // we reduce the num to the one initially requested\n    int actualNum = num / numFactor;\n\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      FieldDoc fd = (FieldDoc) hits.scoreDocs[i];\n\n      BinaryDocValues textDV = MultiDocValues.getBinaryValues(searcher.getIndexReader(), TEXT_FIELD_NAME);\n      assert textDV != null;\n\n      textDV.advance(fd.doc);\n\n      final String text = textDV.binaryValue().utf8ToString();\n      long weight = (Long) fd.fields[0];\n\n      // This will just be null if app didn't pass payloads to build():\n      // TODO: maybe just stored fields?  they compress...\n      BinaryDocValues payloadsDV = MultiDocValues.getBinaryValues(searcher.getIndexReader(), \"payloads\");\n\n      BytesRef payload;\n      if (payloadsDV != null) {\n        if (payloadsDV.advance(fd.doc) == fd.doc) {\n          payload = BytesRef.deepCopyOf(payloadsDV.binaryValue());\n        } else {\n          payload = new BytesRef(BytesRef.EMPTY_BYTES);\n        }\n      } else {\n        payload = null;\n      }\n\n      double coefficient;\n      if (text.startsWith(key.toString())) {\n        // if hit starts with the key, we don't change the score\n        coefficient = 1;\n      } else {\n        coefficient = createCoefficient(searcher, fd.doc, matchedTokens, prefixToken);\n      }\n      if (weight == 0) {\n        weight = 1;\n      }\n      long scaledCoefficient = (long) (coefficient * 10);\n      long score = weight * scaledCoefficient;\n\n      LookupResult result;\n      if (doHighlight) {\n        result = new LookupResult(text, highlight(text, matchedTokens, prefixToken), score, payload);\n      } else {\n        result = new LookupResult(text, score, payload);\n      }\n\n      boundedTreeAdd(results, result, actualNum);\n    }\n\n    return new ArrayList<>(results.descendingSet());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c158eec2b5219a049e3632d30502d2d0f25d35dd","date":1536681820,"type":3,"author":"Mike McCandless","isMerge":true,"pathNew":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/BlendedInfixSuggester#createResults(IndexSearcher,TopFieldDocs,int,CharSequence,boolean,Set[String],String).mjava","pathOld":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/BlendedInfixSuggester#createResults(IndexSearcher,TopFieldDocs,int,CharSequence,boolean,Set[String],String).mjava","sourceNew":"  @Override\n  protected List<Lookup.LookupResult> createResults(IndexSearcher searcher, TopFieldDocs hits, int num, CharSequence key,\n                                                    boolean doHighlight, Set<String> matchedTokens, String prefixToken)\n      throws IOException {\n\n    TreeSet<Lookup.LookupResult> results = new TreeSet<>(LOOKUP_COMP);\n\n    // we reduce the num to the one initially requested\n    int actualNum = num / numFactor;\n\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      FieldDoc fd = (FieldDoc) hits.scoreDocs[i];\n\n      BinaryDocValues textDV = MultiDocValues.getBinaryValues(searcher.getIndexReader(), TEXT_FIELD_NAME);\n      assert textDV != null;\n\n      textDV.advance(fd.doc);\n\n      final String text = textDV.binaryValue().utf8ToString();\n      long weight = (Long) fd.fields[0];\n\n      // This will just be null if app didn't pass payloads to build():\n      // TODO: maybe just stored fields?  they compress...\n      BinaryDocValues payloadsDV = MultiDocValues.getBinaryValues(searcher.getIndexReader(), \"payloads\");\n\n      BytesRef payload;\n      if (payloadsDV != null) {\n        if (payloadsDV.advance(fd.doc) == fd.doc) {\n          payload = BytesRef.deepCopyOf(payloadsDV.binaryValue());\n        } else {\n          payload = new BytesRef(BytesRef.EMPTY_BYTES);\n        }\n      } else {\n        payload = null;\n      }\n\n      double coefficient;\n      if (text.startsWith(key.toString())) {\n        // if hit starts with the key, we don't change the score\n        coefficient = 1;\n      } else {\n        coefficient = createCoefficient(searcher, fd.doc, matchedTokens, prefixToken);\n      }\n      if (weight == 0) {\n        weight = 1;\n      }\n      if (weight < 1 / LINEAR_COEF && weight > -1 / LINEAR_COEF) {\n        weight *= 1 / LINEAR_COEF;\n      }\n      long score = (long) (weight * coefficient);\n\n      LookupResult result;\n      if (doHighlight) {\n        result = new LookupResult(text, highlight(text, matchedTokens, prefixToken), score, payload);\n      } else {\n        result = new LookupResult(text, score, payload);\n      }\n\n      boundedTreeAdd(results, result, actualNum);\n    }\n\n    return new ArrayList<>(results.descendingSet());\n  }\n\n","sourceOld":"  @Override\n  protected List<Lookup.LookupResult> createResults(IndexSearcher searcher, TopFieldDocs hits, int num, CharSequence key,\n                                                    boolean doHighlight, Set<String> matchedTokens, String prefixToken)\n      throws IOException {\n\n    TreeSet<Lookup.LookupResult> results = new TreeSet<>(LOOKUP_COMP);\n\n    // we reduce the num to the one initially requested\n    int actualNum = num / numFactor;\n\n    for (int i = 0; i < hits.scoreDocs.length; i++) {\n      FieldDoc fd = (FieldDoc) hits.scoreDocs[i];\n\n      BinaryDocValues textDV = MultiDocValues.getBinaryValues(searcher.getIndexReader(), TEXT_FIELD_NAME);\n      assert textDV != null;\n\n      textDV.advance(fd.doc);\n\n      final String text = textDV.binaryValue().utf8ToString();\n      long weight = (Long) fd.fields[0];\n\n      // This will just be null if app didn't pass payloads to build():\n      // TODO: maybe just stored fields?  they compress...\n      BinaryDocValues payloadsDV = MultiDocValues.getBinaryValues(searcher.getIndexReader(), \"payloads\");\n\n      BytesRef payload;\n      if (payloadsDV != null) {\n        if (payloadsDV.advance(fd.doc) == fd.doc) {\n          payload = BytesRef.deepCopyOf(payloadsDV.binaryValue());\n        } else {\n          payload = new BytesRef(BytesRef.EMPTY_BYTES);\n        }\n      } else {\n        payload = null;\n      }\n\n      double coefficient;\n      if (text.startsWith(key.toString())) {\n        // if hit starts with the key, we don't change the score\n        coefficient = 1;\n      } else {\n        coefficient = createCoefficient(searcher, fd.doc, matchedTokens, prefixToken);\n      }\n\n      long score = (long) (weight * coefficient);\n\n      LookupResult result;\n      if (doHighlight) {\n        result = new LookupResult(text, highlight(text, matchedTokens, prefixToken), score, payload);\n      } else {\n        result = new LookupResult(text, score, payload);\n      }\n\n      boundedTreeAdd(results, result, actualNum);\n    }\n\n    return new ArrayList<>(results.descendingSet());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"8712eb1280636aa9e2103ef8ad56ec19641709ea":["17e5da53e4e5bd659e22add9bba1cfa222e7e30d"],"53fc2f4c5ce4f2053be3d5f5d14d79129ebb4bbf":["a371aa649cc243e82cb8677ca960a1e0232ecedf"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"17e5da53e4e5bd659e22add9bba1cfa222e7e30d":["ec083aa3f3ecd55f91c47009d49e45553f99bd77","6652c74b2358a0b13223817a6a793bf1c9d0749d"],"6652c74b2358a0b13223817a6a793bf1c9d0749d":["ec083aa3f3ecd55f91c47009d49e45553f99bd77"],"ec083aa3f3ecd55f91c47009d49e45553f99bd77":["53fc2f4c5ce4f2053be3d5f5d14d79129ebb4bbf"],"c158eec2b5219a049e3632d30502d2d0f25d35dd":["17e5da53e4e5bd659e22add9bba1cfa222e7e30d","0f85ab7c9984664325c8d83527d0c5828b1a06b1"],"0f85ab7c9984664325c8d83527d0c5828b1a06b1":["8712eb1280636aa9e2103ef8ad56ec19641709ea"],"a371aa649cc243e82cb8677ca960a1e0232ecedf":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["ec083aa3f3ecd55f91c47009d49e45553f99bd77","17e5da53e4e5bd659e22add9bba1cfa222e7e30d"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["c158eec2b5219a049e3632d30502d2d0f25d35dd"]},"commit2Childs":{"8712eb1280636aa9e2103ef8ad56ec19641709ea":["0f85ab7c9984664325c8d83527d0c5828b1a06b1"],"53fc2f4c5ce4f2053be3d5f5d14d79129ebb4bbf":["ec083aa3f3ecd55f91c47009d49e45553f99bd77"],"17e5da53e4e5bd659e22add9bba1cfa222e7e30d":["8712eb1280636aa9e2103ef8ad56ec19641709ea","c158eec2b5219a049e3632d30502d2d0f25d35dd","4cce5816ef15a48a0bc11e5d400497ee4301dd3b"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["a371aa649cc243e82cb8677ca960a1e0232ecedf"],"6652c74b2358a0b13223817a6a793bf1c9d0749d":["17e5da53e4e5bd659e22add9bba1cfa222e7e30d"],"ec083aa3f3ecd55f91c47009d49e45553f99bd77":["17e5da53e4e5bd659e22add9bba1cfa222e7e30d","6652c74b2358a0b13223817a6a793bf1c9d0749d","4cce5816ef15a48a0bc11e5d400497ee4301dd3b"],"c158eec2b5219a049e3632d30502d2d0f25d35dd":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"0f85ab7c9984664325c8d83527d0c5828b1a06b1":["c158eec2b5219a049e3632d30502d2d0f25d35dd"],"a371aa649cc243e82cb8677ca960a1e0232ecedf":["53fc2f4c5ce4f2053be3d5f5d14d79129ebb4bbf"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}