{"path":"lucene/src/java/org/apache/lucene/index/DocumentsWriter#finishFlushedSegment(SegmentInfo,DocumentsWriterPerThread).mjava","commits":[{"id":"9b832cbed6eb3d54a8bb9339296bdda8eeb53014","date":1279708040,"type":0,"author":"Michael Busch","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/DocumentsWriter#finishFlushedSegment(SegmentInfo,DocumentsWriterPerThread).mjava","pathOld":"/dev/null","sourceNew":"  // nocommit\n  void finishFlushedSegment(SegmentInfo newSegment, DocumentsWriterPerThread perThread) throws IOException {\n    synchronized(indexWriter) {\n      indexWriter.segmentInfos.add(newSegment);\n      indexWriter.checkpoint();\n      SegmentReader reader = indexWriter.readerPool.get(newSegment, false);\n      boolean any = false;\n      try {\n        any = applyDeletes(reader, newSegment.getMinSequenceID(), newSegment.getMaxSequenceID(), perThread.sequenceIDs);\n      } finally {\n        indexWriter.readerPool.release(reader);\n      }\n      if (any) {\n        indexWriter.checkpoint();\n      }\n  \n      if (indexWriter.mergePolicy.useCompoundFile(indexWriter.segmentInfos, newSegment)) {\n        // Now build compound file\n        boolean success = false;\n        try {\n          createCompoundFile(newSegment.name, perThread);\n          success = true;\n        } finally {\n          if (!success) {\n            if (infoStream != null) {\n              message(\"hit exception \" +\n              \t\t\"reating compound file for newly flushed segment \" + newSegment.name);\n            }\n            indexWriter.deleter.deleteFile(IndexFileNames.segmentFileName(newSegment.name, \"\", \n                IndexFileNames.COMPOUND_FILE_EXTENSION));\n          }\n        }\n  \n        newSegment.setUseCompoundFile(true);\n        indexWriter.checkpoint();\n      }\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"334c1175813aea771a71728cd2c4ee4754fd0603","date":1279710173,"type":4,"author":"Uwe Schindler","isMerge":false,"pathNew":"/dev/null","pathOld":"lucene/src/java/org/apache/lucene/index/DocumentsWriter#finishFlushedSegment(SegmentInfo,DocumentsWriterPerThread).mjava","sourceNew":null,"sourceOld":"  // nocommit\n  void finishFlushedSegment(SegmentInfo newSegment, DocumentsWriterPerThread perThread) throws IOException {\n    synchronized(indexWriter) {\n      indexWriter.segmentInfos.add(newSegment);\n      indexWriter.checkpoint();\n      SegmentReader reader = indexWriter.readerPool.get(newSegment, false);\n      boolean any = false;\n      try {\n        any = applyDeletes(reader, newSegment.getMinSequenceID(), newSegment.getMaxSequenceID(), perThread.sequenceIDs);\n      } finally {\n        indexWriter.readerPool.release(reader);\n      }\n      if (any) {\n        indexWriter.checkpoint();\n      }\n  \n      if (indexWriter.mergePolicy.useCompoundFile(indexWriter.segmentInfos, newSegment)) {\n        // Now build compound file\n        boolean success = false;\n        try {\n          createCompoundFile(newSegment.name, perThread);\n          success = true;\n        } finally {\n          if (!success) {\n            if (infoStream != null) {\n              message(\"hit exception \" +\n              \t\t\"reating compound file for newly flushed segment \" + newSegment.name);\n            }\n            indexWriter.deleter.deleteFile(IndexFileNames.segmentFileName(newSegment.name, \"\", \n                IndexFileNames.COMPOUND_FILE_EXTENSION));\n          }\n        }\n  \n        newSegment.setUseCompoundFile(true);\n        indexWriter.checkpoint();\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8fe956d65251358d755c56f14fe8380644790e47","date":1279711318,"type":0,"author":"Michael Busch","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/DocumentsWriter#finishFlushedSegment(SegmentInfo,DocumentsWriterPerThread).mjava","pathOld":"/dev/null","sourceNew":"  // nocommit\n  void finishFlushedSegment(SegmentInfo newSegment, DocumentsWriterPerThread perThread) throws IOException {\n    synchronized(indexWriter) {\n      indexWriter.segmentInfos.add(newSegment);\n      indexWriter.checkpoint();\n      SegmentReader reader = indexWriter.readerPool.get(newSegment, false);\n      boolean any = false;\n      try {\n        any = applyDeletes(reader, newSegment.getMinSequenceID(), newSegment.getMaxSequenceID(), perThread.sequenceIDs);\n      } finally {\n        indexWriter.readerPool.release(reader);\n      }\n      if (any) {\n        indexWriter.checkpoint();\n      }\n  \n      if (indexWriter.mergePolicy.useCompoundFile(indexWriter.segmentInfos, newSegment)) {\n        // Now build compound file\n        boolean success = false;\n        try {\n          createCompoundFile(newSegment.name, perThread);\n          success = true;\n        } finally {\n          if (!success) {\n            if (infoStream != null) {\n              message(\"hit exception \" +\n              \t\t\"reating compound file for newly flushed segment \" + newSegment.name);\n            }\n            indexWriter.deleter.deleteFile(IndexFileNames.segmentFileName(newSegment.name, \"\", \n                IndexFileNames.COMPOUND_FILE_EXTENSION));\n          }\n        }\n  \n        newSegment.setUseCompoundFile(true);\n        indexWriter.checkpoint();\n      }\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["5ef87af8c7bd0f8429622b83aa74202383f2e757"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"833a7987bc1c94455fde83e3311f72bddedcfb93","date":1279951470,"type":3,"author":"Michael Busch","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/DocumentsWriter#finishFlushedSegment(SegmentInfo,DocumentsWriterPerThread).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/DocumentsWriter#finishFlushedSegment(SegmentInfo,DocumentsWriterPerThread).mjava","sourceNew":"  // nocommit\n  void finishFlushedSegment(SegmentInfo newSegment, DocumentsWriterPerThread perThread) throws IOException {\n    synchronized(indexWriter) {\n      indexWriter.segmentInfos.add(newSegment);\n      indexWriter.checkpoint();\n    \n      SegmentReader reader = indexWriter.readerPool.get(newSegment, false);\n      boolean any = false;\n      try {\n        any = applyDeletes(reader, newSegment.getMinSequenceID(), newSegment.getMaxSequenceID(), perThread.sequenceIDs);\n      } finally {\n        indexWriter.readerPool.release(reader);\n      }\n      if (any) {\n        indexWriter.checkpoint();\n      }\n  \n      if (indexWriter.mergePolicy.useCompoundFile(indexWriter.segmentInfos, newSegment)) {\n        // Now build compound file\n        boolean success = false;\n        try {\n          createCompoundFile(newSegment.name, perThread);\n          success = true;\n        } finally {\n          if (!success) {\n            if (infoStream != null) {\n              message(\"hit exception \" +\n              \t\t\"reating compound file for newly flushed segment \" + newSegment.name);\n            }\n            indexWriter.deleter.deleteFile(IndexFileNames.segmentFileName(newSegment.name, \"\", \n                IndexFileNames.COMPOUND_FILE_EXTENSION));\n          }\n        }\n  \n        synchronized(indexWriter) {\n          newSegment.setUseCompoundFile(true);\n          indexWriter.checkpoint();\n          // In case the files we just merged into a CFS were\n          // not previously checkpointed:\n          indexWriter.deleter.deleteNewFiles(perThread.closedFiles());\n        }\n      }\n    }\n  }\n\n","sourceOld":"  // nocommit\n  void finishFlushedSegment(SegmentInfo newSegment, DocumentsWriterPerThread perThread) throws IOException {\n    synchronized(indexWriter) {\n      indexWriter.segmentInfos.add(newSegment);\n      indexWriter.checkpoint();\n      SegmentReader reader = indexWriter.readerPool.get(newSegment, false);\n      boolean any = false;\n      try {\n        any = applyDeletes(reader, newSegment.getMinSequenceID(), newSegment.getMaxSequenceID(), perThread.sequenceIDs);\n      } finally {\n        indexWriter.readerPool.release(reader);\n      }\n      if (any) {\n        indexWriter.checkpoint();\n      }\n  \n      if (indexWriter.mergePolicy.useCompoundFile(indexWriter.segmentInfos, newSegment)) {\n        // Now build compound file\n        boolean success = false;\n        try {\n          createCompoundFile(newSegment.name, perThread);\n          success = true;\n        } finally {\n          if (!success) {\n            if (infoStream != null) {\n              message(\"hit exception \" +\n              \t\t\"reating compound file for newly flushed segment \" + newSegment.name);\n            }\n            indexWriter.deleter.deleteFile(IndexFileNames.segmentFileName(newSegment.name, \"\", \n                IndexFileNames.COMPOUND_FILE_EXTENSION));\n          }\n        }\n  \n        newSegment.setUseCompoundFile(true);\n        indexWriter.checkpoint();\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":["5ef87af8c7bd0f8429622b83aa74202383f2e757"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"5ef87af8c7bd0f8429622b83aa74202383f2e757","date":1280262785,"type":3,"author":"Michael Busch","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/DocumentsWriter#finishFlushedSegment(SegmentInfo,DocumentsWriterPerThread).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/DocumentsWriter#finishFlushedSegment(SegmentInfo,DocumentsWriterPerThread).mjava","sourceNew":"  void finishFlushedSegment(SegmentInfo newSegment, DocumentsWriterPerThread perThread) throws IOException {\n    SegmentReader reader = indexWriter.readerPool.get(newSegment, false);\n    try {\n      applyDeletes(reader, newSegment.getMinSequenceID(), newSegment.getMaxSequenceID(), perThread.sequenceIDs);\n    } finally {\n      indexWriter.readerPool.release(reader);\n    }\n    \n    if (indexWriter.useCompoundFile(newSegment)) {\n      String compoundFileName = IndexFileNames.segmentFileName(newSegment.name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION);\n      message(\"creating compound file \" + compoundFileName);\n      // Now build compound file\n      boolean success = false;\n      try {\n        createCompoundFile(compoundFileName, perThread);\n        success = true;\n      } finally {\n        if (!success) {\n          if (infoStream != null) {\n            message(\"hit exception \" +\n            \t\t\"reating compound file for newly flushed segment \" + newSegment.name);\n          }\n          indexWriter.deleter.deleteFile(IndexFileNames.segmentFileName(newSegment.name, \"\", \n              IndexFileNames.COMPOUND_FILE_EXTENSION));\n          for (String file : perThread.flushState.flushedFiles) {\n            indexWriter.deleter.deleteFile(file);\n          }\n\n        }\n      }\n      \n      for (String file : perThread.flushState.flushedFiles) {\n        indexWriter.deleter.deleteFile(file);\n      }\n\n      newSegment.setUseCompoundFile(true);\n      \n      synchronized(openFiles) {\n        openFiles.remove(compoundFileName);\n      }\n    }\n    \n    synchronized(openFiles) {\n      openFiles.removeAll(perThread.flushState.flushedFiles);\n    }\n    \n    indexWriter.addNewSegment(newSegment);\n  }\n\n","sourceOld":"  // nocommit\n  void finishFlushedSegment(SegmentInfo newSegment, DocumentsWriterPerThread perThread) throws IOException {\n    synchronized(indexWriter) {\n      indexWriter.segmentInfos.add(newSegment);\n      indexWriter.checkpoint();\n    \n      SegmentReader reader = indexWriter.readerPool.get(newSegment, false);\n      boolean any = false;\n      try {\n        any = applyDeletes(reader, newSegment.getMinSequenceID(), newSegment.getMaxSequenceID(), perThread.sequenceIDs);\n      } finally {\n        indexWriter.readerPool.release(reader);\n      }\n      if (any) {\n        indexWriter.checkpoint();\n      }\n  \n      if (indexWriter.mergePolicy.useCompoundFile(indexWriter.segmentInfos, newSegment)) {\n        // Now build compound file\n        boolean success = false;\n        try {\n          createCompoundFile(newSegment.name, perThread);\n          success = true;\n        } finally {\n          if (!success) {\n            if (infoStream != null) {\n              message(\"hit exception \" +\n              \t\t\"reating compound file for newly flushed segment \" + newSegment.name);\n            }\n            indexWriter.deleter.deleteFile(IndexFileNames.segmentFileName(newSegment.name, \"\", \n                IndexFileNames.COMPOUND_FILE_EXTENSION));\n          }\n        }\n  \n        synchronized(indexWriter) {\n          newSegment.setUseCompoundFile(true);\n          indexWriter.checkpoint();\n          // In case the files we just merged into a CFS were\n          // not previously checkpointed:\n          indexWriter.deleter.deleteNewFiles(perThread.closedFiles());\n        }\n      }\n    }\n  }\n\n","bugFix":["833a7987bc1c94455fde83e3311f72bddedcfb93","8fe956d65251358d755c56f14fe8380644790e47"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8dc26bfa5ebbc55b5a04fbec545dfcec647b046b","date":1280297653,"type":3,"author":"Michael Busch","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/DocumentsWriter#finishFlushedSegment(SegmentInfo,DocumentsWriterPerThread).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/DocumentsWriter#finishFlushedSegment(SegmentInfo,DocumentsWriterPerThread).mjava","sourceNew":"  void finishFlushedSegment(SegmentInfo newSegment, DocumentsWriterPerThread perThread) throws IOException {\n    SegmentReader reader = indexWriter.readerPool.get(newSegment, false);\n    try {\n      applyDeletes(reader, newSegment.getMinSequenceID(), newSegment.getMaxSequenceID(), perThread.sequenceIDs);\n    } finally {\n      indexWriter.readerPool.release(reader);\n    }\n    \n    if (indexWriter.useCompoundFile(newSegment)) {\n      String compoundFileName = IndexFileNames.segmentFileName(newSegment.name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION);\n      message(\"creating compound file \" + compoundFileName);\n      // Now build compound file\n      boolean success = false;\n      try {\n        createCompoundFile(compoundFileName, perThread);\n        success = true;\n      } finally {\n        if (!success) {\n          if (infoStream != null) {\n            message(\"hit exception \" +\n            \t\t\"reating compound file for newly flushed segment \" + newSegment.name);\n          }\n          indexWriter.getIndexFileDeleter().deleteFile(IndexFileNames.segmentFileName(newSegment.name, \"\", \n              IndexFileNames.COMPOUND_FILE_EXTENSION));\n          for (String file : perThread.flushState.flushedFiles) {\n            indexWriter.getIndexFileDeleter().deleteFile(file);\n          }\n\n        }\n      }\n      \n      for (String file : perThread.flushState.flushedFiles) {\n        indexWriter.getIndexFileDeleter().deleteFile(file);\n      }\n\n      newSegment.setUseCompoundFile(true);\n      \n      synchronized(openFiles) {\n        openFiles.remove(compoundFileName);\n      }\n    }\n    \n    synchronized(openFiles) {\n      openFiles.removeAll(perThread.flushState.flushedFiles);\n    }\n    \n    indexWriter.addNewSegment(newSegment);\n  }\n\n","sourceOld":"  void finishFlushedSegment(SegmentInfo newSegment, DocumentsWriterPerThread perThread) throws IOException {\n    SegmentReader reader = indexWriter.readerPool.get(newSegment, false);\n    try {\n      applyDeletes(reader, newSegment.getMinSequenceID(), newSegment.getMaxSequenceID(), perThread.sequenceIDs);\n    } finally {\n      indexWriter.readerPool.release(reader);\n    }\n    \n    if (indexWriter.useCompoundFile(newSegment)) {\n      String compoundFileName = IndexFileNames.segmentFileName(newSegment.name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION);\n      message(\"creating compound file \" + compoundFileName);\n      // Now build compound file\n      boolean success = false;\n      try {\n        createCompoundFile(compoundFileName, perThread);\n        success = true;\n      } finally {\n        if (!success) {\n          if (infoStream != null) {\n            message(\"hit exception \" +\n            \t\t\"reating compound file for newly flushed segment \" + newSegment.name);\n          }\n          indexWriter.deleter.deleteFile(IndexFileNames.segmentFileName(newSegment.name, \"\", \n              IndexFileNames.COMPOUND_FILE_EXTENSION));\n          for (String file : perThread.flushState.flushedFiles) {\n            indexWriter.deleter.deleteFile(file);\n          }\n\n        }\n      }\n      \n      for (String file : perThread.flushState.flushedFiles) {\n        indexWriter.deleter.deleteFile(file);\n      }\n\n      newSegment.setUseCompoundFile(true);\n      \n      synchronized(openFiles) {\n        openFiles.remove(compoundFileName);\n      }\n    }\n    \n    synchronized(openFiles) {\n      openFiles.removeAll(perThread.flushState.flushedFiles);\n    }\n    \n    indexWriter.addNewSegment(newSegment);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","date":1292920096,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/DocumentsWriter#finishFlushedSegment(SegmentInfo,DocumentsWriterPerThread).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/DocumentsWriter#finishFlushedSegment(SegmentInfo,DocumentsWriterPerThread).mjava","sourceNew":"  void finishFlushedSegment(SegmentInfo newSegment, DocumentsWriterPerThread perThread) throws IOException {\n    perThread.pushDeletes(newSegment, indexWriter.segmentInfos);\n\n    if (indexWriter.useCompoundFile(newSegment)) {\n      String compoundFileName = IndexFileNames.segmentFileName(newSegment.name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION);\n      message(\"creating compound file \" + compoundFileName);\n      // Now build compound file\n      boolean success = false;\n      try {\n        createCompoundFile(compoundFileName, perThread);\n        success = true;\n      } finally {\n        if (!success) {\n          if (infoStream != null) {\n            message(\"hit exception \" +\n                \"reating compound file for newly flushed segment \" + newSegment.name);\n          }\n\n          indexWriter.deleter.deleteFile(IndexFileNames.segmentFileName(newSegment.name, \"\",\n              IndexFileNames.COMPOUND_FILE_EXTENSION));\n          for (String file : perThread.flushState.flushedFiles) {\n            indexWriter.deleter.deleteFile(file);\n          }\n\n        }\n      }\n\n      for (String file : perThread.flushState.flushedFiles) {\n        indexWriter.deleter.deleteFile(file);\n      }\n\n      newSegment.setUseCompoundFile(true);\n\n    }\n\n    indexWriter.addNewSegment(newSegment);\n  }\n\n","sourceOld":"  void finishFlushedSegment(SegmentInfo newSegment, DocumentsWriterPerThread perThread) throws IOException {\n    SegmentReader reader = indexWriter.readerPool.get(newSegment, false);\n    try {\n      applyDeletes(reader, newSegment.getMinSequenceID(), newSegment.getMaxSequenceID(), perThread.sequenceIDs);\n    } finally {\n      indexWriter.readerPool.release(reader);\n    }\n    \n    if (indexWriter.useCompoundFile(newSegment)) {\n      String compoundFileName = IndexFileNames.segmentFileName(newSegment.name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION);\n      message(\"creating compound file \" + compoundFileName);\n      // Now build compound file\n      boolean success = false;\n      try {\n        createCompoundFile(compoundFileName, perThread);\n        success = true;\n      } finally {\n        if (!success) {\n          if (infoStream != null) {\n            message(\"hit exception \" +\n            \t\t\"reating compound file for newly flushed segment \" + newSegment.name);\n          }\n          indexWriter.getIndexFileDeleter().deleteFile(IndexFileNames.segmentFileName(newSegment.name, \"\", \n              IndexFileNames.COMPOUND_FILE_EXTENSION));\n          for (String file : perThread.flushState.flushedFiles) {\n            indexWriter.getIndexFileDeleter().deleteFile(file);\n          }\n\n        }\n      }\n      \n      for (String file : perThread.flushState.flushedFiles) {\n        indexWriter.getIndexFileDeleter().deleteFile(file);\n      }\n\n      newSegment.setUseCompoundFile(true);\n      \n      synchronized(openFiles) {\n        openFiles.remove(compoundFileName);\n      }\n    }\n    \n    synchronized(openFiles) {\n      openFiles.removeAll(perThread.flushState.flushedFiles);\n    }\n    \n    indexWriter.addNewSegment(newSegment);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ff78505662c0b741e2663a9f38a4889c12a32c9f","date":1294908561,"type":5,"author":"Michael Busch","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/DocumentsWriter#finishFlushedSegment(SegmentInfo,Collection[String]).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/DocumentsWriter#finishFlushedSegment(SegmentInfo,DocumentsWriterPerThread).mjava","sourceNew":"  void finishFlushedSegment(SegmentInfo newSegment, Collection<String> flushedFiles) throws IOException {\n    if (indexWriter.useCompoundFile(newSegment)) {\n      String compoundFileName = IndexFileNames.segmentFileName(newSegment.name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION);\n      message(\"creating compound file \" + compoundFileName);\n      // Now build compound file\n      boolean success = false;\n      try {\n        createCompoundFile(compoundFileName, flushedFiles);\n        success = true;\n      } finally {\n        if (!success) {\n          if (infoStream != null) {\n            message(\"hit exception \" +\n                \"reating compound file for newly flushed segment \" + newSegment.name);\n          }\n\n          indexWriter.deleter.deleteFile(IndexFileNames.segmentFileName(newSegment.name, \"\",\n              IndexFileNames.COMPOUND_FILE_EXTENSION));\n          for (String file : flushedFiles) {\n            indexWriter.deleter.deleteFile(file);\n          }\n\n        }\n      }\n\n      for (String file : flushedFiles) {\n        indexWriter.deleter.deleteFile(file);\n      }\n\n      newSegment.setUseCompoundFile(true);\n\n    }\n\n    indexWriter.addNewSegment(newSegment);\n  }\n\n","sourceOld":"  void finishFlushedSegment(SegmentInfo newSegment, DocumentsWriterPerThread perThread) throws IOException {\n    perThread.pushDeletes(newSegment, indexWriter.segmentInfos);\n\n    if (indexWriter.useCompoundFile(newSegment)) {\n      String compoundFileName = IndexFileNames.segmentFileName(newSegment.name, \"\", IndexFileNames.COMPOUND_FILE_EXTENSION);\n      message(\"creating compound file \" + compoundFileName);\n      // Now build compound file\n      boolean success = false;\n      try {\n        createCompoundFile(compoundFileName, perThread);\n        success = true;\n      } finally {\n        if (!success) {\n          if (infoStream != null) {\n            message(\"hit exception \" +\n                \"reating compound file for newly flushed segment \" + newSegment.name);\n          }\n\n          indexWriter.deleter.deleteFile(IndexFileNames.segmentFileName(newSegment.name, \"\",\n              IndexFileNames.COMPOUND_FILE_EXTENSION));\n          for (String file : perThread.flushState.flushedFiles) {\n            indexWriter.deleter.deleteFile(file);\n          }\n\n        }\n      }\n\n      for (String file : perThread.flushState.flushedFiles) {\n        indexWriter.deleter.deleteFile(file);\n      }\n\n      newSegment.setUseCompoundFile(true);\n\n    }\n\n    indexWriter.addNewSegment(newSegment);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"ff78505662c0b741e2663a9f38a4889c12a32c9f":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"8fe956d65251358d755c56f14fe8380644790e47":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"5ef87af8c7bd0f8429622b83aa74202383f2e757":["833a7987bc1c94455fde83e3311f72bddedcfb93"],"334c1175813aea771a71728cd2c4ee4754fd0603":["9b832cbed6eb3d54a8bb9339296bdda8eeb53014"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":["8dc26bfa5ebbc55b5a04fbec545dfcec647b046b","334c1175813aea771a71728cd2c4ee4754fd0603"],"9b832cbed6eb3d54a8bb9339296bdda8eeb53014":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"8dc26bfa5ebbc55b5a04fbec545dfcec647b046b":["5ef87af8c7bd0f8429622b83aa74202383f2e757"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["334c1175813aea771a71728cd2c4ee4754fd0603"],"833a7987bc1c94455fde83e3311f72bddedcfb93":["8fe956d65251358d755c56f14fe8380644790e47"]},"commit2Childs":{"ff78505662c0b741e2663a9f38a4889c12a32c9f":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["8fe956d65251358d755c56f14fe8380644790e47","9b832cbed6eb3d54a8bb9339296bdda8eeb53014"],"8fe956d65251358d755c56f14fe8380644790e47":["833a7987bc1c94455fde83e3311f72bddedcfb93"],"5ef87af8c7bd0f8429622b83aa74202383f2e757":["8dc26bfa5ebbc55b5a04fbec545dfcec647b046b"],"334c1175813aea771a71728cd2c4ee4754fd0603":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":["ff78505662c0b741e2663a9f38a4889c12a32c9f"],"9b832cbed6eb3d54a8bb9339296bdda8eeb53014":["334c1175813aea771a71728cd2c4ee4754fd0603"],"8dc26bfa5ebbc55b5a04fbec545dfcec647b046b":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a"],"833a7987bc1c94455fde83e3311f72bddedcfb93":["5ef87af8c7bd0f8429622b83aa74202383f2e757"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["ff78505662c0b741e2663a9f38a4889c12a32c9f","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}