{"path":"lucene/src/java/org/apache/lucene/index/IndexWriter#setRAMBufferSizeMB(double).mjava","commits":[{"id":"9454a6510e2db155fb01faa5c049b06ece95fab9","date":1453508333,"type":1,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/IndexWriter#setRAMBufferSizeMB(double).mjava","pathOld":"src/java/org/apache/lucene/index/IndexWriter#setRAMBufferSizeMB(double).mjava","sourceNew":"  /** Determines the amount of RAM that may be used for\n   * buffering added documents and deletions before they are\n   * flushed to the Directory.  Generally for faster\n   * indexing performance it's best to flush by RAM usage\n   * instead of document count and use as large a RAM buffer\n   * as you can.\n   *\n   * <p>When this is set, the writer will flush whenever\n   * buffered documents and deletions use this much RAM.\n   * Pass in {@link #DISABLE_AUTO_FLUSH} to prevent\n   * triggering a flush due to RAM usage.  Note that if\n   * flushing by document count is also enabled, then the\n   * flush will be triggered by whichever comes first.</p>\n   *\n   * <p> <b>NOTE</b>: the account of RAM usage for pending\n   * deletions is only approximate.  Specifically, if you\n   * delete by Query, Lucene currently has no way to measure\n   * the RAM usage if individual Queries so the accounting\n   * will under-estimate and you should compensate by either\n   * calling commit() periodically yourself, or by using\n   * {@link #setMaxBufferedDeleteTerms} to flush by count\n   * instead of RAM usage (each buffered delete Query counts\n   * as one).\n   *\n   * <p> <b>NOTE</b>: because IndexWriter uses\n   * <code>int</code>s when managing its internal storage,\n   * the absolute maximum value for this setting is somewhat\n   * less than 2048 MB.  The precise limit depends on\n   * various factors, such as how large your documents are,\n   * how many fields have norms, etc., so it's best to set\n   * this value comfortably under 2048.</p>\n   *\n   * <p> The default value is {@link #DEFAULT_RAM_BUFFER_SIZE_MB}.</p>\n   * \n   * @throws IllegalArgumentException if ramBufferSize is\n   * enabled but non-positive, or it disables ramBufferSize\n   * when maxBufferedDocs is already disabled\n   * @deprecated use {@link IndexWriterConfig#setRAMBufferSizeMB(double)} instead.\n   */\n  public void setRAMBufferSizeMB(double mb) {\n    if (mb > 2048.0) {\n      throw new IllegalArgumentException(\"ramBufferSize \" + mb + \" is too large; should be comfortably less than 2048\");\n    }\n    if (mb != DISABLE_AUTO_FLUSH && mb <= 0.0)\n      throw new IllegalArgumentException(\n          \"ramBufferSize should be > 0.0 MB when enabled\");\n    if (mb == DISABLE_AUTO_FLUSH && getMaxBufferedDocs() == DISABLE_AUTO_FLUSH)\n      throw new IllegalArgumentException(\n          \"at least one of ramBufferSize and maxBufferedDocs must be enabled\");\n    docWriter.setRAMBufferSizeMB(mb);\n    if (infoStream != null)\n      message(\"setRAMBufferSizeMB \" + mb);\n    // Required so config.getSimilarity returns the right value. But this will\n    // go away together with the method in 4.0.\n    config.setRAMBufferSizeMB(mb);\n  }\n\n","sourceOld":"  /** Determines the amount of RAM that may be used for\n   * buffering added documents and deletions before they are\n   * flushed to the Directory.  Generally for faster\n   * indexing performance it's best to flush by RAM usage\n   * instead of document count and use as large a RAM buffer\n   * as you can.\n   *\n   * <p>When this is set, the writer will flush whenever\n   * buffered documents and deletions use this much RAM.\n   * Pass in {@link #DISABLE_AUTO_FLUSH} to prevent\n   * triggering a flush due to RAM usage.  Note that if\n   * flushing by document count is also enabled, then the\n   * flush will be triggered by whichever comes first.</p>\n   *\n   * <p> <b>NOTE</b>: the account of RAM usage for pending\n   * deletions is only approximate.  Specifically, if you\n   * delete by Query, Lucene currently has no way to measure\n   * the RAM usage if individual Queries so the accounting\n   * will under-estimate and you should compensate by either\n   * calling commit() periodically yourself, or by using\n   * {@link #setMaxBufferedDeleteTerms} to flush by count\n   * instead of RAM usage (each buffered delete Query counts\n   * as one).\n   *\n   * <p> <b>NOTE</b>: because IndexWriter uses\n   * <code>int</code>s when managing its internal storage,\n   * the absolute maximum value for this setting is somewhat\n   * less than 2048 MB.  The precise limit depends on\n   * various factors, such as how large your documents are,\n   * how many fields have norms, etc., so it's best to set\n   * this value comfortably under 2048.</p>\n   *\n   * <p> The default value is {@link #DEFAULT_RAM_BUFFER_SIZE_MB}.</p>\n   * \n   * @throws IllegalArgumentException if ramBufferSize is\n   * enabled but non-positive, or it disables ramBufferSize\n   * when maxBufferedDocs is already disabled\n   * @deprecated use {@link IndexWriterConfig#setRAMBufferSizeMB(double)} instead.\n   */\n  public void setRAMBufferSizeMB(double mb) {\n    if (mb > 2048.0) {\n      throw new IllegalArgumentException(\"ramBufferSize \" + mb + \" is too large; should be comfortably less than 2048\");\n    }\n    if (mb != DISABLE_AUTO_FLUSH && mb <= 0.0)\n      throw new IllegalArgumentException(\n          \"ramBufferSize should be > 0.0 MB when enabled\");\n    if (mb == DISABLE_AUTO_FLUSH && getMaxBufferedDocs() == DISABLE_AUTO_FLUSH)\n      throw new IllegalArgumentException(\n          \"at least one of ramBufferSize and maxBufferedDocs must be enabled\");\n    docWriter.setRAMBufferSizeMB(mb);\n    if (infoStream != null)\n      message(\"setRAMBufferSizeMB \" + mb);\n    // Required so config.getSimilarity returns the right value. But this will\n    // go away together with the method in 4.0.\n    config.setRAMBufferSizeMB(mb);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7ab99e8c71442b92c320e218141dee04a9b91ce8","date":1269203801,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/IndexWriter#setRAMBufferSizeMB(double).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/IndexWriter#setRAMBufferSizeMB(double).mjava","sourceNew":"  /** Determines the amount of RAM that may be used for\n   * buffering added documents and deletions before they are\n   * flushed to the Directory.  Generally for faster\n   * indexing performance it's best to flush by RAM usage\n   * instead of document count and use as large a RAM buffer\n   * as you can.\n   *\n   * <p>When this is set, the writer will flush whenever\n   * buffered documents and deletions use this much RAM.\n   * Pass in {@link #DISABLE_AUTO_FLUSH} to prevent\n   * triggering a flush due to RAM usage.  Note that if\n   * flushing by document count is also enabled, then the\n   * flush will be triggered by whichever comes first.</p>\n   *\n   * <p> <b>NOTE</b>: the account of RAM usage for pending\n   * deletions is only approximate.  Specifically, if you\n   * delete by Query, Lucene currently has no way to measure\n   * the RAM usage if individual Queries so the accounting\n   * will under-estimate and you should compensate by either\n   * calling commit() periodically yourself, or by using\n   * {@link #setMaxBufferedDeleteTerms} to flush by count\n   * instead of RAM usage (each buffered delete Query counts\n   * as one).\n   *\n   * <p> <b>NOTE</b>: because IndexWriter uses\n   * <code>int</code>s when managing its internal storage,\n   * the absolute maximum value for this setting is somewhat\n   * less than 2048 MB.  The precise limit depends on\n   * various factors, such as how large your documents are,\n   * how many fields have norms, etc., so it's best to set\n   * this value comfortably under 2048.</p>\n   *\n   * <p> The default value is {@link #DEFAULT_RAM_BUFFER_SIZE_MB}.</p>\n   * \n   * @throws IllegalArgumentException if ramBufferSize is\n   * enabled but non-positive, or it disables ramBufferSize\n   * when maxBufferedDocs is already disabled\n   * @deprecated use {@link IndexWriterConfig#setRAMBufferSizeMB(double)} instead.\n   */\n  public void setRAMBufferSizeMB(double mb) {\n    if (mb > 2048.0) {\n      throw new IllegalArgumentException(\"ramBufferSize \" + mb + \" is too large; should be comfortably less than 2048\");\n    }\n    if (mb != DISABLE_AUTO_FLUSH && mb <= 0.0)\n      throw new IllegalArgumentException(\n          \"ramBufferSize should be > 0.0 MB when enabled\");\n    if (mb == DISABLE_AUTO_FLUSH && getMaxBufferedDocs() == DISABLE_AUTO_FLUSH)\n      throw new IllegalArgumentException(\n          \"at least one of ramBufferSize and maxBufferedDocs must be enabled\");\n    docWriter.setRAMBufferSizeMB(mb);\n    if (infoStream != null)\n      message(\"setRAMBufferSizeMB \" + mb);\n    // Required so config.getRAMBufferSizeMB returns the right value. But this\n    // will go away together with the method in 4.0.\n    config.setRAMBufferSizeMB(mb);\n  }\n\n","sourceOld":"  /** Determines the amount of RAM that may be used for\n   * buffering added documents and deletions before they are\n   * flushed to the Directory.  Generally for faster\n   * indexing performance it's best to flush by RAM usage\n   * instead of document count and use as large a RAM buffer\n   * as you can.\n   *\n   * <p>When this is set, the writer will flush whenever\n   * buffered documents and deletions use this much RAM.\n   * Pass in {@link #DISABLE_AUTO_FLUSH} to prevent\n   * triggering a flush due to RAM usage.  Note that if\n   * flushing by document count is also enabled, then the\n   * flush will be triggered by whichever comes first.</p>\n   *\n   * <p> <b>NOTE</b>: the account of RAM usage for pending\n   * deletions is only approximate.  Specifically, if you\n   * delete by Query, Lucene currently has no way to measure\n   * the RAM usage if individual Queries so the accounting\n   * will under-estimate and you should compensate by either\n   * calling commit() periodically yourself, or by using\n   * {@link #setMaxBufferedDeleteTerms} to flush by count\n   * instead of RAM usage (each buffered delete Query counts\n   * as one).\n   *\n   * <p> <b>NOTE</b>: because IndexWriter uses\n   * <code>int</code>s when managing its internal storage,\n   * the absolute maximum value for this setting is somewhat\n   * less than 2048 MB.  The precise limit depends on\n   * various factors, such as how large your documents are,\n   * how many fields have norms, etc., so it's best to set\n   * this value comfortably under 2048.</p>\n   *\n   * <p> The default value is {@link #DEFAULT_RAM_BUFFER_SIZE_MB}.</p>\n   * \n   * @throws IllegalArgumentException if ramBufferSize is\n   * enabled but non-positive, or it disables ramBufferSize\n   * when maxBufferedDocs is already disabled\n   * @deprecated use {@link IndexWriterConfig#setRAMBufferSizeMB(double)} instead.\n   */\n  public void setRAMBufferSizeMB(double mb) {\n    if (mb > 2048.0) {\n      throw new IllegalArgumentException(\"ramBufferSize \" + mb + \" is too large; should be comfortably less than 2048\");\n    }\n    if (mb != DISABLE_AUTO_FLUSH && mb <= 0.0)\n      throw new IllegalArgumentException(\n          \"ramBufferSize should be > 0.0 MB when enabled\");\n    if (mb == DISABLE_AUTO_FLUSH && getMaxBufferedDocs() == DISABLE_AUTO_FLUSH)\n      throw new IllegalArgumentException(\n          \"at least one of ramBufferSize and maxBufferedDocs must be enabled\");\n    docWriter.setRAMBufferSizeMB(mb);\n    if (infoStream != null)\n      message(\"setRAMBufferSizeMB \" + mb);\n    // Required so config.getSimilarity returns the right value. But this will\n    // go away together with the method in 4.0.\n    config.setRAMBufferSizeMB(mb);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"068265517d1fbc623f5aeaee57fcd8df925678e4","date":1286043654,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/IndexWriter#setRAMBufferSizeMB(double).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/IndexWriter#setRAMBufferSizeMB(double).mjava","sourceNew":"  /** Determines the amount of RAM that may be used for\n   * buffering added documents and deletions before they are\n   * flushed to the Directory.  Generally for faster\n   * indexing performance it's best to flush by RAM usage\n   * instead of document count and use as large a RAM buffer\n   * as you can.\n   *\n   * <p>When this is set, the writer will flush whenever\n   * buffered documents and deletions use this much RAM.\n   * Pass in {@link #DISABLE_AUTO_FLUSH} to prevent\n   * triggering a flush due to RAM usage.  Note that if\n   * flushing by document count is also enabled, then the\n   * flush will be triggered by whichever comes first.</p>\n   *\n   * <p> <b>NOTE</b>: the account of RAM usage for pending\n   * deletions is only approximate.  Specifically, if you\n   * delete by Query, Lucene currently has no way to measure\n   * the RAM usage if individual Queries so the accounting\n   * will under-estimate and you should compensate by either\n   * calling commit() periodically yourself, or by using\n   * {@link #setMaxBufferedDeleteTerms} to flush by count\n   * instead of RAM usage (each buffered delete Query counts\n   * as one).\n   *\n   * <p> <b>NOTE</b>: because IndexWriter uses\n   * <code>int</code>s when managing its internal storage,\n   * the absolute maximum value for this setting is somewhat\n   * less than 2048 MB.  The precise limit depends on\n   * various factors, such as how large your documents are,\n   * how many fields have norms, etc., so it's best to set\n   * this value comfortably under 2048.</p>\n   *\n   * <p> The default value is {@link #DEFAULT_RAM_BUFFER_SIZE_MB}.</p>\n   * \n   * @throws IllegalArgumentException if ramBufferSize is\n   * enabled but non-positive, or it disables ramBufferSize\n   * when maxBufferedDocs is already disabled\n   * @deprecated use {@link IndexWriterConfig#setRAMBufferSizeMB(double)} instead.\n   */\n  @Deprecated\n  public void setRAMBufferSizeMB(double mb) {\n    if (mb > 2048.0) {\n      throw new IllegalArgumentException(\"ramBufferSize \" + mb + \" is too large; should be comfortably less than 2048\");\n    }\n    if (mb != DISABLE_AUTO_FLUSH && mb <= 0.0)\n      throw new IllegalArgumentException(\n          \"ramBufferSize should be > 0.0 MB when enabled\");\n    if (mb == DISABLE_AUTO_FLUSH && getMaxBufferedDocs() == DISABLE_AUTO_FLUSH)\n      throw new IllegalArgumentException(\n          \"at least one of ramBufferSize and maxBufferedDocs must be enabled\");\n    docWriter.setRAMBufferSizeMB(mb);\n    if (infoStream != null)\n      message(\"setRAMBufferSizeMB \" + mb);\n    // Required so config.getRAMBufferSizeMB returns the right value. But this\n    // will go away together with the method in 4.0.\n    config.setRAMBufferSizeMB(mb);\n  }\n\n","sourceOld":"  /** Determines the amount of RAM that may be used for\n   * buffering added documents and deletions before they are\n   * flushed to the Directory.  Generally for faster\n   * indexing performance it's best to flush by RAM usage\n   * instead of document count and use as large a RAM buffer\n   * as you can.\n   *\n   * <p>When this is set, the writer will flush whenever\n   * buffered documents and deletions use this much RAM.\n   * Pass in {@link #DISABLE_AUTO_FLUSH} to prevent\n   * triggering a flush due to RAM usage.  Note that if\n   * flushing by document count is also enabled, then the\n   * flush will be triggered by whichever comes first.</p>\n   *\n   * <p> <b>NOTE</b>: the account of RAM usage for pending\n   * deletions is only approximate.  Specifically, if you\n   * delete by Query, Lucene currently has no way to measure\n   * the RAM usage if individual Queries so the accounting\n   * will under-estimate and you should compensate by either\n   * calling commit() periodically yourself, or by using\n   * {@link #setMaxBufferedDeleteTerms} to flush by count\n   * instead of RAM usage (each buffered delete Query counts\n   * as one).\n   *\n   * <p> <b>NOTE</b>: because IndexWriter uses\n   * <code>int</code>s when managing its internal storage,\n   * the absolute maximum value for this setting is somewhat\n   * less than 2048 MB.  The precise limit depends on\n   * various factors, such as how large your documents are,\n   * how many fields have norms, etc., so it's best to set\n   * this value comfortably under 2048.</p>\n   *\n   * <p> The default value is {@link #DEFAULT_RAM_BUFFER_SIZE_MB}.</p>\n   * \n   * @throws IllegalArgumentException if ramBufferSize is\n   * enabled but non-positive, or it disables ramBufferSize\n   * when maxBufferedDocs is already disabled\n   * @deprecated use {@link IndexWriterConfig#setRAMBufferSizeMB(double)} instead.\n   */\n  public void setRAMBufferSizeMB(double mb) {\n    if (mb > 2048.0) {\n      throw new IllegalArgumentException(\"ramBufferSize \" + mb + \" is too large; should be comfortably less than 2048\");\n    }\n    if (mb != DISABLE_AUTO_FLUSH && mb <= 0.0)\n      throw new IllegalArgumentException(\n          \"ramBufferSize should be > 0.0 MB when enabled\");\n    if (mb == DISABLE_AUTO_FLUSH && getMaxBufferedDocs() == DISABLE_AUTO_FLUSH)\n      throw new IllegalArgumentException(\n          \"at least one of ramBufferSize and maxBufferedDocs must be enabled\");\n    docWriter.setRAMBufferSizeMB(mb);\n    if (infoStream != null)\n      message(\"setRAMBufferSizeMB \" + mb);\n    // Required so config.getRAMBufferSizeMB returns the right value. But this\n    // will go away together with the method in 4.0.\n    config.setRAMBufferSizeMB(mb);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4e8cc373c801e54cec75daf9f52792cb4b17f536","date":1291116159,"type":4,"author":"Robert Muir","isMerge":false,"pathNew":"/dev/null","pathOld":"lucene/src/java/org/apache/lucene/index/IndexWriter#setRAMBufferSizeMB(double).mjava","sourceNew":null,"sourceOld":"  /** Determines the amount of RAM that may be used for\n   * buffering added documents and deletions before they are\n   * flushed to the Directory.  Generally for faster\n   * indexing performance it's best to flush by RAM usage\n   * instead of document count and use as large a RAM buffer\n   * as you can.\n   *\n   * <p>When this is set, the writer will flush whenever\n   * buffered documents and deletions use this much RAM.\n   * Pass in {@link #DISABLE_AUTO_FLUSH} to prevent\n   * triggering a flush due to RAM usage.  Note that if\n   * flushing by document count is also enabled, then the\n   * flush will be triggered by whichever comes first.</p>\n   *\n   * <p> <b>NOTE</b>: the account of RAM usage for pending\n   * deletions is only approximate.  Specifically, if you\n   * delete by Query, Lucene currently has no way to measure\n   * the RAM usage if individual Queries so the accounting\n   * will under-estimate and you should compensate by either\n   * calling commit() periodically yourself, or by using\n   * {@link #setMaxBufferedDeleteTerms} to flush by count\n   * instead of RAM usage (each buffered delete Query counts\n   * as one).\n   *\n   * <p> <b>NOTE</b>: because IndexWriter uses\n   * <code>int</code>s when managing its internal storage,\n   * the absolute maximum value for this setting is somewhat\n   * less than 2048 MB.  The precise limit depends on\n   * various factors, such as how large your documents are,\n   * how many fields have norms, etc., so it's best to set\n   * this value comfortably under 2048.</p>\n   *\n   * <p> The default value is {@link #DEFAULT_RAM_BUFFER_SIZE_MB}.</p>\n   * \n   * @throws IllegalArgumentException if ramBufferSize is\n   * enabled but non-positive, or it disables ramBufferSize\n   * when maxBufferedDocs is already disabled\n   * @deprecated use {@link IndexWriterConfig#setRAMBufferSizeMB(double)} instead.\n   */\n  @Deprecated\n  public void setRAMBufferSizeMB(double mb) {\n    if (mb > 2048.0) {\n      throw new IllegalArgumentException(\"ramBufferSize \" + mb + \" is too large; should be comfortably less than 2048\");\n    }\n    if (mb != DISABLE_AUTO_FLUSH && mb <= 0.0)\n      throw new IllegalArgumentException(\n          \"ramBufferSize should be > 0.0 MB when enabled\");\n    if (mb == DISABLE_AUTO_FLUSH && getMaxBufferedDocs() == DISABLE_AUTO_FLUSH)\n      throw new IllegalArgumentException(\n          \"at least one of ramBufferSize and maxBufferedDocs must be enabled\");\n    docWriter.setRAMBufferSizeMB(mb);\n    if (infoStream != null)\n      message(\"setRAMBufferSizeMB \" + mb);\n    // Required so config.getRAMBufferSizeMB returns the right value. But this\n    // will go away together with the method in 4.0.\n    config.setRAMBufferSizeMB(mb);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3bb13258feba31ab676502787ab2e1779f129b7a","date":1291596436,"type":4,"author":"Simon Willnauer","isMerge":true,"pathNew":"/dev/null","pathOld":"lucene/src/java/org/apache/lucene/index/IndexWriter#setRAMBufferSizeMB(double).mjava","sourceNew":null,"sourceOld":"  /** Determines the amount of RAM that may be used for\n   * buffering added documents and deletions before they are\n   * flushed to the Directory.  Generally for faster\n   * indexing performance it's best to flush by RAM usage\n   * instead of document count and use as large a RAM buffer\n   * as you can.\n   *\n   * <p>When this is set, the writer will flush whenever\n   * buffered documents and deletions use this much RAM.\n   * Pass in {@link #DISABLE_AUTO_FLUSH} to prevent\n   * triggering a flush due to RAM usage.  Note that if\n   * flushing by document count is also enabled, then the\n   * flush will be triggered by whichever comes first.</p>\n   *\n   * <p> <b>NOTE</b>: the account of RAM usage for pending\n   * deletions is only approximate.  Specifically, if you\n   * delete by Query, Lucene currently has no way to measure\n   * the RAM usage if individual Queries so the accounting\n   * will under-estimate and you should compensate by either\n   * calling commit() periodically yourself, or by using\n   * {@link #setMaxBufferedDeleteTerms} to flush by count\n   * instead of RAM usage (each buffered delete Query counts\n   * as one).\n   *\n   * <p> <b>NOTE</b>: because IndexWriter uses\n   * <code>int</code>s when managing its internal storage,\n   * the absolute maximum value for this setting is somewhat\n   * less than 2048 MB.  The precise limit depends on\n   * various factors, such as how large your documents are,\n   * how many fields have norms, etc., so it's best to set\n   * this value comfortably under 2048.</p>\n   *\n   * <p> The default value is {@link #DEFAULT_RAM_BUFFER_SIZE_MB}.</p>\n   * \n   * @throws IllegalArgumentException if ramBufferSize is\n   * enabled but non-positive, or it disables ramBufferSize\n   * when maxBufferedDocs is already disabled\n   * @deprecated use {@link IndexWriterConfig#setRAMBufferSizeMB(double)} instead.\n   */\n  @Deprecated\n  public void setRAMBufferSizeMB(double mb) {\n    if (mb > 2048.0) {\n      throw new IllegalArgumentException(\"ramBufferSize \" + mb + \" is too large; should be comfortably less than 2048\");\n    }\n    if (mb != DISABLE_AUTO_FLUSH && mb <= 0.0)\n      throw new IllegalArgumentException(\n          \"ramBufferSize should be > 0.0 MB when enabled\");\n    if (mb == DISABLE_AUTO_FLUSH && getMaxBufferedDocs() == DISABLE_AUTO_FLUSH)\n      throw new IllegalArgumentException(\n          \"at least one of ramBufferSize and maxBufferedDocs must be enabled\");\n    docWriter.setRAMBufferSizeMB(mb);\n    if (infoStream != null)\n      message(\"setRAMBufferSizeMB \" + mb);\n    // Required so config.getRAMBufferSizeMB returns the right value. But this\n    // will go away together with the method in 4.0.\n    config.setRAMBufferSizeMB(mb);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","date":1292920096,"type":4,"author":"Michael Busch","isMerge":true,"pathNew":"/dev/null","pathOld":"lucene/src/java/org/apache/lucene/index/IndexWriter#setRAMBufferSizeMB(double).mjava","sourceNew":null,"sourceOld":"  /** Determines the amount of RAM that may be used for\n   * buffering added documents and deletions before they are\n   * flushed to the Directory.  Generally for faster\n   * indexing performance it's best to flush by RAM usage\n   * instead of document count and use as large a RAM buffer\n   * as you can.\n   *\n   * <p>When this is set, the writer will flush whenever\n   * buffered documents and deletions use this much RAM.\n   * Pass in {@link #DISABLE_AUTO_FLUSH} to prevent\n   * triggering a flush due to RAM usage.  Note that if\n   * flushing by document count is also enabled, then the\n   * flush will be triggered by whichever comes first.</p>\n   *\n   * <p> <b>NOTE</b>: the account of RAM usage for pending\n   * deletions is only approximate.  Specifically, if you\n   * delete by Query, Lucene currently has no way to measure\n   * the RAM usage if individual Queries so the accounting\n   * will under-estimate and you should compensate by either\n   * calling commit() periodically yourself, or by using\n   * {@link #setMaxBufferedDeleteTerms} to flush by count\n   * instead of RAM usage (each buffered delete Query counts\n   * as one).\n   *\n   * <p> <b>NOTE</b>: because IndexWriter uses\n   * <code>int</code>s when managing its internal storage,\n   * the absolute maximum value for this setting is somewhat\n   * less than 2048 MB.  The precise limit depends on\n   * various factors, such as how large your documents are,\n   * how many fields have norms, etc., so it's best to set\n   * this value comfortably under 2048.</p>\n   *\n   * <p> The default value is {@link #DEFAULT_RAM_BUFFER_SIZE_MB}.</p>\n   * \n   * @throws IllegalArgumentException if ramBufferSize is\n   * enabled but non-positive, or it disables ramBufferSize\n   * when maxBufferedDocs is already disabled\n   * @deprecated use {@link IndexWriterConfig#setRAMBufferSizeMB(double)} instead.\n   */\n  public void setRAMBufferSizeMB(double mb) {\n    if (mb > 2048.0) {\n      throw new IllegalArgumentException(\"ramBufferSize \" + mb + \" is too large; should be comfortably less than 2048\");\n    }\n    if (mb != DISABLE_AUTO_FLUSH && mb <= 0.0)\n      throw new IllegalArgumentException(\n          \"ramBufferSize should be > 0.0 MB when enabled\");\n    if (mb == DISABLE_AUTO_FLUSH && getMaxBufferedDocs() == DISABLE_AUTO_FLUSH)\n      throw new IllegalArgumentException(\n          \"at least one of ramBufferSize and maxBufferedDocs must be enabled\");\n    docWriter.setRAMBufferSizeMB(mb);\n    if (infoStream != null)\n      message(\"setRAMBufferSizeMB \" + mb);\n    // Required so config.getRAMBufferSizeMB returns the right value. But this\n    // will go away together with the method in 4.0.\n    config.setRAMBufferSizeMB(mb);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"7ab99e8c71442b92c320e218141dee04a9b91ce8":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"068265517d1fbc623f5aeaee57fcd8df925678e4":["7ab99e8c71442b92c320e218141dee04a9b91ce8"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":["7ab99e8c71442b92c320e218141dee04a9b91ce8","4e8cc373c801e54cec75daf9f52792cb4b17f536"],"3bb13258feba31ab676502787ab2e1779f129b7a":["068265517d1fbc623f5aeaee57fcd8df925678e4","4e8cc373c801e54cec75daf9f52792cb4b17f536"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["4e8cc373c801e54cec75daf9f52792cb4b17f536"],"4e8cc373c801e54cec75daf9f52792cb4b17f536":["068265517d1fbc623f5aeaee57fcd8df925678e4"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"7ab99e8c71442b92c320e218141dee04a9b91ce8":["068265517d1fbc623f5aeaee57fcd8df925678e4","7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a"],"068265517d1fbc623f5aeaee57fcd8df925678e4":["3bb13258feba31ab676502787ab2e1779f129b7a","4e8cc373c801e54cec75daf9f52792cb4b17f536"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":[],"3bb13258feba31ab676502787ab2e1779f129b7a":[],"9454a6510e2db155fb01faa5c049b06ece95fab9":["7ab99e8c71442b92c320e218141dee04a9b91ce8"],"4e8cc373c801e54cec75daf9f52792cb4b17f536":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","3bb13258feba31ab676502787ab2e1779f129b7a","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","3bb13258feba31ab676502787ab2e1779f129b7a","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}