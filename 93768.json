{"path":"lucene/src/java/org/apache/lucene/index/IndexWriter#optimize().mjava","commits":[{"id":"9454a6510e2db155fb01faa5c049b06ece95fab9","date":1453508333,"type":1,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/IndexWriter#optimize().mjava","pathOld":"src/java/org/apache/lucene/index/IndexWriter#optimize().mjava","sourceNew":"  /**\n   * Requests an \"optimize\" operation on an index, priming the index\n   * for the fastest available search. Traditionally this has meant\n   * merging all segments into a single segment as is done in the\n   * default merge policy, but individual merge policies may implement\n   * optimize in different ways.\n   *\n   * <p> Optimize is a fairly costly operation, so you\n   * should only do it if your search performance really\n   * requires it.  Many search applications do fine never\n   * calling optimize. </p>\n   *\n   * <p>Note that optimize requires 2X the index size free\n   * space in your Directory.  For example, if your index\n   * size is 10 MB then you need 20 MB free for optimize to\n   * complete.  Also, it's best to call {@link #commit()}\n   * after the optimize completes to allow IndexWriter to\n   * free up disk space.</p>\n   *\n   * <p>If some but not all readers re-open while an\n   * optimize is underway, this will cause > 2X temporary\n   * space to be consumed as those new readers will then\n   * hold open the partially optimized segments at that\n   * time.  It is best not to re-open readers while optimize\n   * is running.</p>\n   *\n   * <p>The actual temporary usage could be much less than\n   * these figures (it depends on many factors).</p>\n   *\n   * <p>In general, once the optimize completes, the total size of the\n   * index will be less than the size of the starting index.\n   * It could be quite a bit smaller (if there were many\n   * pending deletes) or just slightly smaller.</p>\n   *\n   * <p>If an Exception is hit during optimize(), for example\n   * due to disk full, the index will not be corrupt and no\n   * documents will have been lost.  However, it may have\n   * been partially optimized (some segments were merged but\n   * not all), and it's possible that one of the segments in\n   * the index will be in non-compound format even when\n   * using compound file format.  This will occur when the\n   * Exception is hit during conversion of the segment into\n   * compound format.</p>\n   *\n   * <p>This call will optimize those segments present in\n   * the index when the call started.  If other threads are\n   * still adding documents and flushing segments, those\n   * newly created segments will not be optimized unless you\n   * call optimize again.</p>\n   *\n   * <p><b>NOTE</b>: if this method hits an OutOfMemoryError\n   * you should immediately close the writer.  See <a\n   * href=\"#OOME\">above</a> for details.</p>\n   *\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   * @see LogMergePolicy#findMergesForOptimize\n  */\n  public void optimize() throws CorruptIndexException, IOException {\n    optimize(true);\n  }\n\n","sourceOld":"  /**\n   * Requests an \"optimize\" operation on an index, priming the index\n   * for the fastest available search. Traditionally this has meant\n   * merging all segments into a single segment as is done in the\n   * default merge policy, but individual merge policies may implement\n   * optimize in different ways.\n   *\n   * <p> Optimize is a fairly costly operation, so you\n   * should only do it if your search performance really\n   * requires it.  Many search applications do fine never\n   * calling optimize. </p>\n   *\n   * <p>Note that optimize requires 2X the index size free\n   * space in your Directory.  For example, if your index\n   * size is 10 MB then you need 20 MB free for optimize to\n   * complete.  Also, it's best to call {@link #commit()}\n   * after the optimize completes to allow IndexWriter to\n   * free up disk space.</p>\n   *\n   * <p>If some but not all readers re-open while an\n   * optimize is underway, this will cause > 2X temporary\n   * space to be consumed as those new readers will then\n   * hold open the partially optimized segments at that\n   * time.  It is best not to re-open readers while optimize\n   * is running.</p>\n   *\n   * <p>The actual temporary usage could be much less than\n   * these figures (it depends on many factors).</p>\n   *\n   * <p>In general, once the optimize completes, the total size of the\n   * index will be less than the size of the starting index.\n   * It could be quite a bit smaller (if there were many\n   * pending deletes) or just slightly smaller.</p>\n   *\n   * <p>If an Exception is hit during optimize(), for example\n   * due to disk full, the index will not be corrupt and no\n   * documents will have been lost.  However, it may have\n   * been partially optimized (some segments were merged but\n   * not all), and it's possible that one of the segments in\n   * the index will be in non-compound format even when\n   * using compound file format.  This will occur when the\n   * Exception is hit during conversion of the segment into\n   * compound format.</p>\n   *\n   * <p>This call will optimize those segments present in\n   * the index when the call started.  If other threads are\n   * still adding documents and flushing segments, those\n   * newly created segments will not be optimized unless you\n   * call optimize again.</p>\n   *\n   * <p><b>NOTE</b>: if this method hits an OutOfMemoryError\n   * you should immediately close the writer.  See <a\n   * href=\"#OOME\">above</a> for details.</p>\n   *\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   * @see LogMergePolicy#findMergesForOptimize\n  */\n  public void optimize() throws CorruptIndexException, IOException {\n    optimize(true);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8cac9bbcf5acbef2d0d83f6e9e32a22d71301db5","date":1290247889,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/IndexWriter#optimize().mjava","pathOld":"lucene/src/java/org/apache/lucene/index/IndexWriter#optimize().mjava","sourceNew":"  /**\n   * Requests an \"optimize\" operation on an index, priming the index\n   * for the fastest available search. Traditionally this has meant\n   * merging all segments into a single segment as is done in the\n   * default merge policy, but individual merge policies may implement\n   * optimize in different ways.\n   *\n   * <p> Optimize is a fairly costly operation, so you\n   * should only do it if your search performance really\n   * requires it.  Many search applications do fine never\n   * calling optimize. </p>\n   *\n   * <p>Note that optimize requires 2X the index size free\n   * space in your Directory (3X if you're using compound\n   * file format).  For example, if your index size is 10 MB\n   * then you need 20 MB free for optimize to complete (30\n   * MB if you're using compound file format).  Also,\n   * it's best to call {@link #commit()} after the optimize\n   * completes to allow IndexWriter to free up disk space.</p>\n   *\n   * <p>If some but not all readers re-open while an\n   * optimize is underway, this will cause > 2X temporary\n   * space to be consumed as those new readers will then\n   * hold open the partially optimized segments at that\n   * time.  It is best not to re-open readers while optimize\n   * is running.</p>\n   *\n   * <p>The actual temporary usage could be much less than\n   * these figures (it depends on many factors).</p>\n   *\n   * <p>In general, once the optimize completes, the total size of the\n   * index will be less than the size of the starting index.\n   * It could be quite a bit smaller (if there were many\n   * pending deletes) or just slightly smaller.</p>\n   *\n   * <p>If an Exception is hit during optimize(), for example\n   * due to disk full, the index will not be corrupt and no\n   * documents will have been lost.  However, it may have\n   * been partially optimized (some segments were merged but\n   * not all), and it's possible that one of the segments in\n   * the index will be in non-compound format even when\n   * using compound file format.  This will occur when the\n   * Exception is hit during conversion of the segment into\n   * compound format.</p>\n   *\n   * <p>This call will optimize those segments present in\n   * the index when the call started.  If other threads are\n   * still adding documents and flushing segments, those\n   * newly created segments will not be optimized unless you\n   * call optimize again.</p>\n   *\n   * <p><b>NOTE</b>: if this method hits an OutOfMemoryError\n   * you should immediately close the writer.  See <a\n   * href=\"#OOME\">above</a> for details.</p>\n   *\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   * @see LogMergePolicy#findMergesForOptimize\n  */\n  public void optimize() throws CorruptIndexException, IOException {\n    optimize(true);\n  }\n\n","sourceOld":"  /**\n   * Requests an \"optimize\" operation on an index, priming the index\n   * for the fastest available search. Traditionally this has meant\n   * merging all segments into a single segment as is done in the\n   * default merge policy, but individual merge policies may implement\n   * optimize in different ways.\n   *\n   * <p> Optimize is a fairly costly operation, so you\n   * should only do it if your search performance really\n   * requires it.  Many search applications do fine never\n   * calling optimize. </p>\n   *\n   * <p>Note that optimize requires 2X the index size free\n   * space in your Directory.  For example, if your index\n   * size is 10 MB then you need 20 MB free for optimize to\n   * complete.  Also, it's best to call {@link #commit()}\n   * after the optimize completes to allow IndexWriter to\n   * free up disk space.</p>\n   *\n   * <p>If some but not all readers re-open while an\n   * optimize is underway, this will cause > 2X temporary\n   * space to be consumed as those new readers will then\n   * hold open the partially optimized segments at that\n   * time.  It is best not to re-open readers while optimize\n   * is running.</p>\n   *\n   * <p>The actual temporary usage could be much less than\n   * these figures (it depends on many factors).</p>\n   *\n   * <p>In general, once the optimize completes, the total size of the\n   * index will be less than the size of the starting index.\n   * It could be quite a bit smaller (if there were many\n   * pending deletes) or just slightly smaller.</p>\n   *\n   * <p>If an Exception is hit during optimize(), for example\n   * due to disk full, the index will not be corrupt and no\n   * documents will have been lost.  However, it may have\n   * been partially optimized (some segments were merged but\n   * not all), and it's possible that one of the segments in\n   * the index will be in non-compound format even when\n   * using compound file format.  This will occur when the\n   * Exception is hit during conversion of the segment into\n   * compound format.</p>\n   *\n   * <p>This call will optimize those segments present in\n   * the index when the call started.  If other threads are\n   * still adding documents and flushing segments, those\n   * newly created segments will not be optimized unless you\n   * call optimize again.</p>\n   *\n   * <p><b>NOTE</b>: if this method hits an OutOfMemoryError\n   * you should immediately close the writer.  See <a\n   * href=\"#OOME\">above</a> for details.</p>\n   *\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   * @see LogMergePolicy#findMergesForOptimize\n  */\n  public void optimize() throws CorruptIndexException, IOException {\n    optimize(true);\n  }\n\n","bugFix":["80681cc9c3774bc4805a346bee03516e133f9bdd","b1910b847659c345749ba264675088e32b5ab9a2"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"38a62612cfa4e104080d89d7751a8f1a258ac335","date":1291442315,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/IndexWriter#optimize().mjava","pathOld":"lucene/src/java/org/apache/lucene/index/IndexWriter#optimize().mjava","sourceNew":"  /**\n   * Requests an \"optimize\" operation on an index, priming the index\n   * for the fastest available search. Traditionally this has meant\n   * merging all segments into a single segment as is done in the\n   * default merge policy, but individual merge policies may implement\n   * optimize in different ways.\n   *\n   * <p> Optimize is a fairly costly operation, so you\n   * should only do it if your search performance really\n   * requires it.  Many search applications do fine never\n   * calling optimize. </p>\n   *\n   * <p>Note that optimize requires 2X the index size free\n   * space in your Directory (3X if you're using compound\n   * file format).  For example, if your index size is 10 MB\n   * then you need 20 MB free for optimize to complete (30\n   * MB if you're using compound file format).  Also,\n   * it's best to call {@link #commit()} after the optimize\n   * completes to allow IndexWriter to free up disk space.</p>\n   *\n   * <p>If some but not all readers re-open while an\n   * optimize is underway, this will cause > 2X temporary\n   * space to be consumed as those new readers will then\n   * hold open the partially optimized segments at that\n   * time.  It is best not to re-open readers while optimize\n   * is running.</p>\n   *\n   * <p>The actual temporary usage could be much less than\n   * these figures (it depends on many factors).</p>\n   *\n   * <p>In general, once the optimize completes, the total size of the\n   * index will be less than the size of the starting index.\n   * It could be quite a bit smaller (if there were many\n   * pending deletes) or just slightly smaller.</p>\n   *\n   * <p>If an Exception is hit during optimize(), for example\n   * due to disk full, the index will not be corrupt and no\n   * documents will have been lost.  However, it may have\n   * been partially optimized (some segments were merged but\n   * not all), and it's possible that one of the segments in\n   * the index will be in non-compound format even when\n   * using compound file format.  This will occur when the\n   * Exception is hit during conversion of the segment into\n   * compound format.</p>\n   *\n   * <p>This call will optimize those segments present in\n   * the index when the call started.  If other threads are\n   * still adding documents and flushing segments, those\n   * newly created segments will not be optimized unless you\n   * call optimize again.</p>\n   *\n   * <p><b>NOTE</b>: if this method hits an OutOfMemoryError\n   * you should immediately close the writer.  See <a\n   * href=\"#OOME\">above</a> for details.</p>\n   *\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   * @see MergePolicy#findMergesForOptimize\n  */\n  public void optimize() throws CorruptIndexException, IOException {\n    optimize(true);\n  }\n\n","sourceOld":"  /**\n   * Requests an \"optimize\" operation on an index, priming the index\n   * for the fastest available search. Traditionally this has meant\n   * merging all segments into a single segment as is done in the\n   * default merge policy, but individual merge policies may implement\n   * optimize in different ways.\n   *\n   * <p> Optimize is a fairly costly operation, so you\n   * should only do it if your search performance really\n   * requires it.  Many search applications do fine never\n   * calling optimize. </p>\n   *\n   * <p>Note that optimize requires 2X the index size free\n   * space in your Directory (3X if you're using compound\n   * file format).  For example, if your index size is 10 MB\n   * then you need 20 MB free for optimize to complete (30\n   * MB if you're using compound file format).  Also,\n   * it's best to call {@link #commit()} after the optimize\n   * completes to allow IndexWriter to free up disk space.</p>\n   *\n   * <p>If some but not all readers re-open while an\n   * optimize is underway, this will cause > 2X temporary\n   * space to be consumed as those new readers will then\n   * hold open the partially optimized segments at that\n   * time.  It is best not to re-open readers while optimize\n   * is running.</p>\n   *\n   * <p>The actual temporary usage could be much less than\n   * these figures (it depends on many factors).</p>\n   *\n   * <p>In general, once the optimize completes, the total size of the\n   * index will be less than the size of the starting index.\n   * It could be quite a bit smaller (if there were many\n   * pending deletes) or just slightly smaller.</p>\n   *\n   * <p>If an Exception is hit during optimize(), for example\n   * due to disk full, the index will not be corrupt and no\n   * documents will have been lost.  However, it may have\n   * been partially optimized (some segments were merged but\n   * not all), and it's possible that one of the segments in\n   * the index will be in non-compound format even when\n   * using compound file format.  This will occur when the\n   * Exception is hit during conversion of the segment into\n   * compound format.</p>\n   *\n   * <p>This call will optimize those segments present in\n   * the index when the call started.  If other threads are\n   * still adding documents and flushing segments, those\n   * newly created segments will not be optimized unless you\n   * call optimize again.</p>\n   *\n   * <p><b>NOTE</b>: if this method hits an OutOfMemoryError\n   * you should immediately close the writer.  See <a\n   * href=\"#OOME\">above</a> for details.</p>\n   *\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   * @see LogMergePolicy#findMergesForOptimize\n  */\n  public void optimize() throws CorruptIndexException, IOException {\n    optimize(true);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3bb13258feba31ab676502787ab2e1779f129b7a","date":1291596436,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/IndexWriter#optimize().mjava","pathOld":"lucene/src/java/org/apache/lucene/index/IndexWriter#optimize().mjava","sourceNew":"  /**\n   * Requests an \"optimize\" operation on an index, priming the index\n   * for the fastest available search. Traditionally this has meant\n   * merging all segments into a single segment as is done in the\n   * default merge policy, but individual merge policies may implement\n   * optimize in different ways.\n   *\n   * <p> Optimize is a fairly costly operation, so you\n   * should only do it if your search performance really\n   * requires it.  Many search applications do fine never\n   * calling optimize. </p>\n   *\n   * <p>Note that optimize requires 2X the index size free\n   * space in your Directory (3X if you're using compound\n   * file format).  For example, if your index size is 10 MB\n   * then you need 20 MB free for optimize to complete (30\n   * MB if you're using compound file format).  Also,\n   * it's best to call {@link #commit()} after the optimize\n   * completes to allow IndexWriter to free up disk space.</p>\n   *\n   * <p>If some but not all readers re-open while an\n   * optimize is underway, this will cause > 2X temporary\n   * space to be consumed as those new readers will then\n   * hold open the partially optimized segments at that\n   * time.  It is best not to re-open readers while optimize\n   * is running.</p>\n   *\n   * <p>The actual temporary usage could be much less than\n   * these figures (it depends on many factors).</p>\n   *\n   * <p>In general, once the optimize completes, the total size of the\n   * index will be less than the size of the starting index.\n   * It could be quite a bit smaller (if there were many\n   * pending deletes) or just slightly smaller.</p>\n   *\n   * <p>If an Exception is hit during optimize(), for example\n   * due to disk full, the index will not be corrupt and no\n   * documents will have been lost.  However, it may have\n   * been partially optimized (some segments were merged but\n   * not all), and it's possible that one of the segments in\n   * the index will be in non-compound format even when\n   * using compound file format.  This will occur when the\n   * Exception is hit during conversion of the segment into\n   * compound format.</p>\n   *\n   * <p>This call will optimize those segments present in\n   * the index when the call started.  If other threads are\n   * still adding documents and flushing segments, those\n   * newly created segments will not be optimized unless you\n   * call optimize again.</p>\n   *\n   * <p><b>NOTE</b>: if this method hits an OutOfMemoryError\n   * you should immediately close the writer.  See <a\n   * href=\"#OOME\">above</a> for details.</p>\n   *\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   * @see LogMergePolicy#findMergesForOptimize\n  */\n  public void optimize() throws CorruptIndexException, IOException {\n    optimize(true);\n  }\n\n","sourceOld":"  /**\n   * Requests an \"optimize\" operation on an index, priming the index\n   * for the fastest available search. Traditionally this has meant\n   * merging all segments into a single segment as is done in the\n   * default merge policy, but individual merge policies may implement\n   * optimize in different ways.\n   *\n   * <p> Optimize is a fairly costly operation, so you\n   * should only do it if your search performance really\n   * requires it.  Many search applications do fine never\n   * calling optimize. </p>\n   *\n   * <p>Note that optimize requires 2X the index size free\n   * space in your Directory.  For example, if your index\n   * size is 10 MB then you need 20 MB free for optimize to\n   * complete.  Also, it's best to call {@link #commit()}\n   * after the optimize completes to allow IndexWriter to\n   * free up disk space.</p>\n   *\n   * <p>If some but not all readers re-open while an\n   * optimize is underway, this will cause > 2X temporary\n   * space to be consumed as those new readers will then\n   * hold open the partially optimized segments at that\n   * time.  It is best not to re-open readers while optimize\n   * is running.</p>\n   *\n   * <p>The actual temporary usage could be much less than\n   * these figures (it depends on many factors).</p>\n   *\n   * <p>In general, once the optimize completes, the total size of the\n   * index will be less than the size of the starting index.\n   * It could be quite a bit smaller (if there were many\n   * pending deletes) or just slightly smaller.</p>\n   *\n   * <p>If an Exception is hit during optimize(), for example\n   * due to disk full, the index will not be corrupt and no\n   * documents will have been lost.  However, it may have\n   * been partially optimized (some segments were merged but\n   * not all), and it's possible that one of the segments in\n   * the index will be in non-compound format even when\n   * using compound file format.  This will occur when the\n   * Exception is hit during conversion of the segment into\n   * compound format.</p>\n   *\n   * <p>This call will optimize those segments present in\n   * the index when the call started.  If other threads are\n   * still adding documents and flushing segments, those\n   * newly created segments will not be optimized unless you\n   * call optimize again.</p>\n   *\n   * <p><b>NOTE</b>: if this method hits an OutOfMemoryError\n   * you should immediately close the writer.  See <a\n   * href=\"#OOME\">above</a> for details.</p>\n   *\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   * @see LogMergePolicy#findMergesForOptimize\n  */\n  public void optimize() throws CorruptIndexException, IOException {\n    optimize(true);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4a69e5860d014751cc9329dfeb441a6d8fd1ed8e","date":1291833341,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/IndexWriter#optimize().mjava","pathOld":"lucene/src/java/org/apache/lucene/index/IndexWriter#optimize().mjava","sourceNew":"  /**\n   * Requests an \"optimize\" operation on an index, priming the index\n   * for the fastest available search. Traditionally this has meant\n   * merging all segments into a single segment as is done in the\n   * default merge policy, but individual merge policies may implement\n   * optimize in different ways.\n   *\n   * <p> Optimize is a fairly costly operation, so you\n   * should only do it if your search performance really\n   * requires it.  Many search applications do fine never\n   * calling optimize. </p>\n   *\n   * <p>Note that optimize requires 2X the index size free\n   * space in your Directory (3X if you're using compound\n   * file format).  For example, if your index size is 10 MB\n   * then you need 20 MB free for optimize to complete (30\n   * MB if you're using compound file format).  Also,\n   * it's best to call {@link #commit()} after the optimize\n   * completes to allow IndexWriter to free up disk space.</p>\n   *\n   * <p>If some but not all readers re-open while an\n   * optimize is underway, this will cause > 2X temporary\n   * space to be consumed as those new readers will then\n   * hold open the partially optimized segments at that\n   * time.  It is best not to re-open readers while optimize\n   * is running.</p>\n   *\n   * <p>The actual temporary usage could be much less than\n   * these figures (it depends on many factors).</p>\n   *\n   * <p>In general, once the optimize completes, the total size of the\n   * index will be less than the size of the starting index.\n   * It could be quite a bit smaller (if there were many\n   * pending deletes) or just slightly smaller.</p>\n   *\n   * <p>If an Exception is hit during optimize(), for example\n   * due to disk full, the index will not be corrupt and no\n   * documents will have been lost.  However, it may have\n   * been partially optimized (some segments were merged but\n   * not all), and it's possible that one of the segments in\n   * the index will be in non-compound format even when\n   * using compound file format.  This will occur when the\n   * Exception is hit during conversion of the segment into\n   * compound format.</p>\n   *\n   * <p>This call will optimize those segments present in\n   * the index when the call started.  If other threads are\n   * still adding documents and flushing segments, those\n   * newly created segments will not be optimized unless you\n   * call optimize again.</p>\n   *\n   * <p><b>NOTE</b>: if this method hits an OutOfMemoryError\n   * you should immediately close the writer.  See <a\n   * href=\"#OOME\">above</a> for details.</p>\n   *\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   * @see MergePolicy#findMergesForOptimize\n  */\n  public void optimize() throws CorruptIndexException, IOException {\n    optimize(true);\n  }\n\n","sourceOld":"  /**\n   * Requests an \"optimize\" operation on an index, priming the index\n   * for the fastest available search. Traditionally this has meant\n   * merging all segments into a single segment as is done in the\n   * default merge policy, but individual merge policies may implement\n   * optimize in different ways.\n   *\n   * <p> Optimize is a fairly costly operation, so you\n   * should only do it if your search performance really\n   * requires it.  Many search applications do fine never\n   * calling optimize. </p>\n   *\n   * <p>Note that optimize requires 2X the index size free\n   * space in your Directory (3X if you're using compound\n   * file format).  For example, if your index size is 10 MB\n   * then you need 20 MB free for optimize to complete (30\n   * MB if you're using compound file format).  Also,\n   * it's best to call {@link #commit()} after the optimize\n   * completes to allow IndexWriter to free up disk space.</p>\n   *\n   * <p>If some but not all readers re-open while an\n   * optimize is underway, this will cause > 2X temporary\n   * space to be consumed as those new readers will then\n   * hold open the partially optimized segments at that\n   * time.  It is best not to re-open readers while optimize\n   * is running.</p>\n   *\n   * <p>The actual temporary usage could be much less than\n   * these figures (it depends on many factors).</p>\n   *\n   * <p>In general, once the optimize completes, the total size of the\n   * index will be less than the size of the starting index.\n   * It could be quite a bit smaller (if there were many\n   * pending deletes) or just slightly smaller.</p>\n   *\n   * <p>If an Exception is hit during optimize(), for example\n   * due to disk full, the index will not be corrupt and no\n   * documents will have been lost.  However, it may have\n   * been partially optimized (some segments were merged but\n   * not all), and it's possible that one of the segments in\n   * the index will be in non-compound format even when\n   * using compound file format.  This will occur when the\n   * Exception is hit during conversion of the segment into\n   * compound format.</p>\n   *\n   * <p>This call will optimize those segments present in\n   * the index when the call started.  If other threads are\n   * still adding documents and flushing segments, those\n   * newly created segments will not be optimized unless you\n   * call optimize again.</p>\n   *\n   * <p><b>NOTE</b>: if this method hits an OutOfMemoryError\n   * you should immediately close the writer.  See <a\n   * href=\"#OOME\">above</a> for details.</p>\n   *\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   * @see LogMergePolicy#findMergesForOptimize\n  */\n  public void optimize() throws CorruptIndexException, IOException {\n    optimize(true);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","date":1292920096,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/IndexWriter#optimize().mjava","pathOld":"lucene/src/java/org/apache/lucene/index/IndexWriter#optimize().mjava","sourceNew":"  /**\n   * Requests an \"optimize\" operation on an index, priming the index\n   * for the fastest available search. Traditionally this has meant\n   * merging all segments into a single segment as is done in the\n   * default merge policy, but individual merge policies may implement\n   * optimize in different ways.\n   *\n   * <p> Optimize is a fairly costly operation, so you\n   * should only do it if your search performance really\n   * requires it.  Many search applications do fine never\n   * calling optimize. </p>\n   *\n   * <p>Note that optimize requires 2X the index size free\n   * space in your Directory (3X if you're using compound\n   * file format).  For example, if your index size is 10 MB\n   * then you need 20 MB free for optimize to complete (30\n   * MB if you're using compound file format).  Also,\n   * it's best to call {@link #commit()} after the optimize\n   * completes to allow IndexWriter to free up disk space.</p>\n   *\n   * <p>If some but not all readers re-open while an\n   * optimize is underway, this will cause > 2X temporary\n   * space to be consumed as those new readers will then\n   * hold open the partially optimized segments at that\n   * time.  It is best not to re-open readers while optimize\n   * is running.</p>\n   *\n   * <p>The actual temporary usage could be much less than\n   * these figures (it depends on many factors).</p>\n   *\n   * <p>In general, once the optimize completes, the total size of the\n   * index will be less than the size of the starting index.\n   * It could be quite a bit smaller (if there were many\n   * pending deletes) or just slightly smaller.</p>\n   *\n   * <p>If an Exception is hit during optimize(), for example\n   * due to disk full, the index will not be corrupt and no\n   * documents will have been lost.  However, it may have\n   * been partially optimized (some segments were merged but\n   * not all), and it's possible that one of the segments in\n   * the index will be in non-compound format even when\n   * using compound file format.  This will occur when the\n   * Exception is hit during conversion of the segment into\n   * compound format.</p>\n   *\n   * <p>This call will optimize those segments present in\n   * the index when the call started.  If other threads are\n   * still adding documents and flushing segments, those\n   * newly created segments will not be optimized unless you\n   * call optimize again.</p>\n   *\n   * <p><b>NOTE</b>: if this method hits an OutOfMemoryError\n   * you should immediately close the writer.  See <a\n   * href=\"#OOME\">above</a> for details.</p>\n   *\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   * @see MergePolicy#findMergesForOptimize\n  */\n  public void optimize() throws CorruptIndexException, IOException {\n    optimize(true);\n  }\n\n","sourceOld":"  /**\n   * Requests an \"optimize\" operation on an index, priming the index\n   * for the fastest available search. Traditionally this has meant\n   * merging all segments into a single segment as is done in the\n   * default merge policy, but individual merge policies may implement\n   * optimize in different ways.\n   *\n   * <p> Optimize is a fairly costly operation, so you\n   * should only do it if your search performance really\n   * requires it.  Many search applications do fine never\n   * calling optimize. </p>\n   *\n   * <p>Note that optimize requires 2X the index size free\n   * space in your Directory.  For example, if your index\n   * size is 10 MB then you need 20 MB free for optimize to\n   * complete.  Also, it's best to call {@link #commit()}\n   * after the optimize completes to allow IndexWriter to\n   * free up disk space.</p>\n   *\n   * <p>If some but not all readers re-open while an\n   * optimize is underway, this will cause > 2X temporary\n   * space to be consumed as those new readers will then\n   * hold open the partially optimized segments at that\n   * time.  It is best not to re-open readers while optimize\n   * is running.</p>\n   *\n   * <p>The actual temporary usage could be much less than\n   * these figures (it depends on many factors).</p>\n   *\n   * <p>In general, once the optimize completes, the total size of the\n   * index will be less than the size of the starting index.\n   * It could be quite a bit smaller (if there were many\n   * pending deletes) or just slightly smaller.</p>\n   *\n   * <p>If an Exception is hit during optimize(), for example\n   * due to disk full, the index will not be corrupt and no\n   * documents will have been lost.  However, it may have\n   * been partially optimized (some segments were merged but\n   * not all), and it's possible that one of the segments in\n   * the index will be in non-compound format even when\n   * using compound file format.  This will occur when the\n   * Exception is hit during conversion of the segment into\n   * compound format.</p>\n   *\n   * <p>This call will optimize those segments present in\n   * the index when the call started.  If other threads are\n   * still adding documents and flushing segments, those\n   * newly created segments will not be optimized unless you\n   * call optimize again.</p>\n   *\n   * <p><b>NOTE</b>: if this method hits an OutOfMemoryError\n   * you should immediately close the writer.  See <a\n   * href=\"#OOME\">above</a> for details.</p>\n   *\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   * @see LogMergePolicy#findMergesForOptimize\n  */\n  public void optimize() throws CorruptIndexException, IOException {\n    optimize(true);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ad27cbdf7398b36c6a478859f546c84d71cb251b","date":1296069528,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/IndexWriter#optimize().mjava","pathOld":"lucene/src/java/org/apache/lucene/index/IndexWriter#optimize().mjava","sourceNew":"  /**\n   * Requests an \"optimize\" operation on an index, priming the index\n   * for the fastest available search. Traditionally this has meant\n   * merging all segments into a single segment as is done in the\n   * default merge policy, but individual merge policies may implement\n   * optimize in different ways.\n   *\n   * <p> Optimize is a fairly costly operation, so you\n   * should only do it if your search performance really\n   * requires it.  Many search applications do fine never\n   * calling optimize. </p>\n   *\n   * <p>Note that optimize requires 2X the index size free\n   * space in your Directory (3X if you're using compound\n   * file format).  For example, if your index size is 10 MB\n   * then you need 20 MB free for optimize to complete (30\n   * MB if you're using compound file format).  Also,\n   * it's best to call {@link #commit()} after the optimize\n   * completes to allow IndexWriter to free up disk space.</p>\n   *\n   * <p>If some but not all readers re-open while an\n   * optimize is underway, this will cause > 2X temporary\n   * space to be consumed as those new readers will then\n   * hold open the partially optimized segments at that\n   * time.  It is best not to re-open readers while optimize\n   * is running.</p>\n   *\n   * <p>The actual temporary usage could be much less than\n   * these figures (it depends on many factors).</p>\n   *\n   * <p>In general, once the optimize completes, the total size of the\n   * index will be less than the size of the starting index.\n   * It could be quite a bit smaller (if there were many\n   * pending deletes) or just slightly smaller.</p>\n   *\n   * <p>If an Exception is hit during optimize(), for example\n   * due to disk full, the index will not be corrupt and no\n   * documents will have been lost.  However, it may have\n   * been partially optimized (some segments were merged but\n   * not all), and it's possible that one of the segments in\n   * the index will be in non-compound format even when\n   * using compound file format.  This will occur when the\n   * Exception is hit during conversion of the segment into\n   * compound format.</p>\n   *\n   * <p>This call will optimize those segments present in\n   * the index when the call started.  If other threads are\n   * still adding documents and flushing segments, those\n   * newly created segments will not be optimized unless you\n   * call optimize again.</p>\n   *\n   * <p><b>NOTE</b>: if this method hits an OutOfMemoryError\n   * you should immediately close the writer.  See <a\n   * href=\"#OOME\">above</a> for details.</p>\n   *\n   * <p><b>NOTE</b>: if you call {@link #close(boolean)}\n   * with <tt>false</tt>, which aborts all running merges,\n   * then any thread still running this method might hit a\n   * {@link MergePolicy.MergeAbortedException}.\n   *\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   * @see MergePolicy#findMergesForOptimize\n  */\n  public void optimize() throws CorruptIndexException, IOException {\n    optimize(true);\n  }\n\n","sourceOld":"  /**\n   * Requests an \"optimize\" operation on an index, priming the index\n   * for the fastest available search. Traditionally this has meant\n   * merging all segments into a single segment as is done in the\n   * default merge policy, but individual merge policies may implement\n   * optimize in different ways.\n   *\n   * <p> Optimize is a fairly costly operation, so you\n   * should only do it if your search performance really\n   * requires it.  Many search applications do fine never\n   * calling optimize. </p>\n   *\n   * <p>Note that optimize requires 2X the index size free\n   * space in your Directory (3X if you're using compound\n   * file format).  For example, if your index size is 10 MB\n   * then you need 20 MB free for optimize to complete (30\n   * MB if you're using compound file format).  Also,\n   * it's best to call {@link #commit()} after the optimize\n   * completes to allow IndexWriter to free up disk space.</p>\n   *\n   * <p>If some but not all readers re-open while an\n   * optimize is underway, this will cause > 2X temporary\n   * space to be consumed as those new readers will then\n   * hold open the partially optimized segments at that\n   * time.  It is best not to re-open readers while optimize\n   * is running.</p>\n   *\n   * <p>The actual temporary usage could be much less than\n   * these figures (it depends on many factors).</p>\n   *\n   * <p>In general, once the optimize completes, the total size of the\n   * index will be less than the size of the starting index.\n   * It could be quite a bit smaller (if there were many\n   * pending deletes) or just slightly smaller.</p>\n   *\n   * <p>If an Exception is hit during optimize(), for example\n   * due to disk full, the index will not be corrupt and no\n   * documents will have been lost.  However, it may have\n   * been partially optimized (some segments were merged but\n   * not all), and it's possible that one of the segments in\n   * the index will be in non-compound format even when\n   * using compound file format.  This will occur when the\n   * Exception is hit during conversion of the segment into\n   * compound format.</p>\n   *\n   * <p>This call will optimize those segments present in\n   * the index when the call started.  If other threads are\n   * still adding documents and flushing segments, those\n   * newly created segments will not be optimized unless you\n   * call optimize again.</p>\n   *\n   * <p><b>NOTE</b>: if this method hits an OutOfMemoryError\n   * you should immediately close the writer.  See <a\n   * href=\"#OOME\">above</a> for details.</p>\n   *\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   * @see MergePolicy#findMergesForOptimize\n  */\n  public void optimize() throws CorruptIndexException, IOException {\n    optimize(true);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"29ef99d61cda9641b6250bf9567329a6e65f901d","date":1297244127,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/IndexWriter#optimize().mjava","pathOld":"lucene/src/java/org/apache/lucene/index/IndexWriter#optimize().mjava","sourceNew":"  /**\n   * Requests an \"optimize\" operation on an index, priming the index\n   * for the fastest available search. Traditionally this has meant\n   * merging all segments into a single segment as is done in the\n   * default merge policy, but individual merge policies may implement\n   * optimize in different ways.\n   *\n   * <p> Optimize is a fairly costly operation, so you\n   * should only do it if your search performance really\n   * requires it.  Many search applications do fine never\n   * calling optimize. </p>\n   *\n   * <p>Note that optimize requires 2X the index size free\n   * space in your Directory (3X if you're using compound\n   * file format).  For example, if your index size is 10 MB\n   * then you need 20 MB free for optimize to complete (30\n   * MB if you're using compound file format).  Also,\n   * it's best to call {@link #commit()} after the optimize\n   * completes to allow IndexWriter to free up disk space.</p>\n   *\n   * <p>If some but not all readers re-open while an\n   * optimize is underway, this will cause > 2X temporary\n   * space to be consumed as those new readers will then\n   * hold open the partially optimized segments at that\n   * time.  It is best not to re-open readers while optimize\n   * is running.</p>\n   *\n   * <p>The actual temporary usage could be much less than\n   * these figures (it depends on many factors).</p>\n   *\n   * <p>In general, once the optimize completes, the total size of the\n   * index will be less than the size of the starting index.\n   * It could be quite a bit smaller (if there were many\n   * pending deletes) or just slightly smaller.</p>\n   *\n   * <p>If an Exception is hit during optimize(), for example\n   * due to disk full, the index will not be corrupt and no\n   * documents will have been lost.  However, it may have\n   * been partially optimized (some segments were merged but\n   * not all), and it's possible that one of the segments in\n   * the index will be in non-compound format even when\n   * using compound file format.  This will occur when the\n   * Exception is hit during conversion of the segment into\n   * compound format.</p>\n   *\n   * <p>This call will optimize those segments present in\n   * the index when the call started.  If other threads are\n   * still adding documents and flushing segments, those\n   * newly created segments will not be optimized unless you\n   * call optimize again.</p>\n   *\n   * <p><b>NOTE</b>: if this method hits an OutOfMemoryError\n   * you should immediately close the writer.  See <a\n   * href=\"#OOME\">above</a> for details.</p>\n   *\n   * <p><b>NOTE</b>: if you call {@link #close(boolean)}\n   * with <tt>false</tt>, which aborts all running merges,\n   * then any thread still running this method might hit a\n   * {@link MergePolicy.MergeAbortedException}.\n   *\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   * @see MergePolicy#findMergesForOptimize\n  */\n  public void optimize() throws CorruptIndexException, IOException {\n    optimize(true);\n  }\n\n","sourceOld":"  /**\n   * Requests an \"optimize\" operation on an index, priming the index\n   * for the fastest available search. Traditionally this has meant\n   * merging all segments into a single segment as is done in the\n   * default merge policy, but individual merge policies may implement\n   * optimize in different ways.\n   *\n   * <p> Optimize is a fairly costly operation, so you\n   * should only do it if your search performance really\n   * requires it.  Many search applications do fine never\n   * calling optimize. </p>\n   *\n   * <p>Note that optimize requires 2X the index size free\n   * space in your Directory (3X if you're using compound\n   * file format).  For example, if your index size is 10 MB\n   * then you need 20 MB free for optimize to complete (30\n   * MB if you're using compound file format).  Also,\n   * it's best to call {@link #commit()} after the optimize\n   * completes to allow IndexWriter to free up disk space.</p>\n   *\n   * <p>If some but not all readers re-open while an\n   * optimize is underway, this will cause > 2X temporary\n   * space to be consumed as those new readers will then\n   * hold open the partially optimized segments at that\n   * time.  It is best not to re-open readers while optimize\n   * is running.</p>\n   *\n   * <p>The actual temporary usage could be much less than\n   * these figures (it depends on many factors).</p>\n   *\n   * <p>In general, once the optimize completes, the total size of the\n   * index will be less than the size of the starting index.\n   * It could be quite a bit smaller (if there were many\n   * pending deletes) or just slightly smaller.</p>\n   *\n   * <p>If an Exception is hit during optimize(), for example\n   * due to disk full, the index will not be corrupt and no\n   * documents will have been lost.  However, it may have\n   * been partially optimized (some segments were merged but\n   * not all), and it's possible that one of the segments in\n   * the index will be in non-compound format even when\n   * using compound file format.  This will occur when the\n   * Exception is hit during conversion of the segment into\n   * compound format.</p>\n   *\n   * <p>This call will optimize those segments present in\n   * the index when the call started.  If other threads are\n   * still adding documents and flushing segments, those\n   * newly created segments will not be optimized unless you\n   * call optimize again.</p>\n   *\n   * <p><b>NOTE</b>: if this method hits an OutOfMemoryError\n   * you should immediately close the writer.  See <a\n   * href=\"#OOME\">above</a> for details.</p>\n   *\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   * @see MergePolicy#findMergesForOptimize\n  */\n  public void optimize() throws CorruptIndexException, IOException {\n    optimize(true);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"bde51b089eb7f86171eb3406e38a274743f9b7ac","date":1298336439,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/IndexWriter#optimize().mjava","pathOld":"lucene/src/java/org/apache/lucene/index/IndexWriter#optimize().mjava","sourceNew":"  /**\n   * Requests an \"optimize\" operation on an index, priming the index\n   * for the fastest available search. Traditionally this has meant\n   * merging all segments into a single segment as is done in the\n   * default merge policy, but individual merge policies may implement\n   * optimize in different ways.\n   *\n   * <p> Optimize is a fairly costly operation, so you\n   * should only do it if your search performance really\n   * requires it.  Many search applications do fine never\n   * calling optimize. </p>\n   *\n   * <p>Note that optimize requires 2X the index size free\n   * space in your Directory (3X if you're using compound\n   * file format).  For example, if your index size is 10 MB\n   * then you need 20 MB free for optimize to complete (30\n   * MB if you're using compound file format).  Also,\n   * it's best to call {@link #commit()} after the optimize\n   * completes to allow IndexWriter to free up disk space.</p>\n   *\n   * <p>If some but not all readers re-open while an\n   * optimize is underway, this will cause > 2X temporary\n   * space to be consumed as those new readers will then\n   * hold open the partially optimized segments at that\n   * time.  It is best not to re-open readers while optimize\n   * is running.</p>\n   *\n   * <p>The actual temporary usage could be much less than\n   * these figures (it depends on many factors).</p>\n   *\n   * <p>In general, once the optimize completes, the total size of the\n   * index will be less than the size of the starting index.\n   * It could be quite a bit smaller (if there were many\n   * pending deletes) or just slightly smaller.</p>\n   *\n   * <p>If an Exception is hit during optimize(), for example\n   * due to disk full, the index will not be corrupt and no\n   * documents will have been lost.  However, it may have\n   * been partially optimized (some segments were merged but\n   * not all), and it's possible that one of the segments in\n   * the index will be in non-compound format even when\n   * using compound file format.  This will occur when the\n   * Exception is hit during conversion of the segment into\n   * compound format.</p>\n   *\n   * <p>This call will optimize those segments present in\n   * the index when the call started.  If other threads are\n   * still adding documents and flushing segments, those\n   * newly created segments will not be optimized unless you\n   * call optimize again.</p>\n   *\n   * <p><b>NOTE</b>: if this method hits an OutOfMemoryError\n   * you should immediately close the writer.  See <a\n   * href=\"#OOME\">above</a> for details.</p>\n   *\n   * <p><b>NOTE</b>: if you call {@link #close(boolean)}\n   * with <tt>false</tt>, which aborts all running merges,\n   * then any thread still running this method might hit a\n   * {@link MergePolicy.MergeAbortedException}.\n   *\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   * @see MergePolicy#findMergesForOptimize\n  */\n  public void optimize() throws CorruptIndexException, IOException {\n    optimize(true);\n  }\n\n","sourceOld":"  /**\n   * Requests an \"optimize\" operation on an index, priming the index\n   * for the fastest available search. Traditionally this has meant\n   * merging all segments into a single segment as is done in the\n   * default merge policy, but individual merge policies may implement\n   * optimize in different ways.\n   *\n   * <p> Optimize is a fairly costly operation, so you\n   * should only do it if your search performance really\n   * requires it.  Many search applications do fine never\n   * calling optimize. </p>\n   *\n   * <p>Note that optimize requires 2X the index size free\n   * space in your Directory (3X if you're using compound\n   * file format).  For example, if your index size is 10 MB\n   * then you need 20 MB free for optimize to complete (30\n   * MB if you're using compound file format).  Also,\n   * it's best to call {@link #commit()} after the optimize\n   * completes to allow IndexWriter to free up disk space.</p>\n   *\n   * <p>If some but not all readers re-open while an\n   * optimize is underway, this will cause > 2X temporary\n   * space to be consumed as those new readers will then\n   * hold open the partially optimized segments at that\n   * time.  It is best not to re-open readers while optimize\n   * is running.</p>\n   *\n   * <p>The actual temporary usage could be much less than\n   * these figures (it depends on many factors).</p>\n   *\n   * <p>In general, once the optimize completes, the total size of the\n   * index will be less than the size of the starting index.\n   * It could be quite a bit smaller (if there were many\n   * pending deletes) or just slightly smaller.</p>\n   *\n   * <p>If an Exception is hit during optimize(), for example\n   * due to disk full, the index will not be corrupt and no\n   * documents will have been lost.  However, it may have\n   * been partially optimized (some segments were merged but\n   * not all), and it's possible that one of the segments in\n   * the index will be in non-compound format even when\n   * using compound file format.  This will occur when the\n   * Exception is hit during conversion of the segment into\n   * compound format.</p>\n   *\n   * <p>This call will optimize those segments present in\n   * the index when the call started.  If other threads are\n   * still adding documents and flushing segments, those\n   * newly created segments will not be optimized unless you\n   * call optimize again.</p>\n   *\n   * <p><b>NOTE</b>: if this method hits an OutOfMemoryError\n   * you should immediately close the writer.  See <a\n   * href=\"#OOME\">above</a> for details.</p>\n   *\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   * @see MergePolicy#findMergesForOptimize\n  */\n  public void optimize() throws CorruptIndexException, IOException {\n    optimize(true);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b820052f0bbe92816346963822b3207f14bb1836","date":1316929353,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/IndexWriter#optimize().mjava","pathOld":"lucene/src/java/org/apache/lucene/index/IndexWriter#optimize().mjava","sourceNew":"  /**\n   * Requests an \"optimize\" operation on an index, priming the index\n   * for the fastest available search. Traditionally this has meant\n   * merging all segments into a single segment as is done in the\n   * default merge policy, but individual merge policies may implement\n   * optimize in different ways.\n   *\n   * <p> Optimize is a very costly operation, so you\n   * should only do it if your search performance really\n   * requires it.  Many search applications do fine never\n   * calling optimize. </p>\n   *\n   * <p>Note that optimize requires 2X the index size free\n   * space in your Directory (3X if you're using compound\n   * file format).  For example, if your index size is 10 MB\n   * then you need 20 MB free for optimize to complete (30\n   * MB if you're using compound file format).  Also,\n   * it's best to call {@link #commit()} after the optimize\n   * completes to allow IndexWriter to free up disk space.</p>\n   *\n   * <p>If some but not all readers re-open while an\n   * optimize is underway, this will cause > 2X temporary\n   * space to be consumed as those new readers will then\n   * hold open the partially optimized segments at that\n   * time.  It is best not to re-open readers while optimize\n   * is running.</p>\n   *\n   * <p>The actual temporary usage could be much less than\n   * these figures (it depends on many factors).</p>\n   *\n   * <p>In general, once the optimize completes, the total size of the\n   * index will be less than the size of the starting index.\n   * It could be quite a bit smaller (if there were many\n   * pending deletes) or just slightly smaller.</p>\n   *\n   * <p>If an Exception is hit during optimize(), for example\n   * due to disk full, the index will not be corrupt and no\n   * documents will have been lost.  However, it may have\n   * been partially optimized (some segments were merged but\n   * not all), and it's possible that one of the segments in\n   * the index will be in non-compound format even when\n   * using compound file format.  This will occur when the\n   * Exception is hit during conversion of the segment into\n   * compound format.</p>\n   *\n   * <p>This call will optimize those segments present in\n   * the index when the call started.  If other threads are\n   * still adding documents and flushing segments, those\n   * newly created segments will not be optimized unless you\n   * call optimize again.</p>\n   *\n   * <p><b>NOTE</b>: if this method hits an OutOfMemoryError\n   * you should immediately close the writer.  See <a\n   * href=\"#OOME\">above</a> for details.</p>\n   *\n   * <p><b>NOTE</b>: if you call {@link #close(boolean)}\n   * with <tt>false</tt>, which aborts all running merges,\n   * then any thread still running this method might hit a\n   * {@link MergePolicy.MergeAbortedException}.\n   *\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   * @see MergePolicy#findMergesForOptimize\n  */\n  public void optimize() throws CorruptIndexException, IOException {\n    optimize(true);\n  }\n\n","sourceOld":"  /**\n   * Requests an \"optimize\" operation on an index, priming the index\n   * for the fastest available search. Traditionally this has meant\n   * merging all segments into a single segment as is done in the\n   * default merge policy, but individual merge policies may implement\n   * optimize in different ways.\n   *\n   * <p> Optimize is a fairly costly operation, so you\n   * should only do it if your search performance really\n   * requires it.  Many search applications do fine never\n   * calling optimize. </p>\n   *\n   * <p>Note that optimize requires 2X the index size free\n   * space in your Directory (3X if you're using compound\n   * file format).  For example, if your index size is 10 MB\n   * then you need 20 MB free for optimize to complete (30\n   * MB if you're using compound file format).  Also,\n   * it's best to call {@link #commit()} after the optimize\n   * completes to allow IndexWriter to free up disk space.</p>\n   *\n   * <p>If some but not all readers re-open while an\n   * optimize is underway, this will cause > 2X temporary\n   * space to be consumed as those new readers will then\n   * hold open the partially optimized segments at that\n   * time.  It is best not to re-open readers while optimize\n   * is running.</p>\n   *\n   * <p>The actual temporary usage could be much less than\n   * these figures (it depends on many factors).</p>\n   *\n   * <p>In general, once the optimize completes, the total size of the\n   * index will be less than the size of the starting index.\n   * It could be quite a bit smaller (if there were many\n   * pending deletes) or just slightly smaller.</p>\n   *\n   * <p>If an Exception is hit during optimize(), for example\n   * due to disk full, the index will not be corrupt and no\n   * documents will have been lost.  However, it may have\n   * been partially optimized (some segments were merged but\n   * not all), and it's possible that one of the segments in\n   * the index will be in non-compound format even when\n   * using compound file format.  This will occur when the\n   * Exception is hit during conversion of the segment into\n   * compound format.</p>\n   *\n   * <p>This call will optimize those segments present in\n   * the index when the call started.  If other threads are\n   * still adding documents and flushing segments, those\n   * newly created segments will not be optimized unless you\n   * call optimize again.</p>\n   *\n   * <p><b>NOTE</b>: if this method hits an OutOfMemoryError\n   * you should immediately close the writer.  See <a\n   * href=\"#OOME\">above</a> for details.</p>\n   *\n   * <p><b>NOTE</b>: if you call {@link #close(boolean)}\n   * with <tt>false</tt>, which aborts all running merges,\n   * then any thread still running this method might hit a\n   * {@link MergePolicy.MergeAbortedException}.\n   *\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   * @see MergePolicy#findMergesForOptimize\n  */\n  public void optimize() throws CorruptIndexException, IOException {\n    optimize(true);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d14e8d18c0e3970c20354dbeeb49da11bd587fbd","date":1321041051,"type":5,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/IndexWriter#forceMerge(int).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/IndexWriter#optimize().mjava","sourceNew":"  /**\n   * Forces merge policy to merge segments until there's <=\n   * maxNumSegments.  The actual merges to be\n   * executed are determined by the {@link MergePolicy}.\n   *\n   * <p>This is a horribly costly operation, especially when\n   * you pass a small {@code maxNumSegments}; usually you\n   * should only call this if the index is static (will no\n   * longer be changed).</p>\n   *\n   * <p>Note that this requires up to 2X the index size free\n   * space in your Directory (3X if you're using compound\n   * file format).  For example, if your index size is 10 MB\n   * then you need up to 20 MB free for this to complete (30\n   * MB if you're using compound file format).  Also,\n   * it's best to call {@link #commit()} afterwards,\n   * to allow IndexWriter to free up disk space.</p>\n   *\n   * <p>If some but not all readers re-open while merging\n   * is underway, this will cause > 2X temporary\n   * space to be consumed as those new readers will then\n   * hold open the temporary segments at that time.  It is\n   * best not to re-open readers while merging is running.</p>\n   *\n   * <p>The actual temporary usage could be much less than\n   * these figures (it depends on many factors).</p>\n   *\n   * <p>In general, once the this completes, the total size of the\n   * index will be less than the size of the starting index.\n   * It could be quite a bit smaller (if there were many\n   * pending deletes) or just slightly smaller.</p>\n   *\n   * <p>If an Exception is hit, for example\n   * due to disk full, the index will not be corrupt and no\n   * documents will have been lost.  However, it may have\n   * been partially merged (some segments were merged but\n   * not all), and it's possible that one of the segments in\n   * the index will be in non-compound format even when\n   * using compound file format.  This will occur when the\n   * Exception is hit during conversion of the segment into\n   * compound format.</p>\n   *\n   * <p>This call will merge those segments present in\n   * the index when the call started.  If other threads are\n   * still adding documents and flushing segments, those\n   * newly created segments will not be merged unless you\n   * call forceMerge again.</p>\n   *\n   * <p><b>NOTE</b>: if this method hits an OutOfMemoryError\n   * you should immediately close the writer.  See <a\n   * href=\"#OOME\">above</a> for details.</p>\n   *\n   * <p><b>NOTE</b>: if you call {@link #close(boolean)}\n   * with <tt>false</tt>, which aborts all running merges,\n   * then any thread still running this method might hit a\n   * {@link MergePolicy.MergeAbortedException}.\n   *\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   * @see MergePolicy#findMerges\n   *\n   * @param maxNumSegments maximum number of segments left\n   * in the index after merging finishes\n  */\n  public void forceMerge(int maxNumSegments) throws CorruptIndexException, IOException {\n    forceMerge(maxNumSegments, true);\n  }\n\n","sourceOld":"  /**\n   * Requests an \"optimize\" operation on an index, priming the index\n   * for the fastest available search. Traditionally this has meant\n   * merging all segments into a single segment as is done in the\n   * default merge policy, but individual merge policies may implement\n   * optimize in different ways.\n   *\n   * <p> Optimize is a very costly operation, so you\n   * should only do it if your search performance really\n   * requires it.  Many search applications do fine never\n   * calling optimize. </p>\n   *\n   * <p>Note that optimize requires 2X the index size free\n   * space in your Directory (3X if you're using compound\n   * file format).  For example, if your index size is 10 MB\n   * then you need 20 MB free for optimize to complete (30\n   * MB if you're using compound file format).  Also,\n   * it's best to call {@link #commit()} after the optimize\n   * completes to allow IndexWriter to free up disk space.</p>\n   *\n   * <p>If some but not all readers re-open while an\n   * optimize is underway, this will cause > 2X temporary\n   * space to be consumed as those new readers will then\n   * hold open the partially optimized segments at that\n   * time.  It is best not to re-open readers while optimize\n   * is running.</p>\n   *\n   * <p>The actual temporary usage could be much less than\n   * these figures (it depends on many factors).</p>\n   *\n   * <p>In general, once the optimize completes, the total size of the\n   * index will be less than the size of the starting index.\n   * It could be quite a bit smaller (if there were many\n   * pending deletes) or just slightly smaller.</p>\n   *\n   * <p>If an Exception is hit during optimize(), for example\n   * due to disk full, the index will not be corrupt and no\n   * documents will have been lost.  However, it may have\n   * been partially optimized (some segments were merged but\n   * not all), and it's possible that one of the segments in\n   * the index will be in non-compound format even when\n   * using compound file format.  This will occur when the\n   * Exception is hit during conversion of the segment into\n   * compound format.</p>\n   *\n   * <p>This call will optimize those segments present in\n   * the index when the call started.  If other threads are\n   * still adding documents and flushing segments, those\n   * newly created segments will not be optimized unless you\n   * call optimize again.</p>\n   *\n   * <p><b>NOTE</b>: if this method hits an OutOfMemoryError\n   * you should immediately close the writer.  See <a\n   * href=\"#OOME\">above</a> for details.</p>\n   *\n   * <p><b>NOTE</b>: if you call {@link #close(boolean)}\n   * with <tt>false</tt>, which aborts all running merges,\n   * then any thread still running this method might hit a\n   * {@link MergePolicy.MergeAbortedException}.\n   *\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   * @see MergePolicy#findMergesForOptimize\n  */\n  public void optimize() throws CorruptIndexException, IOException {\n    optimize(true);\n  }\n\n","bugFix":null,"bugIntro":["d3fd43b17cc944b4bce6e8d9fd052d58110fdf7b","4d3e8520fd031bab31fd0e4d480e55958bc45efe","15fbe8579d34349a8c79cbc5c933530dd5b6742a"],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"38a62612cfa4e104080d89d7751a8f1a258ac335":["8cac9bbcf5acbef2d0d83f6e9e32a22d71301db5"],"8cac9bbcf5acbef2d0d83f6e9e32a22d71301db5":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"4a69e5860d014751cc9329dfeb441a6d8fd1ed8e":["3bb13258feba31ab676502787ab2e1779f129b7a"],"d14e8d18c0e3970c20354dbeeb49da11bd587fbd":["b820052f0bbe92816346963822b3207f14bb1836"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":["9454a6510e2db155fb01faa5c049b06ece95fab9","38a62612cfa4e104080d89d7751a8f1a258ac335"],"29ef99d61cda9641b6250bf9567329a6e65f901d":["4a69e5860d014751cc9329dfeb441a6d8fd1ed8e","ad27cbdf7398b36c6a478859f546c84d71cb251b"],"ad27cbdf7398b36c6a478859f546c84d71cb251b":["38a62612cfa4e104080d89d7751a8f1a258ac335"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"b820052f0bbe92816346963822b3207f14bb1836":["ad27cbdf7398b36c6a478859f546c84d71cb251b"],"bde51b089eb7f86171eb3406e38a274743f9b7ac":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","ad27cbdf7398b36c6a478859f546c84d71cb251b"],"3bb13258feba31ab676502787ab2e1779f129b7a":["9454a6510e2db155fb01faa5c049b06ece95fab9","8cac9bbcf5acbef2d0d83f6e9e32a22d71301db5"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["d14e8d18c0e3970c20354dbeeb49da11bd587fbd"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"38a62612cfa4e104080d89d7751a8f1a258ac335":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","ad27cbdf7398b36c6a478859f546c84d71cb251b"],"8cac9bbcf5acbef2d0d83f6e9e32a22d71301db5":["38a62612cfa4e104080d89d7751a8f1a258ac335","3bb13258feba31ab676502787ab2e1779f129b7a"],"4a69e5860d014751cc9329dfeb441a6d8fd1ed8e":["29ef99d61cda9641b6250bf9567329a6e65f901d"],"d14e8d18c0e3970c20354dbeeb49da11bd587fbd":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":["bde51b089eb7f86171eb3406e38a274743f9b7ac"],"29ef99d61cda9641b6250bf9567329a6e65f901d":[],"ad27cbdf7398b36c6a478859f546c84d71cb251b":["29ef99d61cda9641b6250bf9567329a6e65f901d","b820052f0bbe92816346963822b3207f14bb1836","bde51b089eb7f86171eb3406e38a274743f9b7ac"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"b820052f0bbe92816346963822b3207f14bb1836":["d14e8d18c0e3970c20354dbeeb49da11bd587fbd"],"3bb13258feba31ab676502787ab2e1779f129b7a":["4a69e5860d014751cc9329dfeb441a6d8fd1ed8e"],"bde51b089eb7f86171eb3406e38a274743f9b7ac":[],"9454a6510e2db155fb01faa5c049b06ece95fab9":["8cac9bbcf5acbef2d0d83f6e9e32a22d71301db5","7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","3bb13258feba31ab676502787ab2e1779f129b7a"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["29ef99d61cda9641b6250bf9567329a6e65f901d","bde51b089eb7f86171eb3406e38a274743f9b7ac","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}