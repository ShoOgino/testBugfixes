{"path":"lucene/src/java/org/apache/lucene/index/PerFieldCodecWrapper.FieldsReader#FieldsReader(Directory,FieldInfos,SegmentInfo,int,int).mjava","commits":[{"id":"a493e6d0c3ad86bd55c0a1360d110142e948f2bd","date":1289406991,"type":0,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/PerFieldCodecWrapper.FieldsReader#FieldsReader(Directory,FieldInfos,SegmentInfo,int,int).mjava","pathOld":"/dev/null","sourceNew":"    public FieldsReader(Directory dir, FieldInfos fieldInfos, SegmentInfo si,\n        int readBufferSize, int indexDivisor) throws IOException {\n\n      final int fieldCount = fieldInfos.size();\n      final Map<Codec, FieldsProducer> producers = new HashMap<Codec, FieldsProducer>();\n      for (int i = 0; i < fieldCount; i++) {\n        FieldInfo fi = fieldInfos.fieldInfo(i);\n        if (fi.isIndexed) { // TODO this does not work for non-indexed fields\n          fields.add(fi.name);\n          Codec codec = segmentCodecs.codecs[fi.codecId];\n          if (!producers.containsKey(codec)) {\n            producers.put(codec, codec.fieldsProducer(new SegmentReadState(dir,\n                si, fieldInfos, readBufferSize, indexDivisor)));\n          }\n          codecs.put(fi.name, producers.get(codec));\n        }\n      }\n    }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"85a883878c0af761245ab048babc63d099f835f3","date":1289553330,"type":0,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/PerFieldCodecWrapper.FieldsReader#FieldsReader(Directory,FieldInfos,SegmentInfo,int,int).mjava","pathOld":"/dev/null","sourceNew":"    public FieldsReader(Directory dir, FieldInfos fieldInfos, SegmentInfo si,\n        int readBufferSize, int indexDivisor) throws IOException {\n\n      final int fieldCount = fieldInfos.size();\n      final Map<Codec, FieldsProducer> producers = new HashMap<Codec, FieldsProducer>();\n      for (int i = 0; i < fieldCount; i++) {\n        FieldInfo fi = fieldInfos.fieldInfo(i);\n        if (fi.isIndexed || fi.hasDocValues()) { // TODO this does not work for non-indexed fields\n          fields.add(fi.name);\n          Codec codec = segmentCodecs.codecs[fi.codecId];\n          if (!producers.containsKey(codec)) {\n            producers.put(codec, codec.fieldsProducer(new SegmentReadState(dir,\n                si, fieldInfos, readBufferSize, indexDivisor)));\n          }\n          codecs.put(fi.name, producers.get(codec));\n        }\n      }\n    }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"16c697f6ca5cdc82f918f753317a4ac9c70d259f","date":1289840486,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/PerFieldCodecWrapper.FieldsReader#FieldsReader(Directory,FieldInfos,SegmentInfo,int,int).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/PerFieldCodecWrapper.FieldsReader#FieldsReader(Directory,FieldInfos,SegmentInfo,int,int).mjava","sourceNew":"    public FieldsReader(Directory dir, FieldInfos fieldInfos, SegmentInfo si,\n        int readBufferSize, int indexDivisor) throws IOException {\n\n      final int fieldCount = fieldInfos.size();\n      final Map<Codec, FieldsProducer> producers = new HashMap<Codec, FieldsProducer>();\n      for (int i = 0; i < fieldCount; i++) {\n        FieldInfo fi = fieldInfos.fieldInfo(i);\n        if (fi.isIndexed) { // TODO this does not work for non-indexed fields\n          fields.add(fi.name);\n          Codec codec = segmentCodecs.codecs[fi.codecId];\n          if (!producers.containsKey(codec)) {\n            producers.put(codec, codec.fieldsProducer(new SegmentReadState(dir,\n                si, fieldInfos, readBufferSize, indexDivisor, \"\"+fi.codecId)));\n          }\n          codecs.put(fi.name, producers.get(codec));\n        }\n      }\n    }\n\n","sourceOld":"    public FieldsReader(Directory dir, FieldInfos fieldInfos, SegmentInfo si,\n        int readBufferSize, int indexDivisor) throws IOException {\n\n      final int fieldCount = fieldInfos.size();\n      final Map<Codec, FieldsProducer> producers = new HashMap<Codec, FieldsProducer>();\n      for (int i = 0; i < fieldCount; i++) {\n        FieldInfo fi = fieldInfos.fieldInfo(i);\n        if (fi.isIndexed) { // TODO this does not work for non-indexed fields\n          fields.add(fi.name);\n          Codec codec = segmentCodecs.codecs[fi.codecId];\n          if (!producers.containsKey(codec)) {\n            producers.put(codec, codec.fieldsProducer(new SegmentReadState(dir,\n                si, fieldInfos, readBufferSize, indexDivisor)));\n          }\n          codecs.put(fi.name, producers.get(codec));\n        }\n      }\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9ab1f5591dc05f1f2b5407d809c9699f75554a32","date":1290008586,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/PerFieldCodecWrapper.FieldsReader#FieldsReader(Directory,FieldInfos,SegmentInfo,int,int).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/PerFieldCodecWrapper.FieldsReader#FieldsReader(Directory,FieldInfos,SegmentInfo,int,int).mjava","sourceNew":"    public FieldsReader(Directory dir, FieldInfos fieldInfos, SegmentInfo si,\n        int readBufferSize, int indexDivisor) throws IOException {\n\n      final int fieldCount = fieldInfos.size();\n      final Map<Codec, FieldsProducer> producers = new HashMap<Codec, FieldsProducer>();\n      for (int i = 0; i < fieldCount; i++) {\n        FieldInfo fi = fieldInfos.fieldInfo(i);\n        if (fi.isIndexed || fi.hasDocValues()) { // TODO this does not work for non-indexed fields\n          fields.add(fi.name);\n          Codec codec = segmentCodecs.codecs[fi.codecId];\n          if (!producers.containsKey(codec)) {\n            producers.put(codec, codec.fieldsProducer(new SegmentReadState(dir,\n                si, fieldInfos, readBufferSize, indexDivisor, \"\"+fi.codecId)));\n          }\n          codecs.put(fi.name, producers.get(codec));\n        }\n      }\n    }\n\n","sourceOld":"    public FieldsReader(Directory dir, FieldInfos fieldInfos, SegmentInfo si,\n        int readBufferSize, int indexDivisor) throws IOException {\n\n      final int fieldCount = fieldInfos.size();\n      final Map<Codec, FieldsProducer> producers = new HashMap<Codec, FieldsProducer>();\n      for (int i = 0; i < fieldCount; i++) {\n        FieldInfo fi = fieldInfos.fieldInfo(i);\n        if (fi.isIndexed || fi.hasDocValues()) { // TODO this does not work for non-indexed fields\n          fields.add(fi.name);\n          Codec codec = segmentCodecs.codecs[fi.codecId];\n          if (!producers.containsKey(codec)) {\n            producers.put(codec, codec.fieldsProducer(new SegmentReadState(dir,\n                si, fieldInfos, readBufferSize, indexDivisor)));\n          }\n          codecs.put(fi.name, producers.get(codec));\n        }\n      }\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8a3c2cd46c82df9039659ca61b07cd39503f06b2","date":1292324700,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/PerFieldCodecWrapper.FieldsReader#FieldsReader(Directory,FieldInfos,SegmentInfo,int,int).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/PerFieldCodecWrapper.FieldsReader#FieldsReader(Directory,FieldInfos,SegmentInfo,int,int).mjava","sourceNew":"    public FieldsReader(Directory dir, FieldInfos fieldInfos, SegmentInfo si,\n        int readBufferSize, int indexDivisor) throws IOException {\n\n      final int fieldCount = fieldInfos.size();\n      final Map<Codec, FieldsProducer> producers = new HashMap<Codec, FieldsProducer>();\n      boolean success = false;\n      try {\n        for (int i = 0; i < fieldCount; i++) {\n          FieldInfo fi = fieldInfos.fieldInfo(i);\n          if (fi.isIndexed) { // TODO this does not work for non-indexed fields\n            fields.add(fi.name);\n            Codec codec = segmentCodecs.codecs[fi.codecId];\n            if (!producers.containsKey(codec)) {\n              producers.put(codec, codec.fieldsProducer(new SegmentReadState(dir,\n                                                                             si, fieldInfos, readBufferSize, indexDivisor, \"\"+fi.codecId)));\n            }\n            codecs.put(fi.name, producers.get(codec));\n          }\n        }\n        success = true;\n      } finally {\n        if (!success) {\n          // If we hit exception (eg, IOE because writer was\n          // committing, or, for any other reason) we must\n          // go back and close all FieldsProducers we opened:\n          for(FieldsProducer fp : producers.values()) {\n            try {\n              fp.close();\n            } catch (Throwable t) {\n              // Suppress all exceptions here so we continue\n              // to throw the original one\n            }\n          }\n        }\n      }\n    }\n\n","sourceOld":"    public FieldsReader(Directory dir, FieldInfos fieldInfos, SegmentInfo si,\n        int readBufferSize, int indexDivisor) throws IOException {\n\n      final int fieldCount = fieldInfos.size();\n      final Map<Codec, FieldsProducer> producers = new HashMap<Codec, FieldsProducer>();\n      for (int i = 0; i < fieldCount; i++) {\n        FieldInfo fi = fieldInfos.fieldInfo(i);\n        if (fi.isIndexed) { // TODO this does not work for non-indexed fields\n          fields.add(fi.name);\n          Codec codec = segmentCodecs.codecs[fi.codecId];\n          if (!producers.containsKey(codec)) {\n            producers.put(codec, codec.fieldsProducer(new SegmentReadState(dir,\n                si, fieldInfos, readBufferSize, indexDivisor, \"\"+fi.codecId)));\n          }\n          codecs.put(fi.name, producers.get(codec));\n        }\n      }\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ab5cb6a74aefb78aa0569857970b9151dfe2e787","date":1292842407,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/PerFieldCodecWrapper.FieldsReader#FieldsReader(Directory,FieldInfos,SegmentInfo,int,int).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/PerFieldCodecWrapper.FieldsReader#FieldsReader(Directory,FieldInfos,SegmentInfo,int,int).mjava","sourceNew":"    public FieldsReader(Directory dir, FieldInfos fieldInfos, SegmentInfo si,\n        int readBufferSize, int indexDivisor) throws IOException {\n\n      final int fieldCount = fieldInfos.size();\n      final Map<Codec, FieldsProducer> producers = new HashMap<Codec, FieldsProducer>();\n      boolean success = false;\n      try {\n        for (int i = 0; i < fieldCount; i++) {\n          FieldInfo fi = fieldInfos.fieldInfo(i);\n          if (fi.isIndexed || fi.hasDocValues()) { // TODO this does not work for non-indexed fields\n            fields.add(fi.name);\n            Codec codec = segmentCodecs.codecs[fi.codecId];\n            if (!producers.containsKey(codec)) {\n              producers.put(codec, codec.fieldsProducer(new SegmentReadState(dir,\n                                                                             si, fieldInfos, readBufferSize, indexDivisor, \"\"+fi.codecId)));\n            }\n            codecs.put(fi.name, producers.get(codec));\n          }\n        }\n        success = true;\n      } finally {\n        if (!success) {\n          // If we hit exception (eg, IOE because writer was\n          // committing, or, for any other reason) we must\n          // go back and close all FieldsProducers we opened:\n          for(FieldsProducer fp : producers.values()) {\n            try {\n              fp.close();\n            } catch (Throwable t) {\n              // Suppress all exceptions here so we continue\n              // to throw the original one\n            }\n          }\n        }\n      }\n    }\n\n","sourceOld":"    public FieldsReader(Directory dir, FieldInfos fieldInfos, SegmentInfo si,\n        int readBufferSize, int indexDivisor) throws IOException {\n\n      final int fieldCount = fieldInfos.size();\n      final Map<Codec, FieldsProducer> producers = new HashMap<Codec, FieldsProducer>();\n      for (int i = 0; i < fieldCount; i++) {\n        FieldInfo fi = fieldInfos.fieldInfo(i);\n        if (fi.isIndexed || fi.hasDocValues()) { // TODO this does not work for non-indexed fields\n          fields.add(fi.name);\n          Codec codec = segmentCodecs.codecs[fi.codecId];\n          if (!producers.containsKey(codec)) {\n            producers.put(codec, codec.fieldsProducer(new SegmentReadState(dir,\n                si, fieldInfos, readBufferSize, indexDivisor, \"\"+fi.codecId)));\n          }\n          codecs.put(fi.name, producers.get(codec));\n        }\n      }\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","date":1292920096,"type":0,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/PerFieldCodecWrapper.FieldsReader#FieldsReader(Directory,FieldInfos,SegmentInfo,int,int).mjava","pathOld":"/dev/null","sourceNew":"    public FieldsReader(Directory dir, FieldInfos fieldInfos, SegmentInfo si,\n        int readBufferSize, int indexDivisor) throws IOException {\n\n      final int fieldCount = fieldInfos.size();\n      final Map<Codec, FieldsProducer> producers = new HashMap<Codec, FieldsProducer>();\n      boolean success = false;\n      try {\n        for (int i = 0; i < fieldCount; i++) {\n          FieldInfo fi = fieldInfos.fieldInfo(i);\n          if (fi.isIndexed) { // TODO this does not work for non-indexed fields\n            fields.add(fi.name);\n            Codec codec = segmentCodecs.codecs[fi.codecId];\n            if (!producers.containsKey(codec)) {\n              producers.put(codec, codec.fieldsProducer(new SegmentReadState(dir,\n                                                                             si, fieldInfos, readBufferSize, indexDivisor, \"\"+fi.codecId)));\n            }\n            codecs.put(fi.name, producers.get(codec));\n          }\n        }\n        success = true;\n      } finally {\n        if (!success) {\n          // If we hit exception (eg, IOE because writer was\n          // committing, or, for any other reason) we must\n          // go back and close all FieldsProducers we opened:\n          for(FieldsProducer fp : producers.values()) {\n            try {\n              fp.close();\n            } catch (Throwable t) {\n              // Suppress all exceptions here so we continue\n              // to throw the original one\n            }\n          }\n        }\n      }\n    }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b0c7a8f7304b75b1528814c5820fa23a96816c27","date":1298314239,"type":3,"author":"Michael Busch","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/PerFieldCodecWrapper.FieldsReader#FieldsReader(Directory,FieldInfos,SegmentInfo,int,int).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/PerFieldCodecWrapper.FieldsReader#FieldsReader(Directory,FieldInfos,SegmentInfo,int,int).mjava","sourceNew":"    public FieldsReader(Directory dir, FieldInfos fieldInfos, SegmentInfo si,\n        int readBufferSize, int indexDivisor) throws IOException {\n\n      final Map<Codec, FieldsProducer> producers = new HashMap<Codec, FieldsProducer>();\n      boolean success = false;\n      try {\n        for (FieldInfo fi : fieldInfos) {\n          if (fi.isIndexed) { // TODO this does not work for non-indexed fields\n            fields.add(fi.name);\n            Codec codec = segmentCodecs.codecs[fi.getCodecId()];\n            if (!producers.containsKey(codec)) {\n              producers.put(codec, codec.fieldsProducer(new SegmentReadState(dir,\n                                                                             si, fieldInfos, readBufferSize, indexDivisor, \"\"+fi.getCodecId())));\n            }\n            codecs.put(fi.name, producers.get(codec));\n          }\n        }\n        success = true;\n      } finally {\n        if (!success) {\n          // If we hit exception (eg, IOE because writer was\n          // committing, or, for any other reason) we must\n          // go back and close all FieldsProducers we opened:\n          for(FieldsProducer fp : producers.values()) {\n            try {\n              fp.close();\n            } catch (Throwable t) {\n              // Suppress all exceptions here so we continue\n              // to throw the original one\n            }\n          }\n        }\n      }\n    }\n\n","sourceOld":"    public FieldsReader(Directory dir, FieldInfos fieldInfos, SegmentInfo si,\n        int readBufferSize, int indexDivisor) throws IOException {\n\n      final int fieldCount = fieldInfos.size();\n      final Map<Codec, FieldsProducer> producers = new HashMap<Codec, FieldsProducer>();\n      boolean success = false;\n      try {\n        for (int i = 0; i < fieldCount; i++) {\n          FieldInfo fi = fieldInfos.fieldInfo(i);\n          if (fi.isIndexed) { // TODO this does not work for non-indexed fields\n            fields.add(fi.name);\n            Codec codec = segmentCodecs.codecs[fi.codecId];\n            if (!producers.containsKey(codec)) {\n              producers.put(codec, codec.fieldsProducer(new SegmentReadState(dir,\n                                                                             si, fieldInfos, readBufferSize, indexDivisor, \"\"+fi.codecId)));\n            }\n            codecs.put(fi.name, producers.get(codec));\n          }\n        }\n        success = true;\n      } finally {\n        if (!success) {\n          // If we hit exception (eg, IOE because writer was\n          // committing, or, for any other reason) we must\n          // go back and close all FieldsProducers we opened:\n          for(FieldsProducer fp : producers.values()) {\n            try {\n              fp.close();\n            } catch (Throwable t) {\n              // Suppress all exceptions here so we continue\n              // to throw the original one\n            }\n          }\n        }\n      }\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"bde51b089eb7f86171eb3406e38a274743f9b7ac","date":1298336439,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/PerFieldCodecWrapper.FieldsReader#FieldsReader(Directory,FieldInfos,SegmentInfo,int,int).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/PerFieldCodecWrapper.FieldsReader#FieldsReader(Directory,FieldInfos,SegmentInfo,int,int).mjava","sourceNew":"    public FieldsReader(Directory dir, FieldInfos fieldInfos, SegmentInfo si,\n        int readBufferSize, int indexDivisor) throws IOException {\n\n      final Map<Codec, FieldsProducer> producers = new HashMap<Codec, FieldsProducer>();\n      boolean success = false;\n      try {\n        for (FieldInfo fi : fieldInfos) {\n          if (fi.isIndexed) { // TODO this does not work for non-indexed fields\n            fields.add(fi.name);\n            Codec codec = segmentCodecs.codecs[fi.getCodecId()];\n            if (!producers.containsKey(codec)) {\n              producers.put(codec, codec.fieldsProducer(new SegmentReadState(dir,\n                                                                             si, fieldInfos, readBufferSize, indexDivisor, \"\"+fi.getCodecId())));\n            }\n            codecs.put(fi.name, producers.get(codec));\n          }\n        }\n        success = true;\n      } finally {\n        if (!success) {\n          // If we hit exception (eg, IOE because writer was\n          // committing, or, for any other reason) we must\n          // go back and close all FieldsProducers we opened:\n          for(FieldsProducer fp : producers.values()) {\n            try {\n              fp.close();\n            } catch (Throwable t) {\n              // Suppress all exceptions here so we continue\n              // to throw the original one\n            }\n          }\n        }\n      }\n    }\n\n","sourceOld":"    public FieldsReader(Directory dir, FieldInfos fieldInfos, SegmentInfo si,\n        int readBufferSize, int indexDivisor) throws IOException {\n\n      final int fieldCount = fieldInfos.size();\n      final Map<Codec, FieldsProducer> producers = new HashMap<Codec, FieldsProducer>();\n      boolean success = false;\n      try {\n        for (int i = 0; i < fieldCount; i++) {\n          FieldInfo fi = fieldInfos.fieldInfo(i);\n          if (fi.isIndexed) { // TODO this does not work for non-indexed fields\n            fields.add(fi.name);\n            Codec codec = segmentCodecs.codecs[fi.codecId];\n            if (!producers.containsKey(codec)) {\n              producers.put(codec, codec.fieldsProducer(new SegmentReadState(dir,\n                                                                             si, fieldInfos, readBufferSize, indexDivisor, \"\"+fi.codecId)));\n            }\n            codecs.put(fi.name, producers.get(codec));\n          }\n        }\n        success = true;\n      } finally {\n        if (!success) {\n          // If we hit exception (eg, IOE because writer was\n          // committing, or, for any other reason) we must\n          // go back and close all FieldsProducers we opened:\n          for(FieldsProducer fp : producers.values()) {\n            try {\n              fp.close();\n            } catch (Throwable t) {\n              // Suppress all exceptions here so we continue\n              // to throw the original one\n            }\n          }\n        }\n      }\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"14ec33385f6fbb6ce172882d14605790418a5d31","date":1298910796,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/PerFieldCodecWrapper.FieldsReader#FieldsReader(Directory,FieldInfos,SegmentInfo,int,int).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/PerFieldCodecWrapper.FieldsReader#FieldsReader(Directory,FieldInfos,SegmentInfo,int,int).mjava","sourceNew":"    public FieldsReader(Directory dir, FieldInfos fieldInfos, SegmentInfo si,\n        int readBufferSize, int indexDivisor) throws IOException {\n\n      final int fieldCount = fieldInfos.size();\n      final Map<Codec, FieldsProducer> producers = new HashMap<Codec, FieldsProducer>();\n      boolean success = false;\n      try {\n        for (int i = 0; i < fieldCount; i++) {\n          FieldInfo fi = fieldInfos.fieldInfo(i);\n          if (fi.isIndexed) { // TODO this does not work for non-indexed fields\n            fields.add(fi.name);\n            Codec codec = segmentCodecs.codecs[fi.codecId];\n            if (!producers.containsKey(codec)) {\n              producers.put(codec, codec.fieldsProducer(new SegmentReadState(dir,\n                                                                             si, fieldInfos, readBufferSize, indexDivisor, \"\"+fi.codecId)));\n            }\n            codecs.put(fi.name, producers.get(codec));\n          }\n        }\n        success = true;\n      } finally {\n        if (!success) {\n          // If we hit exception (eg, IOE because writer was\n          // committing, or, for any other reason) we must\n          // go back and close all FieldsProducers we opened:\n          for(FieldsProducer fp : producers.values()) {\n            try {\n              fp.close();\n            } catch (Throwable t) {\n              // Suppress all exceptions here so we continue\n              // to throw the original one\n            }\n          }\n        }\n      }\n    }\n\n","sourceOld":"    public FieldsReader(Directory dir, FieldInfos fieldInfos, SegmentInfo si,\n        int readBufferSize, int indexDivisor) throws IOException {\n\n      final Map<Codec, FieldsProducer> producers = new HashMap<Codec, FieldsProducer>();\n      boolean success = false;\n      try {\n        for (FieldInfo fi : fieldInfos) {\n          if (fi.isIndexed) { // TODO this does not work for non-indexed fields\n            fields.add(fi.name);\n            Codec codec = segmentCodecs.codecs[fi.getCodecId()];\n            if (!producers.containsKey(codec)) {\n              producers.put(codec, codec.fieldsProducer(new SegmentReadState(dir,\n                                                                             si, fieldInfos, readBufferSize, indexDivisor, \"\"+fi.getCodecId())));\n            }\n            codecs.put(fi.name, producers.get(codec));\n          }\n        }\n        success = true;\n      } finally {\n        if (!success) {\n          // If we hit exception (eg, IOE because writer was\n          // committing, or, for any other reason) we must\n          // go back and close all FieldsProducers we opened:\n          for(FieldsProducer fp : producers.values()) {\n            try {\n              fp.close();\n            } catch (Throwable t) {\n              // Suppress all exceptions here so we continue\n              // to throw the original one\n            }\n          }\n        }\n      }\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1224a4027481acce15495b03bce9b48b93b42722","date":1300792329,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/PerFieldCodecWrapper.FieldsReader#FieldsReader(Directory,FieldInfos,SegmentInfo,int,int).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/PerFieldCodecWrapper.FieldsReader#FieldsReader(Directory,FieldInfos,SegmentInfo,int,int).mjava","sourceNew":"    public FieldsReader(Directory dir, FieldInfos fieldInfos, SegmentInfo si,\n        int readBufferSize, int indexDivisor) throws IOException {\n\n      final Map<Codec, FieldsProducer> producers = new HashMap<Codec, FieldsProducer>();\n      boolean success = false;\n      try {\n        for (FieldInfo fi : fieldInfos) {\n          if (fi.isIndexed) { // TODO this does not work for non-indexed fields\n            fields.add(fi.name);\n            Codec codec = segmentCodecs.codecs[fi.getCodecId()];\n            if (!producers.containsKey(codec)) {\n              producers.put(codec, codec.fieldsProducer(new SegmentReadState(dir,\n                                                                             si, fieldInfos, readBufferSize, indexDivisor, \"\"+fi.getCodecId())));\n            }\n            codecs.put(fi.name, producers.get(codec));\n          }\n        }\n        success = true;\n      } finally {\n        if (!success) {\n          // If we hit exception (eg, IOE because writer was\n          // committing, or, for any other reason) we must\n          // go back and close all FieldsProducers we opened:\n          for(FieldsProducer fp : producers.values()) {\n            try {\n              fp.close();\n            } catch (Throwable t) {\n              // Suppress all exceptions here so we continue\n              // to throw the original one\n            }\n          }\n        }\n      }\n    }\n\n","sourceOld":"    public FieldsReader(Directory dir, FieldInfos fieldInfos, SegmentInfo si,\n        int readBufferSize, int indexDivisor) throws IOException {\n\n      final int fieldCount = fieldInfos.size();\n      final Map<Codec, FieldsProducer> producers = new HashMap<Codec, FieldsProducer>();\n      boolean success = false;\n      try {\n        for (int i = 0; i < fieldCount; i++) {\n          FieldInfo fi = fieldInfos.fieldInfo(i);\n          if (fi.isIndexed) { // TODO this does not work for non-indexed fields\n            fields.add(fi.name);\n            Codec codec = segmentCodecs.codecs[fi.codecId];\n            if (!producers.containsKey(codec)) {\n              producers.put(codec, codec.fieldsProducer(new SegmentReadState(dir,\n                                                                             si, fieldInfos, readBufferSize, indexDivisor, \"\"+fi.codecId)));\n            }\n            codecs.put(fi.name, producers.get(codec));\n          }\n        }\n        success = true;\n      } finally {\n        if (!success) {\n          // If we hit exception (eg, IOE because writer was\n          // committing, or, for any other reason) we must\n          // go back and close all FieldsProducers we opened:\n          for(FieldsProducer fp : producers.values()) {\n            try {\n              fp.close();\n            } catch (Throwable t) {\n              // Suppress all exceptions here so we continue\n              // to throw the original one\n            }\n          }\n        }\n      }\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e92442af786151ee55bc283eb472f629e3c7b52b","date":1301070252,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/PerFieldCodecWrapper.FieldsReader#FieldsReader(Directory,FieldInfos,SegmentInfo,int,int).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/PerFieldCodecWrapper.FieldsReader#FieldsReader(Directory,FieldInfos,SegmentInfo,int,int).mjava","sourceNew":"    public FieldsReader(Directory dir, FieldInfos fieldInfos, SegmentInfo si,\n        int readBufferSize, int indexDivisor) throws IOException {\n\n      final Map<Codec, FieldsProducer> producers = new HashMap<Codec, FieldsProducer>();\n      boolean success = false;\n      try {\n        for (FieldInfo fi : fieldInfos) {\n          if (fi.isIndexed) { // TODO this does not work for non-indexed fields\n            fields.add(fi.name);\n            assert fi.getCodecId() != FieldInfo.UNASSIGNED_CODEC_ID;\n            Codec codec = segmentCodecs.codecs[fi.getCodecId()];\n            if (!producers.containsKey(codec)) {\n              producers.put(codec, codec.fieldsProducer(new SegmentReadState(dir,\n                                                                             si, fieldInfos, readBufferSize, indexDivisor, \"\"+fi.getCodecId())));\n            }\n            codecs.put(fi.name, producers.get(codec));\n          }\n        }\n        success = true;\n      } finally {\n        if (!success) {\n          // If we hit exception (eg, IOE because writer was\n          // committing, or, for any other reason) we must\n          // go back and close all FieldsProducers we opened:\n          for(FieldsProducer fp : producers.values()) {\n            try {\n              fp.close();\n            } catch (Throwable t) {\n              // Suppress all exceptions here so we continue\n              // to throw the original one\n            }\n          }\n        }\n      }\n    }\n\n","sourceOld":"    public FieldsReader(Directory dir, FieldInfos fieldInfos, SegmentInfo si,\n        int readBufferSize, int indexDivisor) throws IOException {\n\n      final Map<Codec, FieldsProducer> producers = new HashMap<Codec, FieldsProducer>();\n      boolean success = false;\n      try {\n        for (FieldInfo fi : fieldInfos) {\n          if (fi.isIndexed) { // TODO this does not work for non-indexed fields\n            fields.add(fi.name);\n            Codec codec = segmentCodecs.codecs[fi.getCodecId()];\n            if (!producers.containsKey(codec)) {\n              producers.put(codec, codec.fieldsProducer(new SegmentReadState(dir,\n                                                                             si, fieldInfos, readBufferSize, indexDivisor, \"\"+fi.getCodecId())));\n            }\n            codecs.put(fi.name, producers.get(codec));\n          }\n        }\n        success = true;\n      } finally {\n        if (!success) {\n          // If we hit exception (eg, IOE because writer was\n          // committing, or, for any other reason) we must\n          // go back and close all FieldsProducers we opened:\n          for(FieldsProducer fp : producers.values()) {\n            try {\n              fp.close();\n            } catch (Throwable t) {\n              // Suppress all exceptions here so we continue\n              // to throw the original one\n            }\n          }\n        }\n      }\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d619839baa8ce5503e496b94a9e42ad6f079293f","date":1301309428,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/PerFieldCodecWrapper.FieldsReader#FieldsReader(Directory,FieldInfos,SegmentInfo,int,int).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/PerFieldCodecWrapper.FieldsReader#FieldsReader(Directory,FieldInfos,SegmentInfo,int,int).mjava","sourceNew":"    public FieldsReader(Directory dir, FieldInfos fieldInfos, SegmentInfo si,\n        int readBufferSize, int indexDivisor) throws IOException {\n\n      final Map<Codec, FieldsProducer> producers = new HashMap<Codec, FieldsProducer>();\n      boolean success = false;\n      try {\n        for (FieldInfo fi : fieldInfos) {\n          if (fi.isIndexed || fi.hasDocValues()) { // TODO this does not work for non-indexed fields\n            fields.add(fi.name);\n            assert fi.getCodecId() != FieldInfo.UNASSIGNED_CODEC_ID;\n            Codec codec = segmentCodecs.codecs[fi.getCodecId()];\n            if (!producers.containsKey(codec)) {\n              producers.put(codec, codec.fieldsProducer(new SegmentReadState(dir,\n                                                                             si, fieldInfos, readBufferSize, indexDivisor, fi.getCodecId())));\n            }\n            codecs.put(fi.name, producers.get(codec));\n          }\n        }\n        success = true;\n      } finally {\n        if (!success) {\n          // If we hit exception (eg, IOE because writer was\n          // committing, or, for any other reason) we must\n          // go back and close all FieldsProducers we opened:\n          for(FieldsProducer fp : producers.values()) {\n            try {\n              fp.close();\n            } catch (Throwable t) {\n              // Suppress all exceptions here so we continue\n              // to throw the original one\n            }\n          }\n        }\n      }\n    }\n\n","sourceOld":"    public FieldsReader(Directory dir, FieldInfos fieldInfos, SegmentInfo si,\n        int readBufferSize, int indexDivisor) throws IOException {\n\n      final int fieldCount = fieldInfos.size();\n      final Map<Codec, FieldsProducer> producers = new HashMap<Codec, FieldsProducer>();\n      boolean success = false;\n      try {\n        for (int i = 0; i < fieldCount; i++) {\n          FieldInfo fi = fieldInfos.fieldInfo(i);\n          if (fi.isIndexed || fi.hasDocValues()) { // TODO this does not work for non-indexed fields\n            fields.add(fi.name);\n            Codec codec = segmentCodecs.codecs[fi.codecId];\n            if (!producers.containsKey(codec)) {\n              producers.put(codec, codec.fieldsProducer(new SegmentReadState(dir,\n                                                                             si, fieldInfos, readBufferSize, indexDivisor, \"\"+fi.codecId)));\n            }\n            codecs.put(fi.name, producers.get(codec));\n          }\n        }\n        success = true;\n      } finally {\n        if (!success) {\n          // If we hit exception (eg, IOE because writer was\n          // committing, or, for any other reason) we must\n          // go back and close all FieldsProducers we opened:\n          for(FieldsProducer fp : producers.values()) {\n            try {\n              fp.close();\n            } catch (Throwable t) {\n              // Suppress all exceptions here so we continue\n              // to throw the original one\n            }\n          }\n        }\n      }\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c0ef0193974807e4bddf5432a6b0287fe4d6c9df","date":1301476645,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/PerFieldCodecWrapper.FieldsReader#FieldsReader(Directory,FieldInfos,SegmentInfo,int,int).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/PerFieldCodecWrapper.FieldsReader#FieldsReader(Directory,FieldInfos,SegmentInfo,int,int).mjava","sourceNew":"    public FieldsReader(Directory dir, FieldInfos fieldInfos, SegmentInfo si,\n        int readBufferSize, int indexDivisor) throws IOException {\n\n      final Map<Codec, FieldsProducer> producers = new HashMap<Codec, FieldsProducer>();\n      boolean success = false;\n      try {\n        for (FieldInfo fi : fieldInfos) {\n          if (fi.isIndexed) { // TODO this does not work for non-indexed fields\n            fields.add(fi.name);\n            assert fi.getCodecId() != FieldInfo.UNASSIGNED_CODEC_ID;\n            Codec codec = segmentCodecs.codecs[fi.getCodecId()];\n            if (!producers.containsKey(codec)) {\n              producers.put(codec, codec.fieldsProducer(new SegmentReadState(dir,\n                                                                             si, fieldInfos, readBufferSize, indexDivisor, \"\"+fi.getCodecId())));\n            }\n            codecs.put(fi.name, producers.get(codec));\n          }\n        }\n        success = true;\n      } finally {\n        if (!success) {\n          // If we hit exception (eg, IOE because writer was\n          // committing, or, for any other reason) we must\n          // go back and close all FieldsProducers we opened:\n          for(FieldsProducer fp : producers.values()) {\n            try {\n              fp.close();\n            } catch (Throwable t) {\n              // Suppress all exceptions here so we continue\n              // to throw the original one\n            }\n          }\n        }\n      }\n    }\n\n","sourceOld":"    public FieldsReader(Directory dir, FieldInfos fieldInfos, SegmentInfo si,\n        int readBufferSize, int indexDivisor) throws IOException {\n\n      final Map<Codec, FieldsProducer> producers = new HashMap<Codec, FieldsProducer>();\n      boolean success = false;\n      try {\n        for (FieldInfo fi : fieldInfos) {\n          if (fi.isIndexed) { // TODO this does not work for non-indexed fields\n            fields.add(fi.name);\n            Codec codec = segmentCodecs.codecs[fi.getCodecId()];\n            if (!producers.containsKey(codec)) {\n              producers.put(codec, codec.fieldsProducer(new SegmentReadState(dir,\n                                                                             si, fieldInfos, readBufferSize, indexDivisor, \"\"+fi.getCodecId())));\n            }\n            codecs.put(fi.name, producers.get(codec));\n          }\n        }\n        success = true;\n      } finally {\n        if (!success) {\n          // If we hit exception (eg, IOE because writer was\n          // committing, or, for any other reason) we must\n          // go back and close all FieldsProducers we opened:\n          for(FieldsProducer fp : producers.values()) {\n            try {\n              fp.close();\n            } catch (Throwable t) {\n              // Suppress all exceptions here so we continue\n              // to throw the original one\n            }\n          }\n        }\n      }\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"135621f3a0670a9394eb563224a3b76cc4dddc0f","date":1304344257,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/PerFieldCodecWrapper.FieldsReader#FieldsReader(Directory,FieldInfos,SegmentInfo,int,int).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/PerFieldCodecWrapper.FieldsReader#FieldsReader(Directory,FieldInfos,SegmentInfo,int,int).mjava","sourceNew":"    public FieldsReader(Directory dir, FieldInfos fieldInfos, SegmentInfo si,\n        int readBufferSize, int indexDivisor) throws IOException {\n\n      final Map<Codec, FieldsProducer> producers = new HashMap<Codec, FieldsProducer>();\n      boolean success = false;\n      try {\n        for (FieldInfo fi : fieldInfos) {\n          if (fi.isIndexed) { \n            fields.add(fi.name);\n            assert fi.getCodecId() != FieldInfo.UNASSIGNED_CODEC_ID;\n            Codec codec = segmentCodecs.codecs[fi.getCodecId()];\n            if (!producers.containsKey(codec)) {\n              producers.put(codec, codec.fieldsProducer(new SegmentReadState(dir,\n                                                                             si, fieldInfos, readBufferSize, indexDivisor, fi.getCodecId())));\n            }\n            codecs.put(fi.name, producers.get(codec));\n          }\n        }\n        success = true;\n      } finally {\n        if (!success) {\n          // If we hit exception (eg, IOE because writer was\n          // committing, or, for any other reason) we must\n          // go back and close all FieldsProducers we opened:\n          for(FieldsProducer fp : producers.values()) {\n            try {\n              fp.close();\n            } catch (Throwable t) {\n              // Suppress all exceptions here so we continue\n              // to throw the original one\n            }\n          }\n        }\n      }\n    }\n\n","sourceOld":"    public FieldsReader(Directory dir, FieldInfos fieldInfos, SegmentInfo si,\n        int readBufferSize, int indexDivisor) throws IOException {\n\n      final Map<Codec, FieldsProducer> producers = new HashMap<Codec, FieldsProducer>();\n      boolean success = false;\n      try {\n        for (FieldInfo fi : fieldInfos) {\n          if (fi.isIndexed || fi.hasDocValues()) { // TODO this does not work for non-indexed fields\n            fields.add(fi.name);\n            assert fi.getCodecId() != FieldInfo.UNASSIGNED_CODEC_ID;\n            Codec codec = segmentCodecs.codecs[fi.getCodecId()];\n            if (!producers.containsKey(codec)) {\n              producers.put(codec, codec.fieldsProducer(new SegmentReadState(dir,\n                                                                             si, fieldInfos, readBufferSize, indexDivisor, fi.getCodecId())));\n            }\n            codecs.put(fi.name, producers.get(codec));\n          }\n        }\n        success = true;\n      } finally {\n        if (!success) {\n          // If we hit exception (eg, IOE because writer was\n          // committing, or, for any other reason) we must\n          // go back and close all FieldsProducers we opened:\n          for(FieldsProducer fp : producers.values()) {\n            try {\n              fp.close();\n            } catch (Throwable t) {\n              // Suppress all exceptions here so we continue\n              // to throw the original one\n            }\n          }\n        }\n      }\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"efb7a19703a037c29e30440260d393500febc1f4","date":1306648116,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/PerFieldCodecWrapper.FieldsReader#FieldsReader(Directory,FieldInfos,SegmentInfo,int,int).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/PerFieldCodecWrapper.FieldsReader#FieldsReader(Directory,FieldInfos,SegmentInfo,int,int).mjava","sourceNew":"    public FieldsReader(Directory dir, FieldInfos fieldInfos, SegmentInfo si,\n        int readBufferSize, int indexDivisor) throws IOException {\n\n      final Map<Codec, FieldsProducer> producers = new HashMap<Codec, FieldsProducer>();\n      boolean success = false;\n      try {\n        for (FieldInfo fi : fieldInfos) {\n          if (fi.isIndexed) { // TODO this does not work for non-indexed fields\n            fields.add(fi.name);\n            assert fi.getCodecId() != FieldInfo.UNASSIGNED_CODEC_ID;\n            Codec codec = segmentCodecs.codecs[fi.getCodecId()];\n            if (!producers.containsKey(codec)) {\n              producers.put(codec, codec.fieldsProducer(new SegmentReadState(dir,\n                                                                             si, fieldInfos, readBufferSize, indexDivisor, \"\"+fi.getCodecId())));\n            }\n            codecs.put(fi.name, producers.get(codec));\n          }\n        }\n        success = true;\n      } finally {\n        if (!success) {\n          // If we hit exception (eg, IOE because writer was\n          // committing, or, for any other reason) we must\n          // go back and close all FieldsProducers we opened:\n          IOUtils.closeSafely(true, producers.values());\n        }\n      }\n    }\n\n","sourceOld":"    public FieldsReader(Directory dir, FieldInfos fieldInfos, SegmentInfo si,\n        int readBufferSize, int indexDivisor) throws IOException {\n\n      final Map<Codec, FieldsProducer> producers = new HashMap<Codec, FieldsProducer>();\n      boolean success = false;\n      try {\n        for (FieldInfo fi : fieldInfos) {\n          if (fi.isIndexed) { // TODO this does not work for non-indexed fields\n            fields.add(fi.name);\n            assert fi.getCodecId() != FieldInfo.UNASSIGNED_CODEC_ID;\n            Codec codec = segmentCodecs.codecs[fi.getCodecId()];\n            if (!producers.containsKey(codec)) {\n              producers.put(codec, codec.fieldsProducer(new SegmentReadState(dir,\n                                                                             si, fieldInfos, readBufferSize, indexDivisor, \"\"+fi.getCodecId())));\n            }\n            codecs.put(fi.name, producers.get(codec));\n          }\n        }\n        success = true;\n      } finally {\n        if (!success) {\n          // If we hit exception (eg, IOE because writer was\n          // committing, or, for any other reason) we must\n          // go back and close all FieldsProducers we opened:\n          for(FieldsProducer fp : producers.values()) {\n            try {\n              fp.close();\n            } catch (Throwable t) {\n              // Suppress all exceptions here so we continue\n              // to throw the original one\n            }\n          }\n        }\n      }\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5128b7b3b73fedff05fdc5ea2e6be53c1020bb91","date":1306767085,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/PerFieldCodecWrapper.FieldsReader#FieldsReader(Directory,FieldInfos,SegmentInfo,int,int).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/PerFieldCodecWrapper.FieldsReader#FieldsReader(Directory,FieldInfos,SegmentInfo,int,int).mjava","sourceNew":"    public FieldsReader(Directory dir, FieldInfos fieldInfos, SegmentInfo si,\n        int readBufferSize, int indexDivisor) throws IOException {\n\n      final Map<Codec, FieldsProducer> producers = new HashMap<Codec, FieldsProducer>();\n      boolean success = false;\n      try {\n        for (FieldInfo fi : fieldInfos) {\n          if (fi.isIndexed) { // TODO this does not work for non-indexed fields\n            fields.add(fi.name);\n            assert fi.getCodecId() != FieldInfo.UNASSIGNED_CODEC_ID;\n            Codec codec = segmentCodecs.codecs[fi.getCodecId()];\n            if (!producers.containsKey(codec)) {\n              producers.put(codec, codec.fieldsProducer(new SegmentReadState(dir,\n                                                                             si, fieldInfos, readBufferSize, indexDivisor, \"\"+fi.getCodecId())));\n            }\n            codecs.put(fi.name, producers.get(codec));\n          }\n        }\n        success = true;\n      } finally {\n        if (!success) {\n          // If we hit exception (eg, IOE because writer was\n          // committing, or, for any other reason) we must\n          // go back and close all FieldsProducers we opened:\n          IOUtils.closeSafely(true, producers.values());\n        }\n      }\n    }\n\n","sourceOld":"    public FieldsReader(Directory dir, FieldInfos fieldInfos, SegmentInfo si,\n        int readBufferSize, int indexDivisor) throws IOException {\n\n      final Map<Codec, FieldsProducer> producers = new HashMap<Codec, FieldsProducer>();\n      boolean success = false;\n      try {\n        for (FieldInfo fi : fieldInfos) {\n          if (fi.isIndexed) { // TODO this does not work for non-indexed fields\n            fields.add(fi.name);\n            assert fi.getCodecId() != FieldInfo.UNASSIGNED_CODEC_ID;\n            Codec codec = segmentCodecs.codecs[fi.getCodecId()];\n            if (!producers.containsKey(codec)) {\n              producers.put(codec, codec.fieldsProducer(new SegmentReadState(dir,\n                                                                             si, fieldInfos, readBufferSize, indexDivisor, \"\"+fi.getCodecId())));\n            }\n            codecs.put(fi.name, producers.get(codec));\n          }\n        }\n        success = true;\n      } finally {\n        if (!success) {\n          // If we hit exception (eg, IOE because writer was\n          // committing, or, for any other reason) we must\n          // go back and close all FieldsProducers we opened:\n          for(FieldsProducer fp : producers.values()) {\n            try {\n              fp.close();\n            } catch (Throwable t) {\n              // Suppress all exceptions here so we continue\n              // to throw the original one\n            }\n          }\n        }\n      }\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2e10cb22a8bdb44339e282925a29182bb2f3174d","date":1306841137,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/PerFieldCodecWrapper.FieldsReader#FieldsReader(Directory,FieldInfos,SegmentInfo,int,int).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/PerFieldCodecWrapper.FieldsReader#FieldsReader(Directory,FieldInfos,SegmentInfo,int,int).mjava","sourceNew":"    public FieldsReader(Directory dir, FieldInfos fieldInfos, SegmentInfo si,\n        int readBufferSize, int indexDivisor) throws IOException {\n\n      final Map<Codec, FieldsProducer> producers = new HashMap<Codec, FieldsProducer>();\n      boolean success = false;\n      try {\n        for (FieldInfo fi : fieldInfos) {\n          if (fi.isIndexed) { \n            fields.add(fi.name);\n            assert fi.getCodecId() != FieldInfo.UNASSIGNED_CODEC_ID;\n            Codec codec = segmentCodecs.codecs[fi.getCodecId()];\n            if (!producers.containsKey(codec)) {\n              producers.put(codec, codec.fieldsProducer(new SegmentReadState(dir,\n                                                                             si, fieldInfos, readBufferSize, indexDivisor, fi.getCodecId())));\n            }\n            codecs.put(fi.name, producers.get(codec));\n          }\n        }\n        success = true;\n      } finally {\n        if (!success) {\n          // If we hit exception (eg, IOE because writer was\n          // committing, or, for any other reason) we must\n          // go back and close all FieldsProducers we opened:\n          IOUtils.closeSafely(true, producers.values());\n        }\n      }\n    }\n\n","sourceOld":"    public FieldsReader(Directory dir, FieldInfos fieldInfos, SegmentInfo si,\n        int readBufferSize, int indexDivisor) throws IOException {\n\n      final Map<Codec, FieldsProducer> producers = new HashMap<Codec, FieldsProducer>();\n      boolean success = false;\n      try {\n        for (FieldInfo fi : fieldInfos) {\n          if (fi.isIndexed) { \n            fields.add(fi.name);\n            assert fi.getCodecId() != FieldInfo.UNASSIGNED_CODEC_ID;\n            Codec codec = segmentCodecs.codecs[fi.getCodecId()];\n            if (!producers.containsKey(codec)) {\n              producers.put(codec, codec.fieldsProducer(new SegmentReadState(dir,\n                                                                             si, fieldInfos, readBufferSize, indexDivisor, fi.getCodecId())));\n            }\n            codecs.put(fi.name, producers.get(codec));\n          }\n        }\n        success = true;\n      } finally {\n        if (!success) {\n          // If we hit exception (eg, IOE because writer was\n          // committing, or, for any other reason) we must\n          // go back and close all FieldsProducers we opened:\n          for(FieldsProducer fp : producers.values()) {\n            try {\n              fp.close();\n            } catch (Throwable t) {\n              // Suppress all exceptions here so we continue\n              // to throw the original one\n            }\n          }\n        }\n      }\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2e8d7ba2175f47e280231533f7d3016249cea88b","date":1307711934,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/PerFieldCodecWrapper.FieldsReader#FieldsReader(Directory,FieldInfos,SegmentInfo,int,int).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/PerFieldCodecWrapper.FieldsReader#FieldsReader(Directory,FieldInfos,SegmentInfo,int,int).mjava","sourceNew":"    public FieldsReader(Directory dir, FieldInfos fieldInfos, SegmentInfo si,\n        int readBufferSize, int indexDivisor) throws IOException {\n\n      final Map<Codec, FieldsProducer> producers = new HashMap<Codec, FieldsProducer>();\n      boolean success = false;\n      try {\n        for (FieldInfo fi : fieldInfos) {\n          if (fi.isIndexed) { \n            fields.add(fi.name);\n            assert fi.getCodecId() != FieldInfo.UNASSIGNED_CODEC_ID;\n            Codec codec = segmentCodecs.codecs[fi.getCodecId()];\n            if (!producers.containsKey(codec)) {\n              producers.put(codec, codec.fieldsProducer(new SegmentReadState(dir,\n                                                                             si, fieldInfos, readBufferSize, indexDivisor, fi.getCodecId())));\n            }\n            codecs.put(fi.name, producers.get(codec));\n          }\n        }\n        success = true;\n      } finally {\n        if (!success) {\n          // If we hit exception (eg, IOE because writer was\n          // committing, or, for any other reason) we must\n          // go back and close all FieldsProducers we opened:\n          IOUtils.closeSafely(true, producers.values());\n        }\n      }\n    }\n\n","sourceOld":"    public FieldsReader(Directory dir, FieldInfos fieldInfos, SegmentInfo si,\n        int readBufferSize, int indexDivisor) throws IOException {\n\n      final Map<Codec, FieldsProducer> producers = new HashMap<Codec, FieldsProducer>();\n      boolean success = false;\n      try {\n        for (FieldInfo fi : fieldInfos) {\n          if (fi.isIndexed) { // TODO this does not work for non-indexed fields\n            fields.add(fi.name);\n            assert fi.getCodecId() != FieldInfo.UNASSIGNED_CODEC_ID;\n            Codec codec = segmentCodecs.codecs[fi.getCodecId()];\n            if (!producers.containsKey(codec)) {\n              producers.put(codec, codec.fieldsProducer(new SegmentReadState(dir,\n                                                                             si, fieldInfos, readBufferSize, indexDivisor, \"\"+fi.getCodecId())));\n            }\n            codecs.put(fi.name, producers.get(codec));\n          }\n        }\n        success = true;\n      } finally {\n        if (!success) {\n          // If we hit exception (eg, IOE because writer was\n          // committing, or, for any other reason) we must\n          // go back and close all FieldsProducers we opened:\n          IOUtils.closeSafely(true, producers.values());\n        }\n      }\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a02058e0eaba4bbd5d05e6b06b9522c0acfd1655","date":1307729864,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/PerFieldCodecWrapper.FieldsReader#FieldsReader(Directory,FieldInfos,SegmentInfo,int,int).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/PerFieldCodecWrapper.FieldsReader#FieldsReader(Directory,FieldInfos,SegmentInfo,int,int).mjava","sourceNew":"    public FieldsReader(Directory dir, FieldInfos fieldInfos, SegmentInfo si,\n        int readBufferSize, int indexDivisor) throws IOException {\n\n      final Map<Codec, FieldsProducer> producers = new HashMap<Codec, FieldsProducer>();\n      boolean success = false;\n      try {\n        for (FieldInfo fi : fieldInfos) {\n          if (fi.isIndexed) { \n            fields.add(fi.name);\n            assert fi.getCodecId() != FieldInfo.UNASSIGNED_CODEC_ID;\n            Codec codec = segmentCodecs.codecs[fi.getCodecId()];\n            if (!producers.containsKey(codec)) {\n              producers.put(codec, codec.fieldsProducer(new SegmentReadState(dir,\n                                                                             si, fieldInfos, readBufferSize, indexDivisor, fi.getCodecId())));\n            }\n            codecs.put(fi.name, producers.get(codec));\n          }\n        }\n        success = true;\n      } finally {\n        if (!success) {\n          // If we hit exception (eg, IOE because writer was\n          // committing, or, for any other reason) we must\n          // go back and close all FieldsProducers we opened:\n          IOUtils.closeSafely(true, producers.values());\n        }\n      }\n    }\n\n","sourceOld":"    public FieldsReader(Directory dir, FieldInfos fieldInfos, SegmentInfo si,\n        int readBufferSize, int indexDivisor) throws IOException {\n\n      final Map<Codec, FieldsProducer> producers = new HashMap<Codec, FieldsProducer>();\n      boolean success = false;\n      try {\n        for (FieldInfo fi : fieldInfos) {\n          if (fi.isIndexed) { // TODO this does not work for non-indexed fields\n            fields.add(fi.name);\n            assert fi.getCodecId() != FieldInfo.UNASSIGNED_CODEC_ID;\n            Codec codec = segmentCodecs.codecs[fi.getCodecId()];\n            if (!producers.containsKey(codec)) {\n              producers.put(codec, codec.fieldsProducer(new SegmentReadState(dir,\n                                                                             si, fieldInfos, readBufferSize, indexDivisor, \"\"+fi.getCodecId())));\n            }\n            codecs.put(fi.name, producers.get(codec));\n          }\n        }\n        success = true;\n      } finally {\n        if (!success) {\n          // If we hit exception (eg, IOE because writer was\n          // committing, or, for any other reason) we must\n          // go back and close all FieldsProducers we opened:\n          IOUtils.closeSafely(true, producers.values());\n        }\n      }\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"639c36565ce03aed5b0fce7c9e4448e53a1f7efd","date":1308580104,"type":5,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/PerFieldCodecWrapper.FieldsReader#FieldsReader(Directory,FieldInfos,SegmentInfo,IOContext,int).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/PerFieldCodecWrapper.FieldsReader#FieldsReader(Directory,FieldInfos,SegmentInfo,int,int).mjava","sourceNew":"    public FieldsReader(Directory dir, FieldInfos fieldInfos, SegmentInfo si,\n        IOContext context, int indexDivisor) throws IOException {\n\n      final Map<Codec, FieldsProducer> producers = new HashMap<Codec, FieldsProducer>();\n      boolean success = false;\n      try {\n        for (FieldInfo fi : fieldInfos) {\n          if (fi.isIndexed) { \n            fields.add(fi.name);\n            assert fi.getCodecId() != FieldInfo.UNASSIGNED_CODEC_ID;\n            Codec codec = segmentCodecs.codecs[fi.getCodecId()];\n            if (!producers.containsKey(codec)) {\n              producers.put(codec, codec.fieldsProducer(new SegmentReadState(dir,\n                                                                             si, fieldInfos, context, indexDivisor, fi.getCodecId())));\n            }\n            codecs.put(fi.name, producers.get(codec));\n          }\n        }\n        success = true;\n      } finally {\n        if (!success) {\n          // If we hit exception (eg, IOE because writer was\n          // committing, or, for any other reason) we must\n          // go back and close all FieldsProducers we opened:\n          IOUtils.closeSafely(true, producers.values());\n        }\n      }\n    }\n\n","sourceOld":"    public FieldsReader(Directory dir, FieldInfos fieldInfos, SegmentInfo si,\n        int readBufferSize, int indexDivisor) throws IOException {\n\n      final Map<Codec, FieldsProducer> producers = new HashMap<Codec, FieldsProducer>();\n      boolean success = false;\n      try {\n        for (FieldInfo fi : fieldInfos) {\n          if (fi.isIndexed) { \n            fields.add(fi.name);\n            assert fi.getCodecId() != FieldInfo.UNASSIGNED_CODEC_ID;\n            Codec codec = segmentCodecs.codecs[fi.getCodecId()];\n            if (!producers.containsKey(codec)) {\n              producers.put(codec, codec.fieldsProducer(new SegmentReadState(dir,\n                                                                             si, fieldInfos, readBufferSize, indexDivisor, fi.getCodecId())));\n            }\n            codecs.put(fi.name, producers.get(codec));\n          }\n        }\n        success = true;\n      } finally {\n        if (!success) {\n          // If we hit exception (eg, IOE because writer was\n          // committing, or, for any other reason) we must\n          // go back and close all FieldsProducers we opened:\n          IOUtils.closeSafely(true, producers.values());\n        }\n      }\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ddc4c914be86e34b54f70023f45a60fa7f04e929","date":1310115160,"type":5,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/PerFieldCodecWrapper.FieldsReader#FieldsReader(Directory,FieldInfos,SegmentInfo,IOContext,int).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/PerFieldCodecWrapper.FieldsReader#FieldsReader(Directory,FieldInfos,SegmentInfo,int,int).mjava","sourceNew":"    public FieldsReader(Directory dir, FieldInfos fieldInfos, SegmentInfo si,\n        IOContext context, int indexDivisor) throws IOException {\n\n      final Map<Codec, FieldsProducer> producers = new HashMap<Codec, FieldsProducer>();\n      boolean success = false;\n      try {\n        for (FieldInfo fi : fieldInfos) {\n          if (fi.isIndexed) { \n            fields.add(fi.name);\n            assert fi.getCodecId() != FieldInfo.UNASSIGNED_CODEC_ID;\n            Codec codec = segmentCodecs.codecs[fi.getCodecId()];\n            if (!producers.containsKey(codec)) {\n              producers.put(codec, codec.fieldsProducer(new SegmentReadState(dir,\n                                                                             si, fieldInfos, context, indexDivisor, fi.getCodecId())));\n            }\n            codecs.put(fi.name, producers.get(codec));\n          }\n        }\n        success = true;\n      } finally {\n        if (!success) {\n          // If we hit exception (eg, IOE because writer was\n          // committing, or, for any other reason) we must\n          // go back and close all FieldsProducers we opened:\n          IOUtils.closeSafely(true, producers.values());\n        }\n      }\n    }\n\n","sourceOld":"    public FieldsReader(Directory dir, FieldInfos fieldInfos, SegmentInfo si,\n        int readBufferSize, int indexDivisor) throws IOException {\n\n      final Map<Codec, FieldsProducer> producers = new HashMap<Codec, FieldsProducer>();\n      boolean success = false;\n      try {\n        for (FieldInfo fi : fieldInfos) {\n          if (fi.isIndexed) { \n            fields.add(fi.name);\n            assert fi.getCodecId() != FieldInfo.UNASSIGNED_CODEC_ID;\n            Codec codec = segmentCodecs.codecs[fi.getCodecId()];\n            if (!producers.containsKey(codec)) {\n              producers.put(codec, codec.fieldsProducer(new SegmentReadState(dir,\n                                                                             si, fieldInfos, readBufferSize, indexDivisor, fi.getCodecId())));\n            }\n            codecs.put(fi.name, producers.get(codec));\n          }\n        }\n        success = true;\n      } finally {\n        if (!success) {\n          // If we hit exception (eg, IOE because writer was\n          // committing, or, for any other reason) we must\n          // go back and close all FieldsProducers we opened:\n          IOUtils.closeSafely(true, producers.values());\n        }\n      }\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5d004d0e0b3f65bb40da76d476d659d7888270e8","date":1310158940,"type":5,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/PerFieldCodecWrapper.FieldsReader#FieldsReader(Directory,FieldInfos,SegmentInfo,IOContext,int).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/PerFieldCodecWrapper.FieldsReader#FieldsReader(Directory,FieldInfos,SegmentInfo,int,int).mjava","sourceNew":"    public FieldsReader(Directory dir, FieldInfos fieldInfos, SegmentInfo si,\n        IOContext context, int indexDivisor) throws IOException {\n\n      final Map<Codec, FieldsProducer> producers = new HashMap<Codec, FieldsProducer>();\n      boolean success = false;\n      try {\n        for (FieldInfo fi : fieldInfos) {\n          if (fi.isIndexed) { \n            fields.add(fi.name);\n            assert fi.getCodecId() != FieldInfo.UNASSIGNED_CODEC_ID;\n            Codec codec = segmentCodecs.codecs[fi.getCodecId()];\n            if (!producers.containsKey(codec)) {\n              producers.put(codec, codec.fieldsProducer(new SegmentReadState(dir,\n                                                                             si, fieldInfos, context, indexDivisor, fi.getCodecId())));\n            }\n            codecs.put(fi.name, producers.get(codec));\n          }\n        }\n        success = true;\n      } finally {\n        if (!success) {\n          // If we hit exception (eg, IOE because writer was\n          // committing, or, for any other reason) we must\n          // go back and close all FieldsProducers we opened:\n          IOUtils.closeSafely(true, producers.values());\n        }\n      }\n    }\n\n","sourceOld":"    public FieldsReader(Directory dir, FieldInfos fieldInfos, SegmentInfo si,\n        int readBufferSize, int indexDivisor) throws IOException {\n\n      final Map<Codec, FieldsProducer> producers = new HashMap<Codec, FieldsProducer>();\n      boolean success = false;\n      try {\n        for (FieldInfo fi : fieldInfos) {\n          if (fi.isIndexed) { \n            fields.add(fi.name);\n            assert fi.getCodecId() != FieldInfo.UNASSIGNED_CODEC_ID;\n            Codec codec = segmentCodecs.codecs[fi.getCodecId()];\n            if (!producers.containsKey(codec)) {\n              producers.put(codec, codec.fieldsProducer(new SegmentReadState(dir,\n                                                                             si, fieldInfos, readBufferSize, indexDivisor, fi.getCodecId())));\n            }\n            codecs.put(fi.name, producers.get(codec));\n          }\n        }\n        success = true;\n      } finally {\n        if (!success) {\n          // If we hit exception (eg, IOE because writer was\n          // committing, or, for any other reason) we must\n          // go back and close all FieldsProducers we opened:\n          IOUtils.closeSafely(true, producers.values());\n        }\n      }\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"efb7a19703a037c29e30440260d393500febc1f4":["e92442af786151ee55bc283eb472f629e3c7b52b"],"a493e6d0c3ad86bd55c0a1360d110142e948f2bd":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"639c36565ce03aed5b0fce7c9e4448e53a1f7efd":["2e8d7ba2175f47e280231533f7d3016249cea88b"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","8a3c2cd46c82df9039659ca61b07cd39503f06b2"],"e92442af786151ee55bc283eb472f629e3c7b52b":["1224a4027481acce15495b03bce9b48b93b42722"],"2e8d7ba2175f47e280231533f7d3016249cea88b":["efb7a19703a037c29e30440260d393500febc1f4","2e10cb22a8bdb44339e282925a29182bb2f3174d"],"c0ef0193974807e4bddf5432a6b0287fe4d6c9df":["bde51b089eb7f86171eb3406e38a274743f9b7ac","e92442af786151ee55bc283eb472f629e3c7b52b"],"14ec33385f6fbb6ce172882d14605790418a5d31":["b0c7a8f7304b75b1528814c5820fa23a96816c27"],"5128b7b3b73fedff05fdc5ea2e6be53c1020bb91":["e92442af786151ee55bc283eb472f629e3c7b52b","efb7a19703a037c29e30440260d393500febc1f4"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"5d004d0e0b3f65bb40da76d476d659d7888270e8":["a02058e0eaba4bbd5d05e6b06b9522c0acfd1655","ddc4c914be86e34b54f70023f45a60fa7f04e929"],"ddc4c914be86e34b54f70023f45a60fa7f04e929":["2e8d7ba2175f47e280231533f7d3016249cea88b","639c36565ce03aed5b0fce7c9e4448e53a1f7efd"],"bde51b089eb7f86171eb3406e38a274743f9b7ac":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","b0c7a8f7304b75b1528814c5820fa23a96816c27"],"1224a4027481acce15495b03bce9b48b93b42722":["14ec33385f6fbb6ce172882d14605790418a5d31"],"2e10cb22a8bdb44339e282925a29182bb2f3174d":["135621f3a0670a9394eb563224a3b76cc4dddc0f","efb7a19703a037c29e30440260d393500febc1f4"],"a02058e0eaba4bbd5d05e6b06b9522c0acfd1655":["5128b7b3b73fedff05fdc5ea2e6be53c1020bb91","2e8d7ba2175f47e280231533f7d3016249cea88b"],"16c697f6ca5cdc82f918f753317a4ac9c70d259f":["a493e6d0c3ad86bd55c0a1360d110142e948f2bd"],"9ab1f5591dc05f1f2b5407d809c9699f75554a32":["85a883878c0af761245ab048babc63d099f835f3","16c697f6ca5cdc82f918f753317a4ac9c70d259f"],"85a883878c0af761245ab048babc63d099f835f3":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","a493e6d0c3ad86bd55c0a1360d110142e948f2bd"],"135621f3a0670a9394eb563224a3b76cc4dddc0f":["d619839baa8ce5503e496b94a9e42ad6f079293f","e92442af786151ee55bc283eb472f629e3c7b52b"],"ab5cb6a74aefb78aa0569857970b9151dfe2e787":["9ab1f5591dc05f1f2b5407d809c9699f75554a32","8a3c2cd46c82df9039659ca61b07cd39503f06b2"],"d619839baa8ce5503e496b94a9e42ad6f079293f":["ab5cb6a74aefb78aa0569857970b9151dfe2e787","e92442af786151ee55bc283eb472f629e3c7b52b"],"b0c7a8f7304b75b1528814c5820fa23a96816c27":["8a3c2cd46c82df9039659ca61b07cd39503f06b2"],"8a3c2cd46c82df9039659ca61b07cd39503f06b2":["16c697f6ca5cdc82f918f753317a4ac9c70d259f"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["ddc4c914be86e34b54f70023f45a60fa7f04e929"]},"commit2Childs":{"efb7a19703a037c29e30440260d393500febc1f4":["2e8d7ba2175f47e280231533f7d3016249cea88b","5128b7b3b73fedff05fdc5ea2e6be53c1020bb91","2e10cb22a8bdb44339e282925a29182bb2f3174d"],"a493e6d0c3ad86bd55c0a1360d110142e948f2bd":["16c697f6ca5cdc82f918f753317a4ac9c70d259f","85a883878c0af761245ab048babc63d099f835f3"],"639c36565ce03aed5b0fce7c9e4448e53a1f7efd":["ddc4c914be86e34b54f70023f45a60fa7f04e929"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":["bde51b089eb7f86171eb3406e38a274743f9b7ac"],"e92442af786151ee55bc283eb472f629e3c7b52b":["efb7a19703a037c29e30440260d393500febc1f4","c0ef0193974807e4bddf5432a6b0287fe4d6c9df","5128b7b3b73fedff05fdc5ea2e6be53c1020bb91","135621f3a0670a9394eb563224a3b76cc4dddc0f","d619839baa8ce5503e496b94a9e42ad6f079293f"],"2e8d7ba2175f47e280231533f7d3016249cea88b":["639c36565ce03aed5b0fce7c9e4448e53a1f7efd","ddc4c914be86e34b54f70023f45a60fa7f04e929","a02058e0eaba4bbd5d05e6b06b9522c0acfd1655"],"c0ef0193974807e4bddf5432a6b0287fe4d6c9df":[],"14ec33385f6fbb6ce172882d14605790418a5d31":["1224a4027481acce15495b03bce9b48b93b42722"],"5128b7b3b73fedff05fdc5ea2e6be53c1020bb91":["a02058e0eaba4bbd5d05e6b06b9522c0acfd1655"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["a493e6d0c3ad86bd55c0a1360d110142e948f2bd","7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","85a883878c0af761245ab048babc63d099f835f3"],"5d004d0e0b3f65bb40da76d476d659d7888270e8":[],"ddc4c914be86e34b54f70023f45a60fa7f04e929":["5d004d0e0b3f65bb40da76d476d659d7888270e8","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"bde51b089eb7f86171eb3406e38a274743f9b7ac":["c0ef0193974807e4bddf5432a6b0287fe4d6c9df"],"1224a4027481acce15495b03bce9b48b93b42722":["e92442af786151ee55bc283eb472f629e3c7b52b"],"2e10cb22a8bdb44339e282925a29182bb2f3174d":["2e8d7ba2175f47e280231533f7d3016249cea88b"],"a02058e0eaba4bbd5d05e6b06b9522c0acfd1655":["5d004d0e0b3f65bb40da76d476d659d7888270e8"],"16c697f6ca5cdc82f918f753317a4ac9c70d259f":["9ab1f5591dc05f1f2b5407d809c9699f75554a32","8a3c2cd46c82df9039659ca61b07cd39503f06b2"],"9ab1f5591dc05f1f2b5407d809c9699f75554a32":["ab5cb6a74aefb78aa0569857970b9151dfe2e787"],"135621f3a0670a9394eb563224a3b76cc4dddc0f":["2e10cb22a8bdb44339e282925a29182bb2f3174d"],"85a883878c0af761245ab048babc63d099f835f3":["9ab1f5591dc05f1f2b5407d809c9699f75554a32"],"ab5cb6a74aefb78aa0569857970b9151dfe2e787":["d619839baa8ce5503e496b94a9e42ad6f079293f"],"d619839baa8ce5503e496b94a9e42ad6f079293f":["135621f3a0670a9394eb563224a3b76cc4dddc0f"],"b0c7a8f7304b75b1528814c5820fa23a96816c27":["14ec33385f6fbb6ce172882d14605790418a5d31","bde51b089eb7f86171eb3406e38a274743f9b7ac"],"8a3c2cd46c82df9039659ca61b07cd39503f06b2":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","ab5cb6a74aefb78aa0569857970b9151dfe2e787","b0c7a8f7304b75b1528814c5820fa23a96816c27"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["c0ef0193974807e4bddf5432a6b0287fe4d6c9df","5d004d0e0b3f65bb40da76d476d659d7888270e8","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}