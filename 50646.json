{"path":"lucene/src/test/org/apache/lucene/index/TestDocValuesIndexing#testSortedBytes().mjava","commits":[{"id":"5eae7c5ddae4b9692a6691d2d252ab6a4229457b","date":1325870827,"type":0,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestDocValuesIndexing#testSortedBytes().mjava","pathOld":"/dev/null","sourceNew":"  public void testSortedBytes() throws IOException {\n    Type[] types = new Type[] { Type.BYTES_FIXED_SORTED, Type.BYTES_VAR_SORTED };\n    for (Type type : types) {\n      boolean fixed = type == Type.BYTES_FIXED_SORTED;\n      final Directory d = newDirectory();\n      IndexWriterConfig cfg = newIndexWriterConfig(TEST_VERSION_CURRENT,\n          new MockAnalyzer(random));\n      IndexWriter w = new IndexWriter(d, cfg);\n      Comparator<BytesRef> comp = BytesRef.getUTF8SortedAsUnicodeComparator();\n      int numDocs = atLeast(100);\n      BytesRefHash hash = new BytesRefHash();\n      Map<String, String> docToString = new HashMap<String, String>();\n      int len = 1 + random.nextInt(50);\n      for (int i = 0; i < numDocs; i++) {\n        Document doc = new Document();\n        doc.add(newField(\"id\", \"\" + i, TextField.TYPE_STORED));\n        DocValuesField f = new DocValuesField(\"field\");\n        String string =fixed ? _TestUtil.randomFixedByteLengthUnicodeString(random,\n            len) : _TestUtil.randomRealisticUnicodeString(random, 1, len);\n        hash.add(new BytesRef(string));\n        docToString.put(\"\" + i, string);\n\n        f.setBytes(new BytesRef(string), type, comp);\n        doc.add(f);\n        w.addDocument(doc);\n      }\n      if (rarely()) {\n        w.commit();\n      }\n      int numDocsNoValue = atLeast(10);\n      for (int i = 0; i < numDocsNoValue; i++) {\n        Document doc = new Document();\n        doc.add(newField(\"id\", \"noValue\", TextField.TYPE_STORED));\n        w.addDocument(doc);\n      }\n      BytesRef bytesRef = new BytesRef(fixed ? len : 0);\n      bytesRef.offset = 0;\n      bytesRef.length = fixed ? len : 0;\n      hash.add(bytesRef); // add empty value for the gaps\n      if (rarely()) {\n        w.commit();\n      }\n      for (int i = 0; i < numDocs; i++) {\n        Document doc = new Document();\n        String id = \"\" + i + numDocs;\n        doc.add(newField(\"id\", id, TextField.TYPE_STORED));\n        DocValuesField f = new DocValuesField(\"field\");\n        String string = fixed ? _TestUtil.randomFixedByteLengthUnicodeString(random,\n            len) : _TestUtil.randomRealisticUnicodeString(random, 1, len);\n        hash.add(new BytesRef(string));\n        docToString.put(id, string);\n        f.setBytes(new BytesRef(string), type, comp);\n        doc.add(f);\n        w.addDocument(doc);\n      }\n      w.commit();\n      IndexReader reader = w.getReader();\n      DocValues docValues = MultiDocValues.getDocValues(reader, \"field\");\n      Source source = getSource(docValues);\n      SortedSource asSortedSource = source.asSortedSource();\n      int[] sort = hash.sort(comp);\n      BytesRef expected = new BytesRef();\n      BytesRef actual = new BytesRef();\n      assertEquals(hash.size(), asSortedSource.getValueCount());\n      for (int i = 0; i < hash.size(); i++) {\n        hash.get(sort[i], expected);\n        asSortedSource.getByOrd(i, actual);\n        assertEquals(expected.utf8ToString(), actual.utf8ToString());\n        int ord = asSortedSource.getByValue(expected, actual);\n        assertEquals(i, ord);\n      }\n      reader = new SlowMultiReaderWrapper(reader);\n      Set<Entry<String, String>> entrySet = docToString.entrySet();\n\n      for (Entry<String, String> entry : entrySet) {\n        int docId = docId(reader, new Term(\"id\", entry.getKey()));\n        expected.copyChars(entry.getValue());\n        assertEquals(expected, asSortedSource.getBytes(docId, actual));\n      }\n\n      reader.close();\n      w.close();\n      d.close();\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["fa0f44f887719e97183771e977cfc4bfb485b766","04f07771a2a7dd3a395700665ed839c3dae2def2","ecb9a70c11e1f9dea44bb46bc2f75ed0c2603b57"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"fa0f44f887719e97183771e977cfc4bfb485b766","date":1326668713,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestDocValuesIndexing#testSortedBytes().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestDocValuesIndexing#testSortedBytes().mjava","sourceNew":"  public void testSortedBytes() throws IOException {\n    Type[] types = new Type[] { Type.BYTES_FIXED_SORTED, Type.BYTES_VAR_SORTED };\n    for (Type type : types) {\n      boolean fixed = type == Type.BYTES_FIXED_SORTED;\n      final Directory d = newDirectory();\n      IndexWriterConfig cfg = newIndexWriterConfig(TEST_VERSION_CURRENT,\n          new MockAnalyzer(random));\n      IndexWriter w = new IndexWriter(d, cfg);\n      int numDocs = atLeast(100);\n      BytesRefHash hash = new BytesRefHash();\n      Map<String, String> docToString = new HashMap<String, String>();\n      int len = 1 + random.nextInt(50);\n      for (int i = 0; i < numDocs; i++) {\n        Document doc = new Document();\n        doc.add(newField(\"id\", \"\" + i, TextField.TYPE_STORED));\n        String string =fixed ? _TestUtil.randomFixedByteLengthUnicodeString(random,\n            len) : _TestUtil.randomRealisticUnicodeString(random, 1, len);\n        BytesRef br = new BytesRef(string);\n        doc.add(new DocValuesField(\"field\", br, type));\n        hash.add(br);\n        docToString.put(\"\" + i, string);\n        w.addDocument(doc);\n      }\n      if (rarely()) {\n        w.commit();\n      }\n      int numDocsNoValue = atLeast(10);\n      for (int i = 0; i < numDocsNoValue; i++) {\n        Document doc = new Document();\n        doc.add(newField(\"id\", \"noValue\", TextField.TYPE_STORED));\n        w.addDocument(doc);\n      }\n      BytesRef bytesRef = new BytesRef(fixed ? len : 0);\n      bytesRef.offset = 0;\n      bytesRef.length = fixed ? len : 0;\n      hash.add(bytesRef); // add empty value for the gaps\n      if (rarely()) {\n        w.commit();\n      }\n      for (int i = 0; i < numDocs; i++) {\n        Document doc = new Document();\n        String id = \"\" + i + numDocs;\n        doc.add(newField(\"id\", id, TextField.TYPE_STORED));\n        String string = fixed ? _TestUtil.randomFixedByteLengthUnicodeString(random,\n            len) : _TestUtil.randomRealisticUnicodeString(random, 1, len);\n        BytesRef br = new BytesRef(string);\n        hash.add(br);\n        docToString.put(id, string);\n        doc.add( new DocValuesField(\"field\", br, type));\n        w.addDocument(doc);\n      }\n      w.commit();\n      IndexReader reader = w.getReader();\n      DocValues docValues = MultiDocValues.getDocValues(reader, \"field\");\n      Source source = getSource(docValues);\n      SortedSource asSortedSource = source.asSortedSource();\n      int[] sort = hash.sort(BytesRef.getUTF8SortedAsUnicodeComparator());\n      BytesRef expected = new BytesRef();\n      BytesRef actual = new BytesRef();\n      assertEquals(hash.size(), asSortedSource.getValueCount());\n      for (int i = 0; i < hash.size(); i++) {\n        hash.get(sort[i], expected);\n        asSortedSource.getByOrd(i, actual);\n        assertEquals(expected.utf8ToString(), actual.utf8ToString());\n        int ord = asSortedSource.getByValue(expected, actual);\n        assertEquals(i, ord);\n      }\n      reader = new SlowMultiReaderWrapper(reader);\n      Set<Entry<String, String>> entrySet = docToString.entrySet();\n\n      for (Entry<String, String> entry : entrySet) {\n        int docId = docId(reader, new Term(\"id\", entry.getKey()));\n        expected.copyChars(entry.getValue());\n        assertEquals(expected, asSortedSource.getBytes(docId, actual));\n      }\n\n      reader.close();\n      w.close();\n      d.close();\n    }\n  }\n\n","sourceOld":"  public void testSortedBytes() throws IOException {\n    Type[] types = new Type[] { Type.BYTES_FIXED_SORTED, Type.BYTES_VAR_SORTED };\n    for (Type type : types) {\n      boolean fixed = type == Type.BYTES_FIXED_SORTED;\n      final Directory d = newDirectory();\n      IndexWriterConfig cfg = newIndexWriterConfig(TEST_VERSION_CURRENT,\n          new MockAnalyzer(random));\n      IndexWriter w = new IndexWriter(d, cfg);\n      Comparator<BytesRef> comp = BytesRef.getUTF8SortedAsUnicodeComparator();\n      int numDocs = atLeast(100);\n      BytesRefHash hash = new BytesRefHash();\n      Map<String, String> docToString = new HashMap<String, String>();\n      int len = 1 + random.nextInt(50);\n      for (int i = 0; i < numDocs; i++) {\n        Document doc = new Document();\n        doc.add(newField(\"id\", \"\" + i, TextField.TYPE_STORED));\n        DocValuesField f = new DocValuesField(\"field\");\n        String string =fixed ? _TestUtil.randomFixedByteLengthUnicodeString(random,\n            len) : _TestUtil.randomRealisticUnicodeString(random, 1, len);\n        hash.add(new BytesRef(string));\n        docToString.put(\"\" + i, string);\n\n        f.setBytes(new BytesRef(string), type, comp);\n        doc.add(f);\n        w.addDocument(doc);\n      }\n      if (rarely()) {\n        w.commit();\n      }\n      int numDocsNoValue = atLeast(10);\n      for (int i = 0; i < numDocsNoValue; i++) {\n        Document doc = new Document();\n        doc.add(newField(\"id\", \"noValue\", TextField.TYPE_STORED));\n        w.addDocument(doc);\n      }\n      BytesRef bytesRef = new BytesRef(fixed ? len : 0);\n      bytesRef.offset = 0;\n      bytesRef.length = fixed ? len : 0;\n      hash.add(bytesRef); // add empty value for the gaps\n      if (rarely()) {\n        w.commit();\n      }\n      for (int i = 0; i < numDocs; i++) {\n        Document doc = new Document();\n        String id = \"\" + i + numDocs;\n        doc.add(newField(\"id\", id, TextField.TYPE_STORED));\n        DocValuesField f = new DocValuesField(\"field\");\n        String string = fixed ? _TestUtil.randomFixedByteLengthUnicodeString(random,\n            len) : _TestUtil.randomRealisticUnicodeString(random, 1, len);\n        hash.add(new BytesRef(string));\n        docToString.put(id, string);\n        f.setBytes(new BytesRef(string), type, comp);\n        doc.add(f);\n        w.addDocument(doc);\n      }\n      w.commit();\n      IndexReader reader = w.getReader();\n      DocValues docValues = MultiDocValues.getDocValues(reader, \"field\");\n      Source source = getSource(docValues);\n      SortedSource asSortedSource = source.asSortedSource();\n      int[] sort = hash.sort(comp);\n      BytesRef expected = new BytesRef();\n      BytesRef actual = new BytesRef();\n      assertEquals(hash.size(), asSortedSource.getValueCount());\n      for (int i = 0; i < hash.size(); i++) {\n        hash.get(sort[i], expected);\n        asSortedSource.getByOrd(i, actual);\n        assertEquals(expected.utf8ToString(), actual.utf8ToString());\n        int ord = asSortedSource.getByValue(expected, actual);\n        assertEquals(i, ord);\n      }\n      reader = new SlowMultiReaderWrapper(reader);\n      Set<Entry<String, String>> entrySet = docToString.entrySet();\n\n      for (Entry<String, String> entry : entrySet) {\n        int docId = docId(reader, new Term(\"id\", entry.getKey()));\n        expected.copyChars(entry.getValue());\n        assertEquals(expected, asSortedSource.getBytes(docId, actual));\n      }\n\n      reader.close();\n      w.close();\n      d.close();\n    }\n  }\n\n","bugFix":["5eae7c5ddae4b9692a6691d2d252ab6a4229457b"],"bugIntro":["cd659803551ebd8ca09b9e4ad7abd18d3d558f9d"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"386d1b0dcb065f1bfc494b1407cb41c536b95485","date":1327848512,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestDocValuesIndexing#testSortedBytes().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestDocValuesIndexing#testSortedBytes().mjava","sourceNew":"  public void testSortedBytes() throws IOException {\n    Type[] types = new Type[] { Type.BYTES_FIXED_SORTED, Type.BYTES_VAR_SORTED };\n    for (Type type : types) {\n      boolean fixed = type == Type.BYTES_FIXED_SORTED;\n      final Directory d = newDirectory();\n      IndexWriterConfig cfg = newIndexWriterConfig(TEST_VERSION_CURRENT,\n          new MockAnalyzer(random));\n      IndexWriter w = new IndexWriter(d, cfg);\n      int numDocs = atLeast(100);\n      BytesRefHash hash = new BytesRefHash();\n      Map<String, String> docToString = new HashMap<String, String>();\n      int len = 1 + random.nextInt(50);\n      for (int i = 0; i < numDocs; i++) {\n        Document doc = new Document();\n        doc.add(newField(\"id\", \"\" + i, TextField.TYPE_STORED));\n        String string =fixed ? _TestUtil.randomFixedByteLengthUnicodeString(random,\n            len) : _TestUtil.randomRealisticUnicodeString(random, 1, len);\n        BytesRef br = new BytesRef(string);\n        doc.add(new DocValuesField(\"field\", br, type));\n        hash.add(br);\n        docToString.put(\"\" + i, string);\n        w.addDocument(doc);\n      }\n      if (rarely()) {\n        w.commit();\n      }\n      int numDocsNoValue = atLeast(10);\n      for (int i = 0; i < numDocsNoValue; i++) {\n        Document doc = new Document();\n        doc.add(newField(\"id\", \"noValue\", TextField.TYPE_STORED));\n        w.addDocument(doc);\n      }\n      BytesRef bytesRef = new BytesRef(fixed ? len : 0);\n      bytesRef.offset = 0;\n      bytesRef.length = fixed ? len : 0;\n      hash.add(bytesRef); // add empty value for the gaps\n      if (rarely()) {\n        w.commit();\n      }\n      for (int i = 0; i < numDocs; i++) {\n        Document doc = new Document();\n        String id = \"\" + i + numDocs;\n        doc.add(newField(\"id\", id, TextField.TYPE_STORED));\n        String string = fixed ? _TestUtil.randomFixedByteLengthUnicodeString(random,\n            len) : _TestUtil.randomRealisticUnicodeString(random, 1, len);\n        BytesRef br = new BytesRef(string);\n        hash.add(br);\n        docToString.put(id, string);\n        doc.add( new DocValuesField(\"field\", br, type));\n        w.addDocument(doc);\n      }\n      w.commit();\n      IndexReader reader = w.getReader();\n      DocValues docValues = MultiDocValues.getDocValues(reader, \"field\");\n      Source source = getSource(docValues);\n      SortedSource asSortedSource = source.asSortedSource();\n      int[] sort = hash.sort(BytesRef.getUTF8SortedAsUnicodeComparator());\n      BytesRef expected = new BytesRef();\n      BytesRef actual = new BytesRef();\n      assertEquals(hash.size(), asSortedSource.getValueCount());\n      for (int i = 0; i < hash.size(); i++) {\n        hash.get(sort[i], expected);\n        asSortedSource.getByOrd(i, actual);\n        assertEquals(expected.utf8ToString(), actual.utf8ToString());\n        int ord = asSortedSource.getByValue(expected, actual);\n        assertEquals(i, ord);\n      }\n      reader = SlowCompositeReaderWrapper.wrap(reader);\n      Set<Entry<String, String>> entrySet = docToString.entrySet();\n\n      for (Entry<String, String> entry : entrySet) {\n        int docId = docId(reader, new Term(\"id\", entry.getKey()));\n        expected.copyChars(entry.getValue());\n        assertEquals(expected, asSortedSource.getBytes(docId, actual));\n      }\n\n      reader.close();\n      w.close();\n      d.close();\n    }\n  }\n\n","sourceOld":"  public void testSortedBytes() throws IOException {\n    Type[] types = new Type[] { Type.BYTES_FIXED_SORTED, Type.BYTES_VAR_SORTED };\n    for (Type type : types) {\n      boolean fixed = type == Type.BYTES_FIXED_SORTED;\n      final Directory d = newDirectory();\n      IndexWriterConfig cfg = newIndexWriterConfig(TEST_VERSION_CURRENT,\n          new MockAnalyzer(random));\n      IndexWriter w = new IndexWriter(d, cfg);\n      int numDocs = atLeast(100);\n      BytesRefHash hash = new BytesRefHash();\n      Map<String, String> docToString = new HashMap<String, String>();\n      int len = 1 + random.nextInt(50);\n      for (int i = 0; i < numDocs; i++) {\n        Document doc = new Document();\n        doc.add(newField(\"id\", \"\" + i, TextField.TYPE_STORED));\n        String string =fixed ? _TestUtil.randomFixedByteLengthUnicodeString(random,\n            len) : _TestUtil.randomRealisticUnicodeString(random, 1, len);\n        BytesRef br = new BytesRef(string);\n        doc.add(new DocValuesField(\"field\", br, type));\n        hash.add(br);\n        docToString.put(\"\" + i, string);\n        w.addDocument(doc);\n      }\n      if (rarely()) {\n        w.commit();\n      }\n      int numDocsNoValue = atLeast(10);\n      for (int i = 0; i < numDocsNoValue; i++) {\n        Document doc = new Document();\n        doc.add(newField(\"id\", \"noValue\", TextField.TYPE_STORED));\n        w.addDocument(doc);\n      }\n      BytesRef bytesRef = new BytesRef(fixed ? len : 0);\n      bytesRef.offset = 0;\n      bytesRef.length = fixed ? len : 0;\n      hash.add(bytesRef); // add empty value for the gaps\n      if (rarely()) {\n        w.commit();\n      }\n      for (int i = 0; i < numDocs; i++) {\n        Document doc = new Document();\n        String id = \"\" + i + numDocs;\n        doc.add(newField(\"id\", id, TextField.TYPE_STORED));\n        String string = fixed ? _TestUtil.randomFixedByteLengthUnicodeString(random,\n            len) : _TestUtil.randomRealisticUnicodeString(random, 1, len);\n        BytesRef br = new BytesRef(string);\n        hash.add(br);\n        docToString.put(id, string);\n        doc.add( new DocValuesField(\"field\", br, type));\n        w.addDocument(doc);\n      }\n      w.commit();\n      IndexReader reader = w.getReader();\n      DocValues docValues = MultiDocValues.getDocValues(reader, \"field\");\n      Source source = getSource(docValues);\n      SortedSource asSortedSource = source.asSortedSource();\n      int[] sort = hash.sort(BytesRef.getUTF8SortedAsUnicodeComparator());\n      BytesRef expected = new BytesRef();\n      BytesRef actual = new BytesRef();\n      assertEquals(hash.size(), asSortedSource.getValueCount());\n      for (int i = 0; i < hash.size(); i++) {\n        hash.get(sort[i], expected);\n        asSortedSource.getByOrd(i, actual);\n        assertEquals(expected.utf8ToString(), actual.utf8ToString());\n        int ord = asSortedSource.getByValue(expected, actual);\n        assertEquals(i, ord);\n      }\n      reader = new SlowMultiReaderWrapper(reader);\n      Set<Entry<String, String>> entrySet = docToString.entrySet();\n\n      for (Entry<String, String> entry : entrySet) {\n        int docId = docId(reader, new Term(\"id\", entry.getKey()));\n        expected.copyChars(entry.getValue());\n        assertEquals(expected, asSortedSource.getBytes(docId, actual));\n      }\n\n      reader.close();\n      w.close();\n      d.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"868186558eb3a854ce7e720a52bb445795d54910","date":1327853682,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestDocValuesIndexing#testSortedBytes().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestDocValuesIndexing#testSortedBytes().mjava","sourceNew":"  public void testSortedBytes() throws IOException {\n    Type[] types = new Type[] { Type.BYTES_FIXED_SORTED, Type.BYTES_VAR_SORTED };\n    for (Type type : types) {\n      boolean fixed = type == Type.BYTES_FIXED_SORTED;\n      final Directory d = newDirectory();\n      IndexWriterConfig cfg = newIndexWriterConfig(TEST_VERSION_CURRENT,\n          new MockAnalyzer(random));\n      IndexWriter w = new IndexWriter(d, cfg);\n      int numDocs = atLeast(100);\n      BytesRefHash hash = new BytesRefHash();\n      Map<String, String> docToString = new HashMap<String, String>();\n      int len = 1 + random.nextInt(50);\n      for (int i = 0; i < numDocs; i++) {\n        Document doc = new Document();\n        doc.add(newField(\"id\", \"\" + i, TextField.TYPE_STORED));\n        String string =fixed ? _TestUtil.randomFixedByteLengthUnicodeString(random,\n            len) : _TestUtil.randomRealisticUnicodeString(random, 1, len);\n        BytesRef br = new BytesRef(string);\n        doc.add(new DocValuesField(\"field\", br, type));\n        hash.add(br);\n        docToString.put(\"\" + i, string);\n        w.addDocument(doc);\n      }\n      if (rarely()) {\n        w.commit();\n      }\n      int numDocsNoValue = atLeast(10);\n      for (int i = 0; i < numDocsNoValue; i++) {\n        Document doc = new Document();\n        doc.add(newField(\"id\", \"noValue\", TextField.TYPE_STORED));\n        w.addDocument(doc);\n      }\n      BytesRef bytesRef = new BytesRef(fixed ? len : 0);\n      bytesRef.offset = 0;\n      bytesRef.length = fixed ? len : 0;\n      hash.add(bytesRef); // add empty value for the gaps\n      if (rarely()) {\n        w.commit();\n      }\n      for (int i = 0; i < numDocs; i++) {\n        Document doc = new Document();\n        String id = \"\" + i + numDocs;\n        doc.add(newField(\"id\", id, TextField.TYPE_STORED));\n        String string = fixed ? _TestUtil.randomFixedByteLengthUnicodeString(random,\n            len) : _TestUtil.randomRealisticUnicodeString(random, 1, len);\n        BytesRef br = new BytesRef(string);\n        hash.add(br);\n        docToString.put(id, string);\n        doc.add( new DocValuesField(\"field\", br, type));\n        w.addDocument(doc);\n      }\n      w.commit();\n      IndexReader reader = w.getReader();\n      DocValues docValues = MultiDocValues.getDocValues(reader, \"field\");\n      Source source = getSource(docValues);\n      SortedSource asSortedSource = source.asSortedSource();\n      int[] sort = hash.sort(BytesRef.getUTF8SortedAsUnicodeComparator());\n      BytesRef expected = new BytesRef();\n      BytesRef actual = new BytesRef();\n      assertEquals(hash.size(), asSortedSource.getValueCount());\n      for (int i = 0; i < hash.size(); i++) {\n        hash.get(sort[i], expected);\n        asSortedSource.getByOrd(i, actual);\n        assertEquals(expected.utf8ToString(), actual.utf8ToString());\n        int ord = asSortedSource.getByValue(expected, actual);\n        assertEquals(i, ord);\n      }\n      AtomicIndexReader slowR = SlowCompositeReaderWrapper.wrap(reader);\n      Set<Entry<String, String>> entrySet = docToString.entrySet();\n\n      for (Entry<String, String> entry : entrySet) {\n        int docId = docId(slowR, new Term(\"id\", entry.getKey()));\n        expected.copyChars(entry.getValue());\n        assertEquals(expected, asSortedSource.getBytes(docId, actual));\n      }\n\n      reader.close();\n      w.close();\n      d.close();\n    }\n  }\n\n","sourceOld":"  public void testSortedBytes() throws IOException {\n    Type[] types = new Type[] { Type.BYTES_FIXED_SORTED, Type.BYTES_VAR_SORTED };\n    for (Type type : types) {\n      boolean fixed = type == Type.BYTES_FIXED_SORTED;\n      final Directory d = newDirectory();\n      IndexWriterConfig cfg = newIndexWriterConfig(TEST_VERSION_CURRENT,\n          new MockAnalyzer(random));\n      IndexWriter w = new IndexWriter(d, cfg);\n      int numDocs = atLeast(100);\n      BytesRefHash hash = new BytesRefHash();\n      Map<String, String> docToString = new HashMap<String, String>();\n      int len = 1 + random.nextInt(50);\n      for (int i = 0; i < numDocs; i++) {\n        Document doc = new Document();\n        doc.add(newField(\"id\", \"\" + i, TextField.TYPE_STORED));\n        String string =fixed ? _TestUtil.randomFixedByteLengthUnicodeString(random,\n            len) : _TestUtil.randomRealisticUnicodeString(random, 1, len);\n        BytesRef br = new BytesRef(string);\n        doc.add(new DocValuesField(\"field\", br, type));\n        hash.add(br);\n        docToString.put(\"\" + i, string);\n        w.addDocument(doc);\n      }\n      if (rarely()) {\n        w.commit();\n      }\n      int numDocsNoValue = atLeast(10);\n      for (int i = 0; i < numDocsNoValue; i++) {\n        Document doc = new Document();\n        doc.add(newField(\"id\", \"noValue\", TextField.TYPE_STORED));\n        w.addDocument(doc);\n      }\n      BytesRef bytesRef = new BytesRef(fixed ? len : 0);\n      bytesRef.offset = 0;\n      bytesRef.length = fixed ? len : 0;\n      hash.add(bytesRef); // add empty value for the gaps\n      if (rarely()) {\n        w.commit();\n      }\n      for (int i = 0; i < numDocs; i++) {\n        Document doc = new Document();\n        String id = \"\" + i + numDocs;\n        doc.add(newField(\"id\", id, TextField.TYPE_STORED));\n        String string = fixed ? _TestUtil.randomFixedByteLengthUnicodeString(random,\n            len) : _TestUtil.randomRealisticUnicodeString(random, 1, len);\n        BytesRef br = new BytesRef(string);\n        hash.add(br);\n        docToString.put(id, string);\n        doc.add( new DocValuesField(\"field\", br, type));\n        w.addDocument(doc);\n      }\n      w.commit();\n      IndexReader reader = w.getReader();\n      DocValues docValues = MultiDocValues.getDocValues(reader, \"field\");\n      Source source = getSource(docValues);\n      SortedSource asSortedSource = source.asSortedSource();\n      int[] sort = hash.sort(BytesRef.getUTF8SortedAsUnicodeComparator());\n      BytesRef expected = new BytesRef();\n      BytesRef actual = new BytesRef();\n      assertEquals(hash.size(), asSortedSource.getValueCount());\n      for (int i = 0; i < hash.size(); i++) {\n        hash.get(sort[i], expected);\n        asSortedSource.getByOrd(i, actual);\n        assertEquals(expected.utf8ToString(), actual.utf8ToString());\n        int ord = asSortedSource.getByValue(expected, actual);\n        assertEquals(i, ord);\n      }\n      reader = SlowCompositeReaderWrapper.wrap(reader);\n      Set<Entry<String, String>> entrySet = docToString.entrySet();\n\n      for (Entry<String, String> entry : entrySet) {\n        int docId = docId(reader, new Term(\"id\", entry.getKey()));\n        expected.copyChars(entry.getValue());\n        assertEquals(expected, asSortedSource.getBytes(docId, actual));\n      }\n\n      reader.close();\n      w.close();\n      d.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"da6d5ac19a80d65b1e864251f155d30960353b7e","date":1327881054,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestDocValuesIndexing#testSortedBytes().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestDocValuesIndexing#testSortedBytes().mjava","sourceNew":"  public void testSortedBytes() throws IOException {\n    Type[] types = new Type[] { Type.BYTES_FIXED_SORTED, Type.BYTES_VAR_SORTED };\n    for (Type type : types) {\n      boolean fixed = type == Type.BYTES_FIXED_SORTED;\n      final Directory d = newDirectory();\n      IndexWriterConfig cfg = newIndexWriterConfig(TEST_VERSION_CURRENT,\n          new MockAnalyzer(random));\n      IndexWriter w = new IndexWriter(d, cfg);\n      int numDocs = atLeast(100);\n      BytesRefHash hash = new BytesRefHash();\n      Map<String, String> docToString = new HashMap<String, String>();\n      int len = 1 + random.nextInt(50);\n      for (int i = 0; i < numDocs; i++) {\n        Document doc = new Document();\n        doc.add(newField(\"id\", \"\" + i, TextField.TYPE_STORED));\n        String string =fixed ? _TestUtil.randomFixedByteLengthUnicodeString(random,\n            len) : _TestUtil.randomRealisticUnicodeString(random, 1, len);\n        BytesRef br = new BytesRef(string);\n        doc.add(new DocValuesField(\"field\", br, type));\n        hash.add(br);\n        docToString.put(\"\" + i, string);\n        w.addDocument(doc);\n      }\n      if (rarely()) {\n        w.commit();\n      }\n      int numDocsNoValue = atLeast(10);\n      for (int i = 0; i < numDocsNoValue; i++) {\n        Document doc = new Document();\n        doc.add(newField(\"id\", \"noValue\", TextField.TYPE_STORED));\n        w.addDocument(doc);\n      }\n      BytesRef bytesRef = new BytesRef(fixed ? len : 0);\n      bytesRef.offset = 0;\n      bytesRef.length = fixed ? len : 0;\n      hash.add(bytesRef); // add empty value for the gaps\n      if (rarely()) {\n        w.commit();\n      }\n      for (int i = 0; i < numDocs; i++) {\n        Document doc = new Document();\n        String id = \"\" + i + numDocs;\n        doc.add(newField(\"id\", id, TextField.TYPE_STORED));\n        String string = fixed ? _TestUtil.randomFixedByteLengthUnicodeString(random,\n            len) : _TestUtil.randomRealisticUnicodeString(random, 1, len);\n        BytesRef br = new BytesRef(string);\n        hash.add(br);\n        docToString.put(id, string);\n        doc.add( new DocValuesField(\"field\", br, type));\n        w.addDocument(doc);\n      }\n      w.commit();\n      IndexReader reader = w.getReader();\n      DocValues docValues = MultiDocValues.getDocValues(reader, \"field\");\n      Source source = getSource(docValues);\n      SortedSource asSortedSource = source.asSortedSource();\n      int[] sort = hash.sort(BytesRef.getUTF8SortedAsUnicodeComparator());\n      BytesRef expected = new BytesRef();\n      BytesRef actual = new BytesRef();\n      assertEquals(hash.size(), asSortedSource.getValueCount());\n      for (int i = 0; i < hash.size(); i++) {\n        hash.get(sort[i], expected);\n        asSortedSource.getByOrd(i, actual);\n        assertEquals(expected.utf8ToString(), actual.utf8ToString());\n        int ord = asSortedSource.getByValue(expected, actual);\n        assertEquals(i, ord);\n      }\n      AtomicReader slowR = SlowCompositeReaderWrapper.wrap(reader);\n      Set<Entry<String, String>> entrySet = docToString.entrySet();\n\n      for (Entry<String, String> entry : entrySet) {\n        int docId = docId(slowR, new Term(\"id\", entry.getKey()));\n        expected.copyChars(entry.getValue());\n        assertEquals(expected, asSortedSource.getBytes(docId, actual));\n      }\n\n      reader.close();\n      w.close();\n      d.close();\n    }\n  }\n\n","sourceOld":"  public void testSortedBytes() throws IOException {\n    Type[] types = new Type[] { Type.BYTES_FIXED_SORTED, Type.BYTES_VAR_SORTED };\n    for (Type type : types) {\n      boolean fixed = type == Type.BYTES_FIXED_SORTED;\n      final Directory d = newDirectory();\n      IndexWriterConfig cfg = newIndexWriterConfig(TEST_VERSION_CURRENT,\n          new MockAnalyzer(random));\n      IndexWriter w = new IndexWriter(d, cfg);\n      int numDocs = atLeast(100);\n      BytesRefHash hash = new BytesRefHash();\n      Map<String, String> docToString = new HashMap<String, String>();\n      int len = 1 + random.nextInt(50);\n      for (int i = 0; i < numDocs; i++) {\n        Document doc = new Document();\n        doc.add(newField(\"id\", \"\" + i, TextField.TYPE_STORED));\n        String string =fixed ? _TestUtil.randomFixedByteLengthUnicodeString(random,\n            len) : _TestUtil.randomRealisticUnicodeString(random, 1, len);\n        BytesRef br = new BytesRef(string);\n        doc.add(new DocValuesField(\"field\", br, type));\n        hash.add(br);\n        docToString.put(\"\" + i, string);\n        w.addDocument(doc);\n      }\n      if (rarely()) {\n        w.commit();\n      }\n      int numDocsNoValue = atLeast(10);\n      for (int i = 0; i < numDocsNoValue; i++) {\n        Document doc = new Document();\n        doc.add(newField(\"id\", \"noValue\", TextField.TYPE_STORED));\n        w.addDocument(doc);\n      }\n      BytesRef bytesRef = new BytesRef(fixed ? len : 0);\n      bytesRef.offset = 0;\n      bytesRef.length = fixed ? len : 0;\n      hash.add(bytesRef); // add empty value for the gaps\n      if (rarely()) {\n        w.commit();\n      }\n      for (int i = 0; i < numDocs; i++) {\n        Document doc = new Document();\n        String id = \"\" + i + numDocs;\n        doc.add(newField(\"id\", id, TextField.TYPE_STORED));\n        String string = fixed ? _TestUtil.randomFixedByteLengthUnicodeString(random,\n            len) : _TestUtil.randomRealisticUnicodeString(random, 1, len);\n        BytesRef br = new BytesRef(string);\n        hash.add(br);\n        docToString.put(id, string);\n        doc.add( new DocValuesField(\"field\", br, type));\n        w.addDocument(doc);\n      }\n      w.commit();\n      IndexReader reader = w.getReader();\n      DocValues docValues = MultiDocValues.getDocValues(reader, \"field\");\n      Source source = getSource(docValues);\n      SortedSource asSortedSource = source.asSortedSource();\n      int[] sort = hash.sort(BytesRef.getUTF8SortedAsUnicodeComparator());\n      BytesRef expected = new BytesRef();\n      BytesRef actual = new BytesRef();\n      assertEquals(hash.size(), asSortedSource.getValueCount());\n      for (int i = 0; i < hash.size(); i++) {\n        hash.get(sort[i], expected);\n        asSortedSource.getByOrd(i, actual);\n        assertEquals(expected.utf8ToString(), actual.utf8ToString());\n        int ord = asSortedSource.getByValue(expected, actual);\n        assertEquals(i, ord);\n      }\n      AtomicIndexReader slowR = SlowCompositeReaderWrapper.wrap(reader);\n      Set<Entry<String, String>> entrySet = docToString.entrySet();\n\n      for (Entry<String, String> entry : entrySet) {\n        int docId = docId(slowR, new Term(\"id\", entry.getKey()));\n        expected.copyChars(entry.getValue());\n        assertEquals(expected, asSortedSource.getBytes(docId, actual));\n      }\n\n      reader.close();\n      w.close();\n      d.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"5cab9a86bd67202d20b6adc463008c8e982b070a","date":1327966443,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestDocValuesIndexing#testSortedBytes().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestDocValuesIndexing#testSortedBytes().mjava","sourceNew":"  public void testSortedBytes() throws IOException {\n    Type[] types = new Type[] { Type.BYTES_FIXED_SORTED, Type.BYTES_VAR_SORTED };\n    for (Type type : types) {\n      boolean fixed = type == Type.BYTES_FIXED_SORTED;\n      final Directory d = newDirectory();\n      IndexWriterConfig cfg = newIndexWriterConfig(TEST_VERSION_CURRENT,\n          new MockAnalyzer(random));\n      IndexWriter w = new IndexWriter(d, cfg);\n      int numDocs = atLeast(100);\n      BytesRefHash hash = new BytesRefHash();\n      Map<String, String> docToString = new HashMap<String, String>();\n      int len = 1 + random.nextInt(50);\n      for (int i = 0; i < numDocs; i++) {\n        Document doc = new Document();\n        doc.add(newField(\"id\", \"\" + i, TextField.TYPE_STORED));\n        String string =fixed ? _TestUtil.randomFixedByteLengthUnicodeString(random,\n            len) : _TestUtil.randomRealisticUnicodeString(random, 1, len);\n        BytesRef br = new BytesRef(string);\n        doc.add(new DocValuesField(\"field\", br, type));\n        hash.add(br);\n        docToString.put(\"\" + i, string);\n        w.addDocument(doc);\n      }\n      if (rarely()) {\n        w.commit();\n      }\n      int numDocsNoValue = atLeast(10);\n      for (int i = 0; i < numDocsNoValue; i++) {\n        Document doc = new Document();\n        doc.add(newField(\"id\", \"noValue\", TextField.TYPE_STORED));\n        w.addDocument(doc);\n      }\n      BytesRef bytesRef = new BytesRef(fixed ? len : 0);\n      bytesRef.offset = 0;\n      bytesRef.length = fixed ? len : 0;\n      hash.add(bytesRef); // add empty value for the gaps\n      if (rarely()) {\n        w.commit();\n      }\n      for (int i = 0; i < numDocs; i++) {\n        Document doc = new Document();\n        String id = \"\" + i + numDocs;\n        doc.add(newField(\"id\", id, TextField.TYPE_STORED));\n        String string = fixed ? _TestUtil.randomFixedByteLengthUnicodeString(random,\n            len) : _TestUtil.randomRealisticUnicodeString(random, 1, len);\n        BytesRef br = new BytesRef(string);\n        hash.add(br);\n        docToString.put(id, string);\n        doc.add( new DocValuesField(\"field\", br, type));\n        w.addDocument(doc);\n      }\n      w.commit();\n      IndexReader reader = w.getReader();\n      DocValues docValues = MultiDocValues.getDocValues(reader, \"field\");\n      Source source = getSource(docValues);\n      SortedSource asSortedSource = source.asSortedSource();\n      int[] sort = hash.sort(BytesRef.getUTF8SortedAsUnicodeComparator());\n      BytesRef expected = new BytesRef();\n      BytesRef actual = new BytesRef();\n      assertEquals(hash.size(), asSortedSource.getValueCount());\n      for (int i = 0; i < hash.size(); i++) {\n        hash.get(sort[i], expected);\n        asSortedSource.getByOrd(i, actual);\n        assertEquals(expected.utf8ToString(), actual.utf8ToString());\n        int ord = asSortedSource.getByValue(expected, actual);\n        assertEquals(i, ord);\n      }\n      AtomicReader slowR = SlowCompositeReaderWrapper.wrap(reader);\n      Set<Entry<String, String>> entrySet = docToString.entrySet();\n\n      for (Entry<String, String> entry : entrySet) {\n        int docId = docId(slowR, new Term(\"id\", entry.getKey()));\n        expected.copyChars(entry.getValue());\n        assertEquals(expected, asSortedSource.getBytes(docId, actual));\n      }\n\n      reader.close();\n      w.close();\n      d.close();\n    }\n  }\n\n","sourceOld":"  public void testSortedBytes() throws IOException {\n    Type[] types = new Type[] { Type.BYTES_FIXED_SORTED, Type.BYTES_VAR_SORTED };\n    for (Type type : types) {\n      boolean fixed = type == Type.BYTES_FIXED_SORTED;\n      final Directory d = newDirectory();\n      IndexWriterConfig cfg = newIndexWriterConfig(TEST_VERSION_CURRENT,\n          new MockAnalyzer(random));\n      IndexWriter w = new IndexWriter(d, cfg);\n      int numDocs = atLeast(100);\n      BytesRefHash hash = new BytesRefHash();\n      Map<String, String> docToString = new HashMap<String, String>();\n      int len = 1 + random.nextInt(50);\n      for (int i = 0; i < numDocs; i++) {\n        Document doc = new Document();\n        doc.add(newField(\"id\", \"\" + i, TextField.TYPE_STORED));\n        String string =fixed ? _TestUtil.randomFixedByteLengthUnicodeString(random,\n            len) : _TestUtil.randomRealisticUnicodeString(random, 1, len);\n        BytesRef br = new BytesRef(string);\n        doc.add(new DocValuesField(\"field\", br, type));\n        hash.add(br);\n        docToString.put(\"\" + i, string);\n        w.addDocument(doc);\n      }\n      if (rarely()) {\n        w.commit();\n      }\n      int numDocsNoValue = atLeast(10);\n      for (int i = 0; i < numDocsNoValue; i++) {\n        Document doc = new Document();\n        doc.add(newField(\"id\", \"noValue\", TextField.TYPE_STORED));\n        w.addDocument(doc);\n      }\n      BytesRef bytesRef = new BytesRef(fixed ? len : 0);\n      bytesRef.offset = 0;\n      bytesRef.length = fixed ? len : 0;\n      hash.add(bytesRef); // add empty value for the gaps\n      if (rarely()) {\n        w.commit();\n      }\n      for (int i = 0; i < numDocs; i++) {\n        Document doc = new Document();\n        String id = \"\" + i + numDocs;\n        doc.add(newField(\"id\", id, TextField.TYPE_STORED));\n        String string = fixed ? _TestUtil.randomFixedByteLengthUnicodeString(random,\n            len) : _TestUtil.randomRealisticUnicodeString(random, 1, len);\n        BytesRef br = new BytesRef(string);\n        hash.add(br);\n        docToString.put(id, string);\n        doc.add( new DocValuesField(\"field\", br, type));\n        w.addDocument(doc);\n      }\n      w.commit();\n      IndexReader reader = w.getReader();\n      DocValues docValues = MultiDocValues.getDocValues(reader, \"field\");\n      Source source = getSource(docValues);\n      SortedSource asSortedSource = source.asSortedSource();\n      int[] sort = hash.sort(BytesRef.getUTF8SortedAsUnicodeComparator());\n      BytesRef expected = new BytesRef();\n      BytesRef actual = new BytesRef();\n      assertEquals(hash.size(), asSortedSource.getValueCount());\n      for (int i = 0; i < hash.size(); i++) {\n        hash.get(sort[i], expected);\n        asSortedSource.getByOrd(i, actual);\n        assertEquals(expected.utf8ToString(), actual.utf8ToString());\n        int ord = asSortedSource.getByValue(expected, actual);\n        assertEquals(i, ord);\n      }\n      reader = new SlowMultiReaderWrapper(reader);\n      Set<Entry<String, String>> entrySet = docToString.entrySet();\n\n      for (Entry<String, String> entry : entrySet) {\n        int docId = docId(reader, new Term(\"id\", entry.getKey()));\n        expected.copyChars(entry.getValue());\n        assertEquals(expected, asSortedSource.getBytes(docId, actual));\n      }\n\n      reader.close();\n      w.close();\n      d.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":5,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDocValuesIndexing#testSortedBytes().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestDocValuesIndexing#testSortedBytes().mjava","sourceNew":"  public void testSortedBytes() throws IOException {\n    Type[] types = new Type[] { Type.BYTES_FIXED_SORTED, Type.BYTES_VAR_SORTED };\n    for (Type type : types) {\n      boolean fixed = type == Type.BYTES_FIXED_SORTED;\n      final Directory d = newDirectory();\n      IndexWriterConfig cfg = newIndexWriterConfig(TEST_VERSION_CURRENT,\n          new MockAnalyzer(random));\n      IndexWriter w = new IndexWriter(d, cfg);\n      int numDocs = atLeast(100);\n      BytesRefHash hash = new BytesRefHash();\n      Map<String, String> docToString = new HashMap<String, String>();\n      int len = 1 + random.nextInt(50);\n      for (int i = 0; i < numDocs; i++) {\n        Document doc = new Document();\n        doc.add(newField(\"id\", \"\" + i, TextField.TYPE_STORED));\n        String string =fixed ? _TestUtil.randomFixedByteLengthUnicodeString(random,\n            len) : _TestUtil.randomRealisticUnicodeString(random, 1, len);\n        BytesRef br = new BytesRef(string);\n        doc.add(new DocValuesField(\"field\", br, type));\n        hash.add(br);\n        docToString.put(\"\" + i, string);\n        w.addDocument(doc);\n      }\n      if (rarely()) {\n        w.commit();\n      }\n      int numDocsNoValue = atLeast(10);\n      for (int i = 0; i < numDocsNoValue; i++) {\n        Document doc = new Document();\n        doc.add(newField(\"id\", \"noValue\", TextField.TYPE_STORED));\n        w.addDocument(doc);\n      }\n      BytesRef bytesRef = new BytesRef(fixed ? len : 0);\n      bytesRef.offset = 0;\n      bytesRef.length = fixed ? len : 0;\n      hash.add(bytesRef); // add empty value for the gaps\n      if (rarely()) {\n        w.commit();\n      }\n      for (int i = 0; i < numDocs; i++) {\n        Document doc = new Document();\n        String id = \"\" + i + numDocs;\n        doc.add(newField(\"id\", id, TextField.TYPE_STORED));\n        String string = fixed ? _TestUtil.randomFixedByteLengthUnicodeString(random,\n            len) : _TestUtil.randomRealisticUnicodeString(random, 1, len);\n        BytesRef br = new BytesRef(string);\n        hash.add(br);\n        docToString.put(id, string);\n        doc.add( new DocValuesField(\"field\", br, type));\n        w.addDocument(doc);\n      }\n      w.commit();\n      IndexReader reader = w.getReader();\n      DocValues docValues = MultiDocValues.getDocValues(reader, \"field\");\n      Source source = getSource(docValues);\n      SortedSource asSortedSource = source.asSortedSource();\n      int[] sort = hash.sort(BytesRef.getUTF8SortedAsUnicodeComparator());\n      BytesRef expected = new BytesRef();\n      BytesRef actual = new BytesRef();\n      assertEquals(hash.size(), asSortedSource.getValueCount());\n      for (int i = 0; i < hash.size(); i++) {\n        hash.get(sort[i], expected);\n        asSortedSource.getByOrd(i, actual);\n        assertEquals(expected.utf8ToString(), actual.utf8ToString());\n        int ord = asSortedSource.getByValue(expected, actual);\n        assertEquals(i, ord);\n      }\n      AtomicReader slowR = SlowCompositeReaderWrapper.wrap(reader);\n      Set<Entry<String, String>> entrySet = docToString.entrySet();\n\n      for (Entry<String, String> entry : entrySet) {\n        int docId = docId(slowR, new Term(\"id\", entry.getKey()));\n        expected.copyChars(entry.getValue());\n        assertEquals(expected, asSortedSource.getBytes(docId, actual));\n      }\n\n      reader.close();\n      w.close();\n      d.close();\n    }\n  }\n\n","sourceOld":"  public void testSortedBytes() throws IOException {\n    Type[] types = new Type[] { Type.BYTES_FIXED_SORTED, Type.BYTES_VAR_SORTED };\n    for (Type type : types) {\n      boolean fixed = type == Type.BYTES_FIXED_SORTED;\n      final Directory d = newDirectory();\n      IndexWriterConfig cfg = newIndexWriterConfig(TEST_VERSION_CURRENT,\n          new MockAnalyzer(random));\n      IndexWriter w = new IndexWriter(d, cfg);\n      int numDocs = atLeast(100);\n      BytesRefHash hash = new BytesRefHash();\n      Map<String, String> docToString = new HashMap<String, String>();\n      int len = 1 + random.nextInt(50);\n      for (int i = 0; i < numDocs; i++) {\n        Document doc = new Document();\n        doc.add(newField(\"id\", \"\" + i, TextField.TYPE_STORED));\n        String string =fixed ? _TestUtil.randomFixedByteLengthUnicodeString(random,\n            len) : _TestUtil.randomRealisticUnicodeString(random, 1, len);\n        BytesRef br = new BytesRef(string);\n        doc.add(new DocValuesField(\"field\", br, type));\n        hash.add(br);\n        docToString.put(\"\" + i, string);\n        w.addDocument(doc);\n      }\n      if (rarely()) {\n        w.commit();\n      }\n      int numDocsNoValue = atLeast(10);\n      for (int i = 0; i < numDocsNoValue; i++) {\n        Document doc = new Document();\n        doc.add(newField(\"id\", \"noValue\", TextField.TYPE_STORED));\n        w.addDocument(doc);\n      }\n      BytesRef bytesRef = new BytesRef(fixed ? len : 0);\n      bytesRef.offset = 0;\n      bytesRef.length = fixed ? len : 0;\n      hash.add(bytesRef); // add empty value for the gaps\n      if (rarely()) {\n        w.commit();\n      }\n      for (int i = 0; i < numDocs; i++) {\n        Document doc = new Document();\n        String id = \"\" + i + numDocs;\n        doc.add(newField(\"id\", id, TextField.TYPE_STORED));\n        String string = fixed ? _TestUtil.randomFixedByteLengthUnicodeString(random,\n            len) : _TestUtil.randomRealisticUnicodeString(random, 1, len);\n        BytesRef br = new BytesRef(string);\n        hash.add(br);\n        docToString.put(id, string);\n        doc.add( new DocValuesField(\"field\", br, type));\n        w.addDocument(doc);\n      }\n      w.commit();\n      IndexReader reader = w.getReader();\n      DocValues docValues = MultiDocValues.getDocValues(reader, \"field\");\n      Source source = getSource(docValues);\n      SortedSource asSortedSource = source.asSortedSource();\n      int[] sort = hash.sort(BytesRef.getUTF8SortedAsUnicodeComparator());\n      BytesRef expected = new BytesRef();\n      BytesRef actual = new BytesRef();\n      assertEquals(hash.size(), asSortedSource.getValueCount());\n      for (int i = 0; i < hash.size(); i++) {\n        hash.get(sort[i], expected);\n        asSortedSource.getByOrd(i, actual);\n        assertEquals(expected.utf8ToString(), actual.utf8ToString());\n        int ord = asSortedSource.getByValue(expected, actual);\n        assertEquals(i, ord);\n      }\n      AtomicReader slowR = SlowCompositeReaderWrapper.wrap(reader);\n      Set<Entry<String, String>> entrySet = docToString.entrySet();\n\n      for (Entry<String, String> entry : entrySet) {\n        int docId = docId(slowR, new Term(\"id\", entry.getKey()));\n        expected.copyChars(entry.getValue());\n        assertEquals(expected, asSortedSource.getBytes(docId, actual));\n      }\n\n      reader.close();\n      w.close();\n      d.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"da6d5ac19a80d65b1e864251f155d30960353b7e":["868186558eb3a854ce7e720a52bb445795d54910"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["5cab9a86bd67202d20b6adc463008c8e982b070a"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"fa0f44f887719e97183771e977cfc4bfb485b766":["5eae7c5ddae4b9692a6691d2d252ab6a4229457b"],"386d1b0dcb065f1bfc494b1407cb41c536b95485":["fa0f44f887719e97183771e977cfc4bfb485b766"],"5cab9a86bd67202d20b6adc463008c8e982b070a":["fa0f44f887719e97183771e977cfc4bfb485b766","da6d5ac19a80d65b1e864251f155d30960353b7e"],"868186558eb3a854ce7e720a52bb445795d54910":["386d1b0dcb065f1bfc494b1407cb41c536b95485"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"5eae7c5ddae4b9692a6691d2d252ab6a4229457b":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"da6d5ac19a80d65b1e864251f155d30960353b7e":["5cab9a86bd67202d20b6adc463008c8e982b070a"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["5eae7c5ddae4b9692a6691d2d252ab6a4229457b"],"fa0f44f887719e97183771e977cfc4bfb485b766":["386d1b0dcb065f1bfc494b1407cb41c536b95485","5cab9a86bd67202d20b6adc463008c8e982b070a"],"386d1b0dcb065f1bfc494b1407cb41c536b95485":["868186558eb3a854ce7e720a52bb445795d54910"],"868186558eb3a854ce7e720a52bb445795d54910":["da6d5ac19a80d65b1e864251f155d30960353b7e"],"5cab9a86bd67202d20b6adc463008c8e982b070a":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"5eae7c5ddae4b9692a6691d2d252ab6a4229457b":["fa0f44f887719e97183771e977cfc4bfb485b766"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}