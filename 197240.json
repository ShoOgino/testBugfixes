{"path":"solr/core/src/java/org/apache/solr/cloud/autoscaling/sim/SimClusterStateProvider#simSplitShard(ZkNodeProps,NamedList).mjava","commits":[{"id":"9ef8d00dbfbeb534eba8a219a5df9d99b2de6ab5","date":1556572478,"type":1,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/autoscaling/sim/SimClusterStateProvider#simSplitShard(ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/SimClusterStateProvider#simSplitShard(ZkNodeProps,NamedList).mjava","sourceNew":"  /**\n   * Split a shard. This uses a similar algorithm as {@link SplitShardCmd}, including simulating its\n   * quirks, and leaving the original parent slice in place.\n   * @param message operation details\n   * @param results operation results.\n   */\n  public void simSplitShard(ZkNodeProps message, NamedList results) throws Exception {\n    ensureNotClosed();\n    if (message.getStr(CommonAdminParams.ASYNC) != null) {\n      results.add(CoreAdminParams.REQUESTID, message.getStr(CommonAdminParams.ASYNC));\n    }\n    String collectionName = message.getStr(COLLECTION_PROP);\n    AtomicReference<String> sliceName = new AtomicReference<>();\n    sliceName.set(message.getStr(SHARD_ID_PROP));\n    String splitKey = message.getStr(\"split.key\");\n\n    ClusterState clusterState = getClusterState();\n    DocCollection collection = clusterState.getCollection(collectionName);\n    Slice parentSlice = SplitShardCmd.getParentSlice(clusterState, collectionName, sliceName, splitKey);\n    Replica leader = parentSlice.getLeader();\n    // XXX leader election may not have happened yet - should we require it?\n    if (leader == null) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Shard \" + collectionName +\n          \" /  \" + sliceName.get() + \" has no leader and can't be split\");\n    }\n    SplitShardCmd.lockForSplit(cloudManager, collectionName, sliceName.get());\n    // start counting buffered updates\n    Map<String, Object> props = sliceProperties.computeIfAbsent(collectionName, c -> new ConcurrentHashMap<>())\n        .computeIfAbsent(sliceName.get(), ss -> new ConcurrentHashMap<>());\n    if (props.containsKey(BUFFERED_UPDATES)) {\n      SplitShardCmd.unlockForSplit(cloudManager, collectionName, sliceName.get());\n      throw new Exception(\"--- SOLR-12729: Overlapping splitShard commands for \" + collectionName + \"/\" + sliceName.get());\n    }\n    props.put(BUFFERED_UPDATES, new AtomicLong());\n\n    List<DocRouter.Range> subRanges = new ArrayList<>();\n    List<String> subSlices = new ArrayList<>();\n    List<String> subShardNames = new ArrayList<>();\n\n    opDelay(collectionName, CollectionParams.CollectionAction.SPLITSHARD.name());\n\n    SplitShardCmd.fillRanges(cloudManager, message, collection, parentSlice, subRanges, subSlices, subShardNames, true);\n    // add replicas for new subShards\n    int repFactor = parentSlice.getReplicas().size();\n    Assign.AssignRequest assignRequest = new Assign.AssignRequestBuilder()\n        .forCollection(collectionName)\n        .forShard(subSlices)\n        .assignNrtReplicas(repFactor)\n        .assignTlogReplicas(0)\n        .assignPullReplicas(0)\n        .onNodes(new ArrayList<>(clusterState.getLiveNodes()))\n        .build();\n    Assign.AssignStrategyFactory assignStrategyFactory = new Assign.AssignStrategyFactory(cloudManager);\n    Assign.AssignStrategy assignStrategy = assignStrategyFactory.create(clusterState, collection);\n    // reproduce the bug\n    List<ReplicaPosition> replicaPositions = assignStrategy.assign(cloudManager, assignRequest);\n    PolicyHelper.SessionWrapper sessionWrapper = PolicyHelper.getLastSessionWrapper(true);\n    if (sessionWrapper != null) sessionWrapper.release();\n\n    // adjust numDocs / deletedDocs / maxDoc\n    String numDocsStr = String.valueOf(getReplicaInfo(leader).getVariable(\"SEARCHER.searcher.numDocs\", \"0\"));\n    long numDocs = Long.parseLong(numDocsStr);\n    long newNumDocs = numDocs / subSlices.size();\n    long remainderDocs = numDocs % subSlices.size();\n    long newIndexSize = SimCloudManager.DEFAULT_IDX_SIZE_BYTES + newNumDocs * DEFAULT_DOC_SIZE_BYTES;\n    long remainderIndexSize = SimCloudManager.DEFAULT_IDX_SIZE_BYTES + remainderDocs * DEFAULT_DOC_SIZE_BYTES;\n    String remainderSlice = null;\n\n    // add slice props\n    for (int i = 0; i < subRanges.size(); i++) {\n      String subSlice = subSlices.get(i);\n      DocRouter.Range range = subRanges.get(i);\n      Map<String, Object> sliceProps = sliceProperties.computeIfAbsent(collectionName, c -> new ConcurrentHashMap<>())\n          .computeIfAbsent(subSlice, ss -> new ConcurrentHashMap<>());\n      sliceProps.put(Slice.RANGE, range);\n      sliceProps.put(Slice.PARENT, sliceName.get());\n      sliceProps.put(ZkStateReader.STATE_PROP, Slice.State.CONSTRUCTION.toString());\n      sliceProps.put(ZkStateReader.STATE_TIMESTAMP_PROP, String.valueOf(cloudManager.getTimeSource().getEpochTimeNs()));\n    }\n    // add replicas\n    for (ReplicaPosition replicaPosition : replicaPositions) {\n      String subSliceName = replicaPosition.shard;\n      String subShardNodeName = replicaPosition.node;\n//      String solrCoreName = collectionName + \"_\" + subSliceName + \"_replica_n\" + (replicaPosition.index);\n      String solrCoreName = Assign.buildSolrCoreName(collectionName, subSliceName, replicaPosition.type, Assign.incAndGetId(stateManager, collectionName, 0));\n      Map<String, Object> replicaProps = new HashMap<>();\n      replicaProps.put(ZkStateReader.SHARD_ID_PROP, replicaPosition.shard);\n      replicaProps.put(ZkStateReader.NODE_NAME_PROP, replicaPosition.node);\n      replicaProps.put(ZkStateReader.REPLICA_TYPE, replicaPosition.type.toString());\n      replicaProps.put(ZkStateReader.BASE_URL_PROP, Utils.getBaseUrlForNodeName(subShardNodeName, \"http\"));\n\n      long replicasNumDocs = newNumDocs;\n      long replicasIndexSize = newIndexSize;\n      if (remainderSlice == null) {\n        remainderSlice = subSliceName;\n      }\n      if (remainderSlice.equals(subSliceName)) { // only add to one sub slice\n        replicasNumDocs += remainderDocs;\n        replicasIndexSize += remainderIndexSize;\n      }\n      replicaProps.put(\"SEARCHER.searcher.numDocs\", new AtomicLong(replicasNumDocs));\n      replicaProps.put(\"SEARCHER.searcher.maxDoc\", new AtomicLong(replicasNumDocs));\n      replicaProps.put(\"SEARCHER.searcher.deletedDocs\", new AtomicLong(0));\n      replicaProps.put(Type.CORE_IDX.metricsAttribute, new AtomicLong(replicasIndexSize));\n      replicaProps.put(Variable.coreidxsize, new AtomicDouble((Double)Type.CORE_IDX.convertVal(replicasIndexSize)));\n\n      ReplicaInfo ri = new ReplicaInfo(\"core_node\" + Assign.incAndGetId(stateManager, collectionName, 0),\n          solrCoreName, collectionName, replicaPosition.shard, replicaPosition.type, subShardNodeName, replicaProps);\n      simAddReplica(replicaPosition.node, ri, false);\n    }\n    simRunLeaderElection(Collections.singleton(collectionName), true);\n\n    // delay it once again to better simulate replica recoveries\n    //opDelay(collectionName, CollectionParams.CollectionAction.SPLITSHARD.name());\n\n    boolean success = false;\n    try {\n      CloudUtil.waitForState(cloudManager, collectionName, 30, TimeUnit.SECONDS, (liveNodes, state) -> {\n        for (String subSlice : subSlices) {\n          Slice s = state.getSlice(subSlice);\n          if (s.getLeader() == null) {\n            log.debug(\"** no leader in {} / {}\", collectionName, s);\n            return false;\n          }\n          if (s.getReplicas().size() < repFactor) {\n            log.debug(\"** expected {} repFactor but there are {} replicas\", repFactor, s.getReplicas().size());\n            return false;\n          }\n        }\n        return true;\n      });\n      success = true;\n    } finally {\n      if (!success) {\n        Map<String, Object> sProps = sliceProperties.computeIfAbsent(collectionName, c -> new ConcurrentHashMap<>())\n            .computeIfAbsent(sliceName.get(), s -> new ConcurrentHashMap<>());\n        sProps.remove(BUFFERED_UPDATES);\n        SplitShardCmd.unlockForSplit(cloudManager, collectionName, sliceName.get());\n      }\n    }\n    // mark the new slices as active and the old slice as inactive\n    log.trace(\"-- switching slice states after split shard: collection={}, parent={}, subSlices={}\", collectionName,\n        sliceName.get(), subSlices);\n    lock.lockInterruptibly();\n    try {\n      Map<String, Object> sProps = sliceProperties.computeIfAbsent(collectionName, c -> new ConcurrentHashMap<>())\n          .computeIfAbsent(sliceName.get(), s -> new ConcurrentHashMap<>());\n      sProps.put(ZkStateReader.STATE_PROP, Slice.State.INACTIVE.toString());\n      sProps.put(ZkStateReader.STATE_TIMESTAMP_PROP, String.valueOf(cloudManager.getTimeSource().getEpochTimeNs()));\n      AtomicLong bufferedUpdates = (AtomicLong)sProps.remove(BUFFERED_UPDATES);\n      if (bufferedUpdates.get() > 0) {\n        // apply buffered updates\n        long perShard = bufferedUpdates.get() / subSlices.size();\n        long remainder = bufferedUpdates.get() % subSlices.size();\n        log.debug(\"-- applying {} buffered docs from {} / {}, perShard={}, remainder={}\", bufferedUpdates.get(),\n            collectionName, parentSlice.getName(), perShard, remainder);\n        for (int i = 0; i < subSlices.size(); i++) {\n          String sub = subSlices.get(i);\n          long numUpdates = perShard;\n          if (i == 0) {\n            numUpdates += remainder;\n          }\n          simSetShardValue(collectionName, sub, \"SEARCHER.searcher.numDocs\", numUpdates, true, false);\n          simSetShardValue(collectionName, sub, \"SEARCHER.searcher.maxDoc\", numUpdates, true, false);\n        }\n      }\n      // XXX also mark replicas as down? currently SplitShardCmd doesn't do this\n\n      for (String s : subSlices) {\n        Map<String, Object> sliceProps = sliceProperties.computeIfAbsent(collectionName, c -> new ConcurrentHashMap<>())\n            .computeIfAbsent(s, ss -> new ConcurrentHashMap<>());\n        sliceProps.put(ZkStateReader.STATE_PROP, Slice.State.ACTIVE.toString());\n        sliceProps.put(ZkStateReader.STATE_TIMESTAMP_PROP, String.valueOf(cloudManager.getTimeSource().getEpochTimeNs()));\n      }\n\n      // invalidate cached state\n      collectionsStatesRef.set(null);\n    } finally {\n      SplitShardCmd.unlockForSplit(cloudManager, collectionName, sliceName.get());\n      lock.unlock();\n    }\n    results.add(\"success\", \"\");\n\n  }\n\n","sourceOld":"  /**\n   * Split a shard. This uses a similar algorithm as {@link SplitShardCmd}, including simulating its\n   * quirks, and leaving the original parent slice in place.\n   * @param message operation details\n   * @param results operation results.\n   */\n  public void simSplitShard(ZkNodeProps message, NamedList results) throws Exception {\n    ensureNotClosed();\n    if (message.getStr(CommonAdminParams.ASYNC) != null) {\n      results.add(CoreAdminParams.REQUESTID, message.getStr(CommonAdminParams.ASYNC));\n    }\n    String collectionName = message.getStr(COLLECTION_PROP);\n    AtomicReference<String> sliceName = new AtomicReference<>();\n    sliceName.set(message.getStr(SHARD_ID_PROP));\n    String splitKey = message.getStr(\"split.key\");\n\n    ClusterState clusterState = getClusterState();\n    DocCollection collection = clusterState.getCollection(collectionName);\n    Slice parentSlice = SplitShardCmd.getParentSlice(clusterState, collectionName, sliceName, splitKey);\n    Replica leader = parentSlice.getLeader();\n    // XXX leader election may not have happened yet - should we require it?\n    if (leader == null) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Shard \" + collectionName +\n          \" /  \" + sliceName.get() + \" has no leader and can't be split\");\n    }\n    SplitShardCmd.lockForSplit(cloudManager, collectionName, sliceName.get());\n    // start counting buffered updates\n    Map<String, Object> props = sliceProperties.computeIfAbsent(collectionName, c -> new ConcurrentHashMap<>())\n        .computeIfAbsent(sliceName.get(), ss -> new ConcurrentHashMap<>());\n    if (props.containsKey(BUFFERED_UPDATES)) {\n      SplitShardCmd.unlockForSplit(cloudManager, collectionName, sliceName.get());\n      throw new Exception(\"--- SOLR-12729: Overlapping splitShard commands for \" + collectionName + \"/\" + sliceName.get());\n    }\n    props.put(BUFFERED_UPDATES, new AtomicLong());\n\n    List<DocRouter.Range> subRanges = new ArrayList<>();\n    List<String> subSlices = new ArrayList<>();\n    List<String> subShardNames = new ArrayList<>();\n\n    opDelay(collectionName, CollectionParams.CollectionAction.SPLITSHARD.name());\n\n    SplitShardCmd.fillRanges(cloudManager, message, collection, parentSlice, subRanges, subSlices, subShardNames, true);\n    // add replicas for new subShards\n    int repFactor = parentSlice.getReplicas().size();\n    Assign.AssignRequest assignRequest = new Assign.AssignRequestBuilder()\n        .forCollection(collectionName)\n        .forShard(subSlices)\n        .assignNrtReplicas(repFactor)\n        .assignTlogReplicas(0)\n        .assignPullReplicas(0)\n        .onNodes(new ArrayList<>(clusterState.getLiveNodes()))\n        .build();\n    Assign.AssignStrategyFactory assignStrategyFactory = new Assign.AssignStrategyFactory(cloudManager);\n    Assign.AssignStrategy assignStrategy = assignStrategyFactory.create(clusterState, collection);\n    // reproduce the bug\n    List<ReplicaPosition> replicaPositions = assignStrategy.assign(cloudManager, assignRequest);\n    PolicyHelper.SessionWrapper sessionWrapper = PolicyHelper.getLastSessionWrapper(true);\n    if (sessionWrapper != null) sessionWrapper.release();\n\n    // adjust numDocs / deletedDocs / maxDoc\n    String numDocsStr = String.valueOf(getReplicaInfo(leader).getVariable(\"SEARCHER.searcher.numDocs\", \"0\"));\n    long numDocs = Long.parseLong(numDocsStr);\n    long newNumDocs = numDocs / subSlices.size();\n    long remainderDocs = numDocs % subSlices.size();\n    long newIndexSize = SimCloudManager.DEFAULT_IDX_SIZE_BYTES + newNumDocs * DEFAULT_DOC_SIZE_BYTES;\n    long remainderIndexSize = SimCloudManager.DEFAULT_IDX_SIZE_BYTES + remainderDocs * DEFAULT_DOC_SIZE_BYTES;\n    String remainderSlice = null;\n\n    // add slice props\n    for (int i = 0; i < subRanges.size(); i++) {\n      String subSlice = subSlices.get(i);\n      DocRouter.Range range = subRanges.get(i);\n      Map<String, Object> sliceProps = sliceProperties.computeIfAbsent(collectionName, c -> new ConcurrentHashMap<>())\n          .computeIfAbsent(subSlice, ss -> new ConcurrentHashMap<>());\n      sliceProps.put(Slice.RANGE, range);\n      sliceProps.put(Slice.PARENT, sliceName.get());\n      sliceProps.put(ZkStateReader.STATE_PROP, Slice.State.CONSTRUCTION.toString());\n      sliceProps.put(ZkStateReader.STATE_TIMESTAMP_PROP, String.valueOf(cloudManager.getTimeSource().getEpochTimeNs()));\n    }\n    // add replicas\n    for (ReplicaPosition replicaPosition : replicaPositions) {\n      String subSliceName = replicaPosition.shard;\n      String subShardNodeName = replicaPosition.node;\n//      String solrCoreName = collectionName + \"_\" + subSliceName + \"_replica_n\" + (replicaPosition.index);\n      String solrCoreName = Assign.buildSolrCoreName(collectionName, subSliceName, replicaPosition.type, Assign.incAndGetId(stateManager, collectionName, 0));\n      Map<String, Object> replicaProps = new HashMap<>();\n      replicaProps.put(ZkStateReader.SHARD_ID_PROP, replicaPosition.shard);\n      replicaProps.put(ZkStateReader.NODE_NAME_PROP, replicaPosition.node);\n      replicaProps.put(ZkStateReader.REPLICA_TYPE, replicaPosition.type.toString());\n      replicaProps.put(ZkStateReader.BASE_URL_PROP, Utils.getBaseUrlForNodeName(subShardNodeName, \"http\"));\n\n      long replicasNumDocs = newNumDocs;\n      long replicasIndexSize = newIndexSize;\n      if (remainderSlice == null) {\n        remainderSlice = subSliceName;\n      }\n      if (remainderSlice.equals(subSliceName)) { // only add to one sub slice\n        replicasNumDocs += remainderDocs;\n        replicasIndexSize += remainderIndexSize;\n      }\n      replicaProps.put(\"SEARCHER.searcher.numDocs\", new AtomicLong(replicasNumDocs));\n      replicaProps.put(\"SEARCHER.searcher.maxDoc\", new AtomicLong(replicasNumDocs));\n      replicaProps.put(\"SEARCHER.searcher.deletedDocs\", new AtomicLong(0));\n      replicaProps.put(Type.CORE_IDX.metricsAttribute, new AtomicLong(replicasIndexSize));\n      replicaProps.put(Variable.coreidxsize, new AtomicDouble((Double)Type.CORE_IDX.convertVal(replicasIndexSize)));\n\n      ReplicaInfo ri = new ReplicaInfo(\"core_node\" + Assign.incAndGetId(stateManager, collectionName, 0),\n          solrCoreName, collectionName, replicaPosition.shard, replicaPosition.type, subShardNodeName, replicaProps);\n      simAddReplica(replicaPosition.node, ri, false);\n    }\n    simRunLeaderElection(Collections.singleton(collectionName), true);\n\n    // delay it once again to better simulate replica recoveries\n    //opDelay(collectionName, CollectionParams.CollectionAction.SPLITSHARD.name());\n\n    boolean success = false;\n    try {\n      CloudTestUtils.waitForState(cloudManager, collectionName, 30, TimeUnit.SECONDS, (liveNodes, state) -> {\n        for (String subSlice : subSlices) {\n          Slice s = state.getSlice(subSlice);\n          if (s.getLeader() == null) {\n            log.debug(\"** no leader in {} / {}\", collectionName, s);\n            return false;\n          }\n          if (s.getReplicas().size() < repFactor) {\n            log.debug(\"** expected {} repFactor but there are {} replicas\", repFactor, s.getReplicas().size());\n            return false;\n          }\n        }\n        return true;\n      });\n      success = true;\n    } finally {\n      if (!success) {\n        Map<String, Object> sProps = sliceProperties.computeIfAbsent(collectionName, c -> new ConcurrentHashMap<>())\n            .computeIfAbsent(sliceName.get(), s -> new ConcurrentHashMap<>());\n        sProps.remove(BUFFERED_UPDATES);\n        SplitShardCmd.unlockForSplit(cloudManager, collectionName, sliceName.get());\n      }\n    }\n    // mark the new slices as active and the old slice as inactive\n    log.trace(\"-- switching slice states after split shard: collection={}, parent={}, subSlices={}\", collectionName,\n        sliceName.get(), subSlices);\n    lock.lockInterruptibly();\n    try {\n      Map<String, Object> sProps = sliceProperties.computeIfAbsent(collectionName, c -> new ConcurrentHashMap<>())\n          .computeIfAbsent(sliceName.get(), s -> new ConcurrentHashMap<>());\n      sProps.put(ZkStateReader.STATE_PROP, Slice.State.INACTIVE.toString());\n      sProps.put(ZkStateReader.STATE_TIMESTAMP_PROP, String.valueOf(cloudManager.getTimeSource().getEpochTimeNs()));\n      AtomicLong bufferedUpdates = (AtomicLong)sProps.remove(BUFFERED_UPDATES);\n      if (bufferedUpdates.get() > 0) {\n        // apply buffered updates\n        long perShard = bufferedUpdates.get() / subSlices.size();\n        long remainder = bufferedUpdates.get() % subSlices.size();\n        log.debug(\"-- applying {} buffered docs from {} / {}, perShard={}, remainder={}\", bufferedUpdates.get(),\n            collectionName, parentSlice.getName(), perShard, remainder);\n        for (int i = 0; i < subSlices.size(); i++) {\n          String sub = subSlices.get(i);\n          long numUpdates = perShard;\n          if (i == 0) {\n            numUpdates += remainder;\n          }\n          simSetShardValue(collectionName, sub, \"SEARCHER.searcher.numDocs\", numUpdates, true, false);\n          simSetShardValue(collectionName, sub, \"SEARCHER.searcher.maxDoc\", numUpdates, true, false);\n        }\n      }\n      // XXX also mark replicas as down? currently SplitShardCmd doesn't do this\n\n      for (String s : subSlices) {\n        Map<String, Object> sliceProps = sliceProperties.computeIfAbsent(collectionName, c -> new ConcurrentHashMap<>())\n            .computeIfAbsent(s, ss -> new ConcurrentHashMap<>());\n        sliceProps.put(ZkStateReader.STATE_PROP, Slice.State.ACTIVE.toString());\n        sliceProps.put(ZkStateReader.STATE_TIMESTAMP_PROP, String.valueOf(cloudManager.getTimeSource().getEpochTimeNs()));\n      }\n\n      // invalidate cached state\n      collectionsStatesRef.set(null);\n    } finally {\n      SplitShardCmd.unlockForSplit(cloudManager, collectionName, sliceName.get());\n      lock.unlock();\n    }\n    results.add(\"success\", \"\");\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8f79e6c597ec19b2f9669589153faac2f803462a","date":1575984097,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/autoscaling/sim/SimClusterStateProvider#simSplitShard(ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/autoscaling/sim/SimClusterStateProvider#simSplitShard(ZkNodeProps,NamedList).mjava","sourceNew":"  /**\n   * Split a shard. This uses a similar algorithm as {@link SplitShardCmd}, including simulating its\n   * quirks, and leaving the original parent slice in place.\n   * @param message operation details\n   * @param results operation results.\n   */\n  public void simSplitShard(ZkNodeProps message, NamedList results) throws Exception {\n    ensureNotClosed();\n    if (message.getStr(CommonAdminParams.ASYNC) != null) {\n      results.add(CoreAdminParams.REQUESTID, message.getStr(CommonAdminParams.ASYNC));\n    }\n    String collectionName = message.getStr(COLLECTION_PROP);\n    AtomicReference<String> sliceName = new AtomicReference<>();\n    sliceName.set(message.getStr(SHARD_ID_PROP));\n    String splitKey = message.getStr(\"split.key\");\n    String methodStr = message.getStr(CommonAdminParams.SPLIT_METHOD, SolrIndexSplitter.SplitMethod.REWRITE.toLower());\n    SolrIndexSplitter.SplitMethod splitMethod = SolrIndexSplitter.SplitMethod.get(methodStr);\n    if (splitMethod == null) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Unknown value '\" + CommonAdminParams.SPLIT_METHOD +\n          \": \" + methodStr);\n    }\n\n    ClusterState clusterState = getClusterState();\n    DocCollection collection = clusterState.getCollection(collectionName);\n    Slice parentSlice = SplitShardCmd.getParentSlice(clusterState, collectionName, sliceName, splitKey);\n    Replica leader = parentSlice.getLeader();\n    // XXX leader election may not have happened yet - should we require it?\n    if (leader == null) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Shard \" + collectionName +\n          \" /  \" + sliceName.get() + \" has no leader and can't be split\");\n    }\n    SplitShardCmd.checkDiskSpace(collectionName, sliceName.get(), leader, splitMethod, cloudManager);\n    SplitShardCmd.lockForSplit(cloudManager, collectionName, sliceName.get());\n    // start counting buffered updates\n    Map<String, Object> props = sliceProperties.computeIfAbsent(collectionName, c -> new ConcurrentHashMap<>())\n        .computeIfAbsent(sliceName.get(), ss -> new ConcurrentHashMap<>());\n    if (props.containsKey(BUFFERED_UPDATES)) {\n      SplitShardCmd.unlockForSplit(cloudManager, collectionName, sliceName.get());\n      throw new Exception(\"--- SOLR-12729: Overlapping splitShard commands for \" + collectionName + \"/\" + sliceName.get());\n    }\n    props.put(BUFFERED_UPDATES, new AtomicLong());\n\n    List<DocRouter.Range> subRanges = new ArrayList<>();\n    List<String> subSlices = new ArrayList<>();\n    List<String> subShardNames = new ArrayList<>();\n\n    opDelay(collectionName, CollectionParams.CollectionAction.SPLITSHARD.name());\n\n    SplitShardCmd.fillRanges(cloudManager, message, collection, parentSlice, subRanges, subSlices, subShardNames, true);\n    // add replicas for new subShards\n    int repFactor = parentSlice.getReplicas().size();\n    Assign.AssignRequest assignRequest = new Assign.AssignRequestBuilder()\n        .forCollection(collectionName)\n        .forShard(subSlices)\n        .assignNrtReplicas(repFactor)\n        .assignTlogReplicas(0)\n        .assignPullReplicas(0)\n        .onNodes(new ArrayList<>(clusterState.getLiveNodes()))\n        .build();\n    Assign.AssignStrategyFactory assignStrategyFactory = new Assign.AssignStrategyFactory(cloudManager);\n    Assign.AssignStrategy assignStrategy = assignStrategyFactory.create(clusterState, collection);\n    // reproduce the bug\n    List<ReplicaPosition> replicaPositions = assignStrategy.assign(cloudManager, assignRequest);\n    PolicyHelper.SessionWrapper sessionWrapper = PolicyHelper.getLastSessionWrapper(true);\n    if (sessionWrapper != null) sessionWrapper.release();\n\n    // adjust numDocs / deletedDocs / maxDoc\n    String numDocsStr = String.valueOf(getReplicaInfo(leader).getVariable(\"SEARCHER.searcher.numDocs\", \"0\"));\n    long numDocs = Long.parseLong(numDocsStr);\n    long newNumDocs = numDocs / subSlices.size();\n    long remainderDocs = numDocs % subSlices.size();\n    long newIndexSize = SimCloudManager.DEFAULT_IDX_SIZE_BYTES + newNumDocs * DEFAULT_DOC_SIZE_BYTES;\n    long remainderIndexSize = SimCloudManager.DEFAULT_IDX_SIZE_BYTES + remainderDocs * DEFAULT_DOC_SIZE_BYTES;\n    String remainderSlice = null;\n\n    // add slice props\n    for (int i = 0; i < subRanges.size(); i++) {\n      String subSlice = subSlices.get(i);\n      DocRouter.Range range = subRanges.get(i);\n      Map<String, Object> sliceProps = sliceProperties.computeIfAbsent(collectionName, c -> new ConcurrentHashMap<>())\n          .computeIfAbsent(subSlice, ss -> new ConcurrentHashMap<>());\n      sliceProps.put(Slice.RANGE, range);\n      sliceProps.put(Slice.PARENT, sliceName.get());\n      sliceProps.put(ZkStateReader.STATE_PROP, Slice.State.CONSTRUCTION.toString());\n      sliceProps.put(ZkStateReader.STATE_TIMESTAMP_PROP, String.valueOf(cloudManager.getTimeSource().getEpochTimeNs()));\n    }\n    // add replicas\n    for (ReplicaPosition replicaPosition : replicaPositions) {\n      String subSliceName = replicaPosition.shard;\n      String subShardNodeName = replicaPosition.node;\n//      String solrCoreName = collectionName + \"_\" + subSliceName + \"_replica_n\" + (replicaPosition.index);\n      String solrCoreName = Assign.buildSolrCoreName(collectionName, subSliceName, replicaPosition.type, Assign.incAndGetId(stateManager, collectionName, 0));\n      Map<String, Object> replicaProps = new HashMap<>();\n      replicaProps.put(ZkStateReader.SHARD_ID_PROP, replicaPosition.shard);\n      replicaProps.put(ZkStateReader.NODE_NAME_PROP, replicaPosition.node);\n      replicaProps.put(ZkStateReader.REPLICA_TYPE, replicaPosition.type.toString());\n      replicaProps.put(ZkStateReader.BASE_URL_PROP, Utils.getBaseUrlForNodeName(subShardNodeName, \"http\"));\n\n      long replicasNumDocs = newNumDocs;\n      long replicasIndexSize = newIndexSize;\n      if (remainderSlice == null) {\n        remainderSlice = subSliceName;\n      }\n      if (remainderSlice.equals(subSliceName)) { // only add to one sub slice\n        replicasNumDocs += remainderDocs;\n        replicasIndexSize += remainderIndexSize;\n      }\n      replicaProps.put(\"SEARCHER.searcher.numDocs\", new AtomicLong(replicasNumDocs));\n      replicaProps.put(\"SEARCHER.searcher.maxDoc\", new AtomicLong(replicasNumDocs));\n      replicaProps.put(\"SEARCHER.searcher.deletedDocs\", new AtomicLong(0));\n      replicaProps.put(Type.CORE_IDX.metricsAttribute, new AtomicLong(replicasIndexSize));\n      replicaProps.put(Variable.coreidxsize, new AtomicDouble((Double)Type.CORE_IDX.convertVal(replicasIndexSize)));\n\n      ReplicaInfo ri = new ReplicaInfo(\"core_node\" + Assign.incAndGetId(stateManager, collectionName, 0),\n          solrCoreName, collectionName, replicaPosition.shard, replicaPosition.type, subShardNodeName, replicaProps);\n      simAddReplica(replicaPosition.node, ri, false);\n    }\n    simRunLeaderElection(Collections.singleton(collectionName), true);\n\n    // delay it once again to better simulate replica recoveries\n    //opDelay(collectionName, CollectionParams.CollectionAction.SPLITSHARD.name());\n\n    boolean success = false;\n    try {\n      CloudUtil.waitForState(cloudManager, collectionName, 30, TimeUnit.SECONDS, (liveNodes, state) -> {\n        for (String subSlice : subSlices) {\n          Slice s = state.getSlice(subSlice);\n          if (s.getLeader() == null) {\n            log.debug(\"** no leader in {} / {}\", collectionName, s);\n            return false;\n          }\n          if (s.getReplicas().size() < repFactor) {\n            log.debug(\"** expected {} repFactor but there are {} replicas\", repFactor, s.getReplicas().size());\n            return false;\n          }\n        }\n        return true;\n      });\n      success = true;\n    } finally {\n      if (!success) {\n        Map<String, Object> sProps = sliceProperties.computeIfAbsent(collectionName, c -> new ConcurrentHashMap<>())\n            .computeIfAbsent(sliceName.get(), s -> new ConcurrentHashMap<>());\n        sProps.remove(BUFFERED_UPDATES);\n        SplitShardCmd.unlockForSplit(cloudManager, collectionName, sliceName.get());\n      }\n    }\n    // mark the new slices as active and the old slice as inactive\n    log.trace(\"-- switching slice states after split shard: collection={}, parent={}, subSlices={}\", collectionName,\n        sliceName.get(), subSlices);\n    lock.lockInterruptibly();\n    try {\n      Map<String, Object> sProps = sliceProperties.computeIfAbsent(collectionName, c -> new ConcurrentHashMap<>())\n          .computeIfAbsent(sliceName.get(), s -> new ConcurrentHashMap<>());\n      sProps.put(ZkStateReader.STATE_PROP, Slice.State.INACTIVE.toString());\n      sProps.put(ZkStateReader.STATE_TIMESTAMP_PROP, String.valueOf(cloudManager.getTimeSource().getEpochTimeNs()));\n      AtomicLong bufferedUpdates = (AtomicLong)sProps.remove(BUFFERED_UPDATES);\n      if (bufferedUpdates.get() > 0) {\n        // apply buffered updates\n        long perShard = bufferedUpdates.get() / subSlices.size();\n        long remainder = bufferedUpdates.get() % subSlices.size();\n        log.debug(\"-- applying {} buffered docs from {} / {}, perShard={}, remainder={}\", bufferedUpdates.get(),\n            collectionName, parentSlice.getName(), perShard, remainder);\n        for (int i = 0; i < subSlices.size(); i++) {\n          String sub = subSlices.get(i);\n          long numUpdates = perShard;\n          if (i == 0) {\n            numUpdates += remainder;\n          }\n          simSetShardValue(collectionName, sub, \"SEARCHER.searcher.numDocs\", numUpdates, true, false);\n          simSetShardValue(collectionName, sub, \"SEARCHER.searcher.maxDoc\", numUpdates, true, false);\n        }\n      }\n      // XXX also mark replicas as down? currently SplitShardCmd doesn't do this\n\n      for (String s : subSlices) {\n        Map<String, Object> sliceProps = sliceProperties.computeIfAbsent(collectionName, c -> new ConcurrentHashMap<>())\n            .computeIfAbsent(s, ss -> new ConcurrentHashMap<>());\n        sliceProps.put(ZkStateReader.STATE_PROP, Slice.State.ACTIVE.toString());\n        sliceProps.put(ZkStateReader.STATE_TIMESTAMP_PROP, String.valueOf(cloudManager.getTimeSource().getEpochTimeNs()));\n      }\n\n      // invalidate cached state\n      collectionsStatesRef.set(null);\n    } finally {\n      SplitShardCmd.unlockForSplit(cloudManager, collectionName, sliceName.get());\n      lock.unlock();\n    }\n    results.add(\"success\", \"\");\n\n  }\n\n","sourceOld":"  /**\n   * Split a shard. This uses a similar algorithm as {@link SplitShardCmd}, including simulating its\n   * quirks, and leaving the original parent slice in place.\n   * @param message operation details\n   * @param results operation results.\n   */\n  public void simSplitShard(ZkNodeProps message, NamedList results) throws Exception {\n    ensureNotClosed();\n    if (message.getStr(CommonAdminParams.ASYNC) != null) {\n      results.add(CoreAdminParams.REQUESTID, message.getStr(CommonAdminParams.ASYNC));\n    }\n    String collectionName = message.getStr(COLLECTION_PROP);\n    AtomicReference<String> sliceName = new AtomicReference<>();\n    sliceName.set(message.getStr(SHARD_ID_PROP));\n    String splitKey = message.getStr(\"split.key\");\n\n    ClusterState clusterState = getClusterState();\n    DocCollection collection = clusterState.getCollection(collectionName);\n    Slice parentSlice = SplitShardCmd.getParentSlice(clusterState, collectionName, sliceName, splitKey);\n    Replica leader = parentSlice.getLeader();\n    // XXX leader election may not have happened yet - should we require it?\n    if (leader == null) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Shard \" + collectionName +\n          \" /  \" + sliceName.get() + \" has no leader and can't be split\");\n    }\n    SplitShardCmd.lockForSplit(cloudManager, collectionName, sliceName.get());\n    // start counting buffered updates\n    Map<String, Object> props = sliceProperties.computeIfAbsent(collectionName, c -> new ConcurrentHashMap<>())\n        .computeIfAbsent(sliceName.get(), ss -> new ConcurrentHashMap<>());\n    if (props.containsKey(BUFFERED_UPDATES)) {\n      SplitShardCmd.unlockForSplit(cloudManager, collectionName, sliceName.get());\n      throw new Exception(\"--- SOLR-12729: Overlapping splitShard commands for \" + collectionName + \"/\" + sliceName.get());\n    }\n    props.put(BUFFERED_UPDATES, new AtomicLong());\n\n    List<DocRouter.Range> subRanges = new ArrayList<>();\n    List<String> subSlices = new ArrayList<>();\n    List<String> subShardNames = new ArrayList<>();\n\n    opDelay(collectionName, CollectionParams.CollectionAction.SPLITSHARD.name());\n\n    SplitShardCmd.fillRanges(cloudManager, message, collection, parentSlice, subRanges, subSlices, subShardNames, true);\n    // add replicas for new subShards\n    int repFactor = parentSlice.getReplicas().size();\n    Assign.AssignRequest assignRequest = new Assign.AssignRequestBuilder()\n        .forCollection(collectionName)\n        .forShard(subSlices)\n        .assignNrtReplicas(repFactor)\n        .assignTlogReplicas(0)\n        .assignPullReplicas(0)\n        .onNodes(new ArrayList<>(clusterState.getLiveNodes()))\n        .build();\n    Assign.AssignStrategyFactory assignStrategyFactory = new Assign.AssignStrategyFactory(cloudManager);\n    Assign.AssignStrategy assignStrategy = assignStrategyFactory.create(clusterState, collection);\n    // reproduce the bug\n    List<ReplicaPosition> replicaPositions = assignStrategy.assign(cloudManager, assignRequest);\n    PolicyHelper.SessionWrapper sessionWrapper = PolicyHelper.getLastSessionWrapper(true);\n    if (sessionWrapper != null) sessionWrapper.release();\n\n    // adjust numDocs / deletedDocs / maxDoc\n    String numDocsStr = String.valueOf(getReplicaInfo(leader).getVariable(\"SEARCHER.searcher.numDocs\", \"0\"));\n    long numDocs = Long.parseLong(numDocsStr);\n    long newNumDocs = numDocs / subSlices.size();\n    long remainderDocs = numDocs % subSlices.size();\n    long newIndexSize = SimCloudManager.DEFAULT_IDX_SIZE_BYTES + newNumDocs * DEFAULT_DOC_SIZE_BYTES;\n    long remainderIndexSize = SimCloudManager.DEFAULT_IDX_SIZE_BYTES + remainderDocs * DEFAULT_DOC_SIZE_BYTES;\n    String remainderSlice = null;\n\n    // add slice props\n    for (int i = 0; i < subRanges.size(); i++) {\n      String subSlice = subSlices.get(i);\n      DocRouter.Range range = subRanges.get(i);\n      Map<String, Object> sliceProps = sliceProperties.computeIfAbsent(collectionName, c -> new ConcurrentHashMap<>())\n          .computeIfAbsent(subSlice, ss -> new ConcurrentHashMap<>());\n      sliceProps.put(Slice.RANGE, range);\n      sliceProps.put(Slice.PARENT, sliceName.get());\n      sliceProps.put(ZkStateReader.STATE_PROP, Slice.State.CONSTRUCTION.toString());\n      sliceProps.put(ZkStateReader.STATE_TIMESTAMP_PROP, String.valueOf(cloudManager.getTimeSource().getEpochTimeNs()));\n    }\n    // add replicas\n    for (ReplicaPosition replicaPosition : replicaPositions) {\n      String subSliceName = replicaPosition.shard;\n      String subShardNodeName = replicaPosition.node;\n//      String solrCoreName = collectionName + \"_\" + subSliceName + \"_replica_n\" + (replicaPosition.index);\n      String solrCoreName = Assign.buildSolrCoreName(collectionName, subSliceName, replicaPosition.type, Assign.incAndGetId(stateManager, collectionName, 0));\n      Map<String, Object> replicaProps = new HashMap<>();\n      replicaProps.put(ZkStateReader.SHARD_ID_PROP, replicaPosition.shard);\n      replicaProps.put(ZkStateReader.NODE_NAME_PROP, replicaPosition.node);\n      replicaProps.put(ZkStateReader.REPLICA_TYPE, replicaPosition.type.toString());\n      replicaProps.put(ZkStateReader.BASE_URL_PROP, Utils.getBaseUrlForNodeName(subShardNodeName, \"http\"));\n\n      long replicasNumDocs = newNumDocs;\n      long replicasIndexSize = newIndexSize;\n      if (remainderSlice == null) {\n        remainderSlice = subSliceName;\n      }\n      if (remainderSlice.equals(subSliceName)) { // only add to one sub slice\n        replicasNumDocs += remainderDocs;\n        replicasIndexSize += remainderIndexSize;\n      }\n      replicaProps.put(\"SEARCHER.searcher.numDocs\", new AtomicLong(replicasNumDocs));\n      replicaProps.put(\"SEARCHER.searcher.maxDoc\", new AtomicLong(replicasNumDocs));\n      replicaProps.put(\"SEARCHER.searcher.deletedDocs\", new AtomicLong(0));\n      replicaProps.put(Type.CORE_IDX.metricsAttribute, new AtomicLong(replicasIndexSize));\n      replicaProps.put(Variable.coreidxsize, new AtomicDouble((Double)Type.CORE_IDX.convertVal(replicasIndexSize)));\n\n      ReplicaInfo ri = new ReplicaInfo(\"core_node\" + Assign.incAndGetId(stateManager, collectionName, 0),\n          solrCoreName, collectionName, replicaPosition.shard, replicaPosition.type, subShardNodeName, replicaProps);\n      simAddReplica(replicaPosition.node, ri, false);\n    }\n    simRunLeaderElection(Collections.singleton(collectionName), true);\n\n    // delay it once again to better simulate replica recoveries\n    //opDelay(collectionName, CollectionParams.CollectionAction.SPLITSHARD.name());\n\n    boolean success = false;\n    try {\n      CloudUtil.waitForState(cloudManager, collectionName, 30, TimeUnit.SECONDS, (liveNodes, state) -> {\n        for (String subSlice : subSlices) {\n          Slice s = state.getSlice(subSlice);\n          if (s.getLeader() == null) {\n            log.debug(\"** no leader in {} / {}\", collectionName, s);\n            return false;\n          }\n          if (s.getReplicas().size() < repFactor) {\n            log.debug(\"** expected {} repFactor but there are {} replicas\", repFactor, s.getReplicas().size());\n            return false;\n          }\n        }\n        return true;\n      });\n      success = true;\n    } finally {\n      if (!success) {\n        Map<String, Object> sProps = sliceProperties.computeIfAbsent(collectionName, c -> new ConcurrentHashMap<>())\n            .computeIfAbsent(sliceName.get(), s -> new ConcurrentHashMap<>());\n        sProps.remove(BUFFERED_UPDATES);\n        SplitShardCmd.unlockForSplit(cloudManager, collectionName, sliceName.get());\n      }\n    }\n    // mark the new slices as active and the old slice as inactive\n    log.trace(\"-- switching slice states after split shard: collection={}, parent={}, subSlices={}\", collectionName,\n        sliceName.get(), subSlices);\n    lock.lockInterruptibly();\n    try {\n      Map<String, Object> sProps = sliceProperties.computeIfAbsent(collectionName, c -> new ConcurrentHashMap<>())\n          .computeIfAbsent(sliceName.get(), s -> new ConcurrentHashMap<>());\n      sProps.put(ZkStateReader.STATE_PROP, Slice.State.INACTIVE.toString());\n      sProps.put(ZkStateReader.STATE_TIMESTAMP_PROP, String.valueOf(cloudManager.getTimeSource().getEpochTimeNs()));\n      AtomicLong bufferedUpdates = (AtomicLong)sProps.remove(BUFFERED_UPDATES);\n      if (bufferedUpdates.get() > 0) {\n        // apply buffered updates\n        long perShard = bufferedUpdates.get() / subSlices.size();\n        long remainder = bufferedUpdates.get() % subSlices.size();\n        log.debug(\"-- applying {} buffered docs from {} / {}, perShard={}, remainder={}\", bufferedUpdates.get(),\n            collectionName, parentSlice.getName(), perShard, remainder);\n        for (int i = 0; i < subSlices.size(); i++) {\n          String sub = subSlices.get(i);\n          long numUpdates = perShard;\n          if (i == 0) {\n            numUpdates += remainder;\n          }\n          simSetShardValue(collectionName, sub, \"SEARCHER.searcher.numDocs\", numUpdates, true, false);\n          simSetShardValue(collectionName, sub, \"SEARCHER.searcher.maxDoc\", numUpdates, true, false);\n        }\n      }\n      // XXX also mark replicas as down? currently SplitShardCmd doesn't do this\n\n      for (String s : subSlices) {\n        Map<String, Object> sliceProps = sliceProperties.computeIfAbsent(collectionName, c -> new ConcurrentHashMap<>())\n            .computeIfAbsent(s, ss -> new ConcurrentHashMap<>());\n        sliceProps.put(ZkStateReader.STATE_PROP, Slice.State.ACTIVE.toString());\n        sliceProps.put(ZkStateReader.STATE_TIMESTAMP_PROP, String.valueOf(cloudManager.getTimeSource().getEpochTimeNs()));\n      }\n\n      // invalidate cached state\n      collectionsStatesRef.set(null);\n    } finally {\n      SplitShardCmd.unlockForSplit(cloudManager, collectionName, sliceName.get());\n      lock.unlock();\n    }\n    results.add(\"success\", \"\");\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"993b0c7dda6341b437fe5685d35c6cc35eaac420","date":1575985950,"type":3,"author":"Dawid Weiss","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/cloud/autoscaling/sim/SimClusterStateProvider#simSplitShard(ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/autoscaling/sim/SimClusterStateProvider#simSplitShard(ZkNodeProps,NamedList).mjava","sourceNew":"  /**\n   * Split a shard. This uses a similar algorithm as {@link SplitShardCmd}, including simulating its\n   * quirks, and leaving the original parent slice in place.\n   * @param message operation details\n   * @param results operation results.\n   */\n  public void simSplitShard(ZkNodeProps message, NamedList results) throws Exception {\n    ensureNotClosed();\n    if (message.getStr(CommonAdminParams.ASYNC) != null) {\n      results.add(CoreAdminParams.REQUESTID, message.getStr(CommonAdminParams.ASYNC));\n    }\n    String collectionName = message.getStr(COLLECTION_PROP);\n    AtomicReference<String> sliceName = new AtomicReference<>();\n    sliceName.set(message.getStr(SHARD_ID_PROP));\n    String splitKey = message.getStr(\"split.key\");\n    String methodStr = message.getStr(CommonAdminParams.SPLIT_METHOD, SolrIndexSplitter.SplitMethod.REWRITE.toLower());\n    SolrIndexSplitter.SplitMethod splitMethod = SolrIndexSplitter.SplitMethod.get(methodStr);\n    if (splitMethod == null) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Unknown value '\" + CommonAdminParams.SPLIT_METHOD +\n          \": \" + methodStr);\n    }\n\n    ClusterState clusterState = getClusterState();\n    DocCollection collection = clusterState.getCollection(collectionName);\n    Slice parentSlice = SplitShardCmd.getParentSlice(clusterState, collectionName, sliceName, splitKey);\n    Replica leader = parentSlice.getLeader();\n    // XXX leader election may not have happened yet - should we require it?\n    if (leader == null) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Shard \" + collectionName +\n          \" /  \" + sliceName.get() + \" has no leader and can't be split\");\n    }\n    SplitShardCmd.checkDiskSpace(collectionName, sliceName.get(), leader, splitMethod, cloudManager);\n    SplitShardCmd.lockForSplit(cloudManager, collectionName, sliceName.get());\n    // start counting buffered updates\n    Map<String, Object> props = sliceProperties.computeIfAbsent(collectionName, c -> new ConcurrentHashMap<>())\n        .computeIfAbsent(sliceName.get(), ss -> new ConcurrentHashMap<>());\n    if (props.containsKey(BUFFERED_UPDATES)) {\n      SplitShardCmd.unlockForSplit(cloudManager, collectionName, sliceName.get());\n      throw new Exception(\"--- SOLR-12729: Overlapping splitShard commands for \" + collectionName + \"/\" + sliceName.get());\n    }\n    props.put(BUFFERED_UPDATES, new AtomicLong());\n\n    List<DocRouter.Range> subRanges = new ArrayList<>();\n    List<String> subSlices = new ArrayList<>();\n    List<String> subShardNames = new ArrayList<>();\n\n    opDelay(collectionName, CollectionParams.CollectionAction.SPLITSHARD.name());\n\n    SplitShardCmd.fillRanges(cloudManager, message, collection, parentSlice, subRanges, subSlices, subShardNames, true);\n    // add replicas for new subShards\n    int repFactor = parentSlice.getReplicas().size();\n    Assign.AssignRequest assignRequest = new Assign.AssignRequestBuilder()\n        .forCollection(collectionName)\n        .forShard(subSlices)\n        .assignNrtReplicas(repFactor)\n        .assignTlogReplicas(0)\n        .assignPullReplicas(0)\n        .onNodes(new ArrayList<>(clusterState.getLiveNodes()))\n        .build();\n    Assign.AssignStrategyFactory assignStrategyFactory = new Assign.AssignStrategyFactory(cloudManager);\n    Assign.AssignStrategy assignStrategy = assignStrategyFactory.create(clusterState, collection);\n    // reproduce the bug\n    List<ReplicaPosition> replicaPositions = assignStrategy.assign(cloudManager, assignRequest);\n    PolicyHelper.SessionWrapper sessionWrapper = PolicyHelper.getLastSessionWrapper(true);\n    if (sessionWrapper != null) sessionWrapper.release();\n\n    // adjust numDocs / deletedDocs / maxDoc\n    String numDocsStr = String.valueOf(getReplicaInfo(leader).getVariable(\"SEARCHER.searcher.numDocs\", \"0\"));\n    long numDocs = Long.parseLong(numDocsStr);\n    long newNumDocs = numDocs / subSlices.size();\n    long remainderDocs = numDocs % subSlices.size();\n    long newIndexSize = SimCloudManager.DEFAULT_IDX_SIZE_BYTES + newNumDocs * DEFAULT_DOC_SIZE_BYTES;\n    long remainderIndexSize = SimCloudManager.DEFAULT_IDX_SIZE_BYTES + remainderDocs * DEFAULT_DOC_SIZE_BYTES;\n    String remainderSlice = null;\n\n    // add slice props\n    for (int i = 0; i < subRanges.size(); i++) {\n      String subSlice = subSlices.get(i);\n      DocRouter.Range range = subRanges.get(i);\n      Map<String, Object> sliceProps = sliceProperties.computeIfAbsent(collectionName, c -> new ConcurrentHashMap<>())\n          .computeIfAbsent(subSlice, ss -> new ConcurrentHashMap<>());\n      sliceProps.put(Slice.RANGE, range);\n      sliceProps.put(Slice.PARENT, sliceName.get());\n      sliceProps.put(ZkStateReader.STATE_PROP, Slice.State.CONSTRUCTION.toString());\n      sliceProps.put(ZkStateReader.STATE_TIMESTAMP_PROP, String.valueOf(cloudManager.getTimeSource().getEpochTimeNs()));\n    }\n    // add replicas\n    for (ReplicaPosition replicaPosition : replicaPositions) {\n      String subSliceName = replicaPosition.shard;\n      String subShardNodeName = replicaPosition.node;\n//      String solrCoreName = collectionName + \"_\" + subSliceName + \"_replica_n\" + (replicaPosition.index);\n      String solrCoreName = Assign.buildSolrCoreName(collectionName, subSliceName, replicaPosition.type, Assign.incAndGetId(stateManager, collectionName, 0));\n      Map<String, Object> replicaProps = new HashMap<>();\n      replicaProps.put(ZkStateReader.SHARD_ID_PROP, replicaPosition.shard);\n      replicaProps.put(ZkStateReader.NODE_NAME_PROP, replicaPosition.node);\n      replicaProps.put(ZkStateReader.REPLICA_TYPE, replicaPosition.type.toString());\n      replicaProps.put(ZkStateReader.BASE_URL_PROP, Utils.getBaseUrlForNodeName(subShardNodeName, \"http\"));\n\n      long replicasNumDocs = newNumDocs;\n      long replicasIndexSize = newIndexSize;\n      if (remainderSlice == null) {\n        remainderSlice = subSliceName;\n      }\n      if (remainderSlice.equals(subSliceName)) { // only add to one sub slice\n        replicasNumDocs += remainderDocs;\n        replicasIndexSize += remainderIndexSize;\n      }\n      replicaProps.put(\"SEARCHER.searcher.numDocs\", new AtomicLong(replicasNumDocs));\n      replicaProps.put(\"SEARCHER.searcher.maxDoc\", new AtomicLong(replicasNumDocs));\n      replicaProps.put(\"SEARCHER.searcher.deletedDocs\", new AtomicLong(0));\n      replicaProps.put(Type.CORE_IDX.metricsAttribute, new AtomicLong(replicasIndexSize));\n      replicaProps.put(Variable.coreidxsize, new AtomicDouble((Double)Type.CORE_IDX.convertVal(replicasIndexSize)));\n\n      ReplicaInfo ri = new ReplicaInfo(\"core_node\" + Assign.incAndGetId(stateManager, collectionName, 0),\n          solrCoreName, collectionName, replicaPosition.shard, replicaPosition.type, subShardNodeName, replicaProps);\n      simAddReplica(replicaPosition.node, ri, false);\n    }\n    simRunLeaderElection(Collections.singleton(collectionName), true);\n\n    // delay it once again to better simulate replica recoveries\n    //opDelay(collectionName, CollectionParams.CollectionAction.SPLITSHARD.name());\n\n    boolean success = false;\n    try {\n      CloudUtil.waitForState(cloudManager, collectionName, 30, TimeUnit.SECONDS, (liveNodes, state) -> {\n        for (String subSlice : subSlices) {\n          Slice s = state.getSlice(subSlice);\n          if (s.getLeader() == null) {\n            log.debug(\"** no leader in {} / {}\", collectionName, s);\n            return false;\n          }\n          if (s.getReplicas().size() < repFactor) {\n            log.debug(\"** expected {} repFactor but there are {} replicas\", repFactor, s.getReplicas().size());\n            return false;\n          }\n        }\n        return true;\n      });\n      success = true;\n    } finally {\n      if (!success) {\n        Map<String, Object> sProps = sliceProperties.computeIfAbsent(collectionName, c -> new ConcurrentHashMap<>())\n            .computeIfAbsent(sliceName.get(), s -> new ConcurrentHashMap<>());\n        sProps.remove(BUFFERED_UPDATES);\n        SplitShardCmd.unlockForSplit(cloudManager, collectionName, sliceName.get());\n      }\n    }\n    // mark the new slices as active and the old slice as inactive\n    log.trace(\"-- switching slice states after split shard: collection={}, parent={}, subSlices={}\", collectionName,\n        sliceName.get(), subSlices);\n    lock.lockInterruptibly();\n    try {\n      Map<String, Object> sProps = sliceProperties.computeIfAbsent(collectionName, c -> new ConcurrentHashMap<>())\n          .computeIfAbsent(sliceName.get(), s -> new ConcurrentHashMap<>());\n      sProps.put(ZkStateReader.STATE_PROP, Slice.State.INACTIVE.toString());\n      sProps.put(ZkStateReader.STATE_TIMESTAMP_PROP, String.valueOf(cloudManager.getTimeSource().getEpochTimeNs()));\n      AtomicLong bufferedUpdates = (AtomicLong)sProps.remove(BUFFERED_UPDATES);\n      if (bufferedUpdates.get() > 0) {\n        // apply buffered updates\n        long perShard = bufferedUpdates.get() / subSlices.size();\n        long remainder = bufferedUpdates.get() % subSlices.size();\n        log.debug(\"-- applying {} buffered docs from {} / {}, perShard={}, remainder={}\", bufferedUpdates.get(),\n            collectionName, parentSlice.getName(), perShard, remainder);\n        for (int i = 0; i < subSlices.size(); i++) {\n          String sub = subSlices.get(i);\n          long numUpdates = perShard;\n          if (i == 0) {\n            numUpdates += remainder;\n          }\n          simSetShardValue(collectionName, sub, \"SEARCHER.searcher.numDocs\", numUpdates, true, false);\n          simSetShardValue(collectionName, sub, \"SEARCHER.searcher.maxDoc\", numUpdates, true, false);\n        }\n      }\n      // XXX also mark replicas as down? currently SplitShardCmd doesn't do this\n\n      for (String s : subSlices) {\n        Map<String, Object> sliceProps = sliceProperties.computeIfAbsent(collectionName, c -> new ConcurrentHashMap<>())\n            .computeIfAbsent(s, ss -> new ConcurrentHashMap<>());\n        sliceProps.put(ZkStateReader.STATE_PROP, Slice.State.ACTIVE.toString());\n        sliceProps.put(ZkStateReader.STATE_TIMESTAMP_PROP, String.valueOf(cloudManager.getTimeSource().getEpochTimeNs()));\n      }\n\n      // invalidate cached state\n      collectionsStatesRef.set(null);\n    } finally {\n      SplitShardCmd.unlockForSplit(cloudManager, collectionName, sliceName.get());\n      lock.unlock();\n    }\n    results.add(\"success\", \"\");\n\n  }\n\n","sourceOld":"  /**\n   * Split a shard. This uses a similar algorithm as {@link SplitShardCmd}, including simulating its\n   * quirks, and leaving the original parent slice in place.\n   * @param message operation details\n   * @param results operation results.\n   */\n  public void simSplitShard(ZkNodeProps message, NamedList results) throws Exception {\n    ensureNotClosed();\n    if (message.getStr(CommonAdminParams.ASYNC) != null) {\n      results.add(CoreAdminParams.REQUESTID, message.getStr(CommonAdminParams.ASYNC));\n    }\n    String collectionName = message.getStr(COLLECTION_PROP);\n    AtomicReference<String> sliceName = new AtomicReference<>();\n    sliceName.set(message.getStr(SHARD_ID_PROP));\n    String splitKey = message.getStr(\"split.key\");\n\n    ClusterState clusterState = getClusterState();\n    DocCollection collection = clusterState.getCollection(collectionName);\n    Slice parentSlice = SplitShardCmd.getParentSlice(clusterState, collectionName, sliceName, splitKey);\n    Replica leader = parentSlice.getLeader();\n    // XXX leader election may not have happened yet - should we require it?\n    if (leader == null) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Shard \" + collectionName +\n          \" /  \" + sliceName.get() + \" has no leader and can't be split\");\n    }\n    SplitShardCmd.lockForSplit(cloudManager, collectionName, sliceName.get());\n    // start counting buffered updates\n    Map<String, Object> props = sliceProperties.computeIfAbsent(collectionName, c -> new ConcurrentHashMap<>())\n        .computeIfAbsent(sliceName.get(), ss -> new ConcurrentHashMap<>());\n    if (props.containsKey(BUFFERED_UPDATES)) {\n      SplitShardCmd.unlockForSplit(cloudManager, collectionName, sliceName.get());\n      throw new Exception(\"--- SOLR-12729: Overlapping splitShard commands for \" + collectionName + \"/\" + sliceName.get());\n    }\n    props.put(BUFFERED_UPDATES, new AtomicLong());\n\n    List<DocRouter.Range> subRanges = new ArrayList<>();\n    List<String> subSlices = new ArrayList<>();\n    List<String> subShardNames = new ArrayList<>();\n\n    opDelay(collectionName, CollectionParams.CollectionAction.SPLITSHARD.name());\n\n    SplitShardCmd.fillRanges(cloudManager, message, collection, parentSlice, subRanges, subSlices, subShardNames, true);\n    // add replicas for new subShards\n    int repFactor = parentSlice.getReplicas().size();\n    Assign.AssignRequest assignRequest = new Assign.AssignRequestBuilder()\n        .forCollection(collectionName)\n        .forShard(subSlices)\n        .assignNrtReplicas(repFactor)\n        .assignTlogReplicas(0)\n        .assignPullReplicas(0)\n        .onNodes(new ArrayList<>(clusterState.getLiveNodes()))\n        .build();\n    Assign.AssignStrategyFactory assignStrategyFactory = new Assign.AssignStrategyFactory(cloudManager);\n    Assign.AssignStrategy assignStrategy = assignStrategyFactory.create(clusterState, collection);\n    // reproduce the bug\n    List<ReplicaPosition> replicaPositions = assignStrategy.assign(cloudManager, assignRequest);\n    PolicyHelper.SessionWrapper sessionWrapper = PolicyHelper.getLastSessionWrapper(true);\n    if (sessionWrapper != null) sessionWrapper.release();\n\n    // adjust numDocs / deletedDocs / maxDoc\n    String numDocsStr = String.valueOf(getReplicaInfo(leader).getVariable(\"SEARCHER.searcher.numDocs\", \"0\"));\n    long numDocs = Long.parseLong(numDocsStr);\n    long newNumDocs = numDocs / subSlices.size();\n    long remainderDocs = numDocs % subSlices.size();\n    long newIndexSize = SimCloudManager.DEFAULT_IDX_SIZE_BYTES + newNumDocs * DEFAULT_DOC_SIZE_BYTES;\n    long remainderIndexSize = SimCloudManager.DEFAULT_IDX_SIZE_BYTES + remainderDocs * DEFAULT_DOC_SIZE_BYTES;\n    String remainderSlice = null;\n\n    // add slice props\n    for (int i = 0; i < subRanges.size(); i++) {\n      String subSlice = subSlices.get(i);\n      DocRouter.Range range = subRanges.get(i);\n      Map<String, Object> sliceProps = sliceProperties.computeIfAbsent(collectionName, c -> new ConcurrentHashMap<>())\n          .computeIfAbsent(subSlice, ss -> new ConcurrentHashMap<>());\n      sliceProps.put(Slice.RANGE, range);\n      sliceProps.put(Slice.PARENT, sliceName.get());\n      sliceProps.put(ZkStateReader.STATE_PROP, Slice.State.CONSTRUCTION.toString());\n      sliceProps.put(ZkStateReader.STATE_TIMESTAMP_PROP, String.valueOf(cloudManager.getTimeSource().getEpochTimeNs()));\n    }\n    // add replicas\n    for (ReplicaPosition replicaPosition : replicaPositions) {\n      String subSliceName = replicaPosition.shard;\n      String subShardNodeName = replicaPosition.node;\n//      String solrCoreName = collectionName + \"_\" + subSliceName + \"_replica_n\" + (replicaPosition.index);\n      String solrCoreName = Assign.buildSolrCoreName(collectionName, subSliceName, replicaPosition.type, Assign.incAndGetId(stateManager, collectionName, 0));\n      Map<String, Object> replicaProps = new HashMap<>();\n      replicaProps.put(ZkStateReader.SHARD_ID_PROP, replicaPosition.shard);\n      replicaProps.put(ZkStateReader.NODE_NAME_PROP, replicaPosition.node);\n      replicaProps.put(ZkStateReader.REPLICA_TYPE, replicaPosition.type.toString());\n      replicaProps.put(ZkStateReader.BASE_URL_PROP, Utils.getBaseUrlForNodeName(subShardNodeName, \"http\"));\n\n      long replicasNumDocs = newNumDocs;\n      long replicasIndexSize = newIndexSize;\n      if (remainderSlice == null) {\n        remainderSlice = subSliceName;\n      }\n      if (remainderSlice.equals(subSliceName)) { // only add to one sub slice\n        replicasNumDocs += remainderDocs;\n        replicasIndexSize += remainderIndexSize;\n      }\n      replicaProps.put(\"SEARCHER.searcher.numDocs\", new AtomicLong(replicasNumDocs));\n      replicaProps.put(\"SEARCHER.searcher.maxDoc\", new AtomicLong(replicasNumDocs));\n      replicaProps.put(\"SEARCHER.searcher.deletedDocs\", new AtomicLong(0));\n      replicaProps.put(Type.CORE_IDX.metricsAttribute, new AtomicLong(replicasIndexSize));\n      replicaProps.put(Variable.coreidxsize, new AtomicDouble((Double)Type.CORE_IDX.convertVal(replicasIndexSize)));\n\n      ReplicaInfo ri = new ReplicaInfo(\"core_node\" + Assign.incAndGetId(stateManager, collectionName, 0),\n          solrCoreName, collectionName, replicaPosition.shard, replicaPosition.type, subShardNodeName, replicaProps);\n      simAddReplica(replicaPosition.node, ri, false);\n    }\n    simRunLeaderElection(Collections.singleton(collectionName), true);\n\n    // delay it once again to better simulate replica recoveries\n    //opDelay(collectionName, CollectionParams.CollectionAction.SPLITSHARD.name());\n\n    boolean success = false;\n    try {\n      CloudUtil.waitForState(cloudManager, collectionName, 30, TimeUnit.SECONDS, (liveNodes, state) -> {\n        for (String subSlice : subSlices) {\n          Slice s = state.getSlice(subSlice);\n          if (s.getLeader() == null) {\n            log.debug(\"** no leader in {} / {}\", collectionName, s);\n            return false;\n          }\n          if (s.getReplicas().size() < repFactor) {\n            log.debug(\"** expected {} repFactor but there are {} replicas\", repFactor, s.getReplicas().size());\n            return false;\n          }\n        }\n        return true;\n      });\n      success = true;\n    } finally {\n      if (!success) {\n        Map<String, Object> sProps = sliceProperties.computeIfAbsent(collectionName, c -> new ConcurrentHashMap<>())\n            .computeIfAbsent(sliceName.get(), s -> new ConcurrentHashMap<>());\n        sProps.remove(BUFFERED_UPDATES);\n        SplitShardCmd.unlockForSplit(cloudManager, collectionName, sliceName.get());\n      }\n    }\n    // mark the new slices as active and the old slice as inactive\n    log.trace(\"-- switching slice states after split shard: collection={}, parent={}, subSlices={}\", collectionName,\n        sliceName.get(), subSlices);\n    lock.lockInterruptibly();\n    try {\n      Map<String, Object> sProps = sliceProperties.computeIfAbsent(collectionName, c -> new ConcurrentHashMap<>())\n          .computeIfAbsent(sliceName.get(), s -> new ConcurrentHashMap<>());\n      sProps.put(ZkStateReader.STATE_PROP, Slice.State.INACTIVE.toString());\n      sProps.put(ZkStateReader.STATE_TIMESTAMP_PROP, String.valueOf(cloudManager.getTimeSource().getEpochTimeNs()));\n      AtomicLong bufferedUpdates = (AtomicLong)sProps.remove(BUFFERED_UPDATES);\n      if (bufferedUpdates.get() > 0) {\n        // apply buffered updates\n        long perShard = bufferedUpdates.get() / subSlices.size();\n        long remainder = bufferedUpdates.get() % subSlices.size();\n        log.debug(\"-- applying {} buffered docs from {} / {}, perShard={}, remainder={}\", bufferedUpdates.get(),\n            collectionName, parentSlice.getName(), perShard, remainder);\n        for (int i = 0; i < subSlices.size(); i++) {\n          String sub = subSlices.get(i);\n          long numUpdates = perShard;\n          if (i == 0) {\n            numUpdates += remainder;\n          }\n          simSetShardValue(collectionName, sub, \"SEARCHER.searcher.numDocs\", numUpdates, true, false);\n          simSetShardValue(collectionName, sub, \"SEARCHER.searcher.maxDoc\", numUpdates, true, false);\n        }\n      }\n      // XXX also mark replicas as down? currently SplitShardCmd doesn't do this\n\n      for (String s : subSlices) {\n        Map<String, Object> sliceProps = sliceProperties.computeIfAbsent(collectionName, c -> new ConcurrentHashMap<>())\n            .computeIfAbsent(s, ss -> new ConcurrentHashMap<>());\n        sliceProps.put(ZkStateReader.STATE_PROP, Slice.State.ACTIVE.toString());\n        sliceProps.put(ZkStateReader.STATE_TIMESTAMP_PROP, String.valueOf(cloudManager.getTimeSource().getEpochTimeNs()));\n      }\n\n      // invalidate cached state\n      collectionsStatesRef.set(null);\n    } finally {\n      SplitShardCmd.unlockForSplit(cloudManager, collectionName, sliceName.get());\n      lock.unlock();\n    }\n    results.add(\"success\", \"\");\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e35f2dde06b35aa9904949a3a93fabd090371077","date":1587906921,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/autoscaling/sim/SimClusterStateProvider#simSplitShard(ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/autoscaling/sim/SimClusterStateProvider#simSplitShard(ZkNodeProps,NamedList).mjava","sourceNew":"  /**\n   * Split a shard. This uses a similar algorithm as {@link SplitShardCmd}, including simulating its\n   * quirks, and leaving the original parent slice in place.\n   * @param message operation details\n   * @param results operation results.\n   */\n  public void simSplitShard(ZkNodeProps message, NamedList results) throws Exception {\n    ensureNotClosed();\n    if (message.getStr(CommonAdminParams.ASYNC) != null) {\n      results.add(CoreAdminParams.REQUESTID, message.getStr(CommonAdminParams.ASYNC));\n    }\n    String collectionName = message.getStr(COLLECTION_PROP);\n    AtomicReference<String> sliceName = new AtomicReference<>();\n    sliceName.set(message.getStr(SHARD_ID_PROP));\n    String splitKey = message.getStr(\"split.key\");\n    String methodStr = message.getStr(CommonAdminParams.SPLIT_METHOD, SolrIndexSplitter.SplitMethod.REWRITE.toLower());\n    SolrIndexSplitter.SplitMethod splitMethod = SolrIndexSplitter.SplitMethod.get(methodStr);\n    if (splitMethod == null) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Unknown value '\" + CommonAdminParams.SPLIT_METHOD +\n          \": \" + methodStr);\n    }\n\n    ClusterState clusterState = getClusterState();\n    DocCollection collection = clusterState.getCollection(collectionName);\n    Slice parentSlice = SplitShardCmd.getParentSlice(clusterState, collectionName, sliceName, splitKey);\n    Replica leader = parentSlice.getLeader();\n    // XXX leader election may not have happened yet - should we require it?\n    if (leader == null) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Shard \" + collectionName +\n          \" /  \" + sliceName.get() + \" has no leader and can't be split\");\n    }\n    SplitShardCmd.checkDiskSpace(collectionName, sliceName.get(), leader, splitMethod, cloudManager);\n    SplitShardCmd.lockForSplit(cloudManager, collectionName, sliceName.get());\n    // start counting buffered updates\n    Map<String, Object> props = sliceProperties.computeIfAbsent(collectionName, c -> new ConcurrentHashMap<>())\n        .computeIfAbsent(sliceName.get(), ss -> new ConcurrentHashMap<>());\n    if (props.containsKey(BUFFERED_UPDATES)) {\n      SplitShardCmd.unlockForSplit(cloudManager, collectionName, sliceName.get());\n      throw new Exception(\"--- SOLR-12729: Overlapping splitShard commands for \" + collectionName + \"/\" + sliceName.get());\n    }\n    props.put(BUFFERED_UPDATES, new AtomicLong());\n\n    List<DocRouter.Range> subRanges = new ArrayList<>();\n    List<String> subSlices = new ArrayList<>();\n    List<String> subShardNames = new ArrayList<>();\n\n    opDelay(collectionName, CollectionParams.CollectionAction.SPLITSHARD.name());\n\n    SplitShardCmd.fillRanges(cloudManager, message, collection, parentSlice, subRanges, subSlices, subShardNames, true);\n    // add replicas for new subShards\n    int repFactor = parentSlice.getReplicas().size();\n    Assign.AssignRequest assignRequest = new Assign.AssignRequestBuilder()\n        .forCollection(collectionName)\n        .forShard(subSlices)\n        .assignNrtReplicas(repFactor)\n        .assignTlogReplicas(0)\n        .assignPullReplicas(0)\n        .onNodes(new ArrayList<>(clusterState.getLiveNodes()))\n        .build();\n    Assign.AssignStrategyFactory assignStrategyFactory = new Assign.AssignStrategyFactory(cloudManager);\n    Assign.AssignStrategy assignStrategy = assignStrategyFactory.create(clusterState, collection);\n    // reproduce the bug\n    List<ReplicaPosition> replicaPositions = assignStrategy.assign(cloudManager, assignRequest);\n    PolicyHelper.SessionWrapper sessionWrapper = PolicyHelper.getLastSessionWrapper(true);\n    if (sessionWrapper != null) sessionWrapper.release();\n\n    // adjust numDocs / deletedDocs / maxDoc\n    String numDocsStr = String.valueOf(getReplicaInfo(leader).getVariable(\"SEARCHER.searcher.numDocs\", \"0\"));\n    long numDocs = Long.parseLong(numDocsStr);\n    long newNumDocs = numDocs / subSlices.size();\n    long remainderDocs = numDocs % subSlices.size();\n    long newIndexSize = SimCloudManager.DEFAULT_IDX_SIZE_BYTES + newNumDocs * DEFAULT_DOC_SIZE_BYTES;\n    long remainderIndexSize = SimCloudManager.DEFAULT_IDX_SIZE_BYTES + remainderDocs * DEFAULT_DOC_SIZE_BYTES;\n    String remainderSlice = null;\n\n    // add slice props\n    for (int i = 0; i < subRanges.size(); i++) {\n      String subSlice = subSlices.get(i);\n      DocRouter.Range range = subRanges.get(i);\n      Map<String, Object> sliceProps = sliceProperties.computeIfAbsent(collectionName, c -> new ConcurrentHashMap<>())\n          .computeIfAbsent(subSlice, ss -> new ConcurrentHashMap<>());\n      sliceProps.put(Slice.RANGE, range);\n      sliceProps.put(Slice.PARENT, sliceName.get());\n      sliceProps.put(ZkStateReader.STATE_PROP, Slice.State.CONSTRUCTION.toString());\n      sliceProps.put(ZkStateReader.STATE_TIMESTAMP_PROP, String.valueOf(cloudManager.getTimeSource().getEpochTimeNs()));\n    }\n    // add replicas\n    for (ReplicaPosition replicaPosition : replicaPositions) {\n      String subSliceName = replicaPosition.shard;\n      String subShardNodeName = replicaPosition.node;\n//      String solrCoreName = collectionName + \"_\" + subSliceName + \"_replica_n\" + (replicaPosition.index);\n      String solrCoreName = Assign.buildSolrCoreName(collectionName, subSliceName, replicaPosition.type, Assign.incAndGetId(stateManager, collectionName, 0));\n      Map<String, Object> replicaProps = new HashMap<>();\n      replicaProps.put(ZkStateReader.SHARD_ID_PROP, replicaPosition.shard);\n      replicaProps.put(ZkStateReader.NODE_NAME_PROP, replicaPosition.node);\n      replicaProps.put(ZkStateReader.REPLICA_TYPE, replicaPosition.type.toString());\n      replicaProps.put(ZkStateReader.BASE_URL_PROP, Utils.getBaseUrlForNodeName(subShardNodeName, \"http\"));\n\n      long replicasNumDocs = newNumDocs;\n      long replicasIndexSize = newIndexSize;\n      if (remainderSlice == null) {\n        remainderSlice = subSliceName;\n      }\n      if (remainderSlice.equals(subSliceName)) { // only add to one sub slice\n        replicasNumDocs += remainderDocs;\n        replicasIndexSize += remainderIndexSize;\n      }\n      replicaProps.put(\"SEARCHER.searcher.numDocs\", new AtomicLong(replicasNumDocs));\n      replicaProps.put(\"SEARCHER.searcher.maxDoc\", new AtomicLong(replicasNumDocs));\n      replicaProps.put(\"SEARCHER.searcher.deletedDocs\", new AtomicLong(0));\n      replicaProps.put(Type.CORE_IDX.metricsAttribute, new AtomicLong(replicasIndexSize));\n      replicaProps.put(Variable.coreidxsize, new AtomicDouble((Double)Type.CORE_IDX.convertVal(replicasIndexSize)));\n\n      ReplicaInfo ri = new ReplicaInfo(\"core_node\" + Assign.incAndGetId(stateManager, collectionName, 0),\n          solrCoreName, collectionName, replicaPosition.shard, replicaPosition.type, subShardNodeName, replicaProps);\n      simAddReplica(replicaPosition.node, ri, false);\n    }\n    simRunLeaderElection(Collections.singleton(collectionName), true);\n\n    // delay it once again to better simulate replica recoveries\n    //opDelay(collectionName, CollectionParams.CollectionAction.SPLITSHARD.name());\n\n    boolean success = false;\n    try {\n      CloudUtil.waitForState(cloudManager, collectionName, 30, TimeUnit.SECONDS, (liveNodes, state) -> {\n        for (String subSlice : subSlices) {\n          Slice s = state.getSlice(subSlice);\n          if (s.getLeader() == null) {\n            log.debug(\"** no leader in {} / {}\", collectionName, s);\n            return false;\n          }\n          if (s.getReplicas().size() < repFactor) {\n            if (log.isDebugEnabled()) {\n              log.debug(\"** expected {} repFactor but there are {} replicas\", repFactor, s.getReplicas().size());\n            }\n            return false;\n          }\n        }\n        return true;\n      });\n      success = true;\n    } finally {\n      if (!success) {\n        Map<String, Object> sProps = sliceProperties.computeIfAbsent(collectionName, c -> new ConcurrentHashMap<>())\n            .computeIfAbsent(sliceName.get(), s -> new ConcurrentHashMap<>());\n        sProps.remove(BUFFERED_UPDATES);\n        SplitShardCmd.unlockForSplit(cloudManager, collectionName, sliceName.get());\n      }\n    }\n    // mark the new slices as active and the old slice as inactive\n    if (log.isTraceEnabled()) {\n      log.trace(\"-- switching slice states after split shard: collection={}, parent={}, subSlices={}\", collectionName,\n          sliceName.get(), subSlices);\n    }\n    lock.lockInterruptibly();\n    try {\n      Map<String, Object> sProps = sliceProperties.computeIfAbsent(collectionName, c -> new ConcurrentHashMap<>())\n          .computeIfAbsent(sliceName.get(), s -> new ConcurrentHashMap<>());\n      sProps.put(ZkStateReader.STATE_PROP, Slice.State.INACTIVE.toString());\n      sProps.put(ZkStateReader.STATE_TIMESTAMP_PROP, String.valueOf(cloudManager.getTimeSource().getEpochTimeNs()));\n      AtomicLong bufferedUpdates = (AtomicLong)sProps.remove(BUFFERED_UPDATES);\n      if (bufferedUpdates.get() > 0) {\n        // apply buffered updates\n        long perShard = bufferedUpdates.get() / subSlices.size();\n        long remainder = bufferedUpdates.get() % subSlices.size();\n        if (log.isDebugEnabled()) {\n          log.debug(\"-- applying {} buffered docs from {} / {}, perShard={}, remainder={}\", bufferedUpdates.get(),\n              collectionName, parentSlice.getName(), perShard, remainder);\n        }\n        for (int i = 0; i < subSlices.size(); i++) {\n          String sub = subSlices.get(i);\n          long numUpdates = perShard;\n          if (i == 0) {\n            numUpdates += remainder;\n          }\n          simSetShardValue(collectionName, sub, \"SEARCHER.searcher.numDocs\", numUpdates, true, false);\n          simSetShardValue(collectionName, sub, \"SEARCHER.searcher.maxDoc\", numUpdates, true, false);\n        }\n      }\n      // XXX also mark replicas as down? currently SplitShardCmd doesn't do this\n\n      for (String s : subSlices) {\n        Map<String, Object> sliceProps = sliceProperties.computeIfAbsent(collectionName, c -> new ConcurrentHashMap<>())\n            .computeIfAbsent(s, ss -> new ConcurrentHashMap<>());\n        sliceProps.put(ZkStateReader.STATE_PROP, Slice.State.ACTIVE.toString());\n        sliceProps.put(ZkStateReader.STATE_TIMESTAMP_PROP, String.valueOf(cloudManager.getTimeSource().getEpochTimeNs()));\n      }\n\n      // invalidate cached state\n      collectionsStatesRef.set(null);\n    } finally {\n      SplitShardCmd.unlockForSplit(cloudManager, collectionName, sliceName.get());\n      lock.unlock();\n    }\n    results.add(\"success\", \"\");\n\n  }\n\n","sourceOld":"  /**\n   * Split a shard. This uses a similar algorithm as {@link SplitShardCmd}, including simulating its\n   * quirks, and leaving the original parent slice in place.\n   * @param message operation details\n   * @param results operation results.\n   */\n  public void simSplitShard(ZkNodeProps message, NamedList results) throws Exception {\n    ensureNotClosed();\n    if (message.getStr(CommonAdminParams.ASYNC) != null) {\n      results.add(CoreAdminParams.REQUESTID, message.getStr(CommonAdminParams.ASYNC));\n    }\n    String collectionName = message.getStr(COLLECTION_PROP);\n    AtomicReference<String> sliceName = new AtomicReference<>();\n    sliceName.set(message.getStr(SHARD_ID_PROP));\n    String splitKey = message.getStr(\"split.key\");\n    String methodStr = message.getStr(CommonAdminParams.SPLIT_METHOD, SolrIndexSplitter.SplitMethod.REWRITE.toLower());\n    SolrIndexSplitter.SplitMethod splitMethod = SolrIndexSplitter.SplitMethod.get(methodStr);\n    if (splitMethod == null) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Unknown value '\" + CommonAdminParams.SPLIT_METHOD +\n          \": \" + methodStr);\n    }\n\n    ClusterState clusterState = getClusterState();\n    DocCollection collection = clusterState.getCollection(collectionName);\n    Slice parentSlice = SplitShardCmd.getParentSlice(clusterState, collectionName, sliceName, splitKey);\n    Replica leader = parentSlice.getLeader();\n    // XXX leader election may not have happened yet - should we require it?\n    if (leader == null) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Shard \" + collectionName +\n          \" /  \" + sliceName.get() + \" has no leader and can't be split\");\n    }\n    SplitShardCmd.checkDiskSpace(collectionName, sliceName.get(), leader, splitMethod, cloudManager);\n    SplitShardCmd.lockForSplit(cloudManager, collectionName, sliceName.get());\n    // start counting buffered updates\n    Map<String, Object> props = sliceProperties.computeIfAbsent(collectionName, c -> new ConcurrentHashMap<>())\n        .computeIfAbsent(sliceName.get(), ss -> new ConcurrentHashMap<>());\n    if (props.containsKey(BUFFERED_UPDATES)) {\n      SplitShardCmd.unlockForSplit(cloudManager, collectionName, sliceName.get());\n      throw new Exception(\"--- SOLR-12729: Overlapping splitShard commands for \" + collectionName + \"/\" + sliceName.get());\n    }\n    props.put(BUFFERED_UPDATES, new AtomicLong());\n\n    List<DocRouter.Range> subRanges = new ArrayList<>();\n    List<String> subSlices = new ArrayList<>();\n    List<String> subShardNames = new ArrayList<>();\n\n    opDelay(collectionName, CollectionParams.CollectionAction.SPLITSHARD.name());\n\n    SplitShardCmd.fillRanges(cloudManager, message, collection, parentSlice, subRanges, subSlices, subShardNames, true);\n    // add replicas for new subShards\n    int repFactor = parentSlice.getReplicas().size();\n    Assign.AssignRequest assignRequest = new Assign.AssignRequestBuilder()\n        .forCollection(collectionName)\n        .forShard(subSlices)\n        .assignNrtReplicas(repFactor)\n        .assignTlogReplicas(0)\n        .assignPullReplicas(0)\n        .onNodes(new ArrayList<>(clusterState.getLiveNodes()))\n        .build();\n    Assign.AssignStrategyFactory assignStrategyFactory = new Assign.AssignStrategyFactory(cloudManager);\n    Assign.AssignStrategy assignStrategy = assignStrategyFactory.create(clusterState, collection);\n    // reproduce the bug\n    List<ReplicaPosition> replicaPositions = assignStrategy.assign(cloudManager, assignRequest);\n    PolicyHelper.SessionWrapper sessionWrapper = PolicyHelper.getLastSessionWrapper(true);\n    if (sessionWrapper != null) sessionWrapper.release();\n\n    // adjust numDocs / deletedDocs / maxDoc\n    String numDocsStr = String.valueOf(getReplicaInfo(leader).getVariable(\"SEARCHER.searcher.numDocs\", \"0\"));\n    long numDocs = Long.parseLong(numDocsStr);\n    long newNumDocs = numDocs / subSlices.size();\n    long remainderDocs = numDocs % subSlices.size();\n    long newIndexSize = SimCloudManager.DEFAULT_IDX_SIZE_BYTES + newNumDocs * DEFAULT_DOC_SIZE_BYTES;\n    long remainderIndexSize = SimCloudManager.DEFAULT_IDX_SIZE_BYTES + remainderDocs * DEFAULT_DOC_SIZE_BYTES;\n    String remainderSlice = null;\n\n    // add slice props\n    for (int i = 0; i < subRanges.size(); i++) {\n      String subSlice = subSlices.get(i);\n      DocRouter.Range range = subRanges.get(i);\n      Map<String, Object> sliceProps = sliceProperties.computeIfAbsent(collectionName, c -> new ConcurrentHashMap<>())\n          .computeIfAbsent(subSlice, ss -> new ConcurrentHashMap<>());\n      sliceProps.put(Slice.RANGE, range);\n      sliceProps.put(Slice.PARENT, sliceName.get());\n      sliceProps.put(ZkStateReader.STATE_PROP, Slice.State.CONSTRUCTION.toString());\n      sliceProps.put(ZkStateReader.STATE_TIMESTAMP_PROP, String.valueOf(cloudManager.getTimeSource().getEpochTimeNs()));\n    }\n    // add replicas\n    for (ReplicaPosition replicaPosition : replicaPositions) {\n      String subSliceName = replicaPosition.shard;\n      String subShardNodeName = replicaPosition.node;\n//      String solrCoreName = collectionName + \"_\" + subSliceName + \"_replica_n\" + (replicaPosition.index);\n      String solrCoreName = Assign.buildSolrCoreName(collectionName, subSliceName, replicaPosition.type, Assign.incAndGetId(stateManager, collectionName, 0));\n      Map<String, Object> replicaProps = new HashMap<>();\n      replicaProps.put(ZkStateReader.SHARD_ID_PROP, replicaPosition.shard);\n      replicaProps.put(ZkStateReader.NODE_NAME_PROP, replicaPosition.node);\n      replicaProps.put(ZkStateReader.REPLICA_TYPE, replicaPosition.type.toString());\n      replicaProps.put(ZkStateReader.BASE_URL_PROP, Utils.getBaseUrlForNodeName(subShardNodeName, \"http\"));\n\n      long replicasNumDocs = newNumDocs;\n      long replicasIndexSize = newIndexSize;\n      if (remainderSlice == null) {\n        remainderSlice = subSliceName;\n      }\n      if (remainderSlice.equals(subSliceName)) { // only add to one sub slice\n        replicasNumDocs += remainderDocs;\n        replicasIndexSize += remainderIndexSize;\n      }\n      replicaProps.put(\"SEARCHER.searcher.numDocs\", new AtomicLong(replicasNumDocs));\n      replicaProps.put(\"SEARCHER.searcher.maxDoc\", new AtomicLong(replicasNumDocs));\n      replicaProps.put(\"SEARCHER.searcher.deletedDocs\", new AtomicLong(0));\n      replicaProps.put(Type.CORE_IDX.metricsAttribute, new AtomicLong(replicasIndexSize));\n      replicaProps.put(Variable.coreidxsize, new AtomicDouble((Double)Type.CORE_IDX.convertVal(replicasIndexSize)));\n\n      ReplicaInfo ri = new ReplicaInfo(\"core_node\" + Assign.incAndGetId(stateManager, collectionName, 0),\n          solrCoreName, collectionName, replicaPosition.shard, replicaPosition.type, subShardNodeName, replicaProps);\n      simAddReplica(replicaPosition.node, ri, false);\n    }\n    simRunLeaderElection(Collections.singleton(collectionName), true);\n\n    // delay it once again to better simulate replica recoveries\n    //opDelay(collectionName, CollectionParams.CollectionAction.SPLITSHARD.name());\n\n    boolean success = false;\n    try {\n      CloudUtil.waitForState(cloudManager, collectionName, 30, TimeUnit.SECONDS, (liveNodes, state) -> {\n        for (String subSlice : subSlices) {\n          Slice s = state.getSlice(subSlice);\n          if (s.getLeader() == null) {\n            log.debug(\"** no leader in {} / {}\", collectionName, s);\n            return false;\n          }\n          if (s.getReplicas().size() < repFactor) {\n            log.debug(\"** expected {} repFactor but there are {} replicas\", repFactor, s.getReplicas().size());\n            return false;\n          }\n        }\n        return true;\n      });\n      success = true;\n    } finally {\n      if (!success) {\n        Map<String, Object> sProps = sliceProperties.computeIfAbsent(collectionName, c -> new ConcurrentHashMap<>())\n            .computeIfAbsent(sliceName.get(), s -> new ConcurrentHashMap<>());\n        sProps.remove(BUFFERED_UPDATES);\n        SplitShardCmd.unlockForSplit(cloudManager, collectionName, sliceName.get());\n      }\n    }\n    // mark the new slices as active and the old slice as inactive\n    log.trace(\"-- switching slice states after split shard: collection={}, parent={}, subSlices={}\", collectionName,\n        sliceName.get(), subSlices);\n    lock.lockInterruptibly();\n    try {\n      Map<String, Object> sProps = sliceProperties.computeIfAbsent(collectionName, c -> new ConcurrentHashMap<>())\n          .computeIfAbsent(sliceName.get(), s -> new ConcurrentHashMap<>());\n      sProps.put(ZkStateReader.STATE_PROP, Slice.State.INACTIVE.toString());\n      sProps.put(ZkStateReader.STATE_TIMESTAMP_PROP, String.valueOf(cloudManager.getTimeSource().getEpochTimeNs()));\n      AtomicLong bufferedUpdates = (AtomicLong)sProps.remove(BUFFERED_UPDATES);\n      if (bufferedUpdates.get() > 0) {\n        // apply buffered updates\n        long perShard = bufferedUpdates.get() / subSlices.size();\n        long remainder = bufferedUpdates.get() % subSlices.size();\n        log.debug(\"-- applying {} buffered docs from {} / {}, perShard={}, remainder={}\", bufferedUpdates.get(),\n            collectionName, parentSlice.getName(), perShard, remainder);\n        for (int i = 0; i < subSlices.size(); i++) {\n          String sub = subSlices.get(i);\n          long numUpdates = perShard;\n          if (i == 0) {\n            numUpdates += remainder;\n          }\n          simSetShardValue(collectionName, sub, \"SEARCHER.searcher.numDocs\", numUpdates, true, false);\n          simSetShardValue(collectionName, sub, \"SEARCHER.searcher.maxDoc\", numUpdates, true, false);\n        }\n      }\n      // XXX also mark replicas as down? currently SplitShardCmd doesn't do this\n\n      for (String s : subSlices) {\n        Map<String, Object> sliceProps = sliceProperties.computeIfAbsent(collectionName, c -> new ConcurrentHashMap<>())\n            .computeIfAbsent(s, ss -> new ConcurrentHashMap<>());\n        sliceProps.put(ZkStateReader.STATE_PROP, Slice.State.ACTIVE.toString());\n        sliceProps.put(ZkStateReader.STATE_TIMESTAMP_PROP, String.valueOf(cloudManager.getTimeSource().getEpochTimeNs()));\n      }\n\n      // invalidate cached state\n      collectionsStatesRef.set(null);\n    } finally {\n      SplitShardCmd.unlockForSplit(cloudManager, collectionName, sliceName.get());\n      lock.unlock();\n    }\n    results.add(\"success\", \"\");\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"eb7a329be123e1f46f9d78d74f6d23f33ec81b0a","date":1589907167,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/autoscaling/sim/SimClusterStateProvider#simSplitShard(ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/autoscaling/sim/SimClusterStateProvider#simSplitShard(ZkNodeProps,NamedList).mjava","sourceNew":"  /**\n   * Split a shard. This uses a similar algorithm as {@link SplitShardCmd}, including simulating its\n   * quirks, and leaving the original parent slice in place.\n   * @param message operation details\n   * @param results operation results.\n   */\n  public void simSplitShard(ZkNodeProps message, NamedList results) throws Exception {\n    ensureNotClosed();\n    if (message.getStr(CommonAdminParams.ASYNC) != null) {\n      results.add(CoreAdminParams.REQUESTID, message.getStr(CommonAdminParams.ASYNC));\n    }\n    String collectionName = message.getStr(COLLECTION_PROP);\n    AtomicReference<String> sliceName = new AtomicReference<>();\n    sliceName.set(message.getStr(SHARD_ID_PROP));\n    String splitKey = message.getStr(\"split.key\");\n    String methodStr = message.getStr(CommonAdminParams.SPLIT_METHOD, SolrIndexSplitter.SplitMethod.REWRITE.toLower());\n    SolrIndexSplitter.SplitMethod splitMethod = SolrIndexSplitter.SplitMethod.get(methodStr);\n    if (splitMethod == null) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Unknown value '\" + CommonAdminParams.SPLIT_METHOD +\n          \": \" + methodStr);\n    }\n\n    ClusterState clusterState = getClusterState();\n    DocCollection collection = clusterState.getCollection(collectionName);\n    Slice parentSlice = SplitShardCmd.getParentSlice(clusterState, collectionName, sliceName, splitKey);\n    Replica leader = parentSlice.getLeader();\n    // XXX leader election may not have happened yet - should we require it?\n    if (leader == null) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Shard \" + collectionName +\n          \" /  \" + sliceName.get() + \" has no leader and can't be split\");\n    }\n    SplitShardCmd.checkDiskSpace(collectionName, sliceName.get(), leader, splitMethod, cloudManager);\n    SplitShardCmd.lockForSplit(cloudManager, collectionName, sliceName.get());\n    // start counting buffered updates\n    Map<String, Object> props = sliceProperties.computeIfAbsent(collectionName, c -> new ConcurrentHashMap<>())\n        .computeIfAbsent(sliceName.get(), ss -> new ConcurrentHashMap<>());\n    if (props.containsKey(BUFFERED_UPDATES)) {\n      SplitShardCmd.unlockForSplit(cloudManager, collectionName, sliceName.get());\n      throw new Exception(\"--- SOLR-12729: Overlapping splitShard commands for \" + collectionName + \"/\" + sliceName.get());\n    }\n    props.put(BUFFERED_UPDATES, new AtomicLong());\n\n    List<DocRouter.Range> subRanges = new ArrayList<>();\n    List<String> subSlices = new ArrayList<>();\n    List<String> subShardNames = new ArrayList<>();\n\n    opDelay(collectionName, CollectionParams.CollectionAction.SPLITSHARD.name());\n\n    SplitShardCmd.fillRanges(cloudManager, message, collection, parentSlice, subRanges, subSlices, subShardNames, true);\n    // add replicas for new subShards\n    int repFactor = parentSlice.getReplicas().size();\n    Assign.AssignRequest assignRequest = new Assign.AssignRequestBuilder()\n        .forCollection(collectionName)\n        .forShard(subSlices)\n        .assignNrtReplicas(repFactor)\n        .assignTlogReplicas(0)\n        .assignPullReplicas(0)\n        .onNodes(new ArrayList<>(clusterState.getLiveNodes()))\n        .build();\n    Assign.AssignStrategyFactory assignStrategyFactory = new Assign.AssignStrategyFactory(cloudManager);\n    Assign.AssignStrategy assignStrategy = assignStrategyFactory.create(clusterState, collection);\n    // reproduce the bug\n    List<ReplicaPosition> replicaPositions = assignStrategy.assign(cloudManager, assignRequest);\n    PolicyHelper.SessionWrapper sessionWrapper = PolicyHelper.getLastSessionWrapper(true);\n    if (sessionWrapper != null) sessionWrapper.release();\n\n    // adjust numDocs / deletedDocs / maxDoc\n    String numDocsStr = String.valueOf(getReplicaInfo(leader).getVariable(\"SEARCHER.searcher.numDocs\", \"0\"));\n    long numDocs = Long.parseLong(numDocsStr);\n    long newNumDocs = numDocs / subSlices.size();\n    long remainderDocs = numDocs % subSlices.size();\n    long newIndexSize = SimCloudManager.DEFAULT_IDX_SIZE_BYTES + newNumDocs * DEFAULT_DOC_SIZE_BYTES;\n    long remainderIndexSize = SimCloudManager.DEFAULT_IDX_SIZE_BYTES + remainderDocs * DEFAULT_DOC_SIZE_BYTES;\n    String remainderSlice = null;\n\n    // add slice props\n    for (int i = 0; i < subRanges.size(); i++) {\n      String subSlice = subSlices.get(i);\n      DocRouter.Range range = subRanges.get(i);\n      Map<String, Object> sliceProps = sliceProperties.computeIfAbsent(collectionName, c -> new ConcurrentHashMap<>())\n          .computeIfAbsent(subSlice, ss -> new ConcurrentHashMap<>());\n      sliceProps.put(Slice.RANGE, range);\n      sliceProps.put(Slice.PARENT, sliceName.get());\n      sliceProps.put(ZkStateReader.STATE_PROP, Slice.State.CONSTRUCTION.toString());\n      sliceProps.put(ZkStateReader.STATE_TIMESTAMP_PROP, String.valueOf(cloudManager.getTimeSource().getEpochTimeNs()));\n    }\n    // add replicas\n    for (ReplicaPosition replicaPosition : replicaPositions) {\n      String subSliceName = replicaPosition.shard;\n      String subShardNodeName = replicaPosition.node;\n//      String solrCoreName = collectionName + \"_\" + subSliceName + \"_replica_n\" + (replicaPosition.index);\n      String solrCoreName = Assign.buildSolrCoreName(collectionName, subSliceName, replicaPosition.type, Assign.incAndGetId(stateManager, collectionName, 0));\n      Map<String, Object> replicaProps = new HashMap<>();\n      replicaProps.put(ZkStateReader.SHARD_ID_PROP, replicaPosition.shard);\n      replicaProps.put(ZkStateReader.NODE_NAME_PROP, replicaPosition.node);\n      replicaProps.put(ZkStateReader.REPLICA_TYPE, replicaPosition.type.toString());\n      replicaProps.put(ZkStateReader.BASE_URL_PROP, Utils.getBaseUrlForNodeName(subShardNodeName, \"http\"));\n\n      long replicasNumDocs = newNumDocs;\n      long replicasIndexSize = newIndexSize;\n      if (remainderSlice == null) {\n        remainderSlice = subSliceName;\n      }\n      if (remainderSlice.equals(subSliceName)) { // only add to one sub slice\n        replicasNumDocs += remainderDocs;\n        replicasIndexSize += remainderIndexSize;\n      }\n      replicaProps.put(\"SEARCHER.searcher.numDocs\", new AtomicLong(replicasNumDocs));\n      replicaProps.put(\"SEARCHER.searcher.maxDoc\", new AtomicLong(replicasNumDocs));\n      replicaProps.put(\"SEARCHER.searcher.deletedDocs\", new AtomicLong(0));\n      replicaProps.put(Type.CORE_IDX.metricsAttribute, new AtomicLong(replicasIndexSize));\n      replicaProps.put(Variable.coreidxsize, new AtomicDouble((Double)Type.CORE_IDX.convertVal(replicasIndexSize)));\n\n      ReplicaInfo ri = new ReplicaInfo(\"core_node\" + Assign.incAndGetId(stateManager, collectionName, 0),\n          solrCoreName, collectionName, replicaPosition.shard, replicaPosition.type, subShardNodeName, replicaProps);\n      simAddReplica(replicaPosition.node, ri, false);\n    }\n    simRunLeaderElection(Collections.singleton(collectionName), true);\n\n    // delay it once again to better simulate replica recoveries\n    //opDelay(collectionName, CollectionParams.CollectionAction.SPLITSHARD.name());\n\n    boolean success = false;\n    try {\n      CloudUtil.waitForState(cloudManager, collectionName, 30, TimeUnit.SECONDS, (liveNodes, state) -> {\n        for (String subSlice : subSlices) {\n          Slice s = state.getSlice(subSlice);\n          if (s.getLeader() == null) {\n            log.debug(\"** no leader in {} / {}\", collectionName, s);\n            return false;\n          }\n          if (s.getReplicas().size() < repFactor) {\n            if (log.isDebugEnabled()) {\n              log.debug(\"** expected {} repFactor but there are {} replicas\", repFactor, s.getReplicas().size());\n            }\n            return false;\n          }\n        }\n        return true;\n      });\n      success = true;\n    } finally {\n      if (!success) {\n        Map<String, Object> sProps = sliceProperties.computeIfAbsent(collectionName, c -> new ConcurrentHashMap<>())\n            .computeIfAbsent(sliceName.get(), s -> new ConcurrentHashMap<>());\n        sProps.remove(BUFFERED_UPDATES);\n        SplitShardCmd.unlockForSplit(cloudManager, collectionName, sliceName.get());\n      }\n    }\n    // mark the new slices as active and the old slice as inactive\n    if (log.isTraceEnabled()) {\n      log.trace(\"-- switching slice states after split shard: collection={}, parent={}, subSlices={}\", collectionName,\n          sliceName.get(), subSlices);\n    }\n    lock.lockInterruptibly();\n    try {\n      Map<String, Object> sProps = sliceProperties.computeIfAbsent(collectionName, c -> new ConcurrentHashMap<>())\n          .computeIfAbsent(sliceName.get(), s -> new ConcurrentHashMap<>());\n      sProps.put(ZkStateReader.STATE_PROP, Slice.State.INACTIVE.toString());\n      sProps.put(ZkStateReader.STATE_TIMESTAMP_PROP, String.valueOf(cloudManager.getTimeSource().getEpochTimeNs()));\n      AtomicLong bufferedUpdates = (AtomicLong)sProps.remove(BUFFERED_UPDATES);\n      if (bufferedUpdates.get() > 0) {\n        // apply buffered updates\n        long perShard = bufferedUpdates.get() / subSlices.size();\n        long remainder = bufferedUpdates.get() % subSlices.size();\n        if (log.isDebugEnabled()) {\n          log.debug(\"-- applying {} buffered docs from {} / {}, perShard={}, remainder={}\", bufferedUpdates.get(),\n              collectionName, parentSlice.getName(), perShard, remainder);\n        }\n        for (int i = 0; i < subSlices.size(); i++) {\n          String sub = subSlices.get(i);\n          long numUpdates = perShard;\n          if (i == 0) {\n            numUpdates += remainder;\n          }\n          simSetShardValue(collectionName, sub, \"SEARCHER.searcher.numDocs\", numUpdates, true, false);\n          simSetShardValue(collectionName, sub, \"SEARCHER.searcher.maxDoc\", numUpdates, true, false);\n        }\n      }\n      // XXX also mark replicas as down? currently SplitShardCmd doesn't do this\n\n      for (String s : subSlices) {\n        Map<String, Object> sliceProps = sliceProperties.computeIfAbsent(collectionName, c -> new ConcurrentHashMap<>())\n            .computeIfAbsent(s, ss -> new ConcurrentHashMap<>());\n        sliceProps.put(ZkStateReader.STATE_PROP, Slice.State.ACTIVE.toString());\n        sliceProps.put(ZkStateReader.STATE_TIMESTAMP_PROP, String.valueOf(cloudManager.getTimeSource().getEpochTimeNs()));\n      }\n\n      // invalidate cached state\n      collectionsStatesRef.get(collectionName).invalidate();\n    } finally {\n      SplitShardCmd.unlockForSplit(cloudManager, collectionName, sliceName.get());\n      lock.unlock();\n    }\n    results.add(\"success\", \"\");\n\n  }\n\n","sourceOld":"  /**\n   * Split a shard. This uses a similar algorithm as {@link SplitShardCmd}, including simulating its\n   * quirks, and leaving the original parent slice in place.\n   * @param message operation details\n   * @param results operation results.\n   */\n  public void simSplitShard(ZkNodeProps message, NamedList results) throws Exception {\n    ensureNotClosed();\n    if (message.getStr(CommonAdminParams.ASYNC) != null) {\n      results.add(CoreAdminParams.REQUESTID, message.getStr(CommonAdminParams.ASYNC));\n    }\n    String collectionName = message.getStr(COLLECTION_PROP);\n    AtomicReference<String> sliceName = new AtomicReference<>();\n    sliceName.set(message.getStr(SHARD_ID_PROP));\n    String splitKey = message.getStr(\"split.key\");\n    String methodStr = message.getStr(CommonAdminParams.SPLIT_METHOD, SolrIndexSplitter.SplitMethod.REWRITE.toLower());\n    SolrIndexSplitter.SplitMethod splitMethod = SolrIndexSplitter.SplitMethod.get(methodStr);\n    if (splitMethod == null) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Unknown value '\" + CommonAdminParams.SPLIT_METHOD +\n          \": \" + methodStr);\n    }\n\n    ClusterState clusterState = getClusterState();\n    DocCollection collection = clusterState.getCollection(collectionName);\n    Slice parentSlice = SplitShardCmd.getParentSlice(clusterState, collectionName, sliceName, splitKey);\n    Replica leader = parentSlice.getLeader();\n    // XXX leader election may not have happened yet - should we require it?\n    if (leader == null) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Shard \" + collectionName +\n          \" /  \" + sliceName.get() + \" has no leader and can't be split\");\n    }\n    SplitShardCmd.checkDiskSpace(collectionName, sliceName.get(), leader, splitMethod, cloudManager);\n    SplitShardCmd.lockForSplit(cloudManager, collectionName, sliceName.get());\n    // start counting buffered updates\n    Map<String, Object> props = sliceProperties.computeIfAbsent(collectionName, c -> new ConcurrentHashMap<>())\n        .computeIfAbsent(sliceName.get(), ss -> new ConcurrentHashMap<>());\n    if (props.containsKey(BUFFERED_UPDATES)) {\n      SplitShardCmd.unlockForSplit(cloudManager, collectionName, sliceName.get());\n      throw new Exception(\"--- SOLR-12729: Overlapping splitShard commands for \" + collectionName + \"/\" + sliceName.get());\n    }\n    props.put(BUFFERED_UPDATES, new AtomicLong());\n\n    List<DocRouter.Range> subRanges = new ArrayList<>();\n    List<String> subSlices = new ArrayList<>();\n    List<String> subShardNames = new ArrayList<>();\n\n    opDelay(collectionName, CollectionParams.CollectionAction.SPLITSHARD.name());\n\n    SplitShardCmd.fillRanges(cloudManager, message, collection, parentSlice, subRanges, subSlices, subShardNames, true);\n    // add replicas for new subShards\n    int repFactor = parentSlice.getReplicas().size();\n    Assign.AssignRequest assignRequest = new Assign.AssignRequestBuilder()\n        .forCollection(collectionName)\n        .forShard(subSlices)\n        .assignNrtReplicas(repFactor)\n        .assignTlogReplicas(0)\n        .assignPullReplicas(0)\n        .onNodes(new ArrayList<>(clusterState.getLiveNodes()))\n        .build();\n    Assign.AssignStrategyFactory assignStrategyFactory = new Assign.AssignStrategyFactory(cloudManager);\n    Assign.AssignStrategy assignStrategy = assignStrategyFactory.create(clusterState, collection);\n    // reproduce the bug\n    List<ReplicaPosition> replicaPositions = assignStrategy.assign(cloudManager, assignRequest);\n    PolicyHelper.SessionWrapper sessionWrapper = PolicyHelper.getLastSessionWrapper(true);\n    if (sessionWrapper != null) sessionWrapper.release();\n\n    // adjust numDocs / deletedDocs / maxDoc\n    String numDocsStr = String.valueOf(getReplicaInfo(leader).getVariable(\"SEARCHER.searcher.numDocs\", \"0\"));\n    long numDocs = Long.parseLong(numDocsStr);\n    long newNumDocs = numDocs / subSlices.size();\n    long remainderDocs = numDocs % subSlices.size();\n    long newIndexSize = SimCloudManager.DEFAULT_IDX_SIZE_BYTES + newNumDocs * DEFAULT_DOC_SIZE_BYTES;\n    long remainderIndexSize = SimCloudManager.DEFAULT_IDX_SIZE_BYTES + remainderDocs * DEFAULT_DOC_SIZE_BYTES;\n    String remainderSlice = null;\n\n    // add slice props\n    for (int i = 0; i < subRanges.size(); i++) {\n      String subSlice = subSlices.get(i);\n      DocRouter.Range range = subRanges.get(i);\n      Map<String, Object> sliceProps = sliceProperties.computeIfAbsent(collectionName, c -> new ConcurrentHashMap<>())\n          .computeIfAbsent(subSlice, ss -> new ConcurrentHashMap<>());\n      sliceProps.put(Slice.RANGE, range);\n      sliceProps.put(Slice.PARENT, sliceName.get());\n      sliceProps.put(ZkStateReader.STATE_PROP, Slice.State.CONSTRUCTION.toString());\n      sliceProps.put(ZkStateReader.STATE_TIMESTAMP_PROP, String.valueOf(cloudManager.getTimeSource().getEpochTimeNs()));\n    }\n    // add replicas\n    for (ReplicaPosition replicaPosition : replicaPositions) {\n      String subSliceName = replicaPosition.shard;\n      String subShardNodeName = replicaPosition.node;\n//      String solrCoreName = collectionName + \"_\" + subSliceName + \"_replica_n\" + (replicaPosition.index);\n      String solrCoreName = Assign.buildSolrCoreName(collectionName, subSliceName, replicaPosition.type, Assign.incAndGetId(stateManager, collectionName, 0));\n      Map<String, Object> replicaProps = new HashMap<>();\n      replicaProps.put(ZkStateReader.SHARD_ID_PROP, replicaPosition.shard);\n      replicaProps.put(ZkStateReader.NODE_NAME_PROP, replicaPosition.node);\n      replicaProps.put(ZkStateReader.REPLICA_TYPE, replicaPosition.type.toString());\n      replicaProps.put(ZkStateReader.BASE_URL_PROP, Utils.getBaseUrlForNodeName(subShardNodeName, \"http\"));\n\n      long replicasNumDocs = newNumDocs;\n      long replicasIndexSize = newIndexSize;\n      if (remainderSlice == null) {\n        remainderSlice = subSliceName;\n      }\n      if (remainderSlice.equals(subSliceName)) { // only add to one sub slice\n        replicasNumDocs += remainderDocs;\n        replicasIndexSize += remainderIndexSize;\n      }\n      replicaProps.put(\"SEARCHER.searcher.numDocs\", new AtomicLong(replicasNumDocs));\n      replicaProps.put(\"SEARCHER.searcher.maxDoc\", new AtomicLong(replicasNumDocs));\n      replicaProps.put(\"SEARCHER.searcher.deletedDocs\", new AtomicLong(0));\n      replicaProps.put(Type.CORE_IDX.metricsAttribute, new AtomicLong(replicasIndexSize));\n      replicaProps.put(Variable.coreidxsize, new AtomicDouble((Double)Type.CORE_IDX.convertVal(replicasIndexSize)));\n\n      ReplicaInfo ri = new ReplicaInfo(\"core_node\" + Assign.incAndGetId(stateManager, collectionName, 0),\n          solrCoreName, collectionName, replicaPosition.shard, replicaPosition.type, subShardNodeName, replicaProps);\n      simAddReplica(replicaPosition.node, ri, false);\n    }\n    simRunLeaderElection(Collections.singleton(collectionName), true);\n\n    // delay it once again to better simulate replica recoveries\n    //opDelay(collectionName, CollectionParams.CollectionAction.SPLITSHARD.name());\n\n    boolean success = false;\n    try {\n      CloudUtil.waitForState(cloudManager, collectionName, 30, TimeUnit.SECONDS, (liveNodes, state) -> {\n        for (String subSlice : subSlices) {\n          Slice s = state.getSlice(subSlice);\n          if (s.getLeader() == null) {\n            log.debug(\"** no leader in {} / {}\", collectionName, s);\n            return false;\n          }\n          if (s.getReplicas().size() < repFactor) {\n            if (log.isDebugEnabled()) {\n              log.debug(\"** expected {} repFactor but there are {} replicas\", repFactor, s.getReplicas().size());\n            }\n            return false;\n          }\n        }\n        return true;\n      });\n      success = true;\n    } finally {\n      if (!success) {\n        Map<String, Object> sProps = sliceProperties.computeIfAbsent(collectionName, c -> new ConcurrentHashMap<>())\n            .computeIfAbsent(sliceName.get(), s -> new ConcurrentHashMap<>());\n        sProps.remove(BUFFERED_UPDATES);\n        SplitShardCmd.unlockForSplit(cloudManager, collectionName, sliceName.get());\n      }\n    }\n    // mark the new slices as active and the old slice as inactive\n    if (log.isTraceEnabled()) {\n      log.trace(\"-- switching slice states after split shard: collection={}, parent={}, subSlices={}\", collectionName,\n          sliceName.get(), subSlices);\n    }\n    lock.lockInterruptibly();\n    try {\n      Map<String, Object> sProps = sliceProperties.computeIfAbsent(collectionName, c -> new ConcurrentHashMap<>())\n          .computeIfAbsent(sliceName.get(), s -> new ConcurrentHashMap<>());\n      sProps.put(ZkStateReader.STATE_PROP, Slice.State.INACTIVE.toString());\n      sProps.put(ZkStateReader.STATE_TIMESTAMP_PROP, String.valueOf(cloudManager.getTimeSource().getEpochTimeNs()));\n      AtomicLong bufferedUpdates = (AtomicLong)sProps.remove(BUFFERED_UPDATES);\n      if (bufferedUpdates.get() > 0) {\n        // apply buffered updates\n        long perShard = bufferedUpdates.get() / subSlices.size();\n        long remainder = bufferedUpdates.get() % subSlices.size();\n        if (log.isDebugEnabled()) {\n          log.debug(\"-- applying {} buffered docs from {} / {}, perShard={}, remainder={}\", bufferedUpdates.get(),\n              collectionName, parentSlice.getName(), perShard, remainder);\n        }\n        for (int i = 0; i < subSlices.size(); i++) {\n          String sub = subSlices.get(i);\n          long numUpdates = perShard;\n          if (i == 0) {\n            numUpdates += remainder;\n          }\n          simSetShardValue(collectionName, sub, \"SEARCHER.searcher.numDocs\", numUpdates, true, false);\n          simSetShardValue(collectionName, sub, \"SEARCHER.searcher.maxDoc\", numUpdates, true, false);\n        }\n      }\n      // XXX also mark replicas as down? currently SplitShardCmd doesn't do this\n\n      for (String s : subSlices) {\n        Map<String, Object> sliceProps = sliceProperties.computeIfAbsent(collectionName, c -> new ConcurrentHashMap<>())\n            .computeIfAbsent(s, ss -> new ConcurrentHashMap<>());\n        sliceProps.put(ZkStateReader.STATE_PROP, Slice.State.ACTIVE.toString());\n        sliceProps.put(ZkStateReader.STATE_TIMESTAMP_PROP, String.valueOf(cloudManager.getTimeSource().getEpochTimeNs()));\n      }\n\n      // invalidate cached state\n      collectionsStatesRef.set(null);\n    } finally {\n      SplitShardCmd.unlockForSplit(cloudManager, collectionName, sliceName.get());\n      lock.unlock();\n    }\n    results.add(\"success\", \"\");\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"daa0f21a44e235a2299ea1fa913898b182dd7cce","date":1590952026,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/autoscaling/sim/SimClusterStateProvider#simSplitShard(ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/autoscaling/sim/SimClusterStateProvider#simSplitShard(ZkNodeProps,NamedList).mjava","sourceNew":"  /**\n   * Split a shard. This uses a similar algorithm as {@link SplitShardCmd}, including simulating its\n   * quirks, and leaving the original parent slice in place.\n   * @param message operation details\n   * @param results operation results.\n   */\n  @SuppressWarnings({\"unchecked\", \"rawtypes\"})\n  public void simSplitShard(ZkNodeProps message, NamedList results) throws Exception {\n    ensureNotClosed();\n    if (message.getStr(CommonAdminParams.ASYNC) != null) {\n      results.add(CoreAdminParams.REQUESTID, message.getStr(CommonAdminParams.ASYNC));\n    }\n    String collectionName = message.getStr(COLLECTION_PROP);\n    AtomicReference<String> sliceName = new AtomicReference<>();\n    sliceName.set(message.getStr(SHARD_ID_PROP));\n    String splitKey = message.getStr(\"split.key\");\n    String methodStr = message.getStr(CommonAdminParams.SPLIT_METHOD, SolrIndexSplitter.SplitMethod.REWRITE.toLower());\n    SolrIndexSplitter.SplitMethod splitMethod = SolrIndexSplitter.SplitMethod.get(methodStr);\n    if (splitMethod == null) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Unknown value '\" + CommonAdminParams.SPLIT_METHOD +\n          \": \" + methodStr);\n    }\n\n    ClusterState clusterState = getClusterState();\n    DocCollection collection = clusterState.getCollection(collectionName);\n    Slice parentSlice = SplitShardCmd.getParentSlice(clusterState, collectionName, sliceName, splitKey);\n    Replica leader = parentSlice.getLeader();\n    // XXX leader election may not have happened yet - should we require it?\n    if (leader == null) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Shard \" + collectionName +\n          \" /  \" + sliceName.get() + \" has no leader and can't be split\");\n    }\n    SplitShardCmd.checkDiskSpace(collectionName, sliceName.get(), leader, splitMethod, cloudManager);\n    SplitShardCmd.lockForSplit(cloudManager, collectionName, sliceName.get());\n    // start counting buffered updates\n    Map<String, Object> props = sliceProperties.computeIfAbsent(collectionName, c -> new ConcurrentHashMap<>())\n        .computeIfAbsent(sliceName.get(), ss -> new ConcurrentHashMap<>());\n    if (props.containsKey(BUFFERED_UPDATES)) {\n      SplitShardCmd.unlockForSplit(cloudManager, collectionName, sliceName.get());\n      throw new Exception(\"--- SOLR-12729: Overlapping splitShard commands for \" + collectionName + \"/\" + sliceName.get());\n    }\n    props.put(BUFFERED_UPDATES, new AtomicLong());\n\n    List<DocRouter.Range> subRanges = new ArrayList<>();\n    List<String> subSlices = new ArrayList<>();\n    List<String> subShardNames = new ArrayList<>();\n\n    opDelay(collectionName, CollectionParams.CollectionAction.SPLITSHARD.name());\n\n    SplitShardCmd.fillRanges(cloudManager, message, collection, parentSlice, subRanges, subSlices, subShardNames, true);\n    // add replicas for new subShards\n    int repFactor = parentSlice.getReplicas().size();\n    Assign.AssignRequest assignRequest = new Assign.AssignRequestBuilder()\n        .forCollection(collectionName)\n        .forShard(subSlices)\n        .assignNrtReplicas(repFactor)\n        .assignTlogReplicas(0)\n        .assignPullReplicas(0)\n        .onNodes(new ArrayList<>(clusterState.getLiveNodes()))\n        .build();\n    Assign.AssignStrategyFactory assignStrategyFactory = new Assign.AssignStrategyFactory(cloudManager);\n    Assign.AssignStrategy assignStrategy = assignStrategyFactory.create(clusterState, collection);\n    // reproduce the bug\n    List<ReplicaPosition> replicaPositions = assignStrategy.assign(cloudManager, assignRequest);\n    PolicyHelper.SessionWrapper sessionWrapper = PolicyHelper.getLastSessionWrapper(true);\n    if (sessionWrapper != null) sessionWrapper.release();\n\n    // adjust numDocs / deletedDocs / maxDoc\n    String numDocsStr = String.valueOf(getReplicaInfo(leader).getVariable(\"SEARCHER.searcher.numDocs\", \"0\"));\n    long numDocs = Long.parseLong(numDocsStr);\n    long newNumDocs = numDocs / subSlices.size();\n    long remainderDocs = numDocs % subSlices.size();\n    long newIndexSize = SimCloudManager.DEFAULT_IDX_SIZE_BYTES + newNumDocs * DEFAULT_DOC_SIZE_BYTES;\n    long remainderIndexSize = SimCloudManager.DEFAULT_IDX_SIZE_BYTES + remainderDocs * DEFAULT_DOC_SIZE_BYTES;\n    String remainderSlice = null;\n\n    // add slice props\n    for (int i = 0; i < subRanges.size(); i++) {\n      String subSlice = subSlices.get(i);\n      DocRouter.Range range = subRanges.get(i);\n      Map<String, Object> sliceProps = sliceProperties.computeIfAbsent(collectionName, c -> new ConcurrentHashMap<>())\n          .computeIfAbsent(subSlice, ss -> new ConcurrentHashMap<>());\n      sliceProps.put(Slice.RANGE, range);\n      sliceProps.put(Slice.PARENT, sliceName.get());\n      sliceProps.put(ZkStateReader.STATE_PROP, Slice.State.CONSTRUCTION.toString());\n      sliceProps.put(ZkStateReader.STATE_TIMESTAMP_PROP, String.valueOf(cloudManager.getTimeSource().getEpochTimeNs()));\n    }\n    // add replicas\n    for (ReplicaPosition replicaPosition : replicaPositions) {\n      String subSliceName = replicaPosition.shard;\n      String subShardNodeName = replicaPosition.node;\n//      String solrCoreName = collectionName + \"_\" + subSliceName + \"_replica_n\" + (replicaPosition.index);\n      String solrCoreName = Assign.buildSolrCoreName(collectionName, subSliceName, replicaPosition.type, Assign.incAndGetId(stateManager, collectionName, 0));\n      Map<String, Object> replicaProps = new HashMap<>();\n      replicaProps.put(ZkStateReader.SHARD_ID_PROP, replicaPosition.shard);\n      replicaProps.put(ZkStateReader.NODE_NAME_PROP, replicaPosition.node);\n      replicaProps.put(ZkStateReader.REPLICA_TYPE, replicaPosition.type.toString());\n      replicaProps.put(ZkStateReader.BASE_URL_PROP, Utils.getBaseUrlForNodeName(subShardNodeName, \"http\"));\n\n      long replicasNumDocs = newNumDocs;\n      long replicasIndexSize = newIndexSize;\n      if (remainderSlice == null) {\n        remainderSlice = subSliceName;\n      }\n      if (remainderSlice.equals(subSliceName)) { // only add to one sub slice\n        replicasNumDocs += remainderDocs;\n        replicasIndexSize += remainderIndexSize;\n      }\n      replicaProps.put(\"SEARCHER.searcher.numDocs\", new AtomicLong(replicasNumDocs));\n      replicaProps.put(\"SEARCHER.searcher.maxDoc\", new AtomicLong(replicasNumDocs));\n      replicaProps.put(\"SEARCHER.searcher.deletedDocs\", new AtomicLong(0));\n      replicaProps.put(Type.CORE_IDX.metricsAttribute, new AtomicLong(replicasIndexSize));\n      replicaProps.put(Variable.coreidxsize, new AtomicDouble((Double)Type.CORE_IDX.convertVal(replicasIndexSize)));\n\n      ReplicaInfo ri = new ReplicaInfo(\"core_node\" + Assign.incAndGetId(stateManager, collectionName, 0),\n          solrCoreName, collectionName, replicaPosition.shard, replicaPosition.type, subShardNodeName, replicaProps);\n      simAddReplica(replicaPosition.node, ri, false);\n    }\n    simRunLeaderElection(Collections.singleton(collectionName), true);\n\n    // delay it once again to better simulate replica recoveries\n    //opDelay(collectionName, CollectionParams.CollectionAction.SPLITSHARD.name());\n\n    boolean success = false;\n    try {\n      CloudUtil.waitForState(cloudManager, collectionName, 30, TimeUnit.SECONDS, (liveNodes, state) -> {\n        for (String subSlice : subSlices) {\n          Slice s = state.getSlice(subSlice);\n          if (s.getLeader() == null) {\n            log.debug(\"** no leader in {} / {}\", collectionName, s);\n            return false;\n          }\n          if (s.getReplicas().size() < repFactor) {\n            if (log.isDebugEnabled()) {\n              log.debug(\"** expected {} repFactor but there are {} replicas\", repFactor, s.getReplicas().size());\n            }\n            return false;\n          }\n        }\n        return true;\n      });\n      success = true;\n    } finally {\n      if (!success) {\n        Map<String, Object> sProps = sliceProperties.computeIfAbsent(collectionName, c -> new ConcurrentHashMap<>())\n            .computeIfAbsent(sliceName.get(), s -> new ConcurrentHashMap<>());\n        sProps.remove(BUFFERED_UPDATES);\n        SplitShardCmd.unlockForSplit(cloudManager, collectionName, sliceName.get());\n      }\n    }\n    // mark the new slices as active and the old slice as inactive\n    if (log.isTraceEnabled()) {\n      log.trace(\"-- switching slice states after split shard: collection={}, parent={}, subSlices={}\", collectionName,\n          sliceName.get(), subSlices);\n    }\n    lock.lockInterruptibly();\n    try {\n      Map<String, Object> sProps = sliceProperties.computeIfAbsent(collectionName, c -> new ConcurrentHashMap<>())\n          .computeIfAbsent(sliceName.get(), s -> new ConcurrentHashMap<>());\n      sProps.put(ZkStateReader.STATE_PROP, Slice.State.INACTIVE.toString());\n      sProps.put(ZkStateReader.STATE_TIMESTAMP_PROP, String.valueOf(cloudManager.getTimeSource().getEpochTimeNs()));\n      AtomicLong bufferedUpdates = (AtomicLong)sProps.remove(BUFFERED_UPDATES);\n      if (bufferedUpdates.get() > 0) {\n        // apply buffered updates\n        long perShard = bufferedUpdates.get() / subSlices.size();\n        long remainder = bufferedUpdates.get() % subSlices.size();\n        if (log.isDebugEnabled()) {\n          log.debug(\"-- applying {} buffered docs from {} / {}, perShard={}, remainder={}\", bufferedUpdates.get(),\n              collectionName, parentSlice.getName(), perShard, remainder);\n        }\n        for (int i = 0; i < subSlices.size(); i++) {\n          String sub = subSlices.get(i);\n          long numUpdates = perShard;\n          if (i == 0) {\n            numUpdates += remainder;\n          }\n          simSetShardValue(collectionName, sub, \"SEARCHER.searcher.numDocs\", numUpdates, true, false);\n          simSetShardValue(collectionName, sub, \"SEARCHER.searcher.maxDoc\", numUpdates, true, false);\n        }\n      }\n      // XXX also mark replicas as down? currently SplitShardCmd doesn't do this\n\n      for (String s : subSlices) {\n        Map<String, Object> sliceProps = sliceProperties.computeIfAbsent(collectionName, c -> new ConcurrentHashMap<>())\n            .computeIfAbsent(s, ss -> new ConcurrentHashMap<>());\n        sliceProps.put(ZkStateReader.STATE_PROP, Slice.State.ACTIVE.toString());\n        sliceProps.put(ZkStateReader.STATE_TIMESTAMP_PROP, String.valueOf(cloudManager.getTimeSource().getEpochTimeNs()));\n      }\n\n      // invalidate cached state\n      collectionsStatesRef.get(collectionName).invalidate();\n    } finally {\n      SplitShardCmd.unlockForSplit(cloudManager, collectionName, sliceName.get());\n      lock.unlock();\n    }\n    results.add(\"success\", \"\");\n\n  }\n\n","sourceOld":"  /**\n   * Split a shard. This uses a similar algorithm as {@link SplitShardCmd}, including simulating its\n   * quirks, and leaving the original parent slice in place.\n   * @param message operation details\n   * @param results operation results.\n   */\n  public void simSplitShard(ZkNodeProps message, NamedList results) throws Exception {\n    ensureNotClosed();\n    if (message.getStr(CommonAdminParams.ASYNC) != null) {\n      results.add(CoreAdminParams.REQUESTID, message.getStr(CommonAdminParams.ASYNC));\n    }\n    String collectionName = message.getStr(COLLECTION_PROP);\n    AtomicReference<String> sliceName = new AtomicReference<>();\n    sliceName.set(message.getStr(SHARD_ID_PROP));\n    String splitKey = message.getStr(\"split.key\");\n    String methodStr = message.getStr(CommonAdminParams.SPLIT_METHOD, SolrIndexSplitter.SplitMethod.REWRITE.toLower());\n    SolrIndexSplitter.SplitMethod splitMethod = SolrIndexSplitter.SplitMethod.get(methodStr);\n    if (splitMethod == null) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Unknown value '\" + CommonAdminParams.SPLIT_METHOD +\n          \": \" + methodStr);\n    }\n\n    ClusterState clusterState = getClusterState();\n    DocCollection collection = clusterState.getCollection(collectionName);\n    Slice parentSlice = SplitShardCmd.getParentSlice(clusterState, collectionName, sliceName, splitKey);\n    Replica leader = parentSlice.getLeader();\n    // XXX leader election may not have happened yet - should we require it?\n    if (leader == null) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Shard \" + collectionName +\n          \" /  \" + sliceName.get() + \" has no leader and can't be split\");\n    }\n    SplitShardCmd.checkDiskSpace(collectionName, sliceName.get(), leader, splitMethod, cloudManager);\n    SplitShardCmd.lockForSplit(cloudManager, collectionName, sliceName.get());\n    // start counting buffered updates\n    Map<String, Object> props = sliceProperties.computeIfAbsent(collectionName, c -> new ConcurrentHashMap<>())\n        .computeIfAbsent(sliceName.get(), ss -> new ConcurrentHashMap<>());\n    if (props.containsKey(BUFFERED_UPDATES)) {\n      SplitShardCmd.unlockForSplit(cloudManager, collectionName, sliceName.get());\n      throw new Exception(\"--- SOLR-12729: Overlapping splitShard commands for \" + collectionName + \"/\" + sliceName.get());\n    }\n    props.put(BUFFERED_UPDATES, new AtomicLong());\n\n    List<DocRouter.Range> subRanges = new ArrayList<>();\n    List<String> subSlices = new ArrayList<>();\n    List<String> subShardNames = new ArrayList<>();\n\n    opDelay(collectionName, CollectionParams.CollectionAction.SPLITSHARD.name());\n\n    SplitShardCmd.fillRanges(cloudManager, message, collection, parentSlice, subRanges, subSlices, subShardNames, true);\n    // add replicas for new subShards\n    int repFactor = parentSlice.getReplicas().size();\n    Assign.AssignRequest assignRequest = new Assign.AssignRequestBuilder()\n        .forCollection(collectionName)\n        .forShard(subSlices)\n        .assignNrtReplicas(repFactor)\n        .assignTlogReplicas(0)\n        .assignPullReplicas(0)\n        .onNodes(new ArrayList<>(clusterState.getLiveNodes()))\n        .build();\n    Assign.AssignStrategyFactory assignStrategyFactory = new Assign.AssignStrategyFactory(cloudManager);\n    Assign.AssignStrategy assignStrategy = assignStrategyFactory.create(clusterState, collection);\n    // reproduce the bug\n    List<ReplicaPosition> replicaPositions = assignStrategy.assign(cloudManager, assignRequest);\n    PolicyHelper.SessionWrapper sessionWrapper = PolicyHelper.getLastSessionWrapper(true);\n    if (sessionWrapper != null) sessionWrapper.release();\n\n    // adjust numDocs / deletedDocs / maxDoc\n    String numDocsStr = String.valueOf(getReplicaInfo(leader).getVariable(\"SEARCHER.searcher.numDocs\", \"0\"));\n    long numDocs = Long.parseLong(numDocsStr);\n    long newNumDocs = numDocs / subSlices.size();\n    long remainderDocs = numDocs % subSlices.size();\n    long newIndexSize = SimCloudManager.DEFAULT_IDX_SIZE_BYTES + newNumDocs * DEFAULT_DOC_SIZE_BYTES;\n    long remainderIndexSize = SimCloudManager.DEFAULT_IDX_SIZE_BYTES + remainderDocs * DEFAULT_DOC_SIZE_BYTES;\n    String remainderSlice = null;\n\n    // add slice props\n    for (int i = 0; i < subRanges.size(); i++) {\n      String subSlice = subSlices.get(i);\n      DocRouter.Range range = subRanges.get(i);\n      Map<String, Object> sliceProps = sliceProperties.computeIfAbsent(collectionName, c -> new ConcurrentHashMap<>())\n          .computeIfAbsent(subSlice, ss -> new ConcurrentHashMap<>());\n      sliceProps.put(Slice.RANGE, range);\n      sliceProps.put(Slice.PARENT, sliceName.get());\n      sliceProps.put(ZkStateReader.STATE_PROP, Slice.State.CONSTRUCTION.toString());\n      sliceProps.put(ZkStateReader.STATE_TIMESTAMP_PROP, String.valueOf(cloudManager.getTimeSource().getEpochTimeNs()));\n    }\n    // add replicas\n    for (ReplicaPosition replicaPosition : replicaPositions) {\n      String subSliceName = replicaPosition.shard;\n      String subShardNodeName = replicaPosition.node;\n//      String solrCoreName = collectionName + \"_\" + subSliceName + \"_replica_n\" + (replicaPosition.index);\n      String solrCoreName = Assign.buildSolrCoreName(collectionName, subSliceName, replicaPosition.type, Assign.incAndGetId(stateManager, collectionName, 0));\n      Map<String, Object> replicaProps = new HashMap<>();\n      replicaProps.put(ZkStateReader.SHARD_ID_PROP, replicaPosition.shard);\n      replicaProps.put(ZkStateReader.NODE_NAME_PROP, replicaPosition.node);\n      replicaProps.put(ZkStateReader.REPLICA_TYPE, replicaPosition.type.toString());\n      replicaProps.put(ZkStateReader.BASE_URL_PROP, Utils.getBaseUrlForNodeName(subShardNodeName, \"http\"));\n\n      long replicasNumDocs = newNumDocs;\n      long replicasIndexSize = newIndexSize;\n      if (remainderSlice == null) {\n        remainderSlice = subSliceName;\n      }\n      if (remainderSlice.equals(subSliceName)) { // only add to one sub slice\n        replicasNumDocs += remainderDocs;\n        replicasIndexSize += remainderIndexSize;\n      }\n      replicaProps.put(\"SEARCHER.searcher.numDocs\", new AtomicLong(replicasNumDocs));\n      replicaProps.put(\"SEARCHER.searcher.maxDoc\", new AtomicLong(replicasNumDocs));\n      replicaProps.put(\"SEARCHER.searcher.deletedDocs\", new AtomicLong(0));\n      replicaProps.put(Type.CORE_IDX.metricsAttribute, new AtomicLong(replicasIndexSize));\n      replicaProps.put(Variable.coreidxsize, new AtomicDouble((Double)Type.CORE_IDX.convertVal(replicasIndexSize)));\n\n      ReplicaInfo ri = new ReplicaInfo(\"core_node\" + Assign.incAndGetId(stateManager, collectionName, 0),\n          solrCoreName, collectionName, replicaPosition.shard, replicaPosition.type, subShardNodeName, replicaProps);\n      simAddReplica(replicaPosition.node, ri, false);\n    }\n    simRunLeaderElection(Collections.singleton(collectionName), true);\n\n    // delay it once again to better simulate replica recoveries\n    //opDelay(collectionName, CollectionParams.CollectionAction.SPLITSHARD.name());\n\n    boolean success = false;\n    try {\n      CloudUtil.waitForState(cloudManager, collectionName, 30, TimeUnit.SECONDS, (liveNodes, state) -> {\n        for (String subSlice : subSlices) {\n          Slice s = state.getSlice(subSlice);\n          if (s.getLeader() == null) {\n            log.debug(\"** no leader in {} / {}\", collectionName, s);\n            return false;\n          }\n          if (s.getReplicas().size() < repFactor) {\n            if (log.isDebugEnabled()) {\n              log.debug(\"** expected {} repFactor but there are {} replicas\", repFactor, s.getReplicas().size());\n            }\n            return false;\n          }\n        }\n        return true;\n      });\n      success = true;\n    } finally {\n      if (!success) {\n        Map<String, Object> sProps = sliceProperties.computeIfAbsent(collectionName, c -> new ConcurrentHashMap<>())\n            .computeIfAbsent(sliceName.get(), s -> new ConcurrentHashMap<>());\n        sProps.remove(BUFFERED_UPDATES);\n        SplitShardCmd.unlockForSplit(cloudManager, collectionName, sliceName.get());\n      }\n    }\n    // mark the new slices as active and the old slice as inactive\n    if (log.isTraceEnabled()) {\n      log.trace(\"-- switching slice states after split shard: collection={}, parent={}, subSlices={}\", collectionName,\n          sliceName.get(), subSlices);\n    }\n    lock.lockInterruptibly();\n    try {\n      Map<String, Object> sProps = sliceProperties.computeIfAbsent(collectionName, c -> new ConcurrentHashMap<>())\n          .computeIfAbsent(sliceName.get(), s -> new ConcurrentHashMap<>());\n      sProps.put(ZkStateReader.STATE_PROP, Slice.State.INACTIVE.toString());\n      sProps.put(ZkStateReader.STATE_TIMESTAMP_PROP, String.valueOf(cloudManager.getTimeSource().getEpochTimeNs()));\n      AtomicLong bufferedUpdates = (AtomicLong)sProps.remove(BUFFERED_UPDATES);\n      if (bufferedUpdates.get() > 0) {\n        // apply buffered updates\n        long perShard = bufferedUpdates.get() / subSlices.size();\n        long remainder = bufferedUpdates.get() % subSlices.size();\n        if (log.isDebugEnabled()) {\n          log.debug(\"-- applying {} buffered docs from {} / {}, perShard={}, remainder={}\", bufferedUpdates.get(),\n              collectionName, parentSlice.getName(), perShard, remainder);\n        }\n        for (int i = 0; i < subSlices.size(); i++) {\n          String sub = subSlices.get(i);\n          long numUpdates = perShard;\n          if (i == 0) {\n            numUpdates += remainder;\n          }\n          simSetShardValue(collectionName, sub, \"SEARCHER.searcher.numDocs\", numUpdates, true, false);\n          simSetShardValue(collectionName, sub, \"SEARCHER.searcher.maxDoc\", numUpdates, true, false);\n        }\n      }\n      // XXX also mark replicas as down? currently SplitShardCmd doesn't do this\n\n      for (String s : subSlices) {\n        Map<String, Object> sliceProps = sliceProperties.computeIfAbsent(collectionName, c -> new ConcurrentHashMap<>())\n            .computeIfAbsent(s, ss -> new ConcurrentHashMap<>());\n        sliceProps.put(ZkStateReader.STATE_PROP, Slice.State.ACTIVE.toString());\n        sliceProps.put(ZkStateReader.STATE_TIMESTAMP_PROP, String.valueOf(cloudManager.getTimeSource().getEpochTimeNs()));\n      }\n\n      // invalidate cached state\n      collectionsStatesRef.get(collectionName).invalidate();\n    } finally {\n      SplitShardCmd.unlockForSplit(cloudManager, collectionName, sliceName.get());\n      lock.unlock();\n    }\n    results.add(\"success\", \"\");\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7e8ce2f9d2ddfcf5cfa7e73b8b2af287a2a276fd","date":1594731683,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/autoscaling/sim/SimClusterStateProvider#simSplitShard(ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/autoscaling/sim/SimClusterStateProvider#simSplitShard(ZkNodeProps,NamedList).mjava","sourceNew":"  /**\n   * Split a shard. This uses a similar algorithm as {@link SplitShardCmd}, including simulating its\n   * quirks, and leaving the original parent slice in place.\n   * @param message operation details\n   * @param results operation results.\n   */\n  @SuppressWarnings({\"unchecked\", \"rawtypes\"})\n  public void simSplitShard(ZkNodeProps message, NamedList results) throws Exception {\n    ensureNotClosed();\n    if (message.getStr(CommonAdminParams.ASYNC) != null) {\n      results.add(CoreAdminParams.REQUESTID, message.getStr(CommonAdminParams.ASYNC));\n    }\n    String collectionName = message.getStr(COLLECTION_PROP);\n    AtomicReference<String> sliceName = new AtomicReference<>();\n    sliceName.set(message.getStr(SHARD_ID_PROP));\n    String splitKey = message.getStr(\"split.key\");\n    String methodStr = message.getStr(CommonAdminParams.SPLIT_METHOD, SolrIndexSplitter.SplitMethod.REWRITE.toLower());\n    SolrIndexSplitter.SplitMethod splitMethod = SolrIndexSplitter.SplitMethod.get(methodStr);\n    if (splitMethod == null) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Unknown value '\" + CommonAdminParams.SPLIT_METHOD +\n          \": \" + methodStr);\n    }\n\n    ClusterState clusterState = getClusterState();\n    DocCollection collection = clusterState.getCollection(collectionName);\n    Slice parentSlice = SplitShardCmd.getParentSlice(clusterState, collectionName, sliceName, splitKey);\n    Replica leader = parentSlice.getLeader();\n    // XXX leader election may not have happened yet - should we require it?\n    if (leader == null) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Shard \" + collectionName +\n          \" /  \" + sliceName.get() + \" has no leader and can't be split\");\n    }\n    SplitShardCmd.checkDiskSpace(collectionName, sliceName.get(), leader, splitMethod, cloudManager);\n    SplitShardCmd.lockForSplit(cloudManager, collectionName, sliceName.get());\n    // start counting buffered updates\n    Map<String, Object> props = sliceProperties.computeIfAbsent(collectionName, c -> new ConcurrentHashMap<>())\n        .computeIfAbsent(sliceName.get(), ss -> new ConcurrentHashMap<>());\n    if (props.containsKey(BUFFERED_UPDATES)) {\n      SplitShardCmd.unlockForSplit(cloudManager, collectionName, sliceName.get());\n      throw new Exception(\"--- SOLR-12729: Overlapping splitShard commands for \" + collectionName + \"/\" + sliceName.get());\n    }\n    props.put(BUFFERED_UPDATES, new AtomicLong());\n\n    List<DocRouter.Range> subRanges = new ArrayList<>();\n    List<String> subSlices = new ArrayList<>();\n    List<String> subShardNames = new ArrayList<>();\n\n    opDelay(collectionName, CollectionParams.CollectionAction.SPLITSHARD.name());\n\n    SplitShardCmd.fillRanges(cloudManager, message, collection, parentSlice, subRanges, subSlices, subShardNames, true);\n    // add replicas for new subShards\n    int repFactor = parentSlice.getReplicas().size();\n    Assign.AssignRequest assignRequest = new Assign.AssignRequestBuilder()\n        .forCollection(collectionName)\n        .forShard(subSlices)\n        .assignNrtReplicas(repFactor)\n        .assignTlogReplicas(0)\n        .assignPullReplicas(0)\n        .onNodes(new ArrayList<>(clusterState.getLiveNodes()))\n        .build();\n    Assign.AssignStrategyFactory assignStrategyFactory = new Assign.AssignStrategyFactory(cloudManager);\n    Assign.AssignStrategy assignStrategy = assignStrategyFactory.create(clusterState, collection);\n    // reproduce the bug\n    List<ReplicaPosition> replicaPositions = assignStrategy.assign(cloudManager, assignRequest);\n    PolicyHelper.SessionWrapper sessionWrapper = PolicyHelper.getLastSessionWrapper(true);\n    if (sessionWrapper != null) sessionWrapper.release();\n\n    // adjust numDocs / deletedDocs / maxDoc\n    String numDocsStr = String.valueOf(getReplicaInfo(leader).get(\"SEARCHER.searcher.numDocs\", \"0\"));\n    long numDocs = Long.parseLong(numDocsStr);\n    long newNumDocs = numDocs / subSlices.size();\n    long remainderDocs = numDocs % subSlices.size();\n    long newIndexSize = SimCloudManager.DEFAULT_IDX_SIZE_BYTES + newNumDocs * DEFAULT_DOC_SIZE_BYTES;\n    long remainderIndexSize = SimCloudManager.DEFAULT_IDX_SIZE_BYTES + remainderDocs * DEFAULT_DOC_SIZE_BYTES;\n    String remainderSlice = null;\n\n    // add slice props\n    for (int i = 0; i < subRanges.size(); i++) {\n      String subSlice = subSlices.get(i);\n      DocRouter.Range range = subRanges.get(i);\n      Map<String, Object> sliceProps = sliceProperties.computeIfAbsent(collectionName, c -> new ConcurrentHashMap<>())\n          .computeIfAbsent(subSlice, ss -> new ConcurrentHashMap<>());\n      sliceProps.put(Slice.RANGE, range);\n      sliceProps.put(Slice.PARENT, sliceName.get());\n      sliceProps.put(ZkStateReader.STATE_PROP, Slice.State.CONSTRUCTION.toString());\n      sliceProps.put(ZkStateReader.STATE_TIMESTAMP_PROP, String.valueOf(cloudManager.getTimeSource().getEpochTimeNs()));\n    }\n    // add replicas\n    for (ReplicaPosition replicaPosition : replicaPositions) {\n      String subSliceName = replicaPosition.shard;\n      String subShardNodeName = replicaPosition.node;\n//      String solrCoreName = collectionName + \"_\" + subSliceName + \"_replica_n\" + (replicaPosition.index);\n      String solrCoreName = Assign.buildSolrCoreName(collectionName, subSliceName, replicaPosition.type, Assign.incAndGetId(stateManager, collectionName, 0));\n      Map<String, Object> replicaProps = new HashMap<>();\n      replicaProps.put(ZkStateReader.SHARD_ID_PROP, replicaPosition.shard);\n      replicaProps.put(ZkStateReader.NODE_NAME_PROP, replicaPosition.node);\n      replicaProps.put(ZkStateReader.REPLICA_TYPE, replicaPosition.type.toString());\n      replicaProps.put(ZkStateReader.BASE_URL_PROP, Utils.getBaseUrlForNodeName(subShardNodeName, \"http\"));\n\n      long replicasNumDocs = newNumDocs;\n      long replicasIndexSize = newIndexSize;\n      if (remainderSlice == null) {\n        remainderSlice = subSliceName;\n      }\n      if (remainderSlice.equals(subSliceName)) { // only add to one sub slice\n        replicasNumDocs += remainderDocs;\n        replicasIndexSize += remainderIndexSize;\n      }\n      replicaProps.put(\"SEARCHER.searcher.numDocs\", new AtomicLong(replicasNumDocs));\n      replicaProps.put(\"SEARCHER.searcher.maxDoc\", new AtomicLong(replicasNumDocs));\n      replicaProps.put(\"SEARCHER.searcher.deletedDocs\", new AtomicLong(0));\n      replicaProps.put(Type.CORE_IDX.metricsAttribute, new AtomicLong(replicasIndexSize));\n      replicaProps.put(Variable.coreidxsize, new AtomicDouble((Double)Type.CORE_IDX.convertVal(replicasIndexSize)));\n\n      Replica ri = new Replica(\"core_node\" + Assign.incAndGetId(stateManager, collectionName, 0),\n          subShardNodeName, collectionName, replicaPosition.shard, solrCoreName,\n          Replica.State.DOWN, replicaPosition.type, replicaProps);\n      simAddReplica(replicaPosition.node, ri, false);\n    }\n    simRunLeaderElection(Collections.singleton(collectionName), true);\n\n    // delay it once again to better simulate replica recoveries\n    //opDelay(collectionName, CollectionParams.CollectionAction.SPLITSHARD.name());\n\n    boolean success = false;\n    try {\n      CloudUtil.waitForState(cloudManager, collectionName, 30, TimeUnit.SECONDS, (liveNodes, state) -> {\n        for (String subSlice : subSlices) {\n          Slice s = state.getSlice(subSlice);\n          if (s.getLeader() == null) {\n            log.debug(\"** no leader in {} / {}\", collectionName, s);\n            return false;\n          }\n          if (s.getReplicas().size() < repFactor) {\n            if (log.isDebugEnabled()) {\n              log.debug(\"** expected {} repFactor but there are {} replicas\", repFactor, s.getReplicas().size());\n            }\n            return false;\n          }\n        }\n        return true;\n      });\n      success = true;\n    } finally {\n      if (!success) {\n        Map<String, Object> sProps = sliceProperties.computeIfAbsent(collectionName, c -> new ConcurrentHashMap<>())\n            .computeIfAbsent(sliceName.get(), s -> new ConcurrentHashMap<>());\n        sProps.remove(BUFFERED_UPDATES);\n        SplitShardCmd.unlockForSplit(cloudManager, collectionName, sliceName.get());\n      }\n    }\n    // mark the new slices as active and the old slice as inactive\n    if (log.isTraceEnabled()) {\n      log.trace(\"-- switching slice states after split shard: collection={}, parent={}, subSlices={}\", collectionName,\n          sliceName.get(), subSlices);\n    }\n    lock.lockInterruptibly();\n    try {\n      Map<String, Object> sProps = sliceProperties.computeIfAbsent(collectionName, c -> new ConcurrentHashMap<>())\n          .computeIfAbsent(sliceName.get(), s -> new ConcurrentHashMap<>());\n      sProps.put(ZkStateReader.STATE_PROP, Slice.State.INACTIVE.toString());\n      sProps.put(ZkStateReader.STATE_TIMESTAMP_PROP, String.valueOf(cloudManager.getTimeSource().getEpochTimeNs()));\n      AtomicLong bufferedUpdates = (AtomicLong)sProps.remove(BUFFERED_UPDATES);\n      if (bufferedUpdates.get() > 0) {\n        // apply buffered updates\n        long perShard = bufferedUpdates.get() / subSlices.size();\n        long remainder = bufferedUpdates.get() % subSlices.size();\n        if (log.isDebugEnabled()) {\n          log.debug(\"-- applying {} buffered docs from {} / {}, perShard={}, remainder={}\", bufferedUpdates.get(),\n              collectionName, parentSlice.getName(), perShard, remainder);\n        }\n        for (int i = 0; i < subSlices.size(); i++) {\n          String sub = subSlices.get(i);\n          long numUpdates = perShard;\n          if (i == 0) {\n            numUpdates += remainder;\n          }\n          simSetShardValue(collectionName, sub, \"SEARCHER.searcher.numDocs\", numUpdates, true, false);\n          simSetShardValue(collectionName, sub, \"SEARCHER.searcher.maxDoc\", numUpdates, true, false);\n        }\n      }\n      // XXX also mark replicas as down? currently SplitShardCmd doesn't do this\n\n      for (String s : subSlices) {\n        Map<String, Object> sliceProps = sliceProperties.computeIfAbsent(collectionName, c -> new ConcurrentHashMap<>())\n            .computeIfAbsent(s, ss -> new ConcurrentHashMap<>());\n        sliceProps.put(ZkStateReader.STATE_PROP, Slice.State.ACTIVE.toString());\n        sliceProps.put(ZkStateReader.STATE_TIMESTAMP_PROP, String.valueOf(cloudManager.getTimeSource().getEpochTimeNs()));\n      }\n\n      // invalidate cached state\n      collectionsStatesRef.get(collectionName).invalidate();\n    } finally {\n      SplitShardCmd.unlockForSplit(cloudManager, collectionName, sliceName.get());\n      lock.unlock();\n    }\n    results.add(\"success\", \"\");\n\n  }\n\n","sourceOld":"  /**\n   * Split a shard. This uses a similar algorithm as {@link SplitShardCmd}, including simulating its\n   * quirks, and leaving the original parent slice in place.\n   * @param message operation details\n   * @param results operation results.\n   */\n  @SuppressWarnings({\"unchecked\", \"rawtypes\"})\n  public void simSplitShard(ZkNodeProps message, NamedList results) throws Exception {\n    ensureNotClosed();\n    if (message.getStr(CommonAdminParams.ASYNC) != null) {\n      results.add(CoreAdminParams.REQUESTID, message.getStr(CommonAdminParams.ASYNC));\n    }\n    String collectionName = message.getStr(COLLECTION_PROP);\n    AtomicReference<String> sliceName = new AtomicReference<>();\n    sliceName.set(message.getStr(SHARD_ID_PROP));\n    String splitKey = message.getStr(\"split.key\");\n    String methodStr = message.getStr(CommonAdminParams.SPLIT_METHOD, SolrIndexSplitter.SplitMethod.REWRITE.toLower());\n    SolrIndexSplitter.SplitMethod splitMethod = SolrIndexSplitter.SplitMethod.get(methodStr);\n    if (splitMethod == null) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Unknown value '\" + CommonAdminParams.SPLIT_METHOD +\n          \": \" + methodStr);\n    }\n\n    ClusterState clusterState = getClusterState();\n    DocCollection collection = clusterState.getCollection(collectionName);\n    Slice parentSlice = SplitShardCmd.getParentSlice(clusterState, collectionName, sliceName, splitKey);\n    Replica leader = parentSlice.getLeader();\n    // XXX leader election may not have happened yet - should we require it?\n    if (leader == null) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Shard \" + collectionName +\n          \" /  \" + sliceName.get() + \" has no leader and can't be split\");\n    }\n    SplitShardCmd.checkDiskSpace(collectionName, sliceName.get(), leader, splitMethod, cloudManager);\n    SplitShardCmd.lockForSplit(cloudManager, collectionName, sliceName.get());\n    // start counting buffered updates\n    Map<String, Object> props = sliceProperties.computeIfAbsent(collectionName, c -> new ConcurrentHashMap<>())\n        .computeIfAbsent(sliceName.get(), ss -> new ConcurrentHashMap<>());\n    if (props.containsKey(BUFFERED_UPDATES)) {\n      SplitShardCmd.unlockForSplit(cloudManager, collectionName, sliceName.get());\n      throw new Exception(\"--- SOLR-12729: Overlapping splitShard commands for \" + collectionName + \"/\" + sliceName.get());\n    }\n    props.put(BUFFERED_UPDATES, new AtomicLong());\n\n    List<DocRouter.Range> subRanges = new ArrayList<>();\n    List<String> subSlices = new ArrayList<>();\n    List<String> subShardNames = new ArrayList<>();\n\n    opDelay(collectionName, CollectionParams.CollectionAction.SPLITSHARD.name());\n\n    SplitShardCmd.fillRanges(cloudManager, message, collection, parentSlice, subRanges, subSlices, subShardNames, true);\n    // add replicas for new subShards\n    int repFactor = parentSlice.getReplicas().size();\n    Assign.AssignRequest assignRequest = new Assign.AssignRequestBuilder()\n        .forCollection(collectionName)\n        .forShard(subSlices)\n        .assignNrtReplicas(repFactor)\n        .assignTlogReplicas(0)\n        .assignPullReplicas(0)\n        .onNodes(new ArrayList<>(clusterState.getLiveNodes()))\n        .build();\n    Assign.AssignStrategyFactory assignStrategyFactory = new Assign.AssignStrategyFactory(cloudManager);\n    Assign.AssignStrategy assignStrategy = assignStrategyFactory.create(clusterState, collection);\n    // reproduce the bug\n    List<ReplicaPosition> replicaPositions = assignStrategy.assign(cloudManager, assignRequest);\n    PolicyHelper.SessionWrapper sessionWrapper = PolicyHelper.getLastSessionWrapper(true);\n    if (sessionWrapper != null) sessionWrapper.release();\n\n    // adjust numDocs / deletedDocs / maxDoc\n    String numDocsStr = String.valueOf(getReplicaInfo(leader).getVariable(\"SEARCHER.searcher.numDocs\", \"0\"));\n    long numDocs = Long.parseLong(numDocsStr);\n    long newNumDocs = numDocs / subSlices.size();\n    long remainderDocs = numDocs % subSlices.size();\n    long newIndexSize = SimCloudManager.DEFAULT_IDX_SIZE_BYTES + newNumDocs * DEFAULT_DOC_SIZE_BYTES;\n    long remainderIndexSize = SimCloudManager.DEFAULT_IDX_SIZE_BYTES + remainderDocs * DEFAULT_DOC_SIZE_BYTES;\n    String remainderSlice = null;\n\n    // add slice props\n    for (int i = 0; i < subRanges.size(); i++) {\n      String subSlice = subSlices.get(i);\n      DocRouter.Range range = subRanges.get(i);\n      Map<String, Object> sliceProps = sliceProperties.computeIfAbsent(collectionName, c -> new ConcurrentHashMap<>())\n          .computeIfAbsent(subSlice, ss -> new ConcurrentHashMap<>());\n      sliceProps.put(Slice.RANGE, range);\n      sliceProps.put(Slice.PARENT, sliceName.get());\n      sliceProps.put(ZkStateReader.STATE_PROP, Slice.State.CONSTRUCTION.toString());\n      sliceProps.put(ZkStateReader.STATE_TIMESTAMP_PROP, String.valueOf(cloudManager.getTimeSource().getEpochTimeNs()));\n    }\n    // add replicas\n    for (ReplicaPosition replicaPosition : replicaPositions) {\n      String subSliceName = replicaPosition.shard;\n      String subShardNodeName = replicaPosition.node;\n//      String solrCoreName = collectionName + \"_\" + subSliceName + \"_replica_n\" + (replicaPosition.index);\n      String solrCoreName = Assign.buildSolrCoreName(collectionName, subSliceName, replicaPosition.type, Assign.incAndGetId(stateManager, collectionName, 0));\n      Map<String, Object> replicaProps = new HashMap<>();\n      replicaProps.put(ZkStateReader.SHARD_ID_PROP, replicaPosition.shard);\n      replicaProps.put(ZkStateReader.NODE_NAME_PROP, replicaPosition.node);\n      replicaProps.put(ZkStateReader.REPLICA_TYPE, replicaPosition.type.toString());\n      replicaProps.put(ZkStateReader.BASE_URL_PROP, Utils.getBaseUrlForNodeName(subShardNodeName, \"http\"));\n\n      long replicasNumDocs = newNumDocs;\n      long replicasIndexSize = newIndexSize;\n      if (remainderSlice == null) {\n        remainderSlice = subSliceName;\n      }\n      if (remainderSlice.equals(subSliceName)) { // only add to one sub slice\n        replicasNumDocs += remainderDocs;\n        replicasIndexSize += remainderIndexSize;\n      }\n      replicaProps.put(\"SEARCHER.searcher.numDocs\", new AtomicLong(replicasNumDocs));\n      replicaProps.put(\"SEARCHER.searcher.maxDoc\", new AtomicLong(replicasNumDocs));\n      replicaProps.put(\"SEARCHER.searcher.deletedDocs\", new AtomicLong(0));\n      replicaProps.put(Type.CORE_IDX.metricsAttribute, new AtomicLong(replicasIndexSize));\n      replicaProps.put(Variable.coreidxsize, new AtomicDouble((Double)Type.CORE_IDX.convertVal(replicasIndexSize)));\n\n      ReplicaInfo ri = new ReplicaInfo(\"core_node\" + Assign.incAndGetId(stateManager, collectionName, 0),\n          solrCoreName, collectionName, replicaPosition.shard, replicaPosition.type, subShardNodeName, replicaProps);\n      simAddReplica(replicaPosition.node, ri, false);\n    }\n    simRunLeaderElection(Collections.singleton(collectionName), true);\n\n    // delay it once again to better simulate replica recoveries\n    //opDelay(collectionName, CollectionParams.CollectionAction.SPLITSHARD.name());\n\n    boolean success = false;\n    try {\n      CloudUtil.waitForState(cloudManager, collectionName, 30, TimeUnit.SECONDS, (liveNodes, state) -> {\n        for (String subSlice : subSlices) {\n          Slice s = state.getSlice(subSlice);\n          if (s.getLeader() == null) {\n            log.debug(\"** no leader in {} / {}\", collectionName, s);\n            return false;\n          }\n          if (s.getReplicas().size() < repFactor) {\n            if (log.isDebugEnabled()) {\n              log.debug(\"** expected {} repFactor but there are {} replicas\", repFactor, s.getReplicas().size());\n            }\n            return false;\n          }\n        }\n        return true;\n      });\n      success = true;\n    } finally {\n      if (!success) {\n        Map<String, Object> sProps = sliceProperties.computeIfAbsent(collectionName, c -> new ConcurrentHashMap<>())\n            .computeIfAbsent(sliceName.get(), s -> new ConcurrentHashMap<>());\n        sProps.remove(BUFFERED_UPDATES);\n        SplitShardCmd.unlockForSplit(cloudManager, collectionName, sliceName.get());\n      }\n    }\n    // mark the new slices as active and the old slice as inactive\n    if (log.isTraceEnabled()) {\n      log.trace(\"-- switching slice states after split shard: collection={}, parent={}, subSlices={}\", collectionName,\n          sliceName.get(), subSlices);\n    }\n    lock.lockInterruptibly();\n    try {\n      Map<String, Object> sProps = sliceProperties.computeIfAbsent(collectionName, c -> new ConcurrentHashMap<>())\n          .computeIfAbsent(sliceName.get(), s -> new ConcurrentHashMap<>());\n      sProps.put(ZkStateReader.STATE_PROP, Slice.State.INACTIVE.toString());\n      sProps.put(ZkStateReader.STATE_TIMESTAMP_PROP, String.valueOf(cloudManager.getTimeSource().getEpochTimeNs()));\n      AtomicLong bufferedUpdates = (AtomicLong)sProps.remove(BUFFERED_UPDATES);\n      if (bufferedUpdates.get() > 0) {\n        // apply buffered updates\n        long perShard = bufferedUpdates.get() / subSlices.size();\n        long remainder = bufferedUpdates.get() % subSlices.size();\n        if (log.isDebugEnabled()) {\n          log.debug(\"-- applying {} buffered docs from {} / {}, perShard={}, remainder={}\", bufferedUpdates.get(),\n              collectionName, parentSlice.getName(), perShard, remainder);\n        }\n        for (int i = 0; i < subSlices.size(); i++) {\n          String sub = subSlices.get(i);\n          long numUpdates = perShard;\n          if (i == 0) {\n            numUpdates += remainder;\n          }\n          simSetShardValue(collectionName, sub, \"SEARCHER.searcher.numDocs\", numUpdates, true, false);\n          simSetShardValue(collectionName, sub, \"SEARCHER.searcher.maxDoc\", numUpdates, true, false);\n        }\n      }\n      // XXX also mark replicas as down? currently SplitShardCmd doesn't do this\n\n      for (String s : subSlices) {\n        Map<String, Object> sliceProps = sliceProperties.computeIfAbsent(collectionName, c -> new ConcurrentHashMap<>())\n            .computeIfAbsent(s, ss -> new ConcurrentHashMap<>());\n        sliceProps.put(ZkStateReader.STATE_PROP, Slice.State.ACTIVE.toString());\n        sliceProps.put(ZkStateReader.STATE_TIMESTAMP_PROP, String.valueOf(cloudManager.getTimeSource().getEpochTimeNs()));\n      }\n\n      // invalidate cached state\n      collectionsStatesRef.get(collectionName).invalidate();\n    } finally {\n      SplitShardCmd.unlockForSplit(cloudManager, collectionName, sliceName.get());\n      lock.unlock();\n    }\n    results.add(\"success\", \"\");\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3f504512a03d978990cbff30db0522b354e846db","date":1595247421,"type":4,"author":"Ishan Chattopadhyaya","isMerge":false,"pathNew":"/dev/null","pathOld":"solr/core/src/java/org/apache/solr/cloud/autoscaling/sim/SimClusterStateProvider#simSplitShard(ZkNodeProps,NamedList).mjava","sourceNew":null,"sourceOld":"  /**\n   * Split a shard. This uses a similar algorithm as {@link SplitShardCmd}, including simulating its\n   * quirks, and leaving the original parent slice in place.\n   * @param message operation details\n   * @param results operation results.\n   */\n  @SuppressWarnings({\"unchecked\", \"rawtypes\"})\n  public void simSplitShard(ZkNodeProps message, NamedList results) throws Exception {\n    ensureNotClosed();\n    if (message.getStr(CommonAdminParams.ASYNC) != null) {\n      results.add(CoreAdminParams.REQUESTID, message.getStr(CommonAdminParams.ASYNC));\n    }\n    String collectionName = message.getStr(COLLECTION_PROP);\n    AtomicReference<String> sliceName = new AtomicReference<>();\n    sliceName.set(message.getStr(SHARD_ID_PROP));\n    String splitKey = message.getStr(\"split.key\");\n    String methodStr = message.getStr(CommonAdminParams.SPLIT_METHOD, SolrIndexSplitter.SplitMethod.REWRITE.toLower());\n    SolrIndexSplitter.SplitMethod splitMethod = SolrIndexSplitter.SplitMethod.get(methodStr);\n    if (splitMethod == null) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Unknown value '\" + CommonAdminParams.SPLIT_METHOD +\n          \": \" + methodStr);\n    }\n\n    ClusterState clusterState = getClusterState();\n    DocCollection collection = clusterState.getCollection(collectionName);\n    Slice parentSlice = SplitShardCmd.getParentSlice(clusterState, collectionName, sliceName, splitKey);\n    Replica leader = parentSlice.getLeader();\n    // XXX leader election may not have happened yet - should we require it?\n    if (leader == null) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Shard \" + collectionName +\n          \" /  \" + sliceName.get() + \" has no leader and can't be split\");\n    }\n    SplitShardCmd.checkDiskSpace(collectionName, sliceName.get(), leader, splitMethod, cloudManager);\n    SplitShardCmd.lockForSplit(cloudManager, collectionName, sliceName.get());\n    // start counting buffered updates\n    Map<String, Object> props = sliceProperties.computeIfAbsent(collectionName, c -> new ConcurrentHashMap<>())\n        .computeIfAbsent(sliceName.get(), ss -> new ConcurrentHashMap<>());\n    if (props.containsKey(BUFFERED_UPDATES)) {\n      SplitShardCmd.unlockForSplit(cloudManager, collectionName, sliceName.get());\n      throw new Exception(\"--- SOLR-12729: Overlapping splitShard commands for \" + collectionName + \"/\" + sliceName.get());\n    }\n    props.put(BUFFERED_UPDATES, new AtomicLong());\n\n    List<DocRouter.Range> subRanges = new ArrayList<>();\n    List<String> subSlices = new ArrayList<>();\n    List<String> subShardNames = new ArrayList<>();\n\n    opDelay(collectionName, CollectionParams.CollectionAction.SPLITSHARD.name());\n\n    SplitShardCmd.fillRanges(cloudManager, message, collection, parentSlice, subRanges, subSlices, subShardNames, true);\n    // add replicas for new subShards\n    int repFactor = parentSlice.getReplicas().size();\n    Assign.AssignRequest assignRequest = new Assign.AssignRequestBuilder()\n        .forCollection(collectionName)\n        .forShard(subSlices)\n        .assignNrtReplicas(repFactor)\n        .assignTlogReplicas(0)\n        .assignPullReplicas(0)\n        .onNodes(new ArrayList<>(clusterState.getLiveNodes()))\n        .build();\n    Assign.AssignStrategyFactory assignStrategyFactory = new Assign.AssignStrategyFactory(cloudManager);\n    Assign.AssignStrategy assignStrategy = assignStrategyFactory.create(clusterState, collection);\n    // reproduce the bug\n    List<ReplicaPosition> replicaPositions = assignStrategy.assign(cloudManager, assignRequest);\n    PolicyHelper.SessionWrapper sessionWrapper = PolicyHelper.getLastSessionWrapper(true);\n    if (sessionWrapper != null) sessionWrapper.release();\n\n    // adjust numDocs / deletedDocs / maxDoc\n    String numDocsStr = String.valueOf(getReplicaInfo(leader).get(\"SEARCHER.searcher.numDocs\", \"0\"));\n    long numDocs = Long.parseLong(numDocsStr);\n    long newNumDocs = numDocs / subSlices.size();\n    long remainderDocs = numDocs % subSlices.size();\n    long newIndexSize = SimCloudManager.DEFAULT_IDX_SIZE_BYTES + newNumDocs * DEFAULT_DOC_SIZE_BYTES;\n    long remainderIndexSize = SimCloudManager.DEFAULT_IDX_SIZE_BYTES + remainderDocs * DEFAULT_DOC_SIZE_BYTES;\n    String remainderSlice = null;\n\n    // add slice props\n    for (int i = 0; i < subRanges.size(); i++) {\n      String subSlice = subSlices.get(i);\n      DocRouter.Range range = subRanges.get(i);\n      Map<String, Object> sliceProps = sliceProperties.computeIfAbsent(collectionName, c -> new ConcurrentHashMap<>())\n          .computeIfAbsent(subSlice, ss -> new ConcurrentHashMap<>());\n      sliceProps.put(Slice.RANGE, range);\n      sliceProps.put(Slice.PARENT, sliceName.get());\n      sliceProps.put(ZkStateReader.STATE_PROP, Slice.State.CONSTRUCTION.toString());\n      sliceProps.put(ZkStateReader.STATE_TIMESTAMP_PROP, String.valueOf(cloudManager.getTimeSource().getEpochTimeNs()));\n    }\n    // add replicas\n    for (ReplicaPosition replicaPosition : replicaPositions) {\n      String subSliceName = replicaPosition.shard;\n      String subShardNodeName = replicaPosition.node;\n//      String solrCoreName = collectionName + \"_\" + subSliceName + \"_replica_n\" + (replicaPosition.index);\n      String solrCoreName = Assign.buildSolrCoreName(collectionName, subSliceName, replicaPosition.type, Assign.incAndGetId(stateManager, collectionName, 0));\n      Map<String, Object> replicaProps = new HashMap<>();\n      replicaProps.put(ZkStateReader.SHARD_ID_PROP, replicaPosition.shard);\n      replicaProps.put(ZkStateReader.NODE_NAME_PROP, replicaPosition.node);\n      replicaProps.put(ZkStateReader.REPLICA_TYPE, replicaPosition.type.toString());\n      replicaProps.put(ZkStateReader.BASE_URL_PROP, Utils.getBaseUrlForNodeName(subShardNodeName, \"http\"));\n\n      long replicasNumDocs = newNumDocs;\n      long replicasIndexSize = newIndexSize;\n      if (remainderSlice == null) {\n        remainderSlice = subSliceName;\n      }\n      if (remainderSlice.equals(subSliceName)) { // only add to one sub slice\n        replicasNumDocs += remainderDocs;\n        replicasIndexSize += remainderIndexSize;\n      }\n      replicaProps.put(\"SEARCHER.searcher.numDocs\", new AtomicLong(replicasNumDocs));\n      replicaProps.put(\"SEARCHER.searcher.maxDoc\", new AtomicLong(replicasNumDocs));\n      replicaProps.put(\"SEARCHER.searcher.deletedDocs\", new AtomicLong(0));\n      replicaProps.put(Type.CORE_IDX.metricsAttribute, new AtomicLong(replicasIndexSize));\n      replicaProps.put(Variable.coreidxsize, new AtomicDouble((Double)Type.CORE_IDX.convertVal(replicasIndexSize)));\n\n      Replica ri = new Replica(\"core_node\" + Assign.incAndGetId(stateManager, collectionName, 0),\n          subShardNodeName, collectionName, replicaPosition.shard, solrCoreName,\n          Replica.State.DOWN, replicaPosition.type, replicaProps);\n      simAddReplica(replicaPosition.node, ri, false);\n    }\n    simRunLeaderElection(Collections.singleton(collectionName), true);\n\n    // delay it once again to better simulate replica recoveries\n    //opDelay(collectionName, CollectionParams.CollectionAction.SPLITSHARD.name());\n\n    boolean success = false;\n    try {\n      CloudUtil.waitForState(cloudManager, collectionName, 30, TimeUnit.SECONDS, (liveNodes, state) -> {\n        for (String subSlice : subSlices) {\n          Slice s = state.getSlice(subSlice);\n          if (s.getLeader() == null) {\n            log.debug(\"** no leader in {} / {}\", collectionName, s);\n            return false;\n          }\n          if (s.getReplicas().size() < repFactor) {\n            if (log.isDebugEnabled()) {\n              log.debug(\"** expected {} repFactor but there are {} replicas\", repFactor, s.getReplicas().size());\n            }\n            return false;\n          }\n        }\n        return true;\n      });\n      success = true;\n    } finally {\n      if (!success) {\n        Map<String, Object> sProps = sliceProperties.computeIfAbsent(collectionName, c -> new ConcurrentHashMap<>())\n            .computeIfAbsent(sliceName.get(), s -> new ConcurrentHashMap<>());\n        sProps.remove(BUFFERED_UPDATES);\n        SplitShardCmd.unlockForSplit(cloudManager, collectionName, sliceName.get());\n      }\n    }\n    // mark the new slices as active and the old slice as inactive\n    if (log.isTraceEnabled()) {\n      log.trace(\"-- switching slice states after split shard: collection={}, parent={}, subSlices={}\", collectionName,\n          sliceName.get(), subSlices);\n    }\n    lock.lockInterruptibly();\n    try {\n      Map<String, Object> sProps = sliceProperties.computeIfAbsent(collectionName, c -> new ConcurrentHashMap<>())\n          .computeIfAbsent(sliceName.get(), s -> new ConcurrentHashMap<>());\n      sProps.put(ZkStateReader.STATE_PROP, Slice.State.INACTIVE.toString());\n      sProps.put(ZkStateReader.STATE_TIMESTAMP_PROP, String.valueOf(cloudManager.getTimeSource().getEpochTimeNs()));\n      AtomicLong bufferedUpdates = (AtomicLong)sProps.remove(BUFFERED_UPDATES);\n      if (bufferedUpdates.get() > 0) {\n        // apply buffered updates\n        long perShard = bufferedUpdates.get() / subSlices.size();\n        long remainder = bufferedUpdates.get() % subSlices.size();\n        if (log.isDebugEnabled()) {\n          log.debug(\"-- applying {} buffered docs from {} / {}, perShard={}, remainder={}\", bufferedUpdates.get(),\n              collectionName, parentSlice.getName(), perShard, remainder);\n        }\n        for (int i = 0; i < subSlices.size(); i++) {\n          String sub = subSlices.get(i);\n          long numUpdates = perShard;\n          if (i == 0) {\n            numUpdates += remainder;\n          }\n          simSetShardValue(collectionName, sub, \"SEARCHER.searcher.numDocs\", numUpdates, true, false);\n          simSetShardValue(collectionName, sub, \"SEARCHER.searcher.maxDoc\", numUpdates, true, false);\n        }\n      }\n      // XXX also mark replicas as down? currently SplitShardCmd doesn't do this\n\n      for (String s : subSlices) {\n        Map<String, Object> sliceProps = sliceProperties.computeIfAbsent(collectionName, c -> new ConcurrentHashMap<>())\n            .computeIfAbsent(s, ss -> new ConcurrentHashMap<>());\n        sliceProps.put(ZkStateReader.STATE_PROP, Slice.State.ACTIVE.toString());\n        sliceProps.put(ZkStateReader.STATE_TIMESTAMP_PROP, String.valueOf(cloudManager.getTimeSource().getEpochTimeNs()));\n      }\n\n      // invalidate cached state\n      collectionsStatesRef.get(collectionName).invalidate();\n    } finally {\n      SplitShardCmd.unlockForSplit(cloudManager, collectionName, sliceName.get());\n      lock.unlock();\n    }\n    results.add(\"success\", \"\");\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"7e8ce2f9d2ddfcf5cfa7e73b8b2af287a2a276fd":["daa0f21a44e235a2299ea1fa913898b182dd7cce"],"993b0c7dda6341b437fe5685d35c6cc35eaac420":["9ef8d00dbfbeb534eba8a219a5df9d99b2de6ab5","8f79e6c597ec19b2f9669589153faac2f803462a"],"3f504512a03d978990cbff30db0522b354e846db":["7e8ce2f9d2ddfcf5cfa7e73b8b2af287a2a276fd"],"daa0f21a44e235a2299ea1fa913898b182dd7cce":["eb7a329be123e1f46f9d78d74f6d23f33ec81b0a"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"8f79e6c597ec19b2f9669589153faac2f803462a":["9ef8d00dbfbeb534eba8a219a5df9d99b2de6ab5"],"eb7a329be123e1f46f9d78d74f6d23f33ec81b0a":["e35f2dde06b35aa9904949a3a93fabd090371077"],"e35f2dde06b35aa9904949a3a93fabd090371077":["8f79e6c597ec19b2f9669589153faac2f803462a"],"9ef8d00dbfbeb534eba8a219a5df9d99b2de6ab5":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["3f504512a03d978990cbff30db0522b354e846db"]},"commit2Childs":{"7e8ce2f9d2ddfcf5cfa7e73b8b2af287a2a276fd":["3f504512a03d978990cbff30db0522b354e846db"],"993b0c7dda6341b437fe5685d35c6cc35eaac420":[],"3f504512a03d978990cbff30db0522b354e846db":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"daa0f21a44e235a2299ea1fa913898b182dd7cce":["7e8ce2f9d2ddfcf5cfa7e73b8b2af287a2a276fd"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["9ef8d00dbfbeb534eba8a219a5df9d99b2de6ab5"],"8f79e6c597ec19b2f9669589153faac2f803462a":["993b0c7dda6341b437fe5685d35c6cc35eaac420","e35f2dde06b35aa9904949a3a93fabd090371077"],"9ef8d00dbfbeb534eba8a219a5df9d99b2de6ab5":["993b0c7dda6341b437fe5685d35c6cc35eaac420","8f79e6c597ec19b2f9669589153faac2f803462a"],"eb7a329be123e1f46f9d78d74f6d23f33ec81b0a":["daa0f21a44e235a2299ea1fa913898b182dd7cce"],"e35f2dde06b35aa9904949a3a93fabd090371077":["eb7a329be123e1f46f9d78d74f6d23f33ec81b0a"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["993b0c7dda6341b437fe5685d35c6cc35eaac420","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}