{"path":"lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/SynonymTokenizer[HighlighterTest].TestHighlightRunner#doStandardHighlights(Analyzer,IndexSearcher,TopDocs,Query,Formatter,boolean).mjava","commits":[{"id":"9454a6510e2db155fb01faa5c049b06ece95fab9","date":1453508333,"type":1,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/SynonymTokenizer[HighlighterTest].TestHighlightRunner#doStandardHighlights(Analyzer,IndexSearcher,TopDocs,Query,Formatter,boolean).mjava","pathOld":"contrib/highlighter/src/test/org/apache/lucene/search/highlight/SynonymTokenizer[HighlighterTest].TestHighlightRunner#doStandardHighlights(Analyzer,IndexSearcher,TopDocs,Query,Formatter,boolean).mjava","sourceNew":"    void doStandardHighlights(Analyzer analyzer, IndexSearcher searcher, TopDocs hits, Query query, Formatter formatter, boolean expandMT)\n        throws Exception {\n\n      for (int i = 0; i < hits.totalHits; i++) {\n        String text = searcher.doc(hits.scoreDocs[i].doc).get(HighlighterTest.FIELD_NAME);\n        int maxNumFragmentsRequired = 2;\n        String fragmentSeparator = \"...\";\n        Scorer scorer = null;\n        TokenStream tokenStream = analyzer.tokenStream(HighlighterTest.FIELD_NAME, new StringReader(text));\n        if (mode == QUERY) {\n          scorer = new QueryScorer(query);\n        } else if (mode == QUERY_TERM) {\n          scorer = new QueryTermScorer(query);\n        }\n        Highlighter highlighter = new Highlighter(formatter, scorer);\n        highlighter.setTextFragmenter(frag);\n\n        String result = highlighter.getBestFragments(tokenStream, text, maxNumFragmentsRequired,\n            fragmentSeparator);\n        if (HighlighterTest.VERBOSE) System.out.println(\"\\t\" + result);\n      }\n    }\n\n","sourceOld":"    void doStandardHighlights(Analyzer analyzer, IndexSearcher searcher, TopDocs hits, Query query, Formatter formatter, boolean expandMT)\n        throws Exception {\n\n      for (int i = 0; i < hits.totalHits; i++) {\n        String text = searcher.doc(hits.scoreDocs[i].doc).get(HighlighterTest.FIELD_NAME);\n        int maxNumFragmentsRequired = 2;\n        String fragmentSeparator = \"...\";\n        Scorer scorer = null;\n        TokenStream tokenStream = analyzer.tokenStream(HighlighterTest.FIELD_NAME, new StringReader(text));\n        if (mode == QUERY) {\n          scorer = new QueryScorer(query);\n        } else if (mode == QUERY_TERM) {\n          scorer = new QueryTermScorer(query);\n        }\n        Highlighter highlighter = new Highlighter(formatter, scorer);\n        highlighter.setTextFragmenter(frag);\n\n        String result = highlighter.getBestFragments(tokenStream, text, maxNumFragmentsRequired,\n            fragmentSeparator);\n        if (HighlighterTest.VERBOSE) System.out.println(\"\\t\" + result);\n      }\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"cf7efd82433f3f64684711c16edfd149db6af111","date":1317013128,"type":3,"author":"Christopher John Male","isMerge":false,"pathNew":"lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/SynonymTokenizer[HighlighterTest].TestHighlightRunner#doStandardHighlights(Analyzer,IndexSearcher,TopDocs,Query,Formatter,boolean).mjava","pathOld":"lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/SynonymTokenizer[HighlighterTest].TestHighlightRunner#doStandardHighlights(Analyzer,IndexSearcher,TopDocs,Query,Formatter,boolean).mjava","sourceNew":"    void doStandardHighlights(Analyzer analyzer, IndexSearcher searcher, TopDocs hits, Query query, Formatter formatter, boolean expandMT)\n        throws Exception {\n\n      for (int i = 0; i < hits.totalHits; i++) {\n        String text = searcher.doc(hits.scoreDocs[i].doc).get(HighlighterTest.FIELD_NAME);\n        int maxNumFragmentsRequired = 2;\n        String fragmentSeparator = \"...\";\n        Scorer scorer = null;\n        TokenStream tokenStream = analyzer.reusableTokenStream(HighlighterTest.FIELD_NAME, new StringReader(text));\n        if (mode == QUERY) {\n          scorer = new QueryScorer(query);\n        } else if (mode == QUERY_TERM) {\n          scorer = new QueryTermScorer(query);\n        }\n        Highlighter highlighter = new Highlighter(formatter, scorer);\n        highlighter.setTextFragmenter(frag);\n\n        String result = highlighter.getBestFragments(tokenStream, text, maxNumFragmentsRequired,\n            fragmentSeparator);\n        if (HighlighterTest.VERBOSE) System.out.println(\"\\t\" + result);\n      }\n    }\n\n","sourceOld":"    void doStandardHighlights(Analyzer analyzer, IndexSearcher searcher, TopDocs hits, Query query, Formatter formatter, boolean expandMT)\n        throws Exception {\n\n      for (int i = 0; i < hits.totalHits; i++) {\n        String text = searcher.doc(hits.scoreDocs[i].doc).get(HighlighterTest.FIELD_NAME);\n        int maxNumFragmentsRequired = 2;\n        String fragmentSeparator = \"...\";\n        Scorer scorer = null;\n        TokenStream tokenStream = analyzer.tokenStream(HighlighterTest.FIELD_NAME, new StringReader(text));\n        if (mode == QUERY) {\n          scorer = new QueryScorer(query);\n        } else if (mode == QUERY_TERM) {\n          scorer = new QueryTermScorer(query);\n        }\n        Highlighter highlighter = new Highlighter(formatter, scorer);\n        highlighter.setTextFragmenter(frag);\n\n        String result = highlighter.getBestFragments(tokenStream, text, maxNumFragmentsRequired,\n            fragmentSeparator);\n        if (HighlighterTest.VERBOSE) System.out.println(\"\\t\" + result);\n      }\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"69e043c521d4e8db770cc140c63f5ef51f03426a","date":1317187614,"type":3,"author":"Christopher John Male","isMerge":false,"pathNew":"lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/SynonymTokenizer[HighlighterTest].TestHighlightRunner#doStandardHighlights(Analyzer,IndexSearcher,TopDocs,Query,Formatter,boolean).mjava","pathOld":"lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/SynonymTokenizer[HighlighterTest].TestHighlightRunner#doStandardHighlights(Analyzer,IndexSearcher,TopDocs,Query,Formatter,boolean).mjava","sourceNew":"    void doStandardHighlights(Analyzer analyzer, IndexSearcher searcher, TopDocs hits, Query query, Formatter formatter, boolean expandMT)\n        throws Exception {\n\n      for (int i = 0; i < hits.totalHits; i++) {\n        String text = searcher.doc(hits.scoreDocs[i].doc).get(HighlighterTest.FIELD_NAME);\n        int maxNumFragmentsRequired = 2;\n        String fragmentSeparator = \"...\";\n        Scorer scorer = null;\n        TokenStream tokenStream = analyzer.tokenStream(HighlighterTest.FIELD_NAME, new StringReader(text));\n        if (mode == QUERY) {\n          scorer = new QueryScorer(query);\n        } else if (mode == QUERY_TERM) {\n          scorer = new QueryTermScorer(query);\n        }\n        Highlighter highlighter = new Highlighter(formatter, scorer);\n        highlighter.setTextFragmenter(frag);\n\n        String result = highlighter.getBestFragments(tokenStream, text, maxNumFragmentsRequired,\n            fragmentSeparator);\n        if (HighlighterTest.VERBOSE) System.out.println(\"\\t\" + result);\n      }\n    }\n\n","sourceOld":"    void doStandardHighlights(Analyzer analyzer, IndexSearcher searcher, TopDocs hits, Query query, Formatter formatter, boolean expandMT)\n        throws Exception {\n\n      for (int i = 0; i < hits.totalHits; i++) {\n        String text = searcher.doc(hits.scoreDocs[i].doc).get(HighlighterTest.FIELD_NAME);\n        int maxNumFragmentsRequired = 2;\n        String fragmentSeparator = \"...\";\n        Scorer scorer = null;\n        TokenStream tokenStream = analyzer.reusableTokenStream(HighlighterTest.FIELD_NAME, new StringReader(text));\n        if (mode == QUERY) {\n          scorer = new QueryScorer(query);\n        } else if (mode == QUERY_TERM) {\n          scorer = new QueryTermScorer(query);\n        }\n        Highlighter highlighter = new Highlighter(formatter, scorer);\n        highlighter.setTextFragmenter(frag);\n\n        String result = highlighter.getBestFragments(tokenStream, text, maxNumFragmentsRequired,\n            fragmentSeparator);\n        if (HighlighterTest.VERBOSE) System.out.println(\"\\t\" + result);\n      }\n    }\n\n","bugFix":null,"bugIntro":["c83d6c4335f31cae14f625a222bc842f20073dcd"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"f08557cdb6c60ac7b88a9342c983a20cd236e74f","date":1330954480,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/SynonymTokenizer[HighlighterTest].TestHighlightRunner#doStandardHighlights(Analyzer,IndexSearcher,TopDocs,Query,Formatter,boolean).mjava","pathOld":"lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/SynonymTokenizer[HighlighterTest].TestHighlightRunner#doStandardHighlights(Analyzer,IndexSearcher,TopDocs,Query,Formatter,boolean).mjava","sourceNew":"    void doStandardHighlights(Analyzer analyzer, IndexSearcher searcher, TopDocs hits, Query query, Formatter formatter, boolean expandMT)\n        throws Exception {\n\n      for (int i = 0; i < hits.totalHits; i++) {\n        String text = searcher.doc(hits.scoreDocs[i].doc).get(HighlighterTest.FIELD_NAME);\n        int maxNumFragmentsRequired = 2;\n        String fragmentSeparator = \"...\";\n        Scorer scorer = null;\n        TokenStream tokenStream = analyzer.tokenStream(HighlighterTest.FIELD_NAME, new StringReader(text));\n        if (mode == QUERY) {\n          scorer = new QueryScorer(query);\n        } else if (mode == QUERY_TERM) {\n          scorer = new QueryTermScorer(query);\n        }\n        Highlighter highlighter = new Highlighter(formatter, scorer);\n        highlighter.setTextFragmenter(frag);\n\n        String result = highlighter.getBestFragments(tokenStream, text, maxNumFragmentsRequired,\n            fragmentSeparator);\n        if (LuceneTestCase.VERBOSE) System.out.println(\"\\t\" + result);\n      }\n    }\n\n","sourceOld":"    void doStandardHighlights(Analyzer analyzer, IndexSearcher searcher, TopDocs hits, Query query, Formatter formatter, boolean expandMT)\n        throws Exception {\n\n      for (int i = 0; i < hits.totalHits; i++) {\n        String text = searcher.doc(hits.scoreDocs[i].doc).get(HighlighterTest.FIELD_NAME);\n        int maxNumFragmentsRequired = 2;\n        String fragmentSeparator = \"...\";\n        Scorer scorer = null;\n        TokenStream tokenStream = analyzer.tokenStream(HighlighterTest.FIELD_NAME, new StringReader(text));\n        if (mode == QUERY) {\n          scorer = new QueryScorer(query);\n        } else if (mode == QUERY_TERM) {\n          scorer = new QueryTermScorer(query);\n        }\n        Highlighter highlighter = new Highlighter(formatter, scorer);\n        highlighter.setTextFragmenter(frag);\n\n        String result = highlighter.getBestFragments(tokenStream, text, maxNumFragmentsRequired,\n            fragmentSeparator);\n        if (HighlighterTest.VERBOSE) System.out.println(\"\\t\" + result);\n      }\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab","date":1331075828,"type":3,"author":"Ryan McKinley","isMerge":true,"pathNew":"lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/SynonymTokenizer[HighlighterTest].TestHighlightRunner#doStandardHighlights(Analyzer,IndexSearcher,TopDocs,Query,Formatter,boolean).mjava","pathOld":"lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/SynonymTokenizer[HighlighterTest].TestHighlightRunner#doStandardHighlights(Analyzer,IndexSearcher,TopDocs,Query,Formatter,boolean).mjava","sourceNew":"    void doStandardHighlights(Analyzer analyzer, IndexSearcher searcher, TopDocs hits, Query query, Formatter formatter, boolean expandMT)\n        throws Exception {\n\n      for (int i = 0; i < hits.totalHits; i++) {\n        String text = searcher.doc(hits.scoreDocs[i].doc).get(HighlighterTest.FIELD_NAME);\n        int maxNumFragmentsRequired = 2;\n        String fragmentSeparator = \"...\";\n        Scorer scorer = null;\n        TokenStream tokenStream = analyzer.tokenStream(HighlighterTest.FIELD_NAME, new StringReader(text));\n        if (mode == QUERY) {\n          scorer = new QueryScorer(query);\n        } else if (mode == QUERY_TERM) {\n          scorer = new QueryTermScorer(query);\n        }\n        Highlighter highlighter = new Highlighter(formatter, scorer);\n        highlighter.setTextFragmenter(frag);\n\n        String result = highlighter.getBestFragments(tokenStream, text, maxNumFragmentsRequired,\n            fragmentSeparator);\n        if (LuceneTestCase.VERBOSE) System.out.println(\"\\t\" + result);\n      }\n    }\n\n","sourceOld":"    void doStandardHighlights(Analyzer analyzer, IndexSearcher searcher, TopDocs hits, Query query, Formatter formatter, boolean expandMT)\n        throws Exception {\n\n      for (int i = 0; i < hits.totalHits; i++) {\n        String text = searcher.doc(hits.scoreDocs[i].doc).get(HighlighterTest.FIELD_NAME);\n        int maxNumFragmentsRequired = 2;\n        String fragmentSeparator = \"...\";\n        Scorer scorer = null;\n        TokenStream tokenStream = analyzer.tokenStream(HighlighterTest.FIELD_NAME, new StringReader(text));\n        if (mode == QUERY) {\n          scorer = new QueryScorer(query);\n        } else if (mode == QUERY_TERM) {\n          scorer = new QueryTermScorer(query);\n        }\n        Highlighter highlighter = new Highlighter(formatter, scorer);\n        highlighter.setTextFragmenter(frag);\n\n        String result = highlighter.getBestFragments(tokenStream, text, maxNumFragmentsRequired,\n            fragmentSeparator);\n        if (HighlighterTest.VERBOSE) System.out.println(\"\\t\" + result);\n      }\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b89678825b68eccaf09e6ab71675fc0b0af1e099","date":1334669779,"type":5,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/highlighter/src/test/org/apache/lucene/search/highlight/SynonymTokenizer[HighlighterTest].TestHighlightRunner#doStandardHighlights(Analyzer,IndexSearcher,TopDocs,Query,Formatter,boolean).mjava","pathOld":"lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/SynonymTokenizer[HighlighterTest].TestHighlightRunner#doStandardHighlights(Analyzer,IndexSearcher,TopDocs,Query,Formatter,boolean).mjava","sourceNew":"    void doStandardHighlights(Analyzer analyzer, IndexSearcher searcher, TopDocs hits, Query query, Formatter formatter, boolean expandMT)\n        throws Exception {\n\n      for (int i = 0; i < hits.totalHits; i++) {\n        String text = searcher.doc(hits.scoreDocs[i].doc).get(HighlighterTest.FIELD_NAME);\n        int maxNumFragmentsRequired = 2;\n        String fragmentSeparator = \"...\";\n        Scorer scorer = null;\n        TokenStream tokenStream = analyzer.tokenStream(HighlighterTest.FIELD_NAME, new StringReader(text));\n        if (mode == QUERY) {\n          scorer = new QueryScorer(query);\n        } else if (mode == QUERY_TERM) {\n          scorer = new QueryTermScorer(query);\n        }\n        Highlighter highlighter = new Highlighter(formatter, scorer);\n        highlighter.setTextFragmenter(frag);\n\n        String result = highlighter.getBestFragments(tokenStream, text, maxNumFragmentsRequired,\n            fragmentSeparator);\n        if (LuceneTestCase.VERBOSE) System.out.println(\"\\t\" + result);\n      }\n    }\n\n","sourceOld":"    void doStandardHighlights(Analyzer analyzer, IndexSearcher searcher, TopDocs hits, Query query, Formatter formatter, boolean expandMT)\n        throws Exception {\n\n      for (int i = 0; i < hits.totalHits; i++) {\n        String text = searcher.doc(hits.scoreDocs[i].doc).get(HighlighterTest.FIELD_NAME);\n        int maxNumFragmentsRequired = 2;\n        String fragmentSeparator = \"...\";\n        Scorer scorer = null;\n        TokenStream tokenStream = analyzer.tokenStream(HighlighterTest.FIELD_NAME, new StringReader(text));\n        if (mode == QUERY) {\n          scorer = new QueryScorer(query);\n        } else if (mode == QUERY_TERM) {\n          scorer = new QueryTermScorer(query);\n        }\n        Highlighter highlighter = new Highlighter(formatter, scorer);\n        highlighter.setTextFragmenter(frag);\n\n        String result = highlighter.getBestFragments(tokenStream, text, maxNumFragmentsRequired,\n            fragmentSeparator);\n        if (LuceneTestCase.VERBOSE) System.out.println(\"\\t\" + result);\n      }\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"b89678825b68eccaf09e6ab71675fc0b0af1e099":["f08557cdb6c60ac7b88a9342c983a20cd236e74f"],"9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab":["69e043c521d4e8db770cc140c63f5ef51f03426a","f08557cdb6c60ac7b88a9342c983a20cd236e74f"],"f08557cdb6c60ac7b88a9342c983a20cd236e74f":["69e043c521d4e8db770cc140c63f5ef51f03426a"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"cf7efd82433f3f64684711c16edfd149db6af111":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"69e043c521d4e8db770cc140c63f5ef51f03426a":["cf7efd82433f3f64684711c16edfd149db6af111"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["b89678825b68eccaf09e6ab71675fc0b0af1e099"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"b89678825b68eccaf09e6ab71675fc0b0af1e099":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab":[],"f08557cdb6c60ac7b88a9342c983a20cd236e74f":["b89678825b68eccaf09e6ab71675fc0b0af1e099","9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"cf7efd82433f3f64684711c16edfd149db6af111":["69e043c521d4e8db770cc140c63f5ef51f03426a"],"69e043c521d4e8db770cc140c63f5ef51f03426a":["9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab","f08557cdb6c60ac7b88a9342c983a20cd236e74f"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["cf7efd82433f3f64684711c16edfd149db6af111"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}