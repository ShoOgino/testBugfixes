{"path":"lucene/src/test/org/apache/lucene/index/TestNorms#testCustomEncoder().mjava","commits":[{"id":"fb065b657ee556326e3666d83aae3150249aeaa3","date":1294525860,"type":0,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestNorms#testCustomEncoder().mjava","pathOld":"/dev/null","sourceNew":"  // LUCENE-1260\n  public void testCustomEncoder() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig config = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer());\n    config.setSimilarity(new CustomNormEncodingSimilarity());\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, config);\n    Document doc = new Document();\n    Field foo = newField(\"foo\", \"\", Field.Store.NO, Field.Index.ANALYZED);\n    Field bar = newField(\"bar\", \"\", Field.Store.NO, Field.Index.ANALYZED);\n    doc.add(foo);\n    doc.add(bar);\n    \n    for (int i = 0; i < 100; i++) {\n      bar.setValue(\"singleton\");\n      writer.addDocument(doc);\n    }\n    \n    IndexReader reader = writer.getReader();\n    writer.close();\n    \n    byte fooNorms[] = MultiNorms.norms(reader, \"foo\");\n    for (int i = 0; i < reader.maxDoc(); i++)\n      assertEquals(0, fooNorms[i]);\n    \n    byte barNorms[] = MultiNorms.norms(reader, \"bar\");\n    for (int i = 0; i < reader.maxDoc(); i++)\n      assertEquals(1, barNorms[i]);\n    \n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["a78a90fc9701e511308346ea29f4f5e548bb39fe","d4d69c535930b5cce125cff868d40f6373dc27d4"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"868da859b43505d9d2a023bfeae6dd0c795f5295","date":1294948401,"type":0,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestNorms#testCustomEncoder().mjava","pathOld":"/dev/null","sourceNew":"  // LUCENE-1260\n  public void testCustomEncoder() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig config = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer());\n    config.setSimilarity(new CustomNormEncodingSimilarity());\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, config);\n    Document doc = new Document();\n    Field foo = newField(\"foo\", \"\", Field.Store.NO, Field.Index.ANALYZED);\n    Field bar = newField(\"bar\", \"\", Field.Store.NO, Field.Index.ANALYZED);\n    doc.add(foo);\n    doc.add(bar);\n    \n    for (int i = 0; i < 100; i++) {\n      bar.setValue(\"singleton\");\n      writer.addDocument(doc);\n    }\n    \n    IndexReader reader = writer.getReader();\n    writer.close();\n    \n    byte fooNorms[] = MultiNorms.norms(reader, \"foo\");\n    for (int i = 0; i < reader.maxDoc(); i++)\n      assertEquals(0, fooNorms[i]);\n    \n    byte barNorms[] = MultiNorms.norms(reader, \"bar\");\n    for (int i = 0; i < reader.maxDoc(); i++)\n      assertEquals(1, barNorms[i]);\n    \n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fd9325c7ff9928fabe81c28553b41fc7aa57dfab","date":1295896411,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestNorms#testCustomEncoder().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestNorms#testCustomEncoder().mjava","sourceNew":"  // LUCENE-1260\n  public void testCustomEncoder() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig config = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer());\n    config.setSimilarityProvider(new CustomNormEncodingSimilarity());\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, config);\n    Document doc = new Document();\n    Field foo = newField(\"foo\", \"\", Field.Store.NO, Field.Index.ANALYZED);\n    Field bar = newField(\"bar\", \"\", Field.Store.NO, Field.Index.ANALYZED);\n    doc.add(foo);\n    doc.add(bar);\n    \n    for (int i = 0; i < 100; i++) {\n      bar.setValue(\"singleton\");\n      writer.addDocument(doc);\n    }\n    \n    IndexReader reader = writer.getReader();\n    writer.close();\n    \n    byte fooNorms[] = MultiNorms.norms(reader, \"foo\");\n    for (int i = 0; i < reader.maxDoc(); i++)\n      assertEquals(0, fooNorms[i]);\n    \n    byte barNorms[] = MultiNorms.norms(reader, \"bar\");\n    for (int i = 0; i < reader.maxDoc(); i++)\n      assertEquals(1, barNorms[i]);\n    \n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-1260\n  public void testCustomEncoder() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig config = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer());\n    config.setSimilarity(new CustomNormEncodingSimilarity());\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, config);\n    Document doc = new Document();\n    Field foo = newField(\"foo\", \"\", Field.Store.NO, Field.Index.ANALYZED);\n    Field bar = newField(\"bar\", \"\", Field.Store.NO, Field.Index.ANALYZED);\n    doc.add(foo);\n    doc.add(bar);\n    \n    for (int i = 0; i < 100; i++) {\n      bar.setValue(\"singleton\");\n      writer.addDocument(doc);\n    }\n    \n    IndexReader reader = writer.getReader();\n    writer.close();\n    \n    byte fooNorms[] = MultiNorms.norms(reader, \"foo\");\n    for (int i = 0; i < reader.maxDoc(); i++)\n      assertEquals(0, fooNorms[i]);\n    \n    byte barNorms[] = MultiNorms.norms(reader, \"bar\");\n    for (int i = 0; i < reader.maxDoc(); i++)\n      assertEquals(1, barNorms[i]);\n    \n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"bb9b72f7c3d7827c64dd4ec580ded81778da361d","date":1295897920,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestNorms#testCustomEncoder().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestNorms#testCustomEncoder().mjava","sourceNew":"  // LUCENE-1260\n  public void testCustomEncoder() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig config = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer());\n    config.setSimilarityProvider(new CustomNormEncodingSimilarity());\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, config);\n    Document doc = new Document();\n    Field foo = newField(\"foo\", \"\", Field.Store.NO, Field.Index.ANALYZED);\n    Field bar = newField(\"bar\", \"\", Field.Store.NO, Field.Index.ANALYZED);\n    doc.add(foo);\n    doc.add(bar);\n    \n    for (int i = 0; i < 100; i++) {\n      bar.setValue(\"singleton\");\n      writer.addDocument(doc);\n    }\n    \n    IndexReader reader = writer.getReader();\n    writer.close();\n    \n    byte fooNorms[] = MultiNorms.norms(reader, \"foo\");\n    for (int i = 0; i < reader.maxDoc(); i++)\n      assertEquals(0, fooNorms[i]);\n    \n    byte barNorms[] = MultiNorms.norms(reader, \"bar\");\n    for (int i = 0; i < reader.maxDoc(); i++)\n      assertEquals(1, barNorms[i]);\n    \n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-1260\n  public void testCustomEncoder() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig config = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer());\n    config.setSimilarity(new CustomNormEncodingSimilarity());\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, config);\n    Document doc = new Document();\n    Field foo = newField(\"foo\", \"\", Field.Store.NO, Field.Index.ANALYZED);\n    Field bar = newField(\"bar\", \"\", Field.Store.NO, Field.Index.ANALYZED);\n    doc.add(foo);\n    doc.add(bar);\n    \n    for (int i = 0; i < 100; i++) {\n      bar.setValue(\"singleton\");\n      writer.addDocument(doc);\n    }\n    \n    IndexReader reader = writer.getReader();\n    writer.close();\n    \n    byte fooNorms[] = MultiNorms.norms(reader, \"foo\");\n    for (int i = 0; i < reader.maxDoc(); i++)\n      assertEquals(0, fooNorms[i]);\n    \n    byte barNorms[] = MultiNorms.norms(reader, \"bar\");\n    for (int i = 0; i < reader.maxDoc(); i++)\n      assertEquals(1, barNorms[i]);\n    \n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"29ef99d61cda9641b6250bf9567329a6e65f901d","date":1297244127,"type":0,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestNorms#testCustomEncoder().mjava","pathOld":"/dev/null","sourceNew":"  // LUCENE-1260\n  public void testCustomEncoder() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig config = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer());\n    config.setSimilarityProvider(new CustomNormEncodingSimilarity());\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, config);\n    Document doc = new Document();\n    Field foo = newField(\"foo\", \"\", Field.Store.NO, Field.Index.ANALYZED);\n    Field bar = newField(\"bar\", \"\", Field.Store.NO, Field.Index.ANALYZED);\n    doc.add(foo);\n    doc.add(bar);\n    \n    for (int i = 0; i < 100; i++) {\n      bar.setValue(\"singleton\");\n      writer.addDocument(doc);\n    }\n    \n    IndexReader reader = writer.getReader();\n    writer.close();\n    \n    byte fooNorms[] = MultiNorms.norms(reader, \"foo\");\n    for (int i = 0; i < reader.maxDoc(); i++)\n      assertEquals(0, fooNorms[i]);\n    \n    byte barNorms[] = MultiNorms.norms(reader, \"bar\");\n    for (int i = 0; i < reader.maxDoc(); i++)\n      assertEquals(1, barNorms[i]);\n    \n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"160d004a0e8f5361a446f9d01456aee1c1af20dc","date":1301061642,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestNorms#testCustomEncoder().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestNorms#testCustomEncoder().mjava","sourceNew":"  // LUCENE-1260\n  public void testCustomEncoder() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig config = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer());\n    config.setSimilarityProvider(new DefaultSimilarityProvider() {\n      @Override\n      public Similarity get(String field) {\n        return new CustomNormEncodingSimilarity();\n      }\n    });\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, config);\n    Document doc = new Document();\n    Field foo = newField(\"foo\", \"\", Field.Store.NO, Field.Index.ANALYZED);\n    Field bar = newField(\"bar\", \"\", Field.Store.NO, Field.Index.ANALYZED);\n    doc.add(foo);\n    doc.add(bar);\n    \n    for (int i = 0; i < 100; i++) {\n      bar.setValue(\"singleton\");\n      writer.addDocument(doc);\n    }\n    \n    IndexReader reader = writer.getReader();\n    writer.close();\n    \n    byte fooNorms[] = MultiNorms.norms(reader, \"foo\");\n    for (int i = 0; i < reader.maxDoc(); i++)\n      assertEquals(0, fooNorms[i]);\n    \n    byte barNorms[] = MultiNorms.norms(reader, \"bar\");\n    for (int i = 0; i < reader.maxDoc(); i++)\n      assertEquals(1, barNorms[i]);\n    \n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-1260\n  public void testCustomEncoder() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig config = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer());\n    config.setSimilarityProvider(new CustomNormEncodingSimilarity());\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, config);\n    Document doc = new Document();\n    Field foo = newField(\"foo\", \"\", Field.Store.NO, Field.Index.ANALYZED);\n    Field bar = newField(\"bar\", \"\", Field.Store.NO, Field.Index.ANALYZED);\n    doc.add(foo);\n    doc.add(bar);\n    \n    for (int i = 0; i < 100; i++) {\n      bar.setValue(\"singleton\");\n      writer.addDocument(doc);\n    }\n    \n    IndexReader reader = writer.getReader();\n    writer.close();\n    \n    byte fooNorms[] = MultiNorms.norms(reader, \"foo\");\n    for (int i = 0; i < reader.maxDoc(); i++)\n      assertEquals(0, fooNorms[i]);\n    \n    byte barNorms[] = MultiNorms.norms(reader, \"bar\");\n    for (int i = 0; i < reader.maxDoc(); i++)\n      assertEquals(1, barNorms[i]);\n    \n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d619839baa8ce5503e496b94a9e42ad6f079293f","date":1301309428,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestNorms#testCustomEncoder().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestNorms#testCustomEncoder().mjava","sourceNew":"  // LUCENE-1260\n  public void testCustomEncoder() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig config = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer());\n    config.setSimilarityProvider(new DefaultSimilarityProvider() {\n      @Override\n      public Similarity get(String field) {\n        return new CustomNormEncodingSimilarity();\n      }\n    });\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, config);\n    Document doc = new Document();\n    Field foo = newField(\"foo\", \"\", Field.Store.NO, Field.Index.ANALYZED);\n    Field bar = newField(\"bar\", \"\", Field.Store.NO, Field.Index.ANALYZED);\n    doc.add(foo);\n    doc.add(bar);\n    \n    for (int i = 0; i < 100; i++) {\n      bar.setValue(\"singleton\");\n      writer.addDocument(doc);\n    }\n    \n    IndexReader reader = writer.getReader();\n    writer.close();\n    \n    byte fooNorms[] = MultiNorms.norms(reader, \"foo\");\n    for (int i = 0; i < reader.maxDoc(); i++)\n      assertEquals(0, fooNorms[i]);\n    \n    byte barNorms[] = MultiNorms.norms(reader, \"bar\");\n    for (int i = 0; i < reader.maxDoc(); i++)\n      assertEquals(1, barNorms[i]);\n    \n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-1260\n  public void testCustomEncoder() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig config = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer());\n    config.setSimilarityProvider(new CustomNormEncodingSimilarity());\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, config);\n    Document doc = new Document();\n    Field foo = newField(\"foo\", \"\", Field.Store.NO, Field.Index.ANALYZED);\n    Field bar = newField(\"bar\", \"\", Field.Store.NO, Field.Index.ANALYZED);\n    doc.add(foo);\n    doc.add(bar);\n    \n    for (int i = 0; i < 100; i++) {\n      bar.setValue(\"singleton\");\n      writer.addDocument(doc);\n    }\n    \n    IndexReader reader = writer.getReader();\n    writer.close();\n    \n    byte fooNorms[] = MultiNorms.norms(reader, \"foo\");\n    for (int i = 0; i < reader.maxDoc(); i++)\n      assertEquals(0, fooNorms[i]);\n    \n    byte barNorms[] = MultiNorms.norms(reader, \"bar\");\n    for (int i = 0; i < reader.maxDoc(); i++)\n      assertEquals(1, barNorms[i]);\n    \n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c0ef0193974807e4bddf5432a6b0287fe4d6c9df","date":1301476645,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestNorms#testCustomEncoder().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestNorms#testCustomEncoder().mjava","sourceNew":"  // LUCENE-1260\n  public void testCustomEncoder() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig config = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer());\n    config.setSimilarityProvider(new DefaultSimilarityProvider() {\n      @Override\n      public Similarity get(String field) {\n        return new CustomNormEncodingSimilarity();\n      }\n    });\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, config);\n    Document doc = new Document();\n    Field foo = newField(\"foo\", \"\", Field.Store.NO, Field.Index.ANALYZED);\n    Field bar = newField(\"bar\", \"\", Field.Store.NO, Field.Index.ANALYZED);\n    doc.add(foo);\n    doc.add(bar);\n    \n    for (int i = 0; i < 100; i++) {\n      bar.setValue(\"singleton\");\n      writer.addDocument(doc);\n    }\n    \n    IndexReader reader = writer.getReader();\n    writer.close();\n    \n    byte fooNorms[] = MultiNorms.norms(reader, \"foo\");\n    for (int i = 0; i < reader.maxDoc(); i++)\n      assertEquals(0, fooNorms[i]);\n    \n    byte barNorms[] = MultiNorms.norms(reader, \"bar\");\n    for (int i = 0; i < reader.maxDoc(); i++)\n      assertEquals(1, barNorms[i]);\n    \n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-1260\n  public void testCustomEncoder() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig config = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer());\n    config.setSimilarityProvider(new CustomNormEncodingSimilarity());\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, config);\n    Document doc = new Document();\n    Field foo = newField(\"foo\", \"\", Field.Store.NO, Field.Index.ANALYZED);\n    Field bar = newField(\"bar\", \"\", Field.Store.NO, Field.Index.ANALYZED);\n    doc.add(foo);\n    doc.add(bar);\n    \n    for (int i = 0; i < 100; i++) {\n      bar.setValue(\"singleton\");\n      writer.addDocument(doc);\n    }\n    \n    IndexReader reader = writer.getReader();\n    writer.close();\n    \n    byte fooNorms[] = MultiNorms.norms(reader, \"foo\");\n    for (int i = 0; i < reader.maxDoc(); i++)\n      assertEquals(0, fooNorms[i]);\n    \n    byte barNorms[] = MultiNorms.norms(reader, \"bar\");\n    for (int i = 0; i < reader.maxDoc(); i++)\n      assertEquals(1, barNorms[i]);\n    \n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f2c5f0cb44df114db4228c8f77861714b5cabaea","date":1302542431,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestNorms#testCustomEncoder().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestNorms#testCustomEncoder().mjava","sourceNew":"  // LUCENE-1260\n  public void testCustomEncoder() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig config = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random));\n    config.setSimilarityProvider(new DefaultSimilarityProvider() {\n      @Override\n      public Similarity get(String field) {\n        return new CustomNormEncodingSimilarity();\n      }\n    });\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, config);\n    Document doc = new Document();\n    Field foo = newField(\"foo\", \"\", Field.Store.NO, Field.Index.ANALYZED);\n    Field bar = newField(\"bar\", \"\", Field.Store.NO, Field.Index.ANALYZED);\n    doc.add(foo);\n    doc.add(bar);\n    \n    for (int i = 0; i < 100; i++) {\n      bar.setValue(\"singleton\");\n      writer.addDocument(doc);\n    }\n    \n    IndexReader reader = writer.getReader();\n    writer.close();\n    \n    byte fooNorms[] = MultiNorms.norms(reader, \"foo\");\n    for (int i = 0; i < reader.maxDoc(); i++)\n      assertEquals(0, fooNorms[i]);\n    \n    byte barNorms[] = MultiNorms.norms(reader, \"bar\");\n    for (int i = 0; i < reader.maxDoc(); i++)\n      assertEquals(1, barNorms[i]);\n    \n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-1260\n  public void testCustomEncoder() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig config = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer());\n    config.setSimilarityProvider(new DefaultSimilarityProvider() {\n      @Override\n      public Similarity get(String field) {\n        return new CustomNormEncodingSimilarity();\n      }\n    });\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, config);\n    Document doc = new Document();\n    Field foo = newField(\"foo\", \"\", Field.Store.NO, Field.Index.ANALYZED);\n    Field bar = newField(\"bar\", \"\", Field.Store.NO, Field.Index.ANALYZED);\n    doc.add(foo);\n    doc.add(bar);\n    \n    for (int i = 0; i < 100; i++) {\n      bar.setValue(\"singleton\");\n      writer.addDocument(doc);\n    }\n    \n    IndexReader reader = writer.getReader();\n    writer.close();\n    \n    byte fooNorms[] = MultiNorms.norms(reader, \"foo\");\n    for (int i = 0; i < reader.maxDoc(); i++)\n      assertEquals(0, fooNorms[i]);\n    \n    byte barNorms[] = MultiNorms.norms(reader, \"bar\");\n    for (int i = 0; i < reader.maxDoc(); i++)\n      assertEquals(1, barNorms[i]);\n    \n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"962d04139994fce5193143ef35615499a9a96d78","date":1302693744,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestNorms#testCustomEncoder().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestNorms#testCustomEncoder().mjava","sourceNew":"  // LUCENE-1260\n  public void testCustomEncoder() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig config = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random));\n    config.setSimilarityProvider(new DefaultSimilarityProvider() {\n      @Override\n      public Similarity get(String field) {\n        return new CustomNormEncodingSimilarity();\n      }\n    });\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, config);\n    Document doc = new Document();\n    Field foo = newField(\"foo\", \"\", Field.Store.NO, Field.Index.ANALYZED);\n    Field bar = newField(\"bar\", \"\", Field.Store.NO, Field.Index.ANALYZED);\n    doc.add(foo);\n    doc.add(bar);\n    \n    for (int i = 0; i < 100; i++) {\n      bar.setValue(\"singleton\");\n      writer.addDocument(doc);\n    }\n    \n    IndexReader reader = writer.getReader();\n    writer.close();\n    \n    byte fooNorms[] = MultiNorms.norms(reader, \"foo\");\n    for (int i = 0; i < reader.maxDoc(); i++)\n      assertEquals(0, fooNorms[i]);\n    \n    byte barNorms[] = MultiNorms.norms(reader, \"bar\");\n    for (int i = 0; i < reader.maxDoc(); i++)\n      assertEquals(1, barNorms[i]);\n    \n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-1260\n  public void testCustomEncoder() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig config = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer());\n    config.setSimilarityProvider(new DefaultSimilarityProvider() {\n      @Override\n      public Similarity get(String field) {\n        return new CustomNormEncodingSimilarity();\n      }\n    });\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, config);\n    Document doc = new Document();\n    Field foo = newField(\"foo\", \"\", Field.Store.NO, Field.Index.ANALYZED);\n    Field bar = newField(\"bar\", \"\", Field.Store.NO, Field.Index.ANALYZED);\n    doc.add(foo);\n    doc.add(bar);\n    \n    for (int i = 0; i < 100; i++) {\n      bar.setValue(\"singleton\");\n      writer.addDocument(doc);\n    }\n    \n    IndexReader reader = writer.getReader();\n    writer.close();\n    \n    byte fooNorms[] = MultiNorms.norms(reader, \"foo\");\n    for (int i = 0; i < reader.maxDoc(); i++)\n      assertEquals(0, fooNorms[i]);\n    \n    byte barNorms[] = MultiNorms.norms(reader, \"bar\");\n    for (int i = 0; i < reader.maxDoc(); i++)\n      assertEquals(1, barNorms[i]);\n    \n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"135621f3a0670a9394eb563224a3b76cc4dddc0f","date":1304344257,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestNorms#testCustomEncoder().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestNorms#testCustomEncoder().mjava","sourceNew":"  // LUCENE-1260\n  public void testCustomEncoder() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig config = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random));\n    config.setSimilarityProvider(new DefaultSimilarityProvider() {\n      @Override\n      public Similarity get(String field) {\n        return new CustomNormEncodingSimilarity();\n      }\n    });\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, config);\n    Document doc = new Document();\n    Field foo = newField(\"foo\", \"\", Field.Store.NO, Field.Index.ANALYZED);\n    Field bar = newField(\"bar\", \"\", Field.Store.NO, Field.Index.ANALYZED);\n    doc.add(foo);\n    doc.add(bar);\n    \n    for (int i = 0; i < 100; i++) {\n      bar.setValue(\"singleton\");\n      writer.addDocument(doc);\n    }\n    \n    IndexReader reader = writer.getReader();\n    writer.close();\n    \n    byte fooNorms[] = MultiNorms.norms(reader, \"foo\");\n    for (int i = 0; i < reader.maxDoc(); i++)\n      assertEquals(0, fooNorms[i]);\n    \n    byte barNorms[] = MultiNorms.norms(reader, \"bar\");\n    for (int i = 0; i < reader.maxDoc(); i++)\n      assertEquals(1, barNorms[i]);\n    \n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-1260\n  public void testCustomEncoder() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig config = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer());\n    config.setSimilarityProvider(new DefaultSimilarityProvider() {\n      @Override\n      public Similarity get(String field) {\n        return new CustomNormEncodingSimilarity();\n      }\n    });\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, config);\n    Document doc = new Document();\n    Field foo = newField(\"foo\", \"\", Field.Store.NO, Field.Index.ANALYZED);\n    Field bar = newField(\"bar\", \"\", Field.Store.NO, Field.Index.ANALYZED);\n    doc.add(foo);\n    doc.add(bar);\n    \n    for (int i = 0; i < 100; i++) {\n      bar.setValue(\"singleton\");\n      writer.addDocument(doc);\n    }\n    \n    IndexReader reader = writer.getReader();\n    writer.close();\n    \n    byte fooNorms[] = MultiNorms.norms(reader, \"foo\");\n    for (int i = 0; i < reader.maxDoc(); i++)\n      assertEquals(0, fooNorms[i]);\n    \n    byte barNorms[] = MultiNorms.norms(reader, \"bar\");\n    for (int i = 0; i < reader.maxDoc(); i++)\n      assertEquals(1, barNorms[i]);\n    \n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a3776dccca01c11e7046323cfad46a3b4a471233","date":1306100719,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestNorms#testCustomEncoder().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestNorms#testCustomEncoder().mjava","sourceNew":"  // LUCENE-1260\n  public void testCustomEncoder() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig config = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random));\n    config.setSimilarityProvider(new DefaultSimilarityProvider() {\n      @Override\n      public Similarity get(String field) {\n        return new CustomNormEncodingSimilarity();\n      }\n    });\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, config);\n    Document doc = new Document();\n    Field foo = newField(\"foo\", \"\", Field.Store.NO, Field.Index.ANALYZED);\n    Field bar = newField(\"bar\", \"\", Field.Store.NO, Field.Index.ANALYZED);\n    doc.add(foo);\n    doc.add(bar);\n    \n    for (int i = 0; i < 100; i++) {\n      bar.setValue(\"singleton\");\n      writer.addDocument(doc);\n    }\n    \n    IndexReader reader = writer.getReader();\n    writer.close();\n    \n    byte fooNorms[] = MultiNorms.norms(reader, \"foo\");\n    for (int i = 0; i < reader.maxDoc(); i++)\n      assertEquals(0, fooNorms[i]);\n    \n    byte barNorms[] = MultiNorms.norms(reader, \"bar\");\n    for (int i = 0; i < reader.maxDoc(); i++)\n      assertEquals(1, barNorms[i]);\n    \n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-1260\n  public void testCustomEncoder() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig config = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer());\n    config.setSimilarityProvider(new DefaultSimilarityProvider() {\n      @Override\n      public Similarity get(String field) {\n        return new CustomNormEncodingSimilarity();\n      }\n    });\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, config);\n    Document doc = new Document();\n    Field foo = newField(\"foo\", \"\", Field.Store.NO, Field.Index.ANALYZED);\n    Field bar = newField(\"bar\", \"\", Field.Store.NO, Field.Index.ANALYZED);\n    doc.add(foo);\n    doc.add(bar);\n    \n    for (int i = 0; i < 100; i++) {\n      bar.setValue(\"singleton\");\n      writer.addDocument(doc);\n    }\n    \n    IndexReader reader = writer.getReader();\n    writer.close();\n    \n    byte fooNorms[] = MultiNorms.norms(reader, \"foo\");\n    for (int i = 0; i < reader.maxDoc(); i++)\n      assertEquals(0, fooNorms[i]);\n    \n    byte barNorms[] = MultiNorms.norms(reader, \"bar\");\n    for (int i = 0; i < reader.maxDoc(); i++)\n      assertEquals(1, barNorms[i]);\n    \n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1509f151d7692d84fae414b2b799ac06ba60fcb4","date":1314451621,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestNorms#testCustomEncoder().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestNorms#testCustomEncoder().mjava","sourceNew":"  // LUCENE-1260\n  public void testCustomEncoder() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig config = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random));\n    config.setSimilarityProvider(new DefaultSimilarityProvider() {\n      @Override\n      public Similarity get(String field) {\n        return new CustomNormEncodingSimilarity();\n      }\n    });\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, config);\n    Document doc = new Document();\n    Field foo = newField(\"foo\", \"\", TextField.TYPE_UNSTORED);\n    Field bar = newField(\"bar\", \"\", TextField.TYPE_UNSTORED);\n    doc.add(foo);\n    doc.add(bar);\n    \n    for (int i = 0; i < 100; i++) {\n      bar.setValue(\"singleton\");\n      writer.addDocument(doc);\n    }\n    \n    IndexReader reader = writer.getReader();\n    writer.close();\n    \n    byte fooNorms[] = MultiNorms.norms(reader, \"foo\");\n    for (int i = 0; i < reader.maxDoc(); i++)\n      assertEquals(0, fooNorms[i]);\n    \n    byte barNorms[] = MultiNorms.norms(reader, \"bar\");\n    for (int i = 0; i < reader.maxDoc(); i++)\n      assertEquals(1, barNorms[i]);\n    \n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-1260\n  public void testCustomEncoder() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig config = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random));\n    config.setSimilarityProvider(new DefaultSimilarityProvider() {\n      @Override\n      public Similarity get(String field) {\n        return new CustomNormEncodingSimilarity();\n      }\n    });\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, config);\n    Document doc = new Document();\n    Field foo = newField(\"foo\", \"\", Field.Store.NO, Field.Index.ANALYZED);\n    Field bar = newField(\"bar\", \"\", Field.Store.NO, Field.Index.ANALYZED);\n    doc.add(foo);\n    doc.add(bar);\n    \n    for (int i = 0; i < 100; i++) {\n      bar.setValue(\"singleton\");\n      writer.addDocument(doc);\n    }\n    \n    IndexReader reader = writer.getReader();\n    writer.close();\n    \n    byte fooNorms[] = MultiNorms.norms(reader, \"foo\");\n    for (int i = 0; i < reader.maxDoc(); i++)\n      assertEquals(0, fooNorms[i]);\n    \n    byte barNorms[] = MultiNorms.norms(reader, \"bar\");\n    for (int i = 0; i < reader.maxDoc(); i++)\n      assertEquals(1, barNorms[i]);\n    \n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":["04f07771a2a7dd3a395700665ed839c3dae2def2"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"0f4b223b56d0c7927ae8baced5e1b1dd4c693b1d","date":1325789720,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestNorms#testCustomEncoder().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestNorms#testCustomEncoder().mjava","sourceNew":"  // LUCENE-1260\n  public void testCustomEncoder() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig config = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random));\n    config.setSimilarityProvider(new DefaultSimilarityProvider() {\n      @Override\n      public Similarity get(String field) {\n        return new CustomNormEncodingSimilarity();\n      }\n    });\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, config);\n    Document doc = new Document();\n    Field foo = newField(\"foo\", \"\", TextField.TYPE_UNSTORED);\n    Field bar = newField(\"bar\", \"\", TextField.TYPE_UNSTORED);\n    doc.add(foo);\n    doc.add(bar);\n    \n    for (int i = 0; i < 100; i++) {\n      bar.setValue(\"singleton\");\n      writer.addDocument(doc);\n    }\n    \n    IndexReader reader = writer.getReader();\n    writer.close();\n    \n    byte fooNorms[] = (byte[]) MultiDocValues.getNormDocValues(reader, \"foo\").getSource().getArray();\n    for (int i = 0; i < reader.maxDoc(); i++)\n      assertEquals(0, fooNorms[i]);\n    \n    byte barNorms[] = (byte[]) MultiDocValues.getNormDocValues(reader, \"bar\").getSource().getArray();\n    for (int i = 0; i < reader.maxDoc(); i++)\n      assertEquals(1, barNorms[i]);\n    \n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-1260\n  public void testCustomEncoder() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig config = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random));\n    config.setSimilarityProvider(new DefaultSimilarityProvider() {\n      @Override\n      public Similarity get(String field) {\n        return new CustomNormEncodingSimilarity();\n      }\n    });\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, config);\n    Document doc = new Document();\n    Field foo = newField(\"foo\", \"\", TextField.TYPE_UNSTORED);\n    Field bar = newField(\"bar\", \"\", TextField.TYPE_UNSTORED);\n    doc.add(foo);\n    doc.add(bar);\n    \n    for (int i = 0; i < 100; i++) {\n      bar.setValue(\"singleton\");\n      writer.addDocument(doc);\n    }\n    \n    IndexReader reader = writer.getReader();\n    writer.close();\n    \n    byte fooNorms[] = MultiNorms.norms(reader, \"foo\");\n    for (int i = 0; i < reader.maxDoc(); i++)\n      assertEquals(0, fooNorms[i]);\n    \n    byte barNorms[] = MultiNorms.norms(reader, \"bar\");\n    for (int i = 0; i < reader.maxDoc(); i++)\n      assertEquals(1, barNorms[i]);\n    \n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":["d4d69c535930b5cce125cff868d40f6373dc27d4"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"1ab42b0756bdd98ac6a6767b5a77d10d9ba12b4b","date":1328532481,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestNorms#testCustomEncoder().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestNorms#testCustomEncoder().mjava","sourceNew":"  // LUCENE-1260\n  public void testCustomEncoder() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig config = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random));\n    config.setSimilarity(new CustomNormEncodingSimilarity());\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, config);\n    Document doc = new Document();\n    Field foo = newField(\"foo\", \"\", TextField.TYPE_UNSTORED);\n    Field bar = newField(\"bar\", \"\", TextField.TYPE_UNSTORED);\n    doc.add(foo);\n    doc.add(bar);\n    \n    for (int i = 0; i < 100; i++) {\n      bar.setValue(\"singleton\");\n      writer.addDocument(doc);\n    }\n    \n    IndexReader reader = writer.getReader();\n    writer.close();\n    \n    byte fooNorms[] = (byte[]) MultiDocValues.getNormDocValues(reader, \"foo\").getSource().getArray();\n    for (int i = 0; i < reader.maxDoc(); i++)\n      assertEquals(0, fooNorms[i]);\n    \n    byte barNorms[] = (byte[]) MultiDocValues.getNormDocValues(reader, \"bar\").getSource().getArray();\n    for (int i = 0; i < reader.maxDoc(); i++)\n      assertEquals(1, barNorms[i]);\n    \n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-1260\n  public void testCustomEncoder() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig config = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random));\n    config.setSimilarityProvider(new DefaultSimilarityProvider() {\n      @Override\n      public Similarity get(String field) {\n        return new CustomNormEncodingSimilarity();\n      }\n    });\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, config);\n    Document doc = new Document();\n    Field foo = newField(\"foo\", \"\", TextField.TYPE_UNSTORED);\n    Field bar = newField(\"bar\", \"\", TextField.TYPE_UNSTORED);\n    doc.add(foo);\n    doc.add(bar);\n    \n    for (int i = 0; i < 100; i++) {\n      bar.setValue(\"singleton\");\n      writer.addDocument(doc);\n    }\n    \n    IndexReader reader = writer.getReader();\n    writer.close();\n    \n    byte fooNorms[] = (byte[]) MultiDocValues.getNormDocValues(reader, \"foo\").getSource().getArray();\n    for (int i = 0; i < reader.maxDoc(); i++)\n      assertEquals(0, fooNorms[i]);\n    \n    byte barNorms[] = (byte[]) MultiDocValues.getNormDocValues(reader, \"bar\").getSource().getArray();\n    for (int i = 0; i < reader.maxDoc(); i++)\n      assertEquals(1, barNorms[i]);\n    \n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":5,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestNorms#testCustomEncoder().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestNorms#testCustomEncoder().mjava","sourceNew":"  // LUCENE-1260\n  public void testCustomEncoder() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig config = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random));\n    config.setSimilarity(new CustomNormEncodingSimilarity());\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, config);\n    Document doc = new Document();\n    Field foo = newField(\"foo\", \"\", TextField.TYPE_UNSTORED);\n    Field bar = newField(\"bar\", \"\", TextField.TYPE_UNSTORED);\n    doc.add(foo);\n    doc.add(bar);\n    \n    for (int i = 0; i < 100; i++) {\n      bar.setValue(\"singleton\");\n      writer.addDocument(doc);\n    }\n    \n    IndexReader reader = writer.getReader();\n    writer.close();\n    \n    byte fooNorms[] = (byte[]) MultiDocValues.getNormDocValues(reader, \"foo\").getSource().getArray();\n    for (int i = 0; i < reader.maxDoc(); i++)\n      assertEquals(0, fooNorms[i]);\n    \n    byte barNorms[] = (byte[]) MultiDocValues.getNormDocValues(reader, \"bar\").getSource().getArray();\n    for (int i = 0; i < reader.maxDoc(); i++)\n      assertEquals(1, barNorms[i]);\n    \n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-1260\n  public void testCustomEncoder() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig config = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random));\n    config.setSimilarity(new CustomNormEncodingSimilarity());\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, config);\n    Document doc = new Document();\n    Field foo = newField(\"foo\", \"\", TextField.TYPE_UNSTORED);\n    Field bar = newField(\"bar\", \"\", TextField.TYPE_UNSTORED);\n    doc.add(foo);\n    doc.add(bar);\n    \n    for (int i = 0; i < 100; i++) {\n      bar.setValue(\"singleton\");\n      writer.addDocument(doc);\n    }\n    \n    IndexReader reader = writer.getReader();\n    writer.close();\n    \n    byte fooNorms[] = (byte[]) MultiDocValues.getNormDocValues(reader, \"foo\").getSource().getArray();\n    for (int i = 0; i < reader.maxDoc(); i++)\n      assertEquals(0, fooNorms[i]);\n    \n    byte barNorms[] = (byte[]) MultiDocValues.getNormDocValues(reader, \"bar\").getSource().getArray();\n    for (int i = 0; i < reader.maxDoc(); i++)\n      assertEquals(1, barNorms[i]);\n    \n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["1ab42b0756bdd98ac6a6767b5a77d10d9ba12b4b"],"135621f3a0670a9394eb563224a3b76cc4dddc0f":["d619839baa8ce5503e496b94a9e42ad6f079293f","f2c5f0cb44df114db4228c8f77861714b5cabaea"],"1ab42b0756bdd98ac6a6767b5a77d10d9ba12b4b":["0f4b223b56d0c7927ae8baced5e1b1dd4c693b1d"],"962d04139994fce5193143ef35615499a9a96d78":["c0ef0193974807e4bddf5432a6b0287fe4d6c9df","f2c5f0cb44df114db4228c8f77861714b5cabaea"],"bb9b72f7c3d7827c64dd4ec580ded81778da361d":["868da859b43505d9d2a023bfeae6dd0c795f5295","fd9325c7ff9928fabe81c28553b41fc7aa57dfab"],"fd9325c7ff9928fabe81c28553b41fc7aa57dfab":["fb065b657ee556326e3666d83aae3150249aeaa3"],"0f4b223b56d0c7927ae8baced5e1b1dd4c693b1d":["1509f151d7692d84fae414b2b799ac06ba60fcb4"],"fb065b657ee556326e3666d83aae3150249aeaa3":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"c0ef0193974807e4bddf5432a6b0287fe4d6c9df":["bb9b72f7c3d7827c64dd4ec580ded81778da361d","160d004a0e8f5361a446f9d01456aee1c1af20dc"],"f2c5f0cb44df114db4228c8f77861714b5cabaea":["160d004a0e8f5361a446f9d01456aee1c1af20dc"],"160d004a0e8f5361a446f9d01456aee1c1af20dc":["fd9325c7ff9928fabe81c28553b41fc7aa57dfab"],"d619839baa8ce5503e496b94a9e42ad6f079293f":["29ef99d61cda9641b6250bf9567329a6e65f901d","160d004a0e8f5361a446f9d01456aee1c1af20dc"],"a3776dccca01c11e7046323cfad46a3b4a471233":["160d004a0e8f5361a446f9d01456aee1c1af20dc","f2c5f0cb44df114db4228c8f77861714b5cabaea"],"29ef99d61cda9641b6250bf9567329a6e65f901d":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","fd9325c7ff9928fabe81c28553b41fc7aa57dfab"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"1509f151d7692d84fae414b2b799ac06ba60fcb4":["f2c5f0cb44df114db4228c8f77861714b5cabaea"],"868da859b43505d9d2a023bfeae6dd0c795f5295":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","fb065b657ee556326e3666d83aae3150249aeaa3"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"]},"commit2Childs":{"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"135621f3a0670a9394eb563224a3b76cc4dddc0f":[],"1ab42b0756bdd98ac6a6767b5a77d10d9ba12b4b":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"962d04139994fce5193143ef35615499a9a96d78":[],"bb9b72f7c3d7827c64dd4ec580ded81778da361d":["c0ef0193974807e4bddf5432a6b0287fe4d6c9df"],"fd9325c7ff9928fabe81c28553b41fc7aa57dfab":["bb9b72f7c3d7827c64dd4ec580ded81778da361d","160d004a0e8f5361a446f9d01456aee1c1af20dc","29ef99d61cda9641b6250bf9567329a6e65f901d"],"0f4b223b56d0c7927ae8baced5e1b1dd4c693b1d":["1ab42b0756bdd98ac6a6767b5a77d10d9ba12b4b"],"fb065b657ee556326e3666d83aae3150249aeaa3":["fd9325c7ff9928fabe81c28553b41fc7aa57dfab","868da859b43505d9d2a023bfeae6dd0c795f5295"],"c0ef0193974807e4bddf5432a6b0287fe4d6c9df":["962d04139994fce5193143ef35615499a9a96d78"],"f2c5f0cb44df114db4228c8f77861714b5cabaea":["135621f3a0670a9394eb563224a3b76cc4dddc0f","962d04139994fce5193143ef35615499a9a96d78","a3776dccca01c11e7046323cfad46a3b4a471233","1509f151d7692d84fae414b2b799ac06ba60fcb4"],"160d004a0e8f5361a446f9d01456aee1c1af20dc":["c0ef0193974807e4bddf5432a6b0287fe4d6c9df","f2c5f0cb44df114db4228c8f77861714b5cabaea","d619839baa8ce5503e496b94a9e42ad6f079293f","a3776dccca01c11e7046323cfad46a3b4a471233"],"d619839baa8ce5503e496b94a9e42ad6f079293f":["135621f3a0670a9394eb563224a3b76cc4dddc0f"],"29ef99d61cda9641b6250bf9567329a6e65f901d":["d619839baa8ce5503e496b94a9e42ad6f079293f"],"a3776dccca01c11e7046323cfad46a3b4a471233":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["fb065b657ee556326e3666d83aae3150249aeaa3","29ef99d61cda9641b6250bf9567329a6e65f901d","868da859b43505d9d2a023bfeae6dd0c795f5295"],"1509f151d7692d84fae414b2b799ac06ba60fcb4":["0f4b223b56d0c7927ae8baced5e1b1dd4c693b1d"],"868da859b43505d9d2a023bfeae6dd0c795f5295":["bb9b72f7c3d7827c64dd4ec580ded81778da361d"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["135621f3a0670a9394eb563224a3b76cc4dddc0f","962d04139994fce5193143ef35615499a9a96d78","a3776dccca01c11e7046323cfad46a3b4a471233","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}