{"path":"lucene/core/src/test/org/apache/lucene/index/TestDocumentsWriterDeleteQueue#testUpdateDelteSlices().mjava","commits":[{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":1,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDocumentsWriterDeleteQueue#testUpdateDelteSlices().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestDocumentsWriterDeleteQueue#testUpdateDelteSlices().mjava","sourceNew":"  public void testUpdateDelteSlices() {\n    DocumentsWriterDeleteQueue queue = new DocumentsWriterDeleteQueue();\n    final int size = 200 + random.nextInt(500) * RANDOM_MULTIPLIER;\n    Integer[] ids = new Integer[size];\n    for (int i = 0; i < ids.length; i++) {\n      ids[i] = random.nextInt();\n    }\n    DeleteSlice slice1 = queue.newSlice();\n    DeleteSlice slice2 = queue.newSlice();\n    BufferedDeletes bd1 = new BufferedDeletes();\n    BufferedDeletes bd2 = new BufferedDeletes();\n    int last1 = 0;\n    int last2 = 0;\n    Set<Term> uniqueValues = new HashSet<Term>();\n    for (int j = 0; j < ids.length; j++) {\n      Integer i = ids[j];\n      // create an array here since we compare identity below against tailItem\n      Term[] term = new Term[] {new Term(\"id\", i.toString())};\n      uniqueValues.add(term[0]);\n      queue.addDelete(term);\n      if (random.nextInt(20) == 0 || j == ids.length - 1) {\n        queue.updateSlice(slice1);\n        assertTrue(slice1.isTailItem(term));\n        slice1.apply(bd1, j);\n        assertAllBetween(last1, j, bd1, ids);\n        last1 = j + 1;\n      }\n      if (random.nextInt(10) == 5 || j == ids.length - 1) {\n        queue.updateSlice(slice2);\n        assertTrue(slice2.isTailItem(term));\n        slice2.apply(bd2, j);\n        assertAllBetween(last2, j, bd2, ids);\n        last2 = j + 1;\n      }\n      assertEquals(uniqueValues.size(), queue.numGlobalTermDeletes());\n    }\n    assertEquals(uniqueValues, bd1.terms.keySet());\n    assertEquals(uniqueValues, bd2.terms.keySet());\n    HashSet<Term> frozenSet = new HashSet<Term>();\n    for (Term t : queue.freezeGlobalBuffer(null).termsIterable()) {\n      BytesRef bytesRef = new BytesRef();\n      bytesRef.copyBytes(t.bytes);\n      frozenSet.add(new Term(t.field, bytesRef));\n    }\n    assertEquals(uniqueValues, frozenSet);\n    assertEquals(\"num deletes must be 0 after freeze\", 0, queue\n        .numGlobalTermDeletes());\n  }\n\n","sourceOld":"  public void testUpdateDelteSlices() {\n    DocumentsWriterDeleteQueue queue = new DocumentsWriterDeleteQueue();\n    final int size = 200 + random.nextInt(500) * RANDOM_MULTIPLIER;\n    Integer[] ids = new Integer[size];\n    for (int i = 0; i < ids.length; i++) {\n      ids[i] = random.nextInt();\n    }\n    DeleteSlice slice1 = queue.newSlice();\n    DeleteSlice slice2 = queue.newSlice();\n    BufferedDeletes bd1 = new BufferedDeletes();\n    BufferedDeletes bd2 = new BufferedDeletes();\n    int last1 = 0;\n    int last2 = 0;\n    Set<Term> uniqueValues = new HashSet<Term>();\n    for (int j = 0; j < ids.length; j++) {\n      Integer i = ids[j];\n      // create an array here since we compare identity below against tailItem\n      Term[] term = new Term[] {new Term(\"id\", i.toString())};\n      uniqueValues.add(term[0]);\n      queue.addDelete(term);\n      if (random.nextInt(20) == 0 || j == ids.length - 1) {\n        queue.updateSlice(slice1);\n        assertTrue(slice1.isTailItem(term));\n        slice1.apply(bd1, j);\n        assertAllBetween(last1, j, bd1, ids);\n        last1 = j + 1;\n      }\n      if (random.nextInt(10) == 5 || j == ids.length - 1) {\n        queue.updateSlice(slice2);\n        assertTrue(slice2.isTailItem(term));\n        slice2.apply(bd2, j);\n        assertAllBetween(last2, j, bd2, ids);\n        last2 = j + 1;\n      }\n      assertEquals(uniqueValues.size(), queue.numGlobalTermDeletes());\n    }\n    assertEquals(uniqueValues, bd1.terms.keySet());\n    assertEquals(uniqueValues, bd2.terms.keySet());\n    HashSet<Term> frozenSet = new HashSet<Term>();\n    for (Term t : queue.freezeGlobalBuffer(null).termsIterable()) {\n      BytesRef bytesRef = new BytesRef();\n      bytesRef.copyBytes(t.bytes);\n      frozenSet.add(new Term(t.field, bytesRef));\n    }\n    assertEquals(uniqueValues, frozenSet);\n    assertEquals(\"num deletes must be 0 after freeze\", 0, queue\n        .numGlobalTermDeletes());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"629c38c4ae4e303d0617e05fbfe508140b32f0a3","date":1334500904,"type":3,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDocumentsWriterDeleteQueue#testUpdateDelteSlices().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDocumentsWriterDeleteQueue#testUpdateDelteSlices().mjava","sourceNew":"  public void testUpdateDelteSlices() {\n    DocumentsWriterDeleteQueue queue = new DocumentsWriterDeleteQueue();\n    final int size = 200 + random().nextInt(500) * RANDOM_MULTIPLIER;\n    Integer[] ids = new Integer[size];\n    for (int i = 0; i < ids.length; i++) {\n      ids[i] = random().nextInt();\n    }\n    DeleteSlice slice1 = queue.newSlice();\n    DeleteSlice slice2 = queue.newSlice();\n    BufferedDeletes bd1 = new BufferedDeletes();\n    BufferedDeletes bd2 = new BufferedDeletes();\n    int last1 = 0;\n    int last2 = 0;\n    Set<Term> uniqueValues = new HashSet<Term>();\n    for (int j = 0; j < ids.length; j++) {\n      Integer i = ids[j];\n      // create an array here since we compare identity below against tailItem\n      Term[] term = new Term[] {new Term(\"id\", i.toString())};\n      uniqueValues.add(term[0]);\n      queue.addDelete(term);\n      if (random().nextInt(20) == 0 || j == ids.length - 1) {\n        queue.updateSlice(slice1);\n        assertTrue(slice1.isTailItem(term));\n        slice1.apply(bd1, j);\n        assertAllBetween(last1, j, bd1, ids);\n        last1 = j + 1;\n      }\n      if (random().nextInt(10) == 5 || j == ids.length - 1) {\n        queue.updateSlice(slice2);\n        assertTrue(slice2.isTailItem(term));\n        slice2.apply(bd2, j);\n        assertAllBetween(last2, j, bd2, ids);\n        last2 = j + 1;\n      }\n      assertEquals(uniqueValues.size(), queue.numGlobalTermDeletes());\n    }\n    assertEquals(uniqueValues, bd1.terms.keySet());\n    assertEquals(uniqueValues, bd2.terms.keySet());\n    HashSet<Term> frozenSet = new HashSet<Term>();\n    for (Term t : queue.freezeGlobalBuffer(null).termsIterable()) {\n      BytesRef bytesRef = new BytesRef();\n      bytesRef.copyBytes(t.bytes);\n      frozenSet.add(new Term(t.field, bytesRef));\n    }\n    assertEquals(uniqueValues, frozenSet);\n    assertEquals(\"num deletes must be 0 after freeze\", 0, queue\n        .numGlobalTermDeletes());\n  }\n\n","sourceOld":"  public void testUpdateDelteSlices() {\n    DocumentsWriterDeleteQueue queue = new DocumentsWriterDeleteQueue();\n    final int size = 200 + random.nextInt(500) * RANDOM_MULTIPLIER;\n    Integer[] ids = new Integer[size];\n    for (int i = 0; i < ids.length; i++) {\n      ids[i] = random.nextInt();\n    }\n    DeleteSlice slice1 = queue.newSlice();\n    DeleteSlice slice2 = queue.newSlice();\n    BufferedDeletes bd1 = new BufferedDeletes();\n    BufferedDeletes bd2 = new BufferedDeletes();\n    int last1 = 0;\n    int last2 = 0;\n    Set<Term> uniqueValues = new HashSet<Term>();\n    for (int j = 0; j < ids.length; j++) {\n      Integer i = ids[j];\n      // create an array here since we compare identity below against tailItem\n      Term[] term = new Term[] {new Term(\"id\", i.toString())};\n      uniqueValues.add(term[0]);\n      queue.addDelete(term);\n      if (random.nextInt(20) == 0 || j == ids.length - 1) {\n        queue.updateSlice(slice1);\n        assertTrue(slice1.isTailItem(term));\n        slice1.apply(bd1, j);\n        assertAllBetween(last1, j, bd1, ids);\n        last1 = j + 1;\n      }\n      if (random.nextInt(10) == 5 || j == ids.length - 1) {\n        queue.updateSlice(slice2);\n        assertTrue(slice2.isTailItem(term));\n        slice2.apply(bd2, j);\n        assertAllBetween(last2, j, bd2, ids);\n        last2 = j + 1;\n      }\n      assertEquals(uniqueValues.size(), queue.numGlobalTermDeletes());\n    }\n    assertEquals(uniqueValues, bd1.terms.keySet());\n    assertEquals(uniqueValues, bd2.terms.keySet());\n    HashSet<Term> frozenSet = new HashSet<Term>();\n    for (Term t : queue.freezeGlobalBuffer(null).termsIterable()) {\n      BytesRef bytesRef = new BytesRef();\n      bytesRef.copyBytes(t.bytes);\n      frozenSet.add(new Term(t.field, bytesRef));\n    }\n    assertEquals(uniqueValues, frozenSet);\n    assertEquals(\"num deletes must be 0 after freeze\", 0, queue\n        .numGlobalTermDeletes());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"50301463ed2a4d5eeea61244ab806b2064df022e","date":1337279595,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDocumentsWriterDeleteQueue#testUpdateDelteSlices().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDocumentsWriterDeleteQueue#testUpdateDelteSlices().mjava","sourceNew":"  public void testUpdateDelteSlices() {\n    DocumentsWriterDeleteQueue queue = new DocumentsWriterDeleteQueue();\n    final int size = 200 + random().nextInt(500) * RANDOM_MULTIPLIER;\n    Integer[] ids = new Integer[size];\n    for (int i = 0; i < ids.length; i++) {\n      ids[i] = random().nextInt();\n    }\n    DeleteSlice slice1 = queue.newSlice();\n    DeleteSlice slice2 = queue.newSlice();\n    BufferedDeletes bd1 = new BufferedDeletes();\n    BufferedDeletes bd2 = new BufferedDeletes();\n    int last1 = 0;\n    int last2 = 0;\n    Set<Term> uniqueValues = new HashSet<Term>();\n    for (int j = 0; j < ids.length; j++) {\n      Integer i = ids[j];\n      // create an array here since we compare identity below against tailItem\n      Term[] term = new Term[] {new Term(\"id\", i.toString())};\n      uniqueValues.add(term[0]);\n      queue.addDelete(term);\n      if (random().nextInt(20) == 0 || j == ids.length - 1) {\n        queue.updateSlice(slice1);\n        assertTrue(slice1.isTailItem(term));\n        slice1.apply(bd1, j);\n        assertAllBetween(last1, j, bd1, ids);\n        last1 = j + 1;\n      }\n      if (random().nextInt(10) == 5 || j == ids.length - 1) {\n        queue.updateSlice(slice2);\n        assertTrue(slice2.isTailItem(term));\n        slice2.apply(bd2, j);\n        assertAllBetween(last2, j, bd2, ids);\n        last2 = j + 1;\n      }\n      assertEquals(j+1, queue.numGlobalTermDeletes());\n    }\n    assertEquals(uniqueValues, bd1.terms.keySet());\n    assertEquals(uniqueValues, bd2.terms.keySet());\n    HashSet<Term> frozenSet = new HashSet<Term>();\n    for (Term t : queue.freezeGlobalBuffer(null).termsIterable()) {\n      BytesRef bytesRef = new BytesRef();\n      bytesRef.copyBytes(t.bytes);\n      frozenSet.add(new Term(t.field, bytesRef));\n    }\n    assertEquals(uniqueValues, frozenSet);\n    assertEquals(\"num deletes must be 0 after freeze\", 0, queue\n        .numGlobalTermDeletes());\n  }\n\n","sourceOld":"  public void testUpdateDelteSlices() {\n    DocumentsWriterDeleteQueue queue = new DocumentsWriterDeleteQueue();\n    final int size = 200 + random().nextInt(500) * RANDOM_MULTIPLIER;\n    Integer[] ids = new Integer[size];\n    for (int i = 0; i < ids.length; i++) {\n      ids[i] = random().nextInt();\n    }\n    DeleteSlice slice1 = queue.newSlice();\n    DeleteSlice slice2 = queue.newSlice();\n    BufferedDeletes bd1 = new BufferedDeletes();\n    BufferedDeletes bd2 = new BufferedDeletes();\n    int last1 = 0;\n    int last2 = 0;\n    Set<Term> uniqueValues = new HashSet<Term>();\n    for (int j = 0; j < ids.length; j++) {\n      Integer i = ids[j];\n      // create an array here since we compare identity below against tailItem\n      Term[] term = new Term[] {new Term(\"id\", i.toString())};\n      uniqueValues.add(term[0]);\n      queue.addDelete(term);\n      if (random().nextInt(20) == 0 || j == ids.length - 1) {\n        queue.updateSlice(slice1);\n        assertTrue(slice1.isTailItem(term));\n        slice1.apply(bd1, j);\n        assertAllBetween(last1, j, bd1, ids);\n        last1 = j + 1;\n      }\n      if (random().nextInt(10) == 5 || j == ids.length - 1) {\n        queue.updateSlice(slice2);\n        assertTrue(slice2.isTailItem(term));\n        slice2.apply(bd2, j);\n        assertAllBetween(last2, j, bd2, ids);\n        last2 = j + 1;\n      }\n      assertEquals(uniqueValues.size(), queue.numGlobalTermDeletes());\n    }\n    assertEquals(uniqueValues, bd1.terms.keySet());\n    assertEquals(uniqueValues, bd2.terms.keySet());\n    HashSet<Term> frozenSet = new HashSet<Term>();\n    for (Term t : queue.freezeGlobalBuffer(null).termsIterable()) {\n      BytesRef bytesRef = new BytesRef();\n      bytesRef.copyBytes(t.bytes);\n      frozenSet.add(new Term(t.field, bytesRef));\n    }\n    assertEquals(uniqueValues, frozenSet);\n    assertEquals(\"num deletes must be 0 after freeze\", 0, queue\n        .numGlobalTermDeletes());\n  }\n\n","bugFix":["327863a2fd61e831028b6c56c8fef6b00a44eb0b"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"ef0d8a69209261514c5739c770bba706c2308450","date":1337607597,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDocumentsWriterDeleteQueue#testUpdateDelteSlices().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDocumentsWriterDeleteQueue#testUpdateDelteSlices().mjava","sourceNew":"  public void testUpdateDelteSlices() {\n    DocumentsWriterDeleteQueue queue = new DocumentsWriterDeleteQueue();\n    final int size = 200 + random().nextInt(500) * RANDOM_MULTIPLIER;\n    Integer[] ids = new Integer[size];\n    for (int i = 0; i < ids.length; i++) {\n      ids[i] = random().nextInt();\n    }\n    DeleteSlice slice1 = queue.newSlice();\n    DeleteSlice slice2 = queue.newSlice();\n    BufferedDeletes bd1 = new BufferedDeletes();\n    BufferedDeletes bd2 = new BufferedDeletes();\n    int last1 = 0;\n    int last2 = 0;\n    Set<Term> uniqueValues = new HashSet<Term>();\n    for (int j = 0; j < ids.length; j++) {\n      Integer i = ids[j];\n      // create an array here since we compare identity below against tailItem\n      Term[] term = new Term[] {new Term(\"id\", i.toString())};\n      uniqueValues.add(term[0]);\n      queue.addDelete(term);\n      if (random().nextInt(20) == 0 || j == ids.length - 1) {\n        queue.updateSlice(slice1);\n        assertTrue(slice1.isTailItem(term));\n        slice1.apply(bd1, j);\n        assertAllBetween(last1, j, bd1, ids);\n        last1 = j + 1;\n      }\n      if (random().nextInt(10) == 5 || j == ids.length - 1) {\n        queue.updateSlice(slice2);\n        assertTrue(slice2.isTailItem(term));\n        slice2.apply(bd2, j);\n        assertAllBetween(last2, j, bd2, ids);\n        last2 = j + 1;\n      }\n      assertEquals(j+1, queue.numGlobalTermDeletes());\n    }\n    assertEquals(uniqueValues, bd1.terms.keySet());\n    assertEquals(uniqueValues, bd2.terms.keySet());\n    HashSet<Term> frozenSet = new HashSet<Term>();\n    for (Term t : queue.freezeGlobalBuffer(null).termsIterable()) {\n      BytesRef bytesRef = new BytesRef();\n      bytesRef.copyBytes(t.bytes);\n      frozenSet.add(new Term(t.field, bytesRef));\n    }\n    assertEquals(uniqueValues, frozenSet);\n    assertEquals(\"num deletes must be 0 after freeze\", 0, queue\n        .numGlobalTermDeletes());\n  }\n\n","sourceOld":"  public void testUpdateDelteSlices() {\n    DocumentsWriterDeleteQueue queue = new DocumentsWriterDeleteQueue();\n    final int size = 200 + random().nextInt(500) * RANDOM_MULTIPLIER;\n    Integer[] ids = new Integer[size];\n    for (int i = 0; i < ids.length; i++) {\n      ids[i] = random().nextInt();\n    }\n    DeleteSlice slice1 = queue.newSlice();\n    DeleteSlice slice2 = queue.newSlice();\n    BufferedDeletes bd1 = new BufferedDeletes();\n    BufferedDeletes bd2 = new BufferedDeletes();\n    int last1 = 0;\n    int last2 = 0;\n    Set<Term> uniqueValues = new HashSet<Term>();\n    for (int j = 0; j < ids.length; j++) {\n      Integer i = ids[j];\n      // create an array here since we compare identity below against tailItem\n      Term[] term = new Term[] {new Term(\"id\", i.toString())};\n      uniqueValues.add(term[0]);\n      queue.addDelete(term);\n      if (random().nextInt(20) == 0 || j == ids.length - 1) {\n        queue.updateSlice(slice1);\n        assertTrue(slice1.isTailItem(term));\n        slice1.apply(bd1, j);\n        assertAllBetween(last1, j, bd1, ids);\n        last1 = j + 1;\n      }\n      if (random().nextInt(10) == 5 || j == ids.length - 1) {\n        queue.updateSlice(slice2);\n        assertTrue(slice2.isTailItem(term));\n        slice2.apply(bd2, j);\n        assertAllBetween(last2, j, bd2, ids);\n        last2 = j + 1;\n      }\n      assertEquals(uniqueValues.size(), queue.numGlobalTermDeletes());\n    }\n    assertEquals(uniqueValues, bd1.terms.keySet());\n    assertEquals(uniqueValues, bd2.terms.keySet());\n    HashSet<Term> frozenSet = new HashSet<Term>();\n    for (Term t : queue.freezeGlobalBuffer(null).termsIterable()) {\n      BytesRef bytesRef = new BytesRef();\n      bytesRef.copyBytes(t.bytes);\n      frozenSet.add(new Term(t.field, bytesRef));\n    }\n    assertEquals(uniqueValues, frozenSet);\n    assertEquals(\"num deletes must be 0 after freeze\", 0, queue\n        .numGlobalTermDeletes());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"73b0a97ef3bd519a5e43398ea9eabe6eed97f6b0","date":1383367127,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDocumentsWriterDeleteQueue#testUpdateDelteSlices().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDocumentsWriterDeleteQueue#testUpdateDelteSlices().mjava","sourceNew":"  public void testUpdateDelteSlices() {\n    DocumentsWriterDeleteQueue queue = new DocumentsWriterDeleteQueue();\n    final int size = 200 + random().nextInt(500) * RANDOM_MULTIPLIER;\n    Integer[] ids = new Integer[size];\n    for (int i = 0; i < ids.length; i++) {\n      ids[i] = random().nextInt();\n    }\n    DeleteSlice slice1 = queue.newSlice();\n    DeleteSlice slice2 = queue.newSlice();\n    BufferedUpdates bd1 = new BufferedUpdates();\n    BufferedUpdates bd2 = new BufferedUpdates();\n    int last1 = 0;\n    int last2 = 0;\n    Set<Term> uniqueValues = new HashSet<Term>();\n    for (int j = 0; j < ids.length; j++) {\n      Integer i = ids[j];\n      // create an array here since we compare identity below against tailItem\n      Term[] term = new Term[] {new Term(\"id\", i.toString())};\n      uniqueValues.add(term[0]);\n      queue.addDelete(term);\n      if (random().nextInt(20) == 0 || j == ids.length - 1) {\n        queue.updateSlice(slice1);\n        assertTrue(slice1.isTailItem(term));\n        slice1.apply(bd1, j);\n        assertAllBetween(last1, j, bd1, ids);\n        last1 = j + 1;\n      }\n      if (random().nextInt(10) == 5 || j == ids.length - 1) {\n        queue.updateSlice(slice2);\n        assertTrue(slice2.isTailItem(term));\n        slice2.apply(bd2, j);\n        assertAllBetween(last2, j, bd2, ids);\n        last2 = j + 1;\n      }\n      assertEquals(j+1, queue.numGlobalTermDeletes());\n    }\n    assertEquals(uniqueValues, bd1.terms.keySet());\n    assertEquals(uniqueValues, bd2.terms.keySet());\n    HashSet<Term> frozenSet = new HashSet<Term>();\n    for (Term t : queue.freezeGlobalBuffer(null).termsIterable()) {\n      BytesRef bytesRef = new BytesRef();\n      bytesRef.copyBytes(t.bytes);\n      frozenSet.add(new Term(t.field, bytesRef));\n    }\n    assertEquals(uniqueValues, frozenSet);\n    assertEquals(\"num deletes must be 0 after freeze\", 0, queue\n        .numGlobalTermDeletes());\n  }\n\n","sourceOld":"  public void testUpdateDelteSlices() {\n    DocumentsWriterDeleteQueue queue = new DocumentsWriterDeleteQueue();\n    final int size = 200 + random().nextInt(500) * RANDOM_MULTIPLIER;\n    Integer[] ids = new Integer[size];\n    for (int i = 0; i < ids.length; i++) {\n      ids[i] = random().nextInt();\n    }\n    DeleteSlice slice1 = queue.newSlice();\n    DeleteSlice slice2 = queue.newSlice();\n    BufferedDeletes bd1 = new BufferedDeletes();\n    BufferedDeletes bd2 = new BufferedDeletes();\n    int last1 = 0;\n    int last2 = 0;\n    Set<Term> uniqueValues = new HashSet<Term>();\n    for (int j = 0; j < ids.length; j++) {\n      Integer i = ids[j];\n      // create an array here since we compare identity below against tailItem\n      Term[] term = new Term[] {new Term(\"id\", i.toString())};\n      uniqueValues.add(term[0]);\n      queue.addDelete(term);\n      if (random().nextInt(20) == 0 || j == ids.length - 1) {\n        queue.updateSlice(slice1);\n        assertTrue(slice1.isTailItem(term));\n        slice1.apply(bd1, j);\n        assertAllBetween(last1, j, bd1, ids);\n        last1 = j + 1;\n      }\n      if (random().nextInt(10) == 5 || j == ids.length - 1) {\n        queue.updateSlice(slice2);\n        assertTrue(slice2.isTailItem(term));\n        slice2.apply(bd2, j);\n        assertAllBetween(last2, j, bd2, ids);\n        last2 = j + 1;\n      }\n      assertEquals(j+1, queue.numGlobalTermDeletes());\n    }\n    assertEquals(uniqueValues, bd1.terms.keySet());\n    assertEquals(uniqueValues, bd2.terms.keySet());\n    HashSet<Term> frozenSet = new HashSet<Term>();\n    for (Term t : queue.freezeGlobalBuffer(null).termsIterable()) {\n      BytesRef bytesRef = new BytesRef();\n      bytesRef.copyBytes(t.bytes);\n      frozenSet.add(new Term(t.field, bytesRef));\n    }\n    assertEquals(uniqueValues, frozenSet);\n    assertEquals(\"num deletes must be 0 after freeze\", 0, queue\n        .numGlobalTermDeletes());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"634f330c54fd3f9f491d52036dc3f40b4f4d8934","date":1394635157,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDocumentsWriterDeleteQueue#testUpdateDelteSlices().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDocumentsWriterDeleteQueue#testUpdateDelteSlices().mjava","sourceNew":"  public void testUpdateDelteSlices() {\n    DocumentsWriterDeleteQueue queue = new DocumentsWriterDeleteQueue();\n    final int size = 200 + random().nextInt(500) * RANDOM_MULTIPLIER;\n    Integer[] ids = new Integer[size];\n    for (int i = 0; i < ids.length; i++) {\n      ids[i] = random().nextInt();\n    }\n    DeleteSlice slice1 = queue.newSlice();\n    DeleteSlice slice2 = queue.newSlice();\n    BufferedUpdates bd1 = new BufferedUpdates();\n    BufferedUpdates bd2 = new BufferedUpdates();\n    int last1 = 0;\n    int last2 = 0;\n    Set<Term> uniqueValues = new HashSet<>();\n    for (int j = 0; j < ids.length; j++) {\n      Integer i = ids[j];\n      // create an array here since we compare identity below against tailItem\n      Term[] term = new Term[] {new Term(\"id\", i.toString())};\n      uniqueValues.add(term[0]);\n      queue.addDelete(term);\n      if (random().nextInt(20) == 0 || j == ids.length - 1) {\n        queue.updateSlice(slice1);\n        assertTrue(slice1.isTailItem(term));\n        slice1.apply(bd1, j);\n        assertAllBetween(last1, j, bd1, ids);\n        last1 = j + 1;\n      }\n      if (random().nextInt(10) == 5 || j == ids.length - 1) {\n        queue.updateSlice(slice2);\n        assertTrue(slice2.isTailItem(term));\n        slice2.apply(bd2, j);\n        assertAllBetween(last2, j, bd2, ids);\n        last2 = j + 1;\n      }\n      assertEquals(j+1, queue.numGlobalTermDeletes());\n    }\n    assertEquals(uniqueValues, bd1.terms.keySet());\n    assertEquals(uniqueValues, bd2.terms.keySet());\n    HashSet<Term> frozenSet = new HashSet<>();\n    for (Term t : queue.freezeGlobalBuffer(null).termsIterable()) {\n      BytesRef bytesRef = new BytesRef();\n      bytesRef.copyBytes(t.bytes);\n      frozenSet.add(new Term(t.field, bytesRef));\n    }\n    assertEquals(uniqueValues, frozenSet);\n    assertEquals(\"num deletes must be 0 after freeze\", 0, queue\n        .numGlobalTermDeletes());\n  }\n\n","sourceOld":"  public void testUpdateDelteSlices() {\n    DocumentsWriterDeleteQueue queue = new DocumentsWriterDeleteQueue();\n    final int size = 200 + random().nextInt(500) * RANDOM_MULTIPLIER;\n    Integer[] ids = new Integer[size];\n    for (int i = 0; i < ids.length; i++) {\n      ids[i] = random().nextInt();\n    }\n    DeleteSlice slice1 = queue.newSlice();\n    DeleteSlice slice2 = queue.newSlice();\n    BufferedUpdates bd1 = new BufferedUpdates();\n    BufferedUpdates bd2 = new BufferedUpdates();\n    int last1 = 0;\n    int last2 = 0;\n    Set<Term> uniqueValues = new HashSet<Term>();\n    for (int j = 0; j < ids.length; j++) {\n      Integer i = ids[j];\n      // create an array here since we compare identity below against tailItem\n      Term[] term = new Term[] {new Term(\"id\", i.toString())};\n      uniqueValues.add(term[0]);\n      queue.addDelete(term);\n      if (random().nextInt(20) == 0 || j == ids.length - 1) {\n        queue.updateSlice(slice1);\n        assertTrue(slice1.isTailItem(term));\n        slice1.apply(bd1, j);\n        assertAllBetween(last1, j, bd1, ids);\n        last1 = j + 1;\n      }\n      if (random().nextInt(10) == 5 || j == ids.length - 1) {\n        queue.updateSlice(slice2);\n        assertTrue(slice2.isTailItem(term));\n        slice2.apply(bd2, j);\n        assertAllBetween(last2, j, bd2, ids);\n        last2 = j + 1;\n      }\n      assertEquals(j+1, queue.numGlobalTermDeletes());\n    }\n    assertEquals(uniqueValues, bd1.terms.keySet());\n    assertEquals(uniqueValues, bd2.terms.keySet());\n    HashSet<Term> frozenSet = new HashSet<Term>();\n    for (Term t : queue.freezeGlobalBuffer(null).termsIterable()) {\n      BytesRef bytesRef = new BytesRef();\n      bytesRef.copyBytes(t.bytes);\n      frozenSet.add(new Term(t.field, bytesRef));\n    }\n    assertEquals(uniqueValues, frozenSet);\n    assertEquals(\"num deletes must be 0 after freeze\", 0, queue\n        .numGlobalTermDeletes());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"7dc6ea5fd38ce7aa8f36b3bac8b757da77f31d50","date":1407854805,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDocumentsWriterDeleteQueue#testUpdateDelteSlices().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDocumentsWriterDeleteQueue#testUpdateDelteSlices().mjava","sourceNew":"  public void testUpdateDelteSlices() {\n    DocumentsWriterDeleteQueue queue = new DocumentsWriterDeleteQueue();\n    final int size = 200 + random().nextInt(500) * RANDOM_MULTIPLIER;\n    Integer[] ids = new Integer[size];\n    for (int i = 0; i < ids.length; i++) {\n      ids[i] = random().nextInt();\n    }\n    DeleteSlice slice1 = queue.newSlice();\n    DeleteSlice slice2 = queue.newSlice();\n    BufferedUpdates bd1 = new BufferedUpdates();\n    BufferedUpdates bd2 = new BufferedUpdates();\n    int last1 = 0;\n    int last2 = 0;\n    Set<Term> uniqueValues = new HashSet<>();\n    for (int j = 0; j < ids.length; j++) {\n      Integer i = ids[j];\n      // create an array here since we compare identity below against tailItem\n      Term[] term = new Term[] {new Term(\"id\", i.toString())};\n      uniqueValues.add(term[0]);\n      queue.addDelete(term);\n      if (random().nextInt(20) == 0 || j == ids.length - 1) {\n        queue.updateSlice(slice1);\n        assertTrue(slice1.isTailItem(term));\n        slice1.apply(bd1, j);\n        assertAllBetween(last1, j, bd1, ids);\n        last1 = j + 1;\n      }\n      if (random().nextInt(10) == 5 || j == ids.length - 1) {\n        queue.updateSlice(slice2);\n        assertTrue(slice2.isTailItem(term));\n        slice2.apply(bd2, j);\n        assertAllBetween(last2, j, bd2, ids);\n        last2 = j + 1;\n      }\n      assertEquals(j+1, queue.numGlobalTermDeletes());\n    }\n    assertEquals(uniqueValues, bd1.terms.keySet());\n    assertEquals(uniqueValues, bd2.terms.keySet());\n    HashSet<Term> frozenSet = new HashSet<>();\n    BytesRefBuilder bytesRef = new BytesRefBuilder();\n    for (Term t : queue.freezeGlobalBuffer(null).termsIterable()) {\n      bytesRef.copyBytes(t.bytes);\n      frozenSet.add(new Term(t.field, bytesRef.toBytesRef()));\n    }\n    assertEquals(uniqueValues, frozenSet);\n    assertEquals(\"num deletes must be 0 after freeze\", 0, queue\n        .numGlobalTermDeletes());\n  }\n\n","sourceOld":"  public void testUpdateDelteSlices() {\n    DocumentsWriterDeleteQueue queue = new DocumentsWriterDeleteQueue();\n    final int size = 200 + random().nextInt(500) * RANDOM_MULTIPLIER;\n    Integer[] ids = new Integer[size];\n    for (int i = 0; i < ids.length; i++) {\n      ids[i] = random().nextInt();\n    }\n    DeleteSlice slice1 = queue.newSlice();\n    DeleteSlice slice2 = queue.newSlice();\n    BufferedUpdates bd1 = new BufferedUpdates();\n    BufferedUpdates bd2 = new BufferedUpdates();\n    int last1 = 0;\n    int last2 = 0;\n    Set<Term> uniqueValues = new HashSet<>();\n    for (int j = 0; j < ids.length; j++) {\n      Integer i = ids[j];\n      // create an array here since we compare identity below against tailItem\n      Term[] term = new Term[] {new Term(\"id\", i.toString())};\n      uniqueValues.add(term[0]);\n      queue.addDelete(term);\n      if (random().nextInt(20) == 0 || j == ids.length - 1) {\n        queue.updateSlice(slice1);\n        assertTrue(slice1.isTailItem(term));\n        slice1.apply(bd1, j);\n        assertAllBetween(last1, j, bd1, ids);\n        last1 = j + 1;\n      }\n      if (random().nextInt(10) == 5 || j == ids.length - 1) {\n        queue.updateSlice(slice2);\n        assertTrue(slice2.isTailItem(term));\n        slice2.apply(bd2, j);\n        assertAllBetween(last2, j, bd2, ids);\n        last2 = j + 1;\n      }\n      assertEquals(j+1, queue.numGlobalTermDeletes());\n    }\n    assertEquals(uniqueValues, bd1.terms.keySet());\n    assertEquals(uniqueValues, bd2.terms.keySet());\n    HashSet<Term> frozenSet = new HashSet<>();\n    for (Term t : queue.freezeGlobalBuffer(null).termsIterable()) {\n      BytesRef bytesRef = new BytesRef();\n      bytesRef.copyBytes(t.bytes);\n      frozenSet.add(new Term(t.field, bytesRef));\n    }\n    assertEquals(uniqueValues, frozenSet);\n    assertEquals(\"num deletes must be 0 after freeze\", 0, queue\n        .numGlobalTermDeletes());\n  }\n\n","bugFix":["21a62a863ced88734bdbffa17760bc6ed7e42ff8"],"bugIntro":["7e4c214a1f904dde76f5611b56d4081533055b3b"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"7e4c214a1f904dde76f5611b56d4081533055b3b","date":1421938451,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDocumentsWriterDeleteQueue#testUpdateDelteSlices().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDocumentsWriterDeleteQueue#testUpdateDelteSlices().mjava","sourceNew":"  public void testUpdateDelteSlices() {\n    DocumentsWriterDeleteQueue queue = new DocumentsWriterDeleteQueue();\n    final int size = 200 + random().nextInt(500) * RANDOM_MULTIPLIER;\n    Integer[] ids = new Integer[size];\n    for (int i = 0; i < ids.length; i++) {\n      ids[i] = random().nextInt();\n    }\n    DeleteSlice slice1 = queue.newSlice();\n    DeleteSlice slice2 = queue.newSlice();\n    BufferedUpdates bd1 = new BufferedUpdates();\n    BufferedUpdates bd2 = new BufferedUpdates();\n    int last1 = 0;\n    int last2 = 0;\n    Set<Term> uniqueValues = new HashSet<>();\n    for (int j = 0; j < ids.length; j++) {\n      Integer i = ids[j];\n      // create an array here since we compare identity below against tailItem\n      Term[] term = new Term[] {new Term(\"id\", i.toString())};\n      uniqueValues.add(term[0]);\n      queue.addDelete(term);\n      if (random().nextInt(20) == 0 || j == ids.length - 1) {\n        queue.updateSlice(slice1);\n        assertTrue(slice1.isTailItem(term));\n        slice1.apply(bd1, j);\n        assertAllBetween(last1, j, bd1, ids);\n        last1 = j + 1;\n      }\n      if (random().nextInt(10) == 5 || j == ids.length - 1) {\n        queue.updateSlice(slice2);\n        assertTrue(slice2.isTailItem(term));\n        slice2.apply(bd2, j);\n        assertAllBetween(last2, j, bd2, ids);\n        last2 = j + 1;\n      }\n      assertEquals(j+1, queue.numGlobalTermDeletes());\n    }\n    assertEquals(uniqueValues, bd1.terms.keySet());\n    assertEquals(uniqueValues, bd2.terms.keySet());\n    HashSet<Term> frozenSet = new HashSet<>();\n    BytesRefBuilder bytesRef = new BytesRefBuilder();\n    TermIterator iter = queue.freezeGlobalBuffer(null).termIterator();\n    String field = null;\n    while (true) {\n      boolean newField = iter.next();\n      if (newField) {\n        field = iter.field;\n        if (field == null) {\n          break;\n        }\n      }\n      bytesRef.copyBytes(iter.bytes);\n      frozenSet.add(new Term(field, bytesRef.toBytesRef()));\n    }\n    assertEquals(uniqueValues, frozenSet);\n    assertEquals(\"num deletes must be 0 after freeze\", 0, queue\n        .numGlobalTermDeletes());\n  }\n\n","sourceOld":"  public void testUpdateDelteSlices() {\n    DocumentsWriterDeleteQueue queue = new DocumentsWriterDeleteQueue();\n    final int size = 200 + random().nextInt(500) * RANDOM_MULTIPLIER;\n    Integer[] ids = new Integer[size];\n    for (int i = 0; i < ids.length; i++) {\n      ids[i] = random().nextInt();\n    }\n    DeleteSlice slice1 = queue.newSlice();\n    DeleteSlice slice2 = queue.newSlice();\n    BufferedUpdates bd1 = new BufferedUpdates();\n    BufferedUpdates bd2 = new BufferedUpdates();\n    int last1 = 0;\n    int last2 = 0;\n    Set<Term> uniqueValues = new HashSet<>();\n    for (int j = 0; j < ids.length; j++) {\n      Integer i = ids[j];\n      // create an array here since we compare identity below against tailItem\n      Term[] term = new Term[] {new Term(\"id\", i.toString())};\n      uniqueValues.add(term[0]);\n      queue.addDelete(term);\n      if (random().nextInt(20) == 0 || j == ids.length - 1) {\n        queue.updateSlice(slice1);\n        assertTrue(slice1.isTailItem(term));\n        slice1.apply(bd1, j);\n        assertAllBetween(last1, j, bd1, ids);\n        last1 = j + 1;\n      }\n      if (random().nextInt(10) == 5 || j == ids.length - 1) {\n        queue.updateSlice(slice2);\n        assertTrue(slice2.isTailItem(term));\n        slice2.apply(bd2, j);\n        assertAllBetween(last2, j, bd2, ids);\n        last2 = j + 1;\n      }\n      assertEquals(j+1, queue.numGlobalTermDeletes());\n    }\n    assertEquals(uniqueValues, bd1.terms.keySet());\n    assertEquals(uniqueValues, bd2.terms.keySet());\n    HashSet<Term> frozenSet = new HashSet<>();\n    BytesRefBuilder bytesRef = new BytesRefBuilder();\n    for (Term t : queue.freezeGlobalBuffer(null).termsIterable()) {\n      bytesRef.copyBytes(t.bytes);\n      frozenSet.add(new Term(t.field, bytesRef.toBytesRef()));\n    }\n    assertEquals(uniqueValues, frozenSet);\n    assertEquals(\"num deletes must be 0 after freeze\", 0, queue\n        .numGlobalTermDeletes());\n  }\n\n","bugFix":["e6e919043fa85ee891123768dd655a98edbbf63c","7dc6ea5fd38ce7aa8f36b3bac8b757da77f31d50","9fa5ed548a2e7179ad03d6dfef30e19b8c06a8e2"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"258f227b48a4dbfc180f6ec70f172469d6a2bef8","date":1428687213,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDocumentsWriterDeleteQueue#testUpdateDelteSlices().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDocumentsWriterDeleteQueue#testUpdateDelteSlices().mjava","sourceNew":"  public void testUpdateDelteSlices() {\n    DocumentsWriterDeleteQueue queue = new DocumentsWriterDeleteQueue();\n    final int size = 200 + random().nextInt(500) * RANDOM_MULTIPLIER;\n    Integer[] ids = new Integer[size];\n    for (int i = 0; i < ids.length; i++) {\n      ids[i] = random().nextInt();\n    }\n    DeleteSlice slice1 = queue.newSlice();\n    DeleteSlice slice2 = queue.newSlice();\n    BufferedUpdates bd1 = new BufferedUpdates();\n    BufferedUpdates bd2 = new BufferedUpdates();\n    int last1 = 0;\n    int last2 = 0;\n    Set<Term> uniqueValues = new HashSet<>();\n    for (int j = 0; j < ids.length; j++) {\n      Integer i = ids[j];\n      // create an array here since we compare identity below against tailItem\n      Term[] term = new Term[] {new Term(\"id\", i.toString())};\n      uniqueValues.add(term[0]);\n      queue.addDelete(term);\n      if (random().nextInt(20) == 0 || j == ids.length - 1) {\n        queue.updateSlice(slice1);\n        assertTrue(slice1.isTailItem(term));\n        slice1.apply(bd1, j);\n        assertAllBetween(last1, j, bd1, ids);\n        last1 = j + 1;\n      }\n      if (random().nextInt(10) == 5 || j == ids.length - 1) {\n        queue.updateSlice(slice2);\n        assertTrue(slice2.isTailItem(term));\n        slice2.apply(bd2, j);\n        assertAllBetween(last2, j, bd2, ids);\n        last2 = j + 1;\n      }\n      assertEquals(j+1, queue.numGlobalTermDeletes());\n    }\n    assertEquals(uniqueValues, bd1.terms.keySet());\n    assertEquals(uniqueValues, bd2.terms.keySet());\n    HashSet<Term> frozenSet = new HashSet<>();\n    BytesRefBuilder bytesRef = new BytesRefBuilder();\n    TermIterator iter = queue.freezeGlobalBuffer(null).termIterator();\n    while (iter.next() != null) {\n      bytesRef.copyBytes(iter.bytes);\n      frozenSet.add(new Term(iter.field(), bytesRef.toBytesRef()));\n    }\n    assertEquals(uniqueValues, frozenSet);\n    assertEquals(\"num deletes must be 0 after freeze\", 0, queue\n        .numGlobalTermDeletes());\n  }\n\n","sourceOld":"  public void testUpdateDelteSlices() {\n    DocumentsWriterDeleteQueue queue = new DocumentsWriterDeleteQueue();\n    final int size = 200 + random().nextInt(500) * RANDOM_MULTIPLIER;\n    Integer[] ids = new Integer[size];\n    for (int i = 0; i < ids.length; i++) {\n      ids[i] = random().nextInt();\n    }\n    DeleteSlice slice1 = queue.newSlice();\n    DeleteSlice slice2 = queue.newSlice();\n    BufferedUpdates bd1 = new BufferedUpdates();\n    BufferedUpdates bd2 = new BufferedUpdates();\n    int last1 = 0;\n    int last2 = 0;\n    Set<Term> uniqueValues = new HashSet<>();\n    for (int j = 0; j < ids.length; j++) {\n      Integer i = ids[j];\n      // create an array here since we compare identity below against tailItem\n      Term[] term = new Term[] {new Term(\"id\", i.toString())};\n      uniqueValues.add(term[0]);\n      queue.addDelete(term);\n      if (random().nextInt(20) == 0 || j == ids.length - 1) {\n        queue.updateSlice(slice1);\n        assertTrue(slice1.isTailItem(term));\n        slice1.apply(bd1, j);\n        assertAllBetween(last1, j, bd1, ids);\n        last1 = j + 1;\n      }\n      if (random().nextInt(10) == 5 || j == ids.length - 1) {\n        queue.updateSlice(slice2);\n        assertTrue(slice2.isTailItem(term));\n        slice2.apply(bd2, j);\n        assertAllBetween(last2, j, bd2, ids);\n        last2 = j + 1;\n      }\n      assertEquals(j+1, queue.numGlobalTermDeletes());\n    }\n    assertEquals(uniqueValues, bd1.terms.keySet());\n    assertEquals(uniqueValues, bd2.terms.keySet());\n    HashSet<Term> frozenSet = new HashSet<>();\n    BytesRefBuilder bytesRef = new BytesRefBuilder();\n    TermIterator iter = queue.freezeGlobalBuffer(null).termIterator();\n    String field = null;\n    while (true) {\n      boolean newField = iter.next();\n      if (newField) {\n        field = iter.field;\n        if (field == null) {\n          break;\n        }\n      }\n      bytesRef.copyBytes(iter.bytes);\n      frozenSet.add(new Term(field, bytesRef.toBytesRef()));\n    }\n    assertEquals(uniqueValues, frozenSet);\n    assertEquals(\"num deletes must be 0 after freeze\", 0, queue\n        .numGlobalTermDeletes());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"122251c49e5a9fa95f056ea257ae3ab452099fc7","date":1464820065,"type":3,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDocumentsWriterDeleteQueue#testUpdateDelteSlices().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDocumentsWriterDeleteQueue#testUpdateDelteSlices().mjava","sourceNew":"  public void testUpdateDelteSlices() {\n    DocumentsWriterDeleteQueue queue = new DocumentsWriterDeleteQueue();\n    final int size = 200 + random().nextInt(500) * RANDOM_MULTIPLIER;\n    Integer[] ids = new Integer[size];\n    for (int i = 0; i < ids.length; i++) {\n      ids[i] = random().nextInt();\n    }\n    DeleteSlice slice1 = queue.newSlice();\n    DeleteSlice slice2 = queue.newSlice();\n    BufferedUpdates bd1 = new BufferedUpdates(\"bd1\");\n    BufferedUpdates bd2 = new BufferedUpdates(\"bd2\");\n    int last1 = 0;\n    int last2 = 0;\n    Set<Term> uniqueValues = new HashSet<>();\n    for (int j = 0; j < ids.length; j++) {\n      Integer i = ids[j];\n      // create an array here since we compare identity below against tailItem\n      Term[] term = new Term[] {new Term(\"id\", i.toString())};\n      uniqueValues.add(term[0]);\n      queue.addDelete(term);\n      if (random().nextInt(20) == 0 || j == ids.length - 1) {\n        queue.updateSlice(slice1);\n        assertTrue(slice1.isTailItem(term));\n        slice1.apply(bd1, j);\n        assertAllBetween(last1, j, bd1, ids);\n        last1 = j + 1;\n      }\n      if (random().nextInt(10) == 5 || j == ids.length - 1) {\n        queue.updateSlice(slice2);\n        assertTrue(slice2.isTailItem(term));\n        slice2.apply(bd2, j);\n        assertAllBetween(last2, j, bd2, ids);\n        last2 = j + 1;\n      }\n      assertEquals(j+1, queue.numGlobalTermDeletes());\n    }\n    assertEquals(uniqueValues, bd1.terms.keySet());\n    assertEquals(uniqueValues, bd2.terms.keySet());\n    HashSet<Term> frozenSet = new HashSet<>();\n    BytesRefBuilder bytesRef = new BytesRefBuilder();\n    TermIterator iter = queue.freezeGlobalBuffer(null).termIterator();\n    while (iter.next() != null) {\n      bytesRef.copyBytes(iter.bytes);\n      frozenSet.add(new Term(iter.field(), bytesRef.toBytesRef()));\n    }\n    assertEquals(uniqueValues, frozenSet);\n    assertEquals(\"num deletes must be 0 after freeze\", 0, queue\n        .numGlobalTermDeletes());\n  }\n\n","sourceOld":"  public void testUpdateDelteSlices() {\n    DocumentsWriterDeleteQueue queue = new DocumentsWriterDeleteQueue();\n    final int size = 200 + random().nextInt(500) * RANDOM_MULTIPLIER;\n    Integer[] ids = new Integer[size];\n    for (int i = 0; i < ids.length; i++) {\n      ids[i] = random().nextInt();\n    }\n    DeleteSlice slice1 = queue.newSlice();\n    DeleteSlice slice2 = queue.newSlice();\n    BufferedUpdates bd1 = new BufferedUpdates();\n    BufferedUpdates bd2 = new BufferedUpdates();\n    int last1 = 0;\n    int last2 = 0;\n    Set<Term> uniqueValues = new HashSet<>();\n    for (int j = 0; j < ids.length; j++) {\n      Integer i = ids[j];\n      // create an array here since we compare identity below against tailItem\n      Term[] term = new Term[] {new Term(\"id\", i.toString())};\n      uniqueValues.add(term[0]);\n      queue.addDelete(term);\n      if (random().nextInt(20) == 0 || j == ids.length - 1) {\n        queue.updateSlice(slice1);\n        assertTrue(slice1.isTailItem(term));\n        slice1.apply(bd1, j);\n        assertAllBetween(last1, j, bd1, ids);\n        last1 = j + 1;\n      }\n      if (random().nextInt(10) == 5 || j == ids.length - 1) {\n        queue.updateSlice(slice2);\n        assertTrue(slice2.isTailItem(term));\n        slice2.apply(bd2, j);\n        assertAllBetween(last2, j, bd2, ids);\n        last2 = j + 1;\n      }\n      assertEquals(j+1, queue.numGlobalTermDeletes());\n    }\n    assertEquals(uniqueValues, bd1.terms.keySet());\n    assertEquals(uniqueValues, bd2.terms.keySet());\n    HashSet<Term> frozenSet = new HashSet<>();\n    BytesRefBuilder bytesRef = new BytesRefBuilder();\n    TermIterator iter = queue.freezeGlobalBuffer(null).termIterator();\n    while (iter.next() != null) {\n      bytesRef.copyBytes(iter.bytes);\n      frozenSet.add(new Term(iter.field(), bytesRef.toBytesRef()));\n    }\n    assertEquals(uniqueValues, frozenSet);\n    assertEquals(\"num deletes must be 0 after freeze\", 0, queue\n        .numGlobalTermDeletes());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b40b1a0adcc6bdcda63b0fbd75dfa2ddd8777e77","date":1464821470,"type":3,"author":"Mike McCandless","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDocumentsWriterDeleteQueue#testUpdateDelteSlices().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDocumentsWriterDeleteQueue#testUpdateDelteSlices().mjava","sourceNew":"  public void testUpdateDelteSlices() {\n    DocumentsWriterDeleteQueue queue = new DocumentsWriterDeleteQueue();\n    final int size = 200 + random().nextInt(500) * RANDOM_MULTIPLIER;\n    Integer[] ids = new Integer[size];\n    for (int i = 0; i < ids.length; i++) {\n      ids[i] = random().nextInt();\n    }\n    DeleteSlice slice1 = queue.newSlice();\n    DeleteSlice slice2 = queue.newSlice();\n    BufferedUpdates bd1 = new BufferedUpdates(\"bd1\");\n    BufferedUpdates bd2 = new BufferedUpdates(\"bd2\");\n    int last1 = 0;\n    int last2 = 0;\n    Set<Term> uniqueValues = new HashSet<>();\n    for (int j = 0; j < ids.length; j++) {\n      Integer i = ids[j];\n      // create an array here since we compare identity below against tailItem\n      Term[] term = new Term[] {new Term(\"id\", i.toString())};\n      uniqueValues.add(term[0]);\n      queue.addDelete(term);\n      if (random().nextInt(20) == 0 || j == ids.length - 1) {\n        queue.updateSlice(slice1);\n        assertTrue(slice1.isTailItem(term));\n        slice1.apply(bd1, j);\n        assertAllBetween(last1, j, bd1, ids);\n        last1 = j + 1;\n      }\n      if (random().nextInt(10) == 5 || j == ids.length - 1) {\n        queue.updateSlice(slice2);\n        assertTrue(slice2.isTailItem(term));\n        slice2.apply(bd2, j);\n        assertAllBetween(last2, j, bd2, ids);\n        last2 = j + 1;\n      }\n      assertEquals(j+1, queue.numGlobalTermDeletes());\n    }\n    assertEquals(uniqueValues, bd1.terms.keySet());\n    assertEquals(uniqueValues, bd2.terms.keySet());\n    HashSet<Term> frozenSet = new HashSet<>();\n    BytesRefBuilder bytesRef = new BytesRefBuilder();\n    TermIterator iter = queue.freezeGlobalBuffer(null).termIterator();\n    while (iter.next() != null) {\n      bytesRef.copyBytes(iter.bytes);\n      frozenSet.add(new Term(iter.field(), bytesRef.toBytesRef()));\n    }\n    assertEquals(uniqueValues, frozenSet);\n    assertEquals(\"num deletes must be 0 after freeze\", 0, queue\n        .numGlobalTermDeletes());\n  }\n\n","sourceOld":"  public void testUpdateDelteSlices() {\n    DocumentsWriterDeleteQueue queue = new DocumentsWriterDeleteQueue();\n    final int size = 200 + random().nextInt(500) * RANDOM_MULTIPLIER;\n    Integer[] ids = new Integer[size];\n    for (int i = 0; i < ids.length; i++) {\n      ids[i] = random().nextInt();\n    }\n    DeleteSlice slice1 = queue.newSlice();\n    DeleteSlice slice2 = queue.newSlice();\n    BufferedUpdates bd1 = new BufferedUpdates();\n    BufferedUpdates bd2 = new BufferedUpdates();\n    int last1 = 0;\n    int last2 = 0;\n    Set<Term> uniqueValues = new HashSet<>();\n    for (int j = 0; j < ids.length; j++) {\n      Integer i = ids[j];\n      // create an array here since we compare identity below against tailItem\n      Term[] term = new Term[] {new Term(\"id\", i.toString())};\n      uniqueValues.add(term[0]);\n      queue.addDelete(term);\n      if (random().nextInt(20) == 0 || j == ids.length - 1) {\n        queue.updateSlice(slice1);\n        assertTrue(slice1.isTailItem(term));\n        slice1.apply(bd1, j);\n        assertAllBetween(last1, j, bd1, ids);\n        last1 = j + 1;\n      }\n      if (random().nextInt(10) == 5 || j == ids.length - 1) {\n        queue.updateSlice(slice2);\n        assertTrue(slice2.isTailItem(term));\n        slice2.apply(bd2, j);\n        assertAllBetween(last2, j, bd2, ids);\n        last2 = j + 1;\n      }\n      assertEquals(j+1, queue.numGlobalTermDeletes());\n    }\n    assertEquals(uniqueValues, bd1.terms.keySet());\n    assertEquals(uniqueValues, bd2.terms.keySet());\n    HashSet<Term> frozenSet = new HashSet<>();\n    BytesRefBuilder bytesRef = new BytesRefBuilder();\n    TermIterator iter = queue.freezeGlobalBuffer(null).termIterator();\n    while (iter.next() != null) {\n      bytesRef.copyBytes(iter.bytes);\n      frozenSet.add(new Term(iter.field(), bytesRef.toBytesRef()));\n    }\n    assertEquals(uniqueValues, frozenSet);\n    assertEquals(\"num deletes must be 0 after freeze\", 0, queue\n        .numGlobalTermDeletes());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6483e4260c08168709c02238ae083a51519a28dd","date":1465117546,"type":3,"author":"Mike McCandless","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDocumentsWriterDeleteQueue#testUpdateDelteSlices().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDocumentsWriterDeleteQueue#testUpdateDelteSlices().mjava","sourceNew":"  public void testUpdateDelteSlices() {\n    DocumentsWriterDeleteQueue queue = new DocumentsWriterDeleteQueue();\n    final int size = 200 + random().nextInt(500) * RANDOM_MULTIPLIER;\n    Integer[] ids = new Integer[size];\n    for (int i = 0; i < ids.length; i++) {\n      ids[i] = random().nextInt();\n    }\n    DeleteSlice slice1 = queue.newSlice();\n    DeleteSlice slice2 = queue.newSlice();\n    BufferedUpdates bd1 = new BufferedUpdates(\"bd1\");\n    BufferedUpdates bd2 = new BufferedUpdates(\"bd2\");\n    int last1 = 0;\n    int last2 = 0;\n    Set<Term> uniqueValues = new HashSet<>();\n    for (int j = 0; j < ids.length; j++) {\n      Integer i = ids[j];\n      // create an array here since we compare identity below against tailItem\n      Term[] term = new Term[] {new Term(\"id\", i.toString())};\n      uniqueValues.add(term[0]);\n      queue.addDelete(term);\n      if (random().nextInt(20) == 0 || j == ids.length - 1) {\n        queue.updateSlice(slice1);\n        assertTrue(slice1.isTailItem(term));\n        slice1.apply(bd1, j);\n        assertAllBetween(last1, j, bd1, ids);\n        last1 = j + 1;\n      }\n      if (random().nextInt(10) == 5 || j == ids.length - 1) {\n        queue.updateSlice(slice2);\n        assertTrue(slice2.isTailItem(term));\n        slice2.apply(bd2, j);\n        assertAllBetween(last2, j, bd2, ids);\n        last2 = j + 1;\n      }\n      assertEquals(j+1, queue.numGlobalTermDeletes());\n    }\n    assertEquals(uniqueValues, bd1.terms.keySet());\n    assertEquals(uniqueValues, bd2.terms.keySet());\n    HashSet<Term> frozenSet = new HashSet<>();\n    BytesRefBuilder bytesRef = new BytesRefBuilder();\n    TermIterator iter = queue.freezeGlobalBuffer(null).termIterator();\n    while (iter.next() != null) {\n      bytesRef.copyBytes(iter.bytes);\n      frozenSet.add(new Term(iter.field(), bytesRef.toBytesRef()));\n    }\n    assertEquals(uniqueValues, frozenSet);\n    assertEquals(\"num deletes must be 0 after freeze\", 0, queue\n        .numGlobalTermDeletes());\n  }\n\n","sourceOld":"  public void testUpdateDelteSlices() {\n    DocumentsWriterDeleteQueue queue = new DocumentsWriterDeleteQueue();\n    final int size = 200 + random().nextInt(500) * RANDOM_MULTIPLIER;\n    Integer[] ids = new Integer[size];\n    for (int i = 0; i < ids.length; i++) {\n      ids[i] = random().nextInt();\n    }\n    DeleteSlice slice1 = queue.newSlice();\n    DeleteSlice slice2 = queue.newSlice();\n    BufferedUpdates bd1 = new BufferedUpdates();\n    BufferedUpdates bd2 = new BufferedUpdates();\n    int last1 = 0;\n    int last2 = 0;\n    Set<Term> uniqueValues = new HashSet<>();\n    for (int j = 0; j < ids.length; j++) {\n      Integer i = ids[j];\n      // create an array here since we compare identity below against tailItem\n      Term[] term = new Term[] {new Term(\"id\", i.toString())};\n      uniqueValues.add(term[0]);\n      queue.addDelete(term);\n      if (random().nextInt(20) == 0 || j == ids.length - 1) {\n        queue.updateSlice(slice1);\n        assertTrue(slice1.isTailItem(term));\n        slice1.apply(bd1, j);\n        assertAllBetween(last1, j, bd1, ids);\n        last1 = j + 1;\n      }\n      if (random().nextInt(10) == 5 || j == ids.length - 1) {\n        queue.updateSlice(slice2);\n        assertTrue(slice2.isTailItem(term));\n        slice2.apply(bd2, j);\n        assertAllBetween(last2, j, bd2, ids);\n        last2 = j + 1;\n      }\n      assertEquals(j+1, queue.numGlobalTermDeletes());\n    }\n    assertEquals(uniqueValues, bd1.terms.keySet());\n    assertEquals(uniqueValues, bd2.terms.keySet());\n    HashSet<Term> frozenSet = new HashSet<>();\n    BytesRefBuilder bytesRef = new BytesRefBuilder();\n    TermIterator iter = queue.freezeGlobalBuffer(null).termIterator();\n    while (iter.next() != null) {\n      bytesRef.copyBytes(iter.bytes);\n      frozenSet.add(new Term(iter.field(), bytesRef.toBytesRef()));\n    }\n    assertEquals(uniqueValues, frozenSet);\n    assertEquals(\"num deletes must be 0 after freeze\", 0, queue\n        .numGlobalTermDeletes());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"191128ac5b85671b1671e2c857437694283b6ebf","date":1465297861,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDocumentsWriterDeleteQueue#testUpdateDelteSlices().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDocumentsWriterDeleteQueue#testUpdateDelteSlices().mjava","sourceNew":"  public void testUpdateDelteSlices() {\n    DocumentsWriterDeleteQueue queue = new DocumentsWriterDeleteQueue();\n    final int size = 200 + random().nextInt(500) * RANDOM_MULTIPLIER;\n    Integer[] ids = new Integer[size];\n    for (int i = 0; i < ids.length; i++) {\n      ids[i] = random().nextInt();\n    }\n    DeleteSlice slice1 = queue.newSlice();\n    DeleteSlice slice2 = queue.newSlice();\n    BufferedUpdates bd1 = new BufferedUpdates(\"bd1\");\n    BufferedUpdates bd2 = new BufferedUpdates(\"bd2\");\n    int last1 = 0;\n    int last2 = 0;\n    Set<Term> uniqueValues = new HashSet<>();\n    for (int j = 0; j < ids.length; j++) {\n      Integer i = ids[j];\n      // create an array here since we compare identity below against tailItem\n      Term[] term = new Term[] {new Term(\"id\", i.toString())};\n      uniqueValues.add(term[0]);\n      queue.addDelete(term);\n      if (random().nextInt(20) == 0 || j == ids.length - 1) {\n        queue.updateSlice(slice1);\n        assertTrue(slice1.isTailItem(term));\n        slice1.apply(bd1, j);\n        assertAllBetween(last1, j, bd1, ids);\n        last1 = j + 1;\n      }\n      if (random().nextInt(10) == 5 || j == ids.length - 1) {\n        queue.updateSlice(slice2);\n        assertTrue(slice2.isTailItem(term));\n        slice2.apply(bd2, j);\n        assertAllBetween(last2, j, bd2, ids);\n        last2 = j + 1;\n      }\n      assertEquals(j+1, queue.numGlobalTermDeletes());\n    }\n    assertEquals(uniqueValues, bd1.terms.keySet());\n    assertEquals(uniqueValues, bd2.terms.keySet());\n    HashSet<Term> frozenSet = new HashSet<>();\n    BytesRefBuilder bytesRef = new BytesRefBuilder();\n    TermIterator iter = queue.freezeGlobalBuffer(null).termIterator();\n    while (iter.next() != null) {\n      bytesRef.copyBytes(iter.bytes);\n      frozenSet.add(new Term(iter.field(), bytesRef.toBytesRef()));\n    }\n    assertEquals(uniqueValues, frozenSet);\n    assertEquals(\"num deletes must be 0 after freeze\", 0, queue\n        .numGlobalTermDeletes());\n  }\n\n","sourceOld":"  public void testUpdateDelteSlices() {\n    DocumentsWriterDeleteQueue queue = new DocumentsWriterDeleteQueue();\n    final int size = 200 + random().nextInt(500) * RANDOM_MULTIPLIER;\n    Integer[] ids = new Integer[size];\n    for (int i = 0; i < ids.length; i++) {\n      ids[i] = random().nextInt();\n    }\n    DeleteSlice slice1 = queue.newSlice();\n    DeleteSlice slice2 = queue.newSlice();\n    BufferedUpdates bd1 = new BufferedUpdates();\n    BufferedUpdates bd2 = new BufferedUpdates();\n    int last1 = 0;\n    int last2 = 0;\n    Set<Term> uniqueValues = new HashSet<>();\n    for (int j = 0; j < ids.length; j++) {\n      Integer i = ids[j];\n      // create an array here since we compare identity below against tailItem\n      Term[] term = new Term[] {new Term(\"id\", i.toString())};\n      uniqueValues.add(term[0]);\n      queue.addDelete(term);\n      if (random().nextInt(20) == 0 || j == ids.length - 1) {\n        queue.updateSlice(slice1);\n        assertTrue(slice1.isTailItem(term));\n        slice1.apply(bd1, j);\n        assertAllBetween(last1, j, bd1, ids);\n        last1 = j + 1;\n      }\n      if (random().nextInt(10) == 5 || j == ids.length - 1) {\n        queue.updateSlice(slice2);\n        assertTrue(slice2.isTailItem(term));\n        slice2.apply(bd2, j);\n        assertAllBetween(last2, j, bd2, ids);\n        last2 = j + 1;\n      }\n      assertEquals(j+1, queue.numGlobalTermDeletes());\n    }\n    assertEquals(uniqueValues, bd1.terms.keySet());\n    assertEquals(uniqueValues, bd2.terms.keySet());\n    HashSet<Term> frozenSet = new HashSet<>();\n    BytesRefBuilder bytesRef = new BytesRefBuilder();\n    TermIterator iter = queue.freezeGlobalBuffer(null).termIterator();\n    while (iter.next() != null) {\n      bytesRef.copyBytes(iter.bytes);\n      frozenSet.add(new Term(iter.field(), bytesRef.toBytesRef()));\n    }\n    assertEquals(uniqueValues, frozenSet);\n    assertEquals(\"num deletes must be 0 after freeze\", 0, queue\n        .numGlobalTermDeletes());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4cce5816ef15a48a0bc11e5d400497ee4301dd3b","date":1476991456,"type":3,"author":"Kevin Risden","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDocumentsWriterDeleteQueue#testUpdateDelteSlices().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDocumentsWriterDeleteQueue#testUpdateDelteSlices().mjava","sourceNew":"  public void testUpdateDelteSlices() {\n    DocumentsWriterDeleteQueue queue = new DocumentsWriterDeleteQueue();\n    final int size = 200 + random().nextInt(500) * RANDOM_MULTIPLIER;\n    Integer[] ids = new Integer[size];\n    for (int i = 0; i < ids.length; i++) {\n      ids[i] = random().nextInt();\n    }\n    DeleteSlice slice1 = queue.newSlice();\n    DeleteSlice slice2 = queue.newSlice();\n    BufferedUpdates bd1 = new BufferedUpdates(\"bd1\");\n    BufferedUpdates bd2 = new BufferedUpdates(\"bd2\");\n    int last1 = 0;\n    int last2 = 0;\n    Set<Term> uniqueValues = new HashSet<>();\n    for (int j = 0; j < ids.length; j++) {\n      Integer i = ids[j];\n      // create an array here since we compare identity below against tailItem\n      Term[] term = new Term[] {new Term(\"id\", i.toString())};\n      uniqueValues.add(term[0]);\n      queue.addDelete(term);\n      if (random().nextInt(20) == 0 || j == ids.length - 1) {\n        queue.updateSlice(slice1);\n        assertTrue(slice1.isTailItem(term));\n        slice1.apply(bd1, j);\n        assertAllBetween(last1, j, bd1, ids);\n        last1 = j + 1;\n      }\n      if (random().nextInt(10) == 5 || j == ids.length - 1) {\n        queue.updateSlice(slice2);\n        assertTrue(slice2.isTailItem(term));\n        slice2.apply(bd2, j);\n        assertAllBetween(last2, j, bd2, ids);\n        last2 = j + 1;\n      }\n      assertEquals(j+1, queue.numGlobalTermDeletes());\n    }\n    assertEquals(uniqueValues, bd1.terms.keySet());\n    assertEquals(uniqueValues, bd2.terms.keySet());\n    HashSet<Term> frozenSet = new HashSet<>();\n    BytesRefBuilder bytesRef = new BytesRefBuilder();\n    TermIterator iter = queue.freezeGlobalBuffer(null).termIterator();\n    while (iter.next() != null) {\n      bytesRef.copyBytes(iter.bytes);\n      frozenSet.add(new Term(iter.field(), bytesRef.toBytesRef()));\n    }\n    assertEquals(uniqueValues, frozenSet);\n    assertEquals(\"num deletes must be 0 after freeze\", 0, queue\n        .numGlobalTermDeletes());\n  }\n\n","sourceOld":"  public void testUpdateDelteSlices() {\n    DocumentsWriterDeleteQueue queue = new DocumentsWriterDeleteQueue();\n    final int size = 200 + random().nextInt(500) * RANDOM_MULTIPLIER;\n    Integer[] ids = new Integer[size];\n    for (int i = 0; i < ids.length; i++) {\n      ids[i] = random().nextInt();\n    }\n    DeleteSlice slice1 = queue.newSlice();\n    DeleteSlice slice2 = queue.newSlice();\n    BufferedUpdates bd1 = new BufferedUpdates();\n    BufferedUpdates bd2 = new BufferedUpdates();\n    int last1 = 0;\n    int last2 = 0;\n    Set<Term> uniqueValues = new HashSet<>();\n    for (int j = 0; j < ids.length; j++) {\n      Integer i = ids[j];\n      // create an array here since we compare identity below against tailItem\n      Term[] term = new Term[] {new Term(\"id\", i.toString())};\n      uniqueValues.add(term[0]);\n      queue.addDelete(term);\n      if (random().nextInt(20) == 0 || j == ids.length - 1) {\n        queue.updateSlice(slice1);\n        assertTrue(slice1.isTailItem(term));\n        slice1.apply(bd1, j);\n        assertAllBetween(last1, j, bd1, ids);\n        last1 = j + 1;\n      }\n      if (random().nextInt(10) == 5 || j == ids.length - 1) {\n        queue.updateSlice(slice2);\n        assertTrue(slice2.isTailItem(term));\n        slice2.apply(bd2, j);\n        assertAllBetween(last2, j, bd2, ids);\n        last2 = j + 1;\n      }\n      assertEquals(j+1, queue.numGlobalTermDeletes());\n    }\n    assertEquals(uniqueValues, bd1.terms.keySet());\n    assertEquals(uniqueValues, bd2.terms.keySet());\n    HashSet<Term> frozenSet = new HashSet<>();\n    BytesRefBuilder bytesRef = new BytesRefBuilder();\n    TermIterator iter = queue.freezeGlobalBuffer(null).termIterator();\n    while (iter.next() != null) {\n      bytesRef.copyBytes(iter.bytes);\n      frozenSet.add(new Term(iter.field(), bytesRef.toBytesRef()));\n    }\n    assertEquals(uniqueValues, frozenSet);\n    assertEquals(\"num deletes must be 0 after freeze\", 0, queue\n        .numGlobalTermDeletes());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f4363cd33f6eff7fb4753574a441e2d18c1022a4","date":1498067235,"type":3,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDocumentsWriterDeleteQueue#testUpdateDelteSlices().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDocumentsWriterDeleteQueue#testUpdateDelteSlices().mjava","sourceNew":"  public void testUpdateDelteSlices() throws Exception {\n    DocumentsWriterDeleteQueue queue = new DocumentsWriterDeleteQueue(null);\n    final int size = 200 + random().nextInt(500) * RANDOM_MULTIPLIER;\n    Integer[] ids = new Integer[size];\n    for (int i = 0; i < ids.length; i++) {\n      ids[i] = random().nextInt();\n    }\n    DeleteSlice slice1 = queue.newSlice();\n    DeleteSlice slice2 = queue.newSlice();\n    BufferedUpdates bd1 = new BufferedUpdates(\"bd1\");\n    BufferedUpdates bd2 = new BufferedUpdates(\"bd2\");\n    int last1 = 0;\n    int last2 = 0;\n    Set<Term> uniqueValues = new HashSet<>();\n    for (int j = 0; j < ids.length; j++) {\n      Integer i = ids[j];\n      // create an array here since we compare identity below against tailItem\n      Term[] term = new Term[] {new Term(\"id\", i.toString())};\n      uniqueValues.add(term[0]);\n      queue.addDelete(term);\n      if (random().nextInt(20) == 0 || j == ids.length - 1) {\n        queue.updateSlice(slice1);\n        assertTrue(slice1.isTailItem(term));\n        slice1.apply(bd1, j);\n        assertAllBetween(last1, j, bd1, ids);\n        last1 = j + 1;\n      }\n      if (random().nextInt(10) == 5 || j == ids.length - 1) {\n        queue.updateSlice(slice2);\n        assertTrue(slice2.isTailItem(term));\n        slice2.apply(bd2, j);\n        assertAllBetween(last2, j, bd2, ids);\n        last2 = j + 1;\n      }\n      assertEquals(j+1, queue.numGlobalTermDeletes());\n    }\n    assertEquals(uniqueValues, bd1.deleteTerms.keySet());\n    assertEquals(uniqueValues, bd2.deleteTerms.keySet());\n    HashSet<Term> frozenSet = new HashSet<>();\n    BytesRefBuilder bytesRef = new BytesRefBuilder();\n    TermIterator iter = queue.freezeGlobalBuffer(null).deleteTerms.iterator();\n    while (iter.next() != null) {\n      bytesRef.copyBytes(iter.bytes);\n      frozenSet.add(new Term(iter.field(), bytesRef.toBytesRef()));\n    }\n    assertEquals(uniqueValues, frozenSet);\n    assertEquals(\"num deletes must be 0 after freeze\", 0, queue\n        .numGlobalTermDeletes());\n  }\n\n","sourceOld":"  public void testUpdateDelteSlices() {\n    DocumentsWriterDeleteQueue queue = new DocumentsWriterDeleteQueue();\n    final int size = 200 + random().nextInt(500) * RANDOM_MULTIPLIER;\n    Integer[] ids = new Integer[size];\n    for (int i = 0; i < ids.length; i++) {\n      ids[i] = random().nextInt();\n    }\n    DeleteSlice slice1 = queue.newSlice();\n    DeleteSlice slice2 = queue.newSlice();\n    BufferedUpdates bd1 = new BufferedUpdates(\"bd1\");\n    BufferedUpdates bd2 = new BufferedUpdates(\"bd2\");\n    int last1 = 0;\n    int last2 = 0;\n    Set<Term> uniqueValues = new HashSet<>();\n    for (int j = 0; j < ids.length; j++) {\n      Integer i = ids[j];\n      // create an array here since we compare identity below against tailItem\n      Term[] term = new Term[] {new Term(\"id\", i.toString())};\n      uniqueValues.add(term[0]);\n      queue.addDelete(term);\n      if (random().nextInt(20) == 0 || j == ids.length - 1) {\n        queue.updateSlice(slice1);\n        assertTrue(slice1.isTailItem(term));\n        slice1.apply(bd1, j);\n        assertAllBetween(last1, j, bd1, ids);\n        last1 = j + 1;\n      }\n      if (random().nextInt(10) == 5 || j == ids.length - 1) {\n        queue.updateSlice(slice2);\n        assertTrue(slice2.isTailItem(term));\n        slice2.apply(bd2, j);\n        assertAllBetween(last2, j, bd2, ids);\n        last2 = j + 1;\n      }\n      assertEquals(j+1, queue.numGlobalTermDeletes());\n    }\n    assertEquals(uniqueValues, bd1.terms.keySet());\n    assertEquals(uniqueValues, bd2.terms.keySet());\n    HashSet<Term> frozenSet = new HashSet<>();\n    BytesRefBuilder bytesRef = new BytesRefBuilder();\n    TermIterator iter = queue.freezeGlobalBuffer(null).termIterator();\n    while (iter.next() != null) {\n      bytesRef.copyBytes(iter.bytes);\n      frozenSet.add(new Term(iter.field(), bytesRef.toBytesRef()));\n    }\n    assertEquals(uniqueValues, frozenSet);\n    assertEquals(\"num deletes must be 0 after freeze\", 0, queue\n        .numGlobalTermDeletes());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b7dfa64bc2074fb87d0ca70095a644c1ead107e1","date":1498356339,"type":3,"author":"Shalin Shekhar Mangar","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDocumentsWriterDeleteQueue#testUpdateDelteSlices().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDocumentsWriterDeleteQueue#testUpdateDelteSlices().mjava","sourceNew":"  public void testUpdateDelteSlices() throws Exception {\n    DocumentsWriterDeleteQueue queue = new DocumentsWriterDeleteQueue(null);\n    final int size = 200 + random().nextInt(500) * RANDOM_MULTIPLIER;\n    Integer[] ids = new Integer[size];\n    for (int i = 0; i < ids.length; i++) {\n      ids[i] = random().nextInt();\n    }\n    DeleteSlice slice1 = queue.newSlice();\n    DeleteSlice slice2 = queue.newSlice();\n    BufferedUpdates bd1 = new BufferedUpdates(\"bd1\");\n    BufferedUpdates bd2 = new BufferedUpdates(\"bd2\");\n    int last1 = 0;\n    int last2 = 0;\n    Set<Term> uniqueValues = new HashSet<>();\n    for (int j = 0; j < ids.length; j++) {\n      Integer i = ids[j];\n      // create an array here since we compare identity below against tailItem\n      Term[] term = new Term[] {new Term(\"id\", i.toString())};\n      uniqueValues.add(term[0]);\n      queue.addDelete(term);\n      if (random().nextInt(20) == 0 || j == ids.length - 1) {\n        queue.updateSlice(slice1);\n        assertTrue(slice1.isTailItem(term));\n        slice1.apply(bd1, j);\n        assertAllBetween(last1, j, bd1, ids);\n        last1 = j + 1;\n      }\n      if (random().nextInt(10) == 5 || j == ids.length - 1) {\n        queue.updateSlice(slice2);\n        assertTrue(slice2.isTailItem(term));\n        slice2.apply(bd2, j);\n        assertAllBetween(last2, j, bd2, ids);\n        last2 = j + 1;\n      }\n      assertEquals(j+1, queue.numGlobalTermDeletes());\n    }\n    assertEquals(uniqueValues, bd1.deleteTerms.keySet());\n    assertEquals(uniqueValues, bd2.deleteTerms.keySet());\n    HashSet<Term> frozenSet = new HashSet<>();\n    BytesRefBuilder bytesRef = new BytesRefBuilder();\n    TermIterator iter = queue.freezeGlobalBuffer(null).deleteTerms.iterator();\n    while (iter.next() != null) {\n      bytesRef.copyBytes(iter.bytes);\n      frozenSet.add(new Term(iter.field(), bytesRef.toBytesRef()));\n    }\n    assertEquals(uniqueValues, frozenSet);\n    assertEquals(\"num deletes must be 0 after freeze\", 0, queue\n        .numGlobalTermDeletes());\n  }\n\n","sourceOld":"  public void testUpdateDelteSlices() {\n    DocumentsWriterDeleteQueue queue = new DocumentsWriterDeleteQueue();\n    final int size = 200 + random().nextInt(500) * RANDOM_MULTIPLIER;\n    Integer[] ids = new Integer[size];\n    for (int i = 0; i < ids.length; i++) {\n      ids[i] = random().nextInt();\n    }\n    DeleteSlice slice1 = queue.newSlice();\n    DeleteSlice slice2 = queue.newSlice();\n    BufferedUpdates bd1 = new BufferedUpdates(\"bd1\");\n    BufferedUpdates bd2 = new BufferedUpdates(\"bd2\");\n    int last1 = 0;\n    int last2 = 0;\n    Set<Term> uniqueValues = new HashSet<>();\n    for (int j = 0; j < ids.length; j++) {\n      Integer i = ids[j];\n      // create an array here since we compare identity below against tailItem\n      Term[] term = new Term[] {new Term(\"id\", i.toString())};\n      uniqueValues.add(term[0]);\n      queue.addDelete(term);\n      if (random().nextInt(20) == 0 || j == ids.length - 1) {\n        queue.updateSlice(slice1);\n        assertTrue(slice1.isTailItem(term));\n        slice1.apply(bd1, j);\n        assertAllBetween(last1, j, bd1, ids);\n        last1 = j + 1;\n      }\n      if (random().nextInt(10) == 5 || j == ids.length - 1) {\n        queue.updateSlice(slice2);\n        assertTrue(slice2.isTailItem(term));\n        slice2.apply(bd2, j);\n        assertAllBetween(last2, j, bd2, ids);\n        last2 = j + 1;\n      }\n      assertEquals(j+1, queue.numGlobalTermDeletes());\n    }\n    assertEquals(uniqueValues, bd1.terms.keySet());\n    assertEquals(uniqueValues, bd2.terms.keySet());\n    HashSet<Term> frozenSet = new HashSet<>();\n    BytesRefBuilder bytesRef = new BytesRefBuilder();\n    TermIterator iter = queue.freezeGlobalBuffer(null).termIterator();\n    while (iter.next() != null) {\n      bytesRef.copyBytes(iter.bytes);\n      frozenSet.add(new Term(iter.field(), bytesRef.toBytesRef()));\n    }\n    assertEquals(uniqueValues, frozenSet);\n    assertEquals(\"num deletes must be 0 after freeze\", 0, queue\n        .numGlobalTermDeletes());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"28288370235ed02234a64753cdbf0c6ec096304a","date":1498726817,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDocumentsWriterDeleteQueue#testUpdateDelteSlices().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDocumentsWriterDeleteQueue#testUpdateDelteSlices().mjava","sourceNew":"  public void testUpdateDelteSlices() throws Exception {\n    DocumentsWriterDeleteQueue queue = new DocumentsWriterDeleteQueue(null);\n    final int size = 200 + random().nextInt(500) * RANDOM_MULTIPLIER;\n    Integer[] ids = new Integer[size];\n    for (int i = 0; i < ids.length; i++) {\n      ids[i] = random().nextInt();\n    }\n    DeleteSlice slice1 = queue.newSlice();\n    DeleteSlice slice2 = queue.newSlice();\n    BufferedUpdates bd1 = new BufferedUpdates(\"bd1\");\n    BufferedUpdates bd2 = new BufferedUpdates(\"bd2\");\n    int last1 = 0;\n    int last2 = 0;\n    Set<Term> uniqueValues = new HashSet<>();\n    for (int j = 0; j < ids.length; j++) {\n      Integer i = ids[j];\n      // create an array here since we compare identity below against tailItem\n      Term[] term = new Term[] {new Term(\"id\", i.toString())};\n      uniqueValues.add(term[0]);\n      queue.addDelete(term);\n      if (random().nextInt(20) == 0 || j == ids.length - 1) {\n        queue.updateSlice(slice1);\n        assertTrue(slice1.isTailItem(term));\n        slice1.apply(bd1, j);\n        assertAllBetween(last1, j, bd1, ids);\n        last1 = j + 1;\n      }\n      if (random().nextInt(10) == 5 || j == ids.length - 1) {\n        queue.updateSlice(slice2);\n        assertTrue(slice2.isTailItem(term));\n        slice2.apply(bd2, j);\n        assertAllBetween(last2, j, bd2, ids);\n        last2 = j + 1;\n      }\n      assertEquals(j+1, queue.numGlobalTermDeletes());\n    }\n    assertEquals(uniqueValues, bd1.deleteTerms.keySet());\n    assertEquals(uniqueValues, bd2.deleteTerms.keySet());\n    HashSet<Term> frozenSet = new HashSet<>();\n    BytesRefBuilder bytesRef = new BytesRefBuilder();\n    TermIterator iter = queue.freezeGlobalBuffer(null).deleteTerms.iterator();\n    while (iter.next() != null) {\n      bytesRef.copyBytes(iter.bytes);\n      frozenSet.add(new Term(iter.field(), bytesRef.toBytesRef()));\n    }\n    assertEquals(uniqueValues, frozenSet);\n    assertEquals(\"num deletes must be 0 after freeze\", 0, queue\n        .numGlobalTermDeletes());\n  }\n\n","sourceOld":"  public void testUpdateDelteSlices() {\n    DocumentsWriterDeleteQueue queue = new DocumentsWriterDeleteQueue();\n    final int size = 200 + random().nextInt(500) * RANDOM_MULTIPLIER;\n    Integer[] ids = new Integer[size];\n    for (int i = 0; i < ids.length; i++) {\n      ids[i] = random().nextInt();\n    }\n    DeleteSlice slice1 = queue.newSlice();\n    DeleteSlice slice2 = queue.newSlice();\n    BufferedUpdates bd1 = new BufferedUpdates(\"bd1\");\n    BufferedUpdates bd2 = new BufferedUpdates(\"bd2\");\n    int last1 = 0;\n    int last2 = 0;\n    Set<Term> uniqueValues = new HashSet<>();\n    for (int j = 0; j < ids.length; j++) {\n      Integer i = ids[j];\n      // create an array here since we compare identity below against tailItem\n      Term[] term = new Term[] {new Term(\"id\", i.toString())};\n      uniqueValues.add(term[0]);\n      queue.addDelete(term);\n      if (random().nextInt(20) == 0 || j == ids.length - 1) {\n        queue.updateSlice(slice1);\n        assertTrue(slice1.isTailItem(term));\n        slice1.apply(bd1, j);\n        assertAllBetween(last1, j, bd1, ids);\n        last1 = j + 1;\n      }\n      if (random().nextInt(10) == 5 || j == ids.length - 1) {\n        queue.updateSlice(slice2);\n        assertTrue(slice2.isTailItem(term));\n        slice2.apply(bd2, j);\n        assertAllBetween(last2, j, bd2, ids);\n        last2 = j + 1;\n      }\n      assertEquals(j+1, queue.numGlobalTermDeletes());\n    }\n    assertEquals(uniqueValues, bd1.terms.keySet());\n    assertEquals(uniqueValues, bd2.terms.keySet());\n    HashSet<Term> frozenSet = new HashSet<>();\n    BytesRefBuilder bytesRef = new BytesRefBuilder();\n    TermIterator iter = queue.freezeGlobalBuffer(null).termIterator();\n    while (iter.next() != null) {\n      bytesRef.copyBytes(iter.bytes);\n      frozenSet.add(new Term(iter.field(), bytesRef.toBytesRef()));\n    }\n    assertEquals(uniqueValues, frozenSet);\n    assertEquals(\"num deletes must be 0 after freeze\", 0, queue\n        .numGlobalTermDeletes());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["73b0a97ef3bd519a5e43398ea9eabe6eed97f6b0"],"73b0a97ef3bd519a5e43398ea9eabe6eed97f6b0":["50301463ed2a4d5eeea61244ab806b2064df022e"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"f4363cd33f6eff7fb4753574a441e2d18c1022a4":["191128ac5b85671b1671e2c857437694283b6ebf"],"6483e4260c08168709c02238ae083a51519a28dd":["258f227b48a4dbfc180f6ec70f172469d6a2bef8","b40b1a0adcc6bdcda63b0fbd75dfa2ddd8777e77"],"7dc6ea5fd38ce7aa8f36b3bac8b757da77f31d50":["634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"191128ac5b85671b1671e2c857437694283b6ebf":["258f227b48a4dbfc180f6ec70f172469d6a2bef8","6483e4260c08168709c02238ae083a51519a28dd"],"b7dfa64bc2074fb87d0ca70095a644c1ead107e1":["191128ac5b85671b1671e2c857437694283b6ebf","f4363cd33f6eff7fb4753574a441e2d18c1022a4"],"b40b1a0adcc6bdcda63b0fbd75dfa2ddd8777e77":["258f227b48a4dbfc180f6ec70f172469d6a2bef8","122251c49e5a9fa95f056ea257ae3ab452099fc7"],"28288370235ed02234a64753cdbf0c6ec096304a":["191128ac5b85671b1671e2c857437694283b6ebf","f4363cd33f6eff7fb4753574a441e2d18c1022a4"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["258f227b48a4dbfc180f6ec70f172469d6a2bef8","191128ac5b85671b1671e2c857437694283b6ebf"],"258f227b48a4dbfc180f6ec70f172469d6a2bef8":["7e4c214a1f904dde76f5611b56d4081533055b3b"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"7e4c214a1f904dde76f5611b56d4081533055b3b":["7dc6ea5fd38ce7aa8f36b3bac8b757da77f31d50"],"629c38c4ae4e303d0617e05fbfe508140b32f0a3":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"50301463ed2a4d5eeea61244ab806b2064df022e":["629c38c4ae4e303d0617e05fbfe508140b32f0a3"],"122251c49e5a9fa95f056ea257ae3ab452099fc7":["258f227b48a4dbfc180f6ec70f172469d6a2bef8"],"ef0d8a69209261514c5739c770bba706c2308450":["629c38c4ae4e303d0617e05fbfe508140b32f0a3","50301463ed2a4d5eeea61244ab806b2064df022e"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["28288370235ed02234a64753cdbf0c6ec096304a"]},"commit2Childs":{"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["7dc6ea5fd38ce7aa8f36b3bac8b757da77f31d50"],"73b0a97ef3bd519a5e43398ea9eabe6eed97f6b0":["634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["629c38c4ae4e303d0617e05fbfe508140b32f0a3"],"f4363cd33f6eff7fb4753574a441e2d18c1022a4":["b7dfa64bc2074fb87d0ca70095a644c1ead107e1","28288370235ed02234a64753cdbf0c6ec096304a"],"6483e4260c08168709c02238ae083a51519a28dd":["191128ac5b85671b1671e2c857437694283b6ebf"],"191128ac5b85671b1671e2c857437694283b6ebf":["f4363cd33f6eff7fb4753574a441e2d18c1022a4","b7dfa64bc2074fb87d0ca70095a644c1ead107e1","28288370235ed02234a64753cdbf0c6ec096304a","4cce5816ef15a48a0bc11e5d400497ee4301dd3b"],"7dc6ea5fd38ce7aa8f36b3bac8b757da77f31d50":["7e4c214a1f904dde76f5611b56d4081533055b3b"],"b7dfa64bc2074fb87d0ca70095a644c1ead107e1":[],"b40b1a0adcc6bdcda63b0fbd75dfa2ddd8777e77":["6483e4260c08168709c02238ae083a51519a28dd"],"28288370235ed02234a64753cdbf0c6ec096304a":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":[],"258f227b48a4dbfc180f6ec70f172469d6a2bef8":["6483e4260c08168709c02238ae083a51519a28dd","191128ac5b85671b1671e2c857437694283b6ebf","b40b1a0adcc6bdcda63b0fbd75dfa2ddd8777e77","4cce5816ef15a48a0bc11e5d400497ee4301dd3b","122251c49e5a9fa95f056ea257ae3ab452099fc7"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"7e4c214a1f904dde76f5611b56d4081533055b3b":["258f227b48a4dbfc180f6ec70f172469d6a2bef8"],"629c38c4ae4e303d0617e05fbfe508140b32f0a3":["50301463ed2a4d5eeea61244ab806b2064df022e","ef0d8a69209261514c5739c770bba706c2308450"],"50301463ed2a4d5eeea61244ab806b2064df022e":["73b0a97ef3bd519a5e43398ea9eabe6eed97f6b0","ef0d8a69209261514c5739c770bba706c2308450"],"122251c49e5a9fa95f056ea257ae3ab452099fc7":["b40b1a0adcc6bdcda63b0fbd75dfa2ddd8777e77"],"ef0d8a69209261514c5739c770bba706c2308450":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["b7dfa64bc2074fb87d0ca70095a644c1ead107e1","4cce5816ef15a48a0bc11e5d400497ee4301dd3b","ef0d8a69209261514c5739c770bba706c2308450","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}