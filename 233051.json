{"path":"lucene/core/src/java/org/apache/lucene/codecs/temp/TempBlockTermsWriter.TermsWriter#flushTermsBlock(int,int).mjava","commits":[{"id":"a10f5f1c7f2dcd4a60664dd5c34d803794e023c9","date":1371380031,"type":0,"author":"Han Jiang","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/temp/TempBlockTermsWriter.TermsWriter#flushTermsBlock(int,int).mjava","pathOld":"/dev/null","sourceNew":"    /** Flush count terms starting at start \"backwards\", as a\n     *  block. start is a negative offset from the end of the\n     *  terms stack, ie bigger start means further back in\n     *  the stack. */\n    void flushTermsBlock(int start, int count) throws IOException {\n      if (count == 0) {\n        out.writeByte((byte) 0);\n        return;\n      }\n\n      assert start <= pendingMetaData.size();\n      assert count <= start;\n\n      final int limit = pendingMetaData.size() - start + count;\n      final int size = postingsWriter.longsSize(fieldInfo);\n\n      long[] lastLongs = new long[size];\n      Arrays.fill(lastLongs, 0);\n      for(int idx=limit-count; idx<limit; idx++) {\n        PendingMetaData meta = pendingMetaData.get(idx);\n        for (int pos = 0; pos < size; pos++) {\n          if (meta.longs[pos] < 0) {\n            // nocommit: this -1 padding is implicit (maybe we need javadocs, or better\n            // an API to tell PostingsBase that: every time you meet a 'don't care', just put -1 on it?\n            meta.longs[pos] = lastLongs[pos];\n          }\n          bytesWriter3.writeVLong(meta.longs[pos] - lastLongs[pos]);\n        }\n        lastLongs = meta.longs;\n        meta.bytesWriter.writeTo(bytesWriter3);\n      }\n\n      out.writeVInt((int) bytesWriter3.getFilePointer());\n      bytesWriter3.writeTo(out);\n      bytesWriter3.reset();\n\n      // Remove the terms we just wrote:\n      pendingMetaData.subList(limit-count, limit).clear();\n    }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8f9e2db1c8ec255bc436c6cf0a92979efdfe2f90","date":1371385497,"type":3,"author":"Han Jiang","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/temp/TempBlockTermsWriter.TermsWriter#flushTermsBlock(int,int).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/temp/TempBlockTermsWriter.TermsWriter#flushTermsBlock(int,int).mjava","sourceNew":"    /** Flush count terms starting at start \"backwards\", as a\n     *  block. start is a negative offset from the end of the\n     *  terms stack, ie bigger start means further back in\n     *  the stack. */\n    void flushTermsBlock(int start, int count) throws IOException {\n      if (count == 0) {\n        out.writeByte((byte) 0);\n        return;\n      }\n\n      assert start <= pendingMetaData.size();\n      assert count <= start;\n\n      final int limit = pendingMetaData.size() - start + count;\n      final int size = postingsWriter.longsSize();\n\n      long[] lastLongs = new long[size];\n      Arrays.fill(lastLongs, 0);\n      for(int idx=limit-count; idx<limit; idx++) {\n        PendingMetaData meta = pendingMetaData.get(idx);\n        for (int pos = 0; pos < size; pos++) {\n          assert meta.longs[pos] >= 0;\n          bytesWriter3.writeVLong(meta.longs[pos] - lastLongs[pos]);\n        }\n        lastLongs = meta.longs;\n        meta.bytesWriter.writeTo(bytesWriter3);\n      }\n\n      out.writeVInt((int) bytesWriter3.getFilePointer());\n      bytesWriter3.writeTo(out);\n      bytesWriter3.reset();\n\n      // Remove the terms we just wrote:\n      pendingMetaData.subList(limit-count, limit).clear();\n    }\n\n","sourceOld":"    /** Flush count terms starting at start \"backwards\", as a\n     *  block. start is a negative offset from the end of the\n     *  terms stack, ie bigger start means further back in\n     *  the stack. */\n    void flushTermsBlock(int start, int count) throws IOException {\n      if (count == 0) {\n        out.writeByte((byte) 0);\n        return;\n      }\n\n      assert start <= pendingMetaData.size();\n      assert count <= start;\n\n      final int limit = pendingMetaData.size() - start + count;\n      final int size = postingsWriter.longsSize(fieldInfo);\n\n      long[] lastLongs = new long[size];\n      Arrays.fill(lastLongs, 0);\n      for(int idx=limit-count; idx<limit; idx++) {\n        PendingMetaData meta = pendingMetaData.get(idx);\n        for (int pos = 0; pos < size; pos++) {\n          if (meta.longs[pos] < 0) {\n            // nocommit: this -1 padding is implicit (maybe we need javadocs, or better\n            // an API to tell PostingsBase that: every time you meet a 'don't care', just put -1 on it?\n            meta.longs[pos] = lastLongs[pos];\n          }\n          bytesWriter3.writeVLong(meta.longs[pos] - lastLongs[pos]);\n        }\n        lastLongs = meta.longs;\n        meta.bytesWriter.writeTo(bytesWriter3);\n      }\n\n      out.writeVInt((int) bytesWriter3.getFilePointer());\n      bytesWriter3.writeTo(out);\n      bytesWriter3.reset();\n\n      // Remove the terms we just wrote:\n      pendingMetaData.subList(limit-count, limit).clear();\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9fdc7abadfc0d660ccad65a5329c3e0abea4e30c","date":1371387989,"type":4,"author":"Han Jiang","isMerge":false,"pathNew":"/dev/null","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/temp/TempBlockTermsWriter.TermsWriter#flushTermsBlock(int,int).mjava","sourceNew":null,"sourceOld":"    /** Flush count terms starting at start \"backwards\", as a\n     *  block. start is a negative offset from the end of the\n     *  terms stack, ie bigger start means further back in\n     *  the stack. */\n    void flushTermsBlock(int start, int count) throws IOException {\n      if (count == 0) {\n        out.writeByte((byte) 0);\n        return;\n      }\n\n      assert start <= pendingMetaData.size();\n      assert count <= start;\n\n      final int limit = pendingMetaData.size() - start + count;\n      final int size = postingsWriter.longsSize();\n\n      long[] lastLongs = new long[size];\n      Arrays.fill(lastLongs, 0);\n      for(int idx=limit-count; idx<limit; idx++) {\n        PendingMetaData meta = pendingMetaData.get(idx);\n        for (int pos = 0; pos < size; pos++) {\n          assert meta.longs[pos] >= 0;\n          bytesWriter3.writeVLong(meta.longs[pos] - lastLongs[pos]);\n        }\n        lastLongs = meta.longs;\n        meta.bytesWriter.writeTo(bytesWriter3);\n      }\n\n      out.writeVInt((int) bytesWriter3.getFilePointer());\n      bytesWriter3.writeTo(out);\n      bytesWriter3.reset();\n\n      // Remove the terms we just wrote:\n      pendingMetaData.subList(limit-count, limit).clear();\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"9fdc7abadfc0d660ccad65a5329c3e0abea4e30c":["8f9e2db1c8ec255bc436c6cf0a92979efdfe2f90"],"8f9e2db1c8ec255bc436c6cf0a92979efdfe2f90":["a10f5f1c7f2dcd4a60664dd5c34d803794e023c9"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"a10f5f1c7f2dcd4a60664dd5c34d803794e023c9":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"9fdc7abadfc0d660ccad65a5329c3e0abea4e30c":[],"8f9e2db1c8ec255bc436c6cf0a92979efdfe2f90":["9fdc7abadfc0d660ccad65a5329c3e0abea4e30c"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["a10f5f1c7f2dcd4a60664dd5c34d803794e023c9","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a10f5f1c7f2dcd4a60664dd5c34d803794e023c9":["8f9e2db1c8ec255bc436c6cf0a92979efdfe2f90"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["9fdc7abadfc0d660ccad65a5329c3e0abea4e30c","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}