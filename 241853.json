{"path":"lucene/src/test/org/apache/lucene/index/TestAddIndexes#testSimpleCaseCustomCodecProvider().mjava","commits":[{"id":"a493e6d0c3ad86bd55c0a1360d110142e948f2bd","date":1289406991,"type":0,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestAddIndexes#testSimpleCaseCustomCodecProvider().mjava","pathOld":"/dev/null","sourceNew":"  public void testSimpleCaseCustomCodecProvider() throws IOException {\n    // main directory\n    Directory dir = newDirectory();\n    // two auxiliary directories\n    Directory aux = newDirectory();\n    Directory aux2 = newDirectory();\n    CodecProvider provider = new MockCodecProvider();\n    IndexWriter writer = null;\n\n    writer = newWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT,\n        new MockAnalyzer()).setOpenMode(OpenMode.CREATE).setCodecProvider(\n        provider));\n    // add 100 documents\n    addDocs3(writer, 100);\n    assertEquals(100, writer.maxDoc());\n    writer.commit();\n    writer.close();\n    _TestUtil.checkIndex(dir, provider);\n\n    writer = newWriter(aux, newIndexWriterConfig(TEST_VERSION_CURRENT,\n        new MockAnalyzer()).setOpenMode(OpenMode.CREATE).setCodecProvider(\n        provider));\n    ((LogMergePolicy) writer.getConfig().getMergePolicy())\n        .setUseCompoundFile(false); // use one without a compound file\n    ((LogMergePolicy) writer.getConfig().getMergePolicy())\n        .setUseCompoundDocStore(false); // use one without a compound file\n    // add 40 documents in separate files\n    addDocs(writer, 40);\n    assertEquals(40, writer.maxDoc());\n    writer.commit();\n    writer.close();\n\n    writer = newWriter(aux2, newIndexWriterConfig(TEST_VERSION_CURRENT,\n        new MockAnalyzer()).setOpenMode(OpenMode.CREATE).setCodecProvider(\n        provider));\n    // add 40 documents in compound files\n    addDocs2(writer, 50);\n    assertEquals(50, writer.maxDoc());\n    writer.commit();\n    writer.close();\n\n    // test doc count before segments are merged\n    writer = newWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT,\n        new MockAnalyzer()).setOpenMode(OpenMode.APPEND).setCodecProvider(\n        provider));\n    assertEquals(100, writer.maxDoc());\n    writer.addIndexes(new Directory[] { aux, aux2 });\n    assertEquals(190, writer.maxDoc());\n    writer.close();\n    _TestUtil.checkIndex(dir, provider);\n\n    dir.close();\n    aux.close();\n    aux2.close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"85a883878c0af761245ab048babc63d099f835f3","date":1289553330,"type":0,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestAddIndexes#testSimpleCaseCustomCodecProvider().mjava","pathOld":"/dev/null","sourceNew":"  public void testSimpleCaseCustomCodecProvider() throws IOException {\n    // main directory\n    Directory dir = newDirectory();\n    // two auxiliary directories\n    Directory aux = newDirectory();\n    Directory aux2 = newDirectory();\n    CodecProvider provider = new MockCodecProvider();\n    IndexWriter writer = null;\n\n    writer = newWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT,\n        new MockAnalyzer()).setOpenMode(OpenMode.CREATE).setCodecProvider(\n        provider));\n    // add 100 documents\n    addDocs3(writer, 100);\n    assertEquals(100, writer.maxDoc());\n    writer.commit();\n    writer.close();\n    _TestUtil.checkIndex(dir, provider);\n\n    writer = newWriter(aux, newIndexWriterConfig(TEST_VERSION_CURRENT,\n        new MockAnalyzer()).setOpenMode(OpenMode.CREATE).setCodecProvider(\n        provider));\n    ((LogMergePolicy) writer.getConfig().getMergePolicy())\n        .setUseCompoundFile(false); // use one without a compound file\n    ((LogMergePolicy) writer.getConfig().getMergePolicy())\n        .setUseCompoundDocStore(false); // use one without a compound file\n    // add 40 documents in separate files\n    addDocs(writer, 40);\n    assertEquals(40, writer.maxDoc());\n    writer.commit();\n    writer.close();\n\n    writer = newWriter(aux2, newIndexWriterConfig(TEST_VERSION_CURRENT,\n        new MockAnalyzer()).setOpenMode(OpenMode.CREATE).setCodecProvider(\n        provider));\n    // add 40 documents in compound files\n    addDocs2(writer, 50);\n    assertEquals(50, writer.maxDoc());\n    writer.commit();\n    writer.close();\n\n    // test doc count before segments are merged\n    writer = newWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT,\n        new MockAnalyzer()).setOpenMode(OpenMode.APPEND).setCodecProvider(\n        provider));\n    assertEquals(100, writer.maxDoc());\n    writer.addIndexes(new Directory[] { aux, aux2 });\n    assertEquals(190, writer.maxDoc());\n    writer.close();\n    _TestUtil.checkIndex(dir, provider);\n\n    dir.close();\n    aux.close();\n    aux2.close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4e8cc373c801e54cec75daf9f52792cb4b17f536","date":1291116159,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestAddIndexes#testSimpleCaseCustomCodecProvider().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestAddIndexes#testSimpleCaseCustomCodecProvider().mjava","sourceNew":"  public void testSimpleCaseCustomCodecProvider() throws IOException {\n    // main directory\n    Directory dir = newDirectory();\n    // two auxiliary directories\n    Directory aux = newDirectory();\n    Directory aux2 = newDirectory();\n    CodecProvider provider = new MockCodecProvider();\n    IndexWriter writer = null;\n\n    writer = newWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT,\n        new MockAnalyzer()).setOpenMode(OpenMode.CREATE).setCodecProvider(\n        provider));\n    // add 100 documents\n    addDocs3(writer, 100);\n    assertEquals(100, writer.maxDoc());\n    writer.commit();\n    writer.close();\n    _TestUtil.checkIndex(dir, provider);\n\n    writer = newWriter(\n        aux,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).\n            setOpenMode(OpenMode.CREATE).\n            setCodecProvider(provider).\n            setMaxBufferedDocs(10).\n            setMergePolicy(newLogMergePolicy(false))\n    );\n    // add 40 documents in separate files\n    addDocs(writer, 40);\n    assertEquals(40, writer.maxDoc());\n    writer.commit();\n    writer.close();\n\n    writer = newWriter(\n        aux2,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).\n            setOpenMode(OpenMode.CREATE).\n            setCodecProvider(provider)\n    );\n    // add 40 documents in compound files\n    addDocs2(writer, 50);\n    assertEquals(50, writer.maxDoc());\n    writer.commit();\n    writer.close();\n\n    // test doc count before segments are merged\n    writer = newWriter(\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).\n            setOpenMode(OpenMode.APPEND).\n            setCodecProvider(provider)\n    );\n    assertEquals(100, writer.maxDoc());\n    writer.addIndexes(aux, aux2);\n    assertEquals(190, writer.maxDoc());\n    writer.close();\n    _TestUtil.checkIndex(dir, provider);\n\n    dir.close();\n    aux.close();\n    aux2.close();\n  }\n\n","sourceOld":"  public void testSimpleCaseCustomCodecProvider() throws IOException {\n    // main directory\n    Directory dir = newDirectory();\n    // two auxiliary directories\n    Directory aux = newDirectory();\n    Directory aux2 = newDirectory();\n    CodecProvider provider = new MockCodecProvider();\n    IndexWriter writer = null;\n\n    writer = newWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT,\n        new MockAnalyzer()).setOpenMode(OpenMode.CREATE).setCodecProvider(\n        provider));\n    // add 100 documents\n    addDocs3(writer, 100);\n    assertEquals(100, writer.maxDoc());\n    writer.commit();\n    writer.close();\n    _TestUtil.checkIndex(dir, provider);\n\n    writer = newWriter(aux, newIndexWriterConfig(TEST_VERSION_CURRENT,\n        new MockAnalyzer()).setOpenMode(OpenMode.CREATE).setCodecProvider(\n        provider));\n    ((LogMergePolicy) writer.getConfig().getMergePolicy())\n        .setUseCompoundFile(false); // use one without a compound file\n    ((LogMergePolicy) writer.getConfig().getMergePolicy())\n        .setUseCompoundDocStore(false); // use one without a compound file\n    // add 40 documents in separate files\n    addDocs(writer, 40);\n    assertEquals(40, writer.maxDoc());\n    writer.commit();\n    writer.close();\n\n    writer = newWriter(aux2, newIndexWriterConfig(TEST_VERSION_CURRENT,\n        new MockAnalyzer()).setOpenMode(OpenMode.CREATE).setCodecProvider(\n        provider));\n    // add 40 documents in compound files\n    addDocs2(writer, 50);\n    assertEquals(50, writer.maxDoc());\n    writer.commit();\n    writer.close();\n\n    // test doc count before segments are merged\n    writer = newWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT,\n        new MockAnalyzer()).setOpenMode(OpenMode.APPEND).setCodecProvider(\n        provider));\n    assertEquals(100, writer.maxDoc());\n    writer.addIndexes(new Directory[] { aux, aux2 });\n    assertEquals(190, writer.maxDoc());\n    writer.close();\n    _TestUtil.checkIndex(dir, provider);\n\n    dir.close();\n    aux.close();\n    aux2.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3bb13258feba31ab676502787ab2e1779f129b7a","date":1291596436,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestAddIndexes#testSimpleCaseCustomCodecProvider().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestAddIndexes#testSimpleCaseCustomCodecProvider().mjava","sourceNew":"  public void testSimpleCaseCustomCodecProvider() throws IOException {\n    // main directory\n    Directory dir = newDirectory();\n    // two auxiliary directories\n    Directory aux = newDirectory();\n    Directory aux2 = newDirectory();\n    CodecProvider provider = new MockCodecProvider();\n    IndexWriter writer = null;\n\n    writer = newWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT,\n        new MockAnalyzer()).setOpenMode(OpenMode.CREATE).setCodecProvider(\n        provider));\n    // add 100 documents\n    addDocs3(writer, 100);\n    assertEquals(100, writer.maxDoc());\n    writer.commit();\n    writer.close();\n    _TestUtil.checkIndex(dir, provider);\n\n    writer = newWriter(\n        aux,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).\n            setOpenMode(OpenMode.CREATE).\n            setCodecProvider(provider).\n            setMaxBufferedDocs(10).\n            setMergePolicy(newLogMergePolicy(false))\n    );\n    // add 40 documents in separate files\n    addDocs(writer, 40);\n    assertEquals(40, writer.maxDoc());\n    writer.commit();\n    writer.close();\n\n    writer = newWriter(\n        aux2,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).\n            setOpenMode(OpenMode.CREATE).\n            setCodecProvider(provider)\n    );\n    // add 40 documents in compound files\n    addDocs2(writer, 50);\n    assertEquals(50, writer.maxDoc());\n    writer.commit();\n    writer.close();\n\n    // test doc count before segments are merged\n    writer = newWriter(\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).\n            setOpenMode(OpenMode.APPEND).\n            setCodecProvider(provider)\n    );\n    assertEquals(100, writer.maxDoc());\n    writer.addIndexes(aux, aux2);\n    assertEquals(190, writer.maxDoc());\n    writer.close();\n    _TestUtil.checkIndex(dir, provider);\n\n    dir.close();\n    aux.close();\n    aux2.close();\n  }\n\n","sourceOld":"  public void testSimpleCaseCustomCodecProvider() throws IOException {\n    // main directory\n    Directory dir = newDirectory();\n    // two auxiliary directories\n    Directory aux = newDirectory();\n    Directory aux2 = newDirectory();\n    CodecProvider provider = new MockCodecProvider();\n    IndexWriter writer = null;\n\n    writer = newWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT,\n        new MockAnalyzer()).setOpenMode(OpenMode.CREATE).setCodecProvider(\n        provider));\n    // add 100 documents\n    addDocs3(writer, 100);\n    assertEquals(100, writer.maxDoc());\n    writer.commit();\n    writer.close();\n    _TestUtil.checkIndex(dir, provider);\n\n    writer = newWriter(aux, newIndexWriterConfig(TEST_VERSION_CURRENT,\n        new MockAnalyzer()).setOpenMode(OpenMode.CREATE).setCodecProvider(\n        provider));\n    ((LogMergePolicy) writer.getConfig().getMergePolicy())\n        .setUseCompoundFile(false); // use one without a compound file\n    ((LogMergePolicy) writer.getConfig().getMergePolicy())\n        .setUseCompoundDocStore(false); // use one without a compound file\n    // add 40 documents in separate files\n    addDocs(writer, 40);\n    assertEquals(40, writer.maxDoc());\n    writer.commit();\n    writer.close();\n\n    writer = newWriter(aux2, newIndexWriterConfig(TEST_VERSION_CURRENT,\n        new MockAnalyzer()).setOpenMode(OpenMode.CREATE).setCodecProvider(\n        provider));\n    // add 40 documents in compound files\n    addDocs2(writer, 50);\n    assertEquals(50, writer.maxDoc());\n    writer.commit();\n    writer.close();\n\n    // test doc count before segments are merged\n    writer = newWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT,\n        new MockAnalyzer()).setOpenMode(OpenMode.APPEND).setCodecProvider(\n        provider));\n    assertEquals(100, writer.maxDoc());\n    writer.addIndexes(new Directory[] { aux, aux2 });\n    assertEquals(190, writer.maxDoc());\n    writer.close();\n    _TestUtil.checkIndex(dir, provider);\n\n    dir.close();\n    aux.close();\n    aux2.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","date":1292920096,"type":0,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestAddIndexes#testSimpleCaseCustomCodecProvider().mjava","pathOld":"/dev/null","sourceNew":"  public void testSimpleCaseCustomCodecProvider() throws IOException {\n    // main directory\n    Directory dir = newDirectory();\n    // two auxiliary directories\n    Directory aux = newDirectory();\n    Directory aux2 = newDirectory();\n    CodecProvider provider = new MockCodecProvider();\n    IndexWriter writer = null;\n\n    writer = newWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT,\n        new MockAnalyzer()).setOpenMode(OpenMode.CREATE).setCodecProvider(\n        provider));\n    // add 100 documents\n    addDocs3(writer, 100);\n    assertEquals(100, writer.maxDoc());\n    writer.commit();\n    writer.close();\n    _TestUtil.checkIndex(dir, provider);\n\n    writer = newWriter(\n        aux,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).\n            setOpenMode(OpenMode.CREATE).\n            setCodecProvider(provider).\n            setMaxBufferedDocs(10).\n            setMergePolicy(newLogMergePolicy(false))\n    );\n    // add 40 documents in separate files\n    addDocs(writer, 40);\n    assertEquals(40, writer.maxDoc());\n    writer.commit();\n    writer.close();\n\n    writer = newWriter(\n        aux2,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).\n            setOpenMode(OpenMode.CREATE).\n            setCodecProvider(provider)\n    );\n    // add 40 documents in compound files\n    addDocs2(writer, 50);\n    assertEquals(50, writer.maxDoc());\n    writer.commit();\n    writer.close();\n\n    // test doc count before segments are merged\n    writer = newWriter(\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).\n            setOpenMode(OpenMode.APPEND).\n            setCodecProvider(provider)\n    );\n    assertEquals(100, writer.maxDoc());\n    writer.addIndexes(aux, aux2);\n    assertEquals(190, writer.maxDoc());\n    writer.close();\n    _TestUtil.checkIndex(dir, provider);\n\n    dir.close();\n    aux.close();\n    aux2.close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f2c5f0cb44df114db4228c8f77861714b5cabaea","date":1302542431,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestAddIndexes#testSimpleCaseCustomCodecProvider().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestAddIndexes#testSimpleCaseCustomCodecProvider().mjava","sourceNew":"  public void testSimpleCaseCustomCodecProvider() throws IOException {\n    // main directory\n    Directory dir = newDirectory();\n    // two auxiliary directories\n    Directory aux = newDirectory();\n    Directory aux2 = newDirectory();\n    CodecProvider provider = new MockCodecProvider();\n    IndexWriter writer = null;\n\n    writer = newWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT,\n        new MockAnalyzer(random)).setOpenMode(OpenMode.CREATE).setCodecProvider(\n        provider));\n    // add 100 documents\n    addDocs3(writer, 100);\n    assertEquals(100, writer.maxDoc());\n    writer.commit();\n    writer.close();\n    _TestUtil.checkIndex(dir, provider);\n\n    writer = newWriter(\n        aux,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setOpenMode(OpenMode.CREATE).\n            setCodecProvider(provider).\n            setMaxBufferedDocs(10).\n            setMergePolicy(newLogMergePolicy(false))\n    );\n    // add 40 documents in separate files\n    addDocs(writer, 40);\n    assertEquals(40, writer.maxDoc());\n    writer.commit();\n    writer.close();\n\n    writer = newWriter(\n        aux2,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setOpenMode(OpenMode.CREATE).\n            setCodecProvider(provider)\n    );\n    // add 40 documents in compound files\n    addDocs2(writer, 50);\n    assertEquals(50, writer.maxDoc());\n    writer.commit();\n    writer.close();\n\n    // test doc count before segments are merged\n    writer = newWriter(\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setOpenMode(OpenMode.APPEND).\n            setCodecProvider(provider)\n    );\n    assertEquals(100, writer.maxDoc());\n    writer.addIndexes(aux, aux2);\n    assertEquals(190, writer.maxDoc());\n    writer.close();\n    _TestUtil.checkIndex(dir, provider);\n\n    dir.close();\n    aux.close();\n    aux2.close();\n  }\n\n","sourceOld":"  public void testSimpleCaseCustomCodecProvider() throws IOException {\n    // main directory\n    Directory dir = newDirectory();\n    // two auxiliary directories\n    Directory aux = newDirectory();\n    Directory aux2 = newDirectory();\n    CodecProvider provider = new MockCodecProvider();\n    IndexWriter writer = null;\n\n    writer = newWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT,\n        new MockAnalyzer()).setOpenMode(OpenMode.CREATE).setCodecProvider(\n        provider));\n    // add 100 documents\n    addDocs3(writer, 100);\n    assertEquals(100, writer.maxDoc());\n    writer.commit();\n    writer.close();\n    _TestUtil.checkIndex(dir, provider);\n\n    writer = newWriter(\n        aux,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).\n            setOpenMode(OpenMode.CREATE).\n            setCodecProvider(provider).\n            setMaxBufferedDocs(10).\n            setMergePolicy(newLogMergePolicy(false))\n    );\n    // add 40 documents in separate files\n    addDocs(writer, 40);\n    assertEquals(40, writer.maxDoc());\n    writer.commit();\n    writer.close();\n\n    writer = newWriter(\n        aux2,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).\n            setOpenMode(OpenMode.CREATE).\n            setCodecProvider(provider)\n    );\n    // add 40 documents in compound files\n    addDocs2(writer, 50);\n    assertEquals(50, writer.maxDoc());\n    writer.commit();\n    writer.close();\n\n    // test doc count before segments are merged\n    writer = newWriter(\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).\n            setOpenMode(OpenMode.APPEND).\n            setCodecProvider(provider)\n    );\n    assertEquals(100, writer.maxDoc());\n    writer.addIndexes(aux, aux2);\n    assertEquals(190, writer.maxDoc());\n    writer.close();\n    _TestUtil.checkIndex(dir, provider);\n\n    dir.close();\n    aux.close();\n    aux2.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"962d04139994fce5193143ef35615499a9a96d78","date":1302693744,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestAddIndexes#testSimpleCaseCustomCodecProvider().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestAddIndexes#testSimpleCaseCustomCodecProvider().mjava","sourceNew":"  public void testSimpleCaseCustomCodecProvider() throws IOException {\n    // main directory\n    Directory dir = newDirectory();\n    // two auxiliary directories\n    Directory aux = newDirectory();\n    Directory aux2 = newDirectory();\n    CodecProvider provider = new MockCodecProvider();\n    IndexWriter writer = null;\n\n    writer = newWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT,\n        new MockAnalyzer(random)).setOpenMode(OpenMode.CREATE).setCodecProvider(\n        provider));\n    // add 100 documents\n    addDocs3(writer, 100);\n    assertEquals(100, writer.maxDoc());\n    writer.commit();\n    writer.close();\n    _TestUtil.checkIndex(dir, provider);\n\n    writer = newWriter(\n        aux,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setOpenMode(OpenMode.CREATE).\n            setCodecProvider(provider).\n            setMaxBufferedDocs(10).\n            setMergePolicy(newLogMergePolicy(false))\n    );\n    // add 40 documents in separate files\n    addDocs(writer, 40);\n    assertEquals(40, writer.maxDoc());\n    writer.commit();\n    writer.close();\n\n    writer = newWriter(\n        aux2,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setOpenMode(OpenMode.CREATE).\n            setCodecProvider(provider)\n    );\n    // add 40 documents in compound files\n    addDocs2(writer, 50);\n    assertEquals(50, writer.maxDoc());\n    writer.commit();\n    writer.close();\n\n    // test doc count before segments are merged\n    writer = newWriter(\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setOpenMode(OpenMode.APPEND).\n            setCodecProvider(provider)\n    );\n    assertEquals(100, writer.maxDoc());\n    writer.addIndexes(aux, aux2);\n    assertEquals(190, writer.maxDoc());\n    writer.close();\n    _TestUtil.checkIndex(dir, provider);\n\n    dir.close();\n    aux.close();\n    aux2.close();\n  }\n\n","sourceOld":"  public void testSimpleCaseCustomCodecProvider() throws IOException {\n    // main directory\n    Directory dir = newDirectory();\n    // two auxiliary directories\n    Directory aux = newDirectory();\n    Directory aux2 = newDirectory();\n    CodecProvider provider = new MockCodecProvider();\n    IndexWriter writer = null;\n\n    writer = newWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT,\n        new MockAnalyzer()).setOpenMode(OpenMode.CREATE).setCodecProvider(\n        provider));\n    // add 100 documents\n    addDocs3(writer, 100);\n    assertEquals(100, writer.maxDoc());\n    writer.commit();\n    writer.close();\n    _TestUtil.checkIndex(dir, provider);\n\n    writer = newWriter(\n        aux,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).\n            setOpenMode(OpenMode.CREATE).\n            setCodecProvider(provider).\n            setMaxBufferedDocs(10).\n            setMergePolicy(newLogMergePolicy(false))\n    );\n    // add 40 documents in separate files\n    addDocs(writer, 40);\n    assertEquals(40, writer.maxDoc());\n    writer.commit();\n    writer.close();\n\n    writer = newWriter(\n        aux2,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).\n            setOpenMode(OpenMode.CREATE).\n            setCodecProvider(provider)\n    );\n    // add 40 documents in compound files\n    addDocs2(writer, 50);\n    assertEquals(50, writer.maxDoc());\n    writer.commit();\n    writer.close();\n\n    // test doc count before segments are merged\n    writer = newWriter(\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).\n            setOpenMode(OpenMode.APPEND).\n            setCodecProvider(provider)\n    );\n    assertEquals(100, writer.maxDoc());\n    writer.addIndexes(aux, aux2);\n    assertEquals(190, writer.maxDoc());\n    writer.close();\n    _TestUtil.checkIndex(dir, provider);\n\n    dir.close();\n    aux.close();\n    aux2.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"135621f3a0670a9394eb563224a3b76cc4dddc0f","date":1304344257,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestAddIndexes#testSimpleCaseCustomCodecProvider().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestAddIndexes#testSimpleCaseCustomCodecProvider().mjava","sourceNew":"  public void testSimpleCaseCustomCodecProvider() throws IOException {\n    // main directory\n    Directory dir = newDirectory();\n    // two auxiliary directories\n    Directory aux = newDirectory();\n    Directory aux2 = newDirectory();\n    CodecProvider provider = new MockCodecProvider();\n    IndexWriter writer = null;\n\n    writer = newWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT,\n        new MockAnalyzer(random)).setOpenMode(OpenMode.CREATE).setCodecProvider(\n        provider));\n    // add 100 documents\n    addDocs3(writer, 100);\n    assertEquals(100, writer.maxDoc());\n    writer.commit();\n    writer.close();\n    _TestUtil.checkIndex(dir, provider);\n\n    writer = newWriter(\n        aux,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setOpenMode(OpenMode.CREATE).\n            setCodecProvider(provider).\n            setMaxBufferedDocs(10).\n            setMergePolicy(newLogMergePolicy(false))\n    );\n    // add 40 documents in separate files\n    addDocs(writer, 40);\n    assertEquals(40, writer.maxDoc());\n    writer.commit();\n    writer.close();\n\n    writer = newWriter(\n        aux2,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setOpenMode(OpenMode.CREATE).\n            setCodecProvider(provider)\n    );\n    // add 40 documents in compound files\n    addDocs2(writer, 50);\n    assertEquals(50, writer.maxDoc());\n    writer.commit();\n    writer.close();\n\n    // test doc count before segments are merged\n    writer = newWriter(\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setOpenMode(OpenMode.APPEND).\n            setCodecProvider(provider)\n    );\n    assertEquals(100, writer.maxDoc());\n    writer.addIndexes(aux, aux2);\n    assertEquals(190, writer.maxDoc());\n    writer.close();\n    _TestUtil.checkIndex(dir, provider);\n\n    dir.close();\n    aux.close();\n    aux2.close();\n  }\n\n","sourceOld":"  public void testSimpleCaseCustomCodecProvider() throws IOException {\n    // main directory\n    Directory dir = newDirectory();\n    // two auxiliary directories\n    Directory aux = newDirectory();\n    Directory aux2 = newDirectory();\n    CodecProvider provider = new MockCodecProvider();\n    IndexWriter writer = null;\n\n    writer = newWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT,\n        new MockAnalyzer()).setOpenMode(OpenMode.CREATE).setCodecProvider(\n        provider));\n    // add 100 documents\n    addDocs3(writer, 100);\n    assertEquals(100, writer.maxDoc());\n    writer.commit();\n    writer.close();\n    _TestUtil.checkIndex(dir, provider);\n\n    writer = newWriter(\n        aux,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).\n            setOpenMode(OpenMode.CREATE).\n            setCodecProvider(provider).\n            setMaxBufferedDocs(10).\n            setMergePolicy(newLogMergePolicy(false))\n    );\n    // add 40 documents in separate files\n    addDocs(writer, 40);\n    assertEquals(40, writer.maxDoc());\n    writer.commit();\n    writer.close();\n\n    writer = newWriter(\n        aux2,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).\n            setOpenMode(OpenMode.CREATE).\n            setCodecProvider(provider)\n    );\n    // add 40 documents in compound files\n    addDocs2(writer, 50);\n    assertEquals(50, writer.maxDoc());\n    writer.commit();\n    writer.close();\n\n    // test doc count before segments are merged\n    writer = newWriter(\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).\n            setOpenMode(OpenMode.APPEND).\n            setCodecProvider(provider)\n    );\n    assertEquals(100, writer.maxDoc());\n    writer.addIndexes(aux, aux2);\n    assertEquals(190, writer.maxDoc());\n    writer.close();\n    _TestUtil.checkIndex(dir, provider);\n\n    dir.close();\n    aux.close();\n    aux2.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a3776dccca01c11e7046323cfad46a3b4a471233","date":1306100719,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestAddIndexes#testSimpleCaseCustomCodecProvider().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestAddIndexes#testSimpleCaseCustomCodecProvider().mjava","sourceNew":"  public void testSimpleCaseCustomCodecProvider() throws IOException {\n    // main directory\n    Directory dir = newDirectory();\n    // two auxiliary directories\n    Directory aux = newDirectory();\n    Directory aux2 = newDirectory();\n    CodecProvider provider = new MockCodecProvider();\n    IndexWriter writer = null;\n\n    writer = newWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT,\n        new MockAnalyzer(random)).setOpenMode(OpenMode.CREATE).setCodecProvider(\n        provider));\n    // add 100 documents\n    addDocs3(writer, 100);\n    assertEquals(100, writer.maxDoc());\n    writer.commit();\n    writer.close();\n    _TestUtil.checkIndex(dir, provider);\n\n    writer = newWriter(\n        aux,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setOpenMode(OpenMode.CREATE).\n            setCodecProvider(provider).\n            setMaxBufferedDocs(10).\n            setMergePolicy(newLogMergePolicy(false))\n    );\n    // add 40 documents in separate files\n    addDocs(writer, 40);\n    assertEquals(40, writer.maxDoc());\n    writer.commit();\n    writer.close();\n\n    writer = newWriter(\n        aux2,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setOpenMode(OpenMode.CREATE).\n            setCodecProvider(provider)\n    );\n    // add 40 documents in compound files\n    addDocs2(writer, 50);\n    assertEquals(50, writer.maxDoc());\n    writer.commit();\n    writer.close();\n\n    // test doc count before segments are merged\n    writer = newWriter(\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setOpenMode(OpenMode.APPEND).\n            setCodecProvider(provider)\n    );\n    assertEquals(100, writer.maxDoc());\n    writer.addIndexes(aux, aux2);\n    assertEquals(190, writer.maxDoc());\n    writer.close();\n    _TestUtil.checkIndex(dir, provider);\n\n    dir.close();\n    aux.close();\n    aux2.close();\n  }\n\n","sourceOld":"  public void testSimpleCaseCustomCodecProvider() throws IOException {\n    // main directory\n    Directory dir = newDirectory();\n    // two auxiliary directories\n    Directory aux = newDirectory();\n    Directory aux2 = newDirectory();\n    CodecProvider provider = new MockCodecProvider();\n    IndexWriter writer = null;\n\n    writer = newWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT,\n        new MockAnalyzer()).setOpenMode(OpenMode.CREATE).setCodecProvider(\n        provider));\n    // add 100 documents\n    addDocs3(writer, 100);\n    assertEquals(100, writer.maxDoc());\n    writer.commit();\n    writer.close();\n    _TestUtil.checkIndex(dir, provider);\n\n    writer = newWriter(\n        aux,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).\n            setOpenMode(OpenMode.CREATE).\n            setCodecProvider(provider).\n            setMaxBufferedDocs(10).\n            setMergePolicy(newLogMergePolicy(false))\n    );\n    // add 40 documents in separate files\n    addDocs(writer, 40);\n    assertEquals(40, writer.maxDoc());\n    writer.commit();\n    writer.close();\n\n    writer = newWriter(\n        aux2,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).\n            setOpenMode(OpenMode.CREATE).\n            setCodecProvider(provider)\n    );\n    // add 40 documents in compound files\n    addDocs2(writer, 50);\n    assertEquals(50, writer.maxDoc());\n    writer.commit();\n    writer.close();\n\n    // test doc count before segments are merged\n    writer = newWriter(\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).\n            setOpenMode(OpenMode.APPEND).\n            setCodecProvider(provider)\n    );\n    assertEquals(100, writer.maxDoc());\n    writer.addIndexes(aux, aux2);\n    assertEquals(190, writer.maxDoc());\n    writer.close();\n    _TestUtil.checkIndex(dir, provider);\n\n    dir.close();\n    aux.close();\n    aux2.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ff6fd241dc6610f7f81b62e3ba4cedf105939623","date":1307331653,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestAddIndexes#testSimpleCaseCustomCodecProvider().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestAddIndexes#testSimpleCaseCustomCodecProvider().mjava","sourceNew":"  public void testSimpleCaseCustomCodecProvider() throws IOException {\n    // main directory\n    Directory dir = newDirectory();\n    // two auxiliary directories\n    Directory aux = newDirectory();\n    Directory aux2 = newDirectory();\n    CodecProvider provider = new MockCodecProvider();\n    IndexWriter writer = null;\n\n    writer = newWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT,\n        new MockAnalyzer(random)).setOpenMode(OpenMode.CREATE).setCodecProvider(\n        provider));\n    // add 100 documents\n    addDocs3(writer, 100);\n    assertEquals(100, writer.maxDoc());\n    writer.commit();\n    writer.close();\n    _TestUtil.checkIndex(dir, provider);\n\n    writer = newWriter(\n        aux,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setOpenMode(OpenMode.CREATE).\n            setCodecProvider(provider).\n            setMaxBufferedDocs(10).\n            setMergePolicy(newLogMergePolicy(false))\n    );\n    // add 40 documents in separate files\n    addDocs(writer, 40);\n    assertEquals(40, writer.maxDoc());\n    writer.commit();\n    writer.close();\n\n    writer = newWriter(\n        aux2,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setOpenMode(OpenMode.CREATE).\n            setCodecProvider(provider)\n    );\n    // add 40 documents in compound files\n    addDocs2(writer, 50);\n    assertEquals(50, writer.maxDoc());\n    writer.commit();\n    writer.close();\n\n    // test doc count before segments are merged\n    writer = newWriter(\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setOpenMode(OpenMode.APPEND).\n            setCodecProvider(provider)\n    );\n    assertEquals(100, writer.maxDoc());\n    writer.addIndexes(aux, aux2);\n    assertEquals(190, writer.maxDoc());\n    writer.close();\n\n    dir.close();\n    aux.close();\n    aux2.close();\n  }\n\n","sourceOld":"  public void testSimpleCaseCustomCodecProvider() throws IOException {\n    // main directory\n    Directory dir = newDirectory();\n    // two auxiliary directories\n    Directory aux = newDirectory();\n    Directory aux2 = newDirectory();\n    CodecProvider provider = new MockCodecProvider();\n    IndexWriter writer = null;\n\n    writer = newWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT,\n        new MockAnalyzer(random)).setOpenMode(OpenMode.CREATE).setCodecProvider(\n        provider));\n    // add 100 documents\n    addDocs3(writer, 100);\n    assertEquals(100, writer.maxDoc());\n    writer.commit();\n    writer.close();\n    _TestUtil.checkIndex(dir, provider);\n\n    writer = newWriter(\n        aux,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setOpenMode(OpenMode.CREATE).\n            setCodecProvider(provider).\n            setMaxBufferedDocs(10).\n            setMergePolicy(newLogMergePolicy(false))\n    );\n    // add 40 documents in separate files\n    addDocs(writer, 40);\n    assertEquals(40, writer.maxDoc());\n    writer.commit();\n    writer.close();\n\n    writer = newWriter(\n        aux2,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setOpenMode(OpenMode.CREATE).\n            setCodecProvider(provider)\n    );\n    // add 40 documents in compound files\n    addDocs2(writer, 50);\n    assertEquals(50, writer.maxDoc());\n    writer.commit();\n    writer.close();\n\n    // test doc count before segments are merged\n    writer = newWriter(\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setOpenMode(OpenMode.APPEND).\n            setCodecProvider(provider)\n    );\n    assertEquals(100, writer.maxDoc());\n    writer.addIndexes(aux, aux2);\n    assertEquals(190, writer.maxDoc());\n    writer.close();\n    _TestUtil.checkIndex(dir, provider);\n\n    dir.close();\n    aux.close();\n    aux2.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"79c2cb24929f2649a8875fb629086171f914d5ce","date":1307332717,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestAddIndexes#testSimpleCaseCustomCodecProvider().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestAddIndexes#testSimpleCaseCustomCodecProvider().mjava","sourceNew":"  public void testSimpleCaseCustomCodecProvider() throws IOException {\n    // main directory\n    Directory dir = newDirectory();\n    // two auxiliary directories\n    Directory aux = newDirectory();\n    Directory aux2 = newDirectory();\n    CodecProvider provider = new MockCodecProvider();\n    IndexWriter writer = null;\n\n    writer = newWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT,\n        new MockAnalyzer(random)).setOpenMode(OpenMode.CREATE).setCodecProvider(\n        provider));\n    // add 100 documents\n    addDocs3(writer, 100);\n    assertEquals(100, writer.maxDoc());\n    writer.commit();\n    writer.close();\n    _TestUtil.checkIndex(dir, provider);\n\n    writer = newWriter(\n        aux,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setOpenMode(OpenMode.CREATE).\n            setCodecProvider(provider).\n            setMaxBufferedDocs(10).\n            setMergePolicy(newLogMergePolicy(false))\n    );\n    // add 40 documents in separate files\n    addDocs(writer, 40);\n    assertEquals(40, writer.maxDoc());\n    writer.commit();\n    writer.close();\n\n    writer = newWriter(\n        aux2,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setOpenMode(OpenMode.CREATE).\n            setCodecProvider(provider)\n    );\n    // add 40 documents in compound files\n    addDocs2(writer, 50);\n    assertEquals(50, writer.maxDoc());\n    writer.commit();\n    writer.close();\n\n    // test doc count before segments are merged\n    writer = newWriter(\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setOpenMode(OpenMode.APPEND).\n            setCodecProvider(provider)\n    );\n    assertEquals(100, writer.maxDoc());\n    writer.addIndexes(aux, aux2);\n    assertEquals(190, writer.maxDoc());\n    writer.close();\n\n    dir.close();\n    aux.close();\n    aux2.close();\n  }\n\n","sourceOld":"  public void testSimpleCaseCustomCodecProvider() throws IOException {\n    // main directory\n    Directory dir = newDirectory();\n    // two auxiliary directories\n    Directory aux = newDirectory();\n    Directory aux2 = newDirectory();\n    CodecProvider provider = new MockCodecProvider();\n    IndexWriter writer = null;\n\n    writer = newWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT,\n        new MockAnalyzer(random)).setOpenMode(OpenMode.CREATE).setCodecProvider(\n        provider));\n    // add 100 documents\n    addDocs3(writer, 100);\n    assertEquals(100, writer.maxDoc());\n    writer.commit();\n    writer.close();\n    _TestUtil.checkIndex(dir, provider);\n\n    writer = newWriter(\n        aux,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setOpenMode(OpenMode.CREATE).\n            setCodecProvider(provider).\n            setMaxBufferedDocs(10).\n            setMergePolicy(newLogMergePolicy(false))\n    );\n    // add 40 documents in separate files\n    addDocs(writer, 40);\n    assertEquals(40, writer.maxDoc());\n    writer.commit();\n    writer.close();\n\n    writer = newWriter(\n        aux2,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setOpenMode(OpenMode.CREATE).\n            setCodecProvider(provider)\n    );\n    // add 40 documents in compound files\n    addDocs2(writer, 50);\n    assertEquals(50, writer.maxDoc());\n    writer.commit();\n    writer.close();\n\n    // test doc count before segments are merged\n    writer = newWriter(\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setOpenMode(OpenMode.APPEND).\n            setCodecProvider(provider)\n    );\n    assertEquals(100, writer.maxDoc());\n    writer.addIndexes(aux, aux2);\n    assertEquals(190, writer.maxDoc());\n    writer.close();\n    _TestUtil.checkIndex(dir, provider);\n\n    dir.close();\n    aux.close();\n    aux2.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"77cf4379b2824f6ea34b091c495d6e95c38ff9e2","date":1307610475,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestAddIndexes#testSimpleCaseCustomCodecProvider().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestAddIndexes#testSimpleCaseCustomCodecProvider().mjava","sourceNew":"  public void testSimpleCaseCustomCodecProvider() throws IOException {\n    // main directory\n    Directory dir = newDirectory();\n    // two auxiliary directories\n    Directory aux = newDirectory();\n    Directory aux2 = newDirectory();\n    CodecProvider provider = new MockCodecProvider();\n    IndexWriter writer = null;\n\n    writer = newWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT,\n        new MockAnalyzer(random)).setOpenMode(OpenMode.CREATE).setCodecProvider(\n        provider));\n    // add 100 documents\n    addDocs3(writer, 100);\n    assertEquals(100, writer.maxDoc());\n    writer.commit();\n    writer.close();\n    _TestUtil.checkIndex(dir, provider);\n\n    writer = newWriter(\n        aux,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setOpenMode(OpenMode.CREATE).\n            setCodecProvider(provider).\n            setMaxBufferedDocs(10).\n            setMergePolicy(newLogMergePolicy(false))\n    );\n    // add 40 documents in separate files\n    addDocs(writer, 40);\n    assertEquals(40, writer.maxDoc());\n    writer.commit();\n    writer.close();\n\n    writer = newWriter(\n        aux2,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setOpenMode(OpenMode.CREATE).\n            setCodecProvider(provider)\n    );\n    // add 40 documents in compound files\n    addDocs2(writer, 50);\n    assertEquals(50, writer.maxDoc());\n    writer.commit();\n    writer.close();\n\n    // test doc count before segments are merged\n    writer = newWriter(\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setOpenMode(OpenMode.APPEND).\n            setCodecProvider(provider)\n    );\n    assertEquals(100, writer.maxDoc());\n    writer.addIndexes(aux, aux2);\n    assertEquals(190, writer.maxDoc());\n    writer.close();\n\n    dir.close();\n    aux.close();\n    aux2.close();\n  }\n\n","sourceOld":"  public void testSimpleCaseCustomCodecProvider() throws IOException {\n    // main directory\n    Directory dir = newDirectory();\n    // two auxiliary directories\n    Directory aux = newDirectory();\n    Directory aux2 = newDirectory();\n    CodecProvider provider = new MockCodecProvider();\n    IndexWriter writer = null;\n\n    writer = newWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT,\n        new MockAnalyzer(random)).setOpenMode(OpenMode.CREATE).setCodecProvider(\n        provider));\n    // add 100 documents\n    addDocs3(writer, 100);\n    assertEquals(100, writer.maxDoc());\n    writer.commit();\n    writer.close();\n    _TestUtil.checkIndex(dir, provider);\n\n    writer = newWriter(\n        aux,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setOpenMode(OpenMode.CREATE).\n            setCodecProvider(provider).\n            setMaxBufferedDocs(10).\n            setMergePolicy(newLogMergePolicy(false))\n    );\n    // add 40 documents in separate files\n    addDocs(writer, 40);\n    assertEquals(40, writer.maxDoc());\n    writer.commit();\n    writer.close();\n\n    writer = newWriter(\n        aux2,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setOpenMode(OpenMode.CREATE).\n            setCodecProvider(provider)\n    );\n    // add 40 documents in compound files\n    addDocs2(writer, 50);\n    assertEquals(50, writer.maxDoc());\n    writer.commit();\n    writer.close();\n\n    // test doc count before segments are merged\n    writer = newWriter(\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setOpenMode(OpenMode.APPEND).\n            setCodecProvider(provider)\n    );\n    assertEquals(100, writer.maxDoc());\n    writer.addIndexes(aux, aux2);\n    assertEquals(190, writer.maxDoc());\n    writer.close();\n    _TestUtil.checkIndex(dir, provider);\n\n    dir.close();\n    aux.close();\n    aux2.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7b91922b55d15444d554721b352861d028eb8278","date":1320421415,"type":5,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestAddIndexes#testSimpleCaseCustomCodec().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestAddIndexes#testSimpleCaseCustomCodecProvider().mjava","sourceNew":"  public void testSimpleCaseCustomCodec() throws IOException {\n    // main directory\n    Directory dir = newDirectory();\n    // two auxiliary directories\n    Directory aux = newDirectory();\n    Directory aux2 = newDirectory();\n    Codec codec = new CustomPerFieldCodec();\n    IndexWriter writer = null;\n\n    writer = newWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT,\n        new MockAnalyzer(random)).setOpenMode(OpenMode.CREATE).setCodec(codec));\n    // add 100 documents\n    addDocs3(writer, 100);\n    assertEquals(100, writer.maxDoc());\n    writer.commit();\n    writer.close();\n    _TestUtil.checkIndex(dir);\n\n    writer = newWriter(\n        aux,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setOpenMode(OpenMode.CREATE).\n            setCodec(codec).\n            setMaxBufferedDocs(10).\n            setMergePolicy(newLogMergePolicy(false))\n    );\n    // add 40 documents in separate files\n    addDocs(writer, 40);\n    assertEquals(40, writer.maxDoc());\n    writer.commit();\n    writer.close();\n\n    writer = newWriter(\n        aux2,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setOpenMode(OpenMode.CREATE).\n            setCodec(codec)\n    );\n    // add 40 documents in compound files\n    addDocs2(writer, 50);\n    assertEquals(50, writer.maxDoc());\n    writer.commit();\n    writer.close();\n\n    // test doc count before segments are merged\n    writer = newWriter(\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setOpenMode(OpenMode.APPEND).\n            setCodec(codec)\n    );\n    assertEquals(100, writer.maxDoc());\n    writer.addIndexes(aux, aux2);\n    assertEquals(190, writer.maxDoc());\n    writer.close();\n\n    dir.close();\n    aux.close();\n    aux2.close();\n  }\n\n","sourceOld":"  public void testSimpleCaseCustomCodecProvider() throws IOException {\n    // main directory\n    Directory dir = newDirectory();\n    // two auxiliary directories\n    Directory aux = newDirectory();\n    Directory aux2 = newDirectory();\n    CodecProvider provider = new MockCodecProvider();\n    IndexWriter writer = null;\n\n    writer = newWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT,\n        new MockAnalyzer(random)).setOpenMode(OpenMode.CREATE).setCodecProvider(\n        provider));\n    // add 100 documents\n    addDocs3(writer, 100);\n    assertEquals(100, writer.maxDoc());\n    writer.commit();\n    writer.close();\n    _TestUtil.checkIndex(dir, provider);\n\n    writer = newWriter(\n        aux,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setOpenMode(OpenMode.CREATE).\n            setCodecProvider(provider).\n            setMaxBufferedDocs(10).\n            setMergePolicy(newLogMergePolicy(false))\n    );\n    // add 40 documents in separate files\n    addDocs(writer, 40);\n    assertEquals(40, writer.maxDoc());\n    writer.commit();\n    writer.close();\n\n    writer = newWriter(\n        aux2,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setOpenMode(OpenMode.CREATE).\n            setCodecProvider(provider)\n    );\n    // add 40 documents in compound files\n    addDocs2(writer, 50);\n    assertEquals(50, writer.maxDoc());\n    writer.commit();\n    writer.close();\n\n    // test doc count before segments are merged\n    writer = newWriter(\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setOpenMode(OpenMode.APPEND).\n            setCodecProvider(provider)\n    );\n    assertEquals(100, writer.maxDoc());\n    writer.addIndexes(aux, aux2);\n    assertEquals(190, writer.maxDoc());\n    writer.close();\n\n    dir.close();\n    aux.close();\n    aux2.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"ff6fd241dc6610f7f81b62e3ba4cedf105939623":["f2c5f0cb44df114db4228c8f77861714b5cabaea"],"a493e6d0c3ad86bd55c0a1360d110142e948f2bd":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"85a883878c0af761245ab048babc63d099f835f3":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","a493e6d0c3ad86bd55c0a1360d110142e948f2bd"],"135621f3a0670a9394eb563224a3b76cc4dddc0f":["3bb13258feba31ab676502787ab2e1779f129b7a","f2c5f0cb44df114db4228c8f77861714b5cabaea"],"962d04139994fce5193143ef35615499a9a96d78":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","f2c5f0cb44df114db4228c8f77861714b5cabaea"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","4e8cc373c801e54cec75daf9f52792cb4b17f536"],"7b91922b55d15444d554721b352861d028eb8278":["ff6fd241dc6610f7f81b62e3ba4cedf105939623"],"f2c5f0cb44df114db4228c8f77861714b5cabaea":["4e8cc373c801e54cec75daf9f52792cb4b17f536"],"79c2cb24929f2649a8875fb629086171f914d5ce":["a3776dccca01c11e7046323cfad46a3b4a471233","ff6fd241dc6610f7f81b62e3ba4cedf105939623"],"a3776dccca01c11e7046323cfad46a3b4a471233":["4e8cc373c801e54cec75daf9f52792cb4b17f536","f2c5f0cb44df114db4228c8f77861714b5cabaea"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"77cf4379b2824f6ea34b091c495d6e95c38ff9e2":["135621f3a0670a9394eb563224a3b76cc4dddc0f","ff6fd241dc6610f7f81b62e3ba4cedf105939623"],"3bb13258feba31ab676502787ab2e1779f129b7a":["85a883878c0af761245ab048babc63d099f835f3","4e8cc373c801e54cec75daf9f52792cb4b17f536"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["7b91922b55d15444d554721b352861d028eb8278"],"4e8cc373c801e54cec75daf9f52792cb4b17f536":["a493e6d0c3ad86bd55c0a1360d110142e948f2bd"]},"commit2Childs":{"ff6fd241dc6610f7f81b62e3ba4cedf105939623":["7b91922b55d15444d554721b352861d028eb8278","79c2cb24929f2649a8875fb629086171f914d5ce","77cf4379b2824f6ea34b091c495d6e95c38ff9e2"],"a493e6d0c3ad86bd55c0a1360d110142e948f2bd":["85a883878c0af761245ab048babc63d099f835f3","4e8cc373c801e54cec75daf9f52792cb4b17f536"],"85a883878c0af761245ab048babc63d099f835f3":["3bb13258feba31ab676502787ab2e1779f129b7a"],"135621f3a0670a9394eb563224a3b76cc4dddc0f":["77cf4379b2824f6ea34b091c495d6e95c38ff9e2"],"962d04139994fce5193143ef35615499a9a96d78":[],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":["962d04139994fce5193143ef35615499a9a96d78"],"7b91922b55d15444d554721b352861d028eb8278":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"f2c5f0cb44df114db4228c8f77861714b5cabaea":["ff6fd241dc6610f7f81b62e3ba4cedf105939623","135621f3a0670a9394eb563224a3b76cc4dddc0f","962d04139994fce5193143ef35615499a9a96d78","a3776dccca01c11e7046323cfad46a3b4a471233"],"79c2cb24929f2649a8875fb629086171f914d5ce":[],"a3776dccca01c11e7046323cfad46a3b4a471233":["79c2cb24929f2649a8875fb629086171f914d5ce"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["a493e6d0c3ad86bd55c0a1360d110142e948f2bd","85a883878c0af761245ab048babc63d099f835f3","7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a"],"77cf4379b2824f6ea34b091c495d6e95c38ff9e2":[],"3bb13258feba31ab676502787ab2e1779f129b7a":["135621f3a0670a9394eb563224a3b76cc4dddc0f"],"4e8cc373c801e54cec75daf9f52792cb4b17f536":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","f2c5f0cb44df114db4228c8f77861714b5cabaea","a3776dccca01c11e7046323cfad46a3b4a471233","3bb13258feba31ab676502787ab2e1779f129b7a"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["962d04139994fce5193143ef35615499a9a96d78","79c2cb24929f2649a8875fb629086171f914d5ce","77cf4379b2824f6ea34b091c495d6e95c38ff9e2","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}