{"path":"src/demo/org/apache/lucene/demo/HTMLDocument#Document(File).mjava","commits":[{"id":"6585acee8c9458b9745b49462abd05c2aa4f23d5","date":1012057292,"type":1,"author":"Andrew C. Oliver","isMerge":false,"pathNew":"src/demo/org/apache/lucene/demo/HTMLDocument#Document(File).mjava","pathOld":"src/demo/org/apache/lucene/HTMLDocument#Document(File).mjava","sourceNew":"  public static Document Document(File f)\n       throws IOException, InterruptedException  {\n    // make a new, empty document\n    Document doc = new Document();\n\n    // Add the url as a field named \"url\".  Use an UnIndexed field, so\n    // that the url is just stored with the document, but is not searchable.\n    doc.add(Field.UnIndexed(\"url\", f.getPath().replace(dirSep, '/')));\n\n    // Add the last modified date of the file a field named \"modified\".  Use a\n    // Keyword field, so that it's searchable, but so that no attempt is made\n    // to tokenize the field into words.\n    doc.add(Field.Keyword(\"modified\",\n\t\t\t  DateField.timeToString(f.lastModified())));\n\n    // Add the uid as a field, so that index can be incrementally maintained.\n    // This field is not stored with document, it is indexed, but it is not\n    // tokenized prior to indexing.\n    doc.add(new Field(\"uid\", uid(f), false, true, false));\n\n    HTMLParser parser = new HTMLParser(f);\n\n    // Add the tag-stripped contents as a Reader-valued Text field so it will\n    // get tokenized and indexed.\n    doc.add(Field.Text(\"contents\", parser.getReader()));\n\n    // Add the summary as an UnIndexed field, so that it is stored and returned\n    // with hit documents for display.\n    doc.add(Field.UnIndexed(\"summary\", parser.getSummary()));\n\n    // Add the title as a separate Text field, so that it can be searched\n    // separately.\n    doc.add(Field.Text(\"title\", parser.getTitle()));\n\n    // return the document\n    return doc;\n  }\n\n","sourceOld":"  public static Document Document(File f)\n       throws IOException, InterruptedException  {\n    // make a new, empty document\n    Document doc = new Document();\n\n    // Add the url as a field named \"url\".  Use an UnIndexed field, so\n    // that the url is just stored with the document, but is not searchable.\n    doc.add(Field.UnIndexed(\"url\", f.getPath().replace(dirSep, '/')));\n\n    // Add the last modified date of the file a field named \"modified\".  Use a\n    // Keyword field, so that it's searchable, but so that no attempt is made\n    // to tokenize the field into words.\n    doc.add(Field.Keyword(\"modified\",\n\t\t\t  DateField.timeToString(f.lastModified())));\n\n    // Add the uid as a field, so that index can be incrementally maintained.\n    // This field is not stored with document, it is indexed, but it is not\n    // tokenized prior to indexing.\n    doc.add(new Field(\"uid\", uid(f), false, true, false));\n\n    HTMLParser parser = new HTMLParser(f);\n\n    // Add the tag-stripped contents as a Reader-valued Text field so it will\n    // get tokenized and indexed.\n    doc.add(Field.Text(\"contents\", parser.getReader()));\n\n    // Add the summary as an UnIndexed field, so that it is stored and returned\n    // with hit documents for display.\n    doc.add(Field.UnIndexed(\"summary\", parser.getSummary()));\n\n    // Add the title as a separate Text field, so that it can be searched\n    // separately.\n    doc.add(Field.Text(\"title\", parser.getTitle()));\n\n    // return the document\n    return doc;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1bbdcd094e2f9e4815621e4b813461caabc9546a","date":1091569764,"type":3,"author":"Daniel Naber","isMerge":false,"pathNew":"src/demo/org/apache/lucene/demo/HTMLDocument#Document(File).mjava","pathOld":"src/demo/org/apache/lucene/demo/HTMLDocument#Document(File).mjava","sourceNew":"  public static Document Document(File f)\n       throws IOException, InterruptedException  {\n    // make a new, empty document\n    Document doc = new Document();\n\n    // Add the url as a field named \"path\".  Use a Keyword field, so \n    // that it's searchable, but so that no attempt is made\n    // to tokenize the field into words.\n    doc.add(Field.Keyword(\"path\", f.getPath().replace(dirSep, '/')));\n\n    // Add the last modified date of the file a field named \"modified\".  Use a\n    // Keyword field, so that it's searchable, but so that no attempt is made\n    // to tokenize the field into words.\n    doc.add(Field.Keyword(\"modified\",\n\t\t\t  DateField.timeToString(f.lastModified())));\n\n    // Add the uid as a field, so that index can be incrementally maintained.\n    // This field is not stored with document, it is indexed, but it is not\n    // tokenized prior to indexing.\n    doc.add(new Field(\"uid\", uid(f), false, true, false));\n\n    HTMLParser parser = new HTMLParser(f);\n\n    // Add the tag-stripped contents as a Reader-valued Text field so it will\n    // get tokenized and indexed.\n    doc.add(Field.Text(\"contents\", parser.getReader()));\n\n    // Add the summary as an UnIndexed field, so that it is stored and returned\n    // with hit documents for display.\n    doc.add(Field.UnIndexed(\"summary\", parser.getSummary()));\n\n    // Add the title as a separate Text field, so that it can be searched\n    // separately.\n    doc.add(Field.Text(\"title\", parser.getTitle()));\n\n    // return the document\n    return doc;\n  }\n\n","sourceOld":"  public static Document Document(File f)\n       throws IOException, InterruptedException  {\n    // make a new, empty document\n    Document doc = new Document();\n\n    // Add the url as a field named \"url\".  Use an UnIndexed field, so\n    // that the url is just stored with the document, but is not searchable.\n    doc.add(Field.UnIndexed(\"url\", f.getPath().replace(dirSep, '/')));\n\n    // Add the last modified date of the file a field named \"modified\".  Use a\n    // Keyword field, so that it's searchable, but so that no attempt is made\n    // to tokenize the field into words.\n    doc.add(Field.Keyword(\"modified\",\n\t\t\t  DateField.timeToString(f.lastModified())));\n\n    // Add the uid as a field, so that index can be incrementally maintained.\n    // This field is not stored with document, it is indexed, but it is not\n    // tokenized prior to indexing.\n    doc.add(new Field(\"uid\", uid(f), false, true, false));\n\n    HTMLParser parser = new HTMLParser(f);\n\n    // Add the tag-stripped contents as a Reader-valued Text field so it will\n    // get tokenized and indexed.\n    doc.add(Field.Text(\"contents\", parser.getReader()));\n\n    // Add the summary as an UnIndexed field, so that it is stored and returned\n    // with hit documents for display.\n    doc.add(Field.UnIndexed(\"summary\", parser.getSummary()));\n\n    // Add the title as a separate Text field, so that it can be searched\n    // separately.\n    doc.add(Field.Text(\"title\", parser.getTitle()));\n\n    // return the document\n    return doc;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b6de170521ead9f8869e3eff5042162b2af6183a","date":1091820376,"type":3,"author":"Daniel Naber","isMerge":false,"pathNew":"src/demo/org/apache/lucene/demo/HTMLDocument#Document(File).mjava","pathOld":"src/demo/org/apache/lucene/demo/HTMLDocument#Document(File).mjava","sourceNew":"  public static Document Document(File f)\n       throws IOException, InterruptedException  {\n    // make a new, empty document\n    Document doc = new Document();\n\n    // Add the url as a field named \"path\".  Use a Keyword field, so \n    // that it's searchable, but so that no attempt is made\n    // to tokenize the field into words.\n    doc.add(Field.Keyword(\"path\", f.getPath().replace(dirSep, '/')));\n\n    // Add the last modified date of the file a field named \"modified\".  Use a\n    // Keyword field, so that it's searchable, but so that no attempt is made\n    // to tokenize the field into words.\n    doc.add(Field.Keyword(\"modified\",\n\t\t\t  DateField.timeToString(f.lastModified())));\n\n    // Add the uid as a field, so that index can be incrementally maintained.\n    // This field is not stored with document, it is indexed, but it is not\n    // tokenized prior to indexing.\n    doc.add(new Field(\"uid\", uid(f), false, true, false));\n\n    FileInputStream fis = null;\n    try {\n      fis = new FileInputStream(f);\n      HTMLParser parser = new HTMLParser(fis);\n      \n      // Add the tag-stripped contents as a Reader-valued Text field so it will\n      // get tokenized and indexed.\n      doc.add(Field.Text(\"contents\", parser.getReader()));\n\n      // Add the summary as an UnIndexed field, so that it is stored and returned\n      // with hit documents for display.\n      doc.add(Field.UnIndexed(\"summary\", parser.getSummary()));\n\n      // Add the title as a separate Text field, so that it can be searched\n      // separately.\n      doc.add(Field.Text(\"title\", parser.getTitle()));\n    } finally {\n      if (fis != null)\n        fis.close();\n    }\n\n    // return the document\n    return doc;\n  }\n\n","sourceOld":"  public static Document Document(File f)\n       throws IOException, InterruptedException  {\n    // make a new, empty document\n    Document doc = new Document();\n\n    // Add the url as a field named \"path\".  Use a Keyword field, so \n    // that it's searchable, but so that no attempt is made\n    // to tokenize the field into words.\n    doc.add(Field.Keyword(\"path\", f.getPath().replace(dirSep, '/')));\n\n    // Add the last modified date of the file a field named \"modified\".  Use a\n    // Keyword field, so that it's searchable, but so that no attempt is made\n    // to tokenize the field into words.\n    doc.add(Field.Keyword(\"modified\",\n\t\t\t  DateField.timeToString(f.lastModified())));\n\n    // Add the uid as a field, so that index can be incrementally maintained.\n    // This field is not stored with document, it is indexed, but it is not\n    // tokenized prior to indexing.\n    doc.add(new Field(\"uid\", uid(f), false, true, false));\n\n    HTMLParser parser = new HTMLParser(f);\n\n    // Add the tag-stripped contents as a Reader-valued Text field so it will\n    // get tokenized and indexed.\n    doc.add(Field.Text(\"contents\", parser.getReader()));\n\n    // Add the summary as an UnIndexed field, so that it is stored and returned\n    // with hit documents for display.\n    doc.add(Field.UnIndexed(\"summary\", parser.getSummary()));\n\n    // Add the title as a separate Text field, so that it can be searched\n    // separately.\n    doc.add(Field.Text(\"title\", parser.getTitle()));\n\n    // return the document\n    return doc;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c04c207670175ad4b1ca26012560c4edf8cc64d2","date":1094077664,"type":3,"author":"Daniel Naber","isMerge":false,"pathNew":"src/demo/org/apache/lucene/demo/HTMLDocument#Document(File).mjava","pathOld":"src/demo/org/apache/lucene/demo/HTMLDocument#Document(File).mjava","sourceNew":"  public static Document Document(File f)\n       throws IOException, InterruptedException  {\n    // make a new, empty document\n    Document doc = new Document();\n\n    // Add the url as a field named \"path\".  Use a field that is \n    // indexed (i.e. searchable), but don't tokenize the field into words.\n    doc.add(new Field(\"path\", f.getPath().replace(dirSep, '/'), Field.Store.YES,\n        Field.Index.UN_TOKENIZED));\n\n    // Add the last modified date of the file a field named \"modified\".  \n    // Use a field that is indexed (i.e. searchable), but don't tokenize\n    // the field into words.\n    doc.add(new Field(\"modified\", DateField.timeToString(f.lastModified()),\n        Field.Store.YES, Field.Index.UN_TOKENIZED));\n\n    // Add the uid as a field, so that index can be incrementally maintained.\n    // This field is not stored with document, it is indexed, but it is not\n    // tokenized prior to indexing.\n    doc.add(new Field(\"uid\", uid(f), Field.Store.NO, Field.Index.UN_TOKENIZED));\n\n    FileInputStream fis = null;\n    try {\n      fis = new FileInputStream(f);\n      HTMLParser parser = new HTMLParser(fis);\n      \n      // Add the tag-stripped contents as a Reader-valued Text field so it will\n      // get tokenized and indexed.\n      doc.add(new Field(\"contents\", parser.getReader()));\n\n      // Add the summary as a field that is stored and returned with\n      // hit documents for display.\n      doc.add(new Field(\"summary\", parser.getSummary(), Field.Store.YES, Field.Index.NO));\n\n      // Add the title as a field that it can be searched and that is stored.\n      doc.add(new Field(\"title\", parser.getTitle(), Field.Store.YES, Field.Index.TOKENIZED));\n    } finally {\n      if (fis != null)\n        fis.close();\n    }\n\n    // return the document\n    return doc;\n  }\n\n","sourceOld":"  public static Document Document(File f)\n       throws IOException, InterruptedException  {\n    // make a new, empty document\n    Document doc = new Document();\n\n    // Add the url as a field named \"path\".  Use a Keyword field, so \n    // that it's searchable, but so that no attempt is made\n    // to tokenize the field into words.\n    doc.add(Field.Keyword(\"path\", f.getPath().replace(dirSep, '/')));\n\n    // Add the last modified date of the file a field named \"modified\".  Use a\n    // Keyword field, so that it's searchable, but so that no attempt is made\n    // to tokenize the field into words.\n    doc.add(Field.Keyword(\"modified\",\n\t\t\t  DateField.timeToString(f.lastModified())));\n\n    // Add the uid as a field, so that index can be incrementally maintained.\n    // This field is not stored with document, it is indexed, but it is not\n    // tokenized prior to indexing.\n    doc.add(new Field(\"uid\", uid(f), false, true, false));\n\n    FileInputStream fis = null;\n    try {\n      fis = new FileInputStream(f);\n      HTMLParser parser = new HTMLParser(fis);\n      \n      // Add the tag-stripped contents as a Reader-valued Text field so it will\n      // get tokenized and indexed.\n      doc.add(Field.Text(\"contents\", parser.getReader()));\n\n      // Add the summary as an UnIndexed field, so that it is stored and returned\n      // with hit documents for display.\n      doc.add(Field.UnIndexed(\"summary\", parser.getSummary()));\n\n      // Add the title as a separate Text field, so that it can be searched\n      // separately.\n      doc.add(Field.Text(\"title\", parser.getTitle()));\n    } finally {\n      if (fis != null)\n        fis.close();\n    }\n\n    // return the document\n    return doc;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"426b1f604ca4a5f07bd99a50f2cb66c29604e8ae","date":1094420877,"type":3,"author":"Daniel Naber","isMerge":false,"pathNew":"src/demo/org/apache/lucene/demo/HTMLDocument#Document(File).mjava","pathOld":"src/demo/org/apache/lucene/demo/HTMLDocument#Document(File).mjava","sourceNew":"  public static Document Document(File f)\n       throws IOException, InterruptedException  {\n    // make a new, empty document\n    Document doc = new Document();\n\n    // Add the url as a field named \"path\".  Use a field that is \n    // indexed (i.e. searchable), but don't tokenize the field into words.\n    doc.add(new Field(\"path\", f.getPath().replace(dirSep, '/'), Field.Store.YES,\n        Field.Index.UN_TOKENIZED));\n\n    // Add the last modified date of the file a field named \"modified\".  \n    // Use a field that is indexed (i.e. searchable), but don't tokenize\n    // the field into words.\n    doc.add(new Field(\"modified\",\n        DateTools.timeToString(f.lastModified(), DateTools.Resolution.MINUTE),\n        Field.Store.YES, Field.Index.UN_TOKENIZED));\n\n    // Add the uid as a field, so that index can be incrementally maintained.\n    // This field is not stored with document, it is indexed, but it is not\n    // tokenized prior to indexing.\n    doc.add(new Field(\"uid\", uid(f), Field.Store.NO, Field.Index.UN_TOKENIZED));\n\n    FileInputStream fis = null;\n    try {\n      fis = new FileInputStream(f);\n      HTMLParser parser = new HTMLParser(fis);\n      \n      // Add the tag-stripped contents as a Reader-valued Text field so it will\n      // get tokenized and indexed.\n      doc.add(new Field(\"contents\", parser.getReader()));\n\n      // Add the summary as a field that is stored and returned with\n      // hit documents for display.\n      doc.add(new Field(\"summary\", parser.getSummary(), Field.Store.YES, Field.Index.NO));\n\n      // Add the title as a field that it can be searched and that is stored.\n      doc.add(new Field(\"title\", parser.getTitle(), Field.Store.YES, Field.Index.TOKENIZED));\n    } finally {\n      if (fis != null)\n        fis.close();\n    }\n\n    // return the document\n    return doc;\n  }\n\n","sourceOld":"  public static Document Document(File f)\n       throws IOException, InterruptedException  {\n    // make a new, empty document\n    Document doc = new Document();\n\n    // Add the url as a field named \"path\".  Use a field that is \n    // indexed (i.e. searchable), but don't tokenize the field into words.\n    doc.add(new Field(\"path\", f.getPath().replace(dirSep, '/'), Field.Store.YES,\n        Field.Index.UN_TOKENIZED));\n\n    // Add the last modified date of the file a field named \"modified\".  \n    // Use a field that is indexed (i.e. searchable), but don't tokenize\n    // the field into words.\n    doc.add(new Field(\"modified\", DateField.timeToString(f.lastModified()),\n        Field.Store.YES, Field.Index.UN_TOKENIZED));\n\n    // Add the uid as a field, so that index can be incrementally maintained.\n    // This field is not stored with document, it is indexed, but it is not\n    // tokenized prior to indexing.\n    doc.add(new Field(\"uid\", uid(f), Field.Store.NO, Field.Index.UN_TOKENIZED));\n\n    FileInputStream fis = null;\n    try {\n      fis = new FileInputStream(f);\n      HTMLParser parser = new HTMLParser(fis);\n      \n      // Add the tag-stripped contents as a Reader-valued Text field so it will\n      // get tokenized and indexed.\n      doc.add(new Field(\"contents\", parser.getReader()));\n\n      // Add the summary as a field that is stored and returned with\n      // hit documents for display.\n      doc.add(new Field(\"summary\", parser.getSummary(), Field.Store.YES, Field.Index.NO));\n\n      // Add the title as a field that it can be searched and that is stored.\n      doc.add(new Field(\"title\", parser.getTitle(), Field.Store.YES, Field.Index.TOKENIZED));\n    } finally {\n      if (fis != null)\n        fis.close();\n    }\n\n    // return the document\n    return doc;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b94de30789d3265084ce35298d0675ada43e7643","date":1121460314,"type":3,"author":"Daniel Naber","isMerge":false,"pathNew":"src/demo/org/apache/lucene/demo/HTMLDocument#Document(File).mjava","pathOld":"src/demo/org/apache/lucene/demo/HTMLDocument#Document(File).mjava","sourceNew":"  public static Document Document(File f)\n       throws IOException, InterruptedException  {\n    // make a new, empty document\n    Document doc = new Document();\n\n    // Add the url as a field named \"path\".  Use a field that is \n    // indexed (i.e. searchable), but don't tokenize the field into words.\n    doc.add(new Field(\"path\", f.getPath().replace(dirSep, '/'), Field.Store.YES,\n        Field.Index.UN_TOKENIZED));\n\n    // Add the last modified date of the file a field named \"modified\".  \n    // Use a field that is indexed (i.e. searchable), but don't tokenize\n    // the field into words.\n    doc.add(new Field(\"modified\",\n        DateTools.timeToString(f.lastModified(), DateTools.Resolution.MINUTE),\n        Field.Store.YES, Field.Index.UN_TOKENIZED));\n\n    // Add the uid as a field, so that index can be incrementally maintained.\n    // This field is not stored with document, it is indexed, but it is not\n    // tokenized prior to indexing.\n    doc.add(new Field(\"uid\", uid(f), Field.Store.NO, Field.Index.UN_TOKENIZED));\n\n    FileInputStream fis = new FileInputStream(f);\n    HTMLParser parser = new HTMLParser(fis);\n      \n    // Add the tag-stripped contents as a Reader-valued Text field so it will\n    // get tokenized and indexed.\n    doc.add(new Field(\"contents\", parser.getReader()));\n\n    // Add the summary as a field that is stored and returned with\n    // hit documents for display.\n    doc.add(new Field(\"summary\", parser.getSummary(), Field.Store.YES, Field.Index.NO));\n\n    // Add the title as a field that it can be searched and that is stored.\n    doc.add(new Field(\"title\", parser.getTitle(), Field.Store.YES, Field.Index.TOKENIZED));\n\n    // return the document\n    return doc;\n  }\n\n","sourceOld":"  public static Document Document(File f)\n       throws IOException, InterruptedException  {\n    // make a new, empty document\n    Document doc = new Document();\n\n    // Add the url as a field named \"path\".  Use a field that is \n    // indexed (i.e. searchable), but don't tokenize the field into words.\n    doc.add(new Field(\"path\", f.getPath().replace(dirSep, '/'), Field.Store.YES,\n        Field.Index.UN_TOKENIZED));\n\n    // Add the last modified date of the file a field named \"modified\".  \n    // Use a field that is indexed (i.e. searchable), but don't tokenize\n    // the field into words.\n    doc.add(new Field(\"modified\",\n        DateTools.timeToString(f.lastModified(), DateTools.Resolution.MINUTE),\n        Field.Store.YES, Field.Index.UN_TOKENIZED));\n\n    // Add the uid as a field, so that index can be incrementally maintained.\n    // This field is not stored with document, it is indexed, but it is not\n    // tokenized prior to indexing.\n    doc.add(new Field(\"uid\", uid(f), Field.Store.NO, Field.Index.UN_TOKENIZED));\n\n    FileInputStream fis = null;\n    try {\n      fis = new FileInputStream(f);\n      HTMLParser parser = new HTMLParser(fis);\n      \n      // Add the tag-stripped contents as a Reader-valued Text field so it will\n      // get tokenized and indexed.\n      doc.add(new Field(\"contents\", parser.getReader()));\n\n      // Add the summary as a field that is stored and returned with\n      // hit documents for display.\n      doc.add(new Field(\"summary\", parser.getSummary(), Field.Store.YES, Field.Index.NO));\n\n      // Add the title as a field that it can be searched and that is stored.\n      doc.add(new Field(\"title\", parser.getTitle(), Field.Store.YES, Field.Index.TOKENIZED));\n    } finally {\n      if (fis != null)\n        fis.close();\n    }\n\n    // return the document\n    return doc;\n  }\n\n","bugFix":null,"bugIntro":["fb38e04906cc704c95b1bb9cdc7a960017b0cc25"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b5015bd4c211c4f399ae66ee20fe6841ba5b0b6a","date":1221082732,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/demo/org/apache/lucene/demo/HTMLDocument#Document(File).mjava","pathOld":"src/demo/org/apache/lucene/demo/HTMLDocument#Document(File).mjava","sourceNew":"  public static Document Document(File f)\n       throws IOException, InterruptedException  {\n    // make a new, empty document\n    Document doc = new Document();\n\n    // Add the url as a field named \"path\".  Use a field that is \n    // indexed (i.e. searchable), but don't tokenize the field into words.\n    doc.add(new Field(\"path\", f.getPath().replace(dirSep, '/'), Field.Store.YES,\n        Field.Index.NOT_ANALYZED));\n\n    // Add the last modified date of the file a field named \"modified\".  \n    // Use a field that is indexed (i.e. searchable), but don't tokenize\n    // the field into words.\n    doc.add(new Field(\"modified\",\n        DateTools.timeToString(f.lastModified(), DateTools.Resolution.MINUTE),\n        Field.Store.YES, Field.Index.NOT_ANALYZED));\n\n    // Add the uid as a field, so that index can be incrementally maintained.\n    // This field is not stored with document, it is indexed, but it is not\n    // tokenized prior to indexing.\n    doc.add(new Field(\"uid\", uid(f), Field.Store.NO, Field.Index.NOT_ANALYZED));\n\n    FileInputStream fis = new FileInputStream(f);\n    HTMLParser parser = new HTMLParser(fis);\n      \n    // Add the tag-stripped contents as a Reader-valued Text field so it will\n    // get tokenized and indexed.\n    doc.add(new Field(\"contents\", parser.getReader()));\n\n    // Add the summary as a field that is stored and returned with\n    // hit documents for display.\n    doc.add(new Field(\"summary\", parser.getSummary(), Field.Store.YES, Field.Index.NO));\n\n    // Add the title as a field that it can be searched and that is stored.\n    doc.add(new Field(\"title\", parser.getTitle(), Field.Store.YES, Field.Index.ANALYZED));\n\n    // return the document\n    return doc;\n  }\n\n","sourceOld":"  public static Document Document(File f)\n       throws IOException, InterruptedException  {\n    // make a new, empty document\n    Document doc = new Document();\n\n    // Add the url as a field named \"path\".  Use a field that is \n    // indexed (i.e. searchable), but don't tokenize the field into words.\n    doc.add(new Field(\"path\", f.getPath().replace(dirSep, '/'), Field.Store.YES,\n        Field.Index.UN_TOKENIZED));\n\n    // Add the last modified date of the file a field named \"modified\".  \n    // Use a field that is indexed (i.e. searchable), but don't tokenize\n    // the field into words.\n    doc.add(new Field(\"modified\",\n        DateTools.timeToString(f.lastModified(), DateTools.Resolution.MINUTE),\n        Field.Store.YES, Field.Index.UN_TOKENIZED));\n\n    // Add the uid as a field, so that index can be incrementally maintained.\n    // This field is not stored with document, it is indexed, but it is not\n    // tokenized prior to indexing.\n    doc.add(new Field(\"uid\", uid(f), Field.Store.NO, Field.Index.UN_TOKENIZED));\n\n    FileInputStream fis = new FileInputStream(f);\n    HTMLParser parser = new HTMLParser(fis);\n      \n    // Add the tag-stripped contents as a Reader-valued Text field so it will\n    // get tokenized and indexed.\n    doc.add(new Field(\"contents\", parser.getReader()));\n\n    // Add the summary as a field that is stored and returned with\n    // hit documents for display.\n    doc.add(new Field(\"summary\", parser.getSummary(), Field.Store.YES, Field.Index.NO));\n\n    // Add the title as a field that it can be searched and that is stored.\n    doc.add(new Field(\"title\", parser.getTitle(), Field.Store.YES, Field.Index.TOKENIZED));\n\n    // return the document\n    return doc;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"9454a6510e2db155fb01faa5c049b06ece95fab9","date":1453508333,"type":5,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/src/demo/org/apache/lucene/demo/HTMLDocument#Document(File).mjava","pathOld":"src/demo/org/apache/lucene/demo/HTMLDocument#Document(File).mjava","sourceNew":"  public static Document Document(File f)\n       throws IOException, InterruptedException  {\n    // make a new, empty document\n    Document doc = new Document();\n\n    // Add the url as a field named \"path\".  Use a field that is \n    // indexed (i.e. searchable), but don't tokenize the field into words.\n    doc.add(new Field(\"path\", f.getPath().replace(dirSep, '/'), Field.Store.YES,\n        Field.Index.NOT_ANALYZED));\n\n    // Add the last modified date of the file a field named \"modified\".  \n    // Use a field that is indexed (i.e. searchable), but don't tokenize\n    // the field into words.\n    doc.add(new Field(\"modified\",\n        DateTools.timeToString(f.lastModified(), DateTools.Resolution.MINUTE),\n        Field.Store.YES, Field.Index.NOT_ANALYZED));\n\n    // Add the uid as a field, so that index can be incrementally maintained.\n    // This field is not stored with document, it is indexed, but it is not\n    // tokenized prior to indexing.\n    doc.add(new Field(\"uid\", uid(f), Field.Store.NO, Field.Index.NOT_ANALYZED));\n\n    FileInputStream fis = new FileInputStream(f);\n    HTMLParser parser = new HTMLParser(fis);\n      \n    // Add the tag-stripped contents as a Reader-valued Text field so it will\n    // get tokenized and indexed.\n    doc.add(new Field(\"contents\", parser.getReader()));\n\n    // Add the summary as a field that is stored and returned with\n    // hit documents for display.\n    doc.add(new Field(\"summary\", parser.getSummary(), Field.Store.YES, Field.Index.NO));\n\n    // Add the title as a field that it can be searched and that is stored.\n    doc.add(new Field(\"title\", parser.getTitle(), Field.Store.YES, Field.Index.ANALYZED));\n\n    // return the document\n    return doc;\n  }\n\n","sourceOld":"  public static Document Document(File f)\n       throws IOException, InterruptedException  {\n    // make a new, empty document\n    Document doc = new Document();\n\n    // Add the url as a field named \"path\".  Use a field that is \n    // indexed (i.e. searchable), but don't tokenize the field into words.\n    doc.add(new Field(\"path\", f.getPath().replace(dirSep, '/'), Field.Store.YES,\n        Field.Index.NOT_ANALYZED));\n\n    // Add the last modified date of the file a field named \"modified\".  \n    // Use a field that is indexed (i.e. searchable), but don't tokenize\n    // the field into words.\n    doc.add(new Field(\"modified\",\n        DateTools.timeToString(f.lastModified(), DateTools.Resolution.MINUTE),\n        Field.Store.YES, Field.Index.NOT_ANALYZED));\n\n    // Add the uid as a field, so that index can be incrementally maintained.\n    // This field is not stored with document, it is indexed, but it is not\n    // tokenized prior to indexing.\n    doc.add(new Field(\"uid\", uid(f), Field.Store.NO, Field.Index.NOT_ANALYZED));\n\n    FileInputStream fis = new FileInputStream(f);\n    HTMLParser parser = new HTMLParser(fis);\n      \n    // Add the tag-stripped contents as a Reader-valued Text field so it will\n    // get tokenized and indexed.\n    doc.add(new Field(\"contents\", parser.getReader()));\n\n    // Add the summary as a field that is stored and returned with\n    // hit documents for display.\n    doc.add(new Field(\"summary\", parser.getSummary(), Field.Store.YES, Field.Index.NO));\n\n    // Add the title as a field that it can be searched and that is stored.\n    doc.add(new Field(\"title\", parser.getTitle(), Field.Store.YES, Field.Index.ANALYZED));\n\n    // return the document\n    return doc;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"b94de30789d3265084ce35298d0675ada43e7643":["426b1f604ca4a5f07bd99a50f2cb66c29604e8ae"],"1bbdcd094e2f9e4815621e4b813461caabc9546a":["6585acee8c9458b9745b49462abd05c2aa4f23d5"],"b6de170521ead9f8869e3eff5042162b2af6183a":["1bbdcd094e2f9e4815621e4b813461caabc9546a"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"426b1f604ca4a5f07bd99a50f2cb66c29604e8ae":["c04c207670175ad4b1ca26012560c4edf8cc64d2"],"b5015bd4c211c4f399ae66ee20fe6841ba5b0b6a":["b94de30789d3265084ce35298d0675ada43e7643"],"6585acee8c9458b9745b49462abd05c2aa4f23d5":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["b5015bd4c211c4f399ae66ee20fe6841ba5b0b6a"],"c04c207670175ad4b1ca26012560c4edf8cc64d2":["b6de170521ead9f8869e3eff5042162b2af6183a"]},"commit2Childs":{"b94de30789d3265084ce35298d0675ada43e7643":["b5015bd4c211c4f399ae66ee20fe6841ba5b0b6a"],"1bbdcd094e2f9e4815621e4b813461caabc9546a":["b6de170521ead9f8869e3eff5042162b2af6183a"],"b6de170521ead9f8869e3eff5042162b2af6183a":["c04c207670175ad4b1ca26012560c4edf8cc64d2"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["6585acee8c9458b9745b49462abd05c2aa4f23d5"],"426b1f604ca4a5f07bd99a50f2cb66c29604e8ae":["b94de30789d3265084ce35298d0675ada43e7643"],"b5015bd4c211c4f399ae66ee20fe6841ba5b0b6a":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"6585acee8c9458b9745b49462abd05c2aa4f23d5":["1bbdcd094e2f9e4815621e4b813461caabc9546a"],"c04c207670175ad4b1ca26012560c4edf8cc64d2":["426b1f604ca4a5f07bd99a50f2cb66c29604e8ae"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"9454a6510e2db155fb01faa5c049b06ece95fab9":["cd5edd1f2b162a5cfa08efd17851a07373a96817"]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}