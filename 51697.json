{"path":"lucene/queries/src/java/org/apache/lucene/queries/TermsFilter#getDocIdSet(LeafReaderContext,Bits).mjava","commits":[{"id":"c9fb5f46e264daf5ba3860defe623a89d202dd87","date":1411516315,"type":0,"author":"Ryan Ernst","isMerge":false,"pathNew":"lucene/queries/src/java/org/apache/lucene/queries/TermsFilter#getDocIdSet(LeafReaderContext,Bits).mjava","pathOld":"/dev/null","sourceNew":"  @Override\n  public DocIdSet getDocIdSet(LeafReaderContext context, Bits acceptDocs) throws IOException {\n    final LeafReader reader = context.reader();\n    FixedBitSet result = null;  // lazy init if needed - no need to create a big bitset ahead of time\n    final Fields fields = reader.fields();\n    final BytesRef spare = new BytesRef(this.termsBytes);\n    if (fields == null) {\n      return result;\n    }\n    Terms terms = null;\n    TermsEnum termsEnum = null;\n    DocsEnum docs = null;\n    for (TermsAndField termsAndField : this.termsAndFields) {\n      if ((terms = fields.terms(termsAndField.field)) != null) {\n        termsEnum = terms.iterator(termsEnum); // this won't return null\n        for (int i = termsAndField.start; i < termsAndField.end; i++) {\n          spare.offset = offsets[i];\n          spare.length = offsets[i+1] - offsets[i];\n          if (termsEnum.seekExact(spare)) {\n            docs = termsEnum.docs(acceptDocs, docs, DocsEnum.FLAG_NONE); // no freq since we don't need them\n            if (result == null) {\n              if (docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                result = new FixedBitSet(reader.maxDoc());\n                // lazy init but don't do it in the hot loop since we could read many docs\n                result.set(docs.docID());\n              }\n            }\n            while (docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              result.set(docs.docID());\n            }\n          }\n        }\n      }\n    }\n    return result;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["8028ab7a24273833d53d35eb160dba5b57283cf5"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"59ce67ef5584d0d65a576a6bbe06322cc84eb9b0","date":1412077943,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/queries/src/java/org/apache/lucene/queries/TermsFilter#getDocIdSet(LeafReaderContext,Bits).mjava","pathOld":"lucene/queries/src/java/org/apache/lucene/queries/TermsFilter#getDocIdSet(LeafReaderContext,Bits).mjava","sourceNew":"  @Override\n  public DocIdSet getDocIdSet(LeafReaderContext context, Bits acceptDocs) throws IOException {\n    final LeafReader reader = context.reader();\n    DocIdSetBuilder builder = new DocIdSetBuilder(reader.maxDoc());\n    final Fields fields = reader.fields();\n    final BytesRef spare = new BytesRef(this.termsBytes);\n    if (fields == null) {\n      return builder.build();\n    }\n    Terms terms = null;\n    TermsEnum termsEnum = null;\n    DocsEnum docs = null;\n    for (TermsAndField termsAndField : this.termsAndFields) {\n      if ((terms = fields.terms(termsAndField.field)) != null) {\n        termsEnum = terms.iterator(termsEnum); // this won't return null\n        for (int i = termsAndField.start; i < termsAndField.end; i++) {\n          spare.offset = offsets[i];\n          spare.length = offsets[i+1] - offsets[i];\n          if (termsEnum.seekExact(spare)) {\n            docs = termsEnum.docs(acceptDocs, docs, DocsEnum.FLAG_NONE); // no freq since we don't need them\n            builder.or(docs);\n          }\n        }\n      }\n    }\n    return builder.build();\n  }\n\n","sourceOld":"  @Override\n  public DocIdSet getDocIdSet(LeafReaderContext context, Bits acceptDocs) throws IOException {\n    final LeafReader reader = context.reader();\n    FixedBitSet result = null;  // lazy init if needed - no need to create a big bitset ahead of time\n    final Fields fields = reader.fields();\n    final BytesRef spare = new BytesRef(this.termsBytes);\n    if (fields == null) {\n      return result;\n    }\n    Terms terms = null;\n    TermsEnum termsEnum = null;\n    DocsEnum docs = null;\n    for (TermsAndField termsAndField : this.termsAndFields) {\n      if ((terms = fields.terms(termsAndField.field)) != null) {\n        termsEnum = terms.iterator(termsEnum); // this won't return null\n        for (int i = termsAndField.start; i < termsAndField.end; i++) {\n          spare.offset = offsets[i];\n          spare.length = offsets[i+1] - offsets[i];\n          if (termsEnum.seekExact(spare)) {\n            docs = termsEnum.docs(acceptDocs, docs, DocsEnum.FLAG_NONE); // no freq since we don't need them\n            if (result == null) {\n              if (docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                result = new FixedBitSet(reader.maxDoc());\n                // lazy init but don't do it in the hot loop since we could read many docs\n                result.set(docs.docID());\n              }\n            }\n            while (docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              result.set(docs.docID());\n            }\n          }\n        }\n      }\n    }\n    return result;\n  }\n\n","bugFix":null,"bugIntro":["8028ab7a24273833d53d35eb160dba5b57283cf5"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d9a47902d6207303f5ed3e7aaca62ca33433af66","date":1412435312,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/queries/src/java/org/apache/lucene/queries/TermsFilter#getDocIdSet(LeafReaderContext,Bits).mjava","pathOld":"lucene/queries/src/java/org/apache/lucene/queries/TermsFilter#getDocIdSet(LeafReaderContext,Bits).mjava","sourceNew":"  @Override\n  public DocIdSet getDocIdSet(LeafReaderContext context, Bits acceptDocs) throws IOException {\n    final LeafReader reader = context.reader();\n    DocIdSetBuilder builder = new DocIdSetBuilder(reader.maxDoc());\n    final Fields fields = reader.fields();\n    final BytesRef spare = new BytesRef(this.termsBytes);\n    if (fields == null) {\n      return builder.build();\n    }\n    Terms terms = null;\n    TermsEnum termsEnum = null;\n    DocsEnum docs = null;\n    for (TermsAndField termsAndField : this.termsAndFields) {\n      if ((terms = fields.terms(termsAndField.field)) != null) {\n        termsEnum = terms.iterator(termsEnum); // this won't return null\n        for (int i = termsAndField.start; i < termsAndField.end; i++) {\n          spare.offset = offsets[i];\n          spare.length = offsets[i+1] - offsets[i];\n          if (termsEnum.seekExact(spare)) {\n            docs = termsEnum.docs(acceptDocs, docs, DocsEnum.FLAG_NONE); // no freq since we don't need them\n            builder.or(docs);\n          }\n        }\n      }\n    }\n    return builder.build();\n  }\n\n","sourceOld":"  @Override\n  public DocIdSet getDocIdSet(LeafReaderContext context, Bits acceptDocs) throws IOException {\n    final LeafReader reader = context.reader();\n    FixedBitSet result = null;  // lazy init if needed - no need to create a big bitset ahead of time\n    final Fields fields = reader.fields();\n    final BytesRef spare = new BytesRef(this.termsBytes);\n    if (fields == null) {\n      return result;\n    }\n    Terms terms = null;\n    TermsEnum termsEnum = null;\n    DocsEnum docs = null;\n    for (TermsAndField termsAndField : this.termsAndFields) {\n      if ((terms = fields.terms(termsAndField.field)) != null) {\n        termsEnum = terms.iterator(termsEnum); // this won't return null\n        for (int i = termsAndField.start; i < termsAndField.end; i++) {\n          spare.offset = offsets[i];\n          spare.length = offsets[i+1] - offsets[i];\n          if (termsEnum.seekExact(spare)) {\n            docs = termsEnum.docs(acceptDocs, docs, DocsEnum.FLAG_NONE); // no freq since we don't need them\n            if (result == null) {\n              if (docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n                result = new FixedBitSet(reader.maxDoc());\n                // lazy init but don't do it in the hot loop since we could read many docs\n                result.set(docs.docID());\n              }\n            }\n            while (docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {\n              result.set(docs.docID());\n            }\n          }\n        }\n      }\n    }\n    return result;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b012914a8110b2ff1d075ed1ef72aa57084d4897","date":1414685177,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/queries/src/java/org/apache/lucene/queries/TermsFilter#getDocIdSet(LeafReaderContext,Bits).mjava","pathOld":"lucene/queries/src/java/org/apache/lucene/queries/TermsFilter#getDocIdSet(LeafReaderContext,Bits).mjava","sourceNew":"  @Override\n  public DocIdSet getDocIdSet(LeafReaderContext context, Bits acceptDocs) throws IOException {\n    final LeafReader reader = context.reader();\n    BitDocIdSet.Builder builder = new BitDocIdSet.Builder(reader.maxDoc());\n    final Fields fields = reader.fields();\n    final BytesRef spare = new BytesRef(this.termsBytes);\n    if (fields == null) {\n      return builder.build();\n    }\n    Terms terms = null;\n    TermsEnum termsEnum = null;\n    DocsEnum docs = null;\n    for (TermsAndField termsAndField : this.termsAndFields) {\n      if ((terms = fields.terms(termsAndField.field)) != null) {\n        termsEnum = terms.iterator(termsEnum); // this won't return null\n        for (int i = termsAndField.start; i < termsAndField.end; i++) {\n          spare.offset = offsets[i];\n          spare.length = offsets[i+1] - offsets[i];\n          if (termsEnum.seekExact(spare)) {\n            docs = termsEnum.docs(acceptDocs, docs, DocsEnum.FLAG_NONE); // no freq since we don't need them\n            builder.or(docs);\n          }\n        }\n      }\n    }\n    return builder.build();\n  }\n\n","sourceOld":"  @Override\n  public DocIdSet getDocIdSet(LeafReaderContext context, Bits acceptDocs) throws IOException {\n    final LeafReader reader = context.reader();\n    DocIdSetBuilder builder = new DocIdSetBuilder(reader.maxDoc());\n    final Fields fields = reader.fields();\n    final BytesRef spare = new BytesRef(this.termsBytes);\n    if (fields == null) {\n      return builder.build();\n    }\n    Terms terms = null;\n    TermsEnum termsEnum = null;\n    DocsEnum docs = null;\n    for (TermsAndField termsAndField : this.termsAndFields) {\n      if ((terms = fields.terms(termsAndField.field)) != null) {\n        termsEnum = terms.iterator(termsEnum); // this won't return null\n        for (int i = termsAndField.start; i < termsAndField.end; i++) {\n          spare.offset = offsets[i];\n          spare.length = offsets[i+1] - offsets[i];\n          if (termsEnum.seekExact(spare)) {\n            docs = termsEnum.docs(acceptDocs, docs, DocsEnum.FLAG_NONE); // no freq since we don't need them\n            builder.or(docs);\n          }\n        }\n      }\n    }\n    return builder.build();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"8028ab7a24273833d53d35eb160dba5b57283cf5","date":1416767720,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/queries/src/java/org/apache/lucene/queries/TermsFilter#getDocIdSet(LeafReaderContext,Bits).mjava","pathOld":"lucene/queries/src/java/org/apache/lucene/queries/TermsFilter#getDocIdSet(LeafReaderContext,Bits).mjava","sourceNew":"  @Override\n  public DocIdSet getDocIdSet(LeafReaderContext context, Bits acceptDocs) throws IOException {\n    final LeafReader reader = context.reader();\n    BitDocIdSet.Builder builder = new BitDocIdSet.Builder(reader.maxDoc());\n    final Fields fields = reader.fields();\n    final BytesRef spare = new BytesRef(this.termsBytes);\n    Terms terms = null;\n    TermsEnum termsEnum = null;\n    DocsEnum docs = null;\n    for (TermsAndField termsAndField : this.termsAndFields) {\n      if ((terms = fields.terms(termsAndField.field)) != null) {\n        termsEnum = terms.iterator(termsEnum); // this won't return null\n        for (int i = termsAndField.start; i < termsAndField.end; i++) {\n          spare.offset = offsets[i];\n          spare.length = offsets[i+1] - offsets[i];\n          if (termsEnum.seekExact(spare)) {\n            docs = termsEnum.docs(acceptDocs, docs, DocsEnum.FLAG_NONE); // no freq since we don't need them\n            builder.or(docs);\n          }\n        }\n      }\n    }\n    return builder.build();\n  }\n\n","sourceOld":"  @Override\n  public DocIdSet getDocIdSet(LeafReaderContext context, Bits acceptDocs) throws IOException {\n    final LeafReader reader = context.reader();\n    BitDocIdSet.Builder builder = new BitDocIdSet.Builder(reader.maxDoc());\n    final Fields fields = reader.fields();\n    final BytesRef spare = new BytesRef(this.termsBytes);\n    if (fields == null) {\n      return builder.build();\n    }\n    Terms terms = null;\n    TermsEnum termsEnum = null;\n    DocsEnum docs = null;\n    for (TermsAndField termsAndField : this.termsAndFields) {\n      if ((terms = fields.terms(termsAndField.field)) != null) {\n        termsEnum = terms.iterator(termsEnum); // this won't return null\n        for (int i = termsAndField.start; i < termsAndField.end; i++) {\n          spare.offset = offsets[i];\n          spare.length = offsets[i+1] - offsets[i];\n          if (termsEnum.seekExact(spare)) {\n            docs = termsEnum.docs(acceptDocs, docs, DocsEnum.FLAG_NONE); // no freq since we don't need them\n            builder.or(docs);\n          }\n        }\n      }\n    }\n    return builder.build();\n  }\n\n","bugFix":["c9fb5f46e264daf5ba3860defe623a89d202dd87","59ce67ef5584d0d65a576a6bbe06322cc84eb9b0"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"51f5280f31484820499077f41fcdfe92d527d9dc","date":1423229122,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"lucene/queries/src/java/org/apache/lucene/queries/TermsFilter#getDocIdSet(LeafReaderContext,Bits).mjava","pathOld":"lucene/queries/src/java/org/apache/lucene/queries/TermsFilter#getDocIdSet(LeafReaderContext,Bits).mjava","sourceNew":"  @Override\n  public DocIdSet getDocIdSet(LeafReaderContext context, Bits acceptDocs) throws IOException {\n    final LeafReader reader = context.reader();\n    BitDocIdSet.Builder builder = new BitDocIdSet.Builder(reader.maxDoc());\n    final Fields fields = reader.fields();\n    final BytesRef spare = new BytesRef(this.termsBytes);\n    Terms terms = null;\n    TermsEnum termsEnum = null;\n    PostingsEnum docs = null;\n    for (TermsAndField termsAndField : this.termsAndFields) {\n      if ((terms = fields.terms(termsAndField.field)) != null) {\n        termsEnum = terms.iterator(termsEnum); // this won't return null\n        for (int i = termsAndField.start; i < termsAndField.end; i++) {\n          spare.offset = offsets[i];\n          spare.length = offsets[i+1] - offsets[i];\n          if (termsEnum.seekExact(spare)) {\n            docs = termsEnum.postings(acceptDocs, docs, PostingsEnum.FLAG_NONE); // no freq since we don't need them\n            builder.or(docs);\n          }\n        }\n      }\n    }\n    return builder.build();\n  }\n\n","sourceOld":"  @Override\n  public DocIdSet getDocIdSet(LeafReaderContext context, Bits acceptDocs) throws IOException {\n    final LeafReader reader = context.reader();\n    BitDocIdSet.Builder builder = new BitDocIdSet.Builder(reader.maxDoc());\n    final Fields fields = reader.fields();\n    final BytesRef spare = new BytesRef(this.termsBytes);\n    Terms terms = null;\n    TermsEnum termsEnum = null;\n    DocsEnum docs = null;\n    for (TermsAndField termsAndField : this.termsAndFields) {\n      if ((terms = fields.terms(termsAndField.field)) != null) {\n        termsEnum = terms.iterator(termsEnum); // this won't return null\n        for (int i = termsAndField.start; i < termsAndField.end; i++) {\n          spare.offset = offsets[i];\n          spare.length = offsets[i+1] - offsets[i];\n          if (termsEnum.seekExact(spare)) {\n            docs = termsEnum.docs(acceptDocs, docs, DocsEnum.FLAG_NONE); // no freq since we don't need them\n            builder.or(docs);\n          }\n        }\n      }\n    }\n    return builder.build();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e73063b92d958076ef4ae8beb5f493e8ccdcecb4","date":1424177215,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/queries/src/java/org/apache/lucene/queries/TermsFilter#getDocIdSet(LeafReaderContext,Bits).mjava","pathOld":"lucene/queries/src/java/org/apache/lucene/queries/TermsFilter#getDocIdSet(LeafReaderContext,Bits).mjava","sourceNew":"  @Override\n  public DocIdSet getDocIdSet(LeafReaderContext context, Bits acceptDocs) throws IOException {\n    final LeafReader reader = context.reader();\n    BitDocIdSet.Builder builder = new BitDocIdSet.Builder(reader.maxDoc());\n    final Fields fields = reader.fields();\n    final BytesRef spare = new BytesRef(this.termsBytes);\n    Terms terms = null;\n    TermsEnum termsEnum = null;\n    PostingsEnum docs = null;\n    for (TermsAndField termsAndField : this.termsAndFields) {\n      if ((terms = fields.terms(termsAndField.field)) != null) {\n        termsEnum = terms.iterator(termsEnum); // this won't return null\n        for (int i = termsAndField.start; i < termsAndField.end; i++) {\n          spare.offset = offsets[i];\n          spare.length = offsets[i+1] - offsets[i];\n          if (termsEnum.seekExact(spare)) {\n            docs = termsEnum.postings(acceptDocs, docs, PostingsEnum.NONE); // no freq since we don't need them\n            builder.or(docs);\n          }\n        }\n      }\n    }\n    return builder.build();\n  }\n\n","sourceOld":"  @Override\n  public DocIdSet getDocIdSet(LeafReaderContext context, Bits acceptDocs) throws IOException {\n    final LeafReader reader = context.reader();\n    BitDocIdSet.Builder builder = new BitDocIdSet.Builder(reader.maxDoc());\n    final Fields fields = reader.fields();\n    final BytesRef spare = new BytesRef(this.termsBytes);\n    Terms terms = null;\n    TermsEnum termsEnum = null;\n    PostingsEnum docs = null;\n    for (TermsAndField termsAndField : this.termsAndFields) {\n      if ((terms = fields.terms(termsAndField.field)) != null) {\n        termsEnum = terms.iterator(termsEnum); // this won't return null\n        for (int i = termsAndField.start; i < termsAndField.end; i++) {\n          spare.offset = offsets[i];\n          spare.length = offsets[i+1] - offsets[i];\n          if (termsEnum.seekExact(spare)) {\n            docs = termsEnum.postings(acceptDocs, docs, PostingsEnum.FLAG_NONE); // no freq since we don't need them\n            builder.or(docs);\n          }\n        }\n      }\n    }\n    return builder.build();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c2042d3e27841c5b60112990fc33559e10ccf6dd","date":1424537395,"type":4,"author":"Adrien Grand","isMerge":false,"pathNew":"/dev/null","pathOld":"lucene/queries/src/java/org/apache/lucene/queries/TermsFilter#getDocIdSet(LeafReaderContext,Bits).mjava","sourceNew":null,"sourceOld":"  @Override\n  public DocIdSet getDocIdSet(LeafReaderContext context, Bits acceptDocs) throws IOException {\n    final LeafReader reader = context.reader();\n    BitDocIdSet.Builder builder = new BitDocIdSet.Builder(reader.maxDoc());\n    final Fields fields = reader.fields();\n    final BytesRef spare = new BytesRef(this.termsBytes);\n    Terms terms = null;\n    TermsEnum termsEnum = null;\n    PostingsEnum docs = null;\n    for (TermsAndField termsAndField : this.termsAndFields) {\n      if ((terms = fields.terms(termsAndField.field)) != null) {\n        termsEnum = terms.iterator(termsEnum); // this won't return null\n        for (int i = termsAndField.start; i < termsAndField.end; i++) {\n          spare.offset = offsets[i];\n          spare.length = offsets[i+1] - offsets[i];\n          if (termsEnum.seekExact(spare)) {\n            docs = termsEnum.postings(acceptDocs, docs, PostingsEnum.NONE); // no freq since we don't need them\n            builder.or(docs);\n          }\n        }\n      }\n    }\n    return builder.build();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"e73063b92d958076ef4ae8beb5f493e8ccdcecb4":["51f5280f31484820499077f41fcdfe92d527d9dc"],"8028ab7a24273833d53d35eb160dba5b57283cf5":["b012914a8110b2ff1d075ed1ef72aa57084d4897"],"b012914a8110b2ff1d075ed1ef72aa57084d4897":["59ce67ef5584d0d65a576a6bbe06322cc84eb9b0"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"d9a47902d6207303f5ed3e7aaca62ca33433af66":["c9fb5f46e264daf5ba3860defe623a89d202dd87","59ce67ef5584d0d65a576a6bbe06322cc84eb9b0"],"51f5280f31484820499077f41fcdfe92d527d9dc":["8028ab7a24273833d53d35eb160dba5b57283cf5"],"59ce67ef5584d0d65a576a6bbe06322cc84eb9b0":["c9fb5f46e264daf5ba3860defe623a89d202dd87"],"c2042d3e27841c5b60112990fc33559e10ccf6dd":["e73063b92d958076ef4ae8beb5f493e8ccdcecb4"],"c9fb5f46e264daf5ba3860defe623a89d202dd87":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["c2042d3e27841c5b60112990fc33559e10ccf6dd"]},"commit2Childs":{"e73063b92d958076ef4ae8beb5f493e8ccdcecb4":["c2042d3e27841c5b60112990fc33559e10ccf6dd"],"8028ab7a24273833d53d35eb160dba5b57283cf5":["51f5280f31484820499077f41fcdfe92d527d9dc"],"b012914a8110b2ff1d075ed1ef72aa57084d4897":["8028ab7a24273833d53d35eb160dba5b57283cf5"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["c9fb5f46e264daf5ba3860defe623a89d202dd87"],"d9a47902d6207303f5ed3e7aaca62ca33433af66":[],"51f5280f31484820499077f41fcdfe92d527d9dc":["e73063b92d958076ef4ae8beb5f493e8ccdcecb4"],"59ce67ef5584d0d65a576a6bbe06322cc84eb9b0":["b012914a8110b2ff1d075ed1ef72aa57084d4897","d9a47902d6207303f5ed3e7aaca62ca33433af66"],"c9fb5f46e264daf5ba3860defe623a89d202dd87":["d9a47902d6207303f5ed3e7aaca62ca33433af66","59ce67ef5584d0d65a576a6bbe06322cc84eb9b0"],"c2042d3e27841c5b60112990fc33559e10ccf6dd":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["d9a47902d6207303f5ed3e7aaca62ca33433af66","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}