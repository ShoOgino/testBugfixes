{"path":"solr/core/src/test/org/apache/solr/TestDistributedSearch#doTest().mjava","commits":[{"id":"c903c3d15906a3da96b8c0c2fb704491005fdbdb","date":1453508227,"type":1,"author":"Dawid Weiss","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/TestDistributedSearch#doTest().mjava","pathOld":"solr/src/test/org/apache/solr/TestDistributedSearch#doTest().mjava","sourceNew":"  @Override\n  public void doTest() throws Exception {\n    int backupStress = stress; // make a copy so we can restore\n\n\n    del(\"*:*\");\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\", \n           tdate_a, \"2010-04-20T11:00:00Z\",\n           tdate_b, \"2009-08-20T11:00:00Z\",\n           \"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\", \n           tdate_a, \"2010-05-02T11:00:00Z\",\n           tdate_b, \"2009-11-02T11:00:00Z\");\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\", \n           tdate_a, \"2010-05-03T11:00:00Z\");\n    indexr(id,4, i1, -100 ,tlong, 101,\n           t1,\"the quick fox jumped over the lazy dog\", \n           tdate_a, \"2010-05-03T11:00:00Z\",\n           tdate_b, \"2010-05-03T11:00:00Z\");\n    indexr(id,5, i1, 500, tlong, 500 ,\n           t1,\"the quick fox jumped way over the lazy dog\", \n           tdate_a, \"2010-05-05T11:00:00Z\");\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,\n           tdate_b, \"2010-01-05T11:00:00Z\",\n           t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,\n           t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,\n           t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,\n           t1,\"no eggs on wall, lesson learned\", \n           oddField, \"odd man out\");\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n\n    handle.clear();\n    handle.put(\"QTime\", SKIPVAL);\n    handle.put(\"timestamp\", SKIPVAL);\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(\"q\",\"*:*\", \"sort\",f+\" desc\");\n      query(\"q\",\"*:*\", \"sort\",f+\" asc\");\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",\"{!func}add(\"+i1+\",5)\"+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" asc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\");\n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"score\");  // test legacy behavior - \"score\"==\"*,score\"\n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 desc\");\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"{!func}\"+i1);// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(\"q\",\"{!func}\"+i1, \"fl\",\"*,score\");  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"quick\");\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\");\n    query(\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\");  // no fields in returned docs\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\");\n\n    handle.put(\"score\", SKIPVAL);\n    query(\"q\",\"quick\",\"fl\",\"*,score\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\");\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"matchesnothing\",\"fl\",\"*,score\");  \n\n    // test that a single NOW value is propagated to all shards... if that is true\n    // then the primary sort should always be a tie and then the secondary should always decide\n    query(\"q\",\"{!func}ms(NOW)\", \"sort\",\"score desc,\"+i1+\" desc\",\"fl\",\"id\");    \n\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\");\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2);\n\n    // simple date facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date.other\", \"all\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // date facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date\",tdate_b, \n          \"facet.date.other\", \"all\", \n          \"f.\"+tdate_b+\".facet.date.start\",\"2009-05-01T11:00:00Z\", \n          \"f.\"+tdate_b+\".facet.date.gap\",\"+3MONTHS\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // simple range facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"facet.range.end\",900);\n\n    // range facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range\",i1, \n          \"f.\"+i1+\".facet.range.start\",300, \n          \"f.\"+i1+\".facet.range.gap\",87, \n          \"facet.range.end\",900,\n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"f.\"+tlong+\".facet.range.end\",900);\n\n    stress=0;  // turn off stress... we want to tex max combos in min time\n    for (int i=0; i<25*RANDOM_MULTIPLIER; i++) {\n      String f = fieldNames[random.nextInt(fieldNames.length)];\n      if (random.nextBoolean()) f = t1;  // the text field is a really interesting one to facet on (and it's multi-valued too)\n\n      // we want a random query and not just *:* so we'll get zero counts in facets also\n      // TODO: do a better random query\n      String q = random.nextBoolean() ? \"*:*\" : \"id:(1 3 5 7 9 11 13) OR id:[100 TO \" + random.nextInt(50) + \"]\";\n\n      int nolimit = random.nextBoolean() ? -1 : 10000;  // these should be equivalent\n\n      // if limit==-1, we should always get exact matches\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"count\", \"facet.mincount\",random.nextInt(5), \"facet.offset\",random.nextInt(10));\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"index\", \"facet.mincount\",random.nextInt(5), \"facet.offset\",random.nextInt(10));\n      // for index sort, we should get exact results for mincount <= 1\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.sort\",\"index\", \"facet.mincount\",random.nextInt(2), \"facet.offset\",random.nextInt(10), \"facet.limit\",random.nextInt(11)-1);\n    }\n    stress = backupStress;  // restore stress\n\n    // test faceting multiple things at once\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1);\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id:[1 TO 7]\", \"fq\",\"{!tag=b}id:[3 TO 9]\"\n    );\n    query(\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\");\n\n    // test field that is valid in schema but missing in all shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2);\n    // test field that is valid in schema and missing in some shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2);\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1);\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    // check a complex key name\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"*:*\", \"rows\",100);\n    }\n\n    // test debugging\n    handle.put(\"explain\", UNORDERED);\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY);\n\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n\n    // Thread.sleep(10000000000L);\n  }\n\n","sourceOld":"  @Override\n  public void doTest() throws Exception {\n    int backupStress = stress; // make a copy so we can restore\n\n\n    del(\"*:*\");\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\", \n           tdate_a, \"2010-04-20T11:00:00Z\",\n           tdate_b, \"2009-08-20T11:00:00Z\",\n           \"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\", \n           tdate_a, \"2010-05-02T11:00:00Z\",\n           tdate_b, \"2009-11-02T11:00:00Z\");\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\", \n           tdate_a, \"2010-05-03T11:00:00Z\");\n    indexr(id,4, i1, -100 ,tlong, 101,\n           t1,\"the quick fox jumped over the lazy dog\", \n           tdate_a, \"2010-05-03T11:00:00Z\",\n           tdate_b, \"2010-05-03T11:00:00Z\");\n    indexr(id,5, i1, 500, tlong, 500 ,\n           t1,\"the quick fox jumped way over the lazy dog\", \n           tdate_a, \"2010-05-05T11:00:00Z\");\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,\n           tdate_b, \"2010-01-05T11:00:00Z\",\n           t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,\n           t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,\n           t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,\n           t1,\"no eggs on wall, lesson learned\", \n           oddField, \"odd man out\");\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n\n    handle.clear();\n    handle.put(\"QTime\", SKIPVAL);\n    handle.put(\"timestamp\", SKIPVAL);\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(\"q\",\"*:*\", \"sort\",f+\" desc\");\n      query(\"q\",\"*:*\", \"sort\",f+\" asc\");\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",\"{!func}add(\"+i1+\",5)\"+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" asc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\");\n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"score\");  // test legacy behavior - \"score\"==\"*,score\"\n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 desc\");\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"{!func}\"+i1);// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(\"q\",\"{!func}\"+i1, \"fl\",\"*,score\");  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"quick\");\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\");\n    query(\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\");  // no fields in returned docs\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\");\n\n    handle.put(\"score\", SKIPVAL);\n    query(\"q\",\"quick\",\"fl\",\"*,score\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\");\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"matchesnothing\",\"fl\",\"*,score\");  \n\n    // test that a single NOW value is propagated to all shards... if that is true\n    // then the primary sort should always be a tie and then the secondary should always decide\n    query(\"q\",\"{!func}ms(NOW)\", \"sort\",\"score desc,\"+i1+\" desc\",\"fl\",\"id\");    \n\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\");\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2);\n\n    // simple date facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date.other\", \"all\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // date facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date\",tdate_b, \n          \"facet.date.other\", \"all\", \n          \"f.\"+tdate_b+\".facet.date.start\",\"2009-05-01T11:00:00Z\", \n          \"f.\"+tdate_b+\".facet.date.gap\",\"+3MONTHS\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // simple range facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"facet.range.end\",900);\n\n    // range facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range\",i1, \n          \"f.\"+i1+\".facet.range.start\",300, \n          \"f.\"+i1+\".facet.range.gap\",87, \n          \"facet.range.end\",900,\n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"f.\"+tlong+\".facet.range.end\",900);\n\n    stress=0;  // turn off stress... we want to tex max combos in min time\n    for (int i=0; i<25*RANDOM_MULTIPLIER; i++) {\n      String f = fieldNames[random.nextInt(fieldNames.length)];\n      if (random.nextBoolean()) f = t1;  // the text field is a really interesting one to facet on (and it's multi-valued too)\n\n      // we want a random query and not just *:* so we'll get zero counts in facets also\n      // TODO: do a better random query\n      String q = random.nextBoolean() ? \"*:*\" : \"id:(1 3 5 7 9 11 13) OR id:[100 TO \" + random.nextInt(50) + \"]\";\n\n      int nolimit = random.nextBoolean() ? -1 : 10000;  // these should be equivalent\n\n      // if limit==-1, we should always get exact matches\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"count\", \"facet.mincount\",random.nextInt(5), \"facet.offset\",random.nextInt(10));\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"index\", \"facet.mincount\",random.nextInt(5), \"facet.offset\",random.nextInt(10));\n      // for index sort, we should get exact results for mincount <= 1\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.sort\",\"index\", \"facet.mincount\",random.nextInt(2), \"facet.offset\",random.nextInt(10), \"facet.limit\",random.nextInt(11)-1);\n    }\n    stress = backupStress;  // restore stress\n\n    // test faceting multiple things at once\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1);\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id:[1 TO 7]\", \"fq\",\"{!tag=b}id:[3 TO 9]\"\n    );\n    query(\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\");\n\n    // test field that is valid in schema but missing in all shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2);\n    // test field that is valid in schema and missing in some shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2);\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1);\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    // check a complex key name\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"*:*\", \"rows\",100);\n    }\n\n    // test debugging\n    handle.put(\"explain\", UNORDERED);\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY);\n\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n\n    // Thread.sleep(10000000000L);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a258fbb26824fd104ed795e5d9033d2d040049ee","date":1453508252,"type":1,"author":"Dawid Weiss","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/TestDistributedSearch#doTest().mjava","pathOld":"solr/src/test/org/apache/solr/TestDistributedSearch#doTest().mjava","sourceNew":"  @Override\n  public void doTest() throws Exception {\n    int backupStress = stress; // make a copy so we can restore\n\n\n    del(\"*:*\");\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\", \n           tdate_a, \"2010-04-20T11:00:00Z\",\n           tdate_b, \"2009-08-20T11:00:00Z\",\n           \"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\", \n           tdate_a, \"2010-05-02T11:00:00Z\",\n           tdate_b, \"2009-11-02T11:00:00Z\");\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\", \n           tdate_a, \"2010-05-03T11:00:00Z\");\n    indexr(id,4, i1, -100 ,tlong, 101,\n           t1,\"the quick fox jumped over the lazy dog\", \n           tdate_a, \"2010-05-03T11:00:00Z\",\n           tdate_b, \"2010-05-03T11:00:00Z\");\n    indexr(id,5, i1, 500, tlong, 500 ,\n           t1,\"the quick fox jumped way over the lazy dog\", \n           tdate_a, \"2010-05-05T11:00:00Z\");\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,\n           tdate_b, \"2010-01-05T11:00:00Z\",\n           t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,\n           t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,\n           t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,\n           t1,\"no eggs on wall, lesson learned\", \n           oddField, \"odd man out\");\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n\n    handle.clear();\n    handle.put(\"QTime\", SKIPVAL);\n    handle.put(\"timestamp\", SKIPVAL);\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(\"q\",\"*:*\", \"sort\",f+\" desc\");\n      query(\"q\",\"*:*\", \"sort\",f+\" asc\");\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",\"{!func}add(\"+i1+\",5)\"+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" asc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\");\n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"score\");  // test legacy behavior - \"score\"==\"*,score\"\n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 desc\");\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"{!func}\"+i1);// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(\"q\",\"{!func}\"+i1, \"fl\",\"*,score\");  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"quick\");\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\");\n    query(\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\");  // no fields in returned docs\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\");\n\n    handle.put(\"score\", SKIPVAL);\n    query(\"q\",\"quick\",\"fl\",\"*,score\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\");\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"matchesnothing\",\"fl\",\"*,score\");  \n\n    // test that a single NOW value is propagated to all shards... if that is true\n    // then the primary sort should always be a tie and then the secondary should always decide\n    query(\"q\",\"{!func}ms(NOW)\", \"sort\",\"score desc,\"+i1+\" desc\",\"fl\",\"id\");    \n\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\");\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2);\n\n    // simple date facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date.other\", \"all\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // date facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date\",tdate_b, \n          \"facet.date.other\", \"all\", \n          \"f.\"+tdate_b+\".facet.date.start\",\"2009-05-01T11:00:00Z\", \n          \"f.\"+tdate_b+\".facet.date.gap\",\"+3MONTHS\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // simple range facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"facet.range.end\",900);\n\n    // range facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range\",i1, \n          \"f.\"+i1+\".facet.range.start\",300, \n          \"f.\"+i1+\".facet.range.gap\",87, \n          \"facet.range.end\",900,\n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"f.\"+tlong+\".facet.range.end\",900);\n\n    stress=0;  // turn off stress... we want to tex max combos in min time\n    for (int i=0; i<25*RANDOM_MULTIPLIER; i++) {\n      String f = fieldNames[random.nextInt(fieldNames.length)];\n      if (random.nextBoolean()) f = t1;  // the text field is a really interesting one to facet on (and it's multi-valued too)\n\n      // we want a random query and not just *:* so we'll get zero counts in facets also\n      // TODO: do a better random query\n      String q = random.nextBoolean() ? \"*:*\" : \"id:(1 3 5 7 9 11 13) OR id:[100 TO \" + random.nextInt(50) + \"]\";\n\n      int nolimit = random.nextBoolean() ? -1 : 10000;  // these should be equivalent\n\n      // if limit==-1, we should always get exact matches\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"count\", \"facet.mincount\",random.nextInt(5), \"facet.offset\",random.nextInt(10));\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"index\", \"facet.mincount\",random.nextInt(5), \"facet.offset\",random.nextInt(10));\n      // for index sort, we should get exact results for mincount <= 1\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.sort\",\"index\", \"facet.mincount\",random.nextInt(2), \"facet.offset\",random.nextInt(10), \"facet.limit\",random.nextInt(11)-1);\n    }\n    stress = backupStress;  // restore stress\n\n    // test faceting multiple things at once\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1);\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id:[1 TO 7]\", \"fq\",\"{!tag=b}id:[3 TO 9]\"\n    );\n    query(\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\");\n\n    // test field that is valid in schema but missing in all shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2);\n    // test field that is valid in schema and missing in some shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2);\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1);\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    // check a complex key name\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"*:*\", \"rows\",100);\n    }\n\n    // test debugging\n    handle.put(\"explain\", UNORDERED);\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY);\n\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n\n    // Thread.sleep(10000000000L);\n  }\n\n","sourceOld":"  @Override\n  public void doTest() throws Exception {\n    int backupStress = stress; // make a copy so we can restore\n\n\n    del(\"*:*\");\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\", \n           tdate_a, \"2010-04-20T11:00:00Z\",\n           tdate_b, \"2009-08-20T11:00:00Z\",\n           \"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\", \n           tdate_a, \"2010-05-02T11:00:00Z\",\n           tdate_b, \"2009-11-02T11:00:00Z\");\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\", \n           tdate_a, \"2010-05-03T11:00:00Z\");\n    indexr(id,4, i1, -100 ,tlong, 101,\n           t1,\"the quick fox jumped over the lazy dog\", \n           tdate_a, \"2010-05-03T11:00:00Z\",\n           tdate_b, \"2010-05-03T11:00:00Z\");\n    indexr(id,5, i1, 500, tlong, 500 ,\n           t1,\"the quick fox jumped way over the lazy dog\", \n           tdate_a, \"2010-05-05T11:00:00Z\");\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,\n           tdate_b, \"2010-01-05T11:00:00Z\",\n           t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,\n           t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,\n           t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,\n           t1,\"no eggs on wall, lesson learned\", \n           oddField, \"odd man out\");\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n\n    handle.clear();\n    handle.put(\"QTime\", SKIPVAL);\n    handle.put(\"timestamp\", SKIPVAL);\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(\"q\",\"*:*\", \"sort\",f+\" desc\");\n      query(\"q\",\"*:*\", \"sort\",f+\" asc\");\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",\"{!func}add(\"+i1+\",5)\"+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" asc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\");\n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"score\");  // test legacy behavior - \"score\"==\"*,score\"\n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 desc\");\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"{!func}\"+i1);// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(\"q\",\"{!func}\"+i1, \"fl\",\"*,score\");  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"quick\");\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\");\n    query(\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\");  // no fields in returned docs\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\");\n\n    handle.put(\"score\", SKIPVAL);\n    query(\"q\",\"quick\",\"fl\",\"*,score\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\");\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"matchesnothing\",\"fl\",\"*,score\");  \n\n    // test that a single NOW value is propagated to all shards... if that is true\n    // then the primary sort should always be a tie and then the secondary should always decide\n    query(\"q\",\"{!func}ms(NOW)\", \"sort\",\"score desc,\"+i1+\" desc\",\"fl\",\"id\");    \n\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\");\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2);\n\n    // simple date facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date.other\", \"all\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // date facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date\",tdate_b, \n          \"facet.date.other\", \"all\", \n          \"f.\"+tdate_b+\".facet.date.start\",\"2009-05-01T11:00:00Z\", \n          \"f.\"+tdate_b+\".facet.date.gap\",\"+3MONTHS\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // simple range facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"facet.range.end\",900);\n\n    // range facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range\",i1, \n          \"f.\"+i1+\".facet.range.start\",300, \n          \"f.\"+i1+\".facet.range.gap\",87, \n          \"facet.range.end\",900,\n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"f.\"+tlong+\".facet.range.end\",900);\n\n    stress=0;  // turn off stress... we want to tex max combos in min time\n    for (int i=0; i<25*RANDOM_MULTIPLIER; i++) {\n      String f = fieldNames[random.nextInt(fieldNames.length)];\n      if (random.nextBoolean()) f = t1;  // the text field is a really interesting one to facet on (and it's multi-valued too)\n\n      // we want a random query and not just *:* so we'll get zero counts in facets also\n      // TODO: do a better random query\n      String q = random.nextBoolean() ? \"*:*\" : \"id:(1 3 5 7 9 11 13) OR id:[100 TO \" + random.nextInt(50) + \"]\";\n\n      int nolimit = random.nextBoolean() ? -1 : 10000;  // these should be equivalent\n\n      // if limit==-1, we should always get exact matches\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"count\", \"facet.mincount\",random.nextInt(5), \"facet.offset\",random.nextInt(10));\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"index\", \"facet.mincount\",random.nextInt(5), \"facet.offset\",random.nextInt(10));\n      // for index sort, we should get exact results for mincount <= 1\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.sort\",\"index\", \"facet.mincount\",random.nextInt(2), \"facet.offset\",random.nextInt(10), \"facet.limit\",random.nextInt(11)-1);\n    }\n    stress = backupStress;  // restore stress\n\n    // test faceting multiple things at once\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1);\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id:[1 TO 7]\", \"fq\",\"{!tag=b}id:[3 TO 9]\"\n    );\n    query(\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\");\n\n    // test field that is valid in schema but missing in all shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2);\n    // test field that is valid in schema and missing in some shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2);\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1);\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    // check a complex key name\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"*:*\", \"rows\",100);\n    }\n\n    // test debugging\n    handle.put(\"explain\", UNORDERED);\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY);\n\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n\n    // Thread.sleep(10000000000L);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c26f00b574427b55127e869b935845554afde1fa","date":1310252513,"type":1,"author":"Steven Rowe","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/TestDistributedSearch#doTest().mjava","pathOld":"solr/src/test/org/apache/solr/TestDistributedSearch#doTest().mjava","sourceNew":"  @Override\n  public void doTest() throws Exception {\n    int backupStress = stress; // make a copy so we can restore\n\n\n    del(\"*:*\");\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\", \n           tdate_a, \"2010-04-20T11:00:00Z\",\n           tdate_b, \"2009-08-20T11:00:00Z\",\n           \"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\", \n           tdate_a, \"2010-05-02T11:00:00Z\",\n           tdate_b, \"2009-11-02T11:00:00Z\");\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\", \n           tdate_a, \"2010-05-03T11:00:00Z\");\n    indexr(id,4, i1, -100 ,tlong, 101,\n           t1,\"the quick fox jumped over the lazy dog\", \n           tdate_a, \"2010-05-03T11:00:00Z\",\n           tdate_b, \"2010-05-03T11:00:00Z\");\n    indexr(id,5, i1, 500, tlong, 500 ,\n           t1,\"the quick fox jumped way over the lazy dog\", \n           tdate_a, \"2010-05-05T11:00:00Z\");\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,\n           tdate_b, \"2010-01-05T11:00:00Z\",\n           t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,\n           t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,\n           t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,\n           t1,\"no eggs on wall, lesson learned\", \n           oddField, \"odd man out\");\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n\n    handle.clear();\n    handle.put(\"QTime\", SKIPVAL);\n    handle.put(\"timestamp\", SKIPVAL);\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(\"q\",\"*:*\", \"sort\",f+\" desc\");\n      query(\"q\",\"*:*\", \"sort\",f+\" asc\");\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",\"{!func}add(\"+i1+\",5)\"+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" asc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\");\n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"score\");  // test legacy behavior - \"score\"==\"*,score\"\n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 desc\");\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"{!func}\"+i1);// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(\"q\",\"{!func}\"+i1, \"fl\",\"*,score\");  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"quick\");\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\");\n    query(\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\");  // no fields in returned docs\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\");\n\n    handle.put(\"score\", SKIPVAL);\n    query(\"q\",\"quick\",\"fl\",\"*,score\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\");\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"matchesnothing\",\"fl\",\"*,score\");  \n\n    // test that a single NOW value is propagated to all shards... if that is true\n    // then the primary sort should always be a tie and then the secondary should always decide\n    query(\"q\",\"{!func}ms(NOW)\", \"sort\",\"score desc,\"+i1+\" desc\",\"fl\",\"id\");    \n\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\");\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2);\n\n    // simple date facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date.other\", \"all\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // date facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date\",tdate_b, \n          \"facet.date.other\", \"all\", \n          \"f.\"+tdate_b+\".facet.date.start\",\"2009-05-01T11:00:00Z\", \n          \"f.\"+tdate_b+\".facet.date.gap\",\"+3MONTHS\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // simple range facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"facet.range.end\",900);\n\n    // range facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range\",i1, \n          \"f.\"+i1+\".facet.range.start\",300, \n          \"f.\"+i1+\".facet.range.gap\",87, \n          \"facet.range.end\",900,\n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"f.\"+tlong+\".facet.range.end\",900);\n\n    stress=0;  // turn off stress... we want to tex max combos in min time\n    for (int i=0; i<25*RANDOM_MULTIPLIER; i++) {\n      String f = fieldNames[random.nextInt(fieldNames.length)];\n      if (random.nextBoolean()) f = t1;  // the text field is a really interesting one to facet on (and it's multi-valued too)\n\n      // we want a random query and not just *:* so we'll get zero counts in facets also\n      // TODO: do a better random query\n      String q = random.nextBoolean() ? \"*:*\" : \"id:(1 3 5 7 9 11 13) OR id:[100 TO \" + random.nextInt(50) + \"]\";\n\n      int nolimit = random.nextBoolean() ? -1 : 10000;  // these should be equivalent\n\n      // if limit==-1, we should always get exact matches\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"count\", \"facet.mincount\",random.nextInt(5), \"facet.offset\",random.nextInt(10));\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"index\", \"facet.mincount\",random.nextInt(5), \"facet.offset\",random.nextInt(10));\n      // for index sort, we should get exact results for mincount <= 1\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.sort\",\"index\", \"facet.mincount\",random.nextInt(2), \"facet.offset\",random.nextInt(10), \"facet.limit\",random.nextInt(11)-1);\n    }\n    stress = backupStress;  // restore stress\n\n    // test faceting multiple things at once\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1);\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id:[1 TO 7]\", \"fq\",\"{!tag=b}id:[3 TO 9]\"\n    );\n    query(\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\");\n\n    // test field that is valid in schema but missing in all shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2);\n    // test field that is valid in schema and missing in some shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2);\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1);\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    // check a complex key name\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"*:*\", \"rows\",100);\n    }\n\n    // test debugging\n    handle.put(\"explain\", UNORDERED);\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY);\n\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n\n    // Thread.sleep(10000000000L);\n  }\n\n","sourceOld":"  @Override\n  public void doTest() throws Exception {\n    int backupStress = stress; // make a copy so we can restore\n\n\n    del(\"*:*\");\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\", \n           tdate_a, \"2010-04-20T11:00:00Z\",\n           tdate_b, \"2009-08-20T11:00:00Z\",\n           \"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\", \n           tdate_a, \"2010-05-02T11:00:00Z\",\n           tdate_b, \"2009-11-02T11:00:00Z\");\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\", \n           tdate_a, \"2010-05-03T11:00:00Z\");\n    indexr(id,4, i1, -100 ,tlong, 101,\n           t1,\"the quick fox jumped over the lazy dog\", \n           tdate_a, \"2010-05-03T11:00:00Z\",\n           tdate_b, \"2010-05-03T11:00:00Z\");\n    indexr(id,5, i1, 500, tlong, 500 ,\n           t1,\"the quick fox jumped way over the lazy dog\", \n           tdate_a, \"2010-05-05T11:00:00Z\");\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,\n           tdate_b, \"2010-01-05T11:00:00Z\",\n           t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,\n           t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,\n           t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,\n           t1,\"no eggs on wall, lesson learned\", \n           oddField, \"odd man out\");\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n\n    handle.clear();\n    handle.put(\"QTime\", SKIPVAL);\n    handle.put(\"timestamp\", SKIPVAL);\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(\"q\",\"*:*\", \"sort\",f+\" desc\");\n      query(\"q\",\"*:*\", \"sort\",f+\" asc\");\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",\"{!func}add(\"+i1+\",5)\"+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" asc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\");\n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"score\");  // test legacy behavior - \"score\"==\"*,score\"\n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 desc\");\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"{!func}\"+i1);// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(\"q\",\"{!func}\"+i1, \"fl\",\"*,score\");  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"quick\");\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\");\n    query(\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\");  // no fields in returned docs\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\");\n\n    handle.put(\"score\", SKIPVAL);\n    query(\"q\",\"quick\",\"fl\",\"*,score\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\");\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"matchesnothing\",\"fl\",\"*,score\");  \n\n    // test that a single NOW value is propagated to all shards... if that is true\n    // then the primary sort should always be a tie and then the secondary should always decide\n    query(\"q\",\"{!func}ms(NOW)\", \"sort\",\"score desc,\"+i1+\" desc\",\"fl\",\"id\");    \n\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\");\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2);\n\n    // simple date facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date.other\", \"all\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // date facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date\",tdate_b, \n          \"facet.date.other\", \"all\", \n          \"f.\"+tdate_b+\".facet.date.start\",\"2009-05-01T11:00:00Z\", \n          \"f.\"+tdate_b+\".facet.date.gap\",\"+3MONTHS\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // simple range facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"facet.range.end\",900);\n\n    // range facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range\",i1, \n          \"f.\"+i1+\".facet.range.start\",300, \n          \"f.\"+i1+\".facet.range.gap\",87, \n          \"facet.range.end\",900,\n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"f.\"+tlong+\".facet.range.end\",900);\n\n    stress=0;  // turn off stress... we want to tex max combos in min time\n    for (int i=0; i<25*RANDOM_MULTIPLIER; i++) {\n      String f = fieldNames[random.nextInt(fieldNames.length)];\n      if (random.nextBoolean()) f = t1;  // the text field is a really interesting one to facet on (and it's multi-valued too)\n\n      // we want a random query and not just *:* so we'll get zero counts in facets also\n      // TODO: do a better random query\n      String q = random.nextBoolean() ? \"*:*\" : \"id:(1 3 5 7 9 11 13) OR id:[100 TO \" + random.nextInt(50) + \"]\";\n\n      int nolimit = random.nextBoolean() ? -1 : 10000;  // these should be equivalent\n\n      // if limit==-1, we should always get exact matches\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"count\", \"facet.mincount\",random.nextInt(5), \"facet.offset\",random.nextInt(10));\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"index\", \"facet.mincount\",random.nextInt(5), \"facet.offset\",random.nextInt(10));\n      // for index sort, we should get exact results for mincount <= 1\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.sort\",\"index\", \"facet.mincount\",random.nextInt(2), \"facet.offset\",random.nextInt(10), \"facet.limit\",random.nextInt(11)-1);\n    }\n    stress = backupStress;  // restore stress\n\n    // test faceting multiple things at once\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1);\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id:[1 TO 7]\", \"fq\",\"{!tag=b}id:[3 TO 9]\"\n    );\n    query(\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\");\n\n    // test field that is valid in schema but missing in all shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2);\n    // test field that is valid in schema and missing in some shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2);\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1);\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    // check a complex key name\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"*:*\", \"rows\",100);\n    }\n\n    // test debugging\n    handle.put(\"explain\", UNORDERED);\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY);\n\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n\n    // Thread.sleep(10000000000L);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0261694600e2fe9786395ecd0838ed98797d2660","date":1328833321,"type":3,"author":"Yonik Seeley","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/TestDistributedSearch#doTest().mjava","pathOld":"solr/core/src/test/org/apache/solr/TestDistributedSearch#doTest().mjava","sourceNew":"  @Override\n  public void doTest() throws Exception {\n    int backupStress = stress; // make a copy so we can restore\n\n\n    del(\"*:*\");\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\", \n           tdate_a, \"2010-04-20T11:00:00Z\",\n           tdate_b, \"2009-08-20T11:00:00Z\",\n           \"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\", \n           tdate_a, \"2010-05-02T11:00:00Z\",\n           tdate_b, \"2009-11-02T11:00:00Z\");\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\", \n           tdate_a, \"2010-05-03T11:00:00Z\");\n    indexr(id,4, i1, -100 ,tlong, 101,\n           t1,\"the quick fox jumped over the lazy dog\", \n           tdate_a, \"2010-05-03T11:00:00Z\",\n           tdate_b, \"2010-05-03T11:00:00Z\");\n    indexr(id,5, i1, 500, tlong, 500 ,\n           t1,\"the quick fox jumped way over the lazy dog\", \n           tdate_a, \"2010-05-05T11:00:00Z\");\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,\n           tdate_b, \"2010-01-05T11:00:00Z\",\n           t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,\n           t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,\n           t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,\n           t1,\"no eggs on wall, lesson learned\", \n           oddField, \"odd man out\");\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n\n    handle.clear();\n    handle.put(\"QTime\", SKIPVAL);\n    handle.put(\"timestamp\", SKIPVAL);\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(\"q\",\"*:*\", \"sort\",f+\" desc\");\n      query(\"q\",\"*:*\", \"sort\",f+\" asc\");\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",\"{!func}testfunc(add(\"+i1+\",5))\"+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" asc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\");\n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"score\");  // test legacy behavior - \"score\"==\"*,score\"\n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 desc\");\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"{!func}\"+i1);// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(\"q\",\"{!func}\"+i1, \"fl\",\"*,score\");  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"quick\");\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\");\n    query(\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\");  // no fields in returned docs\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\");\n\n    handle.put(\"score\", SKIPVAL);\n    query(\"q\",\"quick\",\"fl\",\"*,score\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\");\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"matchesnothing\",\"fl\",\"*,score\");  \n\n    // test that a single NOW value is propagated to all shards... if that is true\n    // then the primary sort should always be a tie and then the secondary should always decide\n    query(\"q\",\"{!func}ms(NOW)\", \"sort\",\"score desc,\"+i1+\" desc\",\"fl\",\"id\");    \n\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\");\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2);\n\n    // simple date facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date.other\", \"all\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // date facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date\",tdate_b, \n          \"facet.date.other\", \"all\", \n          \"f.\"+tdate_b+\".facet.date.start\",\"2009-05-01T11:00:00Z\", \n          \"f.\"+tdate_b+\".facet.date.gap\",\"+3MONTHS\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // simple range facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"facet.range.end\",900);\n\n    // range facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range\",i1, \n          \"f.\"+i1+\".facet.range.start\",300, \n          \"f.\"+i1+\".facet.range.gap\",87, \n          \"facet.range.end\",900,\n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"f.\"+tlong+\".facet.range.end\",900);\n\n    stress=0;  // turn off stress... we want to tex max combos in min time\n    for (int i=0; i<25*RANDOM_MULTIPLIER; i++) {\n      String f = fieldNames[random.nextInt(fieldNames.length)];\n      if (random.nextBoolean()) f = t1;  // the text field is a really interesting one to facet on (and it's multi-valued too)\n\n      // we want a random query and not just *:* so we'll get zero counts in facets also\n      // TODO: do a better random query\n      String q = random.nextBoolean() ? \"*:*\" : \"id:(1 3 5 7 9 11 13) OR id:[100 TO \" + random.nextInt(50) + \"]\";\n\n      int nolimit = random.nextBoolean() ? -1 : 10000;  // these should be equivalent\n\n      // if limit==-1, we should always get exact matches\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"count\", \"facet.mincount\",random.nextInt(5), \"facet.offset\",random.nextInt(10));\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"index\", \"facet.mincount\",random.nextInt(5), \"facet.offset\",random.nextInt(10));\n      // for index sort, we should get exact results for mincount <= 1\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.sort\",\"index\", \"facet.mincount\",random.nextInt(2), \"facet.offset\",random.nextInt(10), \"facet.limit\",random.nextInt(11)-1);\n    }\n    stress = backupStress;  // restore stress\n\n    // test faceting multiple things at once\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1);\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id:[1 TO 7]\", \"fq\",\"{!tag=b}id:[3 TO 9]\"\n    );\n    query(\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\");\n\n    // test field that is valid in schema but missing in all shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2);\n    // test field that is valid in schema and missing in some shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2);\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1);\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    // check a complex key name\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"*:*\", \"rows\",100);\n    }\n\n    // test debugging\n    handle.put(\"explain\", UNORDERED);\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY);\n\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n\n    // Thread.sleep(10000000000L);\n  }\n\n","sourceOld":"  @Override\n  public void doTest() throws Exception {\n    int backupStress = stress; // make a copy so we can restore\n\n\n    del(\"*:*\");\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\", \n           tdate_a, \"2010-04-20T11:00:00Z\",\n           tdate_b, \"2009-08-20T11:00:00Z\",\n           \"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\", \n           tdate_a, \"2010-05-02T11:00:00Z\",\n           tdate_b, \"2009-11-02T11:00:00Z\");\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\", \n           tdate_a, \"2010-05-03T11:00:00Z\");\n    indexr(id,4, i1, -100 ,tlong, 101,\n           t1,\"the quick fox jumped over the lazy dog\", \n           tdate_a, \"2010-05-03T11:00:00Z\",\n           tdate_b, \"2010-05-03T11:00:00Z\");\n    indexr(id,5, i1, 500, tlong, 500 ,\n           t1,\"the quick fox jumped way over the lazy dog\", \n           tdate_a, \"2010-05-05T11:00:00Z\");\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,\n           tdate_b, \"2010-01-05T11:00:00Z\",\n           t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,\n           t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,\n           t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,\n           t1,\"no eggs on wall, lesson learned\", \n           oddField, \"odd man out\");\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n\n    handle.clear();\n    handle.put(\"QTime\", SKIPVAL);\n    handle.put(\"timestamp\", SKIPVAL);\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(\"q\",\"*:*\", \"sort\",f+\" desc\");\n      query(\"q\",\"*:*\", \"sort\",f+\" asc\");\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",\"{!func}add(\"+i1+\",5)\"+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" asc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\");\n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"score\");  // test legacy behavior - \"score\"==\"*,score\"\n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 desc\");\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"{!func}\"+i1);// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(\"q\",\"{!func}\"+i1, \"fl\",\"*,score\");  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"quick\");\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\");\n    query(\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\");  // no fields in returned docs\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\");\n\n    handle.put(\"score\", SKIPVAL);\n    query(\"q\",\"quick\",\"fl\",\"*,score\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\");\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"matchesnothing\",\"fl\",\"*,score\");  \n\n    // test that a single NOW value is propagated to all shards... if that is true\n    // then the primary sort should always be a tie and then the secondary should always decide\n    query(\"q\",\"{!func}ms(NOW)\", \"sort\",\"score desc,\"+i1+\" desc\",\"fl\",\"id\");    \n\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\");\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2);\n\n    // simple date facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date.other\", \"all\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // date facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date\",tdate_b, \n          \"facet.date.other\", \"all\", \n          \"f.\"+tdate_b+\".facet.date.start\",\"2009-05-01T11:00:00Z\", \n          \"f.\"+tdate_b+\".facet.date.gap\",\"+3MONTHS\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // simple range facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"facet.range.end\",900);\n\n    // range facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range\",i1, \n          \"f.\"+i1+\".facet.range.start\",300, \n          \"f.\"+i1+\".facet.range.gap\",87, \n          \"facet.range.end\",900,\n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"f.\"+tlong+\".facet.range.end\",900);\n\n    stress=0;  // turn off stress... we want to tex max combos in min time\n    for (int i=0; i<25*RANDOM_MULTIPLIER; i++) {\n      String f = fieldNames[random.nextInt(fieldNames.length)];\n      if (random.nextBoolean()) f = t1;  // the text field is a really interesting one to facet on (and it's multi-valued too)\n\n      // we want a random query and not just *:* so we'll get zero counts in facets also\n      // TODO: do a better random query\n      String q = random.nextBoolean() ? \"*:*\" : \"id:(1 3 5 7 9 11 13) OR id:[100 TO \" + random.nextInt(50) + \"]\";\n\n      int nolimit = random.nextBoolean() ? -1 : 10000;  // these should be equivalent\n\n      // if limit==-1, we should always get exact matches\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"count\", \"facet.mincount\",random.nextInt(5), \"facet.offset\",random.nextInt(10));\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"index\", \"facet.mincount\",random.nextInt(5), \"facet.offset\",random.nextInt(10));\n      // for index sort, we should get exact results for mincount <= 1\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.sort\",\"index\", \"facet.mincount\",random.nextInt(2), \"facet.offset\",random.nextInt(10), \"facet.limit\",random.nextInt(11)-1);\n    }\n    stress = backupStress;  // restore stress\n\n    // test faceting multiple things at once\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1);\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id:[1 TO 7]\", \"fq\",\"{!tag=b}id:[3 TO 9]\"\n    );\n    query(\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\");\n\n    // test field that is valid in schema but missing in all shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2);\n    // test field that is valid in schema and missing in some shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2);\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1);\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    // check a complex key name\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"*:*\", \"rows\",100);\n    }\n\n    // test debugging\n    handle.put(\"explain\", UNORDERED);\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY);\n\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n\n    // Thread.sleep(10000000000L);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d66363068e87a246ce08fee4a42f30f126b92723","date":1329988051,"type":3,"author":"Ryan McKinley","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/TestDistributedSearch#doTest().mjava","pathOld":"solr/core/src/test/org/apache/solr/TestDistributedSearch#doTest().mjava","sourceNew":"  @Override\n  public void doTest() throws Exception {\n    int backupStress = stress; // make a copy so we can restore\n\n\n    del(\"*:*\");\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\", \n           tdate_a, \"2010-04-20T11:00:00Z\",\n           tdate_b, \"2009-08-20T11:00:00Z\",\n           \"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\", \n           tdate_a, \"2010-05-02T11:00:00Z\",\n           tdate_b, \"2009-11-02T11:00:00Z\");\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\", \n           tdate_a, \"2010-05-03T11:00:00Z\");\n    indexr(id,4, i1, -100 ,tlong, 101,\n           t1,\"the quick fox jumped over the lazy dog\", \n           tdate_a, \"2010-05-03T11:00:00Z\",\n           tdate_b, \"2010-05-03T11:00:00Z\");\n    indexr(id,5, i1, 500, tlong, 500 ,\n           t1,\"the quick fox jumped way over the lazy dog\", \n           tdate_a, \"2010-05-05T11:00:00Z\");\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,\n           tdate_b, \"2010-01-05T11:00:00Z\",\n           t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,\n           t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,\n           t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,\n           t1,\"no eggs on wall, lesson learned\", \n           oddField, \"odd man out\");\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n\n    handle.clear();\n    handle.put(\"QTime\", SKIPVAL);\n    handle.put(\"timestamp\", SKIPVAL);\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(\"q\",\"*:*\", \"sort\",f+\" desc\");\n      query(\"q\",\"*:*\", \"sort\",f+\" asc\");\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",\"{!func}testfunc(add(\"+i1+\",5))\"+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" asc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\");\n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"score\");  // test legacy behavior - \"score\"==\"*,score\"\n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 desc\");\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"{!func}\"+i1);// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(\"q\",\"{!func}\"+i1, \"fl\",\"*,score\");  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"quick\");\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\");\n    query(\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\");  // no fields in returned docs\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\");\n\n    handle.put(\"score\", SKIPVAL);\n    query(\"q\",\"quick\",\"fl\",\"*,score\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\");\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"matchesnothing\",\"fl\",\"*,score\");  \n\n    // test that a single NOW value is propagated to all shards... if that is true\n    // then the primary sort should always be a tie and then the secondary should always decide\n    query(\"q\",\"{!func}ms(NOW)\", \"sort\",\"score desc,\"+i1+\" desc\",\"fl\",\"id\");    \n\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\");\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2);\n\n    // simple date facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date.other\", \"all\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // date facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date\",tdate_b, \n          \"facet.date.other\", \"all\", \n          \"f.\"+tdate_b+\".facet.date.start\",\"2009-05-01T11:00:00Z\", \n          \"f.\"+tdate_b+\".facet.date.gap\",\"+3MONTHS\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // simple range facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"facet.range.end\",900);\n\n    // range facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range\",i1, \n          \"f.\"+i1+\".facet.range.start\",300, \n          \"f.\"+i1+\".facet.range.gap\",87, \n          \"facet.range.end\",900,\n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"f.\"+tlong+\".facet.range.end\",900);\n\n    stress=0;  // turn off stress... we want to tex max combos in min time\n    for (int i=0; i<25*RANDOM_MULTIPLIER; i++) {\n      String f = fieldNames[random.nextInt(fieldNames.length)];\n      if (random.nextBoolean()) f = t1;  // the text field is a really interesting one to facet on (and it's multi-valued too)\n\n      // we want a random query and not just *:* so we'll get zero counts in facets also\n      // TODO: do a better random query\n      String q = random.nextBoolean() ? \"*:*\" : \"id:(1 3 5 7 9 11 13) OR id:[100 TO \" + random.nextInt(50) + \"]\";\n\n      int nolimit = random.nextBoolean() ? -1 : 10000;  // these should be equivalent\n\n      // if limit==-1, we should always get exact matches\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"count\", \"facet.mincount\",random.nextInt(5), \"facet.offset\",random.nextInt(10));\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"index\", \"facet.mincount\",random.nextInt(5), \"facet.offset\",random.nextInt(10));\n      // for index sort, we should get exact results for mincount <= 1\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.sort\",\"index\", \"facet.mincount\",random.nextInt(2), \"facet.offset\",random.nextInt(10), \"facet.limit\",random.nextInt(11)-1);\n    }\n    stress = backupStress;  // restore stress\n\n    // test faceting multiple things at once\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1);\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id:[1 TO 7]\", \"fq\",\"{!tag=b}id:[3 TO 9]\"\n    );\n    query(\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\");\n\n    // test field that is valid in schema but missing in all shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2);\n    // test field that is valid in schema and missing in some shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2);\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1);\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    // check a complex key name\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"*:*\", \"rows\",100);\n    }\n\n    // test debugging\n    handle.put(\"explain\", UNORDERED);\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY);\n\n    // Check Info is added to for each shard\n    ModifiableSolrParams q = new ModifiableSolrParams();\n    q.set(\"q\", \"*:*\");\n    q.set(ShardParams.SHARDS_INFO, true);\n    setDistributedParams(q);\n    QueryResponse rsp = queryServer(q);\n    NamedList<?> sinfo = (NamedList<?>) rsp.getResponse().get(ShardParams.SHARDS_INFO);\n    String shards = getShardsString();\n    int cnt = StringUtils.countMatches(shards, \",\")+1;\n    \n    assertNotNull(\"missing shard info\", sinfo);\n    assertEquals(\"should have an entry for each shard [\"+sinfo+\"] \"+shards, cnt, sinfo.size());\n    \n    \n    // This index has the same number for every field\n    \n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n\n    // Thread.sleep(10000000000L);\n  }\n\n","sourceOld":"  @Override\n  public void doTest() throws Exception {\n    int backupStress = stress; // make a copy so we can restore\n\n\n    del(\"*:*\");\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\", \n           tdate_a, \"2010-04-20T11:00:00Z\",\n           tdate_b, \"2009-08-20T11:00:00Z\",\n           \"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\", \n           tdate_a, \"2010-05-02T11:00:00Z\",\n           tdate_b, \"2009-11-02T11:00:00Z\");\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\", \n           tdate_a, \"2010-05-03T11:00:00Z\");\n    indexr(id,4, i1, -100 ,tlong, 101,\n           t1,\"the quick fox jumped over the lazy dog\", \n           tdate_a, \"2010-05-03T11:00:00Z\",\n           tdate_b, \"2010-05-03T11:00:00Z\");\n    indexr(id,5, i1, 500, tlong, 500 ,\n           t1,\"the quick fox jumped way over the lazy dog\", \n           tdate_a, \"2010-05-05T11:00:00Z\");\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,\n           tdate_b, \"2010-01-05T11:00:00Z\",\n           t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,\n           t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,\n           t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,\n           t1,\"no eggs on wall, lesson learned\", \n           oddField, \"odd man out\");\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n\n    handle.clear();\n    handle.put(\"QTime\", SKIPVAL);\n    handle.put(\"timestamp\", SKIPVAL);\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(\"q\",\"*:*\", \"sort\",f+\" desc\");\n      query(\"q\",\"*:*\", \"sort\",f+\" asc\");\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",\"{!func}testfunc(add(\"+i1+\",5))\"+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" asc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\");\n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"score\");  // test legacy behavior - \"score\"==\"*,score\"\n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 desc\");\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"{!func}\"+i1);// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(\"q\",\"{!func}\"+i1, \"fl\",\"*,score\");  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"quick\");\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\");\n    query(\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\");  // no fields in returned docs\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\");\n\n    handle.put(\"score\", SKIPVAL);\n    query(\"q\",\"quick\",\"fl\",\"*,score\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\");\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"matchesnothing\",\"fl\",\"*,score\");  \n\n    // test that a single NOW value is propagated to all shards... if that is true\n    // then the primary sort should always be a tie and then the secondary should always decide\n    query(\"q\",\"{!func}ms(NOW)\", \"sort\",\"score desc,\"+i1+\" desc\",\"fl\",\"id\");    \n\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\");\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2);\n\n    // simple date facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date.other\", \"all\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // date facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date\",tdate_b, \n          \"facet.date.other\", \"all\", \n          \"f.\"+tdate_b+\".facet.date.start\",\"2009-05-01T11:00:00Z\", \n          \"f.\"+tdate_b+\".facet.date.gap\",\"+3MONTHS\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // simple range facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"facet.range.end\",900);\n\n    // range facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range\",i1, \n          \"f.\"+i1+\".facet.range.start\",300, \n          \"f.\"+i1+\".facet.range.gap\",87, \n          \"facet.range.end\",900,\n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"f.\"+tlong+\".facet.range.end\",900);\n\n    stress=0;  // turn off stress... we want to tex max combos in min time\n    for (int i=0; i<25*RANDOM_MULTIPLIER; i++) {\n      String f = fieldNames[random.nextInt(fieldNames.length)];\n      if (random.nextBoolean()) f = t1;  // the text field is a really interesting one to facet on (and it's multi-valued too)\n\n      // we want a random query and not just *:* so we'll get zero counts in facets also\n      // TODO: do a better random query\n      String q = random.nextBoolean() ? \"*:*\" : \"id:(1 3 5 7 9 11 13) OR id:[100 TO \" + random.nextInt(50) + \"]\";\n\n      int nolimit = random.nextBoolean() ? -1 : 10000;  // these should be equivalent\n\n      // if limit==-1, we should always get exact matches\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"count\", \"facet.mincount\",random.nextInt(5), \"facet.offset\",random.nextInt(10));\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"index\", \"facet.mincount\",random.nextInt(5), \"facet.offset\",random.nextInt(10));\n      // for index sort, we should get exact results for mincount <= 1\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.sort\",\"index\", \"facet.mincount\",random.nextInt(2), \"facet.offset\",random.nextInt(10), \"facet.limit\",random.nextInt(11)-1);\n    }\n    stress = backupStress;  // restore stress\n\n    // test faceting multiple things at once\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1);\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id:[1 TO 7]\", \"fq\",\"{!tag=b}id:[3 TO 9]\"\n    );\n    query(\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\");\n\n    // test field that is valid in schema but missing in all shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2);\n    // test field that is valid in schema and missing in some shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2);\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1);\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    // check a complex key name\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"*:*\", \"rows\",100);\n    }\n\n    // test debugging\n    handle.put(\"explain\", UNORDERED);\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY);\n\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n\n    // Thread.sleep(10000000000L);\n  }\n\n","bugFix":null,"bugIntro":["0d9835c6ddd23dd02eefd5adfc0e5d1e89075fbe"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"e6dd476b943b132ecfa6b3ffc72e439eb2d9e061","date":1330500722,"type":3,"author":"Ryan McKinley","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/TestDistributedSearch#doTest().mjava","pathOld":"solr/core/src/test/org/apache/solr/TestDistributedSearch#doTest().mjava","sourceNew":"  @Override\n  public void doTest() throws Exception {\n    int backupStress = stress; // make a copy so we can restore\n\n\n    del(\"*:*\");\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\", \n           tdate_a, \"2010-04-20T11:00:00Z\",\n           tdate_b, \"2009-08-20T11:00:00Z\",\n           \"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\", \n           tdate_a, \"2010-05-02T11:00:00Z\",\n           tdate_b, \"2009-11-02T11:00:00Z\");\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\", \n           tdate_a, \"2010-05-03T11:00:00Z\");\n    indexr(id,4, i1, -100 ,tlong, 101,\n           t1,\"the quick fox jumped over the lazy dog\", \n           tdate_a, \"2010-05-03T11:00:00Z\",\n           tdate_b, \"2010-05-03T11:00:00Z\");\n    indexr(id,5, i1, 500, tlong, 500 ,\n           t1,\"the quick fox jumped way over the lazy dog\", \n           tdate_a, \"2010-05-05T11:00:00Z\");\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,\n           tdate_b, \"2010-01-05T11:00:00Z\",\n           t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,\n           t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,\n           t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,\n           t1,\"no eggs on wall, lesson learned\", \n           oddField, \"odd man out\");\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n\n    handle.clear();\n    handle.put(\"QTime\", SKIPVAL);\n    handle.put(\"timestamp\", SKIPVAL);\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(\"q\",\"*:*\", \"sort\",f+\" desc\");\n      query(\"q\",\"*:*\", \"sort\",f+\" asc\");\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",\"{!func}testfunc(add(\"+i1+\",5))\"+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" asc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\");\n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"score\");  // test legacy behavior - \"score\"==\"*,score\"\n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 desc\");\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"{!func}\"+i1);// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(\"q\",\"{!func}\"+i1, \"fl\",\"*,score\");  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"quick\");\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\");\n    query(\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\");  // no fields in returned docs\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\");\n\n    handle.put(\"score\", SKIPVAL);\n    query(\"q\",\"quick\",\"fl\",\"*,score\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\");\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"matchesnothing\",\"fl\",\"*,score\");  \n\n    // test that a single NOW value is propagated to all shards... if that is true\n    // then the primary sort should always be a tie and then the secondary should always decide\n    query(\"q\",\"{!func}ms(NOW)\", \"sort\",\"score desc,\"+i1+\" desc\",\"fl\",\"id\");    \n\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\");\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2);\n\n    // simple date facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date.other\", \"all\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // date facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date\",tdate_b, \n          \"facet.date.other\", \"all\", \n          \"f.\"+tdate_b+\".facet.date.start\",\"2009-05-01T11:00:00Z\", \n          \"f.\"+tdate_b+\".facet.date.gap\",\"+3MONTHS\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // simple range facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"facet.range.end\",900);\n\n    // range facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range\",i1, \n          \"f.\"+i1+\".facet.range.start\",300, \n          \"f.\"+i1+\".facet.range.gap\",87, \n          \"facet.range.end\",900,\n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"f.\"+tlong+\".facet.range.end\",900);\n\n    stress=0;  // turn off stress... we want to tex max combos in min time\n    for (int i=0; i<25*RANDOM_MULTIPLIER; i++) {\n      String f = fieldNames[random.nextInt(fieldNames.length)];\n      if (random.nextBoolean()) f = t1;  // the text field is a really interesting one to facet on (and it's multi-valued too)\n\n      // we want a random query and not just *:* so we'll get zero counts in facets also\n      // TODO: do a better random query\n      String q = random.nextBoolean() ? \"*:*\" : \"id:(1 3 5 7 9 11 13) OR id:[100 TO \" + random.nextInt(50) + \"]\";\n\n      int nolimit = random.nextBoolean() ? -1 : 10000;  // these should be equivalent\n\n      // if limit==-1, we should always get exact matches\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"count\", \"facet.mincount\",random.nextInt(5), \"facet.offset\",random.nextInt(10));\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"index\", \"facet.mincount\",random.nextInt(5), \"facet.offset\",random.nextInt(10));\n      // for index sort, we should get exact results for mincount <= 1\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.sort\",\"index\", \"facet.mincount\",random.nextInt(2), \"facet.offset\",random.nextInt(10), \"facet.limit\",random.nextInt(11)-1);\n    }\n    stress = backupStress;  // restore stress\n\n    // test faceting multiple things at once\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1);\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id:[1 TO 7]\", \"fq\",\"{!tag=b}id:[3 TO 9]\"\n    );\n    query(\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\");\n\n    // test field that is valid in schema but missing in all shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2);\n    // test field that is valid in schema and missing in some shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2);\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1);\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    // check a complex key name\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"*:*\", \"rows\",100);\n    }\n\n    // test debugging\n    handle.put(\"explain\", UNORDERED);\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY);\n\n    // Check Info is added to for each shard\n    ModifiableSolrParams q = new ModifiableSolrParams();\n    q.set(\"q\", \"*:*\");\n    q.set(ShardParams.SHARDS_INFO, true);\n    setDistributedParams(q);\n    QueryResponse rsp = queryServer(q);\n    NamedList<?> sinfo = (NamedList<?>) rsp.getResponse().get(ShardParams.SHARDS_INFO);\n    String shards = getShardsString();\n    int cnt = StringUtils.countMatches(shards, \",\")+1;\n    \n    assertNotNull(\"missing shard info\", sinfo);\n    assertEquals(\"should have an entry for each shard [\"+sinfo+\"] \"+shards, cnt, sinfo.size());\n    \n    // test shards.tolerant=true\n    for(int numDownServers = 0; numDownServers < jettys.size()-1; numDownServers++)\n    {\n      List<JettySolrRunner> upJettys = new ArrayList<JettySolrRunner>(jettys);\n      List<SolrServer> upClients = new ArrayList<SolrServer>(clients);\n      List<JettySolrRunner> downJettys = new ArrayList<JettySolrRunner>();\n      List<String> upShards = new ArrayList<String>(Arrays.asList(shardsArr));\n      for(int i=0; i<numDownServers; i++)\n      {\n        // shut down some of the jettys\n        int indexToRemove = r.nextInt(upJettys.size());\n        JettySolrRunner downJetty = upJettys.remove(indexToRemove);\n        upClients.remove(indexToRemove);\n        upShards.remove(indexToRemove);\n        ChaosMonkey.stop(downJetty);\n        downJettys.add(downJetty);\n      }\n      \n      queryPartialResults(upShards, upClients, \"q\",\"*:*\",ShardParams.SHARDS_INFO,\"true\",ShardParams.SHARDS_TOLERANT,\"true\");\n      \n      // restart the jettys\n      for (JettySolrRunner downJetty : downJettys) {\n        downJetty.start();\n      }\n    }\n\n    // This index has the same number for every field\n    \n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n\n    // Thread.sleep(10000000000L);\n  }\n\n","sourceOld":"  @Override\n  public void doTest() throws Exception {\n    int backupStress = stress; // make a copy so we can restore\n\n\n    del(\"*:*\");\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\", \n           tdate_a, \"2010-04-20T11:00:00Z\",\n           tdate_b, \"2009-08-20T11:00:00Z\",\n           \"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\", \n           tdate_a, \"2010-05-02T11:00:00Z\",\n           tdate_b, \"2009-11-02T11:00:00Z\");\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\", \n           tdate_a, \"2010-05-03T11:00:00Z\");\n    indexr(id,4, i1, -100 ,tlong, 101,\n           t1,\"the quick fox jumped over the lazy dog\", \n           tdate_a, \"2010-05-03T11:00:00Z\",\n           tdate_b, \"2010-05-03T11:00:00Z\");\n    indexr(id,5, i1, 500, tlong, 500 ,\n           t1,\"the quick fox jumped way over the lazy dog\", \n           tdate_a, \"2010-05-05T11:00:00Z\");\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,\n           tdate_b, \"2010-01-05T11:00:00Z\",\n           t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,\n           t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,\n           t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,\n           t1,\"no eggs on wall, lesson learned\", \n           oddField, \"odd man out\");\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n\n    handle.clear();\n    handle.put(\"QTime\", SKIPVAL);\n    handle.put(\"timestamp\", SKIPVAL);\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(\"q\",\"*:*\", \"sort\",f+\" desc\");\n      query(\"q\",\"*:*\", \"sort\",f+\" asc\");\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",\"{!func}testfunc(add(\"+i1+\",5))\"+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" asc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\");\n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"score\");  // test legacy behavior - \"score\"==\"*,score\"\n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 desc\");\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"{!func}\"+i1);// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(\"q\",\"{!func}\"+i1, \"fl\",\"*,score\");  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"quick\");\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\");\n    query(\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\");  // no fields in returned docs\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\");\n\n    handle.put(\"score\", SKIPVAL);\n    query(\"q\",\"quick\",\"fl\",\"*,score\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\");\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"matchesnothing\",\"fl\",\"*,score\");  \n\n    // test that a single NOW value is propagated to all shards... if that is true\n    // then the primary sort should always be a tie and then the secondary should always decide\n    query(\"q\",\"{!func}ms(NOW)\", \"sort\",\"score desc,\"+i1+\" desc\",\"fl\",\"id\");    \n\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\");\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2);\n\n    // simple date facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date.other\", \"all\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // date facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date\",tdate_b, \n          \"facet.date.other\", \"all\", \n          \"f.\"+tdate_b+\".facet.date.start\",\"2009-05-01T11:00:00Z\", \n          \"f.\"+tdate_b+\".facet.date.gap\",\"+3MONTHS\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // simple range facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"facet.range.end\",900);\n\n    // range facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range\",i1, \n          \"f.\"+i1+\".facet.range.start\",300, \n          \"f.\"+i1+\".facet.range.gap\",87, \n          \"facet.range.end\",900,\n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"f.\"+tlong+\".facet.range.end\",900);\n\n    stress=0;  // turn off stress... we want to tex max combos in min time\n    for (int i=0; i<25*RANDOM_MULTIPLIER; i++) {\n      String f = fieldNames[random.nextInt(fieldNames.length)];\n      if (random.nextBoolean()) f = t1;  // the text field is a really interesting one to facet on (and it's multi-valued too)\n\n      // we want a random query and not just *:* so we'll get zero counts in facets also\n      // TODO: do a better random query\n      String q = random.nextBoolean() ? \"*:*\" : \"id:(1 3 5 7 9 11 13) OR id:[100 TO \" + random.nextInt(50) + \"]\";\n\n      int nolimit = random.nextBoolean() ? -1 : 10000;  // these should be equivalent\n\n      // if limit==-1, we should always get exact matches\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"count\", \"facet.mincount\",random.nextInt(5), \"facet.offset\",random.nextInt(10));\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"index\", \"facet.mincount\",random.nextInt(5), \"facet.offset\",random.nextInt(10));\n      // for index sort, we should get exact results for mincount <= 1\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.sort\",\"index\", \"facet.mincount\",random.nextInt(2), \"facet.offset\",random.nextInt(10), \"facet.limit\",random.nextInt(11)-1);\n    }\n    stress = backupStress;  // restore stress\n\n    // test faceting multiple things at once\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1);\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id:[1 TO 7]\", \"fq\",\"{!tag=b}id:[3 TO 9]\"\n    );\n    query(\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\");\n\n    // test field that is valid in schema but missing in all shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2);\n    // test field that is valid in schema and missing in some shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2);\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1);\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    // check a complex key name\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"*:*\", \"rows\",100);\n    }\n\n    // test debugging\n    handle.put(\"explain\", UNORDERED);\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY);\n\n    // Check Info is added to for each shard\n    ModifiableSolrParams q = new ModifiableSolrParams();\n    q.set(\"q\", \"*:*\");\n    q.set(ShardParams.SHARDS_INFO, true);\n    setDistributedParams(q);\n    QueryResponse rsp = queryServer(q);\n    NamedList<?> sinfo = (NamedList<?>) rsp.getResponse().get(ShardParams.SHARDS_INFO);\n    String shards = getShardsString();\n    int cnt = StringUtils.countMatches(shards, \",\")+1;\n    \n    assertNotNull(\"missing shard info\", sinfo);\n    assertEquals(\"should have an entry for each shard [\"+sinfo+\"] \"+shards, cnt, sinfo.size());\n    \n    \n    // This index has the same number for every field\n    \n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n\n    // Thread.sleep(10000000000L);\n  }\n\n","bugFix":null,"bugIntro":["bb222a3f9d9421d5c95afce73013fbd8de07ea1f","a2d7ec084be7fa496e6f93352b6e10427881eb35"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab","date":1331075828,"type":3,"author":"Ryan McKinley","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/TestDistributedSearch#doTest().mjava","pathOld":"solr/core/src/test/org/apache/solr/TestDistributedSearch#doTest().mjava","sourceNew":"  @Override\n  public void doTest() throws Exception {\n    int backupStress = stress; // make a copy so we can restore\n\n\n    del(\"*:*\");\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\", \n           tdate_a, \"2010-04-20T11:00:00Z\",\n           tdate_b, \"2009-08-20T11:00:00Z\",\n           \"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\", \n           tdate_a, \"2010-05-02T11:00:00Z\",\n           tdate_b, \"2009-11-02T11:00:00Z\");\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\", \n           tdate_a, \"2010-05-03T11:00:00Z\");\n    indexr(id,4, i1, -100 ,tlong, 101,\n           t1,\"the quick fox jumped over the lazy dog\", \n           tdate_a, \"2010-05-03T11:00:00Z\",\n           tdate_b, \"2010-05-03T11:00:00Z\");\n    indexr(id,5, i1, 500, tlong, 500 ,\n           t1,\"the quick fox jumped way over the lazy dog\", \n           tdate_a, \"2010-05-05T11:00:00Z\");\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,\n           tdate_b, \"2010-01-05T11:00:00Z\",\n           t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,\n           t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,\n           t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,\n           t1,\"no eggs on wall, lesson learned\", \n           oddField, \"odd man out\");\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n\n    handle.clear();\n    handle.put(\"QTime\", SKIPVAL);\n    handle.put(\"timestamp\", SKIPVAL);\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(\"q\",\"*:*\", \"sort\",f+\" desc\");\n      query(\"q\",\"*:*\", \"sort\",f+\" asc\");\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",\"{!func}testfunc(add(\"+i1+\",5))\"+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" asc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\");\n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"score\");  // test legacy behavior - \"score\"==\"*,score\"\n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 desc\");\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"{!func}\"+i1);// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(\"q\",\"{!func}\"+i1, \"fl\",\"*,score\");  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"quick\");\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\");\n    query(\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\");  // no fields in returned docs\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\");\n\n    handle.put(\"score\", SKIPVAL);\n    query(\"q\",\"quick\",\"fl\",\"*,score\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\");\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"matchesnothing\",\"fl\",\"*,score\");  \n\n    // test that a single NOW value is propagated to all shards... if that is true\n    // then the primary sort should always be a tie and then the secondary should always decide\n    query(\"q\",\"{!func}ms(NOW)\", \"sort\",\"score desc,\"+i1+\" desc\",\"fl\",\"id\");    \n\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\");\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2);\n\n    // simple date facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date.other\", \"all\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // date facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date\",tdate_b, \n          \"facet.date.other\", \"all\", \n          \"f.\"+tdate_b+\".facet.date.start\",\"2009-05-01T11:00:00Z\", \n          \"f.\"+tdate_b+\".facet.date.gap\",\"+3MONTHS\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // simple range facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"facet.range.end\",900);\n\n    // range facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range\",i1, \n          \"f.\"+i1+\".facet.range.start\",300, \n          \"f.\"+i1+\".facet.range.gap\",87, \n          \"facet.range.end\",900,\n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"f.\"+tlong+\".facet.range.end\",900);\n\n    stress=0;  // turn off stress... we want to tex max combos in min time\n    for (int i=0; i<25*RANDOM_MULTIPLIER; i++) {\n      String f = fieldNames[random.nextInt(fieldNames.length)];\n      if (random.nextBoolean()) f = t1;  // the text field is a really interesting one to facet on (and it's multi-valued too)\n\n      // we want a random query and not just *:* so we'll get zero counts in facets also\n      // TODO: do a better random query\n      String q = random.nextBoolean() ? \"*:*\" : \"id:(1 3 5 7 9 11 13) OR id:[100 TO \" + random.nextInt(50) + \"]\";\n\n      int nolimit = random.nextBoolean() ? -1 : 10000;  // these should be equivalent\n\n      // if limit==-1, we should always get exact matches\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"count\", \"facet.mincount\",random.nextInt(5), \"facet.offset\",random.nextInt(10));\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"index\", \"facet.mincount\",random.nextInt(5), \"facet.offset\",random.nextInt(10));\n      // for index sort, we should get exact results for mincount <= 1\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.sort\",\"index\", \"facet.mincount\",random.nextInt(2), \"facet.offset\",random.nextInt(10), \"facet.limit\",random.nextInt(11)-1);\n    }\n    stress = backupStress;  // restore stress\n\n    // test faceting multiple things at once\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1);\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id:[1 TO 7]\", \"fq\",\"{!tag=b}id:[3 TO 9]\"\n    );\n    query(\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\");\n\n    // test field that is valid in schema but missing in all shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2);\n    // test field that is valid in schema and missing in some shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2);\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1);\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    // check a complex key name\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"*:*\", \"rows\",100);\n    }\n\n    // test debugging\n    handle.put(\"explain\", UNORDERED);\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY);\n\n    // Check Info is added to for each shard\n    ModifiableSolrParams q = new ModifiableSolrParams();\n    q.set(\"q\", \"*:*\");\n    q.set(ShardParams.SHARDS_INFO, true);\n    setDistributedParams(q);\n    QueryResponse rsp = queryServer(q);\n    NamedList<?> sinfo = (NamedList<?>) rsp.getResponse().get(ShardParams.SHARDS_INFO);\n    String shards = getShardsString();\n    int cnt = StringUtils.countMatches(shards, \",\")+1;\n    \n    assertNotNull(\"missing shard info\", sinfo);\n    assertEquals(\"should have an entry for each shard [\"+sinfo+\"] \"+shards, cnt, sinfo.size());\n    \n    // test shards.tolerant=true\n    for(int numDownServers = 0; numDownServers < jettys.size()-1; numDownServers++)\n    {\n      List<JettySolrRunner> upJettys = new ArrayList<JettySolrRunner>(jettys);\n      List<SolrServer> upClients = new ArrayList<SolrServer>(clients);\n      List<JettySolrRunner> downJettys = new ArrayList<JettySolrRunner>();\n      List<String> upShards = new ArrayList<String>(Arrays.asList(shardsArr));\n      for(int i=0; i<numDownServers; i++)\n      {\n        // shut down some of the jettys\n        int indexToRemove = r.nextInt(upJettys.size());\n        JettySolrRunner downJetty = upJettys.remove(indexToRemove);\n        upClients.remove(indexToRemove);\n        upShards.remove(indexToRemove);\n        ChaosMonkey.stop(downJetty);\n        downJettys.add(downJetty);\n      }\n      \n      queryPartialResults(upShards, upClients, \"q\",\"*:*\",ShardParams.SHARDS_INFO,\"true\",ShardParams.SHARDS_TOLERANT,\"true\");\n      \n      // restart the jettys\n      for (JettySolrRunner downJetty : downJettys) {\n        downJetty.start();\n      }\n    }\n\n    // This index has the same number for every field\n    \n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n\n    // Thread.sleep(10000000000L);\n  }\n\n","sourceOld":"  @Override\n  public void doTest() throws Exception {\n    int backupStress = stress; // make a copy so we can restore\n\n\n    del(\"*:*\");\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\", \n           tdate_a, \"2010-04-20T11:00:00Z\",\n           tdate_b, \"2009-08-20T11:00:00Z\",\n           \"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\", \n           tdate_a, \"2010-05-02T11:00:00Z\",\n           tdate_b, \"2009-11-02T11:00:00Z\");\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\", \n           tdate_a, \"2010-05-03T11:00:00Z\");\n    indexr(id,4, i1, -100 ,tlong, 101,\n           t1,\"the quick fox jumped over the lazy dog\", \n           tdate_a, \"2010-05-03T11:00:00Z\",\n           tdate_b, \"2010-05-03T11:00:00Z\");\n    indexr(id,5, i1, 500, tlong, 500 ,\n           t1,\"the quick fox jumped way over the lazy dog\", \n           tdate_a, \"2010-05-05T11:00:00Z\");\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,\n           tdate_b, \"2010-01-05T11:00:00Z\",\n           t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,\n           t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,\n           t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,\n           t1,\"no eggs on wall, lesson learned\", \n           oddField, \"odd man out\");\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n\n    handle.clear();\n    handle.put(\"QTime\", SKIPVAL);\n    handle.put(\"timestamp\", SKIPVAL);\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(\"q\",\"*:*\", \"sort\",f+\" desc\");\n      query(\"q\",\"*:*\", \"sort\",f+\" asc\");\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",\"{!func}testfunc(add(\"+i1+\",5))\"+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" asc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\");\n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"score\");  // test legacy behavior - \"score\"==\"*,score\"\n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 desc\");\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"{!func}\"+i1);// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(\"q\",\"{!func}\"+i1, \"fl\",\"*,score\");  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"quick\");\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\");\n    query(\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\");  // no fields in returned docs\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\");\n\n    handle.put(\"score\", SKIPVAL);\n    query(\"q\",\"quick\",\"fl\",\"*,score\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\");\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"matchesnothing\",\"fl\",\"*,score\");  \n\n    // test that a single NOW value is propagated to all shards... if that is true\n    // then the primary sort should always be a tie and then the secondary should always decide\n    query(\"q\",\"{!func}ms(NOW)\", \"sort\",\"score desc,\"+i1+\" desc\",\"fl\",\"id\");    \n\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\");\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2);\n\n    // simple date facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date.other\", \"all\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // date facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date\",tdate_b, \n          \"facet.date.other\", \"all\", \n          \"f.\"+tdate_b+\".facet.date.start\",\"2009-05-01T11:00:00Z\", \n          \"f.\"+tdate_b+\".facet.date.gap\",\"+3MONTHS\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // simple range facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"facet.range.end\",900);\n\n    // range facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range\",i1, \n          \"f.\"+i1+\".facet.range.start\",300, \n          \"f.\"+i1+\".facet.range.gap\",87, \n          \"facet.range.end\",900,\n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"f.\"+tlong+\".facet.range.end\",900);\n\n    stress=0;  // turn off stress... we want to tex max combos in min time\n    for (int i=0; i<25*RANDOM_MULTIPLIER; i++) {\n      String f = fieldNames[random.nextInt(fieldNames.length)];\n      if (random.nextBoolean()) f = t1;  // the text field is a really interesting one to facet on (and it's multi-valued too)\n\n      // we want a random query and not just *:* so we'll get zero counts in facets also\n      // TODO: do a better random query\n      String q = random.nextBoolean() ? \"*:*\" : \"id:(1 3 5 7 9 11 13) OR id:[100 TO \" + random.nextInt(50) + \"]\";\n\n      int nolimit = random.nextBoolean() ? -1 : 10000;  // these should be equivalent\n\n      // if limit==-1, we should always get exact matches\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"count\", \"facet.mincount\",random.nextInt(5), \"facet.offset\",random.nextInt(10));\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"index\", \"facet.mincount\",random.nextInt(5), \"facet.offset\",random.nextInt(10));\n      // for index sort, we should get exact results for mincount <= 1\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.sort\",\"index\", \"facet.mincount\",random.nextInt(2), \"facet.offset\",random.nextInt(10), \"facet.limit\",random.nextInt(11)-1);\n    }\n    stress = backupStress;  // restore stress\n\n    // test faceting multiple things at once\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1);\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id:[1 TO 7]\", \"fq\",\"{!tag=b}id:[3 TO 9]\"\n    );\n    query(\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\");\n\n    // test field that is valid in schema but missing in all shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2);\n    // test field that is valid in schema and missing in some shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2);\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1);\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    // check a complex key name\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"*:*\", \"rows\",100);\n    }\n\n    // test debugging\n    handle.put(\"explain\", UNORDERED);\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY);\n\n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n\n    // Thread.sleep(10000000000L);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"df525117ddb4dc8c8fe6e9fded68f55b29070496","date":1331258843,"type":3,"author":"Ryan McKinley","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/TestDistributedSearch#doTest().mjava","pathOld":"solr/core/src/test/org/apache/solr/TestDistributedSearch#doTest().mjava","sourceNew":"  @Override\n  public void doTest() throws Exception {\n    int backupStress = stress; // make a copy so we can restore\n\n\n    del(\"*:*\");\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\", \n           tdate_a, \"2010-04-20T11:00:00Z\",\n           tdate_b, \"2009-08-20T11:00:00Z\",\n           \"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\", \n           tdate_a, \"2010-05-02T11:00:00Z\",\n           tdate_b, \"2009-11-02T11:00:00Z\");\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\", \n           tdate_a, \"2010-05-03T11:00:00Z\");\n    indexr(id,4, i1, -100 ,tlong, 101,\n           t1,\"the quick fox jumped over the lazy dog\", \n           tdate_a, \"2010-05-03T11:00:00Z\",\n           tdate_b, \"2010-05-03T11:00:00Z\");\n    indexr(id,5, i1, 500, tlong, 500 ,\n           t1,\"the quick fox jumped way over the lazy dog\", \n           tdate_a, \"2010-05-05T11:00:00Z\");\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,\n           tdate_b, \"2010-01-05T11:00:00Z\",\n           t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,\n           t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,\n           t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,\n           t1,\"no eggs on wall, lesson learned\", \n           oddField, \"odd man out\");\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n\n    handle.clear();\n    handle.put(\"QTime\", SKIPVAL);\n    handle.put(\"timestamp\", SKIPVAL);\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(\"q\",\"*:*\", \"sort\",f+\" desc\");\n      query(\"q\",\"*:*\", \"sort\",f+\" asc\");\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",\"{!func}testfunc(add(\"+i1+\",5))\"+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" asc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\");\n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"*,score\"); \n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 desc\");\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"{!func}\"+i1);// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(\"q\",\"{!func}\"+i1, \"fl\",\"*,score\");  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"quick\");\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\");\n    query(\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\");  // no fields in returned docs\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\");\n\n    handle.put(\"score\", SKIPVAL);\n    query(\"q\",\"quick\",\"fl\",\"*,score\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\");\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"matchesnothing\",\"fl\",\"*,score\");  \n\n    // test that a single NOW value is propagated to all shards... if that is true\n    // then the primary sort should always be a tie and then the secondary should always decide\n    query(\"q\",\"{!func}ms(NOW)\", \"sort\",\"score desc,\"+i1+\" desc\",\"fl\",\"id\");    \n\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\");\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2);\n\n    // simple date facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date.other\", \"all\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // date facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date\",tdate_b, \n          \"facet.date.other\", \"all\", \n          \"f.\"+tdate_b+\".facet.date.start\",\"2009-05-01T11:00:00Z\", \n          \"f.\"+tdate_b+\".facet.date.gap\",\"+3MONTHS\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // simple range facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"facet.range.end\",900);\n\n    // range facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range\",i1, \n          \"f.\"+i1+\".facet.range.start\",300, \n          \"f.\"+i1+\".facet.range.gap\",87, \n          \"facet.range.end\",900,\n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"f.\"+tlong+\".facet.range.end\",900);\n\n    stress=0;  // turn off stress... we want to tex max combos in min time\n    for (int i=0; i<25*RANDOM_MULTIPLIER; i++) {\n      String f = fieldNames[random.nextInt(fieldNames.length)];\n      if (random.nextBoolean()) f = t1;  // the text field is a really interesting one to facet on (and it's multi-valued too)\n\n      // we want a random query and not just *:* so we'll get zero counts in facets also\n      // TODO: do a better random query\n      String q = random.nextBoolean() ? \"*:*\" : \"id:(1 3 5 7 9 11 13) OR id:[100 TO \" + random.nextInt(50) + \"]\";\n\n      int nolimit = random.nextBoolean() ? -1 : 10000;  // these should be equivalent\n\n      // if limit==-1, we should always get exact matches\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"count\", \"facet.mincount\",random.nextInt(5), \"facet.offset\",random.nextInt(10));\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"index\", \"facet.mincount\",random.nextInt(5), \"facet.offset\",random.nextInt(10));\n      // for index sort, we should get exact results for mincount <= 1\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.sort\",\"index\", \"facet.mincount\",random.nextInt(2), \"facet.offset\",random.nextInt(10), \"facet.limit\",random.nextInt(11)-1);\n    }\n    stress = backupStress;  // restore stress\n\n    // test faceting multiple things at once\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1);\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id:[1 TO 7]\", \"fq\",\"{!tag=b}id:[3 TO 9]\"\n    );\n    query(\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\");\n\n    // test field that is valid in schema but missing in all shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2);\n    // test field that is valid in schema and missing in some shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2);\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1);\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    // check a complex key name\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"*:*\", \"rows\",100);\n    }\n\n    // test debugging\n    handle.put(\"explain\", UNORDERED);\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY);\n\n    // Check Info is added to for each shard\n    ModifiableSolrParams q = new ModifiableSolrParams();\n    q.set(\"q\", \"*:*\");\n    q.set(ShardParams.SHARDS_INFO, true);\n    setDistributedParams(q);\n    QueryResponse rsp = queryServer(q);\n    NamedList<?> sinfo = (NamedList<?>) rsp.getResponse().get(ShardParams.SHARDS_INFO);\n    String shards = getShardsString();\n    int cnt = StringUtils.countMatches(shards, \",\")+1;\n    \n    assertNotNull(\"missing shard info\", sinfo);\n    assertEquals(\"should have an entry for each shard [\"+sinfo+\"] \"+shards, cnt, sinfo.size());\n    \n    // test shards.tolerant=true\n    for(int numDownServers = 0; numDownServers < jettys.size()-1; numDownServers++)\n    {\n      List<JettySolrRunner> upJettys = new ArrayList<JettySolrRunner>(jettys);\n      List<SolrServer> upClients = new ArrayList<SolrServer>(clients);\n      List<JettySolrRunner> downJettys = new ArrayList<JettySolrRunner>();\n      List<String> upShards = new ArrayList<String>(Arrays.asList(shardsArr));\n      for(int i=0; i<numDownServers; i++)\n      {\n        // shut down some of the jettys\n        int indexToRemove = r.nextInt(upJettys.size());\n        JettySolrRunner downJetty = upJettys.remove(indexToRemove);\n        upClients.remove(indexToRemove);\n        upShards.remove(indexToRemove);\n        ChaosMonkey.stop(downJetty);\n        downJettys.add(downJetty);\n      }\n      \n      queryPartialResults(upShards, upClients, \"q\",\"*:*\",ShardParams.SHARDS_INFO,\"true\",ShardParams.SHARDS_TOLERANT,\"true\");\n      \n      // restart the jettys\n      for (JettySolrRunner downJetty : downJettys) {\n        downJetty.start();\n      }\n    }\n\n    // This index has the same number for every field\n    \n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n\n    // Thread.sleep(10000000000L);\n  }\n\n","sourceOld":"  @Override\n  public void doTest() throws Exception {\n    int backupStress = stress; // make a copy so we can restore\n\n\n    del(\"*:*\");\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\", \n           tdate_a, \"2010-04-20T11:00:00Z\",\n           tdate_b, \"2009-08-20T11:00:00Z\",\n           \"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\", \n           tdate_a, \"2010-05-02T11:00:00Z\",\n           tdate_b, \"2009-11-02T11:00:00Z\");\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\", \n           tdate_a, \"2010-05-03T11:00:00Z\");\n    indexr(id,4, i1, -100 ,tlong, 101,\n           t1,\"the quick fox jumped over the lazy dog\", \n           tdate_a, \"2010-05-03T11:00:00Z\",\n           tdate_b, \"2010-05-03T11:00:00Z\");\n    indexr(id,5, i1, 500, tlong, 500 ,\n           t1,\"the quick fox jumped way over the lazy dog\", \n           tdate_a, \"2010-05-05T11:00:00Z\");\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,\n           tdate_b, \"2010-01-05T11:00:00Z\",\n           t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,\n           t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,\n           t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,\n           t1,\"no eggs on wall, lesson learned\", \n           oddField, \"odd man out\");\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n\n    handle.clear();\n    handle.put(\"QTime\", SKIPVAL);\n    handle.put(\"timestamp\", SKIPVAL);\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(\"q\",\"*:*\", \"sort\",f+\" desc\");\n      query(\"q\",\"*:*\", \"sort\",f+\" asc\");\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",\"{!func}testfunc(add(\"+i1+\",5))\"+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" asc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\");\n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"score\");  // test legacy behavior - \"score\"==\"*,score\"\n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 desc\");\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"{!func}\"+i1);// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(\"q\",\"{!func}\"+i1, \"fl\",\"*,score\");  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"quick\");\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\");\n    query(\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\");  // no fields in returned docs\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\");\n\n    handle.put(\"score\", SKIPVAL);\n    query(\"q\",\"quick\",\"fl\",\"*,score\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\");\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"matchesnothing\",\"fl\",\"*,score\");  \n\n    // test that a single NOW value is propagated to all shards... if that is true\n    // then the primary sort should always be a tie and then the secondary should always decide\n    query(\"q\",\"{!func}ms(NOW)\", \"sort\",\"score desc,\"+i1+\" desc\",\"fl\",\"id\");    \n\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\");\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2);\n\n    // simple date facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date.other\", \"all\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // date facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date\",tdate_b, \n          \"facet.date.other\", \"all\", \n          \"f.\"+tdate_b+\".facet.date.start\",\"2009-05-01T11:00:00Z\", \n          \"f.\"+tdate_b+\".facet.date.gap\",\"+3MONTHS\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // simple range facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"facet.range.end\",900);\n\n    // range facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range\",i1, \n          \"f.\"+i1+\".facet.range.start\",300, \n          \"f.\"+i1+\".facet.range.gap\",87, \n          \"facet.range.end\",900,\n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"f.\"+tlong+\".facet.range.end\",900);\n\n    stress=0;  // turn off stress... we want to tex max combos in min time\n    for (int i=0; i<25*RANDOM_MULTIPLIER; i++) {\n      String f = fieldNames[random.nextInt(fieldNames.length)];\n      if (random.nextBoolean()) f = t1;  // the text field is a really interesting one to facet on (and it's multi-valued too)\n\n      // we want a random query and not just *:* so we'll get zero counts in facets also\n      // TODO: do a better random query\n      String q = random.nextBoolean() ? \"*:*\" : \"id:(1 3 5 7 9 11 13) OR id:[100 TO \" + random.nextInt(50) + \"]\";\n\n      int nolimit = random.nextBoolean() ? -1 : 10000;  // these should be equivalent\n\n      // if limit==-1, we should always get exact matches\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"count\", \"facet.mincount\",random.nextInt(5), \"facet.offset\",random.nextInt(10));\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"index\", \"facet.mincount\",random.nextInt(5), \"facet.offset\",random.nextInt(10));\n      // for index sort, we should get exact results for mincount <= 1\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.sort\",\"index\", \"facet.mincount\",random.nextInt(2), \"facet.offset\",random.nextInt(10), \"facet.limit\",random.nextInt(11)-1);\n    }\n    stress = backupStress;  // restore stress\n\n    // test faceting multiple things at once\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1);\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id:[1 TO 7]\", \"fq\",\"{!tag=b}id:[3 TO 9]\"\n    );\n    query(\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\");\n\n    // test field that is valid in schema but missing in all shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2);\n    // test field that is valid in schema and missing in some shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2);\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1);\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    // check a complex key name\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"*:*\", \"rows\",100);\n    }\n\n    // test debugging\n    handle.put(\"explain\", UNORDERED);\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY);\n\n    // Check Info is added to for each shard\n    ModifiableSolrParams q = new ModifiableSolrParams();\n    q.set(\"q\", \"*:*\");\n    q.set(ShardParams.SHARDS_INFO, true);\n    setDistributedParams(q);\n    QueryResponse rsp = queryServer(q);\n    NamedList<?> sinfo = (NamedList<?>) rsp.getResponse().get(ShardParams.SHARDS_INFO);\n    String shards = getShardsString();\n    int cnt = StringUtils.countMatches(shards, \",\")+1;\n    \n    assertNotNull(\"missing shard info\", sinfo);\n    assertEquals(\"should have an entry for each shard [\"+sinfo+\"] \"+shards, cnt, sinfo.size());\n    \n    // test shards.tolerant=true\n    for(int numDownServers = 0; numDownServers < jettys.size()-1; numDownServers++)\n    {\n      List<JettySolrRunner> upJettys = new ArrayList<JettySolrRunner>(jettys);\n      List<SolrServer> upClients = new ArrayList<SolrServer>(clients);\n      List<JettySolrRunner> downJettys = new ArrayList<JettySolrRunner>();\n      List<String> upShards = new ArrayList<String>(Arrays.asList(shardsArr));\n      for(int i=0; i<numDownServers; i++)\n      {\n        // shut down some of the jettys\n        int indexToRemove = r.nextInt(upJettys.size());\n        JettySolrRunner downJetty = upJettys.remove(indexToRemove);\n        upClients.remove(indexToRemove);\n        upShards.remove(indexToRemove);\n        ChaosMonkey.stop(downJetty);\n        downJettys.add(downJetty);\n      }\n      \n      queryPartialResults(upShards, upClients, \"q\",\"*:*\",ShardParams.SHARDS_INFO,\"true\",ShardParams.SHARDS_TOLERANT,\"true\");\n      \n      // restart the jettys\n      for (JettySolrRunner downJetty : downJettys) {\n        downJetty.start();\n      }\n    }\n\n    // This index has the same number for every field\n    \n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n\n    // Thread.sleep(10000000000L);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"38e3b736c7ca086d61b7dbb841c905ee115490da","date":1331657018,"type":3,"author":"Ryan McKinley","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/TestDistributedSearch#doTest().mjava","pathOld":"solr/core/src/test/org/apache/solr/TestDistributedSearch#doTest().mjava","sourceNew":"  @Override\n  public void doTest() throws Exception {\n    int backupStress = stress; // make a copy so we can restore\n\n\n    del(\"*:*\");\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\", \n           tdate_a, \"2010-04-20T11:00:00Z\",\n           tdate_b, \"2009-08-20T11:00:00Z\",\n           \"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\", \n           tdate_a, \"2010-05-02T11:00:00Z\",\n           tdate_b, \"2009-11-02T11:00:00Z\");\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\", \n           tdate_a, \"2010-05-03T11:00:00Z\");\n    indexr(id,4, i1, -100 ,tlong, 101,\n           t1,\"the quick fox jumped over the lazy dog\", \n           tdate_a, \"2010-05-03T11:00:00Z\",\n           tdate_b, \"2010-05-03T11:00:00Z\");\n    indexr(id,5, i1, 500, tlong, 500 ,\n           t1,\"the quick fox jumped way over the lazy dog\", \n           tdate_a, \"2010-05-05T11:00:00Z\");\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,\n           tdate_b, \"2010-01-05T11:00:00Z\",\n           t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,\n           t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,\n           t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,\n           t1,\"no eggs on wall, lesson learned\", \n           oddField, \"odd man out\");\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n\n    handle.clear();\n    handle.put(\"QTime\", SKIPVAL);\n    handle.put(\"timestamp\", SKIPVAL);\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(\"q\",\"*:*\", \"sort\",f+\" desc\");\n      query(\"q\",\"*:*\", \"sort\",f+\" asc\");\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",\"{!func}testfunc(add(\"+i1+\",5))\"+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" asc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\");\n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"*,score\"); \n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 desc\");\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"{!func}\"+i1);// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(\"q\",\"{!func}\"+i1, \"fl\",\"*,score\");  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"quick\");\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\");\n    query(\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\");  // no fields in returned docs\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\");\n\n    handle.put(\"score\", SKIPVAL);\n    query(\"q\",\"quick\",\"fl\",\"*,score\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\");\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"matchesnothing\",\"fl\",\"*,score\");  \n\n    // test that a single NOW value is propagated to all shards... if that is true\n    // then the primary sort should always be a tie and then the secondary should always decide\n    query(\"q\",\"{!func}ms(NOW)\", \"sort\",\"score desc,\"+i1+\" desc\",\"fl\",\"id\");    \n\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\");\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2);\n\n    // simple date facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date.other\", \"all\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // date facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date\",tdate_b, \n          \"facet.date.other\", \"all\", \n          \"f.\"+tdate_b+\".facet.date.start\",\"2009-05-01T11:00:00Z\", \n          \"f.\"+tdate_b+\".facet.date.gap\",\"+3MONTHS\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // simple range facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"facet.range.end\",900);\n\n    // range facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range\",i1, \n          \"f.\"+i1+\".facet.range.start\",300, \n          \"f.\"+i1+\".facet.range.gap\",87, \n          \"facet.range.end\",900,\n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"f.\"+tlong+\".facet.range.end\",900);\n\n    stress=0;  // turn off stress... we want to tex max combos in min time\n    for (int i=0; i<25*RANDOM_MULTIPLIER; i++) {\n      String f = fieldNames[random.nextInt(fieldNames.length)];\n      if (random.nextBoolean()) f = t1;  // the text field is a really interesting one to facet on (and it's multi-valued too)\n\n      // we want a random query and not just *:* so we'll get zero counts in facets also\n      // TODO: do a better random query\n      String q = random.nextBoolean() ? \"*:*\" : \"id:(1 3 5 7 9 11 13) OR id:[100 TO \" + random.nextInt(50) + \"]\";\n\n      int nolimit = random.nextBoolean() ? -1 : 10000;  // these should be equivalent\n\n      // if limit==-1, we should always get exact matches\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"count\", \"facet.mincount\",random.nextInt(5), \"facet.offset\",random.nextInt(10));\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"index\", \"facet.mincount\",random.nextInt(5), \"facet.offset\",random.nextInt(10));\n      // for index sort, we should get exact results for mincount <= 1\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.sort\",\"index\", \"facet.mincount\",random.nextInt(2), \"facet.offset\",random.nextInt(10), \"facet.limit\",random.nextInt(11)-1);\n    }\n    stress = backupStress;  // restore stress\n\n    // test faceting multiple things at once\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1);\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id:[1 TO 7]\", \"fq\",\"{!tag=b}id:[3 TO 9]\"\n    );\n    query(\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\");\n\n    // test field that is valid in schema but missing in all shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2);\n    // test field that is valid in schema and missing in some shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2);\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1);\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    // check a complex key name\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"*:*\", \"rows\",100);\n    }\n\n    // test debugging\n    handle.put(\"explain\", UNORDERED);\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY);\n\n    // Check Info is added to for each shard\n    ModifiableSolrParams q = new ModifiableSolrParams();\n    q.set(\"q\", \"*:*\");\n    q.set(ShardParams.SHARDS_INFO, true);\n    setDistributedParams(q);\n    QueryResponse rsp = queryServer(q);\n    NamedList<?> sinfo = (NamedList<?>) rsp.getResponse().get(ShardParams.SHARDS_INFO);\n    String shards = getShardsString();\n    int cnt = StringUtils.countMatches(shards, \",\")+1;\n    \n    assertNotNull(\"missing shard info\", sinfo);\n    assertEquals(\"should have an entry for each shard [\"+sinfo+\"] \"+shards, cnt, sinfo.size());\n    \n    // test shards.tolerant=true\n    for(int numDownServers = 0; numDownServers < jettys.size()-1; numDownServers++)\n    {\n      List<JettySolrRunner> upJettys = new ArrayList<JettySolrRunner>(jettys);\n      List<SolrServer> upClients = new ArrayList<SolrServer>(clients);\n      List<JettySolrRunner> downJettys = new ArrayList<JettySolrRunner>();\n      List<String> upShards = new ArrayList<String>(Arrays.asList(shardsArr));\n      for(int i=0; i<numDownServers; i++)\n      {\n        // shut down some of the jettys\n        int indexToRemove = r.nextInt(upJettys.size());\n        JettySolrRunner downJetty = upJettys.remove(indexToRemove);\n        upClients.remove(indexToRemove);\n        upShards.remove(indexToRemove);\n        ChaosMonkey.stop(downJetty);\n        downJettys.add(downJetty);\n      }\n      \n      queryPartialResults(upShards, upClients, \"q\",\"*:*\",ShardParams.SHARDS_INFO,\"true\",ShardParams.SHARDS_TOLERANT,\"true\");\n      \n      // restart the jettys\n      for (JettySolrRunner downJetty : downJettys) {\n        downJetty.start();\n      }\n    }\n\n    // This index has the same number for every field\n    \n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n\n    // Thread.sleep(10000000000L);\n  }\n\n","sourceOld":"  @Override\n  public void doTest() throws Exception {\n    int backupStress = stress; // make a copy so we can restore\n\n\n    del(\"*:*\");\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\", \n           tdate_a, \"2010-04-20T11:00:00Z\",\n           tdate_b, \"2009-08-20T11:00:00Z\",\n           \"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\", \n           tdate_a, \"2010-05-02T11:00:00Z\",\n           tdate_b, \"2009-11-02T11:00:00Z\");\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\", \n           tdate_a, \"2010-05-03T11:00:00Z\");\n    indexr(id,4, i1, -100 ,tlong, 101,\n           t1,\"the quick fox jumped over the lazy dog\", \n           tdate_a, \"2010-05-03T11:00:00Z\",\n           tdate_b, \"2010-05-03T11:00:00Z\");\n    indexr(id,5, i1, 500, tlong, 500 ,\n           t1,\"the quick fox jumped way over the lazy dog\", \n           tdate_a, \"2010-05-05T11:00:00Z\");\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,\n           tdate_b, \"2010-01-05T11:00:00Z\",\n           t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,\n           t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,\n           t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,\n           t1,\"no eggs on wall, lesson learned\", \n           oddField, \"odd man out\");\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n\n    handle.clear();\n    handle.put(\"QTime\", SKIPVAL);\n    handle.put(\"timestamp\", SKIPVAL);\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(\"q\",\"*:*\", \"sort\",f+\" desc\");\n      query(\"q\",\"*:*\", \"sort\",f+\" asc\");\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",\"{!func}testfunc(add(\"+i1+\",5))\"+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" asc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\");\n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"score\");  // test legacy behavior - \"score\"==\"*,score\"\n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 desc\");\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"{!func}\"+i1);// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(\"q\",\"{!func}\"+i1, \"fl\",\"*,score\");  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"quick\");\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\");\n    query(\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\");  // no fields in returned docs\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\");\n\n    handle.put(\"score\", SKIPVAL);\n    query(\"q\",\"quick\",\"fl\",\"*,score\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\");\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"matchesnothing\",\"fl\",\"*,score\");  \n\n    // test that a single NOW value is propagated to all shards... if that is true\n    // then the primary sort should always be a tie and then the secondary should always decide\n    query(\"q\",\"{!func}ms(NOW)\", \"sort\",\"score desc,\"+i1+\" desc\",\"fl\",\"id\");    \n\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\");\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2);\n\n    // simple date facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date.other\", \"all\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // date facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date\",tdate_b, \n          \"facet.date.other\", \"all\", \n          \"f.\"+tdate_b+\".facet.date.start\",\"2009-05-01T11:00:00Z\", \n          \"f.\"+tdate_b+\".facet.date.gap\",\"+3MONTHS\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // simple range facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"facet.range.end\",900);\n\n    // range facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range\",i1, \n          \"f.\"+i1+\".facet.range.start\",300, \n          \"f.\"+i1+\".facet.range.gap\",87, \n          \"facet.range.end\",900,\n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"f.\"+tlong+\".facet.range.end\",900);\n\n    stress=0;  // turn off stress... we want to tex max combos in min time\n    for (int i=0; i<25*RANDOM_MULTIPLIER; i++) {\n      String f = fieldNames[random.nextInt(fieldNames.length)];\n      if (random.nextBoolean()) f = t1;  // the text field is a really interesting one to facet on (and it's multi-valued too)\n\n      // we want a random query and not just *:* so we'll get zero counts in facets also\n      // TODO: do a better random query\n      String q = random.nextBoolean() ? \"*:*\" : \"id:(1 3 5 7 9 11 13) OR id:[100 TO \" + random.nextInt(50) + \"]\";\n\n      int nolimit = random.nextBoolean() ? -1 : 10000;  // these should be equivalent\n\n      // if limit==-1, we should always get exact matches\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"count\", \"facet.mincount\",random.nextInt(5), \"facet.offset\",random.nextInt(10));\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"index\", \"facet.mincount\",random.nextInt(5), \"facet.offset\",random.nextInt(10));\n      // for index sort, we should get exact results for mincount <= 1\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.sort\",\"index\", \"facet.mincount\",random.nextInt(2), \"facet.offset\",random.nextInt(10), \"facet.limit\",random.nextInt(11)-1);\n    }\n    stress = backupStress;  // restore stress\n\n    // test faceting multiple things at once\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1);\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id:[1 TO 7]\", \"fq\",\"{!tag=b}id:[3 TO 9]\"\n    );\n    query(\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\");\n\n    // test field that is valid in schema but missing in all shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2);\n    // test field that is valid in schema and missing in some shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2);\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1);\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    // check a complex key name\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"*:*\", \"rows\",100);\n    }\n\n    // test debugging\n    handle.put(\"explain\", UNORDERED);\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY);\n\n    // Check Info is added to for each shard\n    ModifiableSolrParams q = new ModifiableSolrParams();\n    q.set(\"q\", \"*:*\");\n    q.set(ShardParams.SHARDS_INFO, true);\n    setDistributedParams(q);\n    QueryResponse rsp = queryServer(q);\n    NamedList<?> sinfo = (NamedList<?>) rsp.getResponse().get(ShardParams.SHARDS_INFO);\n    String shards = getShardsString();\n    int cnt = StringUtils.countMatches(shards, \",\")+1;\n    \n    assertNotNull(\"missing shard info\", sinfo);\n    assertEquals(\"should have an entry for each shard [\"+sinfo+\"] \"+shards, cnt, sinfo.size());\n    \n    // test shards.tolerant=true\n    for(int numDownServers = 0; numDownServers < jettys.size()-1; numDownServers++)\n    {\n      List<JettySolrRunner> upJettys = new ArrayList<JettySolrRunner>(jettys);\n      List<SolrServer> upClients = new ArrayList<SolrServer>(clients);\n      List<JettySolrRunner> downJettys = new ArrayList<JettySolrRunner>();\n      List<String> upShards = new ArrayList<String>(Arrays.asList(shardsArr));\n      for(int i=0; i<numDownServers; i++)\n      {\n        // shut down some of the jettys\n        int indexToRemove = r.nextInt(upJettys.size());\n        JettySolrRunner downJetty = upJettys.remove(indexToRemove);\n        upClients.remove(indexToRemove);\n        upShards.remove(indexToRemove);\n        ChaosMonkey.stop(downJetty);\n        downJettys.add(downJetty);\n      }\n      \n      queryPartialResults(upShards, upClients, \"q\",\"*:*\",ShardParams.SHARDS_INFO,\"true\",ShardParams.SHARDS_TOLERANT,\"true\");\n      \n      // restart the jettys\n      for (JettySolrRunner downJetty : downJettys) {\n        downJetty.start();\n      }\n    }\n\n    // This index has the same number for every field\n    \n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n\n    // Thread.sleep(10000000000L);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"dfdcc495f7097a13c0ae88a3338561749a4eac0b","date":1332737079,"type":3,"author":"David Wayne Smiley","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/TestDistributedSearch#doTest().mjava","pathOld":"solr/core/src/test/org/apache/solr/TestDistributedSearch#doTest().mjava","sourceNew":"  @Override\n  public void doTest() throws Exception {\n    int backupStress = stress; // make a copy so we can restore\n\n\n    del(\"*:*\");\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\", \n           tdate_a, \"2010-04-20T11:00:00Z\",\n           tdate_b, \"2009-08-20T11:00:00Z\",\n           \"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\", \n           tdate_a, \"2010-05-02T11:00:00Z\",\n           tdate_b, \"2009-11-02T11:00:00Z\");\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\", \n           tdate_a, \"2010-05-03T11:00:00Z\");\n    indexr(id,4, i1, -100 ,tlong, 101,\n           t1,\"the quick fox jumped over the lazy dog\", \n           tdate_a, \"2010-05-03T11:00:00Z\",\n           tdate_b, \"2010-05-03T11:00:00Z\");\n    indexr(id,5, i1, 500, tlong, 500 ,\n           t1,\"the quick fox jumped way over the lazy dog\", \n           tdate_a, \"2010-05-05T11:00:00Z\");\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,\n           tdate_b, \"2010-01-05T11:00:00Z\",\n           t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,\n           t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,\n           t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,\n           t1,\"no eggs on wall, lesson learned\", \n           oddField, \"odd man out\");\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n\n    handle.clear();\n    handle.put(\"QTime\", SKIPVAL);\n    handle.put(\"timestamp\", SKIPVAL);\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(\"q\",\"*:*\", \"sort\",f+\" desc\");\n      query(\"q\",\"*:*\", \"sort\",f+\" asc\");\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",\"{!func}testfunc(add(\"+i1+\",5))\"+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" asc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\");\n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"*,score\"); \n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 desc\");\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"{!func}\"+i1);// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(\"q\",\"{!func}\"+i1, \"fl\",\"*,score\");  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"quick\");\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\");\n    query(\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\");  // no fields in returned docs\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\");\n\n    handle.put(\"score\", SKIPVAL);\n    query(\"q\",\"quick\",\"fl\",\"*,score\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\");\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"matchesnothing\",\"fl\",\"*,score\");  \n\n    // test that a single NOW value is propagated to all shards... if that is true\n    // then the primary sort should always be a tie and then the secondary should always decide\n    query(\"q\",\"{!func}ms(NOW)\", \"sort\",\"score desc,\"+i1+\" desc\",\"fl\",\"id\");    \n\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\");\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2);\n\n    // simple date facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date.other\", \"all\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // date facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date\",tdate_b, \n          \"facet.date.other\", \"all\", \n          \"f.\"+tdate_b+\".facet.date.start\",\"2009-05-01T11:00:00Z\", \n          \"f.\"+tdate_b+\".facet.date.gap\",\"+3MONTHS\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // simple range facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"facet.range.end\",900);\n\n    // range facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range\",i1, \n          \"f.\"+i1+\".facet.range.start\",300, \n          \"f.\"+i1+\".facet.range.gap\",87, \n          \"facet.range.end\",900,\n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"f.\"+tlong+\".facet.range.end\",900);\n\n    stress=0;  // turn off stress... we want to tex max combos in min time\n    for (int i=0; i<25*RANDOM_MULTIPLIER; i++) {\n      String f = fieldNames[random.nextInt(fieldNames.length)];\n      if (random.nextBoolean()) f = t1;  // the text field is a really interesting one to facet on (and it's multi-valued too)\n\n      // we want a random query and not just *:* so we'll get zero counts in facets also\n      // TODO: do a better random query\n      String q = random.nextBoolean() ? \"*:*\" : \"id:(1 3 5 7 9 11 13) OR id:[100 TO \" + random.nextInt(50) + \"]\";\n\n      int nolimit = random.nextBoolean() ? -1 : 10000;  // these should be equivalent\n\n      // if limit==-1, we should always get exact matches\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"count\", \"facet.mincount\",random.nextInt(5), \"facet.offset\",random.nextInt(10));\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"index\", \"facet.mincount\",random.nextInt(5), \"facet.offset\",random.nextInt(10));\n      // for index sort, we should get exact results for mincount <= 1\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.sort\",\"index\", \"facet.mincount\",random.nextInt(2), \"facet.offset\",random.nextInt(10), \"facet.limit\",random.nextInt(11)-1);\n    }\n    stress = backupStress;  // restore stress\n\n    // test faceting multiple things at once\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1);\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id:[1 TO 7]\", \"fq\",\"{!tag=b}id:[3 TO 9]\"\n    );\n    query(\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\");\n\n    // test field that is valid in schema but missing in all shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2);\n    // test field that is valid in schema and missing in some shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2);\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1);\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    // check a complex key name\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"*:*\", \"rows\",100);\n    }\n\n    //SOLR 3161 ensure shards.qt=/update fails (anything but search handler really)\n    // Also see TestRemoteStreaming#testQtUpdateFails()\n    try {\n      query(\"q\",\"*:*\",\"shards.qt\",\"/update\",\"stream.body\",\"<delete><query>*:*</query></delete>\");\n      fail();\n    } catch (SolrException e) {\n      //expected\n    }\n\n    // test debugging\n    handle.put(\"explain\", UNORDERED);\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY);\n\n    // Check Info is added to for each shard\n    ModifiableSolrParams q = new ModifiableSolrParams();\n    q.set(\"q\", \"*:*\");\n    q.set(ShardParams.SHARDS_INFO, true);\n    setDistributedParams(q);\n    QueryResponse rsp = queryServer(q);\n    NamedList<?> sinfo = (NamedList<?>) rsp.getResponse().get(ShardParams.SHARDS_INFO);\n    String shards = getShardsString();\n    int cnt = StringUtils.countMatches(shards, \",\")+1;\n    \n    assertNotNull(\"missing shard info\", sinfo);\n    assertEquals(\"should have an entry for each shard [\"+sinfo+\"] \"+shards, cnt, sinfo.size());\n    \n    // test shards.tolerant=true\n    for(int numDownServers = 0; numDownServers < jettys.size()-1; numDownServers++)\n    {\n      List<JettySolrRunner> upJettys = new ArrayList<JettySolrRunner>(jettys);\n      List<SolrServer> upClients = new ArrayList<SolrServer>(clients);\n      List<JettySolrRunner> downJettys = new ArrayList<JettySolrRunner>();\n      List<String> upShards = new ArrayList<String>(Arrays.asList(shardsArr));\n      for(int i=0; i<numDownServers; i++)\n      {\n        // shut down some of the jettys\n        int indexToRemove = r.nextInt(upJettys.size());\n        JettySolrRunner downJetty = upJettys.remove(indexToRemove);\n        upClients.remove(indexToRemove);\n        upShards.remove(indexToRemove);\n        ChaosMonkey.stop(downJetty);\n        downJettys.add(downJetty);\n      }\n      \n      queryPartialResults(upShards, upClients, \"q\",\"*:*\",ShardParams.SHARDS_INFO,\"true\",ShardParams.SHARDS_TOLERANT,\"true\");\n      \n      // restart the jettys\n      for (JettySolrRunner downJetty : downJettys) {\n        downJetty.start();\n      }\n    }\n\n    // This index has the same number for every field\n    \n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // Thread.sleep(10000000000L);\n  }\n\n","sourceOld":"  @Override\n  public void doTest() throws Exception {\n    int backupStress = stress; // make a copy so we can restore\n\n\n    del(\"*:*\");\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\", \n           tdate_a, \"2010-04-20T11:00:00Z\",\n           tdate_b, \"2009-08-20T11:00:00Z\",\n           \"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\", \n           tdate_a, \"2010-05-02T11:00:00Z\",\n           tdate_b, \"2009-11-02T11:00:00Z\");\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\", \n           tdate_a, \"2010-05-03T11:00:00Z\");\n    indexr(id,4, i1, -100 ,tlong, 101,\n           t1,\"the quick fox jumped over the lazy dog\", \n           tdate_a, \"2010-05-03T11:00:00Z\",\n           tdate_b, \"2010-05-03T11:00:00Z\");\n    indexr(id,5, i1, 500, tlong, 500 ,\n           t1,\"the quick fox jumped way over the lazy dog\", \n           tdate_a, \"2010-05-05T11:00:00Z\");\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,\n           tdate_b, \"2010-01-05T11:00:00Z\",\n           t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,\n           t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,\n           t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,\n           t1,\"no eggs on wall, lesson learned\", \n           oddField, \"odd man out\");\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n\n    handle.clear();\n    handle.put(\"QTime\", SKIPVAL);\n    handle.put(\"timestamp\", SKIPVAL);\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(\"q\",\"*:*\", \"sort\",f+\" desc\");\n      query(\"q\",\"*:*\", \"sort\",f+\" asc\");\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",\"{!func}testfunc(add(\"+i1+\",5))\"+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" asc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\");\n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"*,score\"); \n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 desc\");\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"{!func}\"+i1);// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(\"q\",\"{!func}\"+i1, \"fl\",\"*,score\");  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"quick\");\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\");\n    query(\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\");  // no fields in returned docs\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\");\n\n    handle.put(\"score\", SKIPVAL);\n    query(\"q\",\"quick\",\"fl\",\"*,score\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\");\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"matchesnothing\",\"fl\",\"*,score\");  \n\n    // test that a single NOW value is propagated to all shards... if that is true\n    // then the primary sort should always be a tie and then the secondary should always decide\n    query(\"q\",\"{!func}ms(NOW)\", \"sort\",\"score desc,\"+i1+\" desc\",\"fl\",\"id\");    \n\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\");\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2);\n\n    // simple date facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date.other\", \"all\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // date facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date\",tdate_b, \n          \"facet.date.other\", \"all\", \n          \"f.\"+tdate_b+\".facet.date.start\",\"2009-05-01T11:00:00Z\", \n          \"f.\"+tdate_b+\".facet.date.gap\",\"+3MONTHS\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // simple range facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"facet.range.end\",900);\n\n    // range facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range\",i1, \n          \"f.\"+i1+\".facet.range.start\",300, \n          \"f.\"+i1+\".facet.range.gap\",87, \n          \"facet.range.end\",900,\n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"f.\"+tlong+\".facet.range.end\",900);\n\n    stress=0;  // turn off stress... we want to tex max combos in min time\n    for (int i=0; i<25*RANDOM_MULTIPLIER; i++) {\n      String f = fieldNames[random.nextInt(fieldNames.length)];\n      if (random.nextBoolean()) f = t1;  // the text field is a really interesting one to facet on (and it's multi-valued too)\n\n      // we want a random query and not just *:* so we'll get zero counts in facets also\n      // TODO: do a better random query\n      String q = random.nextBoolean() ? \"*:*\" : \"id:(1 3 5 7 9 11 13) OR id:[100 TO \" + random.nextInt(50) + \"]\";\n\n      int nolimit = random.nextBoolean() ? -1 : 10000;  // these should be equivalent\n\n      // if limit==-1, we should always get exact matches\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"count\", \"facet.mincount\",random.nextInt(5), \"facet.offset\",random.nextInt(10));\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"index\", \"facet.mincount\",random.nextInt(5), \"facet.offset\",random.nextInt(10));\n      // for index sort, we should get exact results for mincount <= 1\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.sort\",\"index\", \"facet.mincount\",random.nextInt(2), \"facet.offset\",random.nextInt(10), \"facet.limit\",random.nextInt(11)-1);\n    }\n    stress = backupStress;  // restore stress\n\n    // test faceting multiple things at once\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1);\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id:[1 TO 7]\", \"fq\",\"{!tag=b}id:[3 TO 9]\"\n    );\n    query(\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\");\n\n    // test field that is valid in schema but missing in all shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2);\n    // test field that is valid in schema and missing in some shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2);\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1);\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    // check a complex key name\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"*:*\", \"rows\",100);\n    }\n\n    // test debugging\n    handle.put(\"explain\", UNORDERED);\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY);\n\n    // Check Info is added to for each shard\n    ModifiableSolrParams q = new ModifiableSolrParams();\n    q.set(\"q\", \"*:*\");\n    q.set(ShardParams.SHARDS_INFO, true);\n    setDistributedParams(q);\n    QueryResponse rsp = queryServer(q);\n    NamedList<?> sinfo = (NamedList<?>) rsp.getResponse().get(ShardParams.SHARDS_INFO);\n    String shards = getShardsString();\n    int cnt = StringUtils.countMatches(shards, \",\")+1;\n    \n    assertNotNull(\"missing shard info\", sinfo);\n    assertEquals(\"should have an entry for each shard [\"+sinfo+\"] \"+shards, cnt, sinfo.size());\n    \n    // test shards.tolerant=true\n    for(int numDownServers = 0; numDownServers < jettys.size()-1; numDownServers++)\n    {\n      List<JettySolrRunner> upJettys = new ArrayList<JettySolrRunner>(jettys);\n      List<SolrServer> upClients = new ArrayList<SolrServer>(clients);\n      List<JettySolrRunner> downJettys = new ArrayList<JettySolrRunner>();\n      List<String> upShards = new ArrayList<String>(Arrays.asList(shardsArr));\n      for(int i=0; i<numDownServers; i++)\n      {\n        // shut down some of the jettys\n        int indexToRemove = r.nextInt(upJettys.size());\n        JettySolrRunner downJetty = upJettys.remove(indexToRemove);\n        upClients.remove(indexToRemove);\n        upShards.remove(indexToRemove);\n        ChaosMonkey.stop(downJetty);\n        downJettys.add(downJetty);\n      }\n      \n      queryPartialResults(upShards, upClients, \"q\",\"*:*\",ShardParams.SHARDS_INFO,\"true\",ShardParams.SHARDS_TOLERANT,\"true\");\n      \n      // restart the jettys\n      for (JettySolrRunner downJetty : downJettys) {\n        downJetty.start();\n      }\n    }\n\n    // This index has the same number for every field\n    \n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n\n    // Thread.sleep(10000000000L);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"a63520843c1d9af055af89fbaeb67eae848f28ae","date":1332870078,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/TestDistributedSearch#doTest().mjava","pathOld":"solr/core/src/test/org/apache/solr/TestDistributedSearch#doTest().mjava","sourceNew":"  @Override\n  public void doTest() throws Exception {\n    int backupStress = stress; // make a copy so we can restore\n\n\n    del(\"*:*\");\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\", \n           tdate_a, \"2010-04-20T11:00:00Z\",\n           tdate_b, \"2009-08-20T11:00:00Z\",\n           \"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\", \n           tdate_a, \"2010-05-02T11:00:00Z\",\n           tdate_b, \"2009-11-02T11:00:00Z\");\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\", \n           tdate_a, \"2010-05-03T11:00:00Z\");\n    indexr(id,4, i1, -100 ,tlong, 101,\n           t1,\"the quick fox jumped over the lazy dog\", \n           tdate_a, \"2010-05-03T11:00:00Z\",\n           tdate_b, \"2010-05-03T11:00:00Z\");\n    indexr(id,5, i1, 500, tlong, 500 ,\n           t1,\"the quick fox jumped way over the lazy dog\", \n           tdate_a, \"2010-05-05T11:00:00Z\");\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,\n           tdate_b, \"2010-01-05T11:00:00Z\",\n           t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,\n           t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,\n           t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,\n           t1,\"no eggs on wall, lesson learned\", \n           oddField, \"odd man out\");\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n\n    handle.clear();\n    handle.put(\"QTime\", SKIPVAL);\n    handle.put(\"timestamp\", SKIPVAL);\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(\"q\",\"*:*\", \"sort\",f+\" desc\");\n      query(\"q\",\"*:*\", \"sort\",f+\" asc\");\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",\"{!func}testfunc(add(\"+i1+\",5))\"+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" asc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\");\n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"*,score\"); \n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 desc\");\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"{!func}\"+i1);// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(\"q\",\"{!func}\"+i1, \"fl\",\"*,score\");  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"quick\");\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\");\n    query(\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\");  // no fields in returned docs\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\");\n\n    handle.put(\"score\", SKIPVAL);\n    query(\"q\",\"quick\",\"fl\",\"*,score\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\");\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"matchesnothing\",\"fl\",\"*,score\");  \n\n    // test that a single NOW value is propagated to all shards... if that is true\n    // then the primary sort should always be a tie and then the secondary should always decide\n    query(\"q\",\"{!func}ms(NOW)\", \"sort\",\"score desc,\"+i1+\" desc\",\"fl\",\"id\");    \n\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\");\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2);\n\n    // simple date facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date.other\", \"all\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // date facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date\",tdate_b, \n          \"facet.date.other\", \"all\", \n          \"f.\"+tdate_b+\".facet.date.start\",\"2009-05-01T11:00:00Z\", \n          \"f.\"+tdate_b+\".facet.date.gap\",\"+3MONTHS\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // simple range facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"facet.range.end\",900);\n\n    // range facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range\",i1, \n          \"f.\"+i1+\".facet.range.start\",300, \n          \"f.\"+i1+\".facet.range.gap\",87, \n          \"facet.range.end\",900,\n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"f.\"+tlong+\".facet.range.end\",900);\n    \n    //  variations of fl\n    query(\"q\",\"*:*\", \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1 + \",score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", i1, \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id,\" + i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1, \"fl\", \"id\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",nint, \"fl\",tint,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",nint, \"fl\", \"id\", \"fl\",tint,\"sort\",i1 + \" desc\");\n\n    stress=0;  // turn off stress... we want to tex max combos in min time\n    for (int i=0; i<25*RANDOM_MULTIPLIER; i++) {\n      String f = fieldNames[random.nextInt(fieldNames.length)];\n      if (random.nextBoolean()) f = t1;  // the text field is a really interesting one to facet on (and it's multi-valued too)\n\n      // we want a random query and not just *:* so we'll get zero counts in facets also\n      // TODO: do a better random query\n      String q = random.nextBoolean() ? \"*:*\" : \"id:(1 3 5 7 9 11 13) OR id:[100 TO \" + random.nextInt(50) + \"]\";\n\n      int nolimit = random.nextBoolean() ? -1 : 10000;  // these should be equivalent\n\n      // if limit==-1, we should always get exact matches\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"count\", \"facet.mincount\",random.nextInt(5), \"facet.offset\",random.nextInt(10));\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"index\", \"facet.mincount\",random.nextInt(5), \"facet.offset\",random.nextInt(10));\n      // for index sort, we should get exact results for mincount <= 1\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.sort\",\"index\", \"facet.mincount\",random.nextInt(2), \"facet.offset\",random.nextInt(10), \"facet.limit\",random.nextInt(11)-1);\n    }\n    stress = backupStress;  // restore stress\n\n    // test faceting multiple things at once\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1);\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id:[1 TO 7]\", \"fq\",\"{!tag=b}id:[3 TO 9]\"\n    );\n    query(\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\");\n\n    // test field that is valid in schema but missing in all shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2);\n    // test field that is valid in schema and missing in some shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2);\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1);\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    // check a complex key name\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"*:*\", \"rows\",100);\n    }\n\n    //SOLR 3161 ensure shards.qt=/update fails (anything but search handler really)\n    // Also see TestRemoteStreaming#testQtUpdateFails()\n    try {\n      query(\"q\",\"*:*\",\"shards.qt\",\"/update\",\"stream.body\",\"<delete><query>*:*</query></delete>\");\n      fail();\n    } catch (SolrException e) {\n      //expected\n    }\n\n    // test debugging\n    handle.put(\"explain\", UNORDERED);\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY);\n\n    // Check Info is added to for each shard\n    ModifiableSolrParams q = new ModifiableSolrParams();\n    q.set(\"q\", \"*:*\");\n    q.set(ShardParams.SHARDS_INFO, true);\n    setDistributedParams(q);\n    QueryResponse rsp = queryServer(q);\n    NamedList<?> sinfo = (NamedList<?>) rsp.getResponse().get(ShardParams.SHARDS_INFO);\n    String shards = getShardsString();\n    int cnt = StringUtils.countMatches(shards, \",\")+1;\n    \n    assertNotNull(\"missing shard info\", sinfo);\n    assertEquals(\"should have an entry for each shard [\"+sinfo+\"] \"+shards, cnt, sinfo.size());\n    \n    // test shards.tolerant=true\n    for(int numDownServers = 0; numDownServers < jettys.size()-1; numDownServers++)\n    {\n      List<JettySolrRunner> upJettys = new ArrayList<JettySolrRunner>(jettys);\n      List<SolrServer> upClients = new ArrayList<SolrServer>(clients);\n      List<JettySolrRunner> downJettys = new ArrayList<JettySolrRunner>();\n      List<String> upShards = new ArrayList<String>(Arrays.asList(shardsArr));\n      for(int i=0; i<numDownServers; i++)\n      {\n        // shut down some of the jettys\n        int indexToRemove = r.nextInt(upJettys.size());\n        JettySolrRunner downJetty = upJettys.remove(indexToRemove);\n        upClients.remove(indexToRemove);\n        upShards.remove(indexToRemove);\n        ChaosMonkey.stop(downJetty);\n        downJettys.add(downJetty);\n      }\n      \n      queryPartialResults(upShards, upClients, \"q\",\"*:*\",ShardParams.SHARDS_INFO,\"true\",ShardParams.SHARDS_TOLERANT,\"true\");\n      \n      // restart the jettys\n      for (JettySolrRunner downJetty : downJettys) {\n        downJetty.start();\n      }\n    }\n\n    // This index has the same number for every field\n    \n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // Thread.sleep(10000000000L);\n  }\n\n","sourceOld":"  @Override\n  public void doTest() throws Exception {\n    int backupStress = stress; // make a copy so we can restore\n\n\n    del(\"*:*\");\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\", \n           tdate_a, \"2010-04-20T11:00:00Z\",\n           tdate_b, \"2009-08-20T11:00:00Z\",\n           \"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\", \n           tdate_a, \"2010-05-02T11:00:00Z\",\n           tdate_b, \"2009-11-02T11:00:00Z\");\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\", \n           tdate_a, \"2010-05-03T11:00:00Z\");\n    indexr(id,4, i1, -100 ,tlong, 101,\n           t1,\"the quick fox jumped over the lazy dog\", \n           tdate_a, \"2010-05-03T11:00:00Z\",\n           tdate_b, \"2010-05-03T11:00:00Z\");\n    indexr(id,5, i1, 500, tlong, 500 ,\n           t1,\"the quick fox jumped way over the lazy dog\", \n           tdate_a, \"2010-05-05T11:00:00Z\");\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,\n           tdate_b, \"2010-01-05T11:00:00Z\",\n           t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,\n           t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,\n           t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,\n           t1,\"no eggs on wall, lesson learned\", \n           oddField, \"odd man out\");\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n\n    handle.clear();\n    handle.put(\"QTime\", SKIPVAL);\n    handle.put(\"timestamp\", SKIPVAL);\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(\"q\",\"*:*\", \"sort\",f+\" desc\");\n      query(\"q\",\"*:*\", \"sort\",f+\" asc\");\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",\"{!func}testfunc(add(\"+i1+\",5))\"+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" asc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\");\n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"*,score\"); \n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 desc\");\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"{!func}\"+i1);// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(\"q\",\"{!func}\"+i1, \"fl\",\"*,score\");  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"quick\");\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\");\n    query(\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\");  // no fields in returned docs\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\");\n\n    handle.put(\"score\", SKIPVAL);\n    query(\"q\",\"quick\",\"fl\",\"*,score\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\");\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"matchesnothing\",\"fl\",\"*,score\");  \n\n    // test that a single NOW value is propagated to all shards... if that is true\n    // then the primary sort should always be a tie and then the secondary should always decide\n    query(\"q\",\"{!func}ms(NOW)\", \"sort\",\"score desc,\"+i1+\" desc\",\"fl\",\"id\");    \n\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\");\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2);\n\n    // simple date facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date.other\", \"all\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // date facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date\",tdate_b, \n          \"facet.date.other\", \"all\", \n          \"f.\"+tdate_b+\".facet.date.start\",\"2009-05-01T11:00:00Z\", \n          \"f.\"+tdate_b+\".facet.date.gap\",\"+3MONTHS\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // simple range facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"facet.range.end\",900);\n\n    // range facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range\",i1, \n          \"f.\"+i1+\".facet.range.start\",300, \n          \"f.\"+i1+\".facet.range.gap\",87, \n          \"facet.range.end\",900,\n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"f.\"+tlong+\".facet.range.end\",900);\n\n    stress=0;  // turn off stress... we want to tex max combos in min time\n    for (int i=0; i<25*RANDOM_MULTIPLIER; i++) {\n      String f = fieldNames[random.nextInt(fieldNames.length)];\n      if (random.nextBoolean()) f = t1;  // the text field is a really interesting one to facet on (and it's multi-valued too)\n\n      // we want a random query and not just *:* so we'll get zero counts in facets also\n      // TODO: do a better random query\n      String q = random.nextBoolean() ? \"*:*\" : \"id:(1 3 5 7 9 11 13) OR id:[100 TO \" + random.nextInt(50) + \"]\";\n\n      int nolimit = random.nextBoolean() ? -1 : 10000;  // these should be equivalent\n\n      // if limit==-1, we should always get exact matches\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"count\", \"facet.mincount\",random.nextInt(5), \"facet.offset\",random.nextInt(10));\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"index\", \"facet.mincount\",random.nextInt(5), \"facet.offset\",random.nextInt(10));\n      // for index sort, we should get exact results for mincount <= 1\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.sort\",\"index\", \"facet.mincount\",random.nextInt(2), \"facet.offset\",random.nextInt(10), \"facet.limit\",random.nextInt(11)-1);\n    }\n    stress = backupStress;  // restore stress\n\n    // test faceting multiple things at once\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1);\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id:[1 TO 7]\", \"fq\",\"{!tag=b}id:[3 TO 9]\"\n    );\n    query(\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\");\n\n    // test field that is valid in schema but missing in all shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2);\n    // test field that is valid in schema and missing in some shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2);\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1);\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    // check a complex key name\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"*:*\", \"rows\",100);\n    }\n\n    //SOLR 3161 ensure shards.qt=/update fails (anything but search handler really)\n    // Also see TestRemoteStreaming#testQtUpdateFails()\n    try {\n      query(\"q\",\"*:*\",\"shards.qt\",\"/update\",\"stream.body\",\"<delete><query>*:*</query></delete>\");\n      fail();\n    } catch (SolrException e) {\n      //expected\n    }\n\n    // test debugging\n    handle.put(\"explain\", UNORDERED);\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY);\n\n    // Check Info is added to for each shard\n    ModifiableSolrParams q = new ModifiableSolrParams();\n    q.set(\"q\", \"*:*\");\n    q.set(ShardParams.SHARDS_INFO, true);\n    setDistributedParams(q);\n    QueryResponse rsp = queryServer(q);\n    NamedList<?> sinfo = (NamedList<?>) rsp.getResponse().get(ShardParams.SHARDS_INFO);\n    String shards = getShardsString();\n    int cnt = StringUtils.countMatches(shards, \",\")+1;\n    \n    assertNotNull(\"missing shard info\", sinfo);\n    assertEquals(\"should have an entry for each shard [\"+sinfo+\"] \"+shards, cnt, sinfo.size());\n    \n    // test shards.tolerant=true\n    for(int numDownServers = 0; numDownServers < jettys.size()-1; numDownServers++)\n    {\n      List<JettySolrRunner> upJettys = new ArrayList<JettySolrRunner>(jettys);\n      List<SolrServer> upClients = new ArrayList<SolrServer>(clients);\n      List<JettySolrRunner> downJettys = new ArrayList<JettySolrRunner>();\n      List<String> upShards = new ArrayList<String>(Arrays.asList(shardsArr));\n      for(int i=0; i<numDownServers; i++)\n      {\n        // shut down some of the jettys\n        int indexToRemove = r.nextInt(upJettys.size());\n        JettySolrRunner downJetty = upJettys.remove(indexToRemove);\n        upClients.remove(indexToRemove);\n        upShards.remove(indexToRemove);\n        ChaosMonkey.stop(downJetty);\n        downJettys.add(downJetty);\n      }\n      \n      queryPartialResults(upShards, upClients, \"q\",\"*:*\",ShardParams.SHARDS_INFO,\"true\",ShardParams.SHARDS_TOLERANT,\"true\");\n      \n      // restart the jettys\n      for (JettySolrRunner downJetty : downJettys) {\n        downJetty.start();\n      }\n    }\n\n    // This index has the same number for every field\n    \n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // Thread.sleep(10000000000L);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"aebe9d27ca22125fc3d6aec04786171dca967833","date":1332991622,"type":3,"author":"Yonik Seeley","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/TestDistributedSearch#doTest().mjava","pathOld":"solr/core/src/test/org/apache/solr/TestDistributedSearch#doTest().mjava","sourceNew":"  @Override\n  public void doTest() throws Exception {\n    int backupStress = stress; // make a copy so we can restore\n\n\n    del(\"*:*\");\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\", \n           tdate_a, \"2010-04-20T11:00:00Z\",\n           tdate_b, \"2009-08-20T11:00:00Z\",\n           \"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\", \n           tdate_a, \"2010-05-02T11:00:00Z\",\n           tdate_b, \"2009-11-02T11:00:00Z\");\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\", \n           tdate_a, \"2010-05-03T11:00:00Z\");\n    indexr(id,4, i1, -100 ,tlong, 101,\n           t1,\"the quick fox jumped over the lazy dog\", \n           tdate_a, \"2010-05-03T11:00:00Z\",\n           tdate_b, \"2010-05-03T11:00:00Z\");\n    indexr(id,5, i1, 500, tlong, 500 ,\n           t1,\"the quick fox jumped way over the lazy dog\", \n           tdate_a, \"2010-05-05T11:00:00Z\");\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,\n           tdate_b, \"2010-01-05T11:00:00Z\",\n           t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,\n           t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,\n           t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,\n           t1,\"no eggs on wall, lesson learned\", \n           oddField, \"odd man out\");\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n\n    handle.clear();\n    handle.put(\"QTime\", SKIPVAL);\n    handle.put(\"timestamp\", SKIPVAL);\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(\"q\",\"*:*\", \"sort\",f+\" desc\");\n      query(\"q\",\"*:*\", \"sort\",f+\" asc\");\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",\"{!func}testfunc(add(\"+i1+\",5))\"+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" asc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\");\n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"*,score\"); \n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 desc\");\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"{!func}\"+i1);// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(\"q\",\"{!func}\"+i1, \"fl\",\"*,score\");  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"quick\");\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\");\n    query(\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\");  // no fields in returned docs\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\");\n\n    handle.put(\"score\", SKIPVAL);\n    query(\"q\",\"quick\",\"fl\",\"*,score\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\");\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"matchesnothing\",\"fl\",\"*,score\");  \n\n    // test that a single NOW value is propagated to all shards... if that is true\n    // then the primary sort should always be a tie and then the secondary should always decide\n    query(\"q\",\"{!func}ms(NOW)\", \"sort\",\"score desc,\"+i1+\" desc\",\"fl\",\"id\");    \n\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\");\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2);\n\n    // simple date facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date.other\", \"all\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // date facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date\",tdate_b, \n          \"facet.date.other\", \"all\", \n          \"f.\"+tdate_b+\".facet.date.start\",\"2009-05-01T11:00:00Z\", \n          \"f.\"+tdate_b+\".facet.date.gap\",\"+3MONTHS\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // simple range facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"facet.range.end\",900);\n\n    // range facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range\",i1, \n          \"f.\"+i1+\".facet.range.start\",300, \n          \"f.\"+i1+\".facet.range.gap\",87, \n          \"facet.range.end\",900,\n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"f.\"+tlong+\".facet.range.end\",900);\n    \n    //  variations of fl\n    query(\"q\",\"*:*\", \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1 + \",score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", i1, \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id,\" + i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1, \"fl\", \"id\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",nint, \"fl\",tint,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",nint, \"fl\", \"id\", \"fl\",tint,\"sort\",i1 + \" desc\");\n\n    stress=0;  // turn off stress... we want to tex max combos in min time\n    for (int i=0; i<25*RANDOM_MULTIPLIER; i++) {\n      String f = fieldNames[random.nextInt(fieldNames.length)];\n      if (random.nextBoolean()) f = t1;  // the text field is a really interesting one to facet on (and it's multi-valued too)\n\n      // we want a random query and not just *:* so we'll get zero counts in facets also\n      // TODO: do a better random query\n      String q = random.nextBoolean() ? \"*:*\" : \"id:(1 3 5 7 9 11 13) OR id:[100 TO \" + random.nextInt(50) + \"]\";\n\n      int nolimit = random.nextBoolean() ? -1 : 10000;  // these should be equivalent\n\n      // if limit==-1, we should always get exact matches\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"count\", \"facet.mincount\",random.nextInt(5), \"facet.offset\",random.nextInt(10));\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"index\", \"facet.mincount\",random.nextInt(5), \"facet.offset\",random.nextInt(10));\n      // for index sort, we should get exact results for mincount <= 1\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.sort\",\"index\", \"facet.mincount\",random.nextInt(2), \"facet.offset\",random.nextInt(10), \"facet.limit\",random.nextInt(11)-1);\n    }\n    stress = backupStress;  // restore stress\n\n    // test faceting multiple things at once\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1);\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id:[1 TO 7]\", \"fq\",\"{!tag=b}id:[3 TO 9]\"\n    );\n    query(\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\");\n\n    // test field that is valid in schema but missing in all shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2);\n    // test field that is valid in schema and missing in some shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2);\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1);\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    // check a complex key name\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"*:*\", \"rows\",100);\n    }\n\n    //SOLR 3161 ensure shards.qt=/update fails (anything but search handler really)\n    // Also see TestRemoteStreaming#testQtUpdateFails()\n    try {\n      ignoreException(\"isShard is only acceptable\");\n      query(\"q\",\"*:*\",\"shards.qt\",\"/update\",\"stream.body\",\"<delete><query>*:*</query></delete>\");\n      fail();\n    } catch (SolrException e) {\n      //expected\n    }\n    unIgnoreException(\"isShard is only acceptable\");\n\n    // test debugging\n    handle.put(\"explain\", UNORDERED);\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY);\n\n    // Check Info is added to for each shard\n    ModifiableSolrParams q = new ModifiableSolrParams();\n    q.set(\"q\", \"*:*\");\n    q.set(ShardParams.SHARDS_INFO, true);\n    setDistributedParams(q);\n    QueryResponse rsp = queryServer(q);\n    NamedList<?> sinfo = (NamedList<?>) rsp.getResponse().get(ShardParams.SHARDS_INFO);\n    String shards = getShardsString();\n    int cnt = StringUtils.countMatches(shards, \",\")+1;\n    \n    assertNotNull(\"missing shard info\", sinfo);\n    assertEquals(\"should have an entry for each shard [\"+sinfo+\"] \"+shards, cnt, sinfo.size());\n    \n    // test shards.tolerant=true\n    for(int numDownServers = 0; numDownServers < jettys.size()-1; numDownServers++)\n    {\n      List<JettySolrRunner> upJettys = new ArrayList<JettySolrRunner>(jettys);\n      List<SolrServer> upClients = new ArrayList<SolrServer>(clients);\n      List<JettySolrRunner> downJettys = new ArrayList<JettySolrRunner>();\n      List<String> upShards = new ArrayList<String>(Arrays.asList(shardsArr));\n      for(int i=0; i<numDownServers; i++)\n      {\n        // shut down some of the jettys\n        int indexToRemove = r.nextInt(upJettys.size());\n        JettySolrRunner downJetty = upJettys.remove(indexToRemove);\n        upClients.remove(indexToRemove);\n        upShards.remove(indexToRemove);\n        ChaosMonkey.stop(downJetty);\n        downJettys.add(downJetty);\n      }\n      \n      queryPartialResults(upShards, upClients, \"q\",\"*:*\",ShardParams.SHARDS_INFO,\"true\",ShardParams.SHARDS_TOLERANT,\"true\");\n      \n      // restart the jettys\n      for (JettySolrRunner downJetty : downJettys) {\n        downJetty.start();\n      }\n    }\n\n    // This index has the same number for every field\n    \n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // Thread.sleep(10000000000L);\n  }\n\n","sourceOld":"  @Override\n  public void doTest() throws Exception {\n    int backupStress = stress; // make a copy so we can restore\n\n\n    del(\"*:*\");\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\", \n           tdate_a, \"2010-04-20T11:00:00Z\",\n           tdate_b, \"2009-08-20T11:00:00Z\",\n           \"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\", \n           tdate_a, \"2010-05-02T11:00:00Z\",\n           tdate_b, \"2009-11-02T11:00:00Z\");\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\", \n           tdate_a, \"2010-05-03T11:00:00Z\");\n    indexr(id,4, i1, -100 ,tlong, 101,\n           t1,\"the quick fox jumped over the lazy dog\", \n           tdate_a, \"2010-05-03T11:00:00Z\",\n           tdate_b, \"2010-05-03T11:00:00Z\");\n    indexr(id,5, i1, 500, tlong, 500 ,\n           t1,\"the quick fox jumped way over the lazy dog\", \n           tdate_a, \"2010-05-05T11:00:00Z\");\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,\n           tdate_b, \"2010-01-05T11:00:00Z\",\n           t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,\n           t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,\n           t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,\n           t1,\"no eggs on wall, lesson learned\", \n           oddField, \"odd man out\");\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n\n    handle.clear();\n    handle.put(\"QTime\", SKIPVAL);\n    handle.put(\"timestamp\", SKIPVAL);\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(\"q\",\"*:*\", \"sort\",f+\" desc\");\n      query(\"q\",\"*:*\", \"sort\",f+\" asc\");\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",\"{!func}testfunc(add(\"+i1+\",5))\"+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" asc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\");\n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"*,score\"); \n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 desc\");\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"{!func}\"+i1);// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(\"q\",\"{!func}\"+i1, \"fl\",\"*,score\");  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"quick\");\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\");\n    query(\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\");  // no fields in returned docs\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\");\n\n    handle.put(\"score\", SKIPVAL);\n    query(\"q\",\"quick\",\"fl\",\"*,score\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\");\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"matchesnothing\",\"fl\",\"*,score\");  \n\n    // test that a single NOW value is propagated to all shards... if that is true\n    // then the primary sort should always be a tie and then the secondary should always decide\n    query(\"q\",\"{!func}ms(NOW)\", \"sort\",\"score desc,\"+i1+\" desc\",\"fl\",\"id\");    \n\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\");\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2);\n\n    // simple date facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date.other\", \"all\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // date facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date\",tdate_b, \n          \"facet.date.other\", \"all\", \n          \"f.\"+tdate_b+\".facet.date.start\",\"2009-05-01T11:00:00Z\", \n          \"f.\"+tdate_b+\".facet.date.gap\",\"+3MONTHS\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // simple range facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"facet.range.end\",900);\n\n    // range facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range\",i1, \n          \"f.\"+i1+\".facet.range.start\",300, \n          \"f.\"+i1+\".facet.range.gap\",87, \n          \"facet.range.end\",900,\n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"f.\"+tlong+\".facet.range.end\",900);\n    \n    //  variations of fl\n    query(\"q\",\"*:*\", \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1 + \",score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", i1, \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id,\" + i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1, \"fl\", \"id\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",nint, \"fl\",tint,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",nint, \"fl\", \"id\", \"fl\",tint,\"sort\",i1 + \" desc\");\n\n    stress=0;  // turn off stress... we want to tex max combos in min time\n    for (int i=0; i<25*RANDOM_MULTIPLIER; i++) {\n      String f = fieldNames[random.nextInt(fieldNames.length)];\n      if (random.nextBoolean()) f = t1;  // the text field is a really interesting one to facet on (and it's multi-valued too)\n\n      // we want a random query and not just *:* so we'll get zero counts in facets also\n      // TODO: do a better random query\n      String q = random.nextBoolean() ? \"*:*\" : \"id:(1 3 5 7 9 11 13) OR id:[100 TO \" + random.nextInt(50) + \"]\";\n\n      int nolimit = random.nextBoolean() ? -1 : 10000;  // these should be equivalent\n\n      // if limit==-1, we should always get exact matches\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"count\", \"facet.mincount\",random.nextInt(5), \"facet.offset\",random.nextInt(10));\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"index\", \"facet.mincount\",random.nextInt(5), \"facet.offset\",random.nextInt(10));\n      // for index sort, we should get exact results for mincount <= 1\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.sort\",\"index\", \"facet.mincount\",random.nextInt(2), \"facet.offset\",random.nextInt(10), \"facet.limit\",random.nextInt(11)-1);\n    }\n    stress = backupStress;  // restore stress\n\n    // test faceting multiple things at once\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1);\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id:[1 TO 7]\", \"fq\",\"{!tag=b}id:[3 TO 9]\"\n    );\n    query(\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\");\n\n    // test field that is valid in schema but missing in all shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2);\n    // test field that is valid in schema and missing in some shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2);\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1);\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    // check a complex key name\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"*:*\", \"rows\",100);\n    }\n\n    //SOLR 3161 ensure shards.qt=/update fails (anything but search handler really)\n    // Also see TestRemoteStreaming#testQtUpdateFails()\n    try {\n      query(\"q\",\"*:*\",\"shards.qt\",\"/update\",\"stream.body\",\"<delete><query>*:*</query></delete>\");\n      fail();\n    } catch (SolrException e) {\n      //expected\n    }\n\n    // test debugging\n    handle.put(\"explain\", UNORDERED);\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY);\n\n    // Check Info is added to for each shard\n    ModifiableSolrParams q = new ModifiableSolrParams();\n    q.set(\"q\", \"*:*\");\n    q.set(ShardParams.SHARDS_INFO, true);\n    setDistributedParams(q);\n    QueryResponse rsp = queryServer(q);\n    NamedList<?> sinfo = (NamedList<?>) rsp.getResponse().get(ShardParams.SHARDS_INFO);\n    String shards = getShardsString();\n    int cnt = StringUtils.countMatches(shards, \",\")+1;\n    \n    assertNotNull(\"missing shard info\", sinfo);\n    assertEquals(\"should have an entry for each shard [\"+sinfo+\"] \"+shards, cnt, sinfo.size());\n    \n    // test shards.tolerant=true\n    for(int numDownServers = 0; numDownServers < jettys.size()-1; numDownServers++)\n    {\n      List<JettySolrRunner> upJettys = new ArrayList<JettySolrRunner>(jettys);\n      List<SolrServer> upClients = new ArrayList<SolrServer>(clients);\n      List<JettySolrRunner> downJettys = new ArrayList<JettySolrRunner>();\n      List<String> upShards = new ArrayList<String>(Arrays.asList(shardsArr));\n      for(int i=0; i<numDownServers; i++)\n      {\n        // shut down some of the jettys\n        int indexToRemove = r.nextInt(upJettys.size());\n        JettySolrRunner downJetty = upJettys.remove(indexToRemove);\n        upClients.remove(indexToRemove);\n        upShards.remove(indexToRemove);\n        ChaosMonkey.stop(downJetty);\n        downJettys.add(downJetty);\n      }\n      \n      queryPartialResults(upShards, upClients, \"q\",\"*:*\",ShardParams.SHARDS_INFO,\"true\",ShardParams.SHARDS_TOLERANT,\"true\");\n      \n      // restart the jettys\n      for (JettySolrRunner downJetty : downJettys) {\n        downJetty.start();\n      }\n    }\n\n    // This index has the same number for every field\n    \n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // Thread.sleep(10000000000L);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"16851b5b065d6bd2924c0819a6d91e8e7bbde5d8","date":1332995634,"type":3,"author":"Yonik Seeley","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/TestDistributedSearch#doTest().mjava","pathOld":"solr/core/src/test/org/apache/solr/TestDistributedSearch#doTest().mjava","sourceNew":"  @Override\n  public void doTest() throws Exception {\n    int backupStress = stress; // make a copy so we can restore\n\n\n    del(\"*:*\");\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\", \n           tdate_a, \"2010-04-20T11:00:00Z\",\n           tdate_b, \"2009-08-20T11:00:00Z\",\n           \"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\", \n           tdate_a, \"2010-05-02T11:00:00Z\",\n           tdate_b, \"2009-11-02T11:00:00Z\");\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\", \n           tdate_a, \"2010-05-03T11:00:00Z\");\n    indexr(id,4, i1, -100 ,tlong, 101,\n           t1,\"the quick fox jumped over the lazy dog\", \n           tdate_a, \"2010-05-03T11:00:00Z\",\n           tdate_b, \"2010-05-03T11:00:00Z\");\n    indexr(id,5, i1, 500, tlong, 500 ,\n           t1,\"the quick fox jumped way over the lazy dog\", \n           tdate_a, \"2010-05-05T11:00:00Z\");\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,\n           tdate_b, \"2010-01-05T11:00:00Z\",\n           t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,\n           t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,\n           t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,\n           t1,\"no eggs on wall, lesson learned\", \n           oddField, \"odd man out\");\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n\n    handle.clear();\n    handle.put(\"QTime\", SKIPVAL);\n    handle.put(\"timestamp\", SKIPVAL);\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(\"q\",\"*:*\", \"sort\",f+\" desc\");\n      query(\"q\",\"*:*\", \"sort\",f+\" asc\");\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",\"{!func}testfunc(add(\"+i1+\",5))\"+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" asc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\");\n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"*,score\"); \n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 desc\");\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"{!func}\"+i1);// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(\"q\",\"{!func}\"+i1, \"fl\",\"*,score\");  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"quick\");\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\");\n    query(\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\");  // no fields in returned docs\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\");\n\n    handle.put(\"score\", SKIPVAL);\n    query(\"q\",\"quick\",\"fl\",\"*,score\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\");\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"matchesnothing\",\"fl\",\"*,score\");  \n\n    // test that a single NOW value is propagated to all shards... if that is true\n    // then the primary sort should always be a tie and then the secondary should always decide\n    query(\"q\",\"{!func}ms(NOW)\", \"sort\",\"score desc,\"+i1+\" desc\",\"fl\",\"id\");    \n\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\");\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2);\n\n    // simple date facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date.other\", \"all\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // date facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date\",tdate_b, \n          \"facet.date.other\", \"all\", \n          \"f.\"+tdate_b+\".facet.date.start\",\"2009-05-01T11:00:00Z\", \n          \"f.\"+tdate_b+\".facet.date.gap\",\"+3MONTHS\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // simple range facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"facet.range.end\",900);\n\n    // range facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range\",i1, \n          \"f.\"+i1+\".facet.range.start\",300, \n          \"f.\"+i1+\".facet.range.gap\",87, \n          \"facet.range.end\",900,\n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"f.\"+tlong+\".facet.range.end\",900);\n    \n    //  variations of fl\n    query(\"q\",\"*:*\", \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1 + \",score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", i1, \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id,\" + i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1, \"fl\", \"id\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",nint, \"fl\",tint,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",nint, \"fl\", \"id\", \"fl\",tint,\"sort\",i1 + \" desc\");\n\n    stress=0;  // turn off stress... we want to tex max combos in min time\n    for (int i=0; i<25*RANDOM_MULTIPLIER; i++) {\n      String f = fieldNames[random.nextInt(fieldNames.length)];\n      if (random.nextBoolean()) f = t1;  // the text field is a really interesting one to facet on (and it's multi-valued too)\n\n      // we want a random query and not just *:* so we'll get zero counts in facets also\n      // TODO: do a better random query\n      String q = random.nextBoolean() ? \"*:*\" : \"id:(1 3 5 7 9 11 13) OR id:[100 TO \" + random.nextInt(50) + \"]\";\n\n      int nolimit = random.nextBoolean() ? -1 : 10000;  // these should be equivalent\n\n      // if limit==-1, we should always get exact matches\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"count\", \"facet.mincount\",random.nextInt(5), \"facet.offset\",random.nextInt(10));\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"index\", \"facet.mincount\",random.nextInt(5), \"facet.offset\",random.nextInt(10));\n      // for index sort, we should get exact results for mincount <= 1\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.sort\",\"index\", \"facet.mincount\",random.nextInt(2), \"facet.offset\",random.nextInt(10), \"facet.limit\",random.nextInt(11)-1);\n    }\n    stress = backupStress;  // restore stress\n\n    // test faceting multiple things at once\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1);\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id:[1 TO 7]\", \"fq\",\"{!tag=b}id:[3 TO 9]\"\n    );\n    query(\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\");\n\n    // test field that is valid in schema but missing in all shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2);\n    // test field that is valid in schema and missing in some shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2);\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1);\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    // check a complex key name\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"*:*\", \"rows\",100);\n    }\n\n    //SOLR 3161 ensure shards.qt=/update fails (anything but search handler really)\n    // Also see TestRemoteStreaming#testQtUpdateFails()\n    try {\n      ignoreException(\"isShard is only acceptable\");\n      query(\"q\",\"*:*\",\"shards.qt\",\"/update\",\"stream.body\",\"<delete><query>*:*</query></delete>\");\n      // fail();\n    } catch (SolrException e) {\n      //expected\n    }\n    unIgnoreException(\"isShard is only acceptable\");\n\n    // test debugging\n    handle.put(\"explain\", UNORDERED);\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY);\n\n    // Check Info is added to for each shard\n    ModifiableSolrParams q = new ModifiableSolrParams();\n    q.set(\"q\", \"*:*\");\n    q.set(ShardParams.SHARDS_INFO, true);\n    setDistributedParams(q);\n    QueryResponse rsp = queryServer(q);\n    NamedList<?> sinfo = (NamedList<?>) rsp.getResponse().get(ShardParams.SHARDS_INFO);\n    String shards = getShardsString();\n    int cnt = StringUtils.countMatches(shards, \",\")+1;\n    \n    assertNotNull(\"missing shard info\", sinfo);\n    assertEquals(\"should have an entry for each shard [\"+sinfo+\"] \"+shards, cnt, sinfo.size());\n    \n    // test shards.tolerant=true\n    for(int numDownServers = 0; numDownServers < jettys.size()-1; numDownServers++)\n    {\n      List<JettySolrRunner> upJettys = new ArrayList<JettySolrRunner>(jettys);\n      List<SolrServer> upClients = new ArrayList<SolrServer>(clients);\n      List<JettySolrRunner> downJettys = new ArrayList<JettySolrRunner>();\n      List<String> upShards = new ArrayList<String>(Arrays.asList(shardsArr));\n      for(int i=0; i<numDownServers; i++)\n      {\n        // shut down some of the jettys\n        int indexToRemove = r.nextInt(upJettys.size());\n        JettySolrRunner downJetty = upJettys.remove(indexToRemove);\n        upClients.remove(indexToRemove);\n        upShards.remove(indexToRemove);\n        ChaosMonkey.stop(downJetty);\n        downJettys.add(downJetty);\n      }\n      \n      queryPartialResults(upShards, upClients, \"q\",\"*:*\",ShardParams.SHARDS_INFO,\"true\",ShardParams.SHARDS_TOLERANT,\"true\");\n      \n      // restart the jettys\n      for (JettySolrRunner downJetty : downJettys) {\n        downJetty.start();\n      }\n    }\n\n    // This index has the same number for every field\n    \n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // Thread.sleep(10000000000L);\n  }\n\n","sourceOld":"  @Override\n  public void doTest() throws Exception {\n    int backupStress = stress; // make a copy so we can restore\n\n\n    del(\"*:*\");\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\", \n           tdate_a, \"2010-04-20T11:00:00Z\",\n           tdate_b, \"2009-08-20T11:00:00Z\",\n           \"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\", \n           tdate_a, \"2010-05-02T11:00:00Z\",\n           tdate_b, \"2009-11-02T11:00:00Z\");\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\", \n           tdate_a, \"2010-05-03T11:00:00Z\");\n    indexr(id,4, i1, -100 ,tlong, 101,\n           t1,\"the quick fox jumped over the lazy dog\", \n           tdate_a, \"2010-05-03T11:00:00Z\",\n           tdate_b, \"2010-05-03T11:00:00Z\");\n    indexr(id,5, i1, 500, tlong, 500 ,\n           t1,\"the quick fox jumped way over the lazy dog\", \n           tdate_a, \"2010-05-05T11:00:00Z\");\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,\n           tdate_b, \"2010-01-05T11:00:00Z\",\n           t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,\n           t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,\n           t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,\n           t1,\"no eggs on wall, lesson learned\", \n           oddField, \"odd man out\");\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n\n    handle.clear();\n    handle.put(\"QTime\", SKIPVAL);\n    handle.put(\"timestamp\", SKIPVAL);\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(\"q\",\"*:*\", \"sort\",f+\" desc\");\n      query(\"q\",\"*:*\", \"sort\",f+\" asc\");\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",\"{!func}testfunc(add(\"+i1+\",5))\"+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" asc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\");\n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"*,score\"); \n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 desc\");\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"{!func}\"+i1);// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(\"q\",\"{!func}\"+i1, \"fl\",\"*,score\");  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"quick\");\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\");\n    query(\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\");  // no fields in returned docs\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\");\n\n    handle.put(\"score\", SKIPVAL);\n    query(\"q\",\"quick\",\"fl\",\"*,score\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\");\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"matchesnothing\",\"fl\",\"*,score\");  \n\n    // test that a single NOW value is propagated to all shards... if that is true\n    // then the primary sort should always be a tie and then the secondary should always decide\n    query(\"q\",\"{!func}ms(NOW)\", \"sort\",\"score desc,\"+i1+\" desc\",\"fl\",\"id\");    \n\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\");\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2);\n\n    // simple date facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date.other\", \"all\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // date facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date\",tdate_b, \n          \"facet.date.other\", \"all\", \n          \"f.\"+tdate_b+\".facet.date.start\",\"2009-05-01T11:00:00Z\", \n          \"f.\"+tdate_b+\".facet.date.gap\",\"+3MONTHS\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // simple range facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"facet.range.end\",900);\n\n    // range facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range\",i1, \n          \"f.\"+i1+\".facet.range.start\",300, \n          \"f.\"+i1+\".facet.range.gap\",87, \n          \"facet.range.end\",900,\n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"f.\"+tlong+\".facet.range.end\",900);\n    \n    //  variations of fl\n    query(\"q\",\"*:*\", \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1 + \",score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", i1, \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id,\" + i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1, \"fl\", \"id\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",nint, \"fl\",tint,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",nint, \"fl\", \"id\", \"fl\",tint,\"sort\",i1 + \" desc\");\n\n    stress=0;  // turn off stress... we want to tex max combos in min time\n    for (int i=0; i<25*RANDOM_MULTIPLIER; i++) {\n      String f = fieldNames[random.nextInt(fieldNames.length)];\n      if (random.nextBoolean()) f = t1;  // the text field is a really interesting one to facet on (and it's multi-valued too)\n\n      // we want a random query and not just *:* so we'll get zero counts in facets also\n      // TODO: do a better random query\n      String q = random.nextBoolean() ? \"*:*\" : \"id:(1 3 5 7 9 11 13) OR id:[100 TO \" + random.nextInt(50) + \"]\";\n\n      int nolimit = random.nextBoolean() ? -1 : 10000;  // these should be equivalent\n\n      // if limit==-1, we should always get exact matches\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"count\", \"facet.mincount\",random.nextInt(5), \"facet.offset\",random.nextInt(10));\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"index\", \"facet.mincount\",random.nextInt(5), \"facet.offset\",random.nextInt(10));\n      // for index sort, we should get exact results for mincount <= 1\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.sort\",\"index\", \"facet.mincount\",random.nextInt(2), \"facet.offset\",random.nextInt(10), \"facet.limit\",random.nextInt(11)-1);\n    }\n    stress = backupStress;  // restore stress\n\n    // test faceting multiple things at once\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1);\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id:[1 TO 7]\", \"fq\",\"{!tag=b}id:[3 TO 9]\"\n    );\n    query(\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\");\n\n    // test field that is valid in schema but missing in all shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2);\n    // test field that is valid in schema and missing in some shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2);\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1);\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    // check a complex key name\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"*:*\", \"rows\",100);\n    }\n\n    //SOLR 3161 ensure shards.qt=/update fails (anything but search handler really)\n    // Also see TestRemoteStreaming#testQtUpdateFails()\n    try {\n      ignoreException(\"isShard is only acceptable\");\n      query(\"q\",\"*:*\",\"shards.qt\",\"/update\",\"stream.body\",\"<delete><query>*:*</query></delete>\");\n      fail();\n    } catch (SolrException e) {\n      //expected\n    }\n    unIgnoreException(\"isShard is only acceptable\");\n\n    // test debugging\n    handle.put(\"explain\", UNORDERED);\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY);\n\n    // Check Info is added to for each shard\n    ModifiableSolrParams q = new ModifiableSolrParams();\n    q.set(\"q\", \"*:*\");\n    q.set(ShardParams.SHARDS_INFO, true);\n    setDistributedParams(q);\n    QueryResponse rsp = queryServer(q);\n    NamedList<?> sinfo = (NamedList<?>) rsp.getResponse().get(ShardParams.SHARDS_INFO);\n    String shards = getShardsString();\n    int cnt = StringUtils.countMatches(shards, \",\")+1;\n    \n    assertNotNull(\"missing shard info\", sinfo);\n    assertEquals(\"should have an entry for each shard [\"+sinfo+\"] \"+shards, cnt, sinfo.size());\n    \n    // test shards.tolerant=true\n    for(int numDownServers = 0; numDownServers < jettys.size()-1; numDownServers++)\n    {\n      List<JettySolrRunner> upJettys = new ArrayList<JettySolrRunner>(jettys);\n      List<SolrServer> upClients = new ArrayList<SolrServer>(clients);\n      List<JettySolrRunner> downJettys = new ArrayList<JettySolrRunner>();\n      List<String> upShards = new ArrayList<String>(Arrays.asList(shardsArr));\n      for(int i=0; i<numDownServers; i++)\n      {\n        // shut down some of the jettys\n        int indexToRemove = r.nextInt(upJettys.size());\n        JettySolrRunner downJetty = upJettys.remove(indexToRemove);\n        upClients.remove(indexToRemove);\n        upShards.remove(indexToRemove);\n        ChaosMonkey.stop(downJetty);\n        downJettys.add(downJetty);\n      }\n      \n      queryPartialResults(upShards, upClients, \"q\",\"*:*\",ShardParams.SHARDS_INFO,\"true\",ShardParams.SHARDS_TOLERANT,\"true\");\n      \n      // restart the jettys\n      for (JettySolrRunner downJetty : downJettys) {\n        downJetty.start();\n      }\n    }\n\n    // This index has the same number for every field\n    \n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // Thread.sleep(10000000000L);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"f420cb3744c81c24c4a8781f95a446b9a2b5e011","date":1333057483,"type":3,"author":"Yonik Seeley","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/TestDistributedSearch#doTest().mjava","pathOld":"solr/core/src/test/org/apache/solr/TestDistributedSearch#doTest().mjava","sourceNew":"  @Override\n  public void doTest() throws Exception {\n    int backupStress = stress; // make a copy so we can restore\n\n\n    del(\"*:*\");\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\", \n           tdate_a, \"2010-04-20T11:00:00Z\",\n           tdate_b, \"2009-08-20T11:00:00Z\",\n           \"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\", \n           tdate_a, \"2010-05-02T11:00:00Z\",\n           tdate_b, \"2009-11-02T11:00:00Z\");\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\", \n           tdate_a, \"2010-05-03T11:00:00Z\");\n    indexr(id,4, i1, -100 ,tlong, 101,\n           t1,\"the quick fox jumped over the lazy dog\", \n           tdate_a, \"2010-05-03T11:00:00Z\",\n           tdate_b, \"2010-05-03T11:00:00Z\");\n    indexr(id,5, i1, 500, tlong, 500 ,\n           t1,\"the quick fox jumped way over the lazy dog\", \n           tdate_a, \"2010-05-05T11:00:00Z\");\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,\n           tdate_b, \"2010-01-05T11:00:00Z\",\n           t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,\n           t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,\n           t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,\n           t1,\"no eggs on wall, lesson learned\", \n           oddField, \"odd man out\");\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n\n    handle.clear();\n    handle.put(\"QTime\", SKIPVAL);\n    handle.put(\"timestamp\", SKIPVAL);\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(\"q\",\"*:*\", \"sort\",f+\" desc\");\n      query(\"q\",\"*:*\", \"sort\",f+\" asc\");\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",\"{!func}testfunc(add(\"+i1+\",5))\"+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" asc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\");\n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"*,score\"); \n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 desc\");\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"{!func}\"+i1);// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(\"q\",\"{!func}\"+i1, \"fl\",\"*,score\");  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"quick\");\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\");\n    query(\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\");  // no fields in returned docs\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\");\n\n    handle.put(\"score\", SKIPVAL);\n    query(\"q\",\"quick\",\"fl\",\"*,score\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\");\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"matchesnothing\",\"fl\",\"*,score\");  \n\n    // test that a single NOW value is propagated to all shards... if that is true\n    // then the primary sort should always be a tie and then the secondary should always decide\n    query(\"q\",\"{!func}ms(NOW)\", \"sort\",\"score desc,\"+i1+\" desc\",\"fl\",\"id\");    \n\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\");\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2);\n\n    // simple date facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date.other\", \"all\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // date facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date\",tdate_b, \n          \"facet.date.other\", \"all\", \n          \"f.\"+tdate_b+\".facet.date.start\",\"2009-05-01T11:00:00Z\", \n          \"f.\"+tdate_b+\".facet.date.gap\",\"+3MONTHS\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // simple range facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"facet.range.end\",900);\n\n    // range facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range\",i1, \n          \"f.\"+i1+\".facet.range.start\",300, \n          \"f.\"+i1+\".facet.range.gap\",87, \n          \"facet.range.end\",900,\n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"f.\"+tlong+\".facet.range.end\",900);\n    \n    //  variations of fl\n    query(\"q\",\"*:*\", \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1 + \",score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", i1, \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id,\" + i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1, \"fl\", \"id\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",nint, \"fl\",tint,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",nint, \"fl\", \"id\", \"fl\",tint,\"sort\",i1 + \" desc\");\n\n    stress=0;  // turn off stress... we want to tex max combos in min time\n    for (int i=0; i<25*RANDOM_MULTIPLIER; i++) {\n      String f = fieldNames[random.nextInt(fieldNames.length)];\n      if (random.nextBoolean()) f = t1;  // the text field is a really interesting one to facet on (and it's multi-valued too)\n\n      // we want a random query and not just *:* so we'll get zero counts in facets also\n      // TODO: do a better random query\n      String q = random.nextBoolean() ? \"*:*\" : \"id:(1 3 5 7 9 11 13) OR id:[100 TO \" + random.nextInt(50) + \"]\";\n\n      int nolimit = random.nextBoolean() ? -1 : 10000;  // these should be equivalent\n\n      // if limit==-1, we should always get exact matches\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"count\", \"facet.mincount\",random.nextInt(5), \"facet.offset\",random.nextInt(10));\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"index\", \"facet.mincount\",random.nextInt(5), \"facet.offset\",random.nextInt(10));\n      // for index sort, we should get exact results for mincount <= 1\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.sort\",\"index\", \"facet.mincount\",random.nextInt(2), \"facet.offset\",random.nextInt(10), \"facet.limit\",random.nextInt(11)-1);\n    }\n    stress = backupStress;  // restore stress\n\n    // test faceting multiple things at once\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1);\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id:[1 TO 7]\", \"fq\",\"{!tag=b}id:[3 TO 9]\"\n    );\n    query(\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\");\n\n    // test field that is valid in schema but missing in all shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2);\n    // test field that is valid in schema and missing in some shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2);\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1);\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    // check a complex key name\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"*:*\", \"rows\",100);\n    }\n\n    //SOLR 3161 ensure shards.qt=/update fails (anything but search handler really)\n    // Also see TestRemoteStreaming#testQtUpdateFails()\n    try {\n      ignoreException(\"isShard is only acceptable\");\n      // query(\"q\",\"*:*\",\"shards.qt\",\"/update\",\"stream.body\",\"<delete><query>*:*</query></delete>\");\n      // fail();\n    } catch (SolrException e) {\n      //expected\n    }\n    unIgnoreException(\"isShard is only acceptable\");\n\n    // test debugging\n    handle.put(\"explain\", UNORDERED);\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY);\n\n    // Check Info is added to for each shard\n    ModifiableSolrParams q = new ModifiableSolrParams();\n    q.set(\"q\", \"*:*\");\n    q.set(ShardParams.SHARDS_INFO, true);\n    setDistributedParams(q);\n    QueryResponse rsp = queryServer(q);\n    NamedList<?> sinfo = (NamedList<?>) rsp.getResponse().get(ShardParams.SHARDS_INFO);\n    String shards = getShardsString();\n    int cnt = StringUtils.countMatches(shards, \",\")+1;\n    \n    assertNotNull(\"missing shard info\", sinfo);\n    assertEquals(\"should have an entry for each shard [\"+sinfo+\"] \"+shards, cnt, sinfo.size());\n    \n    // test shards.tolerant=true\n    for(int numDownServers = 0; numDownServers < jettys.size()-1; numDownServers++)\n    {\n      List<JettySolrRunner> upJettys = new ArrayList<JettySolrRunner>(jettys);\n      List<SolrServer> upClients = new ArrayList<SolrServer>(clients);\n      List<JettySolrRunner> downJettys = new ArrayList<JettySolrRunner>();\n      List<String> upShards = new ArrayList<String>(Arrays.asList(shardsArr));\n      for(int i=0; i<numDownServers; i++)\n      {\n        // shut down some of the jettys\n        int indexToRemove = r.nextInt(upJettys.size());\n        JettySolrRunner downJetty = upJettys.remove(indexToRemove);\n        upClients.remove(indexToRemove);\n        upShards.remove(indexToRemove);\n        ChaosMonkey.stop(downJetty);\n        downJettys.add(downJetty);\n      }\n      \n      queryPartialResults(upShards, upClients, \"q\",\"*:*\",ShardParams.SHARDS_INFO,\"true\",ShardParams.SHARDS_TOLERANT,\"true\");\n      \n      // restart the jettys\n      for (JettySolrRunner downJetty : downJettys) {\n        downJetty.start();\n      }\n    }\n\n    // This index has the same number for every field\n    \n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // Thread.sleep(10000000000L);\n  }\n\n","sourceOld":"  @Override\n  public void doTest() throws Exception {\n    int backupStress = stress; // make a copy so we can restore\n\n\n    del(\"*:*\");\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\", \n           tdate_a, \"2010-04-20T11:00:00Z\",\n           tdate_b, \"2009-08-20T11:00:00Z\",\n           \"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\", \n           tdate_a, \"2010-05-02T11:00:00Z\",\n           tdate_b, \"2009-11-02T11:00:00Z\");\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\", \n           tdate_a, \"2010-05-03T11:00:00Z\");\n    indexr(id,4, i1, -100 ,tlong, 101,\n           t1,\"the quick fox jumped over the lazy dog\", \n           tdate_a, \"2010-05-03T11:00:00Z\",\n           tdate_b, \"2010-05-03T11:00:00Z\");\n    indexr(id,5, i1, 500, tlong, 500 ,\n           t1,\"the quick fox jumped way over the lazy dog\", \n           tdate_a, \"2010-05-05T11:00:00Z\");\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,\n           tdate_b, \"2010-01-05T11:00:00Z\",\n           t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,\n           t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,\n           t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,\n           t1,\"no eggs on wall, lesson learned\", \n           oddField, \"odd man out\");\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n\n    handle.clear();\n    handle.put(\"QTime\", SKIPVAL);\n    handle.put(\"timestamp\", SKIPVAL);\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(\"q\",\"*:*\", \"sort\",f+\" desc\");\n      query(\"q\",\"*:*\", \"sort\",f+\" asc\");\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",\"{!func}testfunc(add(\"+i1+\",5))\"+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" asc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\");\n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"*,score\"); \n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 desc\");\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"{!func}\"+i1);// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(\"q\",\"{!func}\"+i1, \"fl\",\"*,score\");  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"quick\");\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\");\n    query(\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\");  // no fields in returned docs\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\");\n\n    handle.put(\"score\", SKIPVAL);\n    query(\"q\",\"quick\",\"fl\",\"*,score\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\");\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"matchesnothing\",\"fl\",\"*,score\");  \n\n    // test that a single NOW value is propagated to all shards... if that is true\n    // then the primary sort should always be a tie and then the secondary should always decide\n    query(\"q\",\"{!func}ms(NOW)\", \"sort\",\"score desc,\"+i1+\" desc\",\"fl\",\"id\");    \n\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\");\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2);\n\n    // simple date facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date.other\", \"all\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // date facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date\",tdate_b, \n          \"facet.date.other\", \"all\", \n          \"f.\"+tdate_b+\".facet.date.start\",\"2009-05-01T11:00:00Z\", \n          \"f.\"+tdate_b+\".facet.date.gap\",\"+3MONTHS\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // simple range facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"facet.range.end\",900);\n\n    // range facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range\",i1, \n          \"f.\"+i1+\".facet.range.start\",300, \n          \"f.\"+i1+\".facet.range.gap\",87, \n          \"facet.range.end\",900,\n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"f.\"+tlong+\".facet.range.end\",900);\n    \n    //  variations of fl\n    query(\"q\",\"*:*\", \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1 + \",score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", i1, \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id,\" + i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1, \"fl\", \"id\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",nint, \"fl\",tint,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",nint, \"fl\", \"id\", \"fl\",tint,\"sort\",i1 + \" desc\");\n\n    stress=0;  // turn off stress... we want to tex max combos in min time\n    for (int i=0; i<25*RANDOM_MULTIPLIER; i++) {\n      String f = fieldNames[random.nextInt(fieldNames.length)];\n      if (random.nextBoolean()) f = t1;  // the text field is a really interesting one to facet on (and it's multi-valued too)\n\n      // we want a random query and not just *:* so we'll get zero counts in facets also\n      // TODO: do a better random query\n      String q = random.nextBoolean() ? \"*:*\" : \"id:(1 3 5 7 9 11 13) OR id:[100 TO \" + random.nextInt(50) + \"]\";\n\n      int nolimit = random.nextBoolean() ? -1 : 10000;  // these should be equivalent\n\n      // if limit==-1, we should always get exact matches\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"count\", \"facet.mincount\",random.nextInt(5), \"facet.offset\",random.nextInt(10));\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"index\", \"facet.mincount\",random.nextInt(5), \"facet.offset\",random.nextInt(10));\n      // for index sort, we should get exact results for mincount <= 1\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.sort\",\"index\", \"facet.mincount\",random.nextInt(2), \"facet.offset\",random.nextInt(10), \"facet.limit\",random.nextInt(11)-1);\n    }\n    stress = backupStress;  // restore stress\n\n    // test faceting multiple things at once\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1);\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id:[1 TO 7]\", \"fq\",\"{!tag=b}id:[3 TO 9]\"\n    );\n    query(\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\");\n\n    // test field that is valid in schema but missing in all shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2);\n    // test field that is valid in schema and missing in some shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2);\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1);\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    // check a complex key name\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"*:*\", \"rows\",100);\n    }\n\n    //SOLR 3161 ensure shards.qt=/update fails (anything but search handler really)\n    // Also see TestRemoteStreaming#testQtUpdateFails()\n    try {\n      ignoreException(\"isShard is only acceptable\");\n      query(\"q\",\"*:*\",\"shards.qt\",\"/update\",\"stream.body\",\"<delete><query>*:*</query></delete>\");\n      // fail();\n    } catch (SolrException e) {\n      //expected\n    }\n    unIgnoreException(\"isShard is only acceptable\");\n\n    // test debugging\n    handle.put(\"explain\", UNORDERED);\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY);\n\n    // Check Info is added to for each shard\n    ModifiableSolrParams q = new ModifiableSolrParams();\n    q.set(\"q\", \"*:*\");\n    q.set(ShardParams.SHARDS_INFO, true);\n    setDistributedParams(q);\n    QueryResponse rsp = queryServer(q);\n    NamedList<?> sinfo = (NamedList<?>) rsp.getResponse().get(ShardParams.SHARDS_INFO);\n    String shards = getShardsString();\n    int cnt = StringUtils.countMatches(shards, \",\")+1;\n    \n    assertNotNull(\"missing shard info\", sinfo);\n    assertEquals(\"should have an entry for each shard [\"+sinfo+\"] \"+shards, cnt, sinfo.size());\n    \n    // test shards.tolerant=true\n    for(int numDownServers = 0; numDownServers < jettys.size()-1; numDownServers++)\n    {\n      List<JettySolrRunner> upJettys = new ArrayList<JettySolrRunner>(jettys);\n      List<SolrServer> upClients = new ArrayList<SolrServer>(clients);\n      List<JettySolrRunner> downJettys = new ArrayList<JettySolrRunner>();\n      List<String> upShards = new ArrayList<String>(Arrays.asList(shardsArr));\n      for(int i=0; i<numDownServers; i++)\n      {\n        // shut down some of the jettys\n        int indexToRemove = r.nextInt(upJettys.size());\n        JettySolrRunner downJetty = upJettys.remove(indexToRemove);\n        upClients.remove(indexToRemove);\n        upShards.remove(indexToRemove);\n        ChaosMonkey.stop(downJetty);\n        downJettys.add(downJetty);\n      }\n      \n      queryPartialResults(upShards, upClients, \"q\",\"*:*\",ShardParams.SHARDS_INFO,\"true\",ShardParams.SHARDS_TOLERANT,\"true\");\n      \n      // restart the jettys\n      for (JettySolrRunner downJetty : downJettys) {\n        downJetty.start();\n      }\n    }\n\n    // This index has the same number for every field\n    \n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // Thread.sleep(10000000000L);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"ba076ada7f119298baa28ce1043dbcf719a64141","date":1334419277,"type":3,"author":"Yonik Seeley","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/TestDistributedSearch#doTest().mjava","pathOld":"solr/core/src/test/org/apache/solr/TestDistributedSearch#doTest().mjava","sourceNew":"  @Override\n  public void doTest() throws Exception {\n    int backupStress = stress; // make a copy so we can restore\n\n\n    del(\"*:*\");\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\", \n           tdate_a, \"2010-04-20T11:00:00Z\",\n           tdate_b, \"2009-08-20T11:00:00Z\",\n           \"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\", \n           tdate_a, \"2010-05-02T11:00:00Z\",\n           tdate_b, \"2009-11-02T11:00:00Z\");\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\", \n           tdate_a, \"2010-05-03T11:00:00Z\");\n    indexr(id,4, i1, -100 ,tlong, 101,\n           t1,\"the quick fox jumped over the lazy dog\", \n           tdate_a, \"2010-05-03T11:00:00Z\",\n           tdate_b, \"2010-05-03T11:00:00Z\");\n    indexr(id,5, i1, 500, tlong, 500 ,\n           t1,\"the quick fox jumped way over the lazy dog\", \n           tdate_a, \"2010-05-05T11:00:00Z\");\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,\n           tdate_b, \"2010-01-05T11:00:00Z\",\n           t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n\n    commit();  // try to ensure there's more than one segment\n\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,\n           t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,\n           t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,\n           t1,\"no eggs on wall, lesson learned\", \n           oddField, \"odd man out\");\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n\n    handle.clear();\n    handle.put(\"QTime\", SKIPVAL);\n    handle.put(\"timestamp\", SKIPVAL);\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(\"q\",\"*:*\", \"sort\",f+\" desc\");\n      query(\"q\",\"*:*\", \"sort\",f+\" asc\");\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",\"{!func}testfunc(add(\"+i1+\",5))\"+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" asc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\");\n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"*,score\"); \n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 desc\");\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"{!func}\"+i1);// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(\"q\",\"{!func}\"+i1, \"fl\",\"*,score\");  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"quick\");\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\");\n    query(\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\");  // no fields in returned docs\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\");\n\n    handle.put(\"score\", SKIPVAL);\n    query(\"q\",\"quick\",\"fl\",\"*,score\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\");\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"matchesnothing\",\"fl\",\"*,score\");  \n\n    // test that a single NOW value is propagated to all shards... if that is true\n    // then the primary sort should always be a tie and then the secondary should always decide\n    query(\"q\",\"{!func}ms(NOW)\", \"sort\",\"score desc,\"+i1+\" desc\",\"fl\",\"id\");    \n\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\");\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2);\n\n    // simple date facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date.other\", \"all\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // date facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date\",tdate_b, \n          \"facet.date.other\", \"all\", \n          \"f.\"+tdate_b+\".facet.date.start\",\"2009-05-01T11:00:00Z\", \n          \"f.\"+tdate_b+\".facet.date.gap\",\"+3MONTHS\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // simple range facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"facet.range.end\",900);\n\n    // range facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range\",i1, \n          \"f.\"+i1+\".facet.range.start\",300, \n          \"f.\"+i1+\".facet.range.gap\",87, \n          \"facet.range.end\",900,\n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"f.\"+tlong+\".facet.range.end\",900);\n    \n    //  variations of fl\n    query(\"q\",\"*:*\", \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1 + \",score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", i1, \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id,\" + i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1, \"fl\", \"id\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",nint, \"fl\",tint,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",nint, \"fl\", \"id\", \"fl\",tint,\"sort\",i1 + \" desc\");\n\n    stress=0;  // turn off stress... we want to tex max combos in min time\n    for (int i=0; i<25*RANDOM_MULTIPLIER; i++) {\n      String f = fieldNames[random.nextInt(fieldNames.length)];\n      if (random.nextBoolean()) f = t1;  // the text field is a really interesting one to facet on (and it's multi-valued too)\n\n      // we want a random query and not just *:* so we'll get zero counts in facets also\n      // TODO: do a better random query\n      String q = random.nextBoolean() ? \"*:*\" : \"id:(1 3 5 7 9 11 13) OR id:[100 TO \" + random.nextInt(50) + \"]\";\n\n      int nolimit = random.nextBoolean() ? -1 : 10000;  // these should be equivalent\n\n      // if limit==-1, we should always get exact matches\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"count\", \"facet.mincount\",random.nextInt(5), \"facet.offset\",random.nextInt(10));\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"index\", \"facet.mincount\",random.nextInt(5), \"facet.offset\",random.nextInt(10));\n      // for index sort, we should get exact results for mincount <= 1\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.sort\",\"index\", \"facet.mincount\",random.nextInt(2), \"facet.offset\",random.nextInt(10), \"facet.limit\",random.nextInt(11)-1);\n    }\n    stress = backupStress;  // restore stress\n\n    // test faceting multiple things at once\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1);\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id:[1 TO 7]\", \"fq\",\"{!tag=b}id:[3 TO 9]\"\n    );\n    query(\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\");\n\n    // test field that is valid in schema but missing in all shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2);\n    // test field that is valid in schema and missing in some shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2);\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1);\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    // check a complex key name\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"*:*\", \"rows\",100);\n    }\n\n    //SOLR 3161 ensure shards.qt=/update fails (anything but search handler really)\n    // Also see TestRemoteStreaming#testQtUpdateFails()\n    try {\n      ignoreException(\"isShard is only acceptable\");\n      // query(\"q\",\"*:*\",\"shards.qt\",\"/update\",\"stream.body\",\"<delete><query>*:*</query></delete>\");\n      // fail();\n    } catch (SolrException e) {\n      //expected\n    }\n    unIgnoreException(\"isShard is only acceptable\");\n\n    // test debugging\n    handle.put(\"explain\", UNORDERED);\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY);\n\n    // Check Info is added to for each shard\n    ModifiableSolrParams q = new ModifiableSolrParams();\n    q.set(\"q\", \"*:*\");\n    q.set(ShardParams.SHARDS_INFO, true);\n    setDistributedParams(q);\n    QueryResponse rsp = queryServer(q);\n    NamedList<?> sinfo = (NamedList<?>) rsp.getResponse().get(ShardParams.SHARDS_INFO);\n    String shards = getShardsString();\n    int cnt = StringUtils.countMatches(shards, \",\")+1;\n    \n    assertNotNull(\"missing shard info\", sinfo);\n    assertEquals(\"should have an entry for each shard [\"+sinfo+\"] \"+shards, cnt, sinfo.size());\n    \n    // test shards.tolerant=true\n    for(int numDownServers = 0; numDownServers < jettys.size()-1; numDownServers++)\n    {\n      List<JettySolrRunner> upJettys = new ArrayList<JettySolrRunner>(jettys);\n      List<SolrServer> upClients = new ArrayList<SolrServer>(clients);\n      List<JettySolrRunner> downJettys = new ArrayList<JettySolrRunner>();\n      List<String> upShards = new ArrayList<String>(Arrays.asList(shardsArr));\n      for(int i=0; i<numDownServers; i++)\n      {\n        // shut down some of the jettys\n        int indexToRemove = r.nextInt(upJettys.size());\n        JettySolrRunner downJetty = upJettys.remove(indexToRemove);\n        upClients.remove(indexToRemove);\n        upShards.remove(indexToRemove);\n        ChaosMonkey.stop(downJetty);\n        downJettys.add(downJetty);\n      }\n      \n      queryPartialResults(upShards, upClients, \"q\",\"*:*\",ShardParams.SHARDS_INFO,\"true\",ShardParams.SHARDS_TOLERANT,\"true\");\n      \n      // restart the jettys\n      for (JettySolrRunner downJetty : downJettys) {\n        downJetty.start();\n      }\n    }\n\n    // This index has the same number for every field\n    \n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // Thread.sleep(10000000000L);\n\n    purgeFieldCache(FieldCache.DEFAULT);   // avoid FC insanity\n  }\n\n","sourceOld":"  @Override\n  public void doTest() throws Exception {\n    int backupStress = stress; // make a copy so we can restore\n\n\n    del(\"*:*\");\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\", \n           tdate_a, \"2010-04-20T11:00:00Z\",\n           tdate_b, \"2009-08-20T11:00:00Z\",\n           \"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\", \n           tdate_a, \"2010-05-02T11:00:00Z\",\n           tdate_b, \"2009-11-02T11:00:00Z\");\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\", \n           tdate_a, \"2010-05-03T11:00:00Z\");\n    indexr(id,4, i1, -100 ,tlong, 101,\n           t1,\"the quick fox jumped over the lazy dog\", \n           tdate_a, \"2010-05-03T11:00:00Z\",\n           tdate_b, \"2010-05-03T11:00:00Z\");\n    indexr(id,5, i1, 500, tlong, 500 ,\n           t1,\"the quick fox jumped way over the lazy dog\", \n           tdate_a, \"2010-05-05T11:00:00Z\");\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,\n           tdate_b, \"2010-01-05T11:00:00Z\",\n           t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,\n           t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,\n           t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,\n           t1,\"no eggs on wall, lesson learned\", \n           oddField, \"odd man out\");\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n\n    handle.clear();\n    handle.put(\"QTime\", SKIPVAL);\n    handle.put(\"timestamp\", SKIPVAL);\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(\"q\",\"*:*\", \"sort\",f+\" desc\");\n      query(\"q\",\"*:*\", \"sort\",f+\" asc\");\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",\"{!func}testfunc(add(\"+i1+\",5))\"+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" asc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\");\n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"*,score\"); \n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 desc\");\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"{!func}\"+i1);// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(\"q\",\"{!func}\"+i1, \"fl\",\"*,score\");  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"quick\");\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\");\n    query(\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\");  // no fields in returned docs\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\");\n\n    handle.put(\"score\", SKIPVAL);\n    query(\"q\",\"quick\",\"fl\",\"*,score\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\");\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"matchesnothing\",\"fl\",\"*,score\");  \n\n    // test that a single NOW value is propagated to all shards... if that is true\n    // then the primary sort should always be a tie and then the secondary should always decide\n    query(\"q\",\"{!func}ms(NOW)\", \"sort\",\"score desc,\"+i1+\" desc\",\"fl\",\"id\");    \n\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\");\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2);\n\n    // simple date facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date.other\", \"all\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // date facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date\",tdate_b, \n          \"facet.date.other\", \"all\", \n          \"f.\"+tdate_b+\".facet.date.start\",\"2009-05-01T11:00:00Z\", \n          \"f.\"+tdate_b+\".facet.date.gap\",\"+3MONTHS\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // simple range facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"facet.range.end\",900);\n\n    // range facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range\",i1, \n          \"f.\"+i1+\".facet.range.start\",300, \n          \"f.\"+i1+\".facet.range.gap\",87, \n          \"facet.range.end\",900,\n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"f.\"+tlong+\".facet.range.end\",900);\n    \n    //  variations of fl\n    query(\"q\",\"*:*\", \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1 + \",score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", i1, \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id,\" + i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1, \"fl\", \"id\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",nint, \"fl\",tint,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",nint, \"fl\", \"id\", \"fl\",tint,\"sort\",i1 + \" desc\");\n\n    stress=0;  // turn off stress... we want to tex max combos in min time\n    for (int i=0; i<25*RANDOM_MULTIPLIER; i++) {\n      String f = fieldNames[random.nextInt(fieldNames.length)];\n      if (random.nextBoolean()) f = t1;  // the text field is a really interesting one to facet on (and it's multi-valued too)\n\n      // we want a random query and not just *:* so we'll get zero counts in facets also\n      // TODO: do a better random query\n      String q = random.nextBoolean() ? \"*:*\" : \"id:(1 3 5 7 9 11 13) OR id:[100 TO \" + random.nextInt(50) + \"]\";\n\n      int nolimit = random.nextBoolean() ? -1 : 10000;  // these should be equivalent\n\n      // if limit==-1, we should always get exact matches\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"count\", \"facet.mincount\",random.nextInt(5), \"facet.offset\",random.nextInt(10));\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"index\", \"facet.mincount\",random.nextInt(5), \"facet.offset\",random.nextInt(10));\n      // for index sort, we should get exact results for mincount <= 1\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.sort\",\"index\", \"facet.mincount\",random.nextInt(2), \"facet.offset\",random.nextInt(10), \"facet.limit\",random.nextInt(11)-1);\n    }\n    stress = backupStress;  // restore stress\n\n    // test faceting multiple things at once\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1);\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id:[1 TO 7]\", \"fq\",\"{!tag=b}id:[3 TO 9]\"\n    );\n    query(\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\");\n\n    // test field that is valid in schema but missing in all shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2);\n    // test field that is valid in schema and missing in some shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2);\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1);\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    // check a complex key name\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"*:*\", \"rows\",100);\n    }\n\n    //SOLR 3161 ensure shards.qt=/update fails (anything but search handler really)\n    // Also see TestRemoteStreaming#testQtUpdateFails()\n    try {\n      ignoreException(\"isShard is only acceptable\");\n      // query(\"q\",\"*:*\",\"shards.qt\",\"/update\",\"stream.body\",\"<delete><query>*:*</query></delete>\");\n      // fail();\n    } catch (SolrException e) {\n      //expected\n    }\n    unIgnoreException(\"isShard is only acceptable\");\n\n    // test debugging\n    handle.put(\"explain\", UNORDERED);\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY);\n\n    // Check Info is added to for each shard\n    ModifiableSolrParams q = new ModifiableSolrParams();\n    q.set(\"q\", \"*:*\");\n    q.set(ShardParams.SHARDS_INFO, true);\n    setDistributedParams(q);\n    QueryResponse rsp = queryServer(q);\n    NamedList<?> sinfo = (NamedList<?>) rsp.getResponse().get(ShardParams.SHARDS_INFO);\n    String shards = getShardsString();\n    int cnt = StringUtils.countMatches(shards, \",\")+1;\n    \n    assertNotNull(\"missing shard info\", sinfo);\n    assertEquals(\"should have an entry for each shard [\"+sinfo+\"] \"+shards, cnt, sinfo.size());\n    \n    // test shards.tolerant=true\n    for(int numDownServers = 0; numDownServers < jettys.size()-1; numDownServers++)\n    {\n      List<JettySolrRunner> upJettys = new ArrayList<JettySolrRunner>(jettys);\n      List<SolrServer> upClients = new ArrayList<SolrServer>(clients);\n      List<JettySolrRunner> downJettys = new ArrayList<JettySolrRunner>();\n      List<String> upShards = new ArrayList<String>(Arrays.asList(shardsArr));\n      for(int i=0; i<numDownServers; i++)\n      {\n        // shut down some of the jettys\n        int indexToRemove = r.nextInt(upJettys.size());\n        JettySolrRunner downJetty = upJettys.remove(indexToRemove);\n        upClients.remove(indexToRemove);\n        upShards.remove(indexToRemove);\n        ChaosMonkey.stop(downJetty);\n        downJettys.add(downJetty);\n      }\n      \n      queryPartialResults(upShards, upClients, \"q\",\"*:*\",ShardParams.SHARDS_INFO,\"true\",ShardParams.SHARDS_TOLERANT,\"true\");\n      \n      // restart the jettys\n      for (JettySolrRunner downJetty : downJettys) {\n        downJetty.start();\n      }\n    }\n\n    // This index has the same number for every field\n    \n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // Thread.sleep(10000000000L);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"629c38c4ae4e303d0617e05fbfe508140b32f0a3","date":1334500904,"type":3,"author":"Dawid Weiss","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/TestDistributedSearch#doTest().mjava","pathOld":"solr/core/src/test/org/apache/solr/TestDistributedSearch#doTest().mjava","sourceNew":"  @Override\n  public void doTest() throws Exception {\n    int backupStress = stress; // make a copy so we can restore\n\n\n    del(\"*:*\");\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\", \n           tdate_a, \"2010-04-20T11:00:00Z\",\n           tdate_b, \"2009-08-20T11:00:00Z\",\n           \"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\", \n           tdate_a, \"2010-05-02T11:00:00Z\",\n           tdate_b, \"2009-11-02T11:00:00Z\");\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\", \n           tdate_a, \"2010-05-03T11:00:00Z\");\n    indexr(id,4, i1, -100 ,tlong, 101,\n           t1,\"the quick fox jumped over the lazy dog\", \n           tdate_a, \"2010-05-03T11:00:00Z\",\n           tdate_b, \"2010-05-03T11:00:00Z\");\n    indexr(id,5, i1, 500, tlong, 500 ,\n           t1,\"the quick fox jumped way over the lazy dog\", \n           tdate_a, \"2010-05-05T11:00:00Z\");\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,\n           tdate_b, \"2010-01-05T11:00:00Z\",\n           t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n\n    commit();  // try to ensure there's more than one segment\n\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,\n           t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,\n           t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,\n           t1,\"no eggs on wall, lesson learned\", \n           oddField, \"odd man out\");\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n\n    handle.clear();\n    handle.put(\"QTime\", SKIPVAL);\n    handle.put(\"timestamp\", SKIPVAL);\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(\"q\",\"*:*\", \"sort\",f+\" desc\");\n      query(\"q\",\"*:*\", \"sort\",f+\" asc\");\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",\"{!func}testfunc(add(\"+i1+\",5))\"+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" asc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\");\n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"*,score\"); \n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 desc\");\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"{!func}\"+i1);// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(\"q\",\"{!func}\"+i1, \"fl\",\"*,score\");  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"quick\");\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\");\n    query(\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\");  // no fields in returned docs\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\");\n\n    handle.put(\"score\", SKIPVAL);\n    query(\"q\",\"quick\",\"fl\",\"*,score\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\");\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"matchesnothing\",\"fl\",\"*,score\");  \n\n    // test that a single NOW value is propagated to all shards... if that is true\n    // then the primary sort should always be a tie and then the secondary should always decide\n    query(\"q\",\"{!func}ms(NOW)\", \"sort\",\"score desc,\"+i1+\" desc\",\"fl\",\"id\");    \n\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\");\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2);\n\n    // simple date facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date.other\", \"all\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // date facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date\",tdate_b, \n          \"facet.date.other\", \"all\", \n          \"f.\"+tdate_b+\".facet.date.start\",\"2009-05-01T11:00:00Z\", \n          \"f.\"+tdate_b+\".facet.date.gap\",\"+3MONTHS\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // simple range facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"facet.range.end\",900);\n\n    // range facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range\",i1, \n          \"f.\"+i1+\".facet.range.start\",300, \n          \"f.\"+i1+\".facet.range.gap\",87, \n          \"facet.range.end\",900,\n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"f.\"+tlong+\".facet.range.end\",900);\n    \n    //  variations of fl\n    query(\"q\",\"*:*\", \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1 + \",score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", i1, \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id,\" + i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1, \"fl\", \"id\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",nint, \"fl\",tint,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",nint, \"fl\", \"id\", \"fl\",tint,\"sort\",i1 + \" desc\");\n\n    stress=0;  // turn off stress... we want to tex max combos in min time\n    for (int i=0; i<25*RANDOM_MULTIPLIER; i++) {\n      String f = fieldNames[random().nextInt(fieldNames.length)];\n      if (random().nextBoolean()) f = t1;  // the text field is a really interesting one to facet on (and it's multi-valued too)\n\n      // we want a random query and not just *:* so we'll get zero counts in facets also\n      // TODO: do a better random query\n      String q = random().nextBoolean() ? \"*:*\" : \"id:(1 3 5 7 9 11 13) OR id:[100 TO \" + random().nextInt(50) + \"]\";\n\n      int nolimit = random().nextBoolean() ? -1 : 10000;  // these should be equivalent\n\n      // if limit==-1, we should always get exact matches\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"count\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      // for index sort, we should get exact results for mincount <= 1\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(2), \"facet.offset\",random().nextInt(10), \"facet.limit\",random().nextInt(11)-1);\n    }\n    stress = backupStress;  // restore stress\n\n    // test faceting multiple things at once\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1);\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id:[1 TO 7]\", \"fq\",\"{!tag=b}id:[3 TO 9]\"\n    );\n    query(\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\");\n\n    // test field that is valid in schema but missing in all shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2);\n    // test field that is valid in schema and missing in some shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2);\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1);\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    // check a complex key name\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"*:*\", \"rows\",100);\n    }\n\n    //SOLR 3161 ensure shards.qt=/update fails (anything but search handler really)\n    // Also see TestRemoteStreaming#testQtUpdateFails()\n    try {\n      ignoreException(\"isShard is only acceptable\");\n      // query(\"q\",\"*:*\",\"shards.qt\",\"/update\",\"stream.body\",\"<delete><query>*:*</query></delete>\");\n      // fail();\n    } catch (SolrException e) {\n      //expected\n    }\n    unIgnoreException(\"isShard is only acceptable\");\n\n    // test debugging\n    handle.put(\"explain\", UNORDERED);\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY);\n\n    // Check Info is added to for each shard\n    ModifiableSolrParams q = new ModifiableSolrParams();\n    q.set(\"q\", \"*:*\");\n    q.set(ShardParams.SHARDS_INFO, true);\n    setDistributedParams(q);\n    QueryResponse rsp = queryServer(q);\n    NamedList<?> sinfo = (NamedList<?>) rsp.getResponse().get(ShardParams.SHARDS_INFO);\n    String shards = getShardsString();\n    int cnt = StringUtils.countMatches(shards, \",\")+1;\n    \n    assertNotNull(\"missing shard info\", sinfo);\n    assertEquals(\"should have an entry for each shard [\"+sinfo+\"] \"+shards, cnt, sinfo.size());\n    \n    // test shards.tolerant=true\n    for(int numDownServers = 0; numDownServers < jettys.size()-1; numDownServers++)\n    {\n      List<JettySolrRunner> upJettys = new ArrayList<JettySolrRunner>(jettys);\n      List<SolrServer> upClients = new ArrayList<SolrServer>(clients);\n      List<JettySolrRunner> downJettys = new ArrayList<JettySolrRunner>();\n      List<String> upShards = new ArrayList<String>(Arrays.asList(shardsArr));\n      for(int i=0; i<numDownServers; i++)\n      {\n        // shut down some of the jettys\n        int indexToRemove = r.nextInt(upJettys.size());\n        JettySolrRunner downJetty = upJettys.remove(indexToRemove);\n        upClients.remove(indexToRemove);\n        upShards.remove(indexToRemove);\n        ChaosMonkey.stop(downJetty);\n        downJettys.add(downJetty);\n      }\n      \n      queryPartialResults(upShards, upClients, \"q\",\"*:*\",ShardParams.SHARDS_INFO,\"true\",ShardParams.SHARDS_TOLERANT,\"true\");\n      \n      // restart the jettys\n      for (JettySolrRunner downJetty : downJettys) {\n        downJetty.start();\n      }\n    }\n\n    // This index has the same number for every field\n    \n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // Thread.sleep(10000000000L);\n\n    purgeFieldCache(FieldCache.DEFAULT);   // avoid FC insanity\n  }\n\n","sourceOld":"  @Override\n  public void doTest() throws Exception {\n    int backupStress = stress; // make a copy so we can restore\n\n\n    del(\"*:*\");\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\", \n           tdate_a, \"2010-04-20T11:00:00Z\",\n           tdate_b, \"2009-08-20T11:00:00Z\",\n           \"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\", \n           tdate_a, \"2010-05-02T11:00:00Z\",\n           tdate_b, \"2009-11-02T11:00:00Z\");\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\", \n           tdate_a, \"2010-05-03T11:00:00Z\");\n    indexr(id,4, i1, -100 ,tlong, 101,\n           t1,\"the quick fox jumped over the lazy dog\", \n           tdate_a, \"2010-05-03T11:00:00Z\",\n           tdate_b, \"2010-05-03T11:00:00Z\");\n    indexr(id,5, i1, 500, tlong, 500 ,\n           t1,\"the quick fox jumped way over the lazy dog\", \n           tdate_a, \"2010-05-05T11:00:00Z\");\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,\n           tdate_b, \"2010-01-05T11:00:00Z\",\n           t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n\n    commit();  // try to ensure there's more than one segment\n\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,\n           t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,\n           t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,\n           t1,\"no eggs on wall, lesson learned\", \n           oddField, \"odd man out\");\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n\n    handle.clear();\n    handle.put(\"QTime\", SKIPVAL);\n    handle.put(\"timestamp\", SKIPVAL);\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(\"q\",\"*:*\", \"sort\",f+\" desc\");\n      query(\"q\",\"*:*\", \"sort\",f+\" asc\");\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",\"{!func}testfunc(add(\"+i1+\",5))\"+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" asc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\");\n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"*,score\"); \n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 desc\");\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"{!func}\"+i1);// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(\"q\",\"{!func}\"+i1, \"fl\",\"*,score\");  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"quick\");\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\");\n    query(\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\");  // no fields in returned docs\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\");\n\n    handle.put(\"score\", SKIPVAL);\n    query(\"q\",\"quick\",\"fl\",\"*,score\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\");\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"matchesnothing\",\"fl\",\"*,score\");  \n\n    // test that a single NOW value is propagated to all shards... if that is true\n    // then the primary sort should always be a tie and then the secondary should always decide\n    query(\"q\",\"{!func}ms(NOW)\", \"sort\",\"score desc,\"+i1+\" desc\",\"fl\",\"id\");    \n\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\");\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2);\n\n    // simple date facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date.other\", \"all\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // date facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date\",tdate_b, \n          \"facet.date.other\", \"all\", \n          \"f.\"+tdate_b+\".facet.date.start\",\"2009-05-01T11:00:00Z\", \n          \"f.\"+tdate_b+\".facet.date.gap\",\"+3MONTHS\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // simple range facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"facet.range.end\",900);\n\n    // range facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range\",i1, \n          \"f.\"+i1+\".facet.range.start\",300, \n          \"f.\"+i1+\".facet.range.gap\",87, \n          \"facet.range.end\",900,\n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"f.\"+tlong+\".facet.range.end\",900);\n    \n    //  variations of fl\n    query(\"q\",\"*:*\", \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1 + \",score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", i1, \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id,\" + i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1, \"fl\", \"id\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",nint, \"fl\",tint,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",nint, \"fl\", \"id\", \"fl\",tint,\"sort\",i1 + \" desc\");\n\n    stress=0;  // turn off stress... we want to tex max combos in min time\n    for (int i=0; i<25*RANDOM_MULTIPLIER; i++) {\n      String f = fieldNames[random.nextInt(fieldNames.length)];\n      if (random.nextBoolean()) f = t1;  // the text field is a really interesting one to facet on (and it's multi-valued too)\n\n      // we want a random query and not just *:* so we'll get zero counts in facets also\n      // TODO: do a better random query\n      String q = random.nextBoolean() ? \"*:*\" : \"id:(1 3 5 7 9 11 13) OR id:[100 TO \" + random.nextInt(50) + \"]\";\n\n      int nolimit = random.nextBoolean() ? -1 : 10000;  // these should be equivalent\n\n      // if limit==-1, we should always get exact matches\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"count\", \"facet.mincount\",random.nextInt(5), \"facet.offset\",random.nextInt(10));\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"index\", \"facet.mincount\",random.nextInt(5), \"facet.offset\",random.nextInt(10));\n      // for index sort, we should get exact results for mincount <= 1\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.sort\",\"index\", \"facet.mincount\",random.nextInt(2), \"facet.offset\",random.nextInt(10), \"facet.limit\",random.nextInt(11)-1);\n    }\n    stress = backupStress;  // restore stress\n\n    // test faceting multiple things at once\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1);\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id:[1 TO 7]\", \"fq\",\"{!tag=b}id:[3 TO 9]\"\n    );\n    query(\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\");\n\n    // test field that is valid in schema but missing in all shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2);\n    // test field that is valid in schema and missing in some shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2);\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1);\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    // check a complex key name\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"*:*\", \"rows\",100);\n    }\n\n    //SOLR 3161 ensure shards.qt=/update fails (anything but search handler really)\n    // Also see TestRemoteStreaming#testQtUpdateFails()\n    try {\n      ignoreException(\"isShard is only acceptable\");\n      // query(\"q\",\"*:*\",\"shards.qt\",\"/update\",\"stream.body\",\"<delete><query>*:*</query></delete>\");\n      // fail();\n    } catch (SolrException e) {\n      //expected\n    }\n    unIgnoreException(\"isShard is only acceptable\");\n\n    // test debugging\n    handle.put(\"explain\", UNORDERED);\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY);\n\n    // Check Info is added to for each shard\n    ModifiableSolrParams q = new ModifiableSolrParams();\n    q.set(\"q\", \"*:*\");\n    q.set(ShardParams.SHARDS_INFO, true);\n    setDistributedParams(q);\n    QueryResponse rsp = queryServer(q);\n    NamedList<?> sinfo = (NamedList<?>) rsp.getResponse().get(ShardParams.SHARDS_INFO);\n    String shards = getShardsString();\n    int cnt = StringUtils.countMatches(shards, \",\")+1;\n    \n    assertNotNull(\"missing shard info\", sinfo);\n    assertEquals(\"should have an entry for each shard [\"+sinfo+\"] \"+shards, cnt, sinfo.size());\n    \n    // test shards.tolerant=true\n    for(int numDownServers = 0; numDownServers < jettys.size()-1; numDownServers++)\n    {\n      List<JettySolrRunner> upJettys = new ArrayList<JettySolrRunner>(jettys);\n      List<SolrServer> upClients = new ArrayList<SolrServer>(clients);\n      List<JettySolrRunner> downJettys = new ArrayList<JettySolrRunner>();\n      List<String> upShards = new ArrayList<String>(Arrays.asList(shardsArr));\n      for(int i=0; i<numDownServers; i++)\n      {\n        // shut down some of the jettys\n        int indexToRemove = r.nextInt(upJettys.size());\n        JettySolrRunner downJetty = upJettys.remove(indexToRemove);\n        upClients.remove(indexToRemove);\n        upShards.remove(indexToRemove);\n        ChaosMonkey.stop(downJetty);\n        downJettys.add(downJetty);\n      }\n      \n      queryPartialResults(upShards, upClients, \"q\",\"*:*\",ShardParams.SHARDS_INFO,\"true\",ShardParams.SHARDS_TOLERANT,\"true\");\n      \n      // restart the jettys\n      for (JettySolrRunner downJetty : downJettys) {\n        downJetty.start();\n      }\n    }\n\n    // This index has the same number for every field\n    \n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // Thread.sleep(10000000000L);\n\n    purgeFieldCache(FieldCache.DEFAULT);   // avoid FC insanity\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"ea7c3cda25547888b8a5a3989f5bbb00066746ed","date":1334792299,"type":3,"author":"Yonik Seeley","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/TestDistributedSearch#doTest().mjava","pathOld":"solr/core/src/test/org/apache/solr/TestDistributedSearch#doTest().mjava","sourceNew":"  @Override\n  public void doTest() throws Exception {\n    int backupStress = stress; // make a copy so we can restore\n\n\n    del(\"*:*\");\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\", \n           tdate_a, \"2010-04-20T11:00:00Z\",\n           tdate_b, \"2009-08-20T11:00:00Z\",\n           \"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\", \n           tdate_a, \"2010-05-02T11:00:00Z\",\n           tdate_b, \"2009-11-02T11:00:00Z\");\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\", \n           tdate_a, \"2010-05-03T11:00:00Z\");\n    indexr(id,4, i1, -100 ,tlong, 101,\n           t1,\"the quick fox jumped over the lazy dog\", \n           tdate_a, \"2010-05-03T11:00:00Z\",\n           tdate_b, \"2010-05-03T11:00:00Z\");\n    indexr(id,5, i1, 500, tlong, 500 ,\n           t1,\"the quick fox jumped way over the lazy dog\", \n           tdate_a, \"2010-05-05T11:00:00Z\");\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,\n           tdate_b, \"2010-01-05T11:00:00Z\",\n           t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n\n    commit();  // try to ensure there's more than one segment\n\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,\n           t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,\n           t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,\n           t1,\"no eggs on wall, lesson learned\", \n           oddField, \"odd man out\");\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n\n    handle.clear();\n    handle.put(\"QTime\", SKIPVAL);\n    handle.put(\"timestamp\", SKIPVAL);\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(\"q\",\"*:*\", \"sort\",f+\" desc\");\n      query(\"q\",\"*:*\", \"sort\",f+\" asc\");\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",\"{!func}testfunc(add(\"+i1+\",5))\"+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" asc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\");\n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"*,score\"); \n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 desc\");\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"{!func}\"+i1);// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(\"q\",\"{!func}\"+i1, \"fl\",\"*,score\");  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"quick\");\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\");\n    query(\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\");  // no fields in returned docs\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\");\n\n    handle.put(\"score\", SKIPVAL);\n    query(\"q\",\"quick\",\"fl\",\"*,score\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\");\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"matchesnothing\",\"fl\",\"*,score\");  \n\n    // test that a single NOW value is propagated to all shards... if that is true\n    // then the primary sort should always be a tie and then the secondary should always decide\n    query(\"q\",\"{!func}ms(NOW)\", \"sort\",\"score desc,\"+i1+\" desc\",\"fl\",\"id\");    \n\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\");\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2);\n\n    // a facet query to test out chars out of the ascii range\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!term f=foo_s}international\\u00ff\\u01ff\\u2222\\u3333\");\n\n    // simple date facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date.other\", \"all\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // date facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date\",tdate_b, \n          \"facet.date.other\", \"all\", \n          \"f.\"+tdate_b+\".facet.date.start\",\"2009-05-01T11:00:00Z\", \n          \"f.\"+tdate_b+\".facet.date.gap\",\"+3MONTHS\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // simple range facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"facet.range.end\",900);\n\n    // range facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range\",i1, \n          \"f.\"+i1+\".facet.range.start\",300, \n          \"f.\"+i1+\".facet.range.gap\",87, \n          \"facet.range.end\",900,\n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"f.\"+tlong+\".facet.range.end\",900);\n    \n    //  variations of fl\n    query(\"q\",\"*:*\", \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1 + \",score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", i1, \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id,\" + i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1, \"fl\", \"id\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",nint, \"fl\",tint,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",nint, \"fl\", \"id\", \"fl\",tint,\"sort\",i1 + \" desc\");\n\n    stress=0;  // turn off stress... we want to tex max combos in min time\n    for (int i=0; i<25*RANDOM_MULTIPLIER; i++) {\n      String f = fieldNames[random().nextInt(fieldNames.length)];\n      if (random().nextBoolean()) f = t1;  // the text field is a really interesting one to facet on (and it's multi-valued too)\n\n      // we want a random query and not just *:* so we'll get zero counts in facets also\n      // TODO: do a better random query\n      String q = random().nextBoolean() ? \"*:*\" : \"id:(1 3 5 7 9 11 13) OR id:[100 TO \" + random().nextInt(50) + \"]\";\n\n      int nolimit = random().nextBoolean() ? -1 : 10000;  // these should be equivalent\n\n      // if limit==-1, we should always get exact matches\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"count\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      // for index sort, we should get exact results for mincount <= 1\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(2), \"facet.offset\",random().nextInt(10), \"facet.limit\",random().nextInt(11)-1);\n    }\n    stress = backupStress;  // restore stress\n\n    // test faceting multiple things at once\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1);\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id:[1 TO 7]\", \"fq\",\"{!tag=b}id:[3 TO 9]\"\n    );\n    query(\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\");\n\n    // test field that is valid in schema but missing in all shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2);\n    // test field that is valid in schema and missing in some shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2);\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1);\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    // check a complex key name\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"*:*\", \"rows\",100);\n    }\n\n    //SOLR 3161 ensure shards.qt=/update fails (anything but search handler really)\n    // Also see TestRemoteStreaming#testQtUpdateFails()\n    try {\n      ignoreException(\"isShard is only acceptable\");\n      // query(\"q\",\"*:*\",\"shards.qt\",\"/update\",\"stream.body\",\"<delete><query>*:*</query></delete>\");\n      // fail();\n    } catch (SolrException e) {\n      //expected\n    }\n    unIgnoreException(\"isShard is only acceptable\");\n\n    // test debugging\n    handle.put(\"explain\", UNORDERED);\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY);\n\n    // Check Info is added to for each shard\n    ModifiableSolrParams q = new ModifiableSolrParams();\n    q.set(\"q\", \"*:*\");\n    q.set(ShardParams.SHARDS_INFO, true);\n    setDistributedParams(q);\n    QueryResponse rsp = queryServer(q);\n    NamedList<?> sinfo = (NamedList<?>) rsp.getResponse().get(ShardParams.SHARDS_INFO);\n    String shards = getShardsString();\n    int cnt = StringUtils.countMatches(shards, \",\")+1;\n    \n    assertNotNull(\"missing shard info\", sinfo);\n    assertEquals(\"should have an entry for each shard [\"+sinfo+\"] \"+shards, cnt, sinfo.size());\n    \n    // test shards.tolerant=true\n    for(int numDownServers = 0; numDownServers < jettys.size()-1; numDownServers++)\n    {\n      List<JettySolrRunner> upJettys = new ArrayList<JettySolrRunner>(jettys);\n      List<SolrServer> upClients = new ArrayList<SolrServer>(clients);\n      List<JettySolrRunner> downJettys = new ArrayList<JettySolrRunner>();\n      List<String> upShards = new ArrayList<String>(Arrays.asList(shardsArr));\n      for(int i=0; i<numDownServers; i++)\n      {\n        // shut down some of the jettys\n        int indexToRemove = r.nextInt(upJettys.size());\n        JettySolrRunner downJetty = upJettys.remove(indexToRemove);\n        upClients.remove(indexToRemove);\n        upShards.remove(indexToRemove);\n        ChaosMonkey.stop(downJetty);\n        downJettys.add(downJetty);\n      }\n      \n      queryPartialResults(upShards, upClients, \"q\",\"*:*\",ShardParams.SHARDS_INFO,\"true\",ShardParams.SHARDS_TOLERANT,\"true\");\n      \n      // restart the jettys\n      for (JettySolrRunner downJetty : downJettys) {\n        downJetty.start();\n      }\n    }\n\n    // This index has the same number for every field\n    \n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // Thread.sleep(10000000000L);\n\n    purgeFieldCache(FieldCache.DEFAULT);   // avoid FC insanity\n  }\n\n","sourceOld":"  @Override\n  public void doTest() throws Exception {\n    int backupStress = stress; // make a copy so we can restore\n\n\n    del(\"*:*\");\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\", \n           tdate_a, \"2010-04-20T11:00:00Z\",\n           tdate_b, \"2009-08-20T11:00:00Z\",\n           \"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\", \n           tdate_a, \"2010-05-02T11:00:00Z\",\n           tdate_b, \"2009-11-02T11:00:00Z\");\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\", \n           tdate_a, \"2010-05-03T11:00:00Z\");\n    indexr(id,4, i1, -100 ,tlong, 101,\n           t1,\"the quick fox jumped over the lazy dog\", \n           tdate_a, \"2010-05-03T11:00:00Z\",\n           tdate_b, \"2010-05-03T11:00:00Z\");\n    indexr(id,5, i1, 500, tlong, 500 ,\n           t1,\"the quick fox jumped way over the lazy dog\", \n           tdate_a, \"2010-05-05T11:00:00Z\");\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,\n           tdate_b, \"2010-01-05T11:00:00Z\",\n           t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n\n    commit();  // try to ensure there's more than one segment\n\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,\n           t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,\n           t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,\n           t1,\"no eggs on wall, lesson learned\", \n           oddField, \"odd man out\");\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n\n    handle.clear();\n    handle.put(\"QTime\", SKIPVAL);\n    handle.put(\"timestamp\", SKIPVAL);\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(\"q\",\"*:*\", \"sort\",f+\" desc\");\n      query(\"q\",\"*:*\", \"sort\",f+\" asc\");\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",\"{!func}testfunc(add(\"+i1+\",5))\"+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" asc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\");\n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"*,score\"); \n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 desc\");\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"{!func}\"+i1);// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(\"q\",\"{!func}\"+i1, \"fl\",\"*,score\");  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"quick\");\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\");\n    query(\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\");  // no fields in returned docs\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\");\n\n    handle.put(\"score\", SKIPVAL);\n    query(\"q\",\"quick\",\"fl\",\"*,score\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\");\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"matchesnothing\",\"fl\",\"*,score\");  \n\n    // test that a single NOW value is propagated to all shards... if that is true\n    // then the primary sort should always be a tie and then the secondary should always decide\n    query(\"q\",\"{!func}ms(NOW)\", \"sort\",\"score desc,\"+i1+\" desc\",\"fl\",\"id\");    \n\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\");\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2);\n\n    // simple date facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date.other\", \"all\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // date facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date\",tdate_b, \n          \"facet.date.other\", \"all\", \n          \"f.\"+tdate_b+\".facet.date.start\",\"2009-05-01T11:00:00Z\", \n          \"f.\"+tdate_b+\".facet.date.gap\",\"+3MONTHS\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // simple range facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"facet.range.end\",900);\n\n    // range facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range\",i1, \n          \"f.\"+i1+\".facet.range.start\",300, \n          \"f.\"+i1+\".facet.range.gap\",87, \n          \"facet.range.end\",900,\n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"f.\"+tlong+\".facet.range.end\",900);\n    \n    //  variations of fl\n    query(\"q\",\"*:*\", \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1 + \",score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", i1, \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id,\" + i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1, \"fl\", \"id\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",nint, \"fl\",tint,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",nint, \"fl\", \"id\", \"fl\",tint,\"sort\",i1 + \" desc\");\n\n    stress=0;  // turn off stress... we want to tex max combos in min time\n    for (int i=0; i<25*RANDOM_MULTIPLIER; i++) {\n      String f = fieldNames[random().nextInt(fieldNames.length)];\n      if (random().nextBoolean()) f = t1;  // the text field is a really interesting one to facet on (and it's multi-valued too)\n\n      // we want a random query and not just *:* so we'll get zero counts in facets also\n      // TODO: do a better random query\n      String q = random().nextBoolean() ? \"*:*\" : \"id:(1 3 5 7 9 11 13) OR id:[100 TO \" + random().nextInt(50) + \"]\";\n\n      int nolimit = random().nextBoolean() ? -1 : 10000;  // these should be equivalent\n\n      // if limit==-1, we should always get exact matches\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"count\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      // for index sort, we should get exact results for mincount <= 1\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(2), \"facet.offset\",random().nextInt(10), \"facet.limit\",random().nextInt(11)-1);\n    }\n    stress = backupStress;  // restore stress\n\n    // test faceting multiple things at once\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1);\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id:[1 TO 7]\", \"fq\",\"{!tag=b}id:[3 TO 9]\"\n    );\n    query(\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\");\n\n    // test field that is valid in schema but missing in all shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2);\n    // test field that is valid in schema and missing in some shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2);\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1);\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    // check a complex key name\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"*:*\", \"rows\",100);\n    }\n\n    //SOLR 3161 ensure shards.qt=/update fails (anything but search handler really)\n    // Also see TestRemoteStreaming#testQtUpdateFails()\n    try {\n      ignoreException(\"isShard is only acceptable\");\n      // query(\"q\",\"*:*\",\"shards.qt\",\"/update\",\"stream.body\",\"<delete><query>*:*</query></delete>\");\n      // fail();\n    } catch (SolrException e) {\n      //expected\n    }\n    unIgnoreException(\"isShard is only acceptable\");\n\n    // test debugging\n    handle.put(\"explain\", UNORDERED);\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY);\n\n    // Check Info is added to for each shard\n    ModifiableSolrParams q = new ModifiableSolrParams();\n    q.set(\"q\", \"*:*\");\n    q.set(ShardParams.SHARDS_INFO, true);\n    setDistributedParams(q);\n    QueryResponse rsp = queryServer(q);\n    NamedList<?> sinfo = (NamedList<?>) rsp.getResponse().get(ShardParams.SHARDS_INFO);\n    String shards = getShardsString();\n    int cnt = StringUtils.countMatches(shards, \",\")+1;\n    \n    assertNotNull(\"missing shard info\", sinfo);\n    assertEquals(\"should have an entry for each shard [\"+sinfo+\"] \"+shards, cnt, sinfo.size());\n    \n    // test shards.tolerant=true\n    for(int numDownServers = 0; numDownServers < jettys.size()-1; numDownServers++)\n    {\n      List<JettySolrRunner> upJettys = new ArrayList<JettySolrRunner>(jettys);\n      List<SolrServer> upClients = new ArrayList<SolrServer>(clients);\n      List<JettySolrRunner> downJettys = new ArrayList<JettySolrRunner>();\n      List<String> upShards = new ArrayList<String>(Arrays.asList(shardsArr));\n      for(int i=0; i<numDownServers; i++)\n      {\n        // shut down some of the jettys\n        int indexToRemove = r.nextInt(upJettys.size());\n        JettySolrRunner downJetty = upJettys.remove(indexToRemove);\n        upClients.remove(indexToRemove);\n        upShards.remove(indexToRemove);\n        ChaosMonkey.stop(downJetty);\n        downJettys.add(downJetty);\n      }\n      \n      queryPartialResults(upShards, upClients, \"q\",\"*:*\",ShardParams.SHARDS_INFO,\"true\",ShardParams.SHARDS_TOLERANT,\"true\");\n      \n      // restart the jettys\n      for (JettySolrRunner downJetty : downJettys) {\n        downJetty.start();\n      }\n    }\n\n    // This index has the same number for every field\n    \n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // Thread.sleep(10000000000L);\n\n    purgeFieldCache(FieldCache.DEFAULT);   // avoid FC insanity\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"5da0b42730b6b99b31389ef94cb97384e83b9ede","date":1337107665,"type":3,"author":"Dawid Weiss","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/TestDistributedSearch#doTest().mjava","pathOld":"solr/core/src/test/org/apache/solr/TestDistributedSearch#doTest().mjava","sourceNew":"  @Override\n  public void doTest() throws Exception {\n    int backupStress = stress; // make a copy so we can restore\n\n\n    del(\"*:*\");\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\", \n           tdate_a, \"2010-04-20T11:00:00Z\",\n           tdate_b, \"2009-08-20T11:00:00Z\",\n           \"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\", \n           tdate_a, \"2010-05-02T11:00:00Z\",\n           tdate_b, \"2009-11-02T11:00:00Z\");\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\", \n           tdate_a, \"2010-05-03T11:00:00Z\");\n    indexr(id,4, i1, -100 ,tlong, 101,\n           t1,\"the quick fox jumped over the lazy dog\", \n           tdate_a, \"2010-05-03T11:00:00Z\",\n           tdate_b, \"2010-05-03T11:00:00Z\");\n    indexr(id,5, i1, 500, tlong, 500 ,\n           t1,\"the quick fox jumped way over the lazy dog\", \n           tdate_a, \"2010-05-05T11:00:00Z\");\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,\n           tdate_b, \"2010-01-05T11:00:00Z\",\n           t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n\n    commit();  // try to ensure there's more than one segment\n\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,\n           t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,\n           t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,\n           t1,\"no eggs on wall, lesson learned\", \n           oddField, \"odd man out\");\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n\n    handle.clear();\n    handle.put(\"QTime\", SKIPVAL);\n    handle.put(\"timestamp\", SKIPVAL);\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(\"q\",\"*:*\", \"sort\",f+\" desc\");\n      query(\"q\",\"*:*\", \"sort\",f+\" asc\");\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",\"{!func}testfunc(add(\"+i1+\",5))\"+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" asc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\");\n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"*,score\"); \n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 desc\");\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"{!func}\"+i1);// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(\"q\",\"{!func}\"+i1, \"fl\",\"*,score\");  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"quick\");\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\");\n    query(\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\");  // no fields in returned docs\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\");\n\n    handle.put(\"score\", SKIPVAL);\n    query(\"q\",\"quick\",\"fl\",\"*,score\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\");\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"matchesnothing\",\"fl\",\"*,score\");  \n\n    // test that a single NOW value is propagated to all shards... if that is true\n    // then the primary sort should always be a tie and then the secondary should always decide\n    query(\"q\",\"{!func}ms(NOW)\", \"sort\",\"score desc,\"+i1+\" desc\",\"fl\",\"id\");    \n\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\");\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2);\n\n    // a facet query to test out chars out of the ascii range\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!term f=foo_s}international\\u00ff\\u01ff\\u2222\\u3333\");\n\n    // simple date facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date.other\", \"all\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // date facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date\",tdate_b, \n          \"facet.date.other\", \"all\", \n          \"f.\"+tdate_b+\".facet.date.start\",\"2009-05-01T11:00:00Z\", \n          \"f.\"+tdate_b+\".facet.date.gap\",\"+3MONTHS\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // simple range facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"facet.range.end\",900);\n\n    // range facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range\",i1, \n          \"f.\"+i1+\".facet.range.start\",300, \n          \"f.\"+i1+\".facet.range.gap\",87, \n          \"facet.range.end\",900,\n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"f.\"+tlong+\".facet.range.end\",900);\n    \n    //  variations of fl\n    query(\"q\",\"*:*\", \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1 + \",score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", i1, \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id,\" + i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1, \"fl\", \"id\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",nint, \"fl\",tint,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",nint, \"fl\", \"id\", \"fl\",tint,\"sort\",i1 + \" desc\");\n\n    stress=0;  // turn off stress... we want to tex max combos in min time\n    for (int i=0; i<25*RANDOM_MULTIPLIER; i++) {\n      String f = fieldNames[random().nextInt(fieldNames.length)];\n      if (random().nextBoolean()) f = t1;  // the text field is a really interesting one to facet on (and it's multi-valued too)\n\n      // we want a random query and not just *:* so we'll get zero counts in facets also\n      // TODO: do a better random query\n      String q = random().nextBoolean() ? \"*:*\" : \"id:(1 3 5 7 9 11 13) OR id:[100 TO \" + random().nextInt(50) + \"]\";\n\n      int nolimit = random().nextBoolean() ? -1 : 10000;  // these should be equivalent\n\n      // if limit==-1, we should always get exact matches\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"count\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      // for index sort, we should get exact results for mincount <= 1\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(2), \"facet.offset\",random().nextInt(10), \"facet.limit\",random().nextInt(11)-1);\n    }\n    stress = backupStress;  // restore stress\n\n    // test faceting multiple things at once\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1);\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id:[1 TO 7]\", \"fq\",\"{!tag=b}id:[3 TO 9]\"\n    );\n    query(\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\");\n\n    // test field that is valid in schema but missing in all shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2);\n    // test field that is valid in schema and missing in some shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2);\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1);\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    // check a complex key name\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"*:*\", \"rows\",100);\n    }\n\n    //SOLR 3161 ensure shards.qt=/update fails (anything but search handler really)\n    // Also see TestRemoteStreaming#testQtUpdateFails()\n    try {\n      ignoreException(\"isShard is only acceptable\");\n      // query(\"q\",\"*:*\",\"shards.qt\",\"/update\",\"stream.body\",\"<delete><query>*:*</query></delete>\");\n      // fail();\n    } catch (SolrException e) {\n      //expected\n    }\n    unIgnoreException(\"isShard is only acceptable\");\n\n    // test debugging\n    handle.put(\"explain\", UNORDERED);\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY);\n\n    // Check Info is added to for each shard\n    ModifiableSolrParams q = new ModifiableSolrParams();\n    q.set(\"q\", \"*:*\");\n    q.set(ShardParams.SHARDS_INFO, true);\n    setDistributedParams(q);\n    QueryResponse rsp = queryServer(q);\n    NamedList<?> sinfo = (NamedList<?>) rsp.getResponse().get(ShardParams.SHARDS_INFO);\n    String shards = getShardsString();\n    int cnt = StringUtils.countMatches(shards, \",\")+1;\n    \n    assertNotNull(\"missing shard info\", sinfo);\n    assertEquals(\"should have an entry for each shard [\"+sinfo+\"] \"+shards, cnt, sinfo.size());\n    \n    // test shards.tolerant=true\n    for(int numDownServers = 0; numDownServers < jettys.size()-1; numDownServers++)\n    {\n      List<JettySolrRunner> upJettys = new ArrayList<JettySolrRunner>(jettys);\n      List<SolrServer> upClients = new ArrayList<SolrServer>(clients);\n      List<JettySolrRunner> downJettys = new ArrayList<JettySolrRunner>();\n      List<String> upShards = new ArrayList<String>(Arrays.asList(shardsArr));\n      for(int i=0; i<numDownServers; i++)\n      {\n        // shut down some of the jettys\n        int indexToRemove = r.nextInt(upJettys.size());\n        JettySolrRunner downJetty = upJettys.remove(indexToRemove);\n        upClients.remove(indexToRemove);\n        upShards.remove(indexToRemove);\n        ChaosMonkey.stop(downJetty);\n        downJettys.add(downJetty);\n      }\n      \n      queryPartialResults(upShards, upClients, \"q\",\"*:*\",ShardParams.SHARDS_INFO,\"true\",ShardParams.SHARDS_TOLERANT,\"true\");\n      \n      // restart the jettys\n      for (JettySolrRunner downJetty : downJettys) {\n        downJetty.start();\n      }\n    }\n\n    // This index has the same number for every field\n    \n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // Thread.sleep(10000000000L);\n\n    FieldCache.DEFAULT.purgeAllCaches();   // avoid FC insanity\n  }\n\n","sourceOld":"  @Override\n  public void doTest() throws Exception {\n    int backupStress = stress; // make a copy so we can restore\n\n\n    del(\"*:*\");\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\", \n           tdate_a, \"2010-04-20T11:00:00Z\",\n           tdate_b, \"2009-08-20T11:00:00Z\",\n           \"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\", \n           tdate_a, \"2010-05-02T11:00:00Z\",\n           tdate_b, \"2009-11-02T11:00:00Z\");\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\", \n           tdate_a, \"2010-05-03T11:00:00Z\");\n    indexr(id,4, i1, -100 ,tlong, 101,\n           t1,\"the quick fox jumped over the lazy dog\", \n           tdate_a, \"2010-05-03T11:00:00Z\",\n           tdate_b, \"2010-05-03T11:00:00Z\");\n    indexr(id,5, i1, 500, tlong, 500 ,\n           t1,\"the quick fox jumped way over the lazy dog\", \n           tdate_a, \"2010-05-05T11:00:00Z\");\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,\n           tdate_b, \"2010-01-05T11:00:00Z\",\n           t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n\n    commit();  // try to ensure there's more than one segment\n\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,\n           t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,\n           t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,\n           t1,\"no eggs on wall, lesson learned\", \n           oddField, \"odd man out\");\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n\n    handle.clear();\n    handle.put(\"QTime\", SKIPVAL);\n    handle.put(\"timestamp\", SKIPVAL);\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(\"q\",\"*:*\", \"sort\",f+\" desc\");\n      query(\"q\",\"*:*\", \"sort\",f+\" asc\");\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",\"{!func}testfunc(add(\"+i1+\",5))\"+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" asc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\");\n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"*,score\"); \n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 desc\");\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"{!func}\"+i1);// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(\"q\",\"{!func}\"+i1, \"fl\",\"*,score\");  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"quick\");\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\");\n    query(\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\");  // no fields in returned docs\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\");\n\n    handle.put(\"score\", SKIPVAL);\n    query(\"q\",\"quick\",\"fl\",\"*,score\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\");\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"matchesnothing\",\"fl\",\"*,score\");  \n\n    // test that a single NOW value is propagated to all shards... if that is true\n    // then the primary sort should always be a tie and then the secondary should always decide\n    query(\"q\",\"{!func}ms(NOW)\", \"sort\",\"score desc,\"+i1+\" desc\",\"fl\",\"id\");    \n\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\");\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2);\n\n    // a facet query to test out chars out of the ascii range\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!term f=foo_s}international\\u00ff\\u01ff\\u2222\\u3333\");\n\n    // simple date facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date.other\", \"all\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // date facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date\",tdate_b, \n          \"facet.date.other\", \"all\", \n          \"f.\"+tdate_b+\".facet.date.start\",\"2009-05-01T11:00:00Z\", \n          \"f.\"+tdate_b+\".facet.date.gap\",\"+3MONTHS\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // simple range facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"facet.range.end\",900);\n\n    // range facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range\",i1, \n          \"f.\"+i1+\".facet.range.start\",300, \n          \"f.\"+i1+\".facet.range.gap\",87, \n          \"facet.range.end\",900,\n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"f.\"+tlong+\".facet.range.end\",900);\n    \n    //  variations of fl\n    query(\"q\",\"*:*\", \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1 + \",score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", i1, \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id,\" + i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1, \"fl\", \"id\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",nint, \"fl\",tint,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",nint, \"fl\", \"id\", \"fl\",tint,\"sort\",i1 + \" desc\");\n\n    stress=0;  // turn off stress... we want to tex max combos in min time\n    for (int i=0; i<25*RANDOM_MULTIPLIER; i++) {\n      String f = fieldNames[random().nextInt(fieldNames.length)];\n      if (random().nextBoolean()) f = t1;  // the text field is a really interesting one to facet on (and it's multi-valued too)\n\n      // we want a random query and not just *:* so we'll get zero counts in facets also\n      // TODO: do a better random query\n      String q = random().nextBoolean() ? \"*:*\" : \"id:(1 3 5 7 9 11 13) OR id:[100 TO \" + random().nextInt(50) + \"]\";\n\n      int nolimit = random().nextBoolean() ? -1 : 10000;  // these should be equivalent\n\n      // if limit==-1, we should always get exact matches\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"count\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      // for index sort, we should get exact results for mincount <= 1\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(2), \"facet.offset\",random().nextInt(10), \"facet.limit\",random().nextInt(11)-1);\n    }\n    stress = backupStress;  // restore stress\n\n    // test faceting multiple things at once\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1);\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id:[1 TO 7]\", \"fq\",\"{!tag=b}id:[3 TO 9]\"\n    );\n    query(\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\");\n\n    // test field that is valid in schema but missing in all shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2);\n    // test field that is valid in schema and missing in some shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2);\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1);\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    // check a complex key name\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"*:*\", \"rows\",100);\n    }\n\n    //SOLR 3161 ensure shards.qt=/update fails (anything but search handler really)\n    // Also see TestRemoteStreaming#testQtUpdateFails()\n    try {\n      ignoreException(\"isShard is only acceptable\");\n      // query(\"q\",\"*:*\",\"shards.qt\",\"/update\",\"stream.body\",\"<delete><query>*:*</query></delete>\");\n      // fail();\n    } catch (SolrException e) {\n      //expected\n    }\n    unIgnoreException(\"isShard is only acceptable\");\n\n    // test debugging\n    handle.put(\"explain\", UNORDERED);\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY);\n\n    // Check Info is added to for each shard\n    ModifiableSolrParams q = new ModifiableSolrParams();\n    q.set(\"q\", \"*:*\");\n    q.set(ShardParams.SHARDS_INFO, true);\n    setDistributedParams(q);\n    QueryResponse rsp = queryServer(q);\n    NamedList<?> sinfo = (NamedList<?>) rsp.getResponse().get(ShardParams.SHARDS_INFO);\n    String shards = getShardsString();\n    int cnt = StringUtils.countMatches(shards, \",\")+1;\n    \n    assertNotNull(\"missing shard info\", sinfo);\n    assertEquals(\"should have an entry for each shard [\"+sinfo+\"] \"+shards, cnt, sinfo.size());\n    \n    // test shards.tolerant=true\n    for(int numDownServers = 0; numDownServers < jettys.size()-1; numDownServers++)\n    {\n      List<JettySolrRunner> upJettys = new ArrayList<JettySolrRunner>(jettys);\n      List<SolrServer> upClients = new ArrayList<SolrServer>(clients);\n      List<JettySolrRunner> downJettys = new ArrayList<JettySolrRunner>();\n      List<String> upShards = new ArrayList<String>(Arrays.asList(shardsArr));\n      for(int i=0; i<numDownServers; i++)\n      {\n        // shut down some of the jettys\n        int indexToRemove = r.nextInt(upJettys.size());\n        JettySolrRunner downJetty = upJettys.remove(indexToRemove);\n        upClients.remove(indexToRemove);\n        upShards.remove(indexToRemove);\n        ChaosMonkey.stop(downJetty);\n        downJettys.add(downJetty);\n      }\n      \n      queryPartialResults(upShards, upClients, \"q\",\"*:*\",ShardParams.SHARDS_INFO,\"true\",ShardParams.SHARDS_TOLERANT,\"true\");\n      \n      // restart the jettys\n      for (JettySolrRunner downJetty : downJettys) {\n        downJetty.start();\n      }\n    }\n\n    // This index has the same number for every field\n    \n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // Thread.sleep(10000000000L);\n\n    purgeFieldCache(FieldCache.DEFAULT);   // avoid FC insanity\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"88dcbe1d36c9d50525f58425024e87783c4005ab","date":1340729054,"type":3,"author":"Ryan McKinley","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/TestDistributedSearch#doTest().mjava","pathOld":"solr/core/src/test/org/apache/solr/TestDistributedSearch#doTest().mjava","sourceNew":"  @Override\n  public void doTest() throws Exception {\n    int backupStress = stress; // make a copy so we can restore\n\n\n    del(\"*:*\");\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\", \n           tdate_a, \"2010-04-20T11:00:00Z\",\n           tdate_b, \"2009-08-20T11:00:00Z\",\n           \"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\", \n           tdate_a, \"2010-05-02T11:00:00Z\",\n           tdate_b, \"2009-11-02T11:00:00Z\");\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\", \n           tdate_a, \"2010-05-03T11:00:00Z\");\n    indexr(id,4, i1, -100 ,tlong, 101,\n           t1,\"the quick fox jumped over the lazy dog\", \n           tdate_a, \"2010-05-03T11:00:00Z\",\n           tdate_b, \"2010-05-03T11:00:00Z\");\n    indexr(id,5, i1, 500, tlong, 500 ,\n           t1,\"the quick fox jumped way over the lazy dog\", \n           tdate_a, \"2010-05-05T11:00:00Z\");\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,\n           tdate_b, \"2010-01-05T11:00:00Z\",\n           t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n\n    commit();  // try to ensure there's more than one segment\n\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,\n           t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,\n           t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,\n           t1,\"no eggs on wall, lesson learned\", \n           oddField, \"odd man out\");\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n\n    handle.clear();\n    handle.put(\"QTime\", SKIPVAL);\n    handle.put(\"timestamp\", SKIPVAL);\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(\"q\",\"*:*\", \"sort\",f+\" desc\");\n      query(\"q\",\"*:*\", \"sort\",f+\" asc\");\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",\"{!func}testfunc(add(\"+i1+\",5))\"+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" asc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\");\n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"*,score\"); \n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 desc\");\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"{!func}\"+i1);// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(\"q\",\"{!func}\"+i1, \"fl\",\"*,score\");  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"quick\");\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\");\n    query(\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\");  // no fields in returned docs\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\");\n\n    handle.put(\"score\", SKIPVAL);\n    query(\"q\",\"quick\",\"fl\",\"*,score\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\");\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"matchesnothing\",\"fl\",\"*,score\");  \n\n    // test that a single NOW value is propagated to all shards... if that is true\n    // then the primary sort should always be a tie and then the secondary should always decide\n    query(\"q\",\"{!func}ms(NOW)\", \"sort\",\"score desc,\"+i1+\" desc\",\"fl\",\"id\");    \n\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\");\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2);\n\n    // a facet query to test out chars out of the ascii range\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!term f=foo_s}international\\u00ff\\u01ff\\u2222\\u3333\");\n\n    // simple date facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date.other\", \"all\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // date facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date\",tdate_b, \n          \"facet.date.other\", \"all\", \n          \"f.\"+tdate_b+\".facet.date.start\",\"2009-05-01T11:00:00Z\", \n          \"f.\"+tdate_b+\".facet.date.gap\",\"+3MONTHS\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // simple range facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"facet.range.end\",900);\n\n    // range facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range\",i1, \n          \"f.\"+i1+\".facet.range.start\",300, \n          \"f.\"+i1+\".facet.range.gap\",87, \n          \"facet.range.end\",900,\n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"f.\"+tlong+\".facet.range.end\",900);\n    \n    //  variations of fl\n    query(\"q\",\"*:*\", \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1 + \",score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", i1, \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id,\" + i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1, \"fl\", \"id\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",nint, \"fl\",tint,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",nint, \"fl\", \"id\", \"fl\",tint,\"sort\",i1 + \" desc\");\n\n    stress=0;  // turn off stress... we want to tex max combos in min time\n    for (int i=0; i<25*RANDOM_MULTIPLIER; i++) {\n      String f = fieldNames[random().nextInt(fieldNames.length)];\n      if (random().nextBoolean()) f = t1;  // the text field is a really interesting one to facet on (and it's multi-valued too)\n\n      // we want a random query and not just *:* so we'll get zero counts in facets also\n      // TODO: do a better random query\n      String q = random().nextBoolean() ? \"*:*\" : \"id:(1 3 5 7 9 11 13) OR id:[100 TO \" + random().nextInt(50) + \"]\";\n\n      int nolimit = random().nextBoolean() ? -1 : 10000;  // these should be equivalent\n\n      // if limit==-1, we should always get exact matches\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"count\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      // for index sort, we should get exact results for mincount <= 1\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(2), \"facet.offset\",random().nextInt(10), \"facet.limit\",random().nextInt(11)-1);\n    }\n    stress = backupStress;  // restore stress\n\n    // test faceting multiple things at once\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1);\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id:[1 TO 7]\", \"fq\",\"{!tag=b}id:[3 TO 9]\"\n    );\n    query(\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\");\n\n    // test field that is valid in schema but missing in all shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2);\n    // test field that is valid in schema and missing in some shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2);\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1);\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    // check a complex key name\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"*:*\", \"rows\",100);\n    }\n\n    //SOLR 3161 ensure shards.qt=/update fails (anything but search handler really)\n    // Also see TestRemoteStreaming#testQtUpdateFails()\n    try {\n      ignoreException(\"isShard is only acceptable\");\n      // query(\"q\",\"*:*\",\"shards.qt\",\"/update\",\"stream.body\",\"<delete><query>*:*</query></delete>\");\n      // fail();\n    } catch (SolrException e) {\n      //expected\n    }\n    unIgnoreException(\"isShard is only acceptable\");\n\n    // test debugging\n    handle.put(\"explain\", UNORDERED);\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY);\n\n    // Check Info is added to for each shard\n    ModifiableSolrParams q = new ModifiableSolrParams();\n    q.set(\"q\", \"*:*\");\n    q.set(ShardParams.SHARDS_INFO, true);\n    setDistributedParams(q);\n    QueryResponse rsp = queryServer(q);\n    NamedList<?> sinfo = (NamedList<?>) rsp.getResponse().get(ShardParams.SHARDS_INFO);\n    String shards = getShardsString();\n    int cnt = StringUtils.countMatches(shards, \",\")+1;\n    \n    assertNotNull(\"missing shard info\", sinfo);\n    assertEquals(\"should have an entry for each shard [\"+sinfo+\"] \"+shards, cnt, sinfo.size());\n    \n    // test shards.tolerant=true\n    for(int numDownServers = 0; numDownServers < jettys.size()-1; numDownServers++)\n    {\n      List<JettySolrRunner> upJettys = new ArrayList<JettySolrRunner>(jettys);\n      List<SolrServer> upClients = new ArrayList<SolrServer>(clients);\n      List<JettySolrRunner> downJettys = new ArrayList<JettySolrRunner>();\n      List<String> upShards = new ArrayList<String>(Arrays.asList(shardsArr));\n      for(int i=0; i<numDownServers; i++)\n      {\n        // shut down some of the jettys\n        int indexToRemove = r.nextInt(upJettys.size());\n        JettySolrRunner downJetty = upJettys.remove(indexToRemove);\n        upClients.remove(indexToRemove);\n        upShards.remove(indexToRemove);\n        ChaosMonkey.stop(downJetty);\n        downJettys.add(downJetty);\n      }\n      \n      queryPartialResults(upShards, upClients, \n          \"q\",\"*:*\",\n          \"facet\",\"true\", \n          \"facet.field\",t1,\n          \"facet.limit\",5,\n          ShardParams.SHARDS_INFO,\"true\",\n          ShardParams.SHARDS_TOLERANT,\"true\");\n      \n      // restart the jettys\n      for (JettySolrRunner downJetty : downJettys) {\n        downJetty.start();\n      }\n    }\n\n    // This index has the same number for every field\n    \n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // Thread.sleep(10000000000L);\n\n    FieldCache.DEFAULT.purgeAllCaches();   // avoid FC insanity\n  }\n\n","sourceOld":"  @Override\n  public void doTest() throws Exception {\n    int backupStress = stress; // make a copy so we can restore\n\n\n    del(\"*:*\");\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\", \n           tdate_a, \"2010-04-20T11:00:00Z\",\n           tdate_b, \"2009-08-20T11:00:00Z\",\n           \"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\", \n           tdate_a, \"2010-05-02T11:00:00Z\",\n           tdate_b, \"2009-11-02T11:00:00Z\");\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\", \n           tdate_a, \"2010-05-03T11:00:00Z\");\n    indexr(id,4, i1, -100 ,tlong, 101,\n           t1,\"the quick fox jumped over the lazy dog\", \n           tdate_a, \"2010-05-03T11:00:00Z\",\n           tdate_b, \"2010-05-03T11:00:00Z\");\n    indexr(id,5, i1, 500, tlong, 500 ,\n           t1,\"the quick fox jumped way over the lazy dog\", \n           tdate_a, \"2010-05-05T11:00:00Z\");\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,\n           tdate_b, \"2010-01-05T11:00:00Z\",\n           t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n\n    commit();  // try to ensure there's more than one segment\n\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,\n           t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,\n           t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,\n           t1,\"no eggs on wall, lesson learned\", \n           oddField, \"odd man out\");\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n\n    handle.clear();\n    handle.put(\"QTime\", SKIPVAL);\n    handle.put(\"timestamp\", SKIPVAL);\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(\"q\",\"*:*\", \"sort\",f+\" desc\");\n      query(\"q\",\"*:*\", \"sort\",f+\" asc\");\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",\"{!func}testfunc(add(\"+i1+\",5))\"+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" asc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\");\n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"*,score\"); \n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 desc\");\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"{!func}\"+i1);// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(\"q\",\"{!func}\"+i1, \"fl\",\"*,score\");  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"quick\");\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\");\n    query(\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\");  // no fields in returned docs\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\");\n\n    handle.put(\"score\", SKIPVAL);\n    query(\"q\",\"quick\",\"fl\",\"*,score\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\");\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"matchesnothing\",\"fl\",\"*,score\");  \n\n    // test that a single NOW value is propagated to all shards... if that is true\n    // then the primary sort should always be a tie and then the secondary should always decide\n    query(\"q\",\"{!func}ms(NOW)\", \"sort\",\"score desc,\"+i1+\" desc\",\"fl\",\"id\");    \n\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\");\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2);\n\n    // a facet query to test out chars out of the ascii range\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!term f=foo_s}international\\u00ff\\u01ff\\u2222\\u3333\");\n\n    // simple date facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date.other\", \"all\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // date facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date\",tdate_b, \n          \"facet.date.other\", \"all\", \n          \"f.\"+tdate_b+\".facet.date.start\",\"2009-05-01T11:00:00Z\", \n          \"f.\"+tdate_b+\".facet.date.gap\",\"+3MONTHS\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // simple range facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"facet.range.end\",900);\n\n    // range facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range\",i1, \n          \"f.\"+i1+\".facet.range.start\",300, \n          \"f.\"+i1+\".facet.range.gap\",87, \n          \"facet.range.end\",900,\n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"f.\"+tlong+\".facet.range.end\",900);\n    \n    //  variations of fl\n    query(\"q\",\"*:*\", \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1 + \",score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", i1, \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id,\" + i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1, \"fl\", \"id\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",nint, \"fl\",tint,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",nint, \"fl\", \"id\", \"fl\",tint,\"sort\",i1 + \" desc\");\n\n    stress=0;  // turn off stress... we want to tex max combos in min time\n    for (int i=0; i<25*RANDOM_MULTIPLIER; i++) {\n      String f = fieldNames[random().nextInt(fieldNames.length)];\n      if (random().nextBoolean()) f = t1;  // the text field is a really interesting one to facet on (and it's multi-valued too)\n\n      // we want a random query and not just *:* so we'll get zero counts in facets also\n      // TODO: do a better random query\n      String q = random().nextBoolean() ? \"*:*\" : \"id:(1 3 5 7 9 11 13) OR id:[100 TO \" + random().nextInt(50) + \"]\";\n\n      int nolimit = random().nextBoolean() ? -1 : 10000;  // these should be equivalent\n\n      // if limit==-1, we should always get exact matches\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"count\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      // for index sort, we should get exact results for mincount <= 1\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(2), \"facet.offset\",random().nextInt(10), \"facet.limit\",random().nextInt(11)-1);\n    }\n    stress = backupStress;  // restore stress\n\n    // test faceting multiple things at once\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1);\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id:[1 TO 7]\", \"fq\",\"{!tag=b}id:[3 TO 9]\"\n    );\n    query(\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\");\n\n    // test field that is valid in schema but missing in all shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2);\n    // test field that is valid in schema and missing in some shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2);\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1);\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    // check a complex key name\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"*:*\", \"rows\",100);\n    }\n\n    //SOLR 3161 ensure shards.qt=/update fails (anything but search handler really)\n    // Also see TestRemoteStreaming#testQtUpdateFails()\n    try {\n      ignoreException(\"isShard is only acceptable\");\n      // query(\"q\",\"*:*\",\"shards.qt\",\"/update\",\"stream.body\",\"<delete><query>*:*</query></delete>\");\n      // fail();\n    } catch (SolrException e) {\n      //expected\n    }\n    unIgnoreException(\"isShard is only acceptable\");\n\n    // test debugging\n    handle.put(\"explain\", UNORDERED);\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY);\n\n    // Check Info is added to for each shard\n    ModifiableSolrParams q = new ModifiableSolrParams();\n    q.set(\"q\", \"*:*\");\n    q.set(ShardParams.SHARDS_INFO, true);\n    setDistributedParams(q);\n    QueryResponse rsp = queryServer(q);\n    NamedList<?> sinfo = (NamedList<?>) rsp.getResponse().get(ShardParams.SHARDS_INFO);\n    String shards = getShardsString();\n    int cnt = StringUtils.countMatches(shards, \",\")+1;\n    \n    assertNotNull(\"missing shard info\", sinfo);\n    assertEquals(\"should have an entry for each shard [\"+sinfo+\"] \"+shards, cnt, sinfo.size());\n    \n    // test shards.tolerant=true\n    for(int numDownServers = 0; numDownServers < jettys.size()-1; numDownServers++)\n    {\n      List<JettySolrRunner> upJettys = new ArrayList<JettySolrRunner>(jettys);\n      List<SolrServer> upClients = new ArrayList<SolrServer>(clients);\n      List<JettySolrRunner> downJettys = new ArrayList<JettySolrRunner>();\n      List<String> upShards = new ArrayList<String>(Arrays.asList(shardsArr));\n      for(int i=0; i<numDownServers; i++)\n      {\n        // shut down some of the jettys\n        int indexToRemove = r.nextInt(upJettys.size());\n        JettySolrRunner downJetty = upJettys.remove(indexToRemove);\n        upClients.remove(indexToRemove);\n        upShards.remove(indexToRemove);\n        ChaosMonkey.stop(downJetty);\n        downJettys.add(downJetty);\n      }\n      \n      queryPartialResults(upShards, upClients, \"q\",\"*:*\",ShardParams.SHARDS_INFO,\"true\",ShardParams.SHARDS_TOLERANT,\"true\");\n      \n      // restart the jettys\n      for (JettySolrRunner downJetty : downJettys) {\n        downJetty.start();\n      }\n    }\n\n    // This index has the same number for every field\n    \n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // Thread.sleep(10000000000L);\n\n    FieldCache.DEFAULT.purgeAllCaches();   // avoid FC insanity\n  }\n\n","bugFix":null,"bugIntro":["bb222a3f9d9421d5c95afce73013fbd8de07ea1f"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"fe33227f6805edab2036cbb80645cc4e2d1fa424","date":1342713534,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/TestDistributedSearch#doTest().mjava","pathOld":"solr/core/src/test/org/apache/solr/TestDistributedSearch#doTest().mjava","sourceNew":"  @Override\n  public void doTest() throws Exception {\n    int backupStress = stress; // make a copy so we can restore\n\n\n    del(\"*:*\");\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\", \n           tdate_a, \"2010-04-20T11:00:00Z\",\n           tdate_b, \"2009-08-20T11:00:00Z\",\n           \"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\", \n           tdate_a, \"2010-05-02T11:00:00Z\",\n           tdate_b, \"2009-11-02T11:00:00Z\");\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\", \n           tdate_a, \"2010-05-03T11:00:00Z\");\n    indexr(id,4, i1, -100 ,tlong, 101,\n           t1,\"the quick fox jumped over the lazy dog\", \n           tdate_a, \"2010-05-03T11:00:00Z\",\n           tdate_b, \"2010-05-03T11:00:00Z\");\n    indexr(id,5, i1, 500, tlong, 500 ,\n           t1,\"the quick fox jumped way over the lazy dog\", \n           tdate_a, \"2010-05-05T11:00:00Z\");\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,\n           tdate_b, \"2010-01-05T11:00:00Z\",\n           t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n\n    commit();  // try to ensure there's more than one segment\n\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,\n           t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,\n           t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,\n           t1,\"no eggs on wall, lesson learned\", \n           oddField, \"odd man out\");\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n\n    handle.clear();\n    handle.put(\"QTime\", SKIPVAL);\n    handle.put(\"timestamp\", SKIPVAL);\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(\"q\",\"*:*\", \"sort\",f+\" desc\");\n      query(\"q\",\"*:*\", \"sort\",f+\" asc\");\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",\"{!func}testfunc(add(\"+i1+\",5))\"+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" asc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\");\n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"*,score\"); \n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 desc\");\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"{!func}\"+i1);// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(\"q\",\"{!func}\"+i1, \"fl\",\"*,score\");  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"quick\");\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\");\n    query(\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\");  // no fields in returned docs\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\");\n\n    handle.put(\"score\", SKIPVAL);\n    query(\"q\",\"quick\",\"fl\",\"*,score\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\");\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"matchesnothing\",\"fl\",\"*,score\");  \n\n    // test that a single NOW value is propagated to all shards... if that is true\n    // then the primary sort should always be a tie and then the secondary should always decide\n    query(\"q\",\"{!func}ms(NOW)\", \"sort\",\"score desc,\"+i1+\" desc\",\"fl\",\"id\");    \n\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\");\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2);\n\n    // a facet query to test out chars out of the ascii range\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!term f=foo_s}international\\u00ff\\u01ff\\u2222\\u3333\");\n\n    // simple date facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date.other\", \"all\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // date facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date\",tdate_b, \n          \"facet.date.other\", \"all\", \n          \"f.\"+tdate_b+\".facet.date.start\",\"2009-05-01T11:00:00Z\", \n          \"f.\"+tdate_b+\".facet.date.gap\",\"+3MONTHS\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // simple range facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"facet.range.end\",900);\n\n    // range facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range\",i1, \n          \"f.\"+i1+\".facet.range.start\",300, \n          \"f.\"+i1+\".facet.range.gap\",87, \n          \"facet.range.end\",900,\n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"f.\"+tlong+\".facet.range.end\",900);\n    \n    //  variations of fl\n    query(\"q\",\"*:*\", \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1 + \",score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", i1, \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id,\" + i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1, \"fl\", \"id\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",nint, \"fl\",tint,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",nint, \"fl\", \"id\", \"fl\",tint,\"sort\",i1 + \" desc\");\n\n    stress=0;  // turn off stress... we want to tex max combos in min time\n    for (int i=0; i<25*RANDOM_MULTIPLIER; i++) {\n      String f = fieldNames[random().nextInt(fieldNames.length)];\n      if (random().nextBoolean()) f = t1;  // the text field is a really interesting one to facet on (and it's multi-valued too)\n\n      // we want a random query and not just *:* so we'll get zero counts in facets also\n      // TODO: do a better random query\n      String q = random().nextBoolean() ? \"*:*\" : \"id:(1 3 5 7 9 11 13) OR id:[100 TO \" + random().nextInt(50) + \"]\";\n\n      int nolimit = random().nextBoolean() ? -1 : 10000;  // these should be equivalent\n\n      // if limit==-1, we should always get exact matches\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"count\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      // for index sort, we should get exact results for mincount <= 1\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(2), \"facet.offset\",random().nextInt(10), \"facet.limit\",random().nextInt(11)-1);\n    }\n    stress = backupStress;  // restore stress\n\n    // test faceting multiple things at once\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1);\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id:[1 TO 7]\", \"fq\",\"{!tag=b}id:[3 TO 9]\"\n    );\n    query(\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\");\n\n    // test field that is valid in schema but missing in all shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2);\n    // test field that is valid in schema and missing in some shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2);\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1);\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    // check a complex key name\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"*:*\", \"rows\",100);\n    }\n\n    //SOLR 3161 ensure shards.qt=/update fails (anything but search handler really)\n    // Also see TestRemoteStreaming#testQtUpdateFails()\n    try {\n      ignoreException(\"isShard is only acceptable\");\n      // query(\"q\",\"*:*\",\"shards.qt\",\"/update\",\"stream.body\",\"<delete><query>*:*</query></delete>\");\n      // fail();\n    } catch (SolrException e) {\n      //expected\n    }\n    unIgnoreException(\"isShard is only acceptable\");\n\n    // test debugging\n    handle.put(\"explain\", UNORDERED);\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY);\n\n    // Check Info is added to for each shard\n    ModifiableSolrParams q = new ModifiableSolrParams();\n    q.set(\"q\", \"*:*\");\n    q.set(ShardParams.SHARDS_INFO, true);\n    setDistributedParams(q);\n    QueryResponse rsp = queryServer(q);\n    NamedList<?> sinfo = (NamedList<?>) rsp.getResponse().get(ShardParams.SHARDS_INFO);\n    String shards = getShardsString();\n    int cnt = StringUtils.countMatches(shards, \",\")+1;\n    \n    assertNotNull(\"missing shard info\", sinfo);\n    assertEquals(\"should have an entry for each shard [\"+sinfo+\"] \"+shards, cnt, sinfo.size());\n    \n    // test shards.tolerant=true\n    for(int numDownServers = 0; numDownServers < jettys.size()-1; numDownServers++)\n    {\n      List<JettySolrRunner> upJettys = new ArrayList<JettySolrRunner>(jettys);\n      List<SolrServer> upClients = new ArrayList<SolrServer>(clients);\n      List<JettySolrRunner> downJettys = new ArrayList<JettySolrRunner>();\n      List<String> upShards = new ArrayList<String>(Arrays.asList(shardsArr));\n      for(int i=0; i<numDownServers; i++)\n      {\n        // shut down some of the jettys\n        int indexToRemove = r.nextInt(upJettys.size());\n        JettySolrRunner downJetty = upJettys.remove(indexToRemove);\n        upClients.remove(indexToRemove);\n        upShards.remove(indexToRemove);\n        ChaosMonkey.stop(downJetty);\n        downJettys.add(downJetty);\n      }\n      \n      queryPartialResults(upShards, upClients, \n          \"q\",\"*:*\",\n          \"facet\",\"true\", \n          \"facet.field\",t1,\n          \"facet.limit\",5,\n          ShardParams.SHARDS_INFO,\"true\",\n          ShardParams.SHARDS_TOLERANT,\"true\");\n      \n      // restart the jettys\n      for (JettySolrRunner downJetty : downJettys) {\n        downJetty.start();\n      }\n    }\n\n    // This index has the same number for every field\n    \n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // Thread.sleep(10000000000L);\n\n    FieldCache.DEFAULT.purgeAllCaches();   // avoid FC insanity\n  }\n\n","sourceOld":"  @Override\n  public void doTest() throws Exception {\n    int backupStress = stress; // make a copy so we can restore\n\n\n    del(\"*:*\");\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\", \n           tdate_a, \"2010-04-20T11:00:00Z\",\n           tdate_b, \"2009-08-20T11:00:00Z\",\n           \"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\", \n           tdate_a, \"2010-05-02T11:00:00Z\",\n           tdate_b, \"2009-11-02T11:00:00Z\");\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\", \n           tdate_a, \"2010-05-03T11:00:00Z\");\n    indexr(id,4, i1, -100 ,tlong, 101,\n           t1,\"the quick fox jumped over the lazy dog\", \n           tdate_a, \"2010-05-03T11:00:00Z\",\n           tdate_b, \"2010-05-03T11:00:00Z\");\n    indexr(id,5, i1, 500, tlong, 500 ,\n           t1,\"the quick fox jumped way over the lazy dog\", \n           tdate_a, \"2010-05-05T11:00:00Z\");\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,\n           tdate_b, \"2010-01-05T11:00:00Z\",\n           t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n\n    commit();  // try to ensure there's more than one segment\n\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,\n           t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,\n           t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,\n           t1,\"no eggs on wall, lesson learned\", \n           oddField, \"odd man out\");\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n\n    handle.clear();\n    handle.put(\"QTime\", SKIPVAL);\n    handle.put(\"timestamp\", SKIPVAL);\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(\"q\",\"*:*\", \"sort\",f+\" desc\");\n      query(\"q\",\"*:*\", \"sort\",f+\" asc\");\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",\"{!func}testfunc(add(\"+i1+\",5))\"+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" asc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\");\n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"*,score\"); \n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 desc\");\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"{!func}\"+i1);// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(\"q\",\"{!func}\"+i1, \"fl\",\"*,score\");  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"quick\");\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\");\n    query(\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\");  // no fields in returned docs\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\");\n\n    handle.put(\"score\", SKIPVAL);\n    query(\"q\",\"quick\",\"fl\",\"*,score\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\");\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"matchesnothing\",\"fl\",\"*,score\");  \n\n    // test that a single NOW value is propagated to all shards... if that is true\n    // then the primary sort should always be a tie and then the secondary should always decide\n    query(\"q\",\"{!func}ms(NOW)\", \"sort\",\"score desc,\"+i1+\" desc\",\"fl\",\"id\");    \n\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\");\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2);\n\n    // a facet query to test out chars out of the ascii range\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!term f=foo_s}international\\u00ff\\u01ff\\u2222\\u3333\");\n\n    // simple date facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date.other\", \"all\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // date facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date\",tdate_b, \n          \"facet.date.other\", \"all\", \n          \"f.\"+tdate_b+\".facet.date.start\",\"2009-05-01T11:00:00Z\", \n          \"f.\"+tdate_b+\".facet.date.gap\",\"+3MONTHS\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // simple range facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"facet.range.end\",900);\n\n    // range facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range\",i1, \n          \"f.\"+i1+\".facet.range.start\",300, \n          \"f.\"+i1+\".facet.range.gap\",87, \n          \"facet.range.end\",900,\n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"f.\"+tlong+\".facet.range.end\",900);\n    \n    //  variations of fl\n    query(\"q\",\"*:*\", \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1 + \",score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", i1, \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id,\" + i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1, \"fl\", \"id\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",nint, \"fl\",tint,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",nint, \"fl\", \"id\", \"fl\",tint,\"sort\",i1 + \" desc\");\n\n    stress=0;  // turn off stress... we want to tex max combos in min time\n    for (int i=0; i<25*RANDOM_MULTIPLIER; i++) {\n      String f = fieldNames[random().nextInt(fieldNames.length)];\n      if (random().nextBoolean()) f = t1;  // the text field is a really interesting one to facet on (and it's multi-valued too)\n\n      // we want a random query and not just *:* so we'll get zero counts in facets also\n      // TODO: do a better random query\n      String q = random().nextBoolean() ? \"*:*\" : \"id:(1 3 5 7 9 11 13) OR id:[100 TO \" + random().nextInt(50) + \"]\";\n\n      int nolimit = random().nextBoolean() ? -1 : 10000;  // these should be equivalent\n\n      // if limit==-1, we should always get exact matches\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"count\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      // for index sort, we should get exact results for mincount <= 1\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(2), \"facet.offset\",random().nextInt(10), \"facet.limit\",random().nextInt(11)-1);\n    }\n    stress = backupStress;  // restore stress\n\n    // test faceting multiple things at once\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1);\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id:[1 TO 7]\", \"fq\",\"{!tag=b}id:[3 TO 9]\"\n    );\n    query(\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\");\n\n    // test field that is valid in schema but missing in all shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2);\n    // test field that is valid in schema and missing in some shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2);\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1);\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    // check a complex key name\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"*:*\", \"rows\",100);\n    }\n\n    //SOLR 3161 ensure shards.qt=/update fails (anything but search handler really)\n    // Also see TestRemoteStreaming#testQtUpdateFails()\n    try {\n      ignoreException(\"isShard is only acceptable\");\n      // query(\"q\",\"*:*\",\"shards.qt\",\"/update\",\"stream.body\",\"<delete><query>*:*</query></delete>\");\n      // fail();\n    } catch (SolrException e) {\n      //expected\n    }\n    unIgnoreException(\"isShard is only acceptable\");\n\n    // test debugging\n    handle.put(\"explain\", UNORDERED);\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY);\n\n    // Check Info is added to for each shard\n    ModifiableSolrParams q = new ModifiableSolrParams();\n    q.set(\"q\", \"*:*\");\n    q.set(ShardParams.SHARDS_INFO, true);\n    setDistributedParams(q);\n    QueryResponse rsp = queryServer(q);\n    NamedList<?> sinfo = (NamedList<?>) rsp.getResponse().get(ShardParams.SHARDS_INFO);\n    String shards = getShardsString();\n    int cnt = StringUtils.countMatches(shards, \",\")+1;\n    \n    assertNotNull(\"missing shard info\", sinfo);\n    assertEquals(\"should have an entry for each shard [\"+sinfo+\"] \"+shards, cnt, sinfo.size());\n    \n    // test shards.tolerant=true\n    for(int numDownServers = 0; numDownServers < jettys.size()-1; numDownServers++)\n    {\n      List<JettySolrRunner> upJettys = new ArrayList<JettySolrRunner>(jettys);\n      List<SolrServer> upClients = new ArrayList<SolrServer>(clients);\n      List<JettySolrRunner> downJettys = new ArrayList<JettySolrRunner>();\n      List<String> upShards = new ArrayList<String>(Arrays.asList(shardsArr));\n      for(int i=0; i<numDownServers; i++)\n      {\n        // shut down some of the jettys\n        int indexToRemove = r.nextInt(upJettys.size());\n        JettySolrRunner downJetty = upJettys.remove(indexToRemove);\n        upClients.remove(indexToRemove);\n        upShards.remove(indexToRemove);\n        ChaosMonkey.stop(downJetty);\n        downJettys.add(downJetty);\n      }\n      \n      queryPartialResults(upShards, upClients, \"q\",\"*:*\",ShardParams.SHARDS_INFO,\"true\",ShardParams.SHARDS_TOLERANT,\"true\");\n      \n      // restart the jettys\n      for (JettySolrRunner downJetty : downJettys) {\n        downJetty.start();\n      }\n    }\n\n    // This index has the same number for every field\n    \n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // Thread.sleep(10000000000L);\n\n    FieldCache.DEFAULT.purgeAllCaches();   // avoid FC insanity\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5c7ba2bec83cc0a507e2cb5a5af99102deb9b01d","date":1344284819,"type":3,"author":"Yonik Seeley","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/TestDistributedSearch#doTest().mjava","pathOld":"solr/core/src/test/org/apache/solr/TestDistributedSearch#doTest().mjava","sourceNew":"  @Override\n  public void doTest() throws Exception {\n    int backupStress = stress; // make a copy so we can restore\n\n\n    del(\"*:*\");\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\", \n           tdate_a, \"2010-04-20T11:00:00Z\",\n           tdate_b, \"2009-08-20T11:00:00Z\",\n           \"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\", \n           tdate_a, \"2010-05-02T11:00:00Z\",\n           tdate_b, \"2009-11-02T11:00:00Z\");\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\", \n           tdate_a, \"2010-05-03T11:00:00Z\");\n    indexr(id,4, i1, -100 ,tlong, 101,\n           t1,\"the quick fox jumped over the lazy dog\", \n           tdate_a, \"2010-05-03T11:00:00Z\",\n           tdate_b, \"2010-05-03T11:00:00Z\");\n    indexr(id,5, i1, 500, tlong, 500 ,\n           t1,\"the quick fox jumped way over the lazy dog\", \n           tdate_a, \"2010-05-05T11:00:00Z\");\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,\n           tdate_b, \"2010-01-05T11:00:00Z\",\n           t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n\n    commit();  // try to ensure there's more than one segment\n\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,\n           t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,\n           t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,\n           t1,\"no eggs on wall, lesson learned\", \n           oddField, \"odd man out\");\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n\n    handle.clear();\n    handle.put(\"QTime\", SKIPVAL);\n    handle.put(\"timestamp\", SKIPVAL);\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(\"q\",\"*:*\", \"sort\",f+\" desc\");\n      query(\"q\",\"*:*\", \"sort\",f+\" asc\");\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",\"{!func}testfunc(add(\"+i1+\",5))\"+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" asc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\");\n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"*,score\"); \n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 desc\");\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"{!func}\"+i1);// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(\"q\",\"{!func}\"+i1, \"fl\",\"*,score\");  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"quick\");\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\");\n    query(\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\");  // no fields in returned docs\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\");\n\n    handle.put(\"score\", SKIPVAL);\n    query(\"q\",\"quick\",\"fl\",\"*,score\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\");\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"matchesnothing\",\"fl\",\"*,score\");  \n\n    // test that a single NOW value is propagated to all shards... if that is true\n    // then the primary sort should always be a tie and then the secondary should always decide\n    query(\"q\",\"{!func}ms(NOW)\", \"sort\",\"score desc,\"+i1+\" desc\",\"fl\",\"id\");    \n\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\");\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2);\n\n    // a facet query to test out chars out of the ascii range\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!term f=foo_s}international\\u00ff\\u01ff\\u2222\\u3333\");\n\n    // simple date facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date.other\", \"all\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // date facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date\",tdate_b, \n          \"facet.date.other\", \"all\", \n          \"f.\"+tdate_b+\".facet.date.start\",\"2009-05-01T11:00:00Z\", \n          \"f.\"+tdate_b+\".facet.date.gap\",\"+3MONTHS\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // simple range facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"facet.range.end\",900);\n\n    // range facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range\",i1, \n          \"f.\"+i1+\".facet.range.start\",300, \n          \"f.\"+i1+\".facet.range.gap\",87, \n          \"facet.range.end\",900,\n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"f.\"+tlong+\".facet.range.end\",900);\n    \n    //  variations of fl\n    query(\"q\",\"*:*\", \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1 + \",score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", i1, \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id,\" + i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1, \"fl\", \"id\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",nint, \"fl\",tint,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",nint, \"fl\", \"id\", \"fl\",tint,\"sort\",i1 + \" desc\");\n\n    stress=0;  // turn off stress... we want to tex max combos in min time\n    for (int i=0; i<25*RANDOM_MULTIPLIER; i++) {\n      String f = fieldNames[random().nextInt(fieldNames.length)];\n      if (random().nextBoolean()) f = t1;  // the text field is a really interesting one to facet on (and it's multi-valued too)\n\n      // we want a random query and not just *:* so we'll get zero counts in facets also\n      // TODO: do a better random query\n      String q = random().nextBoolean() ? \"*:*\" : \"id:(1 3 5 7 9 11 13) OR id:[100 TO \" + random().nextInt(50) + \"]\";\n\n      int nolimit = random().nextBoolean() ? -1 : 10000;  // these should be equivalent\n\n      // if limit==-1, we should always get exact matches\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"count\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      // for index sort, we should get exact results for mincount <= 1\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(2), \"facet.offset\",random().nextInt(10), \"facet.limit\",random().nextInt(11)-1);\n    }\n    stress = backupStress;  // restore stress\n\n    // test faceting multiple things at once\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1);\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id:[1 TO 7]\", \"fq\",\"{!tag=b}id:[3 TO 9]\"\n    );\n    query(\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\");\n\n    // test field that is valid in schema but missing in all shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2);\n    // test field that is valid in schema and missing in some shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2);\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1);\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    // check a complex key name\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"*:*\", \"rows\",100);\n    }\n\n    //SOLR 3161 ensure shards.qt=/update fails (anything but search handler really)\n    // Also see TestRemoteStreaming#testQtUpdateFails()\n    try {\n      ignoreException(\"isShard is only acceptable\");\n      // query(\"q\",\"*:*\",\"shards.qt\",\"/update\",\"stream.body\",\"<delete><query>*:*</query></delete>\");\n      // fail();\n    } catch (SolrException e) {\n      //expected\n    }\n    unIgnoreException(\"isShard is only acceptable\");\n\n    // test debugging\n    // handle.put(\"explain\", UNORDERED);\n    handle.put(\"explain\", SKIPVAL);  // internal docids differ, idf differs w/o global idf\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY);\n\n    // Check Info is added to for each shard\n    ModifiableSolrParams q = new ModifiableSolrParams();\n    q.set(\"q\", \"*:*\");\n    q.set(ShardParams.SHARDS_INFO, true);\n    setDistributedParams(q);\n    QueryResponse rsp = queryServer(q);\n    NamedList<?> sinfo = (NamedList<?>) rsp.getResponse().get(ShardParams.SHARDS_INFO);\n    String shards = getShardsString();\n    int cnt = StringUtils.countMatches(shards, \",\")+1;\n    \n    assertNotNull(\"missing shard info\", sinfo);\n    assertEquals(\"should have an entry for each shard [\"+sinfo+\"] \"+shards, cnt, sinfo.size());\n    \n    // test shards.tolerant=true\n    for(int numDownServers = 0; numDownServers < jettys.size()-1; numDownServers++)\n    {\n      List<JettySolrRunner> upJettys = new ArrayList<JettySolrRunner>(jettys);\n      List<SolrServer> upClients = new ArrayList<SolrServer>(clients);\n      List<JettySolrRunner> downJettys = new ArrayList<JettySolrRunner>();\n      List<String> upShards = new ArrayList<String>(Arrays.asList(shardsArr));\n      for(int i=0; i<numDownServers; i++)\n      {\n        // shut down some of the jettys\n        int indexToRemove = r.nextInt(upJettys.size());\n        JettySolrRunner downJetty = upJettys.remove(indexToRemove);\n        upClients.remove(indexToRemove);\n        upShards.remove(indexToRemove);\n        ChaosMonkey.stop(downJetty);\n        downJettys.add(downJetty);\n      }\n      \n      queryPartialResults(upShards, upClients, \n          \"q\",\"*:*\",\n          \"facet\",\"true\", \n          \"facet.field\",t1,\n          \"facet.limit\",5,\n          ShardParams.SHARDS_INFO,\"true\",\n          ShardParams.SHARDS_TOLERANT,\"true\");\n      \n      // restart the jettys\n      for (JettySolrRunner downJetty : downJettys) {\n        downJetty.start();\n      }\n    }\n\n    // This index has the same number for every field\n    \n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // Thread.sleep(10000000000L);\n\n    FieldCache.DEFAULT.purgeAllCaches();   // avoid FC insanity\n  }\n\n","sourceOld":"  @Override\n  public void doTest() throws Exception {\n    int backupStress = stress; // make a copy so we can restore\n\n\n    del(\"*:*\");\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\", \n           tdate_a, \"2010-04-20T11:00:00Z\",\n           tdate_b, \"2009-08-20T11:00:00Z\",\n           \"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\", \n           tdate_a, \"2010-05-02T11:00:00Z\",\n           tdate_b, \"2009-11-02T11:00:00Z\");\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\", \n           tdate_a, \"2010-05-03T11:00:00Z\");\n    indexr(id,4, i1, -100 ,tlong, 101,\n           t1,\"the quick fox jumped over the lazy dog\", \n           tdate_a, \"2010-05-03T11:00:00Z\",\n           tdate_b, \"2010-05-03T11:00:00Z\");\n    indexr(id,5, i1, 500, tlong, 500 ,\n           t1,\"the quick fox jumped way over the lazy dog\", \n           tdate_a, \"2010-05-05T11:00:00Z\");\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,\n           tdate_b, \"2010-01-05T11:00:00Z\",\n           t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n\n    commit();  // try to ensure there's more than one segment\n\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,\n           t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,\n           t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,\n           t1,\"no eggs on wall, lesson learned\", \n           oddField, \"odd man out\");\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n\n    handle.clear();\n    handle.put(\"QTime\", SKIPVAL);\n    handle.put(\"timestamp\", SKIPVAL);\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(\"q\",\"*:*\", \"sort\",f+\" desc\");\n      query(\"q\",\"*:*\", \"sort\",f+\" asc\");\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",\"{!func}testfunc(add(\"+i1+\",5))\"+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" asc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\");\n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"*,score\"); \n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 desc\");\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"{!func}\"+i1);// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(\"q\",\"{!func}\"+i1, \"fl\",\"*,score\");  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"quick\");\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\");\n    query(\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\");  // no fields in returned docs\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\");\n\n    handle.put(\"score\", SKIPVAL);\n    query(\"q\",\"quick\",\"fl\",\"*,score\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\");\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"matchesnothing\",\"fl\",\"*,score\");  \n\n    // test that a single NOW value is propagated to all shards... if that is true\n    // then the primary sort should always be a tie and then the secondary should always decide\n    query(\"q\",\"{!func}ms(NOW)\", \"sort\",\"score desc,\"+i1+\" desc\",\"fl\",\"id\");    \n\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\");\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2);\n\n    // a facet query to test out chars out of the ascii range\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!term f=foo_s}international\\u00ff\\u01ff\\u2222\\u3333\");\n\n    // simple date facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date.other\", \"all\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // date facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date\",tdate_b, \n          \"facet.date.other\", \"all\", \n          \"f.\"+tdate_b+\".facet.date.start\",\"2009-05-01T11:00:00Z\", \n          \"f.\"+tdate_b+\".facet.date.gap\",\"+3MONTHS\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // simple range facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"facet.range.end\",900);\n\n    // range facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range\",i1, \n          \"f.\"+i1+\".facet.range.start\",300, \n          \"f.\"+i1+\".facet.range.gap\",87, \n          \"facet.range.end\",900,\n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"f.\"+tlong+\".facet.range.end\",900);\n    \n    //  variations of fl\n    query(\"q\",\"*:*\", \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1 + \",score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", i1, \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id,\" + i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1, \"fl\", \"id\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",nint, \"fl\",tint,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",nint, \"fl\", \"id\", \"fl\",tint,\"sort\",i1 + \" desc\");\n\n    stress=0;  // turn off stress... we want to tex max combos in min time\n    for (int i=0; i<25*RANDOM_MULTIPLIER; i++) {\n      String f = fieldNames[random().nextInt(fieldNames.length)];\n      if (random().nextBoolean()) f = t1;  // the text field is a really interesting one to facet on (and it's multi-valued too)\n\n      // we want a random query and not just *:* so we'll get zero counts in facets also\n      // TODO: do a better random query\n      String q = random().nextBoolean() ? \"*:*\" : \"id:(1 3 5 7 9 11 13) OR id:[100 TO \" + random().nextInt(50) + \"]\";\n\n      int nolimit = random().nextBoolean() ? -1 : 10000;  // these should be equivalent\n\n      // if limit==-1, we should always get exact matches\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"count\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      // for index sort, we should get exact results for mincount <= 1\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(2), \"facet.offset\",random().nextInt(10), \"facet.limit\",random().nextInt(11)-1);\n    }\n    stress = backupStress;  // restore stress\n\n    // test faceting multiple things at once\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1);\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id:[1 TO 7]\", \"fq\",\"{!tag=b}id:[3 TO 9]\"\n    );\n    query(\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\");\n\n    // test field that is valid in schema but missing in all shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2);\n    // test field that is valid in schema and missing in some shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2);\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1);\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    // check a complex key name\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"*:*\", \"rows\",100);\n    }\n\n    //SOLR 3161 ensure shards.qt=/update fails (anything but search handler really)\n    // Also see TestRemoteStreaming#testQtUpdateFails()\n    try {\n      ignoreException(\"isShard is only acceptable\");\n      // query(\"q\",\"*:*\",\"shards.qt\",\"/update\",\"stream.body\",\"<delete><query>*:*</query></delete>\");\n      // fail();\n    } catch (SolrException e) {\n      //expected\n    }\n    unIgnoreException(\"isShard is only acceptable\");\n\n    // test debugging\n    handle.put(\"explain\", UNORDERED);\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY);\n\n    // Check Info is added to for each shard\n    ModifiableSolrParams q = new ModifiableSolrParams();\n    q.set(\"q\", \"*:*\");\n    q.set(ShardParams.SHARDS_INFO, true);\n    setDistributedParams(q);\n    QueryResponse rsp = queryServer(q);\n    NamedList<?> sinfo = (NamedList<?>) rsp.getResponse().get(ShardParams.SHARDS_INFO);\n    String shards = getShardsString();\n    int cnt = StringUtils.countMatches(shards, \",\")+1;\n    \n    assertNotNull(\"missing shard info\", sinfo);\n    assertEquals(\"should have an entry for each shard [\"+sinfo+\"] \"+shards, cnt, sinfo.size());\n    \n    // test shards.tolerant=true\n    for(int numDownServers = 0; numDownServers < jettys.size()-1; numDownServers++)\n    {\n      List<JettySolrRunner> upJettys = new ArrayList<JettySolrRunner>(jettys);\n      List<SolrServer> upClients = new ArrayList<SolrServer>(clients);\n      List<JettySolrRunner> downJettys = new ArrayList<JettySolrRunner>();\n      List<String> upShards = new ArrayList<String>(Arrays.asList(shardsArr));\n      for(int i=0; i<numDownServers; i++)\n      {\n        // shut down some of the jettys\n        int indexToRemove = r.nextInt(upJettys.size());\n        JettySolrRunner downJetty = upJettys.remove(indexToRemove);\n        upClients.remove(indexToRemove);\n        upShards.remove(indexToRemove);\n        ChaosMonkey.stop(downJetty);\n        downJettys.add(downJetty);\n      }\n      \n      queryPartialResults(upShards, upClients, \n          \"q\",\"*:*\",\n          \"facet\",\"true\", \n          \"facet.field\",t1,\n          \"facet.limit\",5,\n          ShardParams.SHARDS_INFO,\"true\",\n          ShardParams.SHARDS_TOLERANT,\"true\");\n      \n      // restart the jettys\n      for (JettySolrRunner downJetty : downJettys) {\n        downJetty.start();\n      }\n    }\n\n    // This index has the same number for every field\n    \n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // Thread.sleep(10000000000L);\n\n    FieldCache.DEFAULT.purgeAllCaches();   // avoid FC insanity\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d6f074e73200c07d54f242d3880a8da5a35ff97b","date":1344507653,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/TestDistributedSearch#doTest().mjava","pathOld":"solr/core/src/test/org/apache/solr/TestDistributedSearch#doTest().mjava","sourceNew":"  @Override\n  public void doTest() throws Exception {\n    int backupStress = stress; // make a copy so we can restore\n\n\n    del(\"*:*\");\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\", \n           tdate_a, \"2010-04-20T11:00:00Z\",\n           tdate_b, \"2009-08-20T11:00:00Z\",\n           \"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\", \n           tdate_a, \"2010-05-02T11:00:00Z\",\n           tdate_b, \"2009-11-02T11:00:00Z\");\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\", \n           tdate_a, \"2010-05-03T11:00:00Z\");\n    indexr(id,4, i1, -100 ,tlong, 101,\n           t1,\"the quick fox jumped over the lazy dog\", \n           tdate_a, \"2010-05-03T11:00:00Z\",\n           tdate_b, \"2010-05-03T11:00:00Z\");\n    indexr(id,5, i1, 500, tlong, 500 ,\n           t1,\"the quick fox jumped way over the lazy dog\", \n           tdate_a, \"2010-05-05T11:00:00Z\");\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,\n           tdate_b, \"2010-01-05T11:00:00Z\",\n           t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n\n    commit();  // try to ensure there's more than one segment\n\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,\n           t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,\n           t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,\n           t1,\"no eggs on wall, lesson learned\", \n           oddField, \"odd man out\");\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n\n    handle.clear();\n    handle.put(\"QTime\", SKIPVAL);\n    handle.put(\"timestamp\", SKIPVAL);\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(\"q\",\"*:*\", \"sort\",f+\" desc\");\n      query(\"q\",\"*:*\", \"sort\",f+\" asc\");\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",\"{!func}testfunc(add(\"+i1+\",5))\"+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" asc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\");\n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"*,score\"); \n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 desc\");\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"{!func}\"+i1);// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(\"q\",\"{!func}\"+i1, \"fl\",\"*,score\");  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"quick\");\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\");\n    query(\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\");  // no fields in returned docs\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\");\n\n    handle.put(\"score\", SKIPVAL);\n    query(\"q\",\"quick\",\"fl\",\"*,score\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\");\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"matchesnothing\",\"fl\",\"*,score\");  \n\n    // test that a single NOW value is propagated to all shards... if that is true\n    // then the primary sort should always be a tie and then the secondary should always decide\n    query(\"q\",\"{!func}ms(NOW)\", \"sort\",\"score desc,\"+i1+\" desc\",\"fl\",\"id\");    \n\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\");\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2);\n\n    // a facet query to test out chars out of the ascii range\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!term f=foo_s}international\\u00ff\\u01ff\\u2222\\u3333\");\n\n    // simple date facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date.other\", \"all\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // date facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date\",tdate_b, \n          \"facet.date.other\", \"all\", \n          \"f.\"+tdate_b+\".facet.date.start\",\"2009-05-01T11:00:00Z\", \n          \"f.\"+tdate_b+\".facet.date.gap\",\"+3MONTHS\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // simple range facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"facet.range.end\",900);\n\n    // range facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range\",i1, \n          \"f.\"+i1+\".facet.range.start\",300, \n          \"f.\"+i1+\".facet.range.gap\",87, \n          \"facet.range.end\",900,\n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"f.\"+tlong+\".facet.range.end\",900);\n    \n    //  variations of fl\n    query(\"q\",\"*:*\", \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1 + \",score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", i1, \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id,\" + i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1, \"fl\", \"id\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",nint, \"fl\",tint,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",nint, \"fl\", \"id\", \"fl\",tint,\"sort\",i1 + \" desc\");\n\n    stress=0;  // turn off stress... we want to tex max combos in min time\n    for (int i=0; i<25*RANDOM_MULTIPLIER; i++) {\n      String f = fieldNames[random().nextInt(fieldNames.length)];\n      if (random().nextBoolean()) f = t1;  // the text field is a really interesting one to facet on (and it's multi-valued too)\n\n      // we want a random query and not just *:* so we'll get zero counts in facets also\n      // TODO: do a better random query\n      String q = random().nextBoolean() ? \"*:*\" : \"id:(1 3 5 7 9 11 13) OR id:[100 TO \" + random().nextInt(50) + \"]\";\n\n      int nolimit = random().nextBoolean() ? -1 : 10000;  // these should be equivalent\n\n      // if limit==-1, we should always get exact matches\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"count\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      // for index sort, we should get exact results for mincount <= 1\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(2), \"facet.offset\",random().nextInt(10), \"facet.limit\",random().nextInt(11)-1);\n    }\n    stress = backupStress;  // restore stress\n\n    // test faceting multiple things at once\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1);\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id:[1 TO 7]\", \"fq\",\"{!tag=b}id:[3 TO 9]\"\n    );\n    query(\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\");\n\n    // test field that is valid in schema but missing in all shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2);\n    // test field that is valid in schema and missing in some shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2);\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1);\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    // check a complex key name\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"*:*\", \"rows\",100);\n    }\n\n    //SOLR 3161 ensure shards.qt=/update fails (anything but search handler really)\n    // Also see TestRemoteStreaming#testQtUpdateFails()\n    try {\n      ignoreException(\"isShard is only acceptable\");\n      // query(\"q\",\"*:*\",\"shards.qt\",\"/update\",\"stream.body\",\"<delete><query>*:*</query></delete>\");\n      // fail();\n    } catch (SolrException e) {\n      //expected\n    }\n    unIgnoreException(\"isShard is only acceptable\");\n\n    // test debugging\n    // handle.put(\"explain\", UNORDERED);\n    handle.put(\"explain\", SKIPVAL);  // internal docids differ, idf differs w/o global idf\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY);\n\n    // Check Info is added to for each shard\n    ModifiableSolrParams q = new ModifiableSolrParams();\n    q.set(\"q\", \"*:*\");\n    q.set(ShardParams.SHARDS_INFO, true);\n    setDistributedParams(q);\n    QueryResponse rsp = queryServer(q);\n    NamedList<?> sinfo = (NamedList<?>) rsp.getResponse().get(ShardParams.SHARDS_INFO);\n    String shards = getShardsString();\n    int cnt = StringUtils.countMatches(shards, \",\")+1;\n    \n    assertNotNull(\"missing shard info\", sinfo);\n    assertEquals(\"should have an entry for each shard [\"+sinfo+\"] \"+shards, cnt, sinfo.size());\n    \n    // test shards.tolerant=true\n    for(int numDownServers = 0; numDownServers < jettys.size()-1; numDownServers++)\n    {\n      List<JettySolrRunner> upJettys = new ArrayList<JettySolrRunner>(jettys);\n      List<SolrServer> upClients = new ArrayList<SolrServer>(clients);\n      List<JettySolrRunner> downJettys = new ArrayList<JettySolrRunner>();\n      List<String> upShards = new ArrayList<String>(Arrays.asList(shardsArr));\n      for(int i=0; i<numDownServers; i++)\n      {\n        // shut down some of the jettys\n        int indexToRemove = r.nextInt(upJettys.size());\n        JettySolrRunner downJetty = upJettys.remove(indexToRemove);\n        upClients.remove(indexToRemove);\n        upShards.remove(indexToRemove);\n        ChaosMonkey.stop(downJetty);\n        downJettys.add(downJetty);\n      }\n      \n      queryPartialResults(upShards, upClients, \n          \"q\",\"*:*\",\n          \"facet\",\"true\", \n          \"facet.field\",t1,\n          \"facet.limit\",5,\n          ShardParams.SHARDS_INFO,\"true\",\n          ShardParams.SHARDS_TOLERANT,\"true\");\n      \n      // restart the jettys\n      for (JettySolrRunner downJetty : downJettys) {\n        downJetty.start();\n      }\n    }\n\n    // This index has the same number for every field\n    \n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // Thread.sleep(10000000000L);\n\n    FieldCache.DEFAULT.purgeAllCaches();   // avoid FC insanity\n  }\n\n","sourceOld":"  @Override\n  public void doTest() throws Exception {\n    int backupStress = stress; // make a copy so we can restore\n\n\n    del(\"*:*\");\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\", \n           tdate_a, \"2010-04-20T11:00:00Z\",\n           tdate_b, \"2009-08-20T11:00:00Z\",\n           \"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\", \n           tdate_a, \"2010-05-02T11:00:00Z\",\n           tdate_b, \"2009-11-02T11:00:00Z\");\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\", \n           tdate_a, \"2010-05-03T11:00:00Z\");\n    indexr(id,4, i1, -100 ,tlong, 101,\n           t1,\"the quick fox jumped over the lazy dog\", \n           tdate_a, \"2010-05-03T11:00:00Z\",\n           tdate_b, \"2010-05-03T11:00:00Z\");\n    indexr(id,5, i1, 500, tlong, 500 ,\n           t1,\"the quick fox jumped way over the lazy dog\", \n           tdate_a, \"2010-05-05T11:00:00Z\");\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,\n           tdate_b, \"2010-01-05T11:00:00Z\",\n           t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n\n    commit();  // try to ensure there's more than one segment\n\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,\n           t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,\n           t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,\n           t1,\"no eggs on wall, lesson learned\", \n           oddField, \"odd man out\");\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n\n    handle.clear();\n    handle.put(\"QTime\", SKIPVAL);\n    handle.put(\"timestamp\", SKIPVAL);\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(\"q\",\"*:*\", \"sort\",f+\" desc\");\n      query(\"q\",\"*:*\", \"sort\",f+\" asc\");\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",\"{!func}testfunc(add(\"+i1+\",5))\"+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" asc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\");\n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"*,score\"); \n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 desc\");\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"{!func}\"+i1);// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(\"q\",\"{!func}\"+i1, \"fl\",\"*,score\");  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"quick\");\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\");\n    query(\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\");  // no fields in returned docs\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\");\n\n    handle.put(\"score\", SKIPVAL);\n    query(\"q\",\"quick\",\"fl\",\"*,score\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\");\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"matchesnothing\",\"fl\",\"*,score\");  \n\n    // test that a single NOW value is propagated to all shards... if that is true\n    // then the primary sort should always be a tie and then the secondary should always decide\n    query(\"q\",\"{!func}ms(NOW)\", \"sort\",\"score desc,\"+i1+\" desc\",\"fl\",\"id\");    \n\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\");\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2);\n\n    // a facet query to test out chars out of the ascii range\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!term f=foo_s}international\\u00ff\\u01ff\\u2222\\u3333\");\n\n    // simple date facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date.other\", \"all\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // date facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date\",tdate_b, \n          \"facet.date.other\", \"all\", \n          \"f.\"+tdate_b+\".facet.date.start\",\"2009-05-01T11:00:00Z\", \n          \"f.\"+tdate_b+\".facet.date.gap\",\"+3MONTHS\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // simple range facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"facet.range.end\",900);\n\n    // range facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range\",i1, \n          \"f.\"+i1+\".facet.range.start\",300, \n          \"f.\"+i1+\".facet.range.gap\",87, \n          \"facet.range.end\",900,\n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"f.\"+tlong+\".facet.range.end\",900);\n    \n    //  variations of fl\n    query(\"q\",\"*:*\", \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1 + \",score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", i1, \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id,\" + i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1, \"fl\", \"id\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",nint, \"fl\",tint,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",nint, \"fl\", \"id\", \"fl\",tint,\"sort\",i1 + \" desc\");\n\n    stress=0;  // turn off stress... we want to tex max combos in min time\n    for (int i=0; i<25*RANDOM_MULTIPLIER; i++) {\n      String f = fieldNames[random().nextInt(fieldNames.length)];\n      if (random().nextBoolean()) f = t1;  // the text field is a really interesting one to facet on (and it's multi-valued too)\n\n      // we want a random query and not just *:* so we'll get zero counts in facets also\n      // TODO: do a better random query\n      String q = random().nextBoolean() ? \"*:*\" : \"id:(1 3 5 7 9 11 13) OR id:[100 TO \" + random().nextInt(50) + \"]\";\n\n      int nolimit = random().nextBoolean() ? -1 : 10000;  // these should be equivalent\n\n      // if limit==-1, we should always get exact matches\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"count\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      // for index sort, we should get exact results for mincount <= 1\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(2), \"facet.offset\",random().nextInt(10), \"facet.limit\",random().nextInt(11)-1);\n    }\n    stress = backupStress;  // restore stress\n\n    // test faceting multiple things at once\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1);\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id:[1 TO 7]\", \"fq\",\"{!tag=b}id:[3 TO 9]\"\n    );\n    query(\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\");\n\n    // test field that is valid in schema but missing in all shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2);\n    // test field that is valid in schema and missing in some shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2);\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1);\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    // check a complex key name\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"*:*\", \"rows\",100);\n    }\n\n    //SOLR 3161 ensure shards.qt=/update fails (anything but search handler really)\n    // Also see TestRemoteStreaming#testQtUpdateFails()\n    try {\n      ignoreException(\"isShard is only acceptable\");\n      // query(\"q\",\"*:*\",\"shards.qt\",\"/update\",\"stream.body\",\"<delete><query>*:*</query></delete>\");\n      // fail();\n    } catch (SolrException e) {\n      //expected\n    }\n    unIgnoreException(\"isShard is only acceptable\");\n\n    // test debugging\n    handle.put(\"explain\", UNORDERED);\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY);\n\n    // Check Info is added to for each shard\n    ModifiableSolrParams q = new ModifiableSolrParams();\n    q.set(\"q\", \"*:*\");\n    q.set(ShardParams.SHARDS_INFO, true);\n    setDistributedParams(q);\n    QueryResponse rsp = queryServer(q);\n    NamedList<?> sinfo = (NamedList<?>) rsp.getResponse().get(ShardParams.SHARDS_INFO);\n    String shards = getShardsString();\n    int cnt = StringUtils.countMatches(shards, \",\")+1;\n    \n    assertNotNull(\"missing shard info\", sinfo);\n    assertEquals(\"should have an entry for each shard [\"+sinfo+\"] \"+shards, cnt, sinfo.size());\n    \n    // test shards.tolerant=true\n    for(int numDownServers = 0; numDownServers < jettys.size()-1; numDownServers++)\n    {\n      List<JettySolrRunner> upJettys = new ArrayList<JettySolrRunner>(jettys);\n      List<SolrServer> upClients = new ArrayList<SolrServer>(clients);\n      List<JettySolrRunner> downJettys = new ArrayList<JettySolrRunner>();\n      List<String> upShards = new ArrayList<String>(Arrays.asList(shardsArr));\n      for(int i=0; i<numDownServers; i++)\n      {\n        // shut down some of the jettys\n        int indexToRemove = r.nextInt(upJettys.size());\n        JettySolrRunner downJetty = upJettys.remove(indexToRemove);\n        upClients.remove(indexToRemove);\n        upShards.remove(indexToRemove);\n        ChaosMonkey.stop(downJetty);\n        downJettys.add(downJetty);\n      }\n      \n      queryPartialResults(upShards, upClients, \n          \"q\",\"*:*\",\n          \"facet\",\"true\", \n          \"facet.field\",t1,\n          \"facet.limit\",5,\n          ShardParams.SHARDS_INFO,\"true\",\n          ShardParams.SHARDS_TOLERANT,\"true\");\n      \n      // restart the jettys\n      for (JettySolrRunner downJetty : downJettys) {\n        downJetty.start();\n      }\n    }\n\n    // This index has the same number for every field\n    \n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // Thread.sleep(10000000000L);\n\n    FieldCache.DEFAULT.purgeAllCaches();   // avoid FC insanity\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c7869f64c874ebf7f317d22c00baf2b6857797a6","date":1344856617,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/TestDistributedSearch#doTest().mjava","pathOld":"solr/core/src/test/org/apache/solr/TestDistributedSearch#doTest().mjava","sourceNew":"  @Override\n  public void doTest() throws Exception {\n    int backupStress = stress; // make a copy so we can restore\n\n\n    del(\"*:*\");\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\", \n           tdate_a, \"2010-04-20T11:00:00Z\",\n           tdate_b, \"2009-08-20T11:00:00Z\",\n           \"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\", \n           tdate_a, \"2010-05-02T11:00:00Z\",\n           tdate_b, \"2009-11-02T11:00:00Z\");\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\", \n           tdate_a, \"2010-05-03T11:00:00Z\");\n    indexr(id,4, i1, -100 ,tlong, 101,\n           t1,\"the quick fox jumped over the lazy dog\", \n           tdate_a, \"2010-05-03T11:00:00Z\",\n           tdate_b, \"2010-05-03T11:00:00Z\");\n    indexr(id,5, i1, 500, tlong, 500 ,\n           t1,\"the quick fox jumped way over the lazy dog\", \n           tdate_a, \"2010-05-05T11:00:00Z\");\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,\n           tdate_b, \"2010-01-05T11:00:00Z\",\n           t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n\n    commit();  // try to ensure there's more than one segment\n\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,\n           t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,\n           t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,\n           t1,\"no eggs on wall, lesson learned\", \n           oddField, \"odd man out\");\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n\n    handle.clear();\n    handle.put(\"QTime\", SKIPVAL);\n    handle.put(\"timestamp\", SKIPVAL);\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(\"q\",\"*:*\", \"sort\",f+\" desc\");\n      query(\"q\",\"*:*\", \"sort\",f+\" asc\");\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",\"{!func}testfunc(add(\"+i1+\",5))\"+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" asc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\");\n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"*,score\"); \n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 desc\");\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"{!func}\"+i1);// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(\"q\",\"{!func}\"+i1, \"fl\",\"*,score\");  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"quick\");\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\");\n    query(\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\");  // no fields in returned docs\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\");\n\n    handle.put(\"score\", SKIPVAL);\n    query(\"q\",\"quick\",\"fl\",\"*,score\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\");\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"matchesnothing\",\"fl\",\"*,score\");  \n\n    // test that a single NOW value is propagated to all shards... if that is true\n    // then the primary sort should always be a tie and then the secondary should always decide\n    query(\"q\",\"{!func}ms(NOW)\", \"sort\",\"score desc,\"+i1+\" desc\",\"fl\",\"id\");    \n\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\");\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2);\n\n    // a facet query to test out chars out of the ascii range\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!term f=foo_s}international\\u00ff\\u01ff\\u2222\\u3333\");\n\n    // simple date facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date.other\", \"all\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // date facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date\",tdate_b, \n          \"facet.date.other\", \"all\", \n          \"f.\"+tdate_b+\".facet.date.start\",\"2009-05-01T11:00:00Z\", \n          \"f.\"+tdate_b+\".facet.date.gap\",\"+3MONTHS\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // simple range facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"facet.range.end\",900);\n\n    // range facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range\",i1, \n          \"f.\"+i1+\".facet.range.start\",300, \n          \"f.\"+i1+\".facet.range.gap\",87, \n          \"facet.range.end\",900,\n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"f.\"+tlong+\".facet.range.end\",900);\n    \n    //  variations of fl\n    query(\"q\",\"*:*\", \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1 + \",score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", i1, \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id,\" + i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1, \"fl\", \"id\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",nint, \"fl\",tint,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",nint, \"fl\", \"id\", \"fl\",tint,\"sort\",i1 + \" desc\");\n\n    stress=0;  // turn off stress... we want to tex max combos in min time\n    for (int i=0; i<25*RANDOM_MULTIPLIER; i++) {\n      String f = fieldNames[random().nextInt(fieldNames.length)];\n      if (random().nextBoolean()) f = t1;  // the text field is a really interesting one to facet on (and it's multi-valued too)\n\n      // we want a random query and not just *:* so we'll get zero counts in facets also\n      // TODO: do a better random query\n      String q = random().nextBoolean() ? \"*:*\" : \"id:(1 3 5 7 9 11 13) OR id:[100 TO \" + random().nextInt(50) + \"]\";\n\n      int nolimit = random().nextBoolean() ? -1 : 10000;  // these should be equivalent\n\n      // if limit==-1, we should always get exact matches\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"count\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      // for index sort, we should get exact results for mincount <= 1\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(2), \"facet.offset\",random().nextInt(10), \"facet.limit\",random().nextInt(11)-1);\n    }\n    stress = backupStress;  // restore stress\n\n    // test faceting multiple things at once\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1);\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id:[1 TO 7]\", \"fq\",\"{!tag=b}id:[3 TO 9]\"\n    );\n    query(\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\");\n\n    // test field that is valid in schema but missing in all shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2);\n    // test field that is valid in schema and missing in some shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2);\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1);\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    // check a complex key name\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"*:*\", \"rows\",100);\n    }\n\n    //SOLR 3161 ensure shards.qt=/update fails (anything but search handler really)\n    // Also see TestRemoteStreaming#testQtUpdateFails()\n    try {\n      ignoreException(\"isShard is only acceptable\");\n      // query(\"q\",\"*:*\",\"shards.qt\",\"/update\",\"stream.body\",\"<delete><query>*:*</query></delete>\");\n      // fail();\n    } catch (SolrException e) {\n      //expected\n    }\n    unIgnoreException(\"isShard is only acceptable\");\n\n    // test debugging\n    // handle.put(\"explain\", UNORDERED);\n    handle.put(\"explain\", SKIPVAL);  // internal docids differ, idf differs w/o global idf\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY);\n\n    // Check Info is added to for each shard\n    ModifiableSolrParams q = new ModifiableSolrParams();\n    q.set(\"q\", \"*:*\");\n    q.set(ShardParams.SHARDS_INFO, true);\n    setDistributedParams(q);\n    QueryResponse rsp = queryServer(q);\n    NamedList<?> sinfo = (NamedList<?>) rsp.getResponse().get(ShardParams.SHARDS_INFO);\n    String shards = getShardsString();\n    int cnt = StringUtils.countMatches(shards, \",\")+1;\n    \n    assertNotNull(\"missing shard info\", sinfo);\n    assertEquals(\"should have an entry for each shard [\"+sinfo+\"] \"+shards, cnt, sinfo.size());\n    \n    // test shards.tolerant=true\n    for(int numDownServers = 0; numDownServers < jettys.size()-1; numDownServers++)\n    {\n      List<JettySolrRunner> upJettys = new ArrayList<JettySolrRunner>(jettys);\n      List<SolrServer> upClients = new ArrayList<SolrServer>(clients);\n      List<JettySolrRunner> downJettys = new ArrayList<JettySolrRunner>();\n      List<String> upShards = new ArrayList<String>(Arrays.asList(shardsArr));\n      for(int i=0; i<numDownServers; i++)\n      {\n        // shut down some of the jettys\n        int indexToRemove = r.nextInt(upJettys.size());\n        JettySolrRunner downJetty = upJettys.remove(indexToRemove);\n        upClients.remove(indexToRemove);\n        upShards.remove(indexToRemove);\n        ChaosMonkey.stop(downJetty);\n        downJettys.add(downJetty);\n      }\n      \n      queryPartialResults(upShards, upClients, \n          \"q\",\"*:*\",\n          \"facet\",\"true\", \n          \"facet.field\",t1,\n          \"facet.limit\",5,\n          ShardParams.SHARDS_INFO,\"true\",\n          ShardParams.SHARDS_TOLERANT,\"true\");\n      \n      // restart the jettys\n      for (JettySolrRunner downJetty : downJettys) {\n        downJetty.start();\n      }\n    }\n\n    // This index has the same number for every field\n    \n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // Thread.sleep(10000000000L);\n\n    FieldCache.DEFAULT.purgeAllCaches();   // avoid FC insanity\n  }\n\n","sourceOld":"  @Override\n  public void doTest() throws Exception {\n    int backupStress = stress; // make a copy so we can restore\n\n\n    del(\"*:*\");\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\", \n           tdate_a, \"2010-04-20T11:00:00Z\",\n           tdate_b, \"2009-08-20T11:00:00Z\",\n           \"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\", \n           tdate_a, \"2010-05-02T11:00:00Z\",\n           tdate_b, \"2009-11-02T11:00:00Z\");\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\", \n           tdate_a, \"2010-05-03T11:00:00Z\");\n    indexr(id,4, i1, -100 ,tlong, 101,\n           t1,\"the quick fox jumped over the lazy dog\", \n           tdate_a, \"2010-05-03T11:00:00Z\",\n           tdate_b, \"2010-05-03T11:00:00Z\");\n    indexr(id,5, i1, 500, tlong, 500 ,\n           t1,\"the quick fox jumped way over the lazy dog\", \n           tdate_a, \"2010-05-05T11:00:00Z\");\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,\n           tdate_b, \"2010-01-05T11:00:00Z\",\n           t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n\n    commit();  // try to ensure there's more than one segment\n\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,\n           t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,\n           t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,\n           t1,\"no eggs on wall, lesson learned\", \n           oddField, \"odd man out\");\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n\n    handle.clear();\n    handle.put(\"QTime\", SKIPVAL);\n    handle.put(\"timestamp\", SKIPVAL);\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(\"q\",\"*:*\", \"sort\",f+\" desc\");\n      query(\"q\",\"*:*\", \"sort\",f+\" asc\");\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",\"{!func}testfunc(add(\"+i1+\",5))\"+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" asc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\");\n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"*,score\"); \n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 desc\");\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"{!func}\"+i1);// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(\"q\",\"{!func}\"+i1, \"fl\",\"*,score\");  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"quick\");\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\");\n    query(\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\");  // no fields in returned docs\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\");\n\n    handle.put(\"score\", SKIPVAL);\n    query(\"q\",\"quick\",\"fl\",\"*,score\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\");\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"matchesnothing\",\"fl\",\"*,score\");  \n\n    // test that a single NOW value is propagated to all shards... if that is true\n    // then the primary sort should always be a tie and then the secondary should always decide\n    query(\"q\",\"{!func}ms(NOW)\", \"sort\",\"score desc,\"+i1+\" desc\",\"fl\",\"id\");    \n\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\");\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2);\n\n    // a facet query to test out chars out of the ascii range\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!term f=foo_s}international\\u00ff\\u01ff\\u2222\\u3333\");\n\n    // simple date facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date.other\", \"all\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // date facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date\",tdate_b, \n          \"facet.date.other\", \"all\", \n          \"f.\"+tdate_b+\".facet.date.start\",\"2009-05-01T11:00:00Z\", \n          \"f.\"+tdate_b+\".facet.date.gap\",\"+3MONTHS\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // simple range facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"facet.range.end\",900);\n\n    // range facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range\",i1, \n          \"f.\"+i1+\".facet.range.start\",300, \n          \"f.\"+i1+\".facet.range.gap\",87, \n          \"facet.range.end\",900,\n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"f.\"+tlong+\".facet.range.end\",900);\n    \n    //  variations of fl\n    query(\"q\",\"*:*\", \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1 + \",score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", i1, \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id,\" + i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1, \"fl\", \"id\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",nint, \"fl\",tint,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",nint, \"fl\", \"id\", \"fl\",tint,\"sort\",i1 + \" desc\");\n\n    stress=0;  // turn off stress... we want to tex max combos in min time\n    for (int i=0; i<25*RANDOM_MULTIPLIER; i++) {\n      String f = fieldNames[random().nextInt(fieldNames.length)];\n      if (random().nextBoolean()) f = t1;  // the text field is a really interesting one to facet on (and it's multi-valued too)\n\n      // we want a random query and not just *:* so we'll get zero counts in facets also\n      // TODO: do a better random query\n      String q = random().nextBoolean() ? \"*:*\" : \"id:(1 3 5 7 9 11 13) OR id:[100 TO \" + random().nextInt(50) + \"]\";\n\n      int nolimit = random().nextBoolean() ? -1 : 10000;  // these should be equivalent\n\n      // if limit==-1, we should always get exact matches\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"count\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      // for index sort, we should get exact results for mincount <= 1\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(2), \"facet.offset\",random().nextInt(10), \"facet.limit\",random().nextInt(11)-1);\n    }\n    stress = backupStress;  // restore stress\n\n    // test faceting multiple things at once\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1);\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id:[1 TO 7]\", \"fq\",\"{!tag=b}id:[3 TO 9]\"\n    );\n    query(\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\");\n\n    // test field that is valid in schema but missing in all shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2);\n    // test field that is valid in schema and missing in some shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2);\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1);\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    // check a complex key name\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"*:*\", \"rows\",100);\n    }\n\n    //SOLR 3161 ensure shards.qt=/update fails (anything but search handler really)\n    // Also see TestRemoteStreaming#testQtUpdateFails()\n    try {\n      ignoreException(\"isShard is only acceptable\");\n      // query(\"q\",\"*:*\",\"shards.qt\",\"/update\",\"stream.body\",\"<delete><query>*:*</query></delete>\");\n      // fail();\n    } catch (SolrException e) {\n      //expected\n    }\n    unIgnoreException(\"isShard is only acceptable\");\n\n    // test debugging\n    handle.put(\"explain\", UNORDERED);\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY);\n\n    // Check Info is added to for each shard\n    ModifiableSolrParams q = new ModifiableSolrParams();\n    q.set(\"q\", \"*:*\");\n    q.set(ShardParams.SHARDS_INFO, true);\n    setDistributedParams(q);\n    QueryResponse rsp = queryServer(q);\n    NamedList<?> sinfo = (NamedList<?>) rsp.getResponse().get(ShardParams.SHARDS_INFO);\n    String shards = getShardsString();\n    int cnt = StringUtils.countMatches(shards, \",\")+1;\n    \n    assertNotNull(\"missing shard info\", sinfo);\n    assertEquals(\"should have an entry for each shard [\"+sinfo+\"] \"+shards, cnt, sinfo.size());\n    \n    // test shards.tolerant=true\n    for(int numDownServers = 0; numDownServers < jettys.size()-1; numDownServers++)\n    {\n      List<JettySolrRunner> upJettys = new ArrayList<JettySolrRunner>(jettys);\n      List<SolrServer> upClients = new ArrayList<SolrServer>(clients);\n      List<JettySolrRunner> downJettys = new ArrayList<JettySolrRunner>();\n      List<String> upShards = new ArrayList<String>(Arrays.asList(shardsArr));\n      for(int i=0; i<numDownServers; i++)\n      {\n        // shut down some of the jettys\n        int indexToRemove = r.nextInt(upJettys.size());\n        JettySolrRunner downJetty = upJettys.remove(indexToRemove);\n        upClients.remove(indexToRemove);\n        upShards.remove(indexToRemove);\n        ChaosMonkey.stop(downJetty);\n        downJettys.add(downJetty);\n      }\n      \n      queryPartialResults(upShards, upClients, \n          \"q\",\"*:*\",\n          \"facet\",\"true\", \n          \"facet.field\",t1,\n          \"facet.limit\",5,\n          ShardParams.SHARDS_INFO,\"true\",\n          ShardParams.SHARDS_TOLERANT,\"true\");\n      \n      // restart the jettys\n      for (JettySolrRunner downJetty : downJettys) {\n        downJetty.start();\n      }\n    }\n\n    // This index has the same number for every field\n    \n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // Thread.sleep(10000000000L);\n\n    FieldCache.DEFAULT.purgeAllCaches();   // avoid FC insanity\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ea7b027695d1003f32a2b5587762e9d51d0d60e8","date":1370029251,"type":3,"author":"Yonik Seeley","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/TestDistributedSearch#doTest().mjava","pathOld":"solr/core/src/test/org/apache/solr/TestDistributedSearch#doTest().mjava","sourceNew":"  @Override\n  public void doTest() throws Exception {\n    int backupStress = stress; // make a copy so we can restore\n\n\n    del(\"*:*\");\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\", \n           tdate_a, \"2010-04-20T11:00:00Z\",\n           tdate_b, \"2009-08-20T11:00:00Z\",\n           \"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\", \n           tdate_a, \"2010-05-02T11:00:00Z\",\n           tdate_b, \"2009-11-02T11:00:00Z\");\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\", \n           tdate_a, \"2010-05-03T11:00:00Z\");\n    indexr(id,4, i1, -100 ,tlong, 101,\n           t1,\"the quick fox jumped over the lazy dog\", \n           tdate_a, \"2010-05-03T11:00:00Z\",\n           tdate_b, \"2010-05-03T11:00:00Z\");\n    indexr(id,5, i1, 500, tlong, 500 ,\n           t1,\"the quick fox jumped way over the lazy dog\", \n           tdate_a, \"2010-05-05T11:00:00Z\");\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,\n           tdate_b, \"2010-01-05T11:00:00Z\",\n           t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n\n    commit();  // try to ensure there's more than one segment\n\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,\n           t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,\n           t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,\n           t1,\"no eggs on wall, lesson learned\", \n           oddField, \"odd man out\");\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n\n    handle.clear();\n    handle.put(\"QTime\", SKIPVAL);\n    handle.put(\"timestamp\", SKIPVAL);\n    handle.put(\"_version_\", SKIPVAL); // not a cloud test, but may use updateLog\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(\"q\",\"*:*\", \"sort\",f+\" desc\");\n      query(\"q\",\"*:*\", \"sort\",f+\" asc\");\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",\"{!func}testfunc(add(\"+i1+\",5))\"+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" asc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\");\n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"*,score\"); \n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 desc\");\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"{!func}\"+i1);// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(\"q\",\"{!func}\"+i1, \"fl\",\"*,score\");  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"quick\");\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\");\n    query(\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\");  // no fields in returned docs\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\");\n\n    handle.put(\"score\", SKIPVAL);\n    query(\"q\",\"quick\",\"fl\",\"*,score\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\");\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"matchesnothing\",\"fl\",\"*,score\");  \n\n    // test that a single NOW value is propagated to all shards... if that is true\n    // then the primary sort should always be a tie and then the secondary should always decide\n    query(\"q\",\"{!func}ms(NOW)\", \"sort\",\"score desc,\"+i1+\" desc\",\"fl\",\"id\");    \n\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\");\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2);\n\n    // a facet query to test out chars out of the ascii range\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!term f=foo_s}international\\u00ff\\u01ff\\u2222\\u3333\");\n\n    // simple date facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date.other\", \"all\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // date facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date\",tdate_b, \n          \"facet.date.other\", \"all\", \n          \"f.\"+tdate_b+\".facet.date.start\",\"2009-05-01T11:00:00Z\", \n          \"f.\"+tdate_b+\".facet.date.gap\",\"+3MONTHS\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // simple range facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"facet.range.end\",900);\n\n    // range facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range\",i1, \n          \"f.\"+i1+\".facet.range.start\",300, \n          \"f.\"+i1+\".facet.range.gap\",87, \n          \"facet.range.end\",900,\n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"f.\"+tlong+\".facet.range.end\",900);\n    \n    //  variations of fl\n    query(\"q\",\"*:*\", \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1 + \",score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", i1, \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id,\" + i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1, \"fl\", \"id\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",nint, \"fl\",tint,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",nint, \"fl\", \"id\", \"fl\",tint,\"sort\",i1 + \" desc\");\n\n    stress=0;  // turn off stress... we want to tex max combos in min time\n    for (int i=0; i<25*RANDOM_MULTIPLIER; i++) {\n      String f = fieldNames[random().nextInt(fieldNames.length)];\n      if (random().nextBoolean()) f = t1;  // the text field is a really interesting one to facet on (and it's multi-valued too)\n\n      // we want a random query and not just *:* so we'll get zero counts in facets also\n      // TODO: do a better random query\n      String q = random().nextBoolean() ? \"*:*\" : \"id:(1 3 5 7 9 11 13) OR id:[100 TO \" + random().nextInt(50) + \"]\";\n\n      int nolimit = random().nextBoolean() ? -1 : 10000;  // these should be equivalent\n\n      // if limit==-1, we should always get exact matches\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"count\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      // for index sort, we should get exact results for mincount <= 1\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(2), \"facet.offset\",random().nextInt(10), \"facet.limit\",random().nextInt(11)-1);\n    }\n    stress = backupStress;  // restore stress\n\n    // test faceting multiple things at once\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1);\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id:[1 TO 7]\", \"fq\",\"{!tag=b}id:[3 TO 9]\"\n    );\n    query(\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\");\n\n    // test field that is valid in schema but missing in all shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2);\n    // test field that is valid in schema and missing in some shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2);\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1);\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    // check a complex key name\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"*:*\", \"rows\",100);\n    }\n\n    //SOLR 3161 ensure shards.qt=/update fails (anything but search handler really)\n    // Also see TestRemoteStreaming#testQtUpdateFails()\n    try {\n      ignoreException(\"isShard is only acceptable\");\n      // query(\"q\",\"*:*\",\"shards.qt\",\"/update\",\"stream.body\",\"<delete><query>*:*</query></delete>\");\n      // fail();\n    } catch (SolrException e) {\n      //expected\n    }\n    unIgnoreException(\"isShard is only acceptable\");\n\n    // test debugging\n    // handle.put(\"explain\", UNORDERED);\n    handle.put(\"explain\", SKIPVAL);  // internal docids differ, idf differs w/o global idf\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY);\n\n    // Check Info is added to for each shard\n    ModifiableSolrParams q = new ModifiableSolrParams();\n    q.set(\"q\", \"*:*\");\n    q.set(ShardParams.SHARDS_INFO, true);\n    setDistributedParams(q);\n    QueryResponse rsp = queryServer(q);\n    NamedList<?> sinfo = (NamedList<?>) rsp.getResponse().get(ShardParams.SHARDS_INFO);\n    String shards = getShardsString();\n    int cnt = StringUtils.countMatches(shards, \",\")+1;\n    \n    assertNotNull(\"missing shard info\", sinfo);\n    assertEquals(\"should have an entry for each shard [\"+sinfo+\"] \"+shards, cnt, sinfo.size());\n    \n    // test shards.tolerant=true\n    for(int numDownServers = 0; numDownServers < jettys.size()-1; numDownServers++)\n    {\n      List<JettySolrRunner> upJettys = new ArrayList<JettySolrRunner>(jettys);\n      List<SolrServer> upClients = new ArrayList<SolrServer>(clients);\n      List<JettySolrRunner> downJettys = new ArrayList<JettySolrRunner>();\n      List<String> upShards = new ArrayList<String>(Arrays.asList(shardsArr));\n      for(int i=0; i<numDownServers; i++)\n      {\n        // shut down some of the jettys\n        int indexToRemove = r.nextInt(upJettys.size());\n        JettySolrRunner downJetty = upJettys.remove(indexToRemove);\n        upClients.remove(indexToRemove);\n        upShards.remove(indexToRemove);\n        ChaosMonkey.stop(downJetty);\n        downJettys.add(downJetty);\n      }\n      \n      queryPartialResults(upShards, upClients, \n          \"q\",\"*:*\",\n          \"facet\",\"true\", \n          \"facet.field\",t1,\n          \"facet.limit\",5,\n          ShardParams.SHARDS_INFO,\"true\",\n          ShardParams.SHARDS_TOLERANT,\"true\");\n      \n      // restart the jettys\n      for (JettySolrRunner downJetty : downJettys) {\n        downJetty.start();\n      }\n    }\n\n    // This index has the same number for every field\n    \n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // Thread.sleep(10000000000L);\n\n    FieldCache.DEFAULT.purgeAllCaches();   // avoid FC insanity\n  }\n\n","sourceOld":"  @Override\n  public void doTest() throws Exception {\n    int backupStress = stress; // make a copy so we can restore\n\n\n    del(\"*:*\");\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\", \n           tdate_a, \"2010-04-20T11:00:00Z\",\n           tdate_b, \"2009-08-20T11:00:00Z\",\n           \"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\", \n           tdate_a, \"2010-05-02T11:00:00Z\",\n           tdate_b, \"2009-11-02T11:00:00Z\");\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\", \n           tdate_a, \"2010-05-03T11:00:00Z\");\n    indexr(id,4, i1, -100 ,tlong, 101,\n           t1,\"the quick fox jumped over the lazy dog\", \n           tdate_a, \"2010-05-03T11:00:00Z\",\n           tdate_b, \"2010-05-03T11:00:00Z\");\n    indexr(id,5, i1, 500, tlong, 500 ,\n           t1,\"the quick fox jumped way over the lazy dog\", \n           tdate_a, \"2010-05-05T11:00:00Z\");\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,\n           tdate_b, \"2010-01-05T11:00:00Z\",\n           t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n\n    commit();  // try to ensure there's more than one segment\n\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,\n           t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,\n           t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,\n           t1,\"no eggs on wall, lesson learned\", \n           oddField, \"odd man out\");\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n\n    handle.clear();\n    handle.put(\"QTime\", SKIPVAL);\n    handle.put(\"timestamp\", SKIPVAL);\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(\"q\",\"*:*\", \"sort\",f+\" desc\");\n      query(\"q\",\"*:*\", \"sort\",f+\" asc\");\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",\"{!func}testfunc(add(\"+i1+\",5))\"+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" asc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\");\n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"*,score\"); \n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 desc\");\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"{!func}\"+i1);// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(\"q\",\"{!func}\"+i1, \"fl\",\"*,score\");  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"quick\");\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\");\n    query(\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\");  // no fields in returned docs\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\");\n\n    handle.put(\"score\", SKIPVAL);\n    query(\"q\",\"quick\",\"fl\",\"*,score\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\");\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"matchesnothing\",\"fl\",\"*,score\");  \n\n    // test that a single NOW value is propagated to all shards... if that is true\n    // then the primary sort should always be a tie and then the secondary should always decide\n    query(\"q\",\"{!func}ms(NOW)\", \"sort\",\"score desc,\"+i1+\" desc\",\"fl\",\"id\");    \n\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\");\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2);\n\n    // a facet query to test out chars out of the ascii range\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!term f=foo_s}international\\u00ff\\u01ff\\u2222\\u3333\");\n\n    // simple date facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date.other\", \"all\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // date facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date\",tdate_b, \n          \"facet.date.other\", \"all\", \n          \"f.\"+tdate_b+\".facet.date.start\",\"2009-05-01T11:00:00Z\", \n          \"f.\"+tdate_b+\".facet.date.gap\",\"+3MONTHS\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // simple range facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"facet.range.end\",900);\n\n    // range facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range\",i1, \n          \"f.\"+i1+\".facet.range.start\",300, \n          \"f.\"+i1+\".facet.range.gap\",87, \n          \"facet.range.end\",900,\n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"f.\"+tlong+\".facet.range.end\",900);\n    \n    //  variations of fl\n    query(\"q\",\"*:*\", \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1 + \",score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", i1, \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id,\" + i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1, \"fl\", \"id\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",nint, \"fl\",tint,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",nint, \"fl\", \"id\", \"fl\",tint,\"sort\",i1 + \" desc\");\n\n    stress=0;  // turn off stress... we want to tex max combos in min time\n    for (int i=0; i<25*RANDOM_MULTIPLIER; i++) {\n      String f = fieldNames[random().nextInt(fieldNames.length)];\n      if (random().nextBoolean()) f = t1;  // the text field is a really interesting one to facet on (and it's multi-valued too)\n\n      // we want a random query and not just *:* so we'll get zero counts in facets also\n      // TODO: do a better random query\n      String q = random().nextBoolean() ? \"*:*\" : \"id:(1 3 5 7 9 11 13) OR id:[100 TO \" + random().nextInt(50) + \"]\";\n\n      int nolimit = random().nextBoolean() ? -1 : 10000;  // these should be equivalent\n\n      // if limit==-1, we should always get exact matches\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"count\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      // for index sort, we should get exact results for mincount <= 1\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(2), \"facet.offset\",random().nextInt(10), \"facet.limit\",random().nextInt(11)-1);\n    }\n    stress = backupStress;  // restore stress\n\n    // test faceting multiple things at once\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1);\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id:[1 TO 7]\", \"fq\",\"{!tag=b}id:[3 TO 9]\"\n    );\n    query(\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\");\n\n    // test field that is valid in schema but missing in all shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2);\n    // test field that is valid in schema and missing in some shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2);\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1);\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    // check a complex key name\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"*:*\", \"rows\",100);\n    }\n\n    //SOLR 3161 ensure shards.qt=/update fails (anything but search handler really)\n    // Also see TestRemoteStreaming#testQtUpdateFails()\n    try {\n      ignoreException(\"isShard is only acceptable\");\n      // query(\"q\",\"*:*\",\"shards.qt\",\"/update\",\"stream.body\",\"<delete><query>*:*</query></delete>\");\n      // fail();\n    } catch (SolrException e) {\n      //expected\n    }\n    unIgnoreException(\"isShard is only acceptable\");\n\n    // test debugging\n    // handle.put(\"explain\", UNORDERED);\n    handle.put(\"explain\", SKIPVAL);  // internal docids differ, idf differs w/o global idf\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY);\n\n    // Check Info is added to for each shard\n    ModifiableSolrParams q = new ModifiableSolrParams();\n    q.set(\"q\", \"*:*\");\n    q.set(ShardParams.SHARDS_INFO, true);\n    setDistributedParams(q);\n    QueryResponse rsp = queryServer(q);\n    NamedList<?> sinfo = (NamedList<?>) rsp.getResponse().get(ShardParams.SHARDS_INFO);\n    String shards = getShardsString();\n    int cnt = StringUtils.countMatches(shards, \",\")+1;\n    \n    assertNotNull(\"missing shard info\", sinfo);\n    assertEquals(\"should have an entry for each shard [\"+sinfo+\"] \"+shards, cnt, sinfo.size());\n    \n    // test shards.tolerant=true\n    for(int numDownServers = 0; numDownServers < jettys.size()-1; numDownServers++)\n    {\n      List<JettySolrRunner> upJettys = new ArrayList<JettySolrRunner>(jettys);\n      List<SolrServer> upClients = new ArrayList<SolrServer>(clients);\n      List<JettySolrRunner> downJettys = new ArrayList<JettySolrRunner>();\n      List<String> upShards = new ArrayList<String>(Arrays.asList(shardsArr));\n      for(int i=0; i<numDownServers; i++)\n      {\n        // shut down some of the jettys\n        int indexToRemove = r.nextInt(upJettys.size());\n        JettySolrRunner downJetty = upJettys.remove(indexToRemove);\n        upClients.remove(indexToRemove);\n        upShards.remove(indexToRemove);\n        ChaosMonkey.stop(downJetty);\n        downJettys.add(downJetty);\n      }\n      \n      queryPartialResults(upShards, upClients, \n          \"q\",\"*:*\",\n          \"facet\",\"true\", \n          \"facet.field\",t1,\n          \"facet.limit\",5,\n          ShardParams.SHARDS_INFO,\"true\",\n          ShardParams.SHARDS_TOLERANT,\"true\");\n      \n      // restart the jettys\n      for (JettySolrRunner downJetty : downJettys) {\n        downJetty.start();\n      }\n    }\n\n    // This index has the same number for every field\n    \n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // Thread.sleep(10000000000L);\n\n    FieldCache.DEFAULT.purgeAllCaches();   // avoid FC insanity\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"a2d7ec084be7fa496e6f93352b6e10427881eb35","date":1372781416,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/TestDistributedSearch#doTest().mjava","pathOld":"solr/core/src/test/org/apache/solr/TestDistributedSearch#doTest().mjava","sourceNew":"  @Override\n  public void doTest() throws Exception {\n    int backupStress = stress; // make a copy so we can restore\n\n\n    del(\"*:*\");\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\", \n           tdate_a, \"2010-04-20T11:00:00Z\",\n           tdate_b, \"2009-08-20T11:00:00Z\",\n           \"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\", \n           tdate_a, \"2010-05-02T11:00:00Z\",\n           tdate_b, \"2009-11-02T11:00:00Z\");\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\", \n           tdate_a, \"2010-05-03T11:00:00Z\");\n    indexr(id,4, i1, -100 ,tlong, 101,\n           t1,\"the quick fox jumped over the lazy dog\", \n           tdate_a, \"2010-05-03T11:00:00Z\",\n           tdate_b, \"2010-05-03T11:00:00Z\");\n    indexr(id,5, i1, 500, tlong, 500 ,\n           t1,\"the quick fox jumped way over the lazy dog\", \n           tdate_a, \"2010-05-05T11:00:00Z\");\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,\n           tdate_b, \"2010-01-05T11:00:00Z\",\n           t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n\n    commit();  // try to ensure there's more than one segment\n\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,\n           t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,\n           t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,\n           t1,\"no eggs on wall, lesson learned\", \n           oddField, \"odd man out\");\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n\n    handle.clear();\n    handle.put(\"QTime\", SKIPVAL);\n    handle.put(\"timestamp\", SKIPVAL);\n    handle.put(\"_version_\", SKIPVAL); // not a cloud test, but may use updateLog\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(\"q\",\"*:*\", \"sort\",f+\" desc\");\n      query(\"q\",\"*:*\", \"sort\",f+\" asc\");\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",\"{!func}testfunc(add(\"+i1+\",5))\"+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" asc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\");\n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"*,score\"); \n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 desc\");\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"{!func}\"+i1);// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(\"q\",\"{!func}\"+i1, \"fl\",\"*,score\");  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"quick\");\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\");\n    query(\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\");  // no fields in returned docs\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\");\n\n    handle.put(\"score\", SKIPVAL);\n    query(\"q\",\"quick\",\"fl\",\"*,score\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\");\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"matchesnothing\",\"fl\",\"*,score\");  \n\n    // test that a single NOW value is propagated to all shards... if that is true\n    // then the primary sort should always be a tie and then the secondary should always decide\n    query(\"q\",\"{!func}ms(NOW)\", \"sort\",\"score desc,\"+i1+\" desc\",\"fl\",\"id\");    \n\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\");\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2);\n\n    // a facet query to test out chars out of the ascii range\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!term f=foo_s}international\\u00ff\\u01ff\\u2222\\u3333\");\n\n    // simple date facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date.other\", \"all\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // date facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date\",tdate_b, \n          \"facet.date.other\", \"all\", \n          \"f.\"+tdate_b+\".facet.date.start\",\"2009-05-01T11:00:00Z\", \n          \"f.\"+tdate_b+\".facet.date.gap\",\"+3MONTHS\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // simple range facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"facet.range.end\",900);\n\n    // range facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range\",i1, \n          \"f.\"+i1+\".facet.range.start\",300, \n          \"f.\"+i1+\".facet.range.gap\",87, \n          \"facet.range.end\",900,\n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"f.\"+tlong+\".facet.range.end\",900);\n    \n    //  variations of fl\n    query(\"q\",\"*:*\", \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1 + \",score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", i1, \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id,\" + i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1, \"fl\", \"id\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",nint, \"fl\",tint,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",nint, \"fl\", \"id\", \"fl\",tint,\"sort\",i1 + \" desc\");\n\n    stress=0;  // turn off stress... we want to tex max combos in min time\n    for (int i=0; i<25*RANDOM_MULTIPLIER; i++) {\n      String f = fieldNames[random().nextInt(fieldNames.length)];\n      if (random().nextBoolean()) f = t1;  // the text field is a really interesting one to facet on (and it's multi-valued too)\n\n      // we want a random query and not just *:* so we'll get zero counts in facets also\n      // TODO: do a better random query\n      String q = random().nextBoolean() ? \"*:*\" : \"id:(1 3 5 7 9 11 13) OR id:[100 TO \" + random().nextInt(50) + \"]\";\n\n      int nolimit = random().nextBoolean() ? -1 : 10000;  // these should be equivalent\n\n      // if limit==-1, we should always get exact matches\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"count\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      // for index sort, we should get exact results for mincount <= 1\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(2), \"facet.offset\",random().nextInt(10), \"facet.limit\",random().nextInt(11)-1);\n    }\n    stress = backupStress;  // restore stress\n\n    // test faceting multiple things at once\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1);\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id:[1 TO 7]\", \"fq\",\"{!tag=b}id:[3 TO 9]\"\n    );\n    query(\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\");\n\n    // test field that is valid in schema but missing in all shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2);\n    // test field that is valid in schema and missing in some shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2);\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1);\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    // check a complex key name\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"*:*\", \"rows\",100);\n    }\n\n    //SOLR 3161 ensure shards.qt=/update fails (anything but search handler really)\n    // Also see TestRemoteStreaming#testQtUpdateFails()\n    try {\n      ignoreException(\"isShard is only acceptable\");\n      // query(\"q\",\"*:*\",\"shards.qt\",\"/update\",\"stream.body\",\"<delete><query>*:*</query></delete>\");\n      // fail();\n    } catch (SolrException e) {\n      //expected\n    }\n    unIgnoreException(\"isShard is only acceptable\");\n\n    // test debugging\n    // handle.put(\"explain\", UNORDERED);\n    handle.put(\"explain\", SKIPVAL);  // internal docids differ, idf differs w/o global idf\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY);\n\n    // Check Info is added to for each shard\n    ModifiableSolrParams q = new ModifiableSolrParams();\n    q.set(\"q\", \"*:*\");\n    q.set(ShardParams.SHARDS_INFO, true);\n    setDistributedParams(q);\n    QueryResponse rsp = queryServer(q);\n    NamedList<?> sinfo = (NamedList<?>) rsp.getResponse().get(ShardParams.SHARDS_INFO);\n    String shards = getShardsString();\n    int cnt = StringUtils.countMatches(shards, \",\")+1;\n    \n    assertNotNull(\"missing shard info\", sinfo);\n    assertEquals(\"should have an entry for each shard [\"+sinfo+\"] \"+shards, cnt, sinfo.size());\n    \n    // test shards.tolerant=true\n    for(int numDownServers = 0; numDownServers < jettys.size()-1; numDownServers++)\n    {\n      List<JettySolrRunner> upJettys = new ArrayList<JettySolrRunner>(jettys);\n      List<SolrServer> upClients = new ArrayList<SolrServer>(clients);\n      List<JettySolrRunner> downJettys = new ArrayList<JettySolrRunner>();\n      List<String> upShards = new ArrayList<String>(Arrays.asList(shardsArr));\n      for(int i=0; i<numDownServers; i++)\n      {\n        // shut down some of the jettys\n        int indexToRemove = r.nextInt(upJettys.size());\n        JettySolrRunner downJetty = upJettys.remove(indexToRemove);\n        upClients.remove(indexToRemove);\n        upShards.remove(indexToRemove);\n        ChaosMonkey.stop(downJetty);\n        downJettys.add(downJetty);\n      }\n\n      queryPartialResults(upShards, upClients, \n          \"q\",\"*:*\",\n          \"facet\",\"true\", \n          \"facet.field\",t1,\n          \"facet.limit\",5,\n          ShardParams.SHARDS_INFO,\"true\",\n          ShardParams.SHARDS_TOLERANT,\"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"facet\", \"true\",\n          \"facet.query\", i1 + \":[1 TO 50]\",\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      // test group query\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"rows\", 100,\n          \"fl\", \"id,\" + i1,\n          \"group\", \"true\",\n          \"group.query\", t1 + \":kings OR \" + t1 + \":eggs\",\n          \"group.limit\", 10,\n          \"sort\", i1 + \" asc, id asc\",\n          CommonParams.TIME_ALLOWED, 1,\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      // restart the jettys\n      for (JettySolrRunner downJetty : downJettys) {\n        downJetty.start();\n      }\n    }\n\n    // This index has the same number for every field\n    \n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // Thread.sleep(10000000000L);\n\n    FieldCache.DEFAULT.purgeAllCaches();   // avoid FC insanity\n  }\n\n","sourceOld":"  @Override\n  public void doTest() throws Exception {\n    int backupStress = stress; // make a copy so we can restore\n\n\n    del(\"*:*\");\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\", \n           tdate_a, \"2010-04-20T11:00:00Z\",\n           tdate_b, \"2009-08-20T11:00:00Z\",\n           \"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\", \n           tdate_a, \"2010-05-02T11:00:00Z\",\n           tdate_b, \"2009-11-02T11:00:00Z\");\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\", \n           tdate_a, \"2010-05-03T11:00:00Z\");\n    indexr(id,4, i1, -100 ,tlong, 101,\n           t1,\"the quick fox jumped over the lazy dog\", \n           tdate_a, \"2010-05-03T11:00:00Z\",\n           tdate_b, \"2010-05-03T11:00:00Z\");\n    indexr(id,5, i1, 500, tlong, 500 ,\n           t1,\"the quick fox jumped way over the lazy dog\", \n           tdate_a, \"2010-05-05T11:00:00Z\");\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,\n           tdate_b, \"2010-01-05T11:00:00Z\",\n           t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n\n    commit();  // try to ensure there's more than one segment\n\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,\n           t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,\n           t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,\n           t1,\"no eggs on wall, lesson learned\", \n           oddField, \"odd man out\");\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n\n    handle.clear();\n    handle.put(\"QTime\", SKIPVAL);\n    handle.put(\"timestamp\", SKIPVAL);\n    handle.put(\"_version_\", SKIPVAL); // not a cloud test, but may use updateLog\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(\"q\",\"*:*\", \"sort\",f+\" desc\");\n      query(\"q\",\"*:*\", \"sort\",f+\" asc\");\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",\"{!func}testfunc(add(\"+i1+\",5))\"+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" asc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\");\n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"*,score\"); \n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 desc\");\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"{!func}\"+i1);// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(\"q\",\"{!func}\"+i1, \"fl\",\"*,score\");  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"quick\");\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\");\n    query(\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\");  // no fields in returned docs\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\");\n\n    handle.put(\"score\", SKIPVAL);\n    query(\"q\",\"quick\",\"fl\",\"*,score\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\");\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"matchesnothing\",\"fl\",\"*,score\");  \n\n    // test that a single NOW value is propagated to all shards... if that is true\n    // then the primary sort should always be a tie and then the secondary should always decide\n    query(\"q\",\"{!func}ms(NOW)\", \"sort\",\"score desc,\"+i1+\" desc\",\"fl\",\"id\");    \n\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\");\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2);\n\n    // a facet query to test out chars out of the ascii range\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!term f=foo_s}international\\u00ff\\u01ff\\u2222\\u3333\");\n\n    // simple date facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date.other\", \"all\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // date facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date\",tdate_b, \n          \"facet.date.other\", \"all\", \n          \"f.\"+tdate_b+\".facet.date.start\",\"2009-05-01T11:00:00Z\", \n          \"f.\"+tdate_b+\".facet.date.gap\",\"+3MONTHS\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // simple range facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"facet.range.end\",900);\n\n    // range facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range\",i1, \n          \"f.\"+i1+\".facet.range.start\",300, \n          \"f.\"+i1+\".facet.range.gap\",87, \n          \"facet.range.end\",900,\n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"f.\"+tlong+\".facet.range.end\",900);\n    \n    //  variations of fl\n    query(\"q\",\"*:*\", \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1 + \",score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", i1, \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id,\" + i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1, \"fl\", \"id\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",nint, \"fl\",tint,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",nint, \"fl\", \"id\", \"fl\",tint,\"sort\",i1 + \" desc\");\n\n    stress=0;  // turn off stress... we want to tex max combos in min time\n    for (int i=0; i<25*RANDOM_MULTIPLIER; i++) {\n      String f = fieldNames[random().nextInt(fieldNames.length)];\n      if (random().nextBoolean()) f = t1;  // the text field is a really interesting one to facet on (and it's multi-valued too)\n\n      // we want a random query and not just *:* so we'll get zero counts in facets also\n      // TODO: do a better random query\n      String q = random().nextBoolean() ? \"*:*\" : \"id:(1 3 5 7 9 11 13) OR id:[100 TO \" + random().nextInt(50) + \"]\";\n\n      int nolimit = random().nextBoolean() ? -1 : 10000;  // these should be equivalent\n\n      // if limit==-1, we should always get exact matches\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"count\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      // for index sort, we should get exact results for mincount <= 1\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(2), \"facet.offset\",random().nextInt(10), \"facet.limit\",random().nextInt(11)-1);\n    }\n    stress = backupStress;  // restore stress\n\n    // test faceting multiple things at once\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1);\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id:[1 TO 7]\", \"fq\",\"{!tag=b}id:[3 TO 9]\"\n    );\n    query(\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\");\n\n    // test field that is valid in schema but missing in all shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2);\n    // test field that is valid in schema and missing in some shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2);\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1);\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    // check a complex key name\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"*:*\", \"rows\",100);\n    }\n\n    //SOLR 3161 ensure shards.qt=/update fails (anything but search handler really)\n    // Also see TestRemoteStreaming#testQtUpdateFails()\n    try {\n      ignoreException(\"isShard is only acceptable\");\n      // query(\"q\",\"*:*\",\"shards.qt\",\"/update\",\"stream.body\",\"<delete><query>*:*</query></delete>\");\n      // fail();\n    } catch (SolrException e) {\n      //expected\n    }\n    unIgnoreException(\"isShard is only acceptable\");\n\n    // test debugging\n    // handle.put(\"explain\", UNORDERED);\n    handle.put(\"explain\", SKIPVAL);  // internal docids differ, idf differs w/o global idf\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY);\n\n    // Check Info is added to for each shard\n    ModifiableSolrParams q = new ModifiableSolrParams();\n    q.set(\"q\", \"*:*\");\n    q.set(ShardParams.SHARDS_INFO, true);\n    setDistributedParams(q);\n    QueryResponse rsp = queryServer(q);\n    NamedList<?> sinfo = (NamedList<?>) rsp.getResponse().get(ShardParams.SHARDS_INFO);\n    String shards = getShardsString();\n    int cnt = StringUtils.countMatches(shards, \",\")+1;\n    \n    assertNotNull(\"missing shard info\", sinfo);\n    assertEquals(\"should have an entry for each shard [\"+sinfo+\"] \"+shards, cnt, sinfo.size());\n    \n    // test shards.tolerant=true\n    for(int numDownServers = 0; numDownServers < jettys.size()-1; numDownServers++)\n    {\n      List<JettySolrRunner> upJettys = new ArrayList<JettySolrRunner>(jettys);\n      List<SolrServer> upClients = new ArrayList<SolrServer>(clients);\n      List<JettySolrRunner> downJettys = new ArrayList<JettySolrRunner>();\n      List<String> upShards = new ArrayList<String>(Arrays.asList(shardsArr));\n      for(int i=0; i<numDownServers; i++)\n      {\n        // shut down some of the jettys\n        int indexToRemove = r.nextInt(upJettys.size());\n        JettySolrRunner downJetty = upJettys.remove(indexToRemove);\n        upClients.remove(indexToRemove);\n        upShards.remove(indexToRemove);\n        ChaosMonkey.stop(downJetty);\n        downJettys.add(downJetty);\n      }\n      \n      queryPartialResults(upShards, upClients, \n          \"q\",\"*:*\",\n          \"facet\",\"true\", \n          \"facet.field\",t1,\n          \"facet.limit\",5,\n          ShardParams.SHARDS_INFO,\"true\",\n          ShardParams.SHARDS_TOLERANT,\"true\");\n      \n      // restart the jettys\n      for (JettySolrRunner downJetty : downJettys) {\n        downJetty.start();\n      }\n    }\n\n    // This index has the same number for every field\n    \n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // Thread.sleep(10000000000L);\n\n    FieldCache.DEFAULT.purgeAllCaches();   // avoid FC insanity\n  }\n\n","bugFix":["e6dd476b943b132ecfa6b3ffc72e439eb2d9e061"],"bugIntro":["bb222a3f9d9421d5c95afce73013fbd8de07ea1f"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"37a0f60745e53927c4c876cfe5b5a58170f0646c","date":1373994005,"type":3,"author":"Han Jiang","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/TestDistributedSearch#doTest().mjava","pathOld":"solr/core/src/test/org/apache/solr/TestDistributedSearch#doTest().mjava","sourceNew":"  @Override\n  public void doTest() throws Exception {\n    int backupStress = stress; // make a copy so we can restore\n\n\n    del(\"*:*\");\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\", \n           tdate_a, \"2010-04-20T11:00:00Z\",\n           tdate_b, \"2009-08-20T11:00:00Z\",\n           \"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\", \n           tdate_a, \"2010-05-02T11:00:00Z\",\n           tdate_b, \"2009-11-02T11:00:00Z\");\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\", \n           tdate_a, \"2010-05-03T11:00:00Z\");\n    indexr(id,4, i1, -100 ,tlong, 101,\n           t1,\"the quick fox jumped over the lazy dog\", \n           tdate_a, \"2010-05-03T11:00:00Z\",\n           tdate_b, \"2010-05-03T11:00:00Z\");\n    indexr(id,5, i1, 500, tlong, 500 ,\n           t1,\"the quick fox jumped way over the lazy dog\", \n           tdate_a, \"2010-05-05T11:00:00Z\");\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,\n           tdate_b, \"2010-01-05T11:00:00Z\",\n           t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n\n    commit();  // try to ensure there's more than one segment\n\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,\n           t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,\n           t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,\n           t1,\"no eggs on wall, lesson learned\", \n           oddField, \"odd man out\");\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n\n    handle.clear();\n    handle.put(\"QTime\", SKIPVAL);\n    handle.put(\"timestamp\", SKIPVAL);\n    handle.put(\"_version_\", SKIPVAL); // not a cloud test, but may use updateLog\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(\"q\",\"*:*\", \"sort\",f+\" desc\");\n      query(\"q\",\"*:*\", \"sort\",f+\" asc\");\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",\"{!func}testfunc(add(\"+i1+\",5))\"+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" asc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\");\n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"*,score\"); \n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 desc\");\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"{!func}\"+i1);// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(\"q\",\"{!func}\"+i1, \"fl\",\"*,score\");  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"quick\");\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\");\n    query(\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\");  // no fields in returned docs\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\");\n\n    handle.put(\"score\", SKIPVAL);\n    query(\"q\",\"quick\",\"fl\",\"*,score\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\");\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"matchesnothing\",\"fl\",\"*,score\");  \n\n    // test that a single NOW value is propagated to all shards... if that is true\n    // then the primary sort should always be a tie and then the secondary should always decide\n    query(\"q\",\"{!func}ms(NOW)\", \"sort\",\"score desc,\"+i1+\" desc\",\"fl\",\"id\");    \n\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\");\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2);\n\n    // a facet query to test out chars out of the ascii range\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!term f=foo_s}international\\u00ff\\u01ff\\u2222\\u3333\");\n\n    // simple date facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date.other\", \"all\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // date facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date\",tdate_b, \n          \"facet.date.other\", \"all\", \n          \"f.\"+tdate_b+\".facet.date.start\",\"2009-05-01T11:00:00Z\", \n          \"f.\"+tdate_b+\".facet.date.gap\",\"+3MONTHS\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // simple range facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"facet.range.end\",900);\n\n    // range facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range\",i1, \n          \"f.\"+i1+\".facet.range.start\",300, \n          \"f.\"+i1+\".facet.range.gap\",87, \n          \"facet.range.end\",900,\n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"f.\"+tlong+\".facet.range.end\",900);\n    \n    //  variations of fl\n    query(\"q\",\"*:*\", \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1 + \",score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", i1, \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id,\" + i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1, \"fl\", \"id\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",nint, \"fl\",tint,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",nint, \"fl\", \"id\", \"fl\",tint,\"sort\",i1 + \" desc\");\n\n    stress=0;  // turn off stress... we want to tex max combos in min time\n    for (int i=0; i<25*RANDOM_MULTIPLIER; i++) {\n      String f = fieldNames[random().nextInt(fieldNames.length)];\n      if (random().nextBoolean()) f = t1;  // the text field is a really interesting one to facet on (and it's multi-valued too)\n\n      // we want a random query and not just *:* so we'll get zero counts in facets also\n      // TODO: do a better random query\n      String q = random().nextBoolean() ? \"*:*\" : \"id:(1 3 5 7 9 11 13) OR id:[100 TO \" + random().nextInt(50) + \"]\";\n\n      int nolimit = random().nextBoolean() ? -1 : 10000;  // these should be equivalent\n\n      // if limit==-1, we should always get exact matches\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"count\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      // for index sort, we should get exact results for mincount <= 1\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(2), \"facet.offset\",random().nextInt(10), \"facet.limit\",random().nextInt(11)-1);\n    }\n    stress = backupStress;  // restore stress\n\n    // test faceting multiple things at once\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1);\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id:[1 TO 7]\", \"fq\",\"{!tag=b}id:[3 TO 9]\"\n    );\n    query(\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\");\n\n    // test field that is valid in schema but missing in all shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2);\n    // test field that is valid in schema and missing in some shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2);\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1);\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    // check a complex key name\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"*:*\", \"rows\",100);\n    }\n\n    //SOLR 3161 ensure shards.qt=/update fails (anything but search handler really)\n    // Also see TestRemoteStreaming#testQtUpdateFails()\n    try {\n      ignoreException(\"isShard is only acceptable\");\n      // query(\"q\",\"*:*\",\"shards.qt\",\"/update\",\"stream.body\",\"<delete><query>*:*</query></delete>\");\n      // fail();\n    } catch (SolrException e) {\n      //expected\n    }\n    unIgnoreException(\"isShard is only acceptable\");\n\n    // test debugging\n    // handle.put(\"explain\", UNORDERED);\n    handle.put(\"explain\", SKIPVAL);  // internal docids differ, idf differs w/o global idf\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY);\n\n    // Check Info is added to for each shard\n    ModifiableSolrParams q = new ModifiableSolrParams();\n    q.set(\"q\", \"*:*\");\n    q.set(ShardParams.SHARDS_INFO, true);\n    setDistributedParams(q);\n    QueryResponse rsp = queryServer(q);\n    NamedList<?> sinfo = (NamedList<?>) rsp.getResponse().get(ShardParams.SHARDS_INFO);\n    String shards = getShardsString();\n    int cnt = StringUtils.countMatches(shards, \",\")+1;\n    \n    assertNotNull(\"missing shard info\", sinfo);\n    assertEquals(\"should have an entry for each shard [\"+sinfo+\"] \"+shards, cnt, sinfo.size());\n    \n    // test shards.tolerant=true\n    for(int numDownServers = 0; numDownServers < jettys.size()-1; numDownServers++)\n    {\n      List<JettySolrRunner> upJettys = new ArrayList<JettySolrRunner>(jettys);\n      List<SolrServer> upClients = new ArrayList<SolrServer>(clients);\n      List<JettySolrRunner> downJettys = new ArrayList<JettySolrRunner>();\n      List<String> upShards = new ArrayList<String>(Arrays.asList(shardsArr));\n      for(int i=0; i<numDownServers; i++)\n      {\n        // shut down some of the jettys\n        int indexToRemove = r.nextInt(upJettys.size());\n        JettySolrRunner downJetty = upJettys.remove(indexToRemove);\n        upClients.remove(indexToRemove);\n        upShards.remove(indexToRemove);\n        ChaosMonkey.stop(downJetty);\n        downJettys.add(downJetty);\n      }\n\n      queryPartialResults(upShards, upClients, \n          \"q\",\"*:*\",\n          \"facet\",\"true\", \n          \"facet.field\",t1,\n          \"facet.limit\",5,\n          ShardParams.SHARDS_INFO,\"true\",\n          ShardParams.SHARDS_TOLERANT,\"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"facet\", \"true\",\n          \"facet.query\", i1 + \":[1 TO 50]\",\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      // test group query\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"rows\", 100,\n          \"fl\", \"id,\" + i1,\n          \"group\", \"true\",\n          \"group.query\", t1 + \":kings OR \" + t1 + \":eggs\",\n          \"group.limit\", 10,\n          \"sort\", i1 + \" asc, id asc\",\n          CommonParams.TIME_ALLOWED, 1,\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      // restart the jettys\n      for (JettySolrRunner downJetty : downJettys) {\n        downJetty.start();\n      }\n    }\n\n    // This index has the same number for every field\n    \n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // Thread.sleep(10000000000L);\n\n    FieldCache.DEFAULT.purgeAllCaches();   // avoid FC insanity\n  }\n\n","sourceOld":"  @Override\n  public void doTest() throws Exception {\n    int backupStress = stress; // make a copy so we can restore\n\n\n    del(\"*:*\");\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\", \n           tdate_a, \"2010-04-20T11:00:00Z\",\n           tdate_b, \"2009-08-20T11:00:00Z\",\n           \"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\", \n           tdate_a, \"2010-05-02T11:00:00Z\",\n           tdate_b, \"2009-11-02T11:00:00Z\");\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\", \n           tdate_a, \"2010-05-03T11:00:00Z\");\n    indexr(id,4, i1, -100 ,tlong, 101,\n           t1,\"the quick fox jumped over the lazy dog\", \n           tdate_a, \"2010-05-03T11:00:00Z\",\n           tdate_b, \"2010-05-03T11:00:00Z\");\n    indexr(id,5, i1, 500, tlong, 500 ,\n           t1,\"the quick fox jumped way over the lazy dog\", \n           tdate_a, \"2010-05-05T11:00:00Z\");\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,\n           tdate_b, \"2010-01-05T11:00:00Z\",\n           t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n\n    commit();  // try to ensure there's more than one segment\n\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,\n           t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,\n           t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,\n           t1,\"no eggs on wall, lesson learned\", \n           oddField, \"odd man out\");\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n\n    handle.clear();\n    handle.put(\"QTime\", SKIPVAL);\n    handle.put(\"timestamp\", SKIPVAL);\n    handle.put(\"_version_\", SKIPVAL); // not a cloud test, but may use updateLog\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(\"q\",\"*:*\", \"sort\",f+\" desc\");\n      query(\"q\",\"*:*\", \"sort\",f+\" asc\");\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",\"{!func}testfunc(add(\"+i1+\",5))\"+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" asc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\");\n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"*,score\"); \n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 desc\");\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"{!func}\"+i1);// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(\"q\",\"{!func}\"+i1, \"fl\",\"*,score\");  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"quick\");\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\");\n    query(\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\");  // no fields in returned docs\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\");\n\n    handle.put(\"score\", SKIPVAL);\n    query(\"q\",\"quick\",\"fl\",\"*,score\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\");\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"matchesnothing\",\"fl\",\"*,score\");  \n\n    // test that a single NOW value is propagated to all shards... if that is true\n    // then the primary sort should always be a tie and then the secondary should always decide\n    query(\"q\",\"{!func}ms(NOW)\", \"sort\",\"score desc,\"+i1+\" desc\",\"fl\",\"id\");    \n\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\");\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2);\n\n    // a facet query to test out chars out of the ascii range\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!term f=foo_s}international\\u00ff\\u01ff\\u2222\\u3333\");\n\n    // simple date facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date.other\", \"all\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // date facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date\",tdate_b, \n          \"facet.date.other\", \"all\", \n          \"f.\"+tdate_b+\".facet.date.start\",\"2009-05-01T11:00:00Z\", \n          \"f.\"+tdate_b+\".facet.date.gap\",\"+3MONTHS\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // simple range facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"facet.range.end\",900);\n\n    // range facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range\",i1, \n          \"f.\"+i1+\".facet.range.start\",300, \n          \"f.\"+i1+\".facet.range.gap\",87, \n          \"facet.range.end\",900,\n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"f.\"+tlong+\".facet.range.end\",900);\n    \n    //  variations of fl\n    query(\"q\",\"*:*\", \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1 + \",score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", i1, \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id,\" + i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1, \"fl\", \"id\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",nint, \"fl\",tint,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",nint, \"fl\", \"id\", \"fl\",tint,\"sort\",i1 + \" desc\");\n\n    stress=0;  // turn off stress... we want to tex max combos in min time\n    for (int i=0; i<25*RANDOM_MULTIPLIER; i++) {\n      String f = fieldNames[random().nextInt(fieldNames.length)];\n      if (random().nextBoolean()) f = t1;  // the text field is a really interesting one to facet on (and it's multi-valued too)\n\n      // we want a random query and not just *:* so we'll get zero counts in facets also\n      // TODO: do a better random query\n      String q = random().nextBoolean() ? \"*:*\" : \"id:(1 3 5 7 9 11 13) OR id:[100 TO \" + random().nextInt(50) + \"]\";\n\n      int nolimit = random().nextBoolean() ? -1 : 10000;  // these should be equivalent\n\n      // if limit==-1, we should always get exact matches\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"count\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      // for index sort, we should get exact results for mincount <= 1\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(2), \"facet.offset\",random().nextInt(10), \"facet.limit\",random().nextInt(11)-1);\n    }\n    stress = backupStress;  // restore stress\n\n    // test faceting multiple things at once\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1);\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id:[1 TO 7]\", \"fq\",\"{!tag=b}id:[3 TO 9]\"\n    );\n    query(\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\");\n\n    // test field that is valid in schema but missing in all shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2);\n    // test field that is valid in schema and missing in some shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2);\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1);\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    // check a complex key name\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"*:*\", \"rows\",100);\n    }\n\n    //SOLR 3161 ensure shards.qt=/update fails (anything but search handler really)\n    // Also see TestRemoteStreaming#testQtUpdateFails()\n    try {\n      ignoreException(\"isShard is only acceptable\");\n      // query(\"q\",\"*:*\",\"shards.qt\",\"/update\",\"stream.body\",\"<delete><query>*:*</query></delete>\");\n      // fail();\n    } catch (SolrException e) {\n      //expected\n    }\n    unIgnoreException(\"isShard is only acceptable\");\n\n    // test debugging\n    // handle.put(\"explain\", UNORDERED);\n    handle.put(\"explain\", SKIPVAL);  // internal docids differ, idf differs w/o global idf\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY);\n\n    // Check Info is added to for each shard\n    ModifiableSolrParams q = new ModifiableSolrParams();\n    q.set(\"q\", \"*:*\");\n    q.set(ShardParams.SHARDS_INFO, true);\n    setDistributedParams(q);\n    QueryResponse rsp = queryServer(q);\n    NamedList<?> sinfo = (NamedList<?>) rsp.getResponse().get(ShardParams.SHARDS_INFO);\n    String shards = getShardsString();\n    int cnt = StringUtils.countMatches(shards, \",\")+1;\n    \n    assertNotNull(\"missing shard info\", sinfo);\n    assertEquals(\"should have an entry for each shard [\"+sinfo+\"] \"+shards, cnt, sinfo.size());\n    \n    // test shards.tolerant=true\n    for(int numDownServers = 0; numDownServers < jettys.size()-1; numDownServers++)\n    {\n      List<JettySolrRunner> upJettys = new ArrayList<JettySolrRunner>(jettys);\n      List<SolrServer> upClients = new ArrayList<SolrServer>(clients);\n      List<JettySolrRunner> downJettys = new ArrayList<JettySolrRunner>();\n      List<String> upShards = new ArrayList<String>(Arrays.asList(shardsArr));\n      for(int i=0; i<numDownServers; i++)\n      {\n        // shut down some of the jettys\n        int indexToRemove = r.nextInt(upJettys.size());\n        JettySolrRunner downJetty = upJettys.remove(indexToRemove);\n        upClients.remove(indexToRemove);\n        upShards.remove(indexToRemove);\n        ChaosMonkey.stop(downJetty);\n        downJettys.add(downJetty);\n      }\n      \n      queryPartialResults(upShards, upClients, \n          \"q\",\"*:*\",\n          \"facet\",\"true\", \n          \"facet.field\",t1,\n          \"facet.limit\",5,\n          ShardParams.SHARDS_INFO,\"true\",\n          ShardParams.SHARDS_TOLERANT,\"true\");\n      \n      // restart the jettys\n      for (JettySolrRunner downJetty : downJettys) {\n        downJetty.start();\n      }\n    }\n\n    // This index has the same number for every field\n    \n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // Thread.sleep(10000000000L);\n\n    FieldCache.DEFAULT.purgeAllCaches();   // avoid FC insanity\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"19275ba31e621f6da1b83bf13af75233876fd3d4","date":1374846698,"type":3,"author":"Han Jiang","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/TestDistributedSearch#doTest().mjava","pathOld":"solr/core/src/test/org/apache/solr/TestDistributedSearch#doTest().mjava","sourceNew":"  @Override\n  public void doTest() throws Exception {\n    int backupStress = stress; // make a copy so we can restore\n\n\n    del(\"*:*\");\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\", \n           tdate_a, \"2010-04-20T11:00:00Z\",\n           tdate_b, \"2009-08-20T11:00:00Z\",\n           \"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\", \n           tdate_a, \"2010-05-02T11:00:00Z\",\n           tdate_b, \"2009-11-02T11:00:00Z\");\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\", \n           tdate_a, \"2010-05-03T11:00:00Z\");\n    indexr(id,4, i1, -100 ,tlong, 101,\n           t1,\"the quick fox jumped over the lazy dog\", \n           tdate_a, \"2010-05-03T11:00:00Z\",\n           tdate_b, \"2010-05-03T11:00:00Z\");\n    indexr(id,5, i1, 500, tlong, 500 ,\n           t1,\"the quick fox jumped way over the lazy dog\", \n           tdate_a, \"2010-05-05T11:00:00Z\");\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,\n           tdate_b, \"2010-01-05T11:00:00Z\",\n           t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n\n    commit();  // try to ensure there's more than one segment\n\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,\n           t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,\n           t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,\n           t1,\"no eggs on wall, lesson learned\", \n           oddField, \"odd man out\");\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n\n    handle.clear();\n    handle.put(\"QTime\", SKIPVAL);\n    handle.put(\"timestamp\", SKIPVAL);\n    handle.put(\"_version_\", SKIPVAL); // not a cloud test, but may use updateLog\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(\"q\",\"*:*\", \"sort\",f+\" desc\");\n      query(\"q\",\"*:*\", \"sort\",f+\" asc\");\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",\"{!func}testfunc(add(\"+i1+\",5))\"+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" asc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\");\n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"*,score\"); \n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 desc\");\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"{!func}\"+i1);// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(\"q\",\"{!func}\"+i1, \"fl\",\"*,score\");  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"quick\");\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\");\n    query(\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\");  // no fields in returned docs\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\");\n\n    handle.put(\"score\", SKIPVAL);\n    query(\"q\",\"quick\",\"fl\",\"*,score\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\");\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"matchesnothing\",\"fl\",\"*,score\");  \n\n    // test that a single NOW value is propagated to all shards... if that is true\n    // then the primary sort should always be a tie and then the secondary should always decide\n    query(\"q\",\"{!func}ms(NOW)\", \"sort\",\"score desc,\"+i1+\" desc\",\"fl\",\"id\");    \n\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\");\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2);\n\n    // a facet query to test out chars out of the ascii range\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!term f=foo_s}international\\u00ff\\u01ff\\u2222\\u3333\");\n\n    // simple date facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date.other\", \"all\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // date facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date\",tdate_b, \n          \"facet.date.other\", \"all\", \n          \"f.\"+tdate_b+\".facet.date.start\",\"2009-05-01T11:00:00Z\", \n          \"f.\"+tdate_b+\".facet.date.gap\",\"+3MONTHS\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // simple range facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"facet.range.end\",900);\n\n    // range facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range\",i1, \n          \"f.\"+i1+\".facet.range.start\",300, \n          \"f.\"+i1+\".facet.range.gap\",87, \n          \"facet.range.end\",900,\n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"f.\"+tlong+\".facet.range.end\",900);\n    \n    //  variations of fl\n    query(\"q\",\"*:*\", \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1 + \",score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", i1, \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id,\" + i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1, \"fl\", \"id\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",nint, \"fl\",tint,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",nint, \"fl\", \"id\", \"fl\",tint,\"sort\",i1 + \" desc\");\n\n    stress=0;  // turn off stress... we want to tex max combos in min time\n    for (int i=0; i<25*RANDOM_MULTIPLIER; i++) {\n      String f = fieldNames[random().nextInt(fieldNames.length)];\n      if (random().nextBoolean()) f = t1;  // the text field is a really interesting one to facet on (and it's multi-valued too)\n\n      // we want a random query and not just *:* so we'll get zero counts in facets also\n      // TODO: do a better random query\n      String q = random().nextBoolean() ? \"*:*\" : \"id:(1 3 5 7 9 11 13) OR id:[100 TO \" + random().nextInt(50) + \"]\";\n\n      int nolimit = random().nextBoolean() ? -1 : 10000;  // these should be equivalent\n\n      // if limit==-1, we should always get exact matches\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"count\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      // for index sort, we should get exact results for mincount <= 1\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(2), \"facet.offset\",random().nextInt(10), \"facet.limit\",random().nextInt(11)-1);\n    }\n    stress = backupStress;  // restore stress\n\n    // test faceting multiple things at once\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1);\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id:[1 TO 7]\", \"fq\",\"{!tag=b}id:[3 TO 9]\"\n    );\n    query(\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\");\n\n    // test field that is valid in schema but missing in all shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2);\n    // test field that is valid in schema and missing in some shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2);\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1);\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    // check a complex key name\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"*:*\", \"rows\",100);\n    }\n\n    //SOLR 3161 ensure shards.qt=/update fails (anything but search handler really)\n    // Also see TestRemoteStreaming#testQtUpdateFails()\n    try {\n      ignoreException(\"isShard is only acceptable\");\n      // query(\"q\",\"*:*\",\"shards.qt\",\"/update\",\"stream.body\",\"<delete><query>*:*</query></delete>\");\n      // fail();\n    } catch (SolrException e) {\n      //expected\n    }\n    unIgnoreException(\"isShard is only acceptable\");\n\n    // test debugging\n    // handle.put(\"explain\", UNORDERED);\n    handle.put(\"explain\", SKIPVAL);  // internal docids differ, idf differs w/o global idf\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY);\n\n    // Check Info is added to for each shard\n    ModifiableSolrParams q = new ModifiableSolrParams();\n    q.set(\"q\", \"*:*\");\n    q.set(ShardParams.SHARDS_INFO, true);\n    setDistributedParams(q);\n    QueryResponse rsp = queryServer(q);\n    NamedList<?> sinfo = (NamedList<?>) rsp.getResponse().get(ShardParams.SHARDS_INFO);\n    String shards = getShardsString();\n    int cnt = StringUtils.countMatches(shards, \",\")+1;\n    \n    assertNotNull(\"missing shard info\", sinfo);\n    assertEquals(\"should have an entry for each shard [\"+sinfo+\"] \"+shards, cnt, sinfo.size());\n    \n    // test shards.tolerant=true\n    for(int numDownServers = 0; numDownServers < jettys.size()-1; numDownServers++)\n    {\n      List<JettySolrRunner> upJettys = new ArrayList<JettySolrRunner>(jettys);\n      List<SolrServer> upClients = new ArrayList<SolrServer>(clients);\n      List<JettySolrRunner> downJettys = new ArrayList<JettySolrRunner>();\n      List<String> upShards = new ArrayList<String>(Arrays.asList(shardsArr));\n      for(int i=0; i<numDownServers; i++)\n      {\n        // shut down some of the jettys\n        int indexToRemove = r.nextInt(upJettys.size());\n        JettySolrRunner downJetty = upJettys.remove(indexToRemove);\n        upClients.remove(indexToRemove);\n        upShards.remove(indexToRemove);\n        ChaosMonkey.stop(downJetty);\n        downJettys.add(downJetty);\n      }\n\n      queryPartialResults(upShards, upClients, \n          \"q\",\"*:*\",\n          \"facet\",\"true\", \n          \"facet.field\",t1,\n          \"facet.limit\",5,\n          ShardParams.SHARDS_INFO,\"true\",\n          ShardParams.SHARDS_TOLERANT,\"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"facet\", \"true\",\n          \"facet.query\", i1 + \":[1 TO 50]\",\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      // test group query\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"rows\", 100,\n          \"fl\", \"id,\" + i1,\n          \"group\", \"true\",\n          \"group.query\", t1 + \":kings OR \" + t1 + \":eggs\",\n          \"group.limit\", 10,\n          \"sort\", i1 + \" asc, id asc\",\n          CommonParams.TIME_ALLOWED, 1,\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      // restart the jettys\n      for (JettySolrRunner downJetty : downJettys) {\n        downJetty.start();\n      }\n    }\n\n    // This index has the same number for every field\n    \n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // Thread.sleep(10000000000L);\n\n    FieldCache.DEFAULT.purgeAllCaches();   // avoid FC insanity\n  }\n\n","sourceOld":"  @Override\n  public void doTest() throws Exception {\n    int backupStress = stress; // make a copy so we can restore\n\n\n    del(\"*:*\");\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\", \n           tdate_a, \"2010-04-20T11:00:00Z\",\n           tdate_b, \"2009-08-20T11:00:00Z\",\n           \"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\", \n           tdate_a, \"2010-05-02T11:00:00Z\",\n           tdate_b, \"2009-11-02T11:00:00Z\");\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\", \n           tdate_a, \"2010-05-03T11:00:00Z\");\n    indexr(id,4, i1, -100 ,tlong, 101,\n           t1,\"the quick fox jumped over the lazy dog\", \n           tdate_a, \"2010-05-03T11:00:00Z\",\n           tdate_b, \"2010-05-03T11:00:00Z\");\n    indexr(id,5, i1, 500, tlong, 500 ,\n           t1,\"the quick fox jumped way over the lazy dog\", \n           tdate_a, \"2010-05-05T11:00:00Z\");\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,\n           tdate_b, \"2010-01-05T11:00:00Z\",\n           t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n\n    commit();  // try to ensure there's more than one segment\n\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,\n           t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,\n           t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,\n           t1,\"no eggs on wall, lesson learned\", \n           oddField, \"odd man out\");\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n\n    handle.clear();\n    handle.put(\"QTime\", SKIPVAL);\n    handle.put(\"timestamp\", SKIPVAL);\n    handle.put(\"_version_\", SKIPVAL); // not a cloud test, but may use updateLog\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(\"q\",\"*:*\", \"sort\",f+\" desc\");\n      query(\"q\",\"*:*\", \"sort\",f+\" asc\");\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",\"{!func}testfunc(add(\"+i1+\",5))\"+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" asc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\");\n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"*,score\"); \n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 desc\");\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"{!func}\"+i1);// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(\"q\",\"{!func}\"+i1, \"fl\",\"*,score\");  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"quick\");\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\");\n    query(\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\");  // no fields in returned docs\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\");\n\n    handle.put(\"score\", SKIPVAL);\n    query(\"q\",\"quick\",\"fl\",\"*,score\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\");\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"matchesnothing\",\"fl\",\"*,score\");  \n\n    // test that a single NOW value is propagated to all shards... if that is true\n    // then the primary sort should always be a tie and then the secondary should always decide\n    query(\"q\",\"{!func}ms(NOW)\", \"sort\",\"score desc,\"+i1+\" desc\",\"fl\",\"id\");    \n\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\");\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2);\n\n    // a facet query to test out chars out of the ascii range\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!term f=foo_s}international\\u00ff\\u01ff\\u2222\\u3333\");\n\n    // simple date facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date.other\", \"all\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // date facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date\",tdate_b, \n          \"facet.date.other\", \"all\", \n          \"f.\"+tdate_b+\".facet.date.start\",\"2009-05-01T11:00:00Z\", \n          \"f.\"+tdate_b+\".facet.date.gap\",\"+3MONTHS\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // simple range facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"facet.range.end\",900);\n\n    // range facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range\",i1, \n          \"f.\"+i1+\".facet.range.start\",300, \n          \"f.\"+i1+\".facet.range.gap\",87, \n          \"facet.range.end\",900,\n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"f.\"+tlong+\".facet.range.end\",900);\n    \n    //  variations of fl\n    query(\"q\",\"*:*\", \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1 + \",score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", i1, \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id,\" + i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1, \"fl\", \"id\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",nint, \"fl\",tint,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",nint, \"fl\", \"id\", \"fl\",tint,\"sort\",i1 + \" desc\");\n\n    stress=0;  // turn off stress... we want to tex max combos in min time\n    for (int i=0; i<25*RANDOM_MULTIPLIER; i++) {\n      String f = fieldNames[random().nextInt(fieldNames.length)];\n      if (random().nextBoolean()) f = t1;  // the text field is a really interesting one to facet on (and it's multi-valued too)\n\n      // we want a random query and not just *:* so we'll get zero counts in facets also\n      // TODO: do a better random query\n      String q = random().nextBoolean() ? \"*:*\" : \"id:(1 3 5 7 9 11 13) OR id:[100 TO \" + random().nextInt(50) + \"]\";\n\n      int nolimit = random().nextBoolean() ? -1 : 10000;  // these should be equivalent\n\n      // if limit==-1, we should always get exact matches\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"count\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      // for index sort, we should get exact results for mincount <= 1\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(2), \"facet.offset\",random().nextInt(10), \"facet.limit\",random().nextInt(11)-1);\n    }\n    stress = backupStress;  // restore stress\n\n    // test faceting multiple things at once\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1);\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id:[1 TO 7]\", \"fq\",\"{!tag=b}id:[3 TO 9]\"\n    );\n    query(\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\");\n\n    // test field that is valid in schema but missing in all shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2);\n    // test field that is valid in schema and missing in some shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2);\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1);\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    // check a complex key name\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"*:*\", \"rows\",100);\n    }\n\n    //SOLR 3161 ensure shards.qt=/update fails (anything but search handler really)\n    // Also see TestRemoteStreaming#testQtUpdateFails()\n    try {\n      ignoreException(\"isShard is only acceptable\");\n      // query(\"q\",\"*:*\",\"shards.qt\",\"/update\",\"stream.body\",\"<delete><query>*:*</query></delete>\");\n      // fail();\n    } catch (SolrException e) {\n      //expected\n    }\n    unIgnoreException(\"isShard is only acceptable\");\n\n    // test debugging\n    // handle.put(\"explain\", UNORDERED);\n    handle.put(\"explain\", SKIPVAL);  // internal docids differ, idf differs w/o global idf\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY);\n\n    // Check Info is added to for each shard\n    ModifiableSolrParams q = new ModifiableSolrParams();\n    q.set(\"q\", \"*:*\");\n    q.set(ShardParams.SHARDS_INFO, true);\n    setDistributedParams(q);\n    QueryResponse rsp = queryServer(q);\n    NamedList<?> sinfo = (NamedList<?>) rsp.getResponse().get(ShardParams.SHARDS_INFO);\n    String shards = getShardsString();\n    int cnt = StringUtils.countMatches(shards, \",\")+1;\n    \n    assertNotNull(\"missing shard info\", sinfo);\n    assertEquals(\"should have an entry for each shard [\"+sinfo+\"] \"+shards, cnt, sinfo.size());\n    \n    // test shards.tolerant=true\n    for(int numDownServers = 0; numDownServers < jettys.size()-1; numDownServers++)\n    {\n      List<JettySolrRunner> upJettys = new ArrayList<JettySolrRunner>(jettys);\n      List<SolrServer> upClients = new ArrayList<SolrServer>(clients);\n      List<JettySolrRunner> downJettys = new ArrayList<JettySolrRunner>();\n      List<String> upShards = new ArrayList<String>(Arrays.asList(shardsArr));\n      for(int i=0; i<numDownServers; i++)\n      {\n        // shut down some of the jettys\n        int indexToRemove = r.nextInt(upJettys.size());\n        JettySolrRunner downJetty = upJettys.remove(indexToRemove);\n        upClients.remove(indexToRemove);\n        upShards.remove(indexToRemove);\n        ChaosMonkey.stop(downJetty);\n        downJettys.add(downJetty);\n      }\n\n      queryPartialResults(upShards, upClients, \n          \"q\",\"*:*\",\n          \"facet\",\"true\", \n          \"facet.field\",t1,\n          \"facet.limit\",5,\n          ShardParams.SHARDS_INFO,\"true\",\n          ShardParams.SHARDS_TOLERANT,\"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"facet\", \"true\",\n          \"facet.query\", i1 + \":[1 TO 50]\",\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      // test group query\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"rows\", 100,\n          \"fl\", \"id,\" + i1,\n          \"group\", \"true\",\n          \"group.query\", t1 + \":kings OR \" + t1 + \":eggs\",\n          \"group.limit\", 10,\n          \"sort\", i1 + \" asc, id asc\",\n          CommonParams.TIME_ALLOWED, 1,\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      // restart the jettys\n      for (JettySolrRunner downJetty : downJettys) {\n        downJetty.start();\n      }\n    }\n\n    // This index has the same number for every field\n    \n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // Thread.sleep(10000000000L);\n\n    FieldCache.DEFAULT.purgeAllCaches();   // avoid FC insanity\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"716d18f3a9b0993bc679d7fa7abdc9bfb03411ec","date":1376375609,"type":3,"author":"Han Jiang","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/TestDistributedSearch#doTest().mjava","pathOld":"solr/core/src/test/org/apache/solr/TestDistributedSearch#doTest().mjava","sourceNew":"  @Override\n  public void doTest() throws Exception {\n    int backupStress = stress; // make a copy so we can restore\n\n\n    del(\"*:*\");\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\", \n           tdate_a, \"2010-04-20T11:00:00Z\",\n           tdate_b, \"2009-08-20T11:00:00Z\",\n           \"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\", \n           tdate_a, \"2010-05-02T11:00:00Z\",\n           tdate_b, \"2009-11-02T11:00:00Z\");\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\", \n           tdate_a, \"2010-05-03T11:00:00Z\");\n    indexr(id,4, i1, -100 ,tlong, 101,\n           t1,\"the quick fox jumped over the lazy dog\", \n           tdate_a, \"2010-05-03T11:00:00Z\",\n           tdate_b, \"2010-05-03T11:00:00Z\");\n    indexr(id,5, i1, 500, tlong, 500 ,\n           t1,\"the quick fox jumped way over the lazy dog\", \n           tdate_a, \"2010-05-05T11:00:00Z\");\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,\n           tdate_b, \"2010-01-05T11:00:00Z\",\n           t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n\n    commit();  // try to ensure there's more than one segment\n\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,\n           t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,\n           t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,\n           t1,\"no eggs on wall, lesson learned\", \n           oddField, \"odd man out\");\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n\n    handle.clear();\n    handle.put(\"QTime\", SKIPVAL);\n    handle.put(\"timestamp\", SKIPVAL);\n    handle.put(\"_version_\", SKIPVAL); // not a cloud test, but may use updateLog\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(\"q\",\"*:*\", \"sort\",f+\" desc\");\n      query(\"q\",\"*:*\", \"sort\",f+\" asc\");\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",\"{!func}testfunc(add(\"+i1+\",5))\"+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" asc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\");\n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"*,score\"); \n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 desc\");\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"{!func}\"+i1);// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(\"q\",\"{!func}\"+i1, \"fl\",\"*,score\");  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"quick\");\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\");\n    query(\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\");  // no fields in returned docs\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\");\n\n    handle.put(\"score\", SKIPVAL);\n    query(\"q\",\"quick\",\"fl\",\"*,score\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\");\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"matchesnothing\",\"fl\",\"*,score\");  \n\n    // test that a single NOW value is propagated to all shards... if that is true\n    // then the primary sort should always be a tie and then the secondary should always decide\n    query(\"q\",\"{!func}ms(NOW)\", \"sort\",\"score desc,\"+i1+\" desc\",\"fl\",\"id\");    \n\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\");\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2);\n\n    // a facet query to test out chars out of the ascii range\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!term f=foo_s}international\\u00ff\\u01ff\\u2222\\u3333\");\n\n    // simple date facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date.other\", \"all\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // date facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date\",tdate_b, \n          \"facet.date.other\", \"all\", \n          \"f.\"+tdate_b+\".facet.date.start\",\"2009-05-01T11:00:00Z\", \n          \"f.\"+tdate_b+\".facet.date.gap\",\"+3MONTHS\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // simple range facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"facet.range.end\",900);\n\n    // range facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range\",i1, \n          \"f.\"+i1+\".facet.range.start\",300, \n          \"f.\"+i1+\".facet.range.gap\",87, \n          \"facet.range.end\",900,\n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"f.\"+tlong+\".facet.range.end\",900);\n    \n    //  variations of fl\n    query(\"q\",\"*:*\", \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1 + \",score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", i1, \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id,\" + i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1, \"fl\", \"id\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",nint, \"fl\",tint,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",nint, \"fl\", \"id\", \"fl\",tint,\"sort\",i1 + \" desc\");\n\n    stress=0;  // turn off stress... we want to tex max combos in min time\n    for (int i=0; i<25*RANDOM_MULTIPLIER; i++) {\n      String f = fieldNames[random().nextInt(fieldNames.length)];\n      if (random().nextBoolean()) f = t1;  // the text field is a really interesting one to facet on (and it's multi-valued too)\n\n      // we want a random query and not just *:* so we'll get zero counts in facets also\n      // TODO: do a better random query\n      String q = random().nextBoolean() ? \"*:*\" : \"id:(1 3 5 7 9 11 13) OR id:[100 TO \" + random().nextInt(50) + \"]\";\n\n      int nolimit = random().nextBoolean() ? -1 : 10000;  // these should be equivalent\n\n      // if limit==-1, we should always get exact matches\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"count\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      // for index sort, we should get exact results for mincount <= 1\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(2), \"facet.offset\",random().nextInt(10), \"facet.limit\",random().nextInt(11)-1);\n    }\n    stress = backupStress;  // restore stress\n\n    // test faceting multiple things at once\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1);\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id:[1 TO 7]\", \"fq\",\"{!tag=b}id:[3 TO 9]\"\n    );\n    query(\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\");\n\n    // test field that is valid in schema but missing in all shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2);\n    // test field that is valid in schema and missing in some shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2);\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1);\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    // check a complex key name\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"*:*\", \"rows\",100);\n    }\n\n    //SOLR 3161 ensure shards.qt=/update fails (anything but search handler really)\n    // Also see TestRemoteStreaming#testQtUpdateFails()\n    try {\n      ignoreException(\"isShard is only acceptable\");\n      // query(\"q\",\"*:*\",\"shards.qt\",\"/update\",\"stream.body\",\"<delete><query>*:*</query></delete>\");\n      // fail();\n    } catch (SolrException e) {\n      //expected\n    }\n    unIgnoreException(\"isShard is only acceptable\");\n\n    // test debugging\n    // handle.put(\"explain\", UNORDERED);\n    handle.put(\"explain\", SKIPVAL);  // internal docids differ, idf differs w/o global idf\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY);\n\n    // Check Info is added to for each shard\n    ModifiableSolrParams q = new ModifiableSolrParams();\n    q.set(\"q\", \"*:*\");\n    q.set(ShardParams.SHARDS_INFO, true);\n    setDistributedParams(q);\n    QueryResponse rsp = queryServer(q);\n    NamedList<?> sinfo = (NamedList<?>) rsp.getResponse().get(ShardParams.SHARDS_INFO);\n    String shards = getShardsString();\n    int cnt = StringUtils.countMatches(shards, \",\")+1;\n    \n    assertNotNull(\"missing shard info\", sinfo);\n    assertEquals(\"should have an entry for each shard [\"+sinfo+\"] \"+shards, cnt, sinfo.size());\n    \n    // test shards.tolerant=true\n    for(int numDownServers = 0; numDownServers < jettys.size()-1; numDownServers++)\n    {\n      List<JettySolrRunner> upJettys = new ArrayList<JettySolrRunner>(jettys);\n      List<SolrServer> upClients = new ArrayList<SolrServer>(clients);\n      List<JettySolrRunner> downJettys = new ArrayList<JettySolrRunner>();\n      List<String> upShards = new ArrayList<String>(Arrays.asList(shardsArr));\n      for(int i=0; i<numDownServers; i++)\n      {\n        // shut down some of the jettys\n        int indexToRemove = r.nextInt(upJettys.size());\n        JettySolrRunner downJetty = upJettys.remove(indexToRemove);\n        upClients.remove(indexToRemove);\n        upShards.remove(indexToRemove);\n        ChaosMonkey.stop(downJetty);\n        downJettys.add(downJetty);\n      }\n\n      queryPartialResults(upShards, upClients, \n          \"q\",\"*:*\",\n          \"facet\",\"true\", \n          \"facet.field\",t1,\n          \"facet.limit\",5,\n          ShardParams.SHARDS_INFO,\"true\",\n          ShardParams.SHARDS_TOLERANT,\"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"facet\", \"true\",\n          \"facet.query\", i1 + \":[1 TO 50]\",\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      // test group query\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"rows\", 100,\n          \"fl\", \"id,\" + i1,\n          \"group\", \"true\",\n          \"group.query\", t1 + \":kings OR \" + t1 + \":eggs\",\n          \"group.limit\", 10,\n          \"sort\", i1 + \" asc, id asc\",\n          CommonParams.TIME_ALLOWED, 1,\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      // restart the jettys\n      for (JettySolrRunner downJetty : downJettys) {\n        downJetty.start();\n      }\n    }\n\n    // This index has the same number for every field\n    \n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // Thread.sleep(10000000000L);\n\n    FieldCache.DEFAULT.purgeAllCaches();   // avoid FC insanity\n  }\n\n","sourceOld":"  @Override\n  public void doTest() throws Exception {\n    int backupStress = stress; // make a copy so we can restore\n\n\n    del(\"*:*\");\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\", \n           tdate_a, \"2010-04-20T11:00:00Z\",\n           tdate_b, \"2009-08-20T11:00:00Z\",\n           \"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\", \n           tdate_a, \"2010-05-02T11:00:00Z\",\n           tdate_b, \"2009-11-02T11:00:00Z\");\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\", \n           tdate_a, \"2010-05-03T11:00:00Z\");\n    indexr(id,4, i1, -100 ,tlong, 101,\n           t1,\"the quick fox jumped over the lazy dog\", \n           tdate_a, \"2010-05-03T11:00:00Z\",\n           tdate_b, \"2010-05-03T11:00:00Z\");\n    indexr(id,5, i1, 500, tlong, 500 ,\n           t1,\"the quick fox jumped way over the lazy dog\", \n           tdate_a, \"2010-05-05T11:00:00Z\");\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,\n           tdate_b, \"2010-01-05T11:00:00Z\",\n           t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n\n    commit();  // try to ensure there's more than one segment\n\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,\n           t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,\n           t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,\n           t1,\"no eggs on wall, lesson learned\", \n           oddField, \"odd man out\");\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n\n    handle.clear();\n    handle.put(\"QTime\", SKIPVAL);\n    handle.put(\"timestamp\", SKIPVAL);\n    handle.put(\"_version_\", SKIPVAL); // not a cloud test, but may use updateLog\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(\"q\",\"*:*\", \"sort\",f+\" desc\");\n      query(\"q\",\"*:*\", \"sort\",f+\" asc\");\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",\"{!func}testfunc(add(\"+i1+\",5))\"+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" asc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\");\n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"*,score\"); \n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 desc\");\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"{!func}\"+i1);// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(\"q\",\"{!func}\"+i1, \"fl\",\"*,score\");  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"quick\");\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\");\n    query(\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\");  // no fields in returned docs\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\");\n\n    handle.put(\"score\", SKIPVAL);\n    query(\"q\",\"quick\",\"fl\",\"*,score\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\");\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"matchesnothing\",\"fl\",\"*,score\");  \n\n    // test that a single NOW value is propagated to all shards... if that is true\n    // then the primary sort should always be a tie and then the secondary should always decide\n    query(\"q\",\"{!func}ms(NOW)\", \"sort\",\"score desc,\"+i1+\" desc\",\"fl\",\"id\");    \n\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\");\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2);\n\n    // a facet query to test out chars out of the ascii range\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!term f=foo_s}international\\u00ff\\u01ff\\u2222\\u3333\");\n\n    // simple date facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date.other\", \"all\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // date facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date\",tdate_b, \n          \"facet.date.other\", \"all\", \n          \"f.\"+tdate_b+\".facet.date.start\",\"2009-05-01T11:00:00Z\", \n          \"f.\"+tdate_b+\".facet.date.gap\",\"+3MONTHS\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // simple range facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"facet.range.end\",900);\n\n    // range facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range\",i1, \n          \"f.\"+i1+\".facet.range.start\",300, \n          \"f.\"+i1+\".facet.range.gap\",87, \n          \"facet.range.end\",900,\n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"f.\"+tlong+\".facet.range.end\",900);\n    \n    //  variations of fl\n    query(\"q\",\"*:*\", \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1 + \",score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", i1, \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id,\" + i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1, \"fl\", \"id\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",nint, \"fl\",tint,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",nint, \"fl\", \"id\", \"fl\",tint,\"sort\",i1 + \" desc\");\n\n    stress=0;  // turn off stress... we want to tex max combos in min time\n    for (int i=0; i<25*RANDOM_MULTIPLIER; i++) {\n      String f = fieldNames[random().nextInt(fieldNames.length)];\n      if (random().nextBoolean()) f = t1;  // the text field is a really interesting one to facet on (and it's multi-valued too)\n\n      // we want a random query and not just *:* so we'll get zero counts in facets also\n      // TODO: do a better random query\n      String q = random().nextBoolean() ? \"*:*\" : \"id:(1 3 5 7 9 11 13) OR id:[100 TO \" + random().nextInt(50) + \"]\";\n\n      int nolimit = random().nextBoolean() ? -1 : 10000;  // these should be equivalent\n\n      // if limit==-1, we should always get exact matches\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"count\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      // for index sort, we should get exact results for mincount <= 1\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(2), \"facet.offset\",random().nextInt(10), \"facet.limit\",random().nextInt(11)-1);\n    }\n    stress = backupStress;  // restore stress\n\n    // test faceting multiple things at once\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1);\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id:[1 TO 7]\", \"fq\",\"{!tag=b}id:[3 TO 9]\"\n    );\n    query(\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\");\n\n    // test field that is valid in schema but missing in all shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2);\n    // test field that is valid in schema and missing in some shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2);\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1);\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    // check a complex key name\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"*:*\", \"rows\",100);\n    }\n\n    //SOLR 3161 ensure shards.qt=/update fails (anything but search handler really)\n    // Also see TestRemoteStreaming#testQtUpdateFails()\n    try {\n      ignoreException(\"isShard is only acceptable\");\n      // query(\"q\",\"*:*\",\"shards.qt\",\"/update\",\"stream.body\",\"<delete><query>*:*</query></delete>\");\n      // fail();\n    } catch (SolrException e) {\n      //expected\n    }\n    unIgnoreException(\"isShard is only acceptable\");\n\n    // test debugging\n    // handle.put(\"explain\", UNORDERED);\n    handle.put(\"explain\", SKIPVAL);  // internal docids differ, idf differs w/o global idf\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY);\n\n    // Check Info is added to for each shard\n    ModifiableSolrParams q = new ModifiableSolrParams();\n    q.set(\"q\", \"*:*\");\n    q.set(ShardParams.SHARDS_INFO, true);\n    setDistributedParams(q);\n    QueryResponse rsp = queryServer(q);\n    NamedList<?> sinfo = (NamedList<?>) rsp.getResponse().get(ShardParams.SHARDS_INFO);\n    String shards = getShardsString();\n    int cnt = StringUtils.countMatches(shards, \",\")+1;\n    \n    assertNotNull(\"missing shard info\", sinfo);\n    assertEquals(\"should have an entry for each shard [\"+sinfo+\"] \"+shards, cnt, sinfo.size());\n    \n    // test shards.tolerant=true\n    for(int numDownServers = 0; numDownServers < jettys.size()-1; numDownServers++)\n    {\n      List<JettySolrRunner> upJettys = new ArrayList<JettySolrRunner>(jettys);\n      List<SolrServer> upClients = new ArrayList<SolrServer>(clients);\n      List<JettySolrRunner> downJettys = new ArrayList<JettySolrRunner>();\n      List<String> upShards = new ArrayList<String>(Arrays.asList(shardsArr));\n      for(int i=0; i<numDownServers; i++)\n      {\n        // shut down some of the jettys\n        int indexToRemove = r.nextInt(upJettys.size());\n        JettySolrRunner downJetty = upJettys.remove(indexToRemove);\n        upClients.remove(indexToRemove);\n        upShards.remove(indexToRemove);\n        ChaosMonkey.stop(downJetty);\n        downJettys.add(downJetty);\n      }\n\n      queryPartialResults(upShards, upClients, \n          \"q\",\"*:*\",\n          \"facet\",\"true\", \n          \"facet.field\",t1,\n          \"facet.limit\",5,\n          ShardParams.SHARDS_INFO,\"true\",\n          ShardParams.SHARDS_TOLERANT,\"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"facet\", \"true\",\n          \"facet.query\", i1 + \":[1 TO 50]\",\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      // test group query\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"rows\", 100,\n          \"fl\", \"id,\" + i1,\n          \"group\", \"true\",\n          \"group.query\", t1 + \":kings OR \" + t1 + \":eggs\",\n          \"group.limit\", 10,\n          \"sort\", i1 + \" asc, id asc\",\n          CommonParams.TIME_ALLOWED, 1,\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      // restart the jettys\n      for (JettySolrRunner downJetty : downJettys) {\n        downJetty.start();\n      }\n    }\n\n    // This index has the same number for every field\n    \n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // Thread.sleep(10000000000L);\n\n    FieldCache.DEFAULT.purgeAllCaches();   // avoid FC insanity\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d9d424bd039937b4125152b454b3a32754b06f6c","date":1384391321,"type":3,"author":"Ryan Ernst","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/TestDistributedSearch#doTest().mjava","pathOld":"solr/core/src/test/org/apache/solr/TestDistributedSearch#doTest().mjava","sourceNew":"  @Override\n  public void doTest() throws Exception {\n    int backupStress = stress; // make a copy so we can restore\n\n\n    del(\"*:*\");\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\", \n           tdate_a, \"2010-04-20T11:00:00Z\",\n           tdate_b, \"2009-08-20T11:00:00Z\",\n           \"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\", \n           tdate_a, \"2010-05-02T11:00:00Z\",\n           tdate_b, \"2009-11-02T11:00:00Z\");\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\", \n           tdate_a, \"2010-05-03T11:00:00Z\");\n    indexr(id,4, i1, -100 ,tlong, 101,\n           t1,\"the quick fox jumped over the lazy dog\", \n           tdate_a, \"2010-05-03T11:00:00Z\",\n           tdate_b, \"2010-05-03T11:00:00Z\");\n    indexr(id,5, i1, 500, tlong, 500 ,\n           t1,\"the quick fox jumped way over the lazy dog\", \n           tdate_a, \"2010-05-05T11:00:00Z\");\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,\n           tdate_b, \"2010-01-05T11:00:00Z\",\n           t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n\n    commit();  // try to ensure there's more than one segment\n\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,\n           t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,\n           t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,\n           t1,\"no eggs on wall, lesson learned\", \n           oddField, \"odd man out\");\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n    \n    \n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n\n    handle.clear();\n    handle.put(\"QTime\", SKIPVAL);\n    handle.put(\"timestamp\", SKIPVAL);\n    handle.put(\"_version_\", SKIPVAL); // not a cloud test, but may use updateLog\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(\"q\",\"*:*\", \"sort\",f+\" desc\");\n      query(\"q\",\"*:*\", \"sort\",f+\" asc\");\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",\"{!func}testfunc(add(\"+i1+\",5))\"+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" asc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\");\n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"*,score\"); \n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 desc\");\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"{!func}\"+i1);// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(\"q\",\"{!func}\"+i1, \"fl\",\"*,score\");  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"quick\");\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\");\n    query(\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\");  // no fields in returned docs\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\");\n\n    handle.put(\"score\", SKIPVAL);\n    query(\"q\",\"quick\",\"fl\",\"*,score\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\");\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"matchesnothing\",\"fl\",\"*,score\");  \n\n    // test that a single NOW value is propagated to all shards... if that is true\n    // then the primary sort should always be a tie and then the secondary should always decide\n    query(\"q\",\"{!func}ms(NOW)\", \"sort\",\"score desc,\"+i1+\" desc\",\"fl\",\"id\");    \n\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\");\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2);\n\n    // a facet query to test out chars out of the ascii range\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!term f=foo_s}international\\u00ff\\u01ff\\u2222\\u3333\");\n\n    // simple date facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date.other\", \"all\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // date facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date\",tdate_b, \n          \"facet.date.other\", \"all\", \n          \"f.\"+tdate_b+\".facet.date.start\",\"2009-05-01T11:00:00Z\", \n          \"f.\"+tdate_b+\".facet.date.gap\",\"+3MONTHS\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // simple range facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"facet.range.end\",900);\n\n    // range facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range\",i1, \n          \"f.\"+i1+\".facet.range.start\",300, \n          \"f.\"+i1+\".facet.range.gap\",87, \n          \"facet.range.end\",900,\n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"f.\"+tlong+\".facet.range.end\",900);\n    \n    //  variations of fl\n    query(\"q\",\"*:*\", \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1 + \",score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", i1, \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id,\" + i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1, \"fl\", \"id\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",nint, \"fl\",tint,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",nint, \"fl\", \"id\", \"fl\",tint,\"sort\",i1 + \" desc\");\n\n    stress=0;  // turn off stress... we want to tex max combos in min time\n    for (int i=0; i<25*RANDOM_MULTIPLIER; i++) {\n      String f = fieldNames[random().nextInt(fieldNames.length)];\n      if (random().nextBoolean()) f = t1;  // the text field is a really interesting one to facet on (and it's multi-valued too)\n\n      // we want a random query and not just *:* so we'll get zero counts in facets also\n      // TODO: do a better random query\n      String q = random().nextBoolean() ? \"*:*\" : \"id:(1 3 5 7 9 11 13) OR id:[100 TO \" + random().nextInt(50) + \"]\";\n\n      int nolimit = random().nextBoolean() ? -1 : 10000;  // these should be equivalent\n\n      // if limit==-1, we should always get exact matches\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"count\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      // for index sort, we should get exact results for mincount <= 1\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(2), \"facet.offset\",random().nextInt(10), \"facet.limit\",random().nextInt(11)-1);\n    }\n    stress = backupStress;  // restore stress\n\n    // test faceting multiple things at once\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1);\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id:[1 TO 7]\", \"fq\",\"{!tag=b}id:[3 TO 9]\"\n    );\n    query(\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\");\n\n    // test field that is valid in schema but missing in all shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2);\n    // test field that is valid in schema and missing in some shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2);\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1);\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    // check a complex key name\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"*:*\", \"rows\",100);\n    }\n\n    //SOLR 3161 ensure shards.qt=/update fails (anything but search handler really)\n    // Also see TestRemoteStreaming#testQtUpdateFails()\n    try {\n      ignoreException(\"isShard is only acceptable\");\n      // query(\"q\",\"*:*\",\"shards.qt\",\"/update\",\"stream.body\",\"<delete><query>*:*</query></delete>\");\n      // fail();\n    } catch (SolrException e) {\n      //expected\n    }\n    unIgnoreException(\"isShard is only acceptable\");\n\n    // test debugging\n    // handle.put(\"explain\", UNORDERED);\n    handle.put(\"explain\", SKIPVAL);  // internal docids differ, idf differs w/o global idf\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    handle.put(\"track\", SKIP); //track is not included in single node search\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY);\n\n    // Check Info is added to for each shard\n    ModifiableSolrParams q = new ModifiableSolrParams();\n    q.set(\"q\", \"*:*\");\n    q.set(ShardParams.SHARDS_INFO, true);\n    setDistributedParams(q);\n    QueryResponse rsp = queryServer(q);\n    NamedList<?> sinfo = (NamedList<?>) rsp.getResponse().get(ShardParams.SHARDS_INFO);\n    String shards = getShardsString();\n    int cnt = StringUtils.countMatches(shards, \",\")+1;\n    \n    assertNotNull(\"missing shard info\", sinfo);\n    assertEquals(\"should have an entry for each shard [\"+sinfo+\"] \"+shards, cnt, sinfo.size());\n    \n    // test shards.tolerant=true\n    for(int numDownServers = 0; numDownServers < jettys.size()-1; numDownServers++)\n    {\n      List<JettySolrRunner> upJettys = new ArrayList<JettySolrRunner>(jettys);\n      List<SolrServer> upClients = new ArrayList<SolrServer>(clients);\n      List<JettySolrRunner> downJettys = new ArrayList<JettySolrRunner>();\n      List<String> upShards = new ArrayList<String>(Arrays.asList(shardsArr));\n      for(int i=0; i<numDownServers; i++)\n      {\n        // shut down some of the jettys\n        int indexToRemove = r.nextInt(upJettys.size());\n        JettySolrRunner downJetty = upJettys.remove(indexToRemove);\n        upClients.remove(indexToRemove);\n        upShards.remove(indexToRemove);\n        ChaosMonkey.stop(downJetty);\n        downJettys.add(downJetty);\n      }\n\n      queryPartialResults(upShards, upClients, \n          \"q\",\"*:*\",\n          \"facet\",\"true\", \n          \"facet.field\",t1,\n          \"facet.limit\",5,\n          ShardParams.SHARDS_INFO,\"true\",\n          ShardParams.SHARDS_TOLERANT,\"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"facet\", \"true\",\n          \"facet.query\", i1 + \":[1 TO 50]\",\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      // test group query\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"rows\", 100,\n          \"fl\", \"id,\" + i1,\n          \"group\", \"true\",\n          \"group.query\", t1 + \":kings OR \" + t1 + \":eggs\",\n          \"group.limit\", 10,\n          \"sort\", i1 + \" asc, id asc\",\n          CommonParams.TIME_ALLOWED, 1,\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      // restart the jettys\n      for (JettySolrRunner downJetty : downJettys) {\n        downJetty.start();\n      }\n    }\n\n    // This index has the same number for every field\n    \n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // Thread.sleep(10000000000L);\n\n    FieldCache.DEFAULT.purgeAllCaches();   // avoid FC insanity\n  }\n\n","sourceOld":"  @Override\n  public void doTest() throws Exception {\n    int backupStress = stress; // make a copy so we can restore\n\n\n    del(\"*:*\");\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\", \n           tdate_a, \"2010-04-20T11:00:00Z\",\n           tdate_b, \"2009-08-20T11:00:00Z\",\n           \"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\", \n           tdate_a, \"2010-05-02T11:00:00Z\",\n           tdate_b, \"2009-11-02T11:00:00Z\");\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\", \n           tdate_a, \"2010-05-03T11:00:00Z\");\n    indexr(id,4, i1, -100 ,tlong, 101,\n           t1,\"the quick fox jumped over the lazy dog\", \n           tdate_a, \"2010-05-03T11:00:00Z\",\n           tdate_b, \"2010-05-03T11:00:00Z\");\n    indexr(id,5, i1, 500, tlong, 500 ,\n           t1,\"the quick fox jumped way over the lazy dog\", \n           tdate_a, \"2010-05-05T11:00:00Z\");\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,\n           tdate_b, \"2010-01-05T11:00:00Z\",\n           t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n\n    commit();  // try to ensure there's more than one segment\n\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,\n           t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,\n           t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,\n           t1,\"no eggs on wall, lesson learned\", \n           oddField, \"odd man out\");\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n\n    handle.clear();\n    handle.put(\"QTime\", SKIPVAL);\n    handle.put(\"timestamp\", SKIPVAL);\n    handle.put(\"_version_\", SKIPVAL); // not a cloud test, but may use updateLog\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(\"q\",\"*:*\", \"sort\",f+\" desc\");\n      query(\"q\",\"*:*\", \"sort\",f+\" asc\");\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",\"{!func}testfunc(add(\"+i1+\",5))\"+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" asc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\");\n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"*,score\"); \n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 desc\");\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"{!func}\"+i1);// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(\"q\",\"{!func}\"+i1, \"fl\",\"*,score\");  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"quick\");\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\");\n    query(\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\");  // no fields in returned docs\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\");\n\n    handle.put(\"score\", SKIPVAL);\n    query(\"q\",\"quick\",\"fl\",\"*,score\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\");\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"matchesnothing\",\"fl\",\"*,score\");  \n\n    // test that a single NOW value is propagated to all shards... if that is true\n    // then the primary sort should always be a tie and then the secondary should always decide\n    query(\"q\",\"{!func}ms(NOW)\", \"sort\",\"score desc,\"+i1+\" desc\",\"fl\",\"id\");    \n\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\");\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2);\n\n    // a facet query to test out chars out of the ascii range\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!term f=foo_s}international\\u00ff\\u01ff\\u2222\\u3333\");\n\n    // simple date facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date.other\", \"all\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // date facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date\",tdate_b, \n          \"facet.date.other\", \"all\", \n          \"f.\"+tdate_b+\".facet.date.start\",\"2009-05-01T11:00:00Z\", \n          \"f.\"+tdate_b+\".facet.date.gap\",\"+3MONTHS\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // simple range facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"facet.range.end\",900);\n\n    // range facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range\",i1, \n          \"f.\"+i1+\".facet.range.start\",300, \n          \"f.\"+i1+\".facet.range.gap\",87, \n          \"facet.range.end\",900,\n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"f.\"+tlong+\".facet.range.end\",900);\n    \n    //  variations of fl\n    query(\"q\",\"*:*\", \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1 + \",score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", i1, \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id,\" + i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1, \"fl\", \"id\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",nint, \"fl\",tint,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",nint, \"fl\", \"id\", \"fl\",tint,\"sort\",i1 + \" desc\");\n\n    stress=0;  // turn off stress... we want to tex max combos in min time\n    for (int i=0; i<25*RANDOM_MULTIPLIER; i++) {\n      String f = fieldNames[random().nextInt(fieldNames.length)];\n      if (random().nextBoolean()) f = t1;  // the text field is a really interesting one to facet on (and it's multi-valued too)\n\n      // we want a random query and not just *:* so we'll get zero counts in facets also\n      // TODO: do a better random query\n      String q = random().nextBoolean() ? \"*:*\" : \"id:(1 3 5 7 9 11 13) OR id:[100 TO \" + random().nextInt(50) + \"]\";\n\n      int nolimit = random().nextBoolean() ? -1 : 10000;  // these should be equivalent\n\n      // if limit==-1, we should always get exact matches\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"count\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      // for index sort, we should get exact results for mincount <= 1\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(2), \"facet.offset\",random().nextInt(10), \"facet.limit\",random().nextInt(11)-1);\n    }\n    stress = backupStress;  // restore stress\n\n    // test faceting multiple things at once\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1);\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id:[1 TO 7]\", \"fq\",\"{!tag=b}id:[3 TO 9]\"\n    );\n    query(\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\");\n\n    // test field that is valid in schema but missing in all shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2);\n    // test field that is valid in schema and missing in some shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2);\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1);\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    // check a complex key name\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"*:*\", \"rows\",100);\n    }\n\n    //SOLR 3161 ensure shards.qt=/update fails (anything but search handler really)\n    // Also see TestRemoteStreaming#testQtUpdateFails()\n    try {\n      ignoreException(\"isShard is only acceptable\");\n      // query(\"q\",\"*:*\",\"shards.qt\",\"/update\",\"stream.body\",\"<delete><query>*:*</query></delete>\");\n      // fail();\n    } catch (SolrException e) {\n      //expected\n    }\n    unIgnoreException(\"isShard is only acceptable\");\n\n    // test debugging\n    // handle.put(\"explain\", UNORDERED);\n    handle.put(\"explain\", SKIPVAL);  // internal docids differ, idf differs w/o global idf\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY);\n\n    // Check Info is added to for each shard\n    ModifiableSolrParams q = new ModifiableSolrParams();\n    q.set(\"q\", \"*:*\");\n    q.set(ShardParams.SHARDS_INFO, true);\n    setDistributedParams(q);\n    QueryResponse rsp = queryServer(q);\n    NamedList<?> sinfo = (NamedList<?>) rsp.getResponse().get(ShardParams.SHARDS_INFO);\n    String shards = getShardsString();\n    int cnt = StringUtils.countMatches(shards, \",\")+1;\n    \n    assertNotNull(\"missing shard info\", sinfo);\n    assertEquals(\"should have an entry for each shard [\"+sinfo+\"] \"+shards, cnt, sinfo.size());\n    \n    // test shards.tolerant=true\n    for(int numDownServers = 0; numDownServers < jettys.size()-1; numDownServers++)\n    {\n      List<JettySolrRunner> upJettys = new ArrayList<JettySolrRunner>(jettys);\n      List<SolrServer> upClients = new ArrayList<SolrServer>(clients);\n      List<JettySolrRunner> downJettys = new ArrayList<JettySolrRunner>();\n      List<String> upShards = new ArrayList<String>(Arrays.asList(shardsArr));\n      for(int i=0; i<numDownServers; i++)\n      {\n        // shut down some of the jettys\n        int indexToRemove = r.nextInt(upJettys.size());\n        JettySolrRunner downJetty = upJettys.remove(indexToRemove);\n        upClients.remove(indexToRemove);\n        upShards.remove(indexToRemove);\n        ChaosMonkey.stop(downJetty);\n        downJettys.add(downJetty);\n      }\n\n      queryPartialResults(upShards, upClients, \n          \"q\",\"*:*\",\n          \"facet\",\"true\", \n          \"facet.field\",t1,\n          \"facet.limit\",5,\n          ShardParams.SHARDS_INFO,\"true\",\n          ShardParams.SHARDS_TOLERANT,\"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"facet\", \"true\",\n          \"facet.query\", i1 + \":[1 TO 50]\",\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      // test group query\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"rows\", 100,\n          \"fl\", \"id,\" + i1,\n          \"group\", \"true\",\n          \"group.query\", t1 + \":kings OR \" + t1 + \":eggs\",\n          \"group.limit\", 10,\n          \"sort\", i1 + \" asc, id asc\",\n          CommonParams.TIME_ALLOWED, 1,\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      // restart the jettys\n      for (JettySolrRunner downJetty : downJettys) {\n        downJetty.start();\n      }\n    }\n\n    // This index has the same number for every field\n    \n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // Thread.sleep(10000000000L);\n\n    FieldCache.DEFAULT.purgeAllCaches();   // avoid FC insanity\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"c1500c4d2642ffe9c4fc6a09a7674b69a550fd36","date":1385816663,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/TestDistributedSearch#doTest().mjava","pathOld":"solr/core/src/test/org/apache/solr/TestDistributedSearch#doTest().mjava","sourceNew":"  @Override\n  public void doTest() throws Exception {\n    int backupStress = stress; // make a copy so we can restore\n\n\n    del(\"*:*\");\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\", \n           tdate_a, \"2010-04-20T11:00:00Z\",\n           tdate_b, \"2009-08-20T11:00:00Z\",\n           \"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\", \n           tdate_a, \"2010-05-02T11:00:00Z\",\n           tdate_b, \"2009-11-02T11:00:00Z\");\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\", \n           tdate_a, \"2010-05-03T11:00:00Z\");\n    indexr(id,4, i1, -100 ,tlong, 101,\n           t1,\"the quick fox jumped over the lazy dog\", \n           tdate_a, \"2010-05-03T11:00:00Z\",\n           tdate_b, \"2010-05-03T11:00:00Z\");\n    indexr(id,5, i1, 500, tlong, 500 ,\n           t1,\"the quick fox jumped way over the lazy dog\", \n           tdate_a, \"2010-05-05T11:00:00Z\");\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,\n           tdate_b, \"2010-01-05T11:00:00Z\",\n           t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n\n    commit();  // try to ensure there's more than one segment\n\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,\n           t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,\n           t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,\n           t1,\"no eggs on wall, lesson learned\", \n           oddField, \"odd man out\");\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n    \n    \n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n\n    handle.clear();\n    handle.put(\"QTime\", SKIPVAL);\n    handle.put(\"timestamp\", SKIPVAL);\n    handle.put(\"_version_\", SKIPVAL); // not a cloud test, but may use updateLog\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(\"q\",\"*:*\", \"sort\",f+\" desc\");\n      query(\"q\",\"*:*\", \"sort\",f+\" asc\");\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",\"{!func}testfunc(add(\"+i1+\",5))\"+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" asc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\");\n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"*,score\"); \n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 desc\");\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"{!func}\"+i1);// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(\"q\",\"{!func}\"+i1, \"fl\",\"*,score\");  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"quick\");\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\");\n    query(\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\");  // no fields in returned docs\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\");\n\n    handle.put(\"score\", SKIPVAL);\n    query(\"q\",\"quick\",\"fl\",\"*,score\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\");\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"matchesnothing\",\"fl\",\"*,score\");  \n\n    // test that a single NOW value is propagated to all shards... if that is true\n    // then the primary sort should always be a tie and then the secondary should always decide\n    query(\"q\",\"{!func}ms(NOW)\", \"sort\",\"score desc,\"+i1+\" desc\",\"fl\",\"id\");    \n\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\");\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2);\n\n    // a facet query to test out chars out of the ascii range\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!term f=foo_s}international\\u00ff\\u01ff\\u2222\\u3333\");\n\n    // simple date facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date.other\", \"all\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // date facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date\",tdate_b, \n          \"facet.date.other\", \"all\", \n          \"f.\"+tdate_b+\".facet.date.start\",\"2009-05-01T11:00:00Z\", \n          \"f.\"+tdate_b+\".facet.date.gap\",\"+3MONTHS\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // simple range facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"facet.range.end\",900);\n\n    // range facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range\",i1, \n          \"f.\"+i1+\".facet.range.start\",300, \n          \"f.\"+i1+\".facet.range.gap\",87, \n          \"facet.range.end\",900,\n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"f.\"+tlong+\".facet.range.end\",900);\n    \n    //  variations of fl\n    query(\"q\",\"*:*\", \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1 + \",score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", i1, \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id,\" + i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1, \"fl\", \"id\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",nint, \"fl\",tint,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",nint, \"fl\", \"id\", \"fl\",tint,\"sort\",i1 + \" desc\");\n\n    stress=0;  // turn off stress... we want to tex max combos in min time\n    for (int i=0; i<25*RANDOM_MULTIPLIER; i++) {\n      String f = fieldNames[random().nextInt(fieldNames.length)];\n      if (random().nextBoolean()) f = t1;  // the text field is a really interesting one to facet on (and it's multi-valued too)\n\n      // we want a random query and not just *:* so we'll get zero counts in facets also\n      // TODO: do a better random query\n      String q = random().nextBoolean() ? \"*:*\" : \"id:(1 3 5 7 9 11 13) OR id:[100 TO \" + random().nextInt(50) + \"]\";\n\n      int nolimit = random().nextBoolean() ? -1 : 10000;  // these should be equivalent\n\n      // if limit==-1, we should always get exact matches\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"count\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      // for index sort, we should get exact results for mincount <= 1\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(2), \"facet.offset\",random().nextInt(10), \"facet.limit\",random().nextInt(11)-1);\n    }\n    stress = backupStress;  // restore stress\n\n    // test faceting multiple things at once\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1);\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id:[1 TO 7]\", \"fq\",\"{!tag=b}id:[3 TO 9]\"\n    );\n    query(\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\");\n\n    // test field that is valid in schema but missing in all shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2);\n    // test field that is valid in schema and missing in some shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2);\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1);\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    // check a complex key name\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"*:*\", \"rows\",100);\n    }\n\n    //SOLR 3161 ensure shards.qt=/update fails (anything but search handler really)\n    // Also see TestRemoteStreaming#testQtUpdateFails()\n    try {\n      ignoreException(\"isShard is only acceptable\");\n      // query(\"q\",\"*:*\",\"shards.qt\",\"/update\",\"stream.body\",\"<delete><query>*:*</query></delete>\");\n      // fail();\n    } catch (SolrException e) {\n      //expected\n    }\n    unIgnoreException(\"isShard is only acceptable\");\n\n    // test debugging\n    // handle.put(\"explain\", UNORDERED);\n    handle.put(\"explain\", SKIPVAL);  // internal docids differ, idf differs w/o global idf\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    handle.put(\"track\", SKIP); //track is not included in single node search\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY);\n\n    // Check Info is added to for each shard\n    ModifiableSolrParams q = new ModifiableSolrParams();\n    q.set(\"q\", \"*:*\");\n    q.set(ShardParams.SHARDS_INFO, true);\n    setDistributedParams(q);\n    QueryResponse rsp = queryServer(q);\n    NamedList<?> sinfo = (NamedList<?>) rsp.getResponse().get(ShardParams.SHARDS_INFO);\n    String shards = getShardsString();\n    int cnt = StringUtils.countMatches(shards, \",\")+1;\n    \n    assertNotNull(\"missing shard info\", sinfo);\n    assertEquals(\"should have an entry for each shard [\"+sinfo+\"] \"+shards, cnt, sinfo.size());\n    \n    // test shards.tolerant=true\n    for(int numDownServers = 0; numDownServers < jettys.size()-1; numDownServers++)\n    {\n      List<JettySolrRunner> upJettys = new ArrayList<JettySolrRunner>(jettys);\n      List<SolrServer> upClients = new ArrayList<SolrServer>(clients);\n      List<JettySolrRunner> downJettys = new ArrayList<JettySolrRunner>();\n      List<String> upShards = new ArrayList<String>(Arrays.asList(shardsArr));\n      for(int i=0; i<numDownServers; i++)\n      {\n        // shut down some of the jettys\n        int indexToRemove = r.nextInt(upJettys.size());\n        JettySolrRunner downJetty = upJettys.remove(indexToRemove);\n        upClients.remove(indexToRemove);\n        upShards.remove(indexToRemove);\n        ChaosMonkey.stop(downJetty);\n        downJettys.add(downJetty);\n      }\n\n      queryPartialResults(upShards, upClients, \n          \"q\",\"*:*\",\n          \"facet\",\"true\", \n          \"facet.field\",t1,\n          \"facet.limit\",5,\n          ShardParams.SHARDS_INFO,\"true\",\n          ShardParams.SHARDS_TOLERANT,\"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"facet\", \"true\",\n          \"facet.query\", i1 + \":[1 TO 50]\",\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      // test group query\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"rows\", 100,\n          \"fl\", \"id,\" + i1,\n          \"group\", \"true\",\n          \"group.query\", t1 + \":kings OR \" + t1 + \":eggs\",\n          \"group.limit\", 10,\n          \"sort\", i1 + \" asc, id asc\",\n          CommonParams.TIME_ALLOWED, 1,\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      // restart the jettys\n      for (JettySolrRunner downJetty : downJettys) {\n        downJetty.start();\n      }\n    }\n\n    // This index has the same number for every field\n    \n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // Thread.sleep(10000000000L);\n\n    FieldCache.DEFAULT.purgeAllCaches();   // avoid FC insanity\n\n    del(\"*:*\"); // delete all docs and test stats request\n    commit();\n    try {\n      query(\"q\", \"*:*\", \"stats\", \"true\", \"stats.field\", \"stats_dt\", \"stats.calcdistinct\", \"true\");\n    } catch (Exception e) {\n      log.error(\"Exception on distrib stats request on empty index\", e);\n      fail(\"NullPointerException with stats request on empty index\");\n    }\n  }\n\n","sourceOld":"  @Override\n  public void doTest() throws Exception {\n    int backupStress = stress; // make a copy so we can restore\n\n\n    del(\"*:*\");\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\", \n           tdate_a, \"2010-04-20T11:00:00Z\",\n           tdate_b, \"2009-08-20T11:00:00Z\",\n           \"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\", \n           tdate_a, \"2010-05-02T11:00:00Z\",\n           tdate_b, \"2009-11-02T11:00:00Z\");\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\", \n           tdate_a, \"2010-05-03T11:00:00Z\");\n    indexr(id,4, i1, -100 ,tlong, 101,\n           t1,\"the quick fox jumped over the lazy dog\", \n           tdate_a, \"2010-05-03T11:00:00Z\",\n           tdate_b, \"2010-05-03T11:00:00Z\");\n    indexr(id,5, i1, 500, tlong, 500 ,\n           t1,\"the quick fox jumped way over the lazy dog\", \n           tdate_a, \"2010-05-05T11:00:00Z\");\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,\n           tdate_b, \"2010-01-05T11:00:00Z\",\n           t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n\n    commit();  // try to ensure there's more than one segment\n\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,\n           t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,\n           t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,\n           t1,\"no eggs on wall, lesson learned\", \n           oddField, \"odd man out\");\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n    \n    \n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n\n    handle.clear();\n    handle.put(\"QTime\", SKIPVAL);\n    handle.put(\"timestamp\", SKIPVAL);\n    handle.put(\"_version_\", SKIPVAL); // not a cloud test, but may use updateLog\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(\"q\",\"*:*\", \"sort\",f+\" desc\");\n      query(\"q\",\"*:*\", \"sort\",f+\" asc\");\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",\"{!func}testfunc(add(\"+i1+\",5))\"+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" asc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\");\n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"*,score\"); \n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 desc\");\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"{!func}\"+i1);// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(\"q\",\"{!func}\"+i1, \"fl\",\"*,score\");  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"quick\");\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\");\n    query(\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\");  // no fields in returned docs\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\");\n\n    handle.put(\"score\", SKIPVAL);\n    query(\"q\",\"quick\",\"fl\",\"*,score\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\");\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"matchesnothing\",\"fl\",\"*,score\");  \n\n    // test that a single NOW value is propagated to all shards... if that is true\n    // then the primary sort should always be a tie and then the secondary should always decide\n    query(\"q\",\"{!func}ms(NOW)\", \"sort\",\"score desc,\"+i1+\" desc\",\"fl\",\"id\");    \n\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\");\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2);\n\n    // a facet query to test out chars out of the ascii range\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!term f=foo_s}international\\u00ff\\u01ff\\u2222\\u3333\");\n\n    // simple date facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date.other\", \"all\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // date facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date\",tdate_b, \n          \"facet.date.other\", \"all\", \n          \"f.\"+tdate_b+\".facet.date.start\",\"2009-05-01T11:00:00Z\", \n          \"f.\"+tdate_b+\".facet.date.gap\",\"+3MONTHS\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // simple range facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"facet.range.end\",900);\n\n    // range facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range\",i1, \n          \"f.\"+i1+\".facet.range.start\",300, \n          \"f.\"+i1+\".facet.range.gap\",87, \n          \"facet.range.end\",900,\n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"f.\"+tlong+\".facet.range.end\",900);\n    \n    //  variations of fl\n    query(\"q\",\"*:*\", \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1 + \",score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", i1, \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id,\" + i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1, \"fl\", \"id\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",nint, \"fl\",tint,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",nint, \"fl\", \"id\", \"fl\",tint,\"sort\",i1 + \" desc\");\n\n    stress=0;  // turn off stress... we want to tex max combos in min time\n    for (int i=0; i<25*RANDOM_MULTIPLIER; i++) {\n      String f = fieldNames[random().nextInt(fieldNames.length)];\n      if (random().nextBoolean()) f = t1;  // the text field is a really interesting one to facet on (and it's multi-valued too)\n\n      // we want a random query and not just *:* so we'll get zero counts in facets also\n      // TODO: do a better random query\n      String q = random().nextBoolean() ? \"*:*\" : \"id:(1 3 5 7 9 11 13) OR id:[100 TO \" + random().nextInt(50) + \"]\";\n\n      int nolimit = random().nextBoolean() ? -1 : 10000;  // these should be equivalent\n\n      // if limit==-1, we should always get exact matches\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"count\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      // for index sort, we should get exact results for mincount <= 1\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(2), \"facet.offset\",random().nextInt(10), \"facet.limit\",random().nextInt(11)-1);\n    }\n    stress = backupStress;  // restore stress\n\n    // test faceting multiple things at once\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1);\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id:[1 TO 7]\", \"fq\",\"{!tag=b}id:[3 TO 9]\"\n    );\n    query(\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\");\n\n    // test field that is valid in schema but missing in all shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2);\n    // test field that is valid in schema and missing in some shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2);\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1);\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    // check a complex key name\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"*:*\", \"rows\",100);\n    }\n\n    //SOLR 3161 ensure shards.qt=/update fails (anything but search handler really)\n    // Also see TestRemoteStreaming#testQtUpdateFails()\n    try {\n      ignoreException(\"isShard is only acceptable\");\n      // query(\"q\",\"*:*\",\"shards.qt\",\"/update\",\"stream.body\",\"<delete><query>*:*</query></delete>\");\n      // fail();\n    } catch (SolrException e) {\n      //expected\n    }\n    unIgnoreException(\"isShard is only acceptable\");\n\n    // test debugging\n    // handle.put(\"explain\", UNORDERED);\n    handle.put(\"explain\", SKIPVAL);  // internal docids differ, idf differs w/o global idf\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    handle.put(\"track\", SKIP); //track is not included in single node search\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY);\n\n    // Check Info is added to for each shard\n    ModifiableSolrParams q = new ModifiableSolrParams();\n    q.set(\"q\", \"*:*\");\n    q.set(ShardParams.SHARDS_INFO, true);\n    setDistributedParams(q);\n    QueryResponse rsp = queryServer(q);\n    NamedList<?> sinfo = (NamedList<?>) rsp.getResponse().get(ShardParams.SHARDS_INFO);\n    String shards = getShardsString();\n    int cnt = StringUtils.countMatches(shards, \",\")+1;\n    \n    assertNotNull(\"missing shard info\", sinfo);\n    assertEquals(\"should have an entry for each shard [\"+sinfo+\"] \"+shards, cnt, sinfo.size());\n    \n    // test shards.tolerant=true\n    for(int numDownServers = 0; numDownServers < jettys.size()-1; numDownServers++)\n    {\n      List<JettySolrRunner> upJettys = new ArrayList<JettySolrRunner>(jettys);\n      List<SolrServer> upClients = new ArrayList<SolrServer>(clients);\n      List<JettySolrRunner> downJettys = new ArrayList<JettySolrRunner>();\n      List<String> upShards = new ArrayList<String>(Arrays.asList(shardsArr));\n      for(int i=0; i<numDownServers; i++)\n      {\n        // shut down some of the jettys\n        int indexToRemove = r.nextInt(upJettys.size());\n        JettySolrRunner downJetty = upJettys.remove(indexToRemove);\n        upClients.remove(indexToRemove);\n        upShards.remove(indexToRemove);\n        ChaosMonkey.stop(downJetty);\n        downJettys.add(downJetty);\n      }\n\n      queryPartialResults(upShards, upClients, \n          \"q\",\"*:*\",\n          \"facet\",\"true\", \n          \"facet.field\",t1,\n          \"facet.limit\",5,\n          ShardParams.SHARDS_INFO,\"true\",\n          ShardParams.SHARDS_TOLERANT,\"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"facet\", \"true\",\n          \"facet.query\", i1 + \":[1 TO 50]\",\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      // test group query\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"rows\", 100,\n          \"fl\", \"id,\" + i1,\n          \"group\", \"true\",\n          \"group.query\", t1 + \":kings OR \" + t1 + \":eggs\",\n          \"group.limit\", 10,\n          \"sort\", i1 + \" asc, id asc\",\n          CommonParams.TIME_ALLOWED, 1,\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      // restart the jettys\n      for (JettySolrRunner downJetty : downJettys) {\n        downJetty.start();\n      }\n    }\n\n    // This index has the same number for every field\n    \n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // Thread.sleep(10000000000L);\n\n    FieldCache.DEFAULT.purgeAllCaches();   // avoid FC insanity\n  }\n\n","bugFix":null,"bugIntro":["9274621789ce990dbfef455dabdf026bb3184821","e6a0af6f7a7677267ad84c35bc106a61fd67dc62"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"0d9835c6ddd23dd02eefd5adfc0e5d1e89075fbe","date":1385910402,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/TestDistributedSearch#doTest().mjava","pathOld":"solr/core/src/test/org/apache/solr/TestDistributedSearch#doTest().mjava","sourceNew":"  @Override\n  public void doTest() throws Exception {\n    int backupStress = stress; // make a copy so we can restore\n\n\n    del(\"*:*\");\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\", \n           tdate_a, \"2010-04-20T11:00:00Z\",\n           tdate_b, \"2009-08-20T11:00:00Z\",\n           \"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\", \n           tdate_a, \"2010-05-02T11:00:00Z\",\n           tdate_b, \"2009-11-02T11:00:00Z\");\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\", \n           tdate_a, \"2010-05-03T11:00:00Z\");\n    indexr(id,4, i1, -100 ,tlong, 101,\n           t1,\"the quick fox jumped over the lazy dog\", \n           tdate_a, \"2010-05-03T11:00:00Z\",\n           tdate_b, \"2010-05-03T11:00:00Z\");\n    indexr(id,5, i1, 500, tlong, 500 ,\n           t1,\"the quick fox jumped way over the lazy dog\", \n           tdate_a, \"2010-05-05T11:00:00Z\");\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,\n           tdate_b, \"2010-01-05T11:00:00Z\",\n           t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n\n    commit();  // try to ensure there's more than one segment\n\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,\n           t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,\n           t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,\n           t1,\"no eggs on wall, lesson learned\", \n           oddField, \"odd man out\");\n\n    indexr(id, \"1001\", \"lowerfilt\", \"toyota\"); // for spellcheck\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n    \n    \n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n\n    handle.clear();\n    handle.put(\"QTime\", SKIPVAL);\n    handle.put(\"timestamp\", SKIPVAL);\n    handle.put(\"_version_\", SKIPVAL); // not a cloud test, but may use updateLog\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(\"q\",\"*:*\", \"sort\",f+\" desc\");\n      query(\"q\",\"*:*\", \"sort\",f+\" asc\");\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",\"{!func}testfunc(add(\"+i1+\",5))\"+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" asc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\");\n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"*,score\"); \n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 desc\");\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"{!func}\"+i1);// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(\"q\",\"{!func}\"+i1, \"fl\",\"*,score\");  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"quick\");\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\");\n    query(\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\");  // no fields in returned docs\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\");\n\n    handle.put(\"score\", SKIPVAL);\n    query(\"q\",\"quick\",\"fl\",\"*,score\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\");\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"matchesnothing\",\"fl\",\"*,score\");  \n\n    // test that a single NOW value is propagated to all shards... if that is true\n    // then the primary sort should always be a tie and then the secondary should always decide\n    query(\"q\",\"{!func}ms(NOW)\", \"sort\",\"score desc,\"+i1+\" desc\",\"fl\",\"id\");    \n\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\");\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2);\n\n    // a facet query to test out chars out of the ascii range\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!term f=foo_s}international\\u00ff\\u01ff\\u2222\\u3333\");\n\n    // simple date facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date.other\", \"all\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // date facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date\",tdate_b, \n          \"facet.date.other\", \"all\", \n          \"f.\"+tdate_b+\".facet.date.start\",\"2009-05-01T11:00:00Z\", \n          \"f.\"+tdate_b+\".facet.date.gap\",\"+3MONTHS\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // simple range facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"facet.range.end\",900);\n\n    // range facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range\",i1, \n          \"f.\"+i1+\".facet.range.start\",300, \n          \"f.\"+i1+\".facet.range.gap\",87, \n          \"facet.range.end\",900,\n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"f.\"+tlong+\".facet.range.end\",900);\n    \n    //  variations of fl\n    query(\"q\",\"*:*\", \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1 + \",score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", i1, \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id,\" + i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1, \"fl\", \"id\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",nint, \"fl\",tint,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",nint, \"fl\", \"id\", \"fl\",tint,\"sort\",i1 + \" desc\");\n\n    // basic spellcheck testing\n    query(\"q\", \"toyata\", \"fl\", \"id,lowerfilt\", \"spellcheck\", true, \"spellcheck.q\", \"toyata\", \"qt\", \"spellCheckCompRH_Direct\", \"shards.qt\", \"spellCheckCompRH_Direct\");\n\n    stress=0;  // turn off stress... we want to tex max combos in min time\n    for (int i=0; i<25*RANDOM_MULTIPLIER; i++) {\n      String f = fieldNames[random().nextInt(fieldNames.length)];\n      if (random().nextBoolean()) f = t1;  // the text field is a really interesting one to facet on (and it's multi-valued too)\n\n      // we want a random query and not just *:* so we'll get zero counts in facets also\n      // TODO: do a better random query\n      String q = random().nextBoolean() ? \"*:*\" : \"id:(1 3 5 7 9 11 13) OR id:[100 TO \" + random().nextInt(50) + \"]\";\n\n      int nolimit = random().nextBoolean() ? -1 : 10000;  // these should be equivalent\n\n      // if limit==-1, we should always get exact matches\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"count\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      // for index sort, we should get exact results for mincount <= 1\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(2), \"facet.offset\",random().nextInt(10), \"facet.limit\",random().nextInt(11)-1);\n    }\n    stress = backupStress;  // restore stress\n\n    // test faceting multiple things at once\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1);\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id:[1 TO 7]\", \"fq\",\"{!tag=b}id:[3 TO 9]\"\n    );\n    query(\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\");\n\n    // test field that is valid in schema but missing in all shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2);\n    // test field that is valid in schema and missing in some shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2);\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1);\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    // check a complex key name\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"*:*\", \"rows\",100);\n    }\n\n    //SOLR 3161 ensure shards.qt=/update fails (anything but search handler really)\n    // Also see TestRemoteStreaming#testQtUpdateFails()\n    try {\n      ignoreException(\"isShard is only acceptable\");\n      // query(\"q\",\"*:*\",\"shards.qt\",\"/update\",\"stream.body\",\"<delete><query>*:*</query></delete>\");\n      // fail();\n    } catch (SolrException e) {\n      //expected\n    }\n    unIgnoreException(\"isShard is only acceptable\");\n\n    // test debugging\n    // handle.put(\"explain\", UNORDERED);\n    handle.put(\"explain\", SKIPVAL);  // internal docids differ, idf differs w/o global idf\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    handle.put(\"track\", SKIP); //track is not included in single node search\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY);\n\n    // Check Info is added to for each shard\n    ModifiableSolrParams q = new ModifiableSolrParams();\n    q.set(\"q\", \"*:*\");\n    q.set(ShardParams.SHARDS_INFO, true);\n    setDistributedParams(q);\n    QueryResponse rsp = queryServer(q);\n    NamedList<?> sinfo = (NamedList<?>) rsp.getResponse().get(ShardParams.SHARDS_INFO);\n    String shards = getShardsString();\n    int cnt = StringUtils.countMatches(shards, \",\")+1;\n    \n    assertNotNull(\"missing shard info\", sinfo);\n    assertEquals(\"should have an entry for each shard [\"+sinfo+\"] \"+shards, cnt, sinfo.size());\n\n    // test shards.tolerant=true\n    for(int numDownServers = 0; numDownServers < jettys.size()-1; numDownServers++)\n    {\n      List<JettySolrRunner> upJettys = new ArrayList<JettySolrRunner>(jettys);\n      List<SolrServer> upClients = new ArrayList<SolrServer>(clients);\n      List<JettySolrRunner> downJettys = new ArrayList<JettySolrRunner>();\n      List<String> upShards = new ArrayList<String>(Arrays.asList(shardsArr));\n      for(int i=0; i<numDownServers; i++)\n      {\n        // shut down some of the jettys\n        int indexToRemove = r.nextInt(upJettys.size());\n        JettySolrRunner downJetty = upJettys.remove(indexToRemove);\n        upClients.remove(indexToRemove);\n        upShards.remove(indexToRemove);\n        ChaosMonkey.stop(downJetty);\n        downJettys.add(downJetty);\n      }\n\n      queryPartialResults(upShards, upClients, \n          \"q\",\"*:*\",\n          \"facet\",\"true\", \n          \"facet.field\",t1,\n          \"facet.limit\",5,\n          ShardParams.SHARDS_INFO,\"true\",\n          ShardParams.SHARDS_TOLERANT,\"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"facet\", \"true\",\n          \"facet.query\", i1 + \":[1 TO 50]\",\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      // test group query\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"rows\", 100,\n          \"fl\", \"id,\" + i1,\n          \"group\", \"true\",\n          \"group.query\", t1 + \":kings OR \" + t1 + \":eggs\",\n          \"group.limit\", 10,\n          \"sort\", i1 + \" asc, id asc\",\n          CommonParams.TIME_ALLOWED, 1,\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"stats\", \"true\",\n          \"stats.field\", i1,\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"toyata\",\n          \"spellcheck\", \"true\",\n          \"spellcheck.q\", \"toyata\",\n          \"qt\", \"spellCheckCompRH_Direct\",\n          \"shards.qt\", \"spellCheckCompRH_Direct\",\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      // restart the jettys\n      for (JettySolrRunner downJetty : downJettys) {\n        downJetty.start();\n      }\n    }\n\n    // This index has the same number for every field\n    \n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // Thread.sleep(10000000000L);\n\n    FieldCache.DEFAULT.purgeAllCaches();   // avoid FC insanity\n\n    del(\"*:*\"); // delete all docs and test stats request\n    commit();\n    try {\n      query(\"q\", \"*:*\", \"stats\", \"true\", \"stats.field\", \"stats_dt\", \"stats.calcdistinct\", \"true\");\n    } catch (Exception e) {\n      log.error(\"Exception on distrib stats request on empty index\", e);\n      fail(\"NullPointerException with stats request on empty index\");\n    }\n  }\n\n","sourceOld":"  @Override\n  public void doTest() throws Exception {\n    int backupStress = stress; // make a copy so we can restore\n\n\n    del(\"*:*\");\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\", \n           tdate_a, \"2010-04-20T11:00:00Z\",\n           tdate_b, \"2009-08-20T11:00:00Z\",\n           \"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\", \n           tdate_a, \"2010-05-02T11:00:00Z\",\n           tdate_b, \"2009-11-02T11:00:00Z\");\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\", \n           tdate_a, \"2010-05-03T11:00:00Z\");\n    indexr(id,4, i1, -100 ,tlong, 101,\n           t1,\"the quick fox jumped over the lazy dog\", \n           tdate_a, \"2010-05-03T11:00:00Z\",\n           tdate_b, \"2010-05-03T11:00:00Z\");\n    indexr(id,5, i1, 500, tlong, 500 ,\n           t1,\"the quick fox jumped way over the lazy dog\", \n           tdate_a, \"2010-05-05T11:00:00Z\");\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,\n           tdate_b, \"2010-01-05T11:00:00Z\",\n           t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n\n    commit();  // try to ensure there's more than one segment\n\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,\n           t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,\n           t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,\n           t1,\"no eggs on wall, lesson learned\", \n           oddField, \"odd man out\");\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n    \n    \n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n\n    handle.clear();\n    handle.put(\"QTime\", SKIPVAL);\n    handle.put(\"timestamp\", SKIPVAL);\n    handle.put(\"_version_\", SKIPVAL); // not a cloud test, but may use updateLog\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(\"q\",\"*:*\", \"sort\",f+\" desc\");\n      query(\"q\",\"*:*\", \"sort\",f+\" asc\");\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",\"{!func}testfunc(add(\"+i1+\",5))\"+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" asc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\");\n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"*,score\"); \n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 desc\");\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"{!func}\"+i1);// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(\"q\",\"{!func}\"+i1, \"fl\",\"*,score\");  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"quick\");\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\");\n    query(\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\");  // no fields in returned docs\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\");\n\n    handle.put(\"score\", SKIPVAL);\n    query(\"q\",\"quick\",\"fl\",\"*,score\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\");\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"matchesnothing\",\"fl\",\"*,score\");  \n\n    // test that a single NOW value is propagated to all shards... if that is true\n    // then the primary sort should always be a tie and then the secondary should always decide\n    query(\"q\",\"{!func}ms(NOW)\", \"sort\",\"score desc,\"+i1+\" desc\",\"fl\",\"id\");    \n\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\");\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2);\n\n    // a facet query to test out chars out of the ascii range\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!term f=foo_s}international\\u00ff\\u01ff\\u2222\\u3333\");\n\n    // simple date facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date.other\", \"all\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // date facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date\",tdate_b, \n          \"facet.date.other\", \"all\", \n          \"f.\"+tdate_b+\".facet.date.start\",\"2009-05-01T11:00:00Z\", \n          \"f.\"+tdate_b+\".facet.date.gap\",\"+3MONTHS\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // simple range facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"facet.range.end\",900);\n\n    // range facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range\",i1, \n          \"f.\"+i1+\".facet.range.start\",300, \n          \"f.\"+i1+\".facet.range.gap\",87, \n          \"facet.range.end\",900,\n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"f.\"+tlong+\".facet.range.end\",900);\n    \n    //  variations of fl\n    query(\"q\",\"*:*\", \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1 + \",score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", i1, \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id,\" + i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1, \"fl\", \"id\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",nint, \"fl\",tint,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",nint, \"fl\", \"id\", \"fl\",tint,\"sort\",i1 + \" desc\");\n\n    stress=0;  // turn off stress... we want to tex max combos in min time\n    for (int i=0; i<25*RANDOM_MULTIPLIER; i++) {\n      String f = fieldNames[random().nextInt(fieldNames.length)];\n      if (random().nextBoolean()) f = t1;  // the text field is a really interesting one to facet on (and it's multi-valued too)\n\n      // we want a random query and not just *:* so we'll get zero counts in facets also\n      // TODO: do a better random query\n      String q = random().nextBoolean() ? \"*:*\" : \"id:(1 3 5 7 9 11 13) OR id:[100 TO \" + random().nextInt(50) + \"]\";\n\n      int nolimit = random().nextBoolean() ? -1 : 10000;  // these should be equivalent\n\n      // if limit==-1, we should always get exact matches\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"count\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      // for index sort, we should get exact results for mincount <= 1\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(2), \"facet.offset\",random().nextInt(10), \"facet.limit\",random().nextInt(11)-1);\n    }\n    stress = backupStress;  // restore stress\n\n    // test faceting multiple things at once\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1);\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id:[1 TO 7]\", \"fq\",\"{!tag=b}id:[3 TO 9]\"\n    );\n    query(\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\");\n\n    // test field that is valid in schema but missing in all shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2);\n    // test field that is valid in schema and missing in some shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2);\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1);\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    // check a complex key name\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"*:*\", \"rows\",100);\n    }\n\n    //SOLR 3161 ensure shards.qt=/update fails (anything but search handler really)\n    // Also see TestRemoteStreaming#testQtUpdateFails()\n    try {\n      ignoreException(\"isShard is only acceptable\");\n      // query(\"q\",\"*:*\",\"shards.qt\",\"/update\",\"stream.body\",\"<delete><query>*:*</query></delete>\");\n      // fail();\n    } catch (SolrException e) {\n      //expected\n    }\n    unIgnoreException(\"isShard is only acceptable\");\n\n    // test debugging\n    // handle.put(\"explain\", UNORDERED);\n    handle.put(\"explain\", SKIPVAL);  // internal docids differ, idf differs w/o global idf\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    handle.put(\"track\", SKIP); //track is not included in single node search\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY);\n\n    // Check Info is added to for each shard\n    ModifiableSolrParams q = new ModifiableSolrParams();\n    q.set(\"q\", \"*:*\");\n    q.set(ShardParams.SHARDS_INFO, true);\n    setDistributedParams(q);\n    QueryResponse rsp = queryServer(q);\n    NamedList<?> sinfo = (NamedList<?>) rsp.getResponse().get(ShardParams.SHARDS_INFO);\n    String shards = getShardsString();\n    int cnt = StringUtils.countMatches(shards, \",\")+1;\n    \n    assertNotNull(\"missing shard info\", sinfo);\n    assertEquals(\"should have an entry for each shard [\"+sinfo+\"] \"+shards, cnt, sinfo.size());\n    \n    // test shards.tolerant=true\n    for(int numDownServers = 0; numDownServers < jettys.size()-1; numDownServers++)\n    {\n      List<JettySolrRunner> upJettys = new ArrayList<JettySolrRunner>(jettys);\n      List<SolrServer> upClients = new ArrayList<SolrServer>(clients);\n      List<JettySolrRunner> downJettys = new ArrayList<JettySolrRunner>();\n      List<String> upShards = new ArrayList<String>(Arrays.asList(shardsArr));\n      for(int i=0; i<numDownServers; i++)\n      {\n        // shut down some of the jettys\n        int indexToRemove = r.nextInt(upJettys.size());\n        JettySolrRunner downJetty = upJettys.remove(indexToRemove);\n        upClients.remove(indexToRemove);\n        upShards.remove(indexToRemove);\n        ChaosMonkey.stop(downJetty);\n        downJettys.add(downJetty);\n      }\n\n      queryPartialResults(upShards, upClients, \n          \"q\",\"*:*\",\n          \"facet\",\"true\", \n          \"facet.field\",t1,\n          \"facet.limit\",5,\n          ShardParams.SHARDS_INFO,\"true\",\n          ShardParams.SHARDS_TOLERANT,\"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"facet\", \"true\",\n          \"facet.query\", i1 + \":[1 TO 50]\",\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      // test group query\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"rows\", 100,\n          \"fl\", \"id,\" + i1,\n          \"group\", \"true\",\n          \"group.query\", t1 + \":kings OR \" + t1 + \":eggs\",\n          \"group.limit\", 10,\n          \"sort\", i1 + \" asc, id asc\",\n          CommonParams.TIME_ALLOWED, 1,\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      // restart the jettys\n      for (JettySolrRunner downJetty : downJettys) {\n        downJetty.start();\n      }\n    }\n\n    // This index has the same number for every field\n    \n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // Thread.sleep(10000000000L);\n\n    FieldCache.DEFAULT.purgeAllCaches();   // avoid FC insanity\n\n    del(\"*:*\"); // delete all docs and test stats request\n    commit();\n    try {\n      query(\"q\", \"*:*\", \"stats\", \"true\", \"stats.field\", \"stats_dt\", \"stats.calcdistinct\", \"true\");\n    } catch (Exception e) {\n      log.error(\"Exception on distrib stats request on empty index\", e);\n      fail(\"NullPointerException with stats request on empty index\");\n    }\n  }\n\n","bugFix":["d66363068e87a246ce08fee4a42f30f126b92723"],"bugIntro":["bb222a3f9d9421d5c95afce73013fbd8de07ea1f","8c19c480d77a53905bbd65f04e90fa35925c0f9b"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"74f45af4339b0daf7a95c820ab88c1aea74fbce0","date":1387475327,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/TestDistributedSearch#doTest().mjava","pathOld":"solr/core/src/test/org/apache/solr/TestDistributedSearch#doTest().mjava","sourceNew":"  @Override\n  public void doTest() throws Exception {\n    int backupStress = stress; // make a copy so we can restore\n\n\n    del(\"*:*\");\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\", \n           tdate_a, \"2010-04-20T11:00:00Z\",\n           tdate_b, \"2009-08-20T11:00:00Z\",\n           \"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\", \n           tdate_a, \"2010-05-02T11:00:00Z\",\n           tdate_b, \"2009-11-02T11:00:00Z\");\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\", \n           tdate_a, \"2010-05-03T11:00:00Z\");\n    indexr(id,4, i1, -100 ,tlong, 101,\n           t1,\"the quick fox jumped over the lazy dog\", \n           tdate_a, \"2010-05-03T11:00:00Z\",\n           tdate_b, \"2010-05-03T11:00:00Z\");\n    indexr(id,5, i1, 500, tlong, 500 ,\n           t1,\"the quick fox jumped way over the lazy dog\", \n           tdate_a, \"2010-05-05T11:00:00Z\");\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,\n           tdate_b, \"2010-01-05T11:00:00Z\",\n           t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n\n    commit();  // try to ensure there's more than one segment\n\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,\n           t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,\n           t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,\n           t1,\"no eggs on wall, lesson learned\", \n           oddField, \"odd man out\");\n\n    indexr(id, \"1001\", \"lowerfilt\", \"toyota\"); // for spellcheck\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n    \n    \n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n\n    handle.clear();\n    handle.put(\"QTime\", SKIPVAL);\n    handle.put(\"timestamp\", SKIPVAL);\n    handle.put(\"_version_\", SKIPVAL); // not a cloud test, but may use updateLog\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(\"q\",\"*:*\", \"sort\",f+\" desc\");\n      query(\"q\",\"*:*\", \"sort\",f+\" asc\");\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",\"{!func}testfunc(add(\"+i1+\",5))\"+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" asc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\");\n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"*,score\"); \n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 desc\");\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"{!func}\"+i1);// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(\"q\",\"{!func}\"+i1, \"fl\",\"*,score\");  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"quick\");\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\");\n    query(\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\");  // no fields in returned docs\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\");\n\n    handle.put(\"score\", SKIPVAL);\n    query(\"q\",\"quick\",\"fl\",\"*,score\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\");\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"matchesnothing\",\"fl\",\"*,score\");  \n\n    // test that a single NOW value is propagated to all shards... if that is true\n    // then the primary sort should always be a tie and then the secondary should always decide\n    query(\"q\",\"{!func}ms(NOW)\", \"sort\",\"score desc,\"+i1+\" desc\",\"fl\",\"id\");    \n\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\");\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2);\n\n    // a facet query to test out chars out of the ascii range\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!term f=foo_s}international\\u00ff\\u01ff\\u2222\\u3333\");\n\n    // simple date facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date.other\", \"all\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // date facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date\",tdate_b, \n          \"facet.date.other\", \"all\", \n          \"f.\"+tdate_b+\".facet.date.start\",\"2009-05-01T11:00:00Z\", \n          \"f.\"+tdate_b+\".facet.date.gap\",\"+3MONTHS\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // simple range facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"facet.range.end\",900);\n\n    // range facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range\",i1, \n          \"f.\"+i1+\".facet.range.start\",300, \n          \"f.\"+i1+\".facet.range.gap\",87, \n          \"facet.range.end\",900,\n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"f.\"+tlong+\".facet.range.end\",900);\n    \n    //  variations of fl\n    query(\"q\",\"*:*\", \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1 + \",score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", i1, \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id,\" + i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1, \"fl\", \"id\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",nint, \"fl\",tint,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",nint, \"fl\", \"id\", \"fl\",tint,\"sort\",i1 + \" desc\");\n\n    // basic spellcheck testing\n    query(\"q\", \"toyata\", \"fl\", \"id,lowerfilt\", \"spellcheck\", true, \"spellcheck.q\", \"toyata\", \"qt\", \"spellCheckCompRH_Direct\", \"shards.qt\", \"spellCheckCompRH_Direct\");\n\n    stress=0;  // turn off stress... we want to tex max combos in min time\n    for (int i=0; i<25*RANDOM_MULTIPLIER; i++) {\n      String f = fieldNames[random().nextInt(fieldNames.length)];\n      if (random().nextBoolean()) f = t1;  // the text field is a really interesting one to facet on (and it's multi-valued too)\n\n      // we want a random query and not just *:* so we'll get zero counts in facets also\n      // TODO: do a better random query\n      String q = random().nextBoolean() ? \"*:*\" : \"id:(1 3 5 7 9 11 13) OR id:[100 TO \" + random().nextInt(50) + \"]\";\n\n      int nolimit = random().nextBoolean() ? -1 : 10000;  // these should be equivalent\n\n      // if limit==-1, we should always get exact matches\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"count\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      // for index sort, we should get exact results for mincount <= 1\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(2), \"facet.offset\",random().nextInt(10), \"facet.limit\",random().nextInt(11)-1);\n    }\n    stress = backupStress;  // restore stress\n\n    // test faceting multiple things at once\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1);\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id:[1 TO 7]\", \"fq\",\"{!tag=b}id:[3 TO 9]\"\n    );\n    query(\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\");\n\n    // test field that is valid in schema but missing in all shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2);\n    // test field that is valid in schema and missing in some shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2);\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1);\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    // check a complex key name\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"*:*\", \"rows\",100);\n    }\n\n    //SOLR 3161 ensure shards.qt=/update fails (anything but search handler really)\n    // Also see TestRemoteStreaming#testQtUpdateFails()\n    try {\n      ignoreException(\"isShard is only acceptable\");\n      // query(\"q\",\"*:*\",\"shards.qt\",\"/update\",\"stream.body\",\"<delete><query>*:*</query></delete>\");\n      // fail();\n    } catch (SolrException e) {\n      //expected\n    }\n    unIgnoreException(\"isShard is only acceptable\");\n\n    // test debugging\n    // handle.put(\"explain\", UNORDERED);\n    handle.put(\"explain\", SKIPVAL);  // internal docids differ, idf differs w/o global idf\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    handle.put(\"track\", SKIP); //track is not included in single node search\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY);\n\n    // Check Info is added to for each shard\n    ModifiableSolrParams q = new ModifiableSolrParams();\n    q.set(\"q\", \"*:*\");\n    q.set(ShardParams.SHARDS_INFO, true);\n    setDistributedParams(q);\n    QueryResponse rsp = queryServer(q);\n    NamedList<?> sinfo = (NamedList<?>) rsp.getResponse().get(ShardParams.SHARDS_INFO);\n    String shards = getShardsString();\n    int cnt = StringUtils.countMatches(shards, \",\")+1;\n    \n    assertNotNull(\"missing shard info\", sinfo);\n    assertEquals(\"should have an entry for each shard [\"+sinfo+\"] \"+shards, cnt, sinfo.size());\n\n    // test shards.tolerant=true\n    for(int numDownServers = 0; numDownServers < jettys.size()-1; numDownServers++)\n    {\n      List<JettySolrRunner> upJettys = new ArrayList<JettySolrRunner>(jettys);\n      List<SolrServer> upClients = new ArrayList<SolrServer>(clients);\n      List<JettySolrRunner> downJettys = new ArrayList<JettySolrRunner>();\n      List<String> upShards = new ArrayList<String>(Arrays.asList(shardsArr));\n      for(int i=0; i<numDownServers; i++)\n      {\n        // shut down some of the jettys\n        int indexToRemove = r.nextInt(upJettys.size());\n        JettySolrRunner downJetty = upJettys.remove(indexToRemove);\n        upClients.remove(indexToRemove);\n        upShards.remove(indexToRemove);\n        ChaosMonkey.stop(downJetty);\n        downJettys.add(downJetty);\n      }\n\n      queryPartialResults(upShards, upClients, \n          \"q\",\"*:*\",\n          \"facet\",\"true\", \n          \"facet.field\",t1,\n          \"facet.limit\",5,\n          ShardParams.SHARDS_INFO,\"true\",\n          ShardParams.SHARDS_TOLERANT,\"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"facet\", \"true\",\n          \"facet.query\", i1 + \":[1 TO 50]\",\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      // test group query\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"rows\", 100,\n          \"fl\", \"id,\" + i1,\n          \"group\", \"true\",\n          \"group.query\", t1 + \":kings OR \" + t1 + \":eggs\",\n          \"group.limit\", 10,\n          \"sort\", i1 + \" asc, id asc\",\n          CommonParams.TIME_ALLOWED, 1,\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"stats\", \"true\",\n          \"stats.field\", i1,\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"toyata\",\n          \"spellcheck\", \"true\",\n          \"spellcheck.q\", \"toyata\",\n          \"qt\", \"spellCheckCompRH_Direct\",\n          \"shards.qt\", \"spellCheckCompRH_Direct\",\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      // restart the jettys\n      for (JettySolrRunner downJetty : downJettys) {\n        downJetty.start();\n      }\n    }\n\n    // This index has the same number for every field\n    \n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // Thread.sleep(10000000000L);\n\n    FieldCache.DEFAULT.purgeAllCaches();   // avoid FC insanity\n\n    del(\"*:*\"); // delete all docs and test stats request\n    commit();\n    try {\n      query(\"q\", \"*:*\", \"stats\", \"true\", \"stats.field\", \"stats_dt\", \"stats.calcdistinct\", \"true\");\n    } catch (Exception e) {\n      log.error(\"Exception on distrib stats request on empty index\", e);\n      fail(\"NullPointerException with stats request on empty index\");\n    }\n  }\n\n","sourceOld":"  @Override\n  public void doTest() throws Exception {\n    int backupStress = stress; // make a copy so we can restore\n\n\n    del(\"*:*\");\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\", \n           tdate_a, \"2010-04-20T11:00:00Z\",\n           tdate_b, \"2009-08-20T11:00:00Z\",\n           \"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\", \n           tdate_a, \"2010-05-02T11:00:00Z\",\n           tdate_b, \"2009-11-02T11:00:00Z\");\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\", \n           tdate_a, \"2010-05-03T11:00:00Z\");\n    indexr(id,4, i1, -100 ,tlong, 101,\n           t1,\"the quick fox jumped over the lazy dog\", \n           tdate_a, \"2010-05-03T11:00:00Z\",\n           tdate_b, \"2010-05-03T11:00:00Z\");\n    indexr(id,5, i1, 500, tlong, 500 ,\n           t1,\"the quick fox jumped way over the lazy dog\", \n           tdate_a, \"2010-05-05T11:00:00Z\");\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,\n           tdate_b, \"2010-01-05T11:00:00Z\",\n           t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n\n    commit();  // try to ensure there's more than one segment\n\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,\n           t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,\n           t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,\n           t1,\"no eggs on wall, lesson learned\", \n           oddField, \"odd man out\");\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n    \n    \n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n\n    handle.clear();\n    handle.put(\"QTime\", SKIPVAL);\n    handle.put(\"timestamp\", SKIPVAL);\n    handle.put(\"_version_\", SKIPVAL); // not a cloud test, but may use updateLog\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(\"q\",\"*:*\", \"sort\",f+\" desc\");\n      query(\"q\",\"*:*\", \"sort\",f+\" asc\");\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",\"{!func}testfunc(add(\"+i1+\",5))\"+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" asc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\");\n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"*,score\"); \n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 desc\");\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"{!func}\"+i1);// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(\"q\",\"{!func}\"+i1, \"fl\",\"*,score\");  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"quick\");\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\");\n    query(\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\");  // no fields in returned docs\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\");\n\n    handle.put(\"score\", SKIPVAL);\n    query(\"q\",\"quick\",\"fl\",\"*,score\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\");\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"matchesnothing\",\"fl\",\"*,score\");  \n\n    // test that a single NOW value is propagated to all shards... if that is true\n    // then the primary sort should always be a tie and then the secondary should always decide\n    query(\"q\",\"{!func}ms(NOW)\", \"sort\",\"score desc,\"+i1+\" desc\",\"fl\",\"id\");    \n\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\");\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2);\n\n    // a facet query to test out chars out of the ascii range\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!term f=foo_s}international\\u00ff\\u01ff\\u2222\\u3333\");\n\n    // simple date facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date.other\", \"all\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // date facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date\",tdate_b, \n          \"facet.date.other\", \"all\", \n          \"f.\"+tdate_b+\".facet.date.start\",\"2009-05-01T11:00:00Z\", \n          \"f.\"+tdate_b+\".facet.date.gap\",\"+3MONTHS\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // simple range facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"facet.range.end\",900);\n\n    // range facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range\",i1, \n          \"f.\"+i1+\".facet.range.start\",300, \n          \"f.\"+i1+\".facet.range.gap\",87, \n          \"facet.range.end\",900,\n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"f.\"+tlong+\".facet.range.end\",900);\n    \n    //  variations of fl\n    query(\"q\",\"*:*\", \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1 + \",score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", i1, \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id,\" + i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1, \"fl\", \"id\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",nint, \"fl\",tint,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",nint, \"fl\", \"id\", \"fl\",tint,\"sort\",i1 + \" desc\");\n\n    stress=0;  // turn off stress... we want to tex max combos in min time\n    for (int i=0; i<25*RANDOM_MULTIPLIER; i++) {\n      String f = fieldNames[random().nextInt(fieldNames.length)];\n      if (random().nextBoolean()) f = t1;  // the text field is a really interesting one to facet on (and it's multi-valued too)\n\n      // we want a random query and not just *:* so we'll get zero counts in facets also\n      // TODO: do a better random query\n      String q = random().nextBoolean() ? \"*:*\" : \"id:(1 3 5 7 9 11 13) OR id:[100 TO \" + random().nextInt(50) + \"]\";\n\n      int nolimit = random().nextBoolean() ? -1 : 10000;  // these should be equivalent\n\n      // if limit==-1, we should always get exact matches\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"count\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      // for index sort, we should get exact results for mincount <= 1\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(2), \"facet.offset\",random().nextInt(10), \"facet.limit\",random().nextInt(11)-1);\n    }\n    stress = backupStress;  // restore stress\n\n    // test faceting multiple things at once\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1);\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id:[1 TO 7]\", \"fq\",\"{!tag=b}id:[3 TO 9]\"\n    );\n    query(\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\");\n\n    // test field that is valid in schema but missing in all shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2);\n    // test field that is valid in schema and missing in some shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2);\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1);\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    // check a complex key name\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"*:*\", \"rows\",100);\n    }\n\n    //SOLR 3161 ensure shards.qt=/update fails (anything but search handler really)\n    // Also see TestRemoteStreaming#testQtUpdateFails()\n    try {\n      ignoreException(\"isShard is only acceptable\");\n      // query(\"q\",\"*:*\",\"shards.qt\",\"/update\",\"stream.body\",\"<delete><query>*:*</query></delete>\");\n      // fail();\n    } catch (SolrException e) {\n      //expected\n    }\n    unIgnoreException(\"isShard is only acceptable\");\n\n    // test debugging\n    // handle.put(\"explain\", UNORDERED);\n    handle.put(\"explain\", SKIPVAL);  // internal docids differ, idf differs w/o global idf\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    handle.put(\"track\", SKIP); //track is not included in single node search\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY);\n\n    // Check Info is added to for each shard\n    ModifiableSolrParams q = new ModifiableSolrParams();\n    q.set(\"q\", \"*:*\");\n    q.set(ShardParams.SHARDS_INFO, true);\n    setDistributedParams(q);\n    QueryResponse rsp = queryServer(q);\n    NamedList<?> sinfo = (NamedList<?>) rsp.getResponse().get(ShardParams.SHARDS_INFO);\n    String shards = getShardsString();\n    int cnt = StringUtils.countMatches(shards, \",\")+1;\n    \n    assertNotNull(\"missing shard info\", sinfo);\n    assertEquals(\"should have an entry for each shard [\"+sinfo+\"] \"+shards, cnt, sinfo.size());\n    \n    // test shards.tolerant=true\n    for(int numDownServers = 0; numDownServers < jettys.size()-1; numDownServers++)\n    {\n      List<JettySolrRunner> upJettys = new ArrayList<JettySolrRunner>(jettys);\n      List<SolrServer> upClients = new ArrayList<SolrServer>(clients);\n      List<JettySolrRunner> downJettys = new ArrayList<JettySolrRunner>();\n      List<String> upShards = new ArrayList<String>(Arrays.asList(shardsArr));\n      for(int i=0; i<numDownServers; i++)\n      {\n        // shut down some of the jettys\n        int indexToRemove = r.nextInt(upJettys.size());\n        JettySolrRunner downJetty = upJettys.remove(indexToRemove);\n        upClients.remove(indexToRemove);\n        upShards.remove(indexToRemove);\n        ChaosMonkey.stop(downJetty);\n        downJettys.add(downJetty);\n      }\n\n      queryPartialResults(upShards, upClients, \n          \"q\",\"*:*\",\n          \"facet\",\"true\", \n          \"facet.field\",t1,\n          \"facet.limit\",5,\n          ShardParams.SHARDS_INFO,\"true\",\n          ShardParams.SHARDS_TOLERANT,\"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"facet\", \"true\",\n          \"facet.query\", i1 + \":[1 TO 50]\",\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      // test group query\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"rows\", 100,\n          \"fl\", \"id,\" + i1,\n          \"group\", \"true\",\n          \"group.query\", t1 + \":kings OR \" + t1 + \":eggs\",\n          \"group.limit\", 10,\n          \"sort\", i1 + \" asc, id asc\",\n          CommonParams.TIME_ALLOWED, 1,\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      // restart the jettys\n      for (JettySolrRunner downJetty : downJettys) {\n        downJetty.start();\n      }\n    }\n\n    // This index has the same number for every field\n    \n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // Thread.sleep(10000000000L);\n\n    FieldCache.DEFAULT.purgeAllCaches();   // avoid FC insanity\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"634f330c54fd3f9f491d52036dc3f40b4f4d8934","date":1394635157,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/TestDistributedSearch#doTest().mjava","pathOld":"solr/core/src/test/org/apache/solr/TestDistributedSearch#doTest().mjava","sourceNew":"  @Override\n  public void doTest() throws Exception {\n    int backupStress = stress; // make a copy so we can restore\n\n\n    del(\"*:*\");\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\", \n           tdate_a, \"2010-04-20T11:00:00Z\",\n           tdate_b, \"2009-08-20T11:00:00Z\",\n           \"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\", \n           tdate_a, \"2010-05-02T11:00:00Z\",\n           tdate_b, \"2009-11-02T11:00:00Z\");\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\", \n           tdate_a, \"2010-05-03T11:00:00Z\");\n    indexr(id,4, i1, -100 ,tlong, 101,\n           t1,\"the quick fox jumped over the lazy dog\", \n           tdate_a, \"2010-05-03T11:00:00Z\",\n           tdate_b, \"2010-05-03T11:00:00Z\");\n    indexr(id,5, i1, 500, tlong, 500 ,\n           t1,\"the quick fox jumped way over the lazy dog\", \n           tdate_a, \"2010-05-05T11:00:00Z\");\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,\n           tdate_b, \"2010-01-05T11:00:00Z\",\n           t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n\n    commit();  // try to ensure there's more than one segment\n\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,\n           t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,\n           t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,\n           t1,\"no eggs on wall, lesson learned\", \n           oddField, \"odd man out\");\n\n    indexr(id, \"1001\", \"lowerfilt\", \"toyota\"); // for spellcheck\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n    \n    \n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n\n    handle.clear();\n    handle.put(\"QTime\", SKIPVAL);\n    handle.put(\"timestamp\", SKIPVAL);\n    handle.put(\"_version_\", SKIPVAL); // not a cloud test, but may use updateLog\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(\"q\",\"*:*\", \"sort\",f+\" desc\");\n      query(\"q\",\"*:*\", \"sort\",f+\" asc\");\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",\"{!func}testfunc(add(\"+i1+\",5))\"+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" asc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\");\n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"*,score\"); \n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 desc\");\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"{!func}\"+i1);// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(\"q\",\"{!func}\"+i1, \"fl\",\"*,score\");  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"quick\");\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\");\n    query(\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\");  // no fields in returned docs\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\");\n\n    handle.put(\"score\", SKIPVAL);\n    query(\"q\",\"quick\",\"fl\",\"*,score\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\");\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"matchesnothing\",\"fl\",\"*,score\");  \n\n    // test that a single NOW value is propagated to all shards... if that is true\n    // then the primary sort should always be a tie and then the secondary should always decide\n    query(\"q\",\"{!func}ms(NOW)\", \"sort\",\"score desc,\"+i1+\" desc\",\"fl\",\"id\");    \n\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\");\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2);\n\n    // a facet query to test out chars out of the ascii range\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!term f=foo_s}international\\u00ff\\u01ff\\u2222\\u3333\");\n\n    // simple date facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date.other\", \"all\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // date facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date\",tdate_b, \n          \"facet.date.other\", \"all\", \n          \"f.\"+tdate_b+\".facet.date.start\",\"2009-05-01T11:00:00Z\", \n          \"f.\"+tdate_b+\".facet.date.gap\",\"+3MONTHS\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // simple range facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"facet.range.end\",900);\n\n    // range facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range\",i1, \n          \"f.\"+i1+\".facet.range.start\",300, \n          \"f.\"+i1+\".facet.range.gap\",87, \n          \"facet.range.end\",900,\n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"f.\"+tlong+\".facet.range.end\",900);\n    \n    //  variations of fl\n    query(\"q\",\"*:*\", \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1 + \",score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", i1, \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id,\" + i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1, \"fl\", \"id\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",nint, \"fl\",tint,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",nint, \"fl\", \"id\", \"fl\",tint,\"sort\",i1 + \" desc\");\n\n    // basic spellcheck testing\n    query(\"q\", \"toyata\", \"fl\", \"id,lowerfilt\", \"spellcheck\", true, \"spellcheck.q\", \"toyata\", \"qt\", \"spellCheckCompRH_Direct\", \"shards.qt\", \"spellCheckCompRH_Direct\");\n\n    stress=0;  // turn off stress... we want to tex max combos in min time\n    for (int i=0; i<25*RANDOM_MULTIPLIER; i++) {\n      String f = fieldNames[random().nextInt(fieldNames.length)];\n      if (random().nextBoolean()) f = t1;  // the text field is a really interesting one to facet on (and it's multi-valued too)\n\n      // we want a random query and not just *:* so we'll get zero counts in facets also\n      // TODO: do a better random query\n      String q = random().nextBoolean() ? \"*:*\" : \"id:(1 3 5 7 9 11 13) OR id:[100 TO \" + random().nextInt(50) + \"]\";\n\n      int nolimit = random().nextBoolean() ? -1 : 10000;  // these should be equivalent\n\n      // if limit==-1, we should always get exact matches\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"count\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      // for index sort, we should get exact results for mincount <= 1\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(2), \"facet.offset\",random().nextInt(10), \"facet.limit\",random().nextInt(11)-1);\n    }\n    stress = backupStress;  // restore stress\n\n    // test faceting multiple things at once\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1);\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id:[1 TO 7]\", \"fq\",\"{!tag=b}id:[3 TO 9]\"\n    );\n    query(\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\");\n\n    // test field that is valid in schema but missing in all shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2);\n    // test field that is valid in schema and missing in some shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2);\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1);\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    // check a complex key name\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"*:*\", \"rows\",100);\n    }\n\n    //SOLR 3161 ensure shards.qt=/update fails (anything but search handler really)\n    // Also see TestRemoteStreaming#testQtUpdateFails()\n    try {\n      ignoreException(\"isShard is only acceptable\");\n      // query(\"q\",\"*:*\",\"shards.qt\",\"/update\",\"stream.body\",\"<delete><query>*:*</query></delete>\");\n      // fail();\n    } catch (SolrException e) {\n      //expected\n    }\n    unIgnoreException(\"isShard is only acceptable\");\n\n    // test debugging\n    // handle.put(\"explain\", UNORDERED);\n    handle.put(\"explain\", SKIPVAL);  // internal docids differ, idf differs w/o global idf\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    handle.put(\"track\", SKIP); //track is not included in single node search\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY);\n\n    // Check Info is added to for each shard\n    ModifiableSolrParams q = new ModifiableSolrParams();\n    q.set(\"q\", \"*:*\");\n    q.set(ShardParams.SHARDS_INFO, true);\n    setDistributedParams(q);\n    QueryResponse rsp = queryServer(q);\n    NamedList<?> sinfo = (NamedList<?>) rsp.getResponse().get(ShardParams.SHARDS_INFO);\n    String shards = getShardsString();\n    int cnt = StringUtils.countMatches(shards, \",\")+1;\n    \n    assertNotNull(\"missing shard info\", sinfo);\n    assertEquals(\"should have an entry for each shard [\"+sinfo+\"] \"+shards, cnt, sinfo.size());\n\n    // test shards.tolerant=true\n    for(int numDownServers = 0; numDownServers < jettys.size()-1; numDownServers++)\n    {\n      List<JettySolrRunner> upJettys = new ArrayList<>(jettys);\n      List<SolrServer> upClients = new ArrayList<>(clients);\n      List<JettySolrRunner> downJettys = new ArrayList<>();\n      List<String> upShards = new ArrayList<>(Arrays.asList(shardsArr));\n      for(int i=0; i<numDownServers; i++)\n      {\n        // shut down some of the jettys\n        int indexToRemove = r.nextInt(upJettys.size());\n        JettySolrRunner downJetty = upJettys.remove(indexToRemove);\n        upClients.remove(indexToRemove);\n        upShards.remove(indexToRemove);\n        ChaosMonkey.stop(downJetty);\n        downJettys.add(downJetty);\n      }\n\n      queryPartialResults(upShards, upClients, \n          \"q\",\"*:*\",\n          \"facet\",\"true\", \n          \"facet.field\",t1,\n          \"facet.limit\",5,\n          ShardParams.SHARDS_INFO,\"true\",\n          ShardParams.SHARDS_TOLERANT,\"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"facet\", \"true\",\n          \"facet.query\", i1 + \":[1 TO 50]\",\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      // test group query\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"rows\", 100,\n          \"fl\", \"id,\" + i1,\n          \"group\", \"true\",\n          \"group.query\", t1 + \":kings OR \" + t1 + \":eggs\",\n          \"group.limit\", 10,\n          \"sort\", i1 + \" asc, id asc\",\n          CommonParams.TIME_ALLOWED, 1,\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"stats\", \"true\",\n          \"stats.field\", i1,\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"toyata\",\n          \"spellcheck\", \"true\",\n          \"spellcheck.q\", \"toyata\",\n          \"qt\", \"spellCheckCompRH_Direct\",\n          \"shards.qt\", \"spellCheckCompRH_Direct\",\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      // restart the jettys\n      for (JettySolrRunner downJetty : downJettys) {\n        downJetty.start();\n      }\n    }\n\n    // This index has the same number for every field\n    \n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // Thread.sleep(10000000000L);\n\n    FieldCache.DEFAULT.purgeAllCaches();   // avoid FC insanity\n\n    del(\"*:*\"); // delete all docs and test stats request\n    commit();\n    try {\n      query(\"q\", \"*:*\", \"stats\", \"true\", \"stats.field\", \"stats_dt\", \"stats.calcdistinct\", \"true\");\n    } catch (Exception e) {\n      log.error(\"Exception on distrib stats request on empty index\", e);\n      fail(\"NullPointerException with stats request on empty index\");\n    }\n  }\n\n","sourceOld":"  @Override\n  public void doTest() throws Exception {\n    int backupStress = stress; // make a copy so we can restore\n\n\n    del(\"*:*\");\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\", \n           tdate_a, \"2010-04-20T11:00:00Z\",\n           tdate_b, \"2009-08-20T11:00:00Z\",\n           \"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\", \n           tdate_a, \"2010-05-02T11:00:00Z\",\n           tdate_b, \"2009-11-02T11:00:00Z\");\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\", \n           tdate_a, \"2010-05-03T11:00:00Z\");\n    indexr(id,4, i1, -100 ,tlong, 101,\n           t1,\"the quick fox jumped over the lazy dog\", \n           tdate_a, \"2010-05-03T11:00:00Z\",\n           tdate_b, \"2010-05-03T11:00:00Z\");\n    indexr(id,5, i1, 500, tlong, 500 ,\n           t1,\"the quick fox jumped way over the lazy dog\", \n           tdate_a, \"2010-05-05T11:00:00Z\");\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,\n           tdate_b, \"2010-01-05T11:00:00Z\",\n           t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n\n    commit();  // try to ensure there's more than one segment\n\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,\n           t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,\n           t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,\n           t1,\"no eggs on wall, lesson learned\", \n           oddField, \"odd man out\");\n\n    indexr(id, \"1001\", \"lowerfilt\", \"toyota\"); // for spellcheck\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n    \n    \n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n\n    handle.clear();\n    handle.put(\"QTime\", SKIPVAL);\n    handle.put(\"timestamp\", SKIPVAL);\n    handle.put(\"_version_\", SKIPVAL); // not a cloud test, but may use updateLog\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(\"q\",\"*:*\", \"sort\",f+\" desc\");\n      query(\"q\",\"*:*\", \"sort\",f+\" asc\");\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",\"{!func}testfunc(add(\"+i1+\",5))\"+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" asc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\");\n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"*,score\"); \n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 desc\");\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"{!func}\"+i1);// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(\"q\",\"{!func}\"+i1, \"fl\",\"*,score\");  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"quick\");\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\");\n    query(\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\");  // no fields in returned docs\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\");\n\n    handle.put(\"score\", SKIPVAL);\n    query(\"q\",\"quick\",\"fl\",\"*,score\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\");\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"matchesnothing\",\"fl\",\"*,score\");  \n\n    // test that a single NOW value is propagated to all shards... if that is true\n    // then the primary sort should always be a tie and then the secondary should always decide\n    query(\"q\",\"{!func}ms(NOW)\", \"sort\",\"score desc,\"+i1+\" desc\",\"fl\",\"id\");    \n\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\");\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2);\n\n    // a facet query to test out chars out of the ascii range\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!term f=foo_s}international\\u00ff\\u01ff\\u2222\\u3333\");\n\n    // simple date facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date.other\", \"all\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // date facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date\",tdate_b, \n          \"facet.date.other\", \"all\", \n          \"f.\"+tdate_b+\".facet.date.start\",\"2009-05-01T11:00:00Z\", \n          \"f.\"+tdate_b+\".facet.date.gap\",\"+3MONTHS\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // simple range facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"facet.range.end\",900);\n\n    // range facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range\",i1, \n          \"f.\"+i1+\".facet.range.start\",300, \n          \"f.\"+i1+\".facet.range.gap\",87, \n          \"facet.range.end\",900,\n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"f.\"+tlong+\".facet.range.end\",900);\n    \n    //  variations of fl\n    query(\"q\",\"*:*\", \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1 + \",score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", i1, \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id,\" + i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1, \"fl\", \"id\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",nint, \"fl\",tint,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",nint, \"fl\", \"id\", \"fl\",tint,\"sort\",i1 + \" desc\");\n\n    // basic spellcheck testing\n    query(\"q\", \"toyata\", \"fl\", \"id,lowerfilt\", \"spellcheck\", true, \"spellcheck.q\", \"toyata\", \"qt\", \"spellCheckCompRH_Direct\", \"shards.qt\", \"spellCheckCompRH_Direct\");\n\n    stress=0;  // turn off stress... we want to tex max combos in min time\n    for (int i=0; i<25*RANDOM_MULTIPLIER; i++) {\n      String f = fieldNames[random().nextInt(fieldNames.length)];\n      if (random().nextBoolean()) f = t1;  // the text field is a really interesting one to facet on (and it's multi-valued too)\n\n      // we want a random query and not just *:* so we'll get zero counts in facets also\n      // TODO: do a better random query\n      String q = random().nextBoolean() ? \"*:*\" : \"id:(1 3 5 7 9 11 13) OR id:[100 TO \" + random().nextInt(50) + \"]\";\n\n      int nolimit = random().nextBoolean() ? -1 : 10000;  // these should be equivalent\n\n      // if limit==-1, we should always get exact matches\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"count\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      // for index sort, we should get exact results for mincount <= 1\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(2), \"facet.offset\",random().nextInt(10), \"facet.limit\",random().nextInt(11)-1);\n    }\n    stress = backupStress;  // restore stress\n\n    // test faceting multiple things at once\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1);\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id:[1 TO 7]\", \"fq\",\"{!tag=b}id:[3 TO 9]\"\n    );\n    query(\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\");\n\n    // test field that is valid in schema but missing in all shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2);\n    // test field that is valid in schema and missing in some shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2);\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1);\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    // check a complex key name\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"*:*\", \"rows\",100);\n    }\n\n    //SOLR 3161 ensure shards.qt=/update fails (anything but search handler really)\n    // Also see TestRemoteStreaming#testQtUpdateFails()\n    try {\n      ignoreException(\"isShard is only acceptable\");\n      // query(\"q\",\"*:*\",\"shards.qt\",\"/update\",\"stream.body\",\"<delete><query>*:*</query></delete>\");\n      // fail();\n    } catch (SolrException e) {\n      //expected\n    }\n    unIgnoreException(\"isShard is only acceptable\");\n\n    // test debugging\n    // handle.put(\"explain\", UNORDERED);\n    handle.put(\"explain\", SKIPVAL);  // internal docids differ, idf differs w/o global idf\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    handle.put(\"track\", SKIP); //track is not included in single node search\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY);\n\n    // Check Info is added to for each shard\n    ModifiableSolrParams q = new ModifiableSolrParams();\n    q.set(\"q\", \"*:*\");\n    q.set(ShardParams.SHARDS_INFO, true);\n    setDistributedParams(q);\n    QueryResponse rsp = queryServer(q);\n    NamedList<?> sinfo = (NamedList<?>) rsp.getResponse().get(ShardParams.SHARDS_INFO);\n    String shards = getShardsString();\n    int cnt = StringUtils.countMatches(shards, \",\")+1;\n    \n    assertNotNull(\"missing shard info\", sinfo);\n    assertEquals(\"should have an entry for each shard [\"+sinfo+\"] \"+shards, cnt, sinfo.size());\n\n    // test shards.tolerant=true\n    for(int numDownServers = 0; numDownServers < jettys.size()-1; numDownServers++)\n    {\n      List<JettySolrRunner> upJettys = new ArrayList<JettySolrRunner>(jettys);\n      List<SolrServer> upClients = new ArrayList<SolrServer>(clients);\n      List<JettySolrRunner> downJettys = new ArrayList<JettySolrRunner>();\n      List<String> upShards = new ArrayList<String>(Arrays.asList(shardsArr));\n      for(int i=0; i<numDownServers; i++)\n      {\n        // shut down some of the jettys\n        int indexToRemove = r.nextInt(upJettys.size());\n        JettySolrRunner downJetty = upJettys.remove(indexToRemove);\n        upClients.remove(indexToRemove);\n        upShards.remove(indexToRemove);\n        ChaosMonkey.stop(downJetty);\n        downJettys.add(downJetty);\n      }\n\n      queryPartialResults(upShards, upClients, \n          \"q\",\"*:*\",\n          \"facet\",\"true\", \n          \"facet.field\",t1,\n          \"facet.limit\",5,\n          ShardParams.SHARDS_INFO,\"true\",\n          ShardParams.SHARDS_TOLERANT,\"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"facet\", \"true\",\n          \"facet.query\", i1 + \":[1 TO 50]\",\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      // test group query\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"rows\", 100,\n          \"fl\", \"id,\" + i1,\n          \"group\", \"true\",\n          \"group.query\", t1 + \":kings OR \" + t1 + \":eggs\",\n          \"group.limit\", 10,\n          \"sort\", i1 + \" asc, id asc\",\n          CommonParams.TIME_ALLOWED, 1,\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"stats\", \"true\",\n          \"stats.field\", i1,\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"toyata\",\n          \"spellcheck\", \"true\",\n          \"spellcheck.q\", \"toyata\",\n          \"qt\", \"spellCheckCompRH_Direct\",\n          \"shards.qt\", \"spellCheckCompRH_Direct\",\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      // restart the jettys\n      for (JettySolrRunner downJetty : downJettys) {\n        downJetty.start();\n      }\n    }\n\n    // This index has the same number for every field\n    \n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // Thread.sleep(10000000000L);\n\n    FieldCache.DEFAULT.purgeAllCaches();   // avoid FC insanity\n\n    del(\"*:*\"); // delete all docs and test stats request\n    commit();\n    try {\n      query(\"q\", \"*:*\", \"stats\", \"true\", \"stats.field\", \"stats_dt\", \"stats.calcdistinct\", \"true\");\n    } catch (Exception e) {\n      log.error(\"Exception on distrib stats request on empty index\", e);\n      fail(\"NullPointerException with stats request on empty index\");\n    }\n  }\n\n","bugFix":null,"bugIntro":["bb222a3f9d9421d5c95afce73013fbd8de07ea1f"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"e6a0af6f7a7677267ad84c35bc106a61fd67dc62","date":1398990808,"type":3,"author":"Chris M. Hostetter","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/TestDistributedSearch#doTest().mjava","pathOld":"solr/core/src/test/org/apache/solr/TestDistributedSearch#doTest().mjava","sourceNew":"  @Override\n  public void doTest() throws Exception {\n    int backupStress = stress; // make a copy so we can restore\n\n\n    del(\"*:*\");\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\", \n           tdate_a, \"2010-04-20T11:00:00Z\",\n           tdate_b, \"2009-08-20T11:00:00Z\",\n           \"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\", \n           tdate_a, \"2010-05-02T11:00:00Z\",\n           tdate_b, \"2009-11-02T11:00:00Z\");\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\", \n           tdate_a, \"2010-05-03T11:00:00Z\");\n    indexr(id,4, i1, -100 ,tlong, 101,\n           t1,\"the quick fox jumped over the lazy dog\", \n           tdate_a, \"2010-05-03T11:00:00Z\",\n           tdate_b, \"2010-05-03T11:00:00Z\");\n    indexr(id,5, i1, 500, tlong, 500 ,\n           t1,\"the quick fox jumped way over the lazy dog\", \n           tdate_a, \"2010-05-05T11:00:00Z\");\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,\n           tdate_b, \"2010-01-05T11:00:00Z\",\n           t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n\n    commit();  // try to ensure there's more than one segment\n\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,\n           t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,\n           t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,\n           t1,\"no eggs on wall, lesson learned\", \n           oddField, \"odd man out\");\n\n    indexr(id, \"1001\", \"lowerfilt\", \"toyota\"); // for spellcheck\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n    \n    \n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n\n    handle.clear();\n    handle.put(\"QTime\", SKIPVAL);\n    handle.put(\"timestamp\", SKIPVAL);\n    handle.put(\"_version_\", SKIPVAL); // not a cloud test, but may use updateLog\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(\"q\",\"*:*\", \"sort\",f+\" desc\");\n      query(\"q\",\"*:*\", \"sort\",f+\" asc\");\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",\"{!func}testfunc(add(\"+i1+\",5))\"+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" asc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\");\n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"*,score\"); \n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 desc\");\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"{!func}\"+i1);// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(\"q\",\"{!func}\"+i1, \"fl\",\"*,score\");  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"quick\");\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\");\n    query(\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\");  // no fields in returned docs\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\");\n\n    handle.put(\"score\", SKIPVAL);\n    query(\"q\",\"quick\",\"fl\",\"*,score\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\");\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"matchesnothing\",\"fl\",\"*,score\");  \n\n    // test that a single NOW value is propagated to all shards... if that is true\n    // then the primary sort should always be a tie and then the secondary should always decide\n    query(\"q\",\"{!func}ms(NOW)\", \"sort\",\"score desc,\"+i1+\" desc\",\"fl\",\"id\");    \n\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\");\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2);\n\n    // a facet query to test out chars out of the ascii range\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!term f=foo_s}international\\u00ff\\u01ff\\u2222\\u3333\");\n\n    // simple date facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date.other\", \"all\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // date facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date\",tdate_b, \n          \"facet.date.other\", \"all\", \n          \"f.\"+tdate_b+\".facet.date.start\",\"2009-05-01T11:00:00Z\", \n          \"f.\"+tdate_b+\".facet.date.gap\",\"+3MONTHS\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // simple range facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"facet.range.end\",900);\n\n    // range facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range\",i1, \n          \"f.\"+i1+\".facet.range.start\",300, \n          \"f.\"+i1+\".facet.range.gap\",87, \n          \"facet.range.end\",900,\n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"f.\"+tlong+\".facet.range.end\",900);\n    \n    //  variations of fl\n    query(\"q\",\"*:*\", \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1 + \",score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", i1, \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id,\" + i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1, \"fl\", \"id\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",nint, \"fl\",tint,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",nint, \"fl\", \"id\", \"fl\",tint,\"sort\",i1 + \" desc\");\n\n    // basic spellcheck testing\n    query(\"q\", \"toyata\", \"fl\", \"id,lowerfilt\", \"spellcheck\", true, \"spellcheck.q\", \"toyata\", \"qt\", \"spellCheckCompRH_Direct\", \"shards.qt\", \"spellCheckCompRH_Direct\");\n\n    stress=0;  // turn off stress... we want to tex max combos in min time\n    for (int i=0; i<25*RANDOM_MULTIPLIER; i++) {\n      String f = fieldNames[random().nextInt(fieldNames.length)];\n      if (random().nextBoolean()) f = t1;  // the text field is a really interesting one to facet on (and it's multi-valued too)\n\n      // we want a random query and not just *:* so we'll get zero counts in facets also\n      // TODO: do a better random query\n      String q = random().nextBoolean() ? \"*:*\" : \"id:(1 3 5 7 9 11 13) OR id:[100 TO \" + random().nextInt(50) + \"]\";\n\n      int nolimit = random().nextBoolean() ? -1 : 10000;  // these should be equivalent\n\n      // if limit==-1, we should always get exact matches\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"count\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      // for index sort, we should get exact results for mincount <= 1\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(2), \"facet.offset\",random().nextInt(10), \"facet.limit\",random().nextInt(11)-1);\n    }\n    stress = backupStress;  // restore stress\n\n    // test faceting multiple things at once\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1);\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id:[1 TO 7]\", \"fq\",\"{!tag=b}id:[3 TO 9]\"\n    );\n    query(\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\");\n\n    // test field that is valid in schema but missing in all shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2);\n    // test field that is valid in schema and missing in some shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2);\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", \"stats_dt\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1);\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", tdate_a);\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", tdate_b);\n\n    handle.put(\"stats_fields\", UNORDERED);\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \n          \"stats.field\", \"stats_dt\", \n          \"stats.field\", i1, \n          \"stats.field\", tdate_a, \n          \"stats.field\", tdate_b);\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    // check a complex key name\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"*:*\", \"rows\",100);\n    }\n\n    //SOLR 3161 ensure shards.qt=/update fails (anything but search handler really)\n    // Also see TestRemoteStreaming#testQtUpdateFails()\n    try {\n      ignoreException(\"isShard is only acceptable\");\n      // query(\"q\",\"*:*\",\"shards.qt\",\"/update\",\"stream.body\",\"<delete><query>*:*</query></delete>\");\n      // fail();\n    } catch (SolrException e) {\n      //expected\n    }\n    unIgnoreException(\"isShard is only acceptable\");\n\n    // test debugging\n    // handle.put(\"explain\", UNORDERED);\n    handle.put(\"explain\", SKIPVAL);  // internal docids differ, idf differs w/o global idf\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    handle.put(\"track\", SKIP); //track is not included in single node search\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY);\n\n    // Check Info is added to for each shard\n    ModifiableSolrParams q = new ModifiableSolrParams();\n    q.set(\"q\", \"*:*\");\n    q.set(ShardParams.SHARDS_INFO, true);\n    setDistributedParams(q);\n    QueryResponse rsp = queryServer(q);\n    NamedList<?> sinfo = (NamedList<?>) rsp.getResponse().get(ShardParams.SHARDS_INFO);\n    String shards = getShardsString();\n    int cnt = StringUtils.countMatches(shards, \",\")+1;\n    \n    assertNotNull(\"missing shard info\", sinfo);\n    assertEquals(\"should have an entry for each shard [\"+sinfo+\"] \"+shards, cnt, sinfo.size());\n\n    // test shards.tolerant=true\n    for(int numDownServers = 0; numDownServers < jettys.size()-1; numDownServers++)\n    {\n      List<JettySolrRunner> upJettys = new ArrayList<>(jettys);\n      List<SolrServer> upClients = new ArrayList<>(clients);\n      List<JettySolrRunner> downJettys = new ArrayList<>();\n      List<String> upShards = new ArrayList<>(Arrays.asList(shardsArr));\n      for(int i=0; i<numDownServers; i++)\n      {\n        // shut down some of the jettys\n        int indexToRemove = r.nextInt(upJettys.size());\n        JettySolrRunner downJetty = upJettys.remove(indexToRemove);\n        upClients.remove(indexToRemove);\n        upShards.remove(indexToRemove);\n        ChaosMonkey.stop(downJetty);\n        downJettys.add(downJetty);\n      }\n\n      queryPartialResults(upShards, upClients, \n          \"q\",\"*:*\",\n          \"facet\",\"true\", \n          \"facet.field\",t1,\n          \"facet.limit\",5,\n          ShardParams.SHARDS_INFO,\"true\",\n          ShardParams.SHARDS_TOLERANT,\"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"facet\", \"true\",\n          \"facet.query\", i1 + \":[1 TO 50]\",\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      // test group query\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"rows\", 100,\n          \"fl\", \"id,\" + i1,\n          \"group\", \"true\",\n          \"group.query\", t1 + \":kings OR \" + t1 + \":eggs\",\n          \"group.limit\", 10,\n          \"sort\", i1 + \" asc, id asc\",\n          CommonParams.TIME_ALLOWED, 1,\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"stats\", \"true\",\n          \"stats.field\", i1,\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"toyata\",\n          \"spellcheck\", \"true\",\n          \"spellcheck.q\", \"toyata\",\n          \"qt\", \"spellCheckCompRH_Direct\",\n          \"shards.qt\", \"spellCheckCompRH_Direct\",\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      // restart the jettys\n      for (JettySolrRunner downJetty : downJettys) {\n        downJetty.start();\n      }\n    }\n\n    // This index has the same number for every field\n    \n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // Thread.sleep(10000000000L);\n\n    FieldCache.DEFAULT.purgeAllCaches();   // avoid FC insanity\n\n    del(\"*:*\"); // delete all docs and test stats request\n    commit();\n    try {\n      query(\"q\", \"*:*\", \"stats\", \"true\", \n            \"stats.field\", \"stats_dt\", \n            \"stats.field\", i1, \n            \"stats.field\", tdate_a, \n            \"stats.field\", tdate_b,\n            \"stats.calcdistinct\", \"true\");\n    } catch (Exception e) {\n      log.error(\"Exception on distrib stats request on empty index\", e);\n      fail(\"NullPointerException with stats request on empty index\");\n    }\n  }\n\n","sourceOld":"  @Override\n  public void doTest() throws Exception {\n    int backupStress = stress; // make a copy so we can restore\n\n\n    del(\"*:*\");\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\", \n           tdate_a, \"2010-04-20T11:00:00Z\",\n           tdate_b, \"2009-08-20T11:00:00Z\",\n           \"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\", \n           tdate_a, \"2010-05-02T11:00:00Z\",\n           tdate_b, \"2009-11-02T11:00:00Z\");\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\", \n           tdate_a, \"2010-05-03T11:00:00Z\");\n    indexr(id,4, i1, -100 ,tlong, 101,\n           t1,\"the quick fox jumped over the lazy dog\", \n           tdate_a, \"2010-05-03T11:00:00Z\",\n           tdate_b, \"2010-05-03T11:00:00Z\");\n    indexr(id,5, i1, 500, tlong, 500 ,\n           t1,\"the quick fox jumped way over the lazy dog\", \n           tdate_a, \"2010-05-05T11:00:00Z\");\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,\n           tdate_b, \"2010-01-05T11:00:00Z\",\n           t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n\n    commit();  // try to ensure there's more than one segment\n\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,\n           t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,\n           t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,\n           t1,\"no eggs on wall, lesson learned\", \n           oddField, \"odd man out\");\n\n    indexr(id, \"1001\", \"lowerfilt\", \"toyota\"); // for spellcheck\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n    \n    \n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n\n    handle.clear();\n    handle.put(\"QTime\", SKIPVAL);\n    handle.put(\"timestamp\", SKIPVAL);\n    handle.put(\"_version_\", SKIPVAL); // not a cloud test, but may use updateLog\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(\"q\",\"*:*\", \"sort\",f+\" desc\");\n      query(\"q\",\"*:*\", \"sort\",f+\" asc\");\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",\"{!func}testfunc(add(\"+i1+\",5))\"+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" asc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\");\n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"*,score\"); \n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 desc\");\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"{!func}\"+i1);// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(\"q\",\"{!func}\"+i1, \"fl\",\"*,score\");  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"quick\");\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\");\n    query(\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\");  // no fields in returned docs\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\");\n\n    handle.put(\"score\", SKIPVAL);\n    query(\"q\",\"quick\",\"fl\",\"*,score\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\");\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"matchesnothing\",\"fl\",\"*,score\");  \n\n    // test that a single NOW value is propagated to all shards... if that is true\n    // then the primary sort should always be a tie and then the secondary should always decide\n    query(\"q\",\"{!func}ms(NOW)\", \"sort\",\"score desc,\"+i1+\" desc\",\"fl\",\"id\");    \n\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\");\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2);\n\n    // a facet query to test out chars out of the ascii range\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!term f=foo_s}international\\u00ff\\u01ff\\u2222\\u3333\");\n\n    // simple date facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date.other\", \"all\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // date facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date\",tdate_b, \n          \"facet.date.other\", \"all\", \n          \"f.\"+tdate_b+\".facet.date.start\",\"2009-05-01T11:00:00Z\", \n          \"f.\"+tdate_b+\".facet.date.gap\",\"+3MONTHS\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // simple range facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"facet.range.end\",900);\n\n    // range facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range\",i1, \n          \"f.\"+i1+\".facet.range.start\",300, \n          \"f.\"+i1+\".facet.range.gap\",87, \n          \"facet.range.end\",900,\n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"f.\"+tlong+\".facet.range.end\",900);\n    \n    //  variations of fl\n    query(\"q\",\"*:*\", \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1 + \",score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", i1, \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id,\" + i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1, \"fl\", \"id\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",nint, \"fl\",tint,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",nint, \"fl\", \"id\", \"fl\",tint,\"sort\",i1 + \" desc\");\n\n    // basic spellcheck testing\n    query(\"q\", \"toyata\", \"fl\", \"id,lowerfilt\", \"spellcheck\", true, \"spellcheck.q\", \"toyata\", \"qt\", \"spellCheckCompRH_Direct\", \"shards.qt\", \"spellCheckCompRH_Direct\");\n\n    stress=0;  // turn off stress... we want to tex max combos in min time\n    for (int i=0; i<25*RANDOM_MULTIPLIER; i++) {\n      String f = fieldNames[random().nextInt(fieldNames.length)];\n      if (random().nextBoolean()) f = t1;  // the text field is a really interesting one to facet on (and it's multi-valued too)\n\n      // we want a random query and not just *:* so we'll get zero counts in facets also\n      // TODO: do a better random query\n      String q = random().nextBoolean() ? \"*:*\" : \"id:(1 3 5 7 9 11 13) OR id:[100 TO \" + random().nextInt(50) + \"]\";\n\n      int nolimit = random().nextBoolean() ? -1 : 10000;  // these should be equivalent\n\n      // if limit==-1, we should always get exact matches\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"count\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      // for index sort, we should get exact results for mincount <= 1\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(2), \"facet.offset\",random().nextInt(10), \"facet.limit\",random().nextInt(11)-1);\n    }\n    stress = backupStress;  // restore stress\n\n    // test faceting multiple things at once\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1);\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id:[1 TO 7]\", \"fq\",\"{!tag=b}id:[3 TO 9]\"\n    );\n    query(\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\");\n\n    // test field that is valid in schema but missing in all shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2);\n    // test field that is valid in schema and missing in some shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2);\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1);\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    // check a complex key name\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"*:*\", \"rows\",100);\n    }\n\n    //SOLR 3161 ensure shards.qt=/update fails (anything but search handler really)\n    // Also see TestRemoteStreaming#testQtUpdateFails()\n    try {\n      ignoreException(\"isShard is only acceptable\");\n      // query(\"q\",\"*:*\",\"shards.qt\",\"/update\",\"stream.body\",\"<delete><query>*:*</query></delete>\");\n      // fail();\n    } catch (SolrException e) {\n      //expected\n    }\n    unIgnoreException(\"isShard is only acceptable\");\n\n    // test debugging\n    // handle.put(\"explain\", UNORDERED);\n    handle.put(\"explain\", SKIPVAL);  // internal docids differ, idf differs w/o global idf\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    handle.put(\"track\", SKIP); //track is not included in single node search\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY);\n\n    // Check Info is added to for each shard\n    ModifiableSolrParams q = new ModifiableSolrParams();\n    q.set(\"q\", \"*:*\");\n    q.set(ShardParams.SHARDS_INFO, true);\n    setDistributedParams(q);\n    QueryResponse rsp = queryServer(q);\n    NamedList<?> sinfo = (NamedList<?>) rsp.getResponse().get(ShardParams.SHARDS_INFO);\n    String shards = getShardsString();\n    int cnt = StringUtils.countMatches(shards, \",\")+1;\n    \n    assertNotNull(\"missing shard info\", sinfo);\n    assertEquals(\"should have an entry for each shard [\"+sinfo+\"] \"+shards, cnt, sinfo.size());\n\n    // test shards.tolerant=true\n    for(int numDownServers = 0; numDownServers < jettys.size()-1; numDownServers++)\n    {\n      List<JettySolrRunner> upJettys = new ArrayList<>(jettys);\n      List<SolrServer> upClients = new ArrayList<>(clients);\n      List<JettySolrRunner> downJettys = new ArrayList<>();\n      List<String> upShards = new ArrayList<>(Arrays.asList(shardsArr));\n      for(int i=0; i<numDownServers; i++)\n      {\n        // shut down some of the jettys\n        int indexToRemove = r.nextInt(upJettys.size());\n        JettySolrRunner downJetty = upJettys.remove(indexToRemove);\n        upClients.remove(indexToRemove);\n        upShards.remove(indexToRemove);\n        ChaosMonkey.stop(downJetty);\n        downJettys.add(downJetty);\n      }\n\n      queryPartialResults(upShards, upClients, \n          \"q\",\"*:*\",\n          \"facet\",\"true\", \n          \"facet.field\",t1,\n          \"facet.limit\",5,\n          ShardParams.SHARDS_INFO,\"true\",\n          ShardParams.SHARDS_TOLERANT,\"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"facet\", \"true\",\n          \"facet.query\", i1 + \":[1 TO 50]\",\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      // test group query\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"rows\", 100,\n          \"fl\", \"id,\" + i1,\n          \"group\", \"true\",\n          \"group.query\", t1 + \":kings OR \" + t1 + \":eggs\",\n          \"group.limit\", 10,\n          \"sort\", i1 + \" asc, id asc\",\n          CommonParams.TIME_ALLOWED, 1,\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"stats\", \"true\",\n          \"stats.field\", i1,\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"toyata\",\n          \"spellcheck\", \"true\",\n          \"spellcheck.q\", \"toyata\",\n          \"qt\", \"spellCheckCompRH_Direct\",\n          \"shards.qt\", \"spellCheckCompRH_Direct\",\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      // restart the jettys\n      for (JettySolrRunner downJetty : downJettys) {\n        downJetty.start();\n      }\n    }\n\n    // This index has the same number for every field\n    \n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // Thread.sleep(10000000000L);\n\n    FieldCache.DEFAULT.purgeAllCaches();   // avoid FC insanity\n\n    del(\"*:*\"); // delete all docs and test stats request\n    commit();\n    try {\n      query(\"q\", \"*:*\", \"stats\", \"true\", \"stats.field\", \"stats_dt\", \"stats.calcdistinct\", \"true\");\n    } catch (Exception e) {\n      log.error(\"Exception on distrib stats request on empty index\", e);\n      fail(\"NullPointerException with stats request on empty index\");\n    }\n  }\n\n","bugFix":["c1500c4d2642ffe9c4fc6a09a7674b69a550fd36"],"bugIntro":["610c97b96420e614c67797fd43822ebc1d4b7ee2"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"e28b14e7783d24ca69089f13ddadadbd2afdcb29","date":1399840701,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/TestDistributedSearch#doTest().mjava","pathOld":"solr/core/src/test/org/apache/solr/TestDistributedSearch#doTest().mjava","sourceNew":"  @Override\n  public void doTest() throws Exception {\n    int backupStress = stress; // make a copy so we can restore\n\n\n    del(\"*:*\");\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\", \n           tdate_a, \"2010-04-20T11:00:00Z\",\n           tdate_b, \"2009-08-20T11:00:00Z\",\n           \"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\", \n           tdate_a, \"2010-05-02T11:00:00Z\",\n           tdate_b, \"2009-11-02T11:00:00Z\");\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\", \n           tdate_a, \"2010-05-03T11:00:00Z\");\n    indexr(id,4, i1, -100 ,tlong, 101,\n           t1,\"the quick fox jumped over the lazy dog\", \n           tdate_a, \"2010-05-03T11:00:00Z\",\n           tdate_b, \"2010-05-03T11:00:00Z\");\n    indexr(id,5, i1, 500, tlong, 500 ,\n           t1,\"the quick fox jumped way over the lazy dog\", \n           tdate_a, \"2010-05-05T11:00:00Z\");\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,\n           tdate_b, \"2010-01-05T11:00:00Z\",\n           t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n\n    commit();  // try to ensure there's more than one segment\n\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,\n           t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,\n           t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,\n           t1,\"no eggs on wall, lesson learned\", \n           oddField, \"odd man out\");\n\n    indexr(id, \"1001\", \"lowerfilt\", \"toyota\"); // for spellcheck\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n    \n    \n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n\n    handle.clear();\n    handle.put(\"QTime\", SKIPVAL);\n    handle.put(\"timestamp\", SKIPVAL);\n    handle.put(\"_version_\", SKIPVAL); // not a cloud test, but may use updateLog\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(\"q\",\"*:*\", \"sort\",f+\" desc\");\n      query(\"q\",\"*:*\", \"sort\",f+\" asc\");\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",\"{!func}testfunc(add(\"+i1+\",5))\"+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" asc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\");\n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"*,score\"); \n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 desc\");\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"{!func}\"+i1);// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(\"q\",\"{!func}\"+i1, \"fl\",\"*,score\");  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"quick\");\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\");\n    query(\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\");  // no fields in returned docs\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\");\n\n    handle.put(\"score\", SKIPVAL);\n    query(\"q\",\"quick\",\"fl\",\"*,score\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\");\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"matchesnothing\",\"fl\",\"*,score\");  \n\n    // test that a single NOW value is propagated to all shards... if that is true\n    // then the primary sort should always be a tie and then the secondary should always decide\n    query(\"q\",\"{!func}ms(NOW)\", \"sort\",\"score desc,\"+i1+\" desc\",\"fl\",\"id\");    \n\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\");\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2);\n\n    // a facet query to test out chars out of the ascii range\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!term f=foo_s}international\\u00ff\\u01ff\\u2222\\u3333\");\n\n    // simple date facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date.other\", \"all\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // date facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date\",tdate_b, \n          \"facet.date.other\", \"all\", \n          \"f.\"+tdate_b+\".facet.date.start\",\"2009-05-01T11:00:00Z\", \n          \"f.\"+tdate_b+\".facet.date.gap\",\"+3MONTHS\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // simple range facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"facet.range.end\",900);\n\n    // range facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range\",i1, \n          \"f.\"+i1+\".facet.range.start\",300, \n          \"f.\"+i1+\".facet.range.gap\",87, \n          \"facet.range.end\",900,\n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"f.\"+tlong+\".facet.range.end\",900);\n    \n    //  variations of fl\n    query(\"q\",\"*:*\", \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1 + \",score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", i1, \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id,\" + i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1, \"fl\", \"id\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",nint, \"fl\",tint,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",nint, \"fl\", \"id\", \"fl\",tint,\"sort\",i1 + \" desc\");\n\n    // basic spellcheck testing\n    query(\"q\", \"toyata\", \"fl\", \"id,lowerfilt\", \"spellcheck\", true, \"spellcheck.q\", \"toyata\", \"qt\", \"spellCheckCompRH_Direct\", \"shards.qt\", \"spellCheckCompRH_Direct\");\n\n    stress=0;  // turn off stress... we want to tex max combos in min time\n    for (int i=0; i<25*RANDOM_MULTIPLIER; i++) {\n      String f = fieldNames[random().nextInt(fieldNames.length)];\n      if (random().nextBoolean()) f = t1;  // the text field is a really interesting one to facet on (and it's multi-valued too)\n\n      // we want a random query and not just *:* so we'll get zero counts in facets also\n      // TODO: do a better random query\n      String q = random().nextBoolean() ? \"*:*\" : \"id:(1 3 5 7 9 11 13) OR id:[100 TO \" + random().nextInt(50) + \"]\";\n\n      int nolimit = random().nextBoolean() ? -1 : 10000;  // these should be equivalent\n\n      // if limit==-1, we should always get exact matches\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"count\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      // for index sort, we should get exact results for mincount <= 1\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(2), \"facet.offset\",random().nextInt(10), \"facet.limit\",random().nextInt(11)-1);\n    }\n    stress = backupStress;  // restore stress\n\n    // test faceting multiple things at once\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1);\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id:[1 TO 7]\", \"fq\",\"{!tag=b}id:[3 TO 9]\"\n    );\n    query(\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\");\n\n    // test field that is valid in schema but missing in all shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2);\n    // test field that is valid in schema and missing in some shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2);\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", \"stats_dt\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1);\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", tdate_a);\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", tdate_b);\n\n    handle.put(\"stats_fields\", UNORDERED);\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \n          \"stats.field\", \"stats_dt\", \n          \"stats.field\", i1, \n          \"stats.field\", tdate_a, \n          \"stats.field\", tdate_b);\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    // check a complex key name\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"*:*\", \"rows\",100);\n    }\n\n    //SOLR 3161 ensure shards.qt=/update fails (anything but search handler really)\n    // Also see TestRemoteStreaming#testQtUpdateFails()\n    try {\n      ignoreException(\"isShard is only acceptable\");\n      // query(\"q\",\"*:*\",\"shards.qt\",\"/update\",\"stream.body\",\"<delete><query>*:*</query></delete>\");\n      // fail();\n    } catch (SolrException e) {\n      //expected\n    }\n    unIgnoreException(\"isShard is only acceptable\");\n\n    // test debugging\n    // handle.put(\"explain\", UNORDERED);\n    handle.put(\"explain\", SKIPVAL);  // internal docids differ, idf differs w/o global idf\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    handle.put(\"track\", SKIP); //track is not included in single node search\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY);\n\n    // Check Info is added to for each shard\n    ModifiableSolrParams q = new ModifiableSolrParams();\n    q.set(\"q\", \"*:*\");\n    q.set(ShardParams.SHARDS_INFO, true);\n    setDistributedParams(q);\n    QueryResponse rsp = queryServer(q);\n    NamedList<?> sinfo = (NamedList<?>) rsp.getResponse().get(ShardParams.SHARDS_INFO);\n    String shards = getShardsString();\n    int cnt = StringUtils.countMatches(shards, \",\")+1;\n    \n    assertNotNull(\"missing shard info\", sinfo);\n    assertEquals(\"should have an entry for each shard [\"+sinfo+\"] \"+shards, cnt, sinfo.size());\n\n    // test shards.tolerant=true\n    for(int numDownServers = 0; numDownServers < jettys.size()-1; numDownServers++)\n    {\n      List<JettySolrRunner> upJettys = new ArrayList<>(jettys);\n      List<SolrServer> upClients = new ArrayList<>(clients);\n      List<JettySolrRunner> downJettys = new ArrayList<>();\n      List<String> upShards = new ArrayList<>(Arrays.asList(shardsArr));\n      for(int i=0; i<numDownServers; i++)\n      {\n        // shut down some of the jettys\n        int indexToRemove = r.nextInt(upJettys.size());\n        JettySolrRunner downJetty = upJettys.remove(indexToRemove);\n        upClients.remove(indexToRemove);\n        upShards.remove(indexToRemove);\n        ChaosMonkey.stop(downJetty);\n        downJettys.add(downJetty);\n      }\n\n      queryPartialResults(upShards, upClients, \n          \"q\",\"*:*\",\n          \"facet\",\"true\", \n          \"facet.field\",t1,\n          \"facet.limit\",5,\n          ShardParams.SHARDS_INFO,\"true\",\n          ShardParams.SHARDS_TOLERANT,\"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"facet\", \"true\",\n          \"facet.query\", i1 + \":[1 TO 50]\",\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      // test group query\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"rows\", 100,\n          \"fl\", \"id,\" + i1,\n          \"group\", \"true\",\n          \"group.query\", t1 + \":kings OR \" + t1 + \":eggs\",\n          \"group.limit\", 10,\n          \"sort\", i1 + \" asc, id asc\",\n          CommonParams.TIME_ALLOWED, 1,\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"stats\", \"true\",\n          \"stats.field\", i1,\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"toyata\",\n          \"spellcheck\", \"true\",\n          \"spellcheck.q\", \"toyata\",\n          \"qt\", \"spellCheckCompRH_Direct\",\n          \"shards.qt\", \"spellCheckCompRH_Direct\",\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      // restart the jettys\n      for (JettySolrRunner downJetty : downJettys) {\n        downJetty.start();\n      }\n    }\n\n    // This index has the same number for every field\n    \n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // Thread.sleep(10000000000L);\n\n    // nocommit: split test if needed\n    // FieldCache.DEFAULT.purgeAllCaches();   // hide FC insanity\n\n    del(\"*:*\"); // delete all docs and test stats request\n    commit();\n    try {\n      query(\"q\", \"*:*\", \"stats\", \"true\", \n            \"stats.field\", \"stats_dt\", \n            \"stats.field\", i1, \n            \"stats.field\", tdate_a, \n            \"stats.field\", tdate_b,\n            \"stats.calcdistinct\", \"true\");\n    } catch (Exception e) {\n      log.error(\"Exception on distrib stats request on empty index\", e);\n      fail(\"NullPointerException with stats request on empty index\");\n    }\n  }\n\n","sourceOld":"  @Override\n  public void doTest() throws Exception {\n    int backupStress = stress; // make a copy so we can restore\n\n\n    del(\"*:*\");\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\", \n           tdate_a, \"2010-04-20T11:00:00Z\",\n           tdate_b, \"2009-08-20T11:00:00Z\",\n           \"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\", \n           tdate_a, \"2010-05-02T11:00:00Z\",\n           tdate_b, \"2009-11-02T11:00:00Z\");\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\", \n           tdate_a, \"2010-05-03T11:00:00Z\");\n    indexr(id,4, i1, -100 ,tlong, 101,\n           t1,\"the quick fox jumped over the lazy dog\", \n           tdate_a, \"2010-05-03T11:00:00Z\",\n           tdate_b, \"2010-05-03T11:00:00Z\");\n    indexr(id,5, i1, 500, tlong, 500 ,\n           t1,\"the quick fox jumped way over the lazy dog\", \n           tdate_a, \"2010-05-05T11:00:00Z\");\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,\n           tdate_b, \"2010-01-05T11:00:00Z\",\n           t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n\n    commit();  // try to ensure there's more than one segment\n\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,\n           t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,\n           t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,\n           t1,\"no eggs on wall, lesson learned\", \n           oddField, \"odd man out\");\n\n    indexr(id, \"1001\", \"lowerfilt\", \"toyota\"); // for spellcheck\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n    \n    \n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n\n    handle.clear();\n    handle.put(\"QTime\", SKIPVAL);\n    handle.put(\"timestamp\", SKIPVAL);\n    handle.put(\"_version_\", SKIPVAL); // not a cloud test, but may use updateLog\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(\"q\",\"*:*\", \"sort\",f+\" desc\");\n      query(\"q\",\"*:*\", \"sort\",f+\" asc\");\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",\"{!func}testfunc(add(\"+i1+\",5))\"+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" asc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\");\n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"*,score\"); \n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 desc\");\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"{!func}\"+i1);// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(\"q\",\"{!func}\"+i1, \"fl\",\"*,score\");  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"quick\");\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\");\n    query(\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\");  // no fields in returned docs\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\");\n\n    handle.put(\"score\", SKIPVAL);\n    query(\"q\",\"quick\",\"fl\",\"*,score\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\");\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"matchesnothing\",\"fl\",\"*,score\");  \n\n    // test that a single NOW value is propagated to all shards... if that is true\n    // then the primary sort should always be a tie and then the secondary should always decide\n    query(\"q\",\"{!func}ms(NOW)\", \"sort\",\"score desc,\"+i1+\" desc\",\"fl\",\"id\");    \n\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\");\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2);\n\n    // a facet query to test out chars out of the ascii range\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!term f=foo_s}international\\u00ff\\u01ff\\u2222\\u3333\");\n\n    // simple date facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date.other\", \"all\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // date facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date\",tdate_b, \n          \"facet.date.other\", \"all\", \n          \"f.\"+tdate_b+\".facet.date.start\",\"2009-05-01T11:00:00Z\", \n          \"f.\"+tdate_b+\".facet.date.gap\",\"+3MONTHS\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // simple range facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"facet.range.end\",900);\n\n    // range facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range\",i1, \n          \"f.\"+i1+\".facet.range.start\",300, \n          \"f.\"+i1+\".facet.range.gap\",87, \n          \"facet.range.end\",900,\n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"f.\"+tlong+\".facet.range.end\",900);\n    \n    //  variations of fl\n    query(\"q\",\"*:*\", \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1 + \",score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", i1, \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id,\" + i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1, \"fl\", \"id\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",nint, \"fl\",tint,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",nint, \"fl\", \"id\", \"fl\",tint,\"sort\",i1 + \" desc\");\n\n    // basic spellcheck testing\n    query(\"q\", \"toyata\", \"fl\", \"id,lowerfilt\", \"spellcheck\", true, \"spellcheck.q\", \"toyata\", \"qt\", \"spellCheckCompRH_Direct\", \"shards.qt\", \"spellCheckCompRH_Direct\");\n\n    stress=0;  // turn off stress... we want to tex max combos in min time\n    for (int i=0; i<25*RANDOM_MULTIPLIER; i++) {\n      String f = fieldNames[random().nextInt(fieldNames.length)];\n      if (random().nextBoolean()) f = t1;  // the text field is a really interesting one to facet on (and it's multi-valued too)\n\n      // we want a random query and not just *:* so we'll get zero counts in facets also\n      // TODO: do a better random query\n      String q = random().nextBoolean() ? \"*:*\" : \"id:(1 3 5 7 9 11 13) OR id:[100 TO \" + random().nextInt(50) + \"]\";\n\n      int nolimit = random().nextBoolean() ? -1 : 10000;  // these should be equivalent\n\n      // if limit==-1, we should always get exact matches\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"count\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      // for index sort, we should get exact results for mincount <= 1\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(2), \"facet.offset\",random().nextInt(10), \"facet.limit\",random().nextInt(11)-1);\n    }\n    stress = backupStress;  // restore stress\n\n    // test faceting multiple things at once\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1);\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id:[1 TO 7]\", \"fq\",\"{!tag=b}id:[3 TO 9]\"\n    );\n    query(\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\");\n\n    // test field that is valid in schema but missing in all shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2);\n    // test field that is valid in schema and missing in some shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2);\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", \"stats_dt\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1);\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", tdate_a);\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", tdate_b);\n\n    handle.put(\"stats_fields\", UNORDERED);\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \n          \"stats.field\", \"stats_dt\", \n          \"stats.field\", i1, \n          \"stats.field\", tdate_a, \n          \"stats.field\", tdate_b);\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    // check a complex key name\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"*:*\", \"rows\",100);\n    }\n\n    //SOLR 3161 ensure shards.qt=/update fails (anything but search handler really)\n    // Also see TestRemoteStreaming#testQtUpdateFails()\n    try {\n      ignoreException(\"isShard is only acceptable\");\n      // query(\"q\",\"*:*\",\"shards.qt\",\"/update\",\"stream.body\",\"<delete><query>*:*</query></delete>\");\n      // fail();\n    } catch (SolrException e) {\n      //expected\n    }\n    unIgnoreException(\"isShard is only acceptable\");\n\n    // test debugging\n    // handle.put(\"explain\", UNORDERED);\n    handle.put(\"explain\", SKIPVAL);  // internal docids differ, idf differs w/o global idf\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    handle.put(\"track\", SKIP); //track is not included in single node search\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY);\n\n    // Check Info is added to for each shard\n    ModifiableSolrParams q = new ModifiableSolrParams();\n    q.set(\"q\", \"*:*\");\n    q.set(ShardParams.SHARDS_INFO, true);\n    setDistributedParams(q);\n    QueryResponse rsp = queryServer(q);\n    NamedList<?> sinfo = (NamedList<?>) rsp.getResponse().get(ShardParams.SHARDS_INFO);\n    String shards = getShardsString();\n    int cnt = StringUtils.countMatches(shards, \",\")+1;\n    \n    assertNotNull(\"missing shard info\", sinfo);\n    assertEquals(\"should have an entry for each shard [\"+sinfo+\"] \"+shards, cnt, sinfo.size());\n\n    // test shards.tolerant=true\n    for(int numDownServers = 0; numDownServers < jettys.size()-1; numDownServers++)\n    {\n      List<JettySolrRunner> upJettys = new ArrayList<>(jettys);\n      List<SolrServer> upClients = new ArrayList<>(clients);\n      List<JettySolrRunner> downJettys = new ArrayList<>();\n      List<String> upShards = new ArrayList<>(Arrays.asList(shardsArr));\n      for(int i=0; i<numDownServers; i++)\n      {\n        // shut down some of the jettys\n        int indexToRemove = r.nextInt(upJettys.size());\n        JettySolrRunner downJetty = upJettys.remove(indexToRemove);\n        upClients.remove(indexToRemove);\n        upShards.remove(indexToRemove);\n        ChaosMonkey.stop(downJetty);\n        downJettys.add(downJetty);\n      }\n\n      queryPartialResults(upShards, upClients, \n          \"q\",\"*:*\",\n          \"facet\",\"true\", \n          \"facet.field\",t1,\n          \"facet.limit\",5,\n          ShardParams.SHARDS_INFO,\"true\",\n          ShardParams.SHARDS_TOLERANT,\"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"facet\", \"true\",\n          \"facet.query\", i1 + \":[1 TO 50]\",\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      // test group query\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"rows\", 100,\n          \"fl\", \"id,\" + i1,\n          \"group\", \"true\",\n          \"group.query\", t1 + \":kings OR \" + t1 + \":eggs\",\n          \"group.limit\", 10,\n          \"sort\", i1 + \" asc, id asc\",\n          CommonParams.TIME_ALLOWED, 1,\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"stats\", \"true\",\n          \"stats.field\", i1,\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"toyata\",\n          \"spellcheck\", \"true\",\n          \"spellcheck.q\", \"toyata\",\n          \"qt\", \"spellCheckCompRH_Direct\",\n          \"shards.qt\", \"spellCheckCompRH_Direct\",\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      // restart the jettys\n      for (JettySolrRunner downJetty : downJettys) {\n        downJetty.start();\n      }\n    }\n\n    // This index has the same number for every field\n    \n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // Thread.sleep(10000000000L);\n\n    FieldCache.DEFAULT.purgeAllCaches();   // avoid FC insanity\n\n    del(\"*:*\"); // delete all docs and test stats request\n    commit();\n    try {\n      query(\"q\", \"*:*\", \"stats\", \"true\", \n            \"stats.field\", \"stats_dt\", \n            \"stats.field\", i1, \n            \"stats.field\", tdate_a, \n            \"stats.field\", tdate_b,\n            \"stats.calcdistinct\", \"true\");\n    } catch (Exception e) {\n      log.error(\"Exception on distrib stats request on empty index\", e);\n      fail(\"NullPointerException with stats request on empty index\");\n    }\n  }\n\n","bugFix":null,"bugIntro":["9274621789ce990dbfef455dabdf026bb3184821"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"9274621789ce990dbfef455dabdf026bb3184821","date":1400046684,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/TestDistributedSearch#doTest().mjava","pathOld":"solr/core/src/test/org/apache/solr/TestDistributedSearch#doTest().mjava","sourceNew":"  @Override\n  public void doTest() throws Exception {\n    int backupStress = stress; // make a copy so we can restore\n\n\n    del(\"*:*\");\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\", \n           tdate_a, \"2010-04-20T11:00:00Z\",\n           tdate_b, \"2009-08-20T11:00:00Z\",\n           \"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\", \n           tdate_a, \"2010-05-02T11:00:00Z\",\n           tdate_b, \"2009-11-02T11:00:00Z\");\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\", \n           tdate_a, \"2010-05-03T11:00:00Z\");\n    indexr(id,4, i1, -100 ,tlong, 101,\n           t1,\"the quick fox jumped over the lazy dog\", \n           tdate_a, \"2010-05-03T11:00:00Z\",\n           tdate_b, \"2010-05-03T11:00:00Z\");\n    indexr(id,5, i1, 500, tlong, 500 ,\n           t1,\"the quick fox jumped way over the lazy dog\", \n           tdate_a, \"2010-05-05T11:00:00Z\");\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,\n           tdate_b, \"2010-01-05T11:00:00Z\",\n           t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n\n    commit();  // try to ensure there's more than one segment\n\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,\n           t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,\n           t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,\n           t1,\"no eggs on wall, lesson learned\", \n           oddField, \"odd man out\");\n\n    indexr(id, \"1001\", \"lowerfilt\", \"toyota\"); // for spellcheck\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n    \n    \n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n\n    handle.clear();\n    handle.put(\"QTime\", SKIPVAL);\n    handle.put(\"timestamp\", SKIPVAL);\n    handle.put(\"_version_\", SKIPVAL); // not a cloud test, but may use updateLog\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(\"q\",\"*:*\", \"sort\",f+\" desc\");\n      query(\"q\",\"*:*\", \"sort\",f+\" asc\");\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",\"{!func}testfunc(add(\"+i1+\",5))\"+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" asc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\");\n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"*,score\"); \n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 desc\");\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"{!func}\"+i1);// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(\"q\",\"{!func}\"+i1, \"fl\",\"*,score\");  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"quick\");\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\");\n    query(\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\");  // no fields in returned docs\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\");\n\n    handle.put(\"score\", SKIPVAL);\n    query(\"q\",\"quick\",\"fl\",\"*,score\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\");\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"matchesnothing\",\"fl\",\"*,score\");  \n\n    // test that a single NOW value is propagated to all shards... if that is true\n    // then the primary sort should always be a tie and then the secondary should always decide\n    query(\"q\",\"{!func}ms(NOW)\", \"sort\",\"score desc,\"+i1+\" desc\",\"fl\",\"id\");    \n\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\");\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2);\n\n    // a facet query to test out chars out of the ascii range\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!term f=foo_s}international\\u00ff\\u01ff\\u2222\\u3333\");\n\n    // simple date facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date.other\", \"all\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // date facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date\",tdate_b, \n          \"facet.date.other\", \"all\", \n          \"f.\"+tdate_b+\".facet.date.start\",\"2009-05-01T11:00:00Z\", \n          \"f.\"+tdate_b+\".facet.date.gap\",\"+3MONTHS\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // simple range facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"facet.range.end\",900);\n\n    // range facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range\",i1, \n          \"f.\"+i1+\".facet.range.start\",300, \n          \"f.\"+i1+\".facet.range.gap\",87, \n          \"facet.range.end\",900,\n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"f.\"+tlong+\".facet.range.end\",900);\n    \n    //  variations of fl\n    query(\"q\",\"*:*\", \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1 + \",score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", i1, \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id,\" + i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1, \"fl\", \"id\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",nint, \"fl\",tint,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",nint, \"fl\", \"id\", \"fl\",tint,\"sort\",i1 + \" desc\");\n\n    // basic spellcheck testing\n    query(\"q\", \"toyata\", \"fl\", \"id,lowerfilt\", \"spellcheck\", true, \"spellcheck.q\", \"toyata\", \"qt\", \"spellCheckCompRH_Direct\", \"shards.qt\", \"spellCheckCompRH_Direct\");\n\n    stress=0;  // turn off stress... we want to tex max combos in min time\n    for (int i=0; i<25*RANDOM_MULTIPLIER; i++) {\n      String f = fieldNames[random().nextInt(fieldNames.length)];\n      if (random().nextBoolean()) f = t1;  // the text field is a really interesting one to facet on (and it's multi-valued too)\n\n      // we want a random query and not just *:* so we'll get zero counts in facets also\n      // TODO: do a better random query\n      String q = random().nextBoolean() ? \"*:*\" : \"id:(1 3 5 7 9 11 13) OR id:[100 TO \" + random().nextInt(50) + \"]\";\n\n      int nolimit = random().nextBoolean() ? -1 : 10000;  // these should be equivalent\n\n      // if limit==-1, we should always get exact matches\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"count\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      // for index sort, we should get exact results for mincount <= 1\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(2), \"facet.offset\",random().nextInt(10), \"facet.limit\",random().nextInt(11)-1);\n    }\n    stress = backupStress;  // restore stress\n\n    // test faceting multiple things at once\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1);\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id:[1 TO 7]\", \"fq\",\"{!tag=b}id:[3 TO 9]\"\n    );\n    query(\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\");\n\n    // test field that is valid in schema but missing in all shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2);\n    // test field that is valid in schema and missing in some shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2);\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", \"stats_dt\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1);\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", tdate_a);\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", tdate_b);\n\n    handle.put(\"stats_fields\", UNORDERED);\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \n          \"stats.field\", \"stats_dt\", \n          \"stats.field\", i1, \n          \"stats.field\", tdate_a, \n          \"stats.field\", tdate_b);\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    // check a complex key name\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"*:*\", \"rows\",100);\n    }\n\n    //SOLR 3161 ensure shards.qt=/update fails (anything but search handler really)\n    // Also see TestRemoteStreaming#testQtUpdateFails()\n    try {\n      ignoreException(\"isShard is only acceptable\");\n      // query(\"q\",\"*:*\",\"shards.qt\",\"/update\",\"stream.body\",\"<delete><query>*:*</query></delete>\");\n      // fail();\n    } catch (SolrException e) {\n      //expected\n    }\n    unIgnoreException(\"isShard is only acceptable\");\n\n    // test debugging\n    // handle.put(\"explain\", UNORDERED);\n    handle.put(\"explain\", SKIPVAL);  // internal docids differ, idf differs w/o global idf\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    handle.put(\"track\", SKIP); //track is not included in single node search\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY);\n\n    // Check Info is added to for each shard\n    ModifiableSolrParams q = new ModifiableSolrParams();\n    q.set(\"q\", \"*:*\");\n    q.set(ShardParams.SHARDS_INFO, true);\n    setDistributedParams(q);\n    QueryResponse rsp = queryServer(q);\n    NamedList<?> sinfo = (NamedList<?>) rsp.getResponse().get(ShardParams.SHARDS_INFO);\n    String shards = getShardsString();\n    int cnt = StringUtils.countMatches(shards, \",\")+1;\n    \n    assertNotNull(\"missing shard info\", sinfo);\n    assertEquals(\"should have an entry for each shard [\"+sinfo+\"] \"+shards, cnt, sinfo.size());\n\n    // test shards.tolerant=true\n    for(int numDownServers = 0; numDownServers < jettys.size()-1; numDownServers++)\n    {\n      List<JettySolrRunner> upJettys = new ArrayList<>(jettys);\n      List<SolrServer> upClients = new ArrayList<>(clients);\n      List<JettySolrRunner> downJettys = new ArrayList<>();\n      List<String> upShards = new ArrayList<>(Arrays.asList(shardsArr));\n      for(int i=0; i<numDownServers; i++)\n      {\n        // shut down some of the jettys\n        int indexToRemove = r.nextInt(upJettys.size());\n        JettySolrRunner downJetty = upJettys.remove(indexToRemove);\n        upClients.remove(indexToRemove);\n        upShards.remove(indexToRemove);\n        ChaosMonkey.stop(downJetty);\n        downJettys.add(downJetty);\n      }\n\n      queryPartialResults(upShards, upClients, \n          \"q\",\"*:*\",\n          \"facet\",\"true\", \n          \"facet.field\",t1,\n          \"facet.limit\",5,\n          ShardParams.SHARDS_INFO,\"true\",\n          ShardParams.SHARDS_TOLERANT,\"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"facet\", \"true\",\n          \"facet.query\", i1 + \":[1 TO 50]\",\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      // test group query\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"rows\", 100,\n          \"fl\", \"id,\" + i1,\n          \"group\", \"true\",\n          \"group.query\", t1 + \":kings OR \" + t1 + \":eggs\",\n          \"group.limit\", 10,\n          \"sort\", i1 + \" asc, id asc\",\n          CommonParams.TIME_ALLOWED, 1,\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"stats\", \"true\",\n          \"stats.field\", i1,\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"toyata\",\n          \"spellcheck\", \"true\",\n          \"spellcheck.q\", \"toyata\",\n          \"qt\", \"spellCheckCompRH_Direct\",\n          \"shards.qt\", \"spellCheckCompRH_Direct\",\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      // restart the jettys\n      for (JettySolrRunner downJetty : downJettys) {\n        downJetty.start();\n      }\n    }\n\n    // This index has the same number for every field\n    \n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // Thread.sleep(10000000000L);\n\n    del(\"*:*\"); // delete all docs and test stats request\n    commit();\n    try {\n      query(\"q\", \"*:*\", \"stats\", \"true\", \n            \"stats.field\", \"stats_dt\", \n            \"stats.field\", i1, \n            \"stats.field\", tdate_a, \n            \"stats.field\", tdate_b,\n            \"stats.calcdistinct\", \"true\");\n    } catch (Exception e) {\n      log.error(\"Exception on distrib stats request on empty index\", e);\n      fail(\"NullPointerException with stats request on empty index\");\n    }\n  }\n\n","sourceOld":"  @Override\n  public void doTest() throws Exception {\n    int backupStress = stress; // make a copy so we can restore\n\n\n    del(\"*:*\");\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\", \n           tdate_a, \"2010-04-20T11:00:00Z\",\n           tdate_b, \"2009-08-20T11:00:00Z\",\n           \"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\", \n           tdate_a, \"2010-05-02T11:00:00Z\",\n           tdate_b, \"2009-11-02T11:00:00Z\");\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\", \n           tdate_a, \"2010-05-03T11:00:00Z\");\n    indexr(id,4, i1, -100 ,tlong, 101,\n           t1,\"the quick fox jumped over the lazy dog\", \n           tdate_a, \"2010-05-03T11:00:00Z\",\n           tdate_b, \"2010-05-03T11:00:00Z\");\n    indexr(id,5, i1, 500, tlong, 500 ,\n           t1,\"the quick fox jumped way over the lazy dog\", \n           tdate_a, \"2010-05-05T11:00:00Z\");\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,\n           tdate_b, \"2010-01-05T11:00:00Z\",\n           t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n\n    commit();  // try to ensure there's more than one segment\n\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,\n           t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,\n           t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,\n           t1,\"no eggs on wall, lesson learned\", \n           oddField, \"odd man out\");\n\n    indexr(id, \"1001\", \"lowerfilt\", \"toyota\"); // for spellcheck\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n    \n    \n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n\n    handle.clear();\n    handle.put(\"QTime\", SKIPVAL);\n    handle.put(\"timestamp\", SKIPVAL);\n    handle.put(\"_version_\", SKIPVAL); // not a cloud test, but may use updateLog\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(\"q\",\"*:*\", \"sort\",f+\" desc\");\n      query(\"q\",\"*:*\", \"sort\",f+\" asc\");\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",\"{!func}testfunc(add(\"+i1+\",5))\"+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" asc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\");\n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"*,score\"); \n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 desc\");\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"{!func}\"+i1);// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(\"q\",\"{!func}\"+i1, \"fl\",\"*,score\");  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"quick\");\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\");\n    query(\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\");  // no fields in returned docs\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\");\n\n    handle.put(\"score\", SKIPVAL);\n    query(\"q\",\"quick\",\"fl\",\"*,score\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\");\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"matchesnothing\",\"fl\",\"*,score\");  \n\n    // test that a single NOW value is propagated to all shards... if that is true\n    // then the primary sort should always be a tie and then the secondary should always decide\n    query(\"q\",\"{!func}ms(NOW)\", \"sort\",\"score desc,\"+i1+\" desc\",\"fl\",\"id\");    \n\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\");\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2);\n\n    // a facet query to test out chars out of the ascii range\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!term f=foo_s}international\\u00ff\\u01ff\\u2222\\u3333\");\n\n    // simple date facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date.other\", \"all\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // date facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date\",tdate_b, \n          \"facet.date.other\", \"all\", \n          \"f.\"+tdate_b+\".facet.date.start\",\"2009-05-01T11:00:00Z\", \n          \"f.\"+tdate_b+\".facet.date.gap\",\"+3MONTHS\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // simple range facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"facet.range.end\",900);\n\n    // range facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range\",i1, \n          \"f.\"+i1+\".facet.range.start\",300, \n          \"f.\"+i1+\".facet.range.gap\",87, \n          \"facet.range.end\",900,\n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"f.\"+tlong+\".facet.range.end\",900);\n    \n    //  variations of fl\n    query(\"q\",\"*:*\", \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1 + \",score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", i1, \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id,\" + i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1, \"fl\", \"id\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",nint, \"fl\",tint,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",nint, \"fl\", \"id\", \"fl\",tint,\"sort\",i1 + \" desc\");\n\n    // basic spellcheck testing\n    query(\"q\", \"toyata\", \"fl\", \"id,lowerfilt\", \"spellcheck\", true, \"spellcheck.q\", \"toyata\", \"qt\", \"spellCheckCompRH_Direct\", \"shards.qt\", \"spellCheckCompRH_Direct\");\n\n    stress=0;  // turn off stress... we want to tex max combos in min time\n    for (int i=0; i<25*RANDOM_MULTIPLIER; i++) {\n      String f = fieldNames[random().nextInt(fieldNames.length)];\n      if (random().nextBoolean()) f = t1;  // the text field is a really interesting one to facet on (and it's multi-valued too)\n\n      // we want a random query and not just *:* so we'll get zero counts in facets also\n      // TODO: do a better random query\n      String q = random().nextBoolean() ? \"*:*\" : \"id:(1 3 5 7 9 11 13) OR id:[100 TO \" + random().nextInt(50) + \"]\";\n\n      int nolimit = random().nextBoolean() ? -1 : 10000;  // these should be equivalent\n\n      // if limit==-1, we should always get exact matches\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"count\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      // for index sort, we should get exact results for mincount <= 1\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(2), \"facet.offset\",random().nextInt(10), \"facet.limit\",random().nextInt(11)-1);\n    }\n    stress = backupStress;  // restore stress\n\n    // test faceting multiple things at once\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1);\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id:[1 TO 7]\", \"fq\",\"{!tag=b}id:[3 TO 9]\"\n    );\n    query(\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\");\n\n    // test field that is valid in schema but missing in all shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2);\n    // test field that is valid in schema and missing in some shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2);\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", \"stats_dt\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1);\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", tdate_a);\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", tdate_b);\n\n    handle.put(\"stats_fields\", UNORDERED);\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \n          \"stats.field\", \"stats_dt\", \n          \"stats.field\", i1, \n          \"stats.field\", tdate_a, \n          \"stats.field\", tdate_b);\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    // check a complex key name\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"*:*\", \"rows\",100);\n    }\n\n    //SOLR 3161 ensure shards.qt=/update fails (anything but search handler really)\n    // Also see TestRemoteStreaming#testQtUpdateFails()\n    try {\n      ignoreException(\"isShard is only acceptable\");\n      // query(\"q\",\"*:*\",\"shards.qt\",\"/update\",\"stream.body\",\"<delete><query>*:*</query></delete>\");\n      // fail();\n    } catch (SolrException e) {\n      //expected\n    }\n    unIgnoreException(\"isShard is only acceptable\");\n\n    // test debugging\n    // handle.put(\"explain\", UNORDERED);\n    handle.put(\"explain\", SKIPVAL);  // internal docids differ, idf differs w/o global idf\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    handle.put(\"track\", SKIP); //track is not included in single node search\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY);\n\n    // Check Info is added to for each shard\n    ModifiableSolrParams q = new ModifiableSolrParams();\n    q.set(\"q\", \"*:*\");\n    q.set(ShardParams.SHARDS_INFO, true);\n    setDistributedParams(q);\n    QueryResponse rsp = queryServer(q);\n    NamedList<?> sinfo = (NamedList<?>) rsp.getResponse().get(ShardParams.SHARDS_INFO);\n    String shards = getShardsString();\n    int cnt = StringUtils.countMatches(shards, \",\")+1;\n    \n    assertNotNull(\"missing shard info\", sinfo);\n    assertEquals(\"should have an entry for each shard [\"+sinfo+\"] \"+shards, cnt, sinfo.size());\n\n    // test shards.tolerant=true\n    for(int numDownServers = 0; numDownServers < jettys.size()-1; numDownServers++)\n    {\n      List<JettySolrRunner> upJettys = new ArrayList<>(jettys);\n      List<SolrServer> upClients = new ArrayList<>(clients);\n      List<JettySolrRunner> downJettys = new ArrayList<>();\n      List<String> upShards = new ArrayList<>(Arrays.asList(shardsArr));\n      for(int i=0; i<numDownServers; i++)\n      {\n        // shut down some of the jettys\n        int indexToRemove = r.nextInt(upJettys.size());\n        JettySolrRunner downJetty = upJettys.remove(indexToRemove);\n        upClients.remove(indexToRemove);\n        upShards.remove(indexToRemove);\n        ChaosMonkey.stop(downJetty);\n        downJettys.add(downJetty);\n      }\n\n      queryPartialResults(upShards, upClients, \n          \"q\",\"*:*\",\n          \"facet\",\"true\", \n          \"facet.field\",t1,\n          \"facet.limit\",5,\n          ShardParams.SHARDS_INFO,\"true\",\n          ShardParams.SHARDS_TOLERANT,\"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"facet\", \"true\",\n          \"facet.query\", i1 + \":[1 TO 50]\",\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      // test group query\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"rows\", 100,\n          \"fl\", \"id,\" + i1,\n          \"group\", \"true\",\n          \"group.query\", t1 + \":kings OR \" + t1 + \":eggs\",\n          \"group.limit\", 10,\n          \"sort\", i1 + \" asc, id asc\",\n          CommonParams.TIME_ALLOWED, 1,\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"stats\", \"true\",\n          \"stats.field\", i1,\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"toyata\",\n          \"spellcheck\", \"true\",\n          \"spellcheck.q\", \"toyata\",\n          \"qt\", \"spellCheckCompRH_Direct\",\n          \"shards.qt\", \"spellCheckCompRH_Direct\",\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      // restart the jettys\n      for (JettySolrRunner downJetty : downJettys) {\n        downJetty.start();\n      }\n    }\n\n    // This index has the same number for every field\n    \n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // Thread.sleep(10000000000L);\n\n    // nocommit: split test if needed\n    // FieldCache.DEFAULT.purgeAllCaches();   // hide FC insanity\n\n    del(\"*:*\"); // delete all docs and test stats request\n    commit();\n    try {\n      query(\"q\", \"*:*\", \"stats\", \"true\", \n            \"stats.field\", \"stats_dt\", \n            \"stats.field\", i1, \n            \"stats.field\", tdate_a, \n            \"stats.field\", tdate_b,\n            \"stats.calcdistinct\", \"true\");\n    } catch (Exception e) {\n      log.error(\"Exception on distrib stats request on empty index\", e);\n      fail(\"NullPointerException with stats request on empty index\");\n    }\n  }\n\n","bugFix":["e28b14e7783d24ca69089f13ddadadbd2afdcb29","c1500c4d2642ffe9c4fc6a09a7674b69a550fd36"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"93dd449115a9247533e44bab47e8429e5dccbc6d","date":1400258396,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/TestDistributedSearch#doTest().mjava","pathOld":"solr/core/src/test/org/apache/solr/TestDistributedSearch#doTest().mjava","sourceNew":"  @Override\n  public void doTest() throws Exception {\n    int backupStress = stress; // make a copy so we can restore\n\n\n    del(\"*:*\");\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\", \n           tdate_a, \"2010-04-20T11:00:00Z\",\n           tdate_b, \"2009-08-20T11:00:00Z\",\n           \"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\", \n           tdate_a, \"2010-05-02T11:00:00Z\",\n           tdate_b, \"2009-11-02T11:00:00Z\");\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\", \n           tdate_a, \"2010-05-03T11:00:00Z\");\n    indexr(id,4, i1, -100 ,tlong, 101,\n           t1,\"the quick fox jumped over the lazy dog\", \n           tdate_a, \"2010-05-03T11:00:00Z\",\n           tdate_b, \"2010-05-03T11:00:00Z\");\n    indexr(id,5, i1, 500, tlong, 500 ,\n           t1,\"the quick fox jumped way over the lazy dog\", \n           tdate_a, \"2010-05-05T11:00:00Z\");\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,\n           tdate_b, \"2010-01-05T11:00:00Z\",\n           t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n\n    commit();  // try to ensure there's more than one segment\n\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,\n           t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,\n           t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,\n           t1,\"no eggs on wall, lesson learned\", \n           oddField, \"odd man out\");\n\n    indexr(id, \"1001\", \"lowerfilt\", \"toyota\"); // for spellcheck\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n    \n    \n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n\n    handle.clear();\n    handle.put(\"QTime\", SKIPVAL);\n    handle.put(\"timestamp\", SKIPVAL);\n    handle.put(\"_version_\", SKIPVAL); // not a cloud test, but may use updateLog\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(\"q\",\"*:*\", \"sort\",f+\" desc\");\n      query(\"q\",\"*:*\", \"sort\",f+\" asc\");\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",\"{!func}testfunc(add(\"+i1+\",5))\"+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" asc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\");\n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"*,score\"); \n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 desc\");\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"{!func}\"+i1);// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(\"q\",\"{!func}\"+i1, \"fl\",\"*,score\");  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"quick\");\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\");\n    query(\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\");  // no fields in returned docs\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\");\n\n    handle.put(\"score\", SKIPVAL);\n    query(\"q\",\"quick\",\"fl\",\"*,score\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\");\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"matchesnothing\",\"fl\",\"*,score\");  \n\n    // test that a single NOW value is propagated to all shards... if that is true\n    // then the primary sort should always be a tie and then the secondary should always decide\n    query(\"q\",\"{!func}ms(NOW)\", \"sort\",\"score desc,\"+i1+\" desc\",\"fl\",\"id\");    \n\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\");\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2);\n\n    // a facet query to test out chars out of the ascii range\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!term f=foo_s}international\\u00ff\\u01ff\\u2222\\u3333\");\n\n    // simple date facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date.other\", \"all\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // date facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date\",tdate_b, \n          \"facet.date.other\", \"all\", \n          \"f.\"+tdate_b+\".facet.date.start\",\"2009-05-01T11:00:00Z\", \n          \"f.\"+tdate_b+\".facet.date.gap\",\"+3MONTHS\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // simple range facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"facet.range.end\",900);\n\n    // range facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range\",i1, \n          \"f.\"+i1+\".facet.range.start\",300, \n          \"f.\"+i1+\".facet.range.gap\",87, \n          \"facet.range.end\",900,\n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"f.\"+tlong+\".facet.range.end\",900);\n    \n    //  variations of fl\n    query(\"q\",\"*:*\", \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1 + \",score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", i1, \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id,\" + i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1, \"fl\", \"id\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",nint, \"fl\",tint,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",nint, \"fl\", \"id\", \"fl\",tint,\"sort\",i1 + \" desc\");\n\n    // basic spellcheck testing\n    query(\"q\", \"toyata\", \"fl\", \"id,lowerfilt\", \"spellcheck\", true, \"spellcheck.q\", \"toyata\", \"qt\", \"spellCheckCompRH_Direct\", \"shards.qt\", \"spellCheckCompRH_Direct\");\n\n    stress=0;  // turn off stress... we want to tex max combos in min time\n    for (int i=0; i<25*RANDOM_MULTIPLIER; i++) {\n      String f = fieldNames[random().nextInt(fieldNames.length)];\n      if (random().nextBoolean()) f = t1;  // the text field is a really interesting one to facet on (and it's multi-valued too)\n\n      // we want a random query and not just *:* so we'll get zero counts in facets also\n      // TODO: do a better random query\n      String q = random().nextBoolean() ? \"*:*\" : \"id:(1 3 5 7 9 11 13) OR id:[100 TO \" + random().nextInt(50) + \"]\";\n\n      int nolimit = random().nextBoolean() ? -1 : 10000;  // these should be equivalent\n\n      // if limit==-1, we should always get exact matches\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"count\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      // for index sort, we should get exact results for mincount <= 1\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(2), \"facet.offset\",random().nextInt(10), \"facet.limit\",random().nextInt(11)-1);\n    }\n    stress = backupStress;  // restore stress\n\n    // test faceting multiple things at once\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1);\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id:[1 TO 7]\", \"fq\",\"{!tag=b}id:[3 TO 9]\"\n    );\n    query(\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\");\n\n    // test field that is valid in schema but missing in all shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2);\n    // test field that is valid in schema and missing in some shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2);\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", \"stats_dt\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1);\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", tdate_a);\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", tdate_b);\n\n    handle.put(\"stats_fields\", UNORDERED);\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \n          \"stats.field\", \"stats_dt\", \n          \"stats.field\", i1, \n          \"stats.field\", tdate_a, \n          \"stats.field\", tdate_b);\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    // check a complex key name\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"*:*\", \"rows\",100);\n    }\n\n    //SOLR 3161 ensure shards.qt=/update fails (anything but search handler really)\n    // Also see TestRemoteStreaming#testQtUpdateFails()\n    try {\n      ignoreException(\"isShard is only acceptable\");\n      // query(\"q\",\"*:*\",\"shards.qt\",\"/update\",\"stream.body\",\"<delete><query>*:*</query></delete>\");\n      // fail();\n    } catch (SolrException e) {\n      //expected\n    }\n    unIgnoreException(\"isShard is only acceptable\");\n\n    // test debugging\n    // handle.put(\"explain\", UNORDERED);\n    handle.put(\"explain\", SKIPVAL);  // internal docids differ, idf differs w/o global idf\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    handle.put(\"track\", SKIP); //track is not included in single node search\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY);\n\n    // Check Info is added to for each shard\n    ModifiableSolrParams q = new ModifiableSolrParams();\n    q.set(\"q\", \"*:*\");\n    q.set(ShardParams.SHARDS_INFO, true);\n    setDistributedParams(q);\n    QueryResponse rsp = queryServer(q);\n    NamedList<?> sinfo = (NamedList<?>) rsp.getResponse().get(ShardParams.SHARDS_INFO);\n    String shards = getShardsString();\n    int cnt = StringUtils.countMatches(shards, \",\")+1;\n    \n    assertNotNull(\"missing shard info\", sinfo);\n    assertEquals(\"should have an entry for each shard [\"+sinfo+\"] \"+shards, cnt, sinfo.size());\n\n    // test shards.tolerant=true\n    for(int numDownServers = 0; numDownServers < jettys.size()-1; numDownServers++)\n    {\n      List<JettySolrRunner> upJettys = new ArrayList<>(jettys);\n      List<SolrServer> upClients = new ArrayList<>(clients);\n      List<JettySolrRunner> downJettys = new ArrayList<>();\n      List<String> upShards = new ArrayList<>(Arrays.asList(shardsArr));\n      for(int i=0; i<numDownServers; i++)\n      {\n        // shut down some of the jettys\n        int indexToRemove = r.nextInt(upJettys.size());\n        JettySolrRunner downJetty = upJettys.remove(indexToRemove);\n        upClients.remove(indexToRemove);\n        upShards.remove(indexToRemove);\n        ChaosMonkey.stop(downJetty);\n        downJettys.add(downJetty);\n      }\n\n      queryPartialResults(upShards, upClients, \n          \"q\",\"*:*\",\n          \"facet\",\"true\", \n          \"facet.field\",t1,\n          \"facet.limit\",5,\n          ShardParams.SHARDS_INFO,\"true\",\n          ShardParams.SHARDS_TOLERANT,\"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"facet\", \"true\",\n          \"facet.query\", i1 + \":[1 TO 50]\",\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      // test group query\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"rows\", 100,\n          \"fl\", \"id,\" + i1,\n          \"group\", \"true\",\n          \"group.query\", t1 + \":kings OR \" + t1 + \":eggs\",\n          \"group.limit\", 10,\n          \"sort\", i1 + \" asc, id asc\",\n          CommonParams.TIME_ALLOWED, 1,\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"stats\", \"true\",\n          \"stats.field\", i1,\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"toyata\",\n          \"spellcheck\", \"true\",\n          \"spellcheck.q\", \"toyata\",\n          \"qt\", \"spellCheckCompRH_Direct\",\n          \"shards.qt\", \"spellCheckCompRH_Direct\",\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      // restart the jettys\n      for (JettySolrRunner downJetty : downJettys) {\n        downJetty.start();\n      }\n    }\n\n    // This index has the same number for every field\n    \n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // Thread.sleep(10000000000L);\n\n    del(\"*:*\"); // delete all docs and test stats request\n    commit();\n    try {\n      query(\"q\", \"*:*\", \"stats\", \"true\", \n            \"stats.field\", \"stats_dt\", \n            \"stats.field\", i1, \n            \"stats.field\", tdate_a, \n            \"stats.field\", tdate_b,\n            \"stats.calcdistinct\", \"true\");\n    } catch (Exception e) {\n      log.error(\"Exception on distrib stats request on empty index\", e);\n      fail(\"NullPointerException with stats request on empty index\");\n    }\n  }\n\n","sourceOld":"  @Override\n  public void doTest() throws Exception {\n    int backupStress = stress; // make a copy so we can restore\n\n\n    del(\"*:*\");\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\", \n           tdate_a, \"2010-04-20T11:00:00Z\",\n           tdate_b, \"2009-08-20T11:00:00Z\",\n           \"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\", \n           tdate_a, \"2010-05-02T11:00:00Z\",\n           tdate_b, \"2009-11-02T11:00:00Z\");\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\", \n           tdate_a, \"2010-05-03T11:00:00Z\");\n    indexr(id,4, i1, -100 ,tlong, 101,\n           t1,\"the quick fox jumped over the lazy dog\", \n           tdate_a, \"2010-05-03T11:00:00Z\",\n           tdate_b, \"2010-05-03T11:00:00Z\");\n    indexr(id,5, i1, 500, tlong, 500 ,\n           t1,\"the quick fox jumped way over the lazy dog\", \n           tdate_a, \"2010-05-05T11:00:00Z\");\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,\n           tdate_b, \"2010-01-05T11:00:00Z\",\n           t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n\n    commit();  // try to ensure there's more than one segment\n\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,\n           t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,\n           t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,\n           t1,\"no eggs on wall, lesson learned\", \n           oddField, \"odd man out\");\n\n    indexr(id, \"1001\", \"lowerfilt\", \"toyota\"); // for spellcheck\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n    \n    \n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n\n    handle.clear();\n    handle.put(\"QTime\", SKIPVAL);\n    handle.put(\"timestamp\", SKIPVAL);\n    handle.put(\"_version_\", SKIPVAL); // not a cloud test, but may use updateLog\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(\"q\",\"*:*\", \"sort\",f+\" desc\");\n      query(\"q\",\"*:*\", \"sort\",f+\" asc\");\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",\"{!func}testfunc(add(\"+i1+\",5))\"+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" asc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\");\n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"*,score\"); \n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 desc\");\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"{!func}\"+i1);// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(\"q\",\"{!func}\"+i1, \"fl\",\"*,score\");  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"quick\");\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\");\n    query(\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\");  // no fields in returned docs\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\");\n\n    handle.put(\"score\", SKIPVAL);\n    query(\"q\",\"quick\",\"fl\",\"*,score\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\");\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"matchesnothing\",\"fl\",\"*,score\");  \n\n    // test that a single NOW value is propagated to all shards... if that is true\n    // then the primary sort should always be a tie and then the secondary should always decide\n    query(\"q\",\"{!func}ms(NOW)\", \"sort\",\"score desc,\"+i1+\" desc\",\"fl\",\"id\");    \n\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\");\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2);\n\n    // a facet query to test out chars out of the ascii range\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!term f=foo_s}international\\u00ff\\u01ff\\u2222\\u3333\");\n\n    // simple date facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date.other\", \"all\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // date facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date\",tdate_b, \n          \"facet.date.other\", \"all\", \n          \"f.\"+tdate_b+\".facet.date.start\",\"2009-05-01T11:00:00Z\", \n          \"f.\"+tdate_b+\".facet.date.gap\",\"+3MONTHS\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // simple range facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"facet.range.end\",900);\n\n    // range facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range\",i1, \n          \"f.\"+i1+\".facet.range.start\",300, \n          \"f.\"+i1+\".facet.range.gap\",87, \n          \"facet.range.end\",900,\n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"f.\"+tlong+\".facet.range.end\",900);\n    \n    //  variations of fl\n    query(\"q\",\"*:*\", \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1 + \",score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", i1, \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id,\" + i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1, \"fl\", \"id\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",nint, \"fl\",tint,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",nint, \"fl\", \"id\", \"fl\",tint,\"sort\",i1 + \" desc\");\n\n    // basic spellcheck testing\n    query(\"q\", \"toyata\", \"fl\", \"id,lowerfilt\", \"spellcheck\", true, \"spellcheck.q\", \"toyata\", \"qt\", \"spellCheckCompRH_Direct\", \"shards.qt\", \"spellCheckCompRH_Direct\");\n\n    stress=0;  // turn off stress... we want to tex max combos in min time\n    for (int i=0; i<25*RANDOM_MULTIPLIER; i++) {\n      String f = fieldNames[random().nextInt(fieldNames.length)];\n      if (random().nextBoolean()) f = t1;  // the text field is a really interesting one to facet on (and it's multi-valued too)\n\n      // we want a random query and not just *:* so we'll get zero counts in facets also\n      // TODO: do a better random query\n      String q = random().nextBoolean() ? \"*:*\" : \"id:(1 3 5 7 9 11 13) OR id:[100 TO \" + random().nextInt(50) + \"]\";\n\n      int nolimit = random().nextBoolean() ? -1 : 10000;  // these should be equivalent\n\n      // if limit==-1, we should always get exact matches\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"count\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      // for index sort, we should get exact results for mincount <= 1\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(2), \"facet.offset\",random().nextInt(10), \"facet.limit\",random().nextInt(11)-1);\n    }\n    stress = backupStress;  // restore stress\n\n    // test faceting multiple things at once\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1);\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id:[1 TO 7]\", \"fq\",\"{!tag=b}id:[3 TO 9]\"\n    );\n    query(\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\");\n\n    // test field that is valid in schema but missing in all shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2);\n    // test field that is valid in schema and missing in some shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2);\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", \"stats_dt\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1);\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", tdate_a);\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", tdate_b);\n\n    handle.put(\"stats_fields\", UNORDERED);\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \n          \"stats.field\", \"stats_dt\", \n          \"stats.field\", i1, \n          \"stats.field\", tdate_a, \n          \"stats.field\", tdate_b);\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    // check a complex key name\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"*:*\", \"rows\",100);\n    }\n\n    //SOLR 3161 ensure shards.qt=/update fails (anything but search handler really)\n    // Also see TestRemoteStreaming#testQtUpdateFails()\n    try {\n      ignoreException(\"isShard is only acceptable\");\n      // query(\"q\",\"*:*\",\"shards.qt\",\"/update\",\"stream.body\",\"<delete><query>*:*</query></delete>\");\n      // fail();\n    } catch (SolrException e) {\n      //expected\n    }\n    unIgnoreException(\"isShard is only acceptable\");\n\n    // test debugging\n    // handle.put(\"explain\", UNORDERED);\n    handle.put(\"explain\", SKIPVAL);  // internal docids differ, idf differs w/o global idf\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    handle.put(\"track\", SKIP); //track is not included in single node search\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY);\n\n    // Check Info is added to for each shard\n    ModifiableSolrParams q = new ModifiableSolrParams();\n    q.set(\"q\", \"*:*\");\n    q.set(ShardParams.SHARDS_INFO, true);\n    setDistributedParams(q);\n    QueryResponse rsp = queryServer(q);\n    NamedList<?> sinfo = (NamedList<?>) rsp.getResponse().get(ShardParams.SHARDS_INFO);\n    String shards = getShardsString();\n    int cnt = StringUtils.countMatches(shards, \",\")+1;\n    \n    assertNotNull(\"missing shard info\", sinfo);\n    assertEquals(\"should have an entry for each shard [\"+sinfo+\"] \"+shards, cnt, sinfo.size());\n\n    // test shards.tolerant=true\n    for(int numDownServers = 0; numDownServers < jettys.size()-1; numDownServers++)\n    {\n      List<JettySolrRunner> upJettys = new ArrayList<>(jettys);\n      List<SolrServer> upClients = new ArrayList<>(clients);\n      List<JettySolrRunner> downJettys = new ArrayList<>();\n      List<String> upShards = new ArrayList<>(Arrays.asList(shardsArr));\n      for(int i=0; i<numDownServers; i++)\n      {\n        // shut down some of the jettys\n        int indexToRemove = r.nextInt(upJettys.size());\n        JettySolrRunner downJetty = upJettys.remove(indexToRemove);\n        upClients.remove(indexToRemove);\n        upShards.remove(indexToRemove);\n        ChaosMonkey.stop(downJetty);\n        downJettys.add(downJetty);\n      }\n\n      queryPartialResults(upShards, upClients, \n          \"q\",\"*:*\",\n          \"facet\",\"true\", \n          \"facet.field\",t1,\n          \"facet.limit\",5,\n          ShardParams.SHARDS_INFO,\"true\",\n          ShardParams.SHARDS_TOLERANT,\"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"facet\", \"true\",\n          \"facet.query\", i1 + \":[1 TO 50]\",\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      // test group query\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"rows\", 100,\n          \"fl\", \"id,\" + i1,\n          \"group\", \"true\",\n          \"group.query\", t1 + \":kings OR \" + t1 + \":eggs\",\n          \"group.limit\", 10,\n          \"sort\", i1 + \" asc, id asc\",\n          CommonParams.TIME_ALLOWED, 1,\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"stats\", \"true\",\n          \"stats.field\", i1,\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"toyata\",\n          \"spellcheck\", \"true\",\n          \"spellcheck.q\", \"toyata\",\n          \"qt\", \"spellCheckCompRH_Direct\",\n          \"shards.qt\", \"spellCheckCompRH_Direct\",\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      // restart the jettys\n      for (JettySolrRunner downJetty : downJettys) {\n        downJetty.start();\n      }\n    }\n\n    // This index has the same number for every field\n    \n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // Thread.sleep(10000000000L);\n\n    FieldCache.DEFAULT.purgeAllCaches();   // avoid FC insanity\n\n    del(\"*:*\"); // delete all docs and test stats request\n    commit();\n    try {\n      query(\"q\", \"*:*\", \"stats\", \"true\", \n            \"stats.field\", \"stats_dt\", \n            \"stats.field\", i1, \n            \"stats.field\", tdate_a, \n            \"stats.field\", tdate_b,\n            \"stats.calcdistinct\", \"true\");\n    } catch (Exception e) {\n      log.error(\"Exception on distrib stats request on empty index\", e);\n      fail(\"NullPointerException with stats request on empty index\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"56572ec06f1407c066d6b7399413178b33176cd8","date":1400495675,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/TestDistributedSearch#doTest().mjava","pathOld":"solr/core/src/test/org/apache/solr/TestDistributedSearch#doTest().mjava","sourceNew":"  @Override\n  public void doTest() throws Exception {\n    int backupStress = stress; // make a copy so we can restore\n\n\n    del(\"*:*\");\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\", \n           tdate_a, \"2010-04-20T11:00:00Z\",\n           tdate_b, \"2009-08-20T11:00:00Z\",\n           \"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\", \n           tdate_a, \"2010-05-02T11:00:00Z\",\n           tdate_b, \"2009-11-02T11:00:00Z\");\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\", \n           tdate_a, \"2010-05-03T11:00:00Z\");\n    indexr(id,4, i1, -100 ,tlong, 101,\n           t1,\"the quick fox jumped over the lazy dog\", \n           tdate_a, \"2010-05-03T11:00:00Z\",\n           tdate_b, \"2010-05-03T11:00:00Z\");\n    indexr(id,5, i1, 500, tlong, 500 ,\n           t1,\"the quick fox jumped way over the lazy dog\", \n           tdate_a, \"2010-05-05T11:00:00Z\");\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,\n           tdate_b, \"2010-01-05T11:00:00Z\",\n           t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n\n    commit();  // try to ensure there's more than one segment\n\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,\n           t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,\n           t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,\n           t1,\"no eggs on wall, lesson learned\", \n           oddField, \"odd man out\");\n\n    indexr(id, \"1001\", \"lowerfilt\", \"toyota\"); // for spellcheck\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n    \n    \n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n\n    handle.clear();\n    handle.put(\"QTime\", SKIPVAL);\n    handle.put(\"timestamp\", SKIPVAL);\n    handle.put(\"_version_\", SKIPVAL); // not a cloud test, but may use updateLog\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(\"q\",\"*:*\", \"sort\",f+\" desc\");\n      query(\"q\",\"*:*\", \"sort\",f+\" asc\");\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",\"{!func}testfunc(add(\"+i1+\",5))\"+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" asc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\");\n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"*,score\"); \n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 desc\");\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"{!func}\"+i1);// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(\"q\",\"{!func}\"+i1, \"fl\",\"*,score\");  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"quick\");\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\");\n    query(\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\");  // no fields in returned docs\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\");\n\n    handle.put(\"score\", SKIPVAL);\n    query(\"q\",\"quick\",\"fl\",\"*,score\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\");\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"matchesnothing\",\"fl\",\"*,score\");  \n\n    // test that a single NOW value is propagated to all shards... if that is true\n    // then the primary sort should always be a tie and then the secondary should always decide\n    query(\"q\",\"{!func}ms(NOW)\", \"sort\",\"score desc,\"+i1+\" desc\",\"fl\",\"id\");    \n\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\");\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2);\n\n    // a facet query to test out chars out of the ascii range\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!term f=foo_s}international\\u00ff\\u01ff\\u2222\\u3333\");\n\n    // simple date facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date.other\", \"all\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // date facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date\",tdate_b, \n          \"facet.date.other\", \"all\", \n          \"f.\"+tdate_b+\".facet.date.start\",\"2009-05-01T11:00:00Z\", \n          \"f.\"+tdate_b+\".facet.date.gap\",\"+3MONTHS\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // simple range facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"facet.range.end\",900);\n\n    // range facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range\",i1, \n          \"f.\"+i1+\".facet.range.start\",300, \n          \"f.\"+i1+\".facet.range.gap\",87, \n          \"facet.range.end\",900,\n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"f.\"+tlong+\".facet.range.end\",900);\n    \n    //  variations of fl\n    query(\"q\",\"*:*\", \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1 + \",score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", i1, \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id,\" + i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1, \"fl\", \"id\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",nint, \"fl\",tint,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",nint, \"fl\", \"id\", \"fl\",tint,\"sort\",i1 + \" desc\");\n\n    // basic spellcheck testing\n    query(\"q\", \"toyata\", \"fl\", \"id,lowerfilt\", \"spellcheck\", true, \"spellcheck.q\", \"toyata\", \"qt\", \"spellCheckCompRH_Direct\", \"shards.qt\", \"spellCheckCompRH_Direct\");\n\n    stress=0;  // turn off stress... we want to tex max combos in min time\n    for (int i=0; i<25*RANDOM_MULTIPLIER; i++) {\n      String f = fieldNames[random().nextInt(fieldNames.length)];\n      if (random().nextBoolean()) f = t1;  // the text field is a really interesting one to facet on (and it's multi-valued too)\n\n      // we want a random query and not just *:* so we'll get zero counts in facets also\n      // TODO: do a better random query\n      String q = random().nextBoolean() ? \"*:*\" : \"id:(1 3 5 7 9 11 13) OR id:[100 TO \" + random().nextInt(50) + \"]\";\n\n      int nolimit = random().nextBoolean() ? -1 : 10000;  // these should be equivalent\n\n      // if limit==-1, we should always get exact matches\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"count\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      // for index sort, we should get exact results for mincount <= 1\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(2), \"facet.offset\",random().nextInt(10), \"facet.limit\",random().nextInt(11)-1);\n    }\n    stress = backupStress;  // restore stress\n\n    // test faceting multiple things at once\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1);\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id:[1 TO 7]\", \"fq\",\"{!tag=b}id:[3 TO 9]\"\n    );\n    query(\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\");\n\n    // test field that is valid in schema but missing in all shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2);\n    // test field that is valid in schema and missing in some shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2);\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", \"stats_dt\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1);\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", tdate_a);\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", tdate_b);\n\n    handle.put(\"stats_fields\", UNORDERED);\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \n          \"stats.field\", \"stats_dt\", \n          \"stats.field\", i1, \n          \"stats.field\", tdate_a, \n          \"stats.field\", tdate_b);\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    // check a complex key name\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"*:*\", \"rows\",100);\n    }\n\n    //SOLR 3161 ensure shards.qt=/update fails (anything but search handler really)\n    // Also see TestRemoteStreaming#testQtUpdateFails()\n    try {\n      ignoreException(\"isShard is only acceptable\");\n      // query(\"q\",\"*:*\",\"shards.qt\",\"/update\",\"stream.body\",\"<delete><query>*:*</query></delete>\");\n      // fail();\n    } catch (SolrException e) {\n      //expected\n    }\n    unIgnoreException(\"isShard is only acceptable\");\n\n    // test debugging\n    // handle.put(\"explain\", UNORDERED);\n    handle.put(\"explain\", SKIPVAL);  // internal docids differ, idf differs w/o global idf\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    handle.put(\"track\", SKIP); //track is not included in single node search\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY);\n\n    // Check Info is added to for each shard\n    ModifiableSolrParams q = new ModifiableSolrParams();\n    q.set(\"q\", \"*:*\");\n    q.set(ShardParams.SHARDS_INFO, true);\n    setDistributedParams(q);\n    QueryResponse rsp = queryServer(q);\n    NamedList<?> sinfo = (NamedList<?>) rsp.getResponse().get(ShardParams.SHARDS_INFO);\n    String shards = getShardsString();\n    int cnt = StringUtils.countMatches(shards, \",\")+1;\n    \n    assertNotNull(\"missing shard info\", sinfo);\n    assertEquals(\"should have an entry for each shard [\"+sinfo+\"] \"+shards, cnt, sinfo.size());\n\n    // test shards.tolerant=true\n    for(int numDownServers = 0; numDownServers < jettys.size()-1; numDownServers++)\n    {\n      List<JettySolrRunner> upJettys = new ArrayList<>(jettys);\n      List<SolrServer> upClients = new ArrayList<>(clients);\n      List<JettySolrRunner> downJettys = new ArrayList<>();\n      List<String> upShards = new ArrayList<>(Arrays.asList(shardsArr));\n      for(int i=0; i<numDownServers; i++)\n      {\n        // shut down some of the jettys\n        int indexToRemove = r.nextInt(upJettys.size());\n        JettySolrRunner downJetty = upJettys.remove(indexToRemove);\n        upClients.remove(indexToRemove);\n        upShards.remove(indexToRemove);\n        ChaosMonkey.stop(downJetty);\n        downJettys.add(downJetty);\n      }\n\n      queryPartialResults(upShards, upClients, \n          \"q\",\"*:*\",\n          \"facet\",\"true\", \n          \"facet.field\",t1,\n          \"facet.limit\",5,\n          ShardParams.SHARDS_INFO,\"true\",\n          ShardParams.SHARDS_TOLERANT,\"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"facet\", \"true\",\n          \"facet.query\", i1 + \":[1 TO 50]\",\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      // test group query\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"rows\", 100,\n          \"fl\", \"id,\" + i1,\n          \"group\", \"true\",\n          \"group.query\", t1 + \":kings OR \" + t1 + \":eggs\",\n          \"group.limit\", 10,\n          \"sort\", i1 + \" asc, id asc\",\n          CommonParams.TIME_ALLOWED, 1,\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"stats\", \"true\",\n          \"stats.field\", i1,\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"toyata\",\n          \"spellcheck\", \"true\",\n          \"spellcheck.q\", \"toyata\",\n          \"qt\", \"spellCheckCompRH_Direct\",\n          \"shards.qt\", \"spellCheckCompRH_Direct\",\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      // restart the jettys\n      for (JettySolrRunner downJetty : downJettys) {\n        downJetty.start();\n      }\n    }\n\n    // This index has the same number for every field\n    \n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // Thread.sleep(10000000000L);\n\n    del(\"*:*\"); // delete all docs and test stats request\n    commit();\n    try {\n      query(\"q\", \"*:*\", \"stats\", \"true\", \n            \"stats.field\", \"stats_dt\", \n            \"stats.field\", i1, \n            \"stats.field\", tdate_a, \n            \"stats.field\", tdate_b,\n            \"stats.calcdistinct\", \"true\");\n    } catch (Exception e) {\n      log.error(\"Exception on distrib stats request on empty index\", e);\n      fail(\"NullPointerException with stats request on empty index\");\n    }\n  }\n\n","sourceOld":"  @Override\n  public void doTest() throws Exception {\n    int backupStress = stress; // make a copy so we can restore\n\n\n    del(\"*:*\");\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\", \n           tdate_a, \"2010-04-20T11:00:00Z\",\n           tdate_b, \"2009-08-20T11:00:00Z\",\n           \"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\", \n           tdate_a, \"2010-05-02T11:00:00Z\",\n           tdate_b, \"2009-11-02T11:00:00Z\");\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\", \n           tdate_a, \"2010-05-03T11:00:00Z\");\n    indexr(id,4, i1, -100 ,tlong, 101,\n           t1,\"the quick fox jumped over the lazy dog\", \n           tdate_a, \"2010-05-03T11:00:00Z\",\n           tdate_b, \"2010-05-03T11:00:00Z\");\n    indexr(id,5, i1, 500, tlong, 500 ,\n           t1,\"the quick fox jumped way over the lazy dog\", \n           tdate_a, \"2010-05-05T11:00:00Z\");\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,\n           tdate_b, \"2010-01-05T11:00:00Z\",\n           t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n\n    commit();  // try to ensure there's more than one segment\n\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,\n           t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,\n           t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,\n           t1,\"no eggs on wall, lesson learned\", \n           oddField, \"odd man out\");\n\n    indexr(id, \"1001\", \"lowerfilt\", \"toyota\"); // for spellcheck\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n    \n    \n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n\n    handle.clear();\n    handle.put(\"QTime\", SKIPVAL);\n    handle.put(\"timestamp\", SKIPVAL);\n    handle.put(\"_version_\", SKIPVAL); // not a cloud test, but may use updateLog\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(\"q\",\"*:*\", \"sort\",f+\" desc\");\n      query(\"q\",\"*:*\", \"sort\",f+\" asc\");\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",\"{!func}testfunc(add(\"+i1+\",5))\"+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" asc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\");\n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"*,score\"); \n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 desc\");\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"{!func}\"+i1);// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(\"q\",\"{!func}\"+i1, \"fl\",\"*,score\");  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"quick\");\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\");\n    query(\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\");  // no fields in returned docs\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\");\n\n    handle.put(\"score\", SKIPVAL);\n    query(\"q\",\"quick\",\"fl\",\"*,score\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\");\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"matchesnothing\",\"fl\",\"*,score\");  \n\n    // test that a single NOW value is propagated to all shards... if that is true\n    // then the primary sort should always be a tie and then the secondary should always decide\n    query(\"q\",\"{!func}ms(NOW)\", \"sort\",\"score desc,\"+i1+\" desc\",\"fl\",\"id\");    \n\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\");\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2);\n\n    // a facet query to test out chars out of the ascii range\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!term f=foo_s}international\\u00ff\\u01ff\\u2222\\u3333\");\n\n    // simple date facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date.other\", \"all\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // date facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date\",tdate_b, \n          \"facet.date.other\", \"all\", \n          \"f.\"+tdate_b+\".facet.date.start\",\"2009-05-01T11:00:00Z\", \n          \"f.\"+tdate_b+\".facet.date.gap\",\"+3MONTHS\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // simple range facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"facet.range.end\",900);\n\n    // range facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range\",i1, \n          \"f.\"+i1+\".facet.range.start\",300, \n          \"f.\"+i1+\".facet.range.gap\",87, \n          \"facet.range.end\",900,\n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"f.\"+tlong+\".facet.range.end\",900);\n    \n    //  variations of fl\n    query(\"q\",\"*:*\", \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1 + \",score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", i1, \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id,\" + i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1, \"fl\", \"id\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",nint, \"fl\",tint,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",nint, \"fl\", \"id\", \"fl\",tint,\"sort\",i1 + \" desc\");\n\n    // basic spellcheck testing\n    query(\"q\", \"toyata\", \"fl\", \"id,lowerfilt\", \"spellcheck\", true, \"spellcheck.q\", \"toyata\", \"qt\", \"spellCheckCompRH_Direct\", \"shards.qt\", \"spellCheckCompRH_Direct\");\n\n    stress=0;  // turn off stress... we want to tex max combos in min time\n    for (int i=0; i<25*RANDOM_MULTIPLIER; i++) {\n      String f = fieldNames[random().nextInt(fieldNames.length)];\n      if (random().nextBoolean()) f = t1;  // the text field is a really interesting one to facet on (and it's multi-valued too)\n\n      // we want a random query and not just *:* so we'll get zero counts in facets also\n      // TODO: do a better random query\n      String q = random().nextBoolean() ? \"*:*\" : \"id:(1 3 5 7 9 11 13) OR id:[100 TO \" + random().nextInt(50) + \"]\";\n\n      int nolimit = random().nextBoolean() ? -1 : 10000;  // these should be equivalent\n\n      // if limit==-1, we should always get exact matches\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"count\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      // for index sort, we should get exact results for mincount <= 1\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(2), \"facet.offset\",random().nextInt(10), \"facet.limit\",random().nextInt(11)-1);\n    }\n    stress = backupStress;  // restore stress\n\n    // test faceting multiple things at once\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1);\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id:[1 TO 7]\", \"fq\",\"{!tag=b}id:[3 TO 9]\"\n    );\n    query(\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\");\n\n    // test field that is valid in schema but missing in all shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2);\n    // test field that is valid in schema and missing in some shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2);\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", \"stats_dt\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1);\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", tdate_a);\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", tdate_b);\n\n    handle.put(\"stats_fields\", UNORDERED);\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \n          \"stats.field\", \"stats_dt\", \n          \"stats.field\", i1, \n          \"stats.field\", tdate_a, \n          \"stats.field\", tdate_b);\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    // check a complex key name\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"*:*\", \"rows\",100);\n    }\n\n    //SOLR 3161 ensure shards.qt=/update fails (anything but search handler really)\n    // Also see TestRemoteStreaming#testQtUpdateFails()\n    try {\n      ignoreException(\"isShard is only acceptable\");\n      // query(\"q\",\"*:*\",\"shards.qt\",\"/update\",\"stream.body\",\"<delete><query>*:*</query></delete>\");\n      // fail();\n    } catch (SolrException e) {\n      //expected\n    }\n    unIgnoreException(\"isShard is only acceptable\");\n\n    // test debugging\n    // handle.put(\"explain\", UNORDERED);\n    handle.put(\"explain\", SKIPVAL);  // internal docids differ, idf differs w/o global idf\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    handle.put(\"track\", SKIP); //track is not included in single node search\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY);\n\n    // Check Info is added to for each shard\n    ModifiableSolrParams q = new ModifiableSolrParams();\n    q.set(\"q\", \"*:*\");\n    q.set(ShardParams.SHARDS_INFO, true);\n    setDistributedParams(q);\n    QueryResponse rsp = queryServer(q);\n    NamedList<?> sinfo = (NamedList<?>) rsp.getResponse().get(ShardParams.SHARDS_INFO);\n    String shards = getShardsString();\n    int cnt = StringUtils.countMatches(shards, \",\")+1;\n    \n    assertNotNull(\"missing shard info\", sinfo);\n    assertEquals(\"should have an entry for each shard [\"+sinfo+\"] \"+shards, cnt, sinfo.size());\n\n    // test shards.tolerant=true\n    for(int numDownServers = 0; numDownServers < jettys.size()-1; numDownServers++)\n    {\n      List<JettySolrRunner> upJettys = new ArrayList<>(jettys);\n      List<SolrServer> upClients = new ArrayList<>(clients);\n      List<JettySolrRunner> downJettys = new ArrayList<>();\n      List<String> upShards = new ArrayList<>(Arrays.asList(shardsArr));\n      for(int i=0; i<numDownServers; i++)\n      {\n        // shut down some of the jettys\n        int indexToRemove = r.nextInt(upJettys.size());\n        JettySolrRunner downJetty = upJettys.remove(indexToRemove);\n        upClients.remove(indexToRemove);\n        upShards.remove(indexToRemove);\n        ChaosMonkey.stop(downJetty);\n        downJettys.add(downJetty);\n      }\n\n      queryPartialResults(upShards, upClients, \n          \"q\",\"*:*\",\n          \"facet\",\"true\", \n          \"facet.field\",t1,\n          \"facet.limit\",5,\n          ShardParams.SHARDS_INFO,\"true\",\n          ShardParams.SHARDS_TOLERANT,\"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"facet\", \"true\",\n          \"facet.query\", i1 + \":[1 TO 50]\",\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      // test group query\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"rows\", 100,\n          \"fl\", \"id,\" + i1,\n          \"group\", \"true\",\n          \"group.query\", t1 + \":kings OR \" + t1 + \":eggs\",\n          \"group.limit\", 10,\n          \"sort\", i1 + \" asc, id asc\",\n          CommonParams.TIME_ALLOWED, 1,\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"stats\", \"true\",\n          \"stats.field\", i1,\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"toyata\",\n          \"spellcheck\", \"true\",\n          \"spellcheck.q\", \"toyata\",\n          \"qt\", \"spellCheckCompRH_Direct\",\n          \"shards.qt\", \"spellCheckCompRH_Direct\",\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      // restart the jettys\n      for (JettySolrRunner downJetty : downJettys) {\n        downJetty.start();\n      }\n    }\n\n    // This index has the same number for every field\n    \n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // Thread.sleep(10000000000L);\n\n    FieldCache.DEFAULT.purgeAllCaches();   // avoid FC insanity\n\n    del(\"*:*\"); // delete all docs and test stats request\n    commit();\n    try {\n      query(\"q\", \"*:*\", \"stats\", \"true\", \n            \"stats.field\", \"stats_dt\", \n            \"stats.field\", i1, \n            \"stats.field\", tdate_a, \n            \"stats.field\", tdate_b,\n            \"stats.calcdistinct\", \"true\");\n    } catch (Exception e) {\n      log.error(\"Exception on distrib stats request on empty index\", e);\n      fail(\"NullPointerException with stats request on empty index\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"92bd590cd3fa131aa5a9c7f56693a7ec9cb6d279","date":1403106436,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/TestDistributedSearch#doTest().mjava","pathOld":"solr/core/src/test/org/apache/solr/TestDistributedSearch#doTest().mjava","sourceNew":"  @Override\n  public void doTest() throws Exception {\n    int backupStress = stress; // make a copy so we can restore\n\n\n    del(\"*:*\");\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\", \n           tdate_a, \"2010-04-20T11:00:00Z\",\n           tdate_b, \"2009-08-20T11:00:00Z\",\n           \"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\", \n           tdate_a, \"2010-05-02T11:00:00Z\",\n           tdate_b, \"2009-11-02T11:00:00Z\");\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\", \n           tdate_a, \"2010-05-03T11:00:00Z\");\n    indexr(id,4, i1, -100 ,tlong, 101,\n           t1,\"the quick fox jumped over the lazy dog\", \n           tdate_a, \"2010-05-03T11:00:00Z\",\n           tdate_b, \"2010-05-03T11:00:00Z\");\n    indexr(id,5, i1, 500, tlong, 500 ,\n           t1,\"the quick fox jumped way over the lazy dog\", \n           tdate_a, \"2010-05-05T11:00:00Z\");\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,\n           tdate_b, \"2010-01-05T11:00:00Z\",\n           t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n\n    commit();  // try to ensure there's more than one segment\n\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,\n           t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,\n           t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,\n           t1,\"no eggs on wall, lesson learned\", \n           oddField, \"odd man out\");\n\n    indexr(id, \"1001\", \"lowerfilt\", \"toyota\"); // for spellcheck\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n    \n    \n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n\n    handle.clear();\n    handle.put(\"QTime\", SKIPVAL);\n    handle.put(\"timestamp\", SKIPVAL);\n    handle.put(\"_version_\", SKIPVAL); // not a cloud test, but may use updateLog\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(\"q\",\"*:*\", \"sort\",f+\" desc\");\n      query(\"q\",\"*:*\", \"sort\",f+\" asc\");\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",\"{!func}testfunc(add(\"+i1+\",5))\"+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" asc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\");\n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"*,score\"); \n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 desc\");\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"{!func}\"+i1);// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(\"q\",\"{!func}\"+i1, \"fl\",\"*,score\");  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"quick\");\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\");\n    query(\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\");  // no fields in returned docs\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\");\n\n    handle.put(\"score\", SKIPVAL);\n    query(\"q\",\"quick\",\"fl\",\"*,score\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\");\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"matchesnothing\",\"fl\",\"*,score\");  \n\n    // test that a single NOW value is propagated to all shards... if that is true\n    // then the primary sort should always be a tie and then the secondary should always decide\n    query(\"q\",\"{!func}ms(NOW)\", \"sort\",\"score desc,\"+i1+\" desc\",\"fl\",\"id\");    \n\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\");\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2);\n\n    // a facet query to test out chars out of the ascii range\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!term f=foo_s}international\\u00ff\\u01ff\\u2222\\u3333\");\n\n    // simple date facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date.other\", \"all\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // date facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date\",tdate_b, \n          \"facet.date.other\", \"all\", \n          \"f.\"+tdate_b+\".facet.date.start\",\"2009-05-01T11:00:00Z\", \n          \"f.\"+tdate_b+\".facet.date.gap\",\"+3MONTHS\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // simple range facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"facet.range.end\",900);\n\n    // range facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range\",i1, \n          \"f.\"+i1+\".facet.range.start\",300, \n          \"f.\"+i1+\".facet.range.gap\",87, \n          \"facet.range.end\",900,\n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"f.\"+tlong+\".facet.range.end\",900);\n    \n    //  variations of fl\n    query(\"q\",\"*:*\", \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1 + \",score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", i1, \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id,\" + i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1, \"fl\", \"id\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",nint, \"fl\",tint,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",nint, \"fl\", \"id\", \"fl\",tint,\"sort\",i1 + \" desc\");\n\n    // basic spellcheck testing\n    query(\"q\", \"toyata\", \"fl\", \"id,lowerfilt\", \"spellcheck\", true, \"spellcheck.q\", \"toyata\", \"qt\", \"spellCheckCompRH_Direct\", \"shards.qt\", \"spellCheckCompRH_Direct\");\n\n    stress=0;  // turn off stress... we want to tex max combos in min time\n    for (int i=0; i<25*RANDOM_MULTIPLIER; i++) {\n      String f = fieldNames[random().nextInt(fieldNames.length)];\n      if (random().nextBoolean()) f = t1;  // the text field is a really interesting one to facet on (and it's multi-valued too)\n\n      // we want a random query and not just *:* so we'll get zero counts in facets also\n      // TODO: do a better random query\n      String q = random().nextBoolean() ? \"*:*\" : \"id:(1 3 5 7 9 11 13) OR id:[100 TO \" + random().nextInt(50) + \"]\";\n\n      int nolimit = random().nextBoolean() ? -1 : 10000;  // these should be equivalent\n\n      // if limit==-1, we should always get exact matches\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"count\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      // for index sort, we should get exact results for mincount <= 1\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(2), \"facet.offset\",random().nextInt(10), \"facet.limit\",random().nextInt(11)-1);\n    }\n    stress = backupStress;  // restore stress\n\n    // test faceting multiple things at once\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1);\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id:[1 TO 7]\", \"fq\",\"{!tag=b}id:[3 TO 9]\"\n    );\n    query(\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\");\n\n    // test field that is valid in schema but missing in all shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2);\n    // test field that is valid in schema and missing in some shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2);\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", \"stats_dt\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1);\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", tdate_a);\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", tdate_b);\n\n    handle.put(\"stats_fields\", UNORDERED);\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\",\n          \"stats.field\", \"stats_dt\",\n          \"stats.field\", i1,\n          \"stats.field\", tdate_a,\n          \"stats.field\", tdate_b);\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    // check a complex key name\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"*:*\", \"rows\",100);\n    }\n\n    //SOLR 3161 ensure shards.qt=/update fails (anything but search handler really)\n    // Also see TestRemoteStreaming#testQtUpdateFails()\n    try {\n      ignoreException(\"isShard is only acceptable\");\n      // query(\"q\",\"*:*\",\"shards.qt\",\"/update\",\"stream.body\",\"<delete><query>*:*</query></delete>\");\n      // fail();\n    } catch (SolrException e) {\n      //expected\n    }\n    unIgnoreException(\"isShard is only acceptable\");\n\n    // test debugging\n    // handle.put(\"explain\", UNORDERED);\n    handle.put(\"explain\", SKIPVAL);  // internal docids differ, idf differs w/o global idf\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    handle.put(\"track\", SKIP); //track is not included in single node search\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY);\n\n    // Check Info is added to for each shard\n    ModifiableSolrParams q = new ModifiableSolrParams();\n    q.set(\"q\", \"*:*\");\n    q.set(ShardParams.SHARDS_INFO, true);\n    setDistributedParams(q);\n    QueryResponse rsp = queryServer(q);\n    NamedList<?> sinfo = (NamedList<?>) rsp.getResponse().get(ShardParams.SHARDS_INFO);\n    String shards = getShardsString();\n    int cnt = StringUtils.countMatches(shards, \",\")+1;\n    \n    assertNotNull(\"missing shard info\", sinfo);\n    assertEquals(\"should have an entry for each shard [\"+sinfo+\"] \"+shards, cnt, sinfo.size());\n\n    // test shards.tolerant=true\n    for(int numDownServers = 0; numDownServers < jettys.size()-1; numDownServers++)\n    {\n      List<JettySolrRunner> upJettys = new ArrayList<>(jettys);\n      List<SolrServer> upClients = new ArrayList<>(clients);\n      List<JettySolrRunner> downJettys = new ArrayList<>();\n      List<String> upShards = new ArrayList<>(Arrays.asList(shardsArr));\n      for(int i=0; i<numDownServers; i++)\n      {\n        // shut down some of the jettys\n        int indexToRemove = r.nextInt(upJettys.size());\n        JettySolrRunner downJetty = upJettys.remove(indexToRemove);\n        upClients.remove(indexToRemove);\n        upShards.remove(indexToRemove);\n        ChaosMonkey.stop(downJetty);\n        downJettys.add(downJetty);\n      }\n\n      queryPartialResults(upShards, upClients, \n          \"q\",\"*:*\",\n          \"facet\",\"true\", \n          \"facet.field\",t1,\n          \"facet.limit\",5,\n          ShardParams.SHARDS_INFO,\"true\",\n          ShardParams.SHARDS_TOLERANT,\"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"facet\", \"true\",\n          \"facet.query\", i1 + \":[1 TO 50]\",\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      // test group query\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"rows\", 100,\n          \"fl\", \"id,\" + i1,\n          \"group\", \"true\",\n          \"group.query\", t1 + \":kings OR \" + t1 + \":eggs\",\n          \"group.limit\", 10,\n          \"sort\", i1 + \" asc, id asc\",\n          CommonParams.TIME_ALLOWED, 1,\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"stats\", \"true\",\n          \"stats.field\", i1,\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"toyata\",\n          \"spellcheck\", \"true\",\n          \"spellcheck.q\", \"toyata\",\n          \"qt\", \"spellCheckCompRH_Direct\",\n          \"shards.qt\", \"spellCheckCompRH_Direct\",\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      // restart the jettys\n      for (JettySolrRunner downJetty : downJettys) {\n        downJetty.start();\n      }\n    }\n\n    // This index has the same number for every field\n    \n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // Thread.sleep(10000000000L);\n\n    del(\"*:*\"); // delete all docs and test stats request\n    commit();\n    try {\n      query(\"q\", \"*:*\", \"stats\", \"true\", \n            \"stats.field\", \"stats_dt\", \n            \"stats.field\", i1, \n            \"stats.field\", tdate_a, \n            \"stats.field\", tdate_b,\n            \"stats.calcdistinct\", \"true\");\n    } catch (HttpSolrServer.RemoteSolrException e) {\n      if (e.getMessage().startsWith(\"java.lang.NullPointerException\"))  {\n        fail(\"NullPointerException with stats request on empty index\");\n      } else  {\n        throw e;\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  public void doTest() throws Exception {\n    int backupStress = stress; // make a copy so we can restore\n\n\n    del(\"*:*\");\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\", \n           tdate_a, \"2010-04-20T11:00:00Z\",\n           tdate_b, \"2009-08-20T11:00:00Z\",\n           \"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\", \n           tdate_a, \"2010-05-02T11:00:00Z\",\n           tdate_b, \"2009-11-02T11:00:00Z\");\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\", \n           tdate_a, \"2010-05-03T11:00:00Z\");\n    indexr(id,4, i1, -100 ,tlong, 101,\n           t1,\"the quick fox jumped over the lazy dog\", \n           tdate_a, \"2010-05-03T11:00:00Z\",\n           tdate_b, \"2010-05-03T11:00:00Z\");\n    indexr(id,5, i1, 500, tlong, 500 ,\n           t1,\"the quick fox jumped way over the lazy dog\", \n           tdate_a, \"2010-05-05T11:00:00Z\");\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,\n           tdate_b, \"2010-01-05T11:00:00Z\",\n           t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n\n    commit();  // try to ensure there's more than one segment\n\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,\n           t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,\n           t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,\n           t1,\"no eggs on wall, lesson learned\", \n           oddField, \"odd man out\");\n\n    indexr(id, \"1001\", \"lowerfilt\", \"toyota\"); // for spellcheck\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n    \n    \n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n\n    handle.clear();\n    handle.put(\"QTime\", SKIPVAL);\n    handle.put(\"timestamp\", SKIPVAL);\n    handle.put(\"_version_\", SKIPVAL); // not a cloud test, but may use updateLog\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(\"q\",\"*:*\", \"sort\",f+\" desc\");\n      query(\"q\",\"*:*\", \"sort\",f+\" asc\");\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",\"{!func}testfunc(add(\"+i1+\",5))\"+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" asc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\");\n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"*,score\"); \n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 desc\");\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"{!func}\"+i1);// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(\"q\",\"{!func}\"+i1, \"fl\",\"*,score\");  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"quick\");\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\");\n    query(\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\");  // no fields in returned docs\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\");\n\n    handle.put(\"score\", SKIPVAL);\n    query(\"q\",\"quick\",\"fl\",\"*,score\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\");\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"matchesnothing\",\"fl\",\"*,score\");  \n\n    // test that a single NOW value is propagated to all shards... if that is true\n    // then the primary sort should always be a tie and then the secondary should always decide\n    query(\"q\",\"{!func}ms(NOW)\", \"sort\",\"score desc,\"+i1+\" desc\",\"fl\",\"id\");    \n\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\");\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2);\n\n    // a facet query to test out chars out of the ascii range\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!term f=foo_s}international\\u00ff\\u01ff\\u2222\\u3333\");\n\n    // simple date facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date.other\", \"all\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // date facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date\",tdate_b, \n          \"facet.date.other\", \"all\", \n          \"f.\"+tdate_b+\".facet.date.start\",\"2009-05-01T11:00:00Z\", \n          \"f.\"+tdate_b+\".facet.date.gap\",\"+3MONTHS\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // simple range facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"facet.range.end\",900);\n\n    // range facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range\",i1, \n          \"f.\"+i1+\".facet.range.start\",300, \n          \"f.\"+i1+\".facet.range.gap\",87, \n          \"facet.range.end\",900,\n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"f.\"+tlong+\".facet.range.end\",900);\n    \n    //  variations of fl\n    query(\"q\",\"*:*\", \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1 + \",score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", i1, \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id,\" + i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1, \"fl\", \"id\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",nint, \"fl\",tint,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",nint, \"fl\", \"id\", \"fl\",tint,\"sort\",i1 + \" desc\");\n\n    // basic spellcheck testing\n    query(\"q\", \"toyata\", \"fl\", \"id,lowerfilt\", \"spellcheck\", true, \"spellcheck.q\", \"toyata\", \"qt\", \"spellCheckCompRH_Direct\", \"shards.qt\", \"spellCheckCompRH_Direct\");\n\n    stress=0;  // turn off stress... we want to tex max combos in min time\n    for (int i=0; i<25*RANDOM_MULTIPLIER; i++) {\n      String f = fieldNames[random().nextInt(fieldNames.length)];\n      if (random().nextBoolean()) f = t1;  // the text field is a really interesting one to facet on (and it's multi-valued too)\n\n      // we want a random query and not just *:* so we'll get zero counts in facets also\n      // TODO: do a better random query\n      String q = random().nextBoolean() ? \"*:*\" : \"id:(1 3 5 7 9 11 13) OR id:[100 TO \" + random().nextInt(50) + \"]\";\n\n      int nolimit = random().nextBoolean() ? -1 : 10000;  // these should be equivalent\n\n      // if limit==-1, we should always get exact matches\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"count\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      // for index sort, we should get exact results for mincount <= 1\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(2), \"facet.offset\",random().nextInt(10), \"facet.limit\",random().nextInt(11)-1);\n    }\n    stress = backupStress;  // restore stress\n\n    // test faceting multiple things at once\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1);\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id:[1 TO 7]\", \"fq\",\"{!tag=b}id:[3 TO 9]\"\n    );\n    query(\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\");\n\n    // test field that is valid in schema but missing in all shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2);\n    // test field that is valid in schema and missing in some shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2);\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", \"stats_dt\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1);\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", tdate_a);\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", tdate_b);\n\n    handle.put(\"stats_fields\", UNORDERED);\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \n          \"stats.field\", \"stats_dt\", \n          \"stats.field\", i1, \n          \"stats.field\", tdate_a, \n          \"stats.field\", tdate_b);\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    // check a complex key name\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"*:*\", \"rows\",100);\n    }\n\n    //SOLR 3161 ensure shards.qt=/update fails (anything but search handler really)\n    // Also see TestRemoteStreaming#testQtUpdateFails()\n    try {\n      ignoreException(\"isShard is only acceptable\");\n      // query(\"q\",\"*:*\",\"shards.qt\",\"/update\",\"stream.body\",\"<delete><query>*:*</query></delete>\");\n      // fail();\n    } catch (SolrException e) {\n      //expected\n    }\n    unIgnoreException(\"isShard is only acceptable\");\n\n    // test debugging\n    // handle.put(\"explain\", UNORDERED);\n    handle.put(\"explain\", SKIPVAL);  // internal docids differ, idf differs w/o global idf\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    handle.put(\"track\", SKIP); //track is not included in single node search\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY);\n\n    // Check Info is added to for each shard\n    ModifiableSolrParams q = new ModifiableSolrParams();\n    q.set(\"q\", \"*:*\");\n    q.set(ShardParams.SHARDS_INFO, true);\n    setDistributedParams(q);\n    QueryResponse rsp = queryServer(q);\n    NamedList<?> sinfo = (NamedList<?>) rsp.getResponse().get(ShardParams.SHARDS_INFO);\n    String shards = getShardsString();\n    int cnt = StringUtils.countMatches(shards, \",\")+1;\n    \n    assertNotNull(\"missing shard info\", sinfo);\n    assertEquals(\"should have an entry for each shard [\"+sinfo+\"] \"+shards, cnt, sinfo.size());\n\n    // test shards.tolerant=true\n    for(int numDownServers = 0; numDownServers < jettys.size()-1; numDownServers++)\n    {\n      List<JettySolrRunner> upJettys = new ArrayList<>(jettys);\n      List<SolrServer> upClients = new ArrayList<>(clients);\n      List<JettySolrRunner> downJettys = new ArrayList<>();\n      List<String> upShards = new ArrayList<>(Arrays.asList(shardsArr));\n      for(int i=0; i<numDownServers; i++)\n      {\n        // shut down some of the jettys\n        int indexToRemove = r.nextInt(upJettys.size());\n        JettySolrRunner downJetty = upJettys.remove(indexToRemove);\n        upClients.remove(indexToRemove);\n        upShards.remove(indexToRemove);\n        ChaosMonkey.stop(downJetty);\n        downJettys.add(downJetty);\n      }\n\n      queryPartialResults(upShards, upClients, \n          \"q\",\"*:*\",\n          \"facet\",\"true\", \n          \"facet.field\",t1,\n          \"facet.limit\",5,\n          ShardParams.SHARDS_INFO,\"true\",\n          ShardParams.SHARDS_TOLERANT,\"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"facet\", \"true\",\n          \"facet.query\", i1 + \":[1 TO 50]\",\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      // test group query\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"rows\", 100,\n          \"fl\", \"id,\" + i1,\n          \"group\", \"true\",\n          \"group.query\", t1 + \":kings OR \" + t1 + \":eggs\",\n          \"group.limit\", 10,\n          \"sort\", i1 + \" asc, id asc\",\n          CommonParams.TIME_ALLOWED, 1,\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"stats\", \"true\",\n          \"stats.field\", i1,\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"toyata\",\n          \"spellcheck\", \"true\",\n          \"spellcheck.q\", \"toyata\",\n          \"qt\", \"spellCheckCompRH_Direct\",\n          \"shards.qt\", \"spellCheckCompRH_Direct\",\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      // restart the jettys\n      for (JettySolrRunner downJetty : downJettys) {\n        downJetty.start();\n      }\n    }\n\n    // This index has the same number for every field\n    \n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // Thread.sleep(10000000000L);\n\n    del(\"*:*\"); // delete all docs and test stats request\n    commit();\n    try {\n      query(\"q\", \"*:*\", \"stats\", \"true\", \n            \"stats.field\", \"stats_dt\", \n            \"stats.field\", i1, \n            \"stats.field\", tdate_a, \n            \"stats.field\", tdate_b,\n            \"stats.calcdistinct\", \"true\");\n    } catch (Exception e) {\n      log.error(\"Exception on distrib stats request on empty index\", e);\n      fail(\"NullPointerException with stats request on empty index\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"072f211dfa8387028bb978d128c35bf9a450bbbf","date":1406041363,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/TestDistributedSearch#doTest().mjava","pathOld":"solr/core/src/test/org/apache/solr/TestDistributedSearch#doTest().mjava","sourceNew":"  @Override\n  public void doTest() throws Exception {\n    int backupStress = stress; // make a copy so we can restore\n\n\n    del(\"*:*\");\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\", \n           tdate_a, \"2010-04-20T11:00:00Z\",\n           tdate_b, \"2009-08-20T11:00:00Z\",\n           \"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\", \n           tdate_a, \"2010-05-02T11:00:00Z\",\n           tdate_b, \"2009-11-02T11:00:00Z\");\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\", \n           tdate_a, \"2010-05-03T11:00:00Z\");\n    indexr(id,4, i1, -100 ,tlong, 101,\n           t1,\"the quick fox jumped over the lazy dog\", \n           tdate_a, \"2010-05-03T11:00:00Z\",\n           tdate_b, \"2010-05-03T11:00:00Z\");\n    indexr(id,5, i1, 500, tlong, 500 ,\n           t1,\"the quick fox jumped way over the lazy dog\", \n           tdate_a, \"2010-05-05T11:00:00Z\");\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,\n           tdate_b, \"2010-01-05T11:00:00Z\",\n           t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n\n    commit();  // try to ensure there's more than one segment\n\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,\n           t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,\n           t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,\n           t1,\"no eggs on wall, lesson learned\", \n           oddField, \"odd man out\");\n\n    indexr(id, \"1001\", \"lowerfilt\", \"toyota\"); // for spellcheck\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n    \n    \n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n\n    handle.clear();\n    handle.put(\"timestamp\", SKIPVAL);\n    handle.put(\"_version_\", SKIPVAL); // not a cloud test, but may use updateLog\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(\"q\",\"*:*\", \"sort\",f+\" desc\");\n      query(\"q\",\"*:*\", \"sort\",f+\" asc\");\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",\"{!func}testfunc(add(\"+i1+\",5))\"+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" asc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\");\n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"*,score\"); \n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 desc\");\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"{!func}\"+i1);// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(\"q\",\"{!func}\"+i1, \"fl\",\"*,score\");  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"quick\");\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\");\n    query(\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\");  // no fields in returned docs\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\");\n\n    handle.put(\"score\", SKIPVAL);\n    query(\"q\",\"quick\",\"fl\",\"*,score\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\");\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"matchesnothing\",\"fl\",\"*,score\");  \n\n    // test that a single NOW value is propagated to all shards... if that is true\n    // then the primary sort should always be a tie and then the secondary should always decide\n    query(\"q\",\"{!func}ms(NOW)\", \"sort\",\"score desc,\"+i1+\" desc\",\"fl\",\"id\");    \n\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\");\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2);\n\n    // a facet query to test out chars out of the ascii range\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!term f=foo_s}international\\u00ff\\u01ff\\u2222\\u3333\");\n\n    // simple date facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date.other\", \"all\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // date facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date\",tdate_b, \n          \"facet.date.other\", \"all\", \n          \"f.\"+tdate_b+\".facet.date.start\",\"2009-05-01T11:00:00Z\", \n          \"f.\"+tdate_b+\".facet.date.gap\",\"+3MONTHS\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // simple range facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"facet.range.end\",900);\n\n    // range facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range\",i1, \n          \"f.\"+i1+\".facet.range.start\",300, \n          \"f.\"+i1+\".facet.range.gap\",87, \n          \"facet.range.end\",900,\n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"f.\"+tlong+\".facet.range.end\",900);\n    \n    //  variations of fl\n    query(\"q\",\"*:*\", \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1 + \",score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", i1, \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id,\" + i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1, \"fl\", \"id\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",nint, \"fl\",tint,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",nint, \"fl\", \"id\", \"fl\",tint,\"sort\",i1 + \" desc\");\n\n    // basic spellcheck testing\n    query(\"q\", \"toyata\", \"fl\", \"id,lowerfilt\", \"spellcheck\", true, \"spellcheck.q\", \"toyata\", \"qt\", \"spellCheckCompRH_Direct\", \"shards.qt\", \"spellCheckCompRH_Direct\");\n\n    stress=0;  // turn off stress... we want to tex max combos in min time\n    for (int i=0; i<25*RANDOM_MULTIPLIER; i++) {\n      String f = fieldNames[random().nextInt(fieldNames.length)];\n      if (random().nextBoolean()) f = t1;  // the text field is a really interesting one to facet on (and it's multi-valued too)\n\n      // we want a random query and not just *:* so we'll get zero counts in facets also\n      // TODO: do a better random query\n      String q = random().nextBoolean() ? \"*:*\" : \"id:(1 3 5 7 9 11 13) OR id:[100 TO \" + random().nextInt(50) + \"]\";\n\n      int nolimit = random().nextBoolean() ? -1 : 10000;  // these should be equivalent\n\n      // if limit==-1, we should always get exact matches\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"count\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      // for index sort, we should get exact results for mincount <= 1\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(2), \"facet.offset\",random().nextInt(10), \"facet.limit\",random().nextInt(11)-1);\n    }\n    stress = backupStress;  // restore stress\n\n    // test faceting multiple things at once\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1);\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id:[1 TO 7]\", \"fq\",\"{!tag=b}id:[3 TO 9]\"\n    );\n    query(\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\");\n\n    // test field that is valid in schema but missing in all shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2);\n    // test field that is valid in schema and missing in some shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2);\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", \"stats_dt\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1);\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", tdate_a);\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", tdate_b);\n\n    handle.put(\"stats_fields\", UNORDERED);\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\",\n          \"stats.field\", \"stats_dt\",\n          \"stats.field\", i1,\n          \"stats.field\", tdate_a,\n          \"stats.field\", tdate_b);\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    // check a complex key name\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"*:*\", \"rows\",100);\n    }\n\n    //SOLR 3161 ensure shards.qt=/update fails (anything but search handler really)\n    // Also see TestRemoteStreaming#testQtUpdateFails()\n    try {\n      ignoreException(\"isShard is only acceptable\");\n      // query(\"q\",\"*:*\",\"shards.qt\",\"/update\",\"stream.body\",\"<delete><query>*:*</query></delete>\");\n      // fail();\n    } catch (SolrException e) {\n      //expected\n    }\n    unIgnoreException(\"isShard is only acceptable\");\n\n    // test debugging\n    // handle.put(\"explain\", UNORDERED);\n    handle.put(\"explain\", SKIPVAL);  // internal docids differ, idf differs w/o global idf\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    handle.put(\"track\", SKIP); //track is not included in single node search\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY);\n\n    // Check Info is added to for each shard\n    ModifiableSolrParams q = new ModifiableSolrParams();\n    q.set(\"q\", \"*:*\");\n    q.set(ShardParams.SHARDS_INFO, true);\n    setDistributedParams(q);\n    QueryResponse rsp = queryServer(q);\n    NamedList<?> sinfo = (NamedList<?>) rsp.getResponse().get(ShardParams.SHARDS_INFO);\n    String shards = getShardsString();\n    int cnt = StringUtils.countMatches(shards, \",\")+1;\n    \n    assertNotNull(\"missing shard info\", sinfo);\n    assertEquals(\"should have an entry for each shard [\"+sinfo+\"] \"+shards, cnt, sinfo.size());\n\n    // test shards.tolerant=true\n    for(int numDownServers = 0; numDownServers < jettys.size()-1; numDownServers++)\n    {\n      List<JettySolrRunner> upJettys = new ArrayList<>(jettys);\n      List<SolrServer> upClients = new ArrayList<>(clients);\n      List<JettySolrRunner> downJettys = new ArrayList<>();\n      List<String> upShards = new ArrayList<>(Arrays.asList(shardsArr));\n      for(int i=0; i<numDownServers; i++)\n      {\n        // shut down some of the jettys\n        int indexToRemove = r.nextInt(upJettys.size());\n        JettySolrRunner downJetty = upJettys.remove(indexToRemove);\n        upClients.remove(indexToRemove);\n        upShards.remove(indexToRemove);\n        ChaosMonkey.stop(downJetty);\n        downJettys.add(downJetty);\n      }\n\n      queryPartialResults(upShards, upClients, \n          \"q\",\"*:*\",\n          \"facet\",\"true\", \n          \"facet.field\",t1,\n          \"facet.limit\",5,\n          ShardParams.SHARDS_INFO,\"true\",\n          ShardParams.SHARDS_TOLERANT,\"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"facet\", \"true\",\n          \"facet.query\", i1 + \":[1 TO 50]\",\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      // test group query\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"rows\", 100,\n          \"fl\", \"id,\" + i1,\n          \"group\", \"true\",\n          \"group.query\", t1 + \":kings OR \" + t1 + \":eggs\",\n          \"group.limit\", 10,\n          \"sort\", i1 + \" asc, id asc\",\n          CommonParams.TIME_ALLOWED, 1,\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"stats\", \"true\",\n          \"stats.field\", i1,\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"toyata\",\n          \"spellcheck\", \"true\",\n          \"spellcheck.q\", \"toyata\",\n          \"qt\", \"spellCheckCompRH_Direct\",\n          \"shards.qt\", \"spellCheckCompRH_Direct\",\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      // restart the jettys\n      for (JettySolrRunner downJetty : downJettys) {\n        downJetty.start();\n      }\n    }\n\n    // This index has the same number for every field\n    \n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // Thread.sleep(10000000000L);\n\n    del(\"*:*\"); // delete all docs and test stats request\n    commit();\n    try {\n      query(\"q\", \"*:*\", \"stats\", \"true\", \n            \"stats.field\", \"stats_dt\", \n            \"stats.field\", i1, \n            \"stats.field\", tdate_a, \n            \"stats.field\", tdate_b,\n            \"stats.calcdistinct\", \"true\");\n    } catch (HttpSolrServer.RemoteSolrException e) {\n      if (e.getMessage().startsWith(\"java.lang.NullPointerException\"))  {\n        fail(\"NullPointerException with stats request on empty index\");\n      } else  {\n        throw e;\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  public void doTest() throws Exception {\n    int backupStress = stress; // make a copy so we can restore\n\n\n    del(\"*:*\");\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\", \n           tdate_a, \"2010-04-20T11:00:00Z\",\n           tdate_b, \"2009-08-20T11:00:00Z\",\n           \"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\", \n           tdate_a, \"2010-05-02T11:00:00Z\",\n           tdate_b, \"2009-11-02T11:00:00Z\");\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\", \n           tdate_a, \"2010-05-03T11:00:00Z\");\n    indexr(id,4, i1, -100 ,tlong, 101,\n           t1,\"the quick fox jumped over the lazy dog\", \n           tdate_a, \"2010-05-03T11:00:00Z\",\n           tdate_b, \"2010-05-03T11:00:00Z\");\n    indexr(id,5, i1, 500, tlong, 500 ,\n           t1,\"the quick fox jumped way over the lazy dog\", \n           tdate_a, \"2010-05-05T11:00:00Z\");\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,\n           tdate_b, \"2010-01-05T11:00:00Z\",\n           t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n\n    commit();  // try to ensure there's more than one segment\n\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,\n           t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,\n           t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,\n           t1,\"no eggs on wall, lesson learned\", \n           oddField, \"odd man out\");\n\n    indexr(id, \"1001\", \"lowerfilt\", \"toyota\"); // for spellcheck\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n    \n    \n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n\n    handle.clear();\n    handle.put(\"QTime\", SKIPVAL);\n    handle.put(\"timestamp\", SKIPVAL);\n    handle.put(\"_version_\", SKIPVAL); // not a cloud test, but may use updateLog\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(\"q\",\"*:*\", \"sort\",f+\" desc\");\n      query(\"q\",\"*:*\", \"sort\",f+\" asc\");\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",\"{!func}testfunc(add(\"+i1+\",5))\"+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" asc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\");\n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"*,score\"); \n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 desc\");\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"{!func}\"+i1);// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(\"q\",\"{!func}\"+i1, \"fl\",\"*,score\");  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"quick\");\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\");\n    query(\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\");  // no fields in returned docs\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\");\n\n    handle.put(\"score\", SKIPVAL);\n    query(\"q\",\"quick\",\"fl\",\"*,score\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\");\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"matchesnothing\",\"fl\",\"*,score\");  \n\n    // test that a single NOW value is propagated to all shards... if that is true\n    // then the primary sort should always be a tie and then the secondary should always decide\n    query(\"q\",\"{!func}ms(NOW)\", \"sort\",\"score desc,\"+i1+\" desc\",\"fl\",\"id\");    \n\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\");\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2);\n\n    // a facet query to test out chars out of the ascii range\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!term f=foo_s}international\\u00ff\\u01ff\\u2222\\u3333\");\n\n    // simple date facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date.other\", \"all\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // date facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date\",tdate_b, \n          \"facet.date.other\", \"all\", \n          \"f.\"+tdate_b+\".facet.date.start\",\"2009-05-01T11:00:00Z\", \n          \"f.\"+tdate_b+\".facet.date.gap\",\"+3MONTHS\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // simple range facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"facet.range.end\",900);\n\n    // range facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range\",i1, \n          \"f.\"+i1+\".facet.range.start\",300, \n          \"f.\"+i1+\".facet.range.gap\",87, \n          \"facet.range.end\",900,\n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"f.\"+tlong+\".facet.range.end\",900);\n    \n    //  variations of fl\n    query(\"q\",\"*:*\", \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1 + \",score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", i1, \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id,\" + i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1, \"fl\", \"id\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",nint, \"fl\",tint,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",nint, \"fl\", \"id\", \"fl\",tint,\"sort\",i1 + \" desc\");\n\n    // basic spellcheck testing\n    query(\"q\", \"toyata\", \"fl\", \"id,lowerfilt\", \"spellcheck\", true, \"spellcheck.q\", \"toyata\", \"qt\", \"spellCheckCompRH_Direct\", \"shards.qt\", \"spellCheckCompRH_Direct\");\n\n    stress=0;  // turn off stress... we want to tex max combos in min time\n    for (int i=0; i<25*RANDOM_MULTIPLIER; i++) {\n      String f = fieldNames[random().nextInt(fieldNames.length)];\n      if (random().nextBoolean()) f = t1;  // the text field is a really interesting one to facet on (and it's multi-valued too)\n\n      // we want a random query and not just *:* so we'll get zero counts in facets also\n      // TODO: do a better random query\n      String q = random().nextBoolean() ? \"*:*\" : \"id:(1 3 5 7 9 11 13) OR id:[100 TO \" + random().nextInt(50) + \"]\";\n\n      int nolimit = random().nextBoolean() ? -1 : 10000;  // these should be equivalent\n\n      // if limit==-1, we should always get exact matches\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"count\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      // for index sort, we should get exact results for mincount <= 1\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(2), \"facet.offset\",random().nextInt(10), \"facet.limit\",random().nextInt(11)-1);\n    }\n    stress = backupStress;  // restore stress\n\n    // test faceting multiple things at once\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1);\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id:[1 TO 7]\", \"fq\",\"{!tag=b}id:[3 TO 9]\"\n    );\n    query(\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\");\n\n    // test field that is valid in schema but missing in all shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2);\n    // test field that is valid in schema and missing in some shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2);\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", \"stats_dt\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1);\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", tdate_a);\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", tdate_b);\n\n    handle.put(\"stats_fields\", UNORDERED);\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\",\n          \"stats.field\", \"stats_dt\",\n          \"stats.field\", i1,\n          \"stats.field\", tdate_a,\n          \"stats.field\", tdate_b);\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    // check a complex key name\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"*:*\", \"rows\",100);\n    }\n\n    //SOLR 3161 ensure shards.qt=/update fails (anything but search handler really)\n    // Also see TestRemoteStreaming#testQtUpdateFails()\n    try {\n      ignoreException(\"isShard is only acceptable\");\n      // query(\"q\",\"*:*\",\"shards.qt\",\"/update\",\"stream.body\",\"<delete><query>*:*</query></delete>\");\n      // fail();\n    } catch (SolrException e) {\n      //expected\n    }\n    unIgnoreException(\"isShard is only acceptable\");\n\n    // test debugging\n    // handle.put(\"explain\", UNORDERED);\n    handle.put(\"explain\", SKIPVAL);  // internal docids differ, idf differs w/o global idf\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    handle.put(\"track\", SKIP); //track is not included in single node search\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY);\n\n    // Check Info is added to for each shard\n    ModifiableSolrParams q = new ModifiableSolrParams();\n    q.set(\"q\", \"*:*\");\n    q.set(ShardParams.SHARDS_INFO, true);\n    setDistributedParams(q);\n    QueryResponse rsp = queryServer(q);\n    NamedList<?> sinfo = (NamedList<?>) rsp.getResponse().get(ShardParams.SHARDS_INFO);\n    String shards = getShardsString();\n    int cnt = StringUtils.countMatches(shards, \",\")+1;\n    \n    assertNotNull(\"missing shard info\", sinfo);\n    assertEquals(\"should have an entry for each shard [\"+sinfo+\"] \"+shards, cnt, sinfo.size());\n\n    // test shards.tolerant=true\n    for(int numDownServers = 0; numDownServers < jettys.size()-1; numDownServers++)\n    {\n      List<JettySolrRunner> upJettys = new ArrayList<>(jettys);\n      List<SolrServer> upClients = new ArrayList<>(clients);\n      List<JettySolrRunner> downJettys = new ArrayList<>();\n      List<String> upShards = new ArrayList<>(Arrays.asList(shardsArr));\n      for(int i=0; i<numDownServers; i++)\n      {\n        // shut down some of the jettys\n        int indexToRemove = r.nextInt(upJettys.size());\n        JettySolrRunner downJetty = upJettys.remove(indexToRemove);\n        upClients.remove(indexToRemove);\n        upShards.remove(indexToRemove);\n        ChaosMonkey.stop(downJetty);\n        downJettys.add(downJetty);\n      }\n\n      queryPartialResults(upShards, upClients, \n          \"q\",\"*:*\",\n          \"facet\",\"true\", \n          \"facet.field\",t1,\n          \"facet.limit\",5,\n          ShardParams.SHARDS_INFO,\"true\",\n          ShardParams.SHARDS_TOLERANT,\"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"facet\", \"true\",\n          \"facet.query\", i1 + \":[1 TO 50]\",\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      // test group query\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"rows\", 100,\n          \"fl\", \"id,\" + i1,\n          \"group\", \"true\",\n          \"group.query\", t1 + \":kings OR \" + t1 + \":eggs\",\n          \"group.limit\", 10,\n          \"sort\", i1 + \" asc, id asc\",\n          CommonParams.TIME_ALLOWED, 1,\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"stats\", \"true\",\n          \"stats.field\", i1,\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"toyata\",\n          \"spellcheck\", \"true\",\n          \"spellcheck.q\", \"toyata\",\n          \"qt\", \"spellCheckCompRH_Direct\",\n          \"shards.qt\", \"spellCheckCompRH_Direct\",\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      // restart the jettys\n      for (JettySolrRunner downJetty : downJettys) {\n        downJetty.start();\n      }\n    }\n\n    // This index has the same number for every field\n    \n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // Thread.sleep(10000000000L);\n\n    del(\"*:*\"); // delete all docs and test stats request\n    commit();\n    try {\n      query(\"q\", \"*:*\", \"stats\", \"true\", \n            \"stats.field\", \"stats_dt\", \n            \"stats.field\", i1, \n            \"stats.field\", tdate_a, \n            \"stats.field\", tdate_b,\n            \"stats.calcdistinct\", \"true\");\n    } catch (HttpSolrServer.RemoteSolrException e) {\n      if (e.getMessage().startsWith(\"java.lang.NullPointerException\"))  {\n        fail(\"NullPointerException with stats request on empty index\");\n      } else  {\n        throw e;\n      }\n    }\n  }\n\n","bugFix":["5bb29c260c4bbaf4ce8a95d362844ebf77ec1f76"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"92751ba9273251eab6a2e379ec42a1697a32ff96","date":1407954233,"type":3,"author":"Chris M. Hostetter","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/TestDistributedSearch#doTest().mjava","pathOld":"solr/core/src/test/org/apache/solr/TestDistributedSearch#doTest().mjava","sourceNew":"  @Override\n  public void doTest() throws Exception {\n    QueryResponse rsp = null;\n    int backupStress = stress; // make a copy so we can restore\n\n\n    del(\"*:*\");\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\", \n           tdate_a, \"2010-04-20T11:00:00Z\",\n           tdate_b, \"2009-08-20T11:00:00Z\",\n           \"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\", \n           tdate_a, \"2010-05-02T11:00:00Z\",\n           tdate_b, \"2009-11-02T11:00:00Z\");\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\", \n           tdate_a, \"2010-05-03T11:00:00Z\");\n    indexr(id,4, i1, -100 ,tlong, 101,\n           t1,\"the quick fox jumped over the lazy dog\", \n           tdate_a, \"2010-05-03T11:00:00Z\",\n           tdate_b, \"2010-05-03T11:00:00Z\");\n    indexr(id,5, i1, 500, tlong, 500 ,\n           t1,\"the quick fox jumped way over the lazy dog\", \n           tdate_a, \"2010-05-05T11:00:00Z\");\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,\n           tdate_b, \"2010-01-05T11:00:00Z\",\n           t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n\n    commit();  // try to ensure there's more than one segment\n\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,\n           t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,\n           t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,\n           t1,\"no eggs on wall, lesson learned\", \n           oddField, \"odd man out\");\n\n    indexr(id, \"1001\", \"lowerfilt\", \"toyota\"); // for spellcheck\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n    \n    \n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n\n    handle.clear();\n    handle.put(\"timestamp\", SKIPVAL);\n    handle.put(\"_version_\", SKIPVAL); // not a cloud test, but may use updateLog\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(\"q\",\"*:*\", \"sort\",f+\" desc\");\n      query(\"q\",\"*:*\", \"sort\",f+\" asc\");\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",\"{!func}testfunc(add(\"+i1+\",5))\"+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" asc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\");\n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"*,score\"); \n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 desc\");\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"{!func}\"+i1);// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(\"q\",\"{!func}\"+i1, \"fl\",\"*,score\");  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"quick\");\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\");\n    query(\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\");  // no fields in returned docs\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\");\n\n    handle.put(\"score\", SKIPVAL);\n    query(\"q\",\"quick\",\"fl\",\"*,score\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\");\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"matchesnothing\",\"fl\",\"*,score\");  \n\n    // test that a single NOW value is propagated to all shards... if that is true\n    // then the primary sort should always be a tie and then the secondary should always decide\n    query(\"q\",\"{!func}ms(NOW)\", \"sort\",\"score desc,\"+i1+\" desc\",\"fl\",\"id\");    \n\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\");\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2);\n\n    // a facet query to test out chars out of the ascii range\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!term f=foo_s}international\\u00ff\\u01ff\\u2222\\u3333\");\n    \n    // simple field facet on date fields\n    rsp = query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\", tdate_a);\n    assertEquals(1, rsp.getFacetFields().size());\n    rsp = query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \n                \"facet.field\", tdate_b, \"facet.field\", tdate_a);\n    assertEquals(2, rsp.getFacetFields().size());\n\n    // simple date facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date.other\", \"all\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // date facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date\",tdate_b, \n          \"facet.date.other\", \"all\", \n          \"f.\"+tdate_b+\".facet.date.start\",\"2009-05-01T11:00:00Z\", \n          \"f.\"+tdate_b+\".facet.date.gap\",\"+3MONTHS\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // simple range facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"facet.range.end\",900);\n\n    // range facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range\",i1, \n          \"f.\"+i1+\".facet.range.start\",300, \n          \"f.\"+i1+\".facet.range.gap\",87, \n          \"facet.range.end\",900,\n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"f.\"+tlong+\".facet.range.end\",900);\n    \n    //  variations of fl\n    query(\"q\",\"*:*\", \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1 + \",score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", i1, \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id,\" + i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1, \"fl\", \"id\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",nint, \"fl\",tint,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",nint, \"fl\", \"id\", \"fl\",tint,\"sort\",i1 + \" desc\");\n\n    // basic spellcheck testing\n    query(\"q\", \"toyata\", \"fl\", \"id,lowerfilt\", \"spellcheck\", true, \"spellcheck.q\", \"toyata\", \"qt\", \"spellCheckCompRH_Direct\", \"shards.qt\", \"spellCheckCompRH_Direct\");\n\n    stress=0;  // turn off stress... we want to tex max combos in min time\n    for (int i=0; i<25*RANDOM_MULTIPLIER; i++) {\n      String f = fieldNames[random().nextInt(fieldNames.length)];\n      if (random().nextBoolean()) f = t1;  // the text field is a really interesting one to facet on (and it's multi-valued too)\n\n      // we want a random query and not just *:* so we'll get zero counts in facets also\n      // TODO: do a better random query\n      String q = random().nextBoolean() ? \"*:*\" : \"id:(1 3 5 7 9 11 13) OR id:[100 TO \" + random().nextInt(50) + \"]\";\n\n      int nolimit = random().nextBoolean() ? -1 : 10000;  // these should be equivalent\n\n      // if limit==-1, we should always get exact matches\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"count\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      // for index sort, we should get exact results for mincount <= 1\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(2), \"facet.offset\",random().nextInt(10), \"facet.limit\",random().nextInt(11)-1);\n    }\n    stress = backupStress;  // restore stress\n\n    // test faceting multiple things at once\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1);\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id:[1 TO 7]\", \"fq\",\"{!tag=b}id:[3 TO 9]\"\n    );\n    query(\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\");\n\n    // test field that is valid in schema but missing in all shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2);\n    // test field that is valid in schema and missing in some shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2);\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", \"stats_dt\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1);\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", tdate_a);\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", tdate_b);\n\n    handle.put(\"stats_fields\", UNORDERED);\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\",\n          \"stats.field\", \"stats_dt\",\n          \"stats.field\", i1,\n          \"stats.field\", tdate_a,\n          \"stats.field\", tdate_b);\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    // check a complex key name\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"*:*\", \"rows\",100);\n    }\n\n    //SOLR 3161 ensure shards.qt=/update fails (anything but search handler really)\n    // Also see TestRemoteStreaming#testQtUpdateFails()\n    try {\n      ignoreException(\"isShard is only acceptable\");\n      // query(\"q\",\"*:*\",\"shards.qt\",\"/update\",\"stream.body\",\"<delete><query>*:*</query></delete>\");\n      // fail();\n    } catch (SolrException e) {\n      //expected\n    }\n    unIgnoreException(\"isShard is only acceptable\");\n\n    // test debugging\n    // handle.put(\"explain\", UNORDERED);\n    handle.put(\"explain\", SKIPVAL);  // internal docids differ, idf differs w/o global idf\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    handle.put(\"track\", SKIP); //track is not included in single node search\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY);\n\n    // Check Info is added to for each shard\n    ModifiableSolrParams q = new ModifiableSolrParams();\n    q.set(\"q\", \"*:*\");\n    q.set(ShardParams.SHARDS_INFO, true);\n    setDistributedParams(q);\n    rsp = queryServer(q);\n    NamedList<?> sinfo = (NamedList<?>) rsp.getResponse().get(ShardParams.SHARDS_INFO);\n    String shards = getShardsString();\n    int cnt = StringUtils.countMatches(shards, \",\")+1;\n    \n    assertNotNull(\"missing shard info\", sinfo);\n    assertEquals(\"should have an entry for each shard [\"+sinfo+\"] \"+shards, cnt, sinfo.size());\n\n    // test shards.tolerant=true\n    for(int numDownServers = 0; numDownServers < jettys.size()-1; numDownServers++)\n    {\n      List<JettySolrRunner> upJettys = new ArrayList<>(jettys);\n      List<SolrServer> upClients = new ArrayList<>(clients);\n      List<JettySolrRunner> downJettys = new ArrayList<>();\n      List<String> upShards = new ArrayList<>(Arrays.asList(shardsArr));\n      for(int i=0; i<numDownServers; i++)\n      {\n        // shut down some of the jettys\n        int indexToRemove = r.nextInt(upJettys.size());\n        JettySolrRunner downJetty = upJettys.remove(indexToRemove);\n        upClients.remove(indexToRemove);\n        upShards.remove(indexToRemove);\n        ChaosMonkey.stop(downJetty);\n        downJettys.add(downJetty);\n      }\n\n      queryPartialResults(upShards, upClients, \n          \"q\",\"*:*\",\n          \"facet\",\"true\", \n          \"facet.field\",t1,\n          \"facet.limit\",5,\n          ShardParams.SHARDS_INFO,\"true\",\n          ShardParams.SHARDS_TOLERANT,\"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"facet\", \"true\",\n          \"facet.query\", i1 + \":[1 TO 50]\",\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      // test group query\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"rows\", 100,\n          \"fl\", \"id,\" + i1,\n          \"group\", \"true\",\n          \"group.query\", t1 + \":kings OR \" + t1 + \":eggs\",\n          \"group.limit\", 10,\n          \"sort\", i1 + \" asc, id asc\",\n          CommonParams.TIME_ALLOWED, 1,\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"stats\", \"true\",\n          \"stats.field\", i1,\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"toyata\",\n          \"spellcheck\", \"true\",\n          \"spellcheck.q\", \"toyata\",\n          \"qt\", \"spellCheckCompRH_Direct\",\n          \"shards.qt\", \"spellCheckCompRH_Direct\",\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      // restart the jettys\n      for (JettySolrRunner downJetty : downJettys) {\n        downJetty.start();\n      }\n    }\n\n    // This index has the same number for every field\n    \n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // Thread.sleep(10000000000L);\n\n    del(\"*:*\"); // delete all docs and test stats request\n    commit();\n    try {\n      query(\"q\", \"*:*\", \"stats\", \"true\", \n            \"stats.field\", \"stats_dt\", \n            \"stats.field\", i1, \n            \"stats.field\", tdate_a, \n            \"stats.field\", tdate_b,\n            \"stats.calcdistinct\", \"true\");\n    } catch (HttpSolrServer.RemoteSolrException e) {\n      if (e.getMessage().startsWith(\"java.lang.NullPointerException\"))  {\n        fail(\"NullPointerException with stats request on empty index\");\n      } else  {\n        throw e;\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  public void doTest() throws Exception {\n    int backupStress = stress; // make a copy so we can restore\n\n\n    del(\"*:*\");\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\", \n           tdate_a, \"2010-04-20T11:00:00Z\",\n           tdate_b, \"2009-08-20T11:00:00Z\",\n           \"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\", \n           tdate_a, \"2010-05-02T11:00:00Z\",\n           tdate_b, \"2009-11-02T11:00:00Z\");\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\", \n           tdate_a, \"2010-05-03T11:00:00Z\");\n    indexr(id,4, i1, -100 ,tlong, 101,\n           t1,\"the quick fox jumped over the lazy dog\", \n           tdate_a, \"2010-05-03T11:00:00Z\",\n           tdate_b, \"2010-05-03T11:00:00Z\");\n    indexr(id,5, i1, 500, tlong, 500 ,\n           t1,\"the quick fox jumped way over the lazy dog\", \n           tdate_a, \"2010-05-05T11:00:00Z\");\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,\n           tdate_b, \"2010-01-05T11:00:00Z\",\n           t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n\n    commit();  // try to ensure there's more than one segment\n\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,\n           t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,\n           t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,\n           t1,\"no eggs on wall, lesson learned\", \n           oddField, \"odd man out\");\n\n    indexr(id, \"1001\", \"lowerfilt\", \"toyota\"); // for spellcheck\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n    \n    \n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n\n    handle.clear();\n    handle.put(\"timestamp\", SKIPVAL);\n    handle.put(\"_version_\", SKIPVAL); // not a cloud test, but may use updateLog\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(\"q\",\"*:*\", \"sort\",f+\" desc\");\n      query(\"q\",\"*:*\", \"sort\",f+\" asc\");\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",\"{!func}testfunc(add(\"+i1+\",5))\"+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" asc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\");\n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"*,score\"); \n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 desc\");\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"{!func}\"+i1);// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(\"q\",\"{!func}\"+i1, \"fl\",\"*,score\");  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"quick\");\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\");\n    query(\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\");  // no fields in returned docs\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\");\n\n    handle.put(\"score\", SKIPVAL);\n    query(\"q\",\"quick\",\"fl\",\"*,score\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\");\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"matchesnothing\",\"fl\",\"*,score\");  \n\n    // test that a single NOW value is propagated to all shards... if that is true\n    // then the primary sort should always be a tie and then the secondary should always decide\n    query(\"q\",\"{!func}ms(NOW)\", \"sort\",\"score desc,\"+i1+\" desc\",\"fl\",\"id\");    \n\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\");\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2);\n\n    // a facet query to test out chars out of the ascii range\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!term f=foo_s}international\\u00ff\\u01ff\\u2222\\u3333\");\n\n    // simple date facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date.other\", \"all\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // date facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date\",tdate_b, \n          \"facet.date.other\", \"all\", \n          \"f.\"+tdate_b+\".facet.date.start\",\"2009-05-01T11:00:00Z\", \n          \"f.\"+tdate_b+\".facet.date.gap\",\"+3MONTHS\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // simple range facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"facet.range.end\",900);\n\n    // range facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range\",i1, \n          \"f.\"+i1+\".facet.range.start\",300, \n          \"f.\"+i1+\".facet.range.gap\",87, \n          \"facet.range.end\",900,\n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"f.\"+tlong+\".facet.range.end\",900);\n    \n    //  variations of fl\n    query(\"q\",\"*:*\", \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1 + \",score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", i1, \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id,\" + i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1, \"fl\", \"id\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",nint, \"fl\",tint,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",nint, \"fl\", \"id\", \"fl\",tint,\"sort\",i1 + \" desc\");\n\n    // basic spellcheck testing\n    query(\"q\", \"toyata\", \"fl\", \"id,lowerfilt\", \"spellcheck\", true, \"spellcheck.q\", \"toyata\", \"qt\", \"spellCheckCompRH_Direct\", \"shards.qt\", \"spellCheckCompRH_Direct\");\n\n    stress=0;  // turn off stress... we want to tex max combos in min time\n    for (int i=0; i<25*RANDOM_MULTIPLIER; i++) {\n      String f = fieldNames[random().nextInt(fieldNames.length)];\n      if (random().nextBoolean()) f = t1;  // the text field is a really interesting one to facet on (and it's multi-valued too)\n\n      // we want a random query and not just *:* so we'll get zero counts in facets also\n      // TODO: do a better random query\n      String q = random().nextBoolean() ? \"*:*\" : \"id:(1 3 5 7 9 11 13) OR id:[100 TO \" + random().nextInt(50) + \"]\";\n\n      int nolimit = random().nextBoolean() ? -1 : 10000;  // these should be equivalent\n\n      // if limit==-1, we should always get exact matches\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"count\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      // for index sort, we should get exact results for mincount <= 1\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(2), \"facet.offset\",random().nextInt(10), \"facet.limit\",random().nextInt(11)-1);\n    }\n    stress = backupStress;  // restore stress\n\n    // test faceting multiple things at once\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1);\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id:[1 TO 7]\", \"fq\",\"{!tag=b}id:[3 TO 9]\"\n    );\n    query(\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\");\n\n    // test field that is valid in schema but missing in all shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2);\n    // test field that is valid in schema and missing in some shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2);\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", \"stats_dt\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1);\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", tdate_a);\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", tdate_b);\n\n    handle.put(\"stats_fields\", UNORDERED);\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\",\n          \"stats.field\", \"stats_dt\",\n          \"stats.field\", i1,\n          \"stats.field\", tdate_a,\n          \"stats.field\", tdate_b);\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    // check a complex key name\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"*:*\", \"rows\",100);\n    }\n\n    //SOLR 3161 ensure shards.qt=/update fails (anything but search handler really)\n    // Also see TestRemoteStreaming#testQtUpdateFails()\n    try {\n      ignoreException(\"isShard is only acceptable\");\n      // query(\"q\",\"*:*\",\"shards.qt\",\"/update\",\"stream.body\",\"<delete><query>*:*</query></delete>\");\n      // fail();\n    } catch (SolrException e) {\n      //expected\n    }\n    unIgnoreException(\"isShard is only acceptable\");\n\n    // test debugging\n    // handle.put(\"explain\", UNORDERED);\n    handle.put(\"explain\", SKIPVAL);  // internal docids differ, idf differs w/o global idf\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    handle.put(\"track\", SKIP); //track is not included in single node search\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY);\n\n    // Check Info is added to for each shard\n    ModifiableSolrParams q = new ModifiableSolrParams();\n    q.set(\"q\", \"*:*\");\n    q.set(ShardParams.SHARDS_INFO, true);\n    setDistributedParams(q);\n    QueryResponse rsp = queryServer(q);\n    NamedList<?> sinfo = (NamedList<?>) rsp.getResponse().get(ShardParams.SHARDS_INFO);\n    String shards = getShardsString();\n    int cnt = StringUtils.countMatches(shards, \",\")+1;\n    \n    assertNotNull(\"missing shard info\", sinfo);\n    assertEquals(\"should have an entry for each shard [\"+sinfo+\"] \"+shards, cnt, sinfo.size());\n\n    // test shards.tolerant=true\n    for(int numDownServers = 0; numDownServers < jettys.size()-1; numDownServers++)\n    {\n      List<JettySolrRunner> upJettys = new ArrayList<>(jettys);\n      List<SolrServer> upClients = new ArrayList<>(clients);\n      List<JettySolrRunner> downJettys = new ArrayList<>();\n      List<String> upShards = new ArrayList<>(Arrays.asList(shardsArr));\n      for(int i=0; i<numDownServers; i++)\n      {\n        // shut down some of the jettys\n        int indexToRemove = r.nextInt(upJettys.size());\n        JettySolrRunner downJetty = upJettys.remove(indexToRemove);\n        upClients.remove(indexToRemove);\n        upShards.remove(indexToRemove);\n        ChaosMonkey.stop(downJetty);\n        downJettys.add(downJetty);\n      }\n\n      queryPartialResults(upShards, upClients, \n          \"q\",\"*:*\",\n          \"facet\",\"true\", \n          \"facet.field\",t1,\n          \"facet.limit\",5,\n          ShardParams.SHARDS_INFO,\"true\",\n          ShardParams.SHARDS_TOLERANT,\"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"facet\", \"true\",\n          \"facet.query\", i1 + \":[1 TO 50]\",\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      // test group query\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"rows\", 100,\n          \"fl\", \"id,\" + i1,\n          \"group\", \"true\",\n          \"group.query\", t1 + \":kings OR \" + t1 + \":eggs\",\n          \"group.limit\", 10,\n          \"sort\", i1 + \" asc, id asc\",\n          CommonParams.TIME_ALLOWED, 1,\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"stats\", \"true\",\n          \"stats.field\", i1,\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"toyata\",\n          \"spellcheck\", \"true\",\n          \"spellcheck.q\", \"toyata\",\n          \"qt\", \"spellCheckCompRH_Direct\",\n          \"shards.qt\", \"spellCheckCompRH_Direct\",\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      // restart the jettys\n      for (JettySolrRunner downJetty : downJettys) {\n        downJetty.start();\n      }\n    }\n\n    // This index has the same number for every field\n    \n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // Thread.sleep(10000000000L);\n\n    del(\"*:*\"); // delete all docs and test stats request\n    commit();\n    try {\n      query(\"q\", \"*:*\", \"stats\", \"true\", \n            \"stats.field\", \"stats_dt\", \n            \"stats.field\", i1, \n            \"stats.field\", tdate_a, \n            \"stats.field\", tdate_b,\n            \"stats.calcdistinct\", \"true\");\n    } catch (HttpSolrServer.RemoteSolrException e) {\n      if (e.getMessage().startsWith(\"java.lang.NullPointerException\"))  {\n        fail(\"NullPointerException with stats request on empty index\");\n      } else  {\n        throw e;\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d5952c5a694ea98255fc6cce4ea7cb36185feefb","date":1408300232,"type":3,"author":"Chris M. Hostetter","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/TestDistributedSearch#doTest().mjava","pathOld":"solr/core/src/test/org/apache/solr/TestDistributedSearch#doTest().mjava","sourceNew":"  @Override\n  public void doTest() throws Exception {\n    QueryResponse rsp = null;\n    int backupStress = stress; // make a copy so we can restore\n\n\n    del(\"*:*\");\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\", \n           tdate_a, \"2010-04-20T11:00:00Z\",\n           tdate_b, \"2009-08-20T11:00:00Z\",\n           \"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\", \n           tdate_a, \"2010-05-02T11:00:00Z\",\n           tdate_b, \"2009-11-02T11:00:00Z\");\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\", \n           tdate_a, \"2010-05-03T11:00:00Z\");\n    indexr(id,4, i1, -100 ,tlong, 101,\n           t1,\"the quick fox jumped over the lazy dog\", \n           tdate_a, \"2010-05-03T11:00:00Z\",\n           tdate_b, \"2010-05-03T11:00:00Z\");\n    indexr(id,5, i1, 500, tlong, 500 ,\n           t1,\"the quick fox jumped way over the lazy dog\", \n           tdate_a, \"2010-05-05T11:00:00Z\");\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,\n           tdate_b, \"2010-01-05T11:00:00Z\",\n           t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n\n    commit();  // try to ensure there's more than one segment\n\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,\n           t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,\n           t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,\n           t1,\"no eggs on wall, lesson learned\", \n           oddField, \"odd man out\");\n\n    indexr(id, \"1001\", \"lowerfilt\", \"toyota\"); // for spellcheck\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n    \n    \n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n\n    handle.clear();\n    handle.put(\"timestamp\", SKIPVAL);\n    handle.put(\"_version_\", SKIPVAL); // not a cloud test, but may use updateLog\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(\"q\",\"*:*\", \"sort\",f+\" desc\");\n      query(\"q\",\"*:*\", \"sort\",f+\" asc\");\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",\"{!func}testfunc(add(\"+i1+\",5))\"+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" asc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\");\n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"*,score\"); \n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 desc\");\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"{!func}\"+i1);// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(\"q\",\"{!func}\"+i1, \"fl\",\"*,score\");  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"quick\");\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\");\n    query(\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\");  // no fields in returned docs\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\");\n\n    handle.put(\"score\", SKIPVAL);\n    query(\"q\",\"quick\",\"fl\",\"*,score\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\");\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"matchesnothing\",\"fl\",\"*,score\");  \n\n    // test that a single NOW value is propagated to all shards... if that is true\n    // then the primary sort should always be a tie and then the secondary should always decide\n    query(\"q\",\"{!func}ms(NOW)\", \"sort\",\"score desc,\"+i1+\" desc\",\"fl\",\"id\");    \n\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\");\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2);\n\n    // a facet query to test out chars out of the ascii range\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!term f=foo_s}international\\u00ff\\u01ff\\u2222\\u3333\");\n    \n    // simple field facet on date fields\n    rsp = query(\"q\",\"*:*\", \"rows\", 0, \n                \"facet\",\"true\", \"facet.limit\", 1, // TODO: limit shouldn't be needed: SOLR-6386\n                \"facet.field\", tdate_a);\n    assertEquals(1, rsp.getFacetFields().size());\n    rsp = query(\"q\",\"*:*\", \"rows\", 0, \n                \"facet\",\"true\", \"facet.limit\", 1, // TODO: limit shouldn't be needed: SOLR-6386\n                \"facet.field\", tdate_b, \"facet.field\", tdate_a);\n    assertEquals(2, rsp.getFacetFields().size());\n\n    // simple date facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date.other\", \"all\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // date facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date\",tdate_b, \n          \"facet.date.other\", \"all\", \n          \"f.\"+tdate_b+\".facet.date.start\",\"2009-05-01T11:00:00Z\", \n          \"f.\"+tdate_b+\".facet.date.gap\",\"+3MONTHS\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // simple range facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"facet.range.end\",900);\n\n    // range facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range\",i1, \n          \"f.\"+i1+\".facet.range.start\",300, \n          \"f.\"+i1+\".facet.range.gap\",87, \n          \"facet.range.end\",900,\n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"f.\"+tlong+\".facet.range.end\",900);\n    \n    //  variations of fl\n    query(\"q\",\"*:*\", \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1 + \",score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", i1, \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id,\" + i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1, \"fl\", \"id\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",nint, \"fl\",tint,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",nint, \"fl\", \"id\", \"fl\",tint,\"sort\",i1 + \" desc\");\n\n    // basic spellcheck testing\n    query(\"q\", \"toyata\", \"fl\", \"id,lowerfilt\", \"spellcheck\", true, \"spellcheck.q\", \"toyata\", \"qt\", \"spellCheckCompRH_Direct\", \"shards.qt\", \"spellCheckCompRH_Direct\");\n\n    stress=0;  // turn off stress... we want to tex max combos in min time\n    for (int i=0; i<25*RANDOM_MULTIPLIER; i++) {\n      String f = fieldNames[random().nextInt(fieldNames.length)];\n      if (random().nextBoolean()) f = t1;  // the text field is a really interesting one to facet on (and it's multi-valued too)\n\n      // we want a random query and not just *:* so we'll get zero counts in facets also\n      // TODO: do a better random query\n      String q = random().nextBoolean() ? \"*:*\" : \"id:(1 3 5 7 9 11 13) OR id:[100 TO \" + random().nextInt(50) + \"]\";\n\n      int nolimit = random().nextBoolean() ? -1 : 10000;  // these should be equivalent\n\n      // if limit==-1, we should always get exact matches\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"count\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      // for index sort, we should get exact results for mincount <= 1\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(2), \"facet.offset\",random().nextInt(10), \"facet.limit\",random().nextInt(11)-1);\n    }\n    stress = backupStress;  // restore stress\n\n    // test faceting multiple things at once\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1);\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id:[1 TO 7]\", \"fq\",\"{!tag=b}id:[3 TO 9]\"\n    );\n    query(\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\");\n\n    // test field that is valid in schema but missing in all shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2);\n    // test field that is valid in schema and missing in some shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2);\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", \"stats_dt\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1);\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", tdate_a);\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", tdate_b);\n\n    handle.put(\"stats_fields\", UNORDERED);\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\",\n          \"stats.field\", \"stats_dt\",\n          \"stats.field\", i1,\n          \"stats.field\", tdate_a,\n          \"stats.field\", tdate_b);\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    // check a complex key name\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"*:*\", \"rows\",100);\n    }\n\n    //SOLR 3161 ensure shards.qt=/update fails (anything but search handler really)\n    // Also see TestRemoteStreaming#testQtUpdateFails()\n    try {\n      ignoreException(\"isShard is only acceptable\");\n      // query(\"q\",\"*:*\",\"shards.qt\",\"/update\",\"stream.body\",\"<delete><query>*:*</query></delete>\");\n      // fail();\n    } catch (SolrException e) {\n      //expected\n    }\n    unIgnoreException(\"isShard is only acceptable\");\n\n    // test debugging\n    // handle.put(\"explain\", UNORDERED);\n    handle.put(\"explain\", SKIPVAL);  // internal docids differ, idf differs w/o global idf\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    handle.put(\"track\", SKIP); //track is not included in single node search\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY);\n\n    // Check Info is added to for each shard\n    ModifiableSolrParams q = new ModifiableSolrParams();\n    q.set(\"q\", \"*:*\");\n    q.set(ShardParams.SHARDS_INFO, true);\n    setDistributedParams(q);\n    rsp = queryServer(q);\n    NamedList<?> sinfo = (NamedList<?>) rsp.getResponse().get(ShardParams.SHARDS_INFO);\n    String shards = getShardsString();\n    int cnt = StringUtils.countMatches(shards, \",\")+1;\n    \n    assertNotNull(\"missing shard info\", sinfo);\n    assertEquals(\"should have an entry for each shard [\"+sinfo+\"] \"+shards, cnt, sinfo.size());\n\n    // test shards.tolerant=true\n    for(int numDownServers = 0; numDownServers < jettys.size()-1; numDownServers++)\n    {\n      List<JettySolrRunner> upJettys = new ArrayList<>(jettys);\n      List<SolrServer> upClients = new ArrayList<>(clients);\n      List<JettySolrRunner> downJettys = new ArrayList<>();\n      List<String> upShards = new ArrayList<>(Arrays.asList(shardsArr));\n      for(int i=0; i<numDownServers; i++)\n      {\n        // shut down some of the jettys\n        int indexToRemove = r.nextInt(upJettys.size());\n        JettySolrRunner downJetty = upJettys.remove(indexToRemove);\n        upClients.remove(indexToRemove);\n        upShards.remove(indexToRemove);\n        ChaosMonkey.stop(downJetty);\n        downJettys.add(downJetty);\n      }\n\n      queryPartialResults(upShards, upClients, \n          \"q\",\"*:*\",\n          \"facet\",\"true\", \n          \"facet.field\",t1,\n          \"facet.limit\",5,\n          ShardParams.SHARDS_INFO,\"true\",\n          ShardParams.SHARDS_TOLERANT,\"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"facet\", \"true\",\n          \"facet.query\", i1 + \":[1 TO 50]\",\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      // test group query\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"rows\", 100,\n          \"fl\", \"id,\" + i1,\n          \"group\", \"true\",\n          \"group.query\", t1 + \":kings OR \" + t1 + \":eggs\",\n          \"group.limit\", 10,\n          \"sort\", i1 + \" asc, id asc\",\n          CommonParams.TIME_ALLOWED, 1,\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"stats\", \"true\",\n          \"stats.field\", i1,\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"toyata\",\n          \"spellcheck\", \"true\",\n          \"spellcheck.q\", \"toyata\",\n          \"qt\", \"spellCheckCompRH_Direct\",\n          \"shards.qt\", \"spellCheckCompRH_Direct\",\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      // restart the jettys\n      for (JettySolrRunner downJetty : downJettys) {\n        downJetty.start();\n      }\n    }\n\n    // This index has the same number for every field\n    \n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // Thread.sleep(10000000000L);\n\n    del(\"*:*\"); // delete all docs and test stats request\n    commit();\n    try {\n      query(\"q\", \"*:*\", \"stats\", \"true\", \n            \"stats.field\", \"stats_dt\", \n            \"stats.field\", i1, \n            \"stats.field\", tdate_a, \n            \"stats.field\", tdate_b,\n            \"stats.calcdistinct\", \"true\");\n    } catch (HttpSolrServer.RemoteSolrException e) {\n      if (e.getMessage().startsWith(\"java.lang.NullPointerException\"))  {\n        fail(\"NullPointerException with stats request on empty index\");\n      } else  {\n        throw e;\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  public void doTest() throws Exception {\n    QueryResponse rsp = null;\n    int backupStress = stress; // make a copy so we can restore\n\n\n    del(\"*:*\");\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\", \n           tdate_a, \"2010-04-20T11:00:00Z\",\n           tdate_b, \"2009-08-20T11:00:00Z\",\n           \"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\", \n           tdate_a, \"2010-05-02T11:00:00Z\",\n           tdate_b, \"2009-11-02T11:00:00Z\");\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\", \n           tdate_a, \"2010-05-03T11:00:00Z\");\n    indexr(id,4, i1, -100 ,tlong, 101,\n           t1,\"the quick fox jumped over the lazy dog\", \n           tdate_a, \"2010-05-03T11:00:00Z\",\n           tdate_b, \"2010-05-03T11:00:00Z\");\n    indexr(id,5, i1, 500, tlong, 500 ,\n           t1,\"the quick fox jumped way over the lazy dog\", \n           tdate_a, \"2010-05-05T11:00:00Z\");\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,\n           tdate_b, \"2010-01-05T11:00:00Z\",\n           t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n\n    commit();  // try to ensure there's more than one segment\n\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,\n           t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,\n           t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,\n           t1,\"no eggs on wall, lesson learned\", \n           oddField, \"odd man out\");\n\n    indexr(id, \"1001\", \"lowerfilt\", \"toyota\"); // for spellcheck\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n    \n    \n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n\n    handle.clear();\n    handle.put(\"timestamp\", SKIPVAL);\n    handle.put(\"_version_\", SKIPVAL); // not a cloud test, but may use updateLog\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(\"q\",\"*:*\", \"sort\",f+\" desc\");\n      query(\"q\",\"*:*\", \"sort\",f+\" asc\");\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",\"{!func}testfunc(add(\"+i1+\",5))\"+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" asc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\");\n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"*,score\"); \n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 desc\");\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"{!func}\"+i1);// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(\"q\",\"{!func}\"+i1, \"fl\",\"*,score\");  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"quick\");\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\");\n    query(\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\");  // no fields in returned docs\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\");\n\n    handle.put(\"score\", SKIPVAL);\n    query(\"q\",\"quick\",\"fl\",\"*,score\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\");\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"matchesnothing\",\"fl\",\"*,score\");  \n\n    // test that a single NOW value is propagated to all shards... if that is true\n    // then the primary sort should always be a tie and then the secondary should always decide\n    query(\"q\",\"{!func}ms(NOW)\", \"sort\",\"score desc,\"+i1+\" desc\",\"fl\",\"id\");    \n\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\");\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2);\n\n    // a facet query to test out chars out of the ascii range\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!term f=foo_s}international\\u00ff\\u01ff\\u2222\\u3333\");\n    \n    // simple field facet on date fields\n    rsp = query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\", tdate_a);\n    assertEquals(1, rsp.getFacetFields().size());\n    rsp = query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \n                \"facet.field\", tdate_b, \"facet.field\", tdate_a);\n    assertEquals(2, rsp.getFacetFields().size());\n\n    // simple date facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date.other\", \"all\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // date facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date\",tdate_b, \n          \"facet.date.other\", \"all\", \n          \"f.\"+tdate_b+\".facet.date.start\",\"2009-05-01T11:00:00Z\", \n          \"f.\"+tdate_b+\".facet.date.gap\",\"+3MONTHS\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // simple range facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"facet.range.end\",900);\n\n    // range facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range\",i1, \n          \"f.\"+i1+\".facet.range.start\",300, \n          \"f.\"+i1+\".facet.range.gap\",87, \n          \"facet.range.end\",900,\n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"f.\"+tlong+\".facet.range.end\",900);\n    \n    //  variations of fl\n    query(\"q\",\"*:*\", \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1 + \",score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", i1, \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id,\" + i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1, \"fl\", \"id\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",nint, \"fl\",tint,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",nint, \"fl\", \"id\", \"fl\",tint,\"sort\",i1 + \" desc\");\n\n    // basic spellcheck testing\n    query(\"q\", \"toyata\", \"fl\", \"id,lowerfilt\", \"spellcheck\", true, \"spellcheck.q\", \"toyata\", \"qt\", \"spellCheckCompRH_Direct\", \"shards.qt\", \"spellCheckCompRH_Direct\");\n\n    stress=0;  // turn off stress... we want to tex max combos in min time\n    for (int i=0; i<25*RANDOM_MULTIPLIER; i++) {\n      String f = fieldNames[random().nextInt(fieldNames.length)];\n      if (random().nextBoolean()) f = t1;  // the text field is a really interesting one to facet on (and it's multi-valued too)\n\n      // we want a random query and not just *:* so we'll get zero counts in facets also\n      // TODO: do a better random query\n      String q = random().nextBoolean() ? \"*:*\" : \"id:(1 3 5 7 9 11 13) OR id:[100 TO \" + random().nextInt(50) + \"]\";\n\n      int nolimit = random().nextBoolean() ? -1 : 10000;  // these should be equivalent\n\n      // if limit==-1, we should always get exact matches\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"count\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      // for index sort, we should get exact results for mincount <= 1\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(2), \"facet.offset\",random().nextInt(10), \"facet.limit\",random().nextInt(11)-1);\n    }\n    stress = backupStress;  // restore stress\n\n    // test faceting multiple things at once\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1);\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id:[1 TO 7]\", \"fq\",\"{!tag=b}id:[3 TO 9]\"\n    );\n    query(\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\");\n\n    // test field that is valid in schema but missing in all shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2);\n    // test field that is valid in schema and missing in some shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2);\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", \"stats_dt\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1);\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", tdate_a);\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", tdate_b);\n\n    handle.put(\"stats_fields\", UNORDERED);\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\",\n          \"stats.field\", \"stats_dt\",\n          \"stats.field\", i1,\n          \"stats.field\", tdate_a,\n          \"stats.field\", tdate_b);\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    // check a complex key name\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"*:*\", \"rows\",100);\n    }\n\n    //SOLR 3161 ensure shards.qt=/update fails (anything but search handler really)\n    // Also see TestRemoteStreaming#testQtUpdateFails()\n    try {\n      ignoreException(\"isShard is only acceptable\");\n      // query(\"q\",\"*:*\",\"shards.qt\",\"/update\",\"stream.body\",\"<delete><query>*:*</query></delete>\");\n      // fail();\n    } catch (SolrException e) {\n      //expected\n    }\n    unIgnoreException(\"isShard is only acceptable\");\n\n    // test debugging\n    // handle.put(\"explain\", UNORDERED);\n    handle.put(\"explain\", SKIPVAL);  // internal docids differ, idf differs w/o global idf\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    handle.put(\"track\", SKIP); //track is not included in single node search\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY);\n\n    // Check Info is added to for each shard\n    ModifiableSolrParams q = new ModifiableSolrParams();\n    q.set(\"q\", \"*:*\");\n    q.set(ShardParams.SHARDS_INFO, true);\n    setDistributedParams(q);\n    rsp = queryServer(q);\n    NamedList<?> sinfo = (NamedList<?>) rsp.getResponse().get(ShardParams.SHARDS_INFO);\n    String shards = getShardsString();\n    int cnt = StringUtils.countMatches(shards, \",\")+1;\n    \n    assertNotNull(\"missing shard info\", sinfo);\n    assertEquals(\"should have an entry for each shard [\"+sinfo+\"] \"+shards, cnt, sinfo.size());\n\n    // test shards.tolerant=true\n    for(int numDownServers = 0; numDownServers < jettys.size()-1; numDownServers++)\n    {\n      List<JettySolrRunner> upJettys = new ArrayList<>(jettys);\n      List<SolrServer> upClients = new ArrayList<>(clients);\n      List<JettySolrRunner> downJettys = new ArrayList<>();\n      List<String> upShards = new ArrayList<>(Arrays.asList(shardsArr));\n      for(int i=0; i<numDownServers; i++)\n      {\n        // shut down some of the jettys\n        int indexToRemove = r.nextInt(upJettys.size());\n        JettySolrRunner downJetty = upJettys.remove(indexToRemove);\n        upClients.remove(indexToRemove);\n        upShards.remove(indexToRemove);\n        ChaosMonkey.stop(downJetty);\n        downJettys.add(downJetty);\n      }\n\n      queryPartialResults(upShards, upClients, \n          \"q\",\"*:*\",\n          \"facet\",\"true\", \n          \"facet.field\",t1,\n          \"facet.limit\",5,\n          ShardParams.SHARDS_INFO,\"true\",\n          ShardParams.SHARDS_TOLERANT,\"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"facet\", \"true\",\n          \"facet.query\", i1 + \":[1 TO 50]\",\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      // test group query\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"rows\", 100,\n          \"fl\", \"id,\" + i1,\n          \"group\", \"true\",\n          \"group.query\", t1 + \":kings OR \" + t1 + \":eggs\",\n          \"group.limit\", 10,\n          \"sort\", i1 + \" asc, id asc\",\n          CommonParams.TIME_ALLOWED, 1,\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"stats\", \"true\",\n          \"stats.field\", i1,\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"toyata\",\n          \"spellcheck\", \"true\",\n          \"spellcheck.q\", \"toyata\",\n          \"qt\", \"spellCheckCompRH_Direct\",\n          \"shards.qt\", \"spellCheckCompRH_Direct\",\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      // restart the jettys\n      for (JettySolrRunner downJetty : downJettys) {\n        downJetty.start();\n      }\n    }\n\n    // This index has the same number for every field\n    \n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // Thread.sleep(10000000000L);\n\n    del(\"*:*\"); // delete all docs and test stats request\n    commit();\n    try {\n      query(\"q\", \"*:*\", \"stats\", \"true\", \n            \"stats.field\", \"stats_dt\", \n            \"stats.field\", i1, \n            \"stats.field\", tdate_a, \n            \"stats.field\", tdate_b,\n            \"stats.calcdistinct\", \"true\");\n    } catch (HttpSolrServer.RemoteSolrException e) {\n      if (e.getMessage().startsWith(\"java.lang.NullPointerException\"))  {\n        fail(\"NullPointerException with stats request on empty index\");\n      } else  {\n        throw e;\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b8a06631c6dd7816f50f77a22d08dac33e15f1f1","date":1408391117,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/TestDistributedSearch#doTest().mjava","pathOld":"solr/core/src/test/org/apache/solr/TestDistributedSearch#doTest().mjava","sourceNew":"  @Override\n  public void doTest() throws Exception {\n    QueryResponse rsp = null;\n    int backupStress = stress; // make a copy so we can restore\n\n\n    del(\"*:*\");\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\", \n           tdate_a, \"2010-04-20T11:00:00Z\",\n           tdate_b, \"2009-08-20T11:00:00Z\",\n           \"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\", \n           tdate_a, \"2010-05-02T11:00:00Z\",\n           tdate_b, \"2009-11-02T11:00:00Z\");\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\", \n           tdate_a, \"2010-05-03T11:00:00Z\");\n    indexr(id,4, i1, -100 ,tlong, 101,\n           t1,\"the quick fox jumped over the lazy dog\", \n           tdate_a, \"2010-05-03T11:00:00Z\",\n           tdate_b, \"2010-05-03T11:00:00Z\");\n    indexr(id,5, i1, 500, tlong, 500 ,\n           t1,\"the quick fox jumped way over the lazy dog\", \n           tdate_a, \"2010-05-05T11:00:00Z\");\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,\n           tdate_b, \"2010-01-05T11:00:00Z\",\n           t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n\n    commit();  // try to ensure there's more than one segment\n\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,\n           t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,\n           t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,\n           t1,\"no eggs on wall, lesson learned\", \n           oddField, \"odd man out\");\n\n    indexr(id, \"1001\", \"lowerfilt\", \"toyota\"); // for spellcheck\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n    \n    \n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n\n    handle.clear();\n    handle.put(\"timestamp\", SKIPVAL);\n    handle.put(\"_version_\", SKIPVAL); // not a cloud test, but may use updateLog\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(\"q\",\"*:*\", \"sort\",f+\" desc\");\n      query(\"q\",\"*:*\", \"sort\",f+\" asc\");\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",\"{!func}testfunc(add(\"+i1+\",5))\"+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" asc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\");\n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"*,score\"); \n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 desc\");\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"{!func}\"+i1);// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(\"q\",\"{!func}\"+i1, \"fl\",\"*,score\");  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"quick\");\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\");\n    query(\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\");  // no fields in returned docs\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\");\n\n    handle.put(\"score\", SKIPVAL);\n    query(\"q\",\"quick\",\"fl\",\"*,score\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\");\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"matchesnothing\",\"fl\",\"*,score\");  \n\n    // test that a single NOW value is propagated to all shards... if that is true\n    // then the primary sort should always be a tie and then the secondary should always decide\n    query(\"q\",\"{!func}ms(NOW)\", \"sort\",\"score desc,\"+i1+\" desc\",\"fl\",\"id\");    \n\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1, \"facet.field\",t1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\");\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2);\n\n    // a facet query to test out chars out of the ascii range\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!term f=foo_s}international\\u00ff\\u01ff\\u2222\\u3333\");\n    \n    // simple field facet on date fields\n    rsp = query(\"q\",\"*:*\", \"rows\", 0, \n                \"facet\",\"true\", \"facet.limit\", 1, // TODO: limit shouldn't be needed: SOLR-6386\n                \"facet.field\", tdate_a);\n    assertEquals(1, rsp.getFacetFields().size());\n    rsp = query(\"q\",\"*:*\", \"rows\", 0, \n                \"facet\",\"true\", \"facet.limit\", 1, // TODO: limit shouldn't be needed: SOLR-6386\n                \"facet.field\", tdate_b, \"facet.field\", tdate_a);\n    assertEquals(2, rsp.getFacetFields().size());\n\n    // simple date facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a,\n          \"facet.date\",tdate_a,\n          \"facet.date.other\", \"all\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // date facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a,\n          \"facet.date\",tdate_b,\n          \"facet.date\",tdate_a,\n          \"facet.date.other\", \"all\", \n          \"f.\"+tdate_b+\".facet.date.start\",\"2009-05-01T11:00:00Z\", \n          \"f.\"+tdate_b+\".facet.date.gap\",\"+3MONTHS\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // simple range facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong,\n          \"facet.range\",tlong,\n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"facet.range.end\",900);\n\n    // range facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range\",i1, \n          \"f.\"+i1+\".facet.range.start\",300, \n          \"f.\"+i1+\".facet.range.gap\",87, \n          \"facet.range.end\",900,\n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"f.\"+tlong+\".facet.range.end\",900);\n    \n    //  variations of fl\n    query(\"q\",\"*:*\", \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1 + \",score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", i1, \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id,\" + i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1, \"fl\", \"id\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",nint, \"fl\",tint,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",nint, \"fl\", \"id\", \"fl\",tint,\"sort\",i1 + \" desc\");\n\n    // basic spellcheck testing\n    query(\"q\", \"toyata\", \"fl\", \"id,lowerfilt\", \"spellcheck\", true, \"spellcheck.q\", \"toyata\", \"qt\", \"spellCheckCompRH_Direct\", \"shards.qt\", \"spellCheckCompRH_Direct\");\n\n    stress=0;  // turn off stress... we want to tex max combos in min time\n    for (int i=0; i<25*RANDOM_MULTIPLIER; i++) {\n      String f = fieldNames[random().nextInt(fieldNames.length)];\n      if (random().nextBoolean()) f = t1;  // the text field is a really interesting one to facet on (and it's multi-valued too)\n\n      // we want a random query and not just *:* so we'll get zero counts in facets also\n      // TODO: do a better random query\n      String q = random().nextBoolean() ? \"*:*\" : \"id:(1 3 5 7 9 11 13) OR id:[100 TO \" + random().nextInt(50) + \"]\";\n\n      int nolimit = random().nextBoolean() ? -1 : 10000;  // these should be equivalent\n\n      // if limit==-1, we should always get exact matches\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"count\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      // for index sort, we should get exact results for mincount <= 1\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(2), \"facet.offset\",random().nextInt(10), \"facet.limit\",random().nextInt(11)-1);\n    }\n    stress = backupStress;  // restore stress\n\n    // test faceting multiple things at once\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1);\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id:[1 TO 7]\", \"fq\",\"{!tag=b}id:[3 TO 9]\"\n    );\n    query(\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\");\n\n    // test field that is valid in schema but missing in all shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2);\n    // test field that is valid in schema and missing in some shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2);\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", \"stats_dt\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1);\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", tdate_a);\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", tdate_b);\n\n    handle.put(\"stats_fields\", UNORDERED);\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\",\n          \"stats.field\", \"stats_dt\",\n          \"stats.field\", i1,\n          \"stats.field\", tdate_a,\n          \"stats.field\", tdate_b);\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    // check a complex key name\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"*:*\", \"rows\",100);\n    }\n\n    //SOLR 3161 ensure shards.qt=/update fails (anything but search handler really)\n    // Also see TestRemoteStreaming#testQtUpdateFails()\n    try {\n      ignoreException(\"isShard is only acceptable\");\n      // query(\"q\",\"*:*\",\"shards.qt\",\"/update\",\"stream.body\",\"<delete><query>*:*</query></delete>\");\n      // fail();\n    } catch (SolrException e) {\n      //expected\n    }\n    unIgnoreException(\"isShard is only acceptable\");\n\n    // test debugging\n    // handle.put(\"explain\", UNORDERED);\n    handle.put(\"explain\", SKIPVAL);  // internal docids differ, idf differs w/o global idf\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    handle.put(\"track\", SKIP); //track is not included in single node search\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY);\n\n    // Check Info is added to for each shard\n    ModifiableSolrParams q = new ModifiableSolrParams();\n    q.set(\"q\", \"*:*\");\n    q.set(ShardParams.SHARDS_INFO, true);\n    setDistributedParams(q);\n    rsp = queryServer(q);\n    NamedList<?> sinfo = (NamedList<?>) rsp.getResponse().get(ShardParams.SHARDS_INFO);\n    String shards = getShardsString();\n    int cnt = StringUtils.countMatches(shards, \",\")+1;\n    \n    assertNotNull(\"missing shard info\", sinfo);\n    assertEquals(\"should have an entry for each shard [\"+sinfo+\"] \"+shards, cnt, sinfo.size());\n\n    // test shards.tolerant=true\n    for(int numDownServers = 0; numDownServers < jettys.size()-1; numDownServers++)\n    {\n      List<JettySolrRunner> upJettys = new ArrayList<>(jettys);\n      List<SolrServer> upClients = new ArrayList<>(clients);\n      List<JettySolrRunner> downJettys = new ArrayList<>();\n      List<String> upShards = new ArrayList<>(Arrays.asList(shardsArr));\n      for(int i=0; i<numDownServers; i++)\n      {\n        // shut down some of the jettys\n        int indexToRemove = r.nextInt(upJettys.size());\n        JettySolrRunner downJetty = upJettys.remove(indexToRemove);\n        upClients.remove(indexToRemove);\n        upShards.remove(indexToRemove);\n        ChaosMonkey.stop(downJetty);\n        downJettys.add(downJetty);\n      }\n\n      queryPartialResults(upShards, upClients, \n          \"q\",\"*:*\",\n          \"facet\",\"true\", \n          \"facet.field\",t1,\n          \"facet.field\",t1,\n          \"facet.limit\",5,\n          ShardParams.SHARDS_INFO,\"true\",\n          ShardParams.SHARDS_TOLERANT,\"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"facet\", \"true\",\n          \"facet.query\", i1 + \":[1 TO 50]\",\n          \"facet.query\", i1 + \":[1 TO 50]\",\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      // test group query\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"rows\", 100,\n          \"fl\", \"id,\" + i1,\n          \"group\", \"true\",\n          \"group.query\", t1 + \":kings OR \" + t1 + \":eggs\",\n          \"group.limit\", 10,\n          \"sort\", i1 + \" asc, id asc\",\n          CommonParams.TIME_ALLOWED, 1,\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"stats\", \"true\",\n          \"stats.field\", i1,\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"toyata\",\n          \"spellcheck\", \"true\",\n          \"spellcheck.q\", \"toyata\",\n          \"qt\", \"spellCheckCompRH_Direct\",\n          \"shards.qt\", \"spellCheckCompRH_Direct\",\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      // restart the jettys\n      for (JettySolrRunner downJetty : downJettys) {\n        downJetty.start();\n      }\n    }\n\n    // This index has the same number for every field\n    \n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // Thread.sleep(10000000000L);\n\n    del(\"*:*\"); // delete all docs and test stats request\n    commit();\n    try {\n      query(\"q\", \"*:*\", \"stats\", \"true\", \n            \"stats.field\", \"stats_dt\", \n            \"stats.field\", i1, \n            \"stats.field\", tdate_a, \n            \"stats.field\", tdate_b,\n            \"stats.calcdistinct\", \"true\");\n    } catch (HttpSolrServer.RemoteSolrException e) {\n      if (e.getMessage().startsWith(\"java.lang.NullPointerException\"))  {\n        fail(\"NullPointerException with stats request on empty index\");\n      } else  {\n        throw e;\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  public void doTest() throws Exception {\n    QueryResponse rsp = null;\n    int backupStress = stress; // make a copy so we can restore\n\n\n    del(\"*:*\");\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\", \n           tdate_a, \"2010-04-20T11:00:00Z\",\n           tdate_b, \"2009-08-20T11:00:00Z\",\n           \"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\", \n           tdate_a, \"2010-05-02T11:00:00Z\",\n           tdate_b, \"2009-11-02T11:00:00Z\");\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\", \n           tdate_a, \"2010-05-03T11:00:00Z\");\n    indexr(id,4, i1, -100 ,tlong, 101,\n           t1,\"the quick fox jumped over the lazy dog\", \n           tdate_a, \"2010-05-03T11:00:00Z\",\n           tdate_b, \"2010-05-03T11:00:00Z\");\n    indexr(id,5, i1, 500, tlong, 500 ,\n           t1,\"the quick fox jumped way over the lazy dog\", \n           tdate_a, \"2010-05-05T11:00:00Z\");\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,\n           tdate_b, \"2010-01-05T11:00:00Z\",\n           t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n\n    commit();  // try to ensure there's more than one segment\n\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,\n           t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,\n           t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,\n           t1,\"no eggs on wall, lesson learned\", \n           oddField, \"odd man out\");\n\n    indexr(id, \"1001\", \"lowerfilt\", \"toyota\"); // for spellcheck\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n    \n    \n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n\n    handle.clear();\n    handle.put(\"timestamp\", SKIPVAL);\n    handle.put(\"_version_\", SKIPVAL); // not a cloud test, but may use updateLog\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(\"q\",\"*:*\", \"sort\",f+\" desc\");\n      query(\"q\",\"*:*\", \"sort\",f+\" asc\");\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",\"{!func}testfunc(add(\"+i1+\",5))\"+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" asc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\");\n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"*,score\"); \n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 desc\");\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"{!func}\"+i1);// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(\"q\",\"{!func}\"+i1, \"fl\",\"*,score\");  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"quick\");\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\");\n    query(\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\");  // no fields in returned docs\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\");\n\n    handle.put(\"score\", SKIPVAL);\n    query(\"q\",\"quick\",\"fl\",\"*,score\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\");\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"matchesnothing\",\"fl\",\"*,score\");  \n\n    // test that a single NOW value is propagated to all shards... if that is true\n    // then the primary sort should always be a tie and then the secondary should always decide\n    query(\"q\",\"{!func}ms(NOW)\", \"sort\",\"score desc,\"+i1+\" desc\",\"fl\",\"id\");    \n\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\");\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2);\n\n    // a facet query to test out chars out of the ascii range\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!term f=foo_s}international\\u00ff\\u01ff\\u2222\\u3333\");\n    \n    // simple field facet on date fields\n    rsp = query(\"q\",\"*:*\", \"rows\", 0, \n                \"facet\",\"true\", \"facet.limit\", 1, // TODO: limit shouldn't be needed: SOLR-6386\n                \"facet.field\", tdate_a);\n    assertEquals(1, rsp.getFacetFields().size());\n    rsp = query(\"q\",\"*:*\", \"rows\", 0, \n                \"facet\",\"true\", \"facet.limit\", 1, // TODO: limit shouldn't be needed: SOLR-6386\n                \"facet.field\", tdate_b, \"facet.field\", tdate_a);\n    assertEquals(2, rsp.getFacetFields().size());\n\n    // simple date facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date.other\", \"all\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // date facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a, \n          \"facet.date\",tdate_b, \n          \"facet.date.other\", \"all\", \n          \"f.\"+tdate_b+\".facet.date.start\",\"2009-05-01T11:00:00Z\", \n          \"f.\"+tdate_b+\".facet.date.gap\",\"+3MONTHS\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // simple range facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"facet.range.end\",900);\n\n    // range facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range\",i1, \n          \"f.\"+i1+\".facet.range.start\",300, \n          \"f.\"+i1+\".facet.range.gap\",87, \n          \"facet.range.end\",900,\n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"f.\"+tlong+\".facet.range.end\",900);\n    \n    //  variations of fl\n    query(\"q\",\"*:*\", \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1 + \",score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", i1, \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id,\" + i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1, \"fl\", \"id\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",nint, \"fl\",tint,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",nint, \"fl\", \"id\", \"fl\",tint,\"sort\",i1 + \" desc\");\n\n    // basic spellcheck testing\n    query(\"q\", \"toyata\", \"fl\", \"id,lowerfilt\", \"spellcheck\", true, \"spellcheck.q\", \"toyata\", \"qt\", \"spellCheckCompRH_Direct\", \"shards.qt\", \"spellCheckCompRH_Direct\");\n\n    stress=0;  // turn off stress... we want to tex max combos in min time\n    for (int i=0; i<25*RANDOM_MULTIPLIER; i++) {\n      String f = fieldNames[random().nextInt(fieldNames.length)];\n      if (random().nextBoolean()) f = t1;  // the text field is a really interesting one to facet on (and it's multi-valued too)\n\n      // we want a random query and not just *:* so we'll get zero counts in facets also\n      // TODO: do a better random query\n      String q = random().nextBoolean() ? \"*:*\" : \"id:(1 3 5 7 9 11 13) OR id:[100 TO \" + random().nextInt(50) + \"]\";\n\n      int nolimit = random().nextBoolean() ? -1 : 10000;  // these should be equivalent\n\n      // if limit==-1, we should always get exact matches\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"count\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      // for index sort, we should get exact results for mincount <= 1\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(2), \"facet.offset\",random().nextInt(10), \"facet.limit\",random().nextInt(11)-1);\n    }\n    stress = backupStress;  // restore stress\n\n    // test faceting multiple things at once\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1);\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id:[1 TO 7]\", \"fq\",\"{!tag=b}id:[3 TO 9]\"\n    );\n    query(\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\");\n\n    // test field that is valid in schema but missing in all shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2);\n    // test field that is valid in schema and missing in some shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2);\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", \"stats_dt\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1);\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", tdate_a);\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", tdate_b);\n\n    handle.put(\"stats_fields\", UNORDERED);\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\",\n          \"stats.field\", \"stats_dt\",\n          \"stats.field\", i1,\n          \"stats.field\", tdate_a,\n          \"stats.field\", tdate_b);\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    // check a complex key name\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"*:*\", \"rows\",100);\n    }\n\n    //SOLR 3161 ensure shards.qt=/update fails (anything but search handler really)\n    // Also see TestRemoteStreaming#testQtUpdateFails()\n    try {\n      ignoreException(\"isShard is only acceptable\");\n      // query(\"q\",\"*:*\",\"shards.qt\",\"/update\",\"stream.body\",\"<delete><query>*:*</query></delete>\");\n      // fail();\n    } catch (SolrException e) {\n      //expected\n    }\n    unIgnoreException(\"isShard is only acceptable\");\n\n    // test debugging\n    // handle.put(\"explain\", UNORDERED);\n    handle.put(\"explain\", SKIPVAL);  // internal docids differ, idf differs w/o global idf\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    handle.put(\"track\", SKIP); //track is not included in single node search\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY);\n\n    // Check Info is added to for each shard\n    ModifiableSolrParams q = new ModifiableSolrParams();\n    q.set(\"q\", \"*:*\");\n    q.set(ShardParams.SHARDS_INFO, true);\n    setDistributedParams(q);\n    rsp = queryServer(q);\n    NamedList<?> sinfo = (NamedList<?>) rsp.getResponse().get(ShardParams.SHARDS_INFO);\n    String shards = getShardsString();\n    int cnt = StringUtils.countMatches(shards, \",\")+1;\n    \n    assertNotNull(\"missing shard info\", sinfo);\n    assertEquals(\"should have an entry for each shard [\"+sinfo+\"] \"+shards, cnt, sinfo.size());\n\n    // test shards.tolerant=true\n    for(int numDownServers = 0; numDownServers < jettys.size()-1; numDownServers++)\n    {\n      List<JettySolrRunner> upJettys = new ArrayList<>(jettys);\n      List<SolrServer> upClients = new ArrayList<>(clients);\n      List<JettySolrRunner> downJettys = new ArrayList<>();\n      List<String> upShards = new ArrayList<>(Arrays.asList(shardsArr));\n      for(int i=0; i<numDownServers; i++)\n      {\n        // shut down some of the jettys\n        int indexToRemove = r.nextInt(upJettys.size());\n        JettySolrRunner downJetty = upJettys.remove(indexToRemove);\n        upClients.remove(indexToRemove);\n        upShards.remove(indexToRemove);\n        ChaosMonkey.stop(downJetty);\n        downJettys.add(downJetty);\n      }\n\n      queryPartialResults(upShards, upClients, \n          \"q\",\"*:*\",\n          \"facet\",\"true\", \n          \"facet.field\",t1,\n          \"facet.limit\",5,\n          ShardParams.SHARDS_INFO,\"true\",\n          ShardParams.SHARDS_TOLERANT,\"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"facet\", \"true\",\n          \"facet.query\", i1 + \":[1 TO 50]\",\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      // test group query\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"rows\", 100,\n          \"fl\", \"id,\" + i1,\n          \"group\", \"true\",\n          \"group.query\", t1 + \":kings OR \" + t1 + \":eggs\",\n          \"group.limit\", 10,\n          \"sort\", i1 + \" asc, id asc\",\n          CommonParams.TIME_ALLOWED, 1,\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"stats\", \"true\",\n          \"stats.field\", i1,\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"toyata\",\n          \"spellcheck\", \"true\",\n          \"spellcheck.q\", \"toyata\",\n          \"qt\", \"spellCheckCompRH_Direct\",\n          \"shards.qt\", \"spellCheckCompRH_Direct\",\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      // restart the jettys\n      for (JettySolrRunner downJetty : downJettys) {\n        downJetty.start();\n      }\n    }\n\n    // This index has the same number for every field\n    \n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // Thread.sleep(10000000000L);\n\n    del(\"*:*\"); // delete all docs and test stats request\n    commit();\n    try {\n      query(\"q\", \"*:*\", \"stats\", \"true\", \n            \"stats.field\", \"stats_dt\", \n            \"stats.field\", i1, \n            \"stats.field\", tdate_a, \n            \"stats.field\", tdate_b,\n            \"stats.calcdistinct\", \"true\");\n    } catch (HttpSolrServer.RemoteSolrException e) {\n      if (e.getMessage().startsWith(\"java.lang.NullPointerException\"))  {\n        fail(\"NullPointerException with stats request on empty index\");\n      } else  {\n        throw e;\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":["bb222a3f9d9421d5c95afce73013fbd8de07ea1f"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"8ff4734b6c86245e852fe8b6a286716d5e59d415","date":1410194063,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/TestDistributedSearch#doTest().mjava","pathOld":"solr/core/src/test/org/apache/solr/TestDistributedSearch#doTest().mjava","sourceNew":"  @Override\n  public void doTest() throws Exception {\n    QueryResponse rsp = null;\n    int backupStress = stress; // make a copy so we can restore\n\n\n    del(\"*:*\");\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\",\n           tdate_a, \"2010-04-20T11:00:00Z\",\n           tdate_b, \"2009-08-20T11:00:00Z\",\n           \"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\",\n           tdate_a, \"2010-05-02T11:00:00Z\",\n           tdate_b, \"2009-11-02T11:00:00Z\");\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\",\n           tdate_a, \"2010-05-03T11:00:00Z\");\n    indexr(id,4, i1, -100 ,tlong, 101,\n           t1,\"the quick fox jumped over the lazy dog\", \n           tdate_a, \"2010-05-03T11:00:00Z\",\n           tdate_b, \"2010-05-03T11:00:00Z\");\n    indexr(id,5, i1, 500, tlong, 500 ,\n           t1,\"the quick fox jumped way over the lazy dog\", \n           tdate_a, \"2010-05-05T11:00:00Z\");\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,\n           tdate_b, \"2010-01-05T11:00:00Z\",\n           t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n\n    commit();  // try to ensure there's more than one segment\n\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,\n           t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,\n           t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,\n           t1,\"no eggs on wall, lesson learned\", \n           oddField, \"odd man out\");\n\n    indexr(id, \"1001\", \"lowerfilt\", \"toyota\"); // for spellcheck\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n    \n    \n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n\n    handle.clear();\n    handle.put(\"timestamp\", SKIPVAL);\n    handle.put(\"_version_\", SKIPVAL); // not a cloud test, but may use updateLog\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(\"q\",\"*:*\", \"sort\",f+\" desc\");\n      query(\"q\",\"*:*\", \"sort\",f+\" asc\");\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",\"{!func}testfunc(add(\"+i1+\",5))\"+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" asc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\");\n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"*,score\"); \n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 desc\");\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"{!func}\"+i1);// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(\"q\",\"{!func}\"+i1, \"fl\",\"*,score\");  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"quick\");\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\");\n    query(\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\");  // no fields in returned docs\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\");\n\n    handle.put(\"score\", SKIPVAL);\n    query(\"q\",\"quick\",\"fl\",\"*,score\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\");\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"matchesnothing\",\"fl\",\"*,score\");  \n\n    // test that a single NOW value is propagated to all shards... if that is true\n    // then the primary sort should always be a tie and then the secondary should always decide\n    query(\"q\",\"{!func}ms(NOW)\", \"sort\",\"score desc,\"+i1+\" desc\",\"fl\",\"id\");    \n\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1, \"facet.field\",t1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\");\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2);\n\n    // a facet query to test out chars out of the ascii range\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!term f=foo_s}international\\u00ff\\u01ff\\u2222\\u3333\");\n\n    // simple field facet on date fields\n    rsp = query(\"q\",\"*:*\", \"rows\", 0,\n                \"facet\",\"true\", \"facet.limit\", 1, // TODO: limit shouldn't be needed: SOLR-6386\n                \"facet.field\", tdate_a);\n    assertEquals(1, rsp.getFacetFields().size());\n    rsp = query(\"q\",\"*:*\", \"rows\", 0,\n                \"facet\",\"true\", \"facet.limit\", 1, // TODO: limit shouldn't be needed: SOLR-6386\n                \"facet.field\", tdate_b, \"facet.field\", tdate_a);\n    assertEquals(2, rsp.getFacetFields().size());\n\n    // simple date facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a,\n          \"facet.date\",tdate_a,\n          \"facet.date.other\", \"all\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // date facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a,\n          \"facet.date\",tdate_b,\n          \"facet.date\",tdate_a,\n          \"facet.date.other\", \"all\", \n          \"f.\"+tdate_b+\".facet.date.start\",\"2009-05-01T11:00:00Z\", \n          \"f.\"+tdate_b+\".facet.date.gap\",\"+3MONTHS\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // simple range facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong,\n          \"facet.range\",tlong,\n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"facet.range.end\",900);\n\n    // range facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range\",i1, \n          \"f.\"+i1+\".facet.range.start\",300, \n          \"f.\"+i1+\".facet.range.gap\",87, \n          \"facet.range.end\",900,\n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"f.\"+tlong+\".facet.range.end\",900);\n\n    // Test mincounts. Do NOT want to go through all the stuff where with validateControlData in query() method\n    // Purposely packing a _bunch_ of stuff together here to insure that the proper level of mincount is used for\n    // each\n    ModifiableSolrParams minParams = new ModifiableSolrParams();\n    minParams.set(\"q\",\"*:*\");\n    minParams.set(\"rows\", 1);\n    minParams.set(\"facet\", \"true\");\n    minParams.set(\"facet.missing\", \"true\");\n    minParams.set(\"facet.field\", i1);\n    minParams.set(\"facet.missing\", \"true\");\n    minParams.set(\"facet.mincount\", 2);\n\n    // Return a separate section of ranges over i1. Should respect global range mincount\n    minParams.set(\"facet.range\", i1);\n    minParams.set(\"f.\" + i1 + \".facet.range.start\", 0);\n    minParams.set(\"f.\" + i1 + \".facet.range.gap\", 200);\n    minParams.set(\"f.\" + i1 + \".facet.range.end\", 1200);\n    minParams.set(\"f.\" + i1 + \".facet.mincount\", 4);\n\n\n    // Return a separate section of ranges over tlong Should respect facet.mincount\n    minParams.add(\"facet.range\", tlong);\n    minParams.set(\"f.\" + tlong + \".facet.range.start\", 0);\n    minParams.set(\"f.\" + tlong + \".facet.range.gap\", 100);\n    minParams.set(\"f.\" + tlong + \".facet.range.end\", 1200);\n    // Repeat with a range type of date\n    minParams.add(\"facet.range\", tdate_b);\n    minParams.set(\"f.\" + tdate_b + \".facet.range.start\", \"2009-02-01T00:00:00Z\");\n    minParams.set(\"f.\" + tdate_b + \".facet.range.gap\", \"+1YEAR\");\n    minParams.set(\"f.\" + tdate_b + \".facet.range.end\", \"2011-01-01T00:00:00Z\");\n    minParams.set(\"f.\" + tdate_b + \".facet.mincount\", 3);\n\n    // Insure that global mincount is respected for facet queries\n    minParams.set(\"facet.query\", tdate_a + \":[2010-01-01T00:00:00Z TO 2011-01-01T00:00:00Z]\"); // Should return some counts\n    //minParams.set(\"facet.query\", tdate_a + \":[* TO *]\"); // Should be removed\n    minParams.add(\"facet.query\", tdate_b + \":[2008-01-01T00:00:00Z TO 2009-09-01T00:00:00Z]\"); // Should be removed from response\n\n\n    setDistributedParams(minParams);\n    QueryResponse minResp = queryServer(minParams);\n\n    ModifiableSolrParams eParams = new ModifiableSolrParams();\n    eParams.set(\"q\",tdate_b + \":[* TO *]\");\n    eParams.set(\"rows\", 1000);\n    eParams.set(\"fl\", tdate_b);\n    setDistributedParams(eParams);\n    QueryResponse eResp = queryServer(eParams);\n\n    // Check that exactly the right numbers of counts came through\n    assertEquals(\"Should be exactly 2 range facets returned after minCounts taken into account \", 3, minResp.getFacetRanges().size());\n    assertEquals(\"Should only be 1 query facets returned after minCounts taken into account \", 1, minResp.getFacetQuery().size());\n\n    checkMinCountsField(minResp.getFacetField(i1).getValues(), new Object[]{null, 55L}); // Should just be the null entries for field\n\n    checkMinCountsRange(minResp.getFacetRanges().get(0).getCounts(), new Object[]{\"0\", 5L}); // range on i1\n    checkMinCountsRange(minResp.getFacetRanges().get(1).getCounts(), new Object[]{\"0\", 3L, \"100\", 3L}); // range on tlong\n    checkMinCountsRange(minResp.getFacetRanges().get(2).getCounts(), new Object[]{\"2009-02-01T00:00:00Z\",  3L}); // date (range) on tvh\n\n    assertTrue(\"Should have a facet for tdate_a\", minResp.getFacetQuery().containsKey(\"a_n_tdt:[2010-01-01T00:00:00Z TO 2011-01-01T00:00:00Z]\"));\n    int qCount = minResp.getFacetQuery().get(\"a_n_tdt:[2010-01-01T00:00:00Z TO 2011-01-01T00:00:00Z]\");\n    assertEquals(\"tdate_a should be 5\", qCount, 5);\n\n    // Now let's do some queries, the above is getting too complex\n    minParams = new ModifiableSolrParams();\n    minParams.set(\"q\",\"*:*\");\n    minParams.set(\"rows\", 1);\n    minParams.set(\"facet\", \"true\");\n    minParams.set(\"facet.mincount\", 3);\n\n    minParams.set(\"facet.query\", tdate_a + \":[2010-01-01T00:00:00Z TO 2010-05-04T00:00:00Z]\");\n    minParams.add(\"facet.query\", tdate_b + \":[2009-01-01T00:00:00Z TO 2010-01-01T00:00:00Z]\"); // Should be removed\n    setDistributedParams(minParams);\n    minResp = queryServer(minParams);\n\n    assertEquals(\"Should only be 1 query facets returned after minCounts taken into account \", 1, minResp.getFacetQuery().size());\n    assertTrue(\"Should be an entry for a_n_tdt\", minResp.getFacetQuery().containsKey(\"a_n_tdt:[2010-01-01T00:00:00Z TO 2010-05-04T00:00:00Z]\"));\n    qCount = minResp.getFacetQuery().get(\"a_n_tdt:[2010-01-01T00:00:00Z TO 2010-05-04T00:00:00Z]\");\n    assertEquals(\"a_n_tdt should have a count of 4 \", qCount, 4);\n    //  variations of fl\n    query(\"q\",\"*:*\", \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1 + \",score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", i1, \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id,\" + i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1, \"fl\", \"id\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",nint, \"fl\",tint,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",nint, \"fl\", \"id\", \"fl\",tint,\"sort\",i1 + \" desc\");\n\n    // basic spellcheck testing\n    query(\"q\", \"toyata\", \"fl\", \"id,lowerfilt\", \"spellcheck\", true, \"spellcheck.q\", \"toyata\", \"qt\", \"spellCheckCompRH_Direct\", \"shards.qt\", \"spellCheckCompRH_Direct\");\n\n    stress=0;  // turn off stress... we want to tex max combos in min time\n    for (int i=0; i<25*RANDOM_MULTIPLIER; i++) {\n      String f = fieldNames[random().nextInt(fieldNames.length)];\n      if (random().nextBoolean()) f = t1;  // the text field is a really interesting one to facet on (and it's multi-valued too)\n\n      // we want a random query and not just *:* so we'll get zero counts in facets also\n      // TODO: do a better random query\n      String q = random().nextBoolean() ? \"*:*\" : \"id:(1 3 5 7 9 11 13) OR id:[100 TO \" + random().nextInt(50) + \"]\";\n\n      int nolimit = random().nextBoolean() ? -1 : 10000;  // these should be equivalent\n\n      // if limit==-1, we should always get exact matches\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"count\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      // for index sort, we should get exact results for mincount <= 1\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(2), \"facet.offset\",random().nextInt(10), \"facet.limit\",random().nextInt(11)-1);\n    }\n    stress = backupStress;  // restore stress\n\n    // test faceting multiple things at once\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1);\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id:[1 TO 7]\", \"fq\",\"{!tag=b}id:[3 TO 9]\"\n    );\n    query(\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\");\n\n    // test field that is valid in schema but missing in all shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2);\n    // test field that is valid in schema and missing in some shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2);\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", \"stats_dt\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1);\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", tdate_a);\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", tdate_b);\n\n    handle.put(\"stats_fields\", UNORDERED);\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\",\n          \"stats.field\", \"stats_dt\",\n          \"stats.field\", i1,\n          \"stats.field\", tdate_a,\n          \"stats.field\", tdate_b);\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    // check a complex key name\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"*:*\", \"rows\",100);\n    }\n\n    //SOLR 3161 ensure shards.qt=/update fails (anything but search handler really)\n    // Also see TestRemoteStreaming#testQtUpdateFails()\n    try {\n      ignoreException(\"isShard is only acceptable\");\n      // query(\"q\",\"*:*\",\"shards.qt\",\"/update\",\"stream.body\",\"<delete><query>*:*</query></delete>\");\n      // fail();\n    } catch (SolrException e) {\n      //expected\n    }\n    unIgnoreException(\"isShard is only acceptable\");\n\n    // test debugging\n    // handle.put(\"explain\", UNORDERED);\n    handle.put(\"explain\", SKIPVAL);  // internal docids differ, idf differs w/o global idf\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    handle.put(\"track\", SKIP); //track is not included in single node search\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY);\n\n    // Check Info is added to for each shard\n    ModifiableSolrParams q = new ModifiableSolrParams();\n    q.set(\"q\", \"*:*\");\n    q.set(ShardParams.SHARDS_INFO, true);\n    setDistributedParams(q);\n    rsp = queryServer(q);\n    NamedList<?> sinfo = (NamedList<?>) rsp.getResponse().get(ShardParams.SHARDS_INFO);\n    String shards = getShardsString();\n    int cnt = StringUtils.countMatches(shards, \",\")+1;\n    \n    assertNotNull(\"missing shard info\", sinfo);\n    assertEquals(\"should have an entry for each shard [\"+sinfo+\"] \"+shards, cnt, sinfo.size());\n\n    // test shards.tolerant=true\n    for(int numDownServers = 0; numDownServers < jettys.size()-1; numDownServers++)\n    {\n      List<JettySolrRunner> upJettys = new ArrayList<>(jettys);\n      List<SolrServer> upClients = new ArrayList<>(clients);\n      List<JettySolrRunner> downJettys = new ArrayList<>();\n      List<String> upShards = new ArrayList<>(Arrays.asList(shardsArr));\n      for(int i=0; i<numDownServers; i++)\n      {\n        // shut down some of the jettys\n        int indexToRemove = r.nextInt(upJettys.size());\n        JettySolrRunner downJetty = upJettys.remove(indexToRemove);\n        upClients.remove(indexToRemove);\n        upShards.remove(indexToRemove);\n        ChaosMonkey.stop(downJetty);\n        downJettys.add(downJetty);\n      }\n\n      queryPartialResults(upShards, upClients, \n          \"q\",\"*:*\",\n          \"facet\",\"true\", \n          \"facet.field\",t1,\n          \"facet.field\",t1,\n          \"facet.limit\",5,\n          ShardParams.SHARDS_INFO,\"true\",\n          ShardParams.SHARDS_TOLERANT,\"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"facet\", \"true\",\n          \"facet.query\", i1 + \":[1 TO 50]\",\n          \"facet.query\", i1 + \":[1 TO 50]\",\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      // test group query\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"rows\", 100,\n          \"fl\", \"id,\" + i1,\n          \"group\", \"true\",\n          \"group.query\", t1 + \":kings OR \" + t1 + \":eggs\",\n          \"group.limit\", 10,\n          \"sort\", i1 + \" asc, id asc\",\n          CommonParams.TIME_ALLOWED, 1,\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"stats\", \"true\",\n          \"stats.field\", i1,\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"toyata\",\n          \"spellcheck\", \"true\",\n          \"spellcheck.q\", \"toyata\",\n          \"qt\", \"spellCheckCompRH_Direct\",\n          \"shards.qt\", \"spellCheckCompRH_Direct\",\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      // restart the jettys\n      for (JettySolrRunner downJetty : downJettys) {\n        downJetty.start();\n      }\n    }\n\n    // This index has the same number for every field\n    \n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // Thread.sleep(10000000000L);\n\n    del(\"*:*\"); // delete all docs and test stats request\n    commit();\n    try {\n      query(\"q\", \"*:*\", \"stats\", \"true\", \n            \"stats.field\", \"stats_dt\", \n            \"stats.field\", i1, \n            \"stats.field\", tdate_a, \n            \"stats.field\", tdate_b,\n            \"stats.calcdistinct\", \"true\");\n    } catch (HttpSolrServer.RemoteSolrException e) {\n      if (e.getMessage().startsWith(\"java.lang.NullPointerException\"))  {\n        fail(\"NullPointerException with stats request on empty index\");\n      } else  {\n        throw e;\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  public void doTest() throws Exception {\n    QueryResponse rsp = null;\n    int backupStress = stress; // make a copy so we can restore\n\n\n    del(\"*:*\");\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\", \n           tdate_a, \"2010-04-20T11:00:00Z\",\n           tdate_b, \"2009-08-20T11:00:00Z\",\n           \"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\", \n           tdate_a, \"2010-05-02T11:00:00Z\",\n           tdate_b, \"2009-11-02T11:00:00Z\");\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\", \n           tdate_a, \"2010-05-03T11:00:00Z\");\n    indexr(id,4, i1, -100 ,tlong, 101,\n           t1,\"the quick fox jumped over the lazy dog\", \n           tdate_a, \"2010-05-03T11:00:00Z\",\n           tdate_b, \"2010-05-03T11:00:00Z\");\n    indexr(id,5, i1, 500, tlong, 500 ,\n           t1,\"the quick fox jumped way over the lazy dog\", \n           tdate_a, \"2010-05-05T11:00:00Z\");\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,\n           tdate_b, \"2010-01-05T11:00:00Z\",\n           t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n\n    commit();  // try to ensure there's more than one segment\n\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,\n           t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,\n           t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,\n           t1,\"no eggs on wall, lesson learned\", \n           oddField, \"odd man out\");\n\n    indexr(id, \"1001\", \"lowerfilt\", \"toyota\"); // for spellcheck\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n    \n    \n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n\n    handle.clear();\n    handle.put(\"timestamp\", SKIPVAL);\n    handle.put(\"_version_\", SKIPVAL); // not a cloud test, but may use updateLog\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(\"q\",\"*:*\", \"sort\",f+\" desc\");\n      query(\"q\",\"*:*\", \"sort\",f+\" asc\");\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",\"{!func}testfunc(add(\"+i1+\",5))\"+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" asc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\");\n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"*,score\"); \n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 desc\");\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"{!func}\"+i1);// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(\"q\",\"{!func}\"+i1, \"fl\",\"*,score\");  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"quick\");\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\");\n    query(\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\");  // no fields in returned docs\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\");\n\n    handle.put(\"score\", SKIPVAL);\n    query(\"q\",\"quick\",\"fl\",\"*,score\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\");\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"matchesnothing\",\"fl\",\"*,score\");  \n\n    // test that a single NOW value is propagated to all shards... if that is true\n    // then the primary sort should always be a tie and then the secondary should always decide\n    query(\"q\",\"{!func}ms(NOW)\", \"sort\",\"score desc,\"+i1+\" desc\",\"fl\",\"id\");    \n\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1, \"facet.field\",t1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\");\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2);\n\n    // a facet query to test out chars out of the ascii range\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!term f=foo_s}international\\u00ff\\u01ff\\u2222\\u3333\");\n    \n    // simple field facet on date fields\n    rsp = query(\"q\",\"*:*\", \"rows\", 0, \n                \"facet\",\"true\", \"facet.limit\", 1, // TODO: limit shouldn't be needed: SOLR-6386\n                \"facet.field\", tdate_a);\n    assertEquals(1, rsp.getFacetFields().size());\n    rsp = query(\"q\",\"*:*\", \"rows\", 0, \n                \"facet\",\"true\", \"facet.limit\", 1, // TODO: limit shouldn't be needed: SOLR-6386\n                \"facet.field\", tdate_b, \"facet.field\", tdate_a);\n    assertEquals(2, rsp.getFacetFields().size());\n\n    // simple date facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a,\n          \"facet.date\",tdate_a,\n          \"facet.date.other\", \"all\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // date facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a,\n          \"facet.date\",tdate_b,\n          \"facet.date\",tdate_a,\n          \"facet.date.other\", \"all\", \n          \"f.\"+tdate_b+\".facet.date.start\",\"2009-05-01T11:00:00Z\", \n          \"f.\"+tdate_b+\".facet.date.gap\",\"+3MONTHS\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // simple range facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong,\n          \"facet.range\",tlong,\n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"facet.range.end\",900);\n\n    // range facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range\",i1, \n          \"f.\"+i1+\".facet.range.start\",300, \n          \"f.\"+i1+\".facet.range.gap\",87, \n          \"facet.range.end\",900,\n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"f.\"+tlong+\".facet.range.end\",900);\n    \n    //  variations of fl\n    query(\"q\",\"*:*\", \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1 + \",score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", i1, \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id,\" + i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1, \"fl\", \"id\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",nint, \"fl\",tint,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",nint, \"fl\", \"id\", \"fl\",tint,\"sort\",i1 + \" desc\");\n\n    // basic spellcheck testing\n    query(\"q\", \"toyata\", \"fl\", \"id,lowerfilt\", \"spellcheck\", true, \"spellcheck.q\", \"toyata\", \"qt\", \"spellCheckCompRH_Direct\", \"shards.qt\", \"spellCheckCompRH_Direct\");\n\n    stress=0;  // turn off stress... we want to tex max combos in min time\n    for (int i=0; i<25*RANDOM_MULTIPLIER; i++) {\n      String f = fieldNames[random().nextInt(fieldNames.length)];\n      if (random().nextBoolean()) f = t1;  // the text field is a really interesting one to facet on (and it's multi-valued too)\n\n      // we want a random query and not just *:* so we'll get zero counts in facets also\n      // TODO: do a better random query\n      String q = random().nextBoolean() ? \"*:*\" : \"id:(1 3 5 7 9 11 13) OR id:[100 TO \" + random().nextInt(50) + \"]\";\n\n      int nolimit = random().nextBoolean() ? -1 : 10000;  // these should be equivalent\n\n      // if limit==-1, we should always get exact matches\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"count\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      // for index sort, we should get exact results for mincount <= 1\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(2), \"facet.offset\",random().nextInt(10), \"facet.limit\",random().nextInt(11)-1);\n    }\n    stress = backupStress;  // restore stress\n\n    // test faceting multiple things at once\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1);\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id:[1 TO 7]\", \"fq\",\"{!tag=b}id:[3 TO 9]\"\n    );\n    query(\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\");\n\n    // test field that is valid in schema but missing in all shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2);\n    // test field that is valid in schema and missing in some shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2);\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", \"stats_dt\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1);\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", tdate_a);\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", tdate_b);\n\n    handle.put(\"stats_fields\", UNORDERED);\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\",\n          \"stats.field\", \"stats_dt\",\n          \"stats.field\", i1,\n          \"stats.field\", tdate_a,\n          \"stats.field\", tdate_b);\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    // check a complex key name\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"*:*\", \"rows\",100);\n    }\n\n    //SOLR 3161 ensure shards.qt=/update fails (anything but search handler really)\n    // Also see TestRemoteStreaming#testQtUpdateFails()\n    try {\n      ignoreException(\"isShard is only acceptable\");\n      // query(\"q\",\"*:*\",\"shards.qt\",\"/update\",\"stream.body\",\"<delete><query>*:*</query></delete>\");\n      // fail();\n    } catch (SolrException e) {\n      //expected\n    }\n    unIgnoreException(\"isShard is only acceptable\");\n\n    // test debugging\n    // handle.put(\"explain\", UNORDERED);\n    handle.put(\"explain\", SKIPVAL);  // internal docids differ, idf differs w/o global idf\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    handle.put(\"track\", SKIP); //track is not included in single node search\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY);\n\n    // Check Info is added to for each shard\n    ModifiableSolrParams q = new ModifiableSolrParams();\n    q.set(\"q\", \"*:*\");\n    q.set(ShardParams.SHARDS_INFO, true);\n    setDistributedParams(q);\n    rsp = queryServer(q);\n    NamedList<?> sinfo = (NamedList<?>) rsp.getResponse().get(ShardParams.SHARDS_INFO);\n    String shards = getShardsString();\n    int cnt = StringUtils.countMatches(shards, \",\")+1;\n    \n    assertNotNull(\"missing shard info\", sinfo);\n    assertEquals(\"should have an entry for each shard [\"+sinfo+\"] \"+shards, cnt, sinfo.size());\n\n    // test shards.tolerant=true\n    for(int numDownServers = 0; numDownServers < jettys.size()-1; numDownServers++)\n    {\n      List<JettySolrRunner> upJettys = new ArrayList<>(jettys);\n      List<SolrServer> upClients = new ArrayList<>(clients);\n      List<JettySolrRunner> downJettys = new ArrayList<>();\n      List<String> upShards = new ArrayList<>(Arrays.asList(shardsArr));\n      for(int i=0; i<numDownServers; i++)\n      {\n        // shut down some of the jettys\n        int indexToRemove = r.nextInt(upJettys.size());\n        JettySolrRunner downJetty = upJettys.remove(indexToRemove);\n        upClients.remove(indexToRemove);\n        upShards.remove(indexToRemove);\n        ChaosMonkey.stop(downJetty);\n        downJettys.add(downJetty);\n      }\n\n      queryPartialResults(upShards, upClients, \n          \"q\",\"*:*\",\n          \"facet\",\"true\", \n          \"facet.field\",t1,\n          \"facet.field\",t1,\n          \"facet.limit\",5,\n          ShardParams.SHARDS_INFO,\"true\",\n          ShardParams.SHARDS_TOLERANT,\"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"facet\", \"true\",\n          \"facet.query\", i1 + \":[1 TO 50]\",\n          \"facet.query\", i1 + \":[1 TO 50]\",\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      // test group query\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"rows\", 100,\n          \"fl\", \"id,\" + i1,\n          \"group\", \"true\",\n          \"group.query\", t1 + \":kings OR \" + t1 + \":eggs\",\n          \"group.limit\", 10,\n          \"sort\", i1 + \" asc, id asc\",\n          CommonParams.TIME_ALLOWED, 1,\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"stats\", \"true\",\n          \"stats.field\", i1,\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"toyata\",\n          \"spellcheck\", \"true\",\n          \"spellcheck.q\", \"toyata\",\n          \"qt\", \"spellCheckCompRH_Direct\",\n          \"shards.qt\", \"spellCheckCompRH_Direct\",\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      // restart the jettys\n      for (JettySolrRunner downJetty : downJettys) {\n        downJetty.start();\n      }\n    }\n\n    // This index has the same number for every field\n    \n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // Thread.sleep(10000000000L);\n\n    del(\"*:*\"); // delete all docs and test stats request\n    commit();\n    try {\n      query(\"q\", \"*:*\", \"stats\", \"true\", \n            \"stats.field\", \"stats_dt\", \n            \"stats.field\", i1, \n            \"stats.field\", tdate_a, \n            \"stats.field\", tdate_b,\n            \"stats.calcdistinct\", \"true\");\n    } catch (HttpSolrServer.RemoteSolrException e) {\n      if (e.getMessage().startsWith(\"java.lang.NullPointerException\"))  {\n        fail(\"NullPointerException with stats request on empty index\");\n      } else  {\n        throw e;\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"610c97b96420e614c67797fd43822ebc1d4b7ee2","date":1410814832,"type":3,"author":"Chris M. Hostetter","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/TestDistributedSearch#doTest().mjava","pathOld":"solr/core/src/test/org/apache/solr/TestDistributedSearch#doTest().mjava","sourceNew":"  @Override\n  public void doTest() throws Exception {\n    QueryResponse rsp = null;\n    int backupStress = stress; // make a copy so we can restore\n\n\n    del(\"*:*\");\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\",\n           tdate_a, \"2010-04-20T11:00:00Z\",\n           tdate_b, \"2009-08-20T11:00:00Z\",\n           \"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\",\n           tdate_a, \"2010-05-02T11:00:00Z\",\n           tdate_b, \"2009-11-02T11:00:00Z\");\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\",\n           tdate_a, \"2010-05-03T11:00:00Z\");\n    indexr(id,4, i1, -100 ,tlong, 101,\n           t1,\"the quick fox jumped over the lazy dog\", \n           tdate_a, \"2010-05-03T11:00:00Z\",\n           tdate_b, \"2010-05-03T11:00:00Z\");\n    indexr(id,5, i1, 500, tlong, 500 ,\n           t1,\"the quick fox jumped way over the lazy dog\", \n           tdate_a, \"2010-05-05T11:00:00Z\");\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,\n           tdate_b, \"2010-01-05T11:00:00Z\",\n           t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n\n    commit();  // try to ensure there's more than one segment\n\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,\n           t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,\n           t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,\n           t1,\"no eggs on wall, lesson learned\", \n           oddField, \"odd man out\");\n\n    indexr(id, \"1001\", \"lowerfilt\", \"toyota\"); // for spellcheck\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n    \n    \n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n\n    handle.clear();\n    handle.put(\"timestamp\", SKIPVAL);\n    handle.put(\"_version_\", SKIPVAL); // not a cloud test, but may use updateLog\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(\"q\",\"*:*\", \"sort\",f+\" desc\");\n      query(\"q\",\"*:*\", \"sort\",f+\" asc\");\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",\"{!func}testfunc(add(\"+i1+\",5))\"+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" asc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\");\n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"*,score\"); \n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 desc\");\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"{!func}\"+i1);// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(\"q\",\"{!func}\"+i1, \"fl\",\"*,score\");  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"quick\");\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\");\n    query(\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\");  // no fields in returned docs\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\");\n\n    handle.put(\"score\", SKIPVAL);\n    query(\"q\",\"quick\",\"fl\",\"*,score\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\");\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"matchesnothing\",\"fl\",\"*,score\");  \n\n    // test that a single NOW value is propagated to all shards... if that is true\n    // then the primary sort should always be a tie and then the secondary should always decide\n    query(\"q\",\"{!func}ms(NOW)\", \"sort\",\"score desc,\"+i1+\" desc\",\"fl\",\"id\");    \n\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1, \"facet.field\",t1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\");\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2);\n\n    // a facet query to test out chars out of the ascii range\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!term f=foo_s}international\\u00ff\\u01ff\\u2222\\u3333\");\n\n    // simple field facet on date fields\n    rsp = query(\"q\",\"*:*\", \"rows\", 0,\n                \"facet\",\"true\", \"facet.limit\", 1, // TODO: limit shouldn't be needed: SOLR-6386\n                \"facet.field\", tdate_a);\n    assertEquals(1, rsp.getFacetFields().size());\n    rsp = query(\"q\",\"*:*\", \"rows\", 0,\n                \"facet\",\"true\", \"facet.limit\", 1, // TODO: limit shouldn't be needed: SOLR-6386\n                \"facet.field\", tdate_b, \"facet.field\", tdate_a);\n    assertEquals(2, rsp.getFacetFields().size());\n\n    // simple date facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a,\n          \"facet.date\",tdate_a,\n          \"facet.date.other\", \"all\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // date facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a,\n          \"facet.date\",tdate_b,\n          \"facet.date\",tdate_a,\n          \"facet.date.other\", \"all\", \n          \"f.\"+tdate_b+\".facet.date.start\",\"2009-05-01T11:00:00Z\", \n          \"f.\"+tdate_b+\".facet.date.gap\",\"+3MONTHS\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // simple range facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong,\n          \"facet.range\",tlong,\n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"facet.range.end\",900);\n\n    // range facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range\",i1, \n          \"f.\"+i1+\".facet.range.start\",300, \n          \"f.\"+i1+\".facet.range.gap\",87, \n          \"facet.range.end\",900,\n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"f.\"+tlong+\".facet.range.end\",900);\n\n    // Test mincounts. Do NOT want to go through all the stuff where with validateControlData in query() method\n    // Purposely packing a _bunch_ of stuff together here to insure that the proper level of mincount is used for\n    // each\n    ModifiableSolrParams minParams = new ModifiableSolrParams();\n    minParams.set(\"q\",\"*:*\");\n    minParams.set(\"rows\", 1);\n    minParams.set(\"facet\", \"true\");\n    minParams.set(\"facet.missing\", \"true\");\n    minParams.set(\"facet.field\", i1);\n    minParams.set(\"facet.missing\", \"true\");\n    minParams.set(\"facet.mincount\", 2);\n\n    // Return a separate section of ranges over i1. Should respect global range mincount\n    minParams.set(\"facet.range\", i1);\n    minParams.set(\"f.\" + i1 + \".facet.range.start\", 0);\n    minParams.set(\"f.\" + i1 + \".facet.range.gap\", 200);\n    minParams.set(\"f.\" + i1 + \".facet.range.end\", 1200);\n    minParams.set(\"f.\" + i1 + \".facet.mincount\", 4);\n\n\n    // Return a separate section of ranges over tlong Should respect facet.mincount\n    minParams.add(\"facet.range\", tlong);\n    minParams.set(\"f.\" + tlong + \".facet.range.start\", 0);\n    minParams.set(\"f.\" + tlong + \".facet.range.gap\", 100);\n    minParams.set(\"f.\" + tlong + \".facet.range.end\", 1200);\n    // Repeat with a range type of date\n    minParams.add(\"facet.range\", tdate_b);\n    minParams.set(\"f.\" + tdate_b + \".facet.range.start\", \"2009-02-01T00:00:00Z\");\n    minParams.set(\"f.\" + tdate_b + \".facet.range.gap\", \"+1YEAR\");\n    minParams.set(\"f.\" + tdate_b + \".facet.range.end\", \"2011-01-01T00:00:00Z\");\n    minParams.set(\"f.\" + tdate_b + \".facet.mincount\", 3);\n\n    // Insure that global mincount is respected for facet queries\n    minParams.set(\"facet.query\", tdate_a + \":[2010-01-01T00:00:00Z TO 2011-01-01T00:00:00Z]\"); // Should return some counts\n    //minParams.set(\"facet.query\", tdate_a + \":[* TO *]\"); // Should be removed\n    minParams.add(\"facet.query\", tdate_b + \":[2008-01-01T00:00:00Z TO 2009-09-01T00:00:00Z]\"); // Should be removed from response\n\n\n    setDistributedParams(minParams);\n    QueryResponse minResp = queryServer(minParams);\n\n    ModifiableSolrParams eParams = new ModifiableSolrParams();\n    eParams.set(\"q\",tdate_b + \":[* TO *]\");\n    eParams.set(\"rows\", 1000);\n    eParams.set(\"fl\", tdate_b);\n    setDistributedParams(eParams);\n    QueryResponse eResp = queryServer(eParams);\n\n    // Check that exactly the right numbers of counts came through\n    assertEquals(\"Should be exactly 2 range facets returned after minCounts taken into account \", 3, minResp.getFacetRanges().size());\n    assertEquals(\"Should only be 1 query facets returned after minCounts taken into account \", 1, minResp.getFacetQuery().size());\n\n    checkMinCountsField(minResp.getFacetField(i1).getValues(), new Object[]{null, 55L}); // Should just be the null entries for field\n\n    checkMinCountsRange(minResp.getFacetRanges().get(0).getCounts(), new Object[]{\"0\", 5L}); // range on i1\n    checkMinCountsRange(minResp.getFacetRanges().get(1).getCounts(), new Object[]{\"0\", 3L, \"100\", 3L}); // range on tlong\n    checkMinCountsRange(minResp.getFacetRanges().get(2).getCounts(), new Object[]{\"2009-02-01T00:00:00Z\",  3L}); // date (range) on tvh\n\n    assertTrue(\"Should have a facet for tdate_a\", minResp.getFacetQuery().containsKey(\"a_n_tdt:[2010-01-01T00:00:00Z TO 2011-01-01T00:00:00Z]\"));\n    int qCount = minResp.getFacetQuery().get(\"a_n_tdt:[2010-01-01T00:00:00Z TO 2011-01-01T00:00:00Z]\");\n    assertEquals(\"tdate_a should be 5\", qCount, 5);\n\n    // Now let's do some queries, the above is getting too complex\n    minParams = new ModifiableSolrParams();\n    minParams.set(\"q\",\"*:*\");\n    minParams.set(\"rows\", 1);\n    minParams.set(\"facet\", \"true\");\n    minParams.set(\"facet.mincount\", 3);\n\n    minParams.set(\"facet.query\", tdate_a + \":[2010-01-01T00:00:00Z TO 2010-05-04T00:00:00Z]\");\n    minParams.add(\"facet.query\", tdate_b + \":[2009-01-01T00:00:00Z TO 2010-01-01T00:00:00Z]\"); // Should be removed\n    setDistributedParams(minParams);\n    minResp = queryServer(minParams);\n\n    assertEquals(\"Should only be 1 query facets returned after minCounts taken into account \", 1, minResp.getFacetQuery().size());\n    assertTrue(\"Should be an entry for a_n_tdt\", minResp.getFacetQuery().containsKey(\"a_n_tdt:[2010-01-01T00:00:00Z TO 2010-05-04T00:00:00Z]\"));\n    qCount = minResp.getFacetQuery().get(\"a_n_tdt:[2010-01-01T00:00:00Z TO 2010-05-04T00:00:00Z]\");\n    assertEquals(\"a_n_tdt should have a count of 4 \", qCount, 4);\n    //  variations of fl\n    query(\"q\",\"*:*\", \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1 + \",score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", i1, \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id,\" + i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1, \"fl\", \"id\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",nint, \"fl\",tint,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",nint, \"fl\", \"id\", \"fl\",tint,\"sort\",i1 + \" desc\");\n\n    // basic spellcheck testing\n    query(\"q\", \"toyata\", \"fl\", \"id,lowerfilt\", \"spellcheck\", true, \"spellcheck.q\", \"toyata\", \"qt\", \"spellCheckCompRH_Direct\", \"shards.qt\", \"spellCheckCompRH_Direct\");\n\n    stress=0;  // turn off stress... we want to tex max combos in min time\n    for (int i=0; i<25*RANDOM_MULTIPLIER; i++) {\n      String f = fieldNames[random().nextInt(fieldNames.length)];\n      if (random().nextBoolean()) f = t1;  // the text field is a really interesting one to facet on (and it's multi-valued too)\n\n      // we want a random query and not just *:* so we'll get zero counts in facets also\n      // TODO: do a better random query\n      String q = random().nextBoolean() ? \"*:*\" : \"id:(1 3 5 7 9 11 13) OR id:[100 TO \" + random().nextInt(50) + \"]\";\n\n      int nolimit = random().nextBoolean() ? -1 : 10000;  // these should be equivalent\n\n      // if limit==-1, we should always get exact matches\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"count\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      // for index sort, we should get exact results for mincount <= 1\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(2), \"facet.offset\",random().nextInt(10), \"facet.limit\",random().nextInt(11)-1);\n    }\n    stress = backupStress;  // restore stress\n\n    // test faceting multiple things at once\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1);\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id:[1 TO 7]\", \"fq\",\"{!tag=b}id:[3 TO 9]\"\n    );\n    query(\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\");\n\n    // test field that is valid in schema but missing in all shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2);\n    // test field that is valid in schema and missing in some shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2);\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", \"stats_dt\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1);\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", tdate_a);\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", tdate_b);\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \n          \"fq\", \"{!tag=nothing}-*:*\",\n          \"stats.field\", \"{!key=special_key ex=nothing}stats_dt\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \n          \"f.stats_dt.stats.calcdistinct\", \"true\",\n          \"stats.field\", \"{!key=special_key}stats_dt\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \n          \"f.stats_dt.stats.calcdistinct\", \"true\",\n          \"fq\", \"{!tag=xxx}id:[3 TO 9]\",\n          \"stats.field\", \"{!key=special_key}stats_dt\",\n          \"stats.field\", \"{!ex=xxx}stats_dt\");\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\",\n          \"stats.field\", \"stats_dt\",\n          \"stats.field\", i1,\n          \"stats.field\", tdate_a,\n          \"stats.field\", tdate_b);\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    // check a complex key name\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"*:*\", \"rows\",100);\n    }\n\n    //SOLR 3161 ensure shards.qt=/update fails (anything but search handler really)\n    // Also see TestRemoteStreaming#testQtUpdateFails()\n    try {\n      ignoreException(\"isShard is only acceptable\");\n      // query(\"q\",\"*:*\",\"shards.qt\",\"/update\",\"stream.body\",\"<delete><query>*:*</query></delete>\");\n      // fail();\n    } catch (SolrException e) {\n      //expected\n    }\n    unIgnoreException(\"isShard is only acceptable\");\n\n    // test debugging\n    // handle.put(\"explain\", UNORDERED);\n    handle.put(\"explain\", SKIPVAL);  // internal docids differ, idf differs w/o global idf\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    handle.put(\"track\", SKIP); //track is not included in single node search\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY);\n\n    // Check Info is added to for each shard\n    ModifiableSolrParams q = new ModifiableSolrParams();\n    q.set(\"q\", \"*:*\");\n    q.set(ShardParams.SHARDS_INFO, true);\n    setDistributedParams(q);\n    rsp = queryServer(q);\n    NamedList<?> sinfo = (NamedList<?>) rsp.getResponse().get(ShardParams.SHARDS_INFO);\n    String shards = getShardsString();\n    int cnt = StringUtils.countMatches(shards, \",\")+1;\n    \n    assertNotNull(\"missing shard info\", sinfo);\n    assertEquals(\"should have an entry for each shard [\"+sinfo+\"] \"+shards, cnt, sinfo.size());\n\n    // test shards.tolerant=true\n    for(int numDownServers = 0; numDownServers < jettys.size()-1; numDownServers++)\n    {\n      List<JettySolrRunner> upJettys = new ArrayList<>(jettys);\n      List<SolrServer> upClients = new ArrayList<>(clients);\n      List<JettySolrRunner> downJettys = new ArrayList<>();\n      List<String> upShards = new ArrayList<>(Arrays.asList(shardsArr));\n      for(int i=0; i<numDownServers; i++)\n      {\n        // shut down some of the jettys\n        int indexToRemove = r.nextInt(upJettys.size());\n        JettySolrRunner downJetty = upJettys.remove(indexToRemove);\n        upClients.remove(indexToRemove);\n        upShards.remove(indexToRemove);\n        ChaosMonkey.stop(downJetty);\n        downJettys.add(downJetty);\n      }\n\n      queryPartialResults(upShards, upClients, \n          \"q\",\"*:*\",\n          \"facet\",\"true\", \n          \"facet.field\",t1,\n          \"facet.field\",t1,\n          \"facet.limit\",5,\n          ShardParams.SHARDS_INFO,\"true\",\n          ShardParams.SHARDS_TOLERANT,\"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"facet\", \"true\",\n          \"facet.query\", i1 + \":[1 TO 50]\",\n          \"facet.query\", i1 + \":[1 TO 50]\",\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      // test group query\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"rows\", 100,\n          \"fl\", \"id,\" + i1,\n          \"group\", \"true\",\n          \"group.query\", t1 + \":kings OR \" + t1 + \":eggs\",\n          \"group.limit\", 10,\n          \"sort\", i1 + \" asc, id asc\",\n          CommonParams.TIME_ALLOWED, 1,\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"stats\", \"true\",\n          \"stats.field\", i1,\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"toyata\",\n          \"spellcheck\", \"true\",\n          \"spellcheck.q\", \"toyata\",\n          \"qt\", \"spellCheckCompRH_Direct\",\n          \"shards.qt\", \"spellCheckCompRH_Direct\",\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      // restart the jettys\n      for (JettySolrRunner downJetty : downJettys) {\n        downJetty.start();\n      }\n    }\n\n    // This index has the same number for every field\n    \n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // Thread.sleep(10000000000L);\n\n    del(\"*:*\"); // delete all docs and test stats request\n    commit();\n    try {\n      query(\"q\", \"*:*\", \"stats\", \"true\", \n            \"stats.field\", \"stats_dt\", \n            \"stats.field\", i1, \n            \"stats.field\", tdate_a, \n            \"stats.field\", tdate_b,\n            \"stats.calcdistinct\", \"true\");\n    } catch (HttpSolrServer.RemoteSolrException e) {\n      if (e.getMessage().startsWith(\"java.lang.NullPointerException\"))  {\n        fail(\"NullPointerException with stats request on empty index\");\n      } else  {\n        throw e;\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  public void doTest() throws Exception {\n    QueryResponse rsp = null;\n    int backupStress = stress; // make a copy so we can restore\n\n\n    del(\"*:*\");\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\",\n           tdate_a, \"2010-04-20T11:00:00Z\",\n           tdate_b, \"2009-08-20T11:00:00Z\",\n           \"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\",\n           tdate_a, \"2010-05-02T11:00:00Z\",\n           tdate_b, \"2009-11-02T11:00:00Z\");\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\",\n           tdate_a, \"2010-05-03T11:00:00Z\");\n    indexr(id,4, i1, -100 ,tlong, 101,\n           t1,\"the quick fox jumped over the lazy dog\", \n           tdate_a, \"2010-05-03T11:00:00Z\",\n           tdate_b, \"2010-05-03T11:00:00Z\");\n    indexr(id,5, i1, 500, tlong, 500 ,\n           t1,\"the quick fox jumped way over the lazy dog\", \n           tdate_a, \"2010-05-05T11:00:00Z\");\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,\n           tdate_b, \"2010-01-05T11:00:00Z\",\n           t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n\n    commit();  // try to ensure there's more than one segment\n\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,\n           t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,\n           t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,\n           t1,\"no eggs on wall, lesson learned\", \n           oddField, \"odd man out\");\n\n    indexr(id, \"1001\", \"lowerfilt\", \"toyota\"); // for spellcheck\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n    \n    \n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n\n    handle.clear();\n    handle.put(\"timestamp\", SKIPVAL);\n    handle.put(\"_version_\", SKIPVAL); // not a cloud test, but may use updateLog\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(\"q\",\"*:*\", \"sort\",f+\" desc\");\n      query(\"q\",\"*:*\", \"sort\",f+\" asc\");\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",\"{!func}testfunc(add(\"+i1+\",5))\"+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" asc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\");\n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"*,score\"); \n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 desc\");\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"{!func}\"+i1);// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(\"q\",\"{!func}\"+i1, \"fl\",\"*,score\");  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"quick\");\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\");\n    query(\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\");  // no fields in returned docs\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\");\n\n    handle.put(\"score\", SKIPVAL);\n    query(\"q\",\"quick\",\"fl\",\"*,score\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\");\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"matchesnothing\",\"fl\",\"*,score\");  \n\n    // test that a single NOW value is propagated to all shards... if that is true\n    // then the primary sort should always be a tie and then the secondary should always decide\n    query(\"q\",\"{!func}ms(NOW)\", \"sort\",\"score desc,\"+i1+\" desc\",\"fl\",\"id\");    \n\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1, \"facet.field\",t1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\");\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2);\n\n    // a facet query to test out chars out of the ascii range\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!term f=foo_s}international\\u00ff\\u01ff\\u2222\\u3333\");\n\n    // simple field facet on date fields\n    rsp = query(\"q\",\"*:*\", \"rows\", 0,\n                \"facet\",\"true\", \"facet.limit\", 1, // TODO: limit shouldn't be needed: SOLR-6386\n                \"facet.field\", tdate_a);\n    assertEquals(1, rsp.getFacetFields().size());\n    rsp = query(\"q\",\"*:*\", \"rows\", 0,\n                \"facet\",\"true\", \"facet.limit\", 1, // TODO: limit shouldn't be needed: SOLR-6386\n                \"facet.field\", tdate_b, \"facet.field\", tdate_a);\n    assertEquals(2, rsp.getFacetFields().size());\n\n    // simple date facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a,\n          \"facet.date\",tdate_a,\n          \"facet.date.other\", \"all\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // date facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a,\n          \"facet.date\",tdate_b,\n          \"facet.date\",tdate_a,\n          \"facet.date.other\", \"all\", \n          \"f.\"+tdate_b+\".facet.date.start\",\"2009-05-01T11:00:00Z\", \n          \"f.\"+tdate_b+\".facet.date.gap\",\"+3MONTHS\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // simple range facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong,\n          \"facet.range\",tlong,\n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"facet.range.end\",900);\n\n    // range facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range\",i1, \n          \"f.\"+i1+\".facet.range.start\",300, \n          \"f.\"+i1+\".facet.range.gap\",87, \n          \"facet.range.end\",900,\n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"f.\"+tlong+\".facet.range.end\",900);\n\n    // Test mincounts. Do NOT want to go through all the stuff where with validateControlData in query() method\n    // Purposely packing a _bunch_ of stuff together here to insure that the proper level of mincount is used for\n    // each\n    ModifiableSolrParams minParams = new ModifiableSolrParams();\n    minParams.set(\"q\",\"*:*\");\n    minParams.set(\"rows\", 1);\n    minParams.set(\"facet\", \"true\");\n    minParams.set(\"facet.missing\", \"true\");\n    minParams.set(\"facet.field\", i1);\n    minParams.set(\"facet.missing\", \"true\");\n    minParams.set(\"facet.mincount\", 2);\n\n    // Return a separate section of ranges over i1. Should respect global range mincount\n    minParams.set(\"facet.range\", i1);\n    minParams.set(\"f.\" + i1 + \".facet.range.start\", 0);\n    minParams.set(\"f.\" + i1 + \".facet.range.gap\", 200);\n    minParams.set(\"f.\" + i1 + \".facet.range.end\", 1200);\n    minParams.set(\"f.\" + i1 + \".facet.mincount\", 4);\n\n\n    // Return a separate section of ranges over tlong Should respect facet.mincount\n    minParams.add(\"facet.range\", tlong);\n    minParams.set(\"f.\" + tlong + \".facet.range.start\", 0);\n    minParams.set(\"f.\" + tlong + \".facet.range.gap\", 100);\n    minParams.set(\"f.\" + tlong + \".facet.range.end\", 1200);\n    // Repeat with a range type of date\n    minParams.add(\"facet.range\", tdate_b);\n    minParams.set(\"f.\" + tdate_b + \".facet.range.start\", \"2009-02-01T00:00:00Z\");\n    minParams.set(\"f.\" + tdate_b + \".facet.range.gap\", \"+1YEAR\");\n    minParams.set(\"f.\" + tdate_b + \".facet.range.end\", \"2011-01-01T00:00:00Z\");\n    minParams.set(\"f.\" + tdate_b + \".facet.mincount\", 3);\n\n    // Insure that global mincount is respected for facet queries\n    minParams.set(\"facet.query\", tdate_a + \":[2010-01-01T00:00:00Z TO 2011-01-01T00:00:00Z]\"); // Should return some counts\n    //minParams.set(\"facet.query\", tdate_a + \":[* TO *]\"); // Should be removed\n    minParams.add(\"facet.query\", tdate_b + \":[2008-01-01T00:00:00Z TO 2009-09-01T00:00:00Z]\"); // Should be removed from response\n\n\n    setDistributedParams(minParams);\n    QueryResponse minResp = queryServer(minParams);\n\n    ModifiableSolrParams eParams = new ModifiableSolrParams();\n    eParams.set(\"q\",tdate_b + \":[* TO *]\");\n    eParams.set(\"rows\", 1000);\n    eParams.set(\"fl\", tdate_b);\n    setDistributedParams(eParams);\n    QueryResponse eResp = queryServer(eParams);\n\n    // Check that exactly the right numbers of counts came through\n    assertEquals(\"Should be exactly 2 range facets returned after minCounts taken into account \", 3, minResp.getFacetRanges().size());\n    assertEquals(\"Should only be 1 query facets returned after minCounts taken into account \", 1, minResp.getFacetQuery().size());\n\n    checkMinCountsField(minResp.getFacetField(i1).getValues(), new Object[]{null, 55L}); // Should just be the null entries for field\n\n    checkMinCountsRange(minResp.getFacetRanges().get(0).getCounts(), new Object[]{\"0\", 5L}); // range on i1\n    checkMinCountsRange(minResp.getFacetRanges().get(1).getCounts(), new Object[]{\"0\", 3L, \"100\", 3L}); // range on tlong\n    checkMinCountsRange(minResp.getFacetRanges().get(2).getCounts(), new Object[]{\"2009-02-01T00:00:00Z\",  3L}); // date (range) on tvh\n\n    assertTrue(\"Should have a facet for tdate_a\", minResp.getFacetQuery().containsKey(\"a_n_tdt:[2010-01-01T00:00:00Z TO 2011-01-01T00:00:00Z]\"));\n    int qCount = minResp.getFacetQuery().get(\"a_n_tdt:[2010-01-01T00:00:00Z TO 2011-01-01T00:00:00Z]\");\n    assertEquals(\"tdate_a should be 5\", qCount, 5);\n\n    // Now let's do some queries, the above is getting too complex\n    minParams = new ModifiableSolrParams();\n    minParams.set(\"q\",\"*:*\");\n    minParams.set(\"rows\", 1);\n    minParams.set(\"facet\", \"true\");\n    minParams.set(\"facet.mincount\", 3);\n\n    minParams.set(\"facet.query\", tdate_a + \":[2010-01-01T00:00:00Z TO 2010-05-04T00:00:00Z]\");\n    minParams.add(\"facet.query\", tdate_b + \":[2009-01-01T00:00:00Z TO 2010-01-01T00:00:00Z]\"); // Should be removed\n    setDistributedParams(minParams);\n    minResp = queryServer(minParams);\n\n    assertEquals(\"Should only be 1 query facets returned after minCounts taken into account \", 1, minResp.getFacetQuery().size());\n    assertTrue(\"Should be an entry for a_n_tdt\", minResp.getFacetQuery().containsKey(\"a_n_tdt:[2010-01-01T00:00:00Z TO 2010-05-04T00:00:00Z]\"));\n    qCount = minResp.getFacetQuery().get(\"a_n_tdt:[2010-01-01T00:00:00Z TO 2010-05-04T00:00:00Z]\");\n    assertEquals(\"a_n_tdt should have a count of 4 \", qCount, 4);\n    //  variations of fl\n    query(\"q\",\"*:*\", \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1 + \",score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", i1, \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id,\" + i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1, \"fl\", \"id\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",nint, \"fl\",tint,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",nint, \"fl\", \"id\", \"fl\",tint,\"sort\",i1 + \" desc\");\n\n    // basic spellcheck testing\n    query(\"q\", \"toyata\", \"fl\", \"id,lowerfilt\", \"spellcheck\", true, \"spellcheck.q\", \"toyata\", \"qt\", \"spellCheckCompRH_Direct\", \"shards.qt\", \"spellCheckCompRH_Direct\");\n\n    stress=0;  // turn off stress... we want to tex max combos in min time\n    for (int i=0; i<25*RANDOM_MULTIPLIER; i++) {\n      String f = fieldNames[random().nextInt(fieldNames.length)];\n      if (random().nextBoolean()) f = t1;  // the text field is a really interesting one to facet on (and it's multi-valued too)\n\n      // we want a random query and not just *:* so we'll get zero counts in facets also\n      // TODO: do a better random query\n      String q = random().nextBoolean() ? \"*:*\" : \"id:(1 3 5 7 9 11 13) OR id:[100 TO \" + random().nextInt(50) + \"]\";\n\n      int nolimit = random().nextBoolean() ? -1 : 10000;  // these should be equivalent\n\n      // if limit==-1, we should always get exact matches\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"count\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      // for index sort, we should get exact results for mincount <= 1\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(2), \"facet.offset\",random().nextInt(10), \"facet.limit\",random().nextInt(11)-1);\n    }\n    stress = backupStress;  // restore stress\n\n    // test faceting multiple things at once\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1);\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id:[1 TO 7]\", \"fq\",\"{!tag=b}id:[3 TO 9]\"\n    );\n    query(\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\");\n\n    // test field that is valid in schema but missing in all shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2);\n    // test field that is valid in schema and missing in some shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2);\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", \"stats_dt\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1);\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", tdate_a);\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", tdate_b);\n\n    handle.put(\"stats_fields\", UNORDERED);\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\",\n          \"stats.field\", \"stats_dt\",\n          \"stats.field\", i1,\n          \"stats.field\", tdate_a,\n          \"stats.field\", tdate_b);\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    // check a complex key name\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"*:*\", \"rows\",100);\n    }\n\n    //SOLR 3161 ensure shards.qt=/update fails (anything but search handler really)\n    // Also see TestRemoteStreaming#testQtUpdateFails()\n    try {\n      ignoreException(\"isShard is only acceptable\");\n      // query(\"q\",\"*:*\",\"shards.qt\",\"/update\",\"stream.body\",\"<delete><query>*:*</query></delete>\");\n      // fail();\n    } catch (SolrException e) {\n      //expected\n    }\n    unIgnoreException(\"isShard is only acceptable\");\n\n    // test debugging\n    // handle.put(\"explain\", UNORDERED);\n    handle.put(\"explain\", SKIPVAL);  // internal docids differ, idf differs w/o global idf\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    handle.put(\"track\", SKIP); //track is not included in single node search\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY);\n\n    // Check Info is added to for each shard\n    ModifiableSolrParams q = new ModifiableSolrParams();\n    q.set(\"q\", \"*:*\");\n    q.set(ShardParams.SHARDS_INFO, true);\n    setDistributedParams(q);\n    rsp = queryServer(q);\n    NamedList<?> sinfo = (NamedList<?>) rsp.getResponse().get(ShardParams.SHARDS_INFO);\n    String shards = getShardsString();\n    int cnt = StringUtils.countMatches(shards, \",\")+1;\n    \n    assertNotNull(\"missing shard info\", sinfo);\n    assertEquals(\"should have an entry for each shard [\"+sinfo+\"] \"+shards, cnt, sinfo.size());\n\n    // test shards.tolerant=true\n    for(int numDownServers = 0; numDownServers < jettys.size()-1; numDownServers++)\n    {\n      List<JettySolrRunner> upJettys = new ArrayList<>(jettys);\n      List<SolrServer> upClients = new ArrayList<>(clients);\n      List<JettySolrRunner> downJettys = new ArrayList<>();\n      List<String> upShards = new ArrayList<>(Arrays.asList(shardsArr));\n      for(int i=0; i<numDownServers; i++)\n      {\n        // shut down some of the jettys\n        int indexToRemove = r.nextInt(upJettys.size());\n        JettySolrRunner downJetty = upJettys.remove(indexToRemove);\n        upClients.remove(indexToRemove);\n        upShards.remove(indexToRemove);\n        ChaosMonkey.stop(downJetty);\n        downJettys.add(downJetty);\n      }\n\n      queryPartialResults(upShards, upClients, \n          \"q\",\"*:*\",\n          \"facet\",\"true\", \n          \"facet.field\",t1,\n          \"facet.field\",t1,\n          \"facet.limit\",5,\n          ShardParams.SHARDS_INFO,\"true\",\n          ShardParams.SHARDS_TOLERANT,\"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"facet\", \"true\",\n          \"facet.query\", i1 + \":[1 TO 50]\",\n          \"facet.query\", i1 + \":[1 TO 50]\",\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      // test group query\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"rows\", 100,\n          \"fl\", \"id,\" + i1,\n          \"group\", \"true\",\n          \"group.query\", t1 + \":kings OR \" + t1 + \":eggs\",\n          \"group.limit\", 10,\n          \"sort\", i1 + \" asc, id asc\",\n          CommonParams.TIME_ALLOWED, 1,\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"stats\", \"true\",\n          \"stats.field\", i1,\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"toyata\",\n          \"spellcheck\", \"true\",\n          \"spellcheck.q\", \"toyata\",\n          \"qt\", \"spellCheckCompRH_Direct\",\n          \"shards.qt\", \"spellCheckCompRH_Direct\",\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      // restart the jettys\n      for (JettySolrRunner downJetty : downJettys) {\n        downJetty.start();\n      }\n    }\n\n    // This index has the same number for every field\n    \n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // Thread.sleep(10000000000L);\n\n    del(\"*:*\"); // delete all docs and test stats request\n    commit();\n    try {\n      query(\"q\", \"*:*\", \"stats\", \"true\", \n            \"stats.field\", \"stats_dt\", \n            \"stats.field\", i1, \n            \"stats.field\", tdate_a, \n            \"stats.field\", tdate_b,\n            \"stats.calcdistinct\", \"true\");\n    } catch (HttpSolrServer.RemoteSolrException e) {\n      if (e.getMessage().startsWith(\"java.lang.NullPointerException\"))  {\n        fail(\"NullPointerException with stats request on empty index\");\n      } else  {\n        throw e;\n      }\n    }\n  }\n\n","bugFix":["e6a0af6f7a7677267ad84c35bc106a61fd67dc62"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"283ff02f401ec3e7a2fad73643970f052383fb0c","date":1411407953,"type":3,"author":"Chris M. Hostetter","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/TestDistributedSearch#doTest().mjava","pathOld":"solr/core/src/test/org/apache/solr/TestDistributedSearch#doTest().mjava","sourceNew":"  @Override\n  public void doTest() throws Exception {\n    QueryResponse rsp = null;\n    int backupStress = stress; // make a copy so we can restore\n\n\n    del(\"*:*\");\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\",\n           tdate_a, \"2010-04-20T11:00:00Z\",\n           tdate_b, \"2009-08-20T11:00:00Z\",\n           \"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\",\n           tdate_a, \"2010-05-02T11:00:00Z\",\n           tdate_b, \"2009-11-02T11:00:00Z\");\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\",\n           tdate_a, \"2010-05-03T11:00:00Z\");\n    indexr(id,4, i1, -100 ,tlong, 101,\n           t1,\"the quick fox jumped over the lazy dog\", \n           tdate_a, \"2010-05-03T11:00:00Z\",\n           tdate_b, \"2010-05-03T11:00:00Z\");\n    indexr(id,5, i1, 500, tlong, 500 ,\n           t1,\"the quick fox jumped way over the lazy dog\", \n           tdate_a, \"2010-05-05T11:00:00Z\");\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,\n           tdate_b, \"2010-01-05T11:00:00Z\",\n           t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n\n    commit();  // try to ensure there's more than one segment\n\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,\n           t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,\n           t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,\n           t1,\"no eggs on wall, lesson learned\", \n           oddField, \"odd man out\");\n\n    indexr(id, \"1001\", \"lowerfilt\", \"toyota\"); // for spellcheck\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n    \n    \n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n\n    handle.clear();\n    handle.put(\"timestamp\", SKIPVAL);\n    handle.put(\"_version_\", SKIPVAL); // not a cloud test, but may use updateLog\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(\"q\",\"*:*\", \"sort\",f+\" desc\");\n      query(\"q\",\"*:*\", \"sort\",f+\" asc\");\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",\"{!func}testfunc(add(\"+i1+\",5))\"+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" asc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\");\n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"*,score\"); \n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 desc\");\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"{!func}\"+i1);// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(\"q\",\"{!func}\"+i1, \"fl\",\"*,score\");  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"quick\");\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\");\n    query(\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\");  // no fields in returned docs\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\");\n\n    handle.put(\"score\", SKIPVAL);\n    query(\"q\",\"quick\",\"fl\",\"*,score\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\");\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"matchesnothing\",\"fl\",\"*,score\");  \n\n    // test that a single NOW value is propagated to all shards... if that is true\n    // then the primary sort should always be a tie and then the secondary should always decide\n    query(\"q\",\"{!func}ms(NOW)\", \"sort\",\"score desc,\"+i1+\" desc\",\"fl\",\"id\");    \n\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1, \"facet.field\",t1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\");\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2);\n\n    // a facet query to test out chars out of the ascii range\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!term f=foo_s}international\\u00ff\\u01ff\\u2222\\u3333\");\n\n    // simple field facet on date fields\n    rsp = query(\"q\",\"*:*\", \"rows\", 0,\n                \"facet\",\"true\", \"facet.limit\", 1, // TODO: limit shouldn't be needed: SOLR-6386\n                \"facet.field\", tdate_a);\n    assertEquals(1, rsp.getFacetFields().size());\n    rsp = query(\"q\",\"*:*\", \"rows\", 0,\n                \"facet\",\"true\", \"facet.limit\", 1, // TODO: limit shouldn't be needed: SOLR-6386\n                \"facet.field\", tdate_b, \"facet.field\", tdate_a);\n    assertEquals(2, rsp.getFacetFields().size());\n\n    // simple date facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a,\n          \"facet.date\",tdate_a,\n          \"facet.date.other\", \"all\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // date facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a,\n          \"facet.date\",tdate_b,\n          \"facet.date\",tdate_a,\n          \"facet.date.other\", \"all\", \n          \"f.\"+tdate_b+\".facet.date.start\",\"2009-05-01T11:00:00Z\", \n          \"f.\"+tdate_b+\".facet.date.gap\",\"+3MONTHS\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // simple range facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong,\n          \"facet.range\",tlong,\n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"facet.range.end\",900);\n\n    // range facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range\",i1, \n          \"f.\"+i1+\".facet.range.start\",300, \n          \"f.\"+i1+\".facet.range.gap\",87, \n          \"facet.range.end\",900,\n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"f.\"+tlong+\".facet.range.end\",900);\n\n    // Test mincounts. Do NOT want to go through all the stuff where with validateControlData in query() method\n    // Purposely packing a _bunch_ of stuff together here to insure that the proper level of mincount is used for\n    // each\n    ModifiableSolrParams minParams = new ModifiableSolrParams();\n    minParams.set(\"q\",\"*:*\");\n    minParams.set(\"rows\", 1);\n    minParams.set(\"facet\", \"true\");\n    minParams.set(\"facet.missing\", \"true\");\n    minParams.set(\"facet.field\", i1);\n    minParams.set(\"facet.missing\", \"true\");\n    minParams.set(\"facet.mincount\", 2);\n\n    // Return a separate section of ranges over i1. Should respect global range mincount\n    minParams.set(\"facet.range\", i1);\n    minParams.set(\"f.\" + i1 + \".facet.range.start\", 0);\n    minParams.set(\"f.\" + i1 + \".facet.range.gap\", 200);\n    minParams.set(\"f.\" + i1 + \".facet.range.end\", 1200);\n    minParams.set(\"f.\" + i1 + \".facet.mincount\", 4);\n\n\n    // Return a separate section of ranges over tlong Should respect facet.mincount\n    minParams.add(\"facet.range\", tlong);\n    minParams.set(\"f.\" + tlong + \".facet.range.start\", 0);\n    minParams.set(\"f.\" + tlong + \".facet.range.gap\", 100);\n    minParams.set(\"f.\" + tlong + \".facet.range.end\", 1200);\n    // Repeat with a range type of date\n    minParams.add(\"facet.range\", tdate_b);\n    minParams.set(\"f.\" + tdate_b + \".facet.range.start\", \"2009-02-01T00:00:00Z\");\n    minParams.set(\"f.\" + tdate_b + \".facet.range.gap\", \"+1YEAR\");\n    minParams.set(\"f.\" + tdate_b + \".facet.range.end\", \"2011-01-01T00:00:00Z\");\n    minParams.set(\"f.\" + tdate_b + \".facet.mincount\", 3);\n\n    // Insure that global mincount is respected for facet queries\n    minParams.set(\"facet.query\", tdate_a + \":[2010-01-01T00:00:00Z TO 2011-01-01T00:00:00Z]\"); // Should return some counts\n    //minParams.set(\"facet.query\", tdate_a + \":[* TO *]\"); // Should be removed\n    minParams.add(\"facet.query\", tdate_b + \":[2008-01-01T00:00:00Z TO 2009-09-01T00:00:00Z]\"); // Should be removed from response\n\n\n    setDistributedParams(minParams);\n    QueryResponse minResp = queryServer(minParams);\n\n    ModifiableSolrParams eParams = new ModifiableSolrParams();\n    eParams.set(\"q\",tdate_b + \":[* TO *]\");\n    eParams.set(\"rows\", 1000);\n    eParams.set(\"fl\", tdate_b);\n    setDistributedParams(eParams);\n    QueryResponse eResp = queryServer(eParams);\n\n    // Check that exactly the right numbers of counts came through\n    assertEquals(\"Should be exactly 2 range facets returned after minCounts taken into account \", 3, minResp.getFacetRanges().size());\n    assertEquals(\"Should only be 1 query facets returned after minCounts taken into account \", 1, minResp.getFacetQuery().size());\n\n    checkMinCountsField(minResp.getFacetField(i1).getValues(), new Object[]{null, 55L}); // Should just be the null entries for field\n\n    checkMinCountsRange(minResp.getFacetRanges().get(0).getCounts(), new Object[]{\"0\", 5L}); // range on i1\n    checkMinCountsRange(minResp.getFacetRanges().get(1).getCounts(), new Object[]{\"0\", 3L, \"100\", 3L}); // range on tlong\n    checkMinCountsRange(minResp.getFacetRanges().get(2).getCounts(), new Object[]{\"2009-02-01T00:00:00Z\",  3L}); // date (range) on tvh\n\n    assertTrue(\"Should have a facet for tdate_a\", minResp.getFacetQuery().containsKey(\"a_n_tdt:[2010-01-01T00:00:00Z TO 2011-01-01T00:00:00Z]\"));\n    int qCount = minResp.getFacetQuery().get(\"a_n_tdt:[2010-01-01T00:00:00Z TO 2011-01-01T00:00:00Z]\");\n    assertEquals(\"tdate_a should be 5\", qCount, 5);\n\n    // Now let's do some queries, the above is getting too complex\n    minParams = new ModifiableSolrParams();\n    minParams.set(\"q\",\"*:*\");\n    minParams.set(\"rows\", 1);\n    minParams.set(\"facet\", \"true\");\n    minParams.set(\"facet.mincount\", 3);\n\n    minParams.set(\"facet.query\", tdate_a + \":[2010-01-01T00:00:00Z TO 2010-05-04T00:00:00Z]\");\n    minParams.add(\"facet.query\", tdate_b + \":[2009-01-01T00:00:00Z TO 2010-01-01T00:00:00Z]\"); // Should be removed\n    setDistributedParams(minParams);\n    minResp = queryServer(minParams);\n\n    assertEquals(\"Should only be 1 query facets returned after minCounts taken into account \", 1, minResp.getFacetQuery().size());\n    assertTrue(\"Should be an entry for a_n_tdt\", minResp.getFacetQuery().containsKey(\"a_n_tdt:[2010-01-01T00:00:00Z TO 2010-05-04T00:00:00Z]\"));\n    qCount = minResp.getFacetQuery().get(\"a_n_tdt:[2010-01-01T00:00:00Z TO 2010-05-04T00:00:00Z]\");\n    assertEquals(\"a_n_tdt should have a count of 4 \", qCount, 4);\n    //  variations of fl\n    query(\"q\",\"*:*\", \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1 + \",score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", i1, \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id,\" + i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1, \"fl\", \"id\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",nint, \"fl\",tint,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",nint, \"fl\", \"id\", \"fl\",tint,\"sort\",i1 + \" desc\");\n\n    // basic spellcheck testing\n    query(\"q\", \"toyata\", \"fl\", \"id,lowerfilt\", \"spellcheck\", true, \"spellcheck.q\", \"toyata\", \"qt\", \"spellCheckCompRH_Direct\", \"shards.qt\", \"spellCheckCompRH_Direct\");\n\n    stress=0;  // turn off stress... we want to tex max combos in min time\n    for (int i=0; i<25*RANDOM_MULTIPLIER; i++) {\n      String f = fieldNames[random().nextInt(fieldNames.length)];\n      if (random().nextBoolean()) f = t1;  // the text field is a really interesting one to facet on (and it's multi-valued too)\n\n      // we want a random query and not just *:* so we'll get zero counts in facets also\n      // TODO: do a better random query\n      String q = random().nextBoolean() ? \"*:*\" : \"id:(1 3 5 7 9 11 13) OR id:[100 TO \" + random().nextInt(50) + \"]\";\n\n      int nolimit = random().nextBoolean() ? -1 : 10000;  // these should be equivalent\n\n      // if limit==-1, we should always get exact matches\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"count\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      // for index sort, we should get exact results for mincount <= 1\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(2), \"facet.offset\",random().nextInt(10), \"facet.limit\",random().nextInt(11)-1);\n    }\n    stress = backupStress;  // restore stress\n\n    // test faceting multiple things at once\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1);\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id:[1 TO 7]\", \"fq\",\"{!tag=b}id:[3 TO 9]\"\n    );\n    query(\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\");\n\n    // test field that is valid in schema but missing in all shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2);\n    // test field that is valid in schema and missing in some shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2);\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", \"stats_dt\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1);\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", tdate_a);\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", tdate_b);\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \n          \"fq\", \"{!tag=nothing}-*:*\",\n          \"stats.field\", \"{!key=special_key ex=nothing}stats_dt\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \n          \"f.stats_dt.stats.calcdistinct\", \"true\",\n          \"stats.field\", \"{!key=special_key}stats_dt\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \n          \"f.stats_dt.stats.calcdistinct\", \"true\",\n          \"fq\", \"{!tag=xxx}id:[3 TO 9]\",\n          \"stats.field\", \"{!key=special_key}stats_dt\",\n          \"stats.field\", \"{!ex=xxx}stats_dt\");\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\",\n          // do a really simple query so distributed IDF doesn't cause problems\n          // when comparing with control collection\n          \"stats.field\", \"{!lucene key=q_key}\" + i1 + \"foo_b:true\",\n          \"stats.field\", \"{!func key=f_key}sum(\" + tlong +\",\"+i1+\")\");\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\",\n          \"stats.field\", \"stats_dt\",\n          \"stats.field\", i1,\n          \"stats.field\", tdate_a,\n          \"stats.field\", tdate_b);\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    // check a complex key name\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"*:*\", \"rows\",100);\n    }\n\n    //SOLR 3161 ensure shards.qt=/update fails (anything but search handler really)\n    // Also see TestRemoteStreaming#testQtUpdateFails()\n    try {\n      ignoreException(\"isShard is only acceptable\");\n      // query(\"q\",\"*:*\",\"shards.qt\",\"/update\",\"stream.body\",\"<delete><query>*:*</query></delete>\");\n      // fail();\n    } catch (SolrException e) {\n      //expected\n    }\n    unIgnoreException(\"isShard is only acceptable\");\n\n    // test debugging\n    // handle.put(\"explain\", UNORDERED);\n    handle.put(\"explain\", SKIPVAL);  // internal docids differ, idf differs w/o global idf\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    handle.put(\"track\", SKIP); //track is not included in single node search\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY);\n\n    // Check Info is added to for each shard\n    ModifiableSolrParams q = new ModifiableSolrParams();\n    q.set(\"q\", \"*:*\");\n    q.set(ShardParams.SHARDS_INFO, true);\n    setDistributedParams(q);\n    rsp = queryServer(q);\n    NamedList<?> sinfo = (NamedList<?>) rsp.getResponse().get(ShardParams.SHARDS_INFO);\n    String shards = getShardsString();\n    int cnt = StringUtils.countMatches(shards, \",\")+1;\n    \n    assertNotNull(\"missing shard info\", sinfo);\n    assertEquals(\"should have an entry for each shard [\"+sinfo+\"] \"+shards, cnt, sinfo.size());\n\n    // test shards.tolerant=true\n    for(int numDownServers = 0; numDownServers < jettys.size()-1; numDownServers++)\n    {\n      List<JettySolrRunner> upJettys = new ArrayList<>(jettys);\n      List<SolrServer> upClients = new ArrayList<>(clients);\n      List<JettySolrRunner> downJettys = new ArrayList<>();\n      List<String> upShards = new ArrayList<>(Arrays.asList(shardsArr));\n      for(int i=0; i<numDownServers; i++)\n      {\n        // shut down some of the jettys\n        int indexToRemove = r.nextInt(upJettys.size());\n        JettySolrRunner downJetty = upJettys.remove(indexToRemove);\n        upClients.remove(indexToRemove);\n        upShards.remove(indexToRemove);\n        ChaosMonkey.stop(downJetty);\n        downJettys.add(downJetty);\n      }\n\n      queryPartialResults(upShards, upClients, \n          \"q\",\"*:*\",\n          \"facet\",\"true\", \n          \"facet.field\",t1,\n          \"facet.field\",t1,\n          \"facet.limit\",5,\n          ShardParams.SHARDS_INFO,\"true\",\n          ShardParams.SHARDS_TOLERANT,\"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"facet\", \"true\",\n          \"facet.query\", i1 + \":[1 TO 50]\",\n          \"facet.query\", i1 + \":[1 TO 50]\",\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      // test group query\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"rows\", 100,\n          \"fl\", \"id,\" + i1,\n          \"group\", \"true\",\n          \"group.query\", t1 + \":kings OR \" + t1 + \":eggs\",\n          \"group.limit\", 10,\n          \"sort\", i1 + \" asc, id asc\",\n          CommonParams.TIME_ALLOWED, 1,\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"stats\", \"true\",\n          \"stats.field\", i1,\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"toyata\",\n          \"spellcheck\", \"true\",\n          \"spellcheck.q\", \"toyata\",\n          \"qt\", \"spellCheckCompRH_Direct\",\n          \"shards.qt\", \"spellCheckCompRH_Direct\",\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      // restart the jettys\n      for (JettySolrRunner downJetty : downJettys) {\n        downJetty.start();\n      }\n    }\n\n    // This index has the same number for every field\n    \n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // Thread.sleep(10000000000L);\n\n    del(\"*:*\"); // delete all docs and test stats request\n    commit();\n    try {\n      query(\"q\", \"*:*\", \"stats\", \"true\", \n            \"stats.field\", \"stats_dt\", \n            \"stats.field\", i1, \n            \"stats.field\", tdate_a, \n            \"stats.field\", tdate_b,\n            \"stats.calcdistinct\", \"true\");\n    } catch (HttpSolrServer.RemoteSolrException e) {\n      if (e.getMessage().startsWith(\"java.lang.NullPointerException\"))  {\n        fail(\"NullPointerException with stats request on empty index\");\n      } else  {\n        throw e;\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  public void doTest() throws Exception {\n    QueryResponse rsp = null;\n    int backupStress = stress; // make a copy so we can restore\n\n\n    del(\"*:*\");\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\",\n           tdate_a, \"2010-04-20T11:00:00Z\",\n           tdate_b, \"2009-08-20T11:00:00Z\",\n           \"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\",\n           tdate_a, \"2010-05-02T11:00:00Z\",\n           tdate_b, \"2009-11-02T11:00:00Z\");\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\",\n           tdate_a, \"2010-05-03T11:00:00Z\");\n    indexr(id,4, i1, -100 ,tlong, 101,\n           t1,\"the quick fox jumped over the lazy dog\", \n           tdate_a, \"2010-05-03T11:00:00Z\",\n           tdate_b, \"2010-05-03T11:00:00Z\");\n    indexr(id,5, i1, 500, tlong, 500 ,\n           t1,\"the quick fox jumped way over the lazy dog\", \n           tdate_a, \"2010-05-05T11:00:00Z\");\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,\n           tdate_b, \"2010-01-05T11:00:00Z\",\n           t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n\n    commit();  // try to ensure there's more than one segment\n\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,\n           t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,\n           t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,\n           t1,\"no eggs on wall, lesson learned\", \n           oddField, \"odd man out\");\n\n    indexr(id, \"1001\", \"lowerfilt\", \"toyota\"); // for spellcheck\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n    \n    \n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n\n    handle.clear();\n    handle.put(\"timestamp\", SKIPVAL);\n    handle.put(\"_version_\", SKIPVAL); // not a cloud test, but may use updateLog\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(\"q\",\"*:*\", \"sort\",f+\" desc\");\n      query(\"q\",\"*:*\", \"sort\",f+\" asc\");\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",\"{!func}testfunc(add(\"+i1+\",5))\"+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" asc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\");\n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"*,score\"); \n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 desc\");\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"{!func}\"+i1);// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(\"q\",\"{!func}\"+i1, \"fl\",\"*,score\");  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"quick\");\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\");\n    query(\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\");  // no fields in returned docs\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\");\n\n    handle.put(\"score\", SKIPVAL);\n    query(\"q\",\"quick\",\"fl\",\"*,score\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\");\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"matchesnothing\",\"fl\",\"*,score\");  \n\n    // test that a single NOW value is propagated to all shards... if that is true\n    // then the primary sort should always be a tie and then the secondary should always decide\n    query(\"q\",\"{!func}ms(NOW)\", \"sort\",\"score desc,\"+i1+\" desc\",\"fl\",\"id\");    \n\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1, \"facet.field\",t1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\");\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2);\n\n    // a facet query to test out chars out of the ascii range\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!term f=foo_s}international\\u00ff\\u01ff\\u2222\\u3333\");\n\n    // simple field facet on date fields\n    rsp = query(\"q\",\"*:*\", \"rows\", 0,\n                \"facet\",\"true\", \"facet.limit\", 1, // TODO: limit shouldn't be needed: SOLR-6386\n                \"facet.field\", tdate_a);\n    assertEquals(1, rsp.getFacetFields().size());\n    rsp = query(\"q\",\"*:*\", \"rows\", 0,\n                \"facet\",\"true\", \"facet.limit\", 1, // TODO: limit shouldn't be needed: SOLR-6386\n                \"facet.field\", tdate_b, \"facet.field\", tdate_a);\n    assertEquals(2, rsp.getFacetFields().size());\n\n    // simple date facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a,\n          \"facet.date\",tdate_a,\n          \"facet.date.other\", \"all\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // date facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a,\n          \"facet.date\",tdate_b,\n          \"facet.date\",tdate_a,\n          \"facet.date.other\", \"all\", \n          \"f.\"+tdate_b+\".facet.date.start\",\"2009-05-01T11:00:00Z\", \n          \"f.\"+tdate_b+\".facet.date.gap\",\"+3MONTHS\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // simple range facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong,\n          \"facet.range\",tlong,\n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"facet.range.end\",900);\n\n    // range facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range\",i1, \n          \"f.\"+i1+\".facet.range.start\",300, \n          \"f.\"+i1+\".facet.range.gap\",87, \n          \"facet.range.end\",900,\n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"f.\"+tlong+\".facet.range.end\",900);\n\n    // Test mincounts. Do NOT want to go through all the stuff where with validateControlData in query() method\n    // Purposely packing a _bunch_ of stuff together here to insure that the proper level of mincount is used for\n    // each\n    ModifiableSolrParams minParams = new ModifiableSolrParams();\n    minParams.set(\"q\",\"*:*\");\n    minParams.set(\"rows\", 1);\n    minParams.set(\"facet\", \"true\");\n    minParams.set(\"facet.missing\", \"true\");\n    minParams.set(\"facet.field\", i1);\n    minParams.set(\"facet.missing\", \"true\");\n    minParams.set(\"facet.mincount\", 2);\n\n    // Return a separate section of ranges over i1. Should respect global range mincount\n    minParams.set(\"facet.range\", i1);\n    minParams.set(\"f.\" + i1 + \".facet.range.start\", 0);\n    minParams.set(\"f.\" + i1 + \".facet.range.gap\", 200);\n    minParams.set(\"f.\" + i1 + \".facet.range.end\", 1200);\n    minParams.set(\"f.\" + i1 + \".facet.mincount\", 4);\n\n\n    // Return a separate section of ranges over tlong Should respect facet.mincount\n    minParams.add(\"facet.range\", tlong);\n    minParams.set(\"f.\" + tlong + \".facet.range.start\", 0);\n    minParams.set(\"f.\" + tlong + \".facet.range.gap\", 100);\n    minParams.set(\"f.\" + tlong + \".facet.range.end\", 1200);\n    // Repeat with a range type of date\n    minParams.add(\"facet.range\", tdate_b);\n    minParams.set(\"f.\" + tdate_b + \".facet.range.start\", \"2009-02-01T00:00:00Z\");\n    minParams.set(\"f.\" + tdate_b + \".facet.range.gap\", \"+1YEAR\");\n    minParams.set(\"f.\" + tdate_b + \".facet.range.end\", \"2011-01-01T00:00:00Z\");\n    minParams.set(\"f.\" + tdate_b + \".facet.mincount\", 3);\n\n    // Insure that global mincount is respected for facet queries\n    minParams.set(\"facet.query\", tdate_a + \":[2010-01-01T00:00:00Z TO 2011-01-01T00:00:00Z]\"); // Should return some counts\n    //minParams.set(\"facet.query\", tdate_a + \":[* TO *]\"); // Should be removed\n    minParams.add(\"facet.query\", tdate_b + \":[2008-01-01T00:00:00Z TO 2009-09-01T00:00:00Z]\"); // Should be removed from response\n\n\n    setDistributedParams(minParams);\n    QueryResponse minResp = queryServer(minParams);\n\n    ModifiableSolrParams eParams = new ModifiableSolrParams();\n    eParams.set(\"q\",tdate_b + \":[* TO *]\");\n    eParams.set(\"rows\", 1000);\n    eParams.set(\"fl\", tdate_b);\n    setDistributedParams(eParams);\n    QueryResponse eResp = queryServer(eParams);\n\n    // Check that exactly the right numbers of counts came through\n    assertEquals(\"Should be exactly 2 range facets returned after minCounts taken into account \", 3, minResp.getFacetRanges().size());\n    assertEquals(\"Should only be 1 query facets returned after minCounts taken into account \", 1, minResp.getFacetQuery().size());\n\n    checkMinCountsField(minResp.getFacetField(i1).getValues(), new Object[]{null, 55L}); // Should just be the null entries for field\n\n    checkMinCountsRange(minResp.getFacetRanges().get(0).getCounts(), new Object[]{\"0\", 5L}); // range on i1\n    checkMinCountsRange(minResp.getFacetRanges().get(1).getCounts(), new Object[]{\"0\", 3L, \"100\", 3L}); // range on tlong\n    checkMinCountsRange(minResp.getFacetRanges().get(2).getCounts(), new Object[]{\"2009-02-01T00:00:00Z\",  3L}); // date (range) on tvh\n\n    assertTrue(\"Should have a facet for tdate_a\", minResp.getFacetQuery().containsKey(\"a_n_tdt:[2010-01-01T00:00:00Z TO 2011-01-01T00:00:00Z]\"));\n    int qCount = minResp.getFacetQuery().get(\"a_n_tdt:[2010-01-01T00:00:00Z TO 2011-01-01T00:00:00Z]\");\n    assertEquals(\"tdate_a should be 5\", qCount, 5);\n\n    // Now let's do some queries, the above is getting too complex\n    minParams = new ModifiableSolrParams();\n    minParams.set(\"q\",\"*:*\");\n    minParams.set(\"rows\", 1);\n    minParams.set(\"facet\", \"true\");\n    minParams.set(\"facet.mincount\", 3);\n\n    minParams.set(\"facet.query\", tdate_a + \":[2010-01-01T00:00:00Z TO 2010-05-04T00:00:00Z]\");\n    minParams.add(\"facet.query\", tdate_b + \":[2009-01-01T00:00:00Z TO 2010-01-01T00:00:00Z]\"); // Should be removed\n    setDistributedParams(minParams);\n    minResp = queryServer(minParams);\n\n    assertEquals(\"Should only be 1 query facets returned after minCounts taken into account \", 1, minResp.getFacetQuery().size());\n    assertTrue(\"Should be an entry for a_n_tdt\", minResp.getFacetQuery().containsKey(\"a_n_tdt:[2010-01-01T00:00:00Z TO 2010-05-04T00:00:00Z]\"));\n    qCount = minResp.getFacetQuery().get(\"a_n_tdt:[2010-01-01T00:00:00Z TO 2010-05-04T00:00:00Z]\");\n    assertEquals(\"a_n_tdt should have a count of 4 \", qCount, 4);\n    //  variations of fl\n    query(\"q\",\"*:*\", \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1 + \",score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", i1, \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id,\" + i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1, \"fl\", \"id\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",nint, \"fl\",tint,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",nint, \"fl\", \"id\", \"fl\",tint,\"sort\",i1 + \" desc\");\n\n    // basic spellcheck testing\n    query(\"q\", \"toyata\", \"fl\", \"id,lowerfilt\", \"spellcheck\", true, \"spellcheck.q\", \"toyata\", \"qt\", \"spellCheckCompRH_Direct\", \"shards.qt\", \"spellCheckCompRH_Direct\");\n\n    stress=0;  // turn off stress... we want to tex max combos in min time\n    for (int i=0; i<25*RANDOM_MULTIPLIER; i++) {\n      String f = fieldNames[random().nextInt(fieldNames.length)];\n      if (random().nextBoolean()) f = t1;  // the text field is a really interesting one to facet on (and it's multi-valued too)\n\n      // we want a random query and not just *:* so we'll get zero counts in facets also\n      // TODO: do a better random query\n      String q = random().nextBoolean() ? \"*:*\" : \"id:(1 3 5 7 9 11 13) OR id:[100 TO \" + random().nextInt(50) + \"]\";\n\n      int nolimit = random().nextBoolean() ? -1 : 10000;  // these should be equivalent\n\n      // if limit==-1, we should always get exact matches\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"count\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      // for index sort, we should get exact results for mincount <= 1\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(2), \"facet.offset\",random().nextInt(10), \"facet.limit\",random().nextInt(11)-1);\n    }\n    stress = backupStress;  // restore stress\n\n    // test faceting multiple things at once\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1);\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id:[1 TO 7]\", \"fq\",\"{!tag=b}id:[3 TO 9]\"\n    );\n    query(\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\");\n\n    // test field that is valid in schema but missing in all shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2);\n    // test field that is valid in schema and missing in some shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2);\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", \"stats_dt\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1);\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", tdate_a);\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", tdate_b);\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \n          \"fq\", \"{!tag=nothing}-*:*\",\n          \"stats.field\", \"{!key=special_key ex=nothing}stats_dt\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \n          \"f.stats_dt.stats.calcdistinct\", \"true\",\n          \"stats.field\", \"{!key=special_key}stats_dt\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \n          \"f.stats_dt.stats.calcdistinct\", \"true\",\n          \"fq\", \"{!tag=xxx}id:[3 TO 9]\",\n          \"stats.field\", \"{!key=special_key}stats_dt\",\n          \"stats.field\", \"{!ex=xxx}stats_dt\");\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\",\n          \"stats.field\", \"stats_dt\",\n          \"stats.field\", i1,\n          \"stats.field\", tdate_a,\n          \"stats.field\", tdate_b);\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    // check a complex key name\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"*:*\", \"rows\",100);\n    }\n\n    //SOLR 3161 ensure shards.qt=/update fails (anything but search handler really)\n    // Also see TestRemoteStreaming#testQtUpdateFails()\n    try {\n      ignoreException(\"isShard is only acceptable\");\n      // query(\"q\",\"*:*\",\"shards.qt\",\"/update\",\"stream.body\",\"<delete><query>*:*</query></delete>\");\n      // fail();\n    } catch (SolrException e) {\n      //expected\n    }\n    unIgnoreException(\"isShard is only acceptable\");\n\n    // test debugging\n    // handle.put(\"explain\", UNORDERED);\n    handle.put(\"explain\", SKIPVAL);  // internal docids differ, idf differs w/o global idf\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    handle.put(\"track\", SKIP); //track is not included in single node search\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY);\n\n    // Check Info is added to for each shard\n    ModifiableSolrParams q = new ModifiableSolrParams();\n    q.set(\"q\", \"*:*\");\n    q.set(ShardParams.SHARDS_INFO, true);\n    setDistributedParams(q);\n    rsp = queryServer(q);\n    NamedList<?> sinfo = (NamedList<?>) rsp.getResponse().get(ShardParams.SHARDS_INFO);\n    String shards = getShardsString();\n    int cnt = StringUtils.countMatches(shards, \",\")+1;\n    \n    assertNotNull(\"missing shard info\", sinfo);\n    assertEquals(\"should have an entry for each shard [\"+sinfo+\"] \"+shards, cnt, sinfo.size());\n\n    // test shards.tolerant=true\n    for(int numDownServers = 0; numDownServers < jettys.size()-1; numDownServers++)\n    {\n      List<JettySolrRunner> upJettys = new ArrayList<>(jettys);\n      List<SolrServer> upClients = new ArrayList<>(clients);\n      List<JettySolrRunner> downJettys = new ArrayList<>();\n      List<String> upShards = new ArrayList<>(Arrays.asList(shardsArr));\n      for(int i=0; i<numDownServers; i++)\n      {\n        // shut down some of the jettys\n        int indexToRemove = r.nextInt(upJettys.size());\n        JettySolrRunner downJetty = upJettys.remove(indexToRemove);\n        upClients.remove(indexToRemove);\n        upShards.remove(indexToRemove);\n        ChaosMonkey.stop(downJetty);\n        downJettys.add(downJetty);\n      }\n\n      queryPartialResults(upShards, upClients, \n          \"q\",\"*:*\",\n          \"facet\",\"true\", \n          \"facet.field\",t1,\n          \"facet.field\",t1,\n          \"facet.limit\",5,\n          ShardParams.SHARDS_INFO,\"true\",\n          ShardParams.SHARDS_TOLERANT,\"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"facet\", \"true\",\n          \"facet.query\", i1 + \":[1 TO 50]\",\n          \"facet.query\", i1 + \":[1 TO 50]\",\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      // test group query\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"rows\", 100,\n          \"fl\", \"id,\" + i1,\n          \"group\", \"true\",\n          \"group.query\", t1 + \":kings OR \" + t1 + \":eggs\",\n          \"group.limit\", 10,\n          \"sort\", i1 + \" asc, id asc\",\n          CommonParams.TIME_ALLOWED, 1,\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"stats\", \"true\",\n          \"stats.field\", i1,\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"toyata\",\n          \"spellcheck\", \"true\",\n          \"spellcheck.q\", \"toyata\",\n          \"qt\", \"spellCheckCompRH_Direct\",\n          \"shards.qt\", \"spellCheckCompRH_Direct\",\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      // restart the jettys\n      for (JettySolrRunner downJetty : downJettys) {\n        downJetty.start();\n      }\n    }\n\n    // This index has the same number for every field\n    \n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // Thread.sleep(10000000000L);\n\n    del(\"*:*\"); // delete all docs and test stats request\n    commit();\n    try {\n      query(\"q\", \"*:*\", \"stats\", \"true\", \n            \"stats.field\", \"stats_dt\", \n            \"stats.field\", i1, \n            \"stats.field\", tdate_a, \n            \"stats.field\", tdate_b,\n            \"stats.calcdistinct\", \"true\");\n    } catch (HttpSolrServer.RemoteSolrException e) {\n      if (e.getMessage().startsWith(\"java.lang.NullPointerException\"))  {\n        fail(\"NullPointerException with stats request on empty index\");\n      } else  {\n        throw e;\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"eb9e4cb185078b4e99e3b7070abb77eb2cdfaf6e","date":1411674127,"type":3,"author":"Anshum Gupta","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/TestDistributedSearch#doTest().mjava","pathOld":"solr/core/src/test/org/apache/solr/TestDistributedSearch#doTest().mjava","sourceNew":"  @Override\n  public void doTest() throws Exception {\n    QueryResponse rsp = null;\n    int backupStress = stress; // make a copy so we can restore\n\n\n    del(\"*:*\");\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\",\n           tdate_a, \"2010-04-20T11:00:00Z\",\n           tdate_b, \"2009-08-20T11:00:00Z\",\n           \"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\",\n           tdate_a, \"2010-05-02T11:00:00Z\",\n           tdate_b, \"2009-11-02T11:00:00Z\");\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\",\n           tdate_a, \"2010-05-03T11:00:00Z\");\n    indexr(id,4, i1, -100 ,tlong, 101,\n           t1,\"the quick fox jumped over the lazy dog\", \n           tdate_a, \"2010-05-03T11:00:00Z\",\n           tdate_b, \"2010-05-03T11:00:00Z\");\n    indexr(id,5, i1, 500, tlong, 500 ,\n           t1,\"the quick fox jumped way over the lazy dog\", \n           tdate_a, \"2010-05-05T11:00:00Z\");\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,\n           tdate_b, \"2010-01-05T11:00:00Z\",\n           t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n\n    commit();  // try to ensure there's more than one segment\n\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,\n           t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,\n           t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,\n           t1,\"no eggs on wall, lesson learned\", \n           oddField, \"odd man out\");\n\n    indexr(id, \"1001\", \"lowerfilt\", \"toyota\"); // for spellcheck\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n    \n    \n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n\n    handle.clear();\n    handle.put(\"timestamp\", SKIPVAL);\n    handle.put(\"_version_\", SKIPVAL); // not a cloud test, but may use updateLog\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(\"q\",\"*:*\", \"sort\",f+\" desc\");\n      query(\"q\",\"*:*\", \"sort\",f+\" asc\");\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",\"{!func}testfunc(add(\"+i1+\",5))\"+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" asc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\");\n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"*,score\"); \n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 desc\");\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"{!func}\"+i1);// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(\"q\",\"{!func}\"+i1, \"fl\",\"*,score\");  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"quick\");\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\");\n    query(\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\");  // no fields in returned docs\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\");\n\n    handle.put(\"score\", SKIPVAL);\n    query(\"q\",\"quick\",\"fl\",\"*,score\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\");\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"matchesnothing\",\"fl\",\"*,score\");  \n\n    // test that a single NOW value is propagated to all shards... if that is true\n    // then the primary sort should always be a tie and then the secondary should always decide\n    query(\"q\",\"{!func}ms(NOW)\", \"sort\",\"score desc,\"+i1+\" desc\",\"fl\",\"id\");    \n\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1, \"facet.field\",t1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\");\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2);\n\n    // a facet query to test out chars out of the ascii range\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!term f=foo_s}international\\u00ff\\u01ff\\u2222\\u3333\");\n\n    // simple field facet on date fields\n    rsp = query(\"q\",\"*:*\", \"rows\", 0,\n                \"facet\",\"true\", \"facet.limit\", 1, // TODO: limit shouldn't be needed: SOLR-6386\n                \"facet.field\", tdate_a);\n    assertEquals(1, rsp.getFacetFields().size());\n    rsp = query(\"q\",\"*:*\", \"rows\", 0,\n                \"facet\",\"true\", \"facet.limit\", 1, // TODO: limit shouldn't be needed: SOLR-6386\n                \"facet.field\", tdate_b, \"facet.field\", tdate_a);\n    assertEquals(2, rsp.getFacetFields().size());\n\n    // simple date facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a,\n          \"facet.date\",tdate_a,\n          \"facet.date.other\", \"all\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // date facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a,\n          \"facet.date\",tdate_b,\n          \"facet.date\",tdate_a,\n          \"facet.date.other\", \"all\", \n          \"f.\"+tdate_b+\".facet.date.start\",\"2009-05-01T11:00:00Z\", \n          \"f.\"+tdate_b+\".facet.date.gap\",\"+3MONTHS\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // simple range facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong,\n          \"facet.range\",tlong,\n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"facet.range.end\",900);\n\n    // range facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range\",i1, \n          \"f.\"+i1+\".facet.range.start\",300, \n          \"f.\"+i1+\".facet.range.gap\",87, \n          \"facet.range.end\",900,\n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"f.\"+tlong+\".facet.range.end\",900);\n\n    // Test mincounts. Do NOT want to go through all the stuff where with validateControlData in query() method\n    // Purposely packing a _bunch_ of stuff together here to insure that the proper level of mincount is used for\n    // each\n    ModifiableSolrParams minParams = new ModifiableSolrParams();\n    minParams.set(\"q\",\"*:*\");\n    minParams.set(\"rows\", 1);\n    minParams.set(\"facet\", \"true\");\n    minParams.set(\"facet.missing\", \"true\");\n    minParams.set(\"facet.field\", i1);\n    minParams.set(\"facet.missing\", \"true\");\n    minParams.set(\"facet.mincount\", 2);\n\n    // Return a separate section of ranges over i1. Should respect global range mincount\n    minParams.set(\"facet.range\", i1);\n    minParams.set(\"f.\" + i1 + \".facet.range.start\", 0);\n    minParams.set(\"f.\" + i1 + \".facet.range.gap\", 200);\n    minParams.set(\"f.\" + i1 + \".facet.range.end\", 1200);\n    minParams.set(\"f.\" + i1 + \".facet.mincount\", 4);\n\n\n    // Return a separate section of ranges over tlong Should respect facet.mincount\n    minParams.add(\"facet.range\", tlong);\n    minParams.set(\"f.\" + tlong + \".facet.range.start\", 0);\n    minParams.set(\"f.\" + tlong + \".facet.range.gap\", 100);\n    minParams.set(\"f.\" + tlong + \".facet.range.end\", 1200);\n    // Repeat with a range type of date\n    minParams.add(\"facet.range\", tdate_b);\n    minParams.set(\"f.\" + tdate_b + \".facet.range.start\", \"2009-02-01T00:00:00Z\");\n    minParams.set(\"f.\" + tdate_b + \".facet.range.gap\", \"+1YEAR\");\n    minParams.set(\"f.\" + tdate_b + \".facet.range.end\", \"2011-01-01T00:00:00Z\");\n    minParams.set(\"f.\" + tdate_b + \".facet.mincount\", 3);\n\n    // Insure that global mincount is respected for facet queries\n    minParams.set(\"facet.query\", tdate_a + \":[2010-01-01T00:00:00Z TO 2011-01-01T00:00:00Z]\"); // Should return some counts\n    //minParams.set(\"facet.query\", tdate_a + \":[* TO *]\"); // Should be removed\n    minParams.add(\"facet.query\", tdate_b + \":[2008-01-01T00:00:00Z TO 2009-09-01T00:00:00Z]\"); // Should be removed from response\n\n\n    setDistributedParams(minParams);\n    QueryResponse minResp = queryServer(minParams);\n\n    ModifiableSolrParams eParams = new ModifiableSolrParams();\n    eParams.set(\"q\",tdate_b + \":[* TO *]\");\n    eParams.set(\"rows\", 1000);\n    eParams.set(\"fl\", tdate_b);\n    setDistributedParams(eParams);\n    QueryResponse eResp = queryServer(eParams);\n\n    // Check that exactly the right numbers of counts came through\n    assertEquals(\"Should be exactly 2 range facets returned after minCounts taken into account \", 3, minResp.getFacetRanges().size());\n    assertEquals(\"Should only be 1 query facets returned after minCounts taken into account \", 1, minResp.getFacetQuery().size());\n\n    checkMinCountsField(minResp.getFacetField(i1).getValues(), new Object[]{null, 55L}); // Should just be the null entries for field\n\n    checkMinCountsRange(minResp.getFacetRanges().get(0).getCounts(), new Object[]{\"0\", 5L}); // range on i1\n    checkMinCountsRange(minResp.getFacetRanges().get(1).getCounts(), new Object[]{\"0\", 3L, \"100\", 3L}); // range on tlong\n    checkMinCountsRange(minResp.getFacetRanges().get(2).getCounts(), new Object[]{\"2009-02-01T00:00:00Z\",  3L}); // date (range) on tvh\n\n    assertTrue(\"Should have a facet for tdate_a\", minResp.getFacetQuery().containsKey(\"a_n_tdt:[2010-01-01T00:00:00Z TO 2011-01-01T00:00:00Z]\"));\n    int qCount = minResp.getFacetQuery().get(\"a_n_tdt:[2010-01-01T00:00:00Z TO 2011-01-01T00:00:00Z]\");\n    assertEquals(\"tdate_a should be 5\", qCount, 5);\n\n    // Now let's do some queries, the above is getting too complex\n    minParams = new ModifiableSolrParams();\n    minParams.set(\"q\",\"*:*\");\n    minParams.set(\"rows\", 1);\n    minParams.set(\"facet\", \"true\");\n    minParams.set(\"facet.mincount\", 3);\n\n    minParams.set(\"facet.query\", tdate_a + \":[2010-01-01T00:00:00Z TO 2010-05-04T00:00:00Z]\");\n    minParams.add(\"facet.query\", tdate_b + \":[2009-01-01T00:00:00Z TO 2010-01-01T00:00:00Z]\"); // Should be removed\n    setDistributedParams(minParams);\n    minResp = queryServer(minParams);\n\n    assertEquals(\"Should only be 1 query facets returned after minCounts taken into account \", 1, minResp.getFacetQuery().size());\n    assertTrue(\"Should be an entry for a_n_tdt\", minResp.getFacetQuery().containsKey(\"a_n_tdt:[2010-01-01T00:00:00Z TO 2010-05-04T00:00:00Z]\"));\n    qCount = minResp.getFacetQuery().get(\"a_n_tdt:[2010-01-01T00:00:00Z TO 2010-05-04T00:00:00Z]\");\n    assertEquals(\"a_n_tdt should have a count of 4 \", qCount, 4);\n    //  variations of fl\n    query(\"q\",\"*:*\", \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1 + \",score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", i1, \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id,\" + i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1, \"fl\", \"id\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",nint, \"fl\",tint,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",nint, \"fl\", \"id\", \"fl\",tint,\"sort\",i1 + \" desc\");\n\n    // basic spellcheck testing\n    query(\"q\", \"toyata\", \"fl\", \"id,lowerfilt\", \"spellcheck\", true, \"spellcheck.q\", \"toyata\", \"qt\", \"spellCheckCompRH_Direct\", \"shards.qt\", \"spellCheckCompRH_Direct\");\n\n    stress=0;  // turn off stress... we want to tex max combos in min time\n    for (int i=0; i<25*RANDOM_MULTIPLIER; i++) {\n      String f = fieldNames[random().nextInt(fieldNames.length)];\n      if (random().nextBoolean()) f = t1;  // the text field is a really interesting one to facet on (and it's multi-valued too)\n\n      // we want a random query and not just *:* so we'll get zero counts in facets also\n      // TODO: do a better random query\n      String q = random().nextBoolean() ? \"*:*\" : \"id:(1 3 5 7 9 11 13) OR id:[100 TO \" + random().nextInt(50) + \"]\";\n\n      int nolimit = random().nextBoolean() ? -1 : 10000;  // these should be equivalent\n\n      // if limit==-1, we should always get exact matches\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"count\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      // for index sort, we should get exact results for mincount <= 1\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(2), \"facet.offset\",random().nextInt(10), \"facet.limit\",random().nextInt(11)-1);\n    }\n    stress = backupStress;  // restore stress\n\n    // test faceting multiple things at once\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1);\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id:[1 TO 7]\", \"fq\",\"{!tag=b}id:[3 TO 9]\"\n    );\n    query(\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\");\n\n    // test field that is valid in schema but missing in all shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2);\n    // test field that is valid in schema and missing in some shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2);\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", \"stats_dt\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1);\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", tdate_a);\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", tdate_b);\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \n          \"fq\", \"{!tag=nothing}-*:*\",\n          \"stats.field\", \"{!key=special_key ex=nothing}stats_dt\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \n          \"f.stats_dt.stats.calcdistinct\", \"true\",\n          \"stats.field\", \"{!key=special_key}stats_dt\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \n          \"f.stats_dt.stats.calcdistinct\", \"true\",\n          \"fq\", \"{!tag=xxx}id:[3 TO 9]\",\n          \"stats.field\", \"{!key=special_key}stats_dt\",\n          \"stats.field\", \"{!ex=xxx}stats_dt\");\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\",\n          // do a really simple query so distributed IDF doesn't cause problems\n          // when comparing with control collection\n          \"stats.field\", \"{!lucene key=q_key}\" + i1 + \"foo_b:true\",\n          \"stats.field\", \"{!func key=f_key}sum(\" + tlong +\",\"+i1+\")\");\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\",\n          \"stats.field\", \"stats_dt\",\n          \"stats.field\", i1,\n          \"stats.field\", tdate_a,\n          \"stats.field\", tdate_b);\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    // check a complex key name\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"*:*\", \"rows\",100);\n    }\n\n    //SOLR 3161 ensure shards.qt=/update fails (anything but search handler really)\n    // Also see TestRemoteStreaming#testQtUpdateFails()\n    try {\n      ignoreException(\"isShard is only acceptable\");\n      // query(\"q\",\"*:*\",\"shards.qt\",\"/update\",\"stream.body\",\"<delete><query>*:*</query></delete>\");\n      // fail();\n    } catch (SolrException e) {\n      //expected\n    }\n    unIgnoreException(\"isShard is only acceptable\");\n\n    // test debugging\n    // handle.put(\"explain\", UNORDERED);\n    handle.put(\"explain\", SKIPVAL);  // internal docids differ, idf differs w/o global idf\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    handle.put(\"track\", SKIP); //track is not included in single node search\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY);\n\n    // Check Info is added to for each shard\n    ModifiableSolrParams q = new ModifiableSolrParams();\n    q.set(\"q\", \"*:*\");\n    q.set(ShardParams.SHARDS_INFO, true);\n    setDistributedParams(q);\n    rsp = queryServer(q);\n    NamedList<?> sinfo = (NamedList<?>) rsp.getResponse().get(ShardParams.SHARDS_INFO);\n    String shards = getShardsString();\n    int cnt = StringUtils.countMatches(shards, \",\")+1;\n    \n    assertNotNull(\"missing shard info\", sinfo);\n    assertEquals(\"should have an entry for each shard [\"+sinfo+\"] \"+shards, cnt, sinfo.size());\n\n    // test shards.tolerant=true\n    for(int numDownServers = 0; numDownServers < jettys.size()-1; numDownServers++)\n    {\n      List<JettySolrRunner> upJettys = new ArrayList<>(jettys);\n      List<SolrServer> upClients = new ArrayList<>(clients);\n      List<JettySolrRunner> downJettys = new ArrayList<>();\n      List<String> upShards = new ArrayList<>(Arrays.asList(shardsArr));\n      for(int i=0; i<numDownServers; i++)\n      {\n        // shut down some of the jettys\n        int indexToRemove = r.nextInt(upJettys.size());\n        JettySolrRunner downJetty = upJettys.remove(indexToRemove);\n        upClients.remove(indexToRemove);\n        upShards.remove(indexToRemove);\n        ChaosMonkey.stop(downJetty);\n        downJettys.add(downJetty);\n      }\n\n      queryPartialResults(upShards, upClients, \n          \"q\",\"*:*\",\n          \"facet\",\"true\", \n          \"facet.field\",t1,\n          \"facet.field\",t1,\n          \"facet.limit\",5,\n          ShardParams.SHARDS_INFO,\"true\",\n          ShardParams.SHARDS_TOLERANT,\"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"facet\", \"true\",\n          \"facet.query\", i1 + \":[1 TO 50]\",\n          \"facet.query\", i1 + \":[1 TO 50]\",\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      // test group query\n      // TODO: Remove this? This doesn't make any real sense now that timeAllowed might trigger early\n      //       termination of the request during Terms enumeration/Query expansion.\n      //       During such an exit, partial results isn't supported as it wouldn't make any sense.\n      // Increasing the timeAllowed from 1 to 100 for now.\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"rows\", 100,\n          \"fl\", \"id,\" + i1,\n          \"group\", \"true\",\n          \"group.query\", t1 + \":kings OR \" + t1 + \":eggs\",\n          \"group.limit\", 10,\n          \"sort\", i1 + \" asc, id asc\",\n          CommonParams.TIME_ALLOWED, 100,\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"stats\", \"true\",\n          \"stats.field\", i1,\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"toyata\",\n          \"spellcheck\", \"true\",\n          \"spellcheck.q\", \"toyata\",\n          \"qt\", \"spellCheckCompRH_Direct\",\n          \"shards.qt\", \"spellCheckCompRH_Direct\",\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      // restart the jettys\n      for (JettySolrRunner downJetty : downJettys) {\n        downJetty.start();\n      }\n    }\n\n    // This index has the same number for every field\n    \n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // Thread.sleep(10000000000L);\n\n    del(\"*:*\"); // delete all docs and test stats request\n    commit();\n    try {\n      query(\"q\", \"*:*\", \"stats\", \"true\", \n            \"stats.field\", \"stats_dt\", \n            \"stats.field\", i1, \n            \"stats.field\", tdate_a, \n            \"stats.field\", tdate_b,\n            \"stats.calcdistinct\", \"true\");\n    } catch (HttpSolrServer.RemoteSolrException e) {\n      if (e.getMessage().startsWith(\"java.lang.NullPointerException\"))  {\n        fail(\"NullPointerException with stats request on empty index\");\n      } else  {\n        throw e;\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  public void doTest() throws Exception {\n    QueryResponse rsp = null;\n    int backupStress = stress; // make a copy so we can restore\n\n\n    del(\"*:*\");\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\",\n           tdate_a, \"2010-04-20T11:00:00Z\",\n           tdate_b, \"2009-08-20T11:00:00Z\",\n           \"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\",\n           tdate_a, \"2010-05-02T11:00:00Z\",\n           tdate_b, \"2009-11-02T11:00:00Z\");\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\",\n           tdate_a, \"2010-05-03T11:00:00Z\");\n    indexr(id,4, i1, -100 ,tlong, 101,\n           t1,\"the quick fox jumped over the lazy dog\", \n           tdate_a, \"2010-05-03T11:00:00Z\",\n           tdate_b, \"2010-05-03T11:00:00Z\");\n    indexr(id,5, i1, 500, tlong, 500 ,\n           t1,\"the quick fox jumped way over the lazy dog\", \n           tdate_a, \"2010-05-05T11:00:00Z\");\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,\n           tdate_b, \"2010-01-05T11:00:00Z\",\n           t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n\n    commit();  // try to ensure there's more than one segment\n\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,\n           t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,\n           t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,\n           t1,\"no eggs on wall, lesson learned\", \n           oddField, \"odd man out\");\n\n    indexr(id, \"1001\", \"lowerfilt\", \"toyota\"); // for spellcheck\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n    \n    \n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n\n    handle.clear();\n    handle.put(\"timestamp\", SKIPVAL);\n    handle.put(\"_version_\", SKIPVAL); // not a cloud test, but may use updateLog\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(\"q\",\"*:*\", \"sort\",f+\" desc\");\n      query(\"q\",\"*:*\", \"sort\",f+\" asc\");\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",\"{!func}testfunc(add(\"+i1+\",5))\"+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" asc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\");\n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"*,score\"); \n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 desc\");\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"{!func}\"+i1);// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(\"q\",\"{!func}\"+i1, \"fl\",\"*,score\");  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"quick\");\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\");\n    query(\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\");  // no fields in returned docs\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\");\n\n    handle.put(\"score\", SKIPVAL);\n    query(\"q\",\"quick\",\"fl\",\"*,score\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\");\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"matchesnothing\",\"fl\",\"*,score\");  \n\n    // test that a single NOW value is propagated to all shards... if that is true\n    // then the primary sort should always be a tie and then the secondary should always decide\n    query(\"q\",\"{!func}ms(NOW)\", \"sort\",\"score desc,\"+i1+\" desc\",\"fl\",\"id\");    \n\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1, \"facet.field\",t1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\");\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2);\n\n    // a facet query to test out chars out of the ascii range\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!term f=foo_s}international\\u00ff\\u01ff\\u2222\\u3333\");\n\n    // simple field facet on date fields\n    rsp = query(\"q\",\"*:*\", \"rows\", 0,\n                \"facet\",\"true\", \"facet.limit\", 1, // TODO: limit shouldn't be needed: SOLR-6386\n                \"facet.field\", tdate_a);\n    assertEquals(1, rsp.getFacetFields().size());\n    rsp = query(\"q\",\"*:*\", \"rows\", 0,\n                \"facet\",\"true\", \"facet.limit\", 1, // TODO: limit shouldn't be needed: SOLR-6386\n                \"facet.field\", tdate_b, \"facet.field\", tdate_a);\n    assertEquals(2, rsp.getFacetFields().size());\n\n    // simple date facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a,\n          \"facet.date\",tdate_a,\n          \"facet.date.other\", \"all\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // date facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a,\n          \"facet.date\",tdate_b,\n          \"facet.date\",tdate_a,\n          \"facet.date.other\", \"all\", \n          \"f.\"+tdate_b+\".facet.date.start\",\"2009-05-01T11:00:00Z\", \n          \"f.\"+tdate_b+\".facet.date.gap\",\"+3MONTHS\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // simple range facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong,\n          \"facet.range\",tlong,\n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"facet.range.end\",900);\n\n    // range facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range\",i1, \n          \"f.\"+i1+\".facet.range.start\",300, \n          \"f.\"+i1+\".facet.range.gap\",87, \n          \"facet.range.end\",900,\n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"f.\"+tlong+\".facet.range.end\",900);\n\n    // Test mincounts. Do NOT want to go through all the stuff where with validateControlData in query() method\n    // Purposely packing a _bunch_ of stuff together here to insure that the proper level of mincount is used for\n    // each\n    ModifiableSolrParams minParams = new ModifiableSolrParams();\n    minParams.set(\"q\",\"*:*\");\n    minParams.set(\"rows\", 1);\n    minParams.set(\"facet\", \"true\");\n    minParams.set(\"facet.missing\", \"true\");\n    minParams.set(\"facet.field\", i1);\n    minParams.set(\"facet.missing\", \"true\");\n    minParams.set(\"facet.mincount\", 2);\n\n    // Return a separate section of ranges over i1. Should respect global range mincount\n    minParams.set(\"facet.range\", i1);\n    minParams.set(\"f.\" + i1 + \".facet.range.start\", 0);\n    minParams.set(\"f.\" + i1 + \".facet.range.gap\", 200);\n    minParams.set(\"f.\" + i1 + \".facet.range.end\", 1200);\n    minParams.set(\"f.\" + i1 + \".facet.mincount\", 4);\n\n\n    // Return a separate section of ranges over tlong Should respect facet.mincount\n    minParams.add(\"facet.range\", tlong);\n    minParams.set(\"f.\" + tlong + \".facet.range.start\", 0);\n    minParams.set(\"f.\" + tlong + \".facet.range.gap\", 100);\n    minParams.set(\"f.\" + tlong + \".facet.range.end\", 1200);\n    // Repeat with a range type of date\n    minParams.add(\"facet.range\", tdate_b);\n    minParams.set(\"f.\" + tdate_b + \".facet.range.start\", \"2009-02-01T00:00:00Z\");\n    minParams.set(\"f.\" + tdate_b + \".facet.range.gap\", \"+1YEAR\");\n    minParams.set(\"f.\" + tdate_b + \".facet.range.end\", \"2011-01-01T00:00:00Z\");\n    minParams.set(\"f.\" + tdate_b + \".facet.mincount\", 3);\n\n    // Insure that global mincount is respected for facet queries\n    minParams.set(\"facet.query\", tdate_a + \":[2010-01-01T00:00:00Z TO 2011-01-01T00:00:00Z]\"); // Should return some counts\n    //minParams.set(\"facet.query\", tdate_a + \":[* TO *]\"); // Should be removed\n    minParams.add(\"facet.query\", tdate_b + \":[2008-01-01T00:00:00Z TO 2009-09-01T00:00:00Z]\"); // Should be removed from response\n\n\n    setDistributedParams(minParams);\n    QueryResponse minResp = queryServer(minParams);\n\n    ModifiableSolrParams eParams = new ModifiableSolrParams();\n    eParams.set(\"q\",tdate_b + \":[* TO *]\");\n    eParams.set(\"rows\", 1000);\n    eParams.set(\"fl\", tdate_b);\n    setDistributedParams(eParams);\n    QueryResponse eResp = queryServer(eParams);\n\n    // Check that exactly the right numbers of counts came through\n    assertEquals(\"Should be exactly 2 range facets returned after minCounts taken into account \", 3, minResp.getFacetRanges().size());\n    assertEquals(\"Should only be 1 query facets returned after minCounts taken into account \", 1, minResp.getFacetQuery().size());\n\n    checkMinCountsField(minResp.getFacetField(i1).getValues(), new Object[]{null, 55L}); // Should just be the null entries for field\n\n    checkMinCountsRange(minResp.getFacetRanges().get(0).getCounts(), new Object[]{\"0\", 5L}); // range on i1\n    checkMinCountsRange(minResp.getFacetRanges().get(1).getCounts(), new Object[]{\"0\", 3L, \"100\", 3L}); // range on tlong\n    checkMinCountsRange(minResp.getFacetRanges().get(2).getCounts(), new Object[]{\"2009-02-01T00:00:00Z\",  3L}); // date (range) on tvh\n\n    assertTrue(\"Should have a facet for tdate_a\", minResp.getFacetQuery().containsKey(\"a_n_tdt:[2010-01-01T00:00:00Z TO 2011-01-01T00:00:00Z]\"));\n    int qCount = minResp.getFacetQuery().get(\"a_n_tdt:[2010-01-01T00:00:00Z TO 2011-01-01T00:00:00Z]\");\n    assertEquals(\"tdate_a should be 5\", qCount, 5);\n\n    // Now let's do some queries, the above is getting too complex\n    minParams = new ModifiableSolrParams();\n    minParams.set(\"q\",\"*:*\");\n    minParams.set(\"rows\", 1);\n    minParams.set(\"facet\", \"true\");\n    minParams.set(\"facet.mincount\", 3);\n\n    minParams.set(\"facet.query\", tdate_a + \":[2010-01-01T00:00:00Z TO 2010-05-04T00:00:00Z]\");\n    minParams.add(\"facet.query\", tdate_b + \":[2009-01-01T00:00:00Z TO 2010-01-01T00:00:00Z]\"); // Should be removed\n    setDistributedParams(minParams);\n    minResp = queryServer(minParams);\n\n    assertEquals(\"Should only be 1 query facets returned after minCounts taken into account \", 1, minResp.getFacetQuery().size());\n    assertTrue(\"Should be an entry for a_n_tdt\", minResp.getFacetQuery().containsKey(\"a_n_tdt:[2010-01-01T00:00:00Z TO 2010-05-04T00:00:00Z]\"));\n    qCount = minResp.getFacetQuery().get(\"a_n_tdt:[2010-01-01T00:00:00Z TO 2010-05-04T00:00:00Z]\");\n    assertEquals(\"a_n_tdt should have a count of 4 \", qCount, 4);\n    //  variations of fl\n    query(\"q\",\"*:*\", \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1 + \",score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", i1, \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id,\" + i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1, \"fl\", \"id\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",nint, \"fl\",tint,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",nint, \"fl\", \"id\", \"fl\",tint,\"sort\",i1 + \" desc\");\n\n    // basic spellcheck testing\n    query(\"q\", \"toyata\", \"fl\", \"id,lowerfilt\", \"spellcheck\", true, \"spellcheck.q\", \"toyata\", \"qt\", \"spellCheckCompRH_Direct\", \"shards.qt\", \"spellCheckCompRH_Direct\");\n\n    stress=0;  // turn off stress... we want to tex max combos in min time\n    for (int i=0; i<25*RANDOM_MULTIPLIER; i++) {\n      String f = fieldNames[random().nextInt(fieldNames.length)];\n      if (random().nextBoolean()) f = t1;  // the text field is a really interesting one to facet on (and it's multi-valued too)\n\n      // we want a random query and not just *:* so we'll get zero counts in facets also\n      // TODO: do a better random query\n      String q = random().nextBoolean() ? \"*:*\" : \"id:(1 3 5 7 9 11 13) OR id:[100 TO \" + random().nextInt(50) + \"]\";\n\n      int nolimit = random().nextBoolean() ? -1 : 10000;  // these should be equivalent\n\n      // if limit==-1, we should always get exact matches\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"count\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      // for index sort, we should get exact results for mincount <= 1\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(2), \"facet.offset\",random().nextInt(10), \"facet.limit\",random().nextInt(11)-1);\n    }\n    stress = backupStress;  // restore stress\n\n    // test faceting multiple things at once\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1);\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id:[1 TO 7]\", \"fq\",\"{!tag=b}id:[3 TO 9]\"\n    );\n    query(\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\");\n\n    // test field that is valid in schema but missing in all shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2);\n    // test field that is valid in schema and missing in some shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2);\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", \"stats_dt\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1);\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", tdate_a);\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", tdate_b);\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \n          \"fq\", \"{!tag=nothing}-*:*\",\n          \"stats.field\", \"{!key=special_key ex=nothing}stats_dt\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \n          \"f.stats_dt.stats.calcdistinct\", \"true\",\n          \"stats.field\", \"{!key=special_key}stats_dt\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \n          \"f.stats_dt.stats.calcdistinct\", \"true\",\n          \"fq\", \"{!tag=xxx}id:[3 TO 9]\",\n          \"stats.field\", \"{!key=special_key}stats_dt\",\n          \"stats.field\", \"{!ex=xxx}stats_dt\");\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\",\n          // do a really simple query so distributed IDF doesn't cause problems\n          // when comparing with control collection\n          \"stats.field\", \"{!lucene key=q_key}\" + i1 + \"foo_b:true\",\n          \"stats.field\", \"{!func key=f_key}sum(\" + tlong +\",\"+i1+\")\");\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\",\n          \"stats.field\", \"stats_dt\",\n          \"stats.field\", i1,\n          \"stats.field\", tdate_a,\n          \"stats.field\", tdate_b);\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    // check a complex key name\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"*:*\", \"rows\",100);\n    }\n\n    //SOLR 3161 ensure shards.qt=/update fails (anything but search handler really)\n    // Also see TestRemoteStreaming#testQtUpdateFails()\n    try {\n      ignoreException(\"isShard is only acceptable\");\n      // query(\"q\",\"*:*\",\"shards.qt\",\"/update\",\"stream.body\",\"<delete><query>*:*</query></delete>\");\n      // fail();\n    } catch (SolrException e) {\n      //expected\n    }\n    unIgnoreException(\"isShard is only acceptable\");\n\n    // test debugging\n    // handle.put(\"explain\", UNORDERED);\n    handle.put(\"explain\", SKIPVAL);  // internal docids differ, idf differs w/o global idf\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    handle.put(\"track\", SKIP); //track is not included in single node search\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY);\n\n    // Check Info is added to for each shard\n    ModifiableSolrParams q = new ModifiableSolrParams();\n    q.set(\"q\", \"*:*\");\n    q.set(ShardParams.SHARDS_INFO, true);\n    setDistributedParams(q);\n    rsp = queryServer(q);\n    NamedList<?> sinfo = (NamedList<?>) rsp.getResponse().get(ShardParams.SHARDS_INFO);\n    String shards = getShardsString();\n    int cnt = StringUtils.countMatches(shards, \",\")+1;\n    \n    assertNotNull(\"missing shard info\", sinfo);\n    assertEquals(\"should have an entry for each shard [\"+sinfo+\"] \"+shards, cnt, sinfo.size());\n\n    // test shards.tolerant=true\n    for(int numDownServers = 0; numDownServers < jettys.size()-1; numDownServers++)\n    {\n      List<JettySolrRunner> upJettys = new ArrayList<>(jettys);\n      List<SolrServer> upClients = new ArrayList<>(clients);\n      List<JettySolrRunner> downJettys = new ArrayList<>();\n      List<String> upShards = new ArrayList<>(Arrays.asList(shardsArr));\n      for(int i=0; i<numDownServers; i++)\n      {\n        // shut down some of the jettys\n        int indexToRemove = r.nextInt(upJettys.size());\n        JettySolrRunner downJetty = upJettys.remove(indexToRemove);\n        upClients.remove(indexToRemove);\n        upShards.remove(indexToRemove);\n        ChaosMonkey.stop(downJetty);\n        downJettys.add(downJetty);\n      }\n\n      queryPartialResults(upShards, upClients, \n          \"q\",\"*:*\",\n          \"facet\",\"true\", \n          \"facet.field\",t1,\n          \"facet.field\",t1,\n          \"facet.limit\",5,\n          ShardParams.SHARDS_INFO,\"true\",\n          ShardParams.SHARDS_TOLERANT,\"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"facet\", \"true\",\n          \"facet.query\", i1 + \":[1 TO 50]\",\n          \"facet.query\", i1 + \":[1 TO 50]\",\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      // test group query\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"rows\", 100,\n          \"fl\", \"id,\" + i1,\n          \"group\", \"true\",\n          \"group.query\", t1 + \":kings OR \" + t1 + \":eggs\",\n          \"group.limit\", 10,\n          \"sort\", i1 + \" asc, id asc\",\n          CommonParams.TIME_ALLOWED, 1,\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"stats\", \"true\",\n          \"stats.field\", i1,\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"toyata\",\n          \"spellcheck\", \"true\",\n          \"spellcheck.q\", \"toyata\",\n          \"qt\", \"spellCheckCompRH_Direct\",\n          \"shards.qt\", \"spellCheckCompRH_Direct\",\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      // restart the jettys\n      for (JettySolrRunner downJetty : downJettys) {\n        downJetty.start();\n      }\n    }\n\n    // This index has the same number for every field\n    \n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // Thread.sleep(10000000000L);\n\n    del(\"*:*\"); // delete all docs and test stats request\n    commit();\n    try {\n      query(\"q\", \"*:*\", \"stats\", \"true\", \n            \"stats.field\", \"stats_dt\", \n            \"stats.field\", i1, \n            \"stats.field\", tdate_a, \n            \"stats.field\", tdate_b,\n            \"stats.calcdistinct\", \"true\");\n    } catch (HttpSolrServer.RemoteSolrException e) {\n      if (e.getMessage().startsWith(\"java.lang.NullPointerException\"))  {\n        fail(\"NullPointerException with stats request on empty index\");\n      } else  {\n        throw e;\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"da951a24a6a87d5ba7e1820f8c28a1e2beea76c1","date":1411744836,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/TestDistributedSearch#doTest().mjava","pathOld":"solr/core/src/test/org/apache/solr/TestDistributedSearch#doTest().mjava","sourceNew":"  @Override\n  public void doTest() throws Exception {\n    QueryResponse rsp = null;\n    int backupStress = stress; // make a copy so we can restore\n\n\n    del(\"*:*\");\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\",\n           tdate_a, \"2010-04-20T11:00:00Z\",\n           tdate_b, \"2009-08-20T11:00:00Z\",\n           \"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\",\n           tdate_a, \"2010-05-02T11:00:00Z\",\n           tdate_b, \"2009-11-02T11:00:00Z\");\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\",\n           tdate_a, \"2010-05-03T11:00:00Z\");\n    indexr(id,4, i1, -100 ,tlong, 101,\n           t1,\"the quick fox jumped over the lazy dog\", \n           tdate_a, \"2010-05-03T11:00:00Z\",\n           tdate_b, \"2010-05-03T11:00:00Z\");\n    indexr(id,5, i1, 500, tlong, 500 ,\n           t1,\"the quick fox jumped way over the lazy dog\", \n           tdate_a, \"2010-05-05T11:00:00Z\");\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,\n           tdate_b, \"2010-01-05T11:00:00Z\",\n           t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n\n    commit();  // try to ensure there's more than one segment\n\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,\n           t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,\n           t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,\n           t1,\"no eggs on wall, lesson learned\", \n           oddField, \"odd man out\");\n\n    indexr(id, \"1001\", \"lowerfilt\", \"toyota\"); // for spellcheck\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n    \n    \n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n\n    handle.clear();\n    handle.put(\"timestamp\", SKIPVAL);\n    handle.put(\"_version_\", SKIPVAL); // not a cloud test, but may use updateLog\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(\"q\",\"*:*\", \"sort\",f+\" desc\");\n      query(\"q\",\"*:*\", \"sort\",f+\" asc\");\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",\"{!func}testfunc(add(\"+i1+\",5))\"+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" asc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\");\n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"*,score\"); \n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 desc\");\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"{!func}\"+i1);// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(\"q\",\"{!func}\"+i1, \"fl\",\"*,score\");  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"quick\");\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\");\n    query(\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\");  // no fields in returned docs\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\");\n\n    handle.put(\"score\", SKIPVAL);\n    query(\"q\",\"quick\",\"fl\",\"*,score\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\");\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"matchesnothing\",\"fl\",\"*,score\");  \n\n    // test that a single NOW value is propagated to all shards... if that is true\n    // then the primary sort should always be a tie and then the secondary should always decide\n    query(\"q\",\"{!func}ms(NOW)\", \"sort\",\"score desc,\"+i1+\" desc\",\"fl\",\"id\");    \n\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1, \"facet.field\",t1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\");\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2);\n\n    // a facet query to test out chars out of the ascii range\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!term f=foo_s}international\\u00ff\\u01ff\\u2222\\u3333\");\n\n    // simple field facet on date fields\n    rsp = query(\"q\",\"*:*\", \"rows\", 0,\n                \"facet\",\"true\", \"facet.limit\", 1, // TODO: limit shouldn't be needed: SOLR-6386\n                \"facet.field\", tdate_a);\n    assertEquals(1, rsp.getFacetFields().size());\n    rsp = query(\"q\",\"*:*\", \"rows\", 0,\n                \"facet\",\"true\", \"facet.limit\", 1, // TODO: limit shouldn't be needed: SOLR-6386\n                \"facet.field\", tdate_b, \"facet.field\", tdate_a);\n    assertEquals(2, rsp.getFacetFields().size());\n\n    // simple date facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a,\n          \"facet.date\",tdate_a,\n          \"facet.date.other\", \"all\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // date facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a,\n          \"facet.date\",tdate_b,\n          \"facet.date\",tdate_a,\n          \"facet.date.other\", \"all\", \n          \"f.\"+tdate_b+\".facet.date.start\",\"2009-05-01T11:00:00Z\", \n          \"f.\"+tdate_b+\".facet.date.gap\",\"+3MONTHS\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // simple range facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong,\n          \"facet.range\",tlong,\n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"facet.range.end\",900);\n\n    // range facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range\",i1, \n          \"f.\"+i1+\".facet.range.start\",300, \n          \"f.\"+i1+\".facet.range.gap\",87, \n          \"facet.range.end\",900,\n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"f.\"+tlong+\".facet.range.end\",900);\n\n    // Test mincounts. Do NOT want to go through all the stuff where with validateControlData in query() method\n    // Purposely packing a _bunch_ of stuff together here to insure that the proper level of mincount is used for\n    // each\n    ModifiableSolrParams minParams = new ModifiableSolrParams();\n    minParams.set(\"q\",\"*:*\");\n    minParams.set(\"rows\", 1);\n    minParams.set(\"facet\", \"true\");\n    minParams.set(\"facet.missing\", \"true\");\n    minParams.set(\"facet.field\", i1);\n    minParams.set(\"facet.missing\", \"true\");\n    minParams.set(\"facet.mincount\", 2);\n\n    // Return a separate section of ranges over i1. Should respect global range mincount\n    minParams.set(\"facet.range\", i1);\n    minParams.set(\"f.\" + i1 + \".facet.range.start\", 0);\n    minParams.set(\"f.\" + i1 + \".facet.range.gap\", 200);\n    minParams.set(\"f.\" + i1 + \".facet.range.end\", 1200);\n    minParams.set(\"f.\" + i1 + \".facet.mincount\", 4);\n\n\n    // Return a separate section of ranges over tlong Should respect facet.mincount\n    minParams.add(\"facet.range\", tlong);\n    minParams.set(\"f.\" + tlong + \".facet.range.start\", 0);\n    minParams.set(\"f.\" + tlong + \".facet.range.gap\", 100);\n    minParams.set(\"f.\" + tlong + \".facet.range.end\", 1200);\n    // Repeat with a range type of date\n    minParams.add(\"facet.range\", tdate_b);\n    minParams.set(\"f.\" + tdate_b + \".facet.range.start\", \"2009-02-01T00:00:00Z\");\n    minParams.set(\"f.\" + tdate_b + \".facet.range.gap\", \"+1YEAR\");\n    minParams.set(\"f.\" + tdate_b + \".facet.range.end\", \"2011-01-01T00:00:00Z\");\n    minParams.set(\"f.\" + tdate_b + \".facet.mincount\", 3);\n\n    // Insure that global mincount is respected for facet queries\n    minParams.set(\"facet.query\", tdate_a + \":[2010-01-01T00:00:00Z TO 2011-01-01T00:00:00Z]\"); // Should return some counts\n    //minParams.set(\"facet.query\", tdate_a + \":[* TO *]\"); // Should be removed\n    minParams.add(\"facet.query\", tdate_b + \":[2008-01-01T00:00:00Z TO 2009-09-01T00:00:00Z]\"); // Should be removed from response\n\n\n    setDistributedParams(minParams);\n    QueryResponse minResp = queryServer(minParams);\n\n    ModifiableSolrParams eParams = new ModifiableSolrParams();\n    eParams.set(\"q\",tdate_b + \":[* TO *]\");\n    eParams.set(\"rows\", 1000);\n    eParams.set(\"fl\", tdate_b);\n    setDistributedParams(eParams);\n    QueryResponse eResp = queryServer(eParams);\n\n    // Check that exactly the right numbers of counts came through\n    assertEquals(\"Should be exactly 2 range facets returned after minCounts taken into account \", 3, minResp.getFacetRanges().size());\n    assertEquals(\"Should only be 1 query facets returned after minCounts taken into account \", 1, minResp.getFacetQuery().size());\n\n    checkMinCountsField(minResp.getFacetField(i1).getValues(), new Object[]{null, 55L}); // Should just be the null entries for field\n\n    checkMinCountsRange(minResp.getFacetRanges().get(0).getCounts(), new Object[]{\"0\", 5L}); // range on i1\n    checkMinCountsRange(minResp.getFacetRanges().get(1).getCounts(), new Object[]{\"0\", 3L, \"100\", 3L}); // range on tlong\n    checkMinCountsRange(minResp.getFacetRanges().get(2).getCounts(), new Object[]{\"2009-02-01T00:00:00Z\",  3L}); // date (range) on tvh\n\n    assertTrue(\"Should have a facet for tdate_a\", minResp.getFacetQuery().containsKey(\"a_n_tdt:[2010-01-01T00:00:00Z TO 2011-01-01T00:00:00Z]\"));\n    int qCount = minResp.getFacetQuery().get(\"a_n_tdt:[2010-01-01T00:00:00Z TO 2011-01-01T00:00:00Z]\");\n    assertEquals(\"tdate_a should be 5\", qCount, 5);\n\n    // Now let's do some queries, the above is getting too complex\n    minParams = new ModifiableSolrParams();\n    minParams.set(\"q\",\"*:*\");\n    minParams.set(\"rows\", 1);\n    minParams.set(\"facet\", \"true\");\n    minParams.set(\"facet.mincount\", 3);\n\n    minParams.set(\"facet.query\", tdate_a + \":[2010-01-01T00:00:00Z TO 2010-05-04T00:00:00Z]\");\n    minParams.add(\"facet.query\", tdate_b + \":[2009-01-01T00:00:00Z TO 2010-01-01T00:00:00Z]\"); // Should be removed\n    setDistributedParams(minParams);\n    minResp = queryServer(minParams);\n\n    assertEquals(\"Should only be 1 query facets returned after minCounts taken into account \", 1, minResp.getFacetQuery().size());\n    assertTrue(\"Should be an entry for a_n_tdt\", minResp.getFacetQuery().containsKey(\"a_n_tdt:[2010-01-01T00:00:00Z TO 2010-05-04T00:00:00Z]\"));\n    qCount = minResp.getFacetQuery().get(\"a_n_tdt:[2010-01-01T00:00:00Z TO 2010-05-04T00:00:00Z]\");\n    assertEquals(\"a_n_tdt should have a count of 4 \", qCount, 4);\n    //  variations of fl\n    query(\"q\",\"*:*\", \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1 + \",score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", i1, \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id,\" + i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1, \"fl\", \"id\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",nint, \"fl\",tint,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",nint, \"fl\", \"id\", \"fl\",tint,\"sort\",i1 + \" desc\");\n\n    // basic spellcheck testing\n    query(\"q\", \"toyata\", \"fl\", \"id,lowerfilt\", \"spellcheck\", true, \"spellcheck.q\", \"toyata\", \"qt\", \"spellCheckCompRH_Direct\", \"shards.qt\", \"spellCheckCompRH_Direct\");\n\n    stress=0;  // turn off stress... we want to tex max combos in min time\n    for (int i=0; i<25*RANDOM_MULTIPLIER; i++) {\n      String f = fieldNames[random().nextInt(fieldNames.length)];\n      if (random().nextBoolean()) f = t1;  // the text field is a really interesting one to facet on (and it's multi-valued too)\n\n      // we want a random query and not just *:* so we'll get zero counts in facets also\n      // TODO: do a better random query\n      String q = random().nextBoolean() ? \"*:*\" : \"id:(1 3 5 7 9 11 13) OR id:[100 TO \" + random().nextInt(50) + \"]\";\n\n      int nolimit = random().nextBoolean() ? -1 : 10000;  // these should be equivalent\n\n      // if limit==-1, we should always get exact matches\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"count\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      // for index sort, we should get exact results for mincount <= 1\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(2), \"facet.offset\",random().nextInt(10), \"facet.limit\",random().nextInt(11)-1);\n    }\n    stress = backupStress;  // restore stress\n\n    // test faceting multiple things at once\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1);\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id:[1 TO 7]\", \"fq\",\"{!tag=b}id:[3 TO 9]\"\n    );\n    query(\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\");\n\n    // test field that is valid in schema but missing in all shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2);\n    // test field that is valid in schema and missing in some shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2);\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", \"stats_dt\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1);\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", tdate_a);\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", tdate_b);\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \n          \"fq\", \"{!tag=nothing}-*:*\",\n          \"stats.field\", \"{!key=special_key ex=nothing}stats_dt\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \n          \"f.stats_dt.stats.calcdistinct\", \"true\",\n          \"stats.field\", \"{!key=special_key}stats_dt\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \n          \"f.stats_dt.stats.calcdistinct\", \"true\",\n          \"fq\", \"{!tag=xxx}id:[3 TO 9]\",\n          \"stats.field\", \"{!key=special_key}stats_dt\",\n          \"stats.field\", \"{!ex=xxx}stats_dt\");\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\",\n          // do a really simple query so distributed IDF doesn't cause problems\n          // when comparing with control collection\n          \"stats.field\", \"{!lucene key=q_key}\" + i1 + \"foo_b:true\",\n          \"stats.field\", \"{!func key=f_key}sum(\" + tlong +\",\"+i1+\")\");\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\",\n          \"stats.field\", \"stats_dt\",\n          \"stats.field\", i1,\n          \"stats.field\", tdate_a,\n          \"stats.field\", tdate_b);\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    // check a complex key name\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"*:*\", \"rows\",100);\n    }\n\n    //SOLR 3161 ensure shards.qt=/update fails (anything but search handler really)\n    // Also see TestRemoteStreaming#testQtUpdateFails()\n    try {\n      ignoreException(\"isShard is only acceptable\");\n      // query(\"q\",\"*:*\",\"shards.qt\",\"/update\",\"stream.body\",\"<delete><query>*:*</query></delete>\");\n      // fail();\n    } catch (SolrException e) {\n      //expected\n    }\n    unIgnoreException(\"isShard is only acceptable\");\n\n    // test debugging\n    // handle.put(\"explain\", UNORDERED);\n    handle.put(\"explain\", SKIPVAL);  // internal docids differ, idf differs w/o global idf\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    handle.put(\"track\", SKIP); //track is not included in single node search\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY);\n\n    // Check Info is added to for each shard\n    ModifiableSolrParams q = new ModifiableSolrParams();\n    q.set(\"q\", \"*:*\");\n    q.set(ShardParams.SHARDS_INFO, true);\n    setDistributedParams(q);\n    rsp = queryServer(q);\n    NamedList<?> sinfo = (NamedList<?>) rsp.getResponse().get(ShardParams.SHARDS_INFO);\n    String shards = getShardsString();\n    int cnt = StringUtils.countMatches(shards, \",\")+1;\n    \n    assertNotNull(\"missing shard info\", sinfo);\n    assertEquals(\"should have an entry for each shard [\"+sinfo+\"] \"+shards, cnt, sinfo.size());\n\n    // test shards.tolerant=true\n    for(int numDownServers = 0; numDownServers < jettys.size()-1; numDownServers++)\n    {\n      List<JettySolrRunner> upJettys = new ArrayList<>(jettys);\n      List<SolrServer> upClients = new ArrayList<>(clients);\n      List<JettySolrRunner> downJettys = new ArrayList<>();\n      List<String> upShards = new ArrayList<>(Arrays.asList(shardsArr));\n      for(int i=0; i<numDownServers; i++)\n      {\n        // shut down some of the jettys\n        int indexToRemove = r.nextInt(upJettys.size());\n        JettySolrRunner downJetty = upJettys.remove(indexToRemove);\n        upClients.remove(indexToRemove);\n        upShards.remove(indexToRemove);\n        ChaosMonkey.stop(downJetty);\n        downJettys.add(downJetty);\n      }\n\n      queryPartialResults(upShards, upClients, \n          \"q\",\"*:*\",\n          \"facet\",\"true\", \n          \"facet.field\",t1,\n          \"facet.field\",t1,\n          \"facet.limit\",5,\n          ShardParams.SHARDS_INFO,\"true\",\n          ShardParams.SHARDS_TOLERANT,\"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"facet\", \"true\",\n          \"facet.query\", i1 + \":[1 TO 50]\",\n          \"facet.query\", i1 + \":[1 TO 50]\",\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      // test group query\n      // TODO: Remove this? This doesn't make any real sense now that timeAllowed might trigger early\n      //       termination of the request during Terms enumeration/Query expansion.\n      //       During such an exit, partial results isn't supported as it wouldn't make any sense.\n      // Increasing the timeAllowed from 1 to 100 for now.\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"rows\", 100,\n          \"fl\", \"id,\" + i1,\n          \"group\", \"true\",\n          \"group.query\", t1 + \":kings OR \" + t1 + \":eggs\",\n          \"group.limit\", 10,\n          \"sort\", i1 + \" asc, id asc\",\n          CommonParams.TIME_ALLOWED, 100,\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"stats\", \"true\",\n          \"stats.field\", i1,\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"toyata\",\n          \"spellcheck\", \"true\",\n          \"spellcheck.q\", \"toyata\",\n          \"qt\", \"spellCheckCompRH_Direct\",\n          \"shards.qt\", \"spellCheckCompRH_Direct\",\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      // restart the jettys\n      for (JettySolrRunner downJetty : downJettys) {\n        downJetty.start();\n      }\n    }\n\n    // This index has the same number for every field\n    \n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // Thread.sleep(10000000000L);\n\n    del(\"*:*\"); // delete all docs and test stats request\n    commit();\n    try {\n      query(\"q\", \"*:*\", \"stats\", \"true\", \n            \"stats.field\", \"stats_dt\", \n            \"stats.field\", i1, \n            \"stats.field\", tdate_a, \n            \"stats.field\", tdate_b,\n            \"stats.calcdistinct\", \"true\");\n    } catch (HttpSolrServer.RemoteSolrException e) {\n      if (e.getMessage().startsWith(\"java.lang.NullPointerException\"))  {\n        fail(\"NullPointerException with stats request on empty index\");\n      } else  {\n        throw e;\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  public void doTest() throws Exception {\n    QueryResponse rsp = null;\n    int backupStress = stress; // make a copy so we can restore\n\n\n    del(\"*:*\");\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\",\n           tdate_a, \"2010-04-20T11:00:00Z\",\n           tdate_b, \"2009-08-20T11:00:00Z\",\n           \"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\",\n           tdate_a, \"2010-05-02T11:00:00Z\",\n           tdate_b, \"2009-11-02T11:00:00Z\");\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\",\n           tdate_a, \"2010-05-03T11:00:00Z\");\n    indexr(id,4, i1, -100 ,tlong, 101,\n           t1,\"the quick fox jumped over the lazy dog\", \n           tdate_a, \"2010-05-03T11:00:00Z\",\n           tdate_b, \"2010-05-03T11:00:00Z\");\n    indexr(id,5, i1, 500, tlong, 500 ,\n           t1,\"the quick fox jumped way over the lazy dog\", \n           tdate_a, \"2010-05-05T11:00:00Z\");\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,\n           tdate_b, \"2010-01-05T11:00:00Z\",\n           t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n\n    commit();  // try to ensure there's more than one segment\n\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,\n           t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,\n           t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,\n           t1,\"no eggs on wall, lesson learned\", \n           oddField, \"odd man out\");\n\n    indexr(id, \"1001\", \"lowerfilt\", \"toyota\"); // for spellcheck\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n    \n    \n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n\n    handle.clear();\n    handle.put(\"timestamp\", SKIPVAL);\n    handle.put(\"_version_\", SKIPVAL); // not a cloud test, but may use updateLog\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(\"q\",\"*:*\", \"sort\",f+\" desc\");\n      query(\"q\",\"*:*\", \"sort\",f+\" asc\");\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",\"{!func}testfunc(add(\"+i1+\",5))\"+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" asc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\");\n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"*,score\"); \n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 desc\");\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"{!func}\"+i1);// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(\"q\",\"{!func}\"+i1, \"fl\",\"*,score\");  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"quick\");\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\");\n    query(\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\");  // no fields in returned docs\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\");\n\n    handle.put(\"score\", SKIPVAL);\n    query(\"q\",\"quick\",\"fl\",\"*,score\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\");\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"matchesnothing\",\"fl\",\"*,score\");  \n\n    // test that a single NOW value is propagated to all shards... if that is true\n    // then the primary sort should always be a tie and then the secondary should always decide\n    query(\"q\",\"{!func}ms(NOW)\", \"sort\",\"score desc,\"+i1+\" desc\",\"fl\",\"id\");    \n\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1, \"facet.field\",t1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\");\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2);\n\n    // a facet query to test out chars out of the ascii range\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!term f=foo_s}international\\u00ff\\u01ff\\u2222\\u3333\");\n\n    // simple field facet on date fields\n    rsp = query(\"q\",\"*:*\", \"rows\", 0,\n                \"facet\",\"true\", \"facet.limit\", 1, // TODO: limit shouldn't be needed: SOLR-6386\n                \"facet.field\", tdate_a);\n    assertEquals(1, rsp.getFacetFields().size());\n    rsp = query(\"q\",\"*:*\", \"rows\", 0,\n                \"facet\",\"true\", \"facet.limit\", 1, // TODO: limit shouldn't be needed: SOLR-6386\n                \"facet.field\", tdate_b, \"facet.field\", tdate_a);\n    assertEquals(2, rsp.getFacetFields().size());\n\n    // simple date facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a,\n          \"facet.date\",tdate_a,\n          \"facet.date.other\", \"all\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // date facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a,\n          \"facet.date\",tdate_b,\n          \"facet.date\",tdate_a,\n          \"facet.date.other\", \"all\", \n          \"f.\"+tdate_b+\".facet.date.start\",\"2009-05-01T11:00:00Z\", \n          \"f.\"+tdate_b+\".facet.date.gap\",\"+3MONTHS\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // simple range facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong,\n          \"facet.range\",tlong,\n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"facet.range.end\",900);\n\n    // range facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range\",i1, \n          \"f.\"+i1+\".facet.range.start\",300, \n          \"f.\"+i1+\".facet.range.gap\",87, \n          \"facet.range.end\",900,\n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"f.\"+tlong+\".facet.range.end\",900);\n\n    // Test mincounts. Do NOT want to go through all the stuff where with validateControlData in query() method\n    // Purposely packing a _bunch_ of stuff together here to insure that the proper level of mincount is used for\n    // each\n    ModifiableSolrParams minParams = new ModifiableSolrParams();\n    minParams.set(\"q\",\"*:*\");\n    minParams.set(\"rows\", 1);\n    minParams.set(\"facet\", \"true\");\n    minParams.set(\"facet.missing\", \"true\");\n    minParams.set(\"facet.field\", i1);\n    minParams.set(\"facet.missing\", \"true\");\n    minParams.set(\"facet.mincount\", 2);\n\n    // Return a separate section of ranges over i1. Should respect global range mincount\n    minParams.set(\"facet.range\", i1);\n    minParams.set(\"f.\" + i1 + \".facet.range.start\", 0);\n    minParams.set(\"f.\" + i1 + \".facet.range.gap\", 200);\n    minParams.set(\"f.\" + i1 + \".facet.range.end\", 1200);\n    minParams.set(\"f.\" + i1 + \".facet.mincount\", 4);\n\n\n    // Return a separate section of ranges over tlong Should respect facet.mincount\n    minParams.add(\"facet.range\", tlong);\n    minParams.set(\"f.\" + tlong + \".facet.range.start\", 0);\n    minParams.set(\"f.\" + tlong + \".facet.range.gap\", 100);\n    minParams.set(\"f.\" + tlong + \".facet.range.end\", 1200);\n    // Repeat with a range type of date\n    minParams.add(\"facet.range\", tdate_b);\n    minParams.set(\"f.\" + tdate_b + \".facet.range.start\", \"2009-02-01T00:00:00Z\");\n    minParams.set(\"f.\" + tdate_b + \".facet.range.gap\", \"+1YEAR\");\n    minParams.set(\"f.\" + tdate_b + \".facet.range.end\", \"2011-01-01T00:00:00Z\");\n    minParams.set(\"f.\" + tdate_b + \".facet.mincount\", 3);\n\n    // Insure that global mincount is respected for facet queries\n    minParams.set(\"facet.query\", tdate_a + \":[2010-01-01T00:00:00Z TO 2011-01-01T00:00:00Z]\"); // Should return some counts\n    //minParams.set(\"facet.query\", tdate_a + \":[* TO *]\"); // Should be removed\n    minParams.add(\"facet.query\", tdate_b + \":[2008-01-01T00:00:00Z TO 2009-09-01T00:00:00Z]\"); // Should be removed from response\n\n\n    setDistributedParams(minParams);\n    QueryResponse minResp = queryServer(minParams);\n\n    ModifiableSolrParams eParams = new ModifiableSolrParams();\n    eParams.set(\"q\",tdate_b + \":[* TO *]\");\n    eParams.set(\"rows\", 1000);\n    eParams.set(\"fl\", tdate_b);\n    setDistributedParams(eParams);\n    QueryResponse eResp = queryServer(eParams);\n\n    // Check that exactly the right numbers of counts came through\n    assertEquals(\"Should be exactly 2 range facets returned after minCounts taken into account \", 3, minResp.getFacetRanges().size());\n    assertEquals(\"Should only be 1 query facets returned after minCounts taken into account \", 1, minResp.getFacetQuery().size());\n\n    checkMinCountsField(minResp.getFacetField(i1).getValues(), new Object[]{null, 55L}); // Should just be the null entries for field\n\n    checkMinCountsRange(minResp.getFacetRanges().get(0).getCounts(), new Object[]{\"0\", 5L}); // range on i1\n    checkMinCountsRange(minResp.getFacetRanges().get(1).getCounts(), new Object[]{\"0\", 3L, \"100\", 3L}); // range on tlong\n    checkMinCountsRange(minResp.getFacetRanges().get(2).getCounts(), new Object[]{\"2009-02-01T00:00:00Z\",  3L}); // date (range) on tvh\n\n    assertTrue(\"Should have a facet for tdate_a\", minResp.getFacetQuery().containsKey(\"a_n_tdt:[2010-01-01T00:00:00Z TO 2011-01-01T00:00:00Z]\"));\n    int qCount = minResp.getFacetQuery().get(\"a_n_tdt:[2010-01-01T00:00:00Z TO 2011-01-01T00:00:00Z]\");\n    assertEquals(\"tdate_a should be 5\", qCount, 5);\n\n    // Now let's do some queries, the above is getting too complex\n    minParams = new ModifiableSolrParams();\n    minParams.set(\"q\",\"*:*\");\n    minParams.set(\"rows\", 1);\n    minParams.set(\"facet\", \"true\");\n    minParams.set(\"facet.mincount\", 3);\n\n    minParams.set(\"facet.query\", tdate_a + \":[2010-01-01T00:00:00Z TO 2010-05-04T00:00:00Z]\");\n    minParams.add(\"facet.query\", tdate_b + \":[2009-01-01T00:00:00Z TO 2010-01-01T00:00:00Z]\"); // Should be removed\n    setDistributedParams(minParams);\n    minResp = queryServer(minParams);\n\n    assertEquals(\"Should only be 1 query facets returned after minCounts taken into account \", 1, minResp.getFacetQuery().size());\n    assertTrue(\"Should be an entry for a_n_tdt\", minResp.getFacetQuery().containsKey(\"a_n_tdt:[2010-01-01T00:00:00Z TO 2010-05-04T00:00:00Z]\"));\n    qCount = minResp.getFacetQuery().get(\"a_n_tdt:[2010-01-01T00:00:00Z TO 2010-05-04T00:00:00Z]\");\n    assertEquals(\"a_n_tdt should have a count of 4 \", qCount, 4);\n    //  variations of fl\n    query(\"q\",\"*:*\", \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1 + \",score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", i1, \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id,\" + i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1, \"fl\", \"id\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",nint, \"fl\",tint,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",nint, \"fl\", \"id\", \"fl\",tint,\"sort\",i1 + \" desc\");\n\n    // basic spellcheck testing\n    query(\"q\", \"toyata\", \"fl\", \"id,lowerfilt\", \"spellcheck\", true, \"spellcheck.q\", \"toyata\", \"qt\", \"spellCheckCompRH_Direct\", \"shards.qt\", \"spellCheckCompRH_Direct\");\n\n    stress=0;  // turn off stress... we want to tex max combos in min time\n    for (int i=0; i<25*RANDOM_MULTIPLIER; i++) {\n      String f = fieldNames[random().nextInt(fieldNames.length)];\n      if (random().nextBoolean()) f = t1;  // the text field is a really interesting one to facet on (and it's multi-valued too)\n\n      // we want a random query and not just *:* so we'll get zero counts in facets also\n      // TODO: do a better random query\n      String q = random().nextBoolean() ? \"*:*\" : \"id:(1 3 5 7 9 11 13) OR id:[100 TO \" + random().nextInt(50) + \"]\";\n\n      int nolimit = random().nextBoolean() ? -1 : 10000;  // these should be equivalent\n\n      // if limit==-1, we should always get exact matches\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"count\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      // for index sort, we should get exact results for mincount <= 1\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(2), \"facet.offset\",random().nextInt(10), \"facet.limit\",random().nextInt(11)-1);\n    }\n    stress = backupStress;  // restore stress\n\n    // test faceting multiple things at once\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1);\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id:[1 TO 7]\", \"fq\",\"{!tag=b}id:[3 TO 9]\"\n    );\n    query(\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\");\n\n    // test field that is valid in schema but missing in all shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2);\n    // test field that is valid in schema and missing in some shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2);\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", \"stats_dt\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1);\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", tdate_a);\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", tdate_b);\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \n          \"fq\", \"{!tag=nothing}-*:*\",\n          \"stats.field\", \"{!key=special_key ex=nothing}stats_dt\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \n          \"f.stats_dt.stats.calcdistinct\", \"true\",\n          \"stats.field\", \"{!key=special_key}stats_dt\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \n          \"f.stats_dt.stats.calcdistinct\", \"true\",\n          \"fq\", \"{!tag=xxx}id:[3 TO 9]\",\n          \"stats.field\", \"{!key=special_key}stats_dt\",\n          \"stats.field\", \"{!ex=xxx}stats_dt\");\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\",\n          // do a really simple query so distributed IDF doesn't cause problems\n          // when comparing with control collection\n          \"stats.field\", \"{!lucene key=q_key}\" + i1 + \"foo_b:true\",\n          \"stats.field\", \"{!func key=f_key}sum(\" + tlong +\",\"+i1+\")\");\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\",\n          \"stats.field\", \"stats_dt\",\n          \"stats.field\", i1,\n          \"stats.field\", tdate_a,\n          \"stats.field\", tdate_b);\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    // check a complex key name\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"*:*\", \"rows\",100);\n    }\n\n    //SOLR 3161 ensure shards.qt=/update fails (anything but search handler really)\n    // Also see TestRemoteStreaming#testQtUpdateFails()\n    try {\n      ignoreException(\"isShard is only acceptable\");\n      // query(\"q\",\"*:*\",\"shards.qt\",\"/update\",\"stream.body\",\"<delete><query>*:*</query></delete>\");\n      // fail();\n    } catch (SolrException e) {\n      //expected\n    }\n    unIgnoreException(\"isShard is only acceptable\");\n\n    // test debugging\n    // handle.put(\"explain\", UNORDERED);\n    handle.put(\"explain\", SKIPVAL);  // internal docids differ, idf differs w/o global idf\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    handle.put(\"track\", SKIP); //track is not included in single node search\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY);\n\n    // Check Info is added to for each shard\n    ModifiableSolrParams q = new ModifiableSolrParams();\n    q.set(\"q\", \"*:*\");\n    q.set(ShardParams.SHARDS_INFO, true);\n    setDistributedParams(q);\n    rsp = queryServer(q);\n    NamedList<?> sinfo = (NamedList<?>) rsp.getResponse().get(ShardParams.SHARDS_INFO);\n    String shards = getShardsString();\n    int cnt = StringUtils.countMatches(shards, \",\")+1;\n    \n    assertNotNull(\"missing shard info\", sinfo);\n    assertEquals(\"should have an entry for each shard [\"+sinfo+\"] \"+shards, cnt, sinfo.size());\n\n    // test shards.tolerant=true\n    for(int numDownServers = 0; numDownServers < jettys.size()-1; numDownServers++)\n    {\n      List<JettySolrRunner> upJettys = new ArrayList<>(jettys);\n      List<SolrServer> upClients = new ArrayList<>(clients);\n      List<JettySolrRunner> downJettys = new ArrayList<>();\n      List<String> upShards = new ArrayList<>(Arrays.asList(shardsArr));\n      for(int i=0; i<numDownServers; i++)\n      {\n        // shut down some of the jettys\n        int indexToRemove = r.nextInt(upJettys.size());\n        JettySolrRunner downJetty = upJettys.remove(indexToRemove);\n        upClients.remove(indexToRemove);\n        upShards.remove(indexToRemove);\n        ChaosMonkey.stop(downJetty);\n        downJettys.add(downJetty);\n      }\n\n      queryPartialResults(upShards, upClients, \n          \"q\",\"*:*\",\n          \"facet\",\"true\", \n          \"facet.field\",t1,\n          \"facet.field\",t1,\n          \"facet.limit\",5,\n          ShardParams.SHARDS_INFO,\"true\",\n          ShardParams.SHARDS_TOLERANT,\"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"facet\", \"true\",\n          \"facet.query\", i1 + \":[1 TO 50]\",\n          \"facet.query\", i1 + \":[1 TO 50]\",\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      // test group query\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"rows\", 100,\n          \"fl\", \"id,\" + i1,\n          \"group\", \"true\",\n          \"group.query\", t1 + \":kings OR \" + t1 + \":eggs\",\n          \"group.limit\", 10,\n          \"sort\", i1 + \" asc, id asc\",\n          CommonParams.TIME_ALLOWED, 1,\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"stats\", \"true\",\n          \"stats.field\", i1,\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"toyata\",\n          \"spellcheck\", \"true\",\n          \"spellcheck.q\", \"toyata\",\n          \"qt\", \"spellCheckCompRH_Direct\",\n          \"shards.qt\", \"spellCheckCompRH_Direct\",\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      // restart the jettys\n      for (JettySolrRunner downJetty : downJettys) {\n        downJetty.start();\n      }\n    }\n\n    // This index has the same number for every field\n    \n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // Thread.sleep(10000000000L);\n\n    del(\"*:*\"); // delete all docs and test stats request\n    commit();\n    try {\n      query(\"q\", \"*:*\", \"stats\", \"true\", \n            \"stats.field\", \"stats_dt\", \n            \"stats.field\", i1, \n            \"stats.field\", tdate_a, \n            \"stats.field\", tdate_b,\n            \"stats.calcdistinct\", \"true\");\n    } catch (HttpSolrServer.RemoteSolrException e) {\n      if (e.getMessage().startsWith(\"java.lang.NullPointerException\"))  {\n        fail(\"NullPointerException with stats request on empty index\");\n      } else  {\n        throw e;\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4283fa55a69b0144f8baca38bb6f4230e27fd954","date":1412373324,"type":3,"author":"Chris M. Hostetter","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/TestDistributedSearch#doTest().mjava","pathOld":"solr/core/src/test/org/apache/solr/TestDistributedSearch#doTest().mjava","sourceNew":"  @Override\n  public void doTest() throws Exception {\n    QueryResponse rsp = null;\n    int backupStress = stress; // make a copy so we can restore\n\n\n    del(\"*:*\");\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\",\n           tdate_a, \"2010-04-20T11:00:00Z\",\n           tdate_b, \"2009-08-20T11:00:00Z\",\n           \"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\",\n           tdate_a, \"2010-05-02T11:00:00Z\",\n           tdate_b, \"2009-11-02T11:00:00Z\");\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\",\n           tdate_a, \"2010-05-03T11:00:00Z\");\n    indexr(id,4, i1, -100 ,tlong, 101,\n           t1,\"the quick fox jumped over the lazy dog\", \n           tdate_a, \"2010-05-03T11:00:00Z\",\n           tdate_b, \"2010-05-03T11:00:00Z\");\n    indexr(id,5, i1, 500, tlong, 500 ,\n           t1,\"the quick fox jumped way over the lazy dog\", \n           tdate_a, \"2010-05-05T11:00:00Z\");\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,\n           tdate_b, \"2010-01-05T11:00:00Z\",\n           t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n\n    commit();  // try to ensure there's more than one segment\n\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,\n           t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,\n           t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,\n           t1,\"no eggs on wall, lesson learned\", \n           oddField, \"odd man out\");\n\n    indexr(id, \"1001\", \"lowerfilt\", \"toyota\"); // for spellcheck\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n    \n    \n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n\n    handle.clear();\n    handle.put(\"timestamp\", SKIPVAL);\n    handle.put(\"_version_\", SKIPVAL); // not a cloud test, but may use updateLog\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(\"q\",\"*:*\", \"sort\",f+\" desc\");\n      query(\"q\",\"*:*\", \"sort\",f+\" asc\");\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",\"{!func}testfunc(add(\"+i1+\",5))\"+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" asc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\");\n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"*,score\"); \n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 desc\");\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"{!func}\"+i1);// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(\"q\",\"{!func}\"+i1, \"fl\",\"*,score\");  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"quick\");\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\");\n    query(\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\");  // no fields in returned docs\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\");\n\n    handle.put(\"score\", SKIPVAL);\n    query(\"q\",\"quick\",\"fl\",\"*,score\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\");\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"matchesnothing\",\"fl\",\"*,score\");  \n\n    // test that a single NOW value is propagated to all shards... if that is true\n    // then the primary sort should always be a tie and then the secondary should always decide\n    query(\"q\",\"{!func}ms(NOW)\", \"sort\",\"score desc,\"+i1+\" desc\",\"fl\",\"id\");    \n\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1, \"facet.field\",t1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\");\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2);\n\n    // a facet query to test out chars out of the ascii range\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!term f=foo_s}international\\u00ff\\u01ff\\u2222\\u3333\");\n\n    // simple field facet on date fields\n    rsp = query(\"q\",\"*:*\", \"rows\", 0,\n                \"facet\",\"true\", \"facet.limit\", 1, // TODO: limit shouldn't be needed: SOLR-6386\n                \"facet.field\", tdate_a);\n    assertEquals(1, rsp.getFacetFields().size());\n    rsp = query(\"q\",\"*:*\", \"rows\", 0,\n                \"facet\",\"true\", \"facet.limit\", 1, // TODO: limit shouldn't be needed: SOLR-6386\n                \"facet.field\", tdate_b, \"facet.field\", tdate_a);\n    assertEquals(2, rsp.getFacetFields().size());\n\n    // simple date facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a,\n          \"facet.date\",tdate_a,\n          \"facet.date.other\", \"all\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // date facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a,\n          \"facet.date\",tdate_b,\n          \"facet.date\",tdate_a,\n          \"facet.date.other\", \"all\", \n          \"f.\"+tdate_b+\".facet.date.start\",\"2009-05-01T11:00:00Z\", \n          \"f.\"+tdate_b+\".facet.date.gap\",\"+3MONTHS\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // simple range facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong,\n          \"facet.range\",tlong,\n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"facet.range.end\",900);\n\n    // range facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range\",i1, \n          \"f.\"+i1+\".facet.range.start\",300, \n          \"f.\"+i1+\".facet.range.gap\",87, \n          \"facet.range.end\",900,\n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"f.\"+tlong+\".facet.range.end\",900);\n\n    // Test mincounts. Do NOT want to go through all the stuff where with validateControlData in query() method\n    // Purposely packing a _bunch_ of stuff together here to insure that the proper level of mincount is used for\n    // each\n    ModifiableSolrParams minParams = new ModifiableSolrParams();\n    minParams.set(\"q\",\"*:*\");\n    minParams.set(\"rows\", 1);\n    minParams.set(\"facet\", \"true\");\n    minParams.set(\"facet.missing\", \"true\");\n    minParams.set(\"facet.field\", i1);\n    minParams.set(\"facet.missing\", \"true\");\n    minParams.set(\"facet.mincount\", 2);\n\n    // Return a separate section of ranges over i1. Should respect global range mincount\n    minParams.set(\"facet.range\", i1);\n    minParams.set(\"f.\" + i1 + \".facet.range.start\", 0);\n    minParams.set(\"f.\" + i1 + \".facet.range.gap\", 200);\n    minParams.set(\"f.\" + i1 + \".facet.range.end\", 1200);\n    minParams.set(\"f.\" + i1 + \".facet.mincount\", 4);\n\n\n    // Return a separate section of ranges over tlong Should respect facet.mincount\n    minParams.add(\"facet.range\", tlong);\n    minParams.set(\"f.\" + tlong + \".facet.range.start\", 0);\n    minParams.set(\"f.\" + tlong + \".facet.range.gap\", 100);\n    minParams.set(\"f.\" + tlong + \".facet.range.end\", 1200);\n    // Repeat with a range type of date\n    minParams.add(\"facet.range\", tdate_b);\n    minParams.set(\"f.\" + tdate_b + \".facet.range.start\", \"2009-02-01T00:00:00Z\");\n    minParams.set(\"f.\" + tdate_b + \".facet.range.gap\", \"+1YEAR\");\n    minParams.set(\"f.\" + tdate_b + \".facet.range.end\", \"2011-01-01T00:00:00Z\");\n    minParams.set(\"f.\" + tdate_b + \".facet.mincount\", 3);\n\n    // Insure that global mincount is respected for facet queries\n    minParams.set(\"facet.query\", tdate_a + \":[2010-01-01T00:00:00Z TO 2011-01-01T00:00:00Z]\"); // Should return some counts\n    //minParams.set(\"facet.query\", tdate_a + \":[* TO *]\"); // Should be removed\n    minParams.add(\"facet.query\", tdate_b + \":[2008-01-01T00:00:00Z TO 2009-09-01T00:00:00Z]\"); // Should be removed from response\n\n\n    setDistributedParams(minParams);\n    QueryResponse minResp = queryServer(minParams);\n\n    ModifiableSolrParams eParams = new ModifiableSolrParams();\n    eParams.set(\"q\",tdate_b + \":[* TO *]\");\n    eParams.set(\"rows\", 1000);\n    eParams.set(\"fl\", tdate_b);\n    setDistributedParams(eParams);\n    QueryResponse eResp = queryServer(eParams);\n\n    // Check that exactly the right numbers of counts came through\n    assertEquals(\"Should be exactly 2 range facets returned after minCounts taken into account \", 3, minResp.getFacetRanges().size());\n    assertEquals(\"Should only be 1 query facets returned after minCounts taken into account \", 1, minResp.getFacetQuery().size());\n\n    checkMinCountsField(minResp.getFacetField(i1).getValues(), new Object[]{null, 55L}); // Should just be the null entries for field\n\n    checkMinCountsRange(minResp.getFacetRanges().get(0).getCounts(), new Object[]{\"0\", 5L}); // range on i1\n    checkMinCountsRange(minResp.getFacetRanges().get(1).getCounts(), new Object[]{\"0\", 3L, \"100\", 3L}); // range on tlong\n    checkMinCountsRange(minResp.getFacetRanges().get(2).getCounts(), new Object[]{\"2009-02-01T00:00:00Z\",  3L}); // date (range) on tvh\n\n    assertTrue(\"Should have a facet for tdate_a\", minResp.getFacetQuery().containsKey(\"a_n_tdt:[2010-01-01T00:00:00Z TO 2011-01-01T00:00:00Z]\"));\n    int qCount = minResp.getFacetQuery().get(\"a_n_tdt:[2010-01-01T00:00:00Z TO 2011-01-01T00:00:00Z]\");\n    assertEquals(\"tdate_a should be 5\", qCount, 5);\n\n    // Now let's do some queries, the above is getting too complex\n    minParams = new ModifiableSolrParams();\n    minParams.set(\"q\",\"*:*\");\n    minParams.set(\"rows\", 1);\n    minParams.set(\"facet\", \"true\");\n    minParams.set(\"facet.mincount\", 3);\n\n    minParams.set(\"facet.query\", tdate_a + \":[2010-01-01T00:00:00Z TO 2010-05-04T00:00:00Z]\");\n    minParams.add(\"facet.query\", tdate_b + \":[2009-01-01T00:00:00Z TO 2010-01-01T00:00:00Z]\"); // Should be removed\n    setDistributedParams(minParams);\n    minResp = queryServer(minParams);\n\n    assertEquals(\"Should only be 1 query facets returned after minCounts taken into account \", 1, minResp.getFacetQuery().size());\n    assertTrue(\"Should be an entry for a_n_tdt\", minResp.getFacetQuery().containsKey(\"a_n_tdt:[2010-01-01T00:00:00Z TO 2010-05-04T00:00:00Z]\"));\n    qCount = minResp.getFacetQuery().get(\"a_n_tdt:[2010-01-01T00:00:00Z TO 2010-05-04T00:00:00Z]\");\n    assertEquals(\"a_n_tdt should have a count of 4 \", qCount, 4);\n    //  variations of fl\n    query(\"q\",\"*:*\", \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1 + \",score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", i1, \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id,\" + i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1, \"fl\", \"id\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",nint, \"fl\",tint,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",nint, \"fl\", \"id\", \"fl\",tint,\"sort\",i1 + \" desc\");\n\n    // basic spellcheck testing\n    query(\"q\", \"toyata\", \"fl\", \"id,lowerfilt\", \"spellcheck\", true, \"spellcheck.q\", \"toyata\", \"qt\", \"spellCheckCompRH_Direct\", \"shards.qt\", \"spellCheckCompRH_Direct\");\n\n    stress=0;  // turn off stress... we want to tex max combos in min time\n    for (int i=0; i<25*RANDOM_MULTIPLIER; i++) {\n      String f = fieldNames[random().nextInt(fieldNames.length)];\n      if (random().nextBoolean()) f = t1;  // the text field is a really interesting one to facet on (and it's multi-valued too)\n\n      // we want a random query and not just *:* so we'll get zero counts in facets also\n      // TODO: do a better random query\n      String q = random().nextBoolean() ? \"*:*\" : \"id:(1 3 5 7 9 11 13) OR id:[100 TO \" + random().nextInt(50) + \"]\";\n\n      int nolimit = random().nextBoolean() ? -1 : 10000;  // these should be equivalent\n\n      // if limit==-1, we should always get exact matches\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"count\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      // for index sort, we should get exact results for mincount <= 1\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(2), \"facet.offset\",random().nextInt(10), \"facet.limit\",random().nextInt(11)-1);\n    }\n    stress = backupStress;  // restore stress\n\n    // test faceting multiple things at once\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1);\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id:[1 TO 7]\", \"fq\",\"{!tag=b}id:[3 TO 9]\"\n    );\n    query(\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\");\n\n    // test field that is valid in schema but missing in all shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2);\n    // test field that is valid in schema and missing in some shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2);\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", \"stats_dt\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1);\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", tdate_a);\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", tdate_b);\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \n          \"fq\", \"{!tag=nothing}-*:*\",\n          \"stats.field\", \"{!key=special_key ex=nothing}stats_dt\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \n          \"f.stats_dt.stats.calcdistinct\", \"true\",\n          \"stats.field\", \"{!key=special_key}stats_dt\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \n          \"f.stats_dt.stats.calcdistinct\", \"true\",\n          \"fq\", \"{!tag=xxx}id:[3 TO 9]\",\n          \"stats.field\", \"{!key=special_key}stats_dt\",\n          \"stats.field\", \"{!ex=xxx}stats_dt\");\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\",\n          // do a really simple query so distributed IDF doesn't cause problems\n          // when comparing with control collection\n          \"stats.field\", \"{!lucene key=q_key}\" + i1 + \"foo_b:true\",\n          \"stats.field\", \"{!func key=f_key}sum(\" + tlong +\",\"+i1+\")\");\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\",\n          \"stats.field\", \"stats_dt\",\n          \"stats.field\", i1,\n          \"stats.field\", tdate_a,\n          \"stats.field\", tdate_b);\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    // check a complex key name\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"*:*\", \"rows\",100);\n    }\n\n    //SOLR 3161 ensure shards.qt=/update fails (anything but search handler really)\n    // Also see TestRemoteStreaming#testQtUpdateFails()\n    try {\n      ignoreException(\"isShard is only acceptable\");\n      // query(\"q\",\"*:*\",\"shards.qt\",\"/update\",\"stream.body\",\"<delete><query>*:*</query></delete>\");\n      // fail();\n    } catch (SolrException e) {\n      //expected\n    }\n    unIgnoreException(\"isShard is only acceptable\");\n\n    // test debugging\n    // handle.put(\"explain\", UNORDERED);\n    handle.put(\"explain\", SKIPVAL);  // internal docids differ, idf differs w/o global idf\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    handle.put(\"track\", SKIP); //track is not included in single node search\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY);\n\n    // Check Info is added to for each shard\n    ModifiableSolrParams q = new ModifiableSolrParams();\n    q.set(\"q\", \"*:*\");\n    q.set(ShardParams.SHARDS_INFO, true);\n    setDistributedParams(q);\n    rsp = queryServer(q);\n    NamedList<?> sinfo = (NamedList<?>) rsp.getResponse().get(ShardParams.SHARDS_INFO);\n    String shards = getShardsString();\n    int cnt = StringUtils.countMatches(shards, \",\")+1;\n    \n    assertNotNull(\"missing shard info\", sinfo);\n    assertEquals(\"should have an entry for each shard [\"+sinfo+\"] \"+shards, cnt, sinfo.size());\n\n    // test shards.tolerant=true\n    for(int numDownServers = 0; numDownServers < jettys.size()-1; numDownServers++)\n    {\n      List<JettySolrRunner> upJettys = new ArrayList<>(jettys);\n      List<SolrServer> upClients = new ArrayList<>(clients);\n      List<JettySolrRunner> downJettys = new ArrayList<>();\n      List<String> upShards = new ArrayList<>(Arrays.asList(shardsArr));\n      for(int i=0; i<numDownServers; i++)\n      {\n        // shut down some of the jettys\n        int indexToRemove = r.nextInt(upJettys.size());\n        JettySolrRunner downJetty = upJettys.remove(indexToRemove);\n        upClients.remove(indexToRemove);\n        upShards.remove(indexToRemove);\n        ChaosMonkey.stop(downJetty);\n        downJettys.add(downJetty);\n      }\n\n      queryPartialResults(upShards, upClients, \n          \"q\",\"*:*\",\n          \"facet\",\"true\", \n          \"facet.field\",t1,\n          \"facet.field\",t1,\n          \"facet.limit\",5,\n          ShardParams.SHARDS_INFO,\"true\",\n          ShardParams.SHARDS_TOLERANT,\"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"facet\", \"true\",\n          \"facet.query\", i1 + \":[1 TO 50]\",\n          \"facet.query\", i1 + \":[1 TO 50]\",\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      // test group query\n      // TODO: Remove this? This doesn't make any real sense now that timeAllowed might trigger early\n      //       termination of the request during Terms enumeration/Query expansion.\n      //       During such an exit, partial results isn't supported as it wouldn't make any sense.\n      // Increasing the timeAllowed from 1 to 100 for now.\n      //\n      // TODO: still failing in jenkins - see SOLR-5986\n      //\n      // queryPartialResults(upShards, upClients,\n      //     \"q\", \"*:*\",\n      //     \"rows\", 100,\n      //     \"fl\", \"id,\" + i1,\n      //     \"group\", \"true\",\n      //     \"group.query\", t1 + \":kings OR \" + t1 + \":eggs\",\n      //     \"group.limit\", 10,\n      //     \"sort\", i1 + \" asc, id asc\",\n      //     CommonParams.TIME_ALLOWED, 100,\n      //     ShardParams.SHARDS_INFO, \"true\",\n      //     ShardParams.SHARDS_TOLERANT, \"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"stats\", \"true\",\n          \"stats.field\", i1,\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"toyata\",\n          \"spellcheck\", \"true\",\n          \"spellcheck.q\", \"toyata\",\n          \"qt\", \"spellCheckCompRH_Direct\",\n          \"shards.qt\", \"spellCheckCompRH_Direct\",\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      // restart the jettys\n      for (JettySolrRunner downJetty : downJettys) {\n        downJetty.start();\n      }\n    }\n\n    // This index has the same number for every field\n    \n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // Thread.sleep(10000000000L);\n\n    del(\"*:*\"); // delete all docs and test stats request\n    commit();\n    try {\n      query(\"q\", \"*:*\", \"stats\", \"true\", \n            \"stats.field\", \"stats_dt\", \n            \"stats.field\", i1, \n            \"stats.field\", tdate_a, \n            \"stats.field\", tdate_b,\n            \"stats.calcdistinct\", \"true\");\n    } catch (HttpSolrServer.RemoteSolrException e) {\n      if (e.getMessage().startsWith(\"java.lang.NullPointerException\"))  {\n        fail(\"NullPointerException with stats request on empty index\");\n      } else  {\n        throw e;\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  public void doTest() throws Exception {\n    QueryResponse rsp = null;\n    int backupStress = stress; // make a copy so we can restore\n\n\n    del(\"*:*\");\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\",\n           tdate_a, \"2010-04-20T11:00:00Z\",\n           tdate_b, \"2009-08-20T11:00:00Z\",\n           \"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\",\n           tdate_a, \"2010-05-02T11:00:00Z\",\n           tdate_b, \"2009-11-02T11:00:00Z\");\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\",\n           tdate_a, \"2010-05-03T11:00:00Z\");\n    indexr(id,4, i1, -100 ,tlong, 101,\n           t1,\"the quick fox jumped over the lazy dog\", \n           tdate_a, \"2010-05-03T11:00:00Z\",\n           tdate_b, \"2010-05-03T11:00:00Z\");\n    indexr(id,5, i1, 500, tlong, 500 ,\n           t1,\"the quick fox jumped way over the lazy dog\", \n           tdate_a, \"2010-05-05T11:00:00Z\");\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,\n           tdate_b, \"2010-01-05T11:00:00Z\",\n           t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n\n    commit();  // try to ensure there's more than one segment\n\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,\n           t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,\n           t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,\n           t1,\"no eggs on wall, lesson learned\", \n           oddField, \"odd man out\");\n\n    indexr(id, \"1001\", \"lowerfilt\", \"toyota\"); // for spellcheck\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n    \n    \n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n\n    handle.clear();\n    handle.put(\"timestamp\", SKIPVAL);\n    handle.put(\"_version_\", SKIPVAL); // not a cloud test, but may use updateLog\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(\"q\",\"*:*\", \"sort\",f+\" desc\");\n      query(\"q\",\"*:*\", \"sort\",f+\" asc\");\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",\"{!func}testfunc(add(\"+i1+\",5))\"+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" asc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\");\n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"*,score\"); \n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 desc\");\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"{!func}\"+i1);// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(\"q\",\"{!func}\"+i1, \"fl\",\"*,score\");  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"quick\");\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\");\n    query(\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\");  // no fields in returned docs\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\");\n\n    handle.put(\"score\", SKIPVAL);\n    query(\"q\",\"quick\",\"fl\",\"*,score\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\");\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"matchesnothing\",\"fl\",\"*,score\");  \n\n    // test that a single NOW value is propagated to all shards... if that is true\n    // then the primary sort should always be a tie and then the secondary should always decide\n    query(\"q\",\"{!func}ms(NOW)\", \"sort\",\"score desc,\"+i1+\" desc\",\"fl\",\"id\");    \n\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1, \"facet.field\",t1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\");\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2);\n\n    // a facet query to test out chars out of the ascii range\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!term f=foo_s}international\\u00ff\\u01ff\\u2222\\u3333\");\n\n    // simple field facet on date fields\n    rsp = query(\"q\",\"*:*\", \"rows\", 0,\n                \"facet\",\"true\", \"facet.limit\", 1, // TODO: limit shouldn't be needed: SOLR-6386\n                \"facet.field\", tdate_a);\n    assertEquals(1, rsp.getFacetFields().size());\n    rsp = query(\"q\",\"*:*\", \"rows\", 0,\n                \"facet\",\"true\", \"facet.limit\", 1, // TODO: limit shouldn't be needed: SOLR-6386\n                \"facet.field\", tdate_b, \"facet.field\", tdate_a);\n    assertEquals(2, rsp.getFacetFields().size());\n\n    // simple date facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a,\n          \"facet.date\",tdate_a,\n          \"facet.date.other\", \"all\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // date facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a,\n          \"facet.date\",tdate_b,\n          \"facet.date\",tdate_a,\n          \"facet.date.other\", \"all\", \n          \"f.\"+tdate_b+\".facet.date.start\",\"2009-05-01T11:00:00Z\", \n          \"f.\"+tdate_b+\".facet.date.gap\",\"+3MONTHS\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // simple range facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong,\n          \"facet.range\",tlong,\n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"facet.range.end\",900);\n\n    // range facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range\",i1, \n          \"f.\"+i1+\".facet.range.start\",300, \n          \"f.\"+i1+\".facet.range.gap\",87, \n          \"facet.range.end\",900,\n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"f.\"+tlong+\".facet.range.end\",900);\n\n    // Test mincounts. Do NOT want to go through all the stuff where with validateControlData in query() method\n    // Purposely packing a _bunch_ of stuff together here to insure that the proper level of mincount is used for\n    // each\n    ModifiableSolrParams minParams = new ModifiableSolrParams();\n    minParams.set(\"q\",\"*:*\");\n    minParams.set(\"rows\", 1);\n    minParams.set(\"facet\", \"true\");\n    minParams.set(\"facet.missing\", \"true\");\n    minParams.set(\"facet.field\", i1);\n    minParams.set(\"facet.missing\", \"true\");\n    minParams.set(\"facet.mincount\", 2);\n\n    // Return a separate section of ranges over i1. Should respect global range mincount\n    minParams.set(\"facet.range\", i1);\n    minParams.set(\"f.\" + i1 + \".facet.range.start\", 0);\n    minParams.set(\"f.\" + i1 + \".facet.range.gap\", 200);\n    minParams.set(\"f.\" + i1 + \".facet.range.end\", 1200);\n    minParams.set(\"f.\" + i1 + \".facet.mincount\", 4);\n\n\n    // Return a separate section of ranges over tlong Should respect facet.mincount\n    minParams.add(\"facet.range\", tlong);\n    minParams.set(\"f.\" + tlong + \".facet.range.start\", 0);\n    minParams.set(\"f.\" + tlong + \".facet.range.gap\", 100);\n    minParams.set(\"f.\" + tlong + \".facet.range.end\", 1200);\n    // Repeat with a range type of date\n    minParams.add(\"facet.range\", tdate_b);\n    minParams.set(\"f.\" + tdate_b + \".facet.range.start\", \"2009-02-01T00:00:00Z\");\n    minParams.set(\"f.\" + tdate_b + \".facet.range.gap\", \"+1YEAR\");\n    minParams.set(\"f.\" + tdate_b + \".facet.range.end\", \"2011-01-01T00:00:00Z\");\n    minParams.set(\"f.\" + tdate_b + \".facet.mincount\", 3);\n\n    // Insure that global mincount is respected for facet queries\n    minParams.set(\"facet.query\", tdate_a + \":[2010-01-01T00:00:00Z TO 2011-01-01T00:00:00Z]\"); // Should return some counts\n    //minParams.set(\"facet.query\", tdate_a + \":[* TO *]\"); // Should be removed\n    minParams.add(\"facet.query\", tdate_b + \":[2008-01-01T00:00:00Z TO 2009-09-01T00:00:00Z]\"); // Should be removed from response\n\n\n    setDistributedParams(minParams);\n    QueryResponse minResp = queryServer(minParams);\n\n    ModifiableSolrParams eParams = new ModifiableSolrParams();\n    eParams.set(\"q\",tdate_b + \":[* TO *]\");\n    eParams.set(\"rows\", 1000);\n    eParams.set(\"fl\", tdate_b);\n    setDistributedParams(eParams);\n    QueryResponse eResp = queryServer(eParams);\n\n    // Check that exactly the right numbers of counts came through\n    assertEquals(\"Should be exactly 2 range facets returned after minCounts taken into account \", 3, minResp.getFacetRanges().size());\n    assertEquals(\"Should only be 1 query facets returned after minCounts taken into account \", 1, minResp.getFacetQuery().size());\n\n    checkMinCountsField(minResp.getFacetField(i1).getValues(), new Object[]{null, 55L}); // Should just be the null entries for field\n\n    checkMinCountsRange(minResp.getFacetRanges().get(0).getCounts(), new Object[]{\"0\", 5L}); // range on i1\n    checkMinCountsRange(minResp.getFacetRanges().get(1).getCounts(), new Object[]{\"0\", 3L, \"100\", 3L}); // range on tlong\n    checkMinCountsRange(minResp.getFacetRanges().get(2).getCounts(), new Object[]{\"2009-02-01T00:00:00Z\",  3L}); // date (range) on tvh\n\n    assertTrue(\"Should have a facet for tdate_a\", minResp.getFacetQuery().containsKey(\"a_n_tdt:[2010-01-01T00:00:00Z TO 2011-01-01T00:00:00Z]\"));\n    int qCount = minResp.getFacetQuery().get(\"a_n_tdt:[2010-01-01T00:00:00Z TO 2011-01-01T00:00:00Z]\");\n    assertEquals(\"tdate_a should be 5\", qCount, 5);\n\n    // Now let's do some queries, the above is getting too complex\n    minParams = new ModifiableSolrParams();\n    minParams.set(\"q\",\"*:*\");\n    minParams.set(\"rows\", 1);\n    minParams.set(\"facet\", \"true\");\n    minParams.set(\"facet.mincount\", 3);\n\n    minParams.set(\"facet.query\", tdate_a + \":[2010-01-01T00:00:00Z TO 2010-05-04T00:00:00Z]\");\n    minParams.add(\"facet.query\", tdate_b + \":[2009-01-01T00:00:00Z TO 2010-01-01T00:00:00Z]\"); // Should be removed\n    setDistributedParams(minParams);\n    minResp = queryServer(minParams);\n\n    assertEquals(\"Should only be 1 query facets returned after minCounts taken into account \", 1, minResp.getFacetQuery().size());\n    assertTrue(\"Should be an entry for a_n_tdt\", minResp.getFacetQuery().containsKey(\"a_n_tdt:[2010-01-01T00:00:00Z TO 2010-05-04T00:00:00Z]\"));\n    qCount = minResp.getFacetQuery().get(\"a_n_tdt:[2010-01-01T00:00:00Z TO 2010-05-04T00:00:00Z]\");\n    assertEquals(\"a_n_tdt should have a count of 4 \", qCount, 4);\n    //  variations of fl\n    query(\"q\",\"*:*\", \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1 + \",score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", i1, \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id,\" + i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1, \"fl\", \"id\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",nint, \"fl\",tint,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",nint, \"fl\", \"id\", \"fl\",tint,\"sort\",i1 + \" desc\");\n\n    // basic spellcheck testing\n    query(\"q\", \"toyata\", \"fl\", \"id,lowerfilt\", \"spellcheck\", true, \"spellcheck.q\", \"toyata\", \"qt\", \"spellCheckCompRH_Direct\", \"shards.qt\", \"spellCheckCompRH_Direct\");\n\n    stress=0;  // turn off stress... we want to tex max combos in min time\n    for (int i=0; i<25*RANDOM_MULTIPLIER; i++) {\n      String f = fieldNames[random().nextInt(fieldNames.length)];\n      if (random().nextBoolean()) f = t1;  // the text field is a really interesting one to facet on (and it's multi-valued too)\n\n      // we want a random query and not just *:* so we'll get zero counts in facets also\n      // TODO: do a better random query\n      String q = random().nextBoolean() ? \"*:*\" : \"id:(1 3 5 7 9 11 13) OR id:[100 TO \" + random().nextInt(50) + \"]\";\n\n      int nolimit = random().nextBoolean() ? -1 : 10000;  // these should be equivalent\n\n      // if limit==-1, we should always get exact matches\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"count\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      // for index sort, we should get exact results for mincount <= 1\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(2), \"facet.offset\",random().nextInt(10), \"facet.limit\",random().nextInt(11)-1);\n    }\n    stress = backupStress;  // restore stress\n\n    // test faceting multiple things at once\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1);\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id:[1 TO 7]\", \"fq\",\"{!tag=b}id:[3 TO 9]\"\n    );\n    query(\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\");\n\n    // test field that is valid in schema but missing in all shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2);\n    // test field that is valid in schema and missing in some shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2);\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", \"stats_dt\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1);\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", tdate_a);\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", tdate_b);\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \n          \"fq\", \"{!tag=nothing}-*:*\",\n          \"stats.field\", \"{!key=special_key ex=nothing}stats_dt\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \n          \"f.stats_dt.stats.calcdistinct\", \"true\",\n          \"stats.field\", \"{!key=special_key}stats_dt\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \n          \"f.stats_dt.stats.calcdistinct\", \"true\",\n          \"fq\", \"{!tag=xxx}id:[3 TO 9]\",\n          \"stats.field\", \"{!key=special_key}stats_dt\",\n          \"stats.field\", \"{!ex=xxx}stats_dt\");\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\",\n          // do a really simple query so distributed IDF doesn't cause problems\n          // when comparing with control collection\n          \"stats.field\", \"{!lucene key=q_key}\" + i1 + \"foo_b:true\",\n          \"stats.field\", \"{!func key=f_key}sum(\" + tlong +\",\"+i1+\")\");\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\",\n          \"stats.field\", \"stats_dt\",\n          \"stats.field\", i1,\n          \"stats.field\", tdate_a,\n          \"stats.field\", tdate_b);\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    // check a complex key name\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"*:*\", \"rows\",100);\n    }\n\n    //SOLR 3161 ensure shards.qt=/update fails (anything but search handler really)\n    // Also see TestRemoteStreaming#testQtUpdateFails()\n    try {\n      ignoreException(\"isShard is only acceptable\");\n      // query(\"q\",\"*:*\",\"shards.qt\",\"/update\",\"stream.body\",\"<delete><query>*:*</query></delete>\");\n      // fail();\n    } catch (SolrException e) {\n      //expected\n    }\n    unIgnoreException(\"isShard is only acceptable\");\n\n    // test debugging\n    // handle.put(\"explain\", UNORDERED);\n    handle.put(\"explain\", SKIPVAL);  // internal docids differ, idf differs w/o global idf\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    handle.put(\"track\", SKIP); //track is not included in single node search\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY);\n\n    // Check Info is added to for each shard\n    ModifiableSolrParams q = new ModifiableSolrParams();\n    q.set(\"q\", \"*:*\");\n    q.set(ShardParams.SHARDS_INFO, true);\n    setDistributedParams(q);\n    rsp = queryServer(q);\n    NamedList<?> sinfo = (NamedList<?>) rsp.getResponse().get(ShardParams.SHARDS_INFO);\n    String shards = getShardsString();\n    int cnt = StringUtils.countMatches(shards, \",\")+1;\n    \n    assertNotNull(\"missing shard info\", sinfo);\n    assertEquals(\"should have an entry for each shard [\"+sinfo+\"] \"+shards, cnt, sinfo.size());\n\n    // test shards.tolerant=true\n    for(int numDownServers = 0; numDownServers < jettys.size()-1; numDownServers++)\n    {\n      List<JettySolrRunner> upJettys = new ArrayList<>(jettys);\n      List<SolrServer> upClients = new ArrayList<>(clients);\n      List<JettySolrRunner> downJettys = new ArrayList<>();\n      List<String> upShards = new ArrayList<>(Arrays.asList(shardsArr));\n      for(int i=0; i<numDownServers; i++)\n      {\n        // shut down some of the jettys\n        int indexToRemove = r.nextInt(upJettys.size());\n        JettySolrRunner downJetty = upJettys.remove(indexToRemove);\n        upClients.remove(indexToRemove);\n        upShards.remove(indexToRemove);\n        ChaosMonkey.stop(downJetty);\n        downJettys.add(downJetty);\n      }\n\n      queryPartialResults(upShards, upClients, \n          \"q\",\"*:*\",\n          \"facet\",\"true\", \n          \"facet.field\",t1,\n          \"facet.field\",t1,\n          \"facet.limit\",5,\n          ShardParams.SHARDS_INFO,\"true\",\n          ShardParams.SHARDS_TOLERANT,\"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"facet\", \"true\",\n          \"facet.query\", i1 + \":[1 TO 50]\",\n          \"facet.query\", i1 + \":[1 TO 50]\",\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      // test group query\n      // TODO: Remove this? This doesn't make any real sense now that timeAllowed might trigger early\n      //       termination of the request during Terms enumeration/Query expansion.\n      //       During such an exit, partial results isn't supported as it wouldn't make any sense.\n      // Increasing the timeAllowed from 1 to 100 for now.\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"rows\", 100,\n          \"fl\", \"id,\" + i1,\n          \"group\", \"true\",\n          \"group.query\", t1 + \":kings OR \" + t1 + \":eggs\",\n          \"group.limit\", 10,\n          \"sort\", i1 + \" asc, id asc\",\n          CommonParams.TIME_ALLOWED, 100,\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"stats\", \"true\",\n          \"stats.field\", i1,\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"toyata\",\n          \"spellcheck\", \"true\",\n          \"spellcheck.q\", \"toyata\",\n          \"qt\", \"spellCheckCompRH_Direct\",\n          \"shards.qt\", \"spellCheckCompRH_Direct\",\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      // restart the jettys\n      for (JettySolrRunner downJetty : downJettys) {\n        downJetty.start();\n      }\n    }\n\n    // This index has the same number for every field\n    \n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // Thread.sleep(10000000000L);\n\n    del(\"*:*\"); // delete all docs and test stats request\n    commit();\n    try {\n      query(\"q\", \"*:*\", \"stats\", \"true\", \n            \"stats.field\", \"stats_dt\", \n            \"stats.field\", i1, \n            \"stats.field\", tdate_a, \n            \"stats.field\", tdate_b,\n            \"stats.calcdistinct\", \"true\");\n    } catch (HttpSolrServer.RemoteSolrException e) {\n      if (e.getMessage().startsWith(\"java.lang.NullPointerException\"))  {\n        fail(\"NullPointerException with stats request on empty index\");\n      } else  {\n        throw e;\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d9a47902d6207303f5ed3e7aaca62ca33433af66","date":1412435312,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/TestDistributedSearch#doTest().mjava","pathOld":"solr/core/src/test/org/apache/solr/TestDistributedSearch#doTest().mjava","sourceNew":"  @Override\n  public void doTest() throws Exception {\n    QueryResponse rsp = null;\n    int backupStress = stress; // make a copy so we can restore\n\n\n    del(\"*:*\");\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\",\n           tdate_a, \"2010-04-20T11:00:00Z\",\n           tdate_b, \"2009-08-20T11:00:00Z\",\n           \"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\",\n           tdate_a, \"2010-05-02T11:00:00Z\",\n           tdate_b, \"2009-11-02T11:00:00Z\");\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\",\n           tdate_a, \"2010-05-03T11:00:00Z\");\n    indexr(id,4, i1, -100 ,tlong, 101,\n           t1,\"the quick fox jumped over the lazy dog\", \n           tdate_a, \"2010-05-03T11:00:00Z\",\n           tdate_b, \"2010-05-03T11:00:00Z\");\n    indexr(id,5, i1, 500, tlong, 500 ,\n           t1,\"the quick fox jumped way over the lazy dog\", \n           tdate_a, \"2010-05-05T11:00:00Z\");\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,\n           tdate_b, \"2010-01-05T11:00:00Z\",\n           t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n\n    commit();  // try to ensure there's more than one segment\n\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,\n           t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,\n           t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,\n           t1,\"no eggs on wall, lesson learned\", \n           oddField, \"odd man out\");\n\n    indexr(id, \"1001\", \"lowerfilt\", \"toyota\"); // for spellcheck\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n    \n    \n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n\n    handle.clear();\n    handle.put(\"timestamp\", SKIPVAL);\n    handle.put(\"_version_\", SKIPVAL); // not a cloud test, but may use updateLog\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(\"q\",\"*:*\", \"sort\",f+\" desc\");\n      query(\"q\",\"*:*\", \"sort\",f+\" asc\");\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",\"{!func}testfunc(add(\"+i1+\",5))\"+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" asc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\");\n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"*,score\"); \n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 desc\");\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"{!func}\"+i1);// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(\"q\",\"{!func}\"+i1, \"fl\",\"*,score\");  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"quick\");\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\");\n    query(\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\");  // no fields in returned docs\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\");\n\n    handle.put(\"score\", SKIPVAL);\n    query(\"q\",\"quick\",\"fl\",\"*,score\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\");\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"matchesnothing\",\"fl\",\"*,score\");  \n\n    // test that a single NOW value is propagated to all shards... if that is true\n    // then the primary sort should always be a tie and then the secondary should always decide\n    query(\"q\",\"{!func}ms(NOW)\", \"sort\",\"score desc,\"+i1+\" desc\",\"fl\",\"id\");    \n\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1, \"facet.field\",t1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\");\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2);\n\n    // a facet query to test out chars out of the ascii range\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!term f=foo_s}international\\u00ff\\u01ff\\u2222\\u3333\");\n\n    // simple field facet on date fields\n    rsp = query(\"q\",\"*:*\", \"rows\", 0,\n                \"facet\",\"true\", \"facet.limit\", 1, // TODO: limit shouldn't be needed: SOLR-6386\n                \"facet.field\", tdate_a);\n    assertEquals(1, rsp.getFacetFields().size());\n    rsp = query(\"q\",\"*:*\", \"rows\", 0,\n                \"facet\",\"true\", \"facet.limit\", 1, // TODO: limit shouldn't be needed: SOLR-6386\n                \"facet.field\", tdate_b, \"facet.field\", tdate_a);\n    assertEquals(2, rsp.getFacetFields().size());\n\n    // simple date facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a,\n          \"facet.date\",tdate_a,\n          \"facet.date.other\", \"all\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // date facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a,\n          \"facet.date\",tdate_b,\n          \"facet.date\",tdate_a,\n          \"facet.date.other\", \"all\", \n          \"f.\"+tdate_b+\".facet.date.start\",\"2009-05-01T11:00:00Z\", \n          \"f.\"+tdate_b+\".facet.date.gap\",\"+3MONTHS\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // simple range facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong,\n          \"facet.range\",tlong,\n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"facet.range.end\",900);\n\n    // range facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range\",i1, \n          \"f.\"+i1+\".facet.range.start\",300, \n          \"f.\"+i1+\".facet.range.gap\",87, \n          \"facet.range.end\",900,\n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"f.\"+tlong+\".facet.range.end\",900);\n\n    // Test mincounts. Do NOT want to go through all the stuff where with validateControlData in query() method\n    // Purposely packing a _bunch_ of stuff together here to insure that the proper level of mincount is used for\n    // each\n    ModifiableSolrParams minParams = new ModifiableSolrParams();\n    minParams.set(\"q\",\"*:*\");\n    minParams.set(\"rows\", 1);\n    minParams.set(\"facet\", \"true\");\n    minParams.set(\"facet.missing\", \"true\");\n    minParams.set(\"facet.field\", i1);\n    minParams.set(\"facet.missing\", \"true\");\n    minParams.set(\"facet.mincount\", 2);\n\n    // Return a separate section of ranges over i1. Should respect global range mincount\n    minParams.set(\"facet.range\", i1);\n    minParams.set(\"f.\" + i1 + \".facet.range.start\", 0);\n    minParams.set(\"f.\" + i1 + \".facet.range.gap\", 200);\n    minParams.set(\"f.\" + i1 + \".facet.range.end\", 1200);\n    minParams.set(\"f.\" + i1 + \".facet.mincount\", 4);\n\n\n    // Return a separate section of ranges over tlong Should respect facet.mincount\n    minParams.add(\"facet.range\", tlong);\n    minParams.set(\"f.\" + tlong + \".facet.range.start\", 0);\n    minParams.set(\"f.\" + tlong + \".facet.range.gap\", 100);\n    minParams.set(\"f.\" + tlong + \".facet.range.end\", 1200);\n    // Repeat with a range type of date\n    minParams.add(\"facet.range\", tdate_b);\n    minParams.set(\"f.\" + tdate_b + \".facet.range.start\", \"2009-02-01T00:00:00Z\");\n    minParams.set(\"f.\" + tdate_b + \".facet.range.gap\", \"+1YEAR\");\n    minParams.set(\"f.\" + tdate_b + \".facet.range.end\", \"2011-01-01T00:00:00Z\");\n    minParams.set(\"f.\" + tdate_b + \".facet.mincount\", 3);\n\n    // Insure that global mincount is respected for facet queries\n    minParams.set(\"facet.query\", tdate_a + \":[2010-01-01T00:00:00Z TO 2011-01-01T00:00:00Z]\"); // Should return some counts\n    //minParams.set(\"facet.query\", tdate_a + \":[* TO *]\"); // Should be removed\n    minParams.add(\"facet.query\", tdate_b + \":[2008-01-01T00:00:00Z TO 2009-09-01T00:00:00Z]\"); // Should be removed from response\n\n\n    setDistributedParams(minParams);\n    QueryResponse minResp = queryServer(minParams);\n\n    ModifiableSolrParams eParams = new ModifiableSolrParams();\n    eParams.set(\"q\",tdate_b + \":[* TO *]\");\n    eParams.set(\"rows\", 1000);\n    eParams.set(\"fl\", tdate_b);\n    setDistributedParams(eParams);\n    QueryResponse eResp = queryServer(eParams);\n\n    // Check that exactly the right numbers of counts came through\n    assertEquals(\"Should be exactly 2 range facets returned after minCounts taken into account \", 3, minResp.getFacetRanges().size());\n    assertEquals(\"Should only be 1 query facets returned after minCounts taken into account \", 1, minResp.getFacetQuery().size());\n\n    checkMinCountsField(minResp.getFacetField(i1).getValues(), new Object[]{null, 55L}); // Should just be the null entries for field\n\n    checkMinCountsRange(minResp.getFacetRanges().get(0).getCounts(), new Object[]{\"0\", 5L}); // range on i1\n    checkMinCountsRange(minResp.getFacetRanges().get(1).getCounts(), new Object[]{\"0\", 3L, \"100\", 3L}); // range on tlong\n    checkMinCountsRange(minResp.getFacetRanges().get(2).getCounts(), new Object[]{\"2009-02-01T00:00:00Z\",  3L}); // date (range) on tvh\n\n    assertTrue(\"Should have a facet for tdate_a\", minResp.getFacetQuery().containsKey(\"a_n_tdt:[2010-01-01T00:00:00Z TO 2011-01-01T00:00:00Z]\"));\n    int qCount = minResp.getFacetQuery().get(\"a_n_tdt:[2010-01-01T00:00:00Z TO 2011-01-01T00:00:00Z]\");\n    assertEquals(\"tdate_a should be 5\", qCount, 5);\n\n    // Now let's do some queries, the above is getting too complex\n    minParams = new ModifiableSolrParams();\n    minParams.set(\"q\",\"*:*\");\n    minParams.set(\"rows\", 1);\n    minParams.set(\"facet\", \"true\");\n    minParams.set(\"facet.mincount\", 3);\n\n    minParams.set(\"facet.query\", tdate_a + \":[2010-01-01T00:00:00Z TO 2010-05-04T00:00:00Z]\");\n    minParams.add(\"facet.query\", tdate_b + \":[2009-01-01T00:00:00Z TO 2010-01-01T00:00:00Z]\"); // Should be removed\n    setDistributedParams(minParams);\n    minResp = queryServer(minParams);\n\n    assertEquals(\"Should only be 1 query facets returned after minCounts taken into account \", 1, minResp.getFacetQuery().size());\n    assertTrue(\"Should be an entry for a_n_tdt\", minResp.getFacetQuery().containsKey(\"a_n_tdt:[2010-01-01T00:00:00Z TO 2010-05-04T00:00:00Z]\"));\n    qCount = minResp.getFacetQuery().get(\"a_n_tdt:[2010-01-01T00:00:00Z TO 2010-05-04T00:00:00Z]\");\n    assertEquals(\"a_n_tdt should have a count of 4 \", qCount, 4);\n    //  variations of fl\n    query(\"q\",\"*:*\", \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1 + \",score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", i1, \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id,\" + i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1, \"fl\", \"id\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",nint, \"fl\",tint,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",nint, \"fl\", \"id\", \"fl\",tint,\"sort\",i1 + \" desc\");\n\n    // basic spellcheck testing\n    query(\"q\", \"toyata\", \"fl\", \"id,lowerfilt\", \"spellcheck\", true, \"spellcheck.q\", \"toyata\", \"qt\", \"spellCheckCompRH_Direct\", \"shards.qt\", \"spellCheckCompRH_Direct\");\n\n    stress=0;  // turn off stress... we want to tex max combos in min time\n    for (int i=0; i<25*RANDOM_MULTIPLIER; i++) {\n      String f = fieldNames[random().nextInt(fieldNames.length)];\n      if (random().nextBoolean()) f = t1;  // the text field is a really interesting one to facet on (and it's multi-valued too)\n\n      // we want a random query and not just *:* so we'll get zero counts in facets also\n      // TODO: do a better random query\n      String q = random().nextBoolean() ? \"*:*\" : \"id:(1 3 5 7 9 11 13) OR id:[100 TO \" + random().nextInt(50) + \"]\";\n\n      int nolimit = random().nextBoolean() ? -1 : 10000;  // these should be equivalent\n\n      // if limit==-1, we should always get exact matches\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"count\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      // for index sort, we should get exact results for mincount <= 1\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(2), \"facet.offset\",random().nextInt(10), \"facet.limit\",random().nextInt(11)-1);\n    }\n    stress = backupStress;  // restore stress\n\n    // test faceting multiple things at once\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1);\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id:[1 TO 7]\", \"fq\",\"{!tag=b}id:[3 TO 9]\"\n    );\n    query(\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\");\n\n    // test field that is valid in schema but missing in all shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2);\n    // test field that is valid in schema and missing in some shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2);\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", \"stats_dt\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1);\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", tdate_a);\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", tdate_b);\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \n          \"fq\", \"{!tag=nothing}-*:*\",\n          \"stats.field\", \"{!key=special_key ex=nothing}stats_dt\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \n          \"f.stats_dt.stats.calcdistinct\", \"true\",\n          \"stats.field\", \"{!key=special_key}stats_dt\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \n          \"f.stats_dt.stats.calcdistinct\", \"true\",\n          \"fq\", \"{!tag=xxx}id:[3 TO 9]\",\n          \"stats.field\", \"{!key=special_key}stats_dt\",\n          \"stats.field\", \"{!ex=xxx}stats_dt\");\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\",\n          // do a really simple query so distributed IDF doesn't cause problems\n          // when comparing with control collection\n          \"stats.field\", \"{!lucene key=q_key}\" + i1 + \"foo_b:true\",\n          \"stats.field\", \"{!func key=f_key}sum(\" + tlong +\",\"+i1+\")\");\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\",\n          \"stats.field\", \"stats_dt\",\n          \"stats.field\", i1,\n          \"stats.field\", tdate_a,\n          \"stats.field\", tdate_b);\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    // check a complex key name\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"*:*\", \"rows\",100);\n    }\n\n    //SOLR 3161 ensure shards.qt=/update fails (anything but search handler really)\n    // Also see TestRemoteStreaming#testQtUpdateFails()\n    try {\n      ignoreException(\"isShard is only acceptable\");\n      // query(\"q\",\"*:*\",\"shards.qt\",\"/update\",\"stream.body\",\"<delete><query>*:*</query></delete>\");\n      // fail();\n    } catch (SolrException e) {\n      //expected\n    }\n    unIgnoreException(\"isShard is only acceptable\");\n\n    // test debugging\n    // handle.put(\"explain\", UNORDERED);\n    handle.put(\"explain\", SKIPVAL);  // internal docids differ, idf differs w/o global idf\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    handle.put(\"track\", SKIP); //track is not included in single node search\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY);\n\n    // Check Info is added to for each shard\n    ModifiableSolrParams q = new ModifiableSolrParams();\n    q.set(\"q\", \"*:*\");\n    q.set(ShardParams.SHARDS_INFO, true);\n    setDistributedParams(q);\n    rsp = queryServer(q);\n    NamedList<?> sinfo = (NamedList<?>) rsp.getResponse().get(ShardParams.SHARDS_INFO);\n    String shards = getShardsString();\n    int cnt = StringUtils.countMatches(shards, \",\")+1;\n    \n    assertNotNull(\"missing shard info\", sinfo);\n    assertEquals(\"should have an entry for each shard [\"+sinfo+\"] \"+shards, cnt, sinfo.size());\n\n    // test shards.tolerant=true\n    for(int numDownServers = 0; numDownServers < jettys.size()-1; numDownServers++)\n    {\n      List<JettySolrRunner> upJettys = new ArrayList<>(jettys);\n      List<SolrServer> upClients = new ArrayList<>(clients);\n      List<JettySolrRunner> downJettys = new ArrayList<>();\n      List<String> upShards = new ArrayList<>(Arrays.asList(shardsArr));\n      for(int i=0; i<numDownServers; i++)\n      {\n        // shut down some of the jettys\n        int indexToRemove = r.nextInt(upJettys.size());\n        JettySolrRunner downJetty = upJettys.remove(indexToRemove);\n        upClients.remove(indexToRemove);\n        upShards.remove(indexToRemove);\n        ChaosMonkey.stop(downJetty);\n        downJettys.add(downJetty);\n      }\n\n      queryPartialResults(upShards, upClients, \n          \"q\",\"*:*\",\n          \"facet\",\"true\", \n          \"facet.field\",t1,\n          \"facet.field\",t1,\n          \"facet.limit\",5,\n          ShardParams.SHARDS_INFO,\"true\",\n          ShardParams.SHARDS_TOLERANT,\"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"facet\", \"true\",\n          \"facet.query\", i1 + \":[1 TO 50]\",\n          \"facet.query\", i1 + \":[1 TO 50]\",\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      // test group query\n      // TODO: Remove this? This doesn't make any real sense now that timeAllowed might trigger early\n      //       termination of the request during Terms enumeration/Query expansion.\n      //       During such an exit, partial results isn't supported as it wouldn't make any sense.\n      // Increasing the timeAllowed from 1 to 100 for now.\n      //\n      // TODO: still failing in jenkins - see SOLR-5986\n      //\n      // queryPartialResults(upShards, upClients,\n      //     \"q\", \"*:*\",\n      //     \"rows\", 100,\n      //     \"fl\", \"id,\" + i1,\n      //     \"group\", \"true\",\n      //     \"group.query\", t1 + \":kings OR \" + t1 + \":eggs\",\n      //     \"group.limit\", 10,\n      //     \"sort\", i1 + \" asc, id asc\",\n      //     CommonParams.TIME_ALLOWED, 100,\n      //     ShardParams.SHARDS_INFO, \"true\",\n      //     ShardParams.SHARDS_TOLERANT, \"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"stats\", \"true\",\n          \"stats.field\", i1,\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"toyata\",\n          \"spellcheck\", \"true\",\n          \"spellcheck.q\", \"toyata\",\n          \"qt\", \"spellCheckCompRH_Direct\",\n          \"shards.qt\", \"spellCheckCompRH_Direct\",\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      // restart the jettys\n      for (JettySolrRunner downJetty : downJettys) {\n        downJetty.start();\n      }\n    }\n\n    // This index has the same number for every field\n    \n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // Thread.sleep(10000000000L);\n\n    del(\"*:*\"); // delete all docs and test stats request\n    commit();\n    try {\n      query(\"q\", \"*:*\", \"stats\", \"true\", \n            \"stats.field\", \"stats_dt\", \n            \"stats.field\", i1, \n            \"stats.field\", tdate_a, \n            \"stats.field\", tdate_b,\n            \"stats.calcdistinct\", \"true\");\n    } catch (HttpSolrServer.RemoteSolrException e) {\n      if (e.getMessage().startsWith(\"java.lang.NullPointerException\"))  {\n        fail(\"NullPointerException with stats request on empty index\");\n      } else  {\n        throw e;\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  public void doTest() throws Exception {\n    QueryResponse rsp = null;\n    int backupStress = stress; // make a copy so we can restore\n\n\n    del(\"*:*\");\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\",\n           tdate_a, \"2010-04-20T11:00:00Z\",\n           tdate_b, \"2009-08-20T11:00:00Z\",\n           \"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\",\n           tdate_a, \"2010-05-02T11:00:00Z\",\n           tdate_b, \"2009-11-02T11:00:00Z\");\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\",\n           tdate_a, \"2010-05-03T11:00:00Z\");\n    indexr(id,4, i1, -100 ,tlong, 101,\n           t1,\"the quick fox jumped over the lazy dog\", \n           tdate_a, \"2010-05-03T11:00:00Z\",\n           tdate_b, \"2010-05-03T11:00:00Z\");\n    indexr(id,5, i1, 500, tlong, 500 ,\n           t1,\"the quick fox jumped way over the lazy dog\", \n           tdate_a, \"2010-05-05T11:00:00Z\");\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,\n           tdate_b, \"2010-01-05T11:00:00Z\",\n           t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n\n    commit();  // try to ensure there's more than one segment\n\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,\n           t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,\n           t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,\n           t1,\"no eggs on wall, lesson learned\", \n           oddField, \"odd man out\");\n\n    indexr(id, \"1001\", \"lowerfilt\", \"toyota\"); // for spellcheck\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n    \n    \n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n\n    handle.clear();\n    handle.put(\"timestamp\", SKIPVAL);\n    handle.put(\"_version_\", SKIPVAL); // not a cloud test, but may use updateLog\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(\"q\",\"*:*\", \"sort\",f+\" desc\");\n      query(\"q\",\"*:*\", \"sort\",f+\" asc\");\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",\"{!func}testfunc(add(\"+i1+\",5))\"+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" asc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\");\n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"*,score\"); \n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 desc\");\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"{!func}\"+i1);// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(\"q\",\"{!func}\"+i1, \"fl\",\"*,score\");  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"quick\");\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\");\n    query(\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\");  // no fields in returned docs\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\");\n\n    handle.put(\"score\", SKIPVAL);\n    query(\"q\",\"quick\",\"fl\",\"*,score\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\");\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"matchesnothing\",\"fl\",\"*,score\");  \n\n    // test that a single NOW value is propagated to all shards... if that is true\n    // then the primary sort should always be a tie and then the secondary should always decide\n    query(\"q\",\"{!func}ms(NOW)\", \"sort\",\"score desc,\"+i1+\" desc\",\"fl\",\"id\");    \n\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1, \"facet.field\",t1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\");\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2);\n\n    // a facet query to test out chars out of the ascii range\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!term f=foo_s}international\\u00ff\\u01ff\\u2222\\u3333\");\n\n    // simple field facet on date fields\n    rsp = query(\"q\",\"*:*\", \"rows\", 0,\n                \"facet\",\"true\", \"facet.limit\", 1, // TODO: limit shouldn't be needed: SOLR-6386\n                \"facet.field\", tdate_a);\n    assertEquals(1, rsp.getFacetFields().size());\n    rsp = query(\"q\",\"*:*\", \"rows\", 0,\n                \"facet\",\"true\", \"facet.limit\", 1, // TODO: limit shouldn't be needed: SOLR-6386\n                \"facet.field\", tdate_b, \"facet.field\", tdate_a);\n    assertEquals(2, rsp.getFacetFields().size());\n\n    // simple date facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a,\n          \"facet.date\",tdate_a,\n          \"facet.date.other\", \"all\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // date facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a,\n          \"facet.date\",tdate_b,\n          \"facet.date\",tdate_a,\n          \"facet.date.other\", \"all\", \n          \"f.\"+tdate_b+\".facet.date.start\",\"2009-05-01T11:00:00Z\", \n          \"f.\"+tdate_b+\".facet.date.gap\",\"+3MONTHS\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // simple range facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong,\n          \"facet.range\",tlong,\n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"facet.range.end\",900);\n\n    // range facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range\",i1, \n          \"f.\"+i1+\".facet.range.start\",300, \n          \"f.\"+i1+\".facet.range.gap\",87, \n          \"facet.range.end\",900,\n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"f.\"+tlong+\".facet.range.end\",900);\n\n    // Test mincounts. Do NOT want to go through all the stuff where with validateControlData in query() method\n    // Purposely packing a _bunch_ of stuff together here to insure that the proper level of mincount is used for\n    // each\n    ModifiableSolrParams minParams = new ModifiableSolrParams();\n    minParams.set(\"q\",\"*:*\");\n    minParams.set(\"rows\", 1);\n    minParams.set(\"facet\", \"true\");\n    minParams.set(\"facet.missing\", \"true\");\n    minParams.set(\"facet.field\", i1);\n    minParams.set(\"facet.missing\", \"true\");\n    minParams.set(\"facet.mincount\", 2);\n\n    // Return a separate section of ranges over i1. Should respect global range mincount\n    minParams.set(\"facet.range\", i1);\n    minParams.set(\"f.\" + i1 + \".facet.range.start\", 0);\n    minParams.set(\"f.\" + i1 + \".facet.range.gap\", 200);\n    minParams.set(\"f.\" + i1 + \".facet.range.end\", 1200);\n    minParams.set(\"f.\" + i1 + \".facet.mincount\", 4);\n\n\n    // Return a separate section of ranges over tlong Should respect facet.mincount\n    minParams.add(\"facet.range\", tlong);\n    minParams.set(\"f.\" + tlong + \".facet.range.start\", 0);\n    minParams.set(\"f.\" + tlong + \".facet.range.gap\", 100);\n    minParams.set(\"f.\" + tlong + \".facet.range.end\", 1200);\n    // Repeat with a range type of date\n    minParams.add(\"facet.range\", tdate_b);\n    minParams.set(\"f.\" + tdate_b + \".facet.range.start\", \"2009-02-01T00:00:00Z\");\n    minParams.set(\"f.\" + tdate_b + \".facet.range.gap\", \"+1YEAR\");\n    minParams.set(\"f.\" + tdate_b + \".facet.range.end\", \"2011-01-01T00:00:00Z\");\n    minParams.set(\"f.\" + tdate_b + \".facet.mincount\", 3);\n\n    // Insure that global mincount is respected for facet queries\n    minParams.set(\"facet.query\", tdate_a + \":[2010-01-01T00:00:00Z TO 2011-01-01T00:00:00Z]\"); // Should return some counts\n    //minParams.set(\"facet.query\", tdate_a + \":[* TO *]\"); // Should be removed\n    minParams.add(\"facet.query\", tdate_b + \":[2008-01-01T00:00:00Z TO 2009-09-01T00:00:00Z]\"); // Should be removed from response\n\n\n    setDistributedParams(minParams);\n    QueryResponse minResp = queryServer(minParams);\n\n    ModifiableSolrParams eParams = new ModifiableSolrParams();\n    eParams.set(\"q\",tdate_b + \":[* TO *]\");\n    eParams.set(\"rows\", 1000);\n    eParams.set(\"fl\", tdate_b);\n    setDistributedParams(eParams);\n    QueryResponse eResp = queryServer(eParams);\n\n    // Check that exactly the right numbers of counts came through\n    assertEquals(\"Should be exactly 2 range facets returned after minCounts taken into account \", 3, minResp.getFacetRanges().size());\n    assertEquals(\"Should only be 1 query facets returned after minCounts taken into account \", 1, minResp.getFacetQuery().size());\n\n    checkMinCountsField(minResp.getFacetField(i1).getValues(), new Object[]{null, 55L}); // Should just be the null entries for field\n\n    checkMinCountsRange(minResp.getFacetRanges().get(0).getCounts(), new Object[]{\"0\", 5L}); // range on i1\n    checkMinCountsRange(minResp.getFacetRanges().get(1).getCounts(), new Object[]{\"0\", 3L, \"100\", 3L}); // range on tlong\n    checkMinCountsRange(minResp.getFacetRanges().get(2).getCounts(), new Object[]{\"2009-02-01T00:00:00Z\",  3L}); // date (range) on tvh\n\n    assertTrue(\"Should have a facet for tdate_a\", minResp.getFacetQuery().containsKey(\"a_n_tdt:[2010-01-01T00:00:00Z TO 2011-01-01T00:00:00Z]\"));\n    int qCount = minResp.getFacetQuery().get(\"a_n_tdt:[2010-01-01T00:00:00Z TO 2011-01-01T00:00:00Z]\");\n    assertEquals(\"tdate_a should be 5\", qCount, 5);\n\n    // Now let's do some queries, the above is getting too complex\n    minParams = new ModifiableSolrParams();\n    minParams.set(\"q\",\"*:*\");\n    minParams.set(\"rows\", 1);\n    minParams.set(\"facet\", \"true\");\n    minParams.set(\"facet.mincount\", 3);\n\n    minParams.set(\"facet.query\", tdate_a + \":[2010-01-01T00:00:00Z TO 2010-05-04T00:00:00Z]\");\n    minParams.add(\"facet.query\", tdate_b + \":[2009-01-01T00:00:00Z TO 2010-01-01T00:00:00Z]\"); // Should be removed\n    setDistributedParams(minParams);\n    minResp = queryServer(minParams);\n\n    assertEquals(\"Should only be 1 query facets returned after minCounts taken into account \", 1, minResp.getFacetQuery().size());\n    assertTrue(\"Should be an entry for a_n_tdt\", minResp.getFacetQuery().containsKey(\"a_n_tdt:[2010-01-01T00:00:00Z TO 2010-05-04T00:00:00Z]\"));\n    qCount = minResp.getFacetQuery().get(\"a_n_tdt:[2010-01-01T00:00:00Z TO 2010-05-04T00:00:00Z]\");\n    assertEquals(\"a_n_tdt should have a count of 4 \", qCount, 4);\n    //  variations of fl\n    query(\"q\",\"*:*\", \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1 + \",score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", i1, \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id,\" + i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1, \"fl\", \"id\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",nint, \"fl\",tint,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",nint, \"fl\", \"id\", \"fl\",tint,\"sort\",i1 + \" desc\");\n\n    // basic spellcheck testing\n    query(\"q\", \"toyata\", \"fl\", \"id,lowerfilt\", \"spellcheck\", true, \"spellcheck.q\", \"toyata\", \"qt\", \"spellCheckCompRH_Direct\", \"shards.qt\", \"spellCheckCompRH_Direct\");\n\n    stress=0;  // turn off stress... we want to tex max combos in min time\n    for (int i=0; i<25*RANDOM_MULTIPLIER; i++) {\n      String f = fieldNames[random().nextInt(fieldNames.length)];\n      if (random().nextBoolean()) f = t1;  // the text field is a really interesting one to facet on (and it's multi-valued too)\n\n      // we want a random query and not just *:* so we'll get zero counts in facets also\n      // TODO: do a better random query\n      String q = random().nextBoolean() ? \"*:*\" : \"id:(1 3 5 7 9 11 13) OR id:[100 TO \" + random().nextInt(50) + \"]\";\n\n      int nolimit = random().nextBoolean() ? -1 : 10000;  // these should be equivalent\n\n      // if limit==-1, we should always get exact matches\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"count\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      // for index sort, we should get exact results for mincount <= 1\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(2), \"facet.offset\",random().nextInt(10), \"facet.limit\",random().nextInt(11)-1);\n    }\n    stress = backupStress;  // restore stress\n\n    // test faceting multiple things at once\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1);\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id:[1 TO 7]\", \"fq\",\"{!tag=b}id:[3 TO 9]\"\n    );\n    query(\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\");\n\n    // test field that is valid in schema but missing in all shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2);\n    // test field that is valid in schema and missing in some shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2);\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", \"stats_dt\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1);\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", tdate_a);\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", tdate_b);\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \n          \"fq\", \"{!tag=nothing}-*:*\",\n          \"stats.field\", \"{!key=special_key ex=nothing}stats_dt\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \n          \"f.stats_dt.stats.calcdistinct\", \"true\",\n          \"stats.field\", \"{!key=special_key}stats_dt\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \n          \"f.stats_dt.stats.calcdistinct\", \"true\",\n          \"fq\", \"{!tag=xxx}id:[3 TO 9]\",\n          \"stats.field\", \"{!key=special_key}stats_dt\",\n          \"stats.field\", \"{!ex=xxx}stats_dt\");\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\",\n          // do a really simple query so distributed IDF doesn't cause problems\n          // when comparing with control collection\n          \"stats.field\", \"{!lucene key=q_key}\" + i1 + \"foo_b:true\",\n          \"stats.field\", \"{!func key=f_key}sum(\" + tlong +\",\"+i1+\")\");\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\",\n          \"stats.field\", \"stats_dt\",\n          \"stats.field\", i1,\n          \"stats.field\", tdate_a,\n          \"stats.field\", tdate_b);\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    // check a complex key name\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"*:*\", \"rows\",100);\n    }\n\n    //SOLR 3161 ensure shards.qt=/update fails (anything but search handler really)\n    // Also see TestRemoteStreaming#testQtUpdateFails()\n    try {\n      ignoreException(\"isShard is only acceptable\");\n      // query(\"q\",\"*:*\",\"shards.qt\",\"/update\",\"stream.body\",\"<delete><query>*:*</query></delete>\");\n      // fail();\n    } catch (SolrException e) {\n      //expected\n    }\n    unIgnoreException(\"isShard is only acceptable\");\n\n    // test debugging\n    // handle.put(\"explain\", UNORDERED);\n    handle.put(\"explain\", SKIPVAL);  // internal docids differ, idf differs w/o global idf\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    handle.put(\"track\", SKIP); //track is not included in single node search\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY);\n\n    // Check Info is added to for each shard\n    ModifiableSolrParams q = new ModifiableSolrParams();\n    q.set(\"q\", \"*:*\");\n    q.set(ShardParams.SHARDS_INFO, true);\n    setDistributedParams(q);\n    rsp = queryServer(q);\n    NamedList<?> sinfo = (NamedList<?>) rsp.getResponse().get(ShardParams.SHARDS_INFO);\n    String shards = getShardsString();\n    int cnt = StringUtils.countMatches(shards, \",\")+1;\n    \n    assertNotNull(\"missing shard info\", sinfo);\n    assertEquals(\"should have an entry for each shard [\"+sinfo+\"] \"+shards, cnt, sinfo.size());\n\n    // test shards.tolerant=true\n    for(int numDownServers = 0; numDownServers < jettys.size()-1; numDownServers++)\n    {\n      List<JettySolrRunner> upJettys = new ArrayList<>(jettys);\n      List<SolrServer> upClients = new ArrayList<>(clients);\n      List<JettySolrRunner> downJettys = new ArrayList<>();\n      List<String> upShards = new ArrayList<>(Arrays.asList(shardsArr));\n      for(int i=0; i<numDownServers; i++)\n      {\n        // shut down some of the jettys\n        int indexToRemove = r.nextInt(upJettys.size());\n        JettySolrRunner downJetty = upJettys.remove(indexToRemove);\n        upClients.remove(indexToRemove);\n        upShards.remove(indexToRemove);\n        ChaosMonkey.stop(downJetty);\n        downJettys.add(downJetty);\n      }\n\n      queryPartialResults(upShards, upClients, \n          \"q\",\"*:*\",\n          \"facet\",\"true\", \n          \"facet.field\",t1,\n          \"facet.field\",t1,\n          \"facet.limit\",5,\n          ShardParams.SHARDS_INFO,\"true\",\n          ShardParams.SHARDS_TOLERANT,\"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"facet\", \"true\",\n          \"facet.query\", i1 + \":[1 TO 50]\",\n          \"facet.query\", i1 + \":[1 TO 50]\",\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      // test group query\n      // TODO: Remove this? This doesn't make any real sense now that timeAllowed might trigger early\n      //       termination of the request during Terms enumeration/Query expansion.\n      //       During such an exit, partial results isn't supported as it wouldn't make any sense.\n      // Increasing the timeAllowed from 1 to 100 for now.\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"rows\", 100,\n          \"fl\", \"id,\" + i1,\n          \"group\", \"true\",\n          \"group.query\", t1 + \":kings OR \" + t1 + \":eggs\",\n          \"group.limit\", 10,\n          \"sort\", i1 + \" asc, id asc\",\n          CommonParams.TIME_ALLOWED, 100,\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"stats\", \"true\",\n          \"stats.field\", i1,\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"toyata\",\n          \"spellcheck\", \"true\",\n          \"spellcheck.q\", \"toyata\",\n          \"qt\", \"spellCheckCompRH_Direct\",\n          \"shards.qt\", \"spellCheckCompRH_Direct\",\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      // restart the jettys\n      for (JettySolrRunner downJetty : downJettys) {\n        downJetty.start();\n      }\n    }\n\n    // This index has the same number for every field\n    \n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // Thread.sleep(10000000000L);\n\n    del(\"*:*\"); // delete all docs and test stats request\n    commit();\n    try {\n      query(\"q\", \"*:*\", \"stats\", \"true\", \n            \"stats.field\", \"stats_dt\", \n            \"stats.field\", i1, \n            \"stats.field\", tdate_a, \n            \"stats.field\", tdate_b,\n            \"stats.calcdistinct\", \"true\");\n    } catch (HttpSolrServer.RemoteSolrException e) {\n      if (e.getMessage().startsWith(\"java.lang.NullPointerException\"))  {\n        fail(\"NullPointerException with stats request on empty index\");\n      } else  {\n        throw e;\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"659bd5da21bf2e51b42e1ad49c7107ad4ff1803f","date":1412786163,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/TestDistributedSearch#doTest().mjava","pathOld":"solr/core/src/test/org/apache/solr/TestDistributedSearch#doTest().mjava","sourceNew":"  @Override\n  public void doTest() throws Exception {\n    QueryResponse rsp = null;\n    int backupStress = stress; // make a copy so we can restore\n\n\n    del(\"*:*\");\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\",\n           tdate_a, \"2010-04-20T11:00:00Z\",\n           tdate_b, \"2009-08-20T11:00:00Z\",\n           \"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\",\n           tdate_a, \"2010-05-02T11:00:00Z\",\n           tdate_b, \"2009-11-02T11:00:00Z\");\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\",\n           tdate_a, \"2010-05-03T11:00:00Z\");\n    indexr(id,4, i1, -100 ,tlong, 101,\n           t1,\"the quick fox jumped over the lazy dog\", \n           tdate_a, \"2010-05-03T11:00:00Z\",\n           tdate_b, \"2010-05-03T11:00:00Z\");\n    indexr(id,5, i1, 500, tlong, 500 ,\n           t1,\"the quick fox jumped way over the lazy dog\", \n           tdate_a, \"2010-05-05T11:00:00Z\");\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,\n           tdate_b, \"2010-01-05T11:00:00Z\",\n           t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n\n    commit();  // try to ensure there's more than one segment\n\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,\n           t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,\n           t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,\n           t1,\"no eggs on wall, lesson learned\", \n           oddField, \"odd man out\");\n\n    indexr(id, \"1001\", \"lowerfilt\", \"toyota\"); // for spellcheck\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n    \n    \n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n\n    handle.clear();\n    handle.put(\"timestamp\", SKIPVAL);\n    handle.put(\"_version_\", SKIPVAL); // not a cloud test, but may use updateLog\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(\"q\",\"*:*\", \"sort\",f+\" desc\");\n      query(\"q\",\"*:*\", \"sort\",f+\" asc\");\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",\"{!func}testfunc(add(\"+i1+\",5))\"+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" asc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\");\n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"*,score\"); \n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 desc\");\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"{!func}\"+i1);// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(\"q\",\"{!func}\"+i1, \"fl\",\"*,score\");  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"quick\");\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\");\n    query(\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\");  // no fields in returned docs\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\");\n\n    handle.put(\"score\", SKIPVAL);\n    query(\"q\",\"quick\",\"fl\",\"*,score\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\");\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"matchesnothing\",\"fl\",\"*,score\");  \n\n    // test that a single NOW value is propagated to all shards... if that is true\n    // then the primary sort should always be a tie and then the secondary should always decide\n    query(\"q\",\"{!func}ms(NOW)\", \"sort\",\"score desc,\"+i1+\" desc\",\"fl\",\"id\");    \n\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1, \"facet.field\",t1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\");\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2);\n\n    // a facet query to test out chars out of the ascii range\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!term f=foo_s}international\\u00ff\\u01ff\\u2222\\u3333\");\n\n    // simple field facet on date fields\n    rsp = query(\"q\",\"*:*\", \"rows\", 0,\n                \"facet\",\"true\", \"facet.limit\", 1, // TODO: limit shouldn't be needed: SOLR-6386\n                \"facet.field\", tdate_a);\n    assertEquals(1, rsp.getFacetFields().size());\n    rsp = query(\"q\",\"*:*\", \"rows\", 0,\n                \"facet\",\"true\", \"facet.limit\", 1, // TODO: limit shouldn't be needed: SOLR-6386\n                \"facet.field\", tdate_b, \"facet.field\", tdate_a);\n    assertEquals(2, rsp.getFacetFields().size());\n\n    // simple date facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a,\n          \"facet.date\",tdate_a,\n          \"facet.date.other\", \"all\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // date facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a,\n          \"facet.date\",tdate_b,\n          \"facet.date\",tdate_a,\n          \"facet.date.other\", \"all\", \n          \"f.\"+tdate_b+\".facet.date.start\",\"2009-05-01T11:00:00Z\", \n          \"f.\"+tdate_b+\".facet.date.gap\",\"+3MONTHS\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // simple range facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong,\n          \"facet.range\",tlong,\n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"facet.range.end\",900);\n\n    // range facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range\",i1, \n          \"f.\"+i1+\".facet.range.start\",300, \n          \"f.\"+i1+\".facet.range.gap\",87, \n          \"facet.range.end\",900,\n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"f.\"+tlong+\".facet.range.end\",900);\n\n    // Test mincounts. Do NOT want to go through all the stuff where with validateControlData in query() method\n    // Purposely packing a _bunch_ of stuff together here to insure that the proper level of mincount is used for\n    // each\n    ModifiableSolrParams minParams = new ModifiableSolrParams();\n    minParams.set(\"q\",\"*:*\");\n    minParams.set(\"rows\", 1);\n    minParams.set(\"facet\", \"true\");\n    minParams.set(\"facet.missing\", \"true\");\n    minParams.set(\"facet.field\", i1);\n    minParams.set(\"facet.missing\", \"true\");\n    minParams.set(\"facet.mincount\", 2);\n\n    // Return a separate section of ranges over i1. Should respect global range mincount\n    minParams.set(\"facet.range\", i1);\n    minParams.set(\"f.\" + i1 + \".facet.range.start\", 0);\n    minParams.set(\"f.\" + i1 + \".facet.range.gap\", 200);\n    minParams.set(\"f.\" + i1 + \".facet.range.end\", 1200);\n    minParams.set(\"f.\" + i1 + \".facet.mincount\", 4);\n\n\n    // Return a separate section of ranges over tlong Should respect facet.mincount\n    minParams.add(\"facet.range\", tlong);\n    minParams.set(\"f.\" + tlong + \".facet.range.start\", 0);\n    minParams.set(\"f.\" + tlong + \".facet.range.gap\", 100);\n    minParams.set(\"f.\" + tlong + \".facet.range.end\", 1200);\n    // Repeat with a range type of date\n    minParams.add(\"facet.range\", tdate_b);\n    minParams.set(\"f.\" + tdate_b + \".facet.range.start\", \"2009-02-01T00:00:00Z\");\n    minParams.set(\"f.\" + tdate_b + \".facet.range.gap\", \"+1YEAR\");\n    minParams.set(\"f.\" + tdate_b + \".facet.range.end\", \"2011-01-01T00:00:00Z\");\n    minParams.set(\"f.\" + tdate_b + \".facet.mincount\", 3);\n\n    // Insure that global mincount is respected for facet queries\n    minParams.set(\"facet.query\", tdate_a + \":[2010-01-01T00:00:00Z TO 2011-01-01T00:00:00Z]\"); // Should return some counts\n    //minParams.set(\"facet.query\", tdate_a + \":[* TO *]\"); // Should be removed\n    minParams.add(\"facet.query\", tdate_b + \":[2008-01-01T00:00:00Z TO 2009-09-01T00:00:00Z]\"); // Should be removed from response\n\n\n    setDistributedParams(minParams);\n    QueryResponse minResp = queryServer(minParams);\n\n    ModifiableSolrParams eParams = new ModifiableSolrParams();\n    eParams.set(\"q\",tdate_b + \":[* TO *]\");\n    eParams.set(\"rows\", 1000);\n    eParams.set(\"fl\", tdate_b);\n    setDistributedParams(eParams);\n    QueryResponse eResp = queryServer(eParams);\n\n    // Check that exactly the right numbers of counts came through\n    assertEquals(\"Should be exactly 2 range facets returned after minCounts taken into account \", 3, minResp.getFacetRanges().size());\n    assertEquals(\"Should only be 1 query facets returned after minCounts taken into account \", 1, minResp.getFacetQuery().size());\n\n    checkMinCountsField(minResp.getFacetField(i1).getValues(), new Object[]{null, 55L}); // Should just be the null entries for field\n\n    checkMinCountsRange(minResp.getFacetRanges().get(0).getCounts(), new Object[]{\"0\", 5L}); // range on i1\n    checkMinCountsRange(minResp.getFacetRanges().get(1).getCounts(), new Object[]{\"0\", 3L, \"100\", 3L}); // range on tlong\n    checkMinCountsRange(minResp.getFacetRanges().get(2).getCounts(), new Object[]{\"2009-02-01T00:00:00Z\",  3L}); // date (range) on tvh\n\n    assertTrue(\"Should have a facet for tdate_a\", minResp.getFacetQuery().containsKey(\"a_n_tdt:[2010-01-01T00:00:00Z TO 2011-01-01T00:00:00Z]\"));\n    int qCount = minResp.getFacetQuery().get(\"a_n_tdt:[2010-01-01T00:00:00Z TO 2011-01-01T00:00:00Z]\");\n    assertEquals(\"tdate_a should be 5\", qCount, 5);\n\n    // Now let's do some queries, the above is getting too complex\n    minParams = new ModifiableSolrParams();\n    minParams.set(\"q\",\"*:*\");\n    minParams.set(\"rows\", 1);\n    minParams.set(\"facet\", \"true\");\n    minParams.set(\"facet.mincount\", 3);\n\n    minParams.set(\"facet.query\", tdate_a + \":[2010-01-01T00:00:00Z TO 2010-05-04T00:00:00Z]\");\n    minParams.add(\"facet.query\", tdate_b + \":[2009-01-01T00:00:00Z TO 2010-01-01T00:00:00Z]\"); // Should be removed\n    setDistributedParams(minParams);\n    minResp = queryServer(minParams);\n\n    assertEquals(\"Should only be 1 query facets returned after minCounts taken into account \", 1, minResp.getFacetQuery().size());\n    assertTrue(\"Should be an entry for a_n_tdt\", minResp.getFacetQuery().containsKey(\"a_n_tdt:[2010-01-01T00:00:00Z TO 2010-05-04T00:00:00Z]\"));\n    qCount = minResp.getFacetQuery().get(\"a_n_tdt:[2010-01-01T00:00:00Z TO 2010-05-04T00:00:00Z]\");\n    assertEquals(\"a_n_tdt should have a count of 4 \", qCount, 4);\n    //  variations of fl\n    query(\"q\",\"*:*\", \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1 + \",score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", i1, \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id,\" + i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1, \"fl\", \"id\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",nint, \"fl\",tint,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",nint, \"fl\", \"id\", \"fl\",tint,\"sort\",i1 + \" desc\");\n\n    // basic spellcheck testing\n    query(\"q\", \"toyata\", \"fl\", \"id,lowerfilt\", \"spellcheck\", true, \"spellcheck.q\", \"toyata\", \"qt\", \"spellCheckCompRH_Direct\", \"shards.qt\", \"spellCheckCompRH_Direct\");\n\n    stress=0;  // turn off stress... we want to tex max combos in min time\n    for (int i=0; i<25*RANDOM_MULTIPLIER; i++) {\n      String f = fieldNames[random().nextInt(fieldNames.length)];\n      if (random().nextBoolean()) f = t1;  // the text field is a really interesting one to facet on (and it's multi-valued too)\n\n      // we want a random query and not just *:* so we'll get zero counts in facets also\n      // TODO: do a better random query\n      String q = random().nextBoolean() ? \"*:*\" : \"id:(1 3 5 7 9 11 13) OR id:[100 TO \" + random().nextInt(50) + \"]\";\n\n      int nolimit = random().nextBoolean() ? -1 : 10000;  // these should be equivalent\n\n      // if limit==-1, we should always get exact matches\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"count\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      // for index sort, we should get exact results for mincount <= 1\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(2), \"facet.offset\",random().nextInt(10), \"facet.limit\",random().nextInt(11)-1);\n    }\n    stress = backupStress;  // restore stress\n\n    // test faceting multiple things at once\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1);\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id:[1 TO 7]\", \"fq\",\"{!tag=b}id:[3 TO 9]\"\n    );\n    query(\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\");\n\n    // test field that is valid in schema but missing in all shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2);\n    // test field that is valid in schema and missing in some shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2);\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", \"stats_dt\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1);\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", tdate_a);\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", tdate_b);\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \n          \"fq\", \"{!tag=nothing}-*:*\",\n          \"stats.field\", \"{!key=special_key ex=nothing}stats_dt\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \n          \"f.stats_dt.stats.calcdistinct\", \"true\",\n          \"stats.field\", \"{!key=special_key}stats_dt\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \n          \"f.stats_dt.stats.calcdistinct\", \"true\",\n          \"fq\", \"{!tag=xxx}id:[3 TO 9]\",\n          \"stats.field\", \"{!key=special_key}stats_dt\",\n          \"stats.field\", \"{!ex=xxx}stats_dt\");\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\",\n          // do a really simple query so distributed IDF doesn't cause problems\n          // when comparing with control collection\n          \"stats.field\", \"{!lucene key=q_key}\" + i1 + \"foo_b:true\",\n          \"stats.field\", \"{!func key=f_key}sum(\" + tlong +\",\"+i1+\")\");\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\",\n          \"stats.field\", \"stats_dt\",\n          \"stats.field\", i1,\n          \"stats.field\", tdate_a,\n          \"stats.field\", tdate_b);\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    // check a complex key name\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"*:*\", \"rows\",100);\n    }\n\n    //SOLR 3161 ensure shards.qt=/update fails (anything but search handler really)\n    // Also see TestRemoteStreaming#testQtUpdateFails()\n    try {\n      ignoreException(\"isShard is only acceptable\");\n      // query(\"q\",\"*:*\",\"shards.qt\",\"/update\",\"stream.body\",\"<delete><query>*:*</query></delete>\");\n      // fail();\n    } catch (SolrException e) {\n      //expected\n    }\n    unIgnoreException(\"isShard is only acceptable\");\n\n    // test debugging\n    // handle.put(\"explain\", UNORDERED);\n    handle.put(\"explain\", SKIPVAL);  // internal docids differ, idf differs w/o global idf\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    handle.put(\"track\", SKIP); //track is not included in single node search\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY);\n\n    // SOLR-6545, wild card field list\n    indexr(id, \"19\", \"text\", \"d\", \"cat_a_sS\", \"1\" ,t1, \"2\");\n    commit();\n\n    rsp = query(\"q\", \"id:19\", \"fl\", \"id\", \"fl\", \"*a_sS\");\n    assertFieldValues(rsp.getResults(), \"id\", 19);\n\n    rsp = query(\"q\", \"id:19\", \"fl\", \"id,\" + t1 + \",cat*\");\n    assertFieldValues(rsp.getResults(), \"id\", 19);\n\n    // Check Info is added to for each shard\n    ModifiableSolrParams q = new ModifiableSolrParams();\n    q.set(\"q\", \"*:*\");\n    q.set(ShardParams.SHARDS_INFO, true);\n    setDistributedParams(q);\n    rsp = queryServer(q);\n    NamedList<?> sinfo = (NamedList<?>) rsp.getResponse().get(ShardParams.SHARDS_INFO);\n    String shards = getShardsString();\n    int cnt = StringUtils.countMatches(shards, \",\")+1;\n    \n    assertNotNull(\"missing shard info\", sinfo);\n    assertEquals(\"should have an entry for each shard [\"+sinfo+\"] \"+shards, cnt, sinfo.size());\n\n    // test shards.tolerant=true\n    for(int numDownServers = 0; numDownServers < jettys.size()-1; numDownServers++)\n    {\n      List<JettySolrRunner> upJettys = new ArrayList<>(jettys);\n      List<SolrServer> upClients = new ArrayList<>(clients);\n      List<JettySolrRunner> downJettys = new ArrayList<>();\n      List<String> upShards = new ArrayList<>(Arrays.asList(shardsArr));\n      for(int i=0; i<numDownServers; i++)\n      {\n        // shut down some of the jettys\n        int indexToRemove = r.nextInt(upJettys.size());\n        JettySolrRunner downJetty = upJettys.remove(indexToRemove);\n        upClients.remove(indexToRemove);\n        upShards.remove(indexToRemove);\n        ChaosMonkey.stop(downJetty);\n        downJettys.add(downJetty);\n      }\n\n      queryPartialResults(upShards, upClients, \n          \"q\",\"*:*\",\n          \"facet\",\"true\", \n          \"facet.field\",t1,\n          \"facet.field\",t1,\n          \"facet.limit\",5,\n          ShardParams.SHARDS_INFO,\"true\",\n          ShardParams.SHARDS_TOLERANT,\"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"facet\", \"true\",\n          \"facet.query\", i1 + \":[1 TO 50]\",\n          \"facet.query\", i1 + \":[1 TO 50]\",\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      // test group query\n      // TODO: Remove this? This doesn't make any real sense now that timeAllowed might trigger early\n      //       termination of the request during Terms enumeration/Query expansion.\n      //       During such an exit, partial results isn't supported as it wouldn't make any sense.\n      // Increasing the timeAllowed from 1 to 100 for now.\n      //\n      // TODO: still failing in jenkins - see SOLR-5986\n      //\n      // queryPartialResults(upShards, upClients,\n      //     \"q\", \"*:*\",\n      //     \"rows\", 100,\n      //     \"fl\", \"id,\" + i1,\n      //     \"group\", \"true\",\n      //     \"group.query\", t1 + \":kings OR \" + t1 + \":eggs\",\n      //     \"group.limit\", 10,\n      //     \"sort\", i1 + \" asc, id asc\",\n      //     CommonParams.TIME_ALLOWED, 100,\n      //     ShardParams.SHARDS_INFO, \"true\",\n      //     ShardParams.SHARDS_TOLERANT, \"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"stats\", \"true\",\n          \"stats.field\", i1,\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"toyata\",\n          \"spellcheck\", \"true\",\n          \"spellcheck.q\", \"toyata\",\n          \"qt\", \"spellCheckCompRH_Direct\",\n          \"shards.qt\", \"spellCheckCompRH_Direct\",\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      // restart the jettys\n      for (JettySolrRunner downJetty : downJettys) {\n        downJetty.start();\n      }\n    }\n\n    // This index has the same number for every field\n    \n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // Thread.sleep(10000000000L);\n\n    del(\"*:*\"); // delete all docs and test stats request\n    commit();\n    try {\n      query(\"q\", \"*:*\", \"stats\", \"true\", \n            \"stats.field\", \"stats_dt\", \n            \"stats.field\", i1, \n            \"stats.field\", tdate_a, \n            \"stats.field\", tdate_b,\n            \"stats.calcdistinct\", \"true\");\n    } catch (HttpSolrServer.RemoteSolrException e) {\n      if (e.getMessage().startsWith(\"java.lang.NullPointerException\"))  {\n        fail(\"NullPointerException with stats request on empty index\");\n      } else  {\n        throw e;\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  public void doTest() throws Exception {\n    QueryResponse rsp = null;\n    int backupStress = stress; // make a copy so we can restore\n\n\n    del(\"*:*\");\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\",\n           tdate_a, \"2010-04-20T11:00:00Z\",\n           tdate_b, \"2009-08-20T11:00:00Z\",\n           \"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\",\n           tdate_a, \"2010-05-02T11:00:00Z\",\n           tdate_b, \"2009-11-02T11:00:00Z\");\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\",\n           tdate_a, \"2010-05-03T11:00:00Z\");\n    indexr(id,4, i1, -100 ,tlong, 101,\n           t1,\"the quick fox jumped over the lazy dog\", \n           tdate_a, \"2010-05-03T11:00:00Z\",\n           tdate_b, \"2010-05-03T11:00:00Z\");\n    indexr(id,5, i1, 500, tlong, 500 ,\n           t1,\"the quick fox jumped way over the lazy dog\", \n           tdate_a, \"2010-05-05T11:00:00Z\");\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,\n           tdate_b, \"2010-01-05T11:00:00Z\",\n           t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n\n    commit();  // try to ensure there's more than one segment\n\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,\n           t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,\n           t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,\n           t1,\"no eggs on wall, lesson learned\", \n           oddField, \"odd man out\");\n\n    indexr(id, \"1001\", \"lowerfilt\", \"toyota\"); // for spellcheck\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n    \n    \n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n\n    handle.clear();\n    handle.put(\"timestamp\", SKIPVAL);\n    handle.put(\"_version_\", SKIPVAL); // not a cloud test, but may use updateLog\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(\"q\",\"*:*\", \"sort\",f+\" desc\");\n      query(\"q\",\"*:*\", \"sort\",f+\" asc\");\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",\"{!func}testfunc(add(\"+i1+\",5))\"+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" asc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\");\n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"*,score\"); \n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 desc\");\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"{!func}\"+i1);// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(\"q\",\"{!func}\"+i1, \"fl\",\"*,score\");  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"quick\");\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\");\n    query(\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\");  // no fields in returned docs\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\");\n\n    handle.put(\"score\", SKIPVAL);\n    query(\"q\",\"quick\",\"fl\",\"*,score\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\");\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"matchesnothing\",\"fl\",\"*,score\");  \n\n    // test that a single NOW value is propagated to all shards... if that is true\n    // then the primary sort should always be a tie and then the secondary should always decide\n    query(\"q\",\"{!func}ms(NOW)\", \"sort\",\"score desc,\"+i1+\" desc\",\"fl\",\"id\");    \n\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1, \"facet.field\",t1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\");\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2);\n\n    // a facet query to test out chars out of the ascii range\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!term f=foo_s}international\\u00ff\\u01ff\\u2222\\u3333\");\n\n    // simple field facet on date fields\n    rsp = query(\"q\",\"*:*\", \"rows\", 0,\n                \"facet\",\"true\", \"facet.limit\", 1, // TODO: limit shouldn't be needed: SOLR-6386\n                \"facet.field\", tdate_a);\n    assertEquals(1, rsp.getFacetFields().size());\n    rsp = query(\"q\",\"*:*\", \"rows\", 0,\n                \"facet\",\"true\", \"facet.limit\", 1, // TODO: limit shouldn't be needed: SOLR-6386\n                \"facet.field\", tdate_b, \"facet.field\", tdate_a);\n    assertEquals(2, rsp.getFacetFields().size());\n\n    // simple date facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a,\n          \"facet.date\",tdate_a,\n          \"facet.date.other\", \"all\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // date facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a,\n          \"facet.date\",tdate_b,\n          \"facet.date\",tdate_a,\n          \"facet.date.other\", \"all\", \n          \"f.\"+tdate_b+\".facet.date.start\",\"2009-05-01T11:00:00Z\", \n          \"f.\"+tdate_b+\".facet.date.gap\",\"+3MONTHS\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // simple range facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong,\n          \"facet.range\",tlong,\n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"facet.range.end\",900);\n\n    // range facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range\",i1, \n          \"f.\"+i1+\".facet.range.start\",300, \n          \"f.\"+i1+\".facet.range.gap\",87, \n          \"facet.range.end\",900,\n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"f.\"+tlong+\".facet.range.end\",900);\n\n    // Test mincounts. Do NOT want to go through all the stuff where with validateControlData in query() method\n    // Purposely packing a _bunch_ of stuff together here to insure that the proper level of mincount is used for\n    // each\n    ModifiableSolrParams minParams = new ModifiableSolrParams();\n    minParams.set(\"q\",\"*:*\");\n    minParams.set(\"rows\", 1);\n    minParams.set(\"facet\", \"true\");\n    minParams.set(\"facet.missing\", \"true\");\n    minParams.set(\"facet.field\", i1);\n    minParams.set(\"facet.missing\", \"true\");\n    minParams.set(\"facet.mincount\", 2);\n\n    // Return a separate section of ranges over i1. Should respect global range mincount\n    minParams.set(\"facet.range\", i1);\n    minParams.set(\"f.\" + i1 + \".facet.range.start\", 0);\n    minParams.set(\"f.\" + i1 + \".facet.range.gap\", 200);\n    minParams.set(\"f.\" + i1 + \".facet.range.end\", 1200);\n    minParams.set(\"f.\" + i1 + \".facet.mincount\", 4);\n\n\n    // Return a separate section of ranges over tlong Should respect facet.mincount\n    minParams.add(\"facet.range\", tlong);\n    minParams.set(\"f.\" + tlong + \".facet.range.start\", 0);\n    minParams.set(\"f.\" + tlong + \".facet.range.gap\", 100);\n    minParams.set(\"f.\" + tlong + \".facet.range.end\", 1200);\n    // Repeat with a range type of date\n    minParams.add(\"facet.range\", tdate_b);\n    minParams.set(\"f.\" + tdate_b + \".facet.range.start\", \"2009-02-01T00:00:00Z\");\n    minParams.set(\"f.\" + tdate_b + \".facet.range.gap\", \"+1YEAR\");\n    minParams.set(\"f.\" + tdate_b + \".facet.range.end\", \"2011-01-01T00:00:00Z\");\n    minParams.set(\"f.\" + tdate_b + \".facet.mincount\", 3);\n\n    // Insure that global mincount is respected for facet queries\n    minParams.set(\"facet.query\", tdate_a + \":[2010-01-01T00:00:00Z TO 2011-01-01T00:00:00Z]\"); // Should return some counts\n    //minParams.set(\"facet.query\", tdate_a + \":[* TO *]\"); // Should be removed\n    minParams.add(\"facet.query\", tdate_b + \":[2008-01-01T00:00:00Z TO 2009-09-01T00:00:00Z]\"); // Should be removed from response\n\n\n    setDistributedParams(minParams);\n    QueryResponse minResp = queryServer(minParams);\n\n    ModifiableSolrParams eParams = new ModifiableSolrParams();\n    eParams.set(\"q\",tdate_b + \":[* TO *]\");\n    eParams.set(\"rows\", 1000);\n    eParams.set(\"fl\", tdate_b);\n    setDistributedParams(eParams);\n    QueryResponse eResp = queryServer(eParams);\n\n    // Check that exactly the right numbers of counts came through\n    assertEquals(\"Should be exactly 2 range facets returned after minCounts taken into account \", 3, minResp.getFacetRanges().size());\n    assertEquals(\"Should only be 1 query facets returned after minCounts taken into account \", 1, minResp.getFacetQuery().size());\n\n    checkMinCountsField(minResp.getFacetField(i1).getValues(), new Object[]{null, 55L}); // Should just be the null entries for field\n\n    checkMinCountsRange(minResp.getFacetRanges().get(0).getCounts(), new Object[]{\"0\", 5L}); // range on i1\n    checkMinCountsRange(minResp.getFacetRanges().get(1).getCounts(), new Object[]{\"0\", 3L, \"100\", 3L}); // range on tlong\n    checkMinCountsRange(minResp.getFacetRanges().get(2).getCounts(), new Object[]{\"2009-02-01T00:00:00Z\",  3L}); // date (range) on tvh\n\n    assertTrue(\"Should have a facet for tdate_a\", minResp.getFacetQuery().containsKey(\"a_n_tdt:[2010-01-01T00:00:00Z TO 2011-01-01T00:00:00Z]\"));\n    int qCount = minResp.getFacetQuery().get(\"a_n_tdt:[2010-01-01T00:00:00Z TO 2011-01-01T00:00:00Z]\");\n    assertEquals(\"tdate_a should be 5\", qCount, 5);\n\n    // Now let's do some queries, the above is getting too complex\n    minParams = new ModifiableSolrParams();\n    minParams.set(\"q\",\"*:*\");\n    minParams.set(\"rows\", 1);\n    minParams.set(\"facet\", \"true\");\n    minParams.set(\"facet.mincount\", 3);\n\n    minParams.set(\"facet.query\", tdate_a + \":[2010-01-01T00:00:00Z TO 2010-05-04T00:00:00Z]\");\n    minParams.add(\"facet.query\", tdate_b + \":[2009-01-01T00:00:00Z TO 2010-01-01T00:00:00Z]\"); // Should be removed\n    setDistributedParams(minParams);\n    minResp = queryServer(minParams);\n\n    assertEquals(\"Should only be 1 query facets returned after minCounts taken into account \", 1, minResp.getFacetQuery().size());\n    assertTrue(\"Should be an entry for a_n_tdt\", minResp.getFacetQuery().containsKey(\"a_n_tdt:[2010-01-01T00:00:00Z TO 2010-05-04T00:00:00Z]\"));\n    qCount = minResp.getFacetQuery().get(\"a_n_tdt:[2010-01-01T00:00:00Z TO 2010-05-04T00:00:00Z]\");\n    assertEquals(\"a_n_tdt should have a count of 4 \", qCount, 4);\n    //  variations of fl\n    query(\"q\",\"*:*\", \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1 + \",score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", i1, \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id,\" + i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1, \"fl\", \"id\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",nint, \"fl\",tint,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",nint, \"fl\", \"id\", \"fl\",tint,\"sort\",i1 + \" desc\");\n\n    // basic spellcheck testing\n    query(\"q\", \"toyata\", \"fl\", \"id,lowerfilt\", \"spellcheck\", true, \"spellcheck.q\", \"toyata\", \"qt\", \"spellCheckCompRH_Direct\", \"shards.qt\", \"spellCheckCompRH_Direct\");\n\n    stress=0;  // turn off stress... we want to tex max combos in min time\n    for (int i=0; i<25*RANDOM_MULTIPLIER; i++) {\n      String f = fieldNames[random().nextInt(fieldNames.length)];\n      if (random().nextBoolean()) f = t1;  // the text field is a really interesting one to facet on (and it's multi-valued too)\n\n      // we want a random query and not just *:* so we'll get zero counts in facets also\n      // TODO: do a better random query\n      String q = random().nextBoolean() ? \"*:*\" : \"id:(1 3 5 7 9 11 13) OR id:[100 TO \" + random().nextInt(50) + \"]\";\n\n      int nolimit = random().nextBoolean() ? -1 : 10000;  // these should be equivalent\n\n      // if limit==-1, we should always get exact matches\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"count\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      // for index sort, we should get exact results for mincount <= 1\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(2), \"facet.offset\",random().nextInt(10), \"facet.limit\",random().nextInt(11)-1);\n    }\n    stress = backupStress;  // restore stress\n\n    // test faceting multiple things at once\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1);\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id:[1 TO 7]\", \"fq\",\"{!tag=b}id:[3 TO 9]\"\n    );\n    query(\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\");\n\n    // test field that is valid in schema but missing in all shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2);\n    // test field that is valid in schema and missing in some shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2);\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", \"stats_dt\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1);\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", tdate_a);\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", tdate_b);\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \n          \"fq\", \"{!tag=nothing}-*:*\",\n          \"stats.field\", \"{!key=special_key ex=nothing}stats_dt\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \n          \"f.stats_dt.stats.calcdistinct\", \"true\",\n          \"stats.field\", \"{!key=special_key}stats_dt\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \n          \"f.stats_dt.stats.calcdistinct\", \"true\",\n          \"fq\", \"{!tag=xxx}id:[3 TO 9]\",\n          \"stats.field\", \"{!key=special_key}stats_dt\",\n          \"stats.field\", \"{!ex=xxx}stats_dt\");\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\",\n          // do a really simple query so distributed IDF doesn't cause problems\n          // when comparing with control collection\n          \"stats.field\", \"{!lucene key=q_key}\" + i1 + \"foo_b:true\",\n          \"stats.field\", \"{!func key=f_key}sum(\" + tlong +\",\"+i1+\")\");\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\",\n          \"stats.field\", \"stats_dt\",\n          \"stats.field\", i1,\n          \"stats.field\", tdate_a,\n          \"stats.field\", tdate_b);\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    // check a complex key name\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"*:*\", \"rows\",100);\n    }\n\n    //SOLR 3161 ensure shards.qt=/update fails (anything but search handler really)\n    // Also see TestRemoteStreaming#testQtUpdateFails()\n    try {\n      ignoreException(\"isShard is only acceptable\");\n      // query(\"q\",\"*:*\",\"shards.qt\",\"/update\",\"stream.body\",\"<delete><query>*:*</query></delete>\");\n      // fail();\n    } catch (SolrException e) {\n      //expected\n    }\n    unIgnoreException(\"isShard is only acceptable\");\n\n    // test debugging\n    // handle.put(\"explain\", UNORDERED);\n    handle.put(\"explain\", SKIPVAL);  // internal docids differ, idf differs w/o global idf\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    handle.put(\"track\", SKIP); //track is not included in single node search\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY);\n\n    // Check Info is added to for each shard\n    ModifiableSolrParams q = new ModifiableSolrParams();\n    q.set(\"q\", \"*:*\");\n    q.set(ShardParams.SHARDS_INFO, true);\n    setDistributedParams(q);\n    rsp = queryServer(q);\n    NamedList<?> sinfo = (NamedList<?>) rsp.getResponse().get(ShardParams.SHARDS_INFO);\n    String shards = getShardsString();\n    int cnt = StringUtils.countMatches(shards, \",\")+1;\n    \n    assertNotNull(\"missing shard info\", sinfo);\n    assertEquals(\"should have an entry for each shard [\"+sinfo+\"] \"+shards, cnt, sinfo.size());\n\n    // test shards.tolerant=true\n    for(int numDownServers = 0; numDownServers < jettys.size()-1; numDownServers++)\n    {\n      List<JettySolrRunner> upJettys = new ArrayList<>(jettys);\n      List<SolrServer> upClients = new ArrayList<>(clients);\n      List<JettySolrRunner> downJettys = new ArrayList<>();\n      List<String> upShards = new ArrayList<>(Arrays.asList(shardsArr));\n      for(int i=0; i<numDownServers; i++)\n      {\n        // shut down some of the jettys\n        int indexToRemove = r.nextInt(upJettys.size());\n        JettySolrRunner downJetty = upJettys.remove(indexToRemove);\n        upClients.remove(indexToRemove);\n        upShards.remove(indexToRemove);\n        ChaosMonkey.stop(downJetty);\n        downJettys.add(downJetty);\n      }\n\n      queryPartialResults(upShards, upClients, \n          \"q\",\"*:*\",\n          \"facet\",\"true\", \n          \"facet.field\",t1,\n          \"facet.field\",t1,\n          \"facet.limit\",5,\n          ShardParams.SHARDS_INFO,\"true\",\n          ShardParams.SHARDS_TOLERANT,\"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"facet\", \"true\",\n          \"facet.query\", i1 + \":[1 TO 50]\",\n          \"facet.query\", i1 + \":[1 TO 50]\",\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      // test group query\n      // TODO: Remove this? This doesn't make any real sense now that timeAllowed might trigger early\n      //       termination of the request during Terms enumeration/Query expansion.\n      //       During such an exit, partial results isn't supported as it wouldn't make any sense.\n      // Increasing the timeAllowed from 1 to 100 for now.\n      //\n      // TODO: still failing in jenkins - see SOLR-5986\n      //\n      // queryPartialResults(upShards, upClients,\n      //     \"q\", \"*:*\",\n      //     \"rows\", 100,\n      //     \"fl\", \"id,\" + i1,\n      //     \"group\", \"true\",\n      //     \"group.query\", t1 + \":kings OR \" + t1 + \":eggs\",\n      //     \"group.limit\", 10,\n      //     \"sort\", i1 + \" asc, id asc\",\n      //     CommonParams.TIME_ALLOWED, 100,\n      //     ShardParams.SHARDS_INFO, \"true\",\n      //     ShardParams.SHARDS_TOLERANT, \"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"stats\", \"true\",\n          \"stats.field\", i1,\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"toyata\",\n          \"spellcheck\", \"true\",\n          \"spellcheck.q\", \"toyata\",\n          \"qt\", \"spellCheckCompRH_Direct\",\n          \"shards.qt\", \"spellCheckCompRH_Direct\",\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      // restart the jettys\n      for (JettySolrRunner downJetty : downJettys) {\n        downJetty.start();\n      }\n    }\n\n    // This index has the same number for every field\n    \n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // Thread.sleep(10000000000L);\n\n    del(\"*:*\"); // delete all docs and test stats request\n    commit();\n    try {\n      query(\"q\", \"*:*\", \"stats\", \"true\", \n            \"stats.field\", \"stats_dt\", \n            \"stats.field\", i1, \n            \"stats.field\", tdate_a, \n            \"stats.field\", tdate_b,\n            \"stats.calcdistinct\", \"true\");\n    } catch (HttpSolrServer.RemoteSolrException e) {\n      if (e.getMessage().startsWith(\"java.lang.NullPointerException\"))  {\n        fail(\"NullPointerException with stats request on empty index\");\n      } else  {\n        throw e;\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"f001da93ec624cbfbf3655c529836b5b1ec1aa46","date":1412885266,"type":3,"author":"Anshum Gupta","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/TestDistributedSearch#doTest().mjava","pathOld":"solr/core/src/test/org/apache/solr/TestDistributedSearch#doTest().mjava","sourceNew":"  @Override\n  public void doTest() throws Exception {\n    QueryResponse rsp = null;\n    int backupStress = stress; // make a copy so we can restore\n\n\n    del(\"*:*\");\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\",\n           tdate_a, \"2010-04-20T11:00:00Z\",\n           tdate_b, \"2009-08-20T11:00:00Z\",\n           \"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\",\n           tdate_a, \"2010-05-02T11:00:00Z\",\n           tdate_b, \"2009-11-02T11:00:00Z\");\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\",\n           tdate_a, \"2010-05-03T11:00:00Z\");\n    indexr(id,4, i1, -100 ,tlong, 101,\n           t1,\"the quick fox jumped over the lazy dog\", \n           tdate_a, \"2010-05-03T11:00:00Z\",\n           tdate_b, \"2010-05-03T11:00:00Z\");\n    indexr(id,5, i1, 500, tlong, 500 ,\n           t1,\"the quick fox jumped way over the lazy dog\", \n           tdate_a, \"2010-05-05T11:00:00Z\");\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,\n           tdate_b, \"2010-01-05T11:00:00Z\",\n           t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n\n    commit();  // try to ensure there's more than one segment\n\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,\n           t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,\n           t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,\n           t1,\"no eggs on wall, lesson learned\", \n           oddField, \"odd man out\");\n\n    indexr(id, \"1001\", \"lowerfilt\", \"toyota\"); // for spellcheck\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n    \n    \n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n\n    handle.clear();\n    handle.put(\"timestamp\", SKIPVAL);\n    handle.put(\"_version_\", SKIPVAL); // not a cloud test, but may use updateLog\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(\"q\",\"*:*\", \"sort\",f+\" desc\");\n      query(\"q\",\"*:*\", \"sort\",f+\" asc\");\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",\"{!func}testfunc(add(\"+i1+\",5))\"+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" asc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\");\n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"*,score\"); \n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 desc\");\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"{!func}\"+i1);// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(\"q\",\"{!func}\"+i1, \"fl\",\"*,score\");  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"quick\");\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\");\n    query(\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\");  // no fields in returned docs\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\");\n\n    handle.put(\"score\", SKIPVAL);\n    query(\"q\",\"quick\",\"fl\",\"*,score\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\");\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"matchesnothing\",\"fl\",\"*,score\");  \n\n    // test that a single NOW value is propagated to all shards... if that is true\n    // then the primary sort should always be a tie and then the secondary should always decide\n    query(\"q\",\"{!func}ms(NOW)\", \"sort\",\"score desc,\"+i1+\" desc\",\"fl\",\"id\");    \n\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1, \"facet.field\",t1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\");\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2);\n\n    // a facet query to test out chars out of the ascii range\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!term f=foo_s}international\\u00ff\\u01ff\\u2222\\u3333\");\n\n    // simple field facet on date fields\n    rsp = query(\"q\",\"*:*\", \"rows\", 0,\n                \"facet\",\"true\", \"facet.limit\", 1, // TODO: limit shouldn't be needed: SOLR-6386\n                \"facet.field\", tdate_a);\n    assertEquals(1, rsp.getFacetFields().size());\n    rsp = query(\"q\",\"*:*\", \"rows\", 0,\n                \"facet\",\"true\", \"facet.limit\", 1, // TODO: limit shouldn't be needed: SOLR-6386\n                \"facet.field\", tdate_b, \"facet.field\", tdate_a);\n    assertEquals(2, rsp.getFacetFields().size());\n\n    // simple date facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a,\n          \"facet.date\",tdate_a,\n          \"facet.date.other\", \"all\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // date facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a,\n          \"facet.date\",tdate_b,\n          \"facet.date\",tdate_a,\n          \"facet.date.other\", \"all\", \n          \"f.\"+tdate_b+\".facet.date.start\",\"2009-05-01T11:00:00Z\", \n          \"f.\"+tdate_b+\".facet.date.gap\",\"+3MONTHS\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // simple range facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong,\n          \"facet.range\",tlong,\n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"facet.range.end\",900);\n\n    // range facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range\",i1, \n          \"f.\"+i1+\".facet.range.start\",300, \n          \"f.\"+i1+\".facet.range.gap\",87, \n          \"facet.range.end\",900,\n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"f.\"+tlong+\".facet.range.end\",900);\n\n    // Test mincounts. Do NOT want to go through all the stuff where with validateControlData in query() method\n    // Purposely packing a _bunch_ of stuff together here to insure that the proper level of mincount is used for\n    // each\n    ModifiableSolrParams minParams = new ModifiableSolrParams();\n    minParams.set(\"q\",\"*:*\");\n    minParams.set(\"rows\", 1);\n    minParams.set(\"facet\", \"true\");\n    minParams.set(\"facet.missing\", \"true\");\n    minParams.set(\"facet.field\", i1);\n    minParams.set(\"facet.missing\", \"true\");\n    minParams.set(\"facet.mincount\", 2);\n\n    // Return a separate section of ranges over i1. Should respect global range mincount\n    minParams.set(\"facet.range\", i1);\n    minParams.set(\"f.\" + i1 + \".facet.range.start\", 0);\n    minParams.set(\"f.\" + i1 + \".facet.range.gap\", 200);\n    minParams.set(\"f.\" + i1 + \".facet.range.end\", 1200);\n    minParams.set(\"f.\" + i1 + \".facet.mincount\", 4);\n\n\n    // Return a separate section of ranges over tlong Should respect facet.mincount\n    minParams.add(\"facet.range\", tlong);\n    minParams.set(\"f.\" + tlong + \".facet.range.start\", 0);\n    minParams.set(\"f.\" + tlong + \".facet.range.gap\", 100);\n    minParams.set(\"f.\" + tlong + \".facet.range.end\", 1200);\n    // Repeat with a range type of date\n    minParams.add(\"facet.range\", tdate_b);\n    minParams.set(\"f.\" + tdate_b + \".facet.range.start\", \"2009-02-01T00:00:00Z\");\n    minParams.set(\"f.\" + tdate_b + \".facet.range.gap\", \"+1YEAR\");\n    minParams.set(\"f.\" + tdate_b + \".facet.range.end\", \"2011-01-01T00:00:00Z\");\n    minParams.set(\"f.\" + tdate_b + \".facet.mincount\", 3);\n\n    // Insure that global mincount is respected for facet queries\n    minParams.set(\"facet.query\", tdate_a + \":[2010-01-01T00:00:00Z TO 2011-01-01T00:00:00Z]\"); // Should return some counts\n    //minParams.set(\"facet.query\", tdate_a + \":[* TO *]\"); // Should be removed\n    minParams.add(\"facet.query\", tdate_b + \":[2008-01-01T00:00:00Z TO 2009-09-01T00:00:00Z]\"); // Should be removed from response\n\n\n    setDistributedParams(minParams);\n    QueryResponse minResp = queryServer(minParams);\n\n    ModifiableSolrParams eParams = new ModifiableSolrParams();\n    eParams.set(\"q\",tdate_b + \":[* TO *]\");\n    eParams.set(\"rows\", 1000);\n    eParams.set(\"fl\", tdate_b);\n    setDistributedParams(eParams);\n    QueryResponse eResp = queryServer(eParams);\n\n    // Check that exactly the right numbers of counts came through\n    assertEquals(\"Should be exactly 2 range facets returned after minCounts taken into account \", 3, minResp.getFacetRanges().size());\n    assertEquals(\"Should only be 1 query facets returned after minCounts taken into account \", 1, minResp.getFacetQuery().size());\n\n    checkMinCountsField(minResp.getFacetField(i1).getValues(), new Object[]{null, 55L}); // Should just be the null entries for field\n\n    checkMinCountsRange(minResp.getFacetRanges().get(0).getCounts(), new Object[]{\"0\", 5L}); // range on i1\n    checkMinCountsRange(minResp.getFacetRanges().get(1).getCounts(), new Object[]{\"0\", 3L, \"100\", 3L}); // range on tlong\n    checkMinCountsRange(minResp.getFacetRanges().get(2).getCounts(), new Object[]{\"2009-02-01T00:00:00Z\",  3L}); // date (range) on tvh\n\n    assertTrue(\"Should have a facet for tdate_a\", minResp.getFacetQuery().containsKey(\"a_n_tdt:[2010-01-01T00:00:00Z TO 2011-01-01T00:00:00Z]\"));\n    int qCount = minResp.getFacetQuery().get(\"a_n_tdt:[2010-01-01T00:00:00Z TO 2011-01-01T00:00:00Z]\");\n    assertEquals(\"tdate_a should be 5\", qCount, 5);\n\n    // Now let's do some queries, the above is getting too complex\n    minParams = new ModifiableSolrParams();\n    minParams.set(\"q\",\"*:*\");\n    minParams.set(\"rows\", 1);\n    minParams.set(\"facet\", \"true\");\n    minParams.set(\"facet.mincount\", 3);\n\n    minParams.set(\"facet.query\", tdate_a + \":[2010-01-01T00:00:00Z TO 2010-05-04T00:00:00Z]\");\n    minParams.add(\"facet.query\", tdate_b + \":[2009-01-01T00:00:00Z TO 2010-01-01T00:00:00Z]\"); // Should be removed\n    setDistributedParams(minParams);\n    minResp = queryServer(minParams);\n\n    assertEquals(\"Should only be 1 query facets returned after minCounts taken into account \", 1, minResp.getFacetQuery().size());\n    assertTrue(\"Should be an entry for a_n_tdt\", minResp.getFacetQuery().containsKey(\"a_n_tdt:[2010-01-01T00:00:00Z TO 2010-05-04T00:00:00Z]\"));\n    qCount = minResp.getFacetQuery().get(\"a_n_tdt:[2010-01-01T00:00:00Z TO 2010-05-04T00:00:00Z]\");\n    assertEquals(\"a_n_tdt should have a count of 4 \", qCount, 4);\n    //  variations of fl\n    query(\"q\",\"*:*\", \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1 + \",score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", i1, \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id,\" + i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1, \"fl\", \"id\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",nint, \"fl\",tint,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",nint, \"fl\", \"id\", \"fl\",tint,\"sort\",i1 + \" desc\");\n\n    // basic spellcheck testing\n    query(\"q\", \"toyata\", \"fl\", \"id,lowerfilt\", \"spellcheck\", true, \"spellcheck.q\", \"toyata\", \"qt\", \"spellCheckCompRH_Direct\", \"shards.qt\", \"spellCheckCompRH_Direct\");\n\n    stress=0;  // turn off stress... we want to tex max combos in min time\n    for (int i=0; i<25*RANDOM_MULTIPLIER; i++) {\n      String f = fieldNames[random().nextInt(fieldNames.length)];\n      if (random().nextBoolean()) f = t1;  // the text field is a really interesting one to facet on (and it's multi-valued too)\n\n      // we want a random query and not just *:* so we'll get zero counts in facets also\n      // TODO: do a better random query\n      String q = random().nextBoolean() ? \"*:*\" : \"id:(1 3 5 7 9 11 13) OR id:[100 TO \" + random().nextInt(50) + \"]\";\n\n      int nolimit = random().nextBoolean() ? -1 : 10000;  // these should be equivalent\n\n      // if limit==-1, we should always get exact matches\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"count\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      // for index sort, we should get exact results for mincount <= 1\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(2), \"facet.offset\",random().nextInt(10), \"facet.limit\",random().nextInt(11)-1);\n    }\n    stress = backupStress;  // restore stress\n\n    // test faceting multiple things at once\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1);\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id:[1 TO 7]\", \"fq\",\"{!tag=b}id:[3 TO 9]\"\n    );\n    query(\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\");\n\n    // test field that is valid in schema but missing in all shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2);\n    // test field that is valid in schema and missing in some shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2);\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", \"stats_dt\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1);\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", tdate_a);\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", tdate_b);\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \n          \"fq\", \"{!tag=nothing}-*:*\",\n          \"stats.field\", \"{!key=special_key ex=nothing}stats_dt\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \n          \"f.stats_dt.stats.calcdistinct\", \"true\",\n          \"stats.field\", \"{!key=special_key}stats_dt\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \n          \"f.stats_dt.stats.calcdistinct\", \"true\",\n          \"fq\", \"{!tag=xxx}id:[3 TO 9]\",\n          \"stats.field\", \"{!key=special_key}stats_dt\",\n          \"stats.field\", \"{!ex=xxx}stats_dt\");\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\",\n          // do a really simple query so distributed IDF doesn't cause problems\n          // when comparing with control collection\n          \"stats.field\", \"{!lucene key=q_key}\" + i1 + \"foo_b:true\",\n          \"stats.field\", \"{!func key=f_key}sum(\" + tlong +\",\"+i1+\")\");\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\",\n          \"stats.field\", \"stats_dt\",\n          \"stats.field\", i1,\n          \"stats.field\", tdate_a,\n          \"stats.field\", tdate_b);\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    // check a complex key name\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"*:*\", \"rows\",100);\n    }\n\n    //SOLR 3161 ensure shards.qt=/update fails (anything but search handler really)\n    // Also see TestRemoteStreaming#testQtUpdateFails()\n    try {\n      ignoreException(\"isShard is only acceptable\");\n      // query(\"q\",\"*:*\",\"shards.qt\",\"/update\",\"stream.body\",\"<delete><query>*:*</query></delete>\");\n      // fail();\n    } catch (SolrException e) {\n      //expected\n    }\n    unIgnoreException(\"isShard is only acceptable\");\n\n    // test debugging\n    // handle.put(\"explain\", UNORDERED);\n    handle.put(\"explain\", SKIPVAL);  // internal docids differ, idf differs w/o global idf\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    handle.put(\"track\", SKIP); //track is not included in single node search\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY);\n\n    // SOLR-6545, wild card field list\n    indexr(id, \"19\", \"text\", \"d\", \"cat_a_sS\", \"1\" ,t1, \"2\");\n    commit();\n\n    rsp = query(\"q\", \"id:19\", \"fl\", \"id\", \"fl\", \"*a_sS\");\n    assertFieldValues(rsp.getResults(), \"id\", 19);\n\n    rsp = query(\"q\", \"id:19\", \"fl\", \"id,\" + t1 + \",cat*\");\n    assertFieldValues(rsp.getResults(), \"id\", 19);\n\n    // Check Info is added to for each shard\n    ModifiableSolrParams q = new ModifiableSolrParams();\n    q.set(\"q\", \"*:*\");\n    q.set(ShardParams.SHARDS_INFO, true);\n    setDistributedParams(q);\n    rsp = queryServer(q);\n    NamedList<?> sinfo = (NamedList<?>) rsp.getResponse().get(ShardParams.SHARDS_INFO);\n    String shards = getShardsString();\n    int cnt = StringUtils.countMatches(shards, \",\")+1;\n    \n    assertNotNull(\"missing shard info\", sinfo);\n    assertEquals(\"should have an entry for each shard [\"+sinfo+\"] \"+shards, cnt, sinfo.size());\n\n    // test shards.tolerant=true\n    for(int numDownServers = 0; numDownServers < jettys.size()-1; numDownServers++)\n    {\n      List<JettySolrRunner> upJettys = new ArrayList<>(jettys);\n      List<SolrServer> upClients = new ArrayList<>(clients);\n      List<JettySolrRunner> downJettys = new ArrayList<>();\n      List<String> upShards = new ArrayList<>(Arrays.asList(shardsArr));\n      for(int i=0; i<numDownServers; i++)\n      {\n        // shut down some of the jettys\n        int indexToRemove = r.nextInt(upJettys.size());\n        JettySolrRunner downJetty = upJettys.remove(indexToRemove);\n        upClients.remove(indexToRemove);\n        upShards.remove(indexToRemove);\n        ChaosMonkey.stop(downJetty);\n        downJettys.add(downJetty);\n      }\n\n      queryPartialResults(upShards, upClients, \n          \"q\",\"*:*\",\n          \"facet\",\"true\", \n          \"facet.field\",t1,\n          \"facet.field\",t1,\n          \"facet.limit\",5,\n          ShardParams.SHARDS_INFO,\"true\",\n          ShardParams.SHARDS_TOLERANT,\"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"facet\", \"true\",\n          \"facet.query\", i1 + \":[1 TO 50]\",\n          \"facet.query\", i1 + \":[1 TO 50]\",\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      // test group query\n      queryPartialResults(upShards, upClients,\n           \"q\", \"*:*\",\n           \"rows\", 100,\n           \"fl\", \"id,\" + i1,\n           \"group\", \"true\",\n           \"group.query\", t1 + \":kings OR \" + t1 + \":eggs\",\n           \"group.limit\", 10,\n           \"sort\", i1 + \" asc, id asc\",\n           CommonParams.TIME_ALLOWED, 1,\n           ShardParams.SHARDS_INFO, \"true\",\n           ShardParams.SHARDS_TOLERANT, \"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"stats\", \"true\",\n          \"stats.field\", i1,\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"toyata\",\n          \"spellcheck\", \"true\",\n          \"spellcheck.q\", \"toyata\",\n          \"qt\", \"spellCheckCompRH_Direct\",\n          \"shards.qt\", \"spellCheckCompRH_Direct\",\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      // restart the jettys\n      for (JettySolrRunner downJetty : downJettys) {\n        downJetty.start();\n      }\n    }\n\n    // This index has the same number for every field\n    \n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // Thread.sleep(10000000000L);\n\n    del(\"*:*\"); // delete all docs and test stats request\n    commit();\n    try {\n      query(\"q\", \"*:*\", \"stats\", \"true\", \n            \"stats.field\", \"stats_dt\", \n            \"stats.field\", i1, \n            \"stats.field\", tdate_a, \n            \"stats.field\", tdate_b,\n            \"stats.calcdistinct\", \"true\");\n    } catch (HttpSolrServer.RemoteSolrException e) {\n      if (e.getMessage().startsWith(\"java.lang.NullPointerException\"))  {\n        fail(\"NullPointerException with stats request on empty index\");\n      } else  {\n        throw e;\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  public void doTest() throws Exception {\n    QueryResponse rsp = null;\n    int backupStress = stress; // make a copy so we can restore\n\n\n    del(\"*:*\");\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\",\n           tdate_a, \"2010-04-20T11:00:00Z\",\n           tdate_b, \"2009-08-20T11:00:00Z\",\n           \"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\",\n           tdate_a, \"2010-05-02T11:00:00Z\",\n           tdate_b, \"2009-11-02T11:00:00Z\");\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\",\n           tdate_a, \"2010-05-03T11:00:00Z\");\n    indexr(id,4, i1, -100 ,tlong, 101,\n           t1,\"the quick fox jumped over the lazy dog\", \n           tdate_a, \"2010-05-03T11:00:00Z\",\n           tdate_b, \"2010-05-03T11:00:00Z\");\n    indexr(id,5, i1, 500, tlong, 500 ,\n           t1,\"the quick fox jumped way over the lazy dog\", \n           tdate_a, \"2010-05-05T11:00:00Z\");\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,\n           tdate_b, \"2010-01-05T11:00:00Z\",\n           t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n\n    commit();  // try to ensure there's more than one segment\n\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,\n           t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,\n           t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,\n           t1,\"no eggs on wall, lesson learned\", \n           oddField, \"odd man out\");\n\n    indexr(id, \"1001\", \"lowerfilt\", \"toyota\"); // for spellcheck\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n    \n    \n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n\n    handle.clear();\n    handle.put(\"timestamp\", SKIPVAL);\n    handle.put(\"_version_\", SKIPVAL); // not a cloud test, but may use updateLog\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(\"q\",\"*:*\", \"sort\",f+\" desc\");\n      query(\"q\",\"*:*\", \"sort\",f+\" asc\");\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",\"{!func}testfunc(add(\"+i1+\",5))\"+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" asc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\");\n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"*,score\"); \n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 desc\");\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"{!func}\"+i1);// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(\"q\",\"{!func}\"+i1, \"fl\",\"*,score\");  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"quick\");\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\");\n    query(\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\");  // no fields in returned docs\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\");\n\n    handle.put(\"score\", SKIPVAL);\n    query(\"q\",\"quick\",\"fl\",\"*,score\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\");\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"matchesnothing\",\"fl\",\"*,score\");  \n\n    // test that a single NOW value is propagated to all shards... if that is true\n    // then the primary sort should always be a tie and then the secondary should always decide\n    query(\"q\",\"{!func}ms(NOW)\", \"sort\",\"score desc,\"+i1+\" desc\",\"fl\",\"id\");    \n\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1, \"facet.field\",t1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\");\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2);\n\n    // a facet query to test out chars out of the ascii range\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!term f=foo_s}international\\u00ff\\u01ff\\u2222\\u3333\");\n\n    // simple field facet on date fields\n    rsp = query(\"q\",\"*:*\", \"rows\", 0,\n                \"facet\",\"true\", \"facet.limit\", 1, // TODO: limit shouldn't be needed: SOLR-6386\n                \"facet.field\", tdate_a);\n    assertEquals(1, rsp.getFacetFields().size());\n    rsp = query(\"q\",\"*:*\", \"rows\", 0,\n                \"facet\",\"true\", \"facet.limit\", 1, // TODO: limit shouldn't be needed: SOLR-6386\n                \"facet.field\", tdate_b, \"facet.field\", tdate_a);\n    assertEquals(2, rsp.getFacetFields().size());\n\n    // simple date facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a,\n          \"facet.date\",tdate_a,\n          \"facet.date.other\", \"all\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // date facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a,\n          \"facet.date\",tdate_b,\n          \"facet.date\",tdate_a,\n          \"facet.date.other\", \"all\", \n          \"f.\"+tdate_b+\".facet.date.start\",\"2009-05-01T11:00:00Z\", \n          \"f.\"+tdate_b+\".facet.date.gap\",\"+3MONTHS\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // simple range facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong,\n          \"facet.range\",tlong,\n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"facet.range.end\",900);\n\n    // range facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range\",i1, \n          \"f.\"+i1+\".facet.range.start\",300, \n          \"f.\"+i1+\".facet.range.gap\",87, \n          \"facet.range.end\",900,\n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"f.\"+tlong+\".facet.range.end\",900);\n\n    // Test mincounts. Do NOT want to go through all the stuff where with validateControlData in query() method\n    // Purposely packing a _bunch_ of stuff together here to insure that the proper level of mincount is used for\n    // each\n    ModifiableSolrParams minParams = new ModifiableSolrParams();\n    minParams.set(\"q\",\"*:*\");\n    minParams.set(\"rows\", 1);\n    minParams.set(\"facet\", \"true\");\n    minParams.set(\"facet.missing\", \"true\");\n    minParams.set(\"facet.field\", i1);\n    minParams.set(\"facet.missing\", \"true\");\n    minParams.set(\"facet.mincount\", 2);\n\n    // Return a separate section of ranges over i1. Should respect global range mincount\n    minParams.set(\"facet.range\", i1);\n    minParams.set(\"f.\" + i1 + \".facet.range.start\", 0);\n    minParams.set(\"f.\" + i1 + \".facet.range.gap\", 200);\n    minParams.set(\"f.\" + i1 + \".facet.range.end\", 1200);\n    minParams.set(\"f.\" + i1 + \".facet.mincount\", 4);\n\n\n    // Return a separate section of ranges over tlong Should respect facet.mincount\n    minParams.add(\"facet.range\", tlong);\n    minParams.set(\"f.\" + tlong + \".facet.range.start\", 0);\n    minParams.set(\"f.\" + tlong + \".facet.range.gap\", 100);\n    minParams.set(\"f.\" + tlong + \".facet.range.end\", 1200);\n    // Repeat with a range type of date\n    minParams.add(\"facet.range\", tdate_b);\n    minParams.set(\"f.\" + tdate_b + \".facet.range.start\", \"2009-02-01T00:00:00Z\");\n    minParams.set(\"f.\" + tdate_b + \".facet.range.gap\", \"+1YEAR\");\n    minParams.set(\"f.\" + tdate_b + \".facet.range.end\", \"2011-01-01T00:00:00Z\");\n    minParams.set(\"f.\" + tdate_b + \".facet.mincount\", 3);\n\n    // Insure that global mincount is respected for facet queries\n    minParams.set(\"facet.query\", tdate_a + \":[2010-01-01T00:00:00Z TO 2011-01-01T00:00:00Z]\"); // Should return some counts\n    //minParams.set(\"facet.query\", tdate_a + \":[* TO *]\"); // Should be removed\n    minParams.add(\"facet.query\", tdate_b + \":[2008-01-01T00:00:00Z TO 2009-09-01T00:00:00Z]\"); // Should be removed from response\n\n\n    setDistributedParams(minParams);\n    QueryResponse minResp = queryServer(minParams);\n\n    ModifiableSolrParams eParams = new ModifiableSolrParams();\n    eParams.set(\"q\",tdate_b + \":[* TO *]\");\n    eParams.set(\"rows\", 1000);\n    eParams.set(\"fl\", tdate_b);\n    setDistributedParams(eParams);\n    QueryResponse eResp = queryServer(eParams);\n\n    // Check that exactly the right numbers of counts came through\n    assertEquals(\"Should be exactly 2 range facets returned after minCounts taken into account \", 3, minResp.getFacetRanges().size());\n    assertEquals(\"Should only be 1 query facets returned after minCounts taken into account \", 1, minResp.getFacetQuery().size());\n\n    checkMinCountsField(minResp.getFacetField(i1).getValues(), new Object[]{null, 55L}); // Should just be the null entries for field\n\n    checkMinCountsRange(minResp.getFacetRanges().get(0).getCounts(), new Object[]{\"0\", 5L}); // range on i1\n    checkMinCountsRange(minResp.getFacetRanges().get(1).getCounts(), new Object[]{\"0\", 3L, \"100\", 3L}); // range on tlong\n    checkMinCountsRange(minResp.getFacetRanges().get(2).getCounts(), new Object[]{\"2009-02-01T00:00:00Z\",  3L}); // date (range) on tvh\n\n    assertTrue(\"Should have a facet for tdate_a\", minResp.getFacetQuery().containsKey(\"a_n_tdt:[2010-01-01T00:00:00Z TO 2011-01-01T00:00:00Z]\"));\n    int qCount = minResp.getFacetQuery().get(\"a_n_tdt:[2010-01-01T00:00:00Z TO 2011-01-01T00:00:00Z]\");\n    assertEquals(\"tdate_a should be 5\", qCount, 5);\n\n    // Now let's do some queries, the above is getting too complex\n    minParams = new ModifiableSolrParams();\n    minParams.set(\"q\",\"*:*\");\n    minParams.set(\"rows\", 1);\n    minParams.set(\"facet\", \"true\");\n    minParams.set(\"facet.mincount\", 3);\n\n    minParams.set(\"facet.query\", tdate_a + \":[2010-01-01T00:00:00Z TO 2010-05-04T00:00:00Z]\");\n    minParams.add(\"facet.query\", tdate_b + \":[2009-01-01T00:00:00Z TO 2010-01-01T00:00:00Z]\"); // Should be removed\n    setDistributedParams(minParams);\n    minResp = queryServer(minParams);\n\n    assertEquals(\"Should only be 1 query facets returned after minCounts taken into account \", 1, minResp.getFacetQuery().size());\n    assertTrue(\"Should be an entry for a_n_tdt\", minResp.getFacetQuery().containsKey(\"a_n_tdt:[2010-01-01T00:00:00Z TO 2010-05-04T00:00:00Z]\"));\n    qCount = minResp.getFacetQuery().get(\"a_n_tdt:[2010-01-01T00:00:00Z TO 2010-05-04T00:00:00Z]\");\n    assertEquals(\"a_n_tdt should have a count of 4 \", qCount, 4);\n    //  variations of fl\n    query(\"q\",\"*:*\", \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1 + \",score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", i1, \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id,\" + i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1, \"fl\", \"id\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",nint, \"fl\",tint,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",nint, \"fl\", \"id\", \"fl\",tint,\"sort\",i1 + \" desc\");\n\n    // basic spellcheck testing\n    query(\"q\", \"toyata\", \"fl\", \"id,lowerfilt\", \"spellcheck\", true, \"spellcheck.q\", \"toyata\", \"qt\", \"spellCheckCompRH_Direct\", \"shards.qt\", \"spellCheckCompRH_Direct\");\n\n    stress=0;  // turn off stress... we want to tex max combos in min time\n    for (int i=0; i<25*RANDOM_MULTIPLIER; i++) {\n      String f = fieldNames[random().nextInt(fieldNames.length)];\n      if (random().nextBoolean()) f = t1;  // the text field is a really interesting one to facet on (and it's multi-valued too)\n\n      // we want a random query and not just *:* so we'll get zero counts in facets also\n      // TODO: do a better random query\n      String q = random().nextBoolean() ? \"*:*\" : \"id:(1 3 5 7 9 11 13) OR id:[100 TO \" + random().nextInt(50) + \"]\";\n\n      int nolimit = random().nextBoolean() ? -1 : 10000;  // these should be equivalent\n\n      // if limit==-1, we should always get exact matches\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"count\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      // for index sort, we should get exact results for mincount <= 1\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(2), \"facet.offset\",random().nextInt(10), \"facet.limit\",random().nextInt(11)-1);\n    }\n    stress = backupStress;  // restore stress\n\n    // test faceting multiple things at once\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1);\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id:[1 TO 7]\", \"fq\",\"{!tag=b}id:[3 TO 9]\"\n    );\n    query(\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\");\n\n    // test field that is valid in schema but missing in all shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2);\n    // test field that is valid in schema and missing in some shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2);\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", \"stats_dt\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1);\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", tdate_a);\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", tdate_b);\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \n          \"fq\", \"{!tag=nothing}-*:*\",\n          \"stats.field\", \"{!key=special_key ex=nothing}stats_dt\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \n          \"f.stats_dt.stats.calcdistinct\", \"true\",\n          \"stats.field\", \"{!key=special_key}stats_dt\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \n          \"f.stats_dt.stats.calcdistinct\", \"true\",\n          \"fq\", \"{!tag=xxx}id:[3 TO 9]\",\n          \"stats.field\", \"{!key=special_key}stats_dt\",\n          \"stats.field\", \"{!ex=xxx}stats_dt\");\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\",\n          // do a really simple query so distributed IDF doesn't cause problems\n          // when comparing with control collection\n          \"stats.field\", \"{!lucene key=q_key}\" + i1 + \"foo_b:true\",\n          \"stats.field\", \"{!func key=f_key}sum(\" + tlong +\",\"+i1+\")\");\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\",\n          \"stats.field\", \"stats_dt\",\n          \"stats.field\", i1,\n          \"stats.field\", tdate_a,\n          \"stats.field\", tdate_b);\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    // check a complex key name\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"*:*\", \"rows\",100);\n    }\n\n    //SOLR 3161 ensure shards.qt=/update fails (anything but search handler really)\n    // Also see TestRemoteStreaming#testQtUpdateFails()\n    try {\n      ignoreException(\"isShard is only acceptable\");\n      // query(\"q\",\"*:*\",\"shards.qt\",\"/update\",\"stream.body\",\"<delete><query>*:*</query></delete>\");\n      // fail();\n    } catch (SolrException e) {\n      //expected\n    }\n    unIgnoreException(\"isShard is only acceptable\");\n\n    // test debugging\n    // handle.put(\"explain\", UNORDERED);\n    handle.put(\"explain\", SKIPVAL);  // internal docids differ, idf differs w/o global idf\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    handle.put(\"track\", SKIP); //track is not included in single node search\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY);\n\n    // SOLR-6545, wild card field list\n    indexr(id, \"19\", \"text\", \"d\", \"cat_a_sS\", \"1\" ,t1, \"2\");\n    commit();\n\n    rsp = query(\"q\", \"id:19\", \"fl\", \"id\", \"fl\", \"*a_sS\");\n    assertFieldValues(rsp.getResults(), \"id\", 19);\n\n    rsp = query(\"q\", \"id:19\", \"fl\", \"id,\" + t1 + \",cat*\");\n    assertFieldValues(rsp.getResults(), \"id\", 19);\n\n    // Check Info is added to for each shard\n    ModifiableSolrParams q = new ModifiableSolrParams();\n    q.set(\"q\", \"*:*\");\n    q.set(ShardParams.SHARDS_INFO, true);\n    setDistributedParams(q);\n    rsp = queryServer(q);\n    NamedList<?> sinfo = (NamedList<?>) rsp.getResponse().get(ShardParams.SHARDS_INFO);\n    String shards = getShardsString();\n    int cnt = StringUtils.countMatches(shards, \",\")+1;\n    \n    assertNotNull(\"missing shard info\", sinfo);\n    assertEquals(\"should have an entry for each shard [\"+sinfo+\"] \"+shards, cnt, sinfo.size());\n\n    // test shards.tolerant=true\n    for(int numDownServers = 0; numDownServers < jettys.size()-1; numDownServers++)\n    {\n      List<JettySolrRunner> upJettys = new ArrayList<>(jettys);\n      List<SolrServer> upClients = new ArrayList<>(clients);\n      List<JettySolrRunner> downJettys = new ArrayList<>();\n      List<String> upShards = new ArrayList<>(Arrays.asList(shardsArr));\n      for(int i=0; i<numDownServers; i++)\n      {\n        // shut down some of the jettys\n        int indexToRemove = r.nextInt(upJettys.size());\n        JettySolrRunner downJetty = upJettys.remove(indexToRemove);\n        upClients.remove(indexToRemove);\n        upShards.remove(indexToRemove);\n        ChaosMonkey.stop(downJetty);\n        downJettys.add(downJetty);\n      }\n\n      queryPartialResults(upShards, upClients, \n          \"q\",\"*:*\",\n          \"facet\",\"true\", \n          \"facet.field\",t1,\n          \"facet.field\",t1,\n          \"facet.limit\",5,\n          ShardParams.SHARDS_INFO,\"true\",\n          ShardParams.SHARDS_TOLERANT,\"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"facet\", \"true\",\n          \"facet.query\", i1 + \":[1 TO 50]\",\n          \"facet.query\", i1 + \":[1 TO 50]\",\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      // test group query\n      // TODO: Remove this? This doesn't make any real sense now that timeAllowed might trigger early\n      //       termination of the request during Terms enumeration/Query expansion.\n      //       During such an exit, partial results isn't supported as it wouldn't make any sense.\n      // Increasing the timeAllowed from 1 to 100 for now.\n      //\n      // TODO: still failing in jenkins - see SOLR-5986\n      //\n      // queryPartialResults(upShards, upClients,\n      //     \"q\", \"*:*\",\n      //     \"rows\", 100,\n      //     \"fl\", \"id,\" + i1,\n      //     \"group\", \"true\",\n      //     \"group.query\", t1 + \":kings OR \" + t1 + \":eggs\",\n      //     \"group.limit\", 10,\n      //     \"sort\", i1 + \" asc, id asc\",\n      //     CommonParams.TIME_ALLOWED, 100,\n      //     ShardParams.SHARDS_INFO, \"true\",\n      //     ShardParams.SHARDS_TOLERANT, \"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"stats\", \"true\",\n          \"stats.field\", i1,\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"toyata\",\n          \"spellcheck\", \"true\",\n          \"spellcheck.q\", \"toyata\",\n          \"qt\", \"spellCheckCompRH_Direct\",\n          \"shards.qt\", \"spellCheckCompRH_Direct\",\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      // restart the jettys\n      for (JettySolrRunner downJetty : downJettys) {\n        downJetty.start();\n      }\n    }\n\n    // This index has the same number for every field\n    \n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // Thread.sleep(10000000000L);\n\n    del(\"*:*\"); // delete all docs and test stats request\n    commit();\n    try {\n      query(\"q\", \"*:*\", \"stats\", \"true\", \n            \"stats.field\", \"stats_dt\", \n            \"stats.field\", i1, \n            \"stats.field\", tdate_a, \n            \"stats.field\", tdate_b,\n            \"stats.calcdistinct\", \"true\");\n    } catch (HttpSolrServer.RemoteSolrException e) {\n      if (e.getMessage().startsWith(\"java.lang.NullPointerException\"))  {\n        fail(\"NullPointerException with stats request on empty index\");\n      } else  {\n        throw e;\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":["bb222a3f9d9421d5c95afce73013fbd8de07ea1f"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"55980207f1977bd1463465de1659b821347e2fa8","date":1413336386,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/TestDistributedSearch#doTest().mjava","pathOld":"solr/core/src/test/org/apache/solr/TestDistributedSearch#doTest().mjava","sourceNew":"  @Override\n  public void doTest() throws Exception {\n    QueryResponse rsp = null;\n    int backupStress = stress; // make a copy so we can restore\n\n\n    del(\"*:*\");\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\",\n           tdate_a, \"2010-04-20T11:00:00Z\",\n           tdate_b, \"2009-08-20T11:00:00Z\",\n           \"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\",\n           tdate_a, \"2010-05-02T11:00:00Z\",\n           tdate_b, \"2009-11-02T11:00:00Z\");\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\",\n           tdate_a, \"2010-05-03T11:00:00Z\");\n    indexr(id,4, i1, -100 ,tlong, 101,\n           t1,\"the quick fox jumped over the lazy dog\", \n           tdate_a, \"2010-05-03T11:00:00Z\",\n           tdate_b, \"2010-05-03T11:00:00Z\");\n    indexr(id,5, i1, 500, tlong, 500 ,\n           t1,\"the quick fox jumped way over the lazy dog\", \n           tdate_a, \"2010-05-05T11:00:00Z\");\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,\n           tdate_b, \"2010-01-05T11:00:00Z\",\n           t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n\n    commit();  // try to ensure there's more than one segment\n\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,\n           t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,\n           t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,\n           t1,\"no eggs on wall, lesson learned\", \n           oddField, \"odd man out\");\n\n    indexr(id, \"1001\", \"lowerfilt\", \"toyota\"); // for spellcheck\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n    \n    \n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n\n    handle.clear();\n    handle.put(\"timestamp\", SKIPVAL);\n    handle.put(\"_version_\", SKIPVAL); // not a cloud test, but may use updateLog\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(\"q\",\"*:*\", \"sort\",f+\" desc\");\n      query(\"q\",\"*:*\", \"sort\",f+\" asc\");\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",\"{!func}testfunc(add(\"+i1+\",5))\"+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" asc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\");\n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"*,score\"); \n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 desc\");\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"{!func}\"+i1);// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(\"q\",\"{!func}\"+i1, \"fl\",\"*,score\");  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"quick\");\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\");\n    query(\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\");  // no fields in returned docs\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\");\n\n    handle.put(\"score\", SKIPVAL);\n    query(\"q\",\"quick\",\"fl\",\"*,score\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\");\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"matchesnothing\",\"fl\",\"*,score\");  \n\n    // test that a single NOW value is propagated to all shards... if that is true\n    // then the primary sort should always be a tie and then the secondary should always decide\n    query(\"q\",\"{!func}ms(NOW)\", \"sort\",\"score desc,\"+i1+\" desc\",\"fl\",\"id\");    \n\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1, \"facet.field\",t1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\");\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2);\n\n    // a facet query to test out chars out of the ascii range\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!term f=foo_s}international\\u00ff\\u01ff\\u2222\\u3333\");\n\n    // simple field facet on date fields\n    rsp = query(\"q\",\"*:*\", \"rows\", 0,\n                \"facet\",\"true\", \"facet.limit\", 1, // TODO: limit shouldn't be needed: SOLR-6386\n                \"facet.field\", tdate_a);\n    assertEquals(1, rsp.getFacetFields().size());\n    rsp = query(\"q\",\"*:*\", \"rows\", 0,\n                \"facet\",\"true\", \"facet.limit\", 1, // TODO: limit shouldn't be needed: SOLR-6386\n                \"facet.field\", tdate_b, \"facet.field\", tdate_a);\n    assertEquals(2, rsp.getFacetFields().size());\n\n    // simple date facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a,\n          \"facet.date\",tdate_a,\n          \"facet.date.other\", \"all\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // date facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a,\n          \"facet.date\",tdate_b,\n          \"facet.date\",tdate_a,\n          \"facet.date.other\", \"all\", \n          \"f.\"+tdate_b+\".facet.date.start\",\"2009-05-01T11:00:00Z\", \n          \"f.\"+tdate_b+\".facet.date.gap\",\"+3MONTHS\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // simple range facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong,\n          \"facet.range\",tlong,\n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"facet.range.end\",900);\n\n    // range facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range\",i1, \n          \"f.\"+i1+\".facet.range.start\",300, \n          \"f.\"+i1+\".facet.range.gap\",87, \n          \"facet.range.end\",900,\n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"f.\"+tlong+\".facet.range.end\",900);\n\n    // Test mincounts. Do NOT want to go through all the stuff where with validateControlData in query() method\n    // Purposely packing a _bunch_ of stuff together here to insure that the proper level of mincount is used for\n    // each\n    ModifiableSolrParams minParams = new ModifiableSolrParams();\n    minParams.set(\"q\",\"*:*\");\n    minParams.set(\"rows\", 1);\n    minParams.set(\"facet\", \"true\");\n    minParams.set(\"facet.missing\", \"true\");\n    minParams.set(\"facet.field\", i1);\n    minParams.set(\"facet.missing\", \"true\");\n    minParams.set(\"facet.mincount\", 2);\n\n    // Return a separate section of ranges over i1. Should respect global range mincount\n    minParams.set(\"facet.range\", i1);\n    minParams.set(\"f.\" + i1 + \".facet.range.start\", 0);\n    minParams.set(\"f.\" + i1 + \".facet.range.gap\", 200);\n    minParams.set(\"f.\" + i1 + \".facet.range.end\", 1200);\n    minParams.set(\"f.\" + i1 + \".facet.mincount\", 4);\n\n\n    // Return a separate section of ranges over tlong Should respect facet.mincount\n    minParams.add(\"facet.range\", tlong);\n    minParams.set(\"f.\" + tlong + \".facet.range.start\", 0);\n    minParams.set(\"f.\" + tlong + \".facet.range.gap\", 100);\n    minParams.set(\"f.\" + tlong + \".facet.range.end\", 1200);\n    // Repeat with a range type of date\n    minParams.add(\"facet.range\", tdate_b);\n    minParams.set(\"f.\" + tdate_b + \".facet.range.start\", \"2009-02-01T00:00:00Z\");\n    minParams.set(\"f.\" + tdate_b + \".facet.range.gap\", \"+1YEAR\");\n    minParams.set(\"f.\" + tdate_b + \".facet.range.end\", \"2011-01-01T00:00:00Z\");\n    minParams.set(\"f.\" + tdate_b + \".facet.mincount\", 3);\n\n    // Insure that global mincount is respected for facet queries\n    minParams.set(\"facet.query\", tdate_a + \":[2010-01-01T00:00:00Z TO 2011-01-01T00:00:00Z]\"); // Should return some counts\n    //minParams.set(\"facet.query\", tdate_a + \":[* TO *]\"); // Should be removed\n    minParams.add(\"facet.query\", tdate_b + \":[2008-01-01T00:00:00Z TO 2009-09-01T00:00:00Z]\"); // Should be removed from response\n\n\n    setDistributedParams(minParams);\n    QueryResponse minResp = queryServer(minParams);\n\n    ModifiableSolrParams eParams = new ModifiableSolrParams();\n    eParams.set(\"q\",tdate_b + \":[* TO *]\");\n    eParams.set(\"rows\", 1000);\n    eParams.set(\"fl\", tdate_b);\n    setDistributedParams(eParams);\n    QueryResponse eResp = queryServer(eParams);\n\n    // Check that exactly the right numbers of counts came through\n    assertEquals(\"Should be exactly 2 range facets returned after minCounts taken into account \", 3, minResp.getFacetRanges().size());\n    assertEquals(\"Should only be 1 query facets returned after minCounts taken into account \", 1, minResp.getFacetQuery().size());\n\n    checkMinCountsField(minResp.getFacetField(i1).getValues(), new Object[]{null, 55L}); // Should just be the null entries for field\n\n    checkMinCountsRange(minResp.getFacetRanges().get(0).getCounts(), new Object[]{\"0\", 5L}); // range on i1\n    checkMinCountsRange(minResp.getFacetRanges().get(1).getCounts(), new Object[]{\"0\", 3L, \"100\", 3L}); // range on tlong\n    checkMinCountsRange(minResp.getFacetRanges().get(2).getCounts(), new Object[]{\"2009-02-01T00:00:00Z\",  3L}); // date (range) on tvh\n\n    assertTrue(\"Should have a facet for tdate_a\", minResp.getFacetQuery().containsKey(\"a_n_tdt:[2010-01-01T00:00:00Z TO 2011-01-01T00:00:00Z]\"));\n    int qCount = minResp.getFacetQuery().get(\"a_n_tdt:[2010-01-01T00:00:00Z TO 2011-01-01T00:00:00Z]\");\n    assertEquals(\"tdate_a should be 5\", qCount, 5);\n\n    // Now let's do some queries, the above is getting too complex\n    minParams = new ModifiableSolrParams();\n    minParams.set(\"q\",\"*:*\");\n    minParams.set(\"rows\", 1);\n    minParams.set(\"facet\", \"true\");\n    minParams.set(\"facet.mincount\", 3);\n\n    minParams.set(\"facet.query\", tdate_a + \":[2010-01-01T00:00:00Z TO 2010-05-04T00:00:00Z]\");\n    minParams.add(\"facet.query\", tdate_b + \":[2009-01-01T00:00:00Z TO 2010-01-01T00:00:00Z]\"); // Should be removed\n    setDistributedParams(minParams);\n    minResp = queryServer(minParams);\n\n    assertEquals(\"Should only be 1 query facets returned after minCounts taken into account \", 1, minResp.getFacetQuery().size());\n    assertTrue(\"Should be an entry for a_n_tdt\", minResp.getFacetQuery().containsKey(\"a_n_tdt:[2010-01-01T00:00:00Z TO 2010-05-04T00:00:00Z]\"));\n    qCount = minResp.getFacetQuery().get(\"a_n_tdt:[2010-01-01T00:00:00Z TO 2010-05-04T00:00:00Z]\");\n    assertEquals(\"a_n_tdt should have a count of 4 \", qCount, 4);\n    //  variations of fl\n    query(\"q\",\"*:*\", \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1 + \",score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", i1, \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id,\" + i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1, \"fl\", \"id\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",nint, \"fl\",tint,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",nint, \"fl\", \"id\", \"fl\",tint,\"sort\",i1 + \" desc\");\n\n    // basic spellcheck testing\n    query(\"q\", \"toyata\", \"fl\", \"id,lowerfilt\", \"spellcheck\", true, \"spellcheck.q\", \"toyata\", \"qt\", \"spellCheckCompRH_Direct\", \"shards.qt\", \"spellCheckCompRH_Direct\");\n\n    stress=0;  // turn off stress... we want to tex max combos in min time\n    for (int i=0; i<25*RANDOM_MULTIPLIER; i++) {\n      String f = fieldNames[random().nextInt(fieldNames.length)];\n      if (random().nextBoolean()) f = t1;  // the text field is a really interesting one to facet on (and it's multi-valued too)\n\n      // we want a random query and not just *:* so we'll get zero counts in facets also\n      // TODO: do a better random query\n      String q = random().nextBoolean() ? \"*:*\" : \"id:(1 3 5 7 9 11 13) OR id:[100 TO \" + random().nextInt(50) + \"]\";\n\n      int nolimit = random().nextBoolean() ? -1 : 10000;  // these should be equivalent\n\n      // if limit==-1, we should always get exact matches\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"count\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      // for index sort, we should get exact results for mincount <= 1\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(2), \"facet.offset\",random().nextInt(10), \"facet.limit\",random().nextInt(11)-1);\n    }\n    stress = backupStress;  // restore stress\n\n    // test faceting multiple things at once\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1);\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id:[1 TO 7]\", \"fq\",\"{!tag=b}id:[3 TO 9]\"\n    );\n    query(\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\");\n\n    // test field that is valid in schema but missing in all shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2);\n    // test field that is valid in schema and missing in some shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2);\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", \"stats_dt\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1);\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", tdate_a);\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", tdate_b);\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \n          \"fq\", \"{!tag=nothing}-*:*\",\n          \"stats.field\", \"{!key=special_key ex=nothing}stats_dt\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \n          \"f.stats_dt.stats.calcdistinct\", \"true\",\n          \"stats.field\", \"{!key=special_key}stats_dt\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \n          \"f.stats_dt.stats.calcdistinct\", \"true\",\n          \"fq\", \"{!tag=xxx}id:[3 TO 9]\",\n          \"stats.field\", \"{!key=special_key}stats_dt\",\n          \"stats.field\", \"{!ex=xxx}stats_dt\");\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\",\n          // do a really simple query so distributed IDF doesn't cause problems\n          // when comparing with control collection\n          \"stats.field\", \"{!lucene key=q_key}\" + i1 + \"foo_b:true\",\n          \"stats.field\", \"{!func key=f_key}sum(\" + tlong +\",\"+i1+\")\");\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\",\n          \"stats.field\", \"stats_dt\",\n          \"stats.field\", i1,\n          \"stats.field\", tdate_a,\n          \"stats.field\", tdate_b);\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    // check a complex key name\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"*:*\", \"rows\",100);\n    }\n\n    //SOLR 3161 ensure shards.qt=/update fails (anything but search handler really)\n    // Also see TestRemoteStreaming#testQtUpdateFails()\n    try {\n      ignoreException(\"isShard is only acceptable\");\n      // query(\"q\",\"*:*\",\"shards.qt\",\"/update\",\"stream.body\",\"<delete><query>*:*</query></delete>\");\n      // fail();\n    } catch (SolrException e) {\n      //expected\n    }\n    unIgnoreException(\"isShard is only acceptable\");\n\n    // test debugging\n    // handle.put(\"explain\", UNORDERED);\n    handle.put(\"explain\", SKIPVAL);  // internal docids differ, idf differs w/o global idf\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    handle.put(\"track\", SKIP); //track is not included in single node search\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY);\n\n    // SOLR-6545, wild card field list\n    indexr(id, \"19\", \"text\", \"d\", \"cat_a_sS\", \"1\" ,t1, \"2\");\n    commit();\n\n    rsp = query(\"q\", \"id:19\", \"fl\", \"id\", \"fl\", \"*a_sS\");\n    assertFieldValues(rsp.getResults(), \"id\", 19);\n\n    rsp = query(\"q\", \"id:19\", \"fl\", \"id,\" + t1 + \",cat*\");\n    assertFieldValues(rsp.getResults(), \"id\", 19);\n\n    // Check Info is added to for each shard\n    ModifiableSolrParams q = new ModifiableSolrParams();\n    q.set(\"q\", \"*:*\");\n    q.set(ShardParams.SHARDS_INFO, true);\n    setDistributedParams(q);\n    rsp = queryServer(q);\n    NamedList<?> sinfo = (NamedList<?>) rsp.getResponse().get(ShardParams.SHARDS_INFO);\n    String shards = getShardsString();\n    int cnt = StringUtils.countMatches(shards, \",\")+1;\n    \n    assertNotNull(\"missing shard info\", sinfo);\n    assertEquals(\"should have an entry for each shard [\"+sinfo+\"] \"+shards, cnt, sinfo.size());\n\n    // test shards.tolerant=true\n    for(int numDownServers = 0; numDownServers < jettys.size()-1; numDownServers++)\n    {\n      List<JettySolrRunner> upJettys = new ArrayList<>(jettys);\n      List<SolrServer> upClients = new ArrayList<>(clients);\n      List<JettySolrRunner> downJettys = new ArrayList<>();\n      List<String> upShards = new ArrayList<>(Arrays.asList(shardsArr));\n      for(int i=0; i<numDownServers; i++)\n      {\n        // shut down some of the jettys\n        int indexToRemove = r.nextInt(upJettys.size());\n        JettySolrRunner downJetty = upJettys.remove(indexToRemove);\n        upClients.remove(indexToRemove);\n        upShards.remove(indexToRemove);\n        ChaosMonkey.stop(downJetty);\n        downJettys.add(downJetty);\n      }\n\n      queryPartialResults(upShards, upClients, \n          \"q\",\"*:*\",\n          \"facet\",\"true\", \n          \"facet.field\",t1,\n          \"facet.field\",t1,\n          \"facet.limit\",5,\n          ShardParams.SHARDS_INFO,\"true\",\n          ShardParams.SHARDS_TOLERANT,\"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"facet\", \"true\",\n          \"facet.query\", i1 + \":[1 TO 50]\",\n          \"facet.query\", i1 + \":[1 TO 50]\",\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      // test group query\n      queryPartialResults(upShards, upClients,\n           \"q\", \"*:*\",\n           \"rows\", 100,\n           \"fl\", \"id,\" + i1,\n           \"group\", \"true\",\n           \"group.query\", t1 + \":kings OR \" + t1 + \":eggs\",\n           \"group.limit\", 10,\n           \"sort\", i1 + \" asc, id asc\",\n           CommonParams.TIME_ALLOWED, 1,\n           ShardParams.SHARDS_INFO, \"true\",\n           ShardParams.SHARDS_TOLERANT, \"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"stats\", \"true\",\n          \"stats.field\", i1,\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"toyata\",\n          \"spellcheck\", \"true\",\n          \"spellcheck.q\", \"toyata\",\n          \"qt\", \"spellCheckCompRH_Direct\",\n          \"shards.qt\", \"spellCheckCompRH_Direct\",\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      // restart the jettys\n      for (JettySolrRunner downJetty : downJettys) {\n        downJetty.start();\n      }\n    }\n\n    // This index has the same number for every field\n    \n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // Thread.sleep(10000000000L);\n\n    del(\"*:*\"); // delete all docs and test stats request\n    commit();\n    try {\n      query(\"q\", \"*:*\", \"stats\", \"true\", \n            \"stats.field\", \"stats_dt\", \n            \"stats.field\", i1, \n            \"stats.field\", tdate_a, \n            \"stats.field\", tdate_b,\n            \"stats.calcdistinct\", \"true\");\n    } catch (HttpSolrServer.RemoteSolrException e) {\n      if (e.getMessage().startsWith(\"java.lang.NullPointerException\"))  {\n        fail(\"NullPointerException with stats request on empty index\");\n      } else  {\n        throw e;\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  public void doTest() throws Exception {\n    QueryResponse rsp = null;\n    int backupStress = stress; // make a copy so we can restore\n\n\n    del(\"*:*\");\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\",\n           tdate_a, \"2010-04-20T11:00:00Z\",\n           tdate_b, \"2009-08-20T11:00:00Z\",\n           \"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\",\n           tdate_a, \"2010-05-02T11:00:00Z\",\n           tdate_b, \"2009-11-02T11:00:00Z\");\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\",\n           tdate_a, \"2010-05-03T11:00:00Z\");\n    indexr(id,4, i1, -100 ,tlong, 101,\n           t1,\"the quick fox jumped over the lazy dog\", \n           tdate_a, \"2010-05-03T11:00:00Z\",\n           tdate_b, \"2010-05-03T11:00:00Z\");\n    indexr(id,5, i1, 500, tlong, 500 ,\n           t1,\"the quick fox jumped way over the lazy dog\", \n           tdate_a, \"2010-05-05T11:00:00Z\");\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,\n           tdate_b, \"2010-01-05T11:00:00Z\",\n           t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n\n    commit();  // try to ensure there's more than one segment\n\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,\n           t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,\n           t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,\n           t1,\"no eggs on wall, lesson learned\", \n           oddField, \"odd man out\");\n\n    indexr(id, \"1001\", \"lowerfilt\", \"toyota\"); // for spellcheck\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n    \n    \n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n\n    handle.clear();\n    handle.put(\"timestamp\", SKIPVAL);\n    handle.put(\"_version_\", SKIPVAL); // not a cloud test, but may use updateLog\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(\"q\",\"*:*\", \"sort\",f+\" desc\");\n      query(\"q\",\"*:*\", \"sort\",f+\" asc\");\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",\"{!func}testfunc(add(\"+i1+\",5))\"+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" asc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\");\n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"*,score\"); \n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 desc\");\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"{!func}\"+i1);// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(\"q\",\"{!func}\"+i1, \"fl\",\"*,score\");  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"quick\");\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\");\n    query(\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\");  // no fields in returned docs\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\");\n\n    handle.put(\"score\", SKIPVAL);\n    query(\"q\",\"quick\",\"fl\",\"*,score\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\");\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"matchesnothing\",\"fl\",\"*,score\");  \n\n    // test that a single NOW value is propagated to all shards... if that is true\n    // then the primary sort should always be a tie and then the secondary should always decide\n    query(\"q\",\"{!func}ms(NOW)\", \"sort\",\"score desc,\"+i1+\" desc\",\"fl\",\"id\");    \n\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1, \"facet.field\",t1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\");\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2);\n\n    // a facet query to test out chars out of the ascii range\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!term f=foo_s}international\\u00ff\\u01ff\\u2222\\u3333\");\n\n    // simple field facet on date fields\n    rsp = query(\"q\",\"*:*\", \"rows\", 0,\n                \"facet\",\"true\", \"facet.limit\", 1, // TODO: limit shouldn't be needed: SOLR-6386\n                \"facet.field\", tdate_a);\n    assertEquals(1, rsp.getFacetFields().size());\n    rsp = query(\"q\",\"*:*\", \"rows\", 0,\n                \"facet\",\"true\", \"facet.limit\", 1, // TODO: limit shouldn't be needed: SOLR-6386\n                \"facet.field\", tdate_b, \"facet.field\", tdate_a);\n    assertEquals(2, rsp.getFacetFields().size());\n\n    // simple date facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a,\n          \"facet.date\",tdate_a,\n          \"facet.date.other\", \"all\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // date facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a,\n          \"facet.date\",tdate_b,\n          \"facet.date\",tdate_a,\n          \"facet.date.other\", \"all\", \n          \"f.\"+tdate_b+\".facet.date.start\",\"2009-05-01T11:00:00Z\", \n          \"f.\"+tdate_b+\".facet.date.gap\",\"+3MONTHS\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // simple range facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong,\n          \"facet.range\",tlong,\n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"facet.range.end\",900);\n\n    // range facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range\",i1, \n          \"f.\"+i1+\".facet.range.start\",300, \n          \"f.\"+i1+\".facet.range.gap\",87, \n          \"facet.range.end\",900,\n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"f.\"+tlong+\".facet.range.end\",900);\n\n    // Test mincounts. Do NOT want to go through all the stuff where with validateControlData in query() method\n    // Purposely packing a _bunch_ of stuff together here to insure that the proper level of mincount is used for\n    // each\n    ModifiableSolrParams minParams = new ModifiableSolrParams();\n    minParams.set(\"q\",\"*:*\");\n    minParams.set(\"rows\", 1);\n    minParams.set(\"facet\", \"true\");\n    minParams.set(\"facet.missing\", \"true\");\n    minParams.set(\"facet.field\", i1);\n    minParams.set(\"facet.missing\", \"true\");\n    minParams.set(\"facet.mincount\", 2);\n\n    // Return a separate section of ranges over i1. Should respect global range mincount\n    minParams.set(\"facet.range\", i1);\n    minParams.set(\"f.\" + i1 + \".facet.range.start\", 0);\n    minParams.set(\"f.\" + i1 + \".facet.range.gap\", 200);\n    minParams.set(\"f.\" + i1 + \".facet.range.end\", 1200);\n    minParams.set(\"f.\" + i1 + \".facet.mincount\", 4);\n\n\n    // Return a separate section of ranges over tlong Should respect facet.mincount\n    minParams.add(\"facet.range\", tlong);\n    minParams.set(\"f.\" + tlong + \".facet.range.start\", 0);\n    minParams.set(\"f.\" + tlong + \".facet.range.gap\", 100);\n    minParams.set(\"f.\" + tlong + \".facet.range.end\", 1200);\n    // Repeat with a range type of date\n    minParams.add(\"facet.range\", tdate_b);\n    minParams.set(\"f.\" + tdate_b + \".facet.range.start\", \"2009-02-01T00:00:00Z\");\n    minParams.set(\"f.\" + tdate_b + \".facet.range.gap\", \"+1YEAR\");\n    minParams.set(\"f.\" + tdate_b + \".facet.range.end\", \"2011-01-01T00:00:00Z\");\n    minParams.set(\"f.\" + tdate_b + \".facet.mincount\", 3);\n\n    // Insure that global mincount is respected for facet queries\n    minParams.set(\"facet.query\", tdate_a + \":[2010-01-01T00:00:00Z TO 2011-01-01T00:00:00Z]\"); // Should return some counts\n    //minParams.set(\"facet.query\", tdate_a + \":[* TO *]\"); // Should be removed\n    minParams.add(\"facet.query\", tdate_b + \":[2008-01-01T00:00:00Z TO 2009-09-01T00:00:00Z]\"); // Should be removed from response\n\n\n    setDistributedParams(minParams);\n    QueryResponse minResp = queryServer(minParams);\n\n    ModifiableSolrParams eParams = new ModifiableSolrParams();\n    eParams.set(\"q\",tdate_b + \":[* TO *]\");\n    eParams.set(\"rows\", 1000);\n    eParams.set(\"fl\", tdate_b);\n    setDistributedParams(eParams);\n    QueryResponse eResp = queryServer(eParams);\n\n    // Check that exactly the right numbers of counts came through\n    assertEquals(\"Should be exactly 2 range facets returned after minCounts taken into account \", 3, minResp.getFacetRanges().size());\n    assertEquals(\"Should only be 1 query facets returned after minCounts taken into account \", 1, minResp.getFacetQuery().size());\n\n    checkMinCountsField(minResp.getFacetField(i1).getValues(), new Object[]{null, 55L}); // Should just be the null entries for field\n\n    checkMinCountsRange(minResp.getFacetRanges().get(0).getCounts(), new Object[]{\"0\", 5L}); // range on i1\n    checkMinCountsRange(minResp.getFacetRanges().get(1).getCounts(), new Object[]{\"0\", 3L, \"100\", 3L}); // range on tlong\n    checkMinCountsRange(minResp.getFacetRanges().get(2).getCounts(), new Object[]{\"2009-02-01T00:00:00Z\",  3L}); // date (range) on tvh\n\n    assertTrue(\"Should have a facet for tdate_a\", minResp.getFacetQuery().containsKey(\"a_n_tdt:[2010-01-01T00:00:00Z TO 2011-01-01T00:00:00Z]\"));\n    int qCount = minResp.getFacetQuery().get(\"a_n_tdt:[2010-01-01T00:00:00Z TO 2011-01-01T00:00:00Z]\");\n    assertEquals(\"tdate_a should be 5\", qCount, 5);\n\n    // Now let's do some queries, the above is getting too complex\n    minParams = new ModifiableSolrParams();\n    minParams.set(\"q\",\"*:*\");\n    minParams.set(\"rows\", 1);\n    minParams.set(\"facet\", \"true\");\n    minParams.set(\"facet.mincount\", 3);\n\n    minParams.set(\"facet.query\", tdate_a + \":[2010-01-01T00:00:00Z TO 2010-05-04T00:00:00Z]\");\n    minParams.add(\"facet.query\", tdate_b + \":[2009-01-01T00:00:00Z TO 2010-01-01T00:00:00Z]\"); // Should be removed\n    setDistributedParams(minParams);\n    minResp = queryServer(minParams);\n\n    assertEquals(\"Should only be 1 query facets returned after minCounts taken into account \", 1, minResp.getFacetQuery().size());\n    assertTrue(\"Should be an entry for a_n_tdt\", minResp.getFacetQuery().containsKey(\"a_n_tdt:[2010-01-01T00:00:00Z TO 2010-05-04T00:00:00Z]\"));\n    qCount = minResp.getFacetQuery().get(\"a_n_tdt:[2010-01-01T00:00:00Z TO 2010-05-04T00:00:00Z]\");\n    assertEquals(\"a_n_tdt should have a count of 4 \", qCount, 4);\n    //  variations of fl\n    query(\"q\",\"*:*\", \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1 + \",score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", i1, \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id,\" + i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1, \"fl\", \"id\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",nint, \"fl\",tint,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",nint, \"fl\", \"id\", \"fl\",tint,\"sort\",i1 + \" desc\");\n\n    // basic spellcheck testing\n    query(\"q\", \"toyata\", \"fl\", \"id,lowerfilt\", \"spellcheck\", true, \"spellcheck.q\", \"toyata\", \"qt\", \"spellCheckCompRH_Direct\", \"shards.qt\", \"spellCheckCompRH_Direct\");\n\n    stress=0;  // turn off stress... we want to tex max combos in min time\n    for (int i=0; i<25*RANDOM_MULTIPLIER; i++) {\n      String f = fieldNames[random().nextInt(fieldNames.length)];\n      if (random().nextBoolean()) f = t1;  // the text field is a really interesting one to facet on (and it's multi-valued too)\n\n      // we want a random query and not just *:* so we'll get zero counts in facets also\n      // TODO: do a better random query\n      String q = random().nextBoolean() ? \"*:*\" : \"id:(1 3 5 7 9 11 13) OR id:[100 TO \" + random().nextInt(50) + \"]\";\n\n      int nolimit = random().nextBoolean() ? -1 : 10000;  // these should be equivalent\n\n      // if limit==-1, we should always get exact matches\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"count\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      // for index sort, we should get exact results for mincount <= 1\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(2), \"facet.offset\",random().nextInt(10), \"facet.limit\",random().nextInt(11)-1);\n    }\n    stress = backupStress;  // restore stress\n\n    // test faceting multiple things at once\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1);\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id:[1 TO 7]\", \"fq\",\"{!tag=b}id:[3 TO 9]\"\n    );\n    query(\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\");\n\n    // test field that is valid in schema but missing in all shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2);\n    // test field that is valid in schema and missing in some shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2);\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", \"stats_dt\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1);\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", tdate_a);\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", tdate_b);\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \n          \"fq\", \"{!tag=nothing}-*:*\",\n          \"stats.field\", \"{!key=special_key ex=nothing}stats_dt\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \n          \"f.stats_dt.stats.calcdistinct\", \"true\",\n          \"stats.field\", \"{!key=special_key}stats_dt\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \n          \"f.stats_dt.stats.calcdistinct\", \"true\",\n          \"fq\", \"{!tag=xxx}id:[3 TO 9]\",\n          \"stats.field\", \"{!key=special_key}stats_dt\",\n          \"stats.field\", \"{!ex=xxx}stats_dt\");\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\",\n          // do a really simple query so distributed IDF doesn't cause problems\n          // when comparing with control collection\n          \"stats.field\", \"{!lucene key=q_key}\" + i1 + \"foo_b:true\",\n          \"stats.field\", \"{!func key=f_key}sum(\" + tlong +\",\"+i1+\")\");\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\",\n          \"stats.field\", \"stats_dt\",\n          \"stats.field\", i1,\n          \"stats.field\", tdate_a,\n          \"stats.field\", tdate_b);\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    // check a complex key name\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"*:*\", \"rows\",100);\n    }\n\n    //SOLR 3161 ensure shards.qt=/update fails (anything but search handler really)\n    // Also see TestRemoteStreaming#testQtUpdateFails()\n    try {\n      ignoreException(\"isShard is only acceptable\");\n      // query(\"q\",\"*:*\",\"shards.qt\",\"/update\",\"stream.body\",\"<delete><query>*:*</query></delete>\");\n      // fail();\n    } catch (SolrException e) {\n      //expected\n    }\n    unIgnoreException(\"isShard is only acceptable\");\n\n    // test debugging\n    // handle.put(\"explain\", UNORDERED);\n    handle.put(\"explain\", SKIPVAL);  // internal docids differ, idf differs w/o global idf\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    handle.put(\"track\", SKIP); //track is not included in single node search\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY);\n\n    // Check Info is added to for each shard\n    ModifiableSolrParams q = new ModifiableSolrParams();\n    q.set(\"q\", \"*:*\");\n    q.set(ShardParams.SHARDS_INFO, true);\n    setDistributedParams(q);\n    rsp = queryServer(q);\n    NamedList<?> sinfo = (NamedList<?>) rsp.getResponse().get(ShardParams.SHARDS_INFO);\n    String shards = getShardsString();\n    int cnt = StringUtils.countMatches(shards, \",\")+1;\n    \n    assertNotNull(\"missing shard info\", sinfo);\n    assertEquals(\"should have an entry for each shard [\"+sinfo+\"] \"+shards, cnt, sinfo.size());\n\n    // test shards.tolerant=true\n    for(int numDownServers = 0; numDownServers < jettys.size()-1; numDownServers++)\n    {\n      List<JettySolrRunner> upJettys = new ArrayList<>(jettys);\n      List<SolrServer> upClients = new ArrayList<>(clients);\n      List<JettySolrRunner> downJettys = new ArrayList<>();\n      List<String> upShards = new ArrayList<>(Arrays.asList(shardsArr));\n      for(int i=0; i<numDownServers; i++)\n      {\n        // shut down some of the jettys\n        int indexToRemove = r.nextInt(upJettys.size());\n        JettySolrRunner downJetty = upJettys.remove(indexToRemove);\n        upClients.remove(indexToRemove);\n        upShards.remove(indexToRemove);\n        ChaosMonkey.stop(downJetty);\n        downJettys.add(downJetty);\n      }\n\n      queryPartialResults(upShards, upClients, \n          \"q\",\"*:*\",\n          \"facet\",\"true\", \n          \"facet.field\",t1,\n          \"facet.field\",t1,\n          \"facet.limit\",5,\n          ShardParams.SHARDS_INFO,\"true\",\n          ShardParams.SHARDS_TOLERANT,\"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"facet\", \"true\",\n          \"facet.query\", i1 + \":[1 TO 50]\",\n          \"facet.query\", i1 + \":[1 TO 50]\",\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      // test group query\n      // TODO: Remove this? This doesn't make any real sense now that timeAllowed might trigger early\n      //       termination of the request during Terms enumeration/Query expansion.\n      //       During such an exit, partial results isn't supported as it wouldn't make any sense.\n      // Increasing the timeAllowed from 1 to 100 for now.\n      //\n      // TODO: still failing in jenkins - see SOLR-5986\n      //\n      // queryPartialResults(upShards, upClients,\n      //     \"q\", \"*:*\",\n      //     \"rows\", 100,\n      //     \"fl\", \"id,\" + i1,\n      //     \"group\", \"true\",\n      //     \"group.query\", t1 + \":kings OR \" + t1 + \":eggs\",\n      //     \"group.limit\", 10,\n      //     \"sort\", i1 + \" asc, id asc\",\n      //     CommonParams.TIME_ALLOWED, 100,\n      //     ShardParams.SHARDS_INFO, \"true\",\n      //     ShardParams.SHARDS_TOLERANT, \"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"stats\", \"true\",\n          \"stats.field\", i1,\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"toyata\",\n          \"spellcheck\", \"true\",\n          \"spellcheck.q\", \"toyata\",\n          \"qt\", \"spellCheckCompRH_Direct\",\n          \"shards.qt\", \"spellCheckCompRH_Direct\",\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      // restart the jettys\n      for (JettySolrRunner downJetty : downJettys) {\n        downJetty.start();\n      }\n    }\n\n    // This index has the same number for every field\n    \n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // Thread.sleep(10000000000L);\n\n    del(\"*:*\"); // delete all docs and test stats request\n    commit();\n    try {\n      query(\"q\", \"*:*\", \"stats\", \"true\", \n            \"stats.field\", \"stats_dt\", \n            \"stats.field\", i1, \n            \"stats.field\", tdate_a, \n            \"stats.field\", tdate_b,\n            \"stats.calcdistinct\", \"true\");\n    } catch (HttpSolrServer.RemoteSolrException e) {\n      if (e.getMessage().startsWith(\"java.lang.NullPointerException\"))  {\n        fail(\"NullPointerException with stats request on empty index\");\n      } else  {\n        throw e;\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"bafca15d8e408346a67f4282ad1143b88023893b","date":1420034748,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/TestDistributedSearch#doTest().mjava","pathOld":"solr/core/src/test/org/apache/solr/TestDistributedSearch#doTest().mjava","sourceNew":"  @Override\n  public void doTest() throws Exception {\n    QueryResponse rsp = null;\n    int backupStress = stress; // make a copy so we can restore\n\n\n    del(\"*:*\");\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\",\n           tdate_a, \"2010-04-20T11:00:00Z\",\n           tdate_b, \"2009-08-20T11:00:00Z\",\n           \"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\",\n           tdate_a, \"2010-05-02T11:00:00Z\",\n           tdate_b, \"2009-11-02T11:00:00Z\");\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\",\n           tdate_a, \"2010-05-03T11:00:00Z\");\n    indexr(id,4, i1, -100 ,tlong, 101,\n           t1,\"the quick fox jumped over the lazy dog\", \n           tdate_a, \"2010-05-03T11:00:00Z\",\n           tdate_b, \"2010-05-03T11:00:00Z\");\n    indexr(id,5, i1, 500, tlong, 500 ,\n           t1,\"the quick fox jumped way over the lazy dog\", \n           tdate_a, \"2010-05-05T11:00:00Z\");\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,\n           tdate_b, \"2010-01-05T11:00:00Z\",\n           t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n\n    commit();  // try to ensure there's more than one segment\n\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,\n           t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,\n           t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,\n           t1,\"no eggs on wall, lesson learned\", \n           oddField, \"odd man out\");\n\n    indexr(id, \"1001\", \"lowerfilt\", \"toyota\"); // for spellcheck\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n    \n    \n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n\n    handle.clear();\n    handle.put(\"timestamp\", SKIPVAL);\n    handle.put(\"_version_\", SKIPVAL); // not a cloud test, but may use updateLog\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(\"q\",\"*:*\", \"sort\",f+\" desc\");\n      query(\"q\",\"*:*\", \"sort\",f+\" asc\");\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",\"{!func}testfunc(add(\"+i1+\",5))\"+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" asc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\");\n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"*,score\"); \n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 desc\");\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"{!func}\"+i1);// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(\"q\",\"{!func}\"+i1, \"fl\",\"*,score\");  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"quick\");\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\");\n    query(\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\");  // no fields in returned docs\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\");\n\n    handle.put(\"score\", SKIPVAL);\n    query(\"q\",\"quick\",\"fl\",\"*,score\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\");\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"matchesnothing\",\"fl\",\"*,score\");  \n\n    // test that a single NOW value is propagated to all shards... if that is true\n    // then the primary sort should always be a tie and then the secondary should always decide\n    query(\"q\",\"{!func}ms(NOW)\", \"sort\",\"score desc,\"+i1+\" desc\",\"fl\",\"id\");    \n\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1, \"facet.field\",t1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\");\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2);\n\n    // a facet query to test out chars out of the ascii range\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!term f=foo_s}international\\u00ff\\u01ff\\u2222\\u3333\");\n\n    // simple field facet on date fields\n    rsp = query(\"q\",\"*:*\", \"rows\", 0,\n                \"facet\",\"true\", \"facet.limit\", 1, // TODO: limit shouldn't be needed: SOLR-6386\n                \"facet.field\", tdate_a);\n    assertEquals(1, rsp.getFacetFields().size());\n    rsp = query(\"q\",\"*:*\", \"rows\", 0,\n                \"facet\",\"true\", \"facet.limit\", 1, // TODO: limit shouldn't be needed: SOLR-6386\n                \"facet.field\", tdate_b, \"facet.field\", tdate_a);\n    assertEquals(2, rsp.getFacetFields().size());\n\n    // simple date facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a,\n          \"facet.date\",tdate_a,\n          \"facet.date.other\", \"all\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // date facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a,\n          \"facet.date\",tdate_b,\n          \"facet.date\",tdate_a,\n          \"facet.date.other\", \"all\", \n          \"f.\"+tdate_b+\".facet.date.start\",\"2009-05-01T11:00:00Z\", \n          \"f.\"+tdate_b+\".facet.date.gap\",\"+3MONTHS\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // simple range facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong,\n          \"facet.range\",tlong,\n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"facet.range.end\",900);\n\n    // range facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range\",i1, \n          \"f.\"+i1+\".facet.range.start\",300, \n          \"f.\"+i1+\".facet.range.gap\",87, \n          \"facet.range.end\",900,\n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"f.\"+tlong+\".facet.range.end\",900);\n\n    // Test mincounts. Do NOT want to go through all the stuff where with validateControlData in query() method\n    // Purposely packing a _bunch_ of stuff together here to insure that the proper level of mincount is used for\n    // each\n    ModifiableSolrParams minParams = new ModifiableSolrParams();\n    minParams.set(\"q\",\"*:*\");\n    minParams.set(\"rows\", 1);\n    minParams.set(\"facet\", \"true\");\n    minParams.set(\"facet.missing\", \"true\");\n    minParams.set(\"facet.field\", i1);\n    minParams.set(\"facet.missing\", \"true\");\n    minParams.set(\"facet.mincount\", 2);\n\n    // Return a separate section of ranges over i1. Should respect global range mincount\n    minParams.set(\"facet.range\", i1);\n    minParams.set(\"f.\" + i1 + \".facet.range.start\", 0);\n    minParams.set(\"f.\" + i1 + \".facet.range.gap\", 200);\n    minParams.set(\"f.\" + i1 + \".facet.range.end\", 1200);\n    minParams.set(\"f.\" + i1 + \".facet.mincount\", 4);\n\n\n    // Return a separate section of ranges over tlong Should respect facet.mincount\n    minParams.add(\"facet.range\", tlong);\n    minParams.set(\"f.\" + tlong + \".facet.range.start\", 0);\n    minParams.set(\"f.\" + tlong + \".facet.range.gap\", 100);\n    minParams.set(\"f.\" + tlong + \".facet.range.end\", 1200);\n    // Repeat with a range type of date\n    minParams.add(\"facet.range\", tdate_b);\n    minParams.set(\"f.\" + tdate_b + \".facet.range.start\", \"2009-02-01T00:00:00Z\");\n    minParams.set(\"f.\" + tdate_b + \".facet.range.gap\", \"+1YEAR\");\n    minParams.set(\"f.\" + tdate_b + \".facet.range.end\", \"2011-01-01T00:00:00Z\");\n    minParams.set(\"f.\" + tdate_b + \".facet.mincount\", 3);\n\n    // Insure that global mincount is respected for facet queries\n    minParams.set(\"facet.query\", tdate_a + \":[2010-01-01T00:00:00Z TO 2011-01-01T00:00:00Z]\"); // Should return some counts\n    //minParams.set(\"facet.query\", tdate_a + \":[* TO *]\"); // Should be removed\n    minParams.add(\"facet.query\", tdate_b + \":[2008-01-01T00:00:00Z TO 2009-09-01T00:00:00Z]\"); // Should be removed from response\n\n\n    setDistributedParams(minParams);\n    QueryResponse minResp = queryServer(minParams);\n\n    ModifiableSolrParams eParams = new ModifiableSolrParams();\n    eParams.set(\"q\",tdate_b + \":[* TO *]\");\n    eParams.set(\"rows\", 1000);\n    eParams.set(\"fl\", tdate_b);\n    setDistributedParams(eParams);\n    QueryResponse eResp = queryServer(eParams);\n\n    // Check that exactly the right numbers of counts came through\n    assertEquals(\"Should be exactly 2 range facets returned after minCounts taken into account \", 3, minResp.getFacetRanges().size());\n    assertEquals(\"Should only be 1 query facets returned after minCounts taken into account \", 1, minResp.getFacetQuery().size());\n\n    checkMinCountsField(minResp.getFacetField(i1).getValues(), new Object[]{null, 55L}); // Should just be the null entries for field\n\n    checkMinCountsRange(minResp.getFacetRanges().get(0).getCounts(), new Object[]{\"0\", 5L}); // range on i1\n    checkMinCountsRange(minResp.getFacetRanges().get(1).getCounts(), new Object[]{\"0\", 3L, \"100\", 3L}); // range on tlong\n    checkMinCountsRange(minResp.getFacetRanges().get(2).getCounts(), new Object[]{\"2009-02-01T00:00:00Z\",  3L}); // date (range) on tvh\n\n    assertTrue(\"Should have a facet for tdate_a\", minResp.getFacetQuery().containsKey(\"a_n_tdt:[2010-01-01T00:00:00Z TO 2011-01-01T00:00:00Z]\"));\n    int qCount = minResp.getFacetQuery().get(\"a_n_tdt:[2010-01-01T00:00:00Z TO 2011-01-01T00:00:00Z]\");\n    assertEquals(\"tdate_a should be 5\", qCount, 5);\n\n    // Now let's do some queries, the above is getting too complex\n    minParams = new ModifiableSolrParams();\n    minParams.set(\"q\",\"*:*\");\n    minParams.set(\"rows\", 1);\n    minParams.set(\"facet\", \"true\");\n    minParams.set(\"facet.mincount\", 3);\n\n    minParams.set(\"facet.query\", tdate_a + \":[2010-01-01T00:00:00Z TO 2010-05-04T00:00:00Z]\");\n    minParams.add(\"facet.query\", tdate_b + \":[2009-01-01T00:00:00Z TO 2010-01-01T00:00:00Z]\"); // Should be removed\n    setDistributedParams(minParams);\n    minResp = queryServer(minParams);\n\n    assertEquals(\"Should only be 1 query facets returned after minCounts taken into account \", 1, minResp.getFacetQuery().size());\n    assertTrue(\"Should be an entry for a_n_tdt\", minResp.getFacetQuery().containsKey(\"a_n_tdt:[2010-01-01T00:00:00Z TO 2010-05-04T00:00:00Z]\"));\n    qCount = minResp.getFacetQuery().get(\"a_n_tdt:[2010-01-01T00:00:00Z TO 2010-05-04T00:00:00Z]\");\n    assertEquals(\"a_n_tdt should have a count of 4 \", qCount, 4);\n    //  variations of fl\n    query(\"q\",\"*:*\", \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1 + \",score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", i1, \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id,\" + i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1, \"fl\", \"id\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",nint, \"fl\",tint,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",nint, \"fl\", \"id\", \"fl\",tint,\"sort\",i1 + \" desc\");\n\n    // basic spellcheck testing\n    query(\"q\", \"toyata\", \"fl\", \"id,lowerfilt\", \"spellcheck\", true, \"spellcheck.q\", \"toyata\", \"qt\", \"spellCheckCompRH_Direct\", \"shards.qt\", \"spellCheckCompRH_Direct\");\n\n    stress=0;  // turn off stress... we want to tex max combos in min time\n    for (int i=0; i<25*RANDOM_MULTIPLIER; i++) {\n      String f = fieldNames[random().nextInt(fieldNames.length)];\n      if (random().nextBoolean()) f = t1;  // the text field is a really interesting one to facet on (and it's multi-valued too)\n\n      // we want a random query and not just *:* so we'll get zero counts in facets also\n      // TODO: do a better random query\n      String q = random().nextBoolean() ? \"*:*\" : \"id:(1 3 5 7 9 11 13) OR id:[100 TO \" + random().nextInt(50) + \"]\";\n\n      int nolimit = random().nextBoolean() ? -1 : 10000;  // these should be equivalent\n\n      // if limit==-1, we should always get exact matches\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"count\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      // for index sort, we should get exact results for mincount <= 1\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(2), \"facet.offset\",random().nextInt(10), \"facet.limit\",random().nextInt(11)-1);\n    }\n    stress = backupStress;  // restore stress\n\n    // test faceting multiple things at once\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1);\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id:[1 TO 7]\", \"fq\",\"{!tag=b}id:[3 TO 9]\"\n    );\n    query(\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\");\n\n    // test field that is valid in schema but missing in all shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2);\n    // test field that is valid in schema and missing in some shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2);\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", \"stats_dt\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1);\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", tdate_a);\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", tdate_b);\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \n          \"fq\", \"{!tag=nothing}-*:*\",\n          \"stats.field\", \"{!key=special_key ex=nothing}stats_dt\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \n          \"f.stats_dt.stats.calcdistinct\", \"true\",\n          \"stats.field\", \"{!key=special_key}stats_dt\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \n          \"f.stats_dt.stats.calcdistinct\", \"true\",\n          \"fq\", \"{!tag=xxx}id:[3 TO 9]\",\n          \"stats.field\", \"{!key=special_key}stats_dt\",\n          \"stats.field\", \"{!ex=xxx}stats_dt\");\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\",\n          // do a really simple query so distributed IDF doesn't cause problems\n          // when comparing with control collection\n          \"stats.field\", \"{!lucene key=q_key}\" + i1 + \"foo_b:true\",\n          \"stats.field\", \"{!func key=f_key}sum(\" + tlong +\",\"+i1+\")\");\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\",\n          \"stats.field\", \"stats_dt\",\n          \"stats.field\", i1,\n          \"stats.field\", tdate_a,\n          \"stats.field\", tdate_b);\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    // check a complex key name\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"*:*\", \"rows\",100);\n    }\n\n    //SOLR 3161 ensure shards.qt=/update fails (anything but search handler really)\n    // Also see TestRemoteStreaming#testQtUpdateFails()\n    try {\n      ignoreException(\"isShard is only acceptable\");\n      // query(\"q\",\"*:*\",\"shards.qt\",\"/update\",\"stream.body\",\"<delete><query>*:*</query></delete>\");\n      // fail();\n    } catch (SolrException e) {\n      //expected\n    }\n    unIgnoreException(\"isShard is only acceptable\");\n\n    // test debugging\n    // handle.put(\"explain\", UNORDERED);\n    handle.put(\"explain\", SKIPVAL);  // internal docids differ, idf differs w/o global idf\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    handle.put(\"track\", SKIP); //track is not included in single node search\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY);\n\n    // SOLR-6545, wild card field list\n    indexr(id, \"19\", \"text\", \"d\", \"cat_a_sS\", \"1\" ,t1, \"2\");\n    commit();\n\n    rsp = query(\"q\", \"id:19\", \"fl\", \"id\", \"fl\", \"*a_sS\");\n    assertFieldValues(rsp.getResults(), \"id\", 19);\n\n    rsp = query(\"q\", \"id:19\", \"fl\", \"id,\" + t1 + \",cat*\");\n    assertFieldValues(rsp.getResults(), \"id\", 19);\n\n    // Check Info is added to for each shard\n    ModifiableSolrParams q = new ModifiableSolrParams();\n    q.set(\"q\", \"*:*\");\n    q.set(ShardParams.SHARDS_INFO, true);\n    setDistributedParams(q);\n    rsp = queryServer(q);\n    NamedList<?> sinfo = (NamedList<?>) rsp.getResponse().get(ShardParams.SHARDS_INFO);\n    String shards = getShardsString();\n    int cnt = StringUtils.countMatches(shards, \",\")+1;\n    \n    assertNotNull(\"missing shard info\", sinfo);\n    assertEquals(\"should have an entry for each shard [\"+sinfo+\"] \"+shards, cnt, sinfo.size());\n\n    // test shards.tolerant=true\n    for(int numDownServers = 0; numDownServers < jettys.size()-1; numDownServers++)\n    {\n      List<JettySolrRunner> upJettys = new ArrayList<>(jettys);\n      List<SolrClient> upClients = new ArrayList<>(clients);\n      List<JettySolrRunner> downJettys = new ArrayList<>();\n      List<String> upShards = new ArrayList<>(Arrays.asList(shardsArr));\n      for(int i=0; i<numDownServers; i++)\n      {\n        // shut down some of the jettys\n        int indexToRemove = r.nextInt(upJettys.size());\n        JettySolrRunner downJetty = upJettys.remove(indexToRemove);\n        upClients.remove(indexToRemove);\n        upShards.remove(indexToRemove);\n        ChaosMonkey.stop(downJetty);\n        downJettys.add(downJetty);\n      }\n\n      queryPartialResults(upShards, upClients, \n          \"q\",\"*:*\",\n          \"facet\",\"true\", \n          \"facet.field\",t1,\n          \"facet.field\",t1,\n          \"facet.limit\",5,\n          ShardParams.SHARDS_INFO,\"true\",\n          ShardParams.SHARDS_TOLERANT,\"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"facet\", \"true\",\n          \"facet.query\", i1 + \":[1 TO 50]\",\n          \"facet.query\", i1 + \":[1 TO 50]\",\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      // test group query\n      queryPartialResults(upShards, upClients,\n           \"q\", \"*:*\",\n           \"rows\", 100,\n           \"fl\", \"id,\" + i1,\n           \"group\", \"true\",\n           \"group.query\", t1 + \":kings OR \" + t1 + \":eggs\",\n           \"group.limit\", 10,\n           \"sort\", i1 + \" asc, id asc\",\n           CommonParams.TIME_ALLOWED, 1,\n           ShardParams.SHARDS_INFO, \"true\",\n           ShardParams.SHARDS_TOLERANT, \"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"stats\", \"true\",\n          \"stats.field\", i1,\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"toyata\",\n          \"spellcheck\", \"true\",\n          \"spellcheck.q\", \"toyata\",\n          \"qt\", \"spellCheckCompRH_Direct\",\n          \"shards.qt\", \"spellCheckCompRH_Direct\",\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      // restart the jettys\n      for (JettySolrRunner downJetty : downJettys) {\n        downJetty.start();\n      }\n    }\n\n    // This index has the same number for every field\n    \n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // Thread.sleep(10000000000L);\n\n    del(\"*:*\"); // delete all docs and test stats request\n    commit();\n    try {\n      query(\"q\", \"*:*\", \"stats\", \"true\", \n            \"stats.field\", \"stats_dt\", \n            \"stats.field\", i1, \n            \"stats.field\", tdate_a, \n            \"stats.field\", tdate_b,\n            \"stats.calcdistinct\", \"true\");\n    } catch (HttpSolrClient.RemoteSolrException e) {\n      if (e.getMessage().startsWith(\"java.lang.NullPointerException\"))  {\n        fail(\"NullPointerException with stats request on empty index\");\n      } else  {\n        throw e;\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  public void doTest() throws Exception {\n    QueryResponse rsp = null;\n    int backupStress = stress; // make a copy so we can restore\n\n\n    del(\"*:*\");\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\",\n           tdate_a, \"2010-04-20T11:00:00Z\",\n           tdate_b, \"2009-08-20T11:00:00Z\",\n           \"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\",\n           tdate_a, \"2010-05-02T11:00:00Z\",\n           tdate_b, \"2009-11-02T11:00:00Z\");\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\",\n           tdate_a, \"2010-05-03T11:00:00Z\");\n    indexr(id,4, i1, -100 ,tlong, 101,\n           t1,\"the quick fox jumped over the lazy dog\", \n           tdate_a, \"2010-05-03T11:00:00Z\",\n           tdate_b, \"2010-05-03T11:00:00Z\");\n    indexr(id,5, i1, 500, tlong, 500 ,\n           t1,\"the quick fox jumped way over the lazy dog\", \n           tdate_a, \"2010-05-05T11:00:00Z\");\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,\n           tdate_b, \"2010-01-05T11:00:00Z\",\n           t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n\n    commit();  // try to ensure there's more than one segment\n\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,\n           t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,\n           t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,\n           t1,\"no eggs on wall, lesson learned\", \n           oddField, \"odd man out\");\n\n    indexr(id, \"1001\", \"lowerfilt\", \"toyota\"); // for spellcheck\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n    \n    \n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n\n    handle.clear();\n    handle.put(\"timestamp\", SKIPVAL);\n    handle.put(\"_version_\", SKIPVAL); // not a cloud test, but may use updateLog\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(\"q\",\"*:*\", \"sort\",f+\" desc\");\n      query(\"q\",\"*:*\", \"sort\",f+\" asc\");\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",\"{!func}testfunc(add(\"+i1+\",5))\"+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" asc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\");\n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"*,score\"); \n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 desc\");\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"{!func}\"+i1);// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(\"q\",\"{!func}\"+i1, \"fl\",\"*,score\");  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"quick\");\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\");\n    query(\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\");  // no fields in returned docs\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\");\n\n    handle.put(\"score\", SKIPVAL);\n    query(\"q\",\"quick\",\"fl\",\"*,score\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\");\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"matchesnothing\",\"fl\",\"*,score\");  \n\n    // test that a single NOW value is propagated to all shards... if that is true\n    // then the primary sort should always be a tie and then the secondary should always decide\n    query(\"q\",\"{!func}ms(NOW)\", \"sort\",\"score desc,\"+i1+\" desc\",\"fl\",\"id\");    \n\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1, \"facet.field\",t1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\");\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2);\n\n    // a facet query to test out chars out of the ascii range\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!term f=foo_s}international\\u00ff\\u01ff\\u2222\\u3333\");\n\n    // simple field facet on date fields\n    rsp = query(\"q\",\"*:*\", \"rows\", 0,\n                \"facet\",\"true\", \"facet.limit\", 1, // TODO: limit shouldn't be needed: SOLR-6386\n                \"facet.field\", tdate_a);\n    assertEquals(1, rsp.getFacetFields().size());\n    rsp = query(\"q\",\"*:*\", \"rows\", 0,\n                \"facet\",\"true\", \"facet.limit\", 1, // TODO: limit shouldn't be needed: SOLR-6386\n                \"facet.field\", tdate_b, \"facet.field\", tdate_a);\n    assertEquals(2, rsp.getFacetFields().size());\n\n    // simple date facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a,\n          \"facet.date\",tdate_a,\n          \"facet.date.other\", \"all\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // date facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a,\n          \"facet.date\",tdate_b,\n          \"facet.date\",tdate_a,\n          \"facet.date.other\", \"all\", \n          \"f.\"+tdate_b+\".facet.date.start\",\"2009-05-01T11:00:00Z\", \n          \"f.\"+tdate_b+\".facet.date.gap\",\"+3MONTHS\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // simple range facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong,\n          \"facet.range\",tlong,\n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"facet.range.end\",900);\n\n    // range facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range\",i1, \n          \"f.\"+i1+\".facet.range.start\",300, \n          \"f.\"+i1+\".facet.range.gap\",87, \n          \"facet.range.end\",900,\n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"f.\"+tlong+\".facet.range.end\",900);\n\n    // Test mincounts. Do NOT want to go through all the stuff where with validateControlData in query() method\n    // Purposely packing a _bunch_ of stuff together here to insure that the proper level of mincount is used for\n    // each\n    ModifiableSolrParams minParams = new ModifiableSolrParams();\n    minParams.set(\"q\",\"*:*\");\n    minParams.set(\"rows\", 1);\n    minParams.set(\"facet\", \"true\");\n    minParams.set(\"facet.missing\", \"true\");\n    minParams.set(\"facet.field\", i1);\n    minParams.set(\"facet.missing\", \"true\");\n    minParams.set(\"facet.mincount\", 2);\n\n    // Return a separate section of ranges over i1. Should respect global range mincount\n    minParams.set(\"facet.range\", i1);\n    minParams.set(\"f.\" + i1 + \".facet.range.start\", 0);\n    minParams.set(\"f.\" + i1 + \".facet.range.gap\", 200);\n    minParams.set(\"f.\" + i1 + \".facet.range.end\", 1200);\n    minParams.set(\"f.\" + i1 + \".facet.mincount\", 4);\n\n\n    // Return a separate section of ranges over tlong Should respect facet.mincount\n    minParams.add(\"facet.range\", tlong);\n    minParams.set(\"f.\" + tlong + \".facet.range.start\", 0);\n    minParams.set(\"f.\" + tlong + \".facet.range.gap\", 100);\n    minParams.set(\"f.\" + tlong + \".facet.range.end\", 1200);\n    // Repeat with a range type of date\n    minParams.add(\"facet.range\", tdate_b);\n    minParams.set(\"f.\" + tdate_b + \".facet.range.start\", \"2009-02-01T00:00:00Z\");\n    minParams.set(\"f.\" + tdate_b + \".facet.range.gap\", \"+1YEAR\");\n    minParams.set(\"f.\" + tdate_b + \".facet.range.end\", \"2011-01-01T00:00:00Z\");\n    minParams.set(\"f.\" + tdate_b + \".facet.mincount\", 3);\n\n    // Insure that global mincount is respected for facet queries\n    minParams.set(\"facet.query\", tdate_a + \":[2010-01-01T00:00:00Z TO 2011-01-01T00:00:00Z]\"); // Should return some counts\n    //minParams.set(\"facet.query\", tdate_a + \":[* TO *]\"); // Should be removed\n    minParams.add(\"facet.query\", tdate_b + \":[2008-01-01T00:00:00Z TO 2009-09-01T00:00:00Z]\"); // Should be removed from response\n\n\n    setDistributedParams(minParams);\n    QueryResponse minResp = queryServer(minParams);\n\n    ModifiableSolrParams eParams = new ModifiableSolrParams();\n    eParams.set(\"q\",tdate_b + \":[* TO *]\");\n    eParams.set(\"rows\", 1000);\n    eParams.set(\"fl\", tdate_b);\n    setDistributedParams(eParams);\n    QueryResponse eResp = queryServer(eParams);\n\n    // Check that exactly the right numbers of counts came through\n    assertEquals(\"Should be exactly 2 range facets returned after minCounts taken into account \", 3, minResp.getFacetRanges().size());\n    assertEquals(\"Should only be 1 query facets returned after minCounts taken into account \", 1, minResp.getFacetQuery().size());\n\n    checkMinCountsField(minResp.getFacetField(i1).getValues(), new Object[]{null, 55L}); // Should just be the null entries for field\n\n    checkMinCountsRange(minResp.getFacetRanges().get(0).getCounts(), new Object[]{\"0\", 5L}); // range on i1\n    checkMinCountsRange(minResp.getFacetRanges().get(1).getCounts(), new Object[]{\"0\", 3L, \"100\", 3L}); // range on tlong\n    checkMinCountsRange(minResp.getFacetRanges().get(2).getCounts(), new Object[]{\"2009-02-01T00:00:00Z\",  3L}); // date (range) on tvh\n\n    assertTrue(\"Should have a facet for tdate_a\", minResp.getFacetQuery().containsKey(\"a_n_tdt:[2010-01-01T00:00:00Z TO 2011-01-01T00:00:00Z]\"));\n    int qCount = minResp.getFacetQuery().get(\"a_n_tdt:[2010-01-01T00:00:00Z TO 2011-01-01T00:00:00Z]\");\n    assertEquals(\"tdate_a should be 5\", qCount, 5);\n\n    // Now let's do some queries, the above is getting too complex\n    minParams = new ModifiableSolrParams();\n    minParams.set(\"q\",\"*:*\");\n    minParams.set(\"rows\", 1);\n    minParams.set(\"facet\", \"true\");\n    minParams.set(\"facet.mincount\", 3);\n\n    minParams.set(\"facet.query\", tdate_a + \":[2010-01-01T00:00:00Z TO 2010-05-04T00:00:00Z]\");\n    minParams.add(\"facet.query\", tdate_b + \":[2009-01-01T00:00:00Z TO 2010-01-01T00:00:00Z]\"); // Should be removed\n    setDistributedParams(minParams);\n    minResp = queryServer(minParams);\n\n    assertEquals(\"Should only be 1 query facets returned after minCounts taken into account \", 1, minResp.getFacetQuery().size());\n    assertTrue(\"Should be an entry for a_n_tdt\", minResp.getFacetQuery().containsKey(\"a_n_tdt:[2010-01-01T00:00:00Z TO 2010-05-04T00:00:00Z]\"));\n    qCount = minResp.getFacetQuery().get(\"a_n_tdt:[2010-01-01T00:00:00Z TO 2010-05-04T00:00:00Z]\");\n    assertEquals(\"a_n_tdt should have a count of 4 \", qCount, 4);\n    //  variations of fl\n    query(\"q\",\"*:*\", \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1 + \",score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", i1, \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id,\" + i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1, \"fl\", \"id\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",nint, \"fl\",tint,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",nint, \"fl\", \"id\", \"fl\",tint,\"sort\",i1 + \" desc\");\n\n    // basic spellcheck testing\n    query(\"q\", \"toyata\", \"fl\", \"id,lowerfilt\", \"spellcheck\", true, \"spellcheck.q\", \"toyata\", \"qt\", \"spellCheckCompRH_Direct\", \"shards.qt\", \"spellCheckCompRH_Direct\");\n\n    stress=0;  // turn off stress... we want to tex max combos in min time\n    for (int i=0; i<25*RANDOM_MULTIPLIER; i++) {\n      String f = fieldNames[random().nextInt(fieldNames.length)];\n      if (random().nextBoolean()) f = t1;  // the text field is a really interesting one to facet on (and it's multi-valued too)\n\n      // we want a random query and not just *:* so we'll get zero counts in facets also\n      // TODO: do a better random query\n      String q = random().nextBoolean() ? \"*:*\" : \"id:(1 3 5 7 9 11 13) OR id:[100 TO \" + random().nextInt(50) + \"]\";\n\n      int nolimit = random().nextBoolean() ? -1 : 10000;  // these should be equivalent\n\n      // if limit==-1, we should always get exact matches\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"count\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      // for index sort, we should get exact results for mincount <= 1\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(2), \"facet.offset\",random().nextInt(10), \"facet.limit\",random().nextInt(11)-1);\n    }\n    stress = backupStress;  // restore stress\n\n    // test faceting multiple things at once\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1);\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id:[1 TO 7]\", \"fq\",\"{!tag=b}id:[3 TO 9]\"\n    );\n    query(\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\");\n\n    // test field that is valid in schema but missing in all shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2);\n    // test field that is valid in schema and missing in some shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2);\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", \"stats_dt\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1);\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", tdate_a);\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", tdate_b);\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \n          \"fq\", \"{!tag=nothing}-*:*\",\n          \"stats.field\", \"{!key=special_key ex=nothing}stats_dt\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \n          \"f.stats_dt.stats.calcdistinct\", \"true\",\n          \"stats.field\", \"{!key=special_key}stats_dt\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \n          \"f.stats_dt.stats.calcdistinct\", \"true\",\n          \"fq\", \"{!tag=xxx}id:[3 TO 9]\",\n          \"stats.field\", \"{!key=special_key}stats_dt\",\n          \"stats.field\", \"{!ex=xxx}stats_dt\");\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\",\n          // do a really simple query so distributed IDF doesn't cause problems\n          // when comparing with control collection\n          \"stats.field\", \"{!lucene key=q_key}\" + i1 + \"foo_b:true\",\n          \"stats.field\", \"{!func key=f_key}sum(\" + tlong +\",\"+i1+\")\");\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\",\n          \"stats.field\", \"stats_dt\",\n          \"stats.field\", i1,\n          \"stats.field\", tdate_a,\n          \"stats.field\", tdate_b);\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    // check a complex key name\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"*:*\", \"rows\",100);\n    }\n\n    //SOLR 3161 ensure shards.qt=/update fails (anything but search handler really)\n    // Also see TestRemoteStreaming#testQtUpdateFails()\n    try {\n      ignoreException(\"isShard is only acceptable\");\n      // query(\"q\",\"*:*\",\"shards.qt\",\"/update\",\"stream.body\",\"<delete><query>*:*</query></delete>\");\n      // fail();\n    } catch (SolrException e) {\n      //expected\n    }\n    unIgnoreException(\"isShard is only acceptable\");\n\n    // test debugging\n    // handle.put(\"explain\", UNORDERED);\n    handle.put(\"explain\", SKIPVAL);  // internal docids differ, idf differs w/o global idf\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    handle.put(\"track\", SKIP); //track is not included in single node search\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY);\n\n    // SOLR-6545, wild card field list\n    indexr(id, \"19\", \"text\", \"d\", \"cat_a_sS\", \"1\" ,t1, \"2\");\n    commit();\n\n    rsp = query(\"q\", \"id:19\", \"fl\", \"id\", \"fl\", \"*a_sS\");\n    assertFieldValues(rsp.getResults(), \"id\", 19);\n\n    rsp = query(\"q\", \"id:19\", \"fl\", \"id,\" + t1 + \",cat*\");\n    assertFieldValues(rsp.getResults(), \"id\", 19);\n\n    // Check Info is added to for each shard\n    ModifiableSolrParams q = new ModifiableSolrParams();\n    q.set(\"q\", \"*:*\");\n    q.set(ShardParams.SHARDS_INFO, true);\n    setDistributedParams(q);\n    rsp = queryServer(q);\n    NamedList<?> sinfo = (NamedList<?>) rsp.getResponse().get(ShardParams.SHARDS_INFO);\n    String shards = getShardsString();\n    int cnt = StringUtils.countMatches(shards, \",\")+1;\n    \n    assertNotNull(\"missing shard info\", sinfo);\n    assertEquals(\"should have an entry for each shard [\"+sinfo+\"] \"+shards, cnt, sinfo.size());\n\n    // test shards.tolerant=true\n    for(int numDownServers = 0; numDownServers < jettys.size()-1; numDownServers++)\n    {\n      List<JettySolrRunner> upJettys = new ArrayList<>(jettys);\n      List<SolrServer> upClients = new ArrayList<>(clients);\n      List<JettySolrRunner> downJettys = new ArrayList<>();\n      List<String> upShards = new ArrayList<>(Arrays.asList(shardsArr));\n      for(int i=0; i<numDownServers; i++)\n      {\n        // shut down some of the jettys\n        int indexToRemove = r.nextInt(upJettys.size());\n        JettySolrRunner downJetty = upJettys.remove(indexToRemove);\n        upClients.remove(indexToRemove);\n        upShards.remove(indexToRemove);\n        ChaosMonkey.stop(downJetty);\n        downJettys.add(downJetty);\n      }\n\n      queryPartialResults(upShards, upClients, \n          \"q\",\"*:*\",\n          \"facet\",\"true\", \n          \"facet.field\",t1,\n          \"facet.field\",t1,\n          \"facet.limit\",5,\n          ShardParams.SHARDS_INFO,\"true\",\n          ShardParams.SHARDS_TOLERANT,\"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"facet\", \"true\",\n          \"facet.query\", i1 + \":[1 TO 50]\",\n          \"facet.query\", i1 + \":[1 TO 50]\",\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      // test group query\n      queryPartialResults(upShards, upClients,\n           \"q\", \"*:*\",\n           \"rows\", 100,\n           \"fl\", \"id,\" + i1,\n           \"group\", \"true\",\n           \"group.query\", t1 + \":kings OR \" + t1 + \":eggs\",\n           \"group.limit\", 10,\n           \"sort\", i1 + \" asc, id asc\",\n           CommonParams.TIME_ALLOWED, 1,\n           ShardParams.SHARDS_INFO, \"true\",\n           ShardParams.SHARDS_TOLERANT, \"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"stats\", \"true\",\n          \"stats.field\", i1,\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"toyata\",\n          \"spellcheck\", \"true\",\n          \"spellcheck.q\", \"toyata\",\n          \"qt\", \"spellCheckCompRH_Direct\",\n          \"shards.qt\", \"spellCheckCompRH_Direct\",\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      // restart the jettys\n      for (JettySolrRunner downJetty : downJettys) {\n        downJetty.start();\n      }\n    }\n\n    // This index has the same number for every field\n    \n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // Thread.sleep(10000000000L);\n\n    del(\"*:*\"); // delete all docs and test stats request\n    commit();\n    try {\n      query(\"q\", \"*:*\", \"stats\", \"true\", \n            \"stats.field\", \"stats_dt\", \n            \"stats.field\", i1, \n            \"stats.field\", tdate_a, \n            \"stats.field\", tdate_b,\n            \"stats.calcdistinct\", \"true\");\n    } catch (HttpSolrServer.RemoteSolrException e) {\n      if (e.getMessage().startsWith(\"java.lang.NullPointerException\"))  {\n        fail(\"NullPointerException with stats request on empty index\");\n      } else  {\n        throw e;\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":["bb222a3f9d9421d5c95afce73013fbd8de07ea1f"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"708afaee6d15fdeac34f31c2e05fb32ee7145bc0","date":1420229296,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/TestDistributedSearch#doTest().mjava","pathOld":"solr/core/src/test/org/apache/solr/TestDistributedSearch#doTest().mjava","sourceNew":"  @Override\n  public void doTest() throws Exception {\n    QueryResponse rsp = null;\n    int backupStress = stress; // make a copy so we can restore\n\n\n    del(\"*:*\");\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\",\n           tdate_a, \"2010-04-20T11:00:00Z\",\n           tdate_b, \"2009-08-20T11:00:00Z\",\n           \"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\",\n           tdate_a, \"2010-05-02T11:00:00Z\",\n           tdate_b, \"2009-11-02T11:00:00Z\");\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\",\n           tdate_a, \"2010-05-03T11:00:00Z\");\n    indexr(id,4, i1, -100 ,tlong, 101,\n           t1,\"the quick fox jumped over the lazy dog\", \n           tdate_a, \"2010-05-03T11:00:00Z\",\n           tdate_b, \"2010-05-03T11:00:00Z\");\n    indexr(id,5, i1, 500, tlong, 500 ,\n           t1,\"the quick fox jumped way over the lazy dog\", \n           tdate_a, \"2010-05-05T11:00:00Z\");\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,\n           tdate_b, \"2010-01-05T11:00:00Z\",\n           t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n\n    commit();  // try to ensure there's more than one segment\n\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,\n           t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,\n           t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,\n           t1,\"no eggs on wall, lesson learned\", \n           oddField, \"odd man out\");\n\n    indexr(id, \"1001\", \"lowerfilt\", \"toyota\"); // for spellcheck\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n    \n    \n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n\n    handle.clear();\n    handle.put(\"timestamp\", SKIPVAL);\n    handle.put(\"_version_\", SKIPVAL); // not a cloud test, but may use updateLog\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(\"q\",\"*:*\", \"sort\",f+\" desc\");\n      query(\"q\",\"*:*\", \"sort\",f+\" asc\");\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",\"{!func}testfunc(add(\"+i1+\",5))\"+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" asc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\");\n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"*,score\"); \n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 desc\");\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"{!func}\"+i1);// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(\"q\",\"{!func}\"+i1, \"fl\",\"*,score\");  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"quick\");\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\");\n    query(\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\");  // no fields in returned docs\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\");\n\n    handle.put(\"score\", SKIPVAL);\n    query(\"q\",\"quick\",\"fl\",\"*,score\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\");\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"matchesnothing\",\"fl\",\"*,score\");  \n\n    // test that a single NOW value is propagated to all shards... if that is true\n    // then the primary sort should always be a tie and then the secondary should always decide\n    query(\"q\",\"{!func}ms(NOW)\", \"sort\",\"score desc,\"+i1+\" desc\",\"fl\",\"id\");    \n\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1, \"facet.field\",t1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\");\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2);\n\n    // a facet query to test out chars out of the ascii range\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!term f=foo_s}international\\u00ff\\u01ff\\u2222\\u3333\");\n\n    // simple field facet on date fields\n    rsp = query(\"q\",\"*:*\", \"rows\", 0,\n                \"facet\",\"true\", \"facet.limit\", 1, // TODO: limit shouldn't be needed: SOLR-6386\n                \"facet.field\", tdate_a);\n    assertEquals(1, rsp.getFacetFields().size());\n    rsp = query(\"q\",\"*:*\", \"rows\", 0,\n                \"facet\",\"true\", \"facet.limit\", 1, // TODO: limit shouldn't be needed: SOLR-6386\n                \"facet.field\", tdate_b, \"facet.field\", tdate_a);\n    assertEquals(2, rsp.getFacetFields().size());\n\n    // simple date facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a,\n          \"facet.date\",tdate_a,\n          \"facet.date.other\", \"all\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // date facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a,\n          \"facet.date\",tdate_b,\n          \"facet.date\",tdate_a,\n          \"facet.date.other\", \"all\", \n          \"f.\"+tdate_b+\".facet.date.start\",\"2009-05-01T11:00:00Z\", \n          \"f.\"+tdate_b+\".facet.date.gap\",\"+3MONTHS\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // simple range facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong,\n          \"facet.range\",tlong,\n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"facet.range.end\",900);\n\n    // range facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range\",i1, \n          \"f.\"+i1+\".facet.range.start\",300, \n          \"f.\"+i1+\".facet.range.gap\",87, \n          \"facet.range.end\",900,\n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"f.\"+tlong+\".facet.range.end\",900);\n\n    // Test mincounts. Do NOT want to go through all the stuff where with validateControlData in query() method\n    // Purposely packing a _bunch_ of stuff together here to insure that the proper level of mincount is used for\n    // each\n    ModifiableSolrParams minParams = new ModifiableSolrParams();\n    minParams.set(\"q\",\"*:*\");\n    minParams.set(\"rows\", 1);\n    minParams.set(\"facet\", \"true\");\n    minParams.set(\"facet.missing\", \"true\");\n    minParams.set(\"facet.field\", i1);\n    minParams.set(\"facet.missing\", \"true\");\n    minParams.set(\"facet.mincount\", 2);\n\n    // Return a separate section of ranges over i1. Should respect global range mincount\n    minParams.set(\"facet.range\", i1);\n    minParams.set(\"f.\" + i1 + \".facet.range.start\", 0);\n    minParams.set(\"f.\" + i1 + \".facet.range.gap\", 200);\n    minParams.set(\"f.\" + i1 + \".facet.range.end\", 1200);\n    minParams.set(\"f.\" + i1 + \".facet.mincount\", 4);\n\n\n    // Return a separate section of ranges over tlong Should respect facet.mincount\n    minParams.add(\"facet.range\", tlong);\n    minParams.set(\"f.\" + tlong + \".facet.range.start\", 0);\n    minParams.set(\"f.\" + tlong + \".facet.range.gap\", 100);\n    minParams.set(\"f.\" + tlong + \".facet.range.end\", 1200);\n    // Repeat with a range type of date\n    minParams.add(\"facet.range\", tdate_b);\n    minParams.set(\"f.\" + tdate_b + \".facet.range.start\", \"2009-02-01T00:00:00Z\");\n    minParams.set(\"f.\" + tdate_b + \".facet.range.gap\", \"+1YEAR\");\n    minParams.set(\"f.\" + tdate_b + \".facet.range.end\", \"2011-01-01T00:00:00Z\");\n    minParams.set(\"f.\" + tdate_b + \".facet.mincount\", 3);\n\n    // Insure that global mincount is respected for facet queries\n    minParams.set(\"facet.query\", tdate_a + \":[2010-01-01T00:00:00Z TO 2011-01-01T00:00:00Z]\"); // Should return some counts\n    //minParams.set(\"facet.query\", tdate_a + \":[* TO *]\"); // Should be removed\n    minParams.add(\"facet.query\", tdate_b + \":[2008-01-01T00:00:00Z TO 2009-09-01T00:00:00Z]\"); // Should be removed from response\n\n\n    setDistributedParams(minParams);\n    QueryResponse minResp = queryServer(minParams);\n\n    ModifiableSolrParams eParams = new ModifiableSolrParams();\n    eParams.set(\"q\",tdate_b + \":[* TO *]\");\n    eParams.set(\"rows\", 1000);\n    eParams.set(\"fl\", tdate_b);\n    setDistributedParams(eParams);\n    QueryResponse eResp = queryServer(eParams);\n\n    // Check that exactly the right numbers of counts came through\n    assertEquals(\"Should be exactly 2 range facets returned after minCounts taken into account \", 3, minResp.getFacetRanges().size());\n    assertEquals(\"Should only be 1 query facets returned after minCounts taken into account \", 1, minResp.getFacetQuery().size());\n\n    checkMinCountsField(minResp.getFacetField(i1).getValues(), new Object[]{null, 55L}); // Should just be the null entries for field\n\n    checkMinCountsRange(minResp.getFacetRanges().get(0).getCounts(), new Object[]{\"0\", 5L}); // range on i1\n    checkMinCountsRange(minResp.getFacetRanges().get(1).getCounts(), new Object[]{\"0\", 3L, \"100\", 3L}); // range on tlong\n    checkMinCountsRange(minResp.getFacetRanges().get(2).getCounts(), new Object[]{\"2009-02-01T00:00:00Z\",  3L}); // date (range) on tvh\n\n    assertTrue(\"Should have a facet for tdate_a\", minResp.getFacetQuery().containsKey(\"a_n_tdt:[2010-01-01T00:00:00Z TO 2011-01-01T00:00:00Z]\"));\n    int qCount = minResp.getFacetQuery().get(\"a_n_tdt:[2010-01-01T00:00:00Z TO 2011-01-01T00:00:00Z]\");\n    assertEquals(\"tdate_a should be 5\", qCount, 5);\n\n    // Now let's do some queries, the above is getting too complex\n    minParams = new ModifiableSolrParams();\n    minParams.set(\"q\",\"*:*\");\n    minParams.set(\"rows\", 1);\n    minParams.set(\"facet\", \"true\");\n    minParams.set(\"facet.mincount\", 3);\n\n    minParams.set(\"facet.query\", tdate_a + \":[2010-01-01T00:00:00Z TO 2010-05-04T00:00:00Z]\");\n    minParams.add(\"facet.query\", tdate_b + \":[2009-01-01T00:00:00Z TO 2010-01-01T00:00:00Z]\"); // Should be removed\n    setDistributedParams(minParams);\n    minResp = queryServer(minParams);\n\n    assertEquals(\"Should only be 1 query facets returned after minCounts taken into account \", 1, minResp.getFacetQuery().size());\n    assertTrue(\"Should be an entry for a_n_tdt\", minResp.getFacetQuery().containsKey(\"a_n_tdt:[2010-01-01T00:00:00Z TO 2010-05-04T00:00:00Z]\"));\n    qCount = minResp.getFacetQuery().get(\"a_n_tdt:[2010-01-01T00:00:00Z TO 2010-05-04T00:00:00Z]\");\n    assertEquals(\"a_n_tdt should have a count of 4 \", qCount, 4);\n    //  variations of fl\n    query(\"q\",\"*:*\", \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1 + \",score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", i1, \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id,\" + i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1, \"fl\", \"id\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",nint, \"fl\",tint,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",nint, \"fl\", \"id\", \"fl\",tint,\"sort\",i1 + \" desc\");\n    handle.put(\"did\", SKIPVAL);\n    query(\"q\",\"*:*\", \"fl\",\"did:[docid]\",\"sort\",i1 + \" desc\");\n    handle.remove(\"did\");\n    query(\"q\",\"*:*\", \"fl\",\"log(\" + tlong + \"),abs(\" + tlong + \"),score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",\"n_*\",\"sort\",i1 + \" desc\");\n\n    // basic spellcheck testing\n    query(\"q\", \"toyata\", \"fl\", \"id,lowerfilt\", \"spellcheck\", true, \"spellcheck.q\", \"toyata\", \"qt\", \"spellCheckCompRH_Direct\", \"shards.qt\", \"spellCheckCompRH_Direct\");\n\n    stress=0;  // turn off stress... we want to tex max combos in min time\n    for (int i=0; i<25*RANDOM_MULTIPLIER; i++) {\n      String f = fieldNames[random().nextInt(fieldNames.length)];\n      if (random().nextBoolean()) f = t1;  // the text field is a really interesting one to facet on (and it's multi-valued too)\n\n      // we want a random query and not just *:* so we'll get zero counts in facets also\n      // TODO: do a better random query\n      String q = random().nextBoolean() ? \"*:*\" : \"id:(1 3 5 7 9 11 13) OR id:[100 TO \" + random().nextInt(50) + \"]\";\n\n      int nolimit = random().nextBoolean() ? -1 : 10000;  // these should be equivalent\n\n      // if limit==-1, we should always get exact matches\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"count\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      // for index sort, we should get exact results for mincount <= 1\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(2), \"facet.offset\",random().nextInt(10), \"facet.limit\",random().nextInt(11)-1);\n    }\n    stress = backupStress;  // restore stress\n\n    // test faceting multiple things at once\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1);\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id:[1 TO 7]\", \"fq\",\"{!tag=b}id:[3 TO 9]\"\n    );\n    query(\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\");\n\n    // test field that is valid in schema but missing in all shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2);\n    // test field that is valid in schema and missing in some shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2);\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", \"stats_dt\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1);\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", tdate_a);\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", tdate_b);\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \n          \"fq\", \"{!tag=nothing}-*:*\",\n          \"stats.field\", \"{!key=special_key ex=nothing}stats_dt\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \n          \"f.stats_dt.stats.calcdistinct\", \"true\",\n          \"stats.field\", \"{!key=special_key}stats_dt\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \n          \"f.stats_dt.stats.calcdistinct\", \"true\",\n          \"fq\", \"{!tag=xxx}id:[3 TO 9]\",\n          \"stats.field\", \"{!key=special_key}stats_dt\",\n          \"stats.field\", \"{!ex=xxx}stats_dt\");\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\",\n          // do a really simple query so distributed IDF doesn't cause problems\n          // when comparing with control collection\n          \"stats.field\", \"{!lucene key=q_key}\" + i1 + \"foo_b:true\",\n          \"stats.field\", \"{!func key=f_key}sum(\" + tlong +\",\"+i1+\")\");\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\",\n          \"stats.field\", \"stats_dt\",\n          \"stats.field\", i1,\n          \"stats.field\", tdate_a,\n          \"stats.field\", tdate_b);\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    // check a complex key name\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"*:*\", \"rows\",100);\n    }\n\n    //SOLR 3161 ensure shards.qt=/update fails (anything but search handler really)\n    // Also see TestRemoteStreaming#testQtUpdateFails()\n    try {\n      ignoreException(\"isShard is only acceptable\");\n      // query(\"q\",\"*:*\",\"shards.qt\",\"/update\",\"stream.body\",\"<delete><query>*:*</query></delete>\");\n      // fail();\n    } catch (SolrException e) {\n      //expected\n    }\n    unIgnoreException(\"isShard is only acceptable\");\n\n    // test debugging\n    // handle.put(\"explain\", UNORDERED);\n    handle.put(\"explain\", SKIPVAL);  // internal docids differ, idf differs w/o global idf\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    handle.put(\"track\", SKIP); //track is not included in single node search\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY);\n\n    // SOLR-6545, wild card field list\n    indexr(id, \"19\", \"text\", \"d\", \"cat_a_sS\", \"1\" ,t1, \"2\");\n    commit();\n\n    rsp = query(\"q\", \"id:19\", \"fl\", \"id\", \"fl\", \"*a_sS\");\n    assertFieldValues(rsp.getResults(), \"id\", 19);\n\n    rsp = query(\"q\", \"id:19\", \"fl\", \"id,\" + t1 + \",cat*\");\n    assertFieldValues(rsp.getResults(), \"id\", 19);\n\n    // Check Info is added to for each shard\n    ModifiableSolrParams q = new ModifiableSolrParams();\n    q.set(\"q\", \"*:*\");\n    q.set(ShardParams.SHARDS_INFO, true);\n    setDistributedParams(q);\n    rsp = queryServer(q);\n    NamedList<?> sinfo = (NamedList<?>) rsp.getResponse().get(ShardParams.SHARDS_INFO);\n    String shards = getShardsString();\n    int cnt = StringUtils.countMatches(shards, \",\")+1;\n    \n    assertNotNull(\"missing shard info\", sinfo);\n    assertEquals(\"should have an entry for each shard [\"+sinfo+\"] \"+shards, cnt, sinfo.size());\n\n    // test shards.tolerant=true\n    for(int numDownServers = 0; numDownServers < jettys.size()-1; numDownServers++)\n    {\n      List<JettySolrRunner> upJettys = new ArrayList<>(jettys);\n      List<SolrClient> upClients = new ArrayList<>(clients);\n      List<JettySolrRunner> downJettys = new ArrayList<>();\n      List<String> upShards = new ArrayList<>(Arrays.asList(shardsArr));\n      for(int i=0; i<numDownServers; i++)\n      {\n        // shut down some of the jettys\n        int indexToRemove = r.nextInt(upJettys.size());\n        JettySolrRunner downJetty = upJettys.remove(indexToRemove);\n        upClients.remove(indexToRemove);\n        upShards.remove(indexToRemove);\n        ChaosMonkey.stop(downJetty);\n        downJettys.add(downJetty);\n      }\n\n      queryPartialResults(upShards, upClients, \n          \"q\",\"*:*\",\n          \"facet\",\"true\", \n          \"facet.field\",t1,\n          \"facet.field\",t1,\n          \"facet.limit\",5,\n          ShardParams.SHARDS_INFO,\"true\",\n          ShardParams.SHARDS_TOLERANT,\"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"facet\", \"true\",\n          \"facet.query\", i1 + \":[1 TO 50]\",\n          \"facet.query\", i1 + \":[1 TO 50]\",\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      // test group query\n      queryPartialResults(upShards, upClients,\n           \"q\", \"*:*\",\n           \"rows\", 100,\n           \"fl\", \"id,\" + i1,\n           \"group\", \"true\",\n           \"group.query\", t1 + \":kings OR \" + t1 + \":eggs\",\n           \"group.limit\", 10,\n           \"sort\", i1 + \" asc, id asc\",\n           CommonParams.TIME_ALLOWED, 1,\n           ShardParams.SHARDS_INFO, \"true\",\n           ShardParams.SHARDS_TOLERANT, \"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"stats\", \"true\",\n          \"stats.field\", i1,\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"toyata\",\n          \"spellcheck\", \"true\",\n          \"spellcheck.q\", \"toyata\",\n          \"qt\", \"spellCheckCompRH_Direct\",\n          \"shards.qt\", \"spellCheckCompRH_Direct\",\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      // restart the jettys\n      for (JettySolrRunner downJetty : downJettys) {\n        downJetty.start();\n      }\n    }\n\n    // This index has the same number for every field\n    \n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // Thread.sleep(10000000000L);\n\n    del(\"*:*\"); // delete all docs and test stats request\n    commit();\n    try {\n      query(\"q\", \"*:*\", \"stats\", \"true\", \n            \"stats.field\", \"stats_dt\", \n            \"stats.field\", i1, \n            \"stats.field\", tdate_a, \n            \"stats.field\", tdate_b,\n            \"stats.calcdistinct\", \"true\");\n    } catch (HttpSolrClient.RemoteSolrException e) {\n      if (e.getMessage().startsWith(\"java.lang.NullPointerException\"))  {\n        fail(\"NullPointerException with stats request on empty index\");\n      } else  {\n        throw e;\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  public void doTest() throws Exception {\n    QueryResponse rsp = null;\n    int backupStress = stress; // make a copy so we can restore\n\n\n    del(\"*:*\");\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\",\n           tdate_a, \"2010-04-20T11:00:00Z\",\n           tdate_b, \"2009-08-20T11:00:00Z\",\n           \"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\",\n           tdate_a, \"2010-05-02T11:00:00Z\",\n           tdate_b, \"2009-11-02T11:00:00Z\");\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\",\n           tdate_a, \"2010-05-03T11:00:00Z\");\n    indexr(id,4, i1, -100 ,tlong, 101,\n           t1,\"the quick fox jumped over the lazy dog\", \n           tdate_a, \"2010-05-03T11:00:00Z\",\n           tdate_b, \"2010-05-03T11:00:00Z\");\n    indexr(id,5, i1, 500, tlong, 500 ,\n           t1,\"the quick fox jumped way over the lazy dog\", \n           tdate_a, \"2010-05-05T11:00:00Z\");\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,\n           tdate_b, \"2010-01-05T11:00:00Z\",\n           t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n\n    commit();  // try to ensure there's more than one segment\n\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,\n           t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,\n           t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,\n           t1,\"no eggs on wall, lesson learned\", \n           oddField, \"odd man out\");\n\n    indexr(id, \"1001\", \"lowerfilt\", \"toyota\"); // for spellcheck\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n    \n    \n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n\n    handle.clear();\n    handle.put(\"timestamp\", SKIPVAL);\n    handle.put(\"_version_\", SKIPVAL); // not a cloud test, but may use updateLog\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(\"q\",\"*:*\", \"sort\",f+\" desc\");\n      query(\"q\",\"*:*\", \"sort\",f+\" asc\");\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",\"{!func}testfunc(add(\"+i1+\",5))\"+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" asc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\");\n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"*,score\"); \n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 desc\");\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"{!func}\"+i1);// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(\"q\",\"{!func}\"+i1, \"fl\",\"*,score\");  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"quick\");\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\");\n    query(\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\");  // no fields in returned docs\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\");\n\n    handle.put(\"score\", SKIPVAL);\n    query(\"q\",\"quick\",\"fl\",\"*,score\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\");\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"matchesnothing\",\"fl\",\"*,score\");  \n\n    // test that a single NOW value is propagated to all shards... if that is true\n    // then the primary sort should always be a tie and then the secondary should always decide\n    query(\"q\",\"{!func}ms(NOW)\", \"sort\",\"score desc,\"+i1+\" desc\",\"fl\",\"id\");    \n\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1, \"facet.field\",t1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\");\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2);\n\n    // a facet query to test out chars out of the ascii range\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!term f=foo_s}international\\u00ff\\u01ff\\u2222\\u3333\");\n\n    // simple field facet on date fields\n    rsp = query(\"q\",\"*:*\", \"rows\", 0,\n                \"facet\",\"true\", \"facet.limit\", 1, // TODO: limit shouldn't be needed: SOLR-6386\n                \"facet.field\", tdate_a);\n    assertEquals(1, rsp.getFacetFields().size());\n    rsp = query(\"q\",\"*:*\", \"rows\", 0,\n                \"facet\",\"true\", \"facet.limit\", 1, // TODO: limit shouldn't be needed: SOLR-6386\n                \"facet.field\", tdate_b, \"facet.field\", tdate_a);\n    assertEquals(2, rsp.getFacetFields().size());\n\n    // simple date facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a,\n          \"facet.date\",tdate_a,\n          \"facet.date.other\", \"all\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // date facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a,\n          \"facet.date\",tdate_b,\n          \"facet.date\",tdate_a,\n          \"facet.date.other\", \"all\", \n          \"f.\"+tdate_b+\".facet.date.start\",\"2009-05-01T11:00:00Z\", \n          \"f.\"+tdate_b+\".facet.date.gap\",\"+3MONTHS\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // simple range facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong,\n          \"facet.range\",tlong,\n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"facet.range.end\",900);\n\n    // range facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range\",i1, \n          \"f.\"+i1+\".facet.range.start\",300, \n          \"f.\"+i1+\".facet.range.gap\",87, \n          \"facet.range.end\",900,\n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"f.\"+tlong+\".facet.range.end\",900);\n\n    // Test mincounts. Do NOT want to go through all the stuff where with validateControlData in query() method\n    // Purposely packing a _bunch_ of stuff together here to insure that the proper level of mincount is used for\n    // each\n    ModifiableSolrParams minParams = new ModifiableSolrParams();\n    minParams.set(\"q\",\"*:*\");\n    minParams.set(\"rows\", 1);\n    minParams.set(\"facet\", \"true\");\n    minParams.set(\"facet.missing\", \"true\");\n    minParams.set(\"facet.field\", i1);\n    minParams.set(\"facet.missing\", \"true\");\n    minParams.set(\"facet.mincount\", 2);\n\n    // Return a separate section of ranges over i1. Should respect global range mincount\n    minParams.set(\"facet.range\", i1);\n    minParams.set(\"f.\" + i1 + \".facet.range.start\", 0);\n    minParams.set(\"f.\" + i1 + \".facet.range.gap\", 200);\n    minParams.set(\"f.\" + i1 + \".facet.range.end\", 1200);\n    minParams.set(\"f.\" + i1 + \".facet.mincount\", 4);\n\n\n    // Return a separate section of ranges over tlong Should respect facet.mincount\n    minParams.add(\"facet.range\", tlong);\n    minParams.set(\"f.\" + tlong + \".facet.range.start\", 0);\n    minParams.set(\"f.\" + tlong + \".facet.range.gap\", 100);\n    minParams.set(\"f.\" + tlong + \".facet.range.end\", 1200);\n    // Repeat with a range type of date\n    minParams.add(\"facet.range\", tdate_b);\n    minParams.set(\"f.\" + tdate_b + \".facet.range.start\", \"2009-02-01T00:00:00Z\");\n    minParams.set(\"f.\" + tdate_b + \".facet.range.gap\", \"+1YEAR\");\n    minParams.set(\"f.\" + tdate_b + \".facet.range.end\", \"2011-01-01T00:00:00Z\");\n    minParams.set(\"f.\" + tdate_b + \".facet.mincount\", 3);\n\n    // Insure that global mincount is respected for facet queries\n    minParams.set(\"facet.query\", tdate_a + \":[2010-01-01T00:00:00Z TO 2011-01-01T00:00:00Z]\"); // Should return some counts\n    //minParams.set(\"facet.query\", tdate_a + \":[* TO *]\"); // Should be removed\n    minParams.add(\"facet.query\", tdate_b + \":[2008-01-01T00:00:00Z TO 2009-09-01T00:00:00Z]\"); // Should be removed from response\n\n\n    setDistributedParams(minParams);\n    QueryResponse minResp = queryServer(minParams);\n\n    ModifiableSolrParams eParams = new ModifiableSolrParams();\n    eParams.set(\"q\",tdate_b + \":[* TO *]\");\n    eParams.set(\"rows\", 1000);\n    eParams.set(\"fl\", tdate_b);\n    setDistributedParams(eParams);\n    QueryResponse eResp = queryServer(eParams);\n\n    // Check that exactly the right numbers of counts came through\n    assertEquals(\"Should be exactly 2 range facets returned after minCounts taken into account \", 3, minResp.getFacetRanges().size());\n    assertEquals(\"Should only be 1 query facets returned after minCounts taken into account \", 1, minResp.getFacetQuery().size());\n\n    checkMinCountsField(minResp.getFacetField(i1).getValues(), new Object[]{null, 55L}); // Should just be the null entries for field\n\n    checkMinCountsRange(minResp.getFacetRanges().get(0).getCounts(), new Object[]{\"0\", 5L}); // range on i1\n    checkMinCountsRange(minResp.getFacetRanges().get(1).getCounts(), new Object[]{\"0\", 3L, \"100\", 3L}); // range on tlong\n    checkMinCountsRange(minResp.getFacetRanges().get(2).getCounts(), new Object[]{\"2009-02-01T00:00:00Z\",  3L}); // date (range) on tvh\n\n    assertTrue(\"Should have a facet for tdate_a\", minResp.getFacetQuery().containsKey(\"a_n_tdt:[2010-01-01T00:00:00Z TO 2011-01-01T00:00:00Z]\"));\n    int qCount = minResp.getFacetQuery().get(\"a_n_tdt:[2010-01-01T00:00:00Z TO 2011-01-01T00:00:00Z]\");\n    assertEquals(\"tdate_a should be 5\", qCount, 5);\n\n    // Now let's do some queries, the above is getting too complex\n    minParams = new ModifiableSolrParams();\n    minParams.set(\"q\",\"*:*\");\n    minParams.set(\"rows\", 1);\n    minParams.set(\"facet\", \"true\");\n    minParams.set(\"facet.mincount\", 3);\n\n    minParams.set(\"facet.query\", tdate_a + \":[2010-01-01T00:00:00Z TO 2010-05-04T00:00:00Z]\");\n    minParams.add(\"facet.query\", tdate_b + \":[2009-01-01T00:00:00Z TO 2010-01-01T00:00:00Z]\"); // Should be removed\n    setDistributedParams(minParams);\n    minResp = queryServer(minParams);\n\n    assertEquals(\"Should only be 1 query facets returned after minCounts taken into account \", 1, minResp.getFacetQuery().size());\n    assertTrue(\"Should be an entry for a_n_tdt\", minResp.getFacetQuery().containsKey(\"a_n_tdt:[2010-01-01T00:00:00Z TO 2010-05-04T00:00:00Z]\"));\n    qCount = minResp.getFacetQuery().get(\"a_n_tdt:[2010-01-01T00:00:00Z TO 2010-05-04T00:00:00Z]\");\n    assertEquals(\"a_n_tdt should have a count of 4 \", qCount, 4);\n    //  variations of fl\n    query(\"q\",\"*:*\", \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1 + \",score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", i1, \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id,\" + i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1, \"fl\", \"id\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",nint, \"fl\",tint,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",nint, \"fl\", \"id\", \"fl\",tint,\"sort\",i1 + \" desc\");\n\n    // basic spellcheck testing\n    query(\"q\", \"toyata\", \"fl\", \"id,lowerfilt\", \"spellcheck\", true, \"spellcheck.q\", \"toyata\", \"qt\", \"spellCheckCompRH_Direct\", \"shards.qt\", \"spellCheckCompRH_Direct\");\n\n    stress=0;  // turn off stress... we want to tex max combos in min time\n    for (int i=0; i<25*RANDOM_MULTIPLIER; i++) {\n      String f = fieldNames[random().nextInt(fieldNames.length)];\n      if (random().nextBoolean()) f = t1;  // the text field is a really interesting one to facet on (and it's multi-valued too)\n\n      // we want a random query and not just *:* so we'll get zero counts in facets also\n      // TODO: do a better random query\n      String q = random().nextBoolean() ? \"*:*\" : \"id:(1 3 5 7 9 11 13) OR id:[100 TO \" + random().nextInt(50) + \"]\";\n\n      int nolimit = random().nextBoolean() ? -1 : 10000;  // these should be equivalent\n\n      // if limit==-1, we should always get exact matches\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"count\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      // for index sort, we should get exact results for mincount <= 1\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(2), \"facet.offset\",random().nextInt(10), \"facet.limit\",random().nextInt(11)-1);\n    }\n    stress = backupStress;  // restore stress\n\n    // test faceting multiple things at once\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1);\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id:[1 TO 7]\", \"fq\",\"{!tag=b}id:[3 TO 9]\"\n    );\n    query(\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\");\n\n    // test field that is valid in schema but missing in all shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2);\n    // test field that is valid in schema and missing in some shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2);\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", \"stats_dt\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1);\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", tdate_a);\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", tdate_b);\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \n          \"fq\", \"{!tag=nothing}-*:*\",\n          \"stats.field\", \"{!key=special_key ex=nothing}stats_dt\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \n          \"f.stats_dt.stats.calcdistinct\", \"true\",\n          \"stats.field\", \"{!key=special_key}stats_dt\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \n          \"f.stats_dt.stats.calcdistinct\", \"true\",\n          \"fq\", \"{!tag=xxx}id:[3 TO 9]\",\n          \"stats.field\", \"{!key=special_key}stats_dt\",\n          \"stats.field\", \"{!ex=xxx}stats_dt\");\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\",\n          // do a really simple query so distributed IDF doesn't cause problems\n          // when comparing with control collection\n          \"stats.field\", \"{!lucene key=q_key}\" + i1 + \"foo_b:true\",\n          \"stats.field\", \"{!func key=f_key}sum(\" + tlong +\",\"+i1+\")\");\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\",\n          \"stats.field\", \"stats_dt\",\n          \"stats.field\", i1,\n          \"stats.field\", tdate_a,\n          \"stats.field\", tdate_b);\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    // check a complex key name\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"*:*\", \"rows\",100);\n    }\n\n    //SOLR 3161 ensure shards.qt=/update fails (anything but search handler really)\n    // Also see TestRemoteStreaming#testQtUpdateFails()\n    try {\n      ignoreException(\"isShard is only acceptable\");\n      // query(\"q\",\"*:*\",\"shards.qt\",\"/update\",\"stream.body\",\"<delete><query>*:*</query></delete>\");\n      // fail();\n    } catch (SolrException e) {\n      //expected\n    }\n    unIgnoreException(\"isShard is only acceptable\");\n\n    // test debugging\n    // handle.put(\"explain\", UNORDERED);\n    handle.put(\"explain\", SKIPVAL);  // internal docids differ, idf differs w/o global idf\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    handle.put(\"track\", SKIP); //track is not included in single node search\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY);\n\n    // SOLR-6545, wild card field list\n    indexr(id, \"19\", \"text\", \"d\", \"cat_a_sS\", \"1\" ,t1, \"2\");\n    commit();\n\n    rsp = query(\"q\", \"id:19\", \"fl\", \"id\", \"fl\", \"*a_sS\");\n    assertFieldValues(rsp.getResults(), \"id\", 19);\n\n    rsp = query(\"q\", \"id:19\", \"fl\", \"id,\" + t1 + \",cat*\");\n    assertFieldValues(rsp.getResults(), \"id\", 19);\n\n    // Check Info is added to for each shard\n    ModifiableSolrParams q = new ModifiableSolrParams();\n    q.set(\"q\", \"*:*\");\n    q.set(ShardParams.SHARDS_INFO, true);\n    setDistributedParams(q);\n    rsp = queryServer(q);\n    NamedList<?> sinfo = (NamedList<?>) rsp.getResponse().get(ShardParams.SHARDS_INFO);\n    String shards = getShardsString();\n    int cnt = StringUtils.countMatches(shards, \",\")+1;\n    \n    assertNotNull(\"missing shard info\", sinfo);\n    assertEquals(\"should have an entry for each shard [\"+sinfo+\"] \"+shards, cnt, sinfo.size());\n\n    // test shards.tolerant=true\n    for(int numDownServers = 0; numDownServers < jettys.size()-1; numDownServers++)\n    {\n      List<JettySolrRunner> upJettys = new ArrayList<>(jettys);\n      List<SolrClient> upClients = new ArrayList<>(clients);\n      List<JettySolrRunner> downJettys = new ArrayList<>();\n      List<String> upShards = new ArrayList<>(Arrays.asList(shardsArr));\n      for(int i=0; i<numDownServers; i++)\n      {\n        // shut down some of the jettys\n        int indexToRemove = r.nextInt(upJettys.size());\n        JettySolrRunner downJetty = upJettys.remove(indexToRemove);\n        upClients.remove(indexToRemove);\n        upShards.remove(indexToRemove);\n        ChaosMonkey.stop(downJetty);\n        downJettys.add(downJetty);\n      }\n\n      queryPartialResults(upShards, upClients, \n          \"q\",\"*:*\",\n          \"facet\",\"true\", \n          \"facet.field\",t1,\n          \"facet.field\",t1,\n          \"facet.limit\",5,\n          ShardParams.SHARDS_INFO,\"true\",\n          ShardParams.SHARDS_TOLERANT,\"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"facet\", \"true\",\n          \"facet.query\", i1 + \":[1 TO 50]\",\n          \"facet.query\", i1 + \":[1 TO 50]\",\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      // test group query\n      queryPartialResults(upShards, upClients,\n           \"q\", \"*:*\",\n           \"rows\", 100,\n           \"fl\", \"id,\" + i1,\n           \"group\", \"true\",\n           \"group.query\", t1 + \":kings OR \" + t1 + \":eggs\",\n           \"group.limit\", 10,\n           \"sort\", i1 + \" asc, id asc\",\n           CommonParams.TIME_ALLOWED, 1,\n           ShardParams.SHARDS_INFO, \"true\",\n           ShardParams.SHARDS_TOLERANT, \"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"stats\", \"true\",\n          \"stats.field\", i1,\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"toyata\",\n          \"spellcheck\", \"true\",\n          \"spellcheck.q\", \"toyata\",\n          \"qt\", \"spellCheckCompRH_Direct\",\n          \"shards.qt\", \"spellCheckCompRH_Direct\",\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      // restart the jettys\n      for (JettySolrRunner downJetty : downJettys) {\n        downJetty.start();\n      }\n    }\n\n    // This index has the same number for every field\n    \n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // Thread.sleep(10000000000L);\n\n    del(\"*:*\"); // delete all docs and test stats request\n    commit();\n    try {\n      query(\"q\", \"*:*\", \"stats\", \"true\", \n            \"stats.field\", \"stats_dt\", \n            \"stats.field\", i1, \n            \"stats.field\", tdate_a, \n            \"stats.field\", tdate_b,\n            \"stats.calcdistinct\", \"true\");\n    } catch (HttpSolrClient.RemoteSolrException e) {\n      if (e.getMessage().startsWith(\"java.lang.NullPointerException\"))  {\n        fail(\"NullPointerException with stats request on empty index\");\n      } else  {\n        throw e;\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"abb23fcc2461782ab204e61213240feb77d355aa","date":1422029612,"type":5,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/TestDistributedSearch#test().mjava","pathOld":"solr/core/src/test/org/apache/solr/TestDistributedSearch#doTest().mjava","sourceNew":"  @Test\n  public void test() throws Exception {\n    QueryResponse rsp = null;\n    int backupStress = stress; // make a copy so we can restore\n\n\n    del(\"*:*\");\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\",\n           tdate_a, \"2010-04-20T11:00:00Z\",\n           tdate_b, \"2009-08-20T11:00:00Z\",\n           \"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\",\n           tdate_a, \"2010-05-02T11:00:00Z\",\n           tdate_b, \"2009-11-02T11:00:00Z\");\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\",\n           tdate_a, \"2010-05-03T11:00:00Z\");\n    indexr(id,4, i1, -100 ,tlong, 101,\n           t1,\"the quick fox jumped over the lazy dog\", \n           tdate_a, \"2010-05-03T11:00:00Z\",\n           tdate_b, \"2010-05-03T11:00:00Z\");\n    indexr(id,5, i1, 500, tlong, 500 ,\n           t1,\"the quick fox jumped way over the lazy dog\", \n           tdate_a, \"2010-05-05T11:00:00Z\");\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,\n           tdate_b, \"2010-01-05T11:00:00Z\",\n           t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n\n    commit();  // try to ensure there's more than one segment\n\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,\n           t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,\n           t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,\n           t1,\"no eggs on wall, lesson learned\", \n           oddField, \"odd man out\");\n\n    indexr(id, \"1001\", \"lowerfilt\", \"toyota\"); // for spellcheck\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n    \n    \n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n\n    handle.clear();\n    handle.put(\"timestamp\", SKIPVAL);\n    handle.put(\"_version_\", SKIPVAL); // not a cloud test, but may use updateLog\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(\"q\",\"*:*\", \"sort\",f+\" desc\");\n      query(\"q\",\"*:*\", \"sort\",f+\" asc\");\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",\"{!func}testfunc(add(\"+i1+\",5))\"+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" asc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\");\n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"*,score\"); \n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 desc\");\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"{!func}\"+i1);// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(\"q\",\"{!func}\"+i1, \"fl\",\"*,score\");  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"quick\");\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\");\n    query(\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\");  // no fields in returned docs\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\");\n\n    handle.put(\"score\", SKIPVAL);\n    query(\"q\",\"quick\",\"fl\",\"*,score\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\");\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"matchesnothing\",\"fl\",\"*,score\");  \n\n    // test that a single NOW value is propagated to all shards... if that is true\n    // then the primary sort should always be a tie and then the secondary should always decide\n    query(\"q\",\"{!func}ms(NOW)\", \"sort\",\"score desc,\"+i1+\" desc\",\"fl\",\"id\");    \n\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1, \"facet.field\",t1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\");\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2);\n\n    // a facet query to test out chars out of the ascii range\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!term f=foo_s}international\\u00ff\\u01ff\\u2222\\u3333\");\n\n    // simple field facet on date fields\n    rsp = query(\"q\",\"*:*\", \"rows\", 0,\n                \"facet\",\"true\", \"facet.limit\", 1, // TODO: limit shouldn't be needed: SOLR-6386\n                \"facet.field\", tdate_a);\n    assertEquals(1, rsp.getFacetFields().size());\n    rsp = query(\"q\",\"*:*\", \"rows\", 0,\n                \"facet\",\"true\", \"facet.limit\", 1, // TODO: limit shouldn't be needed: SOLR-6386\n                \"facet.field\", tdate_b, \"facet.field\", tdate_a);\n    assertEquals(2, rsp.getFacetFields().size());\n\n    // simple date facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a,\n          \"facet.date\",tdate_a,\n          \"facet.date.other\", \"all\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // date facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a,\n          \"facet.date\",tdate_b,\n          \"facet.date\",tdate_a,\n          \"facet.date.other\", \"all\", \n          \"f.\"+tdate_b+\".facet.date.start\",\"2009-05-01T11:00:00Z\", \n          \"f.\"+tdate_b+\".facet.date.gap\",\"+3MONTHS\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // simple range facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong,\n          \"facet.range\",tlong,\n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"facet.range.end\",900);\n\n    // range facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range\",i1, \n          \"f.\"+i1+\".facet.range.start\",300, \n          \"f.\"+i1+\".facet.range.gap\",87, \n          \"facet.range.end\",900,\n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"f.\"+tlong+\".facet.range.end\",900);\n\n    // Test mincounts. Do NOT want to go through all the stuff where with validateControlData in query() method\n    // Purposely packing a _bunch_ of stuff together here to insure that the proper level of mincount is used for\n    // each\n    ModifiableSolrParams minParams = new ModifiableSolrParams();\n    minParams.set(\"q\",\"*:*\");\n    minParams.set(\"rows\", 1);\n    minParams.set(\"facet\", \"true\");\n    minParams.set(\"facet.missing\", \"true\");\n    minParams.set(\"facet.field\", i1);\n    minParams.set(\"facet.missing\", \"true\");\n    minParams.set(\"facet.mincount\", 2);\n\n    // Return a separate section of ranges over i1. Should respect global range mincount\n    minParams.set(\"facet.range\", i1);\n    minParams.set(\"f.\" + i1 + \".facet.range.start\", 0);\n    minParams.set(\"f.\" + i1 + \".facet.range.gap\", 200);\n    minParams.set(\"f.\" + i1 + \".facet.range.end\", 1200);\n    minParams.set(\"f.\" + i1 + \".facet.mincount\", 4);\n\n\n    // Return a separate section of ranges over tlong Should respect facet.mincount\n    minParams.add(\"facet.range\", tlong);\n    minParams.set(\"f.\" + tlong + \".facet.range.start\", 0);\n    minParams.set(\"f.\" + tlong + \".facet.range.gap\", 100);\n    minParams.set(\"f.\" + tlong + \".facet.range.end\", 1200);\n    // Repeat with a range type of date\n    minParams.add(\"facet.range\", tdate_b);\n    minParams.set(\"f.\" + tdate_b + \".facet.range.start\", \"2009-02-01T00:00:00Z\");\n    minParams.set(\"f.\" + tdate_b + \".facet.range.gap\", \"+1YEAR\");\n    minParams.set(\"f.\" + tdate_b + \".facet.range.end\", \"2011-01-01T00:00:00Z\");\n    minParams.set(\"f.\" + tdate_b + \".facet.mincount\", 3);\n\n    // Insure that global mincount is respected for facet queries\n    minParams.set(\"facet.query\", tdate_a + \":[2010-01-01T00:00:00Z TO 2011-01-01T00:00:00Z]\"); // Should return some counts\n    //minParams.set(\"facet.query\", tdate_a + \":[* TO *]\"); // Should be removed\n    minParams.add(\"facet.query\", tdate_b + \":[2008-01-01T00:00:00Z TO 2009-09-01T00:00:00Z]\"); // Should be removed from response\n\n\n    setDistributedParams(minParams);\n    QueryResponse minResp = queryServer(minParams);\n\n    ModifiableSolrParams eParams = new ModifiableSolrParams();\n    eParams.set(\"q\",tdate_b + \":[* TO *]\");\n    eParams.set(\"rows\", 1000);\n    eParams.set(\"fl\", tdate_b);\n    setDistributedParams(eParams);\n    QueryResponse eResp = queryServer(eParams);\n\n    // Check that exactly the right numbers of counts came through\n    assertEquals(\"Should be exactly 2 range facets returned after minCounts taken into account \", 3, minResp.getFacetRanges().size());\n    assertEquals(\"Should only be 1 query facets returned after minCounts taken into account \", 1, minResp.getFacetQuery().size());\n\n    checkMinCountsField(minResp.getFacetField(i1).getValues(), new Object[]{null, 55L}); // Should just be the null entries for field\n\n    checkMinCountsRange(minResp.getFacetRanges().get(0).getCounts(), new Object[]{\"0\", 5L}); // range on i1\n    checkMinCountsRange(minResp.getFacetRanges().get(1).getCounts(), new Object[]{\"0\", 3L, \"100\", 3L}); // range on tlong\n    checkMinCountsRange(minResp.getFacetRanges().get(2).getCounts(), new Object[]{\"2009-02-01T00:00:00Z\",  3L}); // date (range) on tvh\n\n    assertTrue(\"Should have a facet for tdate_a\", minResp.getFacetQuery().containsKey(\"a_n_tdt:[2010-01-01T00:00:00Z TO 2011-01-01T00:00:00Z]\"));\n    int qCount = minResp.getFacetQuery().get(\"a_n_tdt:[2010-01-01T00:00:00Z TO 2011-01-01T00:00:00Z]\");\n    assertEquals(\"tdate_a should be 5\", qCount, 5);\n\n    // Now let's do some queries, the above is getting too complex\n    minParams = new ModifiableSolrParams();\n    minParams.set(\"q\",\"*:*\");\n    minParams.set(\"rows\", 1);\n    minParams.set(\"facet\", \"true\");\n    minParams.set(\"facet.mincount\", 3);\n\n    minParams.set(\"facet.query\", tdate_a + \":[2010-01-01T00:00:00Z TO 2010-05-04T00:00:00Z]\");\n    minParams.add(\"facet.query\", tdate_b + \":[2009-01-01T00:00:00Z TO 2010-01-01T00:00:00Z]\"); // Should be removed\n    setDistributedParams(minParams);\n    minResp = queryServer(minParams);\n\n    assertEquals(\"Should only be 1 query facets returned after minCounts taken into account \", 1, minResp.getFacetQuery().size());\n    assertTrue(\"Should be an entry for a_n_tdt\", minResp.getFacetQuery().containsKey(\"a_n_tdt:[2010-01-01T00:00:00Z TO 2010-05-04T00:00:00Z]\"));\n    qCount = minResp.getFacetQuery().get(\"a_n_tdt:[2010-01-01T00:00:00Z TO 2010-05-04T00:00:00Z]\");\n    assertEquals(\"a_n_tdt should have a count of 4 \", qCount, 4);\n    //  variations of fl\n    query(\"q\",\"*:*\", \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1 + \",score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", i1, \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id,\" + i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1, \"fl\", \"id\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",nint, \"fl\",tint,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",nint, \"fl\", \"id\", \"fl\",tint,\"sort\",i1 + \" desc\");\n    handle.put(\"did\", SKIPVAL);\n    query(\"q\",\"*:*\", \"fl\",\"did:[docid]\",\"sort\",i1 + \" desc\");\n    handle.remove(\"did\");\n    query(\"q\",\"*:*\", \"fl\",\"log(\" + tlong + \"),abs(\" + tlong + \"),score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",\"n_*\",\"sort\",i1 + \" desc\");\n\n    // basic spellcheck testing\n    query(\"q\", \"toyata\", \"fl\", \"id,lowerfilt\", \"spellcheck\", true, \"spellcheck.q\", \"toyata\", \"qt\", \"spellCheckCompRH_Direct\", \"shards.qt\", \"spellCheckCompRH_Direct\");\n\n    stress=0;  // turn off stress... we want to tex max combos in min time\n    for (int i=0; i<25*RANDOM_MULTIPLIER; i++) {\n      String f = fieldNames[random().nextInt(fieldNames.length)];\n      if (random().nextBoolean()) f = t1;  // the text field is a really interesting one to facet on (and it's multi-valued too)\n\n      // we want a random query and not just *:* so we'll get zero counts in facets also\n      // TODO: do a better random query\n      String q = random().nextBoolean() ? \"*:*\" : \"id:(1 3 5 7 9 11 13) OR id:[100 TO \" + random().nextInt(50) + \"]\";\n\n      int nolimit = random().nextBoolean() ? -1 : 10000;  // these should be equivalent\n\n      // if limit==-1, we should always get exact matches\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"count\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      // for index sort, we should get exact results for mincount <= 1\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(2), \"facet.offset\",random().nextInt(10), \"facet.limit\",random().nextInt(11)-1);\n    }\n    stress = backupStress;  // restore stress\n\n    // test faceting multiple things at once\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1);\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id:[1 TO 7]\", \"fq\",\"{!tag=b}id:[3 TO 9]\"\n    );\n    query(\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\");\n\n    // test field that is valid in schema but missing in all shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2);\n    // test field that is valid in schema and missing in some shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2);\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", \"stats_dt\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1);\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", tdate_a);\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", tdate_b);\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \n          \"fq\", \"{!tag=nothing}-*:*\",\n          \"stats.field\", \"{!key=special_key ex=nothing}stats_dt\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \n          \"f.stats_dt.stats.calcdistinct\", \"true\",\n          \"stats.field\", \"{!key=special_key}stats_dt\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \n          \"f.stats_dt.stats.calcdistinct\", \"true\",\n          \"fq\", \"{!tag=xxx}id:[3 TO 9]\",\n          \"stats.field\", \"{!key=special_key}stats_dt\",\n          \"stats.field\", \"{!ex=xxx}stats_dt\");\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\",\n          // do a really simple query so distributed IDF doesn't cause problems\n          // when comparing with control collection\n          \"stats.field\", \"{!lucene key=q_key}\" + i1 + \"foo_b:true\",\n          \"stats.field\", \"{!func key=f_key}sum(\" + tlong +\",\"+i1+\")\");\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\",\n          \"stats.field\", \"stats_dt\",\n          \"stats.field\", i1,\n          \"stats.field\", tdate_a,\n          \"stats.field\", tdate_b);\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    // check a complex key name\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"*:*\", \"rows\",100);\n    }\n\n    //SOLR 3161 ensure shards.qt=/update fails (anything but search handler really)\n    // Also see TestRemoteStreaming#testQtUpdateFails()\n    try {\n      ignoreException(\"isShard is only acceptable\");\n      // query(\"q\",\"*:*\",\"shards.qt\",\"/update\",\"stream.body\",\"<delete><query>*:*</query></delete>\");\n      // fail();\n    } catch (SolrException e) {\n      //expected\n    }\n    unIgnoreException(\"isShard is only acceptable\");\n\n    // test debugging\n    // handle.put(\"explain\", UNORDERED);\n    handle.put(\"explain\", SKIPVAL);  // internal docids differ, idf differs w/o global idf\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    handle.put(\"track\", SKIP); //track is not included in single node search\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY);\n\n    // SOLR-6545, wild card field list\n    indexr(id, \"19\", \"text\", \"d\", \"cat_a_sS\", \"1\" ,t1, \"2\");\n    commit();\n\n    rsp = query(\"q\", \"id:19\", \"fl\", \"id\", \"fl\", \"*a_sS\");\n    assertFieldValues(rsp.getResults(), \"id\", 19);\n\n    rsp = query(\"q\", \"id:19\", \"fl\", \"id,\" + t1 + \",cat*\");\n    assertFieldValues(rsp.getResults(), \"id\", 19);\n\n    // Check Info is added to for each shard\n    ModifiableSolrParams q = new ModifiableSolrParams();\n    q.set(\"q\", \"*:*\");\n    q.set(ShardParams.SHARDS_INFO, true);\n    setDistributedParams(q);\n    rsp = queryServer(q);\n    NamedList<?> sinfo = (NamedList<?>) rsp.getResponse().get(ShardParams.SHARDS_INFO);\n    String shards = getShardsString();\n    int cnt = StringUtils.countMatches(shards, \",\")+1;\n    \n    assertNotNull(\"missing shard info\", sinfo);\n    assertEquals(\"should have an entry for each shard [\"+sinfo+\"] \"+shards, cnt, sinfo.size());\n\n    // test shards.tolerant=true\n    for(int numDownServers = 0; numDownServers < jettys.size()-1; numDownServers++)\n    {\n      List<JettySolrRunner> upJettys = new ArrayList<>(jettys);\n      List<SolrClient> upClients = new ArrayList<>(clients);\n      List<JettySolrRunner> downJettys = new ArrayList<>();\n      List<String> upShards = new ArrayList<>(Arrays.asList(shardsArr));\n      for(int i=0; i<numDownServers; i++)\n      {\n        // shut down some of the jettys\n        int indexToRemove = r.nextInt(upJettys.size());\n        JettySolrRunner downJetty = upJettys.remove(indexToRemove);\n        upClients.remove(indexToRemove);\n        upShards.remove(indexToRemove);\n        ChaosMonkey.stop(downJetty);\n        downJettys.add(downJetty);\n      }\n\n      queryPartialResults(upShards, upClients, \n          \"q\",\"*:*\",\n          \"facet\",\"true\", \n          \"facet.field\",t1,\n          \"facet.field\",t1,\n          \"facet.limit\",5,\n          ShardParams.SHARDS_INFO,\"true\",\n          ShardParams.SHARDS_TOLERANT,\"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"facet\", \"true\",\n          \"facet.query\", i1 + \":[1 TO 50]\",\n          \"facet.query\", i1 + \":[1 TO 50]\",\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      // test group query\n      queryPartialResults(upShards, upClients,\n           \"q\", \"*:*\",\n           \"rows\", 100,\n           \"fl\", \"id,\" + i1,\n           \"group\", \"true\",\n           \"group.query\", t1 + \":kings OR \" + t1 + \":eggs\",\n           \"group.limit\", 10,\n           \"sort\", i1 + \" asc, id asc\",\n           CommonParams.TIME_ALLOWED, 1,\n           ShardParams.SHARDS_INFO, \"true\",\n           ShardParams.SHARDS_TOLERANT, \"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"stats\", \"true\",\n          \"stats.field\", i1,\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"toyata\",\n          \"spellcheck\", \"true\",\n          \"spellcheck.q\", \"toyata\",\n          \"qt\", \"spellCheckCompRH_Direct\",\n          \"shards.qt\", \"spellCheckCompRH_Direct\",\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      // restart the jettys\n      for (JettySolrRunner downJetty : downJettys) {\n        downJetty.start();\n      }\n    }\n\n    // This index has the same number for every field\n    \n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // Thread.sleep(10000000000L);\n\n    del(\"*:*\"); // delete all docs and test stats request\n    commit();\n    try {\n      query(\"q\", \"*:*\", \"stats\", \"true\", \n            \"stats.field\", \"stats_dt\", \n            \"stats.field\", i1, \n            \"stats.field\", tdate_a, \n            \"stats.field\", tdate_b,\n            \"stats.calcdistinct\", \"true\");\n    } catch (HttpSolrClient.RemoteSolrException e) {\n      if (e.getMessage().startsWith(\"java.lang.NullPointerException\"))  {\n        fail(\"NullPointerException with stats request on empty index\");\n      } else  {\n        throw e;\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  public void doTest() throws Exception {\n    QueryResponse rsp = null;\n    int backupStress = stress; // make a copy so we can restore\n\n\n    del(\"*:*\");\n    indexr(id,1, i1, 100, tlong, 100,t1,\"now is the time for all good men\",\n           tdate_a, \"2010-04-20T11:00:00Z\",\n           tdate_b, \"2009-08-20T11:00:00Z\",\n           \"foo_f\", 1.414f, \"foo_b\", \"true\", \"foo_d\", 1.414d);\n    indexr(id,2, i1, 50 , tlong, 50,t1,\"to come to the aid of their country.\",\n           tdate_a, \"2010-05-02T11:00:00Z\",\n           tdate_b, \"2009-11-02T11:00:00Z\");\n    indexr(id,3, i1, 2, tlong, 2,t1,\"how now brown cow\",\n           tdate_a, \"2010-05-03T11:00:00Z\");\n    indexr(id,4, i1, -100 ,tlong, 101,\n           t1,\"the quick fox jumped over the lazy dog\", \n           tdate_a, \"2010-05-03T11:00:00Z\",\n           tdate_b, \"2010-05-03T11:00:00Z\");\n    indexr(id,5, i1, 500, tlong, 500 ,\n           t1,\"the quick fox jumped way over the lazy dog\", \n           tdate_a, \"2010-05-05T11:00:00Z\");\n    indexr(id,6, i1, -600, tlong, 600 ,t1,\"humpty dumpy sat on a wall\");\n    indexr(id,7, i1, 123, tlong, 123 ,t1,\"humpty dumpy had a great fall\");\n    indexr(id,8, i1, 876, tlong, 876,\n           tdate_b, \"2010-01-05T11:00:00Z\",\n           t1,\"all the kings horses and all the kings men\");\n    indexr(id,9, i1, 7, tlong, 7,t1,\"couldn't put humpty together again\");\n\n    commit();  // try to ensure there's more than one segment\n\n    indexr(id,10, i1, 4321, tlong, 4321,t1,\"this too shall pass\");\n    indexr(id,11, i1, -987, tlong, 987,\n           t1,\"An eye for eye only ends up making the whole world blind.\");\n    indexr(id,12, i1, 379, tlong, 379,\n           t1,\"Great works are performed, not by strength, but by perseverance.\");\n    indexr(id,13, i1, 232, tlong, 232,\n           t1,\"no eggs on wall, lesson learned\", \n           oddField, \"odd man out\");\n\n    indexr(id, \"1001\", \"lowerfilt\", \"toyota\"); // for spellcheck\n\n    indexr(id, 14, \"SubjectTerms_mfacet\", new String[]  {\"mathematical models\", \"mathematical analysis\"});\n    indexr(id, 15, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    indexr(id, 16, \"SubjectTerms_mfacet\", new String[]  {\"test 1\", \"test 2\", \"test3\"});\n    String[] vals = new String[100];\n    for (int i=0; i<100; i++) {\n      vals[i] = \"test \" + i;\n    }\n    indexr(id, 17, \"SubjectTerms_mfacet\", vals);\n    \n    \n\n    for (int i=100; i<150; i++) {\n      indexr(id, i);      \n    }\n\n    commit();\n\n    handle.clear();\n    handle.put(\"timestamp\", SKIPVAL);\n    handle.put(\"_version_\", SKIPVAL); // not a cloud test, but may use updateLog\n\n    // random value sort\n    for (String f : fieldNames) {\n      query(\"q\",\"*:*\", \"sort\",f+\" desc\");\n      query(\"q\",\"*:*\", \"sort\",f+\" asc\");\n    }\n\n    // these queries should be exactly ordered and scores should exactly match\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",\"{!func}testfunc(add(\"+i1+\",5))\"+\" desc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" asc\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"fl\",\"*,score\");\n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 asc\", \"fl\",\"*,score\"); \n    query(\"q\",\"*:*\", \"sort\",\"n_tl1 desc\");\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"{!func}\"+i1);// does not expect maxScore. So if it comes ,ignore it. JavaBinCodec.writeSolrDocumentList()\n    //is agnostic of request params.\n    handle.remove(\"maxScore\");\n    query(\"q\",\"{!func}\"+i1, \"fl\",\"*,score\");  // even scores should match exactly here\n\n    handle.put(\"highlighting\", UNORDERED);\n    handle.put(\"response\", UNORDERED);\n\n    handle.put(\"maxScore\", SKIPVAL);\n    query(\"q\",\"quick\");\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"0\");\n    query(\"q\",\"all\",\"fl\",\"foofoofoo\",\"start\",\"0\");  // no fields in returned docs\n    query(\"q\",\"all\",\"fl\",\"id\",\"start\",\"100\");\n\n    handle.put(\"score\", SKIPVAL);\n    query(\"q\",\"quick\",\"fl\",\"*,score\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"1\");\n    query(\"q\",\"all\",\"fl\",\"*,score\",\"start\",\"100\");\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"foofoofoo\",\n            \"hl\",\"true\",\"hl.fl\",t1);\n\n    query(\"q\",\"matchesnothing\",\"fl\",\"*,score\");  \n\n    // test that a single NOW value is propagated to all shards... if that is true\n    // then the primary sort should always be a tie and then the secondary should always decide\n    query(\"q\",\"{!func}ms(NOW)\", \"sort\",\"score desc,\"+i1+\" desc\",\"fl\",\"id\");    \n\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1, \"facet.field\",t1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",1);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\");\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1, \"facet.mincount\",2);\n\n    // a facet query to test out chars out of the ascii range\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!term f=foo_s}international\\u00ff\\u01ff\\u2222\\u3333\");\n\n    // simple field facet on date fields\n    rsp = query(\"q\",\"*:*\", \"rows\", 0,\n                \"facet\",\"true\", \"facet.limit\", 1, // TODO: limit shouldn't be needed: SOLR-6386\n                \"facet.field\", tdate_a);\n    assertEquals(1, rsp.getFacetFields().size());\n    rsp = query(\"q\",\"*:*\", \"rows\", 0,\n                \"facet\",\"true\", \"facet.limit\", 1, // TODO: limit shouldn't be needed: SOLR-6386\n                \"facet.field\", tdate_b, \"facet.field\", tdate_a);\n    assertEquals(2, rsp.getFacetFields().size());\n\n    // simple date facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a,\n          \"facet.date\",tdate_a,\n          \"facet.date.other\", \"all\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // date facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.date\",tdate_a,\n          \"facet.date\",tdate_b,\n          \"facet.date\",tdate_a,\n          \"facet.date.other\", \"all\", \n          \"f.\"+tdate_b+\".facet.date.start\",\"2009-05-01T11:00:00Z\", \n          \"f.\"+tdate_b+\".facet.date.gap\",\"+3MONTHS\", \n          \"facet.date.start\",\"2010-05-01T11:00:00Z\", \n          \"facet.date.gap\",\"+1DAY\", \n          \"facet.date.end\",\"2010-05-20T11:00:00Z\");\n\n    // simple range facet on one field\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong,\n          \"facet.range\",tlong,\n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"facet.range.end\",900);\n\n    // range facet on multiple fields\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \n          \"facet.range\",tlong, \n          \"facet.range\",i1, \n          \"f.\"+i1+\".facet.range.start\",300, \n          \"f.\"+i1+\".facet.range.gap\",87, \n          \"facet.range.end\",900,\n          \"facet.range.start\",200, \n          \"facet.range.gap\",100, \n          \"f.\"+tlong+\".facet.range.end\",900);\n\n    // Test mincounts. Do NOT want to go through all the stuff where with validateControlData in query() method\n    // Purposely packing a _bunch_ of stuff together here to insure that the proper level of mincount is used for\n    // each\n    ModifiableSolrParams minParams = new ModifiableSolrParams();\n    minParams.set(\"q\",\"*:*\");\n    minParams.set(\"rows\", 1);\n    minParams.set(\"facet\", \"true\");\n    minParams.set(\"facet.missing\", \"true\");\n    minParams.set(\"facet.field\", i1);\n    minParams.set(\"facet.missing\", \"true\");\n    minParams.set(\"facet.mincount\", 2);\n\n    // Return a separate section of ranges over i1. Should respect global range mincount\n    minParams.set(\"facet.range\", i1);\n    minParams.set(\"f.\" + i1 + \".facet.range.start\", 0);\n    minParams.set(\"f.\" + i1 + \".facet.range.gap\", 200);\n    minParams.set(\"f.\" + i1 + \".facet.range.end\", 1200);\n    minParams.set(\"f.\" + i1 + \".facet.mincount\", 4);\n\n\n    // Return a separate section of ranges over tlong Should respect facet.mincount\n    minParams.add(\"facet.range\", tlong);\n    minParams.set(\"f.\" + tlong + \".facet.range.start\", 0);\n    minParams.set(\"f.\" + tlong + \".facet.range.gap\", 100);\n    minParams.set(\"f.\" + tlong + \".facet.range.end\", 1200);\n    // Repeat with a range type of date\n    minParams.add(\"facet.range\", tdate_b);\n    minParams.set(\"f.\" + tdate_b + \".facet.range.start\", \"2009-02-01T00:00:00Z\");\n    minParams.set(\"f.\" + tdate_b + \".facet.range.gap\", \"+1YEAR\");\n    minParams.set(\"f.\" + tdate_b + \".facet.range.end\", \"2011-01-01T00:00:00Z\");\n    minParams.set(\"f.\" + tdate_b + \".facet.mincount\", 3);\n\n    // Insure that global mincount is respected for facet queries\n    minParams.set(\"facet.query\", tdate_a + \":[2010-01-01T00:00:00Z TO 2011-01-01T00:00:00Z]\"); // Should return some counts\n    //minParams.set(\"facet.query\", tdate_a + \":[* TO *]\"); // Should be removed\n    minParams.add(\"facet.query\", tdate_b + \":[2008-01-01T00:00:00Z TO 2009-09-01T00:00:00Z]\"); // Should be removed from response\n\n\n    setDistributedParams(minParams);\n    QueryResponse minResp = queryServer(minParams);\n\n    ModifiableSolrParams eParams = new ModifiableSolrParams();\n    eParams.set(\"q\",tdate_b + \":[* TO *]\");\n    eParams.set(\"rows\", 1000);\n    eParams.set(\"fl\", tdate_b);\n    setDistributedParams(eParams);\n    QueryResponse eResp = queryServer(eParams);\n\n    // Check that exactly the right numbers of counts came through\n    assertEquals(\"Should be exactly 2 range facets returned after minCounts taken into account \", 3, minResp.getFacetRanges().size());\n    assertEquals(\"Should only be 1 query facets returned after minCounts taken into account \", 1, minResp.getFacetQuery().size());\n\n    checkMinCountsField(minResp.getFacetField(i1).getValues(), new Object[]{null, 55L}); // Should just be the null entries for field\n\n    checkMinCountsRange(minResp.getFacetRanges().get(0).getCounts(), new Object[]{\"0\", 5L}); // range on i1\n    checkMinCountsRange(minResp.getFacetRanges().get(1).getCounts(), new Object[]{\"0\", 3L, \"100\", 3L}); // range on tlong\n    checkMinCountsRange(minResp.getFacetRanges().get(2).getCounts(), new Object[]{\"2009-02-01T00:00:00Z\",  3L}); // date (range) on tvh\n\n    assertTrue(\"Should have a facet for tdate_a\", minResp.getFacetQuery().containsKey(\"a_n_tdt:[2010-01-01T00:00:00Z TO 2011-01-01T00:00:00Z]\"));\n    int qCount = minResp.getFacetQuery().get(\"a_n_tdt:[2010-01-01T00:00:00Z TO 2011-01-01T00:00:00Z]\");\n    assertEquals(\"tdate_a should be 5\", qCount, 5);\n\n    // Now let's do some queries, the above is getting too complex\n    minParams = new ModifiableSolrParams();\n    minParams.set(\"q\",\"*:*\");\n    minParams.set(\"rows\", 1);\n    minParams.set(\"facet\", \"true\");\n    minParams.set(\"facet.mincount\", 3);\n\n    minParams.set(\"facet.query\", tdate_a + \":[2010-01-01T00:00:00Z TO 2010-05-04T00:00:00Z]\");\n    minParams.add(\"facet.query\", tdate_b + \":[2009-01-01T00:00:00Z TO 2010-01-01T00:00:00Z]\"); // Should be removed\n    setDistributedParams(minParams);\n    minResp = queryServer(minParams);\n\n    assertEquals(\"Should only be 1 query facets returned after minCounts taken into account \", 1, minResp.getFacetQuery().size());\n    assertTrue(\"Should be an entry for a_n_tdt\", minResp.getFacetQuery().containsKey(\"a_n_tdt:[2010-01-01T00:00:00Z TO 2010-05-04T00:00:00Z]\"));\n    qCount = minResp.getFacetQuery().get(\"a_n_tdt:[2010-01-01T00:00:00Z TO 2010-05-04T00:00:00Z]\");\n    assertEquals(\"a_n_tdt should have a count of 4 \", qCount, 4);\n    //  variations of fl\n    query(\"q\",\"*:*\", \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1 + \",score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", i1, \"fl\",\"score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id,\" + i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",i1,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",i1, \"fl\", \"id\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\", \"id\", \"fl\",nint, \"fl\",tint,\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",nint, \"fl\", \"id\", \"fl\",tint,\"sort\",i1 + \" desc\");\n    handle.put(\"did\", SKIPVAL);\n    query(\"q\",\"*:*\", \"fl\",\"did:[docid]\",\"sort\",i1 + \" desc\");\n    handle.remove(\"did\");\n    query(\"q\",\"*:*\", \"fl\",\"log(\" + tlong + \"),abs(\" + tlong + \"),score\",\"sort\",i1 + \" desc\");\n    query(\"q\",\"*:*\", \"fl\",\"n_*\",\"sort\",i1 + \" desc\");\n\n    // basic spellcheck testing\n    query(\"q\", \"toyata\", \"fl\", \"id,lowerfilt\", \"spellcheck\", true, \"spellcheck.q\", \"toyata\", \"qt\", \"spellCheckCompRH_Direct\", \"shards.qt\", \"spellCheckCompRH_Direct\");\n\n    stress=0;  // turn off stress... we want to tex max combos in min time\n    for (int i=0; i<25*RANDOM_MULTIPLIER; i++) {\n      String f = fieldNames[random().nextInt(fieldNames.length)];\n      if (random().nextBoolean()) f = t1;  // the text field is a really interesting one to facet on (and it's multi-valued too)\n\n      // we want a random query and not just *:* so we'll get zero counts in facets also\n      // TODO: do a better random query\n      String q = random().nextBoolean() ? \"*:*\" : \"id:(1 3 5 7 9 11 13) OR id:[100 TO \" + random().nextInt(50) + \"]\";\n\n      int nolimit = random().nextBoolean() ? -1 : 10000;  // these should be equivalent\n\n      // if limit==-1, we should always get exact matches\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"count\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.limit\",nolimit, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(5), \"facet.offset\",random().nextInt(10));\n      // for index sort, we should get exact results for mincount <= 1\n      query(\"q\",q, \"rows\",0, \"facet\",\"true\", \"facet.field\",f, \"facet.sort\",\"index\", \"facet.mincount\",random().nextInt(2), \"facet.offset\",random().nextInt(10), \"facet.limit\",random().nextInt(11)-1);\n    }\n    stress = backupStress;  // restore stress\n\n    // test faceting multiple things at once\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"quick\", \"facet.query\",\"all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",t1);\n\n    // test filter tagging, facet exclusion, and naming (multi-select facet support)\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.query\",\"{!key=myquick}quick\", \"facet.query\",\"{!key=myall ex=a}all\", \"facet.query\",\"*:*\"\n    ,\"facet.field\",\"{!key=mykey ex=a}\"+t1\n    ,\"facet.field\",\"{!key=other ex=b}\"+t1\n    ,\"facet.field\",\"{!key=again ex=a,b}\"+t1\n    ,\"facet.field\",t1\n    ,\"fq\",\"{!tag=a}id:[1 TO 7]\", \"fq\",\"{!tag=b}id:[3 TO 9]\"\n    );\n    query(\"q\", \"*:*\", \"facet\", \"true\", \"facet.field\", \"{!ex=t1}SubjectTerms_mfacet\", \"fq\", \"{!tag=t1}SubjectTerms_mfacet:(test 1)\", \"facet.limit\", \"10\", \"facet.mincount\", \"1\");\n\n    // test field that is valid in schema but missing in all shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",missingField, \"facet.mincount\",2);\n    // test field that is valid in schema and missing in some shards\n    query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",oddField, \"facet.mincount\",2);\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", \"stats_dt\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", i1);\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", tdate_a);\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \"stats.field\", tdate_b);\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \n          \"fq\", \"{!tag=nothing}-*:*\",\n          \"stats.field\", \"{!key=special_key ex=nothing}stats_dt\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \n          \"f.stats_dt.stats.calcdistinct\", \"true\",\n          \"stats.field\", \"{!key=special_key}stats_dt\");\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\", \n          \"f.stats_dt.stats.calcdistinct\", \"true\",\n          \"fq\", \"{!tag=xxx}id:[3 TO 9]\",\n          \"stats.field\", \"{!key=special_key}stats_dt\",\n          \"stats.field\", \"{!ex=xxx}stats_dt\");\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\",\n          // do a really simple query so distributed IDF doesn't cause problems\n          // when comparing with control collection\n          \"stats.field\", \"{!lucene key=q_key}\" + i1 + \"foo_b:true\",\n          \"stats.field\", \"{!func key=f_key}sum(\" + tlong +\",\"+i1+\")\");\n\n    query(\"q\",\"*:*\", \"sort\",i1+\" desc\", \"stats\", \"true\",\n          \"stats.field\", \"stats_dt\",\n          \"stats.field\", i1,\n          \"stats.field\", tdate_a,\n          \"stats.field\", tdate_b);\n\n    /*** TODO: the failure may come back in \"exception\"\n    try {\n      // test error produced for field that is invalid for schema\n      query(\"q\",\"*:*\", \"rows\",100, \"facet\",\"true\", \"facet.field\",invalidField, \"facet.mincount\",2);\n      TestCase.fail(\"SolrServerException expected for invalid field that is not in schema\");\n    } catch (SolrServerException ex) {\n      // expected\n    }\n    ***/\n\n    // Try to get better coverage for refinement queries by turning off over requesting.\n    // This makes it much more likely that we may not get the top facet values and hence\n    // we turn of that checking.\n    handle.put(\"facet_fields\", SKIPVAL);    \n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    // check a complex key name\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a b/c \\\\' \\\\} foo'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    query(\"q\",\"*:*\", \"rows\",0, \"facet\",\"true\", \"facet.field\",\"{!key='$a'}\"+t1,\"facet.limit\",5, \"facet.shard.limit\",5);\n    handle.remove(\"facet_fields\");\n\n\n    // index the same document to two servers and make sure things\n    // don't blow up.\n    if (clients.size()>=2) {\n      index(id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      for (int i=0; i<clients.size(); i++) {\n        index_specific(i, id,100, i1, 107 ,t1,\"oh no, a duplicate!\");\n      }\n      commit();\n      query(\"q\",\"duplicate\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"fox duplicate horses\", \"hl\",\"true\", \"hl.fl\", t1);\n      query(\"q\",\"*:*\", \"rows\",100);\n    }\n\n    //SOLR 3161 ensure shards.qt=/update fails (anything but search handler really)\n    // Also see TestRemoteStreaming#testQtUpdateFails()\n    try {\n      ignoreException(\"isShard is only acceptable\");\n      // query(\"q\",\"*:*\",\"shards.qt\",\"/update\",\"stream.body\",\"<delete><query>*:*</query></delete>\");\n      // fail();\n    } catch (SolrException e) {\n      //expected\n    }\n    unIgnoreException(\"isShard is only acceptable\");\n\n    // test debugging\n    // handle.put(\"explain\", UNORDERED);\n    handle.put(\"explain\", SKIPVAL);  // internal docids differ, idf differs w/o global idf\n    handle.put(\"debug\", UNORDERED);\n    handle.put(\"time\", SKIPVAL);\n    handle.put(\"track\", SKIP); //track is not included in single node search\n    query(\"q\",\"now their fox sat had put\",\"fl\",\"*,score\",CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG_QUERY, \"true\");\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.TIMING);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.RESULTS);\n    query(\"q\", \"id:[1 TO 5]\", CommonParams.DEBUG, CommonParams.QUERY);\n\n    // SOLR-6545, wild card field list\n    indexr(id, \"19\", \"text\", \"d\", \"cat_a_sS\", \"1\" ,t1, \"2\");\n    commit();\n\n    rsp = query(\"q\", \"id:19\", \"fl\", \"id\", \"fl\", \"*a_sS\");\n    assertFieldValues(rsp.getResults(), \"id\", 19);\n\n    rsp = query(\"q\", \"id:19\", \"fl\", \"id,\" + t1 + \",cat*\");\n    assertFieldValues(rsp.getResults(), \"id\", 19);\n\n    // Check Info is added to for each shard\n    ModifiableSolrParams q = new ModifiableSolrParams();\n    q.set(\"q\", \"*:*\");\n    q.set(ShardParams.SHARDS_INFO, true);\n    setDistributedParams(q);\n    rsp = queryServer(q);\n    NamedList<?> sinfo = (NamedList<?>) rsp.getResponse().get(ShardParams.SHARDS_INFO);\n    String shards = getShardsString();\n    int cnt = StringUtils.countMatches(shards, \",\")+1;\n    \n    assertNotNull(\"missing shard info\", sinfo);\n    assertEquals(\"should have an entry for each shard [\"+sinfo+\"] \"+shards, cnt, sinfo.size());\n\n    // test shards.tolerant=true\n    for(int numDownServers = 0; numDownServers < jettys.size()-1; numDownServers++)\n    {\n      List<JettySolrRunner> upJettys = new ArrayList<>(jettys);\n      List<SolrClient> upClients = new ArrayList<>(clients);\n      List<JettySolrRunner> downJettys = new ArrayList<>();\n      List<String> upShards = new ArrayList<>(Arrays.asList(shardsArr));\n      for(int i=0; i<numDownServers; i++)\n      {\n        // shut down some of the jettys\n        int indexToRemove = r.nextInt(upJettys.size());\n        JettySolrRunner downJetty = upJettys.remove(indexToRemove);\n        upClients.remove(indexToRemove);\n        upShards.remove(indexToRemove);\n        ChaosMonkey.stop(downJetty);\n        downJettys.add(downJetty);\n      }\n\n      queryPartialResults(upShards, upClients, \n          \"q\",\"*:*\",\n          \"facet\",\"true\", \n          \"facet.field\",t1,\n          \"facet.field\",t1,\n          \"facet.limit\",5,\n          ShardParams.SHARDS_INFO,\"true\",\n          ShardParams.SHARDS_TOLERANT,\"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"facet\", \"true\",\n          \"facet.query\", i1 + \":[1 TO 50]\",\n          \"facet.query\", i1 + \":[1 TO 50]\",\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      // test group query\n      queryPartialResults(upShards, upClients,\n           \"q\", \"*:*\",\n           \"rows\", 100,\n           \"fl\", \"id,\" + i1,\n           \"group\", \"true\",\n           \"group.query\", t1 + \":kings OR \" + t1 + \":eggs\",\n           \"group.limit\", 10,\n           \"sort\", i1 + \" asc, id asc\",\n           CommonParams.TIME_ALLOWED, 1,\n           ShardParams.SHARDS_INFO, \"true\",\n           ShardParams.SHARDS_TOLERANT, \"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"*:*\",\n          \"stats\", \"true\",\n          \"stats.field\", i1,\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      queryPartialResults(upShards, upClients,\n          \"q\", \"toyata\",\n          \"spellcheck\", \"true\",\n          \"spellcheck.q\", \"toyata\",\n          \"qt\", \"spellCheckCompRH_Direct\",\n          \"shards.qt\", \"spellCheckCompRH_Direct\",\n          ShardParams.SHARDS_INFO, \"true\",\n          ShardParams.SHARDS_TOLERANT, \"true\");\n\n      // restart the jettys\n      for (JettySolrRunner downJetty : downJettys) {\n        downJetty.start();\n      }\n    }\n\n    // This index has the same number for every field\n    \n    // TODO: This test currently fails because debug info is obtained only\n    // on shards with matches.\n    // query(\"q\",\"matchesnothing\",\"fl\",\"*,score\", \"debugQuery\", \"true\");\n    \n    // Thread.sleep(10000000000L);\n\n    del(\"*:*\"); // delete all docs and test stats request\n    commit();\n    try {\n      query(\"q\", \"*:*\", \"stats\", \"true\", \n            \"stats.field\", \"stats_dt\", \n            \"stats.field\", i1, \n            \"stats.field\", tdate_a, \n            \"stats.field\", tdate_b,\n            \"stats.calcdistinct\", \"true\");\n    } catch (HttpSolrClient.RemoteSolrException e) {\n      if (e.getMessage().startsWith(\"java.lang.NullPointerException\"))  {\n        fail(\"NullPointerException with stats request on empty index\");\n      } else  {\n        throw e;\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"659bd5da21bf2e51b42e1ad49c7107ad4ff1803f":["4283fa55a69b0144f8baca38bb6f4230e27fd954"],"92751ba9273251eab6a2e379ec42a1697a32ff96":["072f211dfa8387028bb978d128c35bf9a450bbbf"],"5c7ba2bec83cc0a507e2cb5a5af99102deb9b01d":["88dcbe1d36c9d50525f58425024e87783c4005ab"],"dfdcc495f7097a13c0ae88a3338561749a4eac0b":["df525117ddb4dc8c8fe6e9fded68f55b29070496"],"9274621789ce990dbfef455dabdf026bb3184821":["e28b14e7783d24ca69089f13ddadadbd2afdcb29"],"37a0f60745e53927c4c876cfe5b5a58170f0646c":["ea7b027695d1003f32a2b5587762e9d51d0d60e8","a2d7ec084be7fa496e6f93352b6e10427881eb35"],"9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab":["0261694600e2fe9786395ecd0838ed98797d2660","e6dd476b943b132ecfa6b3ffc72e439eb2d9e061"],"d5952c5a694ea98255fc6cce4ea7cb36185feefb":["92751ba9273251eab6a2e379ec42a1697a32ff96"],"4283fa55a69b0144f8baca38bb6f4230e27fd954":["eb9e4cb185078b4e99e3b7070abb77eb2cdfaf6e"],"b8a06631c6dd7816f50f77a22d08dac33e15f1f1":["d5952c5a694ea98255fc6cce4ea7cb36185feefb"],"ea7c3cda25547888b8a5a3989f5bbb00066746ed":["629c38c4ae4e303d0617e05fbfe508140b32f0a3"],"19275ba31e621f6da1b83bf13af75233876fd3d4":["a2d7ec084be7fa496e6f93352b6e10427881eb35"],"a2d7ec084be7fa496e6f93352b6e10427881eb35":["ea7b027695d1003f32a2b5587762e9d51d0d60e8"],"0d9835c6ddd23dd02eefd5adfc0e5d1e89075fbe":["c1500c4d2642ffe9c4fc6a09a7674b69a550fd36"],"610c97b96420e614c67797fd43822ebc1d4b7ee2":["8ff4734b6c86245e852fe8b6a286716d5e59d415"],"e28b14e7783d24ca69089f13ddadadbd2afdcb29":["e6a0af6f7a7677267ad84c35bc106a61fd67dc62"],"d66363068e87a246ce08fee4a42f30f126b92723":["0261694600e2fe9786395ecd0838ed98797d2660"],"38e3b736c7ca086d61b7dbb841c905ee115490da":["9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab","df525117ddb4dc8c8fe6e9fded68f55b29070496"],"a63520843c1d9af055af89fbaeb67eae848f28ae":["dfdcc495f7097a13c0ae88a3338561749a4eac0b"],"d9a47902d6207303f5ed3e7aaca62ca33433af66":["da951a24a6a87d5ba7e1820f8c28a1e2beea76c1","4283fa55a69b0144f8baca38bb6f4230e27fd954"],"df525117ddb4dc8c8fe6e9fded68f55b29070496":["e6dd476b943b132ecfa6b3ffc72e439eb2d9e061"],"fe33227f6805edab2036cbb80645cc4e2d1fa424":["5da0b42730b6b99b31389ef94cb97384e83b9ede","88dcbe1d36c9d50525f58425024e87783c4005ab"],"f420cb3744c81c24c4a8781f95a446b9a2b5e011":["16851b5b065d6bd2924c0819a6d91e8e7bbde5d8"],"d6f074e73200c07d54f242d3880a8da5a35ff97b":["88dcbe1d36c9d50525f58425024e87783c4005ab","5c7ba2bec83cc0a507e2cb5a5af99102deb9b01d"],"74f45af4339b0daf7a95c820ab88c1aea74fbce0":["d9d424bd039937b4125152b454b3a32754b06f6c","0d9835c6ddd23dd02eefd5adfc0e5d1e89075fbe"],"16851b5b065d6bd2924c0819a6d91e8e7bbde5d8":["aebe9d27ca22125fc3d6aec04786171dca967833"],"eb9e4cb185078b4e99e3b7070abb77eb2cdfaf6e":["283ff02f401ec3e7a2fad73643970f052383fb0c"],"072f211dfa8387028bb978d128c35bf9a450bbbf":["92bd590cd3fa131aa5a9c7f56693a7ec9cb6d279"],"abb23fcc2461782ab204e61213240feb77d355aa":["708afaee6d15fdeac34f31c2e05fb32ee7145bc0"],"c26f00b574427b55127e869b935845554afde1fa":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","c903c3d15906a3da96b8c0c2fb704491005fdbdb"],"bafca15d8e408346a67f4282ad1143b88023893b":["f001da93ec624cbfbf3655c529836b5b1ec1aa46"],"56572ec06f1407c066d6b7399413178b33176cd8":["e6a0af6f7a7677267ad84c35bc106a61fd67dc62","93dd449115a9247533e44bab47e8429e5dccbc6d"],"e6a0af6f7a7677267ad84c35bc106a61fd67dc62":["634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"c7869f64c874ebf7f317d22c00baf2b6857797a6":["fe33227f6805edab2036cbb80645cc4e2d1fa424","5c7ba2bec83cc0a507e2cb5a5af99102deb9b01d"],"708afaee6d15fdeac34f31c2e05fb32ee7145bc0":["bafca15d8e408346a67f4282ad1143b88023893b"],"5da0b42730b6b99b31389ef94cb97384e83b9ede":["ea7c3cda25547888b8a5a3989f5bbb00066746ed"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"0261694600e2fe9786395ecd0838ed98797d2660":["c26f00b574427b55127e869b935845554afde1fa"],"8ff4734b6c86245e852fe8b6a286716d5e59d415":["b8a06631c6dd7816f50f77a22d08dac33e15f1f1"],"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["0d9835c6ddd23dd02eefd5adfc0e5d1e89075fbe"],"ba076ada7f119298baa28ce1043dbcf719a64141":["f420cb3744c81c24c4a8781f95a446b9a2b5e011"],"55980207f1977bd1463465de1659b821347e2fa8":["d9a47902d6207303f5ed3e7aaca62ca33433af66","f001da93ec624cbfbf3655c529836b5b1ec1aa46"],"716d18f3a9b0993bc679d7fa7abdc9bfb03411ec":["37a0f60745e53927c4c876cfe5b5a58170f0646c","19275ba31e621f6da1b83bf13af75233876fd3d4"],"e6dd476b943b132ecfa6b3ffc72e439eb2d9e061":["d66363068e87a246ce08fee4a42f30f126b92723"],"c1500c4d2642ffe9c4fc6a09a7674b69a550fd36":["d9d424bd039937b4125152b454b3a32754b06f6c"],"ea7b027695d1003f32a2b5587762e9d51d0d60e8":["5c7ba2bec83cc0a507e2cb5a5af99102deb9b01d"],"88dcbe1d36c9d50525f58425024e87783c4005ab":["5da0b42730b6b99b31389ef94cb97384e83b9ede"],"283ff02f401ec3e7a2fad73643970f052383fb0c":["610c97b96420e614c67797fd43822ebc1d4b7ee2"],"d9d424bd039937b4125152b454b3a32754b06f6c":["19275ba31e621f6da1b83bf13af75233876fd3d4"],"92bd590cd3fa131aa5a9c7f56693a7ec9cb6d279":["93dd449115a9247533e44bab47e8429e5dccbc6d"],"da951a24a6a87d5ba7e1820f8c28a1e2beea76c1":["283ff02f401ec3e7a2fad73643970f052383fb0c","eb9e4cb185078b4e99e3b7070abb77eb2cdfaf6e"],"c903c3d15906a3da96b8c0c2fb704491005fdbdb":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"93dd449115a9247533e44bab47e8429e5dccbc6d":["e6a0af6f7a7677267ad84c35bc106a61fd67dc62","9274621789ce990dbfef455dabdf026bb3184821"],"f001da93ec624cbfbf3655c529836b5b1ec1aa46":["659bd5da21bf2e51b42e1ad49c7107ad4ff1803f"],"a258fbb26824fd104ed795e5d9033d2d040049ee":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"629c38c4ae4e303d0617e05fbfe508140b32f0a3":["ba076ada7f119298baa28ce1043dbcf719a64141"],"aebe9d27ca22125fc3d6aec04786171dca967833":["a63520843c1d9af055af89fbaeb67eae848f28ae"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["abb23fcc2461782ab204e61213240feb77d355aa"]},"commit2Childs":{"659bd5da21bf2e51b42e1ad49c7107ad4ff1803f":["f001da93ec624cbfbf3655c529836b5b1ec1aa46"],"92751ba9273251eab6a2e379ec42a1697a32ff96":["d5952c5a694ea98255fc6cce4ea7cb36185feefb"],"5c7ba2bec83cc0a507e2cb5a5af99102deb9b01d":["d6f074e73200c07d54f242d3880a8da5a35ff97b","c7869f64c874ebf7f317d22c00baf2b6857797a6","ea7b027695d1003f32a2b5587762e9d51d0d60e8"],"dfdcc495f7097a13c0ae88a3338561749a4eac0b":["a63520843c1d9af055af89fbaeb67eae848f28ae"],"9274621789ce990dbfef455dabdf026bb3184821":["93dd449115a9247533e44bab47e8429e5dccbc6d"],"37a0f60745e53927c4c876cfe5b5a58170f0646c":["716d18f3a9b0993bc679d7fa7abdc9bfb03411ec"],"9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab":["38e3b736c7ca086d61b7dbb841c905ee115490da"],"d5952c5a694ea98255fc6cce4ea7cb36185feefb":["b8a06631c6dd7816f50f77a22d08dac33e15f1f1"],"4283fa55a69b0144f8baca38bb6f4230e27fd954":["659bd5da21bf2e51b42e1ad49c7107ad4ff1803f","d9a47902d6207303f5ed3e7aaca62ca33433af66"],"b8a06631c6dd7816f50f77a22d08dac33e15f1f1":["8ff4734b6c86245e852fe8b6a286716d5e59d415"],"ea7c3cda25547888b8a5a3989f5bbb00066746ed":["5da0b42730b6b99b31389ef94cb97384e83b9ede"],"19275ba31e621f6da1b83bf13af75233876fd3d4":["716d18f3a9b0993bc679d7fa7abdc9bfb03411ec","d9d424bd039937b4125152b454b3a32754b06f6c"],"a2d7ec084be7fa496e6f93352b6e10427881eb35":["37a0f60745e53927c4c876cfe5b5a58170f0646c","19275ba31e621f6da1b83bf13af75233876fd3d4"],"0d9835c6ddd23dd02eefd5adfc0e5d1e89075fbe":["74f45af4339b0daf7a95c820ab88c1aea74fbce0","634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"610c97b96420e614c67797fd43822ebc1d4b7ee2":["283ff02f401ec3e7a2fad73643970f052383fb0c"],"e28b14e7783d24ca69089f13ddadadbd2afdcb29":["9274621789ce990dbfef455dabdf026bb3184821"],"d66363068e87a246ce08fee4a42f30f126b92723":["e6dd476b943b132ecfa6b3ffc72e439eb2d9e061"],"38e3b736c7ca086d61b7dbb841c905ee115490da":[],"a63520843c1d9af055af89fbaeb67eae848f28ae":["aebe9d27ca22125fc3d6aec04786171dca967833"],"d9a47902d6207303f5ed3e7aaca62ca33433af66":["55980207f1977bd1463465de1659b821347e2fa8"],"df525117ddb4dc8c8fe6e9fded68f55b29070496":["dfdcc495f7097a13c0ae88a3338561749a4eac0b","38e3b736c7ca086d61b7dbb841c905ee115490da"],"fe33227f6805edab2036cbb80645cc4e2d1fa424":["c7869f64c874ebf7f317d22c00baf2b6857797a6"],"f420cb3744c81c24c4a8781f95a446b9a2b5e011":["ba076ada7f119298baa28ce1043dbcf719a64141"],"d6f074e73200c07d54f242d3880a8da5a35ff97b":[],"74f45af4339b0daf7a95c820ab88c1aea74fbce0":[],"16851b5b065d6bd2924c0819a6d91e8e7bbde5d8":["f420cb3744c81c24c4a8781f95a446b9a2b5e011"],"072f211dfa8387028bb978d128c35bf9a450bbbf":["92751ba9273251eab6a2e379ec42a1697a32ff96"],"eb9e4cb185078b4e99e3b7070abb77eb2cdfaf6e":["4283fa55a69b0144f8baca38bb6f4230e27fd954","da951a24a6a87d5ba7e1820f8c28a1e2beea76c1"],"abb23fcc2461782ab204e61213240feb77d355aa":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"c26f00b574427b55127e869b935845554afde1fa":["0261694600e2fe9786395ecd0838ed98797d2660"],"bafca15d8e408346a67f4282ad1143b88023893b":["708afaee6d15fdeac34f31c2e05fb32ee7145bc0"],"56572ec06f1407c066d6b7399413178b33176cd8":[],"e6a0af6f7a7677267ad84c35bc106a61fd67dc62":["e28b14e7783d24ca69089f13ddadadbd2afdcb29","56572ec06f1407c066d6b7399413178b33176cd8","93dd449115a9247533e44bab47e8429e5dccbc6d"],"c7869f64c874ebf7f317d22c00baf2b6857797a6":[],"5da0b42730b6b99b31389ef94cb97384e83b9ede":["fe33227f6805edab2036cbb80645cc4e2d1fa424","88dcbe1d36c9d50525f58425024e87783c4005ab"],"708afaee6d15fdeac34f31c2e05fb32ee7145bc0":["abb23fcc2461782ab204e61213240feb77d355aa"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["c26f00b574427b55127e869b935845554afde1fa","c903c3d15906a3da96b8c0c2fb704491005fdbdb","a258fbb26824fd104ed795e5d9033d2d040049ee"],"0261694600e2fe9786395ecd0838ed98797d2660":["9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab","d66363068e87a246ce08fee4a42f30f126b92723"],"8ff4734b6c86245e852fe8b6a286716d5e59d415":["610c97b96420e614c67797fd43822ebc1d4b7ee2"],"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["e6a0af6f7a7677267ad84c35bc106a61fd67dc62"],"ba076ada7f119298baa28ce1043dbcf719a64141":["629c38c4ae4e303d0617e05fbfe508140b32f0a3"],"55980207f1977bd1463465de1659b821347e2fa8":[],"716d18f3a9b0993bc679d7fa7abdc9bfb03411ec":[],"e6dd476b943b132ecfa6b3ffc72e439eb2d9e061":["9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab","df525117ddb4dc8c8fe6e9fded68f55b29070496"],"c1500c4d2642ffe9c4fc6a09a7674b69a550fd36":["0d9835c6ddd23dd02eefd5adfc0e5d1e89075fbe"],"ea7b027695d1003f32a2b5587762e9d51d0d60e8":["37a0f60745e53927c4c876cfe5b5a58170f0646c","a2d7ec084be7fa496e6f93352b6e10427881eb35"],"88dcbe1d36c9d50525f58425024e87783c4005ab":["5c7ba2bec83cc0a507e2cb5a5af99102deb9b01d","fe33227f6805edab2036cbb80645cc4e2d1fa424","d6f074e73200c07d54f242d3880a8da5a35ff97b"],"d9d424bd039937b4125152b454b3a32754b06f6c":["74f45af4339b0daf7a95c820ab88c1aea74fbce0","c1500c4d2642ffe9c4fc6a09a7674b69a550fd36"],"283ff02f401ec3e7a2fad73643970f052383fb0c":["eb9e4cb185078b4e99e3b7070abb77eb2cdfaf6e","da951a24a6a87d5ba7e1820f8c28a1e2beea76c1"],"92bd590cd3fa131aa5a9c7f56693a7ec9cb6d279":["072f211dfa8387028bb978d128c35bf9a450bbbf"],"da951a24a6a87d5ba7e1820f8c28a1e2beea76c1":["d9a47902d6207303f5ed3e7aaca62ca33433af66"],"c903c3d15906a3da96b8c0c2fb704491005fdbdb":["c26f00b574427b55127e869b935845554afde1fa"],"93dd449115a9247533e44bab47e8429e5dccbc6d":["56572ec06f1407c066d6b7399413178b33176cd8","92bd590cd3fa131aa5a9c7f56693a7ec9cb6d279"],"f001da93ec624cbfbf3655c529836b5b1ec1aa46":["bafca15d8e408346a67f4282ad1143b88023893b","55980207f1977bd1463465de1659b821347e2fa8"],"a258fbb26824fd104ed795e5d9033d2d040049ee":[],"629c38c4ae4e303d0617e05fbfe508140b32f0a3":["ea7c3cda25547888b8a5a3989f5bbb00066746ed"],"aebe9d27ca22125fc3d6aec04786171dca967833":["16851b5b065d6bd2924c0819a6d91e8e7bbde5d8"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["38e3b736c7ca086d61b7dbb841c905ee115490da","d6f074e73200c07d54f242d3880a8da5a35ff97b","74f45af4339b0daf7a95c820ab88c1aea74fbce0","56572ec06f1407c066d6b7399413178b33176cd8","c7869f64c874ebf7f317d22c00baf2b6857797a6","55980207f1977bd1463465de1659b821347e2fa8","716d18f3a9b0993bc679d7fa7abdc9bfb03411ec","a258fbb26824fd104ed795e5d9033d2d040049ee","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}