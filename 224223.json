{"path":"lucene/core/src/test/org/apache/lucene/codecs/appending/TestAppendingCodec#testCodec().mjava","commits":[{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":1,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/appending/TestAppendingCodec#testCodec().mjava","pathOld":"lucene/src/test/org/apache/lucene/codecs/appending/TestAppendingCodec#testCodec().mjava","sourceNew":"  public void testCodec() throws Exception {\n    Directory dir = new AppendingRAMDirectory(random, new RAMDirectory());\n    IndexWriterConfig cfg = new IndexWriterConfig(Version.LUCENE_40, new MockAnalyzer(random));\n    \n    cfg.setCodec(new AppendingCodec());\n    ((TieredMergePolicy)cfg.getMergePolicy()).setUseCompoundFile(false);\n    IndexWriter writer = new IndexWriter(dir, cfg);\n    Document doc = new Document();\n    FieldType storedTextType = new FieldType(TextField.TYPE_STORED);\n    storedTextType.setStoreTermVectors(true);\n    storedTextType.setStoreTermVectorPositions(true);\n    storedTextType.setStoreTermVectorOffsets(true);\n    doc.add(newField(\"f\", text, storedTextType));\n    writer.addDocument(doc);\n    writer.commit();\n    writer.addDocument(doc);\n    writer.forceMerge(1);\n    writer.close();\n    IndexReader reader = IndexReader.open(dir, 1);\n    assertEquals(2, reader.numDocs());\n    Document doc2 = reader.document(0);\n    assertEquals(text, doc2.get(\"f\"));\n    Fields fields = MultiFields.getFields(reader);\n    Terms terms = fields.terms(\"f\");\n    assertNotNull(terms);\n    TermsEnum te = terms.iterator(null);\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"quick\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"brown\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"fox\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"jumped\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"over\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"lazy\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"dog\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"the\")));\n    DocsEnum de = te.docs(null, null, true);\n    assertTrue(de.advance(0) != DocsEnum.NO_MORE_DOCS);\n    assertEquals(2, de.freq());\n    assertTrue(de.advance(1) != DocsEnum.NO_MORE_DOCS);\n    assertTrue(de.advance(2) == DocsEnum.NO_MORE_DOCS);\n    reader.close();\n  }\n\n","sourceOld":"  public void testCodec() throws Exception {\n    Directory dir = new AppendingRAMDirectory(random, new RAMDirectory());\n    IndexWriterConfig cfg = new IndexWriterConfig(Version.LUCENE_40, new MockAnalyzer(random));\n    \n    cfg.setCodec(new AppendingCodec());\n    ((TieredMergePolicy)cfg.getMergePolicy()).setUseCompoundFile(false);\n    IndexWriter writer = new IndexWriter(dir, cfg);\n    Document doc = new Document();\n    FieldType storedTextType = new FieldType(TextField.TYPE_STORED);\n    storedTextType.setStoreTermVectors(true);\n    storedTextType.setStoreTermVectorPositions(true);\n    storedTextType.setStoreTermVectorOffsets(true);\n    doc.add(newField(\"f\", text, storedTextType));\n    writer.addDocument(doc);\n    writer.commit();\n    writer.addDocument(doc);\n    writer.forceMerge(1);\n    writer.close();\n    IndexReader reader = IndexReader.open(dir, 1);\n    assertEquals(2, reader.numDocs());\n    Document doc2 = reader.document(0);\n    assertEquals(text, doc2.get(\"f\"));\n    Fields fields = MultiFields.getFields(reader);\n    Terms terms = fields.terms(\"f\");\n    assertNotNull(terms);\n    TermsEnum te = terms.iterator(null);\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"quick\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"brown\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"fox\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"jumped\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"over\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"lazy\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"dog\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"the\")));\n    DocsEnum de = te.docs(null, null, true);\n    assertTrue(de.advance(0) != DocsEnum.NO_MORE_DOCS);\n    assertEquals(2, de.freq());\n    assertTrue(de.advance(1) != DocsEnum.NO_MORE_DOCS);\n    assertTrue(de.advance(2) == DocsEnum.NO_MORE_DOCS);\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f08557cdb6c60ac7b88a9342c983a20cd236e74f","date":1330954480,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/appending/TestAppendingCodec#testCodec().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/codecs/appending/TestAppendingCodec#testCodec().mjava","sourceNew":"  public void testCodec() throws Exception {\n    Directory dir = new AppendingRAMDirectory(random, new RAMDirectory());\n    IndexWriterConfig cfg = new IndexWriterConfig(Version.LUCENE_40, new MockAnalyzer(random));\n    \n    cfg.setCodec(new AppendingCodec());\n    ((TieredMergePolicy)cfg.getMergePolicy()).setUseCompoundFile(false);\n    IndexWriter writer = new IndexWriter(dir, cfg);\n    Document doc = new Document();\n    FieldType storedTextType = new FieldType(TextField.TYPE_STORED);\n    storedTextType.setStoreTermVectors(true);\n    storedTextType.setStoreTermVectorPositions(true);\n    storedTextType.setStoreTermVectorOffsets(true);\n    doc.add(newField(\"f\", text, storedTextType));\n    writer.addDocument(doc);\n    writer.commit();\n    writer.addDocument(doc);\n    writer.forceMerge(1);\n    writer.close();\n    IndexReader reader = IndexReader.open(dir, 1);\n    assertEquals(2, reader.numDocs());\n    Document doc2 = reader.document(0);\n    assertEquals(text, doc2.get(\"f\"));\n    Fields fields = MultiFields.getFields(reader);\n    Terms terms = fields.terms(\"f\");\n    assertNotNull(terms);\n    TermsEnum te = terms.iterator(null);\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"quick\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"brown\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"fox\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"jumped\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"over\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"lazy\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"dog\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"the\")));\n    DocsEnum de = te.docs(null, null, true);\n    assertTrue(de.advance(0) != DocIdSetIterator.NO_MORE_DOCS);\n    assertEquals(2, de.freq());\n    assertTrue(de.advance(1) != DocIdSetIterator.NO_MORE_DOCS);\n    assertTrue(de.advance(2) == DocIdSetIterator.NO_MORE_DOCS);\n    reader.close();\n  }\n\n","sourceOld":"  public void testCodec() throws Exception {\n    Directory dir = new AppendingRAMDirectory(random, new RAMDirectory());\n    IndexWriterConfig cfg = new IndexWriterConfig(Version.LUCENE_40, new MockAnalyzer(random));\n    \n    cfg.setCodec(new AppendingCodec());\n    ((TieredMergePolicy)cfg.getMergePolicy()).setUseCompoundFile(false);\n    IndexWriter writer = new IndexWriter(dir, cfg);\n    Document doc = new Document();\n    FieldType storedTextType = new FieldType(TextField.TYPE_STORED);\n    storedTextType.setStoreTermVectors(true);\n    storedTextType.setStoreTermVectorPositions(true);\n    storedTextType.setStoreTermVectorOffsets(true);\n    doc.add(newField(\"f\", text, storedTextType));\n    writer.addDocument(doc);\n    writer.commit();\n    writer.addDocument(doc);\n    writer.forceMerge(1);\n    writer.close();\n    IndexReader reader = IndexReader.open(dir, 1);\n    assertEquals(2, reader.numDocs());\n    Document doc2 = reader.document(0);\n    assertEquals(text, doc2.get(\"f\"));\n    Fields fields = MultiFields.getFields(reader);\n    Terms terms = fields.terms(\"f\");\n    assertNotNull(terms);\n    TermsEnum te = terms.iterator(null);\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"quick\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"brown\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"fox\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"jumped\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"over\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"lazy\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"dog\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"the\")));\n    DocsEnum de = te.docs(null, null, true);\n    assertTrue(de.advance(0) != DocsEnum.NO_MORE_DOCS);\n    assertEquals(2, de.freq());\n    assertTrue(de.advance(1) != DocsEnum.NO_MORE_DOCS);\n    assertTrue(de.advance(2) == DocsEnum.NO_MORE_DOCS);\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab","date":1331075828,"type":3,"author":"Ryan McKinley","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/appending/TestAppendingCodec#testCodec().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/codecs/appending/TestAppendingCodec#testCodec().mjava","sourceNew":"  public void testCodec() throws Exception {\n    Directory dir = new AppendingRAMDirectory(random, new RAMDirectory());\n    IndexWriterConfig cfg = new IndexWriterConfig(Version.LUCENE_40, new MockAnalyzer(random));\n    \n    cfg.setCodec(new AppendingCodec());\n    ((TieredMergePolicy)cfg.getMergePolicy()).setUseCompoundFile(false);\n    IndexWriter writer = new IndexWriter(dir, cfg);\n    Document doc = new Document();\n    FieldType storedTextType = new FieldType(TextField.TYPE_STORED);\n    storedTextType.setStoreTermVectors(true);\n    storedTextType.setStoreTermVectorPositions(true);\n    storedTextType.setStoreTermVectorOffsets(true);\n    doc.add(newField(\"f\", text, storedTextType));\n    writer.addDocument(doc);\n    writer.commit();\n    writer.addDocument(doc);\n    writer.forceMerge(1);\n    writer.close();\n    IndexReader reader = IndexReader.open(dir, 1);\n    assertEquals(2, reader.numDocs());\n    Document doc2 = reader.document(0);\n    assertEquals(text, doc2.get(\"f\"));\n    Fields fields = MultiFields.getFields(reader);\n    Terms terms = fields.terms(\"f\");\n    assertNotNull(terms);\n    TermsEnum te = terms.iterator(null);\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"quick\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"brown\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"fox\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"jumped\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"over\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"lazy\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"dog\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"the\")));\n    DocsEnum de = te.docs(null, null, true);\n    assertTrue(de.advance(0) != DocIdSetIterator.NO_MORE_DOCS);\n    assertEquals(2, de.freq());\n    assertTrue(de.advance(1) != DocIdSetIterator.NO_MORE_DOCS);\n    assertTrue(de.advance(2) == DocIdSetIterator.NO_MORE_DOCS);\n    reader.close();\n  }\n\n","sourceOld":"  public void testCodec() throws Exception {\n    Directory dir = new AppendingRAMDirectory(random, new RAMDirectory());\n    IndexWriterConfig cfg = new IndexWriterConfig(Version.LUCENE_40, new MockAnalyzer(random));\n    \n    cfg.setCodec(new AppendingCodec());\n    ((TieredMergePolicy)cfg.getMergePolicy()).setUseCompoundFile(false);\n    IndexWriter writer = new IndexWriter(dir, cfg);\n    Document doc = new Document();\n    FieldType storedTextType = new FieldType(TextField.TYPE_STORED);\n    storedTextType.setStoreTermVectors(true);\n    storedTextType.setStoreTermVectorPositions(true);\n    storedTextType.setStoreTermVectorOffsets(true);\n    doc.add(newField(\"f\", text, storedTextType));\n    writer.addDocument(doc);\n    writer.commit();\n    writer.addDocument(doc);\n    writer.forceMerge(1);\n    writer.close();\n    IndexReader reader = IndexReader.open(dir, 1);\n    assertEquals(2, reader.numDocs());\n    Document doc2 = reader.document(0);\n    assertEquals(text, doc2.get(\"f\"));\n    Fields fields = MultiFields.getFields(reader);\n    Terms terms = fields.terms(\"f\");\n    assertNotNull(terms);\n    TermsEnum te = terms.iterator(null);\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"quick\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"brown\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"fox\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"jumped\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"over\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"lazy\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"dog\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"the\")));\n    DocsEnum de = te.docs(null, null, true);\n    assertTrue(de.advance(0) != DocsEnum.NO_MORE_DOCS);\n    assertEquals(2, de.freq());\n    assertTrue(de.advance(1) != DocsEnum.NO_MORE_DOCS);\n    assertTrue(de.advance(2) == DocsEnum.NO_MORE_DOCS);\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d08eba3d52b63561ebf936481ce73e6b6a14aa03","date":1333879759,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/appending/TestAppendingCodec#testCodec().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/codecs/appending/TestAppendingCodec#testCodec().mjava","sourceNew":"  public void testCodec() throws Exception {\n    Directory dir = new AppendingRAMDirectory(random, new RAMDirectory());\n    IndexWriterConfig cfg = new IndexWriterConfig(Version.LUCENE_40, new MockAnalyzer(random));\n    \n    cfg.setCodec(new AppendingCodec());\n    ((TieredMergePolicy)cfg.getMergePolicy()).setUseCompoundFile(false);\n    IndexWriter writer = new IndexWriter(dir, cfg);\n    Document doc = new Document();\n    FieldType storedTextType = new FieldType(TextField.TYPE_STORED);\n    storedTextType.setStoreTermVectors(true);\n    storedTextType.setStoreTermVectorPositions(true);\n    storedTextType.setStoreTermVectorOffsets(true);\n    doc.add(newField(\"f\", text, storedTextType));\n    writer.addDocument(doc);\n    writer.commit();\n    writer.addDocument(doc);\n    writer.forceMerge(1);\n    writer.close();\n    IndexReader reader = IndexReader.open(dir, 1);\n    assertEquals(2, reader.numDocs());\n    Document doc2 = reader.document(0);\n    assertEquals(text, doc2.get(\"f\"));\n    InvertedFields fields = MultiFields.getFields(reader);\n    Terms terms = fields.terms(\"f\");\n    assertNotNull(terms);\n    TermsEnum te = terms.iterator(null);\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"quick\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"brown\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"fox\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"jumped\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"over\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"lazy\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"dog\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"the\")));\n    DocsEnum de = te.docs(null, null, true);\n    assertTrue(de.advance(0) != DocIdSetIterator.NO_MORE_DOCS);\n    assertEquals(2, de.freq());\n    assertTrue(de.advance(1) != DocIdSetIterator.NO_MORE_DOCS);\n    assertTrue(de.advance(2) == DocIdSetIterator.NO_MORE_DOCS);\n    reader.close();\n  }\n\n","sourceOld":"  public void testCodec() throws Exception {\n    Directory dir = new AppendingRAMDirectory(random, new RAMDirectory());\n    IndexWriterConfig cfg = new IndexWriterConfig(Version.LUCENE_40, new MockAnalyzer(random));\n    \n    cfg.setCodec(new AppendingCodec());\n    ((TieredMergePolicy)cfg.getMergePolicy()).setUseCompoundFile(false);\n    IndexWriter writer = new IndexWriter(dir, cfg);\n    Document doc = new Document();\n    FieldType storedTextType = new FieldType(TextField.TYPE_STORED);\n    storedTextType.setStoreTermVectors(true);\n    storedTextType.setStoreTermVectorPositions(true);\n    storedTextType.setStoreTermVectorOffsets(true);\n    doc.add(newField(\"f\", text, storedTextType));\n    writer.addDocument(doc);\n    writer.commit();\n    writer.addDocument(doc);\n    writer.forceMerge(1);\n    writer.close();\n    IndexReader reader = IndexReader.open(dir, 1);\n    assertEquals(2, reader.numDocs());\n    Document doc2 = reader.document(0);\n    assertEquals(text, doc2.get(\"f\"));\n    Fields fields = MultiFields.getFields(reader);\n    Terms terms = fields.terms(\"f\");\n    assertNotNull(terms);\n    TermsEnum te = terms.iterator(null);\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"quick\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"brown\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"fox\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"jumped\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"over\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"lazy\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"dog\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"the\")));\n    DocsEnum de = te.docs(null, null, true);\n    assertTrue(de.advance(0) != DocIdSetIterator.NO_MORE_DOCS);\n    assertEquals(2, de.freq());\n    assertTrue(de.advance(1) != DocIdSetIterator.NO_MORE_DOCS);\n    assertTrue(de.advance(2) == DocIdSetIterator.NO_MORE_DOCS);\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"e3f8ac3877ad6d160de0fd3a6f7155b243dfbddf","date":1333892281,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/appending/TestAppendingCodec#testCodec().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/codecs/appending/TestAppendingCodec#testCodec().mjava","sourceNew":"  public void testCodec() throws Exception {\n    Directory dir = new AppendingRAMDirectory(random, new RAMDirectory());\n    IndexWriterConfig cfg = new IndexWriterConfig(Version.LUCENE_40, new MockAnalyzer(random));\n    \n    cfg.setCodec(new AppendingCodec());\n    ((TieredMergePolicy)cfg.getMergePolicy()).setUseCompoundFile(false);\n    IndexWriter writer = new IndexWriter(dir, cfg);\n    Document doc = new Document();\n    FieldType storedTextType = new FieldType(TextField.TYPE_STORED);\n    storedTextType.setStoreTermVectors(true);\n    storedTextType.setStoreTermVectorPositions(true);\n    storedTextType.setStoreTermVectorOffsets(true);\n    doc.add(newField(\"f\", text, storedTextType));\n    writer.addDocument(doc);\n    writer.commit();\n    writer.addDocument(doc);\n    writer.forceMerge(1);\n    writer.close();\n    IndexReader reader = IndexReader.open(dir, 1);\n    assertEquals(2, reader.numDocs());\n    Document doc2 = reader.document(0);\n    assertEquals(text, doc2.get(\"f\"));\n    Fields fields = MultiFields.getFields(reader);\n    Terms terms = fields.terms(\"f\");\n    assertNotNull(terms);\n    TermsEnum te = terms.iterator(null);\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"quick\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"brown\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"fox\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"jumped\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"over\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"lazy\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"dog\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"the\")));\n    DocsEnum de = te.docs(null, null, true);\n    assertTrue(de.advance(0) != DocIdSetIterator.NO_MORE_DOCS);\n    assertEquals(2, de.freq());\n    assertTrue(de.advance(1) != DocIdSetIterator.NO_MORE_DOCS);\n    assertTrue(de.advance(2) == DocIdSetIterator.NO_MORE_DOCS);\n    reader.close();\n  }\n\n","sourceOld":"  public void testCodec() throws Exception {\n    Directory dir = new AppendingRAMDirectory(random, new RAMDirectory());\n    IndexWriterConfig cfg = new IndexWriterConfig(Version.LUCENE_40, new MockAnalyzer(random));\n    \n    cfg.setCodec(new AppendingCodec());\n    ((TieredMergePolicy)cfg.getMergePolicy()).setUseCompoundFile(false);\n    IndexWriter writer = new IndexWriter(dir, cfg);\n    Document doc = new Document();\n    FieldType storedTextType = new FieldType(TextField.TYPE_STORED);\n    storedTextType.setStoreTermVectors(true);\n    storedTextType.setStoreTermVectorPositions(true);\n    storedTextType.setStoreTermVectorOffsets(true);\n    doc.add(newField(\"f\", text, storedTextType));\n    writer.addDocument(doc);\n    writer.commit();\n    writer.addDocument(doc);\n    writer.forceMerge(1);\n    writer.close();\n    IndexReader reader = IndexReader.open(dir, 1);\n    assertEquals(2, reader.numDocs());\n    Document doc2 = reader.document(0);\n    assertEquals(text, doc2.get(\"f\"));\n    InvertedFields fields = MultiFields.getFields(reader);\n    Terms terms = fields.terms(\"f\");\n    assertNotNull(terms);\n    TermsEnum te = terms.iterator(null);\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"quick\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"brown\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"fox\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"jumped\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"over\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"lazy\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"dog\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"the\")));\n    DocsEnum de = te.docs(null, null, true);\n    assertTrue(de.advance(0) != DocIdSetIterator.NO_MORE_DOCS);\n    assertEquals(2, de.freq());\n    assertTrue(de.advance(1) != DocIdSetIterator.NO_MORE_DOCS);\n    assertTrue(de.advance(2) == DocIdSetIterator.NO_MORE_DOCS);\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"629c38c4ae4e303d0617e05fbfe508140b32f0a3","date":1334500904,"type":3,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/appending/TestAppendingCodec#testCodec().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/codecs/appending/TestAppendingCodec#testCodec().mjava","sourceNew":"  public void testCodec() throws Exception {\n    Directory dir = new AppendingRAMDirectory(random(), new RAMDirectory());\n    IndexWriterConfig cfg = new IndexWriterConfig(Version.LUCENE_40, new MockAnalyzer(random()));\n    \n    cfg.setCodec(new AppendingCodec());\n    ((TieredMergePolicy)cfg.getMergePolicy()).setUseCompoundFile(false);\n    IndexWriter writer = new IndexWriter(dir, cfg);\n    Document doc = new Document();\n    FieldType storedTextType = new FieldType(TextField.TYPE_STORED);\n    storedTextType.setStoreTermVectors(true);\n    storedTextType.setStoreTermVectorPositions(true);\n    storedTextType.setStoreTermVectorOffsets(true);\n    doc.add(newField(\"f\", text, storedTextType));\n    writer.addDocument(doc);\n    writer.commit();\n    writer.addDocument(doc);\n    writer.forceMerge(1);\n    writer.close();\n    IndexReader reader = IndexReader.open(dir, 1);\n    assertEquals(2, reader.numDocs());\n    Document doc2 = reader.document(0);\n    assertEquals(text, doc2.get(\"f\"));\n    Fields fields = MultiFields.getFields(reader);\n    Terms terms = fields.terms(\"f\");\n    assertNotNull(terms);\n    TermsEnum te = terms.iterator(null);\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"quick\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"brown\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"fox\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"jumped\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"over\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"lazy\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"dog\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"the\")));\n    DocsEnum de = te.docs(null, null, true);\n    assertTrue(de.advance(0) != DocIdSetIterator.NO_MORE_DOCS);\n    assertEquals(2, de.freq());\n    assertTrue(de.advance(1) != DocIdSetIterator.NO_MORE_DOCS);\n    assertTrue(de.advance(2) == DocIdSetIterator.NO_MORE_DOCS);\n    reader.close();\n  }\n\n","sourceOld":"  public void testCodec() throws Exception {\n    Directory dir = new AppendingRAMDirectory(random, new RAMDirectory());\n    IndexWriterConfig cfg = new IndexWriterConfig(Version.LUCENE_40, new MockAnalyzer(random));\n    \n    cfg.setCodec(new AppendingCodec());\n    ((TieredMergePolicy)cfg.getMergePolicy()).setUseCompoundFile(false);\n    IndexWriter writer = new IndexWriter(dir, cfg);\n    Document doc = new Document();\n    FieldType storedTextType = new FieldType(TextField.TYPE_STORED);\n    storedTextType.setStoreTermVectors(true);\n    storedTextType.setStoreTermVectorPositions(true);\n    storedTextType.setStoreTermVectorOffsets(true);\n    doc.add(newField(\"f\", text, storedTextType));\n    writer.addDocument(doc);\n    writer.commit();\n    writer.addDocument(doc);\n    writer.forceMerge(1);\n    writer.close();\n    IndexReader reader = IndexReader.open(dir, 1);\n    assertEquals(2, reader.numDocs());\n    Document doc2 = reader.document(0);\n    assertEquals(text, doc2.get(\"f\"));\n    Fields fields = MultiFields.getFields(reader);\n    Terms terms = fields.terms(\"f\");\n    assertNotNull(terms);\n    TermsEnum te = terms.iterator(null);\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"quick\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"brown\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"fox\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"jumped\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"over\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"lazy\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"dog\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"the\")));\n    DocsEnum de = te.docs(null, null, true);\n    assertTrue(de.advance(0) != DocIdSetIterator.NO_MORE_DOCS);\n    assertEquals(2, de.freq());\n    assertTrue(de.advance(1) != DocIdSetIterator.NO_MORE_DOCS);\n    assertTrue(de.advance(2) == DocIdSetIterator.NO_MORE_DOCS);\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"e7e8d6f15900ee22ac3cb0a503f15dc952a3580f","date":1338430031,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/appending/TestAppendingCodec#testCodec().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/codecs/appending/TestAppendingCodec#testCodec().mjava","sourceNew":"  public void testCodec() throws Exception {\n    Directory dir = new AppendingRAMDirectory(random(), new RAMDirectory());\n    IndexWriterConfig cfg = new IndexWriterConfig(Version.LUCENE_40, new MockAnalyzer(random()));\n    \n    cfg.setCodec(new AppendingCodec());\n    ((TieredMergePolicy)cfg.getMergePolicy()).setUseCompoundFile(false);\n    IndexWriter writer = new IndexWriter(dir, cfg);\n    Document doc = new Document();\n    FieldType storedTextType = new FieldType(TextField.TYPE_STORED);\n    storedTextType.setStoreTermVectors(true);\n    storedTextType.setStoreTermVectorPositions(true);\n    storedTextType.setStoreTermVectorOffsets(true);\n    doc.add(newField(\"f\", text, storedTextType));\n    writer.addDocument(doc);\n    writer.commit();\n    writer.addDocument(doc);\n    writer.forceMerge(1);\n    writer.close();\n    IndexReader reader = DirectoryReader.open(dir, 1);\n    assertEquals(2, reader.numDocs());\n    Document doc2 = reader.document(0);\n    assertEquals(text, doc2.get(\"f\"));\n    Fields fields = MultiFields.getFields(reader);\n    Terms terms = fields.terms(\"f\");\n    assertNotNull(terms);\n    TermsEnum te = terms.iterator(null);\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"quick\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"brown\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"fox\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"jumped\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"over\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"lazy\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"dog\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"the\")));\n    DocsEnum de = te.docs(null, null, true);\n    assertTrue(de.advance(0) != DocIdSetIterator.NO_MORE_DOCS);\n    assertEquals(2, de.freq());\n    assertTrue(de.advance(1) != DocIdSetIterator.NO_MORE_DOCS);\n    assertTrue(de.advance(2) == DocIdSetIterator.NO_MORE_DOCS);\n    reader.close();\n  }\n\n","sourceOld":"  public void testCodec() throws Exception {\n    Directory dir = new AppendingRAMDirectory(random(), new RAMDirectory());\n    IndexWriterConfig cfg = new IndexWriterConfig(Version.LUCENE_40, new MockAnalyzer(random()));\n    \n    cfg.setCodec(new AppendingCodec());\n    ((TieredMergePolicy)cfg.getMergePolicy()).setUseCompoundFile(false);\n    IndexWriter writer = new IndexWriter(dir, cfg);\n    Document doc = new Document();\n    FieldType storedTextType = new FieldType(TextField.TYPE_STORED);\n    storedTextType.setStoreTermVectors(true);\n    storedTextType.setStoreTermVectorPositions(true);\n    storedTextType.setStoreTermVectorOffsets(true);\n    doc.add(newField(\"f\", text, storedTextType));\n    writer.addDocument(doc);\n    writer.commit();\n    writer.addDocument(doc);\n    writer.forceMerge(1);\n    writer.close();\n    IndexReader reader = IndexReader.open(dir, 1);\n    assertEquals(2, reader.numDocs());\n    Document doc2 = reader.document(0);\n    assertEquals(text, doc2.get(\"f\"));\n    Fields fields = MultiFields.getFields(reader);\n    Terms terms = fields.terms(\"f\");\n    assertNotNull(terms);\n    TermsEnum te = terms.iterator(null);\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"quick\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"brown\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"fox\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"jumped\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"over\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"lazy\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"dog\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"the\")));\n    DocsEnum de = te.docs(null, null, true);\n    assertTrue(de.advance(0) != DocIdSetIterator.NO_MORE_DOCS);\n    assertEquals(2, de.freq());\n    assertTrue(de.advance(1) != DocIdSetIterator.NO_MORE_DOCS);\n    assertTrue(de.advance(2) == DocIdSetIterator.NO_MORE_DOCS);\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"8f0e28f2a7f0f3f0fca1a2ffedaa10c7ac9536c4","date":1341839195,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/appending/TestAppendingCodec#testCodec().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/codecs/appending/TestAppendingCodec#testCodec().mjava","sourceNew":"  public void testCodec() throws Exception {\n    Directory dir = new AppendingRAMDirectory(random(), new RAMDirectory());\n    IndexWriterConfig cfg = new IndexWriterConfig(Version.LUCENE_40, new MockAnalyzer(random()));\n    \n    cfg.setCodec(new AppendingCodec());\n    ((TieredMergePolicy)cfg.getMergePolicy()).setUseCompoundFile(false);\n    IndexWriter writer = new IndexWriter(dir, cfg);\n    Document doc = new Document();\n    FieldType storedTextType = new FieldType(TextField.TYPE_STORED);\n    storedTextType.setStoreTermVectors(true);\n    storedTextType.setStoreTermVectorPositions(true);\n    storedTextType.setStoreTermVectorOffsets(true);\n    doc.add(newField(\"f\", text, storedTextType));\n    writer.addDocument(doc);\n    writer.commit();\n    writer.addDocument(doc);\n    writer.forceMerge(1);\n    writer.close();\n    IndexReader reader = DirectoryReader.open(dir, 1);\n    assertEquals(2, reader.numDocs());\n    StoredDocument doc2 = reader.document(0);\n    assertEquals(text, doc2.get(\"f\"));\n    Fields fields = MultiFields.getFields(reader);\n    Terms terms = fields.terms(\"f\");\n    assertNotNull(terms);\n    TermsEnum te = terms.iterator(null);\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"quick\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"brown\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"fox\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"jumped\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"over\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"lazy\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"dog\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"the\")));\n    DocsEnum de = te.docs(null, null, true);\n    assertTrue(de.advance(0) != DocIdSetIterator.NO_MORE_DOCS);\n    assertEquals(2, de.freq());\n    assertTrue(de.advance(1) != DocIdSetIterator.NO_MORE_DOCS);\n    assertTrue(de.advance(2) == DocIdSetIterator.NO_MORE_DOCS);\n    reader.close();\n  }\n\n","sourceOld":"  public void testCodec() throws Exception {\n    Directory dir = new AppendingRAMDirectory(random(), new RAMDirectory());\n    IndexWriterConfig cfg = new IndexWriterConfig(Version.LUCENE_40, new MockAnalyzer(random()));\n    \n    cfg.setCodec(new AppendingCodec());\n    ((TieredMergePolicy)cfg.getMergePolicy()).setUseCompoundFile(false);\n    IndexWriter writer = new IndexWriter(dir, cfg);\n    Document doc = new Document();\n    FieldType storedTextType = new FieldType(TextField.TYPE_STORED);\n    storedTextType.setStoreTermVectors(true);\n    storedTextType.setStoreTermVectorPositions(true);\n    storedTextType.setStoreTermVectorOffsets(true);\n    doc.add(newField(\"f\", text, storedTextType));\n    writer.addDocument(doc);\n    writer.commit();\n    writer.addDocument(doc);\n    writer.forceMerge(1);\n    writer.close();\n    IndexReader reader = DirectoryReader.open(dir, 1);\n    assertEquals(2, reader.numDocs());\n    Document doc2 = reader.document(0);\n    assertEquals(text, doc2.get(\"f\"));\n    Fields fields = MultiFields.getFields(reader);\n    Terms terms = fields.terms(\"f\");\n    assertNotNull(terms);\n    TermsEnum te = terms.iterator(null);\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"quick\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"brown\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"fox\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"jumped\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"over\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"lazy\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"dog\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"the\")));\n    DocsEnum de = te.docs(null, null, true);\n    assertTrue(de.advance(0) != DocIdSetIterator.NO_MORE_DOCS);\n    assertEquals(2, de.freq());\n    assertTrue(de.advance(1) != DocIdSetIterator.NO_MORE_DOCS);\n    assertTrue(de.advance(2) == DocIdSetIterator.NO_MORE_DOCS);\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"02331260bb246364779cb6f04919ca47900d01bb","date":1343749884,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/appending/TestAppendingCodec#testCodec().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/codecs/appending/TestAppendingCodec#testCodec().mjava","sourceNew":"  public void testCodec() throws Exception {\n    Directory dir = new AppendingRAMDirectory(random(), new RAMDirectory());\n    IndexWriterConfig cfg = new IndexWriterConfig(Version.LUCENE_40, new MockAnalyzer(random()));\n    \n    cfg.setCodec(new AppendingCodec());\n    ((TieredMergePolicy)cfg.getMergePolicy()).setUseCompoundFile(false);\n    IndexWriter writer = new IndexWriter(dir, cfg);\n    Document doc = new Document();\n    FieldType storedTextType = new FieldType(TextField.TYPE_STORED);\n    storedTextType.setStoreTermVectors(true);\n    storedTextType.setStoreTermVectorPositions(true);\n    storedTextType.setStoreTermVectorOffsets(true);\n    doc.add(newField(\"f\", text, storedTextType));\n    writer.addDocument(doc);\n    writer.commit();\n    writer.addDocument(doc);\n    writer.forceMerge(1);\n    writer.close();\n    IndexReader reader = DirectoryReader.open(dir, 1);\n    assertEquals(2, reader.numDocs());\n    Document doc2 = reader.document(0);\n    assertEquals(text, doc2.get(\"f\"));\n    Fields fields = MultiFields.getFields(reader);\n    Terms terms = fields.terms(\"f\");\n    assertNotNull(terms);\n    TermsEnum te = terms.iterator(null);\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"quick\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"brown\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"fox\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"jumped\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"over\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"lazy\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"dog\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"the\")));\n    DocsEnum de = te.docs(null, null);\n    assertTrue(de.advance(0) != DocIdSetIterator.NO_MORE_DOCS);\n    assertEquals(2, de.freq());\n    assertTrue(de.advance(1) != DocIdSetIterator.NO_MORE_DOCS);\n    assertTrue(de.advance(2) == DocIdSetIterator.NO_MORE_DOCS);\n    reader.close();\n  }\n\n","sourceOld":"  public void testCodec() throws Exception {\n    Directory dir = new AppendingRAMDirectory(random(), new RAMDirectory());\n    IndexWriterConfig cfg = new IndexWriterConfig(Version.LUCENE_40, new MockAnalyzer(random()));\n    \n    cfg.setCodec(new AppendingCodec());\n    ((TieredMergePolicy)cfg.getMergePolicy()).setUseCompoundFile(false);\n    IndexWriter writer = new IndexWriter(dir, cfg);\n    Document doc = new Document();\n    FieldType storedTextType = new FieldType(TextField.TYPE_STORED);\n    storedTextType.setStoreTermVectors(true);\n    storedTextType.setStoreTermVectorPositions(true);\n    storedTextType.setStoreTermVectorOffsets(true);\n    doc.add(newField(\"f\", text, storedTextType));\n    writer.addDocument(doc);\n    writer.commit();\n    writer.addDocument(doc);\n    writer.forceMerge(1);\n    writer.close();\n    IndexReader reader = DirectoryReader.open(dir, 1);\n    assertEquals(2, reader.numDocs());\n    Document doc2 = reader.document(0);\n    assertEquals(text, doc2.get(\"f\"));\n    Fields fields = MultiFields.getFields(reader);\n    Terms terms = fields.terms(\"f\");\n    assertNotNull(terms);\n    TermsEnum te = terms.iterator(null);\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"quick\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"brown\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"fox\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"jumped\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"over\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"lazy\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"dog\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"the\")));\n    DocsEnum de = te.docs(null, null, true);\n    assertTrue(de.advance(0) != DocIdSetIterator.NO_MORE_DOCS);\n    assertEquals(2, de.freq());\n    assertTrue(de.advance(1) != DocIdSetIterator.NO_MORE_DOCS);\n    assertTrue(de.advance(2) == DocIdSetIterator.NO_MORE_DOCS);\n    reader.close();\n  }\n\n","bugFix":["872cff1d3a554e0cd64014cd97f88d3002b0f491"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f","date":1343768312,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/appending/TestAppendingCodec#testCodec().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/codecs/appending/TestAppendingCodec#testCodec().mjava","sourceNew":"  public void testCodec() throws Exception {\n    Directory dir = new AppendingRAMDirectory(random(), new RAMDirectory());\n    IndexWriterConfig cfg = new IndexWriterConfig(Version.LUCENE_40, new MockAnalyzer(random()));\n    \n    cfg.setCodec(new AppendingCodec());\n    ((TieredMergePolicy)cfg.getMergePolicy()).setUseCompoundFile(false);\n    IndexWriter writer = new IndexWriter(dir, cfg);\n    Document doc = new Document();\n    FieldType storedTextType = new FieldType(TextField.TYPE_STORED);\n    storedTextType.setStoreTermVectors(true);\n    storedTextType.setStoreTermVectorPositions(true);\n    storedTextType.setStoreTermVectorOffsets(true);\n    doc.add(newField(\"f\", text, storedTextType));\n    writer.addDocument(doc);\n    writer.commit();\n    writer.addDocument(doc);\n    writer.forceMerge(1);\n    writer.close();\n    IndexReader reader = DirectoryReader.open(dir, 1);\n    assertEquals(2, reader.numDocs());\n    Document doc2 = reader.document(0);\n    assertEquals(text, doc2.get(\"f\"));\n    Fields fields = MultiFields.getFields(reader);\n    Terms terms = fields.terms(\"f\");\n    assertNotNull(terms);\n    TermsEnum te = terms.iterator(null);\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"quick\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"brown\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"fox\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"jumped\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"over\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"lazy\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"dog\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"the\")));\n    DocsEnum de = te.docs(null, null);\n    assertTrue(de.advance(0) != DocIdSetIterator.NO_MORE_DOCS);\n    assertEquals(2, de.freq());\n    assertTrue(de.advance(1) != DocIdSetIterator.NO_MORE_DOCS);\n    assertTrue(de.advance(2) == DocIdSetIterator.NO_MORE_DOCS);\n    reader.close();\n  }\n\n","sourceOld":"  public void testCodec() throws Exception {\n    Directory dir = new AppendingRAMDirectory(random(), new RAMDirectory());\n    IndexWriterConfig cfg = new IndexWriterConfig(Version.LUCENE_40, new MockAnalyzer(random()));\n    \n    cfg.setCodec(new AppendingCodec());\n    ((TieredMergePolicy)cfg.getMergePolicy()).setUseCompoundFile(false);\n    IndexWriter writer = new IndexWriter(dir, cfg);\n    Document doc = new Document();\n    FieldType storedTextType = new FieldType(TextField.TYPE_STORED);\n    storedTextType.setStoreTermVectors(true);\n    storedTextType.setStoreTermVectorPositions(true);\n    storedTextType.setStoreTermVectorOffsets(true);\n    doc.add(newField(\"f\", text, storedTextType));\n    writer.addDocument(doc);\n    writer.commit();\n    writer.addDocument(doc);\n    writer.forceMerge(1);\n    writer.close();\n    IndexReader reader = DirectoryReader.open(dir, 1);\n    assertEquals(2, reader.numDocs());\n    Document doc2 = reader.document(0);\n    assertEquals(text, doc2.get(\"f\"));\n    Fields fields = MultiFields.getFields(reader);\n    Terms terms = fields.terms(\"f\");\n    assertNotNull(terms);\n    TermsEnum te = terms.iterator(null);\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"quick\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"brown\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"fox\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"jumped\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"over\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"lazy\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"dog\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"the\")));\n    DocsEnum de = te.docs(null, null, true);\n    assertTrue(de.advance(0) != DocIdSetIterator.NO_MORE_DOCS);\n    assertEquals(2, de.freq());\n    assertTrue(de.advance(1) != DocIdSetIterator.NO_MORE_DOCS);\n    assertTrue(de.advance(2) == DocIdSetIterator.NO_MORE_DOCS);\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d6f074e73200c07d54f242d3880a8da5a35ff97b","date":1344507653,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/appending/TestAppendingCodec#testCodec().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/codecs/appending/TestAppendingCodec#testCodec().mjava","sourceNew":"  public void testCodec() throws Exception {\n    Directory dir = new AppendingRAMDirectory(random(), new RAMDirectory());\n    IndexWriterConfig cfg = new IndexWriterConfig(Version.LUCENE_40, new MockAnalyzer(random()));\n    \n    cfg.setCodec(new AppendingCodec());\n    ((TieredMergePolicy)cfg.getMergePolicy()).setUseCompoundFile(false);\n    IndexWriter writer = new IndexWriter(dir, cfg);\n    Document doc = new Document();\n    FieldType storedTextType = new FieldType(TextField.TYPE_STORED);\n    storedTextType.setStoreTermVectors(true);\n    storedTextType.setStoreTermVectorPositions(true);\n    storedTextType.setStoreTermVectorOffsets(true);\n    doc.add(newField(\"f\", text, storedTextType));\n    writer.addDocument(doc);\n    writer.commit();\n    writer.addDocument(doc);\n    writer.forceMerge(1);\n    writer.close();\n    IndexReader reader = DirectoryReader.open(dir, 1);\n    assertEquals(2, reader.numDocs());\n    StoredDocument doc2 = reader.document(0);\n    assertEquals(text, doc2.get(\"f\"));\n    Fields fields = MultiFields.getFields(reader);\n    Terms terms = fields.terms(\"f\");\n    assertNotNull(terms);\n    TermsEnum te = terms.iterator(null);\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"quick\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"brown\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"fox\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"jumped\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"over\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"lazy\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"dog\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"the\")));\n    DocsEnum de = te.docs(null, null);\n    assertTrue(de.advance(0) != DocIdSetIterator.NO_MORE_DOCS);\n    assertEquals(2, de.freq());\n    assertTrue(de.advance(1) != DocIdSetIterator.NO_MORE_DOCS);\n    assertTrue(de.advance(2) == DocIdSetIterator.NO_MORE_DOCS);\n    reader.close();\n  }\n\n","sourceOld":"  public void testCodec() throws Exception {\n    Directory dir = new AppendingRAMDirectory(random(), new RAMDirectory());\n    IndexWriterConfig cfg = new IndexWriterConfig(Version.LUCENE_40, new MockAnalyzer(random()));\n    \n    cfg.setCodec(new AppendingCodec());\n    ((TieredMergePolicy)cfg.getMergePolicy()).setUseCompoundFile(false);\n    IndexWriter writer = new IndexWriter(dir, cfg);\n    Document doc = new Document();\n    FieldType storedTextType = new FieldType(TextField.TYPE_STORED);\n    storedTextType.setStoreTermVectors(true);\n    storedTextType.setStoreTermVectorPositions(true);\n    storedTextType.setStoreTermVectorOffsets(true);\n    doc.add(newField(\"f\", text, storedTextType));\n    writer.addDocument(doc);\n    writer.commit();\n    writer.addDocument(doc);\n    writer.forceMerge(1);\n    writer.close();\n    IndexReader reader = DirectoryReader.open(dir, 1);\n    assertEquals(2, reader.numDocs());\n    StoredDocument doc2 = reader.document(0);\n    assertEquals(text, doc2.get(\"f\"));\n    Fields fields = MultiFields.getFields(reader);\n    Terms terms = fields.terms(\"f\");\n    assertNotNull(terms);\n    TermsEnum te = terms.iterator(null);\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"quick\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"brown\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"fox\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"jumped\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"over\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"lazy\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"dog\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"the\")));\n    DocsEnum de = te.docs(null, null, true);\n    assertTrue(de.advance(0) != DocIdSetIterator.NO_MORE_DOCS);\n    assertEquals(2, de.freq());\n    assertTrue(de.advance(1) != DocIdSetIterator.NO_MORE_DOCS);\n    assertTrue(de.advance(2) == DocIdSetIterator.NO_MORE_DOCS);\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1d028314cced5858683a1bb4741423d0f934257b","date":1346596535,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/appending/TestAppendingCodec#testCodec().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/codecs/appending/TestAppendingCodec#testCodec().mjava","sourceNew":"  public void testCodec() throws Exception {\n    Directory dir = new AppendingRAMDirectory(random(), new RAMDirectory());\n    IndexWriterConfig cfg = new IndexWriterConfig(Version.LUCENE_40, new MockAnalyzer(random()));\n    \n    cfg.setCodec(new AppendingCodec());\n    ((TieredMergePolicy)cfg.getMergePolicy()).setUseCompoundFile(false);\n    IndexWriter writer = new IndexWriter(dir, cfg);\n    Document doc = new Document();\n    FieldType storedTextType = new FieldType(TextField.TYPE_STORED);\n    storedTextType.setStoreTermVectors(true);\n    storedTextType.setStoreTermVectorPositions(true);\n    storedTextType.setStoreTermVectorOffsets(true);\n    doc.add(newField(\"f\", text, storedTextType));\n    writer.addDocument(doc);\n    writer.commit();\n    writer.addDocument(doc);\n    writer.forceMerge(1);\n    writer.close();\n    IndexReader reader = DirectoryReader.open(dir, 1);\n    assertEquals(2, reader.numDocs());\n    StoredDocument doc2 = reader.document(0);\n    assertEquals(text, doc2.get(\"f\"));\n    Fields fields = MultiFields.getFields(reader);\n    Terms terms = fields.terms(\"f\");\n    assertNotNull(terms);\n    TermsEnum te = terms.iterator(null);\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"quick\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"brown\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"fox\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"jumped\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"over\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"lazy\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"dog\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"the\")));\n    DocsEnum de = te.docs(null, null);\n    assertTrue(de.advance(0) != DocIdSetIterator.NO_MORE_DOCS);\n    assertEquals(2, de.freq());\n    assertTrue(de.advance(1) != DocIdSetIterator.NO_MORE_DOCS);\n    assertTrue(de.advance(2) == DocIdSetIterator.NO_MORE_DOCS);\n    reader.close();\n  }\n\n","sourceOld":"  public void testCodec() throws Exception {\n    Directory dir = new AppendingRAMDirectory(random(), new RAMDirectory());\n    IndexWriterConfig cfg = new IndexWriterConfig(Version.LUCENE_40, new MockAnalyzer(random()));\n    \n    cfg.setCodec(new AppendingCodec());\n    ((TieredMergePolicy)cfg.getMergePolicy()).setUseCompoundFile(false);\n    IndexWriter writer = new IndexWriter(dir, cfg);\n    Document doc = new Document();\n    FieldType storedTextType = new FieldType(TextField.TYPE_STORED);\n    storedTextType.setStoreTermVectors(true);\n    storedTextType.setStoreTermVectorPositions(true);\n    storedTextType.setStoreTermVectorOffsets(true);\n    doc.add(newField(\"f\", text, storedTextType));\n    writer.addDocument(doc);\n    writer.commit();\n    writer.addDocument(doc);\n    writer.forceMerge(1);\n    writer.close();\n    IndexReader reader = DirectoryReader.open(dir, 1);\n    assertEquals(2, reader.numDocs());\n    Document doc2 = reader.document(0);\n    assertEquals(text, doc2.get(\"f\"));\n    Fields fields = MultiFields.getFields(reader);\n    Terms terms = fields.terms(\"f\");\n    assertNotNull(terms);\n    TermsEnum te = terms.iterator(null);\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"quick\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"brown\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"fox\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"jumped\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"over\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"lazy\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"dog\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"the\")));\n    DocsEnum de = te.docs(null, null);\n    assertTrue(de.advance(0) != DocIdSetIterator.NO_MORE_DOCS);\n    assertEquals(2, de.freq());\n    assertTrue(de.advance(1) != DocIdSetIterator.NO_MORE_DOCS);\n    assertTrue(de.advance(2) == DocIdSetIterator.NO_MORE_DOCS);\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3e45d45bc3730ddd1341f4eb6025f33b8482e6e2","date":1346834651,"type":5,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/codecs/src/test/org/apache/lucene/codecs/appending/TestAppendingCodec#testCodec().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/codecs/appending/TestAppendingCodec#testCodec().mjava","sourceNew":"  public void testCodec() throws Exception {\n    Directory dir = new AppendingRAMDirectory(random(), new RAMDirectory());\n    IndexWriterConfig cfg = new IndexWriterConfig(Version.LUCENE_40, new MockAnalyzer(random()));\n    \n    cfg.setCodec(new AppendingCodec());\n    ((TieredMergePolicy)cfg.getMergePolicy()).setUseCompoundFile(false);\n    IndexWriter writer = new IndexWriter(dir, cfg);\n    Document doc = new Document();\n    FieldType storedTextType = new FieldType(TextField.TYPE_STORED);\n    storedTextType.setStoreTermVectors(true);\n    storedTextType.setStoreTermVectorPositions(true);\n    storedTextType.setStoreTermVectorOffsets(true);\n    doc.add(newField(\"f\", text, storedTextType));\n    writer.addDocument(doc);\n    writer.commit();\n    writer.addDocument(doc);\n    writer.forceMerge(1);\n    writer.close();\n    IndexReader reader = DirectoryReader.open(dir, 1);\n    assertEquals(2, reader.numDocs());\n    StoredDocument doc2 = reader.document(0);\n    assertEquals(text, doc2.get(\"f\"));\n    Fields fields = MultiFields.getFields(reader);\n    Terms terms = fields.terms(\"f\");\n    assertNotNull(terms);\n    TermsEnum te = terms.iterator(null);\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"quick\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"brown\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"fox\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"jumped\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"over\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"lazy\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"dog\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"the\")));\n    DocsEnum de = te.docs(null, null);\n    assertTrue(de.advance(0) != DocIdSetIterator.NO_MORE_DOCS);\n    assertEquals(2, de.freq());\n    assertTrue(de.advance(1) != DocIdSetIterator.NO_MORE_DOCS);\n    assertTrue(de.advance(2) == DocIdSetIterator.NO_MORE_DOCS);\n    reader.close();\n  }\n\n","sourceOld":"  public void testCodec() throws Exception {\n    Directory dir = new AppendingRAMDirectory(random(), new RAMDirectory());\n    IndexWriterConfig cfg = new IndexWriterConfig(Version.LUCENE_40, new MockAnalyzer(random()));\n    \n    cfg.setCodec(new AppendingCodec());\n    ((TieredMergePolicy)cfg.getMergePolicy()).setUseCompoundFile(false);\n    IndexWriter writer = new IndexWriter(dir, cfg);\n    Document doc = new Document();\n    FieldType storedTextType = new FieldType(TextField.TYPE_STORED);\n    storedTextType.setStoreTermVectors(true);\n    storedTextType.setStoreTermVectorPositions(true);\n    storedTextType.setStoreTermVectorOffsets(true);\n    doc.add(newField(\"f\", text, storedTextType));\n    writer.addDocument(doc);\n    writer.commit();\n    writer.addDocument(doc);\n    writer.forceMerge(1);\n    writer.close();\n    IndexReader reader = DirectoryReader.open(dir, 1);\n    assertEquals(2, reader.numDocs());\n    StoredDocument doc2 = reader.document(0);\n    assertEquals(text, doc2.get(\"f\"));\n    Fields fields = MultiFields.getFields(reader);\n    Terms terms = fields.terms(\"f\");\n    assertNotNull(terms);\n    TermsEnum te = terms.iterator(null);\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"quick\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"brown\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"fox\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"jumped\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"over\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"lazy\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"dog\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"the\")));\n    DocsEnum de = te.docs(null, null);\n    assertTrue(de.advance(0) != DocIdSetIterator.NO_MORE_DOCS);\n    assertEquals(2, de.freq());\n    assertTrue(de.advance(1) != DocIdSetIterator.NO_MORE_DOCS);\n    assertTrue(de.advance(2) == DocIdSetIterator.NO_MORE_DOCS);\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"8f0e28f2a7f0f3f0fca1a2ffedaa10c7ac9536c4":["e7e8d6f15900ee22ac3cb0a503f15dc952a3580f"],"9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab":["3a119bbc8703c10faa329ec201c654b3a35a1e3e","f08557cdb6c60ac7b88a9342c983a20cd236e74f"],"3e45d45bc3730ddd1341f4eb6025f33b8482e6e2":["1d028314cced5858683a1bb4741423d0f934257b"],"f08557cdb6c60ac7b88a9342c983a20cd236e74f":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"d08eba3d52b63561ebf936481ce73e6b6a14aa03":["f08557cdb6c60ac7b88a9342c983a20cd236e74f"],"1d028314cced5858683a1bb4741423d0f934257b":["02331260bb246364779cb6f04919ca47900d01bb","d6f074e73200c07d54f242d3880a8da5a35ff97b"],"e7e8d6f15900ee22ac3cb0a503f15dc952a3580f":["629c38c4ae4e303d0617e05fbfe508140b32f0a3"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f":["e7e8d6f15900ee22ac3cb0a503f15dc952a3580f","02331260bb246364779cb6f04919ca47900d01bb"],"e3f8ac3877ad6d160de0fd3a6f7155b243dfbddf":["d08eba3d52b63561ebf936481ce73e6b6a14aa03"],"d6f074e73200c07d54f242d3880a8da5a35ff97b":["8f0e28f2a7f0f3f0fca1a2ffedaa10c7ac9536c4","02331260bb246364779cb6f04919ca47900d01bb"],"629c38c4ae4e303d0617e05fbfe508140b32f0a3":["e3f8ac3877ad6d160de0fd3a6f7155b243dfbddf"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["3e45d45bc3730ddd1341f4eb6025f33b8482e6e2"],"02331260bb246364779cb6f04919ca47900d01bb":["e7e8d6f15900ee22ac3cb0a503f15dc952a3580f"]},"commit2Childs":{"8f0e28f2a7f0f3f0fca1a2ffedaa10c7ac9536c4":["d6f074e73200c07d54f242d3880a8da5a35ff97b"],"9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab":[],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab","f08557cdb6c60ac7b88a9342c983a20cd236e74f"],"f08557cdb6c60ac7b88a9342c983a20cd236e74f":["9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab","d08eba3d52b63561ebf936481ce73e6b6a14aa03"],"3e45d45bc3730ddd1341f4eb6025f33b8482e6e2":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"d08eba3d52b63561ebf936481ce73e6b6a14aa03":["e3f8ac3877ad6d160de0fd3a6f7155b243dfbddf"],"1d028314cced5858683a1bb4741423d0f934257b":["3e45d45bc3730ddd1341f4eb6025f33b8482e6e2"],"e7e8d6f15900ee22ac3cb0a503f15dc952a3580f":["8f0e28f2a7f0f3f0fca1a2ffedaa10c7ac9536c4","b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f","02331260bb246364779cb6f04919ca47900d01bb"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f":[],"d6f074e73200c07d54f242d3880a8da5a35ff97b":["1d028314cced5858683a1bb4741423d0f934257b"],"e3f8ac3877ad6d160de0fd3a6f7155b243dfbddf":["629c38c4ae4e303d0617e05fbfe508140b32f0a3"],"629c38c4ae4e303d0617e05fbfe508140b32f0a3":["e7e8d6f15900ee22ac3cb0a503f15dc952a3580f"],"02331260bb246364779cb6f04919ca47900d01bb":["1d028314cced5858683a1bb4741423d0f934257b","b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f","d6f074e73200c07d54f242d3880a8da5a35ff97b"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab","b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}