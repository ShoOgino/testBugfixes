{"path":"lucene/core/src/test/org/apache/lucene/codecs/lucene70/TestLucene70DocValuesFormat#testSortedNumericAroundBlockSize().mjava","commits":[{"id":"084884d4602f4d1c7411eab29e897e349ce62675","date":1475571034,"type":0,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/lucene70/TestLucene70DocValuesFormat#testSortedNumericAroundBlockSize().mjava","pathOld":"/dev/null","sourceNew":"  @Slow\n  public void testSortedNumericAroundBlockSize() throws IOException {\n    final int frontier = 1 << Lucene70DocValuesFormat.DIRECT_MONOTONIC_BLOCK_SHIFT;\n    for (int maxDoc = frontier - 1; maxDoc <= frontier + 1; ++maxDoc) {\n      final Directory dir = newDirectory();\n      IndexWriter w = new IndexWriter(dir, newIndexWriterConfig().setMergePolicy(newLogMergePolicy()));\n      RAMFile buffer = new RAMFile();\n      RAMOutputStream out = new RAMOutputStream(buffer, false);\n      Document doc = new Document();\n      SortedNumericDocValuesField field1 = new SortedNumericDocValuesField(\"snum\", 0L);\n      doc.add(field1);\n      SortedNumericDocValuesField field2 = new SortedNumericDocValuesField(\"snum\", 0L);\n      doc.add(field2);\n      for (int i = 0; i < maxDoc; ++i) {\n        long s1 = random().nextInt(100);\n        long s2 = random().nextInt(100);\n        field1.setLongValue(s1);\n        field2.setLongValue(s2);\n        w.addDocument(doc);\n        out.writeVLong(Math.min(s1, s2));\n        out.writeVLong(Math.max(s1, s2));\n      }\n      out.close();\n      w.forceMerge(1);\n      DirectoryReader r = DirectoryReader.open(w);\n      w.close();\n      LeafReader sr = getOnlyLeafReader(r);\n      assertEquals(maxDoc, sr.maxDoc());\n      SortedNumericDocValues values = sr.getSortedNumericDocValues(\"snum\");\n      assertNotNull(values);\n      RAMInputStream in = new RAMInputStream(\"\", buffer);\n      for (int i = 0; i < maxDoc; ++i) {\n        assertEquals(i, values.nextDoc());\n        assertEquals(2, values.docValueCount());\n        assertEquals(in.readVLong(), values.nextValue());\n        assertEquals(in.readVLong(), values.nextValue());\n      }\n      r.close();\n      dir.close();\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1967bed916cc89da82a1c2085f27976da6d08cbd","date":1475588750,"type":0,"author":"Noble Paul","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/lucene70/TestLucene70DocValuesFormat#testSortedNumericAroundBlockSize().mjava","pathOld":"/dev/null","sourceNew":"  @Slow\n  public void testSortedNumericAroundBlockSize() throws IOException {\n    final int frontier = 1 << Lucene70DocValuesFormat.DIRECT_MONOTONIC_BLOCK_SHIFT;\n    for (int maxDoc = frontier - 1; maxDoc <= frontier + 1; ++maxDoc) {\n      final Directory dir = newDirectory();\n      IndexWriter w = new IndexWriter(dir, newIndexWriterConfig().setMergePolicy(newLogMergePolicy()));\n      RAMFile buffer = new RAMFile();\n      RAMOutputStream out = new RAMOutputStream(buffer, false);\n      Document doc = new Document();\n      SortedNumericDocValuesField field1 = new SortedNumericDocValuesField(\"snum\", 0L);\n      doc.add(field1);\n      SortedNumericDocValuesField field2 = new SortedNumericDocValuesField(\"snum\", 0L);\n      doc.add(field2);\n      for (int i = 0; i < maxDoc; ++i) {\n        long s1 = random().nextInt(100);\n        long s2 = random().nextInt(100);\n        field1.setLongValue(s1);\n        field2.setLongValue(s2);\n        w.addDocument(doc);\n        out.writeVLong(Math.min(s1, s2));\n        out.writeVLong(Math.max(s1, s2));\n      }\n      out.close();\n      w.forceMerge(1);\n      DirectoryReader r = DirectoryReader.open(w);\n      w.close();\n      LeafReader sr = getOnlyLeafReader(r);\n      assertEquals(maxDoc, sr.maxDoc());\n      SortedNumericDocValues values = sr.getSortedNumericDocValues(\"snum\");\n      assertNotNull(values);\n      RAMInputStream in = new RAMInputStream(\"\", buffer);\n      for (int i = 0; i < maxDoc; ++i) {\n        assertEquals(i, values.nextDoc());\n        assertEquals(2, values.docValueCount());\n        assertEquals(in.readVLong(), values.nextValue());\n        assertEquals(in.readVLong(), values.nextValue());\n      }\n      r.close();\n      dir.close();\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4cce5816ef15a48a0bc11e5d400497ee4301dd3b","date":1476991456,"type":0,"author":"Kevin Risden","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/lucene70/TestLucene70DocValuesFormat#testSortedNumericAroundBlockSize().mjava","pathOld":"/dev/null","sourceNew":"  @Slow\n  public void testSortedNumericAroundBlockSize() throws IOException {\n    final int frontier = 1 << Lucene70DocValuesFormat.DIRECT_MONOTONIC_BLOCK_SHIFT;\n    for (int maxDoc = frontier - 1; maxDoc <= frontier + 1; ++maxDoc) {\n      final Directory dir = newDirectory();\n      IndexWriter w = new IndexWriter(dir, newIndexWriterConfig().setMergePolicy(newLogMergePolicy()));\n      RAMFile buffer = new RAMFile();\n      RAMOutputStream out = new RAMOutputStream(buffer, false);\n      Document doc = new Document();\n      SortedNumericDocValuesField field1 = new SortedNumericDocValuesField(\"snum\", 0L);\n      doc.add(field1);\n      SortedNumericDocValuesField field2 = new SortedNumericDocValuesField(\"snum\", 0L);\n      doc.add(field2);\n      for (int i = 0; i < maxDoc; ++i) {\n        long s1 = random().nextInt(100);\n        long s2 = random().nextInt(100);\n        field1.setLongValue(s1);\n        field2.setLongValue(s2);\n        w.addDocument(doc);\n        out.writeVLong(Math.min(s1, s2));\n        out.writeVLong(Math.max(s1, s2));\n      }\n      out.close();\n      w.forceMerge(1);\n      DirectoryReader r = DirectoryReader.open(w);\n      w.close();\n      LeafReader sr = getOnlyLeafReader(r);\n      assertEquals(maxDoc, sr.maxDoc());\n      SortedNumericDocValues values = sr.getSortedNumericDocValues(\"snum\");\n      assertNotNull(values);\n      RAMInputStream in = new RAMInputStream(\"\", buffer);\n      for (int i = 0; i < maxDoc; ++i) {\n        assertEquals(i, values.nextDoc());\n        assertEquals(2, values.docValueCount());\n        assertEquals(in.readVLong(), values.nextValue());\n        assertEquals(in.readVLong(), values.nextValue());\n      }\n      r.close();\n      dir.close();\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"409da428f28953cf35fddd5c9ff5c7e4f5439863","date":1547556145,"type":3,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/codecs/lucene70/TestLucene70DocValuesFormat#testSortedNumericAroundBlockSize().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/codecs/lucene70/TestLucene70DocValuesFormat#testSortedNumericAroundBlockSize().mjava","sourceNew":"  @Slow\n  public void testSortedNumericAroundBlockSize() throws IOException {\n    final int frontier = 1 << Lucene70DocValuesFormat.DIRECT_MONOTONIC_BLOCK_SHIFT;\n    for (int maxDoc = frontier - 1; maxDoc <= frontier + 1; ++maxDoc) {\n      final Directory dir = newDirectory();\n      IndexWriter w = new IndexWriter(dir, newIndexWriterConfig().setMergePolicy(newLogMergePolicy()));\n      ByteBuffersDataOutput buffer = new ByteBuffersDataOutput();\n\n      Document doc = new Document();\n      SortedNumericDocValuesField field1 = new SortedNumericDocValuesField(\"snum\", 0L);\n      doc.add(field1);\n      SortedNumericDocValuesField field2 = new SortedNumericDocValuesField(\"snum\", 0L);\n      doc.add(field2);\n      for (int i = 0; i < maxDoc; ++i) {\n        long s1 = random().nextInt(100);\n        long s2 = random().nextInt(100);\n        field1.setLongValue(s1);\n        field2.setLongValue(s2);\n        w.addDocument(doc);\n        buffer.writeVLong(Math.min(s1, s2));\n        buffer.writeVLong(Math.max(s1, s2));\n      }\n\n      w.forceMerge(1);\n      DirectoryReader r = DirectoryReader.open(w);\n      w.close();\n      LeafReader sr = getOnlyLeafReader(r);\n      assertEquals(maxDoc, sr.maxDoc());\n      SortedNumericDocValues values = sr.getSortedNumericDocValues(\"snum\");\n      assertNotNull(values);\n      ByteBuffersDataInput dataInput = buffer.toDataInput();\n      for (int i = 0; i < maxDoc; ++i) {\n        assertEquals(i, values.nextDoc());\n        assertEquals(2, values.docValueCount());\n        assertEquals(dataInput.readVLong(), values.nextValue());\n        assertEquals(dataInput.readVLong(), values.nextValue());\n      }\n      r.close();\n      dir.close();\n    }\n  }\n\n","sourceOld":"  @Slow\n  public void testSortedNumericAroundBlockSize() throws IOException {\n    final int frontier = 1 << Lucene70DocValuesFormat.DIRECT_MONOTONIC_BLOCK_SHIFT;\n    for (int maxDoc = frontier - 1; maxDoc <= frontier + 1; ++maxDoc) {\n      final Directory dir = newDirectory();\n      IndexWriter w = new IndexWriter(dir, newIndexWriterConfig().setMergePolicy(newLogMergePolicy()));\n      RAMFile buffer = new RAMFile();\n      RAMOutputStream out = new RAMOutputStream(buffer, false);\n      Document doc = new Document();\n      SortedNumericDocValuesField field1 = new SortedNumericDocValuesField(\"snum\", 0L);\n      doc.add(field1);\n      SortedNumericDocValuesField field2 = new SortedNumericDocValuesField(\"snum\", 0L);\n      doc.add(field2);\n      for (int i = 0; i < maxDoc; ++i) {\n        long s1 = random().nextInt(100);\n        long s2 = random().nextInt(100);\n        field1.setLongValue(s1);\n        field2.setLongValue(s2);\n        w.addDocument(doc);\n        out.writeVLong(Math.min(s1, s2));\n        out.writeVLong(Math.max(s1, s2));\n      }\n      out.close();\n      w.forceMerge(1);\n      DirectoryReader r = DirectoryReader.open(w);\n      w.close();\n      LeafReader sr = getOnlyLeafReader(r);\n      assertEquals(maxDoc, sr.maxDoc());\n      SortedNumericDocValues values = sr.getSortedNumericDocValues(\"snum\");\n      assertNotNull(values);\n      RAMInputStream in = new RAMInputStream(\"\", buffer);\n      for (int i = 0; i < maxDoc; ++i) {\n        assertEquals(i, values.nextDoc());\n        assertEquals(2, values.docValueCount());\n        assertEquals(in.readVLong(), values.nextValue());\n        assertEquals(in.readVLong(), values.nextValue());\n      }\n      r.close();\n      dir.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"03e17b020972a0d6e8d6823f545571a66646a167","date":1547847724,"type":5,"author":"Toke Eskildsen","isMerge":false,"pathNew":"lucene/backward-codecs/src/test/org/apache/lucene/codecs/lucene70/TestLucene70DocValuesFormat#testSortedNumericAroundBlockSize().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/codecs/lucene70/TestLucene70DocValuesFormat#testSortedNumericAroundBlockSize().mjava","sourceNew":"  @Slow\n  public void testSortedNumericAroundBlockSize() throws IOException {\n    final int frontier = 1 << Lucene70DocValuesFormat.DIRECT_MONOTONIC_BLOCK_SHIFT;\n    for (int maxDoc = frontier - 1; maxDoc <= frontier + 1; ++maxDoc) {\n      final Directory dir = newDirectory();\n      IndexWriter w = new IndexWriter(dir, newIndexWriterConfig().setMergePolicy(newLogMergePolicy()));\n      ByteBuffersDataOutput buffer = new ByteBuffersDataOutput();\n\n      Document doc = new Document();\n      SortedNumericDocValuesField field1 = new SortedNumericDocValuesField(\"snum\", 0L);\n      doc.add(field1);\n      SortedNumericDocValuesField field2 = new SortedNumericDocValuesField(\"snum\", 0L);\n      doc.add(field2);\n      for (int i = 0; i < maxDoc; ++i) {\n        long s1 = random().nextInt(100);\n        long s2 = random().nextInt(100);\n        field1.setLongValue(s1);\n        field2.setLongValue(s2);\n        w.addDocument(doc);\n        buffer.writeVLong(Math.min(s1, s2));\n        buffer.writeVLong(Math.max(s1, s2));\n      }\n\n      w.forceMerge(1);\n      DirectoryReader r = DirectoryReader.open(w);\n      w.close();\n      LeafReader sr = getOnlyLeafReader(r);\n      assertEquals(maxDoc, sr.maxDoc());\n      SortedNumericDocValues values = sr.getSortedNumericDocValues(\"snum\");\n      assertNotNull(values);\n      ByteBuffersDataInput dataInput = buffer.toDataInput();\n      for (int i = 0; i < maxDoc; ++i) {\n        assertEquals(i, values.nextDoc());\n        assertEquals(2, values.docValueCount());\n        assertEquals(dataInput.readVLong(), values.nextValue());\n        assertEquals(dataInput.readVLong(), values.nextValue());\n      }\n      r.close();\n      dir.close();\n    }\n  }\n\n","sourceOld":"  @Slow\n  public void testSortedNumericAroundBlockSize() throws IOException {\n    final int frontier = 1 << Lucene70DocValuesFormat.DIRECT_MONOTONIC_BLOCK_SHIFT;\n    for (int maxDoc = frontier - 1; maxDoc <= frontier + 1; ++maxDoc) {\n      final Directory dir = newDirectory();\n      IndexWriter w = new IndexWriter(dir, newIndexWriterConfig().setMergePolicy(newLogMergePolicy()));\n      ByteBuffersDataOutput buffer = new ByteBuffersDataOutput();\n\n      Document doc = new Document();\n      SortedNumericDocValuesField field1 = new SortedNumericDocValuesField(\"snum\", 0L);\n      doc.add(field1);\n      SortedNumericDocValuesField field2 = new SortedNumericDocValuesField(\"snum\", 0L);\n      doc.add(field2);\n      for (int i = 0; i < maxDoc; ++i) {\n        long s1 = random().nextInt(100);\n        long s2 = random().nextInt(100);\n        field1.setLongValue(s1);\n        field2.setLongValue(s2);\n        w.addDocument(doc);\n        buffer.writeVLong(Math.min(s1, s2));\n        buffer.writeVLong(Math.max(s1, s2));\n      }\n\n      w.forceMerge(1);\n      DirectoryReader r = DirectoryReader.open(w);\n      w.close();\n      LeafReader sr = getOnlyLeafReader(r);\n      assertEquals(maxDoc, sr.maxDoc());\n      SortedNumericDocValues values = sr.getSortedNumericDocValues(\"snum\");\n      assertNotNull(values);\n      ByteBuffersDataInput dataInput = buffer.toDataInput();\n      for (int i = 0; i < maxDoc; ++i) {\n        assertEquals(i, values.nextDoc());\n        assertEquals(2, values.docValueCount());\n        assertEquals(dataInput.readVLong(), values.nextValue());\n        assertEquals(dataInput.readVLong(), values.nextValue());\n      }\n      r.close();\n      dir.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c89f1ef80a9432f4eabaeda9a1e135cd72e60836","date":1547972642,"type":5,"author":"Tommaso Teofili","isMerge":true,"pathNew":"lucene/backward-codecs/src/test/org/apache/lucene/codecs/lucene70/TestLucene70DocValuesFormat#testSortedNumericAroundBlockSize().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/codecs/lucene70/TestLucene70DocValuesFormat#testSortedNumericAroundBlockSize().mjava","sourceNew":"  @Slow\n  public void testSortedNumericAroundBlockSize() throws IOException {\n    final int frontier = 1 << Lucene70DocValuesFormat.DIRECT_MONOTONIC_BLOCK_SHIFT;\n    for (int maxDoc = frontier - 1; maxDoc <= frontier + 1; ++maxDoc) {\n      final Directory dir = newDirectory();\n      IndexWriter w = new IndexWriter(dir, newIndexWriterConfig().setMergePolicy(newLogMergePolicy()));\n      ByteBuffersDataOutput buffer = new ByteBuffersDataOutput();\n\n      Document doc = new Document();\n      SortedNumericDocValuesField field1 = new SortedNumericDocValuesField(\"snum\", 0L);\n      doc.add(field1);\n      SortedNumericDocValuesField field2 = new SortedNumericDocValuesField(\"snum\", 0L);\n      doc.add(field2);\n      for (int i = 0; i < maxDoc; ++i) {\n        long s1 = random().nextInt(100);\n        long s2 = random().nextInt(100);\n        field1.setLongValue(s1);\n        field2.setLongValue(s2);\n        w.addDocument(doc);\n        buffer.writeVLong(Math.min(s1, s2));\n        buffer.writeVLong(Math.max(s1, s2));\n      }\n\n      w.forceMerge(1);\n      DirectoryReader r = DirectoryReader.open(w);\n      w.close();\n      LeafReader sr = getOnlyLeafReader(r);\n      assertEquals(maxDoc, sr.maxDoc());\n      SortedNumericDocValues values = sr.getSortedNumericDocValues(\"snum\");\n      assertNotNull(values);\n      ByteBuffersDataInput dataInput = buffer.toDataInput();\n      for (int i = 0; i < maxDoc; ++i) {\n        assertEquals(i, values.nextDoc());\n        assertEquals(2, values.docValueCount());\n        assertEquals(dataInput.readVLong(), values.nextValue());\n        assertEquals(dataInput.readVLong(), values.nextValue());\n      }\n      r.close();\n      dir.close();\n    }\n  }\n\n","sourceOld":"  @Slow\n  public void testSortedNumericAroundBlockSize() throws IOException {\n    final int frontier = 1 << Lucene70DocValuesFormat.DIRECT_MONOTONIC_BLOCK_SHIFT;\n    for (int maxDoc = frontier - 1; maxDoc <= frontier + 1; ++maxDoc) {\n      final Directory dir = newDirectory();\n      IndexWriter w = new IndexWriter(dir, newIndexWriterConfig().setMergePolicy(newLogMergePolicy()));\n      ByteBuffersDataOutput buffer = new ByteBuffersDataOutput();\n\n      Document doc = new Document();\n      SortedNumericDocValuesField field1 = new SortedNumericDocValuesField(\"snum\", 0L);\n      doc.add(field1);\n      SortedNumericDocValuesField field2 = new SortedNumericDocValuesField(\"snum\", 0L);\n      doc.add(field2);\n      for (int i = 0; i < maxDoc; ++i) {\n        long s1 = random().nextInt(100);\n        long s2 = random().nextInt(100);\n        field1.setLongValue(s1);\n        field2.setLongValue(s2);\n        w.addDocument(doc);\n        buffer.writeVLong(Math.min(s1, s2));\n        buffer.writeVLong(Math.max(s1, s2));\n      }\n\n      w.forceMerge(1);\n      DirectoryReader r = DirectoryReader.open(w);\n      w.close();\n      LeafReader sr = getOnlyLeafReader(r);\n      assertEquals(maxDoc, sr.maxDoc());\n      SortedNumericDocValues values = sr.getSortedNumericDocValues(\"snum\");\n      assertNotNull(values);\n      ByteBuffersDataInput dataInput = buffer.toDataInput();\n      for (int i = 0; i < maxDoc; ++i) {\n        assertEquals(i, values.nextDoc());\n        assertEquals(2, values.docValueCount());\n        assertEquals(dataInput.readVLong(), values.nextValue());\n        assertEquals(dataInput.readVLong(), values.nextValue());\n      }\n      r.close();\n      dir.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"03e17b020972a0d6e8d6823f545571a66646a167":["409da428f28953cf35fddd5c9ff5c7e4f5439863"],"409da428f28953cf35fddd5c9ff5c7e4f5439863":["1967bed916cc89da82a1c2085f27976da6d08cbd"],"c89f1ef80a9432f4eabaeda9a1e135cd72e60836":["409da428f28953cf35fddd5c9ff5c7e4f5439863","03e17b020972a0d6e8d6823f545571a66646a167"],"1967bed916cc89da82a1c2085f27976da6d08cbd":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","084884d4602f4d1c7411eab29e897e349ce62675"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","1967bed916cc89da82a1c2085f27976da6d08cbd"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["03e17b020972a0d6e8d6823f545571a66646a167"],"084884d4602f4d1c7411eab29e897e349ce62675":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"03e17b020972a0d6e8d6823f545571a66646a167":["c89f1ef80a9432f4eabaeda9a1e135cd72e60836","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"409da428f28953cf35fddd5c9ff5c7e4f5439863":["03e17b020972a0d6e8d6823f545571a66646a167","c89f1ef80a9432f4eabaeda9a1e135cd72e60836"],"c89f1ef80a9432f4eabaeda9a1e135cd72e60836":[],"1967bed916cc89da82a1c2085f27976da6d08cbd":["409da428f28953cf35fddd5c9ff5c7e4f5439863","4cce5816ef15a48a0bc11e5d400497ee4301dd3b"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["1967bed916cc89da82a1c2085f27976da6d08cbd","4cce5816ef15a48a0bc11e5d400497ee4301dd3b","084884d4602f4d1c7411eab29e897e349ce62675"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":[],"084884d4602f4d1c7411eab29e897e349ce62675":["1967bed916cc89da82a1c2085f27976da6d08cbd"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["c89f1ef80a9432f4eabaeda9a1e135cd72e60836","4cce5816ef15a48a0bc11e5d400497ee4301dd3b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}