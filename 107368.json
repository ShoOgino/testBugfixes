{"path":"lucene/core/src/test/org/apache/lucene/index/TestDirectoryReader#testMultiTermDocs().mjava","commits":[{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":1,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDirectoryReader#testMultiTermDocs().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestDirectoryReader#testMultiTermDocs().mjava","sourceNew":"  public void testMultiTermDocs() throws IOException {\n    Directory ramDir1=newDirectory();\n    addDoc(random, ramDir1, \"test foo\", true);\n    Directory ramDir2=newDirectory();\n    addDoc(random, ramDir2, \"test blah\", true);\n    Directory ramDir3=newDirectory();\n    addDoc(random, ramDir3, \"test wow\", true);\n\n    IndexReader[] readers1 = new IndexReader[]{IndexReader.open(ramDir1), IndexReader.open(ramDir3)};\n    IndexReader[] readers2 = new IndexReader[]{IndexReader.open(ramDir1), IndexReader.open(ramDir2), IndexReader.open(ramDir3)};\n    MultiReader mr2 = new MultiReader(readers1);\n    MultiReader mr3 = new MultiReader(readers2);\n\n    // test mixing up TermDocs and TermEnums from different readers.\n    TermsEnum te2 = MultiFields.getTerms(mr2, \"body\").iterator(null);\n    te2.seekCeil(new BytesRef(\"wow\"));\n    DocsEnum td = _TestUtil.docs(random, mr2,\n                                 \"body\",\n                                 te2.term(),\n                                 MultiFields.getLiveDocs(mr2),\n                                 null,\n                                 false);\n\n    TermsEnum te3 = MultiFields.getTerms(mr3, \"body\").iterator(null);\n    te3.seekCeil(new BytesRef(\"wow\"));\n    td = _TestUtil.docs(random, te3, MultiFields.getLiveDocs(mr3),\n                        td,\n                        false);\n    \n    int ret = 0;\n\n    // This should blow up if we forget to check that the TermEnum is from the same\n    // reader as the TermDocs.\n    while (td.nextDoc() != td.NO_MORE_DOCS) ret += td.docID();\n\n    // really a dummy assert to ensure that we got some docs and to ensure that\n    // nothing is eliminated by hotspot\n    assertTrue(ret > 0);\n    readers1[0].close();\n    readers1[1].close();\n    readers2[0].close();\n    readers2[1].close();\n    readers2[2].close();\n    ramDir1.close();\n    ramDir2.close();\n    ramDir3.close();\n  }\n\n","sourceOld":"  public void testMultiTermDocs() throws IOException {\n    Directory ramDir1=newDirectory();\n    addDoc(random, ramDir1, \"test foo\", true);\n    Directory ramDir2=newDirectory();\n    addDoc(random, ramDir2, \"test blah\", true);\n    Directory ramDir3=newDirectory();\n    addDoc(random, ramDir3, \"test wow\", true);\n\n    IndexReader[] readers1 = new IndexReader[]{IndexReader.open(ramDir1), IndexReader.open(ramDir3)};\n    IndexReader[] readers2 = new IndexReader[]{IndexReader.open(ramDir1), IndexReader.open(ramDir2), IndexReader.open(ramDir3)};\n    MultiReader mr2 = new MultiReader(readers1);\n    MultiReader mr3 = new MultiReader(readers2);\n\n    // test mixing up TermDocs and TermEnums from different readers.\n    TermsEnum te2 = MultiFields.getTerms(mr2, \"body\").iterator(null);\n    te2.seekCeil(new BytesRef(\"wow\"));\n    DocsEnum td = _TestUtil.docs(random, mr2,\n                                 \"body\",\n                                 te2.term(),\n                                 MultiFields.getLiveDocs(mr2),\n                                 null,\n                                 false);\n\n    TermsEnum te3 = MultiFields.getTerms(mr3, \"body\").iterator(null);\n    te3.seekCeil(new BytesRef(\"wow\"));\n    td = _TestUtil.docs(random, te3, MultiFields.getLiveDocs(mr3),\n                        td,\n                        false);\n    \n    int ret = 0;\n\n    // This should blow up if we forget to check that the TermEnum is from the same\n    // reader as the TermDocs.\n    while (td.nextDoc() != td.NO_MORE_DOCS) ret += td.docID();\n\n    // really a dummy assert to ensure that we got some docs and to ensure that\n    // nothing is eliminated by hotspot\n    assertTrue(ret > 0);\n    readers1[0].close();\n    readers1[1].close();\n    readers2[0].close();\n    readers2[1].close();\n    readers2[2].close();\n    ramDir1.close();\n    ramDir2.close();\n    ramDir3.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"83e99d44c4a660a48c0fcc7a0108ad0a56dc2f87","date":1328967626,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDirectoryReader#testMultiTermDocs().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDirectoryReader#testMultiTermDocs().mjava","sourceNew":"  public void testMultiTermDocs() throws IOException {\n    Directory ramDir1=newDirectory();\n    addDoc(random, ramDir1, \"test foo\", true);\n    Directory ramDir2=newDirectory();\n    addDoc(random, ramDir2, \"test blah\", true);\n    Directory ramDir3=newDirectory();\n    addDoc(random, ramDir3, \"test wow\", true);\n\n    IndexReader[] readers1 = new IndexReader[]{DirectoryReader.open(ramDir1), DirectoryReader.open(ramDir3)};\n    IndexReader[] readers2 = new IndexReader[]{DirectoryReader.open(ramDir1), DirectoryReader.open(ramDir2), DirectoryReader.open(ramDir3)};\n    MultiReader mr2 = new MultiReader(readers1);\n    MultiReader mr3 = new MultiReader(readers2);\n\n    // test mixing up TermDocs and TermEnums from different readers.\n    TermsEnum te2 = MultiFields.getTerms(mr2, \"body\").iterator(null);\n    te2.seekCeil(new BytesRef(\"wow\"));\n    DocsEnum td = _TestUtil.docs(random, mr2,\n                                 \"body\",\n                                 te2.term(),\n                                 MultiFields.getLiveDocs(mr2),\n                                 null,\n                                 false);\n\n    TermsEnum te3 = MultiFields.getTerms(mr3, \"body\").iterator(null);\n    te3.seekCeil(new BytesRef(\"wow\"));\n    td = _TestUtil.docs(random, te3, MultiFields.getLiveDocs(mr3),\n                        td,\n                        false);\n    \n    int ret = 0;\n\n    // This should blow up if we forget to check that the TermEnum is from the same\n    // reader as the TermDocs.\n    while (td.nextDoc() != td.NO_MORE_DOCS) ret += td.docID();\n\n    // really a dummy assert to ensure that we got some docs and to ensure that\n    // nothing is eliminated by hotspot\n    assertTrue(ret > 0);\n    readers1[0].close();\n    readers1[1].close();\n    readers2[0].close();\n    readers2[1].close();\n    readers2[2].close();\n    ramDir1.close();\n    ramDir2.close();\n    ramDir3.close();\n  }\n\n","sourceOld":"  public void testMultiTermDocs() throws IOException {\n    Directory ramDir1=newDirectory();\n    addDoc(random, ramDir1, \"test foo\", true);\n    Directory ramDir2=newDirectory();\n    addDoc(random, ramDir2, \"test blah\", true);\n    Directory ramDir3=newDirectory();\n    addDoc(random, ramDir3, \"test wow\", true);\n\n    IndexReader[] readers1 = new IndexReader[]{IndexReader.open(ramDir1), IndexReader.open(ramDir3)};\n    IndexReader[] readers2 = new IndexReader[]{IndexReader.open(ramDir1), IndexReader.open(ramDir2), IndexReader.open(ramDir3)};\n    MultiReader mr2 = new MultiReader(readers1);\n    MultiReader mr3 = new MultiReader(readers2);\n\n    // test mixing up TermDocs and TermEnums from different readers.\n    TermsEnum te2 = MultiFields.getTerms(mr2, \"body\").iterator(null);\n    te2.seekCeil(new BytesRef(\"wow\"));\n    DocsEnum td = _TestUtil.docs(random, mr2,\n                                 \"body\",\n                                 te2.term(),\n                                 MultiFields.getLiveDocs(mr2),\n                                 null,\n                                 false);\n\n    TermsEnum te3 = MultiFields.getTerms(mr3, \"body\").iterator(null);\n    te3.seekCeil(new BytesRef(\"wow\"));\n    td = _TestUtil.docs(random, te3, MultiFields.getLiveDocs(mr3),\n                        td,\n                        false);\n    \n    int ret = 0;\n\n    // This should blow up if we forget to check that the TermEnum is from the same\n    // reader as the TermDocs.\n    while (td.nextDoc() != td.NO_MORE_DOCS) ret += td.docID();\n\n    // really a dummy assert to ensure that we got some docs and to ensure that\n    // nothing is eliminated by hotspot\n    assertTrue(ret > 0);\n    readers1[0].close();\n    readers1[1].close();\n    readers2[0].close();\n    readers2[1].close();\n    readers2[2].close();\n    ramDir1.close();\n    ramDir2.close();\n    ramDir3.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"f08557cdb6c60ac7b88a9342c983a20cd236e74f","date":1330954480,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDirectoryReader#testMultiTermDocs().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDirectoryReader#testMultiTermDocs().mjava","sourceNew":"  public void testMultiTermDocs() throws IOException {\n    Directory ramDir1=newDirectory();\n    addDoc(random, ramDir1, \"test foo\", true);\n    Directory ramDir2=newDirectory();\n    addDoc(random, ramDir2, \"test blah\", true);\n    Directory ramDir3=newDirectory();\n    addDoc(random, ramDir3, \"test wow\", true);\n\n    IndexReader[] readers1 = new IndexReader[]{DirectoryReader.open(ramDir1), DirectoryReader.open(ramDir3)};\n    IndexReader[] readers2 = new IndexReader[]{DirectoryReader.open(ramDir1), DirectoryReader.open(ramDir2), DirectoryReader.open(ramDir3)};\n    MultiReader mr2 = new MultiReader(readers1);\n    MultiReader mr3 = new MultiReader(readers2);\n\n    // test mixing up TermDocs and TermEnums from different readers.\n    TermsEnum te2 = MultiFields.getTerms(mr2, \"body\").iterator(null);\n    te2.seekCeil(new BytesRef(\"wow\"));\n    DocsEnum td = _TestUtil.docs(random, mr2,\n                                 \"body\",\n                                 te2.term(),\n                                 MultiFields.getLiveDocs(mr2),\n                                 null,\n                                 false);\n\n    TermsEnum te3 = MultiFields.getTerms(mr3, \"body\").iterator(null);\n    te3.seekCeil(new BytesRef(\"wow\"));\n    td = _TestUtil.docs(random, te3, MultiFields.getLiveDocs(mr3),\n                        td,\n                        false);\n    \n    int ret = 0;\n\n    // This should blow up if we forget to check that the TermEnum is from the same\n    // reader as the TermDocs.\n    while (td.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) ret += td.docID();\n\n    // really a dummy assert to ensure that we got some docs and to ensure that\n    // nothing is eliminated by hotspot\n    assertTrue(ret > 0);\n    readers1[0].close();\n    readers1[1].close();\n    readers2[0].close();\n    readers2[1].close();\n    readers2[2].close();\n    ramDir1.close();\n    ramDir2.close();\n    ramDir3.close();\n  }\n\n","sourceOld":"  public void testMultiTermDocs() throws IOException {\n    Directory ramDir1=newDirectory();\n    addDoc(random, ramDir1, \"test foo\", true);\n    Directory ramDir2=newDirectory();\n    addDoc(random, ramDir2, \"test blah\", true);\n    Directory ramDir3=newDirectory();\n    addDoc(random, ramDir3, \"test wow\", true);\n\n    IndexReader[] readers1 = new IndexReader[]{DirectoryReader.open(ramDir1), DirectoryReader.open(ramDir3)};\n    IndexReader[] readers2 = new IndexReader[]{DirectoryReader.open(ramDir1), DirectoryReader.open(ramDir2), DirectoryReader.open(ramDir3)};\n    MultiReader mr2 = new MultiReader(readers1);\n    MultiReader mr3 = new MultiReader(readers2);\n\n    // test mixing up TermDocs and TermEnums from different readers.\n    TermsEnum te2 = MultiFields.getTerms(mr2, \"body\").iterator(null);\n    te2.seekCeil(new BytesRef(\"wow\"));\n    DocsEnum td = _TestUtil.docs(random, mr2,\n                                 \"body\",\n                                 te2.term(),\n                                 MultiFields.getLiveDocs(mr2),\n                                 null,\n                                 false);\n\n    TermsEnum te3 = MultiFields.getTerms(mr3, \"body\").iterator(null);\n    te3.seekCeil(new BytesRef(\"wow\"));\n    td = _TestUtil.docs(random, te3, MultiFields.getLiveDocs(mr3),\n                        td,\n                        false);\n    \n    int ret = 0;\n\n    // This should blow up if we forget to check that the TermEnum is from the same\n    // reader as the TermDocs.\n    while (td.nextDoc() != td.NO_MORE_DOCS) ret += td.docID();\n\n    // really a dummy assert to ensure that we got some docs and to ensure that\n    // nothing is eliminated by hotspot\n    assertTrue(ret > 0);\n    readers1[0].close();\n    readers1[1].close();\n    readers2[0].close();\n    readers2[1].close();\n    readers2[2].close();\n    ramDir1.close();\n    ramDir2.close();\n    ramDir3.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab","date":1331075828,"type":3,"author":"Ryan McKinley","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDirectoryReader#testMultiTermDocs().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDirectoryReader#testMultiTermDocs().mjava","sourceNew":"  public void testMultiTermDocs() throws IOException {\n    Directory ramDir1=newDirectory();\n    addDoc(random, ramDir1, \"test foo\", true);\n    Directory ramDir2=newDirectory();\n    addDoc(random, ramDir2, \"test blah\", true);\n    Directory ramDir3=newDirectory();\n    addDoc(random, ramDir3, \"test wow\", true);\n\n    IndexReader[] readers1 = new IndexReader[]{DirectoryReader.open(ramDir1), DirectoryReader.open(ramDir3)};\n    IndexReader[] readers2 = new IndexReader[]{DirectoryReader.open(ramDir1), DirectoryReader.open(ramDir2), DirectoryReader.open(ramDir3)};\n    MultiReader mr2 = new MultiReader(readers1);\n    MultiReader mr3 = new MultiReader(readers2);\n\n    // test mixing up TermDocs and TermEnums from different readers.\n    TermsEnum te2 = MultiFields.getTerms(mr2, \"body\").iterator(null);\n    te2.seekCeil(new BytesRef(\"wow\"));\n    DocsEnum td = _TestUtil.docs(random, mr2,\n                                 \"body\",\n                                 te2.term(),\n                                 MultiFields.getLiveDocs(mr2),\n                                 null,\n                                 false);\n\n    TermsEnum te3 = MultiFields.getTerms(mr3, \"body\").iterator(null);\n    te3.seekCeil(new BytesRef(\"wow\"));\n    td = _TestUtil.docs(random, te3, MultiFields.getLiveDocs(mr3),\n                        td,\n                        false);\n    \n    int ret = 0;\n\n    // This should blow up if we forget to check that the TermEnum is from the same\n    // reader as the TermDocs.\n    while (td.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) ret += td.docID();\n\n    // really a dummy assert to ensure that we got some docs and to ensure that\n    // nothing is eliminated by hotspot\n    assertTrue(ret > 0);\n    readers1[0].close();\n    readers1[1].close();\n    readers2[0].close();\n    readers2[1].close();\n    readers2[2].close();\n    ramDir1.close();\n    ramDir2.close();\n    ramDir3.close();\n  }\n\n","sourceOld":"  public void testMultiTermDocs() throws IOException {\n    Directory ramDir1=newDirectory();\n    addDoc(random, ramDir1, \"test foo\", true);\n    Directory ramDir2=newDirectory();\n    addDoc(random, ramDir2, \"test blah\", true);\n    Directory ramDir3=newDirectory();\n    addDoc(random, ramDir3, \"test wow\", true);\n\n    IndexReader[] readers1 = new IndexReader[]{DirectoryReader.open(ramDir1), DirectoryReader.open(ramDir3)};\n    IndexReader[] readers2 = new IndexReader[]{DirectoryReader.open(ramDir1), DirectoryReader.open(ramDir2), DirectoryReader.open(ramDir3)};\n    MultiReader mr2 = new MultiReader(readers1);\n    MultiReader mr3 = new MultiReader(readers2);\n\n    // test mixing up TermDocs and TermEnums from different readers.\n    TermsEnum te2 = MultiFields.getTerms(mr2, \"body\").iterator(null);\n    te2.seekCeil(new BytesRef(\"wow\"));\n    DocsEnum td = _TestUtil.docs(random, mr2,\n                                 \"body\",\n                                 te2.term(),\n                                 MultiFields.getLiveDocs(mr2),\n                                 null,\n                                 false);\n\n    TermsEnum te3 = MultiFields.getTerms(mr3, \"body\").iterator(null);\n    te3.seekCeil(new BytesRef(\"wow\"));\n    td = _TestUtil.docs(random, te3, MultiFields.getLiveDocs(mr3),\n                        td,\n                        false);\n    \n    int ret = 0;\n\n    // This should blow up if we forget to check that the TermEnum is from the same\n    // reader as the TermDocs.\n    while (td.nextDoc() != td.NO_MORE_DOCS) ret += td.docID();\n\n    // really a dummy assert to ensure that we got some docs and to ensure that\n    // nothing is eliminated by hotspot\n    assertTrue(ret > 0);\n    readers1[0].close();\n    readers1[1].close();\n    readers2[0].close();\n    readers2[1].close();\n    readers2[2].close();\n    ramDir1.close();\n    ramDir2.close();\n    ramDir3.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"629c38c4ae4e303d0617e05fbfe508140b32f0a3","date":1334500904,"type":3,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDirectoryReader#testMultiTermDocs().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDirectoryReader#testMultiTermDocs().mjava","sourceNew":"  public void testMultiTermDocs() throws IOException {\n    Directory ramDir1=newDirectory();\n    addDoc(random(), ramDir1, \"test foo\", true);\n    Directory ramDir2=newDirectory();\n    addDoc(random(), ramDir2, \"test blah\", true);\n    Directory ramDir3=newDirectory();\n    addDoc(random(), ramDir3, \"test wow\", true);\n\n    IndexReader[] readers1 = new IndexReader[]{DirectoryReader.open(ramDir1), DirectoryReader.open(ramDir3)};\n    IndexReader[] readers2 = new IndexReader[]{DirectoryReader.open(ramDir1), DirectoryReader.open(ramDir2), DirectoryReader.open(ramDir3)};\n    MultiReader mr2 = new MultiReader(readers1);\n    MultiReader mr3 = new MultiReader(readers2);\n\n    // test mixing up TermDocs and TermEnums from different readers.\n    TermsEnum te2 = MultiFields.getTerms(mr2, \"body\").iterator(null);\n    te2.seekCeil(new BytesRef(\"wow\"));\n    DocsEnum td = _TestUtil.docs(random(), mr2,\n                                 \"body\",\n                                 te2.term(),\n                                 MultiFields.getLiveDocs(mr2),\n                                 null,\n                                 false);\n\n    TermsEnum te3 = MultiFields.getTerms(mr3, \"body\").iterator(null);\n    te3.seekCeil(new BytesRef(\"wow\"));\n    td = _TestUtil.docs(random(), te3, MultiFields.getLiveDocs(mr3),\n                        td,\n                        false);\n    \n    int ret = 0;\n\n    // This should blow up if we forget to check that the TermEnum is from the same\n    // reader as the TermDocs.\n    while (td.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) ret += td.docID();\n\n    // really a dummy assert to ensure that we got some docs and to ensure that\n    // nothing is eliminated by hotspot\n    assertTrue(ret > 0);\n    readers1[0].close();\n    readers1[1].close();\n    readers2[0].close();\n    readers2[1].close();\n    readers2[2].close();\n    ramDir1.close();\n    ramDir2.close();\n    ramDir3.close();\n  }\n\n","sourceOld":"  public void testMultiTermDocs() throws IOException {\n    Directory ramDir1=newDirectory();\n    addDoc(random, ramDir1, \"test foo\", true);\n    Directory ramDir2=newDirectory();\n    addDoc(random, ramDir2, \"test blah\", true);\n    Directory ramDir3=newDirectory();\n    addDoc(random, ramDir3, \"test wow\", true);\n\n    IndexReader[] readers1 = new IndexReader[]{DirectoryReader.open(ramDir1), DirectoryReader.open(ramDir3)};\n    IndexReader[] readers2 = new IndexReader[]{DirectoryReader.open(ramDir1), DirectoryReader.open(ramDir2), DirectoryReader.open(ramDir3)};\n    MultiReader mr2 = new MultiReader(readers1);\n    MultiReader mr3 = new MultiReader(readers2);\n\n    // test mixing up TermDocs and TermEnums from different readers.\n    TermsEnum te2 = MultiFields.getTerms(mr2, \"body\").iterator(null);\n    te2.seekCeil(new BytesRef(\"wow\"));\n    DocsEnum td = _TestUtil.docs(random, mr2,\n                                 \"body\",\n                                 te2.term(),\n                                 MultiFields.getLiveDocs(mr2),\n                                 null,\n                                 false);\n\n    TermsEnum te3 = MultiFields.getTerms(mr3, \"body\").iterator(null);\n    te3.seekCeil(new BytesRef(\"wow\"));\n    td = _TestUtil.docs(random, te3, MultiFields.getLiveDocs(mr3),\n                        td,\n                        false);\n    \n    int ret = 0;\n\n    // This should blow up if we forget to check that the TermEnum is from the same\n    // reader as the TermDocs.\n    while (td.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) ret += td.docID();\n\n    // really a dummy assert to ensure that we got some docs and to ensure that\n    // nothing is eliminated by hotspot\n    assertTrue(ret > 0);\n    readers1[0].close();\n    readers1[1].close();\n    readers2[0].close();\n    readers2[1].close();\n    readers2[2].close();\n    ramDir1.close();\n    ramDir2.close();\n    ramDir3.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"02331260bb246364779cb6f04919ca47900d01bb","date":1343749884,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDirectoryReader#testMultiTermDocs().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDirectoryReader#testMultiTermDocs().mjava","sourceNew":"  public void testMultiTermDocs() throws IOException {\n    Directory ramDir1=newDirectory();\n    addDoc(random(), ramDir1, \"test foo\", true);\n    Directory ramDir2=newDirectory();\n    addDoc(random(), ramDir2, \"test blah\", true);\n    Directory ramDir3=newDirectory();\n    addDoc(random(), ramDir3, \"test wow\", true);\n\n    IndexReader[] readers1 = new IndexReader[]{DirectoryReader.open(ramDir1), DirectoryReader.open(ramDir3)};\n    IndexReader[] readers2 = new IndexReader[]{DirectoryReader.open(ramDir1), DirectoryReader.open(ramDir2), DirectoryReader.open(ramDir3)};\n    MultiReader mr2 = new MultiReader(readers1);\n    MultiReader mr3 = new MultiReader(readers2);\n\n    // test mixing up TermDocs and TermEnums from different readers.\n    TermsEnum te2 = MultiFields.getTerms(mr2, \"body\").iterator(null);\n    te2.seekCeil(new BytesRef(\"wow\"));\n    DocsEnum td = _TestUtil.docs(random(), mr2,\n                                 \"body\",\n                                 te2.term(),\n                                 MultiFields.getLiveDocs(mr2),\n                                 null,\n                                 0);\n\n    TermsEnum te3 = MultiFields.getTerms(mr3, \"body\").iterator(null);\n    te3.seekCeil(new BytesRef(\"wow\"));\n    td = _TestUtil.docs(random(), te3, MultiFields.getLiveDocs(mr3),\n                        td,\n                        0);\n    \n    int ret = 0;\n\n    // This should blow up if we forget to check that the TermEnum is from the same\n    // reader as the TermDocs.\n    while (td.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) ret += td.docID();\n\n    // really a dummy assert to ensure that we got some docs and to ensure that\n    // nothing is eliminated by hotspot\n    assertTrue(ret > 0);\n    readers1[0].close();\n    readers1[1].close();\n    readers2[0].close();\n    readers2[1].close();\n    readers2[2].close();\n    ramDir1.close();\n    ramDir2.close();\n    ramDir3.close();\n  }\n\n","sourceOld":"  public void testMultiTermDocs() throws IOException {\n    Directory ramDir1=newDirectory();\n    addDoc(random(), ramDir1, \"test foo\", true);\n    Directory ramDir2=newDirectory();\n    addDoc(random(), ramDir2, \"test blah\", true);\n    Directory ramDir3=newDirectory();\n    addDoc(random(), ramDir3, \"test wow\", true);\n\n    IndexReader[] readers1 = new IndexReader[]{DirectoryReader.open(ramDir1), DirectoryReader.open(ramDir3)};\n    IndexReader[] readers2 = new IndexReader[]{DirectoryReader.open(ramDir1), DirectoryReader.open(ramDir2), DirectoryReader.open(ramDir3)};\n    MultiReader mr2 = new MultiReader(readers1);\n    MultiReader mr3 = new MultiReader(readers2);\n\n    // test mixing up TermDocs and TermEnums from different readers.\n    TermsEnum te2 = MultiFields.getTerms(mr2, \"body\").iterator(null);\n    te2.seekCeil(new BytesRef(\"wow\"));\n    DocsEnum td = _TestUtil.docs(random(), mr2,\n                                 \"body\",\n                                 te2.term(),\n                                 MultiFields.getLiveDocs(mr2),\n                                 null,\n                                 false);\n\n    TermsEnum te3 = MultiFields.getTerms(mr3, \"body\").iterator(null);\n    te3.seekCeil(new BytesRef(\"wow\"));\n    td = _TestUtil.docs(random(), te3, MultiFields.getLiveDocs(mr3),\n                        td,\n                        false);\n    \n    int ret = 0;\n\n    // This should blow up if we forget to check that the TermEnum is from the same\n    // reader as the TermDocs.\n    while (td.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) ret += td.docID();\n\n    // really a dummy assert to ensure that we got some docs and to ensure that\n    // nothing is eliminated by hotspot\n    assertTrue(ret > 0);\n    readers1[0].close();\n    readers1[1].close();\n    readers2[0].close();\n    readers2[1].close();\n    readers2[2].close();\n    ramDir1.close();\n    ramDir2.close();\n    ramDir3.close();\n  }\n\n","bugFix":["872cff1d3a554e0cd64014cd97f88d3002b0f491"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f","date":1343768312,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDirectoryReader#testMultiTermDocs().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDirectoryReader#testMultiTermDocs().mjava","sourceNew":"  public void testMultiTermDocs() throws IOException {\n    Directory ramDir1=newDirectory();\n    addDoc(random(), ramDir1, \"test foo\", true);\n    Directory ramDir2=newDirectory();\n    addDoc(random(), ramDir2, \"test blah\", true);\n    Directory ramDir3=newDirectory();\n    addDoc(random(), ramDir3, \"test wow\", true);\n\n    IndexReader[] readers1 = new IndexReader[]{DirectoryReader.open(ramDir1), DirectoryReader.open(ramDir3)};\n    IndexReader[] readers2 = new IndexReader[]{DirectoryReader.open(ramDir1), DirectoryReader.open(ramDir2), DirectoryReader.open(ramDir3)};\n    MultiReader mr2 = new MultiReader(readers1);\n    MultiReader mr3 = new MultiReader(readers2);\n\n    // test mixing up TermDocs and TermEnums from different readers.\n    TermsEnum te2 = MultiFields.getTerms(mr2, \"body\").iterator(null);\n    te2.seekCeil(new BytesRef(\"wow\"));\n    DocsEnum td = _TestUtil.docs(random(), mr2,\n                                 \"body\",\n                                 te2.term(),\n                                 MultiFields.getLiveDocs(mr2),\n                                 null,\n                                 0);\n\n    TermsEnum te3 = MultiFields.getTerms(mr3, \"body\").iterator(null);\n    te3.seekCeil(new BytesRef(\"wow\"));\n    td = _TestUtil.docs(random(), te3, MultiFields.getLiveDocs(mr3),\n                        td,\n                        0);\n    \n    int ret = 0;\n\n    // This should blow up if we forget to check that the TermEnum is from the same\n    // reader as the TermDocs.\n    while (td.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) ret += td.docID();\n\n    // really a dummy assert to ensure that we got some docs and to ensure that\n    // nothing is eliminated by hotspot\n    assertTrue(ret > 0);\n    readers1[0].close();\n    readers1[1].close();\n    readers2[0].close();\n    readers2[1].close();\n    readers2[2].close();\n    ramDir1.close();\n    ramDir2.close();\n    ramDir3.close();\n  }\n\n","sourceOld":"  public void testMultiTermDocs() throws IOException {\n    Directory ramDir1=newDirectory();\n    addDoc(random(), ramDir1, \"test foo\", true);\n    Directory ramDir2=newDirectory();\n    addDoc(random(), ramDir2, \"test blah\", true);\n    Directory ramDir3=newDirectory();\n    addDoc(random(), ramDir3, \"test wow\", true);\n\n    IndexReader[] readers1 = new IndexReader[]{DirectoryReader.open(ramDir1), DirectoryReader.open(ramDir3)};\n    IndexReader[] readers2 = new IndexReader[]{DirectoryReader.open(ramDir1), DirectoryReader.open(ramDir2), DirectoryReader.open(ramDir3)};\n    MultiReader mr2 = new MultiReader(readers1);\n    MultiReader mr3 = new MultiReader(readers2);\n\n    // test mixing up TermDocs and TermEnums from different readers.\n    TermsEnum te2 = MultiFields.getTerms(mr2, \"body\").iterator(null);\n    te2.seekCeil(new BytesRef(\"wow\"));\n    DocsEnum td = _TestUtil.docs(random(), mr2,\n                                 \"body\",\n                                 te2.term(),\n                                 MultiFields.getLiveDocs(mr2),\n                                 null,\n                                 false);\n\n    TermsEnum te3 = MultiFields.getTerms(mr3, \"body\").iterator(null);\n    te3.seekCeil(new BytesRef(\"wow\"));\n    td = _TestUtil.docs(random(), te3, MultiFields.getLiveDocs(mr3),\n                        td,\n                        false);\n    \n    int ret = 0;\n\n    // This should blow up if we forget to check that the TermEnum is from the same\n    // reader as the TermDocs.\n    while (td.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) ret += td.docID();\n\n    // really a dummy assert to ensure that we got some docs and to ensure that\n    // nothing is eliminated by hotspot\n    assertTrue(ret > 0);\n    readers1[0].close();\n    readers1[1].close();\n    readers2[0].close();\n    readers2[1].close();\n    readers2[2].close();\n    ramDir1.close();\n    ramDir2.close();\n    ramDir3.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d6f074e73200c07d54f242d3880a8da5a35ff97b","date":1344507653,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDirectoryReader#testMultiTermDocs().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDirectoryReader#testMultiTermDocs().mjava","sourceNew":"  public void testMultiTermDocs() throws IOException {\n    Directory ramDir1=newDirectory();\n    addDoc(random(), ramDir1, \"test foo\", true);\n    Directory ramDir2=newDirectory();\n    addDoc(random(), ramDir2, \"test blah\", true);\n    Directory ramDir3=newDirectory();\n    addDoc(random(), ramDir3, \"test wow\", true);\n\n    IndexReader[] readers1 = new IndexReader[]{DirectoryReader.open(ramDir1), DirectoryReader.open(ramDir3)};\n    IndexReader[] readers2 = new IndexReader[]{DirectoryReader.open(ramDir1), DirectoryReader.open(ramDir2), DirectoryReader.open(ramDir3)};\n    MultiReader mr2 = new MultiReader(readers1);\n    MultiReader mr3 = new MultiReader(readers2);\n\n    // test mixing up TermDocs and TermEnums from different readers.\n    TermsEnum te2 = MultiFields.getTerms(mr2, \"body\").iterator(null);\n    te2.seekCeil(new BytesRef(\"wow\"));\n    DocsEnum td = _TestUtil.docs(random(), mr2,\n                                 \"body\",\n                                 te2.term(),\n                                 MultiFields.getLiveDocs(mr2),\n                                 null,\n                                 0);\n\n    TermsEnum te3 = MultiFields.getTerms(mr3, \"body\").iterator(null);\n    te3.seekCeil(new BytesRef(\"wow\"));\n    td = _TestUtil.docs(random(), te3, MultiFields.getLiveDocs(mr3),\n                        td,\n                        0);\n    \n    int ret = 0;\n\n    // This should blow up if we forget to check that the TermEnum is from the same\n    // reader as the TermDocs.\n    while (td.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) ret += td.docID();\n\n    // really a dummy assert to ensure that we got some docs and to ensure that\n    // nothing is eliminated by hotspot\n    assertTrue(ret > 0);\n    readers1[0].close();\n    readers1[1].close();\n    readers2[0].close();\n    readers2[1].close();\n    readers2[2].close();\n    ramDir1.close();\n    ramDir2.close();\n    ramDir3.close();\n  }\n\n","sourceOld":"  public void testMultiTermDocs() throws IOException {\n    Directory ramDir1=newDirectory();\n    addDoc(random(), ramDir1, \"test foo\", true);\n    Directory ramDir2=newDirectory();\n    addDoc(random(), ramDir2, \"test blah\", true);\n    Directory ramDir3=newDirectory();\n    addDoc(random(), ramDir3, \"test wow\", true);\n\n    IndexReader[] readers1 = new IndexReader[]{DirectoryReader.open(ramDir1), DirectoryReader.open(ramDir3)};\n    IndexReader[] readers2 = new IndexReader[]{DirectoryReader.open(ramDir1), DirectoryReader.open(ramDir2), DirectoryReader.open(ramDir3)};\n    MultiReader mr2 = new MultiReader(readers1);\n    MultiReader mr3 = new MultiReader(readers2);\n\n    // test mixing up TermDocs and TermEnums from different readers.\n    TermsEnum te2 = MultiFields.getTerms(mr2, \"body\").iterator(null);\n    te2.seekCeil(new BytesRef(\"wow\"));\n    DocsEnum td = _TestUtil.docs(random(), mr2,\n                                 \"body\",\n                                 te2.term(),\n                                 MultiFields.getLiveDocs(mr2),\n                                 null,\n                                 false);\n\n    TermsEnum te3 = MultiFields.getTerms(mr3, \"body\").iterator(null);\n    te3.seekCeil(new BytesRef(\"wow\"));\n    td = _TestUtil.docs(random(), te3, MultiFields.getLiveDocs(mr3),\n                        td,\n                        false);\n    \n    int ret = 0;\n\n    // This should blow up if we forget to check that the TermEnum is from the same\n    // reader as the TermDocs.\n    while (td.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) ret += td.docID();\n\n    // really a dummy assert to ensure that we got some docs and to ensure that\n    // nothing is eliminated by hotspot\n    assertTrue(ret > 0);\n    readers1[0].close();\n    readers1[1].close();\n    readers2[0].close();\n    readers2[1].close();\n    readers2[2].close();\n    ramDir1.close();\n    ramDir2.close();\n    ramDir3.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6613659748fe4411a7dcf85266e55db1f95f7315","date":1392773913,"type":3,"author":"Benson Margulies","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDirectoryReader#testMultiTermDocs().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDirectoryReader#testMultiTermDocs().mjava","sourceNew":"  public void testMultiTermDocs() throws IOException {\n    Directory ramDir1=newDirectory();\n    addDoc(random(), ramDir1, \"test foo\", true);\n    Directory ramDir2=newDirectory();\n    addDoc(random(), ramDir2, \"test blah\", true);\n    Directory ramDir3=newDirectory();\n    addDoc(random(), ramDir3, \"test wow\", true);\n\n    IndexReader[] readers1 = new IndexReader[]{DirectoryReader.open(ramDir1), DirectoryReader.open(ramDir3)};\n    IndexReader[] readers2 = new IndexReader[]{DirectoryReader.open(ramDir1), DirectoryReader.open(ramDir2), DirectoryReader.open(ramDir3)};\n    MultiReader mr2 = new MultiReader(readers1);\n    MultiReader mr3 = new MultiReader(readers2);\n\n    // test mixing up TermDocs and TermEnums from different readers.\n    TermsEnum te2 = MultiFields.getTerms(mr2, \"body\").iterator(null);\n    te2.seekCeil(new BytesRef(\"wow\"));\n    DocsEnum td = TestUtil.docs(random(), mr2,\n        \"body\",\n        te2.term(),\n        MultiFields.getLiveDocs(mr2),\n        null,\n        0);\n\n    TermsEnum te3 = MultiFields.getTerms(mr3, \"body\").iterator(null);\n    te3.seekCeil(new BytesRef(\"wow\"));\n    td = TestUtil.docs(random(), te3, MultiFields.getLiveDocs(mr3),\n        td,\n        0);\n    \n    int ret = 0;\n\n    // This should blow up if we forget to check that the TermEnum is from the same\n    // reader as the TermDocs.\n    while (td.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) ret += td.docID();\n\n    // really a dummy assert to ensure that we got some docs and to ensure that\n    // nothing is eliminated by hotspot\n    assertTrue(ret > 0);\n    readers1[0].close();\n    readers1[1].close();\n    readers2[0].close();\n    readers2[1].close();\n    readers2[2].close();\n    ramDir1.close();\n    ramDir2.close();\n    ramDir3.close();\n  }\n\n","sourceOld":"  public void testMultiTermDocs() throws IOException {\n    Directory ramDir1=newDirectory();\n    addDoc(random(), ramDir1, \"test foo\", true);\n    Directory ramDir2=newDirectory();\n    addDoc(random(), ramDir2, \"test blah\", true);\n    Directory ramDir3=newDirectory();\n    addDoc(random(), ramDir3, \"test wow\", true);\n\n    IndexReader[] readers1 = new IndexReader[]{DirectoryReader.open(ramDir1), DirectoryReader.open(ramDir3)};\n    IndexReader[] readers2 = new IndexReader[]{DirectoryReader.open(ramDir1), DirectoryReader.open(ramDir2), DirectoryReader.open(ramDir3)};\n    MultiReader mr2 = new MultiReader(readers1);\n    MultiReader mr3 = new MultiReader(readers2);\n\n    // test mixing up TermDocs and TermEnums from different readers.\n    TermsEnum te2 = MultiFields.getTerms(mr2, \"body\").iterator(null);\n    te2.seekCeil(new BytesRef(\"wow\"));\n    DocsEnum td = _TestUtil.docs(random(), mr2,\n                                 \"body\",\n                                 te2.term(),\n                                 MultiFields.getLiveDocs(mr2),\n                                 null,\n                                 0);\n\n    TermsEnum te3 = MultiFields.getTerms(mr3, \"body\").iterator(null);\n    te3.seekCeil(new BytesRef(\"wow\"));\n    td = _TestUtil.docs(random(), te3, MultiFields.getLiveDocs(mr3),\n                        td,\n                        0);\n    \n    int ret = 0;\n\n    // This should blow up if we forget to check that the TermEnum is from the same\n    // reader as the TermDocs.\n    while (td.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) ret += td.docID();\n\n    // really a dummy assert to ensure that we got some docs and to ensure that\n    // nothing is eliminated by hotspot\n    assertTrue(ret > 0);\n    readers1[0].close();\n    readers1[1].close();\n    readers2[0].close();\n    readers2[1].close();\n    readers2[2].close();\n    ramDir1.close();\n    ramDir2.close();\n    ramDir3.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"51f5280f31484820499077f41fcdfe92d527d9dc","date":1423229122,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDirectoryReader#testMultiTermDocs().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDirectoryReader#testMultiTermDocs().mjava","sourceNew":"  public void testMultiTermDocs() throws IOException {\n    Directory ramDir1=newDirectory();\n    addDoc(random(), ramDir1, \"test foo\", true);\n    Directory ramDir2=newDirectory();\n    addDoc(random(), ramDir2, \"test blah\", true);\n    Directory ramDir3=newDirectory();\n    addDoc(random(), ramDir3, \"test wow\", true);\n\n    IndexReader[] readers1 = new IndexReader[]{DirectoryReader.open(ramDir1), DirectoryReader.open(ramDir3)};\n    IndexReader[] readers2 = new IndexReader[]{DirectoryReader.open(ramDir1), DirectoryReader.open(ramDir2), DirectoryReader.open(ramDir3)};\n    MultiReader mr2 = new MultiReader(readers1);\n    MultiReader mr3 = new MultiReader(readers2);\n\n    // test mixing up TermDocs and TermEnums from different readers.\n    TermsEnum te2 = MultiFields.getTerms(mr2, \"body\").iterator(null);\n    te2.seekCeil(new BytesRef(\"wow\"));\n    PostingsEnum td = TestUtil.docs(random(), mr2,\n        \"body\",\n        te2.term(),\n        MultiFields.getLiveDocs(mr2),\n        null,\n        0);\n\n    TermsEnum te3 = MultiFields.getTerms(mr3, \"body\").iterator(null);\n    te3.seekCeil(new BytesRef(\"wow\"));\n    td = TestUtil.docs(random(), te3, MultiFields.getLiveDocs(mr3),\n        td,\n        0);\n    \n    int ret = 0;\n\n    // This should blow up if we forget to check that the TermEnum is from the same\n    // reader as the TermDocs.\n    while (td.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) ret += td.docID();\n\n    // really a dummy assert to ensure that we got some docs and to ensure that\n    // nothing is eliminated by hotspot\n    assertTrue(ret > 0);\n    readers1[0].close();\n    readers1[1].close();\n    readers2[0].close();\n    readers2[1].close();\n    readers2[2].close();\n    ramDir1.close();\n    ramDir2.close();\n    ramDir3.close();\n  }\n\n","sourceOld":"  public void testMultiTermDocs() throws IOException {\n    Directory ramDir1=newDirectory();\n    addDoc(random(), ramDir1, \"test foo\", true);\n    Directory ramDir2=newDirectory();\n    addDoc(random(), ramDir2, \"test blah\", true);\n    Directory ramDir3=newDirectory();\n    addDoc(random(), ramDir3, \"test wow\", true);\n\n    IndexReader[] readers1 = new IndexReader[]{DirectoryReader.open(ramDir1), DirectoryReader.open(ramDir3)};\n    IndexReader[] readers2 = new IndexReader[]{DirectoryReader.open(ramDir1), DirectoryReader.open(ramDir2), DirectoryReader.open(ramDir3)};\n    MultiReader mr2 = new MultiReader(readers1);\n    MultiReader mr3 = new MultiReader(readers2);\n\n    // test mixing up TermDocs and TermEnums from different readers.\n    TermsEnum te2 = MultiFields.getTerms(mr2, \"body\").iterator(null);\n    te2.seekCeil(new BytesRef(\"wow\"));\n    DocsEnum td = TestUtil.docs(random(), mr2,\n        \"body\",\n        te2.term(),\n        MultiFields.getLiveDocs(mr2),\n        null,\n        0);\n\n    TermsEnum te3 = MultiFields.getTerms(mr3, \"body\").iterator(null);\n    te3.seekCeil(new BytesRef(\"wow\"));\n    td = TestUtil.docs(random(), te3, MultiFields.getLiveDocs(mr3),\n        td,\n        0);\n    \n    int ret = 0;\n\n    // This should blow up if we forget to check that the TermEnum is from the same\n    // reader as the TermDocs.\n    while (td.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) ret += td.docID();\n\n    // really a dummy assert to ensure that we got some docs and to ensure that\n    // nothing is eliminated by hotspot\n    assertTrue(ret > 0);\n    readers1[0].close();\n    readers1[1].close();\n    readers2[0].close();\n    readers2[1].close();\n    readers2[2].close();\n    ramDir1.close();\n    ramDir2.close();\n    ramDir3.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0a773283ef5eab2e9c7136eeb66574a4b7a2dc82","date":1428522487,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDirectoryReader#testMultiTermDocs().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDirectoryReader#testMultiTermDocs().mjava","sourceNew":"  public void testMultiTermDocs() throws IOException {\n    Directory ramDir1=newDirectory();\n    addDoc(random(), ramDir1, \"test foo\", true);\n    Directory ramDir2=newDirectory();\n    addDoc(random(), ramDir2, \"test blah\", true);\n    Directory ramDir3=newDirectory();\n    addDoc(random(), ramDir3, \"test wow\", true);\n\n    IndexReader[] readers1 = new IndexReader[]{DirectoryReader.open(ramDir1), DirectoryReader.open(ramDir3)};\n    IndexReader[] readers2 = new IndexReader[]{DirectoryReader.open(ramDir1), DirectoryReader.open(ramDir2), DirectoryReader.open(ramDir3)};\n    MultiReader mr2 = new MultiReader(readers1);\n    MultiReader mr3 = new MultiReader(readers2);\n\n    // test mixing up TermDocs and TermEnums from different readers.\n    TermsEnum te2 = MultiFields.getTerms(mr2, \"body\").iterator();\n    te2.seekCeil(new BytesRef(\"wow\"));\n    PostingsEnum td = TestUtil.docs(random(), mr2,\n        \"body\",\n        te2.term(),\n        MultiFields.getLiveDocs(mr2),\n        null,\n        0);\n\n    TermsEnum te3 = MultiFields.getTerms(mr3, \"body\").iterator();\n    te3.seekCeil(new BytesRef(\"wow\"));\n    td = TestUtil.docs(random(), te3, MultiFields.getLiveDocs(mr3),\n        td,\n        0);\n    \n    int ret = 0;\n\n    // This should blow up if we forget to check that the TermEnum is from the same\n    // reader as the TermDocs.\n    while (td.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) ret += td.docID();\n\n    // really a dummy assert to ensure that we got some docs and to ensure that\n    // nothing is eliminated by hotspot\n    assertTrue(ret > 0);\n    readers1[0].close();\n    readers1[1].close();\n    readers2[0].close();\n    readers2[1].close();\n    readers2[2].close();\n    ramDir1.close();\n    ramDir2.close();\n    ramDir3.close();\n  }\n\n","sourceOld":"  public void testMultiTermDocs() throws IOException {\n    Directory ramDir1=newDirectory();\n    addDoc(random(), ramDir1, \"test foo\", true);\n    Directory ramDir2=newDirectory();\n    addDoc(random(), ramDir2, \"test blah\", true);\n    Directory ramDir3=newDirectory();\n    addDoc(random(), ramDir3, \"test wow\", true);\n\n    IndexReader[] readers1 = new IndexReader[]{DirectoryReader.open(ramDir1), DirectoryReader.open(ramDir3)};\n    IndexReader[] readers2 = new IndexReader[]{DirectoryReader.open(ramDir1), DirectoryReader.open(ramDir2), DirectoryReader.open(ramDir3)};\n    MultiReader mr2 = new MultiReader(readers1);\n    MultiReader mr3 = new MultiReader(readers2);\n\n    // test mixing up TermDocs and TermEnums from different readers.\n    TermsEnum te2 = MultiFields.getTerms(mr2, \"body\").iterator(null);\n    te2.seekCeil(new BytesRef(\"wow\"));\n    PostingsEnum td = TestUtil.docs(random(), mr2,\n        \"body\",\n        te2.term(),\n        MultiFields.getLiveDocs(mr2),\n        null,\n        0);\n\n    TermsEnum te3 = MultiFields.getTerms(mr3, \"body\").iterator(null);\n    te3.seekCeil(new BytesRef(\"wow\"));\n    td = TestUtil.docs(random(), te3, MultiFields.getLiveDocs(mr3),\n        td,\n        0);\n    \n    int ret = 0;\n\n    // This should blow up if we forget to check that the TermEnum is from the same\n    // reader as the TermDocs.\n    while (td.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) ret += td.docID();\n\n    // really a dummy assert to ensure that we got some docs and to ensure that\n    // nothing is eliminated by hotspot\n    assertTrue(ret > 0);\n    readers1[0].close();\n    readers1[1].close();\n    readers2[0].close();\n    readers2[1].close();\n    readers2[2].close();\n    ramDir1.close();\n    ramDir2.close();\n    ramDir3.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0f4464508ee83288c8c4585b533f9faaa93aa314","date":1435240759,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDirectoryReader#testMultiTermDocs().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDirectoryReader#testMultiTermDocs().mjava","sourceNew":"  public void testMultiTermDocs() throws IOException {\n    Directory ramDir1=newDirectory();\n    addDoc(random(), ramDir1, \"test foo\", true);\n    Directory ramDir2=newDirectory();\n    addDoc(random(), ramDir2, \"test blah\", true);\n    Directory ramDir3=newDirectory();\n    addDoc(random(), ramDir3, \"test wow\", true);\n\n    IndexReader[] readers1 = new IndexReader[]{DirectoryReader.open(ramDir1), DirectoryReader.open(ramDir3)};\n    IndexReader[] readers2 = new IndexReader[]{DirectoryReader.open(ramDir1), DirectoryReader.open(ramDir2), DirectoryReader.open(ramDir3)};\n    MultiReader mr2 = new MultiReader(readers1);\n    MultiReader mr3 = new MultiReader(readers2);\n\n    // test mixing up TermDocs and TermEnums from different readers.\n    TermsEnum te2 = MultiFields.getTerms(mr2, \"body\").iterator();\n    te2.seekCeil(new BytesRef(\"wow\"));\n    PostingsEnum td = TestUtil.docs(random(), mr2,\n        \"body\",\n        te2.term(),\n        null,\n        0);\n\n    TermsEnum te3 = MultiFields.getTerms(mr3, \"body\").iterator();\n    te3.seekCeil(new BytesRef(\"wow\"));\n    td = TestUtil.docs(random(), te3,\n        td,\n        0);\n    \n    int ret = 0;\n\n    // This should blow up if we forget to check that the TermEnum is from the same\n    // reader as the TermDocs.\n    while (td.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) ret += td.docID();\n\n    // really a dummy assert to ensure that we got some docs and to ensure that\n    // nothing is eliminated by hotspot\n    assertTrue(ret > 0);\n    readers1[0].close();\n    readers1[1].close();\n    readers2[0].close();\n    readers2[1].close();\n    readers2[2].close();\n    ramDir1.close();\n    ramDir2.close();\n    ramDir3.close();\n  }\n\n","sourceOld":"  public void testMultiTermDocs() throws IOException {\n    Directory ramDir1=newDirectory();\n    addDoc(random(), ramDir1, \"test foo\", true);\n    Directory ramDir2=newDirectory();\n    addDoc(random(), ramDir2, \"test blah\", true);\n    Directory ramDir3=newDirectory();\n    addDoc(random(), ramDir3, \"test wow\", true);\n\n    IndexReader[] readers1 = new IndexReader[]{DirectoryReader.open(ramDir1), DirectoryReader.open(ramDir3)};\n    IndexReader[] readers2 = new IndexReader[]{DirectoryReader.open(ramDir1), DirectoryReader.open(ramDir2), DirectoryReader.open(ramDir3)};\n    MultiReader mr2 = new MultiReader(readers1);\n    MultiReader mr3 = new MultiReader(readers2);\n\n    // test mixing up TermDocs and TermEnums from different readers.\n    TermsEnum te2 = MultiFields.getTerms(mr2, \"body\").iterator();\n    te2.seekCeil(new BytesRef(\"wow\"));\n    PostingsEnum td = TestUtil.docs(random(), mr2,\n        \"body\",\n        te2.term(),\n        MultiFields.getLiveDocs(mr2),\n        null,\n        0);\n\n    TermsEnum te3 = MultiFields.getTerms(mr3, \"body\").iterator();\n    te3.seekCeil(new BytesRef(\"wow\"));\n    td = TestUtil.docs(random(), te3, MultiFields.getLiveDocs(mr3),\n        td,\n        0);\n    \n    int ret = 0;\n\n    // This should blow up if we forget to check that the TermEnum is from the same\n    // reader as the TermDocs.\n    while (td.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) ret += td.docID();\n\n    // really a dummy assert to ensure that we got some docs and to ensure that\n    // nothing is eliminated by hotspot\n    assertTrue(ret > 0);\n    readers1[0].close();\n    readers1[1].close();\n    readers2[0].close();\n    readers2[1].close();\n    readers2[2].close();\n    ramDir1.close();\n    ramDir2.close();\n    ramDir3.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"04e775de416dd2d8067b10db1c8af975a1d5017e","date":1539906554,"type":3,"author":"David Smiley","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDirectoryReader#testMultiTermDocs().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDirectoryReader#testMultiTermDocs().mjava","sourceNew":"  public void testMultiTermDocs() throws IOException {\n    Directory ramDir1=newDirectory();\n    addDoc(random(), ramDir1, \"test foo\", true);\n    Directory ramDir2=newDirectory();\n    addDoc(random(), ramDir2, \"test blah\", true);\n    Directory ramDir3=newDirectory();\n    addDoc(random(), ramDir3, \"test wow\", true);\n\n    IndexReader[] readers1 = new IndexReader[]{DirectoryReader.open(ramDir1), DirectoryReader.open(ramDir3)};\n    IndexReader[] readers2 = new IndexReader[]{DirectoryReader.open(ramDir1), DirectoryReader.open(ramDir2), DirectoryReader.open(ramDir3)};\n    MultiReader mr2 = new MultiReader(readers1);\n    MultiReader mr3 = new MultiReader(readers2);\n\n    // test mixing up TermDocs and TermEnums from different readers.\n    TermsEnum te2 = MultiTerms.getTerms(mr2, \"body\").iterator();\n    te2.seekCeil(new BytesRef(\"wow\"));\n    PostingsEnum td = TestUtil.docs(random(), mr2,\n        \"body\",\n        te2.term(),\n        null,\n        0);\n\n    TermsEnum te3 = MultiTerms.getTerms(mr3, \"body\").iterator();\n    te3.seekCeil(new BytesRef(\"wow\"));\n    td = TestUtil.docs(random(), te3,\n        td,\n        0);\n    \n    int ret = 0;\n\n    // This should blow up if we forget to check that the TermEnum is from the same\n    // reader as the TermDocs.\n    while (td.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) ret += td.docID();\n\n    // really a dummy assert to ensure that we got some docs and to ensure that\n    // nothing is eliminated by hotspot\n    assertTrue(ret > 0);\n    readers1[0].close();\n    readers1[1].close();\n    readers2[0].close();\n    readers2[1].close();\n    readers2[2].close();\n    ramDir1.close();\n    ramDir2.close();\n    ramDir3.close();\n  }\n\n","sourceOld":"  public void testMultiTermDocs() throws IOException {\n    Directory ramDir1=newDirectory();\n    addDoc(random(), ramDir1, \"test foo\", true);\n    Directory ramDir2=newDirectory();\n    addDoc(random(), ramDir2, \"test blah\", true);\n    Directory ramDir3=newDirectory();\n    addDoc(random(), ramDir3, \"test wow\", true);\n\n    IndexReader[] readers1 = new IndexReader[]{DirectoryReader.open(ramDir1), DirectoryReader.open(ramDir3)};\n    IndexReader[] readers2 = new IndexReader[]{DirectoryReader.open(ramDir1), DirectoryReader.open(ramDir2), DirectoryReader.open(ramDir3)};\n    MultiReader mr2 = new MultiReader(readers1);\n    MultiReader mr3 = new MultiReader(readers2);\n\n    // test mixing up TermDocs and TermEnums from different readers.\n    TermsEnum te2 = MultiFields.getTerms(mr2, \"body\").iterator();\n    te2.seekCeil(new BytesRef(\"wow\"));\n    PostingsEnum td = TestUtil.docs(random(), mr2,\n        \"body\",\n        te2.term(),\n        null,\n        0);\n\n    TermsEnum te3 = MultiFields.getTerms(mr3, \"body\").iterator();\n    te3.seekCeil(new BytesRef(\"wow\"));\n    td = TestUtil.docs(random(), te3,\n        td,\n        0);\n    \n    int ret = 0;\n\n    // This should blow up if we forget to check that the TermEnum is from the same\n    // reader as the TermDocs.\n    while (td.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) ret += td.docID();\n\n    // really a dummy assert to ensure that we got some docs and to ensure that\n    // nothing is eliminated by hotspot\n    assertTrue(ret > 0);\n    readers1[0].close();\n    readers1[1].close();\n    readers2[0].close();\n    readers2[1].close();\n    readers2[2].close();\n    ramDir1.close();\n    ramDir2.close();\n    ramDir3.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"0a773283ef5eab2e9c7136eeb66574a4b7a2dc82":["51f5280f31484820499077f41fcdfe92d527d9dc"],"83e99d44c4a660a48c0fcc7a0108ad0a56dc2f87":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab":["83e99d44c4a660a48c0fcc7a0108ad0a56dc2f87","f08557cdb6c60ac7b88a9342c983a20cd236e74f"],"6613659748fe4411a7dcf85266e55db1f95f7315":["02331260bb246364779cb6f04919ca47900d01bb"],"f08557cdb6c60ac7b88a9342c983a20cd236e74f":["83e99d44c4a660a48c0fcc7a0108ad0a56dc2f87"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"51f5280f31484820499077f41fcdfe92d527d9dc":["6613659748fe4411a7dcf85266e55db1f95f7315"],"0f4464508ee83288c8c4585b533f9faaa93aa314":["0a773283ef5eab2e9c7136eeb66574a4b7a2dc82"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f":["629c38c4ae4e303d0617e05fbfe508140b32f0a3","02331260bb246364779cb6f04919ca47900d01bb"],"d6f074e73200c07d54f242d3880a8da5a35ff97b":["629c38c4ae4e303d0617e05fbfe508140b32f0a3","02331260bb246364779cb6f04919ca47900d01bb"],"04e775de416dd2d8067b10db1c8af975a1d5017e":["0f4464508ee83288c8c4585b533f9faaa93aa314"],"629c38c4ae4e303d0617e05fbfe508140b32f0a3":["f08557cdb6c60ac7b88a9342c983a20cd236e74f"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["04e775de416dd2d8067b10db1c8af975a1d5017e"],"02331260bb246364779cb6f04919ca47900d01bb":["629c38c4ae4e303d0617e05fbfe508140b32f0a3"]},"commit2Childs":{"0a773283ef5eab2e9c7136eeb66574a4b7a2dc82":["0f4464508ee83288c8c4585b533f9faaa93aa314"],"83e99d44c4a660a48c0fcc7a0108ad0a56dc2f87":["9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab","f08557cdb6c60ac7b88a9342c983a20cd236e74f"],"9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab":[],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["83e99d44c4a660a48c0fcc7a0108ad0a56dc2f87"],"f08557cdb6c60ac7b88a9342c983a20cd236e74f":["9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab","629c38c4ae4e303d0617e05fbfe508140b32f0a3"],"6613659748fe4411a7dcf85266e55db1f95f7315":["51f5280f31484820499077f41fcdfe92d527d9dc"],"51f5280f31484820499077f41fcdfe92d527d9dc":["0a773283ef5eab2e9c7136eeb66574a4b7a2dc82"],"0f4464508ee83288c8c4585b533f9faaa93aa314":["04e775de416dd2d8067b10db1c8af975a1d5017e"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f":[],"d6f074e73200c07d54f242d3880a8da5a35ff97b":[],"04e775de416dd2d8067b10db1c8af975a1d5017e":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"629c38c4ae4e303d0617e05fbfe508140b32f0a3":["b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f","d6f074e73200c07d54f242d3880a8da5a35ff97b","02331260bb246364779cb6f04919ca47900d01bb"],"02331260bb246364779cb6f04919ca47900d01bb":["6613659748fe4411a7dcf85266e55db1f95f7315","b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f","d6f074e73200c07d54f242d3880a8da5a35ff97b"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab","b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f","d6f074e73200c07d54f242d3880a8da5a35ff97b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}