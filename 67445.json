{"path":"lucene/analysis/common/src/test/org/apache/lucene/analysis/pattern/TestPatternTokenizer#testHeapFreedAfterClose().mjava","commits":[{"id":"321859132a55878a0a5004be77840a9f69b3f699","date":1446754259,"type":0,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/analysis/common/src/test/org/apache/lucene/analysis/pattern/TestPatternTokenizer#testHeapFreedAfterClose().mjava","pathOld":"/dev/null","sourceNew":"  // LUCENE-6814\n  public void testHeapFreedAfterClose() throws Exception {\n    // TODO: can we move this to BaseTSTC to catch other \"hangs onto heap\"ers?\n\n    // Build a 1MB string:\n    StringBuilder b = new StringBuilder();\n    for(int i=0;i<1024;i++) {\n      // 1023 spaces, then an x\n      for(int j=0;j<1023;j++) {\n        b.append(' ');\n      }\n      b.append('x');\n    }\n\n    String big = b.toString();\n\n    Pattern x = Pattern.compile(\"x\");\n\n    List<Tokenizer> tokenizers = new ArrayList<>();\n    for(int i=0;i<512;i++) {\n      Tokenizer stream = new PatternTokenizer(x, -1);\n      tokenizers.add(stream);\n      stream.setReader(new StringReader(big));\n      stream.reset();\n      for(int j=0;j<1024;j++) {\n        assertTrue(stream.incrementToken());\n      }\n      assertFalse(stream.incrementToken());\n      stream.end();\n      stream.close();\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fc1e9ddca40a3ddf8b097f2cf1fe2547fe8e384f","date":1579652839,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/analysis/common/src/test/org/apache/lucene/analysis/pattern/TestPatternTokenizer#testHeapFreedAfterClose().mjava","pathOld":"lucene/analysis/common/src/test/org/apache/lucene/analysis/pattern/TestPatternTokenizer#testHeapFreedAfterClose().mjava","sourceNew":"  // LUCENE-6814\n  @Nightly\n  public void testHeapFreedAfterClose() throws Exception {\n    // TODO: can we move this to BaseTSTC to catch other \"hangs onto heap\"ers?\n\n    // Build a 1MB string:\n    StringBuilder b = new StringBuilder();\n    for(int i=0;i<1024;i++) {\n      // 1023 spaces, then an x\n      for(int j=0;j<1023;j++) {\n        b.append(' ');\n      }\n      b.append('x');\n    }\n\n    String big = b.toString();\n\n    Pattern x = Pattern.compile(\"x\");\n\n    List<Tokenizer> tokenizers = new ArrayList<>();\n    for(int i=0;i<512;i++) {\n      Tokenizer stream = new PatternTokenizer(x, -1);\n      tokenizers.add(stream);\n      stream.setReader(new StringReader(big));\n      stream.reset();\n      for(int j=0;j<1024;j++) {\n        assertTrue(stream.incrementToken());\n      }\n      assertFalse(stream.incrementToken());\n      stream.end();\n      stream.close();\n    }\n  }\n\n","sourceOld":"  // LUCENE-6814\n  public void testHeapFreedAfterClose() throws Exception {\n    // TODO: can we move this to BaseTSTC to catch other \"hangs onto heap\"ers?\n\n    // Build a 1MB string:\n    StringBuilder b = new StringBuilder();\n    for(int i=0;i<1024;i++) {\n      // 1023 spaces, then an x\n      for(int j=0;j<1023;j++) {\n        b.append(' ');\n      }\n      b.append('x');\n    }\n\n    String big = b.toString();\n\n    Pattern x = Pattern.compile(\"x\");\n\n    List<Tokenizer> tokenizers = new ArrayList<>();\n    for(int i=0;i<512;i++) {\n      Tokenizer stream = new PatternTokenizer(x, -1);\n      tokenizers.add(stream);\n      stream.setReader(new StringReader(big));\n      stream.reset();\n      for(int j=0;j<1024;j++) {\n        assertTrue(stream.incrementToken());\n      }\n      assertFalse(stream.incrementToken());\n      stream.end();\n      stream.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"fc1e9ddca40a3ddf8b097f2cf1fe2547fe8e384f":["321859132a55878a0a5004be77840a9f69b3f699"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"321859132a55878a0a5004be77840a9f69b3f699":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["fc1e9ddca40a3ddf8b097f2cf1fe2547fe8e384f"]},"commit2Childs":{"fc1e9ddca40a3ddf8b097f2cf1fe2547fe8e384f":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["321859132a55878a0a5004be77840a9f69b3f699"],"321859132a55878a0a5004be77840a9f69b3f699":["fc1e9ddca40a3ddf8b097f2cf1fe2547fe8e384f"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}