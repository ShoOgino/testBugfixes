{"path":"lucene/core/src/test/org/apache/lucene/search/TestShardSearching#testSimple().mjava","commits":[{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":1,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestShardSearching#testSimple().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestShardSearching#testSimple().mjava","sourceNew":"  public void testSimple() throws Exception {\n    final int numNodes = _TestUtil.nextInt(random, 1, 10);\n\n    final double runTimeSec = atLeast(3);\n\n    final int minDocsToMakeTerms = _TestUtil.nextInt(random, 5, 20);\n\n    final int maxSearcherAgeSeconds = _TestUtil.nextInt(random, 1, 3);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: numNodes=\" + numNodes + \" runTimeSec=\" + runTimeSec + \" maxSearcherAgeSeconds=\" + maxSearcherAgeSeconds);\n    }\n\n    start(_TestUtil.getTempDir(\"TestShardSearching\").toString(),\n          numNodes,\n          runTimeSec,\n          maxSearcherAgeSeconds\n          );\n\n    final List<PreviousSearchState> priorSearches = new ArrayList<PreviousSearchState>();\n    List<BytesRef> terms = null;\n    while (System.nanoTime() < endTimeNanos) {\n\n      final boolean doFollowon = priorSearches.size() > 0 && random.nextInt(7) == 1;\n\n      // Pick a random node; we will run the query on this node:\n      final int myNodeID = random.nextInt(numNodes);\n\n      final NodeState.ShardIndexSearcher localShardSearcher;\n\n      final PreviousSearchState prevSearchState;\n\n      if (doFollowon) {\n        // Pretend user issued a followon query:\n        prevSearchState = priorSearches.get(random.nextInt(priorSearches.size()));\n\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: follow-on query age=\" + ((System.nanoTime() - prevSearchState.searchTimeNanos)/1000000000.0));\n        }\n\n        try {\n          localShardSearcher = nodes[myNodeID].acquire(prevSearchState.versions);\n        } catch (SearcherExpiredException see) {\n          // Expected, sometimes; in a \"real\" app we would\n          // either forward this error to the user (\"too\n          // much time has passed; please re-run your\n          // search\") or sneakily just switch to newest\n          // searcher w/o telling them...\n          if (VERBOSE) {\n            System.out.println(\"  searcher expired during local shard searcher init: \" + see);\n          }\n          priorSearches.remove(prevSearchState);\n          continue;\n        }\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: fresh query\");\n        }\n        // Do fresh query:\n        localShardSearcher = nodes[myNodeID].acquire();\n        prevSearchState = null;\n      }\n\n      final IndexReader[] subs = new IndexReader[numNodes];\n\n      PreviousSearchState searchState = null;\n\n      try {\n\n        // Mock: now make a single reader (MultiReader) from all node\n        // searchers.  In a real shard env you can't do this... we\n        // do it to confirm results from the shard searcher\n        // are correct:\n        int docCount = 0;\n        try {\n          for(int nodeID=0;nodeID<numNodes;nodeID++) {\n            final long subVersion = localShardSearcher.nodeVersions[nodeID];\n            final IndexSearcher sub = nodes[nodeID].searchers.acquire(subVersion);\n            if (sub == null) {\n              nodeID--;\n              while(nodeID >= 0) {\n                subs[nodeID].decRef();\n                subs[nodeID] = null;\n                nodeID--;\n              }\n              throw new SearcherExpiredException(\"nodeID=\" + nodeID + \" version=\" + subVersion);\n            }\n            subs[nodeID] = sub.getIndexReader();\n            docCount += subs[nodeID].maxDoc();\n          }\n        } catch (SearcherExpiredException see) {\n          // Expected\n          if (VERBOSE) {\n            System.out.println(\"  searcher expired during mock reader init: \" + see);\n          }\n          continue;\n        }\n\n        final IndexReader mockReader = new MultiReader(subs);\n        final IndexSearcher mockSearcher = new IndexSearcher(mockReader);\n\n        Query query;\n        Sort sort;\n\n        if (prevSearchState != null) {\n          query = prevSearchState.query;\n          sort = prevSearchState.sort;\n        } else {\n          if (terms == null && docCount > minDocsToMakeTerms) {\n            // TODO: try to \"focus\" on high freq terms sometimes too\n            // TODO: maybe also periodically reset the terms...?\n            final TermsEnum termsEnum = MultiFields.getTerms(mockReader, \"body\").iterator(null);\n            terms = new ArrayList<BytesRef>();\n            while(termsEnum.next() != null) {\n              terms.add(BytesRef.deepCopyOf(termsEnum.term()));\n            }\n            if (VERBOSE) {\n              System.out.println(\"TEST: init terms: \" + terms.size() + \" terms\");\n            }\n            if (terms.size() == 0) {\n              terms = null;\n            }\n          }\n\n          if (VERBOSE) {\n            System.out.println(\"  maxDoc=\" + mockReader.maxDoc());\n          }\n\n          if (terms != null) {\n            if (random.nextBoolean()) {\n              query = new TermQuery(new Term(\"body\", terms.get(random.nextInt(terms.size()))));\n            } else {\n              final String t = terms.get(random.nextInt(terms.size())).utf8ToString();\n              final String prefix;\n              if (t.length() <= 1) {\n                prefix = t;\n              } else {\n                prefix = t.substring(0, _TestUtil.nextInt(random, 1, 2));\n              }\n              query = new PrefixQuery(new Term(\"body\", prefix));\n            }\n            \n            if (random.nextBoolean()) {\n              sort = null;\n            } else {\n              // TODO: sort by more than 1 field\n              final int what = random.nextInt(3);\n              if (what == 0) {\n                sort = new Sort(SortField.FIELD_SCORE);\n              } else if (what == 1) {\n                // TODO: this sort doesn't merge\n                // correctly... it's tricky because you\n                // could have > 2.1B docs across all shards: \n                //sort = new Sort(SortField.FIELD_DOC);\n                sort = null;\n              } else if (what == 2) {\n                sort = new Sort(new SortField[] {new SortField(\"docid\", SortField.Type.INT, random.nextBoolean())});\n              } else {\n                sort = new Sort(new SortField[] {new SortField(\"title\", SortField.Type.STRING, random.nextBoolean())});\n              }\n            }\n          } else {\n            query = null;\n            sort = null;\n          }\n        }\n\n        if (query != null) {\n\n          try {\n            searchState = assertSame(mockSearcher, localShardSearcher, query, sort, prevSearchState);\n          } catch (SearcherExpiredException see) {\n            // Expected; in a \"real\" app we would\n            // either forward this error to the user (\"too\n            // much time has passed; please re-run your\n            // search\") or sneakily just switch to newest\n            // searcher w/o telling them...\n            if (VERBOSE) {\n              System.out.println(\"  searcher expired during search: \" + see);\n              see.printStackTrace(System.out);\n            }\n            assert prevSearchState != null;\n            priorSearches.remove(prevSearchState);\n          }\n        }\n      } finally {\n        nodes[myNodeID].release(localShardSearcher);\n        for(IndexReader sub : subs) {\n          if (sub != null) {\n            sub.decRef();\n          }\n        }\n      }\n\n      if (searchState != null && searchState.searchAfterLocal != null && random.nextInt(5) == 3) {\n        priorSearches.add(searchState);\n        if (priorSearches.size() > 200) {\n          Collections.shuffle(priorSearches, random);\n          priorSearches.subList(100, priorSearches.size()).clear();\n        }\n      }\n    }\n\n    finish();\n  }\n\n","sourceOld":"  public void testSimple() throws Exception {\n    final int numNodes = _TestUtil.nextInt(random, 1, 10);\n\n    final double runTimeSec = atLeast(3);\n\n    final int minDocsToMakeTerms = _TestUtil.nextInt(random, 5, 20);\n\n    final int maxSearcherAgeSeconds = _TestUtil.nextInt(random, 1, 3);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: numNodes=\" + numNodes + \" runTimeSec=\" + runTimeSec + \" maxSearcherAgeSeconds=\" + maxSearcherAgeSeconds);\n    }\n\n    start(_TestUtil.getTempDir(\"TestShardSearching\").toString(),\n          numNodes,\n          runTimeSec,\n          maxSearcherAgeSeconds\n          );\n\n    final List<PreviousSearchState> priorSearches = new ArrayList<PreviousSearchState>();\n    List<BytesRef> terms = null;\n    while (System.nanoTime() < endTimeNanos) {\n\n      final boolean doFollowon = priorSearches.size() > 0 && random.nextInt(7) == 1;\n\n      // Pick a random node; we will run the query on this node:\n      final int myNodeID = random.nextInt(numNodes);\n\n      final NodeState.ShardIndexSearcher localShardSearcher;\n\n      final PreviousSearchState prevSearchState;\n\n      if (doFollowon) {\n        // Pretend user issued a followon query:\n        prevSearchState = priorSearches.get(random.nextInt(priorSearches.size()));\n\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: follow-on query age=\" + ((System.nanoTime() - prevSearchState.searchTimeNanos)/1000000000.0));\n        }\n\n        try {\n          localShardSearcher = nodes[myNodeID].acquire(prevSearchState.versions);\n        } catch (SearcherExpiredException see) {\n          // Expected, sometimes; in a \"real\" app we would\n          // either forward this error to the user (\"too\n          // much time has passed; please re-run your\n          // search\") or sneakily just switch to newest\n          // searcher w/o telling them...\n          if (VERBOSE) {\n            System.out.println(\"  searcher expired during local shard searcher init: \" + see);\n          }\n          priorSearches.remove(prevSearchState);\n          continue;\n        }\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: fresh query\");\n        }\n        // Do fresh query:\n        localShardSearcher = nodes[myNodeID].acquire();\n        prevSearchState = null;\n      }\n\n      final IndexReader[] subs = new IndexReader[numNodes];\n\n      PreviousSearchState searchState = null;\n\n      try {\n\n        // Mock: now make a single reader (MultiReader) from all node\n        // searchers.  In a real shard env you can't do this... we\n        // do it to confirm results from the shard searcher\n        // are correct:\n        int docCount = 0;\n        try {\n          for(int nodeID=0;nodeID<numNodes;nodeID++) {\n            final long subVersion = localShardSearcher.nodeVersions[nodeID];\n            final IndexSearcher sub = nodes[nodeID].searchers.acquire(subVersion);\n            if (sub == null) {\n              nodeID--;\n              while(nodeID >= 0) {\n                subs[nodeID].decRef();\n                subs[nodeID] = null;\n                nodeID--;\n              }\n              throw new SearcherExpiredException(\"nodeID=\" + nodeID + \" version=\" + subVersion);\n            }\n            subs[nodeID] = sub.getIndexReader();\n            docCount += subs[nodeID].maxDoc();\n          }\n        } catch (SearcherExpiredException see) {\n          // Expected\n          if (VERBOSE) {\n            System.out.println(\"  searcher expired during mock reader init: \" + see);\n          }\n          continue;\n        }\n\n        final IndexReader mockReader = new MultiReader(subs);\n        final IndexSearcher mockSearcher = new IndexSearcher(mockReader);\n\n        Query query;\n        Sort sort;\n\n        if (prevSearchState != null) {\n          query = prevSearchState.query;\n          sort = prevSearchState.sort;\n        } else {\n          if (terms == null && docCount > minDocsToMakeTerms) {\n            // TODO: try to \"focus\" on high freq terms sometimes too\n            // TODO: maybe also periodically reset the terms...?\n            final TermsEnum termsEnum = MultiFields.getTerms(mockReader, \"body\").iterator(null);\n            terms = new ArrayList<BytesRef>();\n            while(termsEnum.next() != null) {\n              terms.add(BytesRef.deepCopyOf(termsEnum.term()));\n            }\n            if (VERBOSE) {\n              System.out.println(\"TEST: init terms: \" + terms.size() + \" terms\");\n            }\n            if (terms.size() == 0) {\n              terms = null;\n            }\n          }\n\n          if (VERBOSE) {\n            System.out.println(\"  maxDoc=\" + mockReader.maxDoc());\n          }\n\n          if (terms != null) {\n            if (random.nextBoolean()) {\n              query = new TermQuery(new Term(\"body\", terms.get(random.nextInt(terms.size()))));\n            } else {\n              final String t = terms.get(random.nextInt(terms.size())).utf8ToString();\n              final String prefix;\n              if (t.length() <= 1) {\n                prefix = t;\n              } else {\n                prefix = t.substring(0, _TestUtil.nextInt(random, 1, 2));\n              }\n              query = new PrefixQuery(new Term(\"body\", prefix));\n            }\n            \n            if (random.nextBoolean()) {\n              sort = null;\n            } else {\n              // TODO: sort by more than 1 field\n              final int what = random.nextInt(3);\n              if (what == 0) {\n                sort = new Sort(SortField.FIELD_SCORE);\n              } else if (what == 1) {\n                // TODO: this sort doesn't merge\n                // correctly... it's tricky because you\n                // could have > 2.1B docs across all shards: \n                //sort = new Sort(SortField.FIELD_DOC);\n                sort = null;\n              } else if (what == 2) {\n                sort = new Sort(new SortField[] {new SortField(\"docid\", SortField.Type.INT, random.nextBoolean())});\n              } else {\n                sort = new Sort(new SortField[] {new SortField(\"title\", SortField.Type.STRING, random.nextBoolean())});\n              }\n            }\n          } else {\n            query = null;\n            sort = null;\n          }\n        }\n\n        if (query != null) {\n\n          try {\n            searchState = assertSame(mockSearcher, localShardSearcher, query, sort, prevSearchState);\n          } catch (SearcherExpiredException see) {\n            // Expected; in a \"real\" app we would\n            // either forward this error to the user (\"too\n            // much time has passed; please re-run your\n            // search\") or sneakily just switch to newest\n            // searcher w/o telling them...\n            if (VERBOSE) {\n              System.out.println(\"  searcher expired during search: \" + see);\n              see.printStackTrace(System.out);\n            }\n            assert prevSearchState != null;\n            priorSearches.remove(prevSearchState);\n          }\n        }\n      } finally {\n        nodes[myNodeID].release(localShardSearcher);\n        for(IndexReader sub : subs) {\n          if (sub != null) {\n            sub.decRef();\n          }\n        }\n      }\n\n      if (searchState != null && searchState.searchAfterLocal != null && random.nextInt(5) == 3) {\n        priorSearches.add(searchState);\n        if (priorSearches.size() > 200) {\n          Collections.shuffle(priorSearches, random);\n          priorSearches.subList(100, priorSearches.size()).clear();\n        }\n      }\n    }\n\n    finish();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"629c38c4ae4e303d0617e05fbfe508140b32f0a3","date":1334500904,"type":3,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestShardSearching#testSimple().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestShardSearching#testSimple().mjava","sourceNew":"  public void testSimple() throws Exception {\n    final int numNodes = _TestUtil.nextInt(random(), 1, 10);\n\n    final double runTimeSec = atLeast(3);\n\n    final int minDocsToMakeTerms = _TestUtil.nextInt(random(), 5, 20);\n\n    final int maxSearcherAgeSeconds = _TestUtil.nextInt(random(), 1, 3);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: numNodes=\" + numNodes + \" runTimeSec=\" + runTimeSec + \" maxSearcherAgeSeconds=\" + maxSearcherAgeSeconds);\n    }\n\n    start(_TestUtil.getTempDir(\"TestShardSearching\").toString(),\n          numNodes,\n          runTimeSec,\n          maxSearcherAgeSeconds\n          );\n\n    final List<PreviousSearchState> priorSearches = new ArrayList<PreviousSearchState>();\n    List<BytesRef> terms = null;\n    while (System.nanoTime() < endTimeNanos) {\n\n      final boolean doFollowon = priorSearches.size() > 0 && random().nextInt(7) == 1;\n\n      // Pick a random node; we will run the query on this node:\n      final int myNodeID = random().nextInt(numNodes);\n\n      final NodeState.ShardIndexSearcher localShardSearcher;\n\n      final PreviousSearchState prevSearchState;\n\n      if (doFollowon) {\n        // Pretend user issued a followon query:\n        prevSearchState = priorSearches.get(random().nextInt(priorSearches.size()));\n\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: follow-on query age=\" + ((System.nanoTime() - prevSearchState.searchTimeNanos)/1000000000.0));\n        }\n\n        try {\n          localShardSearcher = nodes[myNodeID].acquire(prevSearchState.versions);\n        } catch (SearcherExpiredException see) {\n          // Expected, sometimes; in a \"real\" app we would\n          // either forward this error to the user (\"too\n          // much time has passed; please re-run your\n          // search\") or sneakily just switch to newest\n          // searcher w/o telling them...\n          if (VERBOSE) {\n            System.out.println(\"  searcher expired during local shard searcher init: \" + see);\n          }\n          priorSearches.remove(prevSearchState);\n          continue;\n        }\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: fresh query\");\n        }\n        // Do fresh query:\n        localShardSearcher = nodes[myNodeID].acquire();\n        prevSearchState = null;\n      }\n\n      final IndexReader[] subs = new IndexReader[numNodes];\n\n      PreviousSearchState searchState = null;\n\n      try {\n\n        // Mock: now make a single reader (MultiReader) from all node\n        // searchers.  In a real shard env you can't do this... we\n        // do it to confirm results from the shard searcher\n        // are correct:\n        int docCount = 0;\n        try {\n          for(int nodeID=0;nodeID<numNodes;nodeID++) {\n            final long subVersion = localShardSearcher.nodeVersions[nodeID];\n            final IndexSearcher sub = nodes[nodeID].searchers.acquire(subVersion);\n            if (sub == null) {\n              nodeID--;\n              while(nodeID >= 0) {\n                subs[nodeID].decRef();\n                subs[nodeID] = null;\n                nodeID--;\n              }\n              throw new SearcherExpiredException(\"nodeID=\" + nodeID + \" version=\" + subVersion);\n            }\n            subs[nodeID] = sub.getIndexReader();\n            docCount += subs[nodeID].maxDoc();\n          }\n        } catch (SearcherExpiredException see) {\n          // Expected\n          if (VERBOSE) {\n            System.out.println(\"  searcher expired during mock reader init: \" + see);\n          }\n          continue;\n        }\n\n        final IndexReader mockReader = new MultiReader(subs);\n        final IndexSearcher mockSearcher = new IndexSearcher(mockReader);\n\n        Query query;\n        Sort sort;\n\n        if (prevSearchState != null) {\n          query = prevSearchState.query;\n          sort = prevSearchState.sort;\n        } else {\n          if (terms == null && docCount > minDocsToMakeTerms) {\n            // TODO: try to \"focus\" on high freq terms sometimes too\n            // TODO: maybe also periodically reset the terms...?\n            final TermsEnum termsEnum = MultiFields.getTerms(mockReader, \"body\").iterator(null);\n            terms = new ArrayList<BytesRef>();\n            while(termsEnum.next() != null) {\n              terms.add(BytesRef.deepCopyOf(termsEnum.term()));\n            }\n            if (VERBOSE) {\n              System.out.println(\"TEST: init terms: \" + terms.size() + \" terms\");\n            }\n            if (terms.size() == 0) {\n              terms = null;\n            }\n          }\n\n          if (VERBOSE) {\n            System.out.println(\"  maxDoc=\" + mockReader.maxDoc());\n          }\n\n          if (terms != null) {\n            if (random().nextBoolean()) {\n              query = new TermQuery(new Term(\"body\", terms.get(random().nextInt(terms.size()))));\n            } else {\n              final String t = terms.get(random().nextInt(terms.size())).utf8ToString();\n              final String prefix;\n              if (t.length() <= 1) {\n                prefix = t;\n              } else {\n                prefix = t.substring(0, _TestUtil.nextInt(random(), 1, 2));\n              }\n              query = new PrefixQuery(new Term(\"body\", prefix));\n            }\n            \n            if (random().nextBoolean()) {\n              sort = null;\n            } else {\n              // TODO: sort by more than 1 field\n              final int what = random().nextInt(3);\n              if (what == 0) {\n                sort = new Sort(SortField.FIELD_SCORE);\n              } else if (what == 1) {\n                // TODO: this sort doesn't merge\n                // correctly... it's tricky because you\n                // could have > 2.1B docs across all shards: \n                //sort = new Sort(SortField.FIELD_DOC);\n                sort = null;\n              } else if (what == 2) {\n                sort = new Sort(new SortField[] {new SortField(\"docid\", SortField.Type.INT, random().nextBoolean())});\n              } else {\n                sort = new Sort(new SortField[] {new SortField(\"title\", SortField.Type.STRING, random().nextBoolean())});\n              }\n            }\n          } else {\n            query = null;\n            sort = null;\n          }\n        }\n\n        if (query != null) {\n\n          try {\n            searchState = assertSame(mockSearcher, localShardSearcher, query, sort, prevSearchState);\n          } catch (SearcherExpiredException see) {\n            // Expected; in a \"real\" app we would\n            // either forward this error to the user (\"too\n            // much time has passed; please re-run your\n            // search\") or sneakily just switch to newest\n            // searcher w/o telling them...\n            if (VERBOSE) {\n              System.out.println(\"  searcher expired during search: \" + see);\n              see.printStackTrace(System.out);\n            }\n            assert prevSearchState != null;\n            priorSearches.remove(prevSearchState);\n          }\n        }\n      } finally {\n        nodes[myNodeID].release(localShardSearcher);\n        for(IndexReader sub : subs) {\n          if (sub != null) {\n            sub.decRef();\n          }\n        }\n      }\n\n      if (searchState != null && searchState.searchAfterLocal != null && random().nextInt(5) == 3) {\n        priorSearches.add(searchState);\n        if (priorSearches.size() > 200) {\n          Collections.shuffle(priorSearches, random());\n          priorSearches.subList(100, priorSearches.size()).clear();\n        }\n      }\n    }\n\n    finish();\n  }\n\n","sourceOld":"  public void testSimple() throws Exception {\n    final int numNodes = _TestUtil.nextInt(random, 1, 10);\n\n    final double runTimeSec = atLeast(3);\n\n    final int minDocsToMakeTerms = _TestUtil.nextInt(random, 5, 20);\n\n    final int maxSearcherAgeSeconds = _TestUtil.nextInt(random, 1, 3);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: numNodes=\" + numNodes + \" runTimeSec=\" + runTimeSec + \" maxSearcherAgeSeconds=\" + maxSearcherAgeSeconds);\n    }\n\n    start(_TestUtil.getTempDir(\"TestShardSearching\").toString(),\n          numNodes,\n          runTimeSec,\n          maxSearcherAgeSeconds\n          );\n\n    final List<PreviousSearchState> priorSearches = new ArrayList<PreviousSearchState>();\n    List<BytesRef> terms = null;\n    while (System.nanoTime() < endTimeNanos) {\n\n      final boolean doFollowon = priorSearches.size() > 0 && random.nextInt(7) == 1;\n\n      // Pick a random node; we will run the query on this node:\n      final int myNodeID = random.nextInt(numNodes);\n\n      final NodeState.ShardIndexSearcher localShardSearcher;\n\n      final PreviousSearchState prevSearchState;\n\n      if (doFollowon) {\n        // Pretend user issued a followon query:\n        prevSearchState = priorSearches.get(random.nextInt(priorSearches.size()));\n\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: follow-on query age=\" + ((System.nanoTime() - prevSearchState.searchTimeNanos)/1000000000.0));\n        }\n\n        try {\n          localShardSearcher = nodes[myNodeID].acquire(prevSearchState.versions);\n        } catch (SearcherExpiredException see) {\n          // Expected, sometimes; in a \"real\" app we would\n          // either forward this error to the user (\"too\n          // much time has passed; please re-run your\n          // search\") or sneakily just switch to newest\n          // searcher w/o telling them...\n          if (VERBOSE) {\n            System.out.println(\"  searcher expired during local shard searcher init: \" + see);\n          }\n          priorSearches.remove(prevSearchState);\n          continue;\n        }\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: fresh query\");\n        }\n        // Do fresh query:\n        localShardSearcher = nodes[myNodeID].acquire();\n        prevSearchState = null;\n      }\n\n      final IndexReader[] subs = new IndexReader[numNodes];\n\n      PreviousSearchState searchState = null;\n\n      try {\n\n        // Mock: now make a single reader (MultiReader) from all node\n        // searchers.  In a real shard env you can't do this... we\n        // do it to confirm results from the shard searcher\n        // are correct:\n        int docCount = 0;\n        try {\n          for(int nodeID=0;nodeID<numNodes;nodeID++) {\n            final long subVersion = localShardSearcher.nodeVersions[nodeID];\n            final IndexSearcher sub = nodes[nodeID].searchers.acquire(subVersion);\n            if (sub == null) {\n              nodeID--;\n              while(nodeID >= 0) {\n                subs[nodeID].decRef();\n                subs[nodeID] = null;\n                nodeID--;\n              }\n              throw new SearcherExpiredException(\"nodeID=\" + nodeID + \" version=\" + subVersion);\n            }\n            subs[nodeID] = sub.getIndexReader();\n            docCount += subs[nodeID].maxDoc();\n          }\n        } catch (SearcherExpiredException see) {\n          // Expected\n          if (VERBOSE) {\n            System.out.println(\"  searcher expired during mock reader init: \" + see);\n          }\n          continue;\n        }\n\n        final IndexReader mockReader = new MultiReader(subs);\n        final IndexSearcher mockSearcher = new IndexSearcher(mockReader);\n\n        Query query;\n        Sort sort;\n\n        if (prevSearchState != null) {\n          query = prevSearchState.query;\n          sort = prevSearchState.sort;\n        } else {\n          if (terms == null && docCount > minDocsToMakeTerms) {\n            // TODO: try to \"focus\" on high freq terms sometimes too\n            // TODO: maybe also periodically reset the terms...?\n            final TermsEnum termsEnum = MultiFields.getTerms(mockReader, \"body\").iterator(null);\n            terms = new ArrayList<BytesRef>();\n            while(termsEnum.next() != null) {\n              terms.add(BytesRef.deepCopyOf(termsEnum.term()));\n            }\n            if (VERBOSE) {\n              System.out.println(\"TEST: init terms: \" + terms.size() + \" terms\");\n            }\n            if (terms.size() == 0) {\n              terms = null;\n            }\n          }\n\n          if (VERBOSE) {\n            System.out.println(\"  maxDoc=\" + mockReader.maxDoc());\n          }\n\n          if (terms != null) {\n            if (random.nextBoolean()) {\n              query = new TermQuery(new Term(\"body\", terms.get(random.nextInt(terms.size()))));\n            } else {\n              final String t = terms.get(random.nextInt(terms.size())).utf8ToString();\n              final String prefix;\n              if (t.length() <= 1) {\n                prefix = t;\n              } else {\n                prefix = t.substring(0, _TestUtil.nextInt(random, 1, 2));\n              }\n              query = new PrefixQuery(new Term(\"body\", prefix));\n            }\n            \n            if (random.nextBoolean()) {\n              sort = null;\n            } else {\n              // TODO: sort by more than 1 field\n              final int what = random.nextInt(3);\n              if (what == 0) {\n                sort = new Sort(SortField.FIELD_SCORE);\n              } else if (what == 1) {\n                // TODO: this sort doesn't merge\n                // correctly... it's tricky because you\n                // could have > 2.1B docs across all shards: \n                //sort = new Sort(SortField.FIELD_DOC);\n                sort = null;\n              } else if (what == 2) {\n                sort = new Sort(new SortField[] {new SortField(\"docid\", SortField.Type.INT, random.nextBoolean())});\n              } else {\n                sort = new Sort(new SortField[] {new SortField(\"title\", SortField.Type.STRING, random.nextBoolean())});\n              }\n            }\n          } else {\n            query = null;\n            sort = null;\n          }\n        }\n\n        if (query != null) {\n\n          try {\n            searchState = assertSame(mockSearcher, localShardSearcher, query, sort, prevSearchState);\n          } catch (SearcherExpiredException see) {\n            // Expected; in a \"real\" app we would\n            // either forward this error to the user (\"too\n            // much time has passed; please re-run your\n            // search\") or sneakily just switch to newest\n            // searcher w/o telling them...\n            if (VERBOSE) {\n              System.out.println(\"  searcher expired during search: \" + see);\n              see.printStackTrace(System.out);\n            }\n            assert prevSearchState != null;\n            priorSearches.remove(prevSearchState);\n          }\n        }\n      } finally {\n        nodes[myNodeID].release(localShardSearcher);\n        for(IndexReader sub : subs) {\n          if (sub != null) {\n            sub.decRef();\n          }\n        }\n      }\n\n      if (searchState != null && searchState.searchAfterLocal != null && random.nextInt(5) == 3) {\n        priorSearches.add(searchState);\n        if (priorSearches.size() > 200) {\n          Collections.shuffle(priorSearches, random);\n          priorSearches.subList(100, priorSearches.size()).clear();\n        }\n      }\n    }\n\n    finish();\n  }\n\n","bugFix":null,"bugIntro":["0ed6b1234af94a2693d3e6550e7b3ee41fd3f51c"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"ea8db162694636ac3d19d83debf895a9e089f96a","date":1343856398,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestShardSearching#testSimple().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestShardSearching#testSimple().mjava","sourceNew":"  public void testSimple() throws Exception {\n    final int numNodes = _TestUtil.nextInt(random(), 1, 10);\n\n    final double runTimeSec = atLeast(3);\n\n    final int minDocsToMakeTerms = _TestUtil.nextInt(random(), 5, 20);\n\n    final int maxSearcherAgeSeconds = _TestUtil.nextInt(random(), 1, 3);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: numNodes=\" + numNodes + \" runTimeSec=\" + runTimeSec + \" maxSearcherAgeSeconds=\" + maxSearcherAgeSeconds);\n    }\n\n    start(numNodes,\n          runTimeSec,\n          maxSearcherAgeSeconds\n          );\n\n    final List<PreviousSearchState> priorSearches = new ArrayList<PreviousSearchState>();\n    List<BytesRef> terms = null;\n    while (System.nanoTime() < endTimeNanos) {\n\n      final boolean doFollowon = priorSearches.size() > 0 && random().nextInt(7) == 1;\n\n      // Pick a random node; we will run the query on this node:\n      final int myNodeID = random().nextInt(numNodes);\n\n      final NodeState.ShardIndexSearcher localShardSearcher;\n\n      final PreviousSearchState prevSearchState;\n\n      if (doFollowon) {\n        // Pretend user issued a followon query:\n        prevSearchState = priorSearches.get(random().nextInt(priorSearches.size()));\n\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: follow-on query age=\" + ((System.nanoTime() - prevSearchState.searchTimeNanos)/1000000000.0));\n        }\n\n        try {\n          localShardSearcher = nodes[myNodeID].acquire(prevSearchState.versions);\n        } catch (SearcherExpiredException see) {\n          // Expected, sometimes; in a \"real\" app we would\n          // either forward this error to the user (\"too\n          // much time has passed; please re-run your\n          // search\") or sneakily just switch to newest\n          // searcher w/o telling them...\n          if (VERBOSE) {\n            System.out.println(\"  searcher expired during local shard searcher init: \" + see);\n          }\n          priorSearches.remove(prevSearchState);\n          continue;\n        }\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: fresh query\");\n        }\n        // Do fresh query:\n        localShardSearcher = nodes[myNodeID].acquire();\n        prevSearchState = null;\n      }\n\n      final IndexReader[] subs = new IndexReader[numNodes];\n\n      PreviousSearchState searchState = null;\n\n      try {\n\n        // Mock: now make a single reader (MultiReader) from all node\n        // searchers.  In a real shard env you can't do this... we\n        // do it to confirm results from the shard searcher\n        // are correct:\n        int docCount = 0;\n        try {\n          for(int nodeID=0;nodeID<numNodes;nodeID++) {\n            final long subVersion = localShardSearcher.nodeVersions[nodeID];\n            final IndexSearcher sub = nodes[nodeID].searchers.acquire(subVersion);\n            if (sub == null) {\n              nodeID--;\n              while(nodeID >= 0) {\n                subs[nodeID].decRef();\n                subs[nodeID] = null;\n                nodeID--;\n              }\n              throw new SearcherExpiredException(\"nodeID=\" + nodeID + \" version=\" + subVersion);\n            }\n            subs[nodeID] = sub.getIndexReader();\n            docCount += subs[nodeID].maxDoc();\n          }\n        } catch (SearcherExpiredException see) {\n          // Expected\n          if (VERBOSE) {\n            System.out.println(\"  searcher expired during mock reader init: \" + see);\n          }\n          continue;\n        }\n\n        final IndexReader mockReader = new MultiReader(subs);\n        final IndexSearcher mockSearcher = new IndexSearcher(mockReader);\n\n        Query query;\n        Sort sort;\n\n        if (prevSearchState != null) {\n          query = prevSearchState.query;\n          sort = prevSearchState.sort;\n        } else {\n          if (terms == null && docCount > minDocsToMakeTerms) {\n            // TODO: try to \"focus\" on high freq terms sometimes too\n            // TODO: maybe also periodically reset the terms...?\n            final TermsEnum termsEnum = MultiFields.getTerms(mockReader, \"body\").iterator(null);\n            terms = new ArrayList<BytesRef>();\n            while(termsEnum.next() != null) {\n              terms.add(BytesRef.deepCopyOf(termsEnum.term()));\n            }\n            if (VERBOSE) {\n              System.out.println(\"TEST: init terms: \" + terms.size() + \" terms\");\n            }\n            if (terms.size() == 0) {\n              terms = null;\n            }\n          }\n\n          if (VERBOSE) {\n            System.out.println(\"  maxDoc=\" + mockReader.maxDoc());\n          }\n\n          if (terms != null) {\n            if (random().nextBoolean()) {\n              query = new TermQuery(new Term(\"body\", terms.get(random().nextInt(terms.size()))));\n            } else {\n              final String t = terms.get(random().nextInt(terms.size())).utf8ToString();\n              final String prefix;\n              if (t.length() <= 1) {\n                prefix = t;\n              } else {\n                prefix = t.substring(0, _TestUtil.nextInt(random(), 1, 2));\n              }\n              query = new PrefixQuery(new Term(\"body\", prefix));\n            }\n            \n            if (random().nextBoolean()) {\n              sort = null;\n            } else {\n              // TODO: sort by more than 1 field\n              final int what = random().nextInt(3);\n              if (what == 0) {\n                sort = new Sort(SortField.FIELD_SCORE);\n              } else if (what == 1) {\n                // TODO: this sort doesn't merge\n                // correctly... it's tricky because you\n                // could have > 2.1B docs across all shards: \n                //sort = new Sort(SortField.FIELD_DOC);\n                sort = null;\n              } else if (what == 2) {\n                sort = new Sort(new SortField[] {new SortField(\"docid\", SortField.Type.INT, random().nextBoolean())});\n              } else {\n                sort = new Sort(new SortField[] {new SortField(\"title\", SortField.Type.STRING, random().nextBoolean())});\n              }\n            }\n          } else {\n            query = null;\n            sort = null;\n          }\n        }\n\n        if (query != null) {\n\n          try {\n            searchState = assertSame(mockSearcher, localShardSearcher, query, sort, prevSearchState);\n          } catch (SearcherExpiredException see) {\n            // Expected; in a \"real\" app we would\n            // either forward this error to the user (\"too\n            // much time has passed; please re-run your\n            // search\") or sneakily just switch to newest\n            // searcher w/o telling them...\n            if (VERBOSE) {\n              System.out.println(\"  searcher expired during search: \" + see);\n              see.printStackTrace(System.out);\n            }\n            assert prevSearchState != null;\n            priorSearches.remove(prevSearchState);\n          }\n        }\n      } finally {\n        nodes[myNodeID].release(localShardSearcher);\n        for(IndexReader sub : subs) {\n          if (sub != null) {\n            sub.decRef();\n          }\n        }\n      }\n\n      if (searchState != null && searchState.searchAfterLocal != null && random().nextInt(5) == 3) {\n        priorSearches.add(searchState);\n        if (priorSearches.size() > 200) {\n          Collections.shuffle(priorSearches, random());\n          priorSearches.subList(100, priorSearches.size()).clear();\n        }\n      }\n    }\n\n    finish();\n  }\n\n","sourceOld":"  public void testSimple() throws Exception {\n    final int numNodes = _TestUtil.nextInt(random(), 1, 10);\n\n    final double runTimeSec = atLeast(3);\n\n    final int minDocsToMakeTerms = _TestUtil.nextInt(random(), 5, 20);\n\n    final int maxSearcherAgeSeconds = _TestUtil.nextInt(random(), 1, 3);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: numNodes=\" + numNodes + \" runTimeSec=\" + runTimeSec + \" maxSearcherAgeSeconds=\" + maxSearcherAgeSeconds);\n    }\n\n    start(_TestUtil.getTempDir(\"TestShardSearching\").toString(),\n          numNodes,\n          runTimeSec,\n          maxSearcherAgeSeconds\n          );\n\n    final List<PreviousSearchState> priorSearches = new ArrayList<PreviousSearchState>();\n    List<BytesRef> terms = null;\n    while (System.nanoTime() < endTimeNanos) {\n\n      final boolean doFollowon = priorSearches.size() > 0 && random().nextInt(7) == 1;\n\n      // Pick a random node; we will run the query on this node:\n      final int myNodeID = random().nextInt(numNodes);\n\n      final NodeState.ShardIndexSearcher localShardSearcher;\n\n      final PreviousSearchState prevSearchState;\n\n      if (doFollowon) {\n        // Pretend user issued a followon query:\n        prevSearchState = priorSearches.get(random().nextInt(priorSearches.size()));\n\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: follow-on query age=\" + ((System.nanoTime() - prevSearchState.searchTimeNanos)/1000000000.0));\n        }\n\n        try {\n          localShardSearcher = nodes[myNodeID].acquire(prevSearchState.versions);\n        } catch (SearcherExpiredException see) {\n          // Expected, sometimes; in a \"real\" app we would\n          // either forward this error to the user (\"too\n          // much time has passed; please re-run your\n          // search\") or sneakily just switch to newest\n          // searcher w/o telling them...\n          if (VERBOSE) {\n            System.out.println(\"  searcher expired during local shard searcher init: \" + see);\n          }\n          priorSearches.remove(prevSearchState);\n          continue;\n        }\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: fresh query\");\n        }\n        // Do fresh query:\n        localShardSearcher = nodes[myNodeID].acquire();\n        prevSearchState = null;\n      }\n\n      final IndexReader[] subs = new IndexReader[numNodes];\n\n      PreviousSearchState searchState = null;\n\n      try {\n\n        // Mock: now make a single reader (MultiReader) from all node\n        // searchers.  In a real shard env you can't do this... we\n        // do it to confirm results from the shard searcher\n        // are correct:\n        int docCount = 0;\n        try {\n          for(int nodeID=0;nodeID<numNodes;nodeID++) {\n            final long subVersion = localShardSearcher.nodeVersions[nodeID];\n            final IndexSearcher sub = nodes[nodeID].searchers.acquire(subVersion);\n            if (sub == null) {\n              nodeID--;\n              while(nodeID >= 0) {\n                subs[nodeID].decRef();\n                subs[nodeID] = null;\n                nodeID--;\n              }\n              throw new SearcherExpiredException(\"nodeID=\" + nodeID + \" version=\" + subVersion);\n            }\n            subs[nodeID] = sub.getIndexReader();\n            docCount += subs[nodeID].maxDoc();\n          }\n        } catch (SearcherExpiredException see) {\n          // Expected\n          if (VERBOSE) {\n            System.out.println(\"  searcher expired during mock reader init: \" + see);\n          }\n          continue;\n        }\n\n        final IndexReader mockReader = new MultiReader(subs);\n        final IndexSearcher mockSearcher = new IndexSearcher(mockReader);\n\n        Query query;\n        Sort sort;\n\n        if (prevSearchState != null) {\n          query = prevSearchState.query;\n          sort = prevSearchState.sort;\n        } else {\n          if (terms == null && docCount > minDocsToMakeTerms) {\n            // TODO: try to \"focus\" on high freq terms sometimes too\n            // TODO: maybe also periodically reset the terms...?\n            final TermsEnum termsEnum = MultiFields.getTerms(mockReader, \"body\").iterator(null);\n            terms = new ArrayList<BytesRef>();\n            while(termsEnum.next() != null) {\n              terms.add(BytesRef.deepCopyOf(termsEnum.term()));\n            }\n            if (VERBOSE) {\n              System.out.println(\"TEST: init terms: \" + terms.size() + \" terms\");\n            }\n            if (terms.size() == 0) {\n              terms = null;\n            }\n          }\n\n          if (VERBOSE) {\n            System.out.println(\"  maxDoc=\" + mockReader.maxDoc());\n          }\n\n          if (terms != null) {\n            if (random().nextBoolean()) {\n              query = new TermQuery(new Term(\"body\", terms.get(random().nextInt(terms.size()))));\n            } else {\n              final String t = terms.get(random().nextInt(terms.size())).utf8ToString();\n              final String prefix;\n              if (t.length() <= 1) {\n                prefix = t;\n              } else {\n                prefix = t.substring(0, _TestUtil.nextInt(random(), 1, 2));\n              }\n              query = new PrefixQuery(new Term(\"body\", prefix));\n            }\n            \n            if (random().nextBoolean()) {\n              sort = null;\n            } else {\n              // TODO: sort by more than 1 field\n              final int what = random().nextInt(3);\n              if (what == 0) {\n                sort = new Sort(SortField.FIELD_SCORE);\n              } else if (what == 1) {\n                // TODO: this sort doesn't merge\n                // correctly... it's tricky because you\n                // could have > 2.1B docs across all shards: \n                //sort = new Sort(SortField.FIELD_DOC);\n                sort = null;\n              } else if (what == 2) {\n                sort = new Sort(new SortField[] {new SortField(\"docid\", SortField.Type.INT, random().nextBoolean())});\n              } else {\n                sort = new Sort(new SortField[] {new SortField(\"title\", SortField.Type.STRING, random().nextBoolean())});\n              }\n            }\n          } else {\n            query = null;\n            sort = null;\n          }\n        }\n\n        if (query != null) {\n\n          try {\n            searchState = assertSame(mockSearcher, localShardSearcher, query, sort, prevSearchState);\n          } catch (SearcherExpiredException see) {\n            // Expected; in a \"real\" app we would\n            // either forward this error to the user (\"too\n            // much time has passed; please re-run your\n            // search\") or sneakily just switch to newest\n            // searcher w/o telling them...\n            if (VERBOSE) {\n              System.out.println(\"  searcher expired during search: \" + see);\n              see.printStackTrace(System.out);\n            }\n            assert prevSearchState != null;\n            priorSearches.remove(prevSearchState);\n          }\n        }\n      } finally {\n        nodes[myNodeID].release(localShardSearcher);\n        for(IndexReader sub : subs) {\n          if (sub != null) {\n            sub.decRef();\n          }\n        }\n      }\n\n      if (searchState != null && searchState.searchAfterLocal != null && random().nextInt(5) == 3) {\n        priorSearches.add(searchState);\n        if (priorSearches.size() > 200) {\n          Collections.shuffle(priorSearches, random());\n          priorSearches.subList(100, priorSearches.size()).clear();\n        }\n      }\n    }\n\n    finish();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"8fd5be977c105554c6a7b68afcdbc511439723ab","date":1344115570,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestShardSearching#testSimple().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestShardSearching#testSimple().mjava","sourceNew":"  public void testSimple() throws Exception {\n    final int numNodes = _TestUtil.nextInt(random(), 1, 10);\n\n    final double runTimeSec = atLeast(3);\n\n    final int minDocsToMakeTerms = _TestUtil.nextInt(random(), 5, 20);\n\n    final int maxSearcherAgeSeconds = _TestUtil.nextInt(random(), 1, 3);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: numNodes=\" + numNodes + \" runTimeSec=\" + runTimeSec + \" maxSearcherAgeSeconds=\" + maxSearcherAgeSeconds);\n    }\n\n    start(numNodes,\n          runTimeSec,\n          maxSearcherAgeSeconds\n          );\n\n    final List<PreviousSearchState> priorSearches = new ArrayList<PreviousSearchState>();\n    List<BytesRef> terms = null;\n    while (System.nanoTime() < endTimeNanos) {\n\n      final boolean doFollowon = priorSearches.size() > 0 && random().nextInt(7) == 1;\n\n      // Pick a random node; we will run the query on this node:\n      final int myNodeID = random().nextInt(numNodes);\n\n      final NodeState.ShardIndexSearcher localShardSearcher;\n\n      final PreviousSearchState prevSearchState;\n\n      if (doFollowon) {\n        // Pretend user issued a followon query:\n        prevSearchState = priorSearches.get(random().nextInt(priorSearches.size()));\n\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: follow-on query age=\" + ((System.nanoTime() - prevSearchState.searchTimeNanos)/1000000000.0));\n        }\n\n        try {\n          localShardSearcher = nodes[myNodeID].acquire(prevSearchState.versions);\n        } catch (SearcherExpiredException see) {\n          // Expected, sometimes; in a \"real\" app we would\n          // either forward this error to the user (\"too\n          // much time has passed; please re-run your\n          // search\") or sneakily just switch to newest\n          // searcher w/o telling them...\n          if (VERBOSE) {\n            System.out.println(\"  searcher expired during local shard searcher init: \" + see);\n          }\n          priorSearches.remove(prevSearchState);\n          continue;\n        }\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: fresh query\");\n        }\n        // Do fresh query:\n        localShardSearcher = nodes[myNodeID].acquire();\n        prevSearchState = null;\n      }\n\n      final IndexReader[] subs = new IndexReader[numNodes];\n\n      PreviousSearchState searchState = null;\n\n      try {\n\n        // Mock: now make a single reader (MultiReader) from all node\n        // searchers.  In a real shard env you can't do this... we\n        // do it to confirm results from the shard searcher\n        // are correct:\n        int docCount = 0;\n        try {\n          for(int nodeID=0;nodeID<numNodes;nodeID++) {\n            final long subVersion = localShardSearcher.nodeVersions[nodeID];\n            final IndexSearcher sub = nodes[nodeID].searchers.acquire(subVersion);\n            if (sub == null) {\n              nodeID--;\n              while(nodeID >= 0) {\n                subs[nodeID].decRef();\n                subs[nodeID] = null;\n                nodeID--;\n              }\n              throw new SearcherExpiredException(\"nodeID=\" + nodeID + \" version=\" + subVersion);\n            }\n            subs[nodeID] = sub.getIndexReader();\n            docCount += subs[nodeID].maxDoc();\n          }\n        } catch (SearcherExpiredException see) {\n          // Expected\n          if (VERBOSE) {\n            System.out.println(\"  searcher expired during mock reader init: \" + see);\n          }\n          continue;\n        }\n\n        final IndexReader mockReader = new MultiReader(subs);\n        final IndexSearcher mockSearcher = new IndexSearcher(mockReader);\n\n        Query query;\n        Sort sort;\n\n        if (prevSearchState != null) {\n          query = prevSearchState.query;\n          sort = prevSearchState.sort;\n        } else {\n          if (terms == null && docCount > minDocsToMakeTerms) {\n            // TODO: try to \"focus\" on high freq terms sometimes too\n            // TODO: maybe also periodically reset the terms...?\n            final TermsEnum termsEnum = MultiFields.getTerms(mockReader, \"body\").iterator(null);\n            terms = new ArrayList<BytesRef>();\n            while(termsEnum.next() != null) {\n              terms.add(BytesRef.deepCopyOf(termsEnum.term()));\n            }\n            if (VERBOSE) {\n              System.out.println(\"TEST: init terms: \" + terms.size() + \" terms\");\n            }\n            if (terms.size() == 0) {\n              terms = null;\n            }\n          }\n\n          if (VERBOSE) {\n            System.out.println(\"  maxDoc=\" + mockReader.maxDoc());\n          }\n\n          if (terms != null) {\n            if (random().nextBoolean()) {\n              query = new TermQuery(new Term(\"body\", terms.get(random().nextInt(terms.size()))));\n            } else {\n              final String t = terms.get(random().nextInt(terms.size())).utf8ToString();\n              final String prefix;\n              if (t.length() <= 1) {\n                prefix = t;\n              } else {\n                prefix = t.substring(0, _TestUtil.nextInt(random(), 1, 2));\n              }\n              query = new PrefixQuery(new Term(\"body\", prefix));\n            }\n            \n            if (random().nextBoolean()) {\n              sort = null;\n            } else {\n              // TODO: sort by more than 1 field\n              final int what = random().nextInt(3);\n              if (what == 0) {\n                sort = new Sort(SortField.FIELD_SCORE);\n              } else if (what == 1) {\n                // TODO: this sort doesn't merge\n                // correctly... it's tricky because you\n                // could have > 2.1B docs across all shards: \n                //sort = new Sort(SortField.FIELD_DOC);\n                sort = null;\n              } else if (what == 2) {\n                sort = new Sort(new SortField[] {new SortField(\"docid\", SortField.Type.INT, random().nextBoolean())});\n              } else {\n                sort = new Sort(new SortField[] {new SortField(\"title\", SortField.Type.STRING, random().nextBoolean())});\n              }\n            }\n          } else {\n            query = null;\n            sort = null;\n          }\n        }\n\n        if (query != null) {\n\n          try {\n            searchState = assertSame(mockSearcher, localShardSearcher, query, sort, prevSearchState);\n          } catch (SearcherExpiredException see) {\n            // Expected; in a \"real\" app we would\n            // either forward this error to the user (\"too\n            // much time has passed; please re-run your\n            // search\") or sneakily just switch to newest\n            // searcher w/o telling them...\n            if (VERBOSE) {\n              System.out.println(\"  searcher expired during search: \" + see);\n              see.printStackTrace(System.out);\n            }\n            assert prevSearchState != null;\n            priorSearches.remove(prevSearchState);\n          }\n        }\n      } finally {\n        nodes[myNodeID].release(localShardSearcher);\n        for(IndexReader sub : subs) {\n          if (sub != null) {\n            sub.decRef();\n          }\n        }\n      }\n\n      if (searchState != null && searchState.searchAfterLocal != null && random().nextInt(5) == 3) {\n        priorSearches.add(searchState);\n        if (priorSearches.size() > 200) {\n          Collections.shuffle(priorSearches, random());\n          priorSearches.subList(100, priorSearches.size()).clear();\n        }\n      }\n    }\n\n    finish();\n  }\n\n","sourceOld":"  public void testSimple() throws Exception {\n    final int numNodes = _TestUtil.nextInt(random(), 1, 10);\n\n    final double runTimeSec = atLeast(3);\n\n    final int minDocsToMakeTerms = _TestUtil.nextInt(random(), 5, 20);\n\n    final int maxSearcherAgeSeconds = _TestUtil.nextInt(random(), 1, 3);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: numNodes=\" + numNodes + \" runTimeSec=\" + runTimeSec + \" maxSearcherAgeSeconds=\" + maxSearcherAgeSeconds);\n    }\n\n    start(_TestUtil.getTempDir(\"TestShardSearching\").toString(),\n          numNodes,\n          runTimeSec,\n          maxSearcherAgeSeconds\n          );\n\n    final List<PreviousSearchState> priorSearches = new ArrayList<PreviousSearchState>();\n    List<BytesRef> terms = null;\n    while (System.nanoTime() < endTimeNanos) {\n\n      final boolean doFollowon = priorSearches.size() > 0 && random().nextInt(7) == 1;\n\n      // Pick a random node; we will run the query on this node:\n      final int myNodeID = random().nextInt(numNodes);\n\n      final NodeState.ShardIndexSearcher localShardSearcher;\n\n      final PreviousSearchState prevSearchState;\n\n      if (doFollowon) {\n        // Pretend user issued a followon query:\n        prevSearchState = priorSearches.get(random().nextInt(priorSearches.size()));\n\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: follow-on query age=\" + ((System.nanoTime() - prevSearchState.searchTimeNanos)/1000000000.0));\n        }\n\n        try {\n          localShardSearcher = nodes[myNodeID].acquire(prevSearchState.versions);\n        } catch (SearcherExpiredException see) {\n          // Expected, sometimes; in a \"real\" app we would\n          // either forward this error to the user (\"too\n          // much time has passed; please re-run your\n          // search\") or sneakily just switch to newest\n          // searcher w/o telling them...\n          if (VERBOSE) {\n            System.out.println(\"  searcher expired during local shard searcher init: \" + see);\n          }\n          priorSearches.remove(prevSearchState);\n          continue;\n        }\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: fresh query\");\n        }\n        // Do fresh query:\n        localShardSearcher = nodes[myNodeID].acquire();\n        prevSearchState = null;\n      }\n\n      final IndexReader[] subs = new IndexReader[numNodes];\n\n      PreviousSearchState searchState = null;\n\n      try {\n\n        // Mock: now make a single reader (MultiReader) from all node\n        // searchers.  In a real shard env you can't do this... we\n        // do it to confirm results from the shard searcher\n        // are correct:\n        int docCount = 0;\n        try {\n          for(int nodeID=0;nodeID<numNodes;nodeID++) {\n            final long subVersion = localShardSearcher.nodeVersions[nodeID];\n            final IndexSearcher sub = nodes[nodeID].searchers.acquire(subVersion);\n            if (sub == null) {\n              nodeID--;\n              while(nodeID >= 0) {\n                subs[nodeID].decRef();\n                subs[nodeID] = null;\n                nodeID--;\n              }\n              throw new SearcherExpiredException(\"nodeID=\" + nodeID + \" version=\" + subVersion);\n            }\n            subs[nodeID] = sub.getIndexReader();\n            docCount += subs[nodeID].maxDoc();\n          }\n        } catch (SearcherExpiredException see) {\n          // Expected\n          if (VERBOSE) {\n            System.out.println(\"  searcher expired during mock reader init: \" + see);\n          }\n          continue;\n        }\n\n        final IndexReader mockReader = new MultiReader(subs);\n        final IndexSearcher mockSearcher = new IndexSearcher(mockReader);\n\n        Query query;\n        Sort sort;\n\n        if (prevSearchState != null) {\n          query = prevSearchState.query;\n          sort = prevSearchState.sort;\n        } else {\n          if (terms == null && docCount > minDocsToMakeTerms) {\n            // TODO: try to \"focus\" on high freq terms sometimes too\n            // TODO: maybe also periodically reset the terms...?\n            final TermsEnum termsEnum = MultiFields.getTerms(mockReader, \"body\").iterator(null);\n            terms = new ArrayList<BytesRef>();\n            while(termsEnum.next() != null) {\n              terms.add(BytesRef.deepCopyOf(termsEnum.term()));\n            }\n            if (VERBOSE) {\n              System.out.println(\"TEST: init terms: \" + terms.size() + \" terms\");\n            }\n            if (terms.size() == 0) {\n              terms = null;\n            }\n          }\n\n          if (VERBOSE) {\n            System.out.println(\"  maxDoc=\" + mockReader.maxDoc());\n          }\n\n          if (terms != null) {\n            if (random().nextBoolean()) {\n              query = new TermQuery(new Term(\"body\", terms.get(random().nextInt(terms.size()))));\n            } else {\n              final String t = terms.get(random().nextInt(terms.size())).utf8ToString();\n              final String prefix;\n              if (t.length() <= 1) {\n                prefix = t;\n              } else {\n                prefix = t.substring(0, _TestUtil.nextInt(random(), 1, 2));\n              }\n              query = new PrefixQuery(new Term(\"body\", prefix));\n            }\n            \n            if (random().nextBoolean()) {\n              sort = null;\n            } else {\n              // TODO: sort by more than 1 field\n              final int what = random().nextInt(3);\n              if (what == 0) {\n                sort = new Sort(SortField.FIELD_SCORE);\n              } else if (what == 1) {\n                // TODO: this sort doesn't merge\n                // correctly... it's tricky because you\n                // could have > 2.1B docs across all shards: \n                //sort = new Sort(SortField.FIELD_DOC);\n                sort = null;\n              } else if (what == 2) {\n                sort = new Sort(new SortField[] {new SortField(\"docid\", SortField.Type.INT, random().nextBoolean())});\n              } else {\n                sort = new Sort(new SortField[] {new SortField(\"title\", SortField.Type.STRING, random().nextBoolean())});\n              }\n            }\n          } else {\n            query = null;\n            sort = null;\n          }\n        }\n\n        if (query != null) {\n\n          try {\n            searchState = assertSame(mockSearcher, localShardSearcher, query, sort, prevSearchState);\n          } catch (SearcherExpiredException see) {\n            // Expected; in a \"real\" app we would\n            // either forward this error to the user (\"too\n            // much time has passed; please re-run your\n            // search\") or sneakily just switch to newest\n            // searcher w/o telling them...\n            if (VERBOSE) {\n              System.out.println(\"  searcher expired during search: \" + see);\n              see.printStackTrace(System.out);\n            }\n            assert prevSearchState != null;\n            priorSearches.remove(prevSearchState);\n          }\n        }\n      } finally {\n        nodes[myNodeID].release(localShardSearcher);\n        for(IndexReader sub : subs) {\n          if (sub != null) {\n            sub.decRef();\n          }\n        }\n      }\n\n      if (searchState != null && searchState.searchAfterLocal != null && random().nextInt(5) == 3) {\n        priorSearches.add(searchState);\n        if (priorSearches.size() > 200) {\n          Collections.shuffle(priorSearches, random());\n          priorSearches.subList(100, priorSearches.size()).clear();\n        }\n      }\n    }\n\n    finish();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d6f074e73200c07d54f242d3880a8da5a35ff97b","date":1344507653,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestShardSearching#testSimple().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestShardSearching#testSimple().mjava","sourceNew":"  public void testSimple() throws Exception {\n    final int numNodes = _TestUtil.nextInt(random(), 1, 10);\n\n    final double runTimeSec = atLeast(3);\n\n    final int minDocsToMakeTerms = _TestUtil.nextInt(random(), 5, 20);\n\n    final int maxSearcherAgeSeconds = _TestUtil.nextInt(random(), 1, 3);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: numNodes=\" + numNodes + \" runTimeSec=\" + runTimeSec + \" maxSearcherAgeSeconds=\" + maxSearcherAgeSeconds);\n    }\n\n    start(numNodes,\n          runTimeSec,\n          maxSearcherAgeSeconds\n          );\n\n    final List<PreviousSearchState> priorSearches = new ArrayList<PreviousSearchState>();\n    List<BytesRef> terms = null;\n    while (System.nanoTime() < endTimeNanos) {\n\n      final boolean doFollowon = priorSearches.size() > 0 && random().nextInt(7) == 1;\n\n      // Pick a random node; we will run the query on this node:\n      final int myNodeID = random().nextInt(numNodes);\n\n      final NodeState.ShardIndexSearcher localShardSearcher;\n\n      final PreviousSearchState prevSearchState;\n\n      if (doFollowon) {\n        // Pretend user issued a followon query:\n        prevSearchState = priorSearches.get(random().nextInt(priorSearches.size()));\n\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: follow-on query age=\" + ((System.nanoTime() - prevSearchState.searchTimeNanos)/1000000000.0));\n        }\n\n        try {\n          localShardSearcher = nodes[myNodeID].acquire(prevSearchState.versions);\n        } catch (SearcherExpiredException see) {\n          // Expected, sometimes; in a \"real\" app we would\n          // either forward this error to the user (\"too\n          // much time has passed; please re-run your\n          // search\") or sneakily just switch to newest\n          // searcher w/o telling them...\n          if (VERBOSE) {\n            System.out.println(\"  searcher expired during local shard searcher init: \" + see);\n          }\n          priorSearches.remove(prevSearchState);\n          continue;\n        }\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: fresh query\");\n        }\n        // Do fresh query:\n        localShardSearcher = nodes[myNodeID].acquire();\n        prevSearchState = null;\n      }\n\n      final IndexReader[] subs = new IndexReader[numNodes];\n\n      PreviousSearchState searchState = null;\n\n      try {\n\n        // Mock: now make a single reader (MultiReader) from all node\n        // searchers.  In a real shard env you can't do this... we\n        // do it to confirm results from the shard searcher\n        // are correct:\n        int docCount = 0;\n        try {\n          for(int nodeID=0;nodeID<numNodes;nodeID++) {\n            final long subVersion = localShardSearcher.nodeVersions[nodeID];\n            final IndexSearcher sub = nodes[nodeID].searchers.acquire(subVersion);\n            if (sub == null) {\n              nodeID--;\n              while(nodeID >= 0) {\n                subs[nodeID].decRef();\n                subs[nodeID] = null;\n                nodeID--;\n              }\n              throw new SearcherExpiredException(\"nodeID=\" + nodeID + \" version=\" + subVersion);\n            }\n            subs[nodeID] = sub.getIndexReader();\n            docCount += subs[nodeID].maxDoc();\n          }\n        } catch (SearcherExpiredException see) {\n          // Expected\n          if (VERBOSE) {\n            System.out.println(\"  searcher expired during mock reader init: \" + see);\n          }\n          continue;\n        }\n\n        final IndexReader mockReader = new MultiReader(subs);\n        final IndexSearcher mockSearcher = new IndexSearcher(mockReader);\n\n        Query query;\n        Sort sort;\n\n        if (prevSearchState != null) {\n          query = prevSearchState.query;\n          sort = prevSearchState.sort;\n        } else {\n          if (terms == null && docCount > minDocsToMakeTerms) {\n            // TODO: try to \"focus\" on high freq terms sometimes too\n            // TODO: maybe also periodically reset the terms...?\n            final TermsEnum termsEnum = MultiFields.getTerms(mockReader, \"body\").iterator(null);\n            terms = new ArrayList<BytesRef>();\n            while(termsEnum.next() != null) {\n              terms.add(BytesRef.deepCopyOf(termsEnum.term()));\n            }\n            if (VERBOSE) {\n              System.out.println(\"TEST: init terms: \" + terms.size() + \" terms\");\n            }\n            if (terms.size() == 0) {\n              terms = null;\n            }\n          }\n\n          if (VERBOSE) {\n            System.out.println(\"  maxDoc=\" + mockReader.maxDoc());\n          }\n\n          if (terms != null) {\n            if (random().nextBoolean()) {\n              query = new TermQuery(new Term(\"body\", terms.get(random().nextInt(terms.size()))));\n            } else {\n              final String t = terms.get(random().nextInt(terms.size())).utf8ToString();\n              final String prefix;\n              if (t.length() <= 1) {\n                prefix = t;\n              } else {\n                prefix = t.substring(0, _TestUtil.nextInt(random(), 1, 2));\n              }\n              query = new PrefixQuery(new Term(\"body\", prefix));\n            }\n            \n            if (random().nextBoolean()) {\n              sort = null;\n            } else {\n              // TODO: sort by more than 1 field\n              final int what = random().nextInt(3);\n              if (what == 0) {\n                sort = new Sort(SortField.FIELD_SCORE);\n              } else if (what == 1) {\n                // TODO: this sort doesn't merge\n                // correctly... it's tricky because you\n                // could have > 2.1B docs across all shards: \n                //sort = new Sort(SortField.FIELD_DOC);\n                sort = null;\n              } else if (what == 2) {\n                sort = new Sort(new SortField[] {new SortField(\"docid\", SortField.Type.INT, random().nextBoolean())});\n              } else {\n                sort = new Sort(new SortField[] {new SortField(\"title\", SortField.Type.STRING, random().nextBoolean())});\n              }\n            }\n          } else {\n            query = null;\n            sort = null;\n          }\n        }\n\n        if (query != null) {\n\n          try {\n            searchState = assertSame(mockSearcher, localShardSearcher, query, sort, prevSearchState);\n          } catch (SearcherExpiredException see) {\n            // Expected; in a \"real\" app we would\n            // either forward this error to the user (\"too\n            // much time has passed; please re-run your\n            // search\") or sneakily just switch to newest\n            // searcher w/o telling them...\n            if (VERBOSE) {\n              System.out.println(\"  searcher expired during search: \" + see);\n              see.printStackTrace(System.out);\n            }\n            assert prevSearchState != null;\n            priorSearches.remove(prevSearchState);\n          }\n        }\n      } finally {\n        nodes[myNodeID].release(localShardSearcher);\n        for(IndexReader sub : subs) {\n          if (sub != null) {\n            sub.decRef();\n          }\n        }\n      }\n\n      if (searchState != null && searchState.searchAfterLocal != null && random().nextInt(5) == 3) {\n        priorSearches.add(searchState);\n        if (priorSearches.size() > 200) {\n          Collections.shuffle(priorSearches, random());\n          priorSearches.subList(100, priorSearches.size()).clear();\n        }\n      }\n    }\n\n    finish();\n  }\n\n","sourceOld":"  public void testSimple() throws Exception {\n    final int numNodes = _TestUtil.nextInt(random(), 1, 10);\n\n    final double runTimeSec = atLeast(3);\n\n    final int minDocsToMakeTerms = _TestUtil.nextInt(random(), 5, 20);\n\n    final int maxSearcherAgeSeconds = _TestUtil.nextInt(random(), 1, 3);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: numNodes=\" + numNodes + \" runTimeSec=\" + runTimeSec + \" maxSearcherAgeSeconds=\" + maxSearcherAgeSeconds);\n    }\n\n    start(_TestUtil.getTempDir(\"TestShardSearching\").toString(),\n          numNodes,\n          runTimeSec,\n          maxSearcherAgeSeconds\n          );\n\n    final List<PreviousSearchState> priorSearches = new ArrayList<PreviousSearchState>();\n    List<BytesRef> terms = null;\n    while (System.nanoTime() < endTimeNanos) {\n\n      final boolean doFollowon = priorSearches.size() > 0 && random().nextInt(7) == 1;\n\n      // Pick a random node; we will run the query on this node:\n      final int myNodeID = random().nextInt(numNodes);\n\n      final NodeState.ShardIndexSearcher localShardSearcher;\n\n      final PreviousSearchState prevSearchState;\n\n      if (doFollowon) {\n        // Pretend user issued a followon query:\n        prevSearchState = priorSearches.get(random().nextInt(priorSearches.size()));\n\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: follow-on query age=\" + ((System.nanoTime() - prevSearchState.searchTimeNanos)/1000000000.0));\n        }\n\n        try {\n          localShardSearcher = nodes[myNodeID].acquire(prevSearchState.versions);\n        } catch (SearcherExpiredException see) {\n          // Expected, sometimes; in a \"real\" app we would\n          // either forward this error to the user (\"too\n          // much time has passed; please re-run your\n          // search\") or sneakily just switch to newest\n          // searcher w/o telling them...\n          if (VERBOSE) {\n            System.out.println(\"  searcher expired during local shard searcher init: \" + see);\n          }\n          priorSearches.remove(prevSearchState);\n          continue;\n        }\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: fresh query\");\n        }\n        // Do fresh query:\n        localShardSearcher = nodes[myNodeID].acquire();\n        prevSearchState = null;\n      }\n\n      final IndexReader[] subs = new IndexReader[numNodes];\n\n      PreviousSearchState searchState = null;\n\n      try {\n\n        // Mock: now make a single reader (MultiReader) from all node\n        // searchers.  In a real shard env you can't do this... we\n        // do it to confirm results from the shard searcher\n        // are correct:\n        int docCount = 0;\n        try {\n          for(int nodeID=0;nodeID<numNodes;nodeID++) {\n            final long subVersion = localShardSearcher.nodeVersions[nodeID];\n            final IndexSearcher sub = nodes[nodeID].searchers.acquire(subVersion);\n            if (sub == null) {\n              nodeID--;\n              while(nodeID >= 0) {\n                subs[nodeID].decRef();\n                subs[nodeID] = null;\n                nodeID--;\n              }\n              throw new SearcherExpiredException(\"nodeID=\" + nodeID + \" version=\" + subVersion);\n            }\n            subs[nodeID] = sub.getIndexReader();\n            docCount += subs[nodeID].maxDoc();\n          }\n        } catch (SearcherExpiredException see) {\n          // Expected\n          if (VERBOSE) {\n            System.out.println(\"  searcher expired during mock reader init: \" + see);\n          }\n          continue;\n        }\n\n        final IndexReader mockReader = new MultiReader(subs);\n        final IndexSearcher mockSearcher = new IndexSearcher(mockReader);\n\n        Query query;\n        Sort sort;\n\n        if (prevSearchState != null) {\n          query = prevSearchState.query;\n          sort = prevSearchState.sort;\n        } else {\n          if (terms == null && docCount > minDocsToMakeTerms) {\n            // TODO: try to \"focus\" on high freq terms sometimes too\n            // TODO: maybe also periodically reset the terms...?\n            final TermsEnum termsEnum = MultiFields.getTerms(mockReader, \"body\").iterator(null);\n            terms = new ArrayList<BytesRef>();\n            while(termsEnum.next() != null) {\n              terms.add(BytesRef.deepCopyOf(termsEnum.term()));\n            }\n            if (VERBOSE) {\n              System.out.println(\"TEST: init terms: \" + terms.size() + \" terms\");\n            }\n            if (terms.size() == 0) {\n              terms = null;\n            }\n          }\n\n          if (VERBOSE) {\n            System.out.println(\"  maxDoc=\" + mockReader.maxDoc());\n          }\n\n          if (terms != null) {\n            if (random().nextBoolean()) {\n              query = new TermQuery(new Term(\"body\", terms.get(random().nextInt(terms.size()))));\n            } else {\n              final String t = terms.get(random().nextInt(terms.size())).utf8ToString();\n              final String prefix;\n              if (t.length() <= 1) {\n                prefix = t;\n              } else {\n                prefix = t.substring(0, _TestUtil.nextInt(random(), 1, 2));\n              }\n              query = new PrefixQuery(new Term(\"body\", prefix));\n            }\n            \n            if (random().nextBoolean()) {\n              sort = null;\n            } else {\n              // TODO: sort by more than 1 field\n              final int what = random().nextInt(3);\n              if (what == 0) {\n                sort = new Sort(SortField.FIELD_SCORE);\n              } else if (what == 1) {\n                // TODO: this sort doesn't merge\n                // correctly... it's tricky because you\n                // could have > 2.1B docs across all shards: \n                //sort = new Sort(SortField.FIELD_DOC);\n                sort = null;\n              } else if (what == 2) {\n                sort = new Sort(new SortField[] {new SortField(\"docid\", SortField.Type.INT, random().nextBoolean())});\n              } else {\n                sort = new Sort(new SortField[] {new SortField(\"title\", SortField.Type.STRING, random().nextBoolean())});\n              }\n            }\n          } else {\n            query = null;\n            sort = null;\n          }\n        }\n\n        if (query != null) {\n\n          try {\n            searchState = assertSame(mockSearcher, localShardSearcher, query, sort, prevSearchState);\n          } catch (SearcherExpiredException see) {\n            // Expected; in a \"real\" app we would\n            // either forward this error to the user (\"too\n            // much time has passed; please re-run your\n            // search\") or sneakily just switch to newest\n            // searcher w/o telling them...\n            if (VERBOSE) {\n              System.out.println(\"  searcher expired during search: \" + see);\n              see.printStackTrace(System.out);\n            }\n            assert prevSearchState != null;\n            priorSearches.remove(prevSearchState);\n          }\n        }\n      } finally {\n        nodes[myNodeID].release(localShardSearcher);\n        for(IndexReader sub : subs) {\n          if (sub != null) {\n            sub.decRef();\n          }\n        }\n      }\n\n      if (searchState != null && searchState.searchAfterLocal != null && random().nextInt(5) == 3) {\n        priorSearches.add(searchState);\n        if (priorSearches.size() > 200) {\n          Collections.shuffle(priorSearches, random());\n          priorSearches.subList(100, priorSearches.size()).clear();\n        }\n      }\n    }\n\n    finish();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"49e6a45bc6278d94e7c4aed1d36adde70842e00c","date":1352421282,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestShardSearching#testSimple().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestShardSearching#testSimple().mjava","sourceNew":"  public void testSimple() throws Exception {\n    final int numNodes = _TestUtil.nextInt(random(), 1, 10);\n\n    final double runTimeSec = atLeast(3);\n\n    final int minDocsToMakeTerms = _TestUtil.nextInt(random(), 5, 20);\n\n    final int maxSearcherAgeSeconds = _TestUtil.nextInt(random(), 1, 3);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: numNodes=\" + numNodes + \" runTimeSec=\" + runTimeSec + \" maxSearcherAgeSeconds=\" + maxSearcherAgeSeconds);\n    }\n\n    start(numNodes,\n          runTimeSec,\n          maxSearcherAgeSeconds\n          );\n\n    final List<PreviousSearchState> priorSearches = new ArrayList<PreviousSearchState>();\n    List<BytesRef> terms = null;\n    while (System.nanoTime() < endTimeNanos) {\n\n      final boolean doFollowon = priorSearches.size() > 0 && random().nextInt(7) == 1;\n\n      // Pick a random node; we will run the query on this node:\n      final int myNodeID = random().nextInt(numNodes);\n\n      final NodeState.ShardIndexSearcher localShardSearcher;\n\n      final PreviousSearchState prevSearchState;\n\n      if (doFollowon) {\n        // Pretend user issued a followon query:\n        prevSearchState = priorSearches.get(random().nextInt(priorSearches.size()));\n\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: follow-on query age=\" + ((System.nanoTime() - prevSearchState.searchTimeNanos)/1000000000.0));\n        }\n\n        try {\n          localShardSearcher = nodes[myNodeID].acquire(prevSearchState.versions);\n        } catch (SearcherExpiredException see) {\n          // Expected, sometimes; in a \"real\" app we would\n          // either forward this error to the user (\"too\n          // much time has passed; please re-run your\n          // search\") or sneakily just switch to newest\n          // searcher w/o telling them...\n          if (VERBOSE) {\n            System.out.println(\"  searcher expired during local shard searcher init: \" + see);\n          }\n          priorSearches.remove(prevSearchState);\n          continue;\n        }\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: fresh query\");\n        }\n        // Do fresh query:\n        localShardSearcher = nodes[myNodeID].acquire();\n        prevSearchState = null;\n      }\n\n      final IndexReader[] subs = new IndexReader[numNodes];\n\n      PreviousSearchState searchState = null;\n\n      try {\n\n        // Mock: now make a single reader (MultiReader) from all node\n        // searchers.  In a real shard env you can't do this... we\n        // do it to confirm results from the shard searcher\n        // are correct:\n        int docCount = 0;\n        try {\n          for(int nodeID=0;nodeID<numNodes;nodeID++) {\n            final long subVersion = localShardSearcher.nodeVersions[nodeID];\n            final IndexSearcher sub = nodes[nodeID].searchers.acquire(subVersion);\n            if (sub == null) {\n              nodeID--;\n              while(nodeID >= 0) {\n                subs[nodeID].decRef();\n                subs[nodeID] = null;\n                nodeID--;\n              }\n              throw new SearcherExpiredException(\"nodeID=\" + nodeID + \" version=\" + subVersion);\n            }\n            subs[nodeID] = sub.getIndexReader();\n            docCount += subs[nodeID].maxDoc();\n          }\n        } catch (SearcherExpiredException see) {\n          // Expected\n          if (VERBOSE) {\n            System.out.println(\"  searcher expired during mock reader init: \" + see);\n          }\n          continue;\n        }\n\n        final IndexReader mockReader = new MultiReader(subs);\n        final IndexSearcher mockSearcher = new IndexSearcher(mockReader);\n\n        Query query;\n        Sort sort;\n\n        if (prevSearchState != null) {\n          query = prevSearchState.query;\n          sort = prevSearchState.sort;\n        } else {\n          if (terms == null && docCount > minDocsToMakeTerms) {\n            // TODO: try to \"focus\" on high freq terms sometimes too\n            // TODO: maybe also periodically reset the terms...?\n            final TermsEnum termsEnum = MultiFields.getTerms(mockReader, \"body\").iterator(null);\n            terms = new ArrayList<BytesRef>();\n            while(termsEnum.next() != null) {\n              terms.add(BytesRef.deepCopyOf(termsEnum.term()));\n            }\n            if (VERBOSE) {\n              System.out.println(\"TEST: init terms: \" + terms.size() + \" terms\");\n            }\n            if (terms.size() == 0) {\n              terms = null;\n            }\n          }\n\n          if (VERBOSE) {\n            System.out.println(\"  maxDoc=\" + mockReader.maxDoc());\n          }\n\n          if (terms != null) {\n            if (random().nextBoolean()) {\n              query = new TermQuery(new Term(\"body\", terms.get(random().nextInt(terms.size()))));\n            } else {\n              final String t = terms.get(random().nextInt(terms.size())).utf8ToString();\n              final String prefix;\n              if (t.length() <= 1) {\n                prefix = t;\n              } else {\n                prefix = t.substring(0, _TestUtil.nextInt(random(), 1, 2));\n              }\n              query = new PrefixQuery(new Term(\"body\", prefix));\n            }\n            \n            if (random().nextBoolean()) {\n              sort = null;\n            } else {\n              // TODO: sort by more than 1 field\n              final int what = random().nextInt(3);\n              if (what == 0) {\n                sort = new Sort(SortField.FIELD_SCORE);\n              } else if (what == 1) {\n                // TODO: this sort doesn't merge\n                // correctly... it's tricky because you\n                // could have > 2.1B docs across all shards: \n                //sort = new Sort(SortField.FIELD_DOC);\n                sort = null;\n              } else if (what == 2) {\n                sort = new Sort(new SortField[] {new SortField(\"docid\", SortField.Type.INT, random().nextBoolean())});\n              } else {\n                sort = new Sort(new SortField[] {new SortField(\"title\", SortField.Type.STRING, random().nextBoolean())});\n              }\n            }\n          } else {\n            query = null;\n            sort = null;\n          }\n        }\n\n        if (query != null) {\n\n          try {\n            searchState = assertSame(mockSearcher, localShardSearcher, query, sort, prevSearchState);\n          } catch (SearcherExpiredException see) {\n            // Expected; in a \"real\" app we would\n            // either forward this error to the user (\"too\n            // much time has passed; please re-run your\n            // search\") or sneakily just switch to newest\n            // searcher w/o telling them...\n            if (VERBOSE) {\n              System.out.println(\"  searcher expired during search: \" + see);\n              see.printStackTrace(System.out);\n            }\n            // We can't do this in general: on a very slow\n            // computer it's possible the local searcher\n            // expires before we can finish our search:\n            // assert prevSearchState != null;\n            if (prevSearchState != null) {\n              priorSearches.remove(prevSearchState);\n            }\n          }\n        }\n      } finally {\n        nodes[myNodeID].release(localShardSearcher);\n        for(IndexReader sub : subs) {\n          if (sub != null) {\n            sub.decRef();\n          }\n        }\n      }\n\n      if (searchState != null && searchState.searchAfterLocal != null && random().nextInt(5) == 3) {\n        priorSearches.add(searchState);\n        if (priorSearches.size() > 200) {\n          Collections.shuffle(priorSearches, random());\n          priorSearches.subList(100, priorSearches.size()).clear();\n        }\n      }\n    }\n\n    finish();\n  }\n\n","sourceOld":"  public void testSimple() throws Exception {\n    final int numNodes = _TestUtil.nextInt(random(), 1, 10);\n\n    final double runTimeSec = atLeast(3);\n\n    final int minDocsToMakeTerms = _TestUtil.nextInt(random(), 5, 20);\n\n    final int maxSearcherAgeSeconds = _TestUtil.nextInt(random(), 1, 3);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: numNodes=\" + numNodes + \" runTimeSec=\" + runTimeSec + \" maxSearcherAgeSeconds=\" + maxSearcherAgeSeconds);\n    }\n\n    start(numNodes,\n          runTimeSec,\n          maxSearcherAgeSeconds\n          );\n\n    final List<PreviousSearchState> priorSearches = new ArrayList<PreviousSearchState>();\n    List<BytesRef> terms = null;\n    while (System.nanoTime() < endTimeNanos) {\n\n      final boolean doFollowon = priorSearches.size() > 0 && random().nextInt(7) == 1;\n\n      // Pick a random node; we will run the query on this node:\n      final int myNodeID = random().nextInt(numNodes);\n\n      final NodeState.ShardIndexSearcher localShardSearcher;\n\n      final PreviousSearchState prevSearchState;\n\n      if (doFollowon) {\n        // Pretend user issued a followon query:\n        prevSearchState = priorSearches.get(random().nextInt(priorSearches.size()));\n\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: follow-on query age=\" + ((System.nanoTime() - prevSearchState.searchTimeNanos)/1000000000.0));\n        }\n\n        try {\n          localShardSearcher = nodes[myNodeID].acquire(prevSearchState.versions);\n        } catch (SearcherExpiredException see) {\n          // Expected, sometimes; in a \"real\" app we would\n          // either forward this error to the user (\"too\n          // much time has passed; please re-run your\n          // search\") or sneakily just switch to newest\n          // searcher w/o telling them...\n          if (VERBOSE) {\n            System.out.println(\"  searcher expired during local shard searcher init: \" + see);\n          }\n          priorSearches.remove(prevSearchState);\n          continue;\n        }\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: fresh query\");\n        }\n        // Do fresh query:\n        localShardSearcher = nodes[myNodeID].acquire();\n        prevSearchState = null;\n      }\n\n      final IndexReader[] subs = new IndexReader[numNodes];\n\n      PreviousSearchState searchState = null;\n\n      try {\n\n        // Mock: now make a single reader (MultiReader) from all node\n        // searchers.  In a real shard env you can't do this... we\n        // do it to confirm results from the shard searcher\n        // are correct:\n        int docCount = 0;\n        try {\n          for(int nodeID=0;nodeID<numNodes;nodeID++) {\n            final long subVersion = localShardSearcher.nodeVersions[nodeID];\n            final IndexSearcher sub = nodes[nodeID].searchers.acquire(subVersion);\n            if (sub == null) {\n              nodeID--;\n              while(nodeID >= 0) {\n                subs[nodeID].decRef();\n                subs[nodeID] = null;\n                nodeID--;\n              }\n              throw new SearcherExpiredException(\"nodeID=\" + nodeID + \" version=\" + subVersion);\n            }\n            subs[nodeID] = sub.getIndexReader();\n            docCount += subs[nodeID].maxDoc();\n          }\n        } catch (SearcherExpiredException see) {\n          // Expected\n          if (VERBOSE) {\n            System.out.println(\"  searcher expired during mock reader init: \" + see);\n          }\n          continue;\n        }\n\n        final IndexReader mockReader = new MultiReader(subs);\n        final IndexSearcher mockSearcher = new IndexSearcher(mockReader);\n\n        Query query;\n        Sort sort;\n\n        if (prevSearchState != null) {\n          query = prevSearchState.query;\n          sort = prevSearchState.sort;\n        } else {\n          if (terms == null && docCount > minDocsToMakeTerms) {\n            // TODO: try to \"focus\" on high freq terms sometimes too\n            // TODO: maybe also periodically reset the terms...?\n            final TermsEnum termsEnum = MultiFields.getTerms(mockReader, \"body\").iterator(null);\n            terms = new ArrayList<BytesRef>();\n            while(termsEnum.next() != null) {\n              terms.add(BytesRef.deepCopyOf(termsEnum.term()));\n            }\n            if (VERBOSE) {\n              System.out.println(\"TEST: init terms: \" + terms.size() + \" terms\");\n            }\n            if (terms.size() == 0) {\n              terms = null;\n            }\n          }\n\n          if (VERBOSE) {\n            System.out.println(\"  maxDoc=\" + mockReader.maxDoc());\n          }\n\n          if (terms != null) {\n            if (random().nextBoolean()) {\n              query = new TermQuery(new Term(\"body\", terms.get(random().nextInt(terms.size()))));\n            } else {\n              final String t = terms.get(random().nextInt(terms.size())).utf8ToString();\n              final String prefix;\n              if (t.length() <= 1) {\n                prefix = t;\n              } else {\n                prefix = t.substring(0, _TestUtil.nextInt(random(), 1, 2));\n              }\n              query = new PrefixQuery(new Term(\"body\", prefix));\n            }\n            \n            if (random().nextBoolean()) {\n              sort = null;\n            } else {\n              // TODO: sort by more than 1 field\n              final int what = random().nextInt(3);\n              if (what == 0) {\n                sort = new Sort(SortField.FIELD_SCORE);\n              } else if (what == 1) {\n                // TODO: this sort doesn't merge\n                // correctly... it's tricky because you\n                // could have > 2.1B docs across all shards: \n                //sort = new Sort(SortField.FIELD_DOC);\n                sort = null;\n              } else if (what == 2) {\n                sort = new Sort(new SortField[] {new SortField(\"docid\", SortField.Type.INT, random().nextBoolean())});\n              } else {\n                sort = new Sort(new SortField[] {new SortField(\"title\", SortField.Type.STRING, random().nextBoolean())});\n              }\n            }\n          } else {\n            query = null;\n            sort = null;\n          }\n        }\n\n        if (query != null) {\n\n          try {\n            searchState = assertSame(mockSearcher, localShardSearcher, query, sort, prevSearchState);\n          } catch (SearcherExpiredException see) {\n            // Expected; in a \"real\" app we would\n            // either forward this error to the user (\"too\n            // much time has passed; please re-run your\n            // search\") or sneakily just switch to newest\n            // searcher w/o telling them...\n            if (VERBOSE) {\n              System.out.println(\"  searcher expired during search: \" + see);\n              see.printStackTrace(System.out);\n            }\n            assert prevSearchState != null;\n            priorSearches.remove(prevSearchState);\n          }\n        }\n      } finally {\n        nodes[myNodeID].release(localShardSearcher);\n        for(IndexReader sub : subs) {\n          if (sub != null) {\n            sub.decRef();\n          }\n        }\n      }\n\n      if (searchState != null && searchState.searchAfterLocal != null && random().nextInt(5) == 3) {\n        priorSearches.add(searchState);\n        if (priorSearches.size() > 200) {\n          Collections.shuffle(priorSearches, random());\n          priorSearches.subList(100, priorSearches.size()).clear();\n        }\n      }\n    }\n\n    finish();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"407687e67faf6e1f02a211ca078d8e3eed631027","date":1355157407,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestShardSearching#testSimple().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestShardSearching#testSimple().mjava","sourceNew":"  public void testSimple() throws Exception {\n    final int numNodes = _TestUtil.nextInt(random(), 1, 10);\n\n    final double runTimeSec = atLeast(3);\n\n    final int minDocsToMakeTerms = _TestUtil.nextInt(random(), 5, 20);\n\n    final int maxSearcherAgeSeconds = _TestUtil.nextInt(random(), 1, 3);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: numNodes=\" + numNodes + \" runTimeSec=\" + runTimeSec + \" maxSearcherAgeSeconds=\" + maxSearcherAgeSeconds);\n    }\n\n    start(numNodes,\n          runTimeSec,\n          maxSearcherAgeSeconds\n          );\n\n    final List<PreviousSearchState> priorSearches = new ArrayList<PreviousSearchState>();\n    List<BytesRef> terms = null;\n    while (System.nanoTime() < endTimeNanos) {\n\n      final boolean doFollowon = priorSearches.size() > 0 && random().nextInt(7) == 1;\n\n      // Pick a random node; we will run the query on this node:\n      final int myNodeID = random().nextInt(numNodes);\n\n      final NodeState.ShardIndexSearcher localShardSearcher;\n\n      final PreviousSearchState prevSearchState;\n\n      if (doFollowon) {\n        // Pretend user issued a followon query:\n        prevSearchState = priorSearches.get(random().nextInt(priorSearches.size()));\n\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: follow-on query age=\" + ((System.nanoTime() - prevSearchState.searchTimeNanos)/1000000000.0));\n        }\n\n        try {\n          localShardSearcher = nodes[myNodeID].acquire(prevSearchState.versions);\n        } catch (SearcherExpiredException see) {\n          // Expected, sometimes; in a \"real\" app we would\n          // either forward this error to the user (\"too\n          // much time has passed; please re-run your\n          // search\") or sneakily just switch to newest\n          // searcher w/o telling them...\n          if (VERBOSE) {\n            System.out.println(\"  searcher expired during local shard searcher init: \" + see);\n          }\n          priorSearches.remove(prevSearchState);\n          continue;\n        }\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: fresh query\");\n        }\n        // Do fresh query:\n        localShardSearcher = nodes[myNodeID].acquire();\n        prevSearchState = null;\n      }\n\n      final IndexReader[] subs = new IndexReader[numNodes];\n\n      PreviousSearchState searchState = null;\n\n      try {\n\n        // Mock: now make a single reader (MultiReader) from all node\n        // searchers.  In a real shard env you can't do this... we\n        // do it to confirm results from the shard searcher\n        // are correct:\n        int docCount = 0;\n        try {\n          for(int nodeID=0;nodeID<numNodes;nodeID++) {\n            final long subVersion = localShardSearcher.nodeVersions[nodeID];\n            final IndexSearcher sub = nodes[nodeID].searchers.acquire(subVersion);\n            if (sub == null) {\n              nodeID--;\n              while(nodeID >= 0) {\n                subs[nodeID].decRef();\n                subs[nodeID] = null;\n                nodeID--;\n              }\n              throw new SearcherExpiredException(\"nodeID=\" + nodeID + \" version=\" + subVersion);\n            }\n            subs[nodeID] = sub.getIndexReader();\n            docCount += subs[nodeID].maxDoc();\n          }\n        } catch (SearcherExpiredException see) {\n          // Expected\n          if (VERBOSE) {\n            System.out.println(\"  searcher expired during mock reader init: \" + see);\n          }\n          continue;\n        }\n\n        final IndexReader mockReader = new MultiReader(subs);\n        final IndexSearcher mockSearcher = new IndexSearcher(mockReader);\n\n        Query query;\n        Sort sort;\n\n        if (prevSearchState != null) {\n          query = prevSearchState.query;\n          sort = prevSearchState.sort;\n        } else {\n          if (terms == null && docCount > minDocsToMakeTerms) {\n            // TODO: try to \"focus\" on high freq terms sometimes too\n            // TODO: maybe also periodically reset the terms...?\n            final TermsEnum termsEnum = MultiFields.getTerms(mockReader, \"body\").iterator(null);\n            terms = new ArrayList<BytesRef>();\n            while(termsEnum.next() != null) {\n              terms.add(BytesRef.deepCopyOf(termsEnum.term()));\n            }\n            if (VERBOSE) {\n              System.out.println(\"TEST: init terms: \" + terms.size() + \" terms\");\n            }\n            if (terms.size() == 0) {\n              terms = null;\n            }\n          }\n\n          if (VERBOSE) {\n            System.out.println(\"  maxDoc=\" + mockReader.maxDoc());\n          }\n\n          if (terms != null) {\n            if (random().nextBoolean()) {\n              query = new TermQuery(new Term(\"body\", terms.get(random().nextInt(terms.size()))));\n            } else {\n              final String t = terms.get(random().nextInt(terms.size())).utf8ToString();\n              final String prefix;\n              if (t.length() <= 1) {\n                prefix = t;\n              } else {\n                prefix = t.substring(0, _TestUtil.nextInt(random(), 1, 2));\n              }\n              query = new PrefixQuery(new Term(\"body\", prefix));\n            }\n            \n            if (random().nextBoolean()) {\n              sort = null;\n            } else {\n              // TODO: sort by more than 1 field\n              final int what = random().nextInt(3);\n              if (what == 0) {\n                sort = new Sort(SortField.FIELD_SCORE);\n              } else if (what == 1) {\n                // TODO: this sort doesn't merge\n                // correctly... it's tricky because you\n                // could have > 2.1B docs across all shards: \n                //sort = new Sort(SortField.FIELD_DOC);\n                sort = null;\n              } else if (what == 2) {\n                sort = new Sort(new SortField[] {new SortField(\"docid\", SortField.Type.INT, random().nextBoolean())});\n              } else {\n                sort = new Sort(new SortField[] {new SortField(\"title\", SortField.Type.STRING, random().nextBoolean())});\n              }\n            }\n          } else {\n            query = null;\n            sort = null;\n          }\n        }\n\n        if (query != null) {\n\n          try {\n            searchState = assertSame(mockSearcher, localShardSearcher, query, sort, prevSearchState);\n          } catch (SearcherExpiredException see) {\n            // Expected; in a \"real\" app we would\n            // either forward this error to the user (\"too\n            // much time has passed; please re-run your\n            // search\") or sneakily just switch to newest\n            // searcher w/o telling them...\n            if (VERBOSE) {\n              System.out.println(\"  searcher expired during search: \" + see);\n              see.printStackTrace(System.out);\n            }\n            // We can't do this in general: on a very slow\n            // computer it's possible the local searcher\n            // expires before we can finish our search:\n            // assert prevSearchState != null;\n            if (prevSearchState != null) {\n              priorSearches.remove(prevSearchState);\n            }\n          }\n        }\n      } finally {\n        nodes[myNodeID].release(localShardSearcher);\n        for(IndexReader sub : subs) {\n          if (sub != null) {\n            sub.decRef();\n          }\n        }\n      }\n\n      if (searchState != null && searchState.searchAfterLocal != null && random().nextInt(5) == 3) {\n        priorSearches.add(searchState);\n        if (priorSearches.size() > 200) {\n          Collections.shuffle(priorSearches, random());\n          priorSearches.subList(100, priorSearches.size()).clear();\n        }\n      }\n    }\n\n    finish();\n  }\n\n","sourceOld":"  public void testSimple() throws Exception {\n    final int numNodes = _TestUtil.nextInt(random(), 1, 10);\n\n    final double runTimeSec = atLeast(3);\n\n    final int minDocsToMakeTerms = _TestUtil.nextInt(random(), 5, 20);\n\n    final int maxSearcherAgeSeconds = _TestUtil.nextInt(random(), 1, 3);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: numNodes=\" + numNodes + \" runTimeSec=\" + runTimeSec + \" maxSearcherAgeSeconds=\" + maxSearcherAgeSeconds);\n    }\n\n    start(numNodes,\n          runTimeSec,\n          maxSearcherAgeSeconds\n          );\n\n    final List<PreviousSearchState> priorSearches = new ArrayList<PreviousSearchState>();\n    List<BytesRef> terms = null;\n    while (System.nanoTime() < endTimeNanos) {\n\n      final boolean doFollowon = priorSearches.size() > 0 && random().nextInt(7) == 1;\n\n      // Pick a random node; we will run the query on this node:\n      final int myNodeID = random().nextInt(numNodes);\n\n      final NodeState.ShardIndexSearcher localShardSearcher;\n\n      final PreviousSearchState prevSearchState;\n\n      if (doFollowon) {\n        // Pretend user issued a followon query:\n        prevSearchState = priorSearches.get(random().nextInt(priorSearches.size()));\n\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: follow-on query age=\" + ((System.nanoTime() - prevSearchState.searchTimeNanos)/1000000000.0));\n        }\n\n        try {\n          localShardSearcher = nodes[myNodeID].acquire(prevSearchState.versions);\n        } catch (SearcherExpiredException see) {\n          // Expected, sometimes; in a \"real\" app we would\n          // either forward this error to the user (\"too\n          // much time has passed; please re-run your\n          // search\") or sneakily just switch to newest\n          // searcher w/o telling them...\n          if (VERBOSE) {\n            System.out.println(\"  searcher expired during local shard searcher init: \" + see);\n          }\n          priorSearches.remove(prevSearchState);\n          continue;\n        }\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: fresh query\");\n        }\n        // Do fresh query:\n        localShardSearcher = nodes[myNodeID].acquire();\n        prevSearchState = null;\n      }\n\n      final IndexReader[] subs = new IndexReader[numNodes];\n\n      PreviousSearchState searchState = null;\n\n      try {\n\n        // Mock: now make a single reader (MultiReader) from all node\n        // searchers.  In a real shard env you can't do this... we\n        // do it to confirm results from the shard searcher\n        // are correct:\n        int docCount = 0;\n        try {\n          for(int nodeID=0;nodeID<numNodes;nodeID++) {\n            final long subVersion = localShardSearcher.nodeVersions[nodeID];\n            final IndexSearcher sub = nodes[nodeID].searchers.acquire(subVersion);\n            if (sub == null) {\n              nodeID--;\n              while(nodeID >= 0) {\n                subs[nodeID].decRef();\n                subs[nodeID] = null;\n                nodeID--;\n              }\n              throw new SearcherExpiredException(\"nodeID=\" + nodeID + \" version=\" + subVersion);\n            }\n            subs[nodeID] = sub.getIndexReader();\n            docCount += subs[nodeID].maxDoc();\n          }\n        } catch (SearcherExpiredException see) {\n          // Expected\n          if (VERBOSE) {\n            System.out.println(\"  searcher expired during mock reader init: \" + see);\n          }\n          continue;\n        }\n\n        final IndexReader mockReader = new MultiReader(subs);\n        final IndexSearcher mockSearcher = new IndexSearcher(mockReader);\n\n        Query query;\n        Sort sort;\n\n        if (prevSearchState != null) {\n          query = prevSearchState.query;\n          sort = prevSearchState.sort;\n        } else {\n          if (terms == null && docCount > minDocsToMakeTerms) {\n            // TODO: try to \"focus\" on high freq terms sometimes too\n            // TODO: maybe also periodically reset the terms...?\n            final TermsEnum termsEnum = MultiFields.getTerms(mockReader, \"body\").iterator(null);\n            terms = new ArrayList<BytesRef>();\n            while(termsEnum.next() != null) {\n              terms.add(BytesRef.deepCopyOf(termsEnum.term()));\n            }\n            if (VERBOSE) {\n              System.out.println(\"TEST: init terms: \" + terms.size() + \" terms\");\n            }\n            if (terms.size() == 0) {\n              terms = null;\n            }\n          }\n\n          if (VERBOSE) {\n            System.out.println(\"  maxDoc=\" + mockReader.maxDoc());\n          }\n\n          if (terms != null) {\n            if (random().nextBoolean()) {\n              query = new TermQuery(new Term(\"body\", terms.get(random().nextInt(terms.size()))));\n            } else {\n              final String t = terms.get(random().nextInt(terms.size())).utf8ToString();\n              final String prefix;\n              if (t.length() <= 1) {\n                prefix = t;\n              } else {\n                prefix = t.substring(0, _TestUtil.nextInt(random(), 1, 2));\n              }\n              query = new PrefixQuery(new Term(\"body\", prefix));\n            }\n            \n            if (random().nextBoolean()) {\n              sort = null;\n            } else {\n              // TODO: sort by more than 1 field\n              final int what = random().nextInt(3);\n              if (what == 0) {\n                sort = new Sort(SortField.FIELD_SCORE);\n              } else if (what == 1) {\n                // TODO: this sort doesn't merge\n                // correctly... it's tricky because you\n                // could have > 2.1B docs across all shards: \n                //sort = new Sort(SortField.FIELD_DOC);\n                sort = null;\n              } else if (what == 2) {\n                sort = new Sort(new SortField[] {new SortField(\"docid\", SortField.Type.INT, random().nextBoolean())});\n              } else {\n                sort = new Sort(new SortField[] {new SortField(\"title\", SortField.Type.STRING, random().nextBoolean())});\n              }\n            }\n          } else {\n            query = null;\n            sort = null;\n          }\n        }\n\n        if (query != null) {\n\n          try {\n            searchState = assertSame(mockSearcher, localShardSearcher, query, sort, prevSearchState);\n          } catch (SearcherExpiredException see) {\n            // Expected; in a \"real\" app we would\n            // either forward this error to the user (\"too\n            // much time has passed; please re-run your\n            // search\") or sneakily just switch to newest\n            // searcher w/o telling them...\n            if (VERBOSE) {\n              System.out.println(\"  searcher expired during search: \" + see);\n              see.printStackTrace(System.out);\n            }\n            assert prevSearchState != null;\n            priorSearches.remove(prevSearchState);\n          }\n        }\n      } finally {\n        nodes[myNodeID].release(localShardSearcher);\n        for(IndexReader sub : subs) {\n          if (sub != null) {\n            sub.decRef();\n          }\n        }\n      }\n\n      if (searchState != null && searchState.searchAfterLocal != null && random().nextInt(5) == 3) {\n        priorSearches.add(searchState);\n        if (priorSearches.size() > 200) {\n          Collections.shuffle(priorSearches, random());\n          priorSearches.subList(100, priorSearches.size()).clear();\n        }\n      }\n    }\n\n    finish();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"59a0020b413d44dd79d85d7a66ed5004265fb453","date":1371758877,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestShardSearching#testSimple().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestShardSearching#testSimple().mjava","sourceNew":"  public void testSimple() throws Exception {\n    final int numNodes = _TestUtil.nextInt(random(), 1, 10);\n\n    final double runTimeSec = atLeast(3);\n\n    final int minDocsToMakeTerms = _TestUtil.nextInt(random(), 5, 20);\n\n    final int maxSearcherAgeSeconds = _TestUtil.nextInt(random(), 1, 3);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: numNodes=\" + numNodes + \" runTimeSec=\" + runTimeSec + \" maxSearcherAgeSeconds=\" + maxSearcherAgeSeconds);\n    }\n\n    start(numNodes,\n          runTimeSec,\n          maxSearcherAgeSeconds\n          );\n\n    final List<PreviousSearchState> priorSearches = new ArrayList<PreviousSearchState>();\n    List<BytesRef> terms = null;\n    while (System.nanoTime() < endTimeNanos) {\n\n      final boolean doFollowon = priorSearches.size() > 0 && random().nextInt(7) == 1;\n\n      // Pick a random node; we will run the query on this node:\n      final int myNodeID = random().nextInt(numNodes);\n\n      final NodeState.ShardIndexSearcher localShardSearcher;\n\n      final PreviousSearchState prevSearchState;\n\n      if (doFollowon) {\n        // Pretend user issued a followon query:\n        prevSearchState = priorSearches.get(random().nextInt(priorSearches.size()));\n\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: follow-on query age=\" + ((System.nanoTime() - prevSearchState.searchTimeNanos)/1000000000.0));\n        }\n\n        try {\n          localShardSearcher = nodes[myNodeID].acquire(prevSearchState.versions);\n        } catch (SearcherExpiredException see) {\n          // Expected, sometimes; in a \"real\" app we would\n          // either forward this error to the user (\"too\n          // much time has passed; please re-run your\n          // search\") or sneakily just switch to newest\n          // searcher w/o telling them...\n          if (VERBOSE) {\n            System.out.println(\"  searcher expired during local shard searcher init: \" + see);\n          }\n          priorSearches.remove(prevSearchState);\n          continue;\n        }\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: fresh query\");\n        }\n        // Do fresh query:\n        localShardSearcher = nodes[myNodeID].acquire();\n        prevSearchState = null;\n      }\n\n      final IndexReader[] subs = new IndexReader[numNodes];\n\n      PreviousSearchState searchState = null;\n\n      try {\n\n        // Mock: now make a single reader (MultiReader) from all node\n        // searchers.  In a real shard env you can't do this... we\n        // do it to confirm results from the shard searcher\n        // are correct:\n        int docCount = 0;\n        try {\n          for(int nodeID=0;nodeID<numNodes;nodeID++) {\n            final long subVersion = localShardSearcher.nodeVersions[nodeID];\n            final IndexSearcher sub = nodes[nodeID].searchers.acquire(subVersion);\n            if (sub == null) {\n              nodeID--;\n              while(nodeID >= 0) {\n                subs[nodeID].decRef();\n                subs[nodeID] = null;\n                nodeID--;\n              }\n              throw new SearcherExpiredException(\"nodeID=\" + nodeID + \" version=\" + subVersion);\n            }\n            subs[nodeID] = sub.getIndexReader();\n            docCount += subs[nodeID].maxDoc();\n          }\n        } catch (SearcherExpiredException see) {\n          // Expected\n          if (VERBOSE) {\n            System.out.println(\"  searcher expired during mock reader init: \" + see);\n          }\n          continue;\n        }\n\n        final IndexReader mockReader = new MultiReader(subs);\n        final IndexSearcher mockSearcher = new IndexSearcher(mockReader);\n\n        Query query;\n        Sort sort;\n\n        if (prevSearchState != null) {\n          query = prevSearchState.query;\n          sort = prevSearchState.sort;\n        } else {\n          if (terms == null && docCount > minDocsToMakeTerms) {\n            // TODO: try to \"focus\" on high freq terms sometimes too\n            // TODO: maybe also periodically reset the terms...?\n            final TermsEnum termsEnum = MultiFields.getTerms(mockReader, \"body\").iterator(null);\n            terms = new ArrayList<BytesRef>();\n            while(termsEnum.next() != null) {\n              terms.add(BytesRef.deepCopyOf(termsEnum.term()));\n            }\n            if (VERBOSE) {\n              System.out.println(\"TEST: init terms: \" + terms.size() + \" terms\");\n            }\n            if (terms.size() == 0) {\n              terms = null;\n            }\n          }\n\n          if (VERBOSE) {\n            System.out.println(\"  maxDoc=\" + mockReader.maxDoc());\n          }\n\n          if (terms != null) {\n            if (random().nextBoolean()) {\n              query = new TermQuery(new Term(\"body\", terms.get(random().nextInt(terms.size()))));\n            } else {\n              final String t = terms.get(random().nextInt(terms.size())).utf8ToString();\n              final String prefix;\n              if (t.length() <= 1) {\n                prefix = t;\n              } else {\n                prefix = t.substring(0, _TestUtil.nextInt(random(), 1, 2));\n              }\n              query = new PrefixQuery(new Term(\"body\", prefix));\n            }\n            \n            if (random().nextBoolean()) {\n              sort = null;\n            } else {\n              // TODO: sort by more than 1 field\n              final int what = random().nextInt(3);\n              if (what == 0) {\n                sort = new Sort(SortField.FIELD_SCORE);\n              } else if (what == 1) {\n                // TODO: this sort doesn't merge\n                // correctly... it's tricky because you\n                // could have > 2.1B docs across all shards: \n                //sort = new Sort(SortField.FIELD_DOC);\n                sort = null;\n              } else if (what == 2) {\n                sort = new Sort(new SortField[] {new SortField(\"docid_int\", SortField.Type.INT, random().nextBoolean())});\n              } else {\n                sort = new Sort(new SortField[] {new SortField(\"title\", SortField.Type.STRING, random().nextBoolean())});\n              }\n            }\n          } else {\n            query = null;\n            sort = null;\n          }\n        }\n\n        if (query != null) {\n\n          try {\n            searchState = assertSame(mockSearcher, localShardSearcher, query, sort, prevSearchState);\n          } catch (SearcherExpiredException see) {\n            // Expected; in a \"real\" app we would\n            // either forward this error to the user (\"too\n            // much time has passed; please re-run your\n            // search\") or sneakily just switch to newest\n            // searcher w/o telling them...\n            if (VERBOSE) {\n              System.out.println(\"  searcher expired during search: \" + see);\n              see.printStackTrace(System.out);\n            }\n            // We can't do this in general: on a very slow\n            // computer it's possible the local searcher\n            // expires before we can finish our search:\n            // assert prevSearchState != null;\n            if (prevSearchState != null) {\n              priorSearches.remove(prevSearchState);\n            }\n          }\n        }\n      } finally {\n        nodes[myNodeID].release(localShardSearcher);\n        for(IndexReader sub : subs) {\n          if (sub != null) {\n            sub.decRef();\n          }\n        }\n      }\n\n      if (searchState != null && searchState.searchAfterLocal != null && random().nextInt(5) == 3) {\n        priorSearches.add(searchState);\n        if (priorSearches.size() > 200) {\n          Collections.shuffle(priorSearches, random());\n          priorSearches.subList(100, priorSearches.size()).clear();\n        }\n      }\n    }\n\n    finish();\n  }\n\n","sourceOld":"  public void testSimple() throws Exception {\n    final int numNodes = _TestUtil.nextInt(random(), 1, 10);\n\n    final double runTimeSec = atLeast(3);\n\n    final int minDocsToMakeTerms = _TestUtil.nextInt(random(), 5, 20);\n\n    final int maxSearcherAgeSeconds = _TestUtil.nextInt(random(), 1, 3);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: numNodes=\" + numNodes + \" runTimeSec=\" + runTimeSec + \" maxSearcherAgeSeconds=\" + maxSearcherAgeSeconds);\n    }\n\n    start(numNodes,\n          runTimeSec,\n          maxSearcherAgeSeconds\n          );\n\n    final List<PreviousSearchState> priorSearches = new ArrayList<PreviousSearchState>();\n    List<BytesRef> terms = null;\n    while (System.nanoTime() < endTimeNanos) {\n\n      final boolean doFollowon = priorSearches.size() > 0 && random().nextInt(7) == 1;\n\n      // Pick a random node; we will run the query on this node:\n      final int myNodeID = random().nextInt(numNodes);\n\n      final NodeState.ShardIndexSearcher localShardSearcher;\n\n      final PreviousSearchState prevSearchState;\n\n      if (doFollowon) {\n        // Pretend user issued a followon query:\n        prevSearchState = priorSearches.get(random().nextInt(priorSearches.size()));\n\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: follow-on query age=\" + ((System.nanoTime() - prevSearchState.searchTimeNanos)/1000000000.0));\n        }\n\n        try {\n          localShardSearcher = nodes[myNodeID].acquire(prevSearchState.versions);\n        } catch (SearcherExpiredException see) {\n          // Expected, sometimes; in a \"real\" app we would\n          // either forward this error to the user (\"too\n          // much time has passed; please re-run your\n          // search\") or sneakily just switch to newest\n          // searcher w/o telling them...\n          if (VERBOSE) {\n            System.out.println(\"  searcher expired during local shard searcher init: \" + see);\n          }\n          priorSearches.remove(prevSearchState);\n          continue;\n        }\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: fresh query\");\n        }\n        // Do fresh query:\n        localShardSearcher = nodes[myNodeID].acquire();\n        prevSearchState = null;\n      }\n\n      final IndexReader[] subs = new IndexReader[numNodes];\n\n      PreviousSearchState searchState = null;\n\n      try {\n\n        // Mock: now make a single reader (MultiReader) from all node\n        // searchers.  In a real shard env you can't do this... we\n        // do it to confirm results from the shard searcher\n        // are correct:\n        int docCount = 0;\n        try {\n          for(int nodeID=0;nodeID<numNodes;nodeID++) {\n            final long subVersion = localShardSearcher.nodeVersions[nodeID];\n            final IndexSearcher sub = nodes[nodeID].searchers.acquire(subVersion);\n            if (sub == null) {\n              nodeID--;\n              while(nodeID >= 0) {\n                subs[nodeID].decRef();\n                subs[nodeID] = null;\n                nodeID--;\n              }\n              throw new SearcherExpiredException(\"nodeID=\" + nodeID + \" version=\" + subVersion);\n            }\n            subs[nodeID] = sub.getIndexReader();\n            docCount += subs[nodeID].maxDoc();\n          }\n        } catch (SearcherExpiredException see) {\n          // Expected\n          if (VERBOSE) {\n            System.out.println(\"  searcher expired during mock reader init: \" + see);\n          }\n          continue;\n        }\n\n        final IndexReader mockReader = new MultiReader(subs);\n        final IndexSearcher mockSearcher = new IndexSearcher(mockReader);\n\n        Query query;\n        Sort sort;\n\n        if (prevSearchState != null) {\n          query = prevSearchState.query;\n          sort = prevSearchState.sort;\n        } else {\n          if (terms == null && docCount > minDocsToMakeTerms) {\n            // TODO: try to \"focus\" on high freq terms sometimes too\n            // TODO: maybe also periodically reset the terms...?\n            final TermsEnum termsEnum = MultiFields.getTerms(mockReader, \"body\").iterator(null);\n            terms = new ArrayList<BytesRef>();\n            while(termsEnum.next() != null) {\n              terms.add(BytesRef.deepCopyOf(termsEnum.term()));\n            }\n            if (VERBOSE) {\n              System.out.println(\"TEST: init terms: \" + terms.size() + \" terms\");\n            }\n            if (terms.size() == 0) {\n              terms = null;\n            }\n          }\n\n          if (VERBOSE) {\n            System.out.println(\"  maxDoc=\" + mockReader.maxDoc());\n          }\n\n          if (terms != null) {\n            if (random().nextBoolean()) {\n              query = new TermQuery(new Term(\"body\", terms.get(random().nextInt(terms.size()))));\n            } else {\n              final String t = terms.get(random().nextInt(terms.size())).utf8ToString();\n              final String prefix;\n              if (t.length() <= 1) {\n                prefix = t;\n              } else {\n                prefix = t.substring(0, _TestUtil.nextInt(random(), 1, 2));\n              }\n              query = new PrefixQuery(new Term(\"body\", prefix));\n            }\n            \n            if (random().nextBoolean()) {\n              sort = null;\n            } else {\n              // TODO: sort by more than 1 field\n              final int what = random().nextInt(3);\n              if (what == 0) {\n                sort = new Sort(SortField.FIELD_SCORE);\n              } else if (what == 1) {\n                // TODO: this sort doesn't merge\n                // correctly... it's tricky because you\n                // could have > 2.1B docs across all shards: \n                //sort = new Sort(SortField.FIELD_DOC);\n                sort = null;\n              } else if (what == 2) {\n                sort = new Sort(new SortField[] {new SortField(\"docid\", SortField.Type.INT, random().nextBoolean())});\n              } else {\n                sort = new Sort(new SortField[] {new SortField(\"title\", SortField.Type.STRING, random().nextBoolean())});\n              }\n            }\n          } else {\n            query = null;\n            sort = null;\n          }\n        }\n\n        if (query != null) {\n\n          try {\n            searchState = assertSame(mockSearcher, localShardSearcher, query, sort, prevSearchState);\n          } catch (SearcherExpiredException see) {\n            // Expected; in a \"real\" app we would\n            // either forward this error to the user (\"too\n            // much time has passed; please re-run your\n            // search\") or sneakily just switch to newest\n            // searcher w/o telling them...\n            if (VERBOSE) {\n              System.out.println(\"  searcher expired during search: \" + see);\n              see.printStackTrace(System.out);\n            }\n            // We can't do this in general: on a very slow\n            // computer it's possible the local searcher\n            // expires before we can finish our search:\n            // assert prevSearchState != null;\n            if (prevSearchState != null) {\n              priorSearches.remove(prevSearchState);\n            }\n          }\n        }\n      } finally {\n        nodes[myNodeID].release(localShardSearcher);\n        for(IndexReader sub : subs) {\n          if (sub != null) {\n            sub.decRef();\n          }\n        }\n      }\n\n      if (searchState != null && searchState.searchAfterLocal != null && random().nextInt(5) == 3) {\n        priorSearches.add(searchState);\n        if (priorSearches.size() > 200) {\n          Collections.shuffle(priorSearches, random());\n          priorSearches.subList(100, priorSearches.size()).clear();\n        }\n      }\n    }\n\n    finish();\n  }\n\n","bugFix":null,"bugIntro":["0ed6b1234af94a2693d3e6550e7b3ee41fd3f51c"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"37a0f60745e53927c4c876cfe5b5a58170f0646c","date":1373994005,"type":3,"author":"Han Jiang","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestShardSearching#testSimple().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestShardSearching#testSimple().mjava","sourceNew":"  public void testSimple() throws Exception {\n    final int numNodes = _TestUtil.nextInt(random(), 1, 10);\n\n    final double runTimeSec = atLeast(3);\n\n    final int minDocsToMakeTerms = _TestUtil.nextInt(random(), 5, 20);\n\n    final int maxSearcherAgeSeconds = _TestUtil.nextInt(random(), 1, 3);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: numNodes=\" + numNodes + \" runTimeSec=\" + runTimeSec + \" maxSearcherAgeSeconds=\" + maxSearcherAgeSeconds);\n    }\n\n    start(numNodes,\n          runTimeSec,\n          maxSearcherAgeSeconds\n          );\n\n    final List<PreviousSearchState> priorSearches = new ArrayList<PreviousSearchState>();\n    List<BytesRef> terms = null;\n    while (System.nanoTime() < endTimeNanos) {\n\n      final boolean doFollowon = priorSearches.size() > 0 && random().nextInt(7) == 1;\n\n      // Pick a random node; we will run the query on this node:\n      final int myNodeID = random().nextInt(numNodes);\n\n      final NodeState.ShardIndexSearcher localShardSearcher;\n\n      final PreviousSearchState prevSearchState;\n\n      if (doFollowon) {\n        // Pretend user issued a followon query:\n        prevSearchState = priorSearches.get(random().nextInt(priorSearches.size()));\n\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: follow-on query age=\" + ((System.nanoTime() - prevSearchState.searchTimeNanos)/1000000000.0));\n        }\n\n        try {\n          localShardSearcher = nodes[myNodeID].acquire(prevSearchState.versions);\n        } catch (SearcherExpiredException see) {\n          // Expected, sometimes; in a \"real\" app we would\n          // either forward this error to the user (\"too\n          // much time has passed; please re-run your\n          // search\") or sneakily just switch to newest\n          // searcher w/o telling them...\n          if (VERBOSE) {\n            System.out.println(\"  searcher expired during local shard searcher init: \" + see);\n          }\n          priorSearches.remove(prevSearchState);\n          continue;\n        }\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: fresh query\");\n        }\n        // Do fresh query:\n        localShardSearcher = nodes[myNodeID].acquire();\n        prevSearchState = null;\n      }\n\n      final IndexReader[] subs = new IndexReader[numNodes];\n\n      PreviousSearchState searchState = null;\n\n      try {\n\n        // Mock: now make a single reader (MultiReader) from all node\n        // searchers.  In a real shard env you can't do this... we\n        // do it to confirm results from the shard searcher\n        // are correct:\n        int docCount = 0;\n        try {\n          for(int nodeID=0;nodeID<numNodes;nodeID++) {\n            final long subVersion = localShardSearcher.nodeVersions[nodeID];\n            final IndexSearcher sub = nodes[nodeID].searchers.acquire(subVersion);\n            if (sub == null) {\n              nodeID--;\n              while(nodeID >= 0) {\n                subs[nodeID].decRef();\n                subs[nodeID] = null;\n                nodeID--;\n              }\n              throw new SearcherExpiredException(\"nodeID=\" + nodeID + \" version=\" + subVersion);\n            }\n            subs[nodeID] = sub.getIndexReader();\n            docCount += subs[nodeID].maxDoc();\n          }\n        } catch (SearcherExpiredException see) {\n          // Expected\n          if (VERBOSE) {\n            System.out.println(\"  searcher expired during mock reader init: \" + see);\n          }\n          continue;\n        }\n\n        final IndexReader mockReader = new MultiReader(subs);\n        final IndexSearcher mockSearcher = new IndexSearcher(mockReader);\n\n        Query query;\n        Sort sort;\n\n        if (prevSearchState != null) {\n          query = prevSearchState.query;\n          sort = prevSearchState.sort;\n        } else {\n          if (terms == null && docCount > minDocsToMakeTerms) {\n            // TODO: try to \"focus\" on high freq terms sometimes too\n            // TODO: maybe also periodically reset the terms...?\n            final TermsEnum termsEnum = MultiFields.getTerms(mockReader, \"body\").iterator(null);\n            terms = new ArrayList<BytesRef>();\n            while(termsEnum.next() != null) {\n              terms.add(BytesRef.deepCopyOf(termsEnum.term()));\n            }\n            if (VERBOSE) {\n              System.out.println(\"TEST: init terms: \" + terms.size() + \" terms\");\n            }\n            if (terms.size() == 0) {\n              terms = null;\n            }\n          }\n\n          if (VERBOSE) {\n            System.out.println(\"  maxDoc=\" + mockReader.maxDoc());\n          }\n\n          if (terms != null) {\n            if (random().nextBoolean()) {\n              query = new TermQuery(new Term(\"body\", terms.get(random().nextInt(terms.size()))));\n            } else {\n              final String t = terms.get(random().nextInt(terms.size())).utf8ToString();\n              final String prefix;\n              if (t.length() <= 1) {\n                prefix = t;\n              } else {\n                prefix = t.substring(0, _TestUtil.nextInt(random(), 1, 2));\n              }\n              query = new PrefixQuery(new Term(\"body\", prefix));\n            }\n            \n            if (random().nextBoolean()) {\n              sort = null;\n            } else {\n              // TODO: sort by more than 1 field\n              final int what = random().nextInt(3);\n              if (what == 0) {\n                sort = new Sort(SortField.FIELD_SCORE);\n              } else if (what == 1) {\n                // TODO: this sort doesn't merge\n                // correctly... it's tricky because you\n                // could have > 2.1B docs across all shards: \n                //sort = new Sort(SortField.FIELD_DOC);\n                sort = null;\n              } else if (what == 2) {\n                sort = new Sort(new SortField[] {new SortField(\"docid_int\", SortField.Type.INT, random().nextBoolean())});\n              } else {\n                sort = new Sort(new SortField[] {new SortField(\"title\", SortField.Type.STRING, random().nextBoolean())});\n              }\n            }\n          } else {\n            query = null;\n            sort = null;\n          }\n        }\n\n        if (query != null) {\n\n          try {\n            searchState = assertSame(mockSearcher, localShardSearcher, query, sort, prevSearchState);\n          } catch (SearcherExpiredException see) {\n            // Expected; in a \"real\" app we would\n            // either forward this error to the user (\"too\n            // much time has passed; please re-run your\n            // search\") or sneakily just switch to newest\n            // searcher w/o telling them...\n            if (VERBOSE) {\n              System.out.println(\"  searcher expired during search: \" + see);\n              see.printStackTrace(System.out);\n            }\n            // We can't do this in general: on a very slow\n            // computer it's possible the local searcher\n            // expires before we can finish our search:\n            // assert prevSearchState != null;\n            if (prevSearchState != null) {\n              priorSearches.remove(prevSearchState);\n            }\n          }\n        }\n      } finally {\n        nodes[myNodeID].release(localShardSearcher);\n        for(IndexReader sub : subs) {\n          if (sub != null) {\n            sub.decRef();\n          }\n        }\n      }\n\n      if (searchState != null && searchState.searchAfterLocal != null && random().nextInt(5) == 3) {\n        priorSearches.add(searchState);\n        if (priorSearches.size() > 200) {\n          Collections.shuffle(priorSearches, random());\n          priorSearches.subList(100, priorSearches.size()).clear();\n        }\n      }\n    }\n\n    finish();\n  }\n\n","sourceOld":"  public void testSimple() throws Exception {\n    final int numNodes = _TestUtil.nextInt(random(), 1, 10);\n\n    final double runTimeSec = atLeast(3);\n\n    final int minDocsToMakeTerms = _TestUtil.nextInt(random(), 5, 20);\n\n    final int maxSearcherAgeSeconds = _TestUtil.nextInt(random(), 1, 3);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: numNodes=\" + numNodes + \" runTimeSec=\" + runTimeSec + \" maxSearcherAgeSeconds=\" + maxSearcherAgeSeconds);\n    }\n\n    start(numNodes,\n          runTimeSec,\n          maxSearcherAgeSeconds\n          );\n\n    final List<PreviousSearchState> priorSearches = new ArrayList<PreviousSearchState>();\n    List<BytesRef> terms = null;\n    while (System.nanoTime() < endTimeNanos) {\n\n      final boolean doFollowon = priorSearches.size() > 0 && random().nextInt(7) == 1;\n\n      // Pick a random node; we will run the query on this node:\n      final int myNodeID = random().nextInt(numNodes);\n\n      final NodeState.ShardIndexSearcher localShardSearcher;\n\n      final PreviousSearchState prevSearchState;\n\n      if (doFollowon) {\n        // Pretend user issued a followon query:\n        prevSearchState = priorSearches.get(random().nextInt(priorSearches.size()));\n\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: follow-on query age=\" + ((System.nanoTime() - prevSearchState.searchTimeNanos)/1000000000.0));\n        }\n\n        try {\n          localShardSearcher = nodes[myNodeID].acquire(prevSearchState.versions);\n        } catch (SearcherExpiredException see) {\n          // Expected, sometimes; in a \"real\" app we would\n          // either forward this error to the user (\"too\n          // much time has passed; please re-run your\n          // search\") or sneakily just switch to newest\n          // searcher w/o telling them...\n          if (VERBOSE) {\n            System.out.println(\"  searcher expired during local shard searcher init: \" + see);\n          }\n          priorSearches.remove(prevSearchState);\n          continue;\n        }\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: fresh query\");\n        }\n        // Do fresh query:\n        localShardSearcher = nodes[myNodeID].acquire();\n        prevSearchState = null;\n      }\n\n      final IndexReader[] subs = new IndexReader[numNodes];\n\n      PreviousSearchState searchState = null;\n\n      try {\n\n        // Mock: now make a single reader (MultiReader) from all node\n        // searchers.  In a real shard env you can't do this... we\n        // do it to confirm results from the shard searcher\n        // are correct:\n        int docCount = 0;\n        try {\n          for(int nodeID=0;nodeID<numNodes;nodeID++) {\n            final long subVersion = localShardSearcher.nodeVersions[nodeID];\n            final IndexSearcher sub = nodes[nodeID].searchers.acquire(subVersion);\n            if (sub == null) {\n              nodeID--;\n              while(nodeID >= 0) {\n                subs[nodeID].decRef();\n                subs[nodeID] = null;\n                nodeID--;\n              }\n              throw new SearcherExpiredException(\"nodeID=\" + nodeID + \" version=\" + subVersion);\n            }\n            subs[nodeID] = sub.getIndexReader();\n            docCount += subs[nodeID].maxDoc();\n          }\n        } catch (SearcherExpiredException see) {\n          // Expected\n          if (VERBOSE) {\n            System.out.println(\"  searcher expired during mock reader init: \" + see);\n          }\n          continue;\n        }\n\n        final IndexReader mockReader = new MultiReader(subs);\n        final IndexSearcher mockSearcher = new IndexSearcher(mockReader);\n\n        Query query;\n        Sort sort;\n\n        if (prevSearchState != null) {\n          query = prevSearchState.query;\n          sort = prevSearchState.sort;\n        } else {\n          if (terms == null && docCount > minDocsToMakeTerms) {\n            // TODO: try to \"focus\" on high freq terms sometimes too\n            // TODO: maybe also periodically reset the terms...?\n            final TermsEnum termsEnum = MultiFields.getTerms(mockReader, \"body\").iterator(null);\n            terms = new ArrayList<BytesRef>();\n            while(termsEnum.next() != null) {\n              terms.add(BytesRef.deepCopyOf(termsEnum.term()));\n            }\n            if (VERBOSE) {\n              System.out.println(\"TEST: init terms: \" + terms.size() + \" terms\");\n            }\n            if (terms.size() == 0) {\n              terms = null;\n            }\n          }\n\n          if (VERBOSE) {\n            System.out.println(\"  maxDoc=\" + mockReader.maxDoc());\n          }\n\n          if (terms != null) {\n            if (random().nextBoolean()) {\n              query = new TermQuery(new Term(\"body\", terms.get(random().nextInt(terms.size()))));\n            } else {\n              final String t = terms.get(random().nextInt(terms.size())).utf8ToString();\n              final String prefix;\n              if (t.length() <= 1) {\n                prefix = t;\n              } else {\n                prefix = t.substring(0, _TestUtil.nextInt(random(), 1, 2));\n              }\n              query = new PrefixQuery(new Term(\"body\", prefix));\n            }\n            \n            if (random().nextBoolean()) {\n              sort = null;\n            } else {\n              // TODO: sort by more than 1 field\n              final int what = random().nextInt(3);\n              if (what == 0) {\n                sort = new Sort(SortField.FIELD_SCORE);\n              } else if (what == 1) {\n                // TODO: this sort doesn't merge\n                // correctly... it's tricky because you\n                // could have > 2.1B docs across all shards: \n                //sort = new Sort(SortField.FIELD_DOC);\n                sort = null;\n              } else if (what == 2) {\n                sort = new Sort(new SortField[] {new SortField(\"docid\", SortField.Type.INT, random().nextBoolean())});\n              } else {\n                sort = new Sort(new SortField[] {new SortField(\"title\", SortField.Type.STRING, random().nextBoolean())});\n              }\n            }\n          } else {\n            query = null;\n            sort = null;\n          }\n        }\n\n        if (query != null) {\n\n          try {\n            searchState = assertSame(mockSearcher, localShardSearcher, query, sort, prevSearchState);\n          } catch (SearcherExpiredException see) {\n            // Expected; in a \"real\" app we would\n            // either forward this error to the user (\"too\n            // much time has passed; please re-run your\n            // search\") or sneakily just switch to newest\n            // searcher w/o telling them...\n            if (VERBOSE) {\n              System.out.println(\"  searcher expired during search: \" + see);\n              see.printStackTrace(System.out);\n            }\n            // We can't do this in general: on a very slow\n            // computer it's possible the local searcher\n            // expires before we can finish our search:\n            // assert prevSearchState != null;\n            if (prevSearchState != null) {\n              priorSearches.remove(prevSearchState);\n            }\n          }\n        }\n      } finally {\n        nodes[myNodeID].release(localShardSearcher);\n        for(IndexReader sub : subs) {\n          if (sub != null) {\n            sub.decRef();\n          }\n        }\n      }\n\n      if (searchState != null && searchState.searchAfterLocal != null && random().nextInt(5) == 3) {\n        priorSearches.add(searchState);\n        if (priorSearches.size() > 200) {\n          Collections.shuffle(priorSearches, random());\n          priorSearches.subList(100, priorSearches.size()).clear();\n        }\n      }\n    }\n\n    finish();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6613659748fe4411a7dcf85266e55db1f95f7315","date":1392773913,"type":3,"author":"Benson Margulies","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestShardSearching#testSimple().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestShardSearching#testSimple().mjava","sourceNew":"  public void testSimple() throws Exception {\n    final int numNodes = TestUtil.nextInt(random(), 1, 10);\n\n    final double runTimeSec = atLeast(3);\n\n    final int minDocsToMakeTerms = TestUtil.nextInt(random(), 5, 20);\n\n    final int maxSearcherAgeSeconds = TestUtil.nextInt(random(), 1, 3);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: numNodes=\" + numNodes + \" runTimeSec=\" + runTimeSec + \" maxSearcherAgeSeconds=\" + maxSearcherAgeSeconds);\n    }\n\n    start(numNodes,\n          runTimeSec,\n          maxSearcherAgeSeconds\n          );\n\n    final List<PreviousSearchState> priorSearches = new ArrayList<PreviousSearchState>();\n    List<BytesRef> terms = null;\n    while (System.nanoTime() < endTimeNanos) {\n\n      final boolean doFollowon = priorSearches.size() > 0 && random().nextInt(7) == 1;\n\n      // Pick a random node; we will run the query on this node:\n      final int myNodeID = random().nextInt(numNodes);\n\n      final NodeState.ShardIndexSearcher localShardSearcher;\n\n      final PreviousSearchState prevSearchState;\n\n      if (doFollowon) {\n        // Pretend user issued a followon query:\n        prevSearchState = priorSearches.get(random().nextInt(priorSearches.size()));\n\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: follow-on query age=\" + ((System.nanoTime() - prevSearchState.searchTimeNanos)/1000000000.0));\n        }\n\n        try {\n          localShardSearcher = nodes[myNodeID].acquire(prevSearchState.versions);\n        } catch (SearcherExpiredException see) {\n          // Expected, sometimes; in a \"real\" app we would\n          // either forward this error to the user (\"too\n          // much time has passed; please re-run your\n          // search\") or sneakily just switch to newest\n          // searcher w/o telling them...\n          if (VERBOSE) {\n            System.out.println(\"  searcher expired during local shard searcher init: \" + see);\n          }\n          priorSearches.remove(prevSearchState);\n          continue;\n        }\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: fresh query\");\n        }\n        // Do fresh query:\n        localShardSearcher = nodes[myNodeID].acquire();\n        prevSearchState = null;\n      }\n\n      final IndexReader[] subs = new IndexReader[numNodes];\n\n      PreviousSearchState searchState = null;\n\n      try {\n\n        // Mock: now make a single reader (MultiReader) from all node\n        // searchers.  In a real shard env you can't do this... we\n        // do it to confirm results from the shard searcher\n        // are correct:\n        int docCount = 0;\n        try {\n          for(int nodeID=0;nodeID<numNodes;nodeID++) {\n            final long subVersion = localShardSearcher.nodeVersions[nodeID];\n            final IndexSearcher sub = nodes[nodeID].searchers.acquire(subVersion);\n            if (sub == null) {\n              nodeID--;\n              while(nodeID >= 0) {\n                subs[nodeID].decRef();\n                subs[nodeID] = null;\n                nodeID--;\n              }\n              throw new SearcherExpiredException(\"nodeID=\" + nodeID + \" version=\" + subVersion);\n            }\n            subs[nodeID] = sub.getIndexReader();\n            docCount += subs[nodeID].maxDoc();\n          }\n        } catch (SearcherExpiredException see) {\n          // Expected\n          if (VERBOSE) {\n            System.out.println(\"  searcher expired during mock reader init: \" + see);\n          }\n          continue;\n        }\n\n        final IndexReader mockReader = new MultiReader(subs);\n        final IndexSearcher mockSearcher = new IndexSearcher(mockReader);\n\n        Query query;\n        Sort sort;\n\n        if (prevSearchState != null) {\n          query = prevSearchState.query;\n          sort = prevSearchState.sort;\n        } else {\n          if (terms == null && docCount > minDocsToMakeTerms) {\n            // TODO: try to \"focus\" on high freq terms sometimes too\n            // TODO: maybe also periodically reset the terms...?\n            final TermsEnum termsEnum = MultiFields.getTerms(mockReader, \"body\").iterator(null);\n            terms = new ArrayList<BytesRef>();\n            while(termsEnum.next() != null) {\n              terms.add(BytesRef.deepCopyOf(termsEnum.term()));\n            }\n            if (VERBOSE) {\n              System.out.println(\"TEST: init terms: \" + terms.size() + \" terms\");\n            }\n            if (terms.size() == 0) {\n              terms = null;\n            }\n          }\n\n          if (VERBOSE) {\n            System.out.println(\"  maxDoc=\" + mockReader.maxDoc());\n          }\n\n          if (terms != null) {\n            if (random().nextBoolean()) {\n              query = new TermQuery(new Term(\"body\", terms.get(random().nextInt(terms.size()))));\n            } else {\n              final String t = terms.get(random().nextInt(terms.size())).utf8ToString();\n              final String prefix;\n              if (t.length() <= 1) {\n                prefix = t;\n              } else {\n                prefix = t.substring(0, TestUtil.nextInt(random(), 1, 2));\n              }\n              query = new PrefixQuery(new Term(\"body\", prefix));\n            }\n            \n            if (random().nextBoolean()) {\n              sort = null;\n            } else {\n              // TODO: sort by more than 1 field\n              final int what = random().nextInt(3);\n              if (what == 0) {\n                sort = new Sort(SortField.FIELD_SCORE);\n              } else if (what == 1) {\n                // TODO: this sort doesn't merge\n                // correctly... it's tricky because you\n                // could have > 2.1B docs across all shards: \n                //sort = new Sort(SortField.FIELD_DOC);\n                sort = null;\n              } else if (what == 2) {\n                sort = new Sort(new SortField[] {new SortField(\"docid_int\", SortField.Type.INT, random().nextBoolean())});\n              } else {\n                sort = new Sort(new SortField[] {new SortField(\"title\", SortField.Type.STRING, random().nextBoolean())});\n              }\n            }\n          } else {\n            query = null;\n            sort = null;\n          }\n        }\n\n        if (query != null) {\n\n          try {\n            searchState = assertSame(mockSearcher, localShardSearcher, query, sort, prevSearchState);\n          } catch (SearcherExpiredException see) {\n            // Expected; in a \"real\" app we would\n            // either forward this error to the user (\"too\n            // much time has passed; please re-run your\n            // search\") or sneakily just switch to newest\n            // searcher w/o telling them...\n            if (VERBOSE) {\n              System.out.println(\"  searcher expired during search: \" + see);\n              see.printStackTrace(System.out);\n            }\n            // We can't do this in general: on a very slow\n            // computer it's possible the local searcher\n            // expires before we can finish our search:\n            // assert prevSearchState != null;\n            if (prevSearchState != null) {\n              priorSearches.remove(prevSearchState);\n            }\n          }\n        }\n      } finally {\n        nodes[myNodeID].release(localShardSearcher);\n        for(IndexReader sub : subs) {\n          if (sub != null) {\n            sub.decRef();\n          }\n        }\n      }\n\n      if (searchState != null && searchState.searchAfterLocal != null && random().nextInt(5) == 3) {\n        priorSearches.add(searchState);\n        if (priorSearches.size() > 200) {\n          Collections.shuffle(priorSearches, random());\n          priorSearches.subList(100, priorSearches.size()).clear();\n        }\n      }\n    }\n\n    finish();\n  }\n\n","sourceOld":"  public void testSimple() throws Exception {\n    final int numNodes = _TestUtil.nextInt(random(), 1, 10);\n\n    final double runTimeSec = atLeast(3);\n\n    final int minDocsToMakeTerms = _TestUtil.nextInt(random(), 5, 20);\n\n    final int maxSearcherAgeSeconds = _TestUtil.nextInt(random(), 1, 3);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: numNodes=\" + numNodes + \" runTimeSec=\" + runTimeSec + \" maxSearcherAgeSeconds=\" + maxSearcherAgeSeconds);\n    }\n\n    start(numNodes,\n          runTimeSec,\n          maxSearcherAgeSeconds\n          );\n\n    final List<PreviousSearchState> priorSearches = new ArrayList<PreviousSearchState>();\n    List<BytesRef> terms = null;\n    while (System.nanoTime() < endTimeNanos) {\n\n      final boolean doFollowon = priorSearches.size() > 0 && random().nextInt(7) == 1;\n\n      // Pick a random node; we will run the query on this node:\n      final int myNodeID = random().nextInt(numNodes);\n\n      final NodeState.ShardIndexSearcher localShardSearcher;\n\n      final PreviousSearchState prevSearchState;\n\n      if (doFollowon) {\n        // Pretend user issued a followon query:\n        prevSearchState = priorSearches.get(random().nextInt(priorSearches.size()));\n\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: follow-on query age=\" + ((System.nanoTime() - prevSearchState.searchTimeNanos)/1000000000.0));\n        }\n\n        try {\n          localShardSearcher = nodes[myNodeID].acquire(prevSearchState.versions);\n        } catch (SearcherExpiredException see) {\n          // Expected, sometimes; in a \"real\" app we would\n          // either forward this error to the user (\"too\n          // much time has passed; please re-run your\n          // search\") or sneakily just switch to newest\n          // searcher w/o telling them...\n          if (VERBOSE) {\n            System.out.println(\"  searcher expired during local shard searcher init: \" + see);\n          }\n          priorSearches.remove(prevSearchState);\n          continue;\n        }\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: fresh query\");\n        }\n        // Do fresh query:\n        localShardSearcher = nodes[myNodeID].acquire();\n        prevSearchState = null;\n      }\n\n      final IndexReader[] subs = new IndexReader[numNodes];\n\n      PreviousSearchState searchState = null;\n\n      try {\n\n        // Mock: now make a single reader (MultiReader) from all node\n        // searchers.  In a real shard env you can't do this... we\n        // do it to confirm results from the shard searcher\n        // are correct:\n        int docCount = 0;\n        try {\n          for(int nodeID=0;nodeID<numNodes;nodeID++) {\n            final long subVersion = localShardSearcher.nodeVersions[nodeID];\n            final IndexSearcher sub = nodes[nodeID].searchers.acquire(subVersion);\n            if (sub == null) {\n              nodeID--;\n              while(nodeID >= 0) {\n                subs[nodeID].decRef();\n                subs[nodeID] = null;\n                nodeID--;\n              }\n              throw new SearcherExpiredException(\"nodeID=\" + nodeID + \" version=\" + subVersion);\n            }\n            subs[nodeID] = sub.getIndexReader();\n            docCount += subs[nodeID].maxDoc();\n          }\n        } catch (SearcherExpiredException see) {\n          // Expected\n          if (VERBOSE) {\n            System.out.println(\"  searcher expired during mock reader init: \" + see);\n          }\n          continue;\n        }\n\n        final IndexReader mockReader = new MultiReader(subs);\n        final IndexSearcher mockSearcher = new IndexSearcher(mockReader);\n\n        Query query;\n        Sort sort;\n\n        if (prevSearchState != null) {\n          query = prevSearchState.query;\n          sort = prevSearchState.sort;\n        } else {\n          if (terms == null && docCount > minDocsToMakeTerms) {\n            // TODO: try to \"focus\" on high freq terms sometimes too\n            // TODO: maybe also periodically reset the terms...?\n            final TermsEnum termsEnum = MultiFields.getTerms(mockReader, \"body\").iterator(null);\n            terms = new ArrayList<BytesRef>();\n            while(termsEnum.next() != null) {\n              terms.add(BytesRef.deepCopyOf(termsEnum.term()));\n            }\n            if (VERBOSE) {\n              System.out.println(\"TEST: init terms: \" + terms.size() + \" terms\");\n            }\n            if (terms.size() == 0) {\n              terms = null;\n            }\n          }\n\n          if (VERBOSE) {\n            System.out.println(\"  maxDoc=\" + mockReader.maxDoc());\n          }\n\n          if (terms != null) {\n            if (random().nextBoolean()) {\n              query = new TermQuery(new Term(\"body\", terms.get(random().nextInt(terms.size()))));\n            } else {\n              final String t = terms.get(random().nextInt(terms.size())).utf8ToString();\n              final String prefix;\n              if (t.length() <= 1) {\n                prefix = t;\n              } else {\n                prefix = t.substring(0, _TestUtil.nextInt(random(), 1, 2));\n              }\n              query = new PrefixQuery(new Term(\"body\", prefix));\n            }\n            \n            if (random().nextBoolean()) {\n              sort = null;\n            } else {\n              // TODO: sort by more than 1 field\n              final int what = random().nextInt(3);\n              if (what == 0) {\n                sort = new Sort(SortField.FIELD_SCORE);\n              } else if (what == 1) {\n                // TODO: this sort doesn't merge\n                // correctly... it's tricky because you\n                // could have > 2.1B docs across all shards: \n                //sort = new Sort(SortField.FIELD_DOC);\n                sort = null;\n              } else if (what == 2) {\n                sort = new Sort(new SortField[] {new SortField(\"docid_int\", SortField.Type.INT, random().nextBoolean())});\n              } else {\n                sort = new Sort(new SortField[] {new SortField(\"title\", SortField.Type.STRING, random().nextBoolean())});\n              }\n            }\n          } else {\n            query = null;\n            sort = null;\n          }\n        }\n\n        if (query != null) {\n\n          try {\n            searchState = assertSame(mockSearcher, localShardSearcher, query, sort, prevSearchState);\n          } catch (SearcherExpiredException see) {\n            // Expected; in a \"real\" app we would\n            // either forward this error to the user (\"too\n            // much time has passed; please re-run your\n            // search\") or sneakily just switch to newest\n            // searcher w/o telling them...\n            if (VERBOSE) {\n              System.out.println(\"  searcher expired during search: \" + see);\n              see.printStackTrace(System.out);\n            }\n            // We can't do this in general: on a very slow\n            // computer it's possible the local searcher\n            // expires before we can finish our search:\n            // assert prevSearchState != null;\n            if (prevSearchState != null) {\n              priorSearches.remove(prevSearchState);\n            }\n          }\n        }\n      } finally {\n        nodes[myNodeID].release(localShardSearcher);\n        for(IndexReader sub : subs) {\n          if (sub != null) {\n            sub.decRef();\n          }\n        }\n      }\n\n      if (searchState != null && searchState.searchAfterLocal != null && random().nextInt(5) == 3) {\n        priorSearches.add(searchState);\n        if (priorSearches.size() > 200) {\n          Collections.shuffle(priorSearches, random());\n          priorSearches.subList(100, priorSearches.size()).clear();\n        }\n      }\n    }\n\n    finish();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"634f330c54fd3f9f491d52036dc3f40b4f4d8934","date":1394635157,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestShardSearching#testSimple().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestShardSearching#testSimple().mjava","sourceNew":"  public void testSimple() throws Exception {\n    final int numNodes = TestUtil.nextInt(random(), 1, 10);\n\n    final double runTimeSec = atLeast(3);\n\n    final int minDocsToMakeTerms = TestUtil.nextInt(random(), 5, 20);\n\n    final int maxSearcherAgeSeconds = TestUtil.nextInt(random(), 1, 3);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: numNodes=\" + numNodes + \" runTimeSec=\" + runTimeSec + \" maxSearcherAgeSeconds=\" + maxSearcherAgeSeconds);\n    }\n\n    start(numNodes,\n          runTimeSec,\n          maxSearcherAgeSeconds\n          );\n\n    final List<PreviousSearchState> priorSearches = new ArrayList<>();\n    List<BytesRef> terms = null;\n    while (System.nanoTime() < endTimeNanos) {\n\n      final boolean doFollowon = priorSearches.size() > 0 && random().nextInt(7) == 1;\n\n      // Pick a random node; we will run the query on this node:\n      final int myNodeID = random().nextInt(numNodes);\n\n      final NodeState.ShardIndexSearcher localShardSearcher;\n\n      final PreviousSearchState prevSearchState;\n\n      if (doFollowon) {\n        // Pretend user issued a followon query:\n        prevSearchState = priorSearches.get(random().nextInt(priorSearches.size()));\n\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: follow-on query age=\" + ((System.nanoTime() - prevSearchState.searchTimeNanos)/1000000000.0));\n        }\n\n        try {\n          localShardSearcher = nodes[myNodeID].acquire(prevSearchState.versions);\n        } catch (SearcherExpiredException see) {\n          // Expected, sometimes; in a \"real\" app we would\n          // either forward this error to the user (\"too\n          // much time has passed; please re-run your\n          // search\") or sneakily just switch to newest\n          // searcher w/o telling them...\n          if (VERBOSE) {\n            System.out.println(\"  searcher expired during local shard searcher init: \" + see);\n          }\n          priorSearches.remove(prevSearchState);\n          continue;\n        }\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: fresh query\");\n        }\n        // Do fresh query:\n        localShardSearcher = nodes[myNodeID].acquire();\n        prevSearchState = null;\n      }\n\n      final IndexReader[] subs = new IndexReader[numNodes];\n\n      PreviousSearchState searchState = null;\n\n      try {\n\n        // Mock: now make a single reader (MultiReader) from all node\n        // searchers.  In a real shard env you can't do this... we\n        // do it to confirm results from the shard searcher\n        // are correct:\n        int docCount = 0;\n        try {\n          for(int nodeID=0;nodeID<numNodes;nodeID++) {\n            final long subVersion = localShardSearcher.nodeVersions[nodeID];\n            final IndexSearcher sub = nodes[nodeID].searchers.acquire(subVersion);\n            if (sub == null) {\n              nodeID--;\n              while(nodeID >= 0) {\n                subs[nodeID].decRef();\n                subs[nodeID] = null;\n                nodeID--;\n              }\n              throw new SearcherExpiredException(\"nodeID=\" + nodeID + \" version=\" + subVersion);\n            }\n            subs[nodeID] = sub.getIndexReader();\n            docCount += subs[nodeID].maxDoc();\n          }\n        } catch (SearcherExpiredException see) {\n          // Expected\n          if (VERBOSE) {\n            System.out.println(\"  searcher expired during mock reader init: \" + see);\n          }\n          continue;\n        }\n\n        final IndexReader mockReader = new MultiReader(subs);\n        final IndexSearcher mockSearcher = new IndexSearcher(mockReader);\n\n        Query query;\n        Sort sort;\n\n        if (prevSearchState != null) {\n          query = prevSearchState.query;\n          sort = prevSearchState.sort;\n        } else {\n          if (terms == null && docCount > minDocsToMakeTerms) {\n            // TODO: try to \"focus\" on high freq terms sometimes too\n            // TODO: maybe also periodically reset the terms...?\n            final TermsEnum termsEnum = MultiFields.getTerms(mockReader, \"body\").iterator(null);\n            terms = new ArrayList<>();\n            while(termsEnum.next() != null) {\n              terms.add(BytesRef.deepCopyOf(termsEnum.term()));\n            }\n            if (VERBOSE) {\n              System.out.println(\"TEST: init terms: \" + terms.size() + \" terms\");\n            }\n            if (terms.size() == 0) {\n              terms = null;\n            }\n          }\n\n          if (VERBOSE) {\n            System.out.println(\"  maxDoc=\" + mockReader.maxDoc());\n          }\n\n          if (terms != null) {\n            if (random().nextBoolean()) {\n              query = new TermQuery(new Term(\"body\", terms.get(random().nextInt(terms.size()))));\n            } else {\n              final String t = terms.get(random().nextInt(terms.size())).utf8ToString();\n              final String prefix;\n              if (t.length() <= 1) {\n                prefix = t;\n              } else {\n                prefix = t.substring(0, TestUtil.nextInt(random(), 1, 2));\n              }\n              query = new PrefixQuery(new Term(\"body\", prefix));\n            }\n            \n            if (random().nextBoolean()) {\n              sort = null;\n            } else {\n              // TODO: sort by more than 1 field\n              final int what = random().nextInt(3);\n              if (what == 0) {\n                sort = new Sort(SortField.FIELD_SCORE);\n              } else if (what == 1) {\n                // TODO: this sort doesn't merge\n                // correctly... it's tricky because you\n                // could have > 2.1B docs across all shards: \n                //sort = new Sort(SortField.FIELD_DOC);\n                sort = null;\n              } else if (what == 2) {\n                sort = new Sort(new SortField[] {new SortField(\"docid_int\", SortField.Type.INT, random().nextBoolean())});\n              } else {\n                sort = new Sort(new SortField[] {new SortField(\"title\", SortField.Type.STRING, random().nextBoolean())});\n              }\n            }\n          } else {\n            query = null;\n            sort = null;\n          }\n        }\n\n        if (query != null) {\n\n          try {\n            searchState = assertSame(mockSearcher, localShardSearcher, query, sort, prevSearchState);\n          } catch (SearcherExpiredException see) {\n            // Expected; in a \"real\" app we would\n            // either forward this error to the user (\"too\n            // much time has passed; please re-run your\n            // search\") or sneakily just switch to newest\n            // searcher w/o telling them...\n            if (VERBOSE) {\n              System.out.println(\"  searcher expired during search: \" + see);\n              see.printStackTrace(System.out);\n            }\n            // We can't do this in general: on a very slow\n            // computer it's possible the local searcher\n            // expires before we can finish our search:\n            // assert prevSearchState != null;\n            if (prevSearchState != null) {\n              priorSearches.remove(prevSearchState);\n            }\n          }\n        }\n      } finally {\n        nodes[myNodeID].release(localShardSearcher);\n        for(IndexReader sub : subs) {\n          if (sub != null) {\n            sub.decRef();\n          }\n        }\n      }\n\n      if (searchState != null && searchState.searchAfterLocal != null && random().nextInt(5) == 3) {\n        priorSearches.add(searchState);\n        if (priorSearches.size() > 200) {\n          Collections.shuffle(priorSearches, random());\n          priorSearches.subList(100, priorSearches.size()).clear();\n        }\n      }\n    }\n\n    finish();\n  }\n\n","sourceOld":"  public void testSimple() throws Exception {\n    final int numNodes = TestUtil.nextInt(random(), 1, 10);\n\n    final double runTimeSec = atLeast(3);\n\n    final int minDocsToMakeTerms = TestUtil.nextInt(random(), 5, 20);\n\n    final int maxSearcherAgeSeconds = TestUtil.nextInt(random(), 1, 3);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: numNodes=\" + numNodes + \" runTimeSec=\" + runTimeSec + \" maxSearcherAgeSeconds=\" + maxSearcherAgeSeconds);\n    }\n\n    start(numNodes,\n          runTimeSec,\n          maxSearcherAgeSeconds\n          );\n\n    final List<PreviousSearchState> priorSearches = new ArrayList<PreviousSearchState>();\n    List<BytesRef> terms = null;\n    while (System.nanoTime() < endTimeNanos) {\n\n      final boolean doFollowon = priorSearches.size() > 0 && random().nextInt(7) == 1;\n\n      // Pick a random node; we will run the query on this node:\n      final int myNodeID = random().nextInt(numNodes);\n\n      final NodeState.ShardIndexSearcher localShardSearcher;\n\n      final PreviousSearchState prevSearchState;\n\n      if (doFollowon) {\n        // Pretend user issued a followon query:\n        prevSearchState = priorSearches.get(random().nextInt(priorSearches.size()));\n\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: follow-on query age=\" + ((System.nanoTime() - prevSearchState.searchTimeNanos)/1000000000.0));\n        }\n\n        try {\n          localShardSearcher = nodes[myNodeID].acquire(prevSearchState.versions);\n        } catch (SearcherExpiredException see) {\n          // Expected, sometimes; in a \"real\" app we would\n          // either forward this error to the user (\"too\n          // much time has passed; please re-run your\n          // search\") or sneakily just switch to newest\n          // searcher w/o telling them...\n          if (VERBOSE) {\n            System.out.println(\"  searcher expired during local shard searcher init: \" + see);\n          }\n          priorSearches.remove(prevSearchState);\n          continue;\n        }\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: fresh query\");\n        }\n        // Do fresh query:\n        localShardSearcher = nodes[myNodeID].acquire();\n        prevSearchState = null;\n      }\n\n      final IndexReader[] subs = new IndexReader[numNodes];\n\n      PreviousSearchState searchState = null;\n\n      try {\n\n        // Mock: now make a single reader (MultiReader) from all node\n        // searchers.  In a real shard env you can't do this... we\n        // do it to confirm results from the shard searcher\n        // are correct:\n        int docCount = 0;\n        try {\n          for(int nodeID=0;nodeID<numNodes;nodeID++) {\n            final long subVersion = localShardSearcher.nodeVersions[nodeID];\n            final IndexSearcher sub = nodes[nodeID].searchers.acquire(subVersion);\n            if (sub == null) {\n              nodeID--;\n              while(nodeID >= 0) {\n                subs[nodeID].decRef();\n                subs[nodeID] = null;\n                nodeID--;\n              }\n              throw new SearcherExpiredException(\"nodeID=\" + nodeID + \" version=\" + subVersion);\n            }\n            subs[nodeID] = sub.getIndexReader();\n            docCount += subs[nodeID].maxDoc();\n          }\n        } catch (SearcherExpiredException see) {\n          // Expected\n          if (VERBOSE) {\n            System.out.println(\"  searcher expired during mock reader init: \" + see);\n          }\n          continue;\n        }\n\n        final IndexReader mockReader = new MultiReader(subs);\n        final IndexSearcher mockSearcher = new IndexSearcher(mockReader);\n\n        Query query;\n        Sort sort;\n\n        if (prevSearchState != null) {\n          query = prevSearchState.query;\n          sort = prevSearchState.sort;\n        } else {\n          if (terms == null && docCount > minDocsToMakeTerms) {\n            // TODO: try to \"focus\" on high freq terms sometimes too\n            // TODO: maybe also periodically reset the terms...?\n            final TermsEnum termsEnum = MultiFields.getTerms(mockReader, \"body\").iterator(null);\n            terms = new ArrayList<BytesRef>();\n            while(termsEnum.next() != null) {\n              terms.add(BytesRef.deepCopyOf(termsEnum.term()));\n            }\n            if (VERBOSE) {\n              System.out.println(\"TEST: init terms: \" + terms.size() + \" terms\");\n            }\n            if (terms.size() == 0) {\n              terms = null;\n            }\n          }\n\n          if (VERBOSE) {\n            System.out.println(\"  maxDoc=\" + mockReader.maxDoc());\n          }\n\n          if (terms != null) {\n            if (random().nextBoolean()) {\n              query = new TermQuery(new Term(\"body\", terms.get(random().nextInt(terms.size()))));\n            } else {\n              final String t = terms.get(random().nextInt(terms.size())).utf8ToString();\n              final String prefix;\n              if (t.length() <= 1) {\n                prefix = t;\n              } else {\n                prefix = t.substring(0, TestUtil.nextInt(random(), 1, 2));\n              }\n              query = new PrefixQuery(new Term(\"body\", prefix));\n            }\n            \n            if (random().nextBoolean()) {\n              sort = null;\n            } else {\n              // TODO: sort by more than 1 field\n              final int what = random().nextInt(3);\n              if (what == 0) {\n                sort = new Sort(SortField.FIELD_SCORE);\n              } else if (what == 1) {\n                // TODO: this sort doesn't merge\n                // correctly... it's tricky because you\n                // could have > 2.1B docs across all shards: \n                //sort = new Sort(SortField.FIELD_DOC);\n                sort = null;\n              } else if (what == 2) {\n                sort = new Sort(new SortField[] {new SortField(\"docid_int\", SortField.Type.INT, random().nextBoolean())});\n              } else {\n                sort = new Sort(new SortField[] {new SortField(\"title\", SortField.Type.STRING, random().nextBoolean())});\n              }\n            }\n          } else {\n            query = null;\n            sort = null;\n          }\n        }\n\n        if (query != null) {\n\n          try {\n            searchState = assertSame(mockSearcher, localShardSearcher, query, sort, prevSearchState);\n          } catch (SearcherExpiredException see) {\n            // Expected; in a \"real\" app we would\n            // either forward this error to the user (\"too\n            // much time has passed; please re-run your\n            // search\") or sneakily just switch to newest\n            // searcher w/o telling them...\n            if (VERBOSE) {\n              System.out.println(\"  searcher expired during search: \" + see);\n              see.printStackTrace(System.out);\n            }\n            // We can't do this in general: on a very slow\n            // computer it's possible the local searcher\n            // expires before we can finish our search:\n            // assert prevSearchState != null;\n            if (prevSearchState != null) {\n              priorSearches.remove(prevSearchState);\n            }\n          }\n        }\n      } finally {\n        nodes[myNodeID].release(localShardSearcher);\n        for(IndexReader sub : subs) {\n          if (sub != null) {\n            sub.decRef();\n          }\n        }\n      }\n\n      if (searchState != null && searchState.searchAfterLocal != null && random().nextInt(5) == 3) {\n        priorSearches.add(searchState);\n        if (priorSearches.size() > 200) {\n          Collections.shuffle(priorSearches, random());\n          priorSearches.subList(100, priorSearches.size()).clear();\n        }\n      }\n    }\n\n    finish();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"0ed6b1234af94a2693d3e6550e7b3ee41fd3f51c","date":1416362965,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestShardSearching#testSimple().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestShardSearching#testSimple().mjava","sourceNew":"  public void testSimple() throws Exception {\n    final int numNodes = TestUtil.nextInt(random(), 1, 10);\n\n    final double runTimeSec = atLeast(3);\n\n    final int minDocsToMakeTerms = TestUtil.nextInt(random(), 5, 20);\n\n    final int maxSearcherAgeSeconds = TestUtil.nextInt(random(), 1, 3);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: numNodes=\" + numNodes + \" runTimeSec=\" + runTimeSec + \" maxSearcherAgeSeconds=\" + maxSearcherAgeSeconds);\n    }\n\n    start(numNodes,\n          runTimeSec,\n          maxSearcherAgeSeconds\n          );\n\n    final List<PreviousSearchState> priorSearches = new ArrayList<>();\n    List<BytesRef> terms = null;\n    while (System.nanoTime() < endTimeNanos) {\n\n      final boolean doFollowon = priorSearches.size() > 0 && random().nextInt(7) == 1;\n\n      // Pick a random node; we will run the query on this node:\n      final int myNodeID = random().nextInt(numNodes);\n\n      final NodeState.ShardIndexSearcher localShardSearcher;\n\n      final PreviousSearchState prevSearchState;\n\n      if (doFollowon) {\n        // Pretend user issued a followon query:\n        prevSearchState = priorSearches.get(random().nextInt(priorSearches.size()));\n\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: follow-on query age=\" + ((System.nanoTime() - prevSearchState.searchTimeNanos)/1000000000.0));\n        }\n\n        try {\n          localShardSearcher = nodes[myNodeID].acquire(prevSearchState.versions);\n        } catch (SearcherExpiredException see) {\n          // Expected, sometimes; in a \"real\" app we would\n          // either forward this error to the user (\"too\n          // much time has passed; please re-run your\n          // search\") or sneakily just switch to newest\n          // searcher w/o telling them...\n          if (VERBOSE) {\n            System.out.println(\"  searcher expired during local shard searcher init: \" + see);\n          }\n          priorSearches.remove(prevSearchState);\n          continue;\n        }\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: fresh query\");\n        }\n        // Do fresh query:\n        localShardSearcher = nodes[myNodeID].acquire();\n        prevSearchState = null;\n      }\n\n      final IndexReader[] subs = new IndexReader[numNodes];\n\n      PreviousSearchState searchState = null;\n\n      try {\n\n        // Mock: now make a single reader (MultiReader) from all node\n        // searchers.  In a real shard env you can't do this... we\n        // do it to confirm results from the shard searcher\n        // are correct:\n        int docCount = 0;\n        try {\n          for(int nodeID=0;nodeID<numNodes;nodeID++) {\n            final long subVersion = localShardSearcher.nodeVersions[nodeID];\n            final IndexSearcher sub = nodes[nodeID].searchers.acquire(subVersion);\n            if (sub == null) {\n              nodeID--;\n              while(nodeID >= 0) {\n                subs[nodeID].decRef();\n                subs[nodeID] = null;\n                nodeID--;\n              }\n              throw new SearcherExpiredException(\"nodeID=\" + nodeID + \" version=\" + subVersion);\n            }\n            subs[nodeID] = sub.getIndexReader();\n            docCount += subs[nodeID].maxDoc();\n          }\n        } catch (SearcherExpiredException see) {\n          // Expected\n          if (VERBOSE) {\n            System.out.println(\"  searcher expired during mock reader init: \" + see);\n          }\n          continue;\n        }\n\n        final IndexReader mockReader = new MultiReader(subs);\n        final IndexSearcher mockSearcher = new IndexSearcher(mockReader);\n\n        Query query;\n        Sort sort;\n\n        if (prevSearchState != null) {\n          query = prevSearchState.query;\n          sort = prevSearchState.sort;\n        } else {\n          if (terms == null && docCount > minDocsToMakeTerms) {\n            // TODO: try to \"focus\" on high freq terms sometimes too\n            // TODO: maybe also periodically reset the terms...?\n            final TermsEnum termsEnum = MultiFields.getTerms(mockReader, \"body\").iterator(null);\n            terms = new ArrayList<>();\n            while(termsEnum.next() != null) {\n              terms.add(BytesRef.deepCopyOf(termsEnum.term()));\n            }\n            if (VERBOSE) {\n              System.out.println(\"TEST: init terms: \" + terms.size() + \" terms\");\n            }\n            if (terms.size() == 0) {\n              terms = null;\n            }\n          }\n\n          if (VERBOSE) {\n            System.out.println(\"  maxDoc=\" + mockReader.maxDoc());\n          }\n\n          if (terms != null) {\n            if (random().nextBoolean()) {\n              query = new TermQuery(new Term(\"body\", terms.get(random().nextInt(terms.size()))));\n            } else {\n              final String t = terms.get(random().nextInt(terms.size())).utf8ToString();\n              final String prefix;\n              if (t.length() <= 1) {\n                prefix = t;\n              } else {\n                prefix = t.substring(0, TestUtil.nextInt(random(), 1, 2));\n              }\n              query = new PrefixQuery(new Term(\"body\", prefix));\n            }\n            \n            if (random().nextBoolean()) {\n              sort = null;\n            } else {\n              // TODO: sort by more than 1 field\n              final int what = random().nextInt(3);\n              if (what == 0) {\n                sort = new Sort(SortField.FIELD_SCORE);\n              } else if (what == 1) {\n                // TODO: this sort doesn't merge\n                // correctly... it's tricky because you\n                // could have > 2.1B docs across all shards: \n                //sort = new Sort(SortField.FIELD_DOC);\n                sort = null;\n              } else if (what == 2) {\n                sort = new Sort(new SortField[] {new SortField(\"docid_intDV\", SortField.Type.INT, random().nextBoolean())});\n              } else {\n                sort = new Sort(new SortField[] {new SortField(\"titleDV\", SortField.Type.STRING, random().nextBoolean())});\n              }\n            }\n          } else {\n            query = null;\n            sort = null;\n          }\n        }\n\n        if (query != null) {\n\n          try {\n            searchState = assertSame(mockSearcher, localShardSearcher, query, sort, prevSearchState);\n          } catch (SearcherExpiredException see) {\n            // Expected; in a \"real\" app we would\n            // either forward this error to the user (\"too\n            // much time has passed; please re-run your\n            // search\") or sneakily just switch to newest\n            // searcher w/o telling them...\n            if (VERBOSE) {\n              System.out.println(\"  searcher expired during search: \" + see);\n              see.printStackTrace(System.out);\n            }\n            // We can't do this in general: on a very slow\n            // computer it's possible the local searcher\n            // expires before we can finish our search:\n            // assert prevSearchState != null;\n            if (prevSearchState != null) {\n              priorSearches.remove(prevSearchState);\n            }\n          }\n        }\n      } finally {\n        nodes[myNodeID].release(localShardSearcher);\n        for(IndexReader sub : subs) {\n          if (sub != null) {\n            sub.decRef();\n          }\n        }\n      }\n\n      if (searchState != null && searchState.searchAfterLocal != null && random().nextInt(5) == 3) {\n        priorSearches.add(searchState);\n        if (priorSearches.size() > 200) {\n          Collections.shuffle(priorSearches, random());\n          priorSearches.subList(100, priorSearches.size()).clear();\n        }\n      }\n    }\n\n    finish();\n  }\n\n","sourceOld":"  public void testSimple() throws Exception {\n    final int numNodes = TestUtil.nextInt(random(), 1, 10);\n\n    final double runTimeSec = atLeast(3);\n\n    final int minDocsToMakeTerms = TestUtil.nextInt(random(), 5, 20);\n\n    final int maxSearcherAgeSeconds = TestUtil.nextInt(random(), 1, 3);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: numNodes=\" + numNodes + \" runTimeSec=\" + runTimeSec + \" maxSearcherAgeSeconds=\" + maxSearcherAgeSeconds);\n    }\n\n    start(numNodes,\n          runTimeSec,\n          maxSearcherAgeSeconds\n          );\n\n    final List<PreviousSearchState> priorSearches = new ArrayList<>();\n    List<BytesRef> terms = null;\n    while (System.nanoTime() < endTimeNanos) {\n\n      final boolean doFollowon = priorSearches.size() > 0 && random().nextInt(7) == 1;\n\n      // Pick a random node; we will run the query on this node:\n      final int myNodeID = random().nextInt(numNodes);\n\n      final NodeState.ShardIndexSearcher localShardSearcher;\n\n      final PreviousSearchState prevSearchState;\n\n      if (doFollowon) {\n        // Pretend user issued a followon query:\n        prevSearchState = priorSearches.get(random().nextInt(priorSearches.size()));\n\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: follow-on query age=\" + ((System.nanoTime() - prevSearchState.searchTimeNanos)/1000000000.0));\n        }\n\n        try {\n          localShardSearcher = nodes[myNodeID].acquire(prevSearchState.versions);\n        } catch (SearcherExpiredException see) {\n          // Expected, sometimes; in a \"real\" app we would\n          // either forward this error to the user (\"too\n          // much time has passed; please re-run your\n          // search\") or sneakily just switch to newest\n          // searcher w/o telling them...\n          if (VERBOSE) {\n            System.out.println(\"  searcher expired during local shard searcher init: \" + see);\n          }\n          priorSearches.remove(prevSearchState);\n          continue;\n        }\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: fresh query\");\n        }\n        // Do fresh query:\n        localShardSearcher = nodes[myNodeID].acquire();\n        prevSearchState = null;\n      }\n\n      final IndexReader[] subs = new IndexReader[numNodes];\n\n      PreviousSearchState searchState = null;\n\n      try {\n\n        // Mock: now make a single reader (MultiReader) from all node\n        // searchers.  In a real shard env you can't do this... we\n        // do it to confirm results from the shard searcher\n        // are correct:\n        int docCount = 0;\n        try {\n          for(int nodeID=0;nodeID<numNodes;nodeID++) {\n            final long subVersion = localShardSearcher.nodeVersions[nodeID];\n            final IndexSearcher sub = nodes[nodeID].searchers.acquire(subVersion);\n            if (sub == null) {\n              nodeID--;\n              while(nodeID >= 0) {\n                subs[nodeID].decRef();\n                subs[nodeID] = null;\n                nodeID--;\n              }\n              throw new SearcherExpiredException(\"nodeID=\" + nodeID + \" version=\" + subVersion);\n            }\n            subs[nodeID] = sub.getIndexReader();\n            docCount += subs[nodeID].maxDoc();\n          }\n        } catch (SearcherExpiredException see) {\n          // Expected\n          if (VERBOSE) {\n            System.out.println(\"  searcher expired during mock reader init: \" + see);\n          }\n          continue;\n        }\n\n        final IndexReader mockReader = new MultiReader(subs);\n        final IndexSearcher mockSearcher = new IndexSearcher(mockReader);\n\n        Query query;\n        Sort sort;\n\n        if (prevSearchState != null) {\n          query = prevSearchState.query;\n          sort = prevSearchState.sort;\n        } else {\n          if (terms == null && docCount > minDocsToMakeTerms) {\n            // TODO: try to \"focus\" on high freq terms sometimes too\n            // TODO: maybe also periodically reset the terms...?\n            final TermsEnum termsEnum = MultiFields.getTerms(mockReader, \"body\").iterator(null);\n            terms = new ArrayList<>();\n            while(termsEnum.next() != null) {\n              terms.add(BytesRef.deepCopyOf(termsEnum.term()));\n            }\n            if (VERBOSE) {\n              System.out.println(\"TEST: init terms: \" + terms.size() + \" terms\");\n            }\n            if (terms.size() == 0) {\n              terms = null;\n            }\n          }\n\n          if (VERBOSE) {\n            System.out.println(\"  maxDoc=\" + mockReader.maxDoc());\n          }\n\n          if (terms != null) {\n            if (random().nextBoolean()) {\n              query = new TermQuery(new Term(\"body\", terms.get(random().nextInt(terms.size()))));\n            } else {\n              final String t = terms.get(random().nextInt(terms.size())).utf8ToString();\n              final String prefix;\n              if (t.length() <= 1) {\n                prefix = t;\n              } else {\n                prefix = t.substring(0, TestUtil.nextInt(random(), 1, 2));\n              }\n              query = new PrefixQuery(new Term(\"body\", prefix));\n            }\n            \n            if (random().nextBoolean()) {\n              sort = null;\n            } else {\n              // TODO: sort by more than 1 field\n              final int what = random().nextInt(3);\n              if (what == 0) {\n                sort = new Sort(SortField.FIELD_SCORE);\n              } else if (what == 1) {\n                // TODO: this sort doesn't merge\n                // correctly... it's tricky because you\n                // could have > 2.1B docs across all shards: \n                //sort = new Sort(SortField.FIELD_DOC);\n                sort = null;\n              } else if (what == 2) {\n                sort = new Sort(new SortField[] {new SortField(\"docid_int\", SortField.Type.INT, random().nextBoolean())});\n              } else {\n                sort = new Sort(new SortField[] {new SortField(\"title\", SortField.Type.STRING, random().nextBoolean())});\n              }\n            }\n          } else {\n            query = null;\n            sort = null;\n          }\n        }\n\n        if (query != null) {\n\n          try {\n            searchState = assertSame(mockSearcher, localShardSearcher, query, sort, prevSearchState);\n          } catch (SearcherExpiredException see) {\n            // Expected; in a \"real\" app we would\n            // either forward this error to the user (\"too\n            // much time has passed; please re-run your\n            // search\") or sneakily just switch to newest\n            // searcher w/o telling them...\n            if (VERBOSE) {\n              System.out.println(\"  searcher expired during search: \" + see);\n              see.printStackTrace(System.out);\n            }\n            // We can't do this in general: on a very slow\n            // computer it's possible the local searcher\n            // expires before we can finish our search:\n            // assert prevSearchState != null;\n            if (prevSearchState != null) {\n              priorSearches.remove(prevSearchState);\n            }\n          }\n        }\n      } finally {\n        nodes[myNodeID].release(localShardSearcher);\n        for(IndexReader sub : subs) {\n          if (sub != null) {\n            sub.decRef();\n          }\n        }\n      }\n\n      if (searchState != null && searchState.searchAfterLocal != null && random().nextInt(5) == 3) {\n        priorSearches.add(searchState);\n        if (priorSearches.size() > 200) {\n          Collections.shuffle(priorSearches, random());\n          priorSearches.subList(100, priorSearches.size()).clear();\n        }\n      }\n    }\n\n    finish();\n  }\n\n","bugFix":["59a0020b413d44dd79d85d7a66ed5004265fb453","629c38c4ae4e303d0617e05fbfe508140b32f0a3"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0a773283ef5eab2e9c7136eeb66574a4b7a2dc82","date":1428522487,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestShardSearching#testSimple().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestShardSearching#testSimple().mjava","sourceNew":"  public void testSimple() throws Exception {\n    final int numNodes = TestUtil.nextInt(random(), 1, 10);\n\n    final double runTimeSec = atLeast(3);\n\n    final int minDocsToMakeTerms = TestUtil.nextInt(random(), 5, 20);\n\n    final int maxSearcherAgeSeconds = TestUtil.nextInt(random(), 1, 3);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: numNodes=\" + numNodes + \" runTimeSec=\" + runTimeSec + \" maxSearcherAgeSeconds=\" + maxSearcherAgeSeconds);\n    }\n\n    start(numNodes,\n          runTimeSec,\n          maxSearcherAgeSeconds\n          );\n\n    final List<PreviousSearchState> priorSearches = new ArrayList<>();\n    List<BytesRef> terms = null;\n    while (System.nanoTime() < endTimeNanos) {\n\n      final boolean doFollowon = priorSearches.size() > 0 && random().nextInt(7) == 1;\n\n      // Pick a random node; we will run the query on this node:\n      final int myNodeID = random().nextInt(numNodes);\n\n      final NodeState.ShardIndexSearcher localShardSearcher;\n\n      final PreviousSearchState prevSearchState;\n\n      if (doFollowon) {\n        // Pretend user issued a followon query:\n        prevSearchState = priorSearches.get(random().nextInt(priorSearches.size()));\n\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: follow-on query age=\" + ((System.nanoTime() - prevSearchState.searchTimeNanos)/1000000000.0));\n        }\n\n        try {\n          localShardSearcher = nodes[myNodeID].acquire(prevSearchState.versions);\n        } catch (SearcherExpiredException see) {\n          // Expected, sometimes; in a \"real\" app we would\n          // either forward this error to the user (\"too\n          // much time has passed; please re-run your\n          // search\") or sneakily just switch to newest\n          // searcher w/o telling them...\n          if (VERBOSE) {\n            System.out.println(\"  searcher expired during local shard searcher init: \" + see);\n          }\n          priorSearches.remove(prevSearchState);\n          continue;\n        }\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: fresh query\");\n        }\n        // Do fresh query:\n        localShardSearcher = nodes[myNodeID].acquire();\n        prevSearchState = null;\n      }\n\n      final IndexReader[] subs = new IndexReader[numNodes];\n\n      PreviousSearchState searchState = null;\n\n      try {\n\n        // Mock: now make a single reader (MultiReader) from all node\n        // searchers.  In a real shard env you can't do this... we\n        // do it to confirm results from the shard searcher\n        // are correct:\n        int docCount = 0;\n        try {\n          for(int nodeID=0;nodeID<numNodes;nodeID++) {\n            final long subVersion = localShardSearcher.nodeVersions[nodeID];\n            final IndexSearcher sub = nodes[nodeID].searchers.acquire(subVersion);\n            if (sub == null) {\n              nodeID--;\n              while(nodeID >= 0) {\n                subs[nodeID].decRef();\n                subs[nodeID] = null;\n                nodeID--;\n              }\n              throw new SearcherExpiredException(\"nodeID=\" + nodeID + \" version=\" + subVersion);\n            }\n            subs[nodeID] = sub.getIndexReader();\n            docCount += subs[nodeID].maxDoc();\n          }\n        } catch (SearcherExpiredException see) {\n          // Expected\n          if (VERBOSE) {\n            System.out.println(\"  searcher expired during mock reader init: \" + see);\n          }\n          continue;\n        }\n\n        final IndexReader mockReader = new MultiReader(subs);\n        final IndexSearcher mockSearcher = new IndexSearcher(mockReader);\n\n        Query query;\n        Sort sort;\n\n        if (prevSearchState != null) {\n          query = prevSearchState.query;\n          sort = prevSearchState.sort;\n        } else {\n          if (terms == null && docCount > minDocsToMakeTerms) {\n            // TODO: try to \"focus\" on high freq terms sometimes too\n            // TODO: maybe also periodically reset the terms...?\n            final TermsEnum termsEnum = MultiFields.getTerms(mockReader, \"body\").iterator();\n            terms = new ArrayList<>();\n            while(termsEnum.next() != null) {\n              terms.add(BytesRef.deepCopyOf(termsEnum.term()));\n            }\n            if (VERBOSE) {\n              System.out.println(\"TEST: init terms: \" + terms.size() + \" terms\");\n            }\n            if (terms.size() == 0) {\n              terms = null;\n            }\n          }\n\n          if (VERBOSE) {\n            System.out.println(\"  maxDoc=\" + mockReader.maxDoc());\n          }\n\n          if (terms != null) {\n            if (random().nextBoolean()) {\n              query = new TermQuery(new Term(\"body\", terms.get(random().nextInt(terms.size()))));\n            } else {\n              final String t = terms.get(random().nextInt(terms.size())).utf8ToString();\n              final String prefix;\n              if (t.length() <= 1) {\n                prefix = t;\n              } else {\n                prefix = t.substring(0, TestUtil.nextInt(random(), 1, 2));\n              }\n              query = new PrefixQuery(new Term(\"body\", prefix));\n            }\n            \n            if (random().nextBoolean()) {\n              sort = null;\n            } else {\n              // TODO: sort by more than 1 field\n              final int what = random().nextInt(3);\n              if (what == 0) {\n                sort = new Sort(SortField.FIELD_SCORE);\n              } else if (what == 1) {\n                // TODO: this sort doesn't merge\n                // correctly... it's tricky because you\n                // could have > 2.1B docs across all shards: \n                //sort = new Sort(SortField.FIELD_DOC);\n                sort = null;\n              } else if (what == 2) {\n                sort = new Sort(new SortField[] {new SortField(\"docid_intDV\", SortField.Type.INT, random().nextBoolean())});\n              } else {\n                sort = new Sort(new SortField[] {new SortField(\"titleDV\", SortField.Type.STRING, random().nextBoolean())});\n              }\n            }\n          } else {\n            query = null;\n            sort = null;\n          }\n        }\n\n        if (query != null) {\n\n          try {\n            searchState = assertSame(mockSearcher, localShardSearcher, query, sort, prevSearchState);\n          } catch (SearcherExpiredException see) {\n            // Expected; in a \"real\" app we would\n            // either forward this error to the user (\"too\n            // much time has passed; please re-run your\n            // search\") or sneakily just switch to newest\n            // searcher w/o telling them...\n            if (VERBOSE) {\n              System.out.println(\"  searcher expired during search: \" + see);\n              see.printStackTrace(System.out);\n            }\n            // We can't do this in general: on a very slow\n            // computer it's possible the local searcher\n            // expires before we can finish our search:\n            // assert prevSearchState != null;\n            if (prevSearchState != null) {\n              priorSearches.remove(prevSearchState);\n            }\n          }\n        }\n      } finally {\n        nodes[myNodeID].release(localShardSearcher);\n        for(IndexReader sub : subs) {\n          if (sub != null) {\n            sub.decRef();\n          }\n        }\n      }\n\n      if (searchState != null && searchState.searchAfterLocal != null && random().nextInt(5) == 3) {\n        priorSearches.add(searchState);\n        if (priorSearches.size() > 200) {\n          Collections.shuffle(priorSearches, random());\n          priorSearches.subList(100, priorSearches.size()).clear();\n        }\n      }\n    }\n\n    finish();\n  }\n\n","sourceOld":"  public void testSimple() throws Exception {\n    final int numNodes = TestUtil.nextInt(random(), 1, 10);\n\n    final double runTimeSec = atLeast(3);\n\n    final int minDocsToMakeTerms = TestUtil.nextInt(random(), 5, 20);\n\n    final int maxSearcherAgeSeconds = TestUtil.nextInt(random(), 1, 3);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: numNodes=\" + numNodes + \" runTimeSec=\" + runTimeSec + \" maxSearcherAgeSeconds=\" + maxSearcherAgeSeconds);\n    }\n\n    start(numNodes,\n          runTimeSec,\n          maxSearcherAgeSeconds\n          );\n\n    final List<PreviousSearchState> priorSearches = new ArrayList<>();\n    List<BytesRef> terms = null;\n    while (System.nanoTime() < endTimeNanos) {\n\n      final boolean doFollowon = priorSearches.size() > 0 && random().nextInt(7) == 1;\n\n      // Pick a random node; we will run the query on this node:\n      final int myNodeID = random().nextInt(numNodes);\n\n      final NodeState.ShardIndexSearcher localShardSearcher;\n\n      final PreviousSearchState prevSearchState;\n\n      if (doFollowon) {\n        // Pretend user issued a followon query:\n        prevSearchState = priorSearches.get(random().nextInt(priorSearches.size()));\n\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: follow-on query age=\" + ((System.nanoTime() - prevSearchState.searchTimeNanos)/1000000000.0));\n        }\n\n        try {\n          localShardSearcher = nodes[myNodeID].acquire(prevSearchState.versions);\n        } catch (SearcherExpiredException see) {\n          // Expected, sometimes; in a \"real\" app we would\n          // either forward this error to the user (\"too\n          // much time has passed; please re-run your\n          // search\") or sneakily just switch to newest\n          // searcher w/o telling them...\n          if (VERBOSE) {\n            System.out.println(\"  searcher expired during local shard searcher init: \" + see);\n          }\n          priorSearches.remove(prevSearchState);\n          continue;\n        }\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: fresh query\");\n        }\n        // Do fresh query:\n        localShardSearcher = nodes[myNodeID].acquire();\n        prevSearchState = null;\n      }\n\n      final IndexReader[] subs = new IndexReader[numNodes];\n\n      PreviousSearchState searchState = null;\n\n      try {\n\n        // Mock: now make a single reader (MultiReader) from all node\n        // searchers.  In a real shard env you can't do this... we\n        // do it to confirm results from the shard searcher\n        // are correct:\n        int docCount = 0;\n        try {\n          for(int nodeID=0;nodeID<numNodes;nodeID++) {\n            final long subVersion = localShardSearcher.nodeVersions[nodeID];\n            final IndexSearcher sub = nodes[nodeID].searchers.acquire(subVersion);\n            if (sub == null) {\n              nodeID--;\n              while(nodeID >= 0) {\n                subs[nodeID].decRef();\n                subs[nodeID] = null;\n                nodeID--;\n              }\n              throw new SearcherExpiredException(\"nodeID=\" + nodeID + \" version=\" + subVersion);\n            }\n            subs[nodeID] = sub.getIndexReader();\n            docCount += subs[nodeID].maxDoc();\n          }\n        } catch (SearcherExpiredException see) {\n          // Expected\n          if (VERBOSE) {\n            System.out.println(\"  searcher expired during mock reader init: \" + see);\n          }\n          continue;\n        }\n\n        final IndexReader mockReader = new MultiReader(subs);\n        final IndexSearcher mockSearcher = new IndexSearcher(mockReader);\n\n        Query query;\n        Sort sort;\n\n        if (prevSearchState != null) {\n          query = prevSearchState.query;\n          sort = prevSearchState.sort;\n        } else {\n          if (terms == null && docCount > minDocsToMakeTerms) {\n            // TODO: try to \"focus\" on high freq terms sometimes too\n            // TODO: maybe also periodically reset the terms...?\n            final TermsEnum termsEnum = MultiFields.getTerms(mockReader, \"body\").iterator(null);\n            terms = new ArrayList<>();\n            while(termsEnum.next() != null) {\n              terms.add(BytesRef.deepCopyOf(termsEnum.term()));\n            }\n            if (VERBOSE) {\n              System.out.println(\"TEST: init terms: \" + terms.size() + \" terms\");\n            }\n            if (terms.size() == 0) {\n              terms = null;\n            }\n          }\n\n          if (VERBOSE) {\n            System.out.println(\"  maxDoc=\" + mockReader.maxDoc());\n          }\n\n          if (terms != null) {\n            if (random().nextBoolean()) {\n              query = new TermQuery(new Term(\"body\", terms.get(random().nextInt(terms.size()))));\n            } else {\n              final String t = terms.get(random().nextInt(terms.size())).utf8ToString();\n              final String prefix;\n              if (t.length() <= 1) {\n                prefix = t;\n              } else {\n                prefix = t.substring(0, TestUtil.nextInt(random(), 1, 2));\n              }\n              query = new PrefixQuery(new Term(\"body\", prefix));\n            }\n            \n            if (random().nextBoolean()) {\n              sort = null;\n            } else {\n              // TODO: sort by more than 1 field\n              final int what = random().nextInt(3);\n              if (what == 0) {\n                sort = new Sort(SortField.FIELD_SCORE);\n              } else if (what == 1) {\n                // TODO: this sort doesn't merge\n                // correctly... it's tricky because you\n                // could have > 2.1B docs across all shards: \n                //sort = new Sort(SortField.FIELD_DOC);\n                sort = null;\n              } else if (what == 2) {\n                sort = new Sort(new SortField[] {new SortField(\"docid_intDV\", SortField.Type.INT, random().nextBoolean())});\n              } else {\n                sort = new Sort(new SortField[] {new SortField(\"titleDV\", SortField.Type.STRING, random().nextBoolean())});\n              }\n            }\n          } else {\n            query = null;\n            sort = null;\n          }\n        }\n\n        if (query != null) {\n\n          try {\n            searchState = assertSame(mockSearcher, localShardSearcher, query, sort, prevSearchState);\n          } catch (SearcherExpiredException see) {\n            // Expected; in a \"real\" app we would\n            // either forward this error to the user (\"too\n            // much time has passed; please re-run your\n            // search\") or sneakily just switch to newest\n            // searcher w/o telling them...\n            if (VERBOSE) {\n              System.out.println(\"  searcher expired during search: \" + see);\n              see.printStackTrace(System.out);\n            }\n            // We can't do this in general: on a very slow\n            // computer it's possible the local searcher\n            // expires before we can finish our search:\n            // assert prevSearchState != null;\n            if (prevSearchState != null) {\n              priorSearches.remove(prevSearchState);\n            }\n          }\n        }\n      } finally {\n        nodes[myNodeID].release(localShardSearcher);\n        for(IndexReader sub : subs) {\n          if (sub != null) {\n            sub.decRef();\n          }\n        }\n      }\n\n      if (searchState != null && searchState.searchAfterLocal != null && random().nextInt(5) == 3) {\n        priorSearches.add(searchState);\n        if (priorSearches.size() > 200) {\n          Collections.shuffle(priorSearches, random());\n          priorSearches.subList(100, priorSearches.size()).clear();\n        }\n      }\n    }\n\n    finish();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"04e775de416dd2d8067b10db1c8af975a1d5017e","date":1539906554,"type":3,"author":"David Smiley","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestShardSearching#testSimple().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestShardSearching#testSimple().mjava","sourceNew":"  public void testSimple() throws Exception {\n    final int numNodes = TestUtil.nextInt(random(), 1, 10);\n\n    final double runTimeSec = atLeast(3);\n\n    final int minDocsToMakeTerms = TestUtil.nextInt(random(), 5, 20);\n\n    final int maxSearcherAgeSeconds = TestUtil.nextInt(random(), 1, 3);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: numNodes=\" + numNodes + \" runTimeSec=\" + runTimeSec + \" maxSearcherAgeSeconds=\" + maxSearcherAgeSeconds);\n    }\n\n    start(numNodes,\n          runTimeSec,\n          maxSearcherAgeSeconds\n          );\n\n    final List<PreviousSearchState> priorSearches = new ArrayList<>();\n    List<BytesRef> terms = null;\n    while (System.nanoTime() < endTimeNanos) {\n\n      final boolean doFollowon = priorSearches.size() > 0 && random().nextInt(7) == 1;\n\n      // Pick a random node; we will run the query on this node:\n      final int myNodeID = random().nextInt(numNodes);\n\n      final NodeState.ShardIndexSearcher localShardSearcher;\n\n      final PreviousSearchState prevSearchState;\n\n      if (doFollowon) {\n        // Pretend user issued a followon query:\n        prevSearchState = priorSearches.get(random().nextInt(priorSearches.size()));\n\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: follow-on query age=\" + ((System.nanoTime() - prevSearchState.searchTimeNanos)/1000000000.0));\n        }\n\n        try {\n          localShardSearcher = nodes[myNodeID].acquire(prevSearchState.versions);\n        } catch (SearcherExpiredException see) {\n          // Expected, sometimes; in a \"real\" app we would\n          // either forward this error to the user (\"too\n          // much time has passed; please re-run your\n          // search\") or sneakily just switch to newest\n          // searcher w/o telling them...\n          if (VERBOSE) {\n            System.out.println(\"  searcher expired during local shard searcher init: \" + see);\n          }\n          priorSearches.remove(prevSearchState);\n          continue;\n        }\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: fresh query\");\n        }\n        // Do fresh query:\n        localShardSearcher = nodes[myNodeID].acquire();\n        prevSearchState = null;\n      }\n\n      final IndexReader[] subs = new IndexReader[numNodes];\n\n      PreviousSearchState searchState = null;\n\n      try {\n\n        // Mock: now make a single reader (MultiReader) from all node\n        // searchers.  In a real shard env you can't do this... we\n        // do it to confirm results from the shard searcher\n        // are correct:\n        int docCount = 0;\n        try {\n          for(int nodeID=0;nodeID<numNodes;nodeID++) {\n            final long subVersion = localShardSearcher.nodeVersions[nodeID];\n            final IndexSearcher sub = nodes[nodeID].searchers.acquire(subVersion);\n            if (sub == null) {\n              nodeID--;\n              while(nodeID >= 0) {\n                subs[nodeID].decRef();\n                subs[nodeID] = null;\n                nodeID--;\n              }\n              throw new SearcherExpiredException(\"nodeID=\" + nodeID + \" version=\" + subVersion);\n            }\n            subs[nodeID] = sub.getIndexReader();\n            docCount += subs[nodeID].maxDoc();\n          }\n        } catch (SearcherExpiredException see) {\n          // Expected\n          if (VERBOSE) {\n            System.out.println(\"  searcher expired during mock reader init: \" + see);\n          }\n          continue;\n        }\n\n        final IndexReader mockReader = new MultiReader(subs);\n        final IndexSearcher mockSearcher = new IndexSearcher(mockReader);\n\n        Query query;\n        Sort sort;\n\n        if (prevSearchState != null) {\n          query = prevSearchState.query;\n          sort = prevSearchState.sort;\n        } else {\n          if (terms == null && docCount > minDocsToMakeTerms) {\n            // TODO: try to \"focus\" on high freq terms sometimes too\n            // TODO: maybe also periodically reset the terms...?\n            final TermsEnum termsEnum = MultiTerms.getTerms(mockReader, \"body\").iterator();\n            terms = new ArrayList<>();\n            while(termsEnum.next() != null) {\n              terms.add(BytesRef.deepCopyOf(termsEnum.term()));\n            }\n            if (VERBOSE) {\n              System.out.println(\"TEST: init terms: \" + terms.size() + \" terms\");\n            }\n            if (terms.size() == 0) {\n              terms = null;\n            }\n          }\n\n          if (VERBOSE) {\n            System.out.println(\"  maxDoc=\" + mockReader.maxDoc());\n          }\n\n          if (terms != null) {\n            if (random().nextBoolean()) {\n              query = new TermQuery(new Term(\"body\", terms.get(random().nextInt(terms.size()))));\n            } else {\n              final String t = terms.get(random().nextInt(terms.size())).utf8ToString();\n              final String prefix;\n              if (t.length() <= 1) {\n                prefix = t;\n              } else {\n                prefix = t.substring(0, TestUtil.nextInt(random(), 1, 2));\n              }\n              query = new PrefixQuery(new Term(\"body\", prefix));\n            }\n            \n            if (random().nextBoolean()) {\n              sort = null;\n            } else {\n              // TODO: sort by more than 1 field\n              final int what = random().nextInt(3);\n              if (what == 0) {\n                sort = new Sort(SortField.FIELD_SCORE);\n              } else if (what == 1) {\n                // TODO: this sort doesn't merge\n                // correctly... it's tricky because you\n                // could have > 2.1B docs across all shards: \n                //sort = new Sort(SortField.FIELD_DOC);\n                sort = null;\n              } else if (what == 2) {\n                sort = new Sort(new SortField[] {new SortField(\"docid_intDV\", SortField.Type.INT, random().nextBoolean())});\n              } else {\n                sort = new Sort(new SortField[] {new SortField(\"titleDV\", SortField.Type.STRING, random().nextBoolean())});\n              }\n            }\n          } else {\n            query = null;\n            sort = null;\n          }\n        }\n\n        if (query != null) {\n\n          try {\n            searchState = assertSame(mockSearcher, localShardSearcher, query, sort, prevSearchState);\n          } catch (SearcherExpiredException see) {\n            // Expected; in a \"real\" app we would\n            // either forward this error to the user (\"too\n            // much time has passed; please re-run your\n            // search\") or sneakily just switch to newest\n            // searcher w/o telling them...\n            if (VERBOSE) {\n              System.out.println(\"  searcher expired during search: \" + see);\n              see.printStackTrace(System.out);\n            }\n            // We can't do this in general: on a very slow\n            // computer it's possible the local searcher\n            // expires before we can finish our search:\n            // assert prevSearchState != null;\n            if (prevSearchState != null) {\n              priorSearches.remove(prevSearchState);\n            }\n          }\n        }\n      } finally {\n        nodes[myNodeID].release(localShardSearcher);\n        for(IndexReader sub : subs) {\n          if (sub != null) {\n            sub.decRef();\n          }\n        }\n      }\n\n      if (searchState != null && searchState.searchAfterLocal != null && random().nextInt(5) == 3) {\n        priorSearches.add(searchState);\n        if (priorSearches.size() > 200) {\n          Collections.shuffle(priorSearches, random());\n          priorSearches.subList(100, priorSearches.size()).clear();\n        }\n      }\n    }\n\n    finish();\n  }\n\n","sourceOld":"  public void testSimple() throws Exception {\n    final int numNodes = TestUtil.nextInt(random(), 1, 10);\n\n    final double runTimeSec = atLeast(3);\n\n    final int minDocsToMakeTerms = TestUtil.nextInt(random(), 5, 20);\n\n    final int maxSearcherAgeSeconds = TestUtil.nextInt(random(), 1, 3);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: numNodes=\" + numNodes + \" runTimeSec=\" + runTimeSec + \" maxSearcherAgeSeconds=\" + maxSearcherAgeSeconds);\n    }\n\n    start(numNodes,\n          runTimeSec,\n          maxSearcherAgeSeconds\n          );\n\n    final List<PreviousSearchState> priorSearches = new ArrayList<>();\n    List<BytesRef> terms = null;\n    while (System.nanoTime() < endTimeNanos) {\n\n      final boolean doFollowon = priorSearches.size() > 0 && random().nextInt(7) == 1;\n\n      // Pick a random node; we will run the query on this node:\n      final int myNodeID = random().nextInt(numNodes);\n\n      final NodeState.ShardIndexSearcher localShardSearcher;\n\n      final PreviousSearchState prevSearchState;\n\n      if (doFollowon) {\n        // Pretend user issued a followon query:\n        prevSearchState = priorSearches.get(random().nextInt(priorSearches.size()));\n\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: follow-on query age=\" + ((System.nanoTime() - prevSearchState.searchTimeNanos)/1000000000.0));\n        }\n\n        try {\n          localShardSearcher = nodes[myNodeID].acquire(prevSearchState.versions);\n        } catch (SearcherExpiredException see) {\n          // Expected, sometimes; in a \"real\" app we would\n          // either forward this error to the user (\"too\n          // much time has passed; please re-run your\n          // search\") or sneakily just switch to newest\n          // searcher w/o telling them...\n          if (VERBOSE) {\n            System.out.println(\"  searcher expired during local shard searcher init: \" + see);\n          }\n          priorSearches.remove(prevSearchState);\n          continue;\n        }\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: fresh query\");\n        }\n        // Do fresh query:\n        localShardSearcher = nodes[myNodeID].acquire();\n        prevSearchState = null;\n      }\n\n      final IndexReader[] subs = new IndexReader[numNodes];\n\n      PreviousSearchState searchState = null;\n\n      try {\n\n        // Mock: now make a single reader (MultiReader) from all node\n        // searchers.  In a real shard env you can't do this... we\n        // do it to confirm results from the shard searcher\n        // are correct:\n        int docCount = 0;\n        try {\n          for(int nodeID=0;nodeID<numNodes;nodeID++) {\n            final long subVersion = localShardSearcher.nodeVersions[nodeID];\n            final IndexSearcher sub = nodes[nodeID].searchers.acquire(subVersion);\n            if (sub == null) {\n              nodeID--;\n              while(nodeID >= 0) {\n                subs[nodeID].decRef();\n                subs[nodeID] = null;\n                nodeID--;\n              }\n              throw new SearcherExpiredException(\"nodeID=\" + nodeID + \" version=\" + subVersion);\n            }\n            subs[nodeID] = sub.getIndexReader();\n            docCount += subs[nodeID].maxDoc();\n          }\n        } catch (SearcherExpiredException see) {\n          // Expected\n          if (VERBOSE) {\n            System.out.println(\"  searcher expired during mock reader init: \" + see);\n          }\n          continue;\n        }\n\n        final IndexReader mockReader = new MultiReader(subs);\n        final IndexSearcher mockSearcher = new IndexSearcher(mockReader);\n\n        Query query;\n        Sort sort;\n\n        if (prevSearchState != null) {\n          query = prevSearchState.query;\n          sort = prevSearchState.sort;\n        } else {\n          if (terms == null && docCount > minDocsToMakeTerms) {\n            // TODO: try to \"focus\" on high freq terms sometimes too\n            // TODO: maybe also periodically reset the terms...?\n            final TermsEnum termsEnum = MultiFields.getTerms(mockReader, \"body\").iterator();\n            terms = new ArrayList<>();\n            while(termsEnum.next() != null) {\n              terms.add(BytesRef.deepCopyOf(termsEnum.term()));\n            }\n            if (VERBOSE) {\n              System.out.println(\"TEST: init terms: \" + terms.size() + \" terms\");\n            }\n            if (terms.size() == 0) {\n              terms = null;\n            }\n          }\n\n          if (VERBOSE) {\n            System.out.println(\"  maxDoc=\" + mockReader.maxDoc());\n          }\n\n          if (terms != null) {\n            if (random().nextBoolean()) {\n              query = new TermQuery(new Term(\"body\", terms.get(random().nextInt(terms.size()))));\n            } else {\n              final String t = terms.get(random().nextInt(terms.size())).utf8ToString();\n              final String prefix;\n              if (t.length() <= 1) {\n                prefix = t;\n              } else {\n                prefix = t.substring(0, TestUtil.nextInt(random(), 1, 2));\n              }\n              query = new PrefixQuery(new Term(\"body\", prefix));\n            }\n            \n            if (random().nextBoolean()) {\n              sort = null;\n            } else {\n              // TODO: sort by more than 1 field\n              final int what = random().nextInt(3);\n              if (what == 0) {\n                sort = new Sort(SortField.FIELD_SCORE);\n              } else if (what == 1) {\n                // TODO: this sort doesn't merge\n                // correctly... it's tricky because you\n                // could have > 2.1B docs across all shards: \n                //sort = new Sort(SortField.FIELD_DOC);\n                sort = null;\n              } else if (what == 2) {\n                sort = new Sort(new SortField[] {new SortField(\"docid_intDV\", SortField.Type.INT, random().nextBoolean())});\n              } else {\n                sort = new Sort(new SortField[] {new SortField(\"titleDV\", SortField.Type.STRING, random().nextBoolean())});\n              }\n            }\n          } else {\n            query = null;\n            sort = null;\n          }\n        }\n\n        if (query != null) {\n\n          try {\n            searchState = assertSame(mockSearcher, localShardSearcher, query, sort, prevSearchState);\n          } catch (SearcherExpiredException see) {\n            // Expected; in a \"real\" app we would\n            // either forward this error to the user (\"too\n            // much time has passed; please re-run your\n            // search\") or sneakily just switch to newest\n            // searcher w/o telling them...\n            if (VERBOSE) {\n              System.out.println(\"  searcher expired during search: \" + see);\n              see.printStackTrace(System.out);\n            }\n            // We can't do this in general: on a very slow\n            // computer it's possible the local searcher\n            // expires before we can finish our search:\n            // assert prevSearchState != null;\n            if (prevSearchState != null) {\n              priorSearches.remove(prevSearchState);\n            }\n          }\n        }\n      } finally {\n        nodes[myNodeID].release(localShardSearcher);\n        for(IndexReader sub : subs) {\n          if (sub != null) {\n            sub.decRef();\n          }\n        }\n      }\n\n      if (searchState != null && searchState.searchAfterLocal != null && random().nextInt(5) == 3) {\n        priorSearches.add(searchState);\n        if (priorSearches.size() > 200) {\n          Collections.shuffle(priorSearches, random());\n          priorSearches.subList(100, priorSearches.size()).clear();\n        }\n      }\n    }\n\n    finish();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"57c6c784f777a2cc8fa014507ea129526822714d","date":1579733373,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestShardSearching#testSimple().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestShardSearching#testSimple().mjava","sourceNew":"  public void testSimple() throws Exception {\n    final int numNodes = TestUtil.nextInt(random(), 1, 10);\n\n    final double runTimeSec = TEST_NIGHTLY ? atLeast(5) : atLeast(1);\n\n    final int minDocsToMakeTerms = TestUtil.nextInt(random(), 5, 20);\n\n    final int maxSearcherAgeSeconds = TestUtil.nextInt(random(), 1, 3);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: numNodes=\" + numNodes + \" runTimeSec=\" + runTimeSec + \" maxSearcherAgeSeconds=\" + maxSearcherAgeSeconds);\n    }\n\n    start(numNodes,\n          runTimeSec,\n          maxSearcherAgeSeconds\n          );\n\n    final List<PreviousSearchState> priorSearches = new ArrayList<>();\n    List<BytesRef> terms = null;\n    while (System.nanoTime() < endTimeNanos) {\n\n      final boolean doFollowon = priorSearches.size() > 0 && random().nextInt(7) == 1;\n\n      // Pick a random node; we will run the query on this node:\n      final int myNodeID = random().nextInt(numNodes);\n\n      final NodeState.ShardIndexSearcher localShardSearcher;\n\n      final PreviousSearchState prevSearchState;\n\n      if (doFollowon) {\n        // Pretend user issued a followon query:\n        prevSearchState = priorSearches.get(random().nextInt(priorSearches.size()));\n\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: follow-on query age=\" + ((System.nanoTime() - prevSearchState.searchTimeNanos)/1000000000.0));\n        }\n\n        try {\n          localShardSearcher = nodes[myNodeID].acquire(prevSearchState.versions);\n        } catch (SearcherExpiredException see) {\n          // Expected, sometimes; in a \"real\" app we would\n          // either forward this error to the user (\"too\n          // much time has passed; please re-run your\n          // search\") or sneakily just switch to newest\n          // searcher w/o telling them...\n          if (VERBOSE) {\n            System.out.println(\"  searcher expired during local shard searcher init: \" + see);\n          }\n          priorSearches.remove(prevSearchState);\n          continue;\n        }\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: fresh query\");\n        }\n        // Do fresh query:\n        localShardSearcher = nodes[myNodeID].acquire();\n        prevSearchState = null;\n      }\n\n      final IndexReader[] subs = new IndexReader[numNodes];\n\n      PreviousSearchState searchState = null;\n\n      try {\n\n        // Mock: now make a single reader (MultiReader) from all node\n        // searchers.  In a real shard env you can't do this... we\n        // do it to confirm results from the shard searcher\n        // are correct:\n        int docCount = 0;\n        try {\n          for(int nodeID=0;nodeID<numNodes;nodeID++) {\n            final long subVersion = localShardSearcher.nodeVersions[nodeID];\n            final IndexSearcher sub = nodes[nodeID].searchers.acquire(subVersion);\n            if (sub == null) {\n              nodeID--;\n              while(nodeID >= 0) {\n                subs[nodeID].decRef();\n                subs[nodeID] = null;\n                nodeID--;\n              }\n              throw new SearcherExpiredException(\"nodeID=\" + nodeID + \" version=\" + subVersion);\n            }\n            subs[nodeID] = sub.getIndexReader();\n            docCount += subs[nodeID].maxDoc();\n          }\n        } catch (SearcherExpiredException see) {\n          // Expected\n          if (VERBOSE) {\n            System.out.println(\"  searcher expired during mock reader init: \" + see);\n          }\n          continue;\n        }\n\n        final IndexReader mockReader = new MultiReader(subs);\n        final IndexSearcher mockSearcher = new IndexSearcher(mockReader);\n\n        Query query;\n        Sort sort;\n\n        if (prevSearchState != null) {\n          query = prevSearchState.query;\n          sort = prevSearchState.sort;\n        } else {\n          if (terms == null && docCount > minDocsToMakeTerms) {\n            // TODO: try to \"focus\" on high freq terms sometimes too\n            // TODO: maybe also periodically reset the terms...?\n            final TermsEnum termsEnum = MultiTerms.getTerms(mockReader, \"body\").iterator();\n            terms = new ArrayList<>();\n            while(termsEnum.next() != null) {\n              terms.add(BytesRef.deepCopyOf(termsEnum.term()));\n            }\n            if (VERBOSE) {\n              System.out.println(\"TEST: init terms: \" + terms.size() + \" terms\");\n            }\n            if (terms.size() == 0) {\n              terms = null;\n            }\n          }\n\n          if (VERBOSE) {\n            System.out.println(\"  maxDoc=\" + mockReader.maxDoc());\n          }\n\n          if (terms != null) {\n            if (random().nextBoolean()) {\n              query = new TermQuery(new Term(\"body\", terms.get(random().nextInt(terms.size()))));\n            } else {\n              final String t = terms.get(random().nextInt(terms.size())).utf8ToString();\n              final String prefix;\n              if (t.length() <= 1) {\n                prefix = t;\n              } else {\n                prefix = t.substring(0, TestUtil.nextInt(random(), 1, 2));\n              }\n              query = new PrefixQuery(new Term(\"body\", prefix));\n            }\n            \n            if (random().nextBoolean()) {\n              sort = null;\n            } else {\n              // TODO: sort by more than 1 field\n              final int what = random().nextInt(3);\n              if (what == 0) {\n                sort = new Sort(SortField.FIELD_SCORE);\n              } else if (what == 1) {\n                // TODO: this sort doesn't merge\n                // correctly... it's tricky because you\n                // could have > 2.1B docs across all shards: \n                //sort = new Sort(SortField.FIELD_DOC);\n                sort = null;\n              } else if (what == 2) {\n                sort = new Sort(new SortField[] {new SortField(\"docid_intDV\", SortField.Type.INT, random().nextBoolean())});\n              } else {\n                sort = new Sort(new SortField[] {new SortField(\"titleDV\", SortField.Type.STRING, random().nextBoolean())});\n              }\n            }\n          } else {\n            query = null;\n            sort = null;\n          }\n        }\n\n        if (query != null) {\n\n          try {\n            searchState = assertSame(mockSearcher, localShardSearcher, query, sort, prevSearchState);\n          } catch (SearcherExpiredException see) {\n            // Expected; in a \"real\" app we would\n            // either forward this error to the user (\"too\n            // much time has passed; please re-run your\n            // search\") or sneakily just switch to newest\n            // searcher w/o telling them...\n            if (VERBOSE) {\n              System.out.println(\"  searcher expired during search: \" + see);\n              see.printStackTrace(System.out);\n            }\n            // We can't do this in general: on a very slow\n            // computer it's possible the local searcher\n            // expires before we can finish our search:\n            // assert prevSearchState != null;\n            if (prevSearchState != null) {\n              priorSearches.remove(prevSearchState);\n            }\n          }\n        }\n      } finally {\n        nodes[myNodeID].release(localShardSearcher);\n        for(IndexReader sub : subs) {\n          if (sub != null) {\n            sub.decRef();\n          }\n        }\n      }\n\n      if (searchState != null && searchState.searchAfterLocal != null && random().nextInt(5) == 3) {\n        priorSearches.add(searchState);\n        if (priorSearches.size() > 200) {\n          Collections.shuffle(priorSearches, random());\n          priorSearches.subList(100, priorSearches.size()).clear();\n        }\n      }\n    }\n\n    finish();\n  }\n\n","sourceOld":"  public void testSimple() throws Exception {\n    final int numNodes = TestUtil.nextInt(random(), 1, 10);\n\n    final double runTimeSec = atLeast(3);\n\n    final int minDocsToMakeTerms = TestUtil.nextInt(random(), 5, 20);\n\n    final int maxSearcherAgeSeconds = TestUtil.nextInt(random(), 1, 3);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: numNodes=\" + numNodes + \" runTimeSec=\" + runTimeSec + \" maxSearcherAgeSeconds=\" + maxSearcherAgeSeconds);\n    }\n\n    start(numNodes,\n          runTimeSec,\n          maxSearcherAgeSeconds\n          );\n\n    final List<PreviousSearchState> priorSearches = new ArrayList<>();\n    List<BytesRef> terms = null;\n    while (System.nanoTime() < endTimeNanos) {\n\n      final boolean doFollowon = priorSearches.size() > 0 && random().nextInt(7) == 1;\n\n      // Pick a random node; we will run the query on this node:\n      final int myNodeID = random().nextInt(numNodes);\n\n      final NodeState.ShardIndexSearcher localShardSearcher;\n\n      final PreviousSearchState prevSearchState;\n\n      if (doFollowon) {\n        // Pretend user issued a followon query:\n        prevSearchState = priorSearches.get(random().nextInt(priorSearches.size()));\n\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: follow-on query age=\" + ((System.nanoTime() - prevSearchState.searchTimeNanos)/1000000000.0));\n        }\n\n        try {\n          localShardSearcher = nodes[myNodeID].acquire(prevSearchState.versions);\n        } catch (SearcherExpiredException see) {\n          // Expected, sometimes; in a \"real\" app we would\n          // either forward this error to the user (\"too\n          // much time has passed; please re-run your\n          // search\") or sneakily just switch to newest\n          // searcher w/o telling them...\n          if (VERBOSE) {\n            System.out.println(\"  searcher expired during local shard searcher init: \" + see);\n          }\n          priorSearches.remove(prevSearchState);\n          continue;\n        }\n      } else {\n        if (VERBOSE) {\n          System.out.println(\"\\nTEST: fresh query\");\n        }\n        // Do fresh query:\n        localShardSearcher = nodes[myNodeID].acquire();\n        prevSearchState = null;\n      }\n\n      final IndexReader[] subs = new IndexReader[numNodes];\n\n      PreviousSearchState searchState = null;\n\n      try {\n\n        // Mock: now make a single reader (MultiReader) from all node\n        // searchers.  In a real shard env you can't do this... we\n        // do it to confirm results from the shard searcher\n        // are correct:\n        int docCount = 0;\n        try {\n          for(int nodeID=0;nodeID<numNodes;nodeID++) {\n            final long subVersion = localShardSearcher.nodeVersions[nodeID];\n            final IndexSearcher sub = nodes[nodeID].searchers.acquire(subVersion);\n            if (sub == null) {\n              nodeID--;\n              while(nodeID >= 0) {\n                subs[nodeID].decRef();\n                subs[nodeID] = null;\n                nodeID--;\n              }\n              throw new SearcherExpiredException(\"nodeID=\" + nodeID + \" version=\" + subVersion);\n            }\n            subs[nodeID] = sub.getIndexReader();\n            docCount += subs[nodeID].maxDoc();\n          }\n        } catch (SearcherExpiredException see) {\n          // Expected\n          if (VERBOSE) {\n            System.out.println(\"  searcher expired during mock reader init: \" + see);\n          }\n          continue;\n        }\n\n        final IndexReader mockReader = new MultiReader(subs);\n        final IndexSearcher mockSearcher = new IndexSearcher(mockReader);\n\n        Query query;\n        Sort sort;\n\n        if (prevSearchState != null) {\n          query = prevSearchState.query;\n          sort = prevSearchState.sort;\n        } else {\n          if (terms == null && docCount > minDocsToMakeTerms) {\n            // TODO: try to \"focus\" on high freq terms sometimes too\n            // TODO: maybe also periodically reset the terms...?\n            final TermsEnum termsEnum = MultiTerms.getTerms(mockReader, \"body\").iterator();\n            terms = new ArrayList<>();\n            while(termsEnum.next() != null) {\n              terms.add(BytesRef.deepCopyOf(termsEnum.term()));\n            }\n            if (VERBOSE) {\n              System.out.println(\"TEST: init terms: \" + terms.size() + \" terms\");\n            }\n            if (terms.size() == 0) {\n              terms = null;\n            }\n          }\n\n          if (VERBOSE) {\n            System.out.println(\"  maxDoc=\" + mockReader.maxDoc());\n          }\n\n          if (terms != null) {\n            if (random().nextBoolean()) {\n              query = new TermQuery(new Term(\"body\", terms.get(random().nextInt(terms.size()))));\n            } else {\n              final String t = terms.get(random().nextInt(terms.size())).utf8ToString();\n              final String prefix;\n              if (t.length() <= 1) {\n                prefix = t;\n              } else {\n                prefix = t.substring(0, TestUtil.nextInt(random(), 1, 2));\n              }\n              query = new PrefixQuery(new Term(\"body\", prefix));\n            }\n            \n            if (random().nextBoolean()) {\n              sort = null;\n            } else {\n              // TODO: sort by more than 1 field\n              final int what = random().nextInt(3);\n              if (what == 0) {\n                sort = new Sort(SortField.FIELD_SCORE);\n              } else if (what == 1) {\n                // TODO: this sort doesn't merge\n                // correctly... it's tricky because you\n                // could have > 2.1B docs across all shards: \n                //sort = new Sort(SortField.FIELD_DOC);\n                sort = null;\n              } else if (what == 2) {\n                sort = new Sort(new SortField[] {new SortField(\"docid_intDV\", SortField.Type.INT, random().nextBoolean())});\n              } else {\n                sort = new Sort(new SortField[] {new SortField(\"titleDV\", SortField.Type.STRING, random().nextBoolean())});\n              }\n            }\n          } else {\n            query = null;\n            sort = null;\n          }\n        }\n\n        if (query != null) {\n\n          try {\n            searchState = assertSame(mockSearcher, localShardSearcher, query, sort, prevSearchState);\n          } catch (SearcherExpiredException see) {\n            // Expected; in a \"real\" app we would\n            // either forward this error to the user (\"too\n            // much time has passed; please re-run your\n            // search\") or sneakily just switch to newest\n            // searcher w/o telling them...\n            if (VERBOSE) {\n              System.out.println(\"  searcher expired during search: \" + see);\n              see.printStackTrace(System.out);\n            }\n            // We can't do this in general: on a very slow\n            // computer it's possible the local searcher\n            // expires before we can finish our search:\n            // assert prevSearchState != null;\n            if (prevSearchState != null) {\n              priorSearches.remove(prevSearchState);\n            }\n          }\n        }\n      } finally {\n        nodes[myNodeID].release(localShardSearcher);\n        for(IndexReader sub : subs) {\n          if (sub != null) {\n            sub.decRef();\n          }\n        }\n      }\n\n      if (searchState != null && searchState.searchAfterLocal != null && random().nextInt(5) == 3) {\n        priorSearches.add(searchState);\n        if (priorSearches.size() > 200) {\n          Collections.shuffle(priorSearches, random());\n          priorSearches.subList(100, priorSearches.size()).clear();\n        }\n      }\n    }\n\n    finish();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"0a773283ef5eab2e9c7136eeb66574a4b7a2dc82":["0ed6b1234af94a2693d3e6550e7b3ee41fd3f51c"],"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["6613659748fe4411a7dcf85266e55db1f95f7315"],"37a0f60745e53927c4c876cfe5b5a58170f0646c":["49e6a45bc6278d94e7c4aed1d36adde70842e00c","59a0020b413d44dd79d85d7a66ed5004265fb453"],"6613659748fe4411a7dcf85266e55db1f95f7315":["59a0020b413d44dd79d85d7a66ed5004265fb453"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"407687e67faf6e1f02a211ca078d8e3eed631027":["ea8db162694636ac3d19d83debf895a9e089f96a","49e6a45bc6278d94e7c4aed1d36adde70842e00c"],"8fd5be977c105554c6a7b68afcdbc511439723ab":["629c38c4ae4e303d0617e05fbfe508140b32f0a3","ea8db162694636ac3d19d83debf895a9e089f96a"],"0ed6b1234af94a2693d3e6550e7b3ee41fd3f51c":["634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"57c6c784f777a2cc8fa014507ea129526822714d":["04e775de416dd2d8067b10db1c8af975a1d5017e"],"49e6a45bc6278d94e7c4aed1d36adde70842e00c":["ea8db162694636ac3d19d83debf895a9e089f96a"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"59a0020b413d44dd79d85d7a66ed5004265fb453":["49e6a45bc6278d94e7c4aed1d36adde70842e00c"],"d6f074e73200c07d54f242d3880a8da5a35ff97b":["629c38c4ae4e303d0617e05fbfe508140b32f0a3","ea8db162694636ac3d19d83debf895a9e089f96a"],"04e775de416dd2d8067b10db1c8af975a1d5017e":["0a773283ef5eab2e9c7136eeb66574a4b7a2dc82"],"629c38c4ae4e303d0617e05fbfe508140b32f0a3":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"ea8db162694636ac3d19d83debf895a9e089f96a":["629c38c4ae4e303d0617e05fbfe508140b32f0a3"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["57c6c784f777a2cc8fa014507ea129526822714d"]},"commit2Childs":{"0a773283ef5eab2e9c7136eeb66574a4b7a2dc82":["04e775de416dd2d8067b10db1c8af975a1d5017e"],"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["0ed6b1234af94a2693d3e6550e7b3ee41fd3f51c"],"37a0f60745e53927c4c876cfe5b5a58170f0646c":[],"6613659748fe4411a7dcf85266e55db1f95f7315":["634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["629c38c4ae4e303d0617e05fbfe508140b32f0a3"],"407687e67faf6e1f02a211ca078d8e3eed631027":[],"8fd5be977c105554c6a7b68afcdbc511439723ab":[],"0ed6b1234af94a2693d3e6550e7b3ee41fd3f51c":["0a773283ef5eab2e9c7136eeb66574a4b7a2dc82"],"57c6c784f777a2cc8fa014507ea129526822714d":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"49e6a45bc6278d94e7c4aed1d36adde70842e00c":["37a0f60745e53927c4c876cfe5b5a58170f0646c","407687e67faf6e1f02a211ca078d8e3eed631027","59a0020b413d44dd79d85d7a66ed5004265fb453"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"59a0020b413d44dd79d85d7a66ed5004265fb453":["37a0f60745e53927c4c876cfe5b5a58170f0646c","6613659748fe4411a7dcf85266e55db1f95f7315"],"d6f074e73200c07d54f242d3880a8da5a35ff97b":[],"04e775de416dd2d8067b10db1c8af975a1d5017e":["57c6c784f777a2cc8fa014507ea129526822714d"],"629c38c4ae4e303d0617e05fbfe508140b32f0a3":["8fd5be977c105554c6a7b68afcdbc511439723ab","d6f074e73200c07d54f242d3880a8da5a35ff97b","ea8db162694636ac3d19d83debf895a9e089f96a"],"ea8db162694636ac3d19d83debf895a9e089f96a":["407687e67faf6e1f02a211ca078d8e3eed631027","8fd5be977c105554c6a7b68afcdbc511439723ab","49e6a45bc6278d94e7c4aed1d36adde70842e00c","d6f074e73200c07d54f242d3880a8da5a35ff97b"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["37a0f60745e53927c4c876cfe5b5a58170f0646c","407687e67faf6e1f02a211ca078d8e3eed631027","8fd5be977c105554c6a7b68afcdbc511439723ab","d6f074e73200c07d54f242d3880a8da5a35ff97b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}