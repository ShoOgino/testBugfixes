{"path":"lucene/core/src/java/org/apache/lucene/index/IndexWriterConfig#IndexWriterConfig(Version,Analyzer).mjava","commits":[{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":1,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriterConfig#IndexWriterConfig(Version,Analyzer).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/IndexWriterConfig#IndexWriterConfig(Version,Analyzer).mjava","sourceNew":"  /**\n   * Creates a new config that with defaults that match the specified\n   * {@link Version} as well as the default {@link\n   * Analyzer}. If matchVersion is >= {@link\n   * Version#LUCENE_32}, {@link TieredMergePolicy} is used\n   * for merging; else {@link LogByteSizeMergePolicy}.\n   * Note that {@link TieredMergePolicy} is free to select\n   * non-contiguous merges, which means docIDs may not\n   * remain montonic over time.  If this is a problem you\n   * should switch to {@link LogByteSizeMergePolicy} or\n   * {@link LogDocMergePolicy}.\n   */\n  public IndexWriterConfig(Version matchVersion, Analyzer analyzer) {\n    this.matchVersion = matchVersion;\n    this.analyzer = analyzer;\n    delPolicy = new KeepOnlyLastCommitDeletionPolicy();\n    commit = null;\n    openMode = OpenMode.CREATE_OR_APPEND;\n    similarity = IndexSearcher.getDefaultSimilarity();\n    termIndexInterval = DEFAULT_TERM_INDEX_INTERVAL; // TODO: this should be private to the codec, not settable here\n    mergeScheduler = new ConcurrentMergeScheduler();\n    writeLockTimeout = WRITE_LOCK_TIMEOUT;\n    maxBufferedDeleteTerms = DEFAULT_MAX_BUFFERED_DELETE_TERMS;\n    ramBufferSizeMB = DEFAULT_RAM_BUFFER_SIZE_MB;\n    maxBufferedDocs = DEFAULT_MAX_BUFFERED_DOCS;\n    indexingChain = DocumentsWriterPerThread.defaultIndexingChain;\n    mergedSegmentWarmer = null;\n    codec = Codec.getDefault();\n    infoStream = InfoStream.getDefault();\n    if (matchVersion.onOrAfter(Version.LUCENE_32)) {\n      mergePolicy = new TieredMergePolicy();\n    } else {\n      mergePolicy = new LogByteSizeMergePolicy();\n    }\n    flushPolicy = new FlushByRamOrCountsPolicy();\n    readerPooling = DEFAULT_READER_POOLING;\n    indexerThreadPool = new ThreadAffinityDocumentsWriterThreadPool();\n    readerTermsIndexDivisor = DEFAULT_READER_TERMS_INDEX_DIVISOR;\n    perThreadHardLimitMB = DEFAULT_RAM_PER_THREAD_HARD_LIMIT_MB;\n  }\n\n","sourceOld":"  /**\n   * Creates a new config that with defaults that match the specified\n   * {@link Version} as well as the default {@link\n   * Analyzer}. If matchVersion is >= {@link\n   * Version#LUCENE_32}, {@link TieredMergePolicy} is used\n   * for merging; else {@link LogByteSizeMergePolicy}.\n   * Note that {@link TieredMergePolicy} is free to select\n   * non-contiguous merges, which means docIDs may not\n   * remain montonic over time.  If this is a problem you\n   * should switch to {@link LogByteSizeMergePolicy} or\n   * {@link LogDocMergePolicy}.\n   */\n  public IndexWriterConfig(Version matchVersion, Analyzer analyzer) {\n    this.matchVersion = matchVersion;\n    this.analyzer = analyzer;\n    delPolicy = new KeepOnlyLastCommitDeletionPolicy();\n    commit = null;\n    openMode = OpenMode.CREATE_OR_APPEND;\n    similarity = IndexSearcher.getDefaultSimilarity();\n    termIndexInterval = DEFAULT_TERM_INDEX_INTERVAL; // TODO: this should be private to the codec, not settable here\n    mergeScheduler = new ConcurrentMergeScheduler();\n    writeLockTimeout = WRITE_LOCK_TIMEOUT;\n    maxBufferedDeleteTerms = DEFAULT_MAX_BUFFERED_DELETE_TERMS;\n    ramBufferSizeMB = DEFAULT_RAM_BUFFER_SIZE_MB;\n    maxBufferedDocs = DEFAULT_MAX_BUFFERED_DOCS;\n    indexingChain = DocumentsWriterPerThread.defaultIndexingChain;\n    mergedSegmentWarmer = null;\n    codec = Codec.getDefault();\n    infoStream = InfoStream.getDefault();\n    if (matchVersion.onOrAfter(Version.LUCENE_32)) {\n      mergePolicy = new TieredMergePolicy();\n    } else {\n      mergePolicy = new LogByteSizeMergePolicy();\n    }\n    flushPolicy = new FlushByRamOrCountsPolicy();\n    readerPooling = DEFAULT_READER_POOLING;\n    indexerThreadPool = new ThreadAffinityDocumentsWriterThreadPool();\n    readerTermsIndexDivisor = DEFAULT_READER_TERMS_INDEX_DIVISOR;\n    perThreadHardLimitMB = DEFAULT_RAM_PER_THREAD_HARD_LIMIT_MB;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f64b5c281a42c5a4634b39a4fcb8f21a0cba1600","date":1329061481,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriterConfig#IndexWriterConfig(Version,Analyzer).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriterConfig#IndexWriterConfig(Version,Analyzer).mjava","sourceNew":"  /**\n   * Creates a new config that with defaults that match the specified\n   * {@link Version} as well as the default {@link\n   * Analyzer}. If matchVersion is >= {@link\n   * Version#LUCENE_32}, {@link TieredMergePolicy} is used\n   * for merging; else {@link LogByteSizeMergePolicy}.\n   * Note that {@link TieredMergePolicy} is free to select\n   * non-contiguous merges, which means docIDs may not\n   * remain montonic over time.  If this is a problem you\n   * should switch to {@link LogByteSizeMergePolicy} or\n   * {@link LogDocMergePolicy}.\n   */\n  public IndexWriterConfig(Version matchVersion, Analyzer analyzer) {\n    this.matchVersion = matchVersion;\n    this.analyzer = analyzer;\n    delPolicy = new KeepOnlyLastCommitDeletionPolicy();\n    commit = null;\n    openMode = OpenMode.CREATE_OR_APPEND;\n    similarity = IndexSearcher.getDefaultSimilarity();\n    termIndexInterval = DEFAULT_TERM_INDEX_INTERVAL; // TODO: this should be private to the codec, not settable here\n    mergeScheduler = new ConcurrentMergeScheduler();\n    writeLockTimeout = WRITE_LOCK_TIMEOUT;\n    maxBufferedDeleteTerms = DEFAULT_MAX_BUFFERED_DELETE_TERMS;\n    ramBufferSizeMB = DEFAULT_RAM_BUFFER_SIZE_MB;\n    maxBufferedDocs = DEFAULT_MAX_BUFFERED_DOCS;\n    indexingChain = DocumentsWriterPerThread.defaultIndexingChain;\n    mergedSegmentWarmer = null;\n    codec = Codec.getDefault();\n    infoStream = InfoStream.getDefault();\n    if (matchVersion.onOrAfter(Version.LUCENE_32)) {\n      mergePolicy = new TieredMergePolicy();\n    } else {\n      mergePolicy = new LogByteSizeMergePolicy();\n    }\n    flushPolicy = new FlushByRamOrCountsPolicy();\n    readerPooling = DEFAULT_READER_POOLING;\n    indexerThreadPool = new ThreadAffinityDocumentsWriterThreadPool(DEFAULT_MAX_THREAD_STATES);\n    readerTermsIndexDivisor = DEFAULT_READER_TERMS_INDEX_DIVISOR;\n    perThreadHardLimitMB = DEFAULT_RAM_PER_THREAD_HARD_LIMIT_MB;\n  }\n\n","sourceOld":"  /**\n   * Creates a new config that with defaults that match the specified\n   * {@link Version} as well as the default {@link\n   * Analyzer}. If matchVersion is >= {@link\n   * Version#LUCENE_32}, {@link TieredMergePolicy} is used\n   * for merging; else {@link LogByteSizeMergePolicy}.\n   * Note that {@link TieredMergePolicy} is free to select\n   * non-contiguous merges, which means docIDs may not\n   * remain montonic over time.  If this is a problem you\n   * should switch to {@link LogByteSizeMergePolicy} or\n   * {@link LogDocMergePolicy}.\n   */\n  public IndexWriterConfig(Version matchVersion, Analyzer analyzer) {\n    this.matchVersion = matchVersion;\n    this.analyzer = analyzer;\n    delPolicy = new KeepOnlyLastCommitDeletionPolicy();\n    commit = null;\n    openMode = OpenMode.CREATE_OR_APPEND;\n    similarity = IndexSearcher.getDefaultSimilarity();\n    termIndexInterval = DEFAULT_TERM_INDEX_INTERVAL; // TODO: this should be private to the codec, not settable here\n    mergeScheduler = new ConcurrentMergeScheduler();\n    writeLockTimeout = WRITE_LOCK_TIMEOUT;\n    maxBufferedDeleteTerms = DEFAULT_MAX_BUFFERED_DELETE_TERMS;\n    ramBufferSizeMB = DEFAULT_RAM_BUFFER_SIZE_MB;\n    maxBufferedDocs = DEFAULT_MAX_BUFFERED_DOCS;\n    indexingChain = DocumentsWriterPerThread.defaultIndexingChain;\n    mergedSegmentWarmer = null;\n    codec = Codec.getDefault();\n    infoStream = InfoStream.getDefault();\n    if (matchVersion.onOrAfter(Version.LUCENE_32)) {\n      mergePolicy = new TieredMergePolicy();\n    } else {\n      mergePolicy = new LogByteSizeMergePolicy();\n    }\n    flushPolicy = new FlushByRamOrCountsPolicy();\n    readerPooling = DEFAULT_READER_POOLING;\n    indexerThreadPool = new ThreadAffinityDocumentsWriterThreadPool();\n    readerTermsIndexDivisor = DEFAULT_READER_TERMS_INDEX_DIVISOR;\n    perThreadHardLimitMB = DEFAULT_RAM_PER_THREAD_HARD_LIMIT_MB;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e7e8d6f15900ee22ac3cb0a503f15dc952a3580f","date":1338430031,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriterConfig#IndexWriterConfig(Version,Analyzer).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriterConfig#IndexWriterConfig(Version,Analyzer).mjava","sourceNew":"  /**\n   * Creates a new config that with defaults that match the specified\n   * {@link Version} as well as the default {@link\n   * Analyzer}. By default, {@link TieredMergePolicy} is used\n   * for merging;\n   * Note that {@link TieredMergePolicy} is free to select\n   * non-contiguous merges, which means docIDs may not\n   * remain monotonic over time.  If this is a problem you\n   * should switch to {@link LogByteSizeMergePolicy} or\n   * {@link LogDocMergePolicy}.\n   */\n  public IndexWriterConfig(Version matchVersion, Analyzer analyzer) {\n    this.matchVersion = matchVersion;\n    this.analyzer = analyzer;\n    delPolicy = new KeepOnlyLastCommitDeletionPolicy();\n    commit = null;\n    openMode = OpenMode.CREATE_OR_APPEND;\n    similarity = IndexSearcher.getDefaultSimilarity();\n    termIndexInterval = DEFAULT_TERM_INDEX_INTERVAL; // TODO: this should be private to the codec, not settable here\n    mergeScheduler = new ConcurrentMergeScheduler();\n    writeLockTimeout = WRITE_LOCK_TIMEOUT;\n    maxBufferedDeleteTerms = DEFAULT_MAX_BUFFERED_DELETE_TERMS;\n    ramBufferSizeMB = DEFAULT_RAM_BUFFER_SIZE_MB;\n    maxBufferedDocs = DEFAULT_MAX_BUFFERED_DOCS;\n    indexingChain = DocumentsWriterPerThread.defaultIndexingChain;\n    mergedSegmentWarmer = null;\n    codec = Codec.getDefault();\n    infoStream = InfoStream.getDefault();\n    mergePolicy = new TieredMergePolicy();\n    flushPolicy = new FlushByRamOrCountsPolicy();\n    readerPooling = DEFAULT_READER_POOLING;\n    indexerThreadPool = new ThreadAffinityDocumentsWriterThreadPool(DEFAULT_MAX_THREAD_STATES);\n    readerTermsIndexDivisor = DEFAULT_READER_TERMS_INDEX_DIVISOR;\n    perThreadHardLimitMB = DEFAULT_RAM_PER_THREAD_HARD_LIMIT_MB;\n  }\n\n","sourceOld":"  /**\n   * Creates a new config that with defaults that match the specified\n   * {@link Version} as well as the default {@link\n   * Analyzer}. If matchVersion is >= {@link\n   * Version#LUCENE_32}, {@link TieredMergePolicy} is used\n   * for merging; else {@link LogByteSizeMergePolicy}.\n   * Note that {@link TieredMergePolicy} is free to select\n   * non-contiguous merges, which means docIDs may not\n   * remain montonic over time.  If this is a problem you\n   * should switch to {@link LogByteSizeMergePolicy} or\n   * {@link LogDocMergePolicy}.\n   */\n  public IndexWriterConfig(Version matchVersion, Analyzer analyzer) {\n    this.matchVersion = matchVersion;\n    this.analyzer = analyzer;\n    delPolicy = new KeepOnlyLastCommitDeletionPolicy();\n    commit = null;\n    openMode = OpenMode.CREATE_OR_APPEND;\n    similarity = IndexSearcher.getDefaultSimilarity();\n    termIndexInterval = DEFAULT_TERM_INDEX_INTERVAL; // TODO: this should be private to the codec, not settable here\n    mergeScheduler = new ConcurrentMergeScheduler();\n    writeLockTimeout = WRITE_LOCK_TIMEOUT;\n    maxBufferedDeleteTerms = DEFAULT_MAX_BUFFERED_DELETE_TERMS;\n    ramBufferSizeMB = DEFAULT_RAM_BUFFER_SIZE_MB;\n    maxBufferedDocs = DEFAULT_MAX_BUFFERED_DOCS;\n    indexingChain = DocumentsWriterPerThread.defaultIndexingChain;\n    mergedSegmentWarmer = null;\n    codec = Codec.getDefault();\n    infoStream = InfoStream.getDefault();\n    if (matchVersion.onOrAfter(Version.LUCENE_32)) {\n      mergePolicy = new TieredMergePolicy();\n    } else {\n      mergePolicy = new LogByteSizeMergePolicy();\n    }\n    flushPolicy = new FlushByRamOrCountsPolicy();\n    readerPooling = DEFAULT_READER_POOLING;\n    indexerThreadPool = new ThreadAffinityDocumentsWriterThreadPool(DEFAULT_MAX_THREAD_STATES);\n    readerTermsIndexDivisor = DEFAULT_READER_TERMS_INDEX_DIVISOR;\n    perThreadHardLimitMB = DEFAULT_RAM_PER_THREAD_HARD_LIMIT_MB;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7f4e54ed7cef46f86888b5fb547594f62160395c","date":1340006971,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriterConfig#IndexWriterConfig(Version,Analyzer).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriterConfig#IndexWriterConfig(Version,Analyzer).mjava","sourceNew":"  /**\n   * Creates a new config that with defaults that match the specified\n   * {@link Version} as well as the default {@link\n   * Analyzer}. By default, {@link TieredMergePolicy} is used\n   * for merging;\n   * Note that {@link TieredMergePolicy} is free to select\n   * non-contiguous merges, which means docIDs may not\n   * remain monotonic over time.  If this is a problem you\n   * should switch to {@link LogByteSizeMergePolicy} or\n   * {@link LogDocMergePolicy}.\n   */\n  public IndexWriterConfig(Version matchVersion, Analyzer analyzer) {\n    super(analyzer, matchVersion);\n  }\n\n","sourceOld":"  /**\n   * Creates a new config that with defaults that match the specified\n   * {@link Version} as well as the default {@link\n   * Analyzer}. By default, {@link TieredMergePolicy} is used\n   * for merging;\n   * Note that {@link TieredMergePolicy} is free to select\n   * non-contiguous merges, which means docIDs may not\n   * remain monotonic over time.  If this is a problem you\n   * should switch to {@link LogByteSizeMergePolicy} or\n   * {@link LogDocMergePolicy}.\n   */\n  public IndexWriterConfig(Version matchVersion, Analyzer analyzer) {\n    this.matchVersion = matchVersion;\n    this.analyzer = analyzer;\n    delPolicy = new KeepOnlyLastCommitDeletionPolicy();\n    commit = null;\n    openMode = OpenMode.CREATE_OR_APPEND;\n    similarity = IndexSearcher.getDefaultSimilarity();\n    termIndexInterval = DEFAULT_TERM_INDEX_INTERVAL; // TODO: this should be private to the codec, not settable here\n    mergeScheduler = new ConcurrentMergeScheduler();\n    writeLockTimeout = WRITE_LOCK_TIMEOUT;\n    maxBufferedDeleteTerms = DEFAULT_MAX_BUFFERED_DELETE_TERMS;\n    ramBufferSizeMB = DEFAULT_RAM_BUFFER_SIZE_MB;\n    maxBufferedDocs = DEFAULT_MAX_BUFFERED_DOCS;\n    indexingChain = DocumentsWriterPerThread.defaultIndexingChain;\n    mergedSegmentWarmer = null;\n    codec = Codec.getDefault();\n    infoStream = InfoStream.getDefault();\n    mergePolicy = new TieredMergePolicy();\n    flushPolicy = new FlushByRamOrCountsPolicy();\n    readerPooling = DEFAULT_READER_POOLING;\n    indexerThreadPool = new ThreadAffinityDocumentsWriterThreadPool(DEFAULT_MAX_THREAD_STATES);\n    readerTermsIndexDivisor = DEFAULT_READER_TERMS_INDEX_DIVISOR;\n    perThreadHardLimitMB = DEFAULT_RAM_PER_THREAD_HARD_LIMIT_MB;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d0ef034a4f10871667ae75181537775ddcf8ade4","date":1407610475,"type":5,"author":"Ryan Ernst","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexWriterConfig#IndexWriterConfig(Analyzer).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriterConfig#IndexWriterConfig(Version,Analyzer).mjava","sourceNew":"  /**\n   * Creates a new config that with the default {@link\n   * Analyzer}. By default, {@link TieredMergePolicy} is used\n   * for merging;\n   * Note that {@link TieredMergePolicy} is free to select\n   * non-contiguous merges, which means docIDs may not\n   * remain monotonic over time.  If this is a problem you\n   * should switch to {@link LogByteSizeMergePolicy} or\n   * {@link LogDocMergePolicy}.\n   */\n  public IndexWriterConfig(Analyzer analyzer) {\n    super(analyzer);\n  }\n\n","sourceOld":"  /**\n   * Creates a new config that with defaults that match the specified\n   * {@link Version} as well as the default {@link\n   * Analyzer}. By default, {@link TieredMergePolicy} is used\n   * for merging;\n   * Note that {@link TieredMergePolicy} is free to select\n   * non-contiguous merges, which means docIDs may not\n   * remain monotonic over time.  If this is a problem you\n   * should switch to {@link LogByteSizeMergePolicy} or\n   * {@link LogDocMergePolicy}.\n   */\n  public IndexWriterConfig(Version matchVersion, Analyzer analyzer) {\n    super(analyzer, matchVersion);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"e7e8d6f15900ee22ac3cb0a503f15dc952a3580f":["f64b5c281a42c5a4634b39a4fcb8f21a0cba1600"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"d0ef034a4f10871667ae75181537775ddcf8ade4":["7f4e54ed7cef46f86888b5fb547594f62160395c"],"7f4e54ed7cef46f86888b5fb547594f62160395c":["e7e8d6f15900ee22ac3cb0a503f15dc952a3580f"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"f64b5c281a42c5a4634b39a4fcb8f21a0cba1600":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"]},"commit2Childs":{"e7e8d6f15900ee22ac3cb0a503f15dc952a3580f":["7f4e54ed7cef46f86888b5fb547594f62160395c"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["f64b5c281a42c5a4634b39a4fcb8f21a0cba1600"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"d0ef034a4f10871667ae75181537775ddcf8ade4":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"7f4e54ed7cef46f86888b5fb547594f62160395c":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"f64b5c281a42c5a4634b39a4fcb8f21a0cba1600":["e7e8d6f15900ee22ac3cb0a503f15dc952a3580f"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}