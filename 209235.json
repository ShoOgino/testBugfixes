{"path":"lucene/src/java/org/apache/lucene/index/codecs/BlockTermsReader.FieldReader.SegmentTermsEnum#seek(BytesRef,boolean).mjava","commits":[{"id":"b1add9ddc0005b07550d4350720aac22dc9886b3","date":1295549635,"type":1,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/codecs/BlockTermsReader.FieldReader.SegmentTermsEnum#seek(BytesRef,boolean).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/codecs/PrefixCodedTermsReader.FieldReader.SegmentTermsEnum#seek(BytesRef,boolean).mjava","sourceNew":"      @Override\n      public SeekStatus seek(final BytesRef target, final boolean useCache) throws IOException {\n\n        if (indexEnum == null) {\n          throw new IllegalStateException(\"terms index was not loaded\");\n        }\n        \n        //System.out.println(\"BTR.seek seg=\" + segment + \" target=\" + fieldInfo.name + \":\" + target.utf8ToString() + \" \" + target + \" current=\" + term().utf8ToString() + \" \" + term() + \" useCache=\" + useCache + \" indexIsCurrent=\" + indexIsCurrent + \" didIndexNext=\" + didIndexNext + \" seekPending=\" + seekPending + \" divisor=\" + indexReader.getDivisor() + \" this=\"  + this);\n        /*\n        if (didIndexNext) {\n          if (nextIndexTerm == null) {\n            //System.out.println(\"  nextIndexTerm=null\");\n          } else {\n            //System.out.println(\"  nextIndexTerm=\" + nextIndexTerm.utf8ToString());\n          }\n        }\n        */\n\n        // Check cache\n        if (useCache) {\n          fieldTerm.term = target;\n          // TODO: should we differentiate \"frozen\"\n          // TermState (ie one that was cloned and\n          // cached/returned by termState()) from the\n          // malleable (primary) one?\n          final TermState cachedState = termsCache.get(fieldTerm);\n          if (cachedState != null) {\n            seekPending = true;\n            //System.out.println(\"  cached!\");\n            seek(target, cachedState);\n            //System.out.println(\"  term=\" + term.utf8ToString());\n            return SeekStatus.FOUND;\n          }\n        }\n\n        boolean doSeek = true;\n\n        // See if we can avoid seeking, because target term\n        // is after current term but before next index term:\n        if (indexIsCurrent) {\n\n          final int cmp = termComp.compare(term, target);\n\n          if (cmp == 0) {\n            // Already at the requested term\n            return SeekStatus.FOUND;\n          } else if (cmp < 0) {\n\n            // Target term is after current term\n            if (!didIndexNext) {\n              if (indexEnum.next() == -1) {\n                nextIndexTerm = null;\n              } else {\n                nextIndexTerm = indexEnum.term();\n              }\n              //System.out.println(\"  now do index next() nextIndexTerm=\" + (nextIndexTerm == null ? \"null\" : nextIndexTerm.utf8ToString()));\n              didIndexNext = true;\n            }\n\n            if (nextIndexTerm == null || termComp.compare(target, nextIndexTerm) < 0) {\n              // Optimization: requested term is within the\n              // same term block we are now in; skip seeking\n              // (but do scanning):\n              doSeek = false;\n              //System.out.println(\"  skip seek: nextIndexTerm=\" + (nextIndexTerm == null ? \"null\" : nextIndexTerm.utf8ToString()));\n            }\n          }\n        }\n\n        if (doSeek) {\n          //System.out.println(\"  seek\");\n\n          // Ask terms index to find biggest indexed term (=\n          // first term in a block) that's <= our text:\n          in.seek(indexEnum.seek(target));\n          boolean result = nextBlock();\n\n          // Block must exist since, at least, the indexed term\n          // is in the block:\n          assert result;\n\n          indexIsCurrent = true;\n          didIndexNext = false;\n          blocksSinceSeek = 0;          \n\n          if (doOrd) {\n            state.ord = indexEnum.ord()-1;\n          }\n\n          // NOTE: the first _next() after an index seek is\n          // a bit wasteful, since it redundantly reads some\n          // suffix bytes into the buffer.  We could avoid storing\n          // those bytes in the primary file, but then when\n          // next()ing over an index term we'd have to\n          // special case it:\n          term.copy(indexEnum.term());\n          //System.out.println(\"  seek: term=\" + term.utf8ToString());\n        } else {\n          ////System.out.println(\"  skip seek\");\n        }\n\n        seekPending = false;\n\n        // Now scan:\n        while (_next() != null) {\n          final int cmp = termComp.compare(term, target);\n          if (cmp == 0) {\n            // Match!\n            if (useCache) {\n              // Store in cache\n              decodeMetaData();\n              termsCache.put(new FieldAndTerm(fieldTerm), (BlockTermState) state.clone());\n            }\n            //System.out.println(\"  FOUND\");\n            return SeekStatus.FOUND;\n          } else if (cmp > 0) {\n            //System.out.println(\"  NOT_FOUND term=\" + term.utf8ToString());\n            return SeekStatus.NOT_FOUND;\n          }\n          \n          // The purpose of the terms dict index is to seek\n          // the enum to the closest index term before the\n          // term we are looking for.  So, we should never\n          // cross another index term (besides the first\n          // one) while we are scanning:\n          assert indexIsCurrent;\n        }\n\n        indexIsCurrent = false;\n        //System.out.println(\"  END\");\n        return SeekStatus.END;\n      }\n\n","sourceOld":"      /** Seeks until the first term that's >= the provided\n       *  text; returns SeekStatus.FOUND if the exact term\n       *  is found, SeekStatus.NOT_FOUND if a different term\n       *  was found, SeekStatus.END if we hit EOF */\n      @Override\n      public SeekStatus seek(final BytesRef term, final boolean useCache) throws IOException {\n\n        if (indexEnum == null) {\n          throw new IllegalStateException(\"terms index was not loaded\");\n        }\n        \n        //System.out.println(\"te.seek term=\" + fieldInfo.name + \":\" + term.utf8ToString() + \" current=\" + term().utf8ToString() + \" useCache=\" + useCache + \" this=\"  + this);\n\n        // Check cache\n        fieldTerm.term = term;\n        TermState cachedState;\n        if (useCache) {\n          cachedState = termsCache.get(fieldTerm);\n          if (cachedState != null) {\n            state.copyFrom(cachedState);\n            setTermState(term, state);\n            positioned = false;\n            //System.out.println(\"  cached!\");\n            return SeekStatus.FOUND;\n          }\n        } else {\n          cachedState = null;\n        }\n\n        boolean doSeek = true;\n\n        if (positioned) {\n\n          final int cmp = termComp.compare(bytesReader.term, term);\n\n          if (cmp == 0) {\n            // already at the requested term\n            return SeekStatus.FOUND;\n          } else if (cmp < 0) {\n\n            if (seekPending) {\n              seekPending = false;\n              in.seek(state.filePointer);\n              indexEnum.seek(bytesReader.term);\n              didIndexNext = false;\n            }\n\n            // Target term is after current term\n            if (!didIndexNext) {\n              if (indexEnum.next() == -1) {\n                nextIndexTerm = null;\n              } else {\n                nextIndexTerm = indexEnum.term();\n              }\n              //System.out.println(\"  now do index next() nextIndexTerm=\" + (nextIndexTerm == null ? \"null\" : nextIndexTerm.utf8ToString()));\n              didIndexNext = true;\n            }\n\n            if (nextIndexTerm == null || termComp.compare(term, nextIndexTerm) < 0) {\n              // Optimization: requested term is within the\n              // same index block we are now in; skip seeking\n              // (but do scanning):\n              doSeek = false;\n              //System.out.println(\"  skip seek: nextIndexTerm=\" + nextIndexTerm);\n            }\n          }\n        }\n\n        if (doSeek) {\n\n          positioned = true;\n\n          // Ask terms index to find biggest index term that's <=\n          // our text:\n          in.seek(indexEnum.seek(term));\n          didIndexNext = false;\n          if (doOrd) {\n            state.ord = indexEnum.ord()-1;\n          }\n          seekPending = false;\n\n          // NOTE: the first next() after an index seek is\n          // wasteful, since it redundantly reads the same\n          // bytes into the buffer.  We could avoid storing\n          // those bytes in the primary file, but then when\n          // scanning over an index term we'd have to\n          // special case it:\n          bytesReader.reset(indexEnum.term());\n          //System.out.println(\"  doSeek term=\" + indexEnum.term().utf8ToString() + \" vs target=\" + term.utf8ToString());\n        } else {\n          //System.out.println(\"  skip seek\");\n        }\n\n        assert startSeek();\n\n        // Now scan:\n        while (next() != null) {\n          final int cmp = termComp.compare(bytesReader.term, term);\n          if (cmp == 0) {\n            // Done!\n            if (useCache) {\n              cacheTerm(fieldTerm);\n            }\n\n            return SeekStatus.FOUND;\n          } else if (cmp > 0) {\n            return SeekStatus.NOT_FOUND;\n          }\n\n          // The purpose of the terms dict index is to seek\n          // the enum to the closest index term before the\n          // term we are looking for.  So, we should never\n          // cross another index term (besides the first\n          // one) while we are scanning:\n          assert checkSeekScan();\n        }\n\n        positioned = false;\n        return SeekStatus.END;\n      }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fd1bfe3cedf815c14939d170d53031c88eb5c444","date":1295896578,"type":0,"author":"Michael Busch","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/codecs/BlockTermsReader.FieldReader.SegmentTermsEnum#seek(BytesRef,boolean).mjava","pathOld":"/dev/null","sourceNew":"      @Override\n      public SeekStatus seek(final BytesRef target, final boolean useCache) throws IOException {\n\n        if (indexEnum == null) {\n          throw new IllegalStateException(\"terms index was not loaded\");\n        }\n        \n        //System.out.println(\"BTR.seek seg=\" + segment + \" target=\" + fieldInfo.name + \":\" + target.utf8ToString() + \" \" + target + \" current=\" + term().utf8ToString() + \" \" + term() + \" useCache=\" + useCache + \" indexIsCurrent=\" + indexIsCurrent + \" didIndexNext=\" + didIndexNext + \" seekPending=\" + seekPending + \" divisor=\" + indexReader.getDivisor() + \" this=\"  + this);\n        /*\n        if (didIndexNext) {\n          if (nextIndexTerm == null) {\n            //System.out.println(\"  nextIndexTerm=null\");\n          } else {\n            //System.out.println(\"  nextIndexTerm=\" + nextIndexTerm.utf8ToString());\n          }\n        }\n        */\n\n        // Check cache\n        if (useCache) {\n          fieldTerm.term = target;\n          // TODO: should we differentiate \"frozen\"\n          // TermState (ie one that was cloned and\n          // cached/returned by termState()) from the\n          // malleable (primary) one?\n          final TermState cachedState = termsCache.get(fieldTerm);\n          if (cachedState != null) {\n            seekPending = true;\n            //System.out.println(\"  cached!\");\n            seek(target, cachedState);\n            //System.out.println(\"  term=\" + term.utf8ToString());\n            return SeekStatus.FOUND;\n          }\n        }\n\n        boolean doSeek = true;\n\n        // See if we can avoid seeking, because target term\n        // is after current term but before next index term:\n        if (indexIsCurrent) {\n\n          final int cmp = termComp.compare(term, target);\n\n          if (cmp == 0) {\n            // Already at the requested term\n            return SeekStatus.FOUND;\n          } else if (cmp < 0) {\n\n            // Target term is after current term\n            if (!didIndexNext) {\n              if (indexEnum.next() == -1) {\n                nextIndexTerm = null;\n              } else {\n                nextIndexTerm = indexEnum.term();\n              }\n              //System.out.println(\"  now do index next() nextIndexTerm=\" + (nextIndexTerm == null ? \"null\" : nextIndexTerm.utf8ToString()));\n              didIndexNext = true;\n            }\n\n            if (nextIndexTerm == null || termComp.compare(target, nextIndexTerm) < 0) {\n              // Optimization: requested term is within the\n              // same term block we are now in; skip seeking\n              // (but do scanning):\n              doSeek = false;\n              //System.out.println(\"  skip seek: nextIndexTerm=\" + (nextIndexTerm == null ? \"null\" : nextIndexTerm.utf8ToString()));\n            }\n          }\n        }\n\n        if (doSeek) {\n          //System.out.println(\"  seek\");\n\n          // Ask terms index to find biggest indexed term (=\n          // first term in a block) that's <= our text:\n          in.seek(indexEnum.seek(target));\n          boolean result = nextBlock();\n\n          // Block must exist since, at least, the indexed term\n          // is in the block:\n          assert result;\n\n          indexIsCurrent = true;\n          didIndexNext = false;\n          blocksSinceSeek = 0;          \n\n          if (doOrd) {\n            state.ord = indexEnum.ord()-1;\n          }\n\n          // NOTE: the first _next() after an index seek is\n          // a bit wasteful, since it redundantly reads some\n          // suffix bytes into the buffer.  We could avoid storing\n          // those bytes in the primary file, but then when\n          // next()ing over an index term we'd have to\n          // special case it:\n          term.copy(indexEnum.term());\n          //System.out.println(\"  seek: term=\" + term.utf8ToString());\n        } else {\n          ////System.out.println(\"  skip seek\");\n        }\n\n        seekPending = false;\n\n        // Now scan:\n        while (_next() != null) {\n          final int cmp = termComp.compare(term, target);\n          if (cmp == 0) {\n            // Match!\n            if (useCache) {\n              // Store in cache\n              decodeMetaData();\n              termsCache.put(new FieldAndTerm(fieldTerm), (BlockTermState) state.clone());\n            }\n            //System.out.println(\"  FOUND\");\n            return SeekStatus.FOUND;\n          } else if (cmp > 0) {\n            //System.out.println(\"  NOT_FOUND term=\" + term.utf8ToString());\n            return SeekStatus.NOT_FOUND;\n          }\n          \n          // The purpose of the terms dict index is to seek\n          // the enum to the closest index term before the\n          // term we are looking for.  So, we should never\n          // cross another index term (besides the first\n          // one) while we are scanning:\n          assert indexIsCurrent;\n        }\n\n        indexIsCurrent = false;\n        //System.out.println(\"  END\");\n        return SeekStatus.END;\n      }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"29ef99d61cda9641b6250bf9567329a6e65f901d","date":1297244127,"type":0,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/codecs/BlockTermsReader.FieldReader.SegmentTermsEnum#seek(BytesRef,boolean).mjava","pathOld":"/dev/null","sourceNew":"      @Override\n      public SeekStatus seek(final BytesRef target, final boolean useCache) throws IOException {\n\n        if (indexEnum == null) {\n          throw new IllegalStateException(\"terms index was not loaded\");\n        }\n        \n        //System.out.println(\"BTR.seek seg=\" + segment + \" target=\" + fieldInfo.name + \":\" + target.utf8ToString() + \" \" + target + \" current=\" + term().utf8ToString() + \" \" + term() + \" useCache=\" + useCache + \" indexIsCurrent=\" + indexIsCurrent + \" didIndexNext=\" + didIndexNext + \" seekPending=\" + seekPending + \" divisor=\" + indexReader.getDivisor() + \" this=\"  + this);\n        /*\n        if (didIndexNext) {\n          if (nextIndexTerm == null) {\n            //System.out.println(\"  nextIndexTerm=null\");\n          } else {\n            //System.out.println(\"  nextIndexTerm=\" + nextIndexTerm.utf8ToString());\n          }\n        }\n        */\n\n        // Check cache\n        if (useCache) {\n          fieldTerm.term = target;\n          // TODO: should we differentiate \"frozen\"\n          // TermState (ie one that was cloned and\n          // cached/returned by termState()) from the\n          // malleable (primary) one?\n          final TermState cachedState = termsCache.get(fieldTerm);\n          if (cachedState != null) {\n            seekPending = true;\n            //System.out.println(\"  cached!\");\n            seek(target, cachedState);\n            //System.out.println(\"  term=\" + term.utf8ToString());\n            return SeekStatus.FOUND;\n          }\n        }\n\n        boolean doSeek = true;\n\n        // See if we can avoid seeking, because target term\n        // is after current term but before next index term:\n        if (indexIsCurrent) {\n\n          final int cmp = termComp.compare(term, target);\n\n          if (cmp == 0) {\n            // Already at the requested term\n            return SeekStatus.FOUND;\n          } else if (cmp < 0) {\n\n            // Target term is after current term\n            if (!didIndexNext) {\n              if (indexEnum.next() == -1) {\n                nextIndexTerm = null;\n              } else {\n                nextIndexTerm = indexEnum.term();\n              }\n              //System.out.println(\"  now do index next() nextIndexTerm=\" + (nextIndexTerm == null ? \"null\" : nextIndexTerm.utf8ToString()));\n              didIndexNext = true;\n            }\n\n            if (nextIndexTerm == null || termComp.compare(target, nextIndexTerm) < 0) {\n              // Optimization: requested term is within the\n              // same term block we are now in; skip seeking\n              // (but do scanning):\n              doSeek = false;\n              //System.out.println(\"  skip seek: nextIndexTerm=\" + (nextIndexTerm == null ? \"null\" : nextIndexTerm.utf8ToString()));\n            }\n          }\n        }\n\n        if (doSeek) {\n          //System.out.println(\"  seek\");\n\n          // Ask terms index to find biggest indexed term (=\n          // first term in a block) that's <= our text:\n          in.seek(indexEnum.seek(target));\n          boolean result = nextBlock();\n\n          // Block must exist since, at least, the indexed term\n          // is in the block:\n          assert result;\n\n          indexIsCurrent = true;\n          didIndexNext = false;\n          blocksSinceSeek = 0;          \n\n          if (doOrd) {\n            state.ord = indexEnum.ord()-1;\n          }\n\n          // NOTE: the first _next() after an index seek is\n          // a bit wasteful, since it redundantly reads some\n          // suffix bytes into the buffer.  We could avoid storing\n          // those bytes in the primary file, but then when\n          // next()ing over an index term we'd have to\n          // special case it:\n          term.copy(indexEnum.term());\n          //System.out.println(\"  seek: term=\" + term.utf8ToString());\n        } else {\n          ////System.out.println(\"  skip seek\");\n        }\n\n        seekPending = false;\n\n        // Now scan:\n        while (_next() != null) {\n          final int cmp = termComp.compare(term, target);\n          if (cmp == 0) {\n            // Match!\n            if (useCache) {\n              // Store in cache\n              decodeMetaData();\n              termsCache.put(new FieldAndTerm(fieldTerm), (BlockTermState) state.clone());\n            }\n            //System.out.println(\"  FOUND\");\n            return SeekStatus.FOUND;\n          } else if (cmp > 0) {\n            //System.out.println(\"  NOT_FOUND term=\" + term.utf8ToString());\n            return SeekStatus.NOT_FOUND;\n          }\n          \n          // The purpose of the terms dict index is to seek\n          // the enum to the closest index term before the\n          // term we are looking for.  So, we should never\n          // cross another index term (besides the first\n          // one) while we are scanning:\n          assert indexIsCurrent;\n        }\n\n        indexIsCurrent = false;\n        //System.out.println(\"  END\");\n        return SeekStatus.END;\n      }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4fd64b6aa64934b0e35d9ec3e6c5a5c60ffc1762","date":1297938719,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/codecs/BlockTermsReader.FieldReader.SegmentTermsEnum#seek(BytesRef,boolean).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/codecs/BlockTermsReader.FieldReader.SegmentTermsEnum#seek(BytesRef,boolean).mjava","sourceNew":"      // TODO: we may want an alternate mode here which is\n      // \"if you are about to return NOT_FOUND I won't use\n      // the terms data from that\"; eg FuzzyTermsEnum will\n      // (usually) just immediately call seek again if we\n      // return NOT_FOUND so it's a waste for us to fill in\n      // the term that was actually NOT_FOUND\n      @Override\n      public SeekStatus seek(final BytesRef target, final boolean useCache) throws IOException {\n\n        if (indexEnum == null) {\n          throw new IllegalStateException(\"terms index was not loaded\");\n        }\n   \n        /*\n        System.out.println(\"BTR.seek seg=\" + segment + \" target=\" + fieldInfo.name + \":\" + target.utf8ToString() + \" \" + target + \" current=\" + term().utf8ToString() + \" \" + term() + \" useCache=\" + useCache + \" indexIsCurrent=\" + indexIsCurrent + \" didIndexNext=\" + didIndexNext + \" seekPending=\" + seekPending + \" divisor=\" + indexReader.getDivisor() + \" this=\"  + this);\n        if (didIndexNext) {\n          if (nextIndexTerm == null) {\n            System.out.println(\"  nextIndexTerm=null\");\n          } else {\n            System.out.println(\"  nextIndexTerm=\" + nextIndexTerm.utf8ToString());\n          }\n        }\n        */\n\n        // Check cache\n        if (useCache) {\n          fieldTerm.term = target;\n          // TODO: should we differentiate \"frozen\"\n          // TermState (ie one that was cloned and\n          // cached/returned by termState()) from the\n          // malleable (primary) one?\n          final TermState cachedState = termsCache.get(fieldTerm);\n          if (cachedState != null) {\n            seekPending = true;\n            //System.out.println(\"  cached!\");\n            seek(target, cachedState);\n            //System.out.println(\"  term=\" + term.utf8ToString());\n            return SeekStatus.FOUND;\n          }\n        }\n\n        boolean doSeek = true;\n\n        // See if we can avoid seeking, because target term\n        // is after current term but before next index term:\n        if (indexIsCurrent) {\n\n          final int cmp = BytesRef.getUTF8SortedAsUnicodeComparator().compare(term, target);\n\n          if (cmp == 0) {\n            // Already at the requested term\n            return SeekStatus.FOUND;\n          } else if (cmp < 0) {\n\n            // Target term is after current term\n            if (!didIndexNext) {\n              if (indexEnum.next() == -1) {\n                nextIndexTerm = null;\n              } else {\n                nextIndexTerm = indexEnum.term();\n              }\n              //System.out.println(\"  now do index next() nextIndexTerm=\" + (nextIndexTerm == null ? \"null\" : nextIndexTerm.utf8ToString()));\n              didIndexNext = true;\n            }\n\n            if (nextIndexTerm == null || BytesRef.getUTF8SortedAsUnicodeComparator().compare(target, nextIndexTerm) < 0) {\n              // Optimization: requested term is within the\n              // same term block we are now in; skip seeking\n              // (but do scanning):\n              doSeek = false;\n              //System.out.println(\"  skip seek: nextIndexTerm=\" + (nextIndexTerm == null ? \"null\" : nextIndexTerm.utf8ToString()));\n            }\n          }\n        }\n\n        if (doSeek) {\n          //System.out.println(\"  seek\");\n\n          // Ask terms index to find biggest indexed term (=\n          // first term in a block) that's <= our text:\n          in.seek(indexEnum.seek(target));\n          boolean result = nextBlock();\n\n          // Block must exist since, at least, the indexed term\n          // is in the block:\n          assert result;\n\n          indexIsCurrent = true;\n          didIndexNext = false;\n          blocksSinceSeek = 0;          \n\n          if (doOrd) {\n            state.ord = indexEnum.ord()-1;\n          }\n\n          term.copy(indexEnum.term());\n          //System.out.println(\"  seek: term=\" + term.utf8ToString());\n        } else {\n          //System.out.println(\"  skip seek\");\n          if (state.termCount == state.blockTermCount && !nextBlock()) {\n            indexIsCurrent = false;\n            return SeekStatus.END;\n          }\n        }\n\n        seekPending = false;\n\n        int common = 0;\n\n        // Scan within block.  We could do this by calling\n        // _next() and testing the resulting term, but this\n        // is wasteful.  Instead, we first confirm the\n        // target matches the common prefix of this block,\n        // and then we scan the term bytes directly from the\n        // termSuffixesreader's byte[], saving a copy into\n        // the BytesRef term per term.  Only when we return\n        // do we then copy the bytes into the term.\n\n        while(true) {\n\n          // First, see if target term matches common prefix\n          // in this block:\n          if (common < termBlockPrefix) {\n            final int cmp = (term.bytes[common]&0xFF) - (target.bytes[target.offset + common]&0xFF);\n            if (cmp < 0) {\n\n              // TODO: maybe we should store common prefix\n              // in block header?  (instead of relying on\n              // last term of previous block)\n\n              // Target's prefix is after the common block\n              // prefix, so term cannot be in this block\n              // but it could be in next block.  We\n              // must scan to end-of-block to set common\n              // prefix for next block:\n              if (state.termCount < state.blockTermCount) {\n                while(state.termCount < state.blockTermCount-1) {\n                  state.termCount++;\n                  state.ord++;\n                  termSuffixesReader.skipBytes(termSuffixesReader.readVInt());\n                }\n                final int suffix = termSuffixesReader.readVInt();\n                term.length = termBlockPrefix + suffix;\n                if (term.bytes.length < term.length) {\n                  term.grow(term.length);\n                }\n                termSuffixesReader.readBytes(term.bytes, termBlockPrefix, suffix);\n              }\n              state.ord++;\n              \n              if (!nextBlock()) {\n                indexIsCurrent = false;\n                return SeekStatus.END;\n              }\n              common = 0;\n\n            } else if (cmp > 0) {\n              // Target's prefix is before the common prefix\n              // of this block, so we position to start of\n              // block and return NOT_FOUND:\n              assert state.termCount == 0;\n\n              final int suffix = termSuffixesReader.readVInt();\n              term.length = termBlockPrefix + suffix;\n              if (term.bytes.length < term.length) {\n                term.grow(term.length);\n              }\n              termSuffixesReader.readBytes(term.bytes, termBlockPrefix, suffix);\n              return SeekStatus.NOT_FOUND;\n            } else {\n              common++;\n            }\n\n            continue;\n          }\n\n          // Test every term in this block\n          while (true) {\n            state.termCount++;\n            state.ord++;\n\n            final int suffix = termSuffixesReader.readVInt();\n            \n            // We know the prefix matches, so just compare the new suffix:\n            final int termLen = termBlockPrefix + suffix;\n            int bytePos = termSuffixesReader.getPosition();\n\n            boolean next = false;\n            final int limit = target.offset + (termLen < target.length ? termLen : target.length);\n            int targetPos = target.offset + termBlockPrefix;\n            while(targetPos < limit) {\n              final int cmp = (termSuffixes[bytePos++]&0xFF) - (target.bytes[targetPos++]&0xFF);\n              if (cmp < 0) {\n                // Current term is still before the target;\n                // keep scanning\n                next = true;\n                break;\n              } else if (cmp > 0) {\n                // Done!  Current term is after target. Stop\n                // here, fill in real term, return NOT_FOUND.\n                term.length = termBlockPrefix + suffix;\n                if (term.bytes.length < term.length) {\n                  term.grow(term.length);\n                }\n                termSuffixesReader.readBytes(term.bytes, termBlockPrefix, suffix);\n                //System.out.println(\"  NOT_FOUND\");\n                return SeekStatus.NOT_FOUND;\n              }\n            }\n\n            if (!next && target.length <= termLen) {\n              term.length = termBlockPrefix + suffix;\n              if (term.bytes.length < term.length) {\n                term.grow(term.length);\n              }\n              termSuffixesReader.readBytes(term.bytes, termBlockPrefix, suffix);\n\n              if (target.length == termLen) {\n                // Done!  Exact match.  Stop here, fill in\n                // real term, return FOUND.\n                //System.out.println(\"  FOUND\");\n\n                if (useCache) {\n                  // Store in cache\n                  decodeMetaData();\n                  //System.out.println(\"  cache! state=\" + state);\n                  termsCache.put(new FieldAndTerm(fieldTerm), (BlockTermState) state.clone());\n                }\n\n                return SeekStatus.FOUND;\n              } else {\n                //System.out.println(\"  NOT_FOUND\");\n                return SeekStatus.NOT_FOUND;\n              }\n            }\n\n            if (state.termCount == state.blockTermCount) {\n              // Must pre-fill term for next block's common prefix\n              term.length = termBlockPrefix + suffix;\n              if (term.bytes.length < term.length) {\n                term.grow(term.length);\n              }\n              termSuffixesReader.readBytes(term.bytes, termBlockPrefix, suffix);\n              break;\n            } else {\n              termSuffixesReader.skipBytes(suffix);\n            }\n          }\n\n          // The purpose of the terms dict index is to seek\n          // the enum to the closest index term before the\n          // term we are looking for.  So, we should never\n          // cross another index term (besides the first\n          // one) while we are scanning:\n\n          assert indexIsCurrent;\n\n          if (!nextBlock()) {\n            //System.out.println(\"  END\");\n            indexIsCurrent = false;\n            return SeekStatus.END;\n          }\n          common = 0;\n        }\n      }\n\n","sourceOld":"      @Override\n      public SeekStatus seek(final BytesRef target, final boolean useCache) throws IOException {\n\n        if (indexEnum == null) {\n          throw new IllegalStateException(\"terms index was not loaded\");\n        }\n        \n        //System.out.println(\"BTR.seek seg=\" + segment + \" target=\" + fieldInfo.name + \":\" + target.utf8ToString() + \" \" + target + \" current=\" + term().utf8ToString() + \" \" + term() + \" useCache=\" + useCache + \" indexIsCurrent=\" + indexIsCurrent + \" didIndexNext=\" + didIndexNext + \" seekPending=\" + seekPending + \" divisor=\" + indexReader.getDivisor() + \" this=\"  + this);\n        /*\n        if (didIndexNext) {\n          if (nextIndexTerm == null) {\n            //System.out.println(\"  nextIndexTerm=null\");\n          } else {\n            //System.out.println(\"  nextIndexTerm=\" + nextIndexTerm.utf8ToString());\n          }\n        }\n        */\n\n        // Check cache\n        if (useCache) {\n          fieldTerm.term = target;\n          // TODO: should we differentiate \"frozen\"\n          // TermState (ie one that was cloned and\n          // cached/returned by termState()) from the\n          // malleable (primary) one?\n          final TermState cachedState = termsCache.get(fieldTerm);\n          if (cachedState != null) {\n            seekPending = true;\n            //System.out.println(\"  cached!\");\n            seek(target, cachedState);\n            //System.out.println(\"  term=\" + term.utf8ToString());\n            return SeekStatus.FOUND;\n          }\n        }\n\n        boolean doSeek = true;\n\n        // See if we can avoid seeking, because target term\n        // is after current term but before next index term:\n        if (indexIsCurrent) {\n\n          final int cmp = termComp.compare(term, target);\n\n          if (cmp == 0) {\n            // Already at the requested term\n            return SeekStatus.FOUND;\n          } else if (cmp < 0) {\n\n            // Target term is after current term\n            if (!didIndexNext) {\n              if (indexEnum.next() == -1) {\n                nextIndexTerm = null;\n              } else {\n                nextIndexTerm = indexEnum.term();\n              }\n              //System.out.println(\"  now do index next() nextIndexTerm=\" + (nextIndexTerm == null ? \"null\" : nextIndexTerm.utf8ToString()));\n              didIndexNext = true;\n            }\n\n            if (nextIndexTerm == null || termComp.compare(target, nextIndexTerm) < 0) {\n              // Optimization: requested term is within the\n              // same term block we are now in; skip seeking\n              // (but do scanning):\n              doSeek = false;\n              //System.out.println(\"  skip seek: nextIndexTerm=\" + (nextIndexTerm == null ? \"null\" : nextIndexTerm.utf8ToString()));\n            }\n          }\n        }\n\n        if (doSeek) {\n          //System.out.println(\"  seek\");\n\n          // Ask terms index to find biggest indexed term (=\n          // first term in a block) that's <= our text:\n          in.seek(indexEnum.seek(target));\n          boolean result = nextBlock();\n\n          // Block must exist since, at least, the indexed term\n          // is in the block:\n          assert result;\n\n          indexIsCurrent = true;\n          didIndexNext = false;\n          blocksSinceSeek = 0;          \n\n          if (doOrd) {\n            state.ord = indexEnum.ord()-1;\n          }\n\n          // NOTE: the first _next() after an index seek is\n          // a bit wasteful, since it redundantly reads some\n          // suffix bytes into the buffer.  We could avoid storing\n          // those bytes in the primary file, but then when\n          // next()ing over an index term we'd have to\n          // special case it:\n          term.copy(indexEnum.term());\n          //System.out.println(\"  seek: term=\" + term.utf8ToString());\n        } else {\n          ////System.out.println(\"  skip seek\");\n        }\n\n        seekPending = false;\n\n        // Now scan:\n        while (_next() != null) {\n          final int cmp = termComp.compare(term, target);\n          if (cmp == 0) {\n            // Match!\n            if (useCache) {\n              // Store in cache\n              decodeMetaData();\n              termsCache.put(new FieldAndTerm(fieldTerm), (BlockTermState) state.clone());\n            }\n            //System.out.println(\"  FOUND\");\n            return SeekStatus.FOUND;\n          } else if (cmp > 0) {\n            //System.out.println(\"  NOT_FOUND term=\" + term.utf8ToString());\n            return SeekStatus.NOT_FOUND;\n          }\n          \n          // The purpose of the terms dict index is to seek\n          // the enum to the closest index term before the\n          // term we are looking for.  So, we should never\n          // cross another index term (besides the first\n          // one) while we are scanning:\n          assert indexIsCurrent;\n        }\n\n        indexIsCurrent = false;\n        //System.out.println(\"  END\");\n        return SeekStatus.END;\n      }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f1bdbf92da222965b46c0a942c3857ba56e5c638","date":1298297608,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/codecs/BlockTermsReader.FieldReader.SegmentTermsEnum#seek(BytesRef,boolean).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/codecs/BlockTermsReader.FieldReader.SegmentTermsEnum#seek(BytesRef,boolean).mjava","sourceNew":"      // TODO: we may want an alternate mode here which is\n      // \"if you are about to return NOT_FOUND I won't use\n      // the terms data from that\"; eg FuzzyTermsEnum will\n      // (usually) just immediately call seek again if we\n      // return NOT_FOUND so it's a waste for us to fill in\n      // the term that was actually NOT_FOUND\n      @Override\n      public SeekStatus seek(final BytesRef target, final boolean useCache) throws IOException {\n\n        if (indexEnum == null) {\n          throw new IllegalStateException(\"terms index was not loaded\");\n        }\n   \n        /*\n        System.out.println(\"BTR.seek seg=\" + segment + \" target=\" + fieldInfo.name + \":\" + target.utf8ToString() + \" \" + target + \" current=\" + term().utf8ToString() + \" \" + term() + \" useCache=\" + useCache + \" indexIsCurrent=\" + indexIsCurrent + \" didIndexNext=\" + didIndexNext + \" seekPending=\" + seekPending + \" divisor=\" + indexReader.getDivisor() + \" this=\"  + this);\n        if (didIndexNext) {\n          if (nextIndexTerm == null) {\n            System.out.println(\"  nextIndexTerm=null\");\n          } else {\n            System.out.println(\"  nextIndexTerm=\" + nextIndexTerm.utf8ToString());\n          }\n        }\n        */\n\n        // Check cache\n        if (useCache) {\n          fieldTerm.term = target;\n          // TODO: should we differentiate \"frozen\"\n          // TermState (ie one that was cloned and\n          // cached/returned by termState()) from the\n          // malleable (primary) one?\n          final TermState cachedState = termsCache.get(fieldTerm);\n          if (cachedState != null) {\n            seekPending = true;\n            //System.out.println(\"  cached!\");\n            seek(target, cachedState);\n            //System.out.println(\"  term=\" + term.utf8ToString());\n            return SeekStatus.FOUND;\n          }\n        }\n\n        boolean doSeek = true;\n\n        // See if we can avoid seeking, because target term\n        // is after current term but before next index term:\n        if (indexIsCurrent) {\n\n          final int cmp = BytesRef.getUTF8SortedAsUnicodeComparator().compare(term, target);\n\n          if (cmp == 0) {\n            // Already at the requested term\n            return SeekStatus.FOUND;\n          } else if (cmp < 0) {\n\n            // Target term is after current term\n            if (!didIndexNext) {\n              if (indexEnum.next() == -1) {\n                nextIndexTerm = null;\n              } else {\n                nextIndexTerm = indexEnum.term();\n              }\n              //System.out.println(\"  now do index next() nextIndexTerm=\" + (nextIndexTerm == null ? \"null\" : nextIndexTerm.utf8ToString()));\n              didIndexNext = true;\n            }\n\n            if (nextIndexTerm == null || BytesRef.getUTF8SortedAsUnicodeComparator().compare(target, nextIndexTerm) < 0) {\n              // Optimization: requested term is within the\n              // same term block we are now in; skip seeking\n              // (but do scanning):\n              doSeek = false;\n              //System.out.println(\"  skip seek: nextIndexTerm=\" + (nextIndexTerm == null ? \"null\" : nextIndexTerm.utf8ToString()));\n            }\n          }\n        }\n\n        if (doSeek) {\n          //System.out.println(\"  seek\");\n\n          // Ask terms index to find biggest indexed term (=\n          // first term in a block) that's <= our text:\n          in.seek(indexEnum.seek(target));\n          boolean result = nextBlock();\n\n          // Block must exist since, at least, the indexed term\n          // is in the block:\n          assert result;\n\n          indexIsCurrent = true;\n          didIndexNext = false;\n          blocksSinceSeek = 0;          \n\n          if (doOrd) {\n            state.ord = indexEnum.ord()-1;\n          }\n\n          term.copy(indexEnum.term());\n          //System.out.println(\"  seek: term=\" + term.utf8ToString());\n        } else {\n          //System.out.println(\"  skip seek\");\n          if (state.termCount == state.blockTermCount && !nextBlock()) {\n            indexIsCurrent = false;\n            return SeekStatus.END;\n          }\n        }\n\n        seekPending = false;\n\n        int common = 0;\n\n        // Scan within block.  We could do this by calling\n        // _next() and testing the resulting term, but this\n        // is wasteful.  Instead, we first confirm the\n        // target matches the common prefix of this block,\n        // and then we scan the term bytes directly from the\n        // termSuffixesreader's byte[], saving a copy into\n        // the BytesRef term per term.  Only when we return\n        // do we then copy the bytes into the term.\n\n        while(true) {\n\n          // First, see if target term matches common prefix\n          // in this block:\n          if (common < termBlockPrefix) {\n            final int cmp = (term.bytes[common]&0xFF) - (target.bytes[target.offset + common]&0xFF);\n            if (cmp < 0) {\n\n              // TODO: maybe we should store common prefix\n              // in block header?  (instead of relying on\n              // last term of previous block)\n\n              // Target's prefix is after the common block\n              // prefix, so term cannot be in this block\n              // but it could be in next block.  We\n              // must scan to end-of-block to set common\n              // prefix for next block:\n              if (state.termCount < state.blockTermCount) {\n                while(state.termCount < state.blockTermCount-1) {\n                  state.termCount++;\n                  state.ord++;\n                  termSuffixesReader.skipBytes(termSuffixesReader.readVInt());\n                }\n                final int suffix = termSuffixesReader.readVInt();\n                term.length = termBlockPrefix + suffix;\n                if (term.bytes.length < term.length) {\n                  term.grow(term.length);\n                }\n                termSuffixesReader.readBytes(term.bytes, termBlockPrefix, suffix);\n              }\n              state.ord++;\n              \n              if (!nextBlock()) {\n                indexIsCurrent = false;\n                return SeekStatus.END;\n              }\n              common = 0;\n\n            } else if (cmp > 0) {\n              // Target's prefix is before the common prefix\n              // of this block, so we position to start of\n              // block and return NOT_FOUND:\n              assert state.termCount == 0;\n\n              final int suffix = termSuffixesReader.readVInt();\n              term.length = termBlockPrefix + suffix;\n              if (term.bytes.length < term.length) {\n                term.grow(term.length);\n              }\n              termSuffixesReader.readBytes(term.bytes, termBlockPrefix, suffix);\n              return SeekStatus.NOT_FOUND;\n            } else {\n              common++;\n            }\n\n            continue;\n          }\n\n          // Test every term in this block\n          while (true) {\n            state.termCount++;\n            state.ord++;\n\n            final int suffix = termSuffixesReader.readVInt();\n            \n            // We know the prefix matches, so just compare the new suffix:\n            final int termLen = termBlockPrefix + suffix;\n            int bytePos = termSuffixesReader.getPosition();\n\n            boolean next = false;\n            final int limit = target.offset + (termLen < target.length ? termLen : target.length);\n            int targetPos = target.offset + termBlockPrefix;\n            while(targetPos < limit) {\n              final int cmp = (termSuffixes[bytePos++]&0xFF) - (target.bytes[targetPos++]&0xFF);\n              if (cmp < 0) {\n                // Current term is still before the target;\n                // keep scanning\n                next = true;\n                break;\n              } else if (cmp > 0) {\n                // Done!  Current term is after target. Stop\n                // here, fill in real term, return NOT_FOUND.\n                term.length = termBlockPrefix + suffix;\n                if (term.bytes.length < term.length) {\n                  term.grow(term.length);\n                }\n                termSuffixesReader.readBytes(term.bytes, termBlockPrefix, suffix);\n                //System.out.println(\"  NOT_FOUND\");\n                return SeekStatus.NOT_FOUND;\n              }\n            }\n\n            if (!next && target.length <= termLen) {\n              term.length = termBlockPrefix + suffix;\n              if (term.bytes.length < term.length) {\n                term.grow(term.length);\n              }\n              termSuffixesReader.readBytes(term.bytes, termBlockPrefix, suffix);\n\n              if (target.length == termLen) {\n                // Done!  Exact match.  Stop here, fill in\n                // real term, return FOUND.\n                //System.out.println(\"  FOUND\");\n\n                if (useCache) {\n                  // Store in cache\n                  decodeMetaData();\n                  //System.out.println(\"  cache! state=\" + state);\n                  termsCache.put(new FieldAndTerm(fieldTerm), (BlockTermState) state.clone());\n                }\n\n                return SeekStatus.FOUND;\n              } else {\n                //System.out.println(\"  NOT_FOUND\");\n                return SeekStatus.NOT_FOUND;\n              }\n            }\n\n            if (state.termCount == state.blockTermCount) {\n              // Must pre-fill term for next block's common prefix\n              term.length = termBlockPrefix + suffix;\n              if (term.bytes.length < term.length) {\n                term.grow(term.length);\n              }\n              termSuffixesReader.readBytes(term.bytes, termBlockPrefix, suffix);\n              break;\n            } else {\n              termSuffixesReader.skipBytes(suffix);\n            }\n          }\n\n          // The purpose of the terms dict index is to seek\n          // the enum to the closest index term before the\n          // term we are looking for.  So, we should never\n          // cross another index term (besides the first\n          // one) while we are scanning:\n\n          assert indexIsCurrent;\n\n          if (!nextBlock()) {\n            //System.out.println(\"  END\");\n            indexIsCurrent = false;\n            return SeekStatus.END;\n          }\n          common = 0;\n        }\n      }\n\n","sourceOld":"      @Override\n      public SeekStatus seek(final BytesRef target, final boolean useCache) throws IOException {\n\n        if (indexEnum == null) {\n          throw new IllegalStateException(\"terms index was not loaded\");\n        }\n        \n        //System.out.println(\"BTR.seek seg=\" + segment + \" target=\" + fieldInfo.name + \":\" + target.utf8ToString() + \" \" + target + \" current=\" + term().utf8ToString() + \" \" + term() + \" useCache=\" + useCache + \" indexIsCurrent=\" + indexIsCurrent + \" didIndexNext=\" + didIndexNext + \" seekPending=\" + seekPending + \" divisor=\" + indexReader.getDivisor() + \" this=\"  + this);\n        /*\n        if (didIndexNext) {\n          if (nextIndexTerm == null) {\n            //System.out.println(\"  nextIndexTerm=null\");\n          } else {\n            //System.out.println(\"  nextIndexTerm=\" + nextIndexTerm.utf8ToString());\n          }\n        }\n        */\n\n        // Check cache\n        if (useCache) {\n          fieldTerm.term = target;\n          // TODO: should we differentiate \"frozen\"\n          // TermState (ie one that was cloned and\n          // cached/returned by termState()) from the\n          // malleable (primary) one?\n          final TermState cachedState = termsCache.get(fieldTerm);\n          if (cachedState != null) {\n            seekPending = true;\n            //System.out.println(\"  cached!\");\n            seek(target, cachedState);\n            //System.out.println(\"  term=\" + term.utf8ToString());\n            return SeekStatus.FOUND;\n          }\n        }\n\n        boolean doSeek = true;\n\n        // See if we can avoid seeking, because target term\n        // is after current term but before next index term:\n        if (indexIsCurrent) {\n\n          final int cmp = termComp.compare(term, target);\n\n          if (cmp == 0) {\n            // Already at the requested term\n            return SeekStatus.FOUND;\n          } else if (cmp < 0) {\n\n            // Target term is after current term\n            if (!didIndexNext) {\n              if (indexEnum.next() == -1) {\n                nextIndexTerm = null;\n              } else {\n                nextIndexTerm = indexEnum.term();\n              }\n              //System.out.println(\"  now do index next() nextIndexTerm=\" + (nextIndexTerm == null ? \"null\" : nextIndexTerm.utf8ToString()));\n              didIndexNext = true;\n            }\n\n            if (nextIndexTerm == null || termComp.compare(target, nextIndexTerm) < 0) {\n              // Optimization: requested term is within the\n              // same term block we are now in; skip seeking\n              // (but do scanning):\n              doSeek = false;\n              //System.out.println(\"  skip seek: nextIndexTerm=\" + (nextIndexTerm == null ? \"null\" : nextIndexTerm.utf8ToString()));\n            }\n          }\n        }\n\n        if (doSeek) {\n          //System.out.println(\"  seek\");\n\n          // Ask terms index to find biggest indexed term (=\n          // first term in a block) that's <= our text:\n          in.seek(indexEnum.seek(target));\n          boolean result = nextBlock();\n\n          // Block must exist since, at least, the indexed term\n          // is in the block:\n          assert result;\n\n          indexIsCurrent = true;\n          didIndexNext = false;\n          blocksSinceSeek = 0;          \n\n          if (doOrd) {\n            state.ord = indexEnum.ord()-1;\n          }\n\n          // NOTE: the first _next() after an index seek is\n          // a bit wasteful, since it redundantly reads some\n          // suffix bytes into the buffer.  We could avoid storing\n          // those bytes in the primary file, but then when\n          // next()ing over an index term we'd have to\n          // special case it:\n          term.copy(indexEnum.term());\n          //System.out.println(\"  seek: term=\" + term.utf8ToString());\n        } else {\n          ////System.out.println(\"  skip seek\");\n        }\n\n        seekPending = false;\n\n        // Now scan:\n        while (_next() != null) {\n          final int cmp = termComp.compare(term, target);\n          if (cmp == 0) {\n            // Match!\n            if (useCache) {\n              // Store in cache\n              decodeMetaData();\n              termsCache.put(new FieldAndTerm(fieldTerm), (BlockTermState) state.clone());\n            }\n            //System.out.println(\"  FOUND\");\n            return SeekStatus.FOUND;\n          } else if (cmp > 0) {\n            //System.out.println(\"  NOT_FOUND term=\" + term.utf8ToString());\n            return SeekStatus.NOT_FOUND;\n          }\n          \n          // The purpose of the terms dict index is to seek\n          // the enum to the closest index term before the\n          // term we are looking for.  So, we should never\n          // cross another index term (besides the first\n          // one) while we are scanning:\n          assert indexIsCurrent;\n        }\n\n        indexIsCurrent = false;\n        //System.out.println(\"  END\");\n        return SeekStatus.END;\n      }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"bde51b089eb7f86171eb3406e38a274743f9b7ac","date":1298336439,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/codecs/BlockTermsReader.FieldReader.SegmentTermsEnum#seek(BytesRef,boolean).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/codecs/BlockTermsReader.FieldReader.SegmentTermsEnum#seek(BytesRef,boolean).mjava","sourceNew":"      // TODO: we may want an alternate mode here which is\n      // \"if you are about to return NOT_FOUND I won't use\n      // the terms data from that\"; eg FuzzyTermsEnum will\n      // (usually) just immediately call seek again if we\n      // return NOT_FOUND so it's a waste for us to fill in\n      // the term that was actually NOT_FOUND\n      @Override\n      public SeekStatus seek(final BytesRef target, final boolean useCache) throws IOException {\n\n        if (indexEnum == null) {\n          throw new IllegalStateException(\"terms index was not loaded\");\n        }\n   \n        /*\n        System.out.println(\"BTR.seek seg=\" + segment + \" target=\" + fieldInfo.name + \":\" + target.utf8ToString() + \" \" + target + \" current=\" + term().utf8ToString() + \" \" + term() + \" useCache=\" + useCache + \" indexIsCurrent=\" + indexIsCurrent + \" didIndexNext=\" + didIndexNext + \" seekPending=\" + seekPending + \" divisor=\" + indexReader.getDivisor() + \" this=\"  + this);\n        if (didIndexNext) {\n          if (nextIndexTerm == null) {\n            System.out.println(\"  nextIndexTerm=null\");\n          } else {\n            System.out.println(\"  nextIndexTerm=\" + nextIndexTerm.utf8ToString());\n          }\n        }\n        */\n\n        // Check cache\n        if (useCache) {\n          fieldTerm.term = target;\n          // TODO: should we differentiate \"frozen\"\n          // TermState (ie one that was cloned and\n          // cached/returned by termState()) from the\n          // malleable (primary) one?\n          final TermState cachedState = termsCache.get(fieldTerm);\n          if (cachedState != null) {\n            seekPending = true;\n            //System.out.println(\"  cached!\");\n            seek(target, cachedState);\n            //System.out.println(\"  term=\" + term.utf8ToString());\n            return SeekStatus.FOUND;\n          }\n        }\n\n        boolean doSeek = true;\n\n        // See if we can avoid seeking, because target term\n        // is after current term but before next index term:\n        if (indexIsCurrent) {\n\n          final int cmp = BytesRef.getUTF8SortedAsUnicodeComparator().compare(term, target);\n\n          if (cmp == 0) {\n            // Already at the requested term\n            return SeekStatus.FOUND;\n          } else if (cmp < 0) {\n\n            // Target term is after current term\n            if (!didIndexNext) {\n              if (indexEnum.next() == -1) {\n                nextIndexTerm = null;\n              } else {\n                nextIndexTerm = indexEnum.term();\n              }\n              //System.out.println(\"  now do index next() nextIndexTerm=\" + (nextIndexTerm == null ? \"null\" : nextIndexTerm.utf8ToString()));\n              didIndexNext = true;\n            }\n\n            if (nextIndexTerm == null || BytesRef.getUTF8SortedAsUnicodeComparator().compare(target, nextIndexTerm) < 0) {\n              // Optimization: requested term is within the\n              // same term block we are now in; skip seeking\n              // (but do scanning):\n              doSeek = false;\n              //System.out.println(\"  skip seek: nextIndexTerm=\" + (nextIndexTerm == null ? \"null\" : nextIndexTerm.utf8ToString()));\n            }\n          }\n        }\n\n        if (doSeek) {\n          //System.out.println(\"  seek\");\n\n          // Ask terms index to find biggest indexed term (=\n          // first term in a block) that's <= our text:\n          in.seek(indexEnum.seek(target));\n          boolean result = nextBlock();\n\n          // Block must exist since, at least, the indexed term\n          // is in the block:\n          assert result;\n\n          indexIsCurrent = true;\n          didIndexNext = false;\n          blocksSinceSeek = 0;          \n\n          if (doOrd) {\n            state.ord = indexEnum.ord()-1;\n          }\n\n          term.copy(indexEnum.term());\n          //System.out.println(\"  seek: term=\" + term.utf8ToString());\n        } else {\n          //System.out.println(\"  skip seek\");\n          if (state.termCount == state.blockTermCount && !nextBlock()) {\n            indexIsCurrent = false;\n            return SeekStatus.END;\n          }\n        }\n\n        seekPending = false;\n\n        int common = 0;\n\n        // Scan within block.  We could do this by calling\n        // _next() and testing the resulting term, but this\n        // is wasteful.  Instead, we first confirm the\n        // target matches the common prefix of this block,\n        // and then we scan the term bytes directly from the\n        // termSuffixesreader's byte[], saving a copy into\n        // the BytesRef term per term.  Only when we return\n        // do we then copy the bytes into the term.\n\n        while(true) {\n\n          // First, see if target term matches common prefix\n          // in this block:\n          if (common < termBlockPrefix) {\n            final int cmp = (term.bytes[common]&0xFF) - (target.bytes[target.offset + common]&0xFF);\n            if (cmp < 0) {\n\n              // TODO: maybe we should store common prefix\n              // in block header?  (instead of relying on\n              // last term of previous block)\n\n              // Target's prefix is after the common block\n              // prefix, so term cannot be in this block\n              // but it could be in next block.  We\n              // must scan to end-of-block to set common\n              // prefix for next block:\n              if (state.termCount < state.blockTermCount) {\n                while(state.termCount < state.blockTermCount-1) {\n                  state.termCount++;\n                  state.ord++;\n                  termSuffixesReader.skipBytes(termSuffixesReader.readVInt());\n                }\n                final int suffix = termSuffixesReader.readVInt();\n                term.length = termBlockPrefix + suffix;\n                if (term.bytes.length < term.length) {\n                  term.grow(term.length);\n                }\n                termSuffixesReader.readBytes(term.bytes, termBlockPrefix, suffix);\n              }\n              state.ord++;\n              \n              if (!nextBlock()) {\n                indexIsCurrent = false;\n                return SeekStatus.END;\n              }\n              common = 0;\n\n            } else if (cmp > 0) {\n              // Target's prefix is before the common prefix\n              // of this block, so we position to start of\n              // block and return NOT_FOUND:\n              assert state.termCount == 0;\n\n              final int suffix = termSuffixesReader.readVInt();\n              term.length = termBlockPrefix + suffix;\n              if (term.bytes.length < term.length) {\n                term.grow(term.length);\n              }\n              termSuffixesReader.readBytes(term.bytes, termBlockPrefix, suffix);\n              return SeekStatus.NOT_FOUND;\n            } else {\n              common++;\n            }\n\n            continue;\n          }\n\n          // Test every term in this block\n          while (true) {\n            state.termCount++;\n            state.ord++;\n\n            final int suffix = termSuffixesReader.readVInt();\n            \n            // We know the prefix matches, so just compare the new suffix:\n            final int termLen = termBlockPrefix + suffix;\n            int bytePos = termSuffixesReader.getPosition();\n\n            boolean next = false;\n            final int limit = target.offset + (termLen < target.length ? termLen : target.length);\n            int targetPos = target.offset + termBlockPrefix;\n            while(targetPos < limit) {\n              final int cmp = (termSuffixes[bytePos++]&0xFF) - (target.bytes[targetPos++]&0xFF);\n              if (cmp < 0) {\n                // Current term is still before the target;\n                // keep scanning\n                next = true;\n                break;\n              } else if (cmp > 0) {\n                // Done!  Current term is after target. Stop\n                // here, fill in real term, return NOT_FOUND.\n                term.length = termBlockPrefix + suffix;\n                if (term.bytes.length < term.length) {\n                  term.grow(term.length);\n                }\n                termSuffixesReader.readBytes(term.bytes, termBlockPrefix, suffix);\n                //System.out.println(\"  NOT_FOUND\");\n                return SeekStatus.NOT_FOUND;\n              }\n            }\n\n            if (!next && target.length <= termLen) {\n              term.length = termBlockPrefix + suffix;\n              if (term.bytes.length < term.length) {\n                term.grow(term.length);\n              }\n              termSuffixesReader.readBytes(term.bytes, termBlockPrefix, suffix);\n\n              if (target.length == termLen) {\n                // Done!  Exact match.  Stop here, fill in\n                // real term, return FOUND.\n                //System.out.println(\"  FOUND\");\n\n                if (useCache) {\n                  // Store in cache\n                  decodeMetaData();\n                  //System.out.println(\"  cache! state=\" + state);\n                  termsCache.put(new FieldAndTerm(fieldTerm), (BlockTermState) state.clone());\n                }\n\n                return SeekStatus.FOUND;\n              } else {\n                //System.out.println(\"  NOT_FOUND\");\n                return SeekStatus.NOT_FOUND;\n              }\n            }\n\n            if (state.termCount == state.blockTermCount) {\n              // Must pre-fill term for next block's common prefix\n              term.length = termBlockPrefix + suffix;\n              if (term.bytes.length < term.length) {\n                term.grow(term.length);\n              }\n              termSuffixesReader.readBytes(term.bytes, termBlockPrefix, suffix);\n              break;\n            } else {\n              termSuffixesReader.skipBytes(suffix);\n            }\n          }\n\n          // The purpose of the terms dict index is to seek\n          // the enum to the closest index term before the\n          // term we are looking for.  So, we should never\n          // cross another index term (besides the first\n          // one) while we are scanning:\n\n          assert indexIsCurrent;\n\n          if (!nextBlock()) {\n            //System.out.println(\"  END\");\n            indexIsCurrent = false;\n            return SeekStatus.END;\n          }\n          common = 0;\n        }\n      }\n\n","sourceOld":"      @Override\n      public SeekStatus seek(final BytesRef target, final boolean useCache) throws IOException {\n\n        if (indexEnum == null) {\n          throw new IllegalStateException(\"terms index was not loaded\");\n        }\n        \n        //System.out.println(\"BTR.seek seg=\" + segment + \" target=\" + fieldInfo.name + \":\" + target.utf8ToString() + \" \" + target + \" current=\" + term().utf8ToString() + \" \" + term() + \" useCache=\" + useCache + \" indexIsCurrent=\" + indexIsCurrent + \" didIndexNext=\" + didIndexNext + \" seekPending=\" + seekPending + \" divisor=\" + indexReader.getDivisor() + \" this=\"  + this);\n        /*\n        if (didIndexNext) {\n          if (nextIndexTerm == null) {\n            //System.out.println(\"  nextIndexTerm=null\");\n          } else {\n            //System.out.println(\"  nextIndexTerm=\" + nextIndexTerm.utf8ToString());\n          }\n        }\n        */\n\n        // Check cache\n        if (useCache) {\n          fieldTerm.term = target;\n          // TODO: should we differentiate \"frozen\"\n          // TermState (ie one that was cloned and\n          // cached/returned by termState()) from the\n          // malleable (primary) one?\n          final TermState cachedState = termsCache.get(fieldTerm);\n          if (cachedState != null) {\n            seekPending = true;\n            //System.out.println(\"  cached!\");\n            seek(target, cachedState);\n            //System.out.println(\"  term=\" + term.utf8ToString());\n            return SeekStatus.FOUND;\n          }\n        }\n\n        boolean doSeek = true;\n\n        // See if we can avoid seeking, because target term\n        // is after current term but before next index term:\n        if (indexIsCurrent) {\n\n          final int cmp = termComp.compare(term, target);\n\n          if (cmp == 0) {\n            // Already at the requested term\n            return SeekStatus.FOUND;\n          } else if (cmp < 0) {\n\n            // Target term is after current term\n            if (!didIndexNext) {\n              if (indexEnum.next() == -1) {\n                nextIndexTerm = null;\n              } else {\n                nextIndexTerm = indexEnum.term();\n              }\n              //System.out.println(\"  now do index next() nextIndexTerm=\" + (nextIndexTerm == null ? \"null\" : nextIndexTerm.utf8ToString()));\n              didIndexNext = true;\n            }\n\n            if (nextIndexTerm == null || termComp.compare(target, nextIndexTerm) < 0) {\n              // Optimization: requested term is within the\n              // same term block we are now in; skip seeking\n              // (but do scanning):\n              doSeek = false;\n              //System.out.println(\"  skip seek: nextIndexTerm=\" + (nextIndexTerm == null ? \"null\" : nextIndexTerm.utf8ToString()));\n            }\n          }\n        }\n\n        if (doSeek) {\n          //System.out.println(\"  seek\");\n\n          // Ask terms index to find biggest indexed term (=\n          // first term in a block) that's <= our text:\n          in.seek(indexEnum.seek(target));\n          boolean result = nextBlock();\n\n          // Block must exist since, at least, the indexed term\n          // is in the block:\n          assert result;\n\n          indexIsCurrent = true;\n          didIndexNext = false;\n          blocksSinceSeek = 0;          \n\n          if (doOrd) {\n            state.ord = indexEnum.ord()-1;\n          }\n\n          // NOTE: the first _next() after an index seek is\n          // a bit wasteful, since it redundantly reads some\n          // suffix bytes into the buffer.  We could avoid storing\n          // those bytes in the primary file, but then when\n          // next()ing over an index term we'd have to\n          // special case it:\n          term.copy(indexEnum.term());\n          //System.out.println(\"  seek: term=\" + term.utf8ToString());\n        } else {\n          ////System.out.println(\"  skip seek\");\n        }\n\n        seekPending = false;\n\n        // Now scan:\n        while (_next() != null) {\n          final int cmp = termComp.compare(term, target);\n          if (cmp == 0) {\n            // Match!\n            if (useCache) {\n              // Store in cache\n              decodeMetaData();\n              termsCache.put(new FieldAndTerm(fieldTerm), (BlockTermState) state.clone());\n            }\n            //System.out.println(\"  FOUND\");\n            return SeekStatus.FOUND;\n          } else if (cmp > 0) {\n            //System.out.println(\"  NOT_FOUND term=\" + term.utf8ToString());\n            return SeekStatus.NOT_FOUND;\n          }\n          \n          // The purpose of the terms dict index is to seek\n          // the enum to the closest index term before the\n          // term we are looking for.  So, we should never\n          // cross another index term (besides the first\n          // one) while we are scanning:\n          assert indexIsCurrent;\n        }\n\n        indexIsCurrent = false;\n        //System.out.println(\"  END\");\n        return SeekStatus.END;\n      }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fd9cc9d77712aba3662f24632df7539ab75e3667","date":1309095238,"type":5,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/codecs/BlockTermsReader.FieldReader.SegmentTermsEnum#seekCeil(BytesRef,boolean).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/codecs/BlockTermsReader.FieldReader.SegmentTermsEnum#seek(BytesRef,boolean).mjava","sourceNew":"      // TODO: we may want an alternate mode here which is\n      // \"if you are about to return NOT_FOUND I won't use\n      // the terms data from that\"; eg FuzzyTermsEnum will\n      // (usually) just immediately call seek again if we\n      // return NOT_FOUND so it's a waste for us to fill in\n      // the term that was actually NOT_FOUND\n      @Override\n      public SeekStatus seekCeil(final BytesRef target, final boolean useCache) throws IOException {\n\n        if (indexEnum == null) {\n          throw new IllegalStateException(\"terms index was not loaded\");\n        }\n   \n        /*\n        System.out.println(\"BTR.seek seg=\" + segment + \" target=\" + fieldInfo.name + \":\" + target.utf8ToString() + \" \" + target + \" current=\" + term().utf8ToString() + \" \" + term() + \" useCache=\" + useCache + \" indexIsCurrent=\" + indexIsCurrent + \" didIndexNext=\" + didIndexNext + \" seekPending=\" + seekPending + \" divisor=\" + indexReader.getDivisor() + \" this=\"  + this);\n        if (didIndexNext) {\n          if (nextIndexTerm == null) {\n            System.out.println(\"  nextIndexTerm=null\");\n          } else {\n            System.out.println(\"  nextIndexTerm=\" + nextIndexTerm.utf8ToString());\n          }\n        }\n        */\n\n        // Check cache\n        if (useCache) {\n          fieldTerm.term = target;\n          // TODO: should we differentiate \"frozen\"\n          // TermState (ie one that was cloned and\n          // cached/returned by termState()) from the\n          // malleable (primary) one?\n          final TermState cachedState = termsCache.get(fieldTerm);\n          if (cachedState != null) {\n            seekPending = true;\n            //System.out.println(\"  cached!\");\n            seekExact(target, cachedState);\n            //System.out.println(\"  term=\" + term.utf8ToString());\n            return SeekStatus.FOUND;\n          }\n        }\n\n        boolean doSeek = true;\n\n        // See if we can avoid seeking, because target term\n        // is after current term but before next index term:\n        if (indexIsCurrent) {\n\n          final int cmp = BytesRef.getUTF8SortedAsUnicodeComparator().compare(term, target);\n\n          if (cmp == 0) {\n            // Already at the requested term\n            return SeekStatus.FOUND;\n          } else if (cmp < 0) {\n\n            // Target term is after current term\n            if (!didIndexNext) {\n              if (indexEnum.next() == -1) {\n                nextIndexTerm = null;\n              } else {\n                nextIndexTerm = indexEnum.term();\n              }\n              //System.out.println(\"  now do index next() nextIndexTerm=\" + (nextIndexTerm == null ? \"null\" : nextIndexTerm.utf8ToString()));\n              didIndexNext = true;\n            }\n\n            if (nextIndexTerm == null || BytesRef.getUTF8SortedAsUnicodeComparator().compare(target, nextIndexTerm) < 0) {\n              // Optimization: requested term is within the\n              // same term block we are now in; skip seeking\n              // (but do scanning):\n              doSeek = false;\n              //System.out.println(\"  skip seek: nextIndexTerm=\" + (nextIndexTerm == null ? \"null\" : nextIndexTerm.utf8ToString()));\n            }\n          }\n        }\n\n        if (doSeek) {\n          //System.out.println(\"  seek\");\n\n          // Ask terms index to find biggest indexed term (=\n          // first term in a block) that's <= our text:\n          in.seek(indexEnum.seek(target));\n          boolean result = nextBlock();\n\n          // Block must exist since, at least, the indexed term\n          // is in the block:\n          assert result;\n\n          indexIsCurrent = true;\n          didIndexNext = false;\n          blocksSinceSeek = 0;          \n\n          if (doOrd) {\n            state.ord = indexEnum.ord()-1;\n          }\n\n          term.copy(indexEnum.term());\n          //System.out.println(\"  seek: term=\" + term.utf8ToString());\n        } else {\n          //System.out.println(\"  skip seek\");\n          if (state.termCount == state.blockTermCount && !nextBlock()) {\n            indexIsCurrent = false;\n            return SeekStatus.END;\n          }\n        }\n\n        seekPending = false;\n\n        int common = 0;\n\n        // Scan within block.  We could do this by calling\n        // _next() and testing the resulting term, but this\n        // is wasteful.  Instead, we first confirm the\n        // target matches the common prefix of this block,\n        // and then we scan the term bytes directly from the\n        // termSuffixesreader's byte[], saving a copy into\n        // the BytesRef term per term.  Only when we return\n        // do we then copy the bytes into the term.\n\n        while(true) {\n\n          // First, see if target term matches common prefix\n          // in this block:\n          if (common < termBlockPrefix) {\n            final int cmp = (term.bytes[common]&0xFF) - (target.bytes[target.offset + common]&0xFF);\n            if (cmp < 0) {\n\n              // TODO: maybe we should store common prefix\n              // in block header?  (instead of relying on\n              // last term of previous block)\n\n              // Target's prefix is after the common block\n              // prefix, so term cannot be in this block\n              // but it could be in next block.  We\n              // must scan to end-of-block to set common\n              // prefix for next block:\n              if (state.termCount < state.blockTermCount) {\n                while(state.termCount < state.blockTermCount-1) {\n                  state.termCount++;\n                  state.ord++;\n                  termSuffixesReader.skipBytes(termSuffixesReader.readVInt());\n                }\n                final int suffix = termSuffixesReader.readVInt();\n                term.length = termBlockPrefix + suffix;\n                if (term.bytes.length < term.length) {\n                  term.grow(term.length);\n                }\n                termSuffixesReader.readBytes(term.bytes, termBlockPrefix, suffix);\n              }\n              state.ord++;\n              \n              if (!nextBlock()) {\n                indexIsCurrent = false;\n                return SeekStatus.END;\n              }\n              common = 0;\n\n            } else if (cmp > 0) {\n              // Target's prefix is before the common prefix\n              // of this block, so we position to start of\n              // block and return NOT_FOUND:\n              assert state.termCount == 0;\n\n              final int suffix = termSuffixesReader.readVInt();\n              term.length = termBlockPrefix + suffix;\n              if (term.bytes.length < term.length) {\n                term.grow(term.length);\n              }\n              termSuffixesReader.readBytes(term.bytes, termBlockPrefix, suffix);\n              return SeekStatus.NOT_FOUND;\n            } else {\n              common++;\n            }\n\n            continue;\n          }\n\n          // Test every term in this block\n          while (true) {\n            state.termCount++;\n            state.ord++;\n\n            final int suffix = termSuffixesReader.readVInt();\n            \n            // We know the prefix matches, so just compare the new suffix:\n            final int termLen = termBlockPrefix + suffix;\n            int bytePos = termSuffixesReader.getPosition();\n\n            boolean next = false;\n            final int limit = target.offset + (termLen < target.length ? termLen : target.length);\n            int targetPos = target.offset + termBlockPrefix;\n            while(targetPos < limit) {\n              final int cmp = (termSuffixes[bytePos++]&0xFF) - (target.bytes[targetPos++]&0xFF);\n              if (cmp < 0) {\n                // Current term is still before the target;\n                // keep scanning\n                next = true;\n                break;\n              } else if (cmp > 0) {\n                // Done!  Current term is after target. Stop\n                // here, fill in real term, return NOT_FOUND.\n                term.length = termBlockPrefix + suffix;\n                if (term.bytes.length < term.length) {\n                  term.grow(term.length);\n                }\n                termSuffixesReader.readBytes(term.bytes, termBlockPrefix, suffix);\n                //System.out.println(\"  NOT_FOUND\");\n                return SeekStatus.NOT_FOUND;\n              }\n            }\n\n            if (!next && target.length <= termLen) {\n              term.length = termBlockPrefix + suffix;\n              if (term.bytes.length < term.length) {\n                term.grow(term.length);\n              }\n              termSuffixesReader.readBytes(term.bytes, termBlockPrefix, suffix);\n\n              if (target.length == termLen) {\n                // Done!  Exact match.  Stop here, fill in\n                // real term, return FOUND.\n                //System.out.println(\"  FOUND\");\n\n                if (useCache) {\n                  // Store in cache\n                  decodeMetaData();\n                  //System.out.println(\"  cache! state=\" + state);\n                  termsCache.put(new FieldAndTerm(fieldTerm), (BlockTermState) state.clone());\n                }\n\n                return SeekStatus.FOUND;\n              } else {\n                //System.out.println(\"  NOT_FOUND\");\n                return SeekStatus.NOT_FOUND;\n              }\n            }\n\n            if (state.termCount == state.blockTermCount) {\n              // Must pre-fill term for next block's common prefix\n              term.length = termBlockPrefix + suffix;\n              if (term.bytes.length < term.length) {\n                term.grow(term.length);\n              }\n              termSuffixesReader.readBytes(term.bytes, termBlockPrefix, suffix);\n              break;\n            } else {\n              termSuffixesReader.skipBytes(suffix);\n            }\n          }\n\n          // The purpose of the terms dict index is to seek\n          // the enum to the closest index term before the\n          // term we are looking for.  So, we should never\n          // cross another index term (besides the first\n          // one) while we are scanning:\n\n          assert indexIsCurrent;\n\n          if (!nextBlock()) {\n            //System.out.println(\"  END\");\n            indexIsCurrent = false;\n            return SeekStatus.END;\n          }\n          common = 0;\n        }\n      }\n\n","sourceOld":"      // TODO: we may want an alternate mode here which is\n      // \"if you are about to return NOT_FOUND I won't use\n      // the terms data from that\"; eg FuzzyTermsEnum will\n      // (usually) just immediately call seek again if we\n      // return NOT_FOUND so it's a waste for us to fill in\n      // the term that was actually NOT_FOUND\n      @Override\n      public SeekStatus seek(final BytesRef target, final boolean useCache) throws IOException {\n\n        if (indexEnum == null) {\n          throw new IllegalStateException(\"terms index was not loaded\");\n        }\n   \n        /*\n        System.out.println(\"BTR.seek seg=\" + segment + \" target=\" + fieldInfo.name + \":\" + target.utf8ToString() + \" \" + target + \" current=\" + term().utf8ToString() + \" \" + term() + \" useCache=\" + useCache + \" indexIsCurrent=\" + indexIsCurrent + \" didIndexNext=\" + didIndexNext + \" seekPending=\" + seekPending + \" divisor=\" + indexReader.getDivisor() + \" this=\"  + this);\n        if (didIndexNext) {\n          if (nextIndexTerm == null) {\n            System.out.println(\"  nextIndexTerm=null\");\n          } else {\n            System.out.println(\"  nextIndexTerm=\" + nextIndexTerm.utf8ToString());\n          }\n        }\n        */\n\n        // Check cache\n        if (useCache) {\n          fieldTerm.term = target;\n          // TODO: should we differentiate \"frozen\"\n          // TermState (ie one that was cloned and\n          // cached/returned by termState()) from the\n          // malleable (primary) one?\n          final TermState cachedState = termsCache.get(fieldTerm);\n          if (cachedState != null) {\n            seekPending = true;\n            //System.out.println(\"  cached!\");\n            seek(target, cachedState);\n            //System.out.println(\"  term=\" + term.utf8ToString());\n            return SeekStatus.FOUND;\n          }\n        }\n\n        boolean doSeek = true;\n\n        // See if we can avoid seeking, because target term\n        // is after current term but before next index term:\n        if (indexIsCurrent) {\n\n          final int cmp = BytesRef.getUTF8SortedAsUnicodeComparator().compare(term, target);\n\n          if (cmp == 0) {\n            // Already at the requested term\n            return SeekStatus.FOUND;\n          } else if (cmp < 0) {\n\n            // Target term is after current term\n            if (!didIndexNext) {\n              if (indexEnum.next() == -1) {\n                nextIndexTerm = null;\n              } else {\n                nextIndexTerm = indexEnum.term();\n              }\n              //System.out.println(\"  now do index next() nextIndexTerm=\" + (nextIndexTerm == null ? \"null\" : nextIndexTerm.utf8ToString()));\n              didIndexNext = true;\n            }\n\n            if (nextIndexTerm == null || BytesRef.getUTF8SortedAsUnicodeComparator().compare(target, nextIndexTerm) < 0) {\n              // Optimization: requested term is within the\n              // same term block we are now in; skip seeking\n              // (but do scanning):\n              doSeek = false;\n              //System.out.println(\"  skip seek: nextIndexTerm=\" + (nextIndexTerm == null ? \"null\" : nextIndexTerm.utf8ToString()));\n            }\n          }\n        }\n\n        if (doSeek) {\n          //System.out.println(\"  seek\");\n\n          // Ask terms index to find biggest indexed term (=\n          // first term in a block) that's <= our text:\n          in.seek(indexEnum.seek(target));\n          boolean result = nextBlock();\n\n          // Block must exist since, at least, the indexed term\n          // is in the block:\n          assert result;\n\n          indexIsCurrent = true;\n          didIndexNext = false;\n          blocksSinceSeek = 0;          \n\n          if (doOrd) {\n            state.ord = indexEnum.ord()-1;\n          }\n\n          term.copy(indexEnum.term());\n          //System.out.println(\"  seek: term=\" + term.utf8ToString());\n        } else {\n          //System.out.println(\"  skip seek\");\n          if (state.termCount == state.blockTermCount && !nextBlock()) {\n            indexIsCurrent = false;\n            return SeekStatus.END;\n          }\n        }\n\n        seekPending = false;\n\n        int common = 0;\n\n        // Scan within block.  We could do this by calling\n        // _next() and testing the resulting term, but this\n        // is wasteful.  Instead, we first confirm the\n        // target matches the common prefix of this block,\n        // and then we scan the term bytes directly from the\n        // termSuffixesreader's byte[], saving a copy into\n        // the BytesRef term per term.  Only when we return\n        // do we then copy the bytes into the term.\n\n        while(true) {\n\n          // First, see if target term matches common prefix\n          // in this block:\n          if (common < termBlockPrefix) {\n            final int cmp = (term.bytes[common]&0xFF) - (target.bytes[target.offset + common]&0xFF);\n            if (cmp < 0) {\n\n              // TODO: maybe we should store common prefix\n              // in block header?  (instead of relying on\n              // last term of previous block)\n\n              // Target's prefix is after the common block\n              // prefix, so term cannot be in this block\n              // but it could be in next block.  We\n              // must scan to end-of-block to set common\n              // prefix for next block:\n              if (state.termCount < state.blockTermCount) {\n                while(state.termCount < state.blockTermCount-1) {\n                  state.termCount++;\n                  state.ord++;\n                  termSuffixesReader.skipBytes(termSuffixesReader.readVInt());\n                }\n                final int suffix = termSuffixesReader.readVInt();\n                term.length = termBlockPrefix + suffix;\n                if (term.bytes.length < term.length) {\n                  term.grow(term.length);\n                }\n                termSuffixesReader.readBytes(term.bytes, termBlockPrefix, suffix);\n              }\n              state.ord++;\n              \n              if (!nextBlock()) {\n                indexIsCurrent = false;\n                return SeekStatus.END;\n              }\n              common = 0;\n\n            } else if (cmp > 0) {\n              // Target's prefix is before the common prefix\n              // of this block, so we position to start of\n              // block and return NOT_FOUND:\n              assert state.termCount == 0;\n\n              final int suffix = termSuffixesReader.readVInt();\n              term.length = termBlockPrefix + suffix;\n              if (term.bytes.length < term.length) {\n                term.grow(term.length);\n              }\n              termSuffixesReader.readBytes(term.bytes, termBlockPrefix, suffix);\n              return SeekStatus.NOT_FOUND;\n            } else {\n              common++;\n            }\n\n            continue;\n          }\n\n          // Test every term in this block\n          while (true) {\n            state.termCount++;\n            state.ord++;\n\n            final int suffix = termSuffixesReader.readVInt();\n            \n            // We know the prefix matches, so just compare the new suffix:\n            final int termLen = termBlockPrefix + suffix;\n            int bytePos = termSuffixesReader.getPosition();\n\n            boolean next = false;\n            final int limit = target.offset + (termLen < target.length ? termLen : target.length);\n            int targetPos = target.offset + termBlockPrefix;\n            while(targetPos < limit) {\n              final int cmp = (termSuffixes[bytePos++]&0xFF) - (target.bytes[targetPos++]&0xFF);\n              if (cmp < 0) {\n                // Current term is still before the target;\n                // keep scanning\n                next = true;\n                break;\n              } else if (cmp > 0) {\n                // Done!  Current term is after target. Stop\n                // here, fill in real term, return NOT_FOUND.\n                term.length = termBlockPrefix + suffix;\n                if (term.bytes.length < term.length) {\n                  term.grow(term.length);\n                }\n                termSuffixesReader.readBytes(term.bytes, termBlockPrefix, suffix);\n                //System.out.println(\"  NOT_FOUND\");\n                return SeekStatus.NOT_FOUND;\n              }\n            }\n\n            if (!next && target.length <= termLen) {\n              term.length = termBlockPrefix + suffix;\n              if (term.bytes.length < term.length) {\n                term.grow(term.length);\n              }\n              termSuffixesReader.readBytes(term.bytes, termBlockPrefix, suffix);\n\n              if (target.length == termLen) {\n                // Done!  Exact match.  Stop here, fill in\n                // real term, return FOUND.\n                //System.out.println(\"  FOUND\");\n\n                if (useCache) {\n                  // Store in cache\n                  decodeMetaData();\n                  //System.out.println(\"  cache! state=\" + state);\n                  termsCache.put(new FieldAndTerm(fieldTerm), (BlockTermState) state.clone());\n                }\n\n                return SeekStatus.FOUND;\n              } else {\n                //System.out.println(\"  NOT_FOUND\");\n                return SeekStatus.NOT_FOUND;\n              }\n            }\n\n            if (state.termCount == state.blockTermCount) {\n              // Must pre-fill term for next block's common prefix\n              term.length = termBlockPrefix + suffix;\n              if (term.bytes.length < term.length) {\n                term.grow(term.length);\n              }\n              termSuffixesReader.readBytes(term.bytes, termBlockPrefix, suffix);\n              break;\n            } else {\n              termSuffixesReader.skipBytes(suffix);\n            }\n          }\n\n          // The purpose of the terms dict index is to seek\n          // the enum to the closest index term before the\n          // term we are looking for.  So, we should never\n          // cross another index term (besides the first\n          // one) while we are scanning:\n\n          assert indexIsCurrent;\n\n          if (!nextBlock()) {\n            //System.out.println(\"  END\");\n            indexIsCurrent = false;\n            return SeekStatus.END;\n          }\n          common = 0;\n        }\n      }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2553b00f699380c64959ccb27991289aae87be2e","date":1309290151,"type":5,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/codecs/BlockTermsReader.FieldReader.SegmentTermsEnum#seekCeil(BytesRef,boolean).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/codecs/BlockTermsReader.FieldReader.SegmentTermsEnum#seek(BytesRef,boolean).mjava","sourceNew":"      // TODO: we may want an alternate mode here which is\n      // \"if you are about to return NOT_FOUND I won't use\n      // the terms data from that\"; eg FuzzyTermsEnum will\n      // (usually) just immediately call seek again if we\n      // return NOT_FOUND so it's a waste for us to fill in\n      // the term that was actually NOT_FOUND\n      @Override\n      public SeekStatus seekCeil(final BytesRef target, final boolean useCache) throws IOException {\n\n        if (indexEnum == null) {\n          throw new IllegalStateException(\"terms index was not loaded\");\n        }\n   \n        /*\n        System.out.println(\"BTR.seek seg=\" + segment + \" target=\" + fieldInfo.name + \":\" + target.utf8ToString() + \" \" + target + \" current=\" + term().utf8ToString() + \" \" + term() + \" useCache=\" + useCache + \" indexIsCurrent=\" + indexIsCurrent + \" didIndexNext=\" + didIndexNext + \" seekPending=\" + seekPending + \" divisor=\" + indexReader.getDivisor() + \" this=\"  + this);\n        if (didIndexNext) {\n          if (nextIndexTerm == null) {\n            System.out.println(\"  nextIndexTerm=null\");\n          } else {\n            System.out.println(\"  nextIndexTerm=\" + nextIndexTerm.utf8ToString());\n          }\n        }\n        */\n\n        // Check cache\n        if (useCache) {\n          fieldTerm.term = target;\n          // TODO: should we differentiate \"frozen\"\n          // TermState (ie one that was cloned and\n          // cached/returned by termState()) from the\n          // malleable (primary) one?\n          final TermState cachedState = termsCache.get(fieldTerm);\n          if (cachedState != null) {\n            seekPending = true;\n            //System.out.println(\"  cached!\");\n            seekExact(target, cachedState);\n            //System.out.println(\"  term=\" + term.utf8ToString());\n            return SeekStatus.FOUND;\n          }\n        }\n\n        boolean doSeek = true;\n\n        // See if we can avoid seeking, because target term\n        // is after current term but before next index term:\n        if (indexIsCurrent) {\n\n          final int cmp = BytesRef.getUTF8SortedAsUnicodeComparator().compare(term, target);\n\n          if (cmp == 0) {\n            // Already at the requested term\n            return SeekStatus.FOUND;\n          } else if (cmp < 0) {\n\n            // Target term is after current term\n            if (!didIndexNext) {\n              if (indexEnum.next() == -1) {\n                nextIndexTerm = null;\n              } else {\n                nextIndexTerm = indexEnum.term();\n              }\n              //System.out.println(\"  now do index next() nextIndexTerm=\" + (nextIndexTerm == null ? \"null\" : nextIndexTerm.utf8ToString()));\n              didIndexNext = true;\n            }\n\n            if (nextIndexTerm == null || BytesRef.getUTF8SortedAsUnicodeComparator().compare(target, nextIndexTerm) < 0) {\n              // Optimization: requested term is within the\n              // same term block we are now in; skip seeking\n              // (but do scanning):\n              doSeek = false;\n              //System.out.println(\"  skip seek: nextIndexTerm=\" + (nextIndexTerm == null ? \"null\" : nextIndexTerm.utf8ToString()));\n            }\n          }\n        }\n\n        if (doSeek) {\n          //System.out.println(\"  seek\");\n\n          // Ask terms index to find biggest indexed term (=\n          // first term in a block) that's <= our text:\n          in.seek(indexEnum.seek(target));\n          boolean result = nextBlock();\n\n          // Block must exist since, at least, the indexed term\n          // is in the block:\n          assert result;\n\n          indexIsCurrent = true;\n          didIndexNext = false;\n          blocksSinceSeek = 0;          \n\n          if (doOrd) {\n            state.ord = indexEnum.ord()-1;\n          }\n\n          term.copy(indexEnum.term());\n          //System.out.println(\"  seek: term=\" + term.utf8ToString());\n        } else {\n          //System.out.println(\"  skip seek\");\n          if (state.termCount == state.blockTermCount && !nextBlock()) {\n            indexIsCurrent = false;\n            return SeekStatus.END;\n          }\n        }\n\n        seekPending = false;\n\n        int common = 0;\n\n        // Scan within block.  We could do this by calling\n        // _next() and testing the resulting term, but this\n        // is wasteful.  Instead, we first confirm the\n        // target matches the common prefix of this block,\n        // and then we scan the term bytes directly from the\n        // termSuffixesreader's byte[], saving a copy into\n        // the BytesRef term per term.  Only when we return\n        // do we then copy the bytes into the term.\n\n        while(true) {\n\n          // First, see if target term matches common prefix\n          // in this block:\n          if (common < termBlockPrefix) {\n            final int cmp = (term.bytes[common]&0xFF) - (target.bytes[target.offset + common]&0xFF);\n            if (cmp < 0) {\n\n              // TODO: maybe we should store common prefix\n              // in block header?  (instead of relying on\n              // last term of previous block)\n\n              // Target's prefix is after the common block\n              // prefix, so term cannot be in this block\n              // but it could be in next block.  We\n              // must scan to end-of-block to set common\n              // prefix for next block:\n              if (state.termCount < state.blockTermCount) {\n                while(state.termCount < state.blockTermCount-1) {\n                  state.termCount++;\n                  state.ord++;\n                  termSuffixesReader.skipBytes(termSuffixesReader.readVInt());\n                }\n                final int suffix = termSuffixesReader.readVInt();\n                term.length = termBlockPrefix + suffix;\n                if (term.bytes.length < term.length) {\n                  term.grow(term.length);\n                }\n                termSuffixesReader.readBytes(term.bytes, termBlockPrefix, suffix);\n              }\n              state.ord++;\n              \n              if (!nextBlock()) {\n                indexIsCurrent = false;\n                return SeekStatus.END;\n              }\n              common = 0;\n\n            } else if (cmp > 0) {\n              // Target's prefix is before the common prefix\n              // of this block, so we position to start of\n              // block and return NOT_FOUND:\n              assert state.termCount == 0;\n\n              final int suffix = termSuffixesReader.readVInt();\n              term.length = termBlockPrefix + suffix;\n              if (term.bytes.length < term.length) {\n                term.grow(term.length);\n              }\n              termSuffixesReader.readBytes(term.bytes, termBlockPrefix, suffix);\n              return SeekStatus.NOT_FOUND;\n            } else {\n              common++;\n            }\n\n            continue;\n          }\n\n          // Test every term in this block\n          while (true) {\n            state.termCount++;\n            state.ord++;\n\n            final int suffix = termSuffixesReader.readVInt();\n            \n            // We know the prefix matches, so just compare the new suffix:\n            final int termLen = termBlockPrefix + suffix;\n            int bytePos = termSuffixesReader.getPosition();\n\n            boolean next = false;\n            final int limit = target.offset + (termLen < target.length ? termLen : target.length);\n            int targetPos = target.offset + termBlockPrefix;\n            while(targetPos < limit) {\n              final int cmp = (termSuffixes[bytePos++]&0xFF) - (target.bytes[targetPos++]&0xFF);\n              if (cmp < 0) {\n                // Current term is still before the target;\n                // keep scanning\n                next = true;\n                break;\n              } else if (cmp > 0) {\n                // Done!  Current term is after target. Stop\n                // here, fill in real term, return NOT_FOUND.\n                term.length = termBlockPrefix + suffix;\n                if (term.bytes.length < term.length) {\n                  term.grow(term.length);\n                }\n                termSuffixesReader.readBytes(term.bytes, termBlockPrefix, suffix);\n                //System.out.println(\"  NOT_FOUND\");\n                return SeekStatus.NOT_FOUND;\n              }\n            }\n\n            if (!next && target.length <= termLen) {\n              term.length = termBlockPrefix + suffix;\n              if (term.bytes.length < term.length) {\n                term.grow(term.length);\n              }\n              termSuffixesReader.readBytes(term.bytes, termBlockPrefix, suffix);\n\n              if (target.length == termLen) {\n                // Done!  Exact match.  Stop here, fill in\n                // real term, return FOUND.\n                //System.out.println(\"  FOUND\");\n\n                if (useCache) {\n                  // Store in cache\n                  decodeMetaData();\n                  //System.out.println(\"  cache! state=\" + state);\n                  termsCache.put(new FieldAndTerm(fieldTerm), (BlockTermState) state.clone());\n                }\n\n                return SeekStatus.FOUND;\n              } else {\n                //System.out.println(\"  NOT_FOUND\");\n                return SeekStatus.NOT_FOUND;\n              }\n            }\n\n            if (state.termCount == state.blockTermCount) {\n              // Must pre-fill term for next block's common prefix\n              term.length = termBlockPrefix + suffix;\n              if (term.bytes.length < term.length) {\n                term.grow(term.length);\n              }\n              termSuffixesReader.readBytes(term.bytes, termBlockPrefix, suffix);\n              break;\n            } else {\n              termSuffixesReader.skipBytes(suffix);\n            }\n          }\n\n          // The purpose of the terms dict index is to seek\n          // the enum to the closest index term before the\n          // term we are looking for.  So, we should never\n          // cross another index term (besides the first\n          // one) while we are scanning:\n\n          assert indexIsCurrent;\n\n          if (!nextBlock()) {\n            //System.out.println(\"  END\");\n            indexIsCurrent = false;\n            return SeekStatus.END;\n          }\n          common = 0;\n        }\n      }\n\n","sourceOld":"      // TODO: we may want an alternate mode here which is\n      // \"if you are about to return NOT_FOUND I won't use\n      // the terms data from that\"; eg FuzzyTermsEnum will\n      // (usually) just immediately call seek again if we\n      // return NOT_FOUND so it's a waste for us to fill in\n      // the term that was actually NOT_FOUND\n      @Override\n      public SeekStatus seek(final BytesRef target, final boolean useCache) throws IOException {\n\n        if (indexEnum == null) {\n          throw new IllegalStateException(\"terms index was not loaded\");\n        }\n   \n        /*\n        System.out.println(\"BTR.seek seg=\" + segment + \" target=\" + fieldInfo.name + \":\" + target.utf8ToString() + \" \" + target + \" current=\" + term().utf8ToString() + \" \" + term() + \" useCache=\" + useCache + \" indexIsCurrent=\" + indexIsCurrent + \" didIndexNext=\" + didIndexNext + \" seekPending=\" + seekPending + \" divisor=\" + indexReader.getDivisor() + \" this=\"  + this);\n        if (didIndexNext) {\n          if (nextIndexTerm == null) {\n            System.out.println(\"  nextIndexTerm=null\");\n          } else {\n            System.out.println(\"  nextIndexTerm=\" + nextIndexTerm.utf8ToString());\n          }\n        }\n        */\n\n        // Check cache\n        if (useCache) {\n          fieldTerm.term = target;\n          // TODO: should we differentiate \"frozen\"\n          // TermState (ie one that was cloned and\n          // cached/returned by termState()) from the\n          // malleable (primary) one?\n          final TermState cachedState = termsCache.get(fieldTerm);\n          if (cachedState != null) {\n            seekPending = true;\n            //System.out.println(\"  cached!\");\n            seek(target, cachedState);\n            //System.out.println(\"  term=\" + term.utf8ToString());\n            return SeekStatus.FOUND;\n          }\n        }\n\n        boolean doSeek = true;\n\n        // See if we can avoid seeking, because target term\n        // is after current term but before next index term:\n        if (indexIsCurrent) {\n\n          final int cmp = BytesRef.getUTF8SortedAsUnicodeComparator().compare(term, target);\n\n          if (cmp == 0) {\n            // Already at the requested term\n            return SeekStatus.FOUND;\n          } else if (cmp < 0) {\n\n            // Target term is after current term\n            if (!didIndexNext) {\n              if (indexEnum.next() == -1) {\n                nextIndexTerm = null;\n              } else {\n                nextIndexTerm = indexEnum.term();\n              }\n              //System.out.println(\"  now do index next() nextIndexTerm=\" + (nextIndexTerm == null ? \"null\" : nextIndexTerm.utf8ToString()));\n              didIndexNext = true;\n            }\n\n            if (nextIndexTerm == null || BytesRef.getUTF8SortedAsUnicodeComparator().compare(target, nextIndexTerm) < 0) {\n              // Optimization: requested term is within the\n              // same term block we are now in; skip seeking\n              // (but do scanning):\n              doSeek = false;\n              //System.out.println(\"  skip seek: nextIndexTerm=\" + (nextIndexTerm == null ? \"null\" : nextIndexTerm.utf8ToString()));\n            }\n          }\n        }\n\n        if (doSeek) {\n          //System.out.println(\"  seek\");\n\n          // Ask terms index to find biggest indexed term (=\n          // first term in a block) that's <= our text:\n          in.seek(indexEnum.seek(target));\n          boolean result = nextBlock();\n\n          // Block must exist since, at least, the indexed term\n          // is in the block:\n          assert result;\n\n          indexIsCurrent = true;\n          didIndexNext = false;\n          blocksSinceSeek = 0;          \n\n          if (doOrd) {\n            state.ord = indexEnum.ord()-1;\n          }\n\n          term.copy(indexEnum.term());\n          //System.out.println(\"  seek: term=\" + term.utf8ToString());\n        } else {\n          //System.out.println(\"  skip seek\");\n          if (state.termCount == state.blockTermCount && !nextBlock()) {\n            indexIsCurrent = false;\n            return SeekStatus.END;\n          }\n        }\n\n        seekPending = false;\n\n        int common = 0;\n\n        // Scan within block.  We could do this by calling\n        // _next() and testing the resulting term, but this\n        // is wasteful.  Instead, we first confirm the\n        // target matches the common prefix of this block,\n        // and then we scan the term bytes directly from the\n        // termSuffixesreader's byte[], saving a copy into\n        // the BytesRef term per term.  Only when we return\n        // do we then copy the bytes into the term.\n\n        while(true) {\n\n          // First, see if target term matches common prefix\n          // in this block:\n          if (common < termBlockPrefix) {\n            final int cmp = (term.bytes[common]&0xFF) - (target.bytes[target.offset + common]&0xFF);\n            if (cmp < 0) {\n\n              // TODO: maybe we should store common prefix\n              // in block header?  (instead of relying on\n              // last term of previous block)\n\n              // Target's prefix is after the common block\n              // prefix, so term cannot be in this block\n              // but it could be in next block.  We\n              // must scan to end-of-block to set common\n              // prefix for next block:\n              if (state.termCount < state.blockTermCount) {\n                while(state.termCount < state.blockTermCount-1) {\n                  state.termCount++;\n                  state.ord++;\n                  termSuffixesReader.skipBytes(termSuffixesReader.readVInt());\n                }\n                final int suffix = termSuffixesReader.readVInt();\n                term.length = termBlockPrefix + suffix;\n                if (term.bytes.length < term.length) {\n                  term.grow(term.length);\n                }\n                termSuffixesReader.readBytes(term.bytes, termBlockPrefix, suffix);\n              }\n              state.ord++;\n              \n              if (!nextBlock()) {\n                indexIsCurrent = false;\n                return SeekStatus.END;\n              }\n              common = 0;\n\n            } else if (cmp > 0) {\n              // Target's prefix is before the common prefix\n              // of this block, so we position to start of\n              // block and return NOT_FOUND:\n              assert state.termCount == 0;\n\n              final int suffix = termSuffixesReader.readVInt();\n              term.length = termBlockPrefix + suffix;\n              if (term.bytes.length < term.length) {\n                term.grow(term.length);\n              }\n              termSuffixesReader.readBytes(term.bytes, termBlockPrefix, suffix);\n              return SeekStatus.NOT_FOUND;\n            } else {\n              common++;\n            }\n\n            continue;\n          }\n\n          // Test every term in this block\n          while (true) {\n            state.termCount++;\n            state.ord++;\n\n            final int suffix = termSuffixesReader.readVInt();\n            \n            // We know the prefix matches, so just compare the new suffix:\n            final int termLen = termBlockPrefix + suffix;\n            int bytePos = termSuffixesReader.getPosition();\n\n            boolean next = false;\n            final int limit = target.offset + (termLen < target.length ? termLen : target.length);\n            int targetPos = target.offset + termBlockPrefix;\n            while(targetPos < limit) {\n              final int cmp = (termSuffixes[bytePos++]&0xFF) - (target.bytes[targetPos++]&0xFF);\n              if (cmp < 0) {\n                // Current term is still before the target;\n                // keep scanning\n                next = true;\n                break;\n              } else if (cmp > 0) {\n                // Done!  Current term is after target. Stop\n                // here, fill in real term, return NOT_FOUND.\n                term.length = termBlockPrefix + suffix;\n                if (term.bytes.length < term.length) {\n                  term.grow(term.length);\n                }\n                termSuffixesReader.readBytes(term.bytes, termBlockPrefix, suffix);\n                //System.out.println(\"  NOT_FOUND\");\n                return SeekStatus.NOT_FOUND;\n              }\n            }\n\n            if (!next && target.length <= termLen) {\n              term.length = termBlockPrefix + suffix;\n              if (term.bytes.length < term.length) {\n                term.grow(term.length);\n              }\n              termSuffixesReader.readBytes(term.bytes, termBlockPrefix, suffix);\n\n              if (target.length == termLen) {\n                // Done!  Exact match.  Stop here, fill in\n                // real term, return FOUND.\n                //System.out.println(\"  FOUND\");\n\n                if (useCache) {\n                  // Store in cache\n                  decodeMetaData();\n                  //System.out.println(\"  cache! state=\" + state);\n                  termsCache.put(new FieldAndTerm(fieldTerm), (BlockTermState) state.clone());\n                }\n\n                return SeekStatus.FOUND;\n              } else {\n                //System.out.println(\"  NOT_FOUND\");\n                return SeekStatus.NOT_FOUND;\n              }\n            }\n\n            if (state.termCount == state.blockTermCount) {\n              // Must pre-fill term for next block's common prefix\n              term.length = termBlockPrefix + suffix;\n              if (term.bytes.length < term.length) {\n                term.grow(term.length);\n              }\n              termSuffixesReader.readBytes(term.bytes, termBlockPrefix, suffix);\n              break;\n            } else {\n              termSuffixesReader.skipBytes(suffix);\n            }\n          }\n\n          // The purpose of the terms dict index is to seek\n          // the enum to the closest index term before the\n          // term we are looking for.  So, we should never\n          // cross another index term (besides the first\n          // one) while we are scanning:\n\n          assert indexIsCurrent;\n\n          if (!nextBlock()) {\n            //System.out.println(\"  END\");\n            indexIsCurrent = false;\n            return SeekStatus.END;\n          }\n          common = 0;\n        }\n      }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d083e83f225b11e5fdd900e83d26ddb385b6955c","date":1310029438,"type":4,"author":"Simon Willnauer","isMerge":true,"pathNew":"/dev/null","pathOld":"lucene/src/java/org/apache/lucene/index/codecs/BlockTermsReader.FieldReader.SegmentTermsEnum#seek(BytesRef,boolean).mjava","sourceNew":null,"sourceOld":"      // TODO: we may want an alternate mode here which is\n      // \"if you are about to return NOT_FOUND I won't use\n      // the terms data from that\"; eg FuzzyTermsEnum will\n      // (usually) just immediately call seek again if we\n      // return NOT_FOUND so it's a waste for us to fill in\n      // the term that was actually NOT_FOUND\n      @Override\n      public SeekStatus seek(final BytesRef target, final boolean useCache) throws IOException {\n\n        if (indexEnum == null) {\n          throw new IllegalStateException(\"terms index was not loaded\");\n        }\n   \n        /*\n        System.out.println(\"BTR.seek seg=\" + segment + \" target=\" + fieldInfo.name + \":\" + target.utf8ToString() + \" \" + target + \" current=\" + term().utf8ToString() + \" \" + term() + \" useCache=\" + useCache + \" indexIsCurrent=\" + indexIsCurrent + \" didIndexNext=\" + didIndexNext + \" seekPending=\" + seekPending + \" divisor=\" + indexReader.getDivisor() + \" this=\"  + this);\n        if (didIndexNext) {\n          if (nextIndexTerm == null) {\n            System.out.println(\"  nextIndexTerm=null\");\n          } else {\n            System.out.println(\"  nextIndexTerm=\" + nextIndexTerm.utf8ToString());\n          }\n        }\n        */\n\n        // Check cache\n        if (useCache) {\n          fieldTerm.term = target;\n          // TODO: should we differentiate \"frozen\"\n          // TermState (ie one that was cloned and\n          // cached/returned by termState()) from the\n          // malleable (primary) one?\n          final TermState cachedState = termsCache.get(fieldTerm);\n          if (cachedState != null) {\n            seekPending = true;\n            //System.out.println(\"  cached!\");\n            seek(target, cachedState);\n            //System.out.println(\"  term=\" + term.utf8ToString());\n            return SeekStatus.FOUND;\n          }\n        }\n\n        boolean doSeek = true;\n\n        // See if we can avoid seeking, because target term\n        // is after current term but before next index term:\n        if (indexIsCurrent) {\n\n          final int cmp = BytesRef.getUTF8SortedAsUnicodeComparator().compare(term, target);\n\n          if (cmp == 0) {\n            // Already at the requested term\n            return SeekStatus.FOUND;\n          } else if (cmp < 0) {\n\n            // Target term is after current term\n            if (!didIndexNext) {\n              if (indexEnum.next() == -1) {\n                nextIndexTerm = null;\n              } else {\n                nextIndexTerm = indexEnum.term();\n              }\n              //System.out.println(\"  now do index next() nextIndexTerm=\" + (nextIndexTerm == null ? \"null\" : nextIndexTerm.utf8ToString()));\n              didIndexNext = true;\n            }\n\n            if (nextIndexTerm == null || BytesRef.getUTF8SortedAsUnicodeComparator().compare(target, nextIndexTerm) < 0) {\n              // Optimization: requested term is within the\n              // same term block we are now in; skip seeking\n              // (but do scanning):\n              doSeek = false;\n              //System.out.println(\"  skip seek: nextIndexTerm=\" + (nextIndexTerm == null ? \"null\" : nextIndexTerm.utf8ToString()));\n            }\n          }\n        }\n\n        if (doSeek) {\n          //System.out.println(\"  seek\");\n\n          // Ask terms index to find biggest indexed term (=\n          // first term in a block) that's <= our text:\n          in.seek(indexEnum.seek(target));\n          boolean result = nextBlock();\n\n          // Block must exist since, at least, the indexed term\n          // is in the block:\n          assert result;\n\n          indexIsCurrent = true;\n          didIndexNext = false;\n          blocksSinceSeek = 0;          \n\n          if (doOrd) {\n            state.ord = indexEnum.ord()-1;\n          }\n\n          term.copy(indexEnum.term());\n          //System.out.println(\"  seek: term=\" + term.utf8ToString());\n        } else {\n          //System.out.println(\"  skip seek\");\n          if (state.termCount == state.blockTermCount && !nextBlock()) {\n            indexIsCurrent = false;\n            return SeekStatus.END;\n          }\n        }\n\n        seekPending = false;\n\n        int common = 0;\n\n        // Scan within block.  We could do this by calling\n        // _next() and testing the resulting term, but this\n        // is wasteful.  Instead, we first confirm the\n        // target matches the common prefix of this block,\n        // and then we scan the term bytes directly from the\n        // termSuffixesreader's byte[], saving a copy into\n        // the BytesRef term per term.  Only when we return\n        // do we then copy the bytes into the term.\n\n        while(true) {\n\n          // First, see if target term matches common prefix\n          // in this block:\n          if (common < termBlockPrefix) {\n            final int cmp = (term.bytes[common]&0xFF) - (target.bytes[target.offset + common]&0xFF);\n            if (cmp < 0) {\n\n              // TODO: maybe we should store common prefix\n              // in block header?  (instead of relying on\n              // last term of previous block)\n\n              // Target's prefix is after the common block\n              // prefix, so term cannot be in this block\n              // but it could be in next block.  We\n              // must scan to end-of-block to set common\n              // prefix for next block:\n              if (state.termCount < state.blockTermCount) {\n                while(state.termCount < state.blockTermCount-1) {\n                  state.termCount++;\n                  state.ord++;\n                  termSuffixesReader.skipBytes(termSuffixesReader.readVInt());\n                }\n                final int suffix = termSuffixesReader.readVInt();\n                term.length = termBlockPrefix + suffix;\n                if (term.bytes.length < term.length) {\n                  term.grow(term.length);\n                }\n                termSuffixesReader.readBytes(term.bytes, termBlockPrefix, suffix);\n              }\n              state.ord++;\n              \n              if (!nextBlock()) {\n                indexIsCurrent = false;\n                return SeekStatus.END;\n              }\n              common = 0;\n\n            } else if (cmp > 0) {\n              // Target's prefix is before the common prefix\n              // of this block, so we position to start of\n              // block and return NOT_FOUND:\n              assert state.termCount == 0;\n\n              final int suffix = termSuffixesReader.readVInt();\n              term.length = termBlockPrefix + suffix;\n              if (term.bytes.length < term.length) {\n                term.grow(term.length);\n              }\n              termSuffixesReader.readBytes(term.bytes, termBlockPrefix, suffix);\n              return SeekStatus.NOT_FOUND;\n            } else {\n              common++;\n            }\n\n            continue;\n          }\n\n          // Test every term in this block\n          while (true) {\n            state.termCount++;\n            state.ord++;\n\n            final int suffix = termSuffixesReader.readVInt();\n            \n            // We know the prefix matches, so just compare the new suffix:\n            final int termLen = termBlockPrefix + suffix;\n            int bytePos = termSuffixesReader.getPosition();\n\n            boolean next = false;\n            final int limit = target.offset + (termLen < target.length ? termLen : target.length);\n            int targetPos = target.offset + termBlockPrefix;\n            while(targetPos < limit) {\n              final int cmp = (termSuffixes[bytePos++]&0xFF) - (target.bytes[targetPos++]&0xFF);\n              if (cmp < 0) {\n                // Current term is still before the target;\n                // keep scanning\n                next = true;\n                break;\n              } else if (cmp > 0) {\n                // Done!  Current term is after target. Stop\n                // here, fill in real term, return NOT_FOUND.\n                term.length = termBlockPrefix + suffix;\n                if (term.bytes.length < term.length) {\n                  term.grow(term.length);\n                }\n                termSuffixesReader.readBytes(term.bytes, termBlockPrefix, suffix);\n                //System.out.println(\"  NOT_FOUND\");\n                return SeekStatus.NOT_FOUND;\n              }\n            }\n\n            if (!next && target.length <= termLen) {\n              term.length = termBlockPrefix + suffix;\n              if (term.bytes.length < term.length) {\n                term.grow(term.length);\n              }\n              termSuffixesReader.readBytes(term.bytes, termBlockPrefix, suffix);\n\n              if (target.length == termLen) {\n                // Done!  Exact match.  Stop here, fill in\n                // real term, return FOUND.\n                //System.out.println(\"  FOUND\");\n\n                if (useCache) {\n                  // Store in cache\n                  decodeMetaData();\n                  //System.out.println(\"  cache! state=\" + state);\n                  termsCache.put(new FieldAndTerm(fieldTerm), (BlockTermState) state.clone());\n                }\n\n                return SeekStatus.FOUND;\n              } else {\n                //System.out.println(\"  NOT_FOUND\");\n                return SeekStatus.NOT_FOUND;\n              }\n            }\n\n            if (state.termCount == state.blockTermCount) {\n              // Must pre-fill term for next block's common prefix\n              term.length = termBlockPrefix + suffix;\n              if (term.bytes.length < term.length) {\n                term.grow(term.length);\n              }\n              termSuffixesReader.readBytes(term.bytes, termBlockPrefix, suffix);\n              break;\n            } else {\n              termSuffixesReader.skipBytes(suffix);\n            }\n          }\n\n          // The purpose of the terms dict index is to seek\n          // the enum to the closest index term before the\n          // term we are looking for.  So, we should never\n          // cross another index term (besides the first\n          // one) while we are scanning:\n\n          assert indexIsCurrent;\n\n          if (!nextBlock()) {\n            //System.out.println(\"  END\");\n            indexIsCurrent = false;\n            return SeekStatus.END;\n          }\n          common = 0;\n        }\n      }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"fd1bfe3cedf815c14939d170d53031c88eb5c444":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"f1bdbf92da222965b46c0a942c3857ba56e5c638":["29ef99d61cda9641b6250bf9567329a6e65f901d","4fd64b6aa64934b0e35d9ec3e6c5a5c60ffc1762"],"4fd64b6aa64934b0e35d9ec3e6c5a5c60ffc1762":["b1add9ddc0005b07550d4350720aac22dc9886b3"],"29ef99d61cda9641b6250bf9567329a6e65f901d":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","b1add9ddc0005b07550d4350720aac22dc9886b3"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"b1add9ddc0005b07550d4350720aac22dc9886b3":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"2553b00f699380c64959ccb27991289aae87be2e":["4fd64b6aa64934b0e35d9ec3e6c5a5c60ffc1762","fd9cc9d77712aba3662f24632df7539ab75e3667"],"fd9cc9d77712aba3662f24632df7539ab75e3667":["4fd64b6aa64934b0e35d9ec3e6c5a5c60ffc1762"],"d083e83f225b11e5fdd900e83d26ddb385b6955c":["4fd64b6aa64934b0e35d9ec3e6c5a5c60ffc1762","fd9cc9d77712aba3662f24632df7539ab75e3667"],"bde51b089eb7f86171eb3406e38a274743f9b7ac":["fd1bfe3cedf815c14939d170d53031c88eb5c444","4fd64b6aa64934b0e35d9ec3e6c5a5c60ffc1762"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["fd9cc9d77712aba3662f24632df7539ab75e3667"]},"commit2Childs":{"fd1bfe3cedf815c14939d170d53031c88eb5c444":["bde51b089eb7f86171eb3406e38a274743f9b7ac"],"f1bdbf92da222965b46c0a942c3857ba56e5c638":[],"29ef99d61cda9641b6250bf9567329a6e65f901d":["f1bdbf92da222965b46c0a942c3857ba56e5c638"],"4fd64b6aa64934b0e35d9ec3e6c5a5c60ffc1762":["f1bdbf92da222965b46c0a942c3857ba56e5c638","2553b00f699380c64959ccb27991289aae87be2e","fd9cc9d77712aba3662f24632df7539ab75e3667","d083e83f225b11e5fdd900e83d26ddb385b6955c","bde51b089eb7f86171eb3406e38a274743f9b7ac"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["fd1bfe3cedf815c14939d170d53031c88eb5c444","29ef99d61cda9641b6250bf9567329a6e65f901d","b1add9ddc0005b07550d4350720aac22dc9886b3"],"b1add9ddc0005b07550d4350720aac22dc9886b3":["4fd64b6aa64934b0e35d9ec3e6c5a5c60ffc1762","29ef99d61cda9641b6250bf9567329a6e65f901d"],"2553b00f699380c64959ccb27991289aae87be2e":[],"fd9cc9d77712aba3662f24632df7539ab75e3667":["2553b00f699380c64959ccb27991289aae87be2e","d083e83f225b11e5fdd900e83d26ddb385b6955c","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"d083e83f225b11e5fdd900e83d26ddb385b6955c":[],"bde51b089eb7f86171eb3406e38a274743f9b7ac":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["f1bdbf92da222965b46c0a942c3857ba56e5c638","2553b00f699380c64959ccb27991289aae87be2e","d083e83f225b11e5fdd900e83d26ddb385b6955c","bde51b089eb7f86171eb3406e38a274743f9b7ac","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}