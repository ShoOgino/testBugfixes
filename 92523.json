{"path":"solr/core/src/java/org/apache/solr/cloud/api/collections/SplitShardCmd#cleanupAfterFailure(ZkStateReader,String,String,List[String]).mjava","commits":[{"id":"685af99397b6da31116a2cac747ed255d217d080","date":1530038134,"type":0,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/api/collections/SplitShardCmd#cleanupAfterFailure(ZkStateReader,String,String,List[String]).mjava","pathOld":"/dev/null","sourceNew":"  private void cleanupAfterFailure(ZkStateReader zkStateReader, String collectionName, String parentShard, List<String> subSlices) {\n    log.debug(\"- cleanup after failed split of \" + collectionName + \"/\" + parentShard);\n    // get the latest state\n    try {\n      zkStateReader.forceUpdateCollection(collectionName);\n    } catch (KeeperException | InterruptedException e) {\n      log.warn(\"Cleanup after failed split of \" + collectionName + \"/\" + parentShard + \": (force update collection)\", e);\n      return;\n    }\n    ClusterState clusterState = zkStateReader.getClusterState();\n    DocCollection coll = clusterState.getCollectionOrNull(collectionName);\n\n    if (coll == null) { // may have been deleted\n      return;\n    }\n\n    // set already created sub shards states to CONSTRUCTION - this prevents them\n    // from entering into RECOVERY or ACTIVE (SOLR-9455)\n    DistributedQueue inQueue = Overseer.getStateUpdateQueue(zkStateReader.getZkClient());\n    Map<String, Object> propMap = new HashMap<>();\n    propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n    propMap.put(ZkStateReader.COLLECTION_PROP, collectionName);\n    for (Slice s : coll.getSlices()) {\n      if (!subSlices.contains(s.getName())) {\n        continue;\n      }\n      propMap.put(s.getName(), Slice.State.CONSTRUCTION.toString());\n    }\n\n    // if parent is inactive activate it again\n    Slice parentSlice = coll.getSlice(parentShard);\n    if (parentSlice.getState() == Slice.State.INACTIVE) {\n      propMap.put(parentShard, Slice.State.ACTIVE.toString());\n    }\n\n    try {\n      ZkNodeProps m = new ZkNodeProps(propMap);\n      inQueue.offer(Utils.toJSON(m));\n    } catch (Exception e) {\n      // don't give up yet - just log the error, we may still be able to clean up\n      log.warn(\"Cleanup after failed split of \" + collectionName + \"/\" + parentShard + \": (slice state changes)\", e);\n    }\n\n    // delete existing subShards\n    for (String subSlice : subSlices) {\n      Slice s = coll.getSlice(subSlice);\n      if (s == null) {\n        continue;\n      }\n      log.info(\"Sub-shard: {} already exists therefore requesting its deletion\", subSlice);\n      propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, \"deleteshard\");\n      propMap.put(COLLECTION_PROP, collectionName);\n      propMap.put(SHARD_ID_PROP, subSlice);\n      ZkNodeProps m = new ZkNodeProps(propMap);\n      try {\n        ocmh.commandMap.get(DELETESHARD).call(clusterState, m, new NamedList());\n      } catch (Exception e) {\n        log.warn(\"Cleanup after failed split of \" + collectionName + \"/\" + parentShard + \": (deleting existing sub shard \" + subSlice + \")\", e);\n      }\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7eeaaea0106c7d6a2de50acfc8d357121ef8bd26","date":1531589977,"type":0,"author":"Michael Braun","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/cloud/api/collections/SplitShardCmd#cleanupAfterFailure(ZkStateReader,String,String,List[String]).mjava","pathOld":"/dev/null","sourceNew":"  private void cleanupAfterFailure(ZkStateReader zkStateReader, String collectionName, String parentShard, List<String> subSlices) {\n    log.debug(\"- cleanup after failed split of \" + collectionName + \"/\" + parentShard);\n    // get the latest state\n    try {\n      zkStateReader.forceUpdateCollection(collectionName);\n    } catch (KeeperException | InterruptedException e) {\n      log.warn(\"Cleanup after failed split of \" + collectionName + \"/\" + parentShard + \": (force update collection)\", e);\n      return;\n    }\n    ClusterState clusterState = zkStateReader.getClusterState();\n    DocCollection coll = clusterState.getCollectionOrNull(collectionName);\n\n    if (coll == null) { // may have been deleted\n      return;\n    }\n\n    // set already created sub shards states to CONSTRUCTION - this prevents them\n    // from entering into RECOVERY or ACTIVE (SOLR-9455)\n    DistributedQueue inQueue = Overseer.getStateUpdateQueue(zkStateReader.getZkClient());\n    Map<String, Object> propMap = new HashMap<>();\n    propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n    propMap.put(ZkStateReader.COLLECTION_PROP, collectionName);\n    for (Slice s : coll.getSlices()) {\n      if (!subSlices.contains(s.getName())) {\n        continue;\n      }\n      propMap.put(s.getName(), Slice.State.CONSTRUCTION.toString());\n    }\n\n    // if parent is inactive activate it again\n    Slice parentSlice = coll.getSlice(parentShard);\n    if (parentSlice.getState() == Slice.State.INACTIVE) {\n      propMap.put(parentShard, Slice.State.ACTIVE.toString());\n    }\n\n    try {\n      ZkNodeProps m = new ZkNodeProps(propMap);\n      inQueue.offer(Utils.toJSON(m));\n    } catch (Exception e) {\n      // don't give up yet - just log the error, we may still be able to clean up\n      log.warn(\"Cleanup after failed split of \" + collectionName + \"/\" + parentShard + \": (slice state changes)\", e);\n    }\n\n    // delete existing subShards\n    for (String subSlice : subSlices) {\n      Slice s = coll.getSlice(subSlice);\n      if (s == null) {\n        continue;\n      }\n      log.info(\"Sub-shard: {} already exists therefore requesting its deletion\", subSlice);\n      propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, \"deleteshard\");\n      propMap.put(COLLECTION_PROP, collectionName);\n      propMap.put(SHARD_ID_PROP, subSlice);\n      ZkNodeProps m = new ZkNodeProps(propMap);\n      try {\n        ocmh.commandMap.get(DELETESHARD).call(clusterState, m, new NamedList());\n      } catch (Exception e) {\n        log.warn(\"Cleanup after failed split of \" + collectionName + \"/\" + parentShard + \": (deleting existing sub shard \" + subSlice + \")\", e);\n      }\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0efc9f2cae117418f13ba9035f5e1d516ea7a2b5","date":1531905561,"type":0,"author":"Alessandro Benedetti","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/cloud/api/collections/SplitShardCmd#cleanupAfterFailure(ZkStateReader,String,String,List[String]).mjava","pathOld":"/dev/null","sourceNew":"  private void cleanupAfterFailure(ZkStateReader zkStateReader, String collectionName, String parentShard, List<String> subSlices) {\n    log.debug(\"- cleanup after failed split of \" + collectionName + \"/\" + parentShard);\n    // get the latest state\n    try {\n      zkStateReader.forceUpdateCollection(collectionName);\n    } catch (KeeperException | InterruptedException e) {\n      log.warn(\"Cleanup after failed split of \" + collectionName + \"/\" + parentShard + \": (force update collection)\", e);\n      return;\n    }\n    ClusterState clusterState = zkStateReader.getClusterState();\n    DocCollection coll = clusterState.getCollectionOrNull(collectionName);\n\n    if (coll == null) { // may have been deleted\n      return;\n    }\n\n    // set already created sub shards states to CONSTRUCTION - this prevents them\n    // from entering into RECOVERY or ACTIVE (SOLR-9455)\n    DistributedQueue inQueue = Overseer.getStateUpdateQueue(zkStateReader.getZkClient());\n    Map<String, Object> propMap = new HashMap<>();\n    propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n    propMap.put(ZkStateReader.COLLECTION_PROP, collectionName);\n    for (Slice s : coll.getSlices()) {\n      if (!subSlices.contains(s.getName())) {\n        continue;\n      }\n      propMap.put(s.getName(), Slice.State.CONSTRUCTION.toString());\n    }\n\n    // if parent is inactive activate it again\n    Slice parentSlice = coll.getSlice(parentShard);\n    if (parentSlice.getState() == Slice.State.INACTIVE) {\n      propMap.put(parentShard, Slice.State.ACTIVE.toString());\n    }\n\n    try {\n      ZkNodeProps m = new ZkNodeProps(propMap);\n      inQueue.offer(Utils.toJSON(m));\n    } catch (Exception e) {\n      // don't give up yet - just log the error, we may still be able to clean up\n      log.warn(\"Cleanup after failed split of \" + collectionName + \"/\" + parentShard + \": (slice state changes)\", e);\n    }\n\n    // delete existing subShards\n    for (String subSlice : subSlices) {\n      Slice s = coll.getSlice(subSlice);\n      if (s == null) {\n        continue;\n      }\n      log.info(\"Sub-shard: {} already exists therefore requesting its deletion\", subSlice);\n      propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, \"deleteshard\");\n      propMap.put(COLLECTION_PROP, collectionName);\n      propMap.put(SHARD_ID_PROP, subSlice);\n      ZkNodeProps m = new ZkNodeProps(propMap);\n      try {\n        ocmh.commandMap.get(DELETESHARD).call(clusterState, m, new NamedList());\n      } catch (Exception e) {\n        log.warn(\"Cleanup after failed split of \" + collectionName + \"/\" + parentShard + \": (deleting existing sub shard \" + subSlice + \")\", e);\n      }\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"20c968c14aace7cf49843bf2c1fafc7fd3845659","date":1533133859,"type":5,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/api/collections/SplitShardCmd#cleanupAfterFailure(ZkStateReader,String,String,List[String],Set[String]).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/api/collections/SplitShardCmd#cleanupAfterFailure(ZkStateReader,String,String,List[String]).mjava","sourceNew":"  private void cleanupAfterFailure(ZkStateReader zkStateReader, String collectionName, String parentShard,\n                                   List<String> subSlices, Set<String> offlineSlices) {\n    log.info(\"Cleaning up after a failed split of \" + collectionName + \"/\" + parentShard);\n    // get the latest state\n    try {\n      zkStateReader.forceUpdateCollection(collectionName);\n    } catch (KeeperException | InterruptedException e) {\n      log.warn(\"Cleanup failed after failed split of \" + collectionName + \"/\" + parentShard + \": (force update collection)\", e);\n      return;\n    }\n    ClusterState clusterState = zkStateReader.getClusterState();\n    DocCollection coll = clusterState.getCollectionOrNull(collectionName);\n\n    if (coll == null) { // may have been deleted\n      return;\n    }\n\n    // set already created sub shards states to CONSTRUCTION - this prevents them\n    // from entering into RECOVERY or ACTIVE (SOLR-9455)\n    DistributedQueue inQueue = Overseer.getStateUpdateQueue(zkStateReader.getZkClient());\n    final Map<String, Object> propMap = new HashMap<>();\n    boolean sendUpdateState = false;\n    propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n    propMap.put(ZkStateReader.COLLECTION_PROP, collectionName);\n    for (Slice s : coll.getSlices()) {\n      if (!subSlices.contains(s.getName())) {\n        continue;\n      }\n      propMap.put(s.getName(), Slice.State.CONSTRUCTION.toString());\n      sendUpdateState = true;\n    }\n\n    // if parent is inactive activate it again\n    Slice parentSlice = coll.getSlice(parentShard);\n    if (parentSlice.getState() == Slice.State.INACTIVE) {\n      sendUpdateState = true;\n      propMap.put(parentShard, Slice.State.ACTIVE.toString());\n    }\n    // plus any other previously deactivated slices\n    for (String sliceName : offlineSlices) {\n      propMap.put(sliceName, Slice.State.ACTIVE.toString());\n      sendUpdateState = true;\n    }\n\n    if (sendUpdateState) {\n      try {\n        ZkNodeProps m = new ZkNodeProps(propMap);\n        inQueue.offer(Utils.toJSON(m));\n      } catch (Exception e) {\n        // don't give up yet - just log the error, we may still be able to clean up\n        log.warn(\"Cleanup failed after failed split of \" + collectionName + \"/\" + parentShard + \": (slice state changes)\", e);\n      }\n    }\n\n    // delete existing subShards\n    for (String subSlice : subSlices) {\n      Slice s = coll.getSlice(subSlice);\n      if (s == null) {\n        continue;\n      }\n      log.debug(\"- sub-shard: {} exists therefore requesting its deletion\", subSlice);\n      HashMap<String, Object> props = new HashMap<>();\n      props.put(Overseer.QUEUE_OPERATION, \"deleteshard\");\n      props.put(COLLECTION_PROP, collectionName);\n      props.put(SHARD_ID_PROP, subSlice);\n      ZkNodeProps m = new ZkNodeProps(props);\n      try {\n        ocmh.commandMap.get(DELETESHARD).call(clusterState, m, new NamedList());\n      } catch (Exception e) {\n        log.warn(\"Cleanup failed after failed split of \" + collectionName + \"/\" + parentShard + \": (deleting existing sub shard \" + subSlice + \")\", e);\n      }\n    }\n  }\n\n","sourceOld":"  private void cleanupAfterFailure(ZkStateReader zkStateReader, String collectionName, String parentShard, List<String> subSlices) {\n    log.debug(\"- cleanup after failed split of \" + collectionName + \"/\" + parentShard);\n    // get the latest state\n    try {\n      zkStateReader.forceUpdateCollection(collectionName);\n    } catch (KeeperException | InterruptedException e) {\n      log.warn(\"Cleanup after failed split of \" + collectionName + \"/\" + parentShard + \": (force update collection)\", e);\n      return;\n    }\n    ClusterState clusterState = zkStateReader.getClusterState();\n    DocCollection coll = clusterState.getCollectionOrNull(collectionName);\n\n    if (coll == null) { // may have been deleted\n      return;\n    }\n\n    // set already created sub shards states to CONSTRUCTION - this prevents them\n    // from entering into RECOVERY or ACTIVE (SOLR-9455)\n    DistributedQueue inQueue = Overseer.getStateUpdateQueue(zkStateReader.getZkClient());\n    Map<String, Object> propMap = new HashMap<>();\n    propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n    propMap.put(ZkStateReader.COLLECTION_PROP, collectionName);\n    for (Slice s : coll.getSlices()) {\n      if (!subSlices.contains(s.getName())) {\n        continue;\n      }\n      propMap.put(s.getName(), Slice.State.CONSTRUCTION.toString());\n    }\n\n    // if parent is inactive activate it again\n    Slice parentSlice = coll.getSlice(parentShard);\n    if (parentSlice.getState() == Slice.State.INACTIVE) {\n      propMap.put(parentShard, Slice.State.ACTIVE.toString());\n    }\n\n    try {\n      ZkNodeProps m = new ZkNodeProps(propMap);\n      inQueue.offer(Utils.toJSON(m));\n    } catch (Exception e) {\n      // don't give up yet - just log the error, we may still be able to clean up\n      log.warn(\"Cleanup after failed split of \" + collectionName + \"/\" + parentShard + \": (slice state changes)\", e);\n    }\n\n    // delete existing subShards\n    for (String subSlice : subSlices) {\n      Slice s = coll.getSlice(subSlice);\n      if (s == null) {\n        continue;\n      }\n      log.info(\"Sub-shard: {} already exists therefore requesting its deletion\", subSlice);\n      propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, \"deleteshard\");\n      propMap.put(COLLECTION_PROP, collectionName);\n      propMap.put(SHARD_ID_PROP, subSlice);\n      ZkNodeProps m = new ZkNodeProps(propMap);\n      try {\n        ocmh.commandMap.get(DELETESHARD).call(clusterState, m, new NamedList());\n      } catch (Exception e) {\n        log.warn(\"Cleanup after failed split of \" + collectionName + \"/\" + parentShard + \": (deleting existing sub shard \" + subSlice + \")\", e);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":["69e6520a21709190413a63084ed135271aab1a7c","69e6520a21709190413a63084ed135271aab1a7c","bb222a3f9d9421d5c95afce73013fbd8de07ea1f","bb222a3f9d9421d5c95afce73013fbd8de07ea1f"],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"0efc9f2cae117418f13ba9035f5e1d516ea7a2b5":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","685af99397b6da31116a2cac747ed255d217d080"],"685af99397b6da31116a2cac747ed255d217d080":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"20c968c14aace7cf49843bf2c1fafc7fd3845659":["685af99397b6da31116a2cac747ed255d217d080"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["20c968c14aace7cf49843bf2c1fafc7fd3845659"],"7eeaaea0106c7d6a2de50acfc8d357121ef8bd26":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","685af99397b6da31116a2cac747ed255d217d080"]},"commit2Childs":{"0efc9f2cae117418f13ba9035f5e1d516ea7a2b5":[],"685af99397b6da31116a2cac747ed255d217d080":["0efc9f2cae117418f13ba9035f5e1d516ea7a2b5","20c968c14aace7cf49843bf2c1fafc7fd3845659","7eeaaea0106c7d6a2de50acfc8d357121ef8bd26"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["0efc9f2cae117418f13ba9035f5e1d516ea7a2b5","685af99397b6da31116a2cac747ed255d217d080","7eeaaea0106c7d6a2de50acfc8d357121ef8bd26"],"20c968c14aace7cf49843bf2c1fafc7fd3845659":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"7eeaaea0106c7d6a2de50acfc8d357121ef8bd26":[]},"heads":["0efc9f2cae117418f13ba9035f5e1d516ea7a2b5","cd5edd1f2b162a5cfa08efd17851a07373a96817","7eeaaea0106c7d6a2de50acfc8d357121ef8bd26"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}