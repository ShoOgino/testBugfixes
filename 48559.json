{"path":"lucene/highlighter/src/java/org/apache/lucene/search/highlight/WeightedSpanTermExtractor#extractWeightedSpanTerms(Map[String,WeightedSpanTerm],SpanQuery).mjava","commits":[{"id":"b89678825b68eccaf09e6ab71675fc0b0af1e099","date":1334669779,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/highlighter/src/java/org/apache/lucene/search/highlight/WeightedSpanTermExtractor#extractWeightedSpanTerms(Map[String,WeightedSpanTerm],SpanQuery).mjava","pathOld":"lucene/contrib/highlighter/src/java/org/apache/lucene/search/highlight/WeightedSpanTermExtractor#extractWeightedSpanTerms(Map[String,WeightedSpanTerm],SpanQuery).mjava","sourceNew":"  /**\n   * Fills a <code>Map</code> with <@link WeightedSpanTerm>s using the terms from the supplied <code>SpanQuery</code>.\n   * \n   * @param terms\n   *          Map to place created WeightedSpanTerms in\n   * @param spanQuery\n   *          SpanQuery to extract Terms from\n   * @throws IOException\n   */\n  protected void extractWeightedSpanTerms(Map<String,WeightedSpanTerm> terms, SpanQuery spanQuery) throws IOException {\n    Set<String> fieldNames;\n\n    if (fieldName == null) {\n      fieldNames = new HashSet<String>();\n      collectSpanQueryFields(spanQuery, fieldNames);\n    } else {\n      fieldNames = new HashSet<String>(1);\n      fieldNames.add(fieldName);\n    }\n    // To support the use of the default field name\n    if (defaultField != null) {\n      fieldNames.add(defaultField);\n    }\n    \n    Map<String, SpanQuery> queries = new HashMap<String, SpanQuery>();\n \n    Set<Term> nonWeightedTerms = new HashSet<Term>();\n    final boolean mustRewriteQuery = mustRewriteQuery(spanQuery);\n    if (mustRewriteQuery) {\n      for (final String field : fieldNames) {\n        final SpanQuery rewrittenQuery = (SpanQuery) spanQuery.rewrite(getLeafContextForField(field).reader());\n        queries.put(field, rewrittenQuery);\n        rewrittenQuery.extractTerms(nonWeightedTerms);\n      }\n    } else {\n      spanQuery.extractTerms(nonWeightedTerms);\n    }\n\n    List<PositionSpan> spanPositions = new ArrayList<PositionSpan>();\n\n    for (final String field : fieldNames) {\n      final SpanQuery q;\n      if (mustRewriteQuery) {\n        q = queries.get(field);\n      } else {\n        q = spanQuery;\n      }\n      AtomicReaderContext context = getLeafContextForField(field);\n      Map<Term,TermContext> termContexts = new HashMap<Term,TermContext>();\n      TreeSet<Term> extractedTerms = new TreeSet<Term>();\n      q.extractTerms(extractedTerms);\n      for (Term term : extractedTerms) {\n        termContexts.put(term, TermContext.build(context, term, true));\n      }\n      Bits acceptDocs = context.reader().getLiveDocs();\n      final Spans spans = q.getSpans(context, acceptDocs, termContexts);\n\n      // collect span positions\n      while (spans.next()) {\n        spanPositions.add(new PositionSpan(spans.start(), spans.end() - 1));\n      }\n      \n    }\n\n    if (spanPositions.size() == 0) {\n      // no spans found\n      return;\n    }\n\n    for (final Term queryTerm :  nonWeightedTerms) {\n\n      if (fieldNameComparator(queryTerm.field())) {\n        WeightedSpanTerm weightedSpanTerm = terms.get(queryTerm.text());\n\n        if (weightedSpanTerm == null) {\n          weightedSpanTerm = new WeightedSpanTerm(spanQuery.getBoost(), queryTerm.text());\n          weightedSpanTerm.addPositionSpans(spanPositions);\n          weightedSpanTerm.positionSensitive = true;\n          terms.put(queryTerm.text(), weightedSpanTerm);\n        } else {\n          if (spanPositions.size() > 0) {\n            weightedSpanTerm.addPositionSpans(spanPositions);\n          }\n        }\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Fills a <code>Map</code> with <@link WeightedSpanTerm>s using the terms from the supplied <code>SpanQuery</code>.\n   * \n   * @param terms\n   *          Map to place created WeightedSpanTerms in\n   * @param spanQuery\n   *          SpanQuery to extract Terms from\n   * @throws IOException\n   */\n  protected void extractWeightedSpanTerms(Map<String,WeightedSpanTerm> terms, SpanQuery spanQuery) throws IOException {\n    Set<String> fieldNames;\n\n    if (fieldName == null) {\n      fieldNames = new HashSet<String>();\n      collectSpanQueryFields(spanQuery, fieldNames);\n    } else {\n      fieldNames = new HashSet<String>(1);\n      fieldNames.add(fieldName);\n    }\n    // To support the use of the default field name\n    if (defaultField != null) {\n      fieldNames.add(defaultField);\n    }\n    \n    Map<String, SpanQuery> queries = new HashMap<String, SpanQuery>();\n \n    Set<Term> nonWeightedTerms = new HashSet<Term>();\n    final boolean mustRewriteQuery = mustRewriteQuery(spanQuery);\n    if (mustRewriteQuery) {\n      for (final String field : fieldNames) {\n        final SpanQuery rewrittenQuery = (SpanQuery) spanQuery.rewrite(getLeafContextForField(field).reader());\n        queries.put(field, rewrittenQuery);\n        rewrittenQuery.extractTerms(nonWeightedTerms);\n      }\n    } else {\n      spanQuery.extractTerms(nonWeightedTerms);\n    }\n\n    List<PositionSpan> spanPositions = new ArrayList<PositionSpan>();\n\n    for (final String field : fieldNames) {\n      final SpanQuery q;\n      if (mustRewriteQuery) {\n        q = queries.get(field);\n      } else {\n        q = spanQuery;\n      }\n      AtomicReaderContext context = getLeafContextForField(field);\n      Map<Term,TermContext> termContexts = new HashMap<Term,TermContext>();\n      TreeSet<Term> extractedTerms = new TreeSet<Term>();\n      q.extractTerms(extractedTerms);\n      for (Term term : extractedTerms) {\n        termContexts.put(term, TermContext.build(context, term, true));\n      }\n      Bits acceptDocs = context.reader().getLiveDocs();\n      final Spans spans = q.getSpans(context, acceptDocs, termContexts);\n\n      // collect span positions\n      while (spans.next()) {\n        spanPositions.add(new PositionSpan(spans.start(), spans.end() - 1));\n      }\n      \n    }\n\n    if (spanPositions.size() == 0) {\n      // no spans found\n      return;\n    }\n\n    for (final Term queryTerm :  nonWeightedTerms) {\n\n      if (fieldNameComparator(queryTerm.field())) {\n        WeightedSpanTerm weightedSpanTerm = terms.get(queryTerm.text());\n\n        if (weightedSpanTerm == null) {\n          weightedSpanTerm = new WeightedSpanTerm(spanQuery.getBoost(), queryTerm.text());\n          weightedSpanTerm.addPositionSpans(spanPositions);\n          weightedSpanTerm.positionSensitive = true;\n          terms.put(queryTerm.text(), weightedSpanTerm);\n        } else {\n          if (spanPositions.size() > 0) {\n            weightedSpanTerm.addPositionSpans(spanPositions);\n          }\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c7bd1fdddb8e84c1857d1a55c32ced51f0ed2069","date":1348430063,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/highlighter/src/java/org/apache/lucene/search/highlight/WeightedSpanTermExtractor#extractWeightedSpanTerms(Map[String,WeightedSpanTerm],SpanQuery).mjava","pathOld":"lucene/highlighter/src/java/org/apache/lucene/search/highlight/WeightedSpanTermExtractor#extractWeightedSpanTerms(Map[String,WeightedSpanTerm],SpanQuery).mjava","sourceNew":"  /**\n   * Fills a <code>Map</code> with <@link WeightedSpanTerm>s using the terms from the supplied <code>SpanQuery</code>.\n   * \n   * @param terms\n   *          Map to place created WeightedSpanTerms in\n   * @param spanQuery\n   *          SpanQuery to extract Terms from\n   * @throws IOException If there is a low-level I/O error\n   */\n  protected void extractWeightedSpanTerms(Map<String,WeightedSpanTerm> terms, SpanQuery spanQuery) throws IOException {\n    Set<String> fieldNames;\n\n    if (fieldName == null) {\n      fieldNames = new HashSet<String>();\n      collectSpanQueryFields(spanQuery, fieldNames);\n    } else {\n      fieldNames = new HashSet<String>(1);\n      fieldNames.add(fieldName);\n    }\n    // To support the use of the default field name\n    if (defaultField != null) {\n      fieldNames.add(defaultField);\n    }\n    \n    Map<String, SpanQuery> queries = new HashMap<String, SpanQuery>();\n \n    Set<Term> nonWeightedTerms = new HashSet<Term>();\n    final boolean mustRewriteQuery = mustRewriteQuery(spanQuery);\n    if (mustRewriteQuery) {\n      for (final String field : fieldNames) {\n        final SpanQuery rewrittenQuery = (SpanQuery) spanQuery.rewrite(getLeafContextForField(field).reader());\n        queries.put(field, rewrittenQuery);\n        rewrittenQuery.extractTerms(nonWeightedTerms);\n      }\n    } else {\n      spanQuery.extractTerms(nonWeightedTerms);\n    }\n\n    List<PositionSpan> spanPositions = new ArrayList<PositionSpan>();\n\n    for (final String field : fieldNames) {\n      final SpanQuery q;\n      if (mustRewriteQuery) {\n        q = queries.get(field);\n      } else {\n        q = spanQuery;\n      }\n      AtomicReaderContext context = getLeafContextForField(field);\n      Map<Term,TermContext> termContexts = new HashMap<Term,TermContext>();\n      TreeSet<Term> extractedTerms = new TreeSet<Term>();\n      q.extractTerms(extractedTerms);\n      for (Term term : extractedTerms) {\n        termContexts.put(term, TermContext.build(context, term, true));\n      }\n      Bits acceptDocs = context.reader().getLiveDocs();\n      final Spans spans = q.getSpans(context, acceptDocs, termContexts);\n\n      // collect span positions\n      while (spans.next()) {\n        spanPositions.add(new PositionSpan(spans.start(), spans.end() - 1));\n      }\n      \n    }\n\n    if (spanPositions.size() == 0) {\n      // no spans found\n      return;\n    }\n\n    for (final Term queryTerm :  nonWeightedTerms) {\n\n      if (fieldNameComparator(queryTerm.field())) {\n        WeightedSpanTerm weightedSpanTerm = terms.get(queryTerm.text());\n\n        if (weightedSpanTerm == null) {\n          weightedSpanTerm = new WeightedSpanTerm(spanQuery.getBoost(), queryTerm.text());\n          weightedSpanTerm.addPositionSpans(spanPositions);\n          weightedSpanTerm.positionSensitive = true;\n          terms.put(queryTerm.text(), weightedSpanTerm);\n        } else {\n          if (spanPositions.size() > 0) {\n            weightedSpanTerm.addPositionSpans(spanPositions);\n          }\n        }\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Fills a <code>Map</code> with <@link WeightedSpanTerm>s using the terms from the supplied <code>SpanQuery</code>.\n   * \n   * @param terms\n   *          Map to place created WeightedSpanTerms in\n   * @param spanQuery\n   *          SpanQuery to extract Terms from\n   * @throws IOException\n   */\n  protected void extractWeightedSpanTerms(Map<String,WeightedSpanTerm> terms, SpanQuery spanQuery) throws IOException {\n    Set<String> fieldNames;\n\n    if (fieldName == null) {\n      fieldNames = new HashSet<String>();\n      collectSpanQueryFields(spanQuery, fieldNames);\n    } else {\n      fieldNames = new HashSet<String>(1);\n      fieldNames.add(fieldName);\n    }\n    // To support the use of the default field name\n    if (defaultField != null) {\n      fieldNames.add(defaultField);\n    }\n    \n    Map<String, SpanQuery> queries = new HashMap<String, SpanQuery>();\n \n    Set<Term> nonWeightedTerms = new HashSet<Term>();\n    final boolean mustRewriteQuery = mustRewriteQuery(spanQuery);\n    if (mustRewriteQuery) {\n      for (final String field : fieldNames) {\n        final SpanQuery rewrittenQuery = (SpanQuery) spanQuery.rewrite(getLeafContextForField(field).reader());\n        queries.put(field, rewrittenQuery);\n        rewrittenQuery.extractTerms(nonWeightedTerms);\n      }\n    } else {\n      spanQuery.extractTerms(nonWeightedTerms);\n    }\n\n    List<PositionSpan> spanPositions = new ArrayList<PositionSpan>();\n\n    for (final String field : fieldNames) {\n      final SpanQuery q;\n      if (mustRewriteQuery) {\n        q = queries.get(field);\n      } else {\n        q = spanQuery;\n      }\n      AtomicReaderContext context = getLeafContextForField(field);\n      Map<Term,TermContext> termContexts = new HashMap<Term,TermContext>();\n      TreeSet<Term> extractedTerms = new TreeSet<Term>();\n      q.extractTerms(extractedTerms);\n      for (Term term : extractedTerms) {\n        termContexts.put(term, TermContext.build(context, term, true));\n      }\n      Bits acceptDocs = context.reader().getLiveDocs();\n      final Spans spans = q.getSpans(context, acceptDocs, termContexts);\n\n      // collect span positions\n      while (spans.next()) {\n        spanPositions.add(new PositionSpan(spans.start(), spans.end() - 1));\n      }\n      \n    }\n\n    if (spanPositions.size() == 0) {\n      // no spans found\n      return;\n    }\n\n    for (final Term queryTerm :  nonWeightedTerms) {\n\n      if (fieldNameComparator(queryTerm.field())) {\n        WeightedSpanTerm weightedSpanTerm = terms.get(queryTerm.text());\n\n        if (weightedSpanTerm == null) {\n          weightedSpanTerm = new WeightedSpanTerm(spanQuery.getBoost(), queryTerm.text());\n          weightedSpanTerm.addPositionSpans(spanPositions);\n          weightedSpanTerm.positionSensitive = true;\n          terms.put(queryTerm.text(), weightedSpanTerm);\n        } else {\n          if (spanPositions.size() > 0) {\n            weightedSpanTerm.addPositionSpans(spanPositions);\n          }\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"081b68cb9e8f4b5405b40bfb223fd7c587171aa1","date":1360072766,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/highlighter/src/java/org/apache/lucene/search/highlight/WeightedSpanTermExtractor#extractWeightedSpanTerms(Map[String,WeightedSpanTerm],SpanQuery).mjava","pathOld":"lucene/highlighter/src/java/org/apache/lucene/search/highlight/WeightedSpanTermExtractor#extractWeightedSpanTerms(Map[String,WeightedSpanTerm],SpanQuery).mjava","sourceNew":"  /**\n   * Fills a <code>Map</code> with <@link WeightedSpanTerm>s using the terms from the supplied <code>SpanQuery</code>.\n   * \n   * @param terms\n   *          Map to place created WeightedSpanTerms in\n   * @param spanQuery\n   *          SpanQuery to extract Terms from\n   * @throws IOException If there is a low-level I/O error\n   */\n  protected void extractWeightedSpanTerms(Map<String,WeightedSpanTerm> terms, SpanQuery spanQuery) throws IOException {\n    Set<String> fieldNames;\n\n    if (fieldName == null) {\n      fieldNames = new HashSet<String>();\n      collectSpanQueryFields(spanQuery, fieldNames);\n    } else {\n      fieldNames = new HashSet<String>(1);\n      fieldNames.add(fieldName);\n    }\n    // To support the use of the default field name\n    if (defaultField != null) {\n      fieldNames.add(defaultField);\n    }\n    \n    Map<String, SpanQuery> queries = new HashMap<String, SpanQuery>();\n \n    Set<Term> nonWeightedTerms = new HashSet<Term>();\n    final boolean mustRewriteQuery = mustRewriteQuery(spanQuery);\n    if (mustRewriteQuery) {\n      for (final String field : fieldNames) {\n        final SpanQuery rewrittenQuery = (SpanQuery) spanQuery.rewrite(getLeafContext().reader());\n        queries.put(field, rewrittenQuery);\n        rewrittenQuery.extractTerms(nonWeightedTerms);\n      }\n    } else {\n      spanQuery.extractTerms(nonWeightedTerms);\n    }\n\n    List<PositionSpan> spanPositions = new ArrayList<PositionSpan>();\n\n    for (final String field : fieldNames) {\n      final SpanQuery q;\n      if (mustRewriteQuery) {\n        q = queries.get(field);\n      } else {\n        q = spanQuery;\n      }\n      AtomicReaderContext context = getLeafContext();\n      Map<Term,TermContext> termContexts = new HashMap<Term,TermContext>();\n      TreeSet<Term> extractedTerms = new TreeSet<Term>();\n      q.extractTerms(extractedTerms);\n      for (Term term : extractedTerms) {\n        termContexts.put(term, TermContext.build(context, term, true));\n      }\n      Bits acceptDocs = context.reader().getLiveDocs();\n      final Spans spans = q.getSpans(context, acceptDocs, termContexts);\n\n      // collect span positions\n      while (spans.next()) {\n        spanPositions.add(new PositionSpan(spans.start(), spans.end() - 1));\n      }\n      \n    }\n\n    if (spanPositions.size() == 0) {\n      // no spans found\n      return;\n    }\n\n    for (final Term queryTerm :  nonWeightedTerms) {\n\n      if (fieldNameComparator(queryTerm.field())) {\n        WeightedSpanTerm weightedSpanTerm = terms.get(queryTerm.text());\n\n        if (weightedSpanTerm == null) {\n          weightedSpanTerm = new WeightedSpanTerm(spanQuery.getBoost(), queryTerm.text());\n          weightedSpanTerm.addPositionSpans(spanPositions);\n          weightedSpanTerm.positionSensitive = true;\n          terms.put(queryTerm.text(), weightedSpanTerm);\n        } else {\n          if (spanPositions.size() > 0) {\n            weightedSpanTerm.addPositionSpans(spanPositions);\n          }\n        }\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Fills a <code>Map</code> with <@link WeightedSpanTerm>s using the terms from the supplied <code>SpanQuery</code>.\n   * \n   * @param terms\n   *          Map to place created WeightedSpanTerms in\n   * @param spanQuery\n   *          SpanQuery to extract Terms from\n   * @throws IOException If there is a low-level I/O error\n   */\n  protected void extractWeightedSpanTerms(Map<String,WeightedSpanTerm> terms, SpanQuery spanQuery) throws IOException {\n    Set<String> fieldNames;\n\n    if (fieldName == null) {\n      fieldNames = new HashSet<String>();\n      collectSpanQueryFields(spanQuery, fieldNames);\n    } else {\n      fieldNames = new HashSet<String>(1);\n      fieldNames.add(fieldName);\n    }\n    // To support the use of the default field name\n    if (defaultField != null) {\n      fieldNames.add(defaultField);\n    }\n    \n    Map<String, SpanQuery> queries = new HashMap<String, SpanQuery>();\n \n    Set<Term> nonWeightedTerms = new HashSet<Term>();\n    final boolean mustRewriteQuery = mustRewriteQuery(spanQuery);\n    if (mustRewriteQuery) {\n      for (final String field : fieldNames) {\n        final SpanQuery rewrittenQuery = (SpanQuery) spanQuery.rewrite(getLeafContextForField(field).reader());\n        queries.put(field, rewrittenQuery);\n        rewrittenQuery.extractTerms(nonWeightedTerms);\n      }\n    } else {\n      spanQuery.extractTerms(nonWeightedTerms);\n    }\n\n    List<PositionSpan> spanPositions = new ArrayList<PositionSpan>();\n\n    for (final String field : fieldNames) {\n      final SpanQuery q;\n      if (mustRewriteQuery) {\n        q = queries.get(field);\n      } else {\n        q = spanQuery;\n      }\n      AtomicReaderContext context = getLeafContextForField(field);\n      Map<Term,TermContext> termContexts = new HashMap<Term,TermContext>();\n      TreeSet<Term> extractedTerms = new TreeSet<Term>();\n      q.extractTerms(extractedTerms);\n      for (Term term : extractedTerms) {\n        termContexts.put(term, TermContext.build(context, term, true));\n      }\n      Bits acceptDocs = context.reader().getLiveDocs();\n      final Spans spans = q.getSpans(context, acceptDocs, termContexts);\n\n      // collect span positions\n      while (spans.next()) {\n        spanPositions.add(new PositionSpan(spans.start(), spans.end() - 1));\n      }\n      \n    }\n\n    if (spanPositions.size() == 0) {\n      // no spans found\n      return;\n    }\n\n    for (final Term queryTerm :  nonWeightedTerms) {\n\n      if (fieldNameComparator(queryTerm.field())) {\n        WeightedSpanTerm weightedSpanTerm = terms.get(queryTerm.text());\n\n        if (weightedSpanTerm == null) {\n          weightedSpanTerm = new WeightedSpanTerm(spanQuery.getBoost(), queryTerm.text());\n          weightedSpanTerm.addPositionSpans(spanPositions);\n          weightedSpanTerm.positionSensitive = true;\n          terms.put(queryTerm.text(), weightedSpanTerm);\n        } else {\n          if (spanPositions.size() > 0) {\n            weightedSpanTerm.addPositionSpans(spanPositions);\n          }\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3e4d4ec39bf5396230748ca859ff05ab024b6fc5","date":1360112310,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/highlighter/src/java/org/apache/lucene/search/highlight/WeightedSpanTermExtractor#extractWeightedSpanTerms(Map[String,WeightedSpanTerm],SpanQuery).mjava","pathOld":"lucene/highlighter/src/java/org/apache/lucene/search/highlight/WeightedSpanTermExtractor#extractWeightedSpanTerms(Map[String,WeightedSpanTerm],SpanQuery).mjava","sourceNew":"  /**\n   * Fills a <code>Map</code> with <@link WeightedSpanTerm>s using the terms from the supplied <code>SpanQuery</code>.\n   * \n   * @param terms\n   *          Map to place created WeightedSpanTerms in\n   * @param spanQuery\n   *          SpanQuery to extract Terms from\n   * @throws IOException If there is a low-level I/O error\n   */\n  protected void extractWeightedSpanTerms(Map<String,WeightedSpanTerm> terms, SpanQuery spanQuery) throws IOException {\n    Set<String> fieldNames;\n\n    if (fieldName == null) {\n      fieldNames = new HashSet<String>();\n      collectSpanQueryFields(spanQuery, fieldNames);\n    } else {\n      fieldNames = new HashSet<String>(1);\n      fieldNames.add(fieldName);\n    }\n    // To support the use of the default field name\n    if (defaultField != null) {\n      fieldNames.add(defaultField);\n    }\n    \n    Map<String, SpanQuery> queries = new HashMap<String, SpanQuery>();\n \n    Set<Term> nonWeightedTerms = new HashSet<Term>();\n    final boolean mustRewriteQuery = mustRewriteQuery(spanQuery);\n    if (mustRewriteQuery) {\n      for (final String field : fieldNames) {\n        final SpanQuery rewrittenQuery = (SpanQuery) spanQuery.rewrite(getLeafContext().reader());\n        queries.put(field, rewrittenQuery);\n        rewrittenQuery.extractTerms(nonWeightedTerms);\n      }\n    } else {\n      spanQuery.extractTerms(nonWeightedTerms);\n    }\n\n    List<PositionSpan> spanPositions = new ArrayList<PositionSpan>();\n\n    for (final String field : fieldNames) {\n      final SpanQuery q;\n      if (mustRewriteQuery) {\n        q = queries.get(field);\n      } else {\n        q = spanQuery;\n      }\n      AtomicReaderContext context = getLeafContext();\n      Map<Term,TermContext> termContexts = new HashMap<Term,TermContext>();\n      TreeSet<Term> extractedTerms = new TreeSet<Term>();\n      q.extractTerms(extractedTerms);\n      for (Term term : extractedTerms) {\n        termContexts.put(term, TermContext.build(context, term, true));\n      }\n      Bits acceptDocs = context.reader().getLiveDocs();\n      final Spans spans = q.getSpans(context, acceptDocs, termContexts);\n\n      // collect span positions\n      while (spans.next()) {\n        spanPositions.add(new PositionSpan(spans.start(), spans.end() - 1));\n      }\n      \n    }\n\n    if (spanPositions.size() == 0) {\n      // no spans found\n      return;\n    }\n\n    for (final Term queryTerm :  nonWeightedTerms) {\n\n      if (fieldNameComparator(queryTerm.field())) {\n        WeightedSpanTerm weightedSpanTerm = terms.get(queryTerm.text());\n\n        if (weightedSpanTerm == null) {\n          weightedSpanTerm = new WeightedSpanTerm(spanQuery.getBoost(), queryTerm.text());\n          weightedSpanTerm.addPositionSpans(spanPositions);\n          weightedSpanTerm.positionSensitive = true;\n          terms.put(queryTerm.text(), weightedSpanTerm);\n        } else {\n          if (spanPositions.size() > 0) {\n            weightedSpanTerm.addPositionSpans(spanPositions);\n          }\n        }\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Fills a <code>Map</code> with <@link WeightedSpanTerm>s using the terms from the supplied <code>SpanQuery</code>.\n   * \n   * @param terms\n   *          Map to place created WeightedSpanTerms in\n   * @param spanQuery\n   *          SpanQuery to extract Terms from\n   * @throws IOException If there is a low-level I/O error\n   */\n  protected void extractWeightedSpanTerms(Map<String,WeightedSpanTerm> terms, SpanQuery spanQuery) throws IOException {\n    Set<String> fieldNames;\n\n    if (fieldName == null) {\n      fieldNames = new HashSet<String>();\n      collectSpanQueryFields(spanQuery, fieldNames);\n    } else {\n      fieldNames = new HashSet<String>(1);\n      fieldNames.add(fieldName);\n    }\n    // To support the use of the default field name\n    if (defaultField != null) {\n      fieldNames.add(defaultField);\n    }\n    \n    Map<String, SpanQuery> queries = new HashMap<String, SpanQuery>();\n \n    Set<Term> nonWeightedTerms = new HashSet<Term>();\n    final boolean mustRewriteQuery = mustRewriteQuery(spanQuery);\n    if (mustRewriteQuery) {\n      for (final String field : fieldNames) {\n        final SpanQuery rewrittenQuery = (SpanQuery) spanQuery.rewrite(getLeafContextForField(field).reader());\n        queries.put(field, rewrittenQuery);\n        rewrittenQuery.extractTerms(nonWeightedTerms);\n      }\n    } else {\n      spanQuery.extractTerms(nonWeightedTerms);\n    }\n\n    List<PositionSpan> spanPositions = new ArrayList<PositionSpan>();\n\n    for (final String field : fieldNames) {\n      final SpanQuery q;\n      if (mustRewriteQuery) {\n        q = queries.get(field);\n      } else {\n        q = spanQuery;\n      }\n      AtomicReaderContext context = getLeafContextForField(field);\n      Map<Term,TermContext> termContexts = new HashMap<Term,TermContext>();\n      TreeSet<Term> extractedTerms = new TreeSet<Term>();\n      q.extractTerms(extractedTerms);\n      for (Term term : extractedTerms) {\n        termContexts.put(term, TermContext.build(context, term, true));\n      }\n      Bits acceptDocs = context.reader().getLiveDocs();\n      final Spans spans = q.getSpans(context, acceptDocs, termContexts);\n\n      // collect span positions\n      while (spans.next()) {\n        spanPositions.add(new PositionSpan(spans.start(), spans.end() - 1));\n      }\n      \n    }\n\n    if (spanPositions.size() == 0) {\n      // no spans found\n      return;\n    }\n\n    for (final Term queryTerm :  nonWeightedTerms) {\n\n      if (fieldNameComparator(queryTerm.field())) {\n        WeightedSpanTerm weightedSpanTerm = terms.get(queryTerm.text());\n\n        if (weightedSpanTerm == null) {\n          weightedSpanTerm = new WeightedSpanTerm(spanQuery.getBoost(), queryTerm.text());\n          weightedSpanTerm.addPositionSpans(spanPositions);\n          weightedSpanTerm.positionSensitive = true;\n          terms.put(queryTerm.text(), weightedSpanTerm);\n        } else {\n          if (spanPositions.size() > 0) {\n            weightedSpanTerm.addPositionSpans(spanPositions);\n          }\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"eee5f2a24465d2c9a5f86ab84b7c35041a30fda8","date":1373996650,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/highlighter/src/java/org/apache/lucene/search/highlight/WeightedSpanTermExtractor#extractWeightedSpanTerms(Map[String,WeightedSpanTerm],SpanQuery).mjava","pathOld":"lucene/highlighter/src/java/org/apache/lucene/search/highlight/WeightedSpanTermExtractor#extractWeightedSpanTerms(Map[String,WeightedSpanTerm],SpanQuery).mjava","sourceNew":"  /**\n   * Fills a <code>Map</code> with <@link WeightedSpanTerm>s using the terms from the supplied <code>SpanQuery</code>.\n   * \n   * @param terms\n   *          Map to place created WeightedSpanTerms in\n   * @param spanQuery\n   *          SpanQuery to extract Terms from\n   * @throws IOException If there is a low-level I/O error\n   */\n  protected void extractWeightedSpanTerms(Map<String,WeightedSpanTerm> terms, SpanQuery spanQuery) throws IOException {\n    Set<String> fieldNames;\n\n    if (fieldName == null) {\n      fieldNames = new HashSet<String>();\n      collectSpanQueryFields(spanQuery, fieldNames);\n    } else {\n      fieldNames = new HashSet<String>(1);\n      fieldNames.add(fieldName);\n    }\n    // To support the use of the default field name\n    if (defaultField != null) {\n      fieldNames.add(defaultField);\n    }\n    \n    Map<String, SpanQuery> queries = new HashMap<String, SpanQuery>();\n \n    Set<Term> nonWeightedTerms = new HashSet<Term>();\n    final boolean mustRewriteQuery = mustRewriteQuery(spanQuery);\n    if (mustRewriteQuery) {\n      for (final String field : fieldNames) {\n        final SpanQuery rewrittenQuery = (SpanQuery) spanQuery.rewrite(getLeafContext().reader());\n        queries.put(field, rewrittenQuery);\n        rewrittenQuery.extractTerms(nonWeightedTerms);\n      }\n    } else {\n      spanQuery.extractTerms(nonWeightedTerms);\n    }\n\n    List<PositionSpan> spanPositions = new ArrayList<PositionSpan>();\n\n    for (final String field : fieldNames) {\n      final SpanQuery q;\n      if (mustRewriteQuery) {\n        q = queries.get(field);\n      } else {\n        q = spanQuery;\n      }\n      AtomicReaderContext context = getLeafContext();\n      Map<Term,TermContext> termContexts = new HashMap<Term,TermContext>();\n      TreeSet<Term> extractedTerms = new TreeSet<Term>();\n      q.extractTerms(extractedTerms);\n      for (Term term : extractedTerms) {\n        termContexts.put(term, TermContext.build(context, term));\n      }\n      Bits acceptDocs = context.reader().getLiveDocs();\n      final Spans spans = q.getSpans(context, acceptDocs, termContexts);\n\n      // collect span positions\n      while (spans.next()) {\n        spanPositions.add(new PositionSpan(spans.start(), spans.end() - 1));\n      }\n      \n    }\n\n    if (spanPositions.size() == 0) {\n      // no spans found\n      return;\n    }\n\n    for (final Term queryTerm :  nonWeightedTerms) {\n\n      if (fieldNameComparator(queryTerm.field())) {\n        WeightedSpanTerm weightedSpanTerm = terms.get(queryTerm.text());\n\n        if (weightedSpanTerm == null) {\n          weightedSpanTerm = new WeightedSpanTerm(spanQuery.getBoost(), queryTerm.text());\n          weightedSpanTerm.addPositionSpans(spanPositions);\n          weightedSpanTerm.positionSensitive = true;\n          terms.put(queryTerm.text(), weightedSpanTerm);\n        } else {\n          if (spanPositions.size() > 0) {\n            weightedSpanTerm.addPositionSpans(spanPositions);\n          }\n        }\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Fills a <code>Map</code> with <@link WeightedSpanTerm>s using the terms from the supplied <code>SpanQuery</code>.\n   * \n   * @param terms\n   *          Map to place created WeightedSpanTerms in\n   * @param spanQuery\n   *          SpanQuery to extract Terms from\n   * @throws IOException If there is a low-level I/O error\n   */\n  protected void extractWeightedSpanTerms(Map<String,WeightedSpanTerm> terms, SpanQuery spanQuery) throws IOException {\n    Set<String> fieldNames;\n\n    if (fieldName == null) {\n      fieldNames = new HashSet<String>();\n      collectSpanQueryFields(spanQuery, fieldNames);\n    } else {\n      fieldNames = new HashSet<String>(1);\n      fieldNames.add(fieldName);\n    }\n    // To support the use of the default field name\n    if (defaultField != null) {\n      fieldNames.add(defaultField);\n    }\n    \n    Map<String, SpanQuery> queries = new HashMap<String, SpanQuery>();\n \n    Set<Term> nonWeightedTerms = new HashSet<Term>();\n    final boolean mustRewriteQuery = mustRewriteQuery(spanQuery);\n    if (mustRewriteQuery) {\n      for (final String field : fieldNames) {\n        final SpanQuery rewrittenQuery = (SpanQuery) spanQuery.rewrite(getLeafContext().reader());\n        queries.put(field, rewrittenQuery);\n        rewrittenQuery.extractTerms(nonWeightedTerms);\n      }\n    } else {\n      spanQuery.extractTerms(nonWeightedTerms);\n    }\n\n    List<PositionSpan> spanPositions = new ArrayList<PositionSpan>();\n\n    for (final String field : fieldNames) {\n      final SpanQuery q;\n      if (mustRewriteQuery) {\n        q = queries.get(field);\n      } else {\n        q = spanQuery;\n      }\n      AtomicReaderContext context = getLeafContext();\n      Map<Term,TermContext> termContexts = new HashMap<Term,TermContext>();\n      TreeSet<Term> extractedTerms = new TreeSet<Term>();\n      q.extractTerms(extractedTerms);\n      for (Term term : extractedTerms) {\n        termContexts.put(term, TermContext.build(context, term, true));\n      }\n      Bits acceptDocs = context.reader().getLiveDocs();\n      final Spans spans = q.getSpans(context, acceptDocs, termContexts);\n\n      // collect span positions\n      while (spans.next()) {\n        spanPositions.add(new PositionSpan(spans.start(), spans.end() - 1));\n      }\n      \n    }\n\n    if (spanPositions.size() == 0) {\n      // no spans found\n      return;\n    }\n\n    for (final Term queryTerm :  nonWeightedTerms) {\n\n      if (fieldNameComparator(queryTerm.field())) {\n        WeightedSpanTerm weightedSpanTerm = terms.get(queryTerm.text());\n\n        if (weightedSpanTerm == null) {\n          weightedSpanTerm = new WeightedSpanTerm(spanQuery.getBoost(), queryTerm.text());\n          weightedSpanTerm.addPositionSpans(spanPositions);\n          weightedSpanTerm.positionSensitive = true;\n          terms.put(queryTerm.text(), weightedSpanTerm);\n        } else {\n          if (spanPositions.size() > 0) {\n            weightedSpanTerm.addPositionSpans(spanPositions);\n          }\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee","date":1376366778,"type":3,"author":"Han Jiang","isMerge":false,"pathNew":"lucene/highlighter/src/java/org/apache/lucene/search/highlight/WeightedSpanTermExtractor#extractWeightedSpanTerms(Map[String,WeightedSpanTerm],SpanQuery).mjava","pathOld":"lucene/highlighter/src/java/org/apache/lucene/search/highlight/WeightedSpanTermExtractor#extractWeightedSpanTerms(Map[String,WeightedSpanTerm],SpanQuery).mjava","sourceNew":"  /**\n   * Fills a <code>Map</code> with <@link WeightedSpanTerm>s using the terms from the supplied <code>SpanQuery</code>.\n   * \n   * @param terms\n   *          Map to place created WeightedSpanTerms in\n   * @param spanQuery\n   *          SpanQuery to extract Terms from\n   * @throws IOException If there is a low-level I/O error\n   */\n  protected void extractWeightedSpanTerms(Map<String,WeightedSpanTerm> terms, SpanQuery spanQuery) throws IOException {\n    Set<String> fieldNames;\n\n    if (fieldName == null) {\n      fieldNames = new HashSet<String>();\n      collectSpanQueryFields(spanQuery, fieldNames);\n    } else {\n      fieldNames = new HashSet<String>(1);\n      fieldNames.add(fieldName);\n    }\n    // To support the use of the default field name\n    if (defaultField != null) {\n      fieldNames.add(defaultField);\n    }\n    \n    Map<String, SpanQuery> queries = new HashMap<String, SpanQuery>();\n \n    Set<Term> nonWeightedTerms = new HashSet<Term>();\n    final boolean mustRewriteQuery = mustRewriteQuery(spanQuery);\n    if (mustRewriteQuery) {\n      for (final String field : fieldNames) {\n        final SpanQuery rewrittenQuery = (SpanQuery) spanQuery.rewrite(getLeafContext().reader());\n        queries.put(field, rewrittenQuery);\n        rewrittenQuery.extractTerms(nonWeightedTerms);\n      }\n    } else {\n      spanQuery.extractTerms(nonWeightedTerms);\n    }\n\n    List<PositionSpan> spanPositions = new ArrayList<PositionSpan>();\n\n    for (final String field : fieldNames) {\n      final SpanQuery q;\n      if (mustRewriteQuery) {\n        q = queries.get(field);\n      } else {\n        q = spanQuery;\n      }\n      AtomicReaderContext context = getLeafContext();\n      Map<Term,TermContext> termContexts = new HashMap<Term,TermContext>();\n      TreeSet<Term> extractedTerms = new TreeSet<Term>();\n      q.extractTerms(extractedTerms);\n      for (Term term : extractedTerms) {\n        termContexts.put(term, TermContext.build(context, term));\n      }\n      Bits acceptDocs = context.reader().getLiveDocs();\n      final Spans spans = q.getSpans(context, acceptDocs, termContexts);\n\n      // collect span positions\n      while (spans.next()) {\n        spanPositions.add(new PositionSpan(spans.start(), spans.end() - 1));\n      }\n      \n    }\n\n    if (spanPositions.size() == 0) {\n      // no spans found\n      return;\n    }\n\n    for (final Term queryTerm :  nonWeightedTerms) {\n\n      if (fieldNameComparator(queryTerm.field())) {\n        WeightedSpanTerm weightedSpanTerm = terms.get(queryTerm.text());\n\n        if (weightedSpanTerm == null) {\n          weightedSpanTerm = new WeightedSpanTerm(spanQuery.getBoost(), queryTerm.text());\n          weightedSpanTerm.addPositionSpans(spanPositions);\n          weightedSpanTerm.positionSensitive = true;\n          terms.put(queryTerm.text(), weightedSpanTerm);\n        } else {\n          if (spanPositions.size() > 0) {\n            weightedSpanTerm.addPositionSpans(spanPositions);\n          }\n        }\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Fills a <code>Map</code> with <@link WeightedSpanTerm>s using the terms from the supplied <code>SpanQuery</code>.\n   * \n   * @param terms\n   *          Map to place created WeightedSpanTerms in\n   * @param spanQuery\n   *          SpanQuery to extract Terms from\n   * @throws IOException If there is a low-level I/O error\n   */\n  protected void extractWeightedSpanTerms(Map<String,WeightedSpanTerm> terms, SpanQuery spanQuery) throws IOException {\n    Set<String> fieldNames;\n\n    if (fieldName == null) {\n      fieldNames = new HashSet<String>();\n      collectSpanQueryFields(spanQuery, fieldNames);\n    } else {\n      fieldNames = new HashSet<String>(1);\n      fieldNames.add(fieldName);\n    }\n    // To support the use of the default field name\n    if (defaultField != null) {\n      fieldNames.add(defaultField);\n    }\n    \n    Map<String, SpanQuery> queries = new HashMap<String, SpanQuery>();\n \n    Set<Term> nonWeightedTerms = new HashSet<Term>();\n    final boolean mustRewriteQuery = mustRewriteQuery(spanQuery);\n    if (mustRewriteQuery) {\n      for (final String field : fieldNames) {\n        final SpanQuery rewrittenQuery = (SpanQuery) spanQuery.rewrite(getLeafContext().reader());\n        queries.put(field, rewrittenQuery);\n        rewrittenQuery.extractTerms(nonWeightedTerms);\n      }\n    } else {\n      spanQuery.extractTerms(nonWeightedTerms);\n    }\n\n    List<PositionSpan> spanPositions = new ArrayList<PositionSpan>();\n\n    for (final String field : fieldNames) {\n      final SpanQuery q;\n      if (mustRewriteQuery) {\n        q = queries.get(field);\n      } else {\n        q = spanQuery;\n      }\n      AtomicReaderContext context = getLeafContext();\n      Map<Term,TermContext> termContexts = new HashMap<Term,TermContext>();\n      TreeSet<Term> extractedTerms = new TreeSet<Term>();\n      q.extractTerms(extractedTerms);\n      for (Term term : extractedTerms) {\n        termContexts.put(term, TermContext.build(context, term, true));\n      }\n      Bits acceptDocs = context.reader().getLiveDocs();\n      final Spans spans = q.getSpans(context, acceptDocs, termContexts);\n\n      // collect span positions\n      while (spans.next()) {\n        spanPositions.add(new PositionSpan(spans.start(), spans.end() - 1));\n      }\n      \n    }\n\n    if (spanPositions.size() == 0) {\n      // no spans found\n      return;\n    }\n\n    for (final Term queryTerm :  nonWeightedTerms) {\n\n      if (fieldNameComparator(queryTerm.field())) {\n        WeightedSpanTerm weightedSpanTerm = terms.get(queryTerm.text());\n\n        if (weightedSpanTerm == null) {\n          weightedSpanTerm = new WeightedSpanTerm(spanQuery.getBoost(), queryTerm.text());\n          weightedSpanTerm.addPositionSpans(spanPositions);\n          weightedSpanTerm.positionSensitive = true;\n          terms.put(queryTerm.text(), weightedSpanTerm);\n        } else {\n          if (spanPositions.size() > 0) {\n            weightedSpanTerm.addPositionSpans(spanPositions);\n          }\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"634f330c54fd3f9f491d52036dc3f40b4f4d8934","date":1394635157,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/highlighter/src/java/org/apache/lucene/search/highlight/WeightedSpanTermExtractor#extractWeightedSpanTerms(Map[String,WeightedSpanTerm],SpanQuery).mjava","pathOld":"lucene/highlighter/src/java/org/apache/lucene/search/highlight/WeightedSpanTermExtractor#extractWeightedSpanTerms(Map[String,WeightedSpanTerm],SpanQuery).mjava","sourceNew":"  /**\n   * Fills a <code>Map</code> with <@link WeightedSpanTerm>s using the terms from the supplied <code>SpanQuery</code>.\n   * \n   * @param terms\n   *          Map to place created WeightedSpanTerms in\n   * @param spanQuery\n   *          SpanQuery to extract Terms from\n   * @throws IOException If there is a low-level I/O error\n   */\n  protected void extractWeightedSpanTerms(Map<String,WeightedSpanTerm> terms, SpanQuery spanQuery) throws IOException {\n    Set<String> fieldNames;\n\n    if (fieldName == null) {\n      fieldNames = new HashSet<>();\n      collectSpanQueryFields(spanQuery, fieldNames);\n    } else {\n      fieldNames = new HashSet<>(1);\n      fieldNames.add(fieldName);\n    }\n    // To support the use of the default field name\n    if (defaultField != null) {\n      fieldNames.add(defaultField);\n    }\n    \n    Map<String, SpanQuery> queries = new HashMap<>();\n \n    Set<Term> nonWeightedTerms = new HashSet<>();\n    final boolean mustRewriteQuery = mustRewriteQuery(spanQuery);\n    if (mustRewriteQuery) {\n      for (final String field : fieldNames) {\n        final SpanQuery rewrittenQuery = (SpanQuery) spanQuery.rewrite(getLeafContext().reader());\n        queries.put(field, rewrittenQuery);\n        rewrittenQuery.extractTerms(nonWeightedTerms);\n      }\n    } else {\n      spanQuery.extractTerms(nonWeightedTerms);\n    }\n\n    List<PositionSpan> spanPositions = new ArrayList<>();\n\n    for (final String field : fieldNames) {\n      final SpanQuery q;\n      if (mustRewriteQuery) {\n        q = queries.get(field);\n      } else {\n        q = spanQuery;\n      }\n      AtomicReaderContext context = getLeafContext();\n      Map<Term,TermContext> termContexts = new HashMap<>();\n      TreeSet<Term> extractedTerms = new TreeSet<>();\n      q.extractTerms(extractedTerms);\n      for (Term term : extractedTerms) {\n        termContexts.put(term, TermContext.build(context, term));\n      }\n      Bits acceptDocs = context.reader().getLiveDocs();\n      final Spans spans = q.getSpans(context, acceptDocs, termContexts);\n\n      // collect span positions\n      while (spans.next()) {\n        spanPositions.add(new PositionSpan(spans.start(), spans.end() - 1));\n      }\n      \n    }\n\n    if (spanPositions.size() == 0) {\n      // no spans found\n      return;\n    }\n\n    for (final Term queryTerm :  nonWeightedTerms) {\n\n      if (fieldNameComparator(queryTerm.field())) {\n        WeightedSpanTerm weightedSpanTerm = terms.get(queryTerm.text());\n\n        if (weightedSpanTerm == null) {\n          weightedSpanTerm = new WeightedSpanTerm(spanQuery.getBoost(), queryTerm.text());\n          weightedSpanTerm.addPositionSpans(spanPositions);\n          weightedSpanTerm.positionSensitive = true;\n          terms.put(queryTerm.text(), weightedSpanTerm);\n        } else {\n          if (spanPositions.size() > 0) {\n            weightedSpanTerm.addPositionSpans(spanPositions);\n          }\n        }\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Fills a <code>Map</code> with <@link WeightedSpanTerm>s using the terms from the supplied <code>SpanQuery</code>.\n   * \n   * @param terms\n   *          Map to place created WeightedSpanTerms in\n   * @param spanQuery\n   *          SpanQuery to extract Terms from\n   * @throws IOException If there is a low-level I/O error\n   */\n  protected void extractWeightedSpanTerms(Map<String,WeightedSpanTerm> terms, SpanQuery spanQuery) throws IOException {\n    Set<String> fieldNames;\n\n    if (fieldName == null) {\n      fieldNames = new HashSet<String>();\n      collectSpanQueryFields(spanQuery, fieldNames);\n    } else {\n      fieldNames = new HashSet<String>(1);\n      fieldNames.add(fieldName);\n    }\n    // To support the use of the default field name\n    if (defaultField != null) {\n      fieldNames.add(defaultField);\n    }\n    \n    Map<String, SpanQuery> queries = new HashMap<String, SpanQuery>();\n \n    Set<Term> nonWeightedTerms = new HashSet<Term>();\n    final boolean mustRewriteQuery = mustRewriteQuery(spanQuery);\n    if (mustRewriteQuery) {\n      for (final String field : fieldNames) {\n        final SpanQuery rewrittenQuery = (SpanQuery) spanQuery.rewrite(getLeafContext().reader());\n        queries.put(field, rewrittenQuery);\n        rewrittenQuery.extractTerms(nonWeightedTerms);\n      }\n    } else {\n      spanQuery.extractTerms(nonWeightedTerms);\n    }\n\n    List<PositionSpan> spanPositions = new ArrayList<PositionSpan>();\n\n    for (final String field : fieldNames) {\n      final SpanQuery q;\n      if (mustRewriteQuery) {\n        q = queries.get(field);\n      } else {\n        q = spanQuery;\n      }\n      AtomicReaderContext context = getLeafContext();\n      Map<Term,TermContext> termContexts = new HashMap<Term,TermContext>();\n      TreeSet<Term> extractedTerms = new TreeSet<Term>();\n      q.extractTerms(extractedTerms);\n      for (Term term : extractedTerms) {\n        termContexts.put(term, TermContext.build(context, term));\n      }\n      Bits acceptDocs = context.reader().getLiveDocs();\n      final Spans spans = q.getSpans(context, acceptDocs, termContexts);\n\n      // collect span positions\n      while (spans.next()) {\n        spanPositions.add(new PositionSpan(spans.start(), spans.end() - 1));\n      }\n      \n    }\n\n    if (spanPositions.size() == 0) {\n      // no spans found\n      return;\n    }\n\n    for (final Term queryTerm :  nonWeightedTerms) {\n\n      if (fieldNameComparator(queryTerm.field())) {\n        WeightedSpanTerm weightedSpanTerm = terms.get(queryTerm.text());\n\n        if (weightedSpanTerm == null) {\n          weightedSpanTerm = new WeightedSpanTerm(spanQuery.getBoost(), queryTerm.text());\n          weightedSpanTerm.addPositionSpans(spanPositions);\n          weightedSpanTerm.positionSensitive = true;\n          terms.put(queryTerm.text(), weightedSpanTerm);\n        } else {\n          if (spanPositions.size() > 0) {\n            weightedSpanTerm.addPositionSpans(spanPositions);\n          }\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c9fb5f46e264daf5ba3860defe623a89d202dd87","date":1411516315,"type":3,"author":"Ryan Ernst","isMerge":false,"pathNew":"lucene/highlighter/src/java/org/apache/lucene/search/highlight/WeightedSpanTermExtractor#extractWeightedSpanTerms(Map[String,WeightedSpanTerm],SpanQuery).mjava","pathOld":"lucene/highlighter/src/java/org/apache/lucene/search/highlight/WeightedSpanTermExtractor#extractWeightedSpanTerms(Map[String,WeightedSpanTerm],SpanQuery).mjava","sourceNew":"  /**\n   * Fills a <code>Map</code> with <@link WeightedSpanTerm>s using the terms from the supplied <code>SpanQuery</code>.\n   * \n   * @param terms\n   *          Map to place created WeightedSpanTerms in\n   * @param spanQuery\n   *          SpanQuery to extract Terms from\n   * @throws IOException If there is a low-level I/O error\n   */\n  protected void extractWeightedSpanTerms(Map<String,WeightedSpanTerm> terms, SpanQuery spanQuery) throws IOException {\n    Set<String> fieldNames;\n\n    if (fieldName == null) {\n      fieldNames = new HashSet<>();\n      collectSpanQueryFields(spanQuery, fieldNames);\n    } else {\n      fieldNames = new HashSet<>(1);\n      fieldNames.add(fieldName);\n    }\n    // To support the use of the default field name\n    if (defaultField != null) {\n      fieldNames.add(defaultField);\n    }\n    \n    Map<String, SpanQuery> queries = new HashMap<>();\n \n    Set<Term> nonWeightedTerms = new HashSet<>();\n    final boolean mustRewriteQuery = mustRewriteQuery(spanQuery);\n    if (mustRewriteQuery) {\n      for (final String field : fieldNames) {\n        final SpanQuery rewrittenQuery = (SpanQuery) spanQuery.rewrite(getLeafContext().reader());\n        queries.put(field, rewrittenQuery);\n        rewrittenQuery.extractTerms(nonWeightedTerms);\n      }\n    } else {\n      spanQuery.extractTerms(nonWeightedTerms);\n    }\n\n    List<PositionSpan> spanPositions = new ArrayList<>();\n\n    for (final String field : fieldNames) {\n      final SpanQuery q;\n      if (mustRewriteQuery) {\n        q = queries.get(field);\n      } else {\n        q = spanQuery;\n      }\n      LeafReaderContext context = getLeafContext();\n      Map<Term,TermContext> termContexts = new HashMap<>();\n      TreeSet<Term> extractedTerms = new TreeSet<>();\n      q.extractTerms(extractedTerms);\n      for (Term term : extractedTerms) {\n        termContexts.put(term, TermContext.build(context, term));\n      }\n      Bits acceptDocs = context.reader().getLiveDocs();\n      final Spans spans = q.getSpans(context, acceptDocs, termContexts);\n\n      // collect span positions\n      while (spans.next()) {\n        spanPositions.add(new PositionSpan(spans.start(), spans.end() - 1));\n      }\n      \n    }\n\n    if (spanPositions.size() == 0) {\n      // no spans found\n      return;\n    }\n\n    for (final Term queryTerm :  nonWeightedTerms) {\n\n      if (fieldNameComparator(queryTerm.field())) {\n        WeightedSpanTerm weightedSpanTerm = terms.get(queryTerm.text());\n\n        if (weightedSpanTerm == null) {\n          weightedSpanTerm = new WeightedSpanTerm(spanQuery.getBoost(), queryTerm.text());\n          weightedSpanTerm.addPositionSpans(spanPositions);\n          weightedSpanTerm.positionSensitive = true;\n          terms.put(queryTerm.text(), weightedSpanTerm);\n        } else {\n          if (spanPositions.size() > 0) {\n            weightedSpanTerm.addPositionSpans(spanPositions);\n          }\n        }\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Fills a <code>Map</code> with <@link WeightedSpanTerm>s using the terms from the supplied <code>SpanQuery</code>.\n   * \n   * @param terms\n   *          Map to place created WeightedSpanTerms in\n   * @param spanQuery\n   *          SpanQuery to extract Terms from\n   * @throws IOException If there is a low-level I/O error\n   */\n  protected void extractWeightedSpanTerms(Map<String,WeightedSpanTerm> terms, SpanQuery spanQuery) throws IOException {\n    Set<String> fieldNames;\n\n    if (fieldName == null) {\n      fieldNames = new HashSet<>();\n      collectSpanQueryFields(spanQuery, fieldNames);\n    } else {\n      fieldNames = new HashSet<>(1);\n      fieldNames.add(fieldName);\n    }\n    // To support the use of the default field name\n    if (defaultField != null) {\n      fieldNames.add(defaultField);\n    }\n    \n    Map<String, SpanQuery> queries = new HashMap<>();\n \n    Set<Term> nonWeightedTerms = new HashSet<>();\n    final boolean mustRewriteQuery = mustRewriteQuery(spanQuery);\n    if (mustRewriteQuery) {\n      for (final String field : fieldNames) {\n        final SpanQuery rewrittenQuery = (SpanQuery) spanQuery.rewrite(getLeafContext().reader());\n        queries.put(field, rewrittenQuery);\n        rewrittenQuery.extractTerms(nonWeightedTerms);\n      }\n    } else {\n      spanQuery.extractTerms(nonWeightedTerms);\n    }\n\n    List<PositionSpan> spanPositions = new ArrayList<>();\n\n    for (final String field : fieldNames) {\n      final SpanQuery q;\n      if (mustRewriteQuery) {\n        q = queries.get(field);\n      } else {\n        q = spanQuery;\n      }\n      AtomicReaderContext context = getLeafContext();\n      Map<Term,TermContext> termContexts = new HashMap<>();\n      TreeSet<Term> extractedTerms = new TreeSet<>();\n      q.extractTerms(extractedTerms);\n      for (Term term : extractedTerms) {\n        termContexts.put(term, TermContext.build(context, term));\n      }\n      Bits acceptDocs = context.reader().getLiveDocs();\n      final Spans spans = q.getSpans(context, acceptDocs, termContexts);\n\n      // collect span positions\n      while (spans.next()) {\n        spanPositions.add(new PositionSpan(spans.start(), spans.end() - 1));\n      }\n      \n    }\n\n    if (spanPositions.size() == 0) {\n      // no spans found\n      return;\n    }\n\n    for (final Term queryTerm :  nonWeightedTerms) {\n\n      if (fieldNameComparator(queryTerm.field())) {\n        WeightedSpanTerm weightedSpanTerm = terms.get(queryTerm.text());\n\n        if (weightedSpanTerm == null) {\n          weightedSpanTerm = new WeightedSpanTerm(spanQuery.getBoost(), queryTerm.text());\n          weightedSpanTerm.addPositionSpans(spanPositions);\n          weightedSpanTerm.positionSensitive = true;\n          terms.put(queryTerm.text(), weightedSpanTerm);\n        } else {\n          if (spanPositions.size() > 0) {\n            weightedSpanTerm.addPositionSpans(spanPositions);\n          }\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b1eb427f2c6beed80d1724555fc1db003ccf3030","date":1417137397,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/highlighter/src/java/org/apache/lucene/search/highlight/WeightedSpanTermExtractor#extractWeightedSpanTerms(Map[String,WeightedSpanTerm],SpanQuery).mjava","pathOld":"lucene/highlighter/src/java/org/apache/lucene/search/highlight/WeightedSpanTermExtractor#extractWeightedSpanTerms(Map[String,WeightedSpanTerm],SpanQuery).mjava","sourceNew":"  /**\n   * Fills a <code>Map</code> with {@link WeightedSpanTerm}s using the terms from the supplied <code>SpanQuery</code>.\n   * \n   * @param terms\n   *          Map to place created WeightedSpanTerms in\n   * @param spanQuery\n   *          SpanQuery to extract Terms from\n   * @throws IOException If there is a low-level I/O error\n   */\n  protected void extractWeightedSpanTerms(Map<String,WeightedSpanTerm> terms, SpanQuery spanQuery) throws IOException {\n    Set<String> fieldNames;\n\n    if (fieldName == null) {\n      fieldNames = new HashSet<>();\n      collectSpanQueryFields(spanQuery, fieldNames);\n    } else {\n      fieldNames = new HashSet<>(1);\n      fieldNames.add(fieldName);\n    }\n    // To support the use of the default field name\n    if (defaultField != null) {\n      fieldNames.add(defaultField);\n    }\n    \n    Map<String, SpanQuery> queries = new HashMap<>();\n \n    Set<Term> nonWeightedTerms = new HashSet<>();\n    final boolean mustRewriteQuery = mustRewriteQuery(spanQuery);\n    if (mustRewriteQuery) {\n      for (final String field : fieldNames) {\n        final SpanQuery rewrittenQuery = (SpanQuery) spanQuery.rewrite(getLeafContext().reader());\n        queries.put(field, rewrittenQuery);\n        rewrittenQuery.extractTerms(nonWeightedTerms);\n      }\n    } else {\n      spanQuery.extractTerms(nonWeightedTerms);\n    }\n\n    List<PositionSpan> spanPositions = new ArrayList<>();\n\n    for (final String field : fieldNames) {\n      final SpanQuery q;\n      if (mustRewriteQuery) {\n        q = queries.get(field);\n      } else {\n        q = spanQuery;\n      }\n      LeafReaderContext context = getLeafContext();\n      Map<Term,TermContext> termContexts = new HashMap<>();\n      TreeSet<Term> extractedTerms = new TreeSet<>();\n      q.extractTerms(extractedTerms);\n      for (Term term : extractedTerms) {\n        termContexts.put(term, TermContext.build(context, term));\n      }\n      Bits acceptDocs = context.reader().getLiveDocs();\n      final Spans spans = q.getSpans(context, acceptDocs, termContexts);\n\n      // collect span positions\n      while (spans.next()) {\n        spanPositions.add(new PositionSpan(spans.start(), spans.end() - 1));\n      }\n      \n    }\n\n    if (spanPositions.size() == 0) {\n      // no spans found\n      return;\n    }\n\n    for (final Term queryTerm :  nonWeightedTerms) {\n\n      if (fieldNameComparator(queryTerm.field())) {\n        WeightedSpanTerm weightedSpanTerm = terms.get(queryTerm.text());\n\n        if (weightedSpanTerm == null) {\n          weightedSpanTerm = new WeightedSpanTerm(spanQuery.getBoost(), queryTerm.text());\n          weightedSpanTerm.addPositionSpans(spanPositions);\n          weightedSpanTerm.positionSensitive = true;\n          terms.put(queryTerm.text(), weightedSpanTerm);\n        } else {\n          if (spanPositions.size() > 0) {\n            weightedSpanTerm.addPositionSpans(spanPositions);\n          }\n        }\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Fills a <code>Map</code> with <@link WeightedSpanTerm>s using the terms from the supplied <code>SpanQuery</code>.\n   * \n   * @param terms\n   *          Map to place created WeightedSpanTerms in\n   * @param spanQuery\n   *          SpanQuery to extract Terms from\n   * @throws IOException If there is a low-level I/O error\n   */\n  protected void extractWeightedSpanTerms(Map<String,WeightedSpanTerm> terms, SpanQuery spanQuery) throws IOException {\n    Set<String> fieldNames;\n\n    if (fieldName == null) {\n      fieldNames = new HashSet<>();\n      collectSpanQueryFields(spanQuery, fieldNames);\n    } else {\n      fieldNames = new HashSet<>(1);\n      fieldNames.add(fieldName);\n    }\n    // To support the use of the default field name\n    if (defaultField != null) {\n      fieldNames.add(defaultField);\n    }\n    \n    Map<String, SpanQuery> queries = new HashMap<>();\n \n    Set<Term> nonWeightedTerms = new HashSet<>();\n    final boolean mustRewriteQuery = mustRewriteQuery(spanQuery);\n    if (mustRewriteQuery) {\n      for (final String field : fieldNames) {\n        final SpanQuery rewrittenQuery = (SpanQuery) spanQuery.rewrite(getLeafContext().reader());\n        queries.put(field, rewrittenQuery);\n        rewrittenQuery.extractTerms(nonWeightedTerms);\n      }\n    } else {\n      spanQuery.extractTerms(nonWeightedTerms);\n    }\n\n    List<PositionSpan> spanPositions = new ArrayList<>();\n\n    for (final String field : fieldNames) {\n      final SpanQuery q;\n      if (mustRewriteQuery) {\n        q = queries.get(field);\n      } else {\n        q = spanQuery;\n      }\n      LeafReaderContext context = getLeafContext();\n      Map<Term,TermContext> termContexts = new HashMap<>();\n      TreeSet<Term> extractedTerms = new TreeSet<>();\n      q.extractTerms(extractedTerms);\n      for (Term term : extractedTerms) {\n        termContexts.put(term, TermContext.build(context, term));\n      }\n      Bits acceptDocs = context.reader().getLiveDocs();\n      final Spans spans = q.getSpans(context, acceptDocs, termContexts);\n\n      // collect span positions\n      while (spans.next()) {\n        spanPositions.add(new PositionSpan(spans.start(), spans.end() - 1));\n      }\n      \n    }\n\n    if (spanPositions.size() == 0) {\n      // no spans found\n      return;\n    }\n\n    for (final Term queryTerm :  nonWeightedTerms) {\n\n      if (fieldNameComparator(queryTerm.field())) {\n        WeightedSpanTerm weightedSpanTerm = terms.get(queryTerm.text());\n\n        if (weightedSpanTerm == null) {\n          weightedSpanTerm = new WeightedSpanTerm(spanQuery.getBoost(), queryTerm.text());\n          weightedSpanTerm.addPositionSpans(spanPositions);\n          weightedSpanTerm.positionSensitive = true;\n          terms.put(queryTerm.text(), weightedSpanTerm);\n        } else {\n          if (spanPositions.size() > 0) {\n            weightedSpanTerm.addPositionSpans(spanPositions);\n          }\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"30de45e50bdc1a79a6797f34dca6271c8866cb6e","date":1427790465,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/highlighter/src/java/org/apache/lucene/search/highlight/WeightedSpanTermExtractor#extractWeightedSpanTerms(Map[String,WeightedSpanTerm],SpanQuery).mjava","pathOld":"lucene/highlighter/src/java/org/apache/lucene/search/highlight/WeightedSpanTermExtractor#extractWeightedSpanTerms(Map[String,WeightedSpanTerm],SpanQuery).mjava","sourceNew":"  /**\n   * Fills a <code>Map</code> with {@link WeightedSpanTerm}s using the terms from the supplied <code>SpanQuery</code>.\n   * \n   * @param terms\n   *          Map to place created WeightedSpanTerms in\n   * @param spanQuery\n   *          SpanQuery to extract Terms from\n   * @throws IOException If there is a low-level I/O error\n   */\n  protected void extractWeightedSpanTerms(Map<String,WeightedSpanTerm> terms, SpanQuery spanQuery) throws IOException {\n    Set<String> fieldNames;\n\n    if (fieldName == null) {\n      fieldNames = new HashSet<>();\n      collectSpanQueryFields(spanQuery, fieldNames);\n    } else {\n      fieldNames = new HashSet<>(1);\n      fieldNames.add(fieldName);\n    }\n    // To support the use of the default field name\n    if (defaultField != null) {\n      fieldNames.add(defaultField);\n    }\n    \n    Map<String, SpanQuery> queries = new HashMap<>();\n \n    Set<Term> nonWeightedTerms = new HashSet<>();\n    final boolean mustRewriteQuery = mustRewriteQuery(spanQuery);\n    if (mustRewriteQuery) {\n      for (final String field : fieldNames) {\n        final SpanQuery rewrittenQuery = (SpanQuery) spanQuery.rewrite(getLeafContext().reader());\n        queries.put(field, rewrittenQuery);\n        rewrittenQuery.extractTerms(nonWeightedTerms);\n      }\n    } else {\n      spanQuery.extractTerms(nonWeightedTerms);\n    }\n\n    List<PositionSpan> spanPositions = new ArrayList<>();\n\n    for (final String field : fieldNames) {\n      final SpanQuery q;\n      if (mustRewriteQuery) {\n        q = queries.get(field);\n      } else {\n        q = spanQuery;\n      }\n      LeafReaderContext context = getLeafContext();\n      Map<Term,TermContext> termContexts = new HashMap<>();\n      TreeSet<Term> extractedTerms = new TreeSet<>();\n      q.extractTerms(extractedTerms);\n      for (Term term : extractedTerms) {\n        termContexts.put(term, TermContext.build(context, term));\n      }\n      Bits acceptDocs = context.reader().getLiveDocs();\n      final Spans spans = q.getSpans(context, acceptDocs, termContexts);\n\n      // collect span positions\n      while (spans.nextDoc() != Spans.NO_MORE_DOCS) {\n        while (spans.nextStartPosition() != Spans.NO_MORE_POSITIONS) {\n          spanPositions.add(new PositionSpan(spans.startPosition(), spans.endPosition() - 1));\n        }\n      }\n    }\n\n    if (spanPositions.size() == 0) {\n      // no spans found\n      return;\n    }\n\n    for (final Term queryTerm :  nonWeightedTerms) {\n\n      if (fieldNameComparator(queryTerm.field())) {\n        WeightedSpanTerm weightedSpanTerm = terms.get(queryTerm.text());\n\n        if (weightedSpanTerm == null) {\n          weightedSpanTerm = new WeightedSpanTerm(spanQuery.getBoost(), queryTerm.text());\n          weightedSpanTerm.addPositionSpans(spanPositions);\n          weightedSpanTerm.positionSensitive = true;\n          terms.put(queryTerm.text(), weightedSpanTerm);\n        } else {\n          if (spanPositions.size() > 0) {\n            weightedSpanTerm.addPositionSpans(spanPositions);\n          }\n        }\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Fills a <code>Map</code> with {@link WeightedSpanTerm}s using the terms from the supplied <code>SpanQuery</code>.\n   * \n   * @param terms\n   *          Map to place created WeightedSpanTerms in\n   * @param spanQuery\n   *          SpanQuery to extract Terms from\n   * @throws IOException If there is a low-level I/O error\n   */\n  protected void extractWeightedSpanTerms(Map<String,WeightedSpanTerm> terms, SpanQuery spanQuery) throws IOException {\n    Set<String> fieldNames;\n\n    if (fieldName == null) {\n      fieldNames = new HashSet<>();\n      collectSpanQueryFields(spanQuery, fieldNames);\n    } else {\n      fieldNames = new HashSet<>(1);\n      fieldNames.add(fieldName);\n    }\n    // To support the use of the default field name\n    if (defaultField != null) {\n      fieldNames.add(defaultField);\n    }\n    \n    Map<String, SpanQuery> queries = new HashMap<>();\n \n    Set<Term> nonWeightedTerms = new HashSet<>();\n    final boolean mustRewriteQuery = mustRewriteQuery(spanQuery);\n    if (mustRewriteQuery) {\n      for (final String field : fieldNames) {\n        final SpanQuery rewrittenQuery = (SpanQuery) spanQuery.rewrite(getLeafContext().reader());\n        queries.put(field, rewrittenQuery);\n        rewrittenQuery.extractTerms(nonWeightedTerms);\n      }\n    } else {\n      spanQuery.extractTerms(nonWeightedTerms);\n    }\n\n    List<PositionSpan> spanPositions = new ArrayList<>();\n\n    for (final String field : fieldNames) {\n      final SpanQuery q;\n      if (mustRewriteQuery) {\n        q = queries.get(field);\n      } else {\n        q = spanQuery;\n      }\n      LeafReaderContext context = getLeafContext();\n      Map<Term,TermContext> termContexts = new HashMap<>();\n      TreeSet<Term> extractedTerms = new TreeSet<>();\n      q.extractTerms(extractedTerms);\n      for (Term term : extractedTerms) {\n        termContexts.put(term, TermContext.build(context, term));\n      }\n      Bits acceptDocs = context.reader().getLiveDocs();\n      final Spans spans = q.getSpans(context, acceptDocs, termContexts);\n\n      // collect span positions\n      while (spans.next()) {\n        spanPositions.add(new PositionSpan(spans.start(), spans.end() - 1));\n      }\n      \n    }\n\n    if (spanPositions.size() == 0) {\n      // no spans found\n      return;\n    }\n\n    for (final Term queryTerm :  nonWeightedTerms) {\n\n      if (fieldNameComparator(queryTerm.field())) {\n        WeightedSpanTerm weightedSpanTerm = terms.get(queryTerm.text());\n\n        if (weightedSpanTerm == null) {\n          weightedSpanTerm = new WeightedSpanTerm(spanQuery.getBoost(), queryTerm.text());\n          weightedSpanTerm.addPositionSpans(spanPositions);\n          weightedSpanTerm.positionSensitive = true;\n          terms.put(queryTerm.text(), weightedSpanTerm);\n        } else {\n          if (spanPositions.size() > 0) {\n            weightedSpanTerm.addPositionSpans(spanPositions);\n          }\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fab172655716b96f7e42376116235017a922de3a","date":1427850611,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/highlighter/src/java/org/apache/lucene/search/highlight/WeightedSpanTermExtractor#extractWeightedSpanTerms(Map[String,WeightedSpanTerm],SpanQuery).mjava","pathOld":"lucene/highlighter/src/java/org/apache/lucene/search/highlight/WeightedSpanTermExtractor#extractWeightedSpanTerms(Map[String,WeightedSpanTerm],SpanQuery).mjava","sourceNew":"  /**\n   * Fills a <code>Map</code> with {@link WeightedSpanTerm}s using the terms from the supplied <code>SpanQuery</code>.\n   * \n   * @param terms\n   *          Map to place created WeightedSpanTerms in\n   * @param spanQuery\n   *          SpanQuery to extract Terms from\n   * @throws IOException If there is a low-level I/O error\n   */\n  protected void extractWeightedSpanTerms(Map<String,WeightedSpanTerm> terms, SpanQuery spanQuery) throws IOException {\n    Set<String> fieldNames;\n\n    if (fieldName == null) {\n      fieldNames = new HashSet<>();\n      collectSpanQueryFields(spanQuery, fieldNames);\n    } else {\n      fieldNames = new HashSet<>(1);\n      fieldNames.add(fieldName);\n    }\n    // To support the use of the default field name\n    if (defaultField != null) {\n      fieldNames.add(defaultField);\n    }\n    \n    Map<String, SpanQuery> queries = new HashMap<>();\n \n    Set<Term> nonWeightedTerms = new HashSet<>();\n    final boolean mustRewriteQuery = mustRewriteQuery(spanQuery);\n    if (mustRewriteQuery) {\n      for (final String field : fieldNames) {\n        final SpanQuery rewrittenQuery = (SpanQuery) spanQuery.rewrite(getLeafContext().reader());\n        queries.put(field, rewrittenQuery);\n        rewrittenQuery.extractTerms(nonWeightedTerms);\n      }\n    } else {\n      spanQuery.extractTerms(nonWeightedTerms);\n    }\n\n    List<PositionSpan> spanPositions = new ArrayList<>();\n\n    for (final String field : fieldNames) {\n      final SpanQuery q;\n      if (mustRewriteQuery) {\n        q = queries.get(field);\n      } else {\n        q = spanQuery;\n      }\n      LeafReaderContext context = getLeafContext();\n      Map<Term,TermContext> termContexts = new HashMap<>();\n      TreeSet<Term> extractedTerms = new TreeSet<>();\n      q.extractTerms(extractedTerms);\n      for (Term term : extractedTerms) {\n        termContexts.put(term, TermContext.build(context, term));\n      }\n      Bits acceptDocs = context.reader().getLiveDocs();\n      final Spans spans = q.getSpans(context, acceptDocs, termContexts);\n\n      // collect span positions\n      while (spans.nextDoc() != Spans.NO_MORE_DOCS) {\n        while (spans.nextStartPosition() != Spans.NO_MORE_POSITIONS) {\n          spanPositions.add(new PositionSpan(spans.startPosition(), spans.endPosition() - 1));\n        }\n      }\n    }\n\n    if (spanPositions.size() == 0) {\n      // no spans found\n      return;\n    }\n\n    for (final Term queryTerm :  nonWeightedTerms) {\n\n      if (fieldNameComparator(queryTerm.field())) {\n        WeightedSpanTerm weightedSpanTerm = terms.get(queryTerm.text());\n\n        if (weightedSpanTerm == null) {\n          weightedSpanTerm = new WeightedSpanTerm(spanQuery.getBoost(), queryTerm.text());\n          weightedSpanTerm.addPositionSpans(spanPositions);\n          weightedSpanTerm.positionSensitive = true;\n          terms.put(queryTerm.text(), weightedSpanTerm);\n        } else {\n          if (spanPositions.size() > 0) {\n            weightedSpanTerm.addPositionSpans(spanPositions);\n          }\n        }\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Fills a <code>Map</code> with {@link WeightedSpanTerm}s using the terms from the supplied <code>SpanQuery</code>.\n   * \n   * @param terms\n   *          Map to place created WeightedSpanTerms in\n   * @param spanQuery\n   *          SpanQuery to extract Terms from\n   * @throws IOException If there is a low-level I/O error\n   */\n  protected void extractWeightedSpanTerms(Map<String,WeightedSpanTerm> terms, SpanQuery spanQuery) throws IOException {\n    Set<String> fieldNames;\n\n    if (fieldName == null) {\n      fieldNames = new HashSet<>();\n      collectSpanQueryFields(spanQuery, fieldNames);\n    } else {\n      fieldNames = new HashSet<>(1);\n      fieldNames.add(fieldName);\n    }\n    // To support the use of the default field name\n    if (defaultField != null) {\n      fieldNames.add(defaultField);\n    }\n    \n    Map<String, SpanQuery> queries = new HashMap<>();\n \n    Set<Term> nonWeightedTerms = new HashSet<>();\n    final boolean mustRewriteQuery = mustRewriteQuery(spanQuery);\n    if (mustRewriteQuery) {\n      for (final String field : fieldNames) {\n        final SpanQuery rewrittenQuery = (SpanQuery) spanQuery.rewrite(getLeafContext().reader());\n        queries.put(field, rewrittenQuery);\n        rewrittenQuery.extractTerms(nonWeightedTerms);\n      }\n    } else {\n      spanQuery.extractTerms(nonWeightedTerms);\n    }\n\n    List<PositionSpan> spanPositions = new ArrayList<>();\n\n    for (final String field : fieldNames) {\n      final SpanQuery q;\n      if (mustRewriteQuery) {\n        q = queries.get(field);\n      } else {\n        q = spanQuery;\n      }\n      LeafReaderContext context = getLeafContext();\n      Map<Term,TermContext> termContexts = new HashMap<>();\n      TreeSet<Term> extractedTerms = new TreeSet<>();\n      q.extractTerms(extractedTerms);\n      for (Term term : extractedTerms) {\n        termContexts.put(term, TermContext.build(context, term));\n      }\n      Bits acceptDocs = context.reader().getLiveDocs();\n      final Spans spans = q.getSpans(context, acceptDocs, termContexts);\n\n      // collect span positions\n      while (spans.next()) {\n        spanPositions.add(new PositionSpan(spans.start(), spans.end() - 1));\n      }\n      \n    }\n\n    if (spanPositions.size() == 0) {\n      // no spans found\n      return;\n    }\n\n    for (final Term queryTerm :  nonWeightedTerms) {\n\n      if (fieldNameComparator(queryTerm.field())) {\n        WeightedSpanTerm weightedSpanTerm = terms.get(queryTerm.text());\n\n        if (weightedSpanTerm == null) {\n          weightedSpanTerm = new WeightedSpanTerm(spanQuery.getBoost(), queryTerm.text());\n          weightedSpanTerm.addPositionSpans(spanPositions);\n          weightedSpanTerm.positionSensitive = true;\n          terms.put(queryTerm.text(), weightedSpanTerm);\n        } else {\n          if (spanPositions.size() > 0) {\n            weightedSpanTerm.addPositionSpans(spanPositions);\n          }\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"69fb899bdb552a5f4aba2498bbd358be2fda865b","date":1428067018,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/highlighter/src/java/org/apache/lucene/search/highlight/WeightedSpanTermExtractor#extractWeightedSpanTerms(Map[String,WeightedSpanTerm],SpanQuery).mjava","pathOld":"lucene/highlighter/src/java/org/apache/lucene/search/highlight/WeightedSpanTermExtractor#extractWeightedSpanTerms(Map[String,WeightedSpanTerm],SpanQuery).mjava","sourceNew":"  /**\n   * Fills a <code>Map</code> with {@link WeightedSpanTerm}s using the terms from the supplied <code>SpanQuery</code>.\n   * \n   * @param terms\n   *          Map to place created WeightedSpanTerms in\n   * @param spanQuery\n   *          SpanQuery to extract Terms from\n   * @throws IOException If there is a low-level I/O error\n   */\n  protected void extractWeightedSpanTerms(Map<String,WeightedSpanTerm> terms, SpanQuery spanQuery) throws IOException {\n    Set<String> fieldNames;\n\n    if (fieldName == null) {\n      fieldNames = new HashSet<>();\n      collectSpanQueryFields(spanQuery, fieldNames);\n    } else {\n      fieldNames = new HashSet<>(1);\n      fieldNames.add(fieldName);\n    }\n    // To support the use of the default field name\n    if (defaultField != null) {\n      fieldNames.add(defaultField);\n    }\n    \n    Map<String, SpanQuery> queries = new HashMap<>();\n \n    Set<Term> nonWeightedTerms = new HashSet<>();\n    final boolean mustRewriteQuery = mustRewriteQuery(spanQuery);\n    if (mustRewriteQuery) {\n      for (final String field : fieldNames) {\n        final SpanQuery rewrittenQuery = (SpanQuery) spanQuery.rewrite(getLeafContext().reader());\n        queries.put(field, rewrittenQuery);\n        rewrittenQuery.extractTerms(nonWeightedTerms);\n      }\n    } else {\n      spanQuery.extractTerms(nonWeightedTerms);\n    }\n\n    List<PositionSpan> spanPositions = new ArrayList<>();\n\n    for (final String field : fieldNames) {\n      final SpanQuery q;\n      if (mustRewriteQuery) {\n        q = queries.get(field);\n      } else {\n        q = spanQuery;\n      }\n      LeafReaderContext context = getLeafContext();\n      Map<Term,TermContext> termContexts = new HashMap<>();\n      TreeSet<Term> extractedTerms = new TreeSet<>();\n      q.extractTerms(extractedTerms);\n      for (Term term : extractedTerms) {\n        termContexts.put(term, TermContext.build(context, term));\n      }\n      Bits acceptDocs = context.reader().getLiveDocs();\n      final Spans spans = q.getSpans(context, acceptDocs, termContexts);\n      if (spans == null) {\n        return;\n      }\n\n      // collect span positions\n      while (spans.nextDoc() != Spans.NO_MORE_DOCS) {\n        while (spans.nextStartPosition() != Spans.NO_MORE_POSITIONS) {\n          spanPositions.add(new PositionSpan(spans.startPosition(), spans.endPosition() - 1));\n        }\n      }\n    }\n\n    if (spanPositions.size() == 0) {\n      // no spans found\n      return;\n    }\n\n    for (final Term queryTerm :  nonWeightedTerms) {\n\n      if (fieldNameComparator(queryTerm.field())) {\n        WeightedSpanTerm weightedSpanTerm = terms.get(queryTerm.text());\n\n        if (weightedSpanTerm == null) {\n          weightedSpanTerm = new WeightedSpanTerm(spanQuery.getBoost(), queryTerm.text());\n          weightedSpanTerm.addPositionSpans(spanPositions);\n          weightedSpanTerm.positionSensitive = true;\n          terms.put(queryTerm.text(), weightedSpanTerm);\n        } else {\n          if (spanPositions.size() > 0) {\n            weightedSpanTerm.addPositionSpans(spanPositions);\n          }\n        }\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Fills a <code>Map</code> with {@link WeightedSpanTerm}s using the terms from the supplied <code>SpanQuery</code>.\n   * \n   * @param terms\n   *          Map to place created WeightedSpanTerms in\n   * @param spanQuery\n   *          SpanQuery to extract Terms from\n   * @throws IOException If there is a low-level I/O error\n   */\n  protected void extractWeightedSpanTerms(Map<String,WeightedSpanTerm> terms, SpanQuery spanQuery) throws IOException {\n    Set<String> fieldNames;\n\n    if (fieldName == null) {\n      fieldNames = new HashSet<>();\n      collectSpanQueryFields(spanQuery, fieldNames);\n    } else {\n      fieldNames = new HashSet<>(1);\n      fieldNames.add(fieldName);\n    }\n    // To support the use of the default field name\n    if (defaultField != null) {\n      fieldNames.add(defaultField);\n    }\n    \n    Map<String, SpanQuery> queries = new HashMap<>();\n \n    Set<Term> nonWeightedTerms = new HashSet<>();\n    final boolean mustRewriteQuery = mustRewriteQuery(spanQuery);\n    if (mustRewriteQuery) {\n      for (final String field : fieldNames) {\n        final SpanQuery rewrittenQuery = (SpanQuery) spanQuery.rewrite(getLeafContext().reader());\n        queries.put(field, rewrittenQuery);\n        rewrittenQuery.extractTerms(nonWeightedTerms);\n      }\n    } else {\n      spanQuery.extractTerms(nonWeightedTerms);\n    }\n\n    List<PositionSpan> spanPositions = new ArrayList<>();\n\n    for (final String field : fieldNames) {\n      final SpanQuery q;\n      if (mustRewriteQuery) {\n        q = queries.get(field);\n      } else {\n        q = spanQuery;\n      }\n      LeafReaderContext context = getLeafContext();\n      Map<Term,TermContext> termContexts = new HashMap<>();\n      TreeSet<Term> extractedTerms = new TreeSet<>();\n      q.extractTerms(extractedTerms);\n      for (Term term : extractedTerms) {\n        termContexts.put(term, TermContext.build(context, term));\n      }\n      Bits acceptDocs = context.reader().getLiveDocs();\n      final Spans spans = q.getSpans(context, acceptDocs, termContexts);\n\n      // collect span positions\n      while (spans.nextDoc() != Spans.NO_MORE_DOCS) {\n        while (spans.nextStartPosition() != Spans.NO_MORE_POSITIONS) {\n          spanPositions.add(new PositionSpan(spans.startPosition(), spans.endPosition() - 1));\n        }\n      }\n    }\n\n    if (spanPositions.size() == 0) {\n      // no spans found\n      return;\n    }\n\n    for (final Term queryTerm :  nonWeightedTerms) {\n\n      if (fieldNameComparator(queryTerm.field())) {\n        WeightedSpanTerm weightedSpanTerm = terms.get(queryTerm.text());\n\n        if (weightedSpanTerm == null) {\n          weightedSpanTerm = new WeightedSpanTerm(spanQuery.getBoost(), queryTerm.text());\n          weightedSpanTerm.addPositionSpans(spanPositions);\n          weightedSpanTerm.positionSensitive = true;\n          terms.put(queryTerm.text(), weightedSpanTerm);\n        } else {\n          if (spanPositions.size() > 0) {\n            weightedSpanTerm.addPositionSpans(spanPositions);\n          }\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6c757ac42dd1f3f893db5c4d89c61cbe1a9fab6c","date":1428091986,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/highlighter/src/java/org/apache/lucene/search/highlight/WeightedSpanTermExtractor#extractWeightedSpanTerms(Map[String,WeightedSpanTerm],SpanQuery).mjava","pathOld":"lucene/highlighter/src/java/org/apache/lucene/search/highlight/WeightedSpanTermExtractor#extractWeightedSpanTerms(Map[String,WeightedSpanTerm],SpanQuery).mjava","sourceNew":"  /**\n   * Fills a <code>Map</code> with {@link WeightedSpanTerm}s using the terms from the supplied <code>SpanQuery</code>.\n   * \n   * @param terms\n   *          Map to place created WeightedSpanTerms in\n   * @param spanQuery\n   *          SpanQuery to extract Terms from\n   * @throws IOException If there is a low-level I/O error\n   */\n  protected void extractWeightedSpanTerms(Map<String,WeightedSpanTerm> terms, SpanQuery spanQuery) throws IOException {\n    Set<String> fieldNames;\n\n    if (fieldName == null) {\n      fieldNames = new HashSet<>();\n      collectSpanQueryFields(spanQuery, fieldNames);\n    } else {\n      fieldNames = new HashSet<>(1);\n      fieldNames.add(fieldName);\n    }\n    // To support the use of the default field name\n    if (defaultField != null) {\n      fieldNames.add(defaultField);\n    }\n    \n    Map<String, SpanQuery> queries = new HashMap<>();\n \n    Set<Term> nonWeightedTerms = new HashSet<>();\n    final boolean mustRewriteQuery = mustRewriteQuery(spanQuery);\n    if (mustRewriteQuery) {\n      for (final String field : fieldNames) {\n        final SpanQuery rewrittenQuery = (SpanQuery) spanQuery.rewrite(getLeafContext().reader());\n        queries.put(field, rewrittenQuery);\n        rewrittenQuery.extractTerms(nonWeightedTerms);\n      }\n    } else {\n      spanQuery.extractTerms(nonWeightedTerms);\n    }\n\n    List<PositionSpan> spanPositions = new ArrayList<>();\n\n    for (final String field : fieldNames) {\n      final SpanQuery q;\n      if (mustRewriteQuery) {\n        q = queries.get(field);\n      } else {\n        q = spanQuery;\n      }\n      LeafReaderContext context = getLeafContext();\n      Map<Term,TermContext> termContexts = new HashMap<>();\n      TreeSet<Term> extractedTerms = new TreeSet<>();\n      q.extractTerms(extractedTerms);\n      for (Term term : extractedTerms) {\n        termContexts.put(term, TermContext.build(context, term));\n      }\n      Bits acceptDocs = context.reader().getLiveDocs();\n      final Spans spans = q.getSpans(context, acceptDocs, termContexts);\n      if (spans == null) {\n        return;\n      }\n\n      // collect span positions\n      while (spans.nextDoc() != Spans.NO_MORE_DOCS) {\n        while (spans.nextStartPosition() != Spans.NO_MORE_POSITIONS) {\n          spanPositions.add(new PositionSpan(spans.startPosition(), spans.endPosition() - 1));\n        }\n      }\n    }\n\n    if (spanPositions.size() == 0) {\n      // no spans found\n      return;\n    }\n\n    for (final Term queryTerm :  nonWeightedTerms) {\n\n      if (fieldNameComparator(queryTerm.field())) {\n        WeightedSpanTerm weightedSpanTerm = terms.get(queryTerm.text());\n\n        if (weightedSpanTerm == null) {\n          weightedSpanTerm = new WeightedSpanTerm(spanQuery.getBoost(), queryTerm.text());\n          weightedSpanTerm.addPositionSpans(spanPositions);\n          weightedSpanTerm.positionSensitive = true;\n          terms.put(queryTerm.text(), weightedSpanTerm);\n        } else {\n          if (spanPositions.size() > 0) {\n            weightedSpanTerm.addPositionSpans(spanPositions);\n          }\n        }\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Fills a <code>Map</code> with {@link WeightedSpanTerm}s using the terms from the supplied <code>SpanQuery</code>.\n   * \n   * @param terms\n   *          Map to place created WeightedSpanTerms in\n   * @param spanQuery\n   *          SpanQuery to extract Terms from\n   * @throws IOException If there is a low-level I/O error\n   */\n  protected void extractWeightedSpanTerms(Map<String,WeightedSpanTerm> terms, SpanQuery spanQuery) throws IOException {\n    Set<String> fieldNames;\n\n    if (fieldName == null) {\n      fieldNames = new HashSet<>();\n      collectSpanQueryFields(spanQuery, fieldNames);\n    } else {\n      fieldNames = new HashSet<>(1);\n      fieldNames.add(fieldName);\n    }\n    // To support the use of the default field name\n    if (defaultField != null) {\n      fieldNames.add(defaultField);\n    }\n    \n    Map<String, SpanQuery> queries = new HashMap<>();\n \n    Set<Term> nonWeightedTerms = new HashSet<>();\n    final boolean mustRewriteQuery = mustRewriteQuery(spanQuery);\n    if (mustRewriteQuery) {\n      for (final String field : fieldNames) {\n        final SpanQuery rewrittenQuery = (SpanQuery) spanQuery.rewrite(getLeafContext().reader());\n        queries.put(field, rewrittenQuery);\n        rewrittenQuery.extractTerms(nonWeightedTerms);\n      }\n    } else {\n      spanQuery.extractTerms(nonWeightedTerms);\n    }\n\n    List<PositionSpan> spanPositions = new ArrayList<>();\n\n    for (final String field : fieldNames) {\n      final SpanQuery q;\n      if (mustRewriteQuery) {\n        q = queries.get(field);\n      } else {\n        q = spanQuery;\n      }\n      LeafReaderContext context = getLeafContext();\n      Map<Term,TermContext> termContexts = new HashMap<>();\n      TreeSet<Term> extractedTerms = new TreeSet<>();\n      q.extractTerms(extractedTerms);\n      for (Term term : extractedTerms) {\n        termContexts.put(term, TermContext.build(context, term));\n      }\n      Bits acceptDocs = context.reader().getLiveDocs();\n      final Spans spans = q.getSpans(context, acceptDocs, termContexts);\n\n      // collect span positions\n      while (spans.nextDoc() != Spans.NO_MORE_DOCS) {\n        while (spans.nextStartPosition() != Spans.NO_MORE_POSITIONS) {\n          spanPositions.add(new PositionSpan(spans.startPosition(), spans.endPosition() - 1));\n        }\n      }\n    }\n\n    if (spanPositions.size() == 0) {\n      // no spans found\n      return;\n    }\n\n    for (final Term queryTerm :  nonWeightedTerms) {\n\n      if (fieldNameComparator(queryTerm.field())) {\n        WeightedSpanTerm weightedSpanTerm = terms.get(queryTerm.text());\n\n        if (weightedSpanTerm == null) {\n          weightedSpanTerm = new WeightedSpanTerm(spanQuery.getBoost(), queryTerm.text());\n          weightedSpanTerm.addPositionSpans(spanPositions);\n          weightedSpanTerm.positionSensitive = true;\n          terms.put(queryTerm.text(), weightedSpanTerm);\n        } else {\n          if (spanPositions.size() > 0) {\n            weightedSpanTerm.addPositionSpans(spanPositions);\n          }\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"05c52ac194342b760b830342ee8423fcf00e54d0","date":1429197275,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/highlighter/src/java/org/apache/lucene/search/highlight/WeightedSpanTermExtractor#extractWeightedSpanTerms(Map[String,WeightedSpanTerm],SpanQuery).mjava","pathOld":"lucene/highlighter/src/java/org/apache/lucene/search/highlight/WeightedSpanTermExtractor#extractWeightedSpanTerms(Map[String,WeightedSpanTerm],SpanQuery).mjava","sourceNew":"  /**\n   * Fills a <code>Map</code> with {@link WeightedSpanTerm}s using the terms from the supplied <code>SpanQuery</code>.\n   * \n   * @param terms\n   *          Map to place created WeightedSpanTerms in\n   * @param spanQuery\n   *          SpanQuery to extract Terms from\n   * @throws IOException If there is a low-level I/O error\n   */\n  protected void extractWeightedSpanTerms(Map<String,WeightedSpanTerm> terms, SpanQuery spanQuery) throws IOException {\n    Set<String> fieldNames;\n\n    if (fieldName == null) {\n      fieldNames = new HashSet<>();\n      collectSpanQueryFields(spanQuery, fieldNames);\n    } else {\n      fieldNames = new HashSet<>(1);\n      fieldNames.add(fieldName);\n    }\n    // To support the use of the default field name\n    if (defaultField != null) {\n      fieldNames.add(defaultField);\n    }\n    \n    Map<String, SpanQuery> queries = new HashMap<>();\n \n    Set<Term> nonWeightedTerms = new HashSet<>();\n    final boolean mustRewriteQuery = mustRewriteQuery(spanQuery);\n    final IndexSearcher searcher = new IndexSearcher(getLeafContext());\n    searcher.setQueryCache(null);\n    if (mustRewriteQuery) {\n      for (final String field : fieldNames) {\n        final SpanQuery rewrittenQuery = (SpanQuery) spanQuery.rewrite(getLeafContext().reader());\n        queries.put(field, rewrittenQuery);\n        rewrittenQuery.createWeight(searcher, false).extractTerms(nonWeightedTerms);\n      }\n    } else {\n      spanQuery.createWeight(searcher, false).extractTerms(nonWeightedTerms);\n    }\n\n    List<PositionSpan> spanPositions = new ArrayList<>();\n\n    for (final String field : fieldNames) {\n      final SpanQuery q;\n      if (mustRewriteQuery) {\n        q = queries.get(field);\n      } else {\n        q = spanQuery;\n      }\n      LeafReaderContext context = getLeafContext();\n      Map<Term,TermContext> termContexts = new HashMap<>();\n      TreeSet<Term> extractedTerms = new TreeSet<>();\n      searcher.createNormalizedWeight(q, false).extractTerms(extractedTerms);\n      for (Term term : extractedTerms) {\n        termContexts.put(term, TermContext.build(context, term));\n      }\n      Bits acceptDocs = context.reader().getLiveDocs();\n      final Spans spans = q.getSpans(context, acceptDocs, termContexts);\n      if (spans == null) {\n        return;\n      }\n\n      // collect span positions\n      while (spans.nextDoc() != Spans.NO_MORE_DOCS) {\n        while (spans.nextStartPosition() != Spans.NO_MORE_POSITIONS) {\n          spanPositions.add(new PositionSpan(spans.startPosition(), spans.endPosition() - 1));\n        }\n      }\n    }\n\n    if (spanPositions.size() == 0) {\n      // no spans found\n      return;\n    }\n\n    for (final Term queryTerm :  nonWeightedTerms) {\n\n      if (fieldNameComparator(queryTerm.field())) {\n        WeightedSpanTerm weightedSpanTerm = terms.get(queryTerm.text());\n\n        if (weightedSpanTerm == null) {\n          weightedSpanTerm = new WeightedSpanTerm(spanQuery.getBoost(), queryTerm.text());\n          weightedSpanTerm.addPositionSpans(spanPositions);\n          weightedSpanTerm.positionSensitive = true;\n          terms.put(queryTerm.text(), weightedSpanTerm);\n        } else {\n          if (spanPositions.size() > 0) {\n            weightedSpanTerm.addPositionSpans(spanPositions);\n          }\n        }\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Fills a <code>Map</code> with {@link WeightedSpanTerm}s using the terms from the supplied <code>SpanQuery</code>.\n   * \n   * @param terms\n   *          Map to place created WeightedSpanTerms in\n   * @param spanQuery\n   *          SpanQuery to extract Terms from\n   * @throws IOException If there is a low-level I/O error\n   */\n  protected void extractWeightedSpanTerms(Map<String,WeightedSpanTerm> terms, SpanQuery spanQuery) throws IOException {\n    Set<String> fieldNames;\n\n    if (fieldName == null) {\n      fieldNames = new HashSet<>();\n      collectSpanQueryFields(spanQuery, fieldNames);\n    } else {\n      fieldNames = new HashSet<>(1);\n      fieldNames.add(fieldName);\n    }\n    // To support the use of the default field name\n    if (defaultField != null) {\n      fieldNames.add(defaultField);\n    }\n    \n    Map<String, SpanQuery> queries = new HashMap<>();\n \n    Set<Term> nonWeightedTerms = new HashSet<>();\n    final boolean mustRewriteQuery = mustRewriteQuery(spanQuery);\n    if (mustRewriteQuery) {\n      for (final String field : fieldNames) {\n        final SpanQuery rewrittenQuery = (SpanQuery) spanQuery.rewrite(getLeafContext().reader());\n        queries.put(field, rewrittenQuery);\n        rewrittenQuery.extractTerms(nonWeightedTerms);\n      }\n    } else {\n      spanQuery.extractTerms(nonWeightedTerms);\n    }\n\n    List<PositionSpan> spanPositions = new ArrayList<>();\n\n    for (final String field : fieldNames) {\n      final SpanQuery q;\n      if (mustRewriteQuery) {\n        q = queries.get(field);\n      } else {\n        q = spanQuery;\n      }\n      LeafReaderContext context = getLeafContext();\n      Map<Term,TermContext> termContexts = new HashMap<>();\n      TreeSet<Term> extractedTerms = new TreeSet<>();\n      q.extractTerms(extractedTerms);\n      for (Term term : extractedTerms) {\n        termContexts.put(term, TermContext.build(context, term));\n      }\n      Bits acceptDocs = context.reader().getLiveDocs();\n      final Spans spans = q.getSpans(context, acceptDocs, termContexts);\n      if (spans == null) {\n        return;\n      }\n\n      // collect span positions\n      while (spans.nextDoc() != Spans.NO_MORE_DOCS) {\n        while (spans.nextStartPosition() != Spans.NO_MORE_POSITIONS) {\n          spanPositions.add(new PositionSpan(spans.startPosition(), spans.endPosition() - 1));\n        }\n      }\n    }\n\n    if (spanPositions.size() == 0) {\n      // no spans found\n      return;\n    }\n\n    for (final Term queryTerm :  nonWeightedTerms) {\n\n      if (fieldNameComparator(queryTerm.field())) {\n        WeightedSpanTerm weightedSpanTerm = terms.get(queryTerm.text());\n\n        if (weightedSpanTerm == null) {\n          weightedSpanTerm = new WeightedSpanTerm(spanQuery.getBoost(), queryTerm.text());\n          weightedSpanTerm.addPositionSpans(spanPositions);\n          weightedSpanTerm.positionSensitive = true;\n          terms.put(queryTerm.text(), weightedSpanTerm);\n        } else {\n          if (spanPositions.size() > 0) {\n            weightedSpanTerm.addPositionSpans(spanPositions);\n          }\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":["8f6e2f8b5923e09c68fcefca2b75678c8d9c89f2"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"2d530e71ed32ab23b34ca3fc72b080a554a40404","date":1432026158,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"lucene/highlighter/src/java/org/apache/lucene/search/highlight/WeightedSpanTermExtractor#extractWeightedSpanTerms(Map[String,WeightedSpanTerm],SpanQuery).mjava","pathOld":"lucene/highlighter/src/java/org/apache/lucene/search/highlight/WeightedSpanTermExtractor#extractWeightedSpanTerms(Map[String,WeightedSpanTerm],SpanQuery).mjava","sourceNew":"  /**\n   * Fills a <code>Map</code> with {@link WeightedSpanTerm}s using the terms from the supplied <code>SpanQuery</code>.\n   * \n   * @param terms\n   *          Map to place created WeightedSpanTerms in\n   * @param spanQuery\n   *          SpanQuery to extract Terms from\n   * @throws IOException If there is a low-level I/O error\n   */\n  protected void extractWeightedSpanTerms(Map<String,WeightedSpanTerm> terms, SpanQuery spanQuery) throws IOException {\n    Set<String> fieldNames;\n\n    if (fieldName == null) {\n      fieldNames = new HashSet<>();\n      collectSpanQueryFields(spanQuery, fieldNames);\n    } else {\n      fieldNames = new HashSet<>(1);\n      fieldNames.add(fieldName);\n    }\n    // To support the use of the default field name\n    if (defaultField != null) {\n      fieldNames.add(defaultField);\n    }\n    \n    Map<String, SpanQuery> queries = new HashMap<>();\n \n    Set<Term> nonWeightedTerms = new HashSet<>();\n    final boolean mustRewriteQuery = mustRewriteQuery(spanQuery);\n    final IndexSearcher searcher = new IndexSearcher(getLeafContext());\n    searcher.setQueryCache(null);\n    if (mustRewriteQuery) {\n      for (final String field : fieldNames) {\n        final SpanQuery rewrittenQuery = (SpanQuery) spanQuery.rewrite(getLeafContext().reader());\n        queries.put(field, rewrittenQuery);\n        rewrittenQuery.createWeight(searcher, false).extractTerms(nonWeightedTerms);\n      }\n    } else {\n      spanQuery.createWeight(searcher, false).extractTerms(nonWeightedTerms);\n    }\n\n    List<PositionSpan> spanPositions = new ArrayList<>();\n\n    for (final String field : fieldNames) {\n      final SpanQuery q;\n      if (mustRewriteQuery) {\n        q = queries.get(field);\n      } else {\n        q = spanQuery;\n      }\n      LeafReaderContext context = getLeafContext();\n      Map<Term,TermContext> termContexts = new HashMap<>();\n      TreeSet<Term> extractedTerms = new TreeSet<>();\n      searcher.createNormalizedWeight(q, false).extractTerms(extractedTerms);\n      for (Term term : extractedTerms) {\n        termContexts.put(term, TermContext.build(context, term));\n      }\n      Bits acceptDocs = context.reader().getLiveDocs();\n      final Spans spans = q.getSpans(context, acceptDocs, termContexts, SpanCollector.NO_OP);\n      if (spans == null) {\n        return;\n      }\n\n      // collect span positions\n      while (spans.nextDoc() != Spans.NO_MORE_DOCS) {\n        while (spans.nextStartPosition() != Spans.NO_MORE_POSITIONS) {\n          spanPositions.add(new PositionSpan(spans.startPosition(), spans.endPosition() - 1));\n        }\n      }\n    }\n\n    if (spanPositions.size() == 0) {\n      // no spans found\n      return;\n    }\n\n    for (final Term queryTerm :  nonWeightedTerms) {\n\n      if (fieldNameComparator(queryTerm.field())) {\n        WeightedSpanTerm weightedSpanTerm = terms.get(queryTerm.text());\n\n        if (weightedSpanTerm == null) {\n          weightedSpanTerm = new WeightedSpanTerm(spanQuery.getBoost(), queryTerm.text());\n          weightedSpanTerm.addPositionSpans(spanPositions);\n          weightedSpanTerm.positionSensitive = true;\n          terms.put(queryTerm.text(), weightedSpanTerm);\n        } else {\n          if (spanPositions.size() > 0) {\n            weightedSpanTerm.addPositionSpans(spanPositions);\n          }\n        }\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Fills a <code>Map</code> with {@link WeightedSpanTerm}s using the terms from the supplied <code>SpanQuery</code>.\n   * \n   * @param terms\n   *          Map to place created WeightedSpanTerms in\n   * @param spanQuery\n   *          SpanQuery to extract Terms from\n   * @throws IOException If there is a low-level I/O error\n   */\n  protected void extractWeightedSpanTerms(Map<String,WeightedSpanTerm> terms, SpanQuery spanQuery) throws IOException {\n    Set<String> fieldNames;\n\n    if (fieldName == null) {\n      fieldNames = new HashSet<>();\n      collectSpanQueryFields(spanQuery, fieldNames);\n    } else {\n      fieldNames = new HashSet<>(1);\n      fieldNames.add(fieldName);\n    }\n    // To support the use of the default field name\n    if (defaultField != null) {\n      fieldNames.add(defaultField);\n    }\n    \n    Map<String, SpanQuery> queries = new HashMap<>();\n \n    Set<Term> nonWeightedTerms = new HashSet<>();\n    final boolean mustRewriteQuery = mustRewriteQuery(spanQuery);\n    final IndexSearcher searcher = new IndexSearcher(getLeafContext());\n    searcher.setQueryCache(null);\n    if (mustRewriteQuery) {\n      for (final String field : fieldNames) {\n        final SpanQuery rewrittenQuery = (SpanQuery) spanQuery.rewrite(getLeafContext().reader());\n        queries.put(field, rewrittenQuery);\n        rewrittenQuery.createWeight(searcher, false).extractTerms(nonWeightedTerms);\n      }\n    } else {\n      spanQuery.createWeight(searcher, false).extractTerms(nonWeightedTerms);\n    }\n\n    List<PositionSpan> spanPositions = new ArrayList<>();\n\n    for (final String field : fieldNames) {\n      final SpanQuery q;\n      if (mustRewriteQuery) {\n        q = queries.get(field);\n      } else {\n        q = spanQuery;\n      }\n      LeafReaderContext context = getLeafContext();\n      Map<Term,TermContext> termContexts = new HashMap<>();\n      TreeSet<Term> extractedTerms = new TreeSet<>();\n      searcher.createNormalizedWeight(q, false).extractTerms(extractedTerms);\n      for (Term term : extractedTerms) {\n        termContexts.put(term, TermContext.build(context, term));\n      }\n      Bits acceptDocs = context.reader().getLiveDocs();\n      final Spans spans = q.getSpans(context, acceptDocs, termContexts);\n      if (spans == null) {\n        return;\n      }\n\n      // collect span positions\n      while (spans.nextDoc() != Spans.NO_MORE_DOCS) {\n        while (spans.nextStartPosition() != Spans.NO_MORE_POSITIONS) {\n          spanPositions.add(new PositionSpan(spans.startPosition(), spans.endPosition() - 1));\n        }\n      }\n    }\n\n    if (spanPositions.size() == 0) {\n      // no spans found\n      return;\n    }\n\n    for (final Term queryTerm :  nonWeightedTerms) {\n\n      if (fieldNameComparator(queryTerm.field())) {\n        WeightedSpanTerm weightedSpanTerm = terms.get(queryTerm.text());\n\n        if (weightedSpanTerm == null) {\n          weightedSpanTerm = new WeightedSpanTerm(spanQuery.getBoost(), queryTerm.text());\n          weightedSpanTerm.addPositionSpans(spanPositions);\n          weightedSpanTerm.positionSensitive = true;\n          terms.put(queryTerm.text(), weightedSpanTerm);\n        } else {\n          if (spanPositions.size() > 0) {\n            weightedSpanTerm.addPositionSpans(spanPositions);\n          }\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":["8f6e2f8b5923e09c68fcefca2b75678c8d9c89f2"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"8f6e2f8b5923e09c68fcefca2b75678c8d9c89f2","date":1432114286,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"lucene/highlighter/src/java/org/apache/lucene/search/highlight/WeightedSpanTermExtractor#extractWeightedSpanTerms(Map[String,WeightedSpanTerm],SpanQuery).mjava","pathOld":"lucene/highlighter/src/java/org/apache/lucene/search/highlight/WeightedSpanTermExtractor#extractWeightedSpanTerms(Map[String,WeightedSpanTerm],SpanQuery).mjava","sourceNew":"  /**\n   * Fills a <code>Map</code> with {@link WeightedSpanTerm}s using the terms from the supplied <code>SpanQuery</code>.\n   * \n   * @param terms\n   *          Map to place created WeightedSpanTerms in\n   * @param spanQuery\n   *          SpanQuery to extract Terms from\n   * @throws IOException If there is a low-level I/O error\n   */\n  protected void extractWeightedSpanTerms(Map<String,WeightedSpanTerm> terms, SpanQuery spanQuery) throws IOException {\n    Set<String> fieldNames;\n\n    if (fieldName == null) {\n      fieldNames = new HashSet<>();\n      collectSpanQueryFields(spanQuery, fieldNames);\n    } else {\n      fieldNames = new HashSet<>(1);\n      fieldNames.add(fieldName);\n    }\n    // To support the use of the default field name\n    if (defaultField != null) {\n      fieldNames.add(defaultField);\n    }\n    \n    Map<String, SpanQuery> queries = new HashMap<>();\n \n    Set<Term> nonWeightedTerms = new HashSet<>();\n    final boolean mustRewriteQuery = mustRewriteQuery(spanQuery);\n    final IndexSearcher searcher = new IndexSearcher(getLeafContext());\n    searcher.setQueryCache(null);\n    if (mustRewriteQuery) {\n      for (final String field : fieldNames) {\n        final SpanQuery rewrittenQuery = (SpanQuery) spanQuery.rewrite(getLeafContext().reader());\n        queries.put(field, rewrittenQuery);\n        rewrittenQuery.createWeight(searcher, false).extractTerms(nonWeightedTerms);\n      }\n    } else {\n      spanQuery.createWeight(searcher, false).extractTerms(nonWeightedTerms);\n    }\n\n    List<PositionSpan> spanPositions = new ArrayList<>();\n\n    for (final String field : fieldNames) {\n      final SpanQuery q;\n      if (mustRewriteQuery) {\n        q = queries.get(field);\n      } else {\n        q = spanQuery;\n      }\n      LeafReaderContext context = getLeafContext();\n      Map<Term,TermContext> termContexts = new HashMap<>();\n      TreeSet<Term> extractedTerms = new TreeSet<>();\n      SpanWeight w = (SpanWeight) searcher.createNormalizedWeight(q, false);\n      w.extractTerms(extractedTerms);\n      for (Term term : extractedTerms) {\n        termContexts.put(term, TermContext.build(context, term));\n      }\n      Bits acceptDocs = context.reader().getLiveDocs();\n      final Spans spans = q.getSpans(context, acceptDocs, termContexts, w.getSpanCollectorFactory().newCollector());\n      if (spans == null) {\n        return;\n      }\n\n      // collect span positions\n      while (spans.nextDoc() != Spans.NO_MORE_DOCS) {\n        while (spans.nextStartPosition() != Spans.NO_MORE_POSITIONS) {\n          spanPositions.add(new PositionSpan(spans.startPosition(), spans.endPosition() - 1));\n        }\n      }\n    }\n\n    if (spanPositions.size() == 0) {\n      // no spans found\n      return;\n    }\n\n    for (final Term queryTerm :  nonWeightedTerms) {\n\n      if (fieldNameComparator(queryTerm.field())) {\n        WeightedSpanTerm weightedSpanTerm = terms.get(queryTerm.text());\n\n        if (weightedSpanTerm == null) {\n          weightedSpanTerm = new WeightedSpanTerm(spanQuery.getBoost(), queryTerm.text());\n          weightedSpanTerm.addPositionSpans(spanPositions);\n          weightedSpanTerm.positionSensitive = true;\n          terms.put(queryTerm.text(), weightedSpanTerm);\n        } else {\n          if (spanPositions.size() > 0) {\n            weightedSpanTerm.addPositionSpans(spanPositions);\n          }\n        }\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Fills a <code>Map</code> with {@link WeightedSpanTerm}s using the terms from the supplied <code>SpanQuery</code>.\n   * \n   * @param terms\n   *          Map to place created WeightedSpanTerms in\n   * @param spanQuery\n   *          SpanQuery to extract Terms from\n   * @throws IOException If there is a low-level I/O error\n   */\n  protected void extractWeightedSpanTerms(Map<String,WeightedSpanTerm> terms, SpanQuery spanQuery) throws IOException {\n    Set<String> fieldNames;\n\n    if (fieldName == null) {\n      fieldNames = new HashSet<>();\n      collectSpanQueryFields(spanQuery, fieldNames);\n    } else {\n      fieldNames = new HashSet<>(1);\n      fieldNames.add(fieldName);\n    }\n    // To support the use of the default field name\n    if (defaultField != null) {\n      fieldNames.add(defaultField);\n    }\n    \n    Map<String, SpanQuery> queries = new HashMap<>();\n \n    Set<Term> nonWeightedTerms = new HashSet<>();\n    final boolean mustRewriteQuery = mustRewriteQuery(spanQuery);\n    final IndexSearcher searcher = new IndexSearcher(getLeafContext());\n    searcher.setQueryCache(null);\n    if (mustRewriteQuery) {\n      for (final String field : fieldNames) {\n        final SpanQuery rewrittenQuery = (SpanQuery) spanQuery.rewrite(getLeafContext().reader());\n        queries.put(field, rewrittenQuery);\n        rewrittenQuery.createWeight(searcher, false).extractTerms(nonWeightedTerms);\n      }\n    } else {\n      spanQuery.createWeight(searcher, false).extractTerms(nonWeightedTerms);\n    }\n\n    List<PositionSpan> spanPositions = new ArrayList<>();\n\n    for (final String field : fieldNames) {\n      final SpanQuery q;\n      if (mustRewriteQuery) {\n        q = queries.get(field);\n      } else {\n        q = spanQuery;\n      }\n      LeafReaderContext context = getLeafContext();\n      Map<Term,TermContext> termContexts = new HashMap<>();\n      TreeSet<Term> extractedTerms = new TreeSet<>();\n      searcher.createNormalizedWeight(q, false).extractTerms(extractedTerms);\n      for (Term term : extractedTerms) {\n        termContexts.put(term, TermContext.build(context, term));\n      }\n      Bits acceptDocs = context.reader().getLiveDocs();\n      final Spans spans = q.getSpans(context, acceptDocs, termContexts, SpanCollector.NO_OP);\n      if (spans == null) {\n        return;\n      }\n\n      // collect span positions\n      while (spans.nextDoc() != Spans.NO_MORE_DOCS) {\n        while (spans.nextStartPosition() != Spans.NO_MORE_POSITIONS) {\n          spanPositions.add(new PositionSpan(spans.startPosition(), spans.endPosition() - 1));\n        }\n      }\n    }\n\n    if (spanPositions.size() == 0) {\n      // no spans found\n      return;\n    }\n\n    for (final Term queryTerm :  nonWeightedTerms) {\n\n      if (fieldNameComparator(queryTerm.field())) {\n        WeightedSpanTerm weightedSpanTerm = terms.get(queryTerm.text());\n\n        if (weightedSpanTerm == null) {\n          weightedSpanTerm = new WeightedSpanTerm(spanQuery.getBoost(), queryTerm.text());\n          weightedSpanTerm.addPositionSpans(spanPositions);\n          weightedSpanTerm.positionSensitive = true;\n          terms.put(queryTerm.text(), weightedSpanTerm);\n        } else {\n          if (spanPositions.size() > 0) {\n            weightedSpanTerm.addPositionSpans(spanPositions);\n          }\n        }\n      }\n    }\n  }\n\n","bugFix":["2d530e71ed32ab23b34ca3fc72b080a554a40404","05c52ac194342b760b830342ee8423fcf00e54d0"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c257cd8ddb1ed5632a36c7488614a2ee21705d24","date":1432128550,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"lucene/highlighter/src/java/org/apache/lucene/search/highlight/WeightedSpanTermExtractor#extractWeightedSpanTerms(Map[String,WeightedSpanTerm],SpanQuery).mjava","pathOld":"lucene/highlighter/src/java/org/apache/lucene/search/highlight/WeightedSpanTermExtractor#extractWeightedSpanTerms(Map[String,WeightedSpanTerm],SpanQuery).mjava","sourceNew":"  /**\n   * Fills a <code>Map</code> with {@link WeightedSpanTerm}s using the terms from the supplied <code>SpanQuery</code>.\n   * \n   * @param terms\n   *          Map to place created WeightedSpanTerms in\n   * @param spanQuery\n   *          SpanQuery to extract Terms from\n   * @throws IOException If there is a low-level I/O error\n   */\n  protected void extractWeightedSpanTerms(Map<String,WeightedSpanTerm> terms, SpanQuery spanQuery) throws IOException {\n    Set<String> fieldNames;\n\n    if (fieldName == null) {\n      fieldNames = new HashSet<>();\n      collectSpanQueryFields(spanQuery, fieldNames);\n    } else {\n      fieldNames = new HashSet<>(1);\n      fieldNames.add(fieldName);\n    }\n    // To support the use of the default field name\n    if (defaultField != null) {\n      fieldNames.add(defaultField);\n    }\n    \n    Map<String, SpanQuery> queries = new HashMap<>();\n \n    Set<Term> nonWeightedTerms = new HashSet<>();\n    final boolean mustRewriteQuery = mustRewriteQuery(spanQuery);\n    final IndexSearcher searcher = new IndexSearcher(getLeafContext());\n    searcher.setQueryCache(null);\n    if (mustRewriteQuery) {\n      for (final String field : fieldNames) {\n        final SpanQuery rewrittenQuery = (SpanQuery) spanQuery.rewrite(getLeafContext().reader());\n        queries.put(field, rewrittenQuery);\n        rewrittenQuery.createWeight(searcher, false).extractTerms(nonWeightedTerms);\n      }\n    } else {\n      spanQuery.createWeight(searcher, false).extractTerms(nonWeightedTerms);\n    }\n\n    List<PositionSpan> spanPositions = new ArrayList<>();\n\n    for (final String field : fieldNames) {\n      final SpanQuery q;\n      if (mustRewriteQuery) {\n        q = queries.get(field);\n      } else {\n        q = spanQuery;\n      }\n      LeafReaderContext context = getLeafContext();\n      SpanWeight w = (SpanWeight) searcher.createNormalizedWeight(q, false);\n      Bits acceptDocs = context.reader().getLiveDocs();\n      final Spans spans = w.getSpans(context, acceptDocs);\n      if (spans == null) {\n        return;\n      }\n\n      // collect span positions\n      while (spans.nextDoc() != Spans.NO_MORE_DOCS) {\n        while (spans.nextStartPosition() != Spans.NO_MORE_POSITIONS) {\n          spanPositions.add(new PositionSpan(spans.startPosition(), spans.endPosition() - 1));\n        }\n      }\n    }\n\n    if (spanPositions.size() == 0) {\n      // no spans found\n      return;\n    }\n\n    for (final Term queryTerm :  nonWeightedTerms) {\n\n      if (fieldNameComparator(queryTerm.field())) {\n        WeightedSpanTerm weightedSpanTerm = terms.get(queryTerm.text());\n\n        if (weightedSpanTerm == null) {\n          weightedSpanTerm = new WeightedSpanTerm(spanQuery.getBoost(), queryTerm.text());\n          weightedSpanTerm.addPositionSpans(spanPositions);\n          weightedSpanTerm.positionSensitive = true;\n          terms.put(queryTerm.text(), weightedSpanTerm);\n        } else {\n          if (spanPositions.size() > 0) {\n            weightedSpanTerm.addPositionSpans(spanPositions);\n          }\n        }\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Fills a <code>Map</code> with {@link WeightedSpanTerm}s using the terms from the supplied <code>SpanQuery</code>.\n   * \n   * @param terms\n   *          Map to place created WeightedSpanTerms in\n   * @param spanQuery\n   *          SpanQuery to extract Terms from\n   * @throws IOException If there is a low-level I/O error\n   */\n  protected void extractWeightedSpanTerms(Map<String,WeightedSpanTerm> terms, SpanQuery spanQuery) throws IOException {\n    Set<String> fieldNames;\n\n    if (fieldName == null) {\n      fieldNames = new HashSet<>();\n      collectSpanQueryFields(spanQuery, fieldNames);\n    } else {\n      fieldNames = new HashSet<>(1);\n      fieldNames.add(fieldName);\n    }\n    // To support the use of the default field name\n    if (defaultField != null) {\n      fieldNames.add(defaultField);\n    }\n    \n    Map<String, SpanQuery> queries = new HashMap<>();\n \n    Set<Term> nonWeightedTerms = new HashSet<>();\n    final boolean mustRewriteQuery = mustRewriteQuery(spanQuery);\n    final IndexSearcher searcher = new IndexSearcher(getLeafContext());\n    searcher.setQueryCache(null);\n    if (mustRewriteQuery) {\n      for (final String field : fieldNames) {\n        final SpanQuery rewrittenQuery = (SpanQuery) spanQuery.rewrite(getLeafContext().reader());\n        queries.put(field, rewrittenQuery);\n        rewrittenQuery.createWeight(searcher, false).extractTerms(nonWeightedTerms);\n      }\n    } else {\n      spanQuery.createWeight(searcher, false).extractTerms(nonWeightedTerms);\n    }\n\n    List<PositionSpan> spanPositions = new ArrayList<>();\n\n    for (final String field : fieldNames) {\n      final SpanQuery q;\n      if (mustRewriteQuery) {\n        q = queries.get(field);\n      } else {\n        q = spanQuery;\n      }\n      LeafReaderContext context = getLeafContext();\n      Map<Term,TermContext> termContexts = new HashMap<>();\n      TreeSet<Term> extractedTerms = new TreeSet<>();\n      SpanWeight w = (SpanWeight) searcher.createNormalizedWeight(q, false);\n      w.extractTerms(extractedTerms);\n      for (Term term : extractedTerms) {\n        termContexts.put(term, TermContext.build(context, term));\n      }\n      Bits acceptDocs = context.reader().getLiveDocs();\n      final Spans spans = q.getSpans(context, acceptDocs, termContexts, w.getSpanCollectorFactory().newCollector());\n      if (spans == null) {\n        return;\n      }\n\n      // collect span positions\n      while (spans.nextDoc() != Spans.NO_MORE_DOCS) {\n        while (spans.nextStartPosition() != Spans.NO_MORE_POSITIONS) {\n          spanPositions.add(new PositionSpan(spans.startPosition(), spans.endPosition() - 1));\n        }\n      }\n    }\n\n    if (spanPositions.size() == 0) {\n      // no spans found\n      return;\n    }\n\n    for (final Term queryTerm :  nonWeightedTerms) {\n\n      if (fieldNameComparator(queryTerm.field())) {\n        WeightedSpanTerm weightedSpanTerm = terms.get(queryTerm.text());\n\n        if (weightedSpanTerm == null) {\n          weightedSpanTerm = new WeightedSpanTerm(spanQuery.getBoost(), queryTerm.text());\n          weightedSpanTerm.addPositionSpans(spanPositions);\n          weightedSpanTerm.positionSensitive = true;\n          terms.put(queryTerm.text(), weightedSpanTerm);\n        } else {\n          if (spanPositions.size() > 0) {\n            weightedSpanTerm.addPositionSpans(spanPositions);\n          }\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"29aea3139c4326c0501d75d51059855463220279","date":1433952060,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"lucene/highlighter/src/java/org/apache/lucene/search/highlight/WeightedSpanTermExtractor#extractWeightedSpanTerms(Map[String,WeightedSpanTerm],SpanQuery).mjava","pathOld":"lucene/highlighter/src/java/org/apache/lucene/search/highlight/WeightedSpanTermExtractor#extractWeightedSpanTerms(Map[String,WeightedSpanTerm],SpanQuery).mjava","sourceNew":"  /**\n   * Fills a <code>Map</code> with {@link WeightedSpanTerm}s using the terms from the supplied <code>SpanQuery</code>.\n   * \n   * @param terms\n   *          Map to place created WeightedSpanTerms in\n   * @param spanQuery\n   *          SpanQuery to extract Terms from\n   * @throws IOException If there is a low-level I/O error\n   */\n  protected void extractWeightedSpanTerms(Map<String,WeightedSpanTerm> terms, SpanQuery spanQuery) throws IOException {\n    Set<String> fieldNames;\n\n    if (fieldName == null) {\n      fieldNames = new HashSet<>();\n      collectSpanQueryFields(spanQuery, fieldNames);\n    } else {\n      fieldNames = new HashSet<>(1);\n      fieldNames.add(fieldName);\n    }\n    // To support the use of the default field name\n    if (defaultField != null) {\n      fieldNames.add(defaultField);\n    }\n    \n    Map<String, SpanQuery> queries = new HashMap<>();\n \n    Set<Term> nonWeightedTerms = new HashSet<>();\n    final boolean mustRewriteQuery = mustRewriteQuery(spanQuery);\n    final IndexSearcher searcher = new IndexSearcher(getLeafContext());\n    searcher.setQueryCache(null);\n    if (mustRewriteQuery) {\n      for (final String field : fieldNames) {\n        final SpanQuery rewrittenQuery = (SpanQuery) spanQuery.rewrite(getLeafContext().reader());\n        queries.put(field, rewrittenQuery);\n        rewrittenQuery.createWeight(searcher, false).extractTerms(nonWeightedTerms);\n      }\n    } else {\n      spanQuery.createWeight(searcher, false).extractTerms(nonWeightedTerms);\n    }\n\n    List<PositionSpan> spanPositions = new ArrayList<>();\n\n    for (final String field : fieldNames) {\n      final SpanQuery q;\n      if (mustRewriteQuery) {\n        q = queries.get(field);\n      } else {\n        q = spanQuery;\n      }\n      LeafReaderContext context = getLeafContext();\n      SpanWeight w = (SpanWeight) searcher.createNormalizedWeight(q, false);\n      Bits acceptDocs = context.reader().getLiveDocs();\n      final Spans spans = w.getSpans(context, acceptDocs, SpanWeight.Postings.POSITIONS);\n      if (spans == null) {\n        return;\n      }\n\n      // collect span positions\n      while (spans.nextDoc() != Spans.NO_MORE_DOCS) {\n        while (spans.nextStartPosition() != Spans.NO_MORE_POSITIONS) {\n          spanPositions.add(new PositionSpan(spans.startPosition(), spans.endPosition() - 1));\n        }\n      }\n    }\n\n    if (spanPositions.size() == 0) {\n      // no spans found\n      return;\n    }\n\n    for (final Term queryTerm :  nonWeightedTerms) {\n\n      if (fieldNameComparator(queryTerm.field())) {\n        WeightedSpanTerm weightedSpanTerm = terms.get(queryTerm.text());\n\n        if (weightedSpanTerm == null) {\n          weightedSpanTerm = new WeightedSpanTerm(spanQuery.getBoost(), queryTerm.text());\n          weightedSpanTerm.addPositionSpans(spanPositions);\n          weightedSpanTerm.positionSensitive = true;\n          terms.put(queryTerm.text(), weightedSpanTerm);\n        } else {\n          if (spanPositions.size() > 0) {\n            weightedSpanTerm.addPositionSpans(spanPositions);\n          }\n        }\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Fills a <code>Map</code> with {@link WeightedSpanTerm}s using the terms from the supplied <code>SpanQuery</code>.\n   * \n   * @param terms\n   *          Map to place created WeightedSpanTerms in\n   * @param spanQuery\n   *          SpanQuery to extract Terms from\n   * @throws IOException If there is a low-level I/O error\n   */\n  protected void extractWeightedSpanTerms(Map<String,WeightedSpanTerm> terms, SpanQuery spanQuery) throws IOException {\n    Set<String> fieldNames;\n\n    if (fieldName == null) {\n      fieldNames = new HashSet<>();\n      collectSpanQueryFields(spanQuery, fieldNames);\n    } else {\n      fieldNames = new HashSet<>(1);\n      fieldNames.add(fieldName);\n    }\n    // To support the use of the default field name\n    if (defaultField != null) {\n      fieldNames.add(defaultField);\n    }\n    \n    Map<String, SpanQuery> queries = new HashMap<>();\n \n    Set<Term> nonWeightedTerms = new HashSet<>();\n    final boolean mustRewriteQuery = mustRewriteQuery(spanQuery);\n    final IndexSearcher searcher = new IndexSearcher(getLeafContext());\n    searcher.setQueryCache(null);\n    if (mustRewriteQuery) {\n      for (final String field : fieldNames) {\n        final SpanQuery rewrittenQuery = (SpanQuery) spanQuery.rewrite(getLeafContext().reader());\n        queries.put(field, rewrittenQuery);\n        rewrittenQuery.createWeight(searcher, false).extractTerms(nonWeightedTerms);\n      }\n    } else {\n      spanQuery.createWeight(searcher, false).extractTerms(nonWeightedTerms);\n    }\n\n    List<PositionSpan> spanPositions = new ArrayList<>();\n\n    for (final String field : fieldNames) {\n      final SpanQuery q;\n      if (mustRewriteQuery) {\n        q = queries.get(field);\n      } else {\n        q = spanQuery;\n      }\n      LeafReaderContext context = getLeafContext();\n      SpanWeight w = (SpanWeight) searcher.createNormalizedWeight(q, false);\n      Bits acceptDocs = context.reader().getLiveDocs();\n      final Spans spans = w.getSpans(context, acceptDocs);\n      if (spans == null) {\n        return;\n      }\n\n      // collect span positions\n      while (spans.nextDoc() != Spans.NO_MORE_DOCS) {\n        while (spans.nextStartPosition() != Spans.NO_MORE_POSITIONS) {\n          spanPositions.add(new PositionSpan(spans.startPosition(), spans.endPosition() - 1));\n        }\n      }\n    }\n\n    if (spanPositions.size() == 0) {\n      // no spans found\n      return;\n    }\n\n    for (final Term queryTerm :  nonWeightedTerms) {\n\n      if (fieldNameComparator(queryTerm.field())) {\n        WeightedSpanTerm weightedSpanTerm = terms.get(queryTerm.text());\n\n        if (weightedSpanTerm == null) {\n          weightedSpanTerm = new WeightedSpanTerm(spanQuery.getBoost(), queryTerm.text());\n          weightedSpanTerm.addPositionSpans(spanPositions);\n          weightedSpanTerm.positionSensitive = true;\n          terms.put(queryTerm.text(), weightedSpanTerm);\n        } else {\n          if (spanPositions.size() > 0) {\n            weightedSpanTerm.addPositionSpans(spanPositions);\n          }\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0f4464508ee83288c8c4585b533f9faaa93aa314","date":1435240759,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/highlighter/src/java/org/apache/lucene/search/highlight/WeightedSpanTermExtractor#extractWeightedSpanTerms(Map[String,WeightedSpanTerm],SpanQuery).mjava","pathOld":"lucene/highlighter/src/java/org/apache/lucene/search/highlight/WeightedSpanTermExtractor#extractWeightedSpanTerms(Map[String,WeightedSpanTerm],SpanQuery).mjava","sourceNew":"  /**\n   * Fills a <code>Map</code> with {@link WeightedSpanTerm}s using the terms from the supplied <code>SpanQuery</code>.\n   * \n   * @param terms\n   *          Map to place created WeightedSpanTerms in\n   * @param spanQuery\n   *          SpanQuery to extract Terms from\n   * @throws IOException If there is a low-level I/O error\n   */\n  protected void extractWeightedSpanTerms(Map<String,WeightedSpanTerm> terms, SpanQuery spanQuery) throws IOException {\n    Set<String> fieldNames;\n\n    if (fieldName == null) {\n      fieldNames = new HashSet<>();\n      collectSpanQueryFields(spanQuery, fieldNames);\n    } else {\n      fieldNames = new HashSet<>(1);\n      fieldNames.add(fieldName);\n    }\n    // To support the use of the default field name\n    if (defaultField != null) {\n      fieldNames.add(defaultField);\n    }\n    \n    Map<String, SpanQuery> queries = new HashMap<>();\n \n    Set<Term> nonWeightedTerms = new HashSet<>();\n    final boolean mustRewriteQuery = mustRewriteQuery(spanQuery);\n    final IndexSearcher searcher = new IndexSearcher(getLeafContext());\n    searcher.setQueryCache(null);\n    if (mustRewriteQuery) {\n      for (final String field : fieldNames) {\n        final SpanQuery rewrittenQuery = (SpanQuery) spanQuery.rewrite(getLeafContext().reader());\n        queries.put(field, rewrittenQuery);\n        rewrittenQuery.createWeight(searcher, false).extractTerms(nonWeightedTerms);\n      }\n    } else {\n      spanQuery.createWeight(searcher, false).extractTerms(nonWeightedTerms);\n    }\n\n    List<PositionSpan> spanPositions = new ArrayList<>();\n\n    for (final String field : fieldNames) {\n      final SpanQuery q;\n      if (mustRewriteQuery) {\n        q = queries.get(field);\n      } else {\n        q = spanQuery;\n      }\n      LeafReaderContext context = getLeafContext();\n      SpanWeight w = (SpanWeight) searcher.createNormalizedWeight(q, false);\n      Bits acceptDocs = context.reader().getLiveDocs();\n      final Spans spans = w.getSpans(context, SpanWeight.Postings.POSITIONS);\n      if (spans == null) {\n        return;\n      }\n\n      // collect span positions\n      while (spans.nextDoc() != Spans.NO_MORE_DOCS) {\n        if (acceptDocs != null && acceptDocs.get(spans.docID()) == false) {\n          continue;\n        }\n        while (spans.nextStartPosition() != Spans.NO_MORE_POSITIONS) {\n          spanPositions.add(new PositionSpan(spans.startPosition(), spans.endPosition() - 1));\n        }\n      }\n    }\n\n    if (spanPositions.size() == 0) {\n      // no spans found\n      return;\n    }\n\n    for (final Term queryTerm :  nonWeightedTerms) {\n\n      if (fieldNameComparator(queryTerm.field())) {\n        WeightedSpanTerm weightedSpanTerm = terms.get(queryTerm.text());\n\n        if (weightedSpanTerm == null) {\n          weightedSpanTerm = new WeightedSpanTerm(spanQuery.getBoost(), queryTerm.text());\n          weightedSpanTerm.addPositionSpans(spanPositions);\n          weightedSpanTerm.positionSensitive = true;\n          terms.put(queryTerm.text(), weightedSpanTerm);\n        } else {\n          if (spanPositions.size() > 0) {\n            weightedSpanTerm.addPositionSpans(spanPositions);\n          }\n        }\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Fills a <code>Map</code> with {@link WeightedSpanTerm}s using the terms from the supplied <code>SpanQuery</code>.\n   * \n   * @param terms\n   *          Map to place created WeightedSpanTerms in\n   * @param spanQuery\n   *          SpanQuery to extract Terms from\n   * @throws IOException If there is a low-level I/O error\n   */\n  protected void extractWeightedSpanTerms(Map<String,WeightedSpanTerm> terms, SpanQuery spanQuery) throws IOException {\n    Set<String> fieldNames;\n\n    if (fieldName == null) {\n      fieldNames = new HashSet<>();\n      collectSpanQueryFields(spanQuery, fieldNames);\n    } else {\n      fieldNames = new HashSet<>(1);\n      fieldNames.add(fieldName);\n    }\n    // To support the use of the default field name\n    if (defaultField != null) {\n      fieldNames.add(defaultField);\n    }\n    \n    Map<String, SpanQuery> queries = new HashMap<>();\n \n    Set<Term> nonWeightedTerms = new HashSet<>();\n    final boolean mustRewriteQuery = mustRewriteQuery(spanQuery);\n    final IndexSearcher searcher = new IndexSearcher(getLeafContext());\n    searcher.setQueryCache(null);\n    if (mustRewriteQuery) {\n      for (final String field : fieldNames) {\n        final SpanQuery rewrittenQuery = (SpanQuery) spanQuery.rewrite(getLeafContext().reader());\n        queries.put(field, rewrittenQuery);\n        rewrittenQuery.createWeight(searcher, false).extractTerms(nonWeightedTerms);\n      }\n    } else {\n      spanQuery.createWeight(searcher, false).extractTerms(nonWeightedTerms);\n    }\n\n    List<PositionSpan> spanPositions = new ArrayList<>();\n\n    for (final String field : fieldNames) {\n      final SpanQuery q;\n      if (mustRewriteQuery) {\n        q = queries.get(field);\n      } else {\n        q = spanQuery;\n      }\n      LeafReaderContext context = getLeafContext();\n      SpanWeight w = (SpanWeight) searcher.createNormalizedWeight(q, false);\n      Bits acceptDocs = context.reader().getLiveDocs();\n      final Spans spans = w.getSpans(context, acceptDocs, SpanWeight.Postings.POSITIONS);\n      if (spans == null) {\n        return;\n      }\n\n      // collect span positions\n      while (spans.nextDoc() != Spans.NO_MORE_DOCS) {\n        while (spans.nextStartPosition() != Spans.NO_MORE_POSITIONS) {\n          spanPositions.add(new PositionSpan(spans.startPosition(), spans.endPosition() - 1));\n        }\n      }\n    }\n\n    if (spanPositions.size() == 0) {\n      // no spans found\n      return;\n    }\n\n    for (final Term queryTerm :  nonWeightedTerms) {\n\n      if (fieldNameComparator(queryTerm.field())) {\n        WeightedSpanTerm weightedSpanTerm = terms.get(queryTerm.text());\n\n        if (weightedSpanTerm == null) {\n          weightedSpanTerm = new WeightedSpanTerm(spanQuery.getBoost(), queryTerm.text());\n          weightedSpanTerm.addPositionSpans(spanPositions);\n          weightedSpanTerm.positionSensitive = true;\n          terms.put(queryTerm.text(), weightedSpanTerm);\n        } else {\n          if (spanPositions.size() > 0) {\n            weightedSpanTerm.addPositionSpans(spanPositions);\n          }\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2dfdf766e55e943d942055d7de53c7ad6bc45283","date":1441632886,"type":5,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/highlighter/src/java/org/apache/lucene/search/highlight/WeightedSpanTermExtractor#extractWeightedSpanTerms(Map[String,WeightedSpanTerm],SpanQuery,float).mjava","pathOld":"lucene/highlighter/src/java/org/apache/lucene/search/highlight/WeightedSpanTermExtractor#extractWeightedSpanTerms(Map[String,WeightedSpanTerm],SpanQuery).mjava","sourceNew":"  /**\n   * Fills a <code>Map</code> with {@link WeightedSpanTerm}s using the terms from the supplied <code>SpanQuery</code>.\n   * \n   * @param terms\n   *          Map to place created WeightedSpanTerms in\n   * @param spanQuery\n   *          SpanQuery to extract Terms from\n   * @throws IOException If there is a low-level I/O error\n   */\n  protected void extractWeightedSpanTerms(Map<String,WeightedSpanTerm> terms, SpanQuery spanQuery, float boost) throws IOException {\n    Set<String> fieldNames;\n\n    if (fieldName == null) {\n      fieldNames = new HashSet<>();\n      collectSpanQueryFields(spanQuery, fieldNames);\n    } else {\n      fieldNames = new HashSet<>(1);\n      fieldNames.add(fieldName);\n    }\n    // To support the use of the default field name\n    if (defaultField != null) {\n      fieldNames.add(defaultField);\n    }\n    \n    Map<String, SpanQuery> queries = new HashMap<>();\n \n    Set<Term> nonWeightedTerms = new HashSet<>();\n    final boolean mustRewriteQuery = mustRewriteQuery(spanQuery);\n    final IndexSearcher searcher = new IndexSearcher(getLeafContext());\n    searcher.setQueryCache(null);\n    if (mustRewriteQuery) {\n      for (final String field : fieldNames) {\n        final SpanQuery rewrittenQuery = (SpanQuery) spanQuery.rewrite(getLeafContext().reader());\n        queries.put(field, rewrittenQuery);\n        rewrittenQuery.createWeight(searcher, false).extractTerms(nonWeightedTerms);\n      }\n    } else {\n      spanQuery.createWeight(searcher, false).extractTerms(nonWeightedTerms);\n    }\n\n    List<PositionSpan> spanPositions = new ArrayList<>();\n\n    for (final String field : fieldNames) {\n      final SpanQuery q;\n      if (mustRewriteQuery) {\n        q = queries.get(field);\n      } else {\n        q = spanQuery;\n      }\n      LeafReaderContext context = getLeafContext();\n      SpanWeight w = (SpanWeight) searcher.createNormalizedWeight(q, false);\n      Bits acceptDocs = context.reader().getLiveDocs();\n      final Spans spans = w.getSpans(context, SpanWeight.Postings.POSITIONS);\n      if (spans == null) {\n        return;\n      }\n\n      // collect span positions\n      while (spans.nextDoc() != Spans.NO_MORE_DOCS) {\n        if (acceptDocs != null && acceptDocs.get(spans.docID()) == false) {\n          continue;\n        }\n        while (spans.nextStartPosition() != Spans.NO_MORE_POSITIONS) {\n          spanPositions.add(new PositionSpan(spans.startPosition(), spans.endPosition() - 1));\n        }\n      }\n    }\n\n    if (spanPositions.size() == 0) {\n      // no spans found\n      return;\n    }\n\n    for (final Term queryTerm :  nonWeightedTerms) {\n\n      if (fieldNameComparator(queryTerm.field())) {\n        WeightedSpanTerm weightedSpanTerm = terms.get(queryTerm.text());\n\n        if (weightedSpanTerm == null) {\n          weightedSpanTerm = new WeightedSpanTerm(boost, queryTerm.text());\n          weightedSpanTerm.addPositionSpans(spanPositions);\n          weightedSpanTerm.positionSensitive = true;\n          terms.put(queryTerm.text(), weightedSpanTerm);\n        } else {\n          if (spanPositions.size() > 0) {\n            weightedSpanTerm.addPositionSpans(spanPositions);\n          }\n        }\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Fills a <code>Map</code> with {@link WeightedSpanTerm}s using the terms from the supplied <code>SpanQuery</code>.\n   * \n   * @param terms\n   *          Map to place created WeightedSpanTerms in\n   * @param spanQuery\n   *          SpanQuery to extract Terms from\n   * @throws IOException If there is a low-level I/O error\n   */\n  protected void extractWeightedSpanTerms(Map<String,WeightedSpanTerm> terms, SpanQuery spanQuery) throws IOException {\n    Set<String> fieldNames;\n\n    if (fieldName == null) {\n      fieldNames = new HashSet<>();\n      collectSpanQueryFields(spanQuery, fieldNames);\n    } else {\n      fieldNames = new HashSet<>(1);\n      fieldNames.add(fieldName);\n    }\n    // To support the use of the default field name\n    if (defaultField != null) {\n      fieldNames.add(defaultField);\n    }\n    \n    Map<String, SpanQuery> queries = new HashMap<>();\n \n    Set<Term> nonWeightedTerms = new HashSet<>();\n    final boolean mustRewriteQuery = mustRewriteQuery(spanQuery);\n    final IndexSearcher searcher = new IndexSearcher(getLeafContext());\n    searcher.setQueryCache(null);\n    if (mustRewriteQuery) {\n      for (final String field : fieldNames) {\n        final SpanQuery rewrittenQuery = (SpanQuery) spanQuery.rewrite(getLeafContext().reader());\n        queries.put(field, rewrittenQuery);\n        rewrittenQuery.createWeight(searcher, false).extractTerms(nonWeightedTerms);\n      }\n    } else {\n      spanQuery.createWeight(searcher, false).extractTerms(nonWeightedTerms);\n    }\n\n    List<PositionSpan> spanPositions = new ArrayList<>();\n\n    for (final String field : fieldNames) {\n      final SpanQuery q;\n      if (mustRewriteQuery) {\n        q = queries.get(field);\n      } else {\n        q = spanQuery;\n      }\n      LeafReaderContext context = getLeafContext();\n      SpanWeight w = (SpanWeight) searcher.createNormalizedWeight(q, false);\n      Bits acceptDocs = context.reader().getLiveDocs();\n      final Spans spans = w.getSpans(context, SpanWeight.Postings.POSITIONS);\n      if (spans == null) {\n        return;\n      }\n\n      // collect span positions\n      while (spans.nextDoc() != Spans.NO_MORE_DOCS) {\n        if (acceptDocs != null && acceptDocs.get(spans.docID()) == false) {\n          continue;\n        }\n        while (spans.nextStartPosition() != Spans.NO_MORE_POSITIONS) {\n          spanPositions.add(new PositionSpan(spans.startPosition(), spans.endPosition() - 1));\n        }\n      }\n    }\n\n    if (spanPositions.size() == 0) {\n      // no spans found\n      return;\n    }\n\n    for (final Term queryTerm :  nonWeightedTerms) {\n\n      if (fieldNameComparator(queryTerm.field())) {\n        WeightedSpanTerm weightedSpanTerm = terms.get(queryTerm.text());\n\n        if (weightedSpanTerm == null) {\n          weightedSpanTerm = new WeightedSpanTerm(spanQuery.getBoost(), queryTerm.text());\n          weightedSpanTerm.addPositionSpans(spanPositions);\n          weightedSpanTerm.positionSensitive = true;\n          terms.put(queryTerm.text(), weightedSpanTerm);\n        } else {\n          if (spanPositions.size() > 0) {\n            weightedSpanTerm.addPositionSpans(spanPositions);\n          }\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"c7bd1fdddb8e84c1857d1a55c32ced51f0ed2069":["b89678825b68eccaf09e6ab71675fc0b0af1e099"],"b1eb427f2c6beed80d1724555fc1db003ccf3030":["c9fb5f46e264daf5ba3860defe623a89d202dd87"],"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["eee5f2a24465d2c9a5f86ab84b7c35041a30fda8"],"29aea3139c4326c0501d75d51059855463220279":["c257cd8ddb1ed5632a36c7488614a2ee21705d24"],"69fb899bdb552a5f4aba2498bbd358be2fda865b":["30de45e50bdc1a79a6797f34dca6271c8866cb6e"],"3e4d4ec39bf5396230748ca859ff05ab024b6fc5":["c7bd1fdddb8e84c1857d1a55c32ced51f0ed2069","081b68cb9e8f4b5405b40bfb223fd7c587171aa1"],"2dfdf766e55e943d942055d7de53c7ad6bc45283":["0f4464508ee83288c8c4585b533f9faaa93aa314"],"c257cd8ddb1ed5632a36c7488614a2ee21705d24":["8f6e2f8b5923e09c68fcefca2b75678c8d9c89f2"],"05c52ac194342b760b830342ee8423fcf00e54d0":["69fb899bdb552a5f4aba2498bbd358be2fda865b"],"c9fb5f46e264daf5ba3860defe623a89d202dd87":["634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"0f4464508ee83288c8c4585b533f9faaa93aa314":["29aea3139c4326c0501d75d51059855463220279"],"081b68cb9e8f4b5405b40bfb223fd7c587171aa1":["c7bd1fdddb8e84c1857d1a55c32ced51f0ed2069"],"b89678825b68eccaf09e6ab71675fc0b0af1e099":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"6c757ac42dd1f3f893db5c4d89c61cbe1a9fab6c":["fab172655716b96f7e42376116235017a922de3a","69fb899bdb552a5f4aba2498bbd358be2fda865b"],"8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee":["081b68cb9e8f4b5405b40bfb223fd7c587171aa1"],"2d530e71ed32ab23b34ca3fc72b080a554a40404":["05c52ac194342b760b830342ee8423fcf00e54d0"],"8f6e2f8b5923e09c68fcefca2b75678c8d9c89f2":["2d530e71ed32ab23b34ca3fc72b080a554a40404"],"30de45e50bdc1a79a6797f34dca6271c8866cb6e":["b1eb427f2c6beed80d1724555fc1db003ccf3030"],"fab172655716b96f7e42376116235017a922de3a":["b1eb427f2c6beed80d1724555fc1db003ccf3030","30de45e50bdc1a79a6797f34dca6271c8866cb6e"],"eee5f2a24465d2c9a5f86ab84b7c35041a30fda8":["081b68cb9e8f4b5405b40bfb223fd7c587171aa1"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["2dfdf766e55e943d942055d7de53c7ad6bc45283"]},"commit2Childs":{"c7bd1fdddb8e84c1857d1a55c32ced51f0ed2069":["3e4d4ec39bf5396230748ca859ff05ab024b6fc5","081b68cb9e8f4b5405b40bfb223fd7c587171aa1"],"b1eb427f2c6beed80d1724555fc1db003ccf3030":["30de45e50bdc1a79a6797f34dca6271c8866cb6e","fab172655716b96f7e42376116235017a922de3a"],"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["c9fb5f46e264daf5ba3860defe623a89d202dd87"],"29aea3139c4326c0501d75d51059855463220279":["0f4464508ee83288c8c4585b533f9faaa93aa314"],"69fb899bdb552a5f4aba2498bbd358be2fda865b":["05c52ac194342b760b830342ee8423fcf00e54d0","6c757ac42dd1f3f893db5c4d89c61cbe1a9fab6c"],"3e4d4ec39bf5396230748ca859ff05ab024b6fc5":[],"2dfdf766e55e943d942055d7de53c7ad6bc45283":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"c257cd8ddb1ed5632a36c7488614a2ee21705d24":["29aea3139c4326c0501d75d51059855463220279"],"05c52ac194342b760b830342ee8423fcf00e54d0":["2d530e71ed32ab23b34ca3fc72b080a554a40404"],"c9fb5f46e264daf5ba3860defe623a89d202dd87":["b1eb427f2c6beed80d1724555fc1db003ccf3030"],"b89678825b68eccaf09e6ab71675fc0b0af1e099":["c7bd1fdddb8e84c1857d1a55c32ced51f0ed2069"],"081b68cb9e8f4b5405b40bfb223fd7c587171aa1":["3e4d4ec39bf5396230748ca859ff05ab024b6fc5","8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee","eee5f2a24465d2c9a5f86ab84b7c35041a30fda8"],"0f4464508ee83288c8c4585b533f9faaa93aa314":["2dfdf766e55e943d942055d7de53c7ad6bc45283"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["b89678825b68eccaf09e6ab71675fc0b0af1e099"],"6c757ac42dd1f3f893db5c4d89c61cbe1a9fab6c":[],"8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee":[],"2d530e71ed32ab23b34ca3fc72b080a554a40404":["8f6e2f8b5923e09c68fcefca2b75678c8d9c89f2"],"8f6e2f8b5923e09c68fcefca2b75678c8d9c89f2":["c257cd8ddb1ed5632a36c7488614a2ee21705d24"],"30de45e50bdc1a79a6797f34dca6271c8866cb6e":["69fb899bdb552a5f4aba2498bbd358be2fda865b","fab172655716b96f7e42376116235017a922de3a"],"fab172655716b96f7e42376116235017a922de3a":["6c757ac42dd1f3f893db5c4d89c61cbe1a9fab6c"],"eee5f2a24465d2c9a5f86ab84b7c35041a30fda8":["634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["3e4d4ec39bf5396230748ca859ff05ab024b6fc5","6c757ac42dd1f3f893db5c4d89c61cbe1a9fab6c","8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}