{"path":"lucene/src/test/org/apache/lucene/index/codecs/appending/TestAppendingCodec#testCodec().mjava","commits":[{"id":"9eda19c7aeddd50f2d8bc261c8567cdeb7f094d7","date":1323207588,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/codecs/appending/TestAppendingCodec#testCodec().mjava","pathOld":"lucene/contrib/misc/src/test/org/apache/lucene/index/codecs/appending/TestAppendingCodec#testCodec().mjava","sourceNew":"  public void testCodec() throws Exception {\n    Directory dir = new AppendingRAMDirectory(random, new RAMDirectory());\n    IndexWriterConfig cfg = new IndexWriterConfig(Version.LUCENE_40, new MockAnalyzer(random));\n    \n    cfg.setCodec(new AppendingCodec());\n    ((TieredMergePolicy)cfg.getMergePolicy()).setUseCompoundFile(false);\n    IndexWriter writer = new IndexWriter(dir, cfg);\n    Document doc = new Document();\n    FieldType storedTextType = new FieldType(TextField.TYPE_STORED);\n    storedTextType.setStoreTermVectors(true);\n    storedTextType.setStoreTermVectorPositions(true);\n    storedTextType.setStoreTermVectorOffsets(true);\n    doc.add(newField(\"f\", text, storedTextType));\n    writer.addDocument(doc);\n    writer.commit();\n    writer.addDocument(doc);\n    writer.forceMerge(1);\n    writer.close();\n    IndexReader reader = IndexReader.open(dir, null, true, 1);\n    assertEquals(2, reader.numDocs());\n    Document doc2 = reader.document(0);\n    assertEquals(text, doc2.get(\"f\"));\n    Fields fields = MultiFields.getFields(reader);\n    Terms terms = fields.terms(\"f\");\n    assertNotNull(terms);\n    TermsEnum te = terms.iterator(null);\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"quick\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"brown\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"fox\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"jumped\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"over\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"lazy\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"dog\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"the\")));\n    DocsEnum de = te.docs(null, null, true);\n    assertTrue(de.advance(0) != DocsEnum.NO_MORE_DOCS);\n    assertEquals(2, de.freq());\n    assertTrue(de.advance(1) != DocsEnum.NO_MORE_DOCS);\n    assertTrue(de.advance(2) == DocsEnum.NO_MORE_DOCS);\n    reader.close();\n  }\n\n","sourceOld":"  public void testCodec() throws Exception {\n    Directory dir = new AppendingRAMDirectory(random, new RAMDirectory());\n    IndexWriterConfig cfg = new IndexWriterConfig(Version.LUCENE_40, new MockAnalyzer(random));\n    \n    cfg.setCodec(new AppendingCodec());\n    ((TieredMergePolicy)cfg.getMergePolicy()).setUseCompoundFile(false);\n    IndexWriter writer = new IndexWriter(dir, cfg);\n    Document doc = new Document();\n    FieldType storedTextType = new FieldType(TextField.TYPE_STORED);\n    storedTextType.setStoreTermVectors(true);\n    storedTextType.setStoreTermVectorPositions(true);\n    storedTextType.setStoreTermVectorOffsets(true);\n    doc.add(newField(\"f\", text, storedTextType));\n    writer.addDocument(doc);\n    writer.commit();\n    writer.addDocument(doc);\n    writer.forceMerge(1);\n    writer.close();\n    IndexReader reader = IndexReader.open(dir, null, true, 1);\n    assertEquals(2, reader.numDocs());\n    Document doc2 = reader.document(0);\n    assertEquals(text, doc2.get(\"f\"));\n    Fields fields = MultiFields.getFields(reader);\n    Terms terms = fields.terms(\"f\");\n    assertNotNull(terms);\n    TermsEnum te = terms.iterator(null);\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"quick\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"brown\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"fox\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"jumped\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"over\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"lazy\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"dog\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"the\")));\n    DocsEnum de = te.docs(null, null, true);\n    assertTrue(de.advance(0) != DocsEnum.NO_MORE_DOCS);\n    assertEquals(2, de.freq());\n    assertTrue(de.advance(1) != DocsEnum.NO_MORE_DOCS);\n    assertTrue(de.advance(2) == DocsEnum.NO_MORE_DOCS);\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"929d416aad35e36f2d2743c625e05e23908e7563","date":1323209095,"type":1,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/codecs/appending/TestAppendingCodec#testCodec().mjava","pathOld":"lucene/contrib/misc/src/test/org/apache/lucene/index/codecs/appending/TestAppendingCodec#testCodec().mjava","sourceNew":"  public void testCodec() throws Exception {\n    Directory dir = new AppendingRAMDirectory(random, new RAMDirectory());\n    IndexWriterConfig cfg = new IndexWriterConfig(Version.LUCENE_40, new MockAnalyzer(random));\n    \n    cfg.setCodec(new AppendingCodec());\n    ((TieredMergePolicy)cfg.getMergePolicy()).setUseCompoundFile(false);\n    IndexWriter writer = new IndexWriter(dir, cfg);\n    Document doc = new Document();\n    FieldType storedTextType = new FieldType(TextField.TYPE_STORED);\n    storedTextType.setStoreTermVectors(true);\n    storedTextType.setStoreTermVectorPositions(true);\n    storedTextType.setStoreTermVectorOffsets(true);\n    doc.add(newField(\"f\", text, storedTextType));\n    writer.addDocument(doc);\n    writer.commit();\n    writer.addDocument(doc);\n    writer.forceMerge(1);\n    writer.close();\n    IndexReader reader = IndexReader.open(dir, 1);\n    assertEquals(2, reader.numDocs());\n    Document doc2 = reader.document(0);\n    assertEquals(text, doc2.get(\"f\"));\n    Fields fields = MultiFields.getFields(reader);\n    Terms terms = fields.terms(\"f\");\n    assertNotNull(terms);\n    TermsEnum te = terms.iterator(null);\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"quick\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"brown\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"fox\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"jumped\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"over\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"lazy\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"dog\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"the\")));\n    DocsEnum de = te.docs(null, null, true);\n    assertTrue(de.advance(0) != DocsEnum.NO_MORE_DOCS);\n    assertEquals(2, de.freq());\n    assertTrue(de.advance(1) != DocsEnum.NO_MORE_DOCS);\n    assertTrue(de.advance(2) == DocsEnum.NO_MORE_DOCS);\n    reader.close();\n  }\n\n","sourceOld":"  public void testCodec() throws Exception {\n    Directory dir = new AppendingRAMDirectory(random, new RAMDirectory());\n    IndexWriterConfig cfg = new IndexWriterConfig(Version.LUCENE_40, new MockAnalyzer(random));\n    \n    cfg.setCodec(new AppendingCodec());\n    ((TieredMergePolicy)cfg.getMergePolicy()).setUseCompoundFile(false);\n    IndexWriter writer = new IndexWriter(dir, cfg);\n    Document doc = new Document();\n    FieldType storedTextType = new FieldType(TextField.TYPE_STORED);\n    storedTextType.setStoreTermVectors(true);\n    storedTextType.setStoreTermVectorPositions(true);\n    storedTextType.setStoreTermVectorOffsets(true);\n    doc.add(newField(\"f\", text, storedTextType));\n    writer.addDocument(doc);\n    writer.commit();\n    writer.addDocument(doc);\n    writer.forceMerge(1);\n    writer.close();\n    IndexReader reader = IndexReader.open(dir, 1);\n    assertEquals(2, reader.numDocs());\n    Document doc2 = reader.document(0);\n    assertEquals(text, doc2.get(\"f\"));\n    Fields fields = MultiFields.getFields(reader);\n    Terms terms = fields.terms(\"f\");\n    assertNotNull(terms);\n    TermsEnum te = terms.iterator(null);\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"quick\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"brown\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"fox\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"jumped\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"over\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"lazy\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"dog\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"the\")));\n    DocsEnum de = te.docs(null, null, true);\n    assertTrue(de.advance(0) != DocsEnum.NO_MORE_DOCS);\n    assertEquals(2, de.freq());\n    assertTrue(de.advance(1) != DocsEnum.NO_MORE_DOCS);\n    assertTrue(de.advance(2) == DocsEnum.NO_MORE_DOCS);\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3615ce4a1f785ae1b779244de52c6a7d99227e60","date":1323422019,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/codecs/appending/TestAppendingCodec#testCodec().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/codecs/appending/TestAppendingCodec#testCodec().mjava","sourceNew":"  public void testCodec() throws Exception {\n    Directory dir = new AppendingRAMDirectory(random, new RAMDirectory());\n    IndexWriterConfig cfg = new IndexWriterConfig(Version.LUCENE_40, new MockAnalyzer(random));\n    \n    cfg.setCodec(new AppendingCodec());\n    ((TieredMergePolicy)cfg.getMergePolicy()).setUseCompoundFile(false);\n    IndexWriter writer = new IndexWriter(dir, cfg);\n    Document doc = new Document();\n    FieldType storedTextType = new FieldType(TextField.TYPE_STORED);\n    storedTextType.setStoreTermVectors(true);\n    storedTextType.setStoreTermVectorPositions(true);\n    storedTextType.setStoreTermVectorOffsets(true);\n    doc.add(newField(\"f\", text, storedTextType));\n    writer.addDocument(doc);\n    writer.commit();\n    writer.addDocument(doc);\n    writer.forceMerge(1);\n    writer.close();\n    IndexReader reader = IndexReader.open(dir, 1);\n    assertEquals(2, reader.numDocs());\n    Document doc2 = reader.document(0);\n    assertEquals(text, doc2.get(\"f\"));\n    Fields fields = MultiFields.getFields(reader);\n    Terms terms = fields.terms(\"f\");\n    assertNotNull(terms);\n    TermsEnum te = terms.iterator(null);\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"quick\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"brown\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"fox\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"jumped\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"over\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"lazy\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"dog\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"the\")));\n    DocsEnum de = te.docs(null, null, true);\n    assertTrue(de.advance(0) != DocsEnum.NO_MORE_DOCS);\n    assertEquals(2, de.freq());\n    assertTrue(de.advance(1) != DocsEnum.NO_MORE_DOCS);\n    assertTrue(de.advance(2) == DocsEnum.NO_MORE_DOCS);\n    reader.close();\n  }\n\n","sourceOld":"  public void testCodec() throws Exception {\n    Directory dir = new AppendingRAMDirectory(random, new RAMDirectory());\n    IndexWriterConfig cfg = new IndexWriterConfig(Version.LUCENE_40, new MockAnalyzer(random));\n    \n    cfg.setCodec(new AppendingCodec());\n    ((TieredMergePolicy)cfg.getMergePolicy()).setUseCompoundFile(false);\n    IndexWriter writer = new IndexWriter(dir, cfg);\n    Document doc = new Document();\n    FieldType storedTextType = new FieldType(TextField.TYPE_STORED);\n    storedTextType.setStoreTermVectors(true);\n    storedTextType.setStoreTermVectorPositions(true);\n    storedTextType.setStoreTermVectorOffsets(true);\n    doc.add(newField(\"f\", text, storedTextType));\n    writer.addDocument(doc);\n    writer.commit();\n    writer.addDocument(doc);\n    writer.forceMerge(1);\n    writer.close();\n    IndexReader reader = IndexReader.open(dir, null, true, 1);\n    assertEquals(2, reader.numDocs());\n    Document doc2 = reader.document(0);\n    assertEquals(text, doc2.get(\"f\"));\n    Fields fields = MultiFields.getFields(reader);\n    Terms terms = fields.terms(\"f\");\n    assertNotNull(terms);\n    TermsEnum te = terms.iterator(null);\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"quick\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"brown\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"fox\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"jumped\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"over\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"lazy\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"dog\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"the\")));\n    DocsEnum de = te.docs(null, null, true);\n    assertTrue(de.advance(0) != DocsEnum.NO_MORE_DOCS);\n    assertEquals(2, de.freq());\n    assertTrue(de.advance(1) != DocsEnum.NO_MORE_DOCS);\n    assertTrue(de.advance(2) == DocsEnum.NO_MORE_DOCS);\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00","date":1323437438,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/codecs/appending/TestAppendingCodec#testCodec().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/codecs/appending/TestAppendingCodec#testCodec().mjava","sourceNew":"  public void testCodec() throws Exception {\n    Directory dir = new AppendingRAMDirectory(random, new RAMDirectory());\n    IndexWriterConfig cfg = new IndexWriterConfig(Version.LUCENE_40, new MockAnalyzer(random));\n    \n    cfg.setCodec(new AppendingCodec());\n    ((TieredMergePolicy)cfg.getMergePolicy()).setUseCompoundFile(false);\n    IndexWriter writer = new IndexWriter(dir, cfg);\n    Document doc = new Document();\n    FieldType storedTextType = new FieldType(TextField.TYPE_STORED);\n    storedTextType.setStoreTermVectors(true);\n    storedTextType.setStoreTermVectorPositions(true);\n    storedTextType.setStoreTermVectorOffsets(true);\n    doc.add(newField(\"f\", text, storedTextType));\n    writer.addDocument(doc);\n    writer.commit();\n    writer.addDocument(doc);\n    writer.forceMerge(1);\n    writer.close();\n    IndexReader reader = IndexReader.open(dir, 1);\n    assertEquals(2, reader.numDocs());\n    Document doc2 = reader.document(0);\n    assertEquals(text, doc2.get(\"f\"));\n    Fields fields = MultiFields.getFields(reader);\n    Terms terms = fields.terms(\"f\");\n    assertNotNull(terms);\n    TermsEnum te = terms.iterator(null);\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"quick\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"brown\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"fox\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"jumped\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"over\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"lazy\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"dog\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"the\")));\n    DocsEnum de = te.docs(null, null, true);\n    assertTrue(de.advance(0) != DocsEnum.NO_MORE_DOCS);\n    assertEquals(2, de.freq());\n    assertTrue(de.advance(1) != DocsEnum.NO_MORE_DOCS);\n    assertTrue(de.advance(2) == DocsEnum.NO_MORE_DOCS);\n    reader.close();\n  }\n\n","sourceOld":"  public void testCodec() throws Exception {\n    Directory dir = new AppendingRAMDirectory(random, new RAMDirectory());\n    IndexWriterConfig cfg = new IndexWriterConfig(Version.LUCENE_40, new MockAnalyzer(random));\n    \n    cfg.setCodec(new AppendingCodec());\n    ((TieredMergePolicy)cfg.getMergePolicy()).setUseCompoundFile(false);\n    IndexWriter writer = new IndexWriter(dir, cfg);\n    Document doc = new Document();\n    FieldType storedTextType = new FieldType(TextField.TYPE_STORED);\n    storedTextType.setStoreTermVectors(true);\n    storedTextType.setStoreTermVectorPositions(true);\n    storedTextType.setStoreTermVectorOffsets(true);\n    doc.add(newField(\"f\", text, storedTextType));\n    writer.addDocument(doc);\n    writer.commit();\n    writer.addDocument(doc);\n    writer.forceMerge(1);\n    writer.close();\n    IndexReader reader = IndexReader.open(dir, null, true, 1);\n    assertEquals(2, reader.numDocs());\n    Document doc2 = reader.document(0);\n    assertEquals(text, doc2.get(\"f\"));\n    Fields fields = MultiFields.getFields(reader);\n    Terms terms = fields.terms(\"f\");\n    assertNotNull(terms);\n    TermsEnum te = terms.iterator(null);\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"quick\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"brown\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"fox\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"jumped\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"over\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"lazy\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"dog\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"the\")));\n    DocsEnum de = te.docs(null, null, true);\n    assertTrue(de.advance(0) != DocsEnum.NO_MORE_DOCS);\n    assertEquals(2, de.freq());\n    assertTrue(de.advance(1) != DocsEnum.NO_MORE_DOCS);\n    assertTrue(de.advance(2) == DocsEnum.NO_MORE_DOCS);\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a0ae5e3ed1232483b7b8a014f175a5fe43595982","date":1324062192,"type":5,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/codecs/appending/TestAppendingCodec#testCodec().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/codecs/appending/TestAppendingCodec#testCodec().mjava","sourceNew":"  public void testCodec() throws Exception {\n    Directory dir = new AppendingRAMDirectory(random, new RAMDirectory());\n    IndexWriterConfig cfg = new IndexWriterConfig(Version.LUCENE_40, new MockAnalyzer(random));\n    \n    cfg.setCodec(new AppendingCodec());\n    ((TieredMergePolicy)cfg.getMergePolicy()).setUseCompoundFile(false);\n    IndexWriter writer = new IndexWriter(dir, cfg);\n    Document doc = new Document();\n    FieldType storedTextType = new FieldType(TextField.TYPE_STORED);\n    storedTextType.setStoreTermVectors(true);\n    storedTextType.setStoreTermVectorPositions(true);\n    storedTextType.setStoreTermVectorOffsets(true);\n    doc.add(newField(\"f\", text, storedTextType));\n    writer.addDocument(doc);\n    writer.commit();\n    writer.addDocument(doc);\n    writer.forceMerge(1);\n    writer.close();\n    IndexReader reader = IndexReader.open(dir, 1);\n    assertEquals(2, reader.numDocs());\n    Document doc2 = reader.document(0);\n    assertEquals(text, doc2.get(\"f\"));\n    Fields fields = MultiFields.getFields(reader);\n    Terms terms = fields.terms(\"f\");\n    assertNotNull(terms);\n    TermsEnum te = terms.iterator(null);\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"quick\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"brown\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"fox\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"jumped\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"over\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"lazy\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"dog\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"the\")));\n    DocsEnum de = te.docs(null, null, true);\n    assertTrue(de.advance(0) != DocsEnum.NO_MORE_DOCS);\n    assertEquals(2, de.freq());\n    assertTrue(de.advance(1) != DocsEnum.NO_MORE_DOCS);\n    assertTrue(de.advance(2) == DocsEnum.NO_MORE_DOCS);\n    reader.close();\n  }\n\n","sourceOld":"  public void testCodec() throws Exception {\n    Directory dir = new AppendingRAMDirectory(random, new RAMDirectory());\n    IndexWriterConfig cfg = new IndexWriterConfig(Version.LUCENE_40, new MockAnalyzer(random));\n    \n    cfg.setCodec(new AppendingCodec());\n    ((TieredMergePolicy)cfg.getMergePolicy()).setUseCompoundFile(false);\n    IndexWriter writer = new IndexWriter(dir, cfg);\n    Document doc = new Document();\n    FieldType storedTextType = new FieldType(TextField.TYPE_STORED);\n    storedTextType.setStoreTermVectors(true);\n    storedTextType.setStoreTermVectorPositions(true);\n    storedTextType.setStoreTermVectorOffsets(true);\n    doc.add(newField(\"f\", text, storedTextType));\n    writer.addDocument(doc);\n    writer.commit();\n    writer.addDocument(doc);\n    writer.forceMerge(1);\n    writer.close();\n    IndexReader reader = IndexReader.open(dir, 1);\n    assertEquals(2, reader.numDocs());\n    Document doc2 = reader.document(0);\n    assertEquals(text, doc2.get(\"f\"));\n    Fields fields = MultiFields.getFields(reader);\n    Terms terms = fields.terms(\"f\");\n    assertNotNull(terms);\n    TermsEnum te = terms.iterator(null);\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"quick\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"brown\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"fox\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"jumped\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"over\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"lazy\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"dog\")));\n    assertEquals(SeekStatus.FOUND, te.seekCeil(new BytesRef(\"the\")));\n    DocsEnum de = te.docs(null, null, true);\n    assertTrue(de.advance(0) != DocsEnum.NO_MORE_DOCS);\n    assertEquals(2, de.freq());\n    assertTrue(de.advance(1) != DocsEnum.NO_MORE_DOCS);\n    assertTrue(de.advance(2) == DocsEnum.NO_MORE_DOCS);\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"929d416aad35e36f2d2743c625e05e23908e7563":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","9eda19c7aeddd50f2d8bc261c8567cdeb7f094d7"],"ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00":["9eda19c7aeddd50f2d8bc261c8567cdeb7f094d7","3615ce4a1f785ae1b779244de52c6a7d99227e60"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"3615ce4a1f785ae1b779244de52c6a7d99227e60":["9eda19c7aeddd50f2d8bc261c8567cdeb7f094d7","929d416aad35e36f2d2743c625e05e23908e7563"],"a0ae5e3ed1232483b7b8a014f175a5fe43595982":["3615ce4a1f785ae1b779244de52c6a7d99227e60"],"9eda19c7aeddd50f2d8bc261c8567cdeb7f094d7":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["a0ae5e3ed1232483b7b8a014f175a5fe43595982"]},"commit2Childs":{"929d416aad35e36f2d2743c625e05e23908e7563":["3615ce4a1f785ae1b779244de52c6a7d99227e60"],"ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["929d416aad35e36f2d2743c625e05e23908e7563","9eda19c7aeddd50f2d8bc261c8567cdeb7f094d7"],"3615ce4a1f785ae1b779244de52c6a7d99227e60":["ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00","a0ae5e3ed1232483b7b8a014f175a5fe43595982"],"a0ae5e3ed1232483b7b8a014f175a5fe43595982":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"9eda19c7aeddd50f2d8bc261c8567cdeb7f094d7":["929d416aad35e36f2d2743c625e05e23908e7563","ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00","3615ce4a1f785ae1b779244de52c6a7d99227e60"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["ba5bc70a1fc1e0abc1eb4171af0d6f2532711c00","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}