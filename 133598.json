{"path":"solr/core/src/java/org/apache/solr/core/SolrCore#SolrCore(String,String,SolrConfig,IndexSchema,CoreDescriptor,UpdateHandler,SolrCore).mjava","commits":[{"id":"c9767265f21f7d1246b13dd7e73e8a4ad88b4384","date":1342986300,"type":1,"author":"Yonik Seeley","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/SolrCore#SolrCore(String,String,SolrConfig,IndexSchema,CoreDescriptor,UpdateHandler,SolrCore).mjava","pathOld":"solr/core/src/java/org/apache/solr/core/SolrCore#SolrCore(String,String,SolrConfig,IndexSchema,CoreDescriptor,UpdateHandler).mjava","sourceNew":"  /**\n   * Creates a new core and register it in the list of cores.\n   * If a core with the same name already exists, it will be stopped and replaced by this one.\n   *@param dataDir the index directory\n   *@param config a solr config instance\n   *@param schema a solr schema instance\n   *@param updateHandler\n   *\n   *@since solr 1.3\n   */\n  public SolrCore(String name, String dataDir, SolrConfig config, IndexSchema schema, CoreDescriptor cd, UpdateHandler updateHandler, SolrCore prev) {\n    coreDescriptor = cd;\n    this.setName( name );\n    resourceLoader = config.getResourceLoader();\n    if (dataDir == null){\n      if(cd.usingDefaultDataDir()) dataDir = config.getDataDir();\n      if(dataDir == null) dataDir = cd.getDataDir();\n    }\n\n    dataDir = SolrResourceLoader.normalizeDir(dataDir);\n\n    log.info(logid+\"Opening new SolrCore at \" + resourceLoader.getInstanceDir() + \", dataDir=\"+dataDir);\n\n    if (schema==null) {\n      schema = new IndexSchema(config, IndexSchema.DEFAULT_SCHEMA_FILE, null);\n    }\n\n    //Initialize JMX\n    if (config.jmxConfig.enabled) {\n      infoRegistry = new JmxMonitoredMap<String, SolrInfoMBean>(name, String.valueOf(this.hashCode()), config.jmxConfig);\n    } else  {\n      log.info(\"JMX monitoring not detected for core: \" + name);\n      infoRegistry = new ConcurrentHashMap<String, SolrInfoMBean>();\n    }\n\n    infoRegistry.put(\"fieldCache\", new SolrFieldCacheMBean());\n\n    this.schema = schema;\n    this.dataDir = dataDir;\n    this.solrConfig = config;\n    this.startTime = System.currentTimeMillis();\n    this.maxWarmingSearchers = config.maxWarmingSearchers;\n\n    booleanQueryMaxClauseCount();\n  \n    initListeners();\n\n    initDeletionPolicy();\n\n    this.codec= initCodec(solrConfig, schema);\n    \n    if (updateHandler == null) {\n      initDirectoryFactory();\n    } else {\n      directoryFactory = updateHandler.getSolrCoreState().getDirectoryFactory();\n      this.isReloaded = true;\n    }\n    \n    initIndex();\n\n    initWriters();\n    initQParsers();\n    initValueSourceParsers();\n    initTransformerFactories();\n\n    this.searchComponents = Collections.unmodifiableMap(loadSearchComponents());\n\n    // Processors initialized before the handlers\n    updateProcessorChains = loadUpdateProcessorChains();\n    reqHandlers = new RequestHandlers(this);\n    reqHandlers.initHandlersFromConfig( solrConfig );\n\n\n    // Handle things that should eventually go away\n    initDeprecatedSupport();\n\n    final CountDownLatch latch = new CountDownLatch(1);\n\n    try {\n      // cause the executor to stall so firstSearcher events won't fire\n      // until after inform() has been called for all components.\n      // searchExecutor must be single-threaded for this to work\n      searcherExecutor.submit(new Callable() {\n        public Object call() throws Exception {\n          latch.await();\n          return null;\n        }\n      });\n\n      // use the (old) writer to open the first searcher\n      RefCounted<IndexWriter> iwRef = null;\n      if (prev != null) {\n        iwRef = prev.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n        if (iwRef != null) {\n          final IndexWriter iw = iwRef.get();\n          newReaderCreator = new Callable<DirectoryReader>() {\n            @Override\n            public DirectoryReader call() throws Exception {\n              return DirectoryReader.open(iw, true);\n            }\n          };\n        }\n      }\n\n      // Open the searcher *before* the update handler so we don't end up opening\n      // one in the middle.\n      // With lockless commits in Lucene now, this probably shouldn't be an issue anymore\n\n      try {\n        getSearcher(false,false,null,true);\n      } finally {\n        newReaderCreator = null;\n        if (iwRef != null) iwRef.decref();\n      }\n\n      String updateHandlerClass = solrConfig.getUpdateHandlerInfo().className;\n\n      if (updateHandler == null) {\n        this.updateHandler = createUpdateHandler(updateHandlerClass == null ? DirectUpdateHandler2.class\n            .getName() : updateHandlerClass);\n      } else {\n        this.updateHandler = createUpdateHandler(\n            updateHandlerClass == null ? DirectUpdateHandler2.class.getName()\n                : updateHandlerClass, updateHandler);\n      }\n      infoRegistry.put(\"updateHandler\", this.updateHandler);\n\n      // Finally tell anyone who wants to know\n      resourceLoader.inform( resourceLoader );\n      resourceLoader.inform( this );  // last call before the latch is released.\n    } catch (Throwable e) {\n      latch.countDown();//release the latch, otherwise we block trying to do the close.  This should be fine, since counting down on a latch of 0 is still fine\n      //close down the searcher and any other resources, if it exists, as this is not recoverable\n      close();\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \n                              e.getMessage(), e);\n    } finally {\n      // allow firstSearcher events to fire and make sure it is released\n      latch.countDown();\n    }\n\n    infoRegistry.put(\"core\", this);\n    \n    // register any SolrInfoMBeans SolrResourceLoader initialized\n    //\n    // this must happen after the latch is released, because a JMX server impl may\n    // choose to block on registering until properties can be fetched from an MBean,\n    // and a SolrCoreAware MBean may have properties that depend on getting a Searcher\n    // from the core.\n    resourceLoader.inform(infoRegistry);\n    \n    // For debugging   \n//    numOpens.incrementAndGet();\n//    openHandles.put(this, new RuntimeException(\"unclosed core - name:\" + getName() + \" refs: \" + refCount.get()));\n  }\n\n","sourceOld":"  /**\n   * Creates a new core and register it in the list of cores.\n   * If a core with the same name already exists, it will be stopped and replaced by this one.\n   *@param dataDir the index directory\n   *@param config a solr config instance\n   *@param schema a solr schema instance\n   *@param updateHandler\n   *\n   *@since solr 1.3\n   */\n  public SolrCore(String name, String dataDir, SolrConfig config, IndexSchema schema, CoreDescriptor cd, UpdateHandler updateHandler) {\n    coreDescriptor = cd;\n    this.setName( name );\n    resourceLoader = config.getResourceLoader();\n    if (dataDir == null){\n      if(cd.usingDefaultDataDir()) dataDir = config.getDataDir();\n      if(dataDir == null) dataDir = cd.getDataDir();\n    }\n\n    dataDir = SolrResourceLoader.normalizeDir(dataDir);\n\n    log.info(logid+\"Opening new SolrCore at \" + resourceLoader.getInstanceDir() + \", dataDir=\"+dataDir);\n\n    if (schema==null) {\n      schema = new IndexSchema(config, IndexSchema.DEFAULT_SCHEMA_FILE, null);\n    }\n\n    //Initialize JMX\n    if (config.jmxConfig.enabled) {\n      infoRegistry = new JmxMonitoredMap<String, SolrInfoMBean>(name, String.valueOf(this.hashCode()), config.jmxConfig);\n    } else  {\n      log.info(\"JMX monitoring not detected for core: \" + name);\n      infoRegistry = new ConcurrentHashMap<String, SolrInfoMBean>();\n    }\n\n    infoRegistry.put(\"fieldCache\", new SolrFieldCacheMBean());\n\n    this.schema = schema;\n    this.dataDir = dataDir;\n    this.solrConfig = config;\n    this.startTime = System.currentTimeMillis();\n    this.maxWarmingSearchers = config.maxWarmingSearchers;\n\n    booleanQueryMaxClauseCount();\n  \n    initListeners();\n\n    initDeletionPolicy();\n\n    this.codec= initCodec(solrConfig, schema);\n    \n    if (updateHandler == null) {\n      initDirectoryFactory();\n    } else {\n      directoryFactory = updateHandler.getSolrCoreState().getDirectoryFactory();\n      this.isReloaded = true;\n    }\n    \n    initIndex();\n\n    initWriters();\n    initQParsers();\n    initValueSourceParsers();\n    initTransformerFactories();\n\n    this.searchComponents = Collections.unmodifiableMap(loadSearchComponents());\n\n    // Processors initialized before the handlers\n    updateProcessorChains = loadUpdateProcessorChains();\n    reqHandlers = new RequestHandlers(this);\n    reqHandlers.initHandlersFromConfig( solrConfig );\n\n\n    // Handle things that should eventually go away\n    initDeprecatedSupport();\n\n    final CountDownLatch latch = new CountDownLatch(1);\n\n    try {\n      // cause the executor to stall so firstSearcher events won't fire\n      // until after inform() has been called for all components.\n      // searchExecutor must be single-threaded for this to work\n      searcherExecutor.submit(new Callable() {\n        public Object call() throws Exception {\n          latch.await();\n          return null;\n        }\n      });\n\n      // Open the searcher *before* the update handler so we don't end up opening\n      // one in the middle.\n      // With lockless commits in Lucene now, this probably shouldn't be an issue anymore\n      getSearcher(false,false,null);\n\n      String updateHandlerClass = solrConfig.getUpdateHandlerInfo().className;\n\n      if (updateHandler == null) {\n        this.updateHandler = createUpdateHandler(updateHandlerClass == null ? DirectUpdateHandler2.class\n            .getName() : updateHandlerClass);\n      } else {\n        this.updateHandler = createUpdateHandler(\n            updateHandlerClass == null ? DirectUpdateHandler2.class.getName()\n                : updateHandlerClass, updateHandler);\n      }\n      infoRegistry.put(\"updateHandler\", this.updateHandler);\n\n      // Finally tell anyone who wants to know\n      resourceLoader.inform( resourceLoader );\n      resourceLoader.inform( this );  // last call before the latch is released.\n    } catch (Throwable e) {\n      latch.countDown();//release the latch, otherwise we block trying to do the close.  This should be fine, since counting down on a latch of 0 is still fine\n      //close down the searcher and any other resources, if it exists, as this is not recoverable\n      close();\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \n                              e.getMessage(), e);\n    } finally {\n      // allow firstSearcher events to fire and make sure it is released\n      latch.countDown();\n    }\n\n    infoRegistry.put(\"core\", this);\n    \n    // register any SolrInfoMBeans SolrResourceLoader initialized\n    //\n    // this must happen after the latch is released, because a JMX server impl may\n    // choose to block on registering until properties can be fetched from an MBean,\n    // and a SolrCoreAware MBean may have properties that depend on getting a Searcher\n    // from the core.\n    resourceLoader.inform(infoRegistry);\n    \n    // For debugging   \n//    numOpens.incrementAndGet();\n//    openHandles.put(this, new RuntimeException(\"unclosed core - name:\" + getName() + \" refs: \" + refCount.get()));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4b51f65902cc2d20ddeb7a5b949aaddf990f31a7","date":1343059585,"type":1,"author":"Robert Muir","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/core/SolrCore#SolrCore(String,String,SolrConfig,IndexSchema,CoreDescriptor,UpdateHandler,SolrCore).mjava","pathOld":"solr/core/src/java/org/apache/solr/core/SolrCore#SolrCore(String,String,SolrConfig,IndexSchema,CoreDescriptor,UpdateHandler).mjava","sourceNew":"  /**\n   * Creates a new core and register it in the list of cores.\n   * If a core with the same name already exists, it will be stopped and replaced by this one.\n   *@param dataDir the index directory\n   *@param config a solr config instance\n   *@param schema a solr schema instance\n   *@param updateHandler\n   *\n   *@since solr 1.3\n   */\n  public SolrCore(String name, String dataDir, SolrConfig config, IndexSchema schema, CoreDescriptor cd, UpdateHandler updateHandler, SolrCore prev) {\n    coreDescriptor = cd;\n    this.setName( name );\n    resourceLoader = config.getResourceLoader();\n    if (dataDir == null){\n      if(cd.usingDefaultDataDir()) dataDir = config.getDataDir();\n      if(dataDir == null) dataDir = cd.getDataDir();\n    }\n\n    dataDir = SolrResourceLoader.normalizeDir(dataDir);\n\n    log.info(logid+\"Opening new SolrCore at \" + resourceLoader.getInstanceDir() + \", dataDir=\"+dataDir);\n\n    if (schema==null) {\n      schema = new IndexSchema(config, IndexSchema.DEFAULT_SCHEMA_FILE, null);\n    }\n\n    //Initialize JMX\n    if (config.jmxConfig.enabled) {\n      infoRegistry = new JmxMonitoredMap<String, SolrInfoMBean>(name, String.valueOf(this.hashCode()), config.jmxConfig);\n    } else  {\n      log.info(\"JMX monitoring not detected for core: \" + name);\n      infoRegistry = new ConcurrentHashMap<String, SolrInfoMBean>();\n    }\n\n    infoRegistry.put(\"fieldCache\", new SolrFieldCacheMBean());\n\n    this.schema = schema;\n    this.dataDir = dataDir;\n    this.solrConfig = config;\n    this.startTime = System.currentTimeMillis();\n    this.maxWarmingSearchers = config.maxWarmingSearchers;\n\n    booleanQueryMaxClauseCount();\n  \n    initListeners();\n\n    initDeletionPolicy();\n\n    this.codec= initCodec(solrConfig, schema);\n    \n    if (updateHandler == null) {\n      initDirectoryFactory();\n    } else {\n      directoryFactory = updateHandler.getSolrCoreState().getDirectoryFactory();\n      this.isReloaded = true;\n    }\n    \n    initIndex();\n\n    initWriters();\n    initQParsers();\n    initValueSourceParsers();\n    initTransformerFactories();\n\n    this.searchComponents = Collections.unmodifiableMap(loadSearchComponents());\n\n    // Processors initialized before the handlers\n    updateProcessorChains = loadUpdateProcessorChains();\n    reqHandlers = new RequestHandlers(this);\n    reqHandlers.initHandlersFromConfig( solrConfig );\n\n\n    // Handle things that should eventually go away\n    initDeprecatedSupport();\n\n    final CountDownLatch latch = new CountDownLatch(1);\n\n    try {\n      // cause the executor to stall so firstSearcher events won't fire\n      // until after inform() has been called for all components.\n      // searchExecutor must be single-threaded for this to work\n      searcherExecutor.submit(new Callable() {\n        public Object call() throws Exception {\n          latch.await();\n          return null;\n        }\n      });\n\n      // use the (old) writer to open the first searcher\n      RefCounted<IndexWriter> iwRef = null;\n      if (prev != null) {\n        iwRef = prev.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n        if (iwRef != null) {\n          final IndexWriter iw = iwRef.get();\n          newReaderCreator = new Callable<DirectoryReader>() {\n            @Override\n            public DirectoryReader call() throws Exception {\n              return DirectoryReader.open(iw, true);\n            }\n          };\n        }\n      }\n\n      // Open the searcher *before* the update handler so we don't end up opening\n      // one in the middle.\n      // With lockless commits in Lucene now, this probably shouldn't be an issue anymore\n\n      try {\n        getSearcher(false,false,null,true);\n      } finally {\n        newReaderCreator = null;\n        if (iwRef != null) iwRef.decref();\n      }\n\n      String updateHandlerClass = solrConfig.getUpdateHandlerInfo().className;\n\n      if (updateHandler == null) {\n        this.updateHandler = createUpdateHandler(updateHandlerClass == null ? DirectUpdateHandler2.class\n            .getName() : updateHandlerClass);\n      } else {\n        this.updateHandler = createUpdateHandler(\n            updateHandlerClass == null ? DirectUpdateHandler2.class.getName()\n                : updateHandlerClass, updateHandler);\n      }\n      infoRegistry.put(\"updateHandler\", this.updateHandler);\n\n      // Finally tell anyone who wants to know\n      resourceLoader.inform( resourceLoader );\n      resourceLoader.inform( this );  // last call before the latch is released.\n    } catch (Throwable e) {\n      latch.countDown();//release the latch, otherwise we block trying to do the close.  This should be fine, since counting down on a latch of 0 is still fine\n      //close down the searcher and any other resources, if it exists, as this is not recoverable\n      close();\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \n                              e.getMessage(), e);\n    } finally {\n      // allow firstSearcher events to fire and make sure it is released\n      latch.countDown();\n    }\n\n    infoRegistry.put(\"core\", this);\n    \n    // register any SolrInfoMBeans SolrResourceLoader initialized\n    //\n    // this must happen after the latch is released, because a JMX server impl may\n    // choose to block on registering until properties can be fetched from an MBean,\n    // and a SolrCoreAware MBean may have properties that depend on getting a Searcher\n    // from the core.\n    resourceLoader.inform(infoRegistry);\n    \n    // For debugging   \n//    numOpens.incrementAndGet();\n//    openHandles.put(this, new RuntimeException(\"unclosed core - name:\" + getName() + \" refs: \" + refCount.get()));\n  }\n\n","sourceOld":"  /**\n   * Creates a new core and register it in the list of cores.\n   * If a core with the same name already exists, it will be stopped and replaced by this one.\n   *@param dataDir the index directory\n   *@param config a solr config instance\n   *@param schema a solr schema instance\n   *@param updateHandler\n   *\n   *@since solr 1.3\n   */\n  public SolrCore(String name, String dataDir, SolrConfig config, IndexSchema schema, CoreDescriptor cd, UpdateHandler updateHandler) {\n    coreDescriptor = cd;\n    this.setName( name );\n    resourceLoader = config.getResourceLoader();\n    if (dataDir == null){\n      if(cd.usingDefaultDataDir()) dataDir = config.getDataDir();\n      if(dataDir == null) dataDir = cd.getDataDir();\n    }\n\n    dataDir = SolrResourceLoader.normalizeDir(dataDir);\n\n    log.info(logid+\"Opening new SolrCore at \" + resourceLoader.getInstanceDir() + \", dataDir=\"+dataDir);\n\n    if (schema==null) {\n      schema = new IndexSchema(config, IndexSchema.DEFAULT_SCHEMA_FILE, null);\n    }\n\n    //Initialize JMX\n    if (config.jmxConfig.enabled) {\n      infoRegistry = new JmxMonitoredMap<String, SolrInfoMBean>(name, String.valueOf(this.hashCode()), config.jmxConfig);\n    } else  {\n      log.info(\"JMX monitoring not detected for core: \" + name);\n      infoRegistry = new ConcurrentHashMap<String, SolrInfoMBean>();\n    }\n\n    infoRegistry.put(\"fieldCache\", new SolrFieldCacheMBean());\n\n    this.schema = schema;\n    this.dataDir = dataDir;\n    this.solrConfig = config;\n    this.startTime = System.currentTimeMillis();\n    this.maxWarmingSearchers = config.maxWarmingSearchers;\n\n    booleanQueryMaxClauseCount();\n  \n    initListeners();\n\n    initDeletionPolicy();\n\n    this.codec= initCodec(solrConfig, schema);\n    \n    if (updateHandler == null) {\n      initDirectoryFactory();\n    } else {\n      directoryFactory = updateHandler.getSolrCoreState().getDirectoryFactory();\n      this.isReloaded = true;\n    }\n    \n    initIndex();\n\n    initWriters();\n    initQParsers();\n    initValueSourceParsers();\n    initTransformerFactories();\n\n    this.searchComponents = Collections.unmodifiableMap(loadSearchComponents());\n\n    // Processors initialized before the handlers\n    updateProcessorChains = loadUpdateProcessorChains();\n    reqHandlers = new RequestHandlers(this);\n    reqHandlers.initHandlersFromConfig( solrConfig );\n\n\n    // Handle things that should eventually go away\n    initDeprecatedSupport();\n\n    final CountDownLatch latch = new CountDownLatch(1);\n\n    try {\n      // cause the executor to stall so firstSearcher events won't fire\n      // until after inform() has been called for all components.\n      // searchExecutor must be single-threaded for this to work\n      searcherExecutor.submit(new Callable() {\n        public Object call() throws Exception {\n          latch.await();\n          return null;\n        }\n      });\n\n      // Open the searcher *before* the update handler so we don't end up opening\n      // one in the middle.\n      // With lockless commits in Lucene now, this probably shouldn't be an issue anymore\n      getSearcher(false,false,null);\n\n      String updateHandlerClass = solrConfig.getUpdateHandlerInfo().className;\n\n      if (updateHandler == null) {\n        this.updateHandler = createUpdateHandler(updateHandlerClass == null ? DirectUpdateHandler2.class\n            .getName() : updateHandlerClass);\n      } else {\n        this.updateHandler = createUpdateHandler(\n            updateHandlerClass == null ? DirectUpdateHandler2.class.getName()\n                : updateHandlerClass, updateHandler);\n      }\n      infoRegistry.put(\"updateHandler\", this.updateHandler);\n\n      // Finally tell anyone who wants to know\n      resourceLoader.inform( resourceLoader );\n      resourceLoader.inform( this );  // last call before the latch is released.\n    } catch (Throwable e) {\n      latch.countDown();//release the latch, otherwise we block trying to do the close.  This should be fine, since counting down on a latch of 0 is still fine\n      //close down the searcher and any other resources, if it exists, as this is not recoverable\n      close();\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \n                              e.getMessage(), e);\n    } finally {\n      // allow firstSearcher events to fire and make sure it is released\n      latch.countDown();\n    }\n\n    infoRegistry.put(\"core\", this);\n    \n    // register any SolrInfoMBeans SolrResourceLoader initialized\n    //\n    // this must happen after the latch is released, because a JMX server impl may\n    // choose to block on registering until properties can be fetched from an MBean,\n    // and a SolrCoreAware MBean may have properties that depend on getting a Searcher\n    // from the core.\n    resourceLoader.inform(infoRegistry);\n    \n    // For debugging   \n//    numOpens.incrementAndGet();\n//    openHandles.put(this, new RuntimeException(\"unclosed core - name:\" + getName() + \" refs: \" + refCount.get()));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"aba371508186796cc6151d8223a5b4e16d02e26e","date":1343474871,"type":0,"author":"Uwe Schindler","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/core/SolrCore#SolrCore(String,String,SolrConfig,IndexSchema,CoreDescriptor,UpdateHandler,SolrCore).mjava","pathOld":"/dev/null","sourceNew":"  /**\n   * Creates a new core and register it in the list of cores.\n   * If a core with the same name already exists, it will be stopped and replaced by this one.\n   *@param dataDir the index directory\n   *@param config a solr config instance\n   *@param schema a solr schema instance\n   *@param updateHandler\n   *\n   *@since solr 1.3\n   */\n  public SolrCore(String name, String dataDir, SolrConfig config, IndexSchema schema, CoreDescriptor cd, UpdateHandler updateHandler, SolrCore prev) {\n    coreDescriptor = cd;\n    this.setName( name );\n    resourceLoader = config.getResourceLoader();\n    if (dataDir == null){\n      if(cd.usingDefaultDataDir()) dataDir = config.getDataDir();\n      if(dataDir == null) dataDir = cd.getDataDir();\n    }\n\n    dataDir = SolrResourceLoader.normalizeDir(dataDir);\n\n    log.info(logid+\"Opening new SolrCore at \" + resourceLoader.getInstanceDir() + \", dataDir=\"+dataDir);\n\n    if (schema==null) {\n      schema = new IndexSchema(config, IndexSchema.DEFAULT_SCHEMA_FILE, null);\n    }\n\n    //Initialize JMX\n    if (config.jmxConfig.enabled) {\n      infoRegistry = new JmxMonitoredMap<String, SolrInfoMBean>(name, String.valueOf(this.hashCode()), config.jmxConfig);\n    } else  {\n      log.info(\"JMX monitoring not detected for core: \" + name);\n      infoRegistry = new ConcurrentHashMap<String, SolrInfoMBean>();\n    }\n\n    infoRegistry.put(\"fieldCache\", new SolrFieldCacheMBean());\n\n    this.schema = schema;\n    this.dataDir = dataDir;\n    this.solrConfig = config;\n    this.startTime = System.currentTimeMillis();\n    this.maxWarmingSearchers = config.maxWarmingSearchers;\n\n    booleanQueryMaxClauseCount();\n  \n    initListeners();\n\n    initDeletionPolicy();\n\n    this.codec= initCodec(solrConfig, schema);\n    \n    if (updateHandler == null) {\n      initDirectoryFactory();\n    } else {\n      directoryFactory = updateHandler.getSolrCoreState().getDirectoryFactory();\n      this.isReloaded = true;\n    }\n    \n    initIndex();\n\n    initWriters();\n    initQParsers();\n    initValueSourceParsers();\n    initTransformerFactories();\n\n    this.searchComponents = Collections.unmodifiableMap(loadSearchComponents());\n\n    // Processors initialized before the handlers\n    updateProcessorChains = loadUpdateProcessorChains();\n    reqHandlers = new RequestHandlers(this);\n    reqHandlers.initHandlersFromConfig( solrConfig );\n\n\n    // Handle things that should eventually go away\n    initDeprecatedSupport();\n\n    final CountDownLatch latch = new CountDownLatch(1);\n\n    try {\n      // cause the executor to stall so firstSearcher events won't fire\n      // until after inform() has been called for all components.\n      // searchExecutor must be single-threaded for this to work\n      searcherExecutor.submit(new Callable() {\n        public Object call() throws Exception {\n          latch.await();\n          return null;\n        }\n      });\n\n      // use the (old) writer to open the first searcher\n      RefCounted<IndexWriter> iwRef = null;\n      if (prev != null) {\n        iwRef = prev.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n        if (iwRef != null) {\n          final IndexWriter iw = iwRef.get();\n          newReaderCreator = new Callable<DirectoryReader>() {\n            @Override\n            public DirectoryReader call() throws Exception {\n              return DirectoryReader.open(iw, true);\n            }\n          };\n        }\n      }\n\n      // Open the searcher *before* the update handler so we don't end up opening\n      // one in the middle.\n      // With lockless commits in Lucene now, this probably shouldn't be an issue anymore\n\n      try {\n        getSearcher(false,false,null,true);\n      } finally {\n        newReaderCreator = null;\n        if (iwRef != null) iwRef.decref();\n      }\n\n      String updateHandlerClass = solrConfig.getUpdateHandlerInfo().className;\n\n      if (updateHandler == null) {\n        this.updateHandler = createUpdateHandler(updateHandlerClass == null ? DirectUpdateHandler2.class\n            .getName() : updateHandlerClass);\n      } else {\n        this.updateHandler = createUpdateHandler(\n            updateHandlerClass == null ? DirectUpdateHandler2.class.getName()\n                : updateHandlerClass, updateHandler);\n      }\n      infoRegistry.put(\"updateHandler\", this.updateHandler);\n\n      // Finally tell anyone who wants to know\n      resourceLoader.inform( resourceLoader );\n      resourceLoader.inform( this );  // last call before the latch is released.\n    } catch (Throwable e) {\n      latch.countDown();//release the latch, otherwise we block trying to do the close.  This should be fine, since counting down on a latch of 0 is still fine\n      //close down the searcher and any other resources, if it exists, as this is not recoverable\n      close();\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \n                              e.getMessage(), e);\n    } finally {\n      // allow firstSearcher events to fire and make sure it is released\n      latch.countDown();\n    }\n\n    infoRegistry.put(\"core\", this);\n    \n    // register any SolrInfoMBeans SolrResourceLoader initialized\n    //\n    // this must happen after the latch is released, because a JMX server impl may\n    // choose to block on registering until properties can be fetched from an MBean,\n    // and a SolrCoreAware MBean may have properties that depend on getting a Searcher\n    // from the core.\n    resourceLoader.inform(infoRegistry);\n    \n    // For debugging   \n//    numOpens.incrementAndGet();\n//    openHandles.put(this, new RuntimeException(\"unclosed core - name:\" + getName() + \" refs: \" + refCount.get()));\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9c76c513f7206331c91df98399d28c338ea1b95a","date":1346108471,"type":3,"author":"Chris M. Hostetter","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/SolrCore#SolrCore(String,String,SolrConfig,IndexSchema,CoreDescriptor,UpdateHandler,SolrCore).mjava","pathOld":"solr/core/src/java/org/apache/solr/core/SolrCore#SolrCore(String,String,SolrConfig,IndexSchema,CoreDescriptor,UpdateHandler,SolrCore).mjava","sourceNew":"  /**\n   * Creates a new core and register it in the list of cores.\n   * If a core with the same name already exists, it will be stopped and replaced by this one.\n   *@param dataDir the index directory\n   *@param config a solr config instance\n   *@param schema a solr schema instance\n   *@param updateHandler\n   *\n   *@since solr 1.3\n   */\n  public SolrCore(String name, String dataDir, SolrConfig config, IndexSchema schema, CoreDescriptor cd, UpdateHandler updateHandler, SolrCore prev) {\n    coreDescriptor = cd;\n    this.setName( name );\n    resourceLoader = config.getResourceLoader();\n    if (dataDir == null){\n      if(cd.usingDefaultDataDir()) dataDir = config.getDataDir();\n      if(dataDir == null) dataDir = cd.getDataDir();\n    }\n\n    dataDir = SolrResourceLoader.normalizeDir(dataDir);\n\n    log.info(logid+\"Opening new SolrCore at \" + resourceLoader.getInstanceDir() + \", dataDir=\"+dataDir);\n\n    if (schema==null) {\n      schema = new IndexSchema(config, IndexSchema.DEFAULT_SCHEMA_FILE, null);\n    }\n\n    if (null != cd && null != cd.getCloudDescriptor()) {\n      // we are evidently running in cloud mode.  \n      //\n      // In cloud mode, version field is required for correct consistency\n      // ideally this check would be more fine grained, and individual features\n      // would assert it when they initialize, but DistribuedUpdateProcessor\n      // is currently a big ball of wax that does more then just distributing\n      // updates (ie: partial document updates), so it needs to work in no cloud\n      // mode as well, and can't assert version field support on init.\n\n      try {\n        Object ignored = VersionInfo.getAndCheckVersionField(schema);\n      } catch (SolrException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                                \"Schema will not work with SolrCloud mode: \" +\n                                e.getMessage(), e);\n      }\n    }\n\n    //Initialize JMX\n    if (config.jmxConfig.enabled) {\n      infoRegistry = new JmxMonitoredMap<String, SolrInfoMBean>(name, String.valueOf(this.hashCode()), config.jmxConfig);\n    } else  {\n      log.info(\"JMX monitoring not detected for core: \" + name);\n      infoRegistry = new ConcurrentHashMap<String, SolrInfoMBean>();\n    }\n\n    infoRegistry.put(\"fieldCache\", new SolrFieldCacheMBean());\n\n    this.schema = schema;\n    this.dataDir = dataDir;\n    this.solrConfig = config;\n    this.startTime = System.currentTimeMillis();\n    this.maxWarmingSearchers = config.maxWarmingSearchers;\n\n    booleanQueryMaxClauseCount();\n  \n    initListeners();\n\n    initDeletionPolicy();\n\n    this.codec= initCodec(solrConfig, schema);\n    \n    if (updateHandler == null) {\n      initDirectoryFactory();\n    } else {\n      directoryFactory = updateHandler.getSolrCoreState().getDirectoryFactory();\n      this.isReloaded = true;\n    }\n    \n    initIndex();\n\n    initWriters();\n    initQParsers();\n    initValueSourceParsers();\n    initTransformerFactories();\n\n    this.searchComponents = Collections.unmodifiableMap(loadSearchComponents());\n\n    // Processors initialized before the handlers\n    updateProcessorChains = loadUpdateProcessorChains();\n    reqHandlers = new RequestHandlers(this);\n    reqHandlers.initHandlersFromConfig( solrConfig );\n\n\n    // Handle things that should eventually go away\n    initDeprecatedSupport();\n\n    final CountDownLatch latch = new CountDownLatch(1);\n\n    try {\n      // cause the executor to stall so firstSearcher events won't fire\n      // until after inform() has been called for all components.\n      // searchExecutor must be single-threaded for this to work\n      searcherExecutor.submit(new Callable() {\n        public Object call() throws Exception {\n          latch.await();\n          return null;\n        }\n      });\n\n      // use the (old) writer to open the first searcher\n      RefCounted<IndexWriter> iwRef = null;\n      if (prev != null) {\n        iwRef = prev.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n        if (iwRef != null) {\n          final IndexWriter iw = iwRef.get();\n          newReaderCreator = new Callable<DirectoryReader>() {\n            @Override\n            public DirectoryReader call() throws Exception {\n              return DirectoryReader.open(iw, true);\n            }\n          };\n        }\n      }\n\n      // Open the searcher *before* the update handler so we don't end up opening\n      // one in the middle.\n      // With lockless commits in Lucene now, this probably shouldn't be an issue anymore\n\n      try {\n        getSearcher(false,false,null,true);\n      } finally {\n        newReaderCreator = null;\n        if (iwRef != null) iwRef.decref();\n      }\n\n      String updateHandlerClass = solrConfig.getUpdateHandlerInfo().className;\n\n      if (updateHandler == null) {\n        this.updateHandler = createUpdateHandler(updateHandlerClass == null ? DirectUpdateHandler2.class\n            .getName() : updateHandlerClass);\n      } else {\n        this.updateHandler = createUpdateHandler(\n            updateHandlerClass == null ? DirectUpdateHandler2.class.getName()\n                : updateHandlerClass, updateHandler);\n      }\n      infoRegistry.put(\"updateHandler\", this.updateHandler);\n\n      // Finally tell anyone who wants to know\n      resourceLoader.inform( resourceLoader );\n      resourceLoader.inform( this );  // last call before the latch is released.\n    } catch (Throwable e) {\n      latch.countDown();//release the latch, otherwise we block trying to do the close.  This should be fine, since counting down on a latch of 0 is still fine\n      //close down the searcher and any other resources, if it exists, as this is not recoverable\n      close();\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \n                              e.getMessage(), e);\n    } finally {\n      // allow firstSearcher events to fire and make sure it is released\n      latch.countDown();\n    }\n\n    infoRegistry.put(\"core\", this);\n    \n    // register any SolrInfoMBeans SolrResourceLoader initialized\n    //\n    // this must happen after the latch is released, because a JMX server impl may\n    // choose to block on registering until properties can be fetched from an MBean,\n    // and a SolrCoreAware MBean may have properties that depend on getting a Searcher\n    // from the core.\n    resourceLoader.inform(infoRegistry);\n    \n    // For debugging   \n//    numOpens.incrementAndGet();\n//    openHandles.put(this, new RuntimeException(\"unclosed core - name:\" + getName() + \" refs: \" + refCount.get()));\n  }\n\n","sourceOld":"  /**\n   * Creates a new core and register it in the list of cores.\n   * If a core with the same name already exists, it will be stopped and replaced by this one.\n   *@param dataDir the index directory\n   *@param config a solr config instance\n   *@param schema a solr schema instance\n   *@param updateHandler\n   *\n   *@since solr 1.3\n   */\n  public SolrCore(String name, String dataDir, SolrConfig config, IndexSchema schema, CoreDescriptor cd, UpdateHandler updateHandler, SolrCore prev) {\n    coreDescriptor = cd;\n    this.setName( name );\n    resourceLoader = config.getResourceLoader();\n    if (dataDir == null){\n      if(cd.usingDefaultDataDir()) dataDir = config.getDataDir();\n      if(dataDir == null) dataDir = cd.getDataDir();\n    }\n\n    dataDir = SolrResourceLoader.normalizeDir(dataDir);\n\n    log.info(logid+\"Opening new SolrCore at \" + resourceLoader.getInstanceDir() + \", dataDir=\"+dataDir);\n\n    if (schema==null) {\n      schema = new IndexSchema(config, IndexSchema.DEFAULT_SCHEMA_FILE, null);\n    }\n\n    //Initialize JMX\n    if (config.jmxConfig.enabled) {\n      infoRegistry = new JmxMonitoredMap<String, SolrInfoMBean>(name, String.valueOf(this.hashCode()), config.jmxConfig);\n    } else  {\n      log.info(\"JMX monitoring not detected for core: \" + name);\n      infoRegistry = new ConcurrentHashMap<String, SolrInfoMBean>();\n    }\n\n    infoRegistry.put(\"fieldCache\", new SolrFieldCacheMBean());\n\n    this.schema = schema;\n    this.dataDir = dataDir;\n    this.solrConfig = config;\n    this.startTime = System.currentTimeMillis();\n    this.maxWarmingSearchers = config.maxWarmingSearchers;\n\n    booleanQueryMaxClauseCount();\n  \n    initListeners();\n\n    initDeletionPolicy();\n\n    this.codec= initCodec(solrConfig, schema);\n    \n    if (updateHandler == null) {\n      initDirectoryFactory();\n    } else {\n      directoryFactory = updateHandler.getSolrCoreState().getDirectoryFactory();\n      this.isReloaded = true;\n    }\n    \n    initIndex();\n\n    initWriters();\n    initQParsers();\n    initValueSourceParsers();\n    initTransformerFactories();\n\n    this.searchComponents = Collections.unmodifiableMap(loadSearchComponents());\n\n    // Processors initialized before the handlers\n    updateProcessorChains = loadUpdateProcessorChains();\n    reqHandlers = new RequestHandlers(this);\n    reqHandlers.initHandlersFromConfig( solrConfig );\n\n\n    // Handle things that should eventually go away\n    initDeprecatedSupport();\n\n    final CountDownLatch latch = new CountDownLatch(1);\n\n    try {\n      // cause the executor to stall so firstSearcher events won't fire\n      // until after inform() has been called for all components.\n      // searchExecutor must be single-threaded for this to work\n      searcherExecutor.submit(new Callable() {\n        public Object call() throws Exception {\n          latch.await();\n          return null;\n        }\n      });\n\n      // use the (old) writer to open the first searcher\n      RefCounted<IndexWriter> iwRef = null;\n      if (prev != null) {\n        iwRef = prev.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n        if (iwRef != null) {\n          final IndexWriter iw = iwRef.get();\n          newReaderCreator = new Callable<DirectoryReader>() {\n            @Override\n            public DirectoryReader call() throws Exception {\n              return DirectoryReader.open(iw, true);\n            }\n          };\n        }\n      }\n\n      // Open the searcher *before* the update handler so we don't end up opening\n      // one in the middle.\n      // With lockless commits in Lucene now, this probably shouldn't be an issue anymore\n\n      try {\n        getSearcher(false,false,null,true);\n      } finally {\n        newReaderCreator = null;\n        if (iwRef != null) iwRef.decref();\n      }\n\n      String updateHandlerClass = solrConfig.getUpdateHandlerInfo().className;\n\n      if (updateHandler == null) {\n        this.updateHandler = createUpdateHandler(updateHandlerClass == null ? DirectUpdateHandler2.class\n            .getName() : updateHandlerClass);\n      } else {\n        this.updateHandler = createUpdateHandler(\n            updateHandlerClass == null ? DirectUpdateHandler2.class.getName()\n                : updateHandlerClass, updateHandler);\n      }\n      infoRegistry.put(\"updateHandler\", this.updateHandler);\n\n      // Finally tell anyone who wants to know\n      resourceLoader.inform( resourceLoader );\n      resourceLoader.inform( this );  // last call before the latch is released.\n    } catch (Throwable e) {\n      latch.countDown();//release the latch, otherwise we block trying to do the close.  This should be fine, since counting down on a latch of 0 is still fine\n      //close down the searcher and any other resources, if it exists, as this is not recoverable\n      close();\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \n                              e.getMessage(), e);\n    } finally {\n      // allow firstSearcher events to fire and make sure it is released\n      latch.countDown();\n    }\n\n    infoRegistry.put(\"core\", this);\n    \n    // register any SolrInfoMBeans SolrResourceLoader initialized\n    //\n    // this must happen after the latch is released, because a JMX server impl may\n    // choose to block on registering until properties can be fetched from an MBean,\n    // and a SolrCoreAware MBean may have properties that depend on getting a Searcher\n    // from the core.\n    resourceLoader.inform(infoRegistry);\n    \n    // For debugging   \n//    numOpens.incrementAndGet();\n//    openHandles.put(this, new RuntimeException(\"unclosed core - name:\" + getName() + \" refs: \" + refCount.get()));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"05a14b2611ead08655a2b2bdc61632eb31316e57","date":1346366621,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/core/SolrCore#SolrCore(String,String,SolrConfig,IndexSchema,CoreDescriptor,UpdateHandler,SolrCore).mjava","pathOld":"solr/core/src/java/org/apache/solr/core/SolrCore#SolrCore(String,String,SolrConfig,IndexSchema,CoreDescriptor,UpdateHandler,SolrCore).mjava","sourceNew":"  /**\n   * Creates a new core and register it in the list of cores.\n   * If a core with the same name already exists, it will be stopped and replaced by this one.\n   *@param dataDir the index directory\n   *@param config a solr config instance\n   *@param schema a solr schema instance\n   *@param updateHandler\n   *\n   *@since solr 1.3\n   */\n  public SolrCore(String name, String dataDir, SolrConfig config, IndexSchema schema, CoreDescriptor cd, UpdateHandler updateHandler, SolrCore prev) {\n    coreDescriptor = cd;\n    this.setName( name );\n    resourceLoader = config.getResourceLoader();\n    if (dataDir == null){\n      if(cd.usingDefaultDataDir()) dataDir = config.getDataDir();\n      if(dataDir == null) dataDir = cd.getDataDir();\n    }\n\n    dataDir = SolrResourceLoader.normalizeDir(dataDir);\n\n    log.info(logid+\"Opening new SolrCore at \" + resourceLoader.getInstanceDir() + \", dataDir=\"+dataDir);\n\n    if (schema==null) {\n      schema = new IndexSchema(config, IndexSchema.DEFAULT_SCHEMA_FILE, null);\n    }\n\n    if (null != cd && null != cd.getCloudDescriptor()) {\n      // we are evidently running in cloud mode.  \n      //\n      // In cloud mode, version field is required for correct consistency\n      // ideally this check would be more fine grained, and individual features\n      // would assert it when they initialize, but DistribuedUpdateProcessor\n      // is currently a big ball of wax that does more then just distributing\n      // updates (ie: partial document updates), so it needs to work in no cloud\n      // mode as well, and can't assert version field support on init.\n\n      try {\n        Object ignored = VersionInfo.getAndCheckVersionField(schema);\n      } catch (SolrException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                                \"Schema will not work with SolrCloud mode: \" +\n                                e.getMessage(), e);\n      }\n    }\n\n    //Initialize JMX\n    if (config.jmxConfig.enabled) {\n      infoRegistry = new JmxMonitoredMap<String, SolrInfoMBean>(name, String.valueOf(this.hashCode()), config.jmxConfig);\n    } else  {\n      log.info(\"JMX monitoring not detected for core: \" + name);\n      infoRegistry = new ConcurrentHashMap<String, SolrInfoMBean>();\n    }\n\n    infoRegistry.put(\"fieldCache\", new SolrFieldCacheMBean());\n\n    this.schema = schema;\n    this.dataDir = dataDir;\n    this.solrConfig = config;\n    this.startTime = System.currentTimeMillis();\n    this.maxWarmingSearchers = config.maxWarmingSearchers;\n\n    booleanQueryMaxClauseCount();\n  \n    initListeners();\n\n    initDeletionPolicy();\n\n    this.codec= initCodec(solrConfig, schema);\n    \n    if (updateHandler == null) {\n      initDirectoryFactory();\n    } else {\n      directoryFactory = updateHandler.getSolrCoreState().getDirectoryFactory();\n      this.isReloaded = true;\n    }\n    \n    initIndex();\n\n    initWriters();\n    initQParsers();\n    initValueSourceParsers();\n    initTransformerFactories();\n\n    this.searchComponents = Collections.unmodifiableMap(loadSearchComponents());\n\n    // Processors initialized before the handlers\n    updateProcessorChains = loadUpdateProcessorChains();\n    reqHandlers = new RequestHandlers(this);\n    reqHandlers.initHandlersFromConfig( solrConfig );\n\n\n    // Handle things that should eventually go away\n    initDeprecatedSupport();\n\n    final CountDownLatch latch = new CountDownLatch(1);\n\n    try {\n      // cause the executor to stall so firstSearcher events won't fire\n      // until after inform() has been called for all components.\n      // searchExecutor must be single-threaded for this to work\n      searcherExecutor.submit(new Callable() {\n        public Object call() throws Exception {\n          latch.await();\n          return null;\n        }\n      });\n\n      // use the (old) writer to open the first searcher\n      RefCounted<IndexWriter> iwRef = null;\n      if (prev != null) {\n        iwRef = prev.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n        if (iwRef != null) {\n          final IndexWriter iw = iwRef.get();\n          newReaderCreator = new Callable<DirectoryReader>() {\n            @Override\n            public DirectoryReader call() throws Exception {\n              return DirectoryReader.open(iw, true);\n            }\n          };\n        }\n      }\n\n      // Open the searcher *before* the update handler so we don't end up opening\n      // one in the middle.\n      // With lockless commits in Lucene now, this probably shouldn't be an issue anymore\n\n      try {\n        getSearcher(false,false,null,true);\n      } finally {\n        newReaderCreator = null;\n        if (iwRef != null) iwRef.decref();\n      }\n\n      String updateHandlerClass = solrConfig.getUpdateHandlerInfo().className;\n\n      if (updateHandler == null) {\n        this.updateHandler = createUpdateHandler(updateHandlerClass == null ? DirectUpdateHandler2.class\n            .getName() : updateHandlerClass);\n      } else {\n        this.updateHandler = createUpdateHandler(\n            updateHandlerClass == null ? DirectUpdateHandler2.class.getName()\n                : updateHandlerClass, updateHandler);\n      }\n      infoRegistry.put(\"updateHandler\", this.updateHandler);\n\n      // Finally tell anyone who wants to know\n      resourceLoader.inform( resourceLoader );\n      resourceLoader.inform( this );  // last call before the latch is released.\n    } catch (Throwable e) {\n      latch.countDown();//release the latch, otherwise we block trying to do the close.  This should be fine, since counting down on a latch of 0 is still fine\n      //close down the searcher and any other resources, if it exists, as this is not recoverable\n      close();\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \n                              e.getMessage(), e);\n    } finally {\n      // allow firstSearcher events to fire and make sure it is released\n      latch.countDown();\n    }\n\n    infoRegistry.put(\"core\", this);\n    \n    // register any SolrInfoMBeans SolrResourceLoader initialized\n    //\n    // this must happen after the latch is released, because a JMX server impl may\n    // choose to block on registering until properties can be fetched from an MBean,\n    // and a SolrCoreAware MBean may have properties that depend on getting a Searcher\n    // from the core.\n    resourceLoader.inform(infoRegistry);\n    \n    // For debugging   \n//    numOpens.incrementAndGet();\n//    openHandles.put(this, new RuntimeException(\"unclosed core - name:\" + getName() + \" refs: \" + refCount.get()));\n  }\n\n","sourceOld":"  /**\n   * Creates a new core and register it in the list of cores.\n   * If a core with the same name already exists, it will be stopped and replaced by this one.\n   *@param dataDir the index directory\n   *@param config a solr config instance\n   *@param schema a solr schema instance\n   *@param updateHandler\n   *\n   *@since solr 1.3\n   */\n  public SolrCore(String name, String dataDir, SolrConfig config, IndexSchema schema, CoreDescriptor cd, UpdateHandler updateHandler, SolrCore prev) {\n    coreDescriptor = cd;\n    this.setName( name );\n    resourceLoader = config.getResourceLoader();\n    if (dataDir == null){\n      if(cd.usingDefaultDataDir()) dataDir = config.getDataDir();\n      if(dataDir == null) dataDir = cd.getDataDir();\n    }\n\n    dataDir = SolrResourceLoader.normalizeDir(dataDir);\n\n    log.info(logid+\"Opening new SolrCore at \" + resourceLoader.getInstanceDir() + \", dataDir=\"+dataDir);\n\n    if (schema==null) {\n      schema = new IndexSchema(config, IndexSchema.DEFAULT_SCHEMA_FILE, null);\n    }\n\n    //Initialize JMX\n    if (config.jmxConfig.enabled) {\n      infoRegistry = new JmxMonitoredMap<String, SolrInfoMBean>(name, String.valueOf(this.hashCode()), config.jmxConfig);\n    } else  {\n      log.info(\"JMX monitoring not detected for core: \" + name);\n      infoRegistry = new ConcurrentHashMap<String, SolrInfoMBean>();\n    }\n\n    infoRegistry.put(\"fieldCache\", new SolrFieldCacheMBean());\n\n    this.schema = schema;\n    this.dataDir = dataDir;\n    this.solrConfig = config;\n    this.startTime = System.currentTimeMillis();\n    this.maxWarmingSearchers = config.maxWarmingSearchers;\n\n    booleanQueryMaxClauseCount();\n  \n    initListeners();\n\n    initDeletionPolicy();\n\n    this.codec= initCodec(solrConfig, schema);\n    \n    if (updateHandler == null) {\n      initDirectoryFactory();\n    } else {\n      directoryFactory = updateHandler.getSolrCoreState().getDirectoryFactory();\n      this.isReloaded = true;\n    }\n    \n    initIndex();\n\n    initWriters();\n    initQParsers();\n    initValueSourceParsers();\n    initTransformerFactories();\n\n    this.searchComponents = Collections.unmodifiableMap(loadSearchComponents());\n\n    // Processors initialized before the handlers\n    updateProcessorChains = loadUpdateProcessorChains();\n    reqHandlers = new RequestHandlers(this);\n    reqHandlers.initHandlersFromConfig( solrConfig );\n\n\n    // Handle things that should eventually go away\n    initDeprecatedSupport();\n\n    final CountDownLatch latch = new CountDownLatch(1);\n\n    try {\n      // cause the executor to stall so firstSearcher events won't fire\n      // until after inform() has been called for all components.\n      // searchExecutor must be single-threaded for this to work\n      searcherExecutor.submit(new Callable() {\n        public Object call() throws Exception {\n          latch.await();\n          return null;\n        }\n      });\n\n      // use the (old) writer to open the first searcher\n      RefCounted<IndexWriter> iwRef = null;\n      if (prev != null) {\n        iwRef = prev.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n        if (iwRef != null) {\n          final IndexWriter iw = iwRef.get();\n          newReaderCreator = new Callable<DirectoryReader>() {\n            @Override\n            public DirectoryReader call() throws Exception {\n              return DirectoryReader.open(iw, true);\n            }\n          };\n        }\n      }\n\n      // Open the searcher *before* the update handler so we don't end up opening\n      // one in the middle.\n      // With lockless commits in Lucene now, this probably shouldn't be an issue anymore\n\n      try {\n        getSearcher(false,false,null,true);\n      } finally {\n        newReaderCreator = null;\n        if (iwRef != null) iwRef.decref();\n      }\n\n      String updateHandlerClass = solrConfig.getUpdateHandlerInfo().className;\n\n      if (updateHandler == null) {\n        this.updateHandler = createUpdateHandler(updateHandlerClass == null ? DirectUpdateHandler2.class\n            .getName() : updateHandlerClass);\n      } else {\n        this.updateHandler = createUpdateHandler(\n            updateHandlerClass == null ? DirectUpdateHandler2.class.getName()\n                : updateHandlerClass, updateHandler);\n      }\n      infoRegistry.put(\"updateHandler\", this.updateHandler);\n\n      // Finally tell anyone who wants to know\n      resourceLoader.inform( resourceLoader );\n      resourceLoader.inform( this );  // last call before the latch is released.\n    } catch (Throwable e) {\n      latch.countDown();//release the latch, otherwise we block trying to do the close.  This should be fine, since counting down on a latch of 0 is still fine\n      //close down the searcher and any other resources, if it exists, as this is not recoverable\n      close();\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \n                              e.getMessage(), e);\n    } finally {\n      // allow firstSearcher events to fire and make sure it is released\n      latch.countDown();\n    }\n\n    infoRegistry.put(\"core\", this);\n    \n    // register any SolrInfoMBeans SolrResourceLoader initialized\n    //\n    // this must happen after the latch is released, because a JMX server impl may\n    // choose to block on registering until properties can be fetched from an MBean,\n    // and a SolrCoreAware MBean may have properties that depend on getting a Searcher\n    // from the core.\n    resourceLoader.inform(infoRegistry);\n    \n    // For debugging   \n//    numOpens.incrementAndGet();\n//    openHandles.put(this, new RuntimeException(\"unclosed core - name:\" + getName() + \" refs: \" + refCount.get()));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"df4ed22dc7b048a2e9efa6ee55cb84b9457e9ee5","date":1347730635,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/SolrCore#SolrCore(String,String,SolrConfig,IndexSchema,CoreDescriptor,UpdateHandler,SolrCore).mjava","pathOld":"solr/core/src/java/org/apache/solr/core/SolrCore#SolrCore(String,String,SolrConfig,IndexSchema,CoreDescriptor,UpdateHandler,SolrCore).mjava","sourceNew":"  /**\n   * Creates a new core and register it in the list of cores.\n   * If a core with the same name already exists, it will be stopped and replaced by this one.\n   *@param dataDir the index directory\n   *@param config a solr config instance\n   *@param schema a solr schema instance\n   *@param updateHandler\n   *\n   *@since solr 1.3\n   */\n  public SolrCore(String name, String dataDir, SolrConfig config, IndexSchema schema, CoreDescriptor cd, UpdateHandler updateHandler, SolrCore prev) {\n    coreDescriptor = cd;\n    this.setName( name );\n    resourceLoader = config.getResourceLoader();\n    if (dataDir == null){\n      if(cd.usingDefaultDataDir()) dataDir = config.getDataDir();\n      if(dataDir == null) dataDir = cd.getDataDir();\n    }\n\n    dataDir = SolrResourceLoader.normalizeDir(dataDir);\n\n    log.info(logid+\"Opening new SolrCore at \" + resourceLoader.getInstanceDir() + \", dataDir=\"+dataDir);\n\n    if (schema==null) {\n      schema = new IndexSchema(config, IndexSchema.DEFAULT_SCHEMA_FILE, null);\n    }\n\n    if (null != cd && null != cd.getCloudDescriptor()) {\n      // we are evidently running in cloud mode.  \n      //\n      // In cloud mode, version field is required for correct consistency\n      // ideally this check would be more fine grained, and individual features\n      // would assert it when they initialize, but DistribuedUpdateProcessor\n      // is currently a big ball of wax that does more then just distributing\n      // updates (ie: partial document updates), so it needs to work in no cloud\n      // mode as well, and can't assert version field support on init.\n\n      try {\n        Object ignored = VersionInfo.getAndCheckVersionField(schema);\n      } catch (SolrException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                                \"Schema will not work with SolrCloud mode: \" +\n                                e.getMessage(), e);\n      }\n    }\n\n    //Initialize JMX\n    if (config.jmxConfig.enabled) {\n      infoRegistry = new JmxMonitoredMap<String, SolrInfoMBean>(name, String.valueOf(this.hashCode()), config.jmxConfig);\n    } else  {\n      log.info(\"JMX monitoring not detected for core: \" + name);\n      infoRegistry = new ConcurrentHashMap<String, SolrInfoMBean>();\n    }\n\n    infoRegistry.put(\"fieldCache\", new SolrFieldCacheMBean());\n\n    this.schema = schema;\n    this.dataDir = dataDir;\n    this.solrConfig = config;\n    this.startTime = System.currentTimeMillis();\n    this.maxWarmingSearchers = config.maxWarmingSearchers;\n\n    booleanQueryMaxClauseCount();\n  \n    initListeners();\n\n    initDeletionPolicy();\n\n    this.codec= initCodec(solrConfig, schema);\n    \n    if (updateHandler == null) {\n      initDirectoryFactory();\n    } else {\n      directoryFactory = updateHandler.getSolrCoreState().getDirectoryFactory();\n      this.isReloaded = true;\n    }\n    \n    initIndex(prev != null);\n\n    initWriters();\n    initQParsers();\n    initValueSourceParsers();\n    initTransformerFactories();\n\n    this.searchComponents = Collections.unmodifiableMap(loadSearchComponents());\n\n    // Processors initialized before the handlers\n    updateProcessorChains = loadUpdateProcessorChains();\n    reqHandlers = new RequestHandlers(this);\n    reqHandlers.initHandlersFromConfig( solrConfig );\n\n\n    // Handle things that should eventually go away\n    initDeprecatedSupport();\n\n    final CountDownLatch latch = new CountDownLatch(1);\n\n    try {\n      // cause the executor to stall so firstSearcher events won't fire\n      // until after inform() has been called for all components.\n      // searchExecutor must be single-threaded for this to work\n      searcherExecutor.submit(new Callable() {\n        public Object call() throws Exception {\n          latch.await();\n          return null;\n        }\n      });\n\n      // use the (old) writer to open the first searcher\n      RefCounted<IndexWriter> iwRef = null;\n      if (prev != null) {\n        iwRef = prev.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n        if (iwRef != null) {\n          final IndexWriter iw = iwRef.get();\n          newReaderCreator = new Callable<DirectoryReader>() {\n            @Override\n            public DirectoryReader call() throws Exception {\n              return DirectoryReader.open(iw, true);\n            }\n          };\n        }\n      }\n\n      // Open the searcher *before* the update handler so we don't end up opening\n      // one in the middle.\n      // With lockless commits in Lucene now, this probably shouldn't be an issue anymore\n\n      try {\n        getSearcher(false,false,null,true);\n      } finally {\n        newReaderCreator = null;\n        if (iwRef != null) iwRef.decref();\n      }\n\n      String updateHandlerClass = solrConfig.getUpdateHandlerInfo().className;\n\n      if (updateHandler == null) {\n        this.updateHandler = createUpdateHandler(updateHandlerClass == null ? DirectUpdateHandler2.class\n            .getName() : updateHandlerClass);\n      } else {\n        this.updateHandler = createUpdateHandler(\n            updateHandlerClass == null ? DirectUpdateHandler2.class.getName()\n                : updateHandlerClass, updateHandler);\n      }\n      infoRegistry.put(\"updateHandler\", this.updateHandler);\n\n      // Finally tell anyone who wants to know\n      resourceLoader.inform( resourceLoader );\n      resourceLoader.inform( this );  // last call before the latch is released.\n    } catch (Throwable e) {\n      latch.countDown();//release the latch, otherwise we block trying to do the close.  This should be fine, since counting down on a latch of 0 is still fine\n      //close down the searcher and any other resources, if it exists, as this is not recoverable\n      close();\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \n                              e.getMessage(), e);\n    } finally {\n      // allow firstSearcher events to fire and make sure it is released\n      latch.countDown();\n    }\n\n    infoRegistry.put(\"core\", this);\n    \n    // register any SolrInfoMBeans SolrResourceLoader initialized\n    //\n    // this must happen after the latch is released, because a JMX server impl may\n    // choose to block on registering until properties can be fetched from an MBean,\n    // and a SolrCoreAware MBean may have properties that depend on getting a Searcher\n    // from the core.\n    resourceLoader.inform(infoRegistry);\n    \n    // For debugging   \n//    numOpens.incrementAndGet();\n//    openHandles.put(this, new RuntimeException(\"unclosed core - name:\" + getName() + \" refs: \" + refCount.get()));\n  }\n\n","sourceOld":"  /**\n   * Creates a new core and register it in the list of cores.\n   * If a core with the same name already exists, it will be stopped and replaced by this one.\n   *@param dataDir the index directory\n   *@param config a solr config instance\n   *@param schema a solr schema instance\n   *@param updateHandler\n   *\n   *@since solr 1.3\n   */\n  public SolrCore(String name, String dataDir, SolrConfig config, IndexSchema schema, CoreDescriptor cd, UpdateHandler updateHandler, SolrCore prev) {\n    coreDescriptor = cd;\n    this.setName( name );\n    resourceLoader = config.getResourceLoader();\n    if (dataDir == null){\n      if(cd.usingDefaultDataDir()) dataDir = config.getDataDir();\n      if(dataDir == null) dataDir = cd.getDataDir();\n    }\n\n    dataDir = SolrResourceLoader.normalizeDir(dataDir);\n\n    log.info(logid+\"Opening new SolrCore at \" + resourceLoader.getInstanceDir() + \", dataDir=\"+dataDir);\n\n    if (schema==null) {\n      schema = new IndexSchema(config, IndexSchema.DEFAULT_SCHEMA_FILE, null);\n    }\n\n    if (null != cd && null != cd.getCloudDescriptor()) {\n      // we are evidently running in cloud mode.  \n      //\n      // In cloud mode, version field is required for correct consistency\n      // ideally this check would be more fine grained, and individual features\n      // would assert it when they initialize, but DistribuedUpdateProcessor\n      // is currently a big ball of wax that does more then just distributing\n      // updates (ie: partial document updates), so it needs to work in no cloud\n      // mode as well, and can't assert version field support on init.\n\n      try {\n        Object ignored = VersionInfo.getAndCheckVersionField(schema);\n      } catch (SolrException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                                \"Schema will not work with SolrCloud mode: \" +\n                                e.getMessage(), e);\n      }\n    }\n\n    //Initialize JMX\n    if (config.jmxConfig.enabled) {\n      infoRegistry = new JmxMonitoredMap<String, SolrInfoMBean>(name, String.valueOf(this.hashCode()), config.jmxConfig);\n    } else  {\n      log.info(\"JMX monitoring not detected for core: \" + name);\n      infoRegistry = new ConcurrentHashMap<String, SolrInfoMBean>();\n    }\n\n    infoRegistry.put(\"fieldCache\", new SolrFieldCacheMBean());\n\n    this.schema = schema;\n    this.dataDir = dataDir;\n    this.solrConfig = config;\n    this.startTime = System.currentTimeMillis();\n    this.maxWarmingSearchers = config.maxWarmingSearchers;\n\n    booleanQueryMaxClauseCount();\n  \n    initListeners();\n\n    initDeletionPolicy();\n\n    this.codec= initCodec(solrConfig, schema);\n    \n    if (updateHandler == null) {\n      initDirectoryFactory();\n    } else {\n      directoryFactory = updateHandler.getSolrCoreState().getDirectoryFactory();\n      this.isReloaded = true;\n    }\n    \n    initIndex();\n\n    initWriters();\n    initQParsers();\n    initValueSourceParsers();\n    initTransformerFactories();\n\n    this.searchComponents = Collections.unmodifiableMap(loadSearchComponents());\n\n    // Processors initialized before the handlers\n    updateProcessorChains = loadUpdateProcessorChains();\n    reqHandlers = new RequestHandlers(this);\n    reqHandlers.initHandlersFromConfig( solrConfig );\n\n\n    // Handle things that should eventually go away\n    initDeprecatedSupport();\n\n    final CountDownLatch latch = new CountDownLatch(1);\n\n    try {\n      // cause the executor to stall so firstSearcher events won't fire\n      // until after inform() has been called for all components.\n      // searchExecutor must be single-threaded for this to work\n      searcherExecutor.submit(new Callable() {\n        public Object call() throws Exception {\n          latch.await();\n          return null;\n        }\n      });\n\n      // use the (old) writer to open the first searcher\n      RefCounted<IndexWriter> iwRef = null;\n      if (prev != null) {\n        iwRef = prev.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n        if (iwRef != null) {\n          final IndexWriter iw = iwRef.get();\n          newReaderCreator = new Callable<DirectoryReader>() {\n            @Override\n            public DirectoryReader call() throws Exception {\n              return DirectoryReader.open(iw, true);\n            }\n          };\n        }\n      }\n\n      // Open the searcher *before* the update handler so we don't end up opening\n      // one in the middle.\n      // With lockless commits in Lucene now, this probably shouldn't be an issue anymore\n\n      try {\n        getSearcher(false,false,null,true);\n      } finally {\n        newReaderCreator = null;\n        if (iwRef != null) iwRef.decref();\n      }\n\n      String updateHandlerClass = solrConfig.getUpdateHandlerInfo().className;\n\n      if (updateHandler == null) {\n        this.updateHandler = createUpdateHandler(updateHandlerClass == null ? DirectUpdateHandler2.class\n            .getName() : updateHandlerClass);\n      } else {\n        this.updateHandler = createUpdateHandler(\n            updateHandlerClass == null ? DirectUpdateHandler2.class.getName()\n                : updateHandlerClass, updateHandler);\n      }\n      infoRegistry.put(\"updateHandler\", this.updateHandler);\n\n      // Finally tell anyone who wants to know\n      resourceLoader.inform( resourceLoader );\n      resourceLoader.inform( this );  // last call before the latch is released.\n    } catch (Throwable e) {\n      latch.countDown();//release the latch, otherwise we block trying to do the close.  This should be fine, since counting down on a latch of 0 is still fine\n      //close down the searcher and any other resources, if it exists, as this is not recoverable\n      close();\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \n                              e.getMessage(), e);\n    } finally {\n      // allow firstSearcher events to fire and make sure it is released\n      latch.countDown();\n    }\n\n    infoRegistry.put(\"core\", this);\n    \n    // register any SolrInfoMBeans SolrResourceLoader initialized\n    //\n    // this must happen after the latch is released, because a JMX server impl may\n    // choose to block on registering until properties can be fetched from an MBean,\n    // and a SolrCoreAware MBean may have properties that depend on getting a Searcher\n    // from the core.\n    resourceLoader.inform(infoRegistry);\n    \n    // For debugging   \n//    numOpens.incrementAndGet();\n//    openHandles.put(this, new RuntimeException(\"unclosed core - name:\" + getName() + \" refs: \" + refCount.get()));\n  }\n\n","bugFix":["7a71a0b2d4be2299a163f60626729852d81a8e02"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"c7bd1fdddb8e84c1857d1a55c32ced51f0ed2069","date":1348430063,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/SolrCore#SolrCore(String,String,SolrConfig,IndexSchema,CoreDescriptor,UpdateHandler,SolrCore).mjava","pathOld":"solr/core/src/java/org/apache/solr/core/SolrCore#SolrCore(String,String,SolrConfig,IndexSchema,CoreDescriptor,UpdateHandler,SolrCore).mjava","sourceNew":"  /**\n   * Creates a new core and register it in the list of cores.\n   * If a core with the same name already exists, it will be stopped and replaced by this one.\n   *@param dataDir the index directory\n   *@param config a solr config instance\n   *@param schema a solr schema instance\n   *\n   *@since solr 1.3\n   */\n  public SolrCore(String name, String dataDir, SolrConfig config, IndexSchema schema, CoreDescriptor cd, UpdateHandler updateHandler, SolrCore prev) {\n    coreDescriptor = cd;\n    this.setName( name );\n    resourceLoader = config.getResourceLoader();\n    if (dataDir == null){\n      if(cd.usingDefaultDataDir()) dataDir = config.getDataDir();\n      if(dataDir == null) dataDir = cd.getDataDir();\n    }\n\n    dataDir = SolrResourceLoader.normalizeDir(dataDir);\n\n    log.info(logid+\"Opening new SolrCore at \" + resourceLoader.getInstanceDir() + \", dataDir=\"+dataDir);\n\n    if (schema==null) {\n      schema = new IndexSchema(config, IndexSchema.DEFAULT_SCHEMA_FILE, null);\n    }\n\n    if (null != cd && null != cd.getCloudDescriptor()) {\n      // we are evidently running in cloud mode.  \n      //\n      // In cloud mode, version field is required for correct consistency\n      // ideally this check would be more fine grained, and individual features\n      // would assert it when they initialize, but DistribuedUpdateProcessor\n      // is currently a big ball of wax that does more then just distributing\n      // updates (ie: partial document updates), so it needs to work in no cloud\n      // mode as well, and can't assert version field support on init.\n\n      try {\n        Object ignored = VersionInfo.getAndCheckVersionField(schema);\n      } catch (SolrException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                                \"Schema will not work with SolrCloud mode: \" +\n                                e.getMessage(), e);\n      }\n    }\n\n    //Initialize JMX\n    if (config.jmxConfig.enabled) {\n      infoRegistry = new JmxMonitoredMap<String, SolrInfoMBean>(name, String.valueOf(this.hashCode()), config.jmxConfig);\n    } else  {\n      log.info(\"JMX monitoring not detected for core: \" + name);\n      infoRegistry = new ConcurrentHashMap<String, SolrInfoMBean>();\n    }\n\n    infoRegistry.put(\"fieldCache\", new SolrFieldCacheMBean());\n\n    this.schema = schema;\n    this.dataDir = dataDir;\n    this.solrConfig = config;\n    this.startTime = System.currentTimeMillis();\n    this.maxWarmingSearchers = config.maxWarmingSearchers;\n\n    booleanQueryMaxClauseCount();\n  \n    initListeners();\n\n    initDeletionPolicy();\n\n    this.codec= initCodec(solrConfig, schema);\n    \n    if (updateHandler == null) {\n      initDirectoryFactory();\n    } else {\n      directoryFactory = updateHandler.getSolrCoreState().getDirectoryFactory();\n      this.isReloaded = true;\n    }\n    \n    initIndex(prev != null);\n\n    initWriters();\n    initQParsers();\n    initValueSourceParsers();\n    initTransformerFactories();\n\n    this.searchComponents = Collections.unmodifiableMap(loadSearchComponents());\n\n    // Processors initialized before the handlers\n    updateProcessorChains = loadUpdateProcessorChains();\n    reqHandlers = new RequestHandlers(this);\n    reqHandlers.initHandlersFromConfig( solrConfig );\n\n\n    // Handle things that should eventually go away\n    initDeprecatedSupport();\n\n    final CountDownLatch latch = new CountDownLatch(1);\n\n    try {\n      // cause the executor to stall so firstSearcher events won't fire\n      // until after inform() has been called for all components.\n      // searchExecutor must be single-threaded for this to work\n      searcherExecutor.submit(new Callable() {\n        public Object call() throws Exception {\n          latch.await();\n          return null;\n        }\n      });\n\n      // use the (old) writer to open the first searcher\n      RefCounted<IndexWriter> iwRef = null;\n      if (prev != null) {\n        iwRef = prev.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n        if (iwRef != null) {\n          final IndexWriter iw = iwRef.get();\n          newReaderCreator = new Callable<DirectoryReader>() {\n            @Override\n            public DirectoryReader call() throws Exception {\n              return DirectoryReader.open(iw, true);\n            }\n          };\n        }\n      }\n\n      // Open the searcher *before* the update handler so we don't end up opening\n      // one in the middle.\n      // With lockless commits in Lucene now, this probably shouldn't be an issue anymore\n\n      try {\n        getSearcher(false,false,null,true);\n      } finally {\n        newReaderCreator = null;\n        if (iwRef != null) iwRef.decref();\n      }\n\n      String updateHandlerClass = solrConfig.getUpdateHandlerInfo().className;\n\n      if (updateHandler == null) {\n        this.updateHandler = createUpdateHandler(updateHandlerClass == null ? DirectUpdateHandler2.class\n            .getName() : updateHandlerClass);\n      } else {\n        this.updateHandler = createUpdateHandler(\n            updateHandlerClass == null ? DirectUpdateHandler2.class.getName()\n                : updateHandlerClass, updateHandler);\n      }\n      infoRegistry.put(\"updateHandler\", this.updateHandler);\n\n      // Finally tell anyone who wants to know\n      resourceLoader.inform( resourceLoader );\n      resourceLoader.inform( this );  // last call before the latch is released.\n    } catch (Throwable e) {\n      latch.countDown();//release the latch, otherwise we block trying to do the close.  This should be fine, since counting down on a latch of 0 is still fine\n      //close down the searcher and any other resources, if it exists, as this is not recoverable\n      close();\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \n                              e.getMessage(), e);\n    } finally {\n      // allow firstSearcher events to fire and make sure it is released\n      latch.countDown();\n    }\n\n    infoRegistry.put(\"core\", this);\n    \n    // register any SolrInfoMBeans SolrResourceLoader initialized\n    //\n    // this must happen after the latch is released, because a JMX server impl may\n    // choose to block on registering until properties can be fetched from an MBean,\n    // and a SolrCoreAware MBean may have properties that depend on getting a Searcher\n    // from the core.\n    resourceLoader.inform(infoRegistry);\n    \n    // For debugging   \n//    numOpens.incrementAndGet();\n//    openHandles.put(this, new RuntimeException(\"unclosed core - name:\" + getName() + \" refs: \" + refCount.get()));\n  }\n\n","sourceOld":"  /**\n   * Creates a new core and register it in the list of cores.\n   * If a core with the same name already exists, it will be stopped and replaced by this one.\n   *@param dataDir the index directory\n   *@param config a solr config instance\n   *@param schema a solr schema instance\n   *@param updateHandler\n   *\n   *@since solr 1.3\n   */\n  public SolrCore(String name, String dataDir, SolrConfig config, IndexSchema schema, CoreDescriptor cd, UpdateHandler updateHandler, SolrCore prev) {\n    coreDescriptor = cd;\n    this.setName( name );\n    resourceLoader = config.getResourceLoader();\n    if (dataDir == null){\n      if(cd.usingDefaultDataDir()) dataDir = config.getDataDir();\n      if(dataDir == null) dataDir = cd.getDataDir();\n    }\n\n    dataDir = SolrResourceLoader.normalizeDir(dataDir);\n\n    log.info(logid+\"Opening new SolrCore at \" + resourceLoader.getInstanceDir() + \", dataDir=\"+dataDir);\n\n    if (schema==null) {\n      schema = new IndexSchema(config, IndexSchema.DEFAULT_SCHEMA_FILE, null);\n    }\n\n    if (null != cd && null != cd.getCloudDescriptor()) {\n      // we are evidently running in cloud mode.  \n      //\n      // In cloud mode, version field is required for correct consistency\n      // ideally this check would be more fine grained, and individual features\n      // would assert it when they initialize, but DistribuedUpdateProcessor\n      // is currently a big ball of wax that does more then just distributing\n      // updates (ie: partial document updates), so it needs to work in no cloud\n      // mode as well, and can't assert version field support on init.\n\n      try {\n        Object ignored = VersionInfo.getAndCheckVersionField(schema);\n      } catch (SolrException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                                \"Schema will not work with SolrCloud mode: \" +\n                                e.getMessage(), e);\n      }\n    }\n\n    //Initialize JMX\n    if (config.jmxConfig.enabled) {\n      infoRegistry = new JmxMonitoredMap<String, SolrInfoMBean>(name, String.valueOf(this.hashCode()), config.jmxConfig);\n    } else  {\n      log.info(\"JMX monitoring not detected for core: \" + name);\n      infoRegistry = new ConcurrentHashMap<String, SolrInfoMBean>();\n    }\n\n    infoRegistry.put(\"fieldCache\", new SolrFieldCacheMBean());\n\n    this.schema = schema;\n    this.dataDir = dataDir;\n    this.solrConfig = config;\n    this.startTime = System.currentTimeMillis();\n    this.maxWarmingSearchers = config.maxWarmingSearchers;\n\n    booleanQueryMaxClauseCount();\n  \n    initListeners();\n\n    initDeletionPolicy();\n\n    this.codec= initCodec(solrConfig, schema);\n    \n    if (updateHandler == null) {\n      initDirectoryFactory();\n    } else {\n      directoryFactory = updateHandler.getSolrCoreState().getDirectoryFactory();\n      this.isReloaded = true;\n    }\n    \n    initIndex(prev != null);\n\n    initWriters();\n    initQParsers();\n    initValueSourceParsers();\n    initTransformerFactories();\n\n    this.searchComponents = Collections.unmodifiableMap(loadSearchComponents());\n\n    // Processors initialized before the handlers\n    updateProcessorChains = loadUpdateProcessorChains();\n    reqHandlers = new RequestHandlers(this);\n    reqHandlers.initHandlersFromConfig( solrConfig );\n\n\n    // Handle things that should eventually go away\n    initDeprecatedSupport();\n\n    final CountDownLatch latch = new CountDownLatch(1);\n\n    try {\n      // cause the executor to stall so firstSearcher events won't fire\n      // until after inform() has been called for all components.\n      // searchExecutor must be single-threaded for this to work\n      searcherExecutor.submit(new Callable() {\n        public Object call() throws Exception {\n          latch.await();\n          return null;\n        }\n      });\n\n      // use the (old) writer to open the first searcher\n      RefCounted<IndexWriter> iwRef = null;\n      if (prev != null) {\n        iwRef = prev.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n        if (iwRef != null) {\n          final IndexWriter iw = iwRef.get();\n          newReaderCreator = new Callable<DirectoryReader>() {\n            @Override\n            public DirectoryReader call() throws Exception {\n              return DirectoryReader.open(iw, true);\n            }\n          };\n        }\n      }\n\n      // Open the searcher *before* the update handler so we don't end up opening\n      // one in the middle.\n      // With lockless commits in Lucene now, this probably shouldn't be an issue anymore\n\n      try {\n        getSearcher(false,false,null,true);\n      } finally {\n        newReaderCreator = null;\n        if (iwRef != null) iwRef.decref();\n      }\n\n      String updateHandlerClass = solrConfig.getUpdateHandlerInfo().className;\n\n      if (updateHandler == null) {\n        this.updateHandler = createUpdateHandler(updateHandlerClass == null ? DirectUpdateHandler2.class\n            .getName() : updateHandlerClass);\n      } else {\n        this.updateHandler = createUpdateHandler(\n            updateHandlerClass == null ? DirectUpdateHandler2.class.getName()\n                : updateHandlerClass, updateHandler);\n      }\n      infoRegistry.put(\"updateHandler\", this.updateHandler);\n\n      // Finally tell anyone who wants to know\n      resourceLoader.inform( resourceLoader );\n      resourceLoader.inform( this );  // last call before the latch is released.\n    } catch (Throwable e) {\n      latch.countDown();//release the latch, otherwise we block trying to do the close.  This should be fine, since counting down on a latch of 0 is still fine\n      //close down the searcher and any other resources, if it exists, as this is not recoverable\n      close();\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \n                              e.getMessage(), e);\n    } finally {\n      // allow firstSearcher events to fire and make sure it is released\n      latch.countDown();\n    }\n\n    infoRegistry.put(\"core\", this);\n    \n    // register any SolrInfoMBeans SolrResourceLoader initialized\n    //\n    // this must happen after the latch is released, because a JMX server impl may\n    // choose to block on registering until properties can be fetched from an MBean,\n    // and a SolrCoreAware MBean may have properties that depend on getting a Searcher\n    // from the core.\n    resourceLoader.inform(infoRegistry);\n    \n    // For debugging   \n//    numOpens.incrementAndGet();\n//    openHandles.put(this, new RuntimeException(\"unclosed core - name:\" + getName() + \" refs: \" + refCount.get()));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"3c8475e39c56b28600d2b496f3e78f7421190f62","date":1349102564,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/SolrCore#SolrCore(String,String,SolrConfig,IndexSchema,CoreDescriptor,UpdateHandler,SolrCore).mjava","pathOld":"solr/core/src/java/org/apache/solr/core/SolrCore#SolrCore(String,String,SolrConfig,IndexSchema,CoreDescriptor,UpdateHandler,SolrCore).mjava","sourceNew":"  /**\n   * Creates a new core and register it in the list of cores.\n   * If a core with the same name already exists, it will be stopped and replaced by this one.\n   *@param dataDir the index directory\n   *@param config a solr config instance\n   *@param schema a solr schema instance\n   *\n   *@since solr 1.3\n   */\n  public SolrCore(String name, String dataDir, SolrConfig config, IndexSchema schema, CoreDescriptor cd, UpdateHandler updateHandler, SolrCore prev) {\n    coreDescriptor = cd;\n    this.setName( name );\n    resourceLoader = config.getResourceLoader();\n    if (dataDir == null){\n      if(cd.usingDefaultDataDir()) dataDir = config.getDataDir();\n      if(dataDir == null) dataDir = cd.getDataDir();\n    }\n\n    dataDir = SolrResourceLoader.normalizeDir(dataDir);\n\n    log.info(logid+\"Opening new SolrCore at \" + resourceLoader.getInstanceDir() + \", dataDir=\"+dataDir);\n\n    if (schema==null) {\n      schema = new IndexSchema(config, IndexSchema.DEFAULT_SCHEMA_FILE, null);\n    }\n\n    if (null != cd && null != cd.getCloudDescriptor()) {\n      // we are evidently running in cloud mode.  \n      //\n      // In cloud mode, version field is required for correct consistency\n      // ideally this check would be more fine grained, and individual features\n      // would assert it when they initialize, but DistribuedUpdateProcessor\n      // is currently a big ball of wax that does more then just distributing\n      // updates (ie: partial document updates), so it needs to work in no cloud\n      // mode as well, and can't assert version field support on init.\n\n      try {\n        Object ignored = VersionInfo.getAndCheckVersionField(schema);\n      } catch (SolrException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                                \"Schema will not work with SolrCloud mode: \" +\n                                e.getMessage(), e);\n      }\n    }\n\n    //Initialize JMX\n    if (config.jmxConfig.enabled) {\n      infoRegistry = new JmxMonitoredMap<String, SolrInfoMBean>(name, String.valueOf(this.hashCode()), config.jmxConfig);\n    } else  {\n      log.info(\"JMX monitoring not detected for core: \" + name);\n      infoRegistry = new ConcurrentHashMap<String, SolrInfoMBean>();\n    }\n\n    infoRegistry.put(\"fieldCache\", new SolrFieldCacheMBean());\n\n    this.schema = schema;\n    this.dataDir = dataDir;\n    this.solrConfig = config;\n    this.startTime = System.currentTimeMillis();\n    this.maxWarmingSearchers = config.maxWarmingSearchers;\n\n    booleanQueryMaxClauseCount();\n  \n    initListeners();\n\n    initDeletionPolicy();\n\n    this.codec= initCodec(solrConfig, schema);\n    \n    if (updateHandler == null) {\n      initDirectoryFactory();\n      solrCoreState = new DefaultSolrCoreState(getDirectoryFactory());\n    } else {\n      solrCoreState = updateHandler.getSolrCoreState();\n      directoryFactory = solrCoreState.getDirectoryFactory();\n      this.isReloaded = true;\n    }\n    \n    initIndex(prev != null);\n\n    initWriters();\n    initQParsers();\n    initValueSourceParsers();\n    initTransformerFactories();\n\n    this.searchComponents = Collections.unmodifiableMap(loadSearchComponents());\n\n    // Processors initialized before the handlers\n    updateProcessorChains = loadUpdateProcessorChains();\n    reqHandlers = new RequestHandlers(this);\n    reqHandlers.initHandlersFromConfig( solrConfig );\n\n\n    // Handle things that should eventually go away\n    initDeprecatedSupport();\n\n    final CountDownLatch latch = new CountDownLatch(1);\n\n    try {\n      // cause the executor to stall so firstSearcher events won't fire\n      // until after inform() has been called for all components.\n      // searchExecutor must be single-threaded for this to work\n      searcherExecutor.submit(new Callable() {\n        public Object call() throws Exception {\n          latch.await();\n          return null;\n        }\n      });\n\n      // use the (old) writer to open the first searcher\n      RefCounted<IndexWriter> iwRef = null;\n      if (prev != null) {\n        iwRef = prev.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n        if (iwRef != null) {\n          final IndexWriter iw = iwRef.get();\n          newReaderCreator = new Callable<DirectoryReader>() {\n            @Override\n            public DirectoryReader call() throws Exception {\n              return DirectoryReader.open(iw, true);\n            }\n          };\n        }\n      }\n\n      // Open the searcher *before* the update handler so we don't end up opening\n      // one in the middle.\n      // With lockless commits in Lucene now, this probably shouldn't be an issue anymore\n\n      try {\n        getSearcher(false,false,null,true);\n      } finally {\n        newReaderCreator = null;\n        if (iwRef != null) iwRef.decref();\n      }\n\n      String updateHandlerClass = solrConfig.getUpdateHandlerInfo().className;\n\n      if (updateHandler == null) {\n        this.updateHandler = createUpdateHandler(updateHandlerClass == null ? DirectUpdateHandler2.class\n            .getName() : updateHandlerClass);\n      } else {\n        this.updateHandler = createUpdateHandler(\n            updateHandlerClass == null ? DirectUpdateHandler2.class.getName()\n                : updateHandlerClass, updateHandler);\n      }\n      infoRegistry.put(\"updateHandler\", this.updateHandler);\n\n      // Finally tell anyone who wants to know\n      resourceLoader.inform( resourceLoader );\n      resourceLoader.inform( this );  // last call before the latch is released.\n    } catch (Throwable e) {\n      latch.countDown();//release the latch, otherwise we block trying to do the close.  This should be fine, since counting down on a latch of 0 is still fine\n      //close down the searcher and any other resources, if it exists, as this is not recoverable\n      close();\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \n                              e.getMessage(), e);\n    } finally {\n      // allow firstSearcher events to fire and make sure it is released\n      latch.countDown();\n    }\n\n    infoRegistry.put(\"core\", this);\n    \n    // register any SolrInfoMBeans SolrResourceLoader initialized\n    //\n    // this must happen after the latch is released, because a JMX server impl may\n    // choose to block on registering until properties can be fetched from an MBean,\n    // and a SolrCoreAware MBean may have properties that depend on getting a Searcher\n    // from the core.\n    resourceLoader.inform(infoRegistry);\n    \n    // For debugging   \n//    numOpens.incrementAndGet();\n//    openHandles.put(this, new RuntimeException(\"unclosed core - name:\" + getName() + \" refs: \" + refCount.get()));\n  }\n\n","sourceOld":"  /**\n   * Creates a new core and register it in the list of cores.\n   * If a core with the same name already exists, it will be stopped and replaced by this one.\n   *@param dataDir the index directory\n   *@param config a solr config instance\n   *@param schema a solr schema instance\n   *\n   *@since solr 1.3\n   */\n  public SolrCore(String name, String dataDir, SolrConfig config, IndexSchema schema, CoreDescriptor cd, UpdateHandler updateHandler, SolrCore prev) {\n    coreDescriptor = cd;\n    this.setName( name );\n    resourceLoader = config.getResourceLoader();\n    if (dataDir == null){\n      if(cd.usingDefaultDataDir()) dataDir = config.getDataDir();\n      if(dataDir == null) dataDir = cd.getDataDir();\n    }\n\n    dataDir = SolrResourceLoader.normalizeDir(dataDir);\n\n    log.info(logid+\"Opening new SolrCore at \" + resourceLoader.getInstanceDir() + \", dataDir=\"+dataDir);\n\n    if (schema==null) {\n      schema = new IndexSchema(config, IndexSchema.DEFAULT_SCHEMA_FILE, null);\n    }\n\n    if (null != cd && null != cd.getCloudDescriptor()) {\n      // we are evidently running in cloud mode.  \n      //\n      // In cloud mode, version field is required for correct consistency\n      // ideally this check would be more fine grained, and individual features\n      // would assert it when they initialize, but DistribuedUpdateProcessor\n      // is currently a big ball of wax that does more then just distributing\n      // updates (ie: partial document updates), so it needs to work in no cloud\n      // mode as well, and can't assert version field support on init.\n\n      try {\n        Object ignored = VersionInfo.getAndCheckVersionField(schema);\n      } catch (SolrException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                                \"Schema will not work with SolrCloud mode: \" +\n                                e.getMessage(), e);\n      }\n    }\n\n    //Initialize JMX\n    if (config.jmxConfig.enabled) {\n      infoRegistry = new JmxMonitoredMap<String, SolrInfoMBean>(name, String.valueOf(this.hashCode()), config.jmxConfig);\n    } else  {\n      log.info(\"JMX monitoring not detected for core: \" + name);\n      infoRegistry = new ConcurrentHashMap<String, SolrInfoMBean>();\n    }\n\n    infoRegistry.put(\"fieldCache\", new SolrFieldCacheMBean());\n\n    this.schema = schema;\n    this.dataDir = dataDir;\n    this.solrConfig = config;\n    this.startTime = System.currentTimeMillis();\n    this.maxWarmingSearchers = config.maxWarmingSearchers;\n\n    booleanQueryMaxClauseCount();\n  \n    initListeners();\n\n    initDeletionPolicy();\n\n    this.codec= initCodec(solrConfig, schema);\n    \n    if (updateHandler == null) {\n      initDirectoryFactory();\n    } else {\n      directoryFactory = updateHandler.getSolrCoreState().getDirectoryFactory();\n      this.isReloaded = true;\n    }\n    \n    initIndex(prev != null);\n\n    initWriters();\n    initQParsers();\n    initValueSourceParsers();\n    initTransformerFactories();\n\n    this.searchComponents = Collections.unmodifiableMap(loadSearchComponents());\n\n    // Processors initialized before the handlers\n    updateProcessorChains = loadUpdateProcessorChains();\n    reqHandlers = new RequestHandlers(this);\n    reqHandlers.initHandlersFromConfig( solrConfig );\n\n\n    // Handle things that should eventually go away\n    initDeprecatedSupport();\n\n    final CountDownLatch latch = new CountDownLatch(1);\n\n    try {\n      // cause the executor to stall so firstSearcher events won't fire\n      // until after inform() has been called for all components.\n      // searchExecutor must be single-threaded for this to work\n      searcherExecutor.submit(new Callable() {\n        public Object call() throws Exception {\n          latch.await();\n          return null;\n        }\n      });\n\n      // use the (old) writer to open the first searcher\n      RefCounted<IndexWriter> iwRef = null;\n      if (prev != null) {\n        iwRef = prev.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n        if (iwRef != null) {\n          final IndexWriter iw = iwRef.get();\n          newReaderCreator = new Callable<DirectoryReader>() {\n            @Override\n            public DirectoryReader call() throws Exception {\n              return DirectoryReader.open(iw, true);\n            }\n          };\n        }\n      }\n\n      // Open the searcher *before* the update handler so we don't end up opening\n      // one in the middle.\n      // With lockless commits in Lucene now, this probably shouldn't be an issue anymore\n\n      try {\n        getSearcher(false,false,null,true);\n      } finally {\n        newReaderCreator = null;\n        if (iwRef != null) iwRef.decref();\n      }\n\n      String updateHandlerClass = solrConfig.getUpdateHandlerInfo().className;\n\n      if (updateHandler == null) {\n        this.updateHandler = createUpdateHandler(updateHandlerClass == null ? DirectUpdateHandler2.class\n            .getName() : updateHandlerClass);\n      } else {\n        this.updateHandler = createUpdateHandler(\n            updateHandlerClass == null ? DirectUpdateHandler2.class.getName()\n                : updateHandlerClass, updateHandler);\n      }\n      infoRegistry.put(\"updateHandler\", this.updateHandler);\n\n      // Finally tell anyone who wants to know\n      resourceLoader.inform( resourceLoader );\n      resourceLoader.inform( this );  // last call before the latch is released.\n    } catch (Throwable e) {\n      latch.countDown();//release the latch, otherwise we block trying to do the close.  This should be fine, since counting down on a latch of 0 is still fine\n      //close down the searcher and any other resources, if it exists, as this is not recoverable\n      close();\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \n                              e.getMessage(), e);\n    } finally {\n      // allow firstSearcher events to fire and make sure it is released\n      latch.countDown();\n    }\n\n    infoRegistry.put(\"core\", this);\n    \n    // register any SolrInfoMBeans SolrResourceLoader initialized\n    //\n    // this must happen after the latch is released, because a JMX server impl may\n    // choose to block on registering until properties can be fetched from an MBean,\n    // and a SolrCoreAware MBean may have properties that depend on getting a Searcher\n    // from the core.\n    resourceLoader.inform(infoRegistry);\n    \n    // For debugging   \n//    numOpens.incrementAndGet();\n//    openHandles.put(this, new RuntimeException(\"unclosed core - name:\" + getName() + \" refs: \" + refCount.get()));\n  }\n\n","bugFix":["2c007e7c4cf8c55bc2a5884e315123afaaeec87f"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d9405f486872f1e416304dfe389741f4ee2f8a4d","date":1351276739,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/SolrCore#SolrCore(String,String,SolrConfig,IndexSchema,CoreDescriptor,UpdateHandler,SolrCore).mjava","pathOld":"solr/core/src/java/org/apache/solr/core/SolrCore#SolrCore(String,String,SolrConfig,IndexSchema,CoreDescriptor,UpdateHandler,SolrCore).mjava","sourceNew":"  /**\n   * Creates a new core and register it in the list of cores.\n   * If a core with the same name already exists, it will be stopped and replaced by this one.\n   *@param dataDir the index directory\n   *@param config a solr config instance\n   *@param schema a solr schema instance\n   *\n   *@since solr 1.3\n   */\n  public SolrCore(String name, String dataDir, SolrConfig config, IndexSchema schema, CoreDescriptor cd, UpdateHandler updateHandler, SolrCore prev) {\n    coreDescriptor = cd;\n    this.setName( name );\n    resourceLoader = config.getResourceLoader();\n    if (dataDir == null){\n      if(cd.usingDefaultDataDir()) dataDir = config.getDataDir();\n      if(dataDir == null) dataDir = cd.getDataDir();\n    }\n\n    dataDir = SolrResourceLoader.normalizeDir(dataDir);\n\n    log.info(logid+\"Opening new SolrCore at \" + resourceLoader.getInstanceDir() + \", dataDir=\"+dataDir);\n\n    if (schema==null) {\n      schema = new IndexSchema(config, IndexSchema.DEFAULT_SCHEMA_FILE, null);\n    }\n\n    if (null != cd && null != cd.getCloudDescriptor()) {\n      // we are evidently running in cloud mode.  \n      //\n      // In cloud mode, version field is required for correct consistency\n      // ideally this check would be more fine grained, and individual features\n      // would assert it when they initialize, but DistribuedUpdateProcessor\n      // is currently a big ball of wax that does more then just distributing\n      // updates (ie: partial document updates), so it needs to work in no cloud\n      // mode as well, and can't assert version field support on init.\n\n      try {\n        Object ignored = VersionInfo.getAndCheckVersionField(schema);\n      } catch (SolrException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                                \"Schema will not work with SolrCloud mode: \" +\n                                e.getMessage(), e);\n      }\n    }\n\n    //Initialize JMX\n    if (config.jmxConfig.enabled) {\n      infoRegistry = new JmxMonitoredMap<String, SolrInfoMBean>(name, String.valueOf(this.hashCode()), config.jmxConfig);\n    } else  {\n      log.info(\"JMX monitoring not detected for core: \" + name);\n      infoRegistry = new ConcurrentHashMap<String, SolrInfoMBean>();\n    }\n\n    infoRegistry.put(\"fieldCache\", new SolrFieldCacheMBean());\n\n    this.schema = schema;\n    this.dataDir = dataDir;\n    this.solrConfig = config;\n    this.startTime = System.currentTimeMillis();\n    this.maxWarmingSearchers = config.maxWarmingSearchers;\n\n    booleanQueryMaxClauseCount();\n  \n    final CountDownLatch latch = new CountDownLatch(1);\n\n    try {\n      \n      initListeners();\n      \n      if (updateHandler == null) {\n        initDeletionPolicy();\n      }\n      \n      this.codec = initCodec(solrConfig, schema);\n      \n      if (updateHandler == null) {\n        initDirectoryFactory();\n        solrCoreState = new DefaultSolrCoreState(getDirectoryFactory());\n      } else {\n        solrCoreState = updateHandler.getSolrCoreState();\n        directoryFactory = solrCoreState.getDirectoryFactory();\n        this.isReloaded = true;\n      }\n      \n      initIndex(prev != null);\n      \n      initWriters();\n      initQParsers();\n      initValueSourceParsers();\n      initTransformerFactories();\n      \n      this.searchComponents = Collections\n          .unmodifiableMap(loadSearchComponents());\n      \n      // Processors initialized before the handlers\n      updateProcessorChains = loadUpdateProcessorChains();\n      reqHandlers = new RequestHandlers(this);\n      reqHandlers.initHandlersFromConfig(solrConfig);\n      \n      // Handle things that should eventually go away\n      initDeprecatedSupport();\n      \n      // cause the executor to stall so firstSearcher events won't fire\n      // until after inform() has been called for all components.\n      // searchExecutor must be single-threaded for this to work\n      searcherExecutor.submit(new Callable() {\n        public Object call() throws Exception {\n          latch.await();\n          return null;\n        }\n      });\n      \n      // use the (old) writer to open the first searcher\n      RefCounted<IndexWriter> iwRef = null;\n      if (prev != null) {\n        iwRef = prev.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n        if (iwRef != null) {\n          final IndexWriter iw = iwRef.get();\n          newReaderCreator = new Callable<DirectoryReader>() {\n            @Override\n            public DirectoryReader call() throws Exception {\n              return DirectoryReader.open(iw, true);\n            }\n          };\n        }\n      }\n      \n      // Open the searcher *before* the update handler so we don't end up\n      // opening\n      // one in the middle.\n      // With lockless commits in Lucene now, this probably shouldn't be an\n      // issue anymore\n      \n      try {\n        getSearcher(false, false, null, true);\n      } finally {\n        newReaderCreator = null;\n        if (iwRef != null) iwRef.decref();\n      }\n      \n      String updateHandlerClass = solrConfig.getUpdateHandlerInfo().className;\n      \n      if (updateHandler == null) {\n        this.updateHandler = createUpdateHandler(updateHandlerClass == null ? DirectUpdateHandler2.class\n            .getName() : updateHandlerClass);\n      } else {\n        this.updateHandler = createUpdateHandler(\n            updateHandlerClass == null ? DirectUpdateHandler2.class.getName()\n                : updateHandlerClass, updateHandler);\n      }\n      infoRegistry.put(\"updateHandler\", this.updateHandler);\n      \n      // Finally tell anyone who wants to know\n      resourceLoader.inform(resourceLoader);\n      resourceLoader.inform(this); // last call before the latch is released.\n    } catch (Throwable e) {\n      latch.countDown();//release the latch, otherwise we block trying to do the close.  This should be fine, since counting down on a latch of 0 is still fine\n      //close down the searcher and any other resources, if it exists, as this is not recoverable\n      close();\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \n                              e.getMessage(), e);\n    } finally {\n      // allow firstSearcher events to fire and make sure it is released\n      latch.countDown();\n    }\n\n    infoRegistry.put(\"core\", this);\n    \n    // register any SolrInfoMBeans SolrResourceLoader initialized\n    //\n    // this must happen after the latch is released, because a JMX server impl may\n    // choose to block on registering until properties can be fetched from an MBean,\n    // and a SolrCoreAware MBean may have properties that depend on getting a Searcher\n    // from the core.\n    resourceLoader.inform(infoRegistry);\n    \n    // For debugging   \n//    numOpens.incrementAndGet();\n//    openHandles.put(this, new RuntimeException(\"unclosed core - name:\" + getName() + \" refs: \" + refCount.get()));\n  }\n\n","sourceOld":"  /**\n   * Creates a new core and register it in the list of cores.\n   * If a core with the same name already exists, it will be stopped and replaced by this one.\n   *@param dataDir the index directory\n   *@param config a solr config instance\n   *@param schema a solr schema instance\n   *\n   *@since solr 1.3\n   */\n  public SolrCore(String name, String dataDir, SolrConfig config, IndexSchema schema, CoreDescriptor cd, UpdateHandler updateHandler, SolrCore prev) {\n    coreDescriptor = cd;\n    this.setName( name );\n    resourceLoader = config.getResourceLoader();\n    if (dataDir == null){\n      if(cd.usingDefaultDataDir()) dataDir = config.getDataDir();\n      if(dataDir == null) dataDir = cd.getDataDir();\n    }\n\n    dataDir = SolrResourceLoader.normalizeDir(dataDir);\n\n    log.info(logid+\"Opening new SolrCore at \" + resourceLoader.getInstanceDir() + \", dataDir=\"+dataDir);\n\n    if (schema==null) {\n      schema = new IndexSchema(config, IndexSchema.DEFAULT_SCHEMA_FILE, null);\n    }\n\n    if (null != cd && null != cd.getCloudDescriptor()) {\n      // we are evidently running in cloud mode.  \n      //\n      // In cloud mode, version field is required for correct consistency\n      // ideally this check would be more fine grained, and individual features\n      // would assert it when they initialize, but DistribuedUpdateProcessor\n      // is currently a big ball of wax that does more then just distributing\n      // updates (ie: partial document updates), so it needs to work in no cloud\n      // mode as well, and can't assert version field support on init.\n\n      try {\n        Object ignored = VersionInfo.getAndCheckVersionField(schema);\n      } catch (SolrException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                                \"Schema will not work with SolrCloud mode: \" +\n                                e.getMessage(), e);\n      }\n    }\n\n    //Initialize JMX\n    if (config.jmxConfig.enabled) {\n      infoRegistry = new JmxMonitoredMap<String, SolrInfoMBean>(name, String.valueOf(this.hashCode()), config.jmxConfig);\n    } else  {\n      log.info(\"JMX monitoring not detected for core: \" + name);\n      infoRegistry = new ConcurrentHashMap<String, SolrInfoMBean>();\n    }\n\n    infoRegistry.put(\"fieldCache\", new SolrFieldCacheMBean());\n\n    this.schema = schema;\n    this.dataDir = dataDir;\n    this.solrConfig = config;\n    this.startTime = System.currentTimeMillis();\n    this.maxWarmingSearchers = config.maxWarmingSearchers;\n\n    booleanQueryMaxClauseCount();\n  \n    initListeners();\n\n    initDeletionPolicy();\n\n    this.codec= initCodec(solrConfig, schema);\n    \n    if (updateHandler == null) {\n      initDirectoryFactory();\n      solrCoreState = new DefaultSolrCoreState(getDirectoryFactory());\n    } else {\n      solrCoreState = updateHandler.getSolrCoreState();\n      directoryFactory = solrCoreState.getDirectoryFactory();\n      this.isReloaded = true;\n    }\n    \n    initIndex(prev != null);\n\n    initWriters();\n    initQParsers();\n    initValueSourceParsers();\n    initTransformerFactories();\n\n    this.searchComponents = Collections.unmodifiableMap(loadSearchComponents());\n\n    // Processors initialized before the handlers\n    updateProcessorChains = loadUpdateProcessorChains();\n    reqHandlers = new RequestHandlers(this);\n    reqHandlers.initHandlersFromConfig( solrConfig );\n\n\n    // Handle things that should eventually go away\n    initDeprecatedSupport();\n\n    final CountDownLatch latch = new CountDownLatch(1);\n\n    try {\n      // cause the executor to stall so firstSearcher events won't fire\n      // until after inform() has been called for all components.\n      // searchExecutor must be single-threaded for this to work\n      searcherExecutor.submit(new Callable() {\n        public Object call() throws Exception {\n          latch.await();\n          return null;\n        }\n      });\n\n      // use the (old) writer to open the first searcher\n      RefCounted<IndexWriter> iwRef = null;\n      if (prev != null) {\n        iwRef = prev.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n        if (iwRef != null) {\n          final IndexWriter iw = iwRef.get();\n          newReaderCreator = new Callable<DirectoryReader>() {\n            @Override\n            public DirectoryReader call() throws Exception {\n              return DirectoryReader.open(iw, true);\n            }\n          };\n        }\n      }\n\n      // Open the searcher *before* the update handler so we don't end up opening\n      // one in the middle.\n      // With lockless commits in Lucene now, this probably shouldn't be an issue anymore\n\n      try {\n        getSearcher(false,false,null,true);\n      } finally {\n        newReaderCreator = null;\n        if (iwRef != null) iwRef.decref();\n      }\n\n      String updateHandlerClass = solrConfig.getUpdateHandlerInfo().className;\n\n      if (updateHandler == null) {\n        this.updateHandler = createUpdateHandler(updateHandlerClass == null ? DirectUpdateHandler2.class\n            .getName() : updateHandlerClass);\n      } else {\n        this.updateHandler = createUpdateHandler(\n            updateHandlerClass == null ? DirectUpdateHandler2.class.getName()\n                : updateHandlerClass, updateHandler);\n      }\n      infoRegistry.put(\"updateHandler\", this.updateHandler);\n\n      // Finally tell anyone who wants to know\n      resourceLoader.inform( resourceLoader );\n      resourceLoader.inform( this );  // last call before the latch is released.\n    } catch (Throwable e) {\n      latch.countDown();//release the latch, otherwise we block trying to do the close.  This should be fine, since counting down on a latch of 0 is still fine\n      //close down the searcher and any other resources, if it exists, as this is not recoverable\n      close();\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \n                              e.getMessage(), e);\n    } finally {\n      // allow firstSearcher events to fire and make sure it is released\n      latch.countDown();\n    }\n\n    infoRegistry.put(\"core\", this);\n    \n    // register any SolrInfoMBeans SolrResourceLoader initialized\n    //\n    // this must happen after the latch is released, because a JMX server impl may\n    // choose to block on registering until properties can be fetched from an MBean,\n    // and a SolrCoreAware MBean may have properties that depend on getting a Searcher\n    // from the core.\n    resourceLoader.inform(infoRegistry);\n    \n    // For debugging   \n//    numOpens.incrementAndGet();\n//    openHandles.put(this, new RuntimeException(\"unclosed core - name:\" + getName() + \" refs: \" + refCount.get()));\n  }\n\n","bugFix":null,"bugIntro":["2336740b200d02b6a5fb18b70454dd9aa26f5b47","2679aff35efbec5a5b825d59f006636fda4224d4"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"f2126b84bd093fa3d921582a109a0ee578c28126","date":1351522501,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/core/SolrCore#SolrCore(String,String,SolrConfig,IndexSchema,CoreDescriptor,UpdateHandler,SolrCore).mjava","pathOld":"solr/core/src/java/org/apache/solr/core/SolrCore#SolrCore(String,String,SolrConfig,IndexSchema,CoreDescriptor,UpdateHandler,SolrCore).mjava","sourceNew":"  /**\n   * Creates a new core and register it in the list of cores.\n   * If a core with the same name already exists, it will be stopped and replaced by this one.\n   *@param dataDir the index directory\n   *@param config a solr config instance\n   *@param schema a solr schema instance\n   *\n   *@since solr 1.3\n   */\n  public SolrCore(String name, String dataDir, SolrConfig config, IndexSchema schema, CoreDescriptor cd, UpdateHandler updateHandler, SolrCore prev) {\n    coreDescriptor = cd;\n    this.setName( name );\n    resourceLoader = config.getResourceLoader();\n    if (dataDir == null){\n      if(cd.usingDefaultDataDir()) dataDir = config.getDataDir();\n      if(dataDir == null) dataDir = cd.getDataDir();\n    }\n\n    dataDir = SolrResourceLoader.normalizeDir(dataDir);\n\n    log.info(logid+\"Opening new SolrCore at \" + resourceLoader.getInstanceDir() + \", dataDir=\"+dataDir);\n\n    if (schema==null) {\n      schema = new IndexSchema(config, IndexSchema.DEFAULT_SCHEMA_FILE, null);\n    }\n\n    if (null != cd && null != cd.getCloudDescriptor()) {\n      // we are evidently running in cloud mode.  \n      //\n      // In cloud mode, version field is required for correct consistency\n      // ideally this check would be more fine grained, and individual features\n      // would assert it when they initialize, but DistribuedUpdateProcessor\n      // is currently a big ball of wax that does more then just distributing\n      // updates (ie: partial document updates), so it needs to work in no cloud\n      // mode as well, and can't assert version field support on init.\n\n      try {\n        Object ignored = VersionInfo.getAndCheckVersionField(schema);\n      } catch (SolrException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                                \"Schema will not work with SolrCloud mode: \" +\n                                e.getMessage(), e);\n      }\n    }\n\n    //Initialize JMX\n    if (config.jmxConfig.enabled) {\n      infoRegistry = new JmxMonitoredMap<String, SolrInfoMBean>(name, String.valueOf(this.hashCode()), config.jmxConfig);\n    } else  {\n      log.info(\"JMX monitoring not detected for core: \" + name);\n      infoRegistry = new ConcurrentHashMap<String, SolrInfoMBean>();\n    }\n\n    infoRegistry.put(\"fieldCache\", new SolrFieldCacheMBean());\n\n    this.schema = schema;\n    this.dataDir = dataDir;\n    this.solrConfig = config;\n    this.startTime = System.currentTimeMillis();\n    this.maxWarmingSearchers = config.maxWarmingSearchers;\n\n    booleanQueryMaxClauseCount();\n  \n    final CountDownLatch latch = new CountDownLatch(1);\n\n    try {\n      \n      initListeners();\n      \n      if (updateHandler == null) {\n        initDeletionPolicy();\n      }\n      \n      this.codec = initCodec(solrConfig, schema);\n      \n      if (updateHandler == null) {\n        initDirectoryFactory();\n        solrCoreState = new DefaultSolrCoreState(getDirectoryFactory());\n      } else {\n        solrCoreState = updateHandler.getSolrCoreState();\n        directoryFactory = solrCoreState.getDirectoryFactory();\n        this.isReloaded = true;\n      }\n      \n      initIndex(prev != null);\n      \n      initWriters();\n      initQParsers();\n      initValueSourceParsers();\n      initTransformerFactories();\n      \n      this.searchComponents = Collections\n          .unmodifiableMap(loadSearchComponents());\n      \n      // Processors initialized before the handlers\n      updateProcessorChains = loadUpdateProcessorChains();\n      reqHandlers = new RequestHandlers(this);\n      reqHandlers.initHandlersFromConfig(solrConfig);\n      \n      // Handle things that should eventually go away\n      initDeprecatedSupport();\n      \n      // cause the executor to stall so firstSearcher events won't fire\n      // until after inform() has been called for all components.\n      // searchExecutor must be single-threaded for this to work\n      searcherExecutor.submit(new Callable() {\n        public Object call() throws Exception {\n          latch.await();\n          return null;\n        }\n      });\n      \n      // use the (old) writer to open the first searcher\n      RefCounted<IndexWriter> iwRef = null;\n      if (prev != null) {\n        iwRef = prev.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n        if (iwRef != null) {\n          final IndexWriter iw = iwRef.get();\n          newReaderCreator = new Callable<DirectoryReader>() {\n            @Override\n            public DirectoryReader call() throws Exception {\n              return DirectoryReader.open(iw, true);\n            }\n          };\n        }\n      }\n      \n      // Open the searcher *before* the update handler so we don't end up\n      // opening\n      // one in the middle.\n      // With lockless commits in Lucene now, this probably shouldn't be an\n      // issue anymore\n      \n      try {\n        getSearcher(false, false, null, true);\n      } finally {\n        newReaderCreator = null;\n        if (iwRef != null) iwRef.decref();\n      }\n      \n      String updateHandlerClass = solrConfig.getUpdateHandlerInfo().className;\n      \n      if (updateHandler == null) {\n        this.updateHandler = createUpdateHandler(updateHandlerClass == null ? DirectUpdateHandler2.class\n            .getName() : updateHandlerClass);\n      } else {\n        this.updateHandler = createUpdateHandler(\n            updateHandlerClass == null ? DirectUpdateHandler2.class.getName()\n                : updateHandlerClass, updateHandler);\n      }\n      infoRegistry.put(\"updateHandler\", this.updateHandler);\n      \n      // Finally tell anyone who wants to know\n      resourceLoader.inform(resourceLoader);\n      resourceLoader.inform(this); // last call before the latch is released.\n    } catch (Throwable e) {\n      latch.countDown();//release the latch, otherwise we block trying to do the close.  This should be fine, since counting down on a latch of 0 is still fine\n      //close down the searcher and any other resources, if it exists, as this is not recoverable\n      close();\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \n                              e.getMessage(), e);\n    } finally {\n      // allow firstSearcher events to fire and make sure it is released\n      latch.countDown();\n    }\n\n    infoRegistry.put(\"core\", this);\n    \n    // register any SolrInfoMBeans SolrResourceLoader initialized\n    //\n    // this must happen after the latch is released, because a JMX server impl may\n    // choose to block on registering until properties can be fetched from an MBean,\n    // and a SolrCoreAware MBean may have properties that depend on getting a Searcher\n    // from the core.\n    resourceLoader.inform(infoRegistry);\n    \n    // For debugging   \n//    numOpens.incrementAndGet();\n//    openHandles.put(this, new RuntimeException(\"unclosed core - name:\" + getName() + \" refs: \" + refCount.get()));\n  }\n\n","sourceOld":"  /**\n   * Creates a new core and register it in the list of cores.\n   * If a core with the same name already exists, it will be stopped and replaced by this one.\n   *@param dataDir the index directory\n   *@param config a solr config instance\n   *@param schema a solr schema instance\n   *\n   *@since solr 1.3\n   */\n  public SolrCore(String name, String dataDir, SolrConfig config, IndexSchema schema, CoreDescriptor cd, UpdateHandler updateHandler, SolrCore prev) {\n    coreDescriptor = cd;\n    this.setName( name );\n    resourceLoader = config.getResourceLoader();\n    if (dataDir == null){\n      if(cd.usingDefaultDataDir()) dataDir = config.getDataDir();\n      if(dataDir == null) dataDir = cd.getDataDir();\n    }\n\n    dataDir = SolrResourceLoader.normalizeDir(dataDir);\n\n    log.info(logid+\"Opening new SolrCore at \" + resourceLoader.getInstanceDir() + \", dataDir=\"+dataDir);\n\n    if (schema==null) {\n      schema = new IndexSchema(config, IndexSchema.DEFAULT_SCHEMA_FILE, null);\n    }\n\n    if (null != cd && null != cd.getCloudDescriptor()) {\n      // we are evidently running in cloud mode.  \n      //\n      // In cloud mode, version field is required for correct consistency\n      // ideally this check would be more fine grained, and individual features\n      // would assert it when they initialize, but DistribuedUpdateProcessor\n      // is currently a big ball of wax that does more then just distributing\n      // updates (ie: partial document updates), so it needs to work in no cloud\n      // mode as well, and can't assert version field support on init.\n\n      try {\n        Object ignored = VersionInfo.getAndCheckVersionField(schema);\n      } catch (SolrException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                                \"Schema will not work with SolrCloud mode: \" +\n                                e.getMessage(), e);\n      }\n    }\n\n    //Initialize JMX\n    if (config.jmxConfig.enabled) {\n      infoRegistry = new JmxMonitoredMap<String, SolrInfoMBean>(name, String.valueOf(this.hashCode()), config.jmxConfig);\n    } else  {\n      log.info(\"JMX monitoring not detected for core: \" + name);\n      infoRegistry = new ConcurrentHashMap<String, SolrInfoMBean>();\n    }\n\n    infoRegistry.put(\"fieldCache\", new SolrFieldCacheMBean());\n\n    this.schema = schema;\n    this.dataDir = dataDir;\n    this.solrConfig = config;\n    this.startTime = System.currentTimeMillis();\n    this.maxWarmingSearchers = config.maxWarmingSearchers;\n\n    booleanQueryMaxClauseCount();\n  \n    initListeners();\n\n    initDeletionPolicy();\n\n    this.codec= initCodec(solrConfig, schema);\n    \n    if (updateHandler == null) {\n      initDirectoryFactory();\n      solrCoreState = new DefaultSolrCoreState(getDirectoryFactory());\n    } else {\n      solrCoreState = updateHandler.getSolrCoreState();\n      directoryFactory = solrCoreState.getDirectoryFactory();\n      this.isReloaded = true;\n    }\n    \n    initIndex(prev != null);\n\n    initWriters();\n    initQParsers();\n    initValueSourceParsers();\n    initTransformerFactories();\n\n    this.searchComponents = Collections.unmodifiableMap(loadSearchComponents());\n\n    // Processors initialized before the handlers\n    updateProcessorChains = loadUpdateProcessorChains();\n    reqHandlers = new RequestHandlers(this);\n    reqHandlers.initHandlersFromConfig( solrConfig );\n\n\n    // Handle things that should eventually go away\n    initDeprecatedSupport();\n\n    final CountDownLatch latch = new CountDownLatch(1);\n\n    try {\n      // cause the executor to stall so firstSearcher events won't fire\n      // until after inform() has been called for all components.\n      // searchExecutor must be single-threaded for this to work\n      searcherExecutor.submit(new Callable() {\n        public Object call() throws Exception {\n          latch.await();\n          return null;\n        }\n      });\n\n      // use the (old) writer to open the first searcher\n      RefCounted<IndexWriter> iwRef = null;\n      if (prev != null) {\n        iwRef = prev.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n        if (iwRef != null) {\n          final IndexWriter iw = iwRef.get();\n          newReaderCreator = new Callable<DirectoryReader>() {\n            @Override\n            public DirectoryReader call() throws Exception {\n              return DirectoryReader.open(iw, true);\n            }\n          };\n        }\n      }\n\n      // Open the searcher *before* the update handler so we don't end up opening\n      // one in the middle.\n      // With lockless commits in Lucene now, this probably shouldn't be an issue anymore\n\n      try {\n        getSearcher(false,false,null,true);\n      } finally {\n        newReaderCreator = null;\n        if (iwRef != null) iwRef.decref();\n      }\n\n      String updateHandlerClass = solrConfig.getUpdateHandlerInfo().className;\n\n      if (updateHandler == null) {\n        this.updateHandler = createUpdateHandler(updateHandlerClass == null ? DirectUpdateHandler2.class\n            .getName() : updateHandlerClass);\n      } else {\n        this.updateHandler = createUpdateHandler(\n            updateHandlerClass == null ? DirectUpdateHandler2.class.getName()\n                : updateHandlerClass, updateHandler);\n      }\n      infoRegistry.put(\"updateHandler\", this.updateHandler);\n\n      // Finally tell anyone who wants to know\n      resourceLoader.inform( resourceLoader );\n      resourceLoader.inform( this );  // last call before the latch is released.\n    } catch (Throwable e) {\n      latch.countDown();//release the latch, otherwise we block trying to do the close.  This should be fine, since counting down on a latch of 0 is still fine\n      //close down the searcher and any other resources, if it exists, as this is not recoverable\n      close();\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \n                              e.getMessage(), e);\n    } finally {\n      // allow firstSearcher events to fire and make sure it is released\n      latch.countDown();\n    }\n\n    infoRegistry.put(\"core\", this);\n    \n    // register any SolrInfoMBeans SolrResourceLoader initialized\n    //\n    // this must happen after the latch is released, because a JMX server impl may\n    // choose to block on registering until properties can be fetched from an MBean,\n    // and a SolrCoreAware MBean may have properties that depend on getting a Searcher\n    // from the core.\n    resourceLoader.inform(infoRegistry);\n    \n    // For debugging   \n//    numOpens.incrementAndGet();\n//    openHandles.put(this, new RuntimeException(\"unclosed core - name:\" + getName() + \" refs: \" + refCount.get()));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7530de27b87b961b51f01bd1299b7004d46e8823","date":1355236261,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/SolrCore#SolrCore(String,String,SolrConfig,IndexSchema,CoreDescriptor,UpdateHandler,SolrCore).mjava","pathOld":"solr/core/src/java/org/apache/solr/core/SolrCore#SolrCore(String,String,SolrConfig,IndexSchema,CoreDescriptor,UpdateHandler,SolrCore).mjava","sourceNew":"  /**\n   * Creates a new core and register it in the list of cores.\n   * If a core with the same name already exists, it will be stopped and replaced by this one.\n   *@param dataDir the index directory\n   *@param config a solr config instance\n   *@param schema a solr schema instance\n   *\n   *@since solr 1.3\n   */\n  public SolrCore(String name, String dataDir, SolrConfig config, IndexSchema schema, CoreDescriptor cd, UpdateHandler updateHandler, SolrCore prev) {\n    coreDescriptor = cd;\n    this.setName( name );\n    resourceLoader = config.getResourceLoader();\n    if (dataDir == null){\n      if(cd.usingDefaultDataDir()) dataDir = config.getDataDir();\n      if(dataDir == null) dataDir = cd.getDataDir();\n    }\n\n    dataDir = SolrResourceLoader.normalizeDir(dataDir);\n\n    log.info(logid+\"Opening new SolrCore at \" + resourceLoader.getInstanceDir() + \", dataDir=\"+dataDir);\n\n    if (schema==null) {\n      schema = new IndexSchema(config, IndexSchema.DEFAULT_SCHEMA_FILE, null);\n    }\n\n    if (null != cd && null != cd.getCloudDescriptor()) {\n      // we are evidently running in cloud mode.  \n      //\n      // In cloud mode, version field is required for correct consistency\n      // ideally this check would be more fine grained, and individual features\n      // would assert it when they initialize, but DistribuedUpdateProcessor\n      // is currently a big ball of wax that does more then just distributing\n      // updates (ie: partial document updates), so it needs to work in no cloud\n      // mode as well, and can't assert version field support on init.\n\n      try {\n        Object ignored = VersionInfo.getAndCheckVersionField(schema);\n      } catch (SolrException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                                \"Schema will not work with SolrCloud mode: \" +\n                                e.getMessage(), e);\n      }\n    }\n\n    //Initialize JMX\n    if (config.jmxConfig.enabled) {\n      infoRegistry = new JmxMonitoredMap<String, SolrInfoMBean>(name, String.valueOf(this.hashCode()), config.jmxConfig);\n    } else  {\n      log.info(\"JMX monitoring not detected for core: \" + name);\n      infoRegistry = new ConcurrentHashMap<String, SolrInfoMBean>();\n    }\n\n    infoRegistry.put(\"fieldCache\", new SolrFieldCacheMBean());\n\n    this.schema = schema;\n    this.dataDir = dataDir;\n    this.solrConfig = config;\n    this.startTime = System.currentTimeMillis();\n    this.maxWarmingSearchers = config.maxWarmingSearchers;\n\n    booleanQueryMaxClauseCount();\n  \n    final CountDownLatch latch = new CountDownLatch(1);\n\n    try {\n      \n      initListeners();\n      \n      if (updateHandler == null) {\n        initDeletionPolicy();\n      }\n      \n      this.codec = initCodec(solrConfig, schema);\n      \n      if (updateHandler == null) {\n        initDirectoryFactory();\n        solrCoreState = new DefaultSolrCoreState(getDirectoryFactory());\n      } else {\n        solrCoreState = updateHandler.getSolrCoreState();\n        directoryFactory = solrCoreState.getDirectoryFactory();\n        this.isReloaded = true;\n      }\n      \n      initIndex(prev != null);\n      \n      initWriters();\n      initQParsers();\n      initValueSourceParsers();\n      initTransformerFactories();\n      \n      this.searchComponents = Collections\n          .unmodifiableMap(loadSearchComponents());\n      \n      // Processors initialized before the handlers\n      updateProcessorChains = loadUpdateProcessorChains();\n      reqHandlers = new RequestHandlers(this);\n      reqHandlers.initHandlersFromConfig(solrConfig);\n      \n      // Handle things that should eventually go away\n      initDeprecatedSupport();\n      \n      // cause the executor to stall so firstSearcher events won't fire\n      // until after inform() has been called for all components.\n      // searchExecutor must be single-threaded for this to work\n      searcherExecutor.submit(new Callable() {\n        @Override\n        public Object call() throws Exception {\n          latch.await();\n          return null;\n        }\n      });\n      \n      // use the (old) writer to open the first searcher\n      RefCounted<IndexWriter> iwRef = null;\n      if (prev != null) {\n        iwRef = prev.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n        if (iwRef != null) {\n          final IndexWriter iw = iwRef.get();\n          newReaderCreator = new Callable<DirectoryReader>() {\n            @Override\n            public DirectoryReader call() throws Exception {\n              return DirectoryReader.open(iw, true);\n            }\n          };\n        }\n      }\n      \n      // Open the searcher *before* the update handler so we don't end up\n      // opening\n      // one in the middle.\n      // With lockless commits in Lucene now, this probably shouldn't be an\n      // issue anymore\n      \n      try {\n        getSearcher(false, false, null, true);\n      } finally {\n        newReaderCreator = null;\n        if (iwRef != null) iwRef.decref();\n      }\n      \n      String updateHandlerClass = solrConfig.getUpdateHandlerInfo().className;\n      \n      if (updateHandler == null) {\n        this.updateHandler = createUpdateHandler(updateHandlerClass == null ? DirectUpdateHandler2.class\n            .getName() : updateHandlerClass);\n      } else {\n        this.updateHandler = createUpdateHandler(\n            updateHandlerClass == null ? DirectUpdateHandler2.class.getName()\n                : updateHandlerClass, updateHandler);\n      }\n      infoRegistry.put(\"updateHandler\", this.updateHandler);\n      \n      // Finally tell anyone who wants to know\n      resourceLoader.inform(resourceLoader);\n      resourceLoader.inform(this); // last call before the latch is released.\n    } catch (Throwable e) {\n      latch.countDown();//release the latch, otherwise we block trying to do the close.  This should be fine, since counting down on a latch of 0 is still fine\n      //close down the searcher and any other resources, if it exists, as this is not recoverable\n      close();\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \n                              e.getMessage(), e);\n    } finally {\n      // allow firstSearcher events to fire and make sure it is released\n      latch.countDown();\n    }\n\n    infoRegistry.put(\"core\", this);\n    \n    // register any SolrInfoMBeans SolrResourceLoader initialized\n    //\n    // this must happen after the latch is released, because a JMX server impl may\n    // choose to block on registering until properties can be fetched from an MBean,\n    // and a SolrCoreAware MBean may have properties that depend on getting a Searcher\n    // from the core.\n    resourceLoader.inform(infoRegistry);\n    \n    // For debugging   \n//    numOpens.incrementAndGet();\n//    openHandles.put(this, new RuntimeException(\"unclosed core - name:\" + getName() + \" refs: \" + refCount.get()));\n  }\n\n","sourceOld":"  /**\n   * Creates a new core and register it in the list of cores.\n   * If a core with the same name already exists, it will be stopped and replaced by this one.\n   *@param dataDir the index directory\n   *@param config a solr config instance\n   *@param schema a solr schema instance\n   *\n   *@since solr 1.3\n   */\n  public SolrCore(String name, String dataDir, SolrConfig config, IndexSchema schema, CoreDescriptor cd, UpdateHandler updateHandler, SolrCore prev) {\n    coreDescriptor = cd;\n    this.setName( name );\n    resourceLoader = config.getResourceLoader();\n    if (dataDir == null){\n      if(cd.usingDefaultDataDir()) dataDir = config.getDataDir();\n      if(dataDir == null) dataDir = cd.getDataDir();\n    }\n\n    dataDir = SolrResourceLoader.normalizeDir(dataDir);\n\n    log.info(logid+\"Opening new SolrCore at \" + resourceLoader.getInstanceDir() + \", dataDir=\"+dataDir);\n\n    if (schema==null) {\n      schema = new IndexSchema(config, IndexSchema.DEFAULT_SCHEMA_FILE, null);\n    }\n\n    if (null != cd && null != cd.getCloudDescriptor()) {\n      // we are evidently running in cloud mode.  \n      //\n      // In cloud mode, version field is required for correct consistency\n      // ideally this check would be more fine grained, and individual features\n      // would assert it when they initialize, but DistribuedUpdateProcessor\n      // is currently a big ball of wax that does more then just distributing\n      // updates (ie: partial document updates), so it needs to work in no cloud\n      // mode as well, and can't assert version field support on init.\n\n      try {\n        Object ignored = VersionInfo.getAndCheckVersionField(schema);\n      } catch (SolrException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                                \"Schema will not work with SolrCloud mode: \" +\n                                e.getMessage(), e);\n      }\n    }\n\n    //Initialize JMX\n    if (config.jmxConfig.enabled) {\n      infoRegistry = new JmxMonitoredMap<String, SolrInfoMBean>(name, String.valueOf(this.hashCode()), config.jmxConfig);\n    } else  {\n      log.info(\"JMX monitoring not detected for core: \" + name);\n      infoRegistry = new ConcurrentHashMap<String, SolrInfoMBean>();\n    }\n\n    infoRegistry.put(\"fieldCache\", new SolrFieldCacheMBean());\n\n    this.schema = schema;\n    this.dataDir = dataDir;\n    this.solrConfig = config;\n    this.startTime = System.currentTimeMillis();\n    this.maxWarmingSearchers = config.maxWarmingSearchers;\n\n    booleanQueryMaxClauseCount();\n  \n    final CountDownLatch latch = new CountDownLatch(1);\n\n    try {\n      \n      initListeners();\n      \n      if (updateHandler == null) {\n        initDeletionPolicy();\n      }\n      \n      this.codec = initCodec(solrConfig, schema);\n      \n      if (updateHandler == null) {\n        initDirectoryFactory();\n        solrCoreState = new DefaultSolrCoreState(getDirectoryFactory());\n      } else {\n        solrCoreState = updateHandler.getSolrCoreState();\n        directoryFactory = solrCoreState.getDirectoryFactory();\n        this.isReloaded = true;\n      }\n      \n      initIndex(prev != null);\n      \n      initWriters();\n      initQParsers();\n      initValueSourceParsers();\n      initTransformerFactories();\n      \n      this.searchComponents = Collections\n          .unmodifiableMap(loadSearchComponents());\n      \n      // Processors initialized before the handlers\n      updateProcessorChains = loadUpdateProcessorChains();\n      reqHandlers = new RequestHandlers(this);\n      reqHandlers.initHandlersFromConfig(solrConfig);\n      \n      // Handle things that should eventually go away\n      initDeprecatedSupport();\n      \n      // cause the executor to stall so firstSearcher events won't fire\n      // until after inform() has been called for all components.\n      // searchExecutor must be single-threaded for this to work\n      searcherExecutor.submit(new Callable() {\n        public Object call() throws Exception {\n          latch.await();\n          return null;\n        }\n      });\n      \n      // use the (old) writer to open the first searcher\n      RefCounted<IndexWriter> iwRef = null;\n      if (prev != null) {\n        iwRef = prev.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n        if (iwRef != null) {\n          final IndexWriter iw = iwRef.get();\n          newReaderCreator = new Callable<DirectoryReader>() {\n            @Override\n            public DirectoryReader call() throws Exception {\n              return DirectoryReader.open(iw, true);\n            }\n          };\n        }\n      }\n      \n      // Open the searcher *before* the update handler so we don't end up\n      // opening\n      // one in the middle.\n      // With lockless commits in Lucene now, this probably shouldn't be an\n      // issue anymore\n      \n      try {\n        getSearcher(false, false, null, true);\n      } finally {\n        newReaderCreator = null;\n        if (iwRef != null) iwRef.decref();\n      }\n      \n      String updateHandlerClass = solrConfig.getUpdateHandlerInfo().className;\n      \n      if (updateHandler == null) {\n        this.updateHandler = createUpdateHandler(updateHandlerClass == null ? DirectUpdateHandler2.class\n            .getName() : updateHandlerClass);\n      } else {\n        this.updateHandler = createUpdateHandler(\n            updateHandlerClass == null ? DirectUpdateHandler2.class.getName()\n                : updateHandlerClass, updateHandler);\n      }\n      infoRegistry.put(\"updateHandler\", this.updateHandler);\n      \n      // Finally tell anyone who wants to know\n      resourceLoader.inform(resourceLoader);\n      resourceLoader.inform(this); // last call before the latch is released.\n    } catch (Throwable e) {\n      latch.countDown();//release the latch, otherwise we block trying to do the close.  This should be fine, since counting down on a latch of 0 is still fine\n      //close down the searcher and any other resources, if it exists, as this is not recoverable\n      close();\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \n                              e.getMessage(), e);\n    } finally {\n      // allow firstSearcher events to fire and make sure it is released\n      latch.countDown();\n    }\n\n    infoRegistry.put(\"core\", this);\n    \n    // register any SolrInfoMBeans SolrResourceLoader initialized\n    //\n    // this must happen after the latch is released, because a JMX server impl may\n    // choose to block on registering until properties can be fetched from an MBean,\n    // and a SolrCoreAware MBean may have properties that depend on getting a Searcher\n    // from the core.\n    resourceLoader.inform(infoRegistry);\n    \n    // For debugging   \n//    numOpens.incrementAndGet();\n//    openHandles.put(this, new RuntimeException(\"unclosed core - name:\" + getName() + \" refs: \" + refCount.get()));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d3fcb70cf561547c7bb1506e0cf32ca7b1287064","date":1357616416,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/core/SolrCore#SolrCore(String,String,SolrConfig,IndexSchema,CoreDescriptor,UpdateHandler,SolrCore).mjava","pathOld":"solr/core/src/java/org/apache/solr/core/SolrCore#SolrCore(String,String,SolrConfig,IndexSchema,CoreDescriptor,UpdateHandler,SolrCore).mjava","sourceNew":"  /**\n   * Creates a new core and register it in the list of cores.\n   * If a core with the same name already exists, it will be stopped and replaced by this one.\n   *@param dataDir the index directory\n   *@param config a solr config instance\n   *@param schema a solr schema instance\n   *\n   *@since solr 1.3\n   */\n  public SolrCore(String name, String dataDir, SolrConfig config, IndexSchema schema, CoreDescriptor cd, UpdateHandler updateHandler, SolrCore prev) {\n    coreDescriptor = cd;\n    this.setName( name );\n    resourceLoader = config.getResourceLoader();\n    if (dataDir == null){\n      if(cd.usingDefaultDataDir()) dataDir = config.getDataDir();\n      if(dataDir == null) dataDir = cd.getDataDir();\n    }\n\n    dataDir = SolrResourceLoader.normalizeDir(dataDir);\n\n    log.info(logid+\"Opening new SolrCore at \" + resourceLoader.getInstanceDir() + \", dataDir=\"+dataDir);\n\n    if (schema==null) {\n      schema = new IndexSchema(config, IndexSchema.DEFAULT_SCHEMA_FILE, null);\n    }\n\n    if (null != cd && null != cd.getCloudDescriptor()) {\n      // we are evidently running in cloud mode.  \n      //\n      // In cloud mode, version field is required for correct consistency\n      // ideally this check would be more fine grained, and individual features\n      // would assert it when they initialize, but DistribuedUpdateProcessor\n      // is currently a big ball of wax that does more then just distributing\n      // updates (ie: partial document updates), so it needs to work in no cloud\n      // mode as well, and can't assert version field support on init.\n\n      try {\n        Object ignored = VersionInfo.getAndCheckVersionField(schema);\n      } catch (SolrException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                                \"Schema will not work with SolrCloud mode: \" +\n                                e.getMessage(), e);\n      }\n    }\n\n    //Initialize JMX\n    if (config.jmxConfig.enabled) {\n      infoRegistry = new JmxMonitoredMap<String, SolrInfoMBean>(name, String.valueOf(this.hashCode()), config.jmxConfig);\n    } else  {\n      log.info(\"JMX monitoring not detected for core: \" + name);\n      infoRegistry = new ConcurrentHashMap<String, SolrInfoMBean>();\n    }\n\n    infoRegistry.put(\"fieldCache\", new SolrFieldCacheMBean());\n\n    this.schema = schema;\n    this.dataDir = dataDir;\n    this.solrConfig = config;\n    this.startTime = System.currentTimeMillis();\n    this.maxWarmingSearchers = config.maxWarmingSearchers;\n\n    booleanQueryMaxClauseCount();\n  \n    final CountDownLatch latch = new CountDownLatch(1);\n\n    try {\n      \n      initListeners();\n      \n      if (updateHandler == null) {\n        initDeletionPolicy();\n      }\n      \n      this.codec = initCodec(solrConfig, schema);\n      \n      if (updateHandler == null) {\n        initDirectoryFactory();\n        solrCoreState = new DefaultSolrCoreState(getDirectoryFactory());\n      } else {\n        solrCoreState = updateHandler.getSolrCoreState();\n        directoryFactory = solrCoreState.getDirectoryFactory();\n        this.isReloaded = true;\n      }\n      \n      initIndex(prev != null);\n      \n      initWriters();\n      initQParsers();\n      initValueSourceParsers();\n      initTransformerFactories();\n      \n      this.searchComponents = Collections\n          .unmodifiableMap(loadSearchComponents());\n      \n      // Processors initialized before the handlers\n      updateProcessorChains = loadUpdateProcessorChains();\n      reqHandlers = new RequestHandlers(this);\n      reqHandlers.initHandlersFromConfig(solrConfig);\n      \n      // Handle things that should eventually go away\n      initDeprecatedSupport();\n      \n      // cause the executor to stall so firstSearcher events won't fire\n      // until after inform() has been called for all components.\n      // searchExecutor must be single-threaded for this to work\n      searcherExecutor.submit(new Callable() {\n        @Override\n        public Object call() throws Exception {\n          latch.await();\n          return null;\n        }\n      });\n      \n      // use the (old) writer to open the first searcher\n      RefCounted<IndexWriter> iwRef = null;\n      if (prev != null) {\n        iwRef = prev.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n        if (iwRef != null) {\n          final IndexWriter iw = iwRef.get();\n          newReaderCreator = new Callable<DirectoryReader>() {\n            @Override\n            public DirectoryReader call() throws Exception {\n              return DirectoryReader.open(iw, true);\n            }\n          };\n        }\n      }\n      \n      // Open the searcher *before* the update handler so we don't end up\n      // opening\n      // one in the middle.\n      // With lockless commits in Lucene now, this probably shouldn't be an\n      // issue anymore\n      \n      try {\n        getSearcher(false, false, null, true);\n      } finally {\n        newReaderCreator = null;\n        if (iwRef != null) iwRef.decref();\n      }\n      \n      String updateHandlerClass = solrConfig.getUpdateHandlerInfo().className;\n      \n      if (updateHandler == null) {\n        this.updateHandler = createUpdateHandler(updateHandlerClass == null ? DirectUpdateHandler2.class\n            .getName() : updateHandlerClass);\n      } else {\n        this.updateHandler = createUpdateHandler(\n            updateHandlerClass == null ? DirectUpdateHandler2.class.getName()\n                : updateHandlerClass, updateHandler);\n      }\n      infoRegistry.put(\"updateHandler\", this.updateHandler);\n      \n      // Finally tell anyone who wants to know\n      resourceLoader.inform(resourceLoader);\n      resourceLoader.inform(this); // last call before the latch is released.\n    } catch (Throwable e) {\n      latch.countDown();//release the latch, otherwise we block trying to do the close.  This should be fine, since counting down on a latch of 0 is still fine\n      //close down the searcher and any other resources, if it exists, as this is not recoverable\n      close();\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \n                              e.getMessage(), e);\n    } finally {\n      // allow firstSearcher events to fire and make sure it is released\n      latch.countDown();\n    }\n\n    infoRegistry.put(\"core\", this);\n    \n    // register any SolrInfoMBeans SolrResourceLoader initialized\n    //\n    // this must happen after the latch is released, because a JMX server impl may\n    // choose to block on registering until properties can be fetched from an MBean,\n    // and a SolrCoreAware MBean may have properties that depend on getting a Searcher\n    // from the core.\n    resourceLoader.inform(infoRegistry);\n    \n    // For debugging   \n//    numOpens.incrementAndGet();\n//    openHandles.put(this, new RuntimeException(\"unclosed core - name:\" + getName() + \" refs: \" + refCount.get()));\n  }\n\n","sourceOld":"  /**\n   * Creates a new core and register it in the list of cores.\n   * If a core with the same name already exists, it will be stopped and replaced by this one.\n   *@param dataDir the index directory\n   *@param config a solr config instance\n   *@param schema a solr schema instance\n   *\n   *@since solr 1.3\n   */\n  public SolrCore(String name, String dataDir, SolrConfig config, IndexSchema schema, CoreDescriptor cd, UpdateHandler updateHandler, SolrCore prev) {\n    coreDescriptor = cd;\n    this.setName( name );\n    resourceLoader = config.getResourceLoader();\n    if (dataDir == null){\n      if(cd.usingDefaultDataDir()) dataDir = config.getDataDir();\n      if(dataDir == null) dataDir = cd.getDataDir();\n    }\n\n    dataDir = SolrResourceLoader.normalizeDir(dataDir);\n\n    log.info(logid+\"Opening new SolrCore at \" + resourceLoader.getInstanceDir() + \", dataDir=\"+dataDir);\n\n    if (schema==null) {\n      schema = new IndexSchema(config, IndexSchema.DEFAULT_SCHEMA_FILE, null);\n    }\n\n    if (null != cd && null != cd.getCloudDescriptor()) {\n      // we are evidently running in cloud mode.  \n      //\n      // In cloud mode, version field is required for correct consistency\n      // ideally this check would be more fine grained, and individual features\n      // would assert it when they initialize, but DistribuedUpdateProcessor\n      // is currently a big ball of wax that does more then just distributing\n      // updates (ie: partial document updates), so it needs to work in no cloud\n      // mode as well, and can't assert version field support on init.\n\n      try {\n        Object ignored = VersionInfo.getAndCheckVersionField(schema);\n      } catch (SolrException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                                \"Schema will not work with SolrCloud mode: \" +\n                                e.getMessage(), e);\n      }\n    }\n\n    //Initialize JMX\n    if (config.jmxConfig.enabled) {\n      infoRegistry = new JmxMonitoredMap<String, SolrInfoMBean>(name, String.valueOf(this.hashCode()), config.jmxConfig);\n    } else  {\n      log.info(\"JMX monitoring not detected for core: \" + name);\n      infoRegistry = new ConcurrentHashMap<String, SolrInfoMBean>();\n    }\n\n    infoRegistry.put(\"fieldCache\", new SolrFieldCacheMBean());\n\n    this.schema = schema;\n    this.dataDir = dataDir;\n    this.solrConfig = config;\n    this.startTime = System.currentTimeMillis();\n    this.maxWarmingSearchers = config.maxWarmingSearchers;\n\n    booleanQueryMaxClauseCount();\n  \n    final CountDownLatch latch = new CountDownLatch(1);\n\n    try {\n      \n      initListeners();\n      \n      if (updateHandler == null) {\n        initDeletionPolicy();\n      }\n      \n      this.codec = initCodec(solrConfig, schema);\n      \n      if (updateHandler == null) {\n        initDirectoryFactory();\n        solrCoreState = new DefaultSolrCoreState(getDirectoryFactory());\n      } else {\n        solrCoreState = updateHandler.getSolrCoreState();\n        directoryFactory = solrCoreState.getDirectoryFactory();\n        this.isReloaded = true;\n      }\n      \n      initIndex(prev != null);\n      \n      initWriters();\n      initQParsers();\n      initValueSourceParsers();\n      initTransformerFactories();\n      \n      this.searchComponents = Collections\n          .unmodifiableMap(loadSearchComponents());\n      \n      // Processors initialized before the handlers\n      updateProcessorChains = loadUpdateProcessorChains();\n      reqHandlers = new RequestHandlers(this);\n      reqHandlers.initHandlersFromConfig(solrConfig);\n      \n      // Handle things that should eventually go away\n      initDeprecatedSupport();\n      \n      // cause the executor to stall so firstSearcher events won't fire\n      // until after inform() has been called for all components.\n      // searchExecutor must be single-threaded for this to work\n      searcherExecutor.submit(new Callable() {\n        public Object call() throws Exception {\n          latch.await();\n          return null;\n        }\n      });\n      \n      // use the (old) writer to open the first searcher\n      RefCounted<IndexWriter> iwRef = null;\n      if (prev != null) {\n        iwRef = prev.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n        if (iwRef != null) {\n          final IndexWriter iw = iwRef.get();\n          newReaderCreator = new Callable<DirectoryReader>() {\n            @Override\n            public DirectoryReader call() throws Exception {\n              return DirectoryReader.open(iw, true);\n            }\n          };\n        }\n      }\n      \n      // Open the searcher *before* the update handler so we don't end up\n      // opening\n      // one in the middle.\n      // With lockless commits in Lucene now, this probably shouldn't be an\n      // issue anymore\n      \n      try {\n        getSearcher(false, false, null, true);\n      } finally {\n        newReaderCreator = null;\n        if (iwRef != null) iwRef.decref();\n      }\n      \n      String updateHandlerClass = solrConfig.getUpdateHandlerInfo().className;\n      \n      if (updateHandler == null) {\n        this.updateHandler = createUpdateHandler(updateHandlerClass == null ? DirectUpdateHandler2.class\n            .getName() : updateHandlerClass);\n      } else {\n        this.updateHandler = createUpdateHandler(\n            updateHandlerClass == null ? DirectUpdateHandler2.class.getName()\n                : updateHandlerClass, updateHandler);\n      }\n      infoRegistry.put(\"updateHandler\", this.updateHandler);\n      \n      // Finally tell anyone who wants to know\n      resourceLoader.inform(resourceLoader);\n      resourceLoader.inform(this); // last call before the latch is released.\n    } catch (Throwable e) {\n      latch.countDown();//release the latch, otherwise we block trying to do the close.  This should be fine, since counting down on a latch of 0 is still fine\n      //close down the searcher and any other resources, if it exists, as this is not recoverable\n      close();\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \n                              e.getMessage(), e);\n    } finally {\n      // allow firstSearcher events to fire and make sure it is released\n      latch.countDown();\n    }\n\n    infoRegistry.put(\"core\", this);\n    \n    // register any SolrInfoMBeans SolrResourceLoader initialized\n    //\n    // this must happen after the latch is released, because a JMX server impl may\n    // choose to block on registering until properties can be fetched from an MBean,\n    // and a SolrCoreAware MBean may have properties that depend on getting a Searcher\n    // from the core.\n    resourceLoader.inform(infoRegistry);\n    \n    // For debugging   \n//    numOpens.incrementAndGet();\n//    openHandles.put(this, new RuntimeException(\"unclosed core - name:\" + getName() + \" refs: \" + refCount.get()));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a837c064b67fa63a9394136e31218b908cdcf783","date":1362186072,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/SolrCore#SolrCore(String,String,SolrConfig,IndexSchema,CoreDescriptor,UpdateHandler,SolrCore).mjava","pathOld":"solr/core/src/java/org/apache/solr/core/SolrCore#SolrCore(String,String,SolrConfig,IndexSchema,CoreDescriptor,UpdateHandler,SolrCore).mjava","sourceNew":"  /**\n   * Creates a new core and register it in the list of cores.\n   * If a core with the same name already exists, it will be stopped and replaced by this one.\n   *@param dataDir the index directory\n   *@param config a solr config instance\n   *@param schema a solr schema instance\n   *\n   *@since solr 1.3\n   */\n  public SolrCore(String name, String dataDir, SolrConfig config, IndexSchema schema, CoreDescriptor cd, UpdateHandler updateHandler, SolrCore prev) {\n    coreDescriptor = cd;\n    this.setName( name );\n    resourceLoader = config.getResourceLoader();\n    if (dataDir == null){\n      if(cd.usingDefaultDataDir()) {\n        dataDir = config.getDataDir();\n      }\n      if(dataDir == null) {\n        dataDir = cd.getDataDir();\n      }\n    }\n\n    dataDir = SolrResourceLoader.normalizeDir(dataDir);\n    log.info(logid+\"Opening new SolrCore at \" + resourceLoader.getInstanceDir() + \", dataDir=\"+dataDir);\n\n    if (schema==null) {\n      schema = new IndexSchema(config, IndexSchema.DEFAULT_SCHEMA_FILE, null);\n    }\n\n    if (null != cd && null != cd.getCloudDescriptor()) {\n      // we are evidently running in cloud mode.  \n      //\n      // In cloud mode, version field is required for correct consistency\n      // ideally this check would be more fine grained, and individual features\n      // would assert it when they initialize, but DistribuedUpdateProcessor\n      // is currently a big ball of wax that does more then just distributing\n      // updates (ie: partial document updates), so it needs to work in no cloud\n      // mode as well, and can't assert version field support on init.\n\n      try {\n        Object ignored = VersionInfo.getAndCheckVersionField(schema);\n      } catch (SolrException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                                \"Schema will not work with SolrCloud mode: \" +\n                                e.getMessage(), e);\n      }\n    }\n\n    //Initialize JMX\n    if (config.jmxConfig.enabled) {\n      infoRegistry = new JmxMonitoredMap<String, SolrInfoMBean>(name, String.valueOf(this.hashCode()), config.jmxConfig);\n    } else  {\n      log.info(\"JMX monitoring not detected for core: \" + name);\n      infoRegistry = new ConcurrentHashMap<String, SolrInfoMBean>();\n    }\n\n    infoRegistry.put(\"fieldCache\", new SolrFieldCacheMBean());\n\n    this.schema = schema;\n    this.dataDir = dataDir;\n    this.solrConfig = config;\n    this.startTime = System.currentTimeMillis();\n    this.maxWarmingSearchers = config.maxWarmingSearchers;\n\n    booleanQueryMaxClauseCount();\n  \n    final CountDownLatch latch = new CountDownLatch(1);\n\n    try {\n      \n      initListeners();\n      \n      if (updateHandler == null) {\n        initDeletionPolicy();\n      }\n      \n      this.codec = initCodec(solrConfig, schema);\n      \n      if (updateHandler == null) {\n        initDirectoryFactory();\n        solrCoreState = new DefaultSolrCoreState(getDirectoryFactory());\n      } else {\n        solrCoreState = updateHandler.getSolrCoreState();\n        directoryFactory = solrCoreState.getDirectoryFactory();\n        this.isReloaded = true;\n      }\n      \n      initIndex(prev != null);\n      \n      initWriters();\n      initQParsers();\n      initValueSourceParsers();\n      initTransformerFactories();\n      \n      this.searchComponents = Collections\n          .unmodifiableMap(loadSearchComponents());\n      \n      // Processors initialized before the handlers\n      updateProcessorChains = loadUpdateProcessorChains();\n      reqHandlers = new RequestHandlers(this);\n      reqHandlers.initHandlersFromConfig(solrConfig);\n      \n      // Handle things that should eventually go away\n      initDeprecatedSupport();\n      \n      // cause the executor to stall so firstSearcher events won't fire\n      // until after inform() has been called for all components.\n      // searchExecutor must be single-threaded for this to work\n      searcherExecutor.submit(new Callable() {\n        @Override\n        public Object call() throws Exception {\n          latch.await();\n          return null;\n        }\n      });\n      \n      // use the (old) writer to open the first searcher\n      RefCounted<IndexWriter> iwRef = null;\n      if (prev != null) {\n        iwRef = prev.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n        if (iwRef != null) {\n          final IndexWriter iw = iwRef.get();\n          newReaderCreator = new Callable<DirectoryReader>() {\n            @Override\n            public DirectoryReader call() throws Exception {\n              return DirectoryReader.open(iw, true);\n            }\n          };\n        }\n      }\n      \n      // Open the searcher *before* the update handler so we don't end up\n      // opening\n      // one in the middle.\n      // With lockless commits in Lucene now, this probably shouldn't be an\n      // issue anymore\n      \n      try {\n        getSearcher(false, false, null, true);\n      } finally {\n        newReaderCreator = null;\n        if (iwRef != null) iwRef.decref();\n      }\n      \n      String updateHandlerClass = solrConfig.getUpdateHandlerInfo().className;\n      \n      if (updateHandler == null) {\n        this.updateHandler = createUpdateHandler(updateHandlerClass == null ? DirectUpdateHandler2.class\n            .getName() : updateHandlerClass);\n      } else {\n        this.updateHandler = createUpdateHandler(\n            updateHandlerClass == null ? DirectUpdateHandler2.class.getName()\n                : updateHandlerClass, updateHandler);\n      }\n      infoRegistry.put(\"updateHandler\", this.updateHandler);\n      \n      // Finally tell anyone who wants to know\n      resourceLoader.inform(resourceLoader);\n      resourceLoader.inform(this); // last call before the latch is released.\n    } catch (Throwable e) {\n      latch.countDown();//release the latch, otherwise we block trying to do the close.  This should be fine, since counting down on a latch of 0 is still fine\n      //close down the searcher and any other resources, if it exists, as this is not recoverable\n      close();\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \n                              e.getMessage(), e);\n    } finally {\n      // allow firstSearcher events to fire and make sure it is released\n      latch.countDown();\n    }\n\n    infoRegistry.put(\"core\", this);\n    \n    // register any SolrInfoMBeans SolrResourceLoader initialized\n    //\n    // this must happen after the latch is released, because a JMX server impl may\n    // choose to block on registering until properties can be fetched from an MBean,\n    // and a SolrCoreAware MBean may have properties that depend on getting a Searcher\n    // from the core.\n    resourceLoader.inform(infoRegistry);\n    \n    // For debugging   \n//    numOpens.incrementAndGet();\n//    openHandles.put(this, new RuntimeException(\"unclosed core - name:\" + getName() + \" refs: \" + refCount.get()));\n  }\n\n","sourceOld":"  /**\n   * Creates a new core and register it in the list of cores.\n   * If a core with the same name already exists, it will be stopped and replaced by this one.\n   *@param dataDir the index directory\n   *@param config a solr config instance\n   *@param schema a solr schema instance\n   *\n   *@since solr 1.3\n   */\n  public SolrCore(String name, String dataDir, SolrConfig config, IndexSchema schema, CoreDescriptor cd, UpdateHandler updateHandler, SolrCore prev) {\n    coreDescriptor = cd;\n    this.setName( name );\n    resourceLoader = config.getResourceLoader();\n    if (dataDir == null){\n      if(cd.usingDefaultDataDir()) dataDir = config.getDataDir();\n      if(dataDir == null) dataDir = cd.getDataDir();\n    }\n\n    dataDir = SolrResourceLoader.normalizeDir(dataDir);\n\n    log.info(logid+\"Opening new SolrCore at \" + resourceLoader.getInstanceDir() + \", dataDir=\"+dataDir);\n\n    if (schema==null) {\n      schema = new IndexSchema(config, IndexSchema.DEFAULT_SCHEMA_FILE, null);\n    }\n\n    if (null != cd && null != cd.getCloudDescriptor()) {\n      // we are evidently running in cloud mode.  \n      //\n      // In cloud mode, version field is required for correct consistency\n      // ideally this check would be more fine grained, and individual features\n      // would assert it when they initialize, but DistribuedUpdateProcessor\n      // is currently a big ball of wax that does more then just distributing\n      // updates (ie: partial document updates), so it needs to work in no cloud\n      // mode as well, and can't assert version field support on init.\n\n      try {\n        Object ignored = VersionInfo.getAndCheckVersionField(schema);\n      } catch (SolrException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                                \"Schema will not work with SolrCloud mode: \" +\n                                e.getMessage(), e);\n      }\n    }\n\n    //Initialize JMX\n    if (config.jmxConfig.enabled) {\n      infoRegistry = new JmxMonitoredMap<String, SolrInfoMBean>(name, String.valueOf(this.hashCode()), config.jmxConfig);\n    } else  {\n      log.info(\"JMX monitoring not detected for core: \" + name);\n      infoRegistry = new ConcurrentHashMap<String, SolrInfoMBean>();\n    }\n\n    infoRegistry.put(\"fieldCache\", new SolrFieldCacheMBean());\n\n    this.schema = schema;\n    this.dataDir = dataDir;\n    this.solrConfig = config;\n    this.startTime = System.currentTimeMillis();\n    this.maxWarmingSearchers = config.maxWarmingSearchers;\n\n    booleanQueryMaxClauseCount();\n  \n    final CountDownLatch latch = new CountDownLatch(1);\n\n    try {\n      \n      initListeners();\n      \n      if (updateHandler == null) {\n        initDeletionPolicy();\n      }\n      \n      this.codec = initCodec(solrConfig, schema);\n      \n      if (updateHandler == null) {\n        initDirectoryFactory();\n        solrCoreState = new DefaultSolrCoreState(getDirectoryFactory());\n      } else {\n        solrCoreState = updateHandler.getSolrCoreState();\n        directoryFactory = solrCoreState.getDirectoryFactory();\n        this.isReloaded = true;\n      }\n      \n      initIndex(prev != null);\n      \n      initWriters();\n      initQParsers();\n      initValueSourceParsers();\n      initTransformerFactories();\n      \n      this.searchComponents = Collections\n          .unmodifiableMap(loadSearchComponents());\n      \n      // Processors initialized before the handlers\n      updateProcessorChains = loadUpdateProcessorChains();\n      reqHandlers = new RequestHandlers(this);\n      reqHandlers.initHandlersFromConfig(solrConfig);\n      \n      // Handle things that should eventually go away\n      initDeprecatedSupport();\n      \n      // cause the executor to stall so firstSearcher events won't fire\n      // until after inform() has been called for all components.\n      // searchExecutor must be single-threaded for this to work\n      searcherExecutor.submit(new Callable() {\n        @Override\n        public Object call() throws Exception {\n          latch.await();\n          return null;\n        }\n      });\n      \n      // use the (old) writer to open the first searcher\n      RefCounted<IndexWriter> iwRef = null;\n      if (prev != null) {\n        iwRef = prev.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n        if (iwRef != null) {\n          final IndexWriter iw = iwRef.get();\n          newReaderCreator = new Callable<DirectoryReader>() {\n            @Override\n            public DirectoryReader call() throws Exception {\n              return DirectoryReader.open(iw, true);\n            }\n          };\n        }\n      }\n      \n      // Open the searcher *before* the update handler so we don't end up\n      // opening\n      // one in the middle.\n      // With lockless commits in Lucene now, this probably shouldn't be an\n      // issue anymore\n      \n      try {\n        getSearcher(false, false, null, true);\n      } finally {\n        newReaderCreator = null;\n        if (iwRef != null) iwRef.decref();\n      }\n      \n      String updateHandlerClass = solrConfig.getUpdateHandlerInfo().className;\n      \n      if (updateHandler == null) {\n        this.updateHandler = createUpdateHandler(updateHandlerClass == null ? DirectUpdateHandler2.class\n            .getName() : updateHandlerClass);\n      } else {\n        this.updateHandler = createUpdateHandler(\n            updateHandlerClass == null ? DirectUpdateHandler2.class.getName()\n                : updateHandlerClass, updateHandler);\n      }\n      infoRegistry.put(\"updateHandler\", this.updateHandler);\n      \n      // Finally tell anyone who wants to know\n      resourceLoader.inform(resourceLoader);\n      resourceLoader.inform(this); // last call before the latch is released.\n    } catch (Throwable e) {\n      latch.countDown();//release the latch, otherwise we block trying to do the close.  This should be fine, since counting down on a latch of 0 is still fine\n      //close down the searcher and any other resources, if it exists, as this is not recoverable\n      close();\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \n                              e.getMessage(), e);\n    } finally {\n      // allow firstSearcher events to fire and make sure it is released\n      latch.countDown();\n    }\n\n    infoRegistry.put(\"core\", this);\n    \n    // register any SolrInfoMBeans SolrResourceLoader initialized\n    //\n    // this must happen after the latch is released, because a JMX server impl may\n    // choose to block on registering until properties can be fetched from an MBean,\n    // and a SolrCoreAware MBean may have properties that depend on getting a Searcher\n    // from the core.\n    resourceLoader.inform(infoRegistry);\n    \n    // For debugging   \n//    numOpens.incrementAndGet();\n//    openHandles.put(this, new RuntimeException(\"unclosed core - name:\" + getName() + \" refs: \" + refCount.get()));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"948cb7389da6d4f397f5a0f89caf885a9033c959","date":1362946471,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/SolrCore#SolrCore(String,String,SolrConfig,IndexSchema,CoreDescriptor,UpdateHandler,SolrCore).mjava","pathOld":"solr/core/src/java/org/apache/solr/core/SolrCore#SolrCore(String,String,SolrConfig,IndexSchema,CoreDescriptor,UpdateHandler,SolrCore).mjava","sourceNew":"  /**\n   * Creates a new core and register it in the list of cores.\n   * If a core with the same name already exists, it will be stopped and replaced by this one.\n   *@param dataDir the index directory\n   *@param config a solr config instance\n   *@param schema a solr schema instance\n   *\n   *@since solr 1.3\n   */\n  public SolrCore(String name, String dataDir, SolrConfig config, IndexSchema schema, CoreDescriptor cd, UpdateHandler updateHandler, SolrCore prev) {\n    coreDescriptor = cd;\n    this.setName( name );\n    resourceLoader = config.getResourceLoader();\n    this.solrConfig = config;\n    \n    if (updateHandler == null) {\n      initDirectoryFactory();\n    }\n    \n    if (dataDir == null) {\n      if (cd.usingDefaultDataDir()) dataDir = config.getDataDir();\n      if (dataDir == null) {\n        dataDir = cd.getDataDir();\n        try {\n          if (!directoryFactory.isAbsolute(dataDir)) {\n            dataDir = directoryFactory.normalize(SolrResourceLoader\n                .normalizeDir(cd.getInstanceDir()) + dataDir);\n          }\n        } catch (IOException e) {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, e);\n        }\n      }\n    }\n\n    dataDir = SolrResourceLoader.normalizeDir(dataDir);\n    log.info(logid+\"Opening new SolrCore at \" + resourceLoader.getInstanceDir() + \", dataDir=\"+dataDir);\n\n    if (schema==null) {\n      schema = new IndexSchema(config, IndexSchema.DEFAULT_SCHEMA_FILE, null);\n    }\n\n    if (null != cd && null != cd.getCloudDescriptor()) {\n      // we are evidently running in cloud mode.  \n      //\n      // In cloud mode, version field is required for correct consistency\n      // ideally this check would be more fine grained, and individual features\n      // would assert it when they initialize, but DistribuedUpdateProcessor\n      // is currently a big ball of wax that does more then just distributing\n      // updates (ie: partial document updates), so it needs to work in no cloud\n      // mode as well, and can't assert version field support on init.\n\n      try {\n        Object ignored = VersionInfo.getAndCheckVersionField(schema);\n      } catch (SolrException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                                \"Schema will not work with SolrCloud mode: \" +\n                                e.getMessage(), e);\n      }\n    }\n\n    //Initialize JMX\n    if (config.jmxConfig.enabled) {\n      infoRegistry = new JmxMonitoredMap<String, SolrInfoMBean>(name, String.valueOf(this.hashCode()), config.jmxConfig);\n    } else  {\n      log.info(\"JMX monitoring not detected for core: \" + name);\n      infoRegistry = new ConcurrentHashMap<String, SolrInfoMBean>();\n    }\n\n    infoRegistry.put(\"fieldCache\", new SolrFieldCacheMBean());\n\n    this.schema = schema;\n    this.dataDir = dataDir;\n    this.startTime = System.currentTimeMillis();\n    this.maxWarmingSearchers = config.maxWarmingSearchers;\n\n    booleanQueryMaxClauseCount();\n  \n    final CountDownLatch latch = new CountDownLatch(1);\n\n    try {\n      \n      initListeners();\n      \n      if (updateHandler == null) {\n        initDeletionPolicy();\n      }\n      \n      this.codec = initCodec(solrConfig, schema);\n      \n      if (updateHandler == null) {\n        initDirectoryFactory();\n        solrCoreState = new DefaultSolrCoreState(getDirectoryFactory());\n      } else {\n        solrCoreState = updateHandler.getSolrCoreState();\n        directoryFactory = solrCoreState.getDirectoryFactory();\n        this.isReloaded = true;\n      }\n      \n      initIndex(prev != null);\n      \n      initWriters();\n      initQParsers();\n      initValueSourceParsers();\n      initTransformerFactories();\n      \n      this.searchComponents = Collections\n          .unmodifiableMap(loadSearchComponents());\n      \n      // Processors initialized before the handlers\n      updateProcessorChains = loadUpdateProcessorChains();\n      reqHandlers = new RequestHandlers(this);\n      reqHandlers.initHandlersFromConfig(solrConfig);\n      \n      // Handle things that should eventually go away\n      initDeprecatedSupport();\n      \n      // cause the executor to stall so firstSearcher events won't fire\n      // until after inform() has been called for all components.\n      // searchExecutor must be single-threaded for this to work\n      searcherExecutor.submit(new Callable() {\n        @Override\n        public Object call() throws Exception {\n          latch.await();\n          return null;\n        }\n      });\n      \n      // use the (old) writer to open the first searcher\n      RefCounted<IndexWriter> iwRef = null;\n      if (prev != null) {\n        iwRef = prev.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n        if (iwRef != null) {\n          final IndexWriter iw = iwRef.get();\n          newReaderCreator = new Callable<DirectoryReader>() {\n            @Override\n            public DirectoryReader call() throws Exception {\n              return DirectoryReader.open(iw, true);\n            }\n          };\n        }\n      }\n      \n      // Open the searcher *before* the update handler so we don't end up\n      // opening\n      // one in the middle.\n      // With lockless commits in Lucene now, this probably shouldn't be an\n      // issue anymore\n      \n      try {\n        getSearcher(false, false, null, true);\n      } finally {\n        newReaderCreator = null;\n        if (iwRef != null) iwRef.decref();\n      }\n      \n      String updateHandlerClass = solrConfig.getUpdateHandlerInfo().className;\n      \n      if (updateHandler == null) {\n        this.updateHandler = createUpdateHandler(updateHandlerClass == null ? DirectUpdateHandler2.class\n            .getName() : updateHandlerClass);\n      } else {\n        this.updateHandler = createUpdateHandler(\n            updateHandlerClass == null ? DirectUpdateHandler2.class.getName()\n                : updateHandlerClass, updateHandler);\n      }\n      infoRegistry.put(\"updateHandler\", this.updateHandler);\n      \n      // Finally tell anyone who wants to know\n      resourceLoader.inform(resourceLoader);\n      resourceLoader.inform(this); // last call before the latch is released.\n    } catch (Throwable e) {\n      latch.countDown();//release the latch, otherwise we block trying to do the close.  This should be fine, since counting down on a latch of 0 is still fine\n      //close down the searcher and any other resources, if it exists, as this is not recoverable\n      close();\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \n                              e.getMessage(), e);\n    } finally {\n      // allow firstSearcher events to fire and make sure it is released\n      latch.countDown();\n    }\n\n    infoRegistry.put(\"core\", this);\n    \n    // register any SolrInfoMBeans SolrResourceLoader initialized\n    //\n    // this must happen after the latch is released, because a JMX server impl may\n    // choose to block on registering until properties can be fetched from an MBean,\n    // and a SolrCoreAware MBean may have properties that depend on getting a Searcher\n    // from the core.\n    resourceLoader.inform(infoRegistry);\n    \n    // For debugging   \n//    numOpens.incrementAndGet();\n//    openHandles.put(this, new RuntimeException(\"unclosed core - name:\" + getName() + \" refs: \" + refCount.get()));\n  }\n\n","sourceOld":"  /**\n   * Creates a new core and register it in the list of cores.\n   * If a core with the same name already exists, it will be stopped and replaced by this one.\n   *@param dataDir the index directory\n   *@param config a solr config instance\n   *@param schema a solr schema instance\n   *\n   *@since solr 1.3\n   */\n  public SolrCore(String name, String dataDir, SolrConfig config, IndexSchema schema, CoreDescriptor cd, UpdateHandler updateHandler, SolrCore prev) {\n    coreDescriptor = cd;\n    this.setName( name );\n    resourceLoader = config.getResourceLoader();\n    if (dataDir == null){\n      if(cd.usingDefaultDataDir()) {\n        dataDir = config.getDataDir();\n      }\n      if(dataDir == null) {\n        dataDir = cd.getDataDir();\n      }\n    }\n\n    dataDir = SolrResourceLoader.normalizeDir(dataDir);\n    log.info(logid+\"Opening new SolrCore at \" + resourceLoader.getInstanceDir() + \", dataDir=\"+dataDir);\n\n    if (schema==null) {\n      schema = new IndexSchema(config, IndexSchema.DEFAULT_SCHEMA_FILE, null);\n    }\n\n    if (null != cd && null != cd.getCloudDescriptor()) {\n      // we are evidently running in cloud mode.  \n      //\n      // In cloud mode, version field is required for correct consistency\n      // ideally this check would be more fine grained, and individual features\n      // would assert it when they initialize, but DistribuedUpdateProcessor\n      // is currently a big ball of wax that does more then just distributing\n      // updates (ie: partial document updates), so it needs to work in no cloud\n      // mode as well, and can't assert version field support on init.\n\n      try {\n        Object ignored = VersionInfo.getAndCheckVersionField(schema);\n      } catch (SolrException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                                \"Schema will not work with SolrCloud mode: \" +\n                                e.getMessage(), e);\n      }\n    }\n\n    //Initialize JMX\n    if (config.jmxConfig.enabled) {\n      infoRegistry = new JmxMonitoredMap<String, SolrInfoMBean>(name, String.valueOf(this.hashCode()), config.jmxConfig);\n    } else  {\n      log.info(\"JMX monitoring not detected for core: \" + name);\n      infoRegistry = new ConcurrentHashMap<String, SolrInfoMBean>();\n    }\n\n    infoRegistry.put(\"fieldCache\", new SolrFieldCacheMBean());\n\n    this.schema = schema;\n    this.dataDir = dataDir;\n    this.solrConfig = config;\n    this.startTime = System.currentTimeMillis();\n    this.maxWarmingSearchers = config.maxWarmingSearchers;\n\n    booleanQueryMaxClauseCount();\n  \n    final CountDownLatch latch = new CountDownLatch(1);\n\n    try {\n      \n      initListeners();\n      \n      if (updateHandler == null) {\n        initDeletionPolicy();\n      }\n      \n      this.codec = initCodec(solrConfig, schema);\n      \n      if (updateHandler == null) {\n        initDirectoryFactory();\n        solrCoreState = new DefaultSolrCoreState(getDirectoryFactory());\n      } else {\n        solrCoreState = updateHandler.getSolrCoreState();\n        directoryFactory = solrCoreState.getDirectoryFactory();\n        this.isReloaded = true;\n      }\n      \n      initIndex(prev != null);\n      \n      initWriters();\n      initQParsers();\n      initValueSourceParsers();\n      initTransformerFactories();\n      \n      this.searchComponents = Collections\n          .unmodifiableMap(loadSearchComponents());\n      \n      // Processors initialized before the handlers\n      updateProcessorChains = loadUpdateProcessorChains();\n      reqHandlers = new RequestHandlers(this);\n      reqHandlers.initHandlersFromConfig(solrConfig);\n      \n      // Handle things that should eventually go away\n      initDeprecatedSupport();\n      \n      // cause the executor to stall so firstSearcher events won't fire\n      // until after inform() has been called for all components.\n      // searchExecutor must be single-threaded for this to work\n      searcherExecutor.submit(new Callable() {\n        @Override\n        public Object call() throws Exception {\n          latch.await();\n          return null;\n        }\n      });\n      \n      // use the (old) writer to open the first searcher\n      RefCounted<IndexWriter> iwRef = null;\n      if (prev != null) {\n        iwRef = prev.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n        if (iwRef != null) {\n          final IndexWriter iw = iwRef.get();\n          newReaderCreator = new Callable<DirectoryReader>() {\n            @Override\n            public DirectoryReader call() throws Exception {\n              return DirectoryReader.open(iw, true);\n            }\n          };\n        }\n      }\n      \n      // Open the searcher *before* the update handler so we don't end up\n      // opening\n      // one in the middle.\n      // With lockless commits in Lucene now, this probably shouldn't be an\n      // issue anymore\n      \n      try {\n        getSearcher(false, false, null, true);\n      } finally {\n        newReaderCreator = null;\n        if (iwRef != null) iwRef.decref();\n      }\n      \n      String updateHandlerClass = solrConfig.getUpdateHandlerInfo().className;\n      \n      if (updateHandler == null) {\n        this.updateHandler = createUpdateHandler(updateHandlerClass == null ? DirectUpdateHandler2.class\n            .getName() : updateHandlerClass);\n      } else {\n        this.updateHandler = createUpdateHandler(\n            updateHandlerClass == null ? DirectUpdateHandler2.class.getName()\n                : updateHandlerClass, updateHandler);\n      }\n      infoRegistry.put(\"updateHandler\", this.updateHandler);\n      \n      // Finally tell anyone who wants to know\n      resourceLoader.inform(resourceLoader);\n      resourceLoader.inform(this); // last call before the latch is released.\n    } catch (Throwable e) {\n      latch.countDown();//release the latch, otherwise we block trying to do the close.  This should be fine, since counting down on a latch of 0 is still fine\n      //close down the searcher and any other resources, if it exists, as this is not recoverable\n      close();\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \n                              e.getMessage(), e);\n    } finally {\n      // allow firstSearcher events to fire and make sure it is released\n      latch.countDown();\n    }\n\n    infoRegistry.put(\"core\", this);\n    \n    // register any SolrInfoMBeans SolrResourceLoader initialized\n    //\n    // this must happen after the latch is released, because a JMX server impl may\n    // choose to block on registering until properties can be fetched from an MBean,\n    // and a SolrCoreAware MBean may have properties that depend on getting a Searcher\n    // from the core.\n    resourceLoader.inform(infoRegistry);\n    \n    // For debugging   \n//    numOpens.incrementAndGet();\n//    openHandles.put(this, new RuntimeException(\"unclosed core - name:\" + getName() + \" refs: \" + refCount.get()));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"ab128867904d724d03b93aa2b8048f5ae1649c39","date":1363582188,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/SolrCore#SolrCore(String,String,SolrConfig,IndexSchema,CoreDescriptor,UpdateHandler,SolrCore).mjava","pathOld":"solr/core/src/java/org/apache/solr/core/SolrCore#SolrCore(String,String,SolrConfig,IndexSchema,CoreDescriptor,UpdateHandler,SolrCore).mjava","sourceNew":"  /**\n   * Creates a new core and register it in the list of cores.\n   * If a core with the same name already exists, it will be stopped and replaced by this one.\n   *@param dataDir the index directory\n   *@param config a solr config instance\n   *@param schema a solr schema instance\n   *\n   *@since solr 1.3\n   */\n  public SolrCore(String name, String dataDir, SolrConfig config, IndexSchema schema, CoreDescriptor cd, UpdateHandler updateHandler, SolrCore prev) {\n    coreDescriptor = cd;\n    this.setName( name );\n    resourceLoader = config.getResourceLoader();\n    this.solrConfig = config;\n    \n    if (updateHandler == null) {\n      initDirectoryFactory();\n    }\n    \n    if (dataDir == null) {\n      if (cd.usingDefaultDataDir()) dataDir = config.getDataDir();\n      if (dataDir == null) {\n        dataDir = cd.getDataDir();\n        try {\n          if (!directoryFactory.isAbsolute(dataDir)) {\n            dataDir = directoryFactory.normalize(SolrResourceLoader\n                .normalizeDir(cd.getInstanceDir()) + dataDir);\n          }\n        } catch (IOException e) {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, e);\n        }\n      }\n    }\n\n    dataDir = SolrResourceLoader.normalizeDir(dataDir);\n    log.info(logid+\"Opening new SolrCore at \" + resourceLoader.getInstanceDir() + \", dataDir=\"+dataDir);\n\n    if (schema==null) {\n      schema = new IndexSchema(config, IndexSchema.DEFAULT_SCHEMA_FILE, null);\n    }\n\n    if (null != cd && null != cd.getCloudDescriptor()) {\n      // we are evidently running in cloud mode.  \n      //\n      // In cloud mode, version field is required for correct consistency\n      // ideally this check would be more fine grained, and individual features\n      // would assert it when they initialize, but DistribuedUpdateProcessor\n      // is currently a big ball of wax that does more then just distributing\n      // updates (ie: partial document updates), so it needs to work in no cloud\n      // mode as well, and can't assert version field support on init.\n\n      try {\n        Object ignored = VersionInfo.getAndCheckVersionField(schema);\n      } catch (SolrException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                                \"Schema will not work with SolrCloud mode: \" +\n                                e.getMessage(), e);\n      }\n    }\n\n    //Initialize JMX\n    if (config.jmxConfig.enabled) {\n      infoRegistry = new JmxMonitoredMap<String, SolrInfoMBean>(name, String.valueOf(this.hashCode()), config.jmxConfig);\n    } else  {\n      log.info(\"JMX monitoring not detected for core: \" + name);\n      infoRegistry = new ConcurrentHashMap<String, SolrInfoMBean>();\n    }\n\n    infoRegistry.put(\"fieldCache\", new SolrFieldCacheMBean());\n\n    this.schema = schema;\n    this.dataDir = dataDir;\n    this.startTime = System.currentTimeMillis();\n    this.maxWarmingSearchers = config.maxWarmingSearchers;\n\n    booleanQueryMaxClauseCount();\n  \n    final CountDownLatch latch = new CountDownLatch(1);\n\n    try {\n      \n      initListeners();\n      \n      if (updateHandler == null) {\n        initDeletionPolicy();\n      }\n      \n      this.codec = initCodec(solrConfig, schema);\n      \n      if (updateHandler == null) {\n        initDirectoryFactory();\n        solrCoreState = new DefaultSolrCoreState(getDirectoryFactory());\n      } else {\n        solrCoreState = updateHandler.getSolrCoreState();\n        directoryFactory = solrCoreState.getDirectoryFactory();\n        this.isReloaded = true;\n      }\n      \n      initIndex(prev != null);\n      \n      initWriters();\n      initQParsers();\n      initValueSourceParsers();\n      initTransformerFactories();\n      \n      this.searchComponents = Collections\n          .unmodifiableMap(loadSearchComponents());\n      \n      // Processors initialized before the handlers\n      updateProcessorChains = loadUpdateProcessorChains();\n      reqHandlers = new RequestHandlers(this);\n      reqHandlers.initHandlersFromConfig(solrConfig);\n      \n      // Handle things that should eventually go away\n      initDeprecatedSupport();\n      \n      // cause the executor to stall so firstSearcher events won't fire\n      // until after inform() has been called for all components.\n      // searchExecutor must be single-threaded for this to work\n      searcherExecutor.submit(new Callable() {\n        @Override\n        public Object call() throws Exception {\n          latch.await();\n          return null;\n        }\n      });\n      \n      // use the (old) writer to open the first searcher\n      RefCounted<IndexWriter> iwRef = null;\n      if (prev != null) {\n        iwRef = prev.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n        if (iwRef != null) {\n          final IndexWriter iw = iwRef.get();\n          newReaderCreator = new Callable<DirectoryReader>() {\n            @Override\n            public DirectoryReader call() throws Exception {\n              return DirectoryReader.open(iw, true);\n            }\n          };\n        }\n      }\n      \n      // Open the searcher *before* the update handler so we don't end up\n      // opening\n      // one in the middle.\n      // With lockless commits in Lucene now, this probably shouldn't be an\n      // issue anymore\n      \n      try {\n        getSearcher(false, false, null, true);\n      } finally {\n        newReaderCreator = null;\n        if (iwRef != null) iwRef.decref();\n      }\n      \n      String updateHandlerClass = solrConfig.getUpdateHandlerInfo().className;\n      \n      if (updateHandler == null) {\n        this.updateHandler = createUpdateHandler(updateHandlerClass == null ? DirectUpdateHandler2.class\n            .getName() : updateHandlerClass);\n      } else {\n        this.updateHandler = updateHandler;\n      }\n      infoRegistry.put(\"updateHandler\", this.updateHandler);\n      \n      // Finally tell anyone who wants to know\n      resourceLoader.inform(resourceLoader);\n      resourceLoader.inform(this); // last call before the latch is released.\n    } catch (Throwable e) {\n      latch.countDown();//release the latch, otherwise we block trying to do the close.  This should be fine, since counting down on a latch of 0 is still fine\n      //close down the searcher and any other resources, if it exists, as this is not recoverable\n      close();\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \n                              e.getMessage(), e);\n    } finally {\n      // allow firstSearcher events to fire and make sure it is released\n      latch.countDown();\n    }\n\n    infoRegistry.put(\"core\", this);\n    \n    // register any SolrInfoMBeans SolrResourceLoader initialized\n    //\n    // this must happen after the latch is released, because a JMX server impl may\n    // choose to block on registering until properties can be fetched from an MBean,\n    // and a SolrCoreAware MBean may have properties that depend on getting a Searcher\n    // from the core.\n    resourceLoader.inform(infoRegistry);\n    \n    // For debugging   \n//    numOpens.incrementAndGet();\n//    openHandles.put(this, new RuntimeException(\"unclosed core - name:\" + getName() + \" refs: \" + refCount.get()));\n  }\n\n","sourceOld":"  /**\n   * Creates a new core and register it in the list of cores.\n   * If a core with the same name already exists, it will be stopped and replaced by this one.\n   *@param dataDir the index directory\n   *@param config a solr config instance\n   *@param schema a solr schema instance\n   *\n   *@since solr 1.3\n   */\n  public SolrCore(String name, String dataDir, SolrConfig config, IndexSchema schema, CoreDescriptor cd, UpdateHandler updateHandler, SolrCore prev) {\n    coreDescriptor = cd;\n    this.setName( name );\n    resourceLoader = config.getResourceLoader();\n    this.solrConfig = config;\n    \n    if (updateHandler == null) {\n      initDirectoryFactory();\n    }\n    \n    if (dataDir == null) {\n      if (cd.usingDefaultDataDir()) dataDir = config.getDataDir();\n      if (dataDir == null) {\n        dataDir = cd.getDataDir();\n        try {\n          if (!directoryFactory.isAbsolute(dataDir)) {\n            dataDir = directoryFactory.normalize(SolrResourceLoader\n                .normalizeDir(cd.getInstanceDir()) + dataDir);\n          }\n        } catch (IOException e) {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, e);\n        }\n      }\n    }\n\n    dataDir = SolrResourceLoader.normalizeDir(dataDir);\n    log.info(logid+\"Opening new SolrCore at \" + resourceLoader.getInstanceDir() + \", dataDir=\"+dataDir);\n\n    if (schema==null) {\n      schema = new IndexSchema(config, IndexSchema.DEFAULT_SCHEMA_FILE, null);\n    }\n\n    if (null != cd && null != cd.getCloudDescriptor()) {\n      // we are evidently running in cloud mode.  \n      //\n      // In cloud mode, version field is required for correct consistency\n      // ideally this check would be more fine grained, and individual features\n      // would assert it when they initialize, but DistribuedUpdateProcessor\n      // is currently a big ball of wax that does more then just distributing\n      // updates (ie: partial document updates), so it needs to work in no cloud\n      // mode as well, and can't assert version field support on init.\n\n      try {\n        Object ignored = VersionInfo.getAndCheckVersionField(schema);\n      } catch (SolrException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                                \"Schema will not work with SolrCloud mode: \" +\n                                e.getMessage(), e);\n      }\n    }\n\n    //Initialize JMX\n    if (config.jmxConfig.enabled) {\n      infoRegistry = new JmxMonitoredMap<String, SolrInfoMBean>(name, String.valueOf(this.hashCode()), config.jmxConfig);\n    } else  {\n      log.info(\"JMX monitoring not detected for core: \" + name);\n      infoRegistry = new ConcurrentHashMap<String, SolrInfoMBean>();\n    }\n\n    infoRegistry.put(\"fieldCache\", new SolrFieldCacheMBean());\n\n    this.schema = schema;\n    this.dataDir = dataDir;\n    this.startTime = System.currentTimeMillis();\n    this.maxWarmingSearchers = config.maxWarmingSearchers;\n\n    booleanQueryMaxClauseCount();\n  \n    final CountDownLatch latch = new CountDownLatch(1);\n\n    try {\n      \n      initListeners();\n      \n      if (updateHandler == null) {\n        initDeletionPolicy();\n      }\n      \n      this.codec = initCodec(solrConfig, schema);\n      \n      if (updateHandler == null) {\n        initDirectoryFactory();\n        solrCoreState = new DefaultSolrCoreState(getDirectoryFactory());\n      } else {\n        solrCoreState = updateHandler.getSolrCoreState();\n        directoryFactory = solrCoreState.getDirectoryFactory();\n        this.isReloaded = true;\n      }\n      \n      initIndex(prev != null);\n      \n      initWriters();\n      initQParsers();\n      initValueSourceParsers();\n      initTransformerFactories();\n      \n      this.searchComponents = Collections\n          .unmodifiableMap(loadSearchComponents());\n      \n      // Processors initialized before the handlers\n      updateProcessorChains = loadUpdateProcessorChains();\n      reqHandlers = new RequestHandlers(this);\n      reqHandlers.initHandlersFromConfig(solrConfig);\n      \n      // Handle things that should eventually go away\n      initDeprecatedSupport();\n      \n      // cause the executor to stall so firstSearcher events won't fire\n      // until after inform() has been called for all components.\n      // searchExecutor must be single-threaded for this to work\n      searcherExecutor.submit(new Callable() {\n        @Override\n        public Object call() throws Exception {\n          latch.await();\n          return null;\n        }\n      });\n      \n      // use the (old) writer to open the first searcher\n      RefCounted<IndexWriter> iwRef = null;\n      if (prev != null) {\n        iwRef = prev.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n        if (iwRef != null) {\n          final IndexWriter iw = iwRef.get();\n          newReaderCreator = new Callable<DirectoryReader>() {\n            @Override\n            public DirectoryReader call() throws Exception {\n              return DirectoryReader.open(iw, true);\n            }\n          };\n        }\n      }\n      \n      // Open the searcher *before* the update handler so we don't end up\n      // opening\n      // one in the middle.\n      // With lockless commits in Lucene now, this probably shouldn't be an\n      // issue anymore\n      \n      try {\n        getSearcher(false, false, null, true);\n      } finally {\n        newReaderCreator = null;\n        if (iwRef != null) iwRef.decref();\n      }\n      \n      String updateHandlerClass = solrConfig.getUpdateHandlerInfo().className;\n      \n      if (updateHandler == null) {\n        this.updateHandler = createUpdateHandler(updateHandlerClass == null ? DirectUpdateHandler2.class\n            .getName() : updateHandlerClass);\n      } else {\n        this.updateHandler = createUpdateHandler(\n            updateHandlerClass == null ? DirectUpdateHandler2.class.getName()\n                : updateHandlerClass, updateHandler);\n      }\n      infoRegistry.put(\"updateHandler\", this.updateHandler);\n      \n      // Finally tell anyone who wants to know\n      resourceLoader.inform(resourceLoader);\n      resourceLoader.inform(this); // last call before the latch is released.\n    } catch (Throwable e) {\n      latch.countDown();//release the latch, otherwise we block trying to do the close.  This should be fine, since counting down on a latch of 0 is still fine\n      //close down the searcher and any other resources, if it exists, as this is not recoverable\n      close();\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \n                              e.getMessage(), e);\n    } finally {\n      // allow firstSearcher events to fire and make sure it is released\n      latch.countDown();\n    }\n\n    infoRegistry.put(\"core\", this);\n    \n    // register any SolrInfoMBeans SolrResourceLoader initialized\n    //\n    // this must happen after the latch is released, because a JMX server impl may\n    // choose to block on registering until properties can be fetched from an MBean,\n    // and a SolrCoreAware MBean may have properties that depend on getting a Searcher\n    // from the core.\n    resourceLoader.inform(infoRegistry);\n    \n    // For debugging   \n//    numOpens.incrementAndGet();\n//    openHandles.put(this, new RuntimeException(\"unclosed core - name:\" + getName() + \" refs: \" + refCount.get()));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"28d656aaac42f919a3a7e8a859407018d75fed41","date":1363584435,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/SolrCore#SolrCore(String,String,SolrConfig,IndexSchema,CoreDescriptor,UpdateHandler,SolrCore).mjava","pathOld":"solr/core/src/java/org/apache/solr/core/SolrCore#SolrCore(String,String,SolrConfig,IndexSchema,CoreDescriptor,UpdateHandler,SolrCore).mjava","sourceNew":"  /**\n   * Creates a new core and register it in the list of cores.\n   * If a core with the same name already exists, it will be stopped and replaced by this one.\n   *@param dataDir the index directory\n   *@param config a solr config instance\n   *@param schema a solr schema instance\n   *\n   *@since solr 1.3\n   */\n  public SolrCore(String name, String dataDir, SolrConfig config, IndexSchema schema, CoreDescriptor cd, UpdateHandler updateHandler, SolrCore prev) {\n    coreDescriptor = cd;\n    this.setName( name );\n    resourceLoader = config.getResourceLoader();\n    this.solrConfig = config;\n    \n    if (updateHandler == null) {\n      initDirectoryFactory();\n    }\n    \n    if (dataDir == null) {\n      if (cd.usingDefaultDataDir()) dataDir = config.getDataDir();\n      if (dataDir == null) {\n        dataDir = cd.getDataDir();\n        try {\n          if (!directoryFactory.isAbsolute(dataDir)) {\n            dataDir = directoryFactory.normalize(SolrResourceLoader\n                .normalizeDir(cd.getInstanceDir()) + dataDir);\n          }\n        } catch (IOException e) {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, e);\n        }\n      }\n    }\n\n    dataDir = SolrResourceLoader.normalizeDir(dataDir);\n    log.info(logid+\"Opening new SolrCore at \" + resourceLoader.getInstanceDir() + \", dataDir=\"+dataDir);\n\n    if (schema==null) {\n      schema = new IndexSchema(config, IndexSchema.DEFAULT_SCHEMA_FILE, null);\n    }\n\n    if (null != cd && null != cd.getCloudDescriptor()) {\n      // we are evidently running in cloud mode.  \n      //\n      // In cloud mode, version field is required for correct consistency\n      // ideally this check would be more fine grained, and individual features\n      // would assert it when they initialize, but DistribuedUpdateProcessor\n      // is currently a big ball of wax that does more then just distributing\n      // updates (ie: partial document updates), so it needs to work in no cloud\n      // mode as well, and can't assert version field support on init.\n\n      try {\n        Object ignored = VersionInfo.getAndCheckVersionField(schema);\n      } catch (SolrException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                                \"Schema will not work with SolrCloud mode: \" +\n                                e.getMessage(), e);\n      }\n    }\n\n    //Initialize JMX\n    if (config.jmxConfig.enabled) {\n      infoRegistry = new JmxMonitoredMap<String, SolrInfoMBean>(name, String.valueOf(this.hashCode()), config.jmxConfig);\n    } else  {\n      log.info(\"JMX monitoring not detected for core: \" + name);\n      infoRegistry = new ConcurrentHashMap<String, SolrInfoMBean>();\n    }\n\n    infoRegistry.put(\"fieldCache\", new SolrFieldCacheMBean());\n\n    this.schema = schema;\n    this.dataDir = dataDir;\n    this.startTime = System.currentTimeMillis();\n    this.maxWarmingSearchers = config.maxWarmingSearchers;\n\n    booleanQueryMaxClauseCount();\n  \n    final CountDownLatch latch = new CountDownLatch(1);\n\n    try {\n      \n      initListeners();\n      \n      if (updateHandler == null) {\n        initDeletionPolicy();\n      }\n      \n      this.codec = initCodec(solrConfig, schema);\n      \n      if (updateHandler == null) {\n        initDirectoryFactory();\n        solrCoreState = new DefaultSolrCoreState(getDirectoryFactory());\n      } else {\n        solrCoreState = updateHandler.getSolrCoreState();\n        directoryFactory = solrCoreState.getDirectoryFactory();\n        this.isReloaded = true;\n      }\n      \n      initIndex(prev != null);\n      \n      initWriters();\n      initQParsers();\n      initValueSourceParsers();\n      initTransformerFactories();\n      \n      this.searchComponents = Collections\n          .unmodifiableMap(loadSearchComponents());\n      \n      // Processors initialized before the handlers\n      updateProcessorChains = loadUpdateProcessorChains();\n      reqHandlers = new RequestHandlers(this);\n      reqHandlers.initHandlersFromConfig(solrConfig);\n      \n      // Handle things that should eventually go away\n      initDeprecatedSupport();\n      \n      // cause the executor to stall so firstSearcher events won't fire\n      // until after inform() has been called for all components.\n      // searchExecutor must be single-threaded for this to work\n      searcherExecutor.submit(new Callable() {\n        @Override\n        public Object call() throws Exception {\n          latch.await();\n          return null;\n        }\n      });\n      \n      // use the (old) writer to open the first searcher\n      RefCounted<IndexWriter> iwRef = null;\n      if (prev != null) {\n        iwRef = prev.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n        if (iwRef != null) {\n          final IndexWriter iw = iwRef.get();\n          newReaderCreator = new Callable<DirectoryReader>() {\n            @Override\n            public DirectoryReader call() throws Exception {\n              return DirectoryReader.open(iw, true);\n            }\n          };\n        }\n      }\n      \n      // Open the searcher *before* the update handler so we don't end up\n      // opening\n      // one in the middle.\n      // With lockless commits in Lucene now, this probably shouldn't be an\n      // issue anymore\n      \n      try {\n        getSearcher(false, false, null, true);\n      } finally {\n        newReaderCreator = null;\n        if (iwRef != null) iwRef.decref();\n      }\n      \n      String updateHandlerClass = solrConfig.getUpdateHandlerInfo().className;\n      \n      if (updateHandler == null) {\n        this.updateHandler = createUpdateHandler(updateHandlerClass == null ? DirectUpdateHandler2.class\n            .getName() : updateHandlerClass);\n      } else {\n        this.updateHandler = createUpdateHandler(\n            updateHandlerClass == null ? DirectUpdateHandler2.class.getName()\n                : updateHandlerClass, updateHandler);\n      }\n      infoRegistry.put(\"updateHandler\", this.updateHandler);\n      \n      // Finally tell anyone who wants to know\n      resourceLoader.inform(resourceLoader);\n      resourceLoader.inform(this); // last call before the latch is released.\n    } catch (Throwable e) {\n      latch.countDown();//release the latch, otherwise we block trying to do the close.  This should be fine, since counting down on a latch of 0 is still fine\n      //close down the searcher and any other resources, if it exists, as this is not recoverable\n      close();\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \n                              e.getMessage(), e);\n    } finally {\n      // allow firstSearcher events to fire and make sure it is released\n      latch.countDown();\n    }\n\n    infoRegistry.put(\"core\", this);\n    \n    // register any SolrInfoMBeans SolrResourceLoader initialized\n    //\n    // this must happen after the latch is released, because a JMX server impl may\n    // choose to block on registering until properties can be fetched from an MBean,\n    // and a SolrCoreAware MBean may have properties that depend on getting a Searcher\n    // from the core.\n    resourceLoader.inform(infoRegistry);\n    \n    // For debugging   \n//    numOpens.incrementAndGet();\n//    openHandles.put(this, new RuntimeException(\"unclosed core - name:\" + getName() + \" refs: \" + refCount.get()));\n  }\n\n","sourceOld":"  /**\n   * Creates a new core and register it in the list of cores.\n   * If a core with the same name already exists, it will be stopped and replaced by this one.\n   *@param dataDir the index directory\n   *@param config a solr config instance\n   *@param schema a solr schema instance\n   *\n   *@since solr 1.3\n   */\n  public SolrCore(String name, String dataDir, SolrConfig config, IndexSchema schema, CoreDescriptor cd, UpdateHandler updateHandler, SolrCore prev) {\n    coreDescriptor = cd;\n    this.setName( name );\n    resourceLoader = config.getResourceLoader();\n    this.solrConfig = config;\n    \n    if (updateHandler == null) {\n      initDirectoryFactory();\n    }\n    \n    if (dataDir == null) {\n      if (cd.usingDefaultDataDir()) dataDir = config.getDataDir();\n      if (dataDir == null) {\n        dataDir = cd.getDataDir();\n        try {\n          if (!directoryFactory.isAbsolute(dataDir)) {\n            dataDir = directoryFactory.normalize(SolrResourceLoader\n                .normalizeDir(cd.getInstanceDir()) + dataDir);\n          }\n        } catch (IOException e) {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, e);\n        }\n      }\n    }\n\n    dataDir = SolrResourceLoader.normalizeDir(dataDir);\n    log.info(logid+\"Opening new SolrCore at \" + resourceLoader.getInstanceDir() + \", dataDir=\"+dataDir);\n\n    if (schema==null) {\n      schema = new IndexSchema(config, IndexSchema.DEFAULT_SCHEMA_FILE, null);\n    }\n\n    if (null != cd && null != cd.getCloudDescriptor()) {\n      // we are evidently running in cloud mode.  \n      //\n      // In cloud mode, version field is required for correct consistency\n      // ideally this check would be more fine grained, and individual features\n      // would assert it when they initialize, but DistribuedUpdateProcessor\n      // is currently a big ball of wax that does more then just distributing\n      // updates (ie: partial document updates), so it needs to work in no cloud\n      // mode as well, and can't assert version field support on init.\n\n      try {\n        Object ignored = VersionInfo.getAndCheckVersionField(schema);\n      } catch (SolrException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                                \"Schema will not work with SolrCloud mode: \" +\n                                e.getMessage(), e);\n      }\n    }\n\n    //Initialize JMX\n    if (config.jmxConfig.enabled) {\n      infoRegistry = new JmxMonitoredMap<String, SolrInfoMBean>(name, String.valueOf(this.hashCode()), config.jmxConfig);\n    } else  {\n      log.info(\"JMX monitoring not detected for core: \" + name);\n      infoRegistry = new ConcurrentHashMap<String, SolrInfoMBean>();\n    }\n\n    infoRegistry.put(\"fieldCache\", new SolrFieldCacheMBean());\n\n    this.schema = schema;\n    this.dataDir = dataDir;\n    this.startTime = System.currentTimeMillis();\n    this.maxWarmingSearchers = config.maxWarmingSearchers;\n\n    booleanQueryMaxClauseCount();\n  \n    final CountDownLatch latch = new CountDownLatch(1);\n\n    try {\n      \n      initListeners();\n      \n      if (updateHandler == null) {\n        initDeletionPolicy();\n      }\n      \n      this.codec = initCodec(solrConfig, schema);\n      \n      if (updateHandler == null) {\n        initDirectoryFactory();\n        solrCoreState = new DefaultSolrCoreState(getDirectoryFactory());\n      } else {\n        solrCoreState = updateHandler.getSolrCoreState();\n        directoryFactory = solrCoreState.getDirectoryFactory();\n        this.isReloaded = true;\n      }\n      \n      initIndex(prev != null);\n      \n      initWriters();\n      initQParsers();\n      initValueSourceParsers();\n      initTransformerFactories();\n      \n      this.searchComponents = Collections\n          .unmodifiableMap(loadSearchComponents());\n      \n      // Processors initialized before the handlers\n      updateProcessorChains = loadUpdateProcessorChains();\n      reqHandlers = new RequestHandlers(this);\n      reqHandlers.initHandlersFromConfig(solrConfig);\n      \n      // Handle things that should eventually go away\n      initDeprecatedSupport();\n      \n      // cause the executor to stall so firstSearcher events won't fire\n      // until after inform() has been called for all components.\n      // searchExecutor must be single-threaded for this to work\n      searcherExecutor.submit(new Callable() {\n        @Override\n        public Object call() throws Exception {\n          latch.await();\n          return null;\n        }\n      });\n      \n      // use the (old) writer to open the first searcher\n      RefCounted<IndexWriter> iwRef = null;\n      if (prev != null) {\n        iwRef = prev.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n        if (iwRef != null) {\n          final IndexWriter iw = iwRef.get();\n          newReaderCreator = new Callable<DirectoryReader>() {\n            @Override\n            public DirectoryReader call() throws Exception {\n              return DirectoryReader.open(iw, true);\n            }\n          };\n        }\n      }\n      \n      // Open the searcher *before* the update handler so we don't end up\n      // opening\n      // one in the middle.\n      // With lockless commits in Lucene now, this probably shouldn't be an\n      // issue anymore\n      \n      try {\n        getSearcher(false, false, null, true);\n      } finally {\n        newReaderCreator = null;\n        if (iwRef != null) iwRef.decref();\n      }\n      \n      String updateHandlerClass = solrConfig.getUpdateHandlerInfo().className;\n      \n      if (updateHandler == null) {\n        this.updateHandler = createUpdateHandler(updateHandlerClass == null ? DirectUpdateHandler2.class\n            .getName() : updateHandlerClass);\n      } else {\n        this.updateHandler = updateHandler;\n      }\n      infoRegistry.put(\"updateHandler\", this.updateHandler);\n      \n      // Finally tell anyone who wants to know\n      resourceLoader.inform(resourceLoader);\n      resourceLoader.inform(this); // last call before the latch is released.\n    } catch (Throwable e) {\n      latch.countDown();//release the latch, otherwise we block trying to do the close.  This should be fine, since counting down on a latch of 0 is still fine\n      //close down the searcher and any other resources, if it exists, as this is not recoverable\n      close();\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \n                              e.getMessage(), e);\n    } finally {\n      // allow firstSearcher events to fire and make sure it is released\n      latch.countDown();\n    }\n\n    infoRegistry.put(\"core\", this);\n    \n    // register any SolrInfoMBeans SolrResourceLoader initialized\n    //\n    // this must happen after the latch is released, because a JMX server impl may\n    // choose to block on registering until properties can be fetched from an MBean,\n    // and a SolrCoreAware MBean may have properties that depend on getting a Searcher\n    // from the core.\n    resourceLoader.inform(infoRegistry);\n    \n    // For debugging   \n//    numOpens.incrementAndGet();\n//    openHandles.put(this, new RuntimeException(\"unclosed core - name:\" + getName() + \" refs: \" + refCount.get()));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"47402a40696c1b7bc0524a8857b833c00f4cde3f","date":1363792699,"type":5,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/SolrCore#SolrCore(String,String,SolrConfig,IndexSchema,CoreDescriptor,UpdateHandler,IndexDeletionPolicyWrapper,SolrCore).mjava","pathOld":"solr/core/src/java/org/apache/solr/core/SolrCore#SolrCore(String,String,SolrConfig,IndexSchema,CoreDescriptor,UpdateHandler,SolrCore).mjava","sourceNew":"  /**\n   * Creates a new core and register it in the list of cores.\n   * If a core with the same name already exists, it will be stopped and replaced by this one.\n   *@param dataDir the index directory\n   *@param config a solr config instance\n   *@param schema a solr schema instance\n   *\n   *@since solr 1.3\n   */\n  public SolrCore(String name, String dataDir, SolrConfig config, IndexSchema schema, CoreDescriptor cd, UpdateHandler updateHandler, IndexDeletionPolicyWrapper delPolicy, SolrCore prev) {\n    coreDescriptor = cd;\n    this.setName( name );\n    resourceLoader = config.getResourceLoader();\n    this.solrConfig = config;\n    \n    if (updateHandler == null) {\n      initDirectoryFactory();\n    }\n    \n    if (dataDir == null) {\n      if (cd.usingDefaultDataDir()) dataDir = config.getDataDir();\n      if (dataDir == null) {\n        dataDir = cd.getDataDir();\n        try {\n          if (!directoryFactory.isAbsolute(dataDir)) {\n            dataDir = directoryFactory.normalize(SolrResourceLoader\n                .normalizeDir(cd.getInstanceDir()) + dataDir);\n          }\n        } catch (IOException e) {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, e);\n        }\n      }\n    }\n\n    dataDir = SolrResourceLoader.normalizeDir(dataDir);\n    log.info(logid+\"Opening new SolrCore at \" + resourceLoader.getInstanceDir() + \", dataDir=\"+dataDir);\n\n    if (schema==null) {\n      schema = new IndexSchema(config, IndexSchema.DEFAULT_SCHEMA_FILE, null);\n    }\n\n    if (null != cd && null != cd.getCloudDescriptor()) {\n      // we are evidently running in cloud mode.  \n      //\n      // In cloud mode, version field is required for correct consistency\n      // ideally this check would be more fine grained, and individual features\n      // would assert it when they initialize, but DistribuedUpdateProcessor\n      // is currently a big ball of wax that does more then just distributing\n      // updates (ie: partial document updates), so it needs to work in no cloud\n      // mode as well, and can't assert version field support on init.\n\n      try {\n        Object ignored = VersionInfo.getAndCheckVersionField(schema);\n      } catch (SolrException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                                \"Schema will not work with SolrCloud mode: \" +\n                                e.getMessage(), e);\n      }\n    }\n\n    //Initialize JMX\n    if (config.jmxConfig.enabled) {\n      infoRegistry = new JmxMonitoredMap<String, SolrInfoMBean>(name, String.valueOf(this.hashCode()), config.jmxConfig);\n    } else  {\n      log.info(\"JMX monitoring not detected for core: \" + name);\n      infoRegistry = new ConcurrentHashMap<String, SolrInfoMBean>();\n    }\n\n    infoRegistry.put(\"fieldCache\", new SolrFieldCacheMBean());\n\n    this.schema = schema;\n    this.dataDir = dataDir;\n    this.startTime = System.currentTimeMillis();\n    this.maxWarmingSearchers = config.maxWarmingSearchers;\n\n    booleanQueryMaxClauseCount();\n  \n    final CountDownLatch latch = new CountDownLatch(1);\n\n    try {\n      \n      initListeners();\n      \n      if (delPolicy == null) {\n        initDeletionPolicy();\n      } else {\n        this.solrDelPolicy = delPolicy;\n      }\n      \n      this.codec = initCodec(solrConfig, schema);\n      \n      if (updateHandler == null) {\n        initDirectoryFactory();\n        solrCoreState = new DefaultSolrCoreState(getDirectoryFactory());\n      } else {\n        solrCoreState = updateHandler.getSolrCoreState();\n        directoryFactory = solrCoreState.getDirectoryFactory();\n        this.isReloaded = true;\n      }\n      \n      initIndex(prev != null);\n      \n      initWriters();\n      initQParsers();\n      initValueSourceParsers();\n      initTransformerFactories();\n      \n      this.searchComponents = Collections\n          .unmodifiableMap(loadSearchComponents());\n      \n      // Processors initialized before the handlers\n      updateProcessorChains = loadUpdateProcessorChains();\n      reqHandlers = new RequestHandlers(this);\n      reqHandlers.initHandlersFromConfig(solrConfig);\n      \n      // Handle things that should eventually go away\n      initDeprecatedSupport();\n      \n      // cause the executor to stall so firstSearcher events won't fire\n      // until after inform() has been called for all components.\n      // searchExecutor must be single-threaded for this to work\n      searcherExecutor.submit(new Callable() {\n        @Override\n        public Object call() throws Exception {\n          latch.await();\n          return null;\n        }\n      });\n      \n      // use the (old) writer to open the first searcher\n      RefCounted<IndexWriter> iwRef = null;\n      if (prev != null) {\n        iwRef = prev.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n        if (iwRef != null) {\n          final IndexWriter iw = iwRef.get();\n          newReaderCreator = new Callable<DirectoryReader>() {\n            @Override\n            public DirectoryReader call() throws Exception {\n              return DirectoryReader.open(iw, true);\n            }\n          };\n        }\n      }\n      \n      // Open the searcher *before* the update handler so we don't end up\n      // opening\n      // one in the middle.\n      // With lockless commits in Lucene now, this probably shouldn't be an\n      // issue anymore\n      \n      try {\n        getSearcher(false, false, null, true);\n      } finally {\n        newReaderCreator = null;\n        if (iwRef != null) iwRef.decref();\n      }\n      \n      String updateHandlerClass = solrConfig.getUpdateHandlerInfo().className;\n      \n      if (updateHandler == null) {\n        this.updateHandler = createUpdateHandler(updateHandlerClass == null ? DirectUpdateHandler2.class\n            .getName() : updateHandlerClass);\n      } else {\n        this.updateHandler = createUpdateHandler(\n            updateHandlerClass == null ? DirectUpdateHandler2.class.getName()\n                : updateHandlerClass, updateHandler);\n      }\n      infoRegistry.put(\"updateHandler\", this.updateHandler);\n      \n      // Finally tell anyone who wants to know\n      resourceLoader.inform(resourceLoader);\n      resourceLoader.inform(this); // last call before the latch is released.\n    } catch (Throwable e) {\n      latch.countDown();//release the latch, otherwise we block trying to do the close.  This should be fine, since counting down on a latch of 0 is still fine\n      //close down the searcher and any other resources, if it exists, as this is not recoverable\n      close();\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \n                              e.getMessage(), e);\n    } finally {\n      // allow firstSearcher events to fire and make sure it is released\n      latch.countDown();\n    }\n\n    infoRegistry.put(\"core\", this);\n    \n    // register any SolrInfoMBeans SolrResourceLoader initialized\n    //\n    // this must happen after the latch is released, because a JMX server impl may\n    // choose to block on registering until properties can be fetched from an MBean,\n    // and a SolrCoreAware MBean may have properties that depend on getting a Searcher\n    // from the core.\n    resourceLoader.inform(infoRegistry);\n    \n    // For debugging   \n//    numOpens.incrementAndGet();\n//    openHandles.put(this, new RuntimeException(\"unclosed core - name:\" + getName() + \" refs: \" + refCount.get()));\n  }\n\n","sourceOld":"  /**\n   * Creates a new core and register it in the list of cores.\n   * If a core with the same name already exists, it will be stopped and replaced by this one.\n   *@param dataDir the index directory\n   *@param config a solr config instance\n   *@param schema a solr schema instance\n   *\n   *@since solr 1.3\n   */\n  public SolrCore(String name, String dataDir, SolrConfig config, IndexSchema schema, CoreDescriptor cd, UpdateHandler updateHandler, SolrCore prev) {\n    coreDescriptor = cd;\n    this.setName( name );\n    resourceLoader = config.getResourceLoader();\n    this.solrConfig = config;\n    \n    if (updateHandler == null) {\n      initDirectoryFactory();\n    }\n    \n    if (dataDir == null) {\n      if (cd.usingDefaultDataDir()) dataDir = config.getDataDir();\n      if (dataDir == null) {\n        dataDir = cd.getDataDir();\n        try {\n          if (!directoryFactory.isAbsolute(dataDir)) {\n            dataDir = directoryFactory.normalize(SolrResourceLoader\n                .normalizeDir(cd.getInstanceDir()) + dataDir);\n          }\n        } catch (IOException e) {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, e);\n        }\n      }\n    }\n\n    dataDir = SolrResourceLoader.normalizeDir(dataDir);\n    log.info(logid+\"Opening new SolrCore at \" + resourceLoader.getInstanceDir() + \", dataDir=\"+dataDir);\n\n    if (schema==null) {\n      schema = new IndexSchema(config, IndexSchema.DEFAULT_SCHEMA_FILE, null);\n    }\n\n    if (null != cd && null != cd.getCloudDescriptor()) {\n      // we are evidently running in cloud mode.  \n      //\n      // In cloud mode, version field is required for correct consistency\n      // ideally this check would be more fine grained, and individual features\n      // would assert it when they initialize, but DistribuedUpdateProcessor\n      // is currently a big ball of wax that does more then just distributing\n      // updates (ie: partial document updates), so it needs to work in no cloud\n      // mode as well, and can't assert version field support on init.\n\n      try {\n        Object ignored = VersionInfo.getAndCheckVersionField(schema);\n      } catch (SolrException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                                \"Schema will not work with SolrCloud mode: \" +\n                                e.getMessage(), e);\n      }\n    }\n\n    //Initialize JMX\n    if (config.jmxConfig.enabled) {\n      infoRegistry = new JmxMonitoredMap<String, SolrInfoMBean>(name, String.valueOf(this.hashCode()), config.jmxConfig);\n    } else  {\n      log.info(\"JMX monitoring not detected for core: \" + name);\n      infoRegistry = new ConcurrentHashMap<String, SolrInfoMBean>();\n    }\n\n    infoRegistry.put(\"fieldCache\", new SolrFieldCacheMBean());\n\n    this.schema = schema;\n    this.dataDir = dataDir;\n    this.startTime = System.currentTimeMillis();\n    this.maxWarmingSearchers = config.maxWarmingSearchers;\n\n    booleanQueryMaxClauseCount();\n  \n    final CountDownLatch latch = new CountDownLatch(1);\n\n    try {\n      \n      initListeners();\n      \n      if (updateHandler == null) {\n        initDeletionPolicy();\n      }\n      \n      this.codec = initCodec(solrConfig, schema);\n      \n      if (updateHandler == null) {\n        initDirectoryFactory();\n        solrCoreState = new DefaultSolrCoreState(getDirectoryFactory());\n      } else {\n        solrCoreState = updateHandler.getSolrCoreState();\n        directoryFactory = solrCoreState.getDirectoryFactory();\n        this.isReloaded = true;\n      }\n      \n      initIndex(prev != null);\n      \n      initWriters();\n      initQParsers();\n      initValueSourceParsers();\n      initTransformerFactories();\n      \n      this.searchComponents = Collections\n          .unmodifiableMap(loadSearchComponents());\n      \n      // Processors initialized before the handlers\n      updateProcessorChains = loadUpdateProcessorChains();\n      reqHandlers = new RequestHandlers(this);\n      reqHandlers.initHandlersFromConfig(solrConfig);\n      \n      // Handle things that should eventually go away\n      initDeprecatedSupport();\n      \n      // cause the executor to stall so firstSearcher events won't fire\n      // until after inform() has been called for all components.\n      // searchExecutor must be single-threaded for this to work\n      searcherExecutor.submit(new Callable() {\n        @Override\n        public Object call() throws Exception {\n          latch.await();\n          return null;\n        }\n      });\n      \n      // use the (old) writer to open the first searcher\n      RefCounted<IndexWriter> iwRef = null;\n      if (prev != null) {\n        iwRef = prev.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n        if (iwRef != null) {\n          final IndexWriter iw = iwRef.get();\n          newReaderCreator = new Callable<DirectoryReader>() {\n            @Override\n            public DirectoryReader call() throws Exception {\n              return DirectoryReader.open(iw, true);\n            }\n          };\n        }\n      }\n      \n      // Open the searcher *before* the update handler so we don't end up\n      // opening\n      // one in the middle.\n      // With lockless commits in Lucene now, this probably shouldn't be an\n      // issue anymore\n      \n      try {\n        getSearcher(false, false, null, true);\n      } finally {\n        newReaderCreator = null;\n        if (iwRef != null) iwRef.decref();\n      }\n      \n      String updateHandlerClass = solrConfig.getUpdateHandlerInfo().className;\n      \n      if (updateHandler == null) {\n        this.updateHandler = createUpdateHandler(updateHandlerClass == null ? DirectUpdateHandler2.class\n            .getName() : updateHandlerClass);\n      } else {\n        this.updateHandler = createUpdateHandler(\n            updateHandlerClass == null ? DirectUpdateHandler2.class.getName()\n                : updateHandlerClass, updateHandler);\n      }\n      infoRegistry.put(\"updateHandler\", this.updateHandler);\n      \n      // Finally tell anyone who wants to know\n      resourceLoader.inform(resourceLoader);\n      resourceLoader.inform(this); // last call before the latch is released.\n    } catch (Throwable e) {\n      latch.countDown();//release the latch, otherwise we block trying to do the close.  This should be fine, since counting down on a latch of 0 is still fine\n      //close down the searcher and any other resources, if it exists, as this is not recoverable\n      close();\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \n                              e.getMessage(), e);\n    } finally {\n      // allow firstSearcher events to fire and make sure it is released\n      latch.countDown();\n    }\n\n    infoRegistry.put(\"core\", this);\n    \n    // register any SolrInfoMBeans SolrResourceLoader initialized\n    //\n    // this must happen after the latch is released, because a JMX server impl may\n    // choose to block on registering until properties can be fetched from an MBean,\n    // and a SolrCoreAware MBean may have properties that depend on getting a Searcher\n    // from the core.\n    resourceLoader.inform(infoRegistry);\n    \n    // For debugging   \n//    numOpens.incrementAndGet();\n//    openHandles.put(this, new RuntimeException(\"unclosed core - name:\" + getName() + \" refs: \" + refCount.get()));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"c7bd1fdddb8e84c1857d1a55c32ced51f0ed2069":["df4ed22dc7b048a2e9efa6ee55cb84b9457e9ee5"],"d3fcb70cf561547c7bb1506e0cf32ca7b1287064":["d9405f486872f1e416304dfe389741f4ee2f8a4d","7530de27b87b961b51f01bd1299b7004d46e8823"],"948cb7389da6d4f397f5a0f89caf885a9033c959":["a837c064b67fa63a9394136e31218b908cdcf783"],"9c76c513f7206331c91df98399d28c338ea1b95a":["c9767265f21f7d1246b13dd7e73e8a4ad88b4384"],"d9405f486872f1e416304dfe389741f4ee2f8a4d":["3c8475e39c56b28600d2b496f3e78f7421190f62"],"05a14b2611ead08655a2b2bdc61632eb31316e57":["aba371508186796cc6151d8223a5b4e16d02e26e","9c76c513f7206331c91df98399d28c338ea1b95a"],"28d656aaac42f919a3a7e8a859407018d75fed41":["ab128867904d724d03b93aa2b8048f5ae1649c39"],"aba371508186796cc6151d8223a5b4e16d02e26e":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","c9767265f21f7d1246b13dd7e73e8a4ad88b4384"],"df4ed22dc7b048a2e9efa6ee55cb84b9457e9ee5":["9c76c513f7206331c91df98399d28c338ea1b95a"],"3c8475e39c56b28600d2b496f3e78f7421190f62":["c7bd1fdddb8e84c1857d1a55c32ced51f0ed2069"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"4b51f65902cc2d20ddeb7a5b949aaddf990f31a7":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","c9767265f21f7d1246b13dd7e73e8a4ad88b4384"],"f2126b84bd093fa3d921582a109a0ee578c28126":["3c8475e39c56b28600d2b496f3e78f7421190f62","d9405f486872f1e416304dfe389741f4ee2f8a4d"],"ab128867904d724d03b93aa2b8048f5ae1649c39":["948cb7389da6d4f397f5a0f89caf885a9033c959"],"a837c064b67fa63a9394136e31218b908cdcf783":["7530de27b87b961b51f01bd1299b7004d46e8823"],"c9767265f21f7d1246b13dd7e73e8a4ad88b4384":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"47402a40696c1b7bc0524a8857b833c00f4cde3f":["28d656aaac42f919a3a7e8a859407018d75fed41"],"7530de27b87b961b51f01bd1299b7004d46e8823":["d9405f486872f1e416304dfe389741f4ee2f8a4d"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["47402a40696c1b7bc0524a8857b833c00f4cde3f"]},"commit2Childs":{"c7bd1fdddb8e84c1857d1a55c32ced51f0ed2069":["3c8475e39c56b28600d2b496f3e78f7421190f62"],"d3fcb70cf561547c7bb1506e0cf32ca7b1287064":[],"948cb7389da6d4f397f5a0f89caf885a9033c959":["ab128867904d724d03b93aa2b8048f5ae1649c39"],"9c76c513f7206331c91df98399d28c338ea1b95a":["05a14b2611ead08655a2b2bdc61632eb31316e57","df4ed22dc7b048a2e9efa6ee55cb84b9457e9ee5"],"d9405f486872f1e416304dfe389741f4ee2f8a4d":["d3fcb70cf561547c7bb1506e0cf32ca7b1287064","f2126b84bd093fa3d921582a109a0ee578c28126","7530de27b87b961b51f01bd1299b7004d46e8823"],"05a14b2611ead08655a2b2bdc61632eb31316e57":[],"28d656aaac42f919a3a7e8a859407018d75fed41":["47402a40696c1b7bc0524a8857b833c00f4cde3f"],"aba371508186796cc6151d8223a5b4e16d02e26e":["05a14b2611ead08655a2b2bdc61632eb31316e57"],"df4ed22dc7b048a2e9efa6ee55cb84b9457e9ee5":["c7bd1fdddb8e84c1857d1a55c32ced51f0ed2069"],"3c8475e39c56b28600d2b496f3e78f7421190f62":["d9405f486872f1e416304dfe389741f4ee2f8a4d","f2126b84bd093fa3d921582a109a0ee578c28126"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["aba371508186796cc6151d8223a5b4e16d02e26e","4b51f65902cc2d20ddeb7a5b949aaddf990f31a7","c9767265f21f7d1246b13dd7e73e8a4ad88b4384"],"4b51f65902cc2d20ddeb7a5b949aaddf990f31a7":[],"f2126b84bd093fa3d921582a109a0ee578c28126":[],"a837c064b67fa63a9394136e31218b908cdcf783":["948cb7389da6d4f397f5a0f89caf885a9033c959"],"c9767265f21f7d1246b13dd7e73e8a4ad88b4384":["9c76c513f7206331c91df98399d28c338ea1b95a","aba371508186796cc6151d8223a5b4e16d02e26e","4b51f65902cc2d20ddeb7a5b949aaddf990f31a7"],"ab128867904d724d03b93aa2b8048f5ae1649c39":["28d656aaac42f919a3a7e8a859407018d75fed41"],"7530de27b87b961b51f01bd1299b7004d46e8823":["d3fcb70cf561547c7bb1506e0cf32ca7b1287064","a837c064b67fa63a9394136e31218b908cdcf783"],"47402a40696c1b7bc0524a8857b833c00f4cde3f":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["d3fcb70cf561547c7bb1506e0cf32ca7b1287064","05a14b2611ead08655a2b2bdc61632eb31316e57","4b51f65902cc2d20ddeb7a5b949aaddf990f31a7","f2126b84bd093fa3d921582a109a0ee578c28126","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}