{"path":"lucene/codecs/src/java/org/apache/lucene/codecs/blockterms/FixedGapTermsIndexReader#FixedGapTermsIndexReader(Directory,FieldInfos,String,Comparator[BytesRef],String,IOContext).mjava","commits":[{"id":"a45bec74b98f6fc05f52770cfb425739e6563960","date":1375119292,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/codecs/src/java/org/apache/lucene/codecs/blockterms/FixedGapTermsIndexReader#FixedGapTermsIndexReader(Directory,FieldInfos,String,Comparator[BytesRef],String,IOContext).mjava","pathOld":"lucene/codecs/src/java/org/apache/lucene/codecs/blockterms/FixedGapTermsIndexReader#FixedGapTermsIndexReader(Directory,FieldInfos,String,int,Comparator[BytesRef],String,IOContext).mjava","sourceNew":"  public FixedGapTermsIndexReader(Directory dir, FieldInfos fieldInfos, String segment, Comparator<BytesRef> termComp, String segmentSuffix, IOContext context)\n    throws IOException {\n\n    this.termComp = termComp;\n    \n    final IndexInput in = dir.openInput(IndexFileNames.segmentFileName(segment, segmentSuffix, FixedGapTermsIndexWriter.TERMS_INDEX_EXTENSION), context);\n    \n    boolean success = false;\n\n    try {\n      \n      readHeader(in);\n      indexInterval = in.readVInt();\n      if (indexInterval < 1) {\n        throw new CorruptIndexException(\"invalid indexInterval: \" + indexInterval + \" (resource=\" + in + \")\");\n      }\n      packedIntsVersion = in.readVInt();\n      blocksize = in.readVInt();\n      \n      seekDir(in, dirOffset);\n\n      // Read directory\n      final int numFields = in.readVInt();     \n      if (numFields < 0) {\n        throw new CorruptIndexException(\"invalid numFields: \" + numFields + \" (resource=\" + in + \")\");\n      }\n      //System.out.println(\"FGR: init seg=\" + segment + \" div=\" + indexDivisor + \" nF=\" + numFields);\n      for(int i=0;i<numFields;i++) {\n        final int field = in.readVInt();\n        final long numIndexTerms = in.readVInt(); // TODO: change this to a vLong if we fix writer to support > 2B index terms\n        if (numIndexTerms < 0) {\n          throw new CorruptIndexException(\"invalid numIndexTerms: \" + numIndexTerms + \" (resource=\" + in + \")\");\n        }\n        final long termsStart = in.readVLong();\n        final long indexStart = in.readVLong();\n        final long packedIndexStart = in.readVLong();\n        final long packedOffsetsStart = in.readVLong();\n        if (packedIndexStart < indexStart) {\n          throw new CorruptIndexException(\"invalid packedIndexStart: \" + packedIndexStart + \" indexStart: \" + indexStart + \"numIndexTerms: \" + numIndexTerms + \" (resource=\" + in + \")\");\n        }\n        final FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n        FieldIndexData previous = fields.put(fieldInfo, new FieldIndexData(in, indexStart, termsStart, packedIndexStart, packedOffsetsStart, numIndexTerms));\n        if (previous != null) {\n          throw new CorruptIndexException(\"duplicate field: \" + fieldInfo.name + \" (resource=\" + in + \")\");\n        }\n      }\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(in);\n      } else {\n        IOUtils.closeWhileHandlingException(in);\n      }\n      termBytesReader = termBytes.freeze(true);\n    }\n  }\n\n","sourceOld":"  public FixedGapTermsIndexReader(Directory dir, FieldInfos fieldInfos, String segment, int indexDivisor, Comparator<BytesRef> termComp, String segmentSuffix, IOContext context)\n    throws IOException {\n\n    this.termComp = termComp;\n\n    assert indexDivisor == -1 || indexDivisor > 0;\n\n    in = dir.openInput(IndexFileNames.segmentFileName(segment, segmentSuffix, FixedGapTermsIndexWriter.TERMS_INDEX_EXTENSION), context);\n    \n    boolean success = false;\n\n    try {\n      \n      version = readHeader(in);\n      indexInterval = in.readInt();\n      if (indexInterval < 1) {\n        throw new CorruptIndexException(\"invalid indexInterval: \" + indexInterval + \" (resource=\" + in + \")\");\n      }\n      this.indexDivisor = indexDivisor;\n\n      if (indexDivisor < 0) {\n        totalIndexInterval = indexInterval;\n      } else {\n        // In case terms index gets loaded, later, on demand\n        totalIndexInterval = indexInterval * indexDivisor;\n      }\n      assert totalIndexInterval > 0;\n      \n      seekDir(in, dirOffset);\n\n      // Read directory\n      final int numFields = in.readVInt();     \n      if (numFields < 0) {\n        throw new CorruptIndexException(\"invalid numFields: \" + numFields + \" (resource=\" + in + \")\");\n      }\n      //System.out.println(\"FGR: init seg=\" + segment + \" div=\" + indexDivisor + \" nF=\" + numFields);\n      for(int i=0;i<numFields;i++) {\n        final int field = in.readVInt();\n        final int numIndexTerms = in.readVInt();\n        if (numIndexTerms < 0) {\n          throw new CorruptIndexException(\"invalid numIndexTerms: \" + numIndexTerms + \" (resource=\" + in + \")\");\n        }\n        final long termsStart = in.readVLong();\n        final long indexStart = in.readVLong();\n        final long packedIndexStart = in.readVLong();\n        final long packedOffsetsStart = in.readVLong();\n        if (packedIndexStart < indexStart) {\n          throw new CorruptIndexException(\"invalid packedIndexStart: \" + packedIndexStart + \" indexStart: \" + indexStart + \"numIndexTerms: \" + numIndexTerms + \" (resource=\" + in + \")\");\n        }\n        final FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n        FieldIndexData previous = fields.put(fieldInfo, new FieldIndexData(fieldInfo, numIndexTerms, indexStart, termsStart, packedIndexStart, packedOffsetsStart));\n        if (previous != null) {\n          throw new CorruptIndexException(\"duplicate field: \" + fieldInfo.name + \" (resource=\" + in + \")\");\n        }\n      }\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(in);\n      }\n      if (indexDivisor > 0) {\n        in.close();\n        in = null;\n        if (success) {\n          indexLoaded = true;\n        }\n        termBytesReader = termBytes.freeze(true);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee","date":1376366778,"type":1,"author":"Han Jiang","isMerge":false,"pathNew":"lucene/codecs/src/java/org/apache/lucene/codecs/blockterms/FixedGapTermsIndexReader#FixedGapTermsIndexReader(Directory,FieldInfos,String,Comparator[BytesRef],String,IOContext).mjava","pathOld":"lucene/codecs/src/java/org/apache/lucene/codecs/blockterms/FixedGapTermsIndexReader#FixedGapTermsIndexReader(Directory,FieldInfos,String,int,Comparator[BytesRef],String,IOContext).mjava","sourceNew":"  public FixedGapTermsIndexReader(Directory dir, FieldInfos fieldInfos, String segment, Comparator<BytesRef> termComp, String segmentSuffix, IOContext context)\n    throws IOException {\n\n    this.termComp = termComp;\n    \n    final IndexInput in = dir.openInput(IndexFileNames.segmentFileName(segment, segmentSuffix, FixedGapTermsIndexWriter.TERMS_INDEX_EXTENSION), context);\n    \n    boolean success = false;\n\n    try {\n      \n      readHeader(in);\n      indexInterval = in.readVInt();\n      if (indexInterval < 1) {\n        throw new CorruptIndexException(\"invalid indexInterval: \" + indexInterval + \" (resource=\" + in + \")\");\n      }\n      packedIntsVersion = in.readVInt();\n      blocksize = in.readVInt();\n      \n      seekDir(in, dirOffset);\n\n      // Read directory\n      final int numFields = in.readVInt();     \n      if (numFields < 0) {\n        throw new CorruptIndexException(\"invalid numFields: \" + numFields + \" (resource=\" + in + \")\");\n      }\n      //System.out.println(\"FGR: init seg=\" + segment + \" div=\" + indexDivisor + \" nF=\" + numFields);\n      for(int i=0;i<numFields;i++) {\n        final int field = in.readVInt();\n        final long numIndexTerms = in.readVInt(); // TODO: change this to a vLong if we fix writer to support > 2B index terms\n        if (numIndexTerms < 0) {\n          throw new CorruptIndexException(\"invalid numIndexTerms: \" + numIndexTerms + \" (resource=\" + in + \")\");\n        }\n        final long termsStart = in.readVLong();\n        final long indexStart = in.readVLong();\n        final long packedIndexStart = in.readVLong();\n        final long packedOffsetsStart = in.readVLong();\n        if (packedIndexStart < indexStart) {\n          throw new CorruptIndexException(\"invalid packedIndexStart: \" + packedIndexStart + \" indexStart: \" + indexStart + \"numIndexTerms: \" + numIndexTerms + \" (resource=\" + in + \")\");\n        }\n        final FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n        FieldIndexData previous = fields.put(fieldInfo, new FieldIndexData(in, indexStart, termsStart, packedIndexStart, packedOffsetsStart, numIndexTerms));\n        if (previous != null) {\n          throw new CorruptIndexException(\"duplicate field: \" + fieldInfo.name + \" (resource=\" + in + \")\");\n        }\n      }\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(in);\n      } else {\n        IOUtils.closeWhileHandlingException(in);\n      }\n      termBytesReader = termBytes.freeze(true);\n    }\n  }\n\n","sourceOld":"  public FixedGapTermsIndexReader(Directory dir, FieldInfos fieldInfos, String segment, int indexDivisor, Comparator<BytesRef> termComp, String segmentSuffix, IOContext context)\n    throws IOException {\n\n    this.termComp = termComp;\n\n    assert indexDivisor == -1 || indexDivisor > 0;\n\n    in = dir.openInput(IndexFileNames.segmentFileName(segment, segmentSuffix, FixedGapTermsIndexWriter.TERMS_INDEX_EXTENSION), context);\n    \n    boolean success = false;\n\n    try {\n      \n      version = readHeader(in);\n      indexInterval = in.readInt();\n      if (indexInterval < 1) {\n        throw new CorruptIndexException(\"invalid indexInterval: \" + indexInterval + \" (resource=\" + in + \")\");\n      }\n      this.indexDivisor = indexDivisor;\n\n      if (indexDivisor < 0) {\n        totalIndexInterval = indexInterval;\n      } else {\n        // In case terms index gets loaded, later, on demand\n        totalIndexInterval = indexInterval * indexDivisor;\n      }\n      assert totalIndexInterval > 0;\n      \n      seekDir(in, dirOffset);\n\n      // Read directory\n      final int numFields = in.readVInt();     \n      if (numFields < 0) {\n        throw new CorruptIndexException(\"invalid numFields: \" + numFields + \" (resource=\" + in + \")\");\n      }\n      //System.out.println(\"FGR: init seg=\" + segment + \" div=\" + indexDivisor + \" nF=\" + numFields);\n      for(int i=0;i<numFields;i++) {\n        final int field = in.readVInt();\n        final int numIndexTerms = in.readVInt();\n        if (numIndexTerms < 0) {\n          throw new CorruptIndexException(\"invalid numIndexTerms: \" + numIndexTerms + \" (resource=\" + in + \")\");\n        }\n        final long termsStart = in.readVLong();\n        final long indexStart = in.readVLong();\n        final long packedIndexStart = in.readVLong();\n        final long packedOffsetsStart = in.readVLong();\n        if (packedIndexStart < indexStart) {\n          throw new CorruptIndexException(\"invalid packedIndexStart: \" + packedIndexStart + \" indexStart: \" + indexStart + \"numIndexTerms: \" + numIndexTerms + \" (resource=\" + in + \")\");\n        }\n        final FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n        FieldIndexData previous = fields.put(fieldInfo, new FieldIndexData(fieldInfo, numIndexTerms, indexStart, termsStart, packedIndexStart, packedOffsetsStart));\n        if (previous != null) {\n          throw new CorruptIndexException(\"duplicate field: \" + fieldInfo.name + \" (resource=\" + in + \")\");\n        }\n      }\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(in);\n      }\n      if (indexDivisor > 0) {\n        in.close();\n        in = null;\n        if (success) {\n          indexLoaded = true;\n        }\n        termBytesReader = termBytes.freeze(true);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1f3b037cd083286b2af89f96e768f85dcd8072d6","date":1396337805,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/codecs/src/java/org/apache/lucene/codecs/blockterms/FixedGapTermsIndexReader#FixedGapTermsIndexReader(Directory,FieldInfos,String,Comparator[BytesRef],String,IOContext).mjava","pathOld":"lucene/codecs/src/java/org/apache/lucene/codecs/blockterms/FixedGapTermsIndexReader#FixedGapTermsIndexReader(Directory,FieldInfos,String,Comparator[BytesRef],String,IOContext).mjava","sourceNew":"  public FixedGapTermsIndexReader(Directory dir, FieldInfos fieldInfos, String segment, Comparator<BytesRef> termComp, String segmentSuffix, IOContext context)\n    throws IOException {\n\n    this.termComp = termComp;\n    \n    final IndexInput in = dir.openInput(IndexFileNames.segmentFileName(segment, segmentSuffix, FixedGapTermsIndexWriter.TERMS_INDEX_EXTENSION), context);\n    \n    boolean success = false;\n\n    try {\n      \n      readHeader(in);\n      \n      if (version >= FixedGapTermsIndexWriter.VERSION_CHECKSUM) {\n        CodecUtil.checksumEntireFile(in);\n      }\n      \n      indexInterval = in.readVInt();\n      if (indexInterval < 1) {\n        throw new CorruptIndexException(\"invalid indexInterval: \" + indexInterval + \" (resource=\" + in + \")\");\n      }\n      packedIntsVersion = in.readVInt();\n      blocksize = in.readVInt();\n      \n      seekDir(in, dirOffset);\n\n      // Read directory\n      final int numFields = in.readVInt();     \n      if (numFields < 0) {\n        throw new CorruptIndexException(\"invalid numFields: \" + numFields + \" (resource=\" + in + \")\");\n      }\n      //System.out.println(\"FGR: init seg=\" + segment + \" div=\" + indexDivisor + \" nF=\" + numFields);\n      for(int i=0;i<numFields;i++) {\n        final int field = in.readVInt();\n        final long numIndexTerms = in.readVInt(); // TODO: change this to a vLong if we fix writer to support > 2B index terms\n        if (numIndexTerms < 0) {\n          throw new CorruptIndexException(\"invalid numIndexTerms: \" + numIndexTerms + \" (resource=\" + in + \")\");\n        }\n        final long termsStart = in.readVLong();\n        final long indexStart = in.readVLong();\n        final long packedIndexStart = in.readVLong();\n        final long packedOffsetsStart = in.readVLong();\n        if (packedIndexStart < indexStart) {\n          throw new CorruptIndexException(\"invalid packedIndexStart: \" + packedIndexStart + \" indexStart: \" + indexStart + \"numIndexTerms: \" + numIndexTerms + \" (resource=\" + in + \")\");\n        }\n        final FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n        FieldIndexData previous = fields.put(fieldInfo, new FieldIndexData(in, indexStart, termsStart, packedIndexStart, packedOffsetsStart, numIndexTerms));\n        if (previous != null) {\n          throw new CorruptIndexException(\"duplicate field: \" + fieldInfo.name + \" (resource=\" + in + \")\");\n        }\n      }\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(in);\n      } else {\n        IOUtils.closeWhileHandlingException(in);\n      }\n      termBytesReader = termBytes.freeze(true);\n    }\n  }\n\n","sourceOld":"  public FixedGapTermsIndexReader(Directory dir, FieldInfos fieldInfos, String segment, Comparator<BytesRef> termComp, String segmentSuffix, IOContext context)\n    throws IOException {\n\n    this.termComp = termComp;\n    \n    final IndexInput in = dir.openInput(IndexFileNames.segmentFileName(segment, segmentSuffix, FixedGapTermsIndexWriter.TERMS_INDEX_EXTENSION), context);\n    \n    boolean success = false;\n\n    try {\n      \n      readHeader(in);\n      indexInterval = in.readVInt();\n      if (indexInterval < 1) {\n        throw new CorruptIndexException(\"invalid indexInterval: \" + indexInterval + \" (resource=\" + in + \")\");\n      }\n      packedIntsVersion = in.readVInt();\n      blocksize = in.readVInt();\n      \n      seekDir(in, dirOffset);\n\n      // Read directory\n      final int numFields = in.readVInt();     \n      if (numFields < 0) {\n        throw new CorruptIndexException(\"invalid numFields: \" + numFields + \" (resource=\" + in + \")\");\n      }\n      //System.out.println(\"FGR: init seg=\" + segment + \" div=\" + indexDivisor + \" nF=\" + numFields);\n      for(int i=0;i<numFields;i++) {\n        final int field = in.readVInt();\n        final long numIndexTerms = in.readVInt(); // TODO: change this to a vLong if we fix writer to support > 2B index terms\n        if (numIndexTerms < 0) {\n          throw new CorruptIndexException(\"invalid numIndexTerms: \" + numIndexTerms + \" (resource=\" + in + \")\");\n        }\n        final long termsStart = in.readVLong();\n        final long indexStart = in.readVLong();\n        final long packedIndexStart = in.readVLong();\n        final long packedOffsetsStart = in.readVLong();\n        if (packedIndexStart < indexStart) {\n          throw new CorruptIndexException(\"invalid packedIndexStart: \" + packedIndexStart + \" indexStart: \" + indexStart + \"numIndexTerms: \" + numIndexTerms + \" (resource=\" + in + \")\");\n        }\n        final FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n        FieldIndexData previous = fields.put(fieldInfo, new FieldIndexData(in, indexStart, termsStart, packedIndexStart, packedOffsetsStart, numIndexTerms));\n        if (previous != null) {\n          throw new CorruptIndexException(\"duplicate field: \" + fieldInfo.name + \" (resource=\" + in + \")\");\n        }\n      }\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(in);\n      } else {\n        IOUtils.closeWhileHandlingException(in);\n      }\n      termBytesReader = termBytes.freeze(true);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"5eb2511ababf862ea11e10761c70ee560cd84510","date":1396607225,"type":3,"author":"Dawid Weiss","isMerge":true,"pathNew":"lucene/codecs/src/java/org/apache/lucene/codecs/blockterms/FixedGapTermsIndexReader#FixedGapTermsIndexReader(Directory,FieldInfos,String,Comparator[BytesRef],String,IOContext).mjava","pathOld":"lucene/codecs/src/java/org/apache/lucene/codecs/blockterms/FixedGapTermsIndexReader#FixedGapTermsIndexReader(Directory,FieldInfos,String,Comparator[BytesRef],String,IOContext).mjava","sourceNew":"  public FixedGapTermsIndexReader(Directory dir, FieldInfos fieldInfos, String segment, Comparator<BytesRef> termComp, String segmentSuffix, IOContext context)\n    throws IOException {\n\n    this.termComp = termComp;\n    \n    final IndexInput in = dir.openInput(IndexFileNames.segmentFileName(segment, segmentSuffix, FixedGapTermsIndexWriter.TERMS_INDEX_EXTENSION), context);\n    \n    boolean success = false;\n\n    try {\n      \n      readHeader(in);\n      \n      if (version >= FixedGapTermsIndexWriter.VERSION_CHECKSUM) {\n        CodecUtil.checksumEntireFile(in);\n      }\n      \n      indexInterval = in.readVInt();\n      if (indexInterval < 1) {\n        throw new CorruptIndexException(\"invalid indexInterval: \" + indexInterval + \" (resource=\" + in + \")\");\n      }\n      packedIntsVersion = in.readVInt();\n      blocksize = in.readVInt();\n      \n      seekDir(in, dirOffset);\n\n      // Read directory\n      final int numFields = in.readVInt();     \n      if (numFields < 0) {\n        throw new CorruptIndexException(\"invalid numFields: \" + numFields + \" (resource=\" + in + \")\");\n      }\n      //System.out.println(\"FGR: init seg=\" + segment + \" div=\" + indexDivisor + \" nF=\" + numFields);\n      for(int i=0;i<numFields;i++) {\n        final int field = in.readVInt();\n        final long numIndexTerms = in.readVInt(); // TODO: change this to a vLong if we fix writer to support > 2B index terms\n        if (numIndexTerms < 0) {\n          throw new CorruptIndexException(\"invalid numIndexTerms: \" + numIndexTerms + \" (resource=\" + in + \")\");\n        }\n        final long termsStart = in.readVLong();\n        final long indexStart = in.readVLong();\n        final long packedIndexStart = in.readVLong();\n        final long packedOffsetsStart = in.readVLong();\n        if (packedIndexStart < indexStart) {\n          throw new CorruptIndexException(\"invalid packedIndexStart: \" + packedIndexStart + \" indexStart: \" + indexStart + \"numIndexTerms: \" + numIndexTerms + \" (resource=\" + in + \")\");\n        }\n        final FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n        FieldIndexData previous = fields.put(fieldInfo, new FieldIndexData(in, indexStart, termsStart, packedIndexStart, packedOffsetsStart, numIndexTerms));\n        if (previous != null) {\n          throw new CorruptIndexException(\"duplicate field: \" + fieldInfo.name + \" (resource=\" + in + \")\");\n        }\n      }\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(in);\n      } else {\n        IOUtils.closeWhileHandlingException(in);\n      }\n      termBytesReader = termBytes.freeze(true);\n    }\n  }\n\n","sourceOld":"  public FixedGapTermsIndexReader(Directory dir, FieldInfos fieldInfos, String segment, Comparator<BytesRef> termComp, String segmentSuffix, IOContext context)\n    throws IOException {\n\n    this.termComp = termComp;\n    \n    final IndexInput in = dir.openInput(IndexFileNames.segmentFileName(segment, segmentSuffix, FixedGapTermsIndexWriter.TERMS_INDEX_EXTENSION), context);\n    \n    boolean success = false;\n\n    try {\n      \n      readHeader(in);\n      indexInterval = in.readVInt();\n      if (indexInterval < 1) {\n        throw new CorruptIndexException(\"invalid indexInterval: \" + indexInterval + \" (resource=\" + in + \")\");\n      }\n      packedIntsVersion = in.readVInt();\n      blocksize = in.readVInt();\n      \n      seekDir(in, dirOffset);\n\n      // Read directory\n      final int numFields = in.readVInt();     \n      if (numFields < 0) {\n        throw new CorruptIndexException(\"invalid numFields: \" + numFields + \" (resource=\" + in + \")\");\n      }\n      //System.out.println(\"FGR: init seg=\" + segment + \" div=\" + indexDivisor + \" nF=\" + numFields);\n      for(int i=0;i<numFields;i++) {\n        final int field = in.readVInt();\n        final long numIndexTerms = in.readVInt(); // TODO: change this to a vLong if we fix writer to support > 2B index terms\n        if (numIndexTerms < 0) {\n          throw new CorruptIndexException(\"invalid numIndexTerms: \" + numIndexTerms + \" (resource=\" + in + \")\");\n        }\n        final long termsStart = in.readVLong();\n        final long indexStart = in.readVLong();\n        final long packedIndexStart = in.readVLong();\n        final long packedOffsetsStart = in.readVLong();\n        if (packedIndexStart < indexStart) {\n          throw new CorruptIndexException(\"invalid packedIndexStart: \" + packedIndexStart + \" indexStart: \" + indexStart + \"numIndexTerms: \" + numIndexTerms + \" (resource=\" + in + \")\");\n        }\n        final FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n        FieldIndexData previous = fields.put(fieldInfo, new FieldIndexData(in, indexStart, termsStart, packedIndexStart, packedOffsetsStart, numIndexTerms));\n        if (previous != null) {\n          throw new CorruptIndexException(\"duplicate field: \" + fieldInfo.name + \" (resource=\" + in + \")\");\n        }\n      }\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(in);\n      } else {\n        IOUtils.closeWhileHandlingException(in);\n      }\n      termBytesReader = termBytes.freeze(true);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d943163030bbd7a9caf93cb5fea92257390a2a99","date":1403094254,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/codecs/src/java/org/apache/lucene/codecs/blockterms/FixedGapTermsIndexReader#FixedGapTermsIndexReader(Directory,FieldInfos,String,Comparator[BytesRef],String,IOContext).mjava","pathOld":"lucene/codecs/src/java/org/apache/lucene/codecs/blockterms/FixedGapTermsIndexReader#FixedGapTermsIndexReader(Directory,FieldInfos,String,Comparator[BytesRef],String,IOContext).mjava","sourceNew":"  public FixedGapTermsIndexReader(Directory dir, FieldInfos fieldInfos, String segment, Comparator<BytesRef> termComp, String segmentSuffix, IOContext context)\n    throws IOException {\n    final PagedBytes termBytes = new PagedBytes(PAGED_BYTES_BITS);\n\n    this.termComp = termComp;\n    \n    final IndexInput in = dir.openInput(IndexFileNames.segmentFileName(segment, segmentSuffix, FixedGapTermsIndexWriter.TERMS_INDEX_EXTENSION), context);\n    \n    boolean success = false;\n\n    try {\n      \n      readHeader(in);\n      \n      if (version >= FixedGapTermsIndexWriter.VERSION_CHECKSUM) {\n        CodecUtil.checksumEntireFile(in);\n      }\n      \n      indexInterval = in.readVInt();\n      if (indexInterval < 1) {\n        throw new CorruptIndexException(\"invalid indexInterval: \" + indexInterval + \" (resource=\" + in + \")\");\n      }\n      packedIntsVersion = in.readVInt();\n      blocksize = in.readVInt();\n      \n      seekDir(in, dirOffset);\n\n      // Read directory\n      final int numFields = in.readVInt();     \n      if (numFields < 0) {\n        throw new CorruptIndexException(\"invalid numFields: \" + numFields + \" (resource=\" + in + \")\");\n      }\n      //System.out.println(\"FGR: init seg=\" + segment + \" div=\" + indexDivisor + \" nF=\" + numFields);\n      for(int i=0;i<numFields;i++) {\n        final int field = in.readVInt();\n        final long numIndexTerms = in.readVInt(); // TODO: change this to a vLong if we fix writer to support > 2B index terms\n        if (numIndexTerms < 0) {\n          throw new CorruptIndexException(\"invalid numIndexTerms: \" + numIndexTerms + \" (resource=\" + in + \")\");\n        }\n        final long termsStart = in.readVLong();\n        final long indexStart = in.readVLong();\n        final long packedIndexStart = in.readVLong();\n        final long packedOffsetsStart = in.readVLong();\n        if (packedIndexStart < indexStart) {\n          throw new CorruptIndexException(\"invalid packedIndexStart: \" + packedIndexStart + \" indexStart: \" + indexStart + \"numIndexTerms: \" + numIndexTerms + \" (resource=\" + in + \")\");\n        }\n        final FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n        FieldIndexData previous = fields.put(fieldInfo, new FieldIndexData(in, termBytes, indexStart, termsStart, packedIndexStart, packedOffsetsStart, numIndexTerms));\n        if (previous != null) {\n          throw new CorruptIndexException(\"duplicate field: \" + fieldInfo.name + \" (resource=\" + in + \")\");\n        }\n      }\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(in);\n      } else {\n        IOUtils.closeWhileHandlingException(in);\n      }\n      termBytesReader = termBytes.freeze(true);\n    }\n  }\n\n","sourceOld":"  public FixedGapTermsIndexReader(Directory dir, FieldInfos fieldInfos, String segment, Comparator<BytesRef> termComp, String segmentSuffix, IOContext context)\n    throws IOException {\n\n    this.termComp = termComp;\n    \n    final IndexInput in = dir.openInput(IndexFileNames.segmentFileName(segment, segmentSuffix, FixedGapTermsIndexWriter.TERMS_INDEX_EXTENSION), context);\n    \n    boolean success = false;\n\n    try {\n      \n      readHeader(in);\n      \n      if (version >= FixedGapTermsIndexWriter.VERSION_CHECKSUM) {\n        CodecUtil.checksumEntireFile(in);\n      }\n      \n      indexInterval = in.readVInt();\n      if (indexInterval < 1) {\n        throw new CorruptIndexException(\"invalid indexInterval: \" + indexInterval + \" (resource=\" + in + \")\");\n      }\n      packedIntsVersion = in.readVInt();\n      blocksize = in.readVInt();\n      \n      seekDir(in, dirOffset);\n\n      // Read directory\n      final int numFields = in.readVInt();     \n      if (numFields < 0) {\n        throw new CorruptIndexException(\"invalid numFields: \" + numFields + \" (resource=\" + in + \")\");\n      }\n      //System.out.println(\"FGR: init seg=\" + segment + \" div=\" + indexDivisor + \" nF=\" + numFields);\n      for(int i=0;i<numFields;i++) {\n        final int field = in.readVInt();\n        final long numIndexTerms = in.readVInt(); // TODO: change this to a vLong if we fix writer to support > 2B index terms\n        if (numIndexTerms < 0) {\n          throw new CorruptIndexException(\"invalid numIndexTerms: \" + numIndexTerms + \" (resource=\" + in + \")\");\n        }\n        final long termsStart = in.readVLong();\n        final long indexStart = in.readVLong();\n        final long packedIndexStart = in.readVLong();\n        final long packedOffsetsStart = in.readVLong();\n        if (packedIndexStart < indexStart) {\n          throw new CorruptIndexException(\"invalid packedIndexStart: \" + packedIndexStart + \" indexStart: \" + indexStart + \"numIndexTerms: \" + numIndexTerms + \" (resource=\" + in + \")\");\n        }\n        final FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n        FieldIndexData previous = fields.put(fieldInfo, new FieldIndexData(in, indexStart, termsStart, packedIndexStart, packedOffsetsStart, numIndexTerms));\n        if (previous != null) {\n          throw new CorruptIndexException(\"duplicate field: \" + fieldInfo.name + \" (resource=\" + in + \")\");\n        }\n      }\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(in);\n      } else {\n        IOUtils.closeWhileHandlingException(in);\n      }\n      termBytesReader = termBytes.freeze(true);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"e57c73924f3b8c19defa62e96bfa34a4922d49c2","date":1403106358,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/codecs/src/java/org/apache/lucene/codecs/blockterms/FixedGapTermsIndexReader#FixedGapTermsIndexReader(Directory,FieldInfos,String,Comparator[BytesRef],String,IOContext).mjava","pathOld":"lucene/codecs/src/java/org/apache/lucene/codecs/blockterms/FixedGapTermsIndexReader#FixedGapTermsIndexReader(Directory,FieldInfos,String,Comparator[BytesRef],String,IOContext).mjava","sourceNew":"  public FixedGapTermsIndexReader(Directory dir, FieldInfos fieldInfos, String segment, Comparator<BytesRef> termComp, String segmentSuffix, IOContext context)\n    throws IOException {\n    final PagedBytes termBytes = new PagedBytes(PAGED_BYTES_BITS);\n\n    this.termComp = termComp;\n    \n    final IndexInput in = dir.openInput(IndexFileNames.segmentFileName(segment, segmentSuffix, FixedGapTermsIndexWriter.TERMS_INDEX_EXTENSION), context);\n    \n    boolean success = false;\n\n    try {\n      \n      readHeader(in);\n      \n      if (version >= FixedGapTermsIndexWriter.VERSION_CHECKSUM) {\n        CodecUtil.checksumEntireFile(in);\n      }\n      \n      indexInterval = in.readVInt();\n      if (indexInterval < 1) {\n        throw new CorruptIndexException(\"invalid indexInterval: \" + indexInterval + \" (resource=\" + in + \")\");\n      }\n      packedIntsVersion = in.readVInt();\n      blocksize = in.readVInt();\n      \n      seekDir(in, dirOffset);\n\n      // Read directory\n      final int numFields = in.readVInt();     \n      if (numFields < 0) {\n        throw new CorruptIndexException(\"invalid numFields: \" + numFields + \" (resource=\" + in + \")\");\n      }\n      //System.out.println(\"FGR: init seg=\" + segment + \" div=\" + indexDivisor + \" nF=\" + numFields);\n      for(int i=0;i<numFields;i++) {\n        final int field = in.readVInt();\n        final long numIndexTerms = in.readVInt(); // TODO: change this to a vLong if we fix writer to support > 2B index terms\n        if (numIndexTerms < 0) {\n          throw new CorruptIndexException(\"invalid numIndexTerms: \" + numIndexTerms + \" (resource=\" + in + \")\");\n        }\n        final long termsStart = in.readVLong();\n        final long indexStart = in.readVLong();\n        final long packedIndexStart = in.readVLong();\n        final long packedOffsetsStart = in.readVLong();\n        if (packedIndexStart < indexStart) {\n          throw new CorruptIndexException(\"invalid packedIndexStart: \" + packedIndexStart + \" indexStart: \" + indexStart + \"numIndexTerms: \" + numIndexTerms + \" (resource=\" + in + \")\");\n        }\n        final FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n        FieldIndexData previous = fields.put(fieldInfo, new FieldIndexData(in, termBytes, indexStart, termsStart, packedIndexStart, packedOffsetsStart, numIndexTerms));\n        if (previous != null) {\n          throw new CorruptIndexException(\"duplicate field: \" + fieldInfo.name + \" (resource=\" + in + \")\");\n        }\n      }\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(in);\n      } else {\n        IOUtils.closeWhileHandlingException(in);\n      }\n      termBytesReader = termBytes.freeze(true);\n    }\n  }\n\n","sourceOld":"  public FixedGapTermsIndexReader(Directory dir, FieldInfos fieldInfos, String segment, Comparator<BytesRef> termComp, String segmentSuffix, IOContext context)\n    throws IOException {\n\n    this.termComp = termComp;\n    \n    final IndexInput in = dir.openInput(IndexFileNames.segmentFileName(segment, segmentSuffix, FixedGapTermsIndexWriter.TERMS_INDEX_EXTENSION), context);\n    \n    boolean success = false;\n\n    try {\n      \n      readHeader(in);\n      \n      if (version >= FixedGapTermsIndexWriter.VERSION_CHECKSUM) {\n        CodecUtil.checksumEntireFile(in);\n      }\n      \n      indexInterval = in.readVInt();\n      if (indexInterval < 1) {\n        throw new CorruptIndexException(\"invalid indexInterval: \" + indexInterval + \" (resource=\" + in + \")\");\n      }\n      packedIntsVersion = in.readVInt();\n      blocksize = in.readVInt();\n      \n      seekDir(in, dirOffset);\n\n      // Read directory\n      final int numFields = in.readVInt();     \n      if (numFields < 0) {\n        throw new CorruptIndexException(\"invalid numFields: \" + numFields + \" (resource=\" + in + \")\");\n      }\n      //System.out.println(\"FGR: init seg=\" + segment + \" div=\" + indexDivisor + \" nF=\" + numFields);\n      for(int i=0;i<numFields;i++) {\n        final int field = in.readVInt();\n        final long numIndexTerms = in.readVInt(); // TODO: change this to a vLong if we fix writer to support > 2B index terms\n        if (numIndexTerms < 0) {\n          throw new CorruptIndexException(\"invalid numIndexTerms: \" + numIndexTerms + \" (resource=\" + in + \")\");\n        }\n        final long termsStart = in.readVLong();\n        final long indexStart = in.readVLong();\n        final long packedIndexStart = in.readVLong();\n        final long packedOffsetsStart = in.readVLong();\n        if (packedIndexStart < indexStart) {\n          throw new CorruptIndexException(\"invalid packedIndexStart: \" + packedIndexStart + \" indexStart: \" + indexStart + \"numIndexTerms: \" + numIndexTerms + \" (resource=\" + in + \")\");\n        }\n        final FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n        FieldIndexData previous = fields.put(fieldInfo, new FieldIndexData(in, indexStart, termsStart, packedIndexStart, packedOffsetsStart, numIndexTerms));\n        if (previous != null) {\n          throw new CorruptIndexException(\"duplicate field: \" + fieldInfo.name + \" (resource=\" + in + \")\");\n        }\n      }\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(in);\n      } else {\n        IOUtils.closeWhileHandlingException(in);\n      }\n      termBytesReader = termBytes.freeze(true);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0936055c0eed56be3e4ae5c9db5b0e355390736a","date":1410874015,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/codecs/src/java/org/apache/lucene/codecs/blockterms/FixedGapTermsIndexReader#FixedGapTermsIndexReader(Directory,FieldInfos,String,Comparator[BytesRef],String,IOContext).mjava","pathOld":"lucene/codecs/src/java/org/apache/lucene/codecs/blockterms/FixedGapTermsIndexReader#FixedGapTermsIndexReader(Directory,FieldInfos,String,Comparator[BytesRef],String,IOContext).mjava","sourceNew":"  public FixedGapTermsIndexReader(Directory dir, FieldInfos fieldInfos, String segment, Comparator<BytesRef> termComp, String segmentSuffix, IOContext context)\n    throws IOException {\n    final PagedBytes termBytes = new PagedBytes(PAGED_BYTES_BITS);\n\n    this.termComp = termComp;\n    \n    final IndexInput in = dir.openInput(IndexFileNames.segmentFileName(segment, segmentSuffix, FixedGapTermsIndexWriter.TERMS_INDEX_EXTENSION), context);\n    \n    boolean success = false;\n\n    try {\n      \n      readHeader(in);\n      \n      if (version >= FixedGapTermsIndexWriter.VERSION_CHECKSUM) {\n        CodecUtil.checksumEntireFile(in);\n      }\n      \n      indexInterval = in.readVInt();\n      if (indexInterval < 1) {\n        throw new CorruptIndexException(\"invalid indexInterval: \" + indexInterval + \" (resource=\" + in + \")\");\n      }\n      packedIntsVersion = in.readVInt();\n      blocksize = in.readVInt();\n      \n      seekDir(in, dirOffset);\n\n      // Read directory\n      final int numFields = in.readVInt();     \n      if (numFields < 0) {\n        throw new CorruptIndexException(\"invalid numFields: \" + numFields + \" (resource=\" + in + \")\");\n      }\n      //System.out.println(\"FGR: init seg=\" + segment + \" div=\" + indexDivisor + \" nF=\" + numFields);\n      for(int i=0;i<numFields;i++) {\n        final int field = in.readVInt();\n        final long numIndexTerms = in.readVInt(); // TODO: change this to a vLong if we fix writer to support > 2B index terms\n        if (numIndexTerms < 0) {\n          throw new CorruptIndexException(\"invalid numIndexTerms: \" + numIndexTerms + \" (resource=\" + in + \")\");\n        }\n        final long termsStart = in.readVLong();\n        final long indexStart = in.readVLong();\n        final long packedIndexStart = in.readVLong();\n        final long packedOffsetsStart = in.readVLong();\n        if (packedIndexStart < indexStart) {\n          throw new CorruptIndexException(\"invalid packedIndexStart: \" + packedIndexStart + \" indexStart: \" + indexStart + \"numIndexTerms: \" + numIndexTerms + \" (resource=\" + in + \")\");\n        }\n        final FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n        FieldIndexData previous = fields.put(fieldInfo.name, new FieldIndexData(in, termBytes, indexStart, termsStart, packedIndexStart, packedOffsetsStart, numIndexTerms));\n        if (previous != null) {\n          throw new CorruptIndexException(\"duplicate field: \" + fieldInfo.name + \" (resource=\" + in + \")\");\n        }\n      }\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(in);\n      } else {\n        IOUtils.closeWhileHandlingException(in);\n      }\n      termBytesReader = termBytes.freeze(true);\n    }\n  }\n\n","sourceOld":"  public FixedGapTermsIndexReader(Directory dir, FieldInfos fieldInfos, String segment, Comparator<BytesRef> termComp, String segmentSuffix, IOContext context)\n    throws IOException {\n    final PagedBytes termBytes = new PagedBytes(PAGED_BYTES_BITS);\n\n    this.termComp = termComp;\n    \n    final IndexInput in = dir.openInput(IndexFileNames.segmentFileName(segment, segmentSuffix, FixedGapTermsIndexWriter.TERMS_INDEX_EXTENSION), context);\n    \n    boolean success = false;\n\n    try {\n      \n      readHeader(in);\n      \n      if (version >= FixedGapTermsIndexWriter.VERSION_CHECKSUM) {\n        CodecUtil.checksumEntireFile(in);\n      }\n      \n      indexInterval = in.readVInt();\n      if (indexInterval < 1) {\n        throw new CorruptIndexException(\"invalid indexInterval: \" + indexInterval + \" (resource=\" + in + \")\");\n      }\n      packedIntsVersion = in.readVInt();\n      blocksize = in.readVInt();\n      \n      seekDir(in, dirOffset);\n\n      // Read directory\n      final int numFields = in.readVInt();     \n      if (numFields < 0) {\n        throw new CorruptIndexException(\"invalid numFields: \" + numFields + \" (resource=\" + in + \")\");\n      }\n      //System.out.println(\"FGR: init seg=\" + segment + \" div=\" + indexDivisor + \" nF=\" + numFields);\n      for(int i=0;i<numFields;i++) {\n        final int field = in.readVInt();\n        final long numIndexTerms = in.readVInt(); // TODO: change this to a vLong if we fix writer to support > 2B index terms\n        if (numIndexTerms < 0) {\n          throw new CorruptIndexException(\"invalid numIndexTerms: \" + numIndexTerms + \" (resource=\" + in + \")\");\n        }\n        final long termsStart = in.readVLong();\n        final long indexStart = in.readVLong();\n        final long packedIndexStart = in.readVLong();\n        final long packedOffsetsStart = in.readVLong();\n        if (packedIndexStart < indexStart) {\n          throw new CorruptIndexException(\"invalid packedIndexStart: \" + packedIndexStart + \" indexStart: \" + indexStart + \"numIndexTerms: \" + numIndexTerms + \" (resource=\" + in + \")\");\n        }\n        final FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n        FieldIndexData previous = fields.put(fieldInfo, new FieldIndexData(in, termBytes, indexStart, termsStart, packedIndexStart, packedOffsetsStart, numIndexTerms));\n        if (previous != null) {\n          throw new CorruptIndexException(\"duplicate field: \" + fieldInfo.name + \" (resource=\" + in + \")\");\n        }\n      }\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(in);\n      } else {\n        IOUtils.closeWhileHandlingException(in);\n      }\n      termBytesReader = termBytes.freeze(true);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"9a70ce9bddc6f985feb8e5e182aebe20872328d4","date":1411172748,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/codecs/src/java/org/apache/lucene/codecs/blockterms/FixedGapTermsIndexReader#FixedGapTermsIndexReader(Directory,FieldInfos,String,Comparator[BytesRef],String,IOContext).mjava","pathOld":"lucene/codecs/src/java/org/apache/lucene/codecs/blockterms/FixedGapTermsIndexReader#FixedGapTermsIndexReader(Directory,FieldInfos,String,Comparator[BytesRef],String,IOContext).mjava","sourceNew":"  public FixedGapTermsIndexReader(Directory dir, FieldInfos fieldInfos, String segment, Comparator<BytesRef> termComp, String segmentSuffix, IOContext context)\n    throws IOException {\n    final PagedBytes termBytes = new PagedBytes(PAGED_BYTES_BITS);\n\n    this.termComp = termComp;\n    \n    final IndexInput in = dir.openInput(IndexFileNames.segmentFileName(segment, segmentSuffix, FixedGapTermsIndexWriter.TERMS_INDEX_EXTENSION), context);\n    \n    boolean success = false;\n\n    try {\n      \n      readHeader(in);\n      \n      if (version >= FixedGapTermsIndexWriter.VERSION_CHECKSUM) {\n        CodecUtil.checksumEntireFile(in);\n      }\n      \n      indexInterval = in.readVInt();\n      if (indexInterval < 1) {\n        throw new CorruptIndexException(\"invalid indexInterval: \" + indexInterval, in);\n      }\n      packedIntsVersion = in.readVInt();\n      blocksize = in.readVInt();\n      \n      seekDir(in, dirOffset);\n\n      // Read directory\n      final int numFields = in.readVInt();     \n      if (numFields < 0) {\n        throw new CorruptIndexException(\"invalid numFields: \" + numFields, in);\n      }\n      //System.out.println(\"FGR: init seg=\" + segment + \" div=\" + indexDivisor + \" nF=\" + numFields);\n      for(int i=0;i<numFields;i++) {\n        final int field = in.readVInt();\n        final long numIndexTerms = in.readVInt(); // TODO: change this to a vLong if we fix writer to support > 2B index terms\n        if (numIndexTerms < 0) {\n          throw new CorruptIndexException(\"invalid numIndexTerms: \" + numIndexTerms, in);\n        }\n        final long termsStart = in.readVLong();\n        final long indexStart = in.readVLong();\n        final long packedIndexStart = in.readVLong();\n        final long packedOffsetsStart = in.readVLong();\n        if (packedIndexStart < indexStart) {\n          throw new CorruptIndexException(\"invalid packedIndexStart: \" + packedIndexStart + \" indexStart: \" + indexStart + \"numIndexTerms: \" + numIndexTerms, in);\n        }\n        final FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n        FieldIndexData previous = fields.put(fieldInfo.name, new FieldIndexData(in, termBytes, indexStart, termsStart, packedIndexStart, packedOffsetsStart, numIndexTerms));\n        if (previous != null) {\n          throw new CorruptIndexException(\"duplicate field: \" + fieldInfo.name, in);\n        }\n      }\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(in);\n      } else {\n        IOUtils.closeWhileHandlingException(in);\n      }\n      termBytesReader = termBytes.freeze(true);\n    }\n  }\n\n","sourceOld":"  public FixedGapTermsIndexReader(Directory dir, FieldInfos fieldInfos, String segment, Comparator<BytesRef> termComp, String segmentSuffix, IOContext context)\n    throws IOException {\n    final PagedBytes termBytes = new PagedBytes(PAGED_BYTES_BITS);\n\n    this.termComp = termComp;\n    \n    final IndexInput in = dir.openInput(IndexFileNames.segmentFileName(segment, segmentSuffix, FixedGapTermsIndexWriter.TERMS_INDEX_EXTENSION), context);\n    \n    boolean success = false;\n\n    try {\n      \n      readHeader(in);\n      \n      if (version >= FixedGapTermsIndexWriter.VERSION_CHECKSUM) {\n        CodecUtil.checksumEntireFile(in);\n      }\n      \n      indexInterval = in.readVInt();\n      if (indexInterval < 1) {\n        throw new CorruptIndexException(\"invalid indexInterval: \" + indexInterval + \" (resource=\" + in + \")\");\n      }\n      packedIntsVersion = in.readVInt();\n      blocksize = in.readVInt();\n      \n      seekDir(in, dirOffset);\n\n      // Read directory\n      final int numFields = in.readVInt();     \n      if (numFields < 0) {\n        throw new CorruptIndexException(\"invalid numFields: \" + numFields + \" (resource=\" + in + \")\");\n      }\n      //System.out.println(\"FGR: init seg=\" + segment + \" div=\" + indexDivisor + \" nF=\" + numFields);\n      for(int i=0;i<numFields;i++) {\n        final int field = in.readVInt();\n        final long numIndexTerms = in.readVInt(); // TODO: change this to a vLong if we fix writer to support > 2B index terms\n        if (numIndexTerms < 0) {\n          throw new CorruptIndexException(\"invalid numIndexTerms: \" + numIndexTerms + \" (resource=\" + in + \")\");\n        }\n        final long termsStart = in.readVLong();\n        final long indexStart = in.readVLong();\n        final long packedIndexStart = in.readVLong();\n        final long packedOffsetsStart = in.readVLong();\n        if (packedIndexStart < indexStart) {\n          throw new CorruptIndexException(\"invalid packedIndexStart: \" + packedIndexStart + \" indexStart: \" + indexStart + \"numIndexTerms: \" + numIndexTerms + \" (resource=\" + in + \")\");\n        }\n        final FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n        FieldIndexData previous = fields.put(fieldInfo.name, new FieldIndexData(in, termBytes, indexStart, termsStart, packedIndexStart, packedOffsetsStart, numIndexTerms));\n        if (previous != null) {\n          throw new CorruptIndexException(\"duplicate field: \" + fieldInfo.name + \" (resource=\" + in + \")\");\n        }\n      }\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(in);\n      } else {\n        IOUtils.closeWhileHandlingException(in);\n      }\n      termBytesReader = termBytes.freeze(true);\n    }\n  }\n\n","bugFix":["6e5adcbe5a27941451fdb6194bcbff96c8630e14"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e6f7d3244902a0689d3acc83eaa8d8a4e8504de1","date":1412165020,"type":5,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/codecs/src/java/org/apache/lucene/codecs/blockterms/FixedGapTermsIndexReader#FixedGapTermsIndexReader(SegmentReadState).mjava","pathOld":"lucene/codecs/src/java/org/apache/lucene/codecs/blockterms/FixedGapTermsIndexReader#FixedGapTermsIndexReader(Directory,FieldInfos,String,Comparator[BytesRef],String,IOContext).mjava","sourceNew":"  public FixedGapTermsIndexReader(SegmentReadState state) throws IOException {\n    final PagedBytes termBytes = new PagedBytes(PAGED_BYTES_BITS);\n    \n    String fileName = IndexFileNames.segmentFileName(state.segmentInfo.name, \n                                                     state.segmentSuffix, \n                                                     FixedGapTermsIndexWriter.TERMS_INDEX_EXTENSION);\n    final IndexInput in = state.directory.openInput(fileName, state.context);\n    \n    boolean success = false;\n\n    try {\n      \n      CodecUtil.checkSegmentHeader(in, FixedGapTermsIndexWriter.CODEC_NAME,\n                                       FixedGapTermsIndexWriter.VERSION_CURRENT, \n                                       FixedGapTermsIndexWriter.VERSION_CURRENT,\n                                       state.segmentInfo.getId(), state.segmentSuffix);\n      \n      CodecUtil.checksumEntireFile(in);\n      \n      indexInterval = in.readVInt();\n      if (indexInterval < 1) {\n        throw new CorruptIndexException(\"invalid indexInterval: \" + indexInterval, in);\n      }\n      packedIntsVersion = in.readVInt();\n      blocksize = in.readVInt();\n      \n      seekDir(in);\n\n      // Read directory\n      final int numFields = in.readVInt();     \n      if (numFields < 0) {\n        throw new CorruptIndexException(\"invalid numFields: \" + numFields, in);\n      }\n      //System.out.println(\"FGR: init seg=\" + segment + \" div=\" + indexDivisor + \" nF=\" + numFields);\n      for(int i=0;i<numFields;i++) {\n        final int field = in.readVInt();\n        final long numIndexTerms = in.readVInt(); // TODO: change this to a vLong if we fix writer to support > 2B index terms\n        if (numIndexTerms < 0) {\n          throw new CorruptIndexException(\"invalid numIndexTerms: \" + numIndexTerms, in);\n        }\n        final long termsStart = in.readVLong();\n        final long indexStart = in.readVLong();\n        final long packedIndexStart = in.readVLong();\n        final long packedOffsetsStart = in.readVLong();\n        if (packedIndexStart < indexStart) {\n          throw new CorruptIndexException(\"invalid packedIndexStart: \" + packedIndexStart + \" indexStart: \" + indexStart + \"numIndexTerms: \" + numIndexTerms, in);\n        }\n        final FieldInfo fieldInfo = state.fieldInfos.fieldInfo(field);\n        FieldIndexData previous = fields.put(fieldInfo.name, new FieldIndexData(in, termBytes, indexStart, termsStart, packedIndexStart, packedOffsetsStart, numIndexTerms));\n        if (previous != null) {\n          throw new CorruptIndexException(\"duplicate field: \" + fieldInfo.name, in);\n        }\n      }\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(in);\n      } else {\n        IOUtils.closeWhileHandlingException(in);\n      }\n      termBytesReader = termBytes.freeze(true);\n    }\n  }\n\n","sourceOld":"  public FixedGapTermsIndexReader(Directory dir, FieldInfos fieldInfos, String segment, Comparator<BytesRef> termComp, String segmentSuffix, IOContext context)\n    throws IOException {\n    final PagedBytes termBytes = new PagedBytes(PAGED_BYTES_BITS);\n\n    this.termComp = termComp;\n    \n    final IndexInput in = dir.openInput(IndexFileNames.segmentFileName(segment, segmentSuffix, FixedGapTermsIndexWriter.TERMS_INDEX_EXTENSION), context);\n    \n    boolean success = false;\n\n    try {\n      \n      readHeader(in);\n      \n      if (version >= FixedGapTermsIndexWriter.VERSION_CHECKSUM) {\n        CodecUtil.checksumEntireFile(in);\n      }\n      \n      indexInterval = in.readVInt();\n      if (indexInterval < 1) {\n        throw new CorruptIndexException(\"invalid indexInterval: \" + indexInterval, in);\n      }\n      packedIntsVersion = in.readVInt();\n      blocksize = in.readVInt();\n      \n      seekDir(in, dirOffset);\n\n      // Read directory\n      final int numFields = in.readVInt();     \n      if (numFields < 0) {\n        throw new CorruptIndexException(\"invalid numFields: \" + numFields, in);\n      }\n      //System.out.println(\"FGR: init seg=\" + segment + \" div=\" + indexDivisor + \" nF=\" + numFields);\n      for(int i=0;i<numFields;i++) {\n        final int field = in.readVInt();\n        final long numIndexTerms = in.readVInt(); // TODO: change this to a vLong if we fix writer to support > 2B index terms\n        if (numIndexTerms < 0) {\n          throw new CorruptIndexException(\"invalid numIndexTerms: \" + numIndexTerms, in);\n        }\n        final long termsStart = in.readVLong();\n        final long indexStart = in.readVLong();\n        final long packedIndexStart = in.readVLong();\n        final long packedOffsetsStart = in.readVLong();\n        if (packedIndexStart < indexStart) {\n          throw new CorruptIndexException(\"invalid packedIndexStart: \" + packedIndexStart + \" indexStart: \" + indexStart + \"numIndexTerms: \" + numIndexTerms, in);\n        }\n        final FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n        FieldIndexData previous = fields.put(fieldInfo.name, new FieldIndexData(in, termBytes, indexStart, termsStart, packedIndexStart, packedOffsetsStart, numIndexTerms));\n        if (previous != null) {\n          throw new CorruptIndexException(\"duplicate field: \" + fieldInfo.name, in);\n        }\n      }\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(in);\n      } else {\n        IOUtils.closeWhileHandlingException(in);\n      }\n      termBytesReader = termBytes.freeze(true);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9bb9a29a5e71a90295f175df8919802993142c9a","date":1412517673,"type":5,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/codecs/src/java/org/apache/lucene/codecs/blockterms/FixedGapTermsIndexReader#FixedGapTermsIndexReader(SegmentReadState).mjava","pathOld":"lucene/codecs/src/java/org/apache/lucene/codecs/blockterms/FixedGapTermsIndexReader#FixedGapTermsIndexReader(Directory,FieldInfos,String,Comparator[BytesRef],String,IOContext).mjava","sourceNew":"  public FixedGapTermsIndexReader(SegmentReadState state) throws IOException {\n    final PagedBytes termBytes = new PagedBytes(PAGED_BYTES_BITS);\n    \n    String fileName = IndexFileNames.segmentFileName(state.segmentInfo.name, \n                                                     state.segmentSuffix, \n                                                     FixedGapTermsIndexWriter.TERMS_INDEX_EXTENSION);\n    final IndexInput in = state.directory.openInput(fileName, state.context);\n    \n    boolean success = false;\n\n    try {\n      \n      CodecUtil.checkSegmentHeader(in, FixedGapTermsIndexWriter.CODEC_NAME,\n                                       FixedGapTermsIndexWriter.VERSION_CURRENT, \n                                       FixedGapTermsIndexWriter.VERSION_CURRENT,\n                                       state.segmentInfo.getId(), state.segmentSuffix);\n      \n      CodecUtil.checksumEntireFile(in);\n      \n      indexInterval = in.readVInt();\n      if (indexInterval < 1) {\n        throw new CorruptIndexException(\"invalid indexInterval: \" + indexInterval, in);\n      }\n      packedIntsVersion = in.readVInt();\n      blocksize = in.readVInt();\n      \n      seekDir(in);\n\n      // Read directory\n      final int numFields = in.readVInt();     \n      if (numFields < 0) {\n        throw new CorruptIndexException(\"invalid numFields: \" + numFields, in);\n      }\n      //System.out.println(\"FGR: init seg=\" + segment + \" div=\" + indexDivisor + \" nF=\" + numFields);\n      for(int i=0;i<numFields;i++) {\n        final int field = in.readVInt();\n        final long numIndexTerms = in.readVInt(); // TODO: change this to a vLong if we fix writer to support > 2B index terms\n        if (numIndexTerms < 0) {\n          throw new CorruptIndexException(\"invalid numIndexTerms: \" + numIndexTerms, in);\n        }\n        final long termsStart = in.readVLong();\n        final long indexStart = in.readVLong();\n        final long packedIndexStart = in.readVLong();\n        final long packedOffsetsStart = in.readVLong();\n        if (packedIndexStart < indexStart) {\n          throw new CorruptIndexException(\"invalid packedIndexStart: \" + packedIndexStart + \" indexStart: \" + indexStart + \"numIndexTerms: \" + numIndexTerms, in);\n        }\n        final FieldInfo fieldInfo = state.fieldInfos.fieldInfo(field);\n        FieldIndexData previous = fields.put(fieldInfo.name, new FieldIndexData(in, termBytes, indexStart, termsStart, packedIndexStart, packedOffsetsStart, numIndexTerms));\n        if (previous != null) {\n          throw new CorruptIndexException(\"duplicate field: \" + fieldInfo.name, in);\n        }\n      }\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(in);\n      } else {\n        IOUtils.closeWhileHandlingException(in);\n      }\n      termBytesReader = termBytes.freeze(true);\n    }\n  }\n\n","sourceOld":"  public FixedGapTermsIndexReader(Directory dir, FieldInfos fieldInfos, String segment, Comparator<BytesRef> termComp, String segmentSuffix, IOContext context)\n    throws IOException {\n    final PagedBytes termBytes = new PagedBytes(PAGED_BYTES_BITS);\n\n    this.termComp = termComp;\n    \n    final IndexInput in = dir.openInput(IndexFileNames.segmentFileName(segment, segmentSuffix, FixedGapTermsIndexWriter.TERMS_INDEX_EXTENSION), context);\n    \n    boolean success = false;\n\n    try {\n      \n      readHeader(in);\n      \n      if (version >= FixedGapTermsIndexWriter.VERSION_CHECKSUM) {\n        CodecUtil.checksumEntireFile(in);\n      }\n      \n      indexInterval = in.readVInt();\n      if (indexInterval < 1) {\n        throw new CorruptIndexException(\"invalid indexInterval: \" + indexInterval, in);\n      }\n      packedIntsVersion = in.readVInt();\n      blocksize = in.readVInt();\n      \n      seekDir(in, dirOffset);\n\n      // Read directory\n      final int numFields = in.readVInt();     \n      if (numFields < 0) {\n        throw new CorruptIndexException(\"invalid numFields: \" + numFields, in);\n      }\n      //System.out.println(\"FGR: init seg=\" + segment + \" div=\" + indexDivisor + \" nF=\" + numFields);\n      for(int i=0;i<numFields;i++) {\n        final int field = in.readVInt();\n        final long numIndexTerms = in.readVInt(); // TODO: change this to a vLong if we fix writer to support > 2B index terms\n        if (numIndexTerms < 0) {\n          throw new CorruptIndexException(\"invalid numIndexTerms: \" + numIndexTerms, in);\n        }\n        final long termsStart = in.readVLong();\n        final long indexStart = in.readVLong();\n        final long packedIndexStart = in.readVLong();\n        final long packedOffsetsStart = in.readVLong();\n        if (packedIndexStart < indexStart) {\n          throw new CorruptIndexException(\"invalid packedIndexStart: \" + packedIndexStart + \" indexStart: \" + indexStart + \"numIndexTerms: \" + numIndexTerms, in);\n        }\n        final FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n        FieldIndexData previous = fields.put(fieldInfo.name, new FieldIndexData(in, termBytes, indexStart, termsStart, packedIndexStart, packedOffsetsStart, numIndexTerms));\n        if (previous != null) {\n          throw new CorruptIndexException(\"duplicate field: \" + fieldInfo.name, in);\n        }\n      }\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(in);\n      } else {\n        IOUtils.closeWhileHandlingException(in);\n      }\n      termBytesReader = termBytes.freeze(true);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"5eb2511ababf862ea11e10761c70ee560cd84510":["a45bec74b98f6fc05f52770cfb425739e6563960","1f3b037cd083286b2af89f96e768f85dcd8072d6"],"1f3b037cd083286b2af89f96e768f85dcd8072d6":["a45bec74b98f6fc05f52770cfb425739e6563960"],"9a70ce9bddc6f985feb8e5e182aebe20872328d4":["0936055c0eed56be3e4ae5c9db5b0e355390736a"],"e6f7d3244902a0689d3acc83eaa8d8a4e8504de1":["9a70ce9bddc6f985feb8e5e182aebe20872328d4"],"e57c73924f3b8c19defa62e96bfa34a4922d49c2":["1f3b037cd083286b2af89f96e768f85dcd8072d6","d943163030bbd7a9caf93cb5fea92257390a2a99"],"a45bec74b98f6fc05f52770cfb425739e6563960":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"9bb9a29a5e71a90295f175df8919802993142c9a":["9a70ce9bddc6f985feb8e5e182aebe20872328d4","e6f7d3244902a0689d3acc83eaa8d8a4e8504de1"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"d943163030bbd7a9caf93cb5fea92257390a2a99":["1f3b037cd083286b2af89f96e768f85dcd8072d6"],"8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"0936055c0eed56be3e4ae5c9db5b0e355390736a":["d943163030bbd7a9caf93cb5fea92257390a2a99"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["9bb9a29a5e71a90295f175df8919802993142c9a"]},"commit2Childs":{"5eb2511ababf862ea11e10761c70ee560cd84510":[],"1f3b037cd083286b2af89f96e768f85dcd8072d6":["5eb2511ababf862ea11e10761c70ee560cd84510","e57c73924f3b8c19defa62e96bfa34a4922d49c2","d943163030bbd7a9caf93cb5fea92257390a2a99"],"9a70ce9bddc6f985feb8e5e182aebe20872328d4":["e6f7d3244902a0689d3acc83eaa8d8a4e8504de1","9bb9a29a5e71a90295f175df8919802993142c9a"],"e6f7d3244902a0689d3acc83eaa8d8a4e8504de1":["9bb9a29a5e71a90295f175df8919802993142c9a"],"e57c73924f3b8c19defa62e96bfa34a4922d49c2":[],"a45bec74b98f6fc05f52770cfb425739e6563960":["5eb2511ababf862ea11e10761c70ee560cd84510","1f3b037cd083286b2af89f96e768f85dcd8072d6"],"9bb9a29a5e71a90295f175df8919802993142c9a":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["a45bec74b98f6fc05f52770cfb425739e6563960","8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee"],"d943163030bbd7a9caf93cb5fea92257390a2a99":["e57c73924f3b8c19defa62e96bfa34a4922d49c2","0936055c0eed56be3e4ae5c9db5b0e355390736a"],"8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee":[],"0936055c0eed56be3e4ae5c9db5b0e355390736a":["9a70ce9bddc6f985feb8e5e182aebe20872328d4"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["5eb2511ababf862ea11e10761c70ee560cd84510","e57c73924f3b8c19defa62e96bfa34a4922d49c2","8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}