{"path":"solr/core/src/test/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/BlockPoolSlice#readReplicasFromCache(ReplicaMap,RamDiskReplicaTracker).mjava","commits":[{"id":"44ca189138a5b6e1989d12ab992fab60e235ddc7","date":1549051496,"type":0,"author":"markrmiller","isMerge":false,"pathNew":"solr/core/src/test/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/BlockPoolSlice#readReplicasFromCache(ReplicaMap,RamDiskReplicaTracker).mjava","pathOld":"/dev/null","sourceNew":"  private boolean readReplicasFromCache(ReplicaMap volumeMap,\n                                        final RamDiskReplicaTracker lazyWriteReplicaMap) {\n    ReplicaMap tmpReplicaMap = new ReplicaMap(new AutoCloseableLock());\n    File replicaFile = new File(currentDir, REPLICA_CACHE_FILE);\n    // Check whether the file exists or not.\n    if (!replicaFile.exists()) {\n      LOG.info(\"Replica Cache file: \"+  replicaFile.getPath() +\n          \" doesn't exist \");\n      return false;\n    }\n    long fileLastModifiedTime = replicaFile.lastModified();\n    if (System.currentTimeMillis() > fileLastModifiedTime + replicaCacheExpiry) {\n      LOG.info(\"Replica Cache file: \" + replicaFile.getPath() +\n          \" has gone stale\");\n      // Just to make findbugs happy\n      if (!replicaFile.delete()) {\n        LOG.info(\"Replica Cache file: \" + replicaFile.getPath() +\n            \" cannot be deleted\");\n      }\n      return false;\n    }\n    FileInputStream inputStream = null;\n    try {\n      inputStream = fileIoProvider.getFileInputStream(volume, replicaFile);\n      BlockListAsLongs blocksList =\n          BlockListAsLongs.readFrom(inputStream, maxDataLength);\n      if (blocksList == null) {\n        return false;\n      }\n\n      for (BlockReportReplica replica : blocksList) {\n        switch (replica.getState()) {\n          case FINALIZED:\n            addReplicaToReplicasMap(replica, tmpReplicaMap, lazyWriteReplicaMap, true);\n            break;\n          case RUR:\n          case RBW:\n          case RWR:\n            addReplicaToReplicasMap(replica, tmpReplicaMap, lazyWriteReplicaMap, false);\n            break;\n          default:\n            break;\n        }\n      }\n      // Now it is safe to add the replica into volumeMap\n      // In case of any exception during parsing this cache file, fall back\n      // to scan all the files on disk.\n      for (Iterator<ReplicaInfo> iter =\n           tmpReplicaMap.replicas(bpid).iterator(); iter.hasNext(); ) {\n        ReplicaInfo info = iter.next();\n        // We use a lightweight GSet to store replicaInfo, we need to remove\n        // it from one GSet before adding to another.\n        iter.remove();\n        volumeMap.add(bpid, info);\n      }\n      LOG.info(\"Successfully read replica from cache file : \"\n          + replicaFile.getPath());\n      return true;\n    } catch (Exception e) {\n      // Any exception we need to revert back to read from disk\n      // Log the error and return false\n      LOG.info(\"Exception occurred while reading the replicas cache file: \"\n          + replicaFile.getPath(), e );\n      return false;\n    }\n    finally {\n      // close the inputStream\n      IOUtils.closeStream(inputStream);\n\n      if (!fileIoProvider.delete(volume, replicaFile)) {\n        LOG.info(\"Failed to delete replica cache file: \" +\n            replicaFile.getPath());\n      }\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a966532d92cf9ba2856f15a8140151bb6b518e4b","date":1588290631,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/test/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/BlockPoolSlice#readReplicasFromCache(ReplicaMap,RamDiskReplicaTracker).mjava","pathOld":"solr/core/src/test/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/BlockPoolSlice#readReplicasFromCache(ReplicaMap,RamDiskReplicaTracker).mjava","sourceNew":"  private boolean readReplicasFromCache(ReplicaMap volumeMap,\n                                        final RamDiskReplicaTracker lazyWriteReplicaMap) {\n    ReplicaMap tmpReplicaMap = new ReplicaMap(new AutoCloseableLock());\n    File replicaFile = new File(currentDir, REPLICA_CACHE_FILE);\n    // Check whether the file exists or not.\n    if (!replicaFile.exists()) {\n      if (LOG.isInfoEnabled()) {\n        LOG.info(\"Replica Cache file: {} doesn't exist\", replicaFile.getPath());\n      }\n      return false;\n    }\n    long fileLastModifiedTime = replicaFile.lastModified();\n    if (System.currentTimeMillis() > fileLastModifiedTime + replicaCacheExpiry) {\n      if (LOG.isInfoEnabled()) {\n        LOG.info(\"Replica Cache file: {} has gone stale\", replicaFile.getPath());\n      }\n      // Just to make findbugs happy\n      if (!replicaFile.delete()) {\n        if (LOG.isInfoEnabled()) {\n          LOG.info(\"Replica Cache file: {} cannot be deleted\", replicaFile.getPath());\n        }\n      }\n      return false;\n    }\n    FileInputStream inputStream = null;\n    try {\n      inputStream = fileIoProvider.getFileInputStream(volume, replicaFile);\n      BlockListAsLongs blocksList =\n          BlockListAsLongs.readFrom(inputStream, maxDataLength);\n      if (blocksList == null) {\n        return false;\n      }\n\n      for (BlockReportReplica replica : blocksList) {\n        switch (replica.getState()) {\n          case FINALIZED:\n            addReplicaToReplicasMap(replica, tmpReplicaMap, lazyWriteReplicaMap, true);\n            break;\n          case RUR:\n          case RBW:\n          case RWR:\n            addReplicaToReplicasMap(replica, tmpReplicaMap, lazyWriteReplicaMap, false);\n            break;\n          default:\n            break;\n        }\n      }\n      // Now it is safe to add the replica into volumeMap\n      // In case of any exception during parsing this cache file, fall back\n      // to scan all the files on disk.\n      for (Iterator<ReplicaInfo> iter =\n           tmpReplicaMap.replicas(bpid).iterator(); iter.hasNext(); ) {\n        ReplicaInfo info = iter.next();\n        // We use a lightweight GSet to store replicaInfo, we need to remove\n        // it from one GSet before adding to another.\n        iter.remove();\n        volumeMap.add(bpid, info);\n      }\n      if (LOG.isInfoEnabled()) {\n        LOG.info(\"Successfully read replica from cache file : {}\", replicaFile.getPath());\n      }\n      return true;\n    } catch (Exception e) {\n      // Any exception we need to revert back to read from disk\n      // Log the error and return false\n      if (LOG.isInfoEnabled()) {\n        LOG.info(\"Exception occurred while reading the replicas cache file: {}\", replicaFile.getPath(), e);\n      }\n      return false;\n    }\n    finally {\n      // close the inputStream\n      IOUtils.closeStream(inputStream);\n\n      if (!fileIoProvider.delete(volume, replicaFile)) {\n        if (LOG.isInfoEnabled()) {\n          LOG.info(\"Failed to delete replica cache file: {}\", replicaFile.getPath());\n        }\n      }\n    }\n  }\n\n","sourceOld":"  private boolean readReplicasFromCache(ReplicaMap volumeMap,\n                                        final RamDiskReplicaTracker lazyWriteReplicaMap) {\n    ReplicaMap tmpReplicaMap = new ReplicaMap(new AutoCloseableLock());\n    File replicaFile = new File(currentDir, REPLICA_CACHE_FILE);\n    // Check whether the file exists or not.\n    if (!replicaFile.exists()) {\n      LOG.info(\"Replica Cache file: \"+  replicaFile.getPath() +\n          \" doesn't exist \");\n      return false;\n    }\n    long fileLastModifiedTime = replicaFile.lastModified();\n    if (System.currentTimeMillis() > fileLastModifiedTime + replicaCacheExpiry) {\n      LOG.info(\"Replica Cache file: \" + replicaFile.getPath() +\n          \" has gone stale\");\n      // Just to make findbugs happy\n      if (!replicaFile.delete()) {\n        LOG.info(\"Replica Cache file: \" + replicaFile.getPath() +\n            \" cannot be deleted\");\n      }\n      return false;\n    }\n    FileInputStream inputStream = null;\n    try {\n      inputStream = fileIoProvider.getFileInputStream(volume, replicaFile);\n      BlockListAsLongs blocksList =\n          BlockListAsLongs.readFrom(inputStream, maxDataLength);\n      if (blocksList == null) {\n        return false;\n      }\n\n      for (BlockReportReplica replica : blocksList) {\n        switch (replica.getState()) {\n          case FINALIZED:\n            addReplicaToReplicasMap(replica, tmpReplicaMap, lazyWriteReplicaMap, true);\n            break;\n          case RUR:\n          case RBW:\n          case RWR:\n            addReplicaToReplicasMap(replica, tmpReplicaMap, lazyWriteReplicaMap, false);\n            break;\n          default:\n            break;\n        }\n      }\n      // Now it is safe to add the replica into volumeMap\n      // In case of any exception during parsing this cache file, fall back\n      // to scan all the files on disk.\n      for (Iterator<ReplicaInfo> iter =\n           tmpReplicaMap.replicas(bpid).iterator(); iter.hasNext(); ) {\n        ReplicaInfo info = iter.next();\n        // We use a lightweight GSet to store replicaInfo, we need to remove\n        // it from one GSet before adding to another.\n        iter.remove();\n        volumeMap.add(bpid, info);\n      }\n      LOG.info(\"Successfully read replica from cache file : \"\n          + replicaFile.getPath());\n      return true;\n    } catch (Exception e) {\n      // Any exception we need to revert back to read from disk\n      // Log the error and return false\n      LOG.info(\"Exception occurred while reading the replicas cache file: \"\n          + replicaFile.getPath(), e );\n      return false;\n    }\n    finally {\n      // close the inputStream\n      IOUtils.closeStream(inputStream);\n\n      if (!fileIoProvider.delete(volume, replicaFile)) {\n        LOG.info(\"Failed to delete replica cache file: \" +\n            replicaFile.getPath());\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"44ca189138a5b6e1989d12ab992fab60e235ddc7":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a966532d92cf9ba2856f15a8140151bb6b518e4b":["44ca189138a5b6e1989d12ab992fab60e235ddc7"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["a966532d92cf9ba2856f15a8140151bb6b518e4b"]},"commit2Childs":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["44ca189138a5b6e1989d12ab992fab60e235ddc7"],"44ca189138a5b6e1989d12ab992fab60e235ddc7":["a966532d92cf9ba2856f15a8140151bb6b518e4b"],"a966532d92cf9ba2856f15a8140151bb6b518e4b":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}