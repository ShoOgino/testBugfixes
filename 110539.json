{"path":"lucene/misc/src/java/org/apache/lucene/index/Sorter#sort(int,DocComparator).mjava","commits":[{"id":"82dc51e5dcd7a80b71e40ebe8959b1c43b63f95e","date":1419346542,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/misc/src/java/org/apache/lucene/index/Sorter#sort(int,DocComparator).mjava","pathOld":"lucene/misc/src/java/org/apache/lucene/index/sorter/Sorter#sort(int,DocComparator).mjava","sourceNew":"  /** Computes the old-to-new permutation over the given comparator. */\n  private static Sorter.DocMap sort(final int maxDoc, DocComparator comparator) {\n    // check if the index is sorted\n    boolean sorted = true;\n    for (int i = 1; i < maxDoc; ++i) {\n      if (comparator.compare(i-1, i) > 0) {\n        sorted = false;\n        break;\n      }\n    }\n    if (sorted) {\n      return null;\n    }\n\n    // sort doc IDs\n    final int[] docs = new int[maxDoc];\n    for (int i = 0; i < maxDoc; i++) {\n      docs[i] = i;\n    }\n    \n    DocValueSorter sorter = new DocValueSorter(docs, comparator);\n    // It can be common to sort a reader, add docs, sort it again, ... and in\n    // that case timSort can save a lot of time\n    sorter.sort(0, docs.length); // docs is now the newToOld mapping\n\n    // The reason why we use MonotonicAppendingLongBuffer here is that it\n    // wastes very little memory if the index is in random order but can save\n    // a lot of memory if the index is already \"almost\" sorted\n    final PackedLongValues.Builder newToOldBuilder = PackedLongValues.monotonicBuilder(PackedInts.COMPACT);\n    for (int i = 0; i < maxDoc; ++i) {\n      newToOldBuilder.add(docs[i]);\n    }\n    final PackedLongValues newToOld = newToOldBuilder.build();\n\n    for (int i = 0; i < maxDoc; ++i) {\n      docs[(int) newToOld.get(i)] = i;\n    } // docs is now the oldToNew mapping\n\n    final PackedLongValues.Builder oldToNewBuilder = PackedLongValues.monotonicBuilder(PackedInts.COMPACT);\n    for (int i = 0; i < maxDoc; ++i) {\n      oldToNewBuilder.add(docs[i]);\n    }\n    final PackedLongValues oldToNew = oldToNewBuilder.build();\n    \n    return new Sorter.DocMap() {\n\n      @Override\n      public int oldToNew(int docID) {\n        return (int) oldToNew.get(docID);\n      }\n\n      @Override\n      public int newToOld(int docID) {\n        return (int) newToOld.get(docID);\n      }\n\n      @Override\n      public int size() {\n        return maxDoc;\n      }\n    };\n  }\n\n","sourceOld":"  /** Computes the old-to-new permutation over the given comparator. */\n  private static Sorter.DocMap sort(final int maxDoc, DocComparator comparator) {\n    // check if the index is sorted\n    boolean sorted = true;\n    for (int i = 1; i < maxDoc; ++i) {\n      if (comparator.compare(i-1, i) > 0) {\n        sorted = false;\n        break;\n      }\n    }\n    if (sorted) {\n      return null;\n    }\n\n    // sort doc IDs\n    final int[] docs = new int[maxDoc];\n    for (int i = 0; i < maxDoc; i++) {\n      docs[i] = i;\n    }\n    \n    DocValueSorter sorter = new DocValueSorter(docs, comparator);\n    // It can be common to sort a reader, add docs, sort it again, ... and in\n    // that case timSort can save a lot of time\n    sorter.sort(0, docs.length); // docs is now the newToOld mapping\n\n    // The reason why we use MonotonicAppendingLongBuffer here is that it\n    // wastes very little memory if the index is in random order but can save\n    // a lot of memory if the index is already \"almost\" sorted\n    final PackedLongValues.Builder newToOldBuilder = PackedLongValues.monotonicBuilder(PackedInts.COMPACT);\n    for (int i = 0; i < maxDoc; ++i) {\n      newToOldBuilder.add(docs[i]);\n    }\n    final PackedLongValues newToOld = newToOldBuilder.build();\n\n    for (int i = 0; i < maxDoc; ++i) {\n      docs[(int) newToOld.get(i)] = i;\n    } // docs is now the oldToNew mapping\n\n    final PackedLongValues.Builder oldToNewBuilder = PackedLongValues.monotonicBuilder(PackedInts.COMPACT);\n    for (int i = 0; i < maxDoc; ++i) {\n      oldToNewBuilder.add(docs[i]);\n    }\n    final PackedLongValues oldToNew = oldToNewBuilder.build();\n    \n    return new Sorter.DocMap() {\n\n      @Override\n      public int oldToNew(int docID) {\n        return (int) oldToNew.get(docID);\n      }\n\n      @Override\n      public int newToOld(int docID) {\n        return (int) newToOld.get(docID);\n      }\n\n      @Override\n      public int size() {\n        return maxDoc;\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ceaef6cfc68c8ab22a684192e469a8280f9e6e70","date":1462354657,"type":5,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/Sorter#sort(int,DocComparator).mjava","pathOld":"lucene/misc/src/java/org/apache/lucene/index/Sorter#sort(int,DocComparator).mjava","sourceNew":"  /** Computes the old-to-new permutation over the given comparator. */\n  private static Sorter.DocMap sort(final int maxDoc, DocComparator comparator) {\n    // check if the index is sorted\n    boolean sorted = true;\n    for (int i = 1; i < maxDoc; ++i) {\n      if (comparator.compare(i-1, i) > 0) {\n        sorted = false;\n        break;\n      }\n    }\n    if (sorted) {\n      return null;\n    }\n\n    // sort doc IDs\n    final int[] docs = new int[maxDoc];\n    for (int i = 0; i < maxDoc; i++) {\n      docs[i] = i;\n    }\n    \n    DocValueSorter sorter = new DocValueSorter(docs, comparator);\n    // It can be common to sort a reader, add docs, sort it again, ... and in\n    // that case timSort can save a lot of time\n    sorter.sort(0, docs.length); // docs is now the newToOld mapping\n\n    // The reason why we use MonotonicAppendingLongBuffer here is that it\n    // wastes very little memory if the index is in random order but can save\n    // a lot of memory if the index is already \"almost\" sorted\n    final PackedLongValues.Builder newToOldBuilder = PackedLongValues.monotonicBuilder(PackedInts.COMPACT);\n    for (int i = 0; i < maxDoc; ++i) {\n      newToOldBuilder.add(docs[i]);\n    }\n    final PackedLongValues newToOld = newToOldBuilder.build();\n\n    // invert the docs mapping:\n    for (int i = 0; i < maxDoc; ++i) {\n      docs[(int) newToOld.get(i)] = i;\n    } // docs is now the oldToNew mapping\n\n    final PackedLongValues.Builder oldToNewBuilder = PackedLongValues.monotonicBuilder(PackedInts.COMPACT);\n    for (int i = 0; i < maxDoc; ++i) {\n      oldToNewBuilder.add(docs[i]);\n    }\n    final PackedLongValues oldToNew = oldToNewBuilder.build();\n    \n    return new Sorter.DocMap() {\n\n      @Override\n      public int oldToNew(int docID) {\n        return (int) oldToNew.get(docID);\n      }\n\n      @Override\n      public int newToOld(int docID) {\n        return (int) newToOld.get(docID);\n      }\n\n      @Override\n      public int size() {\n        return maxDoc;\n      }\n    };\n  }\n\n","sourceOld":"  /** Computes the old-to-new permutation over the given comparator. */\n  private static Sorter.DocMap sort(final int maxDoc, DocComparator comparator) {\n    // check if the index is sorted\n    boolean sorted = true;\n    for (int i = 1; i < maxDoc; ++i) {\n      if (comparator.compare(i-1, i) > 0) {\n        sorted = false;\n        break;\n      }\n    }\n    if (sorted) {\n      return null;\n    }\n\n    // sort doc IDs\n    final int[] docs = new int[maxDoc];\n    for (int i = 0; i < maxDoc; i++) {\n      docs[i] = i;\n    }\n    \n    DocValueSorter sorter = new DocValueSorter(docs, comparator);\n    // It can be common to sort a reader, add docs, sort it again, ... and in\n    // that case timSort can save a lot of time\n    sorter.sort(0, docs.length); // docs is now the newToOld mapping\n\n    // The reason why we use MonotonicAppendingLongBuffer here is that it\n    // wastes very little memory if the index is in random order but can save\n    // a lot of memory if the index is already \"almost\" sorted\n    final PackedLongValues.Builder newToOldBuilder = PackedLongValues.monotonicBuilder(PackedInts.COMPACT);\n    for (int i = 0; i < maxDoc; ++i) {\n      newToOldBuilder.add(docs[i]);\n    }\n    final PackedLongValues newToOld = newToOldBuilder.build();\n\n    for (int i = 0; i < maxDoc; ++i) {\n      docs[(int) newToOld.get(i)] = i;\n    } // docs is now the oldToNew mapping\n\n    final PackedLongValues.Builder oldToNewBuilder = PackedLongValues.monotonicBuilder(PackedInts.COMPACT);\n    for (int i = 0; i < maxDoc; ++i) {\n      oldToNewBuilder.add(docs[i]);\n    }\n    final PackedLongValues oldToNew = oldToNewBuilder.build();\n    \n    return new Sorter.DocMap() {\n\n      @Override\n      public int oldToNew(int docID) {\n        return (int) oldToNew.get(docID);\n      }\n\n      @Override\n      public int newToOld(int docID) {\n        return (int) newToOld.get(docID);\n      }\n\n      @Override\n      public int size() {\n        return maxDoc;\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3d33e731a93d4b57e662ff094f64f94a745422d4","date":1463128289,"type":5,"author":"Mike McCandless","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/Sorter#sort(int,DocComparator).mjava","pathOld":"lucene/misc/src/java/org/apache/lucene/index/Sorter#sort(int,DocComparator).mjava","sourceNew":"  /** Computes the old-to-new permutation over the given comparator. */\n  private static Sorter.DocMap sort(final int maxDoc, DocComparator comparator) {\n    // check if the index is sorted\n    boolean sorted = true;\n    for (int i = 1; i < maxDoc; ++i) {\n      if (comparator.compare(i-1, i) > 0) {\n        sorted = false;\n        break;\n      }\n    }\n    if (sorted) {\n      return null;\n    }\n\n    // sort doc IDs\n    final int[] docs = new int[maxDoc];\n    for (int i = 0; i < maxDoc; i++) {\n      docs[i] = i;\n    }\n    \n    DocValueSorter sorter = new DocValueSorter(docs, comparator);\n    // It can be common to sort a reader, add docs, sort it again, ... and in\n    // that case timSort can save a lot of time\n    sorter.sort(0, docs.length); // docs is now the newToOld mapping\n\n    // The reason why we use MonotonicAppendingLongBuffer here is that it\n    // wastes very little memory if the index is in random order but can save\n    // a lot of memory if the index is already \"almost\" sorted\n    final PackedLongValues.Builder newToOldBuilder = PackedLongValues.monotonicBuilder(PackedInts.COMPACT);\n    for (int i = 0; i < maxDoc; ++i) {\n      newToOldBuilder.add(docs[i]);\n    }\n    final PackedLongValues newToOld = newToOldBuilder.build();\n\n    // invert the docs mapping:\n    for (int i = 0; i < maxDoc; ++i) {\n      docs[(int) newToOld.get(i)] = i;\n    } // docs is now the oldToNew mapping\n\n    final PackedLongValues.Builder oldToNewBuilder = PackedLongValues.monotonicBuilder(PackedInts.COMPACT);\n    for (int i = 0; i < maxDoc; ++i) {\n      oldToNewBuilder.add(docs[i]);\n    }\n    final PackedLongValues oldToNew = oldToNewBuilder.build();\n    \n    return new Sorter.DocMap() {\n\n      @Override\n      public int oldToNew(int docID) {\n        return (int) oldToNew.get(docID);\n      }\n\n      @Override\n      public int newToOld(int docID) {\n        return (int) newToOld.get(docID);\n      }\n\n      @Override\n      public int size() {\n        return maxDoc;\n      }\n    };\n  }\n\n","sourceOld":"  /** Computes the old-to-new permutation over the given comparator. */\n  private static Sorter.DocMap sort(final int maxDoc, DocComparator comparator) {\n    // check if the index is sorted\n    boolean sorted = true;\n    for (int i = 1; i < maxDoc; ++i) {\n      if (comparator.compare(i-1, i) > 0) {\n        sorted = false;\n        break;\n      }\n    }\n    if (sorted) {\n      return null;\n    }\n\n    // sort doc IDs\n    final int[] docs = new int[maxDoc];\n    for (int i = 0; i < maxDoc; i++) {\n      docs[i] = i;\n    }\n    \n    DocValueSorter sorter = new DocValueSorter(docs, comparator);\n    // It can be common to sort a reader, add docs, sort it again, ... and in\n    // that case timSort can save a lot of time\n    sorter.sort(0, docs.length); // docs is now the newToOld mapping\n\n    // The reason why we use MonotonicAppendingLongBuffer here is that it\n    // wastes very little memory if the index is in random order but can save\n    // a lot of memory if the index is already \"almost\" sorted\n    final PackedLongValues.Builder newToOldBuilder = PackedLongValues.monotonicBuilder(PackedInts.COMPACT);\n    for (int i = 0; i < maxDoc; ++i) {\n      newToOldBuilder.add(docs[i]);\n    }\n    final PackedLongValues newToOld = newToOldBuilder.build();\n\n    for (int i = 0; i < maxDoc; ++i) {\n      docs[(int) newToOld.get(i)] = i;\n    } // docs is now the oldToNew mapping\n\n    final PackedLongValues.Builder oldToNewBuilder = PackedLongValues.monotonicBuilder(PackedInts.COMPACT);\n    for (int i = 0; i < maxDoc; ++i) {\n      oldToNewBuilder.add(docs[i]);\n    }\n    final PackedLongValues oldToNew = oldToNewBuilder.build();\n    \n    return new Sorter.DocMap() {\n\n      @Override\n      public int oldToNew(int docID) {\n        return (int) oldToNew.get(docID);\n      }\n\n      @Override\n      public int newToOld(int docID) {\n        return (int) newToOld.get(docID);\n      }\n\n      @Override\n      public int size() {\n        return maxDoc;\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0ad30c6a479e764150a3316e57263319775f1df2","date":1463395403,"type":5,"author":"Karl Wright","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/Sorter#sort(int,DocComparator).mjava","pathOld":"lucene/misc/src/java/org/apache/lucene/index/Sorter#sort(int,DocComparator).mjava","sourceNew":"  /** Computes the old-to-new permutation over the given comparator. */\n  private static Sorter.DocMap sort(final int maxDoc, DocComparator comparator) {\n    // check if the index is sorted\n    boolean sorted = true;\n    for (int i = 1; i < maxDoc; ++i) {\n      if (comparator.compare(i-1, i) > 0) {\n        sorted = false;\n        break;\n      }\n    }\n    if (sorted) {\n      return null;\n    }\n\n    // sort doc IDs\n    final int[] docs = new int[maxDoc];\n    for (int i = 0; i < maxDoc; i++) {\n      docs[i] = i;\n    }\n    \n    DocValueSorter sorter = new DocValueSorter(docs, comparator);\n    // It can be common to sort a reader, add docs, sort it again, ... and in\n    // that case timSort can save a lot of time\n    sorter.sort(0, docs.length); // docs is now the newToOld mapping\n\n    // The reason why we use MonotonicAppendingLongBuffer here is that it\n    // wastes very little memory if the index is in random order but can save\n    // a lot of memory if the index is already \"almost\" sorted\n    final PackedLongValues.Builder newToOldBuilder = PackedLongValues.monotonicBuilder(PackedInts.COMPACT);\n    for (int i = 0; i < maxDoc; ++i) {\n      newToOldBuilder.add(docs[i]);\n    }\n    final PackedLongValues newToOld = newToOldBuilder.build();\n\n    // invert the docs mapping:\n    for (int i = 0; i < maxDoc; ++i) {\n      docs[(int) newToOld.get(i)] = i;\n    } // docs is now the oldToNew mapping\n\n    final PackedLongValues.Builder oldToNewBuilder = PackedLongValues.monotonicBuilder(PackedInts.COMPACT);\n    for (int i = 0; i < maxDoc; ++i) {\n      oldToNewBuilder.add(docs[i]);\n    }\n    final PackedLongValues oldToNew = oldToNewBuilder.build();\n    \n    return new Sorter.DocMap() {\n\n      @Override\n      public int oldToNew(int docID) {\n        return (int) oldToNew.get(docID);\n      }\n\n      @Override\n      public int newToOld(int docID) {\n        return (int) newToOld.get(docID);\n      }\n\n      @Override\n      public int size() {\n        return maxDoc;\n      }\n    };\n  }\n\n","sourceOld":"  /** Computes the old-to-new permutation over the given comparator. */\n  private static Sorter.DocMap sort(final int maxDoc, DocComparator comparator) {\n    // check if the index is sorted\n    boolean sorted = true;\n    for (int i = 1; i < maxDoc; ++i) {\n      if (comparator.compare(i-1, i) > 0) {\n        sorted = false;\n        break;\n      }\n    }\n    if (sorted) {\n      return null;\n    }\n\n    // sort doc IDs\n    final int[] docs = new int[maxDoc];\n    for (int i = 0; i < maxDoc; i++) {\n      docs[i] = i;\n    }\n    \n    DocValueSorter sorter = new DocValueSorter(docs, comparator);\n    // It can be common to sort a reader, add docs, sort it again, ... and in\n    // that case timSort can save a lot of time\n    sorter.sort(0, docs.length); // docs is now the newToOld mapping\n\n    // The reason why we use MonotonicAppendingLongBuffer here is that it\n    // wastes very little memory if the index is in random order but can save\n    // a lot of memory if the index is already \"almost\" sorted\n    final PackedLongValues.Builder newToOldBuilder = PackedLongValues.monotonicBuilder(PackedInts.COMPACT);\n    for (int i = 0; i < maxDoc; ++i) {\n      newToOldBuilder.add(docs[i]);\n    }\n    final PackedLongValues newToOld = newToOldBuilder.build();\n\n    for (int i = 0; i < maxDoc; ++i) {\n      docs[(int) newToOld.get(i)] = i;\n    } // docs is now the oldToNew mapping\n\n    final PackedLongValues.Builder oldToNewBuilder = PackedLongValues.monotonicBuilder(PackedInts.COMPACT);\n    for (int i = 0; i < maxDoc; ++i) {\n      oldToNewBuilder.add(docs[i]);\n    }\n    final PackedLongValues oldToNew = oldToNewBuilder.build();\n    \n    return new Sorter.DocMap() {\n\n      @Override\n      public int oldToNew(int docID) {\n        return (int) oldToNew.get(docID);\n      }\n\n      @Override\n      public int newToOld(int docID) {\n        return (int) newToOld.get(docID);\n      }\n\n      @Override\n      public int size() {\n        return maxDoc;\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d470c8182e92b264680e34081b75e70a9f2b3c89","date":1463985353,"type":5,"author":"Noble Paul","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/Sorter#sort(int,DocComparator).mjava","pathOld":"lucene/misc/src/java/org/apache/lucene/index/Sorter#sort(int,DocComparator).mjava","sourceNew":"  /** Computes the old-to-new permutation over the given comparator. */\n  private static Sorter.DocMap sort(final int maxDoc, DocComparator comparator) {\n    // check if the index is sorted\n    boolean sorted = true;\n    for (int i = 1; i < maxDoc; ++i) {\n      if (comparator.compare(i-1, i) > 0) {\n        sorted = false;\n        break;\n      }\n    }\n    if (sorted) {\n      return null;\n    }\n\n    // sort doc IDs\n    final int[] docs = new int[maxDoc];\n    for (int i = 0; i < maxDoc; i++) {\n      docs[i] = i;\n    }\n    \n    DocValueSorter sorter = new DocValueSorter(docs, comparator);\n    // It can be common to sort a reader, add docs, sort it again, ... and in\n    // that case timSort can save a lot of time\n    sorter.sort(0, docs.length); // docs is now the newToOld mapping\n\n    // The reason why we use MonotonicAppendingLongBuffer here is that it\n    // wastes very little memory if the index is in random order but can save\n    // a lot of memory if the index is already \"almost\" sorted\n    final PackedLongValues.Builder newToOldBuilder = PackedLongValues.monotonicBuilder(PackedInts.COMPACT);\n    for (int i = 0; i < maxDoc; ++i) {\n      newToOldBuilder.add(docs[i]);\n    }\n    final PackedLongValues newToOld = newToOldBuilder.build();\n\n    // invert the docs mapping:\n    for (int i = 0; i < maxDoc; ++i) {\n      docs[(int) newToOld.get(i)] = i;\n    } // docs is now the oldToNew mapping\n\n    final PackedLongValues.Builder oldToNewBuilder = PackedLongValues.monotonicBuilder(PackedInts.COMPACT);\n    for (int i = 0; i < maxDoc; ++i) {\n      oldToNewBuilder.add(docs[i]);\n    }\n    final PackedLongValues oldToNew = oldToNewBuilder.build();\n    \n    return new Sorter.DocMap() {\n\n      @Override\n      public int oldToNew(int docID) {\n        return (int) oldToNew.get(docID);\n      }\n\n      @Override\n      public int newToOld(int docID) {\n        return (int) newToOld.get(docID);\n      }\n\n      @Override\n      public int size() {\n        return maxDoc;\n      }\n    };\n  }\n\n","sourceOld":"  /** Computes the old-to-new permutation over the given comparator. */\n  private static Sorter.DocMap sort(final int maxDoc, DocComparator comparator) {\n    // check if the index is sorted\n    boolean sorted = true;\n    for (int i = 1; i < maxDoc; ++i) {\n      if (comparator.compare(i-1, i) > 0) {\n        sorted = false;\n        break;\n      }\n    }\n    if (sorted) {\n      return null;\n    }\n\n    // sort doc IDs\n    final int[] docs = new int[maxDoc];\n    for (int i = 0; i < maxDoc; i++) {\n      docs[i] = i;\n    }\n    \n    DocValueSorter sorter = new DocValueSorter(docs, comparator);\n    // It can be common to sort a reader, add docs, sort it again, ... and in\n    // that case timSort can save a lot of time\n    sorter.sort(0, docs.length); // docs is now the newToOld mapping\n\n    // The reason why we use MonotonicAppendingLongBuffer here is that it\n    // wastes very little memory if the index is in random order but can save\n    // a lot of memory if the index is already \"almost\" sorted\n    final PackedLongValues.Builder newToOldBuilder = PackedLongValues.monotonicBuilder(PackedInts.COMPACT);\n    for (int i = 0; i < maxDoc; ++i) {\n      newToOldBuilder.add(docs[i]);\n    }\n    final PackedLongValues newToOld = newToOldBuilder.build();\n\n    for (int i = 0; i < maxDoc; ++i) {\n      docs[(int) newToOld.get(i)] = i;\n    } // docs is now the oldToNew mapping\n\n    final PackedLongValues.Builder oldToNewBuilder = PackedLongValues.monotonicBuilder(PackedInts.COMPACT);\n    for (int i = 0; i < maxDoc; ++i) {\n      oldToNewBuilder.add(docs[i]);\n    }\n    final PackedLongValues oldToNew = oldToNewBuilder.build();\n    \n    return new Sorter.DocMap() {\n\n      @Override\n      public int oldToNew(int docID) {\n        return (int) oldToNew.get(docID);\n      }\n\n      @Override\n      public int newToOld(int docID) {\n        return (int) newToOld.get(docID);\n      }\n\n      @Override\n      public int size() {\n        return maxDoc;\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4cce5816ef15a48a0bc11e5d400497ee4301dd3b","date":1476991456,"type":4,"author":"Kevin Risden","isMerge":true,"pathNew":"/dev/null","pathOld":"lucene/misc/src/java/org/apache/lucene/index/Sorter#sort(int,DocComparator).mjava","sourceNew":null,"sourceOld":"  /** Computes the old-to-new permutation over the given comparator. */\n  private static Sorter.DocMap sort(final int maxDoc, DocComparator comparator) {\n    // check if the index is sorted\n    boolean sorted = true;\n    for (int i = 1; i < maxDoc; ++i) {\n      if (comparator.compare(i-1, i) > 0) {\n        sorted = false;\n        break;\n      }\n    }\n    if (sorted) {\n      return null;\n    }\n\n    // sort doc IDs\n    final int[] docs = new int[maxDoc];\n    for (int i = 0; i < maxDoc; i++) {\n      docs[i] = i;\n    }\n    \n    DocValueSorter sorter = new DocValueSorter(docs, comparator);\n    // It can be common to sort a reader, add docs, sort it again, ... and in\n    // that case timSort can save a lot of time\n    sorter.sort(0, docs.length); // docs is now the newToOld mapping\n\n    // The reason why we use MonotonicAppendingLongBuffer here is that it\n    // wastes very little memory if the index is in random order but can save\n    // a lot of memory if the index is already \"almost\" sorted\n    final PackedLongValues.Builder newToOldBuilder = PackedLongValues.monotonicBuilder(PackedInts.COMPACT);\n    for (int i = 0; i < maxDoc; ++i) {\n      newToOldBuilder.add(docs[i]);\n    }\n    final PackedLongValues newToOld = newToOldBuilder.build();\n\n    for (int i = 0; i < maxDoc; ++i) {\n      docs[(int) newToOld.get(i)] = i;\n    } // docs is now the oldToNew mapping\n\n    final PackedLongValues.Builder oldToNewBuilder = PackedLongValues.monotonicBuilder(PackedInts.COMPACT);\n    for (int i = 0; i < maxDoc; ++i) {\n      oldToNewBuilder.add(docs[i]);\n    }\n    final PackedLongValues oldToNew = oldToNewBuilder.build();\n    \n    return new Sorter.DocMap() {\n\n      @Override\n      public int oldToNew(int docID) {\n        return (int) oldToNew.get(docID);\n      }\n\n      @Override\n      public int newToOld(int docID) {\n        return (int) newToOld.get(docID);\n      }\n\n      @Override\n      public int size() {\n        return maxDoc;\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"ceaef6cfc68c8ab22a684192e469a8280f9e6e70":["82dc51e5dcd7a80b71e40ebe8959b1c43b63f95e"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"0ad30c6a479e764150a3316e57263319775f1df2":["82dc51e5dcd7a80b71e40ebe8959b1c43b63f95e","3d33e731a93d4b57e662ff094f64f94a745422d4"],"82dc51e5dcd7a80b71e40ebe8959b1c43b63f95e":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"3d33e731a93d4b57e662ff094f64f94a745422d4":["82dc51e5dcd7a80b71e40ebe8959b1c43b63f95e","ceaef6cfc68c8ab22a684192e469a8280f9e6e70"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["82dc51e5dcd7a80b71e40ebe8959b1c43b63f95e","d470c8182e92b264680e34081b75e70a9f2b3c89"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["d470c8182e92b264680e34081b75e70a9f2b3c89"],"d470c8182e92b264680e34081b75e70a9f2b3c89":["82dc51e5dcd7a80b71e40ebe8959b1c43b63f95e","0ad30c6a479e764150a3316e57263319775f1df2"]},"commit2Childs":{"ceaef6cfc68c8ab22a684192e469a8280f9e6e70":["3d33e731a93d4b57e662ff094f64f94a745422d4"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["82dc51e5dcd7a80b71e40ebe8959b1c43b63f95e"],"0ad30c6a479e764150a3316e57263319775f1df2":["d470c8182e92b264680e34081b75e70a9f2b3c89"],"82dc51e5dcd7a80b71e40ebe8959b1c43b63f95e":["ceaef6cfc68c8ab22a684192e469a8280f9e6e70","0ad30c6a479e764150a3316e57263319775f1df2","3d33e731a93d4b57e662ff094f64f94a745422d4","4cce5816ef15a48a0bc11e5d400497ee4301dd3b","d470c8182e92b264680e34081b75e70a9f2b3c89"],"3d33e731a93d4b57e662ff094f64f94a745422d4":["0ad30c6a479e764150a3316e57263319775f1df2"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":[],"d470c8182e92b264680e34081b75e70a9f2b3c89":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}