{"path":"lucene/memory/src/java/org/apache/lucene/index/memory/MemoryIndex#toStringDebug().mjava","commits":[{"id":"198ff473c525ebb23af8521672fdf7195cdde235","date":1467818643,"type":1,"author":"David Smiley","isMerge":false,"pathNew":"lucene/memory/src/java/org/apache/lucene/index/memory/MemoryIndex#toStringDebug().mjava","pathOld":"lucene/memory/src/java/org/apache/lucene/index/memory/MemoryIndex#toString().mjava","sourceNew":"  /**\n   * Returns a String representation of the index data for debugging purposes.\n   * \n   * @return the string representation\n   * @lucene.experimental\n   */\n  public String toStringDebug() {\n    StringBuilder result = new StringBuilder(256);\n    int sumPositions = 0;\n    int sumTerms = 0;\n    final BytesRef spare = new BytesRef();\n    final BytesRefBuilder payloadBuilder = storePayloads ? new BytesRefBuilder() : null;\n    for (Map.Entry<String, Info> entry : fields.entrySet()) {\n      String fieldName = entry.getKey();\n      Info info = entry.getValue();\n      info.sortTerms();\n      result.append(fieldName + \":\\n\");\n      SliceByteStartArray sliceArray = info.sliceArray;\n      int numPositions = 0;\n      SliceReader postingsReader = new SliceReader(intBlockPool);\n      for (int j = 0; j < info.terms.size(); j++) {\n        int ord = info.sortedTerms[j];\n        info.terms.get(ord, spare);\n        int freq = sliceArray.freq[ord];\n        result.append(\"\\t'\" + spare + \"':\" + freq + \":\");\n        postingsReader.reset(sliceArray.start[ord], sliceArray.end[ord]);\n        result.append(\" [\");\n        final int iters = storeOffsets ? 3 : 1;\n        while (!postingsReader.endOfSlice()) {\n          result.append(\"(\");\n\n          for (int k = 0; k < iters; k++) {\n            result.append(postingsReader.readInt());\n            if (k < iters - 1) {\n              result.append(\", \");\n            }\n          }\n          if (storePayloads) {\n            int payloadIndex = postingsReader.readInt();\n            if (payloadIndex != -1) {\n                result.append(\", \" + payloadsBytesRefs.get(payloadBuilder, payloadIndex));\n            }\n          }\n          result.append(\")\");\n\n          if (!postingsReader.endOfSlice()) {\n            result.append(\", \");\n          }\n\n        }\n        result.append(\"]\");\n        result.append(\"\\n\");\n        numPositions += freq;\n      }\n\n      result.append(\"\\tterms=\" + info.terms.size());\n      result.append(\", positions=\" + numPositions);\n      result.append(\"\\n\");\n      sumPositions += numPositions;\n      sumTerms += info.terms.size();\n    }\n    \n    result.append(\"\\nfields=\" + fields.size());\n    result.append(\", terms=\" + sumTerms);\n    result.append(\", positions=\" + sumPositions);\n    return result.toString();\n  }\n\n","sourceOld":"  /**\n   * Returns a String representation of the index data for debugging purposes.\n   * \n   * @return the string representation\n   */\n  @Override\n  public String toString() {\n    StringBuilder result = new StringBuilder(256);\n    int sumPositions = 0;\n    int sumTerms = 0;\n    final BytesRef spare = new BytesRef();\n    for (Map.Entry<String, Info> entry : fields.entrySet()) {\n      String fieldName = entry.getKey();\n      Info info = entry.getValue();\n      info.sortTerms();\n      result.append(fieldName + \":\\n\");\n      SliceByteStartArray sliceArray = info.sliceArray;\n      int numPositions = 0;\n      SliceReader postingsReader = new SliceReader(intBlockPool);\n      for (int j = 0; j < info.terms.size(); j++) {\n        int ord = info.sortedTerms[j];\n        info.terms.get(ord, spare);\n        int freq = sliceArray.freq[ord];\n        result.append(\"\\t'\" + spare + \"':\" + freq + \":\");\n        postingsReader.reset(sliceArray.start[ord], sliceArray.end[ord]);\n        result.append(\" [\");\n        final int iters = storeOffsets ? 3 : 1;\n        while (!postingsReader.endOfSlice()) {\n          result.append(\"(\");\n\n          for (int k = 0; k < iters; k++) {\n            result.append(postingsReader.readInt());\n            if (k < iters - 1) {\n              result.append(\", \");\n            }\n          }\n          result.append(\")\");\n          if (!postingsReader.endOfSlice()) {\n            result.append(\",\");\n          }\n\n        }\n        result.append(\"]\");\n        result.append(\"\\n\");\n        numPositions += freq;\n      }\n\n      result.append(\"\\tterms=\" + info.terms.size());\n      result.append(\", positions=\" + numPositions);\n      result.append(\"\\n\");\n      sumPositions += numPositions;\n      sumTerms += info.terms.size();\n    }\n    \n    result.append(\"\\nfields=\" + fields.size());\n    result.append(\", terms=\" + sumTerms);\n    result.append(\", positions=\" + sumPositions);\n    return result.toString();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4cce5816ef15a48a0bc11e5d400497ee4301dd3b","date":1476991456,"type":0,"author":"Kevin Risden","isMerge":true,"pathNew":"lucene/memory/src/java/org/apache/lucene/index/memory/MemoryIndex#toStringDebug().mjava","pathOld":"/dev/null","sourceNew":"  /**\n   * Returns a String representation of the index data for debugging purposes.\n   * \n   * @return the string representation\n   * @lucene.experimental\n   */\n  public String toStringDebug() {\n    StringBuilder result = new StringBuilder(256);\n    int sumPositions = 0;\n    int sumTerms = 0;\n    final BytesRef spare = new BytesRef();\n    final BytesRefBuilder payloadBuilder = storePayloads ? new BytesRefBuilder() : null;\n    for (Map.Entry<String, Info> entry : fields.entrySet()) {\n      String fieldName = entry.getKey();\n      Info info = entry.getValue();\n      info.sortTerms();\n      result.append(fieldName + \":\\n\");\n      SliceByteStartArray sliceArray = info.sliceArray;\n      int numPositions = 0;\n      SliceReader postingsReader = new SliceReader(intBlockPool);\n      for (int j = 0; j < info.terms.size(); j++) {\n        int ord = info.sortedTerms[j];\n        info.terms.get(ord, spare);\n        int freq = sliceArray.freq[ord];\n        result.append(\"\\t'\" + spare + \"':\" + freq + \":\");\n        postingsReader.reset(sliceArray.start[ord], sliceArray.end[ord]);\n        result.append(\" [\");\n        final int iters = storeOffsets ? 3 : 1;\n        while (!postingsReader.endOfSlice()) {\n          result.append(\"(\");\n\n          for (int k = 0; k < iters; k++) {\n            result.append(postingsReader.readInt());\n            if (k < iters - 1) {\n              result.append(\", \");\n            }\n          }\n          if (storePayloads) {\n            int payloadIndex = postingsReader.readInt();\n            if (payloadIndex != -1) {\n                result.append(\", \" + payloadsBytesRefs.get(payloadBuilder, payloadIndex));\n            }\n          }\n          result.append(\")\");\n\n          if (!postingsReader.endOfSlice()) {\n            result.append(\", \");\n          }\n\n        }\n        result.append(\"]\");\n        result.append(\"\\n\");\n        numPositions += freq;\n      }\n\n      result.append(\"\\tterms=\" + info.terms.size());\n      result.append(\", positions=\" + numPositions);\n      result.append(\"\\n\");\n      sumPositions += numPositions;\n      sumTerms += info.terms.size();\n    }\n    \n    result.append(\"\\nfields=\" + fields.size());\n    result.append(\", terms=\" + sumTerms);\n    result.append(\", positions=\" + sumPositions);\n    return result.toString();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2ffe681f212e5073c69955b4ad22946794c84940","date":1560182863,"type":3,"author":"Koen De Groote","isMerge":false,"pathNew":"lucene/memory/src/java/org/apache/lucene/index/memory/MemoryIndex#toStringDebug().mjava","pathOld":"lucene/memory/src/java/org/apache/lucene/index/memory/MemoryIndex#toStringDebug().mjava","sourceNew":"  /**\n   * Returns a String representation of the index data for debugging purposes.\n   * \n   * @return the string representation\n   * @lucene.experimental\n   */\n  public String toStringDebug() {\n    StringBuilder result = new StringBuilder(256);\n    int sumPositions = 0;\n    int sumTerms = 0;\n    final BytesRef spare = new BytesRef();\n    final BytesRefBuilder payloadBuilder = storePayloads ? new BytesRefBuilder() : null;\n    for (Map.Entry<String, Info> entry : fields.entrySet()) {\n      String fieldName = entry.getKey();\n      Info info = entry.getValue();\n      info.sortTerms();\n      result.append(fieldName).append(\":\\n\");\n      SliceByteStartArray sliceArray = info.sliceArray;\n      int numPositions = 0;\n      SliceReader postingsReader = new SliceReader(intBlockPool);\n      for (int j = 0; j < info.terms.size(); j++) {\n        int ord = info.sortedTerms[j];\n        info.terms.get(ord, spare);\n        int freq = sliceArray.freq[ord];\n        result.append(\"\\t'\").append(spare).append(\"':\").append(freq).append(':');\n        postingsReader.reset(sliceArray.start[ord], sliceArray.end[ord]);\n        result.append(\" [\");\n        final int iters = storeOffsets ? 3 : 1;\n        while (!postingsReader.endOfSlice()) {\n          result.append(\"(\");\n\n          for (int k = 0; k < iters; k++) {\n            result.append(postingsReader.readInt());\n            if (k < iters - 1) {\n              result.append(\", \");\n            }\n          }\n          if (storePayloads) {\n            int payloadIndex = postingsReader.readInt();\n            if (payloadIndex != -1) {\n                result.append(\", \").append(payloadsBytesRefs.get(payloadBuilder, payloadIndex));\n            }\n          }\n          result.append(\")\");\n\n          if (!postingsReader.endOfSlice()) {\n            result.append(\", \");\n          }\n\n        }\n        result.append(\"]\");\n        result.append(\"\\n\");\n        numPositions += freq;\n      }\n\n      result.append(\"\\tterms=\").append(info.terms.size());\n      result.append(\", positions=\").append(numPositions);\n      result.append(\"\\n\");\n      sumPositions += numPositions;\n      sumTerms += info.terms.size();\n    }\n    \n    result.append(\"\\nfields=\").append(fields.size());\n    result.append(\", terms=\").append(sumTerms);\n    result.append(\", positions=\").append(sumPositions);\n    return result.toString();\n  }\n\n","sourceOld":"  /**\n   * Returns a String representation of the index data for debugging purposes.\n   * \n   * @return the string representation\n   * @lucene.experimental\n   */\n  public String toStringDebug() {\n    StringBuilder result = new StringBuilder(256);\n    int sumPositions = 0;\n    int sumTerms = 0;\n    final BytesRef spare = new BytesRef();\n    final BytesRefBuilder payloadBuilder = storePayloads ? new BytesRefBuilder() : null;\n    for (Map.Entry<String, Info> entry : fields.entrySet()) {\n      String fieldName = entry.getKey();\n      Info info = entry.getValue();\n      info.sortTerms();\n      result.append(fieldName + \":\\n\");\n      SliceByteStartArray sliceArray = info.sliceArray;\n      int numPositions = 0;\n      SliceReader postingsReader = new SliceReader(intBlockPool);\n      for (int j = 0; j < info.terms.size(); j++) {\n        int ord = info.sortedTerms[j];\n        info.terms.get(ord, spare);\n        int freq = sliceArray.freq[ord];\n        result.append(\"\\t'\" + spare + \"':\" + freq + \":\");\n        postingsReader.reset(sliceArray.start[ord], sliceArray.end[ord]);\n        result.append(\" [\");\n        final int iters = storeOffsets ? 3 : 1;\n        while (!postingsReader.endOfSlice()) {\n          result.append(\"(\");\n\n          for (int k = 0; k < iters; k++) {\n            result.append(postingsReader.readInt());\n            if (k < iters - 1) {\n              result.append(\", \");\n            }\n          }\n          if (storePayloads) {\n            int payloadIndex = postingsReader.readInt();\n            if (payloadIndex != -1) {\n                result.append(\", \" + payloadsBytesRefs.get(payloadBuilder, payloadIndex));\n            }\n          }\n          result.append(\")\");\n\n          if (!postingsReader.endOfSlice()) {\n            result.append(\", \");\n          }\n\n        }\n        result.append(\"]\");\n        result.append(\"\\n\");\n        numPositions += freq;\n      }\n\n      result.append(\"\\tterms=\" + info.terms.size());\n      result.append(\", positions=\" + numPositions);\n      result.append(\"\\n\");\n      sumPositions += numPositions;\n      sumTerms += info.terms.size();\n    }\n    \n    result.append(\"\\nfields=\" + fields.size());\n    result.append(\", terms=\" + sumTerms);\n    result.append(\", positions=\" + sumPositions);\n    return result.toString();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"2ffe681f212e5073c69955b4ad22946794c84940":["198ff473c525ebb23af8521672fdf7195cdde235"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"198ff473c525ebb23af8521672fdf7195cdde235":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","198ff473c525ebb23af8521672fdf7195cdde235"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["2ffe681f212e5073c69955b4ad22946794c84940"]},"commit2Childs":{"2ffe681f212e5073c69955b4ad22946794c84940":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["198ff473c525ebb23af8521672fdf7195cdde235","4cce5816ef15a48a0bc11e5d400497ee4301dd3b"],"198ff473c525ebb23af8521672fdf7195cdde235":["2ffe681f212e5073c69955b4ad22946794c84940","4cce5816ef15a48a0bc11e5d400497ee4301dd3b"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}