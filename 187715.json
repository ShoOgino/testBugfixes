{"path":"src/java/org/apache/solr/search/SolrIndexSearcher#getDocListC(QueryResult,QueryCommand).mjava","commits":[{"id":"db25c1f61b5ae826f10777da6551a832703967d5","date":1215306972,"type":1,"author":"Yonik Seeley","isMerge":false,"pathNew":"src/java/org/apache/solr/search/SolrIndexSearcher#getDocListC(QueryResult,QueryCommand).mjava","pathOld":"src/java/org/apache/solr/search/SolrIndexSearcher#getDocListC(DocListAndSet,Query,List[Query],DocSet,Sort,int,int,int).mjava","sourceNew":"  /**\n   * getDocList version that uses+populates query and filter caches.\n   * In the event of a timeout, the cache is not populated.\n   */\n  private void getDocListC(QueryResult qr, QueryCommand cmd) throws IOException {\n    // old parameters: DocListAndSet out, Query query, List<Query> filterList, DocSet filter, Sort lsort, int offset, int len, int flags, long timeAllowed, NamedList<Object> responseHeader\n    DocListAndSet out = new DocListAndSet();\n    qr.setDocListAndSet(out);\n    QueryResultKey key=null;\n    int maxDocRequested = cmd.getOffset() + cmd.getLen();\n    // check for overflow, and check for # docs in index\n    if (maxDocRequested < 0 || maxDocRequested > maxDoc()) maxDocRequested = maxDoc();\n    int supersetMaxDoc= maxDocRequested;\n    DocList superset;\n\n    // we can try and look up the complete query in the cache.\n    // we can't do that if filter!=null though (we don't want to\n    // do hashCode() and equals() for a big DocSet).\n    if (queryResultCache != null && cmd.getFilter()==null) {\n        // all of the current flags can be reused during warming,\n        // so set all of them on the cache key.\n        key = new QueryResultKey(cmd.getQuery(), cmd.getFilterList(), cmd.getSort(), cmd.getFlags());\n        if ((cmd.getFlags() & NO_CHECK_QCACHE)==0) {\n          superset = (DocList)queryResultCache.get(key);\n\n          if (superset != null) {\n            // check that the cache entry has scores recorded if we need them\n            if ((cmd.getFlags() & GET_SCORES)==0 || superset.hasScores()) {\n              // NOTE: subset() returns null if the DocList has fewer docs than\n              // requested\n              out.docList = superset.subset(cmd.getOffset(),cmd.getLen());\n            }\n          }\n          if (out.docList != null) {\n            // found the docList in the cache... now check if we need the docset too.\n            // OPT: possible future optimization - if the doclist contains all the matches,\n            // use it to make the docset instead of rerunning the query.\n            if (out.docSet==null && ((cmd.getFlags() & GET_DOCSET)!=0) ) {\n              if (cmd.getFilterList()==null) {\n                out.docSet = getDocSet(cmd.getQuery());\n              } else {\n                List<Query> newList = new ArrayList<Query>(cmd.getFilterList()\n.size()+1);\n                newList.add(cmd.getQuery());\n                newList.addAll(cmd.getFilterList());\n                out.docSet = getDocSet(newList);\n              }\n            }\n            return;\n          }\n        }\n\n        // If we are going to generate the result, bump up to the\n        // next resultWindowSize for better caching.\n\n        // handle 0 special case as well as avoid idiv in the common case.\n        if (maxDocRequested < queryResultWindowSize) {\n          supersetMaxDoc=queryResultWindowSize;\n        } else {\n          supersetMaxDoc = ((maxDocRequested -1)/queryResultWindowSize + 1)*queryResultWindowSize;\n          if (supersetMaxDoc < 0) supersetMaxDoc=maxDocRequested;\n        }\n    }\n\n\n    // OK, so now we need to generate an answer.\n    // One way to do that would be to check if we have an unordered list\n    // of results for the base query.  If so, we can apply the filters and then\n    // sort by the resulting set.  This can only be used if:\n    // - the sort doesn't contain score\n    // - we don't want score returned.\n\n    // check if we should try and use the filter cache\n    boolean useFilterCache=false;\n    if ((cmd.getFlags() & (GET_SCORES|NO_CHECK_FILTERCACHE))==0 && useFilterForSortedQuery && cmd.getSort() != null && filterCache != null) {\n      useFilterCache=true;\n      SortField[] sfields = cmd.getSort().getSort();\n      for (SortField sf : sfields) {\n        if (sf.getType() == SortField.SCORE) {\n          useFilterCache=false;\n          break;\n        }\n      }\n    }\n\n    if (useFilterCache) {\n      // now actually use the filter cache.\n      // for large filters that match few documents, this may be\n      // slower than simply re-executing the query.\n      if (out.docSet == null) {\n        out.docSet = getDocSet(cmd.getQuery(),cmd.getFilter());\n        DocSet bigFilt = getDocSet(cmd.getFilterList());\n        if (bigFilt != null) out.docSet = out.docSet.intersection(bigFilt);\n      }\n      // todo: there could be a sortDocSet that could take a list of\n      // the filters instead of anding them first...\n      // perhaps there should be a multi-docset-iterator\n      superset = sortDocSet(out.docSet,cmd.getSort(),supersetMaxDoc);\n      out.docList = superset.subset(cmd.getOffset(),cmd.getLen());\n    } else {\n      // do it the normal way...\n      cmd.setSupersetMaxDoc(supersetMaxDoc);\n      if ((cmd.getFlags() & GET_DOCSET)!=0) {\n        DocSet qDocSet = getDocListAndSetNC(qr,cmd);\n        // cache the docSet matching the query w/o filtering\n        if (filterCache!=null && !qr.isPartialResults()) filterCache.put(cmd.getQuery(),qDocSet);\n      } else {\n        getDocListNC(qr,cmd);\n        //Parameters: cmd.getQuery(),theFilt,cmd.getSort(),0,supersetMaxDoc,cmd.getFlags(),cmd.getTimeAllowed(),responseHeader);\n      }\n      superset = out.docList;\n      out.docList = superset.subset(cmd.getOffset(),cmd.getLen());\n    }\n\n    // lastly, put the superset in the cache if the size is less than or equal\n    // to queryResultMaxDocsCached\n    if (key != null && superset.size() <= queryResultMaxDocsCached && !qr.isPartialResults()) {\n      queryResultCache.put(key, superset);\n    }\n  }\n\n","sourceOld":"  /** getDocList version that uses+populates query and filter caches.\n   * This should only be called using either filterList or filter, but not both.\n   */\n  private void getDocListC(DocListAndSet out, Query query, List<Query> filterList, DocSet filter, Sort lsort, int offset, int len, int flags) throws IOException {\n    QueryResultKey key=null;\n    int maxDocRequested = offset + len;\n    // check for overflow, and check for # docs in index\n    if (maxDocRequested < 0 || maxDocRequested > maxDoc()) maxDocRequested = maxDoc();\n    int supersetMaxDoc= maxDocRequested;\n    DocList superset;\n\n\n    // we can try and look up the complete query in the cache.\n    // we can't do that if filter!=null though (we don't want to\n    // do hashCode() and equals() for a big DocSet).\n    if (queryResultCache != null && filter==null) {\n        // all of the current flags can be reused during warming,\n        // so set all of them on the cache key.\n        key = new QueryResultKey(query, filterList, lsort, flags);\n        if ((flags & NO_CHECK_QCACHE)==0) {\n          superset = (DocList)queryResultCache.get(key);\n\n          if (superset != null) {\n            // check that the cache entry has scores recorded if we need them\n            if ((flags & GET_SCORES)==0 || superset.hasScores()) {\n              // NOTE: subset() returns null if the DocList has fewer docs than\n              // requested\n              out.docList = superset.subset(offset,len);\n            }\n          }\n          if (out.docList != null) {\n            // found the docList in the cache... now check if we need the docset too.\n            // OPT: possible future optimization - if the doclist contains all the matches,\n            // use it to make the docset instead of rerunning the query.\n            if (out.docSet==null && ((flags & GET_DOCSET)!=0) ) {\n              if (filterList==null) {\n                out.docSet = getDocSet(query);\n              } else {\n                List<Query> newList = new ArrayList<Query>(filterList.size()+1);\n                newList.add(query);\n                newList.addAll(filterList);\n                out.docSet = getDocSet(newList);\n              }\n            }\n            return;\n          }\n        }\n\n        // If we are going to generate the result, bump up to the\n        // next resultWindowSize for better caching.\n\n        // handle 0 special case as well as avoid idiv in the common case.\n        if (maxDocRequested < queryResultWindowSize) {\n          supersetMaxDoc=queryResultWindowSize;\n        } else {\n          supersetMaxDoc = ((maxDocRequested -1)/queryResultWindowSize + 1)*queryResultWindowSize;\n          if (supersetMaxDoc < 0) supersetMaxDoc=maxDocRequested;\n        }\n    }\n\n\n    // OK, so now we need to generate an answer.\n    // One way to do that would be to check if we have an unordered list\n    // of results for the base query.  If so, we can apply the filters and then\n    // sort by the resulting set.  This can only be used if:\n    // - the sort doesn't contain score\n    // - we don't want score returned.\n\n    // check if we should try and use the filter cache\n    boolean useFilterCache=false;\n    if ((flags & (GET_SCORES|NO_CHECK_FILTERCACHE))==0 && useFilterForSortedQuery && lsort != null && filterCache != null) {\n      useFilterCache=true;\n      SortField[] sfields = lsort.getSort();\n      for (SortField sf : sfields) {\n        if (sf.getType() == SortField.SCORE) {\n          useFilterCache=false;\n          break;\n        }\n      }\n    }\n\n    if (useFilterCache) {\n      // now actually use the filter cache.\n      // for large filters that match few documents, this may be\n      // slower than simply re-executing the query.\n      if (out.docSet == null) {\n        out.docSet = getDocSet(query,filter);\n        DocSet bigFilt = getDocSet(filterList);\n        if (bigFilt != null) out.docSet = out.docSet.intersection(bigFilt);\n      }\n      // todo: there could be a sortDocSet that could take a list of\n      // the filters instead of anding them first...\n      // perhaps there should be a multi-docset-iterator\n      superset = sortDocSet(out.docSet,lsort,supersetMaxDoc);\n      out.docList = superset.subset(offset,len);\n    } else {\n      // do it the normal way...\n      DocSet theFilt = filter!=null ? filter : getDocSet(filterList);\n\n      if ((flags & GET_DOCSET)!=0) {\n        DocSet qDocSet = getDocListAndSetNC(out,query,theFilt,lsort,0,supersetMaxDoc,flags);\n        // cache the docSet matching the query w/o filtering\n        if (filterCache!=null) filterCache.put(query,qDocSet);\n      } else {\n        out.docList = getDocListNC(query,theFilt,lsort,0,supersetMaxDoc,flags);\n      }\n      superset = out.docList;\n      out.docList = superset.subset(offset,len);\n    }\n\n    // lastly, put the superset in the cache if the size is less than or equal\n    // to queryResultMaxDocsCached\n    if (key != null && superset.size() <= queryResultMaxDocsCached) {\n      queryResultCache.put(key, superset);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"52df4540d5cd0c887f5e56ef0f387d7489f5d44f","date":1243099614,"type":3,"author":"Yonik Seeley","isMerge":false,"pathNew":"src/java/org/apache/solr/search/SolrIndexSearcher#getDocListC(QueryResult,QueryCommand).mjava","pathOld":"src/java/org/apache/solr/search/SolrIndexSearcher#getDocListC(QueryResult,QueryCommand).mjava","sourceNew":"  /**\n   * getDocList version that uses+populates query and filter caches.\n   * In the event of a timeout, the cache is not populated.\n   */\n  private void getDocListC(QueryResult qr, QueryCommand cmd) throws IOException {\n    // old parameters: DocListAndSet out, Query query, List<Query> filterList, DocSet filter, Sort lsort, int offset, int len, int flags, long timeAllowed, NamedList<Object> responseHeader\n    DocListAndSet out = new DocListAndSet();\n    qr.setDocListAndSet(out);\n    QueryResultKey key=null;\n    int maxDocRequested = cmd.getOffset() + cmd.getLen();\n    // check for overflow, and check for # docs in index\n    if (maxDocRequested < 0 || maxDocRequested > maxDoc()) maxDocRequested = maxDoc();\n    int supersetMaxDoc= maxDocRequested;\n    DocList superset;\n\n    // we can try and look up the complete query in the cache.\n    // we can't do that if filter!=null though (we don't want to\n    // do hashCode() and equals() for a big DocSet).\n    if (queryResultCache != null && cmd.getFilter()==null) {\n        // all of the current flags can be reused during warming,\n        // so set all of them on the cache key.\n        key = new QueryResultKey(cmd.getQuery(), cmd.getFilterList(), cmd.getSort(), cmd.getFlags());\n        if ((cmd.getFlags() & NO_CHECK_QCACHE)==0) {\n          superset = (DocList)queryResultCache.get(key);\n\n          if (superset != null) {\n            // check that the cache entry has scores recorded if we need them\n            if ((cmd.getFlags() & GET_SCORES)==0 || superset.hasScores()) {\n              // NOTE: subset() returns null if the DocList has fewer docs than\n              // requested\n              out.docList = superset.subset(cmd.getOffset(),cmd.getLen());\n            }\n          }\n          if (out.docList != null) {\n            // found the docList in the cache... now check if we need the docset too.\n            // OPT: possible future optimization - if the doclist contains all the matches,\n            // use it to make the docset instead of rerunning the query.\n            if (out.docSet==null && ((cmd.getFlags() & GET_DOCSET)!=0) ) {\n              if (cmd.getFilterList()==null) {\n                out.docSet = getDocSet(cmd.getQuery());\n              } else {\n                List<Query> newList = new ArrayList<Query>(cmd.getFilterList()\n.size()+1);\n                newList.add(cmd.getQuery());\n                newList.addAll(cmd.getFilterList());\n                out.docSet = getDocSet(newList);\n              }\n            }\n            return;\n          }\n        }\n\n        // If we are going to generate the result, bump up to the\n        // next resultWindowSize for better caching.\n\n        // handle 0 special case as well as avoid idiv in the common case.\n        if (maxDocRequested < queryResultWindowSize) {\n          supersetMaxDoc=queryResultWindowSize;\n        } else {\n          supersetMaxDoc = ((maxDocRequested -1)/queryResultWindowSize + 1)*queryResultWindowSize;\n          if (supersetMaxDoc < 0) supersetMaxDoc=maxDocRequested;\n        }\n    }\n\n\n    // OK, so now we need to generate an answer.\n    // One way to do that would be to check if we have an unordered list\n    // of results for the base query.  If so, we can apply the filters and then\n    // sort by the resulting set.  This can only be used if:\n    // - the sort doesn't contain score\n    // - we don't want score returned.\n\n    // check if we should try and use the filter cache\n    boolean useFilterCache=false;\n    if ((cmd.getFlags() & (GET_SCORES|NO_CHECK_FILTERCACHE))==0 && useFilterForSortedQuery && cmd.getSort() != null && filterCache != null) {\n      useFilterCache=true;\n      SortField[] sfields = cmd.getSort().getSort();\n      for (SortField sf : sfields) {\n        if (sf.getType() == SortField.SCORE) {\n          useFilterCache=false;\n          break;\n        }\n      }\n    }\n\n    if (useFilterCache) {\n      // now actually use the filter cache.\n      // for large filters that match few documents, this may be\n      // slower than simply re-executing the query.\n      if (out.docSet == null) {\n        out.docSet = getDocSet(cmd.getQuery(),cmd.getFilter());\n        DocSet bigFilt = getDocSet(cmd.getFilterList());\n        if (bigFilt != null) out.docSet = out.docSet.intersection(bigFilt);\n      }\n      // todo: there could be a sortDocSet that could take a list of\n      // the filters instead of anding them first...\n      // perhaps there should be a multi-docset-iterator\n      superset = sortDocSet(out.docSet,cmd.getSort(),supersetMaxDoc);\n      out.docList = superset.subset(cmd.getOffset(),cmd.getLen());\n    } else {\n      // do it the normal way...\n      cmd.setSupersetMaxDoc(supersetMaxDoc);\n      if ((cmd.getFlags() & GET_DOCSET)!=0) {\n        // this currently conflates returning the docset for the base query vs\n        // the base query and all filters.\n        DocSet qDocSet = getDocListAndSetNC(qr,cmd);\n        // cache the docSet matching the query w/o filtering\n        if (qDocSet!=null && filterCache!=null && !qr.isPartialResults()) filterCache.put(cmd.getQuery(),qDocSet);\n      } else {\n        getDocListNC(qr,cmd);\n        //Parameters: cmd.getQuery(),theFilt,cmd.getSort(),0,supersetMaxDoc,cmd.getFlags(),cmd.getTimeAllowed(),responseHeader);\n      }\n      superset = out.docList;\n      out.docList = superset.subset(cmd.getOffset(),cmd.getLen());\n    }\n\n    // lastly, put the superset in the cache if the size is less than or equal\n    // to queryResultMaxDocsCached\n    if (key != null && superset.size() <= queryResultMaxDocsCached && !qr.isPartialResults()) {\n      queryResultCache.put(key, superset);\n    }\n  }\n\n","sourceOld":"  /**\n   * getDocList version that uses+populates query and filter caches.\n   * In the event of a timeout, the cache is not populated.\n   */\n  private void getDocListC(QueryResult qr, QueryCommand cmd) throws IOException {\n    // old parameters: DocListAndSet out, Query query, List<Query> filterList, DocSet filter, Sort lsort, int offset, int len, int flags, long timeAllowed, NamedList<Object> responseHeader\n    DocListAndSet out = new DocListAndSet();\n    qr.setDocListAndSet(out);\n    QueryResultKey key=null;\n    int maxDocRequested = cmd.getOffset() + cmd.getLen();\n    // check for overflow, and check for # docs in index\n    if (maxDocRequested < 0 || maxDocRequested > maxDoc()) maxDocRequested = maxDoc();\n    int supersetMaxDoc= maxDocRequested;\n    DocList superset;\n\n    // we can try and look up the complete query in the cache.\n    // we can't do that if filter!=null though (we don't want to\n    // do hashCode() and equals() for a big DocSet).\n    if (queryResultCache != null && cmd.getFilter()==null) {\n        // all of the current flags can be reused during warming,\n        // so set all of them on the cache key.\n        key = new QueryResultKey(cmd.getQuery(), cmd.getFilterList(), cmd.getSort(), cmd.getFlags());\n        if ((cmd.getFlags() & NO_CHECK_QCACHE)==0) {\n          superset = (DocList)queryResultCache.get(key);\n\n          if (superset != null) {\n            // check that the cache entry has scores recorded if we need them\n            if ((cmd.getFlags() & GET_SCORES)==0 || superset.hasScores()) {\n              // NOTE: subset() returns null if the DocList has fewer docs than\n              // requested\n              out.docList = superset.subset(cmd.getOffset(),cmd.getLen());\n            }\n          }\n          if (out.docList != null) {\n            // found the docList in the cache... now check if we need the docset too.\n            // OPT: possible future optimization - if the doclist contains all the matches,\n            // use it to make the docset instead of rerunning the query.\n            if (out.docSet==null && ((cmd.getFlags() & GET_DOCSET)!=0) ) {\n              if (cmd.getFilterList()==null) {\n                out.docSet = getDocSet(cmd.getQuery());\n              } else {\n                List<Query> newList = new ArrayList<Query>(cmd.getFilterList()\n.size()+1);\n                newList.add(cmd.getQuery());\n                newList.addAll(cmd.getFilterList());\n                out.docSet = getDocSet(newList);\n              }\n            }\n            return;\n          }\n        }\n\n        // If we are going to generate the result, bump up to the\n        // next resultWindowSize for better caching.\n\n        // handle 0 special case as well as avoid idiv in the common case.\n        if (maxDocRequested < queryResultWindowSize) {\n          supersetMaxDoc=queryResultWindowSize;\n        } else {\n          supersetMaxDoc = ((maxDocRequested -1)/queryResultWindowSize + 1)*queryResultWindowSize;\n          if (supersetMaxDoc < 0) supersetMaxDoc=maxDocRequested;\n        }\n    }\n\n\n    // OK, so now we need to generate an answer.\n    // One way to do that would be to check if we have an unordered list\n    // of results for the base query.  If so, we can apply the filters and then\n    // sort by the resulting set.  This can only be used if:\n    // - the sort doesn't contain score\n    // - we don't want score returned.\n\n    // check if we should try and use the filter cache\n    boolean useFilterCache=false;\n    if ((cmd.getFlags() & (GET_SCORES|NO_CHECK_FILTERCACHE))==0 && useFilterForSortedQuery && cmd.getSort() != null && filterCache != null) {\n      useFilterCache=true;\n      SortField[] sfields = cmd.getSort().getSort();\n      for (SortField sf : sfields) {\n        if (sf.getType() == SortField.SCORE) {\n          useFilterCache=false;\n          break;\n        }\n      }\n    }\n\n    if (useFilterCache) {\n      // now actually use the filter cache.\n      // for large filters that match few documents, this may be\n      // slower than simply re-executing the query.\n      if (out.docSet == null) {\n        out.docSet = getDocSet(cmd.getQuery(),cmd.getFilter());\n        DocSet bigFilt = getDocSet(cmd.getFilterList());\n        if (bigFilt != null) out.docSet = out.docSet.intersection(bigFilt);\n      }\n      // todo: there could be a sortDocSet that could take a list of\n      // the filters instead of anding them first...\n      // perhaps there should be a multi-docset-iterator\n      superset = sortDocSet(out.docSet,cmd.getSort(),supersetMaxDoc);\n      out.docList = superset.subset(cmd.getOffset(),cmd.getLen());\n    } else {\n      // do it the normal way...\n      cmd.setSupersetMaxDoc(supersetMaxDoc);\n      if ((cmd.getFlags() & GET_DOCSET)!=0) {\n        DocSet qDocSet = getDocListAndSetNC(qr,cmd);\n        // cache the docSet matching the query w/o filtering\n        if (filterCache!=null && !qr.isPartialResults()) filterCache.put(cmd.getQuery(),qDocSet);\n      } else {\n        getDocListNC(qr,cmd);\n        //Parameters: cmd.getQuery(),theFilt,cmd.getSort(),0,supersetMaxDoc,cmd.getFlags(),cmd.getTimeAllowed(),responseHeader);\n      }\n      superset = out.docList;\n      out.docList = superset.subset(cmd.getOffset(),cmd.getLen());\n    }\n\n    // lastly, put the superset in the cache if the size is less than or equal\n    // to queryResultMaxDocsCached\n    if (key != null && superset.size() <= queryResultMaxDocsCached && !qr.isPartialResults()) {\n      queryResultCache.put(key, superset);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"ac3e6437547a34cce2b5405ce0cf9e3af578401e","date":1243373693,"type":3,"author":"Yonik Seeley","isMerge":false,"pathNew":"src/java/org/apache/solr/search/SolrIndexSearcher#getDocListC(QueryResult,QueryCommand).mjava","pathOld":"src/java/org/apache/solr/search/SolrIndexSearcher#getDocListC(QueryResult,QueryCommand).mjava","sourceNew":"  /**\n   * getDocList version that uses+populates query and filter caches.\n   * In the event of a timeout, the cache is not populated.\n   */\n  private void getDocListC(QueryResult qr, QueryCommand cmd) throws IOException {\n    // old parameters: DocListAndSet out, Query query, List<Query> filterList, DocSet filter, Sort lsort, int offset, int len, int flags, long timeAllowed, NamedList<Object> responseHeader\n    DocListAndSet out = new DocListAndSet();\n    qr.setDocListAndSet(out);\n    QueryResultKey key=null;\n    int maxDocRequested = cmd.getOffset() + cmd.getLen();\n    // check for overflow, and check for # docs in index\n    if (maxDocRequested < 0 || maxDocRequested > maxDoc()) maxDocRequested = maxDoc();\n    int supersetMaxDoc= maxDocRequested;\n    DocList superset;\n\n    // we can try and look up the complete query in the cache.\n    // we can't do that if filter!=null though (we don't want to\n    // do hashCode() and equals() for a big DocSet).\n    if (queryResultCache != null && cmd.getFilter()==null) {\n        // all of the current flags can be reused during warming,\n        // so set all of them on the cache key.\n        key = new QueryResultKey(cmd.getQuery(), cmd.getFilterList(), cmd.getSort(), cmd.getFlags());\n        if ((cmd.getFlags() & NO_CHECK_QCACHE)==0) {\n          superset = (DocList)queryResultCache.get(key);\n\n          if (superset != null) {\n            // check that the cache entry has scores recorded if we need them\n            if ((cmd.getFlags() & GET_SCORES)==0 || superset.hasScores()) {\n              // NOTE: subset() returns null if the DocList has fewer docs than\n              // requested\n              out.docList = superset.subset(cmd.getOffset(),cmd.getLen());\n            }\n          }\n          if (out.docList != null) {\n            // found the docList in the cache... now check if we need the docset too.\n            // OPT: possible future optimization - if the doclist contains all the matches,\n            // use it to make the docset instead of rerunning the query.\n            if (out.docSet==null && ((cmd.getFlags() & GET_DOCSET)!=0) ) {\n              if (cmd.getFilterList()==null) {\n                out.docSet = getDocSet(cmd.getQuery());\n              } else {\n                List<Query> newList = new ArrayList<Query>(cmd.getFilterList()\n.size()+1);\n                newList.add(cmd.getQuery());\n                newList.addAll(cmd.getFilterList());\n                out.docSet = getDocSet(newList);\n              }\n            }\n            return;\n          }\n        }\n\n        // If we are going to generate the result, bump up to the\n        // next resultWindowSize for better caching.\n\n        // handle 0 special case as well as avoid idiv in the common case.\n        if (maxDocRequested < queryResultWindowSize) {\n          supersetMaxDoc=queryResultWindowSize;\n        } else {\n          supersetMaxDoc = ((maxDocRequested -1)/queryResultWindowSize + 1)*queryResultWindowSize;\n          if (supersetMaxDoc < 0) supersetMaxDoc=maxDocRequested;\n        }\n    }\n\n\n    // OK, so now we need to generate an answer.\n    // One way to do that would be to check if we have an unordered list\n    // of results for the base query.  If so, we can apply the filters and then\n    // sort by the resulting set.  This can only be used if:\n    // - the sort doesn't contain score\n    // - we don't want score returned.\n\n    // check if we should try and use the filter cache\n    boolean useFilterCache=false;\n    if ((cmd.getFlags() & (GET_SCORES|NO_CHECK_FILTERCACHE))==0 && useFilterForSortedQuery && cmd.getSort() != null && filterCache != null) {\n      useFilterCache=true;\n      SortField[] sfields = cmd.getSort().getSort();\n      for (SortField sf : sfields) {\n        if (sf.getType() == SortField.SCORE) {\n          useFilterCache=false;\n          break;\n        }\n      }\n    }\n\n    // disable useFilterCache optimization temporarily\n    if (useFilterCache) {\n      // now actually use the filter cache.\n      // for large filters that match few documents, this may be\n      // slower than simply re-executing the query.\n      if (out.docSet == null) {\n        out.docSet = getDocSet(cmd.getQuery(),cmd.getFilter());\n        DocSet bigFilt = getDocSet(cmd.getFilterList());\n        if (bigFilt != null) out.docSet = out.docSet.intersection(bigFilt);\n      }\n      // todo: there could be a sortDocSet that could take a list of\n      // the filters instead of anding them first...\n      // perhaps there should be a multi-docset-iterator\n      superset = sortDocSet(out.docSet,cmd.getSort(),supersetMaxDoc);\n      out.docList = superset.subset(cmd.getOffset(),cmd.getLen());\n    } else {\n      // do it the normal way...\n      cmd.setSupersetMaxDoc(supersetMaxDoc);\n      if ((cmd.getFlags() & GET_DOCSET)!=0) {\n        // this currently conflates returning the docset for the base query vs\n        // the base query and all filters.\n        DocSet qDocSet = getDocListAndSetNC(qr,cmd);\n        // cache the docSet matching the query w/o filtering\n        if (qDocSet!=null && filterCache!=null && !qr.isPartialResults()) filterCache.put(cmd.getQuery(),qDocSet);\n      } else {\n        getDocListNC(qr,cmd);\n        //Parameters: cmd.getQuery(),theFilt,cmd.getSort(),0,supersetMaxDoc,cmd.getFlags(),cmd.getTimeAllowed(),responseHeader);\n      }\n      superset = out.docList;\n      out.docList = superset.subset(cmd.getOffset(),cmd.getLen());\n    }\n\n    // lastly, put the superset in the cache if the size is less than or equal\n    // to queryResultMaxDocsCached\n    if (key != null && superset.size() <= queryResultMaxDocsCached && !qr.isPartialResults()) {\n      queryResultCache.put(key, superset);\n    }\n  }\n\n","sourceOld":"  /**\n   * getDocList version that uses+populates query and filter caches.\n   * In the event of a timeout, the cache is not populated.\n   */\n  private void getDocListC(QueryResult qr, QueryCommand cmd) throws IOException {\n    // old parameters: DocListAndSet out, Query query, List<Query> filterList, DocSet filter, Sort lsort, int offset, int len, int flags, long timeAllowed, NamedList<Object> responseHeader\n    DocListAndSet out = new DocListAndSet();\n    qr.setDocListAndSet(out);\n    QueryResultKey key=null;\n    int maxDocRequested = cmd.getOffset() + cmd.getLen();\n    // check for overflow, and check for # docs in index\n    if (maxDocRequested < 0 || maxDocRequested > maxDoc()) maxDocRequested = maxDoc();\n    int supersetMaxDoc= maxDocRequested;\n    DocList superset;\n\n    // we can try and look up the complete query in the cache.\n    // we can't do that if filter!=null though (we don't want to\n    // do hashCode() and equals() for a big DocSet).\n    if (queryResultCache != null && cmd.getFilter()==null) {\n        // all of the current flags can be reused during warming,\n        // so set all of them on the cache key.\n        key = new QueryResultKey(cmd.getQuery(), cmd.getFilterList(), cmd.getSort(), cmd.getFlags());\n        if ((cmd.getFlags() & NO_CHECK_QCACHE)==0) {\n          superset = (DocList)queryResultCache.get(key);\n\n          if (superset != null) {\n            // check that the cache entry has scores recorded if we need them\n            if ((cmd.getFlags() & GET_SCORES)==0 || superset.hasScores()) {\n              // NOTE: subset() returns null if the DocList has fewer docs than\n              // requested\n              out.docList = superset.subset(cmd.getOffset(),cmd.getLen());\n            }\n          }\n          if (out.docList != null) {\n            // found the docList in the cache... now check if we need the docset too.\n            // OPT: possible future optimization - if the doclist contains all the matches,\n            // use it to make the docset instead of rerunning the query.\n            if (out.docSet==null && ((cmd.getFlags() & GET_DOCSET)!=0) ) {\n              if (cmd.getFilterList()==null) {\n                out.docSet = getDocSet(cmd.getQuery());\n              } else {\n                List<Query> newList = new ArrayList<Query>(cmd.getFilterList()\n.size()+1);\n                newList.add(cmd.getQuery());\n                newList.addAll(cmd.getFilterList());\n                out.docSet = getDocSet(newList);\n              }\n            }\n            return;\n          }\n        }\n\n        // If we are going to generate the result, bump up to the\n        // next resultWindowSize for better caching.\n\n        // handle 0 special case as well as avoid idiv in the common case.\n        if (maxDocRequested < queryResultWindowSize) {\n          supersetMaxDoc=queryResultWindowSize;\n        } else {\n          supersetMaxDoc = ((maxDocRequested -1)/queryResultWindowSize + 1)*queryResultWindowSize;\n          if (supersetMaxDoc < 0) supersetMaxDoc=maxDocRequested;\n        }\n    }\n\n\n    // OK, so now we need to generate an answer.\n    // One way to do that would be to check if we have an unordered list\n    // of results for the base query.  If so, we can apply the filters and then\n    // sort by the resulting set.  This can only be used if:\n    // - the sort doesn't contain score\n    // - we don't want score returned.\n\n    // check if we should try and use the filter cache\n    boolean useFilterCache=false;\n    if ((cmd.getFlags() & (GET_SCORES|NO_CHECK_FILTERCACHE))==0 && useFilterForSortedQuery && cmd.getSort() != null && filterCache != null) {\n      useFilterCache=true;\n      SortField[] sfields = cmd.getSort().getSort();\n      for (SortField sf : sfields) {\n        if (sf.getType() == SortField.SCORE) {\n          useFilterCache=false;\n          break;\n        }\n      }\n    }\n\n    if (useFilterCache) {\n      // now actually use the filter cache.\n      // for large filters that match few documents, this may be\n      // slower than simply re-executing the query.\n      if (out.docSet == null) {\n        out.docSet = getDocSet(cmd.getQuery(),cmd.getFilter());\n        DocSet bigFilt = getDocSet(cmd.getFilterList());\n        if (bigFilt != null) out.docSet = out.docSet.intersection(bigFilt);\n      }\n      // todo: there could be a sortDocSet that could take a list of\n      // the filters instead of anding them first...\n      // perhaps there should be a multi-docset-iterator\n      superset = sortDocSet(out.docSet,cmd.getSort(),supersetMaxDoc);\n      out.docList = superset.subset(cmd.getOffset(),cmd.getLen());\n    } else {\n      // do it the normal way...\n      cmd.setSupersetMaxDoc(supersetMaxDoc);\n      if ((cmd.getFlags() & GET_DOCSET)!=0) {\n        // this currently conflates returning the docset for the base query vs\n        // the base query and all filters.\n        DocSet qDocSet = getDocListAndSetNC(qr,cmd);\n        // cache the docSet matching the query w/o filtering\n        if (qDocSet!=null && filterCache!=null && !qr.isPartialResults()) filterCache.put(cmd.getQuery(),qDocSet);\n      } else {\n        getDocListNC(qr,cmd);\n        //Parameters: cmd.getQuery(),theFilt,cmd.getSort(),0,supersetMaxDoc,cmd.getFlags(),cmd.getTimeAllowed(),responseHeader);\n      }\n      superset = out.docList;\n      out.docList = superset.subset(cmd.getOffset(),cmd.getLen());\n    }\n\n    // lastly, put the superset in the cache if the size is less than or equal\n    // to queryResultMaxDocsCached\n    if (key != null && superset.size() <= queryResultMaxDocsCached && !qr.isPartialResults()) {\n      queryResultCache.put(key, superset);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"ad94625fb8d088209f46650c8097196fec67f00c","date":1453508319,"type":5,"author":"Dawid Weiss","isMerge":false,"pathNew":"solr/src/java/org/apache/solr/search/SolrIndexSearcher#getDocListC(QueryResult,QueryCommand).mjava","pathOld":"src/java/org/apache/solr/search/SolrIndexSearcher#getDocListC(QueryResult,QueryCommand).mjava","sourceNew":"  /**\n   * getDocList version that uses+populates query and filter caches.\n   * In the event of a timeout, the cache is not populated.\n   */\n  private void getDocListC(QueryResult qr, QueryCommand cmd) throws IOException {\n    // old parameters: DocListAndSet out, Query query, List<Query> filterList, DocSet filter, Sort lsort, int offset, int len, int flags, long timeAllowed, NamedList<Object> responseHeader\n    DocListAndSet out = new DocListAndSet();\n    qr.setDocListAndSet(out);\n    QueryResultKey key=null;\n    int maxDocRequested = cmd.getOffset() + cmd.getLen();\n    // check for overflow, and check for # docs in index\n    if (maxDocRequested < 0 || maxDocRequested > maxDoc()) maxDocRequested = maxDoc();\n    int supersetMaxDoc= maxDocRequested;\n    DocList superset;\n\n    // we can try and look up the complete query in the cache.\n    // we can't do that if filter!=null though (we don't want to\n    // do hashCode() and equals() for a big DocSet).\n    if (queryResultCache != null && cmd.getFilter()==null) {\n        // all of the current flags can be reused during warming,\n        // so set all of them on the cache key.\n        key = new QueryResultKey(cmd.getQuery(), cmd.getFilterList(), cmd.getSort(), cmd.getFlags());\n        if ((cmd.getFlags() & NO_CHECK_QCACHE)==0) {\n          superset = (DocList)queryResultCache.get(key);\n\n          if (superset != null) {\n            // check that the cache entry has scores recorded if we need them\n            if ((cmd.getFlags() & GET_SCORES)==0 || superset.hasScores()) {\n              // NOTE: subset() returns null if the DocList has fewer docs than\n              // requested\n              out.docList = superset.subset(cmd.getOffset(),cmd.getLen());\n            }\n          }\n          if (out.docList != null) {\n            // found the docList in the cache... now check if we need the docset too.\n            // OPT: possible future optimization - if the doclist contains all the matches,\n            // use it to make the docset instead of rerunning the query.\n            if (out.docSet==null && ((cmd.getFlags() & GET_DOCSET)!=0) ) {\n              if (cmd.getFilterList()==null) {\n                out.docSet = getDocSet(cmd.getQuery());\n              } else {\n                List<Query> newList = new ArrayList<Query>(cmd.getFilterList()\n.size()+1);\n                newList.add(cmd.getQuery());\n                newList.addAll(cmd.getFilterList());\n                out.docSet = getDocSet(newList);\n              }\n            }\n            return;\n          }\n        }\n\n        // If we are going to generate the result, bump up to the\n        // next resultWindowSize for better caching.\n\n        // handle 0 special case as well as avoid idiv in the common case.\n        if (maxDocRequested < queryResultWindowSize) {\n          supersetMaxDoc=queryResultWindowSize;\n        } else {\n          supersetMaxDoc = ((maxDocRequested -1)/queryResultWindowSize + 1)*queryResultWindowSize;\n          if (supersetMaxDoc < 0) supersetMaxDoc=maxDocRequested;\n        }\n    }\n\n\n    // OK, so now we need to generate an answer.\n    // One way to do that would be to check if we have an unordered list\n    // of results for the base query.  If so, we can apply the filters and then\n    // sort by the resulting set.  This can only be used if:\n    // - the sort doesn't contain score\n    // - we don't want score returned.\n\n    // check if we should try and use the filter cache\n    boolean useFilterCache=false;\n    if ((cmd.getFlags() & (GET_SCORES|NO_CHECK_FILTERCACHE))==0 && useFilterForSortedQuery && cmd.getSort() != null && filterCache != null) {\n      useFilterCache=true;\n      SortField[] sfields = cmd.getSort().getSort();\n      for (SortField sf : sfields) {\n        if (sf.getType() == SortField.SCORE) {\n          useFilterCache=false;\n          break;\n        }\n      }\n    }\n\n    // disable useFilterCache optimization temporarily\n    if (useFilterCache) {\n      // now actually use the filter cache.\n      // for large filters that match few documents, this may be\n      // slower than simply re-executing the query.\n      if (out.docSet == null) {\n        out.docSet = getDocSet(cmd.getQuery(),cmd.getFilter());\n        DocSet bigFilt = getDocSet(cmd.getFilterList());\n        if (bigFilt != null) out.docSet = out.docSet.intersection(bigFilt);\n      }\n      // todo: there could be a sortDocSet that could take a list of\n      // the filters instead of anding them first...\n      // perhaps there should be a multi-docset-iterator\n      superset = sortDocSet(out.docSet,cmd.getSort(),supersetMaxDoc);\n      out.docList = superset.subset(cmd.getOffset(),cmd.getLen());\n    } else {\n      // do it the normal way...\n      cmd.setSupersetMaxDoc(supersetMaxDoc);\n      if ((cmd.getFlags() & GET_DOCSET)!=0) {\n        // this currently conflates returning the docset for the base query vs\n        // the base query and all filters.\n        DocSet qDocSet = getDocListAndSetNC(qr,cmd);\n        // cache the docSet matching the query w/o filtering\n        if (qDocSet!=null && filterCache!=null && !qr.isPartialResults()) filterCache.put(cmd.getQuery(),qDocSet);\n      } else {\n        getDocListNC(qr,cmd);\n        //Parameters: cmd.getQuery(),theFilt,cmd.getSort(),0,supersetMaxDoc,cmd.getFlags(),cmd.getTimeAllowed(),responseHeader);\n      }\n      superset = out.docList;\n      out.docList = superset.subset(cmd.getOffset(),cmd.getLen());\n    }\n\n    // lastly, put the superset in the cache if the size is less than or equal\n    // to queryResultMaxDocsCached\n    if (key != null && superset.size() <= queryResultMaxDocsCached && !qr.isPartialResults()) {\n      queryResultCache.put(key, superset);\n    }\n  }\n\n","sourceOld":"  /**\n   * getDocList version that uses+populates query and filter caches.\n   * In the event of a timeout, the cache is not populated.\n   */\n  private void getDocListC(QueryResult qr, QueryCommand cmd) throws IOException {\n    // old parameters: DocListAndSet out, Query query, List<Query> filterList, DocSet filter, Sort lsort, int offset, int len, int flags, long timeAllowed, NamedList<Object> responseHeader\n    DocListAndSet out = new DocListAndSet();\n    qr.setDocListAndSet(out);\n    QueryResultKey key=null;\n    int maxDocRequested = cmd.getOffset() + cmd.getLen();\n    // check for overflow, and check for # docs in index\n    if (maxDocRequested < 0 || maxDocRequested > maxDoc()) maxDocRequested = maxDoc();\n    int supersetMaxDoc= maxDocRequested;\n    DocList superset;\n\n    // we can try and look up the complete query in the cache.\n    // we can't do that if filter!=null though (we don't want to\n    // do hashCode() and equals() for a big DocSet).\n    if (queryResultCache != null && cmd.getFilter()==null) {\n        // all of the current flags can be reused during warming,\n        // so set all of them on the cache key.\n        key = new QueryResultKey(cmd.getQuery(), cmd.getFilterList(), cmd.getSort(), cmd.getFlags());\n        if ((cmd.getFlags() & NO_CHECK_QCACHE)==0) {\n          superset = (DocList)queryResultCache.get(key);\n\n          if (superset != null) {\n            // check that the cache entry has scores recorded if we need them\n            if ((cmd.getFlags() & GET_SCORES)==0 || superset.hasScores()) {\n              // NOTE: subset() returns null if the DocList has fewer docs than\n              // requested\n              out.docList = superset.subset(cmd.getOffset(),cmd.getLen());\n            }\n          }\n          if (out.docList != null) {\n            // found the docList in the cache... now check if we need the docset too.\n            // OPT: possible future optimization - if the doclist contains all the matches,\n            // use it to make the docset instead of rerunning the query.\n            if (out.docSet==null && ((cmd.getFlags() & GET_DOCSET)!=0) ) {\n              if (cmd.getFilterList()==null) {\n                out.docSet = getDocSet(cmd.getQuery());\n              } else {\n                List<Query> newList = new ArrayList<Query>(cmd.getFilterList()\n.size()+1);\n                newList.add(cmd.getQuery());\n                newList.addAll(cmd.getFilterList());\n                out.docSet = getDocSet(newList);\n              }\n            }\n            return;\n          }\n        }\n\n        // If we are going to generate the result, bump up to the\n        // next resultWindowSize for better caching.\n\n        // handle 0 special case as well as avoid idiv in the common case.\n        if (maxDocRequested < queryResultWindowSize) {\n          supersetMaxDoc=queryResultWindowSize;\n        } else {\n          supersetMaxDoc = ((maxDocRequested -1)/queryResultWindowSize + 1)*queryResultWindowSize;\n          if (supersetMaxDoc < 0) supersetMaxDoc=maxDocRequested;\n        }\n    }\n\n\n    // OK, so now we need to generate an answer.\n    // One way to do that would be to check if we have an unordered list\n    // of results for the base query.  If so, we can apply the filters and then\n    // sort by the resulting set.  This can only be used if:\n    // - the sort doesn't contain score\n    // - we don't want score returned.\n\n    // check if we should try and use the filter cache\n    boolean useFilterCache=false;\n    if ((cmd.getFlags() & (GET_SCORES|NO_CHECK_FILTERCACHE))==0 && useFilterForSortedQuery && cmd.getSort() != null && filterCache != null) {\n      useFilterCache=true;\n      SortField[] sfields = cmd.getSort().getSort();\n      for (SortField sf : sfields) {\n        if (sf.getType() == SortField.SCORE) {\n          useFilterCache=false;\n          break;\n        }\n      }\n    }\n\n    // disable useFilterCache optimization temporarily\n    if (useFilterCache) {\n      // now actually use the filter cache.\n      // for large filters that match few documents, this may be\n      // slower than simply re-executing the query.\n      if (out.docSet == null) {\n        out.docSet = getDocSet(cmd.getQuery(),cmd.getFilter());\n        DocSet bigFilt = getDocSet(cmd.getFilterList());\n        if (bigFilt != null) out.docSet = out.docSet.intersection(bigFilt);\n      }\n      // todo: there could be a sortDocSet that could take a list of\n      // the filters instead of anding them first...\n      // perhaps there should be a multi-docset-iterator\n      superset = sortDocSet(out.docSet,cmd.getSort(),supersetMaxDoc);\n      out.docList = superset.subset(cmd.getOffset(),cmd.getLen());\n    } else {\n      // do it the normal way...\n      cmd.setSupersetMaxDoc(supersetMaxDoc);\n      if ((cmd.getFlags() & GET_DOCSET)!=0) {\n        // this currently conflates returning the docset for the base query vs\n        // the base query and all filters.\n        DocSet qDocSet = getDocListAndSetNC(qr,cmd);\n        // cache the docSet matching the query w/o filtering\n        if (qDocSet!=null && filterCache!=null && !qr.isPartialResults()) filterCache.put(cmd.getQuery(),qDocSet);\n      } else {\n        getDocListNC(qr,cmd);\n        //Parameters: cmd.getQuery(),theFilt,cmd.getSort(),0,supersetMaxDoc,cmd.getFlags(),cmd.getTimeAllowed(),responseHeader);\n      }\n      superset = out.docList;\n      out.docList = superset.subset(cmd.getOffset(),cmd.getLen());\n    }\n\n    // lastly, put the superset in the cache if the size is less than or equal\n    // to queryResultMaxDocsCached\n    if (key != null && superset.size() <= queryResultMaxDocsCached && !qr.isPartialResults()) {\n      queryResultCache.put(key, superset);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"52df4540d5cd0c887f5e56ef0f387d7489f5d44f":["db25c1f61b5ae826f10777da6551a832703967d5"],"ac3e6437547a34cce2b5405ce0cf9e3af578401e":["52df4540d5cd0c887f5e56ef0f387d7489f5d44f"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b":[],"db25c1f61b5ae826f10777da6551a832703967d5":["3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b"],"ad94625fb8d088209f46650c8097196fec67f00c":["ac3e6437547a34cce2b5405ce0cf9e3af578401e"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"52df4540d5cd0c887f5e56ef0f387d7489f5d44f":["ac3e6437547a34cce2b5405ce0cf9e3af578401e"],"ac3e6437547a34cce2b5405ce0cf9e3af578401e":["ad94625fb8d088209f46650c8097196fec67f00c"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b":["db25c1f61b5ae826f10777da6551a832703967d5"],"db25c1f61b5ae826f10777da6551a832703967d5":["52df4540d5cd0c887f5e56ef0f387d7489f5d44f"],"ad94625fb8d088209f46650c8097196fec67f00c":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["ad94625fb8d088209f46650c8097196fec67f00c","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b"],"pathCommit":null}