{"path":"solr/core/src/test/org/apache/solr/core/snapshots/TestSolrCoreSnapshots#testIndexOptimization().mjava","commits":[{"id":"91e2345fb81b6c1c7faefa550ee5eaafadc54486","date":1469730189,"type":0,"author":"David Smiley","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/core/snapshots/TestSolrCoreSnapshots#testIndexOptimization().mjava","pathOld":"/dev/null","sourceNew":"  @Test\n  public void testIndexOptimization() throws Exception {\n    CloudSolrClient solrClient = cluster.getSolrClient();\n    String collectionName = \"SolrCoreSnapshots_IndexOptimization\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName, \"conf1\", 1, 1);\n    create.process(solrClient);\n\n    int nDocs = BackupRestoreUtils.indexDocs(cluster.getSolrClient(), collectionName, docsSeed);\n\n    DocCollection collectionState = solrClient.getZkStateReader().getClusterState().getCollection(collectionName);\n    assertEquals(1, collectionState.getActiveSlices().size());\n    Slice shard = collectionState.getActiveSlices().iterator().next();\n    assertEquals(1, shard.getReplicas().size());\n    Replica replica = shard.getReplicas().iterator().next();\n\n    String coreName = replica.getStr(ZkStateReader.CORE_NAME_PROP);\n    String commitName = TestUtil.randomSimpleString(random(), 1, 5);\n\n    try (\n        SolrClient adminClient = getHttpSolrClient(cluster.getJettySolrRunners().get(0).getBaseUrl().toString());\n        SolrClient masterClient = getHttpSolrClient(replica.getCoreUrl())) {\n\n      SnapshotMetaData metaData = createSnapshot(adminClient, coreName, commitName);\n\n      int numTests = nDocs > 0 ? TestUtil.nextInt(random(), 1, 5) : 1;\n      for (int attempt=0; attempt<numTests; attempt++) {\n        //Modify existing index before we call optimize.\n        if (nDocs > 0) {\n          //Delete a few docs\n          int numDeletes = TestUtil.nextInt(random(), 1, nDocs);\n          for(int i=0; i<numDeletes; i++) {\n            masterClient.deleteByQuery(\"id:\" + i);\n          }\n          //Add a few more\n          int moreAdds = TestUtil.nextInt(random(), 1, 100);\n          for (int i=0; i<moreAdds; i++) {\n            SolrInputDocument doc = new SolrInputDocument();\n            doc.addField(\"id\", i + nDocs);\n            doc.addField(\"name\", \"name = \" + (i + nDocs));\n            masterClient.add(doc);\n          }\n          masterClient.commit();\n        }\n      }\n\n      // Before invoking optimize command, verify that the index directory contains multiple commits (including the one we snapshotted earlier).\n      {\n        Collection<IndexCommit> commits = listCommits(metaData.getIndexDirPath());\n        // Verify that multiple index commits are stored in this directory.\n        assertTrue(commits.size() > 0);\n        // Verify that the snapshot commit is present in this directory.\n        assertTrue(commits.stream().filter(x -> x.getGeneration() == metaData.getGenerationNumber()).findFirst().isPresent());\n      }\n\n      // Optimize the index.\n      masterClient.optimize(true, true, 1);\n\n      // After invoking optimize command, verify that the index directory contains multiple commits (including the one we snapshotted earlier).\n      {\n        List<IndexCommit> commits = listCommits(metaData.getIndexDirPath());\n        // Verify that multiple index commits are stored in this directory.\n        assertTrue(commits.size() > 1);\n        // Verify that the snapshot commit is present in this directory.\n        assertTrue(commits.stream().filter(x -> x.getGeneration() == metaData.getGenerationNumber()).findFirst().isPresent());\n      }\n\n      // Delete the snapshot\n      deleteSnapshot(adminClient, coreName, metaData.getName());\n\n      // Add few documents. Without this the optimize command below does not take effect.\n      {\n        int moreAdds = TestUtil.nextInt(random(), 1, 100);\n        for (int i=0; i<moreAdds; i++) {\n          SolrInputDocument doc = new SolrInputDocument();\n          doc.addField(\"id\", i + nDocs);\n          doc.addField(\"name\", \"name = \" + (i + nDocs));\n          masterClient.add(doc);\n        }\n        masterClient.commit();\n      }\n\n      // Optimize the index.\n      masterClient.optimize(true, true, 1);\n\n      // Verify that the index directory contains only 1 index commit (which is not the same as the snapshotted commit).\n      Collection<IndexCommit> commits = listCommits(metaData.getIndexDirPath());\n      assertTrue(commits.size() == 1);\n      assertFalse(commits.stream().filter(x -> x.getGeneration() == metaData.getGenerationNumber()).findFirst().isPresent());\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3b013574eedcdbac35dc7e35b0ee616ffc38895d","date":1470897818,"type":0,"author":"Noble Paul","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/core/snapshots/TestSolrCoreSnapshots#testIndexOptimization().mjava","pathOld":"/dev/null","sourceNew":"  @Test\n  public void testIndexOptimization() throws Exception {\n    CloudSolrClient solrClient = cluster.getSolrClient();\n    String collectionName = \"SolrCoreSnapshots_IndexOptimization\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName, \"conf1\", 1, 1);\n    create.process(solrClient);\n\n    int nDocs = BackupRestoreUtils.indexDocs(cluster.getSolrClient(), collectionName, docsSeed);\n\n    DocCollection collectionState = solrClient.getZkStateReader().getClusterState().getCollection(collectionName);\n    assertEquals(1, collectionState.getActiveSlices().size());\n    Slice shard = collectionState.getActiveSlices().iterator().next();\n    assertEquals(1, shard.getReplicas().size());\n    Replica replica = shard.getReplicas().iterator().next();\n\n    String coreName = replica.getStr(ZkStateReader.CORE_NAME_PROP);\n    String commitName = TestUtil.randomSimpleString(random(), 1, 5);\n\n    try (\n        SolrClient adminClient = getHttpSolrClient(cluster.getJettySolrRunners().get(0).getBaseUrl().toString());\n        SolrClient masterClient = getHttpSolrClient(replica.getCoreUrl())) {\n\n      SnapshotMetaData metaData = createSnapshot(adminClient, coreName, commitName);\n\n      int numTests = nDocs > 0 ? TestUtil.nextInt(random(), 1, 5) : 1;\n      for (int attempt=0; attempt<numTests; attempt++) {\n        //Modify existing index before we call optimize.\n        if (nDocs > 0) {\n          //Delete a few docs\n          int numDeletes = TestUtil.nextInt(random(), 1, nDocs);\n          for(int i=0; i<numDeletes; i++) {\n            masterClient.deleteByQuery(\"id:\" + i);\n          }\n          //Add a few more\n          int moreAdds = TestUtil.nextInt(random(), 1, 100);\n          for (int i=0; i<moreAdds; i++) {\n            SolrInputDocument doc = new SolrInputDocument();\n            doc.addField(\"id\", i + nDocs);\n            doc.addField(\"name\", \"name = \" + (i + nDocs));\n            masterClient.add(doc);\n          }\n          masterClient.commit();\n        }\n      }\n\n      // Before invoking optimize command, verify that the index directory contains multiple commits (including the one we snapshotted earlier).\n      {\n        Collection<IndexCommit> commits = listCommits(metaData.getIndexDirPath());\n        // Verify that multiple index commits are stored in this directory.\n        assertTrue(commits.size() > 0);\n        // Verify that the snapshot commit is present in this directory.\n        assertTrue(commits.stream().filter(x -> x.getGeneration() == metaData.getGenerationNumber()).findFirst().isPresent());\n      }\n\n      // Optimize the index.\n      masterClient.optimize(true, true, 1);\n\n      // After invoking optimize command, verify that the index directory contains multiple commits (including the one we snapshotted earlier).\n      {\n        List<IndexCommit> commits = listCommits(metaData.getIndexDirPath());\n        // Verify that multiple index commits are stored in this directory.\n        assertTrue(commits.size() > 1);\n        // Verify that the snapshot commit is present in this directory.\n        assertTrue(commits.stream().filter(x -> x.getGeneration() == metaData.getGenerationNumber()).findFirst().isPresent());\n      }\n\n      // Delete the snapshot\n      deleteSnapshot(adminClient, coreName, metaData.getName());\n\n      // Add few documents. Without this the optimize command below does not take effect.\n      {\n        int moreAdds = TestUtil.nextInt(random(), 1, 100);\n        for (int i=0; i<moreAdds; i++) {\n          SolrInputDocument doc = new SolrInputDocument();\n          doc.addField(\"id\", i + nDocs);\n          doc.addField(\"name\", \"name = \" + (i + nDocs));\n          masterClient.add(doc);\n        }\n        masterClient.commit();\n      }\n\n      // Optimize the index.\n      masterClient.optimize(true, true, 1);\n\n      // Verify that the index directory contains only 1 index commit (which is not the same as the snapshotted commit).\n      Collection<IndexCommit> commits = listCommits(metaData.getIndexDirPath());\n      assertTrue(commits.size() == 1);\n      assertFalse(commits.stream().filter(x -> x.getGeneration() == metaData.getGenerationNumber()).findFirst().isPresent());\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4cce5816ef15a48a0bc11e5d400497ee4301dd3b","date":1476991456,"type":0,"author":"Kevin Risden","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/core/snapshots/TestSolrCoreSnapshots#testIndexOptimization().mjava","pathOld":"/dev/null","sourceNew":"  @Test\n  public void testIndexOptimization() throws Exception {\n    CloudSolrClient solrClient = cluster.getSolrClient();\n    String collectionName = \"SolrCoreSnapshots_IndexOptimization\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName, \"conf1\", 1, 1);\n    create.process(solrClient);\n\n    int nDocs = BackupRestoreUtils.indexDocs(cluster.getSolrClient(), collectionName, docsSeed);\n\n    DocCollection collectionState = solrClient.getZkStateReader().getClusterState().getCollection(collectionName);\n    assertEquals(1, collectionState.getActiveSlices().size());\n    Slice shard = collectionState.getActiveSlices().iterator().next();\n    assertEquals(1, shard.getReplicas().size());\n    Replica replica = shard.getReplicas().iterator().next();\n\n    String coreName = replica.getStr(ZkStateReader.CORE_NAME_PROP);\n    String commitName = TestUtil.randomSimpleString(random(), 1, 5);\n\n    try (\n        SolrClient adminClient = getHttpSolrClient(cluster.getJettySolrRunners().get(0).getBaseUrl().toString());\n        SolrClient masterClient = getHttpSolrClient(replica.getCoreUrl())) {\n\n      SnapshotMetaData metaData = createSnapshot(adminClient, coreName, commitName);\n\n      int numTests = nDocs > 0 ? TestUtil.nextInt(random(), 1, 5) : 1;\n      for (int attempt=0; attempt<numTests; attempt++) {\n        //Modify existing index before we call optimize.\n        if (nDocs > 0) {\n          //Delete a few docs\n          int numDeletes = TestUtil.nextInt(random(), 1, nDocs);\n          for(int i=0; i<numDeletes; i++) {\n            masterClient.deleteByQuery(\"id:\" + i);\n          }\n          //Add a few more\n          int moreAdds = TestUtil.nextInt(random(), 1, 100);\n          for (int i=0; i<moreAdds; i++) {\n            SolrInputDocument doc = new SolrInputDocument();\n            doc.addField(\"id\", i + nDocs);\n            doc.addField(\"name\", \"name = \" + (i + nDocs));\n            masterClient.add(doc);\n          }\n          masterClient.commit();\n        }\n      }\n\n      // Before invoking optimize command, verify that the index directory contains multiple commits (including the one we snapshotted earlier).\n      {\n        Collection<IndexCommit> commits = listCommits(metaData.getIndexDirPath());\n        // Verify that multiple index commits are stored in this directory.\n        assertTrue(commits.size() > 0);\n        // Verify that the snapshot commit is present in this directory.\n        assertTrue(commits.stream().filter(x -> x.getGeneration() == metaData.getGenerationNumber()).findFirst().isPresent());\n      }\n\n      // Optimize the index.\n      masterClient.optimize(true, true, 1);\n\n      // After invoking optimize command, verify that the index directory contains multiple commits (including the one we snapshotted earlier).\n      {\n        List<IndexCommit> commits = listCommits(metaData.getIndexDirPath());\n        // Verify that multiple index commits are stored in this directory.\n        assertTrue(commits.size() > 1);\n        // Verify that the snapshot commit is present in this directory.\n        assertTrue(commits.stream().filter(x -> x.getGeneration() == metaData.getGenerationNumber()).findFirst().isPresent());\n      }\n\n      // Delete the snapshot\n      deleteSnapshot(adminClient, coreName, metaData.getName());\n\n      // Add few documents. Without this the optimize command below does not take effect.\n      {\n        int moreAdds = TestUtil.nextInt(random(), 1, 100);\n        for (int i=0; i<moreAdds; i++) {\n          SolrInputDocument doc = new SolrInputDocument();\n          doc.addField(\"id\", i + nDocs);\n          doc.addField(\"name\", \"name = \" + (i + nDocs));\n          masterClient.add(doc);\n        }\n        masterClient.commit();\n      }\n\n      // Optimize the index.\n      masterClient.optimize(true, true, 1);\n\n      // Verify that the index directory contains only 1 index commit (which is not the same as the snapshotted commit).\n      Collection<IndexCommit> commits = listCommits(metaData.getIndexDirPath());\n      assertTrue(commits.size() == 1);\n      assertFalse(commits.stream().filter(x -> x.getGeneration() == metaData.getGenerationNumber()).findFirst().isPresent());\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"65a5d87a40f9143cd55be76eb1dde1b32a8dae5e","date":1596664368,"type":3,"author":"Marcus","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/core/snapshots/TestSolrCoreSnapshots#testIndexOptimization().mjava","pathOld":"solr/core/src/test/org/apache/solr/core/snapshots/TestSolrCoreSnapshots#testIndexOptimization().mjava","sourceNew":"  @Test\n  public void testIndexOptimization() throws Exception {\n    CloudSolrClient solrClient = cluster.getSolrClient();\n    String collectionName = \"SolrCoreSnapshots_IndexOptimization\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName, \"conf1\", 1, 1);\n    create.process(solrClient);\n\n    int nDocs = BackupRestoreUtils.indexDocs(cluster.getSolrClient(), collectionName, docsSeed);\n\n    DocCollection collectionState = solrClient.getZkStateReader().getClusterState().getCollection(collectionName);\n    assertEquals(1, collectionState.getActiveSlices().size());\n    Slice shard = collectionState.getActiveSlices().iterator().next();\n    assertEquals(1, shard.getReplicas().size());\n    Replica replica = shard.getReplicas().iterator().next();\n\n    String coreName = replica.getStr(ZkStateReader.CORE_NAME_PROP);\n    String commitName = TestUtil.randomSimpleString(random(), 1, 5);\n\n    try (\n        SolrClient adminClient = getHttpSolrClient(cluster.getJettySolrRunners().get(0).getBaseUrl().toString());\n        SolrClient leaderClient = getHttpSolrClient(replica.getCoreUrl())) {\n\n      SnapshotMetaData metaData = createSnapshot(adminClient, coreName, commitName);\n\n      int numTests = nDocs > 0 ? TestUtil.nextInt(random(), 1, 5) : 1;\n      for (int attempt=0; attempt<numTests; attempt++) {\n        //Modify existing index before we call optimize.\n        if (nDocs > 0) {\n          //Delete a few docs\n          int numDeletes = TestUtil.nextInt(random(), 1, nDocs);\n          for(int i=0; i<numDeletes; i++) {\n            leaderClient.deleteByQuery(\"id:\" + i);\n          }\n          //Add a few more\n          int moreAdds = TestUtil.nextInt(random(), 1, 100);\n          for (int i=0; i<moreAdds; i++) {\n            SolrInputDocument doc = new SolrInputDocument();\n            doc.addField(\"id\", i + nDocs);\n            doc.addField(\"name\", \"name = \" + (i + nDocs));\n            leaderClient.add(doc);\n          }\n          leaderClient.commit();\n        }\n      }\n\n      // Before invoking optimize command, verify that the index directory contains multiple commits (including the one we snapshotted earlier).\n      {\n        Collection<IndexCommit> commits = listCommits(metaData.getIndexDirPath());\n        // Verify that multiple index commits are stored in this directory.\n        assertTrue(commits.size() > 0);\n        // Verify that the snapshot commit is present in this directory.\n        assertTrue(commits.stream().filter(x -> x.getGeneration() == metaData.getGenerationNumber()).findFirst().isPresent());\n      }\n\n      // Optimize the index.\n      leaderClient.optimize(true, true, 1);\n\n      // After invoking optimize command, verify that the index directory contains multiple commits (including the one we snapshotted earlier).\n      {\n        List<IndexCommit> commits = listCommits(metaData.getIndexDirPath());\n        // Verify that multiple index commits are stored in this directory.\n        assertTrue(commits.size() > 1);\n        // Verify that the snapshot commit is present in this directory.\n        assertTrue(commits.stream().filter(x -> x.getGeneration() == metaData.getGenerationNumber()).findFirst().isPresent());\n      }\n\n      // Delete the snapshot\n      deleteSnapshot(adminClient, coreName, metaData.getName());\n\n      // Add few documents. Without this the optimize command below does not take effect.\n      {\n        int moreAdds = TestUtil.nextInt(random(), 1, 100);\n        for (int i=0; i<moreAdds; i++) {\n          SolrInputDocument doc = new SolrInputDocument();\n          doc.addField(\"id\", i + nDocs);\n          doc.addField(\"name\", \"name = \" + (i + nDocs));\n          leaderClient.add(doc);\n        }\n        leaderClient.commit();\n      }\n\n      // Optimize the index.\n      leaderClient.optimize(true, true, 1);\n\n      // Verify that the index directory contains only 1 index commit (which is not the same as the snapshotted commit).\n      Collection<IndexCommit> commits = listCommits(metaData.getIndexDirPath());\n      assertTrue(commits.size() == 1);\n      assertFalse(commits.stream().filter(x -> x.getGeneration() == metaData.getGenerationNumber()).findFirst().isPresent());\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testIndexOptimization() throws Exception {\n    CloudSolrClient solrClient = cluster.getSolrClient();\n    String collectionName = \"SolrCoreSnapshots_IndexOptimization\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName, \"conf1\", 1, 1);\n    create.process(solrClient);\n\n    int nDocs = BackupRestoreUtils.indexDocs(cluster.getSolrClient(), collectionName, docsSeed);\n\n    DocCollection collectionState = solrClient.getZkStateReader().getClusterState().getCollection(collectionName);\n    assertEquals(1, collectionState.getActiveSlices().size());\n    Slice shard = collectionState.getActiveSlices().iterator().next();\n    assertEquals(1, shard.getReplicas().size());\n    Replica replica = shard.getReplicas().iterator().next();\n\n    String coreName = replica.getStr(ZkStateReader.CORE_NAME_PROP);\n    String commitName = TestUtil.randomSimpleString(random(), 1, 5);\n\n    try (\n        SolrClient adminClient = getHttpSolrClient(cluster.getJettySolrRunners().get(0).getBaseUrl().toString());\n        SolrClient masterClient = getHttpSolrClient(replica.getCoreUrl())) {\n\n      SnapshotMetaData metaData = createSnapshot(adminClient, coreName, commitName);\n\n      int numTests = nDocs > 0 ? TestUtil.nextInt(random(), 1, 5) : 1;\n      for (int attempt=0; attempt<numTests; attempt++) {\n        //Modify existing index before we call optimize.\n        if (nDocs > 0) {\n          //Delete a few docs\n          int numDeletes = TestUtil.nextInt(random(), 1, nDocs);\n          for(int i=0; i<numDeletes; i++) {\n            masterClient.deleteByQuery(\"id:\" + i);\n          }\n          //Add a few more\n          int moreAdds = TestUtil.nextInt(random(), 1, 100);\n          for (int i=0; i<moreAdds; i++) {\n            SolrInputDocument doc = new SolrInputDocument();\n            doc.addField(\"id\", i + nDocs);\n            doc.addField(\"name\", \"name = \" + (i + nDocs));\n            masterClient.add(doc);\n          }\n          masterClient.commit();\n        }\n      }\n\n      // Before invoking optimize command, verify that the index directory contains multiple commits (including the one we snapshotted earlier).\n      {\n        Collection<IndexCommit> commits = listCommits(metaData.getIndexDirPath());\n        // Verify that multiple index commits are stored in this directory.\n        assertTrue(commits.size() > 0);\n        // Verify that the snapshot commit is present in this directory.\n        assertTrue(commits.stream().filter(x -> x.getGeneration() == metaData.getGenerationNumber()).findFirst().isPresent());\n      }\n\n      // Optimize the index.\n      masterClient.optimize(true, true, 1);\n\n      // After invoking optimize command, verify that the index directory contains multiple commits (including the one we snapshotted earlier).\n      {\n        List<IndexCommit> commits = listCommits(metaData.getIndexDirPath());\n        // Verify that multiple index commits are stored in this directory.\n        assertTrue(commits.size() > 1);\n        // Verify that the snapshot commit is present in this directory.\n        assertTrue(commits.stream().filter(x -> x.getGeneration() == metaData.getGenerationNumber()).findFirst().isPresent());\n      }\n\n      // Delete the snapshot\n      deleteSnapshot(adminClient, coreName, metaData.getName());\n\n      // Add few documents. Without this the optimize command below does not take effect.\n      {\n        int moreAdds = TestUtil.nextInt(random(), 1, 100);\n        for (int i=0; i<moreAdds; i++) {\n          SolrInputDocument doc = new SolrInputDocument();\n          doc.addField(\"id\", i + nDocs);\n          doc.addField(\"name\", \"name = \" + (i + nDocs));\n          masterClient.add(doc);\n        }\n        masterClient.commit();\n      }\n\n      // Optimize the index.\n      masterClient.optimize(true, true, 1);\n\n      // Verify that the index directory contains only 1 index commit (which is not the same as the snapshotted commit).\n      Collection<IndexCommit> commits = listCommits(metaData.getIndexDirPath());\n      assertTrue(commits.size() == 1);\n      assertFalse(commits.stream().filter(x -> x.getGeneration() == metaData.getGenerationNumber()).findFirst().isPresent());\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"65a5d87a40f9143cd55be76eb1dde1b32a8dae5e":["91e2345fb81b6c1c7faefa550ee5eaafadc54486"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","91e2345fb81b6c1c7faefa550ee5eaafadc54486"],"3b013574eedcdbac35dc7e35b0ee616ffc38895d":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","91e2345fb81b6c1c7faefa550ee5eaafadc54486"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["65a5d87a40f9143cd55be76eb1dde1b32a8dae5e"],"91e2345fb81b6c1c7faefa550ee5eaafadc54486":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"65a5d87a40f9143cd55be76eb1dde1b32a8dae5e":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b","3b013574eedcdbac35dc7e35b0ee616ffc38895d","91e2345fb81b6c1c7faefa550ee5eaafadc54486"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":[],"3b013574eedcdbac35dc7e35b0ee616ffc38895d":[],"91e2345fb81b6c1c7faefa550ee5eaafadc54486":["65a5d87a40f9143cd55be76eb1dde1b32a8dae5e","4cce5816ef15a48a0bc11e5d400497ee4301dd3b","3b013574eedcdbac35dc7e35b0ee616ffc38895d"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b","3b013574eedcdbac35dc7e35b0ee616ffc38895d","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}