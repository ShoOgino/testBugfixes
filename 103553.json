{"path":"lucene/src/java/org/apache/lucene/codecs/lucene40/Lucene40StoredFieldsWriter#copyFieldsNoDeletions(MergeState,MergeState.IndexReaderAndLiveDocs,Lucene40StoredFieldsReader,int[]).mjava","commits":[{"id":"a0ae5e3ed1232483b7b8a014f175a5fe43595982","date":1324062192,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/codecs/lucene40/Lucene40StoredFieldsWriter#copyFieldsNoDeletions(MergeState,MergeState.IndexReaderAndLiveDocs,Lucene40StoredFieldsReader,int[]).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/codecs/lucene40/Lucene40StoredFieldsWriter#copyFieldsNoDeletions(MergeState,MergeState.IndexReaderAndLiveDocs,Lucene40StoredFieldsReader,int[]).mjava","sourceNew":"  private int copyFieldsNoDeletions(MergeState mergeState, final MergeState.IndexReaderAndLiveDocs reader,\n                                    final Lucene40StoredFieldsReader matchingFieldsReader, int rawDocLengths[])\n    throws IOException, MergeAbortedException, CorruptIndexException {\n    final int maxDoc = reader.reader.maxDoc();\n    int docCount = 0;\n    if (matchingFieldsReader != null) {\n      // We can bulk-copy because the fieldInfos are \"congruent\"\n      while (docCount < maxDoc) {\n        int len = Math.min(MAX_RAW_MERGE_DOCS, maxDoc - docCount);\n        IndexInput stream = matchingFieldsReader.rawDocs(rawDocLengths, docCount, len);\n        addRawDocuments(stream, rawDocLengths, len);\n        docCount += len;\n        mergeState.checkAbort.work(300 * len);\n      }\n    } else {\n      for (; docCount < maxDoc; docCount++) {\n        // NOTE: it's very important to first assign to doc then pass it to\n        // fieldsWriter.addDocument; see LUCENE-1282\n        Document doc = reader.reader.document(docCount);\n        addDocument(doc, mergeState.fieldInfos);\n        mergeState.checkAbort.work(300);\n      }\n    }\n    return docCount;\n  }\n\n","sourceOld":"  private int copyFieldsNoDeletions(MergeState mergeState, final MergeState.IndexReaderAndLiveDocs reader,\n                                    final Lucene40StoredFieldsReader matchingFieldsReader, int rawDocLengths[])\n    throws IOException, MergeAbortedException, CorruptIndexException {\n    final int maxDoc = reader.reader.maxDoc();\n    int docCount = 0;\n    if (matchingFieldsReader != null) {\n      // We can bulk-copy because the fieldInfos are \"congruent\"\n      while (docCount < maxDoc) {\n        int len = Math.min(MAX_RAW_MERGE_DOCS, maxDoc - docCount);\n        IndexInput stream = matchingFieldsReader.rawDocs(rawDocLengths, docCount, len);\n        addRawDocuments(stream, rawDocLengths, len);\n        docCount += len;\n        mergeState.checkAbort.work(300 * len);\n      }\n    } else {\n      for (; docCount < maxDoc; docCount++) {\n        // NOTE: it's very important to first assign to doc then pass it to\n        // fieldsWriter.addDocument; see LUCENE-1282\n        Document doc = reader.reader.document(docCount);\n        addDocument(doc, mergeState.fieldInfos);\n        mergeState.checkAbort.work(300);\n      }\n    }\n    return docCount;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":5,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene40/Lucene40StoredFieldsWriter#copyFieldsNoDeletions(MergeState,MergeState.IndexReaderAndLiveDocs,Lucene40StoredFieldsReader,int[]).mjava","pathOld":"lucene/src/java/org/apache/lucene/codecs/lucene40/Lucene40StoredFieldsWriter#copyFieldsNoDeletions(MergeState,MergeState.IndexReaderAndLiveDocs,Lucene40StoredFieldsReader,int[]).mjava","sourceNew":"  private int copyFieldsNoDeletions(MergeState mergeState, final MergeState.IndexReaderAndLiveDocs reader,\n                                    final Lucene40StoredFieldsReader matchingFieldsReader, int rawDocLengths[])\n    throws IOException, MergeAbortedException, CorruptIndexException {\n    final int maxDoc = reader.reader.maxDoc();\n    int docCount = 0;\n    if (matchingFieldsReader != null) {\n      // We can bulk-copy because the fieldInfos are \"congruent\"\n      while (docCount < maxDoc) {\n        int len = Math.min(MAX_RAW_MERGE_DOCS, maxDoc - docCount);\n        IndexInput stream = matchingFieldsReader.rawDocs(rawDocLengths, docCount, len);\n        addRawDocuments(stream, rawDocLengths, len);\n        docCount += len;\n        mergeState.checkAbort.work(300 * len);\n      }\n    } else {\n      for (; docCount < maxDoc; docCount++) {\n        // NOTE: it's very important to first assign to doc then pass it to\n        // fieldsWriter.addDocument; see LUCENE-1282\n        Document doc = reader.reader.document(docCount);\n        addDocument(doc, mergeState.fieldInfos);\n        mergeState.checkAbort.work(300);\n      }\n    }\n    return docCount;\n  }\n\n","sourceOld":"  private int copyFieldsNoDeletions(MergeState mergeState, final MergeState.IndexReaderAndLiveDocs reader,\n                                    final Lucene40StoredFieldsReader matchingFieldsReader, int rawDocLengths[])\n    throws IOException, MergeAbortedException, CorruptIndexException {\n    final int maxDoc = reader.reader.maxDoc();\n    int docCount = 0;\n    if (matchingFieldsReader != null) {\n      // We can bulk-copy because the fieldInfos are \"congruent\"\n      while (docCount < maxDoc) {\n        int len = Math.min(MAX_RAW_MERGE_DOCS, maxDoc - docCount);\n        IndexInput stream = matchingFieldsReader.rawDocs(rawDocLengths, docCount, len);\n        addRawDocuments(stream, rawDocLengths, len);\n        docCount += len;\n        mergeState.checkAbort.work(300 * len);\n      }\n    } else {\n      for (; docCount < maxDoc; docCount++) {\n        // NOTE: it's very important to first assign to doc then pass it to\n        // fieldsWriter.addDocument; see LUCENE-1282\n        Document doc = reader.reader.document(docCount);\n        addDocument(doc, mergeState.fieldInfos);\n        mergeState.checkAbort.work(300);\n      }\n    }\n    return docCount;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["a0ae5e3ed1232483b7b8a014f175a5fe43595982"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"a0ae5e3ed1232483b7b8a014f175a5fe43595982":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"]},"commit2Childs":{"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["a0ae5e3ed1232483b7b8a014f175a5fe43595982"],"a0ae5e3ed1232483b7b8a014f175a5fe43595982":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}