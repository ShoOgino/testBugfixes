{"path":"lucene/codecs/src/test/org/apache/lucene/codecs/autoprefix/TestAutoPrefixTerms#testBasicNumericRanges().mjava","commits":[{"id":"3e8715d826e588419327562287d5d6a8040d63d6","date":1427987148,"type":0,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/codecs/src/test/org/apache/lucene/codecs/autoprefix/TestAutoPrefixTerms#testBasicNumericRanges().mjava","pathOld":"/dev/null","sourceNew":"  // Numbers in a restricted range, encoded in decimal, left-0-padded:\n  public void testBasicNumericRanges() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = new IndexWriterConfig(new MockAnalyzer(random()));\n    iwc.setCodec(codec);\n    IndexWriter w = new IndexWriter(dir, iwc);\n    int numTerms = TestUtil.nextInt(random(), 3000, 50000);\n    Set<String> terms = new HashSet<>();\n    int digits = TestUtil.nextInt(random(), 5, 10);\n    int maxValue = 1;\n    for(int i=0;i<digits;i++) {\n      maxValue *= 10;\n    }\n    String format = \"%0\" + digits + \"d\";\n    while (terms.size() < numTerms) {\n      terms.add(String.format(Locale.ROOT, format, random().nextInt(maxValue)));\n    }\n\n    for(String term : terms) {\n      Document doc = new Document();\n      doc.add(new StringField(\"field\", term, Field.Store.NO));\n      doc.add(new NumericDocValuesField(\"field\", Long.parseLong(term)));\n      w.addDocument(doc);\n    }\n\n    if (VERBOSE) System.out.println(\"\\nTEST: now optimize\");\n    if (random().nextBoolean()) {\n      w.forceMerge(1);\n    }\n\n    if (VERBOSE) System.out.println(\"\\nTEST: now done\");\n    IndexReader r = DirectoryReader.open(w, true);\n\n    List<String> sortedTerms = new ArrayList<>(terms);\n    Collections.sort(sortedTerms);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: sorted terms:\");\n      int idx = 0;\n      for(String term : sortedTerms) {\n        System.out.println(idx + \": \" + term);\n        idx++;\n      }\n    }\n\n    int iters = atLeast(100);\n    for(int iter=0;iter<iters;iter++) {\n      int min, max;\n      while (true) {\n        min = random().nextInt(maxValue);\n        max = random().nextInt(maxValue);\n        if (min == max) {\n          continue;\n        } else if (min > max) {\n          int x = min;\n          min = max;\n          max = x;\n        }\n        break;\n      }\n      \n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: iter=\" + iter + \" min=\" + min + \" max=\" + max);\n      }\n\n      boolean minInclusive = random().nextBoolean();\n      boolean maxInclusive = random().nextBoolean();\n      BytesRef minTerm = new BytesRef(String.format(Locale.ROOT, format, min));\n      BytesRef maxTerm = new BytesRef(String.format(Locale.ROOT, format, max));\n      CompiledAutomaton ca = new CompiledAutomaton(Automata.makeBinaryInterval(minTerm, minInclusive, maxTerm, maxInclusive),\n                                                   true, false, Integer.MAX_VALUE, true);\n\n      TermsEnum te = ca.getTermsEnum(MultiFields.getTerms(r, \"field\"));\n      NumericDocValues docValues = MultiDocValues.getNumericValues(r, \"field\");\n      PostingsEnum postingsEnum = null;\n\n      VerifyAutoPrefixTerms verifier = new VerifyAutoPrefixTerms(r.maxDoc(), minTerm, maxTerm);\n\n      while (te.next() != null) {\n        if (VERBOSE) {\n          System.out.println(\"  got term=\" + te.term().utf8ToString());\n        }\n        verifier.sawTerm(te.term());\n        postingsEnum = te.postings(null, postingsEnum);\n        int docID;\n        while ((docID = postingsEnum.nextDoc()) != PostingsEnum.NO_MORE_DOCS) {\n          long v = docValues.get(docID);\n          assert v >= min && v <= max: \"docID=\" + docID + \" v=\" + v;\n          // The auto-prefix terms should never \"overlap\" one another, so we should only ever see a given docID one time:\n          if (VERBOSE) {\n            System.out.println(\"    got docID=\" + docID + \" v=\" + v);\n          }\n          verifier.sawDoc(docID);\n        }\n      }\n      \n      int startLoc = Collections.binarySearch(sortedTerms, String.format(Locale.ROOT, format, min));\n      if (startLoc < 0) {\n        startLoc = -startLoc-1;\n      } else if (minInclusive == false) {\n        startLoc++;\n      }\n      int endLoc = Collections.binarySearch(sortedTerms, String.format(Locale.ROOT, format, max));\n      if (endLoc < 0) {\n        endLoc = -endLoc-2;\n      } else if (maxInclusive == false) {\n        endLoc--;\n      }\n      verifier.finish(endLoc-startLoc+1, maxTermsAutoPrefix);\n    }\n\n    r.close();\n    w.close();\n    dir.close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d2638f781be724518ff6c2263d14a48cf6e68017","date":1427989059,"type":0,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/codecs/src/test/org/apache/lucene/codecs/autoprefix/TestAutoPrefixTerms#testBasicNumericRanges().mjava","pathOld":"/dev/null","sourceNew":"  // Numbers in a restricted range, encoded in decimal, left-0-padded:\n  public void testBasicNumericRanges() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = new IndexWriterConfig(new MockAnalyzer(random()));\n    iwc.setCodec(codec);\n    IndexWriter w = new IndexWriter(dir, iwc);\n    int numTerms = TestUtil.nextInt(random(), 3000, 50000);\n    Set<String> terms = new HashSet<>();\n    int digits = TestUtil.nextInt(random(), 5, 10);\n    int maxValue = 1;\n    for(int i=0;i<digits;i++) {\n      maxValue *= 10;\n    }\n    String format = \"%0\" + digits + \"d\";\n    while (terms.size() < numTerms) {\n      terms.add(String.format(Locale.ROOT, format, random().nextInt(maxValue)));\n    }\n\n    for(String term : terms) {\n      Document doc = new Document();\n      doc.add(new StringField(\"field\", term, Field.Store.NO));\n      doc.add(new NumericDocValuesField(\"field\", Long.parseLong(term)));\n      w.addDocument(doc);\n    }\n\n    if (VERBOSE) System.out.println(\"\\nTEST: now optimize\");\n    if (random().nextBoolean()) {\n      w.forceMerge(1);\n    }\n\n    if (VERBOSE) System.out.println(\"\\nTEST: now done\");\n    IndexReader r = DirectoryReader.open(w, true);\n\n    List<String> sortedTerms = new ArrayList<>(terms);\n    Collections.sort(sortedTerms);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: sorted terms:\");\n      int idx = 0;\n      for(String term : sortedTerms) {\n        System.out.println(idx + \": \" + term);\n        idx++;\n      }\n    }\n\n    int iters = atLeast(100);\n    for(int iter=0;iter<iters;iter++) {\n      int min, max;\n      while (true) {\n        min = random().nextInt(maxValue);\n        max = random().nextInt(maxValue);\n        if (min == max) {\n          continue;\n        } else if (min > max) {\n          int x = min;\n          min = max;\n          max = x;\n        }\n        break;\n      }\n      \n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: iter=\" + iter + \" min=\" + min + \" max=\" + max);\n      }\n\n      boolean minInclusive = random().nextBoolean();\n      boolean maxInclusive = random().nextBoolean();\n      BytesRef minTerm = new BytesRef(String.format(Locale.ROOT, format, min));\n      BytesRef maxTerm = new BytesRef(String.format(Locale.ROOT, format, max));\n      CompiledAutomaton ca = new CompiledAutomaton(Automata.makeBinaryInterval(minTerm, minInclusive, maxTerm, maxInclusive),\n                                                   true, false, Integer.MAX_VALUE, true);\n\n      TermsEnum te = ca.getTermsEnum(MultiFields.getTerms(r, \"field\"));\n      NumericDocValues docValues = MultiDocValues.getNumericValues(r, \"field\");\n      PostingsEnum postingsEnum = null;\n\n      VerifyAutoPrefixTerms verifier = new VerifyAutoPrefixTerms(r.maxDoc(), minTerm, maxTerm);\n\n      while (te.next() != null) {\n        if (VERBOSE) {\n          System.out.println(\"  got term=\" + te.term().utf8ToString());\n        }\n        verifier.sawTerm(te.term());\n        postingsEnum = te.postings(null, postingsEnum);\n        int docID;\n        while ((docID = postingsEnum.nextDoc()) != PostingsEnum.NO_MORE_DOCS) {\n          long v = docValues.get(docID);\n          assert v >= min && v <= max: \"docID=\" + docID + \" v=\" + v;\n          // The auto-prefix terms should never \"overlap\" one another, so we should only ever see a given docID one time:\n          if (VERBOSE) {\n            System.out.println(\"    got docID=\" + docID + \" v=\" + v);\n          }\n          verifier.sawDoc(docID);\n        }\n      }\n      \n      int startLoc = Collections.binarySearch(sortedTerms, String.format(Locale.ROOT, format, min));\n      if (startLoc < 0) {\n        startLoc = -startLoc-1;\n      } else if (minInclusive == false) {\n        startLoc++;\n      }\n      int endLoc = Collections.binarySearch(sortedTerms, String.format(Locale.ROOT, format, max));\n      if (endLoc < 0) {\n        endLoc = -endLoc-2;\n      } else if (maxInclusive == false) {\n        endLoc--;\n      }\n      verifier.finish(endLoc-startLoc+1, maxTermsAutoPrefix);\n    }\n\n    r.close();\n    w.close();\n    dir.close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0f4464508ee83288c8c4585b533f9faaa93aa314","date":1435240759,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/codecs/src/test/org/apache/lucene/codecs/autoprefix/TestAutoPrefixTerms#testBasicNumericRanges().mjava","pathOld":"lucene/codecs/src/test/org/apache/lucene/codecs/autoprefix/TestAutoPrefixTerms#testBasicNumericRanges().mjava","sourceNew":"  // Numbers in a restricted range, encoded in decimal, left-0-padded:\n  public void testBasicNumericRanges() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = new IndexWriterConfig(new MockAnalyzer(random()));\n    iwc.setCodec(codec);\n    IndexWriter w = new IndexWriter(dir, iwc);\n    int numTerms = TestUtil.nextInt(random(), 3000, 50000);\n    Set<String> terms = new HashSet<>();\n    int digits = TestUtil.nextInt(random(), 5, 10);\n    int maxValue = 1;\n    for(int i=0;i<digits;i++) {\n      maxValue *= 10;\n    }\n    String format = \"%0\" + digits + \"d\";\n    while (terms.size() < numTerms) {\n      terms.add(String.format(Locale.ROOT, format, random().nextInt(maxValue)));\n    }\n\n    for(String term : terms) {\n      Document doc = new Document();\n      doc.add(new StringField(\"field\", term, Field.Store.NO));\n      doc.add(new NumericDocValuesField(\"field\", Long.parseLong(term)));\n      w.addDocument(doc);\n    }\n\n    if (VERBOSE) System.out.println(\"\\nTEST: now optimize\");\n    if (random().nextBoolean()) {\n      w.forceMerge(1);\n    }\n\n    if (VERBOSE) System.out.println(\"\\nTEST: now done\");\n    IndexReader r = DirectoryReader.open(w, true);\n\n    List<String> sortedTerms = new ArrayList<>(terms);\n    Collections.sort(sortedTerms);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: sorted terms:\");\n      int idx = 0;\n      for(String term : sortedTerms) {\n        System.out.println(idx + \": \" + term);\n        idx++;\n      }\n    }\n\n    int iters = atLeast(100);\n    for(int iter=0;iter<iters;iter++) {\n      int min, max;\n      while (true) {\n        min = random().nextInt(maxValue);\n        max = random().nextInt(maxValue);\n        if (min == max) {\n          continue;\n        } else if (min > max) {\n          int x = min;\n          min = max;\n          max = x;\n        }\n        break;\n      }\n      \n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: iter=\" + iter + \" min=\" + min + \" max=\" + max);\n      }\n\n      boolean minInclusive = random().nextBoolean();\n      boolean maxInclusive = random().nextBoolean();\n      BytesRef minTerm = new BytesRef(String.format(Locale.ROOT, format, min));\n      BytesRef maxTerm = new BytesRef(String.format(Locale.ROOT, format, max));\n      CompiledAutomaton ca = new CompiledAutomaton(Automata.makeBinaryInterval(minTerm, minInclusive, maxTerm, maxInclusive),\n                                                   true, false, Integer.MAX_VALUE, true);\n\n      TermsEnum te = ca.getTermsEnum(MultiFields.getTerms(r, \"field\"));\n      NumericDocValues docValues = MultiDocValues.getNumericValues(r, \"field\");\n      PostingsEnum postingsEnum = null;\n\n      VerifyAutoPrefixTerms verifier = new VerifyAutoPrefixTerms(r.maxDoc(), minTerm, maxTerm);\n\n      while (te.next() != null) {\n        if (VERBOSE) {\n          System.out.println(\"  got term=\" + te.term().utf8ToString());\n        }\n        verifier.sawTerm(te.term());\n        postingsEnum = te.postings(postingsEnum);\n        int docID;\n        while ((docID = postingsEnum.nextDoc()) != PostingsEnum.NO_MORE_DOCS) {\n          long v = docValues.get(docID);\n          assert v >= min && v <= max: \"docID=\" + docID + \" v=\" + v;\n          // The auto-prefix terms should never \"overlap\" one another, so we should only ever see a given docID one time:\n          if (VERBOSE) {\n            System.out.println(\"    got docID=\" + docID + \" v=\" + v);\n          }\n          verifier.sawDoc(docID);\n        }\n      }\n      \n      int startLoc = Collections.binarySearch(sortedTerms, String.format(Locale.ROOT, format, min));\n      if (startLoc < 0) {\n        startLoc = -startLoc-1;\n      } else if (minInclusive == false) {\n        startLoc++;\n      }\n      int endLoc = Collections.binarySearch(sortedTerms, String.format(Locale.ROOT, format, max));\n      if (endLoc < 0) {\n        endLoc = -endLoc-2;\n      } else if (maxInclusive == false) {\n        endLoc--;\n      }\n      verifier.finish(endLoc-startLoc+1, maxTermsAutoPrefix);\n    }\n\n    r.close();\n    w.close();\n    dir.close();\n  }\n\n","sourceOld":"  // Numbers in a restricted range, encoded in decimal, left-0-padded:\n  public void testBasicNumericRanges() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = new IndexWriterConfig(new MockAnalyzer(random()));\n    iwc.setCodec(codec);\n    IndexWriter w = new IndexWriter(dir, iwc);\n    int numTerms = TestUtil.nextInt(random(), 3000, 50000);\n    Set<String> terms = new HashSet<>();\n    int digits = TestUtil.nextInt(random(), 5, 10);\n    int maxValue = 1;\n    for(int i=0;i<digits;i++) {\n      maxValue *= 10;\n    }\n    String format = \"%0\" + digits + \"d\";\n    while (terms.size() < numTerms) {\n      terms.add(String.format(Locale.ROOT, format, random().nextInt(maxValue)));\n    }\n\n    for(String term : terms) {\n      Document doc = new Document();\n      doc.add(new StringField(\"field\", term, Field.Store.NO));\n      doc.add(new NumericDocValuesField(\"field\", Long.parseLong(term)));\n      w.addDocument(doc);\n    }\n\n    if (VERBOSE) System.out.println(\"\\nTEST: now optimize\");\n    if (random().nextBoolean()) {\n      w.forceMerge(1);\n    }\n\n    if (VERBOSE) System.out.println(\"\\nTEST: now done\");\n    IndexReader r = DirectoryReader.open(w, true);\n\n    List<String> sortedTerms = new ArrayList<>(terms);\n    Collections.sort(sortedTerms);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: sorted terms:\");\n      int idx = 0;\n      for(String term : sortedTerms) {\n        System.out.println(idx + \": \" + term);\n        idx++;\n      }\n    }\n\n    int iters = atLeast(100);\n    for(int iter=0;iter<iters;iter++) {\n      int min, max;\n      while (true) {\n        min = random().nextInt(maxValue);\n        max = random().nextInt(maxValue);\n        if (min == max) {\n          continue;\n        } else if (min > max) {\n          int x = min;\n          min = max;\n          max = x;\n        }\n        break;\n      }\n      \n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: iter=\" + iter + \" min=\" + min + \" max=\" + max);\n      }\n\n      boolean minInclusive = random().nextBoolean();\n      boolean maxInclusive = random().nextBoolean();\n      BytesRef minTerm = new BytesRef(String.format(Locale.ROOT, format, min));\n      BytesRef maxTerm = new BytesRef(String.format(Locale.ROOT, format, max));\n      CompiledAutomaton ca = new CompiledAutomaton(Automata.makeBinaryInterval(minTerm, minInclusive, maxTerm, maxInclusive),\n                                                   true, false, Integer.MAX_VALUE, true);\n\n      TermsEnum te = ca.getTermsEnum(MultiFields.getTerms(r, \"field\"));\n      NumericDocValues docValues = MultiDocValues.getNumericValues(r, \"field\");\n      PostingsEnum postingsEnum = null;\n\n      VerifyAutoPrefixTerms verifier = new VerifyAutoPrefixTerms(r.maxDoc(), minTerm, maxTerm);\n\n      while (te.next() != null) {\n        if (VERBOSE) {\n          System.out.println(\"  got term=\" + te.term().utf8ToString());\n        }\n        verifier.sawTerm(te.term());\n        postingsEnum = te.postings(null, postingsEnum);\n        int docID;\n        while ((docID = postingsEnum.nextDoc()) != PostingsEnum.NO_MORE_DOCS) {\n          long v = docValues.get(docID);\n          assert v >= min && v <= max: \"docID=\" + docID + \" v=\" + v;\n          // The auto-prefix terms should never \"overlap\" one another, so we should only ever see a given docID one time:\n          if (VERBOSE) {\n            System.out.println(\"    got docID=\" + docID + \" v=\" + v);\n          }\n          verifier.sawDoc(docID);\n        }\n      }\n      \n      int startLoc = Collections.binarySearch(sortedTerms, String.format(Locale.ROOT, format, min));\n      if (startLoc < 0) {\n        startLoc = -startLoc-1;\n      } else if (minInclusive == false) {\n        startLoc++;\n      }\n      int endLoc = Collections.binarySearch(sortedTerms, String.format(Locale.ROOT, format, max));\n      if (endLoc < 0) {\n        endLoc = -endLoc-2;\n      } else if (maxInclusive == false) {\n        endLoc--;\n      }\n      verifier.finish(endLoc-startLoc+1, maxTermsAutoPrefix);\n    }\n\n    r.close();\n    w.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2a1862266772deb28cdcb7d996b64d2177022687","date":1453077824,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/codecs/src/test/org/apache/lucene/codecs/autoprefix/TestAutoPrefixTerms#testBasicNumericRanges().mjava","pathOld":"lucene/codecs/src/test/org/apache/lucene/codecs/autoprefix/TestAutoPrefixTerms#testBasicNumericRanges().mjava","sourceNew":"  // Numbers in a restricted range, encoded in decimal, left-0-padded:\n  public void testBasicNumericRanges() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = new IndexWriterConfig(new MockAnalyzer(random()));\n    iwc.setCodec(codec);\n    IndexWriter w = new IndexWriter(dir, iwc);\n    int numTerms = TestUtil.nextInt(random(), 3000, 50000);\n    Set<String> terms = new HashSet<>();\n    int digits = TestUtil.nextInt(random(), 5, 10);\n    int maxValue = 1;\n    for(int i=0;i<digits;i++) {\n      maxValue *= 10;\n    }\n    String format = \"%0\" + digits + \"d\";\n    while (terms.size() < numTerms) {\n      terms.add(String.format(Locale.ROOT, format, random().nextInt(maxValue)));\n    }\n\n    for(String term : terms) {\n      Document doc = new Document();\n      doc.add(new StringField(\"field\", term, Field.Store.NO));\n      doc.add(new NumericDocValuesField(\"field\", Long.parseLong(term)));\n      w.addDocument(doc);\n    }\n\n    if (VERBOSE) System.out.println(\"\\nTEST: now optimize\");\n    if (random().nextBoolean()) {\n      w.forceMerge(1);\n    }\n\n    if (VERBOSE) System.out.println(\"\\nTEST: now done\");\n    IndexReader r = DirectoryReader.open(w);\n\n    List<String> sortedTerms = new ArrayList<>(terms);\n    Collections.sort(sortedTerms);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: sorted terms:\");\n      int idx = 0;\n      for(String term : sortedTerms) {\n        System.out.println(idx + \": \" + term);\n        idx++;\n      }\n    }\n\n    int iters = atLeast(100);\n    for(int iter=0;iter<iters;iter++) {\n      int min, max;\n      while (true) {\n        min = random().nextInt(maxValue);\n        max = random().nextInt(maxValue);\n        if (min == max) {\n          continue;\n        } else if (min > max) {\n          int x = min;\n          min = max;\n          max = x;\n        }\n        break;\n      }\n      \n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: iter=\" + iter + \" min=\" + min + \" max=\" + max);\n      }\n\n      boolean minInclusive = random().nextBoolean();\n      boolean maxInclusive = random().nextBoolean();\n      BytesRef minTerm = new BytesRef(String.format(Locale.ROOT, format, min));\n      BytesRef maxTerm = new BytesRef(String.format(Locale.ROOT, format, max));\n      CompiledAutomaton ca = new CompiledAutomaton(Automata.makeBinaryInterval(minTerm, minInclusive, maxTerm, maxInclusive),\n                                                   true, false, Integer.MAX_VALUE, true);\n\n      TermsEnum te = ca.getTermsEnum(MultiFields.getTerms(r, \"field\"));\n      NumericDocValues docValues = MultiDocValues.getNumericValues(r, \"field\");\n      PostingsEnum postingsEnum = null;\n\n      VerifyAutoPrefixTerms verifier = new VerifyAutoPrefixTerms(r.maxDoc(), minTerm, maxTerm);\n\n      while (te.next() != null) {\n        if (VERBOSE) {\n          System.out.println(\"  got term=\" + te.term().utf8ToString());\n        }\n        verifier.sawTerm(te.term());\n        postingsEnum = te.postings(postingsEnum);\n        int docID;\n        while ((docID = postingsEnum.nextDoc()) != PostingsEnum.NO_MORE_DOCS) {\n          long v = docValues.get(docID);\n          assert v >= min && v <= max: \"docID=\" + docID + \" v=\" + v;\n          // The auto-prefix terms should never \"overlap\" one another, so we should only ever see a given docID one time:\n          if (VERBOSE) {\n            System.out.println(\"    got docID=\" + docID + \" v=\" + v);\n          }\n          verifier.sawDoc(docID);\n        }\n      }\n      \n      int startLoc = Collections.binarySearch(sortedTerms, String.format(Locale.ROOT, format, min));\n      if (startLoc < 0) {\n        startLoc = -startLoc-1;\n      } else if (minInclusive == false) {\n        startLoc++;\n      }\n      int endLoc = Collections.binarySearch(sortedTerms, String.format(Locale.ROOT, format, max));\n      if (endLoc < 0) {\n        endLoc = -endLoc-2;\n      } else if (maxInclusive == false) {\n        endLoc--;\n      }\n      verifier.finish(endLoc-startLoc+1, maxTermsAutoPrefix);\n    }\n\n    r.close();\n    w.close();\n    dir.close();\n  }\n\n","sourceOld":"  // Numbers in a restricted range, encoded in decimal, left-0-padded:\n  public void testBasicNumericRanges() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = new IndexWriterConfig(new MockAnalyzer(random()));\n    iwc.setCodec(codec);\n    IndexWriter w = new IndexWriter(dir, iwc);\n    int numTerms = TestUtil.nextInt(random(), 3000, 50000);\n    Set<String> terms = new HashSet<>();\n    int digits = TestUtil.nextInt(random(), 5, 10);\n    int maxValue = 1;\n    for(int i=0;i<digits;i++) {\n      maxValue *= 10;\n    }\n    String format = \"%0\" + digits + \"d\";\n    while (terms.size() < numTerms) {\n      terms.add(String.format(Locale.ROOT, format, random().nextInt(maxValue)));\n    }\n\n    for(String term : terms) {\n      Document doc = new Document();\n      doc.add(new StringField(\"field\", term, Field.Store.NO));\n      doc.add(new NumericDocValuesField(\"field\", Long.parseLong(term)));\n      w.addDocument(doc);\n    }\n\n    if (VERBOSE) System.out.println(\"\\nTEST: now optimize\");\n    if (random().nextBoolean()) {\n      w.forceMerge(1);\n    }\n\n    if (VERBOSE) System.out.println(\"\\nTEST: now done\");\n    IndexReader r = DirectoryReader.open(w, true);\n\n    List<String> sortedTerms = new ArrayList<>(terms);\n    Collections.sort(sortedTerms);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: sorted terms:\");\n      int idx = 0;\n      for(String term : sortedTerms) {\n        System.out.println(idx + \": \" + term);\n        idx++;\n      }\n    }\n\n    int iters = atLeast(100);\n    for(int iter=0;iter<iters;iter++) {\n      int min, max;\n      while (true) {\n        min = random().nextInt(maxValue);\n        max = random().nextInt(maxValue);\n        if (min == max) {\n          continue;\n        } else if (min > max) {\n          int x = min;\n          min = max;\n          max = x;\n        }\n        break;\n      }\n      \n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: iter=\" + iter + \" min=\" + min + \" max=\" + max);\n      }\n\n      boolean minInclusive = random().nextBoolean();\n      boolean maxInclusive = random().nextBoolean();\n      BytesRef minTerm = new BytesRef(String.format(Locale.ROOT, format, min));\n      BytesRef maxTerm = new BytesRef(String.format(Locale.ROOT, format, max));\n      CompiledAutomaton ca = new CompiledAutomaton(Automata.makeBinaryInterval(minTerm, minInclusive, maxTerm, maxInclusive),\n                                                   true, false, Integer.MAX_VALUE, true);\n\n      TermsEnum te = ca.getTermsEnum(MultiFields.getTerms(r, \"field\"));\n      NumericDocValues docValues = MultiDocValues.getNumericValues(r, \"field\");\n      PostingsEnum postingsEnum = null;\n\n      VerifyAutoPrefixTerms verifier = new VerifyAutoPrefixTerms(r.maxDoc(), minTerm, maxTerm);\n\n      while (te.next() != null) {\n        if (VERBOSE) {\n          System.out.println(\"  got term=\" + te.term().utf8ToString());\n        }\n        verifier.sawTerm(te.term());\n        postingsEnum = te.postings(postingsEnum);\n        int docID;\n        while ((docID = postingsEnum.nextDoc()) != PostingsEnum.NO_MORE_DOCS) {\n          long v = docValues.get(docID);\n          assert v >= min && v <= max: \"docID=\" + docID + \" v=\" + v;\n          // The auto-prefix terms should never \"overlap\" one another, so we should only ever see a given docID one time:\n          if (VERBOSE) {\n            System.out.println(\"    got docID=\" + docID + \" v=\" + v);\n          }\n          verifier.sawDoc(docID);\n        }\n      }\n      \n      int startLoc = Collections.binarySearch(sortedTerms, String.format(Locale.ROOT, format, min));\n      if (startLoc < 0) {\n        startLoc = -startLoc-1;\n      } else if (minInclusive == false) {\n        startLoc++;\n      }\n      int endLoc = Collections.binarySearch(sortedTerms, String.format(Locale.ROOT, format, max));\n      if (endLoc < 0) {\n        endLoc = -endLoc-2;\n      } else if (maxInclusive == false) {\n        endLoc--;\n      }\n      verifier.finish(endLoc-startLoc+1, maxTermsAutoPrefix);\n    }\n\n    r.close();\n    w.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"25b8a027ba57951e63075a2ae9647c5c4a8c5c5f","date":1466407389,"type":4,"author":"Adrien Grand","isMerge":false,"pathNew":"/dev/null","pathOld":"lucene/codecs/src/test/org/apache/lucene/codecs/autoprefix/TestAutoPrefixTerms#testBasicNumericRanges().mjava","sourceNew":null,"sourceOld":"  // Numbers in a restricted range, encoded in decimal, left-0-padded:\n  public void testBasicNumericRanges() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = new IndexWriterConfig(new MockAnalyzer(random()));\n    iwc.setCodec(codec);\n    IndexWriter w = new IndexWriter(dir, iwc);\n    int numTerms = TestUtil.nextInt(random(), 3000, 50000);\n    Set<String> terms = new HashSet<>();\n    int digits = TestUtil.nextInt(random(), 5, 10);\n    int maxValue = 1;\n    for(int i=0;i<digits;i++) {\n      maxValue *= 10;\n    }\n    String format = \"%0\" + digits + \"d\";\n    while (terms.size() < numTerms) {\n      terms.add(String.format(Locale.ROOT, format, random().nextInt(maxValue)));\n    }\n\n    for(String term : terms) {\n      Document doc = new Document();\n      doc.add(new StringField(\"field\", term, Field.Store.NO));\n      doc.add(new NumericDocValuesField(\"field\", Long.parseLong(term)));\n      w.addDocument(doc);\n    }\n\n    if (VERBOSE) System.out.println(\"\\nTEST: now optimize\");\n    if (random().nextBoolean()) {\n      w.forceMerge(1);\n    }\n\n    if (VERBOSE) System.out.println(\"\\nTEST: now done\");\n    IndexReader r = DirectoryReader.open(w);\n\n    List<String> sortedTerms = new ArrayList<>(terms);\n    Collections.sort(sortedTerms);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: sorted terms:\");\n      int idx = 0;\n      for(String term : sortedTerms) {\n        System.out.println(idx + \": \" + term);\n        idx++;\n      }\n    }\n\n    int iters = atLeast(100);\n    for(int iter=0;iter<iters;iter++) {\n      int min, max;\n      while (true) {\n        min = random().nextInt(maxValue);\n        max = random().nextInt(maxValue);\n        if (min == max) {\n          continue;\n        } else if (min > max) {\n          int x = min;\n          min = max;\n          max = x;\n        }\n        break;\n      }\n      \n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: iter=\" + iter + \" min=\" + min + \" max=\" + max);\n      }\n\n      boolean minInclusive = random().nextBoolean();\n      boolean maxInclusive = random().nextBoolean();\n      BytesRef minTerm = new BytesRef(String.format(Locale.ROOT, format, min));\n      BytesRef maxTerm = new BytesRef(String.format(Locale.ROOT, format, max));\n      CompiledAutomaton ca = new CompiledAutomaton(Automata.makeBinaryInterval(minTerm, minInclusive, maxTerm, maxInclusive),\n                                                   true, false, Integer.MAX_VALUE, true);\n\n      TermsEnum te = ca.getTermsEnum(MultiFields.getTerms(r, \"field\"));\n      NumericDocValues docValues = MultiDocValues.getNumericValues(r, \"field\");\n      PostingsEnum postingsEnum = null;\n\n      VerifyAutoPrefixTerms verifier = new VerifyAutoPrefixTerms(r.maxDoc(), minTerm, maxTerm);\n\n      while (te.next() != null) {\n        if (VERBOSE) {\n          System.out.println(\"  got term=\" + te.term().utf8ToString());\n        }\n        verifier.sawTerm(te.term());\n        postingsEnum = te.postings(postingsEnum);\n        int docID;\n        while ((docID = postingsEnum.nextDoc()) != PostingsEnum.NO_MORE_DOCS) {\n          long v = docValues.get(docID);\n          assert v >= min && v <= max: \"docID=\" + docID + \" v=\" + v;\n          // The auto-prefix terms should never \"overlap\" one another, so we should only ever see a given docID one time:\n          if (VERBOSE) {\n            System.out.println(\"    got docID=\" + docID + \" v=\" + v);\n          }\n          verifier.sawDoc(docID);\n        }\n      }\n      \n      int startLoc = Collections.binarySearch(sortedTerms, String.format(Locale.ROOT, format, min));\n      if (startLoc < 0) {\n        startLoc = -startLoc-1;\n      } else if (minInclusive == false) {\n        startLoc++;\n      }\n      int endLoc = Collections.binarySearch(sortedTerms, String.format(Locale.ROOT, format, max));\n      if (endLoc < 0) {\n        endLoc = -endLoc-2;\n      } else if (maxInclusive == false) {\n        endLoc--;\n      }\n      verifier.finish(endLoc-startLoc+1, maxTermsAutoPrefix);\n    }\n\n    r.close();\n    w.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6aaba221b22442bdf0ef28770c25fe259dfb3f55","date":1466496193,"type":4,"author":"Noble Paul","isMerge":true,"pathNew":"/dev/null","pathOld":"lucene/codecs/src/test/org/apache/lucene/codecs/autoprefix/TestAutoPrefixTerms#testBasicNumericRanges().mjava","sourceNew":null,"sourceOld":"  // Numbers in a restricted range, encoded in decimal, left-0-padded:\n  public void testBasicNumericRanges() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = new IndexWriterConfig(new MockAnalyzer(random()));\n    iwc.setCodec(codec);\n    IndexWriter w = new IndexWriter(dir, iwc);\n    int numTerms = TestUtil.nextInt(random(), 3000, 50000);\n    Set<String> terms = new HashSet<>();\n    int digits = TestUtil.nextInt(random(), 5, 10);\n    int maxValue = 1;\n    for(int i=0;i<digits;i++) {\n      maxValue *= 10;\n    }\n    String format = \"%0\" + digits + \"d\";\n    while (terms.size() < numTerms) {\n      terms.add(String.format(Locale.ROOT, format, random().nextInt(maxValue)));\n    }\n\n    for(String term : terms) {\n      Document doc = new Document();\n      doc.add(new StringField(\"field\", term, Field.Store.NO));\n      doc.add(new NumericDocValuesField(\"field\", Long.parseLong(term)));\n      w.addDocument(doc);\n    }\n\n    if (VERBOSE) System.out.println(\"\\nTEST: now optimize\");\n    if (random().nextBoolean()) {\n      w.forceMerge(1);\n    }\n\n    if (VERBOSE) System.out.println(\"\\nTEST: now done\");\n    IndexReader r = DirectoryReader.open(w);\n\n    List<String> sortedTerms = new ArrayList<>(terms);\n    Collections.sort(sortedTerms);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: sorted terms:\");\n      int idx = 0;\n      for(String term : sortedTerms) {\n        System.out.println(idx + \": \" + term);\n        idx++;\n      }\n    }\n\n    int iters = atLeast(100);\n    for(int iter=0;iter<iters;iter++) {\n      int min, max;\n      while (true) {\n        min = random().nextInt(maxValue);\n        max = random().nextInt(maxValue);\n        if (min == max) {\n          continue;\n        } else if (min > max) {\n          int x = min;\n          min = max;\n          max = x;\n        }\n        break;\n      }\n      \n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: iter=\" + iter + \" min=\" + min + \" max=\" + max);\n      }\n\n      boolean minInclusive = random().nextBoolean();\n      boolean maxInclusive = random().nextBoolean();\n      BytesRef minTerm = new BytesRef(String.format(Locale.ROOT, format, min));\n      BytesRef maxTerm = new BytesRef(String.format(Locale.ROOT, format, max));\n      CompiledAutomaton ca = new CompiledAutomaton(Automata.makeBinaryInterval(minTerm, minInclusive, maxTerm, maxInclusive),\n                                                   true, false, Integer.MAX_VALUE, true);\n\n      TermsEnum te = ca.getTermsEnum(MultiFields.getTerms(r, \"field\"));\n      NumericDocValues docValues = MultiDocValues.getNumericValues(r, \"field\");\n      PostingsEnum postingsEnum = null;\n\n      VerifyAutoPrefixTerms verifier = new VerifyAutoPrefixTerms(r.maxDoc(), minTerm, maxTerm);\n\n      while (te.next() != null) {\n        if (VERBOSE) {\n          System.out.println(\"  got term=\" + te.term().utf8ToString());\n        }\n        verifier.sawTerm(te.term());\n        postingsEnum = te.postings(postingsEnum);\n        int docID;\n        while ((docID = postingsEnum.nextDoc()) != PostingsEnum.NO_MORE_DOCS) {\n          long v = docValues.get(docID);\n          assert v >= min && v <= max: \"docID=\" + docID + \" v=\" + v;\n          // The auto-prefix terms should never \"overlap\" one another, so we should only ever see a given docID one time:\n          if (VERBOSE) {\n            System.out.println(\"    got docID=\" + docID + \" v=\" + v);\n          }\n          verifier.sawDoc(docID);\n        }\n      }\n      \n      int startLoc = Collections.binarySearch(sortedTerms, String.format(Locale.ROOT, format, min));\n      if (startLoc < 0) {\n        startLoc = -startLoc-1;\n      } else if (minInclusive == false) {\n        startLoc++;\n      }\n      int endLoc = Collections.binarySearch(sortedTerms, String.format(Locale.ROOT, format, max));\n      if (endLoc < 0) {\n        endLoc = -endLoc-2;\n      } else if (maxInclusive == false) {\n        endLoc--;\n      }\n      verifier.finish(endLoc-startLoc+1, maxTermsAutoPrefix);\n    }\n\n    r.close();\n    w.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4cce5816ef15a48a0bc11e5d400497ee4301dd3b","date":1476991456,"type":4,"author":"Kevin Risden","isMerge":true,"pathNew":"/dev/null","pathOld":"lucene/codecs/src/test/org/apache/lucene/codecs/autoprefix/TestAutoPrefixTerms#testBasicNumericRanges().mjava","sourceNew":null,"sourceOld":"  // Numbers in a restricted range, encoded in decimal, left-0-padded:\n  public void testBasicNumericRanges() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = new IndexWriterConfig(new MockAnalyzer(random()));\n    iwc.setCodec(codec);\n    IndexWriter w = new IndexWriter(dir, iwc);\n    int numTerms = TestUtil.nextInt(random(), 3000, 50000);\n    Set<String> terms = new HashSet<>();\n    int digits = TestUtil.nextInt(random(), 5, 10);\n    int maxValue = 1;\n    for(int i=0;i<digits;i++) {\n      maxValue *= 10;\n    }\n    String format = \"%0\" + digits + \"d\";\n    while (terms.size() < numTerms) {\n      terms.add(String.format(Locale.ROOT, format, random().nextInt(maxValue)));\n    }\n\n    for(String term : terms) {\n      Document doc = new Document();\n      doc.add(new StringField(\"field\", term, Field.Store.NO));\n      doc.add(new NumericDocValuesField(\"field\", Long.parseLong(term)));\n      w.addDocument(doc);\n    }\n\n    if (VERBOSE) System.out.println(\"\\nTEST: now optimize\");\n    if (random().nextBoolean()) {\n      w.forceMerge(1);\n    }\n\n    if (VERBOSE) System.out.println(\"\\nTEST: now done\");\n    IndexReader r = DirectoryReader.open(w);\n\n    List<String> sortedTerms = new ArrayList<>(terms);\n    Collections.sort(sortedTerms);\n\n    if (VERBOSE) {\n      System.out.println(\"TEST: sorted terms:\");\n      int idx = 0;\n      for(String term : sortedTerms) {\n        System.out.println(idx + \": \" + term);\n        idx++;\n      }\n    }\n\n    int iters = atLeast(100);\n    for(int iter=0;iter<iters;iter++) {\n      int min, max;\n      while (true) {\n        min = random().nextInt(maxValue);\n        max = random().nextInt(maxValue);\n        if (min == max) {\n          continue;\n        } else if (min > max) {\n          int x = min;\n          min = max;\n          max = x;\n        }\n        break;\n      }\n      \n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: iter=\" + iter + \" min=\" + min + \" max=\" + max);\n      }\n\n      boolean minInclusive = random().nextBoolean();\n      boolean maxInclusive = random().nextBoolean();\n      BytesRef minTerm = new BytesRef(String.format(Locale.ROOT, format, min));\n      BytesRef maxTerm = new BytesRef(String.format(Locale.ROOT, format, max));\n      CompiledAutomaton ca = new CompiledAutomaton(Automata.makeBinaryInterval(minTerm, minInclusive, maxTerm, maxInclusive),\n                                                   true, false, Integer.MAX_VALUE, true);\n\n      TermsEnum te = ca.getTermsEnum(MultiFields.getTerms(r, \"field\"));\n      NumericDocValues docValues = MultiDocValues.getNumericValues(r, \"field\");\n      PostingsEnum postingsEnum = null;\n\n      VerifyAutoPrefixTerms verifier = new VerifyAutoPrefixTerms(r.maxDoc(), minTerm, maxTerm);\n\n      while (te.next() != null) {\n        if (VERBOSE) {\n          System.out.println(\"  got term=\" + te.term().utf8ToString());\n        }\n        verifier.sawTerm(te.term());\n        postingsEnum = te.postings(postingsEnum);\n        int docID;\n        while ((docID = postingsEnum.nextDoc()) != PostingsEnum.NO_MORE_DOCS) {\n          long v = docValues.get(docID);\n          assert v >= min && v <= max: \"docID=\" + docID + \" v=\" + v;\n          // The auto-prefix terms should never \"overlap\" one another, so we should only ever see a given docID one time:\n          if (VERBOSE) {\n            System.out.println(\"    got docID=\" + docID + \" v=\" + v);\n          }\n          verifier.sawDoc(docID);\n        }\n      }\n      \n      int startLoc = Collections.binarySearch(sortedTerms, String.format(Locale.ROOT, format, min));\n      if (startLoc < 0) {\n        startLoc = -startLoc-1;\n      } else if (minInclusive == false) {\n        startLoc++;\n      }\n      int endLoc = Collections.binarySearch(sortedTerms, String.format(Locale.ROOT, format, max));\n      if (endLoc < 0) {\n        endLoc = -endLoc-2;\n      } else if (maxInclusive == false) {\n        endLoc--;\n      }\n      verifier.finish(endLoc-startLoc+1, maxTermsAutoPrefix);\n    }\n\n    r.close();\n    w.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"0f4464508ee83288c8c4585b533f9faaa93aa314":["3e8715d826e588419327562287d5d6a8040d63d6"],"2a1862266772deb28cdcb7d996b64d2177022687":["0f4464508ee83288c8c4585b533f9faaa93aa314"],"6aaba221b22442bdf0ef28770c25fe259dfb3f55":["2a1862266772deb28cdcb7d996b64d2177022687","25b8a027ba57951e63075a2ae9647c5c4a8c5c5f"],"25b8a027ba57951e63075a2ae9647c5c4a8c5c5f":["2a1862266772deb28cdcb7d996b64d2177022687"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"d2638f781be724518ff6c2263d14a48cf6e68017":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","3e8715d826e588419327562287d5d6a8040d63d6"],"3e8715d826e588419327562287d5d6a8040d63d6":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["2a1862266772deb28cdcb7d996b64d2177022687","6aaba221b22442bdf0ef28770c25fe259dfb3f55"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["6aaba221b22442bdf0ef28770c25fe259dfb3f55"]},"commit2Childs":{"0f4464508ee83288c8c4585b533f9faaa93aa314":["2a1862266772deb28cdcb7d996b64d2177022687"],"2a1862266772deb28cdcb7d996b64d2177022687":["6aaba221b22442bdf0ef28770c25fe259dfb3f55","25b8a027ba57951e63075a2ae9647c5c4a8c5c5f","4cce5816ef15a48a0bc11e5d400497ee4301dd3b"],"6aaba221b22442bdf0ef28770c25fe259dfb3f55":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"25b8a027ba57951e63075a2ae9647c5c4a8c5c5f":["6aaba221b22442bdf0ef28770c25fe259dfb3f55"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["d2638f781be724518ff6c2263d14a48cf6e68017","3e8715d826e588419327562287d5d6a8040d63d6"],"d2638f781be724518ff6c2263d14a48cf6e68017":[],"3e8715d826e588419327562287d5d6a8040d63d6":["0f4464508ee83288c8c4585b533f9faaa93aa314","d2638f781be724518ff6c2263d14a48cf6e68017"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["d2638f781be724518ff6c2263d14a48cf6e68017","4cce5816ef15a48a0bc11e5d400497ee4301dd3b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}