{"path":"solr/core/src/java/org/apache/solr/search/join/GraphQuery.GraphQueryWeight#getDocSet().mjava","commits":[{"id":"49f41ca5b59802ba2b8fb507bb73d5c4bf53db2b","date":1444426023,"type":0,"author":"Yonik Seeley","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/join/GraphQuery.GraphQueryWeight#getDocSet().mjava","pathOld":"/dev/null","sourceNew":"    /**\n     * This computes the matching doc set for a given graph query\n     * \n     * @return DocSet representing the documents in the graph.\n     * @throws IOException - if a sub search fails... maybe other cases too! :)\n     */\n    private DocSet getDocSet() throws IOException {\n      DocSet fromSet = null;\n      FixedBitSet seedResultBits = null;\n      // Size that the bit set needs to be.\n      int capacity = fromSearcher.getRawReader().maxDoc();\n      // The bit set to contain the results that match the query.\n      FixedBitSet resultBits = new FixedBitSet(capacity);\n      // The measure of how deep in the graph we have gone.\n      currentDepth = 0;\n      // the initial query for the frontier for the first query\n      Query frontierQuery = q;\n      // Find all documents in this graph that are leaf nodes to speed traversal\n      // TODO: speed this up in the future with HAS_FIELD type queries\n      BooleanQuery.Builder leafNodeQuery = new BooleanQuery.Builder();\n      WildcardQuery edgeQuery = new WildcardQuery(new Term(toField, \"*\"));\n      leafNodeQuery.add(edgeQuery, Occur.MUST_NOT);\n      DocSet leafNodes = fromSearcher.getDocSet(leafNodeQuery.build());\n      // Start the breadth first graph traversal.\n      do {\n        // Create the graph result collector for this level\n        GraphTermsCollector graphResultCollector = new GraphTermsCollector(toField,capacity, resultBits, leafNodes);\n        // traverse the level!\n        fromSearcher.search(frontierQuery, graphResultCollector);\n        // All edge ids on the frontier.\n        BytesRefHash collectorTerms = graphResultCollector.getCollectorTerms();\n        frontierSize = collectorTerms.size();\n        // The resulting doc set from the frontier.\n        fromSet = graphResultCollector.getDocSet();\n        if (seedResultBits == null) {\n          // grab a copy of the seed bits  (these are the \"rootNodes\")\n          seedResultBits = ((BitDocSet)fromSet).getBits().clone();\n        }\n        Integer fs = new Integer(frontierSize);\n        FrontierQuery fq = buildFrontierQuery(collectorTerms, fs);\n        if (fq == null) {\n          // in case we get null back, make sure we know we're done at this level.\n          fq = new FrontierQuery(null, 0);\n        }\n        frontierQuery = fq.getQuery();\n        frontierSize = fq.getFrontierSize();\n        // Add the bits from this level to the result set.\n        resultBits.or(((BitDocSet)fromSet).getBits());\n        // Increment how far we have gone in the frontier.\n        currentDepth++;\n        // Break out if we have reached our max depth\n        if (currentDepth >= maxDepth && maxDepth != -1) {\n          break;\n        }\n        // test if we discovered any new edges, if not , we're done.\n      } while (frontierSize > 0);\n      // helper bit set operations on the final result set\n      if (!returnRoot) {\n        resultBits.andNot(seedResultBits);\n      }\n      BitDocSet resultSet = new BitDocSet(resultBits);\n      // If we only want to return leaf nodes do that here.\n      if (onlyLeafNodes) {\n        return resultSet.intersection(leafNodes);\n      } else {\n        // create a doc set off the bits that we found.\n        return resultSet;\n      }\n    }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"826e791d635df5093032ca5d1925016bdf0c1df6","date":1454083189,"type":3,"author":"yonik","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/join/GraphQuery.GraphQueryWeight#getDocSet().mjava","pathOld":"solr/core/src/java/org/apache/solr/search/join/GraphQuery.GraphQueryWeight#getDocSet().mjava","sourceNew":"    /**\n     * This computes the matching doc set for a given graph query\n     * \n     * @return DocSet representing the documents in the graph.\n     * @throws IOException - if a sub search fails... maybe other cases too! :)\n     */\n    private DocSet getDocSet() throws IOException {\n      // Size that the bit set needs to be.\n      int capacity = fromSearcher.getRawReader().maxDoc();\n      // The bit set to contain the results that match the query.\n      FixedBitSet resultBits = new FixedBitSet(capacity);\n      // this holds the result at each level\n      BitDocSet fromSet = null;\n      // the root docs if we return root is false\n      FixedBitSet rootBits = null;\n      // the initial query for the frontier for the first query\n      Query frontierQuery = q;\n      // Find all documents in this graph that are leaf nodes to speed traversal\n      DocSet leafNodes = resolveLeafNodes(toField);\n      // Start the breadth first graph traversal.\n      \n      do {\n        // Increment how far we have gone in the frontier.\n        currentDepth++;\n        // if we are at the max level we don't need the graph terms collector.\n        // TODO validate that the join case works properly.\n        if (maxDepth != -1 && currentDepth >= maxDepth) {\n          // if we've reached the max depth, don't worry about collecting edges.\n          fromSet = fromSearcher.getDocSetBits(frontierQuery);\n          // explicitly the frontier size is zero now so we can break\n          frontierSize = 0;\n        } else {\n          // when we're not at the max depth level, we need to collect edges          \n          // Create the graph result collector for this level\n          GraphTermsCollector graphResultCollector = new GraphTermsCollector(toField,capacity, resultBits, leafNodes);\n          fromSearcher.search(frontierQuery, graphResultCollector);\n          fromSet = graphResultCollector.getDocSet();\n          // All edge ids on the frontier.\n          BytesRefHash collectorTerms = graphResultCollector.getCollectorTerms();\n          frontierSize = collectorTerms.size();\n          // The resulting doc set from the frontier.\n          FrontierQuery fq = buildFrontierQuery(collectorTerms, frontierSize);\n          if (fq == null) {\n            // in case we get null back, make sure we know we're done at this level.\n            frontierSize = 0;\n          } else {\n            frontierQuery = fq.getQuery();\n            frontierSize = fq.getFrontierSize();\n          }\n        }\n        if (currentDepth == 0 && !returnRoot) {\n          // grab a copy of the root bits but only if we need it.\n          rootBits = fromSet.getBits();\n        }\n        // Add the bits from this level to the result set.\n        resultBits.or(fromSet.getBits());\n        // test if we discovered any new edges, if not , we're done.\n        if ((maxDepth != -1 && currentDepth >= maxDepth)) {\n          break;\n        }\n      } while (frontierSize > 0);\n      // helper bit set operations on the final result set\n      if (!returnRoot) {\n        resultBits.andNot(rootBits);\n      }\n      // this is the final resulting filter.\n      BitDocSet resultSet = new BitDocSet(resultBits);\n      // If we only want to return leaf nodes do that here.\n      if (onlyLeafNodes) {\n        return resultSet.intersection(leafNodes);\n      } else {\n        return resultSet;\n      }\n    }\n\n","sourceOld":"    /**\n     * This computes the matching doc set for a given graph query\n     * \n     * @return DocSet representing the documents in the graph.\n     * @throws IOException - if a sub search fails... maybe other cases too! :)\n     */\n    private DocSet getDocSet() throws IOException {\n      DocSet fromSet = null;\n      FixedBitSet seedResultBits = null;\n      // Size that the bit set needs to be.\n      int capacity = fromSearcher.getRawReader().maxDoc();\n      // The bit set to contain the results that match the query.\n      FixedBitSet resultBits = new FixedBitSet(capacity);\n      // The measure of how deep in the graph we have gone.\n      currentDepth = 0;\n      // the initial query for the frontier for the first query\n      Query frontierQuery = q;\n      // Find all documents in this graph that are leaf nodes to speed traversal\n      // TODO: speed this up in the future with HAS_FIELD type queries\n      BooleanQuery.Builder leafNodeQuery = new BooleanQuery.Builder();\n      WildcardQuery edgeQuery = new WildcardQuery(new Term(toField, \"*\"));\n      leafNodeQuery.add(edgeQuery, Occur.MUST_NOT);\n      DocSet leafNodes = fromSearcher.getDocSet(leafNodeQuery.build());\n      // Start the breadth first graph traversal.\n      do {\n        // Create the graph result collector for this level\n        GraphTermsCollector graphResultCollector = new GraphTermsCollector(toField,capacity, resultBits, leafNodes);\n        // traverse the level!\n        fromSearcher.search(frontierQuery, graphResultCollector);\n        // All edge ids on the frontier.\n        BytesRefHash collectorTerms = graphResultCollector.getCollectorTerms();\n        frontierSize = collectorTerms.size();\n        // The resulting doc set from the frontier.\n        fromSet = graphResultCollector.getDocSet();\n        if (seedResultBits == null) {\n          // grab a copy of the seed bits  (these are the \"rootNodes\")\n          seedResultBits = ((BitDocSet)fromSet).getBits().clone();\n        }\n        Integer fs = new Integer(frontierSize);\n        FrontierQuery fq = buildFrontierQuery(collectorTerms, fs);\n        if (fq == null) {\n          // in case we get null back, make sure we know we're done at this level.\n          fq = new FrontierQuery(null, 0);\n        }\n        frontierQuery = fq.getQuery();\n        frontierSize = fq.getFrontierSize();\n        // Add the bits from this level to the result set.\n        resultBits.or(((BitDocSet)fromSet).getBits());\n        // Increment how far we have gone in the frontier.\n        currentDepth++;\n        // Break out if we have reached our max depth\n        if (currentDepth >= maxDepth && maxDepth != -1) {\n          break;\n        }\n        // test if we discovered any new edges, if not , we're done.\n      } while (frontierSize > 0);\n      // helper bit set operations on the final result set\n      if (!returnRoot) {\n        resultBits.andNot(seedResultBits);\n      }\n      BitDocSet resultSet = new BitDocSet(resultBits);\n      // If we only want to return leaf nodes do that here.\n      if (onlyLeafNodes) {\n        return resultSet.intersection(leafNodes);\n      } else {\n        // create a doc set off the bits that we found.\n        return resultSet;\n      }\n    }\n\n","bugFix":null,"bugIntro":["487de3f55283f58d7e02a16993f8be55bbe32061"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"8d15e34266d75e4e8b95da046cd0afc812367b38","date":1454246129,"type":3,"author":"Noble Paul","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/search/join/GraphQuery.GraphQueryWeight#getDocSet().mjava","pathOld":"solr/core/src/java/org/apache/solr/search/join/GraphQuery.GraphQueryWeight#getDocSet().mjava","sourceNew":"    /**\n     * This computes the matching doc set for a given graph query\n     * \n     * @return DocSet representing the documents in the graph.\n     * @throws IOException - if a sub search fails... maybe other cases too! :)\n     */\n    private DocSet getDocSet() throws IOException {\n      // Size that the bit set needs to be.\n      int capacity = fromSearcher.getRawReader().maxDoc();\n      // The bit set to contain the results that match the query.\n      FixedBitSet resultBits = new FixedBitSet(capacity);\n      // this holds the result at each level\n      BitDocSet fromSet = null;\n      // the root docs if we return root is false\n      FixedBitSet rootBits = null;\n      // the initial query for the frontier for the first query\n      Query frontierQuery = q;\n      // Find all documents in this graph that are leaf nodes to speed traversal\n      DocSet leafNodes = resolveLeafNodes(toField);\n      // Start the breadth first graph traversal.\n      \n      do {\n        // Increment how far we have gone in the frontier.\n        currentDepth++;\n        // if we are at the max level we don't need the graph terms collector.\n        // TODO validate that the join case works properly.\n        if (maxDepth != -1 && currentDepth >= maxDepth) {\n          // if we've reached the max depth, don't worry about collecting edges.\n          fromSet = fromSearcher.getDocSetBits(frontierQuery);\n          // explicitly the frontier size is zero now so we can break\n          frontierSize = 0;\n        } else {\n          // when we're not at the max depth level, we need to collect edges          \n          // Create the graph result collector for this level\n          GraphTermsCollector graphResultCollector = new GraphTermsCollector(toField,capacity, resultBits, leafNodes);\n          fromSearcher.search(frontierQuery, graphResultCollector);\n          fromSet = graphResultCollector.getDocSet();\n          // All edge ids on the frontier.\n          BytesRefHash collectorTerms = graphResultCollector.getCollectorTerms();\n          frontierSize = collectorTerms.size();\n          // The resulting doc set from the frontier.\n          FrontierQuery fq = buildFrontierQuery(collectorTerms, frontierSize);\n          if (fq == null) {\n            // in case we get null back, make sure we know we're done at this level.\n            frontierSize = 0;\n          } else {\n            frontierQuery = fq.getQuery();\n            frontierSize = fq.getFrontierSize();\n          }\n        }\n        if (currentDepth == 0 && !returnRoot) {\n          // grab a copy of the root bits but only if we need it.\n          rootBits = fromSet.getBits();\n        }\n        // Add the bits from this level to the result set.\n        resultBits.or(fromSet.getBits());\n        // test if we discovered any new edges, if not , we're done.\n        if ((maxDepth != -1 && currentDepth >= maxDepth)) {\n          break;\n        }\n      } while (frontierSize > 0);\n      // helper bit set operations on the final result set\n      if (!returnRoot) {\n        resultBits.andNot(rootBits);\n      }\n      // this is the final resulting filter.\n      BitDocSet resultSet = new BitDocSet(resultBits);\n      // If we only want to return leaf nodes do that here.\n      if (onlyLeafNodes) {\n        return resultSet.intersection(leafNodes);\n      } else {\n        return resultSet;\n      }\n    }\n\n","sourceOld":"    /**\n     * This computes the matching doc set for a given graph query\n     * \n     * @return DocSet representing the documents in the graph.\n     * @throws IOException - if a sub search fails... maybe other cases too! :)\n     */\n    private DocSet getDocSet() throws IOException {\n      DocSet fromSet = null;\n      FixedBitSet seedResultBits = null;\n      // Size that the bit set needs to be.\n      int capacity = fromSearcher.getRawReader().maxDoc();\n      // The bit set to contain the results that match the query.\n      FixedBitSet resultBits = new FixedBitSet(capacity);\n      // The measure of how deep in the graph we have gone.\n      currentDepth = 0;\n      // the initial query for the frontier for the first query\n      Query frontierQuery = q;\n      // Find all documents in this graph that are leaf nodes to speed traversal\n      // TODO: speed this up in the future with HAS_FIELD type queries\n      BooleanQuery.Builder leafNodeQuery = new BooleanQuery.Builder();\n      WildcardQuery edgeQuery = new WildcardQuery(new Term(toField, \"*\"));\n      leafNodeQuery.add(edgeQuery, Occur.MUST_NOT);\n      DocSet leafNodes = fromSearcher.getDocSet(leafNodeQuery.build());\n      // Start the breadth first graph traversal.\n      do {\n        // Create the graph result collector for this level\n        GraphTermsCollector graphResultCollector = new GraphTermsCollector(toField,capacity, resultBits, leafNodes);\n        // traverse the level!\n        fromSearcher.search(frontierQuery, graphResultCollector);\n        // All edge ids on the frontier.\n        BytesRefHash collectorTerms = graphResultCollector.getCollectorTerms();\n        frontierSize = collectorTerms.size();\n        // The resulting doc set from the frontier.\n        fromSet = graphResultCollector.getDocSet();\n        if (seedResultBits == null) {\n          // grab a copy of the seed bits  (these are the \"rootNodes\")\n          seedResultBits = ((BitDocSet)fromSet).getBits().clone();\n        }\n        Integer fs = new Integer(frontierSize);\n        FrontierQuery fq = buildFrontierQuery(collectorTerms, fs);\n        if (fq == null) {\n          // in case we get null back, make sure we know we're done at this level.\n          fq = new FrontierQuery(null, 0);\n        }\n        frontierQuery = fq.getQuery();\n        frontierSize = fq.getFrontierSize();\n        // Add the bits from this level to the result set.\n        resultBits.or(((BitDocSet)fromSet).getBits());\n        // Increment how far we have gone in the frontier.\n        currentDepth++;\n        // Break out if we have reached our max depth\n        if (currentDepth >= maxDepth && maxDepth != -1) {\n          break;\n        }\n        // test if we discovered any new edges, if not , we're done.\n      } while (frontierSize > 0);\n      // helper bit set operations on the final result set\n      if (!returnRoot) {\n        resultBits.andNot(seedResultBits);\n      }\n      BitDocSet resultSet = new BitDocSet(resultBits);\n      // If we only want to return leaf nodes do that here.\n      if (onlyLeafNodes) {\n        return resultSet.intersection(leafNodes);\n      } else {\n        // create a doc set off the bits that we found.\n        return resultSet;\n      }\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"1e6acbaae7af722f17204ceccf0f7db5753eccf3","date":1454775255,"type":3,"author":"Mike McCandless","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/search/join/GraphQuery.GraphQueryWeight#getDocSet().mjava","pathOld":"solr/core/src/java/org/apache/solr/search/join/GraphQuery.GraphQueryWeight#getDocSet().mjava","sourceNew":"    /**\n     * This computes the matching doc set for a given graph query\n     * \n     * @return DocSet representing the documents in the graph.\n     * @throws IOException - if a sub search fails... maybe other cases too! :)\n     */\n    private DocSet getDocSet() throws IOException {\n      // Size that the bit set needs to be.\n      int capacity = fromSearcher.getRawReader().maxDoc();\n      // The bit set to contain the results that match the query.\n      FixedBitSet resultBits = new FixedBitSet(capacity);\n      // this holds the result at each level\n      BitDocSet fromSet = null;\n      // the root docs if we return root is false\n      FixedBitSet rootBits = null;\n      // the initial query for the frontier for the first query\n      Query frontierQuery = q;\n      // Find all documents in this graph that are leaf nodes to speed traversal\n      DocSet leafNodes = resolveLeafNodes(toField);\n      // Start the breadth first graph traversal.\n      \n      do {\n        // Increment how far we have gone in the frontier.\n        currentDepth++;\n        // if we are at the max level we don't need the graph terms collector.\n        // TODO validate that the join case works properly.\n        if (maxDepth != -1 && currentDepth >= maxDepth) {\n          // if we've reached the max depth, don't worry about collecting edges.\n          fromSet = fromSearcher.getDocSetBits(frontierQuery);\n          // explicitly the frontier size is zero now so we can break\n          frontierSize = 0;\n        } else {\n          // when we're not at the max depth level, we need to collect edges          \n          // Create the graph result collector for this level\n          GraphTermsCollector graphResultCollector = new GraphTermsCollector(toField,capacity, resultBits, leafNodes);\n          fromSearcher.search(frontierQuery, graphResultCollector);\n          fromSet = graphResultCollector.getDocSet();\n          // All edge ids on the frontier.\n          BytesRefHash collectorTerms = graphResultCollector.getCollectorTerms();\n          frontierSize = collectorTerms.size();\n          // The resulting doc set from the frontier.\n          FrontierQuery fq = buildFrontierQuery(collectorTerms, frontierSize);\n          if (fq == null) {\n            // in case we get null back, make sure we know we're done at this level.\n            frontierSize = 0;\n          } else {\n            frontierQuery = fq.getQuery();\n            frontierSize = fq.getFrontierSize();\n          }\n        }\n        if (currentDepth == 0 && !returnRoot) {\n          // grab a copy of the root bits but only if we need it.\n          rootBits = fromSet.getBits();\n        }\n        // Add the bits from this level to the result set.\n        resultBits.or(fromSet.getBits());\n        // test if we discovered any new edges, if not , we're done.\n        if ((maxDepth != -1 && currentDepth >= maxDepth)) {\n          break;\n        }\n      } while (frontierSize > 0);\n      // helper bit set operations on the final result set\n      if (!returnRoot) {\n        resultBits.andNot(rootBits);\n      }\n      // this is the final resulting filter.\n      BitDocSet resultSet = new BitDocSet(resultBits);\n      // If we only want to return leaf nodes do that here.\n      if (onlyLeafNodes) {\n        return resultSet.intersection(leafNodes);\n      } else {\n        return resultSet;\n      }\n    }\n\n","sourceOld":"    /**\n     * This computes the matching doc set for a given graph query\n     * \n     * @return DocSet representing the documents in the graph.\n     * @throws IOException - if a sub search fails... maybe other cases too! :)\n     */\n    private DocSet getDocSet() throws IOException {\n      DocSet fromSet = null;\n      FixedBitSet seedResultBits = null;\n      // Size that the bit set needs to be.\n      int capacity = fromSearcher.getRawReader().maxDoc();\n      // The bit set to contain the results that match the query.\n      FixedBitSet resultBits = new FixedBitSet(capacity);\n      // The measure of how deep in the graph we have gone.\n      currentDepth = 0;\n      // the initial query for the frontier for the first query\n      Query frontierQuery = q;\n      // Find all documents in this graph that are leaf nodes to speed traversal\n      // TODO: speed this up in the future with HAS_FIELD type queries\n      BooleanQuery.Builder leafNodeQuery = new BooleanQuery.Builder();\n      WildcardQuery edgeQuery = new WildcardQuery(new Term(toField, \"*\"));\n      leafNodeQuery.add(edgeQuery, Occur.MUST_NOT);\n      DocSet leafNodes = fromSearcher.getDocSet(leafNodeQuery.build());\n      // Start the breadth first graph traversal.\n      do {\n        // Create the graph result collector for this level\n        GraphTermsCollector graphResultCollector = new GraphTermsCollector(toField,capacity, resultBits, leafNodes);\n        // traverse the level!\n        fromSearcher.search(frontierQuery, graphResultCollector);\n        // All edge ids on the frontier.\n        BytesRefHash collectorTerms = graphResultCollector.getCollectorTerms();\n        frontierSize = collectorTerms.size();\n        // The resulting doc set from the frontier.\n        fromSet = graphResultCollector.getDocSet();\n        if (seedResultBits == null) {\n          // grab a copy of the seed bits  (these are the \"rootNodes\")\n          seedResultBits = ((BitDocSet)fromSet).getBits().clone();\n        }\n        Integer fs = new Integer(frontierSize);\n        FrontierQuery fq = buildFrontierQuery(collectorTerms, fs);\n        if (fq == null) {\n          // in case we get null back, make sure we know we're done at this level.\n          fq = new FrontierQuery(null, 0);\n        }\n        frontierQuery = fq.getQuery();\n        frontierSize = fq.getFrontierSize();\n        // Add the bits from this level to the result set.\n        resultBits.or(((BitDocSet)fromSet).getBits());\n        // Increment how far we have gone in the frontier.\n        currentDepth++;\n        // Break out if we have reached our max depth\n        if (currentDepth >= maxDepth && maxDepth != -1) {\n          break;\n        }\n        // test if we discovered any new edges, if not , we're done.\n      } while (frontierSize > 0);\n      // helper bit set operations on the final result set\n      if (!returnRoot) {\n        resultBits.andNot(seedResultBits);\n      }\n      BitDocSet resultSet = new BitDocSet(resultBits);\n      // If we only want to return leaf nodes do that here.\n      if (onlyLeafNodes) {\n        return resultSet.intersection(leafNodes);\n      } else {\n        // create a doc set off the bits that we found.\n        return resultSet;\n      }\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a3be7723008a2c26b93c1b9d6a5e67ed2e4a2976","date":1500994164,"type":3,"author":"yonik","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/join/GraphQuery.GraphQueryWeight#getDocSet().mjava","pathOld":"solr/core/src/java/org/apache/solr/search/join/GraphQuery.GraphQueryWeight#getDocSet().mjava","sourceNew":"    /**\n     * This computes the matching doc set for a given graph query\n     * \n     * @return DocSet representing the documents in the graph.\n     * @throws IOException - if a sub search fails... maybe other cases too! :)\n     */\n    private DocSet getDocSet() throws IOException {\n      // Size that the bit set needs to be.\n      int capacity = fromSearcher.getRawReader().maxDoc();\n      // The bit set to contain the results that match the query.\n      FixedBitSet resultBits = new FixedBitSet(capacity);\n      // this holds the result at each level\n      BitDocSet fromSet = null;\n      // the root docs if we return root is false\n      FixedBitSet rootBits = null;\n      // the initial query for the frontier for the first query\n      Query frontierQuery = q;\n      // Find all documents in this graph that are leaf nodes to speed traversal\n      DocSet leafNodes = resolveLeafNodes();\n      // Start the breadth first graph traversal.\n      \n      do {\n        // Increment how far we have gone in the frontier.\n        currentDepth++;\n        // if we are at the max level we don't need the graph terms collector.\n        // TODO validate that the join case works properly.\n        if (maxDepth != -1 && currentDepth >= maxDepth) {\n          // if we've reached the max depth, don't worry about collecting edges.\n          fromSet = fromSearcher.getDocSetBits(frontierQuery);\n          // explicitly the frontier size is zero now so we can break\n          frontierQuery = null;\n        } else {\n          // when we're not at the max depth level, we need to collect edges          \n          // Create the graph result collector for this level\n          GraphEdgeCollector graphResultCollector = toSchemaField.getType().isPointField()\n              ? new GraphPointsCollector(this, capacity, resultBits, leafNodes)\n              : new GraphTermsCollector(this, capacity, resultBits, leafNodes);\n\n          fromSearcher.search(frontierQuery, graphResultCollector);\n          fromSet = graphResultCollector.getDocSet();\n          frontierQuery = graphResultCollector.getFrontierQuery();\n        }\n        if (currentDepth == 0 && !returnRoot) {\n          // grab a copy of the root bits but only if we need it.\n          rootBits = fromSet.getBits();\n        }\n        // Add the bits from this level to the result set.\n        resultBits.or(fromSet.getBits());\n        // test if we discovered any new edges, if not , we're done.\n        if ((maxDepth != -1 && currentDepth >= maxDepth)) {\n          break;\n        }\n      } while (frontierQuery != null);\n      // helper bit set operations on the final result set\n      if (!returnRoot) {\n        resultBits.andNot(rootBits);\n      }\n      // this is the final resulting filter.\n      BitDocSet resultSet = new BitDocSet(resultBits);\n      // If we only want to return leaf nodes do that here.\n      if (onlyLeafNodes) {\n        return resultSet.intersection(leafNodes);\n      } else {\n        return resultSet;\n      }\n    }\n\n","sourceOld":"    /**\n     * This computes the matching doc set for a given graph query\n     * \n     * @return DocSet representing the documents in the graph.\n     * @throws IOException - if a sub search fails... maybe other cases too! :)\n     */\n    private DocSet getDocSet() throws IOException {\n      // Size that the bit set needs to be.\n      int capacity = fromSearcher.getRawReader().maxDoc();\n      // The bit set to contain the results that match the query.\n      FixedBitSet resultBits = new FixedBitSet(capacity);\n      // this holds the result at each level\n      BitDocSet fromSet = null;\n      // the root docs if we return root is false\n      FixedBitSet rootBits = null;\n      // the initial query for the frontier for the first query\n      Query frontierQuery = q;\n      // Find all documents in this graph that are leaf nodes to speed traversal\n      DocSet leafNodes = resolveLeafNodes(toField);\n      // Start the breadth first graph traversal.\n      \n      do {\n        // Increment how far we have gone in the frontier.\n        currentDepth++;\n        // if we are at the max level we don't need the graph terms collector.\n        // TODO validate that the join case works properly.\n        if (maxDepth != -1 && currentDepth >= maxDepth) {\n          // if we've reached the max depth, don't worry about collecting edges.\n          fromSet = fromSearcher.getDocSetBits(frontierQuery);\n          // explicitly the frontier size is zero now so we can break\n          frontierSize = 0;\n        } else {\n          // when we're not at the max depth level, we need to collect edges          \n          // Create the graph result collector for this level\n          GraphTermsCollector graphResultCollector = new GraphTermsCollector(toField,capacity, resultBits, leafNodes);\n          fromSearcher.search(frontierQuery, graphResultCollector);\n          fromSet = graphResultCollector.getDocSet();\n          // All edge ids on the frontier.\n          BytesRefHash collectorTerms = graphResultCollector.getCollectorTerms();\n          frontierSize = collectorTerms.size();\n          // The resulting doc set from the frontier.\n          FrontierQuery fq = buildFrontierQuery(collectorTerms, frontierSize);\n          if (fq == null) {\n            // in case we get null back, make sure we know we're done at this level.\n            frontierSize = 0;\n          } else {\n            frontierQuery = fq.getQuery();\n            frontierSize = fq.getFrontierSize();\n          }\n        }\n        if (currentDepth == 0 && !returnRoot) {\n          // grab a copy of the root bits but only if we need it.\n          rootBits = fromSet.getBits();\n        }\n        // Add the bits from this level to the result set.\n        resultBits.or(fromSet.getBits());\n        // test if we discovered any new edges, if not , we're done.\n        if ((maxDepth != -1 && currentDepth >= maxDepth)) {\n          break;\n        }\n      } while (frontierSize > 0);\n      // helper bit set operations on the final result set\n      if (!returnRoot) {\n        resultBits.andNot(rootBits);\n      }\n      // this is the final resulting filter.\n      BitDocSet resultSet = new BitDocSet(resultBits);\n      // If we only want to return leaf nodes do that here.\n      if (onlyLeafNodes) {\n        return resultSet.intersection(leafNodes);\n      } else {\n        return resultSet;\n      }\n    }\n\n","bugFix":null,"bugIntro":["487de3f55283f58d7e02a16993f8be55bbe32061"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"a52341299179de5479672f7cf518bf4b173f34b3","date":1501079746,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/search/join/GraphQuery.GraphQueryWeight#getDocSet().mjava","pathOld":"solr/core/src/java/org/apache/solr/search/join/GraphQuery.GraphQueryWeight#getDocSet().mjava","sourceNew":"    /**\n     * This computes the matching doc set for a given graph query\n     * \n     * @return DocSet representing the documents in the graph.\n     * @throws IOException - if a sub search fails... maybe other cases too! :)\n     */\n    private DocSet getDocSet() throws IOException {\n      // Size that the bit set needs to be.\n      int capacity = fromSearcher.getRawReader().maxDoc();\n      // The bit set to contain the results that match the query.\n      FixedBitSet resultBits = new FixedBitSet(capacity);\n      // this holds the result at each level\n      BitDocSet fromSet = null;\n      // the root docs if we return root is false\n      FixedBitSet rootBits = null;\n      // the initial query for the frontier for the first query\n      Query frontierQuery = q;\n      // Find all documents in this graph that are leaf nodes to speed traversal\n      DocSet leafNodes = resolveLeafNodes();\n      // Start the breadth first graph traversal.\n      \n      do {\n        // Increment how far we have gone in the frontier.\n        currentDepth++;\n        // if we are at the max level we don't need the graph terms collector.\n        // TODO validate that the join case works properly.\n        if (maxDepth != -1 && currentDepth >= maxDepth) {\n          // if we've reached the max depth, don't worry about collecting edges.\n          fromSet = fromSearcher.getDocSetBits(frontierQuery);\n          // explicitly the frontier size is zero now so we can break\n          frontierQuery = null;\n        } else {\n          // when we're not at the max depth level, we need to collect edges          \n          // Create the graph result collector for this level\n          GraphEdgeCollector graphResultCollector = toSchemaField.getType().isPointField()\n              ? new GraphPointsCollector(this, capacity, resultBits, leafNodes)\n              : new GraphTermsCollector(this, capacity, resultBits, leafNodes);\n\n          fromSearcher.search(frontierQuery, graphResultCollector);\n          fromSet = graphResultCollector.getDocSet();\n          frontierQuery = graphResultCollector.getFrontierQuery();\n        }\n        if (currentDepth == 0 && !returnRoot) {\n          // grab a copy of the root bits but only if we need it.\n          rootBits = fromSet.getBits();\n        }\n        // Add the bits from this level to the result set.\n        resultBits.or(fromSet.getBits());\n        // test if we discovered any new edges, if not , we're done.\n        if ((maxDepth != -1 && currentDepth >= maxDepth)) {\n          break;\n        }\n      } while (frontierQuery != null);\n      // helper bit set operations on the final result set\n      if (!returnRoot) {\n        resultBits.andNot(rootBits);\n      }\n      // this is the final resulting filter.\n      BitDocSet resultSet = new BitDocSet(resultBits);\n      // If we only want to return leaf nodes do that here.\n      if (onlyLeafNodes) {\n        return resultSet.intersection(leafNodes);\n      } else {\n        return resultSet;\n      }\n    }\n\n","sourceOld":"    /**\n     * This computes the matching doc set for a given graph query\n     * \n     * @return DocSet representing the documents in the graph.\n     * @throws IOException - if a sub search fails... maybe other cases too! :)\n     */\n    private DocSet getDocSet() throws IOException {\n      // Size that the bit set needs to be.\n      int capacity = fromSearcher.getRawReader().maxDoc();\n      // The bit set to contain the results that match the query.\n      FixedBitSet resultBits = new FixedBitSet(capacity);\n      // this holds the result at each level\n      BitDocSet fromSet = null;\n      // the root docs if we return root is false\n      FixedBitSet rootBits = null;\n      // the initial query for the frontier for the first query\n      Query frontierQuery = q;\n      // Find all documents in this graph that are leaf nodes to speed traversal\n      DocSet leafNodes = resolveLeafNodes(toField);\n      // Start the breadth first graph traversal.\n      \n      do {\n        // Increment how far we have gone in the frontier.\n        currentDepth++;\n        // if we are at the max level we don't need the graph terms collector.\n        // TODO validate that the join case works properly.\n        if (maxDepth != -1 && currentDepth >= maxDepth) {\n          // if we've reached the max depth, don't worry about collecting edges.\n          fromSet = fromSearcher.getDocSetBits(frontierQuery);\n          // explicitly the frontier size is zero now so we can break\n          frontierSize = 0;\n        } else {\n          // when we're not at the max depth level, we need to collect edges          \n          // Create the graph result collector for this level\n          GraphTermsCollector graphResultCollector = new GraphTermsCollector(toField,capacity, resultBits, leafNodes);\n          fromSearcher.search(frontierQuery, graphResultCollector);\n          fromSet = graphResultCollector.getDocSet();\n          // All edge ids on the frontier.\n          BytesRefHash collectorTerms = graphResultCollector.getCollectorTerms();\n          frontierSize = collectorTerms.size();\n          // The resulting doc set from the frontier.\n          FrontierQuery fq = buildFrontierQuery(collectorTerms, frontierSize);\n          if (fq == null) {\n            // in case we get null back, make sure we know we're done at this level.\n            frontierSize = 0;\n          } else {\n            frontierQuery = fq.getQuery();\n            frontierSize = fq.getFrontierSize();\n          }\n        }\n        if (currentDepth == 0 && !returnRoot) {\n          // grab a copy of the root bits but only if we need it.\n          rootBits = fromSet.getBits();\n        }\n        // Add the bits from this level to the result set.\n        resultBits.or(fromSet.getBits());\n        // test if we discovered any new edges, if not , we're done.\n        if ((maxDepth != -1 && currentDepth >= maxDepth)) {\n          break;\n        }\n      } while (frontierSize > 0);\n      // helper bit set operations on the final result set\n      if (!returnRoot) {\n        resultBits.andNot(rootBits);\n      }\n      // this is the final resulting filter.\n      BitDocSet resultSet = new BitDocSet(resultBits);\n      // If we only want to return leaf nodes do that here.\n      if (onlyLeafNodes) {\n        return resultSet.intersection(leafNodes);\n      } else {\n        return resultSet;\n      }\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"487de3f55283f58d7e02a16993f8be55bbe32061","date":1502123368,"type":3,"author":"yonik","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/join/GraphQuery.GraphQueryWeight#getDocSet().mjava","pathOld":"solr/core/src/java/org/apache/solr/search/join/GraphQuery.GraphQueryWeight#getDocSet().mjava","sourceNew":"    /**\n     * This computes the matching doc set for a given graph query\n     * \n     * @return DocSet representing the documents in the graph.\n     * @throws IOException - if a sub search fails... maybe other cases too! :)\n     */\n    private DocSet getDocSet() throws IOException {\n      // Size that the bit set needs to be.\n      int capacity = fromSearcher.getRawReader().maxDoc();\n      // The bit set to contain the results that match the query.\n      FixedBitSet resultBits = new FixedBitSet(capacity);\n      // this holds the result at each level\n      BitDocSet fromSet = null;\n      // the root docs if we return root is false\n      FixedBitSet rootBits = null;\n      // the initial query for the frontier for the first query\n      Query frontierQuery = q;\n      // Find all documents in this graph that are leaf nodes to speed traversal\n      DocSet leafNodes = resolveLeafNodes();\n      // Start the breadth first graph traversal.\n      \n      do {\n        // Increment how far we have gone in the frontier.\n        currentDepth++;\n        // if we are at the max level we don't need the graph terms collector.\n        // TODO validate that the join case works properly.\n        if (maxDepth != -1 && currentDepth >= maxDepth) {\n          // if we've reached the max depth, don't worry about collecting edges.\n          fromSet = fromSearcher.getDocSetBits(frontierQuery);\n          // explicitly the frontier size is zero now so we can break\n          frontierQuery = null;\n        } else {\n          // when we're not at the max depth level, we need to collect edges          \n          // Create the graph result collector for this level\n          GraphEdgeCollector graphResultCollector = collectSchemaField.getType().isPointField()\n              ? new GraphPointsCollector(collectSchemaField, new BitDocSet(resultBits), leafNodes)\n              : new GraphTermsCollector(collectSchemaField, new BitDocSet(resultBits), leafNodes);\n\n          fromSet = new BitDocSet(new FixedBitSet(capacity));\n          graphResultCollector.setCollectDocs(fromSet.getBits());\n\n          fromSearcher.search(frontierQuery, graphResultCollector);\n\n          frontierQuery = graphResultCollector.getResultQuery(matchSchemaField, isUseAutn());\n          // If there is a filter to be used while crawling the graph, add that.\n          if (frontierQuery != null && getTraversalFilter() != null) {\n            BooleanQuery.Builder builder = new BooleanQuery.Builder();\n            builder.add(frontierQuery, BooleanClause.Occur.MUST);\n            builder.add(getTraversalFilter(), BooleanClause.Occur.MUST);\n            frontierQuery = builder.build();\n          }\n\n\n        }\n        if (currentDepth == 0 && !returnRoot) {\n          // grab a copy of the root bits but only if we need it.\n          rootBits = fromSet.getBits();\n        }\n        // Add the bits from this level to the result set.\n        resultBits.or(fromSet.getBits());\n        // test if we discovered any new edges, if not , we're done.\n        if ((maxDepth != -1 && currentDepth >= maxDepth)) {\n          break;\n        }\n      } while (frontierQuery != null);\n      // helper bit set operations on the final result set\n      if (!returnRoot) {\n        resultBits.andNot(rootBits);\n      }\n      // this is the final resulting filter.\n      BitDocSet resultSet = new BitDocSet(resultBits);\n      // If we only want to return leaf nodes do that here.\n      if (onlyLeafNodes) {\n        return resultSet.intersection(leafNodes);\n      } else {\n        return resultSet;\n      }\n    }\n\n","sourceOld":"    /**\n     * This computes the matching doc set for a given graph query\n     * \n     * @return DocSet representing the documents in the graph.\n     * @throws IOException - if a sub search fails... maybe other cases too! :)\n     */\n    private DocSet getDocSet() throws IOException {\n      // Size that the bit set needs to be.\n      int capacity = fromSearcher.getRawReader().maxDoc();\n      // The bit set to contain the results that match the query.\n      FixedBitSet resultBits = new FixedBitSet(capacity);\n      // this holds the result at each level\n      BitDocSet fromSet = null;\n      // the root docs if we return root is false\n      FixedBitSet rootBits = null;\n      // the initial query for the frontier for the first query\n      Query frontierQuery = q;\n      // Find all documents in this graph that are leaf nodes to speed traversal\n      DocSet leafNodes = resolveLeafNodes();\n      // Start the breadth first graph traversal.\n      \n      do {\n        // Increment how far we have gone in the frontier.\n        currentDepth++;\n        // if we are at the max level we don't need the graph terms collector.\n        // TODO validate that the join case works properly.\n        if (maxDepth != -1 && currentDepth >= maxDepth) {\n          // if we've reached the max depth, don't worry about collecting edges.\n          fromSet = fromSearcher.getDocSetBits(frontierQuery);\n          // explicitly the frontier size is zero now so we can break\n          frontierQuery = null;\n        } else {\n          // when we're not at the max depth level, we need to collect edges          \n          // Create the graph result collector for this level\n          GraphEdgeCollector graphResultCollector = toSchemaField.getType().isPointField()\n              ? new GraphPointsCollector(this, capacity, resultBits, leafNodes)\n              : new GraphTermsCollector(this, capacity, resultBits, leafNodes);\n\n          fromSearcher.search(frontierQuery, graphResultCollector);\n          fromSet = graphResultCollector.getDocSet();\n          frontierQuery = graphResultCollector.getFrontierQuery();\n        }\n        if (currentDepth == 0 && !returnRoot) {\n          // grab a copy of the root bits but only if we need it.\n          rootBits = fromSet.getBits();\n        }\n        // Add the bits from this level to the result set.\n        resultBits.or(fromSet.getBits());\n        // test if we discovered any new edges, if not , we're done.\n        if ((maxDepth != -1 && currentDepth >= maxDepth)) {\n          break;\n        }\n      } while (frontierQuery != null);\n      // helper bit set operations on the final result set\n      if (!returnRoot) {\n        resultBits.andNot(rootBits);\n      }\n      // this is the final resulting filter.\n      BitDocSet resultSet = new BitDocSet(resultBits);\n      // If we only want to return leaf nodes do that here.\n      if (onlyLeafNodes) {\n        return resultSet.intersection(leafNodes);\n      } else {\n        return resultSet;\n      }\n    }\n\n","bugFix":["826e791d635df5093032ca5d1925016bdf0c1df6","a3be7723008a2c26b93c1b9d6a5e67ed2e4a2976"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7a23cf16c8fa265dc0a564adcabb55e3f054e0ac","date":1502192746,"type":3,"author":"Shalin Shekhar Mangar","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/search/join/GraphQuery.GraphQueryWeight#getDocSet().mjava","pathOld":"solr/core/src/java/org/apache/solr/search/join/GraphQuery.GraphQueryWeight#getDocSet().mjava","sourceNew":"    /**\n     * This computes the matching doc set for a given graph query\n     * \n     * @return DocSet representing the documents in the graph.\n     * @throws IOException - if a sub search fails... maybe other cases too! :)\n     */\n    private DocSet getDocSet() throws IOException {\n      // Size that the bit set needs to be.\n      int capacity = fromSearcher.getRawReader().maxDoc();\n      // The bit set to contain the results that match the query.\n      FixedBitSet resultBits = new FixedBitSet(capacity);\n      // this holds the result at each level\n      BitDocSet fromSet = null;\n      // the root docs if we return root is false\n      FixedBitSet rootBits = null;\n      // the initial query for the frontier for the first query\n      Query frontierQuery = q;\n      // Find all documents in this graph that are leaf nodes to speed traversal\n      DocSet leafNodes = resolveLeafNodes();\n      // Start the breadth first graph traversal.\n      \n      do {\n        // Increment how far we have gone in the frontier.\n        currentDepth++;\n        // if we are at the max level we don't need the graph terms collector.\n        // TODO validate that the join case works properly.\n        if (maxDepth != -1 && currentDepth >= maxDepth) {\n          // if we've reached the max depth, don't worry about collecting edges.\n          fromSet = fromSearcher.getDocSetBits(frontierQuery);\n          // explicitly the frontier size is zero now so we can break\n          frontierQuery = null;\n        } else {\n          // when we're not at the max depth level, we need to collect edges          \n          // Create the graph result collector for this level\n          GraphEdgeCollector graphResultCollector = collectSchemaField.getType().isPointField()\n              ? new GraphPointsCollector(collectSchemaField, new BitDocSet(resultBits), leafNodes)\n              : new GraphTermsCollector(collectSchemaField, new BitDocSet(resultBits), leafNodes);\n\n          fromSet = new BitDocSet(new FixedBitSet(capacity));\n          graphResultCollector.setCollectDocs(fromSet.getBits());\n\n          fromSearcher.search(frontierQuery, graphResultCollector);\n\n          frontierQuery = graphResultCollector.getResultQuery(matchSchemaField, isUseAutn());\n          // If there is a filter to be used while crawling the graph, add that.\n          if (frontierQuery != null && getTraversalFilter() != null) {\n            BooleanQuery.Builder builder = new BooleanQuery.Builder();\n            builder.add(frontierQuery, BooleanClause.Occur.MUST);\n            builder.add(getTraversalFilter(), BooleanClause.Occur.MUST);\n            frontierQuery = builder.build();\n          }\n\n\n        }\n        if (currentDepth == 0 && !returnRoot) {\n          // grab a copy of the root bits but only if we need it.\n          rootBits = fromSet.getBits();\n        }\n        // Add the bits from this level to the result set.\n        resultBits.or(fromSet.getBits());\n        // test if we discovered any new edges, if not , we're done.\n        if ((maxDepth != -1 && currentDepth >= maxDepth)) {\n          break;\n        }\n      } while (frontierQuery != null);\n      // helper bit set operations on the final result set\n      if (!returnRoot) {\n        resultBits.andNot(rootBits);\n      }\n      // this is the final resulting filter.\n      BitDocSet resultSet = new BitDocSet(resultBits);\n      // If we only want to return leaf nodes do that here.\n      if (onlyLeafNodes) {\n        return resultSet.intersection(leafNodes);\n      } else {\n        return resultSet;\n      }\n    }\n\n","sourceOld":"    /**\n     * This computes the matching doc set for a given graph query\n     * \n     * @return DocSet representing the documents in the graph.\n     * @throws IOException - if a sub search fails... maybe other cases too! :)\n     */\n    private DocSet getDocSet() throws IOException {\n      // Size that the bit set needs to be.\n      int capacity = fromSearcher.getRawReader().maxDoc();\n      // The bit set to contain the results that match the query.\n      FixedBitSet resultBits = new FixedBitSet(capacity);\n      // this holds the result at each level\n      BitDocSet fromSet = null;\n      // the root docs if we return root is false\n      FixedBitSet rootBits = null;\n      // the initial query for the frontier for the first query\n      Query frontierQuery = q;\n      // Find all documents in this graph that are leaf nodes to speed traversal\n      DocSet leafNodes = resolveLeafNodes(toField);\n      // Start the breadth first graph traversal.\n      \n      do {\n        // Increment how far we have gone in the frontier.\n        currentDepth++;\n        // if we are at the max level we don't need the graph terms collector.\n        // TODO validate that the join case works properly.\n        if (maxDepth != -1 && currentDepth >= maxDepth) {\n          // if we've reached the max depth, don't worry about collecting edges.\n          fromSet = fromSearcher.getDocSetBits(frontierQuery);\n          // explicitly the frontier size is zero now so we can break\n          frontierSize = 0;\n        } else {\n          // when we're not at the max depth level, we need to collect edges          \n          // Create the graph result collector for this level\n          GraphTermsCollector graphResultCollector = new GraphTermsCollector(toField,capacity, resultBits, leafNodes);\n          fromSearcher.search(frontierQuery, graphResultCollector);\n          fromSet = graphResultCollector.getDocSet();\n          // All edge ids on the frontier.\n          BytesRefHash collectorTerms = graphResultCollector.getCollectorTerms();\n          frontierSize = collectorTerms.size();\n          // The resulting doc set from the frontier.\n          FrontierQuery fq = buildFrontierQuery(collectorTerms, frontierSize);\n          if (fq == null) {\n            // in case we get null back, make sure we know we're done at this level.\n            frontierSize = 0;\n          } else {\n            frontierQuery = fq.getQuery();\n            frontierSize = fq.getFrontierSize();\n          }\n        }\n        if (currentDepth == 0 && !returnRoot) {\n          // grab a copy of the root bits but only if we need it.\n          rootBits = fromSet.getBits();\n        }\n        // Add the bits from this level to the result set.\n        resultBits.or(fromSet.getBits());\n        // test if we discovered any new edges, if not , we're done.\n        if ((maxDepth != -1 && currentDepth >= maxDepth)) {\n          break;\n        }\n      } while (frontierSize > 0);\n      // helper bit set operations on the final result set\n      if (!returnRoot) {\n        resultBits.andNot(rootBits);\n      }\n      // this is the final resulting filter.\n      BitDocSet resultSet = new BitDocSet(resultBits);\n      // If we only want to return leaf nodes do that here.\n      if (onlyLeafNodes) {\n        return resultSet.intersection(leafNodes);\n      } else {\n        return resultSet;\n      }\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"58884af1f68e9d61c217c753fbd6266d86a63b14","date":1502363401,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/search/join/GraphQuery.GraphQueryWeight#getDocSet().mjava","pathOld":"solr/core/src/java/org/apache/solr/search/join/GraphQuery.GraphQueryWeight#getDocSet().mjava","sourceNew":"    /**\n     * This computes the matching doc set for a given graph query\n     * \n     * @return DocSet representing the documents in the graph.\n     * @throws IOException - if a sub search fails... maybe other cases too! :)\n     */\n    private DocSet getDocSet() throws IOException {\n      // Size that the bit set needs to be.\n      int capacity = fromSearcher.getRawReader().maxDoc();\n      // The bit set to contain the results that match the query.\n      FixedBitSet resultBits = new FixedBitSet(capacity);\n      // this holds the result at each level\n      BitDocSet fromSet = null;\n      // the root docs if we return root is false\n      FixedBitSet rootBits = null;\n      // the initial query for the frontier for the first query\n      Query frontierQuery = q;\n      // Find all documents in this graph that are leaf nodes to speed traversal\n      DocSet leafNodes = resolveLeafNodes();\n      // Start the breadth first graph traversal.\n      \n      do {\n        // Increment how far we have gone in the frontier.\n        currentDepth++;\n        // if we are at the max level we don't need the graph terms collector.\n        // TODO validate that the join case works properly.\n        if (maxDepth != -1 && currentDepth >= maxDepth) {\n          // if we've reached the max depth, don't worry about collecting edges.\n          fromSet = fromSearcher.getDocSetBits(frontierQuery);\n          // explicitly the frontier size is zero now so we can break\n          frontierQuery = null;\n        } else {\n          // when we're not at the max depth level, we need to collect edges          \n          // Create the graph result collector for this level\n          GraphEdgeCollector graphResultCollector = collectSchemaField.getType().isPointField()\n              ? new GraphPointsCollector(collectSchemaField, new BitDocSet(resultBits), leafNodes)\n              : new GraphTermsCollector(collectSchemaField, new BitDocSet(resultBits), leafNodes);\n\n          fromSet = new BitDocSet(new FixedBitSet(capacity));\n          graphResultCollector.setCollectDocs(fromSet.getBits());\n\n          fromSearcher.search(frontierQuery, graphResultCollector);\n\n          frontierQuery = graphResultCollector.getResultQuery(matchSchemaField, isUseAutn());\n          // If there is a filter to be used while crawling the graph, add that.\n          if (frontierQuery != null && getTraversalFilter() != null) {\n            BooleanQuery.Builder builder = new BooleanQuery.Builder();\n            builder.add(frontierQuery, BooleanClause.Occur.MUST);\n            builder.add(getTraversalFilter(), BooleanClause.Occur.MUST);\n            frontierQuery = builder.build();\n          }\n\n\n        }\n        if (currentDepth == 0 && !returnRoot) {\n          // grab a copy of the root bits but only if we need it.\n          rootBits = fromSet.getBits();\n        }\n        // Add the bits from this level to the result set.\n        resultBits.or(fromSet.getBits());\n        // test if we discovered any new edges, if not , we're done.\n        if ((maxDepth != -1 && currentDepth >= maxDepth)) {\n          break;\n        }\n      } while (frontierQuery != null);\n      // helper bit set operations on the final result set\n      if (!returnRoot) {\n        resultBits.andNot(rootBits);\n      }\n      // this is the final resulting filter.\n      BitDocSet resultSet = new BitDocSet(resultBits);\n      // If we only want to return leaf nodes do that here.\n      if (onlyLeafNodes) {\n        return resultSet.intersection(leafNodes);\n      } else {\n        return resultSet;\n      }\n    }\n\n","sourceOld":"    /**\n     * This computes the matching doc set for a given graph query\n     * \n     * @return DocSet representing the documents in the graph.\n     * @throws IOException - if a sub search fails... maybe other cases too! :)\n     */\n    private DocSet getDocSet() throws IOException {\n      // Size that the bit set needs to be.\n      int capacity = fromSearcher.getRawReader().maxDoc();\n      // The bit set to contain the results that match the query.\n      FixedBitSet resultBits = new FixedBitSet(capacity);\n      // this holds the result at each level\n      BitDocSet fromSet = null;\n      // the root docs if we return root is false\n      FixedBitSet rootBits = null;\n      // the initial query for the frontier for the first query\n      Query frontierQuery = q;\n      // Find all documents in this graph that are leaf nodes to speed traversal\n      DocSet leafNodes = resolveLeafNodes();\n      // Start the breadth first graph traversal.\n      \n      do {\n        // Increment how far we have gone in the frontier.\n        currentDepth++;\n        // if we are at the max level we don't need the graph terms collector.\n        // TODO validate that the join case works properly.\n        if (maxDepth != -1 && currentDepth >= maxDepth) {\n          // if we've reached the max depth, don't worry about collecting edges.\n          fromSet = fromSearcher.getDocSetBits(frontierQuery);\n          // explicitly the frontier size is zero now so we can break\n          frontierQuery = null;\n        } else {\n          // when we're not at the max depth level, we need to collect edges          \n          // Create the graph result collector for this level\n          GraphEdgeCollector graphResultCollector = toSchemaField.getType().isPointField()\n              ? new GraphPointsCollector(this, capacity, resultBits, leafNodes)\n              : new GraphTermsCollector(this, capacity, resultBits, leafNodes);\n\n          fromSearcher.search(frontierQuery, graphResultCollector);\n          fromSet = graphResultCollector.getDocSet();\n          frontierQuery = graphResultCollector.getFrontierQuery();\n        }\n        if (currentDepth == 0 && !returnRoot) {\n          // grab a copy of the root bits but only if we need it.\n          rootBits = fromSet.getBits();\n        }\n        // Add the bits from this level to the result set.\n        resultBits.or(fromSet.getBits());\n        // test if we discovered any new edges, if not , we're done.\n        if ((maxDepth != -1 && currentDepth >= maxDepth)) {\n          break;\n        }\n      } while (frontierQuery != null);\n      // helper bit set operations on the final result set\n      if (!returnRoot) {\n        resultBits.andNot(rootBits);\n      }\n      // this is the final resulting filter.\n      BitDocSet resultSet = new BitDocSet(resultBits);\n      // If we only want to return leaf nodes do that here.\n      if (onlyLeafNodes) {\n        return resultSet.intersection(leafNodes);\n      } else {\n        return resultSet;\n      }\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ba33781da68babcaa5828121b443d3eb5c9d8480","date":1590595589,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/join/GraphQuery.GraphQueryWeight#getDocSet().mjava","pathOld":"solr/core/src/java/org/apache/solr/search/join/GraphQuery.GraphQueryWeight#getDocSet().mjava","sourceNew":"    /**\n     * This computes the matching doc set for a given graph query\n     * \n     * @return DocSet representing the documents in the graph.\n     * @throws IOException - if a sub search fails... maybe other cases too! :)\n     */\n    private DocSet getDocSet() throws IOException {\n      // Size that the bit set needs to be.\n      int capacity = fromSearcher.getRawReader().maxDoc();\n      // The bit set to contain the results that match the query.\n      FixedBitSet resultBits = new FixedBitSet(capacity);\n      // this holds the result at each level\n      BitDocSet fromSet = null;\n      // the root docs if we return root is false\n      FixedBitSet rootBits = null;\n      // the initial query for the frontier for the first query\n      Query frontierQuery = q;\n      // Find all documents in this graph that are leaf nodes to speed traversal\n      DocSet leafNodes = resolveLeafNodes();\n      // Start the breadth first graph traversal.\n      \n      do {\n        // Increment how far we have gone in the frontier.\n        currentDepth++;\n        // if we are at the max level we don't need the graph terms collector.\n        // TODO validate that the join case works properly.\n        if (maxDepth != -1 && currentDepth >= maxDepth) {\n          // if we've reached the max depth, don't worry about collecting edges.\n          fromSet = fromSearcher.getDocSetBits(frontierQuery);\n          // explicitly the frontier size is zero now so we can break\n          frontierQuery = null;\n        } else {\n          // when we're not at the max depth level, we need to collect edges          \n          // Create the graph result collector for this level\n          GraphEdgeCollector graphResultCollector = collectSchemaField.getType().isPointField()\n              ? new GraphPointsCollector(collectSchemaField, new BitDocSet(resultBits), leafNodes)\n              : new GraphEdgeCollector.GraphTermsCollector(collectSchemaField, new BitDocSet(resultBits), leafNodes);\n\n          fromSet = new BitDocSet(new FixedBitSet(capacity));\n          graphResultCollector.setCollectDocs(fromSet.getBits());\n\n          fromSearcher.search(frontierQuery, graphResultCollector);\n\n          frontierQuery = graphResultCollector.getResultQuery(matchSchemaField, isUseAutn());\n          // If there is a filter to be used while crawling the graph, add that.\n          if (frontierQuery != null && getTraversalFilter() != null) {\n            BooleanQuery.Builder builder = new BooleanQuery.Builder();\n            builder.add(frontierQuery, BooleanClause.Occur.MUST);\n            builder.add(getTraversalFilter(), BooleanClause.Occur.MUST);\n            frontierQuery = builder.build();\n          }\n\n\n        }\n        if (currentDepth == 0 && !returnRoot) {\n          // grab a copy of the root bits but only if we need it.\n          rootBits = fromSet.getBits();\n        }\n        // Add the bits from this level to the result set.\n        resultBits.or(fromSet.getBits());\n        // test if we discovered any new edges, if not , we're done.\n        if ((maxDepth != -1 && currentDepth >= maxDepth)) {\n          break;\n        }\n      } while (frontierQuery != null);\n      // helper bit set operations on the final result set\n      if (!returnRoot) {\n        resultBits.andNot(rootBits);\n      }\n      // this is the final resulting filter.\n      BitDocSet resultSet = new BitDocSet(resultBits);\n      // If we only want to return leaf nodes do that here.\n      if (onlyLeafNodes) {\n        return resultSet.intersection(leafNodes);\n      } else {\n        return resultSet;\n      }\n    }\n\n","sourceOld":"    /**\n     * This computes the matching doc set for a given graph query\n     * \n     * @return DocSet representing the documents in the graph.\n     * @throws IOException - if a sub search fails... maybe other cases too! :)\n     */\n    private DocSet getDocSet() throws IOException {\n      // Size that the bit set needs to be.\n      int capacity = fromSearcher.getRawReader().maxDoc();\n      // The bit set to contain the results that match the query.\n      FixedBitSet resultBits = new FixedBitSet(capacity);\n      // this holds the result at each level\n      BitDocSet fromSet = null;\n      // the root docs if we return root is false\n      FixedBitSet rootBits = null;\n      // the initial query for the frontier for the first query\n      Query frontierQuery = q;\n      // Find all documents in this graph that are leaf nodes to speed traversal\n      DocSet leafNodes = resolveLeafNodes();\n      // Start the breadth first graph traversal.\n      \n      do {\n        // Increment how far we have gone in the frontier.\n        currentDepth++;\n        // if we are at the max level we don't need the graph terms collector.\n        // TODO validate that the join case works properly.\n        if (maxDepth != -1 && currentDepth >= maxDepth) {\n          // if we've reached the max depth, don't worry about collecting edges.\n          fromSet = fromSearcher.getDocSetBits(frontierQuery);\n          // explicitly the frontier size is zero now so we can break\n          frontierQuery = null;\n        } else {\n          // when we're not at the max depth level, we need to collect edges          \n          // Create the graph result collector for this level\n          GraphEdgeCollector graphResultCollector = collectSchemaField.getType().isPointField()\n              ? new GraphPointsCollector(collectSchemaField, new BitDocSet(resultBits), leafNodes)\n              : new GraphTermsCollector(collectSchemaField, new BitDocSet(resultBits), leafNodes);\n\n          fromSet = new BitDocSet(new FixedBitSet(capacity));\n          graphResultCollector.setCollectDocs(fromSet.getBits());\n\n          fromSearcher.search(frontierQuery, graphResultCollector);\n\n          frontierQuery = graphResultCollector.getResultQuery(matchSchemaField, isUseAutn());\n          // If there is a filter to be used while crawling the graph, add that.\n          if (frontierQuery != null && getTraversalFilter() != null) {\n            BooleanQuery.Builder builder = new BooleanQuery.Builder();\n            builder.add(frontierQuery, BooleanClause.Occur.MUST);\n            builder.add(getTraversalFilter(), BooleanClause.Occur.MUST);\n            frontierQuery = builder.build();\n          }\n\n\n        }\n        if (currentDepth == 0 && !returnRoot) {\n          // grab a copy of the root bits but only if we need it.\n          rootBits = fromSet.getBits();\n        }\n        // Add the bits from this level to the result set.\n        resultBits.or(fromSet.getBits());\n        // test if we discovered any new edges, if not , we're done.\n        if ((maxDepth != -1 && currentDepth >= maxDepth)) {\n          break;\n        }\n      } while (frontierQuery != null);\n      // helper bit set operations on the final result set\n      if (!returnRoot) {\n        resultBits.andNot(rootBits);\n      }\n      // this is the final resulting filter.\n      BitDocSet resultSet = new BitDocSet(resultBits);\n      // If we only want to return leaf nodes do that here.\n      if (onlyLeafNodes) {\n        return resultSet.intersection(leafNodes);\n      } else {\n        return resultSet;\n      }\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"a3be7723008a2c26b93c1b9d6a5e67ed2e4a2976":["8d15e34266d75e4e8b95da046cd0afc812367b38"],"a52341299179de5479672f7cf518bf4b173f34b3":["8d15e34266d75e4e8b95da046cd0afc812367b38","a3be7723008a2c26b93c1b9d6a5e67ed2e4a2976"],"58884af1f68e9d61c217c753fbd6266d86a63b14":["a52341299179de5479672f7cf518bf4b173f34b3","487de3f55283f58d7e02a16993f8be55bbe32061"],"7a23cf16c8fa265dc0a564adcabb55e3f054e0ac":["8d15e34266d75e4e8b95da046cd0afc812367b38","487de3f55283f58d7e02a16993f8be55bbe32061"],"49f41ca5b59802ba2b8fb507bb73d5c4bf53db2b":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"826e791d635df5093032ca5d1925016bdf0c1df6":["49f41ca5b59802ba2b8fb507bb73d5c4bf53db2b"],"1e6acbaae7af722f17204ceccf0f7db5753eccf3":["49f41ca5b59802ba2b8fb507bb73d5c4bf53db2b","8d15e34266d75e4e8b95da046cd0afc812367b38"],"487de3f55283f58d7e02a16993f8be55bbe32061":["a52341299179de5479672f7cf518bf4b173f34b3"],"ba33781da68babcaa5828121b443d3eb5c9d8480":["487de3f55283f58d7e02a16993f8be55bbe32061"],"8d15e34266d75e4e8b95da046cd0afc812367b38":["49f41ca5b59802ba2b8fb507bb73d5c4bf53db2b","826e791d635df5093032ca5d1925016bdf0c1df6"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["ba33781da68babcaa5828121b443d3eb5c9d8480"]},"commit2Childs":{"a3be7723008a2c26b93c1b9d6a5e67ed2e4a2976":["a52341299179de5479672f7cf518bf4b173f34b3"],"a52341299179de5479672f7cf518bf4b173f34b3":["58884af1f68e9d61c217c753fbd6266d86a63b14","487de3f55283f58d7e02a16993f8be55bbe32061"],"58884af1f68e9d61c217c753fbd6266d86a63b14":[],"7a23cf16c8fa265dc0a564adcabb55e3f054e0ac":[],"49f41ca5b59802ba2b8fb507bb73d5c4bf53db2b":["826e791d635df5093032ca5d1925016bdf0c1df6","1e6acbaae7af722f17204ceccf0f7db5753eccf3","8d15e34266d75e4e8b95da046cd0afc812367b38"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["49f41ca5b59802ba2b8fb507bb73d5c4bf53db2b"],"826e791d635df5093032ca5d1925016bdf0c1df6":["8d15e34266d75e4e8b95da046cd0afc812367b38"],"1e6acbaae7af722f17204ceccf0f7db5753eccf3":[],"487de3f55283f58d7e02a16993f8be55bbe32061":["58884af1f68e9d61c217c753fbd6266d86a63b14","7a23cf16c8fa265dc0a564adcabb55e3f054e0ac","ba33781da68babcaa5828121b443d3eb5c9d8480"],"ba33781da68babcaa5828121b443d3eb5c9d8480":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"8d15e34266d75e4e8b95da046cd0afc812367b38":["a3be7723008a2c26b93c1b9d6a5e67ed2e4a2976","a52341299179de5479672f7cf518bf4b173f34b3","7a23cf16c8fa265dc0a564adcabb55e3f054e0ac","1e6acbaae7af722f17204ceccf0f7db5753eccf3"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["58884af1f68e9d61c217c753fbd6266d86a63b14","7a23cf16c8fa265dc0a564adcabb55e3f054e0ac","1e6acbaae7af722f17204ceccf0f7db5753eccf3","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}