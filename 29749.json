{"path":"solr/core/src/test/org/apache/solr/cloud/LIROnShardRestartTest#testAllReplicasInLIR().mjava","commits":[{"id":"9339df295b9162e4c81adbb4da44b5939d27c1ef","date":1520594349,"type":0,"author":"Cao Manh Dat","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/LIROnShardRestartTest#testAllReplicasInLIR().mjava","pathOld":"/dev/null","sourceNew":"  public void testAllReplicasInLIR() throws Exception {\n    String collection = \"allReplicasInLIR\";\n    CollectionAdminRequest.createCollection(collection, 1, 3)\n        .process(cluster.getSolrClient());\n    cluster.getSolrClient().add(collection, new SolrInputDocument(\"id\", \"1\"));\n    cluster.getSolrClient().add(collection, new SolrInputDocument(\"id\", \"2\"));\n    cluster.getSolrClient().commit(collection);\n\n    DocCollection docCollection = getCollectionState(collection);\n    Slice shard1 = docCollection.getSlice(\"shard1\");\n    Replica newLeader = shard1.getReplicas(rep -> !rep.getName().equals(shard1.getLeader().getName())).get(random().nextInt(2));\n    JettySolrRunner jettyOfNewLeader = cluster.getJettySolrRunners().stream()\n        .filter(jetty -> jetty.getNodeName().equals(newLeader.getNodeName()))\n        .findAny().get();\n    assertNotNull(jettyOfNewLeader);\n\n    // randomly add too many docs to peer sync to one replica so that only one random replica is the valid leader\n    // the versions don't matter, they just have to be higher than what the last 2 docs got\n    try (HttpSolrClient client = getHttpSolrClient(jettyOfNewLeader.getBaseUrl().toString())) {\n      ModifiableSolrParams params = new ModifiableSolrParams();\n      params.set(DistributingUpdateProcessorFactory.DISTRIB_UPDATE_PARAM, DistributedUpdateProcessor.DistribPhase.FROMLEADER.toString());\n\n      for (int i = 0; i < 101; i++) {\n        UpdateRequest ureq = new UpdateRequest();\n        ureq.setParams(new ModifiableSolrParams(params));\n        ureq.add(sdoc(\"id\", 3 + i, \"_version_\", Long.MAX_VALUE - 1 - i));\n        ureq.process(client, collection);\n      }\n      client.commit(collection);\n    }\n\n    ChaosMonkey.stop(cluster.getJettySolrRunners());\n    assertTrue(\"Timeout waiting for all not live\",\n        ClusterStateUtil.waitForAllReplicasNotLive(cluster.getSolrClient().getZkStateReader(), 45000));\n\n    try (ZkShardTerms zkShardTerms = new ZkShardTerms(collection, \"shard1\", cluster.getZkClient())) {\n      for (Replica replica : docCollection.getReplicas()) {\n        zkShardTerms.removeTerm(replica.getName());\n      }\n    }\n\n    Map<String,Object> stateObj = Utils.makeMap();\n    stateObj.put(ZkStateReader.STATE_PROP, \"down\");\n    stateObj.put(\"createdByNodeName\", \"test\");\n    stateObj.put(\"createdByCoreNodeName\", \"test\");\n    byte[] znodeData = Utils.toJSON(stateObj);\n\n    for (Replica replica : docCollection.getReplicas()) {\n      try {\n        cluster.getZkClient().makePath(\"/collections/\" + collection + \"/leader_initiated_recovery/shard1/\" + replica.getName(),\n            znodeData, true);\n      } catch (KeeperException.NodeExistsException e) {\n\n      }\n    }\n\n    ChaosMonkey.start(cluster.getJettySolrRunners());\n    waitForState(\"Timeout waiting for active replicas\", collection, clusterShape(1, 3));\n\n    assertEquals(103, cluster.getSolrClient().query(collection, new SolrQuery(\"*:*\")).getResults().getNumFound());\n\n\n    // now expire each node\n    for (Replica replica : docCollection.getReplicas()) {\n      try {\n        cluster.getZkClient().makePath(\"/collections/\" + collection + \"/leader_initiated_recovery/shard1/\" + replica.getName(),\n            znodeData, true);\n      } catch (KeeperException.NodeExistsException e) {\n\n      }\n    }\n\n    // only 2 replicas join the election and all of them are in LIR state, no one should win the election\n    List<String> oldElectionNodes = getElectionNodes(collection, \"shard1\", cluster.getZkClient());\n\n    for (JettySolrRunner jetty : cluster.getJettySolrRunners()) {\n      expire(jetty);\n    }\n\n    TimeOut timeOut = new TimeOut(60, TimeUnit.SECONDS, TimeSource.CURRENT_TIME);\n    while (!timeOut.hasTimedOut()) {\n      List<String> electionNodes = getElectionNodes(collection, \"shard1\", cluster.getZkClient());\n      electionNodes.retainAll(oldElectionNodes);\n      if (electionNodes.isEmpty()) break;\n    }\n    assertFalse(\"Timeout waiting for replicas rejoin election\", timeOut.hasTimedOut());\n    waitForState(\"Timeout waiting for active replicas\", collection, clusterShape(1, 3));\n\n    assertEquals(103, cluster.getSolrClient().query(collection, new SolrQuery(\"*:*\")).getResults().getNumFound());\n\n    CollectionAdminRequest.deleteCollection(collection).process(cluster.getSolrClient());\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1c028233025d68dd5abc50afa29107b076b176a2","date":1522414458,"type":3,"author":"Cao Manh Dat","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/LIROnShardRestartTest#testAllReplicasInLIR().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/LIROnShardRestartTest#testAllReplicasInLIR().mjava","sourceNew":"  public void testAllReplicasInLIR() throws Exception {\n    String collection = \"allReplicasInLIR\";\n    CollectionAdminRequest.createCollection(collection, 1, 3)\n        .process(cluster.getSolrClient());\n    cluster.getSolrClient().add(collection, new SolrInputDocument(\"id\", \"1\"));\n    cluster.getSolrClient().add(collection, new SolrInputDocument(\"id\", \"2\"));\n    cluster.getSolrClient().commit(collection);\n\n    DocCollection docCollection = getCollectionState(collection);\n    Slice shard1 = docCollection.getSlice(\"shard1\");\n    Replica newLeader = shard1.getReplicas(rep -> !rep.getName().equals(shard1.getLeader().getName())).get(random().nextInt(2));\n    JettySolrRunner jettyOfNewLeader = cluster.getJettySolrRunners().stream()\n        .filter(jetty -> jetty.getNodeName().equals(newLeader.getNodeName()))\n        .findAny().get();\n    assertNotNull(jettyOfNewLeader);\n\n    // randomly add too many docs to peer sync to one replica so that only one random replica is the valid leader\n    // the versions don't matter, they just have to be higher than what the last 2 docs got\n    try (HttpSolrClient client = getHttpSolrClient(jettyOfNewLeader.getBaseUrl().toString())) {\n      ModifiableSolrParams params = new ModifiableSolrParams();\n      params.set(DistributingUpdateProcessorFactory.DISTRIB_UPDATE_PARAM, DistributedUpdateProcessor.DistribPhase.FROMLEADER.toString());\n\n      for (int i = 0; i < 101; i++) {\n        UpdateRequest ureq = new UpdateRequest();\n        ureq.setParams(new ModifiableSolrParams(params));\n        ureq.add(sdoc(\"id\", 3 + i, \"_version_\", Long.MAX_VALUE - 1 - i));\n        ureq.process(client, collection);\n      }\n      client.commit(collection);\n    }\n\n    ChaosMonkey.stop(cluster.getJettySolrRunners());\n    assertTrue(\"Timeout waiting for all not live\",\n        ClusterStateUtil.waitForAllReplicasNotLive(cluster.getSolrClient().getZkStateReader(), 45000));\n\n    try (ZkShardTerms zkShardTerms = new ZkShardTerms(collection, \"shard1\", cluster.getZkClient())) {\n      for (Replica replica : docCollection.getReplicas()) {\n        zkShardTerms.removeTerm(replica.getName());\n      }\n    }\n\n    Map<String,Object> stateObj = Utils.makeMap();\n    stateObj.put(ZkStateReader.STATE_PROP, \"down\");\n    stateObj.put(\"createdByNodeName\", \"test\");\n    stateObj.put(\"createdByCoreNodeName\", \"test\");\n    byte[] znodeData = Utils.toJSON(stateObj);\n\n    for (Replica replica : docCollection.getReplicas()) {\n      try {\n        cluster.getZkClient().makePath(\"/collections/\" + collection + \"/leader_initiated_recovery/shard1/\" + replica.getName(),\n            znodeData, true);\n      } catch (KeeperException.NodeExistsException e) {\n\n      }\n    }\n\n    ChaosMonkey.start(cluster.getJettySolrRunners());\n    waitForState(\"Timeout waiting for active replicas\", collection, clusterShape(1, 3));\n\n    assertEquals(103, cluster.getSolrClient().query(collection, new SolrQuery(\"*:*\")).getResults().getNumFound());\n\n\n    // now expire each node\n    for (Replica replica : docCollection.getReplicas()) {\n      try {\n        // todo remove the condition for skipping leader after SOLR-12166 is fixed\n        if (newLeader.getName().equals(replica.getName())) continue;\n\n        cluster.getZkClient().makePath(\"/collections/\" + collection + \"/leader_initiated_recovery/shard1/\" + replica.getName(),\n            znodeData, true);\n      } catch (KeeperException.NodeExistsException e) {\n\n      }\n    }\n\n    // only 2 replicas join the election and all of them are in LIR state, no one should win the election\n    List<String> oldElectionNodes = getElectionNodes(collection, \"shard1\", cluster.getZkClient());\n\n    for (JettySolrRunner jetty : cluster.getJettySolrRunners()) {\n      expire(jetty);\n    }\n\n    TimeOut timeOut = new TimeOut(60, TimeUnit.SECONDS, TimeSource.CURRENT_TIME);\n    while (!timeOut.hasTimedOut()) {\n      List<String> electionNodes = getElectionNodes(collection, \"shard1\", cluster.getZkClient());\n      electionNodes.retainAll(oldElectionNodes);\n      if (electionNodes.isEmpty()) break;\n    }\n    assertFalse(\"Timeout waiting for replicas rejoin election\", timeOut.hasTimedOut());\n    try {\n      waitForState(\"Timeout waiting for active replicas\", collection, clusterShape(1, 3));\n    } catch (Throwable th) {\n      String electionPath = \"/collections/allReplicasInLIR/leader_elect/shard1/election/\";\n      List<String> children = zkClient().getChildren(electionPath, null, true);\n      LOG.info(\"Election queue {}\", children);\n      throw th;\n    }\n\n    assertEquals(103, cluster.getSolrClient().query(collection, new SolrQuery(\"*:*\")).getResults().getNumFound());\n\n    CollectionAdminRequest.deleteCollection(collection).process(cluster.getSolrClient());\n  }\n\n","sourceOld":"  public void testAllReplicasInLIR() throws Exception {\n    String collection = \"allReplicasInLIR\";\n    CollectionAdminRequest.createCollection(collection, 1, 3)\n        .process(cluster.getSolrClient());\n    cluster.getSolrClient().add(collection, new SolrInputDocument(\"id\", \"1\"));\n    cluster.getSolrClient().add(collection, new SolrInputDocument(\"id\", \"2\"));\n    cluster.getSolrClient().commit(collection);\n\n    DocCollection docCollection = getCollectionState(collection);\n    Slice shard1 = docCollection.getSlice(\"shard1\");\n    Replica newLeader = shard1.getReplicas(rep -> !rep.getName().equals(shard1.getLeader().getName())).get(random().nextInt(2));\n    JettySolrRunner jettyOfNewLeader = cluster.getJettySolrRunners().stream()\n        .filter(jetty -> jetty.getNodeName().equals(newLeader.getNodeName()))\n        .findAny().get();\n    assertNotNull(jettyOfNewLeader);\n\n    // randomly add too many docs to peer sync to one replica so that only one random replica is the valid leader\n    // the versions don't matter, they just have to be higher than what the last 2 docs got\n    try (HttpSolrClient client = getHttpSolrClient(jettyOfNewLeader.getBaseUrl().toString())) {\n      ModifiableSolrParams params = new ModifiableSolrParams();\n      params.set(DistributingUpdateProcessorFactory.DISTRIB_UPDATE_PARAM, DistributedUpdateProcessor.DistribPhase.FROMLEADER.toString());\n\n      for (int i = 0; i < 101; i++) {\n        UpdateRequest ureq = new UpdateRequest();\n        ureq.setParams(new ModifiableSolrParams(params));\n        ureq.add(sdoc(\"id\", 3 + i, \"_version_\", Long.MAX_VALUE - 1 - i));\n        ureq.process(client, collection);\n      }\n      client.commit(collection);\n    }\n\n    ChaosMonkey.stop(cluster.getJettySolrRunners());\n    assertTrue(\"Timeout waiting for all not live\",\n        ClusterStateUtil.waitForAllReplicasNotLive(cluster.getSolrClient().getZkStateReader(), 45000));\n\n    try (ZkShardTerms zkShardTerms = new ZkShardTerms(collection, \"shard1\", cluster.getZkClient())) {\n      for (Replica replica : docCollection.getReplicas()) {\n        zkShardTerms.removeTerm(replica.getName());\n      }\n    }\n\n    Map<String,Object> stateObj = Utils.makeMap();\n    stateObj.put(ZkStateReader.STATE_PROP, \"down\");\n    stateObj.put(\"createdByNodeName\", \"test\");\n    stateObj.put(\"createdByCoreNodeName\", \"test\");\n    byte[] znodeData = Utils.toJSON(stateObj);\n\n    for (Replica replica : docCollection.getReplicas()) {\n      try {\n        cluster.getZkClient().makePath(\"/collections/\" + collection + \"/leader_initiated_recovery/shard1/\" + replica.getName(),\n            znodeData, true);\n      } catch (KeeperException.NodeExistsException e) {\n\n      }\n    }\n\n    ChaosMonkey.start(cluster.getJettySolrRunners());\n    waitForState(\"Timeout waiting for active replicas\", collection, clusterShape(1, 3));\n\n    assertEquals(103, cluster.getSolrClient().query(collection, new SolrQuery(\"*:*\")).getResults().getNumFound());\n\n\n    // now expire each node\n    for (Replica replica : docCollection.getReplicas()) {\n      try {\n        cluster.getZkClient().makePath(\"/collections/\" + collection + \"/leader_initiated_recovery/shard1/\" + replica.getName(),\n            znodeData, true);\n      } catch (KeeperException.NodeExistsException e) {\n\n      }\n    }\n\n    // only 2 replicas join the election and all of them are in LIR state, no one should win the election\n    List<String> oldElectionNodes = getElectionNodes(collection, \"shard1\", cluster.getZkClient());\n\n    for (JettySolrRunner jetty : cluster.getJettySolrRunners()) {\n      expire(jetty);\n    }\n\n    TimeOut timeOut = new TimeOut(60, TimeUnit.SECONDS, TimeSource.CURRENT_TIME);\n    while (!timeOut.hasTimedOut()) {\n      List<String> electionNodes = getElectionNodes(collection, \"shard1\", cluster.getZkClient());\n      electionNodes.retainAll(oldElectionNodes);\n      if (electionNodes.isEmpty()) break;\n    }\n    assertFalse(\"Timeout waiting for replicas rejoin election\", timeOut.hasTimedOut());\n    waitForState(\"Timeout waiting for active replicas\", collection, clusterShape(1, 3));\n\n    assertEquals(103, cluster.getSolrClient().query(collection, new SolrQuery(\"*:*\")).getResults().getNumFound());\n\n    CollectionAdminRequest.deleteCollection(collection).process(cluster.getSolrClient());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"aa5e39259dfd4a68287c824d3b7e1bc9097dc895","date":1522505041,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/LIROnShardRestartTest#testAllReplicasInLIR().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/LIROnShardRestartTest#testAllReplicasInLIR().mjava","sourceNew":"  public void testAllReplicasInLIR() throws Exception {\n    String collection = \"allReplicasInLIR\";\n    CollectionAdminRequest.createCollection(collection, 1, 3)\n        .process(cluster.getSolrClient());\n    cluster.getSolrClient().add(collection, new SolrInputDocument(\"id\", \"1\"));\n    cluster.getSolrClient().add(collection, new SolrInputDocument(\"id\", \"2\"));\n    cluster.getSolrClient().commit(collection);\n\n    DocCollection docCollection = getCollectionState(collection);\n    Slice shard1 = docCollection.getSlice(\"shard1\");\n    Replica newLeader = shard1.getReplicas(rep -> !rep.getName().equals(shard1.getLeader().getName())).get(random().nextInt(2));\n    JettySolrRunner jettyOfNewLeader = cluster.getJettySolrRunners().stream()\n        .filter(jetty -> jetty.getNodeName().equals(newLeader.getNodeName()))\n        .findAny().get();\n    assertNotNull(jettyOfNewLeader);\n\n    // randomly add too many docs to peer sync to one replica so that only one random replica is the valid leader\n    // the versions don't matter, they just have to be higher than what the last 2 docs got\n    try (HttpSolrClient client = getHttpSolrClient(jettyOfNewLeader.getBaseUrl().toString())) {\n      ModifiableSolrParams params = new ModifiableSolrParams();\n      params.set(DistributingUpdateProcessorFactory.DISTRIB_UPDATE_PARAM, DistributedUpdateProcessor.DistribPhase.FROMLEADER.toString());\n\n      for (int i = 0; i < 101; i++) {\n        UpdateRequest ureq = new UpdateRequest();\n        ureq.setParams(new ModifiableSolrParams(params));\n        ureq.add(sdoc(\"id\", 3 + i, \"_version_\", Long.MAX_VALUE - 1 - i));\n        ureq.process(client, collection);\n      }\n      client.commit(collection);\n    }\n\n    ChaosMonkey.stop(cluster.getJettySolrRunners());\n    assertTrue(\"Timeout waiting for all not live\",\n        ClusterStateUtil.waitForAllReplicasNotLive(cluster.getSolrClient().getZkStateReader(), 45000));\n\n    try (ZkShardTerms zkShardTerms = new ZkShardTerms(collection, \"shard1\", cluster.getZkClient())) {\n      for (Replica replica : docCollection.getReplicas()) {\n        zkShardTerms.removeTerm(replica.getName());\n      }\n    }\n\n    Map<String,Object> stateObj = Utils.makeMap();\n    stateObj.put(ZkStateReader.STATE_PROP, \"down\");\n    stateObj.put(\"createdByNodeName\", \"test\");\n    stateObj.put(\"createdByCoreNodeName\", \"test\");\n    byte[] znodeData = Utils.toJSON(stateObj);\n\n    for (Replica replica : docCollection.getReplicas()) {\n      try {\n        cluster.getZkClient().makePath(\"/collections/\" + collection + \"/leader_initiated_recovery/shard1/\" + replica.getName(),\n            znodeData, true);\n      } catch (KeeperException.NodeExistsException e) {\n\n      }\n    }\n\n    ChaosMonkey.start(cluster.getJettySolrRunners());\n    waitForState(\"Timeout waiting for active replicas\", collection, clusterShape(1, 3));\n\n    assertEquals(103, cluster.getSolrClient().query(collection, new SolrQuery(\"*:*\")).getResults().getNumFound());\n\n\n    // now expire each node\n    for (Replica replica : docCollection.getReplicas()) {\n      try {\n        // todo remove the condition for skipping leader after SOLR-12166 is fixed\n        if (newLeader.getName().equals(replica.getName())) continue;\n\n        cluster.getZkClient().makePath(\"/collections/\" + collection + \"/leader_initiated_recovery/shard1/\" + replica.getName(),\n            znodeData, true);\n      } catch (KeeperException.NodeExistsException e) {\n\n      }\n    }\n\n    // only 2 replicas join the election and all of them are in LIR state, no one should win the election\n    List<String> oldElectionNodes = getElectionNodes(collection, \"shard1\", cluster.getZkClient());\n\n    for (JettySolrRunner jetty : cluster.getJettySolrRunners()) {\n      expire(jetty);\n    }\n\n    TimeOut timeOut = new TimeOut(60, TimeUnit.SECONDS, TimeSource.CURRENT_TIME);\n    while (!timeOut.hasTimedOut()) {\n      List<String> electionNodes = getElectionNodes(collection, \"shard1\", cluster.getZkClient());\n      electionNodes.retainAll(oldElectionNodes);\n      if (electionNodes.isEmpty()) break;\n    }\n    assertFalse(\"Timeout waiting for replicas rejoin election\", timeOut.hasTimedOut());\n    try {\n      waitForState(\"Timeout waiting for active replicas\", collection, clusterShape(1, 3));\n    } catch (Throwable th) {\n      String electionPath = \"/collections/allReplicasInLIR/leader_elect/shard1/election/\";\n      List<String> children = zkClient().getChildren(electionPath, null, true);\n      LOG.info(\"Election queue {}\", children);\n      throw th;\n    }\n\n    assertEquals(103, cluster.getSolrClient().query(collection, new SolrQuery(\"*:*\")).getResults().getNumFound());\n\n    CollectionAdminRequest.deleteCollection(collection).process(cluster.getSolrClient());\n  }\n\n","sourceOld":"  public void testAllReplicasInLIR() throws Exception {\n    String collection = \"allReplicasInLIR\";\n    CollectionAdminRequest.createCollection(collection, 1, 3)\n        .process(cluster.getSolrClient());\n    cluster.getSolrClient().add(collection, new SolrInputDocument(\"id\", \"1\"));\n    cluster.getSolrClient().add(collection, new SolrInputDocument(\"id\", \"2\"));\n    cluster.getSolrClient().commit(collection);\n\n    DocCollection docCollection = getCollectionState(collection);\n    Slice shard1 = docCollection.getSlice(\"shard1\");\n    Replica newLeader = shard1.getReplicas(rep -> !rep.getName().equals(shard1.getLeader().getName())).get(random().nextInt(2));\n    JettySolrRunner jettyOfNewLeader = cluster.getJettySolrRunners().stream()\n        .filter(jetty -> jetty.getNodeName().equals(newLeader.getNodeName()))\n        .findAny().get();\n    assertNotNull(jettyOfNewLeader);\n\n    // randomly add too many docs to peer sync to one replica so that only one random replica is the valid leader\n    // the versions don't matter, they just have to be higher than what the last 2 docs got\n    try (HttpSolrClient client = getHttpSolrClient(jettyOfNewLeader.getBaseUrl().toString())) {\n      ModifiableSolrParams params = new ModifiableSolrParams();\n      params.set(DistributingUpdateProcessorFactory.DISTRIB_UPDATE_PARAM, DistributedUpdateProcessor.DistribPhase.FROMLEADER.toString());\n\n      for (int i = 0; i < 101; i++) {\n        UpdateRequest ureq = new UpdateRequest();\n        ureq.setParams(new ModifiableSolrParams(params));\n        ureq.add(sdoc(\"id\", 3 + i, \"_version_\", Long.MAX_VALUE - 1 - i));\n        ureq.process(client, collection);\n      }\n      client.commit(collection);\n    }\n\n    ChaosMonkey.stop(cluster.getJettySolrRunners());\n    assertTrue(\"Timeout waiting for all not live\",\n        ClusterStateUtil.waitForAllReplicasNotLive(cluster.getSolrClient().getZkStateReader(), 45000));\n\n    try (ZkShardTerms zkShardTerms = new ZkShardTerms(collection, \"shard1\", cluster.getZkClient())) {\n      for (Replica replica : docCollection.getReplicas()) {\n        zkShardTerms.removeTerm(replica.getName());\n      }\n    }\n\n    Map<String,Object> stateObj = Utils.makeMap();\n    stateObj.put(ZkStateReader.STATE_PROP, \"down\");\n    stateObj.put(\"createdByNodeName\", \"test\");\n    stateObj.put(\"createdByCoreNodeName\", \"test\");\n    byte[] znodeData = Utils.toJSON(stateObj);\n\n    for (Replica replica : docCollection.getReplicas()) {\n      try {\n        cluster.getZkClient().makePath(\"/collections/\" + collection + \"/leader_initiated_recovery/shard1/\" + replica.getName(),\n            znodeData, true);\n      } catch (KeeperException.NodeExistsException e) {\n\n      }\n    }\n\n    ChaosMonkey.start(cluster.getJettySolrRunners());\n    waitForState(\"Timeout waiting for active replicas\", collection, clusterShape(1, 3));\n\n    assertEquals(103, cluster.getSolrClient().query(collection, new SolrQuery(\"*:*\")).getResults().getNumFound());\n\n\n    // now expire each node\n    for (Replica replica : docCollection.getReplicas()) {\n      try {\n        cluster.getZkClient().makePath(\"/collections/\" + collection + \"/leader_initiated_recovery/shard1/\" + replica.getName(),\n            znodeData, true);\n      } catch (KeeperException.NodeExistsException e) {\n\n      }\n    }\n\n    // only 2 replicas join the election and all of them are in LIR state, no one should win the election\n    List<String> oldElectionNodes = getElectionNodes(collection, \"shard1\", cluster.getZkClient());\n\n    for (JettySolrRunner jetty : cluster.getJettySolrRunners()) {\n      expire(jetty);\n    }\n\n    TimeOut timeOut = new TimeOut(60, TimeUnit.SECONDS, TimeSource.CURRENT_TIME);\n    while (!timeOut.hasTimedOut()) {\n      List<String> electionNodes = getElectionNodes(collection, \"shard1\", cluster.getZkClient());\n      electionNodes.retainAll(oldElectionNodes);\n      if (electionNodes.isEmpty()) break;\n    }\n    assertFalse(\"Timeout waiting for replicas rejoin election\", timeOut.hasTimedOut());\n    waitForState(\"Timeout waiting for active replicas\", collection, clusterShape(1, 3));\n\n    assertEquals(103, cluster.getSolrClient().query(collection, new SolrQuery(\"*:*\")).getResults().getNumFound());\n\n    CollectionAdminRequest.deleteCollection(collection).process(cluster.getSolrClient());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e9c81f7e703d7ccca5bc78beb61253f0a8a22afd","date":1534976797,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/LIROnShardRestartTest#testAllReplicasInLIR().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/LIROnShardRestartTest#testAllReplicasInLIR().mjava","sourceNew":"  public void testAllReplicasInLIR() throws Exception {\n    String collection = \"allReplicasInLIR\";\n    CollectionAdminRequest.createCollection(collection, 1, 3)\n        .process(cluster.getSolrClient());\n    cluster.getSolrClient().add(collection, new SolrInputDocument(\"id\", \"1\"));\n    cluster.getSolrClient().add(collection, new SolrInputDocument(\"id\", \"2\"));\n    cluster.getSolrClient().commit(collection);\n\n    DocCollection docCollection = getCollectionState(collection);\n    Slice shard1 = docCollection.getSlice(\"shard1\");\n    Replica newLeader = shard1.getReplicas(rep -> !rep.getName().equals(shard1.getLeader().getName())).get(random().nextInt(2));\n    JettySolrRunner jettyOfNewLeader = cluster.getJettySolrRunners().stream()\n        .filter(jetty -> jetty.getNodeName().equals(newLeader.getNodeName()))\n        .findAny().get();\n    assertNotNull(jettyOfNewLeader);\n\n    // randomly add too many docs to peer sync to one replica so that only one random replica is the valid leader\n    // the versions don't matter, they just have to be higher than what the last 2 docs got\n    try (HttpSolrClient client = getHttpSolrClient(jettyOfNewLeader.getBaseUrl().toString())) {\n      ModifiableSolrParams params = new ModifiableSolrParams();\n      params.set(DistributingUpdateProcessorFactory.DISTRIB_UPDATE_PARAM, DistributedUpdateProcessor.DistribPhase.FROMLEADER.toString());\n\n      for (int i = 0; i < 101; i++) {\n        UpdateRequest ureq = new UpdateRequest();\n        ureq.setParams(new ModifiableSolrParams(params));\n        ureq.add(sdoc(\"id\", 3 + i, \"_version_\", Long.MAX_VALUE - 1 - i));\n        ureq.process(client, collection);\n      }\n      client.commit(collection);\n    }\n\n    ChaosMonkey.stop(cluster.getJettySolrRunners());\n    assertTrue(\"Timeout waiting for all not live\",\n        ClusterStateUtil.waitForAllReplicasNotLive(cluster.getSolrClient().getZkStateReader(), 45000));\n\n    try (ZkShardTerms zkShardTerms = new ZkShardTerms(collection, \"shard1\", cluster.getZkClient())) {\n      for (Replica replica : docCollection.getReplicas()) {\n        zkShardTerms.removeTerm(replica.getName());\n      }\n    }\n\n    Map<String,Object> stateObj = Utils.makeMap();\n    stateObj.put(ZkStateReader.STATE_PROP, \"down\");\n    stateObj.put(\"createdByNodeName\", \"test\");\n    stateObj.put(\"createdByCoreNodeName\", \"test\");\n    byte[] znodeData = Utils.toJSON(stateObj);\n\n    for (Replica replica : docCollection.getReplicas()) {\n      try {\n        cluster.getZkClient().makePath(\"/collections/\" + collection + \"/leader_initiated_recovery/shard1/\" + replica.getName(),\n            znodeData, true);\n      } catch (KeeperException.NodeExistsException e) {\n\n      }\n    }\n\n    ChaosMonkey.start(cluster.getJettySolrRunners());\n    waitForState(\"Timeout waiting for active replicas\", collection, clusterShape(1, 3));\n\n    assertEquals(103, cluster.getSolrClient().query(collection, new SolrQuery(\"*:*\")).getResults().getNumFound());\n\n\n    // now expire each node\n    for (Replica replica : docCollection.getReplicas()) {\n      try {\n        // todo remove the condition for skipping leader after SOLR-12166 is fixed\n        if (newLeader.getName().equals(replica.getName())) continue;\n\n        cluster.getZkClient().makePath(\"/collections/\" + collection + \"/leader_initiated_recovery/shard1/\" + replica.getName(),\n            znodeData, true);\n      } catch (KeeperException.NodeExistsException e) {\n\n      }\n    }\n\n    // only 2 replicas join the election and all of them are in LIR state, no one should win the election\n    List<String> oldElectionNodes = getElectionNodes(collection, \"shard1\", cluster.getZkClient());\n\n    for (JettySolrRunner jetty : cluster.getJettySolrRunners()) {\n      expire(jetty);\n    }\n\n    TimeOut timeOut = new TimeOut(60, TimeUnit.SECONDS, TimeSource.CURRENT_TIME);\n    while (!timeOut.hasTimedOut()) {\n      List<String> electionNodes = getElectionNodes(collection, \"shard1\", cluster.getZkClient());\n      electionNodes.retainAll(oldElectionNodes);\n      if (electionNodes.isEmpty()) break;\n    }\n    assertFalse(\"Timeout waiting for replicas rejoin election\", timeOut.hasTimedOut());\n    try {\n      waitForState(\"Timeout waiting for active replicas\", collection, clusterShape(1, 3));\n    } catch (Throwable th) {\n      String electionPath = \"/collections/allReplicasInLIR/leader_elect/shard1/election/\";\n      List<String> children = zkClient().getChildren(electionPath, null, true);\n      log.info(\"Election queue {}\", children);\n      throw th;\n    }\n\n    assertEquals(103, cluster.getSolrClient().query(collection, new SolrQuery(\"*:*\")).getResults().getNumFound());\n\n    CollectionAdminRequest.deleteCollection(collection).process(cluster.getSolrClient());\n  }\n\n","sourceOld":"  public void testAllReplicasInLIR() throws Exception {\n    String collection = \"allReplicasInLIR\";\n    CollectionAdminRequest.createCollection(collection, 1, 3)\n        .process(cluster.getSolrClient());\n    cluster.getSolrClient().add(collection, new SolrInputDocument(\"id\", \"1\"));\n    cluster.getSolrClient().add(collection, new SolrInputDocument(\"id\", \"2\"));\n    cluster.getSolrClient().commit(collection);\n\n    DocCollection docCollection = getCollectionState(collection);\n    Slice shard1 = docCollection.getSlice(\"shard1\");\n    Replica newLeader = shard1.getReplicas(rep -> !rep.getName().equals(shard1.getLeader().getName())).get(random().nextInt(2));\n    JettySolrRunner jettyOfNewLeader = cluster.getJettySolrRunners().stream()\n        .filter(jetty -> jetty.getNodeName().equals(newLeader.getNodeName()))\n        .findAny().get();\n    assertNotNull(jettyOfNewLeader);\n\n    // randomly add too many docs to peer sync to one replica so that only one random replica is the valid leader\n    // the versions don't matter, they just have to be higher than what the last 2 docs got\n    try (HttpSolrClient client = getHttpSolrClient(jettyOfNewLeader.getBaseUrl().toString())) {\n      ModifiableSolrParams params = new ModifiableSolrParams();\n      params.set(DistributingUpdateProcessorFactory.DISTRIB_UPDATE_PARAM, DistributedUpdateProcessor.DistribPhase.FROMLEADER.toString());\n\n      for (int i = 0; i < 101; i++) {\n        UpdateRequest ureq = new UpdateRequest();\n        ureq.setParams(new ModifiableSolrParams(params));\n        ureq.add(sdoc(\"id\", 3 + i, \"_version_\", Long.MAX_VALUE - 1 - i));\n        ureq.process(client, collection);\n      }\n      client.commit(collection);\n    }\n\n    ChaosMonkey.stop(cluster.getJettySolrRunners());\n    assertTrue(\"Timeout waiting for all not live\",\n        ClusterStateUtil.waitForAllReplicasNotLive(cluster.getSolrClient().getZkStateReader(), 45000));\n\n    try (ZkShardTerms zkShardTerms = new ZkShardTerms(collection, \"shard1\", cluster.getZkClient())) {\n      for (Replica replica : docCollection.getReplicas()) {\n        zkShardTerms.removeTerm(replica.getName());\n      }\n    }\n\n    Map<String,Object> stateObj = Utils.makeMap();\n    stateObj.put(ZkStateReader.STATE_PROP, \"down\");\n    stateObj.put(\"createdByNodeName\", \"test\");\n    stateObj.put(\"createdByCoreNodeName\", \"test\");\n    byte[] znodeData = Utils.toJSON(stateObj);\n\n    for (Replica replica : docCollection.getReplicas()) {\n      try {\n        cluster.getZkClient().makePath(\"/collections/\" + collection + \"/leader_initiated_recovery/shard1/\" + replica.getName(),\n            znodeData, true);\n      } catch (KeeperException.NodeExistsException e) {\n\n      }\n    }\n\n    ChaosMonkey.start(cluster.getJettySolrRunners());\n    waitForState(\"Timeout waiting for active replicas\", collection, clusterShape(1, 3));\n\n    assertEquals(103, cluster.getSolrClient().query(collection, new SolrQuery(\"*:*\")).getResults().getNumFound());\n\n\n    // now expire each node\n    for (Replica replica : docCollection.getReplicas()) {\n      try {\n        // todo remove the condition for skipping leader after SOLR-12166 is fixed\n        if (newLeader.getName().equals(replica.getName())) continue;\n\n        cluster.getZkClient().makePath(\"/collections/\" + collection + \"/leader_initiated_recovery/shard1/\" + replica.getName(),\n            znodeData, true);\n      } catch (KeeperException.NodeExistsException e) {\n\n      }\n    }\n\n    // only 2 replicas join the election and all of them are in LIR state, no one should win the election\n    List<String> oldElectionNodes = getElectionNodes(collection, \"shard1\", cluster.getZkClient());\n\n    for (JettySolrRunner jetty : cluster.getJettySolrRunners()) {\n      expire(jetty);\n    }\n\n    TimeOut timeOut = new TimeOut(60, TimeUnit.SECONDS, TimeSource.CURRENT_TIME);\n    while (!timeOut.hasTimedOut()) {\n      List<String> electionNodes = getElectionNodes(collection, \"shard1\", cluster.getZkClient());\n      electionNodes.retainAll(oldElectionNodes);\n      if (electionNodes.isEmpty()) break;\n    }\n    assertFalse(\"Timeout waiting for replicas rejoin election\", timeOut.hasTimedOut());\n    try {\n      waitForState(\"Timeout waiting for active replicas\", collection, clusterShape(1, 3));\n    } catch (Throwable th) {\n      String electionPath = \"/collections/allReplicasInLIR/leader_elect/shard1/election/\";\n      List<String> children = zkClient().getChildren(electionPath, null, true);\n      LOG.info(\"Election queue {}\", children);\n      throw th;\n    }\n\n    assertEquals(103, cluster.getSolrClient().query(collection, new SolrQuery(\"*:*\")).getResults().getNumFound());\n\n    CollectionAdminRequest.deleteCollection(collection).process(cluster.getSolrClient());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e17aaf87787d71a71e24ffcebe989d02f078efd2","date":1540263539,"type":4,"author":"Cao Manh Dat","isMerge":false,"pathNew":"/dev/null","pathOld":"solr/core/src/test/org/apache/solr/cloud/LIROnShardRestartTest#testAllReplicasInLIR().mjava","sourceNew":null,"sourceOld":"  public void testAllReplicasInLIR() throws Exception {\n    String collection = \"allReplicasInLIR\";\n    CollectionAdminRequest.createCollection(collection, 1, 3)\n        .process(cluster.getSolrClient());\n    cluster.getSolrClient().add(collection, new SolrInputDocument(\"id\", \"1\"));\n    cluster.getSolrClient().add(collection, new SolrInputDocument(\"id\", \"2\"));\n    cluster.getSolrClient().commit(collection);\n\n    DocCollection docCollection = getCollectionState(collection);\n    Slice shard1 = docCollection.getSlice(\"shard1\");\n    Replica newLeader = shard1.getReplicas(rep -> !rep.getName().equals(shard1.getLeader().getName())).get(random().nextInt(2));\n    JettySolrRunner jettyOfNewLeader = cluster.getJettySolrRunners().stream()\n        .filter(jetty -> jetty.getNodeName().equals(newLeader.getNodeName()))\n        .findAny().get();\n    assertNotNull(jettyOfNewLeader);\n\n    // randomly add too many docs to peer sync to one replica so that only one random replica is the valid leader\n    // the versions don't matter, they just have to be higher than what the last 2 docs got\n    try (HttpSolrClient client = getHttpSolrClient(jettyOfNewLeader.getBaseUrl().toString())) {\n      ModifiableSolrParams params = new ModifiableSolrParams();\n      params.set(DistributingUpdateProcessorFactory.DISTRIB_UPDATE_PARAM, DistributedUpdateProcessor.DistribPhase.FROMLEADER.toString());\n\n      for (int i = 0; i < 101; i++) {\n        UpdateRequest ureq = new UpdateRequest();\n        ureq.setParams(new ModifiableSolrParams(params));\n        ureq.add(sdoc(\"id\", 3 + i, \"_version_\", Long.MAX_VALUE - 1 - i));\n        ureq.process(client, collection);\n      }\n      client.commit(collection);\n    }\n\n    ChaosMonkey.stop(cluster.getJettySolrRunners());\n    assertTrue(\"Timeout waiting for all not live\",\n        ClusterStateUtil.waitForAllReplicasNotLive(cluster.getSolrClient().getZkStateReader(), 45000));\n\n    try (ZkShardTerms zkShardTerms = new ZkShardTerms(collection, \"shard1\", cluster.getZkClient())) {\n      for (Replica replica : docCollection.getReplicas()) {\n        zkShardTerms.removeTerm(replica.getName());\n      }\n    }\n\n    Map<String,Object> stateObj = Utils.makeMap();\n    stateObj.put(ZkStateReader.STATE_PROP, \"down\");\n    stateObj.put(\"createdByNodeName\", \"test\");\n    stateObj.put(\"createdByCoreNodeName\", \"test\");\n    byte[] znodeData = Utils.toJSON(stateObj);\n\n    for (Replica replica : docCollection.getReplicas()) {\n      try {\n        cluster.getZkClient().makePath(\"/collections/\" + collection + \"/leader_initiated_recovery/shard1/\" + replica.getName(),\n            znodeData, true);\n      } catch (KeeperException.NodeExistsException e) {\n\n      }\n    }\n\n    ChaosMonkey.start(cluster.getJettySolrRunners());\n    waitForState(\"Timeout waiting for active replicas\", collection, clusterShape(1, 3));\n\n    assertEquals(103, cluster.getSolrClient().query(collection, new SolrQuery(\"*:*\")).getResults().getNumFound());\n\n\n    // now expire each node\n    for (Replica replica : docCollection.getReplicas()) {\n      try {\n        // todo remove the condition for skipping leader after SOLR-12166 is fixed\n        if (newLeader.getName().equals(replica.getName())) continue;\n\n        cluster.getZkClient().makePath(\"/collections/\" + collection + \"/leader_initiated_recovery/shard1/\" + replica.getName(),\n            znodeData, true);\n      } catch (KeeperException.NodeExistsException e) {\n\n      }\n    }\n\n    // only 2 replicas join the election and all of them are in LIR state, no one should win the election\n    List<String> oldElectionNodes = getElectionNodes(collection, \"shard1\", cluster.getZkClient());\n\n    for (JettySolrRunner jetty : cluster.getJettySolrRunners()) {\n      expire(jetty);\n    }\n\n    TimeOut timeOut = new TimeOut(60, TimeUnit.SECONDS, TimeSource.CURRENT_TIME);\n    while (!timeOut.hasTimedOut()) {\n      List<String> electionNodes = getElectionNodes(collection, \"shard1\", cluster.getZkClient());\n      electionNodes.retainAll(oldElectionNodes);\n      if (electionNodes.isEmpty()) break;\n    }\n    assertFalse(\"Timeout waiting for replicas rejoin election\", timeOut.hasTimedOut());\n    try {\n      waitForState(\"Timeout waiting for active replicas\", collection, clusterShape(1, 3));\n    } catch (Throwable th) {\n      String electionPath = \"/collections/allReplicasInLIR/leader_elect/shard1/election/\";\n      List<String> children = zkClient().getChildren(electionPath, null, true);\n      log.info(\"Election queue {}\", children);\n      throw th;\n    }\n\n    assertEquals(103, cluster.getSolrClient().query(collection, new SolrQuery(\"*:*\")).getResults().getNumFound());\n\n    CollectionAdminRequest.deleteCollection(collection).process(cluster.getSolrClient());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"e17aaf87787d71a71e24ffcebe989d02f078efd2":["e9c81f7e703d7ccca5bc78beb61253f0a8a22afd"],"9339df295b9162e4c81adbb4da44b5939d27c1ef":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"aa5e39259dfd4a68287c824d3b7e1bc9097dc895":["9339df295b9162e4c81adbb4da44b5939d27c1ef","1c028233025d68dd5abc50afa29107b076b176a2"],"1c028233025d68dd5abc50afa29107b076b176a2":["9339df295b9162e4c81adbb4da44b5939d27c1ef"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["e17aaf87787d71a71e24ffcebe989d02f078efd2"],"e9c81f7e703d7ccca5bc78beb61253f0a8a22afd":["aa5e39259dfd4a68287c824d3b7e1bc9097dc895"]},"commit2Childs":{"e17aaf87787d71a71e24ffcebe989d02f078efd2":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"9339df295b9162e4c81adbb4da44b5939d27c1ef":["aa5e39259dfd4a68287c824d3b7e1bc9097dc895","1c028233025d68dd5abc50afa29107b076b176a2"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["9339df295b9162e4c81adbb4da44b5939d27c1ef"],"aa5e39259dfd4a68287c824d3b7e1bc9097dc895":["e9c81f7e703d7ccca5bc78beb61253f0a8a22afd"],"1c028233025d68dd5abc50afa29107b076b176a2":["aa5e39259dfd4a68287c824d3b7e1bc9097dc895"],"e9c81f7e703d7ccca5bc78beb61253f0a8a22afd":["e17aaf87787d71a71e24ffcebe989d02f078efd2"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}