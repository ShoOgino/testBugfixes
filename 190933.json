{"path":"lucene/grouping/src/java/org/apache/lucene/search/grouping/AbstractFirstPassGroupingCollector#collect(int).mjava","commits":[{"id":"b89678825b68eccaf09e6ab71675fc0b0af1e099","date":1334669779,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/grouping/src/java/org/apache/lucene/search/grouping/AbstractFirstPassGroupingCollector#collect(int).mjava","pathOld":"modules/grouping/src/java/org/apache/lucene/search/grouping/AbstractFirstPassGroupingCollector#collect(int).mjava","sourceNew":"  @Override\n  public void collect(int doc) throws IOException {\n    //System.out.println(\"FP.collect doc=\" + doc);\n\n    // If orderedGroups != null we already have collected N groups and\n    // can short circuit by comparing this document to the bottom group,\n    // without having to find what group this document belongs to.\n    \n    // Even if this document belongs to a group in the top N, we'll know that\n    // we don't have to update that group.\n\n    // Downside: if the number of unique groups is very low, this is\n    // wasted effort as we will most likely be updating an existing group.\n    if (orderedGroups != null) {\n      for (int compIDX = 0;; compIDX++) {\n        final int c = reversed[compIDX] * comparators[compIDX].compareBottom(doc);\n        if (c < 0) {\n          // Definitely not competitive. So don't even bother to continue\n          return;\n        } else if (c > 0) {\n          // Definitely competitive.\n          break;\n        } else if (compIDX == compIDXEnd) {\n          // Here c=0. If we're at the last comparator, this doc is not\n          // competitive, since docs are visited in doc Id order, which means\n          // this doc cannot compete with any other document in the queue.\n          return;\n        }\n      }\n    }\n\n    // TODO: should we add option to mean \"ignore docs that\n    // don't have the group field\" (instead of stuffing them\n    // under null group)?\n    final GROUP_VALUE_TYPE groupValue = getDocGroupValue(doc);\n\n    final CollectedSearchGroup<GROUP_VALUE_TYPE> group = groupMap.get(groupValue);\n\n    if (group == null) {\n\n      // First time we are seeing this group, or, we've seen\n      // it before but it fell out of the top N and is now\n      // coming back\n\n      if (groupMap.size() < topNGroups) {\n\n        // Still in startup transient: we have not\n        // seen enough unique groups to start pruning them;\n        // just keep collecting them\n\n        // Add a new CollectedSearchGroup:\n        CollectedSearchGroup<GROUP_VALUE_TYPE> sg = new CollectedSearchGroup<GROUP_VALUE_TYPE>();\n        sg.groupValue = copyDocGroupValue(groupValue, null);\n        sg.comparatorSlot = groupMap.size();\n        sg.topDoc = docBase + doc;\n        for (FieldComparator<?> fc : comparators) {\n          fc.copy(sg.comparatorSlot, doc);\n        }\n        groupMap.put(sg.groupValue, sg);\n\n        if (groupMap.size() == topNGroups) {\n          // End of startup transient: we now have max\n          // number of groups; from here on we will drop\n          // bottom group when we insert new one:\n          buildSortedSet();\n        }\n\n        return;\n      }\n\n      // We already tested that the document is competitive, so replace\n      // the bottom group with this new group.\n      final CollectedSearchGroup<GROUP_VALUE_TYPE> bottomGroup = orderedGroups.pollLast();\n      assert orderedGroups.size() == topNGroups -1;\n\n      groupMap.remove(bottomGroup.groupValue);\n\n      // reuse the removed CollectedSearchGroup\n      bottomGroup.groupValue = copyDocGroupValue(groupValue, bottomGroup.groupValue);\n      bottomGroup.topDoc = docBase + doc;\n\n      for (FieldComparator<?> fc : comparators) {\n        fc.copy(bottomGroup.comparatorSlot, doc);\n      }\n\n      groupMap.put(bottomGroup.groupValue, bottomGroup);\n      orderedGroups.add(bottomGroup);\n      assert orderedGroups.size() == topNGroups;\n\n      final int lastComparatorSlot = orderedGroups.last().comparatorSlot;\n      for (FieldComparator<?> fc : comparators) {\n        fc.setBottom(lastComparatorSlot);\n      }\n\n      return;\n    }\n\n    // Update existing group:\n    for (int compIDX = 0;; compIDX++) {\n      final FieldComparator<?> fc = comparators[compIDX];\n      fc.copy(spareSlot, doc);\n\n      final int c = reversed[compIDX] * fc.compare(group.comparatorSlot, spareSlot);\n      if (c < 0) {\n        // Definitely not competitive.\n        return;\n      } else if (c > 0) {\n        // Definitely competitive; set remaining comparators:\n        for (int compIDX2=compIDX+1; compIDX2<comparators.length; compIDX2++) {\n          comparators[compIDX2].copy(spareSlot, doc);\n        }\n        break;\n      } else if (compIDX == compIDXEnd) {\n        // Here c=0. If we're at the last comparator, this doc is not\n        // competitive, since docs are visited in doc Id order, which means\n        // this doc cannot compete with any other document in the queue.\n        return;\n      }\n    }\n\n    // Remove before updating the group since lookup is done via comparators\n    // TODO: optimize this\n\n    final CollectedSearchGroup<GROUP_VALUE_TYPE> prevLast;\n    if (orderedGroups != null) {\n      prevLast = orderedGroups.last();\n      orderedGroups.remove(group);\n      assert orderedGroups.size() == topNGroups-1;\n    } else {\n      prevLast = null;\n    }\n\n    group.topDoc = docBase + doc;\n\n    // Swap slots\n    final int tmp = spareSlot;\n    spareSlot = group.comparatorSlot;\n    group.comparatorSlot = tmp;\n\n    // Re-add the changed group\n    if (orderedGroups != null) {\n      orderedGroups.add(group);\n      assert orderedGroups.size() == topNGroups;\n      final CollectedSearchGroup<?> newLast = orderedGroups.last();\n      // If we changed the value of the last group, or changed which group was last, then update bottom:\n      if (group == newLast || prevLast != newLast) {\n        for (FieldComparator<?> fc : comparators) {\n          fc.setBottom(newLast.comparatorSlot);\n        }\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  public void collect(int doc) throws IOException {\n    //System.out.println(\"FP.collect doc=\" + doc);\n\n    // If orderedGroups != null we already have collected N groups and\n    // can short circuit by comparing this document to the bottom group,\n    // without having to find what group this document belongs to.\n    \n    // Even if this document belongs to a group in the top N, we'll know that\n    // we don't have to update that group.\n\n    // Downside: if the number of unique groups is very low, this is\n    // wasted effort as we will most likely be updating an existing group.\n    if (orderedGroups != null) {\n      for (int compIDX = 0;; compIDX++) {\n        final int c = reversed[compIDX] * comparators[compIDX].compareBottom(doc);\n        if (c < 0) {\n          // Definitely not competitive. So don't even bother to continue\n          return;\n        } else if (c > 0) {\n          // Definitely competitive.\n          break;\n        } else if (compIDX == compIDXEnd) {\n          // Here c=0. If we're at the last comparator, this doc is not\n          // competitive, since docs are visited in doc Id order, which means\n          // this doc cannot compete with any other document in the queue.\n          return;\n        }\n      }\n    }\n\n    // TODO: should we add option to mean \"ignore docs that\n    // don't have the group field\" (instead of stuffing them\n    // under null group)?\n    final GROUP_VALUE_TYPE groupValue = getDocGroupValue(doc);\n\n    final CollectedSearchGroup<GROUP_VALUE_TYPE> group = groupMap.get(groupValue);\n\n    if (group == null) {\n\n      // First time we are seeing this group, or, we've seen\n      // it before but it fell out of the top N and is now\n      // coming back\n\n      if (groupMap.size() < topNGroups) {\n\n        // Still in startup transient: we have not\n        // seen enough unique groups to start pruning them;\n        // just keep collecting them\n\n        // Add a new CollectedSearchGroup:\n        CollectedSearchGroup<GROUP_VALUE_TYPE> sg = new CollectedSearchGroup<GROUP_VALUE_TYPE>();\n        sg.groupValue = copyDocGroupValue(groupValue, null);\n        sg.comparatorSlot = groupMap.size();\n        sg.topDoc = docBase + doc;\n        for (FieldComparator<?> fc : comparators) {\n          fc.copy(sg.comparatorSlot, doc);\n        }\n        groupMap.put(sg.groupValue, sg);\n\n        if (groupMap.size() == topNGroups) {\n          // End of startup transient: we now have max\n          // number of groups; from here on we will drop\n          // bottom group when we insert new one:\n          buildSortedSet();\n        }\n\n        return;\n      }\n\n      // We already tested that the document is competitive, so replace\n      // the bottom group with this new group.\n      final CollectedSearchGroup<GROUP_VALUE_TYPE> bottomGroup = orderedGroups.pollLast();\n      assert orderedGroups.size() == topNGroups -1;\n\n      groupMap.remove(bottomGroup.groupValue);\n\n      // reuse the removed CollectedSearchGroup\n      bottomGroup.groupValue = copyDocGroupValue(groupValue, bottomGroup.groupValue);\n      bottomGroup.topDoc = docBase + doc;\n\n      for (FieldComparator<?> fc : comparators) {\n        fc.copy(bottomGroup.comparatorSlot, doc);\n      }\n\n      groupMap.put(bottomGroup.groupValue, bottomGroup);\n      orderedGroups.add(bottomGroup);\n      assert orderedGroups.size() == topNGroups;\n\n      final int lastComparatorSlot = orderedGroups.last().comparatorSlot;\n      for (FieldComparator<?> fc : comparators) {\n        fc.setBottom(lastComparatorSlot);\n      }\n\n      return;\n    }\n\n    // Update existing group:\n    for (int compIDX = 0;; compIDX++) {\n      final FieldComparator<?> fc = comparators[compIDX];\n      fc.copy(spareSlot, doc);\n\n      final int c = reversed[compIDX] * fc.compare(group.comparatorSlot, spareSlot);\n      if (c < 0) {\n        // Definitely not competitive.\n        return;\n      } else if (c > 0) {\n        // Definitely competitive; set remaining comparators:\n        for (int compIDX2=compIDX+1; compIDX2<comparators.length; compIDX2++) {\n          comparators[compIDX2].copy(spareSlot, doc);\n        }\n        break;\n      } else if (compIDX == compIDXEnd) {\n        // Here c=0. If we're at the last comparator, this doc is not\n        // competitive, since docs are visited in doc Id order, which means\n        // this doc cannot compete with any other document in the queue.\n        return;\n      }\n    }\n\n    // Remove before updating the group since lookup is done via comparators\n    // TODO: optimize this\n\n    final CollectedSearchGroup<GROUP_VALUE_TYPE> prevLast;\n    if (orderedGroups != null) {\n      prevLast = orderedGroups.last();\n      orderedGroups.remove(group);\n      assert orderedGroups.size() == topNGroups-1;\n    } else {\n      prevLast = null;\n    }\n\n    group.topDoc = docBase + doc;\n\n    // Swap slots\n    final int tmp = spareSlot;\n    spareSlot = group.comparatorSlot;\n    group.comparatorSlot = tmp;\n\n    // Re-add the changed group\n    if (orderedGroups != null) {\n      orderedGroups.add(group);\n      assert orderedGroups.size() == topNGroups;\n      final CollectedSearchGroup<?> newLast = orderedGroups.last();\n      // If we changed the value of the last group, or changed which group was last, then update bottom:\n      if (group == newLast || prevLast != newLast) {\n        for (FieldComparator<?> fc : comparators) {\n          fc.setBottom(newLast.comparatorSlot);\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"97d4692d0c601ff773f0a2231967312428a904e4","date":1366026608,"type":3,"author":"Martijn van Groningen","isMerge":false,"pathNew":"lucene/grouping/src/java/org/apache/lucene/search/grouping/AbstractFirstPassGroupingCollector#collect(int).mjava","pathOld":"lucene/grouping/src/java/org/apache/lucene/search/grouping/AbstractFirstPassGroupingCollector#collect(int).mjava","sourceNew":"  @Override\n  public void collect(int doc) throws IOException {\n    //System.out.println(\"FP.collect doc=\" + doc);\n\n    // If orderedGroups != null we already have collected N groups and\n    // can short circuit by comparing this document to the bottom group,\n    // without having to find what group this document belongs to.\n    \n    // Even if this document belongs to a group in the top N, we'll know that\n    // we don't have to update that group.\n\n    // Downside: if the number of unique groups is very low, this is\n    // wasted effort as we will most likely be updating an existing group.\n    if (orderedGroups != null) {\n      for (int compIDX = 0;; compIDX++) {\n        final int c = reversed[compIDX] * comparators[compIDX].compareBottom(doc);\n        if (c < 0) {\n          // Definitely not competitive. So don't even bother to continue\n          return;\n        } else if (c > 0) {\n          // Definitely competitive.\n          break;\n        } else if (compIDX == compIDXEnd) {\n          // Here c=0. If we're at the last comparator, this doc is not\n          // competitive, since docs are visited in doc Id order, which means\n          // this doc cannot compete with any other document in the queue.\n          return;\n        }\n      }\n    }\n\n    // TODO: should we add option to mean \"ignore docs that\n    // don't have the group field\" (instead of stuffing them\n    // under null group)?\n    final GROUP_VALUE_TYPE groupValue = getDocGroupValue(doc);\n\n    final CollectedSearchGroup<GROUP_VALUE_TYPE> group = groupMap.get(groupValue);\n\n    if (group == null) {\n\n      // First time we are seeing this group, or, we've seen\n      // it before but it fell out of the top N and is now\n      // coming back\n\n      if (groupMap.size() < topNGroups) {\n\n        // Still in startup transient: we have not\n        // seen enough unique groups to start pruning them;\n        // just keep collecting them\n\n        // Add a new CollectedSearchGroup:\n        CollectedSearchGroup<GROUP_VALUE_TYPE> sg = new CollectedSearchGroup<>();\n        sg.groupValue = copyDocGroupValue(groupValue, null);\n        sg.comparatorSlot = groupMap.size();\n        sg.topDoc = docBase + doc;\n        for (FieldComparator<?> fc : comparators) {\n          fc.copy(sg.comparatorSlot, doc);\n        }\n        groupMap.put(sg.groupValue, sg);\n\n        if (groupMap.size() == topNGroups) {\n          // End of startup transient: we now have max\n          // number of groups; from here on we will drop\n          // bottom group when we insert new one:\n          buildSortedSet();\n        }\n\n        return;\n      }\n\n      // We already tested that the document is competitive, so replace\n      // the bottom group with this new group.\n      final CollectedSearchGroup<GROUP_VALUE_TYPE> bottomGroup = orderedGroups.pollLast();\n      assert orderedGroups.size() == topNGroups -1;\n\n      groupMap.remove(bottomGroup.groupValue);\n\n      // reuse the removed CollectedSearchGroup\n      bottomGroup.groupValue = copyDocGroupValue(groupValue, bottomGroup.groupValue);\n      bottomGroup.topDoc = docBase + doc;\n\n      for (FieldComparator<?> fc : comparators) {\n        fc.copy(bottomGroup.comparatorSlot, doc);\n      }\n\n      groupMap.put(bottomGroup.groupValue, bottomGroup);\n      orderedGroups.add(bottomGroup);\n      assert orderedGroups.size() == topNGroups;\n\n      final int lastComparatorSlot = orderedGroups.last().comparatorSlot;\n      for (FieldComparator<?> fc : comparators) {\n        fc.setBottom(lastComparatorSlot);\n      }\n\n      return;\n    }\n\n    // Update existing group:\n    for (int compIDX = 0;; compIDX++) {\n      final FieldComparator<?> fc = comparators[compIDX];\n      fc.copy(spareSlot, doc);\n\n      final int c = reversed[compIDX] * fc.compare(group.comparatorSlot, spareSlot);\n      if (c < 0) {\n        // Definitely not competitive.\n        return;\n      } else if (c > 0) {\n        // Definitely competitive; set remaining comparators:\n        for (int compIDX2=compIDX+1; compIDX2<comparators.length; compIDX2++) {\n          comparators[compIDX2].copy(spareSlot, doc);\n        }\n        break;\n      } else if (compIDX == compIDXEnd) {\n        // Here c=0. If we're at the last comparator, this doc is not\n        // competitive, since docs are visited in doc Id order, which means\n        // this doc cannot compete with any other document in the queue.\n        return;\n      }\n    }\n\n    // Remove before updating the group since lookup is done via comparators\n    // TODO: optimize this\n\n    final CollectedSearchGroup<GROUP_VALUE_TYPE> prevLast;\n    if (orderedGroups != null) {\n      prevLast = orderedGroups.last();\n      orderedGroups.remove(group);\n      assert orderedGroups.size() == topNGroups-1;\n    } else {\n      prevLast = null;\n    }\n\n    group.topDoc = docBase + doc;\n\n    // Swap slots\n    final int tmp = spareSlot;\n    spareSlot = group.comparatorSlot;\n    group.comparatorSlot = tmp;\n\n    // Re-add the changed group\n    if (orderedGroups != null) {\n      orderedGroups.add(group);\n      assert orderedGroups.size() == topNGroups;\n      final CollectedSearchGroup<?> newLast = orderedGroups.last();\n      // If we changed the value of the last group, or changed which group was last, then update bottom:\n      if (group == newLast || prevLast != newLast) {\n        for (FieldComparator<?> fc : comparators) {\n          fc.setBottom(newLast.comparatorSlot);\n        }\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  public void collect(int doc) throws IOException {\n    //System.out.println(\"FP.collect doc=\" + doc);\n\n    // If orderedGroups != null we already have collected N groups and\n    // can short circuit by comparing this document to the bottom group,\n    // without having to find what group this document belongs to.\n    \n    // Even if this document belongs to a group in the top N, we'll know that\n    // we don't have to update that group.\n\n    // Downside: if the number of unique groups is very low, this is\n    // wasted effort as we will most likely be updating an existing group.\n    if (orderedGroups != null) {\n      for (int compIDX = 0;; compIDX++) {\n        final int c = reversed[compIDX] * comparators[compIDX].compareBottom(doc);\n        if (c < 0) {\n          // Definitely not competitive. So don't even bother to continue\n          return;\n        } else if (c > 0) {\n          // Definitely competitive.\n          break;\n        } else if (compIDX == compIDXEnd) {\n          // Here c=0. If we're at the last comparator, this doc is not\n          // competitive, since docs are visited in doc Id order, which means\n          // this doc cannot compete with any other document in the queue.\n          return;\n        }\n      }\n    }\n\n    // TODO: should we add option to mean \"ignore docs that\n    // don't have the group field\" (instead of stuffing them\n    // under null group)?\n    final GROUP_VALUE_TYPE groupValue = getDocGroupValue(doc);\n\n    final CollectedSearchGroup<GROUP_VALUE_TYPE> group = groupMap.get(groupValue);\n\n    if (group == null) {\n\n      // First time we are seeing this group, or, we've seen\n      // it before but it fell out of the top N and is now\n      // coming back\n\n      if (groupMap.size() < topNGroups) {\n\n        // Still in startup transient: we have not\n        // seen enough unique groups to start pruning them;\n        // just keep collecting them\n\n        // Add a new CollectedSearchGroup:\n        CollectedSearchGroup<GROUP_VALUE_TYPE> sg = new CollectedSearchGroup<GROUP_VALUE_TYPE>();\n        sg.groupValue = copyDocGroupValue(groupValue, null);\n        sg.comparatorSlot = groupMap.size();\n        sg.topDoc = docBase + doc;\n        for (FieldComparator<?> fc : comparators) {\n          fc.copy(sg.comparatorSlot, doc);\n        }\n        groupMap.put(sg.groupValue, sg);\n\n        if (groupMap.size() == topNGroups) {\n          // End of startup transient: we now have max\n          // number of groups; from here on we will drop\n          // bottom group when we insert new one:\n          buildSortedSet();\n        }\n\n        return;\n      }\n\n      // We already tested that the document is competitive, so replace\n      // the bottom group with this new group.\n      final CollectedSearchGroup<GROUP_VALUE_TYPE> bottomGroup = orderedGroups.pollLast();\n      assert orderedGroups.size() == topNGroups -1;\n\n      groupMap.remove(bottomGroup.groupValue);\n\n      // reuse the removed CollectedSearchGroup\n      bottomGroup.groupValue = copyDocGroupValue(groupValue, bottomGroup.groupValue);\n      bottomGroup.topDoc = docBase + doc;\n\n      for (FieldComparator<?> fc : comparators) {\n        fc.copy(bottomGroup.comparatorSlot, doc);\n      }\n\n      groupMap.put(bottomGroup.groupValue, bottomGroup);\n      orderedGroups.add(bottomGroup);\n      assert orderedGroups.size() == topNGroups;\n\n      final int lastComparatorSlot = orderedGroups.last().comparatorSlot;\n      for (FieldComparator<?> fc : comparators) {\n        fc.setBottom(lastComparatorSlot);\n      }\n\n      return;\n    }\n\n    // Update existing group:\n    for (int compIDX = 0;; compIDX++) {\n      final FieldComparator<?> fc = comparators[compIDX];\n      fc.copy(spareSlot, doc);\n\n      final int c = reversed[compIDX] * fc.compare(group.comparatorSlot, spareSlot);\n      if (c < 0) {\n        // Definitely not competitive.\n        return;\n      } else if (c > 0) {\n        // Definitely competitive; set remaining comparators:\n        for (int compIDX2=compIDX+1; compIDX2<comparators.length; compIDX2++) {\n          comparators[compIDX2].copy(spareSlot, doc);\n        }\n        break;\n      } else if (compIDX == compIDXEnd) {\n        // Here c=0. If we're at the last comparator, this doc is not\n        // competitive, since docs are visited in doc Id order, which means\n        // this doc cannot compete with any other document in the queue.\n        return;\n      }\n    }\n\n    // Remove before updating the group since lookup is done via comparators\n    // TODO: optimize this\n\n    final CollectedSearchGroup<GROUP_VALUE_TYPE> prevLast;\n    if (orderedGroups != null) {\n      prevLast = orderedGroups.last();\n      orderedGroups.remove(group);\n      assert orderedGroups.size() == topNGroups-1;\n    } else {\n      prevLast = null;\n    }\n\n    group.topDoc = docBase + doc;\n\n    // Swap slots\n    final int tmp = spareSlot;\n    spareSlot = group.comparatorSlot;\n    group.comparatorSlot = tmp;\n\n    // Re-add the changed group\n    if (orderedGroups != null) {\n      orderedGroups.add(group);\n      assert orderedGroups.size() == topNGroups;\n      final CollectedSearchGroup<?> newLast = orderedGroups.last();\n      // If we changed the value of the last group, or changed which group was last, then update bottom:\n      if (group == newLast || prevLast != newLast) {\n        for (FieldComparator<?> fc : comparators) {\n          fc.setBottom(newLast.comparatorSlot);\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"901e951cec2e6af4e503209a6721c8834db23279","date":1420556599,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/grouping/src/java/org/apache/lucene/search/grouping/AbstractFirstPassGroupingCollector#collect(int).mjava","pathOld":"lucene/grouping/src/java/org/apache/lucene/search/grouping/AbstractFirstPassGroupingCollector#collect(int).mjava","sourceNew":"  @Override\n  public void collect(int doc) throws IOException {\n    //System.out.println(\"FP.collect doc=\" + doc);\n\n    // If orderedGroups != null we already have collected N groups and\n    // can short circuit by comparing this document to the bottom group,\n    // without having to find what group this document belongs to.\n    \n    // Even if this document belongs to a group in the top N, we'll know that\n    // we don't have to update that group.\n\n    // Downside: if the number of unique groups is very low, this is\n    // wasted effort as we will most likely be updating an existing group.\n    if (orderedGroups != null) {\n      for (int compIDX = 0;; compIDX++) {\n        final int c = reversed[compIDX] * leafComparators[compIDX].compareBottom(doc);\n        if (c < 0) {\n          // Definitely not competitive. So don't even bother to continue\n          return;\n        } else if (c > 0) {\n          // Definitely competitive.\n          break;\n        } else if (compIDX == compIDXEnd) {\n          // Here c=0. If we're at the last comparator, this doc is not\n          // competitive, since docs are visited in doc Id order, which means\n          // this doc cannot compete with any other document in the queue.\n          return;\n        }\n      }\n    }\n\n    // TODO: should we add option to mean \"ignore docs that\n    // don't have the group field\" (instead of stuffing them\n    // under null group)?\n    final GROUP_VALUE_TYPE groupValue = getDocGroupValue(doc);\n\n    final CollectedSearchGroup<GROUP_VALUE_TYPE> group = groupMap.get(groupValue);\n\n    if (group == null) {\n\n      // First time we are seeing this group, or, we've seen\n      // it before but it fell out of the top N and is now\n      // coming back\n\n      if (groupMap.size() < topNGroups) {\n\n        // Still in startup transient: we have not\n        // seen enough unique groups to start pruning them;\n        // just keep collecting them\n\n        // Add a new CollectedSearchGroup:\n        CollectedSearchGroup<GROUP_VALUE_TYPE> sg = new CollectedSearchGroup<>();\n        sg.groupValue = copyDocGroupValue(groupValue, null);\n        sg.comparatorSlot = groupMap.size();\n        sg.topDoc = docBase + doc;\n        for (LeafFieldComparator fc : leafComparators) {\n          fc.copy(sg.comparatorSlot, doc);\n        }\n        groupMap.put(sg.groupValue, sg);\n\n        if (groupMap.size() == topNGroups) {\n          // End of startup transient: we now have max\n          // number of groups; from here on we will drop\n          // bottom group when we insert new one:\n          buildSortedSet();\n        }\n\n        return;\n      }\n\n      // We already tested that the document is competitive, so replace\n      // the bottom group with this new group.\n      final CollectedSearchGroup<GROUP_VALUE_TYPE> bottomGroup = orderedGroups.pollLast();\n      assert orderedGroups.size() == topNGroups -1;\n\n      groupMap.remove(bottomGroup.groupValue);\n\n      // reuse the removed CollectedSearchGroup\n      bottomGroup.groupValue = copyDocGroupValue(groupValue, bottomGroup.groupValue);\n      bottomGroup.topDoc = docBase + doc;\n\n      for (LeafFieldComparator fc : leafComparators) {\n        fc.copy(bottomGroup.comparatorSlot, doc);\n      }\n\n      groupMap.put(bottomGroup.groupValue, bottomGroup);\n      orderedGroups.add(bottomGroup);\n      assert orderedGroups.size() == topNGroups;\n\n      final int lastComparatorSlot = orderedGroups.last().comparatorSlot;\n      for (LeafFieldComparator fc : leafComparators) {\n        fc.setBottom(lastComparatorSlot);\n      }\n\n      return;\n    }\n\n    // Update existing group:\n    for (int compIDX = 0;; compIDX++) {\n      leafComparators[compIDX].copy(spareSlot, doc);\n\n      final int c = reversed[compIDX] * comparators[compIDX].compare(group.comparatorSlot, spareSlot);\n      if (c < 0) {\n        // Definitely not competitive.\n        return;\n      } else if (c > 0) {\n        // Definitely competitive; set remaining comparators:\n        for (int compIDX2=compIDX+1; compIDX2<comparators.length; compIDX2++) {\n          leafComparators[compIDX2].copy(spareSlot, doc);\n        }\n        break;\n      } else if (compIDX == compIDXEnd) {\n        // Here c=0. If we're at the last comparator, this doc is not\n        // competitive, since docs are visited in doc Id order, which means\n        // this doc cannot compete with any other document in the queue.\n        return;\n      }\n    }\n\n    // Remove before updating the group since lookup is done via comparators\n    // TODO: optimize this\n\n    final CollectedSearchGroup<GROUP_VALUE_TYPE> prevLast;\n    if (orderedGroups != null) {\n      prevLast = orderedGroups.last();\n      orderedGroups.remove(group);\n      assert orderedGroups.size() == topNGroups-1;\n    } else {\n      prevLast = null;\n    }\n\n    group.topDoc = docBase + doc;\n\n    // Swap slots\n    final int tmp = spareSlot;\n    spareSlot = group.comparatorSlot;\n    group.comparatorSlot = tmp;\n\n    // Re-add the changed group\n    if (orderedGroups != null) {\n      orderedGroups.add(group);\n      assert orderedGroups.size() == topNGroups;\n      final CollectedSearchGroup<?> newLast = orderedGroups.last();\n      // If we changed the value of the last group, or changed which group was last, then update bottom:\n      if (group == newLast || prevLast != newLast) {\n        for (LeafFieldComparator fc : leafComparators) {\n          fc.setBottom(newLast.comparatorSlot);\n        }\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  public void collect(int doc) throws IOException {\n    //System.out.println(\"FP.collect doc=\" + doc);\n\n    // If orderedGroups != null we already have collected N groups and\n    // can short circuit by comparing this document to the bottom group,\n    // without having to find what group this document belongs to.\n    \n    // Even if this document belongs to a group in the top N, we'll know that\n    // we don't have to update that group.\n\n    // Downside: if the number of unique groups is very low, this is\n    // wasted effort as we will most likely be updating an existing group.\n    if (orderedGroups != null) {\n      for (int compIDX = 0;; compIDX++) {\n        final int c = reversed[compIDX] * comparators[compIDX].compareBottom(doc);\n        if (c < 0) {\n          // Definitely not competitive. So don't even bother to continue\n          return;\n        } else if (c > 0) {\n          // Definitely competitive.\n          break;\n        } else if (compIDX == compIDXEnd) {\n          // Here c=0. If we're at the last comparator, this doc is not\n          // competitive, since docs are visited in doc Id order, which means\n          // this doc cannot compete with any other document in the queue.\n          return;\n        }\n      }\n    }\n\n    // TODO: should we add option to mean \"ignore docs that\n    // don't have the group field\" (instead of stuffing them\n    // under null group)?\n    final GROUP_VALUE_TYPE groupValue = getDocGroupValue(doc);\n\n    final CollectedSearchGroup<GROUP_VALUE_TYPE> group = groupMap.get(groupValue);\n\n    if (group == null) {\n\n      // First time we are seeing this group, or, we've seen\n      // it before but it fell out of the top N and is now\n      // coming back\n\n      if (groupMap.size() < topNGroups) {\n\n        // Still in startup transient: we have not\n        // seen enough unique groups to start pruning them;\n        // just keep collecting them\n\n        // Add a new CollectedSearchGroup:\n        CollectedSearchGroup<GROUP_VALUE_TYPE> sg = new CollectedSearchGroup<>();\n        sg.groupValue = copyDocGroupValue(groupValue, null);\n        sg.comparatorSlot = groupMap.size();\n        sg.topDoc = docBase + doc;\n        for (FieldComparator<?> fc : comparators) {\n          fc.copy(sg.comparatorSlot, doc);\n        }\n        groupMap.put(sg.groupValue, sg);\n\n        if (groupMap.size() == topNGroups) {\n          // End of startup transient: we now have max\n          // number of groups; from here on we will drop\n          // bottom group when we insert new one:\n          buildSortedSet();\n        }\n\n        return;\n      }\n\n      // We already tested that the document is competitive, so replace\n      // the bottom group with this new group.\n      final CollectedSearchGroup<GROUP_VALUE_TYPE> bottomGroup = orderedGroups.pollLast();\n      assert orderedGroups.size() == topNGroups -1;\n\n      groupMap.remove(bottomGroup.groupValue);\n\n      // reuse the removed CollectedSearchGroup\n      bottomGroup.groupValue = copyDocGroupValue(groupValue, bottomGroup.groupValue);\n      bottomGroup.topDoc = docBase + doc;\n\n      for (FieldComparator<?> fc : comparators) {\n        fc.copy(bottomGroup.comparatorSlot, doc);\n      }\n\n      groupMap.put(bottomGroup.groupValue, bottomGroup);\n      orderedGroups.add(bottomGroup);\n      assert orderedGroups.size() == topNGroups;\n\n      final int lastComparatorSlot = orderedGroups.last().comparatorSlot;\n      for (FieldComparator<?> fc : comparators) {\n        fc.setBottom(lastComparatorSlot);\n      }\n\n      return;\n    }\n\n    // Update existing group:\n    for (int compIDX = 0;; compIDX++) {\n      final FieldComparator<?> fc = comparators[compIDX];\n      fc.copy(spareSlot, doc);\n\n      final int c = reversed[compIDX] * fc.compare(group.comparatorSlot, spareSlot);\n      if (c < 0) {\n        // Definitely not competitive.\n        return;\n      } else if (c > 0) {\n        // Definitely competitive; set remaining comparators:\n        for (int compIDX2=compIDX+1; compIDX2<comparators.length; compIDX2++) {\n          comparators[compIDX2].copy(spareSlot, doc);\n        }\n        break;\n      } else if (compIDX == compIDXEnd) {\n        // Here c=0. If we're at the last comparator, this doc is not\n        // competitive, since docs are visited in doc Id order, which means\n        // this doc cannot compete with any other document in the queue.\n        return;\n      }\n    }\n\n    // Remove before updating the group since lookup is done via comparators\n    // TODO: optimize this\n\n    final CollectedSearchGroup<GROUP_VALUE_TYPE> prevLast;\n    if (orderedGroups != null) {\n      prevLast = orderedGroups.last();\n      orderedGroups.remove(group);\n      assert orderedGroups.size() == topNGroups-1;\n    } else {\n      prevLast = null;\n    }\n\n    group.topDoc = docBase + doc;\n\n    // Swap slots\n    final int tmp = spareSlot;\n    spareSlot = group.comparatorSlot;\n    group.comparatorSlot = tmp;\n\n    // Re-add the changed group\n    if (orderedGroups != null) {\n      orderedGroups.add(group);\n      assert orderedGroups.size() == topNGroups;\n      final CollectedSearchGroup<?> newLast = orderedGroups.last();\n      // If we changed the value of the last group, or changed which group was last, then update bottom:\n      if (group == newLast || prevLast != newLast) {\n        for (FieldComparator<?> fc : comparators) {\n          fc.setBottom(newLast.comparatorSlot);\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"20e94e61fe5291647346b70437617e6b6c370408","date":1483783127,"type":5,"author":"Alan Woodward","isMerge":false,"pathNew":"lucene/grouping/src/java/org/apache/lucene/search/grouping/FirstPassGroupingCollector#collect(int).mjava","pathOld":"lucene/grouping/src/java/org/apache/lucene/search/grouping/AbstractFirstPassGroupingCollector#collect(int).mjava","sourceNew":"  @Override\n  public void collect(int doc) throws IOException {\n    //System.out.println(\"FP.collect doc=\" + doc);\n\n    // If orderedGroups != null we already have collected N groups and\n    // can short circuit by comparing this document to the bottom group,\n    // without having to find what group this document belongs to.\n    \n    // Even if this document belongs to a group in the top N, we'll know that\n    // we don't have to update that group.\n\n    // Downside: if the number of unique groups is very low, this is\n    // wasted effort as we will most likely be updating an existing group.\n    if (orderedGroups != null) {\n      for (int compIDX = 0;; compIDX++) {\n        final int c = reversed[compIDX] * leafComparators[compIDX].compareBottom(doc);\n        if (c < 0) {\n          // Definitely not competitive. So don't even bother to continue\n          return;\n        } else if (c > 0) {\n          // Definitely competitive.\n          break;\n        } else if (compIDX == compIDXEnd) {\n          // Here c=0. If we're at the last comparator, this doc is not\n          // competitive, since docs are visited in doc Id order, which means\n          // this doc cannot compete with any other document in the queue.\n          return;\n        }\n      }\n    }\n\n    // TODO: should we add option to mean \"ignore docs that\n    // don't have the group field\" (instead of stuffing them\n    // under null group)?\n    final T groupValue = getDocGroupValue(doc);\n\n    final CollectedSearchGroup<T> group = groupMap.get(groupValue);\n\n    if (group == null) {\n\n      // First time we are seeing this group, or, we've seen\n      // it before but it fell out of the top N and is now\n      // coming back\n\n      if (groupMap.size() < topNGroups) {\n\n        // Still in startup transient: we have not\n        // seen enough unique groups to start pruning them;\n        // just keep collecting them\n\n        // Add a new CollectedSearchGroup:\n        CollectedSearchGroup<T> sg = new CollectedSearchGroup<>();\n        sg.groupValue = copyDocGroupValue(groupValue, null);\n        sg.comparatorSlot = groupMap.size();\n        sg.topDoc = docBase + doc;\n        for (LeafFieldComparator fc : leafComparators) {\n          fc.copy(sg.comparatorSlot, doc);\n        }\n        groupMap.put(sg.groupValue, sg);\n\n        if (groupMap.size() == topNGroups) {\n          // End of startup transient: we now have max\n          // number of groups; from here on we will drop\n          // bottom group when we insert new one:\n          buildSortedSet();\n        }\n\n        return;\n      }\n\n      // We already tested that the document is competitive, so replace\n      // the bottom group with this new group.\n      final CollectedSearchGroup<T> bottomGroup = orderedGroups.pollLast();\n      assert orderedGroups.size() == topNGroups -1;\n\n      groupMap.remove(bottomGroup.groupValue);\n\n      // reuse the removed CollectedSearchGroup\n      bottomGroup.groupValue = copyDocGroupValue(groupValue, bottomGroup.groupValue);\n      bottomGroup.topDoc = docBase + doc;\n\n      for (LeafFieldComparator fc : leafComparators) {\n        fc.copy(bottomGroup.comparatorSlot, doc);\n      }\n\n      groupMap.put(bottomGroup.groupValue, bottomGroup);\n      orderedGroups.add(bottomGroup);\n      assert orderedGroups.size() == topNGroups;\n\n      final int lastComparatorSlot = orderedGroups.last().comparatorSlot;\n      for (LeafFieldComparator fc : leafComparators) {\n        fc.setBottom(lastComparatorSlot);\n      }\n\n      return;\n    }\n\n    // Update existing group:\n    for (int compIDX = 0;; compIDX++) {\n      leafComparators[compIDX].copy(spareSlot, doc);\n\n      final int c = reversed[compIDX] * comparators[compIDX].compare(group.comparatorSlot, spareSlot);\n      if (c < 0) {\n        // Definitely not competitive.\n        return;\n      } else if (c > 0) {\n        // Definitely competitive; set remaining comparators:\n        for (int compIDX2=compIDX+1; compIDX2<comparators.length; compIDX2++) {\n          leafComparators[compIDX2].copy(spareSlot, doc);\n        }\n        break;\n      } else if (compIDX == compIDXEnd) {\n        // Here c=0. If we're at the last comparator, this doc is not\n        // competitive, since docs are visited in doc Id order, which means\n        // this doc cannot compete with any other document in the queue.\n        return;\n      }\n    }\n\n    // Remove before updating the group since lookup is done via comparators\n    // TODO: optimize this\n\n    final CollectedSearchGroup<T> prevLast;\n    if (orderedGroups != null) {\n      prevLast = orderedGroups.last();\n      orderedGroups.remove(group);\n      assert orderedGroups.size() == topNGroups-1;\n    } else {\n      prevLast = null;\n    }\n\n    group.topDoc = docBase + doc;\n\n    // Swap slots\n    final int tmp = spareSlot;\n    spareSlot = group.comparatorSlot;\n    group.comparatorSlot = tmp;\n\n    // Re-add the changed group\n    if (orderedGroups != null) {\n      orderedGroups.add(group);\n      assert orderedGroups.size() == topNGroups;\n      final CollectedSearchGroup<?> newLast = orderedGroups.last();\n      // If we changed the value of the last group, or changed which group was last, then update bottom:\n      if (group == newLast || prevLast != newLast) {\n        for (LeafFieldComparator fc : leafComparators) {\n          fc.setBottom(newLast.comparatorSlot);\n        }\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  public void collect(int doc) throws IOException {\n    //System.out.println(\"FP.collect doc=\" + doc);\n\n    // If orderedGroups != null we already have collected N groups and\n    // can short circuit by comparing this document to the bottom group,\n    // without having to find what group this document belongs to.\n    \n    // Even if this document belongs to a group in the top N, we'll know that\n    // we don't have to update that group.\n\n    // Downside: if the number of unique groups is very low, this is\n    // wasted effort as we will most likely be updating an existing group.\n    if (orderedGroups != null) {\n      for (int compIDX = 0;; compIDX++) {\n        final int c = reversed[compIDX] * leafComparators[compIDX].compareBottom(doc);\n        if (c < 0) {\n          // Definitely not competitive. So don't even bother to continue\n          return;\n        } else if (c > 0) {\n          // Definitely competitive.\n          break;\n        } else if (compIDX == compIDXEnd) {\n          // Here c=0. If we're at the last comparator, this doc is not\n          // competitive, since docs are visited in doc Id order, which means\n          // this doc cannot compete with any other document in the queue.\n          return;\n        }\n      }\n    }\n\n    // TODO: should we add option to mean \"ignore docs that\n    // don't have the group field\" (instead of stuffing them\n    // under null group)?\n    final GROUP_VALUE_TYPE groupValue = getDocGroupValue(doc);\n\n    final CollectedSearchGroup<GROUP_VALUE_TYPE> group = groupMap.get(groupValue);\n\n    if (group == null) {\n\n      // First time we are seeing this group, or, we've seen\n      // it before but it fell out of the top N and is now\n      // coming back\n\n      if (groupMap.size() < topNGroups) {\n\n        // Still in startup transient: we have not\n        // seen enough unique groups to start pruning them;\n        // just keep collecting them\n\n        // Add a new CollectedSearchGroup:\n        CollectedSearchGroup<GROUP_VALUE_TYPE> sg = new CollectedSearchGroup<>();\n        sg.groupValue = copyDocGroupValue(groupValue, null);\n        sg.comparatorSlot = groupMap.size();\n        sg.topDoc = docBase + doc;\n        for (LeafFieldComparator fc : leafComparators) {\n          fc.copy(sg.comparatorSlot, doc);\n        }\n        groupMap.put(sg.groupValue, sg);\n\n        if (groupMap.size() == topNGroups) {\n          // End of startup transient: we now have max\n          // number of groups; from here on we will drop\n          // bottom group when we insert new one:\n          buildSortedSet();\n        }\n\n        return;\n      }\n\n      // We already tested that the document is competitive, so replace\n      // the bottom group with this new group.\n      final CollectedSearchGroup<GROUP_VALUE_TYPE> bottomGroup = orderedGroups.pollLast();\n      assert orderedGroups.size() == topNGroups -1;\n\n      groupMap.remove(bottomGroup.groupValue);\n\n      // reuse the removed CollectedSearchGroup\n      bottomGroup.groupValue = copyDocGroupValue(groupValue, bottomGroup.groupValue);\n      bottomGroup.topDoc = docBase + doc;\n\n      for (LeafFieldComparator fc : leafComparators) {\n        fc.copy(bottomGroup.comparatorSlot, doc);\n      }\n\n      groupMap.put(bottomGroup.groupValue, bottomGroup);\n      orderedGroups.add(bottomGroup);\n      assert orderedGroups.size() == topNGroups;\n\n      final int lastComparatorSlot = orderedGroups.last().comparatorSlot;\n      for (LeafFieldComparator fc : leafComparators) {\n        fc.setBottom(lastComparatorSlot);\n      }\n\n      return;\n    }\n\n    // Update existing group:\n    for (int compIDX = 0;; compIDX++) {\n      leafComparators[compIDX].copy(spareSlot, doc);\n\n      final int c = reversed[compIDX] * comparators[compIDX].compare(group.comparatorSlot, spareSlot);\n      if (c < 0) {\n        // Definitely not competitive.\n        return;\n      } else if (c > 0) {\n        // Definitely competitive; set remaining comparators:\n        for (int compIDX2=compIDX+1; compIDX2<comparators.length; compIDX2++) {\n          leafComparators[compIDX2].copy(spareSlot, doc);\n        }\n        break;\n      } else if (compIDX == compIDXEnd) {\n        // Here c=0. If we're at the last comparator, this doc is not\n        // competitive, since docs are visited in doc Id order, which means\n        // this doc cannot compete with any other document in the queue.\n        return;\n      }\n    }\n\n    // Remove before updating the group since lookup is done via comparators\n    // TODO: optimize this\n\n    final CollectedSearchGroup<GROUP_VALUE_TYPE> prevLast;\n    if (orderedGroups != null) {\n      prevLast = orderedGroups.last();\n      orderedGroups.remove(group);\n      assert orderedGroups.size() == topNGroups-1;\n    } else {\n      prevLast = null;\n    }\n\n    group.topDoc = docBase + doc;\n\n    // Swap slots\n    final int tmp = spareSlot;\n    spareSlot = group.comparatorSlot;\n    group.comparatorSlot = tmp;\n\n    // Re-add the changed group\n    if (orderedGroups != null) {\n      orderedGroups.add(group);\n      assert orderedGroups.size() == topNGroups;\n      final CollectedSearchGroup<?> newLast = orderedGroups.last();\n      // If we changed the value of the last group, or changed which group was last, then update bottom:\n      if (group == newLast || prevLast != newLast) {\n        for (LeafFieldComparator fc : leafComparators) {\n          fc.setBottom(newLast.comparatorSlot);\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"09ab8ee44ca898536770d0106a7c0ee4be4f0eb7","date":1484239864,"type":5,"author":"Kevin Risden","isMerge":true,"pathNew":"lucene/grouping/src/java/org/apache/lucene/search/grouping/FirstPassGroupingCollector#collect(int).mjava","pathOld":"lucene/grouping/src/java/org/apache/lucene/search/grouping/AbstractFirstPassGroupingCollector#collect(int).mjava","sourceNew":"  @Override\n  public void collect(int doc) throws IOException {\n    //System.out.println(\"FP.collect doc=\" + doc);\n\n    // If orderedGroups != null we already have collected N groups and\n    // can short circuit by comparing this document to the bottom group,\n    // without having to find what group this document belongs to.\n    \n    // Even if this document belongs to a group in the top N, we'll know that\n    // we don't have to update that group.\n\n    // Downside: if the number of unique groups is very low, this is\n    // wasted effort as we will most likely be updating an existing group.\n    if (orderedGroups != null) {\n      for (int compIDX = 0;; compIDX++) {\n        final int c = reversed[compIDX] * leafComparators[compIDX].compareBottom(doc);\n        if (c < 0) {\n          // Definitely not competitive. So don't even bother to continue\n          return;\n        } else if (c > 0) {\n          // Definitely competitive.\n          break;\n        } else if (compIDX == compIDXEnd) {\n          // Here c=0. If we're at the last comparator, this doc is not\n          // competitive, since docs are visited in doc Id order, which means\n          // this doc cannot compete with any other document in the queue.\n          return;\n        }\n      }\n    }\n\n    // TODO: should we add option to mean \"ignore docs that\n    // don't have the group field\" (instead of stuffing them\n    // under null group)?\n    final T groupValue = getDocGroupValue(doc);\n\n    final CollectedSearchGroup<T> group = groupMap.get(groupValue);\n\n    if (group == null) {\n\n      // First time we are seeing this group, or, we've seen\n      // it before but it fell out of the top N and is now\n      // coming back\n\n      if (groupMap.size() < topNGroups) {\n\n        // Still in startup transient: we have not\n        // seen enough unique groups to start pruning them;\n        // just keep collecting them\n\n        // Add a new CollectedSearchGroup:\n        CollectedSearchGroup<T> sg = new CollectedSearchGroup<>();\n        sg.groupValue = copyDocGroupValue(groupValue, null);\n        sg.comparatorSlot = groupMap.size();\n        sg.topDoc = docBase + doc;\n        for (LeafFieldComparator fc : leafComparators) {\n          fc.copy(sg.comparatorSlot, doc);\n        }\n        groupMap.put(sg.groupValue, sg);\n\n        if (groupMap.size() == topNGroups) {\n          // End of startup transient: we now have max\n          // number of groups; from here on we will drop\n          // bottom group when we insert new one:\n          buildSortedSet();\n        }\n\n        return;\n      }\n\n      // We already tested that the document is competitive, so replace\n      // the bottom group with this new group.\n      final CollectedSearchGroup<T> bottomGroup = orderedGroups.pollLast();\n      assert orderedGroups.size() == topNGroups -1;\n\n      groupMap.remove(bottomGroup.groupValue);\n\n      // reuse the removed CollectedSearchGroup\n      bottomGroup.groupValue = copyDocGroupValue(groupValue, bottomGroup.groupValue);\n      bottomGroup.topDoc = docBase + doc;\n\n      for (LeafFieldComparator fc : leafComparators) {\n        fc.copy(bottomGroup.comparatorSlot, doc);\n      }\n\n      groupMap.put(bottomGroup.groupValue, bottomGroup);\n      orderedGroups.add(bottomGroup);\n      assert orderedGroups.size() == topNGroups;\n\n      final int lastComparatorSlot = orderedGroups.last().comparatorSlot;\n      for (LeafFieldComparator fc : leafComparators) {\n        fc.setBottom(lastComparatorSlot);\n      }\n\n      return;\n    }\n\n    // Update existing group:\n    for (int compIDX = 0;; compIDX++) {\n      leafComparators[compIDX].copy(spareSlot, doc);\n\n      final int c = reversed[compIDX] * comparators[compIDX].compare(group.comparatorSlot, spareSlot);\n      if (c < 0) {\n        // Definitely not competitive.\n        return;\n      } else if (c > 0) {\n        // Definitely competitive; set remaining comparators:\n        for (int compIDX2=compIDX+1; compIDX2<comparators.length; compIDX2++) {\n          leafComparators[compIDX2].copy(spareSlot, doc);\n        }\n        break;\n      } else if (compIDX == compIDXEnd) {\n        // Here c=0. If we're at the last comparator, this doc is not\n        // competitive, since docs are visited in doc Id order, which means\n        // this doc cannot compete with any other document in the queue.\n        return;\n      }\n    }\n\n    // Remove before updating the group since lookup is done via comparators\n    // TODO: optimize this\n\n    final CollectedSearchGroup<T> prevLast;\n    if (orderedGroups != null) {\n      prevLast = orderedGroups.last();\n      orderedGroups.remove(group);\n      assert orderedGroups.size() == topNGroups-1;\n    } else {\n      prevLast = null;\n    }\n\n    group.topDoc = docBase + doc;\n\n    // Swap slots\n    final int tmp = spareSlot;\n    spareSlot = group.comparatorSlot;\n    group.comparatorSlot = tmp;\n\n    // Re-add the changed group\n    if (orderedGroups != null) {\n      orderedGroups.add(group);\n      assert orderedGroups.size() == topNGroups;\n      final CollectedSearchGroup<?> newLast = orderedGroups.last();\n      // If we changed the value of the last group, or changed which group was last, then update bottom:\n      if (group == newLast || prevLast != newLast) {\n        for (LeafFieldComparator fc : leafComparators) {\n          fc.setBottom(newLast.comparatorSlot);\n        }\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  public void collect(int doc) throws IOException {\n    //System.out.println(\"FP.collect doc=\" + doc);\n\n    // If orderedGroups != null we already have collected N groups and\n    // can short circuit by comparing this document to the bottom group,\n    // without having to find what group this document belongs to.\n    \n    // Even if this document belongs to a group in the top N, we'll know that\n    // we don't have to update that group.\n\n    // Downside: if the number of unique groups is very low, this is\n    // wasted effort as we will most likely be updating an existing group.\n    if (orderedGroups != null) {\n      for (int compIDX = 0;; compIDX++) {\n        final int c = reversed[compIDX] * leafComparators[compIDX].compareBottom(doc);\n        if (c < 0) {\n          // Definitely not competitive. So don't even bother to continue\n          return;\n        } else if (c > 0) {\n          // Definitely competitive.\n          break;\n        } else if (compIDX == compIDXEnd) {\n          // Here c=0. If we're at the last comparator, this doc is not\n          // competitive, since docs are visited in doc Id order, which means\n          // this doc cannot compete with any other document in the queue.\n          return;\n        }\n      }\n    }\n\n    // TODO: should we add option to mean \"ignore docs that\n    // don't have the group field\" (instead of stuffing them\n    // under null group)?\n    final GROUP_VALUE_TYPE groupValue = getDocGroupValue(doc);\n\n    final CollectedSearchGroup<GROUP_VALUE_TYPE> group = groupMap.get(groupValue);\n\n    if (group == null) {\n\n      // First time we are seeing this group, or, we've seen\n      // it before but it fell out of the top N and is now\n      // coming back\n\n      if (groupMap.size() < topNGroups) {\n\n        // Still in startup transient: we have not\n        // seen enough unique groups to start pruning them;\n        // just keep collecting them\n\n        // Add a new CollectedSearchGroup:\n        CollectedSearchGroup<GROUP_VALUE_TYPE> sg = new CollectedSearchGroup<>();\n        sg.groupValue = copyDocGroupValue(groupValue, null);\n        sg.comparatorSlot = groupMap.size();\n        sg.topDoc = docBase + doc;\n        for (LeafFieldComparator fc : leafComparators) {\n          fc.copy(sg.comparatorSlot, doc);\n        }\n        groupMap.put(sg.groupValue, sg);\n\n        if (groupMap.size() == topNGroups) {\n          // End of startup transient: we now have max\n          // number of groups; from here on we will drop\n          // bottom group when we insert new one:\n          buildSortedSet();\n        }\n\n        return;\n      }\n\n      // We already tested that the document is competitive, so replace\n      // the bottom group with this new group.\n      final CollectedSearchGroup<GROUP_VALUE_TYPE> bottomGroup = orderedGroups.pollLast();\n      assert orderedGroups.size() == topNGroups -1;\n\n      groupMap.remove(bottomGroup.groupValue);\n\n      // reuse the removed CollectedSearchGroup\n      bottomGroup.groupValue = copyDocGroupValue(groupValue, bottomGroup.groupValue);\n      bottomGroup.topDoc = docBase + doc;\n\n      for (LeafFieldComparator fc : leafComparators) {\n        fc.copy(bottomGroup.comparatorSlot, doc);\n      }\n\n      groupMap.put(bottomGroup.groupValue, bottomGroup);\n      orderedGroups.add(bottomGroup);\n      assert orderedGroups.size() == topNGroups;\n\n      final int lastComparatorSlot = orderedGroups.last().comparatorSlot;\n      for (LeafFieldComparator fc : leafComparators) {\n        fc.setBottom(lastComparatorSlot);\n      }\n\n      return;\n    }\n\n    // Update existing group:\n    for (int compIDX = 0;; compIDX++) {\n      leafComparators[compIDX].copy(spareSlot, doc);\n\n      final int c = reversed[compIDX] * comparators[compIDX].compare(group.comparatorSlot, spareSlot);\n      if (c < 0) {\n        // Definitely not competitive.\n        return;\n      } else if (c > 0) {\n        // Definitely competitive; set remaining comparators:\n        for (int compIDX2=compIDX+1; compIDX2<comparators.length; compIDX2++) {\n          leafComparators[compIDX2].copy(spareSlot, doc);\n        }\n        break;\n      } else if (compIDX == compIDXEnd) {\n        // Here c=0. If we're at the last comparator, this doc is not\n        // competitive, since docs are visited in doc Id order, which means\n        // this doc cannot compete with any other document in the queue.\n        return;\n      }\n    }\n\n    // Remove before updating the group since lookup is done via comparators\n    // TODO: optimize this\n\n    final CollectedSearchGroup<GROUP_VALUE_TYPE> prevLast;\n    if (orderedGroups != null) {\n      prevLast = orderedGroups.last();\n      orderedGroups.remove(group);\n      assert orderedGroups.size() == topNGroups-1;\n    } else {\n      prevLast = null;\n    }\n\n    group.topDoc = docBase + doc;\n\n    // Swap slots\n    final int tmp = spareSlot;\n    spareSlot = group.comparatorSlot;\n    group.comparatorSlot = tmp;\n\n    // Re-add the changed group\n    if (orderedGroups != null) {\n      orderedGroups.add(group);\n      assert orderedGroups.size() == topNGroups;\n      final CollectedSearchGroup<?> newLast = orderedGroups.last();\n      // If we changed the value of the last group, or changed which group was last, then update bottom:\n      if (group == newLast || prevLast != newLast) {\n        for (LeafFieldComparator fc : leafComparators) {\n          fc.setBottom(newLast.comparatorSlot);\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"b89678825b68eccaf09e6ab71675fc0b0af1e099":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"20e94e61fe5291647346b70437617e6b6c370408":["901e951cec2e6af4e503209a6721c8834db23279"],"97d4692d0c601ff773f0a2231967312428a904e4":["b89678825b68eccaf09e6ab71675fc0b0af1e099"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"901e951cec2e6af4e503209a6721c8834db23279":["97d4692d0c601ff773f0a2231967312428a904e4"],"09ab8ee44ca898536770d0106a7c0ee4be4f0eb7":["901e951cec2e6af4e503209a6721c8834db23279","20e94e61fe5291647346b70437617e6b6c370408"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["20e94e61fe5291647346b70437617e6b6c370408"]},"commit2Childs":{"b89678825b68eccaf09e6ab71675fc0b0af1e099":["97d4692d0c601ff773f0a2231967312428a904e4"],"20e94e61fe5291647346b70437617e6b6c370408":["09ab8ee44ca898536770d0106a7c0ee4be4f0eb7","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["b89678825b68eccaf09e6ab71675fc0b0af1e099"],"97d4692d0c601ff773f0a2231967312428a904e4":["901e951cec2e6af4e503209a6721c8834db23279"],"901e951cec2e6af4e503209a6721c8834db23279":["20e94e61fe5291647346b70437617e6b6c370408","09ab8ee44ca898536770d0106a7c0ee4be4f0eb7"],"09ab8ee44ca898536770d0106a7c0ee4be4f0eb7":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["09ab8ee44ca898536770d0106a7c0ee4be4f0eb7","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}