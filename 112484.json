{"path":"src/java/org/apache/lucene/index/CompoundFileWriter#close().mjava","commits":[{"id":"8fb95844e4ba5160067c64c5eb1cd8a09f7a94f1","date":1064527311,"type":0,"author":"Dmitry Serebrennikov","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/CompoundFileWriter#close().mjava","pathOld":"/dev/null","sourceNew":"    /** Merge files with the extensions added up to now.\n     *  All files with these extensions are combined sequentially into the \n     *  compound stream. After successful merge, the source files\n     *  are deleted.\n     */    \n    public void close() throws IOException {\n        if (merged)\n            throw new IllegalStateException(\n                \"Merge already performed\");\n            \n        if (entries.isEmpty())\n            throw new IllegalStateException(\n                \"No entries to merge have been defined\");\n            \n        merged = true;\n        \n        // open the compound stream\n        OutputStream os = null;\n        try {\n            os = directory.createFile(fileName);\n        \n            // Write the number of entries\n            os.writeVInt(entries.size());\n        \n            // Write the directory with all offsets at 0.\n            // Remember the positions of directory entries so that we can\n            // adjust the offsets later\n            Iterator it = entries.iterator();\n            while(it.hasNext()) {\n                FileEntry fe = (FileEntry) it.next();\n                fe.directoryOffset = os.getFilePointer();\n                os.writeLong(0);    // for now\n                os.writeString(fe.file);\n            }\n            \n            // Open the files and copy their data into the stream.\n            // Remeber the locations of each file's data section.\n            byte buffer[] = new byte[1024];\n            it = entries.iterator();\n            while(it.hasNext()) {\n                FileEntry fe = (FileEntry) it.next();\n                fe.dataOffset = os.getFilePointer();                \n                copyFile(fe, os, buffer);\n            }\n            \n            // Write the data offsets into the directory of the compound stream\n            it = entries.iterator();\n            while(it.hasNext()) {\n                FileEntry fe = (FileEntry) it.next();\n                os.seek(fe.directoryOffset);\n                os.writeLong(fe.dataOffset);\n            }\n            \n            // Close the output stream. Set the os to null before trying to\n            // close so that if an exception occurs during the close, the \n            // finally clause below will not attempt to close the stream\n            // the second time.\n            OutputStream tmp = os;\n            os = null;\n            tmp.close();\n            \n        } finally {\n            if (os != null) try { os.close(); } catch (IOException e) { }\n        }\n    }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["462dfb1d8690f192817503773f5b8b94a702246a"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"a67f534c1db9eb255bc5a5137c7bf362ff90c276","date":1066054684,"type":3,"author":"Otis Gospodnetic","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/CompoundFileWriter#close().mjava","pathOld":"src/java/org/apache/lucene/index/CompoundFileWriter#close().mjava","sourceNew":"    /** Merge files with the extensions added up to now.\n     *  All files with these extensions are combined sequentially into the\n     *  compound stream. After successful merge, the source files\n     *  are deleted.\n     */\n    public void close() throws IOException {\n        if (merged)\n            throw new IllegalStateException(\n                \"Merge already performed\");\n\n        if (entries.isEmpty())\n            throw new IllegalStateException(\n                \"No entries to merge have been defined\");\n\n        merged = true;\n\n        // open the compound stream\n        OutputStream os = null;\n        try {\n            os = directory.createFile(fileName);\n\n            // Write the number of entries\n            os.writeVInt(entries.size());\n\n            // Write the directory with all offsets at 0.\n            // Remember the positions of directory entries so that we can\n            // adjust the offsets later\n            Iterator it = entries.iterator();\n            while(it.hasNext()) {\n                FileEntry fe = (FileEntry) it.next();\n                fe.directoryOffset = os.getFilePointer();\n                os.writeLong(0);    // for now\n                os.writeString(fe.file);\n            }\n\n            // Open the files and copy their data into the stream.\n            // Remeber the locations of each file's data section.\n            byte buffer[] = new byte[1024];\n            it = entries.iterator();\n            while(it.hasNext()) {\n                FileEntry fe = (FileEntry) it.next();\n                fe.dataOffset = os.getFilePointer();\n                copyFile(fe, os, buffer);\n            }\n\n            // Write the data offsets into the directory of the compound stream\n            it = entries.iterator();\n            while(it.hasNext()) {\n                FileEntry fe = (FileEntry) it.next();\n                os.seek(fe.directoryOffset);\n                os.writeLong(fe.dataOffset);\n            }\n\n            // Close the output stream. Set the os to null before trying to\n            // close so that if an exception occurs during the close, the\n            // finally clause below will not attempt to close the stream\n            // the second time.\n            OutputStream tmp = os;\n            os = null;\n            tmp.close();\n\n        } finally {\n            if (os != null) try { os.close(); } catch (IOException e) { }\n        }\n    }\n\n","sourceOld":"    /** Merge files with the extensions added up to now.\n     *  All files with these extensions are combined sequentially into the \n     *  compound stream. After successful merge, the source files\n     *  are deleted.\n     */    \n    public void close() throws IOException {\n        if (merged)\n            throw new IllegalStateException(\n                \"Merge already performed\");\n            \n        if (entries.isEmpty())\n            throw new IllegalStateException(\n                \"No entries to merge have been defined\");\n            \n        merged = true;\n        \n        // open the compound stream\n        OutputStream os = null;\n        try {\n            os = directory.createFile(fileName);\n        \n            // Write the number of entries\n            os.writeVInt(entries.size());\n        \n            // Write the directory with all offsets at 0.\n            // Remember the positions of directory entries so that we can\n            // adjust the offsets later\n            Iterator it = entries.iterator();\n            while(it.hasNext()) {\n                FileEntry fe = (FileEntry) it.next();\n                fe.directoryOffset = os.getFilePointer();\n                os.writeLong(0);    // for now\n                os.writeString(fe.file);\n            }\n            \n            // Open the files and copy their data into the stream.\n            // Remeber the locations of each file's data section.\n            byte buffer[] = new byte[1024];\n            it = entries.iterator();\n            while(it.hasNext()) {\n                FileEntry fe = (FileEntry) it.next();\n                fe.dataOffset = os.getFilePointer();                \n                copyFile(fe, os, buffer);\n            }\n            \n            // Write the data offsets into the directory of the compound stream\n            it = entries.iterator();\n            while(it.hasNext()) {\n                FileEntry fe = (FileEntry) it.next();\n                os.seek(fe.directoryOffset);\n                os.writeLong(fe.dataOffset);\n            }\n            \n            // Close the output stream. Set the os to null before trying to\n            // close so that if an exception occurs during the close, the \n            // finally clause below will not attempt to close the stream\n            // the second time.\n            OutputStream tmp = os;\n            os = null;\n            tmp.close();\n            \n        } finally {\n            if (os != null) try { os.close(); } catch (IOException e) { }\n        }\n    }\n\n","bugFix":null,"bugIntro":["462dfb1d8690f192817503773f5b8b94a702246a"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"dd6e3a4e181faba2fa9bc424d5804f03c3fddaa0","date":1093434977,"type":3,"author":"Daniel Naber","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/CompoundFileWriter#close().mjava","pathOld":"src/java/org/apache/lucene/index/CompoundFileWriter#close().mjava","sourceNew":"    /** Merge files with the extensions added up to now.\n     *  All files with these extensions are combined sequentially into the\n     *  compound stream. After successful merge, the source files\n     *  are deleted.\n     */\n    public void close() throws IOException {\n        if (merged)\n            throw new IllegalStateException(\n                \"Merge already performed\");\n\n        if (entries.isEmpty())\n            throw new IllegalStateException(\n                \"No entries to merge have been defined\");\n\n        merged = true;\n\n        // open the compound stream\n        OutputStream os = null;\n        try {\n            os = directory.createFile(fileName);\n\n            // Write the number of entries\n            os.writeVInt(entries.size());\n\n            // Write the directory with all offsets at 0.\n            // Remember the positions of directory entries so that we can\n            // adjust the offsets later\n            Iterator it = entries.iterator();\n            while(it.hasNext()) {\n                FileEntry fe = (FileEntry) it.next();\n                fe.directoryOffset = os.getFilePointer();\n                os.writeLong(0);    // for now\n                os.writeString(fe.file);\n            }\n\n            // Open the files and copy their data into the stream.\n            // Remember the locations of each file's data section.\n            byte buffer[] = new byte[1024];\n            it = entries.iterator();\n            while(it.hasNext()) {\n                FileEntry fe = (FileEntry) it.next();\n                fe.dataOffset = os.getFilePointer();\n                copyFile(fe, os, buffer);\n            }\n\n            // Write the data offsets into the directory of the compound stream\n            it = entries.iterator();\n            while(it.hasNext()) {\n                FileEntry fe = (FileEntry) it.next();\n                os.seek(fe.directoryOffset);\n                os.writeLong(fe.dataOffset);\n            }\n\n            // Close the output stream. Set the os to null before trying to\n            // close so that if an exception occurs during the close, the\n            // finally clause below will not attempt to close the stream\n            // the second time.\n            OutputStream tmp = os;\n            os = null;\n            tmp.close();\n\n        } finally {\n            if (os != null) try { os.close(); } catch (IOException e) { }\n        }\n    }\n\n","sourceOld":"    /** Merge files with the extensions added up to now.\n     *  All files with these extensions are combined sequentially into the\n     *  compound stream. After successful merge, the source files\n     *  are deleted.\n     */\n    public void close() throws IOException {\n        if (merged)\n            throw new IllegalStateException(\n                \"Merge already performed\");\n\n        if (entries.isEmpty())\n            throw new IllegalStateException(\n                \"No entries to merge have been defined\");\n\n        merged = true;\n\n        // open the compound stream\n        OutputStream os = null;\n        try {\n            os = directory.createFile(fileName);\n\n            // Write the number of entries\n            os.writeVInt(entries.size());\n\n            // Write the directory with all offsets at 0.\n            // Remember the positions of directory entries so that we can\n            // adjust the offsets later\n            Iterator it = entries.iterator();\n            while(it.hasNext()) {\n                FileEntry fe = (FileEntry) it.next();\n                fe.directoryOffset = os.getFilePointer();\n                os.writeLong(0);    // for now\n                os.writeString(fe.file);\n            }\n\n            // Open the files and copy their data into the stream.\n            // Remeber the locations of each file's data section.\n            byte buffer[] = new byte[1024];\n            it = entries.iterator();\n            while(it.hasNext()) {\n                FileEntry fe = (FileEntry) it.next();\n                fe.dataOffset = os.getFilePointer();\n                copyFile(fe, os, buffer);\n            }\n\n            // Write the data offsets into the directory of the compound stream\n            it = entries.iterator();\n            while(it.hasNext()) {\n                FileEntry fe = (FileEntry) it.next();\n                os.seek(fe.directoryOffset);\n                os.writeLong(fe.dataOffset);\n            }\n\n            // Close the output stream. Set the os to null before trying to\n            // close so that if an exception occurs during the close, the\n            // finally clause below will not attempt to close the stream\n            // the second time.\n            OutputStream tmp = os;\n            os = null;\n            tmp.close();\n\n        } finally {\n            if (os != null) try { os.close(); } catch (IOException e) { }\n        }\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"f67cd33295438e867652c323bd3edf9bcfb9bf66","date":1093524074,"type":3,"author":"Daniel Naber","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/CompoundFileWriter#close().mjava","pathOld":"src/java/org/apache/lucene/index/CompoundFileWriter#close().mjava","sourceNew":"    /** Merge files with the extensions added up to now.\n     *  All files with these extensions are combined sequentially into the\n     *  compound stream. After successful merge, the source files\n     *  are deleted.\n     *  @throws IllegalStateException if close() had been called before or\n     *   if no file has been added to this object\n     */\n    public void close() throws IOException {\n        if (merged)\n            throw new IllegalStateException(\n                \"Merge already performed\");\n\n        if (entries.isEmpty())\n            throw new IllegalStateException(\n                \"No entries to merge have been defined\");\n\n        merged = true;\n\n        // open the compound stream\n        OutputStream os = null;\n        try {\n            os = directory.createFile(fileName);\n\n            // Write the number of entries\n            os.writeVInt(entries.size());\n\n            // Write the directory with all offsets at 0.\n            // Remember the positions of directory entries so that we can\n            // adjust the offsets later\n            Iterator it = entries.iterator();\n            while(it.hasNext()) {\n                FileEntry fe = (FileEntry) it.next();\n                fe.directoryOffset = os.getFilePointer();\n                os.writeLong(0);    // for now\n                os.writeString(fe.file);\n            }\n\n            // Open the files and copy their data into the stream.\n            // Remember the locations of each file's data section.\n            byte buffer[] = new byte[1024];\n            it = entries.iterator();\n            while(it.hasNext()) {\n                FileEntry fe = (FileEntry) it.next();\n                fe.dataOffset = os.getFilePointer();\n                copyFile(fe, os, buffer);\n            }\n\n            // Write the data offsets into the directory of the compound stream\n            it = entries.iterator();\n            while(it.hasNext()) {\n                FileEntry fe = (FileEntry) it.next();\n                os.seek(fe.directoryOffset);\n                os.writeLong(fe.dataOffset);\n            }\n\n            // Close the output stream. Set the os to null before trying to\n            // close so that if an exception occurs during the close, the\n            // finally clause below will not attempt to close the stream\n            // the second time.\n            OutputStream tmp = os;\n            os = null;\n            tmp.close();\n\n        } finally {\n            if (os != null) try { os.close(); } catch (IOException e) { }\n        }\n    }\n\n","sourceOld":"    /** Merge files with the extensions added up to now.\n     *  All files with these extensions are combined sequentially into the\n     *  compound stream. After successful merge, the source files\n     *  are deleted.\n     */\n    public void close() throws IOException {\n        if (merged)\n            throw new IllegalStateException(\n                \"Merge already performed\");\n\n        if (entries.isEmpty())\n            throw new IllegalStateException(\n                \"No entries to merge have been defined\");\n\n        merged = true;\n\n        // open the compound stream\n        OutputStream os = null;\n        try {\n            os = directory.createFile(fileName);\n\n            // Write the number of entries\n            os.writeVInt(entries.size());\n\n            // Write the directory with all offsets at 0.\n            // Remember the positions of directory entries so that we can\n            // adjust the offsets later\n            Iterator it = entries.iterator();\n            while(it.hasNext()) {\n                FileEntry fe = (FileEntry) it.next();\n                fe.directoryOffset = os.getFilePointer();\n                os.writeLong(0);    // for now\n                os.writeString(fe.file);\n            }\n\n            // Open the files and copy their data into the stream.\n            // Remember the locations of each file's data section.\n            byte buffer[] = new byte[1024];\n            it = entries.iterator();\n            while(it.hasNext()) {\n                FileEntry fe = (FileEntry) it.next();\n                fe.dataOffset = os.getFilePointer();\n                copyFile(fe, os, buffer);\n            }\n\n            // Write the data offsets into the directory of the compound stream\n            it = entries.iterator();\n            while(it.hasNext()) {\n                FileEntry fe = (FileEntry) it.next();\n                os.seek(fe.directoryOffset);\n                os.writeLong(fe.dataOffset);\n            }\n\n            // Close the output stream. Set the os to null before trying to\n            // close so that if an exception occurs during the close, the\n            // finally clause below will not attempt to close the stream\n            // the second time.\n            OutputStream tmp = os;\n            os = null;\n            tmp.close();\n\n        } finally {\n            if (os != null) try { os.close(); } catch (IOException e) { }\n        }\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"dda77265180d41bf85c84c995e25eda7b8e1b74d","date":1096395352,"type":3,"author":"Doug Cutting","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/CompoundFileWriter#close().mjava","pathOld":"src/java/org/apache/lucene/index/CompoundFileWriter#close().mjava","sourceNew":"    /** Merge files with the extensions added up to now.\n     *  All files with these extensions are combined sequentially into the\n     *  compound stream. After successful merge, the source files\n     *  are deleted.\n     *  @throws IllegalStateException if close() had been called before or\n     *   if no file has been added to this object\n     */\n    public void close() throws IOException {\n        if (merged)\n            throw new IllegalStateException(\n                \"Merge already performed\");\n\n        if (entries.isEmpty())\n            throw new IllegalStateException(\n                \"No entries to merge have been defined\");\n\n        merged = true;\n\n        // open the compound stream\n        IndexOutput os = null;\n        try {\n            os = directory.createOutput(fileName);\n\n            // Write the number of entries\n            os.writeVInt(entries.size());\n\n            // Write the directory with all offsets at 0.\n            // Remember the positions of directory entries so that we can\n            // adjust the offsets later\n            Iterator it = entries.iterator();\n            while(it.hasNext()) {\n                FileEntry fe = (FileEntry) it.next();\n                fe.directoryOffset = os.getFilePointer();\n                os.writeLong(0);    // for now\n                os.writeString(fe.file);\n            }\n\n            // Open the files and copy their data into the stream.\n            // Remember the locations of each file's data section.\n            byte buffer[] = new byte[1024];\n            it = entries.iterator();\n            while(it.hasNext()) {\n                FileEntry fe = (FileEntry) it.next();\n                fe.dataOffset = os.getFilePointer();\n                copyFile(fe, os, buffer);\n            }\n\n            // Write the data offsets into the directory of the compound stream\n            it = entries.iterator();\n            while(it.hasNext()) {\n                FileEntry fe = (FileEntry) it.next();\n                os.seek(fe.directoryOffset);\n                os.writeLong(fe.dataOffset);\n            }\n\n            // Close the output stream. Set the os to null before trying to\n            // close so that if an exception occurs during the close, the\n            // finally clause below will not attempt to close the stream\n            // the second time.\n            IndexOutput tmp = os;\n            os = null;\n            tmp.close();\n\n        } finally {\n            if (os != null) try { os.close(); } catch (IOException e) { }\n        }\n    }\n\n","sourceOld":"    /** Merge files with the extensions added up to now.\n     *  All files with these extensions are combined sequentially into the\n     *  compound stream. After successful merge, the source files\n     *  are deleted.\n     *  @throws IllegalStateException if close() had been called before or\n     *   if no file has been added to this object\n     */\n    public void close() throws IOException {\n        if (merged)\n            throw new IllegalStateException(\n                \"Merge already performed\");\n\n        if (entries.isEmpty())\n            throw new IllegalStateException(\n                \"No entries to merge have been defined\");\n\n        merged = true;\n\n        // open the compound stream\n        OutputStream os = null;\n        try {\n            os = directory.createFile(fileName);\n\n            // Write the number of entries\n            os.writeVInt(entries.size());\n\n            // Write the directory with all offsets at 0.\n            // Remember the positions of directory entries so that we can\n            // adjust the offsets later\n            Iterator it = entries.iterator();\n            while(it.hasNext()) {\n                FileEntry fe = (FileEntry) it.next();\n                fe.directoryOffset = os.getFilePointer();\n                os.writeLong(0);    // for now\n                os.writeString(fe.file);\n            }\n\n            // Open the files and copy their data into the stream.\n            // Remember the locations of each file's data section.\n            byte buffer[] = new byte[1024];\n            it = entries.iterator();\n            while(it.hasNext()) {\n                FileEntry fe = (FileEntry) it.next();\n                fe.dataOffset = os.getFilePointer();\n                copyFile(fe, os, buffer);\n            }\n\n            // Write the data offsets into the directory of the compound stream\n            it = entries.iterator();\n            while(it.hasNext()) {\n                FileEntry fe = (FileEntry) it.next();\n                os.seek(fe.directoryOffset);\n                os.writeLong(fe.dataOffset);\n            }\n\n            // Close the output stream. Set the os to null before trying to\n            // close so that if an exception occurs during the close, the\n            // finally clause below will not attempt to close the stream\n            // the second time.\n            OutputStream tmp = os;\n            os = null;\n            tmp.close();\n\n        } finally {\n            if (os != null) try { os.close(); } catch (IOException e) { }\n        }\n    }\n\n","bugFix":null,"bugIntro":["462dfb1d8690f192817503773f5b8b94a702246a"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"f6dba7919de4ff4ed6ff17f90619203772722f08","date":1180451647,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/CompoundFileWriter#close().mjava","pathOld":"src/java/org/apache/lucene/index/CompoundFileWriter#close().mjava","sourceNew":"    /** Merge files with the extensions added up to now.\n     *  All files with these extensions are combined sequentially into the\n     *  compound stream. After successful merge, the source files\n     *  are deleted.\n     *  @throws IllegalStateException if close() had been called before or\n     *   if no file has been added to this object\n     */\n    public void close() throws IOException {\n        if (merged)\n            throw new IllegalStateException(\n                \"Merge already performed\");\n\n        if (entries.isEmpty())\n            throw new IllegalStateException(\n                \"No entries to merge have been defined\");\n\n        merged = true;\n\n        // open the compound stream\n        IndexOutput os = null;\n        try {\n            os = directory.createOutput(fileName);\n\n            // Write the number of entries\n            os.writeVInt(entries.size());\n\n            // Write the directory with all offsets at 0.\n            // Remember the positions of directory entries so that we can\n            // adjust the offsets later\n            Iterator it = entries.iterator();\n            while(it.hasNext()) {\n                FileEntry fe = (FileEntry) it.next();\n                fe.directoryOffset = os.getFilePointer();\n                os.writeLong(0);    // for now\n                os.writeString(fe.file);\n            }\n\n            // Open the files and copy their data into the stream.\n            // Remember the locations of each file's data section.\n            byte buffer[] = new byte[16384];\n            it = entries.iterator();\n            while(it.hasNext()) {\n                FileEntry fe = (FileEntry) it.next();\n                fe.dataOffset = os.getFilePointer();\n                copyFile(fe, os, buffer);\n            }\n\n            // Write the data offsets into the directory of the compound stream\n            it = entries.iterator();\n            while(it.hasNext()) {\n                FileEntry fe = (FileEntry) it.next();\n                os.seek(fe.directoryOffset);\n                os.writeLong(fe.dataOffset);\n            }\n\n            // Close the output stream. Set the os to null before trying to\n            // close so that if an exception occurs during the close, the\n            // finally clause below will not attempt to close the stream\n            // the second time.\n            IndexOutput tmp = os;\n            os = null;\n            tmp.close();\n\n        } finally {\n            if (os != null) try { os.close(); } catch (IOException e) { }\n        }\n    }\n\n","sourceOld":"    /** Merge files with the extensions added up to now.\n     *  All files with these extensions are combined sequentially into the\n     *  compound stream. After successful merge, the source files\n     *  are deleted.\n     *  @throws IllegalStateException if close() had been called before or\n     *   if no file has been added to this object\n     */\n    public void close() throws IOException {\n        if (merged)\n            throw new IllegalStateException(\n                \"Merge already performed\");\n\n        if (entries.isEmpty())\n            throw new IllegalStateException(\n                \"No entries to merge have been defined\");\n\n        merged = true;\n\n        // open the compound stream\n        IndexOutput os = null;\n        try {\n            os = directory.createOutput(fileName);\n\n            // Write the number of entries\n            os.writeVInt(entries.size());\n\n            // Write the directory with all offsets at 0.\n            // Remember the positions of directory entries so that we can\n            // adjust the offsets later\n            Iterator it = entries.iterator();\n            while(it.hasNext()) {\n                FileEntry fe = (FileEntry) it.next();\n                fe.directoryOffset = os.getFilePointer();\n                os.writeLong(0);    // for now\n                os.writeString(fe.file);\n            }\n\n            // Open the files and copy their data into the stream.\n            // Remember the locations of each file's data section.\n            byte buffer[] = new byte[1024];\n            it = entries.iterator();\n            while(it.hasNext()) {\n                FileEntry fe = (FileEntry) it.next();\n                fe.dataOffset = os.getFilePointer();\n                copyFile(fe, os, buffer);\n            }\n\n            // Write the data offsets into the directory of the compound stream\n            it = entries.iterator();\n            while(it.hasNext()) {\n                FileEntry fe = (FileEntry) it.next();\n                os.seek(fe.directoryOffset);\n                os.writeLong(fe.dataOffset);\n            }\n\n            // Close the output stream. Set the os to null before trying to\n            // close so that if an exception occurs during the close, the\n            // finally clause below will not attempt to close the stream\n            // the second time.\n            IndexOutput tmp = os;\n            os = null;\n            tmp.close();\n\n        } finally {\n            if (os != null) try { os.close(); } catch (IOException e) { }\n        }\n    }\n\n","bugFix":null,"bugIntro":["462dfb1d8690f192817503773f5b8b94a702246a"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"4e6647c2984ee4dedd7289e4bd87c64835d4cc77","date":1201254149,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/CompoundFileWriter#close().mjava","pathOld":"src/java/org/apache/lucene/index/CompoundFileWriter#close().mjava","sourceNew":"    /** Merge files with the extensions added up to now.\n     *  All files with these extensions are combined sequentially into the\n     *  compound stream. After successful merge, the source files\n     *  are deleted.\n     *  @throws IllegalStateException if close() had been called before or\n     *   if no file has been added to this object\n     */\n    public void close() throws IOException {\n        if (merged)\n            throw new IllegalStateException(\n                \"Merge already performed\");\n\n        if (entries.isEmpty())\n            throw new IllegalStateException(\n                \"No entries to merge have been defined\");\n\n        merged = true;\n\n        // open the compound stream\n        IndexOutput os = null;\n        try {\n            os = directory.createOutput(fileName);\n\n            // Write the number of entries\n            os.writeVInt(entries.size());\n\n            // Write the directory with all offsets at 0.\n            // Remember the positions of directory entries so that we can\n            // adjust the offsets later\n            Iterator it = entries.iterator();\n            long totalSize = 0;\n            while(it.hasNext()) {\n                FileEntry fe = (FileEntry) it.next();\n                fe.directoryOffset = os.getFilePointer();\n                os.writeLong(0);    // for now\n                os.writeString(fe.file);\n                totalSize += directory.fileLength(fe.file);\n            }\n\n            // Pre-allocate size of file as optimization --\n            // this can potentially help IO performance as\n            // we write the file and also later during\n            // searching.  It also uncovers a disk-full\n            // situation earlier and hopefully without\n            // actually filling disk to 100%:\n            final long finalLength = totalSize+os.getFilePointer();\n            os.setLength(finalLength);\n\n            // Open the files and copy their data into the stream.\n            // Remember the locations of each file's data section.\n            byte buffer[] = new byte[16384];\n            it = entries.iterator();\n            while(it.hasNext()) {\n                FileEntry fe = (FileEntry) it.next();\n                fe.dataOffset = os.getFilePointer();\n                copyFile(fe, os, buffer);\n            }\n\n            // Write the data offsets into the directory of the compound stream\n            it = entries.iterator();\n            while(it.hasNext()) {\n                FileEntry fe = (FileEntry) it.next();\n                os.seek(fe.directoryOffset);\n                os.writeLong(fe.dataOffset);\n            }\n\n            assert finalLength == os.length();\n\n            // Close the output stream. Set the os to null before trying to\n            // close so that if an exception occurs during the close, the\n            // finally clause below will not attempt to close the stream\n            // the second time.\n            IndexOutput tmp = os;\n            os = null;\n            tmp.close();\n\n        } finally {\n            if (os != null) try { os.close(); } catch (IOException e) { }\n        }\n    }\n\n","sourceOld":"    /** Merge files with the extensions added up to now.\n     *  All files with these extensions are combined sequentially into the\n     *  compound stream. After successful merge, the source files\n     *  are deleted.\n     *  @throws IllegalStateException if close() had been called before or\n     *   if no file has been added to this object\n     */\n    public void close() throws IOException {\n        if (merged)\n            throw new IllegalStateException(\n                \"Merge already performed\");\n\n        if (entries.isEmpty())\n            throw new IllegalStateException(\n                \"No entries to merge have been defined\");\n\n        merged = true;\n\n        // open the compound stream\n        IndexOutput os = null;\n        try {\n            os = directory.createOutput(fileName);\n\n            // Write the number of entries\n            os.writeVInt(entries.size());\n\n            // Write the directory with all offsets at 0.\n            // Remember the positions of directory entries so that we can\n            // adjust the offsets later\n            Iterator it = entries.iterator();\n            while(it.hasNext()) {\n                FileEntry fe = (FileEntry) it.next();\n                fe.directoryOffset = os.getFilePointer();\n                os.writeLong(0);    // for now\n                os.writeString(fe.file);\n            }\n\n            // Open the files and copy their data into the stream.\n            // Remember the locations of each file's data section.\n            byte buffer[] = new byte[16384];\n            it = entries.iterator();\n            while(it.hasNext()) {\n                FileEntry fe = (FileEntry) it.next();\n                fe.dataOffset = os.getFilePointer();\n                copyFile(fe, os, buffer);\n            }\n\n            // Write the data offsets into the directory of the compound stream\n            it = entries.iterator();\n            while(it.hasNext()) {\n                FileEntry fe = (FileEntry) it.next();\n                os.seek(fe.directoryOffset);\n                os.writeLong(fe.dataOffset);\n            }\n\n            // Close the output stream. Set the os to null before trying to\n            // close so that if an exception occurs during the close, the\n            // finally clause below will not attempt to close the stream\n            // the second time.\n            IndexOutput tmp = os;\n            os = null;\n            tmp.close();\n\n        } finally {\n            if (os != null) try { os.close(); } catch (IOException e) { }\n        }\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"f011f01db72fa6f556a9a0843944ecee2de4aaa8","date":1255806907,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/CompoundFileWriter#close().mjava","pathOld":"src/java/org/apache/lucene/index/CompoundFileWriter#close().mjava","sourceNew":"    /** Merge files with the extensions added up to now.\n     *  All files with these extensions are combined sequentially into the\n     *  compound stream. After successful merge, the source files\n     *  are deleted.\n     *  @throws IllegalStateException if close() had been called before or\n     *   if no file has been added to this object\n     */\n    public void close() throws IOException {\n        if (merged)\n            throw new IllegalStateException(\n                \"Merge already performed\");\n\n        if (entries.isEmpty())\n            throw new IllegalStateException(\n                \"No entries to merge have been defined\");\n\n        merged = true;\n\n        // open the compound stream\n        IndexOutput os = null;\n        try {\n            os = directory.createOutput(fileName);\n\n            // Write the number of entries\n            os.writeVInt(entries.size());\n\n            // Write the directory with all offsets at 0.\n            // Remember the positions of directory entries so that we can\n            // adjust the offsets later\n            long totalSize = 0;\n            for (FileEntry fe : entries) {\n                fe.directoryOffset = os.getFilePointer();\n                os.writeLong(0);    // for now\n                os.writeString(fe.file);\n                totalSize += directory.fileLength(fe.file);\n            }\n\n            // Pre-allocate size of file as optimization --\n            // this can potentially help IO performance as\n            // we write the file and also later during\n            // searching.  It also uncovers a disk-full\n            // situation earlier and hopefully without\n            // actually filling disk to 100%:\n            final long finalLength = totalSize+os.getFilePointer();\n            os.setLength(finalLength);\n\n            // Open the files and copy their data into the stream.\n            // Remember the locations of each file's data section.\n            byte buffer[] = new byte[16384];\n            for (FileEntry fe : entries) {\n                fe.dataOffset = os.getFilePointer();\n                copyFile(fe, os, buffer);\n            }\n\n            // Write the data offsets into the directory of the compound stream\n            for (FileEntry fe : entries) {\n                os.seek(fe.directoryOffset);\n                os.writeLong(fe.dataOffset);\n            }\n\n            assert finalLength == os.length();\n\n            // Close the output stream. Set the os to null before trying to\n            // close so that if an exception occurs during the close, the\n            // finally clause below will not attempt to close the stream\n            // the second time.\n            IndexOutput tmp = os;\n            os = null;\n            tmp.close();\n\n        } finally {\n            if (os != null) try { os.close(); } catch (IOException e) { }\n        }\n    }\n\n","sourceOld":"    /** Merge files with the extensions added up to now.\n     *  All files with these extensions are combined sequentially into the\n     *  compound stream. After successful merge, the source files\n     *  are deleted.\n     *  @throws IllegalStateException if close() had been called before or\n     *   if no file has been added to this object\n     */\n    public void close() throws IOException {\n        if (merged)\n            throw new IllegalStateException(\n                \"Merge already performed\");\n\n        if (entries.isEmpty())\n            throw new IllegalStateException(\n                \"No entries to merge have been defined\");\n\n        merged = true;\n\n        // open the compound stream\n        IndexOutput os = null;\n        try {\n            os = directory.createOutput(fileName);\n\n            // Write the number of entries\n            os.writeVInt(entries.size());\n\n            // Write the directory with all offsets at 0.\n            // Remember the positions of directory entries so that we can\n            // adjust the offsets later\n            Iterator it = entries.iterator();\n            long totalSize = 0;\n            while(it.hasNext()) {\n                FileEntry fe = (FileEntry) it.next();\n                fe.directoryOffset = os.getFilePointer();\n                os.writeLong(0);    // for now\n                os.writeString(fe.file);\n                totalSize += directory.fileLength(fe.file);\n            }\n\n            // Pre-allocate size of file as optimization --\n            // this can potentially help IO performance as\n            // we write the file and also later during\n            // searching.  It also uncovers a disk-full\n            // situation earlier and hopefully without\n            // actually filling disk to 100%:\n            final long finalLength = totalSize+os.getFilePointer();\n            os.setLength(finalLength);\n\n            // Open the files and copy their data into the stream.\n            // Remember the locations of each file's data section.\n            byte buffer[] = new byte[16384];\n            it = entries.iterator();\n            while(it.hasNext()) {\n                FileEntry fe = (FileEntry) it.next();\n                fe.dataOffset = os.getFilePointer();\n                copyFile(fe, os, buffer);\n            }\n\n            // Write the data offsets into the directory of the compound stream\n            it = entries.iterator();\n            while(it.hasNext()) {\n                FileEntry fe = (FileEntry) it.next();\n                os.seek(fe.directoryOffset);\n                os.writeLong(fe.dataOffset);\n            }\n\n            assert finalLength == os.length();\n\n            // Close the output stream. Set the os to null before trying to\n            // close so that if an exception occurs during the close, the\n            // finally clause below will not attempt to close the stream\n            // the second time.\n            IndexOutput tmp = os;\n            os = null;\n            tmp.close();\n\n        } finally {\n            if (os != null) try { os.close(); } catch (IOException e) { }\n        }\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"9454a6510e2db155fb01faa5c049b06ece95fab9","date":1453508333,"type":5,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/CompoundFileWriter#close().mjava","pathOld":"src/java/org/apache/lucene/index/CompoundFileWriter#close().mjava","sourceNew":"    /** Merge files with the extensions added up to now.\n     *  All files with these extensions are combined sequentially into the\n     *  compound stream. After successful merge, the source files\n     *  are deleted.\n     *  @throws IllegalStateException if close() had been called before or\n     *   if no file has been added to this object\n     */\n    public void close() throws IOException {\n        if (merged)\n            throw new IllegalStateException(\n                \"Merge already performed\");\n\n        if (entries.isEmpty())\n            throw new IllegalStateException(\n                \"No entries to merge have been defined\");\n\n        merged = true;\n\n        // open the compound stream\n        IndexOutput os = null;\n        try {\n            os = directory.createOutput(fileName);\n\n            // Write the number of entries\n            os.writeVInt(entries.size());\n\n            // Write the directory with all offsets at 0.\n            // Remember the positions of directory entries so that we can\n            // adjust the offsets later\n            long totalSize = 0;\n            for (FileEntry fe : entries) {\n                fe.directoryOffset = os.getFilePointer();\n                os.writeLong(0);    // for now\n                os.writeString(fe.file);\n                totalSize += directory.fileLength(fe.file);\n            }\n\n            // Pre-allocate size of file as optimization --\n            // this can potentially help IO performance as\n            // we write the file and also later during\n            // searching.  It also uncovers a disk-full\n            // situation earlier and hopefully without\n            // actually filling disk to 100%:\n            final long finalLength = totalSize+os.getFilePointer();\n            os.setLength(finalLength);\n\n            // Open the files and copy their data into the stream.\n            // Remember the locations of each file's data section.\n            byte buffer[] = new byte[16384];\n            for (FileEntry fe : entries) {\n                fe.dataOffset = os.getFilePointer();\n                copyFile(fe, os, buffer);\n            }\n\n            // Write the data offsets into the directory of the compound stream\n            for (FileEntry fe : entries) {\n                os.seek(fe.directoryOffset);\n                os.writeLong(fe.dataOffset);\n            }\n\n            assert finalLength == os.length();\n\n            // Close the output stream. Set the os to null before trying to\n            // close so that if an exception occurs during the close, the\n            // finally clause below will not attempt to close the stream\n            // the second time.\n            IndexOutput tmp = os;\n            os = null;\n            tmp.close();\n\n        } finally {\n            if (os != null) try { os.close(); } catch (IOException e) { }\n        }\n    }\n\n","sourceOld":"    /** Merge files with the extensions added up to now.\n     *  All files with these extensions are combined sequentially into the\n     *  compound stream. After successful merge, the source files\n     *  are deleted.\n     *  @throws IllegalStateException if close() had been called before or\n     *   if no file has been added to this object\n     */\n    public void close() throws IOException {\n        if (merged)\n            throw new IllegalStateException(\n                \"Merge already performed\");\n\n        if (entries.isEmpty())\n            throw new IllegalStateException(\n                \"No entries to merge have been defined\");\n\n        merged = true;\n\n        // open the compound stream\n        IndexOutput os = null;\n        try {\n            os = directory.createOutput(fileName);\n\n            // Write the number of entries\n            os.writeVInt(entries.size());\n\n            // Write the directory with all offsets at 0.\n            // Remember the positions of directory entries so that we can\n            // adjust the offsets later\n            long totalSize = 0;\n            for (FileEntry fe : entries) {\n                fe.directoryOffset = os.getFilePointer();\n                os.writeLong(0);    // for now\n                os.writeString(fe.file);\n                totalSize += directory.fileLength(fe.file);\n            }\n\n            // Pre-allocate size of file as optimization --\n            // this can potentially help IO performance as\n            // we write the file and also later during\n            // searching.  It also uncovers a disk-full\n            // situation earlier and hopefully without\n            // actually filling disk to 100%:\n            final long finalLength = totalSize+os.getFilePointer();\n            os.setLength(finalLength);\n\n            // Open the files and copy their data into the stream.\n            // Remember the locations of each file's data section.\n            byte buffer[] = new byte[16384];\n            for (FileEntry fe : entries) {\n                fe.dataOffset = os.getFilePointer();\n                copyFile(fe, os, buffer);\n            }\n\n            // Write the data offsets into the directory of the compound stream\n            for (FileEntry fe : entries) {\n                os.seek(fe.directoryOffset);\n                os.writeLong(fe.dataOffset);\n            }\n\n            assert finalLength == os.length();\n\n            // Close the output stream. Set the os to null before trying to\n            // close so that if an exception occurs during the close, the\n            // finally clause below will not attempt to close the stream\n            // the second time.\n            IndexOutput tmp = os;\n            os = null;\n            tmp.close();\n\n        } finally {\n            if (os != null) try { os.close(); } catch (IOException e) { }\n        }\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"f67cd33295438e867652c323bd3edf9bcfb9bf66":["dd6e3a4e181faba2fa9bc424d5804f03c3fddaa0"],"dda77265180d41bf85c84c995e25eda7b8e1b74d":["f67cd33295438e867652c323bd3edf9bcfb9bf66"],"f6dba7919de4ff4ed6ff17f90619203772722f08":["dda77265180d41bf85c84c995e25eda7b8e1b74d"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"4e6647c2984ee4dedd7289e4bd87c64835d4cc77":["f6dba7919de4ff4ed6ff17f90619203772722f08"],"f011f01db72fa6f556a9a0843944ecee2de4aaa8":["4e6647c2984ee4dedd7289e4bd87c64835d4cc77"],"8fb95844e4ba5160067c64c5eb1cd8a09f7a94f1":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"dd6e3a4e181faba2fa9bc424d5804f03c3fddaa0":["a67f534c1db9eb255bc5a5137c7bf362ff90c276"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["f011f01db72fa6f556a9a0843944ecee2de4aaa8"],"a67f534c1db9eb255bc5a5137c7bf362ff90c276":["8fb95844e4ba5160067c64c5eb1cd8a09f7a94f1"]},"commit2Childs":{"f67cd33295438e867652c323bd3edf9bcfb9bf66":["dda77265180d41bf85c84c995e25eda7b8e1b74d"],"dda77265180d41bf85c84c995e25eda7b8e1b74d":["f6dba7919de4ff4ed6ff17f90619203772722f08"],"f6dba7919de4ff4ed6ff17f90619203772722f08":["4e6647c2984ee4dedd7289e4bd87c64835d4cc77"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["8fb95844e4ba5160067c64c5eb1cd8a09f7a94f1"],"4e6647c2984ee4dedd7289e4bd87c64835d4cc77":["f011f01db72fa6f556a9a0843944ecee2de4aaa8"],"f011f01db72fa6f556a9a0843944ecee2de4aaa8":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"8fb95844e4ba5160067c64c5eb1cd8a09f7a94f1":["a67f534c1db9eb255bc5a5137c7bf362ff90c276"],"dd6e3a4e181faba2fa9bc424d5804f03c3fddaa0":["f67cd33295438e867652c323bd3edf9bcfb9bf66"],"a67f534c1db9eb255bc5a5137c7bf362ff90c276":["dd6e3a4e181faba2fa9bc424d5804f03c3fddaa0"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"9454a6510e2db155fb01faa5c049b06ece95fab9":["cd5edd1f2b162a5cfa08efd17851a07373a96817"]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}