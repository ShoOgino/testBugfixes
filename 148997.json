{"path":"lucene/highlighter/src/java/org/apache/lucene/search/uhighlight/FieldOffsetStrategy#createOffsetsEnumsFromReader(LeafReader,int).mjava","commits":[{"id":"1f5ce59aaf4a055cc9ec62c15a89c263a05ff4b2","date":1475611903,"type":0,"author":"David Smiley","isMerge":false,"pathNew":"lucene/highlighter/src/java/org/apache/lucene/search/uhighlight/FieldOffsetStrategy#createOffsetsEnumsFromReader(LeafReader,int).mjava","pathOld":"/dev/null","sourceNew":"  protected List<OffsetsEnum> createOffsetsEnumsFromReader(LeafReader atomicReader, int doc) throws IOException {\n    // For strict positions, get a Map of term to Spans:\n    //    note: ScriptPhraseHelper.NONE does the right thing for these method calls\n    final Map<BytesRef, Spans> strictPhrasesTermToSpans =\n        strictPhrases.getTermToSpans(atomicReader, doc);\n    // Usually simply wraps terms in a List; but if willRewrite() then can be expanded\n    final List<BytesRef> sourceTerms =\n        strictPhrases.expandTermsIfRewrite(terms, strictPhrasesTermToSpans);\n\n    final List<OffsetsEnum> offsetsEnums = new ArrayList<>(sourceTerms.size() + 1);\n\n    Terms termsIndex = atomicReader == null || sourceTerms.isEmpty() ? null : atomicReader.terms(field);\n    if (termsIndex != null) {\n      TermsEnum termsEnum = termsIndex.iterator();//does not return null\n      for (BytesRef term : sourceTerms) {\n        if (!termsEnum.seekExact(term)) {\n          continue; // term not found\n        }\n        PostingsEnum postingsEnum = termsEnum.postings(null, PostingsEnum.OFFSETS);\n        if (postingsEnum == null) {\n          // no offsets or positions available\n          throw new IllegalArgumentException(\"field '\" + field + \"' was indexed without offsets, cannot highlight\");\n        }\n        if (doc != postingsEnum.advance(doc)) { // now it's positioned, although may be exhausted\n          continue;\n        }\n        postingsEnum = strictPhrases.filterPostings(term, postingsEnum, strictPhrasesTermToSpans.get(term));\n        if (postingsEnum == null) {\n          continue;// completely filtered out\n        }\n\n        offsetsEnums.add(new OffsetsEnum(term, postingsEnum));\n      }\n    }\n    return offsetsEnums;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4cce5816ef15a48a0bc11e5d400497ee4301dd3b","date":1476991456,"type":0,"author":"Kevin Risden","isMerge":true,"pathNew":"lucene/highlighter/src/java/org/apache/lucene/search/uhighlight/FieldOffsetStrategy#createOffsetsEnumsFromReader(LeafReader,int).mjava","pathOld":"/dev/null","sourceNew":"  protected List<OffsetsEnum> createOffsetsEnumsFromReader(LeafReader atomicReader, int doc) throws IOException {\n    // For strict positions, get a Map of term to Spans:\n    //    note: ScriptPhraseHelper.NONE does the right thing for these method calls\n    final Map<BytesRef, Spans> strictPhrasesTermToSpans =\n        strictPhrases.getTermToSpans(atomicReader, doc);\n    // Usually simply wraps terms in a List; but if willRewrite() then can be expanded\n    final List<BytesRef> sourceTerms =\n        strictPhrases.expandTermsIfRewrite(terms, strictPhrasesTermToSpans);\n\n    final List<OffsetsEnum> offsetsEnums = new ArrayList<>(sourceTerms.size() + 1);\n\n    Terms termsIndex = atomicReader == null || sourceTerms.isEmpty() ? null : atomicReader.terms(field);\n    if (termsIndex != null) {\n      TermsEnum termsEnum = termsIndex.iterator();//does not return null\n      for (BytesRef term : sourceTerms) {\n        if (!termsEnum.seekExact(term)) {\n          continue; // term not found\n        }\n        PostingsEnum postingsEnum = termsEnum.postings(null, PostingsEnum.OFFSETS);\n        if (postingsEnum == null) {\n          // no offsets or positions available\n          throw new IllegalArgumentException(\"field '\" + field + \"' was indexed without offsets, cannot highlight\");\n        }\n        if (doc != postingsEnum.advance(doc)) { // now it's positioned, although may be exhausted\n          continue;\n        }\n        postingsEnum = strictPhrases.filterPostings(term, postingsEnum, strictPhrasesTermToSpans.get(term));\n        if (postingsEnum == null) {\n          continue;// completely filtered out\n        }\n\n        offsetsEnums.add(new OffsetsEnum(term, postingsEnum));\n      }\n    }\n    return offsetsEnums;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f2e9861e4a2b724d9fc51b618714c579491b78d7","date":1479244606,"type":3,"author":"David Smiley","isMerge":false,"pathNew":"lucene/highlighter/src/java/org/apache/lucene/search/uhighlight/FieldOffsetStrategy#createOffsetsEnumsFromReader(LeafReader,int).mjava","pathOld":"lucene/highlighter/src/java/org/apache/lucene/search/uhighlight/FieldOffsetStrategy#createOffsetsEnumsFromReader(LeafReader,int).mjava","sourceNew":"  protected List<OffsetsEnum> createOffsetsEnumsFromReader(LeafReader leafReader, int doc) throws IOException {\n    final Terms termsIndex = leafReader.terms(field);\n    if (termsIndex == null) {\n      return Collections.emptyList();\n    }\n\n    // For strict positions, get a Map of term to Spans:\n    //    note: ScriptPhraseHelper.NONE does the right thing for these method calls\n    final Map<BytesRef, Spans> strictPhrasesTermToSpans =\n        phraseHelper.getTermToSpans(leafReader, doc);\n    // Usually simply wraps terms in a List; but if willRewrite() then can be expanded\n    final List<BytesRef> sourceTerms =\n        phraseHelper.expandTermsIfRewrite(terms, strictPhrasesTermToSpans);\n\n    final List<OffsetsEnum> offsetsEnums = new ArrayList<>(sourceTerms.size() + automata.length);\n\n    // Handle sourceTerms:\n    if (!sourceTerms.isEmpty()) {\n      TermsEnum termsEnum = termsIndex.iterator();//does not return null\n      for (BytesRef term : sourceTerms) {\n        if (termsEnum.seekExact(term)) {\n          PostingsEnum postingsEnum = termsEnum.postings(null, PostingsEnum.OFFSETS);\n\n          if (postingsEnum == null) {\n            // no offsets or positions available\n            throw new IllegalArgumentException(\"field '\" + field + \"' was indexed without offsets, cannot highlight\");\n          }\n\n          if (doc == postingsEnum.advance(doc)) { // now it's positioned, although may be exhausted\n            postingsEnum = phraseHelper.filterPostings(term, postingsEnum, strictPhrasesTermToSpans.get(term));\n            if (postingsEnum != null) {\n              offsetsEnums.add(new OffsetsEnum(term, postingsEnum));\n            }\n          }\n        }\n      }\n    }\n\n    // Handle automata\n    if (automata.length > 0) {\n      offsetsEnums.addAll(createAutomataOffsetsFromTerms(termsIndex, doc));\n    }\n\n    return offsetsEnums;\n  }\n\n","sourceOld":"  protected List<OffsetsEnum> createOffsetsEnumsFromReader(LeafReader atomicReader, int doc) throws IOException {\n    // For strict positions, get a Map of term to Spans:\n    //    note: ScriptPhraseHelper.NONE does the right thing for these method calls\n    final Map<BytesRef, Spans> strictPhrasesTermToSpans =\n        strictPhrases.getTermToSpans(atomicReader, doc);\n    // Usually simply wraps terms in a List; but if willRewrite() then can be expanded\n    final List<BytesRef> sourceTerms =\n        strictPhrases.expandTermsIfRewrite(terms, strictPhrasesTermToSpans);\n\n    final List<OffsetsEnum> offsetsEnums = new ArrayList<>(sourceTerms.size() + 1);\n\n    Terms termsIndex = atomicReader == null || sourceTerms.isEmpty() ? null : atomicReader.terms(field);\n    if (termsIndex != null) {\n      TermsEnum termsEnum = termsIndex.iterator();//does not return null\n      for (BytesRef term : sourceTerms) {\n        if (!termsEnum.seekExact(term)) {\n          continue; // term not found\n        }\n        PostingsEnum postingsEnum = termsEnum.postings(null, PostingsEnum.OFFSETS);\n        if (postingsEnum == null) {\n          // no offsets or positions available\n          throw new IllegalArgumentException(\"field '\" + field + \"' was indexed without offsets, cannot highlight\");\n        }\n        if (doc != postingsEnum.advance(doc)) { // now it's positioned, although may be exhausted\n          continue;\n        }\n        postingsEnum = strictPhrases.filterPostings(term, postingsEnum, strictPhrasesTermToSpans.get(term));\n        if (postingsEnum == null) {\n          continue;// completely filtered out\n        }\n\n        offsetsEnums.add(new OffsetsEnum(term, postingsEnum));\n      }\n    }\n    return offsetsEnums;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a1ef55e1fff7ff44354432770ad8bc19be1fcc75","date":1479266056,"type":3,"author":"Kevin Risden","isMerge":true,"pathNew":"lucene/highlighter/src/java/org/apache/lucene/search/uhighlight/FieldOffsetStrategy#createOffsetsEnumsFromReader(LeafReader,int).mjava","pathOld":"lucene/highlighter/src/java/org/apache/lucene/search/uhighlight/FieldOffsetStrategy#createOffsetsEnumsFromReader(LeafReader,int).mjava","sourceNew":"  protected List<OffsetsEnum> createOffsetsEnumsFromReader(LeafReader leafReader, int doc) throws IOException {\n    final Terms termsIndex = leafReader.terms(field);\n    if (termsIndex == null) {\n      return Collections.emptyList();\n    }\n\n    // For strict positions, get a Map of term to Spans:\n    //    note: ScriptPhraseHelper.NONE does the right thing for these method calls\n    final Map<BytesRef, Spans> strictPhrasesTermToSpans =\n        phraseHelper.getTermToSpans(leafReader, doc);\n    // Usually simply wraps terms in a List; but if willRewrite() then can be expanded\n    final List<BytesRef> sourceTerms =\n        phraseHelper.expandTermsIfRewrite(terms, strictPhrasesTermToSpans);\n\n    final List<OffsetsEnum> offsetsEnums = new ArrayList<>(sourceTerms.size() + automata.length);\n\n    // Handle sourceTerms:\n    if (!sourceTerms.isEmpty()) {\n      TermsEnum termsEnum = termsIndex.iterator();//does not return null\n      for (BytesRef term : sourceTerms) {\n        if (termsEnum.seekExact(term)) {\n          PostingsEnum postingsEnum = termsEnum.postings(null, PostingsEnum.OFFSETS);\n\n          if (postingsEnum == null) {\n            // no offsets or positions available\n            throw new IllegalArgumentException(\"field '\" + field + \"' was indexed without offsets, cannot highlight\");\n          }\n\n          if (doc == postingsEnum.advance(doc)) { // now it's positioned, although may be exhausted\n            postingsEnum = phraseHelper.filterPostings(term, postingsEnum, strictPhrasesTermToSpans.get(term));\n            if (postingsEnum != null) {\n              offsetsEnums.add(new OffsetsEnum(term, postingsEnum));\n            }\n          }\n        }\n      }\n    }\n\n    // Handle automata\n    if (automata.length > 0) {\n      offsetsEnums.addAll(createAutomataOffsetsFromTerms(termsIndex, doc));\n    }\n\n    return offsetsEnums;\n  }\n\n","sourceOld":"  protected List<OffsetsEnum> createOffsetsEnumsFromReader(LeafReader atomicReader, int doc) throws IOException {\n    // For strict positions, get a Map of term to Spans:\n    //    note: ScriptPhraseHelper.NONE does the right thing for these method calls\n    final Map<BytesRef, Spans> strictPhrasesTermToSpans =\n        strictPhrases.getTermToSpans(atomicReader, doc);\n    // Usually simply wraps terms in a List; but if willRewrite() then can be expanded\n    final List<BytesRef> sourceTerms =\n        strictPhrases.expandTermsIfRewrite(terms, strictPhrasesTermToSpans);\n\n    final List<OffsetsEnum> offsetsEnums = new ArrayList<>(sourceTerms.size() + 1);\n\n    Terms termsIndex = atomicReader == null || sourceTerms.isEmpty() ? null : atomicReader.terms(field);\n    if (termsIndex != null) {\n      TermsEnum termsEnum = termsIndex.iterator();//does not return null\n      for (BytesRef term : sourceTerms) {\n        if (!termsEnum.seekExact(term)) {\n          continue; // term not found\n        }\n        PostingsEnum postingsEnum = termsEnum.postings(null, PostingsEnum.OFFSETS);\n        if (postingsEnum == null) {\n          // no offsets or positions available\n          throw new IllegalArgumentException(\"field '\" + field + \"' was indexed without offsets, cannot highlight\");\n        }\n        if (doc != postingsEnum.advance(doc)) { // now it's positioned, although may be exhausted\n          continue;\n        }\n        postingsEnum = strictPhrases.filterPostings(term, postingsEnum, strictPhrasesTermToSpans.get(term));\n        if (postingsEnum == null) {\n          continue;// completely filtered out\n        }\n\n        offsetsEnums.add(new OffsetsEnum(term, postingsEnum));\n      }\n    }\n    return offsetsEnums;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"eef54e3d232eae0e9fc18d75e9b0c3d9ce04b571","date":1515642580,"type":3,"author":"David Smiley","isMerge":false,"pathNew":"lucene/highlighter/src/java/org/apache/lucene/search/uhighlight/FieldOffsetStrategy#createOffsetsEnumsFromReader(LeafReader,int).mjava","pathOld":"lucene/highlighter/src/java/org/apache/lucene/search/uhighlight/FieldOffsetStrategy#createOffsetsEnumsFromReader(LeafReader,int).mjava","sourceNew":"  protected List<OffsetsEnum> createOffsetsEnumsFromReader(LeafReader leafReader, int doc) throws IOException {\n    final Terms termsIndex = leafReader.terms(field);\n    if (termsIndex == null) {\n      return Collections.emptyList();\n    }\n\n    final List<OffsetsEnum> offsetsEnums = new ArrayList<>(terms.length + automata.length);\n\n    // Handle position insensitive terms (a subset of this.terms field):\n    final BytesRef[] insensitiveTerms;\n    if (phraseHelper.hasPositionSensitivity()) {\n      insensitiveTerms = phraseHelper.getAllPositionInsensitiveTerms();\n      assert insensitiveTerms.length <= terms.length : \"insensitive terms should be smaller set of all terms\";\n    } else {\n      insensitiveTerms = terms;\n    }\n    if (insensitiveTerms.length > 0) {\n      createOffsetsEnumsForTerms(insensitiveTerms, termsIndex, doc, offsetsEnums);\n    }\n\n    // Handle spans\n    if (phraseHelper.hasPositionSensitivity()) {\n      phraseHelper.createOffsetsEnumsForSpans(leafReader, doc, offsetsEnums);\n    }\n\n    // Handle automata\n    if (automata.length > 0) {\n      createOffsetsEnumsForAutomata(termsIndex, doc, offsetsEnums);\n    }\n\n    return offsetsEnums;\n  }\n\n","sourceOld":"  protected List<OffsetsEnum> createOffsetsEnumsFromReader(LeafReader leafReader, int doc) throws IOException {\n    final Terms termsIndex = leafReader.terms(field);\n    if (termsIndex == null) {\n      return Collections.emptyList();\n    }\n\n    // For strict positions, get a Map of term to Spans:\n    //    note: ScriptPhraseHelper.NONE does the right thing for these method calls\n    final Map<BytesRef, Spans> strictPhrasesTermToSpans =\n        phraseHelper.getTermToSpans(leafReader, doc);\n    // Usually simply wraps terms in a List; but if willRewrite() then can be expanded\n    final List<BytesRef> sourceTerms =\n        phraseHelper.expandTermsIfRewrite(terms, strictPhrasesTermToSpans);\n\n    final List<OffsetsEnum> offsetsEnums = new ArrayList<>(sourceTerms.size() + automata.length);\n\n    // Handle sourceTerms:\n    if (!sourceTerms.isEmpty()) {\n      TermsEnum termsEnum = termsIndex.iterator();//does not return null\n      for (BytesRef term : sourceTerms) {\n        if (termsEnum.seekExact(term)) {\n          PostingsEnum postingsEnum = termsEnum.postings(null, PostingsEnum.OFFSETS);\n\n          if (postingsEnum == null) {\n            // no offsets or positions available\n            throw new IllegalArgumentException(\"field '\" + field + \"' was indexed without offsets, cannot highlight\");\n          }\n\n          if (doc == postingsEnum.advance(doc)) { // now it's positioned, although may be exhausted\n            postingsEnum = phraseHelper.filterPostings(term, postingsEnum, strictPhrasesTermToSpans.get(term));\n            if (postingsEnum != null) {\n              offsetsEnums.add(new OffsetsEnum(term, postingsEnum));\n            }\n          }\n        }\n      }\n    }\n\n    // Handle automata\n    if (automata.length > 0) {\n      offsetsEnums.addAll(createAutomataOffsetsFromTerms(termsIndex, doc));\n    }\n\n    return offsetsEnums;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b94236357aaa22b76c10629851fe4e376e0cea82","date":1516710914,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"lucene/highlighter/src/java/org/apache/lucene/search/uhighlight/FieldOffsetStrategy#createOffsetsEnumsFromReader(LeafReader,int).mjava","pathOld":"lucene/highlighter/src/java/org/apache/lucene/search/uhighlight/FieldOffsetStrategy#createOffsetsEnumsFromReader(LeafReader,int).mjava","sourceNew":"  protected List<OffsetsEnum> createOffsetsEnumsFromReader(LeafReader leafReader, int doc) throws IOException {\n    final Terms termsIndex = leafReader.terms(field);\n    if (termsIndex == null) {\n      return Collections.emptyList();\n    }\n\n    final List<OffsetsEnum> offsetsEnums = new ArrayList<>(terms.length + automata.length);\n\n    // Handle position insensitive terms (a subset of this.terms field):\n    final BytesRef[] insensitiveTerms;\n    if (phraseHelper.hasPositionSensitivity()) {\n      insensitiveTerms = phraseHelper.getAllPositionInsensitiveTerms();\n      assert insensitiveTerms.length <= terms.length : \"insensitive terms should be smaller set of all terms\";\n    } else {\n      insensitiveTerms = terms;\n    }\n    if (insensitiveTerms.length > 0) {\n      createOffsetsEnumsForTerms(insensitiveTerms, termsIndex, doc, offsetsEnums);\n    }\n\n    // Handle spans\n    if (phraseHelper.hasPositionSensitivity()) {\n      phraseHelper.createOffsetsEnumsForSpans(leafReader, doc, offsetsEnums);\n    }\n\n    // Handle automata\n    if (automata.length > 0) {\n      createOffsetsEnumsForAutomata(termsIndex, doc, offsetsEnums);\n    }\n\n    return offsetsEnums;\n  }\n\n","sourceOld":"  protected List<OffsetsEnum> createOffsetsEnumsFromReader(LeafReader leafReader, int doc) throws IOException {\n    final Terms termsIndex = leafReader.terms(field);\n    if (termsIndex == null) {\n      return Collections.emptyList();\n    }\n\n    // For strict positions, get a Map of term to Spans:\n    //    note: ScriptPhraseHelper.NONE does the right thing for these method calls\n    final Map<BytesRef, Spans> strictPhrasesTermToSpans =\n        phraseHelper.getTermToSpans(leafReader, doc);\n    // Usually simply wraps terms in a List; but if willRewrite() then can be expanded\n    final List<BytesRef> sourceTerms =\n        phraseHelper.expandTermsIfRewrite(terms, strictPhrasesTermToSpans);\n\n    final List<OffsetsEnum> offsetsEnums = new ArrayList<>(sourceTerms.size() + automata.length);\n\n    // Handle sourceTerms:\n    if (!sourceTerms.isEmpty()) {\n      TermsEnum termsEnum = termsIndex.iterator();//does not return null\n      for (BytesRef term : sourceTerms) {\n        if (termsEnum.seekExact(term)) {\n          PostingsEnum postingsEnum = termsEnum.postings(null, PostingsEnum.OFFSETS);\n\n          if (postingsEnum == null) {\n            // no offsets or positions available\n            throw new IllegalArgumentException(\"field '\" + field + \"' was indexed without offsets, cannot highlight\");\n          }\n\n          if (doc == postingsEnum.advance(doc)) { // now it's positioned, although may be exhausted\n            postingsEnum = phraseHelper.filterPostings(term, postingsEnum, strictPhrasesTermToSpans.get(term));\n            if (postingsEnum != null) {\n              offsetsEnums.add(new OffsetsEnum(term, postingsEnum));\n            }\n          }\n        }\n      }\n    }\n\n    // Handle automata\n    if (automata.length > 0) {\n      offsetsEnums.addAll(createAutomataOffsetsFromTerms(termsIndex, doc));\n    }\n\n    return offsetsEnums;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8764ca7bb74ee716c839b9545a93ec4a578c2005","date":1517564468,"type":5,"author":"Alan Woodward","isMerge":false,"pathNew":"lucene/highlighter/src/java/org/apache/lucene/search/uhighlight/FieldOffsetStrategy#createOffsetsEnumFromReader(LeafReader,int).mjava","pathOld":"lucene/highlighter/src/java/org/apache/lucene/search/uhighlight/FieldOffsetStrategy#createOffsetsEnumsFromReader(LeafReader,int).mjava","sourceNew":"  protected OffsetsEnum createOffsetsEnumFromReader(LeafReader leafReader, int doc) throws IOException {\n    final Terms termsIndex = leafReader.terms(field);\n    if (termsIndex == null) {\n      return OffsetsEnum.EMPTY;\n    }\n\n    final List<OffsetsEnum> offsetsEnums = new ArrayList<>(terms.length + automata.length);\n\n    // Handle position insensitive terms (a subset of this.terms field):\n    final BytesRef[] insensitiveTerms;\n    if (phraseHelper.hasPositionSensitivity()) {\n      insensitiveTerms = phraseHelper.getAllPositionInsensitiveTerms();\n      assert insensitiveTerms.length <= terms.length : \"insensitive terms should be smaller set of all terms\";\n    } else {\n      insensitiveTerms = terms;\n    }\n    if (insensitiveTerms.length > 0) {\n      createOffsetsEnumsForTerms(insensitiveTerms, termsIndex, doc, offsetsEnums);\n    }\n\n    // Handle spans\n    if (phraseHelper.hasPositionSensitivity()) {\n      phraseHelper.createOffsetsEnumsForSpans(leafReader, doc, offsetsEnums);\n    }\n\n    // Handle automata\n    if (automata.length > 0) {\n      createOffsetsEnumsForAutomata(termsIndex, doc, offsetsEnums);\n    }\n\n    return new OffsetsEnum.MultiOffsetsEnum(offsetsEnums);\n  }\n\n","sourceOld":"  protected List<OffsetsEnum> createOffsetsEnumsFromReader(LeafReader leafReader, int doc) throws IOException {\n    final Terms termsIndex = leafReader.terms(field);\n    if (termsIndex == null) {\n      return Collections.emptyList();\n    }\n\n    final List<OffsetsEnum> offsetsEnums = new ArrayList<>(terms.length + automata.length);\n\n    // Handle position insensitive terms (a subset of this.terms field):\n    final BytesRef[] insensitiveTerms;\n    if (phraseHelper.hasPositionSensitivity()) {\n      insensitiveTerms = phraseHelper.getAllPositionInsensitiveTerms();\n      assert insensitiveTerms.length <= terms.length : \"insensitive terms should be smaller set of all terms\";\n    } else {\n      insensitiveTerms = terms;\n    }\n    if (insensitiveTerms.length > 0) {\n      createOffsetsEnumsForTerms(insensitiveTerms, termsIndex, doc, offsetsEnums);\n    }\n\n    // Handle spans\n    if (phraseHelper.hasPositionSensitivity()) {\n      phraseHelper.createOffsetsEnumsForSpans(leafReader, doc, offsetsEnums);\n    }\n\n    // Handle automata\n    if (automata.length > 0) {\n      createOffsetsEnumsForAutomata(termsIndex, doc, offsetsEnums);\n    }\n\n    return offsetsEnums;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"b94236357aaa22b76c10629851fe4e376e0cea82":["f2e9861e4a2b724d9fc51b618714c579491b78d7","eef54e3d232eae0e9fc18d75e9b0c3d9ce04b571"],"f2e9861e4a2b724d9fc51b618714c579491b78d7":["1f5ce59aaf4a055cc9ec62c15a89c263a05ff4b2"],"8764ca7bb74ee716c839b9545a93ec4a578c2005":["b94236357aaa22b76c10629851fe4e376e0cea82"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"a1ef55e1fff7ff44354432770ad8bc19be1fcc75":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b","f2e9861e4a2b724d9fc51b618714c579491b78d7"],"1f5ce59aaf4a055cc9ec62c15a89c263a05ff4b2":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"eef54e3d232eae0e9fc18d75e9b0c3d9ce04b571":["f2e9861e4a2b724d9fc51b618714c579491b78d7"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","1f5ce59aaf4a055cc9ec62c15a89c263a05ff4b2"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["8764ca7bb74ee716c839b9545a93ec4a578c2005"]},"commit2Childs":{"b94236357aaa22b76c10629851fe4e376e0cea82":["8764ca7bb74ee716c839b9545a93ec4a578c2005"],"f2e9861e4a2b724d9fc51b618714c579491b78d7":["b94236357aaa22b76c10629851fe4e376e0cea82","a1ef55e1fff7ff44354432770ad8bc19be1fcc75","eef54e3d232eae0e9fc18d75e9b0c3d9ce04b571"],"8764ca7bb74ee716c839b9545a93ec4a578c2005":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["1f5ce59aaf4a055cc9ec62c15a89c263a05ff4b2","4cce5816ef15a48a0bc11e5d400497ee4301dd3b"],"a1ef55e1fff7ff44354432770ad8bc19be1fcc75":[],"1f5ce59aaf4a055cc9ec62c15a89c263a05ff4b2":["f2e9861e4a2b724d9fc51b618714c579491b78d7","4cce5816ef15a48a0bc11e5d400497ee4301dd3b"],"eef54e3d232eae0e9fc18d75e9b0c3d9ce04b571":["b94236357aaa22b76c10629851fe4e376e0cea82"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["a1ef55e1fff7ff44354432770ad8bc19be1fcc75"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["a1ef55e1fff7ff44354432770ad8bc19be1fcc75","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}