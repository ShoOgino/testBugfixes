{"path":"solr/src/java/org/apache/solr/handler/component/FacetComponent#countFacets(ResponseBuilder,ShardRequest).mjava","commits":[{"id":"893269407f5c988a4b2ee13c7ffc01ec43136c1d","date":1268598046,"type":0,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/src/java/org/apache/solr/handler/component/FacetComponent#countFacets(ResponseBuilder,ShardRequest).mjava","pathOld":"/dev/null","sourceNew":"  private void countFacets(ResponseBuilder rb, ShardRequest sreq) {\n    FacetInfo fi = rb._facetInfo;\n\n    for (ShardResponse srsp: sreq.responses) {\n      int shardNum = rb.getShardNum(srsp.getShard());\n      NamedList facet_counts = (NamedList)srsp.getSolrResponse().getResponse().get(\"facet_counts\");\n\n      // handle facet queries\n      NamedList facet_queries = (NamedList)facet_counts.get(\"facet_queries\");\n      if (facet_queries != null) {\n        for (int i=0; i<facet_queries.size(); i++) {\n          String returnedKey = (String)facet_queries.getName(i);\n          long count = ((Number)facet_queries.getVal(i)).longValue();\n          QueryFacet qf = fi.queryFacets.get(returnedKey);\n          qf.count += count;\n        }\n      }\n\n      // step through each facet.field, adding results from this shard\n      NamedList facet_fields = (NamedList)facet_counts.get(\"facet_fields\");\n      for (DistribFieldFacet dff : fi.facets.values()) {\n        dff.add(shardNum, (NamedList)facet_fields.get(dff.getKey()), dff.initialLimit);\n      }\n    }\n\n\n    //\n    // This code currently assumes that there will be only a single\n    // request ((with responses from all shards) sent out to get facets...\n    // otherwise we would need to wait until all facet responses were received.\n    //\n\n    for (DistribFieldFacet dff : fi.facets.values()) {\n      if (dff.limit <= 0) continue; // no need to check these facets for refinement\n      if (dff.minCount <= 1 && dff.sort.equals(FacetParams.FACET_SORT_INDEX)) continue;\n\n      dff._toRefine = new List[rb.shards.length];\n      ShardFacetCount[] counts = dff.getCountSorted();\n      int ntop = Math.min(counts.length, dff.offset + dff.limit);\n      long smallestCount = counts.length == 0 ? 0 : counts[ntop-1].count;\n\n      for (int i=0; i<counts.length; i++) {\n        ShardFacetCount sfc = counts[i];\n        boolean needRefinement = false;\n\n        if (i<ntop) {\n          // automatically flag the top values for refinement\n          needRefinement = true;\n        } else {\n          // calculate the maximum value that this term may have\n          // and if it is >= smallestCount, then flag for refinement\n          long maxCount = sfc.count;\n          for (int shardNum=0; shardNum<rb.shards.length; shardNum++) {\n            OpenBitSet obs = dff.counted[shardNum];\n            if (!obs.get(sfc.termNum)) {\n              // if missing from this shard, add the max it could be\n              maxCount += dff.maxPossible(sfc,shardNum);\n            }\n          }\n          if (maxCount >= smallestCount) {\n            // TODO: on a tie, we could check the term values\n            needRefinement = true;\n          }\n        }\n\n        if (needRefinement) {\n          // add a query for each shard missing the term that needs refinement\n          for (int shardNum=0; shardNum<rb.shards.length; shardNum++) {\n            OpenBitSet obs = dff.counted[shardNum];\n            if (!obs.get(sfc.termNum) && dff.maxPossible(sfc,shardNum)>0) {\n              dff.needRefinements = true;\n              List<String> lst = dff._toRefine[shardNum];\n              if (lst == null) {\n                lst = dff._toRefine[shardNum] = new ArrayList<String>();\n              }\n              lst.add(sfc.name);\n            }\n          }\n        }\n      }\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a89acb2b4321b599bbfa1e802c00c4dbbc8ee6b8","date":1268599006,"type":4,"author":"Mark Robert Miller","isMerge":false,"pathNew":"/dev/null","pathOld":"solr/src/java/org/apache/solr/handler/component/FacetComponent#countFacets(ResponseBuilder,ShardRequest).mjava","sourceNew":null,"sourceOld":"  private void countFacets(ResponseBuilder rb, ShardRequest sreq) {\n    FacetInfo fi = rb._facetInfo;\n\n    for (ShardResponse srsp: sreq.responses) {\n      int shardNum = rb.getShardNum(srsp.getShard());\n      NamedList facet_counts = (NamedList)srsp.getSolrResponse().getResponse().get(\"facet_counts\");\n\n      // handle facet queries\n      NamedList facet_queries = (NamedList)facet_counts.get(\"facet_queries\");\n      if (facet_queries != null) {\n        for (int i=0; i<facet_queries.size(); i++) {\n          String returnedKey = (String)facet_queries.getName(i);\n          long count = ((Number)facet_queries.getVal(i)).longValue();\n          QueryFacet qf = fi.queryFacets.get(returnedKey);\n          qf.count += count;\n        }\n      }\n\n      // step through each facet.field, adding results from this shard\n      NamedList facet_fields = (NamedList)facet_counts.get(\"facet_fields\");\n      for (DistribFieldFacet dff : fi.facets.values()) {\n        dff.add(shardNum, (NamedList)facet_fields.get(dff.getKey()), dff.initialLimit);\n      }\n    }\n\n\n    //\n    // This code currently assumes that there will be only a single\n    // request ((with responses from all shards) sent out to get facets...\n    // otherwise we would need to wait until all facet responses were received.\n    //\n\n    for (DistribFieldFacet dff : fi.facets.values()) {\n      if (dff.limit <= 0) continue; // no need to check these facets for refinement\n      if (dff.minCount <= 1 && dff.sort.equals(FacetParams.FACET_SORT_INDEX)) continue;\n\n      dff._toRefine = new List[rb.shards.length];\n      ShardFacetCount[] counts = dff.getCountSorted();\n      int ntop = Math.min(counts.length, dff.offset + dff.limit);\n      long smallestCount = counts.length == 0 ? 0 : counts[ntop-1].count;\n\n      for (int i=0; i<counts.length; i++) {\n        ShardFacetCount sfc = counts[i];\n        boolean needRefinement = false;\n\n        if (i<ntop) {\n          // automatically flag the top values for refinement\n          needRefinement = true;\n        } else {\n          // calculate the maximum value that this term may have\n          // and if it is >= smallestCount, then flag for refinement\n          long maxCount = sfc.count;\n          for (int shardNum=0; shardNum<rb.shards.length; shardNum++) {\n            OpenBitSet obs = dff.counted[shardNum];\n            if (!obs.get(sfc.termNum)) {\n              // if missing from this shard, add the max it could be\n              maxCount += dff.maxPossible(sfc,shardNum);\n            }\n          }\n          if (maxCount >= smallestCount) {\n            // TODO: on a tie, we could check the term values\n            needRefinement = true;\n          }\n        }\n\n        if (needRefinement) {\n          // add a query for each shard missing the term that needs refinement\n          for (int shardNum=0; shardNum<rb.shards.length; shardNum++) {\n            OpenBitSet obs = dff.counted[shardNum];\n            if (!obs.get(sfc.termNum) && dff.maxPossible(sfc,shardNum)>0) {\n              dff.needRefinements = true;\n              List<String> lst = dff._toRefine[shardNum];\n              if (lst == null) {\n                lst = dff._toRefine[shardNum] = new ArrayList<String>();\n              }\n              lst.add(sfc.name);\n            }\n          }\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ad94625fb8d088209f46650c8097196fec67f00c","date":1453508319,"type":1,"author":"Dawid Weiss","isMerge":false,"pathNew":"solr/src/java/org/apache/solr/handler/component/FacetComponent#countFacets(ResponseBuilder,ShardRequest).mjava","pathOld":"src/java/org/apache/solr/handler/component/FacetComponent#countFacets(ResponseBuilder,ShardRequest).mjava","sourceNew":"  private void countFacets(ResponseBuilder rb, ShardRequest sreq) {\n    FacetInfo fi = rb._facetInfo;\n\n    for (ShardResponse srsp: sreq.responses) {\n      int shardNum = rb.getShardNum(srsp.getShard());\n      NamedList facet_counts = (NamedList)srsp.getSolrResponse().getResponse().get(\"facet_counts\");\n\n      // handle facet queries\n      NamedList facet_queries = (NamedList)facet_counts.get(\"facet_queries\");\n      if (facet_queries != null) {\n        for (int i=0; i<facet_queries.size(); i++) {\n          String returnedKey = (String)facet_queries.getName(i);\n          long count = ((Number)facet_queries.getVal(i)).longValue();\n          QueryFacet qf = fi.queryFacets.get(returnedKey);\n          qf.count += count;\n        }\n      }\n\n      // step through each facet.field, adding results from this shard\n      NamedList facet_fields = (NamedList)facet_counts.get(\"facet_fields\");\n      for (DistribFieldFacet dff : fi.facets.values()) {\n        dff.add(shardNum, (NamedList)facet_fields.get(dff.getKey()), dff.initialLimit);\n      }\n    }\n\n\n    //\n    // This code currently assumes that there will be only a single\n    // request ((with responses from all shards) sent out to get facets...\n    // otherwise we would need to wait until all facet responses were received.\n    //\n\n    for (DistribFieldFacet dff : fi.facets.values()) {\n      if (dff.limit <= 0) continue; // no need to check these facets for refinement\n      if (dff.minCount <= 1 && dff.sort.equals(FacetParams.FACET_SORT_INDEX)) continue;\n\n      dff._toRefine = new List[rb.shards.length];\n      ShardFacetCount[] counts = dff.getCountSorted();\n      int ntop = Math.min(counts.length, dff.offset + dff.limit);\n      long smallestCount = counts.length == 0 ? 0 : counts[ntop-1].count;\n\n      for (int i=0; i<counts.length; i++) {\n        ShardFacetCount sfc = counts[i];\n        boolean needRefinement = false;\n\n        if (i<ntop) {\n          // automatically flag the top values for refinement\n          needRefinement = true;\n        } else {\n          // calculate the maximum value that this term may have\n          // and if it is >= smallestCount, then flag for refinement\n          long maxCount = sfc.count;\n          for (int shardNum=0; shardNum<rb.shards.length; shardNum++) {\n            OpenBitSet obs = dff.counted[shardNum];\n            if (!obs.get(sfc.termNum)) {\n              // if missing from this shard, add the max it could be\n              maxCount += dff.maxPossible(sfc,shardNum);\n            }\n          }\n          if (maxCount >= smallestCount) {\n            // TODO: on a tie, we could check the term values\n            needRefinement = true;\n          }\n        }\n\n        if (needRefinement) {\n          // add a query for each shard missing the term that needs refinement\n          for (int shardNum=0; shardNum<rb.shards.length; shardNum++) {\n            OpenBitSet obs = dff.counted[shardNum];\n            if (!obs.get(sfc.termNum) && dff.maxPossible(sfc,shardNum)>0) {\n              dff.needRefinements = true;\n              List<String> lst = dff._toRefine[shardNum];\n              if (lst == null) {\n                lst = dff._toRefine[shardNum] = new ArrayList<String>();\n              }\n              lst.add(sfc.name);\n            }\n          }\n        }\n      }\n    }\n  }\n\n","sourceOld":"  private void countFacets(ResponseBuilder rb, ShardRequest sreq) {\n    FacetInfo fi = rb._facetInfo;\n\n    for (ShardResponse srsp: sreq.responses) {\n      int shardNum = rb.getShardNum(srsp.getShard());\n      NamedList facet_counts = (NamedList)srsp.getSolrResponse().getResponse().get(\"facet_counts\");\n\n      // handle facet queries\n      NamedList facet_queries = (NamedList)facet_counts.get(\"facet_queries\");\n      if (facet_queries != null) {\n        for (int i=0; i<facet_queries.size(); i++) {\n          String returnedKey = (String)facet_queries.getName(i);\n          long count = ((Number)facet_queries.getVal(i)).longValue();\n          QueryFacet qf = fi.queryFacets.get(returnedKey);\n          qf.count += count;\n        }\n      }\n\n      // step through each facet.field, adding results from this shard\n      NamedList facet_fields = (NamedList)facet_counts.get(\"facet_fields\");\n      for (DistribFieldFacet dff : fi.facets.values()) {\n        dff.add(shardNum, (NamedList)facet_fields.get(dff.getKey()), dff.initialLimit);\n      }\n    }\n\n\n    //\n    // This code currently assumes that there will be only a single\n    // request ((with responses from all shards) sent out to get facets...\n    // otherwise we would need to wait until all facet responses were received.\n    //\n\n    for (DistribFieldFacet dff : fi.facets.values()) {\n      if (dff.limit <= 0) continue; // no need to check these facets for refinement\n      if (dff.minCount <= 1 && dff.sort.equals(FacetParams.FACET_SORT_INDEX)) continue;\n\n      dff._toRefine = new List[rb.shards.length];\n      ShardFacetCount[] counts = dff.getCountSorted();\n      int ntop = Math.min(counts.length, dff.offset + dff.limit);\n      long smallestCount = counts.length == 0 ? 0 : counts[ntop-1].count;\n\n      for (int i=0; i<counts.length; i++) {\n        ShardFacetCount sfc = counts[i];\n        boolean needRefinement = false;\n\n        if (i<ntop) {\n          // automatically flag the top values for refinement\n          needRefinement = true;\n        } else {\n          // calculate the maximum value that this term may have\n          // and if it is >= smallestCount, then flag for refinement\n          long maxCount = sfc.count;\n          for (int shardNum=0; shardNum<rb.shards.length; shardNum++) {\n            OpenBitSet obs = dff.counted[shardNum];\n            if (!obs.get(sfc.termNum)) {\n              // if missing from this shard, add the max it could be\n              maxCount += dff.maxPossible(sfc,shardNum);\n            }\n          }\n          if (maxCount >= smallestCount) {\n            // TODO: on a tie, we could check the term values\n            needRefinement = true;\n          }\n        }\n\n        if (needRefinement) {\n          // add a query for each shard missing the term that needs refinement\n          for (int shardNum=0; shardNum<rb.shards.length; shardNum++) {\n            OpenBitSet obs = dff.counted[shardNum];\n            if (!obs.get(sfc.termNum) && dff.maxPossible(sfc,shardNum)>0) {\n              dff.needRefinements = true;\n              List<String> lst = dff._toRefine[shardNum];\n              if (lst == null) {\n                lst = dff._toRefine[shardNum] = new ArrayList<String>();\n              }\n              lst.add(sfc.name);\n            }\n          }\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1da8d55113b689b06716246649de6f62430f15c0","date":1453508340,"type":0,"author":"Dawid Weiss","isMerge":true,"pathNew":"solr/src/java/org/apache/solr/handler/component/FacetComponent#countFacets(ResponseBuilder,ShardRequest).mjava","pathOld":"/dev/null","sourceNew":"  private void countFacets(ResponseBuilder rb, ShardRequest sreq) {\n    FacetInfo fi = rb._facetInfo;\n\n    for (ShardResponse srsp: sreq.responses) {\n      int shardNum = rb.getShardNum(srsp.getShard());\n      NamedList facet_counts = (NamedList)srsp.getSolrResponse().getResponse().get(\"facet_counts\");\n\n      // handle facet queries\n      NamedList facet_queries = (NamedList)facet_counts.get(\"facet_queries\");\n      if (facet_queries != null) {\n        for (int i=0; i<facet_queries.size(); i++) {\n          String returnedKey = (String)facet_queries.getName(i);\n          long count = ((Number)facet_queries.getVal(i)).longValue();\n          QueryFacet qf = fi.queryFacets.get(returnedKey);\n          qf.count += count;\n        }\n      }\n\n      // step through each facet.field, adding results from this shard\n      NamedList facet_fields = (NamedList)facet_counts.get(\"facet_fields\");\n      for (DistribFieldFacet dff : fi.facets.values()) {\n        dff.add(shardNum, (NamedList)facet_fields.get(dff.getKey()), dff.initialLimit);\n      }\n    }\n\n\n    //\n    // This code currently assumes that there will be only a single\n    // request ((with responses from all shards) sent out to get facets...\n    // otherwise we would need to wait until all facet responses were received.\n    //\n\n    for (DistribFieldFacet dff : fi.facets.values()) {\n      if (dff.limit <= 0) continue; // no need to check these facets for refinement\n      if (dff.minCount <= 1 && dff.sort.equals(FacetParams.FACET_SORT_INDEX)) continue;\n\n      dff._toRefine = new List[rb.shards.length];\n      ShardFacetCount[] counts = dff.getCountSorted();\n      int ntop = Math.min(counts.length, dff.offset + dff.limit);\n      long smallestCount = counts.length == 0 ? 0 : counts[ntop-1].count;\n\n      for (int i=0; i<counts.length; i++) {\n        ShardFacetCount sfc = counts[i];\n        boolean needRefinement = false;\n\n        if (i<ntop) {\n          // automatically flag the top values for refinement\n          needRefinement = true;\n        } else {\n          // calculate the maximum value that this term may have\n          // and if it is >= smallestCount, then flag for refinement\n          long maxCount = sfc.count;\n          for (int shardNum=0; shardNum<rb.shards.length; shardNum++) {\n            OpenBitSet obs = dff.counted[shardNum];\n            if (!obs.get(sfc.termNum)) {\n              // if missing from this shard, add the max it could be\n              maxCount += dff.maxPossible(sfc,shardNum);\n            }\n          }\n          if (maxCount >= smallestCount) {\n            // TODO: on a tie, we could check the term values\n            needRefinement = true;\n          }\n        }\n\n        if (needRefinement) {\n          // add a query for each shard missing the term that needs refinement\n          for (int shardNum=0; shardNum<rb.shards.length; shardNum++) {\n            OpenBitSet obs = dff.counted[shardNum];\n            if (!obs.get(sfc.termNum) && dff.maxPossible(sfc,shardNum)>0) {\n              dff.needRefinements = true;\n              List<String> lst = dff._toRefine[shardNum];\n              if (lst == null) {\n                lst = dff._toRefine[shardNum] = new ArrayList<String>();\n              }\n              lst.add(sfc.name);\n            }\n          }\n        }\n      }\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"12064130393504cdb2782da654893641a6596056","date":1269379921,"type":3,"author":"Yonik Seeley","isMerge":false,"pathNew":"solr/src/java/org/apache/solr/handler/component/FacetComponent#countFacets(ResponseBuilder,ShardRequest).mjava","pathOld":"solr/src/java/org/apache/solr/handler/component/FacetComponent#countFacets(ResponseBuilder,ShardRequest).mjava","sourceNew":"  private void countFacets(ResponseBuilder rb, ShardRequest sreq) {\n    FacetInfo fi = rb._facetInfo;\n\n    for (ShardResponse srsp: sreq.responses) {\n      int shardNum = rb.getShardNum(srsp.getShard());\n      NamedList facet_counts = (NamedList)srsp.getSolrResponse().getResponse().get(\"facet_counts\");\n\n      // handle facet queries\n      NamedList facet_queries = (NamedList)facet_counts.get(\"facet_queries\");\n      if (facet_queries != null) {\n        for (int i=0; i<facet_queries.size(); i++) {\n          String returnedKey = (String)facet_queries.getName(i);\n          long count = ((Number)facet_queries.getVal(i)).longValue();\n          QueryFacet qf = fi.queryFacets.get(returnedKey);\n          qf.count += count;\n        }\n      }\n\n      // step through each facet.field, adding results from this shard\n      NamedList facet_fields = (NamedList)facet_counts.get(\"facet_fields\");\n\n      // an error could cause facet_fields to come back null\n      if (facet_fields == null) {\n        String msg = (String)facet_counts.get(\"exception\");\n        if (msg == null) msg = \"faceting exception in sub-request - missing facet_fields\";\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, msg);\n\n      }\n\n      for (DistribFieldFacet dff : fi.facets.values()) {\n        dff.add(shardNum, (NamedList)facet_fields.get(dff.getKey()), dff.initialLimit);\n      }\n    }\n\n\n    //\n    // This code currently assumes that there will be only a single\n    // request ((with responses from all shards) sent out to get facets...\n    // otherwise we would need to wait until all facet responses were received.\n    //\n\n    for (DistribFieldFacet dff : fi.facets.values()) {\n      if (dff.limit <= 0) continue; // no need to check these facets for refinement\n      if (dff.minCount <= 1 && dff.sort.equals(FacetParams.FACET_SORT_INDEX)) continue;\n\n      dff._toRefine = new List[rb.shards.length];\n      ShardFacetCount[] counts = dff.getCountSorted();\n      int ntop = Math.min(counts.length, dff.offset + dff.limit);\n      long smallestCount = counts.length == 0 ? 0 : counts[ntop-1].count;\n\n      for (int i=0; i<counts.length; i++) {\n        ShardFacetCount sfc = counts[i];\n        boolean needRefinement = false;\n\n        if (i<ntop) {\n          // automatically flag the top values for refinement\n          needRefinement = true;\n        } else {\n          // calculate the maximum value that this term may have\n          // and if it is >= smallestCount, then flag for refinement\n          long maxCount = sfc.count;\n          for (int shardNum=0; shardNum<rb.shards.length; shardNum++) {\n            OpenBitSet obs = dff.counted[shardNum];\n            if (!obs.get(sfc.termNum)) {\n              // if missing from this shard, add the max it could be\n              maxCount += dff.maxPossible(sfc,shardNum);\n            }\n          }\n          if (maxCount >= smallestCount) {\n            // TODO: on a tie, we could check the term values\n            needRefinement = true;\n          }\n        }\n\n        if (needRefinement) {\n          // add a query for each shard missing the term that needs refinement\n          for (int shardNum=0; shardNum<rb.shards.length; shardNum++) {\n            OpenBitSet obs = dff.counted[shardNum];\n            if (!obs.get(sfc.termNum) && dff.maxPossible(sfc,shardNum)>0) {\n              dff.needRefinements = true;\n              List<String> lst = dff._toRefine[shardNum];\n              if (lst == null) {\n                lst = dff._toRefine[shardNum] = new ArrayList<String>();\n              }\n              lst.add(sfc.name);\n            }\n          }\n        }\n      }\n    }\n  }\n\n","sourceOld":"  private void countFacets(ResponseBuilder rb, ShardRequest sreq) {\n    FacetInfo fi = rb._facetInfo;\n\n    for (ShardResponse srsp: sreq.responses) {\n      int shardNum = rb.getShardNum(srsp.getShard());\n      NamedList facet_counts = (NamedList)srsp.getSolrResponse().getResponse().get(\"facet_counts\");\n\n      // handle facet queries\n      NamedList facet_queries = (NamedList)facet_counts.get(\"facet_queries\");\n      if (facet_queries != null) {\n        for (int i=0; i<facet_queries.size(); i++) {\n          String returnedKey = (String)facet_queries.getName(i);\n          long count = ((Number)facet_queries.getVal(i)).longValue();\n          QueryFacet qf = fi.queryFacets.get(returnedKey);\n          qf.count += count;\n        }\n      }\n\n      // step through each facet.field, adding results from this shard\n      NamedList facet_fields = (NamedList)facet_counts.get(\"facet_fields\");\n      for (DistribFieldFacet dff : fi.facets.values()) {\n        dff.add(shardNum, (NamedList)facet_fields.get(dff.getKey()), dff.initialLimit);\n      }\n    }\n\n\n    //\n    // This code currently assumes that there will be only a single\n    // request ((with responses from all shards) sent out to get facets...\n    // otherwise we would need to wait until all facet responses were received.\n    //\n\n    for (DistribFieldFacet dff : fi.facets.values()) {\n      if (dff.limit <= 0) continue; // no need to check these facets for refinement\n      if (dff.minCount <= 1 && dff.sort.equals(FacetParams.FACET_SORT_INDEX)) continue;\n\n      dff._toRefine = new List[rb.shards.length];\n      ShardFacetCount[] counts = dff.getCountSorted();\n      int ntop = Math.min(counts.length, dff.offset + dff.limit);\n      long smallestCount = counts.length == 0 ? 0 : counts[ntop-1].count;\n\n      for (int i=0; i<counts.length; i++) {\n        ShardFacetCount sfc = counts[i];\n        boolean needRefinement = false;\n\n        if (i<ntop) {\n          // automatically flag the top values for refinement\n          needRefinement = true;\n        } else {\n          // calculate the maximum value that this term may have\n          // and if it is >= smallestCount, then flag for refinement\n          long maxCount = sfc.count;\n          for (int shardNum=0; shardNum<rb.shards.length; shardNum++) {\n            OpenBitSet obs = dff.counted[shardNum];\n            if (!obs.get(sfc.termNum)) {\n              // if missing from this shard, add the max it could be\n              maxCount += dff.maxPossible(sfc,shardNum);\n            }\n          }\n          if (maxCount >= smallestCount) {\n            // TODO: on a tie, we could check the term values\n            needRefinement = true;\n          }\n        }\n\n        if (needRefinement) {\n          // add a query for each shard missing the term that needs refinement\n          for (int shardNum=0; shardNum<rb.shards.length; shardNum++) {\n            OpenBitSet obs = dff.counted[shardNum];\n            if (!obs.get(sfc.termNum) && dff.maxPossible(sfc,shardNum)>0) {\n              dff.needRefinements = true;\n              List<String> lst = dff._toRefine[shardNum];\n              if (lst == null) {\n                lst = dff._toRefine[shardNum] = new ArrayList<String>();\n              }\n              lst.add(sfc.name);\n            }\n          }\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":["ef02613bb5b67b98ca5caf41e8d6e016a0158923"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"ef02613bb5b67b98ca5caf41e8d6e016a0158923","date":1283980033,"type":3,"author":"Yonik Seeley","isMerge":false,"pathNew":"solr/src/java/org/apache/solr/handler/component/FacetComponent#countFacets(ResponseBuilder,ShardRequest).mjava","pathOld":"solr/src/java/org/apache/solr/handler/component/FacetComponent#countFacets(ResponseBuilder,ShardRequest).mjava","sourceNew":"  private void countFacets(ResponseBuilder rb, ShardRequest sreq) {\n    FacetInfo fi = rb._facetInfo;\n\n    for (ShardResponse srsp: sreq.responses) {\n      int shardNum = rb.getShardNum(srsp.getShard());\n      NamedList facet_counts = (NamedList)srsp.getSolrResponse().getResponse().get(\"facet_counts\");\n\n      fi.addExceptions((List)facet_counts.get(\"exception\"));\n\n      // handle facet queries\n      NamedList facet_queries = (NamedList)facet_counts.get(\"facet_queries\");\n      if (facet_queries != null) {\n        for (int i=0; i<facet_queries.size(); i++) {\n          String returnedKey = (String)facet_queries.getName(i);\n          long count = ((Number)facet_queries.getVal(i)).longValue();\n          QueryFacet qf = fi.queryFacets.get(returnedKey);\n          qf.count += count;\n        }\n      }\n\n      // step through each facet.field, adding results from this shard\n      NamedList facet_fields = (NamedList)facet_counts.get(\"facet_fields\");\n    \n      if (facet_fields != null) {\n        for (DistribFieldFacet dff : fi.facets.values()) {\n          dff.add(shardNum, (NamedList)facet_fields.get(dff.getKey()), dff.initialLimit);\n        }\n      }\n    }\n\n\n    //\n    // This code currently assumes that there will be only a single\n    // request ((with responses from all shards) sent out to get facets...\n    // otherwise we would need to wait until all facet responses were received.\n    //\n\n    for (DistribFieldFacet dff : fi.facets.values()) {\n      if (dff.limit <= 0) continue; // no need to check these facets for refinement\n      if (dff.minCount <= 1 && dff.sort.equals(FacetParams.FACET_SORT_INDEX)) continue;\n\n      dff._toRefine = new List[rb.shards.length];\n      ShardFacetCount[] counts = dff.getCountSorted();\n      int ntop = Math.min(counts.length, dff.offset + dff.limit);\n      long smallestCount = counts.length == 0 ? 0 : counts[ntop-1].count;\n\n      for (int i=0; i<counts.length; i++) {\n        ShardFacetCount sfc = counts[i];\n        boolean needRefinement = false;\n\n        if (i<ntop) {\n          // automatically flag the top values for refinement\n          needRefinement = true;\n        } else {\n          // calculate the maximum value that this term may have\n          // and if it is >= smallestCount, then flag for refinement\n          long maxCount = sfc.count;\n          for (int shardNum=0; shardNum<rb.shards.length; shardNum++) {\n            OpenBitSet obs = dff.counted[shardNum];\n            if (!obs.get(sfc.termNum)) {\n              // if missing from this shard, add the max it could be\n              maxCount += dff.maxPossible(sfc,shardNum);\n            }\n          }\n          if (maxCount >= smallestCount) {\n            // TODO: on a tie, we could check the term values\n            needRefinement = true;\n          }\n        }\n\n        if (needRefinement) {\n          // add a query for each shard missing the term that needs refinement\n          for (int shardNum=0; shardNum<rb.shards.length; shardNum++) {\n            OpenBitSet obs = dff.counted[shardNum];\n            if (!obs.get(sfc.termNum) && dff.maxPossible(sfc,shardNum)>0) {\n              dff.needRefinements = true;\n              List<String> lst = dff._toRefine[shardNum];\n              if (lst == null) {\n                lst = dff._toRefine[shardNum] = new ArrayList<String>();\n              }\n              lst.add(sfc.name);\n            }\n          }\n        }\n      }\n    }\n  }\n\n","sourceOld":"  private void countFacets(ResponseBuilder rb, ShardRequest sreq) {\n    FacetInfo fi = rb._facetInfo;\n\n    for (ShardResponse srsp: sreq.responses) {\n      int shardNum = rb.getShardNum(srsp.getShard());\n      NamedList facet_counts = (NamedList)srsp.getSolrResponse().getResponse().get(\"facet_counts\");\n\n      // handle facet queries\n      NamedList facet_queries = (NamedList)facet_counts.get(\"facet_queries\");\n      if (facet_queries != null) {\n        for (int i=0; i<facet_queries.size(); i++) {\n          String returnedKey = (String)facet_queries.getName(i);\n          long count = ((Number)facet_queries.getVal(i)).longValue();\n          QueryFacet qf = fi.queryFacets.get(returnedKey);\n          qf.count += count;\n        }\n      }\n\n      // step through each facet.field, adding results from this shard\n      NamedList facet_fields = (NamedList)facet_counts.get(\"facet_fields\");\n\n      // an error could cause facet_fields to come back null\n      if (facet_fields == null) {\n        String msg = (String)facet_counts.get(\"exception\");\n        if (msg == null) msg = \"faceting exception in sub-request - missing facet_fields\";\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, msg);\n\n      }\n\n      for (DistribFieldFacet dff : fi.facets.values()) {\n        dff.add(shardNum, (NamedList)facet_fields.get(dff.getKey()), dff.initialLimit);\n      }\n    }\n\n\n    //\n    // This code currently assumes that there will be only a single\n    // request ((with responses from all shards) sent out to get facets...\n    // otherwise we would need to wait until all facet responses were received.\n    //\n\n    for (DistribFieldFacet dff : fi.facets.values()) {\n      if (dff.limit <= 0) continue; // no need to check these facets for refinement\n      if (dff.minCount <= 1 && dff.sort.equals(FacetParams.FACET_SORT_INDEX)) continue;\n\n      dff._toRefine = new List[rb.shards.length];\n      ShardFacetCount[] counts = dff.getCountSorted();\n      int ntop = Math.min(counts.length, dff.offset + dff.limit);\n      long smallestCount = counts.length == 0 ? 0 : counts[ntop-1].count;\n\n      for (int i=0; i<counts.length; i++) {\n        ShardFacetCount sfc = counts[i];\n        boolean needRefinement = false;\n\n        if (i<ntop) {\n          // automatically flag the top values for refinement\n          needRefinement = true;\n        } else {\n          // calculate the maximum value that this term may have\n          // and if it is >= smallestCount, then flag for refinement\n          long maxCount = sfc.count;\n          for (int shardNum=0; shardNum<rb.shards.length; shardNum++) {\n            OpenBitSet obs = dff.counted[shardNum];\n            if (!obs.get(sfc.termNum)) {\n              // if missing from this shard, add the max it could be\n              maxCount += dff.maxPossible(sfc,shardNum);\n            }\n          }\n          if (maxCount >= smallestCount) {\n            // TODO: on a tie, we could check the term values\n            needRefinement = true;\n          }\n        }\n\n        if (needRefinement) {\n          // add a query for each shard missing the term that needs refinement\n          for (int shardNum=0; shardNum<rb.shards.length; shardNum++) {\n            OpenBitSet obs = dff.counted[shardNum];\n            if (!obs.get(sfc.termNum) && dff.maxPossible(sfc,shardNum)>0) {\n              dff.needRefinements = true;\n              List<String> lst = dff._toRefine[shardNum];\n              if (lst == null) {\n                lst = dff._toRefine[shardNum] = new ArrayList<String>();\n              }\n              lst.add(sfc.name);\n            }\n          }\n        }\n      }\n    }\n  }\n\n","bugFix":["12064130393504cdb2782da654893641a6596056","e5a95ce1d7a3779af6db59b6b39d3b89172d7445","9cb179b2fab2183d2f6041e450ff8022c592ecf0"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"3f7e3e91f914e6265ed09a3208cc60c9ba2a477d","date":1286157263,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"solr/src/java/org/apache/solr/handler/component/FacetComponent#countFacets(ResponseBuilder,ShardRequest).mjava","pathOld":"solr/src/java/org/apache/solr/handler/component/FacetComponent#countFacets(ResponseBuilder,ShardRequest).mjava","sourceNew":"  private void countFacets(ResponseBuilder rb, ShardRequest sreq) {\n    FacetInfo fi = rb._facetInfo;\n\n    for (ShardResponse srsp: sreq.responses) {\n      int shardNum = rb.getShardNum(srsp.getShard());\n      NamedList facet_counts = (NamedList)srsp.getSolrResponse().getResponse().get(\"facet_counts\");\n\n      fi.addExceptions((List)facet_counts.get(\"exception\"));\n\n      // handle facet queries\n      NamedList facet_queries = (NamedList)facet_counts.get(\"facet_queries\");\n      if (facet_queries != null) {\n        for (int i=0; i<facet_queries.size(); i++) {\n          String returnedKey = facet_queries.getName(i);\n          long count = ((Number)facet_queries.getVal(i)).longValue();\n          QueryFacet qf = fi.queryFacets.get(returnedKey);\n          qf.count += count;\n        }\n      }\n\n      // step through each facet.field, adding results from this shard\n      NamedList facet_fields = (NamedList)facet_counts.get(\"facet_fields\");\n    \n      if (facet_fields != null) {\n        for (DistribFieldFacet dff : fi.facets.values()) {\n          dff.add(shardNum, (NamedList)facet_fields.get(dff.getKey()), dff.initialLimit);\n        }\n      }\n    }\n\n\n    //\n    // This code currently assumes that there will be only a single\n    // request ((with responses from all shards) sent out to get facets...\n    // otherwise we would need to wait until all facet responses were received.\n    //\n\n    for (DistribFieldFacet dff : fi.facets.values()) {\n      if (dff.limit <= 0) continue; // no need to check these facets for refinement\n      if (dff.minCount <= 1 && dff.sort.equals(FacetParams.FACET_SORT_INDEX)) continue;\n\n      dff._toRefine = new List[rb.shards.length];\n      ShardFacetCount[] counts = dff.getCountSorted();\n      int ntop = Math.min(counts.length, dff.offset + dff.limit);\n      long smallestCount = counts.length == 0 ? 0 : counts[ntop-1].count;\n\n      for (int i=0; i<counts.length; i++) {\n        ShardFacetCount sfc = counts[i];\n        boolean needRefinement = false;\n\n        if (i<ntop) {\n          // automatically flag the top values for refinement\n          needRefinement = true;\n        } else {\n          // calculate the maximum value that this term may have\n          // and if it is >= smallestCount, then flag for refinement\n          long maxCount = sfc.count;\n          for (int shardNum=0; shardNum<rb.shards.length; shardNum++) {\n            OpenBitSet obs = dff.counted[shardNum];\n            if (!obs.get(sfc.termNum)) {\n              // if missing from this shard, add the max it could be\n              maxCount += dff.maxPossible(sfc,shardNum);\n            }\n          }\n          if (maxCount >= smallestCount) {\n            // TODO: on a tie, we could check the term values\n            needRefinement = true;\n          }\n        }\n\n        if (needRefinement) {\n          // add a query for each shard missing the term that needs refinement\n          for (int shardNum=0; shardNum<rb.shards.length; shardNum++) {\n            OpenBitSet obs = dff.counted[shardNum];\n            if (!obs.get(sfc.termNum) && dff.maxPossible(sfc,shardNum)>0) {\n              dff.needRefinements = true;\n              List<String> lst = dff._toRefine[shardNum];\n              if (lst == null) {\n                lst = dff._toRefine[shardNum] = new ArrayList<String>();\n              }\n              lst.add(sfc.name);\n            }\n          }\n        }\n      }\n    }\n  }\n\n","sourceOld":"  private void countFacets(ResponseBuilder rb, ShardRequest sreq) {\n    FacetInfo fi = rb._facetInfo;\n\n    for (ShardResponse srsp: sreq.responses) {\n      int shardNum = rb.getShardNum(srsp.getShard());\n      NamedList facet_counts = (NamedList)srsp.getSolrResponse().getResponse().get(\"facet_counts\");\n\n      fi.addExceptions((List)facet_counts.get(\"exception\"));\n\n      // handle facet queries\n      NamedList facet_queries = (NamedList)facet_counts.get(\"facet_queries\");\n      if (facet_queries != null) {\n        for (int i=0; i<facet_queries.size(); i++) {\n          String returnedKey = (String)facet_queries.getName(i);\n          long count = ((Number)facet_queries.getVal(i)).longValue();\n          QueryFacet qf = fi.queryFacets.get(returnedKey);\n          qf.count += count;\n        }\n      }\n\n      // step through each facet.field, adding results from this shard\n      NamedList facet_fields = (NamedList)facet_counts.get(\"facet_fields\");\n    \n      if (facet_fields != null) {\n        for (DistribFieldFacet dff : fi.facets.values()) {\n          dff.add(shardNum, (NamedList)facet_fields.get(dff.getKey()), dff.initialLimit);\n        }\n      }\n    }\n\n\n    //\n    // This code currently assumes that there will be only a single\n    // request ((with responses from all shards) sent out to get facets...\n    // otherwise we would need to wait until all facet responses were received.\n    //\n\n    for (DistribFieldFacet dff : fi.facets.values()) {\n      if (dff.limit <= 0) continue; // no need to check these facets for refinement\n      if (dff.minCount <= 1 && dff.sort.equals(FacetParams.FACET_SORT_INDEX)) continue;\n\n      dff._toRefine = new List[rb.shards.length];\n      ShardFacetCount[] counts = dff.getCountSorted();\n      int ntop = Math.min(counts.length, dff.offset + dff.limit);\n      long smallestCount = counts.length == 0 ? 0 : counts[ntop-1].count;\n\n      for (int i=0; i<counts.length; i++) {\n        ShardFacetCount sfc = counts[i];\n        boolean needRefinement = false;\n\n        if (i<ntop) {\n          // automatically flag the top values for refinement\n          needRefinement = true;\n        } else {\n          // calculate the maximum value that this term may have\n          // and if it is >= smallestCount, then flag for refinement\n          long maxCount = sfc.count;\n          for (int shardNum=0; shardNum<rb.shards.length; shardNum++) {\n            OpenBitSet obs = dff.counted[shardNum];\n            if (!obs.get(sfc.termNum)) {\n              // if missing from this shard, add the max it could be\n              maxCount += dff.maxPossible(sfc,shardNum);\n            }\n          }\n          if (maxCount >= smallestCount) {\n            // TODO: on a tie, we could check the term values\n            needRefinement = true;\n          }\n        }\n\n        if (needRefinement) {\n          // add a query for each shard missing the term that needs refinement\n          for (int shardNum=0; shardNum<rb.shards.length; shardNum++) {\n            OpenBitSet obs = dff.counted[shardNum];\n            if (!obs.get(sfc.termNum) && dff.maxPossible(sfc,shardNum)>0) {\n              dff.needRefinements = true;\n              List<String> lst = dff._toRefine[shardNum];\n              if (lst == null) {\n                lst = dff._toRefine[shardNum] = new ArrayList<String>();\n              }\n              lst.add(sfc.name);\n            }\n          }\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","date":1292920096,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"solr/src/java/org/apache/solr/handler/component/FacetComponent#countFacets(ResponseBuilder,ShardRequest).mjava","pathOld":"solr/src/java/org/apache/solr/handler/component/FacetComponent#countFacets(ResponseBuilder,ShardRequest).mjava","sourceNew":"  private void countFacets(ResponseBuilder rb, ShardRequest sreq) {\n    FacetInfo fi = rb._facetInfo;\n\n    for (ShardResponse srsp: sreq.responses) {\n      int shardNum = rb.getShardNum(srsp.getShard());\n      NamedList facet_counts = (NamedList)srsp.getSolrResponse().getResponse().get(\"facet_counts\");\n\n      fi.addExceptions((List)facet_counts.get(\"exception\"));\n\n      // handle facet queries\n      NamedList facet_queries = (NamedList)facet_counts.get(\"facet_queries\");\n      if (facet_queries != null) {\n        for (int i=0; i<facet_queries.size(); i++) {\n          String returnedKey = facet_queries.getName(i);\n          long count = ((Number)facet_queries.getVal(i)).longValue();\n          QueryFacet qf = fi.queryFacets.get(returnedKey);\n          qf.count += count;\n        }\n      }\n\n      // step through each facet.field, adding results from this shard\n      NamedList facet_fields = (NamedList)facet_counts.get(\"facet_fields\");\n    \n      if (facet_fields != null) {\n        for (DistribFieldFacet dff : fi.facets.values()) {\n          dff.add(shardNum, (NamedList)facet_fields.get(dff.getKey()), dff.initialLimit);\n        }\n      }\n    }\n\n\n    //\n    // This code currently assumes that there will be only a single\n    // request ((with responses from all shards) sent out to get facets...\n    // otherwise we would need to wait until all facet responses were received.\n    //\n\n    for (DistribFieldFacet dff : fi.facets.values()) {\n      if (dff.limit <= 0) continue; // no need to check these facets for refinement\n      if (dff.minCount <= 1 && dff.sort.equals(FacetParams.FACET_SORT_INDEX)) continue;\n\n      dff._toRefine = new List[rb.shards.length];\n      ShardFacetCount[] counts = dff.getCountSorted();\n      int ntop = Math.min(counts.length, dff.offset + dff.limit);\n      long smallestCount = counts.length == 0 ? 0 : counts[ntop-1].count;\n\n      for (int i=0; i<counts.length; i++) {\n        ShardFacetCount sfc = counts[i];\n        boolean needRefinement = false;\n\n        if (i<ntop) {\n          // automatically flag the top values for refinement\n          needRefinement = true;\n        } else {\n          // calculate the maximum value that this term may have\n          // and if it is >= smallestCount, then flag for refinement\n          long maxCount = sfc.count;\n          for (int shardNum=0; shardNum<rb.shards.length; shardNum++) {\n            OpenBitSet obs = dff.counted[shardNum];\n            if (!obs.get(sfc.termNum)) {\n              // if missing from this shard, add the max it could be\n              maxCount += dff.maxPossible(sfc,shardNum);\n            }\n          }\n          if (maxCount >= smallestCount) {\n            // TODO: on a tie, we could check the term values\n            needRefinement = true;\n          }\n        }\n\n        if (needRefinement) {\n          // add a query for each shard missing the term that needs refinement\n          for (int shardNum=0; shardNum<rb.shards.length; shardNum++) {\n            OpenBitSet obs = dff.counted[shardNum];\n            if (!obs.get(sfc.termNum) && dff.maxPossible(sfc,shardNum)>0) {\n              dff.needRefinements = true;\n              List<String> lst = dff._toRefine[shardNum];\n              if (lst == null) {\n                lst = dff._toRefine[shardNum] = new ArrayList<String>();\n              }\n              lst.add(sfc.name);\n            }\n          }\n        }\n      }\n    }\n  }\n\n","sourceOld":"  private void countFacets(ResponseBuilder rb, ShardRequest sreq) {\n    FacetInfo fi = rb._facetInfo;\n\n    for (ShardResponse srsp: sreq.responses) {\n      int shardNum = rb.getShardNum(srsp.getShard());\n      NamedList facet_counts = (NamedList)srsp.getSolrResponse().getResponse().get(\"facet_counts\");\n\n      // handle facet queries\n      NamedList facet_queries = (NamedList)facet_counts.get(\"facet_queries\");\n      if (facet_queries != null) {\n        for (int i=0; i<facet_queries.size(); i++) {\n          String returnedKey = (String)facet_queries.getName(i);\n          long count = ((Number)facet_queries.getVal(i)).longValue();\n          QueryFacet qf = fi.queryFacets.get(returnedKey);\n          qf.count += count;\n        }\n      }\n\n      // step through each facet.field, adding results from this shard\n      NamedList facet_fields = (NamedList)facet_counts.get(\"facet_fields\");\n\n      // an error could cause facet_fields to come back null\n      if (facet_fields == null) {\n        String msg = (String)facet_counts.get(\"exception\");\n        if (msg == null) msg = \"faceting exception in sub-request - missing facet_fields\";\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, msg);\n\n      }\n\n      for (DistribFieldFacet dff : fi.facets.values()) {\n        dff.add(shardNum, (NamedList)facet_fields.get(dff.getKey()), dff.initialLimit);\n      }\n    }\n\n\n    //\n    // This code currently assumes that there will be only a single\n    // request ((with responses from all shards) sent out to get facets...\n    // otherwise we would need to wait until all facet responses were received.\n    //\n\n    for (DistribFieldFacet dff : fi.facets.values()) {\n      if (dff.limit <= 0) continue; // no need to check these facets for refinement\n      if (dff.minCount <= 1 && dff.sort.equals(FacetParams.FACET_SORT_INDEX)) continue;\n\n      dff._toRefine = new List[rb.shards.length];\n      ShardFacetCount[] counts = dff.getCountSorted();\n      int ntop = Math.min(counts.length, dff.offset + dff.limit);\n      long smallestCount = counts.length == 0 ? 0 : counts[ntop-1].count;\n\n      for (int i=0; i<counts.length; i++) {\n        ShardFacetCount sfc = counts[i];\n        boolean needRefinement = false;\n\n        if (i<ntop) {\n          // automatically flag the top values for refinement\n          needRefinement = true;\n        } else {\n          // calculate the maximum value that this term may have\n          // and if it is >= smallestCount, then flag for refinement\n          long maxCount = sfc.count;\n          for (int shardNum=0; shardNum<rb.shards.length; shardNum++) {\n            OpenBitSet obs = dff.counted[shardNum];\n            if (!obs.get(sfc.termNum)) {\n              // if missing from this shard, add the max it could be\n              maxCount += dff.maxPossible(sfc,shardNum);\n            }\n          }\n          if (maxCount >= smallestCount) {\n            // TODO: on a tie, we could check the term values\n            needRefinement = true;\n          }\n        }\n\n        if (needRefinement) {\n          // add a query for each shard missing the term that needs refinement\n          for (int shardNum=0; shardNum<rb.shards.length; shardNum++) {\n            OpenBitSet obs = dff.counted[shardNum];\n            if (!obs.get(sfc.termNum) && dff.maxPossible(sfc,shardNum)>0) {\n              dff.needRefinements = true;\n              List<String> lst = dff._toRefine[shardNum];\n              if (lst == null) {\n                lst = dff._toRefine[shardNum] = new ArrayList<String>();\n              }\n              lst.add(sfc.name);\n            }\n          }\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"755f2f419306d7297c8feee10d1897addf4b2dd0","date":1294442354,"type":3,"author":"Chris M. Hostetter","isMerge":false,"pathNew":"solr/src/java/org/apache/solr/handler/component/FacetComponent#countFacets(ResponseBuilder,ShardRequest).mjava","pathOld":"solr/src/java/org/apache/solr/handler/component/FacetComponent#countFacets(ResponseBuilder,ShardRequest).mjava","sourceNew":"  private void countFacets(ResponseBuilder rb, ShardRequest sreq) {\n    FacetInfo fi = rb._facetInfo;\n\n    for (ShardResponse srsp: sreq.responses) {\n      int shardNum = rb.getShardNum(srsp.getShard());\n      NamedList facet_counts = (NamedList)srsp.getSolrResponse().getResponse().get(\"facet_counts\");\n\n      @SuppressWarnings(\"unchecked\")\n      List<String> excepts = (List<String>)facet_counts.get(\"exception\");\n      fi.addExceptions(excepts);\n\n      // handle facet queries\n      NamedList facet_queries = (NamedList)facet_counts.get(\"facet_queries\");\n      if (facet_queries != null) {\n        for (int i=0; i<facet_queries.size(); i++) {\n          String returnedKey = facet_queries.getName(i);\n          long count = ((Number)facet_queries.getVal(i)).longValue();\n          QueryFacet qf = fi.queryFacets.get(returnedKey);\n          qf.count += count;\n        }\n      }\n\n      // step through each facet.field, adding results from this shard\n      NamedList facet_fields = (NamedList)facet_counts.get(\"facet_fields\");\n    \n      if (facet_fields != null) {\n        for (DistribFieldFacet dff : fi.facets.values()) {\n          dff.add(shardNum, (NamedList)facet_fields.get(dff.getKey()), dff.initialLimit);\n        }\n      }\n    }\n\n\n    //\n    // This code currently assumes that there will be only a single\n    // request ((with responses from all shards) sent out to get facets...\n    // otherwise we would need to wait until all facet responses were received.\n    //\n\n    for (DistribFieldFacet dff : fi.facets.values()) {\n      if (dff.limit <= 0) continue; // no need to check these facets for refinement\n      if (dff.minCount <= 1 && dff.sort.equals(FacetParams.FACET_SORT_INDEX)) continue;\n\n      @SuppressWarnings(\"unchecked\") // generic array's are anoying\n      List<String>[] tmp = (List<String>[]) new List[rb.shards.length];\n      dff._toRefine = tmp;\n\n      ShardFacetCount[] counts = dff.getCountSorted();\n      int ntop = Math.min(counts.length, dff.offset + dff.limit);\n      long smallestCount = counts.length == 0 ? 0 : counts[ntop-1].count;\n\n      for (int i=0; i<counts.length; i++) {\n        ShardFacetCount sfc = counts[i];\n        boolean needRefinement = false;\n\n        if (i<ntop) {\n          // automatically flag the top values for refinement\n          needRefinement = true;\n        } else {\n          // calculate the maximum value that this term may have\n          // and if it is >= smallestCount, then flag for refinement\n          long maxCount = sfc.count;\n          for (int shardNum=0; shardNum<rb.shards.length; shardNum++) {\n            OpenBitSet obs = dff.counted[shardNum];\n            if (!obs.get(sfc.termNum)) {\n              // if missing from this shard, add the max it could be\n              maxCount += dff.maxPossible(sfc,shardNum);\n            }\n          }\n          if (maxCount >= smallestCount) {\n            // TODO: on a tie, we could check the term values\n            needRefinement = true;\n          }\n        }\n\n        if (needRefinement) {\n          // add a query for each shard missing the term that needs refinement\n          for (int shardNum=0; shardNum<rb.shards.length; shardNum++) {\n            OpenBitSet obs = dff.counted[shardNum];\n            if (!obs.get(sfc.termNum) && dff.maxPossible(sfc,shardNum)>0) {\n              dff.needRefinements = true;\n              List<String> lst = dff._toRefine[shardNum];\n              if (lst == null) {\n                lst = dff._toRefine[shardNum] = new ArrayList<String>();\n              }\n              lst.add(sfc.name);\n            }\n          }\n        }\n      }\n    }\n  }\n\n","sourceOld":"  private void countFacets(ResponseBuilder rb, ShardRequest sreq) {\n    FacetInfo fi = rb._facetInfo;\n\n    for (ShardResponse srsp: sreq.responses) {\n      int shardNum = rb.getShardNum(srsp.getShard());\n      NamedList facet_counts = (NamedList)srsp.getSolrResponse().getResponse().get(\"facet_counts\");\n\n      fi.addExceptions((List)facet_counts.get(\"exception\"));\n\n      // handle facet queries\n      NamedList facet_queries = (NamedList)facet_counts.get(\"facet_queries\");\n      if (facet_queries != null) {\n        for (int i=0; i<facet_queries.size(); i++) {\n          String returnedKey = facet_queries.getName(i);\n          long count = ((Number)facet_queries.getVal(i)).longValue();\n          QueryFacet qf = fi.queryFacets.get(returnedKey);\n          qf.count += count;\n        }\n      }\n\n      // step through each facet.field, adding results from this shard\n      NamedList facet_fields = (NamedList)facet_counts.get(\"facet_fields\");\n    \n      if (facet_fields != null) {\n        for (DistribFieldFacet dff : fi.facets.values()) {\n          dff.add(shardNum, (NamedList)facet_fields.get(dff.getKey()), dff.initialLimit);\n        }\n      }\n    }\n\n\n    //\n    // This code currently assumes that there will be only a single\n    // request ((with responses from all shards) sent out to get facets...\n    // otherwise we would need to wait until all facet responses were received.\n    //\n\n    for (DistribFieldFacet dff : fi.facets.values()) {\n      if (dff.limit <= 0) continue; // no need to check these facets for refinement\n      if (dff.minCount <= 1 && dff.sort.equals(FacetParams.FACET_SORT_INDEX)) continue;\n\n      dff._toRefine = new List[rb.shards.length];\n      ShardFacetCount[] counts = dff.getCountSorted();\n      int ntop = Math.min(counts.length, dff.offset + dff.limit);\n      long smallestCount = counts.length == 0 ? 0 : counts[ntop-1].count;\n\n      for (int i=0; i<counts.length; i++) {\n        ShardFacetCount sfc = counts[i];\n        boolean needRefinement = false;\n\n        if (i<ntop) {\n          // automatically flag the top values for refinement\n          needRefinement = true;\n        } else {\n          // calculate the maximum value that this term may have\n          // and if it is >= smallestCount, then flag for refinement\n          long maxCount = sfc.count;\n          for (int shardNum=0; shardNum<rb.shards.length; shardNum++) {\n            OpenBitSet obs = dff.counted[shardNum];\n            if (!obs.get(sfc.termNum)) {\n              // if missing from this shard, add the max it could be\n              maxCount += dff.maxPossible(sfc,shardNum);\n            }\n          }\n          if (maxCount >= smallestCount) {\n            // TODO: on a tie, we could check the term values\n            needRefinement = true;\n          }\n        }\n\n        if (needRefinement) {\n          // add a query for each shard missing the term that needs refinement\n          for (int shardNum=0; shardNum<rb.shards.length; shardNum++) {\n            OpenBitSet obs = dff.counted[shardNum];\n            if (!obs.get(sfc.termNum) && dff.maxPossible(sfc,shardNum)>0) {\n              dff.needRefinements = true;\n              List<String> lst = dff._toRefine[shardNum];\n              if (lst == null) {\n                lst = dff._toRefine[shardNum] = new ArrayList<String>();\n              }\n              lst.add(sfc.name);\n            }\n          }\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":["d1c5c000a4f7db9f84794088342aa428d80dfa37"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"868da859b43505d9d2a023bfeae6dd0c795f5295","date":1294948401,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"solr/src/java/org/apache/solr/handler/component/FacetComponent#countFacets(ResponseBuilder,ShardRequest).mjava","pathOld":"solr/src/java/org/apache/solr/handler/component/FacetComponent#countFacets(ResponseBuilder,ShardRequest).mjava","sourceNew":"  private void countFacets(ResponseBuilder rb, ShardRequest sreq) {\n    FacetInfo fi = rb._facetInfo;\n\n    for (ShardResponse srsp: sreq.responses) {\n      int shardNum = rb.getShardNum(srsp.getShard());\n      NamedList facet_counts = (NamedList)srsp.getSolrResponse().getResponse().get(\"facet_counts\");\n\n      @SuppressWarnings(\"unchecked\")\n      List<String> excepts = (List<String>)facet_counts.get(\"exception\");\n      fi.addExceptions(excepts);\n\n      // handle facet queries\n      NamedList facet_queries = (NamedList)facet_counts.get(\"facet_queries\");\n      if (facet_queries != null) {\n        for (int i=0; i<facet_queries.size(); i++) {\n          String returnedKey = facet_queries.getName(i);\n          long count = ((Number)facet_queries.getVal(i)).longValue();\n          QueryFacet qf = fi.queryFacets.get(returnedKey);\n          qf.count += count;\n        }\n      }\n\n      // step through each facet.field, adding results from this shard\n      NamedList facet_fields = (NamedList)facet_counts.get(\"facet_fields\");\n    \n      if (facet_fields != null) {\n        for (DistribFieldFacet dff : fi.facets.values()) {\n          dff.add(shardNum, (NamedList)facet_fields.get(dff.getKey()), dff.initialLimit);\n        }\n      }\n    }\n\n\n    //\n    // This code currently assumes that there will be only a single\n    // request ((with responses from all shards) sent out to get facets...\n    // otherwise we would need to wait until all facet responses were received.\n    //\n\n    for (DistribFieldFacet dff : fi.facets.values()) {\n      if (dff.limit <= 0) continue; // no need to check these facets for refinement\n      if (dff.minCount <= 1 && dff.sort.equals(FacetParams.FACET_SORT_INDEX)) continue;\n\n      @SuppressWarnings(\"unchecked\") // generic array's are anoying\n      List<String>[] tmp = (List<String>[]) new List[rb.shards.length];\n      dff._toRefine = tmp;\n\n      ShardFacetCount[] counts = dff.getCountSorted();\n      int ntop = Math.min(counts.length, dff.offset + dff.limit);\n      long smallestCount = counts.length == 0 ? 0 : counts[ntop-1].count;\n\n      for (int i=0; i<counts.length; i++) {\n        ShardFacetCount sfc = counts[i];\n        boolean needRefinement = false;\n\n        if (i<ntop) {\n          // automatically flag the top values for refinement\n          needRefinement = true;\n        } else {\n          // calculate the maximum value that this term may have\n          // and if it is >= smallestCount, then flag for refinement\n          long maxCount = sfc.count;\n          for (int shardNum=0; shardNum<rb.shards.length; shardNum++) {\n            OpenBitSet obs = dff.counted[shardNum];\n            if (!obs.get(sfc.termNum)) {\n              // if missing from this shard, add the max it could be\n              maxCount += dff.maxPossible(sfc,shardNum);\n            }\n          }\n          if (maxCount >= smallestCount) {\n            // TODO: on a tie, we could check the term values\n            needRefinement = true;\n          }\n        }\n\n        if (needRefinement) {\n          // add a query for each shard missing the term that needs refinement\n          for (int shardNum=0; shardNum<rb.shards.length; shardNum++) {\n            OpenBitSet obs = dff.counted[shardNum];\n            if (!obs.get(sfc.termNum) && dff.maxPossible(sfc,shardNum)>0) {\n              dff.needRefinements = true;\n              List<String> lst = dff._toRefine[shardNum];\n              if (lst == null) {\n                lst = dff._toRefine[shardNum] = new ArrayList<String>();\n              }\n              lst.add(sfc.name);\n            }\n          }\n        }\n      }\n    }\n  }\n\n","sourceOld":"  private void countFacets(ResponseBuilder rb, ShardRequest sreq) {\n    FacetInfo fi = rb._facetInfo;\n\n    for (ShardResponse srsp: sreq.responses) {\n      int shardNum = rb.getShardNum(srsp.getShard());\n      NamedList facet_counts = (NamedList)srsp.getSolrResponse().getResponse().get(\"facet_counts\");\n\n      fi.addExceptions((List)facet_counts.get(\"exception\"));\n\n      // handle facet queries\n      NamedList facet_queries = (NamedList)facet_counts.get(\"facet_queries\");\n      if (facet_queries != null) {\n        for (int i=0; i<facet_queries.size(); i++) {\n          String returnedKey = facet_queries.getName(i);\n          long count = ((Number)facet_queries.getVal(i)).longValue();\n          QueryFacet qf = fi.queryFacets.get(returnedKey);\n          qf.count += count;\n        }\n      }\n\n      // step through each facet.field, adding results from this shard\n      NamedList facet_fields = (NamedList)facet_counts.get(\"facet_fields\");\n    \n      if (facet_fields != null) {\n        for (DistribFieldFacet dff : fi.facets.values()) {\n          dff.add(shardNum, (NamedList)facet_fields.get(dff.getKey()), dff.initialLimit);\n        }\n      }\n    }\n\n\n    //\n    // This code currently assumes that there will be only a single\n    // request ((with responses from all shards) sent out to get facets...\n    // otherwise we would need to wait until all facet responses were received.\n    //\n\n    for (DistribFieldFacet dff : fi.facets.values()) {\n      if (dff.limit <= 0) continue; // no need to check these facets for refinement\n      if (dff.minCount <= 1 && dff.sort.equals(FacetParams.FACET_SORT_INDEX)) continue;\n\n      dff._toRefine = new List[rb.shards.length];\n      ShardFacetCount[] counts = dff.getCountSorted();\n      int ntop = Math.min(counts.length, dff.offset + dff.limit);\n      long smallestCount = counts.length == 0 ? 0 : counts[ntop-1].count;\n\n      for (int i=0; i<counts.length; i++) {\n        ShardFacetCount sfc = counts[i];\n        boolean needRefinement = false;\n\n        if (i<ntop) {\n          // automatically flag the top values for refinement\n          needRefinement = true;\n        } else {\n          // calculate the maximum value that this term may have\n          // and if it is >= smallestCount, then flag for refinement\n          long maxCount = sfc.count;\n          for (int shardNum=0; shardNum<rb.shards.length; shardNum++) {\n            OpenBitSet obs = dff.counted[shardNum];\n            if (!obs.get(sfc.termNum)) {\n              // if missing from this shard, add the max it could be\n              maxCount += dff.maxPossible(sfc,shardNum);\n            }\n          }\n          if (maxCount >= smallestCount) {\n            // TODO: on a tie, we could check the term values\n            needRefinement = true;\n          }\n        }\n\n        if (needRefinement) {\n          // add a query for each shard missing the term that needs refinement\n          for (int shardNum=0; shardNum<rb.shards.length; shardNum++) {\n            OpenBitSet obs = dff.counted[shardNum];\n            if (!obs.get(sfc.termNum) && dff.maxPossible(sfc,shardNum)>0) {\n              dff.needRefinements = true;\n              List<String> lst = dff._toRefine[shardNum];\n              if (lst == null) {\n                lst = dff._toRefine[shardNum] = new ArrayList<String>();\n              }\n              lst.add(sfc.name);\n            }\n          }\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"29ef99d61cda9641b6250bf9567329a6e65f901d","date":1297244127,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"solr/src/java/org/apache/solr/handler/component/FacetComponent#countFacets(ResponseBuilder,ShardRequest).mjava","pathOld":"solr/src/java/org/apache/solr/handler/component/FacetComponent#countFacets(ResponseBuilder,ShardRequest).mjava","sourceNew":"  private void countFacets(ResponseBuilder rb, ShardRequest sreq) {\n    FacetInfo fi = rb._facetInfo;\n\n    for (ShardResponse srsp: sreq.responses) {\n      int shardNum = rb.getShardNum(srsp.getShard());\n      NamedList facet_counts = (NamedList)srsp.getSolrResponse().getResponse().get(\"facet_counts\");\n\n      @SuppressWarnings(\"unchecked\")\n      List<String> excepts = (List<String>)facet_counts.get(\"exception\");\n      fi.addExceptions(excepts);\n\n      // handle facet queries\n      NamedList facet_queries = (NamedList)facet_counts.get(\"facet_queries\");\n      if (facet_queries != null) {\n        for (int i=0; i<facet_queries.size(); i++) {\n          String returnedKey = facet_queries.getName(i);\n          long count = ((Number)facet_queries.getVal(i)).longValue();\n          QueryFacet qf = fi.queryFacets.get(returnedKey);\n          qf.count += count;\n        }\n      }\n\n      // step through each facet.field, adding results from this shard\n      NamedList facet_fields = (NamedList)facet_counts.get(\"facet_fields\");\n    \n      if (facet_fields != null) {\n        for (DistribFieldFacet dff : fi.facets.values()) {\n          dff.add(shardNum, (NamedList)facet_fields.get(dff.getKey()), dff.initialLimit);\n        }\n      }\n    }\n\n\n    //\n    // This code currently assumes that there will be only a single\n    // request ((with responses from all shards) sent out to get facets...\n    // otherwise we would need to wait until all facet responses were received.\n    //\n\n    for (DistribFieldFacet dff : fi.facets.values()) {\n      if (dff.limit <= 0) continue; // no need to check these facets for refinement\n      if (dff.minCount <= 1 && dff.sort.equals(FacetParams.FACET_SORT_INDEX)) continue;\n\n      @SuppressWarnings(\"unchecked\") // generic array's are anoying\n      List<String>[] tmp = (List<String>[]) new List[rb.shards.length];\n      dff._toRefine = tmp;\n\n      ShardFacetCount[] counts = dff.getCountSorted();\n      int ntop = Math.min(counts.length, dff.offset + dff.limit);\n      long smallestCount = counts.length == 0 ? 0 : counts[ntop-1].count;\n\n      for (int i=0; i<counts.length; i++) {\n        ShardFacetCount sfc = counts[i];\n        boolean needRefinement = false;\n\n        if (i<ntop) {\n          // automatically flag the top values for refinement\n          needRefinement = true;\n        } else {\n          // calculate the maximum value that this term may have\n          // and if it is >= smallestCount, then flag for refinement\n          long maxCount = sfc.count;\n          for (int shardNum=0; shardNum<rb.shards.length; shardNum++) {\n            OpenBitSet obs = dff.counted[shardNum];\n            if (!obs.get(sfc.termNum)) {\n              // if missing from this shard, add the max it could be\n              maxCount += dff.maxPossible(sfc,shardNum);\n            }\n          }\n          if (maxCount >= smallestCount) {\n            // TODO: on a tie, we could check the term values\n            needRefinement = true;\n          }\n        }\n\n        if (needRefinement) {\n          // add a query for each shard missing the term that needs refinement\n          for (int shardNum=0; shardNum<rb.shards.length; shardNum++) {\n            OpenBitSet obs = dff.counted[shardNum];\n            if (!obs.get(sfc.termNum) && dff.maxPossible(sfc,shardNum)>0) {\n              dff.needRefinements = true;\n              List<String> lst = dff._toRefine[shardNum];\n              if (lst == null) {\n                lst = dff._toRefine[shardNum] = new ArrayList<String>();\n              }\n              lst.add(sfc.name);\n            }\n          }\n        }\n      }\n    }\n  }\n\n","sourceOld":"  private void countFacets(ResponseBuilder rb, ShardRequest sreq) {\n    FacetInfo fi = rb._facetInfo;\n\n    for (ShardResponse srsp: sreq.responses) {\n      int shardNum = rb.getShardNum(srsp.getShard());\n      NamedList facet_counts = (NamedList)srsp.getSolrResponse().getResponse().get(\"facet_counts\");\n\n      fi.addExceptions((List)facet_counts.get(\"exception\"));\n\n      // handle facet queries\n      NamedList facet_queries = (NamedList)facet_counts.get(\"facet_queries\");\n      if (facet_queries != null) {\n        for (int i=0; i<facet_queries.size(); i++) {\n          String returnedKey = facet_queries.getName(i);\n          long count = ((Number)facet_queries.getVal(i)).longValue();\n          QueryFacet qf = fi.queryFacets.get(returnedKey);\n          qf.count += count;\n        }\n      }\n\n      // step through each facet.field, adding results from this shard\n      NamedList facet_fields = (NamedList)facet_counts.get(\"facet_fields\");\n    \n      if (facet_fields != null) {\n        for (DistribFieldFacet dff : fi.facets.values()) {\n          dff.add(shardNum, (NamedList)facet_fields.get(dff.getKey()), dff.initialLimit);\n        }\n      }\n    }\n\n\n    //\n    // This code currently assumes that there will be only a single\n    // request ((with responses from all shards) sent out to get facets...\n    // otherwise we would need to wait until all facet responses were received.\n    //\n\n    for (DistribFieldFacet dff : fi.facets.values()) {\n      if (dff.limit <= 0) continue; // no need to check these facets for refinement\n      if (dff.minCount <= 1 && dff.sort.equals(FacetParams.FACET_SORT_INDEX)) continue;\n\n      dff._toRefine = new List[rb.shards.length];\n      ShardFacetCount[] counts = dff.getCountSorted();\n      int ntop = Math.min(counts.length, dff.offset + dff.limit);\n      long smallestCount = counts.length == 0 ? 0 : counts[ntop-1].count;\n\n      for (int i=0; i<counts.length; i++) {\n        ShardFacetCount sfc = counts[i];\n        boolean needRefinement = false;\n\n        if (i<ntop) {\n          // automatically flag the top values for refinement\n          needRefinement = true;\n        } else {\n          // calculate the maximum value that this term may have\n          // and if it is >= smallestCount, then flag for refinement\n          long maxCount = sfc.count;\n          for (int shardNum=0; shardNum<rb.shards.length; shardNum++) {\n            OpenBitSet obs = dff.counted[shardNum];\n            if (!obs.get(sfc.termNum)) {\n              // if missing from this shard, add the max it could be\n              maxCount += dff.maxPossible(sfc,shardNum);\n            }\n          }\n          if (maxCount >= smallestCount) {\n            // TODO: on a tie, we could check the term values\n            needRefinement = true;\n          }\n        }\n\n        if (needRefinement) {\n          // add a query for each shard missing the term that needs refinement\n          for (int shardNum=0; shardNum<rb.shards.length; shardNum++) {\n            OpenBitSet obs = dff.counted[shardNum];\n            if (!obs.get(sfc.termNum) && dff.maxPossible(sfc,shardNum)>0) {\n              dff.needRefinements = true;\n              List<String> lst = dff._toRefine[shardNum];\n              if (lst == null) {\n                lst = dff._toRefine[shardNum] = new ArrayList<String>();\n              }\n              lst.add(sfc.name);\n            }\n          }\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d1c5c000a4f7db9f84794088342aa428d80dfa37","date":1303079085,"type":3,"author":"Yonik Seeley","isMerge":false,"pathNew":"solr/src/java/org/apache/solr/handler/component/FacetComponent#countFacets(ResponseBuilder,ShardRequest).mjava","pathOld":"solr/src/java/org/apache/solr/handler/component/FacetComponent#countFacets(ResponseBuilder,ShardRequest).mjava","sourceNew":"  private void countFacets(ResponseBuilder rb, ShardRequest sreq) {\n    FacetInfo fi = rb._facetInfo;\n\n    for (ShardResponse srsp: sreq.responses) {\n      int shardNum = rb.getShardNum(srsp.getShard());\n      NamedList facet_counts = (NamedList)srsp.getSolrResponse().getResponse().get(\"facet_counts\");\n\n      @SuppressWarnings(\"unchecked\")\n      List<String> excepts = (List<String>)facet_counts.get(\"exception\");\n      fi.addExceptions(excepts);\n\n      // handle facet queries\n      NamedList facet_queries = (NamedList)facet_counts.get(\"facet_queries\");\n      if (facet_queries != null) {\n        for (int i=0; i<facet_queries.size(); i++) {\n          String returnedKey = facet_queries.getName(i);\n          long count = ((Number)facet_queries.getVal(i)).longValue();\n          QueryFacet qf = fi.queryFacets.get(returnedKey);\n          qf.count += count;\n        }\n      }\n\n      // step through each facet.field, adding results from this shard\n      NamedList facet_fields = (NamedList)facet_counts.get(\"facet_fields\");\n    \n      if (facet_fields != null) {\n        for (DistribFieldFacet dff : fi.facets.values()) {\n          dff.add(shardNum, (NamedList)facet_fields.get(dff.getKey()), dff.initialLimit);\n        }\n      }\n    }\n\n\n    //\n    // This code currently assumes that there will be only a single\n    // request ((with responses from all shards) sent out to get facets...\n    // otherwise we would need to wait until all facet responses were received.\n    //\n\n    for (DistribFieldFacet dff : fi.facets.values()) {\n       // no need to check these facets for refinement\n      if (dff.initialLimit <= 0 && dff.initialMincount == 0) continue;\n\n      // only other case where index-sort doesn't need refinement is if minCount==0\n      if (dff.minCount == 0 && dff.sort.equals(FacetParams.FACET_SORT_INDEX)) continue;\n\n      @SuppressWarnings(\"unchecked\") // generic array's are annoying\n      List<String>[] tmp = (List<String>[]) new List[rb.shards.length];\n      dff._toRefine = tmp;\n\n      ShardFacetCount[] counts = dff.getCountSorted();\n      int ntop = Math.min(counts.length, dff.limit >= 0 ? dff.offset + dff.limit : Integer.MAX_VALUE);\n      long smallestCount = counts.length == 0 ? 0 : counts[ntop-1].count;\n\n      for (int i=0; i<counts.length; i++) {\n        ShardFacetCount sfc = counts[i];\n        boolean needRefinement = false;\n\n        if (i<ntop) {\n          // automatically flag the top values for refinement\n          // this should always be true for facet.sort=index\n          needRefinement = true;\n        } else {\n          // this logic should only be invoked for facet.sort=index (for now)\n\n          // calculate the maximum value that this term may have\n          // and if it is >= smallestCount, then flag for refinement\n          long maxCount = sfc.count;\n          for (int shardNum=0; shardNum<rb.shards.length; shardNum++) {\n            OpenBitSet obs = dff.counted[shardNum];\n            if (!obs.get(sfc.termNum)) {\n              // if missing from this shard, add the max it could be\n              maxCount += dff.maxPossible(sfc,shardNum);\n            }\n          }\n          if (maxCount >= smallestCount) {\n            // TODO: on a tie, we could check the term values\n            needRefinement = true;\n          }\n        }\n\n        if (needRefinement) {\n          // add a query for each shard missing the term that needs refinement\n          for (int shardNum=0; shardNum<rb.shards.length; shardNum++) {\n            OpenBitSet obs = dff.counted[shardNum];\n            if (!obs.get(sfc.termNum) && dff.maxPossible(sfc,shardNum)>0) {\n              dff.needRefinements = true;\n              List<String> lst = dff._toRefine[shardNum];\n              if (lst == null) {\n                lst = dff._toRefine[shardNum] = new ArrayList<String>();\n              }\n              lst.add(sfc.name);\n            }\n          }\n        }\n      }\n    }\n  }\n\n","sourceOld":"  private void countFacets(ResponseBuilder rb, ShardRequest sreq) {\n    FacetInfo fi = rb._facetInfo;\n\n    for (ShardResponse srsp: sreq.responses) {\n      int shardNum = rb.getShardNum(srsp.getShard());\n      NamedList facet_counts = (NamedList)srsp.getSolrResponse().getResponse().get(\"facet_counts\");\n\n      @SuppressWarnings(\"unchecked\")\n      List<String> excepts = (List<String>)facet_counts.get(\"exception\");\n      fi.addExceptions(excepts);\n\n      // handle facet queries\n      NamedList facet_queries = (NamedList)facet_counts.get(\"facet_queries\");\n      if (facet_queries != null) {\n        for (int i=0; i<facet_queries.size(); i++) {\n          String returnedKey = facet_queries.getName(i);\n          long count = ((Number)facet_queries.getVal(i)).longValue();\n          QueryFacet qf = fi.queryFacets.get(returnedKey);\n          qf.count += count;\n        }\n      }\n\n      // step through each facet.field, adding results from this shard\n      NamedList facet_fields = (NamedList)facet_counts.get(\"facet_fields\");\n    \n      if (facet_fields != null) {\n        for (DistribFieldFacet dff : fi.facets.values()) {\n          dff.add(shardNum, (NamedList)facet_fields.get(dff.getKey()), dff.initialLimit);\n        }\n      }\n    }\n\n\n    //\n    // This code currently assumes that there will be only a single\n    // request ((with responses from all shards) sent out to get facets...\n    // otherwise we would need to wait until all facet responses were received.\n    //\n\n    for (DistribFieldFacet dff : fi.facets.values()) {\n      if (dff.limit <= 0) continue; // no need to check these facets for refinement\n      if (dff.minCount <= 1 && dff.sort.equals(FacetParams.FACET_SORT_INDEX)) continue;\n\n      @SuppressWarnings(\"unchecked\") // generic array's are anoying\n      List<String>[] tmp = (List<String>[]) new List[rb.shards.length];\n      dff._toRefine = tmp;\n\n      ShardFacetCount[] counts = dff.getCountSorted();\n      int ntop = Math.min(counts.length, dff.offset + dff.limit);\n      long smallestCount = counts.length == 0 ? 0 : counts[ntop-1].count;\n\n      for (int i=0; i<counts.length; i++) {\n        ShardFacetCount sfc = counts[i];\n        boolean needRefinement = false;\n\n        if (i<ntop) {\n          // automatically flag the top values for refinement\n          needRefinement = true;\n        } else {\n          // calculate the maximum value that this term may have\n          // and if it is >= smallestCount, then flag for refinement\n          long maxCount = sfc.count;\n          for (int shardNum=0; shardNum<rb.shards.length; shardNum++) {\n            OpenBitSet obs = dff.counted[shardNum];\n            if (!obs.get(sfc.termNum)) {\n              // if missing from this shard, add the max it could be\n              maxCount += dff.maxPossible(sfc,shardNum);\n            }\n          }\n          if (maxCount >= smallestCount) {\n            // TODO: on a tie, we could check the term values\n            needRefinement = true;\n          }\n        }\n\n        if (needRefinement) {\n          // add a query for each shard missing the term that needs refinement\n          for (int shardNum=0; shardNum<rb.shards.length; shardNum++) {\n            OpenBitSet obs = dff.counted[shardNum];\n            if (!obs.get(sfc.termNum) && dff.maxPossible(sfc,shardNum)>0) {\n              dff.needRefinements = true;\n              List<String> lst = dff._toRefine[shardNum];\n              if (lst == null) {\n                lst = dff._toRefine[shardNum] = new ArrayList<String>();\n              }\n              lst.add(sfc.name);\n            }\n          }\n        }\n      }\n    }\n  }\n\n","bugFix":["4db78c8781346b675fa5f1a6db8adcb96889c2ca","1161f19bd84204b140d97fea16ff621e86ce7ab4","755f2f419306d7297c8feee10d1897addf4b2dd0","5bb29c260c4bbaf4ce8a95d362844ebf77ec1f76"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0833d477d790b0926422e7ac018b1bcee73ad5bd","date":1303334953,"type":3,"author":"Chris M. Hostetter","isMerge":false,"pathNew":"solr/src/java/org/apache/solr/handler/component/FacetComponent#countFacets(ResponseBuilder,ShardRequest).mjava","pathOld":"solr/src/java/org/apache/solr/handler/component/FacetComponent#countFacets(ResponseBuilder,ShardRequest).mjava","sourceNew":"  private void countFacets(ResponseBuilder rb, ShardRequest sreq) {\n    FacetInfo fi = rb._facetInfo;\n\n    for (ShardResponse srsp: sreq.responses) {\n      int shardNum = rb.getShardNum(srsp.getShard());\n      NamedList facet_counts = (NamedList)srsp.getSolrResponse().getResponse().get(\"facet_counts\");\n\n      @SuppressWarnings(\"unchecked\")\n      List<String> excepts = (List<String>)facet_counts.get(\"exception\");\n      fi.addExceptions(excepts);\n\n      // handle facet queries\n      NamedList facet_queries = (NamedList)facet_counts.get(\"facet_queries\");\n      if (facet_queries != null) {\n        for (int i=0; i<facet_queries.size(); i++) {\n          String returnedKey = facet_queries.getName(i);\n          long count = ((Number)facet_queries.getVal(i)).longValue();\n          QueryFacet qf = fi.queryFacets.get(returnedKey);\n          qf.count += count;\n        }\n      }\n\n      // step through each facet.field, adding results from this shard\n      NamedList facet_fields = (NamedList)facet_counts.get(\"facet_fields\");\n    \n      if (facet_fields != null) {\n        for (DistribFieldFacet dff : fi.facets.values()) {\n          dff.add(shardNum, (NamedList)facet_fields.get(dff.getKey()), dff.initialLimit);\n        }\n      }\n\n      // Distributed facet_dates\n      //\n      // The implementation below uses the first encountered shard's \n      // facet_dates as the basis for subsequent shards' data to be merged.\n      // (the \"NOW\" param should ensure consistency)\n      @SuppressWarnings(\"unchecked\")\n      SimpleOrderedMap<SimpleOrderedMap<Object>> facet_dates = \n        (SimpleOrderedMap<SimpleOrderedMap<Object>>) \n        facet_counts.get(\"facet_dates\");\n      \n      if (facet_dates != null) {\n\n        // go through each facet_date\n        for (Map.Entry<String,SimpleOrderedMap<Object>> entry : facet_dates) {\n          final String field = entry.getKey();\n          if (fi.dateFacets.get(field) == null) { \n            // first time we've seen this field, no merging\n            fi.dateFacets.add(field, entry.getValue());\n\n          } else { \n            // not the first time, merge current field\n\n            SimpleOrderedMap<Object> shardFieldValues \n              = entry.getValue();\n            SimpleOrderedMap<Object> existFieldValues \n              = fi.dateFacets.get(field);\n\n            for (Map.Entry<String,Object> existPair : existFieldValues) {\n              final String key = existPair.getKey();\n              if (key.equals(\"gap\") || \n                  key.equals(\"end\") || \n                  key.equals(\"start\")) {\n                // we can skip these, must all be the same across shards\n                continue; \n              }\n              // can be null if inconsistencies in shards responses\n              Integer newValue = (Integer) shardFieldValues.get(key);\n              if  (null != newValue) {\n                Integer oldValue = ((Integer) existPair.getValue());\n                existPair.setValue(oldValue + newValue);\n              }\n            }\n          }\n        }\n      }\n\n      // Distributed facet_ranges\n      //\n      // The implementation below uses the first encountered shard's \n      // facet_ranges as the basis for subsequent shards' data to be merged.\n      @SuppressWarnings(\"unchecked\")\n      SimpleOrderedMap<SimpleOrderedMap<Object>> facet_ranges = \n        (SimpleOrderedMap<SimpleOrderedMap<Object>>) \n        facet_counts.get(\"facet_ranges\");\n      \n      if (facet_ranges != null) {\n\n        // go through each facet_range\n        for (Map.Entry<String,SimpleOrderedMap<Object>> entry : facet_ranges) {\n          final String field = entry.getKey();\n          if (fi.rangeFacets.get(field) == null) { \n            // first time we've seen this field, no merging\n            fi.rangeFacets.add(field, entry.getValue());\n\n          } else { \n            // not the first time, merge current field counts\n\n            @SuppressWarnings(\"unchecked\")\n            NamedList<Integer> shardFieldValues \n              = (NamedList<Integer>) entry.getValue().get(\"counts\");\n\n            @SuppressWarnings(\"unchecked\")\n            NamedList<Integer> existFieldValues \n              = (NamedList<Integer>) fi.rangeFacets.get(field).get(\"counts\");\n\n            for (Map.Entry<String,Integer> existPair : existFieldValues) {\n              final String key = existPair.getKey();\n              // can be null if inconsistencies in shards responses\n              Integer newValue = shardFieldValues.get(key);\n              if  (null != newValue) {\n                Integer oldValue = existPair.getValue();\n                existPair.setValue(oldValue + newValue);\n              }\n            }\n          }\n        }\n      }\n    }\n\n    //\n    // This code currently assumes that there will be only a single\n    // request ((with responses from all shards) sent out to get facets...\n    // otherwise we would need to wait until all facet responses were received.\n    //\n\n    for (DistribFieldFacet dff : fi.facets.values()) {\n       // no need to check these facets for refinement\n      if (dff.initialLimit <= 0 && dff.initialMincount == 0) continue;\n\n      // only other case where index-sort doesn't need refinement is if minCount==0\n      if (dff.minCount == 0 && dff.sort.equals(FacetParams.FACET_SORT_INDEX)) continue;\n\n      @SuppressWarnings(\"unchecked\") // generic array's are annoying\n      List<String>[] tmp = (List<String>[]) new List[rb.shards.length];\n      dff._toRefine = tmp;\n\n      ShardFacetCount[] counts = dff.getCountSorted();\n      int ntop = Math.min(counts.length, dff.limit >= 0 ? dff.offset + dff.limit : Integer.MAX_VALUE);\n      long smallestCount = counts.length == 0 ? 0 : counts[ntop-1].count;\n\n      for (int i=0; i<counts.length; i++) {\n        ShardFacetCount sfc = counts[i];\n        boolean needRefinement = false;\n\n        if (i<ntop) {\n          // automatically flag the top values for refinement\n          // this should always be true for facet.sort=index\n          needRefinement = true;\n        } else {\n          // this logic should only be invoked for facet.sort=index (for now)\n\n          // calculate the maximum value that this term may have\n          // and if it is >= smallestCount, then flag for refinement\n          long maxCount = sfc.count;\n          for (int shardNum=0; shardNum<rb.shards.length; shardNum++) {\n            OpenBitSet obs = dff.counted[shardNum];\n            if (!obs.get(sfc.termNum)) {\n              // if missing from this shard, add the max it could be\n              maxCount += dff.maxPossible(sfc,shardNum);\n            }\n          }\n          if (maxCount >= smallestCount) {\n            // TODO: on a tie, we could check the term values\n            needRefinement = true;\n          }\n        }\n\n        if (needRefinement) {\n          // add a query for each shard missing the term that needs refinement\n          for (int shardNum=0; shardNum<rb.shards.length; shardNum++) {\n            OpenBitSet obs = dff.counted[shardNum];\n            if (!obs.get(sfc.termNum) && dff.maxPossible(sfc,shardNum)>0) {\n              dff.needRefinements = true;\n              List<String> lst = dff._toRefine[shardNum];\n              if (lst == null) {\n                lst = dff._toRefine[shardNum] = new ArrayList<String>();\n              }\n              lst.add(sfc.name);\n            }\n          }\n        }\n      }\n    }\n  }\n\n","sourceOld":"  private void countFacets(ResponseBuilder rb, ShardRequest sreq) {\n    FacetInfo fi = rb._facetInfo;\n\n    for (ShardResponse srsp: sreq.responses) {\n      int shardNum = rb.getShardNum(srsp.getShard());\n      NamedList facet_counts = (NamedList)srsp.getSolrResponse().getResponse().get(\"facet_counts\");\n\n      @SuppressWarnings(\"unchecked\")\n      List<String> excepts = (List<String>)facet_counts.get(\"exception\");\n      fi.addExceptions(excepts);\n\n      // handle facet queries\n      NamedList facet_queries = (NamedList)facet_counts.get(\"facet_queries\");\n      if (facet_queries != null) {\n        for (int i=0; i<facet_queries.size(); i++) {\n          String returnedKey = facet_queries.getName(i);\n          long count = ((Number)facet_queries.getVal(i)).longValue();\n          QueryFacet qf = fi.queryFacets.get(returnedKey);\n          qf.count += count;\n        }\n      }\n\n      // step through each facet.field, adding results from this shard\n      NamedList facet_fields = (NamedList)facet_counts.get(\"facet_fields\");\n    \n      if (facet_fields != null) {\n        for (DistribFieldFacet dff : fi.facets.values()) {\n          dff.add(shardNum, (NamedList)facet_fields.get(dff.getKey()), dff.initialLimit);\n        }\n      }\n    }\n\n\n    //\n    // This code currently assumes that there will be only a single\n    // request ((with responses from all shards) sent out to get facets...\n    // otherwise we would need to wait until all facet responses were received.\n    //\n\n    for (DistribFieldFacet dff : fi.facets.values()) {\n       // no need to check these facets for refinement\n      if (dff.initialLimit <= 0 && dff.initialMincount == 0) continue;\n\n      // only other case where index-sort doesn't need refinement is if minCount==0\n      if (dff.minCount == 0 && dff.sort.equals(FacetParams.FACET_SORT_INDEX)) continue;\n\n      @SuppressWarnings(\"unchecked\") // generic array's are annoying\n      List<String>[] tmp = (List<String>[]) new List[rb.shards.length];\n      dff._toRefine = tmp;\n\n      ShardFacetCount[] counts = dff.getCountSorted();\n      int ntop = Math.min(counts.length, dff.limit >= 0 ? dff.offset + dff.limit : Integer.MAX_VALUE);\n      long smallestCount = counts.length == 0 ? 0 : counts[ntop-1].count;\n\n      for (int i=0; i<counts.length; i++) {\n        ShardFacetCount sfc = counts[i];\n        boolean needRefinement = false;\n\n        if (i<ntop) {\n          // automatically flag the top values for refinement\n          // this should always be true for facet.sort=index\n          needRefinement = true;\n        } else {\n          // this logic should only be invoked for facet.sort=index (for now)\n\n          // calculate the maximum value that this term may have\n          // and if it is >= smallestCount, then flag for refinement\n          long maxCount = sfc.count;\n          for (int shardNum=0; shardNum<rb.shards.length; shardNum++) {\n            OpenBitSet obs = dff.counted[shardNum];\n            if (!obs.get(sfc.termNum)) {\n              // if missing from this shard, add the max it could be\n              maxCount += dff.maxPossible(sfc,shardNum);\n            }\n          }\n          if (maxCount >= smallestCount) {\n            // TODO: on a tie, we could check the term values\n            needRefinement = true;\n          }\n        }\n\n        if (needRefinement) {\n          // add a query for each shard missing the term that needs refinement\n          for (int shardNum=0; shardNum<rb.shards.length; shardNum++) {\n            OpenBitSet obs = dff.counted[shardNum];\n            if (!obs.get(sfc.termNum) && dff.maxPossible(sfc,shardNum)>0) {\n              dff.needRefinements = true;\n              List<String> lst = dff._toRefine[shardNum];\n              if (lst == null) {\n                lst = dff._toRefine[shardNum] = new ArrayList<String>();\n              }\n              lst.add(sfc.name);\n            }\n          }\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d493718201f0d0c54c773fb323d87bbd2fbffe41","date":1303546048,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"solr/src/java/org/apache/solr/handler/component/FacetComponent#countFacets(ResponseBuilder,ShardRequest).mjava","pathOld":"solr/src/java/org/apache/solr/handler/component/FacetComponent#countFacets(ResponseBuilder,ShardRequest).mjava","sourceNew":"  private void countFacets(ResponseBuilder rb, ShardRequest sreq) {\n    FacetInfo fi = rb._facetInfo;\n\n    for (ShardResponse srsp: sreq.responses) {\n      int shardNum = rb.getShardNum(srsp.getShard());\n      NamedList facet_counts = (NamedList)srsp.getSolrResponse().getResponse().get(\"facet_counts\");\n\n      @SuppressWarnings(\"unchecked\")\n      List<String> excepts = (List<String>)facet_counts.get(\"exception\");\n      fi.addExceptions(excepts);\n\n      // handle facet queries\n      NamedList facet_queries = (NamedList)facet_counts.get(\"facet_queries\");\n      if (facet_queries != null) {\n        for (int i=0; i<facet_queries.size(); i++) {\n          String returnedKey = facet_queries.getName(i);\n          long count = ((Number)facet_queries.getVal(i)).longValue();\n          QueryFacet qf = fi.queryFacets.get(returnedKey);\n          qf.count += count;\n        }\n      }\n\n      // step through each facet.field, adding results from this shard\n      NamedList facet_fields = (NamedList)facet_counts.get(\"facet_fields\");\n    \n      if (facet_fields != null) {\n        for (DistribFieldFacet dff : fi.facets.values()) {\n          dff.add(shardNum, (NamedList)facet_fields.get(dff.getKey()), dff.initialLimit);\n        }\n      }\n\n      // Distributed facet_dates\n      //\n      // The implementation below uses the first encountered shard's \n      // facet_dates as the basis for subsequent shards' data to be merged.\n      // (the \"NOW\" param should ensure consistency)\n      @SuppressWarnings(\"unchecked\")\n      SimpleOrderedMap<SimpleOrderedMap<Object>> facet_dates = \n        (SimpleOrderedMap<SimpleOrderedMap<Object>>) \n        facet_counts.get(\"facet_dates\");\n      \n      if (facet_dates != null) {\n\n        // go through each facet_date\n        for (Map.Entry<String,SimpleOrderedMap<Object>> entry : facet_dates) {\n          final String field = entry.getKey();\n          if (fi.dateFacets.get(field) == null) { \n            // first time we've seen this field, no merging\n            fi.dateFacets.add(field, entry.getValue());\n\n          } else { \n            // not the first time, merge current field\n\n            SimpleOrderedMap<Object> shardFieldValues \n              = entry.getValue();\n            SimpleOrderedMap<Object> existFieldValues \n              = fi.dateFacets.get(field);\n\n            for (Map.Entry<String,Object> existPair : existFieldValues) {\n              final String key = existPair.getKey();\n              if (key.equals(\"gap\") || \n                  key.equals(\"end\") || \n                  key.equals(\"start\")) {\n                // we can skip these, must all be the same across shards\n                continue; \n              }\n              // can be null if inconsistencies in shards responses\n              Integer newValue = (Integer) shardFieldValues.get(key);\n              if  (null != newValue) {\n                Integer oldValue = ((Integer) existPair.getValue());\n                existPair.setValue(oldValue + newValue);\n              }\n            }\n          }\n        }\n      }\n\n      // Distributed facet_ranges\n      //\n      // The implementation below uses the first encountered shard's \n      // facet_ranges as the basis for subsequent shards' data to be merged.\n      @SuppressWarnings(\"unchecked\")\n      SimpleOrderedMap<SimpleOrderedMap<Object>> facet_ranges = \n        (SimpleOrderedMap<SimpleOrderedMap<Object>>) \n        facet_counts.get(\"facet_ranges\");\n      \n      if (facet_ranges != null) {\n\n        // go through each facet_range\n        for (Map.Entry<String,SimpleOrderedMap<Object>> entry : facet_ranges) {\n          final String field = entry.getKey();\n          if (fi.rangeFacets.get(field) == null) { \n            // first time we've seen this field, no merging\n            fi.rangeFacets.add(field, entry.getValue());\n\n          } else { \n            // not the first time, merge current field counts\n\n            @SuppressWarnings(\"unchecked\")\n            NamedList<Integer> shardFieldValues \n              = (NamedList<Integer>) entry.getValue().get(\"counts\");\n\n            @SuppressWarnings(\"unchecked\")\n            NamedList<Integer> existFieldValues \n              = (NamedList<Integer>) fi.rangeFacets.get(field).get(\"counts\");\n\n            for (Map.Entry<String,Integer> existPair : existFieldValues) {\n              final String key = existPair.getKey();\n              // can be null if inconsistencies in shards responses\n              Integer newValue = shardFieldValues.get(key);\n              if  (null != newValue) {\n                Integer oldValue = existPair.getValue();\n                existPair.setValue(oldValue + newValue);\n              }\n            }\n          }\n        }\n      }\n    }\n\n    //\n    // This code currently assumes that there will be only a single\n    // request ((with responses from all shards) sent out to get facets...\n    // otherwise we would need to wait until all facet responses were received.\n    //\n\n    for (DistribFieldFacet dff : fi.facets.values()) {\n       // no need to check these facets for refinement\n      if (dff.initialLimit <= 0 && dff.initialMincount == 0) continue;\n\n      // only other case where index-sort doesn't need refinement is if minCount==0\n      if (dff.minCount == 0 && dff.sort.equals(FacetParams.FACET_SORT_INDEX)) continue;\n\n      @SuppressWarnings(\"unchecked\") // generic array's are annoying\n      List<String>[] tmp = (List<String>[]) new List[rb.shards.length];\n      dff._toRefine = tmp;\n\n      ShardFacetCount[] counts = dff.getCountSorted();\n      int ntop = Math.min(counts.length, dff.limit >= 0 ? dff.offset + dff.limit : Integer.MAX_VALUE);\n      long smallestCount = counts.length == 0 ? 0 : counts[ntop-1].count;\n\n      for (int i=0; i<counts.length; i++) {\n        ShardFacetCount sfc = counts[i];\n        boolean needRefinement = false;\n\n        if (i<ntop) {\n          // automatically flag the top values for refinement\n          // this should always be true for facet.sort=index\n          needRefinement = true;\n        } else {\n          // this logic should only be invoked for facet.sort=index (for now)\n\n          // calculate the maximum value that this term may have\n          // and if it is >= smallestCount, then flag for refinement\n          long maxCount = sfc.count;\n          for (int shardNum=0; shardNum<rb.shards.length; shardNum++) {\n            OpenBitSet obs = dff.counted[shardNum];\n            if (!obs.get(sfc.termNum)) {\n              // if missing from this shard, add the max it could be\n              maxCount += dff.maxPossible(sfc,shardNum);\n            }\n          }\n          if (maxCount >= smallestCount) {\n            // TODO: on a tie, we could check the term values\n            needRefinement = true;\n          }\n        }\n\n        if (needRefinement) {\n          // add a query for each shard missing the term that needs refinement\n          for (int shardNum=0; shardNum<rb.shards.length; shardNum++) {\n            OpenBitSet obs = dff.counted[shardNum];\n            if (!obs.get(sfc.termNum) && dff.maxPossible(sfc,shardNum)>0) {\n              dff.needRefinements = true;\n              List<String> lst = dff._toRefine[shardNum];\n              if (lst == null) {\n                lst = dff._toRefine[shardNum] = new ArrayList<String>();\n              }\n              lst.add(sfc.name);\n            }\n          }\n        }\n      }\n    }\n  }\n\n","sourceOld":"  private void countFacets(ResponseBuilder rb, ShardRequest sreq) {\n    FacetInfo fi = rb._facetInfo;\n\n    for (ShardResponse srsp: sreq.responses) {\n      int shardNum = rb.getShardNum(srsp.getShard());\n      NamedList facet_counts = (NamedList)srsp.getSolrResponse().getResponse().get(\"facet_counts\");\n\n      @SuppressWarnings(\"unchecked\")\n      List<String> excepts = (List<String>)facet_counts.get(\"exception\");\n      fi.addExceptions(excepts);\n\n      // handle facet queries\n      NamedList facet_queries = (NamedList)facet_counts.get(\"facet_queries\");\n      if (facet_queries != null) {\n        for (int i=0; i<facet_queries.size(); i++) {\n          String returnedKey = facet_queries.getName(i);\n          long count = ((Number)facet_queries.getVal(i)).longValue();\n          QueryFacet qf = fi.queryFacets.get(returnedKey);\n          qf.count += count;\n        }\n      }\n\n      // step through each facet.field, adding results from this shard\n      NamedList facet_fields = (NamedList)facet_counts.get(\"facet_fields\");\n    \n      if (facet_fields != null) {\n        for (DistribFieldFacet dff : fi.facets.values()) {\n          dff.add(shardNum, (NamedList)facet_fields.get(dff.getKey()), dff.initialLimit);\n        }\n      }\n    }\n\n\n    //\n    // This code currently assumes that there will be only a single\n    // request ((with responses from all shards) sent out to get facets...\n    // otherwise we would need to wait until all facet responses were received.\n    //\n\n    for (DistribFieldFacet dff : fi.facets.values()) {\n      if (dff.limit <= 0) continue; // no need to check these facets for refinement\n      if (dff.minCount <= 1 && dff.sort.equals(FacetParams.FACET_SORT_INDEX)) continue;\n\n      @SuppressWarnings(\"unchecked\") // generic array's are anoying\n      List<String>[] tmp = (List<String>[]) new List[rb.shards.length];\n      dff._toRefine = tmp;\n\n      ShardFacetCount[] counts = dff.getCountSorted();\n      int ntop = Math.min(counts.length, dff.offset + dff.limit);\n      long smallestCount = counts.length == 0 ? 0 : counts[ntop-1].count;\n\n      for (int i=0; i<counts.length; i++) {\n        ShardFacetCount sfc = counts[i];\n        boolean needRefinement = false;\n\n        if (i<ntop) {\n          // automatically flag the top values for refinement\n          needRefinement = true;\n        } else {\n          // calculate the maximum value that this term may have\n          // and if it is >= smallestCount, then flag for refinement\n          long maxCount = sfc.count;\n          for (int shardNum=0; shardNum<rb.shards.length; shardNum++) {\n            OpenBitSet obs = dff.counted[shardNum];\n            if (!obs.get(sfc.termNum)) {\n              // if missing from this shard, add the max it could be\n              maxCount += dff.maxPossible(sfc,shardNum);\n            }\n          }\n          if (maxCount >= smallestCount) {\n            // TODO: on a tie, we could check the term values\n            needRefinement = true;\n          }\n        }\n\n        if (needRefinement) {\n          // add a query for each shard missing the term that needs refinement\n          for (int shardNum=0; shardNum<rb.shards.length; shardNum++) {\n            OpenBitSet obs = dff.counted[shardNum];\n            if (!obs.get(sfc.termNum) && dff.maxPossible(sfc,shardNum)>0) {\n              dff.needRefinements = true;\n              List<String> lst = dff._toRefine[shardNum];\n              if (lst == null) {\n                lst = dff._toRefine[shardNum] = new ArrayList<String>();\n              }\n              lst.add(sfc.name);\n            }\n          }\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"135621f3a0670a9394eb563224a3b76cc4dddc0f","date":1304344257,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"solr/src/java/org/apache/solr/handler/component/FacetComponent#countFacets(ResponseBuilder,ShardRequest).mjava","pathOld":"solr/src/java/org/apache/solr/handler/component/FacetComponent#countFacets(ResponseBuilder,ShardRequest).mjava","sourceNew":"  private void countFacets(ResponseBuilder rb, ShardRequest sreq) {\n    FacetInfo fi = rb._facetInfo;\n\n    for (ShardResponse srsp: sreq.responses) {\n      int shardNum = rb.getShardNum(srsp.getShard());\n      NamedList facet_counts = (NamedList)srsp.getSolrResponse().getResponse().get(\"facet_counts\");\n\n      @SuppressWarnings(\"unchecked\")\n      List<String> excepts = (List<String>)facet_counts.get(\"exception\");\n      fi.addExceptions(excepts);\n\n      // handle facet queries\n      NamedList facet_queries = (NamedList)facet_counts.get(\"facet_queries\");\n      if (facet_queries != null) {\n        for (int i=0; i<facet_queries.size(); i++) {\n          String returnedKey = facet_queries.getName(i);\n          long count = ((Number)facet_queries.getVal(i)).longValue();\n          QueryFacet qf = fi.queryFacets.get(returnedKey);\n          qf.count += count;\n        }\n      }\n\n      // step through each facet.field, adding results from this shard\n      NamedList facet_fields = (NamedList)facet_counts.get(\"facet_fields\");\n    \n      if (facet_fields != null) {\n        for (DistribFieldFacet dff : fi.facets.values()) {\n          dff.add(shardNum, (NamedList)facet_fields.get(dff.getKey()), dff.initialLimit);\n        }\n      }\n\n      // Distributed facet_dates\n      //\n      // The implementation below uses the first encountered shard's \n      // facet_dates as the basis for subsequent shards' data to be merged.\n      // (the \"NOW\" param should ensure consistency)\n      @SuppressWarnings(\"unchecked\")\n      SimpleOrderedMap<SimpleOrderedMap<Object>> facet_dates = \n        (SimpleOrderedMap<SimpleOrderedMap<Object>>) \n        facet_counts.get(\"facet_dates\");\n      \n      if (facet_dates != null) {\n\n        // go through each facet_date\n        for (Map.Entry<String,SimpleOrderedMap<Object>> entry : facet_dates) {\n          final String field = entry.getKey();\n          if (fi.dateFacets.get(field) == null) { \n            // first time we've seen this field, no merging\n            fi.dateFacets.add(field, entry.getValue());\n\n          } else { \n            // not the first time, merge current field\n\n            SimpleOrderedMap<Object> shardFieldValues \n              = entry.getValue();\n            SimpleOrderedMap<Object> existFieldValues \n              = fi.dateFacets.get(field);\n\n            for (Map.Entry<String,Object> existPair : existFieldValues) {\n              final String key = existPair.getKey();\n              if (key.equals(\"gap\") || \n                  key.equals(\"end\") || \n                  key.equals(\"start\")) {\n                // we can skip these, must all be the same across shards\n                continue; \n              }\n              // can be null if inconsistencies in shards responses\n              Integer newValue = (Integer) shardFieldValues.get(key);\n              if  (null != newValue) {\n                Integer oldValue = ((Integer) existPair.getValue());\n                existPair.setValue(oldValue + newValue);\n              }\n            }\n          }\n        }\n      }\n\n      // Distributed facet_ranges\n      //\n      // The implementation below uses the first encountered shard's \n      // facet_ranges as the basis for subsequent shards' data to be merged.\n      @SuppressWarnings(\"unchecked\")\n      SimpleOrderedMap<SimpleOrderedMap<Object>> facet_ranges = \n        (SimpleOrderedMap<SimpleOrderedMap<Object>>) \n        facet_counts.get(\"facet_ranges\");\n      \n      if (facet_ranges != null) {\n\n        // go through each facet_range\n        for (Map.Entry<String,SimpleOrderedMap<Object>> entry : facet_ranges) {\n          final String field = entry.getKey();\n          if (fi.rangeFacets.get(field) == null) { \n            // first time we've seen this field, no merging\n            fi.rangeFacets.add(field, entry.getValue());\n\n          } else { \n            // not the first time, merge current field counts\n\n            @SuppressWarnings(\"unchecked\")\n            NamedList<Integer> shardFieldValues \n              = (NamedList<Integer>) entry.getValue().get(\"counts\");\n\n            @SuppressWarnings(\"unchecked\")\n            NamedList<Integer> existFieldValues \n              = (NamedList<Integer>) fi.rangeFacets.get(field).get(\"counts\");\n\n            for (Map.Entry<String,Integer> existPair : existFieldValues) {\n              final String key = existPair.getKey();\n              // can be null if inconsistencies in shards responses\n              Integer newValue = shardFieldValues.get(key);\n              if  (null != newValue) {\n                Integer oldValue = existPair.getValue();\n                existPair.setValue(oldValue + newValue);\n              }\n            }\n          }\n        }\n      }\n    }\n\n    //\n    // This code currently assumes that there will be only a single\n    // request ((with responses from all shards) sent out to get facets...\n    // otherwise we would need to wait until all facet responses were received.\n    //\n\n    for (DistribFieldFacet dff : fi.facets.values()) {\n       // no need to check these facets for refinement\n      if (dff.initialLimit <= 0 && dff.initialMincount == 0) continue;\n\n      // only other case where index-sort doesn't need refinement is if minCount==0\n      if (dff.minCount == 0 && dff.sort.equals(FacetParams.FACET_SORT_INDEX)) continue;\n\n      @SuppressWarnings(\"unchecked\") // generic array's are annoying\n      List<String>[] tmp = (List<String>[]) new List[rb.shards.length];\n      dff._toRefine = tmp;\n\n      ShardFacetCount[] counts = dff.getCountSorted();\n      int ntop = Math.min(counts.length, dff.limit >= 0 ? dff.offset + dff.limit : Integer.MAX_VALUE);\n      long smallestCount = counts.length == 0 ? 0 : counts[ntop-1].count;\n\n      for (int i=0; i<counts.length; i++) {\n        ShardFacetCount sfc = counts[i];\n        boolean needRefinement = false;\n\n        if (i<ntop) {\n          // automatically flag the top values for refinement\n          // this should always be true for facet.sort=index\n          needRefinement = true;\n        } else {\n          // this logic should only be invoked for facet.sort=index (for now)\n\n          // calculate the maximum value that this term may have\n          // and if it is >= smallestCount, then flag for refinement\n          long maxCount = sfc.count;\n          for (int shardNum=0; shardNum<rb.shards.length; shardNum++) {\n            OpenBitSet obs = dff.counted[shardNum];\n            if (!obs.get(sfc.termNum)) {\n              // if missing from this shard, add the max it could be\n              maxCount += dff.maxPossible(sfc,shardNum);\n            }\n          }\n          if (maxCount >= smallestCount) {\n            // TODO: on a tie, we could check the term values\n            needRefinement = true;\n          }\n        }\n\n        if (needRefinement) {\n          // add a query for each shard missing the term that needs refinement\n          for (int shardNum=0; shardNum<rb.shards.length; shardNum++) {\n            OpenBitSet obs = dff.counted[shardNum];\n            if (!obs.get(sfc.termNum) && dff.maxPossible(sfc,shardNum)>0) {\n              dff.needRefinements = true;\n              List<String> lst = dff._toRefine[shardNum];\n              if (lst == null) {\n                lst = dff._toRefine[shardNum] = new ArrayList<String>();\n              }\n              lst.add(sfc.name);\n            }\n          }\n        }\n      }\n    }\n  }\n\n","sourceOld":"  private void countFacets(ResponseBuilder rb, ShardRequest sreq) {\n    FacetInfo fi = rb._facetInfo;\n\n    for (ShardResponse srsp: sreq.responses) {\n      int shardNum = rb.getShardNum(srsp.getShard());\n      NamedList facet_counts = (NamedList)srsp.getSolrResponse().getResponse().get(\"facet_counts\");\n\n      @SuppressWarnings(\"unchecked\")\n      List<String> excepts = (List<String>)facet_counts.get(\"exception\");\n      fi.addExceptions(excepts);\n\n      // handle facet queries\n      NamedList facet_queries = (NamedList)facet_counts.get(\"facet_queries\");\n      if (facet_queries != null) {\n        for (int i=0; i<facet_queries.size(); i++) {\n          String returnedKey = facet_queries.getName(i);\n          long count = ((Number)facet_queries.getVal(i)).longValue();\n          QueryFacet qf = fi.queryFacets.get(returnedKey);\n          qf.count += count;\n        }\n      }\n\n      // step through each facet.field, adding results from this shard\n      NamedList facet_fields = (NamedList)facet_counts.get(\"facet_fields\");\n    \n      if (facet_fields != null) {\n        for (DistribFieldFacet dff : fi.facets.values()) {\n          dff.add(shardNum, (NamedList)facet_fields.get(dff.getKey()), dff.initialLimit);\n        }\n      }\n    }\n\n\n    //\n    // This code currently assumes that there will be only a single\n    // request ((with responses from all shards) sent out to get facets...\n    // otherwise we would need to wait until all facet responses were received.\n    //\n\n    for (DistribFieldFacet dff : fi.facets.values()) {\n      if (dff.limit <= 0) continue; // no need to check these facets for refinement\n      if (dff.minCount <= 1 && dff.sort.equals(FacetParams.FACET_SORT_INDEX)) continue;\n\n      @SuppressWarnings(\"unchecked\") // generic array's are anoying\n      List<String>[] tmp = (List<String>[]) new List[rb.shards.length];\n      dff._toRefine = tmp;\n\n      ShardFacetCount[] counts = dff.getCountSorted();\n      int ntop = Math.min(counts.length, dff.offset + dff.limit);\n      long smallestCount = counts.length == 0 ? 0 : counts[ntop-1].count;\n\n      for (int i=0; i<counts.length; i++) {\n        ShardFacetCount sfc = counts[i];\n        boolean needRefinement = false;\n\n        if (i<ntop) {\n          // automatically flag the top values for refinement\n          needRefinement = true;\n        } else {\n          // calculate the maximum value that this term may have\n          // and if it is >= smallestCount, then flag for refinement\n          long maxCount = sfc.count;\n          for (int shardNum=0; shardNum<rb.shards.length; shardNum++) {\n            OpenBitSet obs = dff.counted[shardNum];\n            if (!obs.get(sfc.termNum)) {\n              // if missing from this shard, add the max it could be\n              maxCount += dff.maxPossible(sfc,shardNum);\n            }\n          }\n          if (maxCount >= smallestCount) {\n            // TODO: on a tie, we could check the term values\n            needRefinement = true;\n          }\n        }\n\n        if (needRefinement) {\n          // add a query for each shard missing the term that needs refinement\n          for (int shardNum=0; shardNum<rb.shards.length; shardNum++) {\n            OpenBitSet obs = dff.counted[shardNum];\n            if (!obs.get(sfc.termNum) && dff.maxPossible(sfc,shardNum)>0) {\n              dff.needRefinements = true;\n              List<String> lst = dff._toRefine[shardNum];\n              if (lst == null) {\n                lst = dff._toRefine[shardNum] = new ArrayList<String>();\n              }\n              lst.add(sfc.name);\n            }\n          }\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a3776dccca01c11e7046323cfad46a3b4a471233","date":1306100719,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"solr/src/java/org/apache/solr/handler/component/FacetComponent#countFacets(ResponseBuilder,ShardRequest).mjava","pathOld":"solr/src/java/org/apache/solr/handler/component/FacetComponent#countFacets(ResponseBuilder,ShardRequest).mjava","sourceNew":"  private void countFacets(ResponseBuilder rb, ShardRequest sreq) {\n    FacetInfo fi = rb._facetInfo;\n\n    for (ShardResponse srsp: sreq.responses) {\n      int shardNum = rb.getShardNum(srsp.getShard());\n      NamedList facet_counts = (NamedList)srsp.getSolrResponse().getResponse().get(\"facet_counts\");\n\n      @SuppressWarnings(\"unchecked\")\n      List<String> excepts = (List<String>)facet_counts.get(\"exception\");\n      fi.addExceptions(excepts);\n\n      // handle facet queries\n      NamedList facet_queries = (NamedList)facet_counts.get(\"facet_queries\");\n      if (facet_queries != null) {\n        for (int i=0; i<facet_queries.size(); i++) {\n          String returnedKey = facet_queries.getName(i);\n          long count = ((Number)facet_queries.getVal(i)).longValue();\n          QueryFacet qf = fi.queryFacets.get(returnedKey);\n          qf.count += count;\n        }\n      }\n\n      // step through each facet.field, adding results from this shard\n      NamedList facet_fields = (NamedList)facet_counts.get(\"facet_fields\");\n    \n      if (facet_fields != null) {\n        for (DistribFieldFacet dff : fi.facets.values()) {\n          dff.add(shardNum, (NamedList)facet_fields.get(dff.getKey()), dff.initialLimit);\n        }\n      }\n\n      // Distributed facet_dates\n      //\n      // The implementation below uses the first encountered shard's \n      // facet_dates as the basis for subsequent shards' data to be merged.\n      // (the \"NOW\" param should ensure consistency)\n      @SuppressWarnings(\"unchecked\")\n      SimpleOrderedMap<SimpleOrderedMap<Object>> facet_dates = \n        (SimpleOrderedMap<SimpleOrderedMap<Object>>) \n        facet_counts.get(\"facet_dates\");\n      \n      if (facet_dates != null) {\n\n        // go through each facet_date\n        for (Map.Entry<String,SimpleOrderedMap<Object>> entry : facet_dates) {\n          final String field = entry.getKey();\n          if (fi.dateFacets.get(field) == null) { \n            // first time we've seen this field, no merging\n            fi.dateFacets.add(field, entry.getValue());\n\n          } else { \n            // not the first time, merge current field\n\n            SimpleOrderedMap<Object> shardFieldValues \n              = entry.getValue();\n            SimpleOrderedMap<Object> existFieldValues \n              = fi.dateFacets.get(field);\n\n            for (Map.Entry<String,Object> existPair : existFieldValues) {\n              final String key = existPair.getKey();\n              if (key.equals(\"gap\") || \n                  key.equals(\"end\") || \n                  key.equals(\"start\")) {\n                // we can skip these, must all be the same across shards\n                continue; \n              }\n              // can be null if inconsistencies in shards responses\n              Integer newValue = (Integer) shardFieldValues.get(key);\n              if  (null != newValue) {\n                Integer oldValue = ((Integer) existPair.getValue());\n                existPair.setValue(oldValue + newValue);\n              }\n            }\n          }\n        }\n      }\n\n      // Distributed facet_ranges\n      //\n      // The implementation below uses the first encountered shard's \n      // facet_ranges as the basis for subsequent shards' data to be merged.\n      @SuppressWarnings(\"unchecked\")\n      SimpleOrderedMap<SimpleOrderedMap<Object>> facet_ranges = \n        (SimpleOrderedMap<SimpleOrderedMap<Object>>) \n        facet_counts.get(\"facet_ranges\");\n      \n      if (facet_ranges != null) {\n\n        // go through each facet_range\n        for (Map.Entry<String,SimpleOrderedMap<Object>> entry : facet_ranges) {\n          final String field = entry.getKey();\n          if (fi.rangeFacets.get(field) == null) { \n            // first time we've seen this field, no merging\n            fi.rangeFacets.add(field, entry.getValue());\n\n          } else { \n            // not the first time, merge current field counts\n\n            @SuppressWarnings(\"unchecked\")\n            NamedList<Integer> shardFieldValues \n              = (NamedList<Integer>) entry.getValue().get(\"counts\");\n\n            @SuppressWarnings(\"unchecked\")\n            NamedList<Integer> existFieldValues \n              = (NamedList<Integer>) fi.rangeFacets.get(field).get(\"counts\");\n\n            for (Map.Entry<String,Integer> existPair : existFieldValues) {\n              final String key = existPair.getKey();\n              // can be null if inconsistencies in shards responses\n              Integer newValue = shardFieldValues.get(key);\n              if  (null != newValue) {\n                Integer oldValue = existPair.getValue();\n                existPair.setValue(oldValue + newValue);\n              }\n            }\n          }\n        }\n      }\n    }\n\n    //\n    // This code currently assumes that there will be only a single\n    // request ((with responses from all shards) sent out to get facets...\n    // otherwise we would need to wait until all facet responses were received.\n    //\n\n    for (DistribFieldFacet dff : fi.facets.values()) {\n       // no need to check these facets for refinement\n      if (dff.initialLimit <= 0 && dff.initialMincount == 0) continue;\n\n      // only other case where index-sort doesn't need refinement is if minCount==0\n      if (dff.minCount == 0 && dff.sort.equals(FacetParams.FACET_SORT_INDEX)) continue;\n\n      @SuppressWarnings(\"unchecked\") // generic array's are annoying\n      List<String>[] tmp = (List<String>[]) new List[rb.shards.length];\n      dff._toRefine = tmp;\n\n      ShardFacetCount[] counts = dff.getCountSorted();\n      int ntop = Math.min(counts.length, dff.limit >= 0 ? dff.offset + dff.limit : Integer.MAX_VALUE);\n      long smallestCount = counts.length == 0 ? 0 : counts[ntop-1].count;\n\n      for (int i=0; i<counts.length; i++) {\n        ShardFacetCount sfc = counts[i];\n        boolean needRefinement = false;\n\n        if (i<ntop) {\n          // automatically flag the top values for refinement\n          // this should always be true for facet.sort=index\n          needRefinement = true;\n        } else {\n          // this logic should only be invoked for facet.sort=index (for now)\n\n          // calculate the maximum value that this term may have\n          // and if it is >= smallestCount, then flag for refinement\n          long maxCount = sfc.count;\n          for (int shardNum=0; shardNum<rb.shards.length; shardNum++) {\n            OpenBitSet obs = dff.counted[shardNum];\n            if (!obs.get(sfc.termNum)) {\n              // if missing from this shard, add the max it could be\n              maxCount += dff.maxPossible(sfc,shardNum);\n            }\n          }\n          if (maxCount >= smallestCount) {\n            // TODO: on a tie, we could check the term values\n            needRefinement = true;\n          }\n        }\n\n        if (needRefinement) {\n          // add a query for each shard missing the term that needs refinement\n          for (int shardNum=0; shardNum<rb.shards.length; shardNum++) {\n            OpenBitSet obs = dff.counted[shardNum];\n            if (!obs.get(sfc.termNum) && dff.maxPossible(sfc,shardNum)>0) {\n              dff.needRefinements = true;\n              List<String> lst = dff._toRefine[shardNum];\n              if (lst == null) {\n                lst = dff._toRefine[shardNum] = new ArrayList<String>();\n              }\n              lst.add(sfc.name);\n            }\n          }\n        }\n      }\n    }\n  }\n\n","sourceOld":"  private void countFacets(ResponseBuilder rb, ShardRequest sreq) {\n    FacetInfo fi = rb._facetInfo;\n\n    for (ShardResponse srsp: sreq.responses) {\n      int shardNum = rb.getShardNum(srsp.getShard());\n      NamedList facet_counts = (NamedList)srsp.getSolrResponse().getResponse().get(\"facet_counts\");\n\n      @SuppressWarnings(\"unchecked\")\n      List<String> excepts = (List<String>)facet_counts.get(\"exception\");\n      fi.addExceptions(excepts);\n\n      // handle facet queries\n      NamedList facet_queries = (NamedList)facet_counts.get(\"facet_queries\");\n      if (facet_queries != null) {\n        for (int i=0; i<facet_queries.size(); i++) {\n          String returnedKey = facet_queries.getName(i);\n          long count = ((Number)facet_queries.getVal(i)).longValue();\n          QueryFacet qf = fi.queryFacets.get(returnedKey);\n          qf.count += count;\n        }\n      }\n\n      // step through each facet.field, adding results from this shard\n      NamedList facet_fields = (NamedList)facet_counts.get(\"facet_fields\");\n    \n      if (facet_fields != null) {\n        for (DistribFieldFacet dff : fi.facets.values()) {\n          dff.add(shardNum, (NamedList)facet_fields.get(dff.getKey()), dff.initialLimit);\n        }\n      }\n    }\n\n\n    //\n    // This code currently assumes that there will be only a single\n    // request ((with responses from all shards) sent out to get facets...\n    // otherwise we would need to wait until all facet responses were received.\n    //\n\n    for (DistribFieldFacet dff : fi.facets.values()) {\n      if (dff.limit <= 0) continue; // no need to check these facets for refinement\n      if (dff.minCount <= 1 && dff.sort.equals(FacetParams.FACET_SORT_INDEX)) continue;\n\n      @SuppressWarnings(\"unchecked\") // generic array's are anoying\n      List<String>[] tmp = (List<String>[]) new List[rb.shards.length];\n      dff._toRefine = tmp;\n\n      ShardFacetCount[] counts = dff.getCountSorted();\n      int ntop = Math.min(counts.length, dff.offset + dff.limit);\n      long smallestCount = counts.length == 0 ? 0 : counts[ntop-1].count;\n\n      for (int i=0; i<counts.length; i++) {\n        ShardFacetCount sfc = counts[i];\n        boolean needRefinement = false;\n\n        if (i<ntop) {\n          // automatically flag the top values for refinement\n          needRefinement = true;\n        } else {\n          // calculate the maximum value that this term may have\n          // and if it is >= smallestCount, then flag for refinement\n          long maxCount = sfc.count;\n          for (int shardNum=0; shardNum<rb.shards.length; shardNum++) {\n            OpenBitSet obs = dff.counted[shardNum];\n            if (!obs.get(sfc.termNum)) {\n              // if missing from this shard, add the max it could be\n              maxCount += dff.maxPossible(sfc,shardNum);\n            }\n          }\n          if (maxCount >= smallestCount) {\n            // TODO: on a tie, we could check the term values\n            needRefinement = true;\n          }\n        }\n\n        if (needRefinement) {\n          // add a query for each shard missing the term that needs refinement\n          for (int shardNum=0; shardNum<rb.shards.length; shardNum++) {\n            OpenBitSet obs = dff.counted[shardNum];\n            if (!obs.get(sfc.termNum) && dff.maxPossible(sfc,shardNum)>0) {\n              dff.needRefinements = true;\n              List<String> lst = dff._toRefine[shardNum];\n              if (lst == null) {\n                lst = dff._toRefine[shardNum] = new ArrayList<String>();\n              }\n              lst.add(sfc.name);\n            }\n          }\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c903c3d15906a3da96b8c0c2fb704491005fdbdb","date":1453508227,"type":5,"author":"Dawid Weiss","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/FacetComponent#countFacets(ResponseBuilder,ShardRequest).mjava","pathOld":"solr/src/java/org/apache/solr/handler/component/FacetComponent#countFacets(ResponseBuilder,ShardRequest).mjava","sourceNew":"  private void countFacets(ResponseBuilder rb, ShardRequest sreq) {\n    FacetInfo fi = rb._facetInfo;\n\n    for (ShardResponse srsp: sreq.responses) {\n      int shardNum = rb.getShardNum(srsp.getShard());\n      NamedList facet_counts = (NamedList)srsp.getSolrResponse().getResponse().get(\"facet_counts\");\n\n      @SuppressWarnings(\"unchecked\")\n      List<String> excepts = (List<String>)facet_counts.get(\"exception\");\n      fi.addExceptions(excepts);\n\n      // handle facet queries\n      NamedList facet_queries = (NamedList)facet_counts.get(\"facet_queries\");\n      if (facet_queries != null) {\n        for (int i=0; i<facet_queries.size(); i++) {\n          String returnedKey = facet_queries.getName(i);\n          long count = ((Number)facet_queries.getVal(i)).longValue();\n          QueryFacet qf = fi.queryFacets.get(returnedKey);\n          qf.count += count;\n        }\n      }\n\n      // step through each facet.field, adding results from this shard\n      NamedList facet_fields = (NamedList)facet_counts.get(\"facet_fields\");\n    \n      if (facet_fields != null) {\n        for (DistribFieldFacet dff : fi.facets.values()) {\n          dff.add(shardNum, (NamedList)facet_fields.get(dff.getKey()), dff.initialLimit);\n        }\n      }\n\n      // Distributed facet_dates\n      //\n      // The implementation below uses the first encountered shard's \n      // facet_dates as the basis for subsequent shards' data to be merged.\n      // (the \"NOW\" param should ensure consistency)\n      @SuppressWarnings(\"unchecked\")\n      SimpleOrderedMap<SimpleOrderedMap<Object>> facet_dates = \n        (SimpleOrderedMap<SimpleOrderedMap<Object>>) \n        facet_counts.get(\"facet_dates\");\n      \n      if (facet_dates != null) {\n\n        // go through each facet_date\n        for (Map.Entry<String,SimpleOrderedMap<Object>> entry : facet_dates) {\n          final String field = entry.getKey();\n          if (fi.dateFacets.get(field) == null) { \n            // first time we've seen this field, no merging\n            fi.dateFacets.add(field, entry.getValue());\n\n          } else { \n            // not the first time, merge current field\n\n            SimpleOrderedMap<Object> shardFieldValues \n              = entry.getValue();\n            SimpleOrderedMap<Object> existFieldValues \n              = fi.dateFacets.get(field);\n\n            for (Map.Entry<String,Object> existPair : existFieldValues) {\n              final String key = existPair.getKey();\n              if (key.equals(\"gap\") || \n                  key.equals(\"end\") || \n                  key.equals(\"start\")) {\n                // we can skip these, must all be the same across shards\n                continue; \n              }\n              // can be null if inconsistencies in shards responses\n              Integer newValue = (Integer) shardFieldValues.get(key);\n              if  (null != newValue) {\n                Integer oldValue = ((Integer) existPair.getValue());\n                existPair.setValue(oldValue + newValue);\n              }\n            }\n          }\n        }\n      }\n\n      // Distributed facet_ranges\n      //\n      // The implementation below uses the first encountered shard's \n      // facet_ranges as the basis for subsequent shards' data to be merged.\n      @SuppressWarnings(\"unchecked\")\n      SimpleOrderedMap<SimpleOrderedMap<Object>> facet_ranges = \n        (SimpleOrderedMap<SimpleOrderedMap<Object>>) \n        facet_counts.get(\"facet_ranges\");\n      \n      if (facet_ranges != null) {\n\n        // go through each facet_range\n        for (Map.Entry<String,SimpleOrderedMap<Object>> entry : facet_ranges) {\n          final String field = entry.getKey();\n          if (fi.rangeFacets.get(field) == null) { \n            // first time we've seen this field, no merging\n            fi.rangeFacets.add(field, entry.getValue());\n\n          } else { \n            // not the first time, merge current field counts\n\n            @SuppressWarnings(\"unchecked\")\n            NamedList<Integer> shardFieldValues \n              = (NamedList<Integer>) entry.getValue().get(\"counts\");\n\n            @SuppressWarnings(\"unchecked\")\n            NamedList<Integer> existFieldValues \n              = (NamedList<Integer>) fi.rangeFacets.get(field).get(\"counts\");\n\n            for (Map.Entry<String,Integer> existPair : existFieldValues) {\n              final String key = existPair.getKey();\n              // can be null if inconsistencies in shards responses\n              Integer newValue = shardFieldValues.get(key);\n              if  (null != newValue) {\n                Integer oldValue = existPair.getValue();\n                existPair.setValue(oldValue + newValue);\n              }\n            }\n          }\n        }\n      }\n    }\n\n    //\n    // This code currently assumes that there will be only a single\n    // request ((with responses from all shards) sent out to get facets...\n    // otherwise we would need to wait until all facet responses were received.\n    //\n\n    for (DistribFieldFacet dff : fi.facets.values()) {\n       // no need to check these facets for refinement\n      if (dff.initialLimit <= 0 && dff.initialMincount == 0) continue;\n\n      // only other case where index-sort doesn't need refinement is if minCount==0\n      if (dff.minCount == 0 && dff.sort.equals(FacetParams.FACET_SORT_INDEX)) continue;\n\n      @SuppressWarnings(\"unchecked\") // generic array's are annoying\n      List<String>[] tmp = (List<String>[]) new List[rb.shards.length];\n      dff._toRefine = tmp;\n\n      ShardFacetCount[] counts = dff.getCountSorted();\n      int ntop = Math.min(counts.length, dff.limit >= 0 ? dff.offset + dff.limit : Integer.MAX_VALUE);\n      long smallestCount = counts.length == 0 ? 0 : counts[ntop-1].count;\n\n      for (int i=0; i<counts.length; i++) {\n        ShardFacetCount sfc = counts[i];\n        boolean needRefinement = false;\n\n        if (i<ntop) {\n          // automatically flag the top values for refinement\n          // this should always be true for facet.sort=index\n          needRefinement = true;\n        } else {\n          // this logic should only be invoked for facet.sort=index (for now)\n\n          // calculate the maximum value that this term may have\n          // and if it is >= smallestCount, then flag for refinement\n          long maxCount = sfc.count;\n          for (int shardNum=0; shardNum<rb.shards.length; shardNum++) {\n            OpenBitSet obs = dff.counted[shardNum];\n            if (!obs.get(sfc.termNum)) {\n              // if missing from this shard, add the max it could be\n              maxCount += dff.maxPossible(sfc,shardNum);\n            }\n          }\n          if (maxCount >= smallestCount) {\n            // TODO: on a tie, we could check the term values\n            needRefinement = true;\n          }\n        }\n\n        if (needRefinement) {\n          // add a query for each shard missing the term that needs refinement\n          for (int shardNum=0; shardNum<rb.shards.length; shardNum++) {\n            OpenBitSet obs = dff.counted[shardNum];\n            if (!obs.get(sfc.termNum) && dff.maxPossible(sfc,shardNum)>0) {\n              dff.needRefinements = true;\n              List<String> lst = dff._toRefine[shardNum];\n              if (lst == null) {\n                lst = dff._toRefine[shardNum] = new ArrayList<String>();\n              }\n              lst.add(sfc.name);\n            }\n          }\n        }\n      }\n    }\n  }\n\n","sourceOld":"  private void countFacets(ResponseBuilder rb, ShardRequest sreq) {\n    FacetInfo fi = rb._facetInfo;\n\n    for (ShardResponse srsp: sreq.responses) {\n      int shardNum = rb.getShardNum(srsp.getShard());\n      NamedList facet_counts = (NamedList)srsp.getSolrResponse().getResponse().get(\"facet_counts\");\n\n      @SuppressWarnings(\"unchecked\")\n      List<String> excepts = (List<String>)facet_counts.get(\"exception\");\n      fi.addExceptions(excepts);\n\n      // handle facet queries\n      NamedList facet_queries = (NamedList)facet_counts.get(\"facet_queries\");\n      if (facet_queries != null) {\n        for (int i=0; i<facet_queries.size(); i++) {\n          String returnedKey = facet_queries.getName(i);\n          long count = ((Number)facet_queries.getVal(i)).longValue();\n          QueryFacet qf = fi.queryFacets.get(returnedKey);\n          qf.count += count;\n        }\n      }\n\n      // step through each facet.field, adding results from this shard\n      NamedList facet_fields = (NamedList)facet_counts.get(\"facet_fields\");\n    \n      if (facet_fields != null) {\n        for (DistribFieldFacet dff : fi.facets.values()) {\n          dff.add(shardNum, (NamedList)facet_fields.get(dff.getKey()), dff.initialLimit);\n        }\n      }\n\n      // Distributed facet_dates\n      //\n      // The implementation below uses the first encountered shard's \n      // facet_dates as the basis for subsequent shards' data to be merged.\n      // (the \"NOW\" param should ensure consistency)\n      @SuppressWarnings(\"unchecked\")\n      SimpleOrderedMap<SimpleOrderedMap<Object>> facet_dates = \n        (SimpleOrderedMap<SimpleOrderedMap<Object>>) \n        facet_counts.get(\"facet_dates\");\n      \n      if (facet_dates != null) {\n\n        // go through each facet_date\n        for (Map.Entry<String,SimpleOrderedMap<Object>> entry : facet_dates) {\n          final String field = entry.getKey();\n          if (fi.dateFacets.get(field) == null) { \n            // first time we've seen this field, no merging\n            fi.dateFacets.add(field, entry.getValue());\n\n          } else { \n            // not the first time, merge current field\n\n            SimpleOrderedMap<Object> shardFieldValues \n              = entry.getValue();\n            SimpleOrderedMap<Object> existFieldValues \n              = fi.dateFacets.get(field);\n\n            for (Map.Entry<String,Object> existPair : existFieldValues) {\n              final String key = existPair.getKey();\n              if (key.equals(\"gap\") || \n                  key.equals(\"end\") || \n                  key.equals(\"start\")) {\n                // we can skip these, must all be the same across shards\n                continue; \n              }\n              // can be null if inconsistencies in shards responses\n              Integer newValue = (Integer) shardFieldValues.get(key);\n              if  (null != newValue) {\n                Integer oldValue = ((Integer) existPair.getValue());\n                existPair.setValue(oldValue + newValue);\n              }\n            }\n          }\n        }\n      }\n\n      // Distributed facet_ranges\n      //\n      // The implementation below uses the first encountered shard's \n      // facet_ranges as the basis for subsequent shards' data to be merged.\n      @SuppressWarnings(\"unchecked\")\n      SimpleOrderedMap<SimpleOrderedMap<Object>> facet_ranges = \n        (SimpleOrderedMap<SimpleOrderedMap<Object>>) \n        facet_counts.get(\"facet_ranges\");\n      \n      if (facet_ranges != null) {\n\n        // go through each facet_range\n        for (Map.Entry<String,SimpleOrderedMap<Object>> entry : facet_ranges) {\n          final String field = entry.getKey();\n          if (fi.rangeFacets.get(field) == null) { \n            // first time we've seen this field, no merging\n            fi.rangeFacets.add(field, entry.getValue());\n\n          } else { \n            // not the first time, merge current field counts\n\n            @SuppressWarnings(\"unchecked\")\n            NamedList<Integer> shardFieldValues \n              = (NamedList<Integer>) entry.getValue().get(\"counts\");\n\n            @SuppressWarnings(\"unchecked\")\n            NamedList<Integer> existFieldValues \n              = (NamedList<Integer>) fi.rangeFacets.get(field).get(\"counts\");\n\n            for (Map.Entry<String,Integer> existPair : existFieldValues) {\n              final String key = existPair.getKey();\n              // can be null if inconsistencies in shards responses\n              Integer newValue = shardFieldValues.get(key);\n              if  (null != newValue) {\n                Integer oldValue = existPair.getValue();\n                existPair.setValue(oldValue + newValue);\n              }\n            }\n          }\n        }\n      }\n    }\n\n    //\n    // This code currently assumes that there will be only a single\n    // request ((with responses from all shards) sent out to get facets...\n    // otherwise we would need to wait until all facet responses were received.\n    //\n\n    for (DistribFieldFacet dff : fi.facets.values()) {\n       // no need to check these facets for refinement\n      if (dff.initialLimit <= 0 && dff.initialMincount == 0) continue;\n\n      // only other case where index-sort doesn't need refinement is if minCount==0\n      if (dff.minCount == 0 && dff.sort.equals(FacetParams.FACET_SORT_INDEX)) continue;\n\n      @SuppressWarnings(\"unchecked\") // generic array's are annoying\n      List<String>[] tmp = (List<String>[]) new List[rb.shards.length];\n      dff._toRefine = tmp;\n\n      ShardFacetCount[] counts = dff.getCountSorted();\n      int ntop = Math.min(counts.length, dff.limit >= 0 ? dff.offset + dff.limit : Integer.MAX_VALUE);\n      long smallestCount = counts.length == 0 ? 0 : counts[ntop-1].count;\n\n      for (int i=0; i<counts.length; i++) {\n        ShardFacetCount sfc = counts[i];\n        boolean needRefinement = false;\n\n        if (i<ntop) {\n          // automatically flag the top values for refinement\n          // this should always be true for facet.sort=index\n          needRefinement = true;\n        } else {\n          // this logic should only be invoked for facet.sort=index (for now)\n\n          // calculate the maximum value that this term may have\n          // and if it is >= smallestCount, then flag for refinement\n          long maxCount = sfc.count;\n          for (int shardNum=0; shardNum<rb.shards.length; shardNum++) {\n            OpenBitSet obs = dff.counted[shardNum];\n            if (!obs.get(sfc.termNum)) {\n              // if missing from this shard, add the max it could be\n              maxCount += dff.maxPossible(sfc,shardNum);\n            }\n          }\n          if (maxCount >= smallestCount) {\n            // TODO: on a tie, we could check the term values\n            needRefinement = true;\n          }\n        }\n\n        if (needRefinement) {\n          // add a query for each shard missing the term that needs refinement\n          for (int shardNum=0; shardNum<rb.shards.length; shardNum++) {\n            OpenBitSet obs = dff.counted[shardNum];\n            if (!obs.get(sfc.termNum) && dff.maxPossible(sfc,shardNum)>0) {\n              dff.needRefinements = true;\n              List<String> lst = dff._toRefine[shardNum];\n              if (lst == null) {\n                lst = dff._toRefine[shardNum] = new ArrayList<String>();\n              }\n              lst.add(sfc.name);\n            }\n          }\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a258fbb26824fd104ed795e5d9033d2d040049ee","date":1453508252,"type":5,"author":"Dawid Weiss","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/FacetComponent#countFacets(ResponseBuilder,ShardRequest).mjava","pathOld":"solr/src/java/org/apache/solr/handler/component/FacetComponent#countFacets(ResponseBuilder,ShardRequest).mjava","sourceNew":"  private void countFacets(ResponseBuilder rb, ShardRequest sreq) {\n    FacetInfo fi = rb._facetInfo;\n\n    for (ShardResponse srsp: sreq.responses) {\n      int shardNum = rb.getShardNum(srsp.getShard());\n      NamedList facet_counts = (NamedList)srsp.getSolrResponse().getResponse().get(\"facet_counts\");\n\n      @SuppressWarnings(\"unchecked\")\n      List<String> excepts = (List<String>)facet_counts.get(\"exception\");\n      fi.addExceptions(excepts);\n\n      // handle facet queries\n      NamedList facet_queries = (NamedList)facet_counts.get(\"facet_queries\");\n      if (facet_queries != null) {\n        for (int i=0; i<facet_queries.size(); i++) {\n          String returnedKey = facet_queries.getName(i);\n          long count = ((Number)facet_queries.getVal(i)).longValue();\n          QueryFacet qf = fi.queryFacets.get(returnedKey);\n          qf.count += count;\n        }\n      }\n\n      // step through each facet.field, adding results from this shard\n      NamedList facet_fields = (NamedList)facet_counts.get(\"facet_fields\");\n    \n      if (facet_fields != null) {\n        for (DistribFieldFacet dff : fi.facets.values()) {\n          dff.add(shardNum, (NamedList)facet_fields.get(dff.getKey()), dff.initialLimit);\n        }\n      }\n\n      // Distributed facet_dates\n      //\n      // The implementation below uses the first encountered shard's \n      // facet_dates as the basis for subsequent shards' data to be merged.\n      // (the \"NOW\" param should ensure consistency)\n      @SuppressWarnings(\"unchecked\")\n      SimpleOrderedMap<SimpleOrderedMap<Object>> facet_dates = \n        (SimpleOrderedMap<SimpleOrderedMap<Object>>) \n        facet_counts.get(\"facet_dates\");\n      \n      if (facet_dates != null) {\n\n        // go through each facet_date\n        for (Map.Entry<String,SimpleOrderedMap<Object>> entry : facet_dates) {\n          final String field = entry.getKey();\n          if (fi.dateFacets.get(field) == null) { \n            // first time we've seen this field, no merging\n            fi.dateFacets.add(field, entry.getValue());\n\n          } else { \n            // not the first time, merge current field\n\n            SimpleOrderedMap<Object> shardFieldValues \n              = entry.getValue();\n            SimpleOrderedMap<Object> existFieldValues \n              = fi.dateFacets.get(field);\n\n            for (Map.Entry<String,Object> existPair : existFieldValues) {\n              final String key = existPair.getKey();\n              if (key.equals(\"gap\") || \n                  key.equals(\"end\") || \n                  key.equals(\"start\")) {\n                // we can skip these, must all be the same across shards\n                continue; \n              }\n              // can be null if inconsistencies in shards responses\n              Integer newValue = (Integer) shardFieldValues.get(key);\n              if  (null != newValue) {\n                Integer oldValue = ((Integer) existPair.getValue());\n                existPair.setValue(oldValue + newValue);\n              }\n            }\n          }\n        }\n      }\n\n      // Distributed facet_ranges\n      //\n      // The implementation below uses the first encountered shard's \n      // facet_ranges as the basis for subsequent shards' data to be merged.\n      @SuppressWarnings(\"unchecked\")\n      SimpleOrderedMap<SimpleOrderedMap<Object>> facet_ranges = \n        (SimpleOrderedMap<SimpleOrderedMap<Object>>) \n        facet_counts.get(\"facet_ranges\");\n      \n      if (facet_ranges != null) {\n\n        // go through each facet_range\n        for (Map.Entry<String,SimpleOrderedMap<Object>> entry : facet_ranges) {\n          final String field = entry.getKey();\n          if (fi.rangeFacets.get(field) == null) { \n            // first time we've seen this field, no merging\n            fi.rangeFacets.add(field, entry.getValue());\n\n          } else { \n            // not the first time, merge current field counts\n\n            @SuppressWarnings(\"unchecked\")\n            NamedList<Integer> shardFieldValues \n              = (NamedList<Integer>) entry.getValue().get(\"counts\");\n\n            @SuppressWarnings(\"unchecked\")\n            NamedList<Integer> existFieldValues \n              = (NamedList<Integer>) fi.rangeFacets.get(field).get(\"counts\");\n\n            for (Map.Entry<String,Integer> existPair : existFieldValues) {\n              final String key = existPair.getKey();\n              // can be null if inconsistencies in shards responses\n              Integer newValue = shardFieldValues.get(key);\n              if  (null != newValue) {\n                Integer oldValue = existPair.getValue();\n                existPair.setValue(oldValue + newValue);\n              }\n            }\n          }\n        }\n      }\n    }\n\n    //\n    // This code currently assumes that there will be only a single\n    // request ((with responses from all shards) sent out to get facets...\n    // otherwise we would need to wait until all facet responses were received.\n    //\n\n    for (DistribFieldFacet dff : fi.facets.values()) {\n       // no need to check these facets for refinement\n      if (dff.initialLimit <= 0 && dff.initialMincount == 0) continue;\n\n      // only other case where index-sort doesn't need refinement is if minCount==0\n      if (dff.minCount == 0 && dff.sort.equals(FacetParams.FACET_SORT_INDEX)) continue;\n\n      @SuppressWarnings(\"unchecked\") // generic array's are annoying\n      List<String>[] tmp = (List<String>[]) new List[rb.shards.length];\n      dff._toRefine = tmp;\n\n      ShardFacetCount[] counts = dff.getCountSorted();\n      int ntop = Math.min(counts.length, dff.limit >= 0 ? dff.offset + dff.limit : Integer.MAX_VALUE);\n      long smallestCount = counts.length == 0 ? 0 : counts[ntop-1].count;\n\n      for (int i=0; i<counts.length; i++) {\n        ShardFacetCount sfc = counts[i];\n        boolean needRefinement = false;\n\n        if (i<ntop) {\n          // automatically flag the top values for refinement\n          // this should always be true for facet.sort=index\n          needRefinement = true;\n        } else {\n          // this logic should only be invoked for facet.sort=index (for now)\n\n          // calculate the maximum value that this term may have\n          // and if it is >= smallestCount, then flag for refinement\n          long maxCount = sfc.count;\n          for (int shardNum=0; shardNum<rb.shards.length; shardNum++) {\n            OpenBitSet obs = dff.counted[shardNum];\n            if (!obs.get(sfc.termNum)) {\n              // if missing from this shard, add the max it could be\n              maxCount += dff.maxPossible(sfc,shardNum);\n            }\n          }\n          if (maxCount >= smallestCount) {\n            // TODO: on a tie, we could check the term values\n            needRefinement = true;\n          }\n        }\n\n        if (needRefinement) {\n          // add a query for each shard missing the term that needs refinement\n          for (int shardNum=0; shardNum<rb.shards.length; shardNum++) {\n            OpenBitSet obs = dff.counted[shardNum];\n            if (!obs.get(sfc.termNum) && dff.maxPossible(sfc,shardNum)>0) {\n              dff.needRefinements = true;\n              List<String> lst = dff._toRefine[shardNum];\n              if (lst == null) {\n                lst = dff._toRefine[shardNum] = new ArrayList<String>();\n              }\n              lst.add(sfc.name);\n            }\n          }\n        }\n      }\n    }\n  }\n\n","sourceOld":"  private void countFacets(ResponseBuilder rb, ShardRequest sreq) {\n    FacetInfo fi = rb._facetInfo;\n\n    for (ShardResponse srsp: sreq.responses) {\n      int shardNum = rb.getShardNum(srsp.getShard());\n      NamedList facet_counts = (NamedList)srsp.getSolrResponse().getResponse().get(\"facet_counts\");\n\n      @SuppressWarnings(\"unchecked\")\n      List<String> excepts = (List<String>)facet_counts.get(\"exception\");\n      fi.addExceptions(excepts);\n\n      // handle facet queries\n      NamedList facet_queries = (NamedList)facet_counts.get(\"facet_queries\");\n      if (facet_queries != null) {\n        for (int i=0; i<facet_queries.size(); i++) {\n          String returnedKey = facet_queries.getName(i);\n          long count = ((Number)facet_queries.getVal(i)).longValue();\n          QueryFacet qf = fi.queryFacets.get(returnedKey);\n          qf.count += count;\n        }\n      }\n\n      // step through each facet.field, adding results from this shard\n      NamedList facet_fields = (NamedList)facet_counts.get(\"facet_fields\");\n    \n      if (facet_fields != null) {\n        for (DistribFieldFacet dff : fi.facets.values()) {\n          dff.add(shardNum, (NamedList)facet_fields.get(dff.getKey()), dff.initialLimit);\n        }\n      }\n\n      // Distributed facet_dates\n      //\n      // The implementation below uses the first encountered shard's \n      // facet_dates as the basis for subsequent shards' data to be merged.\n      // (the \"NOW\" param should ensure consistency)\n      @SuppressWarnings(\"unchecked\")\n      SimpleOrderedMap<SimpleOrderedMap<Object>> facet_dates = \n        (SimpleOrderedMap<SimpleOrderedMap<Object>>) \n        facet_counts.get(\"facet_dates\");\n      \n      if (facet_dates != null) {\n\n        // go through each facet_date\n        for (Map.Entry<String,SimpleOrderedMap<Object>> entry : facet_dates) {\n          final String field = entry.getKey();\n          if (fi.dateFacets.get(field) == null) { \n            // first time we've seen this field, no merging\n            fi.dateFacets.add(field, entry.getValue());\n\n          } else { \n            // not the first time, merge current field\n\n            SimpleOrderedMap<Object> shardFieldValues \n              = entry.getValue();\n            SimpleOrderedMap<Object> existFieldValues \n              = fi.dateFacets.get(field);\n\n            for (Map.Entry<String,Object> existPair : existFieldValues) {\n              final String key = existPair.getKey();\n              if (key.equals(\"gap\") || \n                  key.equals(\"end\") || \n                  key.equals(\"start\")) {\n                // we can skip these, must all be the same across shards\n                continue; \n              }\n              // can be null if inconsistencies in shards responses\n              Integer newValue = (Integer) shardFieldValues.get(key);\n              if  (null != newValue) {\n                Integer oldValue = ((Integer) existPair.getValue());\n                existPair.setValue(oldValue + newValue);\n              }\n            }\n          }\n        }\n      }\n\n      // Distributed facet_ranges\n      //\n      // The implementation below uses the first encountered shard's \n      // facet_ranges as the basis for subsequent shards' data to be merged.\n      @SuppressWarnings(\"unchecked\")\n      SimpleOrderedMap<SimpleOrderedMap<Object>> facet_ranges = \n        (SimpleOrderedMap<SimpleOrderedMap<Object>>) \n        facet_counts.get(\"facet_ranges\");\n      \n      if (facet_ranges != null) {\n\n        // go through each facet_range\n        for (Map.Entry<String,SimpleOrderedMap<Object>> entry : facet_ranges) {\n          final String field = entry.getKey();\n          if (fi.rangeFacets.get(field) == null) { \n            // first time we've seen this field, no merging\n            fi.rangeFacets.add(field, entry.getValue());\n\n          } else { \n            // not the first time, merge current field counts\n\n            @SuppressWarnings(\"unchecked\")\n            NamedList<Integer> shardFieldValues \n              = (NamedList<Integer>) entry.getValue().get(\"counts\");\n\n            @SuppressWarnings(\"unchecked\")\n            NamedList<Integer> existFieldValues \n              = (NamedList<Integer>) fi.rangeFacets.get(field).get(\"counts\");\n\n            for (Map.Entry<String,Integer> existPair : existFieldValues) {\n              final String key = existPair.getKey();\n              // can be null if inconsistencies in shards responses\n              Integer newValue = shardFieldValues.get(key);\n              if  (null != newValue) {\n                Integer oldValue = existPair.getValue();\n                existPair.setValue(oldValue + newValue);\n              }\n            }\n          }\n        }\n      }\n    }\n\n    //\n    // This code currently assumes that there will be only a single\n    // request ((with responses from all shards) sent out to get facets...\n    // otherwise we would need to wait until all facet responses were received.\n    //\n\n    for (DistribFieldFacet dff : fi.facets.values()) {\n       // no need to check these facets for refinement\n      if (dff.initialLimit <= 0 && dff.initialMincount == 0) continue;\n\n      // only other case where index-sort doesn't need refinement is if minCount==0\n      if (dff.minCount == 0 && dff.sort.equals(FacetParams.FACET_SORT_INDEX)) continue;\n\n      @SuppressWarnings(\"unchecked\") // generic array's are annoying\n      List<String>[] tmp = (List<String>[]) new List[rb.shards.length];\n      dff._toRefine = tmp;\n\n      ShardFacetCount[] counts = dff.getCountSorted();\n      int ntop = Math.min(counts.length, dff.limit >= 0 ? dff.offset + dff.limit : Integer.MAX_VALUE);\n      long smallestCount = counts.length == 0 ? 0 : counts[ntop-1].count;\n\n      for (int i=0; i<counts.length; i++) {\n        ShardFacetCount sfc = counts[i];\n        boolean needRefinement = false;\n\n        if (i<ntop) {\n          // automatically flag the top values for refinement\n          // this should always be true for facet.sort=index\n          needRefinement = true;\n        } else {\n          // this logic should only be invoked for facet.sort=index (for now)\n\n          // calculate the maximum value that this term may have\n          // and if it is >= smallestCount, then flag for refinement\n          long maxCount = sfc.count;\n          for (int shardNum=0; shardNum<rb.shards.length; shardNum++) {\n            OpenBitSet obs = dff.counted[shardNum];\n            if (!obs.get(sfc.termNum)) {\n              // if missing from this shard, add the max it could be\n              maxCount += dff.maxPossible(sfc,shardNum);\n            }\n          }\n          if (maxCount >= smallestCount) {\n            // TODO: on a tie, we could check the term values\n            needRefinement = true;\n          }\n        }\n\n        if (needRefinement) {\n          // add a query for each shard missing the term that needs refinement\n          for (int shardNum=0; shardNum<rb.shards.length; shardNum++) {\n            OpenBitSet obs = dff.counted[shardNum];\n            if (!obs.get(sfc.termNum) && dff.maxPossible(sfc,shardNum)>0) {\n              dff.needRefinements = true;\n              List<String> lst = dff._toRefine[shardNum];\n              if (lst == null) {\n                lst = dff._toRefine[shardNum] = new ArrayList<String>();\n              }\n              lst.add(sfc.name);\n            }\n          }\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c26f00b574427b55127e869b935845554afde1fa","date":1310252513,"type":5,"author":"Steven Rowe","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/handler/component/FacetComponent#countFacets(ResponseBuilder,ShardRequest).mjava","pathOld":"solr/src/java/org/apache/solr/handler/component/FacetComponent#countFacets(ResponseBuilder,ShardRequest).mjava","sourceNew":"  private void countFacets(ResponseBuilder rb, ShardRequest sreq) {\n    FacetInfo fi = rb._facetInfo;\n\n    for (ShardResponse srsp: sreq.responses) {\n      int shardNum = rb.getShardNum(srsp.getShard());\n      NamedList facet_counts = (NamedList)srsp.getSolrResponse().getResponse().get(\"facet_counts\");\n\n      @SuppressWarnings(\"unchecked\")\n      List<String> excepts = (List<String>)facet_counts.get(\"exception\");\n      fi.addExceptions(excepts);\n\n      // handle facet queries\n      NamedList facet_queries = (NamedList)facet_counts.get(\"facet_queries\");\n      if (facet_queries != null) {\n        for (int i=0; i<facet_queries.size(); i++) {\n          String returnedKey = facet_queries.getName(i);\n          long count = ((Number)facet_queries.getVal(i)).longValue();\n          QueryFacet qf = fi.queryFacets.get(returnedKey);\n          qf.count += count;\n        }\n      }\n\n      // step through each facet.field, adding results from this shard\n      NamedList facet_fields = (NamedList)facet_counts.get(\"facet_fields\");\n    \n      if (facet_fields != null) {\n        for (DistribFieldFacet dff : fi.facets.values()) {\n          dff.add(shardNum, (NamedList)facet_fields.get(dff.getKey()), dff.initialLimit);\n        }\n      }\n\n      // Distributed facet_dates\n      //\n      // The implementation below uses the first encountered shard's \n      // facet_dates as the basis for subsequent shards' data to be merged.\n      // (the \"NOW\" param should ensure consistency)\n      @SuppressWarnings(\"unchecked\")\n      SimpleOrderedMap<SimpleOrderedMap<Object>> facet_dates = \n        (SimpleOrderedMap<SimpleOrderedMap<Object>>) \n        facet_counts.get(\"facet_dates\");\n      \n      if (facet_dates != null) {\n\n        // go through each facet_date\n        for (Map.Entry<String,SimpleOrderedMap<Object>> entry : facet_dates) {\n          final String field = entry.getKey();\n          if (fi.dateFacets.get(field) == null) { \n            // first time we've seen this field, no merging\n            fi.dateFacets.add(field, entry.getValue());\n\n          } else { \n            // not the first time, merge current field\n\n            SimpleOrderedMap<Object> shardFieldValues \n              = entry.getValue();\n            SimpleOrderedMap<Object> existFieldValues \n              = fi.dateFacets.get(field);\n\n            for (Map.Entry<String,Object> existPair : existFieldValues) {\n              final String key = existPair.getKey();\n              if (key.equals(\"gap\") || \n                  key.equals(\"end\") || \n                  key.equals(\"start\")) {\n                // we can skip these, must all be the same across shards\n                continue; \n              }\n              // can be null if inconsistencies in shards responses\n              Integer newValue = (Integer) shardFieldValues.get(key);\n              if  (null != newValue) {\n                Integer oldValue = ((Integer) existPair.getValue());\n                existPair.setValue(oldValue + newValue);\n              }\n            }\n          }\n        }\n      }\n\n      // Distributed facet_ranges\n      //\n      // The implementation below uses the first encountered shard's \n      // facet_ranges as the basis for subsequent shards' data to be merged.\n      @SuppressWarnings(\"unchecked\")\n      SimpleOrderedMap<SimpleOrderedMap<Object>> facet_ranges = \n        (SimpleOrderedMap<SimpleOrderedMap<Object>>) \n        facet_counts.get(\"facet_ranges\");\n      \n      if (facet_ranges != null) {\n\n        // go through each facet_range\n        for (Map.Entry<String,SimpleOrderedMap<Object>> entry : facet_ranges) {\n          final String field = entry.getKey();\n          if (fi.rangeFacets.get(field) == null) { \n            // first time we've seen this field, no merging\n            fi.rangeFacets.add(field, entry.getValue());\n\n          } else { \n            // not the first time, merge current field counts\n\n            @SuppressWarnings(\"unchecked\")\n            NamedList<Integer> shardFieldValues \n              = (NamedList<Integer>) entry.getValue().get(\"counts\");\n\n            @SuppressWarnings(\"unchecked\")\n            NamedList<Integer> existFieldValues \n              = (NamedList<Integer>) fi.rangeFacets.get(field).get(\"counts\");\n\n            for (Map.Entry<String,Integer> existPair : existFieldValues) {\n              final String key = existPair.getKey();\n              // can be null if inconsistencies in shards responses\n              Integer newValue = shardFieldValues.get(key);\n              if  (null != newValue) {\n                Integer oldValue = existPair.getValue();\n                existPair.setValue(oldValue + newValue);\n              }\n            }\n          }\n        }\n      }\n    }\n\n    //\n    // This code currently assumes that there will be only a single\n    // request ((with responses from all shards) sent out to get facets...\n    // otherwise we would need to wait until all facet responses were received.\n    //\n\n    for (DistribFieldFacet dff : fi.facets.values()) {\n       // no need to check these facets for refinement\n      if (dff.initialLimit <= 0 && dff.initialMincount == 0) continue;\n\n      // only other case where index-sort doesn't need refinement is if minCount==0\n      if (dff.minCount == 0 && dff.sort.equals(FacetParams.FACET_SORT_INDEX)) continue;\n\n      @SuppressWarnings(\"unchecked\") // generic array's are annoying\n      List<String>[] tmp = (List<String>[]) new List[rb.shards.length];\n      dff._toRefine = tmp;\n\n      ShardFacetCount[] counts = dff.getCountSorted();\n      int ntop = Math.min(counts.length, dff.limit >= 0 ? dff.offset + dff.limit : Integer.MAX_VALUE);\n      long smallestCount = counts.length == 0 ? 0 : counts[ntop-1].count;\n\n      for (int i=0; i<counts.length; i++) {\n        ShardFacetCount sfc = counts[i];\n        boolean needRefinement = false;\n\n        if (i<ntop) {\n          // automatically flag the top values for refinement\n          // this should always be true for facet.sort=index\n          needRefinement = true;\n        } else {\n          // this logic should only be invoked for facet.sort=index (for now)\n\n          // calculate the maximum value that this term may have\n          // and if it is >= smallestCount, then flag for refinement\n          long maxCount = sfc.count;\n          for (int shardNum=0; shardNum<rb.shards.length; shardNum++) {\n            OpenBitSet obs = dff.counted[shardNum];\n            if (!obs.get(sfc.termNum)) {\n              // if missing from this shard, add the max it could be\n              maxCount += dff.maxPossible(sfc,shardNum);\n            }\n          }\n          if (maxCount >= smallestCount) {\n            // TODO: on a tie, we could check the term values\n            needRefinement = true;\n          }\n        }\n\n        if (needRefinement) {\n          // add a query for each shard missing the term that needs refinement\n          for (int shardNum=0; shardNum<rb.shards.length; shardNum++) {\n            OpenBitSet obs = dff.counted[shardNum];\n            if (!obs.get(sfc.termNum) && dff.maxPossible(sfc,shardNum)>0) {\n              dff.needRefinements = true;\n              List<String> lst = dff._toRefine[shardNum];\n              if (lst == null) {\n                lst = dff._toRefine[shardNum] = new ArrayList<String>();\n              }\n              lst.add(sfc.name);\n            }\n          }\n        }\n      }\n    }\n  }\n\n","sourceOld":"  private void countFacets(ResponseBuilder rb, ShardRequest sreq) {\n    FacetInfo fi = rb._facetInfo;\n\n    for (ShardResponse srsp: sreq.responses) {\n      int shardNum = rb.getShardNum(srsp.getShard());\n      NamedList facet_counts = (NamedList)srsp.getSolrResponse().getResponse().get(\"facet_counts\");\n\n      @SuppressWarnings(\"unchecked\")\n      List<String> excepts = (List<String>)facet_counts.get(\"exception\");\n      fi.addExceptions(excepts);\n\n      // handle facet queries\n      NamedList facet_queries = (NamedList)facet_counts.get(\"facet_queries\");\n      if (facet_queries != null) {\n        for (int i=0; i<facet_queries.size(); i++) {\n          String returnedKey = facet_queries.getName(i);\n          long count = ((Number)facet_queries.getVal(i)).longValue();\n          QueryFacet qf = fi.queryFacets.get(returnedKey);\n          qf.count += count;\n        }\n      }\n\n      // step through each facet.field, adding results from this shard\n      NamedList facet_fields = (NamedList)facet_counts.get(\"facet_fields\");\n    \n      if (facet_fields != null) {\n        for (DistribFieldFacet dff : fi.facets.values()) {\n          dff.add(shardNum, (NamedList)facet_fields.get(dff.getKey()), dff.initialLimit);\n        }\n      }\n\n      // Distributed facet_dates\n      //\n      // The implementation below uses the first encountered shard's \n      // facet_dates as the basis for subsequent shards' data to be merged.\n      // (the \"NOW\" param should ensure consistency)\n      @SuppressWarnings(\"unchecked\")\n      SimpleOrderedMap<SimpleOrderedMap<Object>> facet_dates = \n        (SimpleOrderedMap<SimpleOrderedMap<Object>>) \n        facet_counts.get(\"facet_dates\");\n      \n      if (facet_dates != null) {\n\n        // go through each facet_date\n        for (Map.Entry<String,SimpleOrderedMap<Object>> entry : facet_dates) {\n          final String field = entry.getKey();\n          if (fi.dateFacets.get(field) == null) { \n            // first time we've seen this field, no merging\n            fi.dateFacets.add(field, entry.getValue());\n\n          } else { \n            // not the first time, merge current field\n\n            SimpleOrderedMap<Object> shardFieldValues \n              = entry.getValue();\n            SimpleOrderedMap<Object> existFieldValues \n              = fi.dateFacets.get(field);\n\n            for (Map.Entry<String,Object> existPair : existFieldValues) {\n              final String key = existPair.getKey();\n              if (key.equals(\"gap\") || \n                  key.equals(\"end\") || \n                  key.equals(\"start\")) {\n                // we can skip these, must all be the same across shards\n                continue; \n              }\n              // can be null if inconsistencies in shards responses\n              Integer newValue = (Integer) shardFieldValues.get(key);\n              if  (null != newValue) {\n                Integer oldValue = ((Integer) existPair.getValue());\n                existPair.setValue(oldValue + newValue);\n              }\n            }\n          }\n        }\n      }\n\n      // Distributed facet_ranges\n      //\n      // The implementation below uses the first encountered shard's \n      // facet_ranges as the basis for subsequent shards' data to be merged.\n      @SuppressWarnings(\"unchecked\")\n      SimpleOrderedMap<SimpleOrderedMap<Object>> facet_ranges = \n        (SimpleOrderedMap<SimpleOrderedMap<Object>>) \n        facet_counts.get(\"facet_ranges\");\n      \n      if (facet_ranges != null) {\n\n        // go through each facet_range\n        for (Map.Entry<String,SimpleOrderedMap<Object>> entry : facet_ranges) {\n          final String field = entry.getKey();\n          if (fi.rangeFacets.get(field) == null) { \n            // first time we've seen this field, no merging\n            fi.rangeFacets.add(field, entry.getValue());\n\n          } else { \n            // not the first time, merge current field counts\n\n            @SuppressWarnings(\"unchecked\")\n            NamedList<Integer> shardFieldValues \n              = (NamedList<Integer>) entry.getValue().get(\"counts\");\n\n            @SuppressWarnings(\"unchecked\")\n            NamedList<Integer> existFieldValues \n              = (NamedList<Integer>) fi.rangeFacets.get(field).get(\"counts\");\n\n            for (Map.Entry<String,Integer> existPair : existFieldValues) {\n              final String key = existPair.getKey();\n              // can be null if inconsistencies in shards responses\n              Integer newValue = shardFieldValues.get(key);\n              if  (null != newValue) {\n                Integer oldValue = existPair.getValue();\n                existPair.setValue(oldValue + newValue);\n              }\n            }\n          }\n        }\n      }\n    }\n\n    //\n    // This code currently assumes that there will be only a single\n    // request ((with responses from all shards) sent out to get facets...\n    // otherwise we would need to wait until all facet responses were received.\n    //\n\n    for (DistribFieldFacet dff : fi.facets.values()) {\n       // no need to check these facets for refinement\n      if (dff.initialLimit <= 0 && dff.initialMincount == 0) continue;\n\n      // only other case where index-sort doesn't need refinement is if minCount==0\n      if (dff.minCount == 0 && dff.sort.equals(FacetParams.FACET_SORT_INDEX)) continue;\n\n      @SuppressWarnings(\"unchecked\") // generic array's are annoying\n      List<String>[] tmp = (List<String>[]) new List[rb.shards.length];\n      dff._toRefine = tmp;\n\n      ShardFacetCount[] counts = dff.getCountSorted();\n      int ntop = Math.min(counts.length, dff.limit >= 0 ? dff.offset + dff.limit : Integer.MAX_VALUE);\n      long smallestCount = counts.length == 0 ? 0 : counts[ntop-1].count;\n\n      for (int i=0; i<counts.length; i++) {\n        ShardFacetCount sfc = counts[i];\n        boolean needRefinement = false;\n\n        if (i<ntop) {\n          // automatically flag the top values for refinement\n          // this should always be true for facet.sort=index\n          needRefinement = true;\n        } else {\n          // this logic should only be invoked for facet.sort=index (for now)\n\n          // calculate the maximum value that this term may have\n          // and if it is >= smallestCount, then flag for refinement\n          long maxCount = sfc.count;\n          for (int shardNum=0; shardNum<rb.shards.length; shardNum++) {\n            OpenBitSet obs = dff.counted[shardNum];\n            if (!obs.get(sfc.termNum)) {\n              // if missing from this shard, add the max it could be\n              maxCount += dff.maxPossible(sfc,shardNum);\n            }\n          }\n          if (maxCount >= smallestCount) {\n            // TODO: on a tie, we could check the term values\n            needRefinement = true;\n          }\n        }\n\n        if (needRefinement) {\n          // add a query for each shard missing the term that needs refinement\n          for (int shardNum=0; shardNum<rb.shards.length; shardNum++) {\n            OpenBitSet obs = dff.counted[shardNum];\n            if (!obs.get(sfc.termNum) && dff.maxPossible(sfc,shardNum)>0) {\n              dff.needRefinements = true;\n              List<String> lst = dff._toRefine[shardNum];\n              if (lst == null) {\n                lst = dff._toRefine[shardNum] = new ArrayList<String>();\n              }\n              lst.add(sfc.name);\n            }\n          }\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"3f7e3e91f914e6265ed09a3208cc60c9ba2a477d":["ef02613bb5b67b98ca5caf41e8d6e016a0158923"],"893269407f5c988a4b2ee13c7ffc01ec43136c1d":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"ef02613bb5b67b98ca5caf41e8d6e016a0158923":["12064130393504cdb2782da654893641a6596056"],"a89acb2b4321b599bbfa1e802c00c4dbbc8ee6b8":["893269407f5c988a4b2ee13c7ffc01ec43136c1d"],"c26f00b574427b55127e869b935845554afde1fa":["0833d477d790b0926422e7ac018b1bcee73ad5bd","c903c3d15906a3da96b8c0c2fb704491005fdbdb"],"3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b":[],"135621f3a0670a9394eb563224a3b76cc4dddc0f":["29ef99d61cda9641b6250bf9567329a6e65f901d","0833d477d790b0926422e7ac018b1bcee73ad5bd"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":["12064130393504cdb2782da654893641a6596056","3f7e3e91f914e6265ed09a3208cc60c9ba2a477d"],"d493718201f0d0c54c773fb323d87bbd2fbffe41":["868da859b43505d9d2a023bfeae6dd0c795f5295","0833d477d790b0926422e7ac018b1bcee73ad5bd"],"1da8d55113b689b06716246649de6f62430f15c0":["a89acb2b4321b599bbfa1e802c00c4dbbc8ee6b8","ad94625fb8d088209f46650c8097196fec67f00c"],"12064130393504cdb2782da654893641a6596056":["1da8d55113b689b06716246649de6f62430f15c0"],"c903c3d15906a3da96b8c0c2fb704491005fdbdb":["a3776dccca01c11e7046323cfad46a3b4a471233"],"755f2f419306d7297c8feee10d1897addf4b2dd0":["3f7e3e91f914e6265ed09a3208cc60c9ba2a477d"],"a3776dccca01c11e7046323cfad46a3b4a471233":["755f2f419306d7297c8feee10d1897addf4b2dd0","0833d477d790b0926422e7ac018b1bcee73ad5bd"],"29ef99d61cda9641b6250bf9567329a6e65f901d":["3f7e3e91f914e6265ed09a3208cc60c9ba2a477d","755f2f419306d7297c8feee10d1897addf4b2dd0"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"0833d477d790b0926422e7ac018b1bcee73ad5bd":["d1c5c000a4f7db9f84794088342aa428d80dfa37"],"a258fbb26824fd104ed795e5d9033d2d040049ee":["0833d477d790b0926422e7ac018b1bcee73ad5bd"],"ad94625fb8d088209f46650c8097196fec67f00c":["3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b"],"868da859b43505d9d2a023bfeae6dd0c795f5295":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","755f2f419306d7297c8feee10d1897addf4b2dd0"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["c26f00b574427b55127e869b935845554afde1fa"],"d1c5c000a4f7db9f84794088342aa428d80dfa37":["755f2f419306d7297c8feee10d1897addf4b2dd0"]},"commit2Childs":{"3f7e3e91f914e6265ed09a3208cc60c9ba2a477d":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","755f2f419306d7297c8feee10d1897addf4b2dd0","29ef99d61cda9641b6250bf9567329a6e65f901d"],"893269407f5c988a4b2ee13c7ffc01ec43136c1d":["a89acb2b4321b599bbfa1e802c00c4dbbc8ee6b8"],"ef02613bb5b67b98ca5caf41e8d6e016a0158923":["3f7e3e91f914e6265ed09a3208cc60c9ba2a477d"],"a89acb2b4321b599bbfa1e802c00c4dbbc8ee6b8":["1da8d55113b689b06716246649de6f62430f15c0"],"c26f00b574427b55127e869b935845554afde1fa":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b":["ad94625fb8d088209f46650c8097196fec67f00c"],"135621f3a0670a9394eb563224a3b76cc4dddc0f":[],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":["868da859b43505d9d2a023bfeae6dd0c795f5295"],"d493718201f0d0c54c773fb323d87bbd2fbffe41":[],"1da8d55113b689b06716246649de6f62430f15c0":["12064130393504cdb2782da654893641a6596056"],"12064130393504cdb2782da654893641a6596056":["ef02613bb5b67b98ca5caf41e8d6e016a0158923","7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a"],"c903c3d15906a3da96b8c0c2fb704491005fdbdb":["c26f00b574427b55127e869b935845554afde1fa"],"29ef99d61cda9641b6250bf9567329a6e65f901d":["135621f3a0670a9394eb563224a3b76cc4dddc0f"],"a3776dccca01c11e7046323cfad46a3b4a471233":["c903c3d15906a3da96b8c0c2fb704491005fdbdb"],"755f2f419306d7297c8feee10d1897addf4b2dd0":["a3776dccca01c11e7046323cfad46a3b4a471233","29ef99d61cda9641b6250bf9567329a6e65f901d","868da859b43505d9d2a023bfeae6dd0c795f5295","d1c5c000a4f7db9f84794088342aa428d80dfa37"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["893269407f5c988a4b2ee13c7ffc01ec43136c1d"],"0833d477d790b0926422e7ac018b1bcee73ad5bd":["c26f00b574427b55127e869b935845554afde1fa","135621f3a0670a9394eb563224a3b76cc4dddc0f","d493718201f0d0c54c773fb323d87bbd2fbffe41","a3776dccca01c11e7046323cfad46a3b4a471233","a258fbb26824fd104ed795e5d9033d2d040049ee"],"a258fbb26824fd104ed795e5d9033d2d040049ee":[],"ad94625fb8d088209f46650c8097196fec67f00c":["1da8d55113b689b06716246649de6f62430f15c0"],"868da859b43505d9d2a023bfeae6dd0c795f5295":["d493718201f0d0c54c773fb323d87bbd2fbffe41"],"d1c5c000a4f7db9f84794088342aa428d80dfa37":["0833d477d790b0926422e7ac018b1bcee73ad5bd"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["135621f3a0670a9394eb563224a3b76cc4dddc0f","d493718201f0d0c54c773fb323d87bbd2fbffe41","a258fbb26824fd104ed795e5d9033d2d040049ee","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b","a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}