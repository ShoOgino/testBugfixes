{"path":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriter#testIterableThrowsException().mjava","commits":[{"id":"ac7fa87956e618e2e88572544ae87078647f6351","date":1355482487,"type":0,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriter#testIterableThrowsException().mjava","pathOld":"/dev/null","sourceNew":"  public void testIterableThrowsException() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(\n        TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    int iters = atLeast(100);\n    int docCount = 0;\n    int docId = 0;\n    Set<String> liveIds = new HashSet<String>();\n    for (int i = 0; i < iters; i++) {\n      List<Document> docs = new ArrayList<Document>();\n      FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n      FieldType idFt = new FieldType(TextField.TYPE_STORED);\n      \n      int numDocs = atLeast(4);\n      for (int j = 0; j < numDocs; j++) {\n        Document doc = new Document();\n        doc.add(newField(\"id\", \"\"+ (docId++), idFt));\n        doc.add(newField(\"foo\", _TestUtil.randomSimpleString(random()), ft));\n        docs.add(doc);\n      }\n      boolean success = false;\n      try {\n        w.addDocuments(new RandomFailingFieldIterable(docs, random()));\n        success = true;\n      } catch (RuntimeException e) {\n        assertEquals(\"boom\", e.getMessage());\n      } finally {\n        if (success) {\n          docCount += docs.size();\n          for (Document indexDocument : docs) {\n            liveIds.add(indexDocument.get(\"id\"));  \n          }\n        }\n      }\n    }\n    DirectoryReader reader = w.getReader();\n    assertEquals(docCount, reader.numDocs());\n    List<AtomicReaderContext> leaves = reader.leaves();\n    for (AtomicReaderContext atomicReaderContext : leaves) {\n      AtomicReader ar = atomicReaderContext.reader();\n      Bits liveDocs = ar.getLiveDocs();\n      int maxDoc = ar.maxDoc();\n      for (int i = 0; i < maxDoc; i++) {\n        if (liveDocs.get(i)) {\n          assertTrue(liveIds.remove(ar.document(i).get(\"id\")));\n        }\n      }\n    }\n    assertTrue(liveIds.isEmpty());\n    IOUtils.close(reader, w, dir);\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3bdeb3bacd9fab7d3eb4083f73bc002c467bea41","date":1355493922,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriter#testIterableThrowsException().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriter#testIterableThrowsException().mjava","sourceNew":"  public void testIterableThrowsException() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(\n        TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    int iters = atLeast(100);\n    int docCount = 0;\n    int docId = 0;\n    Set<String> liveIds = new HashSet<String>();\n    for (int i = 0; i < iters; i++) {\n      List<Document> docs = new ArrayList<Document>();\n      FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n      FieldType idFt = new FieldType(TextField.TYPE_STORED);\n      \n      int numDocs = atLeast(4);\n      for (int j = 0; j < numDocs; j++) {\n        Document doc = new Document();\n        doc.add(newField(\"id\", \"\"+ (docId++), idFt));\n        doc.add(newField(\"foo\", _TestUtil.randomSimpleString(random()), ft));\n        docs.add(doc);\n      }\n      boolean success = false;\n      try {\n        w.addDocuments(new RandomFailingFieldIterable(docs, random()));\n        success = true;\n      } catch (RuntimeException e) {\n        assertEquals(\"boom\", e.getMessage());\n      } finally {\n        if (success) {\n          docCount += docs.size();\n          for (Document indexDocument : docs) {\n            liveIds.add(indexDocument.get(\"id\"));  \n          }\n        }\n      }\n    }\n    DirectoryReader reader = w.getReader();\n    assertEquals(docCount, reader.numDocs());\n    List<AtomicReaderContext> leaves = reader.leaves();\n    for (AtomicReaderContext atomicReaderContext : leaves) {\n      AtomicReader ar = atomicReaderContext.reader();\n      Bits liveDocs = ar.getLiveDocs();\n      int maxDoc = ar.maxDoc();\n      for (int i = 0; i < maxDoc; i++) {\n        if (liveDocs == null || liveDocs.get(i)) {\n          assertTrue(liveIds.remove(ar.document(i).get(\"id\")));\n        }\n      }\n    }\n    assertTrue(liveIds.isEmpty());\n    IOUtils.close(reader, w, dir);\n  }\n\n","sourceOld":"  public void testIterableThrowsException() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(\n        TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    int iters = atLeast(100);\n    int docCount = 0;\n    int docId = 0;\n    Set<String> liveIds = new HashSet<String>();\n    for (int i = 0; i < iters; i++) {\n      List<Document> docs = new ArrayList<Document>();\n      FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n      FieldType idFt = new FieldType(TextField.TYPE_STORED);\n      \n      int numDocs = atLeast(4);\n      for (int j = 0; j < numDocs; j++) {\n        Document doc = new Document();\n        doc.add(newField(\"id\", \"\"+ (docId++), idFt));\n        doc.add(newField(\"foo\", _TestUtil.randomSimpleString(random()), ft));\n        docs.add(doc);\n      }\n      boolean success = false;\n      try {\n        w.addDocuments(new RandomFailingFieldIterable(docs, random()));\n        success = true;\n      } catch (RuntimeException e) {\n        assertEquals(\"boom\", e.getMessage());\n      } finally {\n        if (success) {\n          docCount += docs.size();\n          for (Document indexDocument : docs) {\n            liveIds.add(indexDocument.get(\"id\"));  \n          }\n        }\n      }\n    }\n    DirectoryReader reader = w.getReader();\n    assertEquals(docCount, reader.numDocs());\n    List<AtomicReaderContext> leaves = reader.leaves();\n    for (AtomicReaderContext atomicReaderContext : leaves) {\n      AtomicReader ar = atomicReaderContext.reader();\n      Bits liveDocs = ar.getLiveDocs();\n      int maxDoc = ar.maxDoc();\n      for (int i = 0; i < maxDoc; i++) {\n        if (liveDocs.get(i)) {\n          assertTrue(liveIds.remove(ar.document(i).get(\"id\")));\n        }\n      }\n    }\n    assertTrue(liveIds.isEmpty());\n    IOUtils.close(reader, w, dir);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d3fcb70cf561547c7bb1506e0cf32ca7b1287064","date":1357616416,"type":0,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriter#testIterableThrowsException().mjava","pathOld":"/dev/null","sourceNew":"  public void testIterableThrowsException() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(\n        TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    int iters = atLeast(100);\n    int docCount = 0;\n    int docId = 0;\n    Set<String> liveIds = new HashSet<String>();\n    for (int i = 0; i < iters; i++) {\n      List<Document> docs = new ArrayList<Document>();\n      FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n      FieldType idFt = new FieldType(TextField.TYPE_STORED);\n      \n      int numDocs = atLeast(4);\n      for (int j = 0; j < numDocs; j++) {\n        Document doc = new Document();\n        doc.add(newField(\"id\", \"\"+ (docId++), idFt));\n        doc.add(newField(\"foo\", _TestUtil.randomSimpleString(random()), ft));\n        docs.add(doc);\n      }\n      boolean success = false;\n      try {\n        w.addDocuments(new RandomFailingFieldIterable(docs, random()));\n        success = true;\n      } catch (RuntimeException e) {\n        assertEquals(\"boom\", e.getMessage());\n      } finally {\n        if (success) {\n          docCount += docs.size();\n          for (Document indexDocument : docs) {\n            liveIds.add(indexDocument.get(\"id\"));  \n          }\n        }\n      }\n    }\n    DirectoryReader reader = w.getReader();\n    assertEquals(docCount, reader.numDocs());\n    List<AtomicReaderContext> leaves = reader.leaves();\n    for (AtomicReaderContext atomicReaderContext : leaves) {\n      AtomicReader ar = atomicReaderContext.reader();\n      Bits liveDocs = ar.getLiveDocs();\n      int maxDoc = ar.maxDoc();\n      for (int i = 0; i < maxDoc; i++) {\n        if (liveDocs == null || liveDocs.get(i)) {\n          assertTrue(liveIds.remove(ar.document(i).get(\"id\")));\n        }\n      }\n    }\n    assertTrue(liveIds.isEmpty());\n    IOUtils.close(reader, w, dir);\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6613659748fe4411a7dcf85266e55db1f95f7315","date":1392773913,"type":3,"author":"Benson Margulies","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriter#testIterableThrowsException().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriter#testIterableThrowsException().mjava","sourceNew":"  public void testIterableThrowsException() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(\n        TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    int iters = atLeast(100);\n    int docCount = 0;\n    int docId = 0;\n    Set<String> liveIds = new HashSet<String>();\n    for (int i = 0; i < iters; i++) {\n      List<Document> docs = new ArrayList<Document>();\n      FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n      FieldType idFt = new FieldType(TextField.TYPE_STORED);\n      \n      int numDocs = atLeast(4);\n      for (int j = 0; j < numDocs; j++) {\n        Document doc = new Document();\n        doc.add(newField(\"id\", \"\"+ (docId++), idFt));\n        doc.add(newField(\"foo\", TestUtil.randomSimpleString(random()), ft));\n        docs.add(doc);\n      }\n      boolean success = false;\n      try {\n        w.addDocuments(new RandomFailingFieldIterable(docs, random()));\n        success = true;\n      } catch (RuntimeException e) {\n        assertEquals(\"boom\", e.getMessage());\n      } finally {\n        if (success) {\n          docCount += docs.size();\n          for (Document indexDocument : docs) {\n            liveIds.add(indexDocument.get(\"id\"));  \n          }\n        }\n      }\n    }\n    DirectoryReader reader = w.getReader();\n    assertEquals(docCount, reader.numDocs());\n    List<AtomicReaderContext> leaves = reader.leaves();\n    for (AtomicReaderContext atomicReaderContext : leaves) {\n      AtomicReader ar = atomicReaderContext.reader();\n      Bits liveDocs = ar.getLiveDocs();\n      int maxDoc = ar.maxDoc();\n      for (int i = 0; i < maxDoc; i++) {\n        if (liveDocs == null || liveDocs.get(i)) {\n          assertTrue(liveIds.remove(ar.document(i).get(\"id\")));\n        }\n      }\n    }\n    assertTrue(liveIds.isEmpty());\n    IOUtils.close(reader, w, dir);\n  }\n\n","sourceOld":"  public void testIterableThrowsException() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(\n        TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    int iters = atLeast(100);\n    int docCount = 0;\n    int docId = 0;\n    Set<String> liveIds = new HashSet<String>();\n    for (int i = 0; i < iters; i++) {\n      List<Document> docs = new ArrayList<Document>();\n      FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n      FieldType idFt = new FieldType(TextField.TYPE_STORED);\n      \n      int numDocs = atLeast(4);\n      for (int j = 0; j < numDocs; j++) {\n        Document doc = new Document();\n        doc.add(newField(\"id\", \"\"+ (docId++), idFt));\n        doc.add(newField(\"foo\", _TestUtil.randomSimpleString(random()), ft));\n        docs.add(doc);\n      }\n      boolean success = false;\n      try {\n        w.addDocuments(new RandomFailingFieldIterable(docs, random()));\n        success = true;\n      } catch (RuntimeException e) {\n        assertEquals(\"boom\", e.getMessage());\n      } finally {\n        if (success) {\n          docCount += docs.size();\n          for (Document indexDocument : docs) {\n            liveIds.add(indexDocument.get(\"id\"));  \n          }\n        }\n      }\n    }\n    DirectoryReader reader = w.getReader();\n    assertEquals(docCount, reader.numDocs());\n    List<AtomicReaderContext> leaves = reader.leaves();\n    for (AtomicReaderContext atomicReaderContext : leaves) {\n      AtomicReader ar = atomicReaderContext.reader();\n      Bits liveDocs = ar.getLiveDocs();\n      int maxDoc = ar.maxDoc();\n      for (int i = 0; i < maxDoc; i++) {\n        if (liveDocs == null || liveDocs.get(i)) {\n          assertTrue(liveIds.remove(ar.document(i).get(\"id\")));\n        }\n      }\n    }\n    assertTrue(liveIds.isEmpty());\n    IOUtils.close(reader, w, dir);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"634f330c54fd3f9f491d52036dc3f40b4f4d8934","date":1394635157,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriter#testIterableThrowsException().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriter#testIterableThrowsException().mjava","sourceNew":"  public void testIterableThrowsException() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(\n        TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    int iters = atLeast(100);\n    int docCount = 0;\n    int docId = 0;\n    Set<String> liveIds = new HashSet<>();\n    for (int i = 0; i < iters; i++) {\n      List<Document> docs = new ArrayList<>();\n      FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n      FieldType idFt = new FieldType(TextField.TYPE_STORED);\n      \n      int numDocs = atLeast(4);\n      for (int j = 0; j < numDocs; j++) {\n        Document doc = new Document();\n        doc.add(newField(\"id\", \"\"+ (docId++), idFt));\n        doc.add(newField(\"foo\", TestUtil.randomSimpleString(random()), ft));\n        docs.add(doc);\n      }\n      boolean success = false;\n      try {\n        w.addDocuments(new RandomFailingFieldIterable(docs, random()));\n        success = true;\n      } catch (RuntimeException e) {\n        assertEquals(\"boom\", e.getMessage());\n      } finally {\n        if (success) {\n          docCount += docs.size();\n          for (Document indexDocument : docs) {\n            liveIds.add(indexDocument.get(\"id\"));  \n          }\n        }\n      }\n    }\n    DirectoryReader reader = w.getReader();\n    assertEquals(docCount, reader.numDocs());\n    List<AtomicReaderContext> leaves = reader.leaves();\n    for (AtomicReaderContext atomicReaderContext : leaves) {\n      AtomicReader ar = atomicReaderContext.reader();\n      Bits liveDocs = ar.getLiveDocs();\n      int maxDoc = ar.maxDoc();\n      for (int i = 0; i < maxDoc; i++) {\n        if (liveDocs == null || liveDocs.get(i)) {\n          assertTrue(liveIds.remove(ar.document(i).get(\"id\")));\n        }\n      }\n    }\n    assertTrue(liveIds.isEmpty());\n    IOUtils.close(reader, w, dir);\n  }\n\n","sourceOld":"  public void testIterableThrowsException() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(\n        TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    int iters = atLeast(100);\n    int docCount = 0;\n    int docId = 0;\n    Set<String> liveIds = new HashSet<String>();\n    for (int i = 0; i < iters; i++) {\n      List<Document> docs = new ArrayList<Document>();\n      FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n      FieldType idFt = new FieldType(TextField.TYPE_STORED);\n      \n      int numDocs = atLeast(4);\n      for (int j = 0; j < numDocs; j++) {\n        Document doc = new Document();\n        doc.add(newField(\"id\", \"\"+ (docId++), idFt));\n        doc.add(newField(\"foo\", TestUtil.randomSimpleString(random()), ft));\n        docs.add(doc);\n      }\n      boolean success = false;\n      try {\n        w.addDocuments(new RandomFailingFieldIterable(docs, random()));\n        success = true;\n      } catch (RuntimeException e) {\n        assertEquals(\"boom\", e.getMessage());\n      } finally {\n        if (success) {\n          docCount += docs.size();\n          for (Document indexDocument : docs) {\n            liveIds.add(indexDocument.get(\"id\"));  \n          }\n        }\n      }\n    }\n    DirectoryReader reader = w.getReader();\n    assertEquals(docCount, reader.numDocs());\n    List<AtomicReaderContext> leaves = reader.leaves();\n    for (AtomicReaderContext atomicReaderContext : leaves) {\n      AtomicReader ar = atomicReaderContext.reader();\n      Bits liveDocs = ar.getLiveDocs();\n      int maxDoc = ar.maxDoc();\n      for (int i = 0; i < maxDoc; i++) {\n        if (liveDocs == null || liveDocs.get(i)) {\n          assertTrue(liveIds.remove(ar.document(i).get(\"id\")));\n        }\n      }\n    }\n    assertTrue(liveIds.isEmpty());\n    IOUtils.close(reader, w, dir);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ae14298f4eec6d5faee6a149f88ba57d14a6f21a","date":1396971290,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriter#testIterableThrowsException().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriter#testIterableThrowsException().mjava","sourceNew":"  public void testIterableThrowsException() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(\n        TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    int iters = atLeast(100);\n    int docCount = 0;\n    int docId = 0;\n    Set<String> liveIds = new HashSet<>();\n    for (int i = 0; i < iters; i++) {\n      List<Document> docs = new ArrayList<>();\n      FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n      FieldType idFt = new FieldType(TextField.TYPE_STORED);\n      \n      int numDocs = atLeast(4);\n      for (int j = 0; j < numDocs; j++) {\n        Document doc = new Document();\n        doc.add(newField(\"id\", \"\"+ (docId++), idFt));\n        doc.add(newField(\"foo\", TestUtil.randomSimpleString(random()), ft));\n        docs.add(doc);\n      }\n      boolean success = false;\n      try {\n        w.addDocuments(new RandomFailingFieldIterable(docs, random()));\n        success = true;\n      } catch (RuntimeException e) {\n        assertEquals(\"boom\", e.getMessage());\n      } finally {\n        if (success) {\n          docCount += docs.size();\n          for (Document indexDocument : docs) {\n            liveIds.add(indexDocument.get(\"id\"));  \n          }\n        }\n      }\n    }\n    DirectoryReader reader = w.getReader();\n    assertEquals(docCount, reader.numDocs());\n    List<AtomicReaderContext> leaves = reader.leaves();\n    for (AtomicReaderContext atomicReaderContext : leaves) {\n      AtomicReader ar = atomicReaderContext.reader();\n      Bits liveDocs = ar.getLiveDocs();\n      int maxDoc = ar.maxDoc();\n      for (int i = 0; i < maxDoc; i++) {\n        if (liveDocs == null || liveDocs.get(i)) {\n          assertTrue(liveIds.remove(ar.document(i).get(\"id\")));\n        }\n      }\n    }\n    assertTrue(liveIds.isEmpty());\n    w.shutdown();\n    IOUtils.close(reader, dir);\n  }\n\n","sourceOld":"  public void testIterableThrowsException() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(\n        TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    int iters = atLeast(100);\n    int docCount = 0;\n    int docId = 0;\n    Set<String> liveIds = new HashSet<>();\n    for (int i = 0; i < iters; i++) {\n      List<Document> docs = new ArrayList<>();\n      FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n      FieldType idFt = new FieldType(TextField.TYPE_STORED);\n      \n      int numDocs = atLeast(4);\n      for (int j = 0; j < numDocs; j++) {\n        Document doc = new Document();\n        doc.add(newField(\"id\", \"\"+ (docId++), idFt));\n        doc.add(newField(\"foo\", TestUtil.randomSimpleString(random()), ft));\n        docs.add(doc);\n      }\n      boolean success = false;\n      try {\n        w.addDocuments(new RandomFailingFieldIterable(docs, random()));\n        success = true;\n      } catch (RuntimeException e) {\n        assertEquals(\"boom\", e.getMessage());\n      } finally {\n        if (success) {\n          docCount += docs.size();\n          for (Document indexDocument : docs) {\n            liveIds.add(indexDocument.get(\"id\"));  \n          }\n        }\n      }\n    }\n    DirectoryReader reader = w.getReader();\n    assertEquals(docCount, reader.numDocs());\n    List<AtomicReaderContext> leaves = reader.leaves();\n    for (AtomicReaderContext atomicReaderContext : leaves) {\n      AtomicReader ar = atomicReaderContext.reader();\n      Bits liveDocs = ar.getLiveDocs();\n      int maxDoc = ar.maxDoc();\n      for (int i = 0; i < maxDoc; i++) {\n        if (liveDocs == null || liveDocs.get(i)) {\n          assertTrue(liveIds.remove(ar.document(i).get(\"id\")));\n        }\n      }\n    }\n    assertTrue(liveIds.isEmpty());\n    IOUtils.close(reader, w, dir);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"36e9f571cf40a8818eb678ed8fcf845cb9f9b456","date":1399039701,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriter#testIterableThrowsException().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriter#testIterableThrowsException().mjava","sourceNew":"  public void testIterableThrowsException() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(\n        TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    int iters = atLeast(100);\n    int docCount = 0;\n    int docId = 0;\n    Set<String> liveIds = new HashSet<>();\n    for (int i = 0; i < iters; i++) {\n      List<Document> docs = new ArrayList<>();\n      FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n      FieldType idFt = new FieldType(TextField.TYPE_STORED);\n      \n      int numDocs = atLeast(4);\n      for (int j = 0; j < numDocs; j++) {\n        Document doc = new Document();\n        doc.add(newField(\"id\", \"\"+ (docId++), idFt));\n        doc.add(newField(\"foo\", TestUtil.randomSimpleString(random()), ft));\n        docs.add(doc);\n      }\n      boolean success = false;\n      try {\n        w.addDocuments(new RandomFailingIterable<IndexDocument>(docs, random()));\n        success = true;\n      } catch (RuntimeException e) {\n        assertEquals(\"boom\", e.getMessage());\n      } finally {\n        if (success) {\n          docCount += docs.size();\n          for (Document indexDocument : docs) {\n            liveIds.add(indexDocument.get(\"id\"));  \n          }\n        }\n      }\n    }\n    DirectoryReader reader = w.getReader();\n    assertEquals(docCount, reader.numDocs());\n    List<AtomicReaderContext> leaves = reader.leaves();\n    for (AtomicReaderContext atomicReaderContext : leaves) {\n      AtomicReader ar = atomicReaderContext.reader();\n      Bits liveDocs = ar.getLiveDocs();\n      int maxDoc = ar.maxDoc();\n      for (int i = 0; i < maxDoc; i++) {\n        if (liveDocs == null || liveDocs.get(i)) {\n          assertTrue(liveIds.remove(ar.document(i).get(\"id\")));\n        }\n      }\n    }\n    assertTrue(liveIds.isEmpty());\n    w.shutdown();\n    IOUtils.close(reader, dir);\n  }\n\n","sourceOld":"  public void testIterableThrowsException() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(\n        TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    int iters = atLeast(100);\n    int docCount = 0;\n    int docId = 0;\n    Set<String> liveIds = new HashSet<>();\n    for (int i = 0; i < iters; i++) {\n      List<Document> docs = new ArrayList<>();\n      FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n      FieldType idFt = new FieldType(TextField.TYPE_STORED);\n      \n      int numDocs = atLeast(4);\n      for (int j = 0; j < numDocs; j++) {\n        Document doc = new Document();\n        doc.add(newField(\"id\", \"\"+ (docId++), idFt));\n        doc.add(newField(\"foo\", TestUtil.randomSimpleString(random()), ft));\n        docs.add(doc);\n      }\n      boolean success = false;\n      try {\n        w.addDocuments(new RandomFailingFieldIterable(docs, random()));\n        success = true;\n      } catch (RuntimeException e) {\n        assertEquals(\"boom\", e.getMessage());\n      } finally {\n        if (success) {\n          docCount += docs.size();\n          for (Document indexDocument : docs) {\n            liveIds.add(indexDocument.get(\"id\"));  \n          }\n        }\n      }\n    }\n    DirectoryReader reader = w.getReader();\n    assertEquals(docCount, reader.numDocs());\n    List<AtomicReaderContext> leaves = reader.leaves();\n    for (AtomicReaderContext atomicReaderContext : leaves) {\n      AtomicReader ar = atomicReaderContext.reader();\n      Bits liveDocs = ar.getLiveDocs();\n      int maxDoc = ar.maxDoc();\n      for (int i = 0; i < maxDoc; i++) {\n        if (liveDocs == null || liveDocs.get(i)) {\n          assertTrue(liveIds.remove(ar.document(i).get(\"id\")));\n        }\n      }\n    }\n    assertTrue(liveIds.isEmpty());\n    w.shutdown();\n    IOUtils.close(reader, dir);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e","date":1406737224,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriter#testIterableThrowsException().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriter#testIterableThrowsException().mjava","sourceNew":"  public void testIterableThrowsException() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random())));\n    int iters = atLeast(100);\n    int docCount = 0;\n    int docId = 0;\n    Set<String> liveIds = new HashSet<>();\n    for (int i = 0; i < iters; i++) {\n      List<Document> docs = new ArrayList<>();\n      FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n      FieldType idFt = new FieldType(TextField.TYPE_STORED);\n      \n      int numDocs = atLeast(4);\n      for (int j = 0; j < numDocs; j++) {\n        Document doc = new Document();\n        doc.add(newField(\"id\", \"\"+ (docId++), idFt));\n        doc.add(newField(\"foo\", TestUtil.randomSimpleString(random()), ft));\n        docs.add(doc);\n      }\n      boolean success = false;\n      try {\n        w.addDocuments(new RandomFailingIterable<IndexDocument>(docs, random()));\n        success = true;\n      } catch (RuntimeException e) {\n        assertEquals(\"boom\", e.getMessage());\n      } finally {\n        if (success) {\n          docCount += docs.size();\n          for (Document indexDocument : docs) {\n            liveIds.add(indexDocument.get(\"id\"));  \n          }\n        }\n      }\n    }\n    DirectoryReader reader = w.getReader();\n    assertEquals(docCount, reader.numDocs());\n    List<AtomicReaderContext> leaves = reader.leaves();\n    for (AtomicReaderContext atomicReaderContext : leaves) {\n      AtomicReader ar = atomicReaderContext.reader();\n      Bits liveDocs = ar.getLiveDocs();\n      int maxDoc = ar.maxDoc();\n      for (int i = 0; i < maxDoc; i++) {\n        if (liveDocs == null || liveDocs.get(i)) {\n          assertTrue(liveIds.remove(ar.document(i).get(\"id\")));\n        }\n      }\n    }\n    assertTrue(liveIds.isEmpty());\n    w.shutdown();\n    IOUtils.close(reader, dir);\n  }\n\n","sourceOld":"  public void testIterableThrowsException() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(\n        TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    int iters = atLeast(100);\n    int docCount = 0;\n    int docId = 0;\n    Set<String> liveIds = new HashSet<>();\n    for (int i = 0; i < iters; i++) {\n      List<Document> docs = new ArrayList<>();\n      FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n      FieldType idFt = new FieldType(TextField.TYPE_STORED);\n      \n      int numDocs = atLeast(4);\n      for (int j = 0; j < numDocs; j++) {\n        Document doc = new Document();\n        doc.add(newField(\"id\", \"\"+ (docId++), idFt));\n        doc.add(newField(\"foo\", TestUtil.randomSimpleString(random()), ft));\n        docs.add(doc);\n      }\n      boolean success = false;\n      try {\n        w.addDocuments(new RandomFailingIterable<IndexDocument>(docs, random()));\n        success = true;\n      } catch (RuntimeException e) {\n        assertEquals(\"boom\", e.getMessage());\n      } finally {\n        if (success) {\n          docCount += docs.size();\n          for (Document indexDocument : docs) {\n            liveIds.add(indexDocument.get(\"id\"));  \n          }\n        }\n      }\n    }\n    DirectoryReader reader = w.getReader();\n    assertEquals(docCount, reader.numDocs());\n    List<AtomicReaderContext> leaves = reader.leaves();\n    for (AtomicReaderContext atomicReaderContext : leaves) {\n      AtomicReader ar = atomicReaderContext.reader();\n      Bits liveDocs = ar.getLiveDocs();\n      int maxDoc = ar.maxDoc();\n      for (int i = 0; i < maxDoc; i++) {\n        if (liveDocs == null || liveDocs.get(i)) {\n          assertTrue(liveIds.remove(ar.document(i).get(\"id\")));\n        }\n      }\n    }\n    assertTrue(liveIds.isEmpty());\n    w.shutdown();\n    IOUtils.close(reader, dir);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d0ef034a4f10871667ae75181537775ddcf8ade4","date":1407610475,"type":3,"author":"Ryan Ernst","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriter#testIterableThrowsException().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriter#testIterableThrowsException().mjava","sourceNew":"  public void testIterableThrowsException() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random())));\n    int iters = atLeast(100);\n    int docCount = 0;\n    int docId = 0;\n    Set<String> liveIds = new HashSet<>();\n    for (int i = 0; i < iters; i++) {\n      List<Document> docs = new ArrayList<>();\n      FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n      FieldType idFt = new FieldType(TextField.TYPE_STORED);\n      \n      int numDocs = atLeast(4);\n      for (int j = 0; j < numDocs; j++) {\n        Document doc = new Document();\n        doc.add(newField(\"id\", \"\"+ (docId++), idFt));\n        doc.add(newField(\"foo\", TestUtil.randomSimpleString(random()), ft));\n        docs.add(doc);\n      }\n      boolean success = false;\n      try {\n        w.addDocuments(new RandomFailingIterable<IndexDocument>(docs, random()));\n        success = true;\n      } catch (RuntimeException e) {\n        assertEquals(\"boom\", e.getMessage());\n      } finally {\n        if (success) {\n          docCount += docs.size();\n          for (Document indexDocument : docs) {\n            liveIds.add(indexDocument.get(\"id\"));  \n          }\n        }\n      }\n    }\n    DirectoryReader reader = w.getReader();\n    assertEquals(docCount, reader.numDocs());\n    List<AtomicReaderContext> leaves = reader.leaves();\n    for (AtomicReaderContext atomicReaderContext : leaves) {\n      AtomicReader ar = atomicReaderContext.reader();\n      Bits liveDocs = ar.getLiveDocs();\n      int maxDoc = ar.maxDoc();\n      for (int i = 0; i < maxDoc; i++) {\n        if (liveDocs == null || liveDocs.get(i)) {\n          assertTrue(liveIds.remove(ar.document(i).get(\"id\")));\n        }\n      }\n    }\n    assertTrue(liveIds.isEmpty());\n    w.close();\n    IOUtils.close(reader, dir);\n  }\n\n","sourceOld":"  public void testIterableThrowsException() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random())));\n    int iters = atLeast(100);\n    int docCount = 0;\n    int docId = 0;\n    Set<String> liveIds = new HashSet<>();\n    for (int i = 0; i < iters; i++) {\n      List<Document> docs = new ArrayList<>();\n      FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n      FieldType idFt = new FieldType(TextField.TYPE_STORED);\n      \n      int numDocs = atLeast(4);\n      for (int j = 0; j < numDocs; j++) {\n        Document doc = new Document();\n        doc.add(newField(\"id\", \"\"+ (docId++), idFt));\n        doc.add(newField(\"foo\", TestUtil.randomSimpleString(random()), ft));\n        docs.add(doc);\n      }\n      boolean success = false;\n      try {\n        w.addDocuments(new RandomFailingIterable<IndexDocument>(docs, random()));\n        success = true;\n      } catch (RuntimeException e) {\n        assertEquals(\"boom\", e.getMessage());\n      } finally {\n        if (success) {\n          docCount += docs.size();\n          for (Document indexDocument : docs) {\n            liveIds.add(indexDocument.get(\"id\"));  \n          }\n        }\n      }\n    }\n    DirectoryReader reader = w.getReader();\n    assertEquals(docCount, reader.numDocs());\n    List<AtomicReaderContext> leaves = reader.leaves();\n    for (AtomicReaderContext atomicReaderContext : leaves) {\n      AtomicReader ar = atomicReaderContext.reader();\n      Bits liveDocs = ar.getLiveDocs();\n      int maxDoc = ar.maxDoc();\n      for (int i = 0; i < maxDoc; i++) {\n        if (liveDocs == null || liveDocs.get(i)) {\n          assertTrue(liveIds.remove(ar.document(i).get(\"id\")));\n        }\n      }\n    }\n    assertTrue(liveIds.isEmpty());\n    w.shutdown();\n    IOUtils.close(reader, dir);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c9fb5f46e264daf5ba3860defe623a89d202dd87","date":1411516315,"type":3,"author":"Ryan Ernst","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriter#testIterableThrowsException().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriter#testIterableThrowsException().mjava","sourceNew":"  public void testIterableThrowsException() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random())));\n    int iters = atLeast(100);\n    int docCount = 0;\n    int docId = 0;\n    Set<String> liveIds = new HashSet<>();\n    for (int i = 0; i < iters; i++) {\n      List<Document> docs = new ArrayList<>();\n      FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n      FieldType idFt = new FieldType(TextField.TYPE_STORED);\n      \n      int numDocs = atLeast(4);\n      for (int j = 0; j < numDocs; j++) {\n        Document doc = new Document();\n        doc.add(newField(\"id\", \"\"+ (docId++), idFt));\n        doc.add(newField(\"foo\", TestUtil.randomSimpleString(random()), ft));\n        docs.add(doc);\n      }\n      boolean success = false;\n      try {\n        w.addDocuments(new RandomFailingIterable<IndexDocument>(docs, random()));\n        success = true;\n      } catch (RuntimeException e) {\n        assertEquals(\"boom\", e.getMessage());\n      } finally {\n        if (success) {\n          docCount += docs.size();\n          for (Document indexDocument : docs) {\n            liveIds.add(indexDocument.get(\"id\"));  \n          }\n        }\n      }\n    }\n    DirectoryReader reader = w.getReader();\n    assertEquals(docCount, reader.numDocs());\n    List<LeafReaderContext> leaves = reader.leaves();\n    for (LeafReaderContext leafReaderContext : leaves) {\n      LeafReader ar = leafReaderContext.reader();\n      Bits liveDocs = ar.getLiveDocs();\n      int maxDoc = ar.maxDoc();\n      for (int i = 0; i < maxDoc; i++) {\n        if (liveDocs == null || liveDocs.get(i)) {\n          assertTrue(liveIds.remove(ar.document(i).get(\"id\")));\n        }\n      }\n    }\n    assertTrue(liveIds.isEmpty());\n    w.close();\n    IOUtils.close(reader, dir);\n  }\n\n","sourceOld":"  public void testIterableThrowsException() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random())));\n    int iters = atLeast(100);\n    int docCount = 0;\n    int docId = 0;\n    Set<String> liveIds = new HashSet<>();\n    for (int i = 0; i < iters; i++) {\n      List<Document> docs = new ArrayList<>();\n      FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n      FieldType idFt = new FieldType(TextField.TYPE_STORED);\n      \n      int numDocs = atLeast(4);\n      for (int j = 0; j < numDocs; j++) {\n        Document doc = new Document();\n        doc.add(newField(\"id\", \"\"+ (docId++), idFt));\n        doc.add(newField(\"foo\", TestUtil.randomSimpleString(random()), ft));\n        docs.add(doc);\n      }\n      boolean success = false;\n      try {\n        w.addDocuments(new RandomFailingIterable<IndexDocument>(docs, random()));\n        success = true;\n      } catch (RuntimeException e) {\n        assertEquals(\"boom\", e.getMessage());\n      } finally {\n        if (success) {\n          docCount += docs.size();\n          for (Document indexDocument : docs) {\n            liveIds.add(indexDocument.get(\"id\"));  \n          }\n        }\n      }\n    }\n    DirectoryReader reader = w.getReader();\n    assertEquals(docCount, reader.numDocs());\n    List<AtomicReaderContext> leaves = reader.leaves();\n    for (AtomicReaderContext atomicReaderContext : leaves) {\n      AtomicReader ar = atomicReaderContext.reader();\n      Bits liveDocs = ar.getLiveDocs();\n      int maxDoc = ar.maxDoc();\n      for (int i = 0; i < maxDoc; i++) {\n        if (liveDocs == null || liveDocs.get(i)) {\n          assertTrue(liveIds.remove(ar.document(i).get(\"id\")));\n        }\n      }\n    }\n    assertTrue(liveIds.isEmpty());\n    w.close();\n    IOUtils.close(reader, dir);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6654c5f3ec2e4a84ef867c82d4eec872c2372c8c","date":1453060490,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriter#testIterableThrowsException().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriter#testIterableThrowsException().mjava","sourceNew":"  public void testIterableThrowsException() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random())));\n    int iters = atLeast(100);\n    int docCount = 0;\n    int docId = 0;\n    Set<String> liveIds = new HashSet<>();\n    for (int i = 0; i < iters; i++) {\n      int numDocs = atLeast(4);\n      for (int j = 0; j < numDocs; j++) {\n        String id = Integer.toString(docId++);\n        final List<IndexableField> fields = new ArrayList<>();\n        fields.add(new StringField(\"id\", id, Field.Store.YES));\n        fields.add(new StringField(\"foo\", TestUtil.randomSimpleString(random()), Field.Store.NO));\n        docId++;\n\n        boolean success = false;\n        try {\n          w.addDocument(new RandomFailingIterable<IndexableField>(fields, random()));\n          success = true;\n        } catch (RuntimeException e) {\n          assertEquals(\"boom\", e.getMessage());\n        } finally {\n          if (success) {\n            docCount++;\n            liveIds.add(id);\n          }\n        }\n      }\n    }\n    DirectoryReader reader = w.getReader();\n    assertEquals(docCount, reader.numDocs());\n    List<LeafReaderContext> leaves = reader.leaves();\n    for (LeafReaderContext leafReaderContext : leaves) {\n      LeafReader ar = leafReaderContext.reader();\n      Bits liveDocs = ar.getLiveDocs();\n      int maxDoc = ar.maxDoc();\n      for (int i = 0; i < maxDoc; i++) {\n        if (liveDocs == null || liveDocs.get(i)) {\n          assertTrue(liveIds.remove(ar.document(i).get(\"id\")));\n        }\n      }\n    }\n    assertTrue(liveIds.isEmpty());\n    w.close();\n    IOUtils.close(reader, dir);\n  }\n\n","sourceOld":"  public void testIterableThrowsException() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random())));\n    int iters = atLeast(100);\n    int docCount = 0;\n    int docId = 0;\n    Set<String> liveIds = new HashSet<>();\n    for (int i = 0; i < iters; i++) {\n      List<Document> docs = new ArrayList<>();\n      FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n      FieldType idFt = new FieldType(TextField.TYPE_STORED);\n      \n      int numDocs = atLeast(4);\n      for (int j = 0; j < numDocs; j++) {\n        Document doc = new Document();\n        doc.add(newField(\"id\", \"\"+ (docId++), idFt));\n        doc.add(newField(\"foo\", TestUtil.randomSimpleString(random()), ft));\n        docs.add(doc);\n      }\n      boolean success = false;\n      try {\n        w.addDocuments(new RandomFailingIterable<IndexDocument>(docs, random()));\n        success = true;\n      } catch (RuntimeException e) {\n        assertEquals(\"boom\", e.getMessage());\n      } finally {\n        if (success) {\n          docCount += docs.size();\n          for (Document indexDocument : docs) {\n            liveIds.add(indexDocument.get(\"id\"));  \n          }\n        }\n      }\n    }\n    DirectoryReader reader = w.getReader();\n    assertEquals(docCount, reader.numDocs());\n    List<LeafReaderContext> leaves = reader.leaves();\n    for (LeafReaderContext leafReaderContext : leaves) {\n      LeafReader ar = leafReaderContext.reader();\n      Bits liveDocs = ar.getLiveDocs();\n      int maxDoc = ar.maxDoc();\n      for (int i = 0; i < maxDoc; i++) {\n        if (liveDocs == null || liveDocs.get(i)) {\n          assertTrue(liveIds.remove(ar.document(i).get(\"id\")));\n        }\n      }\n    }\n    assertTrue(liveIds.isEmpty());\n    w.close();\n    IOUtils.close(reader, dir);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"d3fcb70cf561547c7bb1506e0cf32ca7b1287064":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","3bdeb3bacd9fab7d3eb4083f73bc002c467bea41"],"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["6613659748fe4411a7dcf85266e55db1f95f7315"],"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e":["36e9f571cf40a8818eb678ed8fcf845cb9f9b456"],"ac7fa87956e618e2e88572544ae87078647f6351":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"36e9f571cf40a8818eb678ed8fcf845cb9f9b456":["ae14298f4eec6d5faee6a149f88ba57d14a6f21a"],"6613659748fe4411a7dcf85266e55db1f95f7315":["3bdeb3bacd9fab7d3eb4083f73bc002c467bea41"],"c9fb5f46e264daf5ba3860defe623a89d202dd87":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"3bdeb3bacd9fab7d3eb4083f73bc002c467bea41":["ac7fa87956e618e2e88572544ae87078647f6351"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"d0ef034a4f10871667ae75181537775ddcf8ade4":["54a6bea0b991120a99ad0e2f72ae853fd5ecae0e"],"ae14298f4eec6d5faee6a149f88ba57d14a6f21a":["634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["6654c5f3ec2e4a84ef867c82d4eec872c2372c8c"],"6654c5f3ec2e4a84ef867c82d4eec872c2372c8c":["c9fb5f46e264daf5ba3860defe623a89d202dd87"]},"commit2Childs":{"d3fcb70cf561547c7bb1506e0cf32ca7b1287064":[],"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["ae14298f4eec6d5faee6a149f88ba57d14a6f21a"],"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"ac7fa87956e618e2e88572544ae87078647f6351":["3bdeb3bacd9fab7d3eb4083f73bc002c467bea41"],"6613659748fe4411a7dcf85266e55db1f95f7315":["634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"36e9f571cf40a8818eb678ed8fcf845cb9f9b456":["54a6bea0b991120a99ad0e2f72ae853fd5ecae0e"],"c9fb5f46e264daf5ba3860defe623a89d202dd87":["6654c5f3ec2e4a84ef867c82d4eec872c2372c8c"],"3bdeb3bacd9fab7d3eb4083f73bc002c467bea41":["d3fcb70cf561547c7bb1506e0cf32ca7b1287064","6613659748fe4411a7dcf85266e55db1f95f7315"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["d3fcb70cf561547c7bb1506e0cf32ca7b1287064","ac7fa87956e618e2e88572544ae87078647f6351"],"d0ef034a4f10871667ae75181537775ddcf8ade4":["c9fb5f46e264daf5ba3860defe623a89d202dd87"],"ae14298f4eec6d5faee6a149f88ba57d14a6f21a":["36e9f571cf40a8818eb678ed8fcf845cb9f9b456"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"6654c5f3ec2e4a84ef867c82d4eec872c2372c8c":["cd5edd1f2b162a5cfa08efd17851a07373a96817"]},"heads":["d3fcb70cf561547c7bb1506e0cf32ca7b1287064","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}