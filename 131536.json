{"path":"solr/src/test/org/apache/solr/spelling/IndexBasedSpellCheckerTest#testAlternateLocation().mjava","commits":[{"id":"893269407f5c988a4b2ee13c7ffc01ec43136c1d","date":1268598046,"type":0,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/src/test/org/apache/solr/spelling/IndexBasedSpellCheckerTest#testAlternateLocation().mjava","pathOld":"/dev/null","sourceNew":"  public void testAlternateLocation() throws Exception {\n    String[] ALT_DOCS = new String[]{\n            \"jumpin jack flash\",\n            \"Sargent Peppers Lonely Hearts Club Band\",\n            \"Born to Run\",\n            \"Thunder Road\",\n            \"Londons Burning\",\n            \"A Horse with No Name\",\n            \"Sweet Caroline\"\n    };\n\n    IndexBasedSpellChecker checker = new IndexBasedSpellChecker();\n    NamedList spellchecker = new NamedList();\n    spellchecker.add(\"classname\", IndexBasedSpellChecker.class.getName());\n\n    File tmpDir = new File(System.getProperty(\"java.io.tmpdir\"));\n    File indexDir = new File(tmpDir, \"spellingIdx\" + new Date().getTime());\n    //create a standalone index\n    File altIndexDir = new File(tmpDir, \"alternateIdx\" + new Date().getTime());\n    IndexWriter iw = new IndexWriter(altIndexDir, new WhitespaceAnalyzer(), IndexWriter.MaxFieldLength.LIMITED);\n    for (int i = 0; i < ALT_DOCS.length; i++) {\n      Document doc = new Document();\n      doc.add(new Field(\"title\", ALT_DOCS[i], Field.Store.YES, Field.Index.TOKENIZED));\n      iw.addDocument(doc);\n    }\n    iw.optimize();\n    iw.close();\n    indexDir.mkdirs();\n    spellchecker.add(AbstractLuceneSpellChecker.INDEX_DIR, indexDir.getAbsolutePath());\n    spellchecker.add(AbstractLuceneSpellChecker.LOCATION, altIndexDir.getAbsolutePath());\n    spellchecker.add(IndexBasedSpellChecker.FIELD, \"title\");\n    spellchecker.add(AbstractLuceneSpellChecker.SPELLCHECKER_ARG_NAME, spellchecker);\n    SolrCore core = h.getCore();\n    String dictName = checker.init(spellchecker, core);\n    assertTrue(dictName + \" is not equal to \" + SolrSpellChecker.DEFAULT_DICTIONARY_NAME,\n            dictName.equals(SolrSpellChecker.DEFAULT_DICTIONARY_NAME) == true);\n    RefCounted<SolrIndexSearcher> holder = core.getSearcher();\n    SolrIndexSearcher searcher = holder.get();\n    try {\n    checker.build(core, searcher);\n\n    IndexReader reader = searcher.getReader();\n    Collection<Token> tokens = queryConverter.convert(\"flesh\");\n    SpellingResult result = checker.getSuggestions(tokens, reader, 1, false, true);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    //should be lowercased, b/c we are using a lowercasing analyzer\n    Map<String, Integer> suggestions = result.get(tokens.iterator().next());\n    assertTrue(\"flesh is null and it shouldn't be\", suggestions != null);\n    assertTrue(\"flesh Size: \" + suggestions.size() + \" is not: \" + 1, suggestions.size() == 1);\n    Map.Entry<String, Integer> entry = suggestions.entrySet().iterator().next();\n    assertTrue(entry.getKey() + \" is not equal to \" + \"flash\", entry.getKey().equals(\"flash\") == true);\n    assertTrue(entry.getValue() + \" does not equal: \" + 1, entry.getValue() == 1);\n\n    //test something not in the spell checker\n    tokens = queryConverter.convert(\"super\");\n    result = checker.getSuggestions(tokens, reader, 1, false, true);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    suggestions = result.get(tokens.iterator().next());\n    assertTrue(\"suggestions is not null and it should be\", suggestions == null);\n\n    tokens = queryConverter.convert(\"Caroline\");\n    result = checker.getSuggestions(tokens, reader, 1, false, true);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    suggestions = result.get(tokens.iterator().next());\n    assertTrue(\"suggestions is not null and it should be\", suggestions == null);\n    } finally {\n      holder.decref();\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a89acb2b4321b599bbfa1e802c00c4dbbc8ee6b8","date":1268599006,"type":4,"author":"Mark Robert Miller","isMerge":false,"pathNew":"/dev/null","pathOld":"solr/src/test/org/apache/solr/spelling/IndexBasedSpellCheckerTest#testAlternateLocation().mjava","sourceNew":null,"sourceOld":"  public void testAlternateLocation() throws Exception {\n    String[] ALT_DOCS = new String[]{\n            \"jumpin jack flash\",\n            \"Sargent Peppers Lonely Hearts Club Band\",\n            \"Born to Run\",\n            \"Thunder Road\",\n            \"Londons Burning\",\n            \"A Horse with No Name\",\n            \"Sweet Caroline\"\n    };\n\n    IndexBasedSpellChecker checker = new IndexBasedSpellChecker();\n    NamedList spellchecker = new NamedList();\n    spellchecker.add(\"classname\", IndexBasedSpellChecker.class.getName());\n\n    File tmpDir = new File(System.getProperty(\"java.io.tmpdir\"));\n    File indexDir = new File(tmpDir, \"spellingIdx\" + new Date().getTime());\n    //create a standalone index\n    File altIndexDir = new File(tmpDir, \"alternateIdx\" + new Date().getTime());\n    IndexWriter iw = new IndexWriter(altIndexDir, new WhitespaceAnalyzer(), IndexWriter.MaxFieldLength.LIMITED);\n    for (int i = 0; i < ALT_DOCS.length; i++) {\n      Document doc = new Document();\n      doc.add(new Field(\"title\", ALT_DOCS[i], Field.Store.YES, Field.Index.TOKENIZED));\n      iw.addDocument(doc);\n    }\n    iw.optimize();\n    iw.close();\n    indexDir.mkdirs();\n    spellchecker.add(AbstractLuceneSpellChecker.INDEX_DIR, indexDir.getAbsolutePath());\n    spellchecker.add(AbstractLuceneSpellChecker.LOCATION, altIndexDir.getAbsolutePath());\n    spellchecker.add(IndexBasedSpellChecker.FIELD, \"title\");\n    spellchecker.add(AbstractLuceneSpellChecker.SPELLCHECKER_ARG_NAME, spellchecker);\n    SolrCore core = h.getCore();\n    String dictName = checker.init(spellchecker, core);\n    assertTrue(dictName + \" is not equal to \" + SolrSpellChecker.DEFAULT_DICTIONARY_NAME,\n            dictName.equals(SolrSpellChecker.DEFAULT_DICTIONARY_NAME) == true);\n    RefCounted<SolrIndexSearcher> holder = core.getSearcher();\n    SolrIndexSearcher searcher = holder.get();\n    try {\n    checker.build(core, searcher);\n\n    IndexReader reader = searcher.getReader();\n    Collection<Token> tokens = queryConverter.convert(\"flesh\");\n    SpellingResult result = checker.getSuggestions(tokens, reader, 1, false, true);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    //should be lowercased, b/c we are using a lowercasing analyzer\n    Map<String, Integer> suggestions = result.get(tokens.iterator().next());\n    assertTrue(\"flesh is null and it shouldn't be\", suggestions != null);\n    assertTrue(\"flesh Size: \" + suggestions.size() + \" is not: \" + 1, suggestions.size() == 1);\n    Map.Entry<String, Integer> entry = suggestions.entrySet().iterator().next();\n    assertTrue(entry.getKey() + \" is not equal to \" + \"flash\", entry.getKey().equals(\"flash\") == true);\n    assertTrue(entry.getValue() + \" does not equal: \" + 1, entry.getValue() == 1);\n\n    //test something not in the spell checker\n    tokens = queryConverter.convert(\"super\");\n    result = checker.getSuggestions(tokens, reader, 1, false, true);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    suggestions = result.get(tokens.iterator().next());\n    assertTrue(\"suggestions is not null and it should be\", suggestions == null);\n\n    tokens = queryConverter.convert(\"Caroline\");\n    result = checker.getSuggestions(tokens, reader, 1, false, true);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    suggestions = result.get(tokens.iterator().next());\n    assertTrue(\"suggestions is not null and it should be\", suggestions == null);\n    } finally {\n      holder.decref();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ad94625fb8d088209f46650c8097196fec67f00c","date":1453508319,"type":1,"author":"Dawid Weiss","isMerge":false,"pathNew":"solr/src/test/org/apache/solr/spelling/IndexBasedSpellCheckerTest#testAlternateLocation().mjava","pathOld":"src/test/org/apache/solr/spelling/IndexBasedSpellCheckerTest#testAlternateLocation().mjava","sourceNew":"  public void testAlternateLocation() throws Exception {\n    String[] ALT_DOCS = new String[]{\n            \"jumpin jack flash\",\n            \"Sargent Peppers Lonely Hearts Club Band\",\n            \"Born to Run\",\n            \"Thunder Road\",\n            \"Londons Burning\",\n            \"A Horse with No Name\",\n            \"Sweet Caroline\"\n    };\n\n    IndexBasedSpellChecker checker = new IndexBasedSpellChecker();\n    NamedList spellchecker = new NamedList();\n    spellchecker.add(\"classname\", IndexBasedSpellChecker.class.getName());\n\n    File tmpDir = new File(System.getProperty(\"java.io.tmpdir\"));\n    File indexDir = new File(tmpDir, \"spellingIdx\" + new Date().getTime());\n    //create a standalone index\n    File altIndexDir = new File(tmpDir, \"alternateIdx\" + new Date().getTime());\n    IndexWriter iw = new IndexWriter(FSDirectory.open(altIndexDir), new WhitespaceAnalyzer(), IndexWriter.MaxFieldLength.LIMITED);\n    for (int i = 0; i < ALT_DOCS.length; i++) {\n      Document doc = new Document();\n      doc.add(new Field(\"title\", ALT_DOCS[i], Field.Store.YES, Field.Index.ANALYZED));\n      iw.addDocument(doc);\n    }\n    iw.optimize();\n    iw.close();\n    indexDir.mkdirs();\n    spellchecker.add(AbstractLuceneSpellChecker.INDEX_DIR, indexDir.getAbsolutePath());\n    spellchecker.add(AbstractLuceneSpellChecker.LOCATION, altIndexDir.getAbsolutePath());\n    spellchecker.add(IndexBasedSpellChecker.FIELD, \"title\");\n    spellchecker.add(AbstractLuceneSpellChecker.SPELLCHECKER_ARG_NAME, spellchecker);\n    SolrCore core = h.getCore();\n    String dictName = checker.init(spellchecker, core);\n    assertTrue(dictName + \" is not equal to \" + SolrSpellChecker.DEFAULT_DICTIONARY_NAME,\n            dictName.equals(SolrSpellChecker.DEFAULT_DICTIONARY_NAME) == true);\n    RefCounted<SolrIndexSearcher> holder = core.getSearcher();\n    SolrIndexSearcher searcher = holder.get();\n    try {\n    checker.build(core, searcher);\n\n    IndexReader reader = searcher.getReader();\n    Collection<Token> tokens = queryConverter.convert(\"flesh\");\n    SpellingResult result = checker.getSuggestions(tokens, reader, 1, false, true);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    //should be lowercased, b/c we are using a lowercasing analyzer\n    Map<String, Integer> suggestions = result.get(tokens.iterator().next());\n    assertTrue(\"flesh is null and it shouldn't be\", suggestions != null);\n    assertTrue(\"flesh Size: \" + suggestions.size() + \" is not: \" + 1, suggestions.size() == 1);\n    Map.Entry<String, Integer> entry = suggestions.entrySet().iterator().next();\n    assertTrue(entry.getKey() + \" is not equal to \" + \"flash\", entry.getKey().equals(\"flash\") == true);\n    assertTrue(entry.getValue() + \" does not equal: \" + 1, entry.getValue() == 1);\n\n    //test something not in the spell checker\n    tokens = queryConverter.convert(\"super\");\n    result = checker.getSuggestions(tokens, reader, 1, false, true);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    suggestions = result.get(tokens.iterator().next());\n    assertTrue(\"suggestions is not null and it should be\", suggestions == null);\n\n    tokens = queryConverter.convert(\"Caroline\");\n    result = checker.getSuggestions(tokens, reader, 1, false, true);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    suggestions = result.get(tokens.iterator().next());\n    assertTrue(\"suggestions is not null and it should be\", suggestions == null);\n    } finally {\n      holder.decref();\n    }\n  }\n\n","sourceOld":"  public void testAlternateLocation() throws Exception {\n    String[] ALT_DOCS = new String[]{\n            \"jumpin jack flash\",\n            \"Sargent Peppers Lonely Hearts Club Band\",\n            \"Born to Run\",\n            \"Thunder Road\",\n            \"Londons Burning\",\n            \"A Horse with No Name\",\n            \"Sweet Caroline\"\n    };\n\n    IndexBasedSpellChecker checker = new IndexBasedSpellChecker();\n    NamedList spellchecker = new NamedList();\n    spellchecker.add(\"classname\", IndexBasedSpellChecker.class.getName());\n\n    File tmpDir = new File(System.getProperty(\"java.io.tmpdir\"));\n    File indexDir = new File(tmpDir, \"spellingIdx\" + new Date().getTime());\n    //create a standalone index\n    File altIndexDir = new File(tmpDir, \"alternateIdx\" + new Date().getTime());\n    IndexWriter iw = new IndexWriter(FSDirectory.open(altIndexDir), new WhitespaceAnalyzer(), IndexWriter.MaxFieldLength.LIMITED);\n    for (int i = 0; i < ALT_DOCS.length; i++) {\n      Document doc = new Document();\n      doc.add(new Field(\"title\", ALT_DOCS[i], Field.Store.YES, Field.Index.ANALYZED));\n      iw.addDocument(doc);\n    }\n    iw.optimize();\n    iw.close();\n    indexDir.mkdirs();\n    spellchecker.add(AbstractLuceneSpellChecker.INDEX_DIR, indexDir.getAbsolutePath());\n    spellchecker.add(AbstractLuceneSpellChecker.LOCATION, altIndexDir.getAbsolutePath());\n    spellchecker.add(IndexBasedSpellChecker.FIELD, \"title\");\n    spellchecker.add(AbstractLuceneSpellChecker.SPELLCHECKER_ARG_NAME, spellchecker);\n    SolrCore core = h.getCore();\n    String dictName = checker.init(spellchecker, core);\n    assertTrue(dictName + \" is not equal to \" + SolrSpellChecker.DEFAULT_DICTIONARY_NAME,\n            dictName.equals(SolrSpellChecker.DEFAULT_DICTIONARY_NAME) == true);\n    RefCounted<SolrIndexSearcher> holder = core.getSearcher();\n    SolrIndexSearcher searcher = holder.get();\n    try {\n    checker.build(core, searcher);\n\n    IndexReader reader = searcher.getReader();\n    Collection<Token> tokens = queryConverter.convert(\"flesh\");\n    SpellingResult result = checker.getSuggestions(tokens, reader, 1, false, true);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    //should be lowercased, b/c we are using a lowercasing analyzer\n    Map<String, Integer> suggestions = result.get(tokens.iterator().next());\n    assertTrue(\"flesh is null and it shouldn't be\", suggestions != null);\n    assertTrue(\"flesh Size: \" + suggestions.size() + \" is not: \" + 1, suggestions.size() == 1);\n    Map.Entry<String, Integer> entry = suggestions.entrySet().iterator().next();\n    assertTrue(entry.getKey() + \" is not equal to \" + \"flash\", entry.getKey().equals(\"flash\") == true);\n    assertTrue(entry.getValue() + \" does not equal: \" + 1, entry.getValue() == 1);\n\n    //test something not in the spell checker\n    tokens = queryConverter.convert(\"super\");\n    result = checker.getSuggestions(tokens, reader, 1, false, true);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    suggestions = result.get(tokens.iterator().next());\n    assertTrue(\"suggestions is not null and it should be\", suggestions == null);\n\n    tokens = queryConverter.convert(\"Caroline\");\n    result = checker.getSuggestions(tokens, reader, 1, false, true);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    suggestions = result.get(tokens.iterator().next());\n    assertTrue(\"suggestions is not null and it should be\", suggestions == null);\n    } finally {\n      holder.decref();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1da8d55113b689b06716246649de6f62430f15c0","date":1453508340,"type":0,"author":"Dawid Weiss","isMerge":true,"pathNew":"solr/src/test/org/apache/solr/spelling/IndexBasedSpellCheckerTest#testAlternateLocation().mjava","pathOld":"/dev/null","sourceNew":"  public void testAlternateLocation() throws Exception {\n    String[] ALT_DOCS = new String[]{\n            \"jumpin jack flash\",\n            \"Sargent Peppers Lonely Hearts Club Band\",\n            \"Born to Run\",\n            \"Thunder Road\",\n            \"Londons Burning\",\n            \"A Horse with No Name\",\n            \"Sweet Caroline\"\n    };\n\n    IndexBasedSpellChecker checker = new IndexBasedSpellChecker();\n    NamedList spellchecker = new NamedList();\n    spellchecker.add(\"classname\", IndexBasedSpellChecker.class.getName());\n\n    File tmpDir = new File(System.getProperty(\"java.io.tmpdir\"));\n    File indexDir = new File(tmpDir, \"spellingIdx\" + new Date().getTime());\n    //create a standalone index\n    File altIndexDir = new File(tmpDir, \"alternateIdx\" + new Date().getTime());\n    IndexWriter iw = new IndexWriter(FSDirectory.open(altIndexDir), new WhitespaceAnalyzer(), IndexWriter.MaxFieldLength.LIMITED);\n    for (int i = 0; i < ALT_DOCS.length; i++) {\n      Document doc = new Document();\n      doc.add(new Field(\"title\", ALT_DOCS[i], Field.Store.YES, Field.Index.ANALYZED));\n      iw.addDocument(doc);\n    }\n    iw.optimize();\n    iw.close();\n    indexDir.mkdirs();\n    spellchecker.add(AbstractLuceneSpellChecker.INDEX_DIR, indexDir.getAbsolutePath());\n    spellchecker.add(AbstractLuceneSpellChecker.LOCATION, altIndexDir.getAbsolutePath());\n    spellchecker.add(IndexBasedSpellChecker.FIELD, \"title\");\n    spellchecker.add(AbstractLuceneSpellChecker.SPELLCHECKER_ARG_NAME, spellchecker);\n    SolrCore core = h.getCore();\n    String dictName = checker.init(spellchecker, core);\n    assertTrue(dictName + \" is not equal to \" + SolrSpellChecker.DEFAULT_DICTIONARY_NAME,\n            dictName.equals(SolrSpellChecker.DEFAULT_DICTIONARY_NAME) == true);\n    RefCounted<SolrIndexSearcher> holder = core.getSearcher();\n    SolrIndexSearcher searcher = holder.get();\n    try {\n    checker.build(core, searcher);\n\n    IndexReader reader = searcher.getReader();\n    Collection<Token> tokens = queryConverter.convert(\"flesh\");\n    SpellingResult result = checker.getSuggestions(tokens, reader, 1, false, true);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    //should be lowercased, b/c we are using a lowercasing analyzer\n    Map<String, Integer> suggestions = result.get(tokens.iterator().next());\n    assertTrue(\"flesh is null and it shouldn't be\", suggestions != null);\n    assertTrue(\"flesh Size: \" + suggestions.size() + \" is not: \" + 1, suggestions.size() == 1);\n    Map.Entry<String, Integer> entry = suggestions.entrySet().iterator().next();\n    assertTrue(entry.getKey() + \" is not equal to \" + \"flash\", entry.getKey().equals(\"flash\") == true);\n    assertTrue(entry.getValue() + \" does not equal: \" + 1, entry.getValue() == 1);\n\n    //test something not in the spell checker\n    tokens = queryConverter.convert(\"super\");\n    result = checker.getSuggestions(tokens, reader, 1, false, true);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    suggestions = result.get(tokens.iterator().next());\n    assertTrue(\"suggestions is not null and it should be\", suggestions == null);\n\n    tokens = queryConverter.convert(\"Caroline\");\n    result = checker.getSuggestions(tokens, reader, 1, false, true);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    suggestions = result.get(tokens.iterator().next());\n    assertTrue(\"suggestions is not null and it should be\", suggestions == null);\n    } finally {\n      holder.decref();\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"afeb033b2bd36d8ce9d82142b197da4dde13068b","date":1269115863,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"solr/src/test/org/apache/solr/spelling/IndexBasedSpellCheckerTest#testAlternateLocation().mjava","pathOld":"solr/src/test/org/apache/solr/spelling/IndexBasedSpellCheckerTest#testAlternateLocation().mjava","sourceNew":"  @Test\n  public void testAlternateLocation() throws Exception {\n    String[] ALT_DOCS = new String[]{\n            \"jumpin jack flash\",\n            \"Sargent Peppers Lonely Hearts Club Band\",\n            \"Born to Run\",\n            \"Thunder Road\",\n            \"Londons Burning\",\n            \"A Horse with No Name\",\n            \"Sweet Caroline\"\n    };\n\n    IndexBasedSpellChecker checker = new IndexBasedSpellChecker();\n    NamedList spellchecker = new NamedList();\n    spellchecker.add(\"classname\", IndexBasedSpellChecker.class.getName());\n\n    File tmpDir = new File(System.getProperty(\"java.io.tmpdir\"));\n    File indexDir = new File(tmpDir, \"spellingIdx\" + new Date().getTime());\n    //create a standalone index\n    File altIndexDir = new File(tmpDir, \"alternateIdx\" + new Date().getTime());\n    IndexWriter iw = new IndexWriter(FSDirectory.open(altIndexDir), new WhitespaceAnalyzer(), IndexWriter.MaxFieldLength.LIMITED);\n    for (int i = 0; i < ALT_DOCS.length; i++) {\n      Document doc = new Document();\n      doc.add(new Field(\"title\", ALT_DOCS[i], Field.Store.YES, Field.Index.ANALYZED));\n      iw.addDocument(doc);\n    }\n    iw.optimize();\n    iw.close();\n    indexDir.mkdirs();\n    spellchecker.add(AbstractLuceneSpellChecker.INDEX_DIR, indexDir.getAbsolutePath());\n    spellchecker.add(AbstractLuceneSpellChecker.LOCATION, altIndexDir.getAbsolutePath());\n    spellchecker.add(IndexBasedSpellChecker.FIELD, \"title\");\n    spellchecker.add(AbstractLuceneSpellChecker.SPELLCHECKER_ARG_NAME, spellchecker);\n    SolrCore core = h.getCore();\n    String dictName = checker.init(spellchecker, core);\n    assertTrue(dictName + \" is not equal to \" + SolrSpellChecker.DEFAULT_DICTIONARY_NAME,\n            dictName.equals(SolrSpellChecker.DEFAULT_DICTIONARY_NAME) == true);\n    RefCounted<SolrIndexSearcher> holder = core.getSearcher();\n    SolrIndexSearcher searcher = holder.get();\n    try {\n    checker.build(core, searcher);\n\n    IndexReader reader = searcher.getReader();\n    Collection<Token> tokens = queryConverter.convert(\"flesh\");\n    SpellingResult result = checker.getSuggestions(tokens, reader, 1, false, true);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    //should be lowercased, b/c we are using a lowercasing analyzer\n    Map<String, Integer> suggestions = result.get(tokens.iterator().next());\n    assertTrue(\"flesh is null and it shouldn't be\", suggestions != null);\n    assertTrue(\"flesh Size: \" + suggestions.size() + \" is not: \" + 1, suggestions.size() == 1);\n    Map.Entry<String, Integer> entry = suggestions.entrySet().iterator().next();\n    assertTrue(entry.getKey() + \" is not equal to \" + \"flash\", entry.getKey().equals(\"flash\") == true);\n    assertTrue(entry.getValue() + \" does not equal: \" + 1, entry.getValue() == 1);\n\n    //test something not in the spell checker\n    tokens = queryConverter.convert(\"super\");\n    result = checker.getSuggestions(tokens, reader, 1, false, true);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    suggestions = result.get(tokens.iterator().next());\n    assertTrue(\"suggestions is not null and it should be\", suggestions == null);\n\n    tokens = queryConverter.convert(\"Caroline\");\n    result = checker.getSuggestions(tokens, reader, 1, false, true);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    suggestions = result.get(tokens.iterator().next());\n    assertTrue(\"suggestions is not null and it should be\", suggestions == null);\n    } finally {\n      holder.decref();\n    }\n  }\n\n","sourceOld":"  public void testAlternateLocation() throws Exception {\n    String[] ALT_DOCS = new String[]{\n            \"jumpin jack flash\",\n            \"Sargent Peppers Lonely Hearts Club Band\",\n            \"Born to Run\",\n            \"Thunder Road\",\n            \"Londons Burning\",\n            \"A Horse with No Name\",\n            \"Sweet Caroline\"\n    };\n\n    IndexBasedSpellChecker checker = new IndexBasedSpellChecker();\n    NamedList spellchecker = new NamedList();\n    spellchecker.add(\"classname\", IndexBasedSpellChecker.class.getName());\n\n    File tmpDir = new File(System.getProperty(\"java.io.tmpdir\"));\n    File indexDir = new File(tmpDir, \"spellingIdx\" + new Date().getTime());\n    //create a standalone index\n    File altIndexDir = new File(tmpDir, \"alternateIdx\" + new Date().getTime());\n    IndexWriter iw = new IndexWriter(FSDirectory.open(altIndexDir), new WhitespaceAnalyzer(), IndexWriter.MaxFieldLength.LIMITED);\n    for (int i = 0; i < ALT_DOCS.length; i++) {\n      Document doc = new Document();\n      doc.add(new Field(\"title\", ALT_DOCS[i], Field.Store.YES, Field.Index.ANALYZED));\n      iw.addDocument(doc);\n    }\n    iw.optimize();\n    iw.close();\n    indexDir.mkdirs();\n    spellchecker.add(AbstractLuceneSpellChecker.INDEX_DIR, indexDir.getAbsolutePath());\n    spellchecker.add(AbstractLuceneSpellChecker.LOCATION, altIndexDir.getAbsolutePath());\n    spellchecker.add(IndexBasedSpellChecker.FIELD, \"title\");\n    spellchecker.add(AbstractLuceneSpellChecker.SPELLCHECKER_ARG_NAME, spellchecker);\n    SolrCore core = h.getCore();\n    String dictName = checker.init(spellchecker, core);\n    assertTrue(dictName + \" is not equal to \" + SolrSpellChecker.DEFAULT_DICTIONARY_NAME,\n            dictName.equals(SolrSpellChecker.DEFAULT_DICTIONARY_NAME) == true);\n    RefCounted<SolrIndexSearcher> holder = core.getSearcher();\n    SolrIndexSearcher searcher = holder.get();\n    try {\n    checker.build(core, searcher);\n\n    IndexReader reader = searcher.getReader();\n    Collection<Token> tokens = queryConverter.convert(\"flesh\");\n    SpellingResult result = checker.getSuggestions(tokens, reader, 1, false, true);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    //should be lowercased, b/c we are using a lowercasing analyzer\n    Map<String, Integer> suggestions = result.get(tokens.iterator().next());\n    assertTrue(\"flesh is null and it shouldn't be\", suggestions != null);\n    assertTrue(\"flesh Size: \" + suggestions.size() + \" is not: \" + 1, suggestions.size() == 1);\n    Map.Entry<String, Integer> entry = suggestions.entrySet().iterator().next();\n    assertTrue(entry.getKey() + \" is not equal to \" + \"flash\", entry.getKey().equals(\"flash\") == true);\n    assertTrue(entry.getValue() + \" does not equal: \" + 1, entry.getValue() == 1);\n\n    //test something not in the spell checker\n    tokens = queryConverter.convert(\"super\");\n    result = checker.getSuggestions(tokens, reader, 1, false, true);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    suggestions = result.get(tokens.iterator().next());\n    assertTrue(\"suggestions is not null and it should be\", suggestions == null);\n\n    tokens = queryConverter.convert(\"Caroline\");\n    result = checker.getSuggestions(tokens, reader, 1, false, true);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    suggestions = result.get(tokens.iterator().next());\n    assertTrue(\"suggestions is not null and it should be\", suggestions == null);\n    } finally {\n      holder.decref();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"848cf14d057f83cf4a9ced81c37d4d59ab739e5a","date":1280773472,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"solr/src/test/org/apache/solr/spelling/IndexBasedSpellCheckerTest#testAlternateLocation().mjava","pathOld":"solr/src/test/org/apache/solr/spelling/IndexBasedSpellCheckerTest#testAlternateLocation().mjava","sourceNew":"  @Test\n  public void testAlternateLocation() throws Exception {\n    String[] ALT_DOCS = new String[]{\n            \"jumpin jack flash\",\n            \"Sargent Peppers Lonely Hearts Club Band\",\n            \"Born to Run\",\n            \"Thunder Road\",\n            \"Londons Burning\",\n            \"A Horse with No Name\",\n            \"Sweet Caroline\"\n    };\n\n    IndexBasedSpellChecker checker = new IndexBasedSpellChecker();\n    NamedList spellchecker = new NamedList();\n    spellchecker.add(\"classname\", IndexBasedSpellChecker.class.getName());\n\n    File indexDir = new File(TEMP_DIR, \"spellingIdx\" + new Date().getTime());\n    //create a standalone index\n    File altIndexDir = new File(TEMP_DIR, \"alternateIdx\" + new Date().getTime());\n    IndexWriter iw = new IndexWriter(FSDirectory.open(altIndexDir), new WhitespaceAnalyzer(), IndexWriter.MaxFieldLength.LIMITED);\n    for (int i = 0; i < ALT_DOCS.length; i++) {\n      Document doc = new Document();\n      doc.add(new Field(\"title\", ALT_DOCS[i], Field.Store.YES, Field.Index.ANALYZED));\n      iw.addDocument(doc);\n    }\n    iw.optimize();\n    iw.close();\n    indexDir.mkdirs();\n    spellchecker.add(AbstractLuceneSpellChecker.INDEX_DIR, indexDir.getAbsolutePath());\n    spellchecker.add(AbstractLuceneSpellChecker.LOCATION, altIndexDir.getAbsolutePath());\n    spellchecker.add(IndexBasedSpellChecker.FIELD, \"title\");\n    spellchecker.add(AbstractLuceneSpellChecker.SPELLCHECKER_ARG_NAME, spellchecker);\n    SolrCore core = h.getCore();\n    String dictName = checker.init(spellchecker, core);\n    assertTrue(dictName + \" is not equal to \" + SolrSpellChecker.DEFAULT_DICTIONARY_NAME,\n            dictName.equals(SolrSpellChecker.DEFAULT_DICTIONARY_NAME) == true);\n    RefCounted<SolrIndexSearcher> holder = core.getSearcher();\n    SolrIndexSearcher searcher = holder.get();\n    try {\n    checker.build(core, searcher);\n\n    IndexReader reader = searcher.getReader();\n    Collection<Token> tokens = queryConverter.convert(\"flesh\");\n    SpellingResult result = checker.getSuggestions(tokens, reader, 1, false, true);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    //should be lowercased, b/c we are using a lowercasing analyzer\n    Map<String, Integer> suggestions = result.get(tokens.iterator().next());\n    assertTrue(\"flesh is null and it shouldn't be\", suggestions != null);\n    assertTrue(\"flesh Size: \" + suggestions.size() + \" is not: \" + 1, suggestions.size() == 1);\n    Map.Entry<String, Integer> entry = suggestions.entrySet().iterator().next();\n    assertTrue(entry.getKey() + \" is not equal to \" + \"flash\", entry.getKey().equals(\"flash\") == true);\n    assertTrue(entry.getValue() + \" does not equal: \" + 1, entry.getValue() == 1);\n\n    //test something not in the spell checker\n    tokens = queryConverter.convert(\"super\");\n    result = checker.getSuggestions(tokens, reader, 1, false, true);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    suggestions = result.get(tokens.iterator().next());\n    assertTrue(\"suggestions is not null and it should be\", suggestions == null);\n\n    tokens = queryConverter.convert(\"Caroline\");\n    result = checker.getSuggestions(tokens, reader, 1, false, true);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    suggestions = result.get(tokens.iterator().next());\n    assertTrue(\"suggestions is not null and it should be\", suggestions == null);\n    } finally {\n      holder.decref();\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testAlternateLocation() throws Exception {\n    String[] ALT_DOCS = new String[]{\n            \"jumpin jack flash\",\n            \"Sargent Peppers Lonely Hearts Club Band\",\n            \"Born to Run\",\n            \"Thunder Road\",\n            \"Londons Burning\",\n            \"A Horse with No Name\",\n            \"Sweet Caroline\"\n    };\n\n    IndexBasedSpellChecker checker = new IndexBasedSpellChecker();\n    NamedList spellchecker = new NamedList();\n    spellchecker.add(\"classname\", IndexBasedSpellChecker.class.getName());\n\n    File tmpDir = new File(System.getProperty(\"java.io.tmpdir\"));\n    File indexDir = new File(tmpDir, \"spellingIdx\" + new Date().getTime());\n    //create a standalone index\n    File altIndexDir = new File(tmpDir, \"alternateIdx\" + new Date().getTime());\n    IndexWriter iw = new IndexWriter(FSDirectory.open(altIndexDir), new WhitespaceAnalyzer(), IndexWriter.MaxFieldLength.LIMITED);\n    for (int i = 0; i < ALT_DOCS.length; i++) {\n      Document doc = new Document();\n      doc.add(new Field(\"title\", ALT_DOCS[i], Field.Store.YES, Field.Index.ANALYZED));\n      iw.addDocument(doc);\n    }\n    iw.optimize();\n    iw.close();\n    indexDir.mkdirs();\n    spellchecker.add(AbstractLuceneSpellChecker.INDEX_DIR, indexDir.getAbsolutePath());\n    spellchecker.add(AbstractLuceneSpellChecker.LOCATION, altIndexDir.getAbsolutePath());\n    spellchecker.add(IndexBasedSpellChecker.FIELD, \"title\");\n    spellchecker.add(AbstractLuceneSpellChecker.SPELLCHECKER_ARG_NAME, spellchecker);\n    SolrCore core = h.getCore();\n    String dictName = checker.init(spellchecker, core);\n    assertTrue(dictName + \" is not equal to \" + SolrSpellChecker.DEFAULT_DICTIONARY_NAME,\n            dictName.equals(SolrSpellChecker.DEFAULT_DICTIONARY_NAME) == true);\n    RefCounted<SolrIndexSearcher> holder = core.getSearcher();\n    SolrIndexSearcher searcher = holder.get();\n    try {\n    checker.build(core, searcher);\n\n    IndexReader reader = searcher.getReader();\n    Collection<Token> tokens = queryConverter.convert(\"flesh\");\n    SpellingResult result = checker.getSuggestions(tokens, reader, 1, false, true);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    //should be lowercased, b/c we are using a lowercasing analyzer\n    Map<String, Integer> suggestions = result.get(tokens.iterator().next());\n    assertTrue(\"flesh is null and it shouldn't be\", suggestions != null);\n    assertTrue(\"flesh Size: \" + suggestions.size() + \" is not: \" + 1, suggestions.size() == 1);\n    Map.Entry<String, Integer> entry = suggestions.entrySet().iterator().next();\n    assertTrue(entry.getKey() + \" is not equal to \" + \"flash\", entry.getKey().equals(\"flash\") == true);\n    assertTrue(entry.getValue() + \" does not equal: \" + 1, entry.getValue() == 1);\n\n    //test something not in the spell checker\n    tokens = queryConverter.convert(\"super\");\n    result = checker.getSuggestions(tokens, reader, 1, false, true);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    suggestions = result.get(tokens.iterator().next());\n    assertTrue(\"suggestions is not null and it should be\", suggestions == null);\n\n    tokens = queryConverter.convert(\"Caroline\");\n    result = checker.getSuggestions(tokens, reader, 1, false, true);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    suggestions = result.get(tokens.iterator().next());\n    assertTrue(\"suggestions is not null and it should be\", suggestions == null);\n    } finally {\n      holder.decref();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d76ab9983349b199b0e6f65776c0087b0c08a10d","date":1282230089,"type":3,"author":"Grant Ingersoll","isMerge":false,"pathNew":"solr/src/test/org/apache/solr/spelling/IndexBasedSpellCheckerTest#testAlternateLocation().mjava","pathOld":"solr/src/test/org/apache/solr/spelling/IndexBasedSpellCheckerTest#testAlternateLocation().mjava","sourceNew":"  @Test\n  public void testAlternateLocation() throws Exception {\n    String[] ALT_DOCS = new String[]{\n            \"jumpin jack flash\",\n            \"Sargent Peppers Lonely Hearts Club Band\",\n            \"Born to Run\",\n            \"Thunder Road\",\n            \"Londons Burning\",\n            \"A Horse with No Name\",\n            \"Sweet Caroline\"\n    };\n\n    IndexBasedSpellChecker checker = new IndexBasedSpellChecker();\n    NamedList spellchecker = new NamedList();\n    spellchecker.add(\"classname\", IndexBasedSpellChecker.class.getName());\n\n    File indexDir = new File(TEMP_DIR, \"spellingIdx\" + new Date().getTime());\n    //create a standalone index\n    File altIndexDir = new File(TEMP_DIR, \"alternateIdx\" + new Date().getTime());\n    IndexWriter iw = new IndexWriter(FSDirectory.open(altIndexDir), new WhitespaceAnalyzer(), IndexWriter.MaxFieldLength.LIMITED);\n    for (int i = 0; i < ALT_DOCS.length; i++) {\n      Document doc = new Document();\n      doc.add(new Field(\"title\", ALT_DOCS[i], Field.Store.YES, Field.Index.ANALYZED));\n      iw.addDocument(doc);\n    }\n    iw.optimize();\n    iw.close();\n    indexDir.mkdirs();\n    spellchecker.add(AbstractLuceneSpellChecker.INDEX_DIR, indexDir.getAbsolutePath());\n    spellchecker.add(AbstractLuceneSpellChecker.LOCATION, altIndexDir.getAbsolutePath());\n    spellchecker.add(IndexBasedSpellChecker.FIELD, \"title\");\n    spellchecker.add(AbstractLuceneSpellChecker.SPELLCHECKER_ARG_NAME, spellchecker);\n    SolrCore core = h.getCore();\n    String dictName = checker.init(spellchecker, core);\n    assertTrue(dictName + \" is not equal to \" + SolrSpellChecker.DEFAULT_DICTIONARY_NAME,\n            dictName.equals(SolrSpellChecker.DEFAULT_DICTIONARY_NAME) == true);\n    RefCounted<SolrIndexSearcher> holder = core.getSearcher();\n    SolrIndexSearcher searcher = holder.get();\n    try {\n    checker.build(core, searcher);\n\n    IndexReader reader = searcher.getReader();\n    Collection<Token> tokens = queryConverter.convert(\"flesh\");\n    SpellingOptions spellOpts = new SpellingOptions(tokens, reader, 1, false, true, 0.5f, null);\n    SpellingResult result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    //should be lowercased, b/c we are using a lowercasing analyzer\n    Map<String, Integer> suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"flesh is null and it shouldn't be\", suggestions != null);\n    assertTrue(\"flesh Size: \" + suggestions.size() + \" is not: \" + 1, suggestions.size() == 1);\n    Map.Entry<String, Integer> entry = suggestions.entrySet().iterator().next();\n    assertTrue(entry.getKey() + \" is not equal to \" + \"flash\", entry.getKey().equals(\"flash\") == true);\n    assertTrue(entry.getValue() + \" does not equal: \" + 1, entry.getValue() == 1);\n\n    //test something not in the spell checker\n    spellOpts.tokens = queryConverter.convert(\"super\");\n    result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"suggestions is not null and it should be\", suggestions == null);\n\n    spellOpts.tokens = queryConverter.convert(\"Caroline\");\n    result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"suggestions is not null and it should be\", suggestions == null);\n    } finally {\n      holder.decref();\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testAlternateLocation() throws Exception {\n    String[] ALT_DOCS = new String[]{\n            \"jumpin jack flash\",\n            \"Sargent Peppers Lonely Hearts Club Band\",\n            \"Born to Run\",\n            \"Thunder Road\",\n            \"Londons Burning\",\n            \"A Horse with No Name\",\n            \"Sweet Caroline\"\n    };\n\n    IndexBasedSpellChecker checker = new IndexBasedSpellChecker();\n    NamedList spellchecker = new NamedList();\n    spellchecker.add(\"classname\", IndexBasedSpellChecker.class.getName());\n\n    File indexDir = new File(TEMP_DIR, \"spellingIdx\" + new Date().getTime());\n    //create a standalone index\n    File altIndexDir = new File(TEMP_DIR, \"alternateIdx\" + new Date().getTime());\n    IndexWriter iw = new IndexWriter(FSDirectory.open(altIndexDir), new WhitespaceAnalyzer(), IndexWriter.MaxFieldLength.LIMITED);\n    for (int i = 0; i < ALT_DOCS.length; i++) {\n      Document doc = new Document();\n      doc.add(new Field(\"title\", ALT_DOCS[i], Field.Store.YES, Field.Index.ANALYZED));\n      iw.addDocument(doc);\n    }\n    iw.optimize();\n    iw.close();\n    indexDir.mkdirs();\n    spellchecker.add(AbstractLuceneSpellChecker.INDEX_DIR, indexDir.getAbsolutePath());\n    spellchecker.add(AbstractLuceneSpellChecker.LOCATION, altIndexDir.getAbsolutePath());\n    spellchecker.add(IndexBasedSpellChecker.FIELD, \"title\");\n    spellchecker.add(AbstractLuceneSpellChecker.SPELLCHECKER_ARG_NAME, spellchecker);\n    SolrCore core = h.getCore();\n    String dictName = checker.init(spellchecker, core);\n    assertTrue(dictName + \" is not equal to \" + SolrSpellChecker.DEFAULT_DICTIONARY_NAME,\n            dictName.equals(SolrSpellChecker.DEFAULT_DICTIONARY_NAME) == true);\n    RefCounted<SolrIndexSearcher> holder = core.getSearcher();\n    SolrIndexSearcher searcher = holder.get();\n    try {\n    checker.build(core, searcher);\n\n    IndexReader reader = searcher.getReader();\n    Collection<Token> tokens = queryConverter.convert(\"flesh\");\n    SpellingResult result = checker.getSuggestions(tokens, reader, 1, false, true);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    //should be lowercased, b/c we are using a lowercasing analyzer\n    Map<String, Integer> suggestions = result.get(tokens.iterator().next());\n    assertTrue(\"flesh is null and it shouldn't be\", suggestions != null);\n    assertTrue(\"flesh Size: \" + suggestions.size() + \" is not: \" + 1, suggestions.size() == 1);\n    Map.Entry<String, Integer> entry = suggestions.entrySet().iterator().next();\n    assertTrue(entry.getKey() + \" is not equal to \" + \"flash\", entry.getKey().equals(\"flash\") == true);\n    assertTrue(entry.getValue() + \" does not equal: \" + 1, entry.getValue() == 1);\n\n    //test something not in the spell checker\n    tokens = queryConverter.convert(\"super\");\n    result = checker.getSuggestions(tokens, reader, 1, false, true);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    suggestions = result.get(tokens.iterator().next());\n    assertTrue(\"suggestions is not null and it should be\", suggestions == null);\n\n    tokens = queryConverter.convert(\"Caroline\");\n    result = checker.getSuggestions(tokens, reader, 1, false, true);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    suggestions = result.get(tokens.iterator().next());\n    assertTrue(\"suggestions is not null and it should be\", suggestions == null);\n    } finally {\n      holder.decref();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4e8cc373c801e54cec75daf9f52792cb4b17f536","date":1291116159,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"solr/src/test/org/apache/solr/spelling/IndexBasedSpellCheckerTest#testAlternateLocation().mjava","pathOld":"solr/src/test/org/apache/solr/spelling/IndexBasedSpellCheckerTest#testAlternateLocation().mjava","sourceNew":"  @Test\n  public void testAlternateLocation() throws Exception {\n    String[] ALT_DOCS = new String[]{\n            \"jumpin jack flash\",\n            \"Sargent Peppers Lonely Hearts Club Band\",\n            \"Born to Run\",\n            \"Thunder Road\",\n            \"Londons Burning\",\n            \"A Horse with No Name\",\n            \"Sweet Caroline\"\n    };\n\n    IndexBasedSpellChecker checker = new IndexBasedSpellChecker();\n    NamedList spellchecker = new NamedList();\n    spellchecker.add(\"classname\", IndexBasedSpellChecker.class.getName());\n\n    File indexDir = new File(TEMP_DIR, \"spellingIdx\" + new Date().getTime());\n    //create a standalone index\n    File altIndexDir = new File(TEMP_DIR, \"alternateIdx\" + new Date().getTime());\n    IndexWriter iw = new IndexWriter(\n        FSDirectory.open(altIndexDir),\n        new IndexWriterConfig(TEST_VERSION_CURRENT, new WhitespaceAnalyzer(TEST_VERSION_CURRENT)).\n            setMaxFieldLength(IndexWriterConfig.UNLIMITED_FIELD_LENGTH)\n    );\n    for (int i = 0; i < ALT_DOCS.length; i++) {\n      Document doc = new Document();\n      doc.add(new Field(\"title\", ALT_DOCS[i], Field.Store.YES, Field.Index.ANALYZED));\n      iw.addDocument(doc);\n    }\n    iw.optimize();\n    iw.close();\n    indexDir.mkdirs();\n    spellchecker.add(AbstractLuceneSpellChecker.INDEX_DIR, indexDir.getAbsolutePath());\n    spellchecker.add(AbstractLuceneSpellChecker.LOCATION, altIndexDir.getAbsolutePath());\n    spellchecker.add(IndexBasedSpellChecker.FIELD, \"title\");\n    spellchecker.add(AbstractLuceneSpellChecker.SPELLCHECKER_ARG_NAME, spellchecker);\n    SolrCore core = h.getCore();\n    String dictName = checker.init(spellchecker, core);\n    assertTrue(dictName + \" is not equal to \" + SolrSpellChecker.DEFAULT_DICTIONARY_NAME,\n            dictName.equals(SolrSpellChecker.DEFAULT_DICTIONARY_NAME) == true);\n    RefCounted<SolrIndexSearcher> holder = core.getSearcher();\n    SolrIndexSearcher searcher = holder.get();\n    try {\n    checker.build(core, searcher);\n\n    IndexReader reader = searcher.getReader();\n    Collection<Token> tokens = queryConverter.convert(\"flesh\");\n    SpellingOptions spellOpts = new SpellingOptions(tokens, reader, 1, false, true, 0.5f, null);\n    SpellingResult result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    //should be lowercased, b/c we are using a lowercasing analyzer\n    Map<String, Integer> suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"flesh is null and it shouldn't be\", suggestions != null);\n    assertTrue(\"flesh Size: \" + suggestions.size() + \" is not: \" + 1, suggestions.size() == 1);\n    Map.Entry<String, Integer> entry = suggestions.entrySet().iterator().next();\n    assertTrue(entry.getKey() + \" is not equal to \" + \"flash\", entry.getKey().equals(\"flash\") == true);\n    assertTrue(entry.getValue() + \" does not equal: \" + 1, entry.getValue() == 1);\n\n    //test something not in the spell checker\n    spellOpts.tokens = queryConverter.convert(\"super\");\n    result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"suggestions is not null and it should be\", suggestions == null);\n\n    spellOpts.tokens = queryConverter.convert(\"Caroline\");\n    result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"suggestions is not null and it should be\", suggestions == null);\n    } finally {\n      holder.decref();\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testAlternateLocation() throws Exception {\n    String[] ALT_DOCS = new String[]{\n            \"jumpin jack flash\",\n            \"Sargent Peppers Lonely Hearts Club Band\",\n            \"Born to Run\",\n            \"Thunder Road\",\n            \"Londons Burning\",\n            \"A Horse with No Name\",\n            \"Sweet Caroline\"\n    };\n\n    IndexBasedSpellChecker checker = new IndexBasedSpellChecker();\n    NamedList spellchecker = new NamedList();\n    spellchecker.add(\"classname\", IndexBasedSpellChecker.class.getName());\n\n    File indexDir = new File(TEMP_DIR, \"spellingIdx\" + new Date().getTime());\n    //create a standalone index\n    File altIndexDir = new File(TEMP_DIR, \"alternateIdx\" + new Date().getTime());\n    IndexWriter iw = new IndexWriter(FSDirectory.open(altIndexDir), new WhitespaceAnalyzer(), IndexWriter.MaxFieldLength.LIMITED);\n    for (int i = 0; i < ALT_DOCS.length; i++) {\n      Document doc = new Document();\n      doc.add(new Field(\"title\", ALT_DOCS[i], Field.Store.YES, Field.Index.ANALYZED));\n      iw.addDocument(doc);\n    }\n    iw.optimize();\n    iw.close();\n    indexDir.mkdirs();\n    spellchecker.add(AbstractLuceneSpellChecker.INDEX_DIR, indexDir.getAbsolutePath());\n    spellchecker.add(AbstractLuceneSpellChecker.LOCATION, altIndexDir.getAbsolutePath());\n    spellchecker.add(IndexBasedSpellChecker.FIELD, \"title\");\n    spellchecker.add(AbstractLuceneSpellChecker.SPELLCHECKER_ARG_NAME, spellchecker);\n    SolrCore core = h.getCore();\n    String dictName = checker.init(spellchecker, core);\n    assertTrue(dictName + \" is not equal to \" + SolrSpellChecker.DEFAULT_DICTIONARY_NAME,\n            dictName.equals(SolrSpellChecker.DEFAULT_DICTIONARY_NAME) == true);\n    RefCounted<SolrIndexSearcher> holder = core.getSearcher();\n    SolrIndexSearcher searcher = holder.get();\n    try {\n    checker.build(core, searcher);\n\n    IndexReader reader = searcher.getReader();\n    Collection<Token> tokens = queryConverter.convert(\"flesh\");\n    SpellingOptions spellOpts = new SpellingOptions(tokens, reader, 1, false, true, 0.5f, null);\n    SpellingResult result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    //should be lowercased, b/c we are using a lowercasing analyzer\n    Map<String, Integer> suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"flesh is null and it shouldn't be\", suggestions != null);\n    assertTrue(\"flesh Size: \" + suggestions.size() + \" is not: \" + 1, suggestions.size() == 1);\n    Map.Entry<String, Integer> entry = suggestions.entrySet().iterator().next();\n    assertTrue(entry.getKey() + \" is not equal to \" + \"flash\", entry.getKey().equals(\"flash\") == true);\n    assertTrue(entry.getValue() + \" does not equal: \" + 1, entry.getValue() == 1);\n\n    //test something not in the spell checker\n    spellOpts.tokens = queryConverter.convert(\"super\");\n    result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"suggestions is not null and it should be\", suggestions == null);\n\n    spellOpts.tokens = queryConverter.convert(\"Caroline\");\n    result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"suggestions is not null and it should be\", suggestions == null);\n    } finally {\n      holder.decref();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3bb13258feba31ab676502787ab2e1779f129b7a","date":1291596436,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"solr/src/test/org/apache/solr/spelling/IndexBasedSpellCheckerTest#testAlternateLocation().mjava","pathOld":"solr/src/test/org/apache/solr/spelling/IndexBasedSpellCheckerTest#testAlternateLocation().mjava","sourceNew":"  @Test\n  public void testAlternateLocation() throws Exception {\n    String[] ALT_DOCS = new String[]{\n            \"jumpin jack flash\",\n            \"Sargent Peppers Lonely Hearts Club Band\",\n            \"Born to Run\",\n            \"Thunder Road\",\n            \"Londons Burning\",\n            \"A Horse with No Name\",\n            \"Sweet Caroline\"\n    };\n\n    IndexBasedSpellChecker checker = new IndexBasedSpellChecker();\n    NamedList spellchecker = new NamedList();\n    spellchecker.add(\"classname\", IndexBasedSpellChecker.class.getName());\n\n    File indexDir = new File(TEMP_DIR, \"spellingIdx\" + new Date().getTime());\n    //create a standalone index\n    File altIndexDir = new File(TEMP_DIR, \"alternateIdx\" + new Date().getTime());\n    IndexWriter iw = new IndexWriter(\n        FSDirectory.open(altIndexDir),\n        new IndexWriterConfig(TEST_VERSION_CURRENT, new WhitespaceAnalyzer(TEST_VERSION_CURRENT)).\n            setMaxFieldLength(IndexWriterConfig.UNLIMITED_FIELD_LENGTH)\n    );\n    for (int i = 0; i < ALT_DOCS.length; i++) {\n      Document doc = new Document();\n      doc.add(new Field(\"title\", ALT_DOCS[i], Field.Store.YES, Field.Index.ANALYZED));\n      iw.addDocument(doc);\n    }\n    iw.optimize();\n    iw.close();\n    indexDir.mkdirs();\n    spellchecker.add(AbstractLuceneSpellChecker.INDEX_DIR, indexDir.getAbsolutePath());\n    spellchecker.add(AbstractLuceneSpellChecker.LOCATION, altIndexDir.getAbsolutePath());\n    spellchecker.add(IndexBasedSpellChecker.FIELD, \"title\");\n    spellchecker.add(AbstractLuceneSpellChecker.SPELLCHECKER_ARG_NAME, spellchecker);\n    SolrCore core = h.getCore();\n    String dictName = checker.init(spellchecker, core);\n    assertTrue(dictName + \" is not equal to \" + SolrSpellChecker.DEFAULT_DICTIONARY_NAME,\n            dictName.equals(SolrSpellChecker.DEFAULT_DICTIONARY_NAME) == true);\n    RefCounted<SolrIndexSearcher> holder = core.getSearcher();\n    SolrIndexSearcher searcher = holder.get();\n    try {\n    checker.build(core, searcher);\n\n    IndexReader reader = searcher.getReader();\n    Collection<Token> tokens = queryConverter.convert(\"flesh\");\n    SpellingOptions spellOpts = new SpellingOptions(tokens, reader, 1, false, true, 0.5f, null);\n    SpellingResult result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    //should be lowercased, b/c we are using a lowercasing analyzer\n    Map<String, Integer> suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"flesh is null and it shouldn't be\", suggestions != null);\n    assertTrue(\"flesh Size: \" + suggestions.size() + \" is not: \" + 1, suggestions.size() == 1);\n    Map.Entry<String, Integer> entry = suggestions.entrySet().iterator().next();\n    assertTrue(entry.getKey() + \" is not equal to \" + \"flash\", entry.getKey().equals(\"flash\") == true);\n    assertTrue(entry.getValue() + \" does not equal: \" + 1, entry.getValue() == 1);\n\n    //test something not in the spell checker\n    spellOpts.tokens = queryConverter.convert(\"super\");\n    result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"suggestions is not null and it should be\", suggestions == null);\n\n    spellOpts.tokens = queryConverter.convert(\"Caroline\");\n    result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"suggestions is not null and it should be\", suggestions == null);\n    } finally {\n      holder.decref();\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testAlternateLocation() throws Exception {\n    String[] ALT_DOCS = new String[]{\n            \"jumpin jack flash\",\n            \"Sargent Peppers Lonely Hearts Club Band\",\n            \"Born to Run\",\n            \"Thunder Road\",\n            \"Londons Burning\",\n            \"A Horse with No Name\",\n            \"Sweet Caroline\"\n    };\n\n    IndexBasedSpellChecker checker = new IndexBasedSpellChecker();\n    NamedList spellchecker = new NamedList();\n    spellchecker.add(\"classname\", IndexBasedSpellChecker.class.getName());\n\n    File indexDir = new File(TEMP_DIR, \"spellingIdx\" + new Date().getTime());\n    //create a standalone index\n    File altIndexDir = new File(TEMP_DIR, \"alternateIdx\" + new Date().getTime());\n    IndexWriter iw = new IndexWriter(FSDirectory.open(altIndexDir), new WhitespaceAnalyzer(), IndexWriter.MaxFieldLength.LIMITED);\n    for (int i = 0; i < ALT_DOCS.length; i++) {\n      Document doc = new Document();\n      doc.add(new Field(\"title\", ALT_DOCS[i], Field.Store.YES, Field.Index.ANALYZED));\n      iw.addDocument(doc);\n    }\n    iw.optimize();\n    iw.close();\n    indexDir.mkdirs();\n    spellchecker.add(AbstractLuceneSpellChecker.INDEX_DIR, indexDir.getAbsolutePath());\n    spellchecker.add(AbstractLuceneSpellChecker.LOCATION, altIndexDir.getAbsolutePath());\n    spellchecker.add(IndexBasedSpellChecker.FIELD, \"title\");\n    spellchecker.add(AbstractLuceneSpellChecker.SPELLCHECKER_ARG_NAME, spellchecker);\n    SolrCore core = h.getCore();\n    String dictName = checker.init(spellchecker, core);\n    assertTrue(dictName + \" is not equal to \" + SolrSpellChecker.DEFAULT_DICTIONARY_NAME,\n            dictName.equals(SolrSpellChecker.DEFAULT_DICTIONARY_NAME) == true);\n    RefCounted<SolrIndexSearcher> holder = core.getSearcher();\n    SolrIndexSearcher searcher = holder.get();\n    try {\n    checker.build(core, searcher);\n\n    IndexReader reader = searcher.getReader();\n    Collection<Token> tokens = queryConverter.convert(\"flesh\");\n    SpellingOptions spellOpts = new SpellingOptions(tokens, reader, 1, false, true, 0.5f, null);\n    SpellingResult result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    //should be lowercased, b/c we are using a lowercasing analyzer\n    Map<String, Integer> suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"flesh is null and it shouldn't be\", suggestions != null);\n    assertTrue(\"flesh Size: \" + suggestions.size() + \" is not: \" + 1, suggestions.size() == 1);\n    Map.Entry<String, Integer> entry = suggestions.entrySet().iterator().next();\n    assertTrue(entry.getKey() + \" is not equal to \" + \"flash\", entry.getKey().equals(\"flash\") == true);\n    assertTrue(entry.getValue() + \" does not equal: \" + 1, entry.getValue() == 1);\n\n    //test something not in the spell checker\n    spellOpts.tokens = queryConverter.convert(\"super\");\n    result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"suggestions is not null and it should be\", suggestions == null);\n\n    spellOpts.tokens = queryConverter.convert(\"Caroline\");\n    result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"suggestions is not null and it should be\", suggestions == null);\n    } finally {\n      holder.decref();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a13a126d15299d5c1e117ea99ddae6fb0fa3f209","date":1291909583,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"solr/src/test/org/apache/solr/spelling/IndexBasedSpellCheckerTest#testAlternateLocation().mjava","pathOld":"solr/src/test/org/apache/solr/spelling/IndexBasedSpellCheckerTest#testAlternateLocation().mjava","sourceNew":"  @Test\n  public void testAlternateLocation() throws Exception {\n    String[] ALT_DOCS = new String[]{\n            \"jumpin jack flash\",\n            \"Sargent Peppers Lonely Hearts Club Band\",\n            \"Born to Run\",\n            \"Thunder Road\",\n            \"Londons Burning\",\n            \"A Horse with No Name\",\n            \"Sweet Caroline\"\n    };\n\n    IndexBasedSpellChecker checker = new IndexBasedSpellChecker();\n    NamedList spellchecker = new NamedList();\n    spellchecker.add(\"classname\", IndexBasedSpellChecker.class.getName());\n\n    File indexDir = new File(TEMP_DIR, \"spellingIdx\" + new Date().getTime());\n    //create a standalone index\n    File altIndexDir = new File(TEMP_DIR, \"alternateIdx\" + new Date().getTime());\n    Directory dir = newFSDirectory(altIndexDir);\n    IndexWriter iw = new IndexWriter(\n        dir,\n        new IndexWriterConfig(TEST_VERSION_CURRENT, new WhitespaceAnalyzer(TEST_VERSION_CURRENT)).\n            setMaxFieldLength(IndexWriterConfig.UNLIMITED_FIELD_LENGTH)\n    );\n    for (int i = 0; i < ALT_DOCS.length; i++) {\n      Document doc = new Document();\n      doc.add(new Field(\"title\", ALT_DOCS[i], Field.Store.YES, Field.Index.ANALYZED));\n      iw.addDocument(doc);\n    }\n    iw.optimize();\n    iw.close();\n    dir.close();\n    indexDir.mkdirs();\n    spellchecker.add(AbstractLuceneSpellChecker.INDEX_DIR, indexDir.getAbsolutePath());\n    spellchecker.add(AbstractLuceneSpellChecker.LOCATION, altIndexDir.getAbsolutePath());\n    spellchecker.add(IndexBasedSpellChecker.FIELD, \"title\");\n    spellchecker.add(AbstractLuceneSpellChecker.SPELLCHECKER_ARG_NAME, spellchecker);\n    SolrCore core = h.getCore();\n    String dictName = checker.init(spellchecker, core);\n    assertTrue(dictName + \" is not equal to \" + SolrSpellChecker.DEFAULT_DICTIONARY_NAME,\n            dictName.equals(SolrSpellChecker.DEFAULT_DICTIONARY_NAME) == true);\n    RefCounted<SolrIndexSearcher> holder = core.getSearcher();\n    SolrIndexSearcher searcher = holder.get();\n    try {\n    checker.build(core, searcher);\n\n    IndexReader reader = searcher.getReader();\n    Collection<Token> tokens = queryConverter.convert(\"flesh\");\n    SpellingOptions spellOpts = new SpellingOptions(tokens, reader, 1, false, true, 0.5f, null);\n    SpellingResult result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    //should be lowercased, b/c we are using a lowercasing analyzer\n    Map<String, Integer> suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"flesh is null and it shouldn't be\", suggestions != null);\n    assertTrue(\"flesh Size: \" + suggestions.size() + \" is not: \" + 1, suggestions.size() == 1);\n    Map.Entry<String, Integer> entry = suggestions.entrySet().iterator().next();\n    assertTrue(entry.getKey() + \" is not equal to \" + \"flash\", entry.getKey().equals(\"flash\") == true);\n    assertTrue(entry.getValue() + \" does not equal: \" + 1, entry.getValue() == 1);\n\n    //test something not in the spell checker\n    spellOpts.tokens = queryConverter.convert(\"super\");\n    result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"suggestions is not null and it should be\", suggestions == null);\n\n    spellOpts.tokens = queryConverter.convert(\"Caroline\");\n    result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"suggestions is not null and it should be\", suggestions == null);\n    } finally {\n      holder.decref();\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testAlternateLocation() throws Exception {\n    String[] ALT_DOCS = new String[]{\n            \"jumpin jack flash\",\n            \"Sargent Peppers Lonely Hearts Club Band\",\n            \"Born to Run\",\n            \"Thunder Road\",\n            \"Londons Burning\",\n            \"A Horse with No Name\",\n            \"Sweet Caroline\"\n    };\n\n    IndexBasedSpellChecker checker = new IndexBasedSpellChecker();\n    NamedList spellchecker = new NamedList();\n    spellchecker.add(\"classname\", IndexBasedSpellChecker.class.getName());\n\n    File indexDir = new File(TEMP_DIR, \"spellingIdx\" + new Date().getTime());\n    //create a standalone index\n    File altIndexDir = new File(TEMP_DIR, \"alternateIdx\" + new Date().getTime());\n    IndexWriter iw = new IndexWriter(\n        FSDirectory.open(altIndexDir),\n        new IndexWriterConfig(TEST_VERSION_CURRENT, new WhitespaceAnalyzer(TEST_VERSION_CURRENT)).\n            setMaxFieldLength(IndexWriterConfig.UNLIMITED_FIELD_LENGTH)\n    );\n    for (int i = 0; i < ALT_DOCS.length; i++) {\n      Document doc = new Document();\n      doc.add(new Field(\"title\", ALT_DOCS[i], Field.Store.YES, Field.Index.ANALYZED));\n      iw.addDocument(doc);\n    }\n    iw.optimize();\n    iw.close();\n    indexDir.mkdirs();\n    spellchecker.add(AbstractLuceneSpellChecker.INDEX_DIR, indexDir.getAbsolutePath());\n    spellchecker.add(AbstractLuceneSpellChecker.LOCATION, altIndexDir.getAbsolutePath());\n    spellchecker.add(IndexBasedSpellChecker.FIELD, \"title\");\n    spellchecker.add(AbstractLuceneSpellChecker.SPELLCHECKER_ARG_NAME, spellchecker);\n    SolrCore core = h.getCore();\n    String dictName = checker.init(spellchecker, core);\n    assertTrue(dictName + \" is not equal to \" + SolrSpellChecker.DEFAULT_DICTIONARY_NAME,\n            dictName.equals(SolrSpellChecker.DEFAULT_DICTIONARY_NAME) == true);\n    RefCounted<SolrIndexSearcher> holder = core.getSearcher();\n    SolrIndexSearcher searcher = holder.get();\n    try {\n    checker.build(core, searcher);\n\n    IndexReader reader = searcher.getReader();\n    Collection<Token> tokens = queryConverter.convert(\"flesh\");\n    SpellingOptions spellOpts = new SpellingOptions(tokens, reader, 1, false, true, 0.5f, null);\n    SpellingResult result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    //should be lowercased, b/c we are using a lowercasing analyzer\n    Map<String, Integer> suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"flesh is null and it shouldn't be\", suggestions != null);\n    assertTrue(\"flesh Size: \" + suggestions.size() + \" is not: \" + 1, suggestions.size() == 1);\n    Map.Entry<String, Integer> entry = suggestions.entrySet().iterator().next();\n    assertTrue(entry.getKey() + \" is not equal to \" + \"flash\", entry.getKey().equals(\"flash\") == true);\n    assertTrue(entry.getValue() + \" does not equal: \" + 1, entry.getValue() == 1);\n\n    //test something not in the spell checker\n    spellOpts.tokens = queryConverter.convert(\"super\");\n    result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"suggestions is not null and it should be\", suggestions == null);\n\n    spellOpts.tokens = queryConverter.convert(\"Caroline\");\n    result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"suggestions is not null and it should be\", suggestions == null);\n    } finally {\n      holder.decref();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ab5cb6a74aefb78aa0569857970b9151dfe2e787","date":1292842407,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"solr/src/test/org/apache/solr/spelling/IndexBasedSpellCheckerTest#testAlternateLocation().mjava","pathOld":"solr/src/test/org/apache/solr/spelling/IndexBasedSpellCheckerTest#testAlternateLocation().mjava","sourceNew":"  @Test\n  public void testAlternateLocation() throws Exception {\n    String[] ALT_DOCS = new String[]{\n            \"jumpin jack flash\",\n            \"Sargent Peppers Lonely Hearts Club Band\",\n            \"Born to Run\",\n            \"Thunder Road\",\n            \"Londons Burning\",\n            \"A Horse with No Name\",\n            \"Sweet Caroline\"\n    };\n\n    IndexBasedSpellChecker checker = new IndexBasedSpellChecker();\n    NamedList spellchecker = new NamedList();\n    spellchecker.add(\"classname\", IndexBasedSpellChecker.class.getName());\n\n    File indexDir = new File(TEMP_DIR, \"spellingIdx\" + new Date().getTime());\n    //create a standalone index\n    File altIndexDir = new File(TEMP_DIR, \"alternateIdx\" + new Date().getTime());\n    Directory dir = newFSDirectory(altIndexDir);\n    IndexWriter iw = new IndexWriter(\n        dir,\n        new IndexWriterConfig(TEST_VERSION_CURRENT, new WhitespaceAnalyzer(TEST_VERSION_CURRENT)).\n            setMaxFieldLength(IndexWriterConfig.UNLIMITED_FIELD_LENGTH)\n    );\n    for (int i = 0; i < ALT_DOCS.length; i++) {\n      Document doc = new Document();\n      doc.add(new Field(\"title\", ALT_DOCS[i], Field.Store.YES, Field.Index.ANALYZED));\n      iw.addDocument(doc);\n    }\n    iw.optimize();\n    iw.close();\n    dir.close();\n    indexDir.mkdirs();\n    spellchecker.add(AbstractLuceneSpellChecker.INDEX_DIR, indexDir.getAbsolutePath());\n    spellchecker.add(AbstractLuceneSpellChecker.LOCATION, altIndexDir.getAbsolutePath());\n    spellchecker.add(IndexBasedSpellChecker.FIELD, \"title\");\n    spellchecker.add(AbstractLuceneSpellChecker.SPELLCHECKER_ARG_NAME, spellchecker);\n    SolrCore core = h.getCore();\n    String dictName = checker.init(spellchecker, core);\n    assertTrue(dictName + \" is not equal to \" + SolrSpellChecker.DEFAULT_DICTIONARY_NAME,\n            dictName.equals(SolrSpellChecker.DEFAULT_DICTIONARY_NAME) == true);\n    RefCounted<SolrIndexSearcher> holder = core.getSearcher();\n    SolrIndexSearcher searcher = holder.get();\n    try {\n    checker.build(core, searcher);\n\n    IndexReader reader = searcher.getReader();\n    Collection<Token> tokens = queryConverter.convert(\"flesh\");\n    SpellingOptions spellOpts = new SpellingOptions(tokens, reader, 1, false, true, 0.5f, null);\n    SpellingResult result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    //should be lowercased, b/c we are using a lowercasing analyzer\n    Map<String, Integer> suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"flesh is null and it shouldn't be\", suggestions != null);\n    assertTrue(\"flesh Size: \" + suggestions.size() + \" is not: \" + 1, suggestions.size() == 1);\n    Map.Entry<String, Integer> entry = suggestions.entrySet().iterator().next();\n    assertTrue(entry.getKey() + \" is not equal to \" + \"flash\", entry.getKey().equals(\"flash\") == true);\n    assertTrue(entry.getValue() + \" does not equal: \" + 1, entry.getValue() == 1);\n\n    //test something not in the spell checker\n    spellOpts.tokens = queryConverter.convert(\"super\");\n    result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"suggestions is not null and it should be\", suggestions == null);\n\n    spellOpts.tokens = queryConverter.convert(\"Caroline\");\n    result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"suggestions is not null and it should be\", suggestions == null);\n    } finally {\n      holder.decref();\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testAlternateLocation() throws Exception {\n    String[] ALT_DOCS = new String[]{\n            \"jumpin jack flash\",\n            \"Sargent Peppers Lonely Hearts Club Band\",\n            \"Born to Run\",\n            \"Thunder Road\",\n            \"Londons Burning\",\n            \"A Horse with No Name\",\n            \"Sweet Caroline\"\n    };\n\n    IndexBasedSpellChecker checker = new IndexBasedSpellChecker();\n    NamedList spellchecker = new NamedList();\n    spellchecker.add(\"classname\", IndexBasedSpellChecker.class.getName());\n\n    File indexDir = new File(TEMP_DIR, \"spellingIdx\" + new Date().getTime());\n    //create a standalone index\n    File altIndexDir = new File(TEMP_DIR, \"alternateIdx\" + new Date().getTime());\n    IndexWriter iw = new IndexWriter(\n        FSDirectory.open(altIndexDir),\n        new IndexWriterConfig(TEST_VERSION_CURRENT, new WhitespaceAnalyzer(TEST_VERSION_CURRENT)).\n            setMaxFieldLength(IndexWriterConfig.UNLIMITED_FIELD_LENGTH)\n    );\n    for (int i = 0; i < ALT_DOCS.length; i++) {\n      Document doc = new Document();\n      doc.add(new Field(\"title\", ALT_DOCS[i], Field.Store.YES, Field.Index.ANALYZED));\n      iw.addDocument(doc);\n    }\n    iw.optimize();\n    iw.close();\n    indexDir.mkdirs();\n    spellchecker.add(AbstractLuceneSpellChecker.INDEX_DIR, indexDir.getAbsolutePath());\n    spellchecker.add(AbstractLuceneSpellChecker.LOCATION, altIndexDir.getAbsolutePath());\n    spellchecker.add(IndexBasedSpellChecker.FIELD, \"title\");\n    spellchecker.add(AbstractLuceneSpellChecker.SPELLCHECKER_ARG_NAME, spellchecker);\n    SolrCore core = h.getCore();\n    String dictName = checker.init(spellchecker, core);\n    assertTrue(dictName + \" is not equal to \" + SolrSpellChecker.DEFAULT_DICTIONARY_NAME,\n            dictName.equals(SolrSpellChecker.DEFAULT_DICTIONARY_NAME) == true);\n    RefCounted<SolrIndexSearcher> holder = core.getSearcher();\n    SolrIndexSearcher searcher = holder.get();\n    try {\n    checker.build(core, searcher);\n\n    IndexReader reader = searcher.getReader();\n    Collection<Token> tokens = queryConverter.convert(\"flesh\");\n    SpellingOptions spellOpts = new SpellingOptions(tokens, reader, 1, false, true, 0.5f, null);\n    SpellingResult result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    //should be lowercased, b/c we are using a lowercasing analyzer\n    Map<String, Integer> suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"flesh is null and it shouldn't be\", suggestions != null);\n    assertTrue(\"flesh Size: \" + suggestions.size() + \" is not: \" + 1, suggestions.size() == 1);\n    Map.Entry<String, Integer> entry = suggestions.entrySet().iterator().next();\n    assertTrue(entry.getKey() + \" is not equal to \" + \"flash\", entry.getKey().equals(\"flash\") == true);\n    assertTrue(entry.getValue() + \" does not equal: \" + 1, entry.getValue() == 1);\n\n    //test something not in the spell checker\n    spellOpts.tokens = queryConverter.convert(\"super\");\n    result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"suggestions is not null and it should be\", suggestions == null);\n\n    spellOpts.tokens = queryConverter.convert(\"Caroline\");\n    result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"suggestions is not null and it should be\", suggestions == null);\n    } finally {\n      holder.decref();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","date":1292920096,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"solr/src/test/org/apache/solr/spelling/IndexBasedSpellCheckerTest#testAlternateLocation().mjava","pathOld":"solr/src/test/org/apache/solr/spelling/IndexBasedSpellCheckerTest#testAlternateLocation().mjava","sourceNew":"  @Test\n  public void testAlternateLocation() throws Exception {\n    String[] ALT_DOCS = new String[]{\n            \"jumpin jack flash\",\n            \"Sargent Peppers Lonely Hearts Club Band\",\n            \"Born to Run\",\n            \"Thunder Road\",\n            \"Londons Burning\",\n            \"A Horse with No Name\",\n            \"Sweet Caroline\"\n    };\n\n    IndexBasedSpellChecker checker = new IndexBasedSpellChecker();\n    NamedList spellchecker = new NamedList();\n    spellchecker.add(\"classname\", IndexBasedSpellChecker.class.getName());\n\n    File indexDir = new File(TEMP_DIR, \"spellingIdx\" + new Date().getTime());\n    //create a standalone index\n    File altIndexDir = new File(TEMP_DIR, \"alternateIdx\" + new Date().getTime());\n    Directory dir = newFSDirectory(altIndexDir);\n    IndexWriter iw = new IndexWriter(\n        dir,\n        new IndexWriterConfig(TEST_VERSION_CURRENT, new WhitespaceAnalyzer(TEST_VERSION_CURRENT)).\n            setMaxFieldLength(IndexWriterConfig.UNLIMITED_FIELD_LENGTH)\n    );\n    for (int i = 0; i < ALT_DOCS.length; i++) {\n      Document doc = new Document();\n      doc.add(new Field(\"title\", ALT_DOCS[i], Field.Store.YES, Field.Index.ANALYZED));\n      iw.addDocument(doc);\n    }\n    iw.optimize();\n    iw.close();\n    dir.close();\n    indexDir.mkdirs();\n    spellchecker.add(AbstractLuceneSpellChecker.INDEX_DIR, indexDir.getAbsolutePath());\n    spellchecker.add(AbstractLuceneSpellChecker.LOCATION, altIndexDir.getAbsolutePath());\n    spellchecker.add(IndexBasedSpellChecker.FIELD, \"title\");\n    spellchecker.add(AbstractLuceneSpellChecker.SPELLCHECKER_ARG_NAME, spellchecker);\n    SolrCore core = h.getCore();\n    String dictName = checker.init(spellchecker, core);\n    assertTrue(dictName + \" is not equal to \" + SolrSpellChecker.DEFAULT_DICTIONARY_NAME,\n            dictName.equals(SolrSpellChecker.DEFAULT_DICTIONARY_NAME) == true);\n    RefCounted<SolrIndexSearcher> holder = core.getSearcher();\n    SolrIndexSearcher searcher = holder.get();\n    try {\n    checker.build(core, searcher);\n\n    IndexReader reader = searcher.getReader();\n    Collection<Token> tokens = queryConverter.convert(\"flesh\");\n    SpellingOptions spellOpts = new SpellingOptions(tokens, reader, 1, false, true, 0.5f, null);\n    SpellingResult result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    //should be lowercased, b/c we are using a lowercasing analyzer\n    Map<String, Integer> suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"flesh is null and it shouldn't be\", suggestions != null);\n    assertTrue(\"flesh Size: \" + suggestions.size() + \" is not: \" + 1, suggestions.size() == 1);\n    Map.Entry<String, Integer> entry = suggestions.entrySet().iterator().next();\n    assertTrue(entry.getKey() + \" is not equal to \" + \"flash\", entry.getKey().equals(\"flash\") == true);\n    assertTrue(entry.getValue() + \" does not equal: \" + 1, entry.getValue() == 1);\n\n    //test something not in the spell checker\n    spellOpts.tokens = queryConverter.convert(\"super\");\n    result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"suggestions is not null and it should be\", suggestions == null);\n\n    spellOpts.tokens = queryConverter.convert(\"Caroline\");\n    result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"suggestions is not null and it should be\", suggestions == null);\n    } finally {\n      holder.decref();\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testAlternateLocation() throws Exception {\n    String[] ALT_DOCS = new String[]{\n            \"jumpin jack flash\",\n            \"Sargent Peppers Lonely Hearts Club Band\",\n            \"Born to Run\",\n            \"Thunder Road\",\n            \"Londons Burning\",\n            \"A Horse with No Name\",\n            \"Sweet Caroline\"\n    };\n\n    IndexBasedSpellChecker checker = new IndexBasedSpellChecker();\n    NamedList spellchecker = new NamedList();\n    spellchecker.add(\"classname\", IndexBasedSpellChecker.class.getName());\n\n    File tmpDir = new File(System.getProperty(\"java.io.tmpdir\"));\n    File indexDir = new File(tmpDir, \"spellingIdx\" + new Date().getTime());\n    //create a standalone index\n    File altIndexDir = new File(tmpDir, \"alternateIdx\" + new Date().getTime());\n    IndexWriter iw = new IndexWriter(FSDirectory.open(altIndexDir), new WhitespaceAnalyzer(), IndexWriter.MaxFieldLength.LIMITED);\n    for (int i = 0; i < ALT_DOCS.length; i++) {\n      Document doc = new Document();\n      doc.add(new Field(\"title\", ALT_DOCS[i], Field.Store.YES, Field.Index.ANALYZED));\n      iw.addDocument(doc);\n    }\n    iw.optimize();\n    iw.close();\n    indexDir.mkdirs();\n    spellchecker.add(AbstractLuceneSpellChecker.INDEX_DIR, indexDir.getAbsolutePath());\n    spellchecker.add(AbstractLuceneSpellChecker.LOCATION, altIndexDir.getAbsolutePath());\n    spellchecker.add(IndexBasedSpellChecker.FIELD, \"title\");\n    spellchecker.add(AbstractLuceneSpellChecker.SPELLCHECKER_ARG_NAME, spellchecker);\n    SolrCore core = h.getCore();\n    String dictName = checker.init(spellchecker, core);\n    assertTrue(dictName + \" is not equal to \" + SolrSpellChecker.DEFAULT_DICTIONARY_NAME,\n            dictName.equals(SolrSpellChecker.DEFAULT_DICTIONARY_NAME) == true);\n    RefCounted<SolrIndexSearcher> holder = core.getSearcher();\n    SolrIndexSearcher searcher = holder.get();\n    try {\n    checker.build(core, searcher);\n\n    IndexReader reader = searcher.getReader();\n    Collection<Token> tokens = queryConverter.convert(\"flesh\");\n    SpellingResult result = checker.getSuggestions(tokens, reader, 1, false, true);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    //should be lowercased, b/c we are using a lowercasing analyzer\n    Map<String, Integer> suggestions = result.get(tokens.iterator().next());\n    assertTrue(\"flesh is null and it shouldn't be\", suggestions != null);\n    assertTrue(\"flesh Size: \" + suggestions.size() + \" is not: \" + 1, suggestions.size() == 1);\n    Map.Entry<String, Integer> entry = suggestions.entrySet().iterator().next();\n    assertTrue(entry.getKey() + \" is not equal to \" + \"flash\", entry.getKey().equals(\"flash\") == true);\n    assertTrue(entry.getValue() + \" does not equal: \" + 1, entry.getValue() == 1);\n\n    //test something not in the spell checker\n    tokens = queryConverter.convert(\"super\");\n    result = checker.getSuggestions(tokens, reader, 1, false, true);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    suggestions = result.get(tokens.iterator().next());\n    assertTrue(\"suggestions is not null and it should be\", suggestions == null);\n\n    tokens = queryConverter.convert(\"Caroline\");\n    result = checker.getSuggestions(tokens, reader, 1, false, true);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    suggestions = result.get(tokens.iterator().next());\n    assertTrue(\"suggestions is not null and it should be\", suggestions == null);\n    } finally {\n      holder.decref();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c220849f876de24a79f756f65b3eb045db59f63f","date":1294902803,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"solr/src/test/org/apache/solr/spelling/IndexBasedSpellCheckerTest#testAlternateLocation().mjava","pathOld":"solr/src/test/org/apache/solr/spelling/IndexBasedSpellCheckerTest#testAlternateLocation().mjava","sourceNew":"  @Test\n  public void testAlternateLocation() throws Exception {\n    String[] ALT_DOCS = new String[]{\n            \"jumpin jack flash\",\n            \"Sargent Peppers Lonely Hearts Club Band\",\n            \"Born to Run\",\n            \"Thunder Road\",\n            \"Londons Burning\",\n            \"A Horse with No Name\",\n            \"Sweet Caroline\"\n    };\n\n    IndexBasedSpellChecker checker = new IndexBasedSpellChecker();\n    NamedList spellchecker = new NamedList();\n    spellchecker.add(\"classname\", IndexBasedSpellChecker.class.getName());\n\n    File indexDir = new File(TEMP_DIR, \"spellingIdx\" + new Date().getTime());\n    //create a standalone index\n    File altIndexDir = new File(TEMP_DIR, \"alternateIdx\" + new Date().getTime());\n    Directory dir = newFSDirectory(altIndexDir);\n    IndexWriter iw = new IndexWriter(\n        dir,\n        new IndexWriterConfig(TEST_VERSION_CURRENT, new WhitespaceAnalyzer(TEST_VERSION_CURRENT)).\n            setMaxFieldLength(IndexWriterConfig.UNLIMITED_FIELD_LENGTH)\n    );\n    for (int i = 0; i < ALT_DOCS.length; i++) {\n      Document doc = new Document();\n      doc.add(new Field(\"title\", ALT_DOCS[i], Field.Store.YES, Field.Index.ANALYZED));\n      iw.addDocument(doc);\n    }\n    iw.optimize();\n    iw.close();\n    dir.close();\n    indexDir.mkdirs();\n    spellchecker.add(AbstractLuceneSpellChecker.INDEX_DIR, indexDir.getAbsolutePath());\n    spellchecker.add(AbstractLuceneSpellChecker.LOCATION, altIndexDir.getAbsolutePath());\n    spellchecker.add(IndexBasedSpellChecker.FIELD, \"title\");\n    spellchecker.add(AbstractLuceneSpellChecker.SPELLCHECKER_ARG_NAME, spellchecker);\n    SolrCore core = h.getCore();\n    String dictName = checker.init(spellchecker, core);\n    assertTrue(dictName + \" is not equal to \" + SolrSpellChecker.DEFAULT_DICTIONARY_NAME,\n            dictName.equals(SolrSpellChecker.DEFAULT_DICTIONARY_NAME) == true);\n    RefCounted<SolrIndexSearcher> holder = core.getSearcher();\n    SolrIndexSearcher searcher = holder.get();\n    try {\n    checker.build(core, searcher);\n\n    IndexReader reader = searcher.getIndexReader();\n    Collection<Token> tokens = queryConverter.convert(\"flesh\");\n    SpellingOptions spellOpts = new SpellingOptions(tokens, reader, 1, false, true, 0.5f, null);\n    SpellingResult result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    //should be lowercased, b/c we are using a lowercasing analyzer\n    Map<String, Integer> suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"flesh is null and it shouldn't be\", suggestions != null);\n    assertTrue(\"flesh Size: \" + suggestions.size() + \" is not: \" + 1, suggestions.size() == 1);\n    Map.Entry<String, Integer> entry = suggestions.entrySet().iterator().next();\n    assertTrue(entry.getKey() + \" is not equal to \" + \"flash\", entry.getKey().equals(\"flash\") == true);\n    assertTrue(entry.getValue() + \" does not equal: \" + 1, entry.getValue() == 1);\n\n    //test something not in the spell checker\n    spellOpts.tokens = queryConverter.convert(\"super\");\n    result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"suggestions is not null and it should be\", suggestions == null);\n\n    spellOpts.tokens = queryConverter.convert(\"Caroline\");\n    result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"suggestions is not null and it should be\", suggestions == null);\n    } finally {\n      holder.decref();\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testAlternateLocation() throws Exception {\n    String[] ALT_DOCS = new String[]{\n            \"jumpin jack flash\",\n            \"Sargent Peppers Lonely Hearts Club Band\",\n            \"Born to Run\",\n            \"Thunder Road\",\n            \"Londons Burning\",\n            \"A Horse with No Name\",\n            \"Sweet Caroline\"\n    };\n\n    IndexBasedSpellChecker checker = new IndexBasedSpellChecker();\n    NamedList spellchecker = new NamedList();\n    spellchecker.add(\"classname\", IndexBasedSpellChecker.class.getName());\n\n    File indexDir = new File(TEMP_DIR, \"spellingIdx\" + new Date().getTime());\n    //create a standalone index\n    File altIndexDir = new File(TEMP_DIR, \"alternateIdx\" + new Date().getTime());\n    Directory dir = newFSDirectory(altIndexDir);\n    IndexWriter iw = new IndexWriter(\n        dir,\n        new IndexWriterConfig(TEST_VERSION_CURRENT, new WhitespaceAnalyzer(TEST_VERSION_CURRENT)).\n            setMaxFieldLength(IndexWriterConfig.UNLIMITED_FIELD_LENGTH)\n    );\n    for (int i = 0; i < ALT_DOCS.length; i++) {\n      Document doc = new Document();\n      doc.add(new Field(\"title\", ALT_DOCS[i], Field.Store.YES, Field.Index.ANALYZED));\n      iw.addDocument(doc);\n    }\n    iw.optimize();\n    iw.close();\n    dir.close();\n    indexDir.mkdirs();\n    spellchecker.add(AbstractLuceneSpellChecker.INDEX_DIR, indexDir.getAbsolutePath());\n    spellchecker.add(AbstractLuceneSpellChecker.LOCATION, altIndexDir.getAbsolutePath());\n    spellchecker.add(IndexBasedSpellChecker.FIELD, \"title\");\n    spellchecker.add(AbstractLuceneSpellChecker.SPELLCHECKER_ARG_NAME, spellchecker);\n    SolrCore core = h.getCore();\n    String dictName = checker.init(spellchecker, core);\n    assertTrue(dictName + \" is not equal to \" + SolrSpellChecker.DEFAULT_DICTIONARY_NAME,\n            dictName.equals(SolrSpellChecker.DEFAULT_DICTIONARY_NAME) == true);\n    RefCounted<SolrIndexSearcher> holder = core.getSearcher();\n    SolrIndexSearcher searcher = holder.get();\n    try {\n    checker.build(core, searcher);\n\n    IndexReader reader = searcher.getReader();\n    Collection<Token> tokens = queryConverter.convert(\"flesh\");\n    SpellingOptions spellOpts = new SpellingOptions(tokens, reader, 1, false, true, 0.5f, null);\n    SpellingResult result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    //should be lowercased, b/c we are using a lowercasing analyzer\n    Map<String, Integer> suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"flesh is null and it shouldn't be\", suggestions != null);\n    assertTrue(\"flesh Size: \" + suggestions.size() + \" is not: \" + 1, suggestions.size() == 1);\n    Map.Entry<String, Integer> entry = suggestions.entrySet().iterator().next();\n    assertTrue(entry.getKey() + \" is not equal to \" + \"flash\", entry.getKey().equals(\"flash\") == true);\n    assertTrue(entry.getValue() + \" does not equal: \" + 1, entry.getValue() == 1);\n\n    //test something not in the spell checker\n    spellOpts.tokens = queryConverter.convert(\"super\");\n    result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"suggestions is not null and it should be\", suggestions == null);\n\n    spellOpts.tokens = queryConverter.convert(\"Caroline\");\n    result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"suggestions is not null and it should be\", suggestions == null);\n    } finally {\n      holder.decref();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"868da859b43505d9d2a023bfeae6dd0c795f5295","date":1294948401,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"solr/src/test/org/apache/solr/spelling/IndexBasedSpellCheckerTest#testAlternateLocation().mjava","pathOld":"solr/src/test/org/apache/solr/spelling/IndexBasedSpellCheckerTest#testAlternateLocation().mjava","sourceNew":"  @Test\n  public void testAlternateLocation() throws Exception {\n    String[] ALT_DOCS = new String[]{\n            \"jumpin jack flash\",\n            \"Sargent Peppers Lonely Hearts Club Band\",\n            \"Born to Run\",\n            \"Thunder Road\",\n            \"Londons Burning\",\n            \"A Horse with No Name\",\n            \"Sweet Caroline\"\n    };\n\n    IndexBasedSpellChecker checker = new IndexBasedSpellChecker();\n    NamedList spellchecker = new NamedList();\n    spellchecker.add(\"classname\", IndexBasedSpellChecker.class.getName());\n\n    File indexDir = new File(TEMP_DIR, \"spellingIdx\" + new Date().getTime());\n    //create a standalone index\n    File altIndexDir = new File(TEMP_DIR, \"alternateIdx\" + new Date().getTime());\n    Directory dir = newFSDirectory(altIndexDir);\n    IndexWriter iw = new IndexWriter(\n        dir,\n        new IndexWriterConfig(TEST_VERSION_CURRENT, new WhitespaceAnalyzer(TEST_VERSION_CURRENT)).\n            setMaxFieldLength(IndexWriterConfig.UNLIMITED_FIELD_LENGTH)\n    );\n    for (int i = 0; i < ALT_DOCS.length; i++) {\n      Document doc = new Document();\n      doc.add(new Field(\"title\", ALT_DOCS[i], Field.Store.YES, Field.Index.ANALYZED));\n      iw.addDocument(doc);\n    }\n    iw.optimize();\n    iw.close();\n    dir.close();\n    indexDir.mkdirs();\n    spellchecker.add(AbstractLuceneSpellChecker.INDEX_DIR, indexDir.getAbsolutePath());\n    spellchecker.add(AbstractLuceneSpellChecker.LOCATION, altIndexDir.getAbsolutePath());\n    spellchecker.add(IndexBasedSpellChecker.FIELD, \"title\");\n    spellchecker.add(AbstractLuceneSpellChecker.SPELLCHECKER_ARG_NAME, spellchecker);\n    SolrCore core = h.getCore();\n    String dictName = checker.init(spellchecker, core);\n    assertTrue(dictName + \" is not equal to \" + SolrSpellChecker.DEFAULT_DICTIONARY_NAME,\n            dictName.equals(SolrSpellChecker.DEFAULT_DICTIONARY_NAME) == true);\n    RefCounted<SolrIndexSearcher> holder = core.getSearcher();\n    SolrIndexSearcher searcher = holder.get();\n    try {\n    checker.build(core, searcher);\n\n    IndexReader reader = searcher.getIndexReader();\n    Collection<Token> tokens = queryConverter.convert(\"flesh\");\n    SpellingOptions spellOpts = new SpellingOptions(tokens, reader, 1, false, true, 0.5f, null);\n    SpellingResult result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    //should be lowercased, b/c we are using a lowercasing analyzer\n    Map<String, Integer> suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"flesh is null and it shouldn't be\", suggestions != null);\n    assertTrue(\"flesh Size: \" + suggestions.size() + \" is not: \" + 1, suggestions.size() == 1);\n    Map.Entry<String, Integer> entry = suggestions.entrySet().iterator().next();\n    assertTrue(entry.getKey() + \" is not equal to \" + \"flash\", entry.getKey().equals(\"flash\") == true);\n    assertTrue(entry.getValue() + \" does not equal: \" + 1, entry.getValue() == 1);\n\n    //test something not in the spell checker\n    spellOpts.tokens = queryConverter.convert(\"super\");\n    result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"suggestions is not null and it should be\", suggestions == null);\n\n    spellOpts.tokens = queryConverter.convert(\"Caroline\");\n    result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"suggestions is not null and it should be\", suggestions == null);\n    } finally {\n      holder.decref();\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testAlternateLocation() throws Exception {\n    String[] ALT_DOCS = new String[]{\n            \"jumpin jack flash\",\n            \"Sargent Peppers Lonely Hearts Club Band\",\n            \"Born to Run\",\n            \"Thunder Road\",\n            \"Londons Burning\",\n            \"A Horse with No Name\",\n            \"Sweet Caroline\"\n    };\n\n    IndexBasedSpellChecker checker = new IndexBasedSpellChecker();\n    NamedList spellchecker = new NamedList();\n    spellchecker.add(\"classname\", IndexBasedSpellChecker.class.getName());\n\n    File indexDir = new File(TEMP_DIR, \"spellingIdx\" + new Date().getTime());\n    //create a standalone index\n    File altIndexDir = new File(TEMP_DIR, \"alternateIdx\" + new Date().getTime());\n    Directory dir = newFSDirectory(altIndexDir);\n    IndexWriter iw = new IndexWriter(\n        dir,\n        new IndexWriterConfig(TEST_VERSION_CURRENT, new WhitespaceAnalyzer(TEST_VERSION_CURRENT)).\n            setMaxFieldLength(IndexWriterConfig.UNLIMITED_FIELD_LENGTH)\n    );\n    for (int i = 0; i < ALT_DOCS.length; i++) {\n      Document doc = new Document();\n      doc.add(new Field(\"title\", ALT_DOCS[i], Field.Store.YES, Field.Index.ANALYZED));\n      iw.addDocument(doc);\n    }\n    iw.optimize();\n    iw.close();\n    dir.close();\n    indexDir.mkdirs();\n    spellchecker.add(AbstractLuceneSpellChecker.INDEX_DIR, indexDir.getAbsolutePath());\n    spellchecker.add(AbstractLuceneSpellChecker.LOCATION, altIndexDir.getAbsolutePath());\n    spellchecker.add(IndexBasedSpellChecker.FIELD, \"title\");\n    spellchecker.add(AbstractLuceneSpellChecker.SPELLCHECKER_ARG_NAME, spellchecker);\n    SolrCore core = h.getCore();\n    String dictName = checker.init(spellchecker, core);\n    assertTrue(dictName + \" is not equal to \" + SolrSpellChecker.DEFAULT_DICTIONARY_NAME,\n            dictName.equals(SolrSpellChecker.DEFAULT_DICTIONARY_NAME) == true);\n    RefCounted<SolrIndexSearcher> holder = core.getSearcher();\n    SolrIndexSearcher searcher = holder.get();\n    try {\n    checker.build(core, searcher);\n\n    IndexReader reader = searcher.getReader();\n    Collection<Token> tokens = queryConverter.convert(\"flesh\");\n    SpellingOptions spellOpts = new SpellingOptions(tokens, reader, 1, false, true, 0.5f, null);\n    SpellingResult result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    //should be lowercased, b/c we are using a lowercasing analyzer\n    Map<String, Integer> suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"flesh is null and it shouldn't be\", suggestions != null);\n    assertTrue(\"flesh Size: \" + suggestions.size() + \" is not: \" + 1, suggestions.size() == 1);\n    Map.Entry<String, Integer> entry = suggestions.entrySet().iterator().next();\n    assertTrue(entry.getKey() + \" is not equal to \" + \"flash\", entry.getKey().equals(\"flash\") == true);\n    assertTrue(entry.getValue() + \" does not equal: \" + 1, entry.getValue() == 1);\n\n    //test something not in the spell checker\n    spellOpts.tokens = queryConverter.convert(\"super\");\n    result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"suggestions is not null and it should be\", suggestions == null);\n\n    spellOpts.tokens = queryConverter.convert(\"Caroline\");\n    result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"suggestions is not null and it should be\", suggestions == null);\n    } finally {\n      holder.decref();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c2047784e704fe141e0ff36affac8a7cb6c7bbec","date":1295352100,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"solr/src/test/org/apache/solr/spelling/IndexBasedSpellCheckerTest#testAlternateLocation().mjava","pathOld":"solr/src/test/org/apache/solr/spelling/IndexBasedSpellCheckerTest#testAlternateLocation().mjava","sourceNew":"  @Test\n  public void testAlternateLocation() throws Exception {\n    String[] ALT_DOCS = new String[]{\n            \"jumpin jack flash\",\n            \"Sargent Peppers Lonely Hearts Club Band\",\n            \"Born to Run\",\n            \"Thunder Road\",\n            \"Londons Burning\",\n            \"A Horse with No Name\",\n            \"Sweet Caroline\"\n    };\n\n    IndexBasedSpellChecker checker = new IndexBasedSpellChecker();\n    NamedList spellchecker = new NamedList();\n    spellchecker.add(\"classname\", IndexBasedSpellChecker.class.getName());\n\n    File indexDir = new File(TEMP_DIR, \"spellingIdx\" + new Date().getTime());\n    //create a standalone index\n    File altIndexDir = new File(TEMP_DIR, \"alternateIdx\" + new Date().getTime());\n    Directory dir = newFSDirectory(altIndexDir);\n    IndexWriter iw = new IndexWriter(\n        dir,\n        new IndexWriterConfig(TEST_VERSION_CURRENT, new WhitespaceAnalyzer(TEST_VERSION_CURRENT))\n    );\n    for (int i = 0; i < ALT_DOCS.length; i++) {\n      Document doc = new Document();\n      doc.add(new Field(\"title\", ALT_DOCS[i], Field.Store.YES, Field.Index.ANALYZED));\n      iw.addDocument(doc);\n    }\n    iw.optimize();\n    iw.close();\n    dir.close();\n    indexDir.mkdirs();\n    spellchecker.add(AbstractLuceneSpellChecker.INDEX_DIR, indexDir.getAbsolutePath());\n    spellchecker.add(AbstractLuceneSpellChecker.LOCATION, altIndexDir.getAbsolutePath());\n    spellchecker.add(IndexBasedSpellChecker.FIELD, \"title\");\n    spellchecker.add(AbstractLuceneSpellChecker.SPELLCHECKER_ARG_NAME, spellchecker);\n    SolrCore core = h.getCore();\n    String dictName = checker.init(spellchecker, core);\n    assertTrue(dictName + \" is not equal to \" + SolrSpellChecker.DEFAULT_DICTIONARY_NAME,\n            dictName.equals(SolrSpellChecker.DEFAULT_DICTIONARY_NAME) == true);\n    RefCounted<SolrIndexSearcher> holder = core.getSearcher();\n    SolrIndexSearcher searcher = holder.get();\n    try {\n    checker.build(core, searcher);\n\n    IndexReader reader = searcher.getIndexReader();\n    Collection<Token> tokens = queryConverter.convert(\"flesh\");\n    SpellingOptions spellOpts = new SpellingOptions(tokens, reader, 1, false, true, 0.5f, null);\n    SpellingResult result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    //should be lowercased, b/c we are using a lowercasing analyzer\n    Map<String, Integer> suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"flesh is null and it shouldn't be\", suggestions != null);\n    assertTrue(\"flesh Size: \" + suggestions.size() + \" is not: \" + 1, suggestions.size() == 1);\n    Map.Entry<String, Integer> entry = suggestions.entrySet().iterator().next();\n    assertTrue(entry.getKey() + \" is not equal to \" + \"flash\", entry.getKey().equals(\"flash\") == true);\n    assertTrue(entry.getValue() + \" does not equal: \" + 1, entry.getValue() == 1);\n\n    //test something not in the spell checker\n    spellOpts.tokens = queryConverter.convert(\"super\");\n    result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"suggestions is not null and it should be\", suggestions == null);\n\n    spellOpts.tokens = queryConverter.convert(\"Caroline\");\n    result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"suggestions is not null and it should be\", suggestions == null);\n    } finally {\n      holder.decref();\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testAlternateLocation() throws Exception {\n    String[] ALT_DOCS = new String[]{\n            \"jumpin jack flash\",\n            \"Sargent Peppers Lonely Hearts Club Band\",\n            \"Born to Run\",\n            \"Thunder Road\",\n            \"Londons Burning\",\n            \"A Horse with No Name\",\n            \"Sweet Caroline\"\n    };\n\n    IndexBasedSpellChecker checker = new IndexBasedSpellChecker();\n    NamedList spellchecker = new NamedList();\n    spellchecker.add(\"classname\", IndexBasedSpellChecker.class.getName());\n\n    File indexDir = new File(TEMP_DIR, \"spellingIdx\" + new Date().getTime());\n    //create a standalone index\n    File altIndexDir = new File(TEMP_DIR, \"alternateIdx\" + new Date().getTime());\n    Directory dir = newFSDirectory(altIndexDir);\n    IndexWriter iw = new IndexWriter(\n        dir,\n        new IndexWriterConfig(TEST_VERSION_CURRENT, new WhitespaceAnalyzer(TEST_VERSION_CURRENT)).\n            setMaxFieldLength(IndexWriterConfig.UNLIMITED_FIELD_LENGTH)\n    );\n    for (int i = 0; i < ALT_DOCS.length; i++) {\n      Document doc = new Document();\n      doc.add(new Field(\"title\", ALT_DOCS[i], Field.Store.YES, Field.Index.ANALYZED));\n      iw.addDocument(doc);\n    }\n    iw.optimize();\n    iw.close();\n    dir.close();\n    indexDir.mkdirs();\n    spellchecker.add(AbstractLuceneSpellChecker.INDEX_DIR, indexDir.getAbsolutePath());\n    spellchecker.add(AbstractLuceneSpellChecker.LOCATION, altIndexDir.getAbsolutePath());\n    spellchecker.add(IndexBasedSpellChecker.FIELD, \"title\");\n    spellchecker.add(AbstractLuceneSpellChecker.SPELLCHECKER_ARG_NAME, spellchecker);\n    SolrCore core = h.getCore();\n    String dictName = checker.init(spellchecker, core);\n    assertTrue(dictName + \" is not equal to \" + SolrSpellChecker.DEFAULT_DICTIONARY_NAME,\n            dictName.equals(SolrSpellChecker.DEFAULT_DICTIONARY_NAME) == true);\n    RefCounted<SolrIndexSearcher> holder = core.getSearcher();\n    SolrIndexSearcher searcher = holder.get();\n    try {\n    checker.build(core, searcher);\n\n    IndexReader reader = searcher.getIndexReader();\n    Collection<Token> tokens = queryConverter.convert(\"flesh\");\n    SpellingOptions spellOpts = new SpellingOptions(tokens, reader, 1, false, true, 0.5f, null);\n    SpellingResult result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    //should be lowercased, b/c we are using a lowercasing analyzer\n    Map<String, Integer> suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"flesh is null and it shouldn't be\", suggestions != null);\n    assertTrue(\"flesh Size: \" + suggestions.size() + \" is not: \" + 1, suggestions.size() == 1);\n    Map.Entry<String, Integer> entry = suggestions.entrySet().iterator().next();\n    assertTrue(entry.getKey() + \" is not equal to \" + \"flash\", entry.getKey().equals(\"flash\") == true);\n    assertTrue(entry.getValue() + \" does not equal: \" + 1, entry.getValue() == 1);\n\n    //test something not in the spell checker\n    spellOpts.tokens = queryConverter.convert(\"super\");\n    result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"suggestions is not null and it should be\", suggestions == null);\n\n    spellOpts.tokens = queryConverter.convert(\"Caroline\");\n    result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"suggestions is not null and it should be\", suggestions == null);\n    } finally {\n      holder.decref();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e79a6d080bdd5b2a8f56342cf571b5476de04180","date":1295638686,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"solr/src/test/org/apache/solr/spelling/IndexBasedSpellCheckerTest#testAlternateLocation().mjava","pathOld":"solr/src/test/org/apache/solr/spelling/IndexBasedSpellCheckerTest#testAlternateLocation().mjava","sourceNew":"  @Test\n  public void testAlternateLocation() throws Exception {\n    String[] ALT_DOCS = new String[]{\n            \"jumpin jack flash\",\n            \"Sargent Peppers Lonely Hearts Club Band\",\n            \"Born to Run\",\n            \"Thunder Road\",\n            \"Londons Burning\",\n            \"A Horse with No Name\",\n            \"Sweet Caroline\"\n    };\n\n    IndexBasedSpellChecker checker = new IndexBasedSpellChecker();\n    NamedList spellchecker = new NamedList();\n    spellchecker.add(\"classname\", IndexBasedSpellChecker.class.getName());\n\n    File indexDir = new File(TEMP_DIR, \"spellingIdx\" + new Date().getTime());\n    //create a standalone index\n    File altIndexDir = new File(TEMP_DIR, \"alternateIdx\" + new Date().getTime());\n    Directory dir = newFSDirectory(altIndexDir);\n    IndexWriter iw = new IndexWriter(\n        dir,\n        new IndexWriterConfig(TEST_VERSION_CURRENT, new WhitespaceAnalyzer(TEST_VERSION_CURRENT))\n    );\n    for (int i = 0; i < ALT_DOCS.length; i++) {\n      Document doc = new Document();\n      doc.add(new Field(\"title\", ALT_DOCS[i], Field.Store.YES, Field.Index.ANALYZED));\n      iw.addDocument(doc);\n    }\n    iw.optimize();\n    iw.close();\n    dir.close();\n    indexDir.mkdirs();\n    spellchecker.add(AbstractLuceneSpellChecker.INDEX_DIR, indexDir.getAbsolutePath());\n    spellchecker.add(AbstractLuceneSpellChecker.LOCATION, altIndexDir.getAbsolutePath());\n    spellchecker.add(IndexBasedSpellChecker.FIELD, \"title\");\n    spellchecker.add(AbstractLuceneSpellChecker.SPELLCHECKER_ARG_NAME, spellchecker);\n    SolrCore core = h.getCore();\n    String dictName = checker.init(spellchecker, core);\n    assertTrue(dictName + \" is not equal to \" + SolrSpellChecker.DEFAULT_DICTIONARY_NAME,\n            dictName.equals(SolrSpellChecker.DEFAULT_DICTIONARY_NAME) == true);\n    RefCounted<SolrIndexSearcher> holder = core.getSearcher();\n    SolrIndexSearcher searcher = holder.get();\n    try {\n    checker.build(core, searcher);\n\n    IndexReader reader = searcher.getIndexReader();\n    Collection<Token> tokens = queryConverter.convert(\"flesh\");\n    SpellingOptions spellOpts = new SpellingOptions(tokens, reader, 1, false, true, 0.5f, null);\n    SpellingResult result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    //should be lowercased, b/c we are using a lowercasing analyzer\n    Map<String, Integer> suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"flesh is null and it shouldn't be\", suggestions != null);\n    assertTrue(\"flesh Size: \" + suggestions.size() + \" is not: \" + 1, suggestions.size() == 1);\n    Map.Entry<String, Integer> entry = suggestions.entrySet().iterator().next();\n    assertTrue(entry.getKey() + \" is not equal to \" + \"flash\", entry.getKey().equals(\"flash\") == true);\n    assertTrue(entry.getValue() + \" does not equal: \" + 1, entry.getValue() == 1);\n\n    //test something not in the spell checker\n    spellOpts.tokens = queryConverter.convert(\"super\");\n    result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"suggestions is not null and it should be\", suggestions == null);\n\n    spellOpts.tokens = queryConverter.convert(\"Caroline\");\n    result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"suggestions is not null and it should be\", suggestions == null);\n    } finally {\n      holder.decref();\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testAlternateLocation() throws Exception {\n    String[] ALT_DOCS = new String[]{\n            \"jumpin jack flash\",\n            \"Sargent Peppers Lonely Hearts Club Band\",\n            \"Born to Run\",\n            \"Thunder Road\",\n            \"Londons Burning\",\n            \"A Horse with No Name\",\n            \"Sweet Caroline\"\n    };\n\n    IndexBasedSpellChecker checker = new IndexBasedSpellChecker();\n    NamedList spellchecker = new NamedList();\n    spellchecker.add(\"classname\", IndexBasedSpellChecker.class.getName());\n\n    File indexDir = new File(TEMP_DIR, \"spellingIdx\" + new Date().getTime());\n    //create a standalone index\n    File altIndexDir = new File(TEMP_DIR, \"alternateIdx\" + new Date().getTime());\n    Directory dir = newFSDirectory(altIndexDir);\n    IndexWriter iw = new IndexWriter(\n        dir,\n        new IndexWriterConfig(TEST_VERSION_CURRENT, new WhitespaceAnalyzer(TEST_VERSION_CURRENT)).\n            setMaxFieldLength(IndexWriterConfig.UNLIMITED_FIELD_LENGTH)\n    );\n    for (int i = 0; i < ALT_DOCS.length; i++) {\n      Document doc = new Document();\n      doc.add(new Field(\"title\", ALT_DOCS[i], Field.Store.YES, Field.Index.ANALYZED));\n      iw.addDocument(doc);\n    }\n    iw.optimize();\n    iw.close();\n    dir.close();\n    indexDir.mkdirs();\n    spellchecker.add(AbstractLuceneSpellChecker.INDEX_DIR, indexDir.getAbsolutePath());\n    spellchecker.add(AbstractLuceneSpellChecker.LOCATION, altIndexDir.getAbsolutePath());\n    spellchecker.add(IndexBasedSpellChecker.FIELD, \"title\");\n    spellchecker.add(AbstractLuceneSpellChecker.SPELLCHECKER_ARG_NAME, spellchecker);\n    SolrCore core = h.getCore();\n    String dictName = checker.init(spellchecker, core);\n    assertTrue(dictName + \" is not equal to \" + SolrSpellChecker.DEFAULT_DICTIONARY_NAME,\n            dictName.equals(SolrSpellChecker.DEFAULT_DICTIONARY_NAME) == true);\n    RefCounted<SolrIndexSearcher> holder = core.getSearcher();\n    SolrIndexSearcher searcher = holder.get();\n    try {\n    checker.build(core, searcher);\n\n    IndexReader reader = searcher.getIndexReader();\n    Collection<Token> tokens = queryConverter.convert(\"flesh\");\n    SpellingOptions spellOpts = new SpellingOptions(tokens, reader, 1, false, true, 0.5f, null);\n    SpellingResult result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    //should be lowercased, b/c we are using a lowercasing analyzer\n    Map<String, Integer> suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"flesh is null and it shouldn't be\", suggestions != null);\n    assertTrue(\"flesh Size: \" + suggestions.size() + \" is not: \" + 1, suggestions.size() == 1);\n    Map.Entry<String, Integer> entry = suggestions.entrySet().iterator().next();\n    assertTrue(entry.getKey() + \" is not equal to \" + \"flash\", entry.getKey().equals(\"flash\") == true);\n    assertTrue(entry.getValue() + \" does not equal: \" + 1, entry.getValue() == 1);\n\n    //test something not in the spell checker\n    spellOpts.tokens = queryConverter.convert(\"super\");\n    result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"suggestions is not null and it should be\", suggestions == null);\n\n    spellOpts.tokens = queryConverter.convert(\"Caroline\");\n    result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"suggestions is not null and it should be\", suggestions == null);\n    } finally {\n      holder.decref();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"29ef99d61cda9641b6250bf9567329a6e65f901d","date":1297244127,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"solr/src/test/org/apache/solr/spelling/IndexBasedSpellCheckerTest#testAlternateLocation().mjava","pathOld":"solr/src/test/org/apache/solr/spelling/IndexBasedSpellCheckerTest#testAlternateLocation().mjava","sourceNew":"  @Test\n  public void testAlternateLocation() throws Exception {\n    String[] ALT_DOCS = new String[]{\n            \"jumpin jack flash\",\n            \"Sargent Peppers Lonely Hearts Club Band\",\n            \"Born to Run\",\n            \"Thunder Road\",\n            \"Londons Burning\",\n            \"A Horse with No Name\",\n            \"Sweet Caroline\"\n    };\n\n    IndexBasedSpellChecker checker = new IndexBasedSpellChecker();\n    NamedList spellchecker = new NamedList();\n    spellchecker.add(\"classname\", IndexBasedSpellChecker.class.getName());\n\n    File indexDir = new File(TEMP_DIR, \"spellingIdx\" + new Date().getTime());\n    //create a standalone index\n    File altIndexDir = new File(TEMP_DIR, \"alternateIdx\" + new Date().getTime());\n    Directory dir = newFSDirectory(altIndexDir);\n    IndexWriter iw = new IndexWriter(\n        dir,\n        new IndexWriterConfig(TEST_VERSION_CURRENT, new WhitespaceAnalyzer(TEST_VERSION_CURRENT))\n    );\n    for (int i = 0; i < ALT_DOCS.length; i++) {\n      Document doc = new Document();\n      doc.add(new Field(\"title\", ALT_DOCS[i], Field.Store.YES, Field.Index.ANALYZED));\n      iw.addDocument(doc);\n    }\n    iw.optimize();\n    iw.close();\n    dir.close();\n    indexDir.mkdirs();\n    spellchecker.add(AbstractLuceneSpellChecker.INDEX_DIR, indexDir.getAbsolutePath());\n    spellchecker.add(AbstractLuceneSpellChecker.LOCATION, altIndexDir.getAbsolutePath());\n    spellchecker.add(IndexBasedSpellChecker.FIELD, \"title\");\n    spellchecker.add(AbstractLuceneSpellChecker.SPELLCHECKER_ARG_NAME, spellchecker);\n    SolrCore core = h.getCore();\n    String dictName = checker.init(spellchecker, core);\n    assertTrue(dictName + \" is not equal to \" + SolrSpellChecker.DEFAULT_DICTIONARY_NAME,\n            dictName.equals(SolrSpellChecker.DEFAULT_DICTIONARY_NAME) == true);\n    RefCounted<SolrIndexSearcher> holder = core.getSearcher();\n    SolrIndexSearcher searcher = holder.get();\n    try {\n    checker.build(core, searcher);\n\n    IndexReader reader = searcher.getIndexReader();\n    Collection<Token> tokens = queryConverter.convert(\"flesh\");\n    SpellingOptions spellOpts = new SpellingOptions(tokens, reader, 1, false, true, 0.5f, null);\n    SpellingResult result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    //should be lowercased, b/c we are using a lowercasing analyzer\n    Map<String, Integer> suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"flesh is null and it shouldn't be\", suggestions != null);\n    assertTrue(\"flesh Size: \" + suggestions.size() + \" is not: \" + 1, suggestions.size() == 1);\n    Map.Entry<String, Integer> entry = suggestions.entrySet().iterator().next();\n    assertTrue(entry.getKey() + \" is not equal to \" + \"flash\", entry.getKey().equals(\"flash\") == true);\n    assertTrue(entry.getValue() + \" does not equal: \" + 1, entry.getValue() == 1);\n\n    //test something not in the spell checker\n    spellOpts.tokens = queryConverter.convert(\"super\");\n    result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"suggestions is not null and it should be\", suggestions == null);\n\n    spellOpts.tokens = queryConverter.convert(\"Caroline\");\n    result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"suggestions is not null and it should be\", suggestions == null);\n    } finally {\n      holder.decref();\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testAlternateLocation() throws Exception {\n    String[] ALT_DOCS = new String[]{\n            \"jumpin jack flash\",\n            \"Sargent Peppers Lonely Hearts Club Band\",\n            \"Born to Run\",\n            \"Thunder Road\",\n            \"Londons Burning\",\n            \"A Horse with No Name\",\n            \"Sweet Caroline\"\n    };\n\n    IndexBasedSpellChecker checker = new IndexBasedSpellChecker();\n    NamedList spellchecker = new NamedList();\n    spellchecker.add(\"classname\", IndexBasedSpellChecker.class.getName());\n\n    File indexDir = new File(TEMP_DIR, \"spellingIdx\" + new Date().getTime());\n    //create a standalone index\n    File altIndexDir = new File(TEMP_DIR, \"alternateIdx\" + new Date().getTime());\n    Directory dir = newFSDirectory(altIndexDir);\n    IndexWriter iw = new IndexWriter(\n        dir,\n        new IndexWriterConfig(TEST_VERSION_CURRENT, new WhitespaceAnalyzer(TEST_VERSION_CURRENT)).\n            setMaxFieldLength(IndexWriterConfig.UNLIMITED_FIELD_LENGTH)\n    );\n    for (int i = 0; i < ALT_DOCS.length; i++) {\n      Document doc = new Document();\n      doc.add(new Field(\"title\", ALT_DOCS[i], Field.Store.YES, Field.Index.ANALYZED));\n      iw.addDocument(doc);\n    }\n    iw.optimize();\n    iw.close();\n    dir.close();\n    indexDir.mkdirs();\n    spellchecker.add(AbstractLuceneSpellChecker.INDEX_DIR, indexDir.getAbsolutePath());\n    spellchecker.add(AbstractLuceneSpellChecker.LOCATION, altIndexDir.getAbsolutePath());\n    spellchecker.add(IndexBasedSpellChecker.FIELD, \"title\");\n    spellchecker.add(AbstractLuceneSpellChecker.SPELLCHECKER_ARG_NAME, spellchecker);\n    SolrCore core = h.getCore();\n    String dictName = checker.init(spellchecker, core);\n    assertTrue(dictName + \" is not equal to \" + SolrSpellChecker.DEFAULT_DICTIONARY_NAME,\n            dictName.equals(SolrSpellChecker.DEFAULT_DICTIONARY_NAME) == true);\n    RefCounted<SolrIndexSearcher> holder = core.getSearcher();\n    SolrIndexSearcher searcher = holder.get();\n    try {\n    checker.build(core, searcher);\n\n    IndexReader reader = searcher.getReader();\n    Collection<Token> tokens = queryConverter.convert(\"flesh\");\n    SpellingOptions spellOpts = new SpellingOptions(tokens, reader, 1, false, true, 0.5f, null);\n    SpellingResult result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    //should be lowercased, b/c we are using a lowercasing analyzer\n    Map<String, Integer> suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"flesh is null and it shouldn't be\", suggestions != null);\n    assertTrue(\"flesh Size: \" + suggestions.size() + \" is not: \" + 1, suggestions.size() == 1);\n    Map.Entry<String, Integer> entry = suggestions.entrySet().iterator().next();\n    assertTrue(entry.getKey() + \" is not equal to \" + \"flash\", entry.getKey().equals(\"flash\") == true);\n    assertTrue(entry.getValue() + \" does not equal: \" + 1, entry.getValue() == 1);\n\n    //test something not in the spell checker\n    spellOpts.tokens = queryConverter.convert(\"super\");\n    result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"suggestions is not null and it should be\", suggestions == null);\n\n    spellOpts.tokens = queryConverter.convert(\"Caroline\");\n    result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"suggestions is not null and it should be\", suggestions == null);\n    } finally {\n      holder.decref();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c903c3d15906a3da96b8c0c2fb704491005fdbdb","date":1453508227,"type":5,"author":"Dawid Weiss","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/spelling/IndexBasedSpellCheckerTest#testAlternateLocation().mjava","pathOld":"solr/src/test/org/apache/solr/spelling/IndexBasedSpellCheckerTest#testAlternateLocation().mjava","sourceNew":"  @Test\n  public void testAlternateLocation() throws Exception {\n    String[] ALT_DOCS = new String[]{\n            \"jumpin jack flash\",\n            \"Sargent Peppers Lonely Hearts Club Band\",\n            \"Born to Run\",\n            \"Thunder Road\",\n            \"Londons Burning\",\n            \"A Horse with No Name\",\n            \"Sweet Caroline\"\n    };\n\n    IndexBasedSpellChecker checker = new IndexBasedSpellChecker();\n    NamedList spellchecker = new NamedList();\n    spellchecker.add(\"classname\", IndexBasedSpellChecker.class.getName());\n\n    File indexDir = new File(TEMP_DIR, \"spellingIdx\" + new Date().getTime());\n    //create a standalone index\n    File altIndexDir = new File(TEMP_DIR, \"alternateIdx\" + new Date().getTime());\n    Directory dir = newFSDirectory(altIndexDir);\n    IndexWriter iw = new IndexWriter(\n        dir,\n        new IndexWriterConfig(TEST_VERSION_CURRENT, new WhitespaceAnalyzer(TEST_VERSION_CURRENT))\n    );\n    for (int i = 0; i < ALT_DOCS.length; i++) {\n      Document doc = new Document();\n      doc.add(new Field(\"title\", ALT_DOCS[i], Field.Store.YES, Field.Index.ANALYZED));\n      iw.addDocument(doc);\n    }\n    iw.optimize();\n    iw.close();\n    dir.close();\n    indexDir.mkdirs();\n    spellchecker.add(AbstractLuceneSpellChecker.INDEX_DIR, indexDir.getAbsolutePath());\n    spellchecker.add(AbstractLuceneSpellChecker.LOCATION, altIndexDir.getAbsolutePath());\n    spellchecker.add(IndexBasedSpellChecker.FIELD, \"title\");\n    spellchecker.add(AbstractLuceneSpellChecker.SPELLCHECKER_ARG_NAME, spellchecker);\n    SolrCore core = h.getCore();\n    String dictName = checker.init(spellchecker, core);\n    assertTrue(dictName + \" is not equal to \" + SolrSpellChecker.DEFAULT_DICTIONARY_NAME,\n            dictName.equals(SolrSpellChecker.DEFAULT_DICTIONARY_NAME) == true);\n    RefCounted<SolrIndexSearcher> holder = core.getSearcher();\n    SolrIndexSearcher searcher = holder.get();\n    try {\n    checker.build(core, searcher);\n\n    IndexReader reader = searcher.getIndexReader();\n    Collection<Token> tokens = queryConverter.convert(\"flesh\");\n    SpellingOptions spellOpts = new SpellingOptions(tokens, reader, 1, false, true, 0.5f, null);\n    SpellingResult result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    //should be lowercased, b/c we are using a lowercasing analyzer\n    Map<String, Integer> suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"flesh is null and it shouldn't be\", suggestions != null);\n    assertTrue(\"flesh Size: \" + suggestions.size() + \" is not: \" + 1, suggestions.size() == 1);\n    Map.Entry<String, Integer> entry = suggestions.entrySet().iterator().next();\n    assertTrue(entry.getKey() + \" is not equal to \" + \"flash\", entry.getKey().equals(\"flash\") == true);\n    assertTrue(entry.getValue() + \" does not equal: \" + 1, entry.getValue() == 1);\n\n    //test something not in the spell checker\n    spellOpts.tokens = queryConverter.convert(\"super\");\n    result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"suggestions is not null and it should be\", suggestions == null);\n\n    spellOpts.tokens = queryConverter.convert(\"Caroline\");\n    result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"suggestions is not null and it should be\", suggestions == null);\n    } finally {\n      holder.decref();\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testAlternateLocation() throws Exception {\n    String[] ALT_DOCS = new String[]{\n            \"jumpin jack flash\",\n            \"Sargent Peppers Lonely Hearts Club Band\",\n            \"Born to Run\",\n            \"Thunder Road\",\n            \"Londons Burning\",\n            \"A Horse with No Name\",\n            \"Sweet Caroline\"\n    };\n\n    IndexBasedSpellChecker checker = new IndexBasedSpellChecker();\n    NamedList spellchecker = new NamedList();\n    spellchecker.add(\"classname\", IndexBasedSpellChecker.class.getName());\n\n    File indexDir = new File(TEMP_DIR, \"spellingIdx\" + new Date().getTime());\n    //create a standalone index\n    File altIndexDir = new File(TEMP_DIR, \"alternateIdx\" + new Date().getTime());\n    Directory dir = newFSDirectory(altIndexDir);\n    IndexWriter iw = new IndexWriter(\n        dir,\n        new IndexWriterConfig(TEST_VERSION_CURRENT, new WhitespaceAnalyzer(TEST_VERSION_CURRENT))\n    );\n    for (int i = 0; i < ALT_DOCS.length; i++) {\n      Document doc = new Document();\n      doc.add(new Field(\"title\", ALT_DOCS[i], Field.Store.YES, Field.Index.ANALYZED));\n      iw.addDocument(doc);\n    }\n    iw.optimize();\n    iw.close();\n    dir.close();\n    indexDir.mkdirs();\n    spellchecker.add(AbstractLuceneSpellChecker.INDEX_DIR, indexDir.getAbsolutePath());\n    spellchecker.add(AbstractLuceneSpellChecker.LOCATION, altIndexDir.getAbsolutePath());\n    spellchecker.add(IndexBasedSpellChecker.FIELD, \"title\");\n    spellchecker.add(AbstractLuceneSpellChecker.SPELLCHECKER_ARG_NAME, spellchecker);\n    SolrCore core = h.getCore();\n    String dictName = checker.init(spellchecker, core);\n    assertTrue(dictName + \" is not equal to \" + SolrSpellChecker.DEFAULT_DICTIONARY_NAME,\n            dictName.equals(SolrSpellChecker.DEFAULT_DICTIONARY_NAME) == true);\n    RefCounted<SolrIndexSearcher> holder = core.getSearcher();\n    SolrIndexSearcher searcher = holder.get();\n    try {\n    checker.build(core, searcher);\n\n    IndexReader reader = searcher.getIndexReader();\n    Collection<Token> tokens = queryConverter.convert(\"flesh\");\n    SpellingOptions spellOpts = new SpellingOptions(tokens, reader, 1, false, true, 0.5f, null);\n    SpellingResult result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    //should be lowercased, b/c we are using a lowercasing analyzer\n    Map<String, Integer> suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"flesh is null and it shouldn't be\", suggestions != null);\n    assertTrue(\"flesh Size: \" + suggestions.size() + \" is not: \" + 1, suggestions.size() == 1);\n    Map.Entry<String, Integer> entry = suggestions.entrySet().iterator().next();\n    assertTrue(entry.getKey() + \" is not equal to \" + \"flash\", entry.getKey().equals(\"flash\") == true);\n    assertTrue(entry.getValue() + \" does not equal: \" + 1, entry.getValue() == 1);\n\n    //test something not in the spell checker\n    spellOpts.tokens = queryConverter.convert(\"super\");\n    result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"suggestions is not null and it should be\", suggestions == null);\n\n    spellOpts.tokens = queryConverter.convert(\"Caroline\");\n    result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"suggestions is not null and it should be\", suggestions == null);\n    } finally {\n      holder.decref();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a258fbb26824fd104ed795e5d9033d2d040049ee","date":1453508252,"type":5,"author":"Dawid Weiss","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/spelling/IndexBasedSpellCheckerTest#testAlternateLocation().mjava","pathOld":"solr/src/test/org/apache/solr/spelling/IndexBasedSpellCheckerTest#testAlternateLocation().mjava","sourceNew":"  @Test\n  public void testAlternateLocation() throws Exception {\n    String[] ALT_DOCS = new String[]{\n            \"jumpin jack flash\",\n            \"Sargent Peppers Lonely Hearts Club Band\",\n            \"Born to Run\",\n            \"Thunder Road\",\n            \"Londons Burning\",\n            \"A Horse with No Name\",\n            \"Sweet Caroline\"\n    };\n\n    IndexBasedSpellChecker checker = new IndexBasedSpellChecker();\n    NamedList spellchecker = new NamedList();\n    spellchecker.add(\"classname\", IndexBasedSpellChecker.class.getName());\n\n    File indexDir = new File(TEMP_DIR, \"spellingIdx\" + new Date().getTime());\n    //create a standalone index\n    File altIndexDir = new File(TEMP_DIR, \"alternateIdx\" + new Date().getTime());\n    Directory dir = newFSDirectory(altIndexDir);\n    IndexWriter iw = new IndexWriter(\n        dir,\n        new IndexWriterConfig(TEST_VERSION_CURRENT, new WhitespaceAnalyzer(TEST_VERSION_CURRENT))\n    );\n    for (int i = 0; i < ALT_DOCS.length; i++) {\n      Document doc = new Document();\n      doc.add(new Field(\"title\", ALT_DOCS[i], Field.Store.YES, Field.Index.ANALYZED));\n      iw.addDocument(doc);\n    }\n    iw.optimize();\n    iw.close();\n    dir.close();\n    indexDir.mkdirs();\n    spellchecker.add(AbstractLuceneSpellChecker.INDEX_DIR, indexDir.getAbsolutePath());\n    spellchecker.add(AbstractLuceneSpellChecker.LOCATION, altIndexDir.getAbsolutePath());\n    spellchecker.add(IndexBasedSpellChecker.FIELD, \"title\");\n    spellchecker.add(AbstractLuceneSpellChecker.SPELLCHECKER_ARG_NAME, spellchecker);\n    SolrCore core = h.getCore();\n    String dictName = checker.init(spellchecker, core);\n    assertTrue(dictName + \" is not equal to \" + SolrSpellChecker.DEFAULT_DICTIONARY_NAME,\n            dictName.equals(SolrSpellChecker.DEFAULT_DICTIONARY_NAME) == true);\n    RefCounted<SolrIndexSearcher> holder = core.getSearcher();\n    SolrIndexSearcher searcher = holder.get();\n    try {\n    checker.build(core, searcher);\n\n    IndexReader reader = searcher.getIndexReader();\n    Collection<Token> tokens = queryConverter.convert(\"flesh\");\n    SpellingOptions spellOpts = new SpellingOptions(tokens, reader, 1, false, true, 0.5f, null);\n    SpellingResult result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    //should be lowercased, b/c we are using a lowercasing analyzer\n    Map<String, Integer> suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"flesh is null and it shouldn't be\", suggestions != null);\n    assertTrue(\"flesh Size: \" + suggestions.size() + \" is not: \" + 1, suggestions.size() == 1);\n    Map.Entry<String, Integer> entry = suggestions.entrySet().iterator().next();\n    assertTrue(entry.getKey() + \" is not equal to \" + \"flash\", entry.getKey().equals(\"flash\") == true);\n    assertTrue(entry.getValue() + \" does not equal: \" + 1, entry.getValue() == 1);\n\n    //test something not in the spell checker\n    spellOpts.tokens = queryConverter.convert(\"super\");\n    result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"suggestions is not null and it should be\", suggestions == null);\n\n    spellOpts.tokens = queryConverter.convert(\"Caroline\");\n    result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"suggestions is not null and it should be\", suggestions == null);\n    } finally {\n      holder.decref();\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testAlternateLocation() throws Exception {\n    String[] ALT_DOCS = new String[]{\n            \"jumpin jack flash\",\n            \"Sargent Peppers Lonely Hearts Club Band\",\n            \"Born to Run\",\n            \"Thunder Road\",\n            \"Londons Burning\",\n            \"A Horse with No Name\",\n            \"Sweet Caroline\"\n    };\n\n    IndexBasedSpellChecker checker = new IndexBasedSpellChecker();\n    NamedList spellchecker = new NamedList();\n    spellchecker.add(\"classname\", IndexBasedSpellChecker.class.getName());\n\n    File indexDir = new File(TEMP_DIR, \"spellingIdx\" + new Date().getTime());\n    //create a standalone index\n    File altIndexDir = new File(TEMP_DIR, \"alternateIdx\" + new Date().getTime());\n    Directory dir = newFSDirectory(altIndexDir);\n    IndexWriter iw = new IndexWriter(\n        dir,\n        new IndexWriterConfig(TEST_VERSION_CURRENT, new WhitespaceAnalyzer(TEST_VERSION_CURRENT))\n    );\n    for (int i = 0; i < ALT_DOCS.length; i++) {\n      Document doc = new Document();\n      doc.add(new Field(\"title\", ALT_DOCS[i], Field.Store.YES, Field.Index.ANALYZED));\n      iw.addDocument(doc);\n    }\n    iw.optimize();\n    iw.close();\n    dir.close();\n    indexDir.mkdirs();\n    spellchecker.add(AbstractLuceneSpellChecker.INDEX_DIR, indexDir.getAbsolutePath());\n    spellchecker.add(AbstractLuceneSpellChecker.LOCATION, altIndexDir.getAbsolutePath());\n    spellchecker.add(IndexBasedSpellChecker.FIELD, \"title\");\n    spellchecker.add(AbstractLuceneSpellChecker.SPELLCHECKER_ARG_NAME, spellchecker);\n    SolrCore core = h.getCore();\n    String dictName = checker.init(spellchecker, core);\n    assertTrue(dictName + \" is not equal to \" + SolrSpellChecker.DEFAULT_DICTIONARY_NAME,\n            dictName.equals(SolrSpellChecker.DEFAULT_DICTIONARY_NAME) == true);\n    RefCounted<SolrIndexSearcher> holder = core.getSearcher();\n    SolrIndexSearcher searcher = holder.get();\n    try {\n    checker.build(core, searcher);\n\n    IndexReader reader = searcher.getIndexReader();\n    Collection<Token> tokens = queryConverter.convert(\"flesh\");\n    SpellingOptions spellOpts = new SpellingOptions(tokens, reader, 1, false, true, 0.5f, null);\n    SpellingResult result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    //should be lowercased, b/c we are using a lowercasing analyzer\n    Map<String, Integer> suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"flesh is null and it shouldn't be\", suggestions != null);\n    assertTrue(\"flesh Size: \" + suggestions.size() + \" is not: \" + 1, suggestions.size() == 1);\n    Map.Entry<String, Integer> entry = suggestions.entrySet().iterator().next();\n    assertTrue(entry.getKey() + \" is not equal to \" + \"flash\", entry.getKey().equals(\"flash\") == true);\n    assertTrue(entry.getValue() + \" does not equal: \" + 1, entry.getValue() == 1);\n\n    //test something not in the spell checker\n    spellOpts.tokens = queryConverter.convert(\"super\");\n    result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"suggestions is not null and it should be\", suggestions == null);\n\n    spellOpts.tokens = queryConverter.convert(\"Caroline\");\n    result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"suggestions is not null and it should be\", suggestions == null);\n    } finally {\n      holder.decref();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c26f00b574427b55127e869b935845554afde1fa","date":1310252513,"type":5,"author":"Steven Rowe","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/spelling/IndexBasedSpellCheckerTest#testAlternateLocation().mjava","pathOld":"solr/src/test/org/apache/solr/spelling/IndexBasedSpellCheckerTest#testAlternateLocation().mjava","sourceNew":"  @Test\n  public void testAlternateLocation() throws Exception {\n    String[] ALT_DOCS = new String[]{\n            \"jumpin jack flash\",\n            \"Sargent Peppers Lonely Hearts Club Band\",\n            \"Born to Run\",\n            \"Thunder Road\",\n            \"Londons Burning\",\n            \"A Horse with No Name\",\n            \"Sweet Caroline\"\n    };\n\n    IndexBasedSpellChecker checker = new IndexBasedSpellChecker();\n    NamedList spellchecker = new NamedList();\n    spellchecker.add(\"classname\", IndexBasedSpellChecker.class.getName());\n\n    File indexDir = new File(TEMP_DIR, \"spellingIdx\" + new Date().getTime());\n    //create a standalone index\n    File altIndexDir = new File(TEMP_DIR, \"alternateIdx\" + new Date().getTime());\n    Directory dir = newFSDirectory(altIndexDir);\n    IndexWriter iw = new IndexWriter(\n        dir,\n        new IndexWriterConfig(TEST_VERSION_CURRENT, new WhitespaceAnalyzer(TEST_VERSION_CURRENT))\n    );\n    for (int i = 0; i < ALT_DOCS.length; i++) {\n      Document doc = new Document();\n      doc.add(new Field(\"title\", ALT_DOCS[i], Field.Store.YES, Field.Index.ANALYZED));\n      iw.addDocument(doc);\n    }\n    iw.optimize();\n    iw.close();\n    dir.close();\n    indexDir.mkdirs();\n    spellchecker.add(AbstractLuceneSpellChecker.INDEX_DIR, indexDir.getAbsolutePath());\n    spellchecker.add(AbstractLuceneSpellChecker.LOCATION, altIndexDir.getAbsolutePath());\n    spellchecker.add(IndexBasedSpellChecker.FIELD, \"title\");\n    spellchecker.add(AbstractLuceneSpellChecker.SPELLCHECKER_ARG_NAME, spellchecker);\n    SolrCore core = h.getCore();\n    String dictName = checker.init(spellchecker, core);\n    assertTrue(dictName + \" is not equal to \" + SolrSpellChecker.DEFAULT_DICTIONARY_NAME,\n            dictName.equals(SolrSpellChecker.DEFAULT_DICTIONARY_NAME) == true);\n    RefCounted<SolrIndexSearcher> holder = core.getSearcher();\n    SolrIndexSearcher searcher = holder.get();\n    try {\n    checker.build(core, searcher);\n\n    IndexReader reader = searcher.getIndexReader();\n    Collection<Token> tokens = queryConverter.convert(\"flesh\");\n    SpellingOptions spellOpts = new SpellingOptions(tokens, reader, 1, false, true, 0.5f, null);\n    SpellingResult result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    //should be lowercased, b/c we are using a lowercasing analyzer\n    Map<String, Integer> suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"flesh is null and it shouldn't be\", suggestions != null);\n    assertTrue(\"flesh Size: \" + suggestions.size() + \" is not: \" + 1, suggestions.size() == 1);\n    Map.Entry<String, Integer> entry = suggestions.entrySet().iterator().next();\n    assertTrue(entry.getKey() + \" is not equal to \" + \"flash\", entry.getKey().equals(\"flash\") == true);\n    assertTrue(entry.getValue() + \" does not equal: \" + 1, entry.getValue() == 1);\n\n    //test something not in the spell checker\n    spellOpts.tokens = queryConverter.convert(\"super\");\n    result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"suggestions is not null and it should be\", suggestions == null);\n\n    spellOpts.tokens = queryConverter.convert(\"Caroline\");\n    result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"suggestions is not null and it should be\", suggestions == null);\n    } finally {\n      holder.decref();\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testAlternateLocation() throws Exception {\n    String[] ALT_DOCS = new String[]{\n            \"jumpin jack flash\",\n            \"Sargent Peppers Lonely Hearts Club Band\",\n            \"Born to Run\",\n            \"Thunder Road\",\n            \"Londons Burning\",\n            \"A Horse with No Name\",\n            \"Sweet Caroline\"\n    };\n\n    IndexBasedSpellChecker checker = new IndexBasedSpellChecker();\n    NamedList spellchecker = new NamedList();\n    spellchecker.add(\"classname\", IndexBasedSpellChecker.class.getName());\n\n    File indexDir = new File(TEMP_DIR, \"spellingIdx\" + new Date().getTime());\n    //create a standalone index\n    File altIndexDir = new File(TEMP_DIR, \"alternateIdx\" + new Date().getTime());\n    Directory dir = newFSDirectory(altIndexDir);\n    IndexWriter iw = new IndexWriter(\n        dir,\n        new IndexWriterConfig(TEST_VERSION_CURRENT, new WhitespaceAnalyzer(TEST_VERSION_CURRENT))\n    );\n    for (int i = 0; i < ALT_DOCS.length; i++) {\n      Document doc = new Document();\n      doc.add(new Field(\"title\", ALT_DOCS[i], Field.Store.YES, Field.Index.ANALYZED));\n      iw.addDocument(doc);\n    }\n    iw.optimize();\n    iw.close();\n    dir.close();\n    indexDir.mkdirs();\n    spellchecker.add(AbstractLuceneSpellChecker.INDEX_DIR, indexDir.getAbsolutePath());\n    spellchecker.add(AbstractLuceneSpellChecker.LOCATION, altIndexDir.getAbsolutePath());\n    spellchecker.add(IndexBasedSpellChecker.FIELD, \"title\");\n    spellchecker.add(AbstractLuceneSpellChecker.SPELLCHECKER_ARG_NAME, spellchecker);\n    SolrCore core = h.getCore();\n    String dictName = checker.init(spellchecker, core);\n    assertTrue(dictName + \" is not equal to \" + SolrSpellChecker.DEFAULT_DICTIONARY_NAME,\n            dictName.equals(SolrSpellChecker.DEFAULT_DICTIONARY_NAME) == true);\n    RefCounted<SolrIndexSearcher> holder = core.getSearcher();\n    SolrIndexSearcher searcher = holder.get();\n    try {\n    checker.build(core, searcher);\n\n    IndexReader reader = searcher.getIndexReader();\n    Collection<Token> tokens = queryConverter.convert(\"flesh\");\n    SpellingOptions spellOpts = new SpellingOptions(tokens, reader, 1, false, true, 0.5f, null);\n    SpellingResult result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    //should be lowercased, b/c we are using a lowercasing analyzer\n    Map<String, Integer> suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"flesh is null and it shouldn't be\", suggestions != null);\n    assertTrue(\"flesh Size: \" + suggestions.size() + \" is not: \" + 1, suggestions.size() == 1);\n    Map.Entry<String, Integer> entry = suggestions.entrySet().iterator().next();\n    assertTrue(entry.getKey() + \" is not equal to \" + \"flash\", entry.getKey().equals(\"flash\") == true);\n    assertTrue(entry.getValue() + \" does not equal: \" + 1, entry.getValue() == 1);\n\n    //test something not in the spell checker\n    spellOpts.tokens = queryConverter.convert(\"super\");\n    result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"suggestions is not null and it should be\", suggestions == null);\n\n    spellOpts.tokens = queryConverter.convert(\"Caroline\");\n    result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"suggestions is not null and it should be\", suggestions == null);\n    } finally {\n      holder.decref();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"a13a126d15299d5c1e117ea99ddae6fb0fa3f209":["4e8cc373c801e54cec75daf9f52792cb4b17f536"],"893269407f5c988a4b2ee13c7ffc01ec43136c1d":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a89acb2b4321b599bbfa1e802c00c4dbbc8ee6b8":["893269407f5c988a4b2ee13c7ffc01ec43136c1d"],"c26f00b574427b55127e869b935845554afde1fa":["c2047784e704fe141e0ff36affac8a7cb6c7bbec","c903c3d15906a3da96b8c0c2fb704491005fdbdb"],"3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b":[],"ab5cb6a74aefb78aa0569857970b9151dfe2e787":["3bb13258feba31ab676502787ab2e1779f129b7a","a13a126d15299d5c1e117ea99ddae6fb0fa3f209"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":["afeb033b2bd36d8ce9d82142b197da4dde13068b","a13a126d15299d5c1e117ea99ddae6fb0fa3f209"],"e79a6d080bdd5b2a8f56342cf571b5476de04180":["868da859b43505d9d2a023bfeae6dd0c795f5295","c2047784e704fe141e0ff36affac8a7cb6c7bbec"],"d76ab9983349b199b0e6f65776c0087b0c08a10d":["848cf14d057f83cf4a9ced81c37d4d59ab739e5a"],"1da8d55113b689b06716246649de6f62430f15c0":["a89acb2b4321b599bbfa1e802c00c4dbbc8ee6b8","ad94625fb8d088209f46650c8097196fec67f00c"],"c2047784e704fe141e0ff36affac8a7cb6c7bbec":["c220849f876de24a79f756f65b3eb045db59f63f"],"c220849f876de24a79f756f65b3eb045db59f63f":["a13a126d15299d5c1e117ea99ddae6fb0fa3f209"],"848cf14d057f83cf4a9ced81c37d4d59ab739e5a":["afeb033b2bd36d8ce9d82142b197da4dde13068b"],"c903c3d15906a3da96b8c0c2fb704491005fdbdb":["c2047784e704fe141e0ff36affac8a7cb6c7bbec"],"29ef99d61cda9641b6250bf9567329a6e65f901d":["ab5cb6a74aefb78aa0569857970b9151dfe2e787","c2047784e704fe141e0ff36affac8a7cb6c7bbec"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"afeb033b2bd36d8ce9d82142b197da4dde13068b":["1da8d55113b689b06716246649de6f62430f15c0"],"a258fbb26824fd104ed795e5d9033d2d040049ee":["c2047784e704fe141e0ff36affac8a7cb6c7bbec"],"ad94625fb8d088209f46650c8097196fec67f00c":["3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b"],"868da859b43505d9d2a023bfeae6dd0c795f5295":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","c220849f876de24a79f756f65b3eb045db59f63f"],"3bb13258feba31ab676502787ab2e1779f129b7a":["d76ab9983349b199b0e6f65776c0087b0c08a10d","4e8cc373c801e54cec75daf9f52792cb4b17f536"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["c26f00b574427b55127e869b935845554afde1fa"],"4e8cc373c801e54cec75daf9f52792cb4b17f536":["d76ab9983349b199b0e6f65776c0087b0c08a10d"]},"commit2Childs":{"a13a126d15299d5c1e117ea99ddae6fb0fa3f209":["ab5cb6a74aefb78aa0569857970b9151dfe2e787","7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","c220849f876de24a79f756f65b3eb045db59f63f"],"893269407f5c988a4b2ee13c7ffc01ec43136c1d":["a89acb2b4321b599bbfa1e802c00c4dbbc8ee6b8"],"a89acb2b4321b599bbfa1e802c00c4dbbc8ee6b8":["1da8d55113b689b06716246649de6f62430f15c0"],"c26f00b574427b55127e869b935845554afde1fa":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b":["ad94625fb8d088209f46650c8097196fec67f00c"],"ab5cb6a74aefb78aa0569857970b9151dfe2e787":["29ef99d61cda9641b6250bf9567329a6e65f901d"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":["868da859b43505d9d2a023bfeae6dd0c795f5295"],"e79a6d080bdd5b2a8f56342cf571b5476de04180":[],"d76ab9983349b199b0e6f65776c0087b0c08a10d":["3bb13258feba31ab676502787ab2e1779f129b7a","4e8cc373c801e54cec75daf9f52792cb4b17f536"],"1da8d55113b689b06716246649de6f62430f15c0":["afeb033b2bd36d8ce9d82142b197da4dde13068b"],"c2047784e704fe141e0ff36affac8a7cb6c7bbec":["c26f00b574427b55127e869b935845554afde1fa","e79a6d080bdd5b2a8f56342cf571b5476de04180","c903c3d15906a3da96b8c0c2fb704491005fdbdb","29ef99d61cda9641b6250bf9567329a6e65f901d","a258fbb26824fd104ed795e5d9033d2d040049ee"],"848cf14d057f83cf4a9ced81c37d4d59ab739e5a":["d76ab9983349b199b0e6f65776c0087b0c08a10d"],"c220849f876de24a79f756f65b3eb045db59f63f":["c2047784e704fe141e0ff36affac8a7cb6c7bbec","868da859b43505d9d2a023bfeae6dd0c795f5295"],"c903c3d15906a3da96b8c0c2fb704491005fdbdb":["c26f00b574427b55127e869b935845554afde1fa"],"29ef99d61cda9641b6250bf9567329a6e65f901d":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["893269407f5c988a4b2ee13c7ffc01ec43136c1d"],"afeb033b2bd36d8ce9d82142b197da4dde13068b":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","848cf14d057f83cf4a9ced81c37d4d59ab739e5a"],"a258fbb26824fd104ed795e5d9033d2d040049ee":[],"ad94625fb8d088209f46650c8097196fec67f00c":["1da8d55113b689b06716246649de6f62430f15c0"],"868da859b43505d9d2a023bfeae6dd0c795f5295":["e79a6d080bdd5b2a8f56342cf571b5476de04180"],"3bb13258feba31ab676502787ab2e1779f129b7a":["ab5cb6a74aefb78aa0569857970b9151dfe2e787"],"4e8cc373c801e54cec75daf9f52792cb4b17f536":["a13a126d15299d5c1e117ea99ddae6fb0fa3f209","3bb13258feba31ab676502787ab2e1779f129b7a"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["e79a6d080bdd5b2a8f56342cf571b5476de04180","29ef99d61cda9641b6250bf9567329a6e65f901d","a258fbb26824fd104ed795e5d9033d2d040049ee","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b","a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}