{"path":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#build(int,int,int,MutablePointValues,int,int,IndexOutput,byte[],byte[],int[],byte[],long[],int[]).mjava","commits":[{"id":"d3929a60a731a8848bb9bc0bbfd3c5e3d59195e7","date":1588412059,"type":1,"author":"Ignacio Vera","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#build(int,int,int,MutablePointValues,int,int,IndexOutput,byte[],byte[],int[],byte[],long[],int[]).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#build(int,int,MutablePointValues,int,int,IndexOutput,byte[],byte[],int[],byte[],long[],int[]).mjava","sourceNew":"  /* Recursively reorders the provided reader and writes the bkd-tree on the fly; this method is used\n   * when we are writing a new segment directly from IndexWriter's indexing buffer (MutablePointsReader). */\n  private void build(int nodeID, int leavesOffset, int numLeaves,\n                     MutablePointValues reader, int from, int to,\n                     IndexOutput out,\n                     byte[] minPackedValue, byte[] maxPackedValue,\n                     int[] parentSplits,\n                     byte[] splitPackedValues,\n                     long[] leafBlockFPs,\n                     int[] spareDocIds) throws IOException {\n\n    if (numLeaves == 1) {\n      // leaf node\n      final int count = to - from;\n      assert count <= maxPointsInLeafNode;\n\n      // Compute common prefixes\n      Arrays.fill(commonPrefixLengths, bytesPerDim);\n      reader.getValue(from, scratchBytesRef1);\n      for (int i = from + 1; i < to; ++i) {\n        reader.getValue(i, scratchBytesRef2);\n        for (int dim=0;dim<numDataDims;dim++) {\n          final int offset = dim * bytesPerDim;\n          int dimensionPrefixLength = commonPrefixLengths[dim];\n          commonPrefixLengths[dim] = Arrays.mismatch(scratchBytesRef1.bytes, scratchBytesRef1.offset + offset,\n              scratchBytesRef1.offset + offset + dimensionPrefixLength,\n              scratchBytesRef2.bytes, scratchBytesRef2.offset + offset,\n              scratchBytesRef2.offset + offset + dimensionPrefixLength);\n          if (commonPrefixLengths[dim] == -1) {\n            commonPrefixLengths[dim] = dimensionPrefixLength;\n          }\n        }\n      }\n\n      // Find the dimension that has the least number of unique bytes at commonPrefixLengths[dim]\n      FixedBitSet[] usedBytes = new FixedBitSet[numDataDims];\n      for (int dim = 0; dim < numDataDims; ++dim) {\n        if (commonPrefixLengths[dim] < bytesPerDim) {\n          usedBytes[dim] = new FixedBitSet(256);\n        }\n      }\n      for (int i = from + 1; i < to; ++i) {\n        for (int dim=0;dim<numDataDims;dim++) {\n          if (usedBytes[dim] != null) {\n            byte b = reader.getByteAt(i, dim * bytesPerDim + commonPrefixLengths[dim]);\n            usedBytes[dim].set(Byte.toUnsignedInt(b));\n          }\n        }\n      }\n      int sortedDim = 0;\n      int sortedDimCardinality = Integer.MAX_VALUE;\n      for (int dim = 0; dim < numDataDims; ++dim) {\n        if (usedBytes[dim] != null) {\n          final int cardinality = usedBytes[dim].cardinality();\n          if (cardinality < sortedDimCardinality) {\n            sortedDim = dim;\n            sortedDimCardinality = cardinality;\n          }\n        }\n      }\n\n      // sort by sortedDim\n      MutablePointsReaderUtils.sortByDim(numDataDims, numIndexDims, sortedDim, bytesPerDim, commonPrefixLengths,\n          reader, from, to, scratchBytesRef1, scratchBytesRef2);\n\n      BytesRef comparator = scratchBytesRef1;\n      BytesRef collector = scratchBytesRef2;\n      reader.getValue(from, comparator);\n      int leafCardinality = 1;\n      for (int i = from + 1; i < to; ++i) {\n        reader.getValue(i, collector);\n        for (int dim =0; dim < numDataDims; dim++) {\n          final int start = dim * bytesPerDim + commonPrefixLengths[dim];\n          final int end = dim * bytesPerDim + bytesPerDim;\n          if (Arrays.mismatch(collector.bytes, collector.offset + start, collector.offset + end,\n              comparator.bytes, comparator.offset + start, comparator.offset + end) != -1) {\n            leafCardinality++;\n            BytesRef scratch = collector;\n            collector = comparator;\n            comparator = scratch;\n            break;\n          }\n        }\n      }\n      // Save the block file pointer:\n      leafBlockFPs[leavesOffset] = out.getFilePointer();\n\n      assert scratchOut.size() == 0;\n\n      // Write doc IDs\n      int[] docIDs = spareDocIds;\n      for (int i = from; i < to; ++i) {\n        docIDs[i - from] = reader.getDocID(i);\n      }\n      //System.out.println(\"writeLeafBlock pos=\" + out.getFilePointer());\n      writeLeafBlockDocs(scratchOut, docIDs, 0, count);\n\n      // Write the common prefixes:\n      reader.getValue(from, scratchBytesRef1);\n      System.arraycopy(scratchBytesRef1.bytes, scratchBytesRef1.offset, scratch1, 0, packedBytesLength);\n      writeCommonPrefixes(scratchOut, commonPrefixLengths, scratch1);\n\n      // Write the full values:\n      IntFunction<BytesRef> packedValues = new IntFunction<BytesRef>() {\n        @Override\n        public BytesRef apply(int i) {\n          reader.getValue(from + i, scratchBytesRef1);\n          return scratchBytesRef1;\n        }\n      };\n      assert valuesInOrderAndBounds(count, sortedDim, minPackedValue, maxPackedValue, packedValues,\n          docIDs, 0);\n      writeLeafBlockPackedValues(scratchOut, commonPrefixLengths, count, sortedDim, packedValues, leafCardinality);\n      scratchOut.copyTo(out);\n      scratchOut.reset();\n    } else {\n      // inner node\n\n      final int splitDim;\n      // compute the split dimension and partition around it\n      if (numIndexDims == 1) {\n        splitDim = 0;\n      } else {\n        // for dimensions > 2 we recompute the bounds for the current inner node to help the algorithm choose best\n        // split dimensions. Because it is an expensive operation, the frequency we recompute the bounds is given\n        // by SPLITS_BEFORE_EXACT_BOUNDS.\n        if (nodeID > 1 && numIndexDims > 2 && Arrays.stream(parentSplits).sum() % SPLITS_BEFORE_EXACT_BOUNDS == 0) {\n          computePackedValueBounds(reader, from, to, minPackedValue, maxPackedValue, scratchBytesRef1);\n        }\n        splitDim = split(minPackedValue, maxPackedValue, parentSplits);\n      }\n\n      // How many leaves will be in the left tree:\n      int numLeftLeafNodes = getNumLeftLeafNodes(numLeaves);\n      // How many points will be in the left tree:\n      final int mid = from + numLeftLeafNodes * maxPointsInLeafNode;\n\n      int commonPrefixLen = Arrays.mismatch(minPackedValue, splitDim * bytesPerDim,\n          splitDim * bytesPerDim + bytesPerDim, maxPackedValue, splitDim * bytesPerDim,\n          splitDim * bytesPerDim + bytesPerDim);\n      if (commonPrefixLen == -1) {\n        commonPrefixLen = bytesPerDim;\n      }\n\n      MutablePointsReaderUtils.partition(numDataDims, numIndexDims, maxDoc, splitDim, bytesPerDim, commonPrefixLen,\n          reader, from, to, mid, scratchBytesRef1, scratchBytesRef2);\n\n      // set the split value\n      final int address = nodeID * (1+bytesPerDim);\n      splitPackedValues[address] = (byte) splitDim;\n      reader.getValue(mid, scratchBytesRef1);\n      System.arraycopy(scratchBytesRef1.bytes, scratchBytesRef1.offset + splitDim * bytesPerDim, splitPackedValues, address + 1, bytesPerDim);\n\n      byte[] minSplitPackedValue = ArrayUtil.copyOfSubArray(minPackedValue, 0, packedIndexBytesLength);\n      byte[] maxSplitPackedValue = ArrayUtil.copyOfSubArray(maxPackedValue, 0, packedIndexBytesLength);\n      System.arraycopy(scratchBytesRef1.bytes, scratchBytesRef1.offset + splitDim * bytesPerDim,\n          minSplitPackedValue, splitDim * bytesPerDim, bytesPerDim);\n      System.arraycopy(scratchBytesRef1.bytes, scratchBytesRef1.offset + splitDim * bytesPerDim,\n          maxSplitPackedValue, splitDim * bytesPerDim, bytesPerDim);\n\n      // recurse\n      parentSplits[splitDim]++;\n      build(nodeID * 2, leavesOffset, numLeftLeafNodes, reader, from, mid, out,\n          minPackedValue, maxSplitPackedValue, parentSplits,\n          splitPackedValues, leafBlockFPs, spareDocIds);\n      build(nodeID * 2 + 1, leavesOffset + numLeftLeafNodes, numLeaves - numLeftLeafNodes, reader, mid, to, out,\n          minSplitPackedValue, maxPackedValue, parentSplits,\n          splitPackedValues, leafBlockFPs, spareDocIds);\n      parentSplits[splitDim]--;\n    }\n  }\n\n","sourceOld":"  /* Recursively reorders the provided reader and writes the bkd-tree on the fly; this method is used\n   * when we are writing a new segment directly from IndexWriter's indexing buffer (MutablePointsReader). */\n  private void build(int nodeID, int leafNodeOffset,\n                     MutablePointValues reader, int from, int to,\n                     IndexOutput out,\n                     byte[] minPackedValue, byte[] maxPackedValue,\n                     int[] parentSplits,\n                     byte[] splitPackedValues,\n                     long[] leafBlockFPs,\n                     int[] spareDocIds) throws IOException {\n\n    if (nodeID >= leafNodeOffset) {\n      // leaf node\n      final int count = to - from;\n      assert count <= maxPointsInLeafNode;\n\n      // Compute common prefixes\n      Arrays.fill(commonPrefixLengths, bytesPerDim);\n      reader.getValue(from, scratchBytesRef1);\n      for (int i = from + 1; i < to; ++i) {\n        reader.getValue(i, scratchBytesRef2);\n        for (int dim=0;dim<numDataDims;dim++) {\n          final int offset = dim * bytesPerDim;\n          int dimensionPrefixLength = commonPrefixLengths[dim];\n          commonPrefixLengths[dim] = Arrays.mismatch(scratchBytesRef1.bytes, scratchBytesRef1.offset + offset,\n              scratchBytesRef1.offset + offset + dimensionPrefixLength,\n              scratchBytesRef2.bytes, scratchBytesRef2.offset + offset,\n              scratchBytesRef2.offset + offset + dimensionPrefixLength);\n          if (commonPrefixLengths[dim] == -1) {\n            commonPrefixLengths[dim] = dimensionPrefixLength;\n          }\n        }\n      }\n\n      // Find the dimension that has the least number of unique bytes at commonPrefixLengths[dim]\n      FixedBitSet[] usedBytes = new FixedBitSet[numDataDims];\n      for (int dim = 0; dim < numDataDims; ++dim) {\n        if (commonPrefixLengths[dim] < bytesPerDim) {\n          usedBytes[dim] = new FixedBitSet(256);\n        }\n      }\n      for (int i = from + 1; i < to; ++i) {\n        for (int dim=0;dim<numDataDims;dim++) {\n          if (usedBytes[dim] != null) {\n            byte b = reader.getByteAt(i, dim * bytesPerDim + commonPrefixLengths[dim]);\n            usedBytes[dim].set(Byte.toUnsignedInt(b));\n          }\n        }\n      }\n      int sortedDim = 0;\n      int sortedDimCardinality = Integer.MAX_VALUE;\n      for (int dim = 0; dim < numDataDims; ++dim) {\n        if (usedBytes[dim] != null) {\n          final int cardinality = usedBytes[dim].cardinality();\n          if (cardinality < sortedDimCardinality) {\n            sortedDim = dim;\n            sortedDimCardinality = cardinality;\n          }\n        }\n      }\n\n      // sort by sortedDim\n      MutablePointsReaderUtils.sortByDim(numDataDims, numIndexDims, sortedDim, bytesPerDim, commonPrefixLengths,\n          reader, from, to, scratchBytesRef1, scratchBytesRef2);\n\n      BytesRef comparator = scratchBytesRef1;\n      BytesRef collector = scratchBytesRef2;\n      reader.getValue(from, comparator);\n      int leafCardinality = 1;\n      for (int i = from + 1; i < to; ++i) {\n        reader.getValue(i, collector);\n        for (int dim =0; dim < numDataDims; dim++) {\n          final int start = dim * bytesPerDim + commonPrefixLengths[dim];\n          final int end = dim * bytesPerDim + bytesPerDim;\n          if (Arrays.mismatch(collector.bytes, collector.offset + start, collector.offset + end,\n              comparator.bytes, comparator.offset + start, comparator.offset + end) != -1) {\n            leafCardinality++;\n            BytesRef scratch = collector;\n            collector = comparator;\n            comparator = scratch;\n            break;\n          }\n        }\n      }\n      // Save the block file pointer:\n      leafBlockFPs[nodeID - leafNodeOffset] = out.getFilePointer();\n\n      assert scratchOut.size() == 0;\n\n      // Write doc IDs\n      int[] docIDs = spareDocIds;\n      for (int i = from; i < to; ++i) {\n        docIDs[i - from] = reader.getDocID(i);\n      }\n      //System.out.println(\"writeLeafBlock pos=\" + out.getFilePointer());\n      writeLeafBlockDocs(scratchOut, docIDs, 0, count);\n\n      // Write the common prefixes:\n      reader.getValue(from, scratchBytesRef1);\n      System.arraycopy(scratchBytesRef1.bytes, scratchBytesRef1.offset, scratch1, 0, packedBytesLength);\n      writeCommonPrefixes(scratchOut, commonPrefixLengths, scratch1);\n\n      // Write the full values:\n      IntFunction<BytesRef> packedValues = new IntFunction<BytesRef>() {\n        @Override\n        public BytesRef apply(int i) {\n          reader.getValue(from + i, scratchBytesRef1);\n          return scratchBytesRef1;\n        }\n      };\n      assert valuesInOrderAndBounds(count, sortedDim, minPackedValue, maxPackedValue, packedValues,\n          docIDs, 0);\n      writeLeafBlockPackedValues(scratchOut, commonPrefixLengths, count, sortedDim, packedValues, leafCardinality);\n      scratchOut.copyTo(out);\n      scratchOut.reset();\n    } else {\n      // inner node\n\n      final int splitDim;\n      // compute the split dimension and partition around it\n      if (numIndexDims == 1) {\n        splitDim = 0;\n      } else {\n        // for dimensions > 2 we recompute the bounds for the current inner node to help the algorithm choose best\n        // split dimensions. Because it is an expensive operation, the frequency we recompute the bounds is given\n        // by SPLITS_BEFORE_EXACT_BOUNDS.\n        if (nodeID > 1 && numIndexDims > 2 && Arrays.stream(parentSplits).sum() % SPLITS_BEFORE_EXACT_BOUNDS == 0) {\n          computePackedValueBounds(reader, from, to, minPackedValue, maxPackedValue, scratchBytesRef1);\n        }\n        splitDim = split(minPackedValue, maxPackedValue, parentSplits);\n      }\n\n      final int mid = (from + to + 1) >>> 1;\n\n      int commonPrefixLen = Arrays.mismatch(minPackedValue, splitDim * bytesPerDim,\n          splitDim * bytesPerDim + bytesPerDim, maxPackedValue, splitDim * bytesPerDim,\n          splitDim * bytesPerDim + bytesPerDim);\n      if (commonPrefixLen == -1) {\n        commonPrefixLen = bytesPerDim;\n      }\n\n      MutablePointsReaderUtils.partition(numDataDims, numIndexDims, maxDoc, splitDim, bytesPerDim, commonPrefixLen,\n          reader, from, to, mid, scratchBytesRef1, scratchBytesRef2);\n\n      // set the split value\n      final int address = nodeID * (1+bytesPerDim);\n      splitPackedValues[address] = (byte) splitDim;\n      reader.getValue(mid, scratchBytesRef1);\n      System.arraycopy(scratchBytesRef1.bytes, scratchBytesRef1.offset + splitDim * bytesPerDim, splitPackedValues, address + 1, bytesPerDim);\n\n      byte[] minSplitPackedValue = ArrayUtil.copyOfSubArray(minPackedValue, 0, packedIndexBytesLength);\n      byte[] maxSplitPackedValue = ArrayUtil.copyOfSubArray(maxPackedValue, 0, packedIndexBytesLength);\n      System.arraycopy(scratchBytesRef1.bytes, scratchBytesRef1.offset + splitDim * bytesPerDim,\n          minSplitPackedValue, splitDim * bytesPerDim, bytesPerDim);\n      System.arraycopy(scratchBytesRef1.bytes, scratchBytesRef1.offset + splitDim * bytesPerDim,\n          maxSplitPackedValue, splitDim * bytesPerDim, bytesPerDim);\n\n      // recurse\n      parentSplits[splitDim]++;\n      build(nodeID * 2, leafNodeOffset, reader, from, mid, out,\n          minPackedValue, maxSplitPackedValue, parentSplits,\n          splitPackedValues, leafBlockFPs, spareDocIds);\n      build(nodeID * 2 + 1, leafNodeOffset, reader, mid, to, out,\n          minSplitPackedValue, maxPackedValue, parentSplits,\n          splitPackedValues, leafBlockFPs, spareDocIds);\n      parentSplits[splitDim]--;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"125e5eeb7e933deec0cc0510c2368fe1ec7c36ce","date":1589215155,"type":5,"author":"Ignacio Vera","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#build(int,int,MutablePointValues,int,int,IndexOutput,byte[],byte[],int[],byte[],byte[],long[],int[]).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/util/bkd/BKDWriter#build(int,int,int,MutablePointValues,int,int,IndexOutput,byte[],byte[],int[],byte[],long[],int[]).mjava","sourceNew":"  /* Recursively reorders the provided reader and writes the bkd-tree on the fly; this method is used\n   * when we are writing a new segment directly from IndexWriter's indexing buffer (MutablePointsReader). */\n  private void build(int leavesOffset, int numLeaves,\n                     MutablePointValues reader, int from, int to,\n                     IndexOutput out,\n                     byte[] minPackedValue, byte[] maxPackedValue,\n                     int[] parentSplits,\n                     byte[] splitPackedValues,\n                     byte[] splitDimensionValues,\n                     long[] leafBlockFPs,\n                     int[] spareDocIds) throws IOException {\n\n    if (numLeaves == 1) {\n      // leaf node\n      final int count = to - from;\n      assert count <= maxPointsInLeafNode;\n\n      // Compute common prefixes\n      Arrays.fill(commonPrefixLengths, bytesPerDim);\n      reader.getValue(from, scratchBytesRef1);\n      for (int i = from + 1; i < to; ++i) {\n        reader.getValue(i, scratchBytesRef2);\n        for (int dim=0;dim<numDataDims;dim++) {\n          final int offset = dim * bytesPerDim;\n          int dimensionPrefixLength = commonPrefixLengths[dim];\n          commonPrefixLengths[dim] = Arrays.mismatch(scratchBytesRef1.bytes, scratchBytesRef1.offset + offset,\n              scratchBytesRef1.offset + offset + dimensionPrefixLength,\n              scratchBytesRef2.bytes, scratchBytesRef2.offset + offset,\n              scratchBytesRef2.offset + offset + dimensionPrefixLength);\n          if (commonPrefixLengths[dim] == -1) {\n            commonPrefixLengths[dim] = dimensionPrefixLength;\n          }\n        }\n      }\n\n      // Find the dimension that has the least number of unique bytes at commonPrefixLengths[dim]\n      FixedBitSet[] usedBytes = new FixedBitSet[numDataDims];\n      for (int dim = 0; dim < numDataDims; ++dim) {\n        if (commonPrefixLengths[dim] < bytesPerDim) {\n          usedBytes[dim] = new FixedBitSet(256);\n        }\n      }\n      for (int i = from + 1; i < to; ++i) {\n        for (int dim=0;dim<numDataDims;dim++) {\n          if (usedBytes[dim] != null) {\n            byte b = reader.getByteAt(i, dim * bytesPerDim + commonPrefixLengths[dim]);\n            usedBytes[dim].set(Byte.toUnsignedInt(b));\n          }\n        }\n      }\n      int sortedDim = 0;\n      int sortedDimCardinality = Integer.MAX_VALUE;\n      for (int dim = 0; dim < numDataDims; ++dim) {\n        if (usedBytes[dim] != null) {\n          final int cardinality = usedBytes[dim].cardinality();\n          if (cardinality < sortedDimCardinality) {\n            sortedDim = dim;\n            sortedDimCardinality = cardinality;\n          }\n        }\n      }\n\n      // sort by sortedDim\n      MutablePointsReaderUtils.sortByDim(numDataDims, numIndexDims, sortedDim, bytesPerDim, commonPrefixLengths,\n          reader, from, to, scratchBytesRef1, scratchBytesRef2);\n\n      BytesRef comparator = scratchBytesRef1;\n      BytesRef collector = scratchBytesRef2;\n      reader.getValue(from, comparator);\n      int leafCardinality = 1;\n      for (int i = from + 1; i < to; ++i) {\n        reader.getValue(i, collector);\n        for (int dim =0; dim < numDataDims; dim++) {\n          final int start = dim * bytesPerDim + commonPrefixLengths[dim];\n          final int end = dim * bytesPerDim + bytesPerDim;\n          if (Arrays.mismatch(collector.bytes, collector.offset + start, collector.offset + end,\n              comparator.bytes, comparator.offset + start, comparator.offset + end) != -1) {\n            leafCardinality++;\n            BytesRef scratch = collector;\n            collector = comparator;\n            comparator = scratch;\n            break;\n          }\n        }\n      }\n      // Save the block file pointer:\n      leafBlockFPs[leavesOffset] = out.getFilePointer();\n\n      assert scratchOut.size() == 0;\n\n      // Write doc IDs\n      int[] docIDs = spareDocIds;\n      for (int i = from; i < to; ++i) {\n        docIDs[i - from] = reader.getDocID(i);\n      }\n      //System.out.println(\"writeLeafBlock pos=\" + out.getFilePointer());\n      writeLeafBlockDocs(scratchOut, docIDs, 0, count);\n\n      // Write the common prefixes:\n      reader.getValue(from, scratchBytesRef1);\n      System.arraycopy(scratchBytesRef1.bytes, scratchBytesRef1.offset, scratch1, 0, packedBytesLength);\n      writeCommonPrefixes(scratchOut, commonPrefixLengths, scratch1);\n\n      // Write the full values:\n      IntFunction<BytesRef> packedValues = new IntFunction<BytesRef>() {\n        @Override\n        public BytesRef apply(int i) {\n          reader.getValue(from + i, scratchBytesRef1);\n          return scratchBytesRef1;\n        }\n      };\n      assert valuesInOrderAndBounds(count, sortedDim, minPackedValue, maxPackedValue, packedValues,\n          docIDs, 0);\n      writeLeafBlockPackedValues(scratchOut, commonPrefixLengths, count, sortedDim, packedValues, leafCardinality);\n      scratchOut.copyTo(out);\n      scratchOut.reset();\n    } else {\n      // inner node\n\n      final int splitDim;\n      // compute the split dimension and partition around it\n      if (numIndexDims == 1) {\n        splitDim = 0;\n      } else {\n        // for dimensions > 2 we recompute the bounds for the current inner node to help the algorithm choose best\n        // split dimensions. Because it is an expensive operation, the frequency we recompute the bounds is given\n        // by SPLITS_BEFORE_EXACT_BOUNDS.\n        if (numLeaves != leafBlockFPs.length && numIndexDims > 2 && Arrays.stream(parentSplits).sum() % SPLITS_BEFORE_EXACT_BOUNDS == 0) {\n          computePackedValueBounds(reader, from, to, minPackedValue, maxPackedValue, scratchBytesRef1);\n        }\n        splitDim = split(minPackedValue, maxPackedValue, parentSplits);\n      }\n\n      // How many leaves will be in the left tree:\n      int numLeftLeafNodes = getNumLeftLeafNodes(numLeaves);\n      // How many points will be in the left tree:\n      final int mid = from + numLeftLeafNodes * maxPointsInLeafNode;\n\n      int commonPrefixLen = Arrays.mismatch(minPackedValue, splitDim * bytesPerDim,\n          splitDim * bytesPerDim + bytesPerDim, maxPackedValue, splitDim * bytesPerDim,\n          splitDim * bytesPerDim + bytesPerDim);\n      if (commonPrefixLen == -1) {\n        commonPrefixLen = bytesPerDim;\n      }\n\n      MutablePointsReaderUtils.partition(numDataDims, numIndexDims, maxDoc, splitDim, bytesPerDim, commonPrefixLen,\n          reader, from, to, mid, scratchBytesRef1, scratchBytesRef2);\n\n      final int rightOffset = leavesOffset + numLeftLeafNodes;\n      final int splitOffset = rightOffset - 1;\n      // set the split value\n      final int address = splitOffset * bytesPerDim;\n      splitDimensionValues[splitOffset] = (byte) splitDim;\n      reader.getValue(mid, scratchBytesRef1);\n      System.arraycopy(scratchBytesRef1.bytes, scratchBytesRef1.offset + splitDim * bytesPerDim, splitPackedValues, address, bytesPerDim);\n\n      byte[] minSplitPackedValue = ArrayUtil.copyOfSubArray(minPackedValue, 0, packedIndexBytesLength);\n      byte[] maxSplitPackedValue = ArrayUtil.copyOfSubArray(maxPackedValue, 0, packedIndexBytesLength);\n      System.arraycopy(scratchBytesRef1.bytes, scratchBytesRef1.offset + splitDim * bytesPerDim,\n          minSplitPackedValue, splitDim * bytesPerDim, bytesPerDim);\n      System.arraycopy(scratchBytesRef1.bytes, scratchBytesRef1.offset + splitDim * bytesPerDim,\n          maxSplitPackedValue, splitDim * bytesPerDim, bytesPerDim);\n\n      // recurse\n      parentSplits[splitDim]++;\n      build(leavesOffset, numLeftLeafNodes, reader, from, mid, out,\n          minPackedValue, maxSplitPackedValue, parentSplits,\n          splitPackedValues, splitDimensionValues, leafBlockFPs, spareDocIds);\n      build(rightOffset, numLeaves - numLeftLeafNodes, reader, mid, to, out,\n          minSplitPackedValue, maxPackedValue, parentSplits,\n          splitPackedValues, splitDimensionValues, leafBlockFPs, spareDocIds);\n      parentSplits[splitDim]--;\n    }\n  }\n\n","sourceOld":"  /* Recursively reorders the provided reader and writes the bkd-tree on the fly; this method is used\n   * when we are writing a new segment directly from IndexWriter's indexing buffer (MutablePointsReader). */\n  private void build(int nodeID, int leavesOffset, int numLeaves,\n                     MutablePointValues reader, int from, int to,\n                     IndexOutput out,\n                     byte[] minPackedValue, byte[] maxPackedValue,\n                     int[] parentSplits,\n                     byte[] splitPackedValues,\n                     long[] leafBlockFPs,\n                     int[] spareDocIds) throws IOException {\n\n    if (numLeaves == 1) {\n      // leaf node\n      final int count = to - from;\n      assert count <= maxPointsInLeafNode;\n\n      // Compute common prefixes\n      Arrays.fill(commonPrefixLengths, bytesPerDim);\n      reader.getValue(from, scratchBytesRef1);\n      for (int i = from + 1; i < to; ++i) {\n        reader.getValue(i, scratchBytesRef2);\n        for (int dim=0;dim<numDataDims;dim++) {\n          final int offset = dim * bytesPerDim;\n          int dimensionPrefixLength = commonPrefixLengths[dim];\n          commonPrefixLengths[dim] = Arrays.mismatch(scratchBytesRef1.bytes, scratchBytesRef1.offset + offset,\n              scratchBytesRef1.offset + offset + dimensionPrefixLength,\n              scratchBytesRef2.bytes, scratchBytesRef2.offset + offset,\n              scratchBytesRef2.offset + offset + dimensionPrefixLength);\n          if (commonPrefixLengths[dim] == -1) {\n            commonPrefixLengths[dim] = dimensionPrefixLength;\n          }\n        }\n      }\n\n      // Find the dimension that has the least number of unique bytes at commonPrefixLengths[dim]\n      FixedBitSet[] usedBytes = new FixedBitSet[numDataDims];\n      for (int dim = 0; dim < numDataDims; ++dim) {\n        if (commonPrefixLengths[dim] < bytesPerDim) {\n          usedBytes[dim] = new FixedBitSet(256);\n        }\n      }\n      for (int i = from + 1; i < to; ++i) {\n        for (int dim=0;dim<numDataDims;dim++) {\n          if (usedBytes[dim] != null) {\n            byte b = reader.getByteAt(i, dim * bytesPerDim + commonPrefixLengths[dim]);\n            usedBytes[dim].set(Byte.toUnsignedInt(b));\n          }\n        }\n      }\n      int sortedDim = 0;\n      int sortedDimCardinality = Integer.MAX_VALUE;\n      for (int dim = 0; dim < numDataDims; ++dim) {\n        if (usedBytes[dim] != null) {\n          final int cardinality = usedBytes[dim].cardinality();\n          if (cardinality < sortedDimCardinality) {\n            sortedDim = dim;\n            sortedDimCardinality = cardinality;\n          }\n        }\n      }\n\n      // sort by sortedDim\n      MutablePointsReaderUtils.sortByDim(numDataDims, numIndexDims, sortedDim, bytesPerDim, commonPrefixLengths,\n          reader, from, to, scratchBytesRef1, scratchBytesRef2);\n\n      BytesRef comparator = scratchBytesRef1;\n      BytesRef collector = scratchBytesRef2;\n      reader.getValue(from, comparator);\n      int leafCardinality = 1;\n      for (int i = from + 1; i < to; ++i) {\n        reader.getValue(i, collector);\n        for (int dim =0; dim < numDataDims; dim++) {\n          final int start = dim * bytesPerDim + commonPrefixLengths[dim];\n          final int end = dim * bytesPerDim + bytesPerDim;\n          if (Arrays.mismatch(collector.bytes, collector.offset + start, collector.offset + end,\n              comparator.bytes, comparator.offset + start, comparator.offset + end) != -1) {\n            leafCardinality++;\n            BytesRef scratch = collector;\n            collector = comparator;\n            comparator = scratch;\n            break;\n          }\n        }\n      }\n      // Save the block file pointer:\n      leafBlockFPs[leavesOffset] = out.getFilePointer();\n\n      assert scratchOut.size() == 0;\n\n      // Write doc IDs\n      int[] docIDs = spareDocIds;\n      for (int i = from; i < to; ++i) {\n        docIDs[i - from] = reader.getDocID(i);\n      }\n      //System.out.println(\"writeLeafBlock pos=\" + out.getFilePointer());\n      writeLeafBlockDocs(scratchOut, docIDs, 0, count);\n\n      // Write the common prefixes:\n      reader.getValue(from, scratchBytesRef1);\n      System.arraycopy(scratchBytesRef1.bytes, scratchBytesRef1.offset, scratch1, 0, packedBytesLength);\n      writeCommonPrefixes(scratchOut, commonPrefixLengths, scratch1);\n\n      // Write the full values:\n      IntFunction<BytesRef> packedValues = new IntFunction<BytesRef>() {\n        @Override\n        public BytesRef apply(int i) {\n          reader.getValue(from + i, scratchBytesRef1);\n          return scratchBytesRef1;\n        }\n      };\n      assert valuesInOrderAndBounds(count, sortedDim, minPackedValue, maxPackedValue, packedValues,\n          docIDs, 0);\n      writeLeafBlockPackedValues(scratchOut, commonPrefixLengths, count, sortedDim, packedValues, leafCardinality);\n      scratchOut.copyTo(out);\n      scratchOut.reset();\n    } else {\n      // inner node\n\n      final int splitDim;\n      // compute the split dimension and partition around it\n      if (numIndexDims == 1) {\n        splitDim = 0;\n      } else {\n        // for dimensions > 2 we recompute the bounds for the current inner node to help the algorithm choose best\n        // split dimensions. Because it is an expensive operation, the frequency we recompute the bounds is given\n        // by SPLITS_BEFORE_EXACT_BOUNDS.\n        if (nodeID > 1 && numIndexDims > 2 && Arrays.stream(parentSplits).sum() % SPLITS_BEFORE_EXACT_BOUNDS == 0) {\n          computePackedValueBounds(reader, from, to, minPackedValue, maxPackedValue, scratchBytesRef1);\n        }\n        splitDim = split(minPackedValue, maxPackedValue, parentSplits);\n      }\n\n      // How many leaves will be in the left tree:\n      int numLeftLeafNodes = getNumLeftLeafNodes(numLeaves);\n      // How many points will be in the left tree:\n      final int mid = from + numLeftLeafNodes * maxPointsInLeafNode;\n\n      int commonPrefixLen = Arrays.mismatch(minPackedValue, splitDim * bytesPerDim,\n          splitDim * bytesPerDim + bytesPerDim, maxPackedValue, splitDim * bytesPerDim,\n          splitDim * bytesPerDim + bytesPerDim);\n      if (commonPrefixLen == -1) {\n        commonPrefixLen = bytesPerDim;\n      }\n\n      MutablePointsReaderUtils.partition(numDataDims, numIndexDims, maxDoc, splitDim, bytesPerDim, commonPrefixLen,\n          reader, from, to, mid, scratchBytesRef1, scratchBytesRef2);\n\n      // set the split value\n      final int address = nodeID * (1+bytesPerDim);\n      splitPackedValues[address] = (byte) splitDim;\n      reader.getValue(mid, scratchBytesRef1);\n      System.arraycopy(scratchBytesRef1.bytes, scratchBytesRef1.offset + splitDim * bytesPerDim, splitPackedValues, address + 1, bytesPerDim);\n\n      byte[] minSplitPackedValue = ArrayUtil.copyOfSubArray(minPackedValue, 0, packedIndexBytesLength);\n      byte[] maxSplitPackedValue = ArrayUtil.copyOfSubArray(maxPackedValue, 0, packedIndexBytesLength);\n      System.arraycopy(scratchBytesRef1.bytes, scratchBytesRef1.offset + splitDim * bytesPerDim,\n          minSplitPackedValue, splitDim * bytesPerDim, bytesPerDim);\n      System.arraycopy(scratchBytesRef1.bytes, scratchBytesRef1.offset + splitDim * bytesPerDim,\n          maxSplitPackedValue, splitDim * bytesPerDim, bytesPerDim);\n\n      // recurse\n      parentSplits[splitDim]++;\n      build(nodeID * 2, leavesOffset, numLeftLeafNodes, reader, from, mid, out,\n          minPackedValue, maxSplitPackedValue, parentSplits,\n          splitPackedValues, leafBlockFPs, spareDocIds);\n      build(nodeID * 2 + 1, leavesOffset + numLeftLeafNodes, numLeaves - numLeftLeafNodes, reader, mid, to, out,\n          minSplitPackedValue, maxPackedValue, parentSplits,\n          splitPackedValues, leafBlockFPs, spareDocIds);\n      parentSplits[splitDim]--;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"125e5eeb7e933deec0cc0510c2368fe1ec7c36ce":["d3929a60a731a8848bb9bc0bbfd3c5e3d59195e7"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"d3929a60a731a8848bb9bc0bbfd3c5e3d59195e7":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["125e5eeb7e933deec0cc0510c2368fe1ec7c36ce"]},"commit2Childs":{"125e5eeb7e933deec0cc0510c2368fe1ec7c36ce":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["d3929a60a731a8848bb9bc0bbfd3c5e3d59195e7"],"d3929a60a731a8848bb9bc0bbfd3c5e3d59195e7":["125e5eeb7e933deec0cc0510c2368fe1ec7c36ce"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}