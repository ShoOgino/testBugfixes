{"path":"lucene/analysis/common/src/java/org/apache/lucene/analysis/util/CharTokenizer#incrementToken().mjava","commits":[{"id":"b89678825b68eccaf09e6ab71675fc0b0af1e099","date":1334669779,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/util/CharTokenizer#incrementToken().mjava","pathOld":"modules/analysis/common/src/java/org/apache/lucene/analysis/util/CharTokenizer#incrementToken().mjava","sourceNew":"  @Override\n  public final boolean incrementToken() throws IOException {\n    clearAttributes();\n    int length = 0;\n    int start = -1; // this variable is always initialized\n    int end = -1;\n    char[] buffer = termAtt.buffer();\n    while (true) {\n      if (bufferIndex >= dataLen) {\n        offset += dataLen;\n        if(!charUtils.fill(ioBuffer, input)) { // read supplementary char aware with CharacterUtils\n          dataLen = 0; // so next offset += dataLen won't decrement offset\n          if (length > 0) {\n            break;\n          } else {\n            finalOffset = correctOffset(offset);\n            return false;\n          }\n        }\n        dataLen = ioBuffer.getLength();\n        bufferIndex = 0;\n      }\n      // use CharacterUtils here to support < 3.1 UTF-16 code unit behavior if the char based methods are gone\n      final int c = charUtils.codePointAt(ioBuffer.getBuffer(), bufferIndex);\n      final int charCount = Character.charCount(c);\n      bufferIndex += charCount;\n\n      if (isTokenChar(c)) {               // if it's a token char\n        if (length == 0) {                // start of token\n          assert start == -1;\n          start = offset + bufferIndex - charCount;\n          end = start;\n        } else if (length >= buffer.length-1) { // check if a supplementary could run out of bounds\n          buffer = termAtt.resizeBuffer(2+length); // make sure a supplementary fits in the buffer\n        }\n        end += charCount;\n        length += Character.toChars(normalize(c), buffer, length); // buffer it, normalized\n        if (length >= MAX_WORD_LEN) // buffer overflow! make sure to check for >= surrogate pair could break == test\n          break;\n      } else if (length > 0)             // at non-Letter w/ chars\n        break;                           // return 'em\n    }\n\n    termAtt.setLength(length);\n    assert start != -1;\n    offsetAtt.setOffset(correctOffset(start), finalOffset = correctOffset(end));\n    return true;\n    \n  }\n\n","sourceOld":"  @Override\n  public final boolean incrementToken() throws IOException {\n    clearAttributes();\n    int length = 0;\n    int start = -1; // this variable is always initialized\n    int end = -1;\n    char[] buffer = termAtt.buffer();\n    while (true) {\n      if (bufferIndex >= dataLen) {\n        offset += dataLen;\n        if(!charUtils.fill(ioBuffer, input)) { // read supplementary char aware with CharacterUtils\n          dataLen = 0; // so next offset += dataLen won't decrement offset\n          if (length > 0) {\n            break;\n          } else {\n            finalOffset = correctOffset(offset);\n            return false;\n          }\n        }\n        dataLen = ioBuffer.getLength();\n        bufferIndex = 0;\n      }\n      // use CharacterUtils here to support < 3.1 UTF-16 code unit behavior if the char based methods are gone\n      final int c = charUtils.codePointAt(ioBuffer.getBuffer(), bufferIndex);\n      final int charCount = Character.charCount(c);\n      bufferIndex += charCount;\n\n      if (isTokenChar(c)) {               // if it's a token char\n        if (length == 0) {                // start of token\n          assert start == -1;\n          start = offset + bufferIndex - charCount;\n          end = start;\n        } else if (length >= buffer.length-1) { // check if a supplementary could run out of bounds\n          buffer = termAtt.resizeBuffer(2+length); // make sure a supplementary fits in the buffer\n        }\n        end += charCount;\n        length += Character.toChars(normalize(c), buffer, length); // buffer it, normalized\n        if (length >= MAX_WORD_LEN) // buffer overflow! make sure to check for >= surrogate pair could break == test\n          break;\n      } else if (length > 0)             // at non-Letter w/ chars\n        break;                           // return 'em\n    }\n\n    termAtt.setLength(length);\n    assert start != -1;\n    offsetAtt.setOffset(correctOffset(start), finalOffset = correctOffset(end));\n    return true;\n    \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"bd095de1c7ac6b6ab3a330b5fbe8cb37e4f34704","date":1371043069,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/util/CharTokenizer#incrementToken().mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/util/CharTokenizer#incrementToken().mjava","sourceNew":"  @Override\n  public final boolean incrementToken() throws IOException {\n    clearAttributes();\n    int length = 0;\n    int start = -1; // this variable is always initialized\n    int end = -1;\n    char[] buffer = termAtt.buffer();\n    while (true) {\n      if (bufferIndex >= dataLen) {\n        offset += dataLen;\n        charUtils.fill(ioBuffer, input); // read supplementary char aware with CharacterUtils\n        if (ioBuffer.getLength() == 0) {\n          dataLen = 0; // so next offset += dataLen won't decrement offset\n          if (length > 0) {\n            break;\n          } else {\n            finalOffset = correctOffset(offset);\n            return false;\n          }\n        }\n        dataLen = ioBuffer.getLength();\n        bufferIndex = 0;\n      }\n      // use CharacterUtils here to support < 3.1 UTF-16 code unit behavior if the char based methods are gone\n      final int c = charUtils.codePointAt(ioBuffer.getBuffer(), bufferIndex, ioBuffer.getLength());\n      final int charCount = Character.charCount(c);\n      bufferIndex += charCount;\n\n      if (isTokenChar(c)) {               // if it's a token char\n        if (length == 0) {                // start of token\n          assert start == -1;\n          start = offset + bufferIndex - charCount;\n          end = start;\n        } else if (length >= buffer.length-1) { // check if a supplementary could run out of bounds\n          buffer = termAtt.resizeBuffer(2+length); // make sure a supplementary fits in the buffer\n        }\n        end += charCount;\n        length += Character.toChars(normalize(c), buffer, length); // buffer it, normalized\n        if (length >= MAX_WORD_LEN) // buffer overflow! make sure to check for >= surrogate pair could break == test\n          break;\n      } else if (length > 0)             // at non-Letter w/ chars\n        break;                           // return 'em\n    }\n\n    termAtt.setLength(length);\n    assert start != -1;\n    offsetAtt.setOffset(correctOffset(start), finalOffset = correctOffset(end));\n    return true;\n    \n  }\n\n","sourceOld":"  @Override\n  public final boolean incrementToken() throws IOException {\n    clearAttributes();\n    int length = 0;\n    int start = -1; // this variable is always initialized\n    int end = -1;\n    char[] buffer = termAtt.buffer();\n    while (true) {\n      if (bufferIndex >= dataLen) {\n        offset += dataLen;\n        if(!charUtils.fill(ioBuffer, input)) { // read supplementary char aware with CharacterUtils\n          dataLen = 0; // so next offset += dataLen won't decrement offset\n          if (length > 0) {\n            break;\n          } else {\n            finalOffset = correctOffset(offset);\n            return false;\n          }\n        }\n        dataLen = ioBuffer.getLength();\n        bufferIndex = 0;\n      }\n      // use CharacterUtils here to support < 3.1 UTF-16 code unit behavior if the char based methods are gone\n      final int c = charUtils.codePointAt(ioBuffer.getBuffer(), bufferIndex);\n      final int charCount = Character.charCount(c);\n      bufferIndex += charCount;\n\n      if (isTokenChar(c)) {               // if it's a token char\n        if (length == 0) {                // start of token\n          assert start == -1;\n          start = offset + bufferIndex - charCount;\n          end = start;\n        } else if (length >= buffer.length-1) { // check if a supplementary could run out of bounds\n          buffer = termAtt.resizeBuffer(2+length); // make sure a supplementary fits in the buffer\n        }\n        end += charCount;\n        length += Character.toChars(normalize(c), buffer, length); // buffer it, normalized\n        if (length >= MAX_WORD_LEN) // buffer overflow! make sure to check for >= surrogate pair could break == test\n          break;\n      } else if (length > 0)             // at non-Letter w/ chars\n        break;                           // return 'em\n    }\n\n    termAtt.setLength(length);\n    assert start != -1;\n    offsetAtt.setOffset(correctOffset(start), finalOffset = correctOffset(end));\n    return true;\n    \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fba4cd6a5aae0bc17cc1cbf1e84b0ae32ee039dc","date":1465824262,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/util/CharTokenizer#incrementToken().mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/util/CharTokenizer#incrementToken().mjava","sourceNew":"  @Override\n  public final boolean incrementToken() throws IOException {\n    clearAttributes();\n    int length = 0;\n    int start = -1; // this variable is always initialized\n    int end = -1;\n    char[] buffer = termAtt.buffer();\n    while (true) {\n      if (bufferIndex >= dataLen) {\n        offset += dataLen;\n        CharacterUtils.fill(ioBuffer, input); // read supplementary char aware with CharacterUtils\n        if (ioBuffer.getLength() == 0) {\n          dataLen = 0; // so next offset += dataLen won't decrement offset\n          if (length > 0) {\n            break;\n          } else {\n            finalOffset = correctOffset(offset);\n            return false;\n          }\n        }\n        dataLen = ioBuffer.getLength();\n        bufferIndex = 0;\n      }\n      // use CharacterUtils here to support < 3.1 UTF-16 code unit behavior if the char based methods are gone\n      final int c = Character.codePointAt(ioBuffer.getBuffer(), bufferIndex, ioBuffer.getLength());\n      final int charCount = Character.charCount(c);\n      bufferIndex += charCount;\n\n      if (isTokenChar(c)) {               // if it's a token char\n        if (length == 0) {                // start of token\n          assert start == -1;\n          start = offset + bufferIndex - charCount;\n          end = start;\n        } else if (length >= buffer.length-1) { // check if a supplementary could run out of bounds\n          buffer = termAtt.resizeBuffer(2+length); // make sure a supplementary fits in the buffer\n        }\n        end += charCount;\n        length += Character.toChars(normalize(c), buffer, length); // buffer it, normalized\n        if (length >= MAX_WORD_LEN) // buffer overflow! make sure to check for >= surrogate pair could break == test\n          break;\n      } else if (length > 0)             // at non-Letter w/ chars\n        break;                           // return 'em\n    }\n\n    termAtt.setLength(length);\n    assert start != -1;\n    offsetAtt.setOffset(correctOffset(start), finalOffset = correctOffset(end));\n    return true;\n    \n  }\n\n","sourceOld":"  @Override\n  public final boolean incrementToken() throws IOException {\n    clearAttributes();\n    int length = 0;\n    int start = -1; // this variable is always initialized\n    int end = -1;\n    char[] buffer = termAtt.buffer();\n    while (true) {\n      if (bufferIndex >= dataLen) {\n        offset += dataLen;\n        charUtils.fill(ioBuffer, input); // read supplementary char aware with CharacterUtils\n        if (ioBuffer.getLength() == 0) {\n          dataLen = 0; // so next offset += dataLen won't decrement offset\n          if (length > 0) {\n            break;\n          } else {\n            finalOffset = correctOffset(offset);\n            return false;\n          }\n        }\n        dataLen = ioBuffer.getLength();\n        bufferIndex = 0;\n      }\n      // use CharacterUtils here to support < 3.1 UTF-16 code unit behavior if the char based methods are gone\n      final int c = charUtils.codePointAt(ioBuffer.getBuffer(), bufferIndex, ioBuffer.getLength());\n      final int charCount = Character.charCount(c);\n      bufferIndex += charCount;\n\n      if (isTokenChar(c)) {               // if it's a token char\n        if (length == 0) {                // start of token\n          assert start == -1;\n          start = offset + bufferIndex - charCount;\n          end = start;\n        } else if (length >= buffer.length-1) { // check if a supplementary could run out of bounds\n          buffer = termAtt.resizeBuffer(2+length); // make sure a supplementary fits in the buffer\n        }\n        end += charCount;\n        length += Character.toChars(normalize(c), buffer, length); // buffer it, normalized\n        if (length >= MAX_WORD_LEN) // buffer overflow! make sure to check for >= surrogate pair could break == test\n          break;\n      } else if (length > 0)             // at non-Letter w/ chars\n        break;                           // return 'em\n    }\n\n    termAtt.setLength(length);\n    assert start != -1;\n    offsetAtt.setOffset(correctOffset(start), finalOffset = correctOffset(end));\n    return true;\n    \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"57dc82c7b33cd580e7ab5179019bc78f3d7f8e79","date":1465913303,"type":3,"author":"Noble Paul","isMerge":true,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/util/CharTokenizer#incrementToken().mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/util/CharTokenizer#incrementToken().mjava","sourceNew":"  @Override\n  public final boolean incrementToken() throws IOException {\n    clearAttributes();\n    int length = 0;\n    int start = -1; // this variable is always initialized\n    int end = -1;\n    char[] buffer = termAtt.buffer();\n    while (true) {\n      if (bufferIndex >= dataLen) {\n        offset += dataLen;\n        CharacterUtils.fill(ioBuffer, input); // read supplementary char aware with CharacterUtils\n        if (ioBuffer.getLength() == 0) {\n          dataLen = 0; // so next offset += dataLen won't decrement offset\n          if (length > 0) {\n            break;\n          } else {\n            finalOffset = correctOffset(offset);\n            return false;\n          }\n        }\n        dataLen = ioBuffer.getLength();\n        bufferIndex = 0;\n      }\n      // use CharacterUtils here to support < 3.1 UTF-16 code unit behavior if the char based methods are gone\n      final int c = Character.codePointAt(ioBuffer.getBuffer(), bufferIndex, ioBuffer.getLength());\n      final int charCount = Character.charCount(c);\n      bufferIndex += charCount;\n\n      if (isTokenChar(c)) {               // if it's a token char\n        if (length == 0) {                // start of token\n          assert start == -1;\n          start = offset + bufferIndex - charCount;\n          end = start;\n        } else if (length >= buffer.length-1) { // check if a supplementary could run out of bounds\n          buffer = termAtt.resizeBuffer(2+length); // make sure a supplementary fits in the buffer\n        }\n        end += charCount;\n        length += Character.toChars(normalize(c), buffer, length); // buffer it, normalized\n        if (length >= MAX_WORD_LEN) // buffer overflow! make sure to check for >= surrogate pair could break == test\n          break;\n      } else if (length > 0)             // at non-Letter w/ chars\n        break;                           // return 'em\n    }\n\n    termAtt.setLength(length);\n    assert start != -1;\n    offsetAtt.setOffset(correctOffset(start), finalOffset = correctOffset(end));\n    return true;\n    \n  }\n\n","sourceOld":"  @Override\n  public final boolean incrementToken() throws IOException {\n    clearAttributes();\n    int length = 0;\n    int start = -1; // this variable is always initialized\n    int end = -1;\n    char[] buffer = termAtt.buffer();\n    while (true) {\n      if (bufferIndex >= dataLen) {\n        offset += dataLen;\n        charUtils.fill(ioBuffer, input); // read supplementary char aware with CharacterUtils\n        if (ioBuffer.getLength() == 0) {\n          dataLen = 0; // so next offset += dataLen won't decrement offset\n          if (length > 0) {\n            break;\n          } else {\n            finalOffset = correctOffset(offset);\n            return false;\n          }\n        }\n        dataLen = ioBuffer.getLength();\n        bufferIndex = 0;\n      }\n      // use CharacterUtils here to support < 3.1 UTF-16 code unit behavior if the char based methods are gone\n      final int c = charUtils.codePointAt(ioBuffer.getBuffer(), bufferIndex, ioBuffer.getLength());\n      final int charCount = Character.charCount(c);\n      bufferIndex += charCount;\n\n      if (isTokenChar(c)) {               // if it's a token char\n        if (length == 0) {                // start of token\n          assert start == -1;\n          start = offset + bufferIndex - charCount;\n          end = start;\n        } else if (length >= buffer.length-1) { // check if a supplementary could run out of bounds\n          buffer = termAtt.resizeBuffer(2+length); // make sure a supplementary fits in the buffer\n        }\n        end += charCount;\n        length += Character.toChars(normalize(c), buffer, length); // buffer it, normalized\n        if (length >= MAX_WORD_LEN) // buffer overflow! make sure to check for >= surrogate pair could break == test\n          break;\n      } else if (length > 0)             // at non-Letter w/ chars\n        break;                           // return 'em\n    }\n\n    termAtt.setLength(length);\n    assert start != -1;\n    offsetAtt.setOffset(correctOffset(start), finalOffset = correctOffset(end));\n    return true;\n    \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4cce5816ef15a48a0bc11e5d400497ee4301dd3b","date":1476991456,"type":3,"author":"Kevin Risden","isMerge":true,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/util/CharTokenizer#incrementToken().mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/util/CharTokenizer#incrementToken().mjava","sourceNew":"  @Override\n  public final boolean incrementToken() throws IOException {\n    clearAttributes();\n    int length = 0;\n    int start = -1; // this variable is always initialized\n    int end = -1;\n    char[] buffer = termAtt.buffer();\n    while (true) {\n      if (bufferIndex >= dataLen) {\n        offset += dataLen;\n        CharacterUtils.fill(ioBuffer, input); // read supplementary char aware with CharacterUtils\n        if (ioBuffer.getLength() == 0) {\n          dataLen = 0; // so next offset += dataLen won't decrement offset\n          if (length > 0) {\n            break;\n          } else {\n            finalOffset = correctOffset(offset);\n            return false;\n          }\n        }\n        dataLen = ioBuffer.getLength();\n        bufferIndex = 0;\n      }\n      // use CharacterUtils here to support < 3.1 UTF-16 code unit behavior if the char based methods are gone\n      final int c = Character.codePointAt(ioBuffer.getBuffer(), bufferIndex, ioBuffer.getLength());\n      final int charCount = Character.charCount(c);\n      bufferIndex += charCount;\n\n      if (isTokenChar(c)) {               // if it's a token char\n        if (length == 0) {                // start of token\n          assert start == -1;\n          start = offset + bufferIndex - charCount;\n          end = start;\n        } else if (length >= buffer.length-1) { // check if a supplementary could run out of bounds\n          buffer = termAtt.resizeBuffer(2+length); // make sure a supplementary fits in the buffer\n        }\n        end += charCount;\n        length += Character.toChars(normalize(c), buffer, length); // buffer it, normalized\n        if (length >= MAX_WORD_LEN) // buffer overflow! make sure to check for >= surrogate pair could break == test\n          break;\n      } else if (length > 0)             // at non-Letter w/ chars\n        break;                           // return 'em\n    }\n\n    termAtt.setLength(length);\n    assert start != -1;\n    offsetAtt.setOffset(correctOffset(start), finalOffset = correctOffset(end));\n    return true;\n    \n  }\n\n","sourceOld":"  @Override\n  public final boolean incrementToken() throws IOException {\n    clearAttributes();\n    int length = 0;\n    int start = -1; // this variable is always initialized\n    int end = -1;\n    char[] buffer = termAtt.buffer();\n    while (true) {\n      if (bufferIndex >= dataLen) {\n        offset += dataLen;\n        charUtils.fill(ioBuffer, input); // read supplementary char aware with CharacterUtils\n        if (ioBuffer.getLength() == 0) {\n          dataLen = 0; // so next offset += dataLen won't decrement offset\n          if (length > 0) {\n            break;\n          } else {\n            finalOffset = correctOffset(offset);\n            return false;\n          }\n        }\n        dataLen = ioBuffer.getLength();\n        bufferIndex = 0;\n      }\n      // use CharacterUtils here to support < 3.1 UTF-16 code unit behavior if the char based methods are gone\n      final int c = charUtils.codePointAt(ioBuffer.getBuffer(), bufferIndex, ioBuffer.getLength());\n      final int charCount = Character.charCount(c);\n      bufferIndex += charCount;\n\n      if (isTokenChar(c)) {               // if it's a token char\n        if (length == 0) {                // start of token\n          assert start == -1;\n          start = offset + bufferIndex - charCount;\n          end = start;\n        } else if (length >= buffer.length-1) { // check if a supplementary could run out of bounds\n          buffer = termAtt.resizeBuffer(2+length); // make sure a supplementary fits in the buffer\n        }\n        end += charCount;\n        length += Character.toChars(normalize(c), buffer, length); // buffer it, normalized\n        if (length >= MAX_WORD_LEN) // buffer overflow! make sure to check for >= surrogate pair could break == test\n          break;\n      } else if (length > 0)             // at non-Letter w/ chars\n        break;                           // return 'em\n    }\n\n    termAtt.setLength(length);\n    assert start != -1;\n    offsetAtt.setOffset(correctOffset(start), finalOffset = correctOffset(end));\n    return true;\n    \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"24a98f5fdd23e04f85819dbc63b47a12f7c44311","date":1482439157,"type":3,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/util/CharTokenizer#incrementToken().mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/util/CharTokenizer#incrementToken().mjava","sourceNew":"  @Override\n  public final boolean incrementToken() throws IOException {\n    clearAttributes();\n    int length = 0;\n    int start = -1; // this variable is always initialized\n    int end = -1;\n    char[] buffer = termAtt.buffer();\n    while (true) {\n      if (bufferIndex >= dataLen) {\n        offset += dataLen;\n        CharacterUtils.fill(ioBuffer, input); // read supplementary char aware with CharacterUtils\n        if (ioBuffer.getLength() == 0) {\n          dataLen = 0; // so next offset += dataLen won't decrement offset\n          if (length > 0) {\n            break;\n          } else {\n            finalOffset = correctOffset(offset);\n            return false;\n          }\n        }\n        dataLen = ioBuffer.getLength();\n        bufferIndex = 0;\n      }\n      // use CharacterUtils here to support < 3.1 UTF-16 code unit behavior if the char based methods are gone\n      final int c = Character.codePointAt(ioBuffer.getBuffer(), bufferIndex, ioBuffer.getLength());\n      final int charCount = Character.charCount(c);\n      bufferIndex += charCount;\n\n      if (isTokenChar(c)) {               // if it's a token char\n        if (length == 0) {                // start of token\n          assert start == -1;\n          start = offset + bufferIndex - charCount;\n          end = start;\n        } else if (length >= buffer.length-1) { // check if a supplementary could run out of bounds\n          buffer = termAtt.resizeBuffer(2+length); // make sure a supplementary fits in the buffer\n        }\n        end += charCount;\n        length += Character.toChars(normalize(c), buffer, length); // buffer it, normalized\n        if (length >= MAX_WORD_LEN) { // buffer overflow! make sure to check for >= surrogate pair could break == test\n          break;\n        }\n      } else if (length > 0) {           // at non-Letter w/ chars\n        break;                           // return 'em\n      }\n    }\n\n    termAtt.setLength(length);\n    assert start != -1;\n    offsetAtt.setOffset(correctOffset(start), finalOffset = correctOffset(end));\n    return true;\n    \n  }\n\n","sourceOld":"  @Override\n  public final boolean incrementToken() throws IOException {\n    clearAttributes();\n    int length = 0;\n    int start = -1; // this variable is always initialized\n    int end = -1;\n    char[] buffer = termAtt.buffer();\n    while (true) {\n      if (bufferIndex >= dataLen) {\n        offset += dataLen;\n        CharacterUtils.fill(ioBuffer, input); // read supplementary char aware with CharacterUtils\n        if (ioBuffer.getLength() == 0) {\n          dataLen = 0; // so next offset += dataLen won't decrement offset\n          if (length > 0) {\n            break;\n          } else {\n            finalOffset = correctOffset(offset);\n            return false;\n          }\n        }\n        dataLen = ioBuffer.getLength();\n        bufferIndex = 0;\n      }\n      // use CharacterUtils here to support < 3.1 UTF-16 code unit behavior if the char based methods are gone\n      final int c = Character.codePointAt(ioBuffer.getBuffer(), bufferIndex, ioBuffer.getLength());\n      final int charCount = Character.charCount(c);\n      bufferIndex += charCount;\n\n      if (isTokenChar(c)) {               // if it's a token char\n        if (length == 0) {                // start of token\n          assert start == -1;\n          start = offset + bufferIndex - charCount;\n          end = start;\n        } else if (length >= buffer.length-1) { // check if a supplementary could run out of bounds\n          buffer = termAtt.resizeBuffer(2+length); // make sure a supplementary fits in the buffer\n        }\n        end += charCount;\n        length += Character.toChars(normalize(c), buffer, length); // buffer it, normalized\n        if (length >= MAX_WORD_LEN) // buffer overflow! make sure to check for >= surrogate pair could break == test\n          break;\n      } else if (length > 0)             // at non-Letter w/ chars\n        break;                           // return 'em\n    }\n\n    termAtt.setLength(length);\n    assert start != -1;\n    offsetAtt.setOffset(correctOffset(start), finalOffset = correctOffset(end));\n    return true;\n    \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f03e4bed5023ec3ef93a771b8888cae991cf448d","date":1483469262,"type":3,"author":"Kevin Risden","isMerge":true,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/util/CharTokenizer#incrementToken().mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/util/CharTokenizer#incrementToken().mjava","sourceNew":"  @Override\n  public final boolean incrementToken() throws IOException {\n    clearAttributes();\n    int length = 0;\n    int start = -1; // this variable is always initialized\n    int end = -1;\n    char[] buffer = termAtt.buffer();\n    while (true) {\n      if (bufferIndex >= dataLen) {\n        offset += dataLen;\n        CharacterUtils.fill(ioBuffer, input); // read supplementary char aware with CharacterUtils\n        if (ioBuffer.getLength() == 0) {\n          dataLen = 0; // so next offset += dataLen won't decrement offset\n          if (length > 0) {\n            break;\n          } else {\n            finalOffset = correctOffset(offset);\n            return false;\n          }\n        }\n        dataLen = ioBuffer.getLength();\n        bufferIndex = 0;\n      }\n      // use CharacterUtils here to support < 3.1 UTF-16 code unit behavior if the char based methods are gone\n      final int c = Character.codePointAt(ioBuffer.getBuffer(), bufferIndex, ioBuffer.getLength());\n      final int charCount = Character.charCount(c);\n      bufferIndex += charCount;\n\n      if (isTokenChar(c)) {               // if it's a token char\n        if (length == 0) {                // start of token\n          assert start == -1;\n          start = offset + bufferIndex - charCount;\n          end = start;\n        } else if (length >= buffer.length-1) { // check if a supplementary could run out of bounds\n          buffer = termAtt.resizeBuffer(2+length); // make sure a supplementary fits in the buffer\n        }\n        end += charCount;\n        length += Character.toChars(normalize(c), buffer, length); // buffer it, normalized\n        if (length >= MAX_WORD_LEN) { // buffer overflow! make sure to check for >= surrogate pair could break == test\n          break;\n        }\n      } else if (length > 0) {           // at non-Letter w/ chars\n        break;                           // return 'em\n      }\n    }\n\n    termAtt.setLength(length);\n    assert start != -1;\n    offsetAtt.setOffset(correctOffset(start), finalOffset = correctOffset(end));\n    return true;\n    \n  }\n\n","sourceOld":"  @Override\n  public final boolean incrementToken() throws IOException {\n    clearAttributes();\n    int length = 0;\n    int start = -1; // this variable is always initialized\n    int end = -1;\n    char[] buffer = termAtt.buffer();\n    while (true) {\n      if (bufferIndex >= dataLen) {\n        offset += dataLen;\n        CharacterUtils.fill(ioBuffer, input); // read supplementary char aware with CharacterUtils\n        if (ioBuffer.getLength() == 0) {\n          dataLen = 0; // so next offset += dataLen won't decrement offset\n          if (length > 0) {\n            break;\n          } else {\n            finalOffset = correctOffset(offset);\n            return false;\n          }\n        }\n        dataLen = ioBuffer.getLength();\n        bufferIndex = 0;\n      }\n      // use CharacterUtils here to support < 3.1 UTF-16 code unit behavior if the char based methods are gone\n      final int c = Character.codePointAt(ioBuffer.getBuffer(), bufferIndex, ioBuffer.getLength());\n      final int charCount = Character.charCount(c);\n      bufferIndex += charCount;\n\n      if (isTokenChar(c)) {               // if it's a token char\n        if (length == 0) {                // start of token\n          assert start == -1;\n          start = offset + bufferIndex - charCount;\n          end = start;\n        } else if (length >= buffer.length-1) { // check if a supplementary could run out of bounds\n          buffer = termAtt.resizeBuffer(2+length); // make sure a supplementary fits in the buffer\n        }\n        end += charCount;\n        length += Character.toChars(normalize(c), buffer, length); // buffer it, normalized\n        if (length >= MAX_WORD_LEN) // buffer overflow! make sure to check for >= surrogate pair could break == test\n          break;\n      } else if (length > 0)             // at non-Letter w/ chars\n        break;                           // return 'em\n    }\n\n    termAtt.setLength(length);\n    assert start != -1;\n    offsetAtt.setOffset(correctOffset(start), finalOffset = correctOffset(end));\n    return true;\n    \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"367e74558f41dfa2d24b323440dcb2d653ad1a29","date":1496009928,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/util/CharTokenizer#incrementToken().mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/util/CharTokenizer#incrementToken().mjava","sourceNew":"  @Override\n  public final boolean incrementToken() throws IOException {\n    clearAttributes();\n    int length = 0;\n    int start = -1; // this variable is always initialized\n    int end = -1;\n    char[] buffer = termAtt.buffer();\n    while (true) {\n      if (bufferIndex >= dataLen) {\n        offset += dataLen;\n        CharacterUtils.fill(ioBuffer, input); // read supplementary char aware with CharacterUtils\n        if (ioBuffer.getLength() == 0) {\n          dataLen = 0; // so next offset += dataLen won't decrement offset\n          if (length > 0) {\n            break;\n          } else {\n            finalOffset = correctOffset(offset);\n            return false;\n          }\n        }\n        dataLen = ioBuffer.getLength();\n        bufferIndex = 0;\n      }\n      // use CharacterUtils here to support < 3.1 UTF-16 code unit behavior if the char based methods are gone\n      final int c = Character.codePointAt(ioBuffer.getBuffer(), bufferIndex, ioBuffer.getLength());\n      final int charCount = Character.charCount(c);\n      bufferIndex += charCount;\n\n      if (isTokenChar(c)) {               // if it's a token char\n        if (length == 0) {                // start of token\n          assert start == -1;\n          start = offset + bufferIndex - charCount;\n          end = start;\n        } else if (length >= buffer.length-1) { // check if a supplementary could run out of bounds\n          buffer = termAtt.resizeBuffer(2+length); // make sure a supplementary fits in the buffer\n        }\n        end += charCount;\n        length += Character.toChars(normalize(c), buffer, length); // buffer it, normalized\n        if (length >= maxTokenLen) { // buffer overflow! make sure to check for >= surrogate pair could break == test\n          break;\n        }\n      } else if (length > 0) {           // at non-Letter w/ chars\n        break;                           // return 'em\n      }\n    }\n\n    termAtt.setLength(length);\n    assert start != -1;\n    offsetAtt.setOffset(correctOffset(start), finalOffset = correctOffset(end));\n    return true;\n    \n  }\n\n","sourceOld":"  @Override\n  public final boolean incrementToken() throws IOException {\n    clearAttributes();\n    int length = 0;\n    int start = -1; // this variable is always initialized\n    int end = -1;\n    char[] buffer = termAtt.buffer();\n    while (true) {\n      if (bufferIndex >= dataLen) {\n        offset += dataLen;\n        CharacterUtils.fill(ioBuffer, input); // read supplementary char aware with CharacterUtils\n        if (ioBuffer.getLength() == 0) {\n          dataLen = 0; // so next offset += dataLen won't decrement offset\n          if (length > 0) {\n            break;\n          } else {\n            finalOffset = correctOffset(offset);\n            return false;\n          }\n        }\n        dataLen = ioBuffer.getLength();\n        bufferIndex = 0;\n      }\n      // use CharacterUtils here to support < 3.1 UTF-16 code unit behavior if the char based methods are gone\n      final int c = Character.codePointAt(ioBuffer.getBuffer(), bufferIndex, ioBuffer.getLength());\n      final int charCount = Character.charCount(c);\n      bufferIndex += charCount;\n\n      if (isTokenChar(c)) {               // if it's a token char\n        if (length == 0) {                // start of token\n          assert start == -1;\n          start = offset + bufferIndex - charCount;\n          end = start;\n        } else if (length >= buffer.length-1) { // check if a supplementary could run out of bounds\n          buffer = termAtt.resizeBuffer(2+length); // make sure a supplementary fits in the buffer\n        }\n        end += charCount;\n        length += Character.toChars(normalize(c), buffer, length); // buffer it, normalized\n        if (length >= MAX_WORD_LEN) { // buffer overflow! make sure to check for >= surrogate pair could break == test\n          break;\n        }\n      } else if (length > 0) {           // at non-Letter w/ chars\n        break;                           // return 'em\n      }\n    }\n\n    termAtt.setLength(length);\n    assert start != -1;\n    offsetAtt.setOffset(correctOffset(start), finalOffset = correctOffset(end));\n    return true;\n    \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d1f5728f32a4a256b36cfabd7a2636452f599bb9","date":1496231774,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/util/CharTokenizer#incrementToken().mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/util/CharTokenizer#incrementToken().mjava","sourceNew":"  @Override\n  public final boolean incrementToken() throws IOException {\n    clearAttributes();\n    int length = 0;\n    int start = -1; // this variable is always initialized\n    int end = -1;\n    char[] buffer = termAtt.buffer();\n    while (true) {\n      if (bufferIndex >= dataLen) {\n        offset += dataLen;\n        CharacterUtils.fill(ioBuffer, input); // read supplementary char aware with CharacterUtils\n        if (ioBuffer.getLength() == 0) {\n          dataLen = 0; // so next offset += dataLen won't decrement offset\n          if (length > 0) {\n            break;\n          } else {\n            finalOffset = correctOffset(offset);\n            return false;\n          }\n        }\n        dataLen = ioBuffer.getLength();\n        bufferIndex = 0;\n      }\n      // use CharacterUtils here to support < 3.1 UTF-16 code unit behavior if the char based methods are gone\n      final int c = Character.codePointAt(ioBuffer.getBuffer(), bufferIndex, ioBuffer.getLength());\n      final int charCount = Character.charCount(c);\n      bufferIndex += charCount;\n\n      if (isTokenChar(c)) {               // if it's a token char\n        if (length == 0) {                // start of token\n          assert start == -1;\n          start = offset + bufferIndex - charCount;\n          end = start;\n        } else if (length >= buffer.length-1) { // check if a supplementary could run out of bounds\n          buffer = termAtt.resizeBuffer(2+length); // make sure a supplementary fits in the buffer\n        }\n        end += charCount;\n        length += Character.toChars(normalize(c), buffer, length); // buffer it, normalized\n        if (length >= maxTokenLen) { // buffer overflow! make sure to check for >= surrogate pair could break == test\n          break;\n        }\n      } else if (length > 0) {           // at non-Letter w/ chars\n        break;                           // return 'em\n      }\n    }\n\n    termAtt.setLength(length);\n    assert start != -1;\n    offsetAtt.setOffset(correctOffset(start), finalOffset = correctOffset(end));\n    return true;\n    \n  }\n\n","sourceOld":"  @Override\n  public final boolean incrementToken() throws IOException {\n    clearAttributes();\n    int length = 0;\n    int start = -1; // this variable is always initialized\n    int end = -1;\n    char[] buffer = termAtt.buffer();\n    while (true) {\n      if (bufferIndex >= dataLen) {\n        offset += dataLen;\n        CharacterUtils.fill(ioBuffer, input); // read supplementary char aware with CharacterUtils\n        if (ioBuffer.getLength() == 0) {\n          dataLen = 0; // so next offset += dataLen won't decrement offset\n          if (length > 0) {\n            break;\n          } else {\n            finalOffset = correctOffset(offset);\n            return false;\n          }\n        }\n        dataLen = ioBuffer.getLength();\n        bufferIndex = 0;\n      }\n      // use CharacterUtils here to support < 3.1 UTF-16 code unit behavior if the char based methods are gone\n      final int c = Character.codePointAt(ioBuffer.getBuffer(), bufferIndex, ioBuffer.getLength());\n      final int charCount = Character.charCount(c);\n      bufferIndex += charCount;\n\n      if (isTokenChar(c)) {               // if it's a token char\n        if (length == 0) {                // start of token\n          assert start == -1;\n          start = offset + bufferIndex - charCount;\n          end = start;\n        } else if (length >= buffer.length-1) { // check if a supplementary could run out of bounds\n          buffer = termAtt.resizeBuffer(2+length); // make sure a supplementary fits in the buffer\n        }\n        end += charCount;\n        length += Character.toChars(normalize(c), buffer, length); // buffer it, normalized\n        if (length >= MAX_WORD_LEN) { // buffer overflow! make sure to check for >= surrogate pair could break == test\n          break;\n        }\n      } else if (length > 0) {           // at non-Letter w/ chars\n        break;                           // return 'em\n      }\n    }\n\n    termAtt.setLength(length);\n    assert start != -1;\n    offsetAtt.setOffset(correctOffset(start), finalOffset = correctOffset(end));\n    return true;\n    \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e9017cf144952056066919f1ebc7897ff9bd71b1","date":1496757600,"type":3,"author":"Shalin Shekhar Mangar","isMerge":true,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/util/CharTokenizer#incrementToken().mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/util/CharTokenizer#incrementToken().mjava","sourceNew":"  @Override\n  public final boolean incrementToken() throws IOException {\n    clearAttributes();\n    int length = 0;\n    int start = -1; // this variable is always initialized\n    int end = -1;\n    char[] buffer = termAtt.buffer();\n    while (true) {\n      if (bufferIndex >= dataLen) {\n        offset += dataLen;\n        CharacterUtils.fill(ioBuffer, input); // read supplementary char aware with CharacterUtils\n        if (ioBuffer.getLength() == 0) {\n          dataLen = 0; // so next offset += dataLen won't decrement offset\n          if (length > 0) {\n            break;\n          } else {\n            finalOffset = correctOffset(offset);\n            return false;\n          }\n        }\n        dataLen = ioBuffer.getLength();\n        bufferIndex = 0;\n      }\n      // use CharacterUtils here to support < 3.1 UTF-16 code unit behavior if the char based methods are gone\n      final int c = Character.codePointAt(ioBuffer.getBuffer(), bufferIndex, ioBuffer.getLength());\n      final int charCount = Character.charCount(c);\n      bufferIndex += charCount;\n\n      if (isTokenChar(c)) {               // if it's a token char\n        if (length == 0) {                // start of token\n          assert start == -1;\n          start = offset + bufferIndex - charCount;\n          end = start;\n        } else if (length >= buffer.length-1) { // check if a supplementary could run out of bounds\n          buffer = termAtt.resizeBuffer(2+length); // make sure a supplementary fits in the buffer\n        }\n        end += charCount;\n        length += Character.toChars(normalize(c), buffer, length); // buffer it, normalized\n        if (length >= maxTokenLen) { // buffer overflow! make sure to check for >= surrogate pair could break == test\n          break;\n        }\n      } else if (length > 0) {           // at non-Letter w/ chars\n        break;                           // return 'em\n      }\n    }\n\n    termAtt.setLength(length);\n    assert start != -1;\n    offsetAtt.setOffset(correctOffset(start), finalOffset = correctOffset(end));\n    return true;\n    \n  }\n\n","sourceOld":"  @Override\n  public final boolean incrementToken() throws IOException {\n    clearAttributes();\n    int length = 0;\n    int start = -1; // this variable is always initialized\n    int end = -1;\n    char[] buffer = termAtt.buffer();\n    while (true) {\n      if (bufferIndex >= dataLen) {\n        offset += dataLen;\n        CharacterUtils.fill(ioBuffer, input); // read supplementary char aware with CharacterUtils\n        if (ioBuffer.getLength() == 0) {\n          dataLen = 0; // so next offset += dataLen won't decrement offset\n          if (length > 0) {\n            break;\n          } else {\n            finalOffset = correctOffset(offset);\n            return false;\n          }\n        }\n        dataLen = ioBuffer.getLength();\n        bufferIndex = 0;\n      }\n      // use CharacterUtils here to support < 3.1 UTF-16 code unit behavior if the char based methods are gone\n      final int c = Character.codePointAt(ioBuffer.getBuffer(), bufferIndex, ioBuffer.getLength());\n      final int charCount = Character.charCount(c);\n      bufferIndex += charCount;\n\n      if (isTokenChar(c)) {               // if it's a token char\n        if (length == 0) {                // start of token\n          assert start == -1;\n          start = offset + bufferIndex - charCount;\n          end = start;\n        } else if (length >= buffer.length-1) { // check if a supplementary could run out of bounds\n          buffer = termAtt.resizeBuffer(2+length); // make sure a supplementary fits in the buffer\n        }\n        end += charCount;\n        length += Character.toChars(normalize(c), buffer, length); // buffer it, normalized\n        if (length >= MAX_WORD_LEN) { // buffer overflow! make sure to check for >= surrogate pair could break == test\n          break;\n        }\n      } else if (length > 0) {           // at non-Letter w/ chars\n        break;                           // return 'em\n      }\n    }\n\n    termAtt.setLength(length);\n    assert start != -1;\n    offsetAtt.setOffset(correctOffset(start), finalOffset = correctOffset(end));\n    return true;\n    \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3780f02dd8e07e1feb00e1a4f522c4dedb85d9c0","date":1537441025,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/util/CharTokenizer#incrementToken().mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/util/CharTokenizer#incrementToken().mjava","sourceNew":"  @Override\n  public final boolean incrementToken() throws IOException {\n    clearAttributes();\n    int length = 0;\n    int start = -1; // this variable is always initialized\n    int end = -1;\n    char[] buffer = termAtt.buffer();\n    while (true) {\n      if (bufferIndex >= dataLen) {\n        offset += dataLen;\n        CharacterUtils.fill(ioBuffer, input); // read supplementary char aware with CharacterUtils\n        if (ioBuffer.getLength() == 0) {\n          dataLen = 0; // so next offset += dataLen won't decrement offset\n          if (length > 0) {\n            break;\n          } else {\n            finalOffset = correctOffset(offset);\n            return false;\n          }\n        }\n        dataLen = ioBuffer.getLength();\n        bufferIndex = 0;\n      }\n      // use CharacterUtils here to support < 3.1 UTF-16 code unit behavior if the char based methods are gone\n      final int c = Character.codePointAt(ioBuffer.getBuffer(), bufferIndex, ioBuffer.getLength());\n      final int charCount = Character.charCount(c);\n      bufferIndex += charCount;\n\n      if (isTokenChar(c)) {               // if it's a token char\n        if (length == 0) {                // start of token\n          assert start == -1;\n          start = offset + bufferIndex - charCount;\n          end = start;\n        } else if (length >= buffer.length-1) { // check if a supplementary could run out of bounds\n          buffer = termAtt.resizeBuffer(2+length); // make sure a supplementary fits in the buffer\n        }\n        end += charCount;\n        length += Character.toChars(c, buffer, length); // buffer it, normalized\n        if (length >= maxTokenLen) { // buffer overflow! make sure to check for >= surrogate pair could break == test\n          break;\n        }\n      } else if (length > 0) {           // at non-Letter w/ chars\n        break;                           // return 'em\n      }\n    }\n\n    termAtt.setLength(length);\n    assert start != -1;\n    offsetAtt.setOffset(correctOffset(start), finalOffset = correctOffset(end));\n    return true;\n    \n  }\n\n","sourceOld":"  @Override\n  public final boolean incrementToken() throws IOException {\n    clearAttributes();\n    int length = 0;\n    int start = -1; // this variable is always initialized\n    int end = -1;\n    char[] buffer = termAtt.buffer();\n    while (true) {\n      if (bufferIndex >= dataLen) {\n        offset += dataLen;\n        CharacterUtils.fill(ioBuffer, input); // read supplementary char aware with CharacterUtils\n        if (ioBuffer.getLength() == 0) {\n          dataLen = 0; // so next offset += dataLen won't decrement offset\n          if (length > 0) {\n            break;\n          } else {\n            finalOffset = correctOffset(offset);\n            return false;\n          }\n        }\n        dataLen = ioBuffer.getLength();\n        bufferIndex = 0;\n      }\n      // use CharacterUtils here to support < 3.1 UTF-16 code unit behavior if the char based methods are gone\n      final int c = Character.codePointAt(ioBuffer.getBuffer(), bufferIndex, ioBuffer.getLength());\n      final int charCount = Character.charCount(c);\n      bufferIndex += charCount;\n\n      if (isTokenChar(c)) {               // if it's a token char\n        if (length == 0) {                // start of token\n          assert start == -1;\n          start = offset + bufferIndex - charCount;\n          end = start;\n        } else if (length >= buffer.length-1) { // check if a supplementary could run out of bounds\n          buffer = termAtt.resizeBuffer(2+length); // make sure a supplementary fits in the buffer\n        }\n        end += charCount;\n        length += Character.toChars(normalize(c), buffer, length); // buffer it, normalized\n        if (length >= maxTokenLen) { // buffer overflow! make sure to check for >= surrogate pair could break == test\n          break;\n        }\n      } else if (length > 0) {           // at non-Letter w/ chars\n        break;                           // return 'em\n      }\n    }\n\n    termAtt.setLength(length);\n    assert start != -1;\n    offsetAtt.setOffset(correctOffset(start), finalOffset = correctOffset(end));\n    return true;\n    \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"fba4cd6a5aae0bc17cc1cbf1e84b0ae32ee039dc":["bd095de1c7ac6b6ab3a330b5fbe8cb37e4f34704"],"367e74558f41dfa2d24b323440dcb2d653ad1a29":["24a98f5fdd23e04f85819dbc63b47a12f7c44311"],"24a98f5fdd23e04f85819dbc63b47a12f7c44311":["57dc82c7b33cd580e7ab5179019bc78f3d7f8e79"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["bd095de1c7ac6b6ab3a330b5fbe8cb37e4f34704","57dc82c7b33cd580e7ab5179019bc78f3d7f8e79"],"f03e4bed5023ec3ef93a771b8888cae991cf448d":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b","24a98f5fdd23e04f85819dbc63b47a12f7c44311"],"3780f02dd8e07e1feb00e1a4f522c4dedb85d9c0":["d1f5728f32a4a256b36cfabd7a2636452f599bb9"],"e9017cf144952056066919f1ebc7897ff9bd71b1":["24a98f5fdd23e04f85819dbc63b47a12f7c44311","367e74558f41dfa2d24b323440dcb2d653ad1a29"],"b89678825b68eccaf09e6ab71675fc0b0af1e099":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"bd095de1c7ac6b6ab3a330b5fbe8cb37e4f34704":["b89678825b68eccaf09e6ab71675fc0b0af1e099"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"57dc82c7b33cd580e7ab5179019bc78f3d7f8e79":["bd095de1c7ac6b6ab3a330b5fbe8cb37e4f34704","fba4cd6a5aae0bc17cc1cbf1e84b0ae32ee039dc"],"d1f5728f32a4a256b36cfabd7a2636452f599bb9":["24a98f5fdd23e04f85819dbc63b47a12f7c44311","367e74558f41dfa2d24b323440dcb2d653ad1a29"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["3780f02dd8e07e1feb00e1a4f522c4dedb85d9c0"]},"commit2Childs":{"fba4cd6a5aae0bc17cc1cbf1e84b0ae32ee039dc":["57dc82c7b33cd580e7ab5179019bc78f3d7f8e79"],"367e74558f41dfa2d24b323440dcb2d653ad1a29":["e9017cf144952056066919f1ebc7897ff9bd71b1","d1f5728f32a4a256b36cfabd7a2636452f599bb9"],"24a98f5fdd23e04f85819dbc63b47a12f7c44311":["367e74558f41dfa2d24b323440dcb2d653ad1a29","f03e4bed5023ec3ef93a771b8888cae991cf448d","e9017cf144952056066919f1ebc7897ff9bd71b1","d1f5728f32a4a256b36cfabd7a2636452f599bb9"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["f03e4bed5023ec3ef93a771b8888cae991cf448d"],"f03e4bed5023ec3ef93a771b8888cae991cf448d":[],"3780f02dd8e07e1feb00e1a4f522c4dedb85d9c0":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"e9017cf144952056066919f1ebc7897ff9bd71b1":[],"b89678825b68eccaf09e6ab71675fc0b0af1e099":["bd095de1c7ac6b6ab3a330b5fbe8cb37e4f34704"],"bd095de1c7ac6b6ab3a330b5fbe8cb37e4f34704":["fba4cd6a5aae0bc17cc1cbf1e84b0ae32ee039dc","4cce5816ef15a48a0bc11e5d400497ee4301dd3b","57dc82c7b33cd580e7ab5179019bc78f3d7f8e79"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["b89678825b68eccaf09e6ab71675fc0b0af1e099"],"57dc82c7b33cd580e7ab5179019bc78f3d7f8e79":["24a98f5fdd23e04f85819dbc63b47a12f7c44311","4cce5816ef15a48a0bc11e5d400497ee4301dd3b"],"d1f5728f32a4a256b36cfabd7a2636452f599bb9":["3780f02dd8e07e1feb00e1a4f522c4dedb85d9c0"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["f03e4bed5023ec3ef93a771b8888cae991cf448d","e9017cf144952056066919f1ebc7897ff9bd71b1","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}