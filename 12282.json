{"path":"lucene/test-framework/src/java/org/apache/lucene/index/BaseNormsFormatTestCase#doTestNormsVersusStoredFields(LongProducer).mjava","commits":[{"id":"f45b4d1a00eca88b48ea7e1ffae3041b63da020e","date":1402400148,"type":0,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/index/BaseNormsFormatTestCase#doTestNormsVersusStoredFields(LongProducer).mjava","pathOld":"/dev/null","sourceNew":"  private void doTestNormsVersusStoredFields(LongProducer longs) throws Exception {\n    int numDocs = atLeast(500);\n    long norms[] = new long[numDocs];\n    for (int i = 0; i < numDocs; i++) {\n      norms[i] = longs.next();\n    }\n    \n    Directory dir = newDirectory();\n    Analyzer analyzer = new MockAnalyzer(random(), MockTokenizer.KEYWORD, false);\n    IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n    conf.setSimilarity(new CannedNormSimilarity(norms));\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, conf);\n    Document doc = new Document();\n    Field idField = new StringField(\"id\", \"\", Field.Store.NO);\n    Field storedField = newTextField(\"stored\", \"\", Field.Store.YES);\n    doc.add(idField);\n    doc.add(storedField);\n    \n    for (int i = 0; i < numDocs; i++) {\n      idField.setStringValue(Integer.toString(i));\n      long value = norms[i];\n      storedField.setStringValue(Long.toString(value));\n      writer.addDocument(doc);\n      if (random().nextInt(31) == 0) {\n        writer.commit();\n      }\n    }\n    \n    // delete some docs\n    int numDeletions = random().nextInt(numDocs/10);\n    for (int i = 0; i < numDeletions; i++) {\n      int id = random().nextInt(numDocs);\n      writer.deleteDocuments(new Term(\"id\", Integer.toString(id)));\n    }\n    \n    writer.shutdown();\n    \n    // compare\n    DirectoryReader ir = DirectoryReader.open(dir);\n    for (AtomicReaderContext context : ir.leaves()) {\n      AtomicReader r = context.reader();\n      NumericDocValues docValues = r.getNormValues(\"stored\");\n      for (int i = 0; i < r.maxDoc(); i++) {\n        long storedValue = Long.parseLong(r.document(i).get(\"stored\"));\n        assertEquals(storedValue, docValues.get(i));\n      }\n    }\n    ir.close();\n    dir.close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5f5a414d3ffeed1bf4f1f3cf2b836afbd94ee05c","date":1402461123,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/index/BaseNormsFormatTestCase#doTestNormsVersusStoredFields(LongProducer).mjava","pathOld":"lucene/test-framework/src/java/org/apache/lucene/index/BaseNormsFormatTestCase#doTestNormsVersusStoredFields(LongProducer).mjava","sourceNew":"  private void doTestNormsVersusStoredFields(LongProducer longs) throws Exception {\n    int numDocs = atLeast(500);\n    long norms[] = new long[numDocs];\n    for (int i = 0; i < numDocs; i++) {\n      norms[i] = longs.next();\n    }\n    \n    Directory dir = newDirectory();\n    Analyzer analyzer = new MockAnalyzer(random(), MockTokenizer.KEYWORD, false);\n    IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n    conf.setSimilarity(new CannedNormSimilarity(norms));\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, conf);\n    Document doc = new Document();\n    Field idField = new StringField(\"id\", \"\", Field.Store.NO);\n    Field storedField = newTextField(\"stored\", \"\", Field.Store.YES);\n    doc.add(idField);\n    doc.add(storedField);\n    \n    for (int i = 0; i < numDocs; i++) {\n      idField.setStringValue(Integer.toString(i));\n      long value = norms[i];\n      storedField.setStringValue(Long.toString(value));\n      writer.addDocument(doc);\n      if (random().nextInt(31) == 0) {\n        writer.commit();\n      }\n    }\n    \n    // delete some docs\n    int numDeletions = random().nextInt(numDocs/10);\n    for (int i = 0; i < numDeletions; i++) {\n      int id = random().nextInt(numDocs);\n      writer.deleteDocuments(new Term(\"id\", Integer.toString(id)));\n    }\n    \n    writer.commit();\n    \n    // compare\n    DirectoryReader ir = DirectoryReader.open(dir);\n    for (AtomicReaderContext context : ir.leaves()) {\n      AtomicReader r = context.reader();\n      NumericDocValues docValues = r.getNormValues(\"stored\");\n      for (int i = 0; i < r.maxDoc(); i++) {\n        long storedValue = Long.parseLong(r.document(i).get(\"stored\"));\n        assertEquals(storedValue, docValues.get(i));\n      }\n    }\n    ir.close();\n    \n    writer.forceMerge(1);\n    \n    // compare again\n    ir = DirectoryReader.open(dir);\n    for (AtomicReaderContext context : ir.leaves()) {\n      AtomicReader r = context.reader();\n      NumericDocValues docValues = r.getNormValues(\"stored\");\n      for (int i = 0; i < r.maxDoc(); i++) {\n        long storedValue = Long.parseLong(r.document(i).get(\"stored\"));\n        assertEquals(storedValue, docValues.get(i));\n      }\n    }\n    \n    writer.close();\n    ir.close();\n    dir.close();\n  }\n\n","sourceOld":"  private void doTestNormsVersusStoredFields(LongProducer longs) throws Exception {\n    int numDocs = atLeast(500);\n    long norms[] = new long[numDocs];\n    for (int i = 0; i < numDocs; i++) {\n      norms[i] = longs.next();\n    }\n    \n    Directory dir = newDirectory();\n    Analyzer analyzer = new MockAnalyzer(random(), MockTokenizer.KEYWORD, false);\n    IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n    conf.setSimilarity(new CannedNormSimilarity(norms));\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, conf);\n    Document doc = new Document();\n    Field idField = new StringField(\"id\", \"\", Field.Store.NO);\n    Field storedField = newTextField(\"stored\", \"\", Field.Store.YES);\n    doc.add(idField);\n    doc.add(storedField);\n    \n    for (int i = 0; i < numDocs; i++) {\n      idField.setStringValue(Integer.toString(i));\n      long value = norms[i];\n      storedField.setStringValue(Long.toString(value));\n      writer.addDocument(doc);\n      if (random().nextInt(31) == 0) {\n        writer.commit();\n      }\n    }\n    \n    // delete some docs\n    int numDeletions = random().nextInt(numDocs/10);\n    for (int i = 0; i < numDeletions; i++) {\n      int id = random().nextInt(numDocs);\n      writer.deleteDocuments(new Term(\"id\", Integer.toString(id)));\n    }\n    \n    writer.shutdown();\n    \n    // compare\n    DirectoryReader ir = DirectoryReader.open(dir);\n    for (AtomicReaderContext context : ir.leaves()) {\n      AtomicReader r = context.reader();\n      NumericDocValues docValues = r.getNormValues(\"stored\");\n      for (int i = 0; i < r.maxDoc(); i++) {\n        long storedValue = Long.parseLong(r.document(i).get(\"stored\"));\n        assertEquals(storedValue, docValues.get(i));\n      }\n    }\n    ir.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e","date":1406737224,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/index/BaseNormsFormatTestCase#doTestNormsVersusStoredFields(LongProducer).mjava","pathOld":"lucene/test-framework/src/java/org/apache/lucene/index/BaseNormsFormatTestCase#doTestNormsVersusStoredFields(LongProducer).mjava","sourceNew":"  private void doTestNormsVersusStoredFields(LongProducer longs) throws Exception {\n    int numDocs = atLeast(500);\n    long norms[] = new long[numDocs];\n    for (int i = 0; i < numDocs; i++) {\n      norms[i] = longs.next();\n    }\n    \n    Directory dir = newDirectory();\n    Analyzer analyzer = new MockAnalyzer(random(), MockTokenizer.KEYWORD, false);\n    IndexWriterConfig conf = newIndexWriterConfig(analyzer);\n    conf.setSimilarity(new CannedNormSimilarity(norms));\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, conf);\n    Document doc = new Document();\n    Field idField = new StringField(\"id\", \"\", Field.Store.NO);\n    Field storedField = newTextField(\"stored\", \"\", Field.Store.YES);\n    doc.add(idField);\n    doc.add(storedField);\n    \n    for (int i = 0; i < numDocs; i++) {\n      idField.setStringValue(Integer.toString(i));\n      long value = norms[i];\n      storedField.setStringValue(Long.toString(value));\n      writer.addDocument(doc);\n      if (random().nextInt(31) == 0) {\n        writer.commit();\n      }\n    }\n    \n    // delete some docs\n    int numDeletions = random().nextInt(numDocs/10);\n    for (int i = 0; i < numDeletions; i++) {\n      int id = random().nextInt(numDocs);\n      writer.deleteDocuments(new Term(\"id\", Integer.toString(id)));\n    }\n    \n    writer.commit();\n    \n    // compare\n    DirectoryReader ir = DirectoryReader.open(dir);\n    for (AtomicReaderContext context : ir.leaves()) {\n      AtomicReader r = context.reader();\n      NumericDocValues docValues = r.getNormValues(\"stored\");\n      for (int i = 0; i < r.maxDoc(); i++) {\n        long storedValue = Long.parseLong(r.document(i).get(\"stored\"));\n        assertEquals(storedValue, docValues.get(i));\n      }\n    }\n    ir.close();\n    \n    writer.forceMerge(1);\n    \n    // compare again\n    ir = DirectoryReader.open(dir);\n    for (AtomicReaderContext context : ir.leaves()) {\n      AtomicReader r = context.reader();\n      NumericDocValues docValues = r.getNormValues(\"stored\");\n      for (int i = 0; i < r.maxDoc(); i++) {\n        long storedValue = Long.parseLong(r.document(i).get(\"stored\"));\n        assertEquals(storedValue, docValues.get(i));\n      }\n    }\n    \n    writer.close();\n    ir.close();\n    dir.close();\n  }\n\n","sourceOld":"  private void doTestNormsVersusStoredFields(LongProducer longs) throws Exception {\n    int numDocs = atLeast(500);\n    long norms[] = new long[numDocs];\n    for (int i = 0; i < numDocs; i++) {\n      norms[i] = longs.next();\n    }\n    \n    Directory dir = newDirectory();\n    Analyzer analyzer = new MockAnalyzer(random(), MockTokenizer.KEYWORD, false);\n    IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n    conf.setSimilarity(new CannedNormSimilarity(norms));\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, conf);\n    Document doc = new Document();\n    Field idField = new StringField(\"id\", \"\", Field.Store.NO);\n    Field storedField = newTextField(\"stored\", \"\", Field.Store.YES);\n    doc.add(idField);\n    doc.add(storedField);\n    \n    for (int i = 0; i < numDocs; i++) {\n      idField.setStringValue(Integer.toString(i));\n      long value = norms[i];\n      storedField.setStringValue(Long.toString(value));\n      writer.addDocument(doc);\n      if (random().nextInt(31) == 0) {\n        writer.commit();\n      }\n    }\n    \n    // delete some docs\n    int numDeletions = random().nextInt(numDocs/10);\n    for (int i = 0; i < numDeletions; i++) {\n      int id = random().nextInt(numDocs);\n      writer.deleteDocuments(new Term(\"id\", Integer.toString(id)));\n    }\n    \n    writer.commit();\n    \n    // compare\n    DirectoryReader ir = DirectoryReader.open(dir);\n    for (AtomicReaderContext context : ir.leaves()) {\n      AtomicReader r = context.reader();\n      NumericDocValues docValues = r.getNormValues(\"stored\");\n      for (int i = 0; i < r.maxDoc(); i++) {\n        long storedValue = Long.parseLong(r.document(i).get(\"stored\"));\n        assertEquals(storedValue, docValues.get(i));\n      }\n    }\n    ir.close();\n    \n    writer.forceMerge(1);\n    \n    // compare again\n    ir = DirectoryReader.open(dir);\n    for (AtomicReaderContext context : ir.leaves()) {\n      AtomicReader r = context.reader();\n      NumericDocValues docValues = r.getNormValues(\"stored\");\n      for (int i = 0; i < r.maxDoc(); i++) {\n        long storedValue = Long.parseLong(r.document(i).get(\"stored\"));\n        assertEquals(storedValue, docValues.get(i));\n      }\n    }\n    \n    writer.close();\n    ir.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c9fb5f46e264daf5ba3860defe623a89d202dd87","date":1411516315,"type":3,"author":"Ryan Ernst","isMerge":false,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/index/BaseNormsFormatTestCase#doTestNormsVersusStoredFields(LongProducer).mjava","pathOld":"lucene/test-framework/src/java/org/apache/lucene/index/BaseNormsFormatTestCase#doTestNormsVersusStoredFields(LongProducer).mjava","sourceNew":"  private void doTestNormsVersusStoredFields(LongProducer longs) throws Exception {\n    int numDocs = atLeast(500);\n    long norms[] = new long[numDocs];\n    for (int i = 0; i < numDocs; i++) {\n      norms[i] = longs.next();\n    }\n    \n    Directory dir = newDirectory();\n    Analyzer analyzer = new MockAnalyzer(random(), MockTokenizer.KEYWORD, false);\n    IndexWriterConfig conf = newIndexWriterConfig(analyzer);\n    conf.setSimilarity(new CannedNormSimilarity(norms));\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, conf);\n    Document doc = new Document();\n    Field idField = new StringField(\"id\", \"\", Field.Store.NO);\n    Field storedField = newTextField(\"stored\", \"\", Field.Store.YES);\n    doc.add(idField);\n    doc.add(storedField);\n    \n    for (int i = 0; i < numDocs; i++) {\n      idField.setStringValue(Integer.toString(i));\n      long value = norms[i];\n      storedField.setStringValue(Long.toString(value));\n      writer.addDocument(doc);\n      if (random().nextInt(31) == 0) {\n        writer.commit();\n      }\n    }\n    \n    // delete some docs\n    int numDeletions = random().nextInt(numDocs/10);\n    for (int i = 0; i < numDeletions; i++) {\n      int id = random().nextInt(numDocs);\n      writer.deleteDocuments(new Term(\"id\", Integer.toString(id)));\n    }\n    \n    writer.commit();\n    \n    // compare\n    DirectoryReader ir = DirectoryReader.open(dir);\n    for (LeafReaderContext context : ir.leaves()) {\n      LeafReader r = context.reader();\n      NumericDocValues docValues = r.getNormValues(\"stored\");\n      for (int i = 0; i < r.maxDoc(); i++) {\n        long storedValue = Long.parseLong(r.document(i).get(\"stored\"));\n        assertEquals(storedValue, docValues.get(i));\n      }\n    }\n    ir.close();\n    \n    writer.forceMerge(1);\n    \n    // compare again\n    ir = DirectoryReader.open(dir);\n    for (LeafReaderContext context : ir.leaves()) {\n      LeafReader r = context.reader();\n      NumericDocValues docValues = r.getNormValues(\"stored\");\n      for (int i = 0; i < r.maxDoc(); i++) {\n        long storedValue = Long.parseLong(r.document(i).get(\"stored\"));\n        assertEquals(storedValue, docValues.get(i));\n      }\n    }\n    \n    writer.close();\n    ir.close();\n    dir.close();\n  }\n\n","sourceOld":"  private void doTestNormsVersusStoredFields(LongProducer longs) throws Exception {\n    int numDocs = atLeast(500);\n    long norms[] = new long[numDocs];\n    for (int i = 0; i < numDocs; i++) {\n      norms[i] = longs.next();\n    }\n    \n    Directory dir = newDirectory();\n    Analyzer analyzer = new MockAnalyzer(random(), MockTokenizer.KEYWORD, false);\n    IndexWriterConfig conf = newIndexWriterConfig(analyzer);\n    conf.setSimilarity(new CannedNormSimilarity(norms));\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, conf);\n    Document doc = new Document();\n    Field idField = new StringField(\"id\", \"\", Field.Store.NO);\n    Field storedField = newTextField(\"stored\", \"\", Field.Store.YES);\n    doc.add(idField);\n    doc.add(storedField);\n    \n    for (int i = 0; i < numDocs; i++) {\n      idField.setStringValue(Integer.toString(i));\n      long value = norms[i];\n      storedField.setStringValue(Long.toString(value));\n      writer.addDocument(doc);\n      if (random().nextInt(31) == 0) {\n        writer.commit();\n      }\n    }\n    \n    // delete some docs\n    int numDeletions = random().nextInt(numDocs/10);\n    for (int i = 0; i < numDeletions; i++) {\n      int id = random().nextInt(numDocs);\n      writer.deleteDocuments(new Term(\"id\", Integer.toString(id)));\n    }\n    \n    writer.commit();\n    \n    // compare\n    DirectoryReader ir = DirectoryReader.open(dir);\n    for (AtomicReaderContext context : ir.leaves()) {\n      AtomicReader r = context.reader();\n      NumericDocValues docValues = r.getNormValues(\"stored\");\n      for (int i = 0; i < r.maxDoc(); i++) {\n        long storedValue = Long.parseLong(r.document(i).get(\"stored\"));\n        assertEquals(storedValue, docValues.get(i));\n      }\n    }\n    ir.close();\n    \n    writer.forceMerge(1);\n    \n    // compare again\n    ir = DirectoryReader.open(dir);\n    for (AtomicReaderContext context : ir.leaves()) {\n      AtomicReader r = context.reader();\n      NumericDocValues docValues = r.getNormValues(\"stored\");\n      for (int i = 0; i < r.maxDoc(); i++) {\n        long storedValue = Long.parseLong(r.document(i).get(\"stored\"));\n        assertEquals(storedValue, docValues.get(i));\n      }\n    }\n    \n    writer.close();\n    ir.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0c3fae32338d82a0710e1756793faba13dcb598b","date":1414786590,"type":3,"author":"Ryan Ernst","isMerge":false,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/index/BaseNormsFormatTestCase#doTestNormsVersusStoredFields(LongProducer).mjava","pathOld":"lucene/test-framework/src/java/org/apache/lucene/index/BaseNormsFormatTestCase#doTestNormsVersusStoredFields(LongProducer).mjava","sourceNew":"  private void doTestNormsVersusStoredFields(LongProducer longs) throws Exception {\n    int numDocs = atLeast(500);\n    long norms[] = new long[numDocs];\n    for (int i = 0; i < numDocs; i++) {\n      norms[i] = longs.next();\n    }\n    \n    Directory dir = newDirectory();\n    Analyzer analyzer = new MockAnalyzer(random(), MockTokenizer.KEYWORD, false);\n    IndexWriterConfig conf = newIndexWriterConfig(analyzer);\n    conf.setSimilarity(new CannedNormSimilarity(norms));\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, conf);\n    Document doc = new Document();\n    Field idField = new StringField(\"id\", \"\", Field.Store.NO);\n    Field storedField = newTextField(\"stored\", \"\", Field.Store.YES);\n    doc.add(idField);\n    doc.add(storedField);\n    \n    for (int i = 0; i < numDocs; i++) {\n      idField.setStringValue(Integer.toString(i));\n      long value = norms[i];\n      storedField.setStringValue(Long.toString(value));\n      writer.addDocument(doc);\n      if (random().nextInt(31) == 0) {\n        writer.commit();\n      }\n    }\n    \n    // delete some docs\n    int numDeletions = random().nextInt(numDocs/10);\n    for (int i = 0; i < numDeletions; i++) {\n      int id = random().nextInt(numDocs);\n      writer.deleteDocuments(new Term(\"id\", Integer.toString(id)));\n    }\n    \n    writer.commit();\n    \n    // compare\n    DirectoryReader ir = DirectoryReader.open(dir);\n    for (LeafReaderContext context : ir.leaves()) {\n      LeafReader r = context.reader();\n      NumericDocValues docValues = r.getNormValues(\"stored\");\n      for (int i = 0; i < r.maxDoc(); i++) {\n        long storedValue = Long.parseLong(r.document(i).get(\"stored\"));\n        assertEquals(\"doc \" + i, storedValue, docValues.get(i));\n      }\n    }\n    ir.close();\n    \n    writer.forceMerge(1);\n    \n    // compare again\n    ir = DirectoryReader.open(dir);\n    for (LeafReaderContext context : ir.leaves()) {\n      LeafReader r = context.reader();\n      NumericDocValues docValues = r.getNormValues(\"stored\");\n      for (int i = 0; i < r.maxDoc(); i++) {\n        long storedValue = Long.parseLong(r.document(i).get(\"stored\"));\n        assertEquals(storedValue, docValues.get(i));\n      }\n    }\n    \n    writer.close();\n    ir.close();\n    dir.close();\n  }\n\n","sourceOld":"  private void doTestNormsVersusStoredFields(LongProducer longs) throws Exception {\n    int numDocs = atLeast(500);\n    long norms[] = new long[numDocs];\n    for (int i = 0; i < numDocs; i++) {\n      norms[i] = longs.next();\n    }\n    \n    Directory dir = newDirectory();\n    Analyzer analyzer = new MockAnalyzer(random(), MockTokenizer.KEYWORD, false);\n    IndexWriterConfig conf = newIndexWriterConfig(analyzer);\n    conf.setSimilarity(new CannedNormSimilarity(norms));\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, conf);\n    Document doc = new Document();\n    Field idField = new StringField(\"id\", \"\", Field.Store.NO);\n    Field storedField = newTextField(\"stored\", \"\", Field.Store.YES);\n    doc.add(idField);\n    doc.add(storedField);\n    \n    for (int i = 0; i < numDocs; i++) {\n      idField.setStringValue(Integer.toString(i));\n      long value = norms[i];\n      storedField.setStringValue(Long.toString(value));\n      writer.addDocument(doc);\n      if (random().nextInt(31) == 0) {\n        writer.commit();\n      }\n    }\n    \n    // delete some docs\n    int numDeletions = random().nextInt(numDocs/10);\n    for (int i = 0; i < numDeletions; i++) {\n      int id = random().nextInt(numDocs);\n      writer.deleteDocuments(new Term(\"id\", Integer.toString(id)));\n    }\n    \n    writer.commit();\n    \n    // compare\n    DirectoryReader ir = DirectoryReader.open(dir);\n    for (LeafReaderContext context : ir.leaves()) {\n      LeafReader r = context.reader();\n      NumericDocValues docValues = r.getNormValues(\"stored\");\n      for (int i = 0; i < r.maxDoc(); i++) {\n        long storedValue = Long.parseLong(r.document(i).get(\"stored\"));\n        assertEquals(storedValue, docValues.get(i));\n      }\n    }\n    ir.close();\n    \n    writer.forceMerge(1);\n    \n    // compare again\n    ir = DirectoryReader.open(dir);\n    for (LeafReaderContext context : ir.leaves()) {\n      LeafReader r = context.reader();\n      NumericDocValues docValues = r.getNormValues(\"stored\");\n      for (int i = 0; i < r.maxDoc(); i++) {\n        long storedValue = Long.parseLong(r.document(i).get(\"stored\"));\n        assertEquals(storedValue, docValues.get(i));\n      }\n    }\n    \n    writer.close();\n    ir.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"660512549fb1425ce57576423e6ebedbf4018d37","date":1429640258,"type":5,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/index/BaseNormsFormatTestCase#doTestNormsVersusDocValues(LongProducer).mjava","pathOld":"lucene/test-framework/src/java/org/apache/lucene/index/BaseNormsFormatTestCase#doTestNormsVersusStoredFields(LongProducer).mjava","sourceNew":"  private void doTestNormsVersusDocValues(LongProducer longs) throws Exception {\n    int numDocs = atLeast(500);\n    long norms[] = new long[numDocs];\n    for (int i = 0; i < numDocs; i++) {\n      norms[i] = longs.next();\n    }\n    \n    Directory dir = newDirectory();\n    Analyzer analyzer = new MockAnalyzer(random(), MockTokenizer.KEYWORD, false);\n    IndexWriterConfig conf = newIndexWriterConfig(analyzer);\n    conf.setSimilarity(new CannedNormSimilarity(norms));\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, conf);\n    Document doc = new Document();\n    Field idField = new StringField(\"id\", \"\", Field.Store.NO);\n    Field indexedField = new TextField(\"indexed\", \"\", Field.Store.NO);\n    Field dvField = new NumericDocValuesField(\"dv\", 0);\n    doc.add(idField);\n    doc.add(indexedField);\n    doc.add(dvField);\n    \n    for (int i = 0; i < numDocs; i++) {\n      idField.setStringValue(Integer.toString(i));\n      long value = norms[i];\n      dvField.setLongValue(value);\n      indexedField.setStringValue(Long.toString(value));\n      writer.addDocument(doc);\n      if (random().nextInt(31) == 0) {\n        writer.commit();\n      }\n    }\n    \n    // delete some docs\n    int numDeletions = random().nextInt(numDocs/20);\n    for (int i = 0; i < numDeletions; i++) {\n      int id = random().nextInt(numDocs);\n      writer.deleteDocuments(new Term(\"id\", Integer.toString(id)));\n    }\n    \n    writer.commit();\n    \n    // compare\n    DirectoryReader ir = DirectoryReader.open(dir);\n    for (LeafReaderContext context : ir.leaves()) {\n      LeafReader r = context.reader();\n      NumericDocValues expected = r.getNumericDocValues(\"dv\");\n      NumericDocValues actual = r.getNormValues(\"indexed\");\n      for (int i = 0; i < r.maxDoc(); i++) {\n        assertEquals(\"doc \" + i, expected.get(i), actual.get(i));\n      }\n    }\n    ir.close();\n    \n    writer.forceMerge(1);\n    \n    // compare again\n    ir = DirectoryReader.open(dir);\n    for (LeafReaderContext context : ir.leaves()) {\n      LeafReader r = context.reader();\n      NumericDocValues expected = r.getNumericDocValues(\"dv\");\n      NumericDocValues actual = r.getNormValues(\"indexed\");\n      for (int i = 0; i < r.maxDoc(); i++) {\n        assertEquals(\"doc \" + i, expected.get(i), actual.get(i));\n      }\n    }\n    \n    writer.close();\n    ir.close();\n    dir.close();\n  }\n\n","sourceOld":"  private void doTestNormsVersusStoredFields(LongProducer longs) throws Exception {\n    int numDocs = atLeast(500);\n    long norms[] = new long[numDocs];\n    for (int i = 0; i < numDocs; i++) {\n      norms[i] = longs.next();\n    }\n    \n    Directory dir = newDirectory();\n    Analyzer analyzer = new MockAnalyzer(random(), MockTokenizer.KEYWORD, false);\n    IndexWriterConfig conf = newIndexWriterConfig(analyzer);\n    conf.setSimilarity(new CannedNormSimilarity(norms));\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, conf);\n    Document doc = new Document();\n    Field idField = new StringField(\"id\", \"\", Field.Store.NO);\n    Field storedField = newTextField(\"stored\", \"\", Field.Store.YES);\n    doc.add(idField);\n    doc.add(storedField);\n    \n    for (int i = 0; i < numDocs; i++) {\n      idField.setStringValue(Integer.toString(i));\n      long value = norms[i];\n      storedField.setStringValue(Long.toString(value));\n      writer.addDocument(doc);\n      if (random().nextInt(31) == 0) {\n        writer.commit();\n      }\n    }\n    \n    // delete some docs\n    int numDeletions = random().nextInt(numDocs/10);\n    for (int i = 0; i < numDeletions; i++) {\n      int id = random().nextInt(numDocs);\n      writer.deleteDocuments(new Term(\"id\", Integer.toString(id)));\n    }\n    \n    writer.commit();\n    \n    // compare\n    DirectoryReader ir = DirectoryReader.open(dir);\n    for (LeafReaderContext context : ir.leaves()) {\n      LeafReader r = context.reader();\n      NumericDocValues docValues = r.getNormValues(\"stored\");\n      for (int i = 0; i < r.maxDoc(); i++) {\n        long storedValue = Long.parseLong(r.document(i).get(\"stored\"));\n        assertEquals(\"doc \" + i, storedValue, docValues.get(i));\n      }\n    }\n    ir.close();\n    \n    writer.forceMerge(1);\n    \n    // compare again\n    ir = DirectoryReader.open(dir);\n    for (LeafReaderContext context : ir.leaves()) {\n      LeafReader r = context.reader();\n      NumericDocValues docValues = r.getNormValues(\"stored\");\n      for (int i = 0; i < r.maxDoc(); i++) {\n        long storedValue = Long.parseLong(r.document(i).get(\"stored\"));\n        assertEquals(storedValue, docValues.get(i));\n      }\n    }\n    \n    writer.close();\n    ir.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e":["5f5a414d3ffeed1bf4f1f3cf2b836afbd94ee05c"],"5f5a414d3ffeed1bf4f1f3cf2b836afbd94ee05c":["f45b4d1a00eca88b48ea7e1ffae3041b63da020e"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"0c3fae32338d82a0710e1756793faba13dcb598b":["c9fb5f46e264daf5ba3860defe623a89d202dd87"],"f45b4d1a00eca88b48ea7e1ffae3041b63da020e":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"660512549fb1425ce57576423e6ebedbf4018d37":["0c3fae32338d82a0710e1756793faba13dcb598b"],"c9fb5f46e264daf5ba3860defe623a89d202dd87":["54a6bea0b991120a99ad0e2f72ae853fd5ecae0e"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["660512549fb1425ce57576423e6ebedbf4018d37"]},"commit2Childs":{"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e":["c9fb5f46e264daf5ba3860defe623a89d202dd87"],"5f5a414d3ffeed1bf4f1f3cf2b836afbd94ee05c":["54a6bea0b991120a99ad0e2f72ae853fd5ecae0e"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["f45b4d1a00eca88b48ea7e1ffae3041b63da020e"],"0c3fae32338d82a0710e1756793faba13dcb598b":["660512549fb1425ce57576423e6ebedbf4018d37"],"f45b4d1a00eca88b48ea7e1ffae3041b63da020e":["5f5a414d3ffeed1bf4f1f3cf2b836afbd94ee05c"],"c9fb5f46e264daf5ba3860defe623a89d202dd87":["0c3fae32338d82a0710e1756793faba13dcb598b"],"660512549fb1425ce57576423e6ebedbf4018d37":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}