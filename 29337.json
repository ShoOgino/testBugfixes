{"path":"lucene/contrib/wordnet/src/java/org/apache/lucene/wordnet/AnalyzerUtil#getMostFrequentTerms(Analyzer,String,int).mjava","commits":[{"id":"9454a6510e2db155fb01faa5c049b06ece95fab9","date":1453508333,"type":1,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/contrib/wordnet/src/java/org/apache/lucene/wordnet/AnalyzerUtil#getMostFrequentTerms(Analyzer,String,int).mjava","pathOld":"contrib/wordnet/src/java/org/apache/lucene/wordnet/AnalyzerUtil#getMostFrequentTerms(Analyzer,String,int).mjava","sourceNew":"  /**\n   * Returns (frequency:term) pairs for the top N distinct terms (aka words),\n   * sorted descending by frequency (and ascending by term, if tied).\n   * <p>\n   * Example XQuery:\n   * <pre>\n   * declare namespace util = \"java:org.apache.lucene.index.memory.AnalyzerUtil\";\n   * declare namespace analyzer = \"java:org.apache.lucene.index.memory.PatternAnalyzer\";\n   * \n   * for $pair in util:get-most-frequent-terms(\n   *    analyzer:EXTENDED_ANALYZER(), doc(\"samples/shakespeare/othello.xml\"), 10)\n   * return &lt;word word=\"{substring-after($pair, ':')}\" frequency=\"{substring-before($pair, ':')}\"/>\n   * </pre>\n   * \n   * @param analyzer\n   *            the analyzer to use for splitting text into terms (aka words)\n   * @param text\n   *            the text to analyze\n   * @param limit\n   *            the maximum number of pairs to return; zero indicates \n   *            \"as many as possible\".\n   * @return an array of (frequency:term) pairs in the form of (freq0:term0,\n   *         freq1:term1, ..., freqN:termN). Each pair is a single string\n   *         separated by a ':' delimiter.\n   */\n  public static String[] getMostFrequentTerms(Analyzer analyzer, String text, int limit) {\n    if (analyzer == null) \n      throw new IllegalArgumentException(\"analyzer must not be null\");\n    if (text == null) \n      throw new IllegalArgumentException(\"text must not be null\");\n    if (limit <= 0) limit = Integer.MAX_VALUE;\n    \n    // compute frequencies of distinct terms\n    HashMap<String,MutableInteger> map = new HashMap<String,MutableInteger>();\n    TokenStream stream = analyzer.tokenStream(\"\", new StringReader(text));\n    TermAttribute termAtt = stream.addAttribute(TermAttribute.class);\n    try {\n      while (stream.incrementToken()) {\n        MutableInteger freq = map.get(termAtt.term());\n        if (freq == null) {\n          freq = new MutableInteger(1);\n          map.put(termAtt.term(), freq);\n        } else {\n          freq.setValue(freq.intValue() + 1);\n        }\n      }\n    } catch (IOException e) {\n      throw new RuntimeException(e);\n    } finally {\n      try {\n        stream.close();\n      } catch (IOException e2) {\n        throw new RuntimeException(e2);\n      }\n    }\n    \n    // sort by frequency, text\n    Map.Entry<String,MutableInteger>[] entries = new Map.Entry[map.size()];\n    map.entrySet().toArray(entries);\n    Arrays.sort(entries, new Comparator<Map.Entry<String,MutableInteger>>() {\n      public int compare(Map.Entry<String,MutableInteger> e1, Map.Entry<String,MutableInteger> e2) {\n        int f1 = e1.getValue().intValue();\n        int f2 = e2.getValue().intValue();\n        if (f2 - f1 != 0) return f2 - f1;\n        String s1 = e1.getKey();\n        String s2 = e2.getKey();\n        return s1.compareTo(s2);\n      }\n    });\n    \n    // return top N entries\n    int size = Math.min(limit, entries.length);\n    String[] pairs = new String[size];\n    for (int i=0; i < size; i++) {\n      pairs[i] = entries[i].getValue() + \":\" + entries[i].getKey();\n    }\n    return pairs;\n  }\n\n","sourceOld":"  /**\n   * Returns (frequency:term) pairs for the top N distinct terms (aka words),\n   * sorted descending by frequency (and ascending by term, if tied).\n   * <p>\n   * Example XQuery:\n   * <pre>\n   * declare namespace util = \"java:org.apache.lucene.index.memory.AnalyzerUtil\";\n   * declare namespace analyzer = \"java:org.apache.lucene.index.memory.PatternAnalyzer\";\n   * \n   * for $pair in util:get-most-frequent-terms(\n   *    analyzer:EXTENDED_ANALYZER(), doc(\"samples/shakespeare/othello.xml\"), 10)\n   * return &lt;word word=\"{substring-after($pair, ':')}\" frequency=\"{substring-before($pair, ':')}\"/>\n   * </pre>\n   * \n   * @param analyzer\n   *            the analyzer to use for splitting text into terms (aka words)\n   * @param text\n   *            the text to analyze\n   * @param limit\n   *            the maximum number of pairs to return; zero indicates \n   *            \"as many as possible\".\n   * @return an array of (frequency:term) pairs in the form of (freq0:term0,\n   *         freq1:term1, ..., freqN:termN). Each pair is a single string\n   *         separated by a ':' delimiter.\n   */\n  public static String[] getMostFrequentTerms(Analyzer analyzer, String text, int limit) {\n    if (analyzer == null) \n      throw new IllegalArgumentException(\"analyzer must not be null\");\n    if (text == null) \n      throw new IllegalArgumentException(\"text must not be null\");\n    if (limit <= 0) limit = Integer.MAX_VALUE;\n    \n    // compute frequencies of distinct terms\n    HashMap<String,MutableInteger> map = new HashMap<String,MutableInteger>();\n    TokenStream stream = analyzer.tokenStream(\"\", new StringReader(text));\n    TermAttribute termAtt = stream.addAttribute(TermAttribute.class);\n    try {\n      while (stream.incrementToken()) {\n        MutableInteger freq = map.get(termAtt.term());\n        if (freq == null) {\n          freq = new MutableInteger(1);\n          map.put(termAtt.term(), freq);\n        } else {\n          freq.setValue(freq.intValue() + 1);\n        }\n      }\n    } catch (IOException e) {\n      throw new RuntimeException(e);\n    } finally {\n      try {\n        stream.close();\n      } catch (IOException e2) {\n        throw new RuntimeException(e2);\n      }\n    }\n    \n    // sort by frequency, text\n    Map.Entry<String,MutableInteger>[] entries = new Map.Entry[map.size()];\n    map.entrySet().toArray(entries);\n    Arrays.sort(entries, new Comparator<Map.Entry<String,MutableInteger>>() {\n      public int compare(Map.Entry<String,MutableInteger> e1, Map.Entry<String,MutableInteger> e2) {\n        int f1 = e1.getValue().intValue();\n        int f2 = e2.getValue().intValue();\n        if (f2 - f1 != 0) return f2 - f1;\n        String s1 = e1.getKey();\n        String s2 = e2.getKey();\n        return s1.compareTo(s2);\n      }\n    });\n    \n    // return top N entries\n    int size = Math.min(limit, entries.length);\n    String[] pairs = new String[size];\n    for (int i=0; i < size; i++) {\n      pairs[i] = entries[i].getValue() + \":\" + entries[i].getKey();\n    }\n    return pairs;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"689f35bd9818b47b8d9fe96cf06518228e949ab6","date":1272894884,"type":4,"author":"Robert Muir","isMerge":false,"pathNew":"/dev/null","pathOld":"lucene/contrib/wordnet/src/java/org/apache/lucene/wordnet/AnalyzerUtil#getMostFrequentTerms(Analyzer,String,int).mjava","sourceNew":null,"sourceOld":"  /**\n   * Returns (frequency:term) pairs for the top N distinct terms (aka words),\n   * sorted descending by frequency (and ascending by term, if tied).\n   * <p>\n   * Example XQuery:\n   * <pre>\n   * declare namespace util = \"java:org.apache.lucene.index.memory.AnalyzerUtil\";\n   * declare namespace analyzer = \"java:org.apache.lucene.index.memory.PatternAnalyzer\";\n   * \n   * for $pair in util:get-most-frequent-terms(\n   *    analyzer:EXTENDED_ANALYZER(), doc(\"samples/shakespeare/othello.xml\"), 10)\n   * return &lt;word word=\"{substring-after($pair, ':')}\" frequency=\"{substring-before($pair, ':')}\"/>\n   * </pre>\n   * \n   * @param analyzer\n   *            the analyzer to use for splitting text into terms (aka words)\n   * @param text\n   *            the text to analyze\n   * @param limit\n   *            the maximum number of pairs to return; zero indicates \n   *            \"as many as possible\".\n   * @return an array of (frequency:term) pairs in the form of (freq0:term0,\n   *         freq1:term1, ..., freqN:termN). Each pair is a single string\n   *         separated by a ':' delimiter.\n   */\n  public static String[] getMostFrequentTerms(Analyzer analyzer, String text, int limit) {\n    if (analyzer == null) \n      throw new IllegalArgumentException(\"analyzer must not be null\");\n    if (text == null) \n      throw new IllegalArgumentException(\"text must not be null\");\n    if (limit <= 0) limit = Integer.MAX_VALUE;\n    \n    // compute frequencies of distinct terms\n    HashMap<String,MutableInteger> map = new HashMap<String,MutableInteger>();\n    TokenStream stream = analyzer.tokenStream(\"\", new StringReader(text));\n    TermAttribute termAtt = stream.addAttribute(TermAttribute.class);\n    try {\n      while (stream.incrementToken()) {\n        MutableInteger freq = map.get(termAtt.term());\n        if (freq == null) {\n          freq = new MutableInteger(1);\n          map.put(termAtt.term(), freq);\n        } else {\n          freq.setValue(freq.intValue() + 1);\n        }\n      }\n    } catch (IOException e) {\n      throw new RuntimeException(e);\n    } finally {\n      try {\n        stream.close();\n      } catch (IOException e2) {\n        throw new RuntimeException(e2);\n      }\n    }\n    \n    // sort by frequency, text\n    Map.Entry<String,MutableInteger>[] entries = new Map.Entry[map.size()];\n    map.entrySet().toArray(entries);\n    Arrays.sort(entries, new Comparator<Map.Entry<String,MutableInteger>>() {\n      public int compare(Map.Entry<String,MutableInteger> e1, Map.Entry<String,MutableInteger> e2) {\n        int f1 = e1.getValue().intValue();\n        int f2 = e2.getValue().intValue();\n        if (f2 - f1 != 0) return f2 - f1;\n        String s1 = e1.getKey();\n        String s2 = e2.getKey();\n        return s1.compareTo(s2);\n      }\n    });\n    \n    // return top N entries\n    int size = Math.min(limit, entries.length);\n    String[] pairs = new String[size];\n    for (int i=0; i < size; i++) {\n      pairs[i] = entries[i].getValue() + \":\" + entries[i].getKey();\n    }\n    return pairs;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"689f35bd9818b47b8d9fe96cf06518228e949ab6":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["689f35bd9818b47b8d9fe96cf06518228e949ab6"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"689f35bd9818b47b8d9fe96cf06518228e949ab6":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["689f35bd9818b47b8d9fe96cf06518228e949ab6"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}