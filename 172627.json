{"path":"lucene/test-framework/src/java/org/apache/lucene/index/BaseStoredFieldsFormatTestCase#testConcurrentReads().mjava","commits":[{"id":"70b55953b6a72596cb534ead735a8b849a473cac","date":1363634568,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/index/BaseStoredFieldsFormatTestCase#testConcurrentReads().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/codecs/compressing/TestCompressingStoredFieldsFormat#testConcurrentReads().mjava","sourceNew":"  public void testConcurrentReads() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwConf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n    iwConf.setMaxBufferedDocs(RandomInts.randomIntBetween(random(), 2, 30));\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwConf);\n    \n    // make sure the readers are properly cloned\n    final Document doc = new Document();\n    final Field field = new StringField(\"fld\", \"\", Store.YES);\n    doc.add(field);\n    final int numDocs = atLeast(1000);\n    for (int i = 0; i < numDocs; ++i) {\n      field.setStringValue(\"\" + i);\n      iw.addDocument(doc);\n    }\n    iw.commit();\n\n    final DirectoryReader rd = DirectoryReader.open(dir);\n    final IndexSearcher searcher = new IndexSearcher(rd);\n    final int concurrentReads = atLeast(5);\n    final int readsPerThread = atLeast(50);\n    final List<Thread> readThreads = new ArrayList<Thread>();\n    final AtomicReference<Exception> ex = new AtomicReference<Exception>();\n    for (int i = 0; i < concurrentReads; ++i) {\n      readThreads.add(new Thread() {\n\n        int[] queries;\n\n        {\n          queries = new int[readsPerThread];\n          for (int i = 0; i < queries.length; ++i) {\n            queries[i] = random().nextInt(numDocs);\n          }\n        }\n\n        @Override\n        public void run() {\n          for (int q : queries) {\n            final Query query = new TermQuery(new Term(\"fld\", \"\" + q));\n            try {\n              final TopDocs topDocs = searcher.search(query, 1);\n              if (topDocs.totalHits != 1) {\n                throw new IllegalStateException(\"Expected 1 hit, got \" + topDocs.totalHits);\n              }\n              final StoredDocument sdoc = rd.document(topDocs.scoreDocs[0].doc);\n              if (sdoc == null || sdoc.get(\"fld\") == null) {\n                throw new IllegalStateException(\"Could not find document \" + q);\n              }\n              if (!Integer.toString(q).equals(sdoc.get(\"fld\"))) {\n                throw new IllegalStateException(\"Expected \" + q + \", but got \" + sdoc.get(\"fld\"));\n              }\n            } catch (Exception e) {\n              ex.compareAndSet(null, e);\n            }\n          }\n        }\n      });\n    }\n    for (Thread thread : readThreads) {\n      thread.start();\n    }\n    for (Thread thread : readThreads) {\n      thread.join();\n    }\n    rd.close();\n    if (ex.get() != null) {\n      throw ex.get();\n    }\n    \n    iw.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testConcurrentReads() throws Exception {\n    // make sure the readers are properly cloned\n    final Document doc = new Document();\n    final Field field = new StringField(\"fld\", \"\", Store.YES);\n    doc.add(field);\n    final int numDocs = atLeast(1000);\n    for (int i = 0; i < numDocs; ++i) {\n      field.setStringValue(\"\" + i);\n      iw.addDocument(doc);\n    }\n    iw.commit();\n\n    final DirectoryReader rd = DirectoryReader.open(dir);\n    final IndexSearcher searcher = new IndexSearcher(rd);\n    final int concurrentReads = atLeast(5);\n    final int readsPerThread = atLeast(50);\n    final List<Thread> readThreads = new ArrayList<Thread>();\n    final AtomicReference<Exception> ex = new AtomicReference<Exception>();\n    for (int i = 0; i < concurrentReads; ++i) {\n      readThreads.add(new Thread() {\n\n        int[] queries;\n\n        {\n          queries = new int[readsPerThread];\n          for (int i = 0; i < queries.length; ++i) {\n            queries[i] = random().nextInt(numDocs);\n          }\n        }\n\n        @Override\n        public void run() {\n          for (int q : queries) {\n            final Query query = new TermQuery(new Term(\"fld\", \"\" + q));\n            try {\n              final TopDocs topDocs = searcher.search(query, 1);\n              if (topDocs.totalHits != 1) {\n                throw new IllegalStateException(\"Expected 1 hit, got \" + topDocs.totalHits);\n              }\n              final StoredDocument sdoc = rd.document(topDocs.scoreDocs[0].doc);\n              if (sdoc == null || sdoc.get(\"fld\") == null) {\n                throw new IllegalStateException(\"Could not find document \" + q);\n              }\n              if (!Integer.toString(q).equals(sdoc.get(\"fld\"))) {\n                throw new IllegalStateException(\"Expected \" + q + \", but got \" + sdoc.get(\"fld\"));\n              }\n            } catch (Exception e) {\n              ex.compareAndSet(null, e);\n            }\n          }\n        }\n      });\n    }\n    for (Thread thread : readThreads) {\n      thread.start();\n    }\n    for (Thread thread : readThreads) {\n      thread.join();\n    }\n    rd.close();\n    if (ex.get() != null) {\n      throw ex.get();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"634f330c54fd3f9f491d52036dc3f40b4f4d8934","date":1394635157,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/index/BaseStoredFieldsFormatTestCase#testConcurrentReads().mjava","pathOld":"lucene/test-framework/src/java/org/apache/lucene/index/BaseStoredFieldsFormatTestCase#testConcurrentReads().mjava","sourceNew":"  public void testConcurrentReads() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwConf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n    iwConf.setMaxBufferedDocs(RandomInts.randomIntBetween(random(), 2, 30));\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwConf);\n    \n    // make sure the readers are properly cloned\n    final Document doc = new Document();\n    final Field field = new StringField(\"fld\", \"\", Store.YES);\n    doc.add(field);\n    final int numDocs = atLeast(1000);\n    for (int i = 0; i < numDocs; ++i) {\n      field.setStringValue(\"\" + i);\n      iw.addDocument(doc);\n    }\n    iw.commit();\n\n    final DirectoryReader rd = DirectoryReader.open(dir);\n    final IndexSearcher searcher = new IndexSearcher(rd);\n    final int concurrentReads = atLeast(5);\n    final int readsPerThread = atLeast(50);\n    final List<Thread> readThreads = new ArrayList<>();\n    final AtomicReference<Exception> ex = new AtomicReference<>();\n    for (int i = 0; i < concurrentReads; ++i) {\n      readThreads.add(new Thread() {\n\n        int[] queries;\n\n        {\n          queries = new int[readsPerThread];\n          for (int i = 0; i < queries.length; ++i) {\n            queries[i] = random().nextInt(numDocs);\n          }\n        }\n\n        @Override\n        public void run() {\n          for (int q : queries) {\n            final Query query = new TermQuery(new Term(\"fld\", \"\" + q));\n            try {\n              final TopDocs topDocs = searcher.search(query, 1);\n              if (topDocs.totalHits != 1) {\n                throw new IllegalStateException(\"Expected 1 hit, got \" + topDocs.totalHits);\n              }\n              final StoredDocument sdoc = rd.document(topDocs.scoreDocs[0].doc);\n              if (sdoc == null || sdoc.get(\"fld\") == null) {\n                throw new IllegalStateException(\"Could not find document \" + q);\n              }\n              if (!Integer.toString(q).equals(sdoc.get(\"fld\"))) {\n                throw new IllegalStateException(\"Expected \" + q + \", but got \" + sdoc.get(\"fld\"));\n              }\n            } catch (Exception e) {\n              ex.compareAndSet(null, e);\n            }\n          }\n        }\n      });\n    }\n    for (Thread thread : readThreads) {\n      thread.start();\n    }\n    for (Thread thread : readThreads) {\n      thread.join();\n    }\n    rd.close();\n    if (ex.get() != null) {\n      throw ex.get();\n    }\n    \n    iw.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testConcurrentReads() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwConf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n    iwConf.setMaxBufferedDocs(RandomInts.randomIntBetween(random(), 2, 30));\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwConf);\n    \n    // make sure the readers are properly cloned\n    final Document doc = new Document();\n    final Field field = new StringField(\"fld\", \"\", Store.YES);\n    doc.add(field);\n    final int numDocs = atLeast(1000);\n    for (int i = 0; i < numDocs; ++i) {\n      field.setStringValue(\"\" + i);\n      iw.addDocument(doc);\n    }\n    iw.commit();\n\n    final DirectoryReader rd = DirectoryReader.open(dir);\n    final IndexSearcher searcher = new IndexSearcher(rd);\n    final int concurrentReads = atLeast(5);\n    final int readsPerThread = atLeast(50);\n    final List<Thread> readThreads = new ArrayList<Thread>();\n    final AtomicReference<Exception> ex = new AtomicReference<Exception>();\n    for (int i = 0; i < concurrentReads; ++i) {\n      readThreads.add(new Thread() {\n\n        int[] queries;\n\n        {\n          queries = new int[readsPerThread];\n          for (int i = 0; i < queries.length; ++i) {\n            queries[i] = random().nextInt(numDocs);\n          }\n        }\n\n        @Override\n        public void run() {\n          for (int q : queries) {\n            final Query query = new TermQuery(new Term(\"fld\", \"\" + q));\n            try {\n              final TopDocs topDocs = searcher.search(query, 1);\n              if (topDocs.totalHits != 1) {\n                throw new IllegalStateException(\"Expected 1 hit, got \" + topDocs.totalHits);\n              }\n              final StoredDocument sdoc = rd.document(topDocs.scoreDocs[0].doc);\n              if (sdoc == null || sdoc.get(\"fld\") == null) {\n                throw new IllegalStateException(\"Could not find document \" + q);\n              }\n              if (!Integer.toString(q).equals(sdoc.get(\"fld\"))) {\n                throw new IllegalStateException(\"Expected \" + q + \", but got \" + sdoc.get(\"fld\"));\n              }\n            } catch (Exception e) {\n              ex.compareAndSet(null, e);\n            }\n          }\n        }\n      });\n    }\n    for (Thread thread : readThreads) {\n      thread.start();\n    }\n    for (Thread thread : readThreads) {\n      thread.join();\n    }\n    rd.close();\n    if (ex.get() != null) {\n      throw ex.get();\n    }\n    \n    iw.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ae14298f4eec6d5faee6a149f88ba57d14a6f21a","date":1396971290,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/index/BaseStoredFieldsFormatTestCase#testConcurrentReads().mjava","pathOld":"lucene/test-framework/src/java/org/apache/lucene/index/BaseStoredFieldsFormatTestCase#testConcurrentReads().mjava","sourceNew":"  public void testConcurrentReads() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwConf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n    iwConf.setMaxBufferedDocs(RandomInts.randomIntBetween(random(), 2, 30));\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwConf);\n    \n    // make sure the readers are properly cloned\n    final Document doc = new Document();\n    final Field field = new StringField(\"fld\", \"\", Store.YES);\n    doc.add(field);\n    final int numDocs = atLeast(1000);\n    for (int i = 0; i < numDocs; ++i) {\n      field.setStringValue(\"\" + i);\n      iw.addDocument(doc);\n    }\n    iw.commit();\n\n    final DirectoryReader rd = DirectoryReader.open(dir);\n    final IndexSearcher searcher = new IndexSearcher(rd);\n    final int concurrentReads = atLeast(5);\n    final int readsPerThread = atLeast(50);\n    final List<Thread> readThreads = new ArrayList<>();\n    final AtomicReference<Exception> ex = new AtomicReference<>();\n    for (int i = 0; i < concurrentReads; ++i) {\n      readThreads.add(new Thread() {\n\n        int[] queries;\n\n        {\n          queries = new int[readsPerThread];\n          for (int i = 0; i < queries.length; ++i) {\n            queries[i] = random().nextInt(numDocs);\n          }\n        }\n\n        @Override\n        public void run() {\n          for (int q : queries) {\n            final Query query = new TermQuery(new Term(\"fld\", \"\" + q));\n            try {\n              final TopDocs topDocs = searcher.search(query, 1);\n              if (topDocs.totalHits != 1) {\n                throw new IllegalStateException(\"Expected 1 hit, got \" + topDocs.totalHits);\n              }\n              final StoredDocument sdoc = rd.document(topDocs.scoreDocs[0].doc);\n              if (sdoc == null || sdoc.get(\"fld\") == null) {\n                throw new IllegalStateException(\"Could not find document \" + q);\n              }\n              if (!Integer.toString(q).equals(sdoc.get(\"fld\"))) {\n                throw new IllegalStateException(\"Expected \" + q + \", but got \" + sdoc.get(\"fld\"));\n              }\n            } catch (Exception e) {\n              ex.compareAndSet(null, e);\n            }\n          }\n        }\n      });\n    }\n    for (Thread thread : readThreads) {\n      thread.start();\n    }\n    for (Thread thread : readThreads) {\n      thread.join();\n    }\n    rd.close();\n    if (ex.get() != null) {\n      throw ex.get();\n    }\n    \n    iw.shutdown();\n    dir.close();\n  }\n\n","sourceOld":"  public void testConcurrentReads() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwConf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n    iwConf.setMaxBufferedDocs(RandomInts.randomIntBetween(random(), 2, 30));\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwConf);\n    \n    // make sure the readers are properly cloned\n    final Document doc = new Document();\n    final Field field = new StringField(\"fld\", \"\", Store.YES);\n    doc.add(field);\n    final int numDocs = atLeast(1000);\n    for (int i = 0; i < numDocs; ++i) {\n      field.setStringValue(\"\" + i);\n      iw.addDocument(doc);\n    }\n    iw.commit();\n\n    final DirectoryReader rd = DirectoryReader.open(dir);\n    final IndexSearcher searcher = new IndexSearcher(rd);\n    final int concurrentReads = atLeast(5);\n    final int readsPerThread = atLeast(50);\n    final List<Thread> readThreads = new ArrayList<>();\n    final AtomicReference<Exception> ex = new AtomicReference<>();\n    for (int i = 0; i < concurrentReads; ++i) {\n      readThreads.add(new Thread() {\n\n        int[] queries;\n\n        {\n          queries = new int[readsPerThread];\n          for (int i = 0; i < queries.length; ++i) {\n            queries[i] = random().nextInt(numDocs);\n          }\n        }\n\n        @Override\n        public void run() {\n          for (int q : queries) {\n            final Query query = new TermQuery(new Term(\"fld\", \"\" + q));\n            try {\n              final TopDocs topDocs = searcher.search(query, 1);\n              if (topDocs.totalHits != 1) {\n                throw new IllegalStateException(\"Expected 1 hit, got \" + topDocs.totalHits);\n              }\n              final StoredDocument sdoc = rd.document(topDocs.scoreDocs[0].doc);\n              if (sdoc == null || sdoc.get(\"fld\") == null) {\n                throw new IllegalStateException(\"Could not find document \" + q);\n              }\n              if (!Integer.toString(q).equals(sdoc.get(\"fld\"))) {\n                throw new IllegalStateException(\"Expected \" + q + \", but got \" + sdoc.get(\"fld\"));\n              }\n            } catch (Exception e) {\n              ex.compareAndSet(null, e);\n            }\n          }\n        }\n      });\n    }\n    for (Thread thread : readThreads) {\n      thread.start();\n    }\n    for (Thread thread : readThreads) {\n      thread.join();\n    }\n    rd.close();\n    if (ex.get() != null) {\n      throw ex.get();\n    }\n    \n    iw.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e","date":1406737224,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/index/BaseStoredFieldsFormatTestCase#testConcurrentReads().mjava","pathOld":"lucene/test-framework/src/java/org/apache/lucene/index/BaseStoredFieldsFormatTestCase#testConcurrentReads().mjava","sourceNew":"  public void testConcurrentReads() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwConf = newIndexWriterConfig(new MockAnalyzer(random()));\n    iwConf.setMaxBufferedDocs(RandomInts.randomIntBetween(random(), 2, 30));\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwConf);\n    \n    // make sure the readers are properly cloned\n    final Document doc = new Document();\n    final Field field = new StringField(\"fld\", \"\", Store.YES);\n    doc.add(field);\n    final int numDocs = atLeast(1000);\n    for (int i = 0; i < numDocs; ++i) {\n      field.setStringValue(\"\" + i);\n      iw.addDocument(doc);\n    }\n    iw.commit();\n\n    final DirectoryReader rd = DirectoryReader.open(dir);\n    final IndexSearcher searcher = new IndexSearcher(rd);\n    final int concurrentReads = atLeast(5);\n    final int readsPerThread = atLeast(50);\n    final List<Thread> readThreads = new ArrayList<>();\n    final AtomicReference<Exception> ex = new AtomicReference<>();\n    for (int i = 0; i < concurrentReads; ++i) {\n      readThreads.add(new Thread() {\n\n        int[] queries;\n\n        {\n          queries = new int[readsPerThread];\n          for (int i = 0; i < queries.length; ++i) {\n            queries[i] = random().nextInt(numDocs);\n          }\n        }\n\n        @Override\n        public void run() {\n          for (int q : queries) {\n            final Query query = new TermQuery(new Term(\"fld\", \"\" + q));\n            try {\n              final TopDocs topDocs = searcher.search(query, 1);\n              if (topDocs.totalHits != 1) {\n                throw new IllegalStateException(\"Expected 1 hit, got \" + topDocs.totalHits);\n              }\n              final StoredDocument sdoc = rd.document(topDocs.scoreDocs[0].doc);\n              if (sdoc == null || sdoc.get(\"fld\") == null) {\n                throw new IllegalStateException(\"Could not find document \" + q);\n              }\n              if (!Integer.toString(q).equals(sdoc.get(\"fld\"))) {\n                throw new IllegalStateException(\"Expected \" + q + \", but got \" + sdoc.get(\"fld\"));\n              }\n            } catch (Exception e) {\n              ex.compareAndSet(null, e);\n            }\n          }\n        }\n      });\n    }\n    for (Thread thread : readThreads) {\n      thread.start();\n    }\n    for (Thread thread : readThreads) {\n      thread.join();\n    }\n    rd.close();\n    if (ex.get() != null) {\n      throw ex.get();\n    }\n    \n    iw.shutdown();\n    dir.close();\n  }\n\n","sourceOld":"  public void testConcurrentReads() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwConf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n    iwConf.setMaxBufferedDocs(RandomInts.randomIntBetween(random(), 2, 30));\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwConf);\n    \n    // make sure the readers are properly cloned\n    final Document doc = new Document();\n    final Field field = new StringField(\"fld\", \"\", Store.YES);\n    doc.add(field);\n    final int numDocs = atLeast(1000);\n    for (int i = 0; i < numDocs; ++i) {\n      field.setStringValue(\"\" + i);\n      iw.addDocument(doc);\n    }\n    iw.commit();\n\n    final DirectoryReader rd = DirectoryReader.open(dir);\n    final IndexSearcher searcher = new IndexSearcher(rd);\n    final int concurrentReads = atLeast(5);\n    final int readsPerThread = atLeast(50);\n    final List<Thread> readThreads = new ArrayList<>();\n    final AtomicReference<Exception> ex = new AtomicReference<>();\n    for (int i = 0; i < concurrentReads; ++i) {\n      readThreads.add(new Thread() {\n\n        int[] queries;\n\n        {\n          queries = new int[readsPerThread];\n          for (int i = 0; i < queries.length; ++i) {\n            queries[i] = random().nextInt(numDocs);\n          }\n        }\n\n        @Override\n        public void run() {\n          for (int q : queries) {\n            final Query query = new TermQuery(new Term(\"fld\", \"\" + q));\n            try {\n              final TopDocs topDocs = searcher.search(query, 1);\n              if (topDocs.totalHits != 1) {\n                throw new IllegalStateException(\"Expected 1 hit, got \" + topDocs.totalHits);\n              }\n              final StoredDocument sdoc = rd.document(topDocs.scoreDocs[0].doc);\n              if (sdoc == null || sdoc.get(\"fld\") == null) {\n                throw new IllegalStateException(\"Could not find document \" + q);\n              }\n              if (!Integer.toString(q).equals(sdoc.get(\"fld\"))) {\n                throw new IllegalStateException(\"Expected \" + q + \", but got \" + sdoc.get(\"fld\"));\n              }\n            } catch (Exception e) {\n              ex.compareAndSet(null, e);\n            }\n          }\n        }\n      });\n    }\n    for (Thread thread : readThreads) {\n      thread.start();\n    }\n    for (Thread thread : readThreads) {\n      thread.join();\n    }\n    rd.close();\n    if (ex.get() != null) {\n      throw ex.get();\n    }\n    \n    iw.shutdown();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d0ef034a4f10871667ae75181537775ddcf8ade4","date":1407610475,"type":3,"author":"Ryan Ernst","isMerge":false,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/index/BaseStoredFieldsFormatTestCase#testConcurrentReads().mjava","pathOld":"lucene/test-framework/src/java/org/apache/lucene/index/BaseStoredFieldsFormatTestCase#testConcurrentReads().mjava","sourceNew":"  public void testConcurrentReads() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwConf = newIndexWriterConfig(new MockAnalyzer(random()));\n    iwConf.setMaxBufferedDocs(RandomInts.randomIntBetween(random(), 2, 30));\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwConf);\n    \n    // make sure the readers are properly cloned\n    final Document doc = new Document();\n    final Field field = new StringField(\"fld\", \"\", Store.YES);\n    doc.add(field);\n    final int numDocs = atLeast(1000);\n    for (int i = 0; i < numDocs; ++i) {\n      field.setStringValue(\"\" + i);\n      iw.addDocument(doc);\n    }\n    iw.commit();\n\n    final DirectoryReader rd = DirectoryReader.open(dir);\n    final IndexSearcher searcher = new IndexSearcher(rd);\n    final int concurrentReads = atLeast(5);\n    final int readsPerThread = atLeast(50);\n    final List<Thread> readThreads = new ArrayList<>();\n    final AtomicReference<Exception> ex = new AtomicReference<>();\n    for (int i = 0; i < concurrentReads; ++i) {\n      readThreads.add(new Thread() {\n\n        int[] queries;\n\n        {\n          queries = new int[readsPerThread];\n          for (int i = 0; i < queries.length; ++i) {\n            queries[i] = random().nextInt(numDocs);\n          }\n        }\n\n        @Override\n        public void run() {\n          for (int q : queries) {\n            final Query query = new TermQuery(new Term(\"fld\", \"\" + q));\n            try {\n              final TopDocs topDocs = searcher.search(query, 1);\n              if (topDocs.totalHits != 1) {\n                throw new IllegalStateException(\"Expected 1 hit, got \" + topDocs.totalHits);\n              }\n              final StoredDocument sdoc = rd.document(topDocs.scoreDocs[0].doc);\n              if (sdoc == null || sdoc.get(\"fld\") == null) {\n                throw new IllegalStateException(\"Could not find document \" + q);\n              }\n              if (!Integer.toString(q).equals(sdoc.get(\"fld\"))) {\n                throw new IllegalStateException(\"Expected \" + q + \", but got \" + sdoc.get(\"fld\"));\n              }\n            } catch (Exception e) {\n              ex.compareAndSet(null, e);\n            }\n          }\n        }\n      });\n    }\n    for (Thread thread : readThreads) {\n      thread.start();\n    }\n    for (Thread thread : readThreads) {\n      thread.join();\n    }\n    rd.close();\n    if (ex.get() != null) {\n      throw ex.get();\n    }\n    \n    iw.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testConcurrentReads() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwConf = newIndexWriterConfig(new MockAnalyzer(random()));\n    iwConf.setMaxBufferedDocs(RandomInts.randomIntBetween(random(), 2, 30));\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwConf);\n    \n    // make sure the readers are properly cloned\n    final Document doc = new Document();\n    final Field field = new StringField(\"fld\", \"\", Store.YES);\n    doc.add(field);\n    final int numDocs = atLeast(1000);\n    for (int i = 0; i < numDocs; ++i) {\n      field.setStringValue(\"\" + i);\n      iw.addDocument(doc);\n    }\n    iw.commit();\n\n    final DirectoryReader rd = DirectoryReader.open(dir);\n    final IndexSearcher searcher = new IndexSearcher(rd);\n    final int concurrentReads = atLeast(5);\n    final int readsPerThread = atLeast(50);\n    final List<Thread> readThreads = new ArrayList<>();\n    final AtomicReference<Exception> ex = new AtomicReference<>();\n    for (int i = 0; i < concurrentReads; ++i) {\n      readThreads.add(new Thread() {\n\n        int[] queries;\n\n        {\n          queries = new int[readsPerThread];\n          for (int i = 0; i < queries.length; ++i) {\n            queries[i] = random().nextInt(numDocs);\n          }\n        }\n\n        @Override\n        public void run() {\n          for (int q : queries) {\n            final Query query = new TermQuery(new Term(\"fld\", \"\" + q));\n            try {\n              final TopDocs topDocs = searcher.search(query, 1);\n              if (topDocs.totalHits != 1) {\n                throw new IllegalStateException(\"Expected 1 hit, got \" + topDocs.totalHits);\n              }\n              final StoredDocument sdoc = rd.document(topDocs.scoreDocs[0].doc);\n              if (sdoc == null || sdoc.get(\"fld\") == null) {\n                throw new IllegalStateException(\"Could not find document \" + q);\n              }\n              if (!Integer.toString(q).equals(sdoc.get(\"fld\"))) {\n                throw new IllegalStateException(\"Expected \" + q + \", but got \" + sdoc.get(\"fld\"));\n              }\n            } catch (Exception e) {\n              ex.compareAndSet(null, e);\n            }\n          }\n        }\n      });\n    }\n    for (Thread thread : readThreads) {\n      thread.start();\n    }\n    for (Thread thread : readThreads) {\n      thread.join();\n    }\n    rd.close();\n    if (ex.get() != null) {\n      throw ex.get();\n    }\n    \n    iw.shutdown();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6654c5f3ec2e4a84ef867c82d4eec872c2372c8c","date":1453060490,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/index/BaseStoredFieldsFormatTestCase#testConcurrentReads().mjava","pathOld":"lucene/test-framework/src/java/org/apache/lucene/index/BaseStoredFieldsFormatTestCase#testConcurrentReads().mjava","sourceNew":"  public void testConcurrentReads() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwConf = newIndexWriterConfig(new MockAnalyzer(random()));\n    iwConf.setMaxBufferedDocs(RandomInts.randomIntBetween(random(), 2, 30));\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwConf);\n    \n    // make sure the readers are properly cloned\n    final Document doc = new Document();\n    final Field field = new StringField(\"fld\", \"\", Store.YES);\n    doc.add(field);\n    final int numDocs = atLeast(1000);\n    for (int i = 0; i < numDocs; ++i) {\n      field.setStringValue(\"\" + i);\n      iw.addDocument(doc);\n    }\n    iw.commit();\n\n    final DirectoryReader rd = DirectoryReader.open(dir);\n    final IndexSearcher searcher = new IndexSearcher(rd);\n    final int concurrentReads = atLeast(5);\n    final int readsPerThread = atLeast(50);\n    final List<Thread> readThreads = new ArrayList<>();\n    final AtomicReference<Exception> ex = new AtomicReference<>();\n    for (int i = 0; i < concurrentReads; ++i) {\n      readThreads.add(new Thread() {\n\n        int[] queries;\n\n        {\n          queries = new int[readsPerThread];\n          for (int i = 0; i < queries.length; ++i) {\n            queries[i] = random().nextInt(numDocs);\n          }\n        }\n\n        @Override\n        public void run() {\n          for (int q : queries) {\n            final Query query = new TermQuery(new Term(\"fld\", \"\" + q));\n            try {\n              final TopDocs topDocs = searcher.search(query, 1);\n              if (topDocs.totalHits != 1) {\n                throw new IllegalStateException(\"Expected 1 hit, got \" + topDocs.totalHits);\n              }\n              final Document sdoc = rd.document(topDocs.scoreDocs[0].doc);\n              if (sdoc == null || sdoc.get(\"fld\") == null) {\n                throw new IllegalStateException(\"Could not find document \" + q);\n              }\n              if (!Integer.toString(q).equals(sdoc.get(\"fld\"))) {\n                throw new IllegalStateException(\"Expected \" + q + \", but got \" + sdoc.get(\"fld\"));\n              }\n            } catch (Exception e) {\n              ex.compareAndSet(null, e);\n            }\n          }\n        }\n      });\n    }\n    for (Thread thread : readThreads) {\n      thread.start();\n    }\n    for (Thread thread : readThreads) {\n      thread.join();\n    }\n    rd.close();\n    if (ex.get() != null) {\n      throw ex.get();\n    }\n    \n    iw.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testConcurrentReads() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwConf = newIndexWriterConfig(new MockAnalyzer(random()));\n    iwConf.setMaxBufferedDocs(RandomInts.randomIntBetween(random(), 2, 30));\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwConf);\n    \n    // make sure the readers are properly cloned\n    final Document doc = new Document();\n    final Field field = new StringField(\"fld\", \"\", Store.YES);\n    doc.add(field);\n    final int numDocs = atLeast(1000);\n    for (int i = 0; i < numDocs; ++i) {\n      field.setStringValue(\"\" + i);\n      iw.addDocument(doc);\n    }\n    iw.commit();\n\n    final DirectoryReader rd = DirectoryReader.open(dir);\n    final IndexSearcher searcher = new IndexSearcher(rd);\n    final int concurrentReads = atLeast(5);\n    final int readsPerThread = atLeast(50);\n    final List<Thread> readThreads = new ArrayList<>();\n    final AtomicReference<Exception> ex = new AtomicReference<>();\n    for (int i = 0; i < concurrentReads; ++i) {\n      readThreads.add(new Thread() {\n\n        int[] queries;\n\n        {\n          queries = new int[readsPerThread];\n          for (int i = 0; i < queries.length; ++i) {\n            queries[i] = random().nextInt(numDocs);\n          }\n        }\n\n        @Override\n        public void run() {\n          for (int q : queries) {\n            final Query query = new TermQuery(new Term(\"fld\", \"\" + q));\n            try {\n              final TopDocs topDocs = searcher.search(query, 1);\n              if (topDocs.totalHits != 1) {\n                throw new IllegalStateException(\"Expected 1 hit, got \" + topDocs.totalHits);\n              }\n              final StoredDocument sdoc = rd.document(topDocs.scoreDocs[0].doc);\n              if (sdoc == null || sdoc.get(\"fld\") == null) {\n                throw new IllegalStateException(\"Could not find document \" + q);\n              }\n              if (!Integer.toString(q).equals(sdoc.get(\"fld\"))) {\n                throw new IllegalStateException(\"Expected \" + q + \", but got \" + sdoc.get(\"fld\"));\n              }\n            } catch (Exception e) {\n              ex.compareAndSet(null, e);\n            }\n          }\n        }\n      });\n    }\n    for (Thread thread : readThreads) {\n      thread.start();\n    }\n    for (Thread thread : readThreads) {\n      thread.join();\n    }\n    rd.close();\n    if (ex.get() != null) {\n      throw ex.get();\n    }\n    \n    iw.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6448f67be45147de82a85cd903fec34e8930da75","date":1477041277,"type":3,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/index/BaseStoredFieldsFormatTestCase#testConcurrentReads().mjava","pathOld":"lucene/test-framework/src/java/org/apache/lucene/index/BaseStoredFieldsFormatTestCase#testConcurrentReads().mjava","sourceNew":"  public void testConcurrentReads() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwConf = newIndexWriterConfig(new MockAnalyzer(random()));\n    iwConf.setMaxBufferedDocs(RandomNumbers.randomIntBetween(random(), 2, 30));\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwConf);\n    \n    // make sure the readers are properly cloned\n    final Document doc = new Document();\n    final Field field = new StringField(\"fld\", \"\", Store.YES);\n    doc.add(field);\n    final int numDocs = atLeast(1000);\n    for (int i = 0; i < numDocs; ++i) {\n      field.setStringValue(\"\" + i);\n      iw.addDocument(doc);\n    }\n    iw.commit();\n\n    final DirectoryReader rd = DirectoryReader.open(dir);\n    final IndexSearcher searcher = new IndexSearcher(rd);\n    final int concurrentReads = atLeast(5);\n    final int readsPerThread = atLeast(50);\n    final List<Thread> readThreads = new ArrayList<>();\n    final AtomicReference<Exception> ex = new AtomicReference<>();\n    for (int i = 0; i < concurrentReads; ++i) {\n      readThreads.add(new Thread() {\n\n        int[] queries;\n\n        {\n          queries = new int[readsPerThread];\n          for (int i = 0; i < queries.length; ++i) {\n            queries[i] = random().nextInt(numDocs);\n          }\n        }\n\n        @Override\n        public void run() {\n          for (int q : queries) {\n            final Query query = new TermQuery(new Term(\"fld\", \"\" + q));\n            try {\n              final TopDocs topDocs = searcher.search(query, 1);\n              if (topDocs.totalHits != 1) {\n                throw new IllegalStateException(\"Expected 1 hit, got \" + topDocs.totalHits);\n              }\n              final Document sdoc = rd.document(topDocs.scoreDocs[0].doc);\n              if (sdoc == null || sdoc.get(\"fld\") == null) {\n                throw new IllegalStateException(\"Could not find document \" + q);\n              }\n              if (!Integer.toString(q).equals(sdoc.get(\"fld\"))) {\n                throw new IllegalStateException(\"Expected \" + q + \", but got \" + sdoc.get(\"fld\"));\n              }\n            } catch (Exception e) {\n              ex.compareAndSet(null, e);\n            }\n          }\n        }\n      });\n    }\n    for (Thread thread : readThreads) {\n      thread.start();\n    }\n    for (Thread thread : readThreads) {\n      thread.join();\n    }\n    rd.close();\n    if (ex.get() != null) {\n      throw ex.get();\n    }\n    \n    iw.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testConcurrentReads() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwConf = newIndexWriterConfig(new MockAnalyzer(random()));\n    iwConf.setMaxBufferedDocs(RandomInts.randomIntBetween(random(), 2, 30));\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwConf);\n    \n    // make sure the readers are properly cloned\n    final Document doc = new Document();\n    final Field field = new StringField(\"fld\", \"\", Store.YES);\n    doc.add(field);\n    final int numDocs = atLeast(1000);\n    for (int i = 0; i < numDocs; ++i) {\n      field.setStringValue(\"\" + i);\n      iw.addDocument(doc);\n    }\n    iw.commit();\n\n    final DirectoryReader rd = DirectoryReader.open(dir);\n    final IndexSearcher searcher = new IndexSearcher(rd);\n    final int concurrentReads = atLeast(5);\n    final int readsPerThread = atLeast(50);\n    final List<Thread> readThreads = new ArrayList<>();\n    final AtomicReference<Exception> ex = new AtomicReference<>();\n    for (int i = 0; i < concurrentReads; ++i) {\n      readThreads.add(new Thread() {\n\n        int[] queries;\n\n        {\n          queries = new int[readsPerThread];\n          for (int i = 0; i < queries.length; ++i) {\n            queries[i] = random().nextInt(numDocs);\n          }\n        }\n\n        @Override\n        public void run() {\n          for (int q : queries) {\n            final Query query = new TermQuery(new Term(\"fld\", \"\" + q));\n            try {\n              final TopDocs topDocs = searcher.search(query, 1);\n              if (topDocs.totalHits != 1) {\n                throw new IllegalStateException(\"Expected 1 hit, got \" + topDocs.totalHits);\n              }\n              final Document sdoc = rd.document(topDocs.scoreDocs[0].doc);\n              if (sdoc == null || sdoc.get(\"fld\") == null) {\n                throw new IllegalStateException(\"Could not find document \" + q);\n              }\n              if (!Integer.toString(q).equals(sdoc.get(\"fld\"))) {\n                throw new IllegalStateException(\"Expected \" + q + \", but got \" + sdoc.get(\"fld\"));\n              }\n            } catch (Exception e) {\n              ex.compareAndSet(null, e);\n            }\n          }\n        }\n      });\n    }\n    for (Thread thread : readThreads) {\n      thread.start();\n    }\n    for (Thread thread : readThreads) {\n      thread.join();\n    }\n    rd.close();\n    if (ex.get() != null) {\n      throw ex.get();\n    }\n    \n    iw.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"80d0e6d59ae23f4a6f30eaf40bfb40742300287f","date":1477598926,"type":3,"author":"Kevin Risden","isMerge":true,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/index/BaseStoredFieldsFormatTestCase#testConcurrentReads().mjava","pathOld":"lucene/test-framework/src/java/org/apache/lucene/index/BaseStoredFieldsFormatTestCase#testConcurrentReads().mjava","sourceNew":"  public void testConcurrentReads() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwConf = newIndexWriterConfig(new MockAnalyzer(random()));\n    iwConf.setMaxBufferedDocs(RandomNumbers.randomIntBetween(random(), 2, 30));\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwConf);\n    \n    // make sure the readers are properly cloned\n    final Document doc = new Document();\n    final Field field = new StringField(\"fld\", \"\", Store.YES);\n    doc.add(field);\n    final int numDocs = atLeast(1000);\n    for (int i = 0; i < numDocs; ++i) {\n      field.setStringValue(\"\" + i);\n      iw.addDocument(doc);\n    }\n    iw.commit();\n\n    final DirectoryReader rd = DirectoryReader.open(dir);\n    final IndexSearcher searcher = new IndexSearcher(rd);\n    final int concurrentReads = atLeast(5);\n    final int readsPerThread = atLeast(50);\n    final List<Thread> readThreads = new ArrayList<>();\n    final AtomicReference<Exception> ex = new AtomicReference<>();\n    for (int i = 0; i < concurrentReads; ++i) {\n      readThreads.add(new Thread() {\n\n        int[] queries;\n\n        {\n          queries = new int[readsPerThread];\n          for (int i = 0; i < queries.length; ++i) {\n            queries[i] = random().nextInt(numDocs);\n          }\n        }\n\n        @Override\n        public void run() {\n          for (int q : queries) {\n            final Query query = new TermQuery(new Term(\"fld\", \"\" + q));\n            try {\n              final TopDocs topDocs = searcher.search(query, 1);\n              if (topDocs.totalHits != 1) {\n                throw new IllegalStateException(\"Expected 1 hit, got \" + topDocs.totalHits);\n              }\n              final Document sdoc = rd.document(topDocs.scoreDocs[0].doc);\n              if (sdoc == null || sdoc.get(\"fld\") == null) {\n                throw new IllegalStateException(\"Could not find document \" + q);\n              }\n              if (!Integer.toString(q).equals(sdoc.get(\"fld\"))) {\n                throw new IllegalStateException(\"Expected \" + q + \", but got \" + sdoc.get(\"fld\"));\n              }\n            } catch (Exception e) {\n              ex.compareAndSet(null, e);\n            }\n          }\n        }\n      });\n    }\n    for (Thread thread : readThreads) {\n      thread.start();\n    }\n    for (Thread thread : readThreads) {\n      thread.join();\n    }\n    rd.close();\n    if (ex.get() != null) {\n      throw ex.get();\n    }\n    \n    iw.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testConcurrentReads() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwConf = newIndexWriterConfig(new MockAnalyzer(random()));\n    iwConf.setMaxBufferedDocs(RandomInts.randomIntBetween(random(), 2, 30));\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwConf);\n    \n    // make sure the readers are properly cloned\n    final Document doc = new Document();\n    final Field field = new StringField(\"fld\", \"\", Store.YES);\n    doc.add(field);\n    final int numDocs = atLeast(1000);\n    for (int i = 0; i < numDocs; ++i) {\n      field.setStringValue(\"\" + i);\n      iw.addDocument(doc);\n    }\n    iw.commit();\n\n    final DirectoryReader rd = DirectoryReader.open(dir);\n    final IndexSearcher searcher = new IndexSearcher(rd);\n    final int concurrentReads = atLeast(5);\n    final int readsPerThread = atLeast(50);\n    final List<Thread> readThreads = new ArrayList<>();\n    final AtomicReference<Exception> ex = new AtomicReference<>();\n    for (int i = 0; i < concurrentReads; ++i) {\n      readThreads.add(new Thread() {\n\n        int[] queries;\n\n        {\n          queries = new int[readsPerThread];\n          for (int i = 0; i < queries.length; ++i) {\n            queries[i] = random().nextInt(numDocs);\n          }\n        }\n\n        @Override\n        public void run() {\n          for (int q : queries) {\n            final Query query = new TermQuery(new Term(\"fld\", \"\" + q));\n            try {\n              final TopDocs topDocs = searcher.search(query, 1);\n              if (topDocs.totalHits != 1) {\n                throw new IllegalStateException(\"Expected 1 hit, got \" + topDocs.totalHits);\n              }\n              final Document sdoc = rd.document(topDocs.scoreDocs[0].doc);\n              if (sdoc == null || sdoc.get(\"fld\") == null) {\n                throw new IllegalStateException(\"Could not find document \" + q);\n              }\n              if (!Integer.toString(q).equals(sdoc.get(\"fld\"))) {\n                throw new IllegalStateException(\"Expected \" + q + \", but got \" + sdoc.get(\"fld\"));\n              }\n            } catch (Exception e) {\n              ex.compareAndSet(null, e);\n            }\n          }\n        }\n      });\n    }\n    for (Thread thread : readThreads) {\n      thread.start();\n    }\n    for (Thread thread : readThreads) {\n      thread.join();\n    }\n    rd.close();\n    if (ex.get() != null) {\n      throw ex.get();\n    }\n    \n    iw.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"83788ad129a5154d5c6562c4e8ce3db48793aada","date":1532961485,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/index/BaseStoredFieldsFormatTestCase#testConcurrentReads().mjava","pathOld":"lucene/test-framework/src/java/org/apache/lucene/index/BaseStoredFieldsFormatTestCase#testConcurrentReads().mjava","sourceNew":"  public void testConcurrentReads() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwConf = newIndexWriterConfig(new MockAnalyzer(random()));\n    iwConf.setMaxBufferedDocs(RandomNumbers.randomIntBetween(random(), 2, 30));\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwConf);\n    \n    // make sure the readers are properly cloned\n    final Document doc = new Document();\n    final Field field = new StringField(\"fld\", \"\", Store.YES);\n    doc.add(field);\n    final int numDocs = atLeast(1000);\n    for (int i = 0; i < numDocs; ++i) {\n      field.setStringValue(\"\" + i);\n      iw.addDocument(doc);\n    }\n    iw.commit();\n\n    final DirectoryReader rd = DirectoryReader.open(dir);\n    final IndexSearcher searcher = new IndexSearcher(rd);\n    final int concurrentReads = atLeast(5);\n    final int readsPerThread = atLeast(50);\n    final List<Thread> readThreads = new ArrayList<>();\n    final AtomicReference<Exception> ex = new AtomicReference<>();\n    for (int i = 0; i < concurrentReads; ++i) {\n      readThreads.add(new Thread() {\n\n        int[] queries;\n\n        {\n          queries = new int[readsPerThread];\n          for (int i = 0; i < queries.length; ++i) {\n            queries[i] = random().nextInt(numDocs);\n          }\n        }\n\n        @Override\n        public void run() {\n          for (int q : queries) {\n            final Query query = new TermQuery(new Term(\"fld\", \"\" + q));\n            try {\n              final TopDocs topDocs = searcher.search(query, 1);\n              if (topDocs.totalHits.value != 1) {\n                throw new IllegalStateException(\"Expected 1 hit, got \" + topDocs.totalHits.value);\n              }\n              final Document sdoc = rd.document(topDocs.scoreDocs[0].doc);\n              if (sdoc == null || sdoc.get(\"fld\") == null) {\n                throw new IllegalStateException(\"Could not find document \" + q);\n              }\n              if (!Integer.toString(q).equals(sdoc.get(\"fld\"))) {\n                throw new IllegalStateException(\"Expected \" + q + \", but got \" + sdoc.get(\"fld\"));\n              }\n            } catch (Exception e) {\n              ex.compareAndSet(null, e);\n            }\n          }\n        }\n      });\n    }\n    for (Thread thread : readThreads) {\n      thread.start();\n    }\n    for (Thread thread : readThreads) {\n      thread.join();\n    }\n    rd.close();\n    if (ex.get() != null) {\n      throw ex.get();\n    }\n    \n    iw.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testConcurrentReads() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwConf = newIndexWriterConfig(new MockAnalyzer(random()));\n    iwConf.setMaxBufferedDocs(RandomNumbers.randomIntBetween(random(), 2, 30));\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwConf);\n    \n    // make sure the readers are properly cloned\n    final Document doc = new Document();\n    final Field field = new StringField(\"fld\", \"\", Store.YES);\n    doc.add(field);\n    final int numDocs = atLeast(1000);\n    for (int i = 0; i < numDocs; ++i) {\n      field.setStringValue(\"\" + i);\n      iw.addDocument(doc);\n    }\n    iw.commit();\n\n    final DirectoryReader rd = DirectoryReader.open(dir);\n    final IndexSearcher searcher = new IndexSearcher(rd);\n    final int concurrentReads = atLeast(5);\n    final int readsPerThread = atLeast(50);\n    final List<Thread> readThreads = new ArrayList<>();\n    final AtomicReference<Exception> ex = new AtomicReference<>();\n    for (int i = 0; i < concurrentReads; ++i) {\n      readThreads.add(new Thread() {\n\n        int[] queries;\n\n        {\n          queries = new int[readsPerThread];\n          for (int i = 0; i < queries.length; ++i) {\n            queries[i] = random().nextInt(numDocs);\n          }\n        }\n\n        @Override\n        public void run() {\n          for (int q : queries) {\n            final Query query = new TermQuery(new Term(\"fld\", \"\" + q));\n            try {\n              final TopDocs topDocs = searcher.search(query, 1);\n              if (topDocs.totalHits != 1) {\n                throw new IllegalStateException(\"Expected 1 hit, got \" + topDocs.totalHits);\n              }\n              final Document sdoc = rd.document(topDocs.scoreDocs[0].doc);\n              if (sdoc == null || sdoc.get(\"fld\") == null) {\n                throw new IllegalStateException(\"Could not find document \" + q);\n              }\n              if (!Integer.toString(q).equals(sdoc.get(\"fld\"))) {\n                throw new IllegalStateException(\"Expected \" + q + \", but got \" + sdoc.get(\"fld\"));\n              }\n            } catch (Exception e) {\n              ex.compareAndSet(null, e);\n            }\n          }\n        }\n      });\n    }\n    for (Thread thread : readThreads) {\n      thread.start();\n    }\n    for (Thread thread : readThreads) {\n      thread.join();\n    }\n    rd.close();\n    if (ex.get() != null) {\n      throw ex.get();\n    }\n    \n    iw.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"dbc046116d49cd3d0c50f7169cabaa295bc23a4a","date":1552989114,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/index/BaseStoredFieldsFormatTestCase#testConcurrentReads().mjava","pathOld":"lucene/test-framework/src/java/org/apache/lucene/index/BaseStoredFieldsFormatTestCase#testConcurrentReads().mjava","sourceNew":"  public void testConcurrentReads() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwConf = newIndexWriterConfig(new MockAnalyzer(random()));\n    iwConf.setMaxBufferedDocs(RandomNumbers.randomIntBetween(random(), 2, 30));\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwConf);\n    \n    // make sure the readers are properly cloned\n    final Document doc = new Document();\n    final Field field = new StringField(\"fld\", \"\", Store.YES);\n    doc.add(field);\n    final int numDocs = atLeast(1000);\n    for (int i = 0; i < numDocs; ++i) {\n      field.setStringValue(\"\" + i);\n      iw.addDocument(doc);\n    }\n    iw.commit();\n\n    final DirectoryReader rd = maybeWrapWithMergingReader(DirectoryReader.open(dir));\n    final IndexSearcher searcher = new IndexSearcher(rd);\n    final int concurrentReads = atLeast(5);\n    final int readsPerThread = atLeast(50);\n    final List<Thread> readThreads = new ArrayList<>();\n    final AtomicReference<Exception> ex = new AtomicReference<>();\n    for (int i = 0; i < concurrentReads; ++i) {\n      readThreads.add(new Thread() {\n\n        int[] queries;\n\n        {\n          queries = new int[readsPerThread];\n          for (int i = 0; i < queries.length; ++i) {\n            queries[i] = random().nextInt(numDocs);\n          }\n        }\n\n        @Override\n        public void run() {\n          for (int q : queries) {\n            final Query query = new TermQuery(new Term(\"fld\", \"\" + q));\n            try {\n              final TopDocs topDocs = searcher.search(query, 1);\n              if (topDocs.totalHits.value != 1) {\n                throw new IllegalStateException(\"Expected 1 hit, got \" + topDocs.totalHits.value);\n              }\n              final Document sdoc = rd.document(topDocs.scoreDocs[0].doc);\n              if (sdoc == null || sdoc.get(\"fld\") == null) {\n                throw new IllegalStateException(\"Could not find document \" + q);\n              }\n              if (!Integer.toString(q).equals(sdoc.get(\"fld\"))) {\n                throw new IllegalStateException(\"Expected \" + q + \", but got \" + sdoc.get(\"fld\"));\n              }\n            } catch (Exception e) {\n              ex.compareAndSet(null, e);\n            }\n          }\n        }\n      });\n    }\n    for (Thread thread : readThreads) {\n      thread.start();\n    }\n    for (Thread thread : readThreads) {\n      thread.join();\n    }\n    rd.close();\n    if (ex.get() != null) {\n      throw ex.get();\n    }\n    \n    iw.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testConcurrentReads() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig iwConf = newIndexWriterConfig(new MockAnalyzer(random()));\n    iwConf.setMaxBufferedDocs(RandomNumbers.randomIntBetween(random(), 2, 30));\n    RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwConf);\n    \n    // make sure the readers are properly cloned\n    final Document doc = new Document();\n    final Field field = new StringField(\"fld\", \"\", Store.YES);\n    doc.add(field);\n    final int numDocs = atLeast(1000);\n    for (int i = 0; i < numDocs; ++i) {\n      field.setStringValue(\"\" + i);\n      iw.addDocument(doc);\n    }\n    iw.commit();\n\n    final DirectoryReader rd = DirectoryReader.open(dir);\n    final IndexSearcher searcher = new IndexSearcher(rd);\n    final int concurrentReads = atLeast(5);\n    final int readsPerThread = atLeast(50);\n    final List<Thread> readThreads = new ArrayList<>();\n    final AtomicReference<Exception> ex = new AtomicReference<>();\n    for (int i = 0; i < concurrentReads; ++i) {\n      readThreads.add(new Thread() {\n\n        int[] queries;\n\n        {\n          queries = new int[readsPerThread];\n          for (int i = 0; i < queries.length; ++i) {\n            queries[i] = random().nextInt(numDocs);\n          }\n        }\n\n        @Override\n        public void run() {\n          for (int q : queries) {\n            final Query query = new TermQuery(new Term(\"fld\", \"\" + q));\n            try {\n              final TopDocs topDocs = searcher.search(query, 1);\n              if (topDocs.totalHits.value != 1) {\n                throw new IllegalStateException(\"Expected 1 hit, got \" + topDocs.totalHits.value);\n              }\n              final Document sdoc = rd.document(topDocs.scoreDocs[0].doc);\n              if (sdoc == null || sdoc.get(\"fld\") == null) {\n                throw new IllegalStateException(\"Could not find document \" + q);\n              }\n              if (!Integer.toString(q).equals(sdoc.get(\"fld\"))) {\n                throw new IllegalStateException(\"Expected \" + q + \", but got \" + sdoc.get(\"fld\"));\n              }\n            } catch (Exception e) {\n              ex.compareAndSet(null, e);\n            }\n          }\n        }\n      });\n    }\n    for (Thread thread : readThreads) {\n      thread.start();\n    }\n    for (Thread thread : readThreads) {\n      thread.join();\n    }\n    rd.close();\n    if (ex.get() != null) {\n      throw ex.get();\n    }\n    \n    iw.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["70b55953b6a72596cb534ead735a8b849a473cac"],"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e":["ae14298f4eec6d5faee6a149f88ba57d14a6f21a"],"6448f67be45147de82a85cd903fec34e8930da75":["6654c5f3ec2e4a84ef867c82d4eec872c2372c8c"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"80d0e6d59ae23f4a6f30eaf40bfb40742300287f":["6654c5f3ec2e4a84ef867c82d4eec872c2372c8c","6448f67be45147de82a85cd903fec34e8930da75"],"dbc046116d49cd3d0c50f7169cabaa295bc23a4a":["83788ad129a5154d5c6562c4e8ce3db48793aada"],"d0ef034a4f10871667ae75181537775ddcf8ade4":["54a6bea0b991120a99ad0e2f72ae853fd5ecae0e"],"70b55953b6a72596cb534ead735a8b849a473cac":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"ae14298f4eec6d5faee6a149f88ba57d14a6f21a":["634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"83788ad129a5154d5c6562c4e8ce3db48793aada":["6448f67be45147de82a85cd903fec34e8930da75"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["dbc046116d49cd3d0c50f7169cabaa295bc23a4a"],"6654c5f3ec2e4a84ef867c82d4eec872c2372c8c":["d0ef034a4f10871667ae75181537775ddcf8ade4"]},"commit2Childs":{"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["ae14298f4eec6d5faee6a149f88ba57d14a6f21a"],"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"6448f67be45147de82a85cd903fec34e8930da75":["80d0e6d59ae23f4a6f30eaf40bfb40742300287f","83788ad129a5154d5c6562c4e8ce3db48793aada"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["70b55953b6a72596cb534ead735a8b849a473cac"],"80d0e6d59ae23f4a6f30eaf40bfb40742300287f":[],"dbc046116d49cd3d0c50f7169cabaa295bc23a4a":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"d0ef034a4f10871667ae75181537775ddcf8ade4":["6654c5f3ec2e4a84ef867c82d4eec872c2372c8c"],"70b55953b6a72596cb534ead735a8b849a473cac":["634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"ae14298f4eec6d5faee6a149f88ba57d14a6f21a":["54a6bea0b991120a99ad0e2f72ae853fd5ecae0e"],"83788ad129a5154d5c6562c4e8ce3db48793aada":["dbc046116d49cd3d0c50f7169cabaa295bc23a4a"],"6654c5f3ec2e4a84ef867c82d4eec872c2372c8c":["6448f67be45147de82a85cd903fec34e8930da75","80d0e6d59ae23f4a6f30eaf40bfb40742300287f"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["80d0e6d59ae23f4a6f30eaf40bfb40742300287f","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}