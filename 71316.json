{"path":"lucene/src/java/org/apache/lucene/index/codecs/BlockTermsReader#BlockTermsReader(TermsIndexReaderBase,Directory,FieldInfos,String,PostingsReaderBase,int,int,int).mjava","commits":[{"id":"d619839baa8ce5503e496b94a9e42ad6f079293f","date":1301309428,"type":0,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/codecs/BlockTermsReader#BlockTermsReader(TermsIndexReaderBase,Directory,FieldInfos,String,PostingsReaderBase,int,int,int).mjava","pathOld":"/dev/null","sourceNew":"  public BlockTermsReader(TermsIndexReaderBase indexReader, Directory dir, FieldInfos fieldInfos, String segment, PostingsReaderBase postingsReader, int readBufferSize,\n                          int termsCacheSize, int codecId)\n    throws IOException {\n    \n    this.postingsReader = postingsReader;\n    termsCache = new DoubleBarrelLRUCache<FieldAndTerm,BlockTermState>(termsCacheSize);\n\n    //this.segment = segment;\n    in = dir.openInput(IndexFileNames.segmentFileName(segment, \"\"+codecId, BlockTermsWriter.TERMS_EXTENSION),\n                       readBufferSize);\n\n    boolean success = false;\n    try {\n      readHeader(in);\n\n      // Have PostingsReader init itself\n      postingsReader.init(in);\n\n      // Read per-field details\n      seekDir(in, dirOffset);\n\n      final int numFields = in.readVInt();\n\n      for(int i=0;i<numFields;i++) {\n        final int field = in.readVInt();\n        final long numTerms = in.readVLong();\n        assert numTerms >= 0;\n        final long termsStartPointer = in.readVLong();\n        final FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n        final long sumTotalTermFreq = fieldInfo.omitTermFreqAndPositions ? -1 : in.readVLong();\n        assert !fields.containsKey(fieldInfo.name);\n        fields.put(fieldInfo.name, new FieldReader(fieldInfo, numTerms, termsStartPointer, sumTotalTermFreq));\n      }\n      success = true;\n    } finally {\n      if (!success) {\n        in.close();\n      }\n    }\n\n    this.indexReader = indexReader;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0150c6e116b24d66f02d63fcb0758f336e8791e2","date":1307283797,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/codecs/BlockTermsReader#BlockTermsReader(TermsIndexReaderBase,Directory,FieldInfos,String,PostingsReaderBase,int,int,int).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/codecs/BlockTermsReader#BlockTermsReader(TermsIndexReaderBase,Directory,FieldInfos,String,PostingsReaderBase,int,int,int).mjava","sourceNew":"  public BlockTermsReader(TermsIndexReaderBase indexReader, Directory dir, FieldInfos fieldInfos, String segment, PostingsReaderBase postingsReader, int readBufferSize,\n                          int termsCacheSize, int codecId)\n    throws IOException {\n    \n    this.postingsReader = postingsReader;\n    termsCache = new DoubleBarrelLRUCache<FieldAndTerm,BlockTermState>(termsCacheSize);\n\n    //this.segment = segment;\n    in = dir.openInput(IndexFileNames.segmentFileName(segment, codecId, BlockTermsWriter.TERMS_EXTENSION),\n                       readBufferSize);\n\n    boolean success = false;\n    try {\n      readHeader(in);\n\n      // Have PostingsReader init itself\n      postingsReader.init(in);\n\n      // Read per-field details\n      seekDir(in, dirOffset);\n\n      final int numFields = in.readVInt();\n\n      for(int i=0;i<numFields;i++) {\n        final int field = in.readVInt();\n        final long numTerms = in.readVLong();\n        assert numTerms >= 0;\n        final long termsStartPointer = in.readVLong();\n        final FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n        final long sumTotalTermFreq = fieldInfo.omitTermFreqAndPositions ? -1 : in.readVLong();\n        assert !fields.containsKey(fieldInfo.name);\n        fields.put(fieldInfo.name, new FieldReader(fieldInfo, numTerms, termsStartPointer, sumTotalTermFreq));\n      }\n      success = true;\n    } finally {\n      if (!success) {\n        in.close();\n      }\n    }\n\n    this.indexReader = indexReader;\n  }\n\n","sourceOld":"  public BlockTermsReader(TermsIndexReaderBase indexReader, Directory dir, FieldInfos fieldInfos, String segment, PostingsReaderBase postingsReader, int readBufferSize,\n                          int termsCacheSize, int codecId)\n    throws IOException {\n    \n    this.postingsReader = postingsReader;\n    termsCache = new DoubleBarrelLRUCache<FieldAndTerm,BlockTermState>(termsCacheSize);\n\n    //this.segment = segment;\n    in = dir.openInput(IndexFileNames.segmentFileName(segment, \"\"+codecId, BlockTermsWriter.TERMS_EXTENSION),\n                       readBufferSize);\n\n    boolean success = false;\n    try {\n      readHeader(in);\n\n      // Have PostingsReader init itself\n      postingsReader.init(in);\n\n      // Read per-field details\n      seekDir(in, dirOffset);\n\n      final int numFields = in.readVInt();\n\n      for(int i=0;i<numFields;i++) {\n        final int field = in.readVInt();\n        final long numTerms = in.readVLong();\n        assert numTerms >= 0;\n        final long termsStartPointer = in.readVLong();\n        final FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n        final long sumTotalTermFreq = fieldInfo.omitTermFreqAndPositions ? -1 : in.readVLong();\n        assert !fields.containsKey(fieldInfo.name);\n        fields.put(fieldInfo.name, new FieldReader(fieldInfo, numTerms, termsStartPointer, sumTotalTermFreq));\n      }\n      success = true;\n    } finally {\n      if (!success) {\n        in.close();\n      }\n    }\n\n    this.indexReader = indexReader;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2e8d7ba2175f47e280231533f7d3016249cea88b","date":1307711934,"type":0,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/codecs/BlockTermsReader#BlockTermsReader(TermsIndexReaderBase,Directory,FieldInfos,String,PostingsReaderBase,int,int,int).mjava","pathOld":"/dev/null","sourceNew":"  public BlockTermsReader(TermsIndexReaderBase indexReader, Directory dir, FieldInfos fieldInfos, String segment, PostingsReaderBase postingsReader, int readBufferSize,\n                          int termsCacheSize, int codecId)\n    throws IOException {\n    \n    this.postingsReader = postingsReader;\n    termsCache = new DoubleBarrelLRUCache<FieldAndTerm,BlockTermState>(termsCacheSize);\n\n    //this.segment = segment;\n    in = dir.openInput(IndexFileNames.segmentFileName(segment, codecId, BlockTermsWriter.TERMS_EXTENSION),\n                       readBufferSize);\n\n    boolean success = false;\n    try {\n      readHeader(in);\n\n      // Have PostingsReader init itself\n      postingsReader.init(in);\n\n      // Read per-field details\n      seekDir(in, dirOffset);\n\n      final int numFields = in.readVInt();\n\n      for(int i=0;i<numFields;i++) {\n        final int field = in.readVInt();\n        final long numTerms = in.readVLong();\n        assert numTerms >= 0;\n        final long termsStartPointer = in.readVLong();\n        final FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n        final long sumTotalTermFreq = fieldInfo.omitTermFreqAndPositions ? -1 : in.readVLong();\n        assert !fields.containsKey(fieldInfo.name);\n        fields.put(fieldInfo.name, new FieldReader(fieldInfo, numTerms, termsStartPointer, sumTotalTermFreq));\n      }\n      success = true;\n    } finally {\n      if (!success) {\n        in.close();\n      }\n    }\n\n    this.indexReader = indexReader;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a02058e0eaba4bbd5d05e6b06b9522c0acfd1655","date":1307729864,"type":0,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/codecs/BlockTermsReader#BlockTermsReader(TermsIndexReaderBase,Directory,FieldInfos,String,PostingsReaderBase,int,int,int).mjava","pathOld":"/dev/null","sourceNew":"  public BlockTermsReader(TermsIndexReaderBase indexReader, Directory dir, FieldInfos fieldInfos, String segment, PostingsReaderBase postingsReader, int readBufferSize,\n                          int termsCacheSize, int codecId)\n    throws IOException {\n    \n    this.postingsReader = postingsReader;\n    termsCache = new DoubleBarrelLRUCache<FieldAndTerm,BlockTermState>(termsCacheSize);\n\n    //this.segment = segment;\n    in = dir.openInput(IndexFileNames.segmentFileName(segment, codecId, BlockTermsWriter.TERMS_EXTENSION),\n                       readBufferSize);\n\n    boolean success = false;\n    try {\n      readHeader(in);\n\n      // Have PostingsReader init itself\n      postingsReader.init(in);\n\n      // Read per-field details\n      seekDir(in, dirOffset);\n\n      final int numFields = in.readVInt();\n\n      for(int i=0;i<numFields;i++) {\n        final int field = in.readVInt();\n        final long numTerms = in.readVLong();\n        assert numTerms >= 0;\n        final long termsStartPointer = in.readVLong();\n        final FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n        final long sumTotalTermFreq = fieldInfo.omitTermFreqAndPositions ? -1 : in.readVLong();\n        assert !fields.containsKey(fieldInfo.name);\n        fields.put(fieldInfo.name, new FieldReader(fieldInfo, numTerms, termsStartPointer, sumTotalTermFreq));\n      }\n      success = true;\n    } finally {\n      if (!success) {\n        in.close();\n      }\n    }\n\n    this.indexReader = indexReader;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"639c36565ce03aed5b0fce7c9e4448e53a1f7efd","date":1308580104,"type":5,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/codecs/BlockTermsReader#BlockTermsReader(TermsIndexReaderBase,Directory,FieldInfos,String,PostingsReaderBase,IOContext,int,int).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/codecs/BlockTermsReader#BlockTermsReader(TermsIndexReaderBase,Directory,FieldInfos,String,PostingsReaderBase,int,int,int).mjava","sourceNew":"  public BlockTermsReader(TermsIndexReaderBase indexReader, Directory dir, FieldInfos fieldInfos, String segment, PostingsReaderBase postingsReader, IOContext context,\n                          int termsCacheSize, int codecId)\n    throws IOException {\n    \n    this.postingsReader = postingsReader;\n    termsCache = new DoubleBarrelLRUCache<FieldAndTerm,BlockTermState>(termsCacheSize);\n\n    //this.segment = segment;\n    in = dir.openInput(IndexFileNames.segmentFileName(segment, codecId, BlockTermsWriter.TERMS_EXTENSION),\n                       context);\n\n    boolean success = false;\n    try {\n      readHeader(in);\n\n      // Have PostingsReader init itself\n      postingsReader.init(in);\n\n      // Read per-field details\n      seekDir(in, dirOffset);\n\n      final int numFields = in.readVInt();\n\n      for(int i=0;i<numFields;i++) {\n        final int field = in.readVInt();\n        final long numTerms = in.readVLong();\n        assert numTerms >= 0;\n        final long termsStartPointer = in.readVLong();\n        final FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n        final long sumTotalTermFreq = fieldInfo.omitTermFreqAndPositions ? -1 : in.readVLong();\n        assert !fields.containsKey(fieldInfo.name);\n        fields.put(fieldInfo.name, new FieldReader(fieldInfo, numTerms, termsStartPointer, sumTotalTermFreq));\n      }\n      success = true;\n    } finally {\n      if (!success) {\n        in.close();\n      }\n    }\n\n    this.indexReader = indexReader;\n  }\n\n","sourceOld":"  public BlockTermsReader(TermsIndexReaderBase indexReader, Directory dir, FieldInfos fieldInfos, String segment, PostingsReaderBase postingsReader, int readBufferSize,\n                          int termsCacheSize, int codecId)\n    throws IOException {\n    \n    this.postingsReader = postingsReader;\n    termsCache = new DoubleBarrelLRUCache<FieldAndTerm,BlockTermState>(termsCacheSize);\n\n    //this.segment = segment;\n    in = dir.openInput(IndexFileNames.segmentFileName(segment, codecId, BlockTermsWriter.TERMS_EXTENSION),\n                       readBufferSize);\n\n    boolean success = false;\n    try {\n      readHeader(in);\n\n      // Have PostingsReader init itself\n      postingsReader.init(in);\n\n      // Read per-field details\n      seekDir(in, dirOffset);\n\n      final int numFields = in.readVInt();\n\n      for(int i=0;i<numFields;i++) {\n        final int field = in.readVInt();\n        final long numTerms = in.readVLong();\n        assert numTerms >= 0;\n        final long termsStartPointer = in.readVLong();\n        final FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n        final long sumTotalTermFreq = fieldInfo.omitTermFreqAndPositions ? -1 : in.readVLong();\n        assert !fields.containsKey(fieldInfo.name);\n        fields.put(fieldInfo.name, new FieldReader(fieldInfo, numTerms, termsStartPointer, sumTotalTermFreq));\n      }\n      success = true;\n    } finally {\n      if (!success) {\n        in.close();\n      }\n    }\n\n    this.indexReader = indexReader;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ddc4c914be86e34b54f70023f45a60fa7f04e929","date":1310115160,"type":5,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/codecs/BlockTermsReader#BlockTermsReader(TermsIndexReaderBase,Directory,FieldInfos,String,PostingsReaderBase,IOContext,int,int).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/codecs/BlockTermsReader#BlockTermsReader(TermsIndexReaderBase,Directory,FieldInfos,String,PostingsReaderBase,int,int,int).mjava","sourceNew":"  public BlockTermsReader(TermsIndexReaderBase indexReader, Directory dir, FieldInfos fieldInfos, String segment, PostingsReaderBase postingsReader, IOContext context,\n                          int termsCacheSize, int codecId)\n    throws IOException {\n    \n    this.postingsReader = postingsReader;\n    termsCache = new DoubleBarrelLRUCache<FieldAndTerm,BlockTermState>(termsCacheSize);\n\n    //this.segment = segment;\n    in = dir.openInput(IndexFileNames.segmentFileName(segment, codecId, BlockTermsWriter.TERMS_EXTENSION),\n                       context);\n\n    boolean success = false;\n    try {\n      readHeader(in);\n\n      // Have PostingsReader init itself\n      postingsReader.init(in);\n\n      // Read per-field details\n      seekDir(in, dirOffset);\n\n      final int numFields = in.readVInt();\n\n      for(int i=0;i<numFields;i++) {\n        final int field = in.readVInt();\n        final long numTerms = in.readVLong();\n        assert numTerms >= 0;\n        final long termsStartPointer = in.readVLong();\n        final FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n        final long sumTotalTermFreq = fieldInfo.omitTermFreqAndPositions ? -1 : in.readVLong();\n        assert !fields.containsKey(fieldInfo.name);\n        fields.put(fieldInfo.name, new FieldReader(fieldInfo, numTerms, termsStartPointer, sumTotalTermFreq));\n      }\n      success = true;\n    } finally {\n      if (!success) {\n        in.close();\n      }\n    }\n\n    this.indexReader = indexReader;\n  }\n\n","sourceOld":"  public BlockTermsReader(TermsIndexReaderBase indexReader, Directory dir, FieldInfos fieldInfos, String segment, PostingsReaderBase postingsReader, int readBufferSize,\n                          int termsCacheSize, int codecId)\n    throws IOException {\n    \n    this.postingsReader = postingsReader;\n    termsCache = new DoubleBarrelLRUCache<FieldAndTerm,BlockTermState>(termsCacheSize);\n\n    //this.segment = segment;\n    in = dir.openInput(IndexFileNames.segmentFileName(segment, codecId, BlockTermsWriter.TERMS_EXTENSION),\n                       readBufferSize);\n\n    boolean success = false;\n    try {\n      readHeader(in);\n\n      // Have PostingsReader init itself\n      postingsReader.init(in);\n\n      // Read per-field details\n      seekDir(in, dirOffset);\n\n      final int numFields = in.readVInt();\n\n      for(int i=0;i<numFields;i++) {\n        final int field = in.readVInt();\n        final long numTerms = in.readVLong();\n        assert numTerms >= 0;\n        final long termsStartPointer = in.readVLong();\n        final FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n        final long sumTotalTermFreq = fieldInfo.omitTermFreqAndPositions ? -1 : in.readVLong();\n        assert !fields.containsKey(fieldInfo.name);\n        fields.put(fieldInfo.name, new FieldReader(fieldInfo, numTerms, termsStartPointer, sumTotalTermFreq));\n      }\n      success = true;\n    } finally {\n      if (!success) {\n        in.close();\n      }\n    }\n\n    this.indexReader = indexReader;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5d004d0e0b3f65bb40da76d476d659d7888270e8","date":1310158940,"type":5,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/codecs/BlockTermsReader#BlockTermsReader(TermsIndexReaderBase,Directory,FieldInfos,String,PostingsReaderBase,IOContext,int,int).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/codecs/BlockTermsReader#BlockTermsReader(TermsIndexReaderBase,Directory,FieldInfos,String,PostingsReaderBase,int,int,int).mjava","sourceNew":"  public BlockTermsReader(TermsIndexReaderBase indexReader, Directory dir, FieldInfos fieldInfos, String segment, PostingsReaderBase postingsReader, IOContext context,\n                          int termsCacheSize, int codecId)\n    throws IOException {\n    \n    this.postingsReader = postingsReader;\n    termsCache = new DoubleBarrelLRUCache<FieldAndTerm,BlockTermState>(termsCacheSize);\n\n    //this.segment = segment;\n    in = dir.openInput(IndexFileNames.segmentFileName(segment, codecId, BlockTermsWriter.TERMS_EXTENSION),\n                       context);\n\n    boolean success = false;\n    try {\n      readHeader(in);\n\n      // Have PostingsReader init itself\n      postingsReader.init(in);\n\n      // Read per-field details\n      seekDir(in, dirOffset);\n\n      final int numFields = in.readVInt();\n\n      for(int i=0;i<numFields;i++) {\n        final int field = in.readVInt();\n        final long numTerms = in.readVLong();\n        assert numTerms >= 0;\n        final long termsStartPointer = in.readVLong();\n        final FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n        final long sumTotalTermFreq = fieldInfo.omitTermFreqAndPositions ? -1 : in.readVLong();\n        assert !fields.containsKey(fieldInfo.name);\n        fields.put(fieldInfo.name, new FieldReader(fieldInfo, numTerms, termsStartPointer, sumTotalTermFreq));\n      }\n      success = true;\n    } finally {\n      if (!success) {\n        in.close();\n      }\n    }\n\n    this.indexReader = indexReader;\n  }\n\n","sourceOld":"  public BlockTermsReader(TermsIndexReaderBase indexReader, Directory dir, FieldInfos fieldInfos, String segment, PostingsReaderBase postingsReader, int readBufferSize,\n                          int termsCacheSize, int codecId)\n    throws IOException {\n    \n    this.postingsReader = postingsReader;\n    termsCache = new DoubleBarrelLRUCache<FieldAndTerm,BlockTermState>(termsCacheSize);\n\n    //this.segment = segment;\n    in = dir.openInput(IndexFileNames.segmentFileName(segment, codecId, BlockTermsWriter.TERMS_EXTENSION),\n                       readBufferSize);\n\n    boolean success = false;\n    try {\n      readHeader(in);\n\n      // Have PostingsReader init itself\n      postingsReader.init(in);\n\n      // Read per-field details\n      seekDir(in, dirOffset);\n\n      final int numFields = in.readVInt();\n\n      for(int i=0;i<numFields;i++) {\n        final int field = in.readVInt();\n        final long numTerms = in.readVLong();\n        assert numTerms >= 0;\n        final long termsStartPointer = in.readVLong();\n        final FieldInfo fieldInfo = fieldInfos.fieldInfo(field);\n        final long sumTotalTermFreq = fieldInfo.omitTermFreqAndPositions ? -1 : in.readVLong();\n        assert !fields.containsKey(fieldInfo.name);\n        fields.put(fieldInfo.name, new FieldReader(fieldInfo, numTerms, termsStartPointer, sumTotalTermFreq));\n      }\n      success = true;\n    } finally {\n      if (!success) {\n        in.close();\n      }\n    }\n\n    this.indexReader = indexReader;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"a02058e0eaba4bbd5d05e6b06b9522c0acfd1655":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","2e8d7ba2175f47e280231533f7d3016249cea88b"],"2e8d7ba2175f47e280231533f7d3016249cea88b":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","0150c6e116b24d66f02d63fcb0758f336e8791e2"],"d619839baa8ce5503e496b94a9e42ad6f079293f":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"0150c6e116b24d66f02d63fcb0758f336e8791e2":["d619839baa8ce5503e496b94a9e42ad6f079293f"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"639c36565ce03aed5b0fce7c9e4448e53a1f7efd":["2e8d7ba2175f47e280231533f7d3016249cea88b"],"5d004d0e0b3f65bb40da76d476d659d7888270e8":["a02058e0eaba4bbd5d05e6b06b9522c0acfd1655","ddc4c914be86e34b54f70023f45a60fa7f04e929"],"ddc4c914be86e34b54f70023f45a60fa7f04e929":["2e8d7ba2175f47e280231533f7d3016249cea88b","639c36565ce03aed5b0fce7c9e4448e53a1f7efd"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["ddc4c914be86e34b54f70023f45a60fa7f04e929"]},"commit2Childs":{"a02058e0eaba4bbd5d05e6b06b9522c0acfd1655":["5d004d0e0b3f65bb40da76d476d659d7888270e8"],"2e8d7ba2175f47e280231533f7d3016249cea88b":["a02058e0eaba4bbd5d05e6b06b9522c0acfd1655","639c36565ce03aed5b0fce7c9e4448e53a1f7efd","ddc4c914be86e34b54f70023f45a60fa7f04e929"],"d619839baa8ce5503e496b94a9e42ad6f079293f":["0150c6e116b24d66f02d63fcb0758f336e8791e2"],"0150c6e116b24d66f02d63fcb0758f336e8791e2":["2e8d7ba2175f47e280231533f7d3016249cea88b"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["a02058e0eaba4bbd5d05e6b06b9522c0acfd1655","2e8d7ba2175f47e280231533f7d3016249cea88b","d619839baa8ce5503e496b94a9e42ad6f079293f"],"639c36565ce03aed5b0fce7c9e4448e53a1f7efd":["ddc4c914be86e34b54f70023f45a60fa7f04e929"],"5d004d0e0b3f65bb40da76d476d659d7888270e8":[],"ddc4c914be86e34b54f70023f45a60fa7f04e929":["5d004d0e0b3f65bb40da76d476d659d7888270e8","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["5d004d0e0b3f65bb40da76d476d659d7888270e8","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}