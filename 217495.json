{"path":"lucene/analysis/common/src/java/org/apache/lucene/analysis/ngram/NGramTokenFilter#NGramTokenFilter(TokenStream,int,int).mjava","commits":[{"id":"b89678825b68eccaf09e6ab71675fc0b0af1e099","date":1334669779,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/ngram/NGramTokenFilter#NGramTokenFilter(TokenStream,int,int).mjava","pathOld":"modules/analysis/common/src/java/org/apache/lucene/analysis/ngram/NGramTokenFilter#NGramTokenFilter(TokenStream,int,int).mjava","sourceNew":"  /**\n   * Creates NGramTokenFilter with given min and max n-grams.\n   * @param input {@link TokenStream} holding the input to be tokenized\n   * @param minGram the smallest n-gram to generate\n   * @param maxGram the largest n-gram to generate\n   */\n  public NGramTokenFilter(TokenStream input, int minGram, int maxGram) {\n    super(input);\n    if (minGram < 1) {\n      throw new IllegalArgumentException(\"minGram must be greater than zero\");\n    }\n    if (minGram > maxGram) {\n      throw new IllegalArgumentException(\"minGram must not be greater than maxGram\");\n    }\n    this.minGram = minGram;\n    this.maxGram = maxGram;\n  }\n\n","sourceOld":"  /**\n   * Creates NGramTokenFilter with given min and max n-grams.\n   * @param input {@link TokenStream} holding the input to be tokenized\n   * @param minGram the smallest n-gram to generate\n   * @param maxGram the largest n-gram to generate\n   */\n  public NGramTokenFilter(TokenStream input, int minGram, int maxGram) {\n    super(input);\n    if (minGram < 1) {\n      throw new IllegalArgumentException(\"minGram must be greater than zero\");\n    }\n    if (minGram > maxGram) {\n      throw new IllegalArgumentException(\"minGram must not be greater than maxGram\");\n    }\n    this.minGram = minGram;\n    this.maxGram = maxGram;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4c807c4005aae1acaf5cebc9af40883985fb89a8","date":1366974206,"type":6,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/ngram/NGramTokenFilter#NGramTokenFilter(Version,TokenStream,int,int).mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/ngram/NGramTokenFilter#NGramTokenFilter(TokenStream,int,int).mjava","sourceNew":"  /**\n   * Creates NGramTokenFilter with given min and max n-grams.\n   * @param version Lucene version to enable correct position increments.\n   *                See <a href=\"#version\">above</a> for details.\n   * @param input {@link TokenStream} holding the input to be tokenized\n   * @param minGram the smallest n-gram to generate\n   * @param maxGram the largest n-gram to generate\n   */\n  public NGramTokenFilter(Version version, TokenStream input, int minGram, int maxGram) {\n    super(new LengthFilter(true, input, minGram, Integer.MAX_VALUE));\n    this.version = version;\n    if (minGram < 1) {\n      throw new IllegalArgumentException(\"minGram must be greater than zero\");\n    }\n    if (minGram > maxGram) {\n      throw new IllegalArgumentException(\"minGram must not be greater than maxGram\");\n    }\n    this.minGram = minGram;\n    this.maxGram = maxGram;\n    if (version.onOrAfter(Version.LUCENE_44)) {\n      posIncAtt = addAttribute(PositionIncrementAttribute.class);\n      posLenAtt = addAttribute(PositionLengthAttribute.class);\n    } else {\n      posIncAtt = new PositionIncrementAttribute() {\n        @Override\n        public void setPositionIncrement(int positionIncrement) {}\n        @Override\n        public int getPositionIncrement() {\n          return 0;\n        }\n      };\n      posLenAtt = new PositionLengthAttribute() {\n        @Override\n        public void setPositionLength(int positionLength) {}        \n        @Override\n        public int getPositionLength() {\n          return 0;\n        }\n      };\n    }\n  }\n\n","sourceOld":"  /**\n   * Creates NGramTokenFilter with given min and max n-grams.\n   * @param input {@link TokenStream} holding the input to be tokenized\n   * @param minGram the smallest n-gram to generate\n   * @param maxGram the largest n-gram to generate\n   */\n  public NGramTokenFilter(TokenStream input, int minGram, int maxGram) {\n    super(input);\n    if (minGram < 1) {\n      throw new IllegalArgumentException(\"minGram must be greater than zero\");\n    }\n    if (minGram > maxGram) {\n      throw new IllegalArgumentException(\"minGram must not be greater than maxGram\");\n    }\n    this.minGram = minGram;\n    this.maxGram = maxGram;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4c807c4005aae1acaf5cebc9af40883985fb89a8","date":1366974206,"type":5,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/ngram/NGramTokenizer#init(Version,int,int).mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/ngram/NGramTokenFilter#NGramTokenFilter(TokenStream,int,int).mjava","sourceNew":"  private void init(Version version, int minGram, int maxGram) {\n    if (!version.onOrAfter(Version.LUCENE_44)) {\n      throw new IllegalArgumentException(\"This class only works with Lucene 4.4+. To emulate the old (broken) behavior of NGramTokenizer, use Lucene43NGramTokenizer\");\n    }\n    if (minGram < 1) {\n      throw new IllegalArgumentException(\"minGram must be greater than zero\");\n    }\n    if (minGram > maxGram) {\n      throw new IllegalArgumentException(\"minGram must not be greater than maxGram\");\n    }\n    this.minGram = minGram;\n    this.maxGram = maxGram;\n    buffer = new char[maxGram + 1024];\n  }\n\n","sourceOld":"  /**\n   * Creates NGramTokenFilter with given min and max n-grams.\n   * @param input {@link TokenStream} holding the input to be tokenized\n   * @param minGram the smallest n-gram to generate\n   * @param maxGram the largest n-gram to generate\n   */\n  public NGramTokenFilter(TokenStream input, int minGram, int maxGram) {\n    super(input);\n    if (minGram < 1) {\n      throw new IllegalArgumentException(\"minGram must be greater than zero\");\n    }\n    if (minGram > maxGram) {\n      throw new IllegalArgumentException(\"minGram must not be greater than maxGram\");\n    }\n    this.minGram = minGram;\n    this.maxGram = maxGram;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"379db3ad24c4f0214f30a122265a6d6be003a99d","date":1407537768,"type":1,"author":"Ryan Ernst","isMerge":false,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/ngram/NGramTokenFilter#NGramTokenFilter(TokenStream,int,int).mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/ngram/NGramTokenFilter#NGramTokenFilter(Version,TokenStream,int,int).mjava","sourceNew":"  /**\n   * Creates NGramTokenFilter with given min and max n-grams.\n   * @param input {@link TokenStream} holding the input to be tokenized\n   * @param minGram the smallest n-gram to generate\n   * @param maxGram the largest n-gram to generate\n   */\n  public NGramTokenFilter(TokenStream input, int minGram, int maxGram) {\n    super(new CodepointCountFilter(input, minGram, Integer.MAX_VALUE));\n    this.charUtils = CharacterUtils.getInstance();\n    if (minGram < 1) {\n      throw new IllegalArgumentException(\"minGram must be greater than zero\");\n    }\n    if (minGram > maxGram) {\n      throw new IllegalArgumentException(\"minGram must not be greater than maxGram\");\n    }\n    this.minGram = minGram;\n    this.maxGram = maxGram;\n\n    posIncAtt = addAttribute(PositionIncrementAttribute.class);\n    posLenAtt = addAttribute(PositionLengthAttribute.class);\n  }\n\n","sourceOld":"  /**\n   * Creates NGramTokenFilter with given min and max n-grams.\n   * @param version Lucene version to enable correct position increments.\n   *                See <a href=\"#version\">above</a> for details.\n   * @param input {@link TokenStream} holding the input to be tokenized\n   * @param minGram the smallest n-gram to generate\n   * @param maxGram the largest n-gram to generate\n   */\n  public NGramTokenFilter(Version version, TokenStream input, int minGram, int maxGram) {\n    super(new CodepointCountFilter(version, input, minGram, Integer.MAX_VALUE));\n    this.version = version;\n    this.charUtils = version.onOrAfter(Version.LUCENE_4_4)\n        ? CharacterUtils.getInstance(version)\n        : CharacterUtils.getJava4Instance();\n    if (minGram < 1) {\n      throw new IllegalArgumentException(\"minGram must be greater than zero\");\n    }\n    if (minGram > maxGram) {\n      throw new IllegalArgumentException(\"minGram must not be greater than maxGram\");\n    }\n    this.minGram = minGram;\n    this.maxGram = maxGram;\n    if (version.onOrAfter(Version.LUCENE_4_4)) {\n      posIncAtt = addAttribute(PositionIncrementAttribute.class);\n      posLenAtt = addAttribute(PositionLengthAttribute.class);\n    } else {\n      posIncAtt = new PositionIncrementAttribute() {\n        @Override\n        public void setPositionIncrement(int positionIncrement) {}\n        @Override\n        public int getPositionIncrement() {\n          return 0;\n        }\n      };\n      posLenAtt = new PositionLengthAttribute() {\n        @Override\n        public void setPositionLength(int positionLength) {}        \n        @Override\n        public int getPositionLength() {\n          return 0;\n        }\n      };\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fba4cd6a5aae0bc17cc1cbf1e84b0ae32ee039dc","date":1465824262,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/ngram/NGramTokenFilter#NGramTokenFilter(TokenStream,int,int).mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/ngram/NGramTokenFilter#NGramTokenFilter(TokenStream,int,int).mjava","sourceNew":"  /**\n   * Creates NGramTokenFilter with given min and max n-grams.\n   * @param input {@link TokenStream} holding the input to be tokenized\n   * @param minGram the smallest n-gram to generate\n   * @param maxGram the largest n-gram to generate\n   */\n  public NGramTokenFilter(TokenStream input, int minGram, int maxGram) {\n    super(new CodepointCountFilter(input, minGram, Integer.MAX_VALUE));\n    if (minGram < 1) {\n      throw new IllegalArgumentException(\"minGram must be greater than zero\");\n    }\n    if (minGram > maxGram) {\n      throw new IllegalArgumentException(\"minGram must not be greater than maxGram\");\n    }\n    this.minGram = minGram;\n    this.maxGram = maxGram;\n\n    posIncAtt = addAttribute(PositionIncrementAttribute.class);\n    posLenAtt = addAttribute(PositionLengthAttribute.class);\n  }\n\n","sourceOld":"  /**\n   * Creates NGramTokenFilter with given min and max n-grams.\n   * @param input {@link TokenStream} holding the input to be tokenized\n   * @param minGram the smallest n-gram to generate\n   * @param maxGram the largest n-gram to generate\n   */\n  public NGramTokenFilter(TokenStream input, int minGram, int maxGram) {\n    super(new CodepointCountFilter(input, minGram, Integer.MAX_VALUE));\n    this.charUtils = CharacterUtils.getInstance();\n    if (minGram < 1) {\n      throw new IllegalArgumentException(\"minGram must be greater than zero\");\n    }\n    if (minGram > maxGram) {\n      throw new IllegalArgumentException(\"minGram must not be greater than maxGram\");\n    }\n    this.minGram = minGram;\n    this.maxGram = maxGram;\n\n    posIncAtt = addAttribute(PositionIncrementAttribute.class);\n    posLenAtt = addAttribute(PositionLengthAttribute.class);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"57dc82c7b33cd580e7ab5179019bc78f3d7f8e79","date":1465913303,"type":3,"author":"Noble Paul","isMerge":true,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/ngram/NGramTokenFilter#NGramTokenFilter(TokenStream,int,int).mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/ngram/NGramTokenFilter#NGramTokenFilter(TokenStream,int,int).mjava","sourceNew":"  /**\n   * Creates NGramTokenFilter with given min and max n-grams.\n   * @param input {@link TokenStream} holding the input to be tokenized\n   * @param minGram the smallest n-gram to generate\n   * @param maxGram the largest n-gram to generate\n   */\n  public NGramTokenFilter(TokenStream input, int minGram, int maxGram) {\n    super(new CodepointCountFilter(input, minGram, Integer.MAX_VALUE));\n    if (minGram < 1) {\n      throw new IllegalArgumentException(\"minGram must be greater than zero\");\n    }\n    if (minGram > maxGram) {\n      throw new IllegalArgumentException(\"minGram must not be greater than maxGram\");\n    }\n    this.minGram = minGram;\n    this.maxGram = maxGram;\n\n    posIncAtt = addAttribute(PositionIncrementAttribute.class);\n    posLenAtt = addAttribute(PositionLengthAttribute.class);\n  }\n\n","sourceOld":"  /**\n   * Creates NGramTokenFilter with given min and max n-grams.\n   * @param input {@link TokenStream} holding the input to be tokenized\n   * @param minGram the smallest n-gram to generate\n   * @param maxGram the largest n-gram to generate\n   */\n  public NGramTokenFilter(TokenStream input, int minGram, int maxGram) {\n    super(new CodepointCountFilter(input, minGram, Integer.MAX_VALUE));\n    this.charUtils = CharacterUtils.getInstance();\n    if (minGram < 1) {\n      throw new IllegalArgumentException(\"minGram must be greater than zero\");\n    }\n    if (minGram > maxGram) {\n      throw new IllegalArgumentException(\"minGram must not be greater than maxGram\");\n    }\n    this.minGram = minGram;\n    this.maxGram = maxGram;\n\n    posIncAtt = addAttribute(PositionIncrementAttribute.class);\n    posLenAtt = addAttribute(PositionLengthAttribute.class);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"4cce5816ef15a48a0bc11e5d400497ee4301dd3b","date":1476991456,"type":3,"author":"Kevin Risden","isMerge":true,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/ngram/NGramTokenFilter#NGramTokenFilter(TokenStream,int,int).mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/ngram/NGramTokenFilter#NGramTokenFilter(TokenStream,int,int).mjava","sourceNew":"  /**\n   * Creates NGramTokenFilter with given min and max n-grams.\n   * @param input {@link TokenStream} holding the input to be tokenized\n   * @param minGram the smallest n-gram to generate\n   * @param maxGram the largest n-gram to generate\n   */\n  public NGramTokenFilter(TokenStream input, int minGram, int maxGram) {\n    super(new CodepointCountFilter(input, minGram, Integer.MAX_VALUE));\n    if (minGram < 1) {\n      throw new IllegalArgumentException(\"minGram must be greater than zero\");\n    }\n    if (minGram > maxGram) {\n      throw new IllegalArgumentException(\"minGram must not be greater than maxGram\");\n    }\n    this.minGram = minGram;\n    this.maxGram = maxGram;\n\n    posIncAtt = addAttribute(PositionIncrementAttribute.class);\n    posLenAtt = addAttribute(PositionLengthAttribute.class);\n  }\n\n","sourceOld":"  /**\n   * Creates NGramTokenFilter with given min and max n-grams.\n   * @param input {@link TokenStream} holding the input to be tokenized\n   * @param minGram the smallest n-gram to generate\n   * @param maxGram the largest n-gram to generate\n   */\n  public NGramTokenFilter(TokenStream input, int minGram, int maxGram) {\n    super(new CodepointCountFilter(input, minGram, Integer.MAX_VALUE));\n    this.charUtils = CharacterUtils.getInstance();\n    if (minGram < 1) {\n      throw new IllegalArgumentException(\"minGram must be greater than zero\");\n    }\n    if (minGram > maxGram) {\n      throw new IllegalArgumentException(\"minGram must not be greater than maxGram\");\n    }\n    this.minGram = minGram;\n    this.maxGram = maxGram;\n\n    posIncAtt = addAttribute(PositionIncrementAttribute.class);\n    posLenAtt = addAttribute(PositionLengthAttribute.class);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"4188a39e51b877e66d58390c0583e205eb3d1131","date":1484323643,"type":3,"author":"Nathan Gass","isMerge":false,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/ngram/NGramTokenFilter#NGramTokenFilter(TokenStream,int,int).mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/ngram/NGramTokenFilter#NGramTokenFilter(TokenStream,int,int).mjava","sourceNew":"  /**\n   * Creates NGramTokenFilter with given min and max n-grams.\n   * @param input {@link TokenStream} holding the input to be tokenized\n   * @param minGram the smallest n-gram to generate\n   * @param maxGram the largest n-gram to generate\n   */\n  public NGramTokenFilter(TokenStream input, int minGram, int maxGram) {\n    super(new CodepointCountFilter(input, minGram, Integer.MAX_VALUE));\n    if (minGram < 1) {\n      throw new IllegalArgumentException(\"minGram must be greater than zero\");\n    }\n    if (minGram > maxGram) {\n      throw new IllegalArgumentException(\"minGram must not be greater than maxGram\");\n    }\n    this.minGram = minGram;\n    this.maxGram = maxGram;\n\n    posIncAtt = addAttribute(PositionIncrementAttribute.class);\n  }\n\n","sourceOld":"  /**\n   * Creates NGramTokenFilter with given min and max n-grams.\n   * @param input {@link TokenStream} holding the input to be tokenized\n   * @param minGram the smallest n-gram to generate\n   * @param maxGram the largest n-gram to generate\n   */\n  public NGramTokenFilter(TokenStream input, int minGram, int maxGram) {\n    super(new CodepointCountFilter(input, minGram, Integer.MAX_VALUE));\n    if (minGram < 1) {\n      throw new IllegalArgumentException(\"minGram must be greater than zero\");\n    }\n    if (minGram > maxGram) {\n      throw new IllegalArgumentException(\"minGram must not be greater than maxGram\");\n    }\n    this.minGram = minGram;\n    this.maxGram = maxGram;\n\n    posIncAtt = addAttribute(PositionIncrementAttribute.class);\n    posLenAtt = addAttribute(PositionLengthAttribute.class);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"bbbdd19493fa8ae4bdac9205ae34e7387f08f304","date":1484561803,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/ngram/NGramTokenFilter#NGramTokenFilter(TokenStream,int,int).mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/ngram/NGramTokenFilter#NGramTokenFilter(TokenStream,int,int).mjava","sourceNew":"  /**\n   * Creates NGramTokenFilter with given min and max n-grams.\n   * @param input {@link TokenStream} holding the input to be tokenized\n   * @param minGram the smallest n-gram to generate\n   * @param maxGram the largest n-gram to generate\n   */\n  public NGramTokenFilter(TokenStream input, int minGram, int maxGram) {\n    super(new CodepointCountFilter(input, minGram, Integer.MAX_VALUE));\n    if (minGram < 1) {\n      throw new IllegalArgumentException(\"minGram must be greater than zero\");\n    }\n    if (minGram > maxGram) {\n      throw new IllegalArgumentException(\"minGram must not be greater than maxGram\");\n    }\n    this.minGram = minGram;\n    this.maxGram = maxGram;\n\n    posIncAtt = addAttribute(PositionIncrementAttribute.class);\n  }\n\n","sourceOld":"  /**\n   * Creates NGramTokenFilter with given min and max n-grams.\n   * @param input {@link TokenStream} holding the input to be tokenized\n   * @param minGram the smallest n-gram to generate\n   * @param maxGram the largest n-gram to generate\n   */\n  public NGramTokenFilter(TokenStream input, int minGram, int maxGram) {\n    super(new CodepointCountFilter(input, minGram, Integer.MAX_VALUE));\n    if (minGram < 1) {\n      throw new IllegalArgumentException(\"minGram must be greater than zero\");\n    }\n    if (minGram > maxGram) {\n      throw new IllegalArgumentException(\"minGram must not be greater than maxGram\");\n    }\n    this.minGram = minGram;\n    this.maxGram = maxGram;\n\n    posIncAtt = addAttribute(PositionIncrementAttribute.class);\n    posLenAtt = addAttribute(PositionLengthAttribute.class);\n  }\n\n","bugFix":["379db3ad24c4f0214f30a122265a6d6be003a99d"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"507e7decdf00981d09a74632ea30299a4ce6ba72","date":1484600874,"type":3,"author":"Kevin Risden","isMerge":true,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/ngram/NGramTokenFilter#NGramTokenFilter(TokenStream,int,int).mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/ngram/NGramTokenFilter#NGramTokenFilter(TokenStream,int,int).mjava","sourceNew":"  /**\n   * Creates NGramTokenFilter with given min and max n-grams.\n   * @param input {@link TokenStream} holding the input to be tokenized\n   * @param minGram the smallest n-gram to generate\n   * @param maxGram the largest n-gram to generate\n   */\n  public NGramTokenFilter(TokenStream input, int minGram, int maxGram) {\n    super(new CodepointCountFilter(input, minGram, Integer.MAX_VALUE));\n    if (minGram < 1) {\n      throw new IllegalArgumentException(\"minGram must be greater than zero\");\n    }\n    if (minGram > maxGram) {\n      throw new IllegalArgumentException(\"minGram must not be greater than maxGram\");\n    }\n    this.minGram = minGram;\n    this.maxGram = maxGram;\n\n    posIncAtt = addAttribute(PositionIncrementAttribute.class);\n  }\n\n","sourceOld":"  /**\n   * Creates NGramTokenFilter with given min and max n-grams.\n   * @param input {@link TokenStream} holding the input to be tokenized\n   * @param minGram the smallest n-gram to generate\n   * @param maxGram the largest n-gram to generate\n   */\n  public NGramTokenFilter(TokenStream input, int minGram, int maxGram) {\n    super(new CodepointCountFilter(input, minGram, Integer.MAX_VALUE));\n    if (minGram < 1) {\n      throw new IllegalArgumentException(\"minGram must be greater than zero\");\n    }\n    if (minGram > maxGram) {\n      throw new IllegalArgumentException(\"minGram must not be greater than maxGram\");\n    }\n    this.minGram = minGram;\n    this.maxGram = maxGram;\n\n    posIncAtt = addAttribute(PositionIncrementAttribute.class);\n    posLenAtt = addAttribute(PositionLengthAttribute.class);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8a255765a5625ff80fba75863de5a16ea392015e","date":1528161860,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/ngram/NGramTokenFilter#NGramTokenFilter(TokenStream,int,int).mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/ngram/NGramTokenFilter#NGramTokenFilter(TokenStream,int,int).mjava","sourceNew":"  /**\n   * Creates an NGramTokenFilter that, for a given input term, produces all\n   * contained n-grams with lengths &gt;= minGram and &lt;= maxGram.\n   * \n   * <p>\n   * Behaves the same as\n   * {@link #NGramTokenFilter(TokenStream, int, int, boolean)\n   * NGramTokenFilter(input, minGram, maxGram, false)}\n   * \n   * @param input {@link TokenStream} holding the input to be tokenized\n   * @param minGram the minimum length of the generated n-grams\n   * @param maxGram the maximum length of the generated n-grams\n   *\n   * @deprecated since 7.4. Use\n   * {@link #NGramTokenFilter(TokenStream, int, int, boolean)} instead.\n   */\n  @Deprecated\n  public NGramTokenFilter(TokenStream input, int minGram, int maxGram) {\n    this(input, minGram, maxGram, DEFAULT_PRESERVE_ORIGINAL);\n  }\n\n","sourceOld":"  /**\n   * Creates NGramTokenFilter with given min and max n-grams.\n   * @param input {@link TokenStream} holding the input to be tokenized\n   * @param minGram the smallest n-gram to generate\n   * @param maxGram the largest n-gram to generate\n   */\n  public NGramTokenFilter(TokenStream input, int minGram, int maxGram) {\n    super(new CodepointCountFilter(input, minGram, Integer.MAX_VALUE));\n    if (minGram < 1) {\n      throw new IllegalArgumentException(\"minGram must be greater than zero\");\n    }\n    if (minGram > maxGram) {\n      throw new IllegalArgumentException(\"minGram must not be greater than maxGram\");\n    }\n    this.minGram = minGram;\n    this.maxGram = maxGram;\n\n    posIncAtt = addAttribute(PositionIncrementAttribute.class);\n  }\n\n","bugFix":["379db3ad24c4f0214f30a122265a6d6be003a99d"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7f9d9185dd79758c4a333e1856adfe1388f008e3","date":1528166448,"type":4,"author":"Robert Muir","isMerge":false,"pathNew":"/dev/null","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/ngram/NGramTokenFilter#NGramTokenFilter(TokenStream,int,int).mjava","sourceNew":null,"sourceOld":"  /**\n   * Creates an NGramTokenFilter that, for a given input term, produces all\n   * contained n-grams with lengths &gt;= minGram and &lt;= maxGram.\n   * \n   * <p>\n   * Behaves the same as\n   * {@link #NGramTokenFilter(TokenStream, int, int, boolean)\n   * NGramTokenFilter(input, minGram, maxGram, false)}\n   * \n   * @param input {@link TokenStream} holding the input to be tokenized\n   * @param minGram the minimum length of the generated n-grams\n   * @param maxGram the maximum length of the generated n-grams\n   *\n   * @deprecated since 7.4. Use\n   * {@link #NGramTokenFilter(TokenStream, int, int, boolean)} instead.\n   */\n  @Deprecated\n  public NGramTokenFilter(TokenStream input, int minGram, int maxGram) {\n    this(input, minGram, maxGram, DEFAULT_PRESERVE_ORIGINAL);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f592209545c71895260367152601e9200399776d","date":1528238935,"type":5,"author":"Michael Braun","isMerge":true,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/ngram/NGramTokenFilter#NGramTokenFilter(TokenStream,int,int,boolean).mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/ngram/NGramTokenFilter#NGramTokenFilter(TokenStream,int,int).mjava","sourceNew":"  /**\n   * Creates an NGramTokenFilter that, for a given input term, produces all\n   * contained n-grams with lengths &gt;= minGram and &lt;= maxGram. Will\n   * optionally preserve the original term when its length is outside of the\n   * defined range.\n   * \n   * Note: Care must be taken when choosing minGram and maxGram; depending\n   * on the input token size, this filter potentially produces a huge number\n   * of terms.\n   * \n   * @param input {@link TokenStream} holding the input to be tokenized\n   * @param minGram the minimum length of the generated n-grams\n   * @param maxGram the maximum length of the generated n-grams\n   * @param preserveOriginal Whether or not to keep the original term when it\n   * is shorter than minGram or longer than maxGram\n   */\n  public NGramTokenFilter(TokenStream input, int minGram, int maxGram, boolean preserveOriginal) {\n    super(input);\n    if (minGram < 1) {\n      throw new IllegalArgumentException(\"minGram must be greater than zero\");\n    }\n    if (minGram > maxGram) {\n      throw new IllegalArgumentException(\"minGram must not be greater than maxGram\");\n    }\n    this.minGram = minGram;\n    this.maxGram = maxGram;\n    this.preserveOriginal = preserveOriginal;\n  }\n\n","sourceOld":"  /**\n   * Creates NGramTokenFilter with given min and max n-grams.\n   * @param input {@link TokenStream} holding the input to be tokenized\n   * @param minGram the smallest n-gram to generate\n   * @param maxGram the largest n-gram to generate\n   */\n  public NGramTokenFilter(TokenStream input, int minGram, int maxGram) {\n    super(new CodepointCountFilter(input, minGram, Integer.MAX_VALUE));\n    if (minGram < 1) {\n      throw new IllegalArgumentException(\"minGram must be greater than zero\");\n    }\n    if (minGram > maxGram) {\n      throw new IllegalArgumentException(\"minGram must not be greater than maxGram\");\n    }\n    this.minGram = minGram;\n    this.maxGram = maxGram;\n\n    posIncAtt = addAttribute(PositionIncrementAttribute.class);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b70042a8a492f7054d480ccdd2be9796510d4327","date":1528386658,"type":5,"author":"Alessandro Benedetti","isMerge":true,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/ngram/NGramTokenFilter#NGramTokenFilter(TokenStream,int,int,boolean).mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/ngram/NGramTokenFilter#NGramTokenFilter(TokenStream,int,int).mjava","sourceNew":"  /**\n   * Creates an NGramTokenFilter that, for a given input term, produces all\n   * contained n-grams with lengths &gt;= minGram and &lt;= maxGram. Will\n   * optionally preserve the original term when its length is outside of the\n   * defined range.\n   * \n   * Note: Care must be taken when choosing minGram and maxGram; depending\n   * on the input token size, this filter potentially produces a huge number\n   * of terms.\n   * \n   * @param input {@link TokenStream} holding the input to be tokenized\n   * @param minGram the minimum length of the generated n-grams\n   * @param maxGram the maximum length of the generated n-grams\n   * @param preserveOriginal Whether or not to keep the original term when it\n   * is shorter than minGram or longer than maxGram\n   */\n  public NGramTokenFilter(TokenStream input, int minGram, int maxGram, boolean preserveOriginal) {\n    super(input);\n    if (minGram < 1) {\n      throw new IllegalArgumentException(\"minGram must be greater than zero\");\n    }\n    if (minGram > maxGram) {\n      throw new IllegalArgumentException(\"minGram must not be greater than maxGram\");\n    }\n    this.minGram = minGram;\n    this.maxGram = maxGram;\n    this.preserveOriginal = preserveOriginal;\n  }\n\n","sourceOld":"  /**\n   * Creates NGramTokenFilter with given min and max n-grams.\n   * @param input {@link TokenStream} holding the input to be tokenized\n   * @param minGram the smallest n-gram to generate\n   * @param maxGram the largest n-gram to generate\n   */\n  public NGramTokenFilter(TokenStream input, int minGram, int maxGram) {\n    super(new CodepointCountFilter(input, minGram, Integer.MAX_VALUE));\n    if (minGram < 1) {\n      throw new IllegalArgumentException(\"minGram must be greater than zero\");\n    }\n    if (minGram > maxGram) {\n      throw new IllegalArgumentException(\"minGram must not be greater than maxGram\");\n    }\n    this.minGram = minGram;\n    this.maxGram = maxGram;\n\n    posIncAtt = addAttribute(PositionIncrementAttribute.class);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"8a255765a5625ff80fba75863de5a16ea392015e":["bbbdd19493fa8ae4bdac9205ae34e7387f08f304"],"fba4cd6a5aae0bc17cc1cbf1e84b0ae32ee039dc":["379db3ad24c4f0214f30a122265a6d6be003a99d"],"4188a39e51b877e66d58390c0583e205eb3d1131":["57dc82c7b33cd580e7ab5179019bc78f3d7f8e79"],"4c807c4005aae1acaf5cebc9af40883985fb89a8":["b89678825b68eccaf09e6ab71675fc0b0af1e099"],"507e7decdf00981d09a74632ea30299a4ce6ba72":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b","bbbdd19493fa8ae4bdac9205ae34e7387f08f304"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["379db3ad24c4f0214f30a122265a6d6be003a99d","57dc82c7b33cd580e7ab5179019bc78f3d7f8e79"],"7f9d9185dd79758c4a333e1856adfe1388f008e3":["8a255765a5625ff80fba75863de5a16ea392015e"],"b89678825b68eccaf09e6ab71675fc0b0af1e099":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"379db3ad24c4f0214f30a122265a6d6be003a99d":["4c807c4005aae1acaf5cebc9af40883985fb89a8"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"b70042a8a492f7054d480ccdd2be9796510d4327":["bbbdd19493fa8ae4bdac9205ae34e7387f08f304","7f9d9185dd79758c4a333e1856adfe1388f008e3"],"57dc82c7b33cd580e7ab5179019bc78f3d7f8e79":["379db3ad24c4f0214f30a122265a6d6be003a99d","fba4cd6a5aae0bc17cc1cbf1e84b0ae32ee039dc"],"f592209545c71895260367152601e9200399776d":["bbbdd19493fa8ae4bdac9205ae34e7387f08f304","7f9d9185dd79758c4a333e1856adfe1388f008e3"],"bbbdd19493fa8ae4bdac9205ae34e7387f08f304":["57dc82c7b33cd580e7ab5179019bc78f3d7f8e79","4188a39e51b877e66d58390c0583e205eb3d1131"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["7f9d9185dd79758c4a333e1856adfe1388f008e3"]},"commit2Childs":{"8a255765a5625ff80fba75863de5a16ea392015e":["7f9d9185dd79758c4a333e1856adfe1388f008e3"],"fba4cd6a5aae0bc17cc1cbf1e84b0ae32ee039dc":["57dc82c7b33cd580e7ab5179019bc78f3d7f8e79"],"4188a39e51b877e66d58390c0583e205eb3d1131":["bbbdd19493fa8ae4bdac9205ae34e7387f08f304"],"4c807c4005aae1acaf5cebc9af40883985fb89a8":["379db3ad24c4f0214f30a122265a6d6be003a99d"],"507e7decdf00981d09a74632ea30299a4ce6ba72":[],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["507e7decdf00981d09a74632ea30299a4ce6ba72"],"b89678825b68eccaf09e6ab71675fc0b0af1e099":["4c807c4005aae1acaf5cebc9af40883985fb89a8"],"7f9d9185dd79758c4a333e1856adfe1388f008e3":["b70042a8a492f7054d480ccdd2be9796510d4327","f592209545c71895260367152601e9200399776d","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"379db3ad24c4f0214f30a122265a6d6be003a99d":["fba4cd6a5aae0bc17cc1cbf1e84b0ae32ee039dc","4cce5816ef15a48a0bc11e5d400497ee4301dd3b","57dc82c7b33cd580e7ab5179019bc78f3d7f8e79"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["b89678825b68eccaf09e6ab71675fc0b0af1e099"],"b70042a8a492f7054d480ccdd2be9796510d4327":[],"57dc82c7b33cd580e7ab5179019bc78f3d7f8e79":["4188a39e51b877e66d58390c0583e205eb3d1131","4cce5816ef15a48a0bc11e5d400497ee4301dd3b","bbbdd19493fa8ae4bdac9205ae34e7387f08f304"],"f592209545c71895260367152601e9200399776d":[],"bbbdd19493fa8ae4bdac9205ae34e7387f08f304":["8a255765a5625ff80fba75863de5a16ea392015e","507e7decdf00981d09a74632ea30299a4ce6ba72","b70042a8a492f7054d480ccdd2be9796510d4327","f592209545c71895260367152601e9200399776d"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["507e7decdf00981d09a74632ea30299a4ce6ba72","b70042a8a492f7054d480ccdd2be9796510d4327","f592209545c71895260367152601e9200399776d","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}