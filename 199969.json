{"path":"lucene/core/src/java/org/apache/lucene/index/IndexingChain#writePoints(SegmentWriteState,Sorter.DocMap).mjava","commits":[{"id":"7a6f8af01d9b3067b143bbdc0a492720e2af97cf","date":1600157724,"type":1,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexingChain#writePoints(SegmentWriteState,Sorter.DocMap).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/DefaultIndexingChain#writePoints(SegmentWriteState,Sorter.DocMap).mjava","sourceNew":"  /** Writes all buffered points. */\n  private void writePoints(SegmentWriteState state, Sorter.DocMap sortMap) throws IOException {\n    PointsWriter pointsWriter = null;\n    boolean success = false;\n    try {\n      for (int i=0;i<fieldHash.length;i++) {\n        PerField perField = fieldHash[i];\n        while (perField != null) {\n          if (perField.pointValuesWriter != null) {\n            if (perField.fieldInfo.getPointDimensionCount() == 0) {\n              // BUG\n              throw new AssertionError(\"segment=\" + state.segmentInfo + \": field=\\\"\" + perField.fieldInfo.name + \"\\\" has no points but wrote them\");\n            }\n            if (pointsWriter == null) {\n              // lazy init\n              PointsFormat fmt = state.segmentInfo.getCodec().pointsFormat();\n              if (fmt == null) {\n                throw new IllegalStateException(\"field=\\\"\" + perField.fieldInfo.name + \"\\\" was indexed as points but codec does not support points\");\n              }\n              pointsWriter = fmt.fieldsWriter(state);\n            }\n\n            perField.pointValuesWriter.flush(state, sortMap, pointsWriter);\n            perField.pointValuesWriter = null;\n          } else if (perField.fieldInfo.getPointDimensionCount() != 0) {\n            // BUG\n            throw new AssertionError(\"segment=\" + state.segmentInfo + \": field=\\\"\" + perField.fieldInfo.name + \"\\\" has points but did not write them\");\n          }\n          perField = perField.next;\n        }\n      }\n      if (pointsWriter != null) {\n        pointsWriter.finish();\n      }\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(pointsWriter);\n      } else {\n        IOUtils.closeWhileHandlingException(pointsWriter);\n      }\n    }\n  }\n\n","sourceOld":"  /** Writes all buffered points. */\n  private void writePoints(SegmentWriteState state, Sorter.DocMap sortMap) throws IOException {\n    PointsWriter pointsWriter = null;\n    boolean success = false;\n    try {\n      for (int i=0;i<fieldHash.length;i++) {\n        PerField perField = fieldHash[i];\n        while (perField != null) {\n          if (perField.pointValuesWriter != null) {\n            if (perField.fieldInfo.getPointDimensionCount() == 0) {\n              // BUG\n              throw new AssertionError(\"segment=\" + state.segmentInfo + \": field=\\\"\" + perField.fieldInfo.name + \"\\\" has no points but wrote them\");\n            }\n            if (pointsWriter == null) {\n              // lazy init\n              PointsFormat fmt = state.segmentInfo.getCodec().pointsFormat();\n              if (fmt == null) {\n                throw new IllegalStateException(\"field=\\\"\" + perField.fieldInfo.name + \"\\\" was indexed as points but codec does not support points\");\n              }\n              pointsWriter = fmt.fieldsWriter(state);\n            }\n\n            perField.pointValuesWriter.flush(state, sortMap, pointsWriter);\n            perField.pointValuesWriter = null;\n          } else if (perField.fieldInfo.getPointDimensionCount() != 0) {\n            // BUG\n            throw new AssertionError(\"segment=\" + state.segmentInfo + \": field=\\\"\" + perField.fieldInfo.name + \"\\\" has points but did not write them\");\n          }\n          perField = perField.next;\n        }\n      }\n      if (pointsWriter != null) {\n        pointsWriter.finish();\n      }\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(pointsWriter);\n      } else {\n        IOUtils.closeWhileHandlingException(pointsWriter);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"680b6449f09827f58fe987aff279e014c311d966","date":1600247985,"type":1,"author":"noblepaul","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexingChain#writePoints(SegmentWriteState,Sorter.DocMap).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/DefaultIndexingChain#writePoints(SegmentWriteState,Sorter.DocMap).mjava","sourceNew":"  /** Writes all buffered points. */\n  private void writePoints(SegmentWriteState state, Sorter.DocMap sortMap) throws IOException {\n    PointsWriter pointsWriter = null;\n    boolean success = false;\n    try {\n      for (int i=0;i<fieldHash.length;i++) {\n        PerField perField = fieldHash[i];\n        while (perField != null) {\n          if (perField.pointValuesWriter != null) {\n            if (perField.fieldInfo.getPointDimensionCount() == 0) {\n              // BUG\n              throw new AssertionError(\"segment=\" + state.segmentInfo + \": field=\\\"\" + perField.fieldInfo.name + \"\\\" has no points but wrote them\");\n            }\n            if (pointsWriter == null) {\n              // lazy init\n              PointsFormat fmt = state.segmentInfo.getCodec().pointsFormat();\n              if (fmt == null) {\n                throw new IllegalStateException(\"field=\\\"\" + perField.fieldInfo.name + \"\\\" was indexed as points but codec does not support points\");\n              }\n              pointsWriter = fmt.fieldsWriter(state);\n            }\n\n            perField.pointValuesWriter.flush(state, sortMap, pointsWriter);\n            perField.pointValuesWriter = null;\n          } else if (perField.fieldInfo.getPointDimensionCount() != 0) {\n            // BUG\n            throw new AssertionError(\"segment=\" + state.segmentInfo + \": field=\\\"\" + perField.fieldInfo.name + \"\\\" has points but did not write them\");\n          }\n          perField = perField.next;\n        }\n      }\n      if (pointsWriter != null) {\n        pointsWriter.finish();\n      }\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(pointsWriter);\n      } else {\n        IOUtils.closeWhileHandlingException(pointsWriter);\n      }\n    }\n  }\n\n","sourceOld":"  /** Writes all buffered points. */\n  private void writePoints(SegmentWriteState state, Sorter.DocMap sortMap) throws IOException {\n    PointsWriter pointsWriter = null;\n    boolean success = false;\n    try {\n      for (int i=0;i<fieldHash.length;i++) {\n        PerField perField = fieldHash[i];\n        while (perField != null) {\n          if (perField.pointValuesWriter != null) {\n            if (perField.fieldInfo.getPointDimensionCount() == 0) {\n              // BUG\n              throw new AssertionError(\"segment=\" + state.segmentInfo + \": field=\\\"\" + perField.fieldInfo.name + \"\\\" has no points but wrote them\");\n            }\n            if (pointsWriter == null) {\n              // lazy init\n              PointsFormat fmt = state.segmentInfo.getCodec().pointsFormat();\n              if (fmt == null) {\n                throw new IllegalStateException(\"field=\\\"\" + perField.fieldInfo.name + \"\\\" was indexed as points but codec does not support points\");\n              }\n              pointsWriter = fmt.fieldsWriter(state);\n            }\n\n            perField.pointValuesWriter.flush(state, sortMap, pointsWriter);\n            perField.pointValuesWriter = null;\n          } else if (perField.fieldInfo.getPointDimensionCount() != 0) {\n            // BUG\n            throw new AssertionError(\"segment=\" + state.segmentInfo + \": field=\\\"\" + perField.fieldInfo.name + \"\\\" has points but did not write them\");\n          }\n          perField = perField.next;\n        }\n      }\n      if (pointsWriter != null) {\n        pointsWriter.finish();\n      }\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(pointsWriter);\n      } else {\n        IOUtils.closeWhileHandlingException(pointsWriter);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"680b6449f09827f58fe987aff279e014c311d966":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","7a6f8af01d9b3067b143bbdc0a492720e2af97cf"],"7a6f8af01d9b3067b143bbdc0a492720e2af97cf":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["680b6449f09827f58fe987aff279e014c311d966"]},"commit2Childs":{"680b6449f09827f58fe987aff279e014c311d966":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"7a6f8af01d9b3067b143bbdc0a492720e2af97cf":["680b6449f09827f58fe987aff279e014c311d966"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["680b6449f09827f58fe987aff279e014c311d966","7a6f8af01d9b3067b143bbdc0a492720e2af97cf"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}