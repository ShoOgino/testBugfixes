{"path":"src/java/org/apache/lucene/analysis/Analyzer#tokenStream(Reader).mjava","commits":[{"id":"91109046a59c58ee0ee5d0d2767b08d1f30d6702","date":1000830588,"type":0,"author":"Jason van Zyl","isMerge":false,"pathNew":"src/java/org/apache/lucene/analysis/Analyzer#tokenStream(Reader).mjava","pathOld":"/dev/null","sourceNew":"  /** Creates a TokenStream which tokenizes all the text in the provided\n   *  Reader.  Provided for backward compatibility only.\n   * @deprecated use tokenStream(String, Reader) instead.\n   * @see tokenStream(String, Reader)\n   */\n  public TokenStream tokenStream(Reader reader)\n  {\n\t  return tokenStream(null, reader);\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"bc5e35d003eb3eafe297c99dab2796a8237909fb","date":1001443130,"type":3,"author":"Doug Cutting","isMerge":false,"pathNew":"src/java/org/apache/lucene/analysis/Analyzer#tokenStream(Reader).mjava","pathOld":"src/java/org/apache/lucene/analysis/Analyzer#tokenStream(Reader).mjava","sourceNew":"  /** Creates a TokenStream which tokenizes all the text in the provided\n   *  Reader.  Provided for backward compatibility only.\n   * @deprecated use tokenStream(String, Reader) instead.\n   * @see #tokenStream(String, Reader)\n   */\n  public TokenStream tokenStream(Reader reader)\n  {\n\t  return tokenStream(null, reader);\n  }\n\n","sourceOld":"  /** Creates a TokenStream which tokenizes all the text in the provided\n   *  Reader.  Provided for backward compatibility only.\n   * @deprecated use tokenStream(String, Reader) instead.\n   * @see tokenStream(String, Reader)\n   */\n  public TokenStream tokenStream(Reader reader)\n  {\n\t  return tokenStream(null, reader);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c69e98ffd83f56083b99e5443ca713cd5783a2ae","date":1142955392,"type":4,"author":"Yonik Seeley","isMerge":false,"pathNew":"/dev/null","pathOld":"src/java/org/apache/lucene/analysis/Analyzer#tokenStream(Reader).mjava","sourceNew":null,"sourceOld":"  /** Creates a TokenStream which tokenizes all the text in the provided\n   *  Reader.  Provided for backward compatibility only.\n   * @deprecated use tokenStream(String, Reader) instead.\n   * @see #tokenStream(String, Reader)\n   */\n  public TokenStream tokenStream(Reader reader)\n  {\n\t  return tokenStream(null, reader);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"91109046a59c58ee0ee5d0d2767b08d1f30d6702":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"c69e98ffd83f56083b99e5443ca713cd5783a2ae":["bc5e35d003eb3eafe297c99dab2796a8237909fb"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"bc5e35d003eb3eafe297c99dab2796a8237909fb":["91109046a59c58ee0ee5d0d2767b08d1f30d6702"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["c69e98ffd83f56083b99e5443ca713cd5783a2ae"]},"commit2Childs":{"91109046a59c58ee0ee5d0d2767b08d1f30d6702":["bc5e35d003eb3eafe297c99dab2796a8237909fb"],"c69e98ffd83f56083b99e5443ca713cd5783a2ae":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["91109046a59c58ee0ee5d0d2767b08d1f30d6702"],"bc5e35d003eb3eafe297c99dab2796a8237909fb":["c69e98ffd83f56083b99e5443ca713cd5783a2ae"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}