{"path":"src/test/org/apache/lucene/index/TestPayloads.PayloadAnalyzer#tokenStream(String,Reader).mjava","commits":[{"id":"8522ae207a56c6db28ca06fe6cc33e70911c3600","date":1173935743,"type":0,"author":"Michael Busch","isMerge":false,"pathNew":"src/test/org/apache/lucene/index/TestPayloads.PayloadAnalyzer#tokenStream(String,Reader).mjava","pathOld":"/dev/null","sourceNew":"        public TokenStream tokenStream(String fieldName, Reader reader) {\r\n            PayloadData payload = (PayloadData) fieldToData.get(fieldName);\r\n            TokenStream ts = new WhitespaceTokenizer(reader);\r\n            if (payload != null) {\r\n                if (payload.numFieldInstancesToSkip == 0) {\r\n                    ts = new PayloadFilter(ts, payload.data, payload.offset, payload.length);\r\n                } else {\r\n                    payload.numFieldInstancesToSkip--;\r\n                }\r\n            }\r\n            return ts;\r\n        }\r\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2123bddbd65dea198cac380540636ce43a880403","date":1211269254,"type":3,"author":"Michael Busch","isMerge":false,"pathNew":"src/test/org/apache/lucene/index/TestPayloads.PayloadAnalyzer#tokenStream(String,Reader).mjava","pathOld":"src/test/org/apache/lucene/index/TestPayloads.PayloadAnalyzer#tokenStream(String,Reader).mjava","sourceNew":"        public TokenStream tokenStream(String fieldName, Reader reader) {\n            PayloadData payload = (PayloadData) fieldToData.get(fieldName);\n            TokenStream ts = new WhitespaceTokenizer(reader);\n            if (payload != null) {\n                if (payload.numFieldInstancesToSkip == 0) {\n                    ts = new PayloadFilter(ts, payload.data, payload.offset, payload.length);\n                } else {\n                    payload.numFieldInstancesToSkip--;\n                }\n            }\n            return ts;\n        }\n\n","sourceOld":"        public TokenStream tokenStream(String fieldName, Reader reader) {\r\n            PayloadData payload = (PayloadData) fieldToData.get(fieldName);\r\n            TokenStream ts = new WhitespaceTokenizer(reader);\r\n            if (payload != null) {\r\n                if (payload.numFieldInstancesToSkip == 0) {\r\n                    ts = new PayloadFilter(ts, payload.data, payload.offset, payload.length);\r\n                } else {\r\n                    payload.numFieldInstancesToSkip--;\r\n                }\r\n            }\r\n            return ts;\r\n        }\r\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1326054a8d3aa66382d49decc7f330955c9c6f71","date":1257386139,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"src/test/org/apache/lucene/index/TestPayloads.PayloadAnalyzer#tokenStream(String,Reader).mjava","pathOld":"src/test/org/apache/lucene/index/TestPayloads.PayloadAnalyzer#tokenStream(String,Reader).mjava","sourceNew":"        @Override\n        public TokenStream tokenStream(String fieldName, Reader reader) {\n            PayloadData payload = (PayloadData) fieldToData.get(fieldName);\n            TokenStream ts = new WhitespaceTokenizer(reader);\n            if (payload != null) {\n                if (payload.numFieldInstancesToSkip == 0) {\n                    ts = new PayloadFilter(ts, payload.data, payload.offset, payload.length);\n                } else {\n                    payload.numFieldInstancesToSkip--;\n                }\n            }\n            return ts;\n        }\n\n","sourceOld":"        public TokenStream tokenStream(String fieldName, Reader reader) {\n            PayloadData payload = (PayloadData) fieldToData.get(fieldName);\n            TokenStream ts = new WhitespaceTokenizer(reader);\n            if (payload != null) {\n                if (payload.numFieldInstancesToSkip == 0) {\n                    ts = new PayloadFilter(ts, payload.data, payload.offset, payload.length);\n                } else {\n                    payload.numFieldInstancesToSkip--;\n                }\n            }\n            return ts;\n        }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e450c7d50c2fc84c963d0d7ade9d3217d868064d","date":1259932067,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/test/org/apache/lucene/index/TestPayloads.PayloadAnalyzer#tokenStream(String,Reader).mjava","pathOld":"src/test/org/apache/lucene/index/TestPayloads.PayloadAnalyzer#tokenStream(String,Reader).mjava","sourceNew":"        @Override\n        public TokenStream tokenStream(String fieldName, Reader reader) {\n            PayloadData payload =  fieldToData.get(fieldName);\n            TokenStream ts = new WhitespaceTokenizer(reader);\n            if (payload != null) {\n                if (payload.numFieldInstancesToSkip == 0) {\n                    ts = new PayloadFilter(ts, payload.data, payload.offset, payload.length);\n                } else {\n                    payload.numFieldInstancesToSkip--;\n                }\n            }\n            return ts;\n        }\n\n","sourceOld":"        @Override\n        public TokenStream tokenStream(String fieldName, Reader reader) {\n            PayloadData payload = (PayloadData) fieldToData.get(fieldName);\n            TokenStream ts = new WhitespaceTokenizer(reader);\n            if (payload != null) {\n                if (payload.numFieldInstancesToSkip == 0) {\n                    ts = new PayloadFilter(ts, payload.data, payload.offset, payload.length);\n                } else {\n                    payload.numFieldInstancesToSkip--;\n                }\n            }\n            return ts;\n        }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fe0932c1d340f83fb0a611e5829b3046a1cc1152","date":1264946739,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"src/test/org/apache/lucene/index/TestPayloads.PayloadAnalyzer#tokenStream(String,Reader).mjava","pathOld":"src/test/org/apache/lucene/index/TestPayloads.PayloadAnalyzer#tokenStream(String,Reader).mjava","sourceNew":"        @Override\n        public TokenStream tokenStream(String fieldName, Reader reader) {\n            PayloadData payload =  fieldToData.get(fieldName);\n            TokenStream ts = new WhitespaceTokenizer(Version.LUCENE_CURRENT, reader);\n            if (payload != null) {\n                if (payload.numFieldInstancesToSkip == 0) {\n                    ts = new PayloadFilter(ts, payload.data, payload.offset, payload.length);\n                } else {\n                    payload.numFieldInstancesToSkip--;\n                }\n            }\n            return ts;\n        }\n\n","sourceOld":"        @Override\n        public TokenStream tokenStream(String fieldName, Reader reader) {\n            PayloadData payload =  fieldToData.get(fieldName);\n            TokenStream ts = new WhitespaceTokenizer(reader);\n            if (payload != null) {\n                if (payload.numFieldInstancesToSkip == 0) {\n                    ts = new PayloadFilter(ts, payload.data, payload.offset, payload.length);\n                } else {\n                    payload.numFieldInstancesToSkip--;\n                }\n            }\n            return ts;\n        }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"55f083e91bb056b57de136da1dfc3b9b6ecc4ef6","date":1265808957,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"src/test/org/apache/lucene/index/TestPayloads.PayloadAnalyzer#tokenStream(String,Reader).mjava","pathOld":"src/test/org/apache/lucene/index/TestPayloads.PayloadAnalyzer#tokenStream(String,Reader).mjava","sourceNew":"        @Override\n        public TokenStream tokenStream(String fieldName, Reader reader) {\n            PayloadData payload =  fieldToData.get(fieldName);\n            TokenStream ts = new WhitespaceTokenizer(TEST_VERSION_CURRENT, reader);\n            if (payload != null) {\n                if (payload.numFieldInstancesToSkip == 0) {\n                    ts = new PayloadFilter(ts, payload.data, payload.offset, payload.length);\n                } else {\n                    payload.numFieldInstancesToSkip--;\n                }\n            }\n            return ts;\n        }\n\n","sourceOld":"        @Override\n        public TokenStream tokenStream(String fieldName, Reader reader) {\n            PayloadData payload =  fieldToData.get(fieldName);\n            TokenStream ts = new WhitespaceTokenizer(Version.LUCENE_CURRENT, reader);\n            if (payload != null) {\n                if (payload.numFieldInstancesToSkip == 0) {\n                    ts = new PayloadFilter(ts, payload.data, payload.offset, payload.length);\n                } else {\n                    payload.numFieldInstancesToSkip--;\n                }\n            }\n            return ts;\n        }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9454a6510e2db155fb01faa5c049b06ece95fab9","date":1453508333,"type":5,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestPayloads.PayloadAnalyzer#tokenStream(String,Reader).mjava","pathOld":"src/test/org/apache/lucene/index/TestPayloads.PayloadAnalyzer#tokenStream(String,Reader).mjava","sourceNew":"        @Override\n        public TokenStream tokenStream(String fieldName, Reader reader) {\n            PayloadData payload =  fieldToData.get(fieldName);\n            TokenStream ts = new WhitespaceTokenizer(TEST_VERSION_CURRENT, reader);\n            if (payload != null) {\n                if (payload.numFieldInstancesToSkip == 0) {\n                    ts = new PayloadFilter(ts, payload.data, payload.offset, payload.length);\n                } else {\n                    payload.numFieldInstancesToSkip--;\n                }\n            }\n            return ts;\n        }\n\n","sourceOld":"        @Override\n        public TokenStream tokenStream(String fieldName, Reader reader) {\n            PayloadData payload =  fieldToData.get(fieldName);\n            TokenStream ts = new WhitespaceTokenizer(TEST_VERSION_CURRENT, reader);\n            if (payload != null) {\n                if (payload.numFieldInstancesToSkip == 0) {\n                    ts = new PayloadFilter(ts, payload.data, payload.offset, payload.length);\n                } else {\n                    payload.numFieldInstancesToSkip--;\n                }\n            }\n            return ts;\n        }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"1326054a8d3aa66382d49decc7f330955c9c6f71":["2123bddbd65dea198cac380540636ce43a880403"],"8522ae207a56c6db28ca06fe6cc33e70911c3600":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"fe0932c1d340f83fb0a611e5829b3046a1cc1152":["e450c7d50c2fc84c963d0d7ade9d3217d868064d"],"55f083e91bb056b57de136da1dfc3b9b6ecc4ef6":["fe0932c1d340f83fb0a611e5829b3046a1cc1152"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"2123bddbd65dea198cac380540636ce43a880403":["8522ae207a56c6db28ca06fe6cc33e70911c3600"],"e450c7d50c2fc84c963d0d7ade9d3217d868064d":["1326054a8d3aa66382d49decc7f330955c9c6f71"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["55f083e91bb056b57de136da1dfc3b9b6ecc4ef6"]},"commit2Childs":{"1326054a8d3aa66382d49decc7f330955c9c6f71":["e450c7d50c2fc84c963d0d7ade9d3217d868064d"],"8522ae207a56c6db28ca06fe6cc33e70911c3600":["2123bddbd65dea198cac380540636ce43a880403"],"fe0932c1d340f83fb0a611e5829b3046a1cc1152":["55f083e91bb056b57de136da1dfc3b9b6ecc4ef6"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["8522ae207a56c6db28ca06fe6cc33e70911c3600"],"55f083e91bb056b57de136da1dfc3b9b6ecc4ef6":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"2123bddbd65dea198cac380540636ce43a880403":["1326054a8d3aa66382d49decc7f330955c9c6f71"],"e450c7d50c2fc84c963d0d7ade9d3217d868064d":["fe0932c1d340f83fb0a611e5829b3046a1cc1152"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"9454a6510e2db155fb01faa5c049b06ece95fab9":["cd5edd1f2b162a5cfa08efd17851a07373a96817"]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}