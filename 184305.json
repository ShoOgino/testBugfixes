{"path":"lucene/spatial/src/test/org/apache/lucene/spatial/util/BaseGeoPointTestCase#testMultiValued().mjava","commits":[{"id":"937923083e4d137932336fc80f3d78758ff698a6","date":1454691519,"type":1,"author":"nknize","isMerge":false,"pathNew":"lucene/spatial/src/test/org/apache/lucene/spatial/util/BaseGeoPointTestCase#testMultiValued().mjava","pathOld":"lucene/sandbox/src/test/org/apache/lucene/util/BaseGeoPointTestCase#testMultiValued().mjava","sourceNew":"  public void testMultiValued() throws Exception {\n\n    // For GeoPointQuery, only run this test nightly:\n    assumeTrue(\"GeoPoint*Query is too slow otherwise\", TEST_NIGHTLY || forceSmall() == false);\n\n    int numPoints = atLeast(10000);\n    // Every doc has 2 points:\n    double[] lats = new double[2*numPoints];\n    double[] lons = new double[2*numPoints];\n    Directory dir = newDirectory();\n    noVirusChecker(dir);\n    IndexWriterConfig iwc = newIndexWriterConfig();\n    initIndexWriterConfig(FIELD_NAME, iwc);\n\n    // We rely on docID order:\n    iwc.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n\n    boolean small = random().nextBoolean();\n\n    for (int id=0;id<numPoints;id++) {\n      Document doc = new Document();\n      lats[2*id] = randomLat(small);\n      lons[2*id] = randomLon(small);\n      doc.add(newStringField(\"id\", \"\"+id, Field.Store.YES));\n      addPointToDoc(FIELD_NAME, doc, lats[2*id], lons[2*id]);\n      lats[2*id+1] = randomLat(small);\n      lons[2*id+1] = randomLon(small);\n      addPointToDoc(FIELD_NAME, doc, lats[2*id+1], lons[2*id+1]);\n\n      if (VERBOSE) {\n        System.out.println(\"id=\" + id);\n        System.out.println(\"  lat=\" + lats[2*id] + \" lon=\" + lons[2*id]);\n        System.out.println(\"  lat=\" + lats[2*id+1] + \" lon=\" + lons[2*id+1]);\n      }\n      w.addDocument(doc);\n    }\n\n    // TODO: share w/ verify; just need parallel array of the expected ids\n    if (random().nextBoolean()) {\n      w.forceMerge(1);\n    }\n    IndexReader r = w.getReader();\n    w.close();\n\n    // We can't wrap with \"exotic\" readers because the BKD query must see the BKDDVFormat:\n    IndexSearcher s = newSearcher(r, false);\n\n    int iters = atLeast(75);\n    for (int iter=0;iter<iters;iter++) {\n      GeoRect rect = randomRect(small, small == false);\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: iter=\" + iter + \" rect=\" + rect);\n      }\n\n      Query query = newRectQuery(FIELD_NAME, rect);\n\n      final FixedBitSet hits = new FixedBitSet(r.maxDoc());\n      s.search(query, new SimpleCollector() {\n\n          private int docBase;\n\n          @Override\n          public boolean needsScores() {\n            return false;\n          }\n\n          @Override\n          protected void doSetNextReader(LeafReaderContext context) throws IOException {\n            docBase = context.docBase;\n          }\n\n          @Override\n          public void collect(int doc) {\n            hits.set(docBase+doc);\n          }\n        });\n\n      boolean fail = false;\n\n      for(int docID=0;docID<lats.length/2;docID++) {\n        double latDoc1 = lats[2*docID];\n        double lonDoc1 = lons[2*docID];\n        double latDoc2 = lats[2*docID+1];\n        double lonDoc2 = lons[2*docID+1];\n        \n        Boolean result1 = rectContainsPoint(rect, latDoc1, lonDoc1);\n        if (result1 == null) {\n          // borderline case: cannot test\n          continue;\n        }\n\n        Boolean result2 = rectContainsPoint(rect, latDoc2, lonDoc2);\n        if (result2 == null) {\n          // borderline case: cannot test\n          continue;\n        }\n\n        boolean expected = result1 == Boolean.TRUE || result2 == Boolean.TRUE;\n\n        if (hits.get(docID) != expected) {\n          String id = s.doc(docID).get(\"id\");\n          if (expected) {\n            System.out.println(Thread.currentThread().getName() + \": id=\" + id + \" docID=\" + docID + \" should match but did not\");\n          } else {\n            System.out.println(Thread.currentThread().getName() + \": id=\" + id + \" docID=\" + docID + \" should not match but did\");\n          }\n          System.out.println(\"  rect=\" + rect);\n          System.out.println(\"  lat=\" + latDoc1 + \" lon=\" + lonDoc1 + \"\\n  lat=\" + latDoc2 + \" lon=\" + lonDoc2);\n          System.out.println(\"  result1=\" + result1 + \" result2=\" + result2);\n          fail = true;\n        }\n      }\n\n      if (fail) {\n        fail(\"some hits were wrong\");\n      }\n    }\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testMultiValued() throws Exception {\n\n    // For GeoPointQuery, only run this test nightly:\n    assumeTrue(\"GeoPoint*Query is too slow otherwise\", TEST_NIGHTLY || forceSmall() == false);\n\n    int numPoints = atLeast(10000);\n    // Every doc has 2 points:\n    double[] lats = new double[2*numPoints];\n    double[] lons = new double[2*numPoints];\n    Directory dir = newDirectory();\n    noVirusChecker(dir);\n    IndexWriterConfig iwc = newIndexWriterConfig();\n    initIndexWriterConfig(FIELD_NAME, iwc);\n\n    // We rely on docID order:\n    iwc.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n\n    boolean small = random().nextBoolean();\n\n    for (int id=0;id<numPoints;id++) {\n      Document doc = new Document();\n      lats[2*id] = randomLat(small);\n      lons[2*id] = randomLon(small);\n      doc.add(newStringField(\"id\", \"\"+id, Field.Store.YES));\n      addPointToDoc(FIELD_NAME, doc, lats[2*id], lons[2*id]);\n      lats[2*id+1] = randomLat(small);\n      lons[2*id+1] = randomLon(small);\n      addPointToDoc(FIELD_NAME, doc, lats[2*id+1], lons[2*id+1]);\n\n      if (VERBOSE) {\n        System.out.println(\"id=\" + id);\n        System.out.println(\"  lat=\" + lats[2*id] + \" lon=\" + lons[2*id]);\n        System.out.println(\"  lat=\" + lats[2*id+1] + \" lon=\" + lons[2*id+1]);\n      }\n      w.addDocument(doc);\n    }\n\n    // TODO: share w/ verify; just need parallel array of the expected ids\n    if (random().nextBoolean()) {\n      w.forceMerge(1);\n    }\n    IndexReader r = w.getReader();\n    w.close();\n\n    // We can't wrap with \"exotic\" readers because the BKD query must see the BKDDVFormat:\n    IndexSearcher s = newSearcher(r, false);\n\n    int iters = atLeast(75);\n    for (int iter=0;iter<iters;iter++) {\n      GeoRect rect = randomRect(small, small == false);\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: iter=\" + iter + \" rect=\" + rect);\n      }\n\n      Query query = newRectQuery(FIELD_NAME, rect);\n\n      final FixedBitSet hits = new FixedBitSet(r.maxDoc());\n      s.search(query, new SimpleCollector() {\n\n          private int docBase;\n\n          @Override\n          public boolean needsScores() {\n            return false;\n          }\n\n          @Override\n          protected void doSetNextReader(LeafReaderContext context) throws IOException {\n            docBase = context.docBase;\n          }\n\n          @Override\n          public void collect(int doc) {\n            hits.set(docBase+doc);\n          }\n        });\n\n      boolean fail = false;\n\n      for(int docID=0;docID<lats.length/2;docID++) {\n        double latDoc1 = lats[2*docID];\n        double lonDoc1 = lons[2*docID];\n        double latDoc2 = lats[2*docID+1];\n        double lonDoc2 = lons[2*docID+1];\n        \n        Boolean result1 = rectContainsPoint(rect, latDoc1, lonDoc1);\n        if (result1 == null) {\n          // borderline case: cannot test\n          continue;\n        }\n\n        Boolean result2 = rectContainsPoint(rect, latDoc2, lonDoc2);\n        if (result2 == null) {\n          // borderline case: cannot test\n          continue;\n        }\n\n        boolean expected = result1 == Boolean.TRUE || result2 == Boolean.TRUE;\n\n        if (hits.get(docID) != expected) {\n          String id = s.doc(docID).get(\"id\");\n          if (expected) {\n            System.out.println(Thread.currentThread().getName() + \": id=\" + id + \" docID=\" + docID + \" should match but did not\");\n          } else {\n            System.out.println(Thread.currentThread().getName() + \": id=\" + id + \" docID=\" + docID + \" should not match but did\");\n          }\n          System.out.println(\"  rect=\" + rect);\n          System.out.println(\"  lat=\" + latDoc1 + \" lon=\" + lonDoc1 + \"\\n  lat=\" + latDoc2 + \" lon=\" + lonDoc2);\n          System.out.println(\"  result1=\" + result1 + \" result2=\" + result2);\n          fail = true;\n        }\n      }\n\n      if (fail) {\n        fail(\"some hits were wrong\");\n      }\n    }\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b470f36a9372c97283360b1304eacbde22df6c0d","date":1454765175,"type":3,"author":"Mike McCandless","isMerge":true,"pathNew":"lucene/spatial/src/test/org/apache/lucene/spatial/util/BaseGeoPointTestCase#testMultiValued().mjava","pathOld":"lucene/spatial/src/test/org/apache/lucene/spatial/util/BaseGeoPointTestCase#testMultiValued().mjava","sourceNew":"  public void testMultiValued() throws Exception {\n\n    // For GeoPointQuery, only run this test nightly:\n    assumeTrue(\"GeoPoint*Query is too slow otherwise\", TEST_NIGHTLY || forceSmall() == false);\n\n    int numPoints = atLeast(10000);\n    // Every doc has 2 points:\n    double[] lats = new double[2*numPoints];\n    double[] lons = new double[2*numPoints];\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig();\n    initIndexWriterConfig(FIELD_NAME, iwc);\n\n    // We rely on docID order:\n    iwc.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n\n    boolean small = random().nextBoolean();\n\n    for (int id=0;id<numPoints;id++) {\n      Document doc = new Document();\n      lats[2*id] = randomLat(small);\n      lons[2*id] = randomLon(small);\n      doc.add(newStringField(\"id\", \"\"+id, Field.Store.YES));\n      addPointToDoc(FIELD_NAME, doc, lats[2*id], lons[2*id]);\n      lats[2*id+1] = randomLat(small);\n      lons[2*id+1] = randomLon(small);\n      addPointToDoc(FIELD_NAME, doc, lats[2*id+1], lons[2*id+1]);\n\n      if (VERBOSE) {\n        System.out.println(\"id=\" + id);\n        System.out.println(\"  lat=\" + lats[2*id] + \" lon=\" + lons[2*id]);\n        System.out.println(\"  lat=\" + lats[2*id+1] + \" lon=\" + lons[2*id+1]);\n      }\n      w.addDocument(doc);\n    }\n\n    // TODO: share w/ verify; just need parallel array of the expected ids\n    if (random().nextBoolean()) {\n      w.forceMerge(1);\n    }\n    IndexReader r = w.getReader();\n    w.close();\n\n    // We can't wrap with \"exotic\" readers because the BKD query must see the BKDDVFormat:\n    IndexSearcher s = newSearcher(r, false);\n\n    int iters = atLeast(75);\n    for (int iter=0;iter<iters;iter++) {\n      GeoRect rect = randomRect(small, small == false);\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: iter=\" + iter + \" rect=\" + rect);\n      }\n\n      Query query = newRectQuery(FIELD_NAME, rect);\n\n      final FixedBitSet hits = new FixedBitSet(r.maxDoc());\n      s.search(query, new SimpleCollector() {\n\n          private int docBase;\n\n          @Override\n          public boolean needsScores() {\n            return false;\n          }\n\n          @Override\n          protected void doSetNextReader(LeafReaderContext context) throws IOException {\n            docBase = context.docBase;\n          }\n\n          @Override\n          public void collect(int doc) {\n            hits.set(docBase+doc);\n          }\n        });\n\n      boolean fail = false;\n\n      for(int docID=0;docID<lats.length/2;docID++) {\n        double latDoc1 = lats[2*docID];\n        double lonDoc1 = lons[2*docID];\n        double latDoc2 = lats[2*docID+1];\n        double lonDoc2 = lons[2*docID+1];\n        \n        Boolean result1 = rectContainsPoint(rect, latDoc1, lonDoc1);\n        if (result1 == null) {\n          // borderline case: cannot test\n          continue;\n        }\n\n        Boolean result2 = rectContainsPoint(rect, latDoc2, lonDoc2);\n        if (result2 == null) {\n          // borderline case: cannot test\n          continue;\n        }\n\n        boolean expected = result1 == Boolean.TRUE || result2 == Boolean.TRUE;\n\n        if (hits.get(docID) != expected) {\n          String id = s.doc(docID).get(\"id\");\n          if (expected) {\n            System.out.println(Thread.currentThread().getName() + \": id=\" + id + \" docID=\" + docID + \" should match but did not\");\n          } else {\n            System.out.println(Thread.currentThread().getName() + \": id=\" + id + \" docID=\" + docID + \" should not match but did\");\n          }\n          System.out.println(\"  rect=\" + rect);\n          System.out.println(\"  lat=\" + latDoc1 + \" lon=\" + lonDoc1 + \"\\n  lat=\" + latDoc2 + \" lon=\" + lonDoc2);\n          System.out.println(\"  result1=\" + result1 + \" result2=\" + result2);\n          fail = true;\n        }\n      }\n\n      if (fail) {\n        fail(\"some hits were wrong\");\n      }\n    }\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testMultiValued() throws Exception {\n\n    // For GeoPointQuery, only run this test nightly:\n    assumeTrue(\"GeoPoint*Query is too slow otherwise\", TEST_NIGHTLY || forceSmall() == false);\n\n    int numPoints = atLeast(10000);\n    // Every doc has 2 points:\n    double[] lats = new double[2*numPoints];\n    double[] lons = new double[2*numPoints];\n    Directory dir = newDirectory();\n    noVirusChecker(dir);\n    IndexWriterConfig iwc = newIndexWriterConfig();\n    initIndexWriterConfig(FIELD_NAME, iwc);\n\n    // We rely on docID order:\n    iwc.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n\n    boolean small = random().nextBoolean();\n\n    for (int id=0;id<numPoints;id++) {\n      Document doc = new Document();\n      lats[2*id] = randomLat(small);\n      lons[2*id] = randomLon(small);\n      doc.add(newStringField(\"id\", \"\"+id, Field.Store.YES));\n      addPointToDoc(FIELD_NAME, doc, lats[2*id], lons[2*id]);\n      lats[2*id+1] = randomLat(small);\n      lons[2*id+1] = randomLon(small);\n      addPointToDoc(FIELD_NAME, doc, lats[2*id+1], lons[2*id+1]);\n\n      if (VERBOSE) {\n        System.out.println(\"id=\" + id);\n        System.out.println(\"  lat=\" + lats[2*id] + \" lon=\" + lons[2*id]);\n        System.out.println(\"  lat=\" + lats[2*id+1] + \" lon=\" + lons[2*id+1]);\n      }\n      w.addDocument(doc);\n    }\n\n    // TODO: share w/ verify; just need parallel array of the expected ids\n    if (random().nextBoolean()) {\n      w.forceMerge(1);\n    }\n    IndexReader r = w.getReader();\n    w.close();\n\n    // We can't wrap with \"exotic\" readers because the BKD query must see the BKDDVFormat:\n    IndexSearcher s = newSearcher(r, false);\n\n    int iters = atLeast(75);\n    for (int iter=0;iter<iters;iter++) {\n      GeoRect rect = randomRect(small, small == false);\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: iter=\" + iter + \" rect=\" + rect);\n      }\n\n      Query query = newRectQuery(FIELD_NAME, rect);\n\n      final FixedBitSet hits = new FixedBitSet(r.maxDoc());\n      s.search(query, new SimpleCollector() {\n\n          private int docBase;\n\n          @Override\n          public boolean needsScores() {\n            return false;\n          }\n\n          @Override\n          protected void doSetNextReader(LeafReaderContext context) throws IOException {\n            docBase = context.docBase;\n          }\n\n          @Override\n          public void collect(int doc) {\n            hits.set(docBase+doc);\n          }\n        });\n\n      boolean fail = false;\n\n      for(int docID=0;docID<lats.length/2;docID++) {\n        double latDoc1 = lats[2*docID];\n        double lonDoc1 = lons[2*docID];\n        double latDoc2 = lats[2*docID+1];\n        double lonDoc2 = lons[2*docID+1];\n        \n        Boolean result1 = rectContainsPoint(rect, latDoc1, lonDoc1);\n        if (result1 == null) {\n          // borderline case: cannot test\n          continue;\n        }\n\n        Boolean result2 = rectContainsPoint(rect, latDoc2, lonDoc2);\n        if (result2 == null) {\n          // borderline case: cannot test\n          continue;\n        }\n\n        boolean expected = result1 == Boolean.TRUE || result2 == Boolean.TRUE;\n\n        if (hits.get(docID) != expected) {\n          String id = s.doc(docID).get(\"id\");\n          if (expected) {\n            System.out.println(Thread.currentThread().getName() + \": id=\" + id + \" docID=\" + docID + \" should match but did not\");\n          } else {\n            System.out.println(Thread.currentThread().getName() + \": id=\" + id + \" docID=\" + docID + \" should not match but did\");\n          }\n          System.out.println(\"  rect=\" + rect);\n          System.out.println(\"  lat=\" + latDoc1 + \" lon=\" + lonDoc1 + \"\\n  lat=\" + latDoc2 + \" lon=\" + lonDoc2);\n          System.out.println(\"  result1=\" + result1 + \" result2=\" + result2);\n          fail = true;\n        }\n      }\n\n      if (fail) {\n        fail(\"some hits were wrong\");\n      }\n    }\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"1e6acbaae7af722f17204ceccf0f7db5753eccf3","date":1454775255,"type":1,"author":"Mike McCandless","isMerge":true,"pathNew":"lucene/spatial/src/test/org/apache/lucene/spatial/util/BaseGeoPointTestCase#testMultiValued().mjava","pathOld":"lucene/sandbox/src/test/org/apache/lucene/util/BaseGeoPointTestCase#testMultiValued().mjava","sourceNew":"  public void testMultiValued() throws Exception {\n\n    // For GeoPointQuery, only run this test nightly:\n    assumeTrue(\"GeoPoint*Query is too slow otherwise\", TEST_NIGHTLY || forceSmall() == false);\n\n    int numPoints = atLeast(10000);\n    // Every doc has 2 points:\n    double[] lats = new double[2*numPoints];\n    double[] lons = new double[2*numPoints];\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig();\n    initIndexWriterConfig(FIELD_NAME, iwc);\n\n    // We rely on docID order:\n    iwc.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n\n    boolean small = random().nextBoolean();\n\n    for (int id=0;id<numPoints;id++) {\n      Document doc = new Document();\n      lats[2*id] = randomLat(small);\n      lons[2*id] = randomLon(small);\n      doc.add(newStringField(\"id\", \"\"+id, Field.Store.YES));\n      addPointToDoc(FIELD_NAME, doc, lats[2*id], lons[2*id]);\n      lats[2*id+1] = randomLat(small);\n      lons[2*id+1] = randomLon(small);\n      addPointToDoc(FIELD_NAME, doc, lats[2*id+1], lons[2*id+1]);\n\n      if (VERBOSE) {\n        System.out.println(\"id=\" + id);\n        System.out.println(\"  lat=\" + lats[2*id] + \" lon=\" + lons[2*id]);\n        System.out.println(\"  lat=\" + lats[2*id+1] + \" lon=\" + lons[2*id+1]);\n      }\n      w.addDocument(doc);\n    }\n\n    // TODO: share w/ verify; just need parallel array of the expected ids\n    if (random().nextBoolean()) {\n      w.forceMerge(1);\n    }\n    IndexReader r = w.getReader();\n    w.close();\n\n    // We can't wrap with \"exotic\" readers because the BKD query must see the BKDDVFormat:\n    IndexSearcher s = newSearcher(r, false);\n\n    int iters = atLeast(75);\n    for (int iter=0;iter<iters;iter++) {\n      GeoRect rect = randomRect(small, small == false);\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: iter=\" + iter + \" rect=\" + rect);\n      }\n\n      Query query = newRectQuery(FIELD_NAME, rect);\n\n      final FixedBitSet hits = new FixedBitSet(r.maxDoc());\n      s.search(query, new SimpleCollector() {\n\n          private int docBase;\n\n          @Override\n          public boolean needsScores() {\n            return false;\n          }\n\n          @Override\n          protected void doSetNextReader(LeafReaderContext context) throws IOException {\n            docBase = context.docBase;\n          }\n\n          @Override\n          public void collect(int doc) {\n            hits.set(docBase+doc);\n          }\n        });\n\n      boolean fail = false;\n\n      for(int docID=0;docID<lats.length/2;docID++) {\n        double latDoc1 = lats[2*docID];\n        double lonDoc1 = lons[2*docID];\n        double latDoc2 = lats[2*docID+1];\n        double lonDoc2 = lons[2*docID+1];\n        \n        Boolean result1 = rectContainsPoint(rect, latDoc1, lonDoc1);\n        if (result1 == null) {\n          // borderline case: cannot test\n          continue;\n        }\n\n        Boolean result2 = rectContainsPoint(rect, latDoc2, lonDoc2);\n        if (result2 == null) {\n          // borderline case: cannot test\n          continue;\n        }\n\n        boolean expected = result1 == Boolean.TRUE || result2 == Boolean.TRUE;\n\n        if (hits.get(docID) != expected) {\n          String id = s.doc(docID).get(\"id\");\n          if (expected) {\n            System.out.println(Thread.currentThread().getName() + \": id=\" + id + \" docID=\" + docID + \" should match but did not\");\n          } else {\n            System.out.println(Thread.currentThread().getName() + \": id=\" + id + \" docID=\" + docID + \" should not match but did\");\n          }\n          System.out.println(\"  rect=\" + rect);\n          System.out.println(\"  lat=\" + latDoc1 + \" lon=\" + lonDoc1 + \"\\n  lat=\" + latDoc2 + \" lon=\" + lonDoc2);\n          System.out.println(\"  result1=\" + result1 + \" result2=\" + result2);\n          fail = true;\n        }\n      }\n\n      if (fail) {\n        fail(\"some hits were wrong\");\n      }\n    }\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testMultiValued() throws Exception {\n\n    // For GeoPointQuery, only run this test nightly:\n    assumeTrue(\"GeoPoint*Query is too slow otherwise\", TEST_NIGHTLY || forceSmall() == false);\n\n    int numPoints = atLeast(10000);\n    // Every doc has 2 points:\n    double[] lats = new double[2*numPoints];\n    double[] lons = new double[2*numPoints];\n    Directory dir = newDirectory();\n    noVirusChecker(dir);\n    IndexWriterConfig iwc = newIndexWriterConfig();\n    initIndexWriterConfig(FIELD_NAME, iwc);\n\n    // We rely on docID order:\n    iwc.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n\n    boolean small = random().nextBoolean();\n\n    for (int id=0;id<numPoints;id++) {\n      Document doc = new Document();\n      lats[2*id] = randomLat(small);\n      lons[2*id] = randomLon(small);\n      doc.add(newStringField(\"id\", \"\"+id, Field.Store.YES));\n      addPointToDoc(FIELD_NAME, doc, lats[2*id], lons[2*id]);\n      lats[2*id+1] = randomLat(small);\n      lons[2*id+1] = randomLon(small);\n      addPointToDoc(FIELD_NAME, doc, lats[2*id+1], lons[2*id+1]);\n\n      if (VERBOSE) {\n        System.out.println(\"id=\" + id);\n        System.out.println(\"  lat=\" + lats[2*id] + \" lon=\" + lons[2*id]);\n        System.out.println(\"  lat=\" + lats[2*id+1] + \" lon=\" + lons[2*id+1]);\n      }\n      w.addDocument(doc);\n    }\n\n    // TODO: share w/ verify; just need parallel array of the expected ids\n    if (random().nextBoolean()) {\n      w.forceMerge(1);\n    }\n    IndexReader r = w.getReader();\n    w.close();\n\n    // We can't wrap with \"exotic\" readers because the BKD query must see the BKDDVFormat:\n    IndexSearcher s = newSearcher(r, false);\n\n    int iters = atLeast(75);\n    for (int iter=0;iter<iters;iter++) {\n      GeoRect rect = randomRect(small, small == false);\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: iter=\" + iter + \" rect=\" + rect);\n      }\n\n      Query query = newRectQuery(FIELD_NAME, rect);\n\n      final FixedBitSet hits = new FixedBitSet(r.maxDoc());\n      s.search(query, new SimpleCollector() {\n\n          private int docBase;\n\n          @Override\n          public boolean needsScores() {\n            return false;\n          }\n\n          @Override\n          protected void doSetNextReader(LeafReaderContext context) throws IOException {\n            docBase = context.docBase;\n          }\n\n          @Override\n          public void collect(int doc) {\n            hits.set(docBase+doc);\n          }\n        });\n\n      boolean fail = false;\n\n      for(int docID=0;docID<lats.length/2;docID++) {\n        double latDoc1 = lats[2*docID];\n        double lonDoc1 = lons[2*docID];\n        double latDoc2 = lats[2*docID+1];\n        double lonDoc2 = lons[2*docID+1];\n        \n        Boolean result1 = rectContainsPoint(rect, latDoc1, lonDoc1);\n        if (result1 == null) {\n          // borderline case: cannot test\n          continue;\n        }\n\n        Boolean result2 = rectContainsPoint(rect, latDoc2, lonDoc2);\n        if (result2 == null) {\n          // borderline case: cannot test\n          continue;\n        }\n\n        boolean expected = result1 == Boolean.TRUE || result2 == Boolean.TRUE;\n\n        if (hits.get(docID) != expected) {\n          String id = s.doc(docID).get(\"id\");\n          if (expected) {\n            System.out.println(Thread.currentThread().getName() + \": id=\" + id + \" docID=\" + docID + \" should match but did not\");\n          } else {\n            System.out.println(Thread.currentThread().getName() + \": id=\" + id + \" docID=\" + docID + \" should not match but did\");\n          }\n          System.out.println(\"  rect=\" + rect);\n          System.out.println(\"  lat=\" + latDoc1 + \" lon=\" + lonDoc1 + \"\\n  lat=\" + latDoc2 + \" lon=\" + lonDoc2);\n          System.out.println(\"  result1=\" + result1 + \" result2=\" + result2);\n          fail = true;\n        }\n      }\n\n      if (fail) {\n        fail(\"some hits were wrong\");\n      }\n    }\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5a207d19eac354d649c3f0e2cce070017c78125e","date":1454776470,"type":3,"author":"Erick Erickson","isMerge":true,"pathNew":"lucene/spatial/src/test/org/apache/lucene/spatial/util/BaseGeoPointTestCase#testMultiValued().mjava","pathOld":"lucene/spatial/src/test/org/apache/lucene/spatial/util/BaseGeoPointTestCase#testMultiValued().mjava","sourceNew":"  public void testMultiValued() throws Exception {\n\n    // For GeoPointQuery, only run this test nightly:\n    assumeTrue(\"GeoPoint*Query is too slow otherwise\", TEST_NIGHTLY || forceSmall() == false);\n\n    int numPoints = atLeast(10000);\n    // Every doc has 2 points:\n    double[] lats = new double[2*numPoints];\n    double[] lons = new double[2*numPoints];\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig();\n    initIndexWriterConfig(FIELD_NAME, iwc);\n\n    // We rely on docID order:\n    iwc.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n\n    boolean small = random().nextBoolean();\n\n    for (int id=0;id<numPoints;id++) {\n      Document doc = new Document();\n      lats[2*id] = randomLat(small);\n      lons[2*id] = randomLon(small);\n      doc.add(newStringField(\"id\", \"\"+id, Field.Store.YES));\n      addPointToDoc(FIELD_NAME, doc, lats[2*id], lons[2*id]);\n      lats[2*id+1] = randomLat(small);\n      lons[2*id+1] = randomLon(small);\n      addPointToDoc(FIELD_NAME, doc, lats[2*id+1], lons[2*id+1]);\n\n      if (VERBOSE) {\n        System.out.println(\"id=\" + id);\n        System.out.println(\"  lat=\" + lats[2*id] + \" lon=\" + lons[2*id]);\n        System.out.println(\"  lat=\" + lats[2*id+1] + \" lon=\" + lons[2*id+1]);\n      }\n      w.addDocument(doc);\n    }\n\n    // TODO: share w/ verify; just need parallel array of the expected ids\n    if (random().nextBoolean()) {\n      w.forceMerge(1);\n    }\n    IndexReader r = w.getReader();\n    w.close();\n\n    // We can't wrap with \"exotic\" readers because the BKD query must see the BKDDVFormat:\n    IndexSearcher s = newSearcher(r, false);\n\n    int iters = atLeast(75);\n    for (int iter=0;iter<iters;iter++) {\n      GeoRect rect = randomRect(small, small == false);\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: iter=\" + iter + \" rect=\" + rect);\n      }\n\n      Query query = newRectQuery(FIELD_NAME, rect);\n\n      final FixedBitSet hits = new FixedBitSet(r.maxDoc());\n      s.search(query, new SimpleCollector() {\n\n          private int docBase;\n\n          @Override\n          public boolean needsScores() {\n            return false;\n          }\n\n          @Override\n          protected void doSetNextReader(LeafReaderContext context) throws IOException {\n            docBase = context.docBase;\n          }\n\n          @Override\n          public void collect(int doc) {\n            hits.set(docBase+doc);\n          }\n        });\n\n      boolean fail = false;\n\n      for(int docID=0;docID<lats.length/2;docID++) {\n        double latDoc1 = lats[2*docID];\n        double lonDoc1 = lons[2*docID];\n        double latDoc2 = lats[2*docID+1];\n        double lonDoc2 = lons[2*docID+1];\n        \n        Boolean result1 = rectContainsPoint(rect, latDoc1, lonDoc1);\n        if (result1 == null) {\n          // borderline case: cannot test\n          continue;\n        }\n\n        Boolean result2 = rectContainsPoint(rect, latDoc2, lonDoc2);\n        if (result2 == null) {\n          // borderline case: cannot test\n          continue;\n        }\n\n        boolean expected = result1 == Boolean.TRUE || result2 == Boolean.TRUE;\n\n        if (hits.get(docID) != expected) {\n          String id = s.doc(docID).get(\"id\");\n          if (expected) {\n            System.out.println(Thread.currentThread().getName() + \": id=\" + id + \" docID=\" + docID + \" should match but did not\");\n          } else {\n            System.out.println(Thread.currentThread().getName() + \": id=\" + id + \" docID=\" + docID + \" should not match but did\");\n          }\n          System.out.println(\"  rect=\" + rect);\n          System.out.println(\"  lat=\" + latDoc1 + \" lon=\" + lonDoc1 + \"\\n  lat=\" + latDoc2 + \" lon=\" + lonDoc2);\n          System.out.println(\"  result1=\" + result1 + \" result2=\" + result2);\n          fail = true;\n        }\n      }\n\n      if (fail) {\n        fail(\"some hits were wrong\");\n      }\n    }\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testMultiValued() throws Exception {\n\n    // For GeoPointQuery, only run this test nightly:\n    assumeTrue(\"GeoPoint*Query is too slow otherwise\", TEST_NIGHTLY || forceSmall() == false);\n\n    int numPoints = atLeast(10000);\n    // Every doc has 2 points:\n    double[] lats = new double[2*numPoints];\n    double[] lons = new double[2*numPoints];\n    Directory dir = newDirectory();\n    noVirusChecker(dir);\n    IndexWriterConfig iwc = newIndexWriterConfig();\n    initIndexWriterConfig(FIELD_NAME, iwc);\n\n    // We rely on docID order:\n    iwc.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n\n    boolean small = random().nextBoolean();\n\n    for (int id=0;id<numPoints;id++) {\n      Document doc = new Document();\n      lats[2*id] = randomLat(small);\n      lons[2*id] = randomLon(small);\n      doc.add(newStringField(\"id\", \"\"+id, Field.Store.YES));\n      addPointToDoc(FIELD_NAME, doc, lats[2*id], lons[2*id]);\n      lats[2*id+1] = randomLat(small);\n      lons[2*id+1] = randomLon(small);\n      addPointToDoc(FIELD_NAME, doc, lats[2*id+1], lons[2*id+1]);\n\n      if (VERBOSE) {\n        System.out.println(\"id=\" + id);\n        System.out.println(\"  lat=\" + lats[2*id] + \" lon=\" + lons[2*id]);\n        System.out.println(\"  lat=\" + lats[2*id+1] + \" lon=\" + lons[2*id+1]);\n      }\n      w.addDocument(doc);\n    }\n\n    // TODO: share w/ verify; just need parallel array of the expected ids\n    if (random().nextBoolean()) {\n      w.forceMerge(1);\n    }\n    IndexReader r = w.getReader();\n    w.close();\n\n    // We can't wrap with \"exotic\" readers because the BKD query must see the BKDDVFormat:\n    IndexSearcher s = newSearcher(r, false);\n\n    int iters = atLeast(75);\n    for (int iter=0;iter<iters;iter++) {\n      GeoRect rect = randomRect(small, small == false);\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: iter=\" + iter + \" rect=\" + rect);\n      }\n\n      Query query = newRectQuery(FIELD_NAME, rect);\n\n      final FixedBitSet hits = new FixedBitSet(r.maxDoc());\n      s.search(query, new SimpleCollector() {\n\n          private int docBase;\n\n          @Override\n          public boolean needsScores() {\n            return false;\n          }\n\n          @Override\n          protected void doSetNextReader(LeafReaderContext context) throws IOException {\n            docBase = context.docBase;\n          }\n\n          @Override\n          public void collect(int doc) {\n            hits.set(docBase+doc);\n          }\n        });\n\n      boolean fail = false;\n\n      for(int docID=0;docID<lats.length/2;docID++) {\n        double latDoc1 = lats[2*docID];\n        double lonDoc1 = lons[2*docID];\n        double latDoc2 = lats[2*docID+1];\n        double lonDoc2 = lons[2*docID+1];\n        \n        Boolean result1 = rectContainsPoint(rect, latDoc1, lonDoc1);\n        if (result1 == null) {\n          // borderline case: cannot test\n          continue;\n        }\n\n        Boolean result2 = rectContainsPoint(rect, latDoc2, lonDoc2);\n        if (result2 == null) {\n          // borderline case: cannot test\n          continue;\n        }\n\n        boolean expected = result1 == Boolean.TRUE || result2 == Boolean.TRUE;\n\n        if (hits.get(docID) != expected) {\n          String id = s.doc(docID).get(\"id\");\n          if (expected) {\n            System.out.println(Thread.currentThread().getName() + \": id=\" + id + \" docID=\" + docID + \" should match but did not\");\n          } else {\n            System.out.println(Thread.currentThread().getName() + \": id=\" + id + \" docID=\" + docID + \" should not match but did\");\n          }\n          System.out.println(\"  rect=\" + rect);\n          System.out.println(\"  lat=\" + latDoc1 + \" lon=\" + lonDoc1 + \"\\n  lat=\" + latDoc2 + \" lon=\" + lonDoc2);\n          System.out.println(\"  result1=\" + result1 + \" result2=\" + result2);\n          fail = true;\n        }\n      }\n\n      if (fail) {\n        fail(\"some hits were wrong\");\n      }\n    }\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"cb4875e9db9b77346c36b7fe0d4b8759a1e095d3","date":1458680048,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/spatial/src/test/org/apache/lucene/spatial/util/BaseGeoPointTestCase#testMultiValued().mjava","pathOld":"lucene/spatial/src/test/org/apache/lucene/spatial/util/BaseGeoPointTestCase#testMultiValued().mjava","sourceNew":"  public void testMultiValued() throws Exception {\n    int numPoints = atLeast(10000);\n    // Every doc has 2 points:\n    double[] lats = new double[2*numPoints];\n    double[] lons = new double[2*numPoints];\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig();\n    initIndexWriterConfig(FIELD_NAME, iwc);\n\n    // We rely on docID order:\n    iwc.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n\n    boolean small = random().nextBoolean();\n\n    for (int id=0;id<numPoints;id++) {\n      Document doc = new Document();\n      lats[2*id] = randomLat(small);\n      lons[2*id] = randomLon(small);\n      doc.add(newStringField(\"id\", \"\"+id, Field.Store.YES));\n      addPointToDoc(FIELD_NAME, doc, lats[2*id], lons[2*id]);\n      lats[2*id+1] = randomLat(small);\n      lons[2*id+1] = randomLon(small);\n      addPointToDoc(FIELD_NAME, doc, lats[2*id+1], lons[2*id+1]);\n\n      if (VERBOSE) {\n        System.out.println(\"id=\" + id);\n        System.out.println(\"  lat=\" + lats[2*id] + \" lon=\" + lons[2*id]);\n        System.out.println(\"  lat=\" + lats[2*id+1] + \" lon=\" + lons[2*id+1]);\n      }\n      w.addDocument(doc);\n    }\n\n    // TODO: share w/ verify; just need parallel array of the expected ids\n    if (random().nextBoolean()) {\n      w.forceMerge(1);\n    }\n    IndexReader r = w.getReader();\n    w.close();\n\n    // We can't wrap with \"exotic\" readers because the BKD query must see the BKDDVFormat:\n    IndexSearcher s = newSearcher(r, false);\n\n    int iters = atLeast(75);\n    for (int iter=0;iter<iters;iter++) {\n      GeoRect rect = randomRect(small, small == false);\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: iter=\" + iter + \" rect=\" + rect);\n      }\n\n      Query query = newRectQuery(FIELD_NAME, rect);\n\n      final FixedBitSet hits = new FixedBitSet(r.maxDoc());\n      s.search(query, new SimpleCollector() {\n\n          private int docBase;\n\n          @Override\n          public boolean needsScores() {\n            return false;\n          }\n\n          @Override\n          protected void doSetNextReader(LeafReaderContext context) throws IOException {\n            docBase = context.docBase;\n          }\n\n          @Override\n          public void collect(int doc) {\n            hits.set(docBase+doc);\n          }\n        });\n\n      boolean fail = false;\n\n      for(int docID=0;docID<lats.length/2;docID++) {\n        double latDoc1 = lats[2*docID];\n        double lonDoc1 = lons[2*docID];\n        double latDoc2 = lats[2*docID+1];\n        double lonDoc2 = lons[2*docID+1];\n        \n        boolean result1 = rectContainsPoint(rect, latDoc1, lonDoc1);\n        boolean result2 = rectContainsPoint(rect, latDoc2, lonDoc2);\n\n        boolean expected = result1 || result2;\n\n        if (hits.get(docID) != expected) {\n          String id = s.doc(docID).get(\"id\");\n          if (expected) {\n            System.out.println(Thread.currentThread().getName() + \": id=\" + id + \" docID=\" + docID + \" should match but did not\");\n          } else {\n            System.out.println(Thread.currentThread().getName() + \": id=\" + id + \" docID=\" + docID + \" should not match but did\");\n          }\n          System.out.println(\"  rect=\" + rect);\n          System.out.println(\"  lat=\" + latDoc1 + \" lon=\" + lonDoc1 + \"\\n  lat=\" + latDoc2 + \" lon=\" + lonDoc2);\n          System.out.println(\"  result1=\" + result1 + \" result2=\" + result2);\n          fail = true;\n        }\n      }\n\n      if (fail) {\n        fail(\"some hits were wrong\");\n      }\n    }\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testMultiValued() throws Exception {\n\n    // For GeoPointQuery, only run this test nightly:\n    assumeTrue(\"GeoPoint*Query is too slow otherwise\", TEST_NIGHTLY || forceSmall() == false);\n\n    int numPoints = atLeast(10000);\n    // Every doc has 2 points:\n    double[] lats = new double[2*numPoints];\n    double[] lons = new double[2*numPoints];\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig();\n    initIndexWriterConfig(FIELD_NAME, iwc);\n\n    // We rely on docID order:\n    iwc.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n\n    boolean small = random().nextBoolean();\n\n    for (int id=0;id<numPoints;id++) {\n      Document doc = new Document();\n      lats[2*id] = randomLat(small);\n      lons[2*id] = randomLon(small);\n      doc.add(newStringField(\"id\", \"\"+id, Field.Store.YES));\n      addPointToDoc(FIELD_NAME, doc, lats[2*id], lons[2*id]);\n      lats[2*id+1] = randomLat(small);\n      lons[2*id+1] = randomLon(small);\n      addPointToDoc(FIELD_NAME, doc, lats[2*id+1], lons[2*id+1]);\n\n      if (VERBOSE) {\n        System.out.println(\"id=\" + id);\n        System.out.println(\"  lat=\" + lats[2*id] + \" lon=\" + lons[2*id]);\n        System.out.println(\"  lat=\" + lats[2*id+1] + \" lon=\" + lons[2*id+1]);\n      }\n      w.addDocument(doc);\n    }\n\n    // TODO: share w/ verify; just need parallel array of the expected ids\n    if (random().nextBoolean()) {\n      w.forceMerge(1);\n    }\n    IndexReader r = w.getReader();\n    w.close();\n\n    // We can't wrap with \"exotic\" readers because the BKD query must see the BKDDVFormat:\n    IndexSearcher s = newSearcher(r, false);\n\n    int iters = atLeast(75);\n    for (int iter=0;iter<iters;iter++) {\n      GeoRect rect = randomRect(small, small == false);\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: iter=\" + iter + \" rect=\" + rect);\n      }\n\n      Query query = newRectQuery(FIELD_NAME, rect);\n\n      final FixedBitSet hits = new FixedBitSet(r.maxDoc());\n      s.search(query, new SimpleCollector() {\n\n          private int docBase;\n\n          @Override\n          public boolean needsScores() {\n            return false;\n          }\n\n          @Override\n          protected void doSetNextReader(LeafReaderContext context) throws IOException {\n            docBase = context.docBase;\n          }\n\n          @Override\n          public void collect(int doc) {\n            hits.set(docBase+doc);\n          }\n        });\n\n      boolean fail = false;\n\n      for(int docID=0;docID<lats.length/2;docID++) {\n        double latDoc1 = lats[2*docID];\n        double lonDoc1 = lons[2*docID];\n        double latDoc2 = lats[2*docID+1];\n        double lonDoc2 = lons[2*docID+1];\n        \n        Boolean result1 = rectContainsPoint(rect, latDoc1, lonDoc1);\n        if (result1 == null) {\n          // borderline case: cannot test\n          continue;\n        }\n\n        Boolean result2 = rectContainsPoint(rect, latDoc2, lonDoc2);\n        if (result2 == null) {\n          // borderline case: cannot test\n          continue;\n        }\n\n        boolean expected = result1 == Boolean.TRUE || result2 == Boolean.TRUE;\n\n        if (hits.get(docID) != expected) {\n          String id = s.doc(docID).get(\"id\");\n          if (expected) {\n            System.out.println(Thread.currentThread().getName() + \": id=\" + id + \" docID=\" + docID + \" should match but did not\");\n          } else {\n            System.out.println(Thread.currentThread().getName() + \": id=\" + id + \" docID=\" + docID + \" should not match but did\");\n          }\n          System.out.println(\"  rect=\" + rect);\n          System.out.println(\"  lat=\" + latDoc1 + \" lon=\" + lonDoc1 + \"\\n  lat=\" + latDoc2 + \" lon=\" + lonDoc2);\n          System.out.println(\"  result1=\" + result1 + \" result2=\" + result2);\n          fail = true;\n        }\n      }\n\n      if (fail) {\n        fail(\"some hits were wrong\");\n      }\n    }\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d6c59bc551f4e523ce6a321280cc6733424fb824","date":1458837690,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/spatial/src/test/org/apache/lucene/spatial/util/BaseGeoPointTestCase#testMultiValued().mjava","pathOld":"lucene/spatial/src/test/org/apache/lucene/spatial/util/BaseGeoPointTestCase#testMultiValued().mjava","sourceNew":"  public void testMultiValued() throws Exception {\n    int numPoints = atLeast(10000);\n    // Every doc has 2 points:\n    double[] lats = new double[2*numPoints];\n    double[] lons = new double[2*numPoints];\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig();\n    initIndexWriterConfig(FIELD_NAME, iwc);\n\n    // We rely on docID order:\n    iwc.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n\n    boolean small = random().nextBoolean();\n\n    for (int id=0;id<numPoints;id++) {\n      Document doc = new Document();\n      lats[2*id] = randomLat(small);\n      lons[2*id] = randomLon(small);\n      doc.add(newStringField(\"id\", \"\"+id, Field.Store.YES));\n      addPointToDoc(FIELD_NAME, doc, lats[2*id], lons[2*id]);\n      lats[2*id+1] = randomLat(small);\n      lons[2*id+1] = randomLon(small);\n      addPointToDoc(FIELD_NAME, doc, lats[2*id+1], lons[2*id+1]);\n\n      if (VERBOSE) {\n        System.out.println(\"id=\" + id);\n        System.out.println(\"  lat=\" + lats[2*id] + \" lon=\" + lons[2*id]);\n        System.out.println(\"  lat=\" + lats[2*id+1] + \" lon=\" + lons[2*id+1]);\n      }\n      w.addDocument(doc);\n    }\n\n    // TODO: share w/ verify; just need parallel array of the expected ids\n    if (random().nextBoolean()) {\n      w.forceMerge(1);\n    }\n    IndexReader r = w.getReader();\n    w.close();\n\n    // We can't wrap with \"exotic\" readers because the BKD query must see the BKDDVFormat:\n    IndexSearcher s = newSearcher(r, false);\n\n    int iters = atLeast(75);\n    for (int iter=0;iter<iters;iter++) {\n      GeoRect rect = randomRect(small, small == false);\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: iter=\" + iter + \" rect=\" + rect);\n      }\n\n      Query query = newRectQuery(FIELD_NAME, rect.minLat, rect.maxLat, rect.minLon, rect.maxLon);\n\n      final FixedBitSet hits = new FixedBitSet(r.maxDoc());\n      s.search(query, new SimpleCollector() {\n\n          private int docBase;\n\n          @Override\n          public boolean needsScores() {\n            return false;\n          }\n\n          @Override\n          protected void doSetNextReader(LeafReaderContext context) throws IOException {\n            docBase = context.docBase;\n          }\n\n          @Override\n          public void collect(int doc) {\n            hits.set(docBase+doc);\n          }\n        });\n\n      boolean fail = false;\n\n      for(int docID=0;docID<lats.length/2;docID++) {\n        double latDoc1 = lats[2*docID];\n        double lonDoc1 = lons[2*docID];\n        double latDoc2 = lats[2*docID+1];\n        double lonDoc2 = lons[2*docID+1];\n        \n        boolean result1 = rectContainsPoint(rect, latDoc1, lonDoc1);\n        boolean result2 = rectContainsPoint(rect, latDoc2, lonDoc2);\n\n        boolean expected = result1 || result2;\n\n        if (hits.get(docID) != expected) {\n          String id = s.doc(docID).get(\"id\");\n          if (expected) {\n            System.out.println(Thread.currentThread().getName() + \": id=\" + id + \" docID=\" + docID + \" should match but did not\");\n          } else {\n            System.out.println(Thread.currentThread().getName() + \": id=\" + id + \" docID=\" + docID + \" should not match but did\");\n          }\n          System.out.println(\"  rect=\" + rect);\n          System.out.println(\"  lat=\" + latDoc1 + \" lon=\" + lonDoc1 + \"\\n  lat=\" + latDoc2 + \" lon=\" + lonDoc2);\n          System.out.println(\"  result1=\" + result1 + \" result2=\" + result2);\n          fail = true;\n        }\n      }\n\n      if (fail) {\n        fail(\"some hits were wrong\");\n      }\n    }\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testMultiValued() throws Exception {\n    int numPoints = atLeast(10000);\n    // Every doc has 2 points:\n    double[] lats = new double[2*numPoints];\n    double[] lons = new double[2*numPoints];\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig();\n    initIndexWriterConfig(FIELD_NAME, iwc);\n\n    // We rely on docID order:\n    iwc.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n\n    boolean small = random().nextBoolean();\n\n    for (int id=0;id<numPoints;id++) {\n      Document doc = new Document();\n      lats[2*id] = randomLat(small);\n      lons[2*id] = randomLon(small);\n      doc.add(newStringField(\"id\", \"\"+id, Field.Store.YES));\n      addPointToDoc(FIELD_NAME, doc, lats[2*id], lons[2*id]);\n      lats[2*id+1] = randomLat(small);\n      lons[2*id+1] = randomLon(small);\n      addPointToDoc(FIELD_NAME, doc, lats[2*id+1], lons[2*id+1]);\n\n      if (VERBOSE) {\n        System.out.println(\"id=\" + id);\n        System.out.println(\"  lat=\" + lats[2*id] + \" lon=\" + lons[2*id]);\n        System.out.println(\"  lat=\" + lats[2*id+1] + \" lon=\" + lons[2*id+1]);\n      }\n      w.addDocument(doc);\n    }\n\n    // TODO: share w/ verify; just need parallel array of the expected ids\n    if (random().nextBoolean()) {\n      w.forceMerge(1);\n    }\n    IndexReader r = w.getReader();\n    w.close();\n\n    // We can't wrap with \"exotic\" readers because the BKD query must see the BKDDVFormat:\n    IndexSearcher s = newSearcher(r, false);\n\n    int iters = atLeast(75);\n    for (int iter=0;iter<iters;iter++) {\n      GeoRect rect = randomRect(small, small == false);\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: iter=\" + iter + \" rect=\" + rect);\n      }\n\n      Query query = newRectQuery(FIELD_NAME, rect);\n\n      final FixedBitSet hits = new FixedBitSet(r.maxDoc());\n      s.search(query, new SimpleCollector() {\n\n          private int docBase;\n\n          @Override\n          public boolean needsScores() {\n            return false;\n          }\n\n          @Override\n          protected void doSetNextReader(LeafReaderContext context) throws IOException {\n            docBase = context.docBase;\n          }\n\n          @Override\n          public void collect(int doc) {\n            hits.set(docBase+doc);\n          }\n        });\n\n      boolean fail = false;\n\n      for(int docID=0;docID<lats.length/2;docID++) {\n        double latDoc1 = lats[2*docID];\n        double lonDoc1 = lons[2*docID];\n        double latDoc2 = lats[2*docID+1];\n        double lonDoc2 = lons[2*docID+1];\n        \n        boolean result1 = rectContainsPoint(rect, latDoc1, lonDoc1);\n        boolean result2 = rectContainsPoint(rect, latDoc2, lonDoc2);\n\n        boolean expected = result1 || result2;\n\n        if (hits.get(docID) != expected) {\n          String id = s.doc(docID).get(\"id\");\n          if (expected) {\n            System.out.println(Thread.currentThread().getName() + \": id=\" + id + \" docID=\" + docID + \" should match but did not\");\n          } else {\n            System.out.println(Thread.currentThread().getName() + \": id=\" + id + \" docID=\" + docID + \" should not match but did\");\n          }\n          System.out.println(\"  rect=\" + rect);\n          System.out.println(\"  lat=\" + latDoc1 + \" lon=\" + lonDoc1 + \"\\n  lat=\" + latDoc2 + \" lon=\" + lonDoc2);\n          System.out.println(\"  result1=\" + result1 + \" result2=\" + result2);\n          fail = true;\n        }\n      }\n\n      if (fail) {\n        fail(\"some hits were wrong\");\n      }\n    }\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"84d7daf8313ff5c20a3ab51ffd646f5e862e1bac","date":1459177733,"type":3,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/spatial/src/test/org/apache/lucene/spatial/util/BaseGeoPointTestCase#testMultiValued().mjava","pathOld":"lucene/spatial/src/test/org/apache/lucene/spatial/util/BaseGeoPointTestCase#testMultiValued().mjava","sourceNew":"  public void testMultiValued() throws Exception {\n    int numPoints = atLeast(10000);\n    // Every doc has 2 points:\n    double[] lats = new double[2*numPoints];\n    double[] lons = new double[2*numPoints];\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig();\n    initIndexWriterConfig(FIELD_NAME, iwc);\n\n    // We rely on docID order:\n    iwc.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n\n    boolean small = random().nextBoolean();\n\n    for (int id=0;id<numPoints;id++) {\n      Document doc = new Document();\n      lats[2*id] = randomLat(small);\n      lons[2*id] = randomLon(small);\n      doc.add(newStringField(\"id\", \"\"+id, Field.Store.YES));\n      addPointToDoc(FIELD_NAME, doc, lats[2*id], lons[2*id]);\n      lats[2*id+1] = randomLat(small);\n      lons[2*id+1] = randomLon(small);\n      addPointToDoc(FIELD_NAME, doc, lats[2*id+1], lons[2*id+1]);\n\n      if (VERBOSE) {\n        System.out.println(\"id=\" + id);\n        System.out.println(\"  lat=\" + lats[2*id] + \" lon=\" + lons[2*id]);\n        System.out.println(\"  lat=\" + lats[2*id+1] + \" lon=\" + lons[2*id+1]);\n      }\n      w.addDocument(doc);\n    }\n\n    // TODO: share w/ verify; just need parallel array of the expected ids\n    if (random().nextBoolean()) {\n      w.forceMerge(1);\n    }\n    IndexReader r = w.getReader();\n    w.close();\n\n    IndexSearcher s = newSearcher(r);\n\n    int iters = atLeast(25);\n    for (int iter=0;iter<iters;iter++) {\n      GeoRect rect = randomRect(small, small == false);\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: iter=\" + iter + \" rect=\" + rect);\n      }\n\n      Query query = newRectQuery(FIELD_NAME, rect.minLat, rect.maxLat, rect.minLon, rect.maxLon);\n\n      final FixedBitSet hits = new FixedBitSet(r.maxDoc());\n      s.search(query, new SimpleCollector() {\n\n          private int docBase;\n\n          @Override\n          public boolean needsScores() {\n            return false;\n          }\n\n          @Override\n          protected void doSetNextReader(LeafReaderContext context) throws IOException {\n            docBase = context.docBase;\n          }\n\n          @Override\n          public void collect(int doc) {\n            hits.set(docBase+doc);\n          }\n        });\n\n      boolean fail = false;\n\n      for(int docID=0;docID<lats.length/2;docID++) {\n        double latDoc1 = lats[2*docID];\n        double lonDoc1 = lons[2*docID];\n        double latDoc2 = lats[2*docID+1];\n        double lonDoc2 = lons[2*docID+1];\n        \n        boolean result1 = rectContainsPoint(rect, latDoc1, lonDoc1);\n        boolean result2 = rectContainsPoint(rect, latDoc2, lonDoc2);\n\n        boolean expected = result1 || result2;\n\n        if (hits.get(docID) != expected) {\n          String id = s.doc(docID).get(\"id\");\n          if (expected) {\n            System.out.println(\"TEST: id=\" + id + \" docID=\" + docID + \" should match but did not\");\n          } else {\n            System.out.println(\"TEST: id=\" + id + \" docID=\" + docID + \" should not match but did\");\n          }\n          System.out.println(\"  rect=\" + rect);\n          System.out.println(\"  lat=\" + latDoc1 + \" lon=\" + lonDoc1 + \"\\n  lat=\" + latDoc2 + \" lon=\" + lonDoc2);\n          System.out.println(\"  result1=\" + result1 + \" result2=\" + result2);\n          fail = true;\n        }\n      }\n\n      if (fail) {\n        fail(\"some hits were wrong\");\n      }\n    }\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testMultiValued() throws Exception {\n    int numPoints = atLeast(10000);\n    // Every doc has 2 points:\n    double[] lats = new double[2*numPoints];\n    double[] lons = new double[2*numPoints];\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig();\n    initIndexWriterConfig(FIELD_NAME, iwc);\n\n    // We rely on docID order:\n    iwc.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n\n    boolean small = random().nextBoolean();\n\n    for (int id=0;id<numPoints;id++) {\n      Document doc = new Document();\n      lats[2*id] = randomLat(small);\n      lons[2*id] = randomLon(small);\n      doc.add(newStringField(\"id\", \"\"+id, Field.Store.YES));\n      addPointToDoc(FIELD_NAME, doc, lats[2*id], lons[2*id]);\n      lats[2*id+1] = randomLat(small);\n      lons[2*id+1] = randomLon(small);\n      addPointToDoc(FIELD_NAME, doc, lats[2*id+1], lons[2*id+1]);\n\n      if (VERBOSE) {\n        System.out.println(\"id=\" + id);\n        System.out.println(\"  lat=\" + lats[2*id] + \" lon=\" + lons[2*id]);\n        System.out.println(\"  lat=\" + lats[2*id+1] + \" lon=\" + lons[2*id+1]);\n      }\n      w.addDocument(doc);\n    }\n\n    // TODO: share w/ verify; just need parallel array of the expected ids\n    if (random().nextBoolean()) {\n      w.forceMerge(1);\n    }\n    IndexReader r = w.getReader();\n    w.close();\n\n    // We can't wrap with \"exotic\" readers because the BKD query must see the BKDDVFormat:\n    IndexSearcher s = newSearcher(r, false);\n\n    int iters = atLeast(75);\n    for (int iter=0;iter<iters;iter++) {\n      GeoRect rect = randomRect(small, small == false);\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: iter=\" + iter + \" rect=\" + rect);\n      }\n\n      Query query = newRectQuery(FIELD_NAME, rect.minLat, rect.maxLat, rect.minLon, rect.maxLon);\n\n      final FixedBitSet hits = new FixedBitSet(r.maxDoc());\n      s.search(query, new SimpleCollector() {\n\n          private int docBase;\n\n          @Override\n          public boolean needsScores() {\n            return false;\n          }\n\n          @Override\n          protected void doSetNextReader(LeafReaderContext context) throws IOException {\n            docBase = context.docBase;\n          }\n\n          @Override\n          public void collect(int doc) {\n            hits.set(docBase+doc);\n          }\n        });\n\n      boolean fail = false;\n\n      for(int docID=0;docID<lats.length/2;docID++) {\n        double latDoc1 = lats[2*docID];\n        double lonDoc1 = lons[2*docID];\n        double latDoc2 = lats[2*docID+1];\n        double lonDoc2 = lons[2*docID+1];\n        \n        boolean result1 = rectContainsPoint(rect, latDoc1, lonDoc1);\n        boolean result2 = rectContainsPoint(rect, latDoc2, lonDoc2);\n\n        boolean expected = result1 || result2;\n\n        if (hits.get(docID) != expected) {\n          String id = s.doc(docID).get(\"id\");\n          if (expected) {\n            System.out.println(Thread.currentThread().getName() + \": id=\" + id + \" docID=\" + docID + \" should match but did not\");\n          } else {\n            System.out.println(Thread.currentThread().getName() + \": id=\" + id + \" docID=\" + docID + \" should not match but did\");\n          }\n          System.out.println(\"  rect=\" + rect);\n          System.out.println(\"  lat=\" + latDoc1 + \" lon=\" + lonDoc1 + \"\\n  lat=\" + latDoc2 + \" lon=\" + lonDoc2);\n          System.out.println(\"  result1=\" + result1 + \" result2=\" + result2);\n          fail = true;\n        }\n      }\n\n      if (fail) {\n        fail(\"some hits were wrong\");\n      }\n    }\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"1419d3974886c9518c259c786492b4d3660b0b8e","date":1459180094,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/spatial/src/test/org/apache/lucene/spatial/util/BaseGeoPointTestCase#testMultiValued().mjava","pathOld":"lucene/spatial/src/test/org/apache/lucene/spatial/util/BaseGeoPointTestCase#testMultiValued().mjava","sourceNew":"  public void testMultiValued() throws Exception {\n    int numPoints = atLeast(10000);\n    // Every doc has 2 points:\n    double[] lats = new double[2*numPoints];\n    double[] lons = new double[2*numPoints];\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig();\n    initIndexWriterConfig(FIELD_NAME, iwc);\n\n    // We rely on docID order:\n    iwc.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n\n    boolean small = random().nextBoolean();\n\n    for (int id=0;id<numPoints;id++) {\n      Document doc = new Document();\n      lats[2*id] = randomLat(small);\n      lons[2*id] = randomLon(small);\n      doc.add(newStringField(\"id\", \"\"+id, Field.Store.YES));\n      addPointToDoc(FIELD_NAME, doc, lats[2*id], lons[2*id]);\n      lats[2*id+1] = randomLat(small);\n      lons[2*id+1] = randomLon(small);\n      addPointToDoc(FIELD_NAME, doc, lats[2*id+1], lons[2*id+1]);\n\n      if (VERBOSE) {\n        System.out.println(\"id=\" + id);\n        System.out.println(\"  lat=\" + lats[2*id] + \" lon=\" + lons[2*id]);\n        System.out.println(\"  lat=\" + lats[2*id+1] + \" lon=\" + lons[2*id+1]);\n      }\n      w.addDocument(doc);\n    }\n\n    // TODO: share w/ verify; just need parallel array of the expected ids\n    if (random().nextBoolean()) {\n      w.forceMerge(1);\n    }\n    IndexReader r = w.getReader();\n    w.close();\n\n    IndexSearcher s = newSearcher(r);\n\n    int iters = atLeast(25);\n    for (int iter=0;iter<iters;iter++) {\n      GeoRect rect = randomRect(small);\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: iter=\" + iter + \" rect=\" + rect);\n      }\n\n      Query query = newRectQuery(FIELD_NAME, rect.minLat, rect.maxLat, rect.minLon, rect.maxLon);\n\n      final FixedBitSet hits = new FixedBitSet(r.maxDoc());\n      s.search(query, new SimpleCollector() {\n\n          private int docBase;\n\n          @Override\n          public boolean needsScores() {\n            return false;\n          }\n\n          @Override\n          protected void doSetNextReader(LeafReaderContext context) throws IOException {\n            docBase = context.docBase;\n          }\n\n          @Override\n          public void collect(int doc) {\n            hits.set(docBase+doc);\n          }\n        });\n\n      boolean fail = false;\n\n      for(int docID=0;docID<lats.length/2;docID++) {\n        double latDoc1 = lats[2*docID];\n        double lonDoc1 = lons[2*docID];\n        double latDoc2 = lats[2*docID+1];\n        double lonDoc2 = lons[2*docID+1];\n        \n        boolean result1 = rectContainsPoint(rect, latDoc1, lonDoc1);\n        boolean result2 = rectContainsPoint(rect, latDoc2, lonDoc2);\n\n        boolean expected = result1 || result2;\n\n        if (hits.get(docID) != expected) {\n          String id = s.doc(docID).get(\"id\");\n          if (expected) {\n            System.out.println(\"TEST: id=\" + id + \" docID=\" + docID + \" should match but did not\");\n          } else {\n            System.out.println(\"TEST: id=\" + id + \" docID=\" + docID + \" should not match but did\");\n          }\n          System.out.println(\"  rect=\" + rect);\n          System.out.println(\"  lat=\" + latDoc1 + \" lon=\" + lonDoc1 + \"\\n  lat=\" + latDoc2 + \" lon=\" + lonDoc2);\n          System.out.println(\"  result1=\" + result1 + \" result2=\" + result2);\n          fail = true;\n        }\n      }\n\n      if (fail) {\n        fail(\"some hits were wrong\");\n      }\n    }\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testMultiValued() throws Exception {\n    int numPoints = atLeast(10000);\n    // Every doc has 2 points:\n    double[] lats = new double[2*numPoints];\n    double[] lons = new double[2*numPoints];\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig();\n    initIndexWriterConfig(FIELD_NAME, iwc);\n\n    // We rely on docID order:\n    iwc.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n\n    boolean small = random().nextBoolean();\n\n    for (int id=0;id<numPoints;id++) {\n      Document doc = new Document();\n      lats[2*id] = randomLat(small);\n      lons[2*id] = randomLon(small);\n      doc.add(newStringField(\"id\", \"\"+id, Field.Store.YES));\n      addPointToDoc(FIELD_NAME, doc, lats[2*id], lons[2*id]);\n      lats[2*id+1] = randomLat(small);\n      lons[2*id+1] = randomLon(small);\n      addPointToDoc(FIELD_NAME, doc, lats[2*id+1], lons[2*id+1]);\n\n      if (VERBOSE) {\n        System.out.println(\"id=\" + id);\n        System.out.println(\"  lat=\" + lats[2*id] + \" lon=\" + lons[2*id]);\n        System.out.println(\"  lat=\" + lats[2*id+1] + \" lon=\" + lons[2*id+1]);\n      }\n      w.addDocument(doc);\n    }\n\n    // TODO: share w/ verify; just need parallel array of the expected ids\n    if (random().nextBoolean()) {\n      w.forceMerge(1);\n    }\n    IndexReader r = w.getReader();\n    w.close();\n\n    IndexSearcher s = newSearcher(r);\n\n    int iters = atLeast(25);\n    for (int iter=0;iter<iters;iter++) {\n      GeoRect rect = randomRect(small, small == false);\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: iter=\" + iter + \" rect=\" + rect);\n      }\n\n      Query query = newRectQuery(FIELD_NAME, rect.minLat, rect.maxLat, rect.minLon, rect.maxLon);\n\n      final FixedBitSet hits = new FixedBitSet(r.maxDoc());\n      s.search(query, new SimpleCollector() {\n\n          private int docBase;\n\n          @Override\n          public boolean needsScores() {\n            return false;\n          }\n\n          @Override\n          protected void doSetNextReader(LeafReaderContext context) throws IOException {\n            docBase = context.docBase;\n          }\n\n          @Override\n          public void collect(int doc) {\n            hits.set(docBase+doc);\n          }\n        });\n\n      boolean fail = false;\n\n      for(int docID=0;docID<lats.length/2;docID++) {\n        double latDoc1 = lats[2*docID];\n        double lonDoc1 = lons[2*docID];\n        double latDoc2 = lats[2*docID+1];\n        double lonDoc2 = lons[2*docID+1];\n        \n        boolean result1 = rectContainsPoint(rect, latDoc1, lonDoc1);\n        boolean result2 = rectContainsPoint(rect, latDoc2, lonDoc2);\n\n        boolean expected = result1 || result2;\n\n        if (hits.get(docID) != expected) {\n          String id = s.doc(docID).get(\"id\");\n          if (expected) {\n            System.out.println(\"TEST: id=\" + id + \" docID=\" + docID + \" should match but did not\");\n          } else {\n            System.out.println(\"TEST: id=\" + id + \" docID=\" + docID + \" should not match but did\");\n          }\n          System.out.println(\"  rect=\" + rect);\n          System.out.println(\"  lat=\" + latDoc1 + \" lon=\" + lonDoc1 + \"\\n  lat=\" + latDoc2 + \" lon=\" + lonDoc2);\n          System.out.println(\"  result1=\" + result1 + \" result2=\" + result2);\n          fail = true;\n        }\n      }\n\n      if (fail) {\n        fail(\"some hits were wrong\");\n      }\n    }\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"253f983bd74e240286a3e1a1e40294d589c5bef4","date":1459190341,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/spatial/src/test/org/apache/lucene/spatial/util/BaseGeoPointTestCase#testMultiValued().mjava","pathOld":"lucene/spatial/src/test/org/apache/lucene/spatial/util/BaseGeoPointTestCase#testMultiValued().mjava","sourceNew":"  public void testMultiValued() throws Exception {\n    int numPoints = atLeast(10000);\n    // Every doc has 2 points:\n    double[] lats = new double[2*numPoints];\n    double[] lons = new double[2*numPoints];\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig();\n    initIndexWriterConfig(FIELD_NAME, iwc);\n\n    // We rely on docID order:\n    iwc.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n\n    boolean small = random().nextBoolean();\n\n    for (int id=0;id<numPoints;id++) {\n      Document doc = new Document();\n      lats[2*id] = quantizeLat(randomLat(small));\n      lons[2*id] = quantizeLon(randomLon(small));\n      doc.add(newStringField(\"id\", \"\"+id, Field.Store.YES));\n      addPointToDoc(FIELD_NAME, doc, lats[2*id], lons[2*id]);\n      lats[2*id+1] = quantizeLat(randomLat(small));\n      lons[2*id+1] = quantizeLon(randomLon(small));\n      addPointToDoc(FIELD_NAME, doc, lats[2*id+1], lons[2*id+1]);\n\n      if (VERBOSE) {\n        System.out.println(\"id=\" + id);\n        System.out.println(\"  lat=\" + lats[2*id] + \" lon=\" + lons[2*id]);\n        System.out.println(\"  lat=\" + lats[2*id+1] + \" lon=\" + lons[2*id+1]);\n      }\n      w.addDocument(doc);\n    }\n\n    // TODO: share w/ verify; just need parallel array of the expected ids\n    if (random().nextBoolean()) {\n      w.forceMerge(1);\n    }\n    IndexReader r = w.getReader();\n    w.close();\n\n    IndexSearcher s = newSearcher(r);\n\n    int iters = atLeast(25);\n    for (int iter=0;iter<iters;iter++) {\n      GeoRect rect = randomRect(small);\n      // TODO: why does this test need this quantization leniency? something is not right\n      rect = new GeoRect(quantizeLat(rect.minLat), quantizeLat(rect.maxLat), quantizeLon(rect.minLon), quantizeLon(rect.maxLon));\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: iter=\" + iter + \" rect=\" + rect);\n      }\n\n      Query query = newRectQuery(FIELD_NAME, rect.minLat, rect.maxLat, rect.minLon, rect.maxLon);\n\n      final FixedBitSet hits = new FixedBitSet(r.maxDoc());\n      s.search(query, new SimpleCollector() {\n\n          private int docBase;\n\n          @Override\n          public boolean needsScores() {\n            return false;\n          }\n\n          @Override\n          protected void doSetNextReader(LeafReaderContext context) throws IOException {\n            docBase = context.docBase;\n          }\n\n          @Override\n          public void collect(int doc) {\n            hits.set(docBase+doc);\n          }\n        });\n\n      boolean fail = false;\n\n      for(int docID=0;docID<lats.length/2;docID++) {\n        double latDoc1 = lats[2*docID];\n        double lonDoc1 = lons[2*docID];\n        double latDoc2 = lats[2*docID+1];\n        double lonDoc2 = lons[2*docID+1];\n        \n        boolean result1 = rectContainsPoint(rect, latDoc1, lonDoc1);\n        boolean result2 = rectContainsPoint(rect, latDoc2, lonDoc2);\n\n        boolean expected = result1 || result2;\n\n        if (hits.get(docID) != expected) {\n          String id = s.doc(docID).get(\"id\");\n          if (expected) {\n            System.out.println(\"TEST: id=\" + id + \" docID=\" + docID + \" should match but did not\");\n          } else {\n            System.out.println(\"TEST: id=\" + id + \" docID=\" + docID + \" should not match but did\");\n          }\n          System.out.println(\"  rect=\" + rect);\n          System.out.println(\"  lat=\" + latDoc1 + \" lon=\" + lonDoc1 + \"\\n  lat=\" + latDoc2 + \" lon=\" + lonDoc2);\n          System.out.println(\"  result1=\" + result1 + \" result2=\" + result2);\n          fail = true;\n        }\n      }\n\n      if (fail) {\n        fail(\"some hits were wrong\");\n      }\n    }\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testMultiValued() throws Exception {\n    int numPoints = atLeast(10000);\n    // Every doc has 2 points:\n    double[] lats = new double[2*numPoints];\n    double[] lons = new double[2*numPoints];\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig();\n    initIndexWriterConfig(FIELD_NAME, iwc);\n\n    // We rely on docID order:\n    iwc.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n\n    boolean small = random().nextBoolean();\n\n    for (int id=0;id<numPoints;id++) {\n      Document doc = new Document();\n      lats[2*id] = randomLat(small);\n      lons[2*id] = randomLon(small);\n      doc.add(newStringField(\"id\", \"\"+id, Field.Store.YES));\n      addPointToDoc(FIELD_NAME, doc, lats[2*id], lons[2*id]);\n      lats[2*id+1] = randomLat(small);\n      lons[2*id+1] = randomLon(small);\n      addPointToDoc(FIELD_NAME, doc, lats[2*id+1], lons[2*id+1]);\n\n      if (VERBOSE) {\n        System.out.println(\"id=\" + id);\n        System.out.println(\"  lat=\" + lats[2*id] + \" lon=\" + lons[2*id]);\n        System.out.println(\"  lat=\" + lats[2*id+1] + \" lon=\" + lons[2*id+1]);\n      }\n      w.addDocument(doc);\n    }\n\n    // TODO: share w/ verify; just need parallel array of the expected ids\n    if (random().nextBoolean()) {\n      w.forceMerge(1);\n    }\n    IndexReader r = w.getReader();\n    w.close();\n\n    IndexSearcher s = newSearcher(r);\n\n    int iters = atLeast(25);\n    for (int iter=0;iter<iters;iter++) {\n      GeoRect rect = randomRect(small);\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: iter=\" + iter + \" rect=\" + rect);\n      }\n\n      Query query = newRectQuery(FIELD_NAME, rect.minLat, rect.maxLat, rect.minLon, rect.maxLon);\n\n      final FixedBitSet hits = new FixedBitSet(r.maxDoc());\n      s.search(query, new SimpleCollector() {\n\n          private int docBase;\n\n          @Override\n          public boolean needsScores() {\n            return false;\n          }\n\n          @Override\n          protected void doSetNextReader(LeafReaderContext context) throws IOException {\n            docBase = context.docBase;\n          }\n\n          @Override\n          public void collect(int doc) {\n            hits.set(docBase+doc);\n          }\n        });\n\n      boolean fail = false;\n\n      for(int docID=0;docID<lats.length/2;docID++) {\n        double latDoc1 = lats[2*docID];\n        double lonDoc1 = lons[2*docID];\n        double latDoc2 = lats[2*docID+1];\n        double lonDoc2 = lons[2*docID+1];\n        \n        boolean result1 = rectContainsPoint(rect, latDoc1, lonDoc1);\n        boolean result2 = rectContainsPoint(rect, latDoc2, lonDoc2);\n\n        boolean expected = result1 || result2;\n\n        if (hits.get(docID) != expected) {\n          String id = s.doc(docID).get(\"id\");\n          if (expected) {\n            System.out.println(\"TEST: id=\" + id + \" docID=\" + docID + \" should match but did not\");\n          } else {\n            System.out.println(\"TEST: id=\" + id + \" docID=\" + docID + \" should not match but did\");\n          }\n          System.out.println(\"  rect=\" + rect);\n          System.out.println(\"  lat=\" + latDoc1 + \" lon=\" + lonDoc1 + \"\\n  lat=\" + latDoc2 + \" lon=\" + lonDoc2);\n          System.out.println(\"  result1=\" + result1 + \" result2=\" + result2);\n          fail = true;\n        }\n      }\n\n      if (fail) {\n        fail(\"some hits were wrong\");\n      }\n    }\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":["03bffb520caf6e9833c4b9a82ac67d19a1f3fc97"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b9e52892242a8c82e1b0c1bd4f1d404366b0501c","date":1459531691,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/spatial/src/test/org/apache/lucene/spatial/util/BaseGeoPointTestCase#testMultiValued().mjava","pathOld":"lucene/spatial/src/test/org/apache/lucene/spatial/util/BaseGeoPointTestCase#testMultiValued().mjava","sourceNew":"  public void testMultiValued() throws Exception {\n    int numPoints = atLeast(10000);\n    // Every doc has 2 points:\n    double[] lats = new double[2*numPoints];\n    double[] lons = new double[2*numPoints];\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig();\n\n    // We rely on docID order:\n    iwc.setMergePolicy(newLogMergePolicy());\n    // and on seeds being able to reproduce:\n    iwc.setMergeScheduler(new SerialMergeScheduler());\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n\n    boolean small = random().nextBoolean();\n\n    for (int id=0;id<numPoints;id++) {\n      Document doc = new Document();\n      lats[2*id] = quantizeLat(randomLat(small));\n      lons[2*id] = quantizeLon(randomLon(small));\n      doc.add(newStringField(\"id\", \"\"+id, Field.Store.YES));\n      addPointToDoc(FIELD_NAME, doc, lats[2*id], lons[2*id]);\n      lats[2*id+1] = quantizeLat(randomLat(small));\n      lons[2*id+1] = quantizeLon(randomLon(small));\n      addPointToDoc(FIELD_NAME, doc, lats[2*id+1], lons[2*id+1]);\n\n      if (VERBOSE) {\n        System.out.println(\"id=\" + id);\n        System.out.println(\"  lat=\" + lats[2*id] + \" lon=\" + lons[2*id]);\n        System.out.println(\"  lat=\" + lats[2*id+1] + \" lon=\" + lons[2*id+1]);\n      }\n      w.addDocument(doc);\n    }\n\n    // TODO: share w/ verify; just need parallel array of the expected ids\n    if (random().nextBoolean()) {\n      w.forceMerge(1);\n    }\n    IndexReader r = w.getReader();\n    w.close();\n\n    IndexSearcher s = newSearcher(r);\n\n    int iters = atLeast(25);\n    for (int iter=0;iter<iters;iter++) {\n      GeoRect rect = randomRect(small);\n      // TODO: why does this test need this quantization leniency? something is not right\n      rect = new GeoRect(quantizeLat(rect.minLat), quantizeLat(rect.maxLat), quantizeLon(rect.minLon), quantizeLon(rect.maxLon));\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: iter=\" + iter + \" rect=\" + rect);\n      }\n\n      Query query = newRectQuery(FIELD_NAME, rect.minLat, rect.maxLat, rect.minLon, rect.maxLon);\n\n      final FixedBitSet hits = new FixedBitSet(r.maxDoc());\n      s.search(query, new SimpleCollector() {\n\n          private int docBase;\n\n          @Override\n          public boolean needsScores() {\n            return false;\n          }\n\n          @Override\n          protected void doSetNextReader(LeafReaderContext context) throws IOException {\n            docBase = context.docBase;\n          }\n\n          @Override\n          public void collect(int doc) {\n            hits.set(docBase+doc);\n          }\n        });\n\n      boolean fail = false;\n\n      for(int docID=0;docID<lats.length/2;docID++) {\n        double latDoc1 = lats[2*docID];\n        double lonDoc1 = lons[2*docID];\n        double latDoc2 = lats[2*docID+1];\n        double lonDoc2 = lons[2*docID+1];\n        \n        boolean result1 = rectContainsPoint(rect, latDoc1, lonDoc1);\n        boolean result2 = rectContainsPoint(rect, latDoc2, lonDoc2);\n\n        boolean expected = result1 || result2;\n\n        if (hits.get(docID) != expected) {\n          String id = s.doc(docID).get(\"id\");\n          if (expected) {\n            System.out.println(\"TEST: id=\" + id + \" docID=\" + docID + \" should match but did not\");\n          } else {\n            System.out.println(\"TEST: id=\" + id + \" docID=\" + docID + \" should not match but did\");\n          }\n          System.out.println(\"  rect=\" + rect);\n          System.out.println(\"  lat=\" + latDoc1 + \" lon=\" + lonDoc1 + \"\\n  lat=\" + latDoc2 + \" lon=\" + lonDoc2);\n          System.out.println(\"  result1=\" + result1 + \" result2=\" + result2);\n          fail = true;\n        }\n      }\n\n      if (fail) {\n        fail(\"some hits were wrong\");\n      }\n    }\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testMultiValued() throws Exception {\n    int numPoints = atLeast(10000);\n    // Every doc has 2 points:\n    double[] lats = new double[2*numPoints];\n    double[] lons = new double[2*numPoints];\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig();\n    initIndexWriterConfig(FIELD_NAME, iwc);\n\n    // We rely on docID order:\n    iwc.setMergePolicy(newLogMergePolicy());\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n\n    boolean small = random().nextBoolean();\n\n    for (int id=0;id<numPoints;id++) {\n      Document doc = new Document();\n      lats[2*id] = quantizeLat(randomLat(small));\n      lons[2*id] = quantizeLon(randomLon(small));\n      doc.add(newStringField(\"id\", \"\"+id, Field.Store.YES));\n      addPointToDoc(FIELD_NAME, doc, lats[2*id], lons[2*id]);\n      lats[2*id+1] = quantizeLat(randomLat(small));\n      lons[2*id+1] = quantizeLon(randomLon(small));\n      addPointToDoc(FIELD_NAME, doc, lats[2*id+1], lons[2*id+1]);\n\n      if (VERBOSE) {\n        System.out.println(\"id=\" + id);\n        System.out.println(\"  lat=\" + lats[2*id] + \" lon=\" + lons[2*id]);\n        System.out.println(\"  lat=\" + lats[2*id+1] + \" lon=\" + lons[2*id+1]);\n      }\n      w.addDocument(doc);\n    }\n\n    // TODO: share w/ verify; just need parallel array of the expected ids\n    if (random().nextBoolean()) {\n      w.forceMerge(1);\n    }\n    IndexReader r = w.getReader();\n    w.close();\n\n    IndexSearcher s = newSearcher(r);\n\n    int iters = atLeast(25);\n    for (int iter=0;iter<iters;iter++) {\n      GeoRect rect = randomRect(small);\n      // TODO: why does this test need this quantization leniency? something is not right\n      rect = new GeoRect(quantizeLat(rect.minLat), quantizeLat(rect.maxLat), quantizeLon(rect.minLon), quantizeLon(rect.maxLon));\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: iter=\" + iter + \" rect=\" + rect);\n      }\n\n      Query query = newRectQuery(FIELD_NAME, rect.minLat, rect.maxLat, rect.minLon, rect.maxLon);\n\n      final FixedBitSet hits = new FixedBitSet(r.maxDoc());\n      s.search(query, new SimpleCollector() {\n\n          private int docBase;\n\n          @Override\n          public boolean needsScores() {\n            return false;\n          }\n\n          @Override\n          protected void doSetNextReader(LeafReaderContext context) throws IOException {\n            docBase = context.docBase;\n          }\n\n          @Override\n          public void collect(int doc) {\n            hits.set(docBase+doc);\n          }\n        });\n\n      boolean fail = false;\n\n      for(int docID=0;docID<lats.length/2;docID++) {\n        double latDoc1 = lats[2*docID];\n        double lonDoc1 = lons[2*docID];\n        double latDoc2 = lats[2*docID+1];\n        double lonDoc2 = lons[2*docID+1];\n        \n        boolean result1 = rectContainsPoint(rect, latDoc1, lonDoc1);\n        boolean result2 = rectContainsPoint(rect, latDoc2, lonDoc2);\n\n        boolean expected = result1 || result2;\n\n        if (hits.get(docID) != expected) {\n          String id = s.doc(docID).get(\"id\");\n          if (expected) {\n            System.out.println(\"TEST: id=\" + id + \" docID=\" + docID + \" should match but did not\");\n          } else {\n            System.out.println(\"TEST: id=\" + id + \" docID=\" + docID + \" should not match but did\");\n          }\n          System.out.println(\"  rect=\" + rect);\n          System.out.println(\"  lat=\" + latDoc1 + \" lon=\" + lonDoc1 + \"\\n  lat=\" + latDoc2 + \" lon=\" + lonDoc2);\n          System.out.println(\"  result1=\" + result1 + \" result2=\" + result2);\n          fail = true;\n        }\n      }\n\n      if (fail) {\n        fail(\"some hits were wrong\");\n      }\n    }\n    r.close();\n    dir.close();\n  }\n\n","bugFix":["3c1d0e98e69e3b34294528b2f9ce96fe46b3e77a"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"03bffb520caf6e9833c4b9a82ac67d19a1f3fc97","date":1459595815,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/spatial/src/test/org/apache/lucene/spatial/util/BaseGeoPointTestCase#testMultiValued().mjava","pathOld":"lucene/spatial/src/test/org/apache/lucene/spatial/util/BaseGeoPointTestCase#testMultiValued().mjava","sourceNew":"  public void testMultiValued() throws Exception {\n    int numPoints = atLeast(10000);\n    // Every doc has 2 points:\n    double[] lats = new double[2*numPoints];\n    double[] lons = new double[2*numPoints];\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig();\n\n    // We rely on docID order:\n    iwc.setMergePolicy(newLogMergePolicy());\n    // and on seeds being able to reproduce:\n    iwc.setMergeScheduler(new SerialMergeScheduler());\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n\n    boolean small = random().nextBoolean();\n\n    for (int id=0;id<numPoints;id++) {\n      Document doc = new Document();\n      lats[2*id] = quantizeLat(randomLat(small));\n      lons[2*id] = quantizeLon(randomLon(small));\n      doc.add(newStringField(\"id\", \"\"+id, Field.Store.YES));\n      addPointToDoc(FIELD_NAME, doc, lats[2*id], lons[2*id]);\n      lats[2*id+1] = quantizeLat(randomLat(small));\n      lons[2*id+1] = quantizeLon(randomLon(small));\n      addPointToDoc(FIELD_NAME, doc, lats[2*id+1], lons[2*id+1]);\n\n      if (VERBOSE) {\n        System.out.println(\"id=\" + id);\n        System.out.println(\"  lat=\" + lats[2*id] + \" lon=\" + lons[2*id]);\n        System.out.println(\"  lat=\" + lats[2*id+1] + \" lon=\" + lons[2*id+1]);\n      }\n      w.addDocument(doc);\n    }\n\n    // TODO: share w/ verify; just need parallel array of the expected ids\n    if (random().nextBoolean()) {\n      w.forceMerge(1);\n    }\n    IndexReader r = w.getReader();\n    w.close();\n\n    IndexSearcher s = newSearcher(r);\n\n    int iters = atLeast(25);\n    for (int iter=0;iter<iters;iter++) {\n      GeoRect rect = randomRect(small);\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: iter=\" + iter + \" rect=\" + rect);\n      }\n\n      Query query = newRectQuery(FIELD_NAME, rect.minLat, rect.maxLat, rect.minLon, rect.maxLon);\n\n      final FixedBitSet hits = new FixedBitSet(r.maxDoc());\n      s.search(query, new SimpleCollector() {\n\n          private int docBase;\n\n          @Override\n          public boolean needsScores() {\n            return false;\n          }\n\n          @Override\n          protected void doSetNextReader(LeafReaderContext context) throws IOException {\n            docBase = context.docBase;\n          }\n\n          @Override\n          public void collect(int doc) {\n            hits.set(docBase+doc);\n          }\n        });\n\n      boolean fail = false;\n\n      for(int docID=0;docID<lats.length/2;docID++) {\n        double latDoc1 = lats[2*docID];\n        double lonDoc1 = lons[2*docID];\n        double latDoc2 = lats[2*docID+1];\n        double lonDoc2 = lons[2*docID+1];\n        \n        boolean result1 = rectContainsPoint(rect, latDoc1, lonDoc1);\n        boolean result2 = rectContainsPoint(rect, latDoc2, lonDoc2);\n\n        boolean expected = result1 || result2;\n\n        if (hits.get(docID) != expected) {\n          String id = s.doc(docID).get(\"id\");\n          if (expected) {\n            System.out.println(\"TEST: id=\" + id + \" docID=\" + docID + \" should match but did not\");\n          } else {\n            System.out.println(\"TEST: id=\" + id + \" docID=\" + docID + \" should not match but did\");\n          }\n          System.out.println(\"  rect=\" + rect);\n          System.out.println(\"  lat=\" + latDoc1 + \" lon=\" + lonDoc1 + \"\\n  lat=\" + latDoc2 + \" lon=\" + lonDoc2);\n          System.out.println(\"  result1=\" + result1 + \" result2=\" + result2);\n          fail = true;\n        }\n      }\n\n      if (fail) {\n        fail(\"some hits were wrong\");\n      }\n    }\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testMultiValued() throws Exception {\n    int numPoints = atLeast(10000);\n    // Every doc has 2 points:\n    double[] lats = new double[2*numPoints];\n    double[] lons = new double[2*numPoints];\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig();\n\n    // We rely on docID order:\n    iwc.setMergePolicy(newLogMergePolicy());\n    // and on seeds being able to reproduce:\n    iwc.setMergeScheduler(new SerialMergeScheduler());\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n\n    boolean small = random().nextBoolean();\n\n    for (int id=0;id<numPoints;id++) {\n      Document doc = new Document();\n      lats[2*id] = quantizeLat(randomLat(small));\n      lons[2*id] = quantizeLon(randomLon(small));\n      doc.add(newStringField(\"id\", \"\"+id, Field.Store.YES));\n      addPointToDoc(FIELD_NAME, doc, lats[2*id], lons[2*id]);\n      lats[2*id+1] = quantizeLat(randomLat(small));\n      lons[2*id+1] = quantizeLon(randomLon(small));\n      addPointToDoc(FIELD_NAME, doc, lats[2*id+1], lons[2*id+1]);\n\n      if (VERBOSE) {\n        System.out.println(\"id=\" + id);\n        System.out.println(\"  lat=\" + lats[2*id] + \" lon=\" + lons[2*id]);\n        System.out.println(\"  lat=\" + lats[2*id+1] + \" lon=\" + lons[2*id+1]);\n      }\n      w.addDocument(doc);\n    }\n\n    // TODO: share w/ verify; just need parallel array of the expected ids\n    if (random().nextBoolean()) {\n      w.forceMerge(1);\n    }\n    IndexReader r = w.getReader();\n    w.close();\n\n    IndexSearcher s = newSearcher(r);\n\n    int iters = atLeast(25);\n    for (int iter=0;iter<iters;iter++) {\n      GeoRect rect = randomRect(small);\n      // TODO: why does this test need this quantization leniency? something is not right\n      rect = new GeoRect(quantizeLat(rect.minLat), quantizeLat(rect.maxLat), quantizeLon(rect.minLon), quantizeLon(rect.maxLon));\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: iter=\" + iter + \" rect=\" + rect);\n      }\n\n      Query query = newRectQuery(FIELD_NAME, rect.minLat, rect.maxLat, rect.minLon, rect.maxLon);\n\n      final FixedBitSet hits = new FixedBitSet(r.maxDoc());\n      s.search(query, new SimpleCollector() {\n\n          private int docBase;\n\n          @Override\n          public boolean needsScores() {\n            return false;\n          }\n\n          @Override\n          protected void doSetNextReader(LeafReaderContext context) throws IOException {\n            docBase = context.docBase;\n          }\n\n          @Override\n          public void collect(int doc) {\n            hits.set(docBase+doc);\n          }\n        });\n\n      boolean fail = false;\n\n      for(int docID=0;docID<lats.length/2;docID++) {\n        double latDoc1 = lats[2*docID];\n        double lonDoc1 = lons[2*docID];\n        double latDoc2 = lats[2*docID+1];\n        double lonDoc2 = lons[2*docID+1];\n        \n        boolean result1 = rectContainsPoint(rect, latDoc1, lonDoc1);\n        boolean result2 = rectContainsPoint(rect, latDoc2, lonDoc2);\n\n        boolean expected = result1 || result2;\n\n        if (hits.get(docID) != expected) {\n          String id = s.doc(docID).get(\"id\");\n          if (expected) {\n            System.out.println(\"TEST: id=\" + id + \" docID=\" + docID + \" should match but did not\");\n          } else {\n            System.out.println(\"TEST: id=\" + id + \" docID=\" + docID + \" should not match but did\");\n          }\n          System.out.println(\"  rect=\" + rect);\n          System.out.println(\"  lat=\" + latDoc1 + \" lon=\" + lonDoc1 + \"\\n  lat=\" + latDoc2 + \" lon=\" + lonDoc2);\n          System.out.println(\"  result1=\" + result1 + \" result2=\" + result2);\n          fail = true;\n        }\n      }\n\n      if (fail) {\n        fail(\"some hits were wrong\");\n      }\n    }\n    r.close();\n    dir.close();\n  }\n\n","bugFix":["253f983bd74e240286a3e1a1e40294d589c5bef4"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"546f71f5b1e19230d6e7e59f117d08dbcf59fbfe","date":1459623422,"type":3,"author":"nknize","isMerge":false,"pathNew":"lucene/spatial/src/test/org/apache/lucene/spatial/util/BaseGeoPointTestCase#testMultiValued().mjava","pathOld":"lucene/spatial/src/test/org/apache/lucene/spatial/util/BaseGeoPointTestCase#testMultiValued().mjava","sourceNew":"  public void testMultiValued() throws Exception {\n    int numPoints = atLeast(10000);\n    // Every doc has 2 points:\n    double[] lats = new double[2*numPoints];\n    double[] lons = new double[2*numPoints];\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig();\n\n    // We rely on docID order:\n    iwc.setMergePolicy(newLogMergePolicy());\n    // and on seeds being able to reproduce:\n    iwc.setMergeScheduler(new SerialMergeScheduler());\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n\n    boolean small = random().nextBoolean();\n\n    for (int id=0;id<numPoints;id++) {\n      Document doc = new Document();\n      lats[2*id] = quantizeLat(randomLat(small));\n      lons[2*id] = quantizeLon(randomLon(small));\n      doc.add(newStringField(\"id\", \"\"+id, Field.Store.YES));\n      addPointToDoc(FIELD_NAME, doc, lats[2*id], lons[2*id]);\n      lats[2*id+1] = quantizeLat(randomLat(small));\n      lons[2*id+1] = quantizeLon(randomLon(small));\n      addPointToDoc(FIELD_NAME, doc, lats[2*id+1], lons[2*id+1]);\n\n      if (VERBOSE) {\n        System.out.println(\"id=\" + id);\n        System.out.println(\"  lat=\" + lats[2*id] + \" lon=\" + lons[2*id]);\n        System.out.println(\"  lat=\" + lats[2*id+1] + \" lon=\" + lons[2*id+1]);\n      }\n      w.addDocument(doc);\n    }\n\n    // TODO: share w/ verify; just need parallel array of the expected ids\n    if (random().nextBoolean()) {\n      w.forceMerge(1);\n    }\n    IndexReader r = w.getReader();\n    w.close();\n\n    IndexSearcher s = newSearcher(r);\n\n    int iters = atLeast(25);\n    for (int iter=0;iter<iters;iter++) {\n      Rectangle rect = randomRect(small);\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: iter=\" + iter + \" rect=\" + rect);\n      }\n\n      Query query = newRectQuery(FIELD_NAME, rect.minLat, rect.maxLat, rect.minLon, rect.maxLon);\n\n      final FixedBitSet hits = new FixedBitSet(r.maxDoc());\n      s.search(query, new SimpleCollector() {\n\n          private int docBase;\n\n          @Override\n          public boolean needsScores() {\n            return false;\n          }\n\n          @Override\n          protected void doSetNextReader(LeafReaderContext context) throws IOException {\n            docBase = context.docBase;\n          }\n\n          @Override\n          public void collect(int doc) {\n            hits.set(docBase+doc);\n          }\n        });\n\n      boolean fail = false;\n\n      for(int docID=0;docID<lats.length/2;docID++) {\n        double latDoc1 = lats[2*docID];\n        double lonDoc1 = lons[2*docID];\n        double latDoc2 = lats[2*docID+1];\n        double lonDoc2 = lons[2*docID+1];\n        \n        boolean result1 = rectContainsPoint(rect, latDoc1, lonDoc1);\n        boolean result2 = rectContainsPoint(rect, latDoc2, lonDoc2);\n\n        boolean expected = result1 || result2;\n\n        if (hits.get(docID) != expected) {\n          String id = s.doc(docID).get(\"id\");\n          if (expected) {\n            System.out.println(\"TEST: id=\" + id + \" docID=\" + docID + \" should match but did not\");\n          } else {\n            System.out.println(\"TEST: id=\" + id + \" docID=\" + docID + \" should not match but did\");\n          }\n          System.out.println(\"  rect=\" + rect);\n          System.out.println(\"  lat=\" + latDoc1 + \" lon=\" + lonDoc1 + \"\\n  lat=\" + latDoc2 + \" lon=\" + lonDoc2);\n          System.out.println(\"  result1=\" + result1 + \" result2=\" + result2);\n          fail = true;\n        }\n      }\n\n      if (fail) {\n        fail(\"some hits were wrong\");\n      }\n    }\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testMultiValued() throws Exception {\n    int numPoints = atLeast(10000);\n    // Every doc has 2 points:\n    double[] lats = new double[2*numPoints];\n    double[] lons = new double[2*numPoints];\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig();\n\n    // We rely on docID order:\n    iwc.setMergePolicy(newLogMergePolicy());\n    // and on seeds being able to reproduce:\n    iwc.setMergeScheduler(new SerialMergeScheduler());\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n\n    boolean small = random().nextBoolean();\n\n    for (int id=0;id<numPoints;id++) {\n      Document doc = new Document();\n      lats[2*id] = quantizeLat(randomLat(small));\n      lons[2*id] = quantizeLon(randomLon(small));\n      doc.add(newStringField(\"id\", \"\"+id, Field.Store.YES));\n      addPointToDoc(FIELD_NAME, doc, lats[2*id], lons[2*id]);\n      lats[2*id+1] = quantizeLat(randomLat(small));\n      lons[2*id+1] = quantizeLon(randomLon(small));\n      addPointToDoc(FIELD_NAME, doc, lats[2*id+1], lons[2*id+1]);\n\n      if (VERBOSE) {\n        System.out.println(\"id=\" + id);\n        System.out.println(\"  lat=\" + lats[2*id] + \" lon=\" + lons[2*id]);\n        System.out.println(\"  lat=\" + lats[2*id+1] + \" lon=\" + lons[2*id+1]);\n      }\n      w.addDocument(doc);\n    }\n\n    // TODO: share w/ verify; just need parallel array of the expected ids\n    if (random().nextBoolean()) {\n      w.forceMerge(1);\n    }\n    IndexReader r = w.getReader();\n    w.close();\n\n    IndexSearcher s = newSearcher(r);\n\n    int iters = atLeast(25);\n    for (int iter=0;iter<iters;iter++) {\n      GeoRect rect = randomRect(small);\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: iter=\" + iter + \" rect=\" + rect);\n      }\n\n      Query query = newRectQuery(FIELD_NAME, rect.minLat, rect.maxLat, rect.minLon, rect.maxLon);\n\n      final FixedBitSet hits = new FixedBitSet(r.maxDoc());\n      s.search(query, new SimpleCollector() {\n\n          private int docBase;\n\n          @Override\n          public boolean needsScores() {\n            return false;\n          }\n\n          @Override\n          protected void doSetNextReader(LeafReaderContext context) throws IOException {\n            docBase = context.docBase;\n          }\n\n          @Override\n          public void collect(int doc) {\n            hits.set(docBase+doc);\n          }\n        });\n\n      boolean fail = false;\n\n      for(int docID=0;docID<lats.length/2;docID++) {\n        double latDoc1 = lats[2*docID];\n        double lonDoc1 = lons[2*docID];\n        double latDoc2 = lats[2*docID+1];\n        double lonDoc2 = lons[2*docID+1];\n        \n        boolean result1 = rectContainsPoint(rect, latDoc1, lonDoc1);\n        boolean result2 = rectContainsPoint(rect, latDoc2, lonDoc2);\n\n        boolean expected = result1 || result2;\n\n        if (hits.get(docID) != expected) {\n          String id = s.doc(docID).get(\"id\");\n          if (expected) {\n            System.out.println(\"TEST: id=\" + id + \" docID=\" + docID + \" should match but did not\");\n          } else {\n            System.out.println(\"TEST: id=\" + id + \" docID=\" + docID + \" should not match but did\");\n          }\n          System.out.println(\"  rect=\" + rect);\n          System.out.println(\"  lat=\" + latDoc1 + \" lon=\" + lonDoc1 + \"\\n  lat=\" + latDoc2 + \" lon=\" + lonDoc2);\n          System.out.println(\"  result1=\" + result1 + \" result2=\" + result2);\n          fail = true;\n        }\n      }\n\n      if (fail) {\n        fail(\"some hits were wrong\");\n      }\n    }\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3e21d7642ee7e0c00429964e5b47504602fe218c","date":1460897579,"type":5,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/geo/BaseGeoPointTestCase#testMultiValued().mjava","pathOld":"lucene/spatial/src/test/org/apache/lucene/spatial/util/BaseGeoPointTestCase#testMultiValued().mjava","sourceNew":"  public void testMultiValued() throws Exception {\n    int numPoints = atLeast(10000);\n    // Every doc has 2 points:\n    double[] lats = new double[2*numPoints];\n    double[] lons = new double[2*numPoints];\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig();\n\n    // We rely on docID order:\n    iwc.setMergePolicy(newLogMergePolicy());\n    // and on seeds being able to reproduce:\n    iwc.setMergeScheduler(new SerialMergeScheduler());\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n\n    boolean small = random().nextBoolean();\n\n    for (int id=0;id<numPoints;id++) {\n      Document doc = new Document();\n      lats[2*id] = quantizeLat(randomLat(small));\n      lons[2*id] = quantizeLon(randomLon(small));\n      doc.add(newStringField(\"id\", \"\"+id, Field.Store.YES));\n      addPointToDoc(FIELD_NAME, doc, lats[2*id], lons[2*id]);\n      lats[2*id+1] = quantizeLat(randomLat(small));\n      lons[2*id+1] = quantizeLon(randomLon(small));\n      addPointToDoc(FIELD_NAME, doc, lats[2*id+1], lons[2*id+1]);\n\n      if (VERBOSE) {\n        System.out.println(\"id=\" + id);\n        System.out.println(\"  lat=\" + lats[2*id] + \" lon=\" + lons[2*id]);\n        System.out.println(\"  lat=\" + lats[2*id+1] + \" lon=\" + lons[2*id+1]);\n      }\n      w.addDocument(doc);\n    }\n\n    // TODO: share w/ verify; just need parallel array of the expected ids\n    if (random().nextBoolean()) {\n      w.forceMerge(1);\n    }\n    IndexReader r = w.getReader();\n    w.close();\n\n    IndexSearcher s = newSearcher(r);\n\n    int iters = atLeast(25);\n    for (int iter=0;iter<iters;iter++) {\n      Rectangle rect = randomRect(small);\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: iter=\" + iter + \" rect=\" + rect);\n      }\n\n      Query query = newRectQuery(FIELD_NAME, rect.minLat, rect.maxLat, rect.minLon, rect.maxLon);\n\n      final FixedBitSet hits = new FixedBitSet(r.maxDoc());\n      s.search(query, new SimpleCollector() {\n\n          private int docBase;\n\n          @Override\n          public boolean needsScores() {\n            return false;\n          }\n\n          @Override\n          protected void doSetNextReader(LeafReaderContext context) throws IOException {\n            docBase = context.docBase;\n          }\n\n          @Override\n          public void collect(int doc) {\n            hits.set(docBase+doc);\n          }\n        });\n\n      boolean fail = false;\n\n      for(int docID=0;docID<lats.length/2;docID++) {\n        double latDoc1 = lats[2*docID];\n        double lonDoc1 = lons[2*docID];\n        double latDoc2 = lats[2*docID+1];\n        double lonDoc2 = lons[2*docID+1];\n        \n        boolean result1 = rectContainsPoint(rect, latDoc1, lonDoc1);\n        boolean result2 = rectContainsPoint(rect, latDoc2, lonDoc2);\n\n        boolean expected = result1 || result2;\n\n        if (hits.get(docID) != expected) {\n          String id = s.doc(docID).get(\"id\");\n          if (expected) {\n            System.out.println(\"TEST: id=\" + id + \" docID=\" + docID + \" should match but did not\");\n          } else {\n            System.out.println(\"TEST: id=\" + id + \" docID=\" + docID + \" should not match but did\");\n          }\n          System.out.println(\"  rect=\" + rect);\n          System.out.println(\"  lat=\" + latDoc1 + \" lon=\" + lonDoc1 + \"\\n  lat=\" + latDoc2 + \" lon=\" + lonDoc2);\n          System.out.println(\"  result1=\" + result1 + \" result2=\" + result2);\n          fail = true;\n        }\n      }\n\n      if (fail) {\n        fail(\"some hits were wrong\");\n      }\n    }\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testMultiValued() throws Exception {\n    int numPoints = atLeast(10000);\n    // Every doc has 2 points:\n    double[] lats = new double[2*numPoints];\n    double[] lons = new double[2*numPoints];\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig();\n\n    // We rely on docID order:\n    iwc.setMergePolicy(newLogMergePolicy());\n    // and on seeds being able to reproduce:\n    iwc.setMergeScheduler(new SerialMergeScheduler());\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n\n    boolean small = random().nextBoolean();\n\n    for (int id=0;id<numPoints;id++) {\n      Document doc = new Document();\n      lats[2*id] = quantizeLat(randomLat(small));\n      lons[2*id] = quantizeLon(randomLon(small));\n      doc.add(newStringField(\"id\", \"\"+id, Field.Store.YES));\n      addPointToDoc(FIELD_NAME, doc, lats[2*id], lons[2*id]);\n      lats[2*id+1] = quantizeLat(randomLat(small));\n      lons[2*id+1] = quantizeLon(randomLon(small));\n      addPointToDoc(FIELD_NAME, doc, lats[2*id+1], lons[2*id+1]);\n\n      if (VERBOSE) {\n        System.out.println(\"id=\" + id);\n        System.out.println(\"  lat=\" + lats[2*id] + \" lon=\" + lons[2*id]);\n        System.out.println(\"  lat=\" + lats[2*id+1] + \" lon=\" + lons[2*id+1]);\n      }\n      w.addDocument(doc);\n    }\n\n    // TODO: share w/ verify; just need parallel array of the expected ids\n    if (random().nextBoolean()) {\n      w.forceMerge(1);\n    }\n    IndexReader r = w.getReader();\n    w.close();\n\n    IndexSearcher s = newSearcher(r);\n\n    int iters = atLeast(25);\n    for (int iter=0;iter<iters;iter++) {\n      Rectangle rect = randomRect(small);\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: iter=\" + iter + \" rect=\" + rect);\n      }\n\n      Query query = newRectQuery(FIELD_NAME, rect.minLat, rect.maxLat, rect.minLon, rect.maxLon);\n\n      final FixedBitSet hits = new FixedBitSet(r.maxDoc());\n      s.search(query, new SimpleCollector() {\n\n          private int docBase;\n\n          @Override\n          public boolean needsScores() {\n            return false;\n          }\n\n          @Override\n          protected void doSetNextReader(LeafReaderContext context) throws IOException {\n            docBase = context.docBase;\n          }\n\n          @Override\n          public void collect(int doc) {\n            hits.set(docBase+doc);\n          }\n        });\n\n      boolean fail = false;\n\n      for(int docID=0;docID<lats.length/2;docID++) {\n        double latDoc1 = lats[2*docID];\n        double lonDoc1 = lons[2*docID];\n        double latDoc2 = lats[2*docID+1];\n        double lonDoc2 = lons[2*docID+1];\n        \n        boolean result1 = rectContainsPoint(rect, latDoc1, lonDoc1);\n        boolean result2 = rectContainsPoint(rect, latDoc2, lonDoc2);\n\n        boolean expected = result1 || result2;\n\n        if (hits.get(docID) != expected) {\n          String id = s.doc(docID).get(\"id\");\n          if (expected) {\n            System.out.println(\"TEST: id=\" + id + \" docID=\" + docID + \" should match but did not\");\n          } else {\n            System.out.println(\"TEST: id=\" + id + \" docID=\" + docID + \" should not match but did\");\n          }\n          System.out.println(\"  rect=\" + rect);\n          System.out.println(\"  lat=\" + latDoc1 + \" lon=\" + lonDoc1 + \"\\n  lat=\" + latDoc2 + \" lon=\" + lonDoc2);\n          System.out.println(\"  result1=\" + result1 + \" result2=\" + result2);\n          fail = true;\n        }\n      }\n\n      if (fail) {\n        fail(\"some hits were wrong\");\n      }\n    }\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f8cb57c50beb99a1245256e866350af8e5ea1f36","date":1460921840,"type":5,"author":"Karl Wright","isMerge":true,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/geo/BaseGeoPointTestCase#testMultiValued().mjava","pathOld":"lucene/spatial/src/test/org/apache/lucene/spatial/util/BaseGeoPointTestCase#testMultiValued().mjava","sourceNew":"  public void testMultiValued() throws Exception {\n    int numPoints = atLeast(10000);\n    // Every doc has 2 points:\n    double[] lats = new double[2*numPoints];\n    double[] lons = new double[2*numPoints];\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig();\n\n    // We rely on docID order:\n    iwc.setMergePolicy(newLogMergePolicy());\n    // and on seeds being able to reproduce:\n    iwc.setMergeScheduler(new SerialMergeScheduler());\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n\n    boolean small = random().nextBoolean();\n\n    for (int id=0;id<numPoints;id++) {\n      Document doc = new Document();\n      lats[2*id] = quantizeLat(randomLat(small));\n      lons[2*id] = quantizeLon(randomLon(small));\n      doc.add(newStringField(\"id\", \"\"+id, Field.Store.YES));\n      addPointToDoc(FIELD_NAME, doc, lats[2*id], lons[2*id]);\n      lats[2*id+1] = quantizeLat(randomLat(small));\n      lons[2*id+1] = quantizeLon(randomLon(small));\n      addPointToDoc(FIELD_NAME, doc, lats[2*id+1], lons[2*id+1]);\n\n      if (VERBOSE) {\n        System.out.println(\"id=\" + id);\n        System.out.println(\"  lat=\" + lats[2*id] + \" lon=\" + lons[2*id]);\n        System.out.println(\"  lat=\" + lats[2*id+1] + \" lon=\" + lons[2*id+1]);\n      }\n      w.addDocument(doc);\n    }\n\n    // TODO: share w/ verify; just need parallel array of the expected ids\n    if (random().nextBoolean()) {\n      w.forceMerge(1);\n    }\n    IndexReader r = w.getReader();\n    w.close();\n\n    IndexSearcher s = newSearcher(r);\n\n    int iters = atLeast(25);\n    for (int iter=0;iter<iters;iter++) {\n      Rectangle rect = randomRect(small);\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: iter=\" + iter + \" rect=\" + rect);\n      }\n\n      Query query = newRectQuery(FIELD_NAME, rect.minLat, rect.maxLat, rect.minLon, rect.maxLon);\n\n      final FixedBitSet hits = new FixedBitSet(r.maxDoc());\n      s.search(query, new SimpleCollector() {\n\n          private int docBase;\n\n          @Override\n          public boolean needsScores() {\n            return false;\n          }\n\n          @Override\n          protected void doSetNextReader(LeafReaderContext context) throws IOException {\n            docBase = context.docBase;\n          }\n\n          @Override\n          public void collect(int doc) {\n            hits.set(docBase+doc);\n          }\n        });\n\n      boolean fail = false;\n\n      for(int docID=0;docID<lats.length/2;docID++) {\n        double latDoc1 = lats[2*docID];\n        double lonDoc1 = lons[2*docID];\n        double latDoc2 = lats[2*docID+1];\n        double lonDoc2 = lons[2*docID+1];\n        \n        boolean result1 = rectContainsPoint(rect, latDoc1, lonDoc1);\n        boolean result2 = rectContainsPoint(rect, latDoc2, lonDoc2);\n\n        boolean expected = result1 || result2;\n\n        if (hits.get(docID) != expected) {\n          String id = s.doc(docID).get(\"id\");\n          if (expected) {\n            System.out.println(\"TEST: id=\" + id + \" docID=\" + docID + \" should match but did not\");\n          } else {\n            System.out.println(\"TEST: id=\" + id + \" docID=\" + docID + \" should not match but did\");\n          }\n          System.out.println(\"  rect=\" + rect);\n          System.out.println(\"  lat=\" + latDoc1 + \" lon=\" + lonDoc1 + \"\\n  lat=\" + latDoc2 + \" lon=\" + lonDoc2);\n          System.out.println(\"  result1=\" + result1 + \" result2=\" + result2);\n          fail = true;\n        }\n      }\n\n      if (fail) {\n        fail(\"some hits were wrong\");\n      }\n    }\n    r.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testMultiValued() throws Exception {\n    int numPoints = atLeast(10000);\n    // Every doc has 2 points:\n    double[] lats = new double[2*numPoints];\n    double[] lons = new double[2*numPoints];\n    Directory dir = newDirectory();\n    IndexWriterConfig iwc = newIndexWriterConfig();\n\n    // We rely on docID order:\n    iwc.setMergePolicy(newLogMergePolicy());\n    // and on seeds being able to reproduce:\n    iwc.setMergeScheduler(new SerialMergeScheduler());\n    RandomIndexWriter w = new RandomIndexWriter(random(), dir, iwc);\n\n    boolean small = random().nextBoolean();\n\n    for (int id=0;id<numPoints;id++) {\n      Document doc = new Document();\n      lats[2*id] = quantizeLat(randomLat(small));\n      lons[2*id] = quantizeLon(randomLon(small));\n      doc.add(newStringField(\"id\", \"\"+id, Field.Store.YES));\n      addPointToDoc(FIELD_NAME, doc, lats[2*id], lons[2*id]);\n      lats[2*id+1] = quantizeLat(randomLat(small));\n      lons[2*id+1] = quantizeLon(randomLon(small));\n      addPointToDoc(FIELD_NAME, doc, lats[2*id+1], lons[2*id+1]);\n\n      if (VERBOSE) {\n        System.out.println(\"id=\" + id);\n        System.out.println(\"  lat=\" + lats[2*id] + \" lon=\" + lons[2*id]);\n        System.out.println(\"  lat=\" + lats[2*id+1] + \" lon=\" + lons[2*id+1]);\n      }\n      w.addDocument(doc);\n    }\n\n    // TODO: share w/ verify; just need parallel array of the expected ids\n    if (random().nextBoolean()) {\n      w.forceMerge(1);\n    }\n    IndexReader r = w.getReader();\n    w.close();\n\n    IndexSearcher s = newSearcher(r);\n\n    int iters = atLeast(25);\n    for (int iter=0;iter<iters;iter++) {\n      Rectangle rect = randomRect(small);\n\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: iter=\" + iter + \" rect=\" + rect);\n      }\n\n      Query query = newRectQuery(FIELD_NAME, rect.minLat, rect.maxLat, rect.minLon, rect.maxLon);\n\n      final FixedBitSet hits = new FixedBitSet(r.maxDoc());\n      s.search(query, new SimpleCollector() {\n\n          private int docBase;\n\n          @Override\n          public boolean needsScores() {\n            return false;\n          }\n\n          @Override\n          protected void doSetNextReader(LeafReaderContext context) throws IOException {\n            docBase = context.docBase;\n          }\n\n          @Override\n          public void collect(int doc) {\n            hits.set(docBase+doc);\n          }\n        });\n\n      boolean fail = false;\n\n      for(int docID=0;docID<lats.length/2;docID++) {\n        double latDoc1 = lats[2*docID];\n        double lonDoc1 = lons[2*docID];\n        double latDoc2 = lats[2*docID+1];\n        double lonDoc2 = lons[2*docID+1];\n        \n        boolean result1 = rectContainsPoint(rect, latDoc1, lonDoc1);\n        boolean result2 = rectContainsPoint(rect, latDoc2, lonDoc2);\n\n        boolean expected = result1 || result2;\n\n        if (hits.get(docID) != expected) {\n          String id = s.doc(docID).get(\"id\");\n          if (expected) {\n            System.out.println(\"TEST: id=\" + id + \" docID=\" + docID + \" should match but did not\");\n          } else {\n            System.out.println(\"TEST: id=\" + id + \" docID=\" + docID + \" should not match but did\");\n          }\n          System.out.println(\"  rect=\" + rect);\n          System.out.println(\"  lat=\" + latDoc1 + \" lon=\" + lonDoc1 + \"\\n  lat=\" + latDoc2 + \" lon=\" + lonDoc2);\n          System.out.println(\"  result1=\" + result1 + \" result2=\" + result2);\n          fail = true;\n        }\n      }\n\n      if (fail) {\n        fail(\"some hits were wrong\");\n      }\n    }\n    r.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"253f983bd74e240286a3e1a1e40294d589c5bef4":["1419d3974886c9518c259c786492b4d3660b0b8e"],"5a207d19eac354d649c3f0e2cce070017c78125e":["937923083e4d137932336fc80f3d78758ff698a6","b470f36a9372c97283360b1304eacbde22df6c0d"],"1e6acbaae7af722f17204ceccf0f7db5753eccf3":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","b470f36a9372c97283360b1304eacbde22df6c0d"],"1419d3974886c9518c259c786492b4d3660b0b8e":["84d7daf8313ff5c20a3ab51ffd646f5e862e1bac"],"03bffb520caf6e9833c4b9a82ac67d19a1f3fc97":["b9e52892242a8c82e1b0c1bd4f1d404366b0501c"],"f8cb57c50beb99a1245256e866350af8e5ea1f36":["546f71f5b1e19230d6e7e59f117d08dbcf59fbfe","3e21d7642ee7e0c00429964e5b47504602fe218c"],"d6c59bc551f4e523ce6a321280cc6733424fb824":["cb4875e9db9b77346c36b7fe0d4b8759a1e095d3"],"84d7daf8313ff5c20a3ab51ffd646f5e862e1bac":["d6c59bc551f4e523ce6a321280cc6733424fb824"],"b470f36a9372c97283360b1304eacbde22df6c0d":["937923083e4d137932336fc80f3d78758ff698a6","a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"b9e52892242a8c82e1b0c1bd4f1d404366b0501c":["253f983bd74e240286a3e1a1e40294d589c5bef4"],"546f71f5b1e19230d6e7e59f117d08dbcf59fbfe":["03bffb520caf6e9833c4b9a82ac67d19a1f3fc97"],"cb4875e9db9b77346c36b7fe0d4b8759a1e095d3":["5a207d19eac354d649c3f0e2cce070017c78125e"],"937923083e4d137932336fc80f3d78758ff698a6":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"3e21d7642ee7e0c00429964e5b47504602fe218c":["546f71f5b1e19230d6e7e59f117d08dbcf59fbfe"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["f8cb57c50beb99a1245256e866350af8e5ea1f36"]},"commit2Childs":{"253f983bd74e240286a3e1a1e40294d589c5bef4":["b9e52892242a8c82e1b0c1bd4f1d404366b0501c"],"5a207d19eac354d649c3f0e2cce070017c78125e":["cb4875e9db9b77346c36b7fe0d4b8759a1e095d3"],"1e6acbaae7af722f17204ceccf0f7db5753eccf3":[],"1419d3974886c9518c259c786492b4d3660b0b8e":["253f983bd74e240286a3e1a1e40294d589c5bef4"],"03bffb520caf6e9833c4b9a82ac67d19a1f3fc97":["546f71f5b1e19230d6e7e59f117d08dbcf59fbfe"],"f8cb57c50beb99a1245256e866350af8e5ea1f36":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"d6c59bc551f4e523ce6a321280cc6733424fb824":["84d7daf8313ff5c20a3ab51ffd646f5e862e1bac"],"84d7daf8313ff5c20a3ab51ffd646f5e862e1bac":["1419d3974886c9518c259c786492b4d3660b0b8e"],"b470f36a9372c97283360b1304eacbde22df6c0d":["5a207d19eac354d649c3f0e2cce070017c78125e","1e6acbaae7af722f17204ceccf0f7db5753eccf3"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["1e6acbaae7af722f17204ceccf0f7db5753eccf3","b470f36a9372c97283360b1304eacbde22df6c0d","937923083e4d137932336fc80f3d78758ff698a6"],"b9e52892242a8c82e1b0c1bd4f1d404366b0501c":["03bffb520caf6e9833c4b9a82ac67d19a1f3fc97"],"546f71f5b1e19230d6e7e59f117d08dbcf59fbfe":["f8cb57c50beb99a1245256e866350af8e5ea1f36","3e21d7642ee7e0c00429964e5b47504602fe218c"],"cb4875e9db9b77346c36b7fe0d4b8759a1e095d3":["d6c59bc551f4e523ce6a321280cc6733424fb824"],"937923083e4d137932336fc80f3d78758ff698a6":["5a207d19eac354d649c3f0e2cce070017c78125e","b470f36a9372c97283360b1304eacbde22df6c0d"],"3e21d7642ee7e0c00429964e5b47504602fe218c":["f8cb57c50beb99a1245256e866350af8e5ea1f36"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["1e6acbaae7af722f17204ceccf0f7db5753eccf3","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}