{"path":"lucene/classification/src/java/org/apache/lucene/classification/BM25NBClassifier#tokenize(String).mjava","commits":[{"id":"37dc4585237301aef478cc54a24c7188a28ab2e6","date":1494512792,"type":0,"author":"Tommaso Teofili","isMerge":false,"pathNew":"lucene/classification/src/java/org/apache/lucene/classification/BM25NBClassifier#tokenize(String).mjava","pathOld":"/dev/null","sourceNew":"  /**\n   * tokenize a <code>String</code> on this classifier's text fields and analyzer\n   *\n   * @param text the <code>String</code> representing an input text (to be classified)\n   * @return a <code>String</code> array of the resulting tokens\n   * @throws IOException if tokenization fails\n   */\n  private String[] tokenize(String text) throws IOException {\n    Collection<String> result = new LinkedList<>();\n    for (String textFieldName : textFieldNames) {\n      try (TokenStream tokenStream = analyzer.tokenStream(textFieldName, text)) {\n        CharTermAttribute charTermAttribute = tokenStream.addAttribute(CharTermAttribute.class);\n        tokenStream.reset();\n        while (tokenStream.incrementToken()) {\n          result.add(charTermAttribute.toString());\n        }\n        tokenStream.end();\n      }\n    }\n    return result.toArray(new String[result.size()]);\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"360b3962efc30aa8b2c39c3087aa36069674bbe7","date":1494557674,"type":0,"author":"Cao Manh Dat","isMerge":true,"pathNew":"lucene/classification/src/java/org/apache/lucene/classification/BM25NBClassifier#tokenize(String).mjava","pathOld":"/dev/null","sourceNew":"  /**\n   * tokenize a <code>String</code> on this classifier's text fields and analyzer\n   *\n   * @param text the <code>String</code> representing an input text (to be classified)\n   * @return a <code>String</code> array of the resulting tokens\n   * @throws IOException if tokenization fails\n   */\n  private String[] tokenize(String text) throws IOException {\n    Collection<String> result = new LinkedList<>();\n    for (String textFieldName : textFieldNames) {\n      try (TokenStream tokenStream = analyzer.tokenStream(textFieldName, text)) {\n        CharTermAttribute charTermAttribute = tokenStream.addAttribute(CharTermAttribute.class);\n        tokenStream.reset();\n        while (tokenStream.incrementToken()) {\n          result.add(charTermAttribute.toString());\n        }\n        tokenStream.end();\n      }\n    }\n    return result.toArray(new String[result.size()]);\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e9017cf144952056066919f1ebc7897ff9bd71b1","date":1496757600,"type":0,"author":"Shalin Shekhar Mangar","isMerge":true,"pathNew":"lucene/classification/src/java/org/apache/lucene/classification/BM25NBClassifier#tokenize(String).mjava","pathOld":"/dev/null","sourceNew":"  /**\n   * tokenize a <code>String</code> on this classifier's text fields and analyzer\n   *\n   * @param text the <code>String</code> representing an input text (to be classified)\n   * @return a <code>String</code> array of the resulting tokens\n   * @throws IOException if tokenization fails\n   */\n  private String[] tokenize(String text) throws IOException {\n    Collection<String> result = new LinkedList<>();\n    for (String textFieldName : textFieldNames) {\n      try (TokenStream tokenStream = analyzer.tokenStream(textFieldName, text)) {\n        CharTermAttribute charTermAttribute = tokenStream.addAttribute(CharTermAttribute.class);\n        tokenStream.reset();\n        while (tokenStream.incrementToken()) {\n          result.add(charTermAttribute.toString());\n        }\n        tokenStream.end();\n      }\n    }\n    return result.toArray(new String[result.size()]);\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"33bfee30277584028170135002def66f9d57732b","date":1547842233,"type":3,"author":"Tommaso Teofili","isMerge":false,"pathNew":"lucene/classification/src/java/org/apache/lucene/classification/BM25NBClassifier#tokenize(String).mjava","pathOld":"lucene/classification/src/java/org/apache/lucene/classification/BM25NBClassifier#tokenize(String).mjava","sourceNew":"  /**\n   * tokenize a <code>String</code> on this classifier's text fields and analyzer\n   *\n   * @param text the <code>String</code> representing an input text (to be classified)\n   * @return a <code>String</code> array of the resulting tokens\n   * @throws IOException if tokenization fails\n   */\n  private String[] tokenize(String text) throws IOException {\n    Collection<String> result = new LinkedList<>();\n    for (String textFieldName : textFieldNames) {\n      try (TokenStream tokenStream = analyzer.tokenStream(textFieldName, text)) {\n        CharTermAttribute charTermAttribute = tokenStream.addAttribute(CharTermAttribute.class);\n        tokenStream.reset();\n        while (tokenStream.incrementToken()) {\n          result.add(charTermAttribute.toString());\n        }\n        tokenStream.end();\n      }\n    }\n    return result.toArray(new String[0]);\n  }\n\n","sourceOld":"  /**\n   * tokenize a <code>String</code> on this classifier's text fields and analyzer\n   *\n   * @param text the <code>String</code> representing an input text (to be classified)\n   * @return a <code>String</code> array of the resulting tokens\n   * @throws IOException if tokenization fails\n   */\n  private String[] tokenize(String text) throws IOException {\n    Collection<String> result = new LinkedList<>();\n    for (String textFieldName : textFieldNames) {\n      try (TokenStream tokenStream = analyzer.tokenStream(textFieldName, text)) {\n        CharTermAttribute charTermAttribute = tokenStream.addAttribute(CharTermAttribute.class);\n        tokenStream.reset();\n        while (tokenStream.incrementToken()) {\n          result.add(charTermAttribute.toString());\n        }\n        tokenStream.end();\n      }\n    }\n    return result.toArray(new String[result.size()]);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"52ec154a31cf63bc47d2cc0b49e171a4e75aa99d","date":1548322018,"type":3,"author":"Tommaso Teofili","isMerge":true,"pathNew":"lucene/classification/src/java/org/apache/lucene/classification/BM25NBClassifier#tokenize(String).mjava","pathOld":"lucene/classification/src/java/org/apache/lucene/classification/BM25NBClassifier#tokenize(String).mjava","sourceNew":"  /**\n   * tokenize a <code>String</code> on this classifier's text fields and analyzer\n   *\n   * @param text the <code>String</code> representing an input text (to be classified)\n   * @return a <code>String</code> array of the resulting tokens\n   * @throws IOException if tokenization fails\n   */\n  private String[] tokenize(String text) throws IOException {\n    Collection<String> result = new LinkedList<>();\n    for (String textFieldName : textFieldNames) {\n      try (TokenStream tokenStream = analyzer.tokenStream(textFieldName, text)) {\n        CharTermAttribute charTermAttribute = tokenStream.addAttribute(CharTermAttribute.class);\n        tokenStream.reset();\n        while (tokenStream.incrementToken()) {\n          result.add(charTermAttribute.toString());\n        }\n        tokenStream.end();\n      }\n    }\n    return result.toArray(new String[0]);\n  }\n\n","sourceOld":"  /**\n   * tokenize a <code>String</code> on this classifier's text fields and analyzer\n   *\n   * @param text the <code>String</code> representing an input text (to be classified)\n   * @return a <code>String</code> array of the resulting tokens\n   * @throws IOException if tokenization fails\n   */\n  private String[] tokenize(String text) throws IOException {\n    Collection<String> result = new LinkedList<>();\n    for (String textFieldName : textFieldNames) {\n      try (TokenStream tokenStream = analyzer.tokenStream(textFieldName, text)) {\n        CharTermAttribute charTermAttribute = tokenStream.addAttribute(CharTermAttribute.class);\n        tokenStream.reset();\n        while (tokenStream.incrementToken()) {\n          result.add(charTermAttribute.toString());\n        }\n        tokenStream.end();\n      }\n    }\n    return result.toArray(new String[result.size()]);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"e9017cf144952056066919f1ebc7897ff9bd71b1":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","360b3962efc30aa8b2c39c3087aa36069674bbe7"],"52ec154a31cf63bc47d2cc0b49e171a4e75aa99d":["360b3962efc30aa8b2c39c3087aa36069674bbe7","33bfee30277584028170135002def66f9d57732b"],"360b3962efc30aa8b2c39c3087aa36069674bbe7":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","37dc4585237301aef478cc54a24c7188a28ab2e6"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"33bfee30277584028170135002def66f9d57732b":["360b3962efc30aa8b2c39c3087aa36069674bbe7"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["52ec154a31cf63bc47d2cc0b49e171a4e75aa99d"],"37dc4585237301aef478cc54a24c7188a28ab2e6":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"e9017cf144952056066919f1ebc7897ff9bd71b1":[],"52ec154a31cf63bc47d2cc0b49e171a4e75aa99d":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"360b3962efc30aa8b2c39c3087aa36069674bbe7":["e9017cf144952056066919f1ebc7897ff9bd71b1","52ec154a31cf63bc47d2cc0b49e171a4e75aa99d","33bfee30277584028170135002def66f9d57732b"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["e9017cf144952056066919f1ebc7897ff9bd71b1","360b3962efc30aa8b2c39c3087aa36069674bbe7","37dc4585237301aef478cc54a24c7188a28ab2e6"],"33bfee30277584028170135002def66f9d57732b":["52ec154a31cf63bc47d2cc0b49e171a4e75aa99d"],"37dc4585237301aef478cc54a24c7188a28ab2e6":["360b3962efc30aa8b2c39c3087aa36069674bbe7"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["e9017cf144952056066919f1ebc7897ff9bd71b1","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}