{"path":"solr/core/src/java/org/apache/solr/cloud/autoscaling/OverseerTriggerThread#run().mjava","commits":[{"id":"6ca81a50d0a6c6f97f1e2b15ef90c5bd81765d09","date":1492411712,"type":0,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/autoscaling/OverseerTriggerThread#run().mjava","pathOld":"/dev/null","sourceNew":"  @Override\n  public void run() {\n    int lastZnodeVersion = znodeVersion;\n    SolrZkClient zkClient = zkStateReader.getZkClient();\n    createWatcher(zkClient);\n\n    while (true) {\n      Map<String, AutoScaling.Trigger> copy = null;\n      try {\n        updateLock.lockInterruptibly();\n        if (znodeVersion == lastZnodeVersion) {\n          updated.await();\n\n          // are we closed?\n          if (isClosed) break;\n\n          // spurious wakeup?\n          if (znodeVersion == lastZnodeVersion) continue;\n          lastZnodeVersion = znodeVersion;\n        }\n        copy = new HashMap<>(activeTriggers);\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        log.warn(\"Interrupted\", e);\n        break;\n      } finally {\n        updateLock.unlock();\n      }\n\n      Set<String> managedTriggerNames = scheduledTriggers.getScheduledTriggerNames();\n      // remove the triggers which are no longer active\n      for (String managedTriggerName : managedTriggerNames) {\n        if (!copy.containsKey(managedTriggerName)) {\n          scheduledTriggers.remove(managedTriggerName);\n        }\n      }\n      // add new triggers and/or replace and close the replaced triggers\n      for (Map.Entry<String, AutoScaling.Trigger> entry : copy.entrySet()) {\n        scheduledTriggers.add(entry.getValue());\n      }\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["ea36a4664361dde6d195f6ec9e7487a621caaa69","bb222a3f9d9421d5c95afce73013fbd8de07ea1f","9c787ffd984133d984d6b651ed48f0db5347aeac"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"326b5c746af092eb827c5c1accdab1b47fe0cf3c","date":1492433195,"type":0,"author":"Noble Paul","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/cloud/autoscaling/OverseerTriggerThread#run().mjava","pathOld":"/dev/null","sourceNew":"  @Override\n  public void run() {\n    int lastZnodeVersion = znodeVersion;\n    SolrZkClient zkClient = zkStateReader.getZkClient();\n    createWatcher(zkClient);\n\n    while (true) {\n      Map<String, AutoScaling.Trigger> copy = null;\n      try {\n        updateLock.lockInterruptibly();\n        if (znodeVersion == lastZnodeVersion) {\n          updated.await();\n\n          // are we closed?\n          if (isClosed) break;\n\n          // spurious wakeup?\n          if (znodeVersion == lastZnodeVersion) continue;\n          lastZnodeVersion = znodeVersion;\n        }\n        copy = new HashMap<>(activeTriggers);\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        log.warn(\"Interrupted\", e);\n        break;\n      } finally {\n        updateLock.unlock();\n      }\n\n      Set<String> managedTriggerNames = scheduledTriggers.getScheduledTriggerNames();\n      // remove the triggers which are no longer active\n      for (String managedTriggerName : managedTriggerNames) {\n        if (!copy.containsKey(managedTriggerName)) {\n          scheduledTriggers.remove(managedTriggerName);\n        }\n      }\n      // add new triggers and/or replace and close the replaced triggers\n      for (Map.Entry<String, AutoScaling.Trigger> entry : copy.entrySet()) {\n        scheduledTriggers.add(entry.getValue());\n      }\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"263092c0f07c163d73a8be27ba212aaf7e76bd40","date":1493360294,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/autoscaling/OverseerTriggerThread#run().mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/autoscaling/OverseerTriggerThread#run().mjava","sourceNew":"  @Override\n  public void run() {\n    int lastZnodeVersion = znodeVersion;\n    SolrZkClient zkClient = zkStateReader.getZkClient();\n    createWatcher(zkClient);\n\n    while (true) {\n      Map<String, AutoScaling.Trigger> copy = null;\n      try {\n        // this can throw InterruptedException and we don't want to unlock if it did, so we keep this outside\n        // of the try/finally block\n        updateLock.lockInterruptibly();\n        try {\n          if (znodeVersion == lastZnodeVersion) {\n            updated.await();\n\n            // are we closed?\n            if (isClosed) break;\n\n            // spurious wakeup?\n            if (znodeVersion == lastZnodeVersion) continue;\n            lastZnodeVersion = znodeVersion;\n          }\n          copy = new HashMap<>(activeTriggers);\n        } catch (InterruptedException e) {\n          // Restore the interrupted status\n          Thread.currentThread().interrupt();\n          log.warn(\"Interrupted\", e);\n          break;\n        } finally {\n          updateLock.unlock();\n        }\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        log.warn(\"Interrupted\", e);\n        break;\n      }\n\n      Set<String> managedTriggerNames = scheduledTriggers.getScheduledTriggerNames();\n      // remove the triggers which are no longer active\n      for (String managedTriggerName : managedTriggerNames) {\n        if (!copy.containsKey(managedTriggerName)) {\n          scheduledTriggers.remove(managedTriggerName);\n        }\n      }\n      // add new triggers and/or replace and close the replaced triggers\n      for (Map.Entry<String, AutoScaling.Trigger> entry : copy.entrySet()) {\n        scheduledTriggers.add(entry.getValue());\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  public void run() {\n    int lastZnodeVersion = znodeVersion;\n    SolrZkClient zkClient = zkStateReader.getZkClient();\n    createWatcher(zkClient);\n\n    while (true) {\n      Map<String, AutoScaling.Trigger> copy = null;\n      try {\n        updateLock.lockInterruptibly();\n        if (znodeVersion == lastZnodeVersion) {\n          updated.await();\n\n          // are we closed?\n          if (isClosed) break;\n\n          // spurious wakeup?\n          if (znodeVersion == lastZnodeVersion) continue;\n          lastZnodeVersion = znodeVersion;\n        }\n        copy = new HashMap<>(activeTriggers);\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        log.warn(\"Interrupted\", e);\n        break;\n      } finally {\n        updateLock.unlock();\n      }\n\n      Set<String> managedTriggerNames = scheduledTriggers.getScheduledTriggerNames();\n      // remove the triggers which are no longer active\n      for (String managedTriggerName : managedTriggerNames) {\n        if (!copy.containsKey(managedTriggerName)) {\n          scheduledTriggers.remove(managedTriggerName);\n        }\n      }\n      // add new triggers and/or replace and close the replaced triggers\n      for (Map.Entry<String, AutoScaling.Trigger> entry : copy.entrySet()) {\n        scheduledTriggers.add(entry.getValue());\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":["9c787ffd984133d984d6b651ed48f0db5347aeac"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"7aa2c1715ef9a80383edea1048655da291ed9b8f","date":1495196478,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/autoscaling/OverseerTriggerThread#run().mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/autoscaling/OverseerTriggerThread#run().mjava","sourceNew":"  @Override\n  public void run() {\n    int lastZnodeVersion = znodeVersion;\n\n    try {\n      refreshAutoScalingConf(new AutoScalingWatcher());\n    } catch (KeeperException.ConnectionLossException | KeeperException.SessionExpiredException e) {\n      log.warn(\"ZooKeeper watch triggered for autoscaling conf, but Solr cannot talk to ZK: [{}]\", e.getMessage());\n    } catch (KeeperException e) {\n      log.error(\"A ZK error has occurred\", e);\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"A ZK error has occurred\", e);\n    } catch (InterruptedException e) {\n      // Restore the interrupted status\n      Thread.currentThread().interrupt();\n      log.warn(\"Interrupted\", e);\n    } catch (Exception e)  {\n      log.error(\"Unexpected exception\", e);\n    }\n\n    while (true) {\n      Map<String, AutoScaling.Trigger> copy = null;\n      try {\n        // this can throw InterruptedException and we don't want to unlock if it did, so we keep this outside\n        // of the try/finally block\n        updateLock.lockInterruptibly();\n\n        // must check for close here before we await on the condition otherwise we can only be woken up on interruption\n        if (isClosed) {\n          log.warn(\"OverseerTriggerThread has been closed, exiting.\");\n          break;\n        }\n\n        log.debug(\"Current znodeVersion {}, lastZnodeVersion {}\", znodeVersion, lastZnodeVersion);\n\n        try {\n          if (znodeVersion == lastZnodeVersion) {\n            updated.await();\n\n            // are we closed?\n            if (isClosed) {\n              log.warn(\"OverseerTriggerThread woken up but we are closed, exiting.\");\n              break;\n            }\n\n            // spurious wakeup?\n            if (znodeVersion == lastZnodeVersion) continue;\n          }\n          copy = new HashMap<>(activeTriggers);\n          lastZnodeVersion = znodeVersion;\n          log.debug(\"Processed trigger updates upto znodeVersion {}\", znodeVersion);\n        } catch (InterruptedException e) {\n          // Restore the interrupted status\n          Thread.currentThread().interrupt();\n          log.warn(\"Interrupted\", e);\n          break;\n        } finally {\n          updateLock.unlock();\n        }\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        log.warn(\"Interrupted\", e);\n        break;\n      }\n\n      Set<String> managedTriggerNames = scheduledTriggers.getScheduledTriggerNames();\n      // remove the triggers which are no longer active\n      for (String managedTriggerName : managedTriggerNames) {\n        if (!copy.containsKey(managedTriggerName)) {\n          scheduledTriggers.remove(managedTriggerName);\n        }\n      }\n      // add new triggers and/or replace and close the replaced triggers\n      for (Map.Entry<String, AutoScaling.Trigger> entry : copy.entrySet()) {\n        scheduledTriggers.add(entry.getValue());\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  public void run() {\n    int lastZnodeVersion = znodeVersion;\n    SolrZkClient zkClient = zkStateReader.getZkClient();\n    createWatcher(zkClient);\n\n    while (true) {\n      Map<String, AutoScaling.Trigger> copy = null;\n      try {\n        // this can throw InterruptedException and we don't want to unlock if it did, so we keep this outside\n        // of the try/finally block\n        updateLock.lockInterruptibly();\n        try {\n          if (znodeVersion == lastZnodeVersion) {\n            updated.await();\n\n            // are we closed?\n            if (isClosed) break;\n\n            // spurious wakeup?\n            if (znodeVersion == lastZnodeVersion) continue;\n            lastZnodeVersion = znodeVersion;\n          }\n          copy = new HashMap<>(activeTriggers);\n        } catch (InterruptedException e) {\n          // Restore the interrupted status\n          Thread.currentThread().interrupt();\n          log.warn(\"Interrupted\", e);\n          break;\n        } finally {\n          updateLock.unlock();\n        }\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        log.warn(\"Interrupted\", e);\n        break;\n      }\n\n      Set<String> managedTriggerNames = scheduledTriggers.getScheduledTriggerNames();\n      // remove the triggers which are no longer active\n      for (String managedTriggerName : managedTriggerNames) {\n        if (!copy.containsKey(managedTriggerName)) {\n          scheduledTriggers.remove(managedTriggerName);\n        }\n      }\n      // add new triggers and/or replace and close the replaced triggers\n      for (Map.Entry<String, AutoScaling.Trigger> entry : copy.entrySet()) {\n        scheduledTriggers.add(entry.getValue());\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":["bb222a3f9d9421d5c95afce73013fbd8de07ea1f","9c787ffd984133d984d6b651ed48f0db5347aeac"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"c32a8448145a74a8902798f2e63e322827757ff2","date":1496834422,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/autoscaling/OverseerTriggerThread#run().mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/autoscaling/OverseerTriggerThread#run().mjava","sourceNew":"  @Override\n  public void run() {\n    int lastZnodeVersion = znodeVersion;\n\n    try {\n      refreshAutoScalingConf(new AutoScalingWatcher());\n    } catch (KeeperException.ConnectionLossException | KeeperException.SessionExpiredException e) {\n      log.warn(\"ZooKeeper watch triggered for autoscaling conf, but Solr cannot talk to ZK: [{}]\", e.getMessage());\n    } catch (KeeperException e) {\n      log.error(\"A ZK error has occurred\", e);\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"A ZK error has occurred\", e);\n    } catch (InterruptedException e) {\n      // Restore the interrupted status\n      Thread.currentThread().interrupt();\n      log.warn(\"Interrupted\", e);\n    } catch (Exception e)  {\n      log.error(\"Unexpected exception\", e);\n    }\n\n    while (true) {\n      Map<String, AutoScaling.Trigger> copy = null;\n      try {\n        // this can throw InterruptedException and we don't want to unlock if it did, so we keep this outside\n        // of the try/finally block\n        updateLock.lockInterruptibly();\n\n        // must check for close here before we await on the condition otherwise we can only be woken up on interruption\n        if (isClosed) {\n          log.warn(\"OverseerTriggerThread has been closed, exiting.\");\n          break;\n        }\n\n        log.debug(\"Current znodeVersion {}, lastZnodeVersion {}\", znodeVersion, lastZnodeVersion);\n\n        try {\n          if (znodeVersion == lastZnodeVersion) {\n            updated.await();\n\n            // are we closed?\n            if (isClosed) {\n              log.warn(\"OverseerTriggerThread woken up but we are closed, exiting.\");\n              break;\n            }\n\n            // spurious wakeup?\n            if (znodeVersion == lastZnodeVersion) continue;\n          }\n          copy = new HashMap<>(activeTriggers);\n          lastZnodeVersion = znodeVersion;\n          log.debug(\"Processed trigger updates upto znodeVersion {}\", znodeVersion);\n        } catch (InterruptedException e) {\n          // Restore the interrupted status\n          Thread.currentThread().interrupt();\n          log.warn(\"Interrupted\", e);\n          break;\n        } finally {\n          updateLock.unlock();\n        }\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        log.warn(\"Interrupted\", e);\n        break;\n      }\n\n      Set<String> managedTriggerNames = scheduledTriggers.getScheduledTriggerNames();\n      // remove the triggers which are no longer active\n      for (String managedTriggerName : managedTriggerNames) {\n        if (!copy.containsKey(managedTriggerName)) {\n          scheduledTriggers.remove(managedTriggerName);\n        }\n      }\n      // check for nodeLost triggers in the current config, and if\n      // absent then clean up old nodeLost / nodeAdded markers\n      boolean cleanOldNodeLostMarkers = true;\n      boolean cleanOldNodeAddedMarkers = true;\n      // add new triggers and/or replace and close the replaced triggers\n      for (Map.Entry<String, AutoScaling.Trigger> entry : copy.entrySet()) {\n        if (entry.getValue().getEventType().equals(AutoScaling.EventType.NODELOST)) {\n          cleanOldNodeLostMarkers = false;\n        }\n        if (entry.getValue().getEventType().equals(AutoScaling.EventType.NODEADDED)) {\n          cleanOldNodeAddedMarkers = false;\n        }\n        scheduledTriggers.add(entry.getValue());\n      }\n      if (cleanOldNodeLostMarkers) {\n        log.debug(\"-- clean old nodeLost markers\");\n        try {\n          List<String> markers = zkClient.getChildren(ZkStateReader.SOLR_AUTOSCALING_NODE_LOST_PATH, null, true);\n          markers.forEach(n -> {\n            removeNodeMarker(ZkStateReader.SOLR_AUTOSCALING_NODE_LOST_PATH, n);\n          });\n        } catch (KeeperException.NoNodeException e) {\n          // ignore\n        } catch (KeeperException | InterruptedException e) {\n          log.warn(\"Error removing old nodeLost markers\", e);\n        }\n      }\n      if (cleanOldNodeAddedMarkers) {\n        log.debug(\"-- clean old nodeAdded markers\");\n        try {\n          List<String> markers = zkClient.getChildren(ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH, null, true);\n          markers.forEach(n -> {\n            removeNodeMarker(ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH, n);\n          });\n        } catch (KeeperException.NoNodeException e) {\n          // ignore\n        } catch (KeeperException | InterruptedException e) {\n          log.warn(\"Error removing old nodeAdded markers\", e);\n        }\n\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  public void run() {\n    int lastZnodeVersion = znodeVersion;\n\n    try {\n      refreshAutoScalingConf(new AutoScalingWatcher());\n    } catch (KeeperException.ConnectionLossException | KeeperException.SessionExpiredException e) {\n      log.warn(\"ZooKeeper watch triggered for autoscaling conf, but Solr cannot talk to ZK: [{}]\", e.getMessage());\n    } catch (KeeperException e) {\n      log.error(\"A ZK error has occurred\", e);\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"A ZK error has occurred\", e);\n    } catch (InterruptedException e) {\n      // Restore the interrupted status\n      Thread.currentThread().interrupt();\n      log.warn(\"Interrupted\", e);\n    } catch (Exception e)  {\n      log.error(\"Unexpected exception\", e);\n    }\n\n    while (true) {\n      Map<String, AutoScaling.Trigger> copy = null;\n      try {\n        // this can throw InterruptedException and we don't want to unlock if it did, so we keep this outside\n        // of the try/finally block\n        updateLock.lockInterruptibly();\n\n        // must check for close here before we await on the condition otherwise we can only be woken up on interruption\n        if (isClosed) {\n          log.warn(\"OverseerTriggerThread has been closed, exiting.\");\n          break;\n        }\n\n        log.debug(\"Current znodeVersion {}, lastZnodeVersion {}\", znodeVersion, lastZnodeVersion);\n\n        try {\n          if (znodeVersion == lastZnodeVersion) {\n            updated.await();\n\n            // are we closed?\n            if (isClosed) {\n              log.warn(\"OverseerTriggerThread woken up but we are closed, exiting.\");\n              break;\n            }\n\n            // spurious wakeup?\n            if (znodeVersion == lastZnodeVersion) continue;\n          }\n          copy = new HashMap<>(activeTriggers);\n          lastZnodeVersion = znodeVersion;\n          log.debug(\"Processed trigger updates upto znodeVersion {}\", znodeVersion);\n        } catch (InterruptedException e) {\n          // Restore the interrupted status\n          Thread.currentThread().interrupt();\n          log.warn(\"Interrupted\", e);\n          break;\n        } finally {\n          updateLock.unlock();\n        }\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        log.warn(\"Interrupted\", e);\n        break;\n      }\n\n      Set<String> managedTriggerNames = scheduledTriggers.getScheduledTriggerNames();\n      // remove the triggers which are no longer active\n      for (String managedTriggerName : managedTriggerNames) {\n        if (!copy.containsKey(managedTriggerName)) {\n          scheduledTriggers.remove(managedTriggerName);\n        }\n      }\n      // add new triggers and/or replace and close the replaced triggers\n      for (Map.Entry<String, AutoScaling.Trigger> entry : copy.entrySet()) {\n        scheduledTriggers.add(entry.getValue());\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":["ea36a4664361dde6d195f6ec9e7487a621caaa69"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"664ff2b928393480d9655010aa700656b0fcade0","date":1496842764,"type":3,"author":"Shalin Shekhar Mangar","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/cloud/autoscaling/OverseerTriggerThread#run().mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/autoscaling/OverseerTriggerThread#run().mjava","sourceNew":"  @Override\n  public void run() {\n    int lastZnodeVersion = znodeVersion;\n\n    try {\n      refreshAutoScalingConf(new AutoScalingWatcher());\n    } catch (KeeperException.ConnectionLossException | KeeperException.SessionExpiredException e) {\n      log.warn(\"ZooKeeper watch triggered for autoscaling conf, but Solr cannot talk to ZK: [{}]\", e.getMessage());\n    } catch (KeeperException e) {\n      log.error(\"A ZK error has occurred\", e);\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"A ZK error has occurred\", e);\n    } catch (InterruptedException e) {\n      // Restore the interrupted status\n      Thread.currentThread().interrupt();\n      log.warn(\"Interrupted\", e);\n    } catch (Exception e)  {\n      log.error(\"Unexpected exception\", e);\n    }\n\n    while (true) {\n      Map<String, AutoScaling.Trigger> copy = null;\n      try {\n        // this can throw InterruptedException and we don't want to unlock if it did, so we keep this outside\n        // of the try/finally block\n        updateLock.lockInterruptibly();\n\n        // must check for close here before we await on the condition otherwise we can only be woken up on interruption\n        if (isClosed) {\n          log.warn(\"OverseerTriggerThread has been closed, exiting.\");\n          break;\n        }\n\n        log.debug(\"Current znodeVersion {}, lastZnodeVersion {}\", znodeVersion, lastZnodeVersion);\n\n        try {\n          if (znodeVersion == lastZnodeVersion) {\n            updated.await();\n\n            // are we closed?\n            if (isClosed) {\n              log.warn(\"OverseerTriggerThread woken up but we are closed, exiting.\");\n              break;\n            }\n\n            // spurious wakeup?\n            if (znodeVersion == lastZnodeVersion) continue;\n          }\n          copy = new HashMap<>(activeTriggers);\n          lastZnodeVersion = znodeVersion;\n          log.debug(\"Processed trigger updates upto znodeVersion {}\", znodeVersion);\n        } catch (InterruptedException e) {\n          // Restore the interrupted status\n          Thread.currentThread().interrupt();\n          log.warn(\"Interrupted\", e);\n          break;\n        } finally {\n          updateLock.unlock();\n        }\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        log.warn(\"Interrupted\", e);\n        break;\n      }\n\n      Set<String> managedTriggerNames = scheduledTriggers.getScheduledTriggerNames();\n      // remove the triggers which are no longer active\n      for (String managedTriggerName : managedTriggerNames) {\n        if (!copy.containsKey(managedTriggerName)) {\n          scheduledTriggers.remove(managedTriggerName);\n        }\n      }\n      // check for nodeLost triggers in the current config, and if\n      // absent then clean up old nodeLost / nodeAdded markers\n      boolean cleanOldNodeLostMarkers = true;\n      boolean cleanOldNodeAddedMarkers = true;\n      // add new triggers and/or replace and close the replaced triggers\n      for (Map.Entry<String, AutoScaling.Trigger> entry : copy.entrySet()) {\n        if (entry.getValue().getEventType().equals(AutoScaling.EventType.NODELOST)) {\n          cleanOldNodeLostMarkers = false;\n        }\n        if (entry.getValue().getEventType().equals(AutoScaling.EventType.NODEADDED)) {\n          cleanOldNodeAddedMarkers = false;\n        }\n        scheduledTriggers.add(entry.getValue());\n      }\n      if (cleanOldNodeLostMarkers) {\n        log.debug(\"-- clean old nodeLost markers\");\n        try {\n          List<String> markers = zkClient.getChildren(ZkStateReader.SOLR_AUTOSCALING_NODE_LOST_PATH, null, true);\n          markers.forEach(n -> {\n            removeNodeMarker(ZkStateReader.SOLR_AUTOSCALING_NODE_LOST_PATH, n);\n          });\n        } catch (KeeperException.NoNodeException e) {\n          // ignore\n        } catch (KeeperException | InterruptedException e) {\n          log.warn(\"Error removing old nodeLost markers\", e);\n        }\n      }\n      if (cleanOldNodeAddedMarkers) {\n        log.debug(\"-- clean old nodeAdded markers\");\n        try {\n          List<String> markers = zkClient.getChildren(ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH, null, true);\n          markers.forEach(n -> {\n            removeNodeMarker(ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH, n);\n          });\n        } catch (KeeperException.NoNodeException e) {\n          // ignore\n        } catch (KeeperException | InterruptedException e) {\n          log.warn(\"Error removing old nodeAdded markers\", e);\n        }\n\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  public void run() {\n    int lastZnodeVersion = znodeVersion;\n\n    try {\n      refreshAutoScalingConf(new AutoScalingWatcher());\n    } catch (KeeperException.ConnectionLossException | KeeperException.SessionExpiredException e) {\n      log.warn(\"ZooKeeper watch triggered for autoscaling conf, but Solr cannot talk to ZK: [{}]\", e.getMessage());\n    } catch (KeeperException e) {\n      log.error(\"A ZK error has occurred\", e);\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"A ZK error has occurred\", e);\n    } catch (InterruptedException e) {\n      // Restore the interrupted status\n      Thread.currentThread().interrupt();\n      log.warn(\"Interrupted\", e);\n    } catch (Exception e)  {\n      log.error(\"Unexpected exception\", e);\n    }\n\n    while (true) {\n      Map<String, AutoScaling.Trigger> copy = null;\n      try {\n        // this can throw InterruptedException and we don't want to unlock if it did, so we keep this outside\n        // of the try/finally block\n        updateLock.lockInterruptibly();\n\n        // must check for close here before we await on the condition otherwise we can only be woken up on interruption\n        if (isClosed) {\n          log.warn(\"OverseerTriggerThread has been closed, exiting.\");\n          break;\n        }\n\n        log.debug(\"Current znodeVersion {}, lastZnodeVersion {}\", znodeVersion, lastZnodeVersion);\n\n        try {\n          if (znodeVersion == lastZnodeVersion) {\n            updated.await();\n\n            // are we closed?\n            if (isClosed) {\n              log.warn(\"OverseerTriggerThread woken up but we are closed, exiting.\");\n              break;\n            }\n\n            // spurious wakeup?\n            if (znodeVersion == lastZnodeVersion) continue;\n          }\n          copy = new HashMap<>(activeTriggers);\n          lastZnodeVersion = znodeVersion;\n          log.debug(\"Processed trigger updates upto znodeVersion {}\", znodeVersion);\n        } catch (InterruptedException e) {\n          // Restore the interrupted status\n          Thread.currentThread().interrupt();\n          log.warn(\"Interrupted\", e);\n          break;\n        } finally {\n          updateLock.unlock();\n        }\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        log.warn(\"Interrupted\", e);\n        break;\n      }\n\n      Set<String> managedTriggerNames = scheduledTriggers.getScheduledTriggerNames();\n      // remove the triggers which are no longer active\n      for (String managedTriggerName : managedTriggerNames) {\n        if (!copy.containsKey(managedTriggerName)) {\n          scheduledTriggers.remove(managedTriggerName);\n        }\n      }\n      // add new triggers and/or replace and close the replaced triggers\n      for (Map.Entry<String, AutoScaling.Trigger> entry : copy.entrySet()) {\n        scheduledTriggers.add(entry.getValue());\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"c5fd294da67452cd8d116692194908de00eb5209","date":1499704155,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/autoscaling/OverseerTriggerThread#run().mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/autoscaling/OverseerTriggerThread#run().mjava","sourceNew":"  @Override\n  public void run() {\n    int lastZnodeVersion = znodeVersion;\n\n    try {\n      refreshAutoScalingConf(new AutoScalingWatcher());\n    } catch (KeeperException.ConnectionLossException | KeeperException.SessionExpiredException e) {\n      log.warn(\"ZooKeeper watch triggered for autoscaling conf, but Solr cannot talk to ZK: [{}]\", e.getMessage());\n    } catch (KeeperException e) {\n      log.error(\"A ZK error has occurred\", e);\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"A ZK error has occurred\", e);\n    } catch (InterruptedException e) {\n      // Restore the interrupted status\n      Thread.currentThread().interrupt();\n      log.warn(\"Interrupted\", e);\n    } catch (Exception e)  {\n      log.error(\"Unexpected exception\", e);\n    }\n\n    while (true) {\n      Map<String, AutoScaling.Trigger> copy = null;\n      try {\n        // this can throw InterruptedException and we don't want to unlock if it did, so we keep this outside\n        // of the try/finally block\n        updateLock.lockInterruptibly();\n\n        // must check for close here before we await on the condition otherwise we can only be woken up on interruption\n        if (isClosed) {\n          log.warn(\"OverseerTriggerThread has been closed, exiting.\");\n          break;\n        }\n\n        log.debug(\"Current znodeVersion {}, lastZnodeVersion {}\", znodeVersion, lastZnodeVersion);\n\n        try {\n          if (znodeVersion == lastZnodeVersion) {\n            updated.await();\n\n            // are we closed?\n            if (isClosed) {\n              log.warn(\"OverseerTriggerThread woken up but we are closed, exiting.\");\n              break;\n            }\n\n            // spurious wakeup?\n            if (znodeVersion == lastZnodeVersion) continue;\n          }\n          copy = new HashMap<>(activeTriggers);\n          lastZnodeVersion = znodeVersion;\n          log.debug(\"Processed trigger updates upto znodeVersion {}\", znodeVersion);\n        } catch (InterruptedException e) {\n          // Restore the interrupted status\n          Thread.currentThread().interrupt();\n          log.warn(\"Interrupted\", e);\n          break;\n        } finally {\n          updateLock.unlock();\n        }\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        log.warn(\"Interrupted\", e);\n        break;\n      }\n\n      // update the current config\n      scheduledTriggers.setAutoScalingConfig(autoScalingConfig);\n\n      Set<String> managedTriggerNames = scheduledTriggers.getScheduledTriggerNames();\n      // remove the triggers which are no longer active\n      for (String managedTriggerName : managedTriggerNames) {\n        if (!copy.containsKey(managedTriggerName)) {\n          scheduledTriggers.remove(managedTriggerName);\n        }\n      }\n      // check for nodeLost triggers in the current config, and if\n      // absent then clean up old nodeLost / nodeAdded markers\n      boolean cleanOldNodeLostMarkers = true;\n      boolean cleanOldNodeAddedMarkers = true;\n      // add new triggers and/or replace and close the replaced triggers\n      for (Map.Entry<String, AutoScaling.Trigger> entry : copy.entrySet()) {\n        if (entry.getValue().getEventType().equals(AutoScaling.EventType.NODELOST)) {\n          cleanOldNodeLostMarkers = false;\n        }\n        if (entry.getValue().getEventType().equals(AutoScaling.EventType.NODEADDED)) {\n          cleanOldNodeAddedMarkers = false;\n        }\n        scheduledTriggers.add(entry.getValue());\n      }\n      if (cleanOldNodeLostMarkers) {\n        log.debug(\"-- clean old nodeLost markers\");\n        try {\n          List<String> markers = zkClient.getChildren(ZkStateReader.SOLR_AUTOSCALING_NODE_LOST_PATH, null, true);\n          markers.forEach(n -> {\n            removeNodeMarker(ZkStateReader.SOLR_AUTOSCALING_NODE_LOST_PATH, n);\n          });\n        } catch (KeeperException.NoNodeException e) {\n          // ignore\n        } catch (KeeperException | InterruptedException e) {\n          log.warn(\"Error removing old nodeLost markers\", e);\n        }\n      }\n      if (cleanOldNodeAddedMarkers) {\n        log.debug(\"-- clean old nodeAdded markers\");\n        try {\n          List<String> markers = zkClient.getChildren(ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH, null, true);\n          markers.forEach(n -> {\n            removeNodeMarker(ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH, n);\n          });\n        } catch (KeeperException.NoNodeException e) {\n          // ignore\n        } catch (KeeperException | InterruptedException e) {\n          log.warn(\"Error removing old nodeAdded markers\", e);\n        }\n\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  public void run() {\n    int lastZnodeVersion = znodeVersion;\n\n    try {\n      refreshAutoScalingConf(new AutoScalingWatcher());\n    } catch (KeeperException.ConnectionLossException | KeeperException.SessionExpiredException e) {\n      log.warn(\"ZooKeeper watch triggered for autoscaling conf, but Solr cannot talk to ZK: [{}]\", e.getMessage());\n    } catch (KeeperException e) {\n      log.error(\"A ZK error has occurred\", e);\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"A ZK error has occurred\", e);\n    } catch (InterruptedException e) {\n      // Restore the interrupted status\n      Thread.currentThread().interrupt();\n      log.warn(\"Interrupted\", e);\n    } catch (Exception e)  {\n      log.error(\"Unexpected exception\", e);\n    }\n\n    while (true) {\n      Map<String, AutoScaling.Trigger> copy = null;\n      try {\n        // this can throw InterruptedException and we don't want to unlock if it did, so we keep this outside\n        // of the try/finally block\n        updateLock.lockInterruptibly();\n\n        // must check for close here before we await on the condition otherwise we can only be woken up on interruption\n        if (isClosed) {\n          log.warn(\"OverseerTriggerThread has been closed, exiting.\");\n          break;\n        }\n\n        log.debug(\"Current znodeVersion {}, lastZnodeVersion {}\", znodeVersion, lastZnodeVersion);\n\n        try {\n          if (znodeVersion == lastZnodeVersion) {\n            updated.await();\n\n            // are we closed?\n            if (isClosed) {\n              log.warn(\"OverseerTriggerThread woken up but we are closed, exiting.\");\n              break;\n            }\n\n            // spurious wakeup?\n            if (znodeVersion == lastZnodeVersion) continue;\n          }\n          copy = new HashMap<>(activeTriggers);\n          lastZnodeVersion = znodeVersion;\n          log.debug(\"Processed trigger updates upto znodeVersion {}\", znodeVersion);\n        } catch (InterruptedException e) {\n          // Restore the interrupted status\n          Thread.currentThread().interrupt();\n          log.warn(\"Interrupted\", e);\n          break;\n        } finally {\n          updateLock.unlock();\n        }\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        log.warn(\"Interrupted\", e);\n        break;\n      }\n\n      Set<String> managedTriggerNames = scheduledTriggers.getScheduledTriggerNames();\n      // remove the triggers which are no longer active\n      for (String managedTriggerName : managedTriggerNames) {\n        if (!copy.containsKey(managedTriggerName)) {\n          scheduledTriggers.remove(managedTriggerName);\n        }\n      }\n      // check for nodeLost triggers in the current config, and if\n      // absent then clean up old nodeLost / nodeAdded markers\n      boolean cleanOldNodeLostMarkers = true;\n      boolean cleanOldNodeAddedMarkers = true;\n      // add new triggers and/or replace and close the replaced triggers\n      for (Map.Entry<String, AutoScaling.Trigger> entry : copy.entrySet()) {\n        if (entry.getValue().getEventType().equals(AutoScaling.EventType.NODELOST)) {\n          cleanOldNodeLostMarkers = false;\n        }\n        if (entry.getValue().getEventType().equals(AutoScaling.EventType.NODEADDED)) {\n          cleanOldNodeAddedMarkers = false;\n        }\n        scheduledTriggers.add(entry.getValue());\n      }\n      if (cleanOldNodeLostMarkers) {\n        log.debug(\"-- clean old nodeLost markers\");\n        try {\n          List<String> markers = zkClient.getChildren(ZkStateReader.SOLR_AUTOSCALING_NODE_LOST_PATH, null, true);\n          markers.forEach(n -> {\n            removeNodeMarker(ZkStateReader.SOLR_AUTOSCALING_NODE_LOST_PATH, n);\n          });\n        } catch (KeeperException.NoNodeException e) {\n          // ignore\n        } catch (KeeperException | InterruptedException e) {\n          log.warn(\"Error removing old nodeLost markers\", e);\n        }\n      }\n      if (cleanOldNodeAddedMarkers) {\n        log.debug(\"-- clean old nodeAdded markers\");\n        try {\n          List<String> markers = zkClient.getChildren(ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH, null, true);\n          markers.forEach(n -> {\n            removeNodeMarker(ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH, n);\n          });\n        } catch (KeeperException.NoNodeException e) {\n          // ignore\n        } catch (KeeperException | InterruptedException e) {\n          log.warn(\"Error removing old nodeAdded markers\", e);\n        }\n\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"219ac4e012cb38bcfcd8f4290dccd4f5b4d7bc25","date":1499961129,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/autoscaling/OverseerTriggerThread#run().mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/autoscaling/OverseerTriggerThread#run().mjava","sourceNew":"  @Override\n  public void run() {\n    int lastZnodeVersion = znodeVersion;\n\n    try {\n      refreshAutoScalingConf(new AutoScalingWatcher());\n    } catch (KeeperException.ConnectionLossException | KeeperException.SessionExpiredException e) {\n      log.warn(\"ZooKeeper watch triggered for autoscaling conf, but Solr cannot talk to ZK: [{}]\", e.getMessage());\n    } catch (KeeperException e) {\n      log.error(\"A ZK error has occurred\", e);\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"A ZK error has occurred\", e);\n    } catch (InterruptedException e) {\n      // Restore the interrupted status\n      Thread.currentThread().interrupt();\n      log.warn(\"Interrupted\", e);\n    } catch (Exception e)  {\n      log.error(\"Unexpected exception\", e);\n    }\n\n    while (true) {\n      Map<String, AutoScaling.Trigger> copy = null;\n      try {\n        // this can throw InterruptedException and we don't want to unlock if it did, so we keep this outside\n        // of the try/finally block\n        updateLock.lockInterruptibly();\n\n        // must check for close here before we await on the condition otherwise we can only be woken up on interruption\n        if (isClosed) {\n          log.warn(\"OverseerTriggerThread has been closed, exiting.\");\n          break;\n        }\n\n        log.debug(\"Current znodeVersion {}, lastZnodeVersion {}\", znodeVersion, lastZnodeVersion);\n\n        try {\n          if (znodeVersion == lastZnodeVersion) {\n            updated.await();\n\n            // are we closed?\n            if (isClosed) {\n              log.warn(\"OverseerTriggerThread woken up but we are closed, exiting.\");\n              break;\n            }\n\n            // spurious wakeup?\n            if (znodeVersion == lastZnodeVersion) continue;\n          }\n          copy = new HashMap<>(activeTriggers);\n          lastZnodeVersion = znodeVersion;\n          log.debug(\"Processed trigger updates upto znodeVersion {}\", znodeVersion);\n        } catch (InterruptedException e) {\n          // Restore the interrupted status\n          Thread.currentThread().interrupt();\n          log.warn(\"Interrupted\", e);\n          break;\n        } finally {\n          updateLock.unlock();\n        }\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        log.warn(\"Interrupted\", e);\n        break;\n      }\n\n      // update the current config\n      scheduledTriggers.setAutoScalingConfig(autoScalingConfig);\n\n      Set<String> managedTriggerNames = scheduledTriggers.getScheduledTriggerNames();\n      // remove the triggers which are no longer active\n      for (String managedTriggerName : managedTriggerNames) {\n        if (!copy.containsKey(managedTriggerName)) {\n          scheduledTriggers.remove(managedTriggerName);\n        }\n      }\n      // check for nodeLost triggers in the current config, and if\n      // absent then clean up old nodeLost / nodeAdded markers\n      boolean cleanOldNodeLostMarkers = true;\n      boolean cleanOldNodeAddedMarkers = true;\n      // add new triggers and/or replace and close the replaced triggers\n      for (Map.Entry<String, AutoScaling.Trigger> entry : copy.entrySet()) {\n        if (entry.getValue().getEventType().equals(TriggerEventType.NODELOST)) {\n          cleanOldNodeLostMarkers = false;\n        }\n        if (entry.getValue().getEventType().equals(TriggerEventType.NODEADDED)) {\n          cleanOldNodeAddedMarkers = false;\n        }\n        scheduledTriggers.add(entry.getValue());\n      }\n      if (cleanOldNodeLostMarkers) {\n        log.debug(\"-- clean old nodeLost markers\");\n        try {\n          List<String> markers = zkClient.getChildren(ZkStateReader.SOLR_AUTOSCALING_NODE_LOST_PATH, null, true);\n          markers.forEach(n -> {\n            removeNodeMarker(ZkStateReader.SOLR_AUTOSCALING_NODE_LOST_PATH, n);\n          });\n        } catch (KeeperException.NoNodeException e) {\n          // ignore\n        } catch (KeeperException | InterruptedException e) {\n          log.warn(\"Error removing old nodeLost markers\", e);\n        }\n      }\n      if (cleanOldNodeAddedMarkers) {\n        log.debug(\"-- clean old nodeAdded markers\");\n        try {\n          List<String> markers = zkClient.getChildren(ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH, null, true);\n          markers.forEach(n -> {\n            removeNodeMarker(ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH, n);\n          });\n        } catch (KeeperException.NoNodeException e) {\n          // ignore\n        } catch (KeeperException | InterruptedException e) {\n          log.warn(\"Error removing old nodeAdded markers\", e);\n        }\n\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  public void run() {\n    int lastZnodeVersion = znodeVersion;\n\n    try {\n      refreshAutoScalingConf(new AutoScalingWatcher());\n    } catch (KeeperException.ConnectionLossException | KeeperException.SessionExpiredException e) {\n      log.warn(\"ZooKeeper watch triggered for autoscaling conf, but Solr cannot talk to ZK: [{}]\", e.getMessage());\n    } catch (KeeperException e) {\n      log.error(\"A ZK error has occurred\", e);\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"A ZK error has occurred\", e);\n    } catch (InterruptedException e) {\n      // Restore the interrupted status\n      Thread.currentThread().interrupt();\n      log.warn(\"Interrupted\", e);\n    } catch (Exception e)  {\n      log.error(\"Unexpected exception\", e);\n    }\n\n    while (true) {\n      Map<String, AutoScaling.Trigger> copy = null;\n      try {\n        // this can throw InterruptedException and we don't want to unlock if it did, so we keep this outside\n        // of the try/finally block\n        updateLock.lockInterruptibly();\n\n        // must check for close here before we await on the condition otherwise we can only be woken up on interruption\n        if (isClosed) {\n          log.warn(\"OverseerTriggerThread has been closed, exiting.\");\n          break;\n        }\n\n        log.debug(\"Current znodeVersion {}, lastZnodeVersion {}\", znodeVersion, lastZnodeVersion);\n\n        try {\n          if (znodeVersion == lastZnodeVersion) {\n            updated.await();\n\n            // are we closed?\n            if (isClosed) {\n              log.warn(\"OverseerTriggerThread woken up but we are closed, exiting.\");\n              break;\n            }\n\n            // spurious wakeup?\n            if (znodeVersion == lastZnodeVersion) continue;\n          }\n          copy = new HashMap<>(activeTriggers);\n          lastZnodeVersion = znodeVersion;\n          log.debug(\"Processed trigger updates upto znodeVersion {}\", znodeVersion);\n        } catch (InterruptedException e) {\n          // Restore the interrupted status\n          Thread.currentThread().interrupt();\n          log.warn(\"Interrupted\", e);\n          break;\n        } finally {\n          updateLock.unlock();\n        }\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        log.warn(\"Interrupted\", e);\n        break;\n      }\n\n      // update the current config\n      scheduledTriggers.setAutoScalingConfig(autoScalingConfig);\n\n      Set<String> managedTriggerNames = scheduledTriggers.getScheduledTriggerNames();\n      // remove the triggers which are no longer active\n      for (String managedTriggerName : managedTriggerNames) {\n        if (!copy.containsKey(managedTriggerName)) {\n          scheduledTriggers.remove(managedTriggerName);\n        }\n      }\n      // check for nodeLost triggers in the current config, and if\n      // absent then clean up old nodeLost / nodeAdded markers\n      boolean cleanOldNodeLostMarkers = true;\n      boolean cleanOldNodeAddedMarkers = true;\n      // add new triggers and/or replace and close the replaced triggers\n      for (Map.Entry<String, AutoScaling.Trigger> entry : copy.entrySet()) {\n        if (entry.getValue().getEventType().equals(AutoScaling.EventType.NODELOST)) {\n          cleanOldNodeLostMarkers = false;\n        }\n        if (entry.getValue().getEventType().equals(AutoScaling.EventType.NODEADDED)) {\n          cleanOldNodeAddedMarkers = false;\n        }\n        scheduledTriggers.add(entry.getValue());\n      }\n      if (cleanOldNodeLostMarkers) {\n        log.debug(\"-- clean old nodeLost markers\");\n        try {\n          List<String> markers = zkClient.getChildren(ZkStateReader.SOLR_AUTOSCALING_NODE_LOST_PATH, null, true);\n          markers.forEach(n -> {\n            removeNodeMarker(ZkStateReader.SOLR_AUTOSCALING_NODE_LOST_PATH, n);\n          });\n        } catch (KeeperException.NoNodeException e) {\n          // ignore\n        } catch (KeeperException | InterruptedException e) {\n          log.warn(\"Error removing old nodeLost markers\", e);\n        }\n      }\n      if (cleanOldNodeAddedMarkers) {\n        log.debug(\"-- clean old nodeAdded markers\");\n        try {\n          List<String> markers = zkClient.getChildren(ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH, null, true);\n          markers.forEach(n -> {\n            removeNodeMarker(ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH, n);\n          });\n        } catch (KeeperException.NoNodeException e) {\n          // ignore\n        } catch (KeeperException | InterruptedException e) {\n          log.warn(\"Error removing old nodeAdded markers\", e);\n        }\n\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":["ea36a4664361dde6d195f6ec9e7487a621caaa69"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"ea36a4664361dde6d195f6ec9e7487a621caaa69","date":1501534945,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/autoscaling/OverseerTriggerThread#run().mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/autoscaling/OverseerTriggerThread#run().mjava","sourceNew":"  @Override\n  public void run() {\n    int lastZnodeVersion = znodeVersion;\n\n    try {\n      refreshAutoScalingConf(new AutoScalingWatcher());\n    } catch (KeeperException.ConnectionLossException | KeeperException.SessionExpiredException e) {\n      log.warn(\"ZooKeeper watch triggered for autoscaling conf, but Solr cannot talk to ZK: [{}]\", e.getMessage());\n    } catch (KeeperException e) {\n      log.error(\"A ZK error has occurred\", e);\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"A ZK error has occurred\", e);\n    } catch (InterruptedException e) {\n      // Restore the interrupted status\n      Thread.currentThread().interrupt();\n      log.warn(\"Interrupted\", e);\n    } catch (Exception e)  {\n      log.error(\"Unexpected exception\", e);\n    }\n\n    while (true) {\n      Map<String, AutoScaling.Trigger> copy = null;\n      try {\n        // this can throw InterruptedException and we don't want to unlock if it did, so we keep this outside\n        // of the try/finally block\n        updateLock.lockInterruptibly();\n\n        // must check for close here before we await on the condition otherwise we can only be woken up on interruption\n        if (isClosed) {\n          log.warn(\"OverseerTriggerThread has been closed, exiting.\");\n          break;\n        }\n\n        log.debug(\"Current znodeVersion {}, lastZnodeVersion {}\", znodeVersion, lastZnodeVersion);\n\n        try {\n          if (znodeVersion == lastZnodeVersion) {\n            updated.await();\n\n            // are we closed?\n            if (isClosed) {\n              log.warn(\"OverseerTriggerThread woken up but we are closed, exiting.\");\n              break;\n            }\n\n            // spurious wakeup?\n            if (znodeVersion == lastZnodeVersion) continue;\n          }\n          copy = new HashMap<>(activeTriggers);\n          lastZnodeVersion = znodeVersion;\n          log.debug(\"Processed trigger updates upto znodeVersion {}\", znodeVersion);\n        } catch (InterruptedException e) {\n          // Restore the interrupted status\n          Thread.currentThread().interrupt();\n          log.warn(\"Interrupted\", e);\n          break;\n        } finally {\n          updateLock.unlock();\n        }\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        log.warn(\"Interrupted\", e);\n        break;\n      }\n\n      // update the current config\n      scheduledTriggers.setAutoScalingConfig(autoScalingConfig);\n\n      Set<String> managedTriggerNames = scheduledTriggers.getScheduledTriggerNames();\n      // remove the triggers which are no longer active\n      for (String managedTriggerName : managedTriggerNames) {\n        if (!copy.containsKey(managedTriggerName)) {\n          scheduledTriggers.remove(managedTriggerName);\n        }\n      }\n      // check for nodeLost triggers in the current config, and if\n      // absent then clean up old nodeLost / nodeAdded markers\n      boolean cleanOldNodeLostMarkers = true;\n      boolean cleanOldNodeAddedMarkers = true;\n      try {\n        // add new triggers and/or replace and close the replaced triggers\n        for (Map.Entry<String, AutoScaling.Trigger> entry : copy.entrySet()) {\n          if (entry.getValue().getEventType().equals(TriggerEventType.NODELOST)) {\n            cleanOldNodeLostMarkers = false;\n          }\n          if (entry.getValue().getEventType().equals(TriggerEventType.NODEADDED)) {\n            cleanOldNodeAddedMarkers = false;\n          }\n          scheduledTriggers.add(entry.getValue());\n        }\n      } catch (AlreadyClosedException e) {\n        // this _should_ mean that we're closing, complain loudly if that's not the case\n        if (isClosed) {\n          return;\n        } else {\n          throw new IllegalStateException(\"Caught AlreadyClosedException from ScheduledTriggers, but we're not closed yet!\", e);\n        }\n      }\n      if (cleanOldNodeLostMarkers) {\n        log.debug(\"-- clean old nodeLost markers\");\n        try {\n          List<String> markers = zkClient.getChildren(ZkStateReader.SOLR_AUTOSCALING_NODE_LOST_PATH, null, true);\n          markers.forEach(n -> {\n            removeNodeMarker(ZkStateReader.SOLR_AUTOSCALING_NODE_LOST_PATH, n);\n          });\n        } catch (KeeperException.NoNodeException e) {\n          // ignore\n        } catch (KeeperException | InterruptedException e) {\n          log.warn(\"Error removing old nodeLost markers\", e);\n        }\n      }\n      if (cleanOldNodeAddedMarkers) {\n        log.debug(\"-- clean old nodeAdded markers\");\n        try {\n          List<String> markers = zkClient.getChildren(ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH, null, true);\n          markers.forEach(n -> {\n            removeNodeMarker(ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH, n);\n          });\n        } catch (KeeperException.NoNodeException e) {\n          // ignore\n        } catch (KeeperException | InterruptedException e) {\n          log.warn(\"Error removing old nodeAdded markers\", e);\n        }\n\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  public void run() {\n    int lastZnodeVersion = znodeVersion;\n\n    try {\n      refreshAutoScalingConf(new AutoScalingWatcher());\n    } catch (KeeperException.ConnectionLossException | KeeperException.SessionExpiredException e) {\n      log.warn(\"ZooKeeper watch triggered for autoscaling conf, but Solr cannot talk to ZK: [{}]\", e.getMessage());\n    } catch (KeeperException e) {\n      log.error(\"A ZK error has occurred\", e);\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"A ZK error has occurred\", e);\n    } catch (InterruptedException e) {\n      // Restore the interrupted status\n      Thread.currentThread().interrupt();\n      log.warn(\"Interrupted\", e);\n    } catch (Exception e)  {\n      log.error(\"Unexpected exception\", e);\n    }\n\n    while (true) {\n      Map<String, AutoScaling.Trigger> copy = null;\n      try {\n        // this can throw InterruptedException and we don't want to unlock if it did, so we keep this outside\n        // of the try/finally block\n        updateLock.lockInterruptibly();\n\n        // must check for close here before we await on the condition otherwise we can only be woken up on interruption\n        if (isClosed) {\n          log.warn(\"OverseerTriggerThread has been closed, exiting.\");\n          break;\n        }\n\n        log.debug(\"Current znodeVersion {}, lastZnodeVersion {}\", znodeVersion, lastZnodeVersion);\n\n        try {\n          if (znodeVersion == lastZnodeVersion) {\n            updated.await();\n\n            // are we closed?\n            if (isClosed) {\n              log.warn(\"OverseerTriggerThread woken up but we are closed, exiting.\");\n              break;\n            }\n\n            // spurious wakeup?\n            if (znodeVersion == lastZnodeVersion) continue;\n          }\n          copy = new HashMap<>(activeTriggers);\n          lastZnodeVersion = znodeVersion;\n          log.debug(\"Processed trigger updates upto znodeVersion {}\", znodeVersion);\n        } catch (InterruptedException e) {\n          // Restore the interrupted status\n          Thread.currentThread().interrupt();\n          log.warn(\"Interrupted\", e);\n          break;\n        } finally {\n          updateLock.unlock();\n        }\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        log.warn(\"Interrupted\", e);\n        break;\n      }\n\n      // update the current config\n      scheduledTriggers.setAutoScalingConfig(autoScalingConfig);\n\n      Set<String> managedTriggerNames = scheduledTriggers.getScheduledTriggerNames();\n      // remove the triggers which are no longer active\n      for (String managedTriggerName : managedTriggerNames) {\n        if (!copy.containsKey(managedTriggerName)) {\n          scheduledTriggers.remove(managedTriggerName);\n        }\n      }\n      // check for nodeLost triggers in the current config, and if\n      // absent then clean up old nodeLost / nodeAdded markers\n      boolean cleanOldNodeLostMarkers = true;\n      boolean cleanOldNodeAddedMarkers = true;\n      // add new triggers and/or replace and close the replaced triggers\n      for (Map.Entry<String, AutoScaling.Trigger> entry : copy.entrySet()) {\n        if (entry.getValue().getEventType().equals(TriggerEventType.NODELOST)) {\n          cleanOldNodeLostMarkers = false;\n        }\n        if (entry.getValue().getEventType().equals(TriggerEventType.NODEADDED)) {\n          cleanOldNodeAddedMarkers = false;\n        }\n        scheduledTriggers.add(entry.getValue());\n      }\n      if (cleanOldNodeLostMarkers) {\n        log.debug(\"-- clean old nodeLost markers\");\n        try {\n          List<String> markers = zkClient.getChildren(ZkStateReader.SOLR_AUTOSCALING_NODE_LOST_PATH, null, true);\n          markers.forEach(n -> {\n            removeNodeMarker(ZkStateReader.SOLR_AUTOSCALING_NODE_LOST_PATH, n);\n          });\n        } catch (KeeperException.NoNodeException e) {\n          // ignore\n        } catch (KeeperException | InterruptedException e) {\n          log.warn(\"Error removing old nodeLost markers\", e);\n        }\n      }\n      if (cleanOldNodeAddedMarkers) {\n        log.debug(\"-- clean old nodeAdded markers\");\n        try {\n          List<String> markers = zkClient.getChildren(ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH, null, true);\n          markers.forEach(n -> {\n            removeNodeMarker(ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH, n);\n          });\n        } catch (KeeperException.NoNodeException e) {\n          // ignore\n        } catch (KeeperException | InterruptedException e) {\n          log.warn(\"Error removing old nodeAdded markers\", e);\n        }\n\n      }\n    }\n  }\n\n","bugFix":["c32a8448145a74a8902798f2e63e322827757ff2","219ac4e012cb38bcfcd8f4290dccd4f5b4d7bc25","6ca81a50d0a6c6f97f1e2b15ef90c5bd81765d09"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"c7ff8a6fbdc9c2d84bc6e9e71e1c738e49c441ac","date":1503580177,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/autoscaling/OverseerTriggerThread#run().mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/autoscaling/OverseerTriggerThread#run().mjava","sourceNew":"  @Override\n  public void run() {\n    int lastZnodeVersion = znodeVersion;\n\n    try {\n      refreshAutoScalingConf(new AutoScalingWatcher());\n    } catch (ConnectException e) {\n      log.warn(\"ZooKeeper watch triggered for autoscaling conf, but Solr cannot talk to ZK: [{}]\", e.getMessage());\n    } catch (InterruptedException e) {\n      // Restore the interrupted status\n      Thread.currentThread().interrupt();\n      log.warn(\"Interrupted\", e);\n    } catch (Exception e)  {\n      log.error(\"Unexpected exception\", e);\n    }\n\n    while (true) {\n      Map<String, AutoScaling.Trigger> copy = null;\n      try {\n        // this can throw InterruptedException and we don't want to unlock if it did, so we keep this outside\n        // of the try/finally block\n        updateLock.lockInterruptibly();\n\n        // must check for close here before we await on the condition otherwise we can only be woken up on interruption\n        if (isClosed) {\n          log.warn(\"OverseerTriggerThread has been closed, exiting.\");\n          break;\n        }\n\n        log.debug(\"Current znodeVersion {}, lastZnodeVersion {}\", znodeVersion, lastZnodeVersion);\n\n        try {\n          if (znodeVersion == lastZnodeVersion) {\n            updated.await();\n\n            // are we closed?\n            if (isClosed) {\n              log.warn(\"OverseerTriggerThread woken up but we are closed, exiting.\");\n              break;\n            }\n\n            // spurious wakeup?\n            if (znodeVersion == lastZnodeVersion) continue;\n          }\n          copy = new HashMap<>(activeTriggers);\n          lastZnodeVersion = znodeVersion;\n          log.debug(\"Processed trigger updates upto znodeVersion {}\", znodeVersion);\n        } catch (InterruptedException e) {\n          // Restore the interrupted status\n          Thread.currentThread().interrupt();\n          log.warn(\"Interrupted\", e);\n          break;\n        } finally {\n          updateLock.unlock();\n        }\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        log.warn(\"Interrupted\", e);\n        break;\n      }\n\n      // update the current config\n      scheduledTriggers.setAutoScalingConfig(autoScalingConfig);\n\n      Set<String> managedTriggerNames = scheduledTriggers.getScheduledTriggerNames();\n      // remove the triggers which are no longer active\n      for (String managedTriggerName : managedTriggerNames) {\n        if (!copy.containsKey(managedTriggerName)) {\n          scheduledTriggers.remove(managedTriggerName);\n        }\n      }\n      // check for nodeLost triggers in the current config, and if\n      // absent then clean up old nodeLost / nodeAdded markers\n      boolean cleanOldNodeLostMarkers = true;\n      boolean cleanOldNodeAddedMarkers = true;\n      try {\n        // add new triggers and/or replace and close the replaced triggers\n        for (Map.Entry<String, AutoScaling.Trigger> entry : copy.entrySet()) {\n          if (entry.getValue().getEventType().equals(TriggerEventType.NODELOST)) {\n            cleanOldNodeLostMarkers = false;\n          }\n          if (entry.getValue().getEventType().equals(TriggerEventType.NODEADDED)) {\n            cleanOldNodeAddedMarkers = false;\n          }\n          scheduledTriggers.add(entry.getValue());\n        }\n      } catch (AlreadyClosedException e) {\n        // this _should_ mean that we're closing, complain loudly if that's not the case\n        if (isClosed) {\n          return;\n        } else {\n          throw new IllegalStateException(\"Caught AlreadyClosedException from ScheduledTriggers, but we're not closed yet!\", e);\n        }\n      }\n      if (cleanOldNodeLostMarkers) {\n        log.debug(\"-- clean old nodeLost markers\");\n        try {\n          List<String> markers = clusterDataProvider.listData(ZkStateReader.SOLR_AUTOSCALING_NODE_LOST_PATH);\n          markers.forEach(n -> {\n            removeNodeMarker(ZkStateReader.SOLR_AUTOSCALING_NODE_LOST_PATH, n);\n          });\n        } catch (NoSuchElementException e) {\n          // ignore\n        } catch (Exception e) {\n          log.warn(\"Error removing old nodeLost markers\", e);\n        }\n      }\n      if (cleanOldNodeAddedMarkers) {\n        log.debug(\"-- clean old nodeAdded markers\");\n        try {\n          List<String> markers = clusterDataProvider.listData(ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH);\n          markers.forEach(n -> {\n            removeNodeMarker(ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH, n);\n          });\n        } catch (NoSuchElementException e) {\n          // ignore\n        } catch (Exception e) {\n          log.warn(\"Error removing old nodeAdded markers\", e);\n        }\n\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  public void run() {\n    int lastZnodeVersion = znodeVersion;\n\n    try {\n      refreshAutoScalingConf(new AutoScalingWatcher());\n    } catch (KeeperException.ConnectionLossException | KeeperException.SessionExpiredException e) {\n      log.warn(\"ZooKeeper watch triggered for autoscaling conf, but Solr cannot talk to ZK: [{}]\", e.getMessage());\n    } catch (KeeperException e) {\n      log.error(\"A ZK error has occurred\", e);\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"A ZK error has occurred\", e);\n    } catch (InterruptedException e) {\n      // Restore the interrupted status\n      Thread.currentThread().interrupt();\n      log.warn(\"Interrupted\", e);\n    } catch (Exception e)  {\n      log.error(\"Unexpected exception\", e);\n    }\n\n    while (true) {\n      Map<String, AutoScaling.Trigger> copy = null;\n      try {\n        // this can throw InterruptedException and we don't want to unlock if it did, so we keep this outside\n        // of the try/finally block\n        updateLock.lockInterruptibly();\n\n        // must check for close here before we await on the condition otherwise we can only be woken up on interruption\n        if (isClosed) {\n          log.warn(\"OverseerTriggerThread has been closed, exiting.\");\n          break;\n        }\n\n        log.debug(\"Current znodeVersion {}, lastZnodeVersion {}\", znodeVersion, lastZnodeVersion);\n\n        try {\n          if (znodeVersion == lastZnodeVersion) {\n            updated.await();\n\n            // are we closed?\n            if (isClosed) {\n              log.warn(\"OverseerTriggerThread woken up but we are closed, exiting.\");\n              break;\n            }\n\n            // spurious wakeup?\n            if (znodeVersion == lastZnodeVersion) continue;\n          }\n          copy = new HashMap<>(activeTriggers);\n          lastZnodeVersion = znodeVersion;\n          log.debug(\"Processed trigger updates upto znodeVersion {}\", znodeVersion);\n        } catch (InterruptedException e) {\n          // Restore the interrupted status\n          Thread.currentThread().interrupt();\n          log.warn(\"Interrupted\", e);\n          break;\n        } finally {\n          updateLock.unlock();\n        }\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        log.warn(\"Interrupted\", e);\n        break;\n      }\n\n      // update the current config\n      scheduledTriggers.setAutoScalingConfig(autoScalingConfig);\n\n      Set<String> managedTriggerNames = scheduledTriggers.getScheduledTriggerNames();\n      // remove the triggers which are no longer active\n      for (String managedTriggerName : managedTriggerNames) {\n        if (!copy.containsKey(managedTriggerName)) {\n          scheduledTriggers.remove(managedTriggerName);\n        }\n      }\n      // check for nodeLost triggers in the current config, and if\n      // absent then clean up old nodeLost / nodeAdded markers\n      boolean cleanOldNodeLostMarkers = true;\n      boolean cleanOldNodeAddedMarkers = true;\n      try {\n        // add new triggers and/or replace and close the replaced triggers\n        for (Map.Entry<String, AutoScaling.Trigger> entry : copy.entrySet()) {\n          if (entry.getValue().getEventType().equals(TriggerEventType.NODELOST)) {\n            cleanOldNodeLostMarkers = false;\n          }\n          if (entry.getValue().getEventType().equals(TriggerEventType.NODEADDED)) {\n            cleanOldNodeAddedMarkers = false;\n          }\n          scheduledTriggers.add(entry.getValue());\n        }\n      } catch (AlreadyClosedException e) {\n        // this _should_ mean that we're closing, complain loudly if that's not the case\n        if (isClosed) {\n          return;\n        } else {\n          throw new IllegalStateException(\"Caught AlreadyClosedException from ScheduledTriggers, but we're not closed yet!\", e);\n        }\n      }\n      if (cleanOldNodeLostMarkers) {\n        log.debug(\"-- clean old nodeLost markers\");\n        try {\n          List<String> markers = zkClient.getChildren(ZkStateReader.SOLR_AUTOSCALING_NODE_LOST_PATH, null, true);\n          markers.forEach(n -> {\n            removeNodeMarker(ZkStateReader.SOLR_AUTOSCALING_NODE_LOST_PATH, n);\n          });\n        } catch (KeeperException.NoNodeException e) {\n          // ignore\n        } catch (KeeperException | InterruptedException e) {\n          log.warn(\"Error removing old nodeLost markers\", e);\n        }\n      }\n      if (cleanOldNodeAddedMarkers) {\n        log.debug(\"-- clean old nodeAdded markers\");\n        try {\n          List<String> markers = zkClient.getChildren(ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH, null, true);\n          markers.forEach(n -> {\n            removeNodeMarker(ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH, n);\n          });\n        } catch (KeeperException.NoNodeException e) {\n          // ignore\n        } catch (KeeperException | InterruptedException e) {\n          log.warn(\"Error removing old nodeAdded markers\", e);\n        }\n\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b869898f50ca80263bac2e3ae0949f7700e5c977","date":1503580229,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/autoscaling/OverseerTriggerThread#run().mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/autoscaling/OverseerTriggerThread#run().mjava","sourceNew":"  @Override\n  public void run() {\n    int lastZnodeVersion = znodeVersion;\n\n    try {\n      refreshAutoScalingConf(new AutoScalingWatcher());\n    } catch (KeeperException.ConnectionLossException | KeeperException.SessionExpiredException e) {\n      log.warn(\"ZooKeeper watch triggered for autoscaling conf, but Solr cannot talk to ZK: [{}]\", e.getMessage());\n    } catch (KeeperException e) {\n      log.error(\"A ZK error has occurred\", e);\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"A ZK error has occurred\", e);\n    } catch (InterruptedException e) {\n      // Restore the interrupted status\n      Thread.currentThread().interrupt();\n      log.warn(\"Interrupted\", e);\n    } catch (Exception e)  {\n      log.error(\"Unexpected exception\", e);\n    }\n\n    while (true) {\n      Map<String, AutoScaling.Trigger> copy = null;\n      try {\n        // this can throw InterruptedException and we don't want to unlock if it did, so we keep this outside\n        // of the try/finally block\n        updateLock.lockInterruptibly();\n\n        // must check for close here before we await on the condition otherwise we can only be woken up on interruption\n        if (isClosed) {\n          log.warn(\"OverseerTriggerThread has been closed, exiting.\");\n          break;\n        }\n\n        log.debug(\"Current znodeVersion {}, lastZnodeVersion {}\", znodeVersion, lastZnodeVersion);\n\n        try {\n          if (znodeVersion == lastZnodeVersion) {\n            updated.await();\n\n            // are we closed?\n            if (isClosed) {\n              log.warn(\"OverseerTriggerThread woken up but we are closed, exiting.\");\n              break;\n            }\n\n            // spurious wakeup?\n            if (znodeVersion == lastZnodeVersion) continue;\n          }\n          copy = new HashMap<>(activeTriggers);\n          lastZnodeVersion = znodeVersion;\n          log.debug(\"Processed trigger updates upto znodeVersion {}\", znodeVersion);\n        } catch (InterruptedException e) {\n          // Restore the interrupted status\n          Thread.currentThread().interrupt();\n          log.warn(\"Interrupted\", e);\n          break;\n        } finally {\n          updateLock.unlock();\n        }\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        log.warn(\"Interrupted\", e);\n        break;\n      }\n\n      // update the current config\n      scheduledTriggers.setAutoScalingConfig(autoScalingConfig);\n\n      Set<String> managedTriggerNames = scheduledTriggers.getScheduledTriggerNames();\n      // remove the triggers which are no longer active\n      for (String managedTriggerName : managedTriggerNames) {\n        if (!copy.containsKey(managedTriggerName)) {\n          scheduledTriggers.remove(managedTriggerName);\n        }\n      }\n      // check for nodeLost triggers in the current config, and if\n      // absent then clean up old nodeLost / nodeAdded markers\n      boolean cleanOldNodeLostMarkers = true;\n      boolean cleanOldNodeAddedMarkers = true;\n      try {\n        // add new triggers and/or replace and close the replaced triggers\n        for (Map.Entry<String, AutoScaling.Trigger> entry : copy.entrySet()) {\n          if (entry.getValue().getEventType().equals(TriggerEventType.NODELOST)) {\n            cleanOldNodeLostMarkers = false;\n          }\n          if (entry.getValue().getEventType().equals(TriggerEventType.NODEADDED)) {\n            cleanOldNodeAddedMarkers = false;\n          }\n          scheduledTriggers.add(entry.getValue());\n        }\n      } catch (AlreadyClosedException e) {\n        // this _should_ mean that we're closing, complain loudly if that's not the case\n        if (isClosed) {\n          return;\n        } else {\n          throw new IllegalStateException(\"Caught AlreadyClosedException from ScheduledTriggers, but we're not closed yet!\", e);\n        }\n      }\n      if (cleanOldNodeLostMarkers) {\n        log.debug(\"-- clean old nodeLost markers\");\n        try {\n          List<String> markers = zkClient.getChildren(ZkStateReader.SOLR_AUTOSCALING_NODE_LOST_PATH, null, true);\n          markers.forEach(n -> {\n            removeNodeMarker(ZkStateReader.SOLR_AUTOSCALING_NODE_LOST_PATH, n);\n          });\n        } catch (KeeperException.NoNodeException e) {\n          // ignore\n        } catch (KeeperException | InterruptedException e) {\n          log.warn(\"Error removing old nodeLost markers\", e);\n        }\n      }\n      if (cleanOldNodeAddedMarkers) {\n        log.debug(\"-- clean old nodeAdded markers\");\n        try {\n          List<String> markers = zkClient.getChildren(ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH, null, true);\n          markers.forEach(n -> {\n            removeNodeMarker(ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH, n);\n          });\n        } catch (KeeperException.NoNodeException e) {\n          // ignore\n        } catch (KeeperException | InterruptedException e) {\n          log.warn(\"Error removing old nodeAdded markers\", e);\n        }\n\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  public void run() {\n    int lastZnodeVersion = znodeVersion;\n\n    try {\n      refreshAutoScalingConf(new AutoScalingWatcher());\n    } catch (ConnectException e) {\n      log.warn(\"ZooKeeper watch triggered for autoscaling conf, but Solr cannot talk to ZK: [{}]\", e.getMessage());\n    } catch (InterruptedException e) {\n      // Restore the interrupted status\n      Thread.currentThread().interrupt();\n      log.warn(\"Interrupted\", e);\n    } catch (Exception e)  {\n      log.error(\"Unexpected exception\", e);\n    }\n\n    while (true) {\n      Map<String, AutoScaling.Trigger> copy = null;\n      try {\n        // this can throw InterruptedException and we don't want to unlock if it did, so we keep this outside\n        // of the try/finally block\n        updateLock.lockInterruptibly();\n\n        // must check for close here before we await on the condition otherwise we can only be woken up on interruption\n        if (isClosed) {\n          log.warn(\"OverseerTriggerThread has been closed, exiting.\");\n          break;\n        }\n\n        log.debug(\"Current znodeVersion {}, lastZnodeVersion {}\", znodeVersion, lastZnodeVersion);\n\n        try {\n          if (znodeVersion == lastZnodeVersion) {\n            updated.await();\n\n            // are we closed?\n            if (isClosed) {\n              log.warn(\"OverseerTriggerThread woken up but we are closed, exiting.\");\n              break;\n            }\n\n            // spurious wakeup?\n            if (znodeVersion == lastZnodeVersion) continue;\n          }\n          copy = new HashMap<>(activeTriggers);\n          lastZnodeVersion = znodeVersion;\n          log.debug(\"Processed trigger updates upto znodeVersion {}\", znodeVersion);\n        } catch (InterruptedException e) {\n          // Restore the interrupted status\n          Thread.currentThread().interrupt();\n          log.warn(\"Interrupted\", e);\n          break;\n        } finally {\n          updateLock.unlock();\n        }\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        log.warn(\"Interrupted\", e);\n        break;\n      }\n\n      // update the current config\n      scheduledTriggers.setAutoScalingConfig(autoScalingConfig);\n\n      Set<String> managedTriggerNames = scheduledTriggers.getScheduledTriggerNames();\n      // remove the triggers which are no longer active\n      for (String managedTriggerName : managedTriggerNames) {\n        if (!copy.containsKey(managedTriggerName)) {\n          scheduledTriggers.remove(managedTriggerName);\n        }\n      }\n      // check for nodeLost triggers in the current config, and if\n      // absent then clean up old nodeLost / nodeAdded markers\n      boolean cleanOldNodeLostMarkers = true;\n      boolean cleanOldNodeAddedMarkers = true;\n      try {\n        // add new triggers and/or replace and close the replaced triggers\n        for (Map.Entry<String, AutoScaling.Trigger> entry : copy.entrySet()) {\n          if (entry.getValue().getEventType().equals(TriggerEventType.NODELOST)) {\n            cleanOldNodeLostMarkers = false;\n          }\n          if (entry.getValue().getEventType().equals(TriggerEventType.NODEADDED)) {\n            cleanOldNodeAddedMarkers = false;\n          }\n          scheduledTriggers.add(entry.getValue());\n        }\n      } catch (AlreadyClosedException e) {\n        // this _should_ mean that we're closing, complain loudly if that's not the case\n        if (isClosed) {\n          return;\n        } else {\n          throw new IllegalStateException(\"Caught AlreadyClosedException from ScheduledTriggers, but we're not closed yet!\", e);\n        }\n      }\n      if (cleanOldNodeLostMarkers) {\n        log.debug(\"-- clean old nodeLost markers\");\n        try {\n          List<String> markers = clusterDataProvider.listData(ZkStateReader.SOLR_AUTOSCALING_NODE_LOST_PATH);\n          markers.forEach(n -> {\n            removeNodeMarker(ZkStateReader.SOLR_AUTOSCALING_NODE_LOST_PATH, n);\n          });\n        } catch (NoSuchElementException e) {\n          // ignore\n        } catch (Exception e) {\n          log.warn(\"Error removing old nodeLost markers\", e);\n        }\n      }\n      if (cleanOldNodeAddedMarkers) {\n        log.debug(\"-- clean old nodeAdded markers\");\n        try {\n          List<String> markers = clusterDataProvider.listData(ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH);\n          markers.forEach(n -> {\n            removeNodeMarker(ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH, n);\n          });\n        } catch (NoSuchElementException e) {\n          // ignore\n        } catch (Exception e) {\n          log.warn(\"Error removing old nodeAdded markers\", e);\n        }\n\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b6c71577c4ee99246f48a2c29bc213daab310ee5","date":1505785422,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/autoscaling/OverseerTriggerThread#run().mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/autoscaling/OverseerTriggerThread#run().mjava","sourceNew":"  @Override\n  public void run() {\n    int lastZnodeVersion = znodeVersion;\n\n    // we automatically add a trigger for auto add replicas if it does not exists already\n    while (true)  {\n      try {\n        AutoScalingConfig autoScalingConfig = zkStateReader.getAutoScalingConfig();\n        AutoScalingConfig withAutoAddReplicasTrigger = withAutoAddReplicasTrigger(autoScalingConfig);\n        if (withAutoAddReplicasTrigger.equals(autoScalingConfig)) break;\n        log.debug(\"Adding .autoAddReplicas trigger\");\n        zkClient.setData(SOLR_AUTOSCALING_CONF_PATH, Utils.toJSON(withAutoAddReplicasTrigger), withAutoAddReplicasTrigger.getZkVersion(), true);\n        break;\n      } catch (KeeperException.BadVersionException bve) {\n        // somebody else has changed the configuration so we must retry\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        log.warn(\"Interrupted\", e);\n      } catch (KeeperException e) {\n        log.error(\"A ZK error has occurred\", e);\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"A ZK error has occurred\", e);\n      }\n    }\n\n    try {\n      refreshAutoScalingConf(new AutoScalingWatcher());\n    } catch (KeeperException.ConnectionLossException | KeeperException.SessionExpiredException e) {\n      log.warn(\"ZooKeeper watch triggered for autoscaling conf, but Solr cannot talk to ZK: [{}]\", e.getMessage());\n    } catch (KeeperException e) {\n      log.error(\"A ZK error has occurred\", e);\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"A ZK error has occurred\", e);\n    } catch (InterruptedException e) {\n      // Restore the interrupted status\n      Thread.currentThread().interrupt();\n      log.warn(\"Interrupted\", e);\n    } catch (Exception e)  {\n      log.error(\"Unexpected exception\", e);\n    }\n\n    while (true) {\n      Map<String, AutoScaling.Trigger> copy = null;\n      try {\n        // this can throw InterruptedException and we don't want to unlock if it did, so we keep this outside\n        // of the try/finally block\n        updateLock.lockInterruptibly();\n\n        // must check for close here before we await on the condition otherwise we can only be woken up on interruption\n        if (isClosed) {\n          log.warn(\"OverseerTriggerThread has been closed, exiting.\");\n          break;\n        }\n\n        log.debug(\"Current znodeVersion {}, lastZnodeVersion {}\", znodeVersion, lastZnodeVersion);\n\n        try {\n          if (znodeVersion == lastZnodeVersion) {\n            updated.await();\n\n            // are we closed?\n            if (isClosed) {\n              log.warn(\"OverseerTriggerThread woken up but we are closed, exiting.\");\n              break;\n            }\n\n            // spurious wakeup?\n            if (znodeVersion == lastZnodeVersion) continue;\n          }\n          copy = new HashMap<>(activeTriggers);\n          lastZnodeVersion = znodeVersion;\n          log.debug(\"Processed trigger updates upto znodeVersion {}\", znodeVersion);\n        } catch (InterruptedException e) {\n          // Restore the interrupted status\n          Thread.currentThread().interrupt();\n          log.warn(\"Interrupted\", e);\n          break;\n        } finally {\n          updateLock.unlock();\n        }\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        log.warn(\"Interrupted\", e);\n        break;\n      }\n\n      // update the current config\n      scheduledTriggers.setAutoScalingConfig(autoScalingConfig);\n\n      Set<String> managedTriggerNames = scheduledTriggers.getScheduledTriggerNames();\n      // remove the triggers which are no longer active\n      for (String managedTriggerName : managedTriggerNames) {\n        if (!copy.containsKey(managedTriggerName)) {\n          scheduledTriggers.remove(managedTriggerName);\n        }\n      }\n      // check for nodeLost triggers in the current config, and if\n      // absent then clean up old nodeLost / nodeAdded markers\n      boolean cleanOldNodeLostMarkers = true;\n      boolean cleanOldNodeAddedMarkers = true;\n      try {\n        // add new triggers and/or replace and close the replaced triggers\n        for (Map.Entry<String, AutoScaling.Trigger> entry : copy.entrySet()) {\n          if (entry.getValue().getEventType().equals(TriggerEventType.NODELOST)) {\n            cleanOldNodeLostMarkers = false;\n          }\n          if (entry.getValue().getEventType().equals(TriggerEventType.NODEADDED)) {\n            cleanOldNodeAddedMarkers = false;\n          }\n          scheduledTriggers.add(entry.getValue());\n        }\n      } catch (AlreadyClosedException e) {\n        // this _should_ mean that we're closing, complain loudly if that's not the case\n        if (isClosed) {\n          return;\n        } else {\n          throw new IllegalStateException(\"Caught AlreadyClosedException from ScheduledTriggers, but we're not closed yet!\", e);\n        }\n      }\n      if (cleanOldNodeLostMarkers) {\n        log.debug(\"-- clean old nodeLost markers\");\n        try {\n          List<String> markers = zkClient.getChildren(ZkStateReader.SOLR_AUTOSCALING_NODE_LOST_PATH, null, true);\n          markers.forEach(n -> {\n            removeNodeMarker(ZkStateReader.SOLR_AUTOSCALING_NODE_LOST_PATH, n);\n          });\n        } catch (KeeperException.NoNodeException e) {\n          // ignore\n        } catch (KeeperException | InterruptedException e) {\n          log.warn(\"Error removing old nodeLost markers\", e);\n        }\n      }\n      if (cleanOldNodeAddedMarkers) {\n        log.debug(\"-- clean old nodeAdded markers\");\n        try {\n          List<String> markers = zkClient.getChildren(ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH, null, true);\n          markers.forEach(n -> {\n            removeNodeMarker(ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH, n);\n          });\n        } catch (KeeperException.NoNodeException e) {\n          // ignore\n        } catch (KeeperException | InterruptedException e) {\n          log.warn(\"Error removing old nodeAdded markers\", e);\n        }\n\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  public void run() {\n    int lastZnodeVersion = znodeVersion;\n\n    try {\n      refreshAutoScalingConf(new AutoScalingWatcher());\n    } catch (KeeperException.ConnectionLossException | KeeperException.SessionExpiredException e) {\n      log.warn(\"ZooKeeper watch triggered for autoscaling conf, but Solr cannot talk to ZK: [{}]\", e.getMessage());\n    } catch (KeeperException e) {\n      log.error(\"A ZK error has occurred\", e);\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"A ZK error has occurred\", e);\n    } catch (InterruptedException e) {\n      // Restore the interrupted status\n      Thread.currentThread().interrupt();\n      log.warn(\"Interrupted\", e);\n    } catch (Exception e)  {\n      log.error(\"Unexpected exception\", e);\n    }\n\n    while (true) {\n      Map<String, AutoScaling.Trigger> copy = null;\n      try {\n        // this can throw InterruptedException and we don't want to unlock if it did, so we keep this outside\n        // of the try/finally block\n        updateLock.lockInterruptibly();\n\n        // must check for close here before we await on the condition otherwise we can only be woken up on interruption\n        if (isClosed) {\n          log.warn(\"OverseerTriggerThread has been closed, exiting.\");\n          break;\n        }\n\n        log.debug(\"Current znodeVersion {}, lastZnodeVersion {}\", znodeVersion, lastZnodeVersion);\n\n        try {\n          if (znodeVersion == lastZnodeVersion) {\n            updated.await();\n\n            // are we closed?\n            if (isClosed) {\n              log.warn(\"OverseerTriggerThread woken up but we are closed, exiting.\");\n              break;\n            }\n\n            // spurious wakeup?\n            if (znodeVersion == lastZnodeVersion) continue;\n          }\n          copy = new HashMap<>(activeTriggers);\n          lastZnodeVersion = znodeVersion;\n          log.debug(\"Processed trigger updates upto znodeVersion {}\", znodeVersion);\n        } catch (InterruptedException e) {\n          // Restore the interrupted status\n          Thread.currentThread().interrupt();\n          log.warn(\"Interrupted\", e);\n          break;\n        } finally {\n          updateLock.unlock();\n        }\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        log.warn(\"Interrupted\", e);\n        break;\n      }\n\n      // update the current config\n      scheduledTriggers.setAutoScalingConfig(autoScalingConfig);\n\n      Set<String> managedTriggerNames = scheduledTriggers.getScheduledTriggerNames();\n      // remove the triggers which are no longer active\n      for (String managedTriggerName : managedTriggerNames) {\n        if (!copy.containsKey(managedTriggerName)) {\n          scheduledTriggers.remove(managedTriggerName);\n        }\n      }\n      // check for nodeLost triggers in the current config, and if\n      // absent then clean up old nodeLost / nodeAdded markers\n      boolean cleanOldNodeLostMarkers = true;\n      boolean cleanOldNodeAddedMarkers = true;\n      try {\n        // add new triggers and/or replace and close the replaced triggers\n        for (Map.Entry<String, AutoScaling.Trigger> entry : copy.entrySet()) {\n          if (entry.getValue().getEventType().equals(TriggerEventType.NODELOST)) {\n            cleanOldNodeLostMarkers = false;\n          }\n          if (entry.getValue().getEventType().equals(TriggerEventType.NODEADDED)) {\n            cleanOldNodeAddedMarkers = false;\n          }\n          scheduledTriggers.add(entry.getValue());\n        }\n      } catch (AlreadyClosedException e) {\n        // this _should_ mean that we're closing, complain loudly if that's not the case\n        if (isClosed) {\n          return;\n        } else {\n          throw new IllegalStateException(\"Caught AlreadyClosedException from ScheduledTriggers, but we're not closed yet!\", e);\n        }\n      }\n      if (cleanOldNodeLostMarkers) {\n        log.debug(\"-- clean old nodeLost markers\");\n        try {\n          List<String> markers = zkClient.getChildren(ZkStateReader.SOLR_AUTOSCALING_NODE_LOST_PATH, null, true);\n          markers.forEach(n -> {\n            removeNodeMarker(ZkStateReader.SOLR_AUTOSCALING_NODE_LOST_PATH, n);\n          });\n        } catch (KeeperException.NoNodeException e) {\n          // ignore\n        } catch (KeeperException | InterruptedException e) {\n          log.warn(\"Error removing old nodeLost markers\", e);\n        }\n      }\n      if (cleanOldNodeAddedMarkers) {\n        log.debug(\"-- clean old nodeAdded markers\");\n        try {\n          List<String> markers = zkClient.getChildren(ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH, null, true);\n          markers.forEach(n -> {\n            removeNodeMarker(ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH, n);\n          });\n        } catch (KeeperException.NoNodeException e) {\n          // ignore\n        } catch (KeeperException | InterruptedException e) {\n          log.warn(\"Error removing old nodeAdded markers\", e);\n        }\n\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d74e47b708b42ff110911e64513d0e872ac2577b","date":1505844540,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/autoscaling/OverseerTriggerThread#run().mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/autoscaling/OverseerTriggerThread#run().mjava","sourceNew":"  @Override\n  public void run() {\n    int lastZnodeVersion = znodeVersion;\n\n    // we automatically add a trigger for auto add replicas if it does not exists already\n    while (!isClosed)  {\n      try {\n        AutoScalingConfig autoScalingConfig = zkStateReader.getAutoScalingConfig();\n        AutoScalingConfig withAutoAddReplicasTrigger = withAutoAddReplicasTrigger(autoScalingConfig);\n        if (withAutoAddReplicasTrigger.equals(autoScalingConfig)) break;\n        log.debug(\"Adding .autoAddReplicas trigger\");\n        zkClient.setData(SOLR_AUTOSCALING_CONF_PATH, Utils.toJSON(withAutoAddReplicasTrigger), withAutoAddReplicasTrigger.getZkVersion(), true);\n        break;\n      } catch (KeeperException.BadVersionException bve) {\n        // somebody else has changed the configuration so we must retry\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        log.warn(\"Interrupted\", e);\n      } catch (KeeperException e) {\n        log.error(\"A ZK error has occurred\", e);\n      }\n    }\n\n    if (!isClosed || Thread.currentThread().isInterrupted())  return;\n\n    try {\n      refreshAutoScalingConf(new AutoScalingWatcher());\n    } catch (KeeperException.ConnectionLossException | KeeperException.SessionExpiredException e) {\n      log.warn(\"ZooKeeper watch triggered for autoscaling conf, but Solr cannot talk to ZK: [{}]\", e.getMessage());\n    } catch (KeeperException e) {\n      log.error(\"A ZK error has occurred\", e);\n      if (!isClosed)  {\n        // throw exception only if we haven't been closed already\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"A ZK error has occurred\", e);\n      }\n      return; // silently!\n    } catch (InterruptedException e) {\n      // Restore the interrupted status\n      Thread.currentThread().interrupt();\n      log.warn(\"Interrupted\", e);\n    } catch (Exception e)  {\n      log.error(\"Unexpected exception\", e);\n    }\n\n    while (true) {\n      Map<String, AutoScaling.Trigger> copy = null;\n      try {\n        // this can throw InterruptedException and we don't want to unlock if it did, so we keep this outside\n        // of the try/finally block\n        updateLock.lockInterruptibly();\n\n        // must check for close here before we await on the condition otherwise we can only be woken up on interruption\n        if (isClosed) {\n          log.warn(\"OverseerTriggerThread has been closed, exiting.\");\n          break;\n        }\n\n        log.debug(\"Current znodeVersion {}, lastZnodeVersion {}\", znodeVersion, lastZnodeVersion);\n\n        try {\n          if (znodeVersion == lastZnodeVersion) {\n            updated.await();\n\n            // are we closed?\n            if (isClosed) {\n              log.warn(\"OverseerTriggerThread woken up but we are closed, exiting.\");\n              break;\n            }\n\n            // spurious wakeup?\n            if (znodeVersion == lastZnodeVersion) continue;\n          }\n          copy = new HashMap<>(activeTriggers);\n          lastZnodeVersion = znodeVersion;\n          log.debug(\"Processed trigger updates upto znodeVersion {}\", znodeVersion);\n        } catch (InterruptedException e) {\n          // Restore the interrupted status\n          Thread.currentThread().interrupt();\n          log.warn(\"Interrupted\", e);\n          break;\n        } finally {\n          updateLock.unlock();\n        }\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        log.warn(\"Interrupted\", e);\n        break;\n      }\n\n      // update the current config\n      scheduledTriggers.setAutoScalingConfig(autoScalingConfig);\n\n      Set<String> managedTriggerNames = scheduledTriggers.getScheduledTriggerNames();\n      // remove the triggers which are no longer active\n      for (String managedTriggerName : managedTriggerNames) {\n        if (!copy.containsKey(managedTriggerName)) {\n          scheduledTriggers.remove(managedTriggerName);\n        }\n      }\n      // check for nodeLost triggers in the current config, and if\n      // absent then clean up old nodeLost / nodeAdded markers\n      boolean cleanOldNodeLostMarkers = true;\n      boolean cleanOldNodeAddedMarkers = true;\n      try {\n        // add new triggers and/or replace and close the replaced triggers\n        for (Map.Entry<String, AutoScaling.Trigger> entry : copy.entrySet()) {\n          if (entry.getValue().getEventType().equals(TriggerEventType.NODELOST)) {\n            cleanOldNodeLostMarkers = false;\n          }\n          if (entry.getValue().getEventType().equals(TriggerEventType.NODEADDED)) {\n            cleanOldNodeAddedMarkers = false;\n          }\n          scheduledTriggers.add(entry.getValue());\n        }\n      } catch (AlreadyClosedException e) {\n        // this _should_ mean that we're closing, complain loudly if that's not the case\n        if (isClosed) {\n          return;\n        } else {\n          throw new IllegalStateException(\"Caught AlreadyClosedException from ScheduledTriggers, but we're not closed yet!\", e);\n        }\n      }\n      if (cleanOldNodeLostMarkers) {\n        log.debug(\"-- clean old nodeLost markers\");\n        try {\n          List<String> markers = zkClient.getChildren(ZkStateReader.SOLR_AUTOSCALING_NODE_LOST_PATH, null, true);\n          markers.forEach(n -> {\n            removeNodeMarker(ZkStateReader.SOLR_AUTOSCALING_NODE_LOST_PATH, n);\n          });\n        } catch (KeeperException.NoNodeException e) {\n          // ignore\n        } catch (KeeperException | InterruptedException e) {\n          log.warn(\"Error removing old nodeLost markers\", e);\n        }\n      }\n      if (cleanOldNodeAddedMarkers) {\n        log.debug(\"-- clean old nodeAdded markers\");\n        try {\n          List<String> markers = zkClient.getChildren(ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH, null, true);\n          markers.forEach(n -> {\n            removeNodeMarker(ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH, n);\n          });\n        } catch (KeeperException.NoNodeException e) {\n          // ignore\n        } catch (KeeperException | InterruptedException e) {\n          log.warn(\"Error removing old nodeAdded markers\", e);\n        }\n\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  public void run() {\n    int lastZnodeVersion = znodeVersion;\n\n    // we automatically add a trigger for auto add replicas if it does not exists already\n    while (true)  {\n      try {\n        AutoScalingConfig autoScalingConfig = zkStateReader.getAutoScalingConfig();\n        AutoScalingConfig withAutoAddReplicasTrigger = withAutoAddReplicasTrigger(autoScalingConfig);\n        if (withAutoAddReplicasTrigger.equals(autoScalingConfig)) break;\n        log.debug(\"Adding .autoAddReplicas trigger\");\n        zkClient.setData(SOLR_AUTOSCALING_CONF_PATH, Utils.toJSON(withAutoAddReplicasTrigger), withAutoAddReplicasTrigger.getZkVersion(), true);\n        break;\n      } catch (KeeperException.BadVersionException bve) {\n        // somebody else has changed the configuration so we must retry\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        log.warn(\"Interrupted\", e);\n      } catch (KeeperException e) {\n        log.error(\"A ZK error has occurred\", e);\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"A ZK error has occurred\", e);\n      }\n    }\n\n    try {\n      refreshAutoScalingConf(new AutoScalingWatcher());\n    } catch (KeeperException.ConnectionLossException | KeeperException.SessionExpiredException e) {\n      log.warn(\"ZooKeeper watch triggered for autoscaling conf, but Solr cannot talk to ZK: [{}]\", e.getMessage());\n    } catch (KeeperException e) {\n      log.error(\"A ZK error has occurred\", e);\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"A ZK error has occurred\", e);\n    } catch (InterruptedException e) {\n      // Restore the interrupted status\n      Thread.currentThread().interrupt();\n      log.warn(\"Interrupted\", e);\n    } catch (Exception e)  {\n      log.error(\"Unexpected exception\", e);\n    }\n\n    while (true) {\n      Map<String, AutoScaling.Trigger> copy = null;\n      try {\n        // this can throw InterruptedException and we don't want to unlock if it did, so we keep this outside\n        // of the try/finally block\n        updateLock.lockInterruptibly();\n\n        // must check for close here before we await on the condition otherwise we can only be woken up on interruption\n        if (isClosed) {\n          log.warn(\"OverseerTriggerThread has been closed, exiting.\");\n          break;\n        }\n\n        log.debug(\"Current znodeVersion {}, lastZnodeVersion {}\", znodeVersion, lastZnodeVersion);\n\n        try {\n          if (znodeVersion == lastZnodeVersion) {\n            updated.await();\n\n            // are we closed?\n            if (isClosed) {\n              log.warn(\"OverseerTriggerThread woken up but we are closed, exiting.\");\n              break;\n            }\n\n            // spurious wakeup?\n            if (znodeVersion == lastZnodeVersion) continue;\n          }\n          copy = new HashMap<>(activeTriggers);\n          lastZnodeVersion = znodeVersion;\n          log.debug(\"Processed trigger updates upto znodeVersion {}\", znodeVersion);\n        } catch (InterruptedException e) {\n          // Restore the interrupted status\n          Thread.currentThread().interrupt();\n          log.warn(\"Interrupted\", e);\n          break;\n        } finally {\n          updateLock.unlock();\n        }\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        log.warn(\"Interrupted\", e);\n        break;\n      }\n\n      // update the current config\n      scheduledTriggers.setAutoScalingConfig(autoScalingConfig);\n\n      Set<String> managedTriggerNames = scheduledTriggers.getScheduledTriggerNames();\n      // remove the triggers which are no longer active\n      for (String managedTriggerName : managedTriggerNames) {\n        if (!copy.containsKey(managedTriggerName)) {\n          scheduledTriggers.remove(managedTriggerName);\n        }\n      }\n      // check for nodeLost triggers in the current config, and if\n      // absent then clean up old nodeLost / nodeAdded markers\n      boolean cleanOldNodeLostMarkers = true;\n      boolean cleanOldNodeAddedMarkers = true;\n      try {\n        // add new triggers and/or replace and close the replaced triggers\n        for (Map.Entry<String, AutoScaling.Trigger> entry : copy.entrySet()) {\n          if (entry.getValue().getEventType().equals(TriggerEventType.NODELOST)) {\n            cleanOldNodeLostMarkers = false;\n          }\n          if (entry.getValue().getEventType().equals(TriggerEventType.NODEADDED)) {\n            cleanOldNodeAddedMarkers = false;\n          }\n          scheduledTriggers.add(entry.getValue());\n        }\n      } catch (AlreadyClosedException e) {\n        // this _should_ mean that we're closing, complain loudly if that's not the case\n        if (isClosed) {\n          return;\n        } else {\n          throw new IllegalStateException(\"Caught AlreadyClosedException from ScheduledTriggers, but we're not closed yet!\", e);\n        }\n      }\n      if (cleanOldNodeLostMarkers) {\n        log.debug(\"-- clean old nodeLost markers\");\n        try {\n          List<String> markers = zkClient.getChildren(ZkStateReader.SOLR_AUTOSCALING_NODE_LOST_PATH, null, true);\n          markers.forEach(n -> {\n            removeNodeMarker(ZkStateReader.SOLR_AUTOSCALING_NODE_LOST_PATH, n);\n          });\n        } catch (KeeperException.NoNodeException e) {\n          // ignore\n        } catch (KeeperException | InterruptedException e) {\n          log.warn(\"Error removing old nodeLost markers\", e);\n        }\n      }\n      if (cleanOldNodeAddedMarkers) {\n        log.debug(\"-- clean old nodeAdded markers\");\n        try {\n          List<String> markers = zkClient.getChildren(ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH, null, true);\n          markers.forEach(n -> {\n            removeNodeMarker(ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH, n);\n          });\n        } catch (KeeperException.NoNodeException e) {\n          // ignore\n        } catch (KeeperException | InterruptedException e) {\n          log.warn(\"Error removing old nodeAdded markers\", e);\n        }\n\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"bc9e0ccf4cd88f932a18bc65e24c83e8d011f404","date":1505846093,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/autoscaling/OverseerTriggerThread#run().mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/autoscaling/OverseerTriggerThread#run().mjava","sourceNew":"  @Override\n  public void run() {\n    int lastZnodeVersion = znodeVersion;\n\n    // we automatically add a trigger for auto add replicas if it does not exists already\n    while (!isClosed)  {\n      try {\n        AutoScalingConfig autoScalingConfig = zkStateReader.getAutoScalingConfig();\n        AutoScalingConfig withAutoAddReplicasTrigger = withAutoAddReplicasTrigger(autoScalingConfig);\n        if (withAutoAddReplicasTrigger.equals(autoScalingConfig)) break;\n        log.debug(\"Adding .autoAddReplicas trigger\");\n        zkClient.setData(SOLR_AUTOSCALING_CONF_PATH, Utils.toJSON(withAutoAddReplicasTrigger), withAutoAddReplicasTrigger.getZkVersion(), true);\n        break;\n      } catch (KeeperException.BadVersionException bve) {\n        // somebody else has changed the configuration so we must retry\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        log.warn(\"Interrupted\", e);\n        break;\n      } catch (KeeperException e) {\n        log.error(\"A ZK error has occurred\", e);\n      }\n    }\n\n    if (isClosed || Thread.currentThread().isInterrupted())  return;\n\n    try {\n      refreshAutoScalingConf(new AutoScalingWatcher());\n    } catch (KeeperException.ConnectionLossException | KeeperException.SessionExpiredException e) {\n      log.warn(\"ZooKeeper watch triggered for autoscaling conf, but Solr cannot talk to ZK: [{}]\", e.getMessage());\n    } catch (KeeperException e) {\n      log.error(\"A ZK error has occurred\", e);\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"A ZK error has occurred\", e);\n    } catch (InterruptedException e) {\n      // Restore the interrupted status\n      Thread.currentThread().interrupt();\n      log.warn(\"Interrupted\", e);\n    } catch (Exception e)  {\n      log.error(\"Unexpected exception\", e);\n    }\n\n    while (true) {\n      Map<String, AutoScaling.Trigger> copy = null;\n      try {\n        // this can throw InterruptedException and we don't want to unlock if it did, so we keep this outside\n        // of the try/finally block\n        updateLock.lockInterruptibly();\n\n        // must check for close here before we await on the condition otherwise we can only be woken up on interruption\n        if (isClosed) {\n          log.warn(\"OverseerTriggerThread has been closed, exiting.\");\n          break;\n        }\n\n        log.debug(\"Current znodeVersion {}, lastZnodeVersion {}\", znodeVersion, lastZnodeVersion);\n\n        try {\n          if (znodeVersion == lastZnodeVersion) {\n            updated.await();\n\n            // are we closed?\n            if (isClosed) {\n              log.warn(\"OverseerTriggerThread woken up but we are closed, exiting.\");\n              break;\n            }\n\n            // spurious wakeup?\n            if (znodeVersion == lastZnodeVersion) continue;\n          }\n          copy = new HashMap<>(activeTriggers);\n          lastZnodeVersion = znodeVersion;\n          log.debug(\"Processed trigger updates upto znodeVersion {}\", znodeVersion);\n        } catch (InterruptedException e) {\n          // Restore the interrupted status\n          Thread.currentThread().interrupt();\n          log.warn(\"Interrupted\", e);\n          break;\n        } finally {\n          updateLock.unlock();\n        }\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        log.warn(\"Interrupted\", e);\n        break;\n      }\n\n      // update the current config\n      scheduledTriggers.setAutoScalingConfig(autoScalingConfig);\n\n      Set<String> managedTriggerNames = scheduledTriggers.getScheduledTriggerNames();\n      // remove the triggers which are no longer active\n      for (String managedTriggerName : managedTriggerNames) {\n        if (!copy.containsKey(managedTriggerName)) {\n          scheduledTriggers.remove(managedTriggerName);\n        }\n      }\n      // check for nodeLost triggers in the current config, and if\n      // absent then clean up old nodeLost / nodeAdded markers\n      boolean cleanOldNodeLostMarkers = true;\n      boolean cleanOldNodeAddedMarkers = true;\n      try {\n        // add new triggers and/or replace and close the replaced triggers\n        for (Map.Entry<String, AutoScaling.Trigger> entry : copy.entrySet()) {\n          if (entry.getValue().getEventType().equals(TriggerEventType.NODELOST)) {\n            cleanOldNodeLostMarkers = false;\n          }\n          if (entry.getValue().getEventType().equals(TriggerEventType.NODEADDED)) {\n            cleanOldNodeAddedMarkers = false;\n          }\n          scheduledTriggers.add(entry.getValue());\n        }\n      } catch (AlreadyClosedException e) {\n        // this _should_ mean that we're closing, complain loudly if that's not the case\n        if (isClosed) {\n          return;\n        } else {\n          throw new IllegalStateException(\"Caught AlreadyClosedException from ScheduledTriggers, but we're not closed yet!\", e);\n        }\n      }\n      if (cleanOldNodeLostMarkers) {\n        log.debug(\"-- clean old nodeLost markers\");\n        try {\n          List<String> markers = zkClient.getChildren(ZkStateReader.SOLR_AUTOSCALING_NODE_LOST_PATH, null, true);\n          markers.forEach(n -> {\n            removeNodeMarker(ZkStateReader.SOLR_AUTOSCALING_NODE_LOST_PATH, n);\n          });\n        } catch (KeeperException.NoNodeException e) {\n          // ignore\n        } catch (KeeperException | InterruptedException e) {\n          log.warn(\"Error removing old nodeLost markers\", e);\n        }\n      }\n      if (cleanOldNodeAddedMarkers) {\n        log.debug(\"-- clean old nodeAdded markers\");\n        try {\n          List<String> markers = zkClient.getChildren(ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH, null, true);\n          markers.forEach(n -> {\n            removeNodeMarker(ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH, n);\n          });\n        } catch (KeeperException.NoNodeException e) {\n          // ignore\n        } catch (KeeperException | InterruptedException e) {\n          log.warn(\"Error removing old nodeAdded markers\", e);\n        }\n\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  public void run() {\n    int lastZnodeVersion = znodeVersion;\n\n    // we automatically add a trigger for auto add replicas if it does not exists already\n    while (!isClosed)  {\n      try {\n        AutoScalingConfig autoScalingConfig = zkStateReader.getAutoScalingConfig();\n        AutoScalingConfig withAutoAddReplicasTrigger = withAutoAddReplicasTrigger(autoScalingConfig);\n        if (withAutoAddReplicasTrigger.equals(autoScalingConfig)) break;\n        log.debug(\"Adding .autoAddReplicas trigger\");\n        zkClient.setData(SOLR_AUTOSCALING_CONF_PATH, Utils.toJSON(withAutoAddReplicasTrigger), withAutoAddReplicasTrigger.getZkVersion(), true);\n        break;\n      } catch (KeeperException.BadVersionException bve) {\n        // somebody else has changed the configuration so we must retry\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        log.warn(\"Interrupted\", e);\n      } catch (KeeperException e) {\n        log.error(\"A ZK error has occurred\", e);\n      }\n    }\n\n    if (!isClosed || Thread.currentThread().isInterrupted())  return;\n\n    try {\n      refreshAutoScalingConf(new AutoScalingWatcher());\n    } catch (KeeperException.ConnectionLossException | KeeperException.SessionExpiredException e) {\n      log.warn(\"ZooKeeper watch triggered for autoscaling conf, but Solr cannot talk to ZK: [{}]\", e.getMessage());\n    } catch (KeeperException e) {\n      log.error(\"A ZK error has occurred\", e);\n      if (!isClosed)  {\n        // throw exception only if we haven't been closed already\n        throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"A ZK error has occurred\", e);\n      }\n      return; // silently!\n    } catch (InterruptedException e) {\n      // Restore the interrupted status\n      Thread.currentThread().interrupt();\n      log.warn(\"Interrupted\", e);\n    } catch (Exception e)  {\n      log.error(\"Unexpected exception\", e);\n    }\n\n    while (true) {\n      Map<String, AutoScaling.Trigger> copy = null;\n      try {\n        // this can throw InterruptedException and we don't want to unlock if it did, so we keep this outside\n        // of the try/finally block\n        updateLock.lockInterruptibly();\n\n        // must check for close here before we await on the condition otherwise we can only be woken up on interruption\n        if (isClosed) {\n          log.warn(\"OverseerTriggerThread has been closed, exiting.\");\n          break;\n        }\n\n        log.debug(\"Current znodeVersion {}, lastZnodeVersion {}\", znodeVersion, lastZnodeVersion);\n\n        try {\n          if (znodeVersion == lastZnodeVersion) {\n            updated.await();\n\n            // are we closed?\n            if (isClosed) {\n              log.warn(\"OverseerTriggerThread woken up but we are closed, exiting.\");\n              break;\n            }\n\n            // spurious wakeup?\n            if (znodeVersion == lastZnodeVersion) continue;\n          }\n          copy = new HashMap<>(activeTriggers);\n          lastZnodeVersion = znodeVersion;\n          log.debug(\"Processed trigger updates upto znodeVersion {}\", znodeVersion);\n        } catch (InterruptedException e) {\n          // Restore the interrupted status\n          Thread.currentThread().interrupt();\n          log.warn(\"Interrupted\", e);\n          break;\n        } finally {\n          updateLock.unlock();\n        }\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        log.warn(\"Interrupted\", e);\n        break;\n      }\n\n      // update the current config\n      scheduledTriggers.setAutoScalingConfig(autoScalingConfig);\n\n      Set<String> managedTriggerNames = scheduledTriggers.getScheduledTriggerNames();\n      // remove the triggers which are no longer active\n      for (String managedTriggerName : managedTriggerNames) {\n        if (!copy.containsKey(managedTriggerName)) {\n          scheduledTriggers.remove(managedTriggerName);\n        }\n      }\n      // check for nodeLost triggers in the current config, and if\n      // absent then clean up old nodeLost / nodeAdded markers\n      boolean cleanOldNodeLostMarkers = true;\n      boolean cleanOldNodeAddedMarkers = true;\n      try {\n        // add new triggers and/or replace and close the replaced triggers\n        for (Map.Entry<String, AutoScaling.Trigger> entry : copy.entrySet()) {\n          if (entry.getValue().getEventType().equals(TriggerEventType.NODELOST)) {\n            cleanOldNodeLostMarkers = false;\n          }\n          if (entry.getValue().getEventType().equals(TriggerEventType.NODEADDED)) {\n            cleanOldNodeAddedMarkers = false;\n          }\n          scheduledTriggers.add(entry.getValue());\n        }\n      } catch (AlreadyClosedException e) {\n        // this _should_ mean that we're closing, complain loudly if that's not the case\n        if (isClosed) {\n          return;\n        } else {\n          throw new IllegalStateException(\"Caught AlreadyClosedException from ScheduledTriggers, but we're not closed yet!\", e);\n        }\n      }\n      if (cleanOldNodeLostMarkers) {\n        log.debug(\"-- clean old nodeLost markers\");\n        try {\n          List<String> markers = zkClient.getChildren(ZkStateReader.SOLR_AUTOSCALING_NODE_LOST_PATH, null, true);\n          markers.forEach(n -> {\n            removeNodeMarker(ZkStateReader.SOLR_AUTOSCALING_NODE_LOST_PATH, n);\n          });\n        } catch (KeeperException.NoNodeException e) {\n          // ignore\n        } catch (KeeperException | InterruptedException e) {\n          log.warn(\"Error removing old nodeLost markers\", e);\n        }\n      }\n      if (cleanOldNodeAddedMarkers) {\n        log.debug(\"-- clean old nodeAdded markers\");\n        try {\n          List<String> markers = zkClient.getChildren(ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH, null, true);\n          markers.forEach(n -> {\n            removeNodeMarker(ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH, n);\n          });\n        } catch (KeeperException.NoNodeException e) {\n          // ignore\n        } catch (KeeperException | InterruptedException e) {\n          log.warn(\"Error removing old nodeAdded markers\", e);\n        }\n\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"c304e97e7c1d472bc70e801b35ee78583916c6cd","date":1507105431,"type":0,"author":"Noble Paul","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/cloud/autoscaling/OverseerTriggerThread#run().mjava","pathOld":"/dev/null","sourceNew":"  @Override\n  public void run() {\n    int lastZnodeVersion = znodeVersion;\n\n    // we automatically add a trigger for auto add replicas if it does not exists already\n    while (!isClosed)  {\n      try {\n        AutoScalingConfig autoScalingConfig = zkStateReader.getAutoScalingConfig();\n        AutoScalingConfig withAutoAddReplicasTrigger = withAutoAddReplicasTrigger(autoScalingConfig);\n        if (withAutoAddReplicasTrigger.equals(autoScalingConfig)) break;\n        log.debug(\"Adding .autoAddReplicas trigger\");\n        zkClient.setData(SOLR_AUTOSCALING_CONF_PATH, Utils.toJSON(withAutoAddReplicasTrigger), withAutoAddReplicasTrigger.getZkVersion(), true);\n        break;\n      } catch (KeeperException.BadVersionException bve) {\n        // somebody else has changed the configuration so we must retry\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        log.warn(\"Interrupted\", e);\n        break;\n      } catch (KeeperException e) {\n        log.error(\"A ZK error has occurred\", e);\n      }\n    }\n\n    if (isClosed || Thread.currentThread().isInterrupted())  return;\n\n    try {\n      refreshAutoScalingConf(new AutoScalingWatcher());\n    } catch (KeeperException.ConnectionLossException | KeeperException.SessionExpiredException e) {\n      log.warn(\"ZooKeeper watch triggered for autoscaling conf, but Solr cannot talk to ZK: [{}]\", e.getMessage());\n    } catch (KeeperException e) {\n      log.error(\"A ZK error has occurred\", e);\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"A ZK error has occurred\", e);\n    } catch (InterruptedException e) {\n      // Restore the interrupted status\n      Thread.currentThread().interrupt();\n      log.warn(\"Interrupted\", e);\n    } catch (Exception e)  {\n      log.error(\"Unexpected exception\", e);\n    }\n\n    while (true) {\n      Map<String, AutoScaling.Trigger> copy = null;\n      try {\n        // this can throw InterruptedException and we don't want to unlock if it did, so we keep this outside\n        // of the try/finally block\n        updateLock.lockInterruptibly();\n\n        // must check for close here before we await on the condition otherwise we can only be woken up on interruption\n        if (isClosed) {\n          log.warn(\"OverseerTriggerThread has been closed, exiting.\");\n          break;\n        }\n\n        log.debug(\"Current znodeVersion {}, lastZnodeVersion {}\", znodeVersion, lastZnodeVersion);\n\n        try {\n          if (znodeVersion == lastZnodeVersion) {\n            updated.await();\n\n            // are we closed?\n            if (isClosed) {\n              log.warn(\"OverseerTriggerThread woken up but we are closed, exiting.\");\n              break;\n            }\n\n            // spurious wakeup?\n            if (znodeVersion == lastZnodeVersion) continue;\n          }\n          copy = new HashMap<>(activeTriggers);\n          lastZnodeVersion = znodeVersion;\n          log.debug(\"Processed trigger updates upto znodeVersion {}\", znodeVersion);\n        } catch (InterruptedException e) {\n          // Restore the interrupted status\n          Thread.currentThread().interrupt();\n          log.warn(\"Interrupted\", e);\n          break;\n        } finally {\n          updateLock.unlock();\n        }\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        log.warn(\"Interrupted\", e);\n        break;\n      }\n\n      // update the current config\n      scheduledTriggers.setAutoScalingConfig(autoScalingConfig);\n\n      Set<String> managedTriggerNames = scheduledTriggers.getScheduledTriggerNames();\n      // remove the triggers which are no longer active\n      for (String managedTriggerName : managedTriggerNames) {\n        if (!copy.containsKey(managedTriggerName)) {\n          scheduledTriggers.remove(managedTriggerName);\n        }\n      }\n      // check for nodeLost triggers in the current config, and if\n      // absent then clean up old nodeLost / nodeAdded markers\n      boolean cleanOldNodeLostMarkers = true;\n      boolean cleanOldNodeAddedMarkers = true;\n      try {\n        // add new triggers and/or replace and close the replaced triggers\n        for (Map.Entry<String, AutoScaling.Trigger> entry : copy.entrySet()) {\n          if (entry.getValue().getEventType().equals(TriggerEventType.NODELOST)) {\n            cleanOldNodeLostMarkers = false;\n          }\n          if (entry.getValue().getEventType().equals(TriggerEventType.NODEADDED)) {\n            cleanOldNodeAddedMarkers = false;\n          }\n          scheduledTriggers.add(entry.getValue());\n        }\n      } catch (AlreadyClosedException e) {\n        // this _should_ mean that we're closing, complain loudly if that's not the case\n        if (isClosed) {\n          return;\n        } else {\n          throw new IllegalStateException(\"Caught AlreadyClosedException from ScheduledTriggers, but we're not closed yet!\", e);\n        }\n      }\n      if (cleanOldNodeLostMarkers) {\n        log.debug(\"-- clean old nodeLost markers\");\n        try {\n          List<String> markers = zkClient.getChildren(ZkStateReader.SOLR_AUTOSCALING_NODE_LOST_PATH, null, true);\n          markers.forEach(n -> {\n            removeNodeMarker(ZkStateReader.SOLR_AUTOSCALING_NODE_LOST_PATH, n);\n          });\n        } catch (KeeperException.NoNodeException e) {\n          // ignore\n        } catch (KeeperException | InterruptedException e) {\n          log.warn(\"Error removing old nodeLost markers\", e);\n        }\n      }\n      if (cleanOldNodeAddedMarkers) {\n        log.debug(\"-- clean old nodeAdded markers\");\n        try {\n          List<String> markers = zkClient.getChildren(ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH, null, true);\n          markers.forEach(n -> {\n            removeNodeMarker(ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH, n);\n          });\n        } catch (KeeperException.NoNodeException e) {\n          // ignore\n        } catch (KeeperException | InterruptedException e) {\n          log.warn(\"Error removing old nodeAdded markers\", e);\n        }\n\n      }\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"560c18d71dad43d675158783c3840f8c80d6d39c","date":1507105532,"type":0,"author":"Cao Manh Dat","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/cloud/autoscaling/OverseerTriggerThread#run().mjava","pathOld":"/dev/null","sourceNew":"  @Override\n  public void run() {\n    int lastZnodeVersion = znodeVersion;\n\n    // we automatically add a trigger for auto add replicas if it does not exists already\n    while (!isClosed)  {\n      try {\n        AutoScalingConfig autoScalingConfig = zkStateReader.getAutoScalingConfig();\n        AutoScalingConfig withAutoAddReplicasTrigger = withAutoAddReplicasTrigger(autoScalingConfig);\n        if (withAutoAddReplicasTrigger.equals(autoScalingConfig)) break;\n        log.debug(\"Adding .autoAddReplicas trigger\");\n        zkClient.setData(SOLR_AUTOSCALING_CONF_PATH, Utils.toJSON(withAutoAddReplicasTrigger), withAutoAddReplicasTrigger.getZkVersion(), true);\n        break;\n      } catch (KeeperException.BadVersionException bve) {\n        // somebody else has changed the configuration so we must retry\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        log.warn(\"Interrupted\", e);\n        break;\n      } catch (KeeperException e) {\n        log.error(\"A ZK error has occurred\", e);\n      }\n    }\n\n    if (isClosed || Thread.currentThread().isInterrupted())  return;\n\n    try {\n      refreshAutoScalingConf(new AutoScalingWatcher());\n    } catch (KeeperException.ConnectionLossException | KeeperException.SessionExpiredException e) {\n      log.warn(\"ZooKeeper watch triggered for autoscaling conf, but Solr cannot talk to ZK: [{}]\", e.getMessage());\n    } catch (KeeperException e) {\n      log.error(\"A ZK error has occurred\", e);\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"A ZK error has occurred\", e);\n    } catch (InterruptedException e) {\n      // Restore the interrupted status\n      Thread.currentThread().interrupt();\n      log.warn(\"Interrupted\", e);\n    } catch (Exception e)  {\n      log.error(\"Unexpected exception\", e);\n    }\n\n    while (true) {\n      Map<String, AutoScaling.Trigger> copy = null;\n      try {\n        // this can throw InterruptedException and we don't want to unlock if it did, so we keep this outside\n        // of the try/finally block\n        updateLock.lockInterruptibly();\n\n        // must check for close here before we await on the condition otherwise we can only be woken up on interruption\n        if (isClosed) {\n          log.warn(\"OverseerTriggerThread has been closed, exiting.\");\n          break;\n        }\n\n        log.debug(\"Current znodeVersion {}, lastZnodeVersion {}\", znodeVersion, lastZnodeVersion);\n\n        try {\n          if (znodeVersion == lastZnodeVersion) {\n            updated.await();\n\n            // are we closed?\n            if (isClosed) {\n              log.warn(\"OverseerTriggerThread woken up but we are closed, exiting.\");\n              break;\n            }\n\n            // spurious wakeup?\n            if (znodeVersion == lastZnodeVersion) continue;\n          }\n          copy = new HashMap<>(activeTriggers);\n          lastZnodeVersion = znodeVersion;\n          log.debug(\"Processed trigger updates upto znodeVersion {}\", znodeVersion);\n        } catch (InterruptedException e) {\n          // Restore the interrupted status\n          Thread.currentThread().interrupt();\n          log.warn(\"Interrupted\", e);\n          break;\n        } finally {\n          updateLock.unlock();\n        }\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        log.warn(\"Interrupted\", e);\n        break;\n      }\n\n      // update the current config\n      scheduledTriggers.setAutoScalingConfig(autoScalingConfig);\n\n      Set<String> managedTriggerNames = scheduledTriggers.getScheduledTriggerNames();\n      // remove the triggers which are no longer active\n      for (String managedTriggerName : managedTriggerNames) {\n        if (!copy.containsKey(managedTriggerName)) {\n          scheduledTriggers.remove(managedTriggerName);\n        }\n      }\n      // check for nodeLost triggers in the current config, and if\n      // absent then clean up old nodeLost / nodeAdded markers\n      boolean cleanOldNodeLostMarkers = true;\n      boolean cleanOldNodeAddedMarkers = true;\n      try {\n        // add new triggers and/or replace and close the replaced triggers\n        for (Map.Entry<String, AutoScaling.Trigger> entry : copy.entrySet()) {\n          if (entry.getValue().getEventType().equals(TriggerEventType.NODELOST)) {\n            cleanOldNodeLostMarkers = false;\n          }\n          if (entry.getValue().getEventType().equals(TriggerEventType.NODEADDED)) {\n            cleanOldNodeAddedMarkers = false;\n          }\n          scheduledTriggers.add(entry.getValue());\n        }\n      } catch (AlreadyClosedException e) {\n        // this _should_ mean that we're closing, complain loudly if that's not the case\n        if (isClosed) {\n          return;\n        } else {\n          throw new IllegalStateException(\"Caught AlreadyClosedException from ScheduledTriggers, but we're not closed yet!\", e);\n        }\n      }\n      if (cleanOldNodeLostMarkers) {\n        log.debug(\"-- clean old nodeLost markers\");\n        try {\n          List<String> markers = zkClient.getChildren(ZkStateReader.SOLR_AUTOSCALING_NODE_LOST_PATH, null, true);\n          markers.forEach(n -> {\n            removeNodeMarker(ZkStateReader.SOLR_AUTOSCALING_NODE_LOST_PATH, n);\n          });\n        } catch (KeeperException.NoNodeException e) {\n          // ignore\n        } catch (KeeperException | InterruptedException e) {\n          log.warn(\"Error removing old nodeLost markers\", e);\n        }\n      }\n      if (cleanOldNodeAddedMarkers) {\n        log.debug(\"-- clean old nodeAdded markers\");\n        try {\n          List<String> markers = zkClient.getChildren(ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH, null, true);\n          markers.forEach(n -> {\n            removeNodeMarker(ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH, n);\n          });\n        } catch (KeeperException.NoNodeException e) {\n          // ignore\n        } catch (KeeperException | InterruptedException e) {\n          log.warn(\"Error removing old nodeAdded markers\", e);\n        }\n\n      }\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"85212dad4ed576c7f7e6c165ee19e597b7b4efc8","date":1507997740,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/autoscaling/OverseerTriggerThread#run().mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/autoscaling/OverseerTriggerThread#run().mjava","sourceNew":"  @Override\n  public void run() {\n    int lastZnodeVersion = znodeVersion;\n\n    // we automatically add a trigger for auto add replicas if it does not exists already\n    while (!isClosed)  {\n      try {\n        AutoScalingConfig autoScalingConfig = dataProvider.getDistribStateManager().getAutoScalingConfig();\n        AutoScalingConfig withAutoAddReplicasTrigger = withAutoAddReplicasTrigger(autoScalingConfig);\n        if (withAutoAddReplicasTrigger.equals(autoScalingConfig)) break;\n        log.debug(\"Adding .autoAddReplicas trigger\");\n        dataProvider.getDistribStateManager().setData(SOLR_AUTOSCALING_CONF_PATH, Utils.toJSON(withAutoAddReplicasTrigger), withAutoAddReplicasTrigger.getZkVersion());\n        break;\n      } catch (BadVersionException bve) {\n        // somebody else has changed the configuration so we must retry\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        log.warn(\"Interrupted\", e);\n        break;\n      } catch (IOException | KeeperException e) {\n        log.error(\"A ZK error has occurred\", e);\n      }\n    }\n\n    if (isClosed || Thread.currentThread().isInterrupted())  return;\n\n    try {\n      refreshAutoScalingConf(new AutoScalingWatcher());\n    } catch (ConnectException e) {\n      log.warn(\"ZooKeeper watch triggered for autoscaling conf, but Solr cannot talk to ZK: [{}]\", e.getMessage());\n    } catch (InterruptedException e) {\n      // Restore the interrupted status\n      Thread.currentThread().interrupt();\n      log.warn(\"Interrupted\", e);\n    } catch (Exception e)  {\n      log.error(\"Unexpected exception\", e);\n    }\n\n    while (true) {\n      Map<String, AutoScaling.Trigger> copy = null;\n      try {\n        // this can throw InterruptedException and we don't want to unlock if it did, so we keep this outside\n        // of the try/finally block\n        updateLock.lockInterruptibly();\n\n        // must check for close here before we await on the condition otherwise we can only be woken up on interruption\n        if (isClosed) {\n          log.warn(\"OverseerTriggerThread has been closed, exiting.\");\n          break;\n        }\n\n        log.debug(\"Current znodeVersion {}, lastZnodeVersion {}\", znodeVersion, lastZnodeVersion);\n\n        try {\n          if (znodeVersion == lastZnodeVersion) {\n            updated.await();\n\n            // are we closed?\n            if (isClosed) {\n              log.warn(\"OverseerTriggerThread woken up but we are closed, exiting.\");\n              break;\n            }\n\n            // spurious wakeup?\n            if (znodeVersion == lastZnodeVersion) continue;\n          }\n          copy = new HashMap<>(activeTriggers);\n          lastZnodeVersion = znodeVersion;\n          log.debug(\"Processed trigger updates upto znodeVersion {}\", znodeVersion);\n        } catch (InterruptedException e) {\n          // Restore the interrupted status\n          Thread.currentThread().interrupt();\n          log.warn(\"Interrupted\", e);\n          break;\n        } finally {\n          updateLock.unlock();\n        }\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        log.warn(\"Interrupted\", e);\n        break;\n      }\n\n      // update the current config\n      scheduledTriggers.setAutoScalingConfig(autoScalingConfig);\n\n      Set<String> managedTriggerNames = scheduledTriggers.getScheduledTriggerNames();\n      // remove the triggers which are no longer active\n      for (String managedTriggerName : managedTriggerNames) {\n        if (!copy.containsKey(managedTriggerName)) {\n          scheduledTriggers.remove(managedTriggerName);\n        }\n      }\n      // check for nodeLost triggers in the current config, and if\n      // absent then clean up old nodeLost / nodeAdded markers\n      boolean cleanOldNodeLostMarkers = true;\n      boolean cleanOldNodeAddedMarkers = true;\n      try {\n        // add new triggers and/or replace and close the replaced triggers\n        for (Map.Entry<String, AutoScaling.Trigger> entry : copy.entrySet()) {\n          if (entry.getValue().getEventType().equals(TriggerEventType.NODELOST)) {\n            cleanOldNodeLostMarkers = false;\n          }\n          if (entry.getValue().getEventType().equals(TriggerEventType.NODEADDED)) {\n            cleanOldNodeAddedMarkers = false;\n          }\n          scheduledTriggers.add(entry.getValue());\n        }\n      } catch (AlreadyClosedException e) {\n        // this _should_ mean that we're closing, complain loudly if that's not the case\n        if (isClosed) {\n          return;\n        } else {\n          throw new IllegalStateException(\"Caught AlreadyClosedException from ScheduledTriggers, but we're not closed yet!\", e);\n        }\n      }\n      DistribStateManager stateManager = dataProvider.getDistribStateManager();\n      if (cleanOldNodeLostMarkers) {\n        log.debug(\"-- clean old nodeLost markers\");\n        try {\n          List<String> markers = stateManager.listData(ZkStateReader.SOLR_AUTOSCALING_NODE_LOST_PATH);\n          markers.forEach(n -> {\n            removeNodeMarker(ZkStateReader.SOLR_AUTOSCALING_NODE_LOST_PATH, n);\n          });\n        } catch (NoSuchElementException e) {\n          // ignore\n        } catch (Exception e) {\n          log.warn(\"Error removing old nodeLost markers\", e);\n        }\n      }\n      if (cleanOldNodeAddedMarkers) {\n        log.debug(\"-- clean old nodeAdded markers\");\n        try {\n          List<String> markers = stateManager.listData(ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH);\n          markers.forEach(n -> {\n            removeNodeMarker(ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH, n);\n          });\n        } catch (NoSuchElementException e) {\n          // ignore\n        } catch (Exception e) {\n          log.warn(\"Error removing old nodeAdded markers\", e);\n        }\n\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  public void run() {\n    int lastZnodeVersion = znodeVersion;\n\n    // we automatically add a trigger for auto add replicas if it does not exists already\n    while (!isClosed)  {\n      try {\n        AutoScalingConfig autoScalingConfig = zkStateReader.getAutoScalingConfig();\n        AutoScalingConfig withAutoAddReplicasTrigger = withAutoAddReplicasTrigger(autoScalingConfig);\n        if (withAutoAddReplicasTrigger.equals(autoScalingConfig)) break;\n        log.debug(\"Adding .autoAddReplicas trigger\");\n        zkClient.setData(SOLR_AUTOSCALING_CONF_PATH, Utils.toJSON(withAutoAddReplicasTrigger), withAutoAddReplicasTrigger.getZkVersion(), true);\n        break;\n      } catch (KeeperException.BadVersionException bve) {\n        // somebody else has changed the configuration so we must retry\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        log.warn(\"Interrupted\", e);\n        break;\n      } catch (KeeperException e) {\n        log.error(\"A ZK error has occurred\", e);\n      }\n    }\n\n    if (isClosed || Thread.currentThread().isInterrupted())  return;\n\n    try {\n      refreshAutoScalingConf(new AutoScalingWatcher());\n    } catch (KeeperException.ConnectionLossException | KeeperException.SessionExpiredException e) {\n      log.warn(\"ZooKeeper watch triggered for autoscaling conf, but Solr cannot talk to ZK: [{}]\", e.getMessage());\n    } catch (KeeperException e) {\n      log.error(\"A ZK error has occurred\", e);\n      throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR, \"A ZK error has occurred\", e);\n    } catch (InterruptedException e) {\n      // Restore the interrupted status\n      Thread.currentThread().interrupt();\n      log.warn(\"Interrupted\", e);\n    } catch (Exception e)  {\n      log.error(\"Unexpected exception\", e);\n    }\n\n    while (true) {\n      Map<String, AutoScaling.Trigger> copy = null;\n      try {\n        // this can throw InterruptedException and we don't want to unlock if it did, so we keep this outside\n        // of the try/finally block\n        updateLock.lockInterruptibly();\n\n        // must check for close here before we await on the condition otherwise we can only be woken up on interruption\n        if (isClosed) {\n          log.warn(\"OverseerTriggerThread has been closed, exiting.\");\n          break;\n        }\n\n        log.debug(\"Current znodeVersion {}, lastZnodeVersion {}\", znodeVersion, lastZnodeVersion);\n\n        try {\n          if (znodeVersion == lastZnodeVersion) {\n            updated.await();\n\n            // are we closed?\n            if (isClosed) {\n              log.warn(\"OverseerTriggerThread woken up but we are closed, exiting.\");\n              break;\n            }\n\n            // spurious wakeup?\n            if (znodeVersion == lastZnodeVersion) continue;\n          }\n          copy = new HashMap<>(activeTriggers);\n          lastZnodeVersion = znodeVersion;\n          log.debug(\"Processed trigger updates upto znodeVersion {}\", znodeVersion);\n        } catch (InterruptedException e) {\n          // Restore the interrupted status\n          Thread.currentThread().interrupt();\n          log.warn(\"Interrupted\", e);\n          break;\n        } finally {\n          updateLock.unlock();\n        }\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        log.warn(\"Interrupted\", e);\n        break;\n      }\n\n      // update the current config\n      scheduledTriggers.setAutoScalingConfig(autoScalingConfig);\n\n      Set<String> managedTriggerNames = scheduledTriggers.getScheduledTriggerNames();\n      // remove the triggers which are no longer active\n      for (String managedTriggerName : managedTriggerNames) {\n        if (!copy.containsKey(managedTriggerName)) {\n          scheduledTriggers.remove(managedTriggerName);\n        }\n      }\n      // check for nodeLost triggers in the current config, and if\n      // absent then clean up old nodeLost / nodeAdded markers\n      boolean cleanOldNodeLostMarkers = true;\n      boolean cleanOldNodeAddedMarkers = true;\n      try {\n        // add new triggers and/or replace and close the replaced triggers\n        for (Map.Entry<String, AutoScaling.Trigger> entry : copy.entrySet()) {\n          if (entry.getValue().getEventType().equals(TriggerEventType.NODELOST)) {\n            cleanOldNodeLostMarkers = false;\n          }\n          if (entry.getValue().getEventType().equals(TriggerEventType.NODEADDED)) {\n            cleanOldNodeAddedMarkers = false;\n          }\n          scheduledTriggers.add(entry.getValue());\n        }\n      } catch (AlreadyClosedException e) {\n        // this _should_ mean that we're closing, complain loudly if that's not the case\n        if (isClosed) {\n          return;\n        } else {\n          throw new IllegalStateException(\"Caught AlreadyClosedException from ScheduledTriggers, but we're not closed yet!\", e);\n        }\n      }\n      if (cleanOldNodeLostMarkers) {\n        log.debug(\"-- clean old nodeLost markers\");\n        try {\n          List<String> markers = zkClient.getChildren(ZkStateReader.SOLR_AUTOSCALING_NODE_LOST_PATH, null, true);\n          markers.forEach(n -> {\n            removeNodeMarker(ZkStateReader.SOLR_AUTOSCALING_NODE_LOST_PATH, n);\n          });\n        } catch (KeeperException.NoNodeException e) {\n          // ignore\n        } catch (KeeperException | InterruptedException e) {\n          log.warn(\"Error removing old nodeLost markers\", e);\n        }\n      }\n      if (cleanOldNodeAddedMarkers) {\n        log.debug(\"-- clean old nodeAdded markers\");\n        try {\n          List<String> markers = zkClient.getChildren(ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH, null, true);\n          markers.forEach(n -> {\n            removeNodeMarker(ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH, n);\n          });\n        } catch (KeeperException.NoNodeException e) {\n          // ignore\n        } catch (KeeperException | InterruptedException e) {\n          log.warn(\"Error removing old nodeAdded markers\", e);\n        }\n\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"1d4bf9d5308dfef350829c28f2b3b2648df1e9b1","date":1513252583,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/autoscaling/OverseerTriggerThread#run().mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/autoscaling/OverseerTriggerThread#run().mjava","sourceNew":"  @Override\n  public void run() {\n    int lastZnodeVersion = znodeVersion;\n\n    // we automatically add a trigger for auto add replicas if it does not exists already\n    while (!isClosed)  {\n      try {\n        AutoScalingConfig autoScalingConfig = cloudManager.getDistribStateManager().getAutoScalingConfig();\n        AutoScalingConfig withAutoAddReplicasTrigger = withAutoAddReplicasTrigger(autoScalingConfig);\n        if (withAutoAddReplicasTrigger.equals(autoScalingConfig)) break;\n        log.debug(\"Adding .autoAddReplicas trigger\");\n        cloudManager.getDistribStateManager().setData(SOLR_AUTOSCALING_CONF_PATH, Utils.toJSON(withAutoAddReplicasTrigger), withAutoAddReplicasTrigger.getZkVersion());\n        break;\n      } catch (BadVersionException bve) {\n        // somebody else has changed the configuration so we must retry\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        log.warn(\"Interrupted\", e);\n        break;\n      } catch (IOException | KeeperException e) {\n        log.error(\"A ZK error has occurred\", e);\n      }\n    }\n\n    if (isClosed || Thread.currentThread().isInterrupted())  return;\n\n    try {\n      refreshAutoScalingConf(new AutoScalingWatcher());\n    } catch (ConnectException e) {\n      log.warn(\"ZooKeeper watch triggered for autoscaling conf, but Solr cannot talk to ZK: [{}]\", e.getMessage());\n    } catch (InterruptedException e) {\n      // Restore the interrupted status\n      Thread.currentThread().interrupt();\n      log.warn(\"Interrupted\", e);\n    } catch (Exception e)  {\n      log.error(\"Unexpected exception\", e);\n    }\n\n    while (true) {\n      Map<String, AutoScaling.Trigger> copy = null;\n      try {\n        // this can throw InterruptedException and we don't want to unlock if it did, so we keep this outside\n        // of the try/finally block\n        updateLock.lockInterruptibly();\n\n        // must check for close here before we await on the condition otherwise we can only be woken up on interruption\n        if (isClosed) {\n          log.warn(\"OverseerTriggerThread has been closed, exiting.\");\n          break;\n        }\n\n        log.debug(\"Current znodeVersion {}, lastZnodeVersion {}\", znodeVersion, lastZnodeVersion);\n\n        try {\n          if (znodeVersion == lastZnodeVersion) {\n            updated.await();\n\n            // are we closed?\n            if (isClosed) {\n              log.warn(\"OverseerTriggerThread woken up but we are closed, exiting.\");\n              break;\n            }\n\n            // spurious wakeup?\n            if (znodeVersion == lastZnodeVersion) continue;\n          }\n          copy = new HashMap<>(activeTriggers);\n          lastZnodeVersion = znodeVersion;\n          log.debug(\"Processed trigger updates upto znodeVersion {}\", znodeVersion);\n        } catch (InterruptedException e) {\n          // Restore the interrupted status\n          Thread.currentThread().interrupt();\n          log.warn(\"Interrupted\", e);\n          break;\n        } finally {\n          updateLock.unlock();\n        }\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        log.warn(\"Interrupted\", e);\n        break;\n      }\n\n      // update the current config\n      scheduledTriggers.setAutoScalingConfig(autoScalingConfig);\n\n      Set<String> managedTriggerNames = scheduledTriggers.getScheduledTriggerNames();\n      // remove the triggers which are no longer active\n      for (String managedTriggerName : managedTriggerNames) {\n        if (!copy.containsKey(managedTriggerName)) {\n          scheduledTriggers.remove(managedTriggerName);\n        }\n      }\n      // check for nodeLost triggers in the current config, and if\n      // absent then clean up old nodeLost / nodeAdded markers\n      boolean cleanOldNodeLostMarkers = true;\n      boolean cleanOldNodeAddedMarkers = true;\n      try {\n        // add new triggers and/or replace and close the replaced triggers\n        for (Map.Entry<String, AutoScaling.Trigger> entry : copy.entrySet()) {\n          if (entry.getValue().getEventType().equals(TriggerEventType.NODELOST)) {\n            cleanOldNodeLostMarkers = false;\n          }\n          if (entry.getValue().getEventType().equals(TriggerEventType.NODEADDED)) {\n            cleanOldNodeAddedMarkers = false;\n          }\n          scheduledTriggers.add(entry.getValue());\n        }\n      } catch (AlreadyClosedException e) {\n        // this _should_ mean that we're closing, complain loudly if that's not the case\n        if (isClosed) {\n          return;\n        } else {\n          throw new IllegalStateException(\"Caught AlreadyClosedException from ScheduledTriggers, but we're not closed yet!\", e);\n        }\n      }\n      DistribStateManager stateManager = cloudManager.getDistribStateManager();\n      if (cleanOldNodeLostMarkers) {\n        log.debug(\"-- clean old nodeLost markers\");\n        try {\n          List<String> markers = stateManager.listData(ZkStateReader.SOLR_AUTOSCALING_NODE_LOST_PATH);\n          markers.forEach(n -> {\n            removeNodeMarker(ZkStateReader.SOLR_AUTOSCALING_NODE_LOST_PATH, n);\n          });\n        } catch (NoSuchElementException e) {\n          // ignore\n        } catch (Exception e) {\n          log.warn(\"Error removing old nodeLost markers\", e);\n        }\n      }\n      if (cleanOldNodeAddedMarkers) {\n        log.debug(\"-- clean old nodeAdded markers\");\n        try {\n          List<String> markers = stateManager.listData(ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH);\n          markers.forEach(n -> {\n            removeNodeMarker(ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH, n);\n          });\n        } catch (NoSuchElementException e) {\n          // ignore\n        } catch (Exception e) {\n          log.warn(\"Error removing old nodeAdded markers\", e);\n        }\n\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  public void run() {\n    int lastZnodeVersion = znodeVersion;\n\n    // we automatically add a trigger for auto add replicas if it does not exists already\n    while (!isClosed)  {\n      try {\n        AutoScalingConfig autoScalingConfig = dataProvider.getDistribStateManager().getAutoScalingConfig();\n        AutoScalingConfig withAutoAddReplicasTrigger = withAutoAddReplicasTrigger(autoScalingConfig);\n        if (withAutoAddReplicasTrigger.equals(autoScalingConfig)) break;\n        log.debug(\"Adding .autoAddReplicas trigger\");\n        dataProvider.getDistribStateManager().setData(SOLR_AUTOSCALING_CONF_PATH, Utils.toJSON(withAutoAddReplicasTrigger), withAutoAddReplicasTrigger.getZkVersion());\n        break;\n      } catch (BadVersionException bve) {\n        // somebody else has changed the configuration so we must retry\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        log.warn(\"Interrupted\", e);\n        break;\n      } catch (IOException | KeeperException e) {\n        log.error(\"A ZK error has occurred\", e);\n      }\n    }\n\n    if (isClosed || Thread.currentThread().isInterrupted())  return;\n\n    try {\n      refreshAutoScalingConf(new AutoScalingWatcher());\n    } catch (ConnectException e) {\n      log.warn(\"ZooKeeper watch triggered for autoscaling conf, but Solr cannot talk to ZK: [{}]\", e.getMessage());\n    } catch (InterruptedException e) {\n      // Restore the interrupted status\n      Thread.currentThread().interrupt();\n      log.warn(\"Interrupted\", e);\n    } catch (Exception e)  {\n      log.error(\"Unexpected exception\", e);\n    }\n\n    while (true) {\n      Map<String, AutoScaling.Trigger> copy = null;\n      try {\n        // this can throw InterruptedException and we don't want to unlock if it did, so we keep this outside\n        // of the try/finally block\n        updateLock.lockInterruptibly();\n\n        // must check for close here before we await on the condition otherwise we can only be woken up on interruption\n        if (isClosed) {\n          log.warn(\"OverseerTriggerThread has been closed, exiting.\");\n          break;\n        }\n\n        log.debug(\"Current znodeVersion {}, lastZnodeVersion {}\", znodeVersion, lastZnodeVersion);\n\n        try {\n          if (znodeVersion == lastZnodeVersion) {\n            updated.await();\n\n            // are we closed?\n            if (isClosed) {\n              log.warn(\"OverseerTriggerThread woken up but we are closed, exiting.\");\n              break;\n            }\n\n            // spurious wakeup?\n            if (znodeVersion == lastZnodeVersion) continue;\n          }\n          copy = new HashMap<>(activeTriggers);\n          lastZnodeVersion = znodeVersion;\n          log.debug(\"Processed trigger updates upto znodeVersion {}\", znodeVersion);\n        } catch (InterruptedException e) {\n          // Restore the interrupted status\n          Thread.currentThread().interrupt();\n          log.warn(\"Interrupted\", e);\n          break;\n        } finally {\n          updateLock.unlock();\n        }\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        log.warn(\"Interrupted\", e);\n        break;\n      }\n\n      // update the current config\n      scheduledTriggers.setAutoScalingConfig(autoScalingConfig);\n\n      Set<String> managedTriggerNames = scheduledTriggers.getScheduledTriggerNames();\n      // remove the triggers which are no longer active\n      for (String managedTriggerName : managedTriggerNames) {\n        if (!copy.containsKey(managedTriggerName)) {\n          scheduledTriggers.remove(managedTriggerName);\n        }\n      }\n      // check for nodeLost triggers in the current config, and if\n      // absent then clean up old nodeLost / nodeAdded markers\n      boolean cleanOldNodeLostMarkers = true;\n      boolean cleanOldNodeAddedMarkers = true;\n      try {\n        // add new triggers and/or replace and close the replaced triggers\n        for (Map.Entry<String, AutoScaling.Trigger> entry : copy.entrySet()) {\n          if (entry.getValue().getEventType().equals(TriggerEventType.NODELOST)) {\n            cleanOldNodeLostMarkers = false;\n          }\n          if (entry.getValue().getEventType().equals(TriggerEventType.NODEADDED)) {\n            cleanOldNodeAddedMarkers = false;\n          }\n          scheduledTriggers.add(entry.getValue());\n        }\n      } catch (AlreadyClosedException e) {\n        // this _should_ mean that we're closing, complain loudly if that's not the case\n        if (isClosed) {\n          return;\n        } else {\n          throw new IllegalStateException(\"Caught AlreadyClosedException from ScheduledTriggers, but we're not closed yet!\", e);\n        }\n      }\n      DistribStateManager stateManager = dataProvider.getDistribStateManager();\n      if (cleanOldNodeLostMarkers) {\n        log.debug(\"-- clean old nodeLost markers\");\n        try {\n          List<String> markers = stateManager.listData(ZkStateReader.SOLR_AUTOSCALING_NODE_LOST_PATH);\n          markers.forEach(n -> {\n            removeNodeMarker(ZkStateReader.SOLR_AUTOSCALING_NODE_LOST_PATH, n);\n          });\n        } catch (NoSuchElementException e) {\n          // ignore\n        } catch (Exception e) {\n          log.warn(\"Error removing old nodeLost markers\", e);\n        }\n      }\n      if (cleanOldNodeAddedMarkers) {\n        log.debug(\"-- clean old nodeAdded markers\");\n        try {\n          List<String> markers = stateManager.listData(ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH);\n          markers.forEach(n -> {\n            removeNodeMarker(ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH, n);\n          });\n        } catch (NoSuchElementException e) {\n          // ignore\n        } catch (Exception e) {\n          log.warn(\"Error removing old nodeAdded markers\", e);\n        }\n\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"9c6c0dad4932399aec99b4818086cb1772773916","date":1520515900,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/autoscaling/OverseerTriggerThread#run().mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/autoscaling/OverseerTriggerThread#run().mjava","sourceNew":"  @Override\n  public void run() {\n    int lastZnodeVersion = znodeVersion;\n\n    // we automatically add a trigger for auto add replicas if it does not exists already\n    // we also automatically add a scheduled maintenance trigger\n    while (!isClosed)  {\n      try {\n        AutoScalingConfig autoScalingConfig = cloudManager.getDistribStateManager().getAutoScalingConfig();\n        AutoScalingConfig updatedConfig = withAutoAddReplicasTrigger(autoScalingConfig);\n        updatedConfig = withScheduledMaintenanceTrigger(updatedConfig);\n        if (updatedConfig.equals(autoScalingConfig)) break;\n        log.debug(\"Adding .auto_add_replicas and .scheduled_maintenance triggers\");\n        cloudManager.getDistribStateManager().setData(SOLR_AUTOSCALING_CONF_PATH, Utils.toJSON(updatedConfig), updatedConfig.getZkVersion());\n        break;\n      } catch (BadVersionException bve) {\n        // somebody else has changed the configuration so we must retry\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        log.warn(\"Interrupted\", e);\n        break;\n      } catch (IOException | KeeperException e) {\n        log.error(\"A ZK error has occurred\", e);\n      }\n    }\n\n    if (isClosed || Thread.currentThread().isInterrupted())  return;\n\n    try {\n      refreshAutoScalingConf(new AutoScalingWatcher());\n    } catch (ConnectException e) {\n      log.warn(\"ZooKeeper watch triggered for autoscaling conf, but Solr cannot talk to ZK: [{}]\", e.getMessage());\n    } catch (InterruptedException e) {\n      // Restore the interrupted status\n      Thread.currentThread().interrupt();\n      log.warn(\"Interrupted\", e);\n    } catch (Exception e)  {\n      log.error(\"Unexpected exception\", e);\n    }\n\n    while (true) {\n      Map<String, AutoScaling.Trigger> copy = null;\n      try {\n        // this can throw InterruptedException and we don't want to unlock if it did, so we keep this outside\n        // of the try/finally block\n        updateLock.lockInterruptibly();\n\n        // must check for close here before we await on the condition otherwise we can only be woken up on interruption\n        if (isClosed) {\n          log.warn(\"OverseerTriggerThread has been closed, exiting.\");\n          break;\n        }\n\n        log.debug(\"Current znodeVersion {}, lastZnodeVersion {}\", znodeVersion, lastZnodeVersion);\n\n        try {\n          if (znodeVersion == lastZnodeVersion) {\n            updated.await();\n\n            // are we closed?\n            if (isClosed) {\n              log.warn(\"OverseerTriggerThread woken up but we are closed, exiting.\");\n              break;\n            }\n\n            // spurious wakeup?\n            if (znodeVersion == lastZnodeVersion) continue;\n          }\n          copy = new HashMap<>(activeTriggers);\n          lastZnodeVersion = znodeVersion;\n          log.debug(\"Processed trigger updates upto znodeVersion {}\", znodeVersion);\n        } catch (InterruptedException e) {\n          // Restore the interrupted status\n          Thread.currentThread().interrupt();\n          log.warn(\"Interrupted\", e);\n          break;\n        } finally {\n          updateLock.unlock();\n        }\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        log.warn(\"Interrupted\", e);\n        break;\n      }\n\n      // update the current config\n      scheduledTriggers.setAutoScalingConfig(autoScalingConfig);\n\n      Set<String> managedTriggerNames = scheduledTriggers.getScheduledTriggerNames();\n      // remove the triggers which are no longer active\n      for (String managedTriggerName : managedTriggerNames) {\n        if (!copy.containsKey(managedTriggerName)) {\n          scheduledTriggers.remove(managedTriggerName);\n        }\n      }\n      // check for nodeLost triggers in the current config, and if\n      // absent then clean up old nodeLost / nodeAdded markers\n      boolean cleanOldNodeLostMarkers = true;\n      boolean cleanOldNodeAddedMarkers = true;\n      try {\n        // add new triggers and/or replace and close the replaced triggers\n        for (Map.Entry<String, AutoScaling.Trigger> entry : copy.entrySet()) {\n          if (entry.getValue().getEventType().equals(TriggerEventType.NODELOST)) {\n            cleanOldNodeLostMarkers = false;\n          }\n          if (entry.getValue().getEventType().equals(TriggerEventType.NODEADDED)) {\n            cleanOldNodeAddedMarkers = false;\n          }\n          scheduledTriggers.add(entry.getValue());\n        }\n      } catch (AlreadyClosedException e) {\n        // this _should_ mean that we're closing, complain loudly if that's not the case\n        if (isClosed) {\n          return;\n        } else {\n          throw new IllegalStateException(\"Caught AlreadyClosedException from ScheduledTriggers, but we're not closed yet!\", e);\n        }\n      }\n      DistribStateManager stateManager = cloudManager.getDistribStateManager();\n      if (cleanOldNodeLostMarkers) {\n        log.debug(\"-- clean old nodeLost markers\");\n        try {\n          List<String> markers = stateManager.listData(ZkStateReader.SOLR_AUTOSCALING_NODE_LOST_PATH);\n          markers.forEach(n -> {\n            removeNodeMarker(ZkStateReader.SOLR_AUTOSCALING_NODE_LOST_PATH, n);\n          });\n        } catch (NoSuchElementException e) {\n          // ignore\n        } catch (Exception e) {\n          log.warn(\"Error removing old nodeLost markers\", e);\n        }\n      }\n      if (cleanOldNodeAddedMarkers) {\n        log.debug(\"-- clean old nodeAdded markers\");\n        try {\n          List<String> markers = stateManager.listData(ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH);\n          markers.forEach(n -> {\n            removeNodeMarker(ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH, n);\n          });\n        } catch (NoSuchElementException e) {\n          // ignore\n        } catch (Exception e) {\n          log.warn(\"Error removing old nodeAdded markers\", e);\n        }\n\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  public void run() {\n    int lastZnodeVersion = znodeVersion;\n\n    // we automatically add a trigger for auto add replicas if it does not exists already\n    while (!isClosed)  {\n      try {\n        AutoScalingConfig autoScalingConfig = cloudManager.getDistribStateManager().getAutoScalingConfig();\n        AutoScalingConfig withAutoAddReplicasTrigger = withAutoAddReplicasTrigger(autoScalingConfig);\n        if (withAutoAddReplicasTrigger.equals(autoScalingConfig)) break;\n        log.debug(\"Adding .autoAddReplicas trigger\");\n        cloudManager.getDistribStateManager().setData(SOLR_AUTOSCALING_CONF_PATH, Utils.toJSON(withAutoAddReplicasTrigger), withAutoAddReplicasTrigger.getZkVersion());\n        break;\n      } catch (BadVersionException bve) {\n        // somebody else has changed the configuration so we must retry\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        log.warn(\"Interrupted\", e);\n        break;\n      } catch (IOException | KeeperException e) {\n        log.error(\"A ZK error has occurred\", e);\n      }\n    }\n\n    if (isClosed || Thread.currentThread().isInterrupted())  return;\n\n    try {\n      refreshAutoScalingConf(new AutoScalingWatcher());\n    } catch (ConnectException e) {\n      log.warn(\"ZooKeeper watch triggered for autoscaling conf, but Solr cannot talk to ZK: [{}]\", e.getMessage());\n    } catch (InterruptedException e) {\n      // Restore the interrupted status\n      Thread.currentThread().interrupt();\n      log.warn(\"Interrupted\", e);\n    } catch (Exception e)  {\n      log.error(\"Unexpected exception\", e);\n    }\n\n    while (true) {\n      Map<String, AutoScaling.Trigger> copy = null;\n      try {\n        // this can throw InterruptedException and we don't want to unlock if it did, so we keep this outside\n        // of the try/finally block\n        updateLock.lockInterruptibly();\n\n        // must check for close here before we await on the condition otherwise we can only be woken up on interruption\n        if (isClosed) {\n          log.warn(\"OverseerTriggerThread has been closed, exiting.\");\n          break;\n        }\n\n        log.debug(\"Current znodeVersion {}, lastZnodeVersion {}\", znodeVersion, lastZnodeVersion);\n\n        try {\n          if (znodeVersion == lastZnodeVersion) {\n            updated.await();\n\n            // are we closed?\n            if (isClosed) {\n              log.warn(\"OverseerTriggerThread woken up but we are closed, exiting.\");\n              break;\n            }\n\n            // spurious wakeup?\n            if (znodeVersion == lastZnodeVersion) continue;\n          }\n          copy = new HashMap<>(activeTriggers);\n          lastZnodeVersion = znodeVersion;\n          log.debug(\"Processed trigger updates upto znodeVersion {}\", znodeVersion);\n        } catch (InterruptedException e) {\n          // Restore the interrupted status\n          Thread.currentThread().interrupt();\n          log.warn(\"Interrupted\", e);\n          break;\n        } finally {\n          updateLock.unlock();\n        }\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        log.warn(\"Interrupted\", e);\n        break;\n      }\n\n      // update the current config\n      scheduledTriggers.setAutoScalingConfig(autoScalingConfig);\n\n      Set<String> managedTriggerNames = scheduledTriggers.getScheduledTriggerNames();\n      // remove the triggers which are no longer active\n      for (String managedTriggerName : managedTriggerNames) {\n        if (!copy.containsKey(managedTriggerName)) {\n          scheduledTriggers.remove(managedTriggerName);\n        }\n      }\n      // check for nodeLost triggers in the current config, and if\n      // absent then clean up old nodeLost / nodeAdded markers\n      boolean cleanOldNodeLostMarkers = true;\n      boolean cleanOldNodeAddedMarkers = true;\n      try {\n        // add new triggers and/or replace and close the replaced triggers\n        for (Map.Entry<String, AutoScaling.Trigger> entry : copy.entrySet()) {\n          if (entry.getValue().getEventType().equals(TriggerEventType.NODELOST)) {\n            cleanOldNodeLostMarkers = false;\n          }\n          if (entry.getValue().getEventType().equals(TriggerEventType.NODEADDED)) {\n            cleanOldNodeAddedMarkers = false;\n          }\n          scheduledTriggers.add(entry.getValue());\n        }\n      } catch (AlreadyClosedException e) {\n        // this _should_ mean that we're closing, complain loudly if that's not the case\n        if (isClosed) {\n          return;\n        } else {\n          throw new IllegalStateException(\"Caught AlreadyClosedException from ScheduledTriggers, but we're not closed yet!\", e);\n        }\n      }\n      DistribStateManager stateManager = cloudManager.getDistribStateManager();\n      if (cleanOldNodeLostMarkers) {\n        log.debug(\"-- clean old nodeLost markers\");\n        try {\n          List<String> markers = stateManager.listData(ZkStateReader.SOLR_AUTOSCALING_NODE_LOST_PATH);\n          markers.forEach(n -> {\n            removeNodeMarker(ZkStateReader.SOLR_AUTOSCALING_NODE_LOST_PATH, n);\n          });\n        } catch (NoSuchElementException e) {\n          // ignore\n        } catch (Exception e) {\n          log.warn(\"Error removing old nodeLost markers\", e);\n        }\n      }\n      if (cleanOldNodeAddedMarkers) {\n        log.debug(\"-- clean old nodeAdded markers\");\n        try {\n          List<String> markers = stateManager.listData(ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH);\n          markers.forEach(n -> {\n            removeNodeMarker(ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH, n);\n          });\n        } catch (NoSuchElementException e) {\n          // ignore\n        } catch (Exception e) {\n          log.warn(\"Error removing old nodeAdded markers\", e);\n        }\n\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"f5cada899191a744eac4b584b75dd3103c26a394","date":1522597038,"type":3,"author":"Mikhail Khludnev","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/autoscaling/OverseerTriggerThread#run().mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/autoscaling/OverseerTriggerThread#run().mjava","sourceNew":"  @Override\n  public void run() {\n    int lastZnodeVersion = znodeVersion;\n\n    // we automatically add a trigger for auto add replicas if it does not exists already\n    // we also automatically add a scheduled maintenance trigger\n    while (!isClosed)  {\n      try {\n        if (Thread.currentThread().isInterrupted()) {\n          log.warn(\"Interrupted\");\n          break;\n        }\n        AutoScalingConfig autoScalingConfig = cloudManager.getDistribStateManager().getAutoScalingConfig();\n        AutoScalingConfig updatedConfig = withAutoAddReplicasTrigger(autoScalingConfig);\n        updatedConfig = withScheduledMaintenanceTrigger(updatedConfig);\n        if (updatedConfig.equals(autoScalingConfig)) break;\n        log.debug(\"Adding .auto_add_replicas and .scheduled_maintenance triggers\");\n        cloudManager.getDistribStateManager().setData(SOLR_AUTOSCALING_CONF_PATH, Utils.toJSON(updatedConfig), updatedConfig.getZkVersion());\n        break;\n      } catch (BadVersionException bve) {\n        // somebody else has changed the configuration so we must retry\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        log.warn(\"Interrupted\", e);\n        break;\n      } catch (IOException | KeeperException e) {\n        log.error(\"A ZK error has occurred\", e);\n      }\n    }\n\n    if (isClosed || Thread.currentThread().isInterrupted())  return;\n\n    try {\n      refreshAutoScalingConf(new AutoScalingWatcher());\n    } catch (ConnectException e) {\n      log.warn(\"ZooKeeper watch triggered for autoscaling conf, but Solr cannot talk to ZK: [{}]\", e.getMessage());\n    } catch (InterruptedException e) {\n      // Restore the interrupted status\n      Thread.currentThread().interrupt();\n      log.warn(\"Interrupted\", e);\n    } catch (Exception e)  {\n      log.error(\"Unexpected exception\", e);\n    }\n\n    while (true) {\n      Map<String, AutoScaling.Trigger> copy = null;\n      try {\n        // this can throw InterruptedException and we don't want to unlock if it did, so we keep this outside\n        // of the try/finally block\n        updateLock.lockInterruptibly();\n\n        // must check for close here before we await on the condition otherwise we can only be woken up on interruption\n        if (isClosed) {\n          log.warn(\"OverseerTriggerThread has been closed, exiting.\");\n          break;\n        }\n\n        log.debug(\"Current znodeVersion {}, lastZnodeVersion {}\", znodeVersion, lastZnodeVersion);\n\n        try {\n          if (znodeVersion == lastZnodeVersion) {\n            updated.await();\n\n            // are we closed?\n            if (isClosed) {\n              log.warn(\"OverseerTriggerThread woken up but we are closed, exiting.\");\n              break;\n            }\n\n            // spurious wakeup?\n            if (znodeVersion == lastZnodeVersion) continue;\n          }\n          copy = new HashMap<>(activeTriggers);\n          lastZnodeVersion = znodeVersion;\n          log.debug(\"Processed trigger updates upto znodeVersion {}\", znodeVersion);\n        } catch (InterruptedException e) {\n          // Restore the interrupted status\n          Thread.currentThread().interrupt();\n          log.warn(\"Interrupted\", e);\n          break;\n        } finally {\n          updateLock.unlock();\n        }\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        log.warn(\"Interrupted\", e);\n        break;\n      }\n\n      // update the current config\n      scheduledTriggers.setAutoScalingConfig(autoScalingConfig);\n\n      Set<String> managedTriggerNames = scheduledTriggers.getScheduledTriggerNames();\n      // remove the triggers which are no longer active\n      for (String managedTriggerName : managedTriggerNames) {\n        if (!copy.containsKey(managedTriggerName)) {\n          scheduledTriggers.remove(managedTriggerName);\n        }\n      }\n      // check for nodeLost triggers in the current config, and if\n      // absent then clean up old nodeLost / nodeAdded markers\n      boolean cleanOldNodeLostMarkers = true;\n      boolean cleanOldNodeAddedMarkers = true;\n      try {\n        // add new triggers and/or replace and close the replaced triggers\n        for (Map.Entry<String, AutoScaling.Trigger> entry : copy.entrySet()) {\n          if (entry.getValue().getEventType().equals(TriggerEventType.NODELOST)) {\n            cleanOldNodeLostMarkers = false;\n          }\n          if (entry.getValue().getEventType().equals(TriggerEventType.NODEADDED)) {\n            cleanOldNodeAddedMarkers = false;\n          }\n          scheduledTriggers.add(entry.getValue());\n        }\n      } catch (AlreadyClosedException e) {\n        // this _should_ mean that we're closing, complain loudly if that's not the case\n        if (isClosed) {\n          return;\n        } else {\n          throw new IllegalStateException(\"Caught AlreadyClosedException from ScheduledTriggers, but we're not closed yet!\", e);\n        }\n      }\n      DistribStateManager stateManager = cloudManager.getDistribStateManager();\n      if (cleanOldNodeLostMarkers) {\n        log.debug(\"-- clean old nodeLost markers\");\n        try {\n          List<String> markers = stateManager.listData(ZkStateReader.SOLR_AUTOSCALING_NODE_LOST_PATH);\n          markers.forEach(n -> {\n            removeNodeMarker(ZkStateReader.SOLR_AUTOSCALING_NODE_LOST_PATH, n);\n          });\n        } catch (NoSuchElementException e) {\n          // ignore\n        } catch (Exception e) {\n          log.warn(\"Error removing old nodeLost markers\", e);\n        }\n      }\n      if (cleanOldNodeAddedMarkers) {\n        log.debug(\"-- clean old nodeAdded markers\");\n        try {\n          List<String> markers = stateManager.listData(ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH);\n          markers.forEach(n -> {\n            removeNodeMarker(ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH, n);\n          });\n        } catch (NoSuchElementException e) {\n          // ignore\n        } catch (Exception e) {\n          log.warn(\"Error removing old nodeAdded markers\", e);\n        }\n\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  public void run() {\n    int lastZnodeVersion = znodeVersion;\n\n    // we automatically add a trigger for auto add replicas if it does not exists already\n    // we also automatically add a scheduled maintenance trigger\n    while (!isClosed)  {\n      try {\n        AutoScalingConfig autoScalingConfig = cloudManager.getDistribStateManager().getAutoScalingConfig();\n        AutoScalingConfig updatedConfig = withAutoAddReplicasTrigger(autoScalingConfig);\n        updatedConfig = withScheduledMaintenanceTrigger(updatedConfig);\n        if (updatedConfig.equals(autoScalingConfig)) break;\n        log.debug(\"Adding .auto_add_replicas and .scheduled_maintenance triggers\");\n        cloudManager.getDistribStateManager().setData(SOLR_AUTOSCALING_CONF_PATH, Utils.toJSON(updatedConfig), updatedConfig.getZkVersion());\n        break;\n      } catch (BadVersionException bve) {\n        // somebody else has changed the configuration so we must retry\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        log.warn(\"Interrupted\", e);\n        break;\n      } catch (IOException | KeeperException e) {\n        log.error(\"A ZK error has occurred\", e);\n      }\n    }\n\n    if (isClosed || Thread.currentThread().isInterrupted())  return;\n\n    try {\n      refreshAutoScalingConf(new AutoScalingWatcher());\n    } catch (ConnectException e) {\n      log.warn(\"ZooKeeper watch triggered for autoscaling conf, but Solr cannot talk to ZK: [{}]\", e.getMessage());\n    } catch (InterruptedException e) {\n      // Restore the interrupted status\n      Thread.currentThread().interrupt();\n      log.warn(\"Interrupted\", e);\n    } catch (Exception e)  {\n      log.error(\"Unexpected exception\", e);\n    }\n\n    while (true) {\n      Map<String, AutoScaling.Trigger> copy = null;\n      try {\n        // this can throw InterruptedException and we don't want to unlock if it did, so we keep this outside\n        // of the try/finally block\n        updateLock.lockInterruptibly();\n\n        // must check for close here before we await on the condition otherwise we can only be woken up on interruption\n        if (isClosed) {\n          log.warn(\"OverseerTriggerThread has been closed, exiting.\");\n          break;\n        }\n\n        log.debug(\"Current znodeVersion {}, lastZnodeVersion {}\", znodeVersion, lastZnodeVersion);\n\n        try {\n          if (znodeVersion == lastZnodeVersion) {\n            updated.await();\n\n            // are we closed?\n            if (isClosed) {\n              log.warn(\"OverseerTriggerThread woken up but we are closed, exiting.\");\n              break;\n            }\n\n            // spurious wakeup?\n            if (znodeVersion == lastZnodeVersion) continue;\n          }\n          copy = new HashMap<>(activeTriggers);\n          lastZnodeVersion = znodeVersion;\n          log.debug(\"Processed trigger updates upto znodeVersion {}\", znodeVersion);\n        } catch (InterruptedException e) {\n          // Restore the interrupted status\n          Thread.currentThread().interrupt();\n          log.warn(\"Interrupted\", e);\n          break;\n        } finally {\n          updateLock.unlock();\n        }\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        log.warn(\"Interrupted\", e);\n        break;\n      }\n\n      // update the current config\n      scheduledTriggers.setAutoScalingConfig(autoScalingConfig);\n\n      Set<String> managedTriggerNames = scheduledTriggers.getScheduledTriggerNames();\n      // remove the triggers which are no longer active\n      for (String managedTriggerName : managedTriggerNames) {\n        if (!copy.containsKey(managedTriggerName)) {\n          scheduledTriggers.remove(managedTriggerName);\n        }\n      }\n      // check for nodeLost triggers in the current config, and if\n      // absent then clean up old nodeLost / nodeAdded markers\n      boolean cleanOldNodeLostMarkers = true;\n      boolean cleanOldNodeAddedMarkers = true;\n      try {\n        // add new triggers and/or replace and close the replaced triggers\n        for (Map.Entry<String, AutoScaling.Trigger> entry : copy.entrySet()) {\n          if (entry.getValue().getEventType().equals(TriggerEventType.NODELOST)) {\n            cleanOldNodeLostMarkers = false;\n          }\n          if (entry.getValue().getEventType().equals(TriggerEventType.NODEADDED)) {\n            cleanOldNodeAddedMarkers = false;\n          }\n          scheduledTriggers.add(entry.getValue());\n        }\n      } catch (AlreadyClosedException e) {\n        // this _should_ mean that we're closing, complain loudly if that's not the case\n        if (isClosed) {\n          return;\n        } else {\n          throw new IllegalStateException(\"Caught AlreadyClosedException from ScheduledTriggers, but we're not closed yet!\", e);\n        }\n      }\n      DistribStateManager stateManager = cloudManager.getDistribStateManager();\n      if (cleanOldNodeLostMarkers) {\n        log.debug(\"-- clean old nodeLost markers\");\n        try {\n          List<String> markers = stateManager.listData(ZkStateReader.SOLR_AUTOSCALING_NODE_LOST_PATH);\n          markers.forEach(n -> {\n            removeNodeMarker(ZkStateReader.SOLR_AUTOSCALING_NODE_LOST_PATH, n);\n          });\n        } catch (NoSuchElementException e) {\n          // ignore\n        } catch (Exception e) {\n          log.warn(\"Error removing old nodeLost markers\", e);\n        }\n      }\n      if (cleanOldNodeAddedMarkers) {\n        log.debug(\"-- clean old nodeAdded markers\");\n        try {\n          List<String> markers = stateManager.listData(ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH);\n          markers.forEach(n -> {\n            removeNodeMarker(ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH, n);\n          });\n        } catch (NoSuchElementException e) {\n          // ignore\n        } catch (Exception e) {\n          log.warn(\"Error removing old nodeAdded markers\", e);\n        }\n\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"cd44b11f5d211a0b76c6bc536f38d1eb1fe00c8d","date":1522763990,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/autoscaling/OverseerTriggerThread#run().mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/autoscaling/OverseerTriggerThread#run().mjava","sourceNew":"  @Override\n  public void run() {\n    int lastZnodeVersion = znodeVersion;\n\n    // we automatically add a trigger for auto add replicas if it does not exists already\n    // we also automatically add a scheduled maintenance trigger\n    while (!isClosed)  {\n      try {\n        if (Thread.currentThread().isInterrupted()) {\n          log.warn(\"Interrupted\");\n          break;\n        }\n        AutoScalingConfig autoScalingConfig = cloudManager.getDistribStateManager().getAutoScalingConfig();\n        AutoScalingConfig updatedConfig = withAutoAddReplicasTrigger(autoScalingConfig);\n        updatedConfig = withScheduledMaintenanceTrigger(updatedConfig);\n        if (updatedConfig.equals(autoScalingConfig)) break;\n        log.debug(\"Adding .auto_add_replicas and .scheduled_maintenance triggers\");\n        cloudManager.getDistribStateManager().setData(SOLR_AUTOSCALING_CONF_PATH, Utils.toJSON(updatedConfig), updatedConfig.getZkVersion());\n        break;\n      } catch (BadVersionException bve) {\n        // somebody else has changed the configuration so we must retry\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        log.warn(\"Interrupted\", e);\n        break;\n      } catch (IOException | KeeperException e) {\n        log.error(\"A ZK error has occurred\", e);\n      }\n    }\n\n    if (isClosed || Thread.currentThread().isInterrupted())  return;\n\n    try {\n      refreshAutoScalingConf(new AutoScalingWatcher());\n    } catch (ConnectException e) {\n      log.warn(\"ZooKeeper watch triggered for autoscaling conf, but Solr cannot talk to ZK: [{}]\", e.getMessage());\n    } catch (InterruptedException e) {\n      // Restore the interrupted status\n      Thread.currentThread().interrupt();\n      log.warn(\"Interrupted\", e);\n    } catch (Exception e)  {\n      log.error(\"Unexpected exception\", e);\n    }\n\n    while (true) {\n      Map<String, AutoScaling.Trigger> copy = null;\n      try {\n        // this can throw InterruptedException and we don't want to unlock if it did, so we keep this outside\n        // of the try/finally block\n        updateLock.lockInterruptibly();\n\n        // must check for close here before we await on the condition otherwise we can only be woken up on interruption\n        if (isClosed) {\n          log.warn(\"OverseerTriggerThread has been closed, exiting.\");\n          break;\n        }\n\n        log.debug(\"Current znodeVersion {}, lastZnodeVersion {}\", znodeVersion, lastZnodeVersion);\n\n        try {\n          if (znodeVersion == lastZnodeVersion) {\n            updated.await();\n\n            // are we closed?\n            if (isClosed) {\n              log.warn(\"OverseerTriggerThread woken up but we are closed, exiting.\");\n              break;\n            }\n\n            // spurious wakeup?\n            if (znodeVersion == lastZnodeVersion) continue;\n          }\n          copy = new HashMap<>(activeTriggers);\n          lastZnodeVersion = znodeVersion;\n          log.debug(\"Processed trigger updates upto znodeVersion {}\", znodeVersion);\n        } catch (InterruptedException e) {\n          // Restore the interrupted status\n          Thread.currentThread().interrupt();\n          log.warn(\"Interrupted\", e);\n          break;\n        } finally {\n          updateLock.unlock();\n        }\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        log.warn(\"Interrupted\", e);\n        break;\n      }\n\n      // update the current config\n      scheduledTriggers.setAutoScalingConfig(autoScalingConfig);\n\n      Set<String> managedTriggerNames = scheduledTriggers.getScheduledTriggerNames();\n      // remove the triggers which are no longer active\n      for (String managedTriggerName : managedTriggerNames) {\n        if (!copy.containsKey(managedTriggerName)) {\n          scheduledTriggers.remove(managedTriggerName);\n        }\n      }\n      // check for nodeLost triggers in the current config, and if\n      // absent then clean up old nodeLost / nodeAdded markers\n      boolean cleanOldNodeLostMarkers = true;\n      boolean cleanOldNodeAddedMarkers = true;\n      try {\n        // add new triggers and/or replace and close the replaced triggers\n        for (Map.Entry<String, AutoScaling.Trigger> entry : copy.entrySet()) {\n          if (entry.getValue().getEventType().equals(TriggerEventType.NODELOST)) {\n            cleanOldNodeLostMarkers = false;\n          }\n          if (entry.getValue().getEventType().equals(TriggerEventType.NODEADDED)) {\n            cleanOldNodeAddedMarkers = false;\n          }\n          try {\n            scheduledTriggers.add(entry.getValue());\n          } catch (Exception e) {\n            log.warn(\"Exception initializing trigger \" + entry.getKey() + \", configuration ignored\", e);\n          }\n        }\n      } catch (AlreadyClosedException e) {\n        // this _should_ mean that we're closing, complain loudly if that's not the case\n        if (isClosed) {\n          return;\n        } else {\n          throw new IllegalStateException(\"Caught AlreadyClosedException from ScheduledTriggers, but we're not closed yet!\", e);\n        }\n      }\n      DistribStateManager stateManager = cloudManager.getDistribStateManager();\n      if (cleanOldNodeLostMarkers) {\n        log.debug(\"-- clean old nodeLost markers\");\n        try {\n          List<String> markers = stateManager.listData(ZkStateReader.SOLR_AUTOSCALING_NODE_LOST_PATH);\n          markers.forEach(n -> {\n            removeNodeMarker(ZkStateReader.SOLR_AUTOSCALING_NODE_LOST_PATH, n);\n          });\n        } catch (NoSuchElementException e) {\n          // ignore\n        } catch (Exception e) {\n          log.warn(\"Error removing old nodeLost markers\", e);\n        }\n      }\n      if (cleanOldNodeAddedMarkers) {\n        log.debug(\"-- clean old nodeAdded markers\");\n        try {\n          List<String> markers = stateManager.listData(ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH);\n          markers.forEach(n -> {\n            removeNodeMarker(ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH, n);\n          });\n        } catch (NoSuchElementException e) {\n          // ignore\n        } catch (Exception e) {\n          log.warn(\"Error removing old nodeAdded markers\", e);\n        }\n\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  public void run() {\n    int lastZnodeVersion = znodeVersion;\n\n    // we automatically add a trigger for auto add replicas if it does not exists already\n    // we also automatically add a scheduled maintenance trigger\n    while (!isClosed)  {\n      try {\n        if (Thread.currentThread().isInterrupted()) {\n          log.warn(\"Interrupted\");\n          break;\n        }\n        AutoScalingConfig autoScalingConfig = cloudManager.getDistribStateManager().getAutoScalingConfig();\n        AutoScalingConfig updatedConfig = withAutoAddReplicasTrigger(autoScalingConfig);\n        updatedConfig = withScheduledMaintenanceTrigger(updatedConfig);\n        if (updatedConfig.equals(autoScalingConfig)) break;\n        log.debug(\"Adding .auto_add_replicas and .scheduled_maintenance triggers\");\n        cloudManager.getDistribStateManager().setData(SOLR_AUTOSCALING_CONF_PATH, Utils.toJSON(updatedConfig), updatedConfig.getZkVersion());\n        break;\n      } catch (BadVersionException bve) {\n        // somebody else has changed the configuration so we must retry\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        log.warn(\"Interrupted\", e);\n        break;\n      } catch (IOException | KeeperException e) {\n        log.error(\"A ZK error has occurred\", e);\n      }\n    }\n\n    if (isClosed || Thread.currentThread().isInterrupted())  return;\n\n    try {\n      refreshAutoScalingConf(new AutoScalingWatcher());\n    } catch (ConnectException e) {\n      log.warn(\"ZooKeeper watch triggered for autoscaling conf, but Solr cannot talk to ZK: [{}]\", e.getMessage());\n    } catch (InterruptedException e) {\n      // Restore the interrupted status\n      Thread.currentThread().interrupt();\n      log.warn(\"Interrupted\", e);\n    } catch (Exception e)  {\n      log.error(\"Unexpected exception\", e);\n    }\n\n    while (true) {\n      Map<String, AutoScaling.Trigger> copy = null;\n      try {\n        // this can throw InterruptedException and we don't want to unlock if it did, so we keep this outside\n        // of the try/finally block\n        updateLock.lockInterruptibly();\n\n        // must check for close here before we await on the condition otherwise we can only be woken up on interruption\n        if (isClosed) {\n          log.warn(\"OverseerTriggerThread has been closed, exiting.\");\n          break;\n        }\n\n        log.debug(\"Current znodeVersion {}, lastZnodeVersion {}\", znodeVersion, lastZnodeVersion);\n\n        try {\n          if (znodeVersion == lastZnodeVersion) {\n            updated.await();\n\n            // are we closed?\n            if (isClosed) {\n              log.warn(\"OverseerTriggerThread woken up but we are closed, exiting.\");\n              break;\n            }\n\n            // spurious wakeup?\n            if (znodeVersion == lastZnodeVersion) continue;\n          }\n          copy = new HashMap<>(activeTriggers);\n          lastZnodeVersion = znodeVersion;\n          log.debug(\"Processed trigger updates upto znodeVersion {}\", znodeVersion);\n        } catch (InterruptedException e) {\n          // Restore the interrupted status\n          Thread.currentThread().interrupt();\n          log.warn(\"Interrupted\", e);\n          break;\n        } finally {\n          updateLock.unlock();\n        }\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        log.warn(\"Interrupted\", e);\n        break;\n      }\n\n      // update the current config\n      scheduledTriggers.setAutoScalingConfig(autoScalingConfig);\n\n      Set<String> managedTriggerNames = scheduledTriggers.getScheduledTriggerNames();\n      // remove the triggers which are no longer active\n      for (String managedTriggerName : managedTriggerNames) {\n        if (!copy.containsKey(managedTriggerName)) {\n          scheduledTriggers.remove(managedTriggerName);\n        }\n      }\n      // check for nodeLost triggers in the current config, and if\n      // absent then clean up old nodeLost / nodeAdded markers\n      boolean cleanOldNodeLostMarkers = true;\n      boolean cleanOldNodeAddedMarkers = true;\n      try {\n        // add new triggers and/or replace and close the replaced triggers\n        for (Map.Entry<String, AutoScaling.Trigger> entry : copy.entrySet()) {\n          if (entry.getValue().getEventType().equals(TriggerEventType.NODELOST)) {\n            cleanOldNodeLostMarkers = false;\n          }\n          if (entry.getValue().getEventType().equals(TriggerEventType.NODEADDED)) {\n            cleanOldNodeAddedMarkers = false;\n          }\n          scheduledTriggers.add(entry.getValue());\n        }\n      } catch (AlreadyClosedException e) {\n        // this _should_ mean that we're closing, complain loudly if that's not the case\n        if (isClosed) {\n          return;\n        } else {\n          throw new IllegalStateException(\"Caught AlreadyClosedException from ScheduledTriggers, but we're not closed yet!\", e);\n        }\n      }\n      DistribStateManager stateManager = cloudManager.getDistribStateManager();\n      if (cleanOldNodeLostMarkers) {\n        log.debug(\"-- clean old nodeLost markers\");\n        try {\n          List<String> markers = stateManager.listData(ZkStateReader.SOLR_AUTOSCALING_NODE_LOST_PATH);\n          markers.forEach(n -> {\n            removeNodeMarker(ZkStateReader.SOLR_AUTOSCALING_NODE_LOST_PATH, n);\n          });\n        } catch (NoSuchElementException e) {\n          // ignore\n        } catch (Exception e) {\n          log.warn(\"Error removing old nodeLost markers\", e);\n        }\n      }\n      if (cleanOldNodeAddedMarkers) {\n        log.debug(\"-- clean old nodeAdded markers\");\n        try {\n          List<String> markers = stateManager.listData(ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH);\n          markers.forEach(n -> {\n            removeNodeMarker(ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH, n);\n          });\n        } catch (NoSuchElementException e) {\n          // ignore\n        } catch (Exception e) {\n          log.warn(\"Error removing old nodeAdded markers\", e);\n        }\n\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"dfc7ed9ce80483ee93bdefc775dae05360f20f4b","date":1526114272,"type":3,"author":"Mikhail Khludnev","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/autoscaling/OverseerTriggerThread#run().mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/autoscaling/OverseerTriggerThread#run().mjava","sourceNew":"  @Override\n  public void run() {\n    int lastZnodeVersion = znodeVersion;\n\n    // we automatically add a trigger for auto add replicas if it does not exists already\n    // we also automatically add a scheduled maintenance trigger\n    while (!isClosed)  {\n      try {\n        if (Thread.currentThread().isInterrupted()) {\n          log.warn(\"Interrupted\");\n          break;\n        }\n        AutoScalingConfig autoScalingConfig = cloudManager.getDistribStateManager().getAutoScalingConfig();\n        AutoScalingConfig updatedConfig = withAutoAddReplicasTrigger(autoScalingConfig);\n        updatedConfig = withScheduledMaintenanceTrigger(updatedConfig);\n        if (updatedConfig.equals(autoScalingConfig)) break;\n        log.debug(\"Adding .auto_add_replicas and .scheduled_maintenance triggers\");\n        cloudManager.getDistribStateManager().setData(SOLR_AUTOSCALING_CONF_PATH, Utils.toJSON(updatedConfig), updatedConfig.getZkVersion());\n        break;\n      } catch (BadVersionException bve) {\n        // somebody else has changed the configuration so we must retry\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        log.warn(\"Interrupted\", e);\n        break;\n      }\n      catch (IOException | KeeperException e) {\n        if (e instanceof KeeperException.SessionExpiredException ||\n            (e.getCause()!=null && e.getCause() instanceof KeeperException.SessionExpiredException)) {\n          log.warn(\"Solr cannot talk to ZK, exiting \" + \n              getClass().getSimpleName() + \" main queue loop\", e);\n          return;\n        } else {\n          log.error(\"A ZK error has occurred\", e);\n        }\n      }\n    }\n\n    if (isClosed || Thread.currentThread().isInterrupted())  return;\n\n    try {\n      refreshAutoScalingConf(new AutoScalingWatcher());\n    } catch (ConnectException e) {\n      log.warn(\"ZooKeeper watch triggered for autoscaling conf, but Solr cannot talk to ZK: [{}]\", e.getMessage());\n    } catch (InterruptedException e) {\n      // Restore the interrupted status\n      Thread.currentThread().interrupt();\n      log.warn(\"Interrupted\", e);\n    } catch (Exception e)  {\n      log.error(\"Unexpected exception\", e);\n    }\n\n    while (true) {\n      Map<String, AutoScaling.Trigger> copy = null;\n      try {\n        // this can throw InterruptedException and we don't want to unlock if it did, so we keep this outside\n        // of the try/finally block\n        updateLock.lockInterruptibly();\n\n        // must check for close here before we await on the condition otherwise we can only be woken up on interruption\n        if (isClosed) {\n          log.warn(\"OverseerTriggerThread has been closed, exiting.\");\n          break;\n        }\n\n        log.debug(\"Current znodeVersion {}, lastZnodeVersion {}\", znodeVersion, lastZnodeVersion);\n\n        try {\n          if (znodeVersion == lastZnodeVersion) {\n            updated.await();\n\n            // are we closed?\n            if (isClosed) {\n              log.warn(\"OverseerTriggerThread woken up but we are closed, exiting.\");\n              break;\n            }\n\n            // spurious wakeup?\n            if (znodeVersion == lastZnodeVersion) continue;\n          }\n          copy = new HashMap<>(activeTriggers);\n          lastZnodeVersion = znodeVersion;\n          log.debug(\"Processed trigger updates upto znodeVersion {}\", znodeVersion);\n        } catch (InterruptedException e) {\n          // Restore the interrupted status\n          Thread.currentThread().interrupt();\n          log.warn(\"Interrupted\", e);\n          break;\n        } finally {\n          updateLock.unlock();\n        }\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        log.warn(\"Interrupted\", e);\n        break;\n      }\n\n      // update the current config\n      scheduledTriggers.setAutoScalingConfig(autoScalingConfig);\n\n      Set<String> managedTriggerNames = scheduledTriggers.getScheduledTriggerNames();\n      // remove the triggers which are no longer active\n      for (String managedTriggerName : managedTriggerNames) {\n        if (!copy.containsKey(managedTriggerName)) {\n          scheduledTriggers.remove(managedTriggerName);\n        }\n      }\n      // check for nodeLost triggers in the current config, and if\n      // absent then clean up old nodeLost / nodeAdded markers\n      boolean cleanOldNodeLostMarkers = true;\n      boolean cleanOldNodeAddedMarkers = true;\n      try {\n        // add new triggers and/or replace and close the replaced triggers\n        for (Map.Entry<String, AutoScaling.Trigger> entry : copy.entrySet()) {\n          if (entry.getValue().getEventType().equals(TriggerEventType.NODELOST)) {\n            cleanOldNodeLostMarkers = false;\n          }\n          if (entry.getValue().getEventType().equals(TriggerEventType.NODEADDED)) {\n            cleanOldNodeAddedMarkers = false;\n          }\n          try {\n            scheduledTriggers.add(entry.getValue());\n          } catch (Exception e) {\n            log.warn(\"Exception initializing trigger \" + entry.getKey() + \", configuration ignored\", e);\n          }\n        }\n      } catch (AlreadyClosedException e) {\n        // this _should_ mean that we're closing, complain loudly if that's not the case\n        if (isClosed) {\n          return;\n        } else {\n          throw new IllegalStateException(\"Caught AlreadyClosedException from ScheduledTriggers, but we're not closed yet!\", e);\n        }\n      }\n      DistribStateManager stateManager = cloudManager.getDistribStateManager();\n      if (cleanOldNodeLostMarkers) {\n        log.debug(\"-- clean old nodeLost markers\");\n        try {\n          List<String> markers = stateManager.listData(ZkStateReader.SOLR_AUTOSCALING_NODE_LOST_PATH);\n          markers.forEach(n -> {\n            removeNodeMarker(ZkStateReader.SOLR_AUTOSCALING_NODE_LOST_PATH, n);\n          });\n        } catch (NoSuchElementException e) {\n          // ignore\n        } catch (Exception e) {\n          log.warn(\"Error removing old nodeLost markers\", e);\n        }\n      }\n      if (cleanOldNodeAddedMarkers) {\n        log.debug(\"-- clean old nodeAdded markers\");\n        try {\n          List<String> markers = stateManager.listData(ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH);\n          markers.forEach(n -> {\n            removeNodeMarker(ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH, n);\n          });\n        } catch (NoSuchElementException e) {\n          // ignore\n        } catch (Exception e) {\n          log.warn(\"Error removing old nodeAdded markers\", e);\n        }\n\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  public void run() {\n    int lastZnodeVersion = znodeVersion;\n\n    // we automatically add a trigger for auto add replicas if it does not exists already\n    // we also automatically add a scheduled maintenance trigger\n    while (!isClosed)  {\n      try {\n        if (Thread.currentThread().isInterrupted()) {\n          log.warn(\"Interrupted\");\n          break;\n        }\n        AutoScalingConfig autoScalingConfig = cloudManager.getDistribStateManager().getAutoScalingConfig();\n        AutoScalingConfig updatedConfig = withAutoAddReplicasTrigger(autoScalingConfig);\n        updatedConfig = withScheduledMaintenanceTrigger(updatedConfig);\n        if (updatedConfig.equals(autoScalingConfig)) break;\n        log.debug(\"Adding .auto_add_replicas and .scheduled_maintenance triggers\");\n        cloudManager.getDistribStateManager().setData(SOLR_AUTOSCALING_CONF_PATH, Utils.toJSON(updatedConfig), updatedConfig.getZkVersion());\n        break;\n      } catch (BadVersionException bve) {\n        // somebody else has changed the configuration so we must retry\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        log.warn(\"Interrupted\", e);\n        break;\n      } catch (IOException | KeeperException e) {\n        log.error(\"A ZK error has occurred\", e);\n      }\n    }\n\n    if (isClosed || Thread.currentThread().isInterrupted())  return;\n\n    try {\n      refreshAutoScalingConf(new AutoScalingWatcher());\n    } catch (ConnectException e) {\n      log.warn(\"ZooKeeper watch triggered for autoscaling conf, but Solr cannot talk to ZK: [{}]\", e.getMessage());\n    } catch (InterruptedException e) {\n      // Restore the interrupted status\n      Thread.currentThread().interrupt();\n      log.warn(\"Interrupted\", e);\n    } catch (Exception e)  {\n      log.error(\"Unexpected exception\", e);\n    }\n\n    while (true) {\n      Map<String, AutoScaling.Trigger> copy = null;\n      try {\n        // this can throw InterruptedException and we don't want to unlock if it did, so we keep this outside\n        // of the try/finally block\n        updateLock.lockInterruptibly();\n\n        // must check for close here before we await on the condition otherwise we can only be woken up on interruption\n        if (isClosed) {\n          log.warn(\"OverseerTriggerThread has been closed, exiting.\");\n          break;\n        }\n\n        log.debug(\"Current znodeVersion {}, lastZnodeVersion {}\", znodeVersion, lastZnodeVersion);\n\n        try {\n          if (znodeVersion == lastZnodeVersion) {\n            updated.await();\n\n            // are we closed?\n            if (isClosed) {\n              log.warn(\"OverseerTriggerThread woken up but we are closed, exiting.\");\n              break;\n            }\n\n            // spurious wakeup?\n            if (znodeVersion == lastZnodeVersion) continue;\n          }\n          copy = new HashMap<>(activeTriggers);\n          lastZnodeVersion = znodeVersion;\n          log.debug(\"Processed trigger updates upto znodeVersion {}\", znodeVersion);\n        } catch (InterruptedException e) {\n          // Restore the interrupted status\n          Thread.currentThread().interrupt();\n          log.warn(\"Interrupted\", e);\n          break;\n        } finally {\n          updateLock.unlock();\n        }\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        log.warn(\"Interrupted\", e);\n        break;\n      }\n\n      // update the current config\n      scheduledTriggers.setAutoScalingConfig(autoScalingConfig);\n\n      Set<String> managedTriggerNames = scheduledTriggers.getScheduledTriggerNames();\n      // remove the triggers which are no longer active\n      for (String managedTriggerName : managedTriggerNames) {\n        if (!copy.containsKey(managedTriggerName)) {\n          scheduledTriggers.remove(managedTriggerName);\n        }\n      }\n      // check for nodeLost triggers in the current config, and if\n      // absent then clean up old nodeLost / nodeAdded markers\n      boolean cleanOldNodeLostMarkers = true;\n      boolean cleanOldNodeAddedMarkers = true;\n      try {\n        // add new triggers and/or replace and close the replaced triggers\n        for (Map.Entry<String, AutoScaling.Trigger> entry : copy.entrySet()) {\n          if (entry.getValue().getEventType().equals(TriggerEventType.NODELOST)) {\n            cleanOldNodeLostMarkers = false;\n          }\n          if (entry.getValue().getEventType().equals(TriggerEventType.NODEADDED)) {\n            cleanOldNodeAddedMarkers = false;\n          }\n          try {\n            scheduledTriggers.add(entry.getValue());\n          } catch (Exception e) {\n            log.warn(\"Exception initializing trigger \" + entry.getKey() + \", configuration ignored\", e);\n          }\n        }\n      } catch (AlreadyClosedException e) {\n        // this _should_ mean that we're closing, complain loudly if that's not the case\n        if (isClosed) {\n          return;\n        } else {\n          throw new IllegalStateException(\"Caught AlreadyClosedException from ScheduledTriggers, but we're not closed yet!\", e);\n        }\n      }\n      DistribStateManager stateManager = cloudManager.getDistribStateManager();\n      if (cleanOldNodeLostMarkers) {\n        log.debug(\"-- clean old nodeLost markers\");\n        try {\n          List<String> markers = stateManager.listData(ZkStateReader.SOLR_AUTOSCALING_NODE_LOST_PATH);\n          markers.forEach(n -> {\n            removeNodeMarker(ZkStateReader.SOLR_AUTOSCALING_NODE_LOST_PATH, n);\n          });\n        } catch (NoSuchElementException e) {\n          // ignore\n        } catch (Exception e) {\n          log.warn(\"Error removing old nodeLost markers\", e);\n        }\n      }\n      if (cleanOldNodeAddedMarkers) {\n        log.debug(\"-- clean old nodeAdded markers\");\n        try {\n          List<String> markers = stateManager.listData(ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH);\n          markers.forEach(n -> {\n            removeNodeMarker(ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH, n);\n          });\n        } catch (NoSuchElementException e) {\n          // ignore\n        } catch (Exception e) {\n          log.warn(\"Error removing old nodeAdded markers\", e);\n        }\n\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"bb222a3f9d9421d5c95afce73013fbd8de07ea1f","date":1543514331,"type":3,"author":"markrmiller","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/autoscaling/OverseerTriggerThread#run().mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/autoscaling/OverseerTriggerThread#run().mjava","sourceNew":"  @Override\n  public void run() {\n    int lastZnodeVersion = znodeVersion;\n\n    // we automatically add a trigger for auto add replicas if it does not exists already\n    // we also automatically add a scheduled maintenance trigger\n    while (!isClosed)  {\n      try {\n        if (Thread.currentThread().isInterrupted()) {\n          log.warn(\"Interrupted\");\n          break;\n        }\n        AutoScalingConfig autoScalingConfig = cloudManager.getDistribStateManager().getAutoScalingConfig();\n        AutoScalingConfig updatedConfig = withAutoAddReplicasTrigger(autoScalingConfig);\n        updatedConfig = withScheduledMaintenanceTrigger(updatedConfig);\n        if (updatedConfig.equals(autoScalingConfig)) break;\n        log.debug(\"Adding .auto_add_replicas and .scheduled_maintenance triggers\");\n        cloudManager.getDistribStateManager().setData(SOLR_AUTOSCALING_CONF_PATH, Utils.toJSON(updatedConfig), updatedConfig.getZkVersion());\n        break;\n      } catch (AlreadyClosedException e) {\n        break;\n      } catch (BadVersionException bve) {\n        // somebody else has changed the configuration so we must retry\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        log.warn(\"Interrupted\", e);\n        break;\n      }\n      catch (IOException | KeeperException e) {\n        if (e instanceof KeeperException.SessionExpiredException ||\n            (e.getCause()!=null && e.getCause() instanceof KeeperException.SessionExpiredException)) {\n          log.warn(\"Solr cannot talk to ZK, exiting \" + \n              getClass().getSimpleName() + \" main queue loop\", e);\n          return;\n        } else {\n          log.error(\"A ZK error has occurred\", e);\n        }\n      }\n    }\n\n    if (isClosed || Thread.currentThread().isInterrupted())  return;\n\n    try {\n      refreshAutoScalingConf(new AutoScalingWatcher());\n    } catch (ConnectException e) {\n      log.warn(\"ZooKeeper watch triggered for autoscaling conf, but Solr cannot talk to ZK: [{}]\", e.getMessage());\n    } catch (InterruptedException e) {\n      // Restore the interrupted status\n      Thread.currentThread().interrupt();\n      log.warn(\"Interrupted\", e);\n    } catch (Exception e)  {\n      log.error(\"Unexpected exception\", e);\n    }\n\n    while (true) {\n      Map<String, AutoScaling.Trigger> copy = null;\n      try {\n        // this can throw InterruptedException and we don't want to unlock if it did, so we keep this outside\n        // of the try/finally block\n        updateLock.lockInterruptibly();\n\n        // must check for close here before we await on the condition otherwise we can only be woken up on interruption\n        if (isClosed) {\n          log.info(\"OverseerTriggerThread has been closed, exiting.\");\n          break;\n        }\n\n        log.debug(\"Current znodeVersion {}, lastZnodeVersion {}\", znodeVersion, lastZnodeVersion);\n\n        try {\n          if (znodeVersion == lastZnodeVersion) {\n            updated.await();\n\n            // are we closed?\n            if (isClosed) {\n              log.info(\"OverseerTriggerThread woken up but we are closed, exiting.\");\n              break;\n            }\n\n            // spurious wakeup?\n            if (znodeVersion == lastZnodeVersion) continue;\n          }\n          copy = new HashMap<>(activeTriggers);\n          lastZnodeVersion = znodeVersion;\n          log.debug(\"Processed trigger updates upto znodeVersion {}\", znodeVersion);\n        } catch (InterruptedException e) {\n          // Restore the interrupted status\n          Thread.currentThread().interrupt();\n          log.warn(\"Interrupted\", e);\n          break;\n        } finally {\n          updateLock.unlock();\n        }\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        break;\n      }\n\n      // update the current config\n      scheduledTriggers.setAutoScalingConfig(autoScalingConfig);\n\n      Set<String> managedTriggerNames = scheduledTriggers.getScheduledTriggerNames();\n      // remove the triggers which are no longer active\n      for (String managedTriggerName : managedTriggerNames) {\n        if (!copy.containsKey(managedTriggerName)) {\n          scheduledTriggers.remove(managedTriggerName);\n        }\n      }\n      // check for nodeLost triggers in the current config, and if\n      // absent then clean up old nodeLost / nodeAdded markers\n      boolean cleanOldNodeLostMarkers = true;\n      boolean cleanOldNodeAddedMarkers = true;\n      try {\n        // add new triggers and/or replace and close the replaced triggers\n        for (Map.Entry<String, AutoScaling.Trigger> entry : copy.entrySet()) {\n          if (entry.getValue().getEventType().equals(TriggerEventType.NODELOST)) {\n            cleanOldNodeLostMarkers = false;\n          }\n          if (entry.getValue().getEventType().equals(TriggerEventType.NODEADDED)) {\n            cleanOldNodeAddedMarkers = false;\n          }\n          try {\n            scheduledTriggers.add(entry.getValue());\n          } catch (AlreadyClosedException e) {\n\n          } catch (Exception e) {\n            log.warn(\"Exception initializing trigger \" + entry.getKey() + \", configuration ignored\", e);\n          }\n        }\n      } catch (AlreadyClosedException e) {\n        // this _should_ mean that we're closing, complain loudly if that's not the case\n        if (isClosed) {\n          return;\n        } else {\n          throw new IllegalStateException(\"Caught AlreadyClosedException from ScheduledTriggers, but we're not closed yet!\", e);\n        }\n      }\n      DistribStateManager stateManager = cloudManager.getDistribStateManager();\n      if (cleanOldNodeLostMarkers) {\n        log.debug(\"-- clean old nodeLost markers\");\n        try {\n          List<String> markers = stateManager.listData(ZkStateReader.SOLR_AUTOSCALING_NODE_LOST_PATH);\n          markers.forEach(n -> {\n            removeNodeMarker(ZkStateReader.SOLR_AUTOSCALING_NODE_LOST_PATH, n);\n          });\n        } catch (NoSuchElementException e) {\n          // ignore\n        } catch (Exception e) {\n          log.warn(\"Error removing old nodeLost markers\", e);\n        }\n      }\n      if (cleanOldNodeAddedMarkers) {\n        log.debug(\"-- clean old nodeAdded markers\");\n        try {\n          List<String> markers = stateManager.listData(ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH);\n          markers.forEach(n -> {\n            removeNodeMarker(ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH, n);\n          });\n        } catch (NoSuchElementException e) {\n          // ignore\n        } catch (AlreadyClosedException e) {\n\n        } catch (Exception e) {\n          log.warn(\"Error removing old nodeAdded markers\", e);\n        }\n\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  public void run() {\n    int lastZnodeVersion = znodeVersion;\n\n    // we automatically add a trigger for auto add replicas if it does not exists already\n    // we also automatically add a scheduled maintenance trigger\n    while (!isClosed)  {\n      try {\n        if (Thread.currentThread().isInterrupted()) {\n          log.warn(\"Interrupted\");\n          break;\n        }\n        AutoScalingConfig autoScalingConfig = cloudManager.getDistribStateManager().getAutoScalingConfig();\n        AutoScalingConfig updatedConfig = withAutoAddReplicasTrigger(autoScalingConfig);\n        updatedConfig = withScheduledMaintenanceTrigger(updatedConfig);\n        if (updatedConfig.equals(autoScalingConfig)) break;\n        log.debug(\"Adding .auto_add_replicas and .scheduled_maintenance triggers\");\n        cloudManager.getDistribStateManager().setData(SOLR_AUTOSCALING_CONF_PATH, Utils.toJSON(updatedConfig), updatedConfig.getZkVersion());\n        break;\n      } catch (BadVersionException bve) {\n        // somebody else has changed the configuration so we must retry\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        log.warn(\"Interrupted\", e);\n        break;\n      }\n      catch (IOException | KeeperException e) {\n        if (e instanceof KeeperException.SessionExpiredException ||\n            (e.getCause()!=null && e.getCause() instanceof KeeperException.SessionExpiredException)) {\n          log.warn(\"Solr cannot talk to ZK, exiting \" + \n              getClass().getSimpleName() + \" main queue loop\", e);\n          return;\n        } else {\n          log.error(\"A ZK error has occurred\", e);\n        }\n      }\n    }\n\n    if (isClosed || Thread.currentThread().isInterrupted())  return;\n\n    try {\n      refreshAutoScalingConf(new AutoScalingWatcher());\n    } catch (ConnectException e) {\n      log.warn(\"ZooKeeper watch triggered for autoscaling conf, but Solr cannot talk to ZK: [{}]\", e.getMessage());\n    } catch (InterruptedException e) {\n      // Restore the interrupted status\n      Thread.currentThread().interrupt();\n      log.warn(\"Interrupted\", e);\n    } catch (Exception e)  {\n      log.error(\"Unexpected exception\", e);\n    }\n\n    while (true) {\n      Map<String, AutoScaling.Trigger> copy = null;\n      try {\n        // this can throw InterruptedException and we don't want to unlock if it did, so we keep this outside\n        // of the try/finally block\n        updateLock.lockInterruptibly();\n\n        // must check for close here before we await on the condition otherwise we can only be woken up on interruption\n        if (isClosed) {\n          log.warn(\"OverseerTriggerThread has been closed, exiting.\");\n          break;\n        }\n\n        log.debug(\"Current znodeVersion {}, lastZnodeVersion {}\", znodeVersion, lastZnodeVersion);\n\n        try {\n          if (znodeVersion == lastZnodeVersion) {\n            updated.await();\n\n            // are we closed?\n            if (isClosed) {\n              log.warn(\"OverseerTriggerThread woken up but we are closed, exiting.\");\n              break;\n            }\n\n            // spurious wakeup?\n            if (znodeVersion == lastZnodeVersion) continue;\n          }\n          copy = new HashMap<>(activeTriggers);\n          lastZnodeVersion = znodeVersion;\n          log.debug(\"Processed trigger updates upto znodeVersion {}\", znodeVersion);\n        } catch (InterruptedException e) {\n          // Restore the interrupted status\n          Thread.currentThread().interrupt();\n          log.warn(\"Interrupted\", e);\n          break;\n        } finally {\n          updateLock.unlock();\n        }\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        log.warn(\"Interrupted\", e);\n        break;\n      }\n\n      // update the current config\n      scheduledTriggers.setAutoScalingConfig(autoScalingConfig);\n\n      Set<String> managedTriggerNames = scheduledTriggers.getScheduledTriggerNames();\n      // remove the triggers which are no longer active\n      for (String managedTriggerName : managedTriggerNames) {\n        if (!copy.containsKey(managedTriggerName)) {\n          scheduledTriggers.remove(managedTriggerName);\n        }\n      }\n      // check for nodeLost triggers in the current config, and if\n      // absent then clean up old nodeLost / nodeAdded markers\n      boolean cleanOldNodeLostMarkers = true;\n      boolean cleanOldNodeAddedMarkers = true;\n      try {\n        // add new triggers and/or replace and close the replaced triggers\n        for (Map.Entry<String, AutoScaling.Trigger> entry : copy.entrySet()) {\n          if (entry.getValue().getEventType().equals(TriggerEventType.NODELOST)) {\n            cleanOldNodeLostMarkers = false;\n          }\n          if (entry.getValue().getEventType().equals(TriggerEventType.NODEADDED)) {\n            cleanOldNodeAddedMarkers = false;\n          }\n          try {\n            scheduledTriggers.add(entry.getValue());\n          } catch (Exception e) {\n            log.warn(\"Exception initializing trigger \" + entry.getKey() + \", configuration ignored\", e);\n          }\n        }\n      } catch (AlreadyClosedException e) {\n        // this _should_ mean that we're closing, complain loudly if that's not the case\n        if (isClosed) {\n          return;\n        } else {\n          throw new IllegalStateException(\"Caught AlreadyClosedException from ScheduledTriggers, but we're not closed yet!\", e);\n        }\n      }\n      DistribStateManager stateManager = cloudManager.getDistribStateManager();\n      if (cleanOldNodeLostMarkers) {\n        log.debug(\"-- clean old nodeLost markers\");\n        try {\n          List<String> markers = stateManager.listData(ZkStateReader.SOLR_AUTOSCALING_NODE_LOST_PATH);\n          markers.forEach(n -> {\n            removeNodeMarker(ZkStateReader.SOLR_AUTOSCALING_NODE_LOST_PATH, n);\n          });\n        } catch (NoSuchElementException e) {\n          // ignore\n        } catch (Exception e) {\n          log.warn(\"Error removing old nodeLost markers\", e);\n        }\n      }\n      if (cleanOldNodeAddedMarkers) {\n        log.debug(\"-- clean old nodeAdded markers\");\n        try {\n          List<String> markers = stateManager.listData(ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH);\n          markers.forEach(n -> {\n            removeNodeMarker(ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH, n);\n          });\n        } catch (NoSuchElementException e) {\n          // ignore\n        } catch (Exception e) {\n          log.warn(\"Error removing old nodeAdded markers\", e);\n        }\n\n      }\n    }\n  }\n\n","bugFix":["7aa2c1715ef9a80383edea1048655da291ed9b8f","6ca81a50d0a6c6f97f1e2b15ef90c5bd81765d09"],"bugIntro":["9c787ffd984133d984d6b651ed48f0db5347aeac"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"f7fb1186f5b61e0b74289e6786df8cbecfa471bc","date":1545308188,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/autoscaling/OverseerTriggerThread#run().mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/autoscaling/OverseerTriggerThread#run().mjava","sourceNew":"  @Override\n  public void run() {\n    int lastZnodeVersion = znodeVersion;\n\n    // we automatically add a trigger for auto add replicas if it does not exists already\n    // we also automatically add a scheduled maintenance trigger\n    while (!isClosed)  {\n      try {\n        if (Thread.currentThread().isInterrupted()) {\n          log.warn(\"Interrupted\");\n          break;\n        }\n        AutoScalingConfig autoScalingConfig = cloudManager.getDistribStateManager().getAutoScalingConfig();\n        AutoScalingConfig updatedConfig = withAutoAddReplicasTrigger(autoScalingConfig);\n        updatedConfig = withScheduledMaintenanceTrigger(updatedConfig);\n        if (updatedConfig.equals(autoScalingConfig)) break;\n        log.debug(\"Adding .auto_add_replicas and .scheduled_maintenance triggers\");\n        cloudManager.getDistribStateManager().setData(SOLR_AUTOSCALING_CONF_PATH, Utils.toJSON(updatedConfig), updatedConfig.getZkVersion());\n        break;\n      } catch (AlreadyClosedException e) {\n        break;\n      } catch (BadVersionException bve) {\n        // somebody else has changed the configuration so we must retry\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        log.warn(\"Interrupted\", e);\n        break;\n      }\n      catch (IOException | KeeperException e) {\n        if (e instanceof KeeperException.SessionExpiredException ||\n            (e.getCause()!=null && e.getCause() instanceof KeeperException.SessionExpiredException)) {\n          log.warn(\"Solr cannot talk to ZK, exiting \" + \n              getClass().getSimpleName() + \" main queue loop\", e);\n          return;\n        } else {\n          log.error(\"A ZK error has occurred\", e);\n        }\n      }\n    }\n\n    if (isClosed || Thread.currentThread().isInterrupted())  return;\n\n    try {\n      refreshAutoScalingConf(new AutoScalingWatcher());\n    } catch (ConnectException e) {\n      log.warn(\"ZooKeeper watch triggered for autoscaling conf, but Solr cannot talk to ZK: [{}]\", e.getMessage());\n    } catch (InterruptedException e) {\n      // Restore the interrupted status\n      Thread.currentThread().interrupt();\n      log.warn(\"Interrupted\", e);\n    } catch (Exception e)  {\n      log.error(\"Unexpected exception\", e);\n    }\n\n    while (true) {\n      Map<String, AutoScaling.Trigger> copy = null;\n      try {\n        // this can throw InterruptedException and we don't want to unlock if it did, so we keep this outside\n        // of the try/finally block\n        updateLock.lockInterruptibly();\n\n        // must check for close here before we await on the condition otherwise we can only be woken up on interruption\n        if (isClosed) {\n          log.info(\"OverseerTriggerThread has been closed, exiting.\");\n          break;\n        }\n\n        log.debug(\"Current znodeVersion {}, lastZnodeVersion {}\", znodeVersion, lastZnodeVersion);\n\n        try {\n          if (znodeVersion == lastZnodeVersion) {\n            updated.await();\n\n            // are we closed?\n            if (isClosed) {\n              log.info(\"OverseerTriggerThread woken up but we are closed, exiting.\");\n              break;\n            }\n\n            // spurious wakeup?\n            if (znodeVersion == lastZnodeVersion) continue;\n          }\n          copy = new HashMap<>(activeTriggers);\n          lastZnodeVersion = znodeVersion;\n          log.debug(\"Processed trigger updates upto znodeVersion {}\", znodeVersion);\n        } catch (InterruptedException e) {\n          // Restore the interrupted status\n          Thread.currentThread().interrupt();\n          log.warn(\"Interrupted\", e);\n          break;\n        } finally {\n          updateLock.unlock();\n        }\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        break;\n      }\n\n      // update the current config\n      scheduledTriggers.setAutoScalingConfig(autoScalingConfig);\n\n      Set<String> managedTriggerNames = scheduledTriggers.getScheduledTriggerNames();\n      // remove the triggers which are no longer active\n      for (String managedTriggerName : managedTriggerNames) {\n        if (!copy.containsKey(managedTriggerName)) {\n          scheduledTriggers.remove(managedTriggerName);\n        }\n      }\n      // nodeLost / nodeAdded markers are checked by triggers during their init() call\n      // which is invoked in scheduledTriggers.add(), so once this is done we can remove them\n      try {\n        // add new triggers and/or replace and close the replaced triggers\n        for (Map.Entry<String, AutoScaling.Trigger> entry : copy.entrySet()) {\n          try {\n            scheduledTriggers.add(entry.getValue());\n          } catch (AlreadyClosedException e) {\n\n          } catch (Exception e) {\n            log.warn(\"Exception initializing trigger \" + entry.getKey() + \", configuration ignored\", e);\n          }\n        }\n      } catch (AlreadyClosedException e) {\n        // this _should_ mean that we're closing, complain loudly if that's not the case\n        if (isClosed) {\n          return;\n        } else {\n          throw new IllegalStateException(\"Caught AlreadyClosedException from ScheduledTriggers, but we're not closed yet!\", e);\n        }\n      }\n      log.debug(\"-- cleaning old nodeLost / nodeAdded markers\");\n      removeMarkers(ZkStateReader.SOLR_AUTOSCALING_NODE_LOST_PATH);\n      removeMarkers(ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH);\n    }\n  }\n\n","sourceOld":"  @Override\n  public void run() {\n    int lastZnodeVersion = znodeVersion;\n\n    // we automatically add a trigger for auto add replicas if it does not exists already\n    // we also automatically add a scheduled maintenance trigger\n    while (!isClosed)  {\n      try {\n        if (Thread.currentThread().isInterrupted()) {\n          log.warn(\"Interrupted\");\n          break;\n        }\n        AutoScalingConfig autoScalingConfig = cloudManager.getDistribStateManager().getAutoScalingConfig();\n        AutoScalingConfig updatedConfig = withAutoAddReplicasTrigger(autoScalingConfig);\n        updatedConfig = withScheduledMaintenanceTrigger(updatedConfig);\n        if (updatedConfig.equals(autoScalingConfig)) break;\n        log.debug(\"Adding .auto_add_replicas and .scheduled_maintenance triggers\");\n        cloudManager.getDistribStateManager().setData(SOLR_AUTOSCALING_CONF_PATH, Utils.toJSON(updatedConfig), updatedConfig.getZkVersion());\n        break;\n      } catch (AlreadyClosedException e) {\n        break;\n      } catch (BadVersionException bve) {\n        // somebody else has changed the configuration so we must retry\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        log.warn(\"Interrupted\", e);\n        break;\n      }\n      catch (IOException | KeeperException e) {\n        if (e instanceof KeeperException.SessionExpiredException ||\n            (e.getCause()!=null && e.getCause() instanceof KeeperException.SessionExpiredException)) {\n          log.warn(\"Solr cannot talk to ZK, exiting \" + \n              getClass().getSimpleName() + \" main queue loop\", e);\n          return;\n        } else {\n          log.error(\"A ZK error has occurred\", e);\n        }\n      }\n    }\n\n    if (isClosed || Thread.currentThread().isInterrupted())  return;\n\n    try {\n      refreshAutoScalingConf(new AutoScalingWatcher());\n    } catch (ConnectException e) {\n      log.warn(\"ZooKeeper watch triggered for autoscaling conf, but Solr cannot talk to ZK: [{}]\", e.getMessage());\n    } catch (InterruptedException e) {\n      // Restore the interrupted status\n      Thread.currentThread().interrupt();\n      log.warn(\"Interrupted\", e);\n    } catch (Exception e)  {\n      log.error(\"Unexpected exception\", e);\n    }\n\n    while (true) {\n      Map<String, AutoScaling.Trigger> copy = null;\n      try {\n        // this can throw InterruptedException and we don't want to unlock if it did, so we keep this outside\n        // of the try/finally block\n        updateLock.lockInterruptibly();\n\n        // must check for close here before we await on the condition otherwise we can only be woken up on interruption\n        if (isClosed) {\n          log.info(\"OverseerTriggerThread has been closed, exiting.\");\n          break;\n        }\n\n        log.debug(\"Current znodeVersion {}, lastZnodeVersion {}\", znodeVersion, lastZnodeVersion);\n\n        try {\n          if (znodeVersion == lastZnodeVersion) {\n            updated.await();\n\n            // are we closed?\n            if (isClosed) {\n              log.info(\"OverseerTriggerThread woken up but we are closed, exiting.\");\n              break;\n            }\n\n            // spurious wakeup?\n            if (znodeVersion == lastZnodeVersion) continue;\n          }\n          copy = new HashMap<>(activeTriggers);\n          lastZnodeVersion = znodeVersion;\n          log.debug(\"Processed trigger updates upto znodeVersion {}\", znodeVersion);\n        } catch (InterruptedException e) {\n          // Restore the interrupted status\n          Thread.currentThread().interrupt();\n          log.warn(\"Interrupted\", e);\n          break;\n        } finally {\n          updateLock.unlock();\n        }\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        break;\n      }\n\n      // update the current config\n      scheduledTriggers.setAutoScalingConfig(autoScalingConfig);\n\n      Set<String> managedTriggerNames = scheduledTriggers.getScheduledTriggerNames();\n      // remove the triggers which are no longer active\n      for (String managedTriggerName : managedTriggerNames) {\n        if (!copy.containsKey(managedTriggerName)) {\n          scheduledTriggers.remove(managedTriggerName);\n        }\n      }\n      // check for nodeLost triggers in the current config, and if\n      // absent then clean up old nodeLost / nodeAdded markers\n      boolean cleanOldNodeLostMarkers = true;\n      boolean cleanOldNodeAddedMarkers = true;\n      try {\n        // add new triggers and/or replace and close the replaced triggers\n        for (Map.Entry<String, AutoScaling.Trigger> entry : copy.entrySet()) {\n          if (entry.getValue().getEventType().equals(TriggerEventType.NODELOST)) {\n            cleanOldNodeLostMarkers = false;\n          }\n          if (entry.getValue().getEventType().equals(TriggerEventType.NODEADDED)) {\n            cleanOldNodeAddedMarkers = false;\n          }\n          try {\n            scheduledTriggers.add(entry.getValue());\n          } catch (AlreadyClosedException e) {\n\n          } catch (Exception e) {\n            log.warn(\"Exception initializing trigger \" + entry.getKey() + \", configuration ignored\", e);\n          }\n        }\n      } catch (AlreadyClosedException e) {\n        // this _should_ mean that we're closing, complain loudly if that's not the case\n        if (isClosed) {\n          return;\n        } else {\n          throw new IllegalStateException(\"Caught AlreadyClosedException from ScheduledTriggers, but we're not closed yet!\", e);\n        }\n      }\n      DistribStateManager stateManager = cloudManager.getDistribStateManager();\n      if (cleanOldNodeLostMarkers) {\n        log.debug(\"-- clean old nodeLost markers\");\n        try {\n          List<String> markers = stateManager.listData(ZkStateReader.SOLR_AUTOSCALING_NODE_LOST_PATH);\n          markers.forEach(n -> {\n            removeNodeMarker(ZkStateReader.SOLR_AUTOSCALING_NODE_LOST_PATH, n);\n          });\n        } catch (NoSuchElementException e) {\n          // ignore\n        } catch (Exception e) {\n          log.warn(\"Error removing old nodeLost markers\", e);\n        }\n      }\n      if (cleanOldNodeAddedMarkers) {\n        log.debug(\"-- clean old nodeAdded markers\");\n        try {\n          List<String> markers = stateManager.listData(ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH);\n          markers.forEach(n -> {\n            removeNodeMarker(ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH, n);\n          });\n        } catch (NoSuchElementException e) {\n          // ignore\n        } catch (AlreadyClosedException e) {\n\n        } catch (Exception e) {\n          log.warn(\"Error removing old nodeAdded markers\", e);\n        }\n\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":["98d4af357762468d37df7424f81785cd89b49a7b"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"35b336749840ccc5e7c88aa0a787fc6e3730d6e7","date":1546960615,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/autoscaling/OverseerTriggerThread#run().mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/autoscaling/OverseerTriggerThread#run().mjava","sourceNew":"  @Override\n  public void run() {\n    int lastZnodeVersion = znodeVersion;\n\n    // we automatically add a trigger for auto add replicas if it does not exists already\n    // we also automatically add a scheduled maintenance trigger\n    while (!isClosed)  {\n      try {\n        if (Thread.currentThread().isInterrupted()) {\n          log.warn(\"Interrupted\");\n          break;\n        }\n        AutoScalingConfig autoScalingConfig = cloudManager.getDistribStateManager().getAutoScalingConfig();\n        AutoScalingConfig updatedConfig = withAutoAddReplicasTrigger(autoScalingConfig);\n        updatedConfig = withScheduledMaintenanceTrigger(updatedConfig);\n        if (updatedConfig.equals(autoScalingConfig)) break;\n        log.debug(\"Adding .auto_add_replicas and .scheduled_maintenance triggers\");\n        cloudManager.getDistribStateManager().setData(SOLR_AUTOSCALING_CONF_PATH, Utils.toJSON(updatedConfig), updatedConfig.getZkVersion());\n        break;\n      } catch (AlreadyClosedException e) {\n        break;\n      } catch (BadVersionException bve) {\n        // somebody else has changed the configuration so we must retry\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        log.warn(\"Interrupted\", e);\n        break;\n      }\n      catch (IOException | KeeperException e) {\n        if (e instanceof KeeperException.SessionExpiredException ||\n            (e.getCause()!=null && e.getCause() instanceof KeeperException.SessionExpiredException)) {\n          log.warn(\"Solr cannot talk to ZK, exiting \" + \n              getClass().getSimpleName() + \" main queue loop\", e);\n          return;\n        } else {\n          log.error(\"A ZK error has occurred\", e);\n        }\n      }\n    }\n\n    if (isClosed || Thread.currentThread().isInterrupted())  return;\n\n    try {\n      refreshAutoScalingConf(new AutoScalingWatcher());\n    } catch (ConnectException e) {\n      log.warn(\"ZooKeeper watch triggered for autoscaling conf, but Solr cannot talk to ZK: [{}]\", e.getMessage());\n    } catch (InterruptedException e) {\n      // Restore the interrupted status\n      Thread.currentThread().interrupt();\n      log.warn(\"Interrupted\", e);\n    } catch (Exception e)  {\n      log.error(\"Unexpected exception\", e);\n    }\n\n    while (true) {\n      Map<String, AutoScaling.Trigger> copy = null;\n      try {\n        // this can throw InterruptedException and we don't want to unlock if it did, so we keep this outside\n        // of the try/finally block\n        updateLock.lockInterruptibly();\n\n        // must check for close here before we await on the condition otherwise we can only be woken up on interruption\n        if (isClosed) {\n          log.info(\"OverseerTriggerThread has been closed, exiting.\");\n          break;\n        }\n\n        log.debug(\"Current znodeVersion {}, lastZnodeVersion {}\", znodeVersion, lastZnodeVersion);\n\n        try {\n          if (znodeVersion == lastZnodeVersion) {\n            updated.await();\n\n            // are we closed?\n            if (isClosed) {\n              log.info(\"OverseerTriggerThread woken up but we are closed, exiting.\");\n              break;\n            }\n\n            // spurious wakeup?\n            if (znodeVersion == lastZnodeVersion) continue;\n          }\n          copy = new HashMap<>(activeTriggers);\n          lastZnodeVersion = znodeVersion;\n          log.debug(\"Processed trigger updates upto znodeVersion {}\", znodeVersion);\n        } catch (InterruptedException e) {\n          // Restore the interrupted status\n          Thread.currentThread().interrupt();\n          log.warn(\"Interrupted\", e);\n          break;\n        } finally {\n          updateLock.unlock();\n        }\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        break;\n      }\n\n      // update the current config\n      scheduledTriggers.setAutoScalingConfig(autoScalingConfig);\n\n      Set<String> managedTriggerNames = scheduledTriggers.getScheduledTriggerNames();\n      // remove the triggers which are no longer active\n      for (String managedTriggerName : managedTriggerNames) {\n        if (!copy.containsKey(managedTriggerName)) {\n          scheduledTriggers.remove(managedTriggerName);\n        }\n      }\n      // nodeLost / nodeAdded markers are checked by triggers during their init() call\n      // which is invoked in scheduledTriggers.add(), so once this is done we can remove them\n      try {\n        // add new triggers and/or replace and close the replaced triggers\n        for (Map.Entry<String, AutoScaling.Trigger> entry : copy.entrySet()) {\n          try {\n            scheduledTriggers.add(entry.getValue());\n          } catch (AlreadyClosedException e) {\n\n          } catch (Exception e) {\n            log.warn(\"Exception initializing trigger \" + entry.getKey() + \", configuration ignored\", e);\n          }\n        }\n      } catch (AlreadyClosedException e) {\n        // this _should_ mean that we're closing, complain loudly if that's not the case\n        if (isClosed) {\n          return;\n        } else {\n          throw new IllegalStateException(\"Caught AlreadyClosedException from ScheduledTriggers, but we're not closed yet!\", e);\n        }\n      }\n      log.debug(\"-- cleaning old nodeLost / nodeAdded markers\");\n      removeMarkers(ZkStateReader.SOLR_AUTOSCALING_NODE_LOST_PATH);\n      removeMarkers(ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH);\n      processedZnodeVersion = znodeVersion;\n    }\n  }\n\n","sourceOld":"  @Override\n  public void run() {\n    int lastZnodeVersion = znodeVersion;\n\n    // we automatically add a trigger for auto add replicas if it does not exists already\n    // we also automatically add a scheduled maintenance trigger\n    while (!isClosed)  {\n      try {\n        if (Thread.currentThread().isInterrupted()) {\n          log.warn(\"Interrupted\");\n          break;\n        }\n        AutoScalingConfig autoScalingConfig = cloudManager.getDistribStateManager().getAutoScalingConfig();\n        AutoScalingConfig updatedConfig = withAutoAddReplicasTrigger(autoScalingConfig);\n        updatedConfig = withScheduledMaintenanceTrigger(updatedConfig);\n        if (updatedConfig.equals(autoScalingConfig)) break;\n        log.debug(\"Adding .auto_add_replicas and .scheduled_maintenance triggers\");\n        cloudManager.getDistribStateManager().setData(SOLR_AUTOSCALING_CONF_PATH, Utils.toJSON(updatedConfig), updatedConfig.getZkVersion());\n        break;\n      } catch (AlreadyClosedException e) {\n        break;\n      } catch (BadVersionException bve) {\n        // somebody else has changed the configuration so we must retry\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        log.warn(\"Interrupted\", e);\n        break;\n      }\n      catch (IOException | KeeperException e) {\n        if (e instanceof KeeperException.SessionExpiredException ||\n            (e.getCause()!=null && e.getCause() instanceof KeeperException.SessionExpiredException)) {\n          log.warn(\"Solr cannot talk to ZK, exiting \" + \n              getClass().getSimpleName() + \" main queue loop\", e);\n          return;\n        } else {\n          log.error(\"A ZK error has occurred\", e);\n        }\n      }\n    }\n\n    if (isClosed || Thread.currentThread().isInterrupted())  return;\n\n    try {\n      refreshAutoScalingConf(new AutoScalingWatcher());\n    } catch (ConnectException e) {\n      log.warn(\"ZooKeeper watch triggered for autoscaling conf, but Solr cannot talk to ZK: [{}]\", e.getMessage());\n    } catch (InterruptedException e) {\n      // Restore the interrupted status\n      Thread.currentThread().interrupt();\n      log.warn(\"Interrupted\", e);\n    } catch (Exception e)  {\n      log.error(\"Unexpected exception\", e);\n    }\n\n    while (true) {\n      Map<String, AutoScaling.Trigger> copy = null;\n      try {\n        // this can throw InterruptedException and we don't want to unlock if it did, so we keep this outside\n        // of the try/finally block\n        updateLock.lockInterruptibly();\n\n        // must check for close here before we await on the condition otherwise we can only be woken up on interruption\n        if (isClosed) {\n          log.info(\"OverseerTriggerThread has been closed, exiting.\");\n          break;\n        }\n\n        log.debug(\"Current znodeVersion {}, lastZnodeVersion {}\", znodeVersion, lastZnodeVersion);\n\n        try {\n          if (znodeVersion == lastZnodeVersion) {\n            updated.await();\n\n            // are we closed?\n            if (isClosed) {\n              log.info(\"OverseerTriggerThread woken up but we are closed, exiting.\");\n              break;\n            }\n\n            // spurious wakeup?\n            if (znodeVersion == lastZnodeVersion) continue;\n          }\n          copy = new HashMap<>(activeTriggers);\n          lastZnodeVersion = znodeVersion;\n          log.debug(\"Processed trigger updates upto znodeVersion {}\", znodeVersion);\n        } catch (InterruptedException e) {\n          // Restore the interrupted status\n          Thread.currentThread().interrupt();\n          log.warn(\"Interrupted\", e);\n          break;\n        } finally {\n          updateLock.unlock();\n        }\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        break;\n      }\n\n      // update the current config\n      scheduledTriggers.setAutoScalingConfig(autoScalingConfig);\n\n      Set<String> managedTriggerNames = scheduledTriggers.getScheduledTriggerNames();\n      // remove the triggers which are no longer active\n      for (String managedTriggerName : managedTriggerNames) {\n        if (!copy.containsKey(managedTriggerName)) {\n          scheduledTriggers.remove(managedTriggerName);\n        }\n      }\n      // nodeLost / nodeAdded markers are checked by triggers during their init() call\n      // which is invoked in scheduledTriggers.add(), so once this is done we can remove them\n      try {\n        // add new triggers and/or replace and close the replaced triggers\n        for (Map.Entry<String, AutoScaling.Trigger> entry : copy.entrySet()) {\n          try {\n            scheduledTriggers.add(entry.getValue());\n          } catch (AlreadyClosedException e) {\n\n          } catch (Exception e) {\n            log.warn(\"Exception initializing trigger \" + entry.getKey() + \", configuration ignored\", e);\n          }\n        }\n      } catch (AlreadyClosedException e) {\n        // this _should_ mean that we're closing, complain loudly if that's not the case\n        if (isClosed) {\n          return;\n        } else {\n          throw new IllegalStateException(\"Caught AlreadyClosedException from ScheduledTriggers, but we're not closed yet!\", e);\n        }\n      }\n      log.debug(\"-- cleaning old nodeLost / nodeAdded markers\");\n      removeMarkers(ZkStateReader.SOLR_AUTOSCALING_NODE_LOST_PATH);\n      removeMarkers(ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"9c787ffd984133d984d6b651ed48f0db5347aeac","date":1554140091,"type":3,"author":"Chris Hostetter","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/autoscaling/OverseerTriggerThread#run().mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/autoscaling/OverseerTriggerThread#run().mjava","sourceNew":"  @Override\n  public void run() {\n    int lastZnodeVersion = znodeVersion;\n\n    // we automatically add a trigger for auto add replicas if it does not exists already\n    // we also automatically add a scheduled maintenance trigger\n    while (!isClosed)  {\n      try {\n        if (Thread.currentThread().isInterrupted()) {\n          log.warn(\"Interrupted\");\n          break;\n        }\n        AutoScalingConfig autoScalingConfig = cloudManager.getDistribStateManager().getAutoScalingConfig();\n        AutoScalingConfig updatedConfig = withAutoAddReplicasTrigger(autoScalingConfig);\n        updatedConfig = withScheduledMaintenanceTrigger(updatedConfig);\n        if (updatedConfig.equals(autoScalingConfig)) break;\n        log.debug(\"Adding .auto_add_replicas and .scheduled_maintenance triggers\");\n        cloudManager.getDistribStateManager().setData(SOLR_AUTOSCALING_CONF_PATH, Utils.toJSON(updatedConfig), updatedConfig.getZkVersion());\n        break;\n      } catch (AlreadyClosedException e) {\n        break;\n      } catch (BadVersionException bve) {\n        // somebody else has changed the configuration so we must retry\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        log.warn(\"Interrupted\", e);\n        break;\n      }\n      catch (IOException | KeeperException e) {\n        if (e instanceof KeeperException.SessionExpiredException ||\n            (e.getCause()!=null && e.getCause() instanceof KeeperException.SessionExpiredException)) {\n          log.warn(\"Solr cannot talk to ZK, exiting \" + \n              getClass().getSimpleName() + \" main queue loop\", e);\n          return;\n        } else {\n          log.error(\"A ZK error has occurred\", e);\n        }\n      }\n    }\n\n    if (isClosed || Thread.currentThread().isInterrupted())  return;\n\n    try {\n      refreshAutoScalingConf(new AutoScalingWatcher());\n    } catch (ConnectException e) {\n      log.warn(\"ZooKeeper watch triggered for autoscaling conf, but Solr cannot talk to ZK: [{}]\", e.getMessage());\n    } catch (InterruptedException e) {\n      // Restore the interrupted status\n      Thread.currentThread().interrupt();\n      log.warn(\"Interrupted\", e);\n    } catch (Exception e)  {\n      log.error(\"Unexpected exception\", e);\n    }\n\n    while (true) {\n      Map<String, AutoScaling.Trigger> copy = null;\n      try {\n        \n        updateLock.lockInterruptibly();\n        try {\n          // must check for close here before we await on the condition otherwise we can\n          // only be woken up on interruption\n          if (isClosed) {\n            log.info(\"OverseerTriggerThread has been closed, exiting.\");\n            break;\n          }\n          \n          log.debug(\"Current znodeVersion {}, lastZnodeVersion {}\", znodeVersion, lastZnodeVersion);\n          \n          if (znodeVersion == lastZnodeVersion) {\n            updated.await();\n            \n            // are we closed?\n            if (isClosed) {\n              log.info(\"OverseerTriggerThread woken up but we are closed, exiting.\");\n              break;\n            }\n            \n            // spurious wakeup?\n            if (znodeVersion == lastZnodeVersion) continue;\n          }\n          copy = new HashMap<>(activeTriggers);\n          lastZnodeVersion = znodeVersion;\n          log.debug(\"Processed trigger updates upto znodeVersion {}\", znodeVersion);\n        } finally {\n          updateLock.unlock();\n        }\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        log.warn(\"Interrupted\", e);\n        break;\n      }\n     \n      // update the current config\n      scheduledTriggers.setAutoScalingConfig(autoScalingConfig);\n\n      Set<String> managedTriggerNames = scheduledTriggers.getScheduledTriggerNames();\n      // remove the triggers which are no longer active\n      for (String managedTriggerName : managedTriggerNames) {\n        if (!copy.containsKey(managedTriggerName)) {\n          scheduledTriggers.remove(managedTriggerName);\n        }\n      }\n      // nodeLost / nodeAdded markers are checked by triggers during their init() call\n      // which is invoked in scheduledTriggers.add(), so once this is done we can remove them\n      try {\n        // add new triggers and/or replace and close the replaced triggers\n        for (Map.Entry<String, AutoScaling.Trigger> entry : copy.entrySet()) {\n          try {\n            scheduledTriggers.add(entry.getValue());\n          } catch (AlreadyClosedException e) {\n\n          } catch (Exception e) {\n            log.warn(\"Exception initializing trigger \" + entry.getKey() + \", configuration ignored\", e);\n          }\n        }\n      } catch (AlreadyClosedException e) {\n        // this _should_ mean that we're closing, complain loudly if that's not the case\n        if (isClosed) {\n          return;\n        } else {\n          throw new IllegalStateException(\"Caught AlreadyClosedException from ScheduledTriggers, but we're not closed yet!\", e);\n        }\n      }\n      log.debug(\"-- cleaning old nodeLost / nodeAdded markers\");\n      removeMarkers(ZkStateReader.SOLR_AUTOSCALING_NODE_LOST_PATH);\n      removeMarkers(ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH);\n      processedZnodeVersion = znodeVersion;\n    }\n  }\n\n","sourceOld":"  @Override\n  public void run() {\n    int lastZnodeVersion = znodeVersion;\n\n    // we automatically add a trigger for auto add replicas if it does not exists already\n    // we also automatically add a scheduled maintenance trigger\n    while (!isClosed)  {\n      try {\n        if (Thread.currentThread().isInterrupted()) {\n          log.warn(\"Interrupted\");\n          break;\n        }\n        AutoScalingConfig autoScalingConfig = cloudManager.getDistribStateManager().getAutoScalingConfig();\n        AutoScalingConfig updatedConfig = withAutoAddReplicasTrigger(autoScalingConfig);\n        updatedConfig = withScheduledMaintenanceTrigger(updatedConfig);\n        if (updatedConfig.equals(autoScalingConfig)) break;\n        log.debug(\"Adding .auto_add_replicas and .scheduled_maintenance triggers\");\n        cloudManager.getDistribStateManager().setData(SOLR_AUTOSCALING_CONF_PATH, Utils.toJSON(updatedConfig), updatedConfig.getZkVersion());\n        break;\n      } catch (AlreadyClosedException e) {\n        break;\n      } catch (BadVersionException bve) {\n        // somebody else has changed the configuration so we must retry\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        log.warn(\"Interrupted\", e);\n        break;\n      }\n      catch (IOException | KeeperException e) {\n        if (e instanceof KeeperException.SessionExpiredException ||\n            (e.getCause()!=null && e.getCause() instanceof KeeperException.SessionExpiredException)) {\n          log.warn(\"Solr cannot talk to ZK, exiting \" + \n              getClass().getSimpleName() + \" main queue loop\", e);\n          return;\n        } else {\n          log.error(\"A ZK error has occurred\", e);\n        }\n      }\n    }\n\n    if (isClosed || Thread.currentThread().isInterrupted())  return;\n\n    try {\n      refreshAutoScalingConf(new AutoScalingWatcher());\n    } catch (ConnectException e) {\n      log.warn(\"ZooKeeper watch triggered for autoscaling conf, but Solr cannot talk to ZK: [{}]\", e.getMessage());\n    } catch (InterruptedException e) {\n      // Restore the interrupted status\n      Thread.currentThread().interrupt();\n      log.warn(\"Interrupted\", e);\n    } catch (Exception e)  {\n      log.error(\"Unexpected exception\", e);\n    }\n\n    while (true) {\n      Map<String, AutoScaling.Trigger> copy = null;\n      try {\n        // this can throw InterruptedException and we don't want to unlock if it did, so we keep this outside\n        // of the try/finally block\n        updateLock.lockInterruptibly();\n\n        // must check for close here before we await on the condition otherwise we can only be woken up on interruption\n        if (isClosed) {\n          log.info(\"OverseerTriggerThread has been closed, exiting.\");\n          break;\n        }\n\n        log.debug(\"Current znodeVersion {}, lastZnodeVersion {}\", znodeVersion, lastZnodeVersion);\n\n        try {\n          if (znodeVersion == lastZnodeVersion) {\n            updated.await();\n\n            // are we closed?\n            if (isClosed) {\n              log.info(\"OverseerTriggerThread woken up but we are closed, exiting.\");\n              break;\n            }\n\n            // spurious wakeup?\n            if (znodeVersion == lastZnodeVersion) continue;\n          }\n          copy = new HashMap<>(activeTriggers);\n          lastZnodeVersion = znodeVersion;\n          log.debug(\"Processed trigger updates upto znodeVersion {}\", znodeVersion);\n        } catch (InterruptedException e) {\n          // Restore the interrupted status\n          Thread.currentThread().interrupt();\n          log.warn(\"Interrupted\", e);\n          break;\n        } finally {\n          updateLock.unlock();\n        }\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        break;\n      }\n\n      // update the current config\n      scheduledTriggers.setAutoScalingConfig(autoScalingConfig);\n\n      Set<String> managedTriggerNames = scheduledTriggers.getScheduledTriggerNames();\n      // remove the triggers which are no longer active\n      for (String managedTriggerName : managedTriggerNames) {\n        if (!copy.containsKey(managedTriggerName)) {\n          scheduledTriggers.remove(managedTriggerName);\n        }\n      }\n      // nodeLost / nodeAdded markers are checked by triggers during their init() call\n      // which is invoked in scheduledTriggers.add(), so once this is done we can remove them\n      try {\n        // add new triggers and/or replace and close the replaced triggers\n        for (Map.Entry<String, AutoScaling.Trigger> entry : copy.entrySet()) {\n          try {\n            scheduledTriggers.add(entry.getValue());\n          } catch (AlreadyClosedException e) {\n\n          } catch (Exception e) {\n            log.warn(\"Exception initializing trigger \" + entry.getKey() + \", configuration ignored\", e);\n          }\n        }\n      } catch (AlreadyClosedException e) {\n        // this _should_ mean that we're closing, complain loudly if that's not the case\n        if (isClosed) {\n          return;\n        } else {\n          throw new IllegalStateException(\"Caught AlreadyClosedException from ScheduledTriggers, but we're not closed yet!\", e);\n        }\n      }\n      log.debug(\"-- cleaning old nodeLost / nodeAdded markers\");\n      removeMarkers(ZkStateReader.SOLR_AUTOSCALING_NODE_LOST_PATH);\n      removeMarkers(ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH);\n      processedZnodeVersion = znodeVersion;\n    }\n  }\n\n","bugFix":["263092c0f07c163d73a8be27ba212aaf7e76bd40","bb222a3f9d9421d5c95afce73013fbd8de07ea1f","7aa2c1715ef9a80383edea1048655da291ed9b8f","6ca81a50d0a6c6f97f1e2b15ef90c5bd81765d09"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"98d4af357762468d37df7424f81785cd89b49a7b","date":1570534862,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/autoscaling/OverseerTriggerThread#run().mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/autoscaling/OverseerTriggerThread#run().mjava","sourceNew":"  @Override\n  public void run() {\n    int lastZnodeVersion = znodeVersion;\n\n    // we automatically add a trigger for auto add replicas if it does not exists already\n    // we also automatically add a scheduled maintenance trigger\n    while (!isClosed)  {\n      try {\n        if (Thread.currentThread().isInterrupted()) {\n          log.warn(\"Interrupted\");\n          break;\n        }\n        AutoScalingConfig autoScalingConfig = cloudManager.getDistribStateManager().getAutoScalingConfig();\n        AutoScalingConfig updatedConfig = withAutoAddReplicasTrigger(autoScalingConfig);\n        updatedConfig = withScheduledMaintenanceTrigger(updatedConfig);\n        if (updatedConfig.equals(autoScalingConfig)) break;\n        log.debug(\"Adding .auto_add_replicas and .scheduled_maintenance triggers\");\n        cloudManager.getDistribStateManager().setData(SOLR_AUTOSCALING_CONF_PATH, Utils.toJSON(updatedConfig), updatedConfig.getZkVersion());\n        break;\n      } catch (AlreadyClosedException e) {\n        break;\n      } catch (BadVersionException bve) {\n        // somebody else has changed the configuration so we must retry\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        log.warn(\"Interrupted\", e);\n        break;\n      }\n      catch (IOException | KeeperException e) {\n        if (e instanceof KeeperException.SessionExpiredException ||\n            (e.getCause()!=null && e.getCause() instanceof KeeperException.SessionExpiredException)) {\n          log.warn(\"Solr cannot talk to ZK, exiting \" + \n              getClass().getSimpleName() + \" main queue loop\", e);\n          return;\n        } else {\n          log.error(\"A ZK error has occurred\", e);\n        }\n      }\n    }\n\n    if (isClosed || Thread.currentThread().isInterrupted())  return;\n\n    try {\n      refreshAutoScalingConf(new AutoScalingWatcher());\n    } catch (ConnectException e) {\n      log.warn(\"ZooKeeper watch triggered for autoscaling conf, but Solr cannot talk to ZK: [{}]\", e.getMessage());\n    } catch (InterruptedException e) {\n      // Restore the interrupted status\n      Thread.currentThread().interrupt();\n      log.warn(\"Interrupted\", e);\n    } catch (Exception e)  {\n      log.error(\"Unexpected exception\", e);\n    }\n\n    while (true) {\n      Map<String, AutoScaling.Trigger> copy = null;\n      try {\n        \n        updateLock.lockInterruptibly();\n        try {\n          // must check for close here before we await on the condition otherwise we can\n          // only be woken up on interruption\n          if (isClosed) {\n            log.info(\"OverseerTriggerThread has been closed, exiting.\");\n            break;\n          }\n          \n          log.debug(\"Current znodeVersion {}, lastZnodeVersion {}\", znodeVersion, lastZnodeVersion);\n          \n          if (znodeVersion == lastZnodeVersion) {\n            updated.await();\n            \n            // are we closed?\n            if (isClosed) {\n              log.info(\"OverseerTriggerThread woken up but we are closed, exiting.\");\n              break;\n            }\n            \n            // spurious wakeup?\n            if (znodeVersion == lastZnodeVersion) continue;\n          }\n          copy = new HashMap<>(activeTriggers);\n          lastZnodeVersion = znodeVersion;\n          log.debug(\"Processed trigger updates upto znodeVersion {}\", znodeVersion);\n        } finally {\n          updateLock.unlock();\n        }\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        log.warn(\"Interrupted\", e);\n        break;\n      }\n     \n      // update the current config\n      scheduledTriggers.setAutoScalingConfig(autoScalingConfig);\n\n      Set<String> managedTriggerNames = scheduledTriggers.getScheduledTriggerNames();\n      // remove the triggers which are no longer active\n      for (String managedTriggerName : managedTriggerNames) {\n        if (!copy.containsKey(managedTriggerName)) {\n          scheduledTriggers.remove(managedTriggerName);\n        }\n      }\n      // nodeLost / nodeAdded markers are checked by triggers during their init() call\n      // which is invoked in scheduledTriggers.add(), so once this is done we can remove them\n      try {\n        // add new triggers and/or replace and close the replaced triggers\n        for (Map.Entry<String, AutoScaling.Trigger> entry : copy.entrySet()) {\n          try {\n            scheduledTriggers.add(entry.getValue());\n          } catch (AlreadyClosedException e) {\n\n          } catch (Exception e) {\n            log.warn(\"Exception initializing trigger \" + entry.getKey() + \", configuration ignored\", e);\n          }\n        }\n      } catch (AlreadyClosedException e) {\n        // this _should_ mean that we're closing, complain loudly if that's not the case\n        if (isClosed) {\n          return;\n        } else {\n          throw new IllegalStateException(\"Caught AlreadyClosedException from ScheduledTriggers, but we're not closed yet!\", e);\n        }\n      }\n      log.debug(\"-- deactivating old nodeLost / nodeAdded markers\");\n      deactivateMarkers(ZkStateReader.SOLR_AUTOSCALING_NODE_LOST_PATH);\n      deactivateMarkers(ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH);\n      processedZnodeVersion = znodeVersion;\n    }\n  }\n\n","sourceOld":"  @Override\n  public void run() {\n    int lastZnodeVersion = znodeVersion;\n\n    // we automatically add a trigger for auto add replicas if it does not exists already\n    // we also automatically add a scheduled maintenance trigger\n    while (!isClosed)  {\n      try {\n        if (Thread.currentThread().isInterrupted()) {\n          log.warn(\"Interrupted\");\n          break;\n        }\n        AutoScalingConfig autoScalingConfig = cloudManager.getDistribStateManager().getAutoScalingConfig();\n        AutoScalingConfig updatedConfig = withAutoAddReplicasTrigger(autoScalingConfig);\n        updatedConfig = withScheduledMaintenanceTrigger(updatedConfig);\n        if (updatedConfig.equals(autoScalingConfig)) break;\n        log.debug(\"Adding .auto_add_replicas and .scheduled_maintenance triggers\");\n        cloudManager.getDistribStateManager().setData(SOLR_AUTOSCALING_CONF_PATH, Utils.toJSON(updatedConfig), updatedConfig.getZkVersion());\n        break;\n      } catch (AlreadyClosedException e) {\n        break;\n      } catch (BadVersionException bve) {\n        // somebody else has changed the configuration so we must retry\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        log.warn(\"Interrupted\", e);\n        break;\n      }\n      catch (IOException | KeeperException e) {\n        if (e instanceof KeeperException.SessionExpiredException ||\n            (e.getCause()!=null && e.getCause() instanceof KeeperException.SessionExpiredException)) {\n          log.warn(\"Solr cannot talk to ZK, exiting \" + \n              getClass().getSimpleName() + \" main queue loop\", e);\n          return;\n        } else {\n          log.error(\"A ZK error has occurred\", e);\n        }\n      }\n    }\n\n    if (isClosed || Thread.currentThread().isInterrupted())  return;\n\n    try {\n      refreshAutoScalingConf(new AutoScalingWatcher());\n    } catch (ConnectException e) {\n      log.warn(\"ZooKeeper watch triggered for autoscaling conf, but Solr cannot talk to ZK: [{}]\", e.getMessage());\n    } catch (InterruptedException e) {\n      // Restore the interrupted status\n      Thread.currentThread().interrupt();\n      log.warn(\"Interrupted\", e);\n    } catch (Exception e)  {\n      log.error(\"Unexpected exception\", e);\n    }\n\n    while (true) {\n      Map<String, AutoScaling.Trigger> copy = null;\n      try {\n        \n        updateLock.lockInterruptibly();\n        try {\n          // must check for close here before we await on the condition otherwise we can\n          // only be woken up on interruption\n          if (isClosed) {\n            log.info(\"OverseerTriggerThread has been closed, exiting.\");\n            break;\n          }\n          \n          log.debug(\"Current znodeVersion {}, lastZnodeVersion {}\", znodeVersion, lastZnodeVersion);\n          \n          if (znodeVersion == lastZnodeVersion) {\n            updated.await();\n            \n            // are we closed?\n            if (isClosed) {\n              log.info(\"OverseerTriggerThread woken up but we are closed, exiting.\");\n              break;\n            }\n            \n            // spurious wakeup?\n            if (znodeVersion == lastZnodeVersion) continue;\n          }\n          copy = new HashMap<>(activeTriggers);\n          lastZnodeVersion = znodeVersion;\n          log.debug(\"Processed trigger updates upto znodeVersion {}\", znodeVersion);\n        } finally {\n          updateLock.unlock();\n        }\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        log.warn(\"Interrupted\", e);\n        break;\n      }\n     \n      // update the current config\n      scheduledTriggers.setAutoScalingConfig(autoScalingConfig);\n\n      Set<String> managedTriggerNames = scheduledTriggers.getScheduledTriggerNames();\n      // remove the triggers which are no longer active\n      for (String managedTriggerName : managedTriggerNames) {\n        if (!copy.containsKey(managedTriggerName)) {\n          scheduledTriggers.remove(managedTriggerName);\n        }\n      }\n      // nodeLost / nodeAdded markers are checked by triggers during their init() call\n      // which is invoked in scheduledTriggers.add(), so once this is done we can remove them\n      try {\n        // add new triggers and/or replace and close the replaced triggers\n        for (Map.Entry<String, AutoScaling.Trigger> entry : copy.entrySet()) {\n          try {\n            scheduledTriggers.add(entry.getValue());\n          } catch (AlreadyClosedException e) {\n\n          } catch (Exception e) {\n            log.warn(\"Exception initializing trigger \" + entry.getKey() + \", configuration ignored\", e);\n          }\n        }\n      } catch (AlreadyClosedException e) {\n        // this _should_ mean that we're closing, complain loudly if that's not the case\n        if (isClosed) {\n          return;\n        } else {\n          throw new IllegalStateException(\"Caught AlreadyClosedException from ScheduledTriggers, but we're not closed yet!\", e);\n        }\n      }\n      log.debug(\"-- cleaning old nodeLost / nodeAdded markers\");\n      removeMarkers(ZkStateReader.SOLR_AUTOSCALING_NODE_LOST_PATH);\n      removeMarkers(ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH);\n      processedZnodeVersion = znodeVersion;\n    }\n  }\n\n","bugFix":["f7fb1186f5b61e0b74289e6786df8cbecfa471bc"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b0b597c65628ca9e73913a07e81691f8229bae35","date":1571224353,"type":3,"author":"jimczi","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/cloud/autoscaling/OverseerTriggerThread#run().mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/autoscaling/OverseerTriggerThread#run().mjava","sourceNew":"  @Override\n  public void run() {\n    int lastZnodeVersion = znodeVersion;\n\n    // we automatically add a trigger for auto add replicas if it does not exists already\n    // we also automatically add a scheduled maintenance trigger\n    while (!isClosed)  {\n      try {\n        if (Thread.currentThread().isInterrupted()) {\n          log.warn(\"Interrupted\");\n          break;\n        }\n        AutoScalingConfig autoScalingConfig = cloudManager.getDistribStateManager().getAutoScalingConfig();\n        AutoScalingConfig updatedConfig = withAutoAddReplicasTrigger(autoScalingConfig);\n        updatedConfig = withScheduledMaintenanceTrigger(updatedConfig);\n        if (updatedConfig.equals(autoScalingConfig)) break;\n        log.debug(\"Adding .auto_add_replicas and .scheduled_maintenance triggers\");\n        cloudManager.getDistribStateManager().setData(SOLR_AUTOSCALING_CONF_PATH, Utils.toJSON(updatedConfig), updatedConfig.getZkVersion());\n        break;\n      } catch (AlreadyClosedException e) {\n        break;\n      } catch (BadVersionException bve) {\n        // somebody else has changed the configuration so we must retry\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        log.warn(\"Interrupted\", e);\n        break;\n      }\n      catch (IOException | KeeperException e) {\n        if (e instanceof KeeperException.SessionExpiredException ||\n            (e.getCause()!=null && e.getCause() instanceof KeeperException.SessionExpiredException)) {\n          log.warn(\"Solr cannot talk to ZK, exiting \" + \n              getClass().getSimpleName() + \" main queue loop\", e);\n          return;\n        } else {\n          log.error(\"A ZK error has occurred\", e);\n        }\n      }\n    }\n\n    if (isClosed || Thread.currentThread().isInterrupted())  return;\n\n    try {\n      refreshAutoScalingConf(new AutoScalingWatcher());\n    } catch (ConnectException e) {\n      log.warn(\"ZooKeeper watch triggered for autoscaling conf, but Solr cannot talk to ZK: [{}]\", e.getMessage());\n    } catch (InterruptedException e) {\n      // Restore the interrupted status\n      Thread.currentThread().interrupt();\n      log.warn(\"Interrupted\", e);\n    } catch (Exception e)  {\n      log.error(\"Unexpected exception\", e);\n    }\n\n    while (true) {\n      Map<String, AutoScaling.Trigger> copy = null;\n      try {\n        \n        updateLock.lockInterruptibly();\n        try {\n          // must check for close here before we await on the condition otherwise we can\n          // only be woken up on interruption\n          if (isClosed) {\n            log.info(\"OverseerTriggerThread has been closed, exiting.\");\n            break;\n          }\n          \n          log.debug(\"Current znodeVersion {}, lastZnodeVersion {}\", znodeVersion, lastZnodeVersion);\n          \n          if (znodeVersion == lastZnodeVersion) {\n            updated.await();\n            \n            // are we closed?\n            if (isClosed) {\n              log.info(\"OverseerTriggerThread woken up but we are closed, exiting.\");\n              break;\n            }\n            \n            // spurious wakeup?\n            if (znodeVersion == lastZnodeVersion) continue;\n          }\n          copy = new HashMap<>(activeTriggers);\n          lastZnodeVersion = znodeVersion;\n          log.debug(\"Processed trigger updates upto znodeVersion {}\", znodeVersion);\n        } finally {\n          updateLock.unlock();\n        }\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        log.warn(\"Interrupted\", e);\n        break;\n      }\n     \n      // update the current config\n      scheduledTriggers.setAutoScalingConfig(autoScalingConfig);\n\n      Set<String> managedTriggerNames = scheduledTriggers.getScheduledTriggerNames();\n      // remove the triggers which are no longer active\n      for (String managedTriggerName : managedTriggerNames) {\n        if (!copy.containsKey(managedTriggerName)) {\n          scheduledTriggers.remove(managedTriggerName);\n        }\n      }\n      // nodeLost / nodeAdded markers are checked by triggers during their init() call\n      // which is invoked in scheduledTriggers.add(), so once this is done we can remove them\n      try {\n        // add new triggers and/or replace and close the replaced triggers\n        for (Map.Entry<String, AutoScaling.Trigger> entry : copy.entrySet()) {\n          try {\n            scheduledTriggers.add(entry.getValue());\n          } catch (AlreadyClosedException e) {\n\n          } catch (Exception e) {\n            log.warn(\"Exception initializing trigger \" + entry.getKey() + \", configuration ignored\", e);\n          }\n        }\n      } catch (AlreadyClosedException e) {\n        // this _should_ mean that we're closing, complain loudly if that's not the case\n        if (isClosed) {\n          return;\n        } else {\n          throw new IllegalStateException(\"Caught AlreadyClosedException from ScheduledTriggers, but we're not closed yet!\", e);\n        }\n      }\n      log.debug(\"-- deactivating old nodeLost / nodeAdded markers\");\n      deactivateMarkers(ZkStateReader.SOLR_AUTOSCALING_NODE_LOST_PATH);\n      deactivateMarkers(ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH);\n      processedZnodeVersion = znodeVersion;\n    }\n  }\n\n","sourceOld":"  @Override\n  public void run() {\n    int lastZnodeVersion = znodeVersion;\n\n    // we automatically add a trigger for auto add replicas if it does not exists already\n    // we also automatically add a scheduled maintenance trigger\n    while (!isClosed)  {\n      try {\n        if (Thread.currentThread().isInterrupted()) {\n          log.warn(\"Interrupted\");\n          break;\n        }\n        AutoScalingConfig autoScalingConfig = cloudManager.getDistribStateManager().getAutoScalingConfig();\n        AutoScalingConfig updatedConfig = withAutoAddReplicasTrigger(autoScalingConfig);\n        updatedConfig = withScheduledMaintenanceTrigger(updatedConfig);\n        if (updatedConfig.equals(autoScalingConfig)) break;\n        log.debug(\"Adding .auto_add_replicas and .scheduled_maintenance triggers\");\n        cloudManager.getDistribStateManager().setData(SOLR_AUTOSCALING_CONF_PATH, Utils.toJSON(updatedConfig), updatedConfig.getZkVersion());\n        break;\n      } catch (AlreadyClosedException e) {\n        break;\n      } catch (BadVersionException bve) {\n        // somebody else has changed the configuration so we must retry\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        log.warn(\"Interrupted\", e);\n        break;\n      }\n      catch (IOException | KeeperException e) {\n        if (e instanceof KeeperException.SessionExpiredException ||\n            (e.getCause()!=null && e.getCause() instanceof KeeperException.SessionExpiredException)) {\n          log.warn(\"Solr cannot talk to ZK, exiting \" + \n              getClass().getSimpleName() + \" main queue loop\", e);\n          return;\n        } else {\n          log.error(\"A ZK error has occurred\", e);\n        }\n      }\n    }\n\n    if (isClosed || Thread.currentThread().isInterrupted())  return;\n\n    try {\n      refreshAutoScalingConf(new AutoScalingWatcher());\n    } catch (ConnectException e) {\n      log.warn(\"ZooKeeper watch triggered for autoscaling conf, but Solr cannot talk to ZK: [{}]\", e.getMessage());\n    } catch (InterruptedException e) {\n      // Restore the interrupted status\n      Thread.currentThread().interrupt();\n      log.warn(\"Interrupted\", e);\n    } catch (Exception e)  {\n      log.error(\"Unexpected exception\", e);\n    }\n\n    while (true) {\n      Map<String, AutoScaling.Trigger> copy = null;\n      try {\n        \n        updateLock.lockInterruptibly();\n        try {\n          // must check for close here before we await on the condition otherwise we can\n          // only be woken up on interruption\n          if (isClosed) {\n            log.info(\"OverseerTriggerThread has been closed, exiting.\");\n            break;\n          }\n          \n          log.debug(\"Current znodeVersion {}, lastZnodeVersion {}\", znodeVersion, lastZnodeVersion);\n          \n          if (znodeVersion == lastZnodeVersion) {\n            updated.await();\n            \n            // are we closed?\n            if (isClosed) {\n              log.info(\"OverseerTriggerThread woken up but we are closed, exiting.\");\n              break;\n            }\n            \n            // spurious wakeup?\n            if (znodeVersion == lastZnodeVersion) continue;\n          }\n          copy = new HashMap<>(activeTriggers);\n          lastZnodeVersion = znodeVersion;\n          log.debug(\"Processed trigger updates upto znodeVersion {}\", znodeVersion);\n        } finally {\n          updateLock.unlock();\n        }\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        log.warn(\"Interrupted\", e);\n        break;\n      }\n     \n      // update the current config\n      scheduledTriggers.setAutoScalingConfig(autoScalingConfig);\n\n      Set<String> managedTriggerNames = scheduledTriggers.getScheduledTriggerNames();\n      // remove the triggers which are no longer active\n      for (String managedTriggerName : managedTriggerNames) {\n        if (!copy.containsKey(managedTriggerName)) {\n          scheduledTriggers.remove(managedTriggerName);\n        }\n      }\n      // nodeLost / nodeAdded markers are checked by triggers during their init() call\n      // which is invoked in scheduledTriggers.add(), so once this is done we can remove them\n      try {\n        // add new triggers and/or replace and close the replaced triggers\n        for (Map.Entry<String, AutoScaling.Trigger> entry : copy.entrySet()) {\n          try {\n            scheduledTriggers.add(entry.getValue());\n          } catch (AlreadyClosedException e) {\n\n          } catch (Exception e) {\n            log.warn(\"Exception initializing trigger \" + entry.getKey() + \", configuration ignored\", e);\n          }\n        }\n      } catch (AlreadyClosedException e) {\n        // this _should_ mean that we're closing, complain loudly if that's not the case\n        if (isClosed) {\n          return;\n        } else {\n          throw new IllegalStateException(\"Caught AlreadyClosedException from ScheduledTriggers, but we're not closed yet!\", e);\n        }\n      }\n      log.debug(\"-- cleaning old nodeLost / nodeAdded markers\");\n      removeMarkers(ZkStateReader.SOLR_AUTOSCALING_NODE_LOST_PATH);\n      removeMarkers(ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH);\n      processedZnodeVersion = znodeVersion;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"067ba8c807b0f23eae8bf41bc27046a87b548134","date":1587570399,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/autoscaling/OverseerTriggerThread#run().mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/autoscaling/OverseerTriggerThread#run().mjava","sourceNew":"  @Override\n  public void run() {\n    int lastZnodeVersion = znodeVersion;\n\n    // we automatically add a trigger for auto add replicas if it does not exists already\n    // we also automatically add a scheduled maintenance trigger\n    while (!isClosed)  {\n      try {\n        if (Thread.currentThread().isInterrupted()) {\n          log.warn(\"Interrupted\");\n          break;\n        }\n        AutoScalingConfig autoScalingConfig = cloudManager.getDistribStateManager().getAutoScalingConfig();\n        AutoScalingConfig updatedConfig = withDefaultPolicy(autoScalingConfig);\n        updatedConfig = withAutoAddReplicasTrigger(updatedConfig);\n        updatedConfig = withScheduledMaintenanceTrigger(updatedConfig);\n        if (updatedConfig.equals(autoScalingConfig)) break;\n        log.debug(\"Adding .auto_add_replicas and .scheduled_maintenance triggers\");\n        cloudManager.getDistribStateManager().setData(SOLR_AUTOSCALING_CONF_PATH, Utils.toJSON(updatedConfig), updatedConfig.getZkVersion());\n        break;\n      } catch (AlreadyClosedException e) {\n        break;\n      } catch (BadVersionException bve) {\n        // somebody else has changed the configuration so we must retry\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        log.warn(\"Interrupted\", e);\n        break;\n      }\n      catch (IOException | KeeperException e) {\n        if (e instanceof KeeperException.SessionExpiredException ||\n            (e.getCause()!=null && e.getCause() instanceof KeeperException.SessionExpiredException)) {\n          log.warn(\"Solr cannot talk to ZK, exiting \" + \n              getClass().getSimpleName() + \" main queue loop\", e);\n          return;\n        } else {\n          log.error(\"A ZK error has occurred\", e);\n        }\n      }\n    }\n\n    if (isClosed || Thread.currentThread().isInterrupted())  return;\n\n    try {\n      refreshAutoScalingConf(new AutoScalingWatcher());\n    } catch (ConnectException e) {\n      log.warn(\"ZooKeeper watch triggered for autoscaling conf, but Solr cannot talk to ZK: [{}]\", e.getMessage());\n    } catch (InterruptedException e) {\n      // Restore the interrupted status\n      Thread.currentThread().interrupt();\n      log.warn(\"Interrupted\", e);\n    } catch (Exception e)  {\n      log.error(\"Unexpected exception\", e);\n    }\n\n    while (true) {\n      Map<String, AutoScaling.Trigger> copy = null;\n      try {\n        \n        updateLock.lockInterruptibly();\n        try {\n          // must check for close here before we await on the condition otherwise we can\n          // only be woken up on interruption\n          if (isClosed) {\n            log.info(\"OverseerTriggerThread has been closed, exiting.\");\n            break;\n          }\n          \n          log.debug(\"Current znodeVersion {}, lastZnodeVersion {}\", znodeVersion, lastZnodeVersion);\n          \n          if (znodeVersion == lastZnodeVersion) {\n            updated.await();\n            \n            // are we closed?\n            if (isClosed) {\n              log.info(\"OverseerTriggerThread woken up but we are closed, exiting.\");\n              break;\n            }\n            \n            // spurious wakeup?\n            if (znodeVersion == lastZnodeVersion) continue;\n          }\n          copy = new HashMap<>(activeTriggers);\n          lastZnodeVersion = znodeVersion;\n          log.debug(\"Processed trigger updates upto znodeVersion {}\", znodeVersion);\n        } finally {\n          updateLock.unlock();\n        }\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        log.warn(\"Interrupted\", e);\n        break;\n      }\n     \n      // update the current config\n      scheduledTriggers.setAutoScalingConfig(autoScalingConfig);\n\n      Set<String> managedTriggerNames = scheduledTriggers.getScheduledTriggerNames();\n      // remove the triggers which are no longer active\n      for (String managedTriggerName : managedTriggerNames) {\n        if (!copy.containsKey(managedTriggerName)) {\n          scheduledTriggers.remove(managedTriggerName);\n        }\n      }\n      // nodeLost / nodeAdded markers are checked by triggers during their init() call\n      // which is invoked in scheduledTriggers.add(), so once this is done we can remove them\n      try {\n        // add new triggers and/or replace and close the replaced triggers\n        for (Map.Entry<String, AutoScaling.Trigger> entry : copy.entrySet()) {\n          try {\n            scheduledTriggers.add(entry.getValue());\n          } catch (AlreadyClosedException e) {\n\n          } catch (Exception e) {\n            log.warn(\"Exception initializing trigger \" + entry.getKey() + \", configuration ignored\", e);\n          }\n        }\n      } catch (AlreadyClosedException e) {\n        // this _should_ mean that we're closing, complain loudly if that's not the case\n        if (isClosed) {\n          return;\n        } else {\n          throw new IllegalStateException(\"Caught AlreadyClosedException from ScheduledTriggers, but we're not closed yet!\", e);\n        }\n      }\n      log.debug(\"-- deactivating old nodeLost / nodeAdded markers\");\n      deactivateMarkers(ZkStateReader.SOLR_AUTOSCALING_NODE_LOST_PATH);\n      deactivateMarkers(ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH);\n      processedZnodeVersion = znodeVersion;\n    }\n  }\n\n","sourceOld":"  @Override\n  public void run() {\n    int lastZnodeVersion = znodeVersion;\n\n    // we automatically add a trigger for auto add replicas if it does not exists already\n    // we also automatically add a scheduled maintenance trigger\n    while (!isClosed)  {\n      try {\n        if (Thread.currentThread().isInterrupted()) {\n          log.warn(\"Interrupted\");\n          break;\n        }\n        AutoScalingConfig autoScalingConfig = cloudManager.getDistribStateManager().getAutoScalingConfig();\n        AutoScalingConfig updatedConfig = withAutoAddReplicasTrigger(autoScalingConfig);\n        updatedConfig = withScheduledMaintenanceTrigger(updatedConfig);\n        if (updatedConfig.equals(autoScalingConfig)) break;\n        log.debug(\"Adding .auto_add_replicas and .scheduled_maintenance triggers\");\n        cloudManager.getDistribStateManager().setData(SOLR_AUTOSCALING_CONF_PATH, Utils.toJSON(updatedConfig), updatedConfig.getZkVersion());\n        break;\n      } catch (AlreadyClosedException e) {\n        break;\n      } catch (BadVersionException bve) {\n        // somebody else has changed the configuration so we must retry\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        log.warn(\"Interrupted\", e);\n        break;\n      }\n      catch (IOException | KeeperException e) {\n        if (e instanceof KeeperException.SessionExpiredException ||\n            (e.getCause()!=null && e.getCause() instanceof KeeperException.SessionExpiredException)) {\n          log.warn(\"Solr cannot talk to ZK, exiting \" + \n              getClass().getSimpleName() + \" main queue loop\", e);\n          return;\n        } else {\n          log.error(\"A ZK error has occurred\", e);\n        }\n      }\n    }\n\n    if (isClosed || Thread.currentThread().isInterrupted())  return;\n\n    try {\n      refreshAutoScalingConf(new AutoScalingWatcher());\n    } catch (ConnectException e) {\n      log.warn(\"ZooKeeper watch triggered for autoscaling conf, but Solr cannot talk to ZK: [{}]\", e.getMessage());\n    } catch (InterruptedException e) {\n      // Restore the interrupted status\n      Thread.currentThread().interrupt();\n      log.warn(\"Interrupted\", e);\n    } catch (Exception e)  {\n      log.error(\"Unexpected exception\", e);\n    }\n\n    while (true) {\n      Map<String, AutoScaling.Trigger> copy = null;\n      try {\n        \n        updateLock.lockInterruptibly();\n        try {\n          // must check for close here before we await on the condition otherwise we can\n          // only be woken up on interruption\n          if (isClosed) {\n            log.info(\"OverseerTriggerThread has been closed, exiting.\");\n            break;\n          }\n          \n          log.debug(\"Current znodeVersion {}, lastZnodeVersion {}\", znodeVersion, lastZnodeVersion);\n          \n          if (znodeVersion == lastZnodeVersion) {\n            updated.await();\n            \n            // are we closed?\n            if (isClosed) {\n              log.info(\"OverseerTriggerThread woken up but we are closed, exiting.\");\n              break;\n            }\n            \n            // spurious wakeup?\n            if (znodeVersion == lastZnodeVersion) continue;\n          }\n          copy = new HashMap<>(activeTriggers);\n          lastZnodeVersion = znodeVersion;\n          log.debug(\"Processed trigger updates upto znodeVersion {}\", znodeVersion);\n        } finally {\n          updateLock.unlock();\n        }\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        log.warn(\"Interrupted\", e);\n        break;\n      }\n     \n      // update the current config\n      scheduledTriggers.setAutoScalingConfig(autoScalingConfig);\n\n      Set<String> managedTriggerNames = scheduledTriggers.getScheduledTriggerNames();\n      // remove the triggers which are no longer active\n      for (String managedTriggerName : managedTriggerNames) {\n        if (!copy.containsKey(managedTriggerName)) {\n          scheduledTriggers.remove(managedTriggerName);\n        }\n      }\n      // nodeLost / nodeAdded markers are checked by triggers during their init() call\n      // which is invoked in scheduledTriggers.add(), so once this is done we can remove them\n      try {\n        // add new triggers and/or replace and close the replaced triggers\n        for (Map.Entry<String, AutoScaling.Trigger> entry : copy.entrySet()) {\n          try {\n            scheduledTriggers.add(entry.getValue());\n          } catch (AlreadyClosedException e) {\n\n          } catch (Exception e) {\n            log.warn(\"Exception initializing trigger \" + entry.getKey() + \", configuration ignored\", e);\n          }\n        }\n      } catch (AlreadyClosedException e) {\n        // this _should_ mean that we're closing, complain loudly if that's not the case\n        if (isClosed) {\n          return;\n        } else {\n          throw new IllegalStateException(\"Caught AlreadyClosedException from ScheduledTriggers, but we're not closed yet!\", e);\n        }\n      }\n      log.debug(\"-- deactivating old nodeLost / nodeAdded markers\");\n      deactivateMarkers(ZkStateReader.SOLR_AUTOSCALING_NODE_LOST_PATH);\n      deactivateMarkers(ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH);\n      processedZnodeVersion = znodeVersion;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e35f2dde06b35aa9904949a3a93fabd090371077","date":1587906921,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/autoscaling/OverseerTriggerThread#run().mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/autoscaling/OverseerTriggerThread#run().mjava","sourceNew":"  @Override\n  public void run() {\n    int lastZnodeVersion = znodeVersion;\n\n    // we automatically add a trigger for auto add replicas if it does not exists already\n    // we also automatically add a scheduled maintenance trigger\n    while (!isClosed)  {\n      try {\n        if (Thread.currentThread().isInterrupted()) {\n          log.warn(\"Interrupted\");\n          break;\n        }\n        AutoScalingConfig autoScalingConfig = cloudManager.getDistribStateManager().getAutoScalingConfig();\n        AutoScalingConfig updatedConfig = withDefaultPolicy(autoScalingConfig);\n        updatedConfig = withAutoAddReplicasTrigger(updatedConfig);\n        updatedConfig = withScheduledMaintenanceTrigger(updatedConfig);\n        if (updatedConfig.equals(autoScalingConfig)) break;\n        log.debug(\"Adding .auto_add_replicas and .scheduled_maintenance triggers\");\n        cloudManager.getDistribStateManager().setData(SOLR_AUTOSCALING_CONF_PATH, Utils.toJSON(updatedConfig), updatedConfig.getZkVersion());\n        break;\n      } catch (AlreadyClosedException e) {\n        break;\n      } catch (BadVersionException bve) {\n        // somebody else has changed the configuration so we must retry\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        log.warn(\"Interrupted\", e);\n        break;\n      }\n      catch (IOException | KeeperException e) {\n        if (e instanceof KeeperException.SessionExpiredException ||\n            (e.getCause()!=null && e.getCause() instanceof KeeperException.SessionExpiredException)) {\n          log.warn(\"Solr cannot talk to ZK, exiting {} main queue loop\"\n              , getClass().getSimpleName(), e);\n          return;\n        } else {\n          log.error(\"A ZK error has occurred\", e);\n        }\n      }\n    }\n\n    if (isClosed || Thread.currentThread().isInterrupted())  return;\n\n    try {\n      refreshAutoScalingConf(new AutoScalingWatcher());\n    } catch (ConnectException e) {\n      log.warn(\"ZooKeeper watch triggered for autoscaling conf, but Solr cannot talk to ZK: [{}]\", e.getMessage());\n    } catch (InterruptedException e) {\n      // Restore the interrupted status\n      Thread.currentThread().interrupt();\n      log.warn(\"Interrupted\", e);\n    } catch (Exception e)  {\n      log.error(\"Unexpected exception\", e);\n    }\n\n    while (true) {\n      Map<String, AutoScaling.Trigger> copy = null;\n      try {\n        \n        updateLock.lockInterruptibly();\n        try {\n          // must check for close here before we await on the condition otherwise we can\n          // only be woken up on interruption\n          if (isClosed) {\n            log.info(\"OverseerTriggerThread has been closed, exiting.\");\n            break;\n          }\n          \n          log.debug(\"Current znodeVersion {}, lastZnodeVersion {}\", znodeVersion, lastZnodeVersion);\n          \n          if (znodeVersion == lastZnodeVersion) {\n            updated.await();\n            \n            // are we closed?\n            if (isClosed) {\n              log.info(\"OverseerTriggerThread woken up but we are closed, exiting.\");\n              break;\n            }\n            \n            // spurious wakeup?\n            if (znodeVersion == lastZnodeVersion) continue;\n          }\n          copy = new HashMap<>(activeTriggers);\n          lastZnodeVersion = znodeVersion;\n          log.debug(\"Processed trigger updates upto znodeVersion {}\", znodeVersion);\n        } finally {\n          updateLock.unlock();\n        }\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        log.warn(\"Interrupted\", e);\n        break;\n      }\n     \n      // update the current config\n      scheduledTriggers.setAutoScalingConfig(autoScalingConfig);\n\n      Set<String> managedTriggerNames = scheduledTriggers.getScheduledTriggerNames();\n      // remove the triggers which are no longer active\n      for (String managedTriggerName : managedTriggerNames) {\n        if (!copy.containsKey(managedTriggerName)) {\n          scheduledTriggers.remove(managedTriggerName);\n        }\n      }\n      // nodeLost / nodeAdded markers are checked by triggers during their init() call\n      // which is invoked in scheduledTriggers.add(), so once this is done we can remove them\n      try {\n        // add new triggers and/or replace and close the replaced triggers\n        for (Map.Entry<String, AutoScaling.Trigger> entry : copy.entrySet()) {\n          try {\n            scheduledTriggers.add(entry.getValue());\n          } catch (AlreadyClosedException e) {\n\n          } catch (Exception e) {\n            log.warn(\"Exception initializing trigger {}, configuration ignored\", entry.getKey(), e);\n          }\n        }\n      } catch (AlreadyClosedException e) {\n        // this _should_ mean that we're closing, complain loudly if that's not the case\n        if (isClosed) {\n          return;\n        } else {\n          throw new IllegalStateException(\"Caught AlreadyClosedException from ScheduledTriggers, but we're not closed yet!\", e);\n        }\n      }\n      log.debug(\"-- deactivating old nodeLost / nodeAdded markers\");\n      deactivateMarkers(ZkStateReader.SOLR_AUTOSCALING_NODE_LOST_PATH);\n      deactivateMarkers(ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH);\n      processedZnodeVersion = znodeVersion;\n    }\n  }\n\n","sourceOld":"  @Override\n  public void run() {\n    int lastZnodeVersion = znodeVersion;\n\n    // we automatically add a trigger for auto add replicas if it does not exists already\n    // we also automatically add a scheduled maintenance trigger\n    while (!isClosed)  {\n      try {\n        if (Thread.currentThread().isInterrupted()) {\n          log.warn(\"Interrupted\");\n          break;\n        }\n        AutoScalingConfig autoScalingConfig = cloudManager.getDistribStateManager().getAutoScalingConfig();\n        AutoScalingConfig updatedConfig = withDefaultPolicy(autoScalingConfig);\n        updatedConfig = withAutoAddReplicasTrigger(updatedConfig);\n        updatedConfig = withScheduledMaintenanceTrigger(updatedConfig);\n        if (updatedConfig.equals(autoScalingConfig)) break;\n        log.debug(\"Adding .auto_add_replicas and .scheduled_maintenance triggers\");\n        cloudManager.getDistribStateManager().setData(SOLR_AUTOSCALING_CONF_PATH, Utils.toJSON(updatedConfig), updatedConfig.getZkVersion());\n        break;\n      } catch (AlreadyClosedException e) {\n        break;\n      } catch (BadVersionException bve) {\n        // somebody else has changed the configuration so we must retry\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        log.warn(\"Interrupted\", e);\n        break;\n      }\n      catch (IOException | KeeperException e) {\n        if (e instanceof KeeperException.SessionExpiredException ||\n            (e.getCause()!=null && e.getCause() instanceof KeeperException.SessionExpiredException)) {\n          log.warn(\"Solr cannot talk to ZK, exiting \" + \n              getClass().getSimpleName() + \" main queue loop\", e);\n          return;\n        } else {\n          log.error(\"A ZK error has occurred\", e);\n        }\n      }\n    }\n\n    if (isClosed || Thread.currentThread().isInterrupted())  return;\n\n    try {\n      refreshAutoScalingConf(new AutoScalingWatcher());\n    } catch (ConnectException e) {\n      log.warn(\"ZooKeeper watch triggered for autoscaling conf, but Solr cannot talk to ZK: [{}]\", e.getMessage());\n    } catch (InterruptedException e) {\n      // Restore the interrupted status\n      Thread.currentThread().interrupt();\n      log.warn(\"Interrupted\", e);\n    } catch (Exception e)  {\n      log.error(\"Unexpected exception\", e);\n    }\n\n    while (true) {\n      Map<String, AutoScaling.Trigger> copy = null;\n      try {\n        \n        updateLock.lockInterruptibly();\n        try {\n          // must check for close here before we await on the condition otherwise we can\n          // only be woken up on interruption\n          if (isClosed) {\n            log.info(\"OverseerTriggerThread has been closed, exiting.\");\n            break;\n          }\n          \n          log.debug(\"Current znodeVersion {}, lastZnodeVersion {}\", znodeVersion, lastZnodeVersion);\n          \n          if (znodeVersion == lastZnodeVersion) {\n            updated.await();\n            \n            // are we closed?\n            if (isClosed) {\n              log.info(\"OverseerTriggerThread woken up but we are closed, exiting.\");\n              break;\n            }\n            \n            // spurious wakeup?\n            if (znodeVersion == lastZnodeVersion) continue;\n          }\n          copy = new HashMap<>(activeTriggers);\n          lastZnodeVersion = znodeVersion;\n          log.debug(\"Processed trigger updates upto znodeVersion {}\", znodeVersion);\n        } finally {\n          updateLock.unlock();\n        }\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        log.warn(\"Interrupted\", e);\n        break;\n      }\n     \n      // update the current config\n      scheduledTriggers.setAutoScalingConfig(autoScalingConfig);\n\n      Set<String> managedTriggerNames = scheduledTriggers.getScheduledTriggerNames();\n      // remove the triggers which are no longer active\n      for (String managedTriggerName : managedTriggerNames) {\n        if (!copy.containsKey(managedTriggerName)) {\n          scheduledTriggers.remove(managedTriggerName);\n        }\n      }\n      // nodeLost / nodeAdded markers are checked by triggers during their init() call\n      // which is invoked in scheduledTriggers.add(), so once this is done we can remove them\n      try {\n        // add new triggers and/or replace and close the replaced triggers\n        for (Map.Entry<String, AutoScaling.Trigger> entry : copy.entrySet()) {\n          try {\n            scheduledTriggers.add(entry.getValue());\n          } catch (AlreadyClosedException e) {\n\n          } catch (Exception e) {\n            log.warn(\"Exception initializing trigger \" + entry.getKey() + \", configuration ignored\", e);\n          }\n        }\n      } catch (AlreadyClosedException e) {\n        // this _should_ mean that we're closing, complain loudly if that's not the case\n        if (isClosed) {\n          return;\n        } else {\n          throw new IllegalStateException(\"Caught AlreadyClosedException from ScheduledTriggers, but we're not closed yet!\", e);\n        }\n      }\n      log.debug(\"-- deactivating old nodeLost / nodeAdded markers\");\n      deactivateMarkers(ZkStateReader.SOLR_AUTOSCALING_NODE_LOST_PATH);\n      deactivateMarkers(ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH);\n      processedZnodeVersion = znodeVersion;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"57c238f5fb83803b49b37b3a1a12224a64d47542","date":1593655679,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/autoscaling/OverseerTriggerThread#run().mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/autoscaling/OverseerTriggerThread#run().mjava","sourceNew":"  @Override\n  public void run() {\n    int lastZnodeVersion = znodeVersion;\n\n    // we automatically add a trigger for auto add replicas if it does not exists already\n    // we also automatically add a scheduled maintenance trigger\n    while (!isClosed)  {\n      try {\n        if (Thread.currentThread().isInterrupted()) {\n          log.warn(\"Interrupted\");\n          break;\n        }\n        AutoScalingConfig autoScalingConfig = cloudManager.getDistribStateManager().getAutoScalingConfig();\n        AutoScalingConfig updatedConfig = withDefaultPolicy(autoScalingConfig);\n        updatedConfig = withAutoAddReplicasTrigger(updatedConfig);\n        updatedConfig = withScheduledMaintenanceTrigger(updatedConfig);\n        if (updatedConfig.equals(autoScalingConfig)) break;\n        log.debug(\"Adding .auto_add_replicas and .scheduled_maintenance triggers\");\n        cloudManager.getDistribStateManager().setData(SOLR_AUTOSCALING_CONF_PATH, Utils.toJSON(updatedConfig), updatedConfig.getZkVersion());\n        break;\n      } catch (AlreadyClosedException e) {\n        break;\n      } catch (BadVersionException bve) {\n        // somebody else has changed the configuration so we must retry\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        log.warn(\"Interrupted\", e);\n        break;\n      }\n      catch (IOException | KeeperException e) {\n        if (e instanceof KeeperException.SessionExpiredException ||\n            (e.getCause()!=null && e.getCause() instanceof KeeperException.SessionExpiredException)) {\n          log.warn(\"Solr cannot talk to ZK, exiting {} main queue loop\"\n              , getClass().getSimpleName(), e);\n          return;\n        } else {\n          log.error(\"A ZK error has occurred\", e);\n        }\n      }\n    }\n\n    if (isClosed || Thread.currentThread().isInterrupted())  return;\n\n    try {\n      refreshAutoScalingConf(new AutoScalingWatcher());\n    } catch (ConnectException e) {\n      log.warn(\"ZooKeeper watch triggered for autoscaling conf, but Solr cannot talk to ZK: \", e);\n    } catch (InterruptedException e) {\n      // Restore the interrupted status\n      Thread.currentThread().interrupt();\n      log.warn(\"Interrupted\", e);\n    } catch (Exception e)  {\n      log.error(\"Unexpected exception\", e);\n    }\n\n    while (true) {\n      Map<String, AutoScaling.Trigger> copy = null;\n      try {\n        \n        updateLock.lockInterruptibly();\n        try {\n          // must check for close here before we await on the condition otherwise we can\n          // only be woken up on interruption\n          if (isClosed) {\n            log.info(\"OverseerTriggerThread has been closed, exiting.\");\n            break;\n          }\n          \n          log.debug(\"Current znodeVersion {}, lastZnodeVersion {}\", znodeVersion, lastZnodeVersion);\n          \n          if (znodeVersion == lastZnodeVersion) {\n            updated.await();\n            \n            // are we closed?\n            if (isClosed) {\n              log.info(\"OverseerTriggerThread woken up but we are closed, exiting.\");\n              break;\n            }\n            \n            // spurious wakeup?\n            if (znodeVersion == lastZnodeVersion) continue;\n          }\n          copy = new HashMap<>(activeTriggers);\n          lastZnodeVersion = znodeVersion;\n          log.debug(\"Processed trigger updates upto znodeVersion {}\", znodeVersion);\n        } finally {\n          updateLock.unlock();\n        }\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        log.warn(\"Interrupted\", e);\n        break;\n      }\n     \n      // update the current config\n      scheduledTriggers.setAutoScalingConfig(autoScalingConfig);\n\n      Set<String> managedTriggerNames = scheduledTriggers.getScheduledTriggerNames();\n      // remove the triggers which are no longer active\n      for (String managedTriggerName : managedTriggerNames) {\n        if (!copy.containsKey(managedTriggerName)) {\n          scheduledTriggers.remove(managedTriggerName);\n        }\n      }\n      // nodeLost / nodeAdded markers are checked by triggers during their init() call\n      // which is invoked in scheduledTriggers.add(), so once this is done we can remove them\n      try {\n        // add new triggers and/or replace and close the replaced triggers\n        for (Map.Entry<String, AutoScaling.Trigger> entry : copy.entrySet()) {\n          try {\n            scheduledTriggers.add(entry.getValue());\n          } catch (AlreadyClosedException e) {\n\n          } catch (Exception e) {\n            log.warn(\"Exception initializing trigger {}, configuration ignored\", entry.getKey(), e);\n          }\n        }\n      } catch (AlreadyClosedException e) {\n        // this _should_ mean that we're closing, complain loudly if that's not the case\n        if (isClosed) {\n          return;\n        } else {\n          throw new IllegalStateException(\"Caught AlreadyClosedException from ScheduledTriggers, but we're not closed yet!\", e);\n        }\n      }\n      log.debug(\"-- deactivating old nodeLost / nodeAdded markers\");\n      deactivateMarkers(ZkStateReader.SOLR_AUTOSCALING_NODE_LOST_PATH);\n      deactivateMarkers(ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH);\n      processedZnodeVersion = znodeVersion;\n    }\n  }\n\n","sourceOld":"  @Override\n  public void run() {\n    int lastZnodeVersion = znodeVersion;\n\n    // we automatically add a trigger for auto add replicas if it does not exists already\n    // we also automatically add a scheduled maintenance trigger\n    while (!isClosed)  {\n      try {\n        if (Thread.currentThread().isInterrupted()) {\n          log.warn(\"Interrupted\");\n          break;\n        }\n        AutoScalingConfig autoScalingConfig = cloudManager.getDistribStateManager().getAutoScalingConfig();\n        AutoScalingConfig updatedConfig = withDefaultPolicy(autoScalingConfig);\n        updatedConfig = withAutoAddReplicasTrigger(updatedConfig);\n        updatedConfig = withScheduledMaintenanceTrigger(updatedConfig);\n        if (updatedConfig.equals(autoScalingConfig)) break;\n        log.debug(\"Adding .auto_add_replicas and .scheduled_maintenance triggers\");\n        cloudManager.getDistribStateManager().setData(SOLR_AUTOSCALING_CONF_PATH, Utils.toJSON(updatedConfig), updatedConfig.getZkVersion());\n        break;\n      } catch (AlreadyClosedException e) {\n        break;\n      } catch (BadVersionException bve) {\n        // somebody else has changed the configuration so we must retry\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        log.warn(\"Interrupted\", e);\n        break;\n      }\n      catch (IOException | KeeperException e) {\n        if (e instanceof KeeperException.SessionExpiredException ||\n            (e.getCause()!=null && e.getCause() instanceof KeeperException.SessionExpiredException)) {\n          log.warn(\"Solr cannot talk to ZK, exiting {} main queue loop\"\n              , getClass().getSimpleName(), e);\n          return;\n        } else {\n          log.error(\"A ZK error has occurred\", e);\n        }\n      }\n    }\n\n    if (isClosed || Thread.currentThread().isInterrupted())  return;\n\n    try {\n      refreshAutoScalingConf(new AutoScalingWatcher());\n    } catch (ConnectException e) {\n      log.warn(\"ZooKeeper watch triggered for autoscaling conf, but Solr cannot talk to ZK: [{}]\", e.getMessage());\n    } catch (InterruptedException e) {\n      // Restore the interrupted status\n      Thread.currentThread().interrupt();\n      log.warn(\"Interrupted\", e);\n    } catch (Exception e)  {\n      log.error(\"Unexpected exception\", e);\n    }\n\n    while (true) {\n      Map<String, AutoScaling.Trigger> copy = null;\n      try {\n        \n        updateLock.lockInterruptibly();\n        try {\n          // must check for close here before we await on the condition otherwise we can\n          // only be woken up on interruption\n          if (isClosed) {\n            log.info(\"OverseerTriggerThread has been closed, exiting.\");\n            break;\n          }\n          \n          log.debug(\"Current znodeVersion {}, lastZnodeVersion {}\", znodeVersion, lastZnodeVersion);\n          \n          if (znodeVersion == lastZnodeVersion) {\n            updated.await();\n            \n            // are we closed?\n            if (isClosed) {\n              log.info(\"OverseerTriggerThread woken up but we are closed, exiting.\");\n              break;\n            }\n            \n            // spurious wakeup?\n            if (znodeVersion == lastZnodeVersion) continue;\n          }\n          copy = new HashMap<>(activeTriggers);\n          lastZnodeVersion = znodeVersion;\n          log.debug(\"Processed trigger updates upto znodeVersion {}\", znodeVersion);\n        } finally {\n          updateLock.unlock();\n        }\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        log.warn(\"Interrupted\", e);\n        break;\n      }\n     \n      // update the current config\n      scheduledTriggers.setAutoScalingConfig(autoScalingConfig);\n\n      Set<String> managedTriggerNames = scheduledTriggers.getScheduledTriggerNames();\n      // remove the triggers which are no longer active\n      for (String managedTriggerName : managedTriggerNames) {\n        if (!copy.containsKey(managedTriggerName)) {\n          scheduledTriggers.remove(managedTriggerName);\n        }\n      }\n      // nodeLost / nodeAdded markers are checked by triggers during their init() call\n      // which is invoked in scheduledTriggers.add(), so once this is done we can remove them\n      try {\n        // add new triggers and/or replace and close the replaced triggers\n        for (Map.Entry<String, AutoScaling.Trigger> entry : copy.entrySet()) {\n          try {\n            scheduledTriggers.add(entry.getValue());\n          } catch (AlreadyClosedException e) {\n\n          } catch (Exception e) {\n            log.warn(\"Exception initializing trigger {}, configuration ignored\", entry.getKey(), e);\n          }\n        }\n      } catch (AlreadyClosedException e) {\n        // this _should_ mean that we're closing, complain loudly if that's not the case\n        if (isClosed) {\n          return;\n        } else {\n          throw new IllegalStateException(\"Caught AlreadyClosedException from ScheduledTriggers, but we're not closed yet!\", e);\n        }\n      }\n      log.debug(\"-- deactivating old nodeLost / nodeAdded markers\");\n      deactivateMarkers(ZkStateReader.SOLR_AUTOSCALING_NODE_LOST_PATH);\n      deactivateMarkers(ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH);\n      processedZnodeVersion = znodeVersion;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3f504512a03d978990cbff30db0522b354e846db","date":1595247421,"type":4,"author":"Ishan Chattopadhyaya","isMerge":false,"pathNew":"/dev/null","pathOld":"solr/core/src/java/org/apache/solr/cloud/autoscaling/OverseerTriggerThread#run().mjava","sourceNew":null,"sourceOld":"  @Override\n  public void run() {\n    int lastZnodeVersion = znodeVersion;\n\n    // we automatically add a trigger for auto add replicas if it does not exists already\n    // we also automatically add a scheduled maintenance trigger\n    while (!isClosed)  {\n      try {\n        if (Thread.currentThread().isInterrupted()) {\n          log.warn(\"Interrupted\");\n          break;\n        }\n        AutoScalingConfig autoScalingConfig = cloudManager.getDistribStateManager().getAutoScalingConfig();\n        AutoScalingConfig updatedConfig = withDefaultPolicy(autoScalingConfig);\n        updatedConfig = withAutoAddReplicasTrigger(updatedConfig);\n        updatedConfig = withScheduledMaintenanceTrigger(updatedConfig);\n        if (updatedConfig.equals(autoScalingConfig)) break;\n        log.debug(\"Adding .auto_add_replicas and .scheduled_maintenance triggers\");\n        cloudManager.getDistribStateManager().setData(SOLR_AUTOSCALING_CONF_PATH, Utils.toJSON(updatedConfig), updatedConfig.getZkVersion());\n        break;\n      } catch (AlreadyClosedException e) {\n        break;\n      } catch (BadVersionException bve) {\n        // somebody else has changed the configuration so we must retry\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        log.warn(\"Interrupted\", e);\n        break;\n      }\n      catch (IOException | KeeperException e) {\n        if (e instanceof KeeperException.SessionExpiredException ||\n            (e.getCause()!=null && e.getCause() instanceof KeeperException.SessionExpiredException)) {\n          log.warn(\"Solr cannot talk to ZK, exiting {} main queue loop\"\n              , getClass().getSimpleName(), e);\n          return;\n        } else {\n          log.error(\"A ZK error has occurred\", e);\n        }\n      }\n    }\n\n    if (isClosed || Thread.currentThread().isInterrupted())  return;\n\n    try {\n      refreshAutoScalingConf(new AutoScalingWatcher());\n    } catch (ConnectException e) {\n      log.warn(\"ZooKeeper watch triggered for autoscaling conf, but Solr cannot talk to ZK: \", e);\n    } catch (InterruptedException e) {\n      // Restore the interrupted status\n      Thread.currentThread().interrupt();\n      log.warn(\"Interrupted\", e);\n    } catch (Exception e)  {\n      log.error(\"Unexpected exception\", e);\n    }\n\n    while (true) {\n      Map<String, AutoScaling.Trigger> copy = null;\n      try {\n        \n        updateLock.lockInterruptibly();\n        try {\n          // must check for close here before we await on the condition otherwise we can\n          // only be woken up on interruption\n          if (isClosed) {\n            log.info(\"OverseerTriggerThread has been closed, exiting.\");\n            break;\n          }\n          \n          log.debug(\"Current znodeVersion {}, lastZnodeVersion {}\", znodeVersion, lastZnodeVersion);\n          \n          if (znodeVersion == lastZnodeVersion) {\n            updated.await();\n            \n            // are we closed?\n            if (isClosed) {\n              log.info(\"OverseerTriggerThread woken up but we are closed, exiting.\");\n              break;\n            }\n            \n            // spurious wakeup?\n            if (znodeVersion == lastZnodeVersion) continue;\n          }\n          copy = new HashMap<>(activeTriggers);\n          lastZnodeVersion = znodeVersion;\n          log.debug(\"Processed trigger updates upto znodeVersion {}\", znodeVersion);\n        } finally {\n          updateLock.unlock();\n        }\n      } catch (InterruptedException e) {\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        log.warn(\"Interrupted\", e);\n        break;\n      }\n     \n      // update the current config\n      scheduledTriggers.setAutoScalingConfig(autoScalingConfig);\n\n      Set<String> managedTriggerNames = scheduledTriggers.getScheduledTriggerNames();\n      // remove the triggers which are no longer active\n      for (String managedTriggerName : managedTriggerNames) {\n        if (!copy.containsKey(managedTriggerName)) {\n          scheduledTriggers.remove(managedTriggerName);\n        }\n      }\n      // nodeLost / nodeAdded markers are checked by triggers during their init() call\n      // which is invoked in scheduledTriggers.add(), so once this is done we can remove them\n      try {\n        // add new triggers and/or replace and close the replaced triggers\n        for (Map.Entry<String, AutoScaling.Trigger> entry : copy.entrySet()) {\n          try {\n            scheduledTriggers.add(entry.getValue());\n          } catch (AlreadyClosedException e) {\n\n          } catch (Exception e) {\n            log.warn(\"Exception initializing trigger {}, configuration ignored\", entry.getKey(), e);\n          }\n        }\n      } catch (AlreadyClosedException e) {\n        // this _should_ mean that we're closing, complain loudly if that's not the case\n        if (isClosed) {\n          return;\n        } else {\n          throw new IllegalStateException(\"Caught AlreadyClosedException from ScheduledTriggers, but we're not closed yet!\", e);\n        }\n      }\n      log.debug(\"-- deactivating old nodeLost / nodeAdded markers\");\n      deactivateMarkers(ZkStateReader.SOLR_AUTOSCALING_NODE_LOST_PATH);\n      deactivateMarkers(ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH);\n      processedZnodeVersion = znodeVersion;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"c304e97e7c1d472bc70e801b35ee78583916c6cd":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","bc9e0ccf4cd88f932a18bc65e24c83e8d011f404"],"bb222a3f9d9421d5c95afce73013fbd8de07ea1f":["dfc7ed9ce80483ee93bdefc775dae05360f20f4b"],"263092c0f07c163d73a8be27ba212aaf7e76bd40":["326b5c746af092eb827c5c1accdab1b47fe0cf3c"],"cd44b11f5d211a0b76c6bc536f38d1eb1fe00c8d":["f5cada899191a744eac4b584b75dd3103c26a394"],"219ac4e012cb38bcfcd8f4290dccd4f5b4d7bc25":["c5fd294da67452cd8d116692194908de00eb5209"],"f7fb1186f5b61e0b74289e6786df8cbecfa471bc":["bb222a3f9d9421d5c95afce73013fbd8de07ea1f"],"f5cada899191a744eac4b584b75dd3103c26a394":["9c6c0dad4932399aec99b4818086cb1772773916"],"9c787ffd984133d984d6b651ed48f0db5347aeac":["35b336749840ccc5e7c88aa0a787fc6e3730d6e7"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"dfc7ed9ce80483ee93bdefc775dae05360f20f4b":["cd44b11f5d211a0b76c6bc536f38d1eb1fe00c8d"],"1d4bf9d5308dfef350829c28f2b3b2648df1e9b1":["85212dad4ed576c7f7e6c165ee19e597b7b4efc8"],"560c18d71dad43d675158783c3840f8c80d6d39c":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","c304e97e7c1d472bc70e801b35ee78583916c6cd"],"664ff2b928393480d9655010aa700656b0fcade0":["7aa2c1715ef9a80383edea1048655da291ed9b8f","c32a8448145a74a8902798f2e63e322827757ff2"],"c7ff8a6fbdc9c2d84bc6e9e71e1c738e49c441ac":["ea36a4664361dde6d195f6ec9e7487a621caaa69"],"6ca81a50d0a6c6f97f1e2b15ef90c5bd81765d09":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"3f504512a03d978990cbff30db0522b354e846db":["57c238f5fb83803b49b37b3a1a12224a64d47542"],"35b336749840ccc5e7c88aa0a787fc6e3730d6e7":["f7fb1186f5b61e0b74289e6786df8cbecfa471bc"],"57c238f5fb83803b49b37b3a1a12224a64d47542":["e35f2dde06b35aa9904949a3a93fabd090371077"],"85212dad4ed576c7f7e6c165ee19e597b7b4efc8":["560c18d71dad43d675158783c3840f8c80d6d39c"],"067ba8c807b0f23eae8bf41bc27046a87b548134":["98d4af357762468d37df7424f81785cd89b49a7b"],"b869898f50ca80263bac2e3ae0949f7700e5c977":["c7ff8a6fbdc9c2d84bc6e9e71e1c738e49c441ac"],"326b5c746af092eb827c5c1accdab1b47fe0cf3c":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","6ca81a50d0a6c6f97f1e2b15ef90c5bd81765d09"],"9c6c0dad4932399aec99b4818086cb1772773916":["1d4bf9d5308dfef350829c28f2b3b2648df1e9b1"],"ea36a4664361dde6d195f6ec9e7487a621caaa69":["219ac4e012cb38bcfcd8f4290dccd4f5b4d7bc25"],"7aa2c1715ef9a80383edea1048655da291ed9b8f":["263092c0f07c163d73a8be27ba212aaf7e76bd40"],"98d4af357762468d37df7424f81785cd89b49a7b":["9c787ffd984133d984d6b651ed48f0db5347aeac"],"c5fd294da67452cd8d116692194908de00eb5209":["664ff2b928393480d9655010aa700656b0fcade0"],"e35f2dde06b35aa9904949a3a93fabd090371077":["067ba8c807b0f23eae8bf41bc27046a87b548134"],"c32a8448145a74a8902798f2e63e322827757ff2":["7aa2c1715ef9a80383edea1048655da291ed9b8f"],"d74e47b708b42ff110911e64513d0e872ac2577b":["b6c71577c4ee99246f48a2c29bc213daab310ee5"],"b6c71577c4ee99246f48a2c29bc213daab310ee5":["b869898f50ca80263bac2e3ae0949f7700e5c977"],"bc9e0ccf4cd88f932a18bc65e24c83e8d011f404":["d74e47b708b42ff110911e64513d0e872ac2577b"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["3f504512a03d978990cbff30db0522b354e846db"],"b0b597c65628ca9e73913a07e81691f8229bae35":["9c787ffd984133d984d6b651ed48f0db5347aeac","98d4af357762468d37df7424f81785cd89b49a7b"]},"commit2Childs":{"c304e97e7c1d472bc70e801b35ee78583916c6cd":["560c18d71dad43d675158783c3840f8c80d6d39c"],"bb222a3f9d9421d5c95afce73013fbd8de07ea1f":["f7fb1186f5b61e0b74289e6786df8cbecfa471bc"],"263092c0f07c163d73a8be27ba212aaf7e76bd40":["7aa2c1715ef9a80383edea1048655da291ed9b8f"],"cd44b11f5d211a0b76c6bc536f38d1eb1fe00c8d":["dfc7ed9ce80483ee93bdefc775dae05360f20f4b"],"219ac4e012cb38bcfcd8f4290dccd4f5b4d7bc25":["ea36a4664361dde6d195f6ec9e7487a621caaa69"],"f7fb1186f5b61e0b74289e6786df8cbecfa471bc":["35b336749840ccc5e7c88aa0a787fc6e3730d6e7"],"f5cada899191a744eac4b584b75dd3103c26a394":["cd44b11f5d211a0b76c6bc536f38d1eb1fe00c8d"],"9c787ffd984133d984d6b651ed48f0db5347aeac":["98d4af357762468d37df7424f81785cd89b49a7b","b0b597c65628ca9e73913a07e81691f8229bae35"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["c304e97e7c1d472bc70e801b35ee78583916c6cd","560c18d71dad43d675158783c3840f8c80d6d39c","6ca81a50d0a6c6f97f1e2b15ef90c5bd81765d09","326b5c746af092eb827c5c1accdab1b47fe0cf3c"],"dfc7ed9ce80483ee93bdefc775dae05360f20f4b":["bb222a3f9d9421d5c95afce73013fbd8de07ea1f"],"1d4bf9d5308dfef350829c28f2b3b2648df1e9b1":["9c6c0dad4932399aec99b4818086cb1772773916"],"560c18d71dad43d675158783c3840f8c80d6d39c":["85212dad4ed576c7f7e6c165ee19e597b7b4efc8"],"664ff2b928393480d9655010aa700656b0fcade0":["c5fd294da67452cd8d116692194908de00eb5209"],"c7ff8a6fbdc9c2d84bc6e9e71e1c738e49c441ac":["b869898f50ca80263bac2e3ae0949f7700e5c977"],"6ca81a50d0a6c6f97f1e2b15ef90c5bd81765d09":["326b5c746af092eb827c5c1accdab1b47fe0cf3c"],"3f504512a03d978990cbff30db0522b354e846db":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"35b336749840ccc5e7c88aa0a787fc6e3730d6e7":["9c787ffd984133d984d6b651ed48f0db5347aeac"],"85212dad4ed576c7f7e6c165ee19e597b7b4efc8":["1d4bf9d5308dfef350829c28f2b3b2648df1e9b1"],"57c238f5fb83803b49b37b3a1a12224a64d47542":["3f504512a03d978990cbff30db0522b354e846db"],"067ba8c807b0f23eae8bf41bc27046a87b548134":["e35f2dde06b35aa9904949a3a93fabd090371077"],"b869898f50ca80263bac2e3ae0949f7700e5c977":["b6c71577c4ee99246f48a2c29bc213daab310ee5"],"326b5c746af092eb827c5c1accdab1b47fe0cf3c":["263092c0f07c163d73a8be27ba212aaf7e76bd40"],"9c6c0dad4932399aec99b4818086cb1772773916":["f5cada899191a744eac4b584b75dd3103c26a394"],"7aa2c1715ef9a80383edea1048655da291ed9b8f":["664ff2b928393480d9655010aa700656b0fcade0","c32a8448145a74a8902798f2e63e322827757ff2"],"ea36a4664361dde6d195f6ec9e7487a621caaa69":["c7ff8a6fbdc9c2d84bc6e9e71e1c738e49c441ac"],"c5fd294da67452cd8d116692194908de00eb5209":["219ac4e012cb38bcfcd8f4290dccd4f5b4d7bc25"],"98d4af357762468d37df7424f81785cd89b49a7b":["067ba8c807b0f23eae8bf41bc27046a87b548134","b0b597c65628ca9e73913a07e81691f8229bae35"],"c32a8448145a74a8902798f2e63e322827757ff2":["664ff2b928393480d9655010aa700656b0fcade0"],"e35f2dde06b35aa9904949a3a93fabd090371077":["57c238f5fb83803b49b37b3a1a12224a64d47542"],"d74e47b708b42ff110911e64513d0e872ac2577b":["bc9e0ccf4cd88f932a18bc65e24c83e8d011f404"],"b6c71577c4ee99246f48a2c29bc213daab310ee5":["d74e47b708b42ff110911e64513d0e872ac2577b"],"bc9e0ccf4cd88f932a18bc65e24c83e8d011f404":["c304e97e7c1d472bc70e801b35ee78583916c6cd"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"b0b597c65628ca9e73913a07e81691f8229bae35":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817","b0b597c65628ca9e73913a07e81691f8229bae35"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}