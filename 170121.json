{"path":"lucene/contrib/ant/src/java/org/apache/lucene/ant/IndexTask#indexDocs().mjava","commits":[{"id":"9454a6510e2db155fb01faa5c049b06ece95fab9","date":1453508333,"type":1,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/contrib/ant/src/java/org/apache/lucene/ant/IndexTask#indexDocs().mjava","pathOld":"contrib/ant/src/java/org/apache/lucene/ant/IndexTask#indexDocs().mjava","sourceNew":"  /**\n   * Index the fileset.\n   *\n   *@exception  IOException if Lucene I/O exception\n   *TODO: refactor!!!!!\n   */\n  private void indexDocs() throws IOException {\n    Date start = new Date();\n\n    boolean create = overwrite;\n    // If the index directory doesn't exist,\n    // create it and force create mode\n    if (indexDir.mkdirs() && !overwrite) {\n      create = true;\n    }\n\n    FSDirectory dir = FSDirectory.open(indexDir);\n    try {\n      Searcher searcher = null;\n      boolean checkLastModified = false;\n      if (!create) {\n        try {\n          searcher = new IndexSearcher(dir, true);\n          checkLastModified = true;\n        } catch (IOException ioe) {\n          log(\"IOException: \" + ioe.getMessage());\n          // Empty - ignore, which indicates to index all\n          // documents\n        }\n      }\n\n      log(\"checkLastModified = \" + checkLastModified, Project.MSG_VERBOSE);\n\n      IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig(\n          Version.LUCENE_CURRENT, analyzer).setOpenMode(\n          create ? OpenMode.CREATE : OpenMode.APPEND));\n      LogMergePolicy lmp = (LogMergePolicy) writer.getMergePolicy();\n      lmp.setUseCompoundFile(useCompoundIndex);\n      lmp.setUseCompoundDocStore(useCompoundIndex);\n      lmp.setMergeFactor(mergeFactor);\n      int totalFiles = 0;\n      int totalIndexed = 0;\n      int totalIgnored = 0;\n      try {\n\n        for (int i = 0; i < rcs.size(); i++) {\n          ResourceCollection rc = rcs.elementAt(i);\n          if (rc.isFilesystemOnly()) {\n            Iterator resources = rc.iterator();\n            while (resources.hasNext()) {\n              Resource r = (Resource) resources.next();\n              if (!r.isExists() || !(r instanceof FileResource)) {\n                continue;\n              }\n              \n              totalFiles++;\n\n              File file = ((FileResource) r).getFile();\n              \n              if (!file.exists() || !file.canRead()) {\n                throw new BuildException(\"File \\\"\" +\n                                         file.getAbsolutePath()\n                                         + \"\\\" does not exist or is not readable.\");\n              }\n\n              boolean indexIt = true;\n\n              if (checkLastModified) {\n                Term pathTerm =\n                  new Term(\"path\", file.getPath());\n                TermQuery query =\n                  new TermQuery(pathTerm);\n                ScoreDoc[] hits = searcher.search(query, null, 1).scoreDocs;\n\n                // if document is found, compare the\n                // indexed last modified time with the\n                // current file\n                // - don't index if up to date\n                if (hits.length > 0) {\n                  Document doc = searcher.doc(hits[0].doc);\n                  String indexModified =\n                    doc.get(\"modified\").trim();\n                  if (indexModified != null) {\n                    long lastModified = 0;\n                    try {\n                      lastModified = DateTools.stringToTime(indexModified);\n                    } catch (ParseException e) {\n                      // if modified time is not parsable, skip\n                    }\n                    if (lastModified == file.lastModified()) {\n                      // TODO: remove existing document\n                      indexIt = false;\n                    }\n                  }\n                }\n              }\n\n              if (indexIt) {\n                try {\n                  log(\"Indexing \" + file.getPath(),\n                      Project.MSG_VERBOSE);\n                  Document doc =\n                    handler.getDocument(file);\n\n                  if (doc == null) {\n                    totalIgnored++;\n                  } else {\n                    // Add the path of the file as a field named \"path\".  Use a Keyword field, so\n                    // that the index stores the path, and so that the path is searchable\n                    doc.add(new Field(\"path\", file.getPath(), Field.Store.YES, Field.Index.NOT_ANALYZED));\n\n                    // Add the last modified date of the file a field named \"modified\".  Use a\n                    // Keyword field, so that it's searchable, but so that no attempt is made\n                    // to tokenize the field into words.\n                    doc.add(new Field(\"modified\", DateTools.timeToString(file.lastModified(), DateTools.Resolution.MILLISECOND), Field.Store.YES, Field.Index.NOT_ANALYZED));\n\n                    writer.addDocument(doc);\n                    totalIndexed++;\n                  }\n                } catch (DocumentHandlerException e) {\n                  throw new BuildException(e);\n                }\n              }\n            }\n            // for j\n          }\n          // if (fs != null)\n        }\n        // for i\n\n        writer.optimize();\n      }\n        //try\n      finally {\n        // always make sure everything gets closed,\n        // no matter how we exit.\n        writer.close();\n        if (searcher != null) {\n          searcher.close();\n        }\n      }\n\n      Date end = new Date();\n\n      log(totalIndexed + \" out of \" + totalFiles + \" indexed (\" +\n          totalIgnored + \" ignored) in \" + (end.getTime() - start.getTime()) +\n          \" milliseconds\");\n    } finally {\n      dir.close();\n    }\n  }\n\n","sourceOld":"  /**\n   * Index the fileset.\n   *\n   *@exception  IOException if Lucene I/O exception\n   *TODO: refactor!!!!!\n   */\n  private void indexDocs() throws IOException {\n    Date start = new Date();\n\n    boolean create = overwrite;\n    // If the index directory doesn't exist,\n    // create it and force create mode\n    if (indexDir.mkdirs() && !overwrite) {\n      create = true;\n    }\n\n    FSDirectory dir = FSDirectory.open(indexDir);\n    try {\n      Searcher searcher = null;\n      boolean checkLastModified = false;\n      if (!create) {\n        try {\n          searcher = new IndexSearcher(dir, true);\n          checkLastModified = true;\n        } catch (IOException ioe) {\n          log(\"IOException: \" + ioe.getMessage());\n          // Empty - ignore, which indicates to index all\n          // documents\n        }\n      }\n\n      log(\"checkLastModified = \" + checkLastModified, Project.MSG_VERBOSE);\n\n      IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig(\n          Version.LUCENE_CURRENT, analyzer).setOpenMode(\n          create ? OpenMode.CREATE : OpenMode.APPEND));\n      LogMergePolicy lmp = (LogMergePolicy) writer.getMergePolicy();\n      lmp.setUseCompoundFile(useCompoundIndex);\n      lmp.setUseCompoundDocStore(useCompoundIndex);\n      lmp.setMergeFactor(mergeFactor);\n      int totalFiles = 0;\n      int totalIndexed = 0;\n      int totalIgnored = 0;\n      try {\n\n        for (int i = 0; i < rcs.size(); i++) {\n          ResourceCollection rc = rcs.elementAt(i);\n          if (rc.isFilesystemOnly()) {\n            Iterator resources = rc.iterator();\n            while (resources.hasNext()) {\n              Resource r = (Resource) resources.next();\n              if (!r.isExists() || !(r instanceof FileResource)) {\n                continue;\n              }\n              \n              totalFiles++;\n\n              File file = ((FileResource) r).getFile();\n              \n              if (!file.exists() || !file.canRead()) {\n                throw new BuildException(\"File \\\"\" +\n                                         file.getAbsolutePath()\n                                         + \"\\\" does not exist or is not readable.\");\n              }\n\n              boolean indexIt = true;\n\n              if (checkLastModified) {\n                Term pathTerm =\n                  new Term(\"path\", file.getPath());\n                TermQuery query =\n                  new TermQuery(pathTerm);\n                ScoreDoc[] hits = searcher.search(query, null, 1).scoreDocs;\n\n                // if document is found, compare the\n                // indexed last modified time with the\n                // current file\n                // - don't index if up to date\n                if (hits.length > 0) {\n                  Document doc = searcher.doc(hits[0].doc);\n                  String indexModified =\n                    doc.get(\"modified\").trim();\n                  if (indexModified != null) {\n                    long lastModified = 0;\n                    try {\n                      lastModified = DateTools.stringToTime(indexModified);\n                    } catch (ParseException e) {\n                      // if modified time is not parsable, skip\n                    }\n                    if (lastModified == file.lastModified()) {\n                      // TODO: remove existing document\n                      indexIt = false;\n                    }\n                  }\n                }\n              }\n\n              if (indexIt) {\n                try {\n                  log(\"Indexing \" + file.getPath(),\n                      Project.MSG_VERBOSE);\n                  Document doc =\n                    handler.getDocument(file);\n\n                  if (doc == null) {\n                    totalIgnored++;\n                  } else {\n                    // Add the path of the file as a field named \"path\".  Use a Keyword field, so\n                    // that the index stores the path, and so that the path is searchable\n                    doc.add(new Field(\"path\", file.getPath(), Field.Store.YES, Field.Index.NOT_ANALYZED));\n\n                    // Add the last modified date of the file a field named \"modified\".  Use a\n                    // Keyword field, so that it's searchable, but so that no attempt is made\n                    // to tokenize the field into words.\n                    doc.add(new Field(\"modified\", DateTools.timeToString(file.lastModified(), DateTools.Resolution.MILLISECOND), Field.Store.YES, Field.Index.NOT_ANALYZED));\n\n                    writer.addDocument(doc);\n                    totalIndexed++;\n                  }\n                } catch (DocumentHandlerException e) {\n                  throw new BuildException(e);\n                }\n              }\n            }\n            // for j\n          }\n          // if (fs != null)\n        }\n        // for i\n\n        writer.optimize();\n      }\n        //try\n      finally {\n        // always make sure everything gets closed,\n        // no matter how we exit.\n        writer.close();\n        if (searcher != null) {\n          searcher.close();\n        }\n      }\n\n      Date end = new Date();\n\n      log(totalIndexed + \" out of \" + totalFiles + \" indexed (\" +\n          totalIgnored + \" ignored) in \" + (end.getTime() - start.getTime()) +\n          \" milliseconds\");\n    } finally {\n      dir.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7ab99e8c71442b92c320e218141dee04a9b91ce8","date":1269203801,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/contrib/ant/src/java/org/apache/lucene/ant/IndexTask#indexDocs().mjava","pathOld":"lucene/contrib/ant/src/java/org/apache/lucene/ant/IndexTask#indexDocs().mjava","sourceNew":"  /**\n   * Index the fileset.\n   *\n   *@exception  IOException if Lucene I/O exception\n   *TODO: refactor!!!!!\n   */\n  private void indexDocs() throws IOException {\n    Date start = new Date();\n\n    boolean create = overwrite;\n    // If the index directory doesn't exist,\n    // create it and force create mode\n    if (indexDir.mkdirs() && !overwrite) {\n      create = true;\n    }\n\n    FSDirectory dir = FSDirectory.open(indexDir);\n    try {\n      Searcher searcher = null;\n      boolean checkLastModified = false;\n      if (!create) {\n        try {\n          searcher = new IndexSearcher(dir, true);\n          checkLastModified = true;\n        } catch (IOException ioe) {\n          log(\"IOException: \" + ioe.getMessage());\n          // Empty - ignore, which indicates to index all\n          // documents\n        }\n      }\n\n      log(\"checkLastModified = \" + checkLastModified, Project.MSG_VERBOSE);\n\n      IndexWriterConfig conf = new IndexWriterConfig(\n          Version.LUCENE_CURRENT, analyzer).setOpenMode(\n          create ? OpenMode.CREATE : OpenMode.APPEND);\n      LogMergePolicy lmp = (LogMergePolicy) conf.getMergePolicy();\n      lmp.setUseCompoundFile(useCompoundIndex);\n      lmp.setUseCompoundDocStore(useCompoundIndex);\n      lmp.setMergeFactor(mergeFactor);\n      IndexWriter writer = new IndexWriter(dir, conf);\n      int totalFiles = 0;\n      int totalIndexed = 0;\n      int totalIgnored = 0;\n      try {\n\n        for (int i = 0; i < rcs.size(); i++) {\n          ResourceCollection rc = rcs.elementAt(i);\n          if (rc.isFilesystemOnly()) {\n            Iterator resources = rc.iterator();\n            while (resources.hasNext()) {\n              Resource r = (Resource) resources.next();\n              if (!r.isExists() || !(r instanceof FileResource)) {\n                continue;\n              }\n              \n              totalFiles++;\n\n              File file = ((FileResource) r).getFile();\n              \n              if (!file.exists() || !file.canRead()) {\n                throw new BuildException(\"File \\\"\" +\n                                         file.getAbsolutePath()\n                                         + \"\\\" does not exist or is not readable.\");\n              }\n\n              boolean indexIt = true;\n\n              if (checkLastModified) {\n                Term pathTerm =\n                  new Term(\"path\", file.getPath());\n                TermQuery query =\n                  new TermQuery(pathTerm);\n                ScoreDoc[] hits = searcher.search(query, null, 1).scoreDocs;\n\n                // if document is found, compare the\n                // indexed last modified time with the\n                // current file\n                // - don't index if up to date\n                if (hits.length > 0) {\n                  Document doc = searcher.doc(hits[0].doc);\n                  String indexModified =\n                    doc.get(\"modified\").trim();\n                  if (indexModified != null) {\n                    long lastModified = 0;\n                    try {\n                      lastModified = DateTools.stringToTime(indexModified);\n                    } catch (ParseException e) {\n                      // if modified time is not parsable, skip\n                    }\n                    if (lastModified == file.lastModified()) {\n                      // TODO: remove existing document\n                      indexIt = false;\n                    }\n                  }\n                }\n              }\n\n              if (indexIt) {\n                try {\n                  log(\"Indexing \" + file.getPath(),\n                      Project.MSG_VERBOSE);\n                  Document doc =\n                    handler.getDocument(file);\n\n                  if (doc == null) {\n                    totalIgnored++;\n                  } else {\n                    // Add the path of the file as a field named \"path\".  Use a Keyword field, so\n                    // that the index stores the path, and so that the path is searchable\n                    doc.add(new Field(\"path\", file.getPath(), Field.Store.YES, Field.Index.NOT_ANALYZED));\n\n                    // Add the last modified date of the file a field named \"modified\".  Use a\n                    // Keyword field, so that it's searchable, but so that no attempt is made\n                    // to tokenize the field into words.\n                    doc.add(new Field(\"modified\", DateTools.timeToString(file.lastModified(), DateTools.Resolution.MILLISECOND), Field.Store.YES, Field.Index.NOT_ANALYZED));\n\n                    writer.addDocument(doc);\n                    totalIndexed++;\n                  }\n                } catch (DocumentHandlerException e) {\n                  throw new BuildException(e);\n                }\n              }\n            }\n            // for j\n          }\n          // if (fs != null)\n        }\n        // for i\n\n        writer.optimize();\n      }\n        //try\n      finally {\n        // always make sure everything gets closed,\n        // no matter how we exit.\n        writer.close();\n        if (searcher != null) {\n          searcher.close();\n        }\n      }\n\n      Date end = new Date();\n\n      log(totalIndexed + \" out of \" + totalFiles + \" indexed (\" +\n          totalIgnored + \" ignored) in \" + (end.getTime() - start.getTime()) +\n          \" milliseconds\");\n    } finally {\n      dir.close();\n    }\n  }\n\n","sourceOld":"  /**\n   * Index the fileset.\n   *\n   *@exception  IOException if Lucene I/O exception\n   *TODO: refactor!!!!!\n   */\n  private void indexDocs() throws IOException {\n    Date start = new Date();\n\n    boolean create = overwrite;\n    // If the index directory doesn't exist,\n    // create it and force create mode\n    if (indexDir.mkdirs() && !overwrite) {\n      create = true;\n    }\n\n    FSDirectory dir = FSDirectory.open(indexDir);\n    try {\n      Searcher searcher = null;\n      boolean checkLastModified = false;\n      if (!create) {\n        try {\n          searcher = new IndexSearcher(dir, true);\n          checkLastModified = true;\n        } catch (IOException ioe) {\n          log(\"IOException: \" + ioe.getMessage());\n          // Empty - ignore, which indicates to index all\n          // documents\n        }\n      }\n\n      log(\"checkLastModified = \" + checkLastModified, Project.MSG_VERBOSE);\n\n      IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig(\n          Version.LUCENE_CURRENT, analyzer).setOpenMode(\n          create ? OpenMode.CREATE : OpenMode.APPEND));\n      LogMergePolicy lmp = (LogMergePolicy) writer.getMergePolicy();\n      lmp.setUseCompoundFile(useCompoundIndex);\n      lmp.setUseCompoundDocStore(useCompoundIndex);\n      lmp.setMergeFactor(mergeFactor);\n      int totalFiles = 0;\n      int totalIndexed = 0;\n      int totalIgnored = 0;\n      try {\n\n        for (int i = 0; i < rcs.size(); i++) {\n          ResourceCollection rc = rcs.elementAt(i);\n          if (rc.isFilesystemOnly()) {\n            Iterator resources = rc.iterator();\n            while (resources.hasNext()) {\n              Resource r = (Resource) resources.next();\n              if (!r.isExists() || !(r instanceof FileResource)) {\n                continue;\n              }\n              \n              totalFiles++;\n\n              File file = ((FileResource) r).getFile();\n              \n              if (!file.exists() || !file.canRead()) {\n                throw new BuildException(\"File \\\"\" +\n                                         file.getAbsolutePath()\n                                         + \"\\\" does not exist or is not readable.\");\n              }\n\n              boolean indexIt = true;\n\n              if (checkLastModified) {\n                Term pathTerm =\n                  new Term(\"path\", file.getPath());\n                TermQuery query =\n                  new TermQuery(pathTerm);\n                ScoreDoc[] hits = searcher.search(query, null, 1).scoreDocs;\n\n                // if document is found, compare the\n                // indexed last modified time with the\n                // current file\n                // - don't index if up to date\n                if (hits.length > 0) {\n                  Document doc = searcher.doc(hits[0].doc);\n                  String indexModified =\n                    doc.get(\"modified\").trim();\n                  if (indexModified != null) {\n                    long lastModified = 0;\n                    try {\n                      lastModified = DateTools.stringToTime(indexModified);\n                    } catch (ParseException e) {\n                      // if modified time is not parsable, skip\n                    }\n                    if (lastModified == file.lastModified()) {\n                      // TODO: remove existing document\n                      indexIt = false;\n                    }\n                  }\n                }\n              }\n\n              if (indexIt) {\n                try {\n                  log(\"Indexing \" + file.getPath(),\n                      Project.MSG_VERBOSE);\n                  Document doc =\n                    handler.getDocument(file);\n\n                  if (doc == null) {\n                    totalIgnored++;\n                  } else {\n                    // Add the path of the file as a field named \"path\".  Use a Keyword field, so\n                    // that the index stores the path, and so that the path is searchable\n                    doc.add(new Field(\"path\", file.getPath(), Field.Store.YES, Field.Index.NOT_ANALYZED));\n\n                    // Add the last modified date of the file a field named \"modified\".  Use a\n                    // Keyword field, so that it's searchable, but so that no attempt is made\n                    // to tokenize the field into words.\n                    doc.add(new Field(\"modified\", DateTools.timeToString(file.lastModified(), DateTools.Resolution.MILLISECOND), Field.Store.YES, Field.Index.NOT_ANALYZED));\n\n                    writer.addDocument(doc);\n                    totalIndexed++;\n                  }\n                } catch (DocumentHandlerException e) {\n                  throw new BuildException(e);\n                }\n              }\n            }\n            // for j\n          }\n          // if (fs != null)\n        }\n        // for i\n\n        writer.optimize();\n      }\n        //try\n      finally {\n        // always make sure everything gets closed,\n        // no matter how we exit.\n        writer.close();\n        if (searcher != null) {\n          searcher.close();\n        }\n      }\n\n      Date end = new Date();\n\n      log(totalIndexed + \" out of \" + totalFiles + \" indexed (\" +\n          totalIgnored + \" ignored) in \" + (end.getTime() - start.getTime()) +\n          \" milliseconds\");\n    } finally {\n      dir.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8dc26bfa5ebbc55b5a04fbec545dfcec647b046b","date":1280297653,"type":3,"author":"Michael Busch","isMerge":false,"pathNew":"lucene/contrib/ant/src/java/org/apache/lucene/ant/IndexTask#indexDocs().mjava","pathOld":"lucene/contrib/ant/src/java/org/apache/lucene/ant/IndexTask#indexDocs().mjava","sourceNew":"  /**\n   * Index the fileset.\n   *\n   *@exception  IOException if Lucene I/O exception\n   *TODO: refactor!!!!!\n   */\n  private void indexDocs() throws IOException {\n    Date start = new Date();\n\n    boolean create = overwrite;\n    // If the index directory doesn't exist,\n    // create it and force create mode\n    if (indexDir.mkdirs() && !overwrite) {\n      create = true;\n    }\n\n    FSDirectory dir = FSDirectory.open(indexDir);\n    try {\n      Searcher searcher = null;\n      boolean checkLastModified = false;\n      if (!create) {\n        try {\n          searcher = new IndexSearcher(dir, true);\n          checkLastModified = true;\n        } catch (IOException ioe) {\n          log(\"IOException: \" + ioe.getMessage());\n          // Empty - ignore, which indicates to index all\n          // documents\n        }\n      }\n\n      log(\"checkLastModified = \" + checkLastModified, Project.MSG_VERBOSE);\n\n      IndexWriterConfig conf = new IndexWriterConfig(\n          Version.LUCENE_CURRENT, analyzer).setOpenMode(\n          create ? OpenMode.CREATE : OpenMode.APPEND);\n      LogMergePolicy lmp = (LogMergePolicy) conf.getMergePolicy();\n      lmp.setUseCompoundFile(useCompoundIndex);\n      lmp.setMergeFactor(mergeFactor);\n      IndexWriter writer = new IndexWriter(dir, conf);\n      int totalFiles = 0;\n      int totalIndexed = 0;\n      int totalIgnored = 0;\n      try {\n\n        for (int i = 0; i < rcs.size(); i++) {\n          ResourceCollection rc = rcs.elementAt(i);\n          if (rc.isFilesystemOnly()) {\n            Iterator resources = rc.iterator();\n            while (resources.hasNext()) {\n              Resource r = (Resource) resources.next();\n              if (!r.isExists() || !(r instanceof FileResource)) {\n                continue;\n              }\n              \n              totalFiles++;\n\n              File file = ((FileResource) r).getFile();\n              \n              if (!file.exists() || !file.canRead()) {\n                throw new BuildException(\"File \\\"\" +\n                                         file.getAbsolutePath()\n                                         + \"\\\" does not exist or is not readable.\");\n              }\n\n              boolean indexIt = true;\n\n              if (checkLastModified) {\n                Term pathTerm =\n                  new Term(\"path\", file.getPath());\n                TermQuery query =\n                  new TermQuery(pathTerm);\n                ScoreDoc[] hits = searcher.search(query, null, 1).scoreDocs;\n\n                // if document is found, compare the\n                // indexed last modified time with the\n                // current file\n                // - don't index if up to date\n                if (hits.length > 0) {\n                  Document doc = searcher.doc(hits[0].doc);\n                  String indexModified =\n                    doc.get(\"modified\").trim();\n                  if (indexModified != null) {\n                    long lastModified = 0;\n                    try {\n                      lastModified = DateTools.stringToTime(indexModified);\n                    } catch (ParseException e) {\n                      // if modified time is not parsable, skip\n                    }\n                    if (lastModified == file.lastModified()) {\n                      // TODO: remove existing document\n                      indexIt = false;\n                    }\n                  }\n                }\n              }\n\n              if (indexIt) {\n                try {\n                  log(\"Indexing \" + file.getPath(),\n                      Project.MSG_VERBOSE);\n                  Document doc =\n                    handler.getDocument(file);\n\n                  if (doc == null) {\n                    totalIgnored++;\n                  } else {\n                    // Add the path of the file as a field named \"path\".  Use a Keyword field, so\n                    // that the index stores the path, and so that the path is searchable\n                    doc.add(new Field(\"path\", file.getPath(), Field.Store.YES, Field.Index.NOT_ANALYZED));\n\n                    // Add the last modified date of the file a field named \"modified\".  Use a\n                    // Keyword field, so that it's searchable, but so that no attempt is made\n                    // to tokenize the field into words.\n                    doc.add(new Field(\"modified\", DateTools.timeToString(file.lastModified(), DateTools.Resolution.MILLISECOND), Field.Store.YES, Field.Index.NOT_ANALYZED));\n\n                    writer.addDocument(doc);\n                    totalIndexed++;\n                  }\n                } catch (DocumentHandlerException e) {\n                  throw new BuildException(e);\n                }\n              }\n            }\n            // for j\n          }\n          // if (fs != null)\n        }\n        // for i\n\n        writer.optimize();\n      }\n        //try\n      finally {\n        // always make sure everything gets closed,\n        // no matter how we exit.\n        writer.close();\n        if (searcher != null) {\n          searcher.close();\n        }\n      }\n\n      Date end = new Date();\n\n      log(totalIndexed + \" out of \" + totalFiles + \" indexed (\" +\n          totalIgnored + \" ignored) in \" + (end.getTime() - start.getTime()) +\n          \" milliseconds\");\n    } finally {\n      dir.close();\n    }\n  }\n\n","sourceOld":"  /**\n   * Index the fileset.\n   *\n   *@exception  IOException if Lucene I/O exception\n   *TODO: refactor!!!!!\n   */\n  private void indexDocs() throws IOException {\n    Date start = new Date();\n\n    boolean create = overwrite;\n    // If the index directory doesn't exist,\n    // create it and force create mode\n    if (indexDir.mkdirs() && !overwrite) {\n      create = true;\n    }\n\n    FSDirectory dir = FSDirectory.open(indexDir);\n    try {\n      Searcher searcher = null;\n      boolean checkLastModified = false;\n      if (!create) {\n        try {\n          searcher = new IndexSearcher(dir, true);\n          checkLastModified = true;\n        } catch (IOException ioe) {\n          log(\"IOException: \" + ioe.getMessage());\n          // Empty - ignore, which indicates to index all\n          // documents\n        }\n      }\n\n      log(\"checkLastModified = \" + checkLastModified, Project.MSG_VERBOSE);\n\n      IndexWriterConfig conf = new IndexWriterConfig(\n          Version.LUCENE_CURRENT, analyzer).setOpenMode(\n          create ? OpenMode.CREATE : OpenMode.APPEND);\n      LogMergePolicy lmp = (LogMergePolicy) conf.getMergePolicy();\n      lmp.setUseCompoundFile(useCompoundIndex);\n      lmp.setUseCompoundDocStore(useCompoundIndex);\n      lmp.setMergeFactor(mergeFactor);\n      IndexWriter writer = new IndexWriter(dir, conf);\n      int totalFiles = 0;\n      int totalIndexed = 0;\n      int totalIgnored = 0;\n      try {\n\n        for (int i = 0; i < rcs.size(); i++) {\n          ResourceCollection rc = rcs.elementAt(i);\n          if (rc.isFilesystemOnly()) {\n            Iterator resources = rc.iterator();\n            while (resources.hasNext()) {\n              Resource r = (Resource) resources.next();\n              if (!r.isExists() || !(r instanceof FileResource)) {\n                continue;\n              }\n              \n              totalFiles++;\n\n              File file = ((FileResource) r).getFile();\n              \n              if (!file.exists() || !file.canRead()) {\n                throw new BuildException(\"File \\\"\" +\n                                         file.getAbsolutePath()\n                                         + \"\\\" does not exist or is not readable.\");\n              }\n\n              boolean indexIt = true;\n\n              if (checkLastModified) {\n                Term pathTerm =\n                  new Term(\"path\", file.getPath());\n                TermQuery query =\n                  new TermQuery(pathTerm);\n                ScoreDoc[] hits = searcher.search(query, null, 1).scoreDocs;\n\n                // if document is found, compare the\n                // indexed last modified time with the\n                // current file\n                // - don't index if up to date\n                if (hits.length > 0) {\n                  Document doc = searcher.doc(hits[0].doc);\n                  String indexModified =\n                    doc.get(\"modified\").trim();\n                  if (indexModified != null) {\n                    long lastModified = 0;\n                    try {\n                      lastModified = DateTools.stringToTime(indexModified);\n                    } catch (ParseException e) {\n                      // if modified time is not parsable, skip\n                    }\n                    if (lastModified == file.lastModified()) {\n                      // TODO: remove existing document\n                      indexIt = false;\n                    }\n                  }\n                }\n              }\n\n              if (indexIt) {\n                try {\n                  log(\"Indexing \" + file.getPath(),\n                      Project.MSG_VERBOSE);\n                  Document doc =\n                    handler.getDocument(file);\n\n                  if (doc == null) {\n                    totalIgnored++;\n                  } else {\n                    // Add the path of the file as a field named \"path\".  Use a Keyword field, so\n                    // that the index stores the path, and so that the path is searchable\n                    doc.add(new Field(\"path\", file.getPath(), Field.Store.YES, Field.Index.NOT_ANALYZED));\n\n                    // Add the last modified date of the file a field named \"modified\".  Use a\n                    // Keyword field, so that it's searchable, but so that no attempt is made\n                    // to tokenize the field into words.\n                    doc.add(new Field(\"modified\", DateTools.timeToString(file.lastModified(), DateTools.Resolution.MILLISECOND), Field.Store.YES, Field.Index.NOT_ANALYZED));\n\n                    writer.addDocument(doc);\n                    totalIndexed++;\n                  }\n                } catch (DocumentHandlerException e) {\n                  throw new BuildException(e);\n                }\n              }\n            }\n            // for j\n          }\n          // if (fs != null)\n        }\n        // for i\n\n        writer.optimize();\n      }\n        //try\n      finally {\n        // always make sure everything gets closed,\n        // no matter how we exit.\n        writer.close();\n        if (searcher != null) {\n          searcher.close();\n        }\n      }\n\n      Date end = new Date();\n\n      log(totalIndexed + \" out of \" + totalFiles + \" indexed (\" +\n          totalIgnored + \" ignored) in \" + (end.getTime() - start.getTime()) +\n          \" milliseconds\");\n    } finally {\n      dir.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4948bc5d29211f0c9b5ccc31b2632cdd27066ea5","date":1292695408,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/contrib/ant/src/java/org/apache/lucene/ant/IndexTask#indexDocs().mjava","pathOld":"lucene/contrib/ant/src/java/org/apache/lucene/ant/IndexTask#indexDocs().mjava","sourceNew":"  /**\n   * Index the fileset.\n   *\n   *@exception  IOException if Lucene I/O exception\n   *TODO: refactor!!!!!\n   */\n  private void indexDocs() throws IOException {\n    Date start = new Date();\n\n    boolean create = overwrite;\n    // If the index directory doesn't exist,\n    // create it and force create mode\n    if (indexDir.mkdirs() && !overwrite) {\n      create = true;\n    }\n\n    FSDirectory dir = FSDirectory.open(indexDir);\n    try {\n      Searcher searcher = null;\n      boolean checkLastModified = false;\n      if (!create) {\n        try {\n          searcher = new IndexSearcher(dir, true);\n          checkLastModified = true;\n        } catch (IOException ioe) {\n          log(\"IOException: \" + ioe.getMessage());\n          // Empty - ignore, which indicates to index all\n          // documents\n        }\n      }\n\n      log(\"checkLastModified = \" + checkLastModified, Project.MSG_VERBOSE);\n\n      IndexWriterConfig conf = new IndexWriterConfig(\n          Version.LUCENE_CURRENT, analyzer).setOpenMode(\n          create ? OpenMode.CREATE : OpenMode.APPEND);\n      LogMergePolicy lmp = (LogMergePolicy) conf.getMergePolicy();\n      lmp.setUseCompoundFile(useCompoundIndex);\n      lmp.setMergeFactor(mergeFactor);\n      IndexWriter writer = new IndexWriter(dir, conf);\n      int totalFiles = 0;\n      int totalIndexed = 0;\n      int totalIgnored = 0;\n      try {\n\n        for (int i = 0; i < rcs.size(); i++) {\n          ResourceCollection rc = rcs.elementAt(i);\n          if (rc.isFilesystemOnly()) {\n            Iterator resources = rc.iterator();\n            while (resources.hasNext()) {\n              Resource r = (Resource) resources.next();\n              if (!r.isExists() || !(r instanceof FileResource)) {\n                continue;\n              }\n              \n              totalFiles++;\n\n              File file = ((FileResource) r).getFile();\n              \n              if (!file.exists() || !file.canRead()) {\n                throw new BuildException(\"File \\\"\" +\n                                         file.getAbsolutePath()\n                                         + \"\\\" does not exist or is not readable.\");\n              }\n\n              boolean indexIt = true;\n\n              if (checkLastModified) {\n                Term pathTerm =\n                  new Term(\"path\", file.getPath());\n                TermQuery query =\n                  new TermQuery(pathTerm);\n                ScoreDoc[] hits = searcher.search(query, null, 1).scoreDocs;\n\n                // if document is found, compare the\n                // indexed last modified time with the\n                // current file\n                // - don't index if up to date\n                if (hits.length > 0) {\n                  Document doc = searcher.doc(hits[0].doc);\n                  String indexModified =\n                    doc.get(\"modified\").trim();\n                  if (indexModified != null) {\n                    long lastModified = 0;\n                    try {\n                      lastModified = DateTools.stringToTime(indexModified);\n                    } catch (ParseException e) {\n                      // if modified time is not parsable, skip\n                    }\n                    if (lastModified == file.lastModified()) {\n                      // TODO: remove existing document\n                      indexIt = false;\n                    }\n                  }\n                }\n              }\n\n              if (indexIt) {\n                try {\n                  log(\"Indexing \" + file.getPath(),\n                      Project.MSG_VERBOSE);\n                  Document doc =\n                    handler.getDocument(file);\n\n                  if (doc == null) {\n                    totalIgnored++;\n                  } else {\n                    // Add the path of the file as a field named \"path\".  Use a Keyword field, so\n                    // that the index stores the path, and so that the path is searchable\n                    doc.add(new Field(\"path\", file.getPath(), Field.Store.YES, Field.Index.NOT_ANALYZED));\n\n                    // Add the last modified date of the file a field named \"modified\".  Use a\n                    // Keyword field, so that it's searchable, but so that no attempt is made\n                    // to tokenize the field into words.\n                    doc.add(new Field(\"modified\", DateTools.timeToString(file.lastModified(), DateTools.Resolution.MILLISECOND), Field.Store.YES, Field.Index.NOT_ANALYZED));\n\n                    writer.addDocument(doc);\n                    totalIndexed++;\n                  }\n                } catch (DocumentHandlerException e) {\n                  throw new BuildException(e);\n                }\n              }\n            }\n            // for j\n          }\n          // if (fs != null)\n        }\n        // for i\n\n        writer.optimize();\n      }\n        //try\n      finally {\n        // always make sure everything gets closed,\n        // no matter how we exit.\n        writer.close();\n        if (searcher != null) {\n          searcher.close();\n        }\n      }\n\n      Date end = new Date();\n\n      log(totalIndexed + \" out of \" + totalFiles + \" indexed (\" +\n          totalIgnored + \" ignored) in \" + (end.getTime() - start.getTime()) +\n          \" milliseconds\");\n    } finally {\n      dir.close();\n    }\n  }\n\n","sourceOld":"  /**\n   * Index the fileset.\n   *\n   *@exception  IOException if Lucene I/O exception\n   *TODO: refactor!!!!!\n   */\n  private void indexDocs() throws IOException {\n    Date start = new Date();\n\n    boolean create = overwrite;\n    // If the index directory doesn't exist,\n    // create it and force create mode\n    if (indexDir.mkdirs() && !overwrite) {\n      create = true;\n    }\n\n    FSDirectory dir = FSDirectory.open(indexDir);\n    try {\n      Searcher searcher = null;\n      boolean checkLastModified = false;\n      if (!create) {\n        try {\n          searcher = new IndexSearcher(dir, true);\n          checkLastModified = true;\n        } catch (IOException ioe) {\n          log(\"IOException: \" + ioe.getMessage());\n          // Empty - ignore, which indicates to index all\n          // documents\n        }\n      }\n\n      log(\"checkLastModified = \" + checkLastModified, Project.MSG_VERBOSE);\n\n      IndexWriterConfig conf = new IndexWriterConfig(\n          Version.LUCENE_CURRENT, analyzer).setOpenMode(\n          create ? OpenMode.CREATE : OpenMode.APPEND);\n      LogMergePolicy lmp = (LogMergePolicy) conf.getMergePolicy();\n      lmp.setUseCompoundFile(useCompoundIndex);\n      lmp.setUseCompoundDocStore(useCompoundIndex);\n      lmp.setMergeFactor(mergeFactor);\n      IndexWriter writer = new IndexWriter(dir, conf);\n      int totalFiles = 0;\n      int totalIndexed = 0;\n      int totalIgnored = 0;\n      try {\n\n        for (int i = 0; i < rcs.size(); i++) {\n          ResourceCollection rc = rcs.elementAt(i);\n          if (rc.isFilesystemOnly()) {\n            Iterator resources = rc.iterator();\n            while (resources.hasNext()) {\n              Resource r = (Resource) resources.next();\n              if (!r.isExists() || !(r instanceof FileResource)) {\n                continue;\n              }\n              \n              totalFiles++;\n\n              File file = ((FileResource) r).getFile();\n              \n              if (!file.exists() || !file.canRead()) {\n                throw new BuildException(\"File \\\"\" +\n                                         file.getAbsolutePath()\n                                         + \"\\\" does not exist or is not readable.\");\n              }\n\n              boolean indexIt = true;\n\n              if (checkLastModified) {\n                Term pathTerm =\n                  new Term(\"path\", file.getPath());\n                TermQuery query =\n                  new TermQuery(pathTerm);\n                ScoreDoc[] hits = searcher.search(query, null, 1).scoreDocs;\n\n                // if document is found, compare the\n                // indexed last modified time with the\n                // current file\n                // - don't index if up to date\n                if (hits.length > 0) {\n                  Document doc = searcher.doc(hits[0].doc);\n                  String indexModified =\n                    doc.get(\"modified\").trim();\n                  if (indexModified != null) {\n                    long lastModified = 0;\n                    try {\n                      lastModified = DateTools.stringToTime(indexModified);\n                    } catch (ParseException e) {\n                      // if modified time is not parsable, skip\n                    }\n                    if (lastModified == file.lastModified()) {\n                      // TODO: remove existing document\n                      indexIt = false;\n                    }\n                  }\n                }\n              }\n\n              if (indexIt) {\n                try {\n                  log(\"Indexing \" + file.getPath(),\n                      Project.MSG_VERBOSE);\n                  Document doc =\n                    handler.getDocument(file);\n\n                  if (doc == null) {\n                    totalIgnored++;\n                  } else {\n                    // Add the path of the file as a field named \"path\".  Use a Keyword field, so\n                    // that the index stores the path, and so that the path is searchable\n                    doc.add(new Field(\"path\", file.getPath(), Field.Store.YES, Field.Index.NOT_ANALYZED));\n\n                    // Add the last modified date of the file a field named \"modified\".  Use a\n                    // Keyword field, so that it's searchable, but so that no attempt is made\n                    // to tokenize the field into words.\n                    doc.add(new Field(\"modified\", DateTools.timeToString(file.lastModified(), DateTools.Resolution.MILLISECOND), Field.Store.YES, Field.Index.NOT_ANALYZED));\n\n                    writer.addDocument(doc);\n                    totalIndexed++;\n                  }\n                } catch (DocumentHandlerException e) {\n                  throw new BuildException(e);\n                }\n              }\n            }\n            // for j\n          }\n          // if (fs != null)\n        }\n        // for i\n\n        writer.optimize();\n      }\n        //try\n      finally {\n        // always make sure everything gets closed,\n        // no matter how we exit.\n        writer.close();\n        if (searcher != null) {\n          searcher.close();\n        }\n      }\n\n      Date end = new Date();\n\n      log(totalIndexed + \" out of \" + totalFiles + \" indexed (\" +\n          totalIgnored + \" ignored) in \" + (end.getTime() - start.getTime()) +\n          \" milliseconds\");\n    } finally {\n      dir.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ab5cb6a74aefb78aa0569857970b9151dfe2e787","date":1292842407,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/contrib/ant/src/java/org/apache/lucene/ant/IndexTask#indexDocs().mjava","pathOld":"lucene/contrib/ant/src/java/org/apache/lucene/ant/IndexTask#indexDocs().mjava","sourceNew":"  /**\n   * Index the fileset.\n   *\n   *@exception  IOException if Lucene I/O exception\n   *TODO: refactor!!!!!\n   */\n  private void indexDocs() throws IOException {\n    Date start = new Date();\n\n    boolean create = overwrite;\n    // If the index directory doesn't exist,\n    // create it and force create mode\n    if (indexDir.mkdirs() && !overwrite) {\n      create = true;\n    }\n\n    FSDirectory dir = FSDirectory.open(indexDir);\n    try {\n      Searcher searcher = null;\n      boolean checkLastModified = false;\n      if (!create) {\n        try {\n          searcher = new IndexSearcher(dir, true);\n          checkLastModified = true;\n        } catch (IOException ioe) {\n          log(\"IOException: \" + ioe.getMessage());\n          // Empty - ignore, which indicates to index all\n          // documents\n        }\n      }\n\n      log(\"checkLastModified = \" + checkLastModified, Project.MSG_VERBOSE);\n\n      IndexWriterConfig conf = new IndexWriterConfig(\n          Version.LUCENE_CURRENT, analyzer).setOpenMode(\n          create ? OpenMode.CREATE : OpenMode.APPEND);\n      LogMergePolicy lmp = (LogMergePolicy) conf.getMergePolicy();\n      lmp.setUseCompoundFile(useCompoundIndex);\n      lmp.setMergeFactor(mergeFactor);\n      IndexWriter writer = new IndexWriter(dir, conf);\n      int totalFiles = 0;\n      int totalIndexed = 0;\n      int totalIgnored = 0;\n      try {\n\n        for (int i = 0; i < rcs.size(); i++) {\n          ResourceCollection rc = rcs.elementAt(i);\n          if (rc.isFilesystemOnly()) {\n            Iterator resources = rc.iterator();\n            while (resources.hasNext()) {\n              Resource r = (Resource) resources.next();\n              if (!r.isExists() || !(r instanceof FileResource)) {\n                continue;\n              }\n              \n              totalFiles++;\n\n              File file = ((FileResource) r).getFile();\n              \n              if (!file.exists() || !file.canRead()) {\n                throw new BuildException(\"File \\\"\" +\n                                         file.getAbsolutePath()\n                                         + \"\\\" does not exist or is not readable.\");\n              }\n\n              boolean indexIt = true;\n\n              if (checkLastModified) {\n                Term pathTerm =\n                  new Term(\"path\", file.getPath());\n                TermQuery query =\n                  new TermQuery(pathTerm);\n                ScoreDoc[] hits = searcher.search(query, null, 1).scoreDocs;\n\n                // if document is found, compare the\n                // indexed last modified time with the\n                // current file\n                // - don't index if up to date\n                if (hits.length > 0) {\n                  Document doc = searcher.doc(hits[0].doc);\n                  String indexModified =\n                    doc.get(\"modified\").trim();\n                  if (indexModified != null) {\n                    long lastModified = 0;\n                    try {\n                      lastModified = DateTools.stringToTime(indexModified);\n                    } catch (ParseException e) {\n                      // if modified time is not parsable, skip\n                    }\n                    if (lastModified == file.lastModified()) {\n                      // TODO: remove existing document\n                      indexIt = false;\n                    }\n                  }\n                }\n              }\n\n              if (indexIt) {\n                try {\n                  log(\"Indexing \" + file.getPath(),\n                      Project.MSG_VERBOSE);\n                  Document doc =\n                    handler.getDocument(file);\n\n                  if (doc == null) {\n                    totalIgnored++;\n                  } else {\n                    // Add the path of the file as a field named \"path\".  Use a Keyword field, so\n                    // that the index stores the path, and so that the path is searchable\n                    doc.add(new Field(\"path\", file.getPath(), Field.Store.YES, Field.Index.NOT_ANALYZED));\n\n                    // Add the last modified date of the file a field named \"modified\".  Use a\n                    // Keyword field, so that it's searchable, but so that no attempt is made\n                    // to tokenize the field into words.\n                    doc.add(new Field(\"modified\", DateTools.timeToString(file.lastModified(), DateTools.Resolution.MILLISECOND), Field.Store.YES, Field.Index.NOT_ANALYZED));\n\n                    writer.addDocument(doc);\n                    totalIndexed++;\n                  }\n                } catch (DocumentHandlerException e) {\n                  throw new BuildException(e);\n                }\n              }\n            }\n            // for j\n          }\n          // if (fs != null)\n        }\n        // for i\n\n        writer.optimize();\n      }\n        //try\n      finally {\n        // always make sure everything gets closed,\n        // no matter how we exit.\n        writer.close();\n        if (searcher != null) {\n          searcher.close();\n        }\n      }\n\n      Date end = new Date();\n\n      log(totalIndexed + \" out of \" + totalFiles + \" indexed (\" +\n          totalIgnored + \" ignored) in \" + (end.getTime() - start.getTime()) +\n          \" milliseconds\");\n    } finally {\n      dir.close();\n    }\n  }\n\n","sourceOld":"  /**\n   * Index the fileset.\n   *\n   *@exception  IOException if Lucene I/O exception\n   *TODO: refactor!!!!!\n   */\n  private void indexDocs() throws IOException {\n    Date start = new Date();\n\n    boolean create = overwrite;\n    // If the index directory doesn't exist,\n    // create it and force create mode\n    if (indexDir.mkdirs() && !overwrite) {\n      create = true;\n    }\n\n    FSDirectory dir = FSDirectory.open(indexDir);\n    try {\n      Searcher searcher = null;\n      boolean checkLastModified = false;\n      if (!create) {\n        try {\n          searcher = new IndexSearcher(dir, true);\n          checkLastModified = true;\n        } catch (IOException ioe) {\n          log(\"IOException: \" + ioe.getMessage());\n          // Empty - ignore, which indicates to index all\n          // documents\n        }\n      }\n\n      log(\"checkLastModified = \" + checkLastModified, Project.MSG_VERBOSE);\n\n      IndexWriterConfig conf = new IndexWriterConfig(\n          Version.LUCENE_CURRENT, analyzer).setOpenMode(\n          create ? OpenMode.CREATE : OpenMode.APPEND);\n      LogMergePolicy lmp = (LogMergePolicy) conf.getMergePolicy();\n      lmp.setUseCompoundFile(useCompoundIndex);\n      lmp.setUseCompoundDocStore(useCompoundIndex);\n      lmp.setMergeFactor(mergeFactor);\n      IndexWriter writer = new IndexWriter(dir, conf);\n      int totalFiles = 0;\n      int totalIndexed = 0;\n      int totalIgnored = 0;\n      try {\n\n        for (int i = 0; i < rcs.size(); i++) {\n          ResourceCollection rc = rcs.elementAt(i);\n          if (rc.isFilesystemOnly()) {\n            Iterator resources = rc.iterator();\n            while (resources.hasNext()) {\n              Resource r = (Resource) resources.next();\n              if (!r.isExists() || !(r instanceof FileResource)) {\n                continue;\n              }\n              \n              totalFiles++;\n\n              File file = ((FileResource) r).getFile();\n              \n              if (!file.exists() || !file.canRead()) {\n                throw new BuildException(\"File \\\"\" +\n                                         file.getAbsolutePath()\n                                         + \"\\\" does not exist or is not readable.\");\n              }\n\n              boolean indexIt = true;\n\n              if (checkLastModified) {\n                Term pathTerm =\n                  new Term(\"path\", file.getPath());\n                TermQuery query =\n                  new TermQuery(pathTerm);\n                ScoreDoc[] hits = searcher.search(query, null, 1).scoreDocs;\n\n                // if document is found, compare the\n                // indexed last modified time with the\n                // current file\n                // - don't index if up to date\n                if (hits.length > 0) {\n                  Document doc = searcher.doc(hits[0].doc);\n                  String indexModified =\n                    doc.get(\"modified\").trim();\n                  if (indexModified != null) {\n                    long lastModified = 0;\n                    try {\n                      lastModified = DateTools.stringToTime(indexModified);\n                    } catch (ParseException e) {\n                      // if modified time is not parsable, skip\n                    }\n                    if (lastModified == file.lastModified()) {\n                      // TODO: remove existing document\n                      indexIt = false;\n                    }\n                  }\n                }\n              }\n\n              if (indexIt) {\n                try {\n                  log(\"Indexing \" + file.getPath(),\n                      Project.MSG_VERBOSE);\n                  Document doc =\n                    handler.getDocument(file);\n\n                  if (doc == null) {\n                    totalIgnored++;\n                  } else {\n                    // Add the path of the file as a field named \"path\".  Use a Keyword field, so\n                    // that the index stores the path, and so that the path is searchable\n                    doc.add(new Field(\"path\", file.getPath(), Field.Store.YES, Field.Index.NOT_ANALYZED));\n\n                    // Add the last modified date of the file a field named \"modified\".  Use a\n                    // Keyword field, so that it's searchable, but so that no attempt is made\n                    // to tokenize the field into words.\n                    doc.add(new Field(\"modified\", DateTools.timeToString(file.lastModified(), DateTools.Resolution.MILLISECOND), Field.Store.YES, Field.Index.NOT_ANALYZED));\n\n                    writer.addDocument(doc);\n                    totalIndexed++;\n                  }\n                } catch (DocumentHandlerException e) {\n                  throw new BuildException(e);\n                }\n              }\n            }\n            // for j\n          }\n          // if (fs != null)\n        }\n        // for i\n\n        writer.optimize();\n      }\n        //try\n      finally {\n        // always make sure everything gets closed,\n        // no matter how we exit.\n        writer.close();\n        if (searcher != null) {\n          searcher.close();\n        }\n      }\n\n      Date end = new Date();\n\n      log(totalIndexed + \" out of \" + totalFiles + \" indexed (\" +\n          totalIgnored + \" ignored) in \" + (end.getTime() - start.getTime()) +\n          \" milliseconds\");\n    } finally {\n      dir.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8b241ea5e635d896cc0af83cd96ffd0322e0aba7","date":1294226200,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/contrib/ant/src/java/org/apache/lucene/ant/IndexTask#indexDocs().mjava","pathOld":"lucene/contrib/ant/src/java/org/apache/lucene/ant/IndexTask#indexDocs().mjava","sourceNew":"  /**\n   * Index the fileset.\n   *\n   *@exception  IOException if Lucene I/O exception\n   *TODO: refactor!!!!!\n   */\n  private void indexDocs() throws IOException {\n    Date start = new Date();\n\n    boolean create = overwrite;\n    // If the index directory doesn't exist,\n    // create it and force create mode\n    if (indexDir.mkdirs() && !overwrite) {\n      create = true;\n    }\n\n    FSDirectory dir = FSDirectory.open(indexDir);\n    try {\n      IndexSearcher searcher = null;\n      boolean checkLastModified = false;\n      if (!create) {\n        try {\n          searcher = new IndexSearcher(dir, true);\n          checkLastModified = true;\n        } catch (IOException ioe) {\n          log(\"IOException: \" + ioe.getMessage());\n          // Empty - ignore, which indicates to index all\n          // documents\n        }\n      }\n\n      log(\"checkLastModified = \" + checkLastModified, Project.MSG_VERBOSE);\n\n      IndexWriterConfig conf = new IndexWriterConfig(\n          Version.LUCENE_CURRENT, analyzer).setOpenMode(\n          create ? OpenMode.CREATE : OpenMode.APPEND);\n      LogMergePolicy lmp = (LogMergePolicy) conf.getMergePolicy();\n      lmp.setUseCompoundFile(useCompoundIndex);\n      lmp.setMergeFactor(mergeFactor);\n      IndexWriter writer = new IndexWriter(dir, conf);\n      int totalFiles = 0;\n      int totalIndexed = 0;\n      int totalIgnored = 0;\n      try {\n\n        for (int i = 0; i < rcs.size(); i++) {\n          ResourceCollection rc = rcs.elementAt(i);\n          if (rc.isFilesystemOnly()) {\n            Iterator resources = rc.iterator();\n            while (resources.hasNext()) {\n              Resource r = (Resource) resources.next();\n              if (!r.isExists() || !(r instanceof FileResource)) {\n                continue;\n              }\n              \n              totalFiles++;\n\n              File file = ((FileResource) r).getFile();\n              \n              if (!file.exists() || !file.canRead()) {\n                throw new BuildException(\"File \\\"\" +\n                                         file.getAbsolutePath()\n                                         + \"\\\" does not exist or is not readable.\");\n              }\n\n              boolean indexIt = true;\n\n              if (checkLastModified) {\n                Term pathTerm =\n                  new Term(\"path\", file.getPath());\n                TermQuery query =\n                  new TermQuery(pathTerm);\n                ScoreDoc[] hits = searcher.search(query, null, 1).scoreDocs;\n\n                // if document is found, compare the\n                // indexed last modified time with the\n                // current file\n                // - don't index if up to date\n                if (hits.length > 0) {\n                  Document doc = searcher.doc(hits[0].doc);\n                  String indexModified =\n                    doc.get(\"modified\").trim();\n                  if (indexModified != null) {\n                    long lastModified = 0;\n                    try {\n                      lastModified = DateTools.stringToTime(indexModified);\n                    } catch (ParseException e) {\n                      // if modified time is not parsable, skip\n                    }\n                    if (lastModified == file.lastModified()) {\n                      // TODO: remove existing document\n                      indexIt = false;\n                    }\n                  }\n                }\n              }\n\n              if (indexIt) {\n                try {\n                  log(\"Indexing \" + file.getPath(),\n                      Project.MSG_VERBOSE);\n                  Document doc =\n                    handler.getDocument(file);\n\n                  if (doc == null) {\n                    totalIgnored++;\n                  } else {\n                    // Add the path of the file as a field named \"path\".  Use a Keyword field, so\n                    // that the index stores the path, and so that the path is searchable\n                    doc.add(new Field(\"path\", file.getPath(), Field.Store.YES, Field.Index.NOT_ANALYZED));\n\n                    // Add the last modified date of the file a field named \"modified\".  Use a\n                    // Keyword field, so that it's searchable, but so that no attempt is made\n                    // to tokenize the field into words.\n                    doc.add(new Field(\"modified\", DateTools.timeToString(file.lastModified(), DateTools.Resolution.MILLISECOND), Field.Store.YES, Field.Index.NOT_ANALYZED));\n\n                    writer.addDocument(doc);\n                    totalIndexed++;\n                  }\n                } catch (DocumentHandlerException e) {\n                  throw new BuildException(e);\n                }\n              }\n            }\n            // for j\n          }\n          // if (fs != null)\n        }\n        // for i\n\n        writer.optimize();\n      }\n        //try\n      finally {\n        // always make sure everything gets closed,\n        // no matter how we exit.\n        writer.close();\n        if (searcher != null) {\n          searcher.close();\n        }\n      }\n\n      Date end = new Date();\n\n      log(totalIndexed + \" out of \" + totalFiles + \" indexed (\" +\n          totalIgnored + \" ignored) in \" + (end.getTime() - start.getTime()) +\n          \" milliseconds\");\n    } finally {\n      dir.close();\n    }\n  }\n\n","sourceOld":"  /**\n   * Index the fileset.\n   *\n   *@exception  IOException if Lucene I/O exception\n   *TODO: refactor!!!!!\n   */\n  private void indexDocs() throws IOException {\n    Date start = new Date();\n\n    boolean create = overwrite;\n    // If the index directory doesn't exist,\n    // create it and force create mode\n    if (indexDir.mkdirs() && !overwrite) {\n      create = true;\n    }\n\n    FSDirectory dir = FSDirectory.open(indexDir);\n    try {\n      Searcher searcher = null;\n      boolean checkLastModified = false;\n      if (!create) {\n        try {\n          searcher = new IndexSearcher(dir, true);\n          checkLastModified = true;\n        } catch (IOException ioe) {\n          log(\"IOException: \" + ioe.getMessage());\n          // Empty - ignore, which indicates to index all\n          // documents\n        }\n      }\n\n      log(\"checkLastModified = \" + checkLastModified, Project.MSG_VERBOSE);\n\n      IndexWriterConfig conf = new IndexWriterConfig(\n          Version.LUCENE_CURRENT, analyzer).setOpenMode(\n          create ? OpenMode.CREATE : OpenMode.APPEND);\n      LogMergePolicy lmp = (LogMergePolicy) conf.getMergePolicy();\n      lmp.setUseCompoundFile(useCompoundIndex);\n      lmp.setMergeFactor(mergeFactor);\n      IndexWriter writer = new IndexWriter(dir, conf);\n      int totalFiles = 0;\n      int totalIndexed = 0;\n      int totalIgnored = 0;\n      try {\n\n        for (int i = 0; i < rcs.size(); i++) {\n          ResourceCollection rc = rcs.elementAt(i);\n          if (rc.isFilesystemOnly()) {\n            Iterator resources = rc.iterator();\n            while (resources.hasNext()) {\n              Resource r = (Resource) resources.next();\n              if (!r.isExists() || !(r instanceof FileResource)) {\n                continue;\n              }\n              \n              totalFiles++;\n\n              File file = ((FileResource) r).getFile();\n              \n              if (!file.exists() || !file.canRead()) {\n                throw new BuildException(\"File \\\"\" +\n                                         file.getAbsolutePath()\n                                         + \"\\\" does not exist or is not readable.\");\n              }\n\n              boolean indexIt = true;\n\n              if (checkLastModified) {\n                Term pathTerm =\n                  new Term(\"path\", file.getPath());\n                TermQuery query =\n                  new TermQuery(pathTerm);\n                ScoreDoc[] hits = searcher.search(query, null, 1).scoreDocs;\n\n                // if document is found, compare the\n                // indexed last modified time with the\n                // current file\n                // - don't index if up to date\n                if (hits.length > 0) {\n                  Document doc = searcher.doc(hits[0].doc);\n                  String indexModified =\n                    doc.get(\"modified\").trim();\n                  if (indexModified != null) {\n                    long lastModified = 0;\n                    try {\n                      lastModified = DateTools.stringToTime(indexModified);\n                    } catch (ParseException e) {\n                      // if modified time is not parsable, skip\n                    }\n                    if (lastModified == file.lastModified()) {\n                      // TODO: remove existing document\n                      indexIt = false;\n                    }\n                  }\n                }\n              }\n\n              if (indexIt) {\n                try {\n                  log(\"Indexing \" + file.getPath(),\n                      Project.MSG_VERBOSE);\n                  Document doc =\n                    handler.getDocument(file);\n\n                  if (doc == null) {\n                    totalIgnored++;\n                  } else {\n                    // Add the path of the file as a field named \"path\".  Use a Keyword field, so\n                    // that the index stores the path, and so that the path is searchable\n                    doc.add(new Field(\"path\", file.getPath(), Field.Store.YES, Field.Index.NOT_ANALYZED));\n\n                    // Add the last modified date of the file a field named \"modified\".  Use a\n                    // Keyword field, so that it's searchable, but so that no attempt is made\n                    // to tokenize the field into words.\n                    doc.add(new Field(\"modified\", DateTools.timeToString(file.lastModified(), DateTools.Resolution.MILLISECOND), Field.Store.YES, Field.Index.NOT_ANALYZED));\n\n                    writer.addDocument(doc);\n                    totalIndexed++;\n                  }\n                } catch (DocumentHandlerException e) {\n                  throw new BuildException(e);\n                }\n              }\n            }\n            // for j\n          }\n          // if (fs != null)\n        }\n        // for i\n\n        writer.optimize();\n      }\n        //try\n      finally {\n        // always make sure everything gets closed,\n        // no matter how we exit.\n        writer.close();\n        if (searcher != null) {\n          searcher.close();\n        }\n      }\n\n      Date end = new Date();\n\n      log(totalIndexed + \" out of \" + totalFiles + \" indexed (\" +\n          totalIgnored + \" ignored) in \" + (end.getTime() - start.getTime()) +\n          \" milliseconds\");\n    } finally {\n      dir.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"70ad682703b8585f5d0a637efec044d57ec05efb","date":1294259117,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/contrib/ant/src/java/org/apache/lucene/ant/IndexTask#indexDocs().mjava","pathOld":"lucene/contrib/ant/src/java/org/apache/lucene/ant/IndexTask#indexDocs().mjava","sourceNew":"  /**\n   * Index the fileset.\n   *\n   *@exception  IOException if Lucene I/O exception\n   *TODO: refactor!!!!!\n   */\n  private void indexDocs() throws IOException {\n    Date start = new Date();\n\n    boolean create = overwrite;\n    // If the index directory doesn't exist,\n    // create it and force create mode\n    if (indexDir.mkdirs() && !overwrite) {\n      create = true;\n    }\n\n    FSDirectory dir = FSDirectory.open(indexDir);\n    try {\n      IndexSearcher searcher = null;\n      boolean checkLastModified = false;\n      if (!create) {\n        try {\n          searcher = new IndexSearcher(dir, true);\n          checkLastModified = true;\n        } catch (IOException ioe) {\n          log(\"IOException: \" + ioe.getMessage());\n          // Empty - ignore, which indicates to index all\n          // documents\n        }\n      }\n\n      log(\"checkLastModified = \" + checkLastModified, Project.MSG_VERBOSE);\n\n      IndexWriterConfig conf = new IndexWriterConfig(\n          Version.LUCENE_CURRENT, analyzer).setOpenMode(\n          create ? OpenMode.CREATE : OpenMode.APPEND);\n      LogMergePolicy lmp = (LogMergePolicy) conf.getMergePolicy();\n      lmp.setUseCompoundFile(useCompoundIndex);\n      lmp.setMergeFactor(mergeFactor);\n      IndexWriter writer = new IndexWriter(dir, conf);\n      int totalFiles = 0;\n      int totalIndexed = 0;\n      int totalIgnored = 0;\n      try {\n\n        for (int i = 0; i < rcs.size(); i++) {\n          ResourceCollection rc = rcs.elementAt(i);\n          if (rc.isFilesystemOnly()) {\n            Iterator resources = rc.iterator();\n            while (resources.hasNext()) {\n              Resource r = (Resource) resources.next();\n              if (!r.isExists() || !(r instanceof FileResource)) {\n                continue;\n              }\n              \n              totalFiles++;\n\n              File file = ((FileResource) r).getFile();\n              \n              if (!file.exists() || !file.canRead()) {\n                throw new BuildException(\"File \\\"\" +\n                                         file.getAbsolutePath()\n                                         + \"\\\" does not exist or is not readable.\");\n              }\n\n              boolean indexIt = true;\n\n              if (checkLastModified) {\n                Term pathTerm =\n                  new Term(\"path\", file.getPath());\n                TermQuery query =\n                  new TermQuery(pathTerm);\n                ScoreDoc[] hits = searcher.search(query, null, 1).scoreDocs;\n\n                // if document is found, compare the\n                // indexed last modified time with the\n                // current file\n                // - don't index if up to date\n                if (hits.length > 0) {\n                  Document doc = searcher.doc(hits[0].doc);\n                  String indexModified =\n                    doc.get(\"modified\").trim();\n                  if (indexModified != null) {\n                    long lastModified = 0;\n                    try {\n                      lastModified = DateTools.stringToTime(indexModified);\n                    } catch (ParseException e) {\n                      // if modified time is not parsable, skip\n                    }\n                    if (lastModified == file.lastModified()) {\n                      // TODO: remove existing document\n                      indexIt = false;\n                    }\n                  }\n                }\n              }\n\n              if (indexIt) {\n                try {\n                  log(\"Indexing \" + file.getPath(),\n                      Project.MSG_VERBOSE);\n                  Document doc =\n                    handler.getDocument(file);\n\n                  if (doc == null) {\n                    totalIgnored++;\n                  } else {\n                    // Add the path of the file as a field named \"path\".  Use a Keyword field, so\n                    // that the index stores the path, and so that the path is searchable\n                    doc.add(new Field(\"path\", file.getPath(), Field.Store.YES, Field.Index.NOT_ANALYZED));\n\n                    // Add the last modified date of the file a field named \"modified\".  Use a\n                    // Keyword field, so that it's searchable, but so that no attempt is made\n                    // to tokenize the field into words.\n                    doc.add(new Field(\"modified\", DateTools.timeToString(file.lastModified(), DateTools.Resolution.MILLISECOND), Field.Store.YES, Field.Index.NOT_ANALYZED));\n\n                    writer.addDocument(doc);\n                    totalIndexed++;\n                  }\n                } catch (DocumentHandlerException e) {\n                  throw new BuildException(e);\n                }\n              }\n            }\n            // for j\n          }\n          // if (fs != null)\n        }\n        // for i\n\n        writer.optimize();\n      }\n        //try\n      finally {\n        // always make sure everything gets closed,\n        // no matter how we exit.\n        writer.close();\n        if (searcher != null) {\n          searcher.close();\n        }\n      }\n\n      Date end = new Date();\n\n      log(totalIndexed + \" out of \" + totalFiles + \" indexed (\" +\n          totalIgnored + \" ignored) in \" + (end.getTime() - start.getTime()) +\n          \" milliseconds\");\n    } finally {\n      dir.close();\n    }\n  }\n\n","sourceOld":"  /**\n   * Index the fileset.\n   *\n   *@exception  IOException if Lucene I/O exception\n   *TODO: refactor!!!!!\n   */\n  private void indexDocs() throws IOException {\n    Date start = new Date();\n\n    boolean create = overwrite;\n    // If the index directory doesn't exist,\n    // create it and force create mode\n    if (indexDir.mkdirs() && !overwrite) {\n      create = true;\n    }\n\n    FSDirectory dir = FSDirectory.open(indexDir);\n    try {\n      Searcher searcher = null;\n      boolean checkLastModified = false;\n      if (!create) {\n        try {\n          searcher = new IndexSearcher(dir, true);\n          checkLastModified = true;\n        } catch (IOException ioe) {\n          log(\"IOException: \" + ioe.getMessage());\n          // Empty - ignore, which indicates to index all\n          // documents\n        }\n      }\n\n      log(\"checkLastModified = \" + checkLastModified, Project.MSG_VERBOSE);\n\n      IndexWriterConfig conf = new IndexWriterConfig(\n          Version.LUCENE_CURRENT, analyzer).setOpenMode(\n          create ? OpenMode.CREATE : OpenMode.APPEND);\n      LogMergePolicy lmp = (LogMergePolicy) conf.getMergePolicy();\n      lmp.setUseCompoundFile(useCompoundIndex);\n      lmp.setMergeFactor(mergeFactor);\n      IndexWriter writer = new IndexWriter(dir, conf);\n      int totalFiles = 0;\n      int totalIndexed = 0;\n      int totalIgnored = 0;\n      try {\n\n        for (int i = 0; i < rcs.size(); i++) {\n          ResourceCollection rc = rcs.elementAt(i);\n          if (rc.isFilesystemOnly()) {\n            Iterator resources = rc.iterator();\n            while (resources.hasNext()) {\n              Resource r = (Resource) resources.next();\n              if (!r.isExists() || !(r instanceof FileResource)) {\n                continue;\n              }\n              \n              totalFiles++;\n\n              File file = ((FileResource) r).getFile();\n              \n              if (!file.exists() || !file.canRead()) {\n                throw new BuildException(\"File \\\"\" +\n                                         file.getAbsolutePath()\n                                         + \"\\\" does not exist or is not readable.\");\n              }\n\n              boolean indexIt = true;\n\n              if (checkLastModified) {\n                Term pathTerm =\n                  new Term(\"path\", file.getPath());\n                TermQuery query =\n                  new TermQuery(pathTerm);\n                ScoreDoc[] hits = searcher.search(query, null, 1).scoreDocs;\n\n                // if document is found, compare the\n                // indexed last modified time with the\n                // current file\n                // - don't index if up to date\n                if (hits.length > 0) {\n                  Document doc = searcher.doc(hits[0].doc);\n                  String indexModified =\n                    doc.get(\"modified\").trim();\n                  if (indexModified != null) {\n                    long lastModified = 0;\n                    try {\n                      lastModified = DateTools.stringToTime(indexModified);\n                    } catch (ParseException e) {\n                      // if modified time is not parsable, skip\n                    }\n                    if (lastModified == file.lastModified()) {\n                      // TODO: remove existing document\n                      indexIt = false;\n                    }\n                  }\n                }\n              }\n\n              if (indexIt) {\n                try {\n                  log(\"Indexing \" + file.getPath(),\n                      Project.MSG_VERBOSE);\n                  Document doc =\n                    handler.getDocument(file);\n\n                  if (doc == null) {\n                    totalIgnored++;\n                  } else {\n                    // Add the path of the file as a field named \"path\".  Use a Keyword field, so\n                    // that the index stores the path, and so that the path is searchable\n                    doc.add(new Field(\"path\", file.getPath(), Field.Store.YES, Field.Index.NOT_ANALYZED));\n\n                    // Add the last modified date of the file a field named \"modified\".  Use a\n                    // Keyword field, so that it's searchable, but so that no attempt is made\n                    // to tokenize the field into words.\n                    doc.add(new Field(\"modified\", DateTools.timeToString(file.lastModified(), DateTools.Resolution.MILLISECOND), Field.Store.YES, Field.Index.NOT_ANALYZED));\n\n                    writer.addDocument(doc);\n                    totalIndexed++;\n                  }\n                } catch (DocumentHandlerException e) {\n                  throw new BuildException(e);\n                }\n              }\n            }\n            // for j\n          }\n          // if (fs != null)\n        }\n        // for i\n\n        writer.optimize();\n      }\n        //try\n      finally {\n        // always make sure everything gets closed,\n        // no matter how we exit.\n        writer.close();\n        if (searcher != null) {\n          searcher.close();\n        }\n      }\n\n      Date end = new Date();\n\n      log(totalIndexed + \" out of \" + totalFiles + \" indexed (\" +\n          totalIgnored + \" ignored) in \" + (end.getTime() - start.getTime()) +\n          \" milliseconds\");\n    } finally {\n      dir.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"868da859b43505d9d2a023bfeae6dd0c795f5295","date":1294948401,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/contrib/ant/src/java/org/apache/lucene/ant/IndexTask#indexDocs().mjava","pathOld":"lucene/contrib/ant/src/java/org/apache/lucene/ant/IndexTask#indexDocs().mjava","sourceNew":"  /**\n   * Index the fileset.\n   *\n   *@exception  IOException if Lucene I/O exception\n   *TODO: refactor!!!!!\n   */\n  private void indexDocs() throws IOException {\n    Date start = new Date();\n\n    boolean create = overwrite;\n    // If the index directory doesn't exist,\n    // create it and force create mode\n    if (indexDir.mkdirs() && !overwrite) {\n      create = true;\n    }\n\n    FSDirectory dir = FSDirectory.open(indexDir);\n    try {\n      IndexSearcher searcher = null;\n      boolean checkLastModified = false;\n      if (!create) {\n        try {\n          searcher = new IndexSearcher(dir, true);\n          checkLastModified = true;\n        } catch (IOException ioe) {\n          log(\"IOException: \" + ioe.getMessage());\n          // Empty - ignore, which indicates to index all\n          // documents\n        }\n      }\n\n      log(\"checkLastModified = \" + checkLastModified, Project.MSG_VERBOSE);\n\n      IndexWriterConfig conf = new IndexWriterConfig(\n          Version.LUCENE_CURRENT, analyzer).setOpenMode(\n          create ? OpenMode.CREATE : OpenMode.APPEND);\n      LogMergePolicy lmp = (LogMergePolicy) conf.getMergePolicy();\n      lmp.setUseCompoundFile(useCompoundIndex);\n      lmp.setMergeFactor(mergeFactor);\n      IndexWriter writer = new IndexWriter(dir, conf);\n      int totalFiles = 0;\n      int totalIndexed = 0;\n      int totalIgnored = 0;\n      try {\n\n        for (int i = 0; i < rcs.size(); i++) {\n          ResourceCollection rc = rcs.elementAt(i);\n          if (rc.isFilesystemOnly()) {\n            Iterator resources = rc.iterator();\n            while (resources.hasNext()) {\n              Resource r = (Resource) resources.next();\n              if (!r.isExists() || !(r instanceof FileResource)) {\n                continue;\n              }\n              \n              totalFiles++;\n\n              File file = ((FileResource) r).getFile();\n              \n              if (!file.exists() || !file.canRead()) {\n                throw new BuildException(\"File \\\"\" +\n                                         file.getAbsolutePath()\n                                         + \"\\\" does not exist or is not readable.\");\n              }\n\n              boolean indexIt = true;\n\n              if (checkLastModified) {\n                Term pathTerm =\n                  new Term(\"path\", file.getPath());\n                TermQuery query =\n                  new TermQuery(pathTerm);\n                ScoreDoc[] hits = searcher.search(query, null, 1).scoreDocs;\n\n                // if document is found, compare the\n                // indexed last modified time with the\n                // current file\n                // - don't index if up to date\n                if (hits.length > 0) {\n                  Document doc = searcher.doc(hits[0].doc);\n                  String indexModified =\n                    doc.get(\"modified\").trim();\n                  if (indexModified != null) {\n                    long lastModified = 0;\n                    try {\n                      lastModified = DateTools.stringToTime(indexModified);\n                    } catch (ParseException e) {\n                      // if modified time is not parsable, skip\n                    }\n                    if (lastModified == file.lastModified()) {\n                      // TODO: remove existing document\n                      indexIt = false;\n                    }\n                  }\n                }\n              }\n\n              if (indexIt) {\n                try {\n                  log(\"Indexing \" + file.getPath(),\n                      Project.MSG_VERBOSE);\n                  Document doc =\n                    handler.getDocument(file);\n\n                  if (doc == null) {\n                    totalIgnored++;\n                  } else {\n                    // Add the path of the file as a field named \"path\".  Use a Keyword field, so\n                    // that the index stores the path, and so that the path is searchable\n                    doc.add(new Field(\"path\", file.getPath(), Field.Store.YES, Field.Index.NOT_ANALYZED));\n\n                    // Add the last modified date of the file a field named \"modified\".  Use a\n                    // Keyword field, so that it's searchable, but so that no attempt is made\n                    // to tokenize the field into words.\n                    doc.add(new Field(\"modified\", DateTools.timeToString(file.lastModified(), DateTools.Resolution.MILLISECOND), Field.Store.YES, Field.Index.NOT_ANALYZED));\n\n                    writer.addDocument(doc);\n                    totalIndexed++;\n                  }\n                } catch (DocumentHandlerException e) {\n                  throw new BuildException(e);\n                }\n              }\n            }\n            // for j\n          }\n          // if (fs != null)\n        }\n        // for i\n\n        writer.optimize();\n      }\n        //try\n      finally {\n        // always make sure everything gets closed,\n        // no matter how we exit.\n        writer.close();\n        if (searcher != null) {\n          searcher.close();\n        }\n      }\n\n      Date end = new Date();\n\n      log(totalIndexed + \" out of \" + totalFiles + \" indexed (\" +\n          totalIgnored + \" ignored) in \" + (end.getTime() - start.getTime()) +\n          \" milliseconds\");\n    } finally {\n      dir.close();\n    }\n  }\n\n","sourceOld":"  /**\n   * Index the fileset.\n   *\n   *@exception  IOException if Lucene I/O exception\n   *TODO: refactor!!!!!\n   */\n  private void indexDocs() throws IOException {\n    Date start = new Date();\n\n    boolean create = overwrite;\n    // If the index directory doesn't exist,\n    // create it and force create mode\n    if (indexDir.mkdirs() && !overwrite) {\n      create = true;\n    }\n\n    FSDirectory dir = FSDirectory.open(indexDir);\n    try {\n      Searcher searcher = null;\n      boolean checkLastModified = false;\n      if (!create) {\n        try {\n          searcher = new IndexSearcher(dir, true);\n          checkLastModified = true;\n        } catch (IOException ioe) {\n          log(\"IOException: \" + ioe.getMessage());\n          // Empty - ignore, which indicates to index all\n          // documents\n        }\n      }\n\n      log(\"checkLastModified = \" + checkLastModified, Project.MSG_VERBOSE);\n\n      IndexWriterConfig conf = new IndexWriterConfig(\n          Version.LUCENE_CURRENT, analyzer).setOpenMode(\n          create ? OpenMode.CREATE : OpenMode.APPEND);\n      LogMergePolicy lmp = (LogMergePolicy) conf.getMergePolicy();\n      lmp.setUseCompoundFile(useCompoundIndex);\n      lmp.setMergeFactor(mergeFactor);\n      IndexWriter writer = new IndexWriter(dir, conf);\n      int totalFiles = 0;\n      int totalIndexed = 0;\n      int totalIgnored = 0;\n      try {\n\n        for (int i = 0; i < rcs.size(); i++) {\n          ResourceCollection rc = rcs.elementAt(i);\n          if (rc.isFilesystemOnly()) {\n            Iterator resources = rc.iterator();\n            while (resources.hasNext()) {\n              Resource r = (Resource) resources.next();\n              if (!r.isExists() || !(r instanceof FileResource)) {\n                continue;\n              }\n              \n              totalFiles++;\n\n              File file = ((FileResource) r).getFile();\n              \n              if (!file.exists() || !file.canRead()) {\n                throw new BuildException(\"File \\\"\" +\n                                         file.getAbsolutePath()\n                                         + \"\\\" does not exist or is not readable.\");\n              }\n\n              boolean indexIt = true;\n\n              if (checkLastModified) {\n                Term pathTerm =\n                  new Term(\"path\", file.getPath());\n                TermQuery query =\n                  new TermQuery(pathTerm);\n                ScoreDoc[] hits = searcher.search(query, null, 1).scoreDocs;\n\n                // if document is found, compare the\n                // indexed last modified time with the\n                // current file\n                // - don't index if up to date\n                if (hits.length > 0) {\n                  Document doc = searcher.doc(hits[0].doc);\n                  String indexModified =\n                    doc.get(\"modified\").trim();\n                  if (indexModified != null) {\n                    long lastModified = 0;\n                    try {\n                      lastModified = DateTools.stringToTime(indexModified);\n                    } catch (ParseException e) {\n                      // if modified time is not parsable, skip\n                    }\n                    if (lastModified == file.lastModified()) {\n                      // TODO: remove existing document\n                      indexIt = false;\n                    }\n                  }\n                }\n              }\n\n              if (indexIt) {\n                try {\n                  log(\"Indexing \" + file.getPath(),\n                      Project.MSG_VERBOSE);\n                  Document doc =\n                    handler.getDocument(file);\n\n                  if (doc == null) {\n                    totalIgnored++;\n                  } else {\n                    // Add the path of the file as a field named \"path\".  Use a Keyword field, so\n                    // that the index stores the path, and so that the path is searchable\n                    doc.add(new Field(\"path\", file.getPath(), Field.Store.YES, Field.Index.NOT_ANALYZED));\n\n                    // Add the last modified date of the file a field named \"modified\".  Use a\n                    // Keyword field, so that it's searchable, but so that no attempt is made\n                    // to tokenize the field into words.\n                    doc.add(new Field(\"modified\", DateTools.timeToString(file.lastModified(), DateTools.Resolution.MILLISECOND), Field.Store.YES, Field.Index.NOT_ANALYZED));\n\n                    writer.addDocument(doc);\n                    totalIndexed++;\n                  }\n                } catch (DocumentHandlerException e) {\n                  throw new BuildException(e);\n                }\n              }\n            }\n            // for j\n          }\n          // if (fs != null)\n        }\n        // for i\n\n        writer.optimize();\n      }\n        //try\n      finally {\n        // always make sure everything gets closed,\n        // no matter how we exit.\n        writer.close();\n        if (searcher != null) {\n          searcher.close();\n        }\n      }\n\n      Date end = new Date();\n\n      log(totalIndexed + \" out of \" + totalFiles + \" indexed (\" +\n          totalIgnored + \" ignored) in \" + (end.getTime() - start.getTime()) +\n          \" milliseconds\");\n    } finally {\n      dir.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"01e5948db9a07144112d2f08f28ca2e3cd880348","date":1301759232,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/contrib/ant/src/java/org/apache/lucene/ant/IndexTask#indexDocs().mjava","pathOld":"lucene/contrib/ant/src/java/org/apache/lucene/ant/IndexTask#indexDocs().mjava","sourceNew":"  /**\n   * Index the fileset.\n   *\n   *@exception  IOException if Lucene I/O exception\n   *TODO: refactor!!!!!\n   */\n  private void indexDocs() throws IOException {\n    Date start = new Date();\n\n    boolean create = overwrite;\n    // If the index directory doesn't exist,\n    // create it and force create mode\n    if (indexDir.mkdirs() && !overwrite) {\n      create = true;\n    }\n\n    FSDirectory dir = FSDirectory.open(indexDir);\n    try {\n      IndexSearcher searcher = null;\n      boolean checkLastModified = false;\n      if (!create) {\n        try {\n          searcher = new IndexSearcher(dir, true);\n          checkLastModified = true;\n        } catch (IOException ioe) {\n          log(\"IOException: \" + ioe.getMessage());\n          // Empty - ignore, which indicates to index all\n          // documents\n        }\n      }\n\n      log(\"checkLastModified = \" + checkLastModified, Project.MSG_VERBOSE);\n\n      IndexWriterConfig conf = new IndexWriterConfig(\n          Version.LUCENE_CURRENT, analyzer).setOpenMode(\n          create ? OpenMode.CREATE : OpenMode.APPEND);\n      TieredMergePolicy tmp = (TieredMergePolicy) conf.getMergePolicy();\n      tmp.setUseCompoundFile(useCompoundIndex);\n      tmp.setMaxMergeAtOnce(mergeFactor);\n      IndexWriter writer = new IndexWriter(dir, conf);\n      int totalFiles = 0;\n      int totalIndexed = 0;\n      int totalIgnored = 0;\n      try {\n\n        for (int i = 0; i < rcs.size(); i++) {\n          ResourceCollection rc = rcs.elementAt(i);\n          if (rc.isFilesystemOnly()) {\n            Iterator resources = rc.iterator();\n            while (resources.hasNext()) {\n              Resource r = (Resource) resources.next();\n              if (!r.isExists() || !(r instanceof FileResource)) {\n                continue;\n              }\n              \n              totalFiles++;\n\n              File file = ((FileResource) r).getFile();\n              \n              if (!file.exists() || !file.canRead()) {\n                throw new BuildException(\"File \\\"\" +\n                                         file.getAbsolutePath()\n                                         + \"\\\" does not exist or is not readable.\");\n              }\n\n              boolean indexIt = true;\n\n              if (checkLastModified) {\n                Term pathTerm =\n                  new Term(\"path\", file.getPath());\n                TermQuery query =\n                  new TermQuery(pathTerm);\n                ScoreDoc[] hits = searcher.search(query, null, 1).scoreDocs;\n\n                // if document is found, compare the\n                // indexed last modified time with the\n                // current file\n                // - don't index if up to date\n                if (hits.length > 0) {\n                  Document doc = searcher.doc(hits[0].doc);\n                  String indexModified =\n                    doc.get(\"modified\").trim();\n                  if (indexModified != null) {\n                    long lastModified = 0;\n                    try {\n                      lastModified = DateTools.stringToTime(indexModified);\n                    } catch (ParseException e) {\n                      // if modified time is not parsable, skip\n                    }\n                    if (lastModified == file.lastModified()) {\n                      // TODO: remove existing document\n                      indexIt = false;\n                    }\n                  }\n                }\n              }\n\n              if (indexIt) {\n                try {\n                  log(\"Indexing \" + file.getPath(),\n                      Project.MSG_VERBOSE);\n                  Document doc =\n                    handler.getDocument(file);\n\n                  if (doc == null) {\n                    totalIgnored++;\n                  } else {\n                    // Add the path of the file as a field named \"path\".  Use a Keyword field, so\n                    // that the index stores the path, and so that the path is searchable\n                    doc.add(new Field(\"path\", file.getPath(), Field.Store.YES, Field.Index.NOT_ANALYZED));\n\n                    // Add the last modified date of the file a field named \"modified\".  Use a\n                    // Keyword field, so that it's searchable, but so that no attempt is made\n                    // to tokenize the field into words.\n                    doc.add(new Field(\"modified\", DateTools.timeToString(file.lastModified(), DateTools.Resolution.MILLISECOND), Field.Store.YES, Field.Index.NOT_ANALYZED));\n\n                    writer.addDocument(doc);\n                    totalIndexed++;\n                  }\n                } catch (DocumentHandlerException e) {\n                  throw new BuildException(e);\n                }\n              }\n            }\n            // for j\n          }\n          // if (fs != null)\n        }\n        // for i\n\n        writer.optimize();\n      }\n        //try\n      finally {\n        // always make sure everything gets closed,\n        // no matter how we exit.\n        writer.close();\n        if (searcher != null) {\n          searcher.close();\n        }\n      }\n\n      Date end = new Date();\n\n      log(totalIndexed + \" out of \" + totalFiles + \" indexed (\" +\n          totalIgnored + \" ignored) in \" + (end.getTime() - start.getTime()) +\n          \" milliseconds\");\n    } finally {\n      dir.close();\n    }\n  }\n\n","sourceOld":"  /**\n   * Index the fileset.\n   *\n   *@exception  IOException if Lucene I/O exception\n   *TODO: refactor!!!!!\n   */\n  private void indexDocs() throws IOException {\n    Date start = new Date();\n\n    boolean create = overwrite;\n    // If the index directory doesn't exist,\n    // create it and force create mode\n    if (indexDir.mkdirs() && !overwrite) {\n      create = true;\n    }\n\n    FSDirectory dir = FSDirectory.open(indexDir);\n    try {\n      IndexSearcher searcher = null;\n      boolean checkLastModified = false;\n      if (!create) {\n        try {\n          searcher = new IndexSearcher(dir, true);\n          checkLastModified = true;\n        } catch (IOException ioe) {\n          log(\"IOException: \" + ioe.getMessage());\n          // Empty - ignore, which indicates to index all\n          // documents\n        }\n      }\n\n      log(\"checkLastModified = \" + checkLastModified, Project.MSG_VERBOSE);\n\n      IndexWriterConfig conf = new IndexWriterConfig(\n          Version.LUCENE_CURRENT, analyzer).setOpenMode(\n          create ? OpenMode.CREATE : OpenMode.APPEND);\n      LogMergePolicy lmp = (LogMergePolicy) conf.getMergePolicy();\n      lmp.setUseCompoundFile(useCompoundIndex);\n      lmp.setMergeFactor(mergeFactor);\n      IndexWriter writer = new IndexWriter(dir, conf);\n      int totalFiles = 0;\n      int totalIndexed = 0;\n      int totalIgnored = 0;\n      try {\n\n        for (int i = 0; i < rcs.size(); i++) {\n          ResourceCollection rc = rcs.elementAt(i);\n          if (rc.isFilesystemOnly()) {\n            Iterator resources = rc.iterator();\n            while (resources.hasNext()) {\n              Resource r = (Resource) resources.next();\n              if (!r.isExists() || !(r instanceof FileResource)) {\n                continue;\n              }\n              \n              totalFiles++;\n\n              File file = ((FileResource) r).getFile();\n              \n              if (!file.exists() || !file.canRead()) {\n                throw new BuildException(\"File \\\"\" +\n                                         file.getAbsolutePath()\n                                         + \"\\\" does not exist or is not readable.\");\n              }\n\n              boolean indexIt = true;\n\n              if (checkLastModified) {\n                Term pathTerm =\n                  new Term(\"path\", file.getPath());\n                TermQuery query =\n                  new TermQuery(pathTerm);\n                ScoreDoc[] hits = searcher.search(query, null, 1).scoreDocs;\n\n                // if document is found, compare the\n                // indexed last modified time with the\n                // current file\n                // - don't index if up to date\n                if (hits.length > 0) {\n                  Document doc = searcher.doc(hits[0].doc);\n                  String indexModified =\n                    doc.get(\"modified\").trim();\n                  if (indexModified != null) {\n                    long lastModified = 0;\n                    try {\n                      lastModified = DateTools.stringToTime(indexModified);\n                    } catch (ParseException e) {\n                      // if modified time is not parsable, skip\n                    }\n                    if (lastModified == file.lastModified()) {\n                      // TODO: remove existing document\n                      indexIt = false;\n                    }\n                  }\n                }\n              }\n\n              if (indexIt) {\n                try {\n                  log(\"Indexing \" + file.getPath(),\n                      Project.MSG_VERBOSE);\n                  Document doc =\n                    handler.getDocument(file);\n\n                  if (doc == null) {\n                    totalIgnored++;\n                  } else {\n                    // Add the path of the file as a field named \"path\".  Use a Keyword field, so\n                    // that the index stores the path, and so that the path is searchable\n                    doc.add(new Field(\"path\", file.getPath(), Field.Store.YES, Field.Index.NOT_ANALYZED));\n\n                    // Add the last modified date of the file a field named \"modified\".  Use a\n                    // Keyword field, so that it's searchable, but so that no attempt is made\n                    // to tokenize the field into words.\n                    doc.add(new Field(\"modified\", DateTools.timeToString(file.lastModified(), DateTools.Resolution.MILLISECOND), Field.Store.YES, Field.Index.NOT_ANALYZED));\n\n                    writer.addDocument(doc);\n                    totalIndexed++;\n                  }\n                } catch (DocumentHandlerException e) {\n                  throw new BuildException(e);\n                }\n              }\n            }\n            // for j\n          }\n          // if (fs != null)\n        }\n        // for i\n\n        writer.optimize();\n      }\n        //try\n      finally {\n        // always make sure everything gets closed,\n        // no matter how we exit.\n        writer.close();\n        if (searcher != null) {\n          searcher.close();\n        }\n      }\n\n      Date end = new Date();\n\n      log(totalIndexed + \" out of \" + totalFiles + \" indexed (\" +\n          totalIgnored + \" ignored) in \" + (end.getTime() - start.getTime()) +\n          \" milliseconds\");\n    } finally {\n      dir.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"45669a651c970812a680841b97a77cce06af559f","date":1301922222,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/contrib/ant/src/java/org/apache/lucene/ant/IndexTask#indexDocs().mjava","pathOld":"lucene/contrib/ant/src/java/org/apache/lucene/ant/IndexTask#indexDocs().mjava","sourceNew":"  /**\n   * Index the fileset.\n   *\n   *@exception  IOException if Lucene I/O exception\n   *TODO: refactor!!!!!\n   */\n  private void indexDocs() throws IOException {\n    Date start = new Date();\n\n    boolean create = overwrite;\n    // If the index directory doesn't exist,\n    // create it and force create mode\n    if (indexDir.mkdirs() && !overwrite) {\n      create = true;\n    }\n\n    FSDirectory dir = FSDirectory.open(indexDir);\n    try {\n      IndexSearcher searcher = null;\n      boolean checkLastModified = false;\n      if (!create) {\n        try {\n          searcher = new IndexSearcher(dir, true);\n          checkLastModified = true;\n        } catch (IOException ioe) {\n          log(\"IOException: \" + ioe.getMessage());\n          // Empty - ignore, which indicates to index all\n          // documents\n        }\n      }\n\n      log(\"checkLastModified = \" + checkLastModified, Project.MSG_VERBOSE);\n\n      IndexWriterConfig conf = new IndexWriterConfig(\n          Version.LUCENE_CURRENT, analyzer).setOpenMode(\n          create ? OpenMode.CREATE : OpenMode.APPEND);\n      TieredMergePolicy tmp = (TieredMergePolicy) conf.getMergePolicy();\n      tmp.setUseCompoundFile(useCompoundIndex);\n      tmp.setMaxMergeAtOnce(mergeFactor);\n      IndexWriter writer = new IndexWriter(dir, conf);\n      int totalFiles = 0;\n      int totalIndexed = 0;\n      int totalIgnored = 0;\n      try {\n\n        for (int i = 0; i < rcs.size(); i++) {\n          ResourceCollection rc = rcs.elementAt(i);\n          if (rc.isFilesystemOnly()) {\n            Iterator resources = rc.iterator();\n            while (resources.hasNext()) {\n              Resource r = (Resource) resources.next();\n              if (!r.isExists() || !(r instanceof FileResource)) {\n                continue;\n              }\n              \n              totalFiles++;\n\n              File file = ((FileResource) r).getFile();\n              \n              if (!file.exists() || !file.canRead()) {\n                throw new BuildException(\"File \\\"\" +\n                                         file.getAbsolutePath()\n                                         + \"\\\" does not exist or is not readable.\");\n              }\n\n              boolean indexIt = true;\n\n              if (checkLastModified) {\n                Term pathTerm =\n                  new Term(\"path\", file.getPath());\n                TermQuery query =\n                  new TermQuery(pathTerm);\n                ScoreDoc[] hits = searcher.search(query, null, 1).scoreDocs;\n\n                // if document is found, compare the\n                // indexed last modified time with the\n                // current file\n                // - don't index if up to date\n                if (hits.length > 0) {\n                  Document doc = searcher.doc(hits[0].doc);\n                  String indexModified =\n                    doc.get(\"modified\").trim();\n                  if (indexModified != null) {\n                    long lastModified = 0;\n                    try {\n                      lastModified = DateTools.stringToTime(indexModified);\n                    } catch (ParseException e) {\n                      // if modified time is not parsable, skip\n                    }\n                    if (lastModified == file.lastModified()) {\n                      // TODO: remove existing document\n                      indexIt = false;\n                    }\n                  }\n                }\n              }\n\n              if (indexIt) {\n                try {\n                  log(\"Indexing \" + file.getPath(),\n                      Project.MSG_VERBOSE);\n                  Document doc =\n                    handler.getDocument(file);\n\n                  if (doc == null) {\n                    totalIgnored++;\n                  } else {\n                    // Add the path of the file as a field named \"path\".  Use a Keyword field, so\n                    // that the index stores the path, and so that the path is searchable\n                    doc.add(new Field(\"path\", file.getPath(), Field.Store.YES, Field.Index.NOT_ANALYZED));\n\n                    // Add the last modified date of the file a field named \"modified\".  Use a\n                    // Keyword field, so that it's searchable, but so that no attempt is made\n                    // to tokenize the field into words.\n                    doc.add(new Field(\"modified\", DateTools.timeToString(file.lastModified(), DateTools.Resolution.MILLISECOND), Field.Store.YES, Field.Index.NOT_ANALYZED));\n\n                    writer.addDocument(doc);\n                    totalIndexed++;\n                  }\n                } catch (DocumentHandlerException e) {\n                  throw new BuildException(e);\n                }\n              }\n            }\n            // for j\n          }\n          // if (fs != null)\n        }\n        // for i\n\n        writer.optimize();\n      }\n        //try\n      finally {\n        // always make sure everything gets closed,\n        // no matter how we exit.\n        writer.close();\n        if (searcher != null) {\n          searcher.close();\n        }\n      }\n\n      Date end = new Date();\n\n      log(totalIndexed + \" out of \" + totalFiles + \" indexed (\" +\n          totalIgnored + \" ignored) in \" + (end.getTime() - start.getTime()) +\n          \" milliseconds\");\n    } finally {\n      dir.close();\n    }\n  }\n\n","sourceOld":"  /**\n   * Index the fileset.\n   *\n   *@exception  IOException if Lucene I/O exception\n   *TODO: refactor!!!!!\n   */\n  private void indexDocs() throws IOException {\n    Date start = new Date();\n\n    boolean create = overwrite;\n    // If the index directory doesn't exist,\n    // create it and force create mode\n    if (indexDir.mkdirs() && !overwrite) {\n      create = true;\n    }\n\n    FSDirectory dir = FSDirectory.open(indexDir);\n    try {\n      IndexSearcher searcher = null;\n      boolean checkLastModified = false;\n      if (!create) {\n        try {\n          searcher = new IndexSearcher(dir, true);\n          checkLastModified = true;\n        } catch (IOException ioe) {\n          log(\"IOException: \" + ioe.getMessage());\n          // Empty - ignore, which indicates to index all\n          // documents\n        }\n      }\n\n      log(\"checkLastModified = \" + checkLastModified, Project.MSG_VERBOSE);\n\n      IndexWriterConfig conf = new IndexWriterConfig(\n          Version.LUCENE_CURRENT, analyzer).setOpenMode(\n          create ? OpenMode.CREATE : OpenMode.APPEND);\n      LogMergePolicy lmp = (LogMergePolicy) conf.getMergePolicy();\n      lmp.setUseCompoundFile(useCompoundIndex);\n      lmp.setMergeFactor(mergeFactor);\n      IndexWriter writer = new IndexWriter(dir, conf);\n      int totalFiles = 0;\n      int totalIndexed = 0;\n      int totalIgnored = 0;\n      try {\n\n        for (int i = 0; i < rcs.size(); i++) {\n          ResourceCollection rc = rcs.elementAt(i);\n          if (rc.isFilesystemOnly()) {\n            Iterator resources = rc.iterator();\n            while (resources.hasNext()) {\n              Resource r = (Resource) resources.next();\n              if (!r.isExists() || !(r instanceof FileResource)) {\n                continue;\n              }\n              \n              totalFiles++;\n\n              File file = ((FileResource) r).getFile();\n              \n              if (!file.exists() || !file.canRead()) {\n                throw new BuildException(\"File \\\"\" +\n                                         file.getAbsolutePath()\n                                         + \"\\\" does not exist or is not readable.\");\n              }\n\n              boolean indexIt = true;\n\n              if (checkLastModified) {\n                Term pathTerm =\n                  new Term(\"path\", file.getPath());\n                TermQuery query =\n                  new TermQuery(pathTerm);\n                ScoreDoc[] hits = searcher.search(query, null, 1).scoreDocs;\n\n                // if document is found, compare the\n                // indexed last modified time with the\n                // current file\n                // - don't index if up to date\n                if (hits.length > 0) {\n                  Document doc = searcher.doc(hits[0].doc);\n                  String indexModified =\n                    doc.get(\"modified\").trim();\n                  if (indexModified != null) {\n                    long lastModified = 0;\n                    try {\n                      lastModified = DateTools.stringToTime(indexModified);\n                    } catch (ParseException e) {\n                      // if modified time is not parsable, skip\n                    }\n                    if (lastModified == file.lastModified()) {\n                      // TODO: remove existing document\n                      indexIt = false;\n                    }\n                  }\n                }\n              }\n\n              if (indexIt) {\n                try {\n                  log(\"Indexing \" + file.getPath(),\n                      Project.MSG_VERBOSE);\n                  Document doc =\n                    handler.getDocument(file);\n\n                  if (doc == null) {\n                    totalIgnored++;\n                  } else {\n                    // Add the path of the file as a field named \"path\".  Use a Keyword field, so\n                    // that the index stores the path, and so that the path is searchable\n                    doc.add(new Field(\"path\", file.getPath(), Field.Store.YES, Field.Index.NOT_ANALYZED));\n\n                    // Add the last modified date of the file a field named \"modified\".  Use a\n                    // Keyword field, so that it's searchable, but so that no attempt is made\n                    // to tokenize the field into words.\n                    doc.add(new Field(\"modified\", DateTools.timeToString(file.lastModified(), DateTools.Resolution.MILLISECOND), Field.Store.YES, Field.Index.NOT_ANALYZED));\n\n                    writer.addDocument(doc);\n                    totalIndexed++;\n                  }\n                } catch (DocumentHandlerException e) {\n                  throw new BuildException(e);\n                }\n              }\n            }\n            // for j\n          }\n          // if (fs != null)\n        }\n        // for i\n\n        writer.optimize();\n      }\n        //try\n      finally {\n        // always make sure everything gets closed,\n        // no matter how we exit.\n        writer.close();\n        if (searcher != null) {\n          searcher.close();\n        }\n      }\n\n      Date end = new Date();\n\n      log(totalIndexed + \" out of \" + totalFiles + \" indexed (\" +\n          totalIgnored + \" ignored) in \" + (end.getTime() - start.getTime()) +\n          \" milliseconds\");\n    } finally {\n      dir.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"135621f3a0670a9394eb563224a3b76cc4dddc0f","date":1304344257,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/contrib/ant/src/java/org/apache/lucene/ant/IndexTask#indexDocs().mjava","pathOld":"lucene/contrib/ant/src/java/org/apache/lucene/ant/IndexTask#indexDocs().mjava","sourceNew":"  /**\n   * Index the fileset.\n   *\n   *@exception  IOException if Lucene I/O exception\n   *TODO: refactor!!!!!\n   */\n  private void indexDocs() throws IOException {\n    Date start = new Date();\n\n    boolean create = overwrite;\n    // If the index directory doesn't exist,\n    // create it and force create mode\n    if (indexDir.mkdirs() && !overwrite) {\n      create = true;\n    }\n\n    FSDirectory dir = FSDirectory.open(indexDir);\n    try {\n      IndexSearcher searcher = null;\n      boolean checkLastModified = false;\n      if (!create) {\n        try {\n          searcher = new IndexSearcher(dir, true);\n          checkLastModified = true;\n        } catch (IOException ioe) {\n          log(\"IOException: \" + ioe.getMessage());\n          // Empty - ignore, which indicates to index all\n          // documents\n        }\n      }\n\n      log(\"checkLastModified = \" + checkLastModified, Project.MSG_VERBOSE);\n\n      IndexWriterConfig conf = new IndexWriterConfig(\n          Version.LUCENE_CURRENT, analyzer).setOpenMode(\n          create ? OpenMode.CREATE : OpenMode.APPEND);\n      TieredMergePolicy tmp = (TieredMergePolicy) conf.getMergePolicy();\n      tmp.setUseCompoundFile(useCompoundIndex);\n      tmp.setMaxMergeAtOnce(mergeFactor);\n      IndexWriter writer = new IndexWriter(dir, conf);\n      int totalFiles = 0;\n      int totalIndexed = 0;\n      int totalIgnored = 0;\n      try {\n\n        for (int i = 0; i < rcs.size(); i++) {\n          ResourceCollection rc = rcs.elementAt(i);\n          if (rc.isFilesystemOnly()) {\n            Iterator resources = rc.iterator();\n            while (resources.hasNext()) {\n              Resource r = (Resource) resources.next();\n              if (!r.isExists() || !(r instanceof FileResource)) {\n                continue;\n              }\n              \n              totalFiles++;\n\n              File file = ((FileResource) r).getFile();\n              \n              if (!file.exists() || !file.canRead()) {\n                throw new BuildException(\"File \\\"\" +\n                                         file.getAbsolutePath()\n                                         + \"\\\" does not exist or is not readable.\");\n              }\n\n              boolean indexIt = true;\n\n              if (checkLastModified) {\n                Term pathTerm =\n                  new Term(\"path\", file.getPath());\n                TermQuery query =\n                  new TermQuery(pathTerm);\n                ScoreDoc[] hits = searcher.search(query, null, 1).scoreDocs;\n\n                // if document is found, compare the\n                // indexed last modified time with the\n                // current file\n                // - don't index if up to date\n                if (hits.length > 0) {\n                  Document doc = searcher.doc(hits[0].doc);\n                  String indexModified =\n                    doc.get(\"modified\").trim();\n                  if (indexModified != null) {\n                    long lastModified = 0;\n                    try {\n                      lastModified = DateTools.stringToTime(indexModified);\n                    } catch (ParseException e) {\n                      // if modified time is not parsable, skip\n                    }\n                    if (lastModified == file.lastModified()) {\n                      // TODO: remove existing document\n                      indexIt = false;\n                    }\n                  }\n                }\n              }\n\n              if (indexIt) {\n                try {\n                  log(\"Indexing \" + file.getPath(),\n                      Project.MSG_VERBOSE);\n                  Document doc =\n                    handler.getDocument(file);\n\n                  if (doc == null) {\n                    totalIgnored++;\n                  } else {\n                    // Add the path of the file as a field named \"path\".  Use a Keyword field, so\n                    // that the index stores the path, and so that the path is searchable\n                    doc.add(new Field(\"path\", file.getPath(), Field.Store.YES, Field.Index.NOT_ANALYZED));\n\n                    // Add the last modified date of the file a field named \"modified\".  Use a\n                    // Keyword field, so that it's searchable, but so that no attempt is made\n                    // to tokenize the field into words.\n                    doc.add(new Field(\"modified\", DateTools.timeToString(file.lastModified(), DateTools.Resolution.MILLISECOND), Field.Store.YES, Field.Index.NOT_ANALYZED));\n\n                    writer.addDocument(doc);\n                    totalIndexed++;\n                  }\n                } catch (DocumentHandlerException e) {\n                  throw new BuildException(e);\n                }\n              }\n            }\n            // for j\n          }\n          // if (fs != null)\n        }\n        // for i\n\n        writer.optimize();\n      }\n        //try\n      finally {\n        // always make sure everything gets closed,\n        // no matter how we exit.\n        writer.close();\n        if (searcher != null) {\n          searcher.close();\n        }\n      }\n\n      Date end = new Date();\n\n      log(totalIndexed + \" out of \" + totalFiles + \" indexed (\" +\n          totalIgnored + \" ignored) in \" + (end.getTime() - start.getTime()) +\n          \" milliseconds\");\n    } finally {\n      dir.close();\n    }\n  }\n\n","sourceOld":"  /**\n   * Index the fileset.\n   *\n   *@exception  IOException if Lucene I/O exception\n   *TODO: refactor!!!!!\n   */\n  private void indexDocs() throws IOException {\n    Date start = new Date();\n\n    boolean create = overwrite;\n    // If the index directory doesn't exist,\n    // create it and force create mode\n    if (indexDir.mkdirs() && !overwrite) {\n      create = true;\n    }\n\n    FSDirectory dir = FSDirectory.open(indexDir);\n    try {\n      IndexSearcher searcher = null;\n      boolean checkLastModified = false;\n      if (!create) {\n        try {\n          searcher = new IndexSearcher(dir, true);\n          checkLastModified = true;\n        } catch (IOException ioe) {\n          log(\"IOException: \" + ioe.getMessage());\n          // Empty - ignore, which indicates to index all\n          // documents\n        }\n      }\n\n      log(\"checkLastModified = \" + checkLastModified, Project.MSG_VERBOSE);\n\n      IndexWriterConfig conf = new IndexWriterConfig(\n          Version.LUCENE_CURRENT, analyzer).setOpenMode(\n          create ? OpenMode.CREATE : OpenMode.APPEND);\n      LogMergePolicy lmp = (LogMergePolicy) conf.getMergePolicy();\n      lmp.setUseCompoundFile(useCompoundIndex);\n      lmp.setMergeFactor(mergeFactor);\n      IndexWriter writer = new IndexWriter(dir, conf);\n      int totalFiles = 0;\n      int totalIndexed = 0;\n      int totalIgnored = 0;\n      try {\n\n        for (int i = 0; i < rcs.size(); i++) {\n          ResourceCollection rc = rcs.elementAt(i);\n          if (rc.isFilesystemOnly()) {\n            Iterator resources = rc.iterator();\n            while (resources.hasNext()) {\n              Resource r = (Resource) resources.next();\n              if (!r.isExists() || !(r instanceof FileResource)) {\n                continue;\n              }\n              \n              totalFiles++;\n\n              File file = ((FileResource) r).getFile();\n              \n              if (!file.exists() || !file.canRead()) {\n                throw new BuildException(\"File \\\"\" +\n                                         file.getAbsolutePath()\n                                         + \"\\\" does not exist or is not readable.\");\n              }\n\n              boolean indexIt = true;\n\n              if (checkLastModified) {\n                Term pathTerm =\n                  new Term(\"path\", file.getPath());\n                TermQuery query =\n                  new TermQuery(pathTerm);\n                ScoreDoc[] hits = searcher.search(query, null, 1).scoreDocs;\n\n                // if document is found, compare the\n                // indexed last modified time with the\n                // current file\n                // - don't index if up to date\n                if (hits.length > 0) {\n                  Document doc = searcher.doc(hits[0].doc);\n                  String indexModified =\n                    doc.get(\"modified\").trim();\n                  if (indexModified != null) {\n                    long lastModified = 0;\n                    try {\n                      lastModified = DateTools.stringToTime(indexModified);\n                    } catch (ParseException e) {\n                      // if modified time is not parsable, skip\n                    }\n                    if (lastModified == file.lastModified()) {\n                      // TODO: remove existing document\n                      indexIt = false;\n                    }\n                  }\n                }\n              }\n\n              if (indexIt) {\n                try {\n                  log(\"Indexing \" + file.getPath(),\n                      Project.MSG_VERBOSE);\n                  Document doc =\n                    handler.getDocument(file);\n\n                  if (doc == null) {\n                    totalIgnored++;\n                  } else {\n                    // Add the path of the file as a field named \"path\".  Use a Keyword field, so\n                    // that the index stores the path, and so that the path is searchable\n                    doc.add(new Field(\"path\", file.getPath(), Field.Store.YES, Field.Index.NOT_ANALYZED));\n\n                    // Add the last modified date of the file a field named \"modified\".  Use a\n                    // Keyword field, so that it's searchable, but so that no attempt is made\n                    // to tokenize the field into words.\n                    doc.add(new Field(\"modified\", DateTools.timeToString(file.lastModified(), DateTools.Resolution.MILLISECOND), Field.Store.YES, Field.Index.NOT_ANALYZED));\n\n                    writer.addDocument(doc);\n                    totalIndexed++;\n                  }\n                } catch (DocumentHandlerException e) {\n                  throw new BuildException(e);\n                }\n              }\n            }\n            // for j\n          }\n          // if (fs != null)\n        }\n        // for i\n\n        writer.optimize();\n      }\n        //try\n      finally {\n        // always make sure everything gets closed,\n        // no matter how we exit.\n        writer.close();\n        if (searcher != null) {\n          searcher.close();\n        }\n      }\n\n      Date end = new Date();\n\n      log(totalIndexed + \" out of \" + totalFiles + \" indexed (\" +\n          totalIgnored + \" ignored) in \" + (end.getTime() - start.getTime()) +\n          \" milliseconds\");\n    } finally {\n      dir.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a3776dccca01c11e7046323cfad46a3b4a471233","date":1306100719,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/contrib/ant/src/java/org/apache/lucene/ant/IndexTask#indexDocs().mjava","pathOld":"lucene/contrib/ant/src/java/org/apache/lucene/ant/IndexTask#indexDocs().mjava","sourceNew":"  /**\n   * Index the fileset.\n   *\n   *@exception  IOException if Lucene I/O exception\n   *TODO: refactor!!!!!\n   */\n  private void indexDocs() throws IOException {\n    Date start = new Date();\n\n    boolean create = overwrite;\n    // If the index directory doesn't exist,\n    // create it and force create mode\n    if (indexDir.mkdirs() && !overwrite) {\n      create = true;\n    }\n\n    FSDirectory dir = FSDirectory.open(indexDir);\n    try {\n      IndexSearcher searcher = null;\n      boolean checkLastModified = false;\n      if (!create) {\n        try {\n          searcher = new IndexSearcher(dir, true);\n          checkLastModified = true;\n        } catch (IOException ioe) {\n          log(\"IOException: \" + ioe.getMessage());\n          // Empty - ignore, which indicates to index all\n          // documents\n        }\n      }\n\n      log(\"checkLastModified = \" + checkLastModified, Project.MSG_VERBOSE);\n\n      IndexWriterConfig conf = new IndexWriterConfig(\n          Version.LUCENE_CURRENT, analyzer).setOpenMode(\n          create ? OpenMode.CREATE : OpenMode.APPEND);\n      TieredMergePolicy tmp = (TieredMergePolicy) conf.getMergePolicy();\n      tmp.setUseCompoundFile(useCompoundIndex);\n      tmp.setMaxMergeAtOnce(mergeFactor);\n      IndexWriter writer = new IndexWriter(dir, conf);\n      int totalFiles = 0;\n      int totalIndexed = 0;\n      int totalIgnored = 0;\n      try {\n\n        for (int i = 0; i < rcs.size(); i++) {\n          ResourceCollection rc = rcs.elementAt(i);\n          if (rc.isFilesystemOnly()) {\n            Iterator resources = rc.iterator();\n            while (resources.hasNext()) {\n              Resource r = (Resource) resources.next();\n              if (!r.isExists() || !(r instanceof FileResource)) {\n                continue;\n              }\n              \n              totalFiles++;\n\n              File file = ((FileResource) r).getFile();\n              \n              if (!file.exists() || !file.canRead()) {\n                throw new BuildException(\"File \\\"\" +\n                                         file.getAbsolutePath()\n                                         + \"\\\" does not exist or is not readable.\");\n              }\n\n              boolean indexIt = true;\n\n              if (checkLastModified) {\n                Term pathTerm =\n                  new Term(\"path\", file.getPath());\n                TermQuery query =\n                  new TermQuery(pathTerm);\n                ScoreDoc[] hits = searcher.search(query, null, 1).scoreDocs;\n\n                // if document is found, compare the\n                // indexed last modified time with the\n                // current file\n                // - don't index if up to date\n                if (hits.length > 0) {\n                  Document doc = searcher.doc(hits[0].doc);\n                  String indexModified =\n                    doc.get(\"modified\").trim();\n                  if (indexModified != null) {\n                    long lastModified = 0;\n                    try {\n                      lastModified = DateTools.stringToTime(indexModified);\n                    } catch (ParseException e) {\n                      // if modified time is not parsable, skip\n                    }\n                    if (lastModified == file.lastModified()) {\n                      // TODO: remove existing document\n                      indexIt = false;\n                    }\n                  }\n                }\n              }\n\n              if (indexIt) {\n                try {\n                  log(\"Indexing \" + file.getPath(),\n                      Project.MSG_VERBOSE);\n                  Document doc =\n                    handler.getDocument(file);\n\n                  if (doc == null) {\n                    totalIgnored++;\n                  } else {\n                    // Add the path of the file as a field named \"path\".  Use a Keyword field, so\n                    // that the index stores the path, and so that the path is searchable\n                    doc.add(new Field(\"path\", file.getPath(), Field.Store.YES, Field.Index.NOT_ANALYZED));\n\n                    // Add the last modified date of the file a field named \"modified\".  Use a\n                    // Keyword field, so that it's searchable, but so that no attempt is made\n                    // to tokenize the field into words.\n                    doc.add(new Field(\"modified\", DateTools.timeToString(file.lastModified(), DateTools.Resolution.MILLISECOND), Field.Store.YES, Field.Index.NOT_ANALYZED));\n\n                    writer.addDocument(doc);\n                    totalIndexed++;\n                  }\n                } catch (DocumentHandlerException e) {\n                  throw new BuildException(e);\n                }\n              }\n            }\n            // for j\n          }\n          // if (fs != null)\n        }\n        // for i\n\n        writer.optimize();\n      }\n        //try\n      finally {\n        // always make sure everything gets closed,\n        // no matter how we exit.\n        writer.close();\n        if (searcher != null) {\n          searcher.close();\n        }\n      }\n\n      Date end = new Date();\n\n      log(totalIndexed + \" out of \" + totalFiles + \" indexed (\" +\n          totalIgnored + \" ignored) in \" + (end.getTime() - start.getTime()) +\n          \" milliseconds\");\n    } finally {\n      dir.close();\n    }\n  }\n\n","sourceOld":"  /**\n   * Index the fileset.\n   *\n   *@exception  IOException if Lucene I/O exception\n   *TODO: refactor!!!!!\n   */\n  private void indexDocs() throws IOException {\n    Date start = new Date();\n\n    boolean create = overwrite;\n    // If the index directory doesn't exist,\n    // create it and force create mode\n    if (indexDir.mkdirs() && !overwrite) {\n      create = true;\n    }\n\n    FSDirectory dir = FSDirectory.open(indexDir);\n    try {\n      IndexSearcher searcher = null;\n      boolean checkLastModified = false;\n      if (!create) {\n        try {\n          searcher = new IndexSearcher(dir, true);\n          checkLastModified = true;\n        } catch (IOException ioe) {\n          log(\"IOException: \" + ioe.getMessage());\n          // Empty - ignore, which indicates to index all\n          // documents\n        }\n      }\n\n      log(\"checkLastModified = \" + checkLastModified, Project.MSG_VERBOSE);\n\n      IndexWriterConfig conf = new IndexWriterConfig(\n          Version.LUCENE_CURRENT, analyzer).setOpenMode(\n          create ? OpenMode.CREATE : OpenMode.APPEND);\n      LogMergePolicy lmp = (LogMergePolicy) conf.getMergePolicy();\n      lmp.setUseCompoundFile(useCompoundIndex);\n      lmp.setMergeFactor(mergeFactor);\n      IndexWriter writer = new IndexWriter(dir, conf);\n      int totalFiles = 0;\n      int totalIndexed = 0;\n      int totalIgnored = 0;\n      try {\n\n        for (int i = 0; i < rcs.size(); i++) {\n          ResourceCollection rc = rcs.elementAt(i);\n          if (rc.isFilesystemOnly()) {\n            Iterator resources = rc.iterator();\n            while (resources.hasNext()) {\n              Resource r = (Resource) resources.next();\n              if (!r.isExists() || !(r instanceof FileResource)) {\n                continue;\n              }\n              \n              totalFiles++;\n\n              File file = ((FileResource) r).getFile();\n              \n              if (!file.exists() || !file.canRead()) {\n                throw new BuildException(\"File \\\"\" +\n                                         file.getAbsolutePath()\n                                         + \"\\\" does not exist or is not readable.\");\n              }\n\n              boolean indexIt = true;\n\n              if (checkLastModified) {\n                Term pathTerm =\n                  new Term(\"path\", file.getPath());\n                TermQuery query =\n                  new TermQuery(pathTerm);\n                ScoreDoc[] hits = searcher.search(query, null, 1).scoreDocs;\n\n                // if document is found, compare the\n                // indexed last modified time with the\n                // current file\n                // - don't index if up to date\n                if (hits.length > 0) {\n                  Document doc = searcher.doc(hits[0].doc);\n                  String indexModified =\n                    doc.get(\"modified\").trim();\n                  if (indexModified != null) {\n                    long lastModified = 0;\n                    try {\n                      lastModified = DateTools.stringToTime(indexModified);\n                    } catch (ParseException e) {\n                      // if modified time is not parsable, skip\n                    }\n                    if (lastModified == file.lastModified()) {\n                      // TODO: remove existing document\n                      indexIt = false;\n                    }\n                  }\n                }\n              }\n\n              if (indexIt) {\n                try {\n                  log(\"Indexing \" + file.getPath(),\n                      Project.MSG_VERBOSE);\n                  Document doc =\n                    handler.getDocument(file);\n\n                  if (doc == null) {\n                    totalIgnored++;\n                  } else {\n                    // Add the path of the file as a field named \"path\".  Use a Keyword field, so\n                    // that the index stores the path, and so that the path is searchable\n                    doc.add(new Field(\"path\", file.getPath(), Field.Store.YES, Field.Index.NOT_ANALYZED));\n\n                    // Add the last modified date of the file a field named \"modified\".  Use a\n                    // Keyword field, so that it's searchable, but so that no attempt is made\n                    // to tokenize the field into words.\n                    doc.add(new Field(\"modified\", DateTools.timeToString(file.lastModified(), DateTools.Resolution.MILLISECOND), Field.Store.YES, Field.Index.NOT_ANALYZED));\n\n                    writer.addDocument(doc);\n                    totalIndexed++;\n                  }\n                } catch (DocumentHandlerException e) {\n                  throw new BuildException(e);\n                }\n              }\n            }\n            // for j\n          }\n          // if (fs != null)\n        }\n        // for i\n\n        writer.optimize();\n      }\n        //try\n      finally {\n        // always make sure everything gets closed,\n        // no matter how we exit.\n        writer.close();\n        if (searcher != null) {\n          searcher.close();\n        }\n      }\n\n      Date end = new Date();\n\n      log(totalIndexed + \" out of \" + totalFiles + \" indexed (\" +\n          totalIgnored + \" ignored) in \" + (end.getTime() - start.getTime()) +\n          \" milliseconds\");\n    } finally {\n      dir.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3a55c46ea262f9033bd9ab60542dea4b38abef33","date":1306109444,"type":4,"author":"Robert Muir","isMerge":false,"pathNew":"/dev/null","pathOld":"lucene/contrib/ant/src/java/org/apache/lucene/ant/IndexTask#indexDocs().mjava","sourceNew":null,"sourceOld":"  /**\n   * Index the fileset.\n   *\n   *@exception  IOException if Lucene I/O exception\n   *TODO: refactor!!!!!\n   */\n  private void indexDocs() throws IOException {\n    Date start = new Date();\n\n    boolean create = overwrite;\n    // If the index directory doesn't exist,\n    // create it and force create mode\n    if (indexDir.mkdirs() && !overwrite) {\n      create = true;\n    }\n\n    FSDirectory dir = FSDirectory.open(indexDir);\n    try {\n      IndexSearcher searcher = null;\n      boolean checkLastModified = false;\n      if (!create) {\n        try {\n          searcher = new IndexSearcher(dir, true);\n          checkLastModified = true;\n        } catch (IOException ioe) {\n          log(\"IOException: \" + ioe.getMessage());\n          // Empty - ignore, which indicates to index all\n          // documents\n        }\n      }\n\n      log(\"checkLastModified = \" + checkLastModified, Project.MSG_VERBOSE);\n\n      IndexWriterConfig conf = new IndexWriterConfig(\n          Version.LUCENE_CURRENT, analyzer).setOpenMode(\n          create ? OpenMode.CREATE : OpenMode.APPEND);\n      TieredMergePolicy tmp = (TieredMergePolicy) conf.getMergePolicy();\n      tmp.setUseCompoundFile(useCompoundIndex);\n      tmp.setMaxMergeAtOnce(mergeFactor);\n      IndexWriter writer = new IndexWriter(dir, conf);\n      int totalFiles = 0;\n      int totalIndexed = 0;\n      int totalIgnored = 0;\n      try {\n\n        for (int i = 0; i < rcs.size(); i++) {\n          ResourceCollection rc = rcs.elementAt(i);\n          if (rc.isFilesystemOnly()) {\n            Iterator resources = rc.iterator();\n            while (resources.hasNext()) {\n              Resource r = (Resource) resources.next();\n              if (!r.isExists() || !(r instanceof FileResource)) {\n                continue;\n              }\n              \n              totalFiles++;\n\n              File file = ((FileResource) r).getFile();\n              \n              if (!file.exists() || !file.canRead()) {\n                throw new BuildException(\"File \\\"\" +\n                                         file.getAbsolutePath()\n                                         + \"\\\" does not exist or is not readable.\");\n              }\n\n              boolean indexIt = true;\n\n              if (checkLastModified) {\n                Term pathTerm =\n                  new Term(\"path\", file.getPath());\n                TermQuery query =\n                  new TermQuery(pathTerm);\n                ScoreDoc[] hits = searcher.search(query, null, 1).scoreDocs;\n\n                // if document is found, compare the\n                // indexed last modified time with the\n                // current file\n                // - don't index if up to date\n                if (hits.length > 0) {\n                  Document doc = searcher.doc(hits[0].doc);\n                  String indexModified =\n                    doc.get(\"modified\").trim();\n                  if (indexModified != null) {\n                    long lastModified = 0;\n                    try {\n                      lastModified = DateTools.stringToTime(indexModified);\n                    } catch (ParseException e) {\n                      // if modified time is not parsable, skip\n                    }\n                    if (lastModified == file.lastModified()) {\n                      // TODO: remove existing document\n                      indexIt = false;\n                    }\n                  }\n                }\n              }\n\n              if (indexIt) {\n                try {\n                  log(\"Indexing \" + file.getPath(),\n                      Project.MSG_VERBOSE);\n                  Document doc =\n                    handler.getDocument(file);\n\n                  if (doc == null) {\n                    totalIgnored++;\n                  } else {\n                    // Add the path of the file as a field named \"path\".  Use a Keyword field, so\n                    // that the index stores the path, and so that the path is searchable\n                    doc.add(new Field(\"path\", file.getPath(), Field.Store.YES, Field.Index.NOT_ANALYZED));\n\n                    // Add the last modified date of the file a field named \"modified\".  Use a\n                    // Keyword field, so that it's searchable, but so that no attempt is made\n                    // to tokenize the field into words.\n                    doc.add(new Field(\"modified\", DateTools.timeToString(file.lastModified(), DateTools.Resolution.MILLISECOND), Field.Store.YES, Field.Index.NOT_ANALYZED));\n\n                    writer.addDocument(doc);\n                    totalIndexed++;\n                  }\n                } catch (DocumentHandlerException e) {\n                  throw new BuildException(e);\n                }\n              }\n            }\n            // for j\n          }\n          // if (fs != null)\n        }\n        // for i\n\n        writer.optimize();\n      }\n        //try\n      finally {\n        // always make sure everything gets closed,\n        // no matter how we exit.\n        writer.close();\n        if (searcher != null) {\n          searcher.close();\n        }\n      }\n\n      Date end = new Date();\n\n      log(totalIndexed + \" out of \" + totalFiles + \" indexed (\" +\n          totalIgnored + \" ignored) in \" + (end.getTime() - start.getTime()) +\n          \" milliseconds\");\n    } finally {\n      dir.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ae132b768aece5bf21cda14e2f17fba66eb6f7d6","date":1306128032,"type":4,"author":"Steven Rowe","isMerge":true,"pathNew":"/dev/null","pathOld":"lucene/contrib/ant/src/java/org/apache/lucene/ant/IndexTask#indexDocs().mjava","sourceNew":null,"sourceOld":"  /**\n   * Index the fileset.\n   *\n   *@exception  IOException if Lucene I/O exception\n   *TODO: refactor!!!!!\n   */\n  private void indexDocs() throws IOException {\n    Date start = new Date();\n\n    boolean create = overwrite;\n    // If the index directory doesn't exist,\n    // create it and force create mode\n    if (indexDir.mkdirs() && !overwrite) {\n      create = true;\n    }\n\n    FSDirectory dir = FSDirectory.open(indexDir);\n    try {\n      IndexSearcher searcher = null;\n      boolean checkLastModified = false;\n      if (!create) {\n        try {\n          searcher = new IndexSearcher(dir, true);\n          checkLastModified = true;\n        } catch (IOException ioe) {\n          log(\"IOException: \" + ioe.getMessage());\n          // Empty - ignore, which indicates to index all\n          // documents\n        }\n      }\n\n      log(\"checkLastModified = \" + checkLastModified, Project.MSG_VERBOSE);\n\n      IndexWriterConfig conf = new IndexWriterConfig(\n          Version.LUCENE_CURRENT, analyzer).setOpenMode(\n          create ? OpenMode.CREATE : OpenMode.APPEND);\n      TieredMergePolicy tmp = (TieredMergePolicy) conf.getMergePolicy();\n      tmp.setUseCompoundFile(useCompoundIndex);\n      tmp.setMaxMergeAtOnce(mergeFactor);\n      IndexWriter writer = new IndexWriter(dir, conf);\n      int totalFiles = 0;\n      int totalIndexed = 0;\n      int totalIgnored = 0;\n      try {\n\n        for (int i = 0; i < rcs.size(); i++) {\n          ResourceCollection rc = rcs.elementAt(i);\n          if (rc.isFilesystemOnly()) {\n            Iterator resources = rc.iterator();\n            while (resources.hasNext()) {\n              Resource r = (Resource) resources.next();\n              if (!r.isExists() || !(r instanceof FileResource)) {\n                continue;\n              }\n              \n              totalFiles++;\n\n              File file = ((FileResource) r).getFile();\n              \n              if (!file.exists() || !file.canRead()) {\n                throw new BuildException(\"File \\\"\" +\n                                         file.getAbsolutePath()\n                                         + \"\\\" does not exist or is not readable.\");\n              }\n\n              boolean indexIt = true;\n\n              if (checkLastModified) {\n                Term pathTerm =\n                  new Term(\"path\", file.getPath());\n                TermQuery query =\n                  new TermQuery(pathTerm);\n                ScoreDoc[] hits = searcher.search(query, null, 1).scoreDocs;\n\n                // if document is found, compare the\n                // indexed last modified time with the\n                // current file\n                // - don't index if up to date\n                if (hits.length > 0) {\n                  Document doc = searcher.doc(hits[0].doc);\n                  String indexModified =\n                    doc.get(\"modified\").trim();\n                  if (indexModified != null) {\n                    long lastModified = 0;\n                    try {\n                      lastModified = DateTools.stringToTime(indexModified);\n                    } catch (ParseException e) {\n                      // if modified time is not parsable, skip\n                    }\n                    if (lastModified == file.lastModified()) {\n                      // TODO: remove existing document\n                      indexIt = false;\n                    }\n                  }\n                }\n              }\n\n              if (indexIt) {\n                try {\n                  log(\"Indexing \" + file.getPath(),\n                      Project.MSG_VERBOSE);\n                  Document doc =\n                    handler.getDocument(file);\n\n                  if (doc == null) {\n                    totalIgnored++;\n                  } else {\n                    // Add the path of the file as a field named \"path\".  Use a Keyword field, so\n                    // that the index stores the path, and so that the path is searchable\n                    doc.add(new Field(\"path\", file.getPath(), Field.Store.YES, Field.Index.NOT_ANALYZED));\n\n                    // Add the last modified date of the file a field named \"modified\".  Use a\n                    // Keyword field, so that it's searchable, but so that no attempt is made\n                    // to tokenize the field into words.\n                    doc.add(new Field(\"modified\", DateTools.timeToString(file.lastModified(), DateTools.Resolution.MILLISECOND), Field.Store.YES, Field.Index.NOT_ANALYZED));\n\n                    writer.addDocument(doc);\n                    totalIndexed++;\n                  }\n                } catch (DocumentHandlerException e) {\n                  throw new BuildException(e);\n                }\n              }\n            }\n            // for j\n          }\n          // if (fs != null)\n        }\n        // for i\n\n        writer.optimize();\n      }\n        //try\n      finally {\n        // always make sure everything gets closed,\n        // no matter how we exit.\n        writer.close();\n        if (searcher != null) {\n          searcher.close();\n        }\n      }\n\n      Date end = new Date();\n\n      log(totalIndexed + \" out of \" + totalFiles + \" indexed (\" +\n          totalIgnored + \" ignored) in \" + (end.getTime() - start.getTime()) +\n          \" milliseconds\");\n    } finally {\n      dir.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5c698c0cb88bac4bcd36a1b1001a0c6a2163ea2a","date":1306150983,"type":4,"author":"Simon Willnauer","isMerge":true,"pathNew":"/dev/null","pathOld":"lucene/contrib/ant/src/java/org/apache/lucene/ant/IndexTask#indexDocs().mjava","sourceNew":null,"sourceOld":"  /**\n   * Index the fileset.\n   *\n   *@exception  IOException if Lucene I/O exception\n   *TODO: refactor!!!!!\n   */\n  private void indexDocs() throws IOException {\n    Date start = new Date();\n\n    boolean create = overwrite;\n    // If the index directory doesn't exist,\n    // create it and force create mode\n    if (indexDir.mkdirs() && !overwrite) {\n      create = true;\n    }\n\n    FSDirectory dir = FSDirectory.open(indexDir);\n    try {\n      IndexSearcher searcher = null;\n      boolean checkLastModified = false;\n      if (!create) {\n        try {\n          searcher = new IndexSearcher(dir, true);\n          checkLastModified = true;\n        } catch (IOException ioe) {\n          log(\"IOException: \" + ioe.getMessage());\n          // Empty - ignore, which indicates to index all\n          // documents\n        }\n      }\n\n      log(\"checkLastModified = \" + checkLastModified, Project.MSG_VERBOSE);\n\n      IndexWriterConfig conf = new IndexWriterConfig(\n          Version.LUCENE_CURRENT, analyzer).setOpenMode(\n          create ? OpenMode.CREATE : OpenMode.APPEND);\n      TieredMergePolicy tmp = (TieredMergePolicy) conf.getMergePolicy();\n      tmp.setUseCompoundFile(useCompoundIndex);\n      tmp.setMaxMergeAtOnce(mergeFactor);\n      IndexWriter writer = new IndexWriter(dir, conf);\n      int totalFiles = 0;\n      int totalIndexed = 0;\n      int totalIgnored = 0;\n      try {\n\n        for (int i = 0; i < rcs.size(); i++) {\n          ResourceCollection rc = rcs.elementAt(i);\n          if (rc.isFilesystemOnly()) {\n            Iterator resources = rc.iterator();\n            while (resources.hasNext()) {\n              Resource r = (Resource) resources.next();\n              if (!r.isExists() || !(r instanceof FileResource)) {\n                continue;\n              }\n              \n              totalFiles++;\n\n              File file = ((FileResource) r).getFile();\n              \n              if (!file.exists() || !file.canRead()) {\n                throw new BuildException(\"File \\\"\" +\n                                         file.getAbsolutePath()\n                                         + \"\\\" does not exist or is not readable.\");\n              }\n\n              boolean indexIt = true;\n\n              if (checkLastModified) {\n                Term pathTerm =\n                  new Term(\"path\", file.getPath());\n                TermQuery query =\n                  new TermQuery(pathTerm);\n                ScoreDoc[] hits = searcher.search(query, null, 1).scoreDocs;\n\n                // if document is found, compare the\n                // indexed last modified time with the\n                // current file\n                // - don't index if up to date\n                if (hits.length > 0) {\n                  Document doc = searcher.doc(hits[0].doc);\n                  String indexModified =\n                    doc.get(\"modified\").trim();\n                  if (indexModified != null) {\n                    long lastModified = 0;\n                    try {\n                      lastModified = DateTools.stringToTime(indexModified);\n                    } catch (ParseException e) {\n                      // if modified time is not parsable, skip\n                    }\n                    if (lastModified == file.lastModified()) {\n                      // TODO: remove existing document\n                      indexIt = false;\n                    }\n                  }\n                }\n              }\n\n              if (indexIt) {\n                try {\n                  log(\"Indexing \" + file.getPath(),\n                      Project.MSG_VERBOSE);\n                  Document doc =\n                    handler.getDocument(file);\n\n                  if (doc == null) {\n                    totalIgnored++;\n                  } else {\n                    // Add the path of the file as a field named \"path\".  Use a Keyword field, so\n                    // that the index stores the path, and so that the path is searchable\n                    doc.add(new Field(\"path\", file.getPath(), Field.Store.YES, Field.Index.NOT_ANALYZED));\n\n                    // Add the last modified date of the file a field named \"modified\".  Use a\n                    // Keyword field, so that it's searchable, but so that no attempt is made\n                    // to tokenize the field into words.\n                    doc.add(new Field(\"modified\", DateTools.timeToString(file.lastModified(), DateTools.Resolution.MILLISECOND), Field.Store.YES, Field.Index.NOT_ANALYZED));\n\n                    writer.addDocument(doc);\n                    totalIndexed++;\n                  }\n                } catch (DocumentHandlerException e) {\n                  throw new BuildException(e);\n                }\n              }\n            }\n            // for j\n          }\n          // if (fs != null)\n        }\n        // for i\n\n        writer.optimize();\n      }\n        //try\n      finally {\n        // always make sure everything gets closed,\n        // no matter how we exit.\n        writer.close();\n        if (searcher != null) {\n          searcher.close();\n        }\n      }\n\n      Date end = new Date();\n\n      log(totalIndexed + \" out of \" + totalFiles + \" indexed (\" +\n          totalIgnored + \" ignored) in \" + (end.getTime() - start.getTime()) +\n          \" milliseconds\");\n    } finally {\n      dir.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"70ad682703b8585f5d0a637efec044d57ec05efb":["ab5cb6a74aefb78aa0569857970b9151dfe2e787","8b241ea5e635d896cc0af83cd96ffd0322e0aba7"],"ae132b768aece5bf21cda14e2f17fba66eb6f7d6":["a3776dccca01c11e7046323cfad46a3b4a471233","3a55c46ea262f9033bd9ab60542dea4b38abef33"],"5c698c0cb88bac4bcd36a1b1001a0c6a2163ea2a":["135621f3a0670a9394eb563224a3b76cc4dddc0f","3a55c46ea262f9033bd9ab60542dea4b38abef33"],"7ab99e8c71442b92c320e218141dee04a9b91ce8":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"135621f3a0670a9394eb563224a3b76cc4dddc0f":["70ad682703b8585f5d0a637efec044d57ec05efb","01e5948db9a07144112d2f08f28ca2e3cd880348"],"ab5cb6a74aefb78aa0569857970b9151dfe2e787":["7ab99e8c71442b92c320e218141dee04a9b91ce8","4948bc5d29211f0c9b5ccc31b2632cdd27066ea5"],"8dc26bfa5ebbc55b5a04fbec545dfcec647b046b":["7ab99e8c71442b92c320e218141dee04a9b91ce8"],"01e5948db9a07144112d2f08f28ca2e3cd880348":["8b241ea5e635d896cc0af83cd96ffd0322e0aba7"],"8b241ea5e635d896cc0af83cd96ffd0322e0aba7":["4948bc5d29211f0c9b5ccc31b2632cdd27066ea5"],"a3776dccca01c11e7046323cfad46a3b4a471233":["8b241ea5e635d896cc0af83cd96ffd0322e0aba7","01e5948db9a07144112d2f08f28ca2e3cd880348"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"3a55c46ea262f9033bd9ab60542dea4b38abef33":["01e5948db9a07144112d2f08f28ca2e3cd880348"],"4948bc5d29211f0c9b5ccc31b2632cdd27066ea5":["7ab99e8c71442b92c320e218141dee04a9b91ce8"],"868da859b43505d9d2a023bfeae6dd0c795f5295":["8dc26bfa5ebbc55b5a04fbec545dfcec647b046b","8b241ea5e635d896cc0af83cd96ffd0322e0aba7"],"45669a651c970812a680841b97a77cce06af559f":["868da859b43505d9d2a023bfeae6dd0c795f5295","01e5948db9a07144112d2f08f28ca2e3cd880348"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["3a55c46ea262f9033bd9ab60542dea4b38abef33"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"70ad682703b8585f5d0a637efec044d57ec05efb":["135621f3a0670a9394eb563224a3b76cc4dddc0f"],"ae132b768aece5bf21cda14e2f17fba66eb6f7d6":[],"5c698c0cb88bac4bcd36a1b1001a0c6a2163ea2a":[],"7ab99e8c71442b92c320e218141dee04a9b91ce8":["ab5cb6a74aefb78aa0569857970b9151dfe2e787","8dc26bfa5ebbc55b5a04fbec545dfcec647b046b","4948bc5d29211f0c9b5ccc31b2632cdd27066ea5"],"135621f3a0670a9394eb563224a3b76cc4dddc0f":["5c698c0cb88bac4bcd36a1b1001a0c6a2163ea2a"],"ab5cb6a74aefb78aa0569857970b9151dfe2e787":["70ad682703b8585f5d0a637efec044d57ec05efb"],"8dc26bfa5ebbc55b5a04fbec545dfcec647b046b":["868da859b43505d9d2a023bfeae6dd0c795f5295"],"01e5948db9a07144112d2f08f28ca2e3cd880348":["135621f3a0670a9394eb563224a3b76cc4dddc0f","a3776dccca01c11e7046323cfad46a3b4a471233","3a55c46ea262f9033bd9ab60542dea4b38abef33","45669a651c970812a680841b97a77cce06af559f"],"8b241ea5e635d896cc0af83cd96ffd0322e0aba7":["70ad682703b8585f5d0a637efec044d57ec05efb","01e5948db9a07144112d2f08f28ca2e3cd880348","a3776dccca01c11e7046323cfad46a3b4a471233","868da859b43505d9d2a023bfeae6dd0c795f5295"],"a3776dccca01c11e7046323cfad46a3b4a471233":["ae132b768aece5bf21cda14e2f17fba66eb6f7d6"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"3a55c46ea262f9033bd9ab60542dea4b38abef33":["ae132b768aece5bf21cda14e2f17fba66eb6f7d6","5c698c0cb88bac4bcd36a1b1001a0c6a2163ea2a","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"4948bc5d29211f0c9b5ccc31b2632cdd27066ea5":["ab5cb6a74aefb78aa0569857970b9151dfe2e787","8b241ea5e635d896cc0af83cd96ffd0322e0aba7"],"868da859b43505d9d2a023bfeae6dd0c795f5295":["45669a651c970812a680841b97a77cce06af559f"],"45669a651c970812a680841b97a77cce06af559f":[],"9454a6510e2db155fb01faa5c049b06ece95fab9":["7ab99e8c71442b92c320e218141dee04a9b91ce8"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["ae132b768aece5bf21cda14e2f17fba66eb6f7d6","5c698c0cb88bac4bcd36a1b1001a0c6a2163ea2a","45669a651c970812a680841b97a77cce06af559f","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}