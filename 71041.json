{"path":"lucene/contrib/misc/src/java/org/apache/lucene/misc/HighFreqTerms#getTotalTermFreq(IndexReader,String,BytesRef).mjava","commits":[{"id":"1513361122ebc5ddd6075f633cd77d2345611767","date":1273770174,"type":0,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/contrib/misc/src/java/org/apache/lucene/misc/HighFreqTerms#getTotalTermFreq(IndexReader,String,BytesRef).mjava","pathOld":"/dev/null","sourceNew":"  public static long getTotalTermFreq(IndexReader reader, String field, BytesRef termtext) throws Exception {\n    BytesRef br = termtext;\n    long totalTF = 0;\n    Bits skipDocs = MultiFields.getDeletedDocs(reader);\n    DocsEnum de = MultiFields.getTermDocsEnum(reader, skipDocs, field, br);\n    // if term is not in index return totalTF of 0\n    if (de == null) {\n      return 0;\n    }\n    // use DocsEnum.read() and BulkResult api\n    final DocsEnum.BulkReadResult bulkresult = de.getBulkResult();\n    int count;\n    while ((count = de.read()) != 0) {\n      final int[] freqs = bulkresult.freqs.ints;\n      final int limit = bulkresult.freqs.offset + count;\n      for(int i=bulkresult.freqs.offset;i<limit;i++) {\n        totalTF += freqs[i];\n      }\n    }\n    return totalTF;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6ecd298fdc085e7eba27afa7fae58df1ba1a2808","date":1295102557,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/contrib/misc/src/java/org/apache/lucene/misc/HighFreqTerms#getTotalTermFreq(IndexReader,String,BytesRef).mjava","pathOld":"lucene/contrib/misc/src/java/org/apache/lucene/misc/HighFreqTerms#getTotalTermFreq(IndexReader,String,BytesRef).mjava","sourceNew":"  public static long getTotalTermFreq(IndexReader reader, String field, BytesRef termText) throws Exception {\n\n    long totalTF = 0;\n    \n    Terms terms = MultiFields.getTerms(reader, field);\n    if (terms == null) {\n      return 0;\n    }\n\n    TermsEnum termsEnum = terms.iterator();\n    if (termsEnum.seek(termText) != TermsEnum.SeekStatus.FOUND) {\n      return 0;\n    }\n\n    Bits skipDocs = MultiFields.getDeletedDocs(reader);\n    if (skipDocs == null) {\n      // TODO: we could do this up front, during the scan\n      // (next()), instead of after-the-fact here w/ seek,\n      // if the codec supports it and there are no del\n      // docs...\n      final long totTF = termsEnum.totalTermFreq();\n      if (totTF != -1) {\n        return totTF;\n      }\n    }\n    \n    DocsEnum de = termsEnum.docs(skipDocs, null);\n\n    // use DocsEnum.read() and BulkResult api\n    final DocsEnum.BulkReadResult bulkresult = de.getBulkResult();\n    int count;\n    while ((count = de.read()) != 0) {\n      final int[] freqs = bulkresult.freqs.ints;\n      final int limit = bulkresult.freqs.offset + count;\n      for(int i=bulkresult.freqs.offset;i<limit;i++) {\n        totalTF += freqs[i];\n      }\n    }\n    return totalTF;\n  }\n\n","sourceOld":"  public static long getTotalTermFreq(IndexReader reader, String field, BytesRef termtext) throws Exception {\n    BytesRef br = termtext;\n    long totalTF = 0;\n    Bits skipDocs = MultiFields.getDeletedDocs(reader);\n    DocsEnum de = MultiFields.getTermDocsEnum(reader, skipDocs, field, br);\n    // if term is not in index return totalTF of 0\n    if (de == null) {\n      return 0;\n    }\n    // use DocsEnum.read() and BulkResult api\n    final DocsEnum.BulkReadResult bulkresult = de.getBulkResult();\n    int count;\n    while ((count = de.read()) != 0) {\n      final int[] freqs = bulkresult.freqs.ints;\n      final int limit = bulkresult.freqs.offset + count;\n      for(int i=bulkresult.freqs.offset;i<limit;i++) {\n        totalTF += freqs[i];\n      }\n    }\n    return totalTF;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"16843358872ed92ba92888ab99df297550b9a36a","date":1295144724,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/contrib/misc/src/java/org/apache/lucene/misc/HighFreqTerms#getTotalTermFreq(IndexReader,String,BytesRef).mjava","pathOld":"lucene/contrib/misc/src/java/org/apache/lucene/misc/HighFreqTerms#getTotalTermFreq(IndexReader,String,BytesRef).mjava","sourceNew":"  public static long getTotalTermFreq(IndexReader reader, String field, BytesRef termText) throws Exception {\n\n    long totalTF = 0;\n    \n    Terms terms = MultiFields.getTerms(reader, field);\n    if (terms == null) {\n      return 0;\n    }\n\n    TermsEnum termsEnum = terms.iterator();\n    if (termsEnum.seek(termText) != TermsEnum.SeekStatus.FOUND) {\n      return 0;\n    }\n\n    Bits skipDocs = MultiFields.getDeletedDocs(reader);\n    if (skipDocs == null) {\n      // TODO: we could do this up front, during the scan\n      // (next()), instead of after-the-fact here w/ seek,\n      // if the codec supports it and there are no del\n      // docs...\n      final long totTF = termsEnum.totalTermFreq();\n      if (totTF != -1) {\n        return totTF;\n      }\n    }\n    \n    DocsEnum de = termsEnum.docs(skipDocs, null);\n\n    // use DocsEnum.read() and BulkResult api\n    final DocsEnum.BulkReadResult bulkresult = de.getBulkResult();\n    int count;\n    while ((count = de.read()) != 0) {\n      final int[] freqs = bulkresult.freqs.ints;\n      final int limit = bulkresult.freqs.offset + count;\n      for(int i=bulkresult.freqs.offset;i<limit;i++) {\n        totalTF += freqs[i];\n      }\n    }\n    return totalTF;\n  }\n\n","sourceOld":"  public static long getTotalTermFreq(IndexReader reader, String field, BytesRef termtext) throws Exception {\n    BytesRef br = termtext;\n    long totalTF = 0;\n    Bits skipDocs = MultiFields.getDeletedDocs(reader);\n    DocsEnum de = MultiFields.getTermDocsEnum(reader, skipDocs, field, br);\n    // if term is not in index return totalTF of 0\n    if (de == null) {\n      return 0;\n    }\n    // use DocsEnum.read() and BulkResult api\n    final DocsEnum.BulkReadResult bulkresult = de.getBulkResult();\n    int count;\n    while ((count = de.read()) != 0) {\n      final int[] freqs = bulkresult.freqs.ints;\n      final int limit = bulkresult.freqs.offset + count;\n      for(int i=bulkresult.freqs.offset;i<limit;i++) {\n        totalTF += freqs[i];\n      }\n    }\n    return totalTF;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"29ef99d61cda9641b6250bf9567329a6e65f901d","date":1297244127,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/contrib/misc/src/java/org/apache/lucene/misc/HighFreqTerms#getTotalTermFreq(IndexReader,String,BytesRef).mjava","pathOld":"lucene/contrib/misc/src/java/org/apache/lucene/misc/HighFreqTerms#getTotalTermFreq(IndexReader,String,BytesRef).mjava","sourceNew":"  public static long getTotalTermFreq(IndexReader reader, String field, BytesRef termText) throws Exception {\n\n    long totalTF = 0;\n    \n    Terms terms = MultiFields.getTerms(reader, field);\n    if (terms == null) {\n      return 0;\n    }\n\n    TermsEnum termsEnum = terms.iterator();\n    if (termsEnum.seek(termText) != TermsEnum.SeekStatus.FOUND) {\n      return 0;\n    }\n\n    Bits skipDocs = MultiFields.getDeletedDocs(reader);\n    if (skipDocs == null) {\n      // TODO: we could do this up front, during the scan\n      // (next()), instead of after-the-fact here w/ seek,\n      // if the codec supports it and there are no del\n      // docs...\n      final long totTF = termsEnum.totalTermFreq();\n      if (totTF != -1) {\n        return totTF;\n      }\n    }\n    \n    DocsEnum de = termsEnum.docs(skipDocs, null);\n\n    // use DocsEnum.read() and BulkResult api\n    final DocsEnum.BulkReadResult bulkresult = de.getBulkResult();\n    int count;\n    while ((count = de.read()) != 0) {\n      final int[] freqs = bulkresult.freqs.ints;\n      final int limit = bulkresult.freqs.offset + count;\n      for(int i=bulkresult.freqs.offset;i<limit;i++) {\n        totalTF += freqs[i];\n      }\n    }\n    return totalTF;\n  }\n\n","sourceOld":"  public static long getTotalTermFreq(IndexReader reader, String field, BytesRef termtext) throws Exception {\n    BytesRef br = termtext;\n    long totalTF = 0;\n    Bits skipDocs = MultiFields.getDeletedDocs(reader);\n    DocsEnum de = MultiFields.getTermDocsEnum(reader, skipDocs, field, br);\n    // if term is not in index return totalTF of 0\n    if (de == null) {\n      return 0;\n    }\n    // use DocsEnum.read() and BulkResult api\n    final DocsEnum.BulkReadResult bulkresult = de.getBulkResult();\n    int count;\n    while ((count = de.read()) != 0) {\n      final int[] freqs = bulkresult.freqs.ints;\n      final int limit = bulkresult.freqs.offset + count;\n      for(int i=bulkresult.freqs.offset;i<limit;i++) {\n        totalTF += freqs[i];\n      }\n    }\n    return totalTF;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fd9cc9d77712aba3662f24632df7539ab75e3667","date":1309095238,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/contrib/misc/src/java/org/apache/lucene/misc/HighFreqTerms#getTotalTermFreq(IndexReader,String,BytesRef).mjava","pathOld":"lucene/contrib/misc/src/java/org/apache/lucene/misc/HighFreqTerms#getTotalTermFreq(IndexReader,String,BytesRef).mjava","sourceNew":"  public static long getTotalTermFreq(IndexReader reader, String field, BytesRef termText) throws Exception {\n\n    long totalTF = 0;\n    \n    Terms terms = MultiFields.getTerms(reader, field);\n    if (terms == null) {\n      return 0;\n    }\n\n    TermsEnum termsEnum = terms.iterator();\n    if (termsEnum.seekCeil(termText) != TermsEnum.SeekStatus.FOUND) {\n      return 0;\n    }\n\n    Bits skipDocs = MultiFields.getDeletedDocs(reader);\n    if (skipDocs == null) {\n      // TODO: we could do this up front, during the scan\n      // (next()), instead of after-the-fact here w/ seek,\n      // if the codec supports it and there are no del\n      // docs...\n      final long totTF = termsEnum.totalTermFreq();\n      if (totTF != -1) {\n        return totTF;\n      }\n    }\n    \n    DocsEnum de = termsEnum.docs(skipDocs, null);\n\n    // use DocsEnum.read() and BulkResult api\n    final DocsEnum.BulkReadResult bulkresult = de.getBulkResult();\n    int count;\n    while ((count = de.read()) != 0) {\n      final int[] freqs = bulkresult.freqs.ints;\n      final int limit = bulkresult.freqs.offset + count;\n      for(int i=bulkresult.freqs.offset;i<limit;i++) {\n        totalTF += freqs[i];\n      }\n    }\n    return totalTF;\n  }\n\n","sourceOld":"  public static long getTotalTermFreq(IndexReader reader, String field, BytesRef termText) throws Exception {\n\n    long totalTF = 0;\n    \n    Terms terms = MultiFields.getTerms(reader, field);\n    if (terms == null) {\n      return 0;\n    }\n\n    TermsEnum termsEnum = terms.iterator();\n    if (termsEnum.seek(termText) != TermsEnum.SeekStatus.FOUND) {\n      return 0;\n    }\n\n    Bits skipDocs = MultiFields.getDeletedDocs(reader);\n    if (skipDocs == null) {\n      // TODO: we could do this up front, during the scan\n      // (next()), instead of after-the-fact here w/ seek,\n      // if the codec supports it and there are no del\n      // docs...\n      final long totTF = termsEnum.totalTermFreq();\n      if (totTF != -1) {\n        return totTF;\n      }\n    }\n    \n    DocsEnum de = termsEnum.docs(skipDocs, null);\n\n    // use DocsEnum.read() and BulkResult api\n    final DocsEnum.BulkReadResult bulkresult = de.getBulkResult();\n    int count;\n    while ((count = de.read()) != 0) {\n      final int[] freqs = bulkresult.freqs.ints;\n      final int limit = bulkresult.freqs.offset + count;\n      for(int i=bulkresult.freqs.offset;i<limit;i++) {\n        totalTF += freqs[i];\n      }\n    }\n    return totalTF;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2553b00f699380c64959ccb27991289aae87be2e","date":1309290151,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/contrib/misc/src/java/org/apache/lucene/misc/HighFreqTerms#getTotalTermFreq(IndexReader,String,BytesRef).mjava","pathOld":"lucene/contrib/misc/src/java/org/apache/lucene/misc/HighFreqTerms#getTotalTermFreq(IndexReader,String,BytesRef).mjava","sourceNew":"  public static long getTotalTermFreq(IndexReader reader, String field, BytesRef termText) throws Exception {\n\n    long totalTF = 0;\n    \n    Terms terms = MultiFields.getTerms(reader, field);\n    if (terms == null) {\n      return 0;\n    }\n\n    TermsEnum termsEnum = terms.iterator();\n    if (termsEnum.seekCeil(termText) != TermsEnum.SeekStatus.FOUND) {\n      return 0;\n    }\n\n    Bits skipDocs = MultiFields.getDeletedDocs(reader);\n    if (skipDocs == null) {\n      // TODO: we could do this up front, during the scan\n      // (next()), instead of after-the-fact here w/ seek,\n      // if the codec supports it and there are no del\n      // docs...\n      final long totTF = termsEnum.totalTermFreq();\n      if (totTF != -1) {\n        return totTF;\n      }\n    }\n    \n    DocsEnum de = termsEnum.docs(skipDocs, null);\n\n    // use DocsEnum.read() and BulkResult api\n    final DocsEnum.BulkReadResult bulkresult = de.getBulkResult();\n    int count;\n    while ((count = de.read()) != 0) {\n      final int[] freqs = bulkresult.freqs.ints;\n      final int limit = bulkresult.freqs.offset + count;\n      for(int i=bulkresult.freqs.offset;i<limit;i++) {\n        totalTF += freqs[i];\n      }\n    }\n    return totalTF;\n  }\n\n","sourceOld":"  public static long getTotalTermFreq(IndexReader reader, String field, BytesRef termText) throws Exception {\n\n    long totalTF = 0;\n    \n    Terms terms = MultiFields.getTerms(reader, field);\n    if (terms == null) {\n      return 0;\n    }\n\n    TermsEnum termsEnum = terms.iterator();\n    if (termsEnum.seek(termText) != TermsEnum.SeekStatus.FOUND) {\n      return 0;\n    }\n\n    Bits skipDocs = MultiFields.getDeletedDocs(reader);\n    if (skipDocs == null) {\n      // TODO: we could do this up front, during the scan\n      // (next()), instead of after-the-fact here w/ seek,\n      // if the codec supports it and there are no del\n      // docs...\n      final long totTF = termsEnum.totalTermFreq();\n      if (totTF != -1) {\n        return totTF;\n      }\n    }\n    \n    DocsEnum de = termsEnum.docs(skipDocs, null);\n\n    // use DocsEnum.read() and BulkResult api\n    final DocsEnum.BulkReadResult bulkresult = de.getBulkResult();\n    int count;\n    while ((count = de.read()) != 0) {\n      final int[] freqs = bulkresult.freqs.ints;\n      final int limit = bulkresult.freqs.offset + count;\n      for(int i=bulkresult.freqs.offset;i<limit;i++) {\n        totalTF += freqs[i];\n      }\n    }\n    return totalTF;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e7bd246bb7bc35ac22edfee9157e034dfc4e65eb","date":1309960478,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/contrib/misc/src/java/org/apache/lucene/misc/HighFreqTerms#getTotalTermFreq(IndexReader,String,BytesRef).mjava","pathOld":"lucene/contrib/misc/src/java/org/apache/lucene/misc/HighFreqTerms#getTotalTermFreq(IndexReader,String,BytesRef).mjava","sourceNew":"  public static long getTotalTermFreq(IndexReader reader, String field, BytesRef termText) throws Exception {\n\n    long totalTF = 0;\n    \n    Terms terms = MultiFields.getTerms(reader, field);\n    if (terms == null) {\n      return 0;\n    }\n\n    TermsEnum termsEnum = terms.iterator();\n    if (termsEnum.seekCeil(termText) != TermsEnum.SeekStatus.FOUND) {\n      return 0;\n    }\n\n    Bits liveDocs = MultiFields.getLiveDocs(reader);\n    if (liveDocs == null) {\n      // TODO: we could do this up front, during the scan\n      // (next()), instead of after-the-fact here w/ seek,\n      // if the codec supports it and there are no del\n      // docs...\n      final long totTF = termsEnum.totalTermFreq();\n      if (totTF != -1) {\n        return totTF;\n      }\n    }\n    \n    DocsEnum de = termsEnum.docs(liveDocs, null);\n\n    // use DocsEnum.read() and BulkResult api\n    final DocsEnum.BulkReadResult bulkresult = de.getBulkResult();\n    int count;\n    while ((count = de.read()) != 0) {\n      final int[] freqs = bulkresult.freqs.ints;\n      final int limit = bulkresult.freqs.offset + count;\n      for(int i=bulkresult.freqs.offset;i<limit;i++) {\n        totalTF += freqs[i];\n      }\n    }\n    return totalTF;\n  }\n\n","sourceOld":"  public static long getTotalTermFreq(IndexReader reader, String field, BytesRef termText) throws Exception {\n\n    long totalTF = 0;\n    \n    Terms terms = MultiFields.getTerms(reader, field);\n    if (terms == null) {\n      return 0;\n    }\n\n    TermsEnum termsEnum = terms.iterator();\n    if (termsEnum.seekCeil(termText) != TermsEnum.SeekStatus.FOUND) {\n      return 0;\n    }\n\n    Bits skipDocs = MultiFields.getDeletedDocs(reader);\n    if (skipDocs == null) {\n      // TODO: we could do this up front, during the scan\n      // (next()), instead of after-the-fact here w/ seek,\n      // if the codec supports it and there are no del\n      // docs...\n      final long totTF = termsEnum.totalTermFreq();\n      if (totTF != -1) {\n        return totTF;\n      }\n    }\n    \n    DocsEnum de = termsEnum.docs(skipDocs, null);\n\n    // use DocsEnum.read() and BulkResult api\n    final DocsEnum.BulkReadResult bulkresult = de.getBulkResult();\n    int count;\n    while ((count = de.read()) != 0) {\n      final int[] freqs = bulkresult.freqs.ints;\n      final int limit = bulkresult.freqs.offset + count;\n      for(int i=bulkresult.freqs.offset;i<limit;i++) {\n        totalTF += freqs[i];\n      }\n    }\n    return totalTF;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"817d8435e9135b756f08ce6710ab0baac51bdf88","date":1309986993,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/contrib/misc/src/java/org/apache/lucene/misc/HighFreqTerms#getTotalTermFreq(IndexReader,String,BytesRef).mjava","pathOld":"lucene/contrib/misc/src/java/org/apache/lucene/misc/HighFreqTerms#getTotalTermFreq(IndexReader,String,BytesRef).mjava","sourceNew":"  public static long getTotalTermFreq(IndexReader reader, String field, BytesRef termText) throws Exception {\n\n    long totalTF = 0;\n    \n    Terms terms = MultiFields.getTerms(reader, field);\n    if (terms == null) {\n      return 0;\n    }\n\n    TermsEnum termsEnum = terms.iterator();\n    if (termsEnum.seekCeil(termText) != TermsEnum.SeekStatus.FOUND) {\n      return 0;\n    }\n\n    Bits liveDocs = MultiFields.getLiveDocs(reader);\n    if (liveDocs == null) {\n      // TODO: we could do this up front, during the scan\n      // (next()), instead of after-the-fact here w/ seek,\n      // if the codec supports it and there are no del\n      // docs...\n      final long totTF = termsEnum.totalTermFreq();\n      if (totTF != -1) {\n        return totTF;\n      }\n    }\n    \n    DocsEnum de = termsEnum.docs(liveDocs, null);\n\n    // use DocsEnum.read() and BulkResult api\n    final DocsEnum.BulkReadResult bulkresult = de.getBulkResult();\n    int count;\n    while ((count = de.read()) != 0) {\n      final int[] freqs = bulkresult.freqs.ints;\n      final int limit = bulkresult.freqs.offset + count;\n      for(int i=bulkresult.freqs.offset;i<limit;i++) {\n        totalTF += freqs[i];\n      }\n    }\n    return totalTF;\n  }\n\n","sourceOld":"  public static long getTotalTermFreq(IndexReader reader, String field, BytesRef termText) throws Exception {\n\n    long totalTF = 0;\n    \n    Terms terms = MultiFields.getTerms(reader, field);\n    if (terms == null) {\n      return 0;\n    }\n\n    TermsEnum termsEnum = terms.iterator();\n    if (termsEnum.seekCeil(termText) != TermsEnum.SeekStatus.FOUND) {\n      return 0;\n    }\n\n    Bits skipDocs = MultiFields.getDeletedDocs(reader);\n    if (skipDocs == null) {\n      // TODO: we could do this up front, during the scan\n      // (next()), instead of after-the-fact here w/ seek,\n      // if the codec supports it and there are no del\n      // docs...\n      final long totTF = termsEnum.totalTermFreq();\n      if (totTF != -1) {\n        return totTF;\n      }\n    }\n    \n    DocsEnum de = termsEnum.docs(skipDocs, null);\n\n    // use DocsEnum.read() and BulkResult api\n    final DocsEnum.BulkReadResult bulkresult = de.getBulkResult();\n    int count;\n    while ((count = de.read()) != 0) {\n      final int[] freqs = bulkresult.freqs.ints;\n      final int limit = bulkresult.freqs.offset + count;\n      for(int i=bulkresult.freqs.offset;i<limit;i++) {\n        totalTF += freqs[i];\n      }\n    }\n    return totalTF;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d083e83f225b11e5fdd900e83d26ddb385b6955c","date":1310029438,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/contrib/misc/src/java/org/apache/lucene/misc/HighFreqTerms#getTotalTermFreq(IndexReader,String,BytesRef).mjava","pathOld":"lucene/contrib/misc/src/java/org/apache/lucene/misc/HighFreqTerms#getTotalTermFreq(IndexReader,String,BytesRef).mjava","sourceNew":"  public static long getTotalTermFreq(IndexReader reader, String field, BytesRef termText) throws Exception {\n\n    long totalTF = 0;\n    \n    Terms terms = MultiFields.getTerms(reader, field);\n    if (terms == null) {\n      return 0;\n    }\n\n    TermsEnum termsEnum = terms.iterator();\n    if (termsEnum.seekCeil(termText) != TermsEnum.SeekStatus.FOUND) {\n      return 0;\n    }\n\n    Bits liveDocs = MultiFields.getLiveDocs(reader);\n    if (liveDocs == null) {\n      // TODO: we could do this up front, during the scan\n      // (next()), instead of after-the-fact here w/ seek,\n      // if the codec supports it and there are no del\n      // docs...\n      final long totTF = termsEnum.totalTermFreq();\n      if (totTF != -1) {\n        return totTF;\n      }\n    }\n    \n    DocsEnum de = termsEnum.docs(liveDocs, null);\n\n    // use DocsEnum.read() and BulkResult api\n    final DocsEnum.BulkReadResult bulkresult = de.getBulkResult();\n    int count;\n    while ((count = de.read()) != 0) {\n      final int[] freqs = bulkresult.freqs.ints;\n      final int limit = bulkresult.freqs.offset + count;\n      for(int i=bulkresult.freqs.offset;i<limit;i++) {\n        totalTF += freqs[i];\n      }\n    }\n    return totalTF;\n  }\n\n","sourceOld":"  public static long getTotalTermFreq(IndexReader reader, String field, BytesRef termText) throws Exception {\n\n    long totalTF = 0;\n    \n    Terms terms = MultiFields.getTerms(reader, field);\n    if (terms == null) {\n      return 0;\n    }\n\n    TermsEnum termsEnum = terms.iterator();\n    if (termsEnum.seek(termText) != TermsEnum.SeekStatus.FOUND) {\n      return 0;\n    }\n\n    Bits skipDocs = MultiFields.getDeletedDocs(reader);\n    if (skipDocs == null) {\n      // TODO: we could do this up front, during the scan\n      // (next()), instead of after-the-fact here w/ seek,\n      // if the codec supports it and there are no del\n      // docs...\n      final long totTF = termsEnum.totalTermFreq();\n      if (totTF != -1) {\n        return totTF;\n      }\n    }\n    \n    DocsEnum de = termsEnum.docs(skipDocs, null);\n\n    // use DocsEnum.read() and BulkResult api\n    final DocsEnum.BulkReadResult bulkresult = de.getBulkResult();\n    int count;\n    while ((count = de.read()) != 0) {\n      final int[] freqs = bulkresult.freqs.ints;\n      final int limit = bulkresult.freqs.offset + count;\n      for(int i=bulkresult.freqs.offset;i<limit;i++) {\n        totalTF += freqs[i];\n      }\n    }\n    return totalTF;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3cc749c053615f5871f3b95715fe292f34e70a53","date":1321470575,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/contrib/misc/src/java/org/apache/lucene/misc/HighFreqTerms#getTotalTermFreq(IndexReader,String,BytesRef).mjava","pathOld":"lucene/contrib/misc/src/java/org/apache/lucene/misc/HighFreqTerms#getTotalTermFreq(IndexReader,String,BytesRef).mjava","sourceNew":"  public static long getTotalTermFreq(IndexReader reader, String field, BytesRef termText) throws Exception {\n\n    long totalTF = 0;\n    \n    Terms terms = MultiFields.getTerms(reader, field);\n    if (terms == null) {\n      return 0;\n    }\n\n    TermsEnum termsEnum = terms.iterator(null);\n    if (termsEnum.seekCeil(termText) != TermsEnum.SeekStatus.FOUND) {\n      return 0;\n    }\n\n    Bits liveDocs = MultiFields.getLiveDocs(reader);\n    if (liveDocs == null) {\n      // TODO: we could do this up front, during the scan\n      // (next()), instead of after-the-fact here w/ seek,\n      // if the codec supports it and there are no del\n      // docs...\n      final long totTF = termsEnum.totalTermFreq();\n      if (totTF != -1) {\n        return totTF;\n      }\n    }\n    \n    DocsEnum de = termsEnum.docs(liveDocs, null);\n\n    // use DocsEnum.read() and BulkResult api\n    final DocsEnum.BulkReadResult bulkresult = de.getBulkResult();\n    int count;\n    while ((count = de.read()) != 0) {\n      final int[] freqs = bulkresult.freqs.ints;\n      final int limit = bulkresult.freqs.offset + count;\n      for(int i=bulkresult.freqs.offset;i<limit;i++) {\n        totalTF += freqs[i];\n      }\n    }\n    return totalTF;\n  }\n\n","sourceOld":"  public static long getTotalTermFreq(IndexReader reader, String field, BytesRef termText) throws Exception {\n\n    long totalTF = 0;\n    \n    Terms terms = MultiFields.getTerms(reader, field);\n    if (terms == null) {\n      return 0;\n    }\n\n    TermsEnum termsEnum = terms.iterator();\n    if (termsEnum.seekCeil(termText) != TermsEnum.SeekStatus.FOUND) {\n      return 0;\n    }\n\n    Bits liveDocs = MultiFields.getLiveDocs(reader);\n    if (liveDocs == null) {\n      // TODO: we could do this up front, during the scan\n      // (next()), instead of after-the-fact here w/ seek,\n      // if the codec supports it and there are no del\n      // docs...\n      final long totTF = termsEnum.totalTermFreq();\n      if (totTF != -1) {\n        return totTF;\n      }\n    }\n    \n    DocsEnum de = termsEnum.docs(liveDocs, null);\n\n    // use DocsEnum.read() and BulkResult api\n    final DocsEnum.BulkReadResult bulkresult = de.getBulkResult();\n    int count;\n    while ((count = de.read()) != 0) {\n      final int[] freqs = bulkresult.freqs.ints;\n      final int limit = bulkresult.freqs.offset + count;\n      for(int i=bulkresult.freqs.offset;i<limit;i++) {\n        totalTF += freqs[i];\n      }\n    }\n    return totalTF;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0445bcd8433e331f296f5502fc089b336cbac3a6","date":1322630375,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/contrib/misc/src/java/org/apache/lucene/misc/HighFreqTerms#getTotalTermFreq(IndexReader,String,BytesRef).mjava","pathOld":"lucene/contrib/misc/src/java/org/apache/lucene/misc/HighFreqTerms#getTotalTermFreq(IndexReader,String,BytesRef).mjava","sourceNew":"  public static long getTotalTermFreq(IndexReader reader, final String field, final BytesRef termText) throws Exception {   \n    final long totalTF[] = new long[1];\n    \n    new ReaderUtil.Gather(reader) {\n\n      @Override\n      protected void add(int base, IndexReader r) throws IOException {\n        Bits liveDocs = r.getLiveDocs();\n        if (liveDocs == null) {\n          // TODO: we could do this up front, during the scan\n          // (next()), instead of after-the-fact here w/ seek,\n          // if the codec supports it and there are no del\n          // docs...\n          final long totTF = r.totalTermFreq(field, termText);\n          if (totTF != -1) {\n            totalTF[0] += totTF;\n            return;\n          }\n        }\n        DocsEnum de = r.termDocsEnum(liveDocs, field, termText);\n        if (de != null) {\n          while (de.nextDoc() != DocIdSetIterator.NO_MORE_DOCS)\n            totalTF[0] += de.freq();\n        }\n      }\n    }.run();\n    \n    return totalTF[0];\n  }\n\n","sourceOld":"  public static long getTotalTermFreq(IndexReader reader, String field, BytesRef termText) throws Exception {\n\n    long totalTF = 0;\n    \n    Terms terms = MultiFields.getTerms(reader, field);\n    if (terms == null) {\n      return 0;\n    }\n\n    TermsEnum termsEnum = terms.iterator(null);\n    if (termsEnum.seekCeil(termText) != TermsEnum.SeekStatus.FOUND) {\n      return 0;\n    }\n\n    Bits liveDocs = MultiFields.getLiveDocs(reader);\n    if (liveDocs == null) {\n      // TODO: we could do this up front, during the scan\n      // (next()), instead of after-the-fact here w/ seek,\n      // if the codec supports it and there are no del\n      // docs...\n      final long totTF = termsEnum.totalTermFreq();\n      if (totTF != -1) {\n        return totTF;\n      }\n    }\n    \n    DocsEnum de = termsEnum.docs(liveDocs, null);\n\n    // use DocsEnum.read() and BulkResult api\n    final DocsEnum.BulkReadResult bulkresult = de.getBulkResult();\n    int count;\n    while ((count = de.read()) != 0) {\n      final int[] freqs = bulkresult.freqs.ints;\n      final int limit = bulkresult.freqs.offset + count;\n      for(int i=bulkresult.freqs.offset;i<limit;i++) {\n        totalTF += freqs[i];\n      }\n    }\n    return totalTF;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"872cff1d3a554e0cd64014cd97f88d3002b0f491","date":1323024658,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/contrib/misc/src/java/org/apache/lucene/misc/HighFreqTerms#getTotalTermFreq(IndexReader,String,BytesRef).mjava","pathOld":"lucene/contrib/misc/src/java/org/apache/lucene/misc/HighFreqTerms#getTotalTermFreq(IndexReader,String,BytesRef).mjava","sourceNew":"  public static long getTotalTermFreq(IndexReader reader, final String field, final BytesRef termText) throws Exception {   \n    final long totalTF[] = new long[1];\n    \n    new ReaderUtil.Gather(reader) {\n\n      @Override\n      protected void add(int base, IndexReader r) throws IOException {\n        Bits liveDocs = r.getLiveDocs();\n        if (liveDocs == null) {\n          // TODO: we could do this up front, during the scan\n          // (next()), instead of after-the-fact here w/ seek,\n          // if the codec supports it and there are no del\n          // docs...\n          final long totTF = r.totalTermFreq(field, termText);\n          if (totTF != -1) {\n            totalTF[0] += totTF;\n            return;\n          }\n        }\n        DocsEnum de = r.termDocsEnum(liveDocs, field, termText, true);\n        if (de != null) {\n          while (de.nextDoc() != DocIdSetIterator.NO_MORE_DOCS)\n            totalTF[0] += de.freq();\n        }\n      }\n    }.run();\n    \n    return totalTF[0];\n  }\n\n","sourceOld":"  public static long getTotalTermFreq(IndexReader reader, final String field, final BytesRef termText) throws Exception {   \n    final long totalTF[] = new long[1];\n    \n    new ReaderUtil.Gather(reader) {\n\n      @Override\n      protected void add(int base, IndexReader r) throws IOException {\n        Bits liveDocs = r.getLiveDocs();\n        if (liveDocs == null) {\n          // TODO: we could do this up front, during the scan\n          // (next()), instead of after-the-fact here w/ seek,\n          // if the codec supports it and there are no del\n          // docs...\n          final long totTF = r.totalTermFreq(field, termText);\n          if (totTF != -1) {\n            totalTF[0] += totTF;\n            return;\n          }\n        }\n        DocsEnum de = r.termDocsEnum(liveDocs, field, termText);\n        if (de != null) {\n          while (de.nextDoc() != DocIdSetIterator.NO_MORE_DOCS)\n            totalTF[0] += de.freq();\n        }\n      }\n    }.run();\n    \n    return totalTF[0];\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b65b350ca9588f9fc76ce7d6804160d06c45ff42","date":1323026297,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/contrib/misc/src/java/org/apache/lucene/misc/HighFreqTerms#getTotalTermFreq(IndexReader,String,BytesRef).mjava","pathOld":"lucene/contrib/misc/src/java/org/apache/lucene/misc/HighFreqTerms#getTotalTermFreq(IndexReader,String,BytesRef).mjava","sourceNew":"  public static long getTotalTermFreq(IndexReader reader, final String field, final BytesRef termText) throws Exception {   \n    final long totalTF[] = new long[1];\n    \n    new ReaderUtil.Gather(reader) {\n\n      @Override\n      protected void add(int base, IndexReader r) throws IOException {\n        Bits liveDocs = r.getLiveDocs();\n        if (liveDocs == null) {\n          // TODO: we could do this up front, during the scan\n          // (next()), instead of after-the-fact here w/ seek,\n          // if the codec supports it and there are no del\n          // docs...\n          final long totTF = r.totalTermFreq(field, termText);\n          if (totTF != -1) {\n            totalTF[0] += totTF;\n            return;\n          }\n        }\n        DocsEnum de = r.termDocsEnum(liveDocs, field, termText, true);\n        if (de != null) {\n          while (de.nextDoc() != DocIdSetIterator.NO_MORE_DOCS)\n            totalTF[0] += de.freq();\n        }\n      }\n    }.run();\n    \n    return totalTF[0];\n  }\n\n","sourceOld":"  public static long getTotalTermFreq(IndexReader reader, final String field, final BytesRef termText) throws Exception {   \n    final long totalTF[] = new long[1];\n    \n    new ReaderUtil.Gather(reader) {\n\n      @Override\n      protected void add(int base, IndexReader r) throws IOException {\n        Bits liveDocs = r.getLiveDocs();\n        if (liveDocs == null) {\n          // TODO: we could do this up front, during the scan\n          // (next()), instead of after-the-fact here w/ seek,\n          // if the codec supports it and there are no del\n          // docs...\n          final long totTF = r.totalTermFreq(field, termText);\n          if (totTF != -1) {\n            totalTF[0] += totTF;\n            return;\n          }\n        }\n        DocsEnum de = r.termDocsEnum(liveDocs, field, termText);\n        if (de != null) {\n          while (de.nextDoc() != DocIdSetIterator.NO_MORE_DOCS)\n            totalTF[0] += de.freq();\n        }\n      }\n    }.run();\n    \n    return totalTF[0];\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"04d96eb3480582ebc4cc14711c2ca1a032791d75","date":1327856672,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/contrib/misc/src/java/org/apache/lucene/misc/HighFreqTerms#getTotalTermFreq(IndexReader,String,BytesRef).mjava","pathOld":"lucene/contrib/misc/src/java/org/apache/lucene/misc/HighFreqTerms#getTotalTermFreq(IndexReader,String,BytesRef).mjava","sourceNew":"  public static long getTotalTermFreq(IndexReader reader, final String field, final BytesRef termText) throws Exception {   \n    final long totalTF[] = new long[1];\n    \n    new ReaderUtil.Gather(reader) {\n\n      @Override\n      protected void add(int base, AtomicIndexReader r) throws IOException {\n        Bits liveDocs = r.getLiveDocs();\n        if (liveDocs == null) {\n          // TODO: we could do this up front, during the scan\n          // (next()), instead of after-the-fact here w/ seek,\n          // if the codec supports it and there are no del\n          // docs...\n          final long totTF = r.totalTermFreq(field, termText);\n          if (totTF != -1) {\n            totalTF[0] += totTF;\n            return;\n          }\n        }\n        DocsEnum de = r.termDocsEnum(liveDocs, field, termText, true);\n        if (de != null) {\n          while (de.nextDoc() != DocIdSetIterator.NO_MORE_DOCS)\n            totalTF[0] += de.freq();\n        }\n      }\n    }.run();\n    \n    return totalTF[0];\n  }\n\n","sourceOld":"  public static long getTotalTermFreq(IndexReader reader, final String field, final BytesRef termText) throws Exception {   \n    final long totalTF[] = new long[1];\n    \n    new ReaderUtil.Gather(reader) {\n\n      @Override\n      protected void add(int base, IndexReader r) throws IOException {\n        Bits liveDocs = r.getLiveDocs();\n        if (liveDocs == null) {\n          // TODO: we could do this up front, during the scan\n          // (next()), instead of after-the-fact here w/ seek,\n          // if the codec supports it and there are no del\n          // docs...\n          final long totTF = r.totalTermFreq(field, termText);\n          if (totTF != -1) {\n            totalTF[0] += totTF;\n            return;\n          }\n        }\n        DocsEnum de = r.termDocsEnum(liveDocs, field, termText, true);\n        if (de != null) {\n          while (de.nextDoc() != DocIdSetIterator.NO_MORE_DOCS)\n            totalTF[0] += de.freq();\n        }\n      }\n    }.run();\n    \n    return totalTF[0];\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"da6d5ac19a80d65b1e864251f155d30960353b7e","date":1327881054,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/contrib/misc/src/java/org/apache/lucene/misc/HighFreqTerms#getTotalTermFreq(IndexReader,String,BytesRef).mjava","pathOld":"lucene/contrib/misc/src/java/org/apache/lucene/misc/HighFreqTerms#getTotalTermFreq(IndexReader,String,BytesRef).mjava","sourceNew":"  public static long getTotalTermFreq(IndexReader reader, final String field, final BytesRef termText) throws Exception {   \n    final long totalTF[] = new long[1];\n    \n    new ReaderUtil.Gather(reader) {\n\n      @Override\n      protected void add(int base, AtomicReader r) throws IOException {\n        Bits liveDocs = r.getLiveDocs();\n        if (liveDocs == null) {\n          // TODO: we could do this up front, during the scan\n          // (next()), instead of after-the-fact here w/ seek,\n          // if the codec supports it and there are no del\n          // docs...\n          final long totTF = r.totalTermFreq(field, termText);\n          if (totTF != -1) {\n            totalTF[0] += totTF;\n            return;\n          }\n        }\n        DocsEnum de = r.termDocsEnum(liveDocs, field, termText, true);\n        if (de != null) {\n          while (de.nextDoc() != DocIdSetIterator.NO_MORE_DOCS)\n            totalTF[0] += de.freq();\n        }\n      }\n    }.run();\n    \n    return totalTF[0];\n  }\n\n","sourceOld":"  public static long getTotalTermFreq(IndexReader reader, final String field, final BytesRef termText) throws Exception {   \n    final long totalTF[] = new long[1];\n    \n    new ReaderUtil.Gather(reader) {\n\n      @Override\n      protected void add(int base, AtomicIndexReader r) throws IOException {\n        Bits liveDocs = r.getLiveDocs();\n        if (liveDocs == null) {\n          // TODO: we could do this up front, during the scan\n          // (next()), instead of after-the-fact here w/ seek,\n          // if the codec supports it and there are no del\n          // docs...\n          final long totTF = r.totalTermFreq(field, termText);\n          if (totTF != -1) {\n            totalTF[0] += totTF;\n            return;\n          }\n        }\n        DocsEnum de = r.termDocsEnum(liveDocs, field, termText, true);\n        if (de != null) {\n          while (de.nextDoc() != DocIdSetIterator.NO_MORE_DOCS)\n            totalTF[0] += de.freq();\n        }\n      }\n    }.run();\n    \n    return totalTF[0];\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5cab9a86bd67202d20b6adc463008c8e982b070a","date":1327966443,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/contrib/misc/src/java/org/apache/lucene/misc/HighFreqTerms#getTotalTermFreq(IndexReader,String,BytesRef).mjava","pathOld":"lucene/contrib/misc/src/java/org/apache/lucene/misc/HighFreqTerms#getTotalTermFreq(IndexReader,String,BytesRef).mjava","sourceNew":"  public static long getTotalTermFreq(IndexReader reader, final String field, final BytesRef termText) throws Exception {   \n    final long totalTF[] = new long[1];\n    \n    new ReaderUtil.Gather(reader) {\n\n      @Override\n      protected void add(int base, AtomicReader r) throws IOException {\n        Bits liveDocs = r.getLiveDocs();\n        if (liveDocs == null) {\n          // TODO: we could do this up front, during the scan\n          // (next()), instead of after-the-fact here w/ seek,\n          // if the codec supports it and there are no del\n          // docs...\n          final long totTF = r.totalTermFreq(field, termText);\n          if (totTF != -1) {\n            totalTF[0] += totTF;\n            return;\n          }\n        }\n        DocsEnum de = r.termDocsEnum(liveDocs, field, termText, true);\n        if (de != null) {\n          while (de.nextDoc() != DocIdSetIterator.NO_MORE_DOCS)\n            totalTF[0] += de.freq();\n        }\n      }\n    }.run();\n    \n    return totalTF[0];\n  }\n\n","sourceOld":"  public static long getTotalTermFreq(IndexReader reader, final String field, final BytesRef termText) throws Exception {   \n    final long totalTF[] = new long[1];\n    \n    new ReaderUtil.Gather(reader) {\n\n      @Override\n      protected void add(int base, IndexReader r) throws IOException {\n        Bits liveDocs = r.getLiveDocs();\n        if (liveDocs == null) {\n          // TODO: we could do this up front, during the scan\n          // (next()), instead of after-the-fact here w/ seek,\n          // if the codec supports it and there are no del\n          // docs...\n          final long totTF = r.totalTermFreq(field, termText);\n          if (totTF != -1) {\n            totalTF[0] += totTF;\n            return;\n          }\n        }\n        DocsEnum de = r.termDocsEnum(liveDocs, field, termText, true);\n        if (de != null) {\n          while (de.nextDoc() != DocIdSetIterator.NO_MORE_DOCS)\n            totalTF[0] += de.freq();\n        }\n      }\n    }.run();\n    \n    return totalTF[0];\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b89678825b68eccaf09e6ab71675fc0b0af1e099","date":1334669779,"type":5,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/misc/src/java/org/apache/lucene/misc/HighFreqTerms#getTotalTermFreq(IndexReader,String,BytesRef).mjava","pathOld":"lucene/contrib/misc/src/java/org/apache/lucene/misc/HighFreqTerms#getTotalTermFreq(IndexReader,String,BytesRef).mjava","sourceNew":"  public static long getTotalTermFreq(IndexReader reader, final String field, final BytesRef termText) throws Exception {   \n    final long totalTF[] = new long[1];\n    \n    new ReaderUtil.Gather(reader) {\n\n      @Override\n      protected void add(int base, AtomicReader r) throws IOException {\n        Bits liveDocs = r.getLiveDocs();\n        if (liveDocs == null) {\n          // TODO: we could do this up front, during the scan\n          // (next()), instead of after-the-fact here w/ seek,\n          // if the codec supports it and there are no del\n          // docs...\n          final long totTF = r.totalTermFreq(field, termText);\n          if (totTF != -1) {\n            totalTF[0] += totTF;\n            return;\n          }\n        }\n        DocsEnum de = r.termDocsEnum(liveDocs, field, termText, true);\n        if (de != null) {\n          while (de.nextDoc() != DocIdSetIterator.NO_MORE_DOCS)\n            totalTF[0] += de.freq();\n        }\n      }\n    }.run();\n    \n    return totalTF[0];\n  }\n\n","sourceOld":"  public static long getTotalTermFreq(IndexReader reader, final String field, final BytesRef termText) throws Exception {   \n    final long totalTF[] = new long[1];\n    \n    new ReaderUtil.Gather(reader) {\n\n      @Override\n      protected void add(int base, AtomicReader r) throws IOException {\n        Bits liveDocs = r.getLiveDocs();\n        if (liveDocs == null) {\n          // TODO: we could do this up front, during the scan\n          // (next()), instead of after-the-fact here w/ seek,\n          // if the codec supports it and there are no del\n          // docs...\n          final long totTF = r.totalTermFreq(field, termText);\n          if (totTF != -1) {\n            totalTF[0] += totTF;\n            return;\n          }\n        }\n        DocsEnum de = r.termDocsEnum(liveDocs, field, termText, true);\n        if (de != null) {\n          while (de.nextDoc() != DocIdSetIterator.NO_MORE_DOCS)\n            totalTF[0] += de.freq();\n        }\n      }\n    }.run();\n    \n    return totalTF[0];\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"0445bcd8433e331f296f5502fc089b336cbac3a6":["3cc749c053615f5871f3b95715fe292f34e70a53"],"e7bd246bb7bc35ac22edfee9157e034dfc4e65eb":["fd9cc9d77712aba3662f24632df7539ab75e3667"],"16843358872ed92ba92888ab99df297550b9a36a":["1513361122ebc5ddd6075f633cd77d2345611767","6ecd298fdc085e7eba27afa7fae58df1ba1a2808"],"3cc749c053615f5871f3b95715fe292f34e70a53":["e7bd246bb7bc35ac22edfee9157e034dfc4e65eb"],"872cff1d3a554e0cd64014cd97f88d3002b0f491":["0445bcd8433e331f296f5502fc089b336cbac3a6"],"2553b00f699380c64959ccb27991289aae87be2e":["6ecd298fdc085e7eba27afa7fae58df1ba1a2808","fd9cc9d77712aba3662f24632df7539ab75e3667"],"1513361122ebc5ddd6075f633cd77d2345611767":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"d083e83f225b11e5fdd900e83d26ddb385b6955c":["6ecd298fdc085e7eba27afa7fae58df1ba1a2808","e7bd246bb7bc35ac22edfee9157e034dfc4e65eb"],"5cab9a86bd67202d20b6adc463008c8e982b070a":["872cff1d3a554e0cd64014cd97f88d3002b0f491","da6d5ac19a80d65b1e864251f155d30960353b7e"],"817d8435e9135b756f08ce6710ab0baac51bdf88":["2553b00f699380c64959ccb27991289aae87be2e","e7bd246bb7bc35ac22edfee9157e034dfc4e65eb"],"b89678825b68eccaf09e6ab71675fc0b0af1e099":["5cab9a86bd67202d20b6adc463008c8e982b070a"],"da6d5ac19a80d65b1e864251f155d30960353b7e":["04d96eb3480582ebc4cc14711c2ca1a032791d75"],"b65b350ca9588f9fc76ce7d6804160d06c45ff42":["0445bcd8433e331f296f5502fc089b336cbac3a6","872cff1d3a554e0cd64014cd97f88d3002b0f491"],"29ef99d61cda9641b6250bf9567329a6e65f901d":["1513361122ebc5ddd6075f633cd77d2345611767","6ecd298fdc085e7eba27afa7fae58df1ba1a2808"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"04d96eb3480582ebc4cc14711c2ca1a032791d75":["872cff1d3a554e0cd64014cd97f88d3002b0f491"],"fd9cc9d77712aba3662f24632df7539ab75e3667":["6ecd298fdc085e7eba27afa7fae58df1ba1a2808"],"6ecd298fdc085e7eba27afa7fae58df1ba1a2808":["1513361122ebc5ddd6075f633cd77d2345611767"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["b89678825b68eccaf09e6ab71675fc0b0af1e099"]},"commit2Childs":{"0445bcd8433e331f296f5502fc089b336cbac3a6":["872cff1d3a554e0cd64014cd97f88d3002b0f491","b65b350ca9588f9fc76ce7d6804160d06c45ff42"],"e7bd246bb7bc35ac22edfee9157e034dfc4e65eb":["3cc749c053615f5871f3b95715fe292f34e70a53","d083e83f225b11e5fdd900e83d26ddb385b6955c","817d8435e9135b756f08ce6710ab0baac51bdf88"],"16843358872ed92ba92888ab99df297550b9a36a":[],"3cc749c053615f5871f3b95715fe292f34e70a53":["0445bcd8433e331f296f5502fc089b336cbac3a6"],"872cff1d3a554e0cd64014cd97f88d3002b0f491":["5cab9a86bd67202d20b6adc463008c8e982b070a","b65b350ca9588f9fc76ce7d6804160d06c45ff42","04d96eb3480582ebc4cc14711c2ca1a032791d75"],"2553b00f699380c64959ccb27991289aae87be2e":["817d8435e9135b756f08ce6710ab0baac51bdf88"],"1513361122ebc5ddd6075f633cd77d2345611767":["16843358872ed92ba92888ab99df297550b9a36a","29ef99d61cda9641b6250bf9567329a6e65f901d","6ecd298fdc085e7eba27afa7fae58df1ba1a2808"],"d083e83f225b11e5fdd900e83d26ddb385b6955c":[],"5cab9a86bd67202d20b6adc463008c8e982b070a":["b89678825b68eccaf09e6ab71675fc0b0af1e099"],"817d8435e9135b756f08ce6710ab0baac51bdf88":[],"b89678825b68eccaf09e6ab71675fc0b0af1e099":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"da6d5ac19a80d65b1e864251f155d30960353b7e":["5cab9a86bd67202d20b6adc463008c8e982b070a"],"b65b350ca9588f9fc76ce7d6804160d06c45ff42":[],"29ef99d61cda9641b6250bf9567329a6e65f901d":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["1513361122ebc5ddd6075f633cd77d2345611767"],"04d96eb3480582ebc4cc14711c2ca1a032791d75":["da6d5ac19a80d65b1e864251f155d30960353b7e"],"fd9cc9d77712aba3662f24632df7539ab75e3667":["e7bd246bb7bc35ac22edfee9157e034dfc4e65eb","2553b00f699380c64959ccb27991289aae87be2e"],"6ecd298fdc085e7eba27afa7fae58df1ba1a2808":["16843358872ed92ba92888ab99df297550b9a36a","2553b00f699380c64959ccb27991289aae87be2e","d083e83f225b11e5fdd900e83d26ddb385b6955c","29ef99d61cda9641b6250bf9567329a6e65f901d","fd9cc9d77712aba3662f24632df7539ab75e3667"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["16843358872ed92ba92888ab99df297550b9a36a","d083e83f225b11e5fdd900e83d26ddb385b6955c","817d8435e9135b756f08ce6710ab0baac51bdf88","b65b350ca9588f9fc76ce7d6804160d06c45ff42","29ef99d61cda9641b6250bf9567329a6e65f901d","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}