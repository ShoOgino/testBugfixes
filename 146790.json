{"path":"solr/core/src/test/org/apache/solr/search/TestRecovery#testRemoveOldLogs().mjava","commits":[{"id":"2c007e7c4cf8c55bc2a5884e315123afaaeec87f","date":1327520966,"type":0,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/search/TestRecovery#testRemoveOldLogs().mjava","pathOld":"/dev/null","sourceNew":"  @Test\n  public void testRemoveOldLogs() throws Exception {\n    try {\n      DirectUpdateHandler2.commitOnClose = false;\n      final Semaphore logReplay = new Semaphore(0);\n      final Semaphore logReplayFinish = new Semaphore(0);\n\n      UpdateLog.testing_logReplayHook = new Runnable() {\n        @Override\n        public void run() {\n          try {\n            assertTrue(logReplay.tryAcquire(timeout, TimeUnit.SECONDS));\n          } catch (Exception e) {\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      UpdateLog.testing_logReplayFinishHook = new Runnable() {\n        @Override\n        public void run() {\n          logReplayFinish.release();\n        }\n      };\n\n\n      clearIndex();\n      assertU(commit());\n\n      File logDir = h.getCore().getUpdateHandler().getUpdateLog().getLogDir();\n\n      h.close();\n\n      String[] files = UpdateLog.getLogList(logDir);\n      for (String file : files) {\n        new File(logDir, file).delete();\n      }\n\n      assertEquals(0, UpdateLog.getLogList(logDir).length);\n\n      createCore();\n\n      int start = 0;\n      int maxReq = 50;\n\n      LinkedList<Long> versions = new LinkedList<Long>();\n      addDocs(10, start, versions); start+=10;\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n      assertU(commit());\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      addDocs(10, start, versions);  start+=10;\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n      assertU(commit());\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      assertEquals(2, UpdateLog.getLogList(logDir).length);\n\n      addDocs(105, start, versions);  start+=105;\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n      assertU(commit());\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      // previous two logs should be gone now\n      assertEquals(1, UpdateLog.getLogList(logDir).length);\n\n      addDocs(1, start, versions);  start+=1;\n      h.close();\n      createCore();      // trigger recovery, make sure that tlog reference handling is correct\n\n      // test we can get versions while replay is happening\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      logReplay.release(1000);\n      assertTrue(logReplayFinish.tryAcquire(timeout, TimeUnit.SECONDS));\n\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      addDocs(105, start, versions);  start+=105;\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n      assertU(commit());\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      // previous logs should be gone now\n      assertEquals(1, UpdateLog.getLogList(logDir).length);\n\n      //\n      // test that a corrupt tlog file doesn't stop us from coming up, or seeing versions before that tlog file.\n      //\n      addDocs(1, start, new LinkedList<Long>()); // don't add this to the versions list because we are going to lose it...\n      h.close();\n      files = UpdateLog.getLogList(logDir);\n      Arrays.sort(files);\n      RandomAccessFile raf = new RandomAccessFile(new File(logDir, files[files.length-1]), \"rw\");\n      raf.writeChars(\"This is a trashed log file that really shouldn't work at all, but we'll see...\");\n      raf.close();\n\n      ignoreException(\"Failure to open existing\");\n      createCore();\n      // we should still be able to get the list of versions (not including the trashed log file)\n      assertJQ(req(\"qt\", \"/get\", \"getVersions\", \"\" + maxReq), \"/versions==\" + versions.subList(0, Math.min(maxReq, start)));\n      resetExceptionIgnores();\n\n    } finally {\n      DirectUpdateHandler2.commitOnClose = true;\n      UpdateLog.testing_logReplayHook = null;\n      UpdateLog.testing_logReplayFinishHook = null;\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["cbc3688252d4a8045d69a164236b2cf87b721f17"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"a3c68e20c73359a10cf3eb4a35c9fa7ab1f3c30d","date":1327523564,"type":0,"author":"Robert Muir","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/search/TestRecovery#testRemoveOldLogs().mjava","pathOld":"/dev/null","sourceNew":"  @Test\n  public void testRemoveOldLogs() throws Exception {\n    try {\n      DirectUpdateHandler2.commitOnClose = false;\n      final Semaphore logReplay = new Semaphore(0);\n      final Semaphore logReplayFinish = new Semaphore(0);\n\n      UpdateLog.testing_logReplayHook = new Runnable() {\n        @Override\n        public void run() {\n          try {\n            assertTrue(logReplay.tryAcquire(timeout, TimeUnit.SECONDS));\n          } catch (Exception e) {\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      UpdateLog.testing_logReplayFinishHook = new Runnable() {\n        @Override\n        public void run() {\n          logReplayFinish.release();\n        }\n      };\n\n\n      clearIndex();\n      assertU(commit());\n\n      File logDir = h.getCore().getUpdateHandler().getUpdateLog().getLogDir();\n\n      h.close();\n\n      String[] files = UpdateLog.getLogList(logDir);\n      for (String file : files) {\n        new File(logDir, file).delete();\n      }\n\n      assertEquals(0, UpdateLog.getLogList(logDir).length);\n\n      createCore();\n\n      int start = 0;\n      int maxReq = 50;\n\n      LinkedList<Long> versions = new LinkedList<Long>();\n      addDocs(10, start, versions); start+=10;\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n      assertU(commit());\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      addDocs(10, start, versions);  start+=10;\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n      assertU(commit());\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      assertEquals(2, UpdateLog.getLogList(logDir).length);\n\n      addDocs(105, start, versions);  start+=105;\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n      assertU(commit());\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      // previous two logs should be gone now\n      assertEquals(1, UpdateLog.getLogList(logDir).length);\n\n      addDocs(1, start, versions);  start+=1;\n      h.close();\n      createCore();      // trigger recovery, make sure that tlog reference handling is correct\n\n      // test we can get versions while replay is happening\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      logReplay.release(1000);\n      assertTrue(logReplayFinish.tryAcquire(timeout, TimeUnit.SECONDS));\n\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      addDocs(105, start, versions);  start+=105;\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n      assertU(commit());\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      // previous logs should be gone now\n      assertEquals(1, UpdateLog.getLogList(logDir).length);\n\n      //\n      // test that a corrupt tlog file doesn't stop us from coming up, or seeing versions before that tlog file.\n      //\n      addDocs(1, start, new LinkedList<Long>()); // don't add this to the versions list because we are going to lose it...\n      h.close();\n      files = UpdateLog.getLogList(logDir);\n      Arrays.sort(files);\n      RandomAccessFile raf = new RandomAccessFile(new File(logDir, files[files.length-1]), \"rw\");\n      raf.writeChars(\"This is a trashed log file that really shouldn't work at all, but we'll see...\");\n      raf.close();\n\n      ignoreException(\"Failure to open existing\");\n      createCore();\n      // we should still be able to get the list of versions (not including the trashed log file)\n      assertJQ(req(\"qt\", \"/get\", \"getVersions\", \"\" + maxReq), \"/versions==\" + versions.subList(0, Math.min(maxReq, start)));\n      resetExceptionIgnores();\n\n    } finally {\n      DirectUpdateHandler2.commitOnClose = true;\n      UpdateLog.testing_logReplayHook = null;\n      UpdateLog.testing_logReplayFinishHook = null;\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0d22ac6a4146774c1bc8400160fc0b6150294e92","date":1327528604,"type":0,"author":"Uwe Schindler","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/search/TestRecovery#testRemoveOldLogs().mjava","pathOld":"/dev/null","sourceNew":"  @Test\n  public void testRemoveOldLogs() throws Exception {\n    try {\n      DirectUpdateHandler2.commitOnClose = false;\n      final Semaphore logReplay = new Semaphore(0);\n      final Semaphore logReplayFinish = new Semaphore(0);\n\n      UpdateLog.testing_logReplayHook = new Runnable() {\n        @Override\n        public void run() {\n          try {\n            assertTrue(logReplay.tryAcquire(timeout, TimeUnit.SECONDS));\n          } catch (Exception e) {\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      UpdateLog.testing_logReplayFinishHook = new Runnable() {\n        @Override\n        public void run() {\n          logReplayFinish.release();\n        }\n      };\n\n\n      clearIndex();\n      assertU(commit());\n\n      File logDir = h.getCore().getUpdateHandler().getUpdateLog().getLogDir();\n\n      h.close();\n\n      String[] files = UpdateLog.getLogList(logDir);\n      for (String file : files) {\n        new File(logDir, file).delete();\n      }\n\n      assertEquals(0, UpdateLog.getLogList(logDir).length);\n\n      createCore();\n\n      int start = 0;\n      int maxReq = 50;\n\n      LinkedList<Long> versions = new LinkedList<Long>();\n      addDocs(10, start, versions); start+=10;\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n      assertU(commit());\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      addDocs(10, start, versions);  start+=10;\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n      assertU(commit());\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      assertEquals(2, UpdateLog.getLogList(logDir).length);\n\n      addDocs(105, start, versions);  start+=105;\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n      assertU(commit());\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      // previous two logs should be gone now\n      assertEquals(1, UpdateLog.getLogList(logDir).length);\n\n      addDocs(1, start, versions);  start+=1;\n      h.close();\n      createCore();      // trigger recovery, make sure that tlog reference handling is correct\n\n      // test we can get versions while replay is happening\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      logReplay.release(1000);\n      assertTrue(logReplayFinish.tryAcquire(timeout, TimeUnit.SECONDS));\n\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      addDocs(105, start, versions);  start+=105;\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n      assertU(commit());\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      // previous logs should be gone now\n      assertEquals(1, UpdateLog.getLogList(logDir).length);\n\n      //\n      // test that a corrupt tlog file doesn't stop us from coming up, or seeing versions before that tlog file.\n      //\n      addDocs(1, start, new LinkedList<Long>()); // don't add this to the versions list because we are going to lose it...\n      h.close();\n      files = UpdateLog.getLogList(logDir);\n      Arrays.sort(files);\n      RandomAccessFile raf = new RandomAccessFile(new File(logDir, files[files.length-1]), \"rw\");\n      raf.writeChars(\"This is a trashed log file that really shouldn't work at all, but we'll see...\");\n      raf.close();\n\n      ignoreException(\"Failure to open existing\");\n      createCore();\n      // we should still be able to get the list of versions (not including the trashed log file)\n      assertJQ(req(\"qt\", \"/get\", \"getVersions\", \"\" + maxReq), \"/versions==\" + versions.subList(0, Math.min(maxReq, start)));\n      resetExceptionIgnores();\n\n    } finally {\n      DirectUpdateHandler2.commitOnClose = true;\n      UpdateLog.testing_logReplayHook = null;\n      UpdateLog.testing_logReplayFinishHook = null;\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"849494cf2f3a96af5c8c84995108ddd8456fcd04","date":1372277913,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/search/TestRecovery#testRemoveOldLogs().mjava","pathOld":"solr/core/src/test/org/apache/solr/search/TestRecovery#testRemoveOldLogs().mjava","sourceNew":"  @Test\n  public void testRemoveOldLogs() throws Exception {\n    try {\n      DirectUpdateHandler2.commitOnClose = false;\n      final Semaphore logReplay = new Semaphore(0);\n      final Semaphore logReplayFinish = new Semaphore(0);\n\n      UpdateLog.testing_logReplayHook = new Runnable() {\n        @Override\n        public void run() {\n          try {\n            assertTrue(logReplay.tryAcquire(timeout, TimeUnit.SECONDS));\n          } catch (Exception e) {\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      UpdateLog.testing_logReplayFinishHook = new Runnable() {\n        @Override\n        public void run() {\n          logReplayFinish.release();\n        }\n      };\n\n\n      clearIndex();\n      assertU(commit());\n\n      UpdateLog ulog = h.getCore().getUpdateHandler().getUpdateLog();\n      File logDir = new File(h.getCore().getUpdateHandler().getUpdateLog().getLogDir());\n\n      h.close();\n\n      String[] files = ulog.getLogList(logDir);\n      for (String file : files) {\n        new File(logDir, file).delete();\n      }\n\n      assertEquals(0, ulog.getLogList(logDir).length);\n\n      createCore();\n\n      int start = 0;\n      int maxReq = 50;\n\n      LinkedList<Long> versions = new LinkedList<Long>();\n      addDocs(10, start, versions); start+=10;\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n      assertU(commit());\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      addDocs(10, start, versions);  start+=10;\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n      assertU(commit());\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      assertEquals(2, ulog.getLogList(logDir).length);\n\n      addDocs(105, start, versions);  start+=105;\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n      assertU(commit());\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      // previous two logs should be gone now\n      assertEquals(1, ulog.getLogList(logDir).length);\n\n      addDocs(1, start, versions);  start+=1;\n      h.close();\n      createCore();      // trigger recovery, make sure that tlog reference handling is correct\n\n      // test we can get versions while replay is happening\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      logReplay.release(1000);\n      assertTrue(logReplayFinish.tryAcquire(timeout, TimeUnit.SECONDS));\n\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      addDocs(105, start, versions);  start+=105;\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n      assertU(commit());\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      // previous logs should be gone now\n      assertEquals(1, ulog.getLogList(logDir).length);\n\n      //\n      // test that a corrupt tlog file doesn't stop us from coming up, or seeing versions before that tlog file.\n      //\n      addDocs(1, start, new LinkedList<Long>()); // don't add this to the versions list because we are going to lose it...\n      h.close();\n      files = ulog.getLogList(logDir);\n      Arrays.sort(files);\n      RandomAccessFile raf = new RandomAccessFile(new File(logDir, files[files.length-1]), \"rw\");\n      raf.writeChars(\"This is a trashed log file that really shouldn't work at all, but we'll see...\");\n      raf.close();\n\n      ignoreException(\"Failure to open existing\");\n      createCore();\n      // we should still be able to get the list of versions (not including the trashed log file)\n      assertJQ(req(\"qt\", \"/get\", \"getVersions\", \"\" + maxReq), \"/versions==\" + versions.subList(0, Math.min(maxReq, start)));\n      resetExceptionIgnores();\n\n    } finally {\n      DirectUpdateHandler2.commitOnClose = true;\n      UpdateLog.testing_logReplayHook = null;\n      UpdateLog.testing_logReplayFinishHook = null;\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testRemoveOldLogs() throws Exception {\n    try {\n      DirectUpdateHandler2.commitOnClose = false;\n      final Semaphore logReplay = new Semaphore(0);\n      final Semaphore logReplayFinish = new Semaphore(0);\n\n      UpdateLog.testing_logReplayHook = new Runnable() {\n        @Override\n        public void run() {\n          try {\n            assertTrue(logReplay.tryAcquire(timeout, TimeUnit.SECONDS));\n          } catch (Exception e) {\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      UpdateLog.testing_logReplayFinishHook = new Runnable() {\n        @Override\n        public void run() {\n          logReplayFinish.release();\n        }\n      };\n\n\n      clearIndex();\n      assertU(commit());\n\n      File logDir = h.getCore().getUpdateHandler().getUpdateLog().getLogDir();\n\n      h.close();\n\n      String[] files = UpdateLog.getLogList(logDir);\n      for (String file : files) {\n        new File(logDir, file).delete();\n      }\n\n      assertEquals(0, UpdateLog.getLogList(logDir).length);\n\n      createCore();\n\n      int start = 0;\n      int maxReq = 50;\n\n      LinkedList<Long> versions = new LinkedList<Long>();\n      addDocs(10, start, versions); start+=10;\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n      assertU(commit());\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      addDocs(10, start, versions);  start+=10;\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n      assertU(commit());\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      assertEquals(2, UpdateLog.getLogList(logDir).length);\n\n      addDocs(105, start, versions);  start+=105;\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n      assertU(commit());\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      // previous two logs should be gone now\n      assertEquals(1, UpdateLog.getLogList(logDir).length);\n\n      addDocs(1, start, versions);  start+=1;\n      h.close();\n      createCore();      // trigger recovery, make sure that tlog reference handling is correct\n\n      // test we can get versions while replay is happening\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      logReplay.release(1000);\n      assertTrue(logReplayFinish.tryAcquire(timeout, TimeUnit.SECONDS));\n\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      addDocs(105, start, versions);  start+=105;\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n      assertU(commit());\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      // previous logs should be gone now\n      assertEquals(1, UpdateLog.getLogList(logDir).length);\n\n      //\n      // test that a corrupt tlog file doesn't stop us from coming up, or seeing versions before that tlog file.\n      //\n      addDocs(1, start, new LinkedList<Long>()); // don't add this to the versions list because we are going to lose it...\n      h.close();\n      files = UpdateLog.getLogList(logDir);\n      Arrays.sort(files);\n      RandomAccessFile raf = new RandomAccessFile(new File(logDir, files[files.length-1]), \"rw\");\n      raf.writeChars(\"This is a trashed log file that really shouldn't work at all, but we'll see...\");\n      raf.close();\n\n      ignoreException(\"Failure to open existing\");\n      createCore();\n      // we should still be able to get the list of versions (not including the trashed log file)\n      assertJQ(req(\"qt\", \"/get\", \"getVersions\", \"\" + maxReq), \"/versions==\" + versions.subList(0, Math.min(maxReq, start)));\n      resetExceptionIgnores();\n\n    } finally {\n      DirectUpdateHandler2.commitOnClose = true;\n      UpdateLog.testing_logReplayHook = null;\n      UpdateLog.testing_logReplayFinishHook = null;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"37a0f60745e53927c4c876cfe5b5a58170f0646c","date":1373994005,"type":3,"author":"Han Jiang","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/search/TestRecovery#testRemoveOldLogs().mjava","pathOld":"solr/core/src/test/org/apache/solr/search/TestRecovery#testRemoveOldLogs().mjava","sourceNew":"  @Test\n  public void testRemoveOldLogs() throws Exception {\n    try {\n      DirectUpdateHandler2.commitOnClose = false;\n      final Semaphore logReplay = new Semaphore(0);\n      final Semaphore logReplayFinish = new Semaphore(0);\n\n      UpdateLog.testing_logReplayHook = new Runnable() {\n        @Override\n        public void run() {\n          try {\n            assertTrue(logReplay.tryAcquire(timeout, TimeUnit.SECONDS));\n          } catch (Exception e) {\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      UpdateLog.testing_logReplayFinishHook = new Runnable() {\n        @Override\n        public void run() {\n          logReplayFinish.release();\n        }\n      };\n\n\n      clearIndex();\n      assertU(commit());\n\n      UpdateLog ulog = h.getCore().getUpdateHandler().getUpdateLog();\n      File logDir = new File(h.getCore().getUpdateHandler().getUpdateLog().getLogDir());\n\n      h.close();\n\n      String[] files = ulog.getLogList(logDir);\n      for (String file : files) {\n        new File(logDir, file).delete();\n      }\n\n      assertEquals(0, ulog.getLogList(logDir).length);\n\n      createCore();\n\n      int start = 0;\n      int maxReq = 50;\n\n      LinkedList<Long> versions = new LinkedList<Long>();\n      addDocs(10, start, versions); start+=10;\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n      assertU(commit());\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      addDocs(10, start, versions);  start+=10;\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n      assertU(commit());\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      assertEquals(2, ulog.getLogList(logDir).length);\n\n      addDocs(105, start, versions);  start+=105;\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n      assertU(commit());\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      // previous two logs should be gone now\n      assertEquals(1, ulog.getLogList(logDir).length);\n\n      addDocs(1, start, versions);  start+=1;\n      h.close();\n      createCore();      // trigger recovery, make sure that tlog reference handling is correct\n\n      // test we can get versions while replay is happening\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      logReplay.release(1000);\n      assertTrue(logReplayFinish.tryAcquire(timeout, TimeUnit.SECONDS));\n\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      addDocs(105, start, versions);  start+=105;\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n      assertU(commit());\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      // previous logs should be gone now\n      assertEquals(1, ulog.getLogList(logDir).length);\n\n      //\n      // test that a corrupt tlog file doesn't stop us from coming up, or seeing versions before that tlog file.\n      //\n      addDocs(1, start, new LinkedList<Long>()); // don't add this to the versions list because we are going to lose it...\n      h.close();\n      files = ulog.getLogList(logDir);\n      Arrays.sort(files);\n      RandomAccessFile raf = new RandomAccessFile(new File(logDir, files[files.length-1]), \"rw\");\n      raf.writeChars(\"This is a trashed log file that really shouldn't work at all, but we'll see...\");\n      raf.close();\n\n      ignoreException(\"Failure to open existing\");\n      createCore();\n      // we should still be able to get the list of versions (not including the trashed log file)\n      assertJQ(req(\"qt\", \"/get\", \"getVersions\", \"\" + maxReq), \"/versions==\" + versions.subList(0, Math.min(maxReq, start)));\n      resetExceptionIgnores();\n\n    } finally {\n      DirectUpdateHandler2.commitOnClose = true;\n      UpdateLog.testing_logReplayHook = null;\n      UpdateLog.testing_logReplayFinishHook = null;\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testRemoveOldLogs() throws Exception {\n    try {\n      DirectUpdateHandler2.commitOnClose = false;\n      final Semaphore logReplay = new Semaphore(0);\n      final Semaphore logReplayFinish = new Semaphore(0);\n\n      UpdateLog.testing_logReplayHook = new Runnable() {\n        @Override\n        public void run() {\n          try {\n            assertTrue(logReplay.tryAcquire(timeout, TimeUnit.SECONDS));\n          } catch (Exception e) {\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      UpdateLog.testing_logReplayFinishHook = new Runnable() {\n        @Override\n        public void run() {\n          logReplayFinish.release();\n        }\n      };\n\n\n      clearIndex();\n      assertU(commit());\n\n      File logDir = h.getCore().getUpdateHandler().getUpdateLog().getLogDir();\n\n      h.close();\n\n      String[] files = UpdateLog.getLogList(logDir);\n      for (String file : files) {\n        new File(logDir, file).delete();\n      }\n\n      assertEquals(0, UpdateLog.getLogList(logDir).length);\n\n      createCore();\n\n      int start = 0;\n      int maxReq = 50;\n\n      LinkedList<Long> versions = new LinkedList<Long>();\n      addDocs(10, start, versions); start+=10;\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n      assertU(commit());\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      addDocs(10, start, versions);  start+=10;\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n      assertU(commit());\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      assertEquals(2, UpdateLog.getLogList(logDir).length);\n\n      addDocs(105, start, versions);  start+=105;\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n      assertU(commit());\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      // previous two logs should be gone now\n      assertEquals(1, UpdateLog.getLogList(logDir).length);\n\n      addDocs(1, start, versions);  start+=1;\n      h.close();\n      createCore();      // trigger recovery, make sure that tlog reference handling is correct\n\n      // test we can get versions while replay is happening\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      logReplay.release(1000);\n      assertTrue(logReplayFinish.tryAcquire(timeout, TimeUnit.SECONDS));\n\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      addDocs(105, start, versions);  start+=105;\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n      assertU(commit());\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      // previous logs should be gone now\n      assertEquals(1, UpdateLog.getLogList(logDir).length);\n\n      //\n      // test that a corrupt tlog file doesn't stop us from coming up, or seeing versions before that tlog file.\n      //\n      addDocs(1, start, new LinkedList<Long>()); // don't add this to the versions list because we are going to lose it...\n      h.close();\n      files = UpdateLog.getLogList(logDir);\n      Arrays.sort(files);\n      RandomAccessFile raf = new RandomAccessFile(new File(logDir, files[files.length-1]), \"rw\");\n      raf.writeChars(\"This is a trashed log file that really shouldn't work at all, but we'll see...\");\n      raf.close();\n\n      ignoreException(\"Failure to open existing\");\n      createCore();\n      // we should still be able to get the list of versions (not including the trashed log file)\n      assertJQ(req(\"qt\", \"/get\", \"getVersions\", \"\" + maxReq), \"/versions==\" + versions.subList(0, Math.min(maxReq, start)));\n      resetExceptionIgnores();\n\n    } finally {\n      DirectUpdateHandler2.commitOnClose = true;\n      UpdateLog.testing_logReplayHook = null;\n      UpdateLog.testing_logReplayFinishHook = null;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"634f330c54fd3f9f491d52036dc3f40b4f4d8934","date":1394635157,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/search/TestRecovery#testRemoveOldLogs().mjava","pathOld":"solr/core/src/test/org/apache/solr/search/TestRecovery#testRemoveOldLogs().mjava","sourceNew":"  @Test\n  public void testRemoveOldLogs() throws Exception {\n    try {\n      DirectUpdateHandler2.commitOnClose = false;\n      final Semaphore logReplay = new Semaphore(0);\n      final Semaphore logReplayFinish = new Semaphore(0);\n\n      UpdateLog.testing_logReplayHook = new Runnable() {\n        @Override\n        public void run() {\n          try {\n            assertTrue(logReplay.tryAcquire(timeout, TimeUnit.SECONDS));\n          } catch (Exception e) {\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      UpdateLog.testing_logReplayFinishHook = new Runnable() {\n        @Override\n        public void run() {\n          logReplayFinish.release();\n        }\n      };\n\n\n      clearIndex();\n      assertU(commit());\n\n      UpdateLog ulog = h.getCore().getUpdateHandler().getUpdateLog();\n      File logDir = new File(h.getCore().getUpdateHandler().getUpdateLog().getLogDir());\n\n      h.close();\n\n      String[] files = ulog.getLogList(logDir);\n      for (String file : files) {\n        new File(logDir, file).delete();\n      }\n\n      assertEquals(0, ulog.getLogList(logDir).length);\n\n      createCore();\n\n      int start = 0;\n      int maxReq = 50;\n\n      LinkedList<Long> versions = new LinkedList<>();\n      addDocs(10, start, versions); start+=10;\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n      assertU(commit());\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      addDocs(10, start, versions);  start+=10;\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n      assertU(commit());\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      assertEquals(2, ulog.getLogList(logDir).length);\n\n      addDocs(105, start, versions);  start+=105;\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n      assertU(commit());\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      // previous two logs should be gone now\n      assertEquals(1, ulog.getLogList(logDir).length);\n\n      addDocs(1, start, versions);  start+=1;\n      h.close();\n      createCore();      // trigger recovery, make sure that tlog reference handling is correct\n\n      // test we can get versions while replay is happening\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      logReplay.release(1000);\n      assertTrue(logReplayFinish.tryAcquire(timeout, TimeUnit.SECONDS));\n\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      addDocs(105, start, versions);  start+=105;\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n      assertU(commit());\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      // previous logs should be gone now\n      assertEquals(1, ulog.getLogList(logDir).length);\n\n      //\n      // test that a corrupt tlog file doesn't stop us from coming up, or seeing versions before that tlog file.\n      //\n      addDocs(1, start, new LinkedList<Long>()); // don't add this to the versions list because we are going to lose it...\n      h.close();\n      files = ulog.getLogList(logDir);\n      Arrays.sort(files);\n      RandomAccessFile raf = new RandomAccessFile(new File(logDir, files[files.length-1]), \"rw\");\n      raf.writeChars(\"This is a trashed log file that really shouldn't work at all, but we'll see...\");\n      raf.close();\n\n      ignoreException(\"Failure to open existing\");\n      createCore();\n      // we should still be able to get the list of versions (not including the trashed log file)\n      assertJQ(req(\"qt\", \"/get\", \"getVersions\", \"\" + maxReq), \"/versions==\" + versions.subList(0, Math.min(maxReq, start)));\n      resetExceptionIgnores();\n\n    } finally {\n      DirectUpdateHandler2.commitOnClose = true;\n      UpdateLog.testing_logReplayHook = null;\n      UpdateLog.testing_logReplayFinishHook = null;\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testRemoveOldLogs() throws Exception {\n    try {\n      DirectUpdateHandler2.commitOnClose = false;\n      final Semaphore logReplay = new Semaphore(0);\n      final Semaphore logReplayFinish = new Semaphore(0);\n\n      UpdateLog.testing_logReplayHook = new Runnable() {\n        @Override\n        public void run() {\n          try {\n            assertTrue(logReplay.tryAcquire(timeout, TimeUnit.SECONDS));\n          } catch (Exception e) {\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      UpdateLog.testing_logReplayFinishHook = new Runnable() {\n        @Override\n        public void run() {\n          logReplayFinish.release();\n        }\n      };\n\n\n      clearIndex();\n      assertU(commit());\n\n      UpdateLog ulog = h.getCore().getUpdateHandler().getUpdateLog();\n      File logDir = new File(h.getCore().getUpdateHandler().getUpdateLog().getLogDir());\n\n      h.close();\n\n      String[] files = ulog.getLogList(logDir);\n      for (String file : files) {\n        new File(logDir, file).delete();\n      }\n\n      assertEquals(0, ulog.getLogList(logDir).length);\n\n      createCore();\n\n      int start = 0;\n      int maxReq = 50;\n\n      LinkedList<Long> versions = new LinkedList<Long>();\n      addDocs(10, start, versions); start+=10;\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n      assertU(commit());\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      addDocs(10, start, versions);  start+=10;\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n      assertU(commit());\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      assertEquals(2, ulog.getLogList(logDir).length);\n\n      addDocs(105, start, versions);  start+=105;\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n      assertU(commit());\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      // previous two logs should be gone now\n      assertEquals(1, ulog.getLogList(logDir).length);\n\n      addDocs(1, start, versions);  start+=1;\n      h.close();\n      createCore();      // trigger recovery, make sure that tlog reference handling is correct\n\n      // test we can get versions while replay is happening\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      logReplay.release(1000);\n      assertTrue(logReplayFinish.tryAcquire(timeout, TimeUnit.SECONDS));\n\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      addDocs(105, start, versions);  start+=105;\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n      assertU(commit());\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      // previous logs should be gone now\n      assertEquals(1, ulog.getLogList(logDir).length);\n\n      //\n      // test that a corrupt tlog file doesn't stop us from coming up, or seeing versions before that tlog file.\n      //\n      addDocs(1, start, new LinkedList<Long>()); // don't add this to the versions list because we are going to lose it...\n      h.close();\n      files = ulog.getLogList(logDir);\n      Arrays.sort(files);\n      RandomAccessFile raf = new RandomAccessFile(new File(logDir, files[files.length-1]), \"rw\");\n      raf.writeChars(\"This is a trashed log file that really shouldn't work at all, but we'll see...\");\n      raf.close();\n\n      ignoreException(\"Failure to open existing\");\n      createCore();\n      // we should still be able to get the list of versions (not including the trashed log file)\n      assertJQ(req(\"qt\", \"/get\", \"getVersions\", \"\" + maxReq), \"/versions==\" + versions.subList(0, Math.min(maxReq, start)));\n      resetExceptionIgnores();\n\n    } finally {\n      DirectUpdateHandler2.commitOnClose = true;\n      UpdateLog.testing_logReplayHook = null;\n      UpdateLog.testing_logReplayFinishHook = null;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"cbc3688252d4a8045d69a164236b2cf87b721f17","date":1409846185,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/search/TestRecovery#testRemoveOldLogs().mjava","pathOld":"solr/core/src/test/org/apache/solr/search/TestRecovery#testRemoveOldLogs().mjava","sourceNew":"  @Test\n  public void testRemoveOldLogs() throws Exception {\n    try {\n      DirectUpdateHandler2.commitOnClose = false;\n      final Semaphore logReplay = new Semaphore(0);\n      final Semaphore logReplayFinish = new Semaphore(0);\n\n      UpdateLog.testing_logReplayHook = new Runnable() {\n        @Override\n        public void run() {\n          try {\n            assertTrue(logReplay.tryAcquire(timeout, TimeUnit.SECONDS));\n          } catch (Exception e) {\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      UpdateLog.testing_logReplayFinishHook = new Runnable() {\n        @Override\n        public void run() {\n          logReplayFinish.release();\n        }\n      };\n\n\n      clearIndex();\n      assertU(commit());\n\n      UpdateLog ulog = h.getCore().getUpdateHandler().getUpdateLog();\n      File logDir = new File(h.getCore().getUpdateHandler().getUpdateLog().getLogDir());\n\n      h.close();\n\n      String[] files = ulog.getLogList(logDir);\n      for (String file : files) {\n        Files.delete(new File(logDir, file).toPath());\n      }\n\n      assertEquals(0, ulog.getLogList(logDir).length);\n\n      createCore();\n\n      int start = 0;\n      int maxReq = 50;\n\n      LinkedList<Long> versions = new LinkedList<>();\n      addDocs(10, start, versions); start+=10;\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n      assertU(commit());\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      addDocs(10, start, versions);  start+=10;\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n      assertU(commit());\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      assertEquals(2, ulog.getLogList(logDir).length);\n\n      addDocs(105, start, versions);  start+=105;\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n      assertU(commit());\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      // previous two logs should be gone now\n      assertEquals(1, ulog.getLogList(logDir).length);\n\n      addDocs(1, start, versions);  start+=1;\n      h.close();\n      createCore();      // trigger recovery, make sure that tlog reference handling is correct\n\n      // test we can get versions while replay is happening\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      logReplay.release(1000);\n      assertTrue(logReplayFinish.tryAcquire(timeout, TimeUnit.SECONDS));\n\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      addDocs(105, start, versions);  start+=105;\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n      assertU(commit());\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      // previous logs should be gone now\n      assertEquals(1, ulog.getLogList(logDir).length);\n\n      //\n      // test that a corrupt tlog file doesn't stop us from coming up, or seeing versions before that tlog file.\n      //\n      addDocs(1, start, new LinkedList<Long>()); // don't add this to the versions list because we are going to lose it...\n      h.close();\n      files = ulog.getLogList(logDir);\n      Arrays.sort(files);\n      RandomAccessFile raf = new RandomAccessFile(new File(logDir, files[files.length-1]), \"rw\");\n      raf.writeChars(\"This is a trashed log file that really shouldn't work at all, but we'll see...\");\n      raf.close();\n\n      ignoreException(\"Failure to open existing\");\n      createCore();\n      // we should still be able to get the list of versions (not including the trashed log file)\n      assertJQ(req(\"qt\", \"/get\", \"getVersions\", \"\" + maxReq), \"/versions==\" + versions.subList(0, Math.min(maxReq, start)));\n      resetExceptionIgnores();\n\n    } finally {\n      DirectUpdateHandler2.commitOnClose = true;\n      UpdateLog.testing_logReplayHook = null;\n      UpdateLog.testing_logReplayFinishHook = null;\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testRemoveOldLogs() throws Exception {\n    try {\n      DirectUpdateHandler2.commitOnClose = false;\n      final Semaphore logReplay = new Semaphore(0);\n      final Semaphore logReplayFinish = new Semaphore(0);\n\n      UpdateLog.testing_logReplayHook = new Runnable() {\n        @Override\n        public void run() {\n          try {\n            assertTrue(logReplay.tryAcquire(timeout, TimeUnit.SECONDS));\n          } catch (Exception e) {\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      UpdateLog.testing_logReplayFinishHook = new Runnable() {\n        @Override\n        public void run() {\n          logReplayFinish.release();\n        }\n      };\n\n\n      clearIndex();\n      assertU(commit());\n\n      UpdateLog ulog = h.getCore().getUpdateHandler().getUpdateLog();\n      File logDir = new File(h.getCore().getUpdateHandler().getUpdateLog().getLogDir());\n\n      h.close();\n\n      String[] files = ulog.getLogList(logDir);\n      for (String file : files) {\n        new File(logDir, file).delete();\n      }\n\n      assertEquals(0, ulog.getLogList(logDir).length);\n\n      createCore();\n\n      int start = 0;\n      int maxReq = 50;\n\n      LinkedList<Long> versions = new LinkedList<>();\n      addDocs(10, start, versions); start+=10;\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n      assertU(commit());\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      addDocs(10, start, versions);  start+=10;\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n      assertU(commit());\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      assertEquals(2, ulog.getLogList(logDir).length);\n\n      addDocs(105, start, versions);  start+=105;\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n      assertU(commit());\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      // previous two logs should be gone now\n      assertEquals(1, ulog.getLogList(logDir).length);\n\n      addDocs(1, start, versions);  start+=1;\n      h.close();\n      createCore();      // trigger recovery, make sure that tlog reference handling is correct\n\n      // test we can get versions while replay is happening\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      logReplay.release(1000);\n      assertTrue(logReplayFinish.tryAcquire(timeout, TimeUnit.SECONDS));\n\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      addDocs(105, start, versions);  start+=105;\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n      assertU(commit());\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      // previous logs should be gone now\n      assertEquals(1, ulog.getLogList(logDir).length);\n\n      //\n      // test that a corrupt tlog file doesn't stop us from coming up, or seeing versions before that tlog file.\n      //\n      addDocs(1, start, new LinkedList<Long>()); // don't add this to the versions list because we are going to lose it...\n      h.close();\n      files = ulog.getLogList(logDir);\n      Arrays.sort(files);\n      RandomAccessFile raf = new RandomAccessFile(new File(logDir, files[files.length-1]), \"rw\");\n      raf.writeChars(\"This is a trashed log file that really shouldn't work at all, but we'll see...\");\n      raf.close();\n\n      ignoreException(\"Failure to open existing\");\n      createCore();\n      // we should still be able to get the list of versions (not including the trashed log file)\n      assertJQ(req(\"qt\", \"/get\", \"getVersions\", \"\" + maxReq), \"/versions==\" + versions.subList(0, Math.min(maxReq, start)));\n      resetExceptionIgnores();\n\n    } finally {\n      DirectUpdateHandler2.commitOnClose = true;\n      UpdateLog.testing_logReplayHook = null;\n      UpdateLog.testing_logReplayFinishHook = null;\n    }\n  }\n\n","bugFix":["2c007e7c4cf8c55bc2a5884e315123afaaeec87f"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6f3c1f22c5fe0011e187dac3151422365ae857f3","date":1425728437,"type":3,"author":"Ramkumar Aiyengar","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/search/TestRecovery#testRemoveOldLogs().mjava","pathOld":"solr/core/src/test/org/apache/solr/search/TestRecovery#testRemoveOldLogs().mjava","sourceNew":"  @Test\n  public void testRemoveOldLogs() throws Exception {\n    try {\n      DirectUpdateHandler2.commitOnClose = false;\n      final Semaphore logReplay = new Semaphore(0);\n      final Semaphore logReplayFinish = new Semaphore(0);\n\n      UpdateLog.testing_logReplayHook = new Runnable() {\n        @Override\n        public void run() {\n          try {\n            assertTrue(logReplay.tryAcquire(timeout, TimeUnit.SECONDS));\n          } catch (Exception e) {\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      UpdateLog.testing_logReplayFinishHook = new Runnable() {\n        @Override\n        public void run() {\n          logReplayFinish.release();\n        }\n      };\n\n\n      clearIndex();\n      assertU(commit());\n\n      UpdateLog ulog = h.getCore().getUpdateHandler().getUpdateLog();\n      File logDir = new File(h.getCore().getUpdateHandler().getUpdateLog().getLogDir());\n\n      h.close();\n\n      String[] files = ulog.getLogList(logDir);\n      for (String file : files) {\n        Files.delete(new File(logDir, file).toPath());\n      }\n\n      assertEquals(0, ulog.getLogList(logDir).length);\n\n      createCore();\n\n      int numIndexed = 0;\n      int maxReq = 200;\n\n      LinkedList<Long> versions = new LinkedList<>();\n\n      int docsPerBatch = 3;\n      // we don't expect to reach numRecordsToKeep as yet, so the bottleneck is still number of logs to keep\n      int expectedToRetain = ulog.getMaxNumLogsToKeep() * docsPerBatch;\n      int versExpected;\n\n      for (int i = 1; i <= ulog.getMaxNumLogsToKeep() + 2; i ++) {\n        addDocs(docsPerBatch, numIndexed, versions); numIndexed += docsPerBatch;\n        versExpected = Math.min(numIndexed, expectedToRetain + docsPerBatch); // not yet committed, so one more tlog could slip in\n        assertJQ(req(\"qt\", \"/get\", \"getVersions\", \"\" + maxReq), \"/versions==\" + versions.subList(0, Math.min(maxReq, versExpected)));\n        assertU(commit());\n        versExpected = Math.min(numIndexed, expectedToRetain);\n        assertJQ(req(\"qt\", \"/get\", \"getVersions\", \"\" + maxReq), \"/versions==\" + versions.subList(0, Math.min(maxReq, versExpected)));\n        assertEquals(Math.min(i, ulog.getMaxNumLogsToKeep()), ulog.getLogList(logDir).length);\n      }\n\n      docsPerBatch = ulog.getNumRecordsToKeep() + 20;\n      // about to commit a lot of docs, so numRecordsToKeep becomes the bottleneck\n      expectedToRetain = ulog.getNumRecordsToKeep();\n\n      addDocs(docsPerBatch, numIndexed, versions);  numIndexed+=docsPerBatch;\n      versExpected = Math.min(numIndexed, expectedToRetain);\n      assertJQ(req(\"qt\", \"/get\", \"getVersions\", \"\" + maxReq), \"/versions==\" + versions.subList(0, Math.min(maxReq, versExpected)));\n      assertU(commit());\n      expectedToRetain = expectedToRetain - 1; // we lose a log entry due to the commit record\n      versExpected = Math.min(numIndexed, expectedToRetain);\n      assertJQ(req(\"qt\", \"/get\", \"getVersions\", \"\" + maxReq), \"/versions==\" + versions.subList(0, Math.min(maxReq, versExpected)));\n\n      // previous logs should be gone now\n      assertEquals(1, ulog.getLogList(logDir).length);\n\n      addDocs(1, numIndexed, versions);  numIndexed+=1;\n      h.close();\n      createCore();      // trigger recovery, make sure that tlog reference handling is correct\n\n      // test we can get versions while replay is happening\n      assertJQ(req(\"qt\", \"/get\", \"getVersions\", \"\" + maxReq), \"/versions==\" + versions.subList(0, Math.min(maxReq, expectedToRetain)));\n\n      logReplay.release(1000);\n      assertTrue(logReplayFinish.tryAcquire(timeout, TimeUnit.SECONDS));\n\n      expectedToRetain = expectedToRetain - 1; // we lose a log entry due to the commit record made by recovery\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,expectedToRetain)));\n\n      docsPerBatch = ulog.getNumRecordsToKeep() + 20;\n      // about to commit a lot of docs, so numRecordsToKeep becomes the bottleneck\n      expectedToRetain = ulog.getNumRecordsToKeep();\n\n      addDocs(docsPerBatch, numIndexed, versions);  numIndexed+=docsPerBatch;\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,expectedToRetain)));\n      assertU(commit());\n      expectedToRetain = expectedToRetain - 1; // we lose a log entry due to the commit record\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,expectedToRetain)));\n\n      // previous logs should be gone now\n      assertEquals(1, ulog.getLogList(logDir).length);\n\n      //\n      // test that a corrupt tlog file doesn't stop us from coming up, or seeing versions before that tlog file.\n      //\n      addDocs(1, numIndexed, new LinkedList<Long>()); // don't add this to the versions list because we are going to lose it...\n      h.close();\n      files = ulog.getLogList(logDir);\n      Arrays.sort(files);\n      RandomAccessFile raf = new RandomAccessFile(new File(logDir, files[files.length-1]), \"rw\");\n      raf.writeChars(\"This is a trashed log file that really shouldn't work at all, but we'll see...\");\n      raf.close();\n\n      ignoreException(\"Failure to open existing\");\n      createCore();\n      // we should still be able to get the list of versions (not including the trashed log file)\n      assertJQ(req(\"qt\", \"/get\", \"getVersions\", \"\" + maxReq), \"/versions==\" + versions.subList(0, Math.min(maxReq, expectedToRetain)));\n      resetExceptionIgnores();\n\n    } finally {\n      DirectUpdateHandler2.commitOnClose = true;\n      UpdateLog.testing_logReplayHook = null;\n      UpdateLog.testing_logReplayFinishHook = null;\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testRemoveOldLogs() throws Exception {\n    try {\n      DirectUpdateHandler2.commitOnClose = false;\n      final Semaphore logReplay = new Semaphore(0);\n      final Semaphore logReplayFinish = new Semaphore(0);\n\n      UpdateLog.testing_logReplayHook = new Runnable() {\n        @Override\n        public void run() {\n          try {\n            assertTrue(logReplay.tryAcquire(timeout, TimeUnit.SECONDS));\n          } catch (Exception e) {\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      UpdateLog.testing_logReplayFinishHook = new Runnable() {\n        @Override\n        public void run() {\n          logReplayFinish.release();\n        }\n      };\n\n\n      clearIndex();\n      assertU(commit());\n\n      UpdateLog ulog = h.getCore().getUpdateHandler().getUpdateLog();\n      File logDir = new File(h.getCore().getUpdateHandler().getUpdateLog().getLogDir());\n\n      h.close();\n\n      String[] files = ulog.getLogList(logDir);\n      for (String file : files) {\n        Files.delete(new File(logDir, file).toPath());\n      }\n\n      assertEquals(0, ulog.getLogList(logDir).length);\n\n      createCore();\n\n      int start = 0;\n      int maxReq = 50;\n\n      LinkedList<Long> versions = new LinkedList<>();\n      addDocs(10, start, versions); start+=10;\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n      assertU(commit());\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      addDocs(10, start, versions);  start+=10;\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n      assertU(commit());\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      assertEquals(2, ulog.getLogList(logDir).length);\n\n      addDocs(105, start, versions);  start+=105;\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n      assertU(commit());\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      // previous two logs should be gone now\n      assertEquals(1, ulog.getLogList(logDir).length);\n\n      addDocs(1, start, versions);  start+=1;\n      h.close();\n      createCore();      // trigger recovery, make sure that tlog reference handling is correct\n\n      // test we can get versions while replay is happening\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      logReplay.release(1000);\n      assertTrue(logReplayFinish.tryAcquire(timeout, TimeUnit.SECONDS));\n\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      addDocs(105, start, versions);  start+=105;\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n      assertU(commit());\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      // previous logs should be gone now\n      assertEquals(1, ulog.getLogList(logDir).length);\n\n      //\n      // test that a corrupt tlog file doesn't stop us from coming up, or seeing versions before that tlog file.\n      //\n      addDocs(1, start, new LinkedList<Long>()); // don't add this to the versions list because we are going to lose it...\n      h.close();\n      files = ulog.getLogList(logDir);\n      Arrays.sort(files);\n      RandomAccessFile raf = new RandomAccessFile(new File(logDir, files[files.length-1]), \"rw\");\n      raf.writeChars(\"This is a trashed log file that really shouldn't work at all, but we'll see...\");\n      raf.close();\n\n      ignoreException(\"Failure to open existing\");\n      createCore();\n      // we should still be able to get the list of versions (not including the trashed log file)\n      assertJQ(req(\"qt\", \"/get\", \"getVersions\", \"\" + maxReq), \"/versions==\" + versions.subList(0, Math.min(maxReq, start)));\n      resetExceptionIgnores();\n\n    } finally {\n      DirectUpdateHandler2.commitOnClose = true;\n      UpdateLog.testing_logReplayHook = null;\n      UpdateLog.testing_logReplayFinishHook = null;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","date":1427779360,"type":3,"author":"Ryan Ernst","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/search/TestRecovery#testRemoveOldLogs().mjava","pathOld":"solr/core/src/test/org/apache/solr/search/TestRecovery#testRemoveOldLogs().mjava","sourceNew":"  @Test\n  public void testRemoveOldLogs() throws Exception {\n    try {\n      DirectUpdateHandler2.commitOnClose = false;\n      final Semaphore logReplay = new Semaphore(0);\n      final Semaphore logReplayFinish = new Semaphore(0);\n\n      UpdateLog.testing_logReplayHook = new Runnable() {\n        @Override\n        public void run() {\n          try {\n            assertTrue(logReplay.tryAcquire(timeout, TimeUnit.SECONDS));\n          } catch (Exception e) {\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      UpdateLog.testing_logReplayFinishHook = new Runnable() {\n        @Override\n        public void run() {\n          logReplayFinish.release();\n        }\n      };\n\n\n      clearIndex();\n      assertU(commit());\n\n      UpdateLog ulog = h.getCore().getUpdateHandler().getUpdateLog();\n      File logDir = new File(h.getCore().getUpdateHandler().getUpdateLog().getLogDir());\n\n      h.close();\n\n      String[] files = ulog.getLogList(logDir);\n      for (String file : files) {\n        Files.delete(new File(logDir, file).toPath());\n      }\n\n      assertEquals(0, ulog.getLogList(logDir).length);\n\n      createCore();\n\n      int numIndexed = 0;\n      int maxReq = 200;\n\n      LinkedList<Long> versions = new LinkedList<>();\n\n      int docsPerBatch = 3;\n      // we don't expect to reach numRecordsToKeep as yet, so the bottleneck is still number of logs to keep\n      int expectedToRetain = ulog.getMaxNumLogsToKeep() * docsPerBatch;\n      int versExpected;\n\n      for (int i = 1; i <= ulog.getMaxNumLogsToKeep() + 2; i ++) {\n        addDocs(docsPerBatch, numIndexed, versions); numIndexed += docsPerBatch;\n        versExpected = Math.min(numIndexed, expectedToRetain + docsPerBatch); // not yet committed, so one more tlog could slip in\n        assertJQ(req(\"qt\", \"/get\", \"getVersions\", \"\" + maxReq), \"/versions==\" + versions.subList(0, Math.min(maxReq, versExpected)));\n        assertU(commit());\n        versExpected = Math.min(numIndexed, expectedToRetain);\n        assertJQ(req(\"qt\", \"/get\", \"getVersions\", \"\" + maxReq), \"/versions==\" + versions.subList(0, Math.min(maxReq, versExpected)));\n        assertEquals(Math.min(i, ulog.getMaxNumLogsToKeep()), ulog.getLogList(logDir).length);\n      }\n\n      docsPerBatch = ulog.getNumRecordsToKeep() + 20;\n      // about to commit a lot of docs, so numRecordsToKeep becomes the bottleneck\n      expectedToRetain = ulog.getNumRecordsToKeep();\n\n      addDocs(docsPerBatch, numIndexed, versions);  numIndexed+=docsPerBatch;\n      versExpected = Math.min(numIndexed, expectedToRetain);\n      assertJQ(req(\"qt\", \"/get\", \"getVersions\", \"\" + maxReq), \"/versions==\" + versions.subList(0, Math.min(maxReq, versExpected)));\n      assertU(commit());\n      expectedToRetain = expectedToRetain - 1; // we lose a log entry due to the commit record\n      versExpected = Math.min(numIndexed, expectedToRetain);\n      assertJQ(req(\"qt\", \"/get\", \"getVersions\", \"\" + maxReq), \"/versions==\" + versions.subList(0, Math.min(maxReq, versExpected)));\n\n      // previous logs should be gone now\n      assertEquals(1, ulog.getLogList(logDir).length);\n\n      addDocs(1, numIndexed, versions);  numIndexed+=1;\n      h.close();\n      createCore();      // trigger recovery, make sure that tlog reference handling is correct\n\n      // test we can get versions while replay is happening\n      assertJQ(req(\"qt\", \"/get\", \"getVersions\", \"\" + maxReq), \"/versions==\" + versions.subList(0, Math.min(maxReq, expectedToRetain)));\n\n      logReplay.release(1000);\n      assertTrue(logReplayFinish.tryAcquire(timeout, TimeUnit.SECONDS));\n\n      expectedToRetain = expectedToRetain - 1; // we lose a log entry due to the commit record made by recovery\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,expectedToRetain)));\n\n      docsPerBatch = ulog.getNumRecordsToKeep() + 20;\n      // about to commit a lot of docs, so numRecordsToKeep becomes the bottleneck\n      expectedToRetain = ulog.getNumRecordsToKeep();\n\n      addDocs(docsPerBatch, numIndexed, versions);  numIndexed+=docsPerBatch;\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,expectedToRetain)));\n      assertU(commit());\n      expectedToRetain = expectedToRetain - 1; // we lose a log entry due to the commit record\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,expectedToRetain)));\n\n      // previous logs should be gone now\n      assertEquals(1, ulog.getLogList(logDir).length);\n\n      //\n      // test that a corrupt tlog file doesn't stop us from coming up, or seeing versions before that tlog file.\n      //\n      addDocs(1, numIndexed, new LinkedList<Long>()); // don't add this to the versions list because we are going to lose it...\n      h.close();\n      files = ulog.getLogList(logDir);\n      Arrays.sort(files);\n      RandomAccessFile raf = new RandomAccessFile(new File(logDir, files[files.length-1]), \"rw\");\n      raf.writeChars(\"This is a trashed log file that really shouldn't work at all, but we'll see...\");\n      raf.close();\n\n      ignoreException(\"Failure to open existing\");\n      createCore();\n      // we should still be able to get the list of versions (not including the trashed log file)\n      assertJQ(req(\"qt\", \"/get\", \"getVersions\", \"\" + maxReq), \"/versions==\" + versions.subList(0, Math.min(maxReq, expectedToRetain)));\n      resetExceptionIgnores();\n\n    } finally {\n      DirectUpdateHandler2.commitOnClose = true;\n      UpdateLog.testing_logReplayHook = null;\n      UpdateLog.testing_logReplayFinishHook = null;\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testRemoveOldLogs() throws Exception {\n    try {\n      DirectUpdateHandler2.commitOnClose = false;\n      final Semaphore logReplay = new Semaphore(0);\n      final Semaphore logReplayFinish = new Semaphore(0);\n\n      UpdateLog.testing_logReplayHook = new Runnable() {\n        @Override\n        public void run() {\n          try {\n            assertTrue(logReplay.tryAcquire(timeout, TimeUnit.SECONDS));\n          } catch (Exception e) {\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      UpdateLog.testing_logReplayFinishHook = new Runnable() {\n        @Override\n        public void run() {\n          logReplayFinish.release();\n        }\n      };\n\n\n      clearIndex();\n      assertU(commit());\n\n      UpdateLog ulog = h.getCore().getUpdateHandler().getUpdateLog();\n      File logDir = new File(h.getCore().getUpdateHandler().getUpdateLog().getLogDir());\n\n      h.close();\n\n      String[] files = ulog.getLogList(logDir);\n      for (String file : files) {\n        Files.delete(new File(logDir, file).toPath());\n      }\n\n      assertEquals(0, ulog.getLogList(logDir).length);\n\n      createCore();\n\n      int start = 0;\n      int maxReq = 50;\n\n      LinkedList<Long> versions = new LinkedList<>();\n      addDocs(10, start, versions); start+=10;\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n      assertU(commit());\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      addDocs(10, start, versions);  start+=10;\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n      assertU(commit());\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      assertEquals(2, ulog.getLogList(logDir).length);\n\n      addDocs(105, start, versions);  start+=105;\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n      assertU(commit());\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      // previous two logs should be gone now\n      assertEquals(1, ulog.getLogList(logDir).length);\n\n      addDocs(1, start, versions);  start+=1;\n      h.close();\n      createCore();      // trigger recovery, make sure that tlog reference handling is correct\n\n      // test we can get versions while replay is happening\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      logReplay.release(1000);\n      assertTrue(logReplayFinish.tryAcquire(timeout, TimeUnit.SECONDS));\n\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      addDocs(105, start, versions);  start+=105;\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n      assertU(commit());\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,start)));\n\n      // previous logs should be gone now\n      assertEquals(1, ulog.getLogList(logDir).length);\n\n      //\n      // test that a corrupt tlog file doesn't stop us from coming up, or seeing versions before that tlog file.\n      //\n      addDocs(1, start, new LinkedList<Long>()); // don't add this to the versions list because we are going to lose it...\n      h.close();\n      files = ulog.getLogList(logDir);\n      Arrays.sort(files);\n      RandomAccessFile raf = new RandomAccessFile(new File(logDir, files[files.length-1]), \"rw\");\n      raf.writeChars(\"This is a trashed log file that really shouldn't work at all, but we'll see...\");\n      raf.close();\n\n      ignoreException(\"Failure to open existing\");\n      createCore();\n      // we should still be able to get the list of versions (not including the trashed log file)\n      assertJQ(req(\"qt\", \"/get\", \"getVersions\", \"\" + maxReq), \"/versions==\" + versions.subList(0, Math.min(maxReq, start)));\n      resetExceptionIgnores();\n\n    } finally {\n      DirectUpdateHandler2.commitOnClose = true;\n      UpdateLog.testing_logReplayHook = null;\n      UpdateLog.testing_logReplayFinishHook = null;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3a0c04b71951333291abc7f317109a6a5957bd28","date":1457097827,"type":3,"author":"Noble Paul","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/search/TestRecovery#testRemoveOldLogs().mjava","pathOld":"solr/core/src/test/org/apache/solr/search/TestRecovery#testRemoveOldLogs().mjava","sourceNew":"  @Test\n  public void testRemoveOldLogs() throws Exception {\n    try {\n      DirectUpdateHandler2.commitOnClose = false;\n      final Semaphore logReplay = new Semaphore(0);\n      final Semaphore logReplayFinish = new Semaphore(0);\n\n      UpdateLog.testing_logReplayHook = () -> {\n        try {\n          assertTrue(logReplay.tryAcquire(timeout, TimeUnit.SECONDS));\n        } catch (Exception e) {\n          throw new RuntimeException(e);\n        }\n      };\n\n      UpdateLog.testing_logReplayFinishHook = () -> logReplayFinish.release();\n\n\n      clearIndex();\n      assertU(commit());\n\n      UpdateLog ulog = h.getCore().getUpdateHandler().getUpdateLog();\n      File logDir = new File(h.getCore().getUpdateHandler().getUpdateLog().getLogDir());\n\n      h.close();\n\n      String[] files = ulog.getLogList(logDir);\n      for (String file : files) {\n        Files.delete(new File(logDir, file).toPath());\n      }\n\n      assertEquals(0, ulog.getLogList(logDir).length);\n\n      createCore();\n\n      int numIndexed = 0;\n      int maxReq = 200;\n\n      LinkedList<Long> versions = new LinkedList<>();\n\n      int docsPerBatch = 3;\n      // we don't expect to reach numRecordsToKeep as yet, so the bottleneck is still number of logs to keep\n      int expectedToRetain = ulog.getMaxNumLogsToKeep() * docsPerBatch;\n      int versExpected;\n\n      for (int i = 1; i <= ulog.getMaxNumLogsToKeep() + 2; i ++) {\n        addDocs(docsPerBatch, numIndexed, versions); numIndexed += docsPerBatch;\n        versExpected = Math.min(numIndexed, expectedToRetain + docsPerBatch); // not yet committed, so one more tlog could slip in\n        assertJQ(req(\"qt\", \"/get\", \"getVersions\", \"\" + maxReq), \"/versions==\" + versions.subList(0, Math.min(maxReq, versExpected)));\n        assertU(commit());\n        versExpected = Math.min(numIndexed, expectedToRetain);\n        assertJQ(req(\"qt\", \"/get\", \"getVersions\", \"\" + maxReq), \"/versions==\" + versions.subList(0, Math.min(maxReq, versExpected)));\n        assertEquals(Math.min(i, ulog.getMaxNumLogsToKeep()), ulog.getLogList(logDir).length);\n      }\n\n      docsPerBatch = ulog.getNumRecordsToKeep() + 20;\n      // about to commit a lot of docs, so numRecordsToKeep becomes the bottleneck\n      expectedToRetain = ulog.getNumRecordsToKeep();\n\n      addDocs(docsPerBatch, numIndexed, versions);  numIndexed+=docsPerBatch;\n      versExpected = Math.min(numIndexed, expectedToRetain);\n      assertJQ(req(\"qt\", \"/get\", \"getVersions\", \"\" + maxReq), \"/versions==\" + versions.subList(0, Math.min(maxReq, versExpected)));\n      assertU(commit());\n      expectedToRetain = expectedToRetain - 1; // we lose a log entry due to the commit record\n      versExpected = Math.min(numIndexed, expectedToRetain);\n      assertJQ(req(\"qt\", \"/get\", \"getVersions\", \"\" + maxReq), \"/versions==\" + versions.subList(0, Math.min(maxReq, versExpected)));\n\n      // previous logs should be gone now\n      assertEquals(1, ulog.getLogList(logDir).length);\n\n      addDocs(1, numIndexed, versions);  numIndexed+=1;\n      h.close();\n      createCore();      // trigger recovery, make sure that tlog reference handling is correct\n\n      // test we can get versions while replay is happening\n      assertJQ(req(\"qt\", \"/get\", \"getVersions\", \"\" + maxReq), \"/versions==\" + versions.subList(0, Math.min(maxReq, expectedToRetain)));\n\n      logReplay.release(1000);\n      assertTrue(logReplayFinish.tryAcquire(timeout, TimeUnit.SECONDS));\n\n      expectedToRetain = expectedToRetain - 1; // we lose a log entry due to the commit record made by recovery\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,expectedToRetain)));\n\n      docsPerBatch = ulog.getNumRecordsToKeep() + 20;\n      // about to commit a lot of docs, so numRecordsToKeep becomes the bottleneck\n      expectedToRetain = ulog.getNumRecordsToKeep();\n\n      addDocs(docsPerBatch, numIndexed, versions);  numIndexed+=docsPerBatch;\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,expectedToRetain)));\n      assertU(commit());\n      expectedToRetain = expectedToRetain - 1; // we lose a log entry due to the commit record\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,expectedToRetain)));\n\n      // previous logs should be gone now\n      assertEquals(1, ulog.getLogList(logDir).length);\n\n      //\n      // test that a corrupt tlog file doesn't stop us from coming up, or seeing versions before that tlog file.\n      //\n      addDocs(1, numIndexed, new LinkedList<Long>()); // don't add this to the versions list because we are going to lose it...\n      h.close();\n      files = ulog.getLogList(logDir);\n      Arrays.sort(files);\n      RandomAccessFile raf = new RandomAccessFile(new File(logDir, files[files.length-1]), \"rw\");\n      raf.writeChars(\"This is a trashed log file that really shouldn't work at all, but we'll see...\");\n      raf.close();\n\n      ignoreException(\"Failure to open existing\");\n      createCore();\n      // we should still be able to get the list of versions (not including the trashed log file)\n      assertJQ(req(\"qt\", \"/get\", \"getVersions\", \"\" + maxReq), \"/versions==\" + versions.subList(0, Math.min(maxReq, expectedToRetain)));\n      resetExceptionIgnores();\n\n    } finally {\n      DirectUpdateHandler2.commitOnClose = true;\n      UpdateLog.testing_logReplayHook = null;\n      UpdateLog.testing_logReplayFinishHook = null;\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testRemoveOldLogs() throws Exception {\n    try {\n      DirectUpdateHandler2.commitOnClose = false;\n      final Semaphore logReplay = new Semaphore(0);\n      final Semaphore logReplayFinish = new Semaphore(0);\n\n      UpdateLog.testing_logReplayHook = new Runnable() {\n        @Override\n        public void run() {\n          try {\n            assertTrue(logReplay.tryAcquire(timeout, TimeUnit.SECONDS));\n          } catch (Exception e) {\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      UpdateLog.testing_logReplayFinishHook = new Runnable() {\n        @Override\n        public void run() {\n          logReplayFinish.release();\n        }\n      };\n\n\n      clearIndex();\n      assertU(commit());\n\n      UpdateLog ulog = h.getCore().getUpdateHandler().getUpdateLog();\n      File logDir = new File(h.getCore().getUpdateHandler().getUpdateLog().getLogDir());\n\n      h.close();\n\n      String[] files = ulog.getLogList(logDir);\n      for (String file : files) {\n        Files.delete(new File(logDir, file).toPath());\n      }\n\n      assertEquals(0, ulog.getLogList(logDir).length);\n\n      createCore();\n\n      int numIndexed = 0;\n      int maxReq = 200;\n\n      LinkedList<Long> versions = new LinkedList<>();\n\n      int docsPerBatch = 3;\n      // we don't expect to reach numRecordsToKeep as yet, so the bottleneck is still number of logs to keep\n      int expectedToRetain = ulog.getMaxNumLogsToKeep() * docsPerBatch;\n      int versExpected;\n\n      for (int i = 1; i <= ulog.getMaxNumLogsToKeep() + 2; i ++) {\n        addDocs(docsPerBatch, numIndexed, versions); numIndexed += docsPerBatch;\n        versExpected = Math.min(numIndexed, expectedToRetain + docsPerBatch); // not yet committed, so one more tlog could slip in\n        assertJQ(req(\"qt\", \"/get\", \"getVersions\", \"\" + maxReq), \"/versions==\" + versions.subList(0, Math.min(maxReq, versExpected)));\n        assertU(commit());\n        versExpected = Math.min(numIndexed, expectedToRetain);\n        assertJQ(req(\"qt\", \"/get\", \"getVersions\", \"\" + maxReq), \"/versions==\" + versions.subList(0, Math.min(maxReq, versExpected)));\n        assertEquals(Math.min(i, ulog.getMaxNumLogsToKeep()), ulog.getLogList(logDir).length);\n      }\n\n      docsPerBatch = ulog.getNumRecordsToKeep() + 20;\n      // about to commit a lot of docs, so numRecordsToKeep becomes the bottleneck\n      expectedToRetain = ulog.getNumRecordsToKeep();\n\n      addDocs(docsPerBatch, numIndexed, versions);  numIndexed+=docsPerBatch;\n      versExpected = Math.min(numIndexed, expectedToRetain);\n      assertJQ(req(\"qt\", \"/get\", \"getVersions\", \"\" + maxReq), \"/versions==\" + versions.subList(0, Math.min(maxReq, versExpected)));\n      assertU(commit());\n      expectedToRetain = expectedToRetain - 1; // we lose a log entry due to the commit record\n      versExpected = Math.min(numIndexed, expectedToRetain);\n      assertJQ(req(\"qt\", \"/get\", \"getVersions\", \"\" + maxReq), \"/versions==\" + versions.subList(0, Math.min(maxReq, versExpected)));\n\n      // previous logs should be gone now\n      assertEquals(1, ulog.getLogList(logDir).length);\n\n      addDocs(1, numIndexed, versions);  numIndexed+=1;\n      h.close();\n      createCore();      // trigger recovery, make sure that tlog reference handling is correct\n\n      // test we can get versions while replay is happening\n      assertJQ(req(\"qt\", \"/get\", \"getVersions\", \"\" + maxReq), \"/versions==\" + versions.subList(0, Math.min(maxReq, expectedToRetain)));\n\n      logReplay.release(1000);\n      assertTrue(logReplayFinish.tryAcquire(timeout, TimeUnit.SECONDS));\n\n      expectedToRetain = expectedToRetain - 1; // we lose a log entry due to the commit record made by recovery\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,expectedToRetain)));\n\n      docsPerBatch = ulog.getNumRecordsToKeep() + 20;\n      // about to commit a lot of docs, so numRecordsToKeep becomes the bottleneck\n      expectedToRetain = ulog.getNumRecordsToKeep();\n\n      addDocs(docsPerBatch, numIndexed, versions);  numIndexed+=docsPerBatch;\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,expectedToRetain)));\n      assertU(commit());\n      expectedToRetain = expectedToRetain - 1; // we lose a log entry due to the commit record\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,expectedToRetain)));\n\n      // previous logs should be gone now\n      assertEquals(1, ulog.getLogList(logDir).length);\n\n      //\n      // test that a corrupt tlog file doesn't stop us from coming up, or seeing versions before that tlog file.\n      //\n      addDocs(1, numIndexed, new LinkedList<Long>()); // don't add this to the versions list because we are going to lose it...\n      h.close();\n      files = ulog.getLogList(logDir);\n      Arrays.sort(files);\n      RandomAccessFile raf = new RandomAccessFile(new File(logDir, files[files.length-1]), \"rw\");\n      raf.writeChars(\"This is a trashed log file that really shouldn't work at all, but we'll see...\");\n      raf.close();\n\n      ignoreException(\"Failure to open existing\");\n      createCore();\n      // we should still be able to get the list of versions (not including the trashed log file)\n      assertJQ(req(\"qt\", \"/get\", \"getVersions\", \"\" + maxReq), \"/versions==\" + versions.subList(0, Math.min(maxReq, expectedToRetain)));\n      resetExceptionIgnores();\n\n    } finally {\n      DirectUpdateHandler2.commitOnClose = true;\n      UpdateLog.testing_logReplayHook = null;\n      UpdateLog.testing_logReplayFinishHook = null;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0d1071f88e3697a2eb3ed682c527f5c35859bad0","date":1565425271,"type":3,"author":"Munendra S N","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/search/TestRecovery#testRemoveOldLogs().mjava","pathOld":"solr/core/src/test/org/apache/solr/search/TestRecovery#testRemoveOldLogs().mjava","sourceNew":"  @Test\n  public void testRemoveOldLogs() throws Exception {\n    try {\n      DirectUpdateHandler2.commitOnClose = false;\n      final Semaphore logReplay = new Semaphore(0);\n      final Semaphore logReplayFinish = new Semaphore(0);\n\n      UpdateLog.testing_logReplayHook = () -> {\n        try {\n          assertTrue(logReplay.tryAcquire(timeout, TimeUnit.SECONDS));\n        } catch (Exception e) {\n          throw new RuntimeException(e);\n        }\n      };\n\n      UpdateLog.testing_logReplayFinishHook = () -> logReplayFinish.release();\n\n\n      clearIndex();\n      assertU(commit());\n\n      UpdateLog ulog = h.getCore().getUpdateHandler().getUpdateLog();\n      File logDir = new File(h.getCore().getUpdateHandler().getUpdateLog().getLogDir());\n\n      h.close();\n\n      String[] files = ulog.getLogList(logDir);\n      for (String file : files) {\n        Files.delete(new File(logDir, file).toPath());\n      }\n\n      assertEquals(0, ulog.getLogList(logDir).length);\n\n      createCore();\n\n      int numIndexed = 0;\n      int maxReq = 200;\n\n      LinkedList<Long> versions = new LinkedList<>();\n\n      int docsPerBatch = 3;\n      // we don't expect to reach numRecordsToKeep as yet, so the bottleneck is still number of logs to keep\n      int expectedToRetain = ulog.getMaxNumLogsToKeep() * docsPerBatch;\n      int versExpected;\n\n      for (int i = 1; i <= ulog.getMaxNumLogsToKeep() + 2; i ++) {\n        addDocs(docsPerBatch, numIndexed, versions); numIndexed += docsPerBatch;\n        versExpected = Math.min(numIndexed, expectedToRetain + docsPerBatch); // not yet committed, so one more tlog could slip in\n        assertJQ(req(\"qt\", \"/get\", \"getVersions\", \"\" + maxReq), \"/versions==\" + versions.subList(0, Math.min(maxReq, versExpected)));\n        assertU(commit());\n        versExpected = Math.min(numIndexed, expectedToRetain);\n        assertJQ(req(\"qt\", \"/get\", \"getVersions\", \"\" + maxReq), \"/versions==\" + versions.subList(0, Math.min(maxReq, versExpected)));\n        assertEquals(Math.min(i, ulog.getMaxNumLogsToKeep()), ulog.getLogList(logDir).length);\n      }\n\n      docsPerBatch = ulog.getNumRecordsToKeep() + 20;\n      // about to commit a lot of docs, so numRecordsToKeep becomes the bottleneck\n      expectedToRetain = ulog.getNumRecordsToKeep();\n\n      addDocs(docsPerBatch, numIndexed, versions);  numIndexed+=docsPerBatch;\n      versExpected = Math.min(numIndexed, expectedToRetain);\n      assertJQ(req(\"qt\", \"/get\", \"getVersions\", \"\" + maxReq), \"/versions==\" + versions.subList(0, Math.min(maxReq, versExpected)));\n      assertU(commit());\n      expectedToRetain = expectedToRetain - 1; // we lose a log entry due to the commit record\n      versExpected = Math.min(numIndexed, expectedToRetain);\n      assertJQ(req(\"qt\", \"/get\", \"getVersions\", \"\" + maxReq), \"/versions==\" + versions.subList(0, Math.min(maxReq, versExpected)));\n\n      // previous logs should be gone now\n      assertEquals(1, ulog.getLogList(logDir).length);\n\n      addDocs(1, numIndexed, versions);  numIndexed+=1;\n      h.close();\n      createCore();      // trigger recovery, make sure that tlog reference handling is correct\n\n      // test we can get versions while replay is happening\n      assertJQ(req(\"qt\", \"/get\", \"getVersions\", \"\" + maxReq), \"/versions==\" + versions.subList(0, Math.min(maxReq, expectedToRetain)));\n\n      logReplay.release(1000);\n      assertTrue(logReplayFinish.tryAcquire(timeout, TimeUnit.SECONDS));\n\n      expectedToRetain = expectedToRetain - 1; // we lose a log entry due to the commit record made by recovery\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,expectedToRetain)));\n\n      docsPerBatch = ulog.getNumRecordsToKeep() + 20;\n      // about to commit a lot of docs, so numRecordsToKeep becomes the bottleneck\n      expectedToRetain = ulog.getNumRecordsToKeep();\n\n      addDocs(docsPerBatch, numIndexed, versions);  numIndexed+=docsPerBatch;\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,expectedToRetain)));\n      assertU(commit());\n      expectedToRetain = expectedToRetain - 1; // we lose a log entry due to the commit record\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,expectedToRetain)));\n\n      // previous logs should be gone now\n      assertEquals(1, ulog.getLogList(logDir).length);\n\n      //\n      // test that a corrupt tlog file doesn't stop us from coming up, or seeing versions before that tlog file.\n      //\n      addDocs(1, numIndexed, new LinkedList<Long>()); // don't add this to the versions list because we are going to lose it...\n      h.close();\n      files = ulog.getLogList(logDir);\n      Arrays.sort(files);\n      try (RandomAccessFile raf = new RandomAccessFile(new File(logDir, files[files.length - 1]), \"rw\")) {\n        raf.writeChars(\"This is a trashed log file that really shouldn't work at all, but we'll see...\");\n      }\n\n      ignoreException(\"Failure to open existing\");\n      createCore();\n      // we should still be able to get the list of versions (not including the trashed log file)\n      assertJQ(req(\"qt\", \"/get\", \"getVersions\", \"\" + maxReq), \"/versions==\" + versions.subList(0, Math.min(maxReq, expectedToRetain)));\n      resetExceptionIgnores();\n\n    } finally {\n      DirectUpdateHandler2.commitOnClose = true;\n      UpdateLog.testing_logReplayHook = null;\n      UpdateLog.testing_logReplayFinishHook = null;\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testRemoveOldLogs() throws Exception {\n    try {\n      DirectUpdateHandler2.commitOnClose = false;\n      final Semaphore logReplay = new Semaphore(0);\n      final Semaphore logReplayFinish = new Semaphore(0);\n\n      UpdateLog.testing_logReplayHook = () -> {\n        try {\n          assertTrue(logReplay.tryAcquire(timeout, TimeUnit.SECONDS));\n        } catch (Exception e) {\n          throw new RuntimeException(e);\n        }\n      };\n\n      UpdateLog.testing_logReplayFinishHook = () -> logReplayFinish.release();\n\n\n      clearIndex();\n      assertU(commit());\n\n      UpdateLog ulog = h.getCore().getUpdateHandler().getUpdateLog();\n      File logDir = new File(h.getCore().getUpdateHandler().getUpdateLog().getLogDir());\n\n      h.close();\n\n      String[] files = ulog.getLogList(logDir);\n      for (String file : files) {\n        Files.delete(new File(logDir, file).toPath());\n      }\n\n      assertEquals(0, ulog.getLogList(logDir).length);\n\n      createCore();\n\n      int numIndexed = 0;\n      int maxReq = 200;\n\n      LinkedList<Long> versions = new LinkedList<>();\n\n      int docsPerBatch = 3;\n      // we don't expect to reach numRecordsToKeep as yet, so the bottleneck is still number of logs to keep\n      int expectedToRetain = ulog.getMaxNumLogsToKeep() * docsPerBatch;\n      int versExpected;\n\n      for (int i = 1; i <= ulog.getMaxNumLogsToKeep() + 2; i ++) {\n        addDocs(docsPerBatch, numIndexed, versions); numIndexed += docsPerBatch;\n        versExpected = Math.min(numIndexed, expectedToRetain + docsPerBatch); // not yet committed, so one more tlog could slip in\n        assertJQ(req(\"qt\", \"/get\", \"getVersions\", \"\" + maxReq), \"/versions==\" + versions.subList(0, Math.min(maxReq, versExpected)));\n        assertU(commit());\n        versExpected = Math.min(numIndexed, expectedToRetain);\n        assertJQ(req(\"qt\", \"/get\", \"getVersions\", \"\" + maxReq), \"/versions==\" + versions.subList(0, Math.min(maxReq, versExpected)));\n        assertEquals(Math.min(i, ulog.getMaxNumLogsToKeep()), ulog.getLogList(logDir).length);\n      }\n\n      docsPerBatch = ulog.getNumRecordsToKeep() + 20;\n      // about to commit a lot of docs, so numRecordsToKeep becomes the bottleneck\n      expectedToRetain = ulog.getNumRecordsToKeep();\n\n      addDocs(docsPerBatch, numIndexed, versions);  numIndexed+=docsPerBatch;\n      versExpected = Math.min(numIndexed, expectedToRetain);\n      assertJQ(req(\"qt\", \"/get\", \"getVersions\", \"\" + maxReq), \"/versions==\" + versions.subList(0, Math.min(maxReq, versExpected)));\n      assertU(commit());\n      expectedToRetain = expectedToRetain - 1; // we lose a log entry due to the commit record\n      versExpected = Math.min(numIndexed, expectedToRetain);\n      assertJQ(req(\"qt\", \"/get\", \"getVersions\", \"\" + maxReq), \"/versions==\" + versions.subList(0, Math.min(maxReq, versExpected)));\n\n      // previous logs should be gone now\n      assertEquals(1, ulog.getLogList(logDir).length);\n\n      addDocs(1, numIndexed, versions);  numIndexed+=1;\n      h.close();\n      createCore();      // trigger recovery, make sure that tlog reference handling is correct\n\n      // test we can get versions while replay is happening\n      assertJQ(req(\"qt\", \"/get\", \"getVersions\", \"\" + maxReq), \"/versions==\" + versions.subList(0, Math.min(maxReq, expectedToRetain)));\n\n      logReplay.release(1000);\n      assertTrue(logReplayFinish.tryAcquire(timeout, TimeUnit.SECONDS));\n\n      expectedToRetain = expectedToRetain - 1; // we lose a log entry due to the commit record made by recovery\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,expectedToRetain)));\n\n      docsPerBatch = ulog.getNumRecordsToKeep() + 20;\n      // about to commit a lot of docs, so numRecordsToKeep becomes the bottleneck\n      expectedToRetain = ulog.getNumRecordsToKeep();\n\n      addDocs(docsPerBatch, numIndexed, versions);  numIndexed+=docsPerBatch;\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,expectedToRetain)));\n      assertU(commit());\n      expectedToRetain = expectedToRetain - 1; // we lose a log entry due to the commit record\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,expectedToRetain)));\n\n      // previous logs should be gone now\n      assertEquals(1, ulog.getLogList(logDir).length);\n\n      //\n      // test that a corrupt tlog file doesn't stop us from coming up, or seeing versions before that tlog file.\n      //\n      addDocs(1, numIndexed, new LinkedList<Long>()); // don't add this to the versions list because we are going to lose it...\n      h.close();\n      files = ulog.getLogList(logDir);\n      Arrays.sort(files);\n      RandomAccessFile raf = new RandomAccessFile(new File(logDir, files[files.length-1]), \"rw\");\n      raf.writeChars(\"This is a trashed log file that really shouldn't work at all, but we'll see...\");\n      raf.close();\n\n      ignoreException(\"Failure to open existing\");\n      createCore();\n      // we should still be able to get the list of versions (not including the trashed log file)\n      assertJQ(req(\"qt\", \"/get\", \"getVersions\", \"\" + maxReq), \"/versions==\" + versions.subList(0, Math.min(maxReq, expectedToRetain)));\n      resetExceptionIgnores();\n\n    } finally {\n      DirectUpdateHandler2.commitOnClose = true;\n      UpdateLog.testing_logReplayHook = null;\n      UpdateLog.testing_logReplayFinishHook = null;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b6a0ad05ae2af8aa028b1a6099a8222fad0bc8c1","date":1579200426,"type":3,"author":"Chris Hostetter","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/search/TestRecovery#testRemoveOldLogs().mjava","pathOld":"solr/core/src/test/org/apache/solr/search/TestRecovery#testRemoveOldLogs().mjava","sourceNew":"  @Test\n  public void testRemoveOldLogs() throws Exception {\n    try {\n      TestInjection.skipIndexWriterCommitOnClose = true;\n      final Semaphore logReplay = new Semaphore(0);\n      final Semaphore logReplayFinish = new Semaphore(0);\n\n      UpdateLog.testing_logReplayHook = () -> {\n        try {\n          assertTrue(logReplay.tryAcquire(timeout, TimeUnit.SECONDS));\n        } catch (Exception e) {\n          throw new RuntimeException(e);\n        }\n      };\n\n      UpdateLog.testing_logReplayFinishHook = () -> logReplayFinish.release();\n\n\n      clearIndex();\n      assertU(commit());\n\n      UpdateLog ulog = h.getCore().getUpdateHandler().getUpdateLog();\n      File logDir = new File(h.getCore().getUpdateHandler().getUpdateLog().getLogDir());\n\n      h.close();\n\n      String[] files = ulog.getLogList(logDir);\n      for (String file : files) {\n        Files.delete(new File(logDir, file).toPath());\n      }\n\n      assertEquals(0, ulog.getLogList(logDir).length);\n\n      createCore();\n\n      int numIndexed = 0;\n      int maxReq = 200;\n\n      LinkedList<Long> versions = new LinkedList<>();\n\n      int docsPerBatch = 3;\n      // we don't expect to reach numRecordsToKeep as yet, so the bottleneck is still number of logs to keep\n      int expectedToRetain = ulog.getMaxNumLogsToKeep() * docsPerBatch;\n      int versExpected;\n\n      for (int i = 1; i <= ulog.getMaxNumLogsToKeep() + 2; i ++) {\n        addDocs(docsPerBatch, numIndexed, versions); numIndexed += docsPerBatch;\n        versExpected = Math.min(numIndexed, expectedToRetain + docsPerBatch); // not yet committed, so one more tlog could slip in\n        assertJQ(req(\"qt\", \"/get\", \"getVersions\", \"\" + maxReq), \"/versions==\" + versions.subList(0, Math.min(maxReq, versExpected)));\n        assertU(commit());\n        versExpected = Math.min(numIndexed, expectedToRetain);\n        assertJQ(req(\"qt\", \"/get\", \"getVersions\", \"\" + maxReq), \"/versions==\" + versions.subList(0, Math.min(maxReq, versExpected)));\n        assertEquals(Math.min(i, ulog.getMaxNumLogsToKeep()), ulog.getLogList(logDir).length);\n      }\n\n      docsPerBatch = ulog.getNumRecordsToKeep() + 20;\n      // about to commit a lot of docs, so numRecordsToKeep becomes the bottleneck\n      expectedToRetain = ulog.getNumRecordsToKeep();\n\n      addDocs(docsPerBatch, numIndexed, versions);  numIndexed+=docsPerBatch;\n      versExpected = Math.min(numIndexed, expectedToRetain);\n      assertJQ(req(\"qt\", \"/get\", \"getVersions\", \"\" + maxReq), \"/versions==\" + versions.subList(0, Math.min(maxReq, versExpected)));\n      assertU(commit());\n      expectedToRetain = expectedToRetain - 1; // we lose a log entry due to the commit record\n      versExpected = Math.min(numIndexed, expectedToRetain);\n      assertJQ(req(\"qt\", \"/get\", \"getVersions\", \"\" + maxReq), \"/versions==\" + versions.subList(0, Math.min(maxReq, versExpected)));\n\n      // previous logs should be gone now\n      assertEquals(1, ulog.getLogList(logDir).length);\n\n      addDocs(1, numIndexed, versions);  numIndexed+=1;\n      h.close();\n      createCore();      // trigger recovery, make sure that tlog reference handling is correct\n\n      // test we can get versions while replay is happening\n      assertJQ(req(\"qt\", \"/get\", \"getVersions\", \"\" + maxReq), \"/versions==\" + versions.subList(0, Math.min(maxReq, expectedToRetain)));\n\n      logReplay.release(1000);\n      assertTrue(logReplayFinish.tryAcquire(timeout, TimeUnit.SECONDS));\n\n      expectedToRetain = expectedToRetain - 1; // we lose a log entry due to the commit record made by recovery\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,expectedToRetain)));\n\n      docsPerBatch = ulog.getNumRecordsToKeep() + 20;\n      // about to commit a lot of docs, so numRecordsToKeep becomes the bottleneck\n      expectedToRetain = ulog.getNumRecordsToKeep();\n\n      addDocs(docsPerBatch, numIndexed, versions);  numIndexed+=docsPerBatch;\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,expectedToRetain)));\n      assertU(commit());\n      expectedToRetain = expectedToRetain - 1; // we lose a log entry due to the commit record\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,expectedToRetain)));\n\n      // previous logs should be gone now\n      assertEquals(1, ulog.getLogList(logDir).length);\n\n      //\n      // test that a corrupt tlog file doesn't stop us from coming up, or seeing versions before that tlog file.\n      //\n      addDocs(1, numIndexed, new LinkedList<Long>()); // don't add this to the versions list because we are going to lose it...\n      h.close();\n      files = ulog.getLogList(logDir);\n      Arrays.sort(files);\n      try (RandomAccessFile raf = new RandomAccessFile(new File(logDir, files[files.length - 1]), \"rw\")) {\n        raf.writeChars(\"This is a trashed log file that really shouldn't work at all, but we'll see...\");\n      }\n\n      ignoreException(\"Failure to open existing\");\n      createCore();\n      // we should still be able to get the list of versions (not including the trashed log file)\n      assertJQ(req(\"qt\", \"/get\", \"getVersions\", \"\" + maxReq), \"/versions==\" + versions.subList(0, Math.min(maxReq, expectedToRetain)));\n      resetExceptionIgnores();\n\n    } finally {\n      UpdateLog.testing_logReplayHook = null;\n      UpdateLog.testing_logReplayFinishHook = null;\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testRemoveOldLogs() throws Exception {\n    try {\n      DirectUpdateHandler2.commitOnClose = false;\n      final Semaphore logReplay = new Semaphore(0);\n      final Semaphore logReplayFinish = new Semaphore(0);\n\n      UpdateLog.testing_logReplayHook = () -> {\n        try {\n          assertTrue(logReplay.tryAcquire(timeout, TimeUnit.SECONDS));\n        } catch (Exception e) {\n          throw new RuntimeException(e);\n        }\n      };\n\n      UpdateLog.testing_logReplayFinishHook = () -> logReplayFinish.release();\n\n\n      clearIndex();\n      assertU(commit());\n\n      UpdateLog ulog = h.getCore().getUpdateHandler().getUpdateLog();\n      File logDir = new File(h.getCore().getUpdateHandler().getUpdateLog().getLogDir());\n\n      h.close();\n\n      String[] files = ulog.getLogList(logDir);\n      for (String file : files) {\n        Files.delete(new File(logDir, file).toPath());\n      }\n\n      assertEquals(0, ulog.getLogList(logDir).length);\n\n      createCore();\n\n      int numIndexed = 0;\n      int maxReq = 200;\n\n      LinkedList<Long> versions = new LinkedList<>();\n\n      int docsPerBatch = 3;\n      // we don't expect to reach numRecordsToKeep as yet, so the bottleneck is still number of logs to keep\n      int expectedToRetain = ulog.getMaxNumLogsToKeep() * docsPerBatch;\n      int versExpected;\n\n      for (int i = 1; i <= ulog.getMaxNumLogsToKeep() + 2; i ++) {\n        addDocs(docsPerBatch, numIndexed, versions); numIndexed += docsPerBatch;\n        versExpected = Math.min(numIndexed, expectedToRetain + docsPerBatch); // not yet committed, so one more tlog could slip in\n        assertJQ(req(\"qt\", \"/get\", \"getVersions\", \"\" + maxReq), \"/versions==\" + versions.subList(0, Math.min(maxReq, versExpected)));\n        assertU(commit());\n        versExpected = Math.min(numIndexed, expectedToRetain);\n        assertJQ(req(\"qt\", \"/get\", \"getVersions\", \"\" + maxReq), \"/versions==\" + versions.subList(0, Math.min(maxReq, versExpected)));\n        assertEquals(Math.min(i, ulog.getMaxNumLogsToKeep()), ulog.getLogList(logDir).length);\n      }\n\n      docsPerBatch = ulog.getNumRecordsToKeep() + 20;\n      // about to commit a lot of docs, so numRecordsToKeep becomes the bottleneck\n      expectedToRetain = ulog.getNumRecordsToKeep();\n\n      addDocs(docsPerBatch, numIndexed, versions);  numIndexed+=docsPerBatch;\n      versExpected = Math.min(numIndexed, expectedToRetain);\n      assertJQ(req(\"qt\", \"/get\", \"getVersions\", \"\" + maxReq), \"/versions==\" + versions.subList(0, Math.min(maxReq, versExpected)));\n      assertU(commit());\n      expectedToRetain = expectedToRetain - 1; // we lose a log entry due to the commit record\n      versExpected = Math.min(numIndexed, expectedToRetain);\n      assertJQ(req(\"qt\", \"/get\", \"getVersions\", \"\" + maxReq), \"/versions==\" + versions.subList(0, Math.min(maxReq, versExpected)));\n\n      // previous logs should be gone now\n      assertEquals(1, ulog.getLogList(logDir).length);\n\n      addDocs(1, numIndexed, versions);  numIndexed+=1;\n      h.close();\n      createCore();      // trigger recovery, make sure that tlog reference handling is correct\n\n      // test we can get versions while replay is happening\n      assertJQ(req(\"qt\", \"/get\", \"getVersions\", \"\" + maxReq), \"/versions==\" + versions.subList(0, Math.min(maxReq, expectedToRetain)));\n\n      logReplay.release(1000);\n      assertTrue(logReplayFinish.tryAcquire(timeout, TimeUnit.SECONDS));\n\n      expectedToRetain = expectedToRetain - 1; // we lose a log entry due to the commit record made by recovery\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,expectedToRetain)));\n\n      docsPerBatch = ulog.getNumRecordsToKeep() + 20;\n      // about to commit a lot of docs, so numRecordsToKeep becomes the bottleneck\n      expectedToRetain = ulog.getNumRecordsToKeep();\n\n      addDocs(docsPerBatch, numIndexed, versions);  numIndexed+=docsPerBatch;\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,expectedToRetain)));\n      assertU(commit());\n      expectedToRetain = expectedToRetain - 1; // we lose a log entry due to the commit record\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"\"+maxReq), \"/versions==\" + versions.subList(0,Math.min(maxReq,expectedToRetain)));\n\n      // previous logs should be gone now\n      assertEquals(1, ulog.getLogList(logDir).length);\n\n      //\n      // test that a corrupt tlog file doesn't stop us from coming up, or seeing versions before that tlog file.\n      //\n      addDocs(1, numIndexed, new LinkedList<Long>()); // don't add this to the versions list because we are going to lose it...\n      h.close();\n      files = ulog.getLogList(logDir);\n      Arrays.sort(files);\n      try (RandomAccessFile raf = new RandomAccessFile(new File(logDir, files[files.length - 1]), \"rw\")) {\n        raf.writeChars(\"This is a trashed log file that really shouldn't work at all, but we'll see...\");\n      }\n\n      ignoreException(\"Failure to open existing\");\n      createCore();\n      // we should still be able to get the list of versions (not including the trashed log file)\n      assertJQ(req(\"qt\", \"/get\", \"getVersions\", \"\" + maxReq), \"/versions==\" + versions.subList(0, Math.min(maxReq, expectedToRetain)));\n      resetExceptionIgnores();\n\n    } finally {\n      DirectUpdateHandler2.commitOnClose = true;\n      UpdateLog.testing_logReplayHook = null;\n      UpdateLog.testing_logReplayFinishHook = null;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["849494cf2f3a96af5c8c84995108ddd8456fcd04"],"37a0f60745e53927c4c876cfe5b5a58170f0646c":["2c007e7c4cf8c55bc2a5884e315123afaaeec87f","849494cf2f3a96af5c8c84995108ddd8456fcd04"],"a3c68e20c73359a10cf3eb4a35c9fa7ab1f3c30d":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","2c007e7c4cf8c55bc2a5884e315123afaaeec87f"],"6f3c1f22c5fe0011e187dac3151422365ae857f3":["cbc3688252d4a8045d69a164236b2cf87b721f17"],"b6a0ad05ae2af8aa028b1a6099a8222fad0bc8c1":["0d1071f88e3697a2eb3ed682c527f5c35859bad0"],"3a0c04b71951333291abc7f317109a6a5957bd28":["6f3c1f22c5fe0011e187dac3151422365ae857f3"],"849494cf2f3a96af5c8c84995108ddd8456fcd04":["2c007e7c4cf8c55bc2a5884e315123afaaeec87f"],"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae":["cbc3688252d4a8045d69a164236b2cf87b721f17","6f3c1f22c5fe0011e187dac3151422365ae857f3"],"0d22ac6a4146774c1bc8400160fc0b6150294e92":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","2c007e7c4cf8c55bc2a5884e315123afaaeec87f"],"cbc3688252d4a8045d69a164236b2cf87b721f17":["634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"2c007e7c4cf8c55bc2a5884e315123afaaeec87f":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"0d1071f88e3697a2eb3ed682c527f5c35859bad0":["3a0c04b71951333291abc7f317109a6a5957bd28"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["b6a0ad05ae2af8aa028b1a6099a8222fad0bc8c1"]},"commit2Childs":{"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["cbc3688252d4a8045d69a164236b2cf87b721f17"],"37a0f60745e53927c4c876cfe5b5a58170f0646c":[],"a3c68e20c73359a10cf3eb4a35c9fa7ab1f3c30d":[],"6f3c1f22c5fe0011e187dac3151422365ae857f3":["3a0c04b71951333291abc7f317109a6a5957bd28","a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae"],"b6a0ad05ae2af8aa028b1a6099a8222fad0bc8c1":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"3a0c04b71951333291abc7f317109a6a5957bd28":["0d1071f88e3697a2eb3ed682c527f5c35859bad0"],"849494cf2f3a96af5c8c84995108ddd8456fcd04":["634f330c54fd3f9f491d52036dc3f40b4f4d8934","37a0f60745e53927c4c876cfe5b5a58170f0646c"],"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae":[],"0d22ac6a4146774c1bc8400160fc0b6150294e92":[],"cbc3688252d4a8045d69a164236b2cf87b721f17":["6f3c1f22c5fe0011e187dac3151422365ae857f3","a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["a3c68e20c73359a10cf3eb4a35c9fa7ab1f3c30d","0d22ac6a4146774c1bc8400160fc0b6150294e92","2c007e7c4cf8c55bc2a5884e315123afaaeec87f"],"2c007e7c4cf8c55bc2a5884e315123afaaeec87f":["37a0f60745e53927c4c876cfe5b5a58170f0646c","a3c68e20c73359a10cf3eb4a35c9fa7ab1f3c30d","849494cf2f3a96af5c8c84995108ddd8456fcd04","0d22ac6a4146774c1bc8400160fc0b6150294e92"],"0d1071f88e3697a2eb3ed682c527f5c35859bad0":["b6a0ad05ae2af8aa028b1a6099a8222fad0bc8c1"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["37a0f60745e53927c4c876cfe5b5a58170f0646c","a3c68e20c73359a10cf3eb4a35c9fa7ab1f3c30d","a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","0d22ac6a4146774c1bc8400160fc0b6150294e92","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}