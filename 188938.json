{"path":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggester#build(TermFreqPayloadIterator).mjava","commits":[{"id":"ada2f7352a7f964fe49bccd13227c4ec38563d39","date":1381659982,"type":1,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggester#build(TermFreqPayloadIterator).mjava","pathOld":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggester#build(TermFreqIterator).mjava","sourceNew":"  @Override\n  public void build(TermFreqPayloadIterator iter) throws IOException {\n\n    if (searcher != null) {\n      searcher.getIndexReader().close();\n      searcher = null;\n    }\n\n\n    Directory dirTmp = getDirectory(new File(indexPath.toString() + \".tmp\"));\n\n    IndexWriter w = null;\n    IndexWriter w2 = null;\n    AtomicReader r = null;\n    boolean success = false;\n    try {\n      Analyzer gramAnalyzer = new AnalyzerWrapper(Analyzer.PER_FIELD_REUSE_STRATEGY) {\n          @Override\n          protected Analyzer getWrappedAnalyzer(String fieldName) {\n            return indexAnalyzer;\n          }\n\n          @Override\n          protected TokenStreamComponents wrapComponents(String fieldName, TokenStreamComponents components) {\n            if (fieldName.equals(\"textgrams\") && minPrefixChars > 0) {\n              return new TokenStreamComponents(components.getTokenizer(),\n                                               new EdgeNGramTokenFilter(matchVersion,\n                                                                        components.getTokenStream(),\n                                                                        1, minPrefixChars));\n            } else {\n              return components;\n            }\n          }\n        };\n\n      w = new IndexWriter(dirTmp,\n                          getIndexWriterConfig(matchVersion, gramAnalyzer));\n      BytesRef text;\n      Document doc = new Document();\n      FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n      ft.setIndexOptions(IndexOptions.DOCS_ONLY);\n      ft.setOmitNorms(true);\n      Field textField = new Field(TEXT_FIELD_NAME, \"\", ft);\n      doc.add(textField);\n\n      Field textGramField = new Field(\"textgrams\", \"\", ft);\n      doc.add(textGramField);\n\n      Field textDVField = new BinaryDocValuesField(TEXT_FIELD_NAME, new BytesRef());\n      doc.add(textDVField);\n\n      // TODO: use threads...?\n      Field weightField = new NumericDocValuesField(\"weight\", 0);\n      doc.add(weightField);\n\n      Field payloadField;\n      if (iter.hasPayloads()) {\n        payloadField = new BinaryDocValuesField(\"payloads\", new BytesRef());\n        doc.add(payloadField);\n      } else {\n        payloadField = null;\n      }\n\n      //long t0 = System.nanoTime();\n      while ((text = iter.next()) != null) {\n        String textString = text.utf8ToString();\n        textField.setStringValue(textString);\n        textGramField.setStringValue(textString);\n        textDVField.setBytesValue(text);\n        weightField.setLongValue(iter.weight());\n        if (iter.hasPayloads()) {\n          payloadField.setBytesValue(iter.payload());\n        }\n        w.addDocument(doc);\n      }\n      //System.out.println(\"initial indexing time: \" + ((System.nanoTime()-t0)/1000000) + \" msec\");\n\n      r = SlowCompositeReaderWrapper.wrap(DirectoryReader.open(w, false));\n      //long t1 = System.nanoTime();\n      w.rollback();\n\n      final int maxDoc = r.maxDoc();\n\n      final NumericDocValues weights = r.getNumericDocValues(\"weight\");\n\n      final Sorter.DocComparator comparator = new Sorter.DocComparator() {\n          @Override\n          public int compare(int docID1, int docID2) {\n            final long v1 = weights.get(docID1);\n            final long v2 = weights.get(docID2);\n            // Reverse sort (highest weight first);\n            // java7 only:\n            //return Long.compare(v2, v1);\n            if (v1 > v2) {\n              return -1;\n            } else if (v1 < v2) {\n              return 1;\n            } else {\n              return 0;\n            }\n          }\n        };\n\n      r = SortingAtomicReader.wrap(r, new Sorter() {\n          @Override\n          public Sorter.DocMap sort(AtomicReader reader) throws IOException {\n            return Sorter.sort(maxDoc, comparator);\n          }\n\n          @Override\n          public String getID() {\n            return \"Weight\";\n          }\n        });\n      \n      w2 = new IndexWriter(dir,\n                           getIndexWriterConfig(matchVersion, indexAnalyzer));\n      w2.addIndexes(new IndexReader[] {r});\n      r.close();\n\n      //System.out.println(\"sort time: \" + ((System.nanoTime()-t1)/1000000) + \" msec\");\n\n      searcher = new IndexSearcher(DirectoryReader.open(w2, false));\n      w2.close();\n\n      payloadsDV = MultiDocValues.getBinaryValues(searcher.getIndexReader(), \"payloads\");\n      weightsDV = MultiDocValues.getNumericValues(searcher.getIndexReader(), \"weight\");\n      textDV = MultiDocValues.getBinaryValues(searcher.getIndexReader(), TEXT_FIELD_NAME);\n      assert textDV != null;\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(w, w2, r, dirTmp);\n      } else {\n        IOUtils.closeWhileHandlingException(w, w2, r, dirTmp);\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  public void build(TermFreqIterator iter) throws IOException {\n\n    if (searcher != null) {\n      searcher.getIndexReader().close();\n      searcher = null;\n    }\n\n    TermFreqPayloadIterator payloads;\n    if (iter instanceof TermFreqPayloadIterator) {\n      payloads = (TermFreqPayloadIterator) iter;\n    } else {\n      payloads = null;\n    }\n    Directory dirTmp = getDirectory(new File(indexPath.toString() + \".tmp\"));\n\n    IndexWriter w = null;\n    IndexWriter w2 = null;\n    AtomicReader r = null;\n    boolean success = false;\n    try {\n      Analyzer gramAnalyzer = new AnalyzerWrapper(Analyzer.PER_FIELD_REUSE_STRATEGY) {\n          @Override\n          protected Analyzer getWrappedAnalyzer(String fieldName) {\n            return indexAnalyzer;\n          }\n\n          @Override\n          protected TokenStreamComponents wrapComponents(String fieldName, TokenStreamComponents components) {\n            if (fieldName.equals(\"textgrams\") && minPrefixChars > 0) {\n              return new TokenStreamComponents(components.getTokenizer(),\n                                               new EdgeNGramTokenFilter(matchVersion,\n                                                                        components.getTokenStream(),\n                                                                        1, minPrefixChars));\n            } else {\n              return components;\n            }\n          }\n        };\n\n      w = new IndexWriter(dirTmp,\n                          getIndexWriterConfig(matchVersion, gramAnalyzer));\n      BytesRef text;\n      Document doc = new Document();\n      FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n      ft.setIndexOptions(IndexOptions.DOCS_ONLY);\n      ft.setOmitNorms(true);\n      Field textField = new Field(TEXT_FIELD_NAME, \"\", ft);\n      doc.add(textField);\n\n      Field textGramField = new Field(\"textgrams\", \"\", ft);\n      doc.add(textGramField);\n\n      Field textDVField = new BinaryDocValuesField(TEXT_FIELD_NAME, new BytesRef());\n      doc.add(textDVField);\n\n      // TODO: use threads...?\n      Field weightField = new NumericDocValuesField(\"weight\", 0);\n      doc.add(weightField);\n\n      Field payloadField;\n      if (payloads != null) {\n        payloadField = new BinaryDocValuesField(\"payloads\", new BytesRef());\n        doc.add(payloadField);\n      } else {\n        payloadField = null;\n      }\n\n      //long t0 = System.nanoTime();\n      while ((text = iter.next()) != null) {\n        String textString = text.utf8ToString();\n        textField.setStringValue(textString);\n        textGramField.setStringValue(textString);\n        textDVField.setBytesValue(text);\n        weightField.setLongValue(iter.weight());\n        if (payloads != null) {\n          payloadField.setBytesValue(payloads.payload());\n        }\n        w.addDocument(doc);\n      }\n      //System.out.println(\"initial indexing time: \" + ((System.nanoTime()-t0)/1000000) + \" msec\");\n\n      r = SlowCompositeReaderWrapper.wrap(DirectoryReader.open(w, false));\n      //long t1 = System.nanoTime();\n      w.rollback();\n\n      final int maxDoc = r.maxDoc();\n\n      final NumericDocValues weights = r.getNumericDocValues(\"weight\");\n\n      final Sorter.DocComparator comparator = new Sorter.DocComparator() {\n          @Override\n          public int compare(int docID1, int docID2) {\n            final long v1 = weights.get(docID1);\n            final long v2 = weights.get(docID2);\n            // Reverse sort (highest weight first);\n            // java7 only:\n            //return Long.compare(v2, v1);\n            if (v1 > v2) {\n              return -1;\n            } else if (v1 < v2) {\n              return 1;\n            } else {\n              return 0;\n            }\n          }\n        };\n\n      r = SortingAtomicReader.wrap(r, new Sorter() {\n          @Override\n          public Sorter.DocMap sort(AtomicReader reader) throws IOException {\n            return Sorter.sort(maxDoc, comparator);\n          }\n\n          @Override\n          public String getID() {\n            return \"Weight\";\n          }\n        });\n      \n      w2 = new IndexWriter(dir,\n                           getIndexWriterConfig(matchVersion, indexAnalyzer));\n      w2.addIndexes(new IndexReader[] {r});\n      r.close();\n\n      //System.out.println(\"sort time: \" + ((System.nanoTime()-t1)/1000000) + \" msec\");\n\n      searcher = new IndexSearcher(DirectoryReader.open(w2, false));\n      w2.close();\n\n      payloadsDV = MultiDocValues.getBinaryValues(searcher.getIndexReader(), \"payloads\");\n      weightsDV = MultiDocValues.getNumericValues(searcher.getIndexReader(), \"weight\");\n      textDV = MultiDocValues.getBinaryValues(searcher.getIndexReader(), TEXT_FIELD_NAME);\n      assert textDV != null;\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(w, w2, r, dirTmp);\n      } else {\n        IOUtils.closeWhileHandlingException(w, w2, r, dirTmp);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"41aee74b5f91a096e3fd950f4a336bc763f0e7a7","date":1381772070,"type":5,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggester#build(InputIterator).mjava","pathOld":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggester#build(TermFreqPayloadIterator).mjava","sourceNew":"  @Override\n  public void build(InputIterator iter) throws IOException {\n\n    if (searcher != null) {\n      searcher.getIndexReader().close();\n      searcher = null;\n    }\n\n\n    Directory dirTmp = getDirectory(new File(indexPath.toString() + \".tmp\"));\n\n    IndexWriter w = null;\n    IndexWriter w2 = null;\n    AtomicReader r = null;\n    boolean success = false;\n    try {\n      Analyzer gramAnalyzer = new AnalyzerWrapper(Analyzer.PER_FIELD_REUSE_STRATEGY) {\n          @Override\n          protected Analyzer getWrappedAnalyzer(String fieldName) {\n            return indexAnalyzer;\n          }\n\n          @Override\n          protected TokenStreamComponents wrapComponents(String fieldName, TokenStreamComponents components) {\n            if (fieldName.equals(\"textgrams\") && minPrefixChars > 0) {\n              return new TokenStreamComponents(components.getTokenizer(),\n                                               new EdgeNGramTokenFilter(matchVersion,\n                                                                        components.getTokenStream(),\n                                                                        1, minPrefixChars));\n            } else {\n              return components;\n            }\n          }\n        };\n\n      w = new IndexWriter(dirTmp,\n                          getIndexWriterConfig(matchVersion, gramAnalyzer));\n      BytesRef text;\n      Document doc = new Document();\n      FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n      ft.setIndexOptions(IndexOptions.DOCS_ONLY);\n      ft.setOmitNorms(true);\n      Field textField = new Field(TEXT_FIELD_NAME, \"\", ft);\n      doc.add(textField);\n\n      Field textGramField = new Field(\"textgrams\", \"\", ft);\n      doc.add(textGramField);\n\n      Field textDVField = new BinaryDocValuesField(TEXT_FIELD_NAME, new BytesRef());\n      doc.add(textDVField);\n\n      // TODO: use threads...?\n      Field weightField = new NumericDocValuesField(\"weight\", 0);\n      doc.add(weightField);\n\n      Field payloadField;\n      if (iter.hasPayloads()) {\n        payloadField = new BinaryDocValuesField(\"payloads\", new BytesRef());\n        doc.add(payloadField);\n      } else {\n        payloadField = null;\n      }\n\n      //long t0 = System.nanoTime();\n      while ((text = iter.next()) != null) {\n        String textString = text.utf8ToString();\n        textField.setStringValue(textString);\n        textGramField.setStringValue(textString);\n        textDVField.setBytesValue(text);\n        weightField.setLongValue(iter.weight());\n        if (iter.hasPayloads()) {\n          payloadField.setBytesValue(iter.payload());\n        }\n        w.addDocument(doc);\n      }\n      //System.out.println(\"initial indexing time: \" + ((System.nanoTime()-t0)/1000000) + \" msec\");\n\n      r = SlowCompositeReaderWrapper.wrap(DirectoryReader.open(w, false));\n      //long t1 = System.nanoTime();\n      w.rollback();\n\n      final int maxDoc = r.maxDoc();\n\n      final NumericDocValues weights = r.getNumericDocValues(\"weight\");\n\n      final Sorter.DocComparator comparator = new Sorter.DocComparator() {\n          @Override\n          public int compare(int docID1, int docID2) {\n            final long v1 = weights.get(docID1);\n            final long v2 = weights.get(docID2);\n            // Reverse sort (highest weight first);\n            // java7 only:\n            //return Long.compare(v2, v1);\n            if (v1 > v2) {\n              return -1;\n            } else if (v1 < v2) {\n              return 1;\n            } else {\n              return 0;\n            }\n          }\n        };\n\n      r = SortingAtomicReader.wrap(r, new Sorter() {\n          @Override\n          public Sorter.DocMap sort(AtomicReader reader) throws IOException {\n            return Sorter.sort(maxDoc, comparator);\n          }\n\n          @Override\n          public String getID() {\n            return \"Weight\";\n          }\n        });\n      \n      w2 = new IndexWriter(dir,\n                           getIndexWriterConfig(matchVersion, indexAnalyzer));\n      w2.addIndexes(new IndexReader[] {r});\n      r.close();\n\n      //System.out.println(\"sort time: \" + ((System.nanoTime()-t1)/1000000) + \" msec\");\n\n      searcher = new IndexSearcher(DirectoryReader.open(w2, false));\n      w2.close();\n\n      payloadsDV = MultiDocValues.getBinaryValues(searcher.getIndexReader(), \"payloads\");\n      weightsDV = MultiDocValues.getNumericValues(searcher.getIndexReader(), \"weight\");\n      textDV = MultiDocValues.getBinaryValues(searcher.getIndexReader(), TEXT_FIELD_NAME);\n      assert textDV != null;\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(w, w2, r, dirTmp);\n      } else {\n        IOUtils.closeWhileHandlingException(w, w2, r, dirTmp);\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  public void build(TermFreqPayloadIterator iter) throws IOException {\n\n    if (searcher != null) {\n      searcher.getIndexReader().close();\n      searcher = null;\n    }\n\n\n    Directory dirTmp = getDirectory(new File(indexPath.toString() + \".tmp\"));\n\n    IndexWriter w = null;\n    IndexWriter w2 = null;\n    AtomicReader r = null;\n    boolean success = false;\n    try {\n      Analyzer gramAnalyzer = new AnalyzerWrapper(Analyzer.PER_FIELD_REUSE_STRATEGY) {\n          @Override\n          protected Analyzer getWrappedAnalyzer(String fieldName) {\n            return indexAnalyzer;\n          }\n\n          @Override\n          protected TokenStreamComponents wrapComponents(String fieldName, TokenStreamComponents components) {\n            if (fieldName.equals(\"textgrams\") && minPrefixChars > 0) {\n              return new TokenStreamComponents(components.getTokenizer(),\n                                               new EdgeNGramTokenFilter(matchVersion,\n                                                                        components.getTokenStream(),\n                                                                        1, minPrefixChars));\n            } else {\n              return components;\n            }\n          }\n        };\n\n      w = new IndexWriter(dirTmp,\n                          getIndexWriterConfig(matchVersion, gramAnalyzer));\n      BytesRef text;\n      Document doc = new Document();\n      FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n      ft.setIndexOptions(IndexOptions.DOCS_ONLY);\n      ft.setOmitNorms(true);\n      Field textField = new Field(TEXT_FIELD_NAME, \"\", ft);\n      doc.add(textField);\n\n      Field textGramField = new Field(\"textgrams\", \"\", ft);\n      doc.add(textGramField);\n\n      Field textDVField = new BinaryDocValuesField(TEXT_FIELD_NAME, new BytesRef());\n      doc.add(textDVField);\n\n      // TODO: use threads...?\n      Field weightField = new NumericDocValuesField(\"weight\", 0);\n      doc.add(weightField);\n\n      Field payloadField;\n      if (iter.hasPayloads()) {\n        payloadField = new BinaryDocValuesField(\"payloads\", new BytesRef());\n        doc.add(payloadField);\n      } else {\n        payloadField = null;\n      }\n\n      //long t0 = System.nanoTime();\n      while ((text = iter.next()) != null) {\n        String textString = text.utf8ToString();\n        textField.setStringValue(textString);\n        textGramField.setStringValue(textString);\n        textDVField.setBytesValue(text);\n        weightField.setLongValue(iter.weight());\n        if (iter.hasPayloads()) {\n          payloadField.setBytesValue(iter.payload());\n        }\n        w.addDocument(doc);\n      }\n      //System.out.println(\"initial indexing time: \" + ((System.nanoTime()-t0)/1000000) + \" msec\");\n\n      r = SlowCompositeReaderWrapper.wrap(DirectoryReader.open(w, false));\n      //long t1 = System.nanoTime();\n      w.rollback();\n\n      final int maxDoc = r.maxDoc();\n\n      final NumericDocValues weights = r.getNumericDocValues(\"weight\");\n\n      final Sorter.DocComparator comparator = new Sorter.DocComparator() {\n          @Override\n          public int compare(int docID1, int docID2) {\n            final long v1 = weights.get(docID1);\n            final long v2 = weights.get(docID2);\n            // Reverse sort (highest weight first);\n            // java7 only:\n            //return Long.compare(v2, v1);\n            if (v1 > v2) {\n              return -1;\n            } else if (v1 < v2) {\n              return 1;\n            } else {\n              return 0;\n            }\n          }\n        };\n\n      r = SortingAtomicReader.wrap(r, new Sorter() {\n          @Override\n          public Sorter.DocMap sort(AtomicReader reader) throws IOException {\n            return Sorter.sort(maxDoc, comparator);\n          }\n\n          @Override\n          public String getID() {\n            return \"Weight\";\n          }\n        });\n      \n      w2 = new IndexWriter(dir,\n                           getIndexWriterConfig(matchVersion, indexAnalyzer));\n      w2.addIndexes(new IndexReader[] {r});\n      r.close();\n\n      //System.out.println(\"sort time: \" + ((System.nanoTime()-t1)/1000000) + \" msec\");\n\n      searcher = new IndexSearcher(DirectoryReader.open(w2, false));\n      w2.close();\n\n      payloadsDV = MultiDocValues.getBinaryValues(searcher.getIndexReader(), \"payloads\");\n      weightsDV = MultiDocValues.getNumericValues(searcher.getIndexReader(), \"weight\");\n      textDV = MultiDocValues.getBinaryValues(searcher.getIndexReader(), TEXT_FIELD_NAME);\n      assert textDV != null;\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(w, w2, r, dirTmp);\n      } else {\n        IOUtils.closeWhileHandlingException(w, w2, r, dirTmp);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"41aee74b5f91a096e3fd950f4a336bc763f0e7a7":["ada2f7352a7f964fe49bccd13227c4ec38563d39"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["41aee74b5f91a096e3fd950f4a336bc763f0e7a7"],"ada2f7352a7f964fe49bccd13227c4ec38563d39":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"41aee74b5f91a096e3fd950f4a336bc763f0e7a7":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["ada2f7352a7f964fe49bccd13227c4ec38563d39"],"ada2f7352a7f964fe49bccd13227c4ec38563d39":["41aee74b5f91a096e3fd950f4a336bc763f0e7a7"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}