{"path":"solr/core/src/test/org/apache/solr/cloud/api/collections/ShardSplitTest#doSplitStaticIndexReplication(SolrIndexSplitter.SplitMethod).mjava","commits":[{"id":"20c968c14aace7cf49843bf2c1fafc7fd3845659","date":1533133859,"type":0,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/api/collections/ShardSplitTest#doSplitStaticIndexReplication(SolrIndexSplitter.SplitMethod).mjava","pathOld":"/dev/null","sourceNew":"  private void doSplitStaticIndexReplication(SolrIndexSplitter.SplitMethod splitMethod) throws Exception {\n    waitForThingsToLevelOut(15);\n\n    DocCollection defCol = cloudClient.getZkStateReader().getClusterState().getCollection(AbstractDistribZkTestBase.DEFAULT_COLLECTION);\n    Replica replica = defCol.getReplicas().get(0);\n    String nodeName = replica.getNodeName();\n\n    String collectionName = \"testSplitStaticIndexReplication_\" + splitMethod.toLower();\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName, \"conf1\", 1, 1);\n    create.setMaxShardsPerNode(5); // some high number so we can create replicas without hindrance\n    create.setCreateNodeSet(nodeName); // we want to create the leader on a fixed node so that we know which one to restart later\n    create.process(cloudClient);\n    try (CloudSolrClient client = getCloudSolrClient(zkServer.getZkAddress(), true, cloudClient.getLbClient().getHttpClient())) {\n      client.setDefaultCollection(collectionName);\n      StoppableIndexingThread thread = new StoppableIndexingThread(controlClient, client, \"i1\", true);\n      try {\n        thread.start();\n        Thread.sleep(1000); // give the indexer sometime to do its work\n        thread.safeStop();\n        thread.join();\n        client.commit();\n        controlClient.commit();\n\n        CollectionAdminRequest.SplitShard splitShard = CollectionAdminRequest.splitShard(collectionName);\n        splitShard.setShardName(SHARD1);\n        splitShard.setSplitMethod(splitMethod.toLower());\n        String asyncId = splitShard.processAsync(client);\n        RequestStatusState state = CollectionAdminRequest.requestStatus(asyncId).waitFor(client, 120);\n        if (state == RequestStatusState.COMPLETED)  {\n          waitForRecoveriesToFinish(collectionName, true);\n          // let's wait to see parent shard become inactive\n          CountDownLatch latch = new CountDownLatch(1);\n          client.getZkStateReader().registerCollectionStateWatcher(collectionName, new CollectionStateWatcher() {\n            @Override\n            public boolean onStateChanged(Set<String> liveNodes, DocCollection collectionState) {\n              Slice parent = collectionState.getSlice(SHARD1);\n              Slice slice10 = collectionState.getSlice(SHARD1_0);\n              Slice slice11 = collectionState.getSlice(SHARD1_1);\n              if (slice10 != null && slice11 != null &&\n                  parent.getState() == Slice.State.INACTIVE &&\n                  slice10.getState() == Slice.State.ACTIVE &&\n                  slice11.getState() == Slice.State.ACTIVE) {\n                latch.countDown();\n                return true; // removes the watch\n              }\n              return false;\n            }\n          });\n          latch.await(1, TimeUnit.MINUTES);\n          if (latch.getCount() != 0)  {\n            // sanity check\n            fail(\"Sub-shards did not become active even after waiting for 1 minute\");\n          }\n\n          int liveNodeCount = client.getZkStateReader().getClusterState().getLiveNodes().size();\n\n          // restart the sub-shard leader node\n          boolean restarted = false;\n          for (JettySolrRunner jetty : jettys) {\n            int port = jetty.getBaseUrl().getPort();\n            if (replica.getStr(BASE_URL_PROP).contains(\":\" + port))  {\n              ChaosMonkey.kill(jetty);\n              ChaosMonkey.start(jetty);\n              restarted = true;\n              break;\n            }\n          }\n          if (!restarted) {\n            // sanity check\n            fail(\"We could not find a jetty to kill for replica: \" + replica.getCoreUrl());\n          }\n\n          // add a new replica for the sub-shard\n          CollectionAdminRequest.AddReplica addReplica = CollectionAdminRequest.addReplicaToShard(collectionName, SHARD1_0);\n          // use control client because less chances of it being the node being restarted\n          // this is to avoid flakiness of test because of NoHttpResponseExceptions\n          String control_collection = client.getZkStateReader().getClusterState().getCollection(\"control_collection\").getReplicas().get(0).getStr(BASE_URL_PROP);\n          try (HttpSolrClient control = new HttpSolrClient.Builder(control_collection).withHttpClient(client.getLbClient().getHttpClient()).build())  {\n            state = addReplica.processAndWait(control, 30);\n          }\n          if (state == RequestStatusState.COMPLETED)  {\n            CountDownLatch newReplicaLatch = new CountDownLatch(1);\n            client.getZkStateReader().registerCollectionStateWatcher(collectionName, new CollectionStateWatcher() {\n              @Override\n              public boolean onStateChanged(Set<String> liveNodes, DocCollection collectionState) {\n                if (liveNodes.size() != liveNodeCount)  {\n                  return false;\n                }\n                Slice slice = collectionState.getSlice(SHARD1_0);\n                if (slice.getReplicas().size() == 2)  {\n                  if (!slice.getReplicas().stream().anyMatch(r -> r.getState() == Replica.State.RECOVERING)) {\n                    // we see replicas and none of them are recovering\n                    newReplicaLatch.countDown();\n                    return true;\n                  }\n                }\n                return false;\n              }\n            });\n            newReplicaLatch.await(30, TimeUnit.SECONDS);\n            // check consistency of sub-shard replica explicitly because checkShardConsistency methods doesn't\n            // handle new shards/replica so well.\n            ClusterState clusterState = client.getZkStateReader().getClusterState();\n            DocCollection collection = clusterState.getCollection(collectionName);\n            int numReplicasChecked = assertConsistentReplicas(collection.getSlice(SHARD1_0));\n            assertEquals(\"We should have checked consistency for exactly 2 replicas of shard1_0\", 2, numReplicasChecked);\n          } else  {\n            fail(\"Adding a replica to sub-shard did not complete even after waiting for 30 seconds!. Saw state = \" + state.getKey());\n          }\n        } else {\n          fail(\"We expected shard split to succeed on a static index but it didn't. Found state = \" + state.getKey());\n        }\n      } finally {\n        thread.safeStop();\n        thread.join();\n      }\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["bb222a3f9d9421d5c95afce73013fbd8de07ea1f"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"a9be06eb0504cb6312c2a585959299e40280d9ba","date":1534415825,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/api/collections/ShardSplitTest#doSplitStaticIndexReplication(SolrIndexSplitter.SplitMethod).mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/api/collections/ShardSplitTest#doSplitStaticIndexReplication(SolrIndexSplitter.SplitMethod).mjava","sourceNew":"  private void doSplitStaticIndexReplication(SolrIndexSplitter.SplitMethod splitMethod) throws Exception {\n    waitForThingsToLevelOut(15);\n\n    DocCollection defCol = cloudClient.getZkStateReader().getClusterState().getCollection(AbstractDistribZkTestBase.DEFAULT_COLLECTION);\n    Replica replica = defCol.getReplicas().get(0);\n    String nodeName = replica.getNodeName();\n\n    String collectionName = \"testSplitStaticIndexReplication_\" + splitMethod.toLower();\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName, \"conf1\", 1, 1);\n    create.setMaxShardsPerNode(5); // some high number so we can create replicas without hindrance\n    create.setCreateNodeSet(nodeName); // we want to create the leader on a fixed node so that we know which one to restart later\n    create.process(cloudClient);\n    try (CloudSolrClient client = getCloudSolrClient(zkServer.getZkAddress(), true, cloudClient.getLbClient().getHttpClient())) {\n      client.setDefaultCollection(collectionName);\n      StoppableIndexingThread thread = new StoppableIndexingThread(controlClient, client, \"i1\", true);\n      try {\n        thread.start();\n        Thread.sleep(1000); // give the indexer sometime to do its work\n        thread.safeStop();\n        thread.join();\n        client.commit();\n        controlClient.commit();\n\n        CollectionAdminRequest.SplitShard splitShard = CollectionAdminRequest.splitShard(collectionName);\n        splitShard.setShardName(SHARD1);\n        splitShard.setSplitMethod(splitMethod.toLower());\n        String asyncId = splitShard.processAsync(client);\n        RequestStatusState state = CollectionAdminRequest.requestStatus(asyncId).waitFor(client, 120);\n        if (state == RequestStatusState.COMPLETED)  {\n          waitForRecoveriesToFinish(collectionName, true);\n          // let's wait to see parent shard become inactive\n          CountDownLatch latch = new CountDownLatch(1);\n          client.getZkStateReader().registerCollectionStateWatcher(collectionName, (liveNodes, collectionState) -> {\n            Slice parent = collectionState.getSlice(SHARD1);\n            Slice slice10 = collectionState.getSlice(SHARD1_0);\n            Slice slice11 = collectionState.getSlice(SHARD1_1);\n            if (slice10 != null && slice11 != null &&\n                parent.getState() == Slice.State.INACTIVE &&\n                slice10.getState() == Slice.State.ACTIVE &&\n                slice11.getState() == Slice.State.ACTIVE) {\n              latch.countDown();\n              return true; // removes the watch\n            }\n            return false;\n          });\n          latch.await(1, TimeUnit.MINUTES);\n          if (latch.getCount() != 0)  {\n            // sanity check\n            fail(\"Sub-shards did not become active even after waiting for 1 minute\");\n          }\n\n          int liveNodeCount = client.getZkStateReader().getClusterState().getLiveNodes().size();\n\n          // restart the sub-shard leader node\n          boolean restarted = false;\n          for (JettySolrRunner jetty : jettys) {\n            int port = jetty.getBaseUrl().getPort();\n            if (replica.getStr(BASE_URL_PROP).contains(\":\" + port))  {\n              ChaosMonkey.kill(jetty);\n              ChaosMonkey.start(jetty);\n              restarted = true;\n              break;\n            }\n          }\n          if (!restarted) {\n            // sanity check\n            fail(\"We could not find a jetty to kill for replica: \" + replica.getCoreUrl());\n          }\n\n          // add a new replica for the sub-shard\n          CollectionAdminRequest.AddReplica addReplica = CollectionAdminRequest.addReplicaToShard(collectionName, SHARD1_0);\n          // use control client because less chances of it being the node being restarted\n          // this is to avoid flakiness of test because of NoHttpResponseExceptions\n          String control_collection = client.getZkStateReader().getClusterState().getCollection(\"control_collection\").getReplicas().get(0).getStr(BASE_URL_PROP);\n          try (HttpSolrClient control = new HttpSolrClient.Builder(control_collection).withHttpClient(client.getLbClient().getHttpClient()).build())  {\n            state = addReplica.processAndWait(control, 30);\n          }\n          if (state == RequestStatusState.COMPLETED)  {\n            CountDownLatch newReplicaLatch = new CountDownLatch(1);\n            client.getZkStateReader().registerCollectionStateWatcher(collectionName, (liveNodes, collectionState) -> {\n              if (liveNodes.size() != liveNodeCount)  {\n                return false;\n              }\n              Slice slice = collectionState.getSlice(SHARD1_0);\n              if (slice.getReplicas().size() == 2)  {\n                if (slice.getReplicas().stream().noneMatch(r -> r.getState() == Replica.State.RECOVERING)) {\n                  // we see replicas and none of them are recovering\n                  newReplicaLatch.countDown();\n                  return true;\n                }\n              }\n              return false;\n            });\n            newReplicaLatch.await(30, TimeUnit.SECONDS);\n            // check consistency of sub-shard replica explicitly because checkShardConsistency methods doesn't\n            // handle new shards/replica so well.\n            ClusterState clusterState = client.getZkStateReader().getClusterState();\n            DocCollection collection = clusterState.getCollection(collectionName);\n            int numReplicasChecked = assertConsistentReplicas(collection.getSlice(SHARD1_0));\n            assertEquals(\"We should have checked consistency for exactly 2 replicas of shard1_0\", 2, numReplicasChecked);\n          } else  {\n            fail(\"Adding a replica to sub-shard did not complete even after waiting for 30 seconds!. Saw state = \" + state.getKey());\n          }\n        } else {\n          fail(\"We expected shard split to succeed on a static index but it didn't. Found state = \" + state.getKey());\n        }\n      } finally {\n        thread.safeStop();\n        thread.join();\n      }\n    }\n  }\n\n","sourceOld":"  private void doSplitStaticIndexReplication(SolrIndexSplitter.SplitMethod splitMethod) throws Exception {\n    waitForThingsToLevelOut(15);\n\n    DocCollection defCol = cloudClient.getZkStateReader().getClusterState().getCollection(AbstractDistribZkTestBase.DEFAULT_COLLECTION);\n    Replica replica = defCol.getReplicas().get(0);\n    String nodeName = replica.getNodeName();\n\n    String collectionName = \"testSplitStaticIndexReplication_\" + splitMethod.toLower();\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName, \"conf1\", 1, 1);\n    create.setMaxShardsPerNode(5); // some high number so we can create replicas without hindrance\n    create.setCreateNodeSet(nodeName); // we want to create the leader on a fixed node so that we know which one to restart later\n    create.process(cloudClient);\n    try (CloudSolrClient client = getCloudSolrClient(zkServer.getZkAddress(), true, cloudClient.getLbClient().getHttpClient())) {\n      client.setDefaultCollection(collectionName);\n      StoppableIndexingThread thread = new StoppableIndexingThread(controlClient, client, \"i1\", true);\n      try {\n        thread.start();\n        Thread.sleep(1000); // give the indexer sometime to do its work\n        thread.safeStop();\n        thread.join();\n        client.commit();\n        controlClient.commit();\n\n        CollectionAdminRequest.SplitShard splitShard = CollectionAdminRequest.splitShard(collectionName);\n        splitShard.setShardName(SHARD1);\n        splitShard.setSplitMethod(splitMethod.toLower());\n        String asyncId = splitShard.processAsync(client);\n        RequestStatusState state = CollectionAdminRequest.requestStatus(asyncId).waitFor(client, 120);\n        if (state == RequestStatusState.COMPLETED)  {\n          waitForRecoveriesToFinish(collectionName, true);\n          // let's wait to see parent shard become inactive\n          CountDownLatch latch = new CountDownLatch(1);\n          client.getZkStateReader().registerCollectionStateWatcher(collectionName, new CollectionStateWatcher() {\n            @Override\n            public boolean onStateChanged(Set<String> liveNodes, DocCollection collectionState) {\n              Slice parent = collectionState.getSlice(SHARD1);\n              Slice slice10 = collectionState.getSlice(SHARD1_0);\n              Slice slice11 = collectionState.getSlice(SHARD1_1);\n              if (slice10 != null && slice11 != null &&\n                  parent.getState() == Slice.State.INACTIVE &&\n                  slice10.getState() == Slice.State.ACTIVE &&\n                  slice11.getState() == Slice.State.ACTIVE) {\n                latch.countDown();\n                return true; // removes the watch\n              }\n              return false;\n            }\n          });\n          latch.await(1, TimeUnit.MINUTES);\n          if (latch.getCount() != 0)  {\n            // sanity check\n            fail(\"Sub-shards did not become active even after waiting for 1 minute\");\n          }\n\n          int liveNodeCount = client.getZkStateReader().getClusterState().getLiveNodes().size();\n\n          // restart the sub-shard leader node\n          boolean restarted = false;\n          for (JettySolrRunner jetty : jettys) {\n            int port = jetty.getBaseUrl().getPort();\n            if (replica.getStr(BASE_URL_PROP).contains(\":\" + port))  {\n              ChaosMonkey.kill(jetty);\n              ChaosMonkey.start(jetty);\n              restarted = true;\n              break;\n            }\n          }\n          if (!restarted) {\n            // sanity check\n            fail(\"We could not find a jetty to kill for replica: \" + replica.getCoreUrl());\n          }\n\n          // add a new replica for the sub-shard\n          CollectionAdminRequest.AddReplica addReplica = CollectionAdminRequest.addReplicaToShard(collectionName, SHARD1_0);\n          // use control client because less chances of it being the node being restarted\n          // this is to avoid flakiness of test because of NoHttpResponseExceptions\n          String control_collection = client.getZkStateReader().getClusterState().getCollection(\"control_collection\").getReplicas().get(0).getStr(BASE_URL_PROP);\n          try (HttpSolrClient control = new HttpSolrClient.Builder(control_collection).withHttpClient(client.getLbClient().getHttpClient()).build())  {\n            state = addReplica.processAndWait(control, 30);\n          }\n          if (state == RequestStatusState.COMPLETED)  {\n            CountDownLatch newReplicaLatch = new CountDownLatch(1);\n            client.getZkStateReader().registerCollectionStateWatcher(collectionName, new CollectionStateWatcher() {\n              @Override\n              public boolean onStateChanged(Set<String> liveNodes, DocCollection collectionState) {\n                if (liveNodes.size() != liveNodeCount)  {\n                  return false;\n                }\n                Slice slice = collectionState.getSlice(SHARD1_0);\n                if (slice.getReplicas().size() == 2)  {\n                  if (!slice.getReplicas().stream().anyMatch(r -> r.getState() == Replica.State.RECOVERING)) {\n                    // we see replicas and none of them are recovering\n                    newReplicaLatch.countDown();\n                    return true;\n                  }\n                }\n                return false;\n              }\n            });\n            newReplicaLatch.await(30, TimeUnit.SECONDS);\n            // check consistency of sub-shard replica explicitly because checkShardConsistency methods doesn't\n            // handle new shards/replica so well.\n            ClusterState clusterState = client.getZkStateReader().getClusterState();\n            DocCollection collection = clusterState.getCollection(collectionName);\n            int numReplicasChecked = assertConsistentReplicas(collection.getSlice(SHARD1_0));\n            assertEquals(\"We should have checked consistency for exactly 2 replicas of shard1_0\", 2, numReplicasChecked);\n          } else  {\n            fail(\"Adding a replica to sub-shard did not complete even after waiting for 30 seconds!. Saw state = \" + state.getKey());\n          }\n        } else {\n          fail(\"We expected shard split to succeed on a static index but it didn't. Found state = \" + state.getKey());\n        }\n      } finally {\n        thread.safeStop();\n        thread.join();\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"bb222a3f9d9421d5c95afce73013fbd8de07ea1f","date":1543514331,"type":3,"author":"markrmiller","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/api/collections/ShardSplitTest#doSplitStaticIndexReplication(SolrIndexSplitter.SplitMethod).mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/api/collections/ShardSplitTest#doSplitStaticIndexReplication(SolrIndexSplitter.SplitMethod).mjava","sourceNew":"  private void doSplitStaticIndexReplication(SolrIndexSplitter.SplitMethod splitMethod) throws Exception {\n    waitForThingsToLevelOut(15);\n\n    DocCollection defCol = cloudClient.getZkStateReader().getClusterState().getCollection(AbstractDistribZkTestBase.DEFAULT_COLLECTION);\n    Replica replica = defCol.getReplicas().get(0);\n    String nodeName = replica.getNodeName();\n\n    String collectionName = \"testSplitStaticIndexReplication_\" + splitMethod.toLower();\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName, \"conf1\", 1, 1);\n    create.setMaxShardsPerNode(5); // some high number so we can create replicas without hindrance\n    create.setCreateNodeSet(nodeName); // we want to create the leader on a fixed node so that we know which one to restart later\n    create.process(cloudClient);\n    \n    cloudClient.waitForState(collectionName, 30, TimeUnit.SECONDS, SolrCloudTestCase.activeClusterShape(1, 1));\n    \n    try (CloudSolrClient client = getCloudSolrClient(zkServer.getZkAddress(), true, cloudClient.getLbClient().getHttpClient())) {\n      client.setDefaultCollection(collectionName);\n      StoppableIndexingThread thread = new StoppableIndexingThread(controlClient, client, \"i1\", true);\n      try {\n        thread.start();\n        Thread.sleep(1000); // give the indexer sometime to do its work\n        thread.safeStop();\n        thread.join();\n        client.commit();\n        controlClient.commit();\n\n        CollectionAdminRequest.SplitShard splitShard = CollectionAdminRequest.splitShard(collectionName);\n        splitShard.setShardName(SHARD1);\n        splitShard.setSplitMethod(splitMethod.toLower());\n        String asyncId = splitShard.processAsync(client);\n        RequestStatusState state = CollectionAdminRequest.requestStatus(asyncId).waitFor(client, 120);\n        if (state == RequestStatusState.COMPLETED)  {\n          waitForRecoveriesToFinish(collectionName, true);\n          // let's wait to see parent shard become inactive\n          CountDownLatch latch = new CountDownLatch(1);\n          client.getZkStateReader().registerCollectionStateWatcher(collectionName, (liveNodes, collectionState) -> {\n            Slice parent = collectionState.getSlice(SHARD1);\n            Slice slice10 = collectionState.getSlice(SHARD1_0);\n            Slice slice11 = collectionState.getSlice(SHARD1_1);\n            if (slice10 != null && slice11 != null &&\n                parent.getState() == Slice.State.INACTIVE &&\n                slice10.getState() == Slice.State.ACTIVE &&\n                slice11.getState() == Slice.State.ACTIVE) {\n              latch.countDown();\n              return true; // removes the watch\n            }\n            return false;\n          });\n          latch.await(1, TimeUnit.MINUTES);\n          if (latch.getCount() != 0)  {\n            // sanity check\n            fail(\"Sub-shards did not become active even after waiting for 1 minute\");\n          }\n\n          int liveNodeCount = client.getZkStateReader().getClusterState().getLiveNodes().size();\n\n          // restart the sub-shard leader node\n          String stoppedNodeName = null;\n          boolean restarted = false;\n          for (JettySolrRunner jetty : jettys) {\n            int port = jetty.getBaseUrl().getPort();\n            if (replica.getStr(BASE_URL_PROP).contains(\":\" + port))  {\n              stoppedNodeName = jetty.getNodeName();\n              jetty.stop();\n              jetty.start();\n              restarted = true;\n              break;\n            }\n          }\n          if (!restarted) {\n            // sanity check\n            fail(\"We could not find a jetty to kill for replica: \" + replica.getCoreUrl());\n          }\n          \n          cloudClient.getZkStateReader().waitForLiveNodes(30, TimeUnit.SECONDS, SolrCloudTestCase.containsLiveNode(stoppedNodeName));\n\n          // add a new replica for the sub-shard\n          CollectionAdminRequest.AddReplica addReplica = CollectionAdminRequest.addReplicaToShard(collectionName, SHARD1_0);\n          // use control client because less chances of it being the node being restarted\n          // this is to avoid flakiness of test because of NoHttpResponseExceptions\n          String control_collection = client.getZkStateReader().getClusterState().getCollection(\"control_collection\").getReplicas().get(0).getStr(BASE_URL_PROP);\n          try (HttpSolrClient control = new HttpSolrClient.Builder(control_collection).withHttpClient(client.getLbClient().getHttpClient()).build())  {\n            state = addReplica.processAndWait(control, 30);\n          }\n          \n          cloudClient.waitForState(collectionName, 30, TimeUnit.SECONDS, SolrCloudTestCase.activeClusterShape(2, 4));\n          \n          if (state == RequestStatusState.COMPLETED)  {\n            CountDownLatch newReplicaLatch = new CountDownLatch(1);\n            client.getZkStateReader().registerCollectionStateWatcher(collectionName, (liveNodes, collectionState) -> {\n              if (liveNodes.size() != liveNodeCount)  {\n                return false;\n              }\n              Slice slice = collectionState.getSlice(SHARD1_0);\n              if (slice.getReplicas().size() == 2)  {\n                if (slice.getReplicas().stream().noneMatch(r -> r.getState() == Replica.State.RECOVERING)) {\n                  // we see replicas and none of them are recovering\n                  newReplicaLatch.countDown();\n                  return true;\n                }\n              }\n              return false;\n            });\n            newReplicaLatch.await(30, TimeUnit.SECONDS);\n            // check consistency of sub-shard replica explicitly because checkShardConsistency methods doesn't\n            // handle new shards/replica so well.\n            ClusterState clusterState = client.getZkStateReader().getClusterState();\n            DocCollection collection = clusterState.getCollection(collectionName);\n            int numReplicasChecked = assertConsistentReplicas(collection.getSlice(SHARD1_0));\n            assertEquals(\"We should have checked consistency for exactly 2 replicas of shard1_0\", 2, numReplicasChecked);\n          } else  {\n            fail(\"Adding a replica to sub-shard did not complete even after waiting for 30 seconds!. Saw state = \" + state.getKey());\n          }\n        } else {\n          fail(\"We expected shard split to succeed on a static index but it didn't. Found state = \" + state.getKey());\n        }\n      } finally {\n        thread.safeStop();\n        thread.join();\n      }\n    }\n  }\n\n","sourceOld":"  private void doSplitStaticIndexReplication(SolrIndexSplitter.SplitMethod splitMethod) throws Exception {\n    waitForThingsToLevelOut(15);\n\n    DocCollection defCol = cloudClient.getZkStateReader().getClusterState().getCollection(AbstractDistribZkTestBase.DEFAULT_COLLECTION);\n    Replica replica = defCol.getReplicas().get(0);\n    String nodeName = replica.getNodeName();\n\n    String collectionName = \"testSplitStaticIndexReplication_\" + splitMethod.toLower();\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName, \"conf1\", 1, 1);\n    create.setMaxShardsPerNode(5); // some high number so we can create replicas without hindrance\n    create.setCreateNodeSet(nodeName); // we want to create the leader on a fixed node so that we know which one to restart later\n    create.process(cloudClient);\n    try (CloudSolrClient client = getCloudSolrClient(zkServer.getZkAddress(), true, cloudClient.getLbClient().getHttpClient())) {\n      client.setDefaultCollection(collectionName);\n      StoppableIndexingThread thread = new StoppableIndexingThread(controlClient, client, \"i1\", true);\n      try {\n        thread.start();\n        Thread.sleep(1000); // give the indexer sometime to do its work\n        thread.safeStop();\n        thread.join();\n        client.commit();\n        controlClient.commit();\n\n        CollectionAdminRequest.SplitShard splitShard = CollectionAdminRequest.splitShard(collectionName);\n        splitShard.setShardName(SHARD1);\n        splitShard.setSplitMethod(splitMethod.toLower());\n        String asyncId = splitShard.processAsync(client);\n        RequestStatusState state = CollectionAdminRequest.requestStatus(asyncId).waitFor(client, 120);\n        if (state == RequestStatusState.COMPLETED)  {\n          waitForRecoveriesToFinish(collectionName, true);\n          // let's wait to see parent shard become inactive\n          CountDownLatch latch = new CountDownLatch(1);\n          client.getZkStateReader().registerCollectionStateWatcher(collectionName, (liveNodes, collectionState) -> {\n            Slice parent = collectionState.getSlice(SHARD1);\n            Slice slice10 = collectionState.getSlice(SHARD1_0);\n            Slice slice11 = collectionState.getSlice(SHARD1_1);\n            if (slice10 != null && slice11 != null &&\n                parent.getState() == Slice.State.INACTIVE &&\n                slice10.getState() == Slice.State.ACTIVE &&\n                slice11.getState() == Slice.State.ACTIVE) {\n              latch.countDown();\n              return true; // removes the watch\n            }\n            return false;\n          });\n          latch.await(1, TimeUnit.MINUTES);\n          if (latch.getCount() != 0)  {\n            // sanity check\n            fail(\"Sub-shards did not become active even after waiting for 1 minute\");\n          }\n\n          int liveNodeCount = client.getZkStateReader().getClusterState().getLiveNodes().size();\n\n          // restart the sub-shard leader node\n          boolean restarted = false;\n          for (JettySolrRunner jetty : jettys) {\n            int port = jetty.getBaseUrl().getPort();\n            if (replica.getStr(BASE_URL_PROP).contains(\":\" + port))  {\n              ChaosMonkey.kill(jetty);\n              ChaosMonkey.start(jetty);\n              restarted = true;\n              break;\n            }\n          }\n          if (!restarted) {\n            // sanity check\n            fail(\"We could not find a jetty to kill for replica: \" + replica.getCoreUrl());\n          }\n\n          // add a new replica for the sub-shard\n          CollectionAdminRequest.AddReplica addReplica = CollectionAdminRequest.addReplicaToShard(collectionName, SHARD1_0);\n          // use control client because less chances of it being the node being restarted\n          // this is to avoid flakiness of test because of NoHttpResponseExceptions\n          String control_collection = client.getZkStateReader().getClusterState().getCollection(\"control_collection\").getReplicas().get(0).getStr(BASE_URL_PROP);\n          try (HttpSolrClient control = new HttpSolrClient.Builder(control_collection).withHttpClient(client.getLbClient().getHttpClient()).build())  {\n            state = addReplica.processAndWait(control, 30);\n          }\n          if (state == RequestStatusState.COMPLETED)  {\n            CountDownLatch newReplicaLatch = new CountDownLatch(1);\n            client.getZkStateReader().registerCollectionStateWatcher(collectionName, (liveNodes, collectionState) -> {\n              if (liveNodes.size() != liveNodeCount)  {\n                return false;\n              }\n              Slice slice = collectionState.getSlice(SHARD1_0);\n              if (slice.getReplicas().size() == 2)  {\n                if (slice.getReplicas().stream().noneMatch(r -> r.getState() == Replica.State.RECOVERING)) {\n                  // we see replicas and none of them are recovering\n                  newReplicaLatch.countDown();\n                  return true;\n                }\n              }\n              return false;\n            });\n            newReplicaLatch.await(30, TimeUnit.SECONDS);\n            // check consistency of sub-shard replica explicitly because checkShardConsistency methods doesn't\n            // handle new shards/replica so well.\n            ClusterState clusterState = client.getZkStateReader().getClusterState();\n            DocCollection collection = clusterState.getCollection(collectionName);\n            int numReplicasChecked = assertConsistentReplicas(collection.getSlice(SHARD1_0));\n            assertEquals(\"We should have checked consistency for exactly 2 replicas of shard1_0\", 2, numReplicasChecked);\n          } else  {\n            fail(\"Adding a replica to sub-shard did not complete even after waiting for 30 seconds!. Saw state = \" + state.getKey());\n          }\n        } else {\n          fail(\"We expected shard split to succeed on a static index but it didn't. Found state = \" + state.getKey());\n        }\n      } finally {\n        thread.safeStop();\n        thread.join();\n      }\n    }\n  }\n\n","bugFix":["20c968c14aace7cf49843bf2c1fafc7fd3845659"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"add1e7dd742ea533ff4318cea83ca0a1f669f662","date":1585262285,"type":3,"author":"Mike Drob","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/api/collections/ShardSplitTest#doSplitStaticIndexReplication(SolrIndexSplitter.SplitMethod).mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/api/collections/ShardSplitTest#doSplitStaticIndexReplication(SolrIndexSplitter.SplitMethod).mjava","sourceNew":"  private void doSplitStaticIndexReplication(SolrIndexSplitter.SplitMethod splitMethod) throws Exception {\n    waitForThingsToLevelOut(15, TimeUnit.SECONDS);\n\n    DocCollection defCol = cloudClient.getZkStateReader().getClusterState().getCollection(AbstractDistribZkTestBase.DEFAULT_COLLECTION);\n    Replica replica = defCol.getReplicas().get(0);\n    String nodeName = replica.getNodeName();\n\n    String collectionName = \"testSplitStaticIndexReplication_\" + splitMethod.toLower();\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName, \"conf1\", 1, 1);\n    create.setMaxShardsPerNode(5); // some high number so we can create replicas without hindrance\n    create.setCreateNodeSet(nodeName); // we want to create the leader on a fixed node so that we know which one to restart later\n    create.process(cloudClient);\n    \n    cloudClient.waitForState(collectionName, 30, TimeUnit.SECONDS, SolrCloudTestCase.activeClusterShape(1, 1));\n    \n    try (CloudSolrClient client = getCloudSolrClient(zkServer.getZkAddress(), true, cloudClient.getLbClient().getHttpClient())) {\n      client.setDefaultCollection(collectionName);\n      StoppableIndexingThread thread = new StoppableIndexingThread(controlClient, client, \"i1\", true);\n      try {\n        thread.start();\n        Thread.sleep(1000); // give the indexer sometime to do its work\n        thread.safeStop();\n        thread.join();\n        client.commit();\n        controlClient.commit();\n\n        CollectionAdminRequest.SplitShard splitShard = CollectionAdminRequest.splitShard(collectionName);\n        splitShard.setShardName(SHARD1);\n        splitShard.setSplitMethod(splitMethod.toLower());\n        String asyncId = splitShard.processAsync(client);\n        RequestStatusState state = CollectionAdminRequest.requestStatus(asyncId).waitFor(client, 120);\n        if (state == RequestStatusState.COMPLETED)  {\n          waitForRecoveriesToFinish(collectionName, true);\n          // let's wait to see parent shard become inactive\n          CountDownLatch latch = new CountDownLatch(1);\n          client.getZkStateReader().registerCollectionStateWatcher(collectionName, (liveNodes, collectionState) -> {\n            Slice parent = collectionState.getSlice(SHARD1);\n            Slice slice10 = collectionState.getSlice(SHARD1_0);\n            Slice slice11 = collectionState.getSlice(SHARD1_1);\n            if (slice10 != null && slice11 != null &&\n                parent.getState() == Slice.State.INACTIVE &&\n                slice10.getState() == Slice.State.ACTIVE &&\n                slice11.getState() == Slice.State.ACTIVE) {\n              latch.countDown();\n              return true; // removes the watch\n            }\n            return false;\n          });\n          latch.await(1, TimeUnit.MINUTES);\n          if (latch.getCount() != 0)  {\n            // sanity check\n            fail(\"Sub-shards did not become active even after waiting for 1 minute\");\n          }\n\n          int liveNodeCount = client.getZkStateReader().getClusterState().getLiveNodes().size();\n\n          // restart the sub-shard leader node\n          String stoppedNodeName = null;\n          boolean restarted = false;\n          for (JettySolrRunner jetty : jettys) {\n            int port = jetty.getBaseUrl().getPort();\n            if (replica.getStr(BASE_URL_PROP).contains(\":\" + port))  {\n              stoppedNodeName = jetty.getNodeName();\n              jetty.stop();\n              jetty.start();\n              restarted = true;\n              break;\n            }\n          }\n          if (!restarted) {\n            // sanity check\n            fail(\"We could not find a jetty to kill for replica: \" + replica.getCoreUrl());\n          }\n          \n          cloudClient.getZkStateReader().waitForLiveNodes(30, TimeUnit.SECONDS, SolrCloudTestCase.containsLiveNode(stoppedNodeName));\n\n          // add a new replica for the sub-shard\n          CollectionAdminRequest.AddReplica addReplica = CollectionAdminRequest.addReplicaToShard(collectionName, SHARD1_0);\n          // use control client because less chances of it being the node being restarted\n          // this is to avoid flakiness of test because of NoHttpResponseExceptions\n          String control_collection = client.getZkStateReader().getClusterState().getCollection(\"control_collection\").getReplicas().get(0).getStr(BASE_URL_PROP);\n          try (HttpSolrClient control = new HttpSolrClient.Builder(control_collection).withHttpClient(client.getLbClient().getHttpClient()).build())  {\n            state = addReplica.processAndWait(control, 30);\n          }\n          \n          cloudClient.waitForState(collectionName, 30, TimeUnit.SECONDS, SolrCloudTestCase.activeClusterShape(2, 4));\n          \n          if (state == RequestStatusState.COMPLETED)  {\n            CountDownLatch newReplicaLatch = new CountDownLatch(1);\n            client.getZkStateReader().registerCollectionStateWatcher(collectionName, (liveNodes, collectionState) -> {\n              if (liveNodes.size() != liveNodeCount)  {\n                return false;\n              }\n              Slice slice = collectionState.getSlice(SHARD1_0);\n              if (slice.getReplicas().size() == 2)  {\n                if (slice.getReplicas().stream().noneMatch(r -> r.getState() == Replica.State.RECOVERING)) {\n                  // we see replicas and none of them are recovering\n                  newReplicaLatch.countDown();\n                  return true;\n                }\n              }\n              return false;\n            });\n            newReplicaLatch.await(30, TimeUnit.SECONDS);\n            // check consistency of sub-shard replica explicitly because checkShardConsistency methods doesn't\n            // handle new shards/replica so well.\n            ClusterState clusterState = client.getZkStateReader().getClusterState();\n            DocCollection collection = clusterState.getCollection(collectionName);\n            int numReplicasChecked = assertConsistentReplicas(collection.getSlice(SHARD1_0));\n            assertEquals(\"We should have checked consistency for exactly 2 replicas of shard1_0\", 2, numReplicasChecked);\n          } else  {\n            fail(\"Adding a replica to sub-shard did not complete even after waiting for 30 seconds!. Saw state = \" + state.getKey());\n          }\n        } else {\n          fail(\"We expected shard split to succeed on a static index but it didn't. Found state = \" + state.getKey());\n        }\n      } finally {\n        thread.safeStop();\n        thread.join();\n      }\n    }\n  }\n\n","sourceOld":"  private void doSplitStaticIndexReplication(SolrIndexSplitter.SplitMethod splitMethod) throws Exception {\n    waitForThingsToLevelOut(15);\n\n    DocCollection defCol = cloudClient.getZkStateReader().getClusterState().getCollection(AbstractDistribZkTestBase.DEFAULT_COLLECTION);\n    Replica replica = defCol.getReplicas().get(0);\n    String nodeName = replica.getNodeName();\n\n    String collectionName = \"testSplitStaticIndexReplication_\" + splitMethod.toLower();\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName, \"conf1\", 1, 1);\n    create.setMaxShardsPerNode(5); // some high number so we can create replicas without hindrance\n    create.setCreateNodeSet(nodeName); // we want to create the leader on a fixed node so that we know which one to restart later\n    create.process(cloudClient);\n    \n    cloudClient.waitForState(collectionName, 30, TimeUnit.SECONDS, SolrCloudTestCase.activeClusterShape(1, 1));\n    \n    try (CloudSolrClient client = getCloudSolrClient(zkServer.getZkAddress(), true, cloudClient.getLbClient().getHttpClient())) {\n      client.setDefaultCollection(collectionName);\n      StoppableIndexingThread thread = new StoppableIndexingThread(controlClient, client, \"i1\", true);\n      try {\n        thread.start();\n        Thread.sleep(1000); // give the indexer sometime to do its work\n        thread.safeStop();\n        thread.join();\n        client.commit();\n        controlClient.commit();\n\n        CollectionAdminRequest.SplitShard splitShard = CollectionAdminRequest.splitShard(collectionName);\n        splitShard.setShardName(SHARD1);\n        splitShard.setSplitMethod(splitMethod.toLower());\n        String asyncId = splitShard.processAsync(client);\n        RequestStatusState state = CollectionAdminRequest.requestStatus(asyncId).waitFor(client, 120);\n        if (state == RequestStatusState.COMPLETED)  {\n          waitForRecoveriesToFinish(collectionName, true);\n          // let's wait to see parent shard become inactive\n          CountDownLatch latch = new CountDownLatch(1);\n          client.getZkStateReader().registerCollectionStateWatcher(collectionName, (liveNodes, collectionState) -> {\n            Slice parent = collectionState.getSlice(SHARD1);\n            Slice slice10 = collectionState.getSlice(SHARD1_0);\n            Slice slice11 = collectionState.getSlice(SHARD1_1);\n            if (slice10 != null && slice11 != null &&\n                parent.getState() == Slice.State.INACTIVE &&\n                slice10.getState() == Slice.State.ACTIVE &&\n                slice11.getState() == Slice.State.ACTIVE) {\n              latch.countDown();\n              return true; // removes the watch\n            }\n            return false;\n          });\n          latch.await(1, TimeUnit.MINUTES);\n          if (latch.getCount() != 0)  {\n            // sanity check\n            fail(\"Sub-shards did not become active even after waiting for 1 minute\");\n          }\n\n          int liveNodeCount = client.getZkStateReader().getClusterState().getLiveNodes().size();\n\n          // restart the sub-shard leader node\n          String stoppedNodeName = null;\n          boolean restarted = false;\n          for (JettySolrRunner jetty : jettys) {\n            int port = jetty.getBaseUrl().getPort();\n            if (replica.getStr(BASE_URL_PROP).contains(\":\" + port))  {\n              stoppedNodeName = jetty.getNodeName();\n              jetty.stop();\n              jetty.start();\n              restarted = true;\n              break;\n            }\n          }\n          if (!restarted) {\n            // sanity check\n            fail(\"We could not find a jetty to kill for replica: \" + replica.getCoreUrl());\n          }\n          \n          cloudClient.getZkStateReader().waitForLiveNodes(30, TimeUnit.SECONDS, SolrCloudTestCase.containsLiveNode(stoppedNodeName));\n\n          // add a new replica for the sub-shard\n          CollectionAdminRequest.AddReplica addReplica = CollectionAdminRequest.addReplicaToShard(collectionName, SHARD1_0);\n          // use control client because less chances of it being the node being restarted\n          // this is to avoid flakiness of test because of NoHttpResponseExceptions\n          String control_collection = client.getZkStateReader().getClusterState().getCollection(\"control_collection\").getReplicas().get(0).getStr(BASE_URL_PROP);\n          try (HttpSolrClient control = new HttpSolrClient.Builder(control_collection).withHttpClient(client.getLbClient().getHttpClient()).build())  {\n            state = addReplica.processAndWait(control, 30);\n          }\n          \n          cloudClient.waitForState(collectionName, 30, TimeUnit.SECONDS, SolrCloudTestCase.activeClusterShape(2, 4));\n          \n          if (state == RequestStatusState.COMPLETED)  {\n            CountDownLatch newReplicaLatch = new CountDownLatch(1);\n            client.getZkStateReader().registerCollectionStateWatcher(collectionName, (liveNodes, collectionState) -> {\n              if (liveNodes.size() != liveNodeCount)  {\n                return false;\n              }\n              Slice slice = collectionState.getSlice(SHARD1_0);\n              if (slice.getReplicas().size() == 2)  {\n                if (slice.getReplicas().stream().noneMatch(r -> r.getState() == Replica.State.RECOVERING)) {\n                  // we see replicas and none of them are recovering\n                  newReplicaLatch.countDown();\n                  return true;\n                }\n              }\n              return false;\n            });\n            newReplicaLatch.await(30, TimeUnit.SECONDS);\n            // check consistency of sub-shard replica explicitly because checkShardConsistency methods doesn't\n            // handle new shards/replica so well.\n            ClusterState clusterState = client.getZkStateReader().getClusterState();\n            DocCollection collection = clusterState.getCollection(collectionName);\n            int numReplicasChecked = assertConsistentReplicas(collection.getSlice(SHARD1_0));\n            assertEquals(\"We should have checked consistency for exactly 2 replicas of shard1_0\", 2, numReplicasChecked);\n          } else  {\n            fail(\"Adding a replica to sub-shard did not complete even after waiting for 30 seconds!. Saw state = \" + state.getKey());\n          }\n        } else {\n          fail(\"We expected shard split to succeed on a static index but it didn't. Found state = \" + state.getKey());\n        }\n      } finally {\n        thread.safeStop();\n        thread.join();\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e46a76bb135597b8bf35930cfdb3702bdd1cbe6e","date":1594223844,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/api/collections/ShardSplitTest#doSplitStaticIndexReplication(SolrIndexSplitter.SplitMethod).mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/api/collections/ShardSplitTest#doSplitStaticIndexReplication(SolrIndexSplitter.SplitMethod).mjava","sourceNew":"  private void doSplitStaticIndexReplication(SolrIndexSplitter.SplitMethod splitMethod) throws Exception {\n    waitForThingsToLevelOut(15, TimeUnit.SECONDS);\n\n    DocCollection defCol = cloudClient.getZkStateReader().getClusterState().getCollection(AbstractDistribZkTestBase.DEFAULT_COLLECTION);\n    Replica replica = defCol.getReplicas().get(0);\n    String nodeName = replica.getNodeName();\n\n    String collectionName = \"testSplitStaticIndexReplication_\" + splitMethod.toLower();\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName, \"conf1\", 1, 1);\n    create.setCreateNodeSet(nodeName); // we want to create the leader on a fixed node so that we know which one to restart later\n    create.process(cloudClient);\n    \n    cloudClient.waitForState(collectionName, 30, TimeUnit.SECONDS, SolrCloudTestCase.activeClusterShape(1, 1));\n    \n    try (CloudSolrClient client = getCloudSolrClient(zkServer.getZkAddress(), true, cloudClient.getLbClient().getHttpClient())) {\n      client.setDefaultCollection(collectionName);\n      StoppableIndexingThread thread = new StoppableIndexingThread(controlClient, client, \"i1\", true);\n      try {\n        thread.start();\n        Thread.sleep(1000); // give the indexer sometime to do its work\n        thread.safeStop();\n        thread.join();\n        client.commit();\n        controlClient.commit();\n\n        CollectionAdminRequest.SplitShard splitShard = CollectionAdminRequest.splitShard(collectionName);\n        splitShard.setShardName(SHARD1);\n        splitShard.setSplitMethod(splitMethod.toLower());\n        String asyncId = splitShard.processAsync(client);\n        RequestStatusState state = CollectionAdminRequest.requestStatus(asyncId).waitFor(client, 120);\n        if (state == RequestStatusState.COMPLETED)  {\n          waitForRecoveriesToFinish(collectionName, true);\n          // let's wait to see parent shard become inactive\n          CountDownLatch latch = new CountDownLatch(1);\n          client.getZkStateReader().registerCollectionStateWatcher(collectionName, (liveNodes, collectionState) -> {\n            Slice parent = collectionState.getSlice(SHARD1);\n            Slice slice10 = collectionState.getSlice(SHARD1_0);\n            Slice slice11 = collectionState.getSlice(SHARD1_1);\n            if (slice10 != null && slice11 != null &&\n                parent.getState() == Slice.State.INACTIVE &&\n                slice10.getState() == Slice.State.ACTIVE &&\n                slice11.getState() == Slice.State.ACTIVE) {\n              latch.countDown();\n              return true; // removes the watch\n            }\n            return false;\n          });\n          latch.await(1, TimeUnit.MINUTES);\n          if (latch.getCount() != 0)  {\n            // sanity check\n            fail(\"Sub-shards did not become active even after waiting for 1 minute\");\n          }\n\n          int liveNodeCount = client.getZkStateReader().getClusterState().getLiveNodes().size();\n\n          // restart the sub-shard leader node\n          String stoppedNodeName = null;\n          boolean restarted = false;\n          for (JettySolrRunner jetty : jettys) {\n            int port = jetty.getBaseUrl().getPort();\n            if (replica.getStr(BASE_URL_PROP).contains(\":\" + port))  {\n              stoppedNodeName = jetty.getNodeName();\n              jetty.stop();\n              jetty.start();\n              restarted = true;\n              break;\n            }\n          }\n          if (!restarted) {\n            // sanity check\n            fail(\"We could not find a jetty to kill for replica: \" + replica.getCoreUrl());\n          }\n          \n          cloudClient.getZkStateReader().waitForLiveNodes(30, TimeUnit.SECONDS, SolrCloudTestCase.containsLiveNode(stoppedNodeName));\n\n          // add a new replica for the sub-shard\n          CollectionAdminRequest.AddReplica addReplica = CollectionAdminRequest.addReplicaToShard(collectionName, SHARD1_0);\n          // use control client because less chances of it being the node being restarted\n          // this is to avoid flakiness of test because of NoHttpResponseExceptions\n          String control_collection = client.getZkStateReader().getClusterState().getCollection(\"control_collection\").getReplicas().get(0).getStr(BASE_URL_PROP);\n          try (HttpSolrClient control = new HttpSolrClient.Builder(control_collection).withHttpClient(client.getLbClient().getHttpClient()).build())  {\n            state = addReplica.processAndWait(control, 30);\n          }\n          \n          cloudClient.waitForState(collectionName, 30, TimeUnit.SECONDS, SolrCloudTestCase.activeClusterShape(2, 4));\n          \n          if (state == RequestStatusState.COMPLETED)  {\n            CountDownLatch newReplicaLatch = new CountDownLatch(1);\n            client.getZkStateReader().registerCollectionStateWatcher(collectionName, (liveNodes, collectionState) -> {\n              if (liveNodes.size() != liveNodeCount)  {\n                return false;\n              }\n              Slice slice = collectionState.getSlice(SHARD1_0);\n              if (slice.getReplicas().size() == 2)  {\n                if (slice.getReplicas().stream().noneMatch(r -> r.getState() == Replica.State.RECOVERING)) {\n                  // we see replicas and none of them are recovering\n                  newReplicaLatch.countDown();\n                  return true;\n                }\n              }\n              return false;\n            });\n            newReplicaLatch.await(30, TimeUnit.SECONDS);\n            // check consistency of sub-shard replica explicitly because checkShardConsistency methods doesn't\n            // handle new shards/replica so well.\n            ClusterState clusterState = client.getZkStateReader().getClusterState();\n            DocCollection collection = clusterState.getCollection(collectionName);\n            int numReplicasChecked = assertConsistentReplicas(collection.getSlice(SHARD1_0));\n            assertEquals(\"We should have checked consistency for exactly 2 replicas of shard1_0\", 2, numReplicasChecked);\n          } else  {\n            fail(\"Adding a replica to sub-shard did not complete even after waiting for 30 seconds!. Saw state = \" + state.getKey());\n          }\n        } else {\n          fail(\"We expected shard split to succeed on a static index but it didn't. Found state = \" + state.getKey());\n        }\n      } finally {\n        thread.safeStop();\n        thread.join();\n      }\n    }\n  }\n\n","sourceOld":"  private void doSplitStaticIndexReplication(SolrIndexSplitter.SplitMethod splitMethod) throws Exception {\n    waitForThingsToLevelOut(15, TimeUnit.SECONDS);\n\n    DocCollection defCol = cloudClient.getZkStateReader().getClusterState().getCollection(AbstractDistribZkTestBase.DEFAULT_COLLECTION);\n    Replica replica = defCol.getReplicas().get(0);\n    String nodeName = replica.getNodeName();\n\n    String collectionName = \"testSplitStaticIndexReplication_\" + splitMethod.toLower();\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName, \"conf1\", 1, 1);\n    create.setMaxShardsPerNode(5); // some high number so we can create replicas without hindrance\n    create.setCreateNodeSet(nodeName); // we want to create the leader on a fixed node so that we know which one to restart later\n    create.process(cloudClient);\n    \n    cloudClient.waitForState(collectionName, 30, TimeUnit.SECONDS, SolrCloudTestCase.activeClusterShape(1, 1));\n    \n    try (CloudSolrClient client = getCloudSolrClient(zkServer.getZkAddress(), true, cloudClient.getLbClient().getHttpClient())) {\n      client.setDefaultCollection(collectionName);\n      StoppableIndexingThread thread = new StoppableIndexingThread(controlClient, client, \"i1\", true);\n      try {\n        thread.start();\n        Thread.sleep(1000); // give the indexer sometime to do its work\n        thread.safeStop();\n        thread.join();\n        client.commit();\n        controlClient.commit();\n\n        CollectionAdminRequest.SplitShard splitShard = CollectionAdminRequest.splitShard(collectionName);\n        splitShard.setShardName(SHARD1);\n        splitShard.setSplitMethod(splitMethod.toLower());\n        String asyncId = splitShard.processAsync(client);\n        RequestStatusState state = CollectionAdminRequest.requestStatus(asyncId).waitFor(client, 120);\n        if (state == RequestStatusState.COMPLETED)  {\n          waitForRecoveriesToFinish(collectionName, true);\n          // let's wait to see parent shard become inactive\n          CountDownLatch latch = new CountDownLatch(1);\n          client.getZkStateReader().registerCollectionStateWatcher(collectionName, (liveNodes, collectionState) -> {\n            Slice parent = collectionState.getSlice(SHARD1);\n            Slice slice10 = collectionState.getSlice(SHARD1_0);\n            Slice slice11 = collectionState.getSlice(SHARD1_1);\n            if (slice10 != null && slice11 != null &&\n                parent.getState() == Slice.State.INACTIVE &&\n                slice10.getState() == Slice.State.ACTIVE &&\n                slice11.getState() == Slice.State.ACTIVE) {\n              latch.countDown();\n              return true; // removes the watch\n            }\n            return false;\n          });\n          latch.await(1, TimeUnit.MINUTES);\n          if (latch.getCount() != 0)  {\n            // sanity check\n            fail(\"Sub-shards did not become active even after waiting for 1 minute\");\n          }\n\n          int liveNodeCount = client.getZkStateReader().getClusterState().getLiveNodes().size();\n\n          // restart the sub-shard leader node\n          String stoppedNodeName = null;\n          boolean restarted = false;\n          for (JettySolrRunner jetty : jettys) {\n            int port = jetty.getBaseUrl().getPort();\n            if (replica.getStr(BASE_URL_PROP).contains(\":\" + port))  {\n              stoppedNodeName = jetty.getNodeName();\n              jetty.stop();\n              jetty.start();\n              restarted = true;\n              break;\n            }\n          }\n          if (!restarted) {\n            // sanity check\n            fail(\"We could not find a jetty to kill for replica: \" + replica.getCoreUrl());\n          }\n          \n          cloudClient.getZkStateReader().waitForLiveNodes(30, TimeUnit.SECONDS, SolrCloudTestCase.containsLiveNode(stoppedNodeName));\n\n          // add a new replica for the sub-shard\n          CollectionAdminRequest.AddReplica addReplica = CollectionAdminRequest.addReplicaToShard(collectionName, SHARD1_0);\n          // use control client because less chances of it being the node being restarted\n          // this is to avoid flakiness of test because of NoHttpResponseExceptions\n          String control_collection = client.getZkStateReader().getClusterState().getCollection(\"control_collection\").getReplicas().get(0).getStr(BASE_URL_PROP);\n          try (HttpSolrClient control = new HttpSolrClient.Builder(control_collection).withHttpClient(client.getLbClient().getHttpClient()).build())  {\n            state = addReplica.processAndWait(control, 30);\n          }\n          \n          cloudClient.waitForState(collectionName, 30, TimeUnit.SECONDS, SolrCloudTestCase.activeClusterShape(2, 4));\n          \n          if (state == RequestStatusState.COMPLETED)  {\n            CountDownLatch newReplicaLatch = new CountDownLatch(1);\n            client.getZkStateReader().registerCollectionStateWatcher(collectionName, (liveNodes, collectionState) -> {\n              if (liveNodes.size() != liveNodeCount)  {\n                return false;\n              }\n              Slice slice = collectionState.getSlice(SHARD1_0);\n              if (slice.getReplicas().size() == 2)  {\n                if (slice.getReplicas().stream().noneMatch(r -> r.getState() == Replica.State.RECOVERING)) {\n                  // we see replicas and none of them are recovering\n                  newReplicaLatch.countDown();\n                  return true;\n                }\n              }\n              return false;\n            });\n            newReplicaLatch.await(30, TimeUnit.SECONDS);\n            // check consistency of sub-shard replica explicitly because checkShardConsistency methods doesn't\n            // handle new shards/replica so well.\n            ClusterState clusterState = client.getZkStateReader().getClusterState();\n            DocCollection collection = clusterState.getCollection(collectionName);\n            int numReplicasChecked = assertConsistentReplicas(collection.getSlice(SHARD1_0));\n            assertEquals(\"We should have checked consistency for exactly 2 replicas of shard1_0\", 2, numReplicasChecked);\n          } else  {\n            fail(\"Adding a replica to sub-shard did not complete even after waiting for 30 seconds!. Saw state = \" + state.getKey());\n          }\n        } else {\n          fail(\"We expected shard split to succeed on a static index but it didn't. Found state = \" + state.getKey());\n        }\n      } finally {\n        thread.safeStop();\n        thread.join();\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"bb222a3f9d9421d5c95afce73013fbd8de07ea1f":["a9be06eb0504cb6312c2a585959299e40280d9ba"],"a9be06eb0504cb6312c2a585959299e40280d9ba":["20c968c14aace7cf49843bf2c1fafc7fd3845659"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"add1e7dd742ea533ff4318cea83ca0a1f669f662":["bb222a3f9d9421d5c95afce73013fbd8de07ea1f"],"e46a76bb135597b8bf35930cfdb3702bdd1cbe6e":["add1e7dd742ea533ff4318cea83ca0a1f669f662"],"20c968c14aace7cf49843bf2c1fafc7fd3845659":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["e46a76bb135597b8bf35930cfdb3702bdd1cbe6e"]},"commit2Childs":{"bb222a3f9d9421d5c95afce73013fbd8de07ea1f":["add1e7dd742ea533ff4318cea83ca0a1f669f662"],"a9be06eb0504cb6312c2a585959299e40280d9ba":["bb222a3f9d9421d5c95afce73013fbd8de07ea1f"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["20c968c14aace7cf49843bf2c1fafc7fd3845659"],"add1e7dd742ea533ff4318cea83ca0a1f669f662":["e46a76bb135597b8bf35930cfdb3702bdd1cbe6e"],"20c968c14aace7cf49843bf2c1fafc7fd3845659":["a9be06eb0504cb6312c2a585959299e40280d9ba"],"e46a76bb135597b8bf35930cfdb3702bdd1cbe6e":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}