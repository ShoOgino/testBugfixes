{"path":"solr/core/src/java/org/apache/solr/spelling/PossibilityIterator#PossibilityIterator(Map[Token,LinkedHashMap[String,Integer]],int,int).mjava","commits":[{"id":"c903c3d15906a3da96b8c0c2fb704491005fdbdb","date":1453508227,"type":1,"author":"Dawid Weiss","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/spelling/PossibilityIterator#PossibilityIterator(Map[Token,LinkedHashMap[String,Integer]],int,int).mjava","pathOld":"solr/src/java/org/apache/solr/spelling/PossibilityIterator#PossibilityIterator(Map[Token,LinkedHashMap[String,Integer]],int,int).mjava","sourceNew":"\t/**\n\t * <p>\n\t * We assume here that the passed-in inner LinkedHashMaps are already sorted\n\t * in order of \"Best Possible Correction\".\n\t * </p>\n\t * \n\t * @param suggestions\n\t */\n\tpublic PossibilityIterator(Map<Token, LinkedHashMap<String, Integer>> suggestions, int maximumRequiredSuggestions, int maxEvaluations) {\n\t\tfor (Map.Entry<Token, LinkedHashMap<String, Integer>> entry : suggestions.entrySet()) {\n\t\t\tToken token = entry.getKey();\n\t\t\tList<SpellCheckCorrection> possibleCorrections = new ArrayList<SpellCheckCorrection>();\n\t\t\tfor (Map.Entry<String, Integer> entry1 : entry.getValue().entrySet()) {\n\t\t\t\tSpellCheckCorrection correction = new SpellCheckCorrection();\n\t\t\t\tcorrection.setOriginal(token);\n\t\t\t\tcorrection.setCorrection(entry1.getKey());\n\t\t\t\tcorrection.setNumberOfOccurences(entry1.getValue());\n\t\t\t\tpossibleCorrections.add(correction);\n\t\t\t}\n\t\t\tpossibilityList.add(possibleCorrections);\n\t\t}\n\n\t\tint wrapSize = possibilityList.size();\n\t\tif (wrapSize == 0) {\n\t\t\tdone = true;\n\t\t} else {\n\t\t\tcorrectionIndex = new int[wrapSize];\n\t\t\tfor (int i = 0; i < wrapSize; i++) {\n\t\t\t\tint suggestSize = possibilityList.get(i).size();\n\t\t\t\tif (suggestSize == 0) {\n\t\t\t\t\tdone = true;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tcorrectionIndex[i] = 0;\n\t\t\t}\n\t\t}\n\t\t\n\t\tlong count = 0;\n\t\tPriorityQueue<RankedSpellPossibility> rankedPossibilities = new PriorityQueue<RankedSpellPossibility>();\t\t\n\t\twhile (count < maxEvaluations && internalHasNext()) {\n\t\t\tRankedSpellPossibility rsp = internalNext();\n\t\t\tcount++;\t\t\t\n\t\t\t\n\t\t\tif(rankedPossibilities.size() >= maximumRequiredSuggestions && rsp.getRank() >= rankedPossibilities.peek().getRank()) {\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\trankedPossibilities.offer(rsp);\n\t\t\tif(rankedPossibilities.size() > maximumRequiredSuggestions) {\n\t\t\t\trankedPossibilities.poll();\n\t\t\t}\n\t\t}\n\t\t\n\t\tRankedSpellPossibility[] rpArr = new RankedSpellPossibility[rankedPossibilities.size()];\n\t\tfor(int i=rankedPossibilities.size() - 1  ; i>=0 ; i--) {\n\t\t\trpArr[i] = rankedPossibilities.remove();\n\t\t}\n\t\trankedPossibilityIterator = Arrays.asList(rpArr).iterator();\t\t\n\t}\n\n","sourceOld":"\t/**\n\t * <p>\n\t * We assume here that the passed-in inner LinkedHashMaps are already sorted\n\t * in order of \"Best Possible Correction\".\n\t * </p>\n\t * \n\t * @param suggestions\n\t */\n\tpublic PossibilityIterator(Map<Token, LinkedHashMap<String, Integer>> suggestions, int maximumRequiredSuggestions, int maxEvaluations) {\n\t\tfor (Map.Entry<Token, LinkedHashMap<String, Integer>> entry : suggestions.entrySet()) {\n\t\t\tToken token = entry.getKey();\n\t\t\tList<SpellCheckCorrection> possibleCorrections = new ArrayList<SpellCheckCorrection>();\n\t\t\tfor (Map.Entry<String, Integer> entry1 : entry.getValue().entrySet()) {\n\t\t\t\tSpellCheckCorrection correction = new SpellCheckCorrection();\n\t\t\t\tcorrection.setOriginal(token);\n\t\t\t\tcorrection.setCorrection(entry1.getKey());\n\t\t\t\tcorrection.setNumberOfOccurences(entry1.getValue());\n\t\t\t\tpossibleCorrections.add(correction);\n\t\t\t}\n\t\t\tpossibilityList.add(possibleCorrections);\n\t\t}\n\n\t\tint wrapSize = possibilityList.size();\n\t\tif (wrapSize == 0) {\n\t\t\tdone = true;\n\t\t} else {\n\t\t\tcorrectionIndex = new int[wrapSize];\n\t\t\tfor (int i = 0; i < wrapSize; i++) {\n\t\t\t\tint suggestSize = possibilityList.get(i).size();\n\t\t\t\tif (suggestSize == 0) {\n\t\t\t\t\tdone = true;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tcorrectionIndex[i] = 0;\n\t\t\t}\n\t\t}\n\t\t\n\t\tlong count = 0;\n\t\tPriorityQueue<RankedSpellPossibility> rankedPossibilities = new PriorityQueue<RankedSpellPossibility>();\t\t\n\t\twhile (count < maxEvaluations && internalHasNext()) {\n\t\t\tRankedSpellPossibility rsp = internalNext();\n\t\t\tcount++;\t\t\t\n\t\t\t\n\t\t\tif(rankedPossibilities.size() >= maximumRequiredSuggestions && rsp.getRank() >= rankedPossibilities.peek().getRank()) {\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\trankedPossibilities.offer(rsp);\n\t\t\tif(rankedPossibilities.size() > maximumRequiredSuggestions) {\n\t\t\t\trankedPossibilities.poll();\n\t\t\t}\n\t\t}\n\t\t\n\t\tRankedSpellPossibility[] rpArr = new RankedSpellPossibility[rankedPossibilities.size()];\n\t\tfor(int i=rankedPossibilities.size() - 1  ; i>=0 ; i--) {\n\t\t\trpArr[i] = rankedPossibilities.remove();\n\t\t}\n\t\trankedPossibilityIterator = Arrays.asList(rpArr).iterator();\t\t\n\t}\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a258fbb26824fd104ed795e5d9033d2d040049ee","date":1453508252,"type":1,"author":"Dawid Weiss","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/spelling/PossibilityIterator#PossibilityIterator(Map[Token,LinkedHashMap[String,Integer]],int,int).mjava","pathOld":"solr/src/java/org/apache/solr/spelling/PossibilityIterator#PossibilityIterator(Map[Token,LinkedHashMap[String,Integer]],int,int).mjava","sourceNew":"\t/**\n\t * <p>\n\t * We assume here that the passed-in inner LinkedHashMaps are already sorted\n\t * in order of \"Best Possible Correction\".\n\t * </p>\n\t * \n\t * @param suggestions\n\t */\n\tpublic PossibilityIterator(Map<Token, LinkedHashMap<String, Integer>> suggestions, int maximumRequiredSuggestions, int maxEvaluations) {\n\t\tfor (Map.Entry<Token, LinkedHashMap<String, Integer>> entry : suggestions.entrySet()) {\n\t\t\tToken token = entry.getKey();\n\t\t\tList<SpellCheckCorrection> possibleCorrections = new ArrayList<SpellCheckCorrection>();\n\t\t\tfor (Map.Entry<String, Integer> entry1 : entry.getValue().entrySet()) {\n\t\t\t\tSpellCheckCorrection correction = new SpellCheckCorrection();\n\t\t\t\tcorrection.setOriginal(token);\n\t\t\t\tcorrection.setCorrection(entry1.getKey());\n\t\t\t\tcorrection.setNumberOfOccurences(entry1.getValue());\n\t\t\t\tpossibleCorrections.add(correction);\n\t\t\t}\n\t\t\tpossibilityList.add(possibleCorrections);\n\t\t}\n\n\t\tint wrapSize = possibilityList.size();\n\t\tif (wrapSize == 0) {\n\t\t\tdone = true;\n\t\t} else {\n\t\t\tcorrectionIndex = new int[wrapSize];\n\t\t\tfor (int i = 0; i < wrapSize; i++) {\n\t\t\t\tint suggestSize = possibilityList.get(i).size();\n\t\t\t\tif (suggestSize == 0) {\n\t\t\t\t\tdone = true;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tcorrectionIndex[i] = 0;\n\t\t\t}\n\t\t}\n\t\t\n\t\tlong count = 0;\n\t\tPriorityQueue<RankedSpellPossibility> rankedPossibilities = new PriorityQueue<RankedSpellPossibility>();\t\t\n\t\twhile (count < maxEvaluations && internalHasNext()) {\n\t\t\tRankedSpellPossibility rsp = internalNext();\n\t\t\tcount++;\t\t\t\n\t\t\t\n\t\t\tif(rankedPossibilities.size() >= maximumRequiredSuggestions && rsp.getRank() >= rankedPossibilities.peek().getRank()) {\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\trankedPossibilities.offer(rsp);\n\t\t\tif(rankedPossibilities.size() > maximumRequiredSuggestions) {\n\t\t\t\trankedPossibilities.poll();\n\t\t\t}\n\t\t}\n\t\t\n\t\tRankedSpellPossibility[] rpArr = new RankedSpellPossibility[rankedPossibilities.size()];\n\t\tfor(int i=rankedPossibilities.size() - 1  ; i>=0 ; i--) {\n\t\t\trpArr[i] = rankedPossibilities.remove();\n\t\t}\n\t\trankedPossibilityIterator = Arrays.asList(rpArr).iterator();\t\t\n\t}\n\n","sourceOld":"\t/**\n\t * <p>\n\t * We assume here that the passed-in inner LinkedHashMaps are already sorted\n\t * in order of \"Best Possible Correction\".\n\t * </p>\n\t * \n\t * @param suggestions\n\t */\n\tpublic PossibilityIterator(Map<Token, LinkedHashMap<String, Integer>> suggestions, int maximumRequiredSuggestions, int maxEvaluations) {\n\t\tfor (Map.Entry<Token, LinkedHashMap<String, Integer>> entry : suggestions.entrySet()) {\n\t\t\tToken token = entry.getKey();\n\t\t\tList<SpellCheckCorrection> possibleCorrections = new ArrayList<SpellCheckCorrection>();\n\t\t\tfor (Map.Entry<String, Integer> entry1 : entry.getValue().entrySet()) {\n\t\t\t\tSpellCheckCorrection correction = new SpellCheckCorrection();\n\t\t\t\tcorrection.setOriginal(token);\n\t\t\t\tcorrection.setCorrection(entry1.getKey());\n\t\t\t\tcorrection.setNumberOfOccurences(entry1.getValue());\n\t\t\t\tpossibleCorrections.add(correction);\n\t\t\t}\n\t\t\tpossibilityList.add(possibleCorrections);\n\t\t}\n\n\t\tint wrapSize = possibilityList.size();\n\t\tif (wrapSize == 0) {\n\t\t\tdone = true;\n\t\t} else {\n\t\t\tcorrectionIndex = new int[wrapSize];\n\t\t\tfor (int i = 0; i < wrapSize; i++) {\n\t\t\t\tint suggestSize = possibilityList.get(i).size();\n\t\t\t\tif (suggestSize == 0) {\n\t\t\t\t\tdone = true;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tcorrectionIndex[i] = 0;\n\t\t\t}\n\t\t}\n\t\t\n\t\tlong count = 0;\n\t\tPriorityQueue<RankedSpellPossibility> rankedPossibilities = new PriorityQueue<RankedSpellPossibility>();\t\t\n\t\twhile (count < maxEvaluations && internalHasNext()) {\n\t\t\tRankedSpellPossibility rsp = internalNext();\n\t\t\tcount++;\t\t\t\n\t\t\t\n\t\t\tif(rankedPossibilities.size() >= maximumRequiredSuggestions && rsp.getRank() >= rankedPossibilities.peek().getRank()) {\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\trankedPossibilities.offer(rsp);\n\t\t\tif(rankedPossibilities.size() > maximumRequiredSuggestions) {\n\t\t\t\trankedPossibilities.poll();\n\t\t\t}\n\t\t}\n\t\t\n\t\tRankedSpellPossibility[] rpArr = new RankedSpellPossibility[rankedPossibilities.size()];\n\t\tfor(int i=rankedPossibilities.size() - 1  ; i>=0 ; i--) {\n\t\t\trpArr[i] = rankedPossibilities.remove();\n\t\t}\n\t\trankedPossibilityIterator = Arrays.asList(rpArr).iterator();\t\t\n\t}\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c26f00b574427b55127e869b935845554afde1fa","date":1310252513,"type":1,"author":"Steven Rowe","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/spelling/PossibilityIterator#PossibilityIterator(Map[Token,LinkedHashMap[String,Integer]],int,int).mjava","pathOld":"solr/src/java/org/apache/solr/spelling/PossibilityIterator#PossibilityIterator(Map[Token,LinkedHashMap[String,Integer]],int,int).mjava","sourceNew":"\t/**\n\t * <p>\n\t * We assume here that the passed-in inner LinkedHashMaps are already sorted\n\t * in order of \"Best Possible Correction\".\n\t * </p>\n\t * \n\t * @param suggestions\n\t */\n\tpublic PossibilityIterator(Map<Token, LinkedHashMap<String, Integer>> suggestions, int maximumRequiredSuggestions, int maxEvaluations) {\n\t\tfor (Map.Entry<Token, LinkedHashMap<String, Integer>> entry : suggestions.entrySet()) {\n\t\t\tToken token = entry.getKey();\n\t\t\tList<SpellCheckCorrection> possibleCorrections = new ArrayList<SpellCheckCorrection>();\n\t\t\tfor (Map.Entry<String, Integer> entry1 : entry.getValue().entrySet()) {\n\t\t\t\tSpellCheckCorrection correction = new SpellCheckCorrection();\n\t\t\t\tcorrection.setOriginal(token);\n\t\t\t\tcorrection.setCorrection(entry1.getKey());\n\t\t\t\tcorrection.setNumberOfOccurences(entry1.getValue());\n\t\t\t\tpossibleCorrections.add(correction);\n\t\t\t}\n\t\t\tpossibilityList.add(possibleCorrections);\n\t\t}\n\n\t\tint wrapSize = possibilityList.size();\n\t\tif (wrapSize == 0) {\n\t\t\tdone = true;\n\t\t} else {\n\t\t\tcorrectionIndex = new int[wrapSize];\n\t\t\tfor (int i = 0; i < wrapSize; i++) {\n\t\t\t\tint suggestSize = possibilityList.get(i).size();\n\t\t\t\tif (suggestSize == 0) {\n\t\t\t\t\tdone = true;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tcorrectionIndex[i] = 0;\n\t\t\t}\n\t\t}\n\t\t\n\t\tlong count = 0;\n\t\tPriorityQueue<RankedSpellPossibility> rankedPossibilities = new PriorityQueue<RankedSpellPossibility>();\t\t\n\t\twhile (count < maxEvaluations && internalHasNext()) {\n\t\t\tRankedSpellPossibility rsp = internalNext();\n\t\t\tcount++;\t\t\t\n\t\t\t\n\t\t\tif(rankedPossibilities.size() >= maximumRequiredSuggestions && rsp.getRank() >= rankedPossibilities.peek().getRank()) {\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\trankedPossibilities.offer(rsp);\n\t\t\tif(rankedPossibilities.size() > maximumRequiredSuggestions) {\n\t\t\t\trankedPossibilities.poll();\n\t\t\t}\n\t\t}\n\t\t\n\t\tRankedSpellPossibility[] rpArr = new RankedSpellPossibility[rankedPossibilities.size()];\n\t\tfor(int i=rankedPossibilities.size() - 1  ; i>=0 ; i--) {\n\t\t\trpArr[i] = rankedPossibilities.remove();\n\t\t}\n\t\trankedPossibilityIterator = Arrays.asList(rpArr).iterator();\t\t\n\t}\n\n","sourceOld":"\t/**\n\t * <p>\n\t * We assume here that the passed-in inner LinkedHashMaps are already sorted\n\t * in order of \"Best Possible Correction\".\n\t * </p>\n\t * \n\t * @param suggestions\n\t */\n\tpublic PossibilityIterator(Map<Token, LinkedHashMap<String, Integer>> suggestions, int maximumRequiredSuggestions, int maxEvaluations) {\n\t\tfor (Map.Entry<Token, LinkedHashMap<String, Integer>> entry : suggestions.entrySet()) {\n\t\t\tToken token = entry.getKey();\n\t\t\tList<SpellCheckCorrection> possibleCorrections = new ArrayList<SpellCheckCorrection>();\n\t\t\tfor (Map.Entry<String, Integer> entry1 : entry.getValue().entrySet()) {\n\t\t\t\tSpellCheckCorrection correction = new SpellCheckCorrection();\n\t\t\t\tcorrection.setOriginal(token);\n\t\t\t\tcorrection.setCorrection(entry1.getKey());\n\t\t\t\tcorrection.setNumberOfOccurences(entry1.getValue());\n\t\t\t\tpossibleCorrections.add(correction);\n\t\t\t}\n\t\t\tpossibilityList.add(possibleCorrections);\n\t\t}\n\n\t\tint wrapSize = possibilityList.size();\n\t\tif (wrapSize == 0) {\n\t\t\tdone = true;\n\t\t} else {\n\t\t\tcorrectionIndex = new int[wrapSize];\n\t\t\tfor (int i = 0; i < wrapSize; i++) {\n\t\t\t\tint suggestSize = possibilityList.get(i).size();\n\t\t\t\tif (suggestSize == 0) {\n\t\t\t\t\tdone = true;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tcorrectionIndex[i] = 0;\n\t\t\t}\n\t\t}\n\t\t\n\t\tlong count = 0;\n\t\tPriorityQueue<RankedSpellPossibility> rankedPossibilities = new PriorityQueue<RankedSpellPossibility>();\t\t\n\t\twhile (count < maxEvaluations && internalHasNext()) {\n\t\t\tRankedSpellPossibility rsp = internalNext();\n\t\t\tcount++;\t\t\t\n\t\t\t\n\t\t\tif(rankedPossibilities.size() >= maximumRequiredSuggestions && rsp.getRank() >= rankedPossibilities.peek().getRank()) {\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\trankedPossibilities.offer(rsp);\n\t\t\tif(rankedPossibilities.size() > maximumRequiredSuggestions) {\n\t\t\t\trankedPossibilities.poll();\n\t\t\t}\n\t\t}\n\t\t\n\t\tRankedSpellPossibility[] rpArr = new RankedSpellPossibility[rankedPossibilities.size()];\n\t\tfor(int i=rankedPossibilities.size() - 1  ; i>=0 ; i--) {\n\t\t\trpArr[i] = rankedPossibilities.remove();\n\t\t}\n\t\trankedPossibilityIterator = Arrays.asList(rpArr).iterator();\t\t\n\t}\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"51338b5fe0f5d865f3d3ce9ed83d94ae4733a8c5","date":1320922486,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/spelling/PossibilityIterator#PossibilityIterator(Map[Token,LinkedHashMap[String,Integer]],int,int).mjava","pathOld":"solr/core/src/java/org/apache/solr/spelling/PossibilityIterator#PossibilityIterator(Map[Token,LinkedHashMap[String,Integer]],int,int).mjava","sourceNew":"\t/**\n\t * <p>\n\t * We assume here that the passed-in inner LinkedHashMaps are already sorted\n\t * in order of \"Best Possible Correction\".\n\t * </p>\n\t * \n\t * @param suggestions\n\t */\n\tpublic PossibilityIterator(Map<Token, LinkedHashMap<String, Integer>> suggestions, int maximumRequiredSuggestions, int maxEvaluations) {\n\t\tfor (Map.Entry<Token, LinkedHashMap<String, Integer>> entry : suggestions.entrySet()) {\n\t\t\tToken token = entry.getKey();\n\t\t\tif(entry.getValue().size()==0) {\n\t\t\t  continue;\n\t\t\t}\n\t\t\tList<SpellCheckCorrection> possibleCorrections = new ArrayList<SpellCheckCorrection>();\n\t\t\tfor (Map.Entry<String, Integer> entry1 : entry.getValue().entrySet()) {\n\t\t\t\tSpellCheckCorrection correction = new SpellCheckCorrection();\n\t\t\t\tcorrection.setOriginal(token);\n\t\t\t\tcorrection.setCorrection(entry1.getKey());\n\t\t\t\tcorrection.setNumberOfOccurences(entry1.getValue());\n\t\t\t\tpossibleCorrections.add(correction);\n\t\t\t}\n\t\t\tpossibilityList.add(possibleCorrections);\n\t\t}\n\n\t\tint wrapSize = possibilityList.size();\n\t\tif (wrapSize == 0) {\n\t\t\tdone = true;\n\t\t} else {\n\t\t\tcorrectionIndex = new int[wrapSize];\n\t\t\tfor (int i = 0; i < wrapSize; i++) {\n\t\t\t\tint suggestSize = possibilityList.get(i).size();\n\t\t\t\tif (suggestSize == 0) {\n\t\t\t\t\tdone = true;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tcorrectionIndex[i] = 0;\n\t\t\t}\n\t\t}\n\t\t\n\t\tlong count = 0;\n\t\tPriorityQueue<RankedSpellPossibility> rankedPossibilities = new PriorityQueue<RankedSpellPossibility>();\t\t\n\t\twhile (count < maxEvaluations && internalHasNext()) {\n\t\t\tRankedSpellPossibility rsp = internalNext();\n\t\t\tcount++;\t\t\t\n\t\t\t\n\t\t\tif(rankedPossibilities.size() >= maximumRequiredSuggestions && rsp.getRank() >= rankedPossibilities.peek().getRank()) {\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\trankedPossibilities.offer(rsp);\n\t\t\tif(rankedPossibilities.size() > maximumRequiredSuggestions) {\n\t\t\t\trankedPossibilities.poll();\n\t\t\t}\n\t\t}\n\t\t\n\t\tRankedSpellPossibility[] rpArr = new RankedSpellPossibility[rankedPossibilities.size()];\n\t\tfor(int i=rankedPossibilities.size() - 1  ; i>=0 ; i--) {\n\t\t\trpArr[i] = rankedPossibilities.remove();\n\t\t}\n\t\trankedPossibilityIterator = Arrays.asList(rpArr).iterator();\t\t\n\t}\n\n","sourceOld":"\t/**\n\t * <p>\n\t * We assume here that the passed-in inner LinkedHashMaps are already sorted\n\t * in order of \"Best Possible Correction\".\n\t * </p>\n\t * \n\t * @param suggestions\n\t */\n\tpublic PossibilityIterator(Map<Token, LinkedHashMap<String, Integer>> suggestions, int maximumRequiredSuggestions, int maxEvaluations) {\n\t\tfor (Map.Entry<Token, LinkedHashMap<String, Integer>> entry : suggestions.entrySet()) {\n\t\t\tToken token = entry.getKey();\n\t\t\tList<SpellCheckCorrection> possibleCorrections = new ArrayList<SpellCheckCorrection>();\n\t\t\tfor (Map.Entry<String, Integer> entry1 : entry.getValue().entrySet()) {\n\t\t\t\tSpellCheckCorrection correction = new SpellCheckCorrection();\n\t\t\t\tcorrection.setOriginal(token);\n\t\t\t\tcorrection.setCorrection(entry1.getKey());\n\t\t\t\tcorrection.setNumberOfOccurences(entry1.getValue());\n\t\t\t\tpossibleCorrections.add(correction);\n\t\t\t}\n\t\t\tpossibilityList.add(possibleCorrections);\n\t\t}\n\n\t\tint wrapSize = possibilityList.size();\n\t\tif (wrapSize == 0) {\n\t\t\tdone = true;\n\t\t} else {\n\t\t\tcorrectionIndex = new int[wrapSize];\n\t\t\tfor (int i = 0; i < wrapSize; i++) {\n\t\t\t\tint suggestSize = possibilityList.get(i).size();\n\t\t\t\tif (suggestSize == 0) {\n\t\t\t\t\tdone = true;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tcorrectionIndex[i] = 0;\n\t\t\t}\n\t\t}\n\t\t\n\t\tlong count = 0;\n\t\tPriorityQueue<RankedSpellPossibility> rankedPossibilities = new PriorityQueue<RankedSpellPossibility>();\t\t\n\t\twhile (count < maxEvaluations && internalHasNext()) {\n\t\t\tRankedSpellPossibility rsp = internalNext();\n\t\t\tcount++;\t\t\t\n\t\t\t\n\t\t\tif(rankedPossibilities.size() >= maximumRequiredSuggestions && rsp.getRank() >= rankedPossibilities.peek().getRank()) {\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\trankedPossibilities.offer(rsp);\n\t\t\tif(rankedPossibilities.size() > maximumRequiredSuggestions) {\n\t\t\t\trankedPossibilities.poll();\n\t\t\t}\n\t\t}\n\t\t\n\t\tRankedSpellPossibility[] rpArr = new RankedSpellPossibility[rankedPossibilities.size()];\n\t\tfor(int i=rankedPossibilities.size() - 1  ; i>=0 ; i--) {\n\t\t\trpArr[i] = rankedPossibilities.remove();\n\t\t}\n\t\trankedPossibilityIterator = Arrays.asList(rpArr).iterator();\t\t\n\t}\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"541f6605a29362fa8a42f33b69069e7da5178034","date":1337786849,"type":3,"author":"James Dyer","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/spelling/PossibilityIterator#PossibilityIterator(Map[Token,LinkedHashMap[String,Integer]],int,int).mjava","pathOld":"solr/core/src/java/org/apache/solr/spelling/PossibilityIterator#PossibilityIterator(Map[Token,LinkedHashMap[String,Integer]],int,int).mjava","sourceNew":"\t/**\n\t * <p>\n\t * We assume here that the passed-in inner LinkedHashMaps are already sorted\n\t * in order of \"Best Possible Correction\".\n\t * </p>\n\t * \n\t * @param suggestions\n\t */\n\tpublic PossibilityIterator(Map<Token, LinkedHashMap<String, Integer>> suggestions, int maximumRequiredSuggestions, int maxEvaluations) {\n\t\tfor (Map.Entry<Token, LinkedHashMap<String, Integer>> entry : suggestions.entrySet()) {\n\t\t\tToken token = entry.getKey();\n\t\t\tif(entry.getValue().size()==0) {\n\t\t\t  continue;\n\t\t\t}\n\t\t\tList<SpellCheckCorrection> possibleCorrections = new ArrayList<SpellCheckCorrection>();\n\t\t\tfor (Map.Entry<String, Integer> entry1 : entry.getValue().entrySet()) {\n\t\t\t\tSpellCheckCorrection correction = new SpellCheckCorrection();\n\t\t\t\tcorrection.setOriginal(token);\n\t\t\t\tcorrection.setCorrection(entry1.getKey());\n\t\t\t\tcorrection.setNumberOfOccurences(entry1.getValue());\n\t\t\t\tpossibleCorrections.add(correction);\n\t\t\t}\n\t\t\tpossibilityList.add(possibleCorrections);\n\t\t}\n\n\t\tint wrapSize = possibilityList.size();\n\t\tif (wrapSize == 0) {\n\t\t\tdone = true;\n\t\t} else {\n\t\t\tcorrectionIndex = new int[wrapSize];\n\t\t\tfor (int i = 0; i < wrapSize; i++) {\n\t\t\t\tint suggestSize = possibilityList.get(i).size();\n\t\t\t\tif (suggestSize == 0) {\n\t\t\t\t\tdone = true;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tcorrectionIndex[i] = 0;\n\t\t\t}\n\t\t}\n\t\t\n\t\tlong count = 0;\n\t\tPriorityQueue<RankedSpellPossibility> rankedPossibilities = new PriorityQueue<RankedSpellPossibility>();\t\t\n\t\twhile (count < maxEvaluations && internalHasNext()) {\n\t\t\tRankedSpellPossibility rsp = internalNext();\n\t\t\tcount++;\t\t\t\n\t\t\t\n\t\t\tif(rankedPossibilities.size() >= maximumRequiredSuggestions && rsp.getRank() >= rankedPossibilities.peek().getRank()) {\n\t\t\t\tcontinue;\n\t\t\t}\n      if (!isSuggestionForReal(rsp)) {\n        continue;\n      }\n\t\t\trankedPossibilities.offer(rsp);\n\t\t\tif(rankedPossibilities.size() > maximumRequiredSuggestions) {\n\t\t\t\trankedPossibilities.poll();\n\t\t\t}\n\t\t}\n\t\t\n\t\tRankedSpellPossibility[] rpArr = new RankedSpellPossibility[rankedPossibilities.size()];\n\t\tfor(int i=rankedPossibilities.size() - 1  ; i>=0 ; i--) {\n\t\t\trpArr[i] = rankedPossibilities.remove();\n\t\t}\n\t\trankedPossibilityIterator = Arrays.asList(rpArr).iterator();\t\t\n\t}\n\n","sourceOld":"\t/**\n\t * <p>\n\t * We assume here that the passed-in inner LinkedHashMaps are already sorted\n\t * in order of \"Best Possible Correction\".\n\t * </p>\n\t * \n\t * @param suggestions\n\t */\n\tpublic PossibilityIterator(Map<Token, LinkedHashMap<String, Integer>> suggestions, int maximumRequiredSuggestions, int maxEvaluations) {\n\t\tfor (Map.Entry<Token, LinkedHashMap<String, Integer>> entry : suggestions.entrySet()) {\n\t\t\tToken token = entry.getKey();\n\t\t\tif(entry.getValue().size()==0) {\n\t\t\t  continue;\n\t\t\t}\n\t\t\tList<SpellCheckCorrection> possibleCorrections = new ArrayList<SpellCheckCorrection>();\n\t\t\tfor (Map.Entry<String, Integer> entry1 : entry.getValue().entrySet()) {\n\t\t\t\tSpellCheckCorrection correction = new SpellCheckCorrection();\n\t\t\t\tcorrection.setOriginal(token);\n\t\t\t\tcorrection.setCorrection(entry1.getKey());\n\t\t\t\tcorrection.setNumberOfOccurences(entry1.getValue());\n\t\t\t\tpossibleCorrections.add(correction);\n\t\t\t}\n\t\t\tpossibilityList.add(possibleCorrections);\n\t\t}\n\n\t\tint wrapSize = possibilityList.size();\n\t\tif (wrapSize == 0) {\n\t\t\tdone = true;\n\t\t} else {\n\t\t\tcorrectionIndex = new int[wrapSize];\n\t\t\tfor (int i = 0; i < wrapSize; i++) {\n\t\t\t\tint suggestSize = possibilityList.get(i).size();\n\t\t\t\tif (suggestSize == 0) {\n\t\t\t\t\tdone = true;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tcorrectionIndex[i] = 0;\n\t\t\t}\n\t\t}\n\t\t\n\t\tlong count = 0;\n\t\tPriorityQueue<RankedSpellPossibility> rankedPossibilities = new PriorityQueue<RankedSpellPossibility>();\t\t\n\t\twhile (count < maxEvaluations && internalHasNext()) {\n\t\t\tRankedSpellPossibility rsp = internalNext();\n\t\t\tcount++;\t\t\t\n\t\t\t\n\t\t\tif(rankedPossibilities.size() >= maximumRequiredSuggestions && rsp.getRank() >= rankedPossibilities.peek().getRank()) {\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\trankedPossibilities.offer(rsp);\n\t\t\tif(rankedPossibilities.size() > maximumRequiredSuggestions) {\n\t\t\t\trankedPossibilities.poll();\n\t\t\t}\n\t\t}\n\t\t\n\t\tRankedSpellPossibility[] rpArr = new RankedSpellPossibility[rankedPossibilities.size()];\n\t\tfor(int i=rankedPossibilities.size() - 1  ; i>=0 ; i--) {\n\t\t\trpArr[i] = rankedPossibilities.remove();\n\t\t}\n\t\trankedPossibilityIterator = Arrays.asList(rpArr).iterator();\t\t\n\t}\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3599646b4d4c346cf74d334813488b8b337b5bf5","date":1337790261,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/spelling/PossibilityIterator#PossibilityIterator(Map[Token,LinkedHashMap[String,Integer]],int,int).mjava","pathOld":"solr/core/src/java/org/apache/solr/spelling/PossibilityIterator#PossibilityIterator(Map[Token,LinkedHashMap[String,Integer]],int,int).mjava","sourceNew":"\t/**\n\t * <p>\n\t * We assume here that the passed-in inner LinkedHashMaps are already sorted\n\t * in order of \"Best Possible Correction\".\n\t * </p>\n\t * \n\t * @param suggestions\n\t */\n\tpublic PossibilityIterator(Map<Token, LinkedHashMap<String, Integer>> suggestions, int maximumRequiredSuggestions, int maxEvaluations) {\n\t\tfor (Map.Entry<Token, LinkedHashMap<String, Integer>> entry : suggestions.entrySet()) {\n\t\t\tToken token = entry.getKey();\n\t\t\tif(entry.getValue().size()==0) {\n\t\t\t  continue;\n\t\t\t}\n\t\t\tList<SpellCheckCorrection> possibleCorrections = new ArrayList<SpellCheckCorrection>();\n\t\t\tfor (Map.Entry<String, Integer> entry1 : entry.getValue().entrySet()) {\n\t\t\t\tSpellCheckCorrection correction = new SpellCheckCorrection();\n\t\t\t\tcorrection.setOriginal(token);\n\t\t\t\tcorrection.setCorrection(entry1.getKey());\n\t\t\t\tcorrection.setNumberOfOccurences(entry1.getValue());\n\t\t\t\tpossibleCorrections.add(correction);\n\t\t\t}\n\t\t\tpossibilityList.add(possibleCorrections);\n\t\t}\n\n\t\tint wrapSize = possibilityList.size();\n\t\tif (wrapSize == 0) {\n\t\t\tdone = true;\n\t\t} else {\n\t\t\tcorrectionIndex = new int[wrapSize];\n\t\t\tfor (int i = 0; i < wrapSize; i++) {\n\t\t\t\tint suggestSize = possibilityList.get(i).size();\n\t\t\t\tif (suggestSize == 0) {\n\t\t\t\t\tdone = true;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tcorrectionIndex[i] = 0;\n\t\t\t}\n\t\t}\n\t\t\n\t\tlong count = 0;\n\t\tPriorityQueue<RankedSpellPossibility> rankedPossibilities = new PriorityQueue<RankedSpellPossibility>();\t\t\n\t\twhile (count < maxEvaluations && internalHasNext()) {\n\t\t\tRankedSpellPossibility rsp = internalNext();\n\t\t\tcount++;\t\t\t\n\t\t\t\n\t\t\tif(rankedPossibilities.size() >= maximumRequiredSuggestions && rsp.getRank() >= rankedPossibilities.peek().getRank()) {\n\t\t\t\tcontinue;\n\t\t\t}\n      if (!isSuggestionForReal(rsp)) {\n        continue;\n      }\n\t\t\trankedPossibilities.offer(rsp);\n\t\t\tif(rankedPossibilities.size() > maximumRequiredSuggestions) {\n\t\t\t\trankedPossibilities.poll();\n\t\t\t}\n\t\t}\n\t\t\n\t\tRankedSpellPossibility[] rpArr = new RankedSpellPossibility[rankedPossibilities.size()];\n\t\tfor(int i=rankedPossibilities.size() - 1  ; i>=0 ; i--) {\n\t\t\trpArr[i] = rankedPossibilities.remove();\n\t\t}\n\t\trankedPossibilityIterator = Arrays.asList(rpArr).iterator();\t\t\n\t}\n\n","sourceOld":"\t/**\n\t * <p>\n\t * We assume here that the passed-in inner LinkedHashMaps are already sorted\n\t * in order of \"Best Possible Correction\".\n\t * </p>\n\t * \n\t * @param suggestions\n\t */\n\tpublic PossibilityIterator(Map<Token, LinkedHashMap<String, Integer>> suggestions, int maximumRequiredSuggestions, int maxEvaluations) {\n\t\tfor (Map.Entry<Token, LinkedHashMap<String, Integer>> entry : suggestions.entrySet()) {\n\t\t\tToken token = entry.getKey();\n\t\t\tif(entry.getValue().size()==0) {\n\t\t\t  continue;\n\t\t\t}\n\t\t\tList<SpellCheckCorrection> possibleCorrections = new ArrayList<SpellCheckCorrection>();\n\t\t\tfor (Map.Entry<String, Integer> entry1 : entry.getValue().entrySet()) {\n\t\t\t\tSpellCheckCorrection correction = new SpellCheckCorrection();\n\t\t\t\tcorrection.setOriginal(token);\n\t\t\t\tcorrection.setCorrection(entry1.getKey());\n\t\t\t\tcorrection.setNumberOfOccurences(entry1.getValue());\n\t\t\t\tpossibleCorrections.add(correction);\n\t\t\t}\n\t\t\tpossibilityList.add(possibleCorrections);\n\t\t}\n\n\t\tint wrapSize = possibilityList.size();\n\t\tif (wrapSize == 0) {\n\t\t\tdone = true;\n\t\t} else {\n\t\t\tcorrectionIndex = new int[wrapSize];\n\t\t\tfor (int i = 0; i < wrapSize; i++) {\n\t\t\t\tint suggestSize = possibilityList.get(i).size();\n\t\t\t\tif (suggestSize == 0) {\n\t\t\t\t\tdone = true;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tcorrectionIndex[i] = 0;\n\t\t\t}\n\t\t}\n\t\t\n\t\tlong count = 0;\n\t\tPriorityQueue<RankedSpellPossibility> rankedPossibilities = new PriorityQueue<RankedSpellPossibility>();\t\t\n\t\twhile (count < maxEvaluations && internalHasNext()) {\n\t\t\tRankedSpellPossibility rsp = internalNext();\n\t\t\tcount++;\t\t\t\n\t\t\t\n\t\t\tif(rankedPossibilities.size() >= maximumRequiredSuggestions && rsp.getRank() >= rankedPossibilities.peek().getRank()) {\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\trankedPossibilities.offer(rsp);\n\t\t\tif(rankedPossibilities.size() > maximumRequiredSuggestions) {\n\t\t\t\trankedPossibilities.poll();\n\t\t\t}\n\t\t}\n\t\t\n\t\tRankedSpellPossibility[] rpArr = new RankedSpellPossibility[rankedPossibilities.size()];\n\t\tfor(int i=rankedPossibilities.size() - 1  ; i>=0 ; i--) {\n\t\t\trpArr[i] = rankedPossibilities.remove();\n\t\t}\n\t\trankedPossibilityIterator = Arrays.asList(rpArr).iterator();\t\t\n\t}\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0ad9ec888e587ca9a3279368245cdf00aabdc108","date":1338832525,"type":4,"author":"James Dyer","isMerge":false,"pathNew":"/dev/null","pathOld":"solr/core/src/java/org/apache/solr/spelling/PossibilityIterator#PossibilityIterator(Map[Token,LinkedHashMap[String,Integer]],int,int).mjava","sourceNew":null,"sourceOld":"\t/**\n\t * <p>\n\t * We assume here that the passed-in inner LinkedHashMaps are already sorted\n\t * in order of \"Best Possible Correction\".\n\t * </p>\n\t * \n\t * @param suggestions\n\t */\n\tpublic PossibilityIterator(Map<Token, LinkedHashMap<String, Integer>> suggestions, int maximumRequiredSuggestions, int maxEvaluations) {\n\t\tfor (Map.Entry<Token, LinkedHashMap<String, Integer>> entry : suggestions.entrySet()) {\n\t\t\tToken token = entry.getKey();\n\t\t\tif(entry.getValue().size()==0) {\n\t\t\t  continue;\n\t\t\t}\n\t\t\tList<SpellCheckCorrection> possibleCorrections = new ArrayList<SpellCheckCorrection>();\n\t\t\tfor (Map.Entry<String, Integer> entry1 : entry.getValue().entrySet()) {\n\t\t\t\tSpellCheckCorrection correction = new SpellCheckCorrection();\n\t\t\t\tcorrection.setOriginal(token);\n\t\t\t\tcorrection.setCorrection(entry1.getKey());\n\t\t\t\tcorrection.setNumberOfOccurences(entry1.getValue());\n\t\t\t\tpossibleCorrections.add(correction);\n\t\t\t}\n\t\t\tpossibilityList.add(possibleCorrections);\n\t\t}\n\n\t\tint wrapSize = possibilityList.size();\n\t\tif (wrapSize == 0) {\n\t\t\tdone = true;\n\t\t} else {\n\t\t\tcorrectionIndex = new int[wrapSize];\n\t\t\tfor (int i = 0; i < wrapSize; i++) {\n\t\t\t\tint suggestSize = possibilityList.get(i).size();\n\t\t\t\tif (suggestSize == 0) {\n\t\t\t\t\tdone = true;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tcorrectionIndex[i] = 0;\n\t\t\t}\n\t\t}\n\t\t\n\t\tlong count = 0;\n\t\tPriorityQueue<RankedSpellPossibility> rankedPossibilities = new PriorityQueue<RankedSpellPossibility>();\t\t\n\t\twhile (count < maxEvaluations && internalHasNext()) {\n\t\t\tRankedSpellPossibility rsp = internalNext();\n\t\t\tcount++;\t\t\t\n\t\t\t\n\t\t\tif(rankedPossibilities.size() >= maximumRequiredSuggestions && rsp.getRank() >= rankedPossibilities.peek().getRank()) {\n\t\t\t\tcontinue;\n\t\t\t}\n      if (!isSuggestionForReal(rsp)) {\n        continue;\n      }\n\t\t\trankedPossibilities.offer(rsp);\n\t\t\tif(rankedPossibilities.size() > maximumRequiredSuggestions) {\n\t\t\t\trankedPossibilities.poll();\n\t\t\t}\n\t\t}\n\t\t\n\t\tRankedSpellPossibility[] rpArr = new RankedSpellPossibility[rankedPossibilities.size()];\n\t\tfor(int i=rankedPossibilities.size() - 1  ; i>=0 ; i--) {\n\t\t\trpArr[i] = rankedPossibilities.remove();\n\t\t}\n\t\trankedPossibilityIterator = Arrays.asList(rpArr).iterator();\t\t\n\t}\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"0ad9ec888e587ca9a3279368245cdf00aabdc108":["541f6605a29362fa8a42f33b69069e7da5178034"],"c903c3d15906a3da96b8c0c2fb704491005fdbdb":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"c26f00b574427b55127e869b935845554afde1fa":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","c903c3d15906a3da96b8c0c2fb704491005fdbdb"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"3599646b4d4c346cf74d334813488b8b337b5bf5":["51338b5fe0f5d865f3d3ce9ed83d94ae4733a8c5","541f6605a29362fa8a42f33b69069e7da5178034"],"51338b5fe0f5d865f3d3ce9ed83d94ae4733a8c5":["c26f00b574427b55127e869b935845554afde1fa"],"a258fbb26824fd104ed795e5d9033d2d040049ee":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["0ad9ec888e587ca9a3279368245cdf00aabdc108"],"541f6605a29362fa8a42f33b69069e7da5178034":["51338b5fe0f5d865f3d3ce9ed83d94ae4733a8c5"]},"commit2Childs":{"0ad9ec888e587ca9a3279368245cdf00aabdc108":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"c903c3d15906a3da96b8c0c2fb704491005fdbdb":["c26f00b574427b55127e869b935845554afde1fa"],"c26f00b574427b55127e869b935845554afde1fa":["51338b5fe0f5d865f3d3ce9ed83d94ae4733a8c5"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["c903c3d15906a3da96b8c0c2fb704491005fdbdb","c26f00b574427b55127e869b935845554afde1fa","a258fbb26824fd104ed795e5d9033d2d040049ee"],"3599646b4d4c346cf74d334813488b8b337b5bf5":[],"51338b5fe0f5d865f3d3ce9ed83d94ae4733a8c5":["3599646b4d4c346cf74d334813488b8b337b5bf5","541f6605a29362fa8a42f33b69069e7da5178034"],"a258fbb26824fd104ed795e5d9033d2d040049ee":[],"541f6605a29362fa8a42f33b69069e7da5178034":["0ad9ec888e587ca9a3279368245cdf00aabdc108","3599646b4d4c346cf74d334813488b8b337b5bf5"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["3599646b4d4c346cf74d334813488b8b337b5bf5","a258fbb26824fd104ed795e5d9033d2d040049ee","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}