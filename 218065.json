{"path":"lucene/src/test/org/apache/lucene/index/TestLazyProxSkipping#createIndex(Random,int).mjava","commits":[{"id":"b21422ff1d1d56499dec481f193b402e5e8def5b","date":1281472367,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestLazyProxSkipping#createIndex(Random,int).mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestLazyProxSkipping#createIndex(int).mjava","sourceNew":"    private void createIndex(Random random, int numHits) throws IOException {\n        int numDocs = 500;\n        \n        Directory directory = new SeekCountingDirectory();\n        IndexWriter writer = new IndexWriter(directory, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(10));\n        ((LogMergePolicy) writer.getConfig().getMergePolicy()).setUseCompoundFile(false);\n        ((LogMergePolicy) writer.getConfig().getMergePolicy()).setUseCompoundDocStore(false);\n        for (int i = 0; i < numDocs; i++) {\n            Document doc = new Document();\n            String content;\n            if (i % (numDocs / numHits) == 0) {\n                // add a document that matches the query \"term1 term2\"\n                content = this.term1 + \" \" + this.term2;\n            } else if (i % 15 == 0) {\n                // add a document that only contains term1\n                content = this.term1 + \" \" + this.term1;\n            } else {\n                // add a document that contains term2 but not term 1\n                content = this.term3 + \" \" + this.term2;\n            }\n\n            doc.add(new Field(this.field, content, Field.Store.YES, Field.Index.ANALYZED));\n            writer.addDocument(doc);\n        }\n        \n        // make sure the index has only a single segment\n        writer.optimize();\n        writer.close();\n        \n        SegmentReader reader = SegmentReader.getOnlySegmentReader(directory);\n\n        this.searcher = new IndexSearcher(reader);        \n    }\n\n","sourceOld":"    private void createIndex(int numHits) throws IOException {\n        int numDocs = 500;\n        \n        Directory directory = new SeekCountingDirectory();\n        IndexWriter writer = new IndexWriter(directory, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(10));\n        ((LogMergePolicy) writer.getConfig().getMergePolicy()).setUseCompoundFile(false);\n        ((LogMergePolicy) writer.getConfig().getMergePolicy()).setUseCompoundDocStore(false);\n        for (int i = 0; i < numDocs; i++) {\n            Document doc = new Document();\n            String content;\n            if (i % (numDocs / numHits) == 0) {\n                // add a document that matches the query \"term1 term2\"\n                content = this.term1 + \" \" + this.term2;\n            } else if (i % 15 == 0) {\n                // add a document that only contains term1\n                content = this.term1 + \" \" + this.term1;\n            } else {\n                // add a document that contains term2 but not term 1\n                content = this.term3 + \" \" + this.term2;\n            }\n\n            doc.add(new Field(this.field, content, Field.Store.YES, Field.Index.ANALYZED));\n            writer.addDocument(doc);\n        }\n        \n        // make sure the index has only a single segment\n        writer.optimize();\n        writer.close();\n        \n        SegmentReader reader = SegmentReader.getOnlySegmentReader(directory);\n\n        this.searcher = new IndexSearcher(reader);        \n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a05409176bd65129d67a785ee70e881e238a9aef","date":1282582843,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestLazyProxSkipping#createIndex(Random,int).mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestLazyProxSkipping#createIndex(Random,int).mjava","sourceNew":"    private void createIndex(Random random, int numHits) throws IOException {\n        int numDocs = 500;\n        \n        Directory directory = new SeekCountingDirectory(new RAMDirectory());\n        IndexWriter writer = new IndexWriter(directory, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(10));\n        ((LogMergePolicy) writer.getConfig().getMergePolicy()).setUseCompoundFile(false);\n        ((LogMergePolicy) writer.getConfig().getMergePolicy()).setUseCompoundDocStore(false);\n        for (int i = 0; i < numDocs; i++) {\n            Document doc = new Document();\n            String content;\n            if (i % (numDocs / numHits) == 0) {\n                // add a document that matches the query \"term1 term2\"\n                content = this.term1 + \" \" + this.term2;\n            } else if (i % 15 == 0) {\n                // add a document that only contains term1\n                content = this.term1 + \" \" + this.term1;\n            } else {\n                // add a document that contains term2 but not term 1\n                content = this.term3 + \" \" + this.term2;\n            }\n\n            doc.add(new Field(this.field, content, Field.Store.YES, Field.Index.ANALYZED));\n            writer.addDocument(doc);\n        }\n        \n        // make sure the index has only a single segment\n        writer.optimize();\n        writer.close();\n        \n        SegmentReader reader = SegmentReader.getOnlySegmentReader(directory);\n\n        this.searcher = new IndexSearcher(reader);        \n    }\n\n","sourceOld":"    private void createIndex(Random random, int numHits) throws IOException {\n        int numDocs = 500;\n        \n        Directory directory = new SeekCountingDirectory();\n        IndexWriter writer = new IndexWriter(directory, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(10));\n        ((LogMergePolicy) writer.getConfig().getMergePolicy()).setUseCompoundFile(false);\n        ((LogMergePolicy) writer.getConfig().getMergePolicy()).setUseCompoundDocStore(false);\n        for (int i = 0; i < numDocs; i++) {\n            Document doc = new Document();\n            String content;\n            if (i % (numDocs / numHits) == 0) {\n                // add a document that matches the query \"term1 term2\"\n                content = this.term1 + \" \" + this.term2;\n            } else if (i % 15 == 0) {\n                // add a document that only contains term1\n                content = this.term1 + \" \" + this.term1;\n            } else {\n                // add a document that contains term2 but not term 1\n                content = this.term3 + \" \" + this.term2;\n            }\n\n            doc.add(new Field(this.field, content, Field.Store.YES, Field.Index.ANALYZED));\n            writer.addDocument(doc);\n        }\n        \n        // make sure the index has only a single segment\n        writer.optimize();\n        writer.close();\n        \n        SegmentReader reader = SegmentReader.getOnlySegmentReader(directory);\n\n        this.searcher = new IndexSearcher(reader);        \n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1f653cfcf159baeaafe5d01682a911e95bba4012","date":1284122058,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestLazyProxSkipping#createIndex(Random,int).mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestLazyProxSkipping#createIndex(Random,int).mjava","sourceNew":"    private void createIndex(Random random, int numHits) throws IOException {\n        int numDocs = 500;\n        \n        Directory directory = new SeekCountingDirectory(new RAMDirectory());\n        IndexWriter writer = new IndexWriter(directory, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(10));\n        ((LogMergePolicy) writer.getConfig().getMergePolicy()).setUseCompoundFile(false);\n        ((LogMergePolicy) writer.getConfig().getMergePolicy()).setUseCompoundDocStore(false);\n        for (int i = 0; i < numDocs; i++) {\n            Document doc = new Document();\n            String content;\n            if (i % (numDocs / numHits) == 0) {\n                // add a document that matches the query \"term1 term2\"\n                content = this.term1 + \" \" + this.term2;\n            } else if (i % 15 == 0) {\n                // add a document that only contains term1\n                content = this.term1 + \" \" + this.term1;\n            } else {\n                // add a document that contains term2 but not term 1\n                content = this.term3 + \" \" + this.term2;\n            }\n\n            doc.add(new Field(this.field, content, Field.Store.YES, Field.Index.ANALYZED));\n            writer.addDocument(doc);\n        }\n        \n        // make sure the index has only a single segment\n        writer.optimize();\n        writer.close();\n        \n        SegmentReader reader = SegmentReader.getOnlySegmentReader(directory);\n\n        this.searcher = new IndexSearcher(reader);        \n    }\n\n","sourceOld":"    private void createIndex(Random random, int numHits) throws IOException {\n        int numDocs = 500;\n        \n        Directory directory = new SeekCountingDirectory(new RAMDirectory());\n        IndexWriter writer = new IndexWriter(directory, newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(10));\n        ((LogMergePolicy) writer.getConfig().getMergePolicy()).setUseCompoundFile(false);\n        ((LogMergePolicy) writer.getConfig().getMergePolicy()).setUseCompoundDocStore(false);\n        for (int i = 0; i < numDocs; i++) {\n            Document doc = new Document();\n            String content;\n            if (i % (numDocs / numHits) == 0) {\n                // add a document that matches the query \"term1 term2\"\n                content = this.term1 + \" \" + this.term2;\n            } else if (i % 15 == 0) {\n                // add a document that only contains term1\n                content = this.term1 + \" \" + this.term1;\n            } else {\n                // add a document that contains term2 but not term 1\n                content = this.term3 + \" \" + this.term2;\n            }\n\n            doc.add(new Field(this.field, content, Field.Store.YES, Field.Index.ANALYZED));\n            writer.addDocument(doc);\n        }\n        \n        // make sure the index has only a single segment\n        writer.optimize();\n        writer.close();\n        \n        SegmentReader reader = SegmentReader.getOnlySegmentReader(directory);\n\n        this.searcher = new IndexSearcher(reader);        \n    }\n\n","bugFix":null,"bugIntro":["7740a3e0858e88aaf6b09efe52e35c04a0d717f7"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"132903c28af3aa6f67284b78de91c0f0a99488c2","date":1284282129,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestLazyProxSkipping#createIndex(Random,int).mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestLazyProxSkipping#createIndex(Random,int).mjava","sourceNew":"    private void createIndex(Random random, int numHits) throws IOException {\n        int numDocs = 500;\n        \n        Directory directory = new SeekCountingDirectory(new RAMDirectory());\n        IndexWriter writer = new IndexWriter(directory, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(10));\n        ((LogMergePolicy) writer.getConfig().getMergePolicy()).setUseCompoundFile(false);\n        ((LogMergePolicy) writer.getConfig().getMergePolicy()).setUseCompoundDocStore(false);\n        for (int i = 0; i < numDocs; i++) {\n            Document doc = new Document();\n            String content;\n            if (i % (numDocs / numHits) == 0) {\n                // add a document that matches the query \"term1 term2\"\n                content = this.term1 + \" \" + this.term2;\n            } else if (i % 15 == 0) {\n                // add a document that only contains term1\n                content = this.term1 + \" \" + this.term1;\n            } else {\n                // add a document that contains term2 but not term 1\n                content = this.term3 + \" \" + this.term2;\n            }\n\n            doc.add(newField(this.field, content, Field.Store.YES, Field.Index.ANALYZED));\n            writer.addDocument(doc);\n        }\n        \n        // make sure the index has only a single segment\n        writer.optimize();\n        writer.close();\n        \n        SegmentReader reader = SegmentReader.getOnlySegmentReader(directory);\n\n        this.searcher = new IndexSearcher(reader);        \n    }\n\n","sourceOld":"    private void createIndex(Random random, int numHits) throws IOException {\n        int numDocs = 500;\n        \n        Directory directory = new SeekCountingDirectory(new RAMDirectory());\n        IndexWriter writer = new IndexWriter(directory, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(10));\n        ((LogMergePolicy) writer.getConfig().getMergePolicy()).setUseCompoundFile(false);\n        ((LogMergePolicy) writer.getConfig().getMergePolicy()).setUseCompoundDocStore(false);\n        for (int i = 0; i < numDocs; i++) {\n            Document doc = new Document();\n            String content;\n            if (i % (numDocs / numHits) == 0) {\n                // add a document that matches the query \"term1 term2\"\n                content = this.term1 + \" \" + this.term2;\n            } else if (i % 15 == 0) {\n                // add a document that only contains term1\n                content = this.term1 + \" \" + this.term1;\n            } else {\n                // add a document that contains term2 but not term 1\n                content = this.term3 + \" \" + this.term2;\n            }\n\n            doc.add(new Field(this.field, content, Field.Store.YES, Field.Index.ANALYZED));\n            writer.addDocument(doc);\n        }\n        \n        // make sure the index has only a single segment\n        writer.optimize();\n        writer.close();\n        \n        SegmentReader reader = SegmentReader.getOnlySegmentReader(directory);\n\n        this.searcher = new IndexSearcher(reader);        \n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"8d47f68d60cbff5718136b945ba8c55982342f38","date":1285583375,"type":5,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestLazyProxSkipping#createIndex(int).mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestLazyProxSkipping#createIndex(Random,int).mjava","sourceNew":"    private void createIndex(int numHits) throws IOException {\n        int numDocs = 500;\n        \n        Directory directory = new SeekCountingDirectory(new RAMDirectory());\n        IndexWriter writer = new IndexWriter(directory, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(10));\n        ((LogMergePolicy) writer.getConfig().getMergePolicy()).setUseCompoundFile(false);\n        ((LogMergePolicy) writer.getConfig().getMergePolicy()).setUseCompoundDocStore(false);\n        for (int i = 0; i < numDocs; i++) {\n            Document doc = new Document();\n            String content;\n            if (i % (numDocs / numHits) == 0) {\n                // add a document that matches the query \"term1 term2\"\n                content = this.term1 + \" \" + this.term2;\n            } else if (i % 15 == 0) {\n                // add a document that only contains term1\n                content = this.term1 + \" \" + this.term1;\n            } else {\n                // add a document that contains term2 but not term 1\n                content = this.term3 + \" \" + this.term2;\n            }\n\n            doc.add(newField(this.field, content, Field.Store.YES, Field.Index.ANALYZED));\n            writer.addDocument(doc);\n        }\n        \n        // make sure the index has only a single segment\n        writer.optimize();\n        writer.close();\n        \n        SegmentReader reader = SegmentReader.getOnlySegmentReader(directory);\n\n        this.searcher = new IndexSearcher(reader);        \n    }\n\n","sourceOld":"    private void createIndex(Random random, int numHits) throws IOException {\n        int numDocs = 500;\n        \n        Directory directory = new SeekCountingDirectory(new RAMDirectory());\n        IndexWriter writer = new IndexWriter(directory, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(10));\n        ((LogMergePolicy) writer.getConfig().getMergePolicy()).setUseCompoundFile(false);\n        ((LogMergePolicy) writer.getConfig().getMergePolicy()).setUseCompoundDocStore(false);\n        for (int i = 0; i < numDocs; i++) {\n            Document doc = new Document();\n            String content;\n            if (i % (numDocs / numHits) == 0) {\n                // add a document that matches the query \"term1 term2\"\n                content = this.term1 + \" \" + this.term2;\n            } else if (i % 15 == 0) {\n                // add a document that only contains term1\n                content = this.term1 + \" \" + this.term1;\n            } else {\n                // add a document that contains term2 but not term 1\n                content = this.term3 + \" \" + this.term2;\n            }\n\n            doc.add(newField(this.field, content, Field.Store.YES, Field.Index.ANALYZED));\n            writer.addDocument(doc);\n        }\n        \n        // make sure the index has only a single segment\n        writer.optimize();\n        writer.close();\n        \n        SegmentReader reader = SegmentReader.getOnlySegmentReader(directory);\n\n        this.searcher = new IndexSearcher(reader);        \n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"1f653cfcf159baeaafe5d01682a911e95bba4012":["a05409176bd65129d67a785ee70e881e238a9aef"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"a05409176bd65129d67a785ee70e881e238a9aef":["b21422ff1d1d56499dec481f193b402e5e8def5b"],"132903c28af3aa6f67284b78de91c0f0a99488c2":["1f653cfcf159baeaafe5d01682a911e95bba4012"],"8d47f68d60cbff5718136b945ba8c55982342f38":["132903c28af3aa6f67284b78de91c0f0a99488c2"],"b21422ff1d1d56499dec481f193b402e5e8def5b":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["8d47f68d60cbff5718136b945ba8c55982342f38"]},"commit2Childs":{"1f653cfcf159baeaafe5d01682a911e95bba4012":["132903c28af3aa6f67284b78de91c0f0a99488c2"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["b21422ff1d1d56499dec481f193b402e5e8def5b"],"a05409176bd65129d67a785ee70e881e238a9aef":["1f653cfcf159baeaafe5d01682a911e95bba4012"],"132903c28af3aa6f67284b78de91c0f0a99488c2":["8d47f68d60cbff5718136b945ba8c55982342f38"],"8d47f68d60cbff5718136b945ba8c55982342f38":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"b21422ff1d1d56499dec481f193b402e5e8def5b":["a05409176bd65129d67a785ee70e881e238a9aef"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}