{"path":"contrib/dataimporthandler/src/main/java/org/apache/solr/handler/dataimport/XPathEntityProcessor#initQuery(String).mjava","commits":[{"id":"4d4f1b2c5601680b01c4bb95a43fe6fb73f03103","date":1217446558,"type":0,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"contrib/dataimporthandler/src/main/java/org/apache/solr/handler/dataimport/XPathEntityProcessor#initQuery(String).mjava","pathOld":"/dev/null","sourceNew":"  private void initQuery(String s) {\n    Reader data = null;\n    try {\n      final List<Map<String, Object>> rows = new ArrayList<Map<String, Object>>();\n      data = dataSource.getData(s);\n      if (xslTransformer != null) {\n        try {\n          SimpleCharArrayReader caw = new SimpleCharArrayReader();\n          xslTransformer.transform(new StreamSource(data),\n                  new StreamResult(caw));\n          data = caw.getReader();\n        } catch (TransformerException e) {\n          throw new DataImportHandlerException(\n                  DataImportHandlerException.SEVERE,\n                  \"Exception in applying XSL Transformeation\", e);\n        }\n      }\n      final List<Map<String, Object>> solrDocs = new ArrayList<Map<String, Object>>();\n      final boolean useSolrAddXml = Boolean.parseBoolean(context\n              .getEntityAttribute(USE_SOLR_ADD_SCHEMA));\n      xpathReader.streamRecords(data, new XPathRecordReader.Handler() {\n        @SuppressWarnings(\"unchecked\")\n        public void handle(Map<String, Object> record, String xpath) {\n          if (useSolrAddXml) {\n            List<String> names = (List<String>) record.get(\"name\");\n            List<String> values = (List<String>) record.get(\"value\");\n\n            Map<String, Object> row = new HashMap<String, Object>();\n\n            for (int i = 0; i < names.size(); i++) {\n              if (row.containsKey(names.get(i))) {\n                Object existing = row.get(names.get(i));\n                if (existing instanceof List) {\n                  List list = (List) existing;\n                  list.add(values.get(i));\n                } else {\n                  List list = new ArrayList();\n                  list.add(existing);\n                  list.add(values.get(i));\n                  row.put(names.get(i), list);\n                }\n              } else {\n                row.put(names.get(i), values.get(i));\n              }\n            }\n\n            solrDocs.add(row);\n          } else {\n            record.put(XPATH_FIELD_NAME, xpath);\n            rows.add(record);\n          }\n        }\n      });\n\n      if (useSolrAddXml) {\n        rowIterator = solrDocs.iterator();\n      } else {\n        rowIterator = rows.iterator();\n      }\n    } finally {\n      try {\n        data.close();\n      } catch (Exception e) { /* Ignore */\n      }\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d902f463d0a39aa9fc43326e245a5e5c94295d68","date":1217857015,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"contrib/dataimporthandler/src/main/java/org/apache/solr/handler/dataimport/XPathEntityProcessor#initQuery(String).mjava","pathOld":"contrib/dataimporthandler/src/main/java/org/apache/solr/handler/dataimport/XPathEntityProcessor#initQuery(String).mjava","sourceNew":"  private void initQuery(String s) {\n      Reader data = null;\n      try {\n        final List<Map<String, Object>> rows = new ArrayList<Map<String, Object>>();\n        data = dataSource.getData(s);\n        if (xslTransformer != null) {\n          try {\n            SimpleCharArrayReader caw = new SimpleCharArrayReader();\n            xslTransformer.transform(new StreamSource(data),\n                new StreamResult(caw));\n            data = caw.getReader();\n          } catch (TransformerException e) {\n            throw new DataImportHandlerException(\n                DataImportHandlerException.SEVERE,\n                \"Exception in applying XSL Transformeation\", e);\n          }\n        }\n        if(streamRows ){\n          rowIterator = getRowIterator(data);\n        } else {\n          xpathReader.streamRecords(data, new XPathRecordReader.Handler() {\n            @SuppressWarnings(\"unchecked\")\n            public void handle(Map<String, Object> record, String xpath) {\n              rows.add(readRow(record, xpath));\n            }\n          });\n          rowIterator = rows.iterator();\n        }\n      } finally {\n        if (!streamRows) {\n          closeIt(data);\n        }\n\n      }\n    }\n\n","sourceOld":"  private void initQuery(String s) {\n    Reader data = null;\n    try {\n      final List<Map<String, Object>> rows = new ArrayList<Map<String, Object>>();\n      data = dataSource.getData(s);\n      if (xslTransformer != null) {\n        try {\n          SimpleCharArrayReader caw = new SimpleCharArrayReader();\n          xslTransformer.transform(new StreamSource(data),\n                  new StreamResult(caw));\n          data = caw.getReader();\n        } catch (TransformerException e) {\n          throw new DataImportHandlerException(\n                  DataImportHandlerException.SEVERE,\n                  \"Exception in applying XSL Transformeation\", e);\n        }\n      }\n      final List<Map<String, Object>> solrDocs = new ArrayList<Map<String, Object>>();\n      final boolean useSolrAddXml = Boolean.parseBoolean(context\n              .getEntityAttribute(USE_SOLR_ADD_SCHEMA));\n      xpathReader.streamRecords(data, new XPathRecordReader.Handler() {\n        @SuppressWarnings(\"unchecked\")\n        public void handle(Map<String, Object> record, String xpath) {\n          if (useSolrAddXml) {\n            List<String> names = (List<String>) record.get(\"name\");\n            List<String> values = (List<String>) record.get(\"value\");\n\n            Map<String, Object> row = new HashMap<String, Object>();\n\n            for (int i = 0; i < names.size(); i++) {\n              if (row.containsKey(names.get(i))) {\n                Object existing = row.get(names.get(i));\n                if (existing instanceof List) {\n                  List list = (List) existing;\n                  list.add(values.get(i));\n                } else {\n                  List list = new ArrayList();\n                  list.add(existing);\n                  list.add(values.get(i));\n                  row.put(names.get(i), list);\n                }\n              } else {\n                row.put(names.get(i), values.get(i));\n              }\n            }\n\n            solrDocs.add(row);\n          } else {\n            record.put(XPATH_FIELD_NAME, xpath);\n            rows.add(record);\n          }\n        }\n      });\n\n      if (useSolrAddXml) {\n        rowIterator = solrDocs.iterator();\n      } else {\n        rowIterator = rows.iterator();\n      }\n    } finally {\n      try {\n        data.close();\n      } catch (Exception e) { /* Ignore */\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0ed3f47d0f68ca5e5107d28c942fbd1185f44c62","date":1226483472,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"contrib/dataimporthandler/src/main/java/org/apache/solr/handler/dataimport/XPathEntityProcessor#initQuery(String).mjava","pathOld":"contrib/dataimporthandler/src/main/java/org/apache/solr/handler/dataimport/XPathEntityProcessor#initQuery(String).mjava","sourceNew":"  private void initQuery(String s) {\n    Reader data = null;\n    try {\n      final List<Map<String, Object>> rows = new ArrayList<Map<String, Object>>();\n      try {\n        data = dataSource.getData(s);\n      } catch (Exception e) {\n        if (ABORT.equals(onError)) {\n          wrapAndThrow(SEVERE, e);\n        } else if (SKIP.equals(onError)) {\n          wrapAndThrow(DataImportHandlerException.SKIP, e);\n        } else {\n          LOG.warn(\"Failed for url : \" + s, e);\n          rowIterator = Collections.EMPTY_LIST.iterator();\n          return;\n        }\n      }\n      if (xslTransformer != null) {\n        try {\n          SimpleCharArrayReader caw = new SimpleCharArrayReader();\n          xslTransformer.transform(new StreamSource(data),\n                  new StreamResult(caw));\n          data = caw.getReader();\n        } catch (TransformerException e) {\n          if (ABORT.equals(onError)) {\n            wrapAndThrow(SEVERE, e, \"Exception in applying XSL Transformeation\");\n          } else if (SKIP.equals(onError)) {\n            wrapAndThrow(DataImportHandlerException.SKIP, e);\n          } else {\n            LOG.warn(\"Failed for url : \" + s, e);\n            rowIterator = Collections.EMPTY_LIST.iterator();\n            return;\n          }\n        }\n      }\n      if (streamRows) {\n        rowIterator = getRowIterator(data, s);\n      } else {\n        try {\n          xpathReader.streamRecords(data, new XPathRecordReader.Handler() {\n            @SuppressWarnings(\"unchecked\")\n            public void handle(Map<String, Object> record, String xpath) {\n              rows.add(readRow(record, xpath));\n            }\n          });\n        } catch (Exception e) {\n          String msg = \"Parsing failed for xml, url:\" + s + \"rows processed :\" + rows.size();\n          if (rows.size() > 0) msg += \"last row : \" + rows.get(rows.size() - 1);\n          if (ABORT.equals(onError)) {\n            wrapAndThrow(SEVERE, e, msg);\n          } else if (SKIP.equals(onError)) {\n            LOG.warn(msg, e);\n            Map<String, Object> map = new HashMap<String, Object>();\n            map.put(SKIP_DOC, Boolean.TRUE);\n            rows.add(map);\n          } else if (CONTINUE.equals(onError)) {\n            LOG.warn(msg, e);\n          }\n        }\n        rowIterator = rows.iterator();\n      }\n    } finally {\n      if (!streamRows) {\n        closeIt(data);\n      }\n\n    }\n  }\n\n","sourceOld":"  private void initQuery(String s) {\n      Reader data = null;\n      try {\n        final List<Map<String, Object>> rows = new ArrayList<Map<String, Object>>();\n        data = dataSource.getData(s);\n        if (xslTransformer != null) {\n          try {\n            SimpleCharArrayReader caw = new SimpleCharArrayReader();\n            xslTransformer.transform(new StreamSource(data),\n                new StreamResult(caw));\n            data = caw.getReader();\n          } catch (TransformerException e) {\n            throw new DataImportHandlerException(\n                DataImportHandlerException.SEVERE,\n                \"Exception in applying XSL Transformeation\", e);\n          }\n        }\n        if(streamRows ){\n          rowIterator = getRowIterator(data);\n        } else {\n          xpathReader.streamRecords(data, new XPathRecordReader.Handler() {\n            @SuppressWarnings(\"unchecked\")\n            public void handle(Map<String, Object> record, String xpath) {\n              rows.add(readRow(record, xpath));\n            }\n          });\n          rowIterator = rows.iterator();\n        }\n      } finally {\n        if (!streamRows) {\n          closeIt(data);\n        }\n\n      }\n    }\n\n","bugFix":null,"bugIntro":["1b604003611eabbb4d3f0fb1f89d3b6a017f8faa","1b604003611eabbb4d3f0fb1f89d3b6a017f8faa"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d183f54b5c7a1c64bd2935a5d5bd71091ebe4198","date":1235539651,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"contrib/dataimporthandler/src/main/java/org/apache/solr/handler/dataimport/XPathEntityProcessor#initQuery(String).mjava","pathOld":"contrib/dataimporthandler/src/main/java/org/apache/solr/handler/dataimport/XPathEntityProcessor#initQuery(String).mjava","sourceNew":"  private void initQuery(String s) {\n    Reader data = null;\n    try {\n      final List<Map<String, Object>> rows = new ArrayList<Map<String, Object>>();\n      try {\n        data = dataSource.getData(s);\n      } catch (Exception e) {\n        if (ABORT.equals(onError)) {\n          wrapAndThrow(SEVERE, e);\n        } else if (SKIP.equals(onError)) {\n          wrapAndThrow(DataImportHandlerException.SKIP, e);\n        } else {\n          LOG.warn(\"Failed for url : \" + s, e);\n          rowIterator = Collections.EMPTY_LIST.iterator();\n          return;\n        }\n      }\n      if (xslTransformer != null) {\n        try {\n          SimpleCharArrayReader caw = new SimpleCharArrayReader();\n          xslTransformer.transform(new StreamSource(data),\n                  new StreamResult(caw));\n          data = caw.getReader();\n        } catch (TransformerException e) {\n          if (ABORT.equals(onError)) {\n            wrapAndThrow(SEVERE, e, \"Exception in applying XSL Transformeation\");\n          } else if (SKIP.equals(onError)) {\n            wrapAndThrow(DataImportHandlerException.SKIP, e);\n          } else {\n            LOG.warn(\"Failed for url : \" + s, e);\n            rowIterator = Collections.EMPTY_LIST.iterator();\n            return;\n          }\n        }\n      }\n      if (streamRows) {\n        rowIterator = getRowIterator(data, s);\n      } else {\n        try {\n          xpathReader.streamRecords(data, new XPathRecordReader.Handler() {\n            @SuppressWarnings(\"unchecked\")\n            public void handle(Map<String, Object> record, String xpath) {\n              rows.add(readRow(record, xpath));\n            }\n          });\n        } catch (Exception e) {\n          String msg = \"Parsing failed for xml, url:\" + s + \" rows processed:\" + rows.size();\n          if (rows.size() > 0) msg += \" last row: \" + rows.get(rows.size() - 1);\n          if (ABORT.equals(onError)) {\n            wrapAndThrow(SEVERE, e, msg);\n          } else if (SKIP.equals(onError)) {\n            LOG.warn(msg, e);\n            Map<String, Object> map = new HashMap<String, Object>();\n            map.put(SKIP_DOC, Boolean.TRUE);\n            rows.add(map);\n          } else if (CONTINUE.equals(onError)) {\n            LOG.warn(msg, e);\n          }\n        }\n        rowIterator = rows.iterator();\n      }\n    } finally {\n      if (!streamRows) {\n        closeIt(data);\n      }\n\n    }\n  }\n\n","sourceOld":"  private void initQuery(String s) {\n    Reader data = null;\n    try {\n      final List<Map<String, Object>> rows = new ArrayList<Map<String, Object>>();\n      try {\n        data = dataSource.getData(s);\n      } catch (Exception e) {\n        if (ABORT.equals(onError)) {\n          wrapAndThrow(SEVERE, e);\n        } else if (SKIP.equals(onError)) {\n          wrapAndThrow(DataImportHandlerException.SKIP, e);\n        } else {\n          LOG.warn(\"Failed for url : \" + s, e);\n          rowIterator = Collections.EMPTY_LIST.iterator();\n          return;\n        }\n      }\n      if (xslTransformer != null) {\n        try {\n          SimpleCharArrayReader caw = new SimpleCharArrayReader();\n          xslTransformer.transform(new StreamSource(data),\n                  new StreamResult(caw));\n          data = caw.getReader();\n        } catch (TransformerException e) {\n          if (ABORT.equals(onError)) {\n            wrapAndThrow(SEVERE, e, \"Exception in applying XSL Transformeation\");\n          } else if (SKIP.equals(onError)) {\n            wrapAndThrow(DataImportHandlerException.SKIP, e);\n          } else {\n            LOG.warn(\"Failed for url : \" + s, e);\n            rowIterator = Collections.EMPTY_LIST.iterator();\n            return;\n          }\n        }\n      }\n      if (streamRows) {\n        rowIterator = getRowIterator(data, s);\n      } else {\n        try {\n          xpathReader.streamRecords(data, new XPathRecordReader.Handler() {\n            @SuppressWarnings(\"unchecked\")\n            public void handle(Map<String, Object> record, String xpath) {\n              rows.add(readRow(record, xpath));\n            }\n          });\n        } catch (Exception e) {\n          String msg = \"Parsing failed for xml, url:\" + s + \"rows processed :\" + rows.size();\n          if (rows.size() > 0) msg += \"last row : \" + rows.get(rows.size() - 1);\n          if (ABORT.equals(onError)) {\n            wrapAndThrow(SEVERE, e, msg);\n          } else if (SKIP.equals(onError)) {\n            LOG.warn(msg, e);\n            Map<String, Object> map = new HashMap<String, Object>();\n            map.put(SKIP_DOC, Boolean.TRUE);\n            rows.add(map);\n          } else if (CONTINUE.equals(onError)) {\n            LOG.warn(msg, e);\n          }\n        }\n        rowIterator = rows.iterator();\n      }\n    } finally {\n      if (!streamRows) {\n        closeIt(data);\n      }\n\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"93869e43eabb4102906d96ddbaf1125d8896dd5a","date":1247238464,"type":3,"author":"Erik Hatcher","isMerge":false,"pathNew":"contrib/dataimporthandler/src/main/java/org/apache/solr/handler/dataimport/XPathEntityProcessor#initQuery(String).mjava","pathOld":"contrib/dataimporthandler/src/main/java/org/apache/solr/handler/dataimport/XPathEntityProcessor#initQuery(String).mjava","sourceNew":"  private void initQuery(String s) {\n    Reader data = null;\n    try {\n      final List<Map<String, Object>> rows = new ArrayList<Map<String, Object>>();\n      try {\n        data = dataSource.getData(s);\n      } catch (Exception e) {\n        if (ABORT.equals(onError)) {\n          wrapAndThrow(SEVERE, e);\n        } else if (SKIP.equals(onError)) {\n          if (LOG.isDebugEnabled()) LOG.debug(\"Skipping url : \" + s, e);\n          wrapAndThrow(DataImportHandlerException.SKIP, e);\n        } else {\n          LOG.warn(\"Failed for url : \" + s, e);\n          rowIterator = Collections.EMPTY_LIST.iterator();\n          return;\n        }\n      }\n      if (xslTransformer != null) {\n        try {\n          SimpleCharArrayReader caw = new SimpleCharArrayReader();\n          xslTransformer.transform(new StreamSource(data),\n                  new StreamResult(caw));\n          data = caw.getReader();\n        } catch (TransformerException e) {\n          if (ABORT.equals(onError)) {\n            wrapAndThrow(SEVERE, e, \"Exception in applying XSL Transformeation\");\n          } else if (SKIP.equals(onError)) {\n            wrapAndThrow(DataImportHandlerException.SKIP, e);\n          } else {\n            LOG.warn(\"Failed for url : \" + s, e);\n            rowIterator = Collections.EMPTY_LIST.iterator();\n            return;\n          }\n        }\n      }\n      if (streamRows) {\n        rowIterator = getRowIterator(data, s);\n      } else {\n        try {\n          xpathReader.streamRecords(data, new XPathRecordReader.Handler() {\n            @SuppressWarnings(\"unchecked\")\n            public void handle(Map<String, Object> record, String xpath) {\n              rows.add(readRow(record, xpath));\n            }\n          });\n        } catch (Exception e) {\n          String msg = \"Parsing failed for xml, url:\" + s + \" rows processed:\" + rows.size();\n          if (rows.size() > 0) msg += \" last row: \" + rows.get(rows.size() - 1);\n          if (ABORT.equals(onError)) {\n            wrapAndThrow(SEVERE, e, msg);\n          } else if (SKIP.equals(onError)) {\n            LOG.warn(msg, e);\n            Map<String, Object> map = new HashMap<String, Object>();\n            map.put(SKIP_DOC, Boolean.TRUE);\n            rows.add(map);\n          } else if (CONTINUE.equals(onError)) {\n            LOG.warn(msg, e);\n          }\n        }\n        rowIterator = rows.iterator();\n      }\n    } finally {\n      if (!streamRows) {\n        closeIt(data);\n      }\n\n    }\n  }\n\n","sourceOld":"  private void initQuery(String s) {\n    Reader data = null;\n    try {\n      final List<Map<String, Object>> rows = new ArrayList<Map<String, Object>>();\n      try {\n        data = dataSource.getData(s);\n      } catch (Exception e) {\n        if (ABORT.equals(onError)) {\n          wrapAndThrow(SEVERE, e);\n        } else if (SKIP.equals(onError)) {\n          wrapAndThrow(DataImportHandlerException.SKIP, e);\n        } else {\n          LOG.warn(\"Failed for url : \" + s, e);\n          rowIterator = Collections.EMPTY_LIST.iterator();\n          return;\n        }\n      }\n      if (xslTransformer != null) {\n        try {\n          SimpleCharArrayReader caw = new SimpleCharArrayReader();\n          xslTransformer.transform(new StreamSource(data),\n                  new StreamResult(caw));\n          data = caw.getReader();\n        } catch (TransformerException e) {\n          if (ABORT.equals(onError)) {\n            wrapAndThrow(SEVERE, e, \"Exception in applying XSL Transformeation\");\n          } else if (SKIP.equals(onError)) {\n            wrapAndThrow(DataImportHandlerException.SKIP, e);\n          } else {\n            LOG.warn(\"Failed for url : \" + s, e);\n            rowIterator = Collections.EMPTY_LIST.iterator();\n            return;\n          }\n        }\n      }\n      if (streamRows) {\n        rowIterator = getRowIterator(data, s);\n      } else {\n        try {\n          xpathReader.streamRecords(data, new XPathRecordReader.Handler() {\n            @SuppressWarnings(\"unchecked\")\n            public void handle(Map<String, Object> record, String xpath) {\n              rows.add(readRow(record, xpath));\n            }\n          });\n        } catch (Exception e) {\n          String msg = \"Parsing failed for xml, url:\" + s + \" rows processed:\" + rows.size();\n          if (rows.size() > 0) msg += \" last row: \" + rows.get(rows.size() - 1);\n          if (ABORT.equals(onError)) {\n            wrapAndThrow(SEVERE, e, msg);\n          } else if (SKIP.equals(onError)) {\n            LOG.warn(msg, e);\n            Map<String, Object> map = new HashMap<String, Object>();\n            map.put(SKIP_DOC, Boolean.TRUE);\n            rows.add(map);\n          } else if (CONTINUE.equals(onError)) {\n            LOG.warn(msg, e);\n          }\n        }\n        rowIterator = rows.iterator();\n      }\n    } finally {\n      if (!streamRows) {\n        closeIt(data);\n      }\n\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"ad94625fb8d088209f46650c8097196fec67f00c","date":1453508319,"type":5,"author":"Dawid Weiss","isMerge":false,"pathNew":"solr/contrib/dataimporthandler/src/main/java/org/apache/solr/handler/dataimport/XPathEntityProcessor#initQuery(String).mjava","pathOld":"contrib/dataimporthandler/src/main/java/org/apache/solr/handler/dataimport/XPathEntityProcessor#initQuery(String).mjava","sourceNew":"  private void initQuery(String s) {\n    Reader data = null;\n    try {\n      final List<Map<String, Object>> rows = new ArrayList<Map<String, Object>>();\n      try {\n        data = dataSource.getData(s);\n      } catch (Exception e) {\n        if (ABORT.equals(onError)) {\n          wrapAndThrow(SEVERE, e);\n        } else if (SKIP.equals(onError)) {\n          if (LOG.isDebugEnabled()) LOG.debug(\"Skipping url : \" + s, e);\n          wrapAndThrow(DataImportHandlerException.SKIP, e);\n        } else {\n          LOG.warn(\"Failed for url : \" + s, e);\n          rowIterator = Collections.EMPTY_LIST.iterator();\n          return;\n        }\n      }\n      if (xslTransformer != null) {\n        try {\n          SimpleCharArrayReader caw = new SimpleCharArrayReader();\n          xslTransformer.transform(new StreamSource(data),\n                  new StreamResult(caw));\n          data = caw.getReader();\n        } catch (TransformerException e) {\n          if (ABORT.equals(onError)) {\n            wrapAndThrow(SEVERE, e, \"Exception in applying XSL Transformeation\");\n          } else if (SKIP.equals(onError)) {\n            wrapAndThrow(DataImportHandlerException.SKIP, e);\n          } else {\n            LOG.warn(\"Failed for url : \" + s, e);\n            rowIterator = Collections.EMPTY_LIST.iterator();\n            return;\n          }\n        }\n      }\n      if (streamRows) {\n        rowIterator = getRowIterator(data, s);\n      } else {\n        try {\n          xpathReader.streamRecords(data, new XPathRecordReader.Handler() {\n            @SuppressWarnings(\"unchecked\")\n            public void handle(Map<String, Object> record, String xpath) {\n              rows.add(readRow(record, xpath));\n            }\n          });\n        } catch (Exception e) {\n          String msg = \"Parsing failed for xml, url:\" + s + \" rows processed:\" + rows.size();\n          if (rows.size() > 0) msg += \" last row: \" + rows.get(rows.size() - 1);\n          if (ABORT.equals(onError)) {\n            wrapAndThrow(SEVERE, e, msg);\n          } else if (SKIP.equals(onError)) {\n            LOG.warn(msg, e);\n            Map<String, Object> map = new HashMap<String, Object>();\n            map.put(SKIP_DOC, Boolean.TRUE);\n            rows.add(map);\n          } else if (CONTINUE.equals(onError)) {\n            LOG.warn(msg, e);\n          }\n        }\n        rowIterator = rows.iterator();\n      }\n    } finally {\n      if (!streamRows) {\n        closeIt(data);\n      }\n\n    }\n  }\n\n","sourceOld":"  private void initQuery(String s) {\n    Reader data = null;\n    try {\n      final List<Map<String, Object>> rows = new ArrayList<Map<String, Object>>();\n      try {\n        data = dataSource.getData(s);\n      } catch (Exception e) {\n        if (ABORT.equals(onError)) {\n          wrapAndThrow(SEVERE, e);\n        } else if (SKIP.equals(onError)) {\n          if (LOG.isDebugEnabled()) LOG.debug(\"Skipping url : \" + s, e);\n          wrapAndThrow(DataImportHandlerException.SKIP, e);\n        } else {\n          LOG.warn(\"Failed for url : \" + s, e);\n          rowIterator = Collections.EMPTY_LIST.iterator();\n          return;\n        }\n      }\n      if (xslTransformer != null) {\n        try {\n          SimpleCharArrayReader caw = new SimpleCharArrayReader();\n          xslTransformer.transform(new StreamSource(data),\n                  new StreamResult(caw));\n          data = caw.getReader();\n        } catch (TransformerException e) {\n          if (ABORT.equals(onError)) {\n            wrapAndThrow(SEVERE, e, \"Exception in applying XSL Transformeation\");\n          } else if (SKIP.equals(onError)) {\n            wrapAndThrow(DataImportHandlerException.SKIP, e);\n          } else {\n            LOG.warn(\"Failed for url : \" + s, e);\n            rowIterator = Collections.EMPTY_LIST.iterator();\n            return;\n          }\n        }\n      }\n      if (streamRows) {\n        rowIterator = getRowIterator(data, s);\n      } else {\n        try {\n          xpathReader.streamRecords(data, new XPathRecordReader.Handler() {\n            @SuppressWarnings(\"unchecked\")\n            public void handle(Map<String, Object> record, String xpath) {\n              rows.add(readRow(record, xpath));\n            }\n          });\n        } catch (Exception e) {\n          String msg = \"Parsing failed for xml, url:\" + s + \" rows processed:\" + rows.size();\n          if (rows.size() > 0) msg += \" last row: \" + rows.get(rows.size() - 1);\n          if (ABORT.equals(onError)) {\n            wrapAndThrow(SEVERE, e, msg);\n          } else if (SKIP.equals(onError)) {\n            LOG.warn(msg, e);\n            Map<String, Object> map = new HashMap<String, Object>();\n            map.put(SKIP_DOC, Boolean.TRUE);\n            rows.add(map);\n          } else if (CONTINUE.equals(onError)) {\n            LOG.warn(msg, e);\n          }\n        }\n        rowIterator = rows.iterator();\n      }\n    } finally {\n      if (!streamRows) {\n        closeIt(data);\n      }\n\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"0ed3f47d0f68ca5e5107d28c942fbd1185f44c62":["d902f463d0a39aa9fc43326e245a5e5c94295d68"],"4d4f1b2c5601680b01c4bb95a43fe6fb73f03103":["3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b":[],"d183f54b5c7a1c64bd2935a5d5bd71091ebe4198":["0ed3f47d0f68ca5e5107d28c942fbd1185f44c62"],"ad94625fb8d088209f46650c8097196fec67f00c":["93869e43eabb4102906d96ddbaf1125d8896dd5a"],"93869e43eabb4102906d96ddbaf1125d8896dd5a":["d183f54b5c7a1c64bd2935a5d5bd71091ebe4198"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"d902f463d0a39aa9fc43326e245a5e5c94295d68":["4d4f1b2c5601680b01c4bb95a43fe6fb73f03103"]},"commit2Childs":{"0ed3f47d0f68ca5e5107d28c942fbd1185f44c62":["d183f54b5c7a1c64bd2935a5d5bd71091ebe4198"],"4d4f1b2c5601680b01c4bb95a43fe6fb73f03103":["d902f463d0a39aa9fc43326e245a5e5c94295d68"],"3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b":["4d4f1b2c5601680b01c4bb95a43fe6fb73f03103"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"d183f54b5c7a1c64bd2935a5d5bd71091ebe4198":["93869e43eabb4102906d96ddbaf1125d8896dd5a"],"ad94625fb8d088209f46650c8097196fec67f00c":[],"93869e43eabb4102906d96ddbaf1125d8896dd5a":["ad94625fb8d088209f46650c8097196fec67f00c"],"d902f463d0a39aa9fc43326e245a5e5c94295d68":["0ed3f47d0f68ca5e5107d28c942fbd1185f44c62"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["ad94625fb8d088209f46650c8097196fec67f00c","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b","a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}