{"path":"lucene/facet/src/test/org/apache/lucene/facet/search/CategoryListIteratorTest#testPayloadIteratorWithInvalidDoc().mjava","commits":[{"id":"b89678825b68eccaf09e6ab71675fc0b0af1e099","date":1334669779,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/facet/src/test/org/apache/lucene/facet/search/CategoryListIteratorTest#testPayloadIteratorWithInvalidDoc().mjava","pathOld":"modules/facet/src/test/org/apache/lucene/facet/search/CategoryListIteratorTest#testPayloadIteratorWithInvalidDoc().mjava","sourceNew":"  /**\n   * Test that a document with no payloads does not confuse the payload decoder.\n   */\n  @Test\n  public void testPayloadIteratorWithInvalidDoc() throws Exception {\n    Directory dir = newDirectory();\n    DataTokenStream dts = new DataTokenStream(\"1\",new SortingIntEncoder(\n        new UniqueValuesIntEncoder(new DGapIntEncoder(new VInt8IntEncoder()))));\n    // this test requires that no payloads ever be randomly present!\n    final Analyzer noPayloadsAnalyzer = new Analyzer() {\n      @Override\n      public TokenStreamComponents createComponents(String fieldName, Reader reader) {\n        return new TokenStreamComponents(new MockTokenizer(reader, MockTokenizer.KEYWORD, false));\n      }\n    };\n    // NOTE: test is wired to LogMP... because test relies on certain docids having payloads\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, \n        newIndexWriterConfig(TEST_VERSION_CURRENT, noPayloadsAnalyzer).setMergePolicy(newLogMergePolicy()));\n    for (int i = 0; i < data.length; i++) {\n      Document doc = new Document();\n      if (i == 0) {\n        dts.setIdx(i);\n        doc.add(new TextField(\"f\", dts)); // only doc 0 has payloads!\n      } else {\n        doc.add(new TextField(\"f\", \"1\"));\n      }\n      writer.addDocument(doc);\n      writer.commit();\n    }\n\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    CategoryListIterator cli = new PayloadIntDecodingIterator(reader, new Term(\n        \"f\",\"1\"), dts.encoder.createMatchingDecoder());\n    assertTrue(\"Failed to initialize payload iterator\", cli.init());\n    int totalCats = 0;\n    for (int i = 0; i < data.length; i++) {\n      // doc no. i\n      Set<Integer> values = new HashSet<Integer>();\n      for (int j = 0; j < data[i].length; j++) {\n        values.add(data[i][j]);\n      }\n      boolean hasDoc = cli.skipTo(i);\n      if (hasDoc) {\n        assertTrue(\"Document \" + i + \" must not have a payload!\", i == 0);\n        long cat;\n        while ((cat = cli.nextCategory()) < Integer.MAX_VALUE) {\n          assertTrue(\"expected category not found: \" + cat, values.contains((int) cat));\n          ++totalCats;\n        }\n      } else {\n        assertFalse(\"Document \" + i + \" must have a payload!\", i == 0);\n      }\n\n    }\n    assertEquals(\"Wrong number of total categories!\", 2, totalCats);\n\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  /**\n   * Test that a document with no payloads does not confuse the payload decoder.\n   */\n  @Test\n  public void testPayloadIteratorWithInvalidDoc() throws Exception {\n    Directory dir = newDirectory();\n    DataTokenStream dts = new DataTokenStream(\"1\",new SortingIntEncoder(\n        new UniqueValuesIntEncoder(new DGapIntEncoder(new VInt8IntEncoder()))));\n    // this test requires that no payloads ever be randomly present!\n    final Analyzer noPayloadsAnalyzer = new Analyzer() {\n      @Override\n      public TokenStreamComponents createComponents(String fieldName, Reader reader) {\n        return new TokenStreamComponents(new MockTokenizer(reader, MockTokenizer.KEYWORD, false));\n      }\n    };\n    // NOTE: test is wired to LogMP... because test relies on certain docids having payloads\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, \n        newIndexWriterConfig(TEST_VERSION_CURRENT, noPayloadsAnalyzer).setMergePolicy(newLogMergePolicy()));\n    for (int i = 0; i < data.length; i++) {\n      Document doc = new Document();\n      if (i == 0) {\n        dts.setIdx(i);\n        doc.add(new TextField(\"f\", dts)); // only doc 0 has payloads!\n      } else {\n        doc.add(new TextField(\"f\", \"1\"));\n      }\n      writer.addDocument(doc);\n      writer.commit();\n    }\n\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    CategoryListIterator cli = new PayloadIntDecodingIterator(reader, new Term(\n        \"f\",\"1\"), dts.encoder.createMatchingDecoder());\n    assertTrue(\"Failed to initialize payload iterator\", cli.init());\n    int totalCats = 0;\n    for (int i = 0; i < data.length; i++) {\n      // doc no. i\n      Set<Integer> values = new HashSet<Integer>();\n      for (int j = 0; j < data[i].length; j++) {\n        values.add(data[i][j]);\n      }\n      boolean hasDoc = cli.skipTo(i);\n      if (hasDoc) {\n        assertTrue(\"Document \" + i + \" must not have a payload!\", i == 0);\n        long cat;\n        while ((cat = cli.nextCategory()) < Integer.MAX_VALUE) {\n          assertTrue(\"expected category not found: \" + cat, values.contains((int) cat));\n          ++totalCats;\n        }\n      } else {\n        assertFalse(\"Document \" + i + \" must have a payload!\", i == 0);\n      }\n\n    }\n    assertEquals(\"Wrong number of total categories!\", 2, totalCats);\n\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"04f07771a2a7dd3a395700665ed839c3dae2def2","date":1339350139,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/facet/src/test/org/apache/lucene/facet/search/CategoryListIteratorTest#testPayloadIteratorWithInvalidDoc().mjava","pathOld":"lucene/facet/src/test/org/apache/lucene/facet/search/CategoryListIteratorTest#testPayloadIteratorWithInvalidDoc().mjava","sourceNew":"  /**\n   * Test that a document with no payloads does not confuse the payload decoder.\n   */\n  @Test\n  public void testPayloadIteratorWithInvalidDoc() throws Exception {\n    Directory dir = newDirectory();\n    DataTokenStream dts = new DataTokenStream(\"1\",new SortingIntEncoder(\n        new UniqueValuesIntEncoder(new DGapIntEncoder(new VInt8IntEncoder()))));\n    // this test requires that no payloads ever be randomly present!\n    final Analyzer noPayloadsAnalyzer = new Analyzer() {\n      @Override\n      public TokenStreamComponents createComponents(String fieldName, Reader reader) {\n        return new TokenStreamComponents(new MockTokenizer(reader, MockTokenizer.KEYWORD, false));\n      }\n    };\n    // NOTE: test is wired to LogMP... because test relies on certain docids having payloads\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, \n        newIndexWriterConfig(TEST_VERSION_CURRENT, noPayloadsAnalyzer).setMergePolicy(newLogMergePolicy()));\n    for (int i = 0; i < data.length; i++) {\n      Document doc = new Document();\n      if (i == 0) {\n        dts.setIdx(i);\n        doc.add(new TextField(\"f\", dts)); // only doc 0 has payloads!\n      } else {\n        doc.add(new TextField(\"f\", \"1\", Field.Store.NO));\n      }\n      writer.addDocument(doc);\n      writer.commit();\n    }\n\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    CategoryListIterator cli = new PayloadIntDecodingIterator(reader, new Term(\n        \"f\",\"1\"), dts.encoder.createMatchingDecoder());\n    assertTrue(\"Failed to initialize payload iterator\", cli.init());\n    int totalCats = 0;\n    for (int i = 0; i < data.length; i++) {\n      // doc no. i\n      Set<Integer> values = new HashSet<Integer>();\n      for (int j = 0; j < data[i].length; j++) {\n        values.add(data[i][j]);\n      }\n      boolean hasDoc = cli.skipTo(i);\n      if (hasDoc) {\n        assertTrue(\"Document \" + i + \" must not have a payload!\", i == 0);\n        long cat;\n        while ((cat = cli.nextCategory()) < Integer.MAX_VALUE) {\n          assertTrue(\"expected category not found: \" + cat, values.contains((int) cat));\n          ++totalCats;\n        }\n      } else {\n        assertFalse(\"Document \" + i + \" must have a payload!\", i == 0);\n      }\n\n    }\n    assertEquals(\"Wrong number of total categories!\", 2, totalCats);\n\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  /**\n   * Test that a document with no payloads does not confuse the payload decoder.\n   */\n  @Test\n  public void testPayloadIteratorWithInvalidDoc() throws Exception {\n    Directory dir = newDirectory();\n    DataTokenStream dts = new DataTokenStream(\"1\",new SortingIntEncoder(\n        new UniqueValuesIntEncoder(new DGapIntEncoder(new VInt8IntEncoder()))));\n    // this test requires that no payloads ever be randomly present!\n    final Analyzer noPayloadsAnalyzer = new Analyzer() {\n      @Override\n      public TokenStreamComponents createComponents(String fieldName, Reader reader) {\n        return new TokenStreamComponents(new MockTokenizer(reader, MockTokenizer.KEYWORD, false));\n      }\n    };\n    // NOTE: test is wired to LogMP... because test relies on certain docids having payloads\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, \n        newIndexWriterConfig(TEST_VERSION_CURRENT, noPayloadsAnalyzer).setMergePolicy(newLogMergePolicy()));\n    for (int i = 0; i < data.length; i++) {\n      Document doc = new Document();\n      if (i == 0) {\n        dts.setIdx(i);\n        doc.add(new TextField(\"f\", dts)); // only doc 0 has payloads!\n      } else {\n        doc.add(new TextField(\"f\", \"1\"));\n      }\n      writer.addDocument(doc);\n      writer.commit();\n    }\n\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    CategoryListIterator cli = new PayloadIntDecodingIterator(reader, new Term(\n        \"f\",\"1\"), dts.encoder.createMatchingDecoder());\n    assertTrue(\"Failed to initialize payload iterator\", cli.init());\n    int totalCats = 0;\n    for (int i = 0; i < data.length; i++) {\n      // doc no. i\n      Set<Integer> values = new HashSet<Integer>();\n      for (int j = 0; j < data[i].length; j++) {\n        values.add(data[i][j]);\n      }\n      boolean hasDoc = cli.skipTo(i);\n      if (hasDoc) {\n        assertTrue(\"Document \" + i + \" must not have a payload!\", i == 0);\n        long cat;\n        while ((cat = cli.nextCategory()) < Integer.MAX_VALUE) {\n          assertTrue(\"expected category not found: \" + cat, values.contains((int) cat));\n          ++totalCats;\n        }\n      } else {\n        assertFalse(\"Document \" + i + \" must have a payload!\", i == 0);\n      }\n\n    }\n    assertEquals(\"Wrong number of total categories!\", 2, totalCats);\n\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":["056f70824cc48de597e42753d004f6747ff6d521"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"bceb02c33032dd9bbf107cd06d0b74e5db4f110a","date":1357909746,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/facet/src/test/org/apache/lucene/facet/search/CategoryListIteratorTest#testPayloadIteratorWithInvalidDoc().mjava","pathOld":"lucene/facet/src/test/org/apache/lucene/facet/search/CategoryListIteratorTest#testPayloadIteratorWithInvalidDoc().mjava","sourceNew":"  /**\n   * Test that a document with no payloads does not confuse the payload decoder.\n   */\n  @Test\n  public void testPayloadIteratorWithInvalidDoc() throws Exception {\n    Directory dir = newDirectory();\n    final IntEncoder encoder = new SortingIntEncoder(new UniqueValuesIntEncoder(new DGapIntEncoder(new VInt8IntEncoder())));\n    DataTokenStream dts = new DataTokenStream(\"1\", encoder);\n    // this test requires that no payloads ever be randomly present!\n    final Analyzer noPayloadsAnalyzer = new Analyzer() {\n      @Override\n      public TokenStreamComponents createComponents(String fieldName, Reader reader) {\n        return new TokenStreamComponents(new MockTokenizer(reader, MockTokenizer.KEYWORD, false));\n      }\n    };\n    // NOTE: test is wired to LogMP... because test relies on certain docids having payloads\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, \n        newIndexWriterConfig(TEST_VERSION_CURRENT, noPayloadsAnalyzer).setMergePolicy(newLogMergePolicy()));\n    for (int i = 0; i < data.length; i++) {\n      Document doc = new Document();\n      if (i == 0) {\n        dts.setIdx(i);\n        doc.add(new TextField(\"f\", dts)); // only doc 0 has payloads!\n      } else {\n        doc.add(new TextField(\"f\", \"1\", Field.Store.NO));\n      }\n      writer.addDocument(doc);\n      writer.commit();\n    }\n\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    IntsRef ordinals = new IntsRef();\n    CategoryListIterator cli = new PayloadCategoryListIteraor(reader, new Term(\"f\",\"1\"), encoder.createMatchingDecoder());\n    assertTrue(\"Failed to initialize payload iterator\", cli.init());\n    int totalCategories = 0;\n    for (int i = 0; i < data.length; i++) {\n      Set<Integer> values = new HashSet<Integer>();\n      for (int j = 0; j < data[i].length; j++) {\n        values.add(data[i].ints[j]);\n      }\n      cli.getOrdinals(i, ordinals);\n      if (i == 0) {\n        assertTrue(\"document 0 must have a payload\", ordinals.length > 0);\n        for (int j = 0; j < ordinals.length; j++) {\n          assertTrue(\"expected category not found: \" + ordinals.ints[j], values.contains(ordinals.ints[j]));\n        }\n        totalCategories += ordinals.length;\n      } else {\n        assertTrue(\"only document 0 should have a payload\", ordinals.length == 0);\n      }\n    }\n    assertEquals(\"Wrong number of total categories!\", 2, totalCategories);\n\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  /**\n   * Test that a document with no payloads does not confuse the payload decoder.\n   */\n  @Test\n  public void testPayloadIteratorWithInvalidDoc() throws Exception {\n    Directory dir = newDirectory();\n    DataTokenStream dts = new DataTokenStream(\"1\",new SortingIntEncoder(\n        new UniqueValuesIntEncoder(new DGapIntEncoder(new VInt8IntEncoder()))));\n    // this test requires that no payloads ever be randomly present!\n    final Analyzer noPayloadsAnalyzer = new Analyzer() {\n      @Override\n      public TokenStreamComponents createComponents(String fieldName, Reader reader) {\n        return new TokenStreamComponents(new MockTokenizer(reader, MockTokenizer.KEYWORD, false));\n      }\n    };\n    // NOTE: test is wired to LogMP... because test relies on certain docids having payloads\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, \n        newIndexWriterConfig(TEST_VERSION_CURRENT, noPayloadsAnalyzer).setMergePolicy(newLogMergePolicy()));\n    for (int i = 0; i < data.length; i++) {\n      Document doc = new Document();\n      if (i == 0) {\n        dts.setIdx(i);\n        doc.add(new TextField(\"f\", dts)); // only doc 0 has payloads!\n      } else {\n        doc.add(new TextField(\"f\", \"1\", Field.Store.NO));\n      }\n      writer.addDocument(doc);\n      writer.commit();\n    }\n\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    CategoryListIterator cli = new PayloadIntDecodingIterator(reader, new Term(\n        \"f\",\"1\"), dts.encoder.createMatchingDecoder());\n    assertTrue(\"Failed to initialize payload iterator\", cli.init());\n    int totalCats = 0;\n    for (int i = 0; i < data.length; i++) {\n      // doc no. i\n      Set<Integer> values = new HashSet<Integer>();\n      for (int j = 0; j < data[i].length; j++) {\n        values.add(data[i][j]);\n      }\n      boolean hasDoc = cli.skipTo(i);\n      if (hasDoc) {\n        assertTrue(\"Document \" + i + \" must not have a payload!\", i == 0);\n        long cat;\n        while ((cat = cli.nextCategory()) < Integer.MAX_VALUE) {\n          assertTrue(\"expected category not found: \" + cat, values.contains((int) cat));\n          ++totalCats;\n        }\n      } else {\n        assertFalse(\"Document \" + i + \" must have a payload!\", i == 0);\n      }\n\n    }\n    assertEquals(\"Wrong number of total categories!\", 2, totalCats);\n\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4e6354dd7c71fe122926fc53d7d29f715b1283db","date":1357915185,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/facet/src/test/org/apache/lucene/facet/search/CategoryListIteratorTest#testPayloadIteratorWithInvalidDoc().mjava","pathOld":"lucene/facet/src/test/org/apache/lucene/facet/search/CategoryListIteratorTest#testPayloadIteratorWithInvalidDoc().mjava","sourceNew":"  /**\n   * Test that a document with no payloads does not confuse the payload decoder.\n   */\n  @Test\n  public void testPayloadIteratorWithInvalidDoc() throws Exception {\n    Directory dir = newDirectory();\n    final IntEncoder encoder = new SortingIntEncoder(new UniqueValuesIntEncoder(new DGapIntEncoder(new VInt8IntEncoder())));\n    DataTokenStream dts = new DataTokenStream(\"1\", encoder);\n    // this test requires that no payloads ever be randomly present!\n    final Analyzer noPayloadsAnalyzer = new Analyzer() {\n      @Override\n      public TokenStreamComponents createComponents(String fieldName, Reader reader) {\n        return new TokenStreamComponents(new MockTokenizer(reader, MockTokenizer.KEYWORD, false));\n      }\n    };\n    // NOTE: test is wired to LogMP... because test relies on certain docids having payloads\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, \n        newIndexWriterConfig(TEST_VERSION_CURRENT, noPayloadsAnalyzer).setMergePolicy(newLogMergePolicy()));\n    for (int i = 0; i < data.length; i++) {\n      Document doc = new Document();\n      if (i == 0) {\n        dts.setIdx(i);\n        doc.add(new TextField(\"f\", dts)); // only doc 0 has payloads!\n      } else {\n        doc.add(new TextField(\"f\", \"1\", Field.Store.NO));\n      }\n      writer.addDocument(doc);\n      writer.commit();\n    }\n\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    IntsRef ordinals = new IntsRef();\n    CategoryListIterator cli = new PayloadCategoryListIteraor(reader, new Term(\"f\",\"1\"), encoder.createMatchingDecoder());\n    assertTrue(\"Failed to initialize payload iterator\", cli.init());\n    int totalCategories = 0;\n    for (int i = 0; i < data.length; i++) {\n      Set<Integer> values = new HashSet<Integer>();\n      for (int j = 0; j < data[i].length; j++) {\n        values.add(data[i].ints[j]);\n      }\n      cli.getOrdinals(i, ordinals);\n      if (i == 0) {\n        assertTrue(\"document 0 must have a payload\", ordinals.length > 0);\n        for (int j = 0; j < ordinals.length; j++) {\n          assertTrue(\"expected category not found: \" + ordinals.ints[j], values.contains(ordinals.ints[j]));\n        }\n        totalCategories += ordinals.length;\n      } else {\n        assertTrue(\"only document 0 should have a payload\", ordinals.length == 0);\n      }\n    }\n    assertEquals(\"Wrong number of total categories!\", 2, totalCategories);\n\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  /**\n   * Test that a document with no payloads does not confuse the payload decoder.\n   */\n  @Test\n  public void testPayloadIteratorWithInvalidDoc() throws Exception {\n    Directory dir = newDirectory();\n    DataTokenStream dts = new DataTokenStream(\"1\",new SortingIntEncoder(\n        new UniqueValuesIntEncoder(new DGapIntEncoder(new VInt8IntEncoder()))));\n    // this test requires that no payloads ever be randomly present!\n    final Analyzer noPayloadsAnalyzer = new Analyzer() {\n      @Override\n      public TokenStreamComponents createComponents(String fieldName, Reader reader) {\n        return new TokenStreamComponents(new MockTokenizer(reader, MockTokenizer.KEYWORD, false));\n      }\n    };\n    // NOTE: test is wired to LogMP... because test relies on certain docids having payloads\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, \n        newIndexWriterConfig(TEST_VERSION_CURRENT, noPayloadsAnalyzer).setMergePolicy(newLogMergePolicy()));\n    for (int i = 0; i < data.length; i++) {\n      Document doc = new Document();\n      if (i == 0) {\n        dts.setIdx(i);\n        doc.add(new TextField(\"f\", dts)); // only doc 0 has payloads!\n      } else {\n        doc.add(new TextField(\"f\", \"1\", Field.Store.NO));\n      }\n      writer.addDocument(doc);\n      writer.commit();\n    }\n\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    CategoryListIterator cli = new PayloadIntDecodingIterator(reader, new Term(\n        \"f\",\"1\"), dts.encoder.createMatchingDecoder());\n    assertTrue(\"Failed to initialize payload iterator\", cli.init());\n    int totalCats = 0;\n    for (int i = 0; i < data.length; i++) {\n      // doc no. i\n      Set<Integer> values = new HashSet<Integer>();\n      for (int j = 0; j < data[i].length; j++) {\n        values.add(data[i][j]);\n      }\n      boolean hasDoc = cli.skipTo(i);\n      if (hasDoc) {\n        assertTrue(\"Document \" + i + \" must not have a payload!\", i == 0);\n        long cat;\n        while ((cat = cli.nextCategory()) < Integer.MAX_VALUE) {\n          assertTrue(\"expected category not found: \" + cat, values.contains((int) cat));\n          ++totalCats;\n        }\n      } else {\n        assertFalse(\"Document \" + i + \" must have a payload!\", i == 0);\n      }\n\n    }\n    assertEquals(\"Wrong number of total categories!\", 2, totalCats);\n\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"42f51b3ab4258ff4623227b0db011b8bb83db5c7","date":1358164991,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/facet/src/test/org/apache/lucene/facet/search/CategoryListIteratorTest#testPayloadIteratorWithInvalidDoc().mjava","pathOld":"lucene/facet/src/test/org/apache/lucene/facet/search/CategoryListIteratorTest#testPayloadIteratorWithInvalidDoc().mjava","sourceNew":"  @Test\n  public void testPayloadIteratorWithInvalidDoc() throws Exception {\n    Directory dir = newDirectory();\n    final IntEncoder encoder = new SortingIntEncoder(new UniqueValuesIntEncoder(new DGapIntEncoder(new VInt8IntEncoder())));\n    DataTokenStream dts = new DataTokenStream(\"1\", encoder);\n    // this test requires that no payloads ever be randomly present!\n    final Analyzer noPayloadsAnalyzer = new Analyzer() {\n      @Override\n      public TokenStreamComponents createComponents(String fieldName, Reader reader) {\n        return new TokenStreamComponents(new MockTokenizer(reader, MockTokenizer.KEYWORD, false));\n      }\n    };\n    // NOTE: test is wired to LogMP... because test relies on certain docids having payloads\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, \n        newIndexWriterConfig(TEST_VERSION_CURRENT, noPayloadsAnalyzer).setMergePolicy(newLogMergePolicy()));\n    for (int i = 0; i < data.length; i++) {\n      Document doc = new Document();\n      if (i == 0) {\n        dts.setIdx(i);\n        doc.add(new TextField(\"f\", dts)); // only doc 0 has payloads!\n      } else {\n        doc.add(new TextField(\"f\", \"1\", Field.Store.NO));\n      }\n      writer.addDocument(doc);\n      writer.commit();\n    }\n\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    int totalCategories = 0;\n    IntsRef ordinals = new IntsRef();\n    CategoryListIterator cli = new PayloadCategoryListIteraor(new Term(\"f\",\"1\"), encoder.createMatchingDecoder());\n    for (AtomicReaderContext context : reader.leaves()) {\n      cli.setNextReader(context);\n      int maxDoc = context.reader().maxDoc();\n      int dataIdx = context.docBase;\n      for (int doc = 0; doc < maxDoc; doc++, dataIdx++) {\n        Set<Integer> values = new HashSet<Integer>();\n        for (int j = 0; j < data[dataIdx].length; j++) {\n          values.add(data[dataIdx].ints[j]);\n        }\n        cli.getOrdinals(doc, ordinals);\n        if (dataIdx == 0) {\n          assertTrue(\"document 0 must have a payload\", ordinals.length > 0);\n          for (int j = 0; j < ordinals.length; j++) {\n            assertTrue(\"expected category not found: \" + ordinals.ints[j], values.contains(ordinals.ints[j]));\n          }\n          totalCategories += ordinals.length;\n        } else {\n          assertTrue(\"only document 0 should have a payload\", ordinals.length == 0);\n        }\n      }\n    }\n    assertEquals(\"Wrong number of total categories!\", 2, totalCategories);\n\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  /**\n   * Test that a document with no payloads does not confuse the payload decoder.\n   */\n  @Test\n  public void testPayloadIteratorWithInvalidDoc() throws Exception {\n    Directory dir = newDirectory();\n    final IntEncoder encoder = new SortingIntEncoder(new UniqueValuesIntEncoder(new DGapIntEncoder(new VInt8IntEncoder())));\n    DataTokenStream dts = new DataTokenStream(\"1\", encoder);\n    // this test requires that no payloads ever be randomly present!\n    final Analyzer noPayloadsAnalyzer = new Analyzer() {\n      @Override\n      public TokenStreamComponents createComponents(String fieldName, Reader reader) {\n        return new TokenStreamComponents(new MockTokenizer(reader, MockTokenizer.KEYWORD, false));\n      }\n    };\n    // NOTE: test is wired to LogMP... because test relies on certain docids having payloads\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, \n        newIndexWriterConfig(TEST_VERSION_CURRENT, noPayloadsAnalyzer).setMergePolicy(newLogMergePolicy()));\n    for (int i = 0; i < data.length; i++) {\n      Document doc = new Document();\n      if (i == 0) {\n        dts.setIdx(i);\n        doc.add(new TextField(\"f\", dts)); // only doc 0 has payloads!\n      } else {\n        doc.add(new TextField(\"f\", \"1\", Field.Store.NO));\n      }\n      writer.addDocument(doc);\n      writer.commit();\n    }\n\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    IntsRef ordinals = new IntsRef();\n    CategoryListIterator cli = new PayloadCategoryListIteraor(reader, new Term(\"f\",\"1\"), encoder.createMatchingDecoder());\n    assertTrue(\"Failed to initialize payload iterator\", cli.init());\n    int totalCategories = 0;\n    for (int i = 0; i < data.length; i++) {\n      Set<Integer> values = new HashSet<Integer>();\n      for (int j = 0; j < data[i].length; j++) {\n        values.add(data[i].ints[j]);\n      }\n      cli.getOrdinals(i, ordinals);\n      if (i == 0) {\n        assertTrue(\"document 0 must have a payload\", ordinals.length > 0);\n        for (int j = 0; j < ordinals.length; j++) {\n          assertTrue(\"expected category not found: \" + ordinals.ints[j], values.contains(ordinals.ints[j]));\n        }\n        totalCategories += ordinals.length;\n      } else {\n        assertTrue(\"only document 0 should have a payload\", ordinals.length == 0);\n      }\n    }\n    assertEquals(\"Wrong number of total categories!\", 2, totalCategories);\n\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8917bfede3b4ca30f4305c1e391e9218959cd723","date":1358189662,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/facet/src/test/org/apache/lucene/facet/search/CategoryListIteratorTest#testPayloadIteratorWithInvalidDoc().mjava","pathOld":"lucene/facet/src/test/org/apache/lucene/facet/search/CategoryListIteratorTest#testPayloadIteratorWithInvalidDoc().mjava","sourceNew":"  @Test\n  public void testPayloadIteratorWithInvalidDoc() throws Exception {\n    Directory dir = newDirectory();\n    final IntEncoder encoder = new SortingIntEncoder(new UniqueValuesIntEncoder(new DGapIntEncoder(new VInt8IntEncoder())));\n    DataTokenStream dts = new DataTokenStream(\"1\", encoder);\n    // this test requires that no payloads ever be randomly present!\n    final Analyzer noPayloadsAnalyzer = new Analyzer() {\n      @Override\n      public TokenStreamComponents createComponents(String fieldName, Reader reader) {\n        return new TokenStreamComponents(new MockTokenizer(reader, MockTokenizer.KEYWORD, false));\n      }\n    };\n    // NOTE: test is wired to LogMP... because test relies on certain docids having payloads\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, \n        newIndexWriterConfig(TEST_VERSION_CURRENT, noPayloadsAnalyzer).setMergePolicy(newLogMergePolicy()));\n    for (int i = 0; i < data.length; i++) {\n      Document doc = new Document();\n      if (i == 0) {\n        dts.setIdx(i);\n        doc.add(new TextField(\"f\", dts)); // only doc 0 has payloads!\n      } else {\n        doc.add(new TextField(\"f\", \"1\", Field.Store.NO));\n      }\n      writer.addDocument(doc);\n      writer.commit();\n    }\n\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    int totalCategories = 0;\n    IntsRef ordinals = new IntsRef();\n    CategoryListIterator cli = new PayloadCategoryListIteraor(new Term(\"f\",\"1\"), encoder.createMatchingDecoder());\n    for (AtomicReaderContext context : reader.leaves()) {\n      cli.setNextReader(context);\n      int maxDoc = context.reader().maxDoc();\n      int dataIdx = context.docBase;\n      for (int doc = 0; doc < maxDoc; doc++, dataIdx++) {\n        Set<Integer> values = new HashSet<Integer>();\n        for (int j = 0; j < data[dataIdx].length; j++) {\n          values.add(data[dataIdx].ints[j]);\n        }\n        cli.getOrdinals(doc, ordinals);\n        if (dataIdx == 0) {\n          assertTrue(\"document 0 must have a payload\", ordinals.length > 0);\n          for (int j = 0; j < ordinals.length; j++) {\n            assertTrue(\"expected category not found: \" + ordinals.ints[j], values.contains(ordinals.ints[j]));\n          }\n          totalCategories += ordinals.length;\n        } else {\n          assertTrue(\"only document 0 should have a payload\", ordinals.length == 0);\n        }\n      }\n    }\n    assertEquals(\"Wrong number of total categories!\", 2, totalCategories);\n\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  /**\n   * Test that a document with no payloads does not confuse the payload decoder.\n   */\n  @Test\n  public void testPayloadIteratorWithInvalidDoc() throws Exception {\n    Directory dir = newDirectory();\n    final IntEncoder encoder = new SortingIntEncoder(new UniqueValuesIntEncoder(new DGapIntEncoder(new VInt8IntEncoder())));\n    DataTokenStream dts = new DataTokenStream(\"1\", encoder);\n    // this test requires that no payloads ever be randomly present!\n    final Analyzer noPayloadsAnalyzer = new Analyzer() {\n      @Override\n      public TokenStreamComponents createComponents(String fieldName, Reader reader) {\n        return new TokenStreamComponents(new MockTokenizer(reader, MockTokenizer.KEYWORD, false));\n      }\n    };\n    // NOTE: test is wired to LogMP... because test relies on certain docids having payloads\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, \n        newIndexWriterConfig(TEST_VERSION_CURRENT, noPayloadsAnalyzer).setMergePolicy(newLogMergePolicy()));\n    for (int i = 0; i < data.length; i++) {\n      Document doc = new Document();\n      if (i == 0) {\n        dts.setIdx(i);\n        doc.add(new TextField(\"f\", dts)); // only doc 0 has payloads!\n      } else {\n        doc.add(new TextField(\"f\", \"1\", Field.Store.NO));\n      }\n      writer.addDocument(doc);\n      writer.commit();\n    }\n\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    IntsRef ordinals = new IntsRef();\n    CategoryListIterator cli = new PayloadCategoryListIteraor(reader, new Term(\"f\",\"1\"), encoder.createMatchingDecoder());\n    assertTrue(\"Failed to initialize payload iterator\", cli.init());\n    int totalCategories = 0;\n    for (int i = 0; i < data.length; i++) {\n      Set<Integer> values = new HashSet<Integer>();\n      for (int j = 0; j < data[i].length; j++) {\n        values.add(data[i].ints[j]);\n      }\n      cli.getOrdinals(i, ordinals);\n      if (i == 0) {\n        assertTrue(\"document 0 must have a payload\", ordinals.length > 0);\n        for (int j = 0; j < ordinals.length; j++) {\n          assertTrue(\"expected category not found: \" + ordinals.ints[j], values.contains(ordinals.ints[j]));\n        }\n        totalCategories += ordinals.length;\n      } else {\n        assertTrue(\"only document 0 should have a payload\", ordinals.length == 0);\n      }\n    }\n    assertEquals(\"Wrong number of total categories!\", 2, totalCategories);\n\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6c2cd18c7da6f499a33f06fc89c07a463ec074c0","date":1358329431,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/facet/src/test/org/apache/lucene/facet/search/CategoryListIteratorTest#testPayloadIteratorWithInvalidDoc().mjava","pathOld":"lucene/facet/src/test/org/apache/lucene/facet/search/CategoryListIteratorTest#testPayloadIteratorWithInvalidDoc().mjava","sourceNew":"  @Test\n  public void testPayloadIteratorWithInvalidDoc() throws Exception {\n    Directory dir = newDirectory();\n    final IntEncoder encoder = new SortingIntEncoder(new UniqueValuesIntEncoder(new DGapIntEncoder(new VInt8IntEncoder())));\n    // NOTE: test is wired to LogMP... because test relies on certain docids having payloads\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, \n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMergePolicy(newLogMergePolicy()));\n    for (int i = 0; i < data.length; i++) {\n      Document doc = new Document();\n      if (i == 0) {\n        BytesRef buf = new BytesRef();\n        encoder.encode(IntsRef.deepCopyOf(data[i]), buf );\n        doc.add(new StraightBytesDocValuesField(\"f\", buf));\n      } else {\n        doc.add(new StraightBytesDocValuesField(\"f\", new BytesRef()));\n      }\n      writer.addDocument(doc);\n      writer.commit();\n    }\n\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    int totalCategories = 0;\n    IntsRef ordinals = new IntsRef();\n    CategoryListIterator cli = new DocValuesCategoryListIterator(\"f\", encoder.createMatchingDecoder());\n    for (AtomicReaderContext context : reader.leaves()) {\n      assertTrue(\"failed to initalize iterator\", cli.setNextReader(context));\n      int maxDoc = context.reader().maxDoc();\n      int dataIdx = context.docBase;\n      for (int doc = 0; doc < maxDoc; doc++, dataIdx++) {\n        Set<Integer> values = new HashSet<Integer>();\n        for (int j = 0; j < data[dataIdx].length; j++) {\n          values.add(data[dataIdx].ints[j]);\n        }\n        cli.getOrdinals(doc, ordinals);\n        if (dataIdx == 0) {\n          assertTrue(\"document 0 must have ordinals\", ordinals.length > 0);\n          for (int j = 0; j < ordinals.length; j++) {\n            assertTrue(\"expected category not found: \" + ordinals.ints[j], values.contains(ordinals.ints[j]));\n          }\n          totalCategories += ordinals.length;\n        } else {\n          assertTrue(\"only document 0 should have ordinals\", ordinals.length == 0);\n        }\n      }\n    }\n    assertEquals(\"Wrong number of total categories!\", 2, totalCategories);\n\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  @Test\n  public void testPayloadIteratorWithInvalidDoc() throws Exception {\n    Directory dir = newDirectory();\n    final IntEncoder encoder = new SortingIntEncoder(new UniqueValuesIntEncoder(new DGapIntEncoder(new VInt8IntEncoder())));\n    DataTokenStream dts = new DataTokenStream(\"1\", encoder);\n    // this test requires that no payloads ever be randomly present!\n    final Analyzer noPayloadsAnalyzer = new Analyzer() {\n      @Override\n      public TokenStreamComponents createComponents(String fieldName, Reader reader) {\n        return new TokenStreamComponents(new MockTokenizer(reader, MockTokenizer.KEYWORD, false));\n      }\n    };\n    // NOTE: test is wired to LogMP... because test relies on certain docids having payloads\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, \n        newIndexWriterConfig(TEST_VERSION_CURRENT, noPayloadsAnalyzer).setMergePolicy(newLogMergePolicy()));\n    for (int i = 0; i < data.length; i++) {\n      Document doc = new Document();\n      if (i == 0) {\n        dts.setIdx(i);\n        doc.add(new TextField(\"f\", dts)); // only doc 0 has payloads!\n      } else {\n        doc.add(new TextField(\"f\", \"1\", Field.Store.NO));\n      }\n      writer.addDocument(doc);\n      writer.commit();\n    }\n\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    int totalCategories = 0;\n    IntsRef ordinals = new IntsRef();\n    CategoryListIterator cli = new PayloadCategoryListIteraor(new Term(\"f\",\"1\"), encoder.createMatchingDecoder());\n    for (AtomicReaderContext context : reader.leaves()) {\n      cli.setNextReader(context);\n      int maxDoc = context.reader().maxDoc();\n      int dataIdx = context.docBase;\n      for (int doc = 0; doc < maxDoc; doc++, dataIdx++) {\n        Set<Integer> values = new HashSet<Integer>();\n        for (int j = 0; j < data[dataIdx].length; j++) {\n          values.add(data[dataIdx].ints[j]);\n        }\n        cli.getOrdinals(doc, ordinals);\n        if (dataIdx == 0) {\n          assertTrue(\"document 0 must have a payload\", ordinals.length > 0);\n          for (int j = 0; j < ordinals.length; j++) {\n            assertTrue(\"expected category not found: \" + ordinals.ints[j], values.contains(ordinals.ints[j]));\n          }\n          totalCategories += ordinals.length;\n        } else {\n          assertTrue(\"only document 0 should have a payload\", ordinals.length == 0);\n        }\n      }\n    }\n    assertEquals(\"Wrong number of total categories!\", 2, totalCategories);\n\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":["d4d69c535930b5cce125cff868d40f6373dc27d4","d4d69c535930b5cce125cff868d40f6373dc27d4"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"c4015cd39dff8d4dec562d909f9766debac53aa6","date":1358548736,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/facet/src/test/org/apache/lucene/facet/search/CategoryListIteratorTest#testPayloadIteratorWithInvalidDoc().mjava","pathOld":"lucene/facet/src/test/org/apache/lucene/facet/search/CategoryListIteratorTest#testPayloadIteratorWithInvalidDoc().mjava","sourceNew":"  @Test\n  public void testPayloadIteratorWithInvalidDoc() throws Exception {\n    Directory dir = newDirectory();\n    final IntEncoder encoder = new SortingIntEncoder(new UniqueValuesIntEncoder(new DGapIntEncoder(new VInt8IntEncoder())));\n    // NOTE: test is wired to LogMP... because test relies on certain docids having payloads\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, \n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMergePolicy(newLogMergePolicy()));\n    for (int i = 0; i < data.length; i++) {\n      Document doc = new Document();\n      if (i == 0) {\n        BytesRef buf = new BytesRef();\n        encoder.encode(IntsRef.deepCopyOf(data[i]), buf );\n        doc.add(new StraightBytesDocValuesField(\"f\", buf));\n      } else {\n        doc.add(new StraightBytesDocValuesField(\"f\", new BytesRef()));\n      }\n      writer.addDocument(doc);\n      writer.commit();\n    }\n\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    int totalCategories = 0;\n    IntsRef ordinals = new IntsRef();\n    CategoryListIterator cli = new DocValuesCategoryListIterator(\"f\", encoder.createMatchingDecoder());\n    for (AtomicReaderContext context : reader.leaves()) {\n      assertTrue(\"failed to initalize iterator\", cli.setNextReader(context));\n      int maxDoc = context.reader().maxDoc();\n      int dataIdx = context.docBase;\n      for (int doc = 0; doc < maxDoc; doc++, dataIdx++) {\n        Set<Integer> values = new HashSet<Integer>();\n        for (int j = 0; j < data[dataIdx].length; j++) {\n          values.add(data[dataIdx].ints[j]);\n        }\n        cli.getOrdinals(doc, ordinals);\n        if (dataIdx == 0) {\n          assertTrue(\"document 0 must have ordinals\", ordinals.length > 0);\n          for (int j = 0; j < ordinals.length; j++) {\n            assertTrue(\"expected category not found: \" + ordinals.ints[j], values.contains(ordinals.ints[j]));\n          }\n          totalCategories += ordinals.length;\n        } else {\n          assertTrue(\"only document 0 should have ordinals\", ordinals.length == 0);\n        }\n      }\n    }\n    assertEquals(\"Wrong number of total categories!\", 2, totalCategories);\n\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  @Test\n  public void testPayloadIteratorWithInvalidDoc() throws Exception {\n    Directory dir = newDirectory();\n    final IntEncoder encoder = new SortingIntEncoder(new UniqueValuesIntEncoder(new DGapIntEncoder(new VInt8IntEncoder())));\n    DataTokenStream dts = new DataTokenStream(\"1\", encoder);\n    // this test requires that no payloads ever be randomly present!\n    final Analyzer noPayloadsAnalyzer = new Analyzer() {\n      @Override\n      public TokenStreamComponents createComponents(String fieldName, Reader reader) {\n        return new TokenStreamComponents(new MockTokenizer(reader, MockTokenizer.KEYWORD, false));\n      }\n    };\n    // NOTE: test is wired to LogMP... because test relies on certain docids having payloads\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, \n        newIndexWriterConfig(TEST_VERSION_CURRENT, noPayloadsAnalyzer).setMergePolicy(newLogMergePolicy()));\n    for (int i = 0; i < data.length; i++) {\n      Document doc = new Document();\n      if (i == 0) {\n        dts.setIdx(i);\n        doc.add(new TextField(\"f\", dts)); // only doc 0 has payloads!\n      } else {\n        doc.add(new TextField(\"f\", \"1\", Field.Store.NO));\n      }\n      writer.addDocument(doc);\n      writer.commit();\n    }\n\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    int totalCategories = 0;\n    IntsRef ordinals = new IntsRef();\n    CategoryListIterator cli = new PayloadCategoryListIteraor(new Term(\"f\",\"1\"), encoder.createMatchingDecoder());\n    for (AtomicReaderContext context : reader.leaves()) {\n      cli.setNextReader(context);\n      int maxDoc = context.reader().maxDoc();\n      int dataIdx = context.docBase;\n      for (int doc = 0; doc < maxDoc; doc++, dataIdx++) {\n        Set<Integer> values = new HashSet<Integer>();\n        for (int j = 0; j < data[dataIdx].length; j++) {\n          values.add(data[dataIdx].ints[j]);\n        }\n        cli.getOrdinals(doc, ordinals);\n        if (dataIdx == 0) {\n          assertTrue(\"document 0 must have a payload\", ordinals.length > 0);\n          for (int j = 0; j < ordinals.length; j++) {\n            assertTrue(\"expected category not found: \" + ordinals.ints[j], values.contains(ordinals.ints[j]));\n          }\n          totalCategories += ordinals.length;\n        } else {\n          assertTrue(\"only document 0 should have a payload\", ordinals.length == 0);\n        }\n      }\n    }\n    assertEquals(\"Wrong number of total categories!\", 2, totalCategories);\n\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"423d89a2b3cc419b647c07c2b3fdbc54311d07f9","date":1358836612,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/facet/src/test/org/apache/lucene/facet/search/CategoryListIteratorTest#testPayloadIteratorWithInvalidDoc().mjava","pathOld":"lucene/facet/src/test/org/apache/lucene/facet/search/CategoryListIteratorTest#testPayloadIteratorWithInvalidDoc().mjava","sourceNew":"  @Test\n  public void testPayloadIteratorWithInvalidDoc() throws Exception {\n    Directory dir = newDirectory();\n    final IntEncoder encoder = new SortingIntEncoder(new UniqueValuesIntEncoder(new DGapIntEncoder(new VInt8IntEncoder())));\n    // NOTE: test is wired to LogMP... because test relies on certain docids having payloads\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, \n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMergePolicy(newLogMergePolicy()));\n    for (int i = 0; i < data.length; i++) {\n      Document doc = new Document();\n      if (i == 0) {\n        BytesRef buf = new BytesRef();\n        encoder.encode(IntsRef.deepCopyOf(data[i]), buf );\n        doc.add(new BinaryDocValuesField(\"f\", buf));\n      } else {\n        doc.add(new BinaryDocValuesField(\"f\", new BytesRef()));\n      }\n      writer.addDocument(doc);\n      writer.commit();\n    }\n\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    int totalCategories = 0;\n    IntsRef ordinals = new IntsRef();\n    CategoryListIterator cli = new DocValuesCategoryListIterator(\"f\", encoder.createMatchingDecoder());\n    for (AtomicReaderContext context : reader.leaves()) {\n      assertTrue(\"failed to initalize iterator\", cli.setNextReader(context));\n      int maxDoc = context.reader().maxDoc();\n      int dataIdx = context.docBase;\n      for (int doc = 0; doc < maxDoc; doc++, dataIdx++) {\n        Set<Integer> values = new HashSet<Integer>();\n        for (int j = 0; j < data[dataIdx].length; j++) {\n          values.add(data[dataIdx].ints[j]);\n        }\n        cli.getOrdinals(doc, ordinals);\n        if (dataIdx == 0) {\n          assertTrue(\"document 0 must have ordinals\", ordinals.length > 0);\n          for (int j = 0; j < ordinals.length; j++) {\n            assertTrue(\"expected category not found: \" + ordinals.ints[j], values.contains(ordinals.ints[j]));\n          }\n          totalCategories += ordinals.length;\n        } else {\n          assertTrue(\"only document 0 should have ordinals\", ordinals.length == 0);\n        }\n      }\n    }\n    assertEquals(\"Wrong number of total categories!\", 2, totalCategories);\n\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  @Test\n  public void testPayloadIteratorWithInvalidDoc() throws Exception {\n    Directory dir = newDirectory();\n    final IntEncoder encoder = new SortingIntEncoder(new UniqueValuesIntEncoder(new DGapIntEncoder(new VInt8IntEncoder())));\n    // NOTE: test is wired to LogMP... because test relies on certain docids having payloads\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, \n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMergePolicy(newLogMergePolicy()));\n    for (int i = 0; i < data.length; i++) {\n      Document doc = new Document();\n      if (i == 0) {\n        BytesRef buf = new BytesRef();\n        encoder.encode(IntsRef.deepCopyOf(data[i]), buf );\n        doc.add(new StraightBytesDocValuesField(\"f\", buf));\n      } else {\n        doc.add(new StraightBytesDocValuesField(\"f\", new BytesRef()));\n      }\n      writer.addDocument(doc);\n      writer.commit();\n    }\n\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    int totalCategories = 0;\n    IntsRef ordinals = new IntsRef();\n    CategoryListIterator cli = new DocValuesCategoryListIterator(\"f\", encoder.createMatchingDecoder());\n    for (AtomicReaderContext context : reader.leaves()) {\n      assertTrue(\"failed to initalize iterator\", cli.setNextReader(context));\n      int maxDoc = context.reader().maxDoc();\n      int dataIdx = context.docBase;\n      for (int doc = 0; doc < maxDoc; doc++, dataIdx++) {\n        Set<Integer> values = new HashSet<Integer>();\n        for (int j = 0; j < data[dataIdx].length; j++) {\n          values.add(data[dataIdx].ints[j]);\n        }\n        cli.getOrdinals(doc, ordinals);\n        if (dataIdx == 0) {\n          assertTrue(\"document 0 must have ordinals\", ordinals.length > 0);\n          for (int j = 0; j < ordinals.length; j++) {\n            assertTrue(\"expected category not found: \" + ordinals.ints[j], values.contains(ordinals.ints[j]));\n          }\n          totalCategories += ordinals.length;\n        } else {\n          assertTrue(\"only document 0 should have ordinals\", ordinals.length == 0);\n        }\n      }\n    }\n    assertEquals(\"Wrong number of total categories!\", 2, totalCategories);\n\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"90213788e5007cc5e2b3d88200a8265de9d4e6d4","date":1359060940,"type":5,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/facet/src/test/org/apache/lucene/facet/search/CategoryListIteratorTest#testEmptyDocuments().mjava","pathOld":"lucene/facet/src/test/org/apache/lucene/facet/search/CategoryListIteratorTest#testPayloadIteratorWithInvalidDoc().mjava","sourceNew":"  @Test\n  public void testEmptyDocuments() throws Exception {\n    Directory dir = newDirectory();\n    final IntEncoder encoder = new SortingIntEncoder(new UniqueValuesIntEncoder(new DGapIntEncoder(new VInt8IntEncoder())));\n    // NOTE: test is wired to LogMP... because test relies on certain docids having payloads\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, \n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMergePolicy(newLogMergePolicy()));\n    for (int i = 0; i < data.length; i++) {\n      Document doc = new Document();\n      if (i == 0) {\n        BytesRef buf = new BytesRef();\n        encoder.encode(IntsRef.deepCopyOf(data[i]), buf );\n        doc.add(new StraightBytesDocValuesField(\"f\", buf));\n      } else {\n        doc.add(new StraightBytesDocValuesField(\"f\", new BytesRef()));\n      }\n      writer.addDocument(doc);\n      writer.commit();\n    }\n\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    int totalCategories = 0;\n    IntsRef ordinals = new IntsRef();\n    CategoryListIterator cli = new DocValuesCategoryListIterator(\"f\", encoder.createMatchingDecoder());\n    for (AtomicReaderContext context : reader.leaves()) {\n      assertTrue(\"failed to initalize iterator\", cli.setNextReader(context));\n      int maxDoc = context.reader().maxDoc();\n      int dataIdx = context.docBase;\n      for (int doc = 0; doc < maxDoc; doc++, dataIdx++) {\n        Set<Integer> values = new HashSet<Integer>();\n        for (int j = 0; j < data[dataIdx].length; j++) {\n          values.add(data[dataIdx].ints[j]);\n        }\n        cli.getOrdinals(doc, ordinals);\n        if (dataIdx == 0) {\n          assertTrue(\"document 0 must have ordinals\", ordinals.length > 0);\n          for (int j = 0; j < ordinals.length; j++) {\n            assertTrue(\"expected category not found: \" + ordinals.ints[j], values.contains(ordinals.ints[j]));\n          }\n          totalCategories += ordinals.length;\n        } else {\n          assertTrue(\"only document 0 should have ordinals\", ordinals.length == 0);\n        }\n      }\n    }\n    assertEquals(\"Wrong number of total categories!\", 2, totalCategories);\n\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  @Test\n  public void testPayloadIteratorWithInvalidDoc() throws Exception {\n    Directory dir = newDirectory();\n    final IntEncoder encoder = new SortingIntEncoder(new UniqueValuesIntEncoder(new DGapIntEncoder(new VInt8IntEncoder())));\n    // NOTE: test is wired to LogMP... because test relies on certain docids having payloads\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, \n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMergePolicy(newLogMergePolicy()));\n    for (int i = 0; i < data.length; i++) {\n      Document doc = new Document();\n      if (i == 0) {\n        BytesRef buf = new BytesRef();\n        encoder.encode(IntsRef.deepCopyOf(data[i]), buf );\n        doc.add(new StraightBytesDocValuesField(\"f\", buf));\n      } else {\n        doc.add(new StraightBytesDocValuesField(\"f\", new BytesRef()));\n      }\n      writer.addDocument(doc);\n      writer.commit();\n    }\n\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    int totalCategories = 0;\n    IntsRef ordinals = new IntsRef();\n    CategoryListIterator cli = new DocValuesCategoryListIterator(\"f\", encoder.createMatchingDecoder());\n    for (AtomicReaderContext context : reader.leaves()) {\n      assertTrue(\"failed to initalize iterator\", cli.setNextReader(context));\n      int maxDoc = context.reader().maxDoc();\n      int dataIdx = context.docBase;\n      for (int doc = 0; doc < maxDoc; doc++, dataIdx++) {\n        Set<Integer> values = new HashSet<Integer>();\n        for (int j = 0; j < data[dataIdx].length; j++) {\n          values.add(data[dataIdx].ints[j]);\n        }\n        cli.getOrdinals(doc, ordinals);\n        if (dataIdx == 0) {\n          assertTrue(\"document 0 must have ordinals\", ordinals.length > 0);\n          for (int j = 0; j < ordinals.length; j++) {\n            assertTrue(\"expected category not found: \" + ordinals.ints[j], values.contains(ordinals.ints[j]));\n          }\n          totalCategories += ordinals.length;\n        } else {\n          assertTrue(\"only document 0 should have ordinals\", ordinals.length == 0);\n        }\n      }\n    }\n    assertEquals(\"Wrong number of total categories!\", 2, totalCategories);\n\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"dd45d4a2ee01a1932d33eec42f5272c2402da679","date":1359316912,"type":5,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/facet/src/test/org/apache/lucene/facet/search/CategoryListIteratorTest#testEmptyDocuments().mjava","pathOld":"lucene/facet/src/test/org/apache/lucene/facet/search/CategoryListIteratorTest#testPayloadIteratorWithInvalidDoc().mjava","sourceNew":"  @Test\n  public void testEmptyDocuments() throws Exception {\n    Directory dir = newDirectory();\n    final IntEncoder encoder = new SortingIntEncoder(new UniqueValuesIntEncoder(new DGapIntEncoder(new VInt8IntEncoder())));\n    // NOTE: test is wired to LogMP... because test relies on certain docids having payloads\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, \n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMergePolicy(newLogMergePolicy()));\n    for (int i = 0; i < data.length; i++) {\n      Document doc = new Document();\n      if (i == 0) {\n        BytesRef buf = new BytesRef();\n        encoder.encode(IntsRef.deepCopyOf(data[i]), buf );\n        doc.add(new BinaryDocValuesField(\"f\", buf));\n      } else {\n        doc.add(new BinaryDocValuesField(\"f\", new BytesRef()));\n      }\n      writer.addDocument(doc);\n      writer.commit();\n    }\n\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    int totalCategories = 0;\n    IntsRef ordinals = new IntsRef();\n    CategoryListIterator cli = new DocValuesCategoryListIterator(\"f\", encoder.createMatchingDecoder());\n    for (AtomicReaderContext context : reader.leaves()) {\n      assertTrue(\"failed to initalize iterator\", cli.setNextReader(context));\n      int maxDoc = context.reader().maxDoc();\n      int dataIdx = context.docBase;\n      for (int doc = 0; doc < maxDoc; doc++, dataIdx++) {\n        Set<Integer> values = new HashSet<Integer>();\n        for (int j = 0; j < data[dataIdx].length; j++) {\n          values.add(data[dataIdx].ints[j]);\n        }\n        cli.getOrdinals(doc, ordinals);\n        if (dataIdx == 0) {\n          assertTrue(\"document 0 must have ordinals\", ordinals.length > 0);\n          for (int j = 0; j < ordinals.length; j++) {\n            assertTrue(\"expected category not found: \" + ordinals.ints[j], values.contains(ordinals.ints[j]));\n          }\n          totalCategories += ordinals.length;\n        } else {\n          assertTrue(\"only document 0 should have ordinals\", ordinals.length == 0);\n        }\n      }\n    }\n    assertEquals(\"Wrong number of total categories!\", 2, totalCategories);\n\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  @Test\n  public void testPayloadIteratorWithInvalidDoc() throws Exception {\n    Directory dir = newDirectory();\n    final IntEncoder encoder = new SortingIntEncoder(new UniqueValuesIntEncoder(new DGapIntEncoder(new VInt8IntEncoder())));\n    // NOTE: test is wired to LogMP... because test relies on certain docids having payloads\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, \n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMergePolicy(newLogMergePolicy()));\n    for (int i = 0; i < data.length; i++) {\n      Document doc = new Document();\n      if (i == 0) {\n        BytesRef buf = new BytesRef();\n        encoder.encode(IntsRef.deepCopyOf(data[i]), buf );\n        doc.add(new BinaryDocValuesField(\"f\", buf));\n      } else {\n        doc.add(new BinaryDocValuesField(\"f\", new BytesRef()));\n      }\n      writer.addDocument(doc);\n      writer.commit();\n    }\n\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    int totalCategories = 0;\n    IntsRef ordinals = new IntsRef();\n    CategoryListIterator cli = new DocValuesCategoryListIterator(\"f\", encoder.createMatchingDecoder());\n    for (AtomicReaderContext context : reader.leaves()) {\n      assertTrue(\"failed to initalize iterator\", cli.setNextReader(context));\n      int maxDoc = context.reader().maxDoc();\n      int dataIdx = context.docBase;\n      for (int doc = 0; doc < maxDoc; doc++, dataIdx++) {\n        Set<Integer> values = new HashSet<Integer>();\n        for (int j = 0; j < data[dataIdx].length; j++) {\n          values.add(data[dataIdx].ints[j]);\n        }\n        cli.getOrdinals(doc, ordinals);\n        if (dataIdx == 0) {\n          assertTrue(\"document 0 must have ordinals\", ordinals.length > 0);\n          for (int j = 0; j < ordinals.length; j++) {\n            assertTrue(\"expected category not found: \" + ordinals.ints[j], values.contains(ordinals.ints[j]));\n          }\n          totalCategories += ordinals.length;\n        } else {\n          assertTrue(\"only document 0 should have ordinals\", ordinals.length == 0);\n        }\n      }\n    }\n    assertEquals(\"Wrong number of total categories!\", 2, totalCategories);\n\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"42f51b3ab4258ff4623227b0db011b8bb83db5c7":["bceb02c33032dd9bbf107cd06d0b74e5db4f110a"],"c4015cd39dff8d4dec562d909f9766debac53aa6":["8917bfede3b4ca30f4305c1e391e9218959cd723","6c2cd18c7da6f499a33f06fc89c07a463ec074c0"],"bceb02c33032dd9bbf107cd06d0b74e5db4f110a":["04f07771a2a7dd3a395700665ed839c3dae2def2"],"8917bfede3b4ca30f4305c1e391e9218959cd723":["4e6354dd7c71fe122926fc53d7d29f715b1283db","42f51b3ab4258ff4623227b0db011b8bb83db5c7"],"dd45d4a2ee01a1932d33eec42f5272c2402da679":["423d89a2b3cc419b647c07c2b3fdbc54311d07f9","90213788e5007cc5e2b3d88200a8265de9d4e6d4"],"04f07771a2a7dd3a395700665ed839c3dae2def2":["b89678825b68eccaf09e6ab71675fc0b0af1e099"],"90213788e5007cc5e2b3d88200a8265de9d4e6d4":["6c2cd18c7da6f499a33f06fc89c07a463ec074c0"],"b89678825b68eccaf09e6ab71675fc0b0af1e099":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"423d89a2b3cc419b647c07c2b3fdbc54311d07f9":["c4015cd39dff8d4dec562d909f9766debac53aa6"],"6c2cd18c7da6f499a33f06fc89c07a463ec074c0":["42f51b3ab4258ff4623227b0db011b8bb83db5c7"],"4e6354dd7c71fe122926fc53d7d29f715b1283db":["04f07771a2a7dd3a395700665ed839c3dae2def2","bceb02c33032dd9bbf107cd06d0b74e5db4f110a"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["90213788e5007cc5e2b3d88200a8265de9d4e6d4"]},"commit2Childs":{"42f51b3ab4258ff4623227b0db011b8bb83db5c7":["8917bfede3b4ca30f4305c1e391e9218959cd723","6c2cd18c7da6f499a33f06fc89c07a463ec074c0"],"c4015cd39dff8d4dec562d909f9766debac53aa6":["423d89a2b3cc419b647c07c2b3fdbc54311d07f9"],"bceb02c33032dd9bbf107cd06d0b74e5db4f110a":["42f51b3ab4258ff4623227b0db011b8bb83db5c7","4e6354dd7c71fe122926fc53d7d29f715b1283db"],"8917bfede3b4ca30f4305c1e391e9218959cd723":["c4015cd39dff8d4dec562d909f9766debac53aa6"],"dd45d4a2ee01a1932d33eec42f5272c2402da679":[],"04f07771a2a7dd3a395700665ed839c3dae2def2":["bceb02c33032dd9bbf107cd06d0b74e5db4f110a","4e6354dd7c71fe122926fc53d7d29f715b1283db"],"90213788e5007cc5e2b3d88200a8265de9d4e6d4":["dd45d4a2ee01a1932d33eec42f5272c2402da679","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"b89678825b68eccaf09e6ab71675fc0b0af1e099":["04f07771a2a7dd3a395700665ed839c3dae2def2"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["b89678825b68eccaf09e6ab71675fc0b0af1e099"],"423d89a2b3cc419b647c07c2b3fdbc54311d07f9":["dd45d4a2ee01a1932d33eec42f5272c2402da679"],"6c2cd18c7da6f499a33f06fc89c07a463ec074c0":["c4015cd39dff8d4dec562d909f9766debac53aa6","90213788e5007cc5e2b3d88200a8265de9d4e6d4"],"4e6354dd7c71fe122926fc53d7d29f715b1283db":["8917bfede3b4ca30f4305c1e391e9218959cd723"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["dd45d4a2ee01a1932d33eec42f5272c2402da679","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}