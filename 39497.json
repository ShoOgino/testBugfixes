{"path":"solr/contrib/analysis-extras/src/main/java/org/apache/solr/schema/ICUCollationField#analyzeRangePart(String,String).mjava","commits":[{"id":"a3776dccca01c11e7046323cfad46a3b4a471233","date":1306100719,"type":1,"author":"Steven Rowe","isMerge":true,"pathNew":"solr/contrib/analysis-extras/src/main/java/org/apache/solr/schema/ICUCollationField#analyzeRangePart(String,String).mjava","pathOld":"solr/contrib/analysis-extras/src/java/org/apache/solr/schema/ICUCollationField#analyzeRangePart(String,String).mjava","sourceNew":"  /**\n   * analyze the range with the analyzer, instead of the collator.\n   * because icu collators are not thread safe, this keeps things \n   * simple (we already have a threadlocal clone in the reused TS)\n   */\n  private BytesRef analyzeRangePart(String field, String part) {\n    TokenStream source;\n      \n    try {\n      source = analyzer.reusableTokenStream(field, new StringReader(part));\n      source.reset();\n    } catch (IOException e) {\n      source = analyzer.tokenStream(field, new StringReader(part));\n    }\n      \n    TermToBytesRefAttribute termAtt = source.getAttribute(TermToBytesRefAttribute.class);\n    BytesRef bytes = termAtt.getBytesRef();\n\n    // we control the analyzer here: most errors are impossible\n    try {\n      if (!source.incrementToken())\n        throw new IllegalArgumentException(\"analyzer returned no terms for range part: \" + part);\n      termAtt.fillBytesRef();\n      assert !source.incrementToken();\n    } catch (IOException e) {\n      throw new RuntimeException(\"error analyzing range part: \" + part, e);\n    }\n      \n    try {\n      source.close();\n    } catch (IOException ignored) {}\n      \n    return new BytesRef(bytes);\n  }\n\n","sourceOld":"  /**\n   * analyze the range with the analyzer, instead of the collator.\n   * because icu collators are not thread safe, this keeps things \n   * simple (we already have a threadlocal clone in the reused TS)\n   */\n  private BytesRef analyzeRangePart(String field, String part) {\n    TokenStream source;\n      \n    try {\n      source = analyzer.reusableTokenStream(field, new StringReader(part));\n      source.reset();\n    } catch (IOException e) {\n      source = analyzer.tokenStream(field, new StringReader(part));\n    }\n      \n    TermToBytesRefAttribute termAtt = source.getAttribute(TermToBytesRefAttribute.class);\n    BytesRef bytes = termAtt.getBytesRef();\n\n    // we control the analyzer here: most errors are impossible\n    try {\n      if (!source.incrementToken())\n        throw new IllegalArgumentException(\"analyzer returned no terms for range part: \" + part);\n      termAtt.fillBytesRef();\n      assert !source.incrementToken();\n    } catch (IOException e) {\n      throw new RuntimeException(\"error analyzing range part: \" + part, e);\n    }\n      \n    try {\n      source.close();\n    } catch (IOException ignored) {}\n      \n    return new BytesRef(bytes);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5128b7b3b73fedff05fdc5ea2e6be53c1020bb91","date":1306767085,"type":5,"author":"Steven Rowe","isMerge":true,"pathNew":"solr/contrib/analysis-extras/src/java/org/apache/solr/schema/ICUCollationField#analyzeRangePart(String,String).mjava","pathOld":"solr/contrib/analysis-extras/src/main/java/org/apache/solr/schema/ICUCollationField#analyzeRangePart(String,String).mjava","sourceNew":"  /**\n   * analyze the range with the analyzer, instead of the collator.\n   * because icu collators are not thread safe, this keeps things \n   * simple (we already have a threadlocal clone in the reused TS)\n   */\n  private BytesRef analyzeRangePart(String field, String part) {\n    TokenStream source;\n      \n    try {\n      source = analyzer.reusableTokenStream(field, new StringReader(part));\n      source.reset();\n    } catch (IOException e) {\n      source = analyzer.tokenStream(field, new StringReader(part));\n    }\n      \n    TermToBytesRefAttribute termAtt = source.getAttribute(TermToBytesRefAttribute.class);\n    BytesRef bytes = termAtt.getBytesRef();\n\n    // we control the analyzer here: most errors are impossible\n    try {\n      if (!source.incrementToken())\n        throw new IllegalArgumentException(\"analyzer returned no terms for range part: \" + part);\n      termAtt.fillBytesRef();\n      assert !source.incrementToken();\n    } catch (IOException e) {\n      throw new RuntimeException(\"error analyzing range part: \" + part, e);\n    }\n      \n    try {\n      source.close();\n    } catch (IOException ignored) {}\n      \n    return new BytesRef(bytes);\n  }\n\n","sourceOld":"  /**\n   * analyze the range with the analyzer, instead of the collator.\n   * because icu collators are not thread safe, this keeps things \n   * simple (we already have a threadlocal clone in the reused TS)\n   */\n  private BytesRef analyzeRangePart(String field, String part) {\n    TokenStream source;\n      \n    try {\n      source = analyzer.reusableTokenStream(field, new StringReader(part));\n      source.reset();\n    } catch (IOException e) {\n      source = analyzer.tokenStream(field, new StringReader(part));\n    }\n      \n    TermToBytesRefAttribute termAtt = source.getAttribute(TermToBytesRefAttribute.class);\n    BytesRef bytes = termAtt.getBytesRef();\n\n    // we control the analyzer here: most errors are impossible\n    try {\n      if (!source.incrementToken())\n        throw new IllegalArgumentException(\"analyzer returned no terms for range part: \" + part);\n      termAtt.fillBytesRef();\n      assert !source.incrementToken();\n    } catch (IOException e) {\n      throw new RuntimeException(\"error analyzing range part: \" + part, e);\n    }\n      \n    try {\n      source.close();\n    } catch (IOException ignored) {}\n      \n    return new BytesRef(bytes);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"5128b7b3b73fedff05fdc5ea2e6be53c1020bb91":["a3776dccca01c11e7046323cfad46a3b4a471233","a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a3776dccca01c11e7046323cfad46a3b4a471233":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"5128b7b3b73fedff05fdc5ea2e6be53c1020bb91":[],"a3776dccca01c11e7046323cfad46a3b4a471233":["5128b7b3b73fedff05fdc5ea2e6be53c1020bb91"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["5128b7b3b73fedff05fdc5ea2e6be53c1020bb91","a3776dccca01c11e7046323cfad46a3b4a471233","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["5128b7b3b73fedff05fdc5ea2e6be53c1020bb91","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}