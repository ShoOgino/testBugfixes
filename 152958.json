{"path":"solr/core/src/java/org/apache/solr/update/PeerSync#handleUpdates(ShardResponse).mjava","commits":[{"id":"2c007e7c4cf8c55bc2a5884e315123afaaeec87f","date":1327520966,"type":0,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/update/PeerSync#handleUpdates(ShardResponse).mjava","pathOld":"/dev/null","sourceNew":"  private boolean handleUpdates(ShardResponse srsp) {\n    // we retrieved the last N updates from the replica\n    List<Object> updates = (List<Object>)srsp.getSolrResponse().getResponse().get(\"updates\");\n\n    SyncShardRequest sreq = (SyncShardRequest) srsp.getShardRequest();\n    if (updates.size() < sreq.requestedUpdates.size()) {\n      log.error(\"PeerSync: Requested \" + sreq.requestedUpdates.size() + \" updates from \" + sreq.shards[0] + \" but retrieved \" + updates.size());\n      return false;\n    }\n\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(DistributedUpdateProcessor.SEEN_LEADER, true);\n    SolrQueryRequest req = new LocalSolrQueryRequest(uhandler.core, params);\n    SolrQueryResponse rsp = new SolrQueryResponse();\n\n    RunUpdateProcessorFactory runFac = new RunUpdateProcessorFactory();\n    DistributedUpdateProcessorFactory magicFac = new DistributedUpdateProcessorFactory();\n    runFac.init(new NamedList());\n    magicFac.init(new NamedList());\n\n    UpdateRequestProcessor proc = magicFac.getInstance(req, rsp, runFac.getInstance(req, rsp, null));\n\n    Collections.sort(updates, updateRecordComparator);\n\n    Object o = null;\n    long lastVersion = 0;\n    try {\n      // Apply oldest updates first\n      for (Object obj : updates) {\n        // should currently be a List<Oper,Ver,Doc/Id>\n        o = obj;\n        List<Object> entry = (List<Object>)o;\n\n        int oper = (Integer)entry.get(0);\n        long version = (Long) entry.get(1);\n        if (version == lastVersion && version != 0) continue;\n        lastVersion = version;\n\n        switch (oper) {\n          case UpdateLog.ADD:\n          {\n            // byte[] idBytes = (byte[]) entry.get(2);\n            SolrInputDocument sdoc = (SolrInputDocument)entry.get(entry.size()-1);\n            AddUpdateCommand cmd = new AddUpdateCommand(req);\n            // cmd.setIndexedId(new BytesRef(idBytes));\n            cmd.solrDoc = sdoc;\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            proc.processAdd(cmd);\n            break;\n          }\n          case UpdateLog.DELETE:\n          {\n            byte[] idBytes = (byte[]) entry.get(2);\n            DeleteUpdateCommand cmd = new DeleteUpdateCommand(req);\n            cmd.setIndexedId(new BytesRef(idBytes));\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            proc.processDelete(cmd);\n            break;\n          }\n\n          case UpdateLog.DELETE_BY_QUERY:\n          {\n            String query = (String)entry.get(2);\n            DeleteUpdateCommand cmd = new DeleteUpdateCommand(req);\n            cmd.query = query;\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            proc.processDelete(cmd);\n            break;\n          }\n\n          default:\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n        }\n\n      }\n\n    }\n    catch (IOException e) {\n      // TODO: should this be handled separately as a problem with us?\n      // I guess it probably already will by causing replication to be kicked off.\n      sreq.updateException = e;\n      log.error(\"Error applying updates from \" + sreq.shards + \" ,update=\" + o, e);\n      return false;\n    }\n    catch (Exception e) {\n      sreq.updateException = e;\n      log.error(\"Error applying updates from \" + sreq.shards + \" ,update=\" + o, e);\n      return false;\n    }\n    finally {\n      try {\n        proc.finish();\n      } catch (Exception e) {\n        sreq.updateException = e;\n        log.error(\"Error applying updates from \" + sreq.shards + \" ,finish()\", e);\n        return false;\n      }\n    }\n\n    return true;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["e511b092029d56e0d4e30204fba8509c1c2647b6","0e05f2a24d572cfb09482deb87b03100ce3af1a7","e99829242bceda4cf974ec0eb5d82d713615b3da"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"a3c68e20c73359a10cf3eb4a35c9fa7ab1f3c30d","date":1327523564,"type":0,"author":"Robert Muir","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/update/PeerSync#handleUpdates(ShardResponse).mjava","pathOld":"/dev/null","sourceNew":"  private boolean handleUpdates(ShardResponse srsp) {\n    // we retrieved the last N updates from the replica\n    List<Object> updates = (List<Object>)srsp.getSolrResponse().getResponse().get(\"updates\");\n\n    SyncShardRequest sreq = (SyncShardRequest) srsp.getShardRequest();\n    if (updates.size() < sreq.requestedUpdates.size()) {\n      log.error(\"PeerSync: Requested \" + sreq.requestedUpdates.size() + \" updates from \" + sreq.shards[0] + \" but retrieved \" + updates.size());\n      return false;\n    }\n\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(DistributedUpdateProcessor.SEEN_LEADER, true);\n    SolrQueryRequest req = new LocalSolrQueryRequest(uhandler.core, params);\n    SolrQueryResponse rsp = new SolrQueryResponse();\n\n    RunUpdateProcessorFactory runFac = new RunUpdateProcessorFactory();\n    DistributedUpdateProcessorFactory magicFac = new DistributedUpdateProcessorFactory();\n    runFac.init(new NamedList());\n    magicFac.init(new NamedList());\n\n    UpdateRequestProcessor proc = magicFac.getInstance(req, rsp, runFac.getInstance(req, rsp, null));\n\n    Collections.sort(updates, updateRecordComparator);\n\n    Object o = null;\n    long lastVersion = 0;\n    try {\n      // Apply oldest updates first\n      for (Object obj : updates) {\n        // should currently be a List<Oper,Ver,Doc/Id>\n        o = obj;\n        List<Object> entry = (List<Object>)o;\n\n        int oper = (Integer)entry.get(0);\n        long version = (Long) entry.get(1);\n        if (version == lastVersion && version != 0) continue;\n        lastVersion = version;\n\n        switch (oper) {\n          case UpdateLog.ADD:\n          {\n            // byte[] idBytes = (byte[]) entry.get(2);\n            SolrInputDocument sdoc = (SolrInputDocument)entry.get(entry.size()-1);\n            AddUpdateCommand cmd = new AddUpdateCommand(req);\n            // cmd.setIndexedId(new BytesRef(idBytes));\n            cmd.solrDoc = sdoc;\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            proc.processAdd(cmd);\n            break;\n          }\n          case UpdateLog.DELETE:\n          {\n            byte[] idBytes = (byte[]) entry.get(2);\n            DeleteUpdateCommand cmd = new DeleteUpdateCommand(req);\n            cmd.setIndexedId(new BytesRef(idBytes));\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            proc.processDelete(cmd);\n            break;\n          }\n\n          case UpdateLog.DELETE_BY_QUERY:\n          {\n            String query = (String)entry.get(2);\n            DeleteUpdateCommand cmd = new DeleteUpdateCommand(req);\n            cmd.query = query;\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            proc.processDelete(cmd);\n            break;\n          }\n\n          default:\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n        }\n\n      }\n\n    }\n    catch (IOException e) {\n      // TODO: should this be handled separately as a problem with us?\n      // I guess it probably already will by causing replication to be kicked off.\n      sreq.updateException = e;\n      log.error(\"Error applying updates from \" + sreq.shards + \" ,update=\" + o, e);\n      return false;\n    }\n    catch (Exception e) {\n      sreq.updateException = e;\n      log.error(\"Error applying updates from \" + sreq.shards + \" ,update=\" + o, e);\n      return false;\n    }\n    finally {\n      try {\n        proc.finish();\n      } catch (Exception e) {\n        sreq.updateException = e;\n        log.error(\"Error applying updates from \" + sreq.shards + \" ,finish()\", e);\n        return false;\n      }\n    }\n\n    return true;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0d22ac6a4146774c1bc8400160fc0b6150294e92","date":1327528604,"type":0,"author":"Uwe Schindler","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/update/PeerSync#handleUpdates(ShardResponse).mjava","pathOld":"/dev/null","sourceNew":"  private boolean handleUpdates(ShardResponse srsp) {\n    // we retrieved the last N updates from the replica\n    List<Object> updates = (List<Object>)srsp.getSolrResponse().getResponse().get(\"updates\");\n\n    SyncShardRequest sreq = (SyncShardRequest) srsp.getShardRequest();\n    if (updates.size() < sreq.requestedUpdates.size()) {\n      log.error(\"PeerSync: Requested \" + sreq.requestedUpdates.size() + \" updates from \" + sreq.shards[0] + \" but retrieved \" + updates.size());\n      return false;\n    }\n\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(DistributedUpdateProcessor.SEEN_LEADER, true);\n    SolrQueryRequest req = new LocalSolrQueryRequest(uhandler.core, params);\n    SolrQueryResponse rsp = new SolrQueryResponse();\n\n    RunUpdateProcessorFactory runFac = new RunUpdateProcessorFactory();\n    DistributedUpdateProcessorFactory magicFac = new DistributedUpdateProcessorFactory();\n    runFac.init(new NamedList());\n    magicFac.init(new NamedList());\n\n    UpdateRequestProcessor proc = magicFac.getInstance(req, rsp, runFac.getInstance(req, rsp, null));\n\n    Collections.sort(updates, updateRecordComparator);\n\n    Object o = null;\n    long lastVersion = 0;\n    try {\n      // Apply oldest updates first\n      for (Object obj : updates) {\n        // should currently be a List<Oper,Ver,Doc/Id>\n        o = obj;\n        List<Object> entry = (List<Object>)o;\n\n        int oper = (Integer)entry.get(0);\n        long version = (Long) entry.get(1);\n        if (version == lastVersion && version != 0) continue;\n        lastVersion = version;\n\n        switch (oper) {\n          case UpdateLog.ADD:\n          {\n            // byte[] idBytes = (byte[]) entry.get(2);\n            SolrInputDocument sdoc = (SolrInputDocument)entry.get(entry.size()-1);\n            AddUpdateCommand cmd = new AddUpdateCommand(req);\n            // cmd.setIndexedId(new BytesRef(idBytes));\n            cmd.solrDoc = sdoc;\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            proc.processAdd(cmd);\n            break;\n          }\n          case UpdateLog.DELETE:\n          {\n            byte[] idBytes = (byte[]) entry.get(2);\n            DeleteUpdateCommand cmd = new DeleteUpdateCommand(req);\n            cmd.setIndexedId(new BytesRef(idBytes));\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            proc.processDelete(cmd);\n            break;\n          }\n\n          case UpdateLog.DELETE_BY_QUERY:\n          {\n            String query = (String)entry.get(2);\n            DeleteUpdateCommand cmd = new DeleteUpdateCommand(req);\n            cmd.query = query;\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            proc.processDelete(cmd);\n            break;\n          }\n\n          default:\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n        }\n\n      }\n\n    }\n    catch (IOException e) {\n      // TODO: should this be handled separately as a problem with us?\n      // I guess it probably already will by causing replication to be kicked off.\n      sreq.updateException = e;\n      log.error(\"Error applying updates from \" + sreq.shards + \" ,update=\" + o, e);\n      return false;\n    }\n    catch (Exception e) {\n      sreq.updateException = e;\n      log.error(\"Error applying updates from \" + sreq.shards + \" ,update=\" + o, e);\n      return false;\n    }\n    finally {\n      try {\n        proc.finish();\n      } catch (Exception e) {\n        sreq.updateException = e;\n        log.error(\"Error applying updates from \" + sreq.shards + \" ,finish()\", e);\n        return false;\n      }\n    }\n\n    return true;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5620d3cb34306ea5b7d016a832fbc964b74c2650","date":1329755478,"type":3,"author":"Yonik Seeley","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/update/PeerSync#handleUpdates(ShardResponse).mjava","pathOld":"solr/core/src/java/org/apache/solr/update/PeerSync#handleUpdates(ShardResponse).mjava","sourceNew":"  private boolean handleUpdates(ShardResponse srsp) {\n    // we retrieved the last N updates from the replica\n    List<Object> updates = (List<Object>)srsp.getSolrResponse().getResponse().get(\"updates\");\n\n    SyncShardRequest sreq = (SyncShardRequest) srsp.getShardRequest();\n    if (updates.size() < sreq.requestedUpdates.size()) {\n      log.error(msg() + \" Requested \" + sreq.requestedUpdates.size() + \" updates from \" + sreq.shards[0] + \" but retrieved \" + updates.size());\n      return false;\n    }\n\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(DistributedUpdateProcessor.SEEN_LEADER, true);\n    SolrQueryRequest req = new LocalSolrQueryRequest(uhandler.core, params);\n    SolrQueryResponse rsp = new SolrQueryResponse();\n\n    RunUpdateProcessorFactory runFac = new RunUpdateProcessorFactory();\n    DistributedUpdateProcessorFactory magicFac = new DistributedUpdateProcessorFactory();\n    runFac.init(new NamedList());\n    magicFac.init(new NamedList());\n\n    UpdateRequestProcessor proc = magicFac.getInstance(req, rsp, runFac.getInstance(req, rsp, null));\n\n    Collections.sort(updates, updateRecordComparator);\n\n    Object o = null;\n    long lastVersion = 0;\n    try {\n      // Apply oldest updates first\n      for (Object obj : updates) {\n        // should currently be a List<Oper,Ver,Doc/Id>\n        o = obj;\n        List<Object> entry = (List<Object>)o;\n\n        if (debug) {\n          log.debug(msg() + \"raw update record \" + o);\n        }\n        \n        int oper = (Integer)entry.get(0);\n        long version = (Long) entry.get(1);\n        if (version == lastVersion && version != 0) continue;\n        lastVersion = version;\n\n        switch (oper) {\n          case UpdateLog.ADD:\n          {\n            // byte[] idBytes = (byte[]) entry.get(2);\n            SolrInputDocument sdoc = (SolrInputDocument)entry.get(entry.size()-1);\n            AddUpdateCommand cmd = new AddUpdateCommand(req);\n            // cmd.setIndexedId(new BytesRef(idBytes));\n            cmd.solrDoc = sdoc;\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"add \" + cmd);\n            }\n            proc.processAdd(cmd);\n            break;\n          }\n          case UpdateLog.DELETE:\n          {\n            byte[] idBytes = (byte[]) entry.get(2);\n            DeleteUpdateCommand cmd = new DeleteUpdateCommand(req);\n            cmd.setIndexedId(new BytesRef(idBytes));\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"delete \" + cmd);\n            }\n            proc.processDelete(cmd);\n            break;\n          }\n\n          case UpdateLog.DELETE_BY_QUERY:\n          {\n            String query = (String)entry.get(2);\n            DeleteUpdateCommand cmd = new DeleteUpdateCommand(req);\n            cmd.query = query;\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"deleteByQuery \" + cmd);\n            }\n            proc.processDelete(cmd);\n            break;\n          }\n\n          default:\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n        }\n\n      }\n\n    }\n    catch (IOException e) {\n      // TODO: should this be handled separately as a problem with us?\n      // I guess it probably already will by causing replication to be kicked off.\n      sreq.updateException = e;\n      log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,update=\" + o, e);\n      return false;\n    }\n    catch (Exception e) {\n      sreq.updateException = e;\n      log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,update=\" + o, e);\n      return false;\n    }\n    finally {\n      try {\n        proc.finish();\n      } catch (Exception e) {\n        sreq.updateException = e;\n        log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,finish()\", e);\n        return false;\n      }\n    }\n\n    return true;\n  }\n\n","sourceOld":"  private boolean handleUpdates(ShardResponse srsp) {\n    // we retrieved the last N updates from the replica\n    List<Object> updates = (List<Object>)srsp.getSolrResponse().getResponse().get(\"updates\");\n\n    SyncShardRequest sreq = (SyncShardRequest) srsp.getShardRequest();\n    if (updates.size() < sreq.requestedUpdates.size()) {\n      log.error(\"PeerSync: Requested \" + sreq.requestedUpdates.size() + \" updates from \" + sreq.shards[0] + \" but retrieved \" + updates.size());\n      return false;\n    }\n\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(DistributedUpdateProcessor.SEEN_LEADER, true);\n    SolrQueryRequest req = new LocalSolrQueryRequest(uhandler.core, params);\n    SolrQueryResponse rsp = new SolrQueryResponse();\n\n    RunUpdateProcessorFactory runFac = new RunUpdateProcessorFactory();\n    DistributedUpdateProcessorFactory magicFac = new DistributedUpdateProcessorFactory();\n    runFac.init(new NamedList());\n    magicFac.init(new NamedList());\n\n    UpdateRequestProcessor proc = magicFac.getInstance(req, rsp, runFac.getInstance(req, rsp, null));\n\n    Collections.sort(updates, updateRecordComparator);\n\n    Object o = null;\n    long lastVersion = 0;\n    try {\n      // Apply oldest updates first\n      for (Object obj : updates) {\n        // should currently be a List<Oper,Ver,Doc/Id>\n        o = obj;\n        List<Object> entry = (List<Object>)o;\n\n        int oper = (Integer)entry.get(0);\n        long version = (Long) entry.get(1);\n        if (version == lastVersion && version != 0) continue;\n        lastVersion = version;\n\n        switch (oper) {\n          case UpdateLog.ADD:\n          {\n            // byte[] idBytes = (byte[]) entry.get(2);\n            SolrInputDocument sdoc = (SolrInputDocument)entry.get(entry.size()-1);\n            AddUpdateCommand cmd = new AddUpdateCommand(req);\n            // cmd.setIndexedId(new BytesRef(idBytes));\n            cmd.solrDoc = sdoc;\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            proc.processAdd(cmd);\n            break;\n          }\n          case UpdateLog.DELETE:\n          {\n            byte[] idBytes = (byte[]) entry.get(2);\n            DeleteUpdateCommand cmd = new DeleteUpdateCommand(req);\n            cmd.setIndexedId(new BytesRef(idBytes));\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            proc.processDelete(cmd);\n            break;\n          }\n\n          case UpdateLog.DELETE_BY_QUERY:\n          {\n            String query = (String)entry.get(2);\n            DeleteUpdateCommand cmd = new DeleteUpdateCommand(req);\n            cmd.query = query;\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            proc.processDelete(cmd);\n            break;\n          }\n\n          default:\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n        }\n\n      }\n\n    }\n    catch (IOException e) {\n      // TODO: should this be handled separately as a problem with us?\n      // I guess it probably already will by causing replication to be kicked off.\n      sreq.updateException = e;\n      log.error(\"Error applying updates from \" + sreq.shards + \" ,update=\" + o, e);\n      return false;\n    }\n    catch (Exception e) {\n      sreq.updateException = e;\n      log.error(\"Error applying updates from \" + sreq.shards + \" ,update=\" + o, e);\n      return false;\n    }\n    finally {\n      try {\n        proc.finish();\n      } catch (Exception e) {\n        sreq.updateException = e;\n        log.error(\"Error applying updates from \" + sreq.shards + \" ,finish()\", e);\n        return false;\n      }\n    }\n\n    return true;\n  }\n\n","bugFix":null,"bugIntro":["6c94d2661bc1c14426980ec7882e951fdcff08d0","e99829242bceda4cf974ec0eb5d82d713615b3da"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"f8f7907798e0c730e9ab37681c6e8dfbde0e4173","date":1330361299,"type":3,"author":"Yonik Seeley","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/update/PeerSync#handleUpdates(ShardResponse).mjava","pathOld":"solr/core/src/java/org/apache/solr/update/PeerSync#handleUpdates(ShardResponse).mjava","sourceNew":"  private boolean handleUpdates(ShardResponse srsp) {\n    // we retrieved the last N updates from the replica\n    List<Object> updates = (List<Object>)srsp.getSolrResponse().getResponse().get(\"updates\");\n\n    SyncShardRequest sreq = (SyncShardRequest) srsp.getShardRequest();\n    if (updates.size() < sreq.requestedUpdates.size()) {\n      log.error(msg() + \" Requested \" + sreq.requestedUpdates.size() + \" updates from \" + sreq.shards[0] + \" but retrieved \" + updates.size());\n      return false;\n    }\n\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(DistributedUpdateProcessor.SEEN_LEADER, true);\nparams.set(\"peersync\",true); // nocommit\n    SolrQueryRequest req = new LocalSolrQueryRequest(uhandler.core, params);\n    SolrQueryResponse rsp = new SolrQueryResponse();\n\n    RunUpdateProcessorFactory runFac = new RunUpdateProcessorFactory();\n    DistributedUpdateProcessorFactory magicFac = new DistributedUpdateProcessorFactory();\n    runFac.init(new NamedList());\n    magicFac.init(new NamedList());\n\n    UpdateRequestProcessor proc = magicFac.getInstance(req, rsp, runFac.getInstance(req, rsp, null));\n\n    Collections.sort(updates, updateRecordComparator);\n\n    Object o = null;\n    long lastVersion = 0;\n    try {\n      // Apply oldest updates first\n      for (Object obj : updates) {\n        // should currently be a List<Oper,Ver,Doc/Id>\n        o = obj;\n        List<Object> entry = (List<Object>)o;\n\n        if (debug) {\n          log.debug(msg() + \"raw update record \" + o);\n        }\n        \n        int oper = (Integer)entry.get(0);\n        long version = (Long) entry.get(1);\n        if (version == lastVersion && version != 0) continue;\n        lastVersion = version;\n\n        switch (oper) {\n          case UpdateLog.ADD:\n          {\n            // byte[] idBytes = (byte[]) entry.get(2);\n            SolrInputDocument sdoc = (SolrInputDocument)entry.get(entry.size()-1);\n            AddUpdateCommand cmd = new AddUpdateCommand(req);\n            // cmd.setIndexedId(new BytesRef(idBytes));\n            cmd.solrDoc = sdoc;\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"add \" + cmd);\n            }\n            proc.processAdd(cmd);\n            break;\n          }\n          case UpdateLog.DELETE:\n          {\n            byte[] idBytes = (byte[]) entry.get(2);\n            DeleteUpdateCommand cmd = new DeleteUpdateCommand(req);\n            cmd.setIndexedId(new BytesRef(idBytes));\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"delete \" + cmd);\n            }\n            proc.processDelete(cmd);\n            break;\n          }\n\n          case UpdateLog.DELETE_BY_QUERY:\n          {\n            String query = (String)entry.get(2);\n            DeleteUpdateCommand cmd = new DeleteUpdateCommand(req);\n            cmd.query = query;\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"deleteByQuery \" + cmd);\n            }\n            proc.processDelete(cmd);\n            break;\n          }\n\n          default:\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n        }\n\n      }\n\n    }\n    catch (IOException e) {\n      // TODO: should this be handled separately as a problem with us?\n      // I guess it probably already will by causing replication to be kicked off.\n      sreq.updateException = e;\n      log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,update=\" + o, e);\n      return false;\n    }\n    catch (Exception e) {\n      sreq.updateException = e;\n      log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,update=\" + o, e);\n      return false;\n    }\n    finally {\n      try {\n        proc.finish();\n      } catch (Exception e) {\n        sreq.updateException = e;\n        log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,finish()\", e);\n        return false;\n      }\n    }\n\n    return true;\n  }\n\n","sourceOld":"  private boolean handleUpdates(ShardResponse srsp) {\n    // we retrieved the last N updates from the replica\n    List<Object> updates = (List<Object>)srsp.getSolrResponse().getResponse().get(\"updates\");\n\n    SyncShardRequest sreq = (SyncShardRequest) srsp.getShardRequest();\n    if (updates.size() < sreq.requestedUpdates.size()) {\n      log.error(msg() + \" Requested \" + sreq.requestedUpdates.size() + \" updates from \" + sreq.shards[0] + \" but retrieved \" + updates.size());\n      return false;\n    }\n\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(DistributedUpdateProcessor.SEEN_LEADER, true);\n    SolrQueryRequest req = new LocalSolrQueryRequest(uhandler.core, params);\n    SolrQueryResponse rsp = new SolrQueryResponse();\n\n    RunUpdateProcessorFactory runFac = new RunUpdateProcessorFactory();\n    DistributedUpdateProcessorFactory magicFac = new DistributedUpdateProcessorFactory();\n    runFac.init(new NamedList());\n    magicFac.init(new NamedList());\n\n    UpdateRequestProcessor proc = magicFac.getInstance(req, rsp, runFac.getInstance(req, rsp, null));\n\n    Collections.sort(updates, updateRecordComparator);\n\n    Object o = null;\n    long lastVersion = 0;\n    try {\n      // Apply oldest updates first\n      for (Object obj : updates) {\n        // should currently be a List<Oper,Ver,Doc/Id>\n        o = obj;\n        List<Object> entry = (List<Object>)o;\n\n        if (debug) {\n          log.debug(msg() + \"raw update record \" + o);\n        }\n        \n        int oper = (Integer)entry.get(0);\n        long version = (Long) entry.get(1);\n        if (version == lastVersion && version != 0) continue;\n        lastVersion = version;\n\n        switch (oper) {\n          case UpdateLog.ADD:\n          {\n            // byte[] idBytes = (byte[]) entry.get(2);\n            SolrInputDocument sdoc = (SolrInputDocument)entry.get(entry.size()-1);\n            AddUpdateCommand cmd = new AddUpdateCommand(req);\n            // cmd.setIndexedId(new BytesRef(idBytes));\n            cmd.solrDoc = sdoc;\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"add \" + cmd);\n            }\n            proc.processAdd(cmd);\n            break;\n          }\n          case UpdateLog.DELETE:\n          {\n            byte[] idBytes = (byte[]) entry.get(2);\n            DeleteUpdateCommand cmd = new DeleteUpdateCommand(req);\n            cmd.setIndexedId(new BytesRef(idBytes));\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"delete \" + cmd);\n            }\n            proc.processDelete(cmd);\n            break;\n          }\n\n          case UpdateLog.DELETE_BY_QUERY:\n          {\n            String query = (String)entry.get(2);\n            DeleteUpdateCommand cmd = new DeleteUpdateCommand(req);\n            cmd.query = query;\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"deleteByQuery \" + cmd);\n            }\n            proc.processDelete(cmd);\n            break;\n          }\n\n          default:\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n        }\n\n      }\n\n    }\n    catch (IOException e) {\n      // TODO: should this be handled separately as a problem with us?\n      // I guess it probably already will by causing replication to be kicked off.\n      sreq.updateException = e;\n      log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,update=\" + o, e);\n      return false;\n    }\n    catch (Exception e) {\n      sreq.updateException = e;\n      log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,update=\" + o, e);\n      return false;\n    }\n    finally {\n      try {\n        proc.finish();\n      } catch (Exception e) {\n        sreq.updateException = e;\n        log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,finish()\", e);\n        return false;\n      }\n    }\n\n    return true;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"3060d5648a525a745f0ac45420e84bf5c7e9b135","date":1330363977,"type":3,"author":"Yonik Seeley","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/update/PeerSync#handleUpdates(ShardResponse).mjava","pathOld":"solr/core/src/java/org/apache/solr/update/PeerSync#handleUpdates(ShardResponse).mjava","sourceNew":"  private boolean handleUpdates(ShardResponse srsp) {\n    // we retrieved the last N updates from the replica\n    List<Object> updates = (List<Object>)srsp.getSolrResponse().getResponse().get(\"updates\");\n\n    SyncShardRequest sreq = (SyncShardRequest) srsp.getShardRequest();\n    if (updates.size() < sreq.requestedUpdates.size()) {\n      log.error(msg() + \" Requested \" + sreq.requestedUpdates.size() + \" updates from \" + sreq.shards[0] + \" but retrieved \" + updates.size());\n      return false;\n    }\n\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(DistributedUpdateProcessor.SEEN_LEADER, true);\n    // params.set(\"peersync\",true); // debugging\n    SolrQueryRequest req = new LocalSolrQueryRequest(uhandler.core, params);\n    SolrQueryResponse rsp = new SolrQueryResponse();\n\n    RunUpdateProcessorFactory runFac = new RunUpdateProcessorFactory();\n    DistributedUpdateProcessorFactory magicFac = new DistributedUpdateProcessorFactory();\n    runFac.init(new NamedList());\n    magicFac.init(new NamedList());\n\n    UpdateRequestProcessor proc = magicFac.getInstance(req, rsp, runFac.getInstance(req, rsp, null));\n\n    Collections.sort(updates, updateRecordComparator);\n\n    Object o = null;\n    long lastVersion = 0;\n    try {\n      // Apply oldest updates first\n      for (Object obj : updates) {\n        // should currently be a List<Oper,Ver,Doc/Id>\n        o = obj;\n        List<Object> entry = (List<Object>)o;\n\n        if (debug) {\n          log.debug(msg() + \"raw update record \" + o);\n        }\n        \n        int oper = (Integer)entry.get(0);\n        long version = (Long) entry.get(1);\n        if (version == lastVersion && version != 0) continue;\n        lastVersion = version;\n\n        switch (oper) {\n          case UpdateLog.ADD:\n          {\n            // byte[] idBytes = (byte[]) entry.get(2);\n            SolrInputDocument sdoc = (SolrInputDocument)entry.get(entry.size()-1);\n            AddUpdateCommand cmd = new AddUpdateCommand(req);\n            // cmd.setIndexedId(new BytesRef(idBytes));\n            cmd.solrDoc = sdoc;\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"add \" + cmd);\n            }\n            proc.processAdd(cmd);\n            break;\n          }\n          case UpdateLog.DELETE:\n          {\n            byte[] idBytes = (byte[]) entry.get(2);\n            DeleteUpdateCommand cmd = new DeleteUpdateCommand(req);\n            cmd.setIndexedId(new BytesRef(idBytes));\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"delete \" + cmd);\n            }\n            proc.processDelete(cmd);\n            break;\n          }\n\n          case UpdateLog.DELETE_BY_QUERY:\n          {\n            String query = (String)entry.get(2);\n            DeleteUpdateCommand cmd = new DeleteUpdateCommand(req);\n            cmd.query = query;\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"deleteByQuery \" + cmd);\n            }\n            proc.processDelete(cmd);\n            break;\n          }\n\n          default:\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n        }\n\n      }\n\n    }\n    catch (IOException e) {\n      // TODO: should this be handled separately as a problem with us?\n      // I guess it probably already will by causing replication to be kicked off.\n      sreq.updateException = e;\n      log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,update=\" + o, e);\n      return false;\n    }\n    catch (Exception e) {\n      sreq.updateException = e;\n      log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,update=\" + o, e);\n      return false;\n    }\n    finally {\n      try {\n        proc.finish();\n      } catch (Exception e) {\n        sreq.updateException = e;\n        log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,finish()\", e);\n        return false;\n      }\n    }\n\n    return true;\n  }\n\n","sourceOld":"  private boolean handleUpdates(ShardResponse srsp) {\n    // we retrieved the last N updates from the replica\n    List<Object> updates = (List<Object>)srsp.getSolrResponse().getResponse().get(\"updates\");\n\n    SyncShardRequest sreq = (SyncShardRequest) srsp.getShardRequest();\n    if (updates.size() < sreq.requestedUpdates.size()) {\n      log.error(msg() + \" Requested \" + sreq.requestedUpdates.size() + \" updates from \" + sreq.shards[0] + \" but retrieved \" + updates.size());\n      return false;\n    }\n\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(DistributedUpdateProcessor.SEEN_LEADER, true);\nparams.set(\"peersync\",true); // nocommit\n    SolrQueryRequest req = new LocalSolrQueryRequest(uhandler.core, params);\n    SolrQueryResponse rsp = new SolrQueryResponse();\n\n    RunUpdateProcessorFactory runFac = new RunUpdateProcessorFactory();\n    DistributedUpdateProcessorFactory magicFac = new DistributedUpdateProcessorFactory();\n    runFac.init(new NamedList());\n    magicFac.init(new NamedList());\n\n    UpdateRequestProcessor proc = magicFac.getInstance(req, rsp, runFac.getInstance(req, rsp, null));\n\n    Collections.sort(updates, updateRecordComparator);\n\n    Object o = null;\n    long lastVersion = 0;\n    try {\n      // Apply oldest updates first\n      for (Object obj : updates) {\n        // should currently be a List<Oper,Ver,Doc/Id>\n        o = obj;\n        List<Object> entry = (List<Object>)o;\n\n        if (debug) {\n          log.debug(msg() + \"raw update record \" + o);\n        }\n        \n        int oper = (Integer)entry.get(0);\n        long version = (Long) entry.get(1);\n        if (version == lastVersion && version != 0) continue;\n        lastVersion = version;\n\n        switch (oper) {\n          case UpdateLog.ADD:\n          {\n            // byte[] idBytes = (byte[]) entry.get(2);\n            SolrInputDocument sdoc = (SolrInputDocument)entry.get(entry.size()-1);\n            AddUpdateCommand cmd = new AddUpdateCommand(req);\n            // cmd.setIndexedId(new BytesRef(idBytes));\n            cmd.solrDoc = sdoc;\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"add \" + cmd);\n            }\n            proc.processAdd(cmd);\n            break;\n          }\n          case UpdateLog.DELETE:\n          {\n            byte[] idBytes = (byte[]) entry.get(2);\n            DeleteUpdateCommand cmd = new DeleteUpdateCommand(req);\n            cmd.setIndexedId(new BytesRef(idBytes));\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"delete \" + cmd);\n            }\n            proc.processDelete(cmd);\n            break;\n          }\n\n          case UpdateLog.DELETE_BY_QUERY:\n          {\n            String query = (String)entry.get(2);\n            DeleteUpdateCommand cmd = new DeleteUpdateCommand(req);\n            cmd.query = query;\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"deleteByQuery \" + cmd);\n            }\n            proc.processDelete(cmd);\n            break;\n          }\n\n          default:\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n        }\n\n      }\n\n    }\n    catch (IOException e) {\n      // TODO: should this be handled separately as a problem with us?\n      // I guess it probably already will by causing replication to be kicked off.\n      sreq.updateException = e;\n      log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,update=\" + o, e);\n      return false;\n    }\n    catch (Exception e) {\n      sreq.updateException = e;\n      log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,update=\" + o, e);\n      return false;\n    }\n    finally {\n      try {\n        proc.finish();\n      } catch (Exception e) {\n        sreq.updateException = e;\n        log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,finish()\", e);\n        return false;\n      }\n    }\n\n    return true;\n  }\n\n","bugFix":null,"bugIntro":["3d7c0c8a97beb56d2e168604f9928de17981eabe"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab","date":1331075828,"type":3,"author":"Ryan McKinley","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/update/PeerSync#handleUpdates(ShardResponse).mjava","pathOld":"solr/core/src/java/org/apache/solr/update/PeerSync#handleUpdates(ShardResponse).mjava","sourceNew":"  private boolean handleUpdates(ShardResponse srsp) {\n    // we retrieved the last N updates from the replica\n    List<Object> updates = (List<Object>)srsp.getSolrResponse().getResponse().get(\"updates\");\n\n    SyncShardRequest sreq = (SyncShardRequest) srsp.getShardRequest();\n    if (updates.size() < sreq.requestedUpdates.size()) {\n      log.error(msg() + \" Requested \" + sreq.requestedUpdates.size() + \" updates from \" + sreq.shards[0] + \" but retrieved \" + updates.size());\n      return false;\n    }\n\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(DistributedUpdateProcessor.SEEN_LEADER, true);\n    // params.set(\"peersync\",true); // debugging\n    SolrQueryRequest req = new LocalSolrQueryRequest(uhandler.core, params);\n    SolrQueryResponse rsp = new SolrQueryResponse();\n\n    RunUpdateProcessorFactory runFac = new RunUpdateProcessorFactory();\n    DistributedUpdateProcessorFactory magicFac = new DistributedUpdateProcessorFactory();\n    runFac.init(new NamedList());\n    magicFac.init(new NamedList());\n\n    UpdateRequestProcessor proc = magicFac.getInstance(req, rsp, runFac.getInstance(req, rsp, null));\n\n    Collections.sort(updates, updateRecordComparator);\n\n    Object o = null;\n    long lastVersion = 0;\n    try {\n      // Apply oldest updates first\n      for (Object obj : updates) {\n        // should currently be a List<Oper,Ver,Doc/Id>\n        o = obj;\n        List<Object> entry = (List<Object>)o;\n\n        if (debug) {\n          log.debug(msg() + \"raw update record \" + o);\n        }\n        \n        int oper = (Integer)entry.get(0);\n        long version = (Long) entry.get(1);\n        if (version == lastVersion && version != 0) continue;\n        lastVersion = version;\n\n        switch (oper) {\n          case UpdateLog.ADD:\n          {\n            // byte[] idBytes = (byte[]) entry.get(2);\n            SolrInputDocument sdoc = (SolrInputDocument)entry.get(entry.size()-1);\n            AddUpdateCommand cmd = new AddUpdateCommand(req);\n            // cmd.setIndexedId(new BytesRef(idBytes));\n            cmd.solrDoc = sdoc;\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"add \" + cmd);\n            }\n            proc.processAdd(cmd);\n            break;\n          }\n          case UpdateLog.DELETE:\n          {\n            byte[] idBytes = (byte[]) entry.get(2);\n            DeleteUpdateCommand cmd = new DeleteUpdateCommand(req);\n            cmd.setIndexedId(new BytesRef(idBytes));\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"delete \" + cmd);\n            }\n            proc.processDelete(cmd);\n            break;\n          }\n\n          case UpdateLog.DELETE_BY_QUERY:\n          {\n            String query = (String)entry.get(2);\n            DeleteUpdateCommand cmd = new DeleteUpdateCommand(req);\n            cmd.query = query;\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"deleteByQuery \" + cmd);\n            }\n            proc.processDelete(cmd);\n            break;\n          }\n\n          default:\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n        }\n\n      }\n\n    }\n    catch (IOException e) {\n      // TODO: should this be handled separately as a problem with us?\n      // I guess it probably already will by causing replication to be kicked off.\n      sreq.updateException = e;\n      log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,update=\" + o, e);\n      return false;\n    }\n    catch (Exception e) {\n      sreq.updateException = e;\n      log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,update=\" + o, e);\n      return false;\n    }\n    finally {\n      try {\n        proc.finish();\n      } catch (Exception e) {\n        sreq.updateException = e;\n        log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,finish()\", e);\n        return false;\n      }\n    }\n\n    return true;\n  }\n\n","sourceOld":"  private boolean handleUpdates(ShardResponse srsp) {\n    // we retrieved the last N updates from the replica\n    List<Object> updates = (List<Object>)srsp.getSolrResponse().getResponse().get(\"updates\");\n\n    SyncShardRequest sreq = (SyncShardRequest) srsp.getShardRequest();\n    if (updates.size() < sreq.requestedUpdates.size()) {\n      log.error(msg() + \" Requested \" + sreq.requestedUpdates.size() + \" updates from \" + sreq.shards[0] + \" but retrieved \" + updates.size());\n      return false;\n    }\n\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(DistributedUpdateProcessor.SEEN_LEADER, true);\n    SolrQueryRequest req = new LocalSolrQueryRequest(uhandler.core, params);\n    SolrQueryResponse rsp = new SolrQueryResponse();\n\n    RunUpdateProcessorFactory runFac = new RunUpdateProcessorFactory();\n    DistributedUpdateProcessorFactory magicFac = new DistributedUpdateProcessorFactory();\n    runFac.init(new NamedList());\n    magicFac.init(new NamedList());\n\n    UpdateRequestProcessor proc = magicFac.getInstance(req, rsp, runFac.getInstance(req, rsp, null));\n\n    Collections.sort(updates, updateRecordComparator);\n\n    Object o = null;\n    long lastVersion = 0;\n    try {\n      // Apply oldest updates first\n      for (Object obj : updates) {\n        // should currently be a List<Oper,Ver,Doc/Id>\n        o = obj;\n        List<Object> entry = (List<Object>)o;\n\n        if (debug) {\n          log.debug(msg() + \"raw update record \" + o);\n        }\n        \n        int oper = (Integer)entry.get(0);\n        long version = (Long) entry.get(1);\n        if (version == lastVersion && version != 0) continue;\n        lastVersion = version;\n\n        switch (oper) {\n          case UpdateLog.ADD:\n          {\n            // byte[] idBytes = (byte[]) entry.get(2);\n            SolrInputDocument sdoc = (SolrInputDocument)entry.get(entry.size()-1);\n            AddUpdateCommand cmd = new AddUpdateCommand(req);\n            // cmd.setIndexedId(new BytesRef(idBytes));\n            cmd.solrDoc = sdoc;\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"add \" + cmd);\n            }\n            proc.processAdd(cmd);\n            break;\n          }\n          case UpdateLog.DELETE:\n          {\n            byte[] idBytes = (byte[]) entry.get(2);\n            DeleteUpdateCommand cmd = new DeleteUpdateCommand(req);\n            cmd.setIndexedId(new BytesRef(idBytes));\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"delete \" + cmd);\n            }\n            proc.processDelete(cmd);\n            break;\n          }\n\n          case UpdateLog.DELETE_BY_QUERY:\n          {\n            String query = (String)entry.get(2);\n            DeleteUpdateCommand cmd = new DeleteUpdateCommand(req);\n            cmd.query = query;\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"deleteByQuery \" + cmd);\n            }\n            proc.processDelete(cmd);\n            break;\n          }\n\n          default:\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n        }\n\n      }\n\n    }\n    catch (IOException e) {\n      // TODO: should this be handled separately as a problem with us?\n      // I guess it probably already will by causing replication to be kicked off.\n      sreq.updateException = e;\n      log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,update=\" + o, e);\n      return false;\n    }\n    catch (Exception e) {\n      sreq.updateException = e;\n      log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,update=\" + o, e);\n      return false;\n    }\n    finally {\n      try {\n        proc.finish();\n      } catch (Exception e) {\n        sreq.updateException = e;\n        log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,finish()\", e);\n        return false;\n      }\n    }\n\n    return true;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e99829242bceda4cf974ec0eb5d82d713615b3da","date":1337646971,"type":3,"author":"Yonik Seeley","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/update/PeerSync#handleUpdates(ShardResponse).mjava","pathOld":"solr/core/src/java/org/apache/solr/update/PeerSync#handleUpdates(ShardResponse).mjava","sourceNew":"  private boolean handleUpdates(ShardResponse srsp) {\n    // we retrieved the last N updates from the replica\n    List<Object> updates = (List<Object>)srsp.getSolrResponse().getResponse().get(\"updates\");\n\n    SyncShardRequest sreq = (SyncShardRequest) srsp.getShardRequest();\n    if (updates.size() < sreq.requestedUpdates.size()) {\n      log.error(msg() + \" Requested \" + sreq.requestedUpdates.size() + \" updates from \" + sreq.shards[0] + \" but retrieved \" + updates.size());\n      return false;\n    }\n\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(DistributedUpdateProcessor.SEEN_LEADER, true);\n    // params.set(\"peersync\",true); // debugging\n    SolrQueryRequest req = new LocalSolrQueryRequest(uhandler.core, params);\n    SolrQueryResponse rsp = new SolrQueryResponse();\n\n    RunUpdateProcessorFactory runFac = new RunUpdateProcessorFactory();\n    DistributedUpdateProcessorFactory magicFac = new DistributedUpdateProcessorFactory();\n    runFac.init(new NamedList());\n    magicFac.init(new NamedList());\n\n    UpdateRequestProcessor proc = magicFac.getInstance(req, rsp, runFac.getInstance(req, rsp, null));\n\n    Collections.sort(updates, updateRecordComparator);\n\n    Object o = null;\n    long lastVersion = 0;\n    try {\n      // Apply oldest updates first\n      for (Object obj : updates) {\n        // should currently be a List<Oper,Ver,Doc/Id>\n        o = obj;\n        List<Object> entry = (List<Object>)o;\n\n        if (debug) {\n          log.debug(msg() + \"raw update record \" + o);\n        }\n\n        int oper = (Integer)entry.get(0) & UpdateLog.OPERATION_MASK;\n        long version = (Long) entry.get(1);\n        if (version == lastVersion && version != 0) continue;\n        lastVersion = version;\n\n        switch (oper) {\n          case UpdateLog.ADD:\n          {\n            // byte[] idBytes = (byte[]) entry.get(2);\n            SolrInputDocument sdoc = (SolrInputDocument)entry.get(entry.size()-1);\n            AddUpdateCommand cmd = new AddUpdateCommand(req);\n            // cmd.setIndexedId(new BytesRef(idBytes));\n            cmd.solrDoc = sdoc;\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"add \" + cmd);\n            }\n            proc.processAdd(cmd);\n            break;\n          }\n          case UpdateLog.DELETE:\n          {\n            byte[] idBytes = (byte[]) entry.get(2);\n            DeleteUpdateCommand cmd = new DeleteUpdateCommand(req);\n            cmd.setIndexedId(new BytesRef(idBytes));\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"delete \" + cmd);\n            }\n            proc.processDelete(cmd);\n            break;\n          }\n\n          case UpdateLog.DELETE_BY_QUERY:\n          {\n            String query = (String)entry.get(2);\n            DeleteUpdateCommand cmd = new DeleteUpdateCommand(req);\n            cmd.query = query;\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"deleteByQuery \" + cmd);\n            }\n            proc.processDelete(cmd);\n            break;\n          }\n\n          default:\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n        }\n\n      }\n\n    }\n    catch (IOException e) {\n      // TODO: should this be handled separately as a problem with us?\n      // I guess it probably already will by causing replication to be kicked off.\n      sreq.updateException = e;\n      log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,update=\" + o, e);\n      return false;\n    }\n    catch (Exception e) {\n      sreq.updateException = e;\n      log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,update=\" + o, e);\n      return false;\n    }\n    finally {\n      try {\n        proc.finish();\n      } catch (Exception e) {\n        sreq.updateException = e;\n        log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,finish()\", e);\n        return false;\n      }\n    }\n\n    return true;\n  }\n\n","sourceOld":"  private boolean handleUpdates(ShardResponse srsp) {\n    // we retrieved the last N updates from the replica\n    List<Object> updates = (List<Object>)srsp.getSolrResponse().getResponse().get(\"updates\");\n\n    SyncShardRequest sreq = (SyncShardRequest) srsp.getShardRequest();\n    if (updates.size() < sreq.requestedUpdates.size()) {\n      log.error(msg() + \" Requested \" + sreq.requestedUpdates.size() + \" updates from \" + sreq.shards[0] + \" but retrieved \" + updates.size());\n      return false;\n    }\n\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(DistributedUpdateProcessor.SEEN_LEADER, true);\n    // params.set(\"peersync\",true); // debugging\n    SolrQueryRequest req = new LocalSolrQueryRequest(uhandler.core, params);\n    SolrQueryResponse rsp = new SolrQueryResponse();\n\n    RunUpdateProcessorFactory runFac = new RunUpdateProcessorFactory();\n    DistributedUpdateProcessorFactory magicFac = new DistributedUpdateProcessorFactory();\n    runFac.init(new NamedList());\n    magicFac.init(new NamedList());\n\n    UpdateRequestProcessor proc = magicFac.getInstance(req, rsp, runFac.getInstance(req, rsp, null));\n\n    Collections.sort(updates, updateRecordComparator);\n\n    Object o = null;\n    long lastVersion = 0;\n    try {\n      // Apply oldest updates first\n      for (Object obj : updates) {\n        // should currently be a List<Oper,Ver,Doc/Id>\n        o = obj;\n        List<Object> entry = (List<Object>)o;\n\n        if (debug) {\n          log.debug(msg() + \"raw update record \" + o);\n        }\n        \n        int oper = (Integer)entry.get(0);\n        long version = (Long) entry.get(1);\n        if (version == lastVersion && version != 0) continue;\n        lastVersion = version;\n\n        switch (oper) {\n          case UpdateLog.ADD:\n          {\n            // byte[] idBytes = (byte[]) entry.get(2);\n            SolrInputDocument sdoc = (SolrInputDocument)entry.get(entry.size()-1);\n            AddUpdateCommand cmd = new AddUpdateCommand(req);\n            // cmd.setIndexedId(new BytesRef(idBytes));\n            cmd.solrDoc = sdoc;\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"add \" + cmd);\n            }\n            proc.processAdd(cmd);\n            break;\n          }\n          case UpdateLog.DELETE:\n          {\n            byte[] idBytes = (byte[]) entry.get(2);\n            DeleteUpdateCommand cmd = new DeleteUpdateCommand(req);\n            cmd.setIndexedId(new BytesRef(idBytes));\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"delete \" + cmd);\n            }\n            proc.processDelete(cmd);\n            break;\n          }\n\n          case UpdateLog.DELETE_BY_QUERY:\n          {\n            String query = (String)entry.get(2);\n            DeleteUpdateCommand cmd = new DeleteUpdateCommand(req);\n            cmd.query = query;\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"deleteByQuery \" + cmd);\n            }\n            proc.processDelete(cmd);\n            break;\n          }\n\n          default:\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n        }\n\n      }\n\n    }\n    catch (IOException e) {\n      // TODO: should this be handled separately as a problem with us?\n      // I guess it probably already will by causing replication to be kicked off.\n      sreq.updateException = e;\n      log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,update=\" + o, e);\n      return false;\n    }\n    catch (Exception e) {\n      sreq.updateException = e;\n      log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,update=\" + o, e);\n      return false;\n    }\n    finally {\n      try {\n        proc.finish();\n      } catch (Exception e) {\n        sreq.updateException = e;\n        log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,finish()\", e);\n        return false;\n      }\n    }\n\n    return true;\n  }\n\n","bugFix":["2c007e7c4cf8c55bc2a5884e315123afaaeec87f","5620d3cb34306ea5b7d016a832fbc964b74c2650"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"3599646b4d4c346cf74d334813488b8b337b5bf5","date":1337790261,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/update/PeerSync#handleUpdates(ShardResponse).mjava","pathOld":"solr/core/src/java/org/apache/solr/update/PeerSync#handleUpdates(ShardResponse).mjava","sourceNew":"  private boolean handleUpdates(ShardResponse srsp) {\n    // we retrieved the last N updates from the replica\n    List<Object> updates = (List<Object>)srsp.getSolrResponse().getResponse().get(\"updates\");\n\n    SyncShardRequest sreq = (SyncShardRequest) srsp.getShardRequest();\n    if (updates.size() < sreq.requestedUpdates.size()) {\n      log.error(msg() + \" Requested \" + sreq.requestedUpdates.size() + \" updates from \" + sreq.shards[0] + \" but retrieved \" + updates.size());\n      return false;\n    }\n\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(DistributedUpdateProcessor.SEEN_LEADER, true);\n    // params.set(\"peersync\",true); // debugging\n    SolrQueryRequest req = new LocalSolrQueryRequest(uhandler.core, params);\n    SolrQueryResponse rsp = new SolrQueryResponse();\n\n    RunUpdateProcessorFactory runFac = new RunUpdateProcessorFactory();\n    DistributedUpdateProcessorFactory magicFac = new DistributedUpdateProcessorFactory();\n    runFac.init(new NamedList());\n    magicFac.init(new NamedList());\n\n    UpdateRequestProcessor proc = magicFac.getInstance(req, rsp, runFac.getInstance(req, rsp, null));\n\n    Collections.sort(updates, updateRecordComparator);\n\n    Object o = null;\n    long lastVersion = 0;\n    try {\n      // Apply oldest updates first\n      for (Object obj : updates) {\n        // should currently be a List<Oper,Ver,Doc/Id>\n        o = obj;\n        List<Object> entry = (List<Object>)o;\n\n        if (debug) {\n          log.debug(msg() + \"raw update record \" + o);\n        }\n\n        int oper = (Integer)entry.get(0) & UpdateLog.OPERATION_MASK;\n        long version = (Long) entry.get(1);\n        if (version == lastVersion && version != 0) continue;\n        lastVersion = version;\n\n        switch (oper) {\n          case UpdateLog.ADD:\n          {\n            // byte[] idBytes = (byte[]) entry.get(2);\n            SolrInputDocument sdoc = (SolrInputDocument)entry.get(entry.size()-1);\n            AddUpdateCommand cmd = new AddUpdateCommand(req);\n            // cmd.setIndexedId(new BytesRef(idBytes));\n            cmd.solrDoc = sdoc;\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"add \" + cmd);\n            }\n            proc.processAdd(cmd);\n            break;\n          }\n          case UpdateLog.DELETE:\n          {\n            byte[] idBytes = (byte[]) entry.get(2);\n            DeleteUpdateCommand cmd = new DeleteUpdateCommand(req);\n            cmd.setIndexedId(new BytesRef(idBytes));\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"delete \" + cmd);\n            }\n            proc.processDelete(cmd);\n            break;\n          }\n\n          case UpdateLog.DELETE_BY_QUERY:\n          {\n            String query = (String)entry.get(2);\n            DeleteUpdateCommand cmd = new DeleteUpdateCommand(req);\n            cmd.query = query;\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"deleteByQuery \" + cmd);\n            }\n            proc.processDelete(cmd);\n            break;\n          }\n\n          default:\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n        }\n\n      }\n\n    }\n    catch (IOException e) {\n      // TODO: should this be handled separately as a problem with us?\n      // I guess it probably already will by causing replication to be kicked off.\n      sreq.updateException = e;\n      log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,update=\" + o, e);\n      return false;\n    }\n    catch (Exception e) {\n      sreq.updateException = e;\n      log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,update=\" + o, e);\n      return false;\n    }\n    finally {\n      try {\n        proc.finish();\n      } catch (Exception e) {\n        sreq.updateException = e;\n        log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,finish()\", e);\n        return false;\n      }\n    }\n\n    return true;\n  }\n\n","sourceOld":"  private boolean handleUpdates(ShardResponse srsp) {\n    // we retrieved the last N updates from the replica\n    List<Object> updates = (List<Object>)srsp.getSolrResponse().getResponse().get(\"updates\");\n\n    SyncShardRequest sreq = (SyncShardRequest) srsp.getShardRequest();\n    if (updates.size() < sreq.requestedUpdates.size()) {\n      log.error(msg() + \" Requested \" + sreq.requestedUpdates.size() + \" updates from \" + sreq.shards[0] + \" but retrieved \" + updates.size());\n      return false;\n    }\n\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(DistributedUpdateProcessor.SEEN_LEADER, true);\n    // params.set(\"peersync\",true); // debugging\n    SolrQueryRequest req = new LocalSolrQueryRequest(uhandler.core, params);\n    SolrQueryResponse rsp = new SolrQueryResponse();\n\n    RunUpdateProcessorFactory runFac = new RunUpdateProcessorFactory();\n    DistributedUpdateProcessorFactory magicFac = new DistributedUpdateProcessorFactory();\n    runFac.init(new NamedList());\n    magicFac.init(new NamedList());\n\n    UpdateRequestProcessor proc = magicFac.getInstance(req, rsp, runFac.getInstance(req, rsp, null));\n\n    Collections.sort(updates, updateRecordComparator);\n\n    Object o = null;\n    long lastVersion = 0;\n    try {\n      // Apply oldest updates first\n      for (Object obj : updates) {\n        // should currently be a List<Oper,Ver,Doc/Id>\n        o = obj;\n        List<Object> entry = (List<Object>)o;\n\n        if (debug) {\n          log.debug(msg() + \"raw update record \" + o);\n        }\n        \n        int oper = (Integer)entry.get(0);\n        long version = (Long) entry.get(1);\n        if (version == lastVersion && version != 0) continue;\n        lastVersion = version;\n\n        switch (oper) {\n          case UpdateLog.ADD:\n          {\n            // byte[] idBytes = (byte[]) entry.get(2);\n            SolrInputDocument sdoc = (SolrInputDocument)entry.get(entry.size()-1);\n            AddUpdateCommand cmd = new AddUpdateCommand(req);\n            // cmd.setIndexedId(new BytesRef(idBytes));\n            cmd.solrDoc = sdoc;\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"add \" + cmd);\n            }\n            proc.processAdd(cmd);\n            break;\n          }\n          case UpdateLog.DELETE:\n          {\n            byte[] idBytes = (byte[]) entry.get(2);\n            DeleteUpdateCommand cmd = new DeleteUpdateCommand(req);\n            cmd.setIndexedId(new BytesRef(idBytes));\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"delete \" + cmd);\n            }\n            proc.processDelete(cmd);\n            break;\n          }\n\n          case UpdateLog.DELETE_BY_QUERY:\n          {\n            String query = (String)entry.get(2);\n            DeleteUpdateCommand cmd = new DeleteUpdateCommand(req);\n            cmd.query = query;\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"deleteByQuery \" + cmd);\n            }\n            proc.processDelete(cmd);\n            break;\n          }\n\n          default:\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n        }\n\n      }\n\n    }\n    catch (IOException e) {\n      // TODO: should this be handled separately as a problem with us?\n      // I guess it probably already will by causing replication to be kicked off.\n      sreq.updateException = e;\n      log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,update=\" + o, e);\n      return false;\n    }\n    catch (Exception e) {\n      sreq.updateException = e;\n      log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,update=\" + o, e);\n      return false;\n    }\n    finally {\n      try {\n        proc.finish();\n      } catch (Exception e) {\n        sreq.updateException = e;\n        log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,finish()\", e);\n        return false;\n      }\n    }\n\n    return true;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e2fe35ac47f8f51356d6c1724455d18f31c94fae","date":1337966698,"type":3,"author":"Chris M. Hostetter","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/update/PeerSync#handleUpdates(ShardResponse).mjava","pathOld":"solr/core/src/java/org/apache/solr/update/PeerSync#handleUpdates(ShardResponse).mjava","sourceNew":"  private boolean handleUpdates(ShardResponse srsp) {\n    // we retrieved the last N updates from the replica\n    List<Object> updates = (List<Object>)srsp.getSolrResponse().getResponse().get(\"updates\");\n\n    SyncShardRequest sreq = (SyncShardRequest) srsp.getShardRequest();\n    if (updates.size() < sreq.requestedUpdates.size()) {\n      log.error(msg() + \" Requested \" + sreq.requestedUpdates.size() + \" updates from \" + sreq.shards[0] + \" but retrieved \" + updates.size());\n      return false;\n    }\n\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(DISTRIB_UPDATE_PARAM, FROMLEADER.toString());\n    // params.set(\"peersync\",true); // debugging\n    SolrQueryRequest req = new LocalSolrQueryRequest(uhandler.core, params);\n    SolrQueryResponse rsp = new SolrQueryResponse();\n\n    RunUpdateProcessorFactory runFac = new RunUpdateProcessorFactory();\n    DistributedUpdateProcessorFactory magicFac = new DistributedUpdateProcessorFactory();\n    runFac.init(new NamedList());\n    magicFac.init(new NamedList());\n\n    UpdateRequestProcessor proc = magicFac.getInstance(req, rsp, runFac.getInstance(req, rsp, null));\n\n    Collections.sort(updates, updateRecordComparator);\n\n    Object o = null;\n    long lastVersion = 0;\n    try {\n      // Apply oldest updates first\n      for (Object obj : updates) {\n        // should currently be a List<Oper,Ver,Doc/Id>\n        o = obj;\n        List<Object> entry = (List<Object>)o;\n\n        if (debug) {\n          log.debug(msg() + \"raw update record \" + o);\n        }\n\n        int oper = (Integer)entry.get(0) & UpdateLog.OPERATION_MASK;\n        long version = (Long) entry.get(1);\n        if (version == lastVersion && version != 0) continue;\n        lastVersion = version;\n\n        switch (oper) {\n          case UpdateLog.ADD:\n          {\n            // byte[] idBytes = (byte[]) entry.get(2);\n            SolrInputDocument sdoc = (SolrInputDocument)entry.get(entry.size()-1);\n            AddUpdateCommand cmd = new AddUpdateCommand(req);\n            // cmd.setIndexedId(new BytesRef(idBytes));\n            cmd.solrDoc = sdoc;\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"add \" + cmd);\n            }\n            proc.processAdd(cmd);\n            break;\n          }\n          case UpdateLog.DELETE:\n          {\n            byte[] idBytes = (byte[]) entry.get(2);\n            DeleteUpdateCommand cmd = new DeleteUpdateCommand(req);\n            cmd.setIndexedId(new BytesRef(idBytes));\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"delete \" + cmd);\n            }\n            proc.processDelete(cmd);\n            break;\n          }\n\n          case UpdateLog.DELETE_BY_QUERY:\n          {\n            String query = (String)entry.get(2);\n            DeleteUpdateCommand cmd = new DeleteUpdateCommand(req);\n            cmd.query = query;\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"deleteByQuery \" + cmd);\n            }\n            proc.processDelete(cmd);\n            break;\n          }\n\n          default:\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n        }\n\n      }\n\n    }\n    catch (IOException e) {\n      // TODO: should this be handled separately as a problem with us?\n      // I guess it probably already will by causing replication to be kicked off.\n      sreq.updateException = e;\n      log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,update=\" + o, e);\n      return false;\n    }\n    catch (Exception e) {\n      sreq.updateException = e;\n      log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,update=\" + o, e);\n      return false;\n    }\n    finally {\n      try {\n        proc.finish();\n      } catch (Exception e) {\n        sreq.updateException = e;\n        log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,finish()\", e);\n        return false;\n      }\n    }\n\n    return true;\n  }\n\n","sourceOld":"  private boolean handleUpdates(ShardResponse srsp) {\n    // we retrieved the last N updates from the replica\n    List<Object> updates = (List<Object>)srsp.getSolrResponse().getResponse().get(\"updates\");\n\n    SyncShardRequest sreq = (SyncShardRequest) srsp.getShardRequest();\n    if (updates.size() < sreq.requestedUpdates.size()) {\n      log.error(msg() + \" Requested \" + sreq.requestedUpdates.size() + \" updates from \" + sreq.shards[0] + \" but retrieved \" + updates.size());\n      return false;\n    }\n\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(DistributedUpdateProcessor.SEEN_LEADER, true);\n    // params.set(\"peersync\",true); // debugging\n    SolrQueryRequest req = new LocalSolrQueryRequest(uhandler.core, params);\n    SolrQueryResponse rsp = new SolrQueryResponse();\n\n    RunUpdateProcessorFactory runFac = new RunUpdateProcessorFactory();\n    DistributedUpdateProcessorFactory magicFac = new DistributedUpdateProcessorFactory();\n    runFac.init(new NamedList());\n    magicFac.init(new NamedList());\n\n    UpdateRequestProcessor proc = magicFac.getInstance(req, rsp, runFac.getInstance(req, rsp, null));\n\n    Collections.sort(updates, updateRecordComparator);\n\n    Object o = null;\n    long lastVersion = 0;\n    try {\n      // Apply oldest updates first\n      for (Object obj : updates) {\n        // should currently be a List<Oper,Ver,Doc/Id>\n        o = obj;\n        List<Object> entry = (List<Object>)o;\n\n        if (debug) {\n          log.debug(msg() + \"raw update record \" + o);\n        }\n\n        int oper = (Integer)entry.get(0) & UpdateLog.OPERATION_MASK;\n        long version = (Long) entry.get(1);\n        if (version == lastVersion && version != 0) continue;\n        lastVersion = version;\n\n        switch (oper) {\n          case UpdateLog.ADD:\n          {\n            // byte[] idBytes = (byte[]) entry.get(2);\n            SolrInputDocument sdoc = (SolrInputDocument)entry.get(entry.size()-1);\n            AddUpdateCommand cmd = new AddUpdateCommand(req);\n            // cmd.setIndexedId(new BytesRef(idBytes));\n            cmd.solrDoc = sdoc;\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"add \" + cmd);\n            }\n            proc.processAdd(cmd);\n            break;\n          }\n          case UpdateLog.DELETE:\n          {\n            byte[] idBytes = (byte[]) entry.get(2);\n            DeleteUpdateCommand cmd = new DeleteUpdateCommand(req);\n            cmd.setIndexedId(new BytesRef(idBytes));\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"delete \" + cmd);\n            }\n            proc.processDelete(cmd);\n            break;\n          }\n\n          case UpdateLog.DELETE_BY_QUERY:\n          {\n            String query = (String)entry.get(2);\n            DeleteUpdateCommand cmd = new DeleteUpdateCommand(req);\n            cmd.query = query;\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"deleteByQuery \" + cmd);\n            }\n            proc.processDelete(cmd);\n            break;\n          }\n\n          default:\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n        }\n\n      }\n\n    }\n    catch (IOException e) {\n      // TODO: should this be handled separately as a problem with us?\n      // I guess it probably already will by causing replication to be kicked off.\n      sreq.updateException = e;\n      log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,update=\" + o, e);\n      return false;\n    }\n    catch (Exception e) {\n      sreq.updateException = e;\n      log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,update=\" + o, e);\n      return false;\n    }\n    finally {\n      try {\n        proc.finish();\n      } catch (Exception e) {\n        sreq.updateException = e;\n        log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,finish()\", e);\n        return false;\n      }\n    }\n\n    return true;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"3d7c0c8a97beb56d2e168604f9928de17981eabe","date":1357257676,"type":3,"author":"Yonik Seeley","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/update/PeerSync#handleUpdates(ShardResponse).mjava","pathOld":"solr/core/src/java/org/apache/solr/update/PeerSync#handleUpdates(ShardResponse).mjava","sourceNew":"  private boolean handleUpdates(ShardResponse srsp) {\n    // we retrieved the last N updates from the replica\n    List<Object> updates = (List<Object>)srsp.getSolrResponse().getResponse().get(\"updates\");\n\n    SyncShardRequest sreq = (SyncShardRequest) srsp.getShardRequest();\n    if (updates.size() < sreq.requestedUpdates.size()) {\n      log.error(msg() + \" Requested \" + sreq.requestedUpdates.size() + \" updates from \" + sreq.shards[0] + \" but retrieved \" + updates.size());\n      return false;\n    }\n\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(DISTRIB_UPDATE_PARAM, FROMLEADER.toString());\n    params.set(\"peersync\",true); // debugging\n    SolrQueryRequest req = new LocalSolrQueryRequest(uhandler.core, params);\n    SolrQueryResponse rsp = new SolrQueryResponse();\n\n    // TODO: use the standard update processor chain now that it has support to skip processors before the DistributedUpdateProcessor?\n    RunUpdateProcessorFactory runFac = new RunUpdateProcessorFactory();\n    DistributedUpdateProcessorFactory magicFac = new DistributedUpdateProcessorFactory();\n    runFac.init(new NamedList());\n    magicFac.init(new NamedList());\n\n    UpdateRequestProcessor proc = magicFac.getInstance(req, rsp, runFac.getInstance(req, rsp, null));\n\n    Collections.sort(updates, updateRecordComparator);\n\n    Object o = null;\n    long lastVersion = 0;\n    try {\n      // Apply oldest updates first\n      for (Object obj : updates) {\n        // should currently be a List<Oper,Ver,Doc/Id>\n        o = obj;\n        List<Object> entry = (List<Object>)o;\n\n        if (debug) {\n          log.debug(msg() + \"raw update record \" + o);\n        }\n\n        int oper = (Integer)entry.get(0) & UpdateLog.OPERATION_MASK;\n        long version = (Long) entry.get(1);\n        if (version == lastVersion && version != 0) continue;\n        lastVersion = version;\n\n        switch (oper) {\n          case UpdateLog.ADD:\n          {\n            // byte[] idBytes = (byte[]) entry.get(2);\n            SolrInputDocument sdoc = (SolrInputDocument)entry.get(entry.size()-1);\n            AddUpdateCommand cmd = new AddUpdateCommand(req);\n            // cmd.setIndexedId(new BytesRef(idBytes));\n            cmd.solrDoc = sdoc;\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"add \" + cmd);\n            }\n            proc.processAdd(cmd);\n            break;\n          }\n          case UpdateLog.DELETE:\n          {\n            byte[] idBytes = (byte[]) entry.get(2);\n            DeleteUpdateCommand cmd = new DeleteUpdateCommand(req);\n            cmd.setIndexedId(new BytesRef(idBytes));\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"delete \" + cmd);\n            }\n            proc.processDelete(cmd);\n            break;\n          }\n\n          case UpdateLog.DELETE_BY_QUERY:\n          {\n            String query = (String)entry.get(2);\n            DeleteUpdateCommand cmd = new DeleteUpdateCommand(req);\n            cmd.query = query;\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"deleteByQuery \" + cmd);\n            }\n            proc.processDelete(cmd);\n            break;\n          }\n\n          default:\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n        }\n\n      }\n\n    }\n    catch (IOException e) {\n      // TODO: should this be handled separately as a problem with us?\n      // I guess it probably already will by causing replication to be kicked off.\n      sreq.updateException = e;\n      log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,update=\" + o, e);\n      return false;\n    }\n    catch (Exception e) {\n      sreq.updateException = e;\n      log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,update=\" + o, e);\n      return false;\n    }\n    finally {\n      try {\n        proc.finish();\n      } catch (Exception e) {\n        sreq.updateException = e;\n        log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,finish()\", e);\n        return false;\n      }\n    }\n\n    return true;\n  }\n\n","sourceOld":"  private boolean handleUpdates(ShardResponse srsp) {\n    // we retrieved the last N updates from the replica\n    List<Object> updates = (List<Object>)srsp.getSolrResponse().getResponse().get(\"updates\");\n\n    SyncShardRequest sreq = (SyncShardRequest) srsp.getShardRequest();\n    if (updates.size() < sreq.requestedUpdates.size()) {\n      log.error(msg() + \" Requested \" + sreq.requestedUpdates.size() + \" updates from \" + sreq.shards[0] + \" but retrieved \" + updates.size());\n      return false;\n    }\n\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(DISTRIB_UPDATE_PARAM, FROMLEADER.toString());\n    // params.set(\"peersync\",true); // debugging\n    SolrQueryRequest req = new LocalSolrQueryRequest(uhandler.core, params);\n    SolrQueryResponse rsp = new SolrQueryResponse();\n\n    RunUpdateProcessorFactory runFac = new RunUpdateProcessorFactory();\n    DistributedUpdateProcessorFactory magicFac = new DistributedUpdateProcessorFactory();\n    runFac.init(new NamedList());\n    magicFac.init(new NamedList());\n\n    UpdateRequestProcessor proc = magicFac.getInstance(req, rsp, runFac.getInstance(req, rsp, null));\n\n    Collections.sort(updates, updateRecordComparator);\n\n    Object o = null;\n    long lastVersion = 0;\n    try {\n      // Apply oldest updates first\n      for (Object obj : updates) {\n        // should currently be a List<Oper,Ver,Doc/Id>\n        o = obj;\n        List<Object> entry = (List<Object>)o;\n\n        if (debug) {\n          log.debug(msg() + \"raw update record \" + o);\n        }\n\n        int oper = (Integer)entry.get(0) & UpdateLog.OPERATION_MASK;\n        long version = (Long) entry.get(1);\n        if (version == lastVersion && version != 0) continue;\n        lastVersion = version;\n\n        switch (oper) {\n          case UpdateLog.ADD:\n          {\n            // byte[] idBytes = (byte[]) entry.get(2);\n            SolrInputDocument sdoc = (SolrInputDocument)entry.get(entry.size()-1);\n            AddUpdateCommand cmd = new AddUpdateCommand(req);\n            // cmd.setIndexedId(new BytesRef(idBytes));\n            cmd.solrDoc = sdoc;\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"add \" + cmd);\n            }\n            proc.processAdd(cmd);\n            break;\n          }\n          case UpdateLog.DELETE:\n          {\n            byte[] idBytes = (byte[]) entry.get(2);\n            DeleteUpdateCommand cmd = new DeleteUpdateCommand(req);\n            cmd.setIndexedId(new BytesRef(idBytes));\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"delete \" + cmd);\n            }\n            proc.processDelete(cmd);\n            break;\n          }\n\n          case UpdateLog.DELETE_BY_QUERY:\n          {\n            String query = (String)entry.get(2);\n            DeleteUpdateCommand cmd = new DeleteUpdateCommand(req);\n            cmd.query = query;\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"deleteByQuery \" + cmd);\n            }\n            proc.processDelete(cmd);\n            break;\n          }\n\n          default:\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n        }\n\n      }\n\n    }\n    catch (IOException e) {\n      // TODO: should this be handled separately as a problem with us?\n      // I guess it probably already will by causing replication to be kicked off.\n      sreq.updateException = e;\n      log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,update=\" + o, e);\n      return false;\n    }\n    catch (Exception e) {\n      sreq.updateException = e;\n      log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,update=\" + o, e);\n      return false;\n    }\n    finally {\n      try {\n        proc.finish();\n      } catch (Exception e) {\n        sreq.updateException = e;\n        log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,finish()\", e);\n        return false;\n      }\n    }\n\n    return true;\n  }\n\n","bugFix":["3060d5648a525a745f0ac45420e84bf5c7e9b135"],"bugIntro":["0e05f2a24d572cfb09482deb87b03100ce3af1a7"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d3fcb70cf561547c7bb1506e0cf32ca7b1287064","date":1357616416,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/update/PeerSync#handleUpdates(ShardResponse).mjava","pathOld":"solr/core/src/java/org/apache/solr/update/PeerSync#handleUpdates(ShardResponse).mjava","sourceNew":"  private boolean handleUpdates(ShardResponse srsp) {\n    // we retrieved the last N updates from the replica\n    List<Object> updates = (List<Object>)srsp.getSolrResponse().getResponse().get(\"updates\");\n\n    SyncShardRequest sreq = (SyncShardRequest) srsp.getShardRequest();\n    if (updates.size() < sreq.requestedUpdates.size()) {\n      log.error(msg() + \" Requested \" + sreq.requestedUpdates.size() + \" updates from \" + sreq.shards[0] + \" but retrieved \" + updates.size());\n      return false;\n    }\n\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(DISTRIB_UPDATE_PARAM, FROMLEADER.toString());\n    params.set(\"peersync\",true); // debugging\n    SolrQueryRequest req = new LocalSolrQueryRequest(uhandler.core, params);\n    SolrQueryResponse rsp = new SolrQueryResponse();\n\n    // TODO: use the standard update processor chain now that it has support to skip processors before the DistributedUpdateProcessor?\n    RunUpdateProcessorFactory runFac = new RunUpdateProcessorFactory();\n    DistributedUpdateProcessorFactory magicFac = new DistributedUpdateProcessorFactory();\n    runFac.init(new NamedList());\n    magicFac.init(new NamedList());\n\n    UpdateRequestProcessor proc = magicFac.getInstance(req, rsp, runFac.getInstance(req, rsp, null));\n\n    Collections.sort(updates, updateRecordComparator);\n\n    Object o = null;\n    long lastVersion = 0;\n    try {\n      // Apply oldest updates first\n      for (Object obj : updates) {\n        // should currently be a List<Oper,Ver,Doc/Id>\n        o = obj;\n        List<Object> entry = (List<Object>)o;\n\n        if (debug) {\n          log.debug(msg() + \"raw update record \" + o);\n        }\n\n        int oper = (Integer)entry.get(0) & UpdateLog.OPERATION_MASK;\n        long version = (Long) entry.get(1);\n        if (version == lastVersion && version != 0) continue;\n        lastVersion = version;\n\n        switch (oper) {\n          case UpdateLog.ADD:\n          {\n            // byte[] idBytes = (byte[]) entry.get(2);\n            SolrInputDocument sdoc = (SolrInputDocument)entry.get(entry.size()-1);\n            AddUpdateCommand cmd = new AddUpdateCommand(req);\n            // cmd.setIndexedId(new BytesRef(idBytes));\n            cmd.solrDoc = sdoc;\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"add \" + cmd);\n            }\n            proc.processAdd(cmd);\n            break;\n          }\n          case UpdateLog.DELETE:\n          {\n            byte[] idBytes = (byte[]) entry.get(2);\n            DeleteUpdateCommand cmd = new DeleteUpdateCommand(req);\n            cmd.setIndexedId(new BytesRef(idBytes));\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"delete \" + cmd);\n            }\n            proc.processDelete(cmd);\n            break;\n          }\n\n          case UpdateLog.DELETE_BY_QUERY:\n          {\n            String query = (String)entry.get(2);\n            DeleteUpdateCommand cmd = new DeleteUpdateCommand(req);\n            cmd.query = query;\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"deleteByQuery \" + cmd);\n            }\n            proc.processDelete(cmd);\n            break;\n          }\n\n          default:\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n        }\n\n      }\n\n    }\n    catch (IOException e) {\n      // TODO: should this be handled separately as a problem with us?\n      // I guess it probably already will by causing replication to be kicked off.\n      sreq.updateException = e;\n      log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,update=\" + o, e);\n      return false;\n    }\n    catch (Exception e) {\n      sreq.updateException = e;\n      log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,update=\" + o, e);\n      return false;\n    }\n    finally {\n      try {\n        proc.finish();\n      } catch (Exception e) {\n        sreq.updateException = e;\n        log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,finish()\", e);\n        return false;\n      }\n    }\n\n    return true;\n  }\n\n","sourceOld":"  private boolean handleUpdates(ShardResponse srsp) {\n    // we retrieved the last N updates from the replica\n    List<Object> updates = (List<Object>)srsp.getSolrResponse().getResponse().get(\"updates\");\n\n    SyncShardRequest sreq = (SyncShardRequest) srsp.getShardRequest();\n    if (updates.size() < sreq.requestedUpdates.size()) {\n      log.error(msg() + \" Requested \" + sreq.requestedUpdates.size() + \" updates from \" + sreq.shards[0] + \" but retrieved \" + updates.size());\n      return false;\n    }\n\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(DISTRIB_UPDATE_PARAM, FROMLEADER.toString());\n    // params.set(\"peersync\",true); // debugging\n    SolrQueryRequest req = new LocalSolrQueryRequest(uhandler.core, params);\n    SolrQueryResponse rsp = new SolrQueryResponse();\n\n    RunUpdateProcessorFactory runFac = new RunUpdateProcessorFactory();\n    DistributedUpdateProcessorFactory magicFac = new DistributedUpdateProcessorFactory();\n    runFac.init(new NamedList());\n    magicFac.init(new NamedList());\n\n    UpdateRequestProcessor proc = magicFac.getInstance(req, rsp, runFac.getInstance(req, rsp, null));\n\n    Collections.sort(updates, updateRecordComparator);\n\n    Object o = null;\n    long lastVersion = 0;\n    try {\n      // Apply oldest updates first\n      for (Object obj : updates) {\n        // should currently be a List<Oper,Ver,Doc/Id>\n        o = obj;\n        List<Object> entry = (List<Object>)o;\n\n        if (debug) {\n          log.debug(msg() + \"raw update record \" + o);\n        }\n\n        int oper = (Integer)entry.get(0) & UpdateLog.OPERATION_MASK;\n        long version = (Long) entry.get(1);\n        if (version == lastVersion && version != 0) continue;\n        lastVersion = version;\n\n        switch (oper) {\n          case UpdateLog.ADD:\n          {\n            // byte[] idBytes = (byte[]) entry.get(2);\n            SolrInputDocument sdoc = (SolrInputDocument)entry.get(entry.size()-1);\n            AddUpdateCommand cmd = new AddUpdateCommand(req);\n            // cmd.setIndexedId(new BytesRef(idBytes));\n            cmd.solrDoc = sdoc;\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"add \" + cmd);\n            }\n            proc.processAdd(cmd);\n            break;\n          }\n          case UpdateLog.DELETE:\n          {\n            byte[] idBytes = (byte[]) entry.get(2);\n            DeleteUpdateCommand cmd = new DeleteUpdateCommand(req);\n            cmd.setIndexedId(new BytesRef(idBytes));\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"delete \" + cmd);\n            }\n            proc.processDelete(cmd);\n            break;\n          }\n\n          case UpdateLog.DELETE_BY_QUERY:\n          {\n            String query = (String)entry.get(2);\n            DeleteUpdateCommand cmd = new DeleteUpdateCommand(req);\n            cmd.query = query;\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"deleteByQuery \" + cmd);\n            }\n            proc.processDelete(cmd);\n            break;\n          }\n\n          default:\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n        }\n\n      }\n\n    }\n    catch (IOException e) {\n      // TODO: should this be handled separately as a problem with us?\n      // I guess it probably already will by causing replication to be kicked off.\n      sreq.updateException = e;\n      log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,update=\" + o, e);\n      return false;\n    }\n    catch (Exception e) {\n      sreq.updateException = e;\n      log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,update=\" + o, e);\n      return false;\n    }\n    finally {\n      try {\n        proc.finish();\n      } catch (Exception e) {\n        sreq.updateException = e;\n        log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,finish()\", e);\n        return false;\n      }\n    }\n\n    return true;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0e05f2a24d572cfb09482deb87b03100ce3af1a7","date":1363888591,"type":3,"author":"Yonik Seeley","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/update/PeerSync#handleUpdates(ShardResponse).mjava","pathOld":"solr/core/src/java/org/apache/solr/update/PeerSync#handleUpdates(ShardResponse).mjava","sourceNew":"  private boolean handleUpdates(ShardResponse srsp) {\n    // we retrieved the last N updates from the replica\n    List<Object> updates = (List<Object>)srsp.getSolrResponse().getResponse().get(\"updates\");\n\n    SyncShardRequest sreq = (SyncShardRequest) srsp.getShardRequest();\n    if (updates.size() < sreq.requestedUpdates.size()) {\n      log.error(msg() + \" Requested \" + sreq.requestedUpdates.size() + \" updates from \" + sreq.shards[0] + \" but retrieved \" + updates.size());\n      return false;\n    }\n\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(DISTRIB_UPDATE_PARAM, FROMLEADER.toString());\n    params.set(\"peersync\",true); // debugging\n    SolrQueryRequest req = new LocalSolrQueryRequest(uhandler.core, params);\n    SolrQueryResponse rsp = new SolrQueryResponse();\n\n    UpdateRequestProcessorChain processorChain = req.getCore().getUpdateProcessingChain(null);\n    UpdateRequestProcessor proc = processorChain.createProcessor(req, rsp);\n\n    Collections.sort(updates, updateRecordComparator);\n\n    Object o = null;\n    long lastVersion = 0;\n    try {\n      // Apply oldest updates first\n      for (Object obj : updates) {\n        // should currently be a List<Oper,Ver,Doc/Id>\n        o = obj;\n        List<Object> entry = (List<Object>)o;\n\n        if (debug) {\n          log.debug(msg() + \"raw update record \" + o);\n        }\n\n        int oper = (Integer)entry.get(0) & UpdateLog.OPERATION_MASK;\n        long version = (Long) entry.get(1);\n        if (version == lastVersion && version != 0) continue;\n        lastVersion = version;\n\n        switch (oper) {\n          case UpdateLog.ADD:\n          {\n            // byte[] idBytes = (byte[]) entry.get(2);\n            SolrInputDocument sdoc = (SolrInputDocument)entry.get(entry.size()-1);\n            AddUpdateCommand cmd = new AddUpdateCommand(req);\n            // cmd.setIndexedId(new BytesRef(idBytes));\n            cmd.solrDoc = sdoc;\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"add \" + cmd);\n            }\n            proc.processAdd(cmd);\n            break;\n          }\n          case UpdateLog.DELETE:\n          {\n            byte[] idBytes = (byte[]) entry.get(2);\n            DeleteUpdateCommand cmd = new DeleteUpdateCommand(req);\n            cmd.setIndexedId(new BytesRef(idBytes));\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"delete \" + cmd);\n            }\n            proc.processDelete(cmd);\n            break;\n          }\n\n          case UpdateLog.DELETE_BY_QUERY:\n          {\n            String query = (String)entry.get(2);\n            DeleteUpdateCommand cmd = new DeleteUpdateCommand(req);\n            cmd.query = query;\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"deleteByQuery \" + cmd);\n            }\n            proc.processDelete(cmd);\n            break;\n          }\n\n          default:\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n        }\n\n      }\n\n    }\n    catch (IOException e) {\n      // TODO: should this be handled separately as a problem with us?\n      // I guess it probably already will by causing replication to be kicked off.\n      sreq.updateException = e;\n      log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,update=\" + o, e);\n      return false;\n    }\n    catch (Exception e) {\n      sreq.updateException = e;\n      log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,update=\" + o, e);\n      return false;\n    }\n    finally {\n      try {\n        proc.finish();\n      } catch (Exception e) {\n        sreq.updateException = e;\n        log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,finish()\", e);\n        return false;\n      }\n    }\n\n    return true;\n  }\n\n","sourceOld":"  private boolean handleUpdates(ShardResponse srsp) {\n    // we retrieved the last N updates from the replica\n    List<Object> updates = (List<Object>)srsp.getSolrResponse().getResponse().get(\"updates\");\n\n    SyncShardRequest sreq = (SyncShardRequest) srsp.getShardRequest();\n    if (updates.size() < sreq.requestedUpdates.size()) {\n      log.error(msg() + \" Requested \" + sreq.requestedUpdates.size() + \" updates from \" + sreq.shards[0] + \" but retrieved \" + updates.size());\n      return false;\n    }\n\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(DISTRIB_UPDATE_PARAM, FROMLEADER.toString());\n    params.set(\"peersync\",true); // debugging\n    SolrQueryRequest req = new LocalSolrQueryRequest(uhandler.core, params);\n    SolrQueryResponse rsp = new SolrQueryResponse();\n\n    // TODO: use the standard update processor chain now that it has support to skip processors before the DistributedUpdateProcessor?\n    RunUpdateProcessorFactory runFac = new RunUpdateProcessorFactory();\n    DistributedUpdateProcessorFactory magicFac = new DistributedUpdateProcessorFactory();\n    runFac.init(new NamedList());\n    magicFac.init(new NamedList());\n\n    UpdateRequestProcessor proc = magicFac.getInstance(req, rsp, runFac.getInstance(req, rsp, null));\n\n    Collections.sort(updates, updateRecordComparator);\n\n    Object o = null;\n    long lastVersion = 0;\n    try {\n      // Apply oldest updates first\n      for (Object obj : updates) {\n        // should currently be a List<Oper,Ver,Doc/Id>\n        o = obj;\n        List<Object> entry = (List<Object>)o;\n\n        if (debug) {\n          log.debug(msg() + \"raw update record \" + o);\n        }\n\n        int oper = (Integer)entry.get(0) & UpdateLog.OPERATION_MASK;\n        long version = (Long) entry.get(1);\n        if (version == lastVersion && version != 0) continue;\n        lastVersion = version;\n\n        switch (oper) {\n          case UpdateLog.ADD:\n          {\n            // byte[] idBytes = (byte[]) entry.get(2);\n            SolrInputDocument sdoc = (SolrInputDocument)entry.get(entry.size()-1);\n            AddUpdateCommand cmd = new AddUpdateCommand(req);\n            // cmd.setIndexedId(new BytesRef(idBytes));\n            cmd.solrDoc = sdoc;\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"add \" + cmd);\n            }\n            proc.processAdd(cmd);\n            break;\n          }\n          case UpdateLog.DELETE:\n          {\n            byte[] idBytes = (byte[]) entry.get(2);\n            DeleteUpdateCommand cmd = new DeleteUpdateCommand(req);\n            cmd.setIndexedId(new BytesRef(idBytes));\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"delete \" + cmd);\n            }\n            proc.processDelete(cmd);\n            break;\n          }\n\n          case UpdateLog.DELETE_BY_QUERY:\n          {\n            String query = (String)entry.get(2);\n            DeleteUpdateCommand cmd = new DeleteUpdateCommand(req);\n            cmd.query = query;\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"deleteByQuery \" + cmd);\n            }\n            proc.processDelete(cmd);\n            break;\n          }\n\n          default:\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n        }\n\n      }\n\n    }\n    catch (IOException e) {\n      // TODO: should this be handled separately as a problem with us?\n      // I guess it probably already will by causing replication to be kicked off.\n      sreq.updateException = e;\n      log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,update=\" + o, e);\n      return false;\n    }\n    catch (Exception e) {\n      sreq.updateException = e;\n      log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,update=\" + o, e);\n      return false;\n    }\n    finally {\n      try {\n        proc.finish();\n      } catch (Exception e) {\n        sreq.updateException = e;\n        log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,finish()\", e);\n        return false;\n      }\n    }\n\n    return true;\n  }\n\n","bugFix":["3d7c0c8a97beb56d2e168604f9928de17981eabe","2c007e7c4cf8c55bc2a5884e315123afaaeec87f"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"6c94d2661bc1c14426980ec7882e951fdcff08d0","date":1427167177,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/update/PeerSync#handleUpdates(ShardResponse).mjava","pathOld":"solr/core/src/java/org/apache/solr/update/PeerSync#handleUpdates(ShardResponse).mjava","sourceNew":"  private boolean handleUpdates(ShardResponse srsp) {\n    // we retrieved the last N updates from the replica\n    List<Object> updates = (List<Object>)srsp.getSolrResponse().getResponse().get(\"updates\");\n\n    SyncShardRequest sreq = (SyncShardRequest) srsp.getShardRequest();\n    if (updates.size() < sreq.requestedUpdates.size()) {\n      log.error(msg() + \" Requested \" + sreq.requestedUpdates.size() + \" updates from \" + sreq.shards[0] + \" but retrieved \" + updates.size());\n      return false;\n    }\n\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(DISTRIB_UPDATE_PARAM, FROMLEADER.toString());\n    params.set(\"peersync\",true); // debugging\n    SolrQueryRequest req = new LocalSolrQueryRequest(uhandler.core, params);\n    SolrQueryResponse rsp = new SolrQueryResponse();\n\n    UpdateRequestProcessorChain processorChain = req.getCore().getUpdateProcessingChain(null);\n    UpdateRequestProcessor proc = processorChain.createProcessor(req, rsp);\n\n    Collections.sort(updates, updateRecordComparator);\n\n    Object o = null;\n    long lastVersion = 0;\n    try {\n      // Apply oldest updates first\n      for (Object obj : updates) {\n        // should currently be a List<Oper,Ver,Doc/Id>\n        o = obj;\n        List<Object> entry = (List<Object>)o;\n\n        if (debug) {\n          log.debug(msg() + \"raw update record \" + o);\n        }\n\n        int oper = (Integer)entry.get(0) & UpdateLog.OPERATION_MASK;\n        long version = (Long) entry.get(1);\n        if (version == lastVersion && version != 0) continue;\n        lastVersion = version;\n\n        switch (oper) {\n          case UpdateLog.ADD:\n          {\n            // byte[] idBytes = (byte[]) entry.get(2);\n            SolrInputDocument sdoc = (SolrInputDocument)entry.get(entry.size()-1);\n            AddUpdateCommand cmd = new AddUpdateCommand(req);\n            // cmd.setIndexedId(new BytesRef(idBytes));\n            cmd.solrDoc = sdoc;\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"add \" + cmd + \" id \" + sdoc.getField(\"id\"));\n            }\n            proc.processAdd(cmd);\n            break;\n          }\n          case UpdateLog.DELETE:\n          {\n            byte[] idBytes = (byte[]) entry.get(2);\n            DeleteUpdateCommand cmd = new DeleteUpdateCommand(req);\n            cmd.setIndexedId(new BytesRef(idBytes));\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"delete \" + cmd + \" \" + new BytesRef(idBytes).utf8ToString());\n            }\n            proc.processDelete(cmd);\n            break;\n          }\n\n          case UpdateLog.DELETE_BY_QUERY:\n          {\n            String query = (String)entry.get(2);\n            DeleteUpdateCommand cmd = new DeleteUpdateCommand(req);\n            cmd.query = query;\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"deleteByQuery \" + cmd);\n            }\n            proc.processDelete(cmd);\n            break;\n          }\n\n          default:\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n        }\n\n      }\n\n    }\n    catch (IOException e) {\n      // TODO: should this be handled separately as a problem with us?\n      // I guess it probably already will by causing replication to be kicked off.\n      sreq.updateException = e;\n      log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,update=\" + o, e);\n      return false;\n    }\n    catch (Exception e) {\n      sreq.updateException = e;\n      log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,update=\" + o, e);\n      return false;\n    }\n    finally {\n      try {\n        proc.finish();\n      } catch (Exception e) {\n        sreq.updateException = e;\n        log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,finish()\", e);\n        return false;\n      }\n    }\n\n    return true;\n  }\n\n","sourceOld":"  private boolean handleUpdates(ShardResponse srsp) {\n    // we retrieved the last N updates from the replica\n    List<Object> updates = (List<Object>)srsp.getSolrResponse().getResponse().get(\"updates\");\n\n    SyncShardRequest sreq = (SyncShardRequest) srsp.getShardRequest();\n    if (updates.size() < sreq.requestedUpdates.size()) {\n      log.error(msg() + \" Requested \" + sreq.requestedUpdates.size() + \" updates from \" + sreq.shards[0] + \" but retrieved \" + updates.size());\n      return false;\n    }\n\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(DISTRIB_UPDATE_PARAM, FROMLEADER.toString());\n    params.set(\"peersync\",true); // debugging\n    SolrQueryRequest req = new LocalSolrQueryRequest(uhandler.core, params);\n    SolrQueryResponse rsp = new SolrQueryResponse();\n\n    UpdateRequestProcessorChain processorChain = req.getCore().getUpdateProcessingChain(null);\n    UpdateRequestProcessor proc = processorChain.createProcessor(req, rsp);\n\n    Collections.sort(updates, updateRecordComparator);\n\n    Object o = null;\n    long lastVersion = 0;\n    try {\n      // Apply oldest updates first\n      for (Object obj : updates) {\n        // should currently be a List<Oper,Ver,Doc/Id>\n        o = obj;\n        List<Object> entry = (List<Object>)o;\n\n        if (debug) {\n          log.debug(msg() + \"raw update record \" + o);\n        }\n\n        int oper = (Integer)entry.get(0) & UpdateLog.OPERATION_MASK;\n        long version = (Long) entry.get(1);\n        if (version == lastVersion && version != 0) continue;\n        lastVersion = version;\n\n        switch (oper) {\n          case UpdateLog.ADD:\n          {\n            // byte[] idBytes = (byte[]) entry.get(2);\n            SolrInputDocument sdoc = (SolrInputDocument)entry.get(entry.size()-1);\n            AddUpdateCommand cmd = new AddUpdateCommand(req);\n            // cmd.setIndexedId(new BytesRef(idBytes));\n            cmd.solrDoc = sdoc;\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"add \" + cmd);\n            }\n            proc.processAdd(cmd);\n            break;\n          }\n          case UpdateLog.DELETE:\n          {\n            byte[] idBytes = (byte[]) entry.get(2);\n            DeleteUpdateCommand cmd = new DeleteUpdateCommand(req);\n            cmd.setIndexedId(new BytesRef(idBytes));\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"delete \" + cmd);\n            }\n            proc.processDelete(cmd);\n            break;\n          }\n\n          case UpdateLog.DELETE_BY_QUERY:\n          {\n            String query = (String)entry.get(2);\n            DeleteUpdateCommand cmd = new DeleteUpdateCommand(req);\n            cmd.query = query;\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"deleteByQuery \" + cmd);\n            }\n            proc.processDelete(cmd);\n            break;\n          }\n\n          default:\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n        }\n\n      }\n\n    }\n    catch (IOException e) {\n      // TODO: should this be handled separately as a problem with us?\n      // I guess it probably already will by causing replication to be kicked off.\n      sreq.updateException = e;\n      log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,update=\" + o, e);\n      return false;\n    }\n    catch (Exception e) {\n      sreq.updateException = e;\n      log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,update=\" + o, e);\n      return false;\n    }\n    finally {\n      try {\n        proc.finish();\n      } catch (Exception e) {\n        sreq.updateException = e;\n        log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,finish()\", e);\n        return false;\n      }\n    }\n\n    return true;\n  }\n\n","bugFix":["5620d3cb34306ea5b7d016a832fbc964b74c2650"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","date":1427779360,"type":3,"author":"Ryan Ernst","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/update/PeerSync#handleUpdates(ShardResponse).mjava","pathOld":"solr/core/src/java/org/apache/solr/update/PeerSync#handleUpdates(ShardResponse).mjava","sourceNew":"  private boolean handleUpdates(ShardResponse srsp) {\n    // we retrieved the last N updates from the replica\n    List<Object> updates = (List<Object>)srsp.getSolrResponse().getResponse().get(\"updates\");\n\n    SyncShardRequest sreq = (SyncShardRequest) srsp.getShardRequest();\n    if (updates.size() < sreq.requestedUpdates.size()) {\n      log.error(msg() + \" Requested \" + sreq.requestedUpdates.size() + \" updates from \" + sreq.shards[0] + \" but retrieved \" + updates.size());\n      return false;\n    }\n\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(DISTRIB_UPDATE_PARAM, FROMLEADER.toString());\n    params.set(\"peersync\",true); // debugging\n    SolrQueryRequest req = new LocalSolrQueryRequest(uhandler.core, params);\n    SolrQueryResponse rsp = new SolrQueryResponse();\n\n    UpdateRequestProcessorChain processorChain = req.getCore().getUpdateProcessingChain(null);\n    UpdateRequestProcessor proc = processorChain.createProcessor(req, rsp);\n\n    Collections.sort(updates, updateRecordComparator);\n\n    Object o = null;\n    long lastVersion = 0;\n    try {\n      // Apply oldest updates first\n      for (Object obj : updates) {\n        // should currently be a List<Oper,Ver,Doc/Id>\n        o = obj;\n        List<Object> entry = (List<Object>)o;\n\n        if (debug) {\n          log.debug(msg() + \"raw update record \" + o);\n        }\n\n        int oper = (Integer)entry.get(0) & UpdateLog.OPERATION_MASK;\n        long version = (Long) entry.get(1);\n        if (version == lastVersion && version != 0) continue;\n        lastVersion = version;\n\n        switch (oper) {\n          case UpdateLog.ADD:\n          {\n            // byte[] idBytes = (byte[]) entry.get(2);\n            SolrInputDocument sdoc = (SolrInputDocument)entry.get(entry.size()-1);\n            AddUpdateCommand cmd = new AddUpdateCommand(req);\n            // cmd.setIndexedId(new BytesRef(idBytes));\n            cmd.solrDoc = sdoc;\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"add \" + cmd + \" id \" + sdoc.getField(\"id\"));\n            }\n            proc.processAdd(cmd);\n            break;\n          }\n          case UpdateLog.DELETE:\n          {\n            byte[] idBytes = (byte[]) entry.get(2);\n            DeleteUpdateCommand cmd = new DeleteUpdateCommand(req);\n            cmd.setIndexedId(new BytesRef(idBytes));\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"delete \" + cmd + \" \" + new BytesRef(idBytes).utf8ToString());\n            }\n            proc.processDelete(cmd);\n            break;\n          }\n\n          case UpdateLog.DELETE_BY_QUERY:\n          {\n            String query = (String)entry.get(2);\n            DeleteUpdateCommand cmd = new DeleteUpdateCommand(req);\n            cmd.query = query;\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"deleteByQuery \" + cmd);\n            }\n            proc.processDelete(cmd);\n            break;\n          }\n\n          default:\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n        }\n\n      }\n\n    }\n    catch (IOException e) {\n      // TODO: should this be handled separately as a problem with us?\n      // I guess it probably already will by causing replication to be kicked off.\n      sreq.updateException = e;\n      log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,update=\" + o, e);\n      return false;\n    }\n    catch (Exception e) {\n      sreq.updateException = e;\n      log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,update=\" + o, e);\n      return false;\n    }\n    finally {\n      try {\n        proc.finish();\n      } catch (Exception e) {\n        sreq.updateException = e;\n        log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,finish()\", e);\n        return false;\n      }\n    }\n\n    return true;\n  }\n\n","sourceOld":"  private boolean handleUpdates(ShardResponse srsp) {\n    // we retrieved the last N updates from the replica\n    List<Object> updates = (List<Object>)srsp.getSolrResponse().getResponse().get(\"updates\");\n\n    SyncShardRequest sreq = (SyncShardRequest) srsp.getShardRequest();\n    if (updates.size() < sreq.requestedUpdates.size()) {\n      log.error(msg() + \" Requested \" + sreq.requestedUpdates.size() + \" updates from \" + sreq.shards[0] + \" but retrieved \" + updates.size());\n      return false;\n    }\n\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(DISTRIB_UPDATE_PARAM, FROMLEADER.toString());\n    params.set(\"peersync\",true); // debugging\n    SolrQueryRequest req = new LocalSolrQueryRequest(uhandler.core, params);\n    SolrQueryResponse rsp = new SolrQueryResponse();\n\n    UpdateRequestProcessorChain processorChain = req.getCore().getUpdateProcessingChain(null);\n    UpdateRequestProcessor proc = processorChain.createProcessor(req, rsp);\n\n    Collections.sort(updates, updateRecordComparator);\n\n    Object o = null;\n    long lastVersion = 0;\n    try {\n      // Apply oldest updates first\n      for (Object obj : updates) {\n        // should currently be a List<Oper,Ver,Doc/Id>\n        o = obj;\n        List<Object> entry = (List<Object>)o;\n\n        if (debug) {\n          log.debug(msg() + \"raw update record \" + o);\n        }\n\n        int oper = (Integer)entry.get(0) & UpdateLog.OPERATION_MASK;\n        long version = (Long) entry.get(1);\n        if (version == lastVersion && version != 0) continue;\n        lastVersion = version;\n\n        switch (oper) {\n          case UpdateLog.ADD:\n          {\n            // byte[] idBytes = (byte[]) entry.get(2);\n            SolrInputDocument sdoc = (SolrInputDocument)entry.get(entry.size()-1);\n            AddUpdateCommand cmd = new AddUpdateCommand(req);\n            // cmd.setIndexedId(new BytesRef(idBytes));\n            cmd.solrDoc = sdoc;\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"add \" + cmd);\n            }\n            proc.processAdd(cmd);\n            break;\n          }\n          case UpdateLog.DELETE:\n          {\n            byte[] idBytes = (byte[]) entry.get(2);\n            DeleteUpdateCommand cmd = new DeleteUpdateCommand(req);\n            cmd.setIndexedId(new BytesRef(idBytes));\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"delete \" + cmd);\n            }\n            proc.processDelete(cmd);\n            break;\n          }\n\n          case UpdateLog.DELETE_BY_QUERY:\n          {\n            String query = (String)entry.get(2);\n            DeleteUpdateCommand cmd = new DeleteUpdateCommand(req);\n            cmd.query = query;\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"deleteByQuery \" + cmd);\n            }\n            proc.processDelete(cmd);\n            break;\n          }\n\n          default:\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n        }\n\n      }\n\n    }\n    catch (IOException e) {\n      // TODO: should this be handled separately as a problem with us?\n      // I guess it probably already will by causing replication to be kicked off.\n      sreq.updateException = e;\n      log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,update=\" + o, e);\n      return false;\n    }\n    catch (Exception e) {\n      sreq.updateException = e;\n      log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,update=\" + o, e);\n      return false;\n    }\n    finally {\n      try {\n        proc.finish();\n      } catch (Exception e) {\n        sreq.updateException = e;\n        log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,finish()\", e);\n        return false;\n      }\n    }\n\n    return true;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"979e22aa7c63c9dc651adf861610c7e444d45832","date":1454615713,"type":3,"author":"yonik","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/update/PeerSync#handleUpdates(ShardResponse).mjava","pathOld":"solr/core/src/java/org/apache/solr/update/PeerSync#handleUpdates(ShardResponse).mjava","sourceNew":"  private boolean handleUpdates(ShardResponse srsp) {\n    // we retrieved the last N updates from the replica\n    List<Object> updates = (List<Object>)srsp.getSolrResponse().getResponse().get(\"updates\");\n\n    SyncShardRequest sreq = (SyncShardRequest) srsp.getShardRequest();\n    if (updates.size() < sreq.requestedUpdates.size()) {\n      log.error(msg() + \" Requested \" + sreq.requestedUpdates.size() + \" updates from \" + sreq.shards[0] + \" but retrieved \" + updates.size());\n      return false;\n    }\n\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(DISTRIB_UPDATE_PARAM, FROMLEADER.toString());\n    params.set(\"peersync\",true); // debugging\n    SolrQueryRequest req = new LocalSolrQueryRequest(uhandler.core, params);\n    SolrQueryResponse rsp = new SolrQueryResponse();\n\n    UpdateRequestProcessorChain processorChain = req.getCore().getUpdateProcessingChain(null);\n    UpdateRequestProcessor proc = processorChain.createProcessor(req, rsp);\n\n    Collections.sort(updates, updateRecordComparator);\n\n    Object o = null;\n    long lastVersion = 0;\n    try {\n      // Apply oldest updates first\n      for (Object obj : updates) {\n        // should currently be a List<Oper,Ver,Doc/Id>\n        o = obj;\n        List<Object> entry = (List<Object>)o;\n\n        if (debug) {\n          log.debug(msg() + \"raw update record \" + o);\n        }\n\n        int oper = (Integer)entry.get(0) & UpdateLog.OPERATION_MASK;\n        long version = (Long) entry.get(1);\n        if (version == lastVersion && version != 0) continue;\n        lastVersion = version;\n\n        switch (oper) {\n          case UpdateLog.ADD:\n          {\n            // byte[] idBytes = (byte[]) entry.get(2);\n            SolrInputDocument sdoc = (SolrInputDocument)entry.get(entry.size()-1);\n            AddUpdateCommand cmd = new AddUpdateCommand(req);\n            // cmd.setIndexedId(new BytesRef(idBytes));\n            cmd.solrDoc = sdoc;\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"add \" + cmd + \" id \" + sdoc.getField(\"id\"));\n            }\n            proc.processAdd(cmd);\n            break;\n          }\n          case UpdateLog.DELETE:\n          {\n            byte[] idBytes = (byte[]) entry.get(2);\n            DeleteUpdateCommand cmd = new DeleteUpdateCommand(req);\n            cmd.setIndexedId(new BytesRef(idBytes));\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"delete \" + cmd + \" \" + new BytesRef(idBytes).utf8ToString());\n            }\n            proc.processDelete(cmd);\n            break;\n          }\n\n          case UpdateLog.DELETE_BY_QUERY:\n          {\n            String query = (String)entry.get(2);\n            DeleteUpdateCommand cmd = new DeleteUpdateCommand(req);\n            cmd.query = query;\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"deleteByQuery \" + cmd);\n            }\n            proc.processDelete(cmd);\n            break;\n          }\n\n          default:\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n        }\n\n      }\n\n    }\n    catch (IOException e) {\n      // TODO: should this be handled separately as a problem with us?\n      // I guess it probably already will by causing replication to be kicked off.\n      sreq.updateException = e;\n      log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,update=\" + o, e);\n      return false;\n    }\n    catch (Exception e) {\n      sreq.updateException = e;\n      log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,update=\" + o, e);\n      return false;\n    }\n    finally {\n      try {\n        proc.finish();\n      } catch (Exception e) {\n        sreq.updateException = e;\n        log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,finish()\", e);\n        return false;\n      }\n    }\n\n    return compareFingerprint(sreq);\n  }\n\n","sourceOld":"  private boolean handleUpdates(ShardResponse srsp) {\n    // we retrieved the last N updates from the replica\n    List<Object> updates = (List<Object>)srsp.getSolrResponse().getResponse().get(\"updates\");\n\n    SyncShardRequest sreq = (SyncShardRequest) srsp.getShardRequest();\n    if (updates.size() < sreq.requestedUpdates.size()) {\n      log.error(msg() + \" Requested \" + sreq.requestedUpdates.size() + \" updates from \" + sreq.shards[0] + \" but retrieved \" + updates.size());\n      return false;\n    }\n\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(DISTRIB_UPDATE_PARAM, FROMLEADER.toString());\n    params.set(\"peersync\",true); // debugging\n    SolrQueryRequest req = new LocalSolrQueryRequest(uhandler.core, params);\n    SolrQueryResponse rsp = new SolrQueryResponse();\n\n    UpdateRequestProcessorChain processorChain = req.getCore().getUpdateProcessingChain(null);\n    UpdateRequestProcessor proc = processorChain.createProcessor(req, rsp);\n\n    Collections.sort(updates, updateRecordComparator);\n\n    Object o = null;\n    long lastVersion = 0;\n    try {\n      // Apply oldest updates first\n      for (Object obj : updates) {\n        // should currently be a List<Oper,Ver,Doc/Id>\n        o = obj;\n        List<Object> entry = (List<Object>)o;\n\n        if (debug) {\n          log.debug(msg() + \"raw update record \" + o);\n        }\n\n        int oper = (Integer)entry.get(0) & UpdateLog.OPERATION_MASK;\n        long version = (Long) entry.get(1);\n        if (version == lastVersion && version != 0) continue;\n        lastVersion = version;\n\n        switch (oper) {\n          case UpdateLog.ADD:\n          {\n            // byte[] idBytes = (byte[]) entry.get(2);\n            SolrInputDocument sdoc = (SolrInputDocument)entry.get(entry.size()-1);\n            AddUpdateCommand cmd = new AddUpdateCommand(req);\n            // cmd.setIndexedId(new BytesRef(idBytes));\n            cmd.solrDoc = sdoc;\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"add \" + cmd + \" id \" + sdoc.getField(\"id\"));\n            }\n            proc.processAdd(cmd);\n            break;\n          }\n          case UpdateLog.DELETE:\n          {\n            byte[] idBytes = (byte[]) entry.get(2);\n            DeleteUpdateCommand cmd = new DeleteUpdateCommand(req);\n            cmd.setIndexedId(new BytesRef(idBytes));\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"delete \" + cmd + \" \" + new BytesRef(idBytes).utf8ToString());\n            }\n            proc.processDelete(cmd);\n            break;\n          }\n\n          case UpdateLog.DELETE_BY_QUERY:\n          {\n            String query = (String)entry.get(2);\n            DeleteUpdateCommand cmd = new DeleteUpdateCommand(req);\n            cmd.query = query;\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"deleteByQuery \" + cmd);\n            }\n            proc.processDelete(cmd);\n            break;\n          }\n\n          default:\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n        }\n\n      }\n\n    }\n    catch (IOException e) {\n      // TODO: should this be handled separately as a problem with us?\n      // I guess it probably already will by causing replication to be kicked off.\n      sreq.updateException = e;\n      log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,update=\" + o, e);\n      return false;\n    }\n    catch (Exception e) {\n      sreq.updateException = e;\n      log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,update=\" + o, e);\n      return false;\n    }\n    finally {\n      try {\n        proc.finish();\n      } catch (Exception e) {\n        sreq.updateException = e;\n        log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,finish()\", e);\n        return false;\n      }\n    }\n\n    return true;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b1704c078ec59838c9d95d5bf5738b393b537494","date":1454693901,"type":3,"author":"Mike McCandless","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/update/PeerSync#handleUpdates(ShardResponse).mjava","pathOld":"solr/core/src/java/org/apache/solr/update/PeerSync#handleUpdates(ShardResponse).mjava","sourceNew":"  private boolean handleUpdates(ShardResponse srsp) {\n    // we retrieved the last N updates from the replica\n    List<Object> updates = (List<Object>)srsp.getSolrResponse().getResponse().get(\"updates\");\n\n    SyncShardRequest sreq = (SyncShardRequest) srsp.getShardRequest();\n    if (updates.size() < sreq.requestedUpdates.size()) {\n      log.error(msg() + \" Requested \" + sreq.requestedUpdates.size() + \" updates from \" + sreq.shards[0] + \" but retrieved \" + updates.size());\n      return false;\n    }\n\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(DISTRIB_UPDATE_PARAM, FROMLEADER.toString());\n    params.set(\"peersync\",true); // debugging\n    SolrQueryRequest req = new LocalSolrQueryRequest(uhandler.core, params);\n    SolrQueryResponse rsp = new SolrQueryResponse();\n\n    UpdateRequestProcessorChain processorChain = req.getCore().getUpdateProcessingChain(null);\n    UpdateRequestProcessor proc = processorChain.createProcessor(req, rsp);\n\n    Collections.sort(updates, updateRecordComparator);\n\n    Object o = null;\n    long lastVersion = 0;\n    try {\n      // Apply oldest updates first\n      for (Object obj : updates) {\n        // should currently be a List<Oper,Ver,Doc/Id>\n        o = obj;\n        List<Object> entry = (List<Object>)o;\n\n        if (debug) {\n          log.debug(msg() + \"raw update record \" + o);\n        }\n\n        int oper = (Integer)entry.get(0) & UpdateLog.OPERATION_MASK;\n        long version = (Long) entry.get(1);\n        if (version == lastVersion && version != 0) continue;\n        lastVersion = version;\n\n        switch (oper) {\n          case UpdateLog.ADD:\n          {\n            // byte[] idBytes = (byte[]) entry.get(2);\n            SolrInputDocument sdoc = (SolrInputDocument)entry.get(entry.size()-1);\n            AddUpdateCommand cmd = new AddUpdateCommand(req);\n            // cmd.setIndexedId(new BytesRef(idBytes));\n            cmd.solrDoc = sdoc;\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"add \" + cmd + \" id \" + sdoc.getField(\"id\"));\n            }\n            proc.processAdd(cmd);\n            break;\n          }\n          case UpdateLog.DELETE:\n          {\n            byte[] idBytes = (byte[]) entry.get(2);\n            DeleteUpdateCommand cmd = new DeleteUpdateCommand(req);\n            cmd.setIndexedId(new BytesRef(idBytes));\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"delete \" + cmd + \" \" + new BytesRef(idBytes).utf8ToString());\n            }\n            proc.processDelete(cmd);\n            break;\n          }\n\n          case UpdateLog.DELETE_BY_QUERY:\n          {\n            String query = (String)entry.get(2);\n            DeleteUpdateCommand cmd = new DeleteUpdateCommand(req);\n            cmd.query = query;\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"deleteByQuery \" + cmd);\n            }\n            proc.processDelete(cmd);\n            break;\n          }\n\n          default:\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n        }\n\n      }\n\n    }\n    catch (IOException e) {\n      // TODO: should this be handled separately as a problem with us?\n      // I guess it probably already will by causing replication to be kicked off.\n      sreq.updateException = e;\n      log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,update=\" + o, e);\n      return false;\n    }\n    catch (Exception e) {\n      sreq.updateException = e;\n      log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,update=\" + o, e);\n      return false;\n    }\n    finally {\n      try {\n        proc.finish();\n      } catch (Exception e) {\n        sreq.updateException = e;\n        log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,finish()\", e);\n        return false;\n      }\n    }\n\n    return compareFingerprint(sreq);\n  }\n\n","sourceOld":"  private boolean handleUpdates(ShardResponse srsp) {\n    // we retrieved the last N updates from the replica\n    List<Object> updates = (List<Object>)srsp.getSolrResponse().getResponse().get(\"updates\");\n\n    SyncShardRequest sreq = (SyncShardRequest) srsp.getShardRequest();\n    if (updates.size() < sreq.requestedUpdates.size()) {\n      log.error(msg() + \" Requested \" + sreq.requestedUpdates.size() + \" updates from \" + sreq.shards[0] + \" but retrieved \" + updates.size());\n      return false;\n    }\n\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(DISTRIB_UPDATE_PARAM, FROMLEADER.toString());\n    params.set(\"peersync\",true); // debugging\n    SolrQueryRequest req = new LocalSolrQueryRequest(uhandler.core, params);\n    SolrQueryResponse rsp = new SolrQueryResponse();\n\n    UpdateRequestProcessorChain processorChain = req.getCore().getUpdateProcessingChain(null);\n    UpdateRequestProcessor proc = processorChain.createProcessor(req, rsp);\n\n    Collections.sort(updates, updateRecordComparator);\n\n    Object o = null;\n    long lastVersion = 0;\n    try {\n      // Apply oldest updates first\n      for (Object obj : updates) {\n        // should currently be a List<Oper,Ver,Doc/Id>\n        o = obj;\n        List<Object> entry = (List<Object>)o;\n\n        if (debug) {\n          log.debug(msg() + \"raw update record \" + o);\n        }\n\n        int oper = (Integer)entry.get(0) & UpdateLog.OPERATION_MASK;\n        long version = (Long) entry.get(1);\n        if (version == lastVersion && version != 0) continue;\n        lastVersion = version;\n\n        switch (oper) {\n          case UpdateLog.ADD:\n          {\n            // byte[] idBytes = (byte[]) entry.get(2);\n            SolrInputDocument sdoc = (SolrInputDocument)entry.get(entry.size()-1);\n            AddUpdateCommand cmd = new AddUpdateCommand(req);\n            // cmd.setIndexedId(new BytesRef(idBytes));\n            cmd.solrDoc = sdoc;\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"add \" + cmd + \" id \" + sdoc.getField(\"id\"));\n            }\n            proc.processAdd(cmd);\n            break;\n          }\n          case UpdateLog.DELETE:\n          {\n            byte[] idBytes = (byte[]) entry.get(2);\n            DeleteUpdateCommand cmd = new DeleteUpdateCommand(req);\n            cmd.setIndexedId(new BytesRef(idBytes));\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"delete \" + cmd + \" \" + new BytesRef(idBytes).utf8ToString());\n            }\n            proc.processDelete(cmd);\n            break;\n          }\n\n          case UpdateLog.DELETE_BY_QUERY:\n          {\n            String query = (String)entry.get(2);\n            DeleteUpdateCommand cmd = new DeleteUpdateCommand(req);\n            cmd.query = query;\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"deleteByQuery \" + cmd);\n            }\n            proc.processDelete(cmd);\n            break;\n          }\n\n          default:\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n        }\n\n      }\n\n    }\n    catch (IOException e) {\n      // TODO: should this be handled separately as a problem with us?\n      // I guess it probably already will by causing replication to be kicked off.\n      sreq.updateException = e;\n      log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,update=\" + o, e);\n      return false;\n    }\n    catch (Exception e) {\n      sreq.updateException = e;\n      log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,update=\" + o, e);\n      return false;\n    }\n    finally {\n      try {\n        proc.finish();\n      } catch (Exception e) {\n        sreq.updateException = e;\n        log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,finish()\", e);\n        return false;\n      }\n    }\n\n    return true;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1e6acbaae7af722f17204ceccf0f7db5753eccf3","date":1454775255,"type":3,"author":"Mike McCandless","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/update/PeerSync#handleUpdates(ShardResponse).mjava","pathOld":"solr/core/src/java/org/apache/solr/update/PeerSync#handleUpdates(ShardResponse).mjava","sourceNew":"  private boolean handleUpdates(ShardResponse srsp) {\n    // we retrieved the last N updates from the replica\n    List<Object> updates = (List<Object>)srsp.getSolrResponse().getResponse().get(\"updates\");\n\n    SyncShardRequest sreq = (SyncShardRequest) srsp.getShardRequest();\n    if (updates.size() < sreq.requestedUpdates.size()) {\n      log.error(msg() + \" Requested \" + sreq.requestedUpdates.size() + \" updates from \" + sreq.shards[0] + \" but retrieved \" + updates.size());\n      return false;\n    }\n\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(DISTRIB_UPDATE_PARAM, FROMLEADER.toString());\n    params.set(\"peersync\",true); // debugging\n    SolrQueryRequest req = new LocalSolrQueryRequest(uhandler.core, params);\n    SolrQueryResponse rsp = new SolrQueryResponse();\n\n    UpdateRequestProcessorChain processorChain = req.getCore().getUpdateProcessingChain(null);\n    UpdateRequestProcessor proc = processorChain.createProcessor(req, rsp);\n\n    Collections.sort(updates, updateRecordComparator);\n\n    Object o = null;\n    long lastVersion = 0;\n    try {\n      // Apply oldest updates first\n      for (Object obj : updates) {\n        // should currently be a List<Oper,Ver,Doc/Id>\n        o = obj;\n        List<Object> entry = (List<Object>)o;\n\n        if (debug) {\n          log.debug(msg() + \"raw update record \" + o);\n        }\n\n        int oper = (Integer)entry.get(0) & UpdateLog.OPERATION_MASK;\n        long version = (Long) entry.get(1);\n        if (version == lastVersion && version != 0) continue;\n        lastVersion = version;\n\n        switch (oper) {\n          case UpdateLog.ADD:\n          {\n            // byte[] idBytes = (byte[]) entry.get(2);\n            SolrInputDocument sdoc = (SolrInputDocument)entry.get(entry.size()-1);\n            AddUpdateCommand cmd = new AddUpdateCommand(req);\n            // cmd.setIndexedId(new BytesRef(idBytes));\n            cmd.solrDoc = sdoc;\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"add \" + cmd + \" id \" + sdoc.getField(\"id\"));\n            }\n            proc.processAdd(cmd);\n            break;\n          }\n          case UpdateLog.DELETE:\n          {\n            byte[] idBytes = (byte[]) entry.get(2);\n            DeleteUpdateCommand cmd = new DeleteUpdateCommand(req);\n            cmd.setIndexedId(new BytesRef(idBytes));\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"delete \" + cmd + \" \" + new BytesRef(idBytes).utf8ToString());\n            }\n            proc.processDelete(cmd);\n            break;\n          }\n\n          case UpdateLog.DELETE_BY_QUERY:\n          {\n            String query = (String)entry.get(2);\n            DeleteUpdateCommand cmd = new DeleteUpdateCommand(req);\n            cmd.query = query;\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"deleteByQuery \" + cmd);\n            }\n            proc.processDelete(cmd);\n            break;\n          }\n\n          default:\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n        }\n\n      }\n\n    }\n    catch (IOException e) {\n      // TODO: should this be handled separately as a problem with us?\n      // I guess it probably already will by causing replication to be kicked off.\n      sreq.updateException = e;\n      log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,update=\" + o, e);\n      return false;\n    }\n    catch (Exception e) {\n      sreq.updateException = e;\n      log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,update=\" + o, e);\n      return false;\n    }\n    finally {\n      try {\n        proc.finish();\n      } catch (Exception e) {\n        sreq.updateException = e;\n        log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,finish()\", e);\n        return false;\n      }\n    }\n\n    return compareFingerprint(sreq);\n  }\n\n","sourceOld":"  private boolean handleUpdates(ShardResponse srsp) {\n    // we retrieved the last N updates from the replica\n    List<Object> updates = (List<Object>)srsp.getSolrResponse().getResponse().get(\"updates\");\n\n    SyncShardRequest sreq = (SyncShardRequest) srsp.getShardRequest();\n    if (updates.size() < sreq.requestedUpdates.size()) {\n      log.error(msg() + \" Requested \" + sreq.requestedUpdates.size() + \" updates from \" + sreq.shards[0] + \" but retrieved \" + updates.size());\n      return false;\n    }\n\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(DISTRIB_UPDATE_PARAM, FROMLEADER.toString());\n    params.set(\"peersync\",true); // debugging\n    SolrQueryRequest req = new LocalSolrQueryRequest(uhandler.core, params);\n    SolrQueryResponse rsp = new SolrQueryResponse();\n\n    UpdateRequestProcessorChain processorChain = req.getCore().getUpdateProcessingChain(null);\n    UpdateRequestProcessor proc = processorChain.createProcessor(req, rsp);\n\n    Collections.sort(updates, updateRecordComparator);\n\n    Object o = null;\n    long lastVersion = 0;\n    try {\n      // Apply oldest updates first\n      for (Object obj : updates) {\n        // should currently be a List<Oper,Ver,Doc/Id>\n        o = obj;\n        List<Object> entry = (List<Object>)o;\n\n        if (debug) {\n          log.debug(msg() + \"raw update record \" + o);\n        }\n\n        int oper = (Integer)entry.get(0) & UpdateLog.OPERATION_MASK;\n        long version = (Long) entry.get(1);\n        if (version == lastVersion && version != 0) continue;\n        lastVersion = version;\n\n        switch (oper) {\n          case UpdateLog.ADD:\n          {\n            // byte[] idBytes = (byte[]) entry.get(2);\n            SolrInputDocument sdoc = (SolrInputDocument)entry.get(entry.size()-1);\n            AddUpdateCommand cmd = new AddUpdateCommand(req);\n            // cmd.setIndexedId(new BytesRef(idBytes));\n            cmd.solrDoc = sdoc;\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"add \" + cmd + \" id \" + sdoc.getField(\"id\"));\n            }\n            proc.processAdd(cmd);\n            break;\n          }\n          case UpdateLog.DELETE:\n          {\n            byte[] idBytes = (byte[]) entry.get(2);\n            DeleteUpdateCommand cmd = new DeleteUpdateCommand(req);\n            cmd.setIndexedId(new BytesRef(idBytes));\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"delete \" + cmd + \" \" + new BytesRef(idBytes).utf8ToString());\n            }\n            proc.processDelete(cmd);\n            break;\n          }\n\n          case UpdateLog.DELETE_BY_QUERY:\n          {\n            String query = (String)entry.get(2);\n            DeleteUpdateCommand cmd = new DeleteUpdateCommand(req);\n            cmd.query = query;\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"deleteByQuery \" + cmd);\n            }\n            proc.processDelete(cmd);\n            break;\n          }\n\n          default:\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n        }\n\n      }\n\n    }\n    catch (IOException e) {\n      // TODO: should this be handled separately as a problem with us?\n      // I guess it probably already will by causing replication to be kicked off.\n      sreq.updateException = e;\n      log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,update=\" + o, e);\n      return false;\n    }\n    catch (Exception e) {\n      sreq.updateException = e;\n      log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,update=\" + o, e);\n      return false;\n    }\n    finally {\n      try {\n        proc.finish();\n      } catch (Exception e) {\n        sreq.updateException = e;\n        log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,finish()\", e);\n        return false;\n      }\n    }\n\n    return true;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e511b092029d56e0d4e30204fba8509c1c2647b6","date":1467838965,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/update/PeerSync#handleUpdates(ShardResponse).mjava","pathOld":"solr/core/src/java/org/apache/solr/update/PeerSync#handleUpdates(ShardResponse).mjava","sourceNew":"  private boolean handleUpdates(ShardResponse srsp) {\n    // we retrieved the last N updates from the replica\n    List<Object> updates = (List<Object>)srsp.getSolrResponse().getResponse().get(\"updates\");\n\n    SyncShardRequest sreq = (SyncShardRequest) srsp.getShardRequest();\n    if (updates.size() < sreq.totalRequestedUpdates) {\n      log.error(msg() + \" Requested \" + sreq.requestedUpdates.size() + \" updates from \" + sreq.shards[0] + \" but retrieved \" + updates.size());\n      return false;\n    }\n\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(DISTRIB_UPDATE_PARAM, FROMLEADER.toString());\n    params.set(\"peersync\",true); // debugging\n    SolrQueryRequest req = new LocalSolrQueryRequest(uhandler.core, params);\n    SolrQueryResponse rsp = new SolrQueryResponse();\n\n    UpdateRequestProcessorChain processorChain = req.getCore().getUpdateProcessingChain(null);\n    UpdateRequestProcessor proc = processorChain.createProcessor(req, rsp);\n\n    Collections.sort(updates, updateRecordComparator);\n\n    Object o = null;\n    long lastVersion = 0;\n    try {\n      // Apply oldest updates first\n      for (Object obj : updates) {\n        // should currently be a List<Oper,Ver,Doc/Id>\n        o = obj;\n        List<Object> entry = (List<Object>)o;\n\n        if (debug) {\n          log.debug(msg() + \"raw update record \" + o);\n        }\n\n        int oper = (Integer)entry.get(0) & UpdateLog.OPERATION_MASK;\n        long version = (Long) entry.get(1);\n        if (version == lastVersion && version != 0) continue;\n        lastVersion = version;\n\n        switch (oper) {\n          case UpdateLog.ADD:\n          {\n            // byte[] idBytes = (byte[]) entry.get(2);\n            SolrInputDocument sdoc = (SolrInputDocument)entry.get(entry.size()-1);\n            AddUpdateCommand cmd = new AddUpdateCommand(req);\n            // cmd.setIndexedId(new BytesRef(idBytes));\n            cmd.solrDoc = sdoc;\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"add \" + cmd + \" id \" + sdoc.getField(\"id\"));\n            }\n            proc.processAdd(cmd);\n            break;\n          }\n          case UpdateLog.DELETE:\n          {\n            byte[] idBytes = (byte[]) entry.get(2);\n            DeleteUpdateCommand cmd = new DeleteUpdateCommand(req);\n            cmd.setIndexedId(new BytesRef(idBytes));\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"delete \" + cmd + \" \" + new BytesRef(idBytes).utf8ToString());\n            }\n            proc.processDelete(cmd);\n            break;\n          }\n\n          case UpdateLog.DELETE_BY_QUERY:\n          {\n            String query = (String)entry.get(2);\n            DeleteUpdateCommand cmd = new DeleteUpdateCommand(req);\n            cmd.query = query;\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"deleteByQuery \" + cmd);\n            }\n            proc.processDelete(cmd);\n            break;\n          }\n\n          default:\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n        }\n\n      }\n\n    }\n    catch (IOException e) {\n      // TODO: should this be handled separately as a problem with us?\n      // I guess it probably already will by causing replication to be kicked off.\n      sreq.updateException = e;\n      log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,update=\" + o, e);\n      return false;\n    }\n    catch (Exception e) {\n      sreq.updateException = e;\n      log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,update=\" + o, e);\n      return false;\n    }\n    finally {\n      try {\n        proc.finish();\n      } catch (Exception e) {\n        sreq.updateException = e;\n        log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,finish()\", e);\n        return false;\n      }\n    }\n\n    return compareFingerprint(sreq);\n  }\n\n","sourceOld":"  private boolean handleUpdates(ShardResponse srsp) {\n    // we retrieved the last N updates from the replica\n    List<Object> updates = (List<Object>)srsp.getSolrResponse().getResponse().get(\"updates\");\n\n    SyncShardRequest sreq = (SyncShardRequest) srsp.getShardRequest();\n    if (updates.size() < sreq.requestedUpdates.size()) {\n      log.error(msg() + \" Requested \" + sreq.requestedUpdates.size() + \" updates from \" + sreq.shards[0] + \" but retrieved \" + updates.size());\n      return false;\n    }\n\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(DISTRIB_UPDATE_PARAM, FROMLEADER.toString());\n    params.set(\"peersync\",true); // debugging\n    SolrQueryRequest req = new LocalSolrQueryRequest(uhandler.core, params);\n    SolrQueryResponse rsp = new SolrQueryResponse();\n\n    UpdateRequestProcessorChain processorChain = req.getCore().getUpdateProcessingChain(null);\n    UpdateRequestProcessor proc = processorChain.createProcessor(req, rsp);\n\n    Collections.sort(updates, updateRecordComparator);\n\n    Object o = null;\n    long lastVersion = 0;\n    try {\n      // Apply oldest updates first\n      for (Object obj : updates) {\n        // should currently be a List<Oper,Ver,Doc/Id>\n        o = obj;\n        List<Object> entry = (List<Object>)o;\n\n        if (debug) {\n          log.debug(msg() + \"raw update record \" + o);\n        }\n\n        int oper = (Integer)entry.get(0) & UpdateLog.OPERATION_MASK;\n        long version = (Long) entry.get(1);\n        if (version == lastVersion && version != 0) continue;\n        lastVersion = version;\n\n        switch (oper) {\n          case UpdateLog.ADD:\n          {\n            // byte[] idBytes = (byte[]) entry.get(2);\n            SolrInputDocument sdoc = (SolrInputDocument)entry.get(entry.size()-1);\n            AddUpdateCommand cmd = new AddUpdateCommand(req);\n            // cmd.setIndexedId(new BytesRef(idBytes));\n            cmd.solrDoc = sdoc;\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"add \" + cmd + \" id \" + sdoc.getField(\"id\"));\n            }\n            proc.processAdd(cmd);\n            break;\n          }\n          case UpdateLog.DELETE:\n          {\n            byte[] idBytes = (byte[]) entry.get(2);\n            DeleteUpdateCommand cmd = new DeleteUpdateCommand(req);\n            cmd.setIndexedId(new BytesRef(idBytes));\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"delete \" + cmd + \" \" + new BytesRef(idBytes).utf8ToString());\n            }\n            proc.processDelete(cmd);\n            break;\n          }\n\n          case UpdateLog.DELETE_BY_QUERY:\n          {\n            String query = (String)entry.get(2);\n            DeleteUpdateCommand cmd = new DeleteUpdateCommand(req);\n            cmd.query = query;\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"deleteByQuery \" + cmd);\n            }\n            proc.processDelete(cmd);\n            break;\n          }\n\n          default:\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n        }\n\n      }\n\n    }\n    catch (IOException e) {\n      // TODO: should this be handled separately as a problem with us?\n      // I guess it probably already will by causing replication to be kicked off.\n      sreq.updateException = e;\n      log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,update=\" + o, e);\n      return false;\n    }\n    catch (Exception e) {\n      sreq.updateException = e;\n      log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,update=\" + o, e);\n      return false;\n    }\n    finally {\n      try {\n        proc.finish();\n      } catch (Exception e) {\n        sreq.updateException = e;\n        log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,finish()\", e);\n        return false;\n      }\n    }\n\n    return compareFingerprint(sreq);\n  }\n\n","bugFix":["2c007e7c4cf8c55bc2a5884e315123afaaeec87f"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8381eb1cd44d2e0defb52130de3295a576ac1e7b","date":1467840340,"type":3,"author":"Chris Hostetter","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/update/PeerSync#handleUpdates(ShardResponse).mjava","pathOld":"solr/core/src/java/org/apache/solr/update/PeerSync#handleUpdates(ShardResponse).mjava","sourceNew":"  private boolean handleUpdates(ShardResponse srsp) {\n    // we retrieved the last N updates from the replica\n    List<Object> updates = (List<Object>)srsp.getSolrResponse().getResponse().get(\"updates\");\n\n    SyncShardRequest sreq = (SyncShardRequest) srsp.getShardRequest();\n    if (updates.size() < sreq.totalRequestedUpdates) {\n      log.error(msg() + \" Requested \" + sreq.requestedUpdates.size() + \" updates from \" + sreq.shards[0] + \" but retrieved \" + updates.size());\n      return false;\n    }\n\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(DISTRIB_UPDATE_PARAM, FROMLEADER.toString());\n    params.set(\"peersync\",true); // debugging\n    SolrQueryRequest req = new LocalSolrQueryRequest(uhandler.core, params);\n    SolrQueryResponse rsp = new SolrQueryResponse();\n\n    UpdateRequestProcessorChain processorChain = req.getCore().getUpdateProcessingChain(null);\n    UpdateRequestProcessor proc = processorChain.createProcessor(req, rsp);\n\n    Collections.sort(updates, updateRecordComparator);\n\n    Object o = null;\n    long lastVersion = 0;\n    try {\n      // Apply oldest updates first\n      for (Object obj : updates) {\n        // should currently be a List<Oper,Ver,Doc/Id>\n        o = obj;\n        List<Object> entry = (List<Object>)o;\n\n        if (debug) {\n          log.debug(msg() + \"raw update record \" + o);\n        }\n\n        int oper = (Integer)entry.get(0) & UpdateLog.OPERATION_MASK;\n        long version = (Long) entry.get(1);\n        if (version == lastVersion && version != 0) continue;\n        lastVersion = version;\n\n        switch (oper) {\n          case UpdateLog.ADD:\n          {\n            // byte[] idBytes = (byte[]) entry.get(2);\n            SolrInputDocument sdoc = (SolrInputDocument)entry.get(entry.size()-1);\n            AddUpdateCommand cmd = new AddUpdateCommand(req);\n            // cmd.setIndexedId(new BytesRef(idBytes));\n            cmd.solrDoc = sdoc;\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"add \" + cmd + \" id \" + sdoc.getField(\"id\"));\n            }\n            proc.processAdd(cmd);\n            break;\n          }\n          case UpdateLog.DELETE:\n          {\n            byte[] idBytes = (byte[]) entry.get(2);\n            DeleteUpdateCommand cmd = new DeleteUpdateCommand(req);\n            cmd.setIndexedId(new BytesRef(idBytes));\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"delete \" + cmd + \" \" + new BytesRef(idBytes).utf8ToString());\n            }\n            proc.processDelete(cmd);\n            break;\n          }\n\n          case UpdateLog.DELETE_BY_QUERY:\n          {\n            String query = (String)entry.get(2);\n            DeleteUpdateCommand cmd = new DeleteUpdateCommand(req);\n            cmd.query = query;\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"deleteByQuery \" + cmd);\n            }\n            proc.processDelete(cmd);\n            break;\n          }\n\n          default:\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n        }\n\n      }\n\n    }\n    catch (IOException e) {\n      // TODO: should this be handled separately as a problem with us?\n      // I guess it probably already will by causing replication to be kicked off.\n      sreq.updateException = e;\n      log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,update=\" + o, e);\n      return false;\n    }\n    catch (Exception e) {\n      sreq.updateException = e;\n      log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,update=\" + o, e);\n      return false;\n    }\n    finally {\n      try {\n        proc.finish();\n      } catch (Exception e) {\n        sreq.updateException = e;\n        log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,finish()\", e);\n        return false;\n      }\n    }\n\n    return compareFingerprint(sreq);\n  }\n\n","sourceOld":"  private boolean handleUpdates(ShardResponse srsp) {\n    // we retrieved the last N updates from the replica\n    List<Object> updates = (List<Object>)srsp.getSolrResponse().getResponse().get(\"updates\");\n\n    SyncShardRequest sreq = (SyncShardRequest) srsp.getShardRequest();\n    if (updates.size() < sreq.requestedUpdates.size()) {\n      log.error(msg() + \" Requested \" + sreq.requestedUpdates.size() + \" updates from \" + sreq.shards[0] + \" but retrieved \" + updates.size());\n      return false;\n    }\n\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(DISTRIB_UPDATE_PARAM, FROMLEADER.toString());\n    params.set(\"peersync\",true); // debugging\n    SolrQueryRequest req = new LocalSolrQueryRequest(uhandler.core, params);\n    SolrQueryResponse rsp = new SolrQueryResponse();\n\n    UpdateRequestProcessorChain processorChain = req.getCore().getUpdateProcessingChain(null);\n    UpdateRequestProcessor proc = processorChain.createProcessor(req, rsp);\n\n    Collections.sort(updates, updateRecordComparator);\n\n    Object o = null;\n    long lastVersion = 0;\n    try {\n      // Apply oldest updates first\n      for (Object obj : updates) {\n        // should currently be a List<Oper,Ver,Doc/Id>\n        o = obj;\n        List<Object> entry = (List<Object>)o;\n\n        if (debug) {\n          log.debug(msg() + \"raw update record \" + o);\n        }\n\n        int oper = (Integer)entry.get(0) & UpdateLog.OPERATION_MASK;\n        long version = (Long) entry.get(1);\n        if (version == lastVersion && version != 0) continue;\n        lastVersion = version;\n\n        switch (oper) {\n          case UpdateLog.ADD:\n          {\n            // byte[] idBytes = (byte[]) entry.get(2);\n            SolrInputDocument sdoc = (SolrInputDocument)entry.get(entry.size()-1);\n            AddUpdateCommand cmd = new AddUpdateCommand(req);\n            // cmd.setIndexedId(new BytesRef(idBytes));\n            cmd.solrDoc = sdoc;\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"add \" + cmd + \" id \" + sdoc.getField(\"id\"));\n            }\n            proc.processAdd(cmd);\n            break;\n          }\n          case UpdateLog.DELETE:\n          {\n            byte[] idBytes = (byte[]) entry.get(2);\n            DeleteUpdateCommand cmd = new DeleteUpdateCommand(req);\n            cmd.setIndexedId(new BytesRef(idBytes));\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"delete \" + cmd + \" \" + new BytesRef(idBytes).utf8ToString());\n            }\n            proc.processDelete(cmd);\n            break;\n          }\n\n          case UpdateLog.DELETE_BY_QUERY:\n          {\n            String query = (String)entry.get(2);\n            DeleteUpdateCommand cmd = new DeleteUpdateCommand(req);\n            cmd.query = query;\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"deleteByQuery \" + cmd);\n            }\n            proc.processDelete(cmd);\n            break;\n          }\n\n          default:\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n        }\n\n      }\n\n    }\n    catch (IOException e) {\n      // TODO: should this be handled separately as a problem with us?\n      // I guess it probably already will by causing replication to be kicked off.\n      sreq.updateException = e;\n      log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,update=\" + o, e);\n      return false;\n    }\n    catch (Exception e) {\n      sreq.updateException = e;\n      log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,update=\" + o, e);\n      return false;\n    }\n    finally {\n      try {\n        proc.finish();\n      } catch (Exception e) {\n        sreq.updateException = e;\n        log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,finish()\", e);\n        return false;\n      }\n    }\n\n    return compareFingerprint(sreq);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4c835cc1a7b07477a469cdb1bf6c67bc05b85c07","date":1471849333,"type":3,"author":"Noble Paul","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/update/PeerSync#handleUpdates(ShardResponse).mjava","pathOld":"solr/core/src/java/org/apache/solr/update/PeerSync#handleUpdates(ShardResponse).mjava","sourceNew":"  private boolean handleUpdates(ShardResponse srsp) {\n    // we retrieved the last N updates from the replica\n    List<Object> updates = (List<Object>)srsp.getSolrResponse().getResponse().get(\"updates\");\n\n    SyncShardRequest sreq = (SyncShardRequest) srsp.getShardRequest();\n    if (updates.size() < sreq.totalRequestedUpdates) {\n      log.error(msg() + \" Requested \" + sreq.totalRequestedUpdates + \" updates from \" + sreq.shards[0] + \" but retrieved \" + updates.size());\n      return false;\n    }\n    \n    // overwrite fingerprint we saved in 'handleVersions()'   \n    Object fingerprint = srsp.getSolrResponse().getResponse().get(\"fingerprint\");\n\n    if (fingerprint != null) {\n      sreq.fingerprint = IndexFingerprint.fromObject(fingerprint);\n    }\n\n\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(DISTRIB_UPDATE_PARAM, FROMLEADER.toString());\n    params.set(\"peersync\",true); // debugging\n    SolrQueryRequest req = new LocalSolrQueryRequest(uhandler.core, params);\n    SolrQueryResponse rsp = new SolrQueryResponse();\n\n    UpdateRequestProcessorChain processorChain = req.getCore().getUpdateProcessingChain(null);\n    UpdateRequestProcessor proc = processorChain.createProcessor(req, rsp);\n\n    Collections.sort(updates, updateRecordComparator);\n\n    Object o = null;\n    long lastVersion = 0;\n    try {\n      // Apply oldest updates first\n      for (Object obj : updates) {\n        // should currently be a List<Oper,Ver,Doc/Id>\n        o = obj;\n        List<Object> entry = (List<Object>)o;\n\n        if (debug) {\n          log.debug(msg() + \"raw update record \" + o);\n        }\n\n        int oper = (Integer)entry.get(0) & UpdateLog.OPERATION_MASK;\n        long version = (Long) entry.get(1);\n        if (version == lastVersion && version != 0) continue;\n        lastVersion = version;\n\n        switch (oper) {\n          case UpdateLog.ADD:\n          {\n            // byte[] idBytes = (byte[]) entry.get(2);\n            SolrInputDocument sdoc = (SolrInputDocument)entry.get(entry.size()-1);\n            AddUpdateCommand cmd = new AddUpdateCommand(req);\n            // cmd.setIndexedId(new BytesRef(idBytes));\n            cmd.solrDoc = sdoc;\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"add \" + cmd + \" id \" + sdoc.getField(\"id\"));\n            }\n            proc.processAdd(cmd);\n            break;\n          }\n          case UpdateLog.DELETE:\n          {\n            byte[] idBytes = (byte[]) entry.get(2);\n            DeleteUpdateCommand cmd = new DeleteUpdateCommand(req);\n            cmd.setIndexedId(new BytesRef(idBytes));\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"delete \" + cmd + \" \" + new BytesRef(idBytes).utf8ToString());\n            }\n            proc.processDelete(cmd);\n            break;\n          }\n\n          case UpdateLog.DELETE_BY_QUERY:\n          {\n            String query = (String)entry.get(2);\n            DeleteUpdateCommand cmd = new DeleteUpdateCommand(req);\n            cmd.query = query;\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"deleteByQuery \" + cmd);\n            }\n            proc.processDelete(cmd);\n            break;\n          }\n\n          default:\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n        }\n\n      }\n\n    }\n    catch (IOException e) {\n      // TODO: should this be handled separately as a problem with us?\n      // I guess it probably already will by causing replication to be kicked off.\n      sreq.updateException = e;\n      log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,update=\" + o, e);\n      return false;\n    }\n    catch (Exception e) {\n      sreq.updateException = e;\n      log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,update=\" + o, e);\n      return false;\n    }\n    finally {\n      try {\n        proc.finish();\n      } catch (Exception e) {\n        sreq.updateException = e;\n        log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,finish()\", e);\n        return false;\n      }\n    }\n\n    return compareFingerprint(sreq);\n  }\n\n","sourceOld":"  private boolean handleUpdates(ShardResponse srsp) {\n    // we retrieved the last N updates from the replica\n    List<Object> updates = (List<Object>)srsp.getSolrResponse().getResponse().get(\"updates\");\n\n    SyncShardRequest sreq = (SyncShardRequest) srsp.getShardRequest();\n    if (updates.size() < sreq.totalRequestedUpdates) {\n      log.error(msg() + \" Requested \" + sreq.requestedUpdates.size() + \" updates from \" + sreq.shards[0] + \" but retrieved \" + updates.size());\n      return false;\n    }\n\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(DISTRIB_UPDATE_PARAM, FROMLEADER.toString());\n    params.set(\"peersync\",true); // debugging\n    SolrQueryRequest req = new LocalSolrQueryRequest(uhandler.core, params);\n    SolrQueryResponse rsp = new SolrQueryResponse();\n\n    UpdateRequestProcessorChain processorChain = req.getCore().getUpdateProcessingChain(null);\n    UpdateRequestProcessor proc = processorChain.createProcessor(req, rsp);\n\n    Collections.sort(updates, updateRecordComparator);\n\n    Object o = null;\n    long lastVersion = 0;\n    try {\n      // Apply oldest updates first\n      for (Object obj : updates) {\n        // should currently be a List<Oper,Ver,Doc/Id>\n        o = obj;\n        List<Object> entry = (List<Object>)o;\n\n        if (debug) {\n          log.debug(msg() + \"raw update record \" + o);\n        }\n\n        int oper = (Integer)entry.get(0) & UpdateLog.OPERATION_MASK;\n        long version = (Long) entry.get(1);\n        if (version == lastVersion && version != 0) continue;\n        lastVersion = version;\n\n        switch (oper) {\n          case UpdateLog.ADD:\n          {\n            // byte[] idBytes = (byte[]) entry.get(2);\n            SolrInputDocument sdoc = (SolrInputDocument)entry.get(entry.size()-1);\n            AddUpdateCommand cmd = new AddUpdateCommand(req);\n            // cmd.setIndexedId(new BytesRef(idBytes));\n            cmd.solrDoc = sdoc;\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"add \" + cmd + \" id \" + sdoc.getField(\"id\"));\n            }\n            proc.processAdd(cmd);\n            break;\n          }\n          case UpdateLog.DELETE:\n          {\n            byte[] idBytes = (byte[]) entry.get(2);\n            DeleteUpdateCommand cmd = new DeleteUpdateCommand(req);\n            cmd.setIndexedId(new BytesRef(idBytes));\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"delete \" + cmd + \" \" + new BytesRef(idBytes).utf8ToString());\n            }\n            proc.processDelete(cmd);\n            break;\n          }\n\n          case UpdateLog.DELETE_BY_QUERY:\n          {\n            String query = (String)entry.get(2);\n            DeleteUpdateCommand cmd = new DeleteUpdateCommand(req);\n            cmd.query = query;\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"deleteByQuery \" + cmd);\n            }\n            proc.processDelete(cmd);\n            break;\n          }\n\n          default:\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n        }\n\n      }\n\n    }\n    catch (IOException e) {\n      // TODO: should this be handled separately as a problem with us?\n      // I guess it probably already will by causing replication to be kicked off.\n      sreq.updateException = e;\n      log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,update=\" + o, e);\n      return false;\n    }\n    catch (Exception e) {\n      sreq.updateException = e;\n      log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,update=\" + o, e);\n      return false;\n    }\n    finally {\n      try {\n        proc.finish();\n      } catch (Exception e) {\n        sreq.updateException = e;\n        log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,finish()\", e);\n        return false;\n      }\n    }\n\n    return compareFingerprint(sreq);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e1c5f7ce544a129550a8515f7f0eb5f1c0f4472a","date":1472163016,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/update/PeerSync#handleUpdates(ShardResponse).mjava","pathOld":"solr/core/src/java/org/apache/solr/update/PeerSync#handleUpdates(ShardResponse).mjava","sourceNew":"  private boolean handleUpdates(ShardResponse srsp) {\n    // we retrieved the last N updates from the replica\n    List<Object> updates = (List<Object>)srsp.getSolrResponse().getResponse().get(\"updates\");\n\n    SyncShardRequest sreq = (SyncShardRequest) srsp.getShardRequest();\n    if (updates.size() < sreq.totalRequestedUpdates) {\n      log.error(msg() + \" Requested \" + sreq.totalRequestedUpdates + \" updates from \" + sreq.shards[0] + \" but retrieved \" + updates.size());\n      return false;\n    }\n    \n    // overwrite fingerprint we saved in 'handleVersions()'   \n    Object fingerprint = srsp.getSolrResponse().getResponse().get(\"fingerprint\");\n\n    if (fingerprint != null) {\n      sreq.fingerprint = IndexFingerprint.fromObject(fingerprint);\n    }\n\n\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(DISTRIB_UPDATE_PARAM, FROMLEADER.toString());\n    params.set(\"peersync\",true); // debugging\n    SolrQueryRequest req = new LocalSolrQueryRequest(uhandler.core, params);\n    SolrQueryResponse rsp = new SolrQueryResponse();\n\n    UpdateRequestProcessorChain processorChain = req.getCore().getUpdateProcessingChain(null);\n    UpdateRequestProcessor proc = processorChain.createProcessor(req, rsp);\n\n    Collections.sort(updates, updateRecordComparator);\n\n    Object o = null;\n    long lastVersion = 0;\n    try {\n      // Apply oldest updates first\n      for (Object obj : updates) {\n        // should currently be a List<Oper,Ver,Doc/Id>\n        o = obj;\n        List<Object> entry = (List<Object>)o;\n\n        if (debug) {\n          log.debug(msg() + \"raw update record \" + o);\n        }\n\n        int oper = (Integer)entry.get(0) & UpdateLog.OPERATION_MASK;\n        long version = (Long) entry.get(1);\n        if (version == lastVersion && version != 0) continue;\n        lastVersion = version;\n\n        switch (oper) {\n          case UpdateLog.ADD:\n          {\n            // byte[] idBytes = (byte[]) entry.get(2);\n            SolrInputDocument sdoc = (SolrInputDocument)entry.get(entry.size()-1);\n            AddUpdateCommand cmd = new AddUpdateCommand(req);\n            // cmd.setIndexedId(new BytesRef(idBytes));\n            cmd.solrDoc = sdoc;\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"add \" + cmd + \" id \" + sdoc.getField(\"id\"));\n            }\n            proc.processAdd(cmd);\n            break;\n          }\n          case UpdateLog.DELETE:\n          {\n            byte[] idBytes = (byte[]) entry.get(2);\n            DeleteUpdateCommand cmd = new DeleteUpdateCommand(req);\n            cmd.setIndexedId(new BytesRef(idBytes));\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"delete \" + cmd + \" \" + new BytesRef(idBytes).utf8ToString());\n            }\n            proc.processDelete(cmd);\n            break;\n          }\n\n          case UpdateLog.DELETE_BY_QUERY:\n          {\n            String query = (String)entry.get(2);\n            DeleteUpdateCommand cmd = new DeleteUpdateCommand(req);\n            cmd.query = query;\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"deleteByQuery \" + cmd);\n            }\n            proc.processDelete(cmd);\n            break;\n          }\n\n          default:\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n        }\n\n      }\n\n    }\n    catch (IOException e) {\n      // TODO: should this be handled separately as a problem with us?\n      // I guess it probably already will by causing replication to be kicked off.\n      sreq.updateException = e;\n      log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,update=\" + o, e);\n      return false;\n    }\n    catch (Exception e) {\n      sreq.updateException = e;\n      log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,update=\" + o, e);\n      return false;\n    }\n    finally {\n      try {\n        proc.finish();\n      } catch (Exception e) {\n        sreq.updateException = e;\n        log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,finish()\", e);\n        return false;\n      }\n    }\n\n    return compareFingerprint(sreq);\n  }\n\n","sourceOld":"  private boolean handleUpdates(ShardResponse srsp) {\n    // we retrieved the last N updates from the replica\n    List<Object> updates = (List<Object>)srsp.getSolrResponse().getResponse().get(\"updates\");\n\n    SyncShardRequest sreq = (SyncShardRequest) srsp.getShardRequest();\n    if (updates.size() < sreq.totalRequestedUpdates) {\n      log.error(msg() + \" Requested \" + sreq.requestedUpdates.size() + \" updates from \" + sreq.shards[0] + \" but retrieved \" + updates.size());\n      return false;\n    }\n\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(DISTRIB_UPDATE_PARAM, FROMLEADER.toString());\n    params.set(\"peersync\",true); // debugging\n    SolrQueryRequest req = new LocalSolrQueryRequest(uhandler.core, params);\n    SolrQueryResponse rsp = new SolrQueryResponse();\n\n    UpdateRequestProcessorChain processorChain = req.getCore().getUpdateProcessingChain(null);\n    UpdateRequestProcessor proc = processorChain.createProcessor(req, rsp);\n\n    Collections.sort(updates, updateRecordComparator);\n\n    Object o = null;\n    long lastVersion = 0;\n    try {\n      // Apply oldest updates first\n      for (Object obj : updates) {\n        // should currently be a List<Oper,Ver,Doc/Id>\n        o = obj;\n        List<Object> entry = (List<Object>)o;\n\n        if (debug) {\n          log.debug(msg() + \"raw update record \" + o);\n        }\n\n        int oper = (Integer)entry.get(0) & UpdateLog.OPERATION_MASK;\n        long version = (Long) entry.get(1);\n        if (version == lastVersion && version != 0) continue;\n        lastVersion = version;\n\n        switch (oper) {\n          case UpdateLog.ADD:\n          {\n            // byte[] idBytes = (byte[]) entry.get(2);\n            SolrInputDocument sdoc = (SolrInputDocument)entry.get(entry.size()-1);\n            AddUpdateCommand cmd = new AddUpdateCommand(req);\n            // cmd.setIndexedId(new BytesRef(idBytes));\n            cmd.solrDoc = sdoc;\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"add \" + cmd + \" id \" + sdoc.getField(\"id\"));\n            }\n            proc.processAdd(cmd);\n            break;\n          }\n          case UpdateLog.DELETE:\n          {\n            byte[] idBytes = (byte[]) entry.get(2);\n            DeleteUpdateCommand cmd = new DeleteUpdateCommand(req);\n            cmd.setIndexedId(new BytesRef(idBytes));\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"delete \" + cmd + \" \" + new BytesRef(idBytes).utf8ToString());\n            }\n            proc.processDelete(cmd);\n            break;\n          }\n\n          case UpdateLog.DELETE_BY_QUERY:\n          {\n            String query = (String)entry.get(2);\n            DeleteUpdateCommand cmd = new DeleteUpdateCommand(req);\n            cmd.query = query;\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"deleteByQuery \" + cmd);\n            }\n            proc.processDelete(cmd);\n            break;\n          }\n\n          default:\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n        }\n\n      }\n\n    }\n    catch (IOException e) {\n      // TODO: should this be handled separately as a problem with us?\n      // I guess it probably already will by causing replication to be kicked off.\n      sreq.updateException = e;\n      log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,update=\" + o, e);\n      return false;\n    }\n    catch (Exception e) {\n      sreq.updateException = e;\n      log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,update=\" + o, e);\n      return false;\n    }\n    finally {\n      try {\n        proc.finish();\n      } catch (Exception e) {\n        sreq.updateException = e;\n        log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,finish()\", e);\n        return false;\n      }\n    }\n\n    return compareFingerprint(sreq);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4cce5816ef15a48a0bc11e5d400497ee4301dd3b","date":1476991456,"type":3,"author":"Kevin Risden","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/update/PeerSync#handleUpdates(ShardResponse).mjava","pathOld":"solr/core/src/java/org/apache/solr/update/PeerSync#handleUpdates(ShardResponse).mjava","sourceNew":"  private boolean handleUpdates(ShardResponse srsp) {\n    // we retrieved the last N updates from the replica\n    List<Object> updates = (List<Object>)srsp.getSolrResponse().getResponse().get(\"updates\");\n\n    SyncShardRequest sreq = (SyncShardRequest) srsp.getShardRequest();\n    if (updates.size() < sreq.totalRequestedUpdates) {\n      log.error(msg() + \" Requested \" + sreq.totalRequestedUpdates + \" updates from \" + sreq.shards[0] + \" but retrieved \" + updates.size());\n      return false;\n    }\n    \n    // overwrite fingerprint we saved in 'handleVersions()'   \n    Object fingerprint = srsp.getSolrResponse().getResponse().get(\"fingerprint\");\n\n    if (fingerprint != null) {\n      sreq.fingerprint = IndexFingerprint.fromObject(fingerprint);\n    }\n\n\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(DISTRIB_UPDATE_PARAM, FROMLEADER.toString());\n    params.set(\"peersync\",true); // debugging\n    SolrQueryRequest req = new LocalSolrQueryRequest(uhandler.core, params);\n    SolrQueryResponse rsp = new SolrQueryResponse();\n\n    UpdateRequestProcessorChain processorChain = req.getCore().getUpdateProcessingChain(null);\n    UpdateRequestProcessor proc = processorChain.createProcessor(req, rsp);\n\n    Collections.sort(updates, updateRecordComparator);\n\n    Object o = null;\n    long lastVersion = 0;\n    try {\n      // Apply oldest updates first\n      for (Object obj : updates) {\n        // should currently be a List<Oper,Ver,Doc/Id>\n        o = obj;\n        List<Object> entry = (List<Object>)o;\n\n        if (debug) {\n          log.debug(msg() + \"raw update record \" + o);\n        }\n\n        int oper = (Integer)entry.get(0) & UpdateLog.OPERATION_MASK;\n        long version = (Long) entry.get(1);\n        if (version == lastVersion && version != 0) continue;\n        lastVersion = version;\n\n        switch (oper) {\n          case UpdateLog.ADD:\n          {\n            // byte[] idBytes = (byte[]) entry.get(2);\n            SolrInputDocument sdoc = (SolrInputDocument)entry.get(entry.size()-1);\n            AddUpdateCommand cmd = new AddUpdateCommand(req);\n            // cmd.setIndexedId(new BytesRef(idBytes));\n            cmd.solrDoc = sdoc;\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"add \" + cmd + \" id \" + sdoc.getField(\"id\"));\n            }\n            proc.processAdd(cmd);\n            break;\n          }\n          case UpdateLog.DELETE:\n          {\n            byte[] idBytes = (byte[]) entry.get(2);\n            DeleteUpdateCommand cmd = new DeleteUpdateCommand(req);\n            cmd.setIndexedId(new BytesRef(idBytes));\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"delete \" + cmd + \" \" + new BytesRef(idBytes).utf8ToString());\n            }\n            proc.processDelete(cmd);\n            break;\n          }\n\n          case UpdateLog.DELETE_BY_QUERY:\n          {\n            String query = (String)entry.get(2);\n            DeleteUpdateCommand cmd = new DeleteUpdateCommand(req);\n            cmd.query = query;\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"deleteByQuery \" + cmd);\n            }\n            proc.processDelete(cmd);\n            break;\n          }\n\n          default:\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n        }\n\n      }\n\n    }\n    catch (IOException e) {\n      // TODO: should this be handled separately as a problem with us?\n      // I guess it probably already will by causing replication to be kicked off.\n      sreq.updateException = e;\n      log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,update=\" + o, e);\n      return false;\n    }\n    catch (Exception e) {\n      sreq.updateException = e;\n      log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,update=\" + o, e);\n      return false;\n    }\n    finally {\n      try {\n        proc.finish();\n      } catch (Exception e) {\n        sreq.updateException = e;\n        log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,finish()\", e);\n        return false;\n      }\n    }\n\n    return compareFingerprint(sreq);\n  }\n\n","sourceOld":"  private boolean handleUpdates(ShardResponse srsp) {\n    // we retrieved the last N updates from the replica\n    List<Object> updates = (List<Object>)srsp.getSolrResponse().getResponse().get(\"updates\");\n\n    SyncShardRequest sreq = (SyncShardRequest) srsp.getShardRequest();\n    if (updates.size() < sreq.requestedUpdates.size()) {\n      log.error(msg() + \" Requested \" + sreq.requestedUpdates.size() + \" updates from \" + sreq.shards[0] + \" but retrieved \" + updates.size());\n      return false;\n    }\n\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(DISTRIB_UPDATE_PARAM, FROMLEADER.toString());\n    params.set(\"peersync\",true); // debugging\n    SolrQueryRequest req = new LocalSolrQueryRequest(uhandler.core, params);\n    SolrQueryResponse rsp = new SolrQueryResponse();\n\n    UpdateRequestProcessorChain processorChain = req.getCore().getUpdateProcessingChain(null);\n    UpdateRequestProcessor proc = processorChain.createProcessor(req, rsp);\n\n    Collections.sort(updates, updateRecordComparator);\n\n    Object o = null;\n    long lastVersion = 0;\n    try {\n      // Apply oldest updates first\n      for (Object obj : updates) {\n        // should currently be a List<Oper,Ver,Doc/Id>\n        o = obj;\n        List<Object> entry = (List<Object>)o;\n\n        if (debug) {\n          log.debug(msg() + \"raw update record \" + o);\n        }\n\n        int oper = (Integer)entry.get(0) & UpdateLog.OPERATION_MASK;\n        long version = (Long) entry.get(1);\n        if (version == lastVersion && version != 0) continue;\n        lastVersion = version;\n\n        switch (oper) {\n          case UpdateLog.ADD:\n          {\n            // byte[] idBytes = (byte[]) entry.get(2);\n            SolrInputDocument sdoc = (SolrInputDocument)entry.get(entry.size()-1);\n            AddUpdateCommand cmd = new AddUpdateCommand(req);\n            // cmd.setIndexedId(new BytesRef(idBytes));\n            cmd.solrDoc = sdoc;\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"add \" + cmd + \" id \" + sdoc.getField(\"id\"));\n            }\n            proc.processAdd(cmd);\n            break;\n          }\n          case UpdateLog.DELETE:\n          {\n            byte[] idBytes = (byte[]) entry.get(2);\n            DeleteUpdateCommand cmd = new DeleteUpdateCommand(req);\n            cmd.setIndexedId(new BytesRef(idBytes));\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"delete \" + cmd + \" \" + new BytesRef(idBytes).utf8ToString());\n            }\n            proc.processDelete(cmd);\n            break;\n          }\n\n          case UpdateLog.DELETE_BY_QUERY:\n          {\n            String query = (String)entry.get(2);\n            DeleteUpdateCommand cmd = new DeleteUpdateCommand(req);\n            cmd.query = query;\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"deleteByQuery \" + cmd);\n            }\n            proc.processDelete(cmd);\n            break;\n          }\n\n          default:\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n        }\n\n      }\n\n    }\n    catch (IOException e) {\n      // TODO: should this be handled separately as a problem with us?\n      // I guess it probably already will by causing replication to be kicked off.\n      sreq.updateException = e;\n      log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,update=\" + o, e);\n      return false;\n    }\n    catch (Exception e) {\n      sreq.updateException = e;\n      log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,update=\" + o, e);\n      return false;\n    }\n    finally {\n      try {\n        proc.finish();\n      } catch (Exception e) {\n        sreq.updateException = e;\n        log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,finish()\", e);\n        return false;\n      }\n    }\n\n    return compareFingerprint(sreq);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"415bbbe7da8065dd3c477bdc3c703c6425622998","date":1485393793,"type":3,"author":"Ishan Chattopadhyaya","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/update/PeerSync#handleUpdates(ShardResponse).mjava","pathOld":"solr/core/src/java/org/apache/solr/update/PeerSync#handleUpdates(ShardResponse).mjava","sourceNew":"  private boolean handleUpdates(ShardResponse srsp) {\n    // we retrieved the last N updates from the replica\n    List<Object> updates = (List<Object>)srsp.getSolrResponse().getResponse().get(\"updates\");\n\n    SyncShardRequest sreq = (SyncShardRequest) srsp.getShardRequest();\n    if (updates.size() < sreq.totalRequestedUpdates) {\n      log.error(msg() + \" Requested \" + sreq.totalRequestedUpdates + \" updates from \" + sreq.shards[0] + \" but retrieved \" + updates.size());\n      return false;\n    }\n    \n    // overwrite fingerprint we saved in 'handleVersions()'   \n    Object fingerprint = srsp.getSolrResponse().getResponse().get(\"fingerprint\");\n\n    if (fingerprint != null) {\n      sreq.fingerprint = IndexFingerprint.fromObject(fingerprint);\n    }\n\n\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(DISTRIB_UPDATE_PARAM, FROMLEADER.toString());\n    params.set(\"peersync\",true); // debugging\n    SolrQueryRequest req = new LocalSolrQueryRequest(uhandler.core, params);\n    SolrQueryResponse rsp = new SolrQueryResponse();\n\n    UpdateRequestProcessorChain processorChain = req.getCore().getUpdateProcessingChain(null);\n    UpdateRequestProcessor proc = processorChain.createProcessor(req, rsp);\n\n    Collections.sort(updates, updateRecordComparator);\n\n    Object o = null;\n    long lastVersion = 0;\n    try {\n      // Apply oldest updates first\n      for (Object obj : updates) {\n        // should currently be a List<Oper,Ver,Doc/Id>\n        o = obj;\n        List<Object> entry = (List<Object>)o;\n\n        if (debug) {\n          log.debug(msg() + \"raw update record \" + o);\n        }\n\n        int oper = (Integer)entry.get(0) & UpdateLog.OPERATION_MASK;\n        long version = (Long) entry.get(1);\n        if (version == lastVersion && version != 0) continue;\n        lastVersion = version;\n\n        switch (oper) {\n          case UpdateLog.ADD:\n          {\n            // byte[] idBytes = (byte[]) entry.get(2);\n            SolrInputDocument sdoc = (SolrInputDocument)entry.get(entry.size()-1);\n            AddUpdateCommand cmd = new AddUpdateCommand(req);\n            // cmd.setIndexedId(new BytesRef(idBytes));\n            cmd.solrDoc = sdoc;\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"add \" + cmd + \" id \" + sdoc.getField(\"id\"));\n            }\n            proc.processAdd(cmd);\n            break;\n          }\n          case UpdateLog.DELETE:\n          {\n            byte[] idBytes = (byte[]) entry.get(2);\n            DeleteUpdateCommand cmd = new DeleteUpdateCommand(req);\n            cmd.setIndexedId(new BytesRef(idBytes));\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"delete \" + cmd + \" \" + new BytesRef(idBytes).utf8ToString());\n            }\n            proc.processDelete(cmd);\n            break;\n          }\n\n          case UpdateLog.DELETE_BY_QUERY:\n          {\n            String query = (String)entry.get(2);\n            DeleteUpdateCommand cmd = new DeleteUpdateCommand(req);\n            cmd.query = query;\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"deleteByQuery \" + cmd);\n            }\n            proc.processDelete(cmd);\n            break;\n          }\n          case UpdateLog.UPDATE_INPLACE:\n          {\n            AddUpdateCommand cmd = UpdateLog.convertTlogEntryToAddUpdateCommand(req, entry, oper, version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"inplace update \" + cmd + \" prevVersion=\" + cmd.prevVersion + \", doc=\" + cmd.solrDoc);\n            }\n            proc.processAdd(cmd);\n            break;\n          }\n\n          default:\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n        }\n\n      }\n\n    }\n    catch (IOException e) {\n      // TODO: should this be handled separately as a problem with us?\n      // I guess it probably already will by causing replication to be kicked off.\n      sreq.updateException = e;\n      log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,update=\" + o, e);\n      return false;\n    }\n    catch (Exception e) {\n      sreq.updateException = e;\n      log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,update=\" + o, e);\n      return false;\n    }\n    finally {\n      try {\n        proc.finish();\n      } catch (Exception e) {\n        sreq.updateException = e;\n        log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,finish()\", e);\n        return false;\n      }\n    }\n\n    return compareFingerprint(sreq);\n  }\n\n","sourceOld":"  private boolean handleUpdates(ShardResponse srsp) {\n    // we retrieved the last N updates from the replica\n    List<Object> updates = (List<Object>)srsp.getSolrResponse().getResponse().get(\"updates\");\n\n    SyncShardRequest sreq = (SyncShardRequest) srsp.getShardRequest();\n    if (updates.size() < sreq.totalRequestedUpdates) {\n      log.error(msg() + \" Requested \" + sreq.totalRequestedUpdates + \" updates from \" + sreq.shards[0] + \" but retrieved \" + updates.size());\n      return false;\n    }\n    \n    // overwrite fingerprint we saved in 'handleVersions()'   \n    Object fingerprint = srsp.getSolrResponse().getResponse().get(\"fingerprint\");\n\n    if (fingerprint != null) {\n      sreq.fingerprint = IndexFingerprint.fromObject(fingerprint);\n    }\n\n\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(DISTRIB_UPDATE_PARAM, FROMLEADER.toString());\n    params.set(\"peersync\",true); // debugging\n    SolrQueryRequest req = new LocalSolrQueryRequest(uhandler.core, params);\n    SolrQueryResponse rsp = new SolrQueryResponse();\n\n    UpdateRequestProcessorChain processorChain = req.getCore().getUpdateProcessingChain(null);\n    UpdateRequestProcessor proc = processorChain.createProcessor(req, rsp);\n\n    Collections.sort(updates, updateRecordComparator);\n\n    Object o = null;\n    long lastVersion = 0;\n    try {\n      // Apply oldest updates first\n      for (Object obj : updates) {\n        // should currently be a List<Oper,Ver,Doc/Id>\n        o = obj;\n        List<Object> entry = (List<Object>)o;\n\n        if (debug) {\n          log.debug(msg() + \"raw update record \" + o);\n        }\n\n        int oper = (Integer)entry.get(0) & UpdateLog.OPERATION_MASK;\n        long version = (Long) entry.get(1);\n        if (version == lastVersion && version != 0) continue;\n        lastVersion = version;\n\n        switch (oper) {\n          case UpdateLog.ADD:\n          {\n            // byte[] idBytes = (byte[]) entry.get(2);\n            SolrInputDocument sdoc = (SolrInputDocument)entry.get(entry.size()-1);\n            AddUpdateCommand cmd = new AddUpdateCommand(req);\n            // cmd.setIndexedId(new BytesRef(idBytes));\n            cmd.solrDoc = sdoc;\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"add \" + cmd + \" id \" + sdoc.getField(\"id\"));\n            }\n            proc.processAdd(cmd);\n            break;\n          }\n          case UpdateLog.DELETE:\n          {\n            byte[] idBytes = (byte[]) entry.get(2);\n            DeleteUpdateCommand cmd = new DeleteUpdateCommand(req);\n            cmd.setIndexedId(new BytesRef(idBytes));\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"delete \" + cmd + \" \" + new BytesRef(idBytes).utf8ToString());\n            }\n            proc.processDelete(cmd);\n            break;\n          }\n\n          case UpdateLog.DELETE_BY_QUERY:\n          {\n            String query = (String)entry.get(2);\n            DeleteUpdateCommand cmd = new DeleteUpdateCommand(req);\n            cmd.query = query;\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"deleteByQuery \" + cmd);\n            }\n            proc.processDelete(cmd);\n            break;\n          }\n\n          default:\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n        }\n\n      }\n\n    }\n    catch (IOException e) {\n      // TODO: should this be handled separately as a problem with us?\n      // I guess it probably already will by causing replication to be kicked off.\n      sreq.updateException = e;\n      log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,update=\" + o, e);\n      return false;\n    }\n    catch (Exception e) {\n      sreq.updateException = e;\n      log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,update=\" + o, e);\n      return false;\n    }\n    finally {\n      try {\n        proc.finish();\n      } catch (Exception e) {\n        sreq.updateException = e;\n        log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,finish()\", e);\n        return false;\n      }\n    }\n\n    return compareFingerprint(sreq);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"598b5d23aa7c9732bf473c21a9cd309c44599394","date":1485530378,"type":3,"author":"Kevin Risden","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/update/PeerSync#handleUpdates(ShardResponse).mjava","pathOld":"solr/core/src/java/org/apache/solr/update/PeerSync#handleUpdates(ShardResponse).mjava","sourceNew":"  private boolean handleUpdates(ShardResponse srsp) {\n    // we retrieved the last N updates from the replica\n    List<Object> updates = (List<Object>)srsp.getSolrResponse().getResponse().get(\"updates\");\n\n    SyncShardRequest sreq = (SyncShardRequest) srsp.getShardRequest();\n    if (updates.size() < sreq.totalRequestedUpdates) {\n      log.error(msg() + \" Requested \" + sreq.totalRequestedUpdates + \" updates from \" + sreq.shards[0] + \" but retrieved \" + updates.size());\n      return false;\n    }\n    \n    // overwrite fingerprint we saved in 'handleVersions()'   \n    Object fingerprint = srsp.getSolrResponse().getResponse().get(\"fingerprint\");\n\n    if (fingerprint != null) {\n      sreq.fingerprint = IndexFingerprint.fromObject(fingerprint);\n    }\n\n\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(DISTRIB_UPDATE_PARAM, FROMLEADER.toString());\n    params.set(\"peersync\",true); // debugging\n    SolrQueryRequest req = new LocalSolrQueryRequest(uhandler.core, params);\n    SolrQueryResponse rsp = new SolrQueryResponse();\n\n    UpdateRequestProcessorChain processorChain = req.getCore().getUpdateProcessingChain(null);\n    UpdateRequestProcessor proc = processorChain.createProcessor(req, rsp);\n\n    Collections.sort(updates, updateRecordComparator);\n\n    Object o = null;\n    long lastVersion = 0;\n    try {\n      // Apply oldest updates first\n      for (Object obj : updates) {\n        // should currently be a List<Oper,Ver,Doc/Id>\n        o = obj;\n        List<Object> entry = (List<Object>)o;\n\n        if (debug) {\n          log.debug(msg() + \"raw update record \" + o);\n        }\n\n        int oper = (Integer)entry.get(0) & UpdateLog.OPERATION_MASK;\n        long version = (Long) entry.get(1);\n        if (version == lastVersion && version != 0) continue;\n        lastVersion = version;\n\n        switch (oper) {\n          case UpdateLog.ADD:\n          {\n            // byte[] idBytes = (byte[]) entry.get(2);\n            SolrInputDocument sdoc = (SolrInputDocument)entry.get(entry.size()-1);\n            AddUpdateCommand cmd = new AddUpdateCommand(req);\n            // cmd.setIndexedId(new BytesRef(idBytes));\n            cmd.solrDoc = sdoc;\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"add \" + cmd + \" id \" + sdoc.getField(\"id\"));\n            }\n            proc.processAdd(cmd);\n            break;\n          }\n          case UpdateLog.DELETE:\n          {\n            byte[] idBytes = (byte[]) entry.get(2);\n            DeleteUpdateCommand cmd = new DeleteUpdateCommand(req);\n            cmd.setIndexedId(new BytesRef(idBytes));\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"delete \" + cmd + \" \" + new BytesRef(idBytes).utf8ToString());\n            }\n            proc.processDelete(cmd);\n            break;\n          }\n\n          case UpdateLog.DELETE_BY_QUERY:\n          {\n            String query = (String)entry.get(2);\n            DeleteUpdateCommand cmd = new DeleteUpdateCommand(req);\n            cmd.query = query;\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"deleteByQuery \" + cmd);\n            }\n            proc.processDelete(cmd);\n            break;\n          }\n          case UpdateLog.UPDATE_INPLACE:\n          {\n            AddUpdateCommand cmd = UpdateLog.convertTlogEntryToAddUpdateCommand(req, entry, oper, version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"inplace update \" + cmd + \" prevVersion=\" + cmd.prevVersion + \", doc=\" + cmd.solrDoc);\n            }\n            proc.processAdd(cmd);\n            break;\n          }\n\n          default:\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n        }\n\n      }\n\n    }\n    catch (IOException e) {\n      // TODO: should this be handled separately as a problem with us?\n      // I guess it probably already will by causing replication to be kicked off.\n      sreq.updateException = e;\n      log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,update=\" + o, e);\n      return false;\n    }\n    catch (Exception e) {\n      sreq.updateException = e;\n      log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,update=\" + o, e);\n      return false;\n    }\n    finally {\n      try {\n        proc.finish();\n      } catch (Exception e) {\n        sreq.updateException = e;\n        log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,finish()\", e);\n        return false;\n      }\n    }\n\n    return compareFingerprint(sreq);\n  }\n\n","sourceOld":"  private boolean handleUpdates(ShardResponse srsp) {\n    // we retrieved the last N updates from the replica\n    List<Object> updates = (List<Object>)srsp.getSolrResponse().getResponse().get(\"updates\");\n\n    SyncShardRequest sreq = (SyncShardRequest) srsp.getShardRequest();\n    if (updates.size() < sreq.totalRequestedUpdates) {\n      log.error(msg() + \" Requested \" + sreq.totalRequestedUpdates + \" updates from \" + sreq.shards[0] + \" but retrieved \" + updates.size());\n      return false;\n    }\n    \n    // overwrite fingerprint we saved in 'handleVersions()'   \n    Object fingerprint = srsp.getSolrResponse().getResponse().get(\"fingerprint\");\n\n    if (fingerprint != null) {\n      sreq.fingerprint = IndexFingerprint.fromObject(fingerprint);\n    }\n\n\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(DISTRIB_UPDATE_PARAM, FROMLEADER.toString());\n    params.set(\"peersync\",true); // debugging\n    SolrQueryRequest req = new LocalSolrQueryRequest(uhandler.core, params);\n    SolrQueryResponse rsp = new SolrQueryResponse();\n\n    UpdateRequestProcessorChain processorChain = req.getCore().getUpdateProcessingChain(null);\n    UpdateRequestProcessor proc = processorChain.createProcessor(req, rsp);\n\n    Collections.sort(updates, updateRecordComparator);\n\n    Object o = null;\n    long lastVersion = 0;\n    try {\n      // Apply oldest updates first\n      for (Object obj : updates) {\n        // should currently be a List<Oper,Ver,Doc/Id>\n        o = obj;\n        List<Object> entry = (List<Object>)o;\n\n        if (debug) {\n          log.debug(msg() + \"raw update record \" + o);\n        }\n\n        int oper = (Integer)entry.get(0) & UpdateLog.OPERATION_MASK;\n        long version = (Long) entry.get(1);\n        if (version == lastVersion && version != 0) continue;\n        lastVersion = version;\n\n        switch (oper) {\n          case UpdateLog.ADD:\n          {\n            // byte[] idBytes = (byte[]) entry.get(2);\n            SolrInputDocument sdoc = (SolrInputDocument)entry.get(entry.size()-1);\n            AddUpdateCommand cmd = new AddUpdateCommand(req);\n            // cmd.setIndexedId(new BytesRef(idBytes));\n            cmd.solrDoc = sdoc;\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"add \" + cmd + \" id \" + sdoc.getField(\"id\"));\n            }\n            proc.processAdd(cmd);\n            break;\n          }\n          case UpdateLog.DELETE:\n          {\n            byte[] idBytes = (byte[]) entry.get(2);\n            DeleteUpdateCommand cmd = new DeleteUpdateCommand(req);\n            cmd.setIndexedId(new BytesRef(idBytes));\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"delete \" + cmd + \" \" + new BytesRef(idBytes).utf8ToString());\n            }\n            proc.processDelete(cmd);\n            break;\n          }\n\n          case UpdateLog.DELETE_BY_QUERY:\n          {\n            String query = (String)entry.get(2);\n            DeleteUpdateCommand cmd = new DeleteUpdateCommand(req);\n            cmd.query = query;\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"deleteByQuery \" + cmd);\n            }\n            proc.processDelete(cmd);\n            break;\n          }\n\n          default:\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n        }\n\n      }\n\n    }\n    catch (IOException e) {\n      // TODO: should this be handled separately as a problem with us?\n      // I guess it probably already will by causing replication to be kicked off.\n      sreq.updateException = e;\n      log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,update=\" + o, e);\n      return false;\n    }\n    catch (Exception e) {\n      sreq.updateException = e;\n      log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,update=\" + o, e);\n      return false;\n    }\n    finally {\n      try {\n        proc.finish();\n      } catch (Exception e) {\n        sreq.updateException = e;\n        log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,finish()\", e);\n        return false;\n      }\n    }\n\n    return compareFingerprint(sreq);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2d06ba55ef44382e5547ff01fff8eb1f0fa0faa6","date":1487775028,"type":3,"author":"markrmiller","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/update/PeerSync#handleUpdates(ShardResponse).mjava","pathOld":"solr/core/src/java/org/apache/solr/update/PeerSync#handleUpdates(ShardResponse).mjava","sourceNew":"  private boolean handleUpdates(ShardResponse srsp) {\n    // we retrieved the last N updates from the replica\n    List<Object> updates = (List<Object>)srsp.getSolrResponse().getResponse().get(\"updates\");\n\n    SyncShardRequest sreq = (SyncShardRequest) srsp.getShardRequest();\n    if (updates.size() < sreq.totalRequestedUpdates) {\n      log.error(msg() + \" Requested \" + sreq.totalRequestedUpdates + \" updates from \" + sreq.shards[0] + \" but retrieved \" + updates.size());\n      return false;\n    }\n    \n    // overwrite fingerprint we saved in 'handleVersions()'   \n    Object fingerprint = srsp.getSolrResponse().getResponse().get(\"fingerprint\");\n\n    if (fingerprint != null) {\n      sreq.fingerprint = IndexFingerprint.fromObject(fingerprint);\n    }\n\n\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(DISTRIB_UPDATE_PARAM, FROMLEADER.toString());\n    params.set(\"peersync\",true); // debugging\n    SolrQueryRequest req = new LocalSolrQueryRequest(uhandler.core, params);\n    SolrQueryResponse rsp = new SolrQueryResponse();\n\n    UpdateRequestProcessorChain processorChain = req.getCore().getUpdateProcessingChain(null);\n    UpdateRequestProcessor proc = processorChain.createProcessor(req, rsp);\n\n    Collections.sort(updates, updateRecordComparator);\n\n    Object o = null;\n    long lastVersion = 0;\n    try {\n      // Apply oldest updates first\n      for (Object obj : updates) {\n        // should currently be a List<Oper,Ver,Doc/Id>\n        o = obj;\n        List<Object> entry = (List<Object>)o;\n\n        if (debug) {\n          log.debug(msg() + \"raw update record \" + o);\n        }\n\n        int oper = (Integer)entry.get(0) & UpdateLog.OPERATION_MASK;\n        long version = (Long) entry.get(1);\n        if (version == lastVersion && version != 0) continue;\n        lastVersion = version;\n\n        switch (oper) {\n          case UpdateLog.ADD:\n          {\n            // byte[] idBytes = (byte[]) entry.get(2);\n            SolrInputDocument sdoc = (SolrInputDocument)entry.get(entry.size()-1);\n            AddUpdateCommand cmd = new AddUpdateCommand(req);\n            // cmd.setIndexedId(new BytesRef(idBytes));\n            cmd.solrDoc = sdoc;\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"add \" + cmd + \" id \" + sdoc.getField(\"id\"));\n            }\n            proc.processAdd(cmd);\n            break;\n          }\n          case UpdateLog.DELETE:\n          {\n            byte[] idBytes = (byte[]) entry.get(2);\n            DeleteUpdateCommand cmd = new DeleteUpdateCommand(req);\n            cmd.setIndexedId(new BytesRef(idBytes));\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"delete \" + cmd + \" \" + new BytesRef(idBytes).utf8ToString());\n            }\n            proc.processDelete(cmd);\n            break;\n          }\n\n          case UpdateLog.DELETE_BY_QUERY:\n          {\n            String query = (String)entry.get(2);\n            DeleteUpdateCommand cmd = new DeleteUpdateCommand(req);\n            cmd.query = query;\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"deleteByQuery \" + cmd);\n            }\n            proc.processDelete(cmd);\n            break;\n          }\n          case UpdateLog.UPDATE_INPLACE:\n          {\n            AddUpdateCommand cmd = UpdateLog.convertTlogEntryToAddUpdateCommand(req, entry, oper, version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"inplace update \" + cmd + \" prevVersion=\" + cmd.prevVersion + \", doc=\" + cmd.solrDoc);\n            }\n            proc.processAdd(cmd);\n            break;\n          }\n\n          default:\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n        }\n\n      }\n\n    }\n    catch (IOException e) {\n      // TODO: should this be handled separately as a problem with us?\n      // I guess it probably already will by causing replication to be kicked off.\n      sreq.updateException = e;\n      log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,update=\" + o, e);\n      return false;\n    }\n    catch (Exception e) {\n      sreq.updateException = e;\n      log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,update=\" + o, e);\n      return false;\n    }\n    finally {\n      try {\n        proc.finish();\n      } catch (Exception e) {\n        sreq.updateException = e;\n        log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,finish()\", e);\n        return false;\n      } finally {\n        IOUtils.closeQuietly(proc);\n      }\n    }\n\n    return compareFingerprint(sreq);\n  }\n\n","sourceOld":"  private boolean handleUpdates(ShardResponse srsp) {\n    // we retrieved the last N updates from the replica\n    List<Object> updates = (List<Object>)srsp.getSolrResponse().getResponse().get(\"updates\");\n\n    SyncShardRequest sreq = (SyncShardRequest) srsp.getShardRequest();\n    if (updates.size() < sreq.totalRequestedUpdates) {\n      log.error(msg() + \" Requested \" + sreq.totalRequestedUpdates + \" updates from \" + sreq.shards[0] + \" but retrieved \" + updates.size());\n      return false;\n    }\n    \n    // overwrite fingerprint we saved in 'handleVersions()'   \n    Object fingerprint = srsp.getSolrResponse().getResponse().get(\"fingerprint\");\n\n    if (fingerprint != null) {\n      sreq.fingerprint = IndexFingerprint.fromObject(fingerprint);\n    }\n\n\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(DISTRIB_UPDATE_PARAM, FROMLEADER.toString());\n    params.set(\"peersync\",true); // debugging\n    SolrQueryRequest req = new LocalSolrQueryRequest(uhandler.core, params);\n    SolrQueryResponse rsp = new SolrQueryResponse();\n\n    UpdateRequestProcessorChain processorChain = req.getCore().getUpdateProcessingChain(null);\n    UpdateRequestProcessor proc = processorChain.createProcessor(req, rsp);\n\n    Collections.sort(updates, updateRecordComparator);\n\n    Object o = null;\n    long lastVersion = 0;\n    try {\n      // Apply oldest updates first\n      for (Object obj : updates) {\n        // should currently be a List<Oper,Ver,Doc/Id>\n        o = obj;\n        List<Object> entry = (List<Object>)o;\n\n        if (debug) {\n          log.debug(msg() + \"raw update record \" + o);\n        }\n\n        int oper = (Integer)entry.get(0) & UpdateLog.OPERATION_MASK;\n        long version = (Long) entry.get(1);\n        if (version == lastVersion && version != 0) continue;\n        lastVersion = version;\n\n        switch (oper) {\n          case UpdateLog.ADD:\n          {\n            // byte[] idBytes = (byte[]) entry.get(2);\n            SolrInputDocument sdoc = (SolrInputDocument)entry.get(entry.size()-1);\n            AddUpdateCommand cmd = new AddUpdateCommand(req);\n            // cmd.setIndexedId(new BytesRef(idBytes));\n            cmd.solrDoc = sdoc;\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"add \" + cmd + \" id \" + sdoc.getField(\"id\"));\n            }\n            proc.processAdd(cmd);\n            break;\n          }\n          case UpdateLog.DELETE:\n          {\n            byte[] idBytes = (byte[]) entry.get(2);\n            DeleteUpdateCommand cmd = new DeleteUpdateCommand(req);\n            cmd.setIndexedId(new BytesRef(idBytes));\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"delete \" + cmd + \" \" + new BytesRef(idBytes).utf8ToString());\n            }\n            proc.processDelete(cmd);\n            break;\n          }\n\n          case UpdateLog.DELETE_BY_QUERY:\n          {\n            String query = (String)entry.get(2);\n            DeleteUpdateCommand cmd = new DeleteUpdateCommand(req);\n            cmd.query = query;\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"deleteByQuery \" + cmd);\n            }\n            proc.processDelete(cmd);\n            break;\n          }\n          case UpdateLog.UPDATE_INPLACE:\n          {\n            AddUpdateCommand cmd = UpdateLog.convertTlogEntryToAddUpdateCommand(req, entry, oper, version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"inplace update \" + cmd + \" prevVersion=\" + cmd.prevVersion + \", doc=\" + cmd.solrDoc);\n            }\n            proc.processAdd(cmd);\n            break;\n          }\n\n          default:\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n        }\n\n      }\n\n    }\n    catch (IOException e) {\n      // TODO: should this be handled separately as a problem with us?\n      // I guess it probably already will by causing replication to be kicked off.\n      sreq.updateException = e;\n      log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,update=\" + o, e);\n      return false;\n    }\n    catch (Exception e) {\n      sreq.updateException = e;\n      log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,update=\" + o, e);\n      return false;\n    }\n    finally {\n      try {\n        proc.finish();\n      } catch (Exception e) {\n        sreq.updateException = e;\n        log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,finish()\", e);\n        return false;\n      }\n    }\n\n    return compareFingerprint(sreq);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6d2dadc1f5ca8703d8659f4964961f9967935d75","date":1490231750,"type":3,"author":"Noble Paul","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/update/PeerSync#handleUpdates(ShardResponse).mjava","pathOld":"solr/core/src/java/org/apache/solr/update/PeerSync#handleUpdates(ShardResponse).mjava","sourceNew":"  private boolean handleUpdates(ShardResponse srsp) {\n    // we retrieved the last N updates from the replica\n    List<Object> updates = (List<Object>)srsp.getSolrResponse().getResponse().get(\"updates\");\n\n    SyncShardRequest sreq = (SyncShardRequest) srsp.getShardRequest();\n    if (updates.size() < sreq.totalRequestedUpdates) {\n      log.error(msg() + \" Requested \" + sreq.totalRequestedUpdates + \" updates from \" + sreq.shards[0] + \" but retrieved \" + updates.size());\n      return false;\n    }\n    \n    // overwrite fingerprint we saved in 'handleVersions()'   \n    Object fingerprint = srsp.getSolrResponse().getResponse().get(\"fingerprint\");\n\n    if (fingerprint != null) {\n      sreq.fingerprint = IndexFingerprint.fromObject(fingerprint);\n    }\n\n\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(DISTRIB_UPDATE_PARAM, FROMLEADER.toString());\n    params.set(\"peersync\",true); // debugging\n    SolrQueryRequest req = new LocalSolrQueryRequest(uhandler.core, params);\n    SolrQueryResponse rsp = new SolrQueryResponse();\n\n    UpdateRequestProcessorChain processorChain = req.getCore().getUpdateProcessingChain(null);\n    UpdateRequestProcessor proc = processorChain.createProcessor(req, rsp);\n\n    Collections.sort(updates, updateRecordComparator);\n\n    Object o = null;\n    long lastVersion = 0;\n    try {\n      // Apply oldest updates first\n      for (Object obj : updates) {\n        // should currently be a List<Oper,Ver,Doc/Id>\n        o = obj;\n        List<Object> entry = (List<Object>)o;\n\n        if (debug) {\n          log.debug(msg() + \"raw update record \" + o);\n        }\n\n        int oper = (Integer)entry.get(0) & UpdateLog.OPERATION_MASK;\n        long version = (Long) entry.get(1);\n        if (version == lastVersion && version != 0) continue;\n        lastVersion = version;\n\n        switch (oper) {\n          case UpdateLog.ADD:\n          {\n            // byte[] idBytes = (byte[]) entry.get(2);\n            SolrInputDocument sdoc = (SolrInputDocument)entry.get(entry.size()-1);\n            AddUpdateCommand cmd = new AddUpdateCommand(req);\n            // cmd.setIndexedId(new BytesRef(idBytes));\n            cmd.solrDoc = sdoc;\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"add \" + cmd + \" id \" + sdoc.getField(ID));\n            }\n            proc.processAdd(cmd);\n            break;\n          }\n          case UpdateLog.DELETE:\n          {\n            byte[] idBytes = (byte[]) entry.get(2);\n            DeleteUpdateCommand cmd = new DeleteUpdateCommand(req);\n            cmd.setIndexedId(new BytesRef(idBytes));\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"delete \" + cmd + \" \" + new BytesRef(idBytes).utf8ToString());\n            }\n            proc.processDelete(cmd);\n            break;\n          }\n\n          case UpdateLog.DELETE_BY_QUERY:\n          {\n            String query = (String)entry.get(2);\n            DeleteUpdateCommand cmd = new DeleteUpdateCommand(req);\n            cmd.query = query;\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"deleteByQuery \" + cmd);\n            }\n            proc.processDelete(cmd);\n            break;\n          }\n          case UpdateLog.UPDATE_INPLACE:\n          {\n            AddUpdateCommand cmd = UpdateLog.convertTlogEntryToAddUpdateCommand(req, entry, oper, version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"inplace update \" + cmd + \" prevVersion=\" + cmd.prevVersion + \", doc=\" + cmd.solrDoc);\n            }\n            proc.processAdd(cmd);\n            break;\n          }\n\n          default:\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n        }\n\n      }\n\n    }\n    catch (IOException e) {\n      // TODO: should this be handled separately as a problem with us?\n      // I guess it probably already will by causing replication to be kicked off.\n      sreq.updateException = e;\n      log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,update=\" + o, e);\n      return false;\n    }\n    catch (Exception e) {\n      sreq.updateException = e;\n      log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,update=\" + o, e);\n      return false;\n    }\n    finally {\n      try {\n        proc.finish();\n      } catch (Exception e) {\n        sreq.updateException = e;\n        log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,finish()\", e);\n        return false;\n      } finally {\n        IOUtils.closeQuietly(proc);\n      }\n    }\n\n    return compareFingerprint(sreq);\n  }\n\n","sourceOld":"  private boolean handleUpdates(ShardResponse srsp) {\n    // we retrieved the last N updates from the replica\n    List<Object> updates = (List<Object>)srsp.getSolrResponse().getResponse().get(\"updates\");\n\n    SyncShardRequest sreq = (SyncShardRequest) srsp.getShardRequest();\n    if (updates.size() < sreq.totalRequestedUpdates) {\n      log.error(msg() + \" Requested \" + sreq.totalRequestedUpdates + \" updates from \" + sreq.shards[0] + \" but retrieved \" + updates.size());\n      return false;\n    }\n    \n    // overwrite fingerprint we saved in 'handleVersions()'   \n    Object fingerprint = srsp.getSolrResponse().getResponse().get(\"fingerprint\");\n\n    if (fingerprint != null) {\n      sreq.fingerprint = IndexFingerprint.fromObject(fingerprint);\n    }\n\n\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(DISTRIB_UPDATE_PARAM, FROMLEADER.toString());\n    params.set(\"peersync\",true); // debugging\n    SolrQueryRequest req = new LocalSolrQueryRequest(uhandler.core, params);\n    SolrQueryResponse rsp = new SolrQueryResponse();\n\n    UpdateRequestProcessorChain processorChain = req.getCore().getUpdateProcessingChain(null);\n    UpdateRequestProcessor proc = processorChain.createProcessor(req, rsp);\n\n    Collections.sort(updates, updateRecordComparator);\n\n    Object o = null;\n    long lastVersion = 0;\n    try {\n      // Apply oldest updates first\n      for (Object obj : updates) {\n        // should currently be a List<Oper,Ver,Doc/Id>\n        o = obj;\n        List<Object> entry = (List<Object>)o;\n\n        if (debug) {\n          log.debug(msg() + \"raw update record \" + o);\n        }\n\n        int oper = (Integer)entry.get(0) & UpdateLog.OPERATION_MASK;\n        long version = (Long) entry.get(1);\n        if (version == lastVersion && version != 0) continue;\n        lastVersion = version;\n\n        switch (oper) {\n          case UpdateLog.ADD:\n          {\n            // byte[] idBytes = (byte[]) entry.get(2);\n            SolrInputDocument sdoc = (SolrInputDocument)entry.get(entry.size()-1);\n            AddUpdateCommand cmd = new AddUpdateCommand(req);\n            // cmd.setIndexedId(new BytesRef(idBytes));\n            cmd.solrDoc = sdoc;\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"add \" + cmd + \" id \" + sdoc.getField(\"id\"));\n            }\n            proc.processAdd(cmd);\n            break;\n          }\n          case UpdateLog.DELETE:\n          {\n            byte[] idBytes = (byte[]) entry.get(2);\n            DeleteUpdateCommand cmd = new DeleteUpdateCommand(req);\n            cmd.setIndexedId(new BytesRef(idBytes));\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"delete \" + cmd + \" \" + new BytesRef(idBytes).utf8ToString());\n            }\n            proc.processDelete(cmd);\n            break;\n          }\n\n          case UpdateLog.DELETE_BY_QUERY:\n          {\n            String query = (String)entry.get(2);\n            DeleteUpdateCommand cmd = new DeleteUpdateCommand(req);\n            cmd.query = query;\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"deleteByQuery \" + cmd);\n            }\n            proc.processDelete(cmd);\n            break;\n          }\n          case UpdateLog.UPDATE_INPLACE:\n          {\n            AddUpdateCommand cmd = UpdateLog.convertTlogEntryToAddUpdateCommand(req, entry, oper, version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"inplace update \" + cmd + \" prevVersion=\" + cmd.prevVersion + \", doc=\" + cmd.solrDoc);\n            }\n            proc.processAdd(cmd);\n            break;\n          }\n\n          default:\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n        }\n\n      }\n\n    }\n    catch (IOException e) {\n      // TODO: should this be handled separately as a problem with us?\n      // I guess it probably already will by causing replication to be kicked off.\n      sreq.updateException = e;\n      log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,update=\" + o, e);\n      return false;\n    }\n    catch (Exception e) {\n      sreq.updateException = e;\n      log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,update=\" + o, e);\n      return false;\n    }\n    finally {\n      try {\n        proc.finish();\n      } catch (Exception e) {\n        sreq.updateException = e;\n        log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,finish()\", e);\n        return false;\n      } finally {\n        IOUtils.closeQuietly(proc);\n      }\n    }\n\n    return compareFingerprint(sreq);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e5fa6615014cd2288fe930f8c8bb726f9504961d","date":1490280013,"type":3,"author":"Noble Paul","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/update/PeerSync#handleUpdates(ShardResponse).mjava","pathOld":"solr/core/src/java/org/apache/solr/update/PeerSync#handleUpdates(ShardResponse).mjava","sourceNew":"  private boolean handleUpdates(ShardResponse srsp) {\n    // we retrieved the last N updates from the replica\n    List<Object> updates = (List<Object>)srsp.getSolrResponse().getResponse().get(\"updates\");\n\n    SyncShardRequest sreq = (SyncShardRequest) srsp.getShardRequest();\n    if (updates.size() < sreq.totalRequestedUpdates) {\n      log.error(msg() + \" Requested \" + sreq.totalRequestedUpdates + \" updates from \" + sreq.shards[0] + \" but retrieved \" + updates.size());\n      return false;\n    }\n    \n    // overwrite fingerprint we saved in 'handleVersions()'   \n    Object fingerprint = srsp.getSolrResponse().getResponse().get(\"fingerprint\");\n\n    if (fingerprint != null) {\n      sreq.fingerprint = IndexFingerprint.fromObject(fingerprint);\n    }\n\n\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(DISTRIB_UPDATE_PARAM, FROMLEADER.toString());\n    params.set(\"peersync\",true); // debugging\n    SolrQueryRequest req = new LocalSolrQueryRequest(uhandler.core, params);\n    SolrQueryResponse rsp = new SolrQueryResponse();\n\n    UpdateRequestProcessorChain processorChain = req.getCore().getUpdateProcessingChain(null);\n    UpdateRequestProcessor proc = processorChain.createProcessor(req, rsp);\n\n    Collections.sort(updates, updateRecordComparator);\n\n    Object o = null;\n    long lastVersion = 0;\n    try {\n      // Apply oldest updates first\n      for (Object obj : updates) {\n        // should currently be a List<Oper,Ver,Doc/Id>\n        o = obj;\n        List<Object> entry = (List<Object>)o;\n\n        if (debug) {\n          log.debug(msg() + \"raw update record \" + o);\n        }\n\n        int oper = (Integer)entry.get(0) & UpdateLog.OPERATION_MASK;\n        long version = (Long) entry.get(1);\n        if (version == lastVersion && version != 0) continue;\n        lastVersion = version;\n\n        switch (oper) {\n          case UpdateLog.ADD:\n          {\n            // byte[] idBytes = (byte[]) entry.get(2);\n            SolrInputDocument sdoc = (SolrInputDocument)entry.get(entry.size()-1);\n            AddUpdateCommand cmd = new AddUpdateCommand(req);\n            // cmd.setIndexedId(new BytesRef(idBytes));\n            cmd.solrDoc = sdoc;\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"add \" + cmd + \" id \" + sdoc.getField(ID));\n            }\n            proc.processAdd(cmd);\n            break;\n          }\n          case UpdateLog.DELETE:\n          {\n            byte[] idBytes = (byte[]) entry.get(2);\n            DeleteUpdateCommand cmd = new DeleteUpdateCommand(req);\n            cmd.setIndexedId(new BytesRef(idBytes));\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"delete \" + cmd + \" \" + new BytesRef(idBytes).utf8ToString());\n            }\n            proc.processDelete(cmd);\n            break;\n          }\n\n          case UpdateLog.DELETE_BY_QUERY:\n          {\n            String query = (String)entry.get(2);\n            DeleteUpdateCommand cmd = new DeleteUpdateCommand(req);\n            cmd.query = query;\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"deleteByQuery \" + cmd);\n            }\n            proc.processDelete(cmd);\n            break;\n          }\n          case UpdateLog.UPDATE_INPLACE:\n          {\n            AddUpdateCommand cmd = UpdateLog.convertTlogEntryToAddUpdateCommand(req, entry, oper, version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"inplace update \" + cmd + \" prevVersion=\" + cmd.prevVersion + \", doc=\" + cmd.solrDoc);\n            }\n            proc.processAdd(cmd);\n            break;\n          }\n\n          default:\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n        }\n\n      }\n\n    }\n    catch (IOException e) {\n      // TODO: should this be handled separately as a problem with us?\n      // I guess it probably already will by causing replication to be kicked off.\n      sreq.updateException = e;\n      log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,update=\" + o, e);\n      return false;\n    }\n    catch (Exception e) {\n      sreq.updateException = e;\n      log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,update=\" + o, e);\n      return false;\n    }\n    finally {\n      try {\n        proc.finish();\n      } catch (Exception e) {\n        sreq.updateException = e;\n        log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,finish()\", e);\n        return false;\n      } finally {\n        IOUtils.closeQuietly(proc);\n      }\n    }\n\n    return compareFingerprint(sreq);\n  }\n\n","sourceOld":"  private boolean handleUpdates(ShardResponse srsp) {\n    // we retrieved the last N updates from the replica\n    List<Object> updates = (List<Object>)srsp.getSolrResponse().getResponse().get(\"updates\");\n\n    SyncShardRequest sreq = (SyncShardRequest) srsp.getShardRequest();\n    if (updates.size() < sreq.totalRequestedUpdates) {\n      log.error(msg() + \" Requested \" + sreq.totalRequestedUpdates + \" updates from \" + sreq.shards[0] + \" but retrieved \" + updates.size());\n      return false;\n    }\n    \n    // overwrite fingerprint we saved in 'handleVersions()'   \n    Object fingerprint = srsp.getSolrResponse().getResponse().get(\"fingerprint\");\n\n    if (fingerprint != null) {\n      sreq.fingerprint = IndexFingerprint.fromObject(fingerprint);\n    }\n\n\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(DISTRIB_UPDATE_PARAM, FROMLEADER.toString());\n    params.set(\"peersync\",true); // debugging\n    SolrQueryRequest req = new LocalSolrQueryRequest(uhandler.core, params);\n    SolrQueryResponse rsp = new SolrQueryResponse();\n\n    UpdateRequestProcessorChain processorChain = req.getCore().getUpdateProcessingChain(null);\n    UpdateRequestProcessor proc = processorChain.createProcessor(req, rsp);\n\n    Collections.sort(updates, updateRecordComparator);\n\n    Object o = null;\n    long lastVersion = 0;\n    try {\n      // Apply oldest updates first\n      for (Object obj : updates) {\n        // should currently be a List<Oper,Ver,Doc/Id>\n        o = obj;\n        List<Object> entry = (List<Object>)o;\n\n        if (debug) {\n          log.debug(msg() + \"raw update record \" + o);\n        }\n\n        int oper = (Integer)entry.get(0) & UpdateLog.OPERATION_MASK;\n        long version = (Long) entry.get(1);\n        if (version == lastVersion && version != 0) continue;\n        lastVersion = version;\n\n        switch (oper) {\n          case UpdateLog.ADD:\n          {\n            // byte[] idBytes = (byte[]) entry.get(2);\n            SolrInputDocument sdoc = (SolrInputDocument)entry.get(entry.size()-1);\n            AddUpdateCommand cmd = new AddUpdateCommand(req);\n            // cmd.setIndexedId(new BytesRef(idBytes));\n            cmd.solrDoc = sdoc;\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"add \" + cmd + \" id \" + sdoc.getField(\"id\"));\n            }\n            proc.processAdd(cmd);\n            break;\n          }\n          case UpdateLog.DELETE:\n          {\n            byte[] idBytes = (byte[]) entry.get(2);\n            DeleteUpdateCommand cmd = new DeleteUpdateCommand(req);\n            cmd.setIndexedId(new BytesRef(idBytes));\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"delete \" + cmd + \" \" + new BytesRef(idBytes).utf8ToString());\n            }\n            proc.processDelete(cmd);\n            break;\n          }\n\n          case UpdateLog.DELETE_BY_QUERY:\n          {\n            String query = (String)entry.get(2);\n            DeleteUpdateCommand cmd = new DeleteUpdateCommand(req);\n            cmd.query = query;\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"deleteByQuery \" + cmd);\n            }\n            proc.processDelete(cmd);\n            break;\n          }\n          case UpdateLog.UPDATE_INPLACE:\n          {\n            AddUpdateCommand cmd = UpdateLog.convertTlogEntryToAddUpdateCommand(req, entry, oper, version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"inplace update \" + cmd + \" prevVersion=\" + cmd.prevVersion + \", doc=\" + cmd.solrDoc);\n            }\n            proc.processAdd(cmd);\n            break;\n          }\n\n          default:\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n        }\n\n      }\n\n    }\n    catch (IOException e) {\n      // TODO: should this be handled separately as a problem with us?\n      // I guess it probably already will by causing replication to be kicked off.\n      sreq.updateException = e;\n      log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,update=\" + o, e);\n      return false;\n    }\n    catch (Exception e) {\n      sreq.updateException = e;\n      log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,update=\" + o, e);\n      return false;\n    }\n    finally {\n      try {\n        proc.finish();\n      } catch (Exception e) {\n        sreq.updateException = e;\n        log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,finish()\", e);\n        return false;\n      } finally {\n        IOUtils.closeQuietly(proc);\n      }\n    }\n\n    return compareFingerprint(sreq);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ba0e7b86ac6002d5286b4589d87b3c80bbcabdc7","date":1529486762,"type":3,"author":"Cao Manh Dat","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/update/PeerSync#handleUpdates(ShardResponse).mjava","pathOld":"solr/core/src/java/org/apache/solr/update/PeerSync#handleUpdates(ShardResponse).mjava","sourceNew":"  private boolean handleUpdates(ShardResponse srsp) {\n    // we retrieved the last N updates from the replica\n    List<Object> updates = (List<Object>)srsp.getSolrResponse().getResponse().get(\"updates\");\n\n    SyncShardRequest sreq = (SyncShardRequest) srsp.getShardRequest();\n    if (updates.size() < sreq.totalRequestedUpdates) {\n      log.error(msg() + \" Requested \" + sreq.totalRequestedUpdates + \" updates from \" + sreq.shards[0] + \" but retrieved \" + updates.size());\n      return false;\n    }\n    \n    // overwrite fingerprint we saved in 'handleVersions()'   \n    Object fingerprint = srsp.getSolrResponse().getResponse().get(\"fingerprint\");\n\n    if (fingerprint != null) {\n      sreq.fingerprint = IndexFingerprint.fromObject(fingerprint);\n    }\n\n    try {\n      this.updater.applyUpdates(updates, sreq.shards);\n    } catch (Exception e) {\n      sreq.updateException = e;\n      return false;\n    }\n\n    return compareFingerprint(sreq);\n  }\n\n","sourceOld":"  private boolean handleUpdates(ShardResponse srsp) {\n    // we retrieved the last N updates from the replica\n    List<Object> updates = (List<Object>)srsp.getSolrResponse().getResponse().get(\"updates\");\n\n    SyncShardRequest sreq = (SyncShardRequest) srsp.getShardRequest();\n    if (updates.size() < sreq.totalRequestedUpdates) {\n      log.error(msg() + \" Requested \" + sreq.totalRequestedUpdates + \" updates from \" + sreq.shards[0] + \" but retrieved \" + updates.size());\n      return false;\n    }\n    \n    // overwrite fingerprint we saved in 'handleVersions()'   \n    Object fingerprint = srsp.getSolrResponse().getResponse().get(\"fingerprint\");\n\n    if (fingerprint != null) {\n      sreq.fingerprint = IndexFingerprint.fromObject(fingerprint);\n    }\n\n\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(DISTRIB_UPDATE_PARAM, FROMLEADER.toString());\n    params.set(\"peersync\",true); // debugging\n    SolrQueryRequest req = new LocalSolrQueryRequest(uhandler.core, params);\n    SolrQueryResponse rsp = new SolrQueryResponse();\n\n    UpdateRequestProcessorChain processorChain = req.getCore().getUpdateProcessingChain(null);\n    UpdateRequestProcessor proc = processorChain.createProcessor(req, rsp);\n\n    Collections.sort(updates, updateRecordComparator);\n\n    Object o = null;\n    long lastVersion = 0;\n    try {\n      // Apply oldest updates first\n      for (Object obj : updates) {\n        // should currently be a List<Oper,Ver,Doc/Id>\n        o = obj;\n        List<Object> entry = (List<Object>)o;\n\n        if (debug) {\n          log.debug(msg() + \"raw update record \" + o);\n        }\n\n        int oper = (Integer)entry.get(0) & UpdateLog.OPERATION_MASK;\n        long version = (Long) entry.get(1);\n        if (version == lastVersion && version != 0) continue;\n        lastVersion = version;\n\n        switch (oper) {\n          case UpdateLog.ADD:\n          {\n            // byte[] idBytes = (byte[]) entry.get(2);\n            SolrInputDocument sdoc = (SolrInputDocument)entry.get(entry.size()-1);\n            AddUpdateCommand cmd = new AddUpdateCommand(req);\n            // cmd.setIndexedId(new BytesRef(idBytes));\n            cmd.solrDoc = sdoc;\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"add \" + cmd + \" id \" + sdoc.getField(ID));\n            }\n            proc.processAdd(cmd);\n            break;\n          }\n          case UpdateLog.DELETE:\n          {\n            byte[] idBytes = (byte[]) entry.get(2);\n            DeleteUpdateCommand cmd = new DeleteUpdateCommand(req);\n            cmd.setIndexedId(new BytesRef(idBytes));\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"delete \" + cmd + \" \" + new BytesRef(idBytes).utf8ToString());\n            }\n            proc.processDelete(cmd);\n            break;\n          }\n\n          case UpdateLog.DELETE_BY_QUERY:\n          {\n            String query = (String)entry.get(2);\n            DeleteUpdateCommand cmd = new DeleteUpdateCommand(req);\n            cmd.query = query;\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"deleteByQuery \" + cmd);\n            }\n            proc.processDelete(cmd);\n            break;\n          }\n          case UpdateLog.UPDATE_INPLACE:\n          {\n            AddUpdateCommand cmd = UpdateLog.convertTlogEntryToAddUpdateCommand(req, entry, oper, version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"inplace update \" + cmd + \" prevVersion=\" + cmd.prevVersion + \", doc=\" + cmd.solrDoc);\n            }\n            proc.processAdd(cmd);\n            break;\n          }\n\n          default:\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n        }\n\n      }\n\n    }\n    catch (IOException e) {\n      // TODO: should this be handled separately as a problem with us?\n      // I guess it probably already will by causing replication to be kicked off.\n      sreq.updateException = e;\n      log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,update=\" + o, e);\n      return false;\n    }\n    catch (Exception e) {\n      sreq.updateException = e;\n      log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,update=\" + o, e);\n      return false;\n    }\n    finally {\n      try {\n        proc.finish();\n      } catch (Exception e) {\n        sreq.updateException = e;\n        log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,finish()\", e);\n        return false;\n      } finally {\n        IOUtils.closeQuietly(proc);\n      }\n    }\n\n    return compareFingerprint(sreq);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7eeaaea0106c7d6a2de50acfc8d357121ef8bd26","date":1531589977,"type":3,"author":"Michael Braun","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/update/PeerSync#handleUpdates(ShardResponse).mjava","pathOld":"solr/core/src/java/org/apache/solr/update/PeerSync#handleUpdates(ShardResponse).mjava","sourceNew":"  private boolean handleUpdates(ShardResponse srsp) {\n    // we retrieved the last N updates from the replica\n    List<Object> updates = (List<Object>)srsp.getSolrResponse().getResponse().get(\"updates\");\n\n    SyncShardRequest sreq = (SyncShardRequest) srsp.getShardRequest();\n    if (updates.size() < sreq.totalRequestedUpdates) {\n      log.error(msg() + \" Requested \" + sreq.totalRequestedUpdates + \" updates from \" + sreq.shards[0] + \" but retrieved \" + updates.size());\n      return false;\n    }\n    \n    // overwrite fingerprint we saved in 'handleVersions()'   \n    Object fingerprint = srsp.getSolrResponse().getResponse().get(\"fingerprint\");\n\n    if (fingerprint != null) {\n      sreq.fingerprint = IndexFingerprint.fromObject(fingerprint);\n    }\n\n    try {\n      this.updater.applyUpdates(updates, sreq.shards);\n    } catch (Exception e) {\n      sreq.updateException = e;\n      return false;\n    }\n\n    return compareFingerprint(sreq);\n  }\n\n","sourceOld":"  private boolean handleUpdates(ShardResponse srsp) {\n    // we retrieved the last N updates from the replica\n    List<Object> updates = (List<Object>)srsp.getSolrResponse().getResponse().get(\"updates\");\n\n    SyncShardRequest sreq = (SyncShardRequest) srsp.getShardRequest();\n    if (updates.size() < sreq.totalRequestedUpdates) {\n      log.error(msg() + \" Requested \" + sreq.totalRequestedUpdates + \" updates from \" + sreq.shards[0] + \" but retrieved \" + updates.size());\n      return false;\n    }\n    \n    // overwrite fingerprint we saved in 'handleVersions()'   \n    Object fingerprint = srsp.getSolrResponse().getResponse().get(\"fingerprint\");\n\n    if (fingerprint != null) {\n      sreq.fingerprint = IndexFingerprint.fromObject(fingerprint);\n    }\n\n\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(DISTRIB_UPDATE_PARAM, FROMLEADER.toString());\n    params.set(\"peersync\",true); // debugging\n    SolrQueryRequest req = new LocalSolrQueryRequest(uhandler.core, params);\n    SolrQueryResponse rsp = new SolrQueryResponse();\n\n    UpdateRequestProcessorChain processorChain = req.getCore().getUpdateProcessingChain(null);\n    UpdateRequestProcessor proc = processorChain.createProcessor(req, rsp);\n\n    Collections.sort(updates, updateRecordComparator);\n\n    Object o = null;\n    long lastVersion = 0;\n    try {\n      // Apply oldest updates first\n      for (Object obj : updates) {\n        // should currently be a List<Oper,Ver,Doc/Id>\n        o = obj;\n        List<Object> entry = (List<Object>)o;\n\n        if (debug) {\n          log.debug(msg() + \"raw update record \" + o);\n        }\n\n        int oper = (Integer)entry.get(0) & UpdateLog.OPERATION_MASK;\n        long version = (Long) entry.get(1);\n        if (version == lastVersion && version != 0) continue;\n        lastVersion = version;\n\n        switch (oper) {\n          case UpdateLog.ADD:\n          {\n            // byte[] idBytes = (byte[]) entry.get(2);\n            SolrInputDocument sdoc = (SolrInputDocument)entry.get(entry.size()-1);\n            AddUpdateCommand cmd = new AddUpdateCommand(req);\n            // cmd.setIndexedId(new BytesRef(idBytes));\n            cmd.solrDoc = sdoc;\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"add \" + cmd + \" id \" + sdoc.getField(ID));\n            }\n            proc.processAdd(cmd);\n            break;\n          }\n          case UpdateLog.DELETE:\n          {\n            byte[] idBytes = (byte[]) entry.get(2);\n            DeleteUpdateCommand cmd = new DeleteUpdateCommand(req);\n            cmd.setIndexedId(new BytesRef(idBytes));\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"delete \" + cmd + \" \" + new BytesRef(idBytes).utf8ToString());\n            }\n            proc.processDelete(cmd);\n            break;\n          }\n\n          case UpdateLog.DELETE_BY_QUERY:\n          {\n            String query = (String)entry.get(2);\n            DeleteUpdateCommand cmd = new DeleteUpdateCommand(req);\n            cmd.query = query;\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"deleteByQuery \" + cmd);\n            }\n            proc.processDelete(cmd);\n            break;\n          }\n          case UpdateLog.UPDATE_INPLACE:\n          {\n            AddUpdateCommand cmd = UpdateLog.convertTlogEntryToAddUpdateCommand(req, entry, oper, version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"inplace update \" + cmd + \" prevVersion=\" + cmd.prevVersion + \", doc=\" + cmd.solrDoc);\n            }\n            proc.processAdd(cmd);\n            break;\n          }\n\n          default:\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n        }\n\n      }\n\n    }\n    catch (IOException e) {\n      // TODO: should this be handled separately as a problem with us?\n      // I guess it probably already will by causing replication to be kicked off.\n      sreq.updateException = e;\n      log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,update=\" + o, e);\n      return false;\n    }\n    catch (Exception e) {\n      sreq.updateException = e;\n      log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,update=\" + o, e);\n      return false;\n    }\n    finally {\n      try {\n        proc.finish();\n      } catch (Exception e) {\n        sreq.updateException = e;\n        log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,finish()\", e);\n        return false;\n      } finally {\n        IOUtils.closeQuietly(proc);\n      }\n    }\n\n    return compareFingerprint(sreq);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0efc9f2cae117418f13ba9035f5e1d516ea7a2b5","date":1531905561,"type":3,"author":"Alessandro Benedetti","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/update/PeerSync#handleUpdates(ShardResponse).mjava","pathOld":"solr/core/src/java/org/apache/solr/update/PeerSync#handleUpdates(ShardResponse).mjava","sourceNew":"  private boolean handleUpdates(ShardResponse srsp) {\n    // we retrieved the last N updates from the replica\n    List<Object> updates = (List<Object>)srsp.getSolrResponse().getResponse().get(\"updates\");\n\n    SyncShardRequest sreq = (SyncShardRequest) srsp.getShardRequest();\n    if (updates.size() < sreq.totalRequestedUpdates) {\n      log.error(msg() + \" Requested \" + sreq.totalRequestedUpdates + \" updates from \" + sreq.shards[0] + \" but retrieved \" + updates.size());\n      return false;\n    }\n    \n    // overwrite fingerprint we saved in 'handleVersions()'   \n    Object fingerprint = srsp.getSolrResponse().getResponse().get(\"fingerprint\");\n\n    if (fingerprint != null) {\n      sreq.fingerprint = IndexFingerprint.fromObject(fingerprint);\n    }\n\n    try {\n      this.updater.applyUpdates(updates, sreq.shards);\n    } catch (Exception e) {\n      sreq.updateException = e;\n      return false;\n    }\n\n    return compareFingerprint(sreq);\n  }\n\n","sourceOld":"  private boolean handleUpdates(ShardResponse srsp) {\n    // we retrieved the last N updates from the replica\n    List<Object> updates = (List<Object>)srsp.getSolrResponse().getResponse().get(\"updates\");\n\n    SyncShardRequest sreq = (SyncShardRequest) srsp.getShardRequest();\n    if (updates.size() < sreq.totalRequestedUpdates) {\n      log.error(msg() + \" Requested \" + sreq.totalRequestedUpdates + \" updates from \" + sreq.shards[0] + \" but retrieved \" + updates.size());\n      return false;\n    }\n    \n    // overwrite fingerprint we saved in 'handleVersions()'   \n    Object fingerprint = srsp.getSolrResponse().getResponse().get(\"fingerprint\");\n\n    if (fingerprint != null) {\n      sreq.fingerprint = IndexFingerprint.fromObject(fingerprint);\n    }\n\n\n    ModifiableSolrParams params = new ModifiableSolrParams();\n    params.set(DISTRIB_UPDATE_PARAM, FROMLEADER.toString());\n    params.set(\"peersync\",true); // debugging\n    SolrQueryRequest req = new LocalSolrQueryRequest(uhandler.core, params);\n    SolrQueryResponse rsp = new SolrQueryResponse();\n\n    UpdateRequestProcessorChain processorChain = req.getCore().getUpdateProcessingChain(null);\n    UpdateRequestProcessor proc = processorChain.createProcessor(req, rsp);\n\n    Collections.sort(updates, updateRecordComparator);\n\n    Object o = null;\n    long lastVersion = 0;\n    try {\n      // Apply oldest updates first\n      for (Object obj : updates) {\n        // should currently be a List<Oper,Ver,Doc/Id>\n        o = obj;\n        List<Object> entry = (List<Object>)o;\n\n        if (debug) {\n          log.debug(msg() + \"raw update record \" + o);\n        }\n\n        int oper = (Integer)entry.get(0) & UpdateLog.OPERATION_MASK;\n        long version = (Long) entry.get(1);\n        if (version == lastVersion && version != 0) continue;\n        lastVersion = version;\n\n        switch (oper) {\n          case UpdateLog.ADD:\n          {\n            // byte[] idBytes = (byte[]) entry.get(2);\n            SolrInputDocument sdoc = (SolrInputDocument)entry.get(entry.size()-1);\n            AddUpdateCommand cmd = new AddUpdateCommand(req);\n            // cmd.setIndexedId(new BytesRef(idBytes));\n            cmd.solrDoc = sdoc;\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"add \" + cmd + \" id \" + sdoc.getField(ID));\n            }\n            proc.processAdd(cmd);\n            break;\n          }\n          case UpdateLog.DELETE:\n          {\n            byte[] idBytes = (byte[]) entry.get(2);\n            DeleteUpdateCommand cmd = new DeleteUpdateCommand(req);\n            cmd.setIndexedId(new BytesRef(idBytes));\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"delete \" + cmd + \" \" + new BytesRef(idBytes).utf8ToString());\n            }\n            proc.processDelete(cmd);\n            break;\n          }\n\n          case UpdateLog.DELETE_BY_QUERY:\n          {\n            String query = (String)entry.get(2);\n            DeleteUpdateCommand cmd = new DeleteUpdateCommand(req);\n            cmd.query = query;\n            cmd.setVersion(version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"deleteByQuery \" + cmd);\n            }\n            proc.processDelete(cmd);\n            break;\n          }\n          case UpdateLog.UPDATE_INPLACE:\n          {\n            AddUpdateCommand cmd = UpdateLog.convertTlogEntryToAddUpdateCommand(req, entry, oper, version);\n            cmd.setFlags(UpdateCommand.PEER_SYNC | UpdateCommand.IGNORE_AUTOCOMMIT);\n            if (debug) {\n              log.debug(msg() + \"inplace update \" + cmd + \" prevVersion=\" + cmd.prevVersion + \", doc=\" + cmd.solrDoc);\n            }\n            proc.processAdd(cmd);\n            break;\n          }\n\n          default:\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,  \"Unknown Operation! \" + oper);\n        }\n\n      }\n\n    }\n    catch (IOException e) {\n      // TODO: should this be handled separately as a problem with us?\n      // I guess it probably already will by causing replication to be kicked off.\n      sreq.updateException = e;\n      log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,update=\" + o, e);\n      return false;\n    }\n    catch (Exception e) {\n      sreq.updateException = e;\n      log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,update=\" + o, e);\n      return false;\n    }\n    finally {\n      try {\n        proc.finish();\n      } catch (Exception e) {\n        sreq.updateException = e;\n        log.error(msg() + \"Error applying updates from \" + sreq.shards + \" ,finish()\", e);\n        return false;\n      } finally {\n        IOUtils.closeQuietly(proc);\n      }\n    }\n\n    return compareFingerprint(sreq);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"740d649f013f07efbeb73ca854f106c60166e7c0","date":1587431295,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/update/PeerSync#handleUpdates(ShardResponse).mjava","pathOld":"solr/core/src/java/org/apache/solr/update/PeerSync#handleUpdates(ShardResponse).mjava","sourceNew":"  private boolean handleUpdates(ShardResponse srsp) {\n    // we retrieved the last N updates from the replica\n    List<Object> updates = (List<Object>)srsp.getSolrResponse().getResponse().get(\"updates\");\n\n    SyncShardRequest sreq = (SyncShardRequest) srsp.getShardRequest();\n    if (updates.size() < sreq.totalRequestedUpdates) {\n      log.error(\"{} Requested {} updates from {} but retrieved {}\", msg(), sreq.totalRequestedUpdates, sreq.shards[0], updates.size());\n      return false;\n    }\n    \n    // overwrite fingerprint we saved in 'handleVersions()'   \n    Object fingerprint = srsp.getSolrResponse().getResponse().get(\"fingerprint\");\n\n    if (fingerprint != null) {\n      sreq.fingerprint = IndexFingerprint.fromObject(fingerprint);\n    }\n\n    try {\n      this.updater.applyUpdates(updates, sreq.shards);\n    } catch (Exception e) {\n      sreq.updateException = e;\n      return false;\n    }\n\n    return compareFingerprint(sreq);\n  }\n\n","sourceOld":"  private boolean handleUpdates(ShardResponse srsp) {\n    // we retrieved the last N updates from the replica\n    List<Object> updates = (List<Object>)srsp.getSolrResponse().getResponse().get(\"updates\");\n\n    SyncShardRequest sreq = (SyncShardRequest) srsp.getShardRequest();\n    if (updates.size() < sreq.totalRequestedUpdates) {\n      log.error(msg() + \" Requested \" + sreq.totalRequestedUpdates + \" updates from \" + sreq.shards[0] + \" but retrieved \" + updates.size());\n      return false;\n    }\n    \n    // overwrite fingerprint we saved in 'handleVersions()'   \n    Object fingerprint = srsp.getSolrResponse().getResponse().get(\"fingerprint\");\n\n    if (fingerprint != null) {\n      sreq.fingerprint = IndexFingerprint.fromObject(fingerprint);\n    }\n\n    try {\n      this.updater.applyUpdates(updates, sreq.shards);\n    } catch (Exception e) {\n      sreq.updateException = e;\n      return false;\n    }\n\n    return compareFingerprint(sreq);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"018a36ff4088cb91ab12cbe44f696d81d1fadd77","date":1591657414,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/update/PeerSync#handleUpdates(ShardResponse).mjava","pathOld":"solr/core/src/java/org/apache/solr/update/PeerSync#handleUpdates(ShardResponse).mjava","sourceNew":"  private boolean handleUpdates(ShardResponse srsp) {\n    // we retrieved the last N updates from the replica\n    @SuppressWarnings({\"unchecked\"})\n    List<Object> updates = (List<Object>)srsp.getSolrResponse().getResponse().get(\"updates\");\n\n    SyncShardRequest sreq = (SyncShardRequest) srsp.getShardRequest();\n    if (updates.size() < sreq.totalRequestedUpdates) {\n      log.error(\"{} Requested {} updates from {} but retrieved {}\", msg(), sreq.totalRequestedUpdates, sreq.shards[0], updates.size());\n      return false;\n    }\n    \n    // overwrite fingerprint we saved in 'handleVersions()'   \n    Object fingerprint = srsp.getSolrResponse().getResponse().get(\"fingerprint\");\n\n    if (fingerprint != null) {\n      sreq.fingerprint = IndexFingerprint.fromObject(fingerprint);\n    }\n\n    try {\n      this.updater.applyUpdates(updates, sreq.shards);\n    } catch (Exception e) {\n      sreq.updateException = e;\n      return false;\n    }\n\n    return compareFingerprint(sreq);\n  }\n\n","sourceOld":"  private boolean handleUpdates(ShardResponse srsp) {\n    // we retrieved the last N updates from the replica\n    List<Object> updates = (List<Object>)srsp.getSolrResponse().getResponse().get(\"updates\");\n\n    SyncShardRequest sreq = (SyncShardRequest) srsp.getShardRequest();\n    if (updates.size() < sreq.totalRequestedUpdates) {\n      log.error(\"{} Requested {} updates from {} but retrieved {}\", msg(), sreq.totalRequestedUpdates, sreq.shards[0], updates.size());\n      return false;\n    }\n    \n    // overwrite fingerprint we saved in 'handleVersions()'   \n    Object fingerprint = srsp.getSolrResponse().getResponse().get(\"fingerprint\");\n\n    if (fingerprint != null) {\n      sreq.fingerprint = IndexFingerprint.fromObject(fingerprint);\n    }\n\n    try {\n      this.updater.applyUpdates(updates, sreq.shards);\n    } catch (Exception e) {\n      sreq.updateException = e;\n      return false;\n    }\n\n    return compareFingerprint(sreq);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"d3fcb70cf561547c7bb1506e0cf32ca7b1287064":["e2fe35ac47f8f51356d6c1724455d18f31c94fae","3d7c0c8a97beb56d2e168604f9928de17981eabe"],"5620d3cb34306ea5b7d016a832fbc964b74c2650":["2c007e7c4cf8c55bc2a5884e315123afaaeec87f"],"598b5d23aa7c9732bf473c21a9cd309c44599394":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b","415bbbe7da8065dd3c477bdc3c703c6425622998"],"018a36ff4088cb91ab12cbe44f696d81d1fadd77":["740d649f013f07efbeb73ca854f106c60166e7c0"],"740d649f013f07efbeb73ca854f106c60166e7c0":["ba0e7b86ac6002d5286b4589d87b3c80bbcabdc7"],"9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab":["5620d3cb34306ea5b7d016a832fbc964b74c2650","3060d5648a525a745f0ac45420e84bf5c7e9b135"],"6c94d2661bc1c14426980ec7882e951fdcff08d0":["0e05f2a24d572cfb09482deb87b03100ce3af1a7"],"3d7c0c8a97beb56d2e168604f9928de17981eabe":["e2fe35ac47f8f51356d6c1724455d18f31c94fae"],"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae":["0e05f2a24d572cfb09482deb87b03100ce3af1a7","6c94d2661bc1c14426980ec7882e951fdcff08d0"],"e511b092029d56e0d4e30204fba8509c1c2647b6":["979e22aa7c63c9dc651adf861610c7e444d45832"],"0efc9f2cae117418f13ba9035f5e1d516ea7a2b5":["6d2dadc1f5ca8703d8659f4964961f9967935d75","ba0e7b86ac6002d5286b4589d87b3c80bbcabdc7"],"0d22ac6a4146774c1bc8400160fc0b6150294e92":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","2c007e7c4cf8c55bc2a5884e315123afaaeec87f"],"4c835cc1a7b07477a469cdb1bf6c67bc05b85c07":["8381eb1cd44d2e0defb52130de3295a576ac1e7b"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"3599646b4d4c346cf74d334813488b8b337b5bf5":["3060d5648a525a745f0ac45420e84bf5c7e9b135","e99829242bceda4cf974ec0eb5d82d713615b3da"],"2d06ba55ef44382e5547ff01fff8eb1f0fa0faa6":["415bbbe7da8065dd3c477bdc3c703c6425622998"],"b1704c078ec59838c9d95d5bf5738b393b537494":["6c94d2661bc1c14426980ec7882e951fdcff08d0","979e22aa7c63c9dc651adf861610c7e444d45832"],"e99829242bceda4cf974ec0eb5d82d713615b3da":["3060d5648a525a745f0ac45420e84bf5c7e9b135"],"e1c5f7ce544a129550a8515f7f0eb5f1c0f4472a":["8381eb1cd44d2e0defb52130de3295a576ac1e7b","4c835cc1a7b07477a469cdb1bf6c67bc05b85c07"],"ba0e7b86ac6002d5286b4589d87b3c80bbcabdc7":["6d2dadc1f5ca8703d8659f4964961f9967935d75"],"7eeaaea0106c7d6a2de50acfc8d357121ef8bd26":["6d2dadc1f5ca8703d8659f4964961f9967935d75","ba0e7b86ac6002d5286b4589d87b3c80bbcabdc7"],"415bbbe7da8065dd3c477bdc3c703c6425622998":["e1c5f7ce544a129550a8515f7f0eb5f1c0f4472a"],"8381eb1cd44d2e0defb52130de3295a576ac1e7b":["979e22aa7c63c9dc651adf861610c7e444d45832","e511b092029d56e0d4e30204fba8509c1c2647b6"],"f8f7907798e0c730e9ab37681c6e8dfbde0e4173":["5620d3cb34306ea5b7d016a832fbc964b74c2650"],"6d2dadc1f5ca8703d8659f4964961f9967935d75":["2d06ba55ef44382e5547ff01fff8eb1f0fa0faa6"],"1e6acbaae7af722f17204ceccf0f7db5753eccf3":["6c94d2661bc1c14426980ec7882e951fdcff08d0","979e22aa7c63c9dc651adf861610c7e444d45832"],"a3c68e20c73359a10cf3eb4a35c9fa7ab1f3c30d":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","2c007e7c4cf8c55bc2a5884e315123afaaeec87f"],"0e05f2a24d572cfb09482deb87b03100ce3af1a7":["3d7c0c8a97beb56d2e168604f9928de17981eabe"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["979e22aa7c63c9dc651adf861610c7e444d45832","e1c5f7ce544a129550a8515f7f0eb5f1c0f4472a"],"e5fa6615014cd2288fe930f8c8bb726f9504961d":["2d06ba55ef44382e5547ff01fff8eb1f0fa0faa6"],"979e22aa7c63c9dc651adf861610c7e444d45832":["6c94d2661bc1c14426980ec7882e951fdcff08d0"],"2c007e7c4cf8c55bc2a5884e315123afaaeec87f":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"3060d5648a525a745f0ac45420e84bf5c7e9b135":["f8f7907798e0c730e9ab37681c6e8dfbde0e4173"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["018a36ff4088cb91ab12cbe44f696d81d1fadd77"],"e2fe35ac47f8f51356d6c1724455d18f31c94fae":["e99829242bceda4cf974ec0eb5d82d713615b3da"]},"commit2Childs":{"d3fcb70cf561547c7bb1506e0cf32ca7b1287064":[],"5620d3cb34306ea5b7d016a832fbc964b74c2650":["9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab","f8f7907798e0c730e9ab37681c6e8dfbde0e4173"],"598b5d23aa7c9732bf473c21a9cd309c44599394":[],"018a36ff4088cb91ab12cbe44f696d81d1fadd77":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"740d649f013f07efbeb73ca854f106c60166e7c0":["018a36ff4088cb91ab12cbe44f696d81d1fadd77"],"9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab":[],"6c94d2661bc1c14426980ec7882e951fdcff08d0":["a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","b1704c078ec59838c9d95d5bf5738b393b537494","1e6acbaae7af722f17204ceccf0f7db5753eccf3","979e22aa7c63c9dc651adf861610c7e444d45832"],"3d7c0c8a97beb56d2e168604f9928de17981eabe":["d3fcb70cf561547c7bb1506e0cf32ca7b1287064","0e05f2a24d572cfb09482deb87b03100ce3af1a7"],"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae":[],"e511b092029d56e0d4e30204fba8509c1c2647b6":["8381eb1cd44d2e0defb52130de3295a576ac1e7b"],"0efc9f2cae117418f13ba9035f5e1d516ea7a2b5":[],"0d22ac6a4146774c1bc8400160fc0b6150294e92":[],"4c835cc1a7b07477a469cdb1bf6c67bc05b85c07":["e1c5f7ce544a129550a8515f7f0eb5f1c0f4472a"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["0d22ac6a4146774c1bc8400160fc0b6150294e92","a3c68e20c73359a10cf3eb4a35c9fa7ab1f3c30d","2c007e7c4cf8c55bc2a5884e315123afaaeec87f"],"3599646b4d4c346cf74d334813488b8b337b5bf5":[],"2d06ba55ef44382e5547ff01fff8eb1f0fa0faa6":["6d2dadc1f5ca8703d8659f4964961f9967935d75","e5fa6615014cd2288fe930f8c8bb726f9504961d"],"b1704c078ec59838c9d95d5bf5738b393b537494":[],"e99829242bceda4cf974ec0eb5d82d713615b3da":["3599646b4d4c346cf74d334813488b8b337b5bf5","e2fe35ac47f8f51356d6c1724455d18f31c94fae"],"e1c5f7ce544a129550a8515f7f0eb5f1c0f4472a":["415bbbe7da8065dd3c477bdc3c703c6425622998","4cce5816ef15a48a0bc11e5d400497ee4301dd3b"],"ba0e7b86ac6002d5286b4589d87b3c80bbcabdc7":["740d649f013f07efbeb73ca854f106c60166e7c0","0efc9f2cae117418f13ba9035f5e1d516ea7a2b5","7eeaaea0106c7d6a2de50acfc8d357121ef8bd26"],"7eeaaea0106c7d6a2de50acfc8d357121ef8bd26":[],"415bbbe7da8065dd3c477bdc3c703c6425622998":["598b5d23aa7c9732bf473c21a9cd309c44599394","2d06ba55ef44382e5547ff01fff8eb1f0fa0faa6"],"8381eb1cd44d2e0defb52130de3295a576ac1e7b":["4c835cc1a7b07477a469cdb1bf6c67bc05b85c07","e1c5f7ce544a129550a8515f7f0eb5f1c0f4472a"],"f8f7907798e0c730e9ab37681c6e8dfbde0e4173":["3060d5648a525a745f0ac45420e84bf5c7e9b135"],"6d2dadc1f5ca8703d8659f4964961f9967935d75":["0efc9f2cae117418f13ba9035f5e1d516ea7a2b5","ba0e7b86ac6002d5286b4589d87b3c80bbcabdc7","7eeaaea0106c7d6a2de50acfc8d357121ef8bd26"],"1e6acbaae7af722f17204ceccf0f7db5753eccf3":[],"a3c68e20c73359a10cf3eb4a35c9fa7ab1f3c30d":[],"0e05f2a24d572cfb09482deb87b03100ce3af1a7":["6c94d2661bc1c14426980ec7882e951fdcff08d0","a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["598b5d23aa7c9732bf473c21a9cd309c44599394"],"e5fa6615014cd2288fe930f8c8bb726f9504961d":[],"2c007e7c4cf8c55bc2a5884e315123afaaeec87f":["5620d3cb34306ea5b7d016a832fbc964b74c2650","0d22ac6a4146774c1bc8400160fc0b6150294e92","a3c68e20c73359a10cf3eb4a35c9fa7ab1f3c30d"],"979e22aa7c63c9dc651adf861610c7e444d45832":["e511b092029d56e0d4e30204fba8509c1c2647b6","b1704c078ec59838c9d95d5bf5738b393b537494","8381eb1cd44d2e0defb52130de3295a576ac1e7b","1e6acbaae7af722f17204ceccf0f7db5753eccf3","4cce5816ef15a48a0bc11e5d400497ee4301dd3b"],"3060d5648a525a745f0ac45420e84bf5c7e9b135":["9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab","3599646b4d4c346cf74d334813488b8b337b5bf5","e99829242bceda4cf974ec0eb5d82d713615b3da"],"e2fe35ac47f8f51356d6c1724455d18f31c94fae":["d3fcb70cf561547c7bb1506e0cf32ca7b1287064","3d7c0c8a97beb56d2e168604f9928de17981eabe"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["d3fcb70cf561547c7bb1506e0cf32ca7b1287064","598b5d23aa7c9732bf473c21a9cd309c44599394","9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab","a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","0efc9f2cae117418f13ba9035f5e1d516ea7a2b5","0d22ac6a4146774c1bc8400160fc0b6150294e92","3599646b4d4c346cf74d334813488b8b337b5bf5","b1704c078ec59838c9d95d5bf5738b393b537494","7eeaaea0106c7d6a2de50acfc8d357121ef8bd26","1e6acbaae7af722f17204ceccf0f7db5753eccf3","a3c68e20c73359a10cf3eb4a35c9fa7ab1f3c30d","e5fa6615014cd2288fe930f8c8bb726f9504961d","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}