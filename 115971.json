{"path":"lucene/test-framework/src/java/org/apache/lucene/analysis/BaseTokenStreamTestCase#assertAnalyzesTo(Analyzer,String,String[],int[],int[],String[],int[],int[],boolean,byte[][]).mjava","commits":[{"id":"afc5b4b2446e392448f36ae4f5a164540f2ccb65","date":1513355058,"type":0,"author":"Steve Rowe","isMerge":false,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/analysis/BaseTokenStreamTestCase#assertAnalyzesTo(Analyzer,String,String[],int[],int[],String[],int[],int[],boolean,byte[][]).mjava","pathOld":"/dev/null","sourceNew":"  public static void assertAnalyzesTo(Analyzer a, String input, String[] output, int startOffsets[], int endOffsets[], String types[], int posIncrements[], int posLengths[], boolean offsetsAreCorrect, byte[][] payloads) throws IOException {\n    checkResetException(a, input);\n    assertTokenStreamContents(a.tokenStream(\"dummy\", input), output, startOffsets, endOffsets, types, posIncrements, posLengths, input.length(), null, null, offsetsAreCorrect, payloads);\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["995993f24c9f6feb42b49b71e1982cda8fa0b37c"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"995993f24c9f6feb42b49b71e1982cda8fa0b37c","date":1522116154,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/analysis/BaseTokenStreamTestCase#assertAnalyzesTo(Analyzer,String,String[],int[],int[],String[],int[],int[],boolean,byte[][]).mjava","pathOld":"lucene/test-framework/src/java/org/apache/lucene/analysis/BaseTokenStreamTestCase#assertAnalyzesTo(Analyzer,String,String[],int[],int[],String[],int[],int[],boolean,byte[][]).mjava","sourceNew":"  public static void assertAnalyzesTo(Analyzer a, String input, String[] output, int startOffsets[], int endOffsets[], String types[], int posIncrements[], int posLengths[], boolean graphOffsetsAreCorrect, byte[][] payloads) throws IOException {\n    checkResetException(a, input);\n    assertTokenStreamContents(a.tokenStream(\"dummy\", input), output, startOffsets, endOffsets, types, posIncrements, posLengths, input.length(), null, null, graphOffsetsAreCorrect, payloads);\n  }\n\n","sourceOld":"  public static void assertAnalyzesTo(Analyzer a, String input, String[] output, int startOffsets[], int endOffsets[], String types[], int posIncrements[], int posLengths[], boolean offsetsAreCorrect, byte[][] payloads) throws IOException {\n    checkResetException(a, input);\n    assertTokenStreamContents(a.tokenStream(\"dummy\", input), output, startOffsets, endOffsets, types, posIncrements, posLengths, input.length(), null, null, offsetsAreCorrect, payloads);\n  }\n\n","bugFix":["afc5b4b2446e392448f36ae4f5a164540f2ccb65"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d61a3e0821ed080b9b21e1328bbaa91dcf79f7d7","date":1522191940,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/analysis/BaseTokenStreamTestCase#assertAnalyzesTo(Analyzer,String,String[],int[],int[],String[],int[],int[],boolean,byte[][]).mjava","pathOld":"lucene/test-framework/src/java/org/apache/lucene/analysis/BaseTokenStreamTestCase#assertAnalyzesTo(Analyzer,String,String[],int[],int[],String[],int[],int[],boolean,byte[][]).mjava","sourceNew":"  public static void assertAnalyzesTo(Analyzer a, String input, String[] output, int startOffsets[], int endOffsets[], String types[], int posIncrements[], int posLengths[], boolean graphOffsetsAreCorrect, byte[][] payloads) throws IOException {\n    checkResetException(a, input);\n    assertTokenStreamContents(a.tokenStream(\"dummy\", input), output, startOffsets, endOffsets, types, posIncrements, posLengths, input.length(), null, null, graphOffsetsAreCorrect, payloads);\n  }\n\n","sourceOld":"  public static void assertAnalyzesTo(Analyzer a, String input, String[] output, int startOffsets[], int endOffsets[], String types[], int posIncrements[], int posLengths[], boolean offsetsAreCorrect, byte[][] payloads) throws IOException {\n    checkResetException(a, input);\n    assertTokenStreamContents(a.tokenStream(\"dummy\", input), output, startOffsets, endOffsets, types, posIncrements, posLengths, input.length(), null, null, offsetsAreCorrect, payloads);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1c85bcc0cb48e35688c792a172bed271a9836d6b","date":1571776257,"type":3,"author":"David Smiley","isMerge":false,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/analysis/BaseTokenStreamTestCase#assertAnalyzesTo(Analyzer,String,String[],int[],int[],String[],int[],int[],boolean,byte[][]).mjava","pathOld":"lucene/test-framework/src/java/org/apache/lucene/analysis/BaseTokenStreamTestCase#assertAnalyzesTo(Analyzer,String,String[],int[],int[],String[],int[],int[],boolean,byte[][]).mjava","sourceNew":"  public static void assertAnalyzesTo(Analyzer a, String input, String[] output, int startOffsets[], int endOffsets[], String types[], int posIncrements[], int posLengths[], boolean graphOffsetsAreCorrect, byte[][] payloads) throws IOException {\n    assertTokenStreamContents(a.tokenStream(\"dummy\", input), output, startOffsets, endOffsets, types, posIncrements, posLengths, input.length(), null, null, graphOffsetsAreCorrect, payloads);\n    checkResetException(a, input);\n  }\n\n","sourceOld":"  public static void assertAnalyzesTo(Analyzer a, String input, String[] output, int startOffsets[], int endOffsets[], String types[], int posIncrements[], int posLengths[], boolean graphOffsetsAreCorrect, byte[][] payloads) throws IOException {\n    checkResetException(a, input);\n    assertTokenStreamContents(a.tokenStream(\"dummy\", input), output, startOffsets, endOffsets, types, posIncrements, posLengths, input.length(), null, null, graphOffsetsAreCorrect, payloads);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"560fe82f36cc44907b79b23f49d25f60e5e86fe4","date":1601610183,"type":3,"author":"David Smiley","isMerge":false,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/analysis/BaseTokenStreamTestCase#assertAnalyzesTo(Analyzer,String,String[],int[],int[],String[],int[],int[],boolean,byte[][]).mjava","pathOld":"lucene/test-framework/src/java/org/apache/lucene/analysis/BaseTokenStreamTestCase#assertAnalyzesTo(Analyzer,String,String[],int[],int[],String[],int[],int[],boolean,byte[][]).mjava","sourceNew":"  public static void assertAnalyzesTo(Analyzer a, String input, String[] output, int startOffsets[], int endOffsets[], String types[], int posIncrements[], int posLengths[], boolean graphOffsetsAreCorrect, byte[][] payloads) throws IOException {\n    assertTokenStreamContents(a.tokenStream(\"dummy\", input), output, startOffsets, endOffsets, types, posIncrements, posLengths, input.length(), null, null, graphOffsetsAreCorrect, payloads);\n    checkResetException(a, input);\n    checkAnalysisConsistency(random(), a, true, input, graphOffsetsAreCorrect);\n  }\n\n","sourceOld":"  public static void assertAnalyzesTo(Analyzer a, String input, String[] output, int startOffsets[], int endOffsets[], String types[], int posIncrements[], int posLengths[], boolean graphOffsetsAreCorrect, byte[][] payloads) throws IOException {\n    assertTokenStreamContents(a.tokenStream(\"dummy\", input), output, startOffsets, endOffsets, types, posIncrements, posLengths, input.length(), null, null, graphOffsetsAreCorrect, payloads);\n    checkResetException(a, input);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"995993f24c9f6feb42b49b71e1982cda8fa0b37c":["afc5b4b2446e392448f36ae4f5a164540f2ccb65"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"d61a3e0821ed080b9b21e1328bbaa91dcf79f7d7":["afc5b4b2446e392448f36ae4f5a164540f2ccb65","995993f24c9f6feb42b49b71e1982cda8fa0b37c"],"1c85bcc0cb48e35688c792a172bed271a9836d6b":["d61a3e0821ed080b9b21e1328bbaa91dcf79f7d7"],"560fe82f36cc44907b79b23f49d25f60e5e86fe4":["1c85bcc0cb48e35688c792a172bed271a9836d6b"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["560fe82f36cc44907b79b23f49d25f60e5e86fe4"],"afc5b4b2446e392448f36ae4f5a164540f2ccb65":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"995993f24c9f6feb42b49b71e1982cda8fa0b37c":["d61a3e0821ed080b9b21e1328bbaa91dcf79f7d7"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["afc5b4b2446e392448f36ae4f5a164540f2ccb65"],"d61a3e0821ed080b9b21e1328bbaa91dcf79f7d7":["1c85bcc0cb48e35688c792a172bed271a9836d6b"],"1c85bcc0cb48e35688c792a172bed271a9836d6b":["560fe82f36cc44907b79b23f49d25f60e5e86fe4"],"560fe82f36cc44907b79b23f49d25f60e5e86fe4":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"afc5b4b2446e392448f36ae4f5a164540f2ccb65":["995993f24c9f6feb42b49b71e1982cda8fa0b37c","d61a3e0821ed080b9b21e1328bbaa91dcf79f7d7"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}