{"path":"lucene/queryparser/src/java/org/apache/lucene/queryparser/analyzing/AnalyzingQueryParser#analyzeSingleChunk(String,String,String).mjava","commits":[{"id":"046829b17e246624c179b94d5a20cb53fa945e87","date":1367880720,"type":0,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/queryparser/src/java/org/apache/lucene/queryparser/analyzing/AnalyzingQueryParser#analyzeSingleChunk(String,String,String).mjava","pathOld":"/dev/null","sourceNew":"  /**\n   * Returns the analyzed form for the given chunk\n   * \n   * If the analyzer produces more than one output token from the given chunk,\n   * a ParseException is thrown.\n   *\n   * @param field The target field\n   * @param termStr The full term from which the given chunk is excerpted\n   * @param chunk The portion of the given termStr to be analyzed\n   * @return The result of analyzing the given chunk\n   * @throws ParseException when analysis returns other than one output token\n   */\n  protected String analyzeSingleChunk(String field, String termStr, String chunk) throws ParseException{\n    String analyzed = null;\n    TokenStream stream = null;\n    try{\n      stream = getAnalyzer().tokenStream(field, new StringReader(chunk));\n      stream.reset();\n      CharTermAttribute termAtt = stream.getAttribute(CharTermAttribute.class);\n      // get first and hopefully only output token\n      if (stream.incrementToken()) {\n        analyzed = termAtt.toString();\n        \n        // try to increment again, there should only be one output token\n        StringBuilder multipleOutputs = null;\n        while (stream.incrementToken()) {\n          if (null == multipleOutputs) {\n            multipleOutputs = new StringBuilder();\n            multipleOutputs.append('\"');\n            multipleOutputs.append(analyzed);\n            multipleOutputs.append('\"');\n          }\n          multipleOutputs.append(',');\n          multipleOutputs.append('\"');\n          multipleOutputs.append(termAtt.toString());\n          multipleOutputs.append('\"');\n        }\n        stream.end();\n        stream.close();\n        if (null != multipleOutputs) {\n          throw new ParseException(\n              String.format(getLocale(),\n                  \"Analyzer created multiple terms for \\\"%s\\\": %s\", chunk, multipleOutputs.toString()));\n        }\n      } else {\n        // nothing returned by analyzer.  Was it a stop word and the user accidentally\n        // used an analyzer with stop words?\n        stream.end();\n        stream.close();\n        throw new ParseException(String.format(getLocale(), \"Analyzer returned nothing for \\\"%s\\\"\", chunk));\n      }\n    } catch (IOException e){\n      throw new ParseException(\n          String.format(getLocale(), \"IO error while trying to analyze single term: \\\"%s\\\"\", termStr));\n    }\n    return analyzed;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["c83d6c4335f31cae14f625a222bc842f20073dcd","782ed6a4b4ba50ec19734fc8db4e570ee193d627"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"c83d6c4335f31cae14f625a222bc842f20073dcd","date":1373306148,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/queryparser/src/java/org/apache/lucene/queryparser/analyzing/AnalyzingQueryParser#analyzeSingleChunk(String,String,String).mjava","pathOld":"lucene/queryparser/src/java/org/apache/lucene/queryparser/analyzing/AnalyzingQueryParser#analyzeSingleChunk(String,String,String).mjava","sourceNew":"  /**\n   * Returns the analyzed form for the given chunk\n   * \n   * If the analyzer produces more than one output token from the given chunk,\n   * a ParseException is thrown.\n   *\n   * @param field The target field\n   * @param termStr The full term from which the given chunk is excerpted\n   * @param chunk The portion of the given termStr to be analyzed\n   * @return The result of analyzing the given chunk\n   * @throws ParseException when analysis returns other than one output token\n   */\n  protected String analyzeSingleChunk(String field, String termStr, String chunk) throws ParseException{\n    String analyzed = null;\n    TokenStream stream = null;\n    try{\n      stream = getAnalyzer().tokenStream(field, chunk);\n      stream.reset();\n      CharTermAttribute termAtt = stream.getAttribute(CharTermAttribute.class);\n      // get first and hopefully only output token\n      if (stream.incrementToken()) {\n        analyzed = termAtt.toString();\n        \n        // try to increment again, there should only be one output token\n        StringBuilder multipleOutputs = null;\n        while (stream.incrementToken()) {\n          if (null == multipleOutputs) {\n            multipleOutputs = new StringBuilder();\n            multipleOutputs.append('\"');\n            multipleOutputs.append(analyzed);\n            multipleOutputs.append('\"');\n          }\n          multipleOutputs.append(',');\n          multipleOutputs.append('\"');\n          multipleOutputs.append(termAtt.toString());\n          multipleOutputs.append('\"');\n        }\n        stream.end();\n        stream.close();\n        if (null != multipleOutputs) {\n          throw new ParseException(\n              String.format(getLocale(),\n                  \"Analyzer created multiple terms for \\\"%s\\\": %s\", chunk, multipleOutputs.toString()));\n        }\n      } else {\n        // nothing returned by analyzer.  Was it a stop word and the user accidentally\n        // used an analyzer with stop words?\n        stream.end();\n        stream.close();\n        throw new ParseException(String.format(getLocale(), \"Analyzer returned nothing for \\\"%s\\\"\", chunk));\n      }\n    } catch (IOException e){\n      throw new ParseException(\n          String.format(getLocale(), \"IO error while trying to analyze single term: \\\"%s\\\"\", termStr));\n    }\n    return analyzed;\n  }\n\n","sourceOld":"  /**\n   * Returns the analyzed form for the given chunk\n   * \n   * If the analyzer produces more than one output token from the given chunk,\n   * a ParseException is thrown.\n   *\n   * @param field The target field\n   * @param termStr The full term from which the given chunk is excerpted\n   * @param chunk The portion of the given termStr to be analyzed\n   * @return The result of analyzing the given chunk\n   * @throws ParseException when analysis returns other than one output token\n   */\n  protected String analyzeSingleChunk(String field, String termStr, String chunk) throws ParseException{\n    String analyzed = null;\n    TokenStream stream = null;\n    try{\n      stream = getAnalyzer().tokenStream(field, new StringReader(chunk));\n      stream.reset();\n      CharTermAttribute termAtt = stream.getAttribute(CharTermAttribute.class);\n      // get first and hopefully only output token\n      if (stream.incrementToken()) {\n        analyzed = termAtt.toString();\n        \n        // try to increment again, there should only be one output token\n        StringBuilder multipleOutputs = null;\n        while (stream.incrementToken()) {\n          if (null == multipleOutputs) {\n            multipleOutputs = new StringBuilder();\n            multipleOutputs.append('\"');\n            multipleOutputs.append(analyzed);\n            multipleOutputs.append('\"');\n          }\n          multipleOutputs.append(',');\n          multipleOutputs.append('\"');\n          multipleOutputs.append(termAtt.toString());\n          multipleOutputs.append('\"');\n        }\n        stream.end();\n        stream.close();\n        if (null != multipleOutputs) {\n          throw new ParseException(\n              String.format(getLocale(),\n                  \"Analyzer created multiple terms for \\\"%s\\\": %s\", chunk, multipleOutputs.toString()));\n        }\n      } else {\n        // nothing returned by analyzer.  Was it a stop word and the user accidentally\n        // used an analyzer with stop words?\n        stream.end();\n        stream.close();\n        throw new ParseException(String.format(getLocale(), \"Analyzer returned nothing for \\\"%s\\\"\", chunk));\n      }\n    } catch (IOException e){\n      throw new ParseException(\n          String.format(getLocale(), \"IO error while trying to analyze single term: \\\"%s\\\"\", termStr));\n    }\n    return analyzed;\n  }\n\n","bugFix":["046829b17e246624c179b94d5a20cb53fa945e87"],"bugIntro":["782ed6a4b4ba50ec19734fc8db4e570ee193d627"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"37a0f60745e53927c4c876cfe5b5a58170f0646c","date":1373994005,"type":3,"author":"Han Jiang","isMerge":true,"pathNew":"lucene/queryparser/src/java/org/apache/lucene/queryparser/analyzing/AnalyzingQueryParser#analyzeSingleChunk(String,String,String).mjava","pathOld":"lucene/queryparser/src/java/org/apache/lucene/queryparser/analyzing/AnalyzingQueryParser#analyzeSingleChunk(String,String,String).mjava","sourceNew":"  /**\n   * Returns the analyzed form for the given chunk\n   * \n   * If the analyzer produces more than one output token from the given chunk,\n   * a ParseException is thrown.\n   *\n   * @param field The target field\n   * @param termStr The full term from which the given chunk is excerpted\n   * @param chunk The portion of the given termStr to be analyzed\n   * @return The result of analyzing the given chunk\n   * @throws ParseException when analysis returns other than one output token\n   */\n  protected String analyzeSingleChunk(String field, String termStr, String chunk) throws ParseException{\n    String analyzed = null;\n    TokenStream stream = null;\n    try{\n      stream = getAnalyzer().tokenStream(field, chunk);\n      stream.reset();\n      CharTermAttribute termAtt = stream.getAttribute(CharTermAttribute.class);\n      // get first and hopefully only output token\n      if (stream.incrementToken()) {\n        analyzed = termAtt.toString();\n        \n        // try to increment again, there should only be one output token\n        StringBuilder multipleOutputs = null;\n        while (stream.incrementToken()) {\n          if (null == multipleOutputs) {\n            multipleOutputs = new StringBuilder();\n            multipleOutputs.append('\"');\n            multipleOutputs.append(analyzed);\n            multipleOutputs.append('\"');\n          }\n          multipleOutputs.append(',');\n          multipleOutputs.append('\"');\n          multipleOutputs.append(termAtt.toString());\n          multipleOutputs.append('\"');\n        }\n        stream.end();\n        stream.close();\n        if (null != multipleOutputs) {\n          throw new ParseException(\n              String.format(getLocale(),\n                  \"Analyzer created multiple terms for \\\"%s\\\": %s\", chunk, multipleOutputs.toString()));\n        }\n      } else {\n        // nothing returned by analyzer.  Was it a stop word and the user accidentally\n        // used an analyzer with stop words?\n        stream.end();\n        stream.close();\n        throw new ParseException(String.format(getLocale(), \"Analyzer returned nothing for \\\"%s\\\"\", chunk));\n      }\n    } catch (IOException e){\n      throw new ParseException(\n          String.format(getLocale(), \"IO error while trying to analyze single term: \\\"%s\\\"\", termStr));\n    }\n    return analyzed;\n  }\n\n","sourceOld":"  /**\n   * Returns the analyzed form for the given chunk\n   * \n   * If the analyzer produces more than one output token from the given chunk,\n   * a ParseException is thrown.\n   *\n   * @param field The target field\n   * @param termStr The full term from which the given chunk is excerpted\n   * @param chunk The portion of the given termStr to be analyzed\n   * @return The result of analyzing the given chunk\n   * @throws ParseException when analysis returns other than one output token\n   */\n  protected String analyzeSingleChunk(String field, String termStr, String chunk) throws ParseException{\n    String analyzed = null;\n    TokenStream stream = null;\n    try{\n      stream = getAnalyzer().tokenStream(field, new StringReader(chunk));\n      stream.reset();\n      CharTermAttribute termAtt = stream.getAttribute(CharTermAttribute.class);\n      // get first and hopefully only output token\n      if (stream.incrementToken()) {\n        analyzed = termAtt.toString();\n        \n        // try to increment again, there should only be one output token\n        StringBuilder multipleOutputs = null;\n        while (stream.incrementToken()) {\n          if (null == multipleOutputs) {\n            multipleOutputs = new StringBuilder();\n            multipleOutputs.append('\"');\n            multipleOutputs.append(analyzed);\n            multipleOutputs.append('\"');\n          }\n          multipleOutputs.append(',');\n          multipleOutputs.append('\"');\n          multipleOutputs.append(termAtt.toString());\n          multipleOutputs.append('\"');\n        }\n        stream.end();\n        stream.close();\n        if (null != multipleOutputs) {\n          throw new ParseException(\n              String.format(getLocale(),\n                  \"Analyzer created multiple terms for \\\"%s\\\": %s\", chunk, multipleOutputs.toString()));\n        }\n      } else {\n        // nothing returned by analyzer.  Was it a stop word and the user accidentally\n        // used an analyzer with stop words?\n        stream.end();\n        stream.close();\n        throw new ParseException(String.format(getLocale(), \"Analyzer returned nothing for \\\"%s\\\"\", chunk));\n      }\n    } catch (IOException e){\n      throw new ParseException(\n          String.format(getLocale(), \"IO error while trying to analyze single term: \\\"%s\\\"\", termStr));\n    }\n    return analyzed;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"782ed6a4b4ba50ec19734fc8db4e570ee193d627","date":1381127065,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/queryparser/src/java/org/apache/lucene/queryparser/analyzing/AnalyzingQueryParser#analyzeSingleChunk(String,String,String).mjava","pathOld":"lucene/queryparser/src/java/org/apache/lucene/queryparser/analyzing/AnalyzingQueryParser#analyzeSingleChunk(String,String,String).mjava","sourceNew":"  /**\n   * Returns the analyzed form for the given chunk\n   * \n   * If the analyzer produces more than one output token from the given chunk,\n   * a ParseException is thrown.\n   *\n   * @param field The target field\n   * @param termStr The full term from which the given chunk is excerpted\n   * @param chunk The portion of the given termStr to be analyzed\n   * @return The result of analyzing the given chunk\n   * @throws ParseException when analysis returns other than one output token\n   */\n  protected String analyzeSingleChunk(String field, String termStr, String chunk) throws ParseException{\n    String analyzed = null;\n    try (TokenStream stream = getAnalyzer().tokenStream(field, chunk)) {\n      stream.reset();\n      CharTermAttribute termAtt = stream.getAttribute(CharTermAttribute.class);\n      // get first and hopefully only output token\n      if (stream.incrementToken()) {\n        analyzed = termAtt.toString();\n        \n        // try to increment again, there should only be one output token\n        StringBuilder multipleOutputs = null;\n        while (stream.incrementToken()) {\n          if (null == multipleOutputs) {\n            multipleOutputs = new StringBuilder();\n            multipleOutputs.append('\"');\n            multipleOutputs.append(analyzed);\n            multipleOutputs.append('\"');\n          }\n          multipleOutputs.append(',');\n          multipleOutputs.append('\"');\n          multipleOutputs.append(termAtt.toString());\n          multipleOutputs.append('\"');\n        }\n        stream.end();\n        if (null != multipleOutputs) {\n          throw new ParseException(\n              String.format(getLocale(),\n                  \"Analyzer created multiple terms for \\\"%s\\\": %s\", chunk, multipleOutputs.toString()));\n        }\n      } else {\n        // nothing returned by analyzer.  Was it a stop word and the user accidentally\n        // used an analyzer with stop words?\n        stream.end();\n        throw new ParseException(String.format(getLocale(), \"Analyzer returned nothing for \\\"%s\\\"\", chunk));\n      }\n    } catch (IOException e){\n      throw new ParseException(\n          String.format(getLocale(), \"IO error while trying to analyze single term: \\\"%s\\\"\", termStr));\n    }\n    return analyzed;\n  }\n\n","sourceOld":"  /**\n   * Returns the analyzed form for the given chunk\n   * \n   * If the analyzer produces more than one output token from the given chunk,\n   * a ParseException is thrown.\n   *\n   * @param field The target field\n   * @param termStr The full term from which the given chunk is excerpted\n   * @param chunk The portion of the given termStr to be analyzed\n   * @return The result of analyzing the given chunk\n   * @throws ParseException when analysis returns other than one output token\n   */\n  protected String analyzeSingleChunk(String field, String termStr, String chunk) throws ParseException{\n    String analyzed = null;\n    TokenStream stream = null;\n    try{\n      stream = getAnalyzer().tokenStream(field, chunk);\n      stream.reset();\n      CharTermAttribute termAtt = stream.getAttribute(CharTermAttribute.class);\n      // get first and hopefully only output token\n      if (stream.incrementToken()) {\n        analyzed = termAtt.toString();\n        \n        // try to increment again, there should only be one output token\n        StringBuilder multipleOutputs = null;\n        while (stream.incrementToken()) {\n          if (null == multipleOutputs) {\n            multipleOutputs = new StringBuilder();\n            multipleOutputs.append('\"');\n            multipleOutputs.append(analyzed);\n            multipleOutputs.append('\"');\n          }\n          multipleOutputs.append(',');\n          multipleOutputs.append('\"');\n          multipleOutputs.append(termAtt.toString());\n          multipleOutputs.append('\"');\n        }\n        stream.end();\n        stream.close();\n        if (null != multipleOutputs) {\n          throw new ParseException(\n              String.format(getLocale(),\n                  \"Analyzer created multiple terms for \\\"%s\\\": %s\", chunk, multipleOutputs.toString()));\n        }\n      } else {\n        // nothing returned by analyzer.  Was it a stop word and the user accidentally\n        // used an analyzer with stop words?\n        stream.end();\n        stream.close();\n        throw new ParseException(String.format(getLocale(), \"Analyzer returned nothing for \\\"%s\\\"\", chunk));\n      }\n    } catch (IOException e){\n      throw new ParseException(\n          String.format(getLocale(), \"IO error while trying to analyze single term: \\\"%s\\\"\", termStr));\n    }\n    return analyzed;\n  }\n\n","bugFix":["046829b17e246624c179b94d5a20cb53fa945e87","c83d6c4335f31cae14f625a222bc842f20073dcd"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ea4107f60b9f95623c16025c9c247412ff809092","date":1468333987,"type":4,"author":"Adrien Grand","isMerge":false,"pathNew":"/dev/null","pathOld":"lucene/queryparser/src/java/org/apache/lucene/queryparser/analyzing/AnalyzingQueryParser#analyzeSingleChunk(String,String,String).mjava","sourceNew":null,"sourceOld":"  /**\n   * Returns the analyzed form for the given chunk\n   * \n   * If the analyzer produces more than one output token from the given chunk,\n   * a ParseException is thrown.\n   *\n   * @param field The target field\n   * @param termStr The full term from which the given chunk is excerpted\n   * @param chunk The portion of the given termStr to be analyzed\n   * @return The result of analyzing the given chunk\n   * @throws ParseException when analysis returns other than one output token\n   */\n  protected String analyzeSingleChunk(String field, String termStr, String chunk) throws ParseException{\n    String analyzed = null;\n    try (TokenStream stream = getAnalyzer().tokenStream(field, chunk)) {\n      stream.reset();\n      CharTermAttribute termAtt = stream.getAttribute(CharTermAttribute.class);\n      // get first and hopefully only output token\n      if (stream.incrementToken()) {\n        analyzed = termAtt.toString();\n        \n        // try to increment again, there should only be one output token\n        StringBuilder multipleOutputs = null;\n        while (stream.incrementToken()) {\n          if (null == multipleOutputs) {\n            multipleOutputs = new StringBuilder();\n            multipleOutputs.append('\"');\n            multipleOutputs.append(analyzed);\n            multipleOutputs.append('\"');\n          }\n          multipleOutputs.append(',');\n          multipleOutputs.append('\"');\n          multipleOutputs.append(termAtt.toString());\n          multipleOutputs.append('\"');\n        }\n        stream.end();\n        if (null != multipleOutputs) {\n          throw new ParseException(\n              String.format(getLocale(),\n                  \"Analyzer created multiple terms for \\\"%s\\\": %s\", chunk, multipleOutputs.toString()));\n        }\n      } else {\n        // nothing returned by analyzer.  Was it a stop word and the user accidentally\n        // used an analyzer with stop words?\n        stream.end();\n        throw new ParseException(String.format(getLocale(), \"Analyzer returned nothing for \\\"%s\\\"\", chunk));\n      }\n    } catch (IOException e){\n      throw new ParseException(\n          String.format(getLocale(), \"IO error while trying to analyze single term: \\\"%s\\\"\", termStr));\n    }\n    return analyzed;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4cce5816ef15a48a0bc11e5d400497ee4301dd3b","date":1476991456,"type":4,"author":"Kevin Risden","isMerge":true,"pathNew":"/dev/null","pathOld":"lucene/queryparser/src/java/org/apache/lucene/queryparser/analyzing/AnalyzingQueryParser#analyzeSingleChunk(String,String,String).mjava","sourceNew":null,"sourceOld":"  /**\n   * Returns the analyzed form for the given chunk\n   * \n   * If the analyzer produces more than one output token from the given chunk,\n   * a ParseException is thrown.\n   *\n   * @param field The target field\n   * @param termStr The full term from which the given chunk is excerpted\n   * @param chunk The portion of the given termStr to be analyzed\n   * @return The result of analyzing the given chunk\n   * @throws ParseException when analysis returns other than one output token\n   */\n  protected String analyzeSingleChunk(String field, String termStr, String chunk) throws ParseException{\n    String analyzed = null;\n    try (TokenStream stream = getAnalyzer().tokenStream(field, chunk)) {\n      stream.reset();\n      CharTermAttribute termAtt = stream.getAttribute(CharTermAttribute.class);\n      // get first and hopefully only output token\n      if (stream.incrementToken()) {\n        analyzed = termAtt.toString();\n        \n        // try to increment again, there should only be one output token\n        StringBuilder multipleOutputs = null;\n        while (stream.incrementToken()) {\n          if (null == multipleOutputs) {\n            multipleOutputs = new StringBuilder();\n            multipleOutputs.append('\"');\n            multipleOutputs.append(analyzed);\n            multipleOutputs.append('\"');\n          }\n          multipleOutputs.append(',');\n          multipleOutputs.append('\"');\n          multipleOutputs.append(termAtt.toString());\n          multipleOutputs.append('\"');\n        }\n        stream.end();\n        if (null != multipleOutputs) {\n          throw new ParseException(\n              String.format(getLocale(),\n                  \"Analyzer created multiple terms for \\\"%s\\\": %s\", chunk, multipleOutputs.toString()));\n        }\n      } else {\n        // nothing returned by analyzer.  Was it a stop word and the user accidentally\n        // used an analyzer with stop words?\n        stream.end();\n        throw new ParseException(String.format(getLocale(), \"Analyzer returned nothing for \\\"%s\\\"\", chunk));\n      }\n    } catch (IOException e){\n      throw new ParseException(\n          String.format(getLocale(), \"IO error while trying to analyze single term: \\\"%s\\\"\", termStr));\n    }\n    return analyzed;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"37a0f60745e53927c4c876cfe5b5a58170f0646c":["046829b17e246624c179b94d5a20cb53fa945e87","c83d6c4335f31cae14f625a222bc842f20073dcd"],"c83d6c4335f31cae14f625a222bc842f20073dcd":["046829b17e246624c179b94d5a20cb53fa945e87"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"782ed6a4b4ba50ec19734fc8db4e570ee193d627":["c83d6c4335f31cae14f625a222bc842f20073dcd"],"ea4107f60b9f95623c16025c9c247412ff809092":["782ed6a4b4ba50ec19734fc8db4e570ee193d627"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["782ed6a4b4ba50ec19734fc8db4e570ee193d627","ea4107f60b9f95623c16025c9c247412ff809092"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["ea4107f60b9f95623c16025c9c247412ff809092"],"046829b17e246624c179b94d5a20cb53fa945e87":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"37a0f60745e53927c4c876cfe5b5a58170f0646c":[],"c83d6c4335f31cae14f625a222bc842f20073dcd":["37a0f60745e53927c4c876cfe5b5a58170f0646c","782ed6a4b4ba50ec19734fc8db4e570ee193d627"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["046829b17e246624c179b94d5a20cb53fa945e87"],"782ed6a4b4ba50ec19734fc8db4e570ee193d627":["ea4107f60b9f95623c16025c9c247412ff809092","4cce5816ef15a48a0bc11e5d400497ee4301dd3b"],"ea4107f60b9f95623c16025c9c247412ff809092":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":[],"046829b17e246624c179b94d5a20cb53fa945e87":["37a0f60745e53927c4c876cfe5b5a58170f0646c","c83d6c4335f31cae14f625a222bc842f20073dcd"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["37a0f60745e53927c4c876cfe5b5a58170f0646c","4cce5816ef15a48a0bc11e5d400497ee4301dd3b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}