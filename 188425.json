{"path":"lucene/core/src/java/org/apache/lucene/index/MultiDocValues#getDocValues(IndexReader,String,DocValuesPuller).mjava","commits":[{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":1,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/MultiDocValues#getDocValues(IndexReader,String,DocValuesPuller).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/MultiDocValues#getDocValues(IndexReader,String,DocValuesPuller).mjava","sourceNew":"  private static DocValues getDocValues(IndexReader r, final String field, final DocValuesPuller puller) throws IOException {\n    if (r instanceof AtomicReader) {\n      // already an atomic reader\n      return puller.pull((AtomicReader) r, field);\n    }\n    assert r instanceof CompositeReader;\n    final IndexReader[] subs = ((CompositeReader) r).getSequentialSubReaders();\n    if (subs.length == 0) {\n      // no fields\n      return null;\n    } else if (subs.length == 1) {\n      return getDocValues(subs[0], field, puller);\n    } else {      \n      final List<DocValuesSlice> slices = new ArrayList<DocValuesSlice>();\n      \n      final TypePromoter promotedType[] = new TypePromoter[1];\n      promotedType[0] = TypePromoter.getIdentityPromoter();\n      \n      // gather all docvalues fields, accumulating a promoted type across \n      // potentially incompatible types\n      \n      new ReaderUtil.Gather(r) {\n        boolean stop = false;\n        @Override\n        protected void add(int base, AtomicReader r) throws IOException {\n          if (stop) {\n            return;\n          }\n          final DocValues d = puller.pull(r, field);\n          if (d != null) {\n            TypePromoter incoming = TypePromoter.create(d.type(), d.getValueSize());\n            promotedType[0] = promotedType[0].promote(incoming);\n          } else if (puller.stopLoadingOnNull(r, field)){\n            promotedType[0] = TypePromoter.getIdentityPromoter(); // set to identity to return null\n            stop = true;\n          }\n          slices.add(new DocValuesSlice(d, base, r.maxDoc()));\n        }\n      }.run();\n      \n      // return null if no docvalues encountered anywhere\n      if (promotedType[0] == TypePromoter.getIdentityPromoter()) {\n        return null;\n      }\n           \n      // populate starts and fill gaps with empty docvalues \n      int starts[] = new int[slices.size()];\n      for (int i = 0; i < slices.size(); i++) {\n        DocValuesSlice slice = slices.get(i);\n        starts[i] = slice.start;\n        if (slice.docValues == null) {\n          Type promoted = promotedType[0].type();\n          switch(promoted) {\n            case BYTES_FIXED_DEREF:\n            case BYTES_FIXED_STRAIGHT:\n            case BYTES_FIXED_SORTED:\n              assert promotedType[0].getValueSize() >= 0;\n              slice.docValues = new EmptyFixedDocValues(slice.length, promoted, promotedType[0].getValueSize());\n              break;\n            default:\n              slice.docValues = new EmptyDocValues(slice.length, promoted);\n          }\n        }\n      }\n      \n      return new MultiDocValues(slices.toArray(new DocValuesSlice[slices.size()]), starts, promotedType[0]);\n    }\n  }\n\n","sourceOld":"  private static DocValues getDocValues(IndexReader r, final String field, final DocValuesPuller puller) throws IOException {\n    if (r instanceof AtomicReader) {\n      // already an atomic reader\n      return puller.pull((AtomicReader) r, field);\n    }\n    assert r instanceof CompositeReader;\n    final IndexReader[] subs = ((CompositeReader) r).getSequentialSubReaders();\n    if (subs.length == 0) {\n      // no fields\n      return null;\n    } else if (subs.length == 1) {\n      return getDocValues(subs[0], field, puller);\n    } else {      \n      final List<DocValuesSlice> slices = new ArrayList<DocValuesSlice>();\n      \n      final TypePromoter promotedType[] = new TypePromoter[1];\n      promotedType[0] = TypePromoter.getIdentityPromoter();\n      \n      // gather all docvalues fields, accumulating a promoted type across \n      // potentially incompatible types\n      \n      new ReaderUtil.Gather(r) {\n        boolean stop = false;\n        @Override\n        protected void add(int base, AtomicReader r) throws IOException {\n          if (stop) {\n            return;\n          }\n          final DocValues d = puller.pull(r, field);\n          if (d != null) {\n            TypePromoter incoming = TypePromoter.create(d.type(), d.getValueSize());\n            promotedType[0] = promotedType[0].promote(incoming);\n          } else if (puller.stopLoadingOnNull(r, field)){\n            promotedType[0] = TypePromoter.getIdentityPromoter(); // set to identity to return null\n            stop = true;\n          }\n          slices.add(new DocValuesSlice(d, base, r.maxDoc()));\n        }\n      }.run();\n      \n      // return null if no docvalues encountered anywhere\n      if (promotedType[0] == TypePromoter.getIdentityPromoter()) {\n        return null;\n      }\n           \n      // populate starts and fill gaps with empty docvalues \n      int starts[] = new int[slices.size()];\n      for (int i = 0; i < slices.size(); i++) {\n        DocValuesSlice slice = slices.get(i);\n        starts[i] = slice.start;\n        if (slice.docValues == null) {\n          Type promoted = promotedType[0].type();\n          switch(promoted) {\n            case BYTES_FIXED_DEREF:\n            case BYTES_FIXED_STRAIGHT:\n            case BYTES_FIXED_SORTED:\n              assert promotedType[0].getValueSize() >= 0;\n              slice.docValues = new EmptyFixedDocValues(slice.length, promoted, promotedType[0].getValueSize());\n              break;\n            default:\n              slice.docValues = new EmptyDocValues(slice.length, promoted);\n          }\n        }\n      }\n      \n      return new MultiDocValues(slices.toArray(new DocValuesSlice[slices.size()]), starts, promotedType[0]);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"cd0f953fbccd59aa346f280fe7e30a698f5ecb04","date":1331511349,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/MultiDocValues#getDocValues(IndexReader,String,DocValuesPuller).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/MultiDocValues#getDocValues(IndexReader,String,DocValuesPuller).mjava","sourceNew":"  private static DocValues getDocValues(IndexReader r, final String field, final DocValuesPuller puller) throws IOException {\n    if (r instanceof AtomicReader) {\n      // already an atomic reader\n      return puller.pull((AtomicReader) r, field);\n    }\n    assert r instanceof CompositeReader;\n    final IndexReader[] subs = ((CompositeReader) r).getSequentialSubReaders();\n    if (subs.length == 0) {\n      // no fields\n      return null;\n    } else if (subs.length == 1) {\n      return getDocValues(subs[0], field, puller);\n    } else {      \n      final List<DocValuesSlice> slices = new ArrayList<DocValuesSlice>();\n      \n      final TypePromoter promotedType[] = new TypePromoter[1];\n      promotedType[0] = TypePromoter.getIdentityPromoter();\n      \n      // gather all docvalues fields, accumulating a promoted type across \n      // potentially incompatible types\n      \n      new ReaderUtil.Gather(r) {\n        boolean stop = false;\n        @Override\n        protected void add(int base, AtomicReader r) throws IOException {\n          if (stop) {\n            return;\n          }\n          final DocValues d = puller.pull(r, field);\n          if (d != null) {\n            TypePromoter incoming = TypePromoter.create(d.getType(), d.getValueSize());\n            promotedType[0] = promotedType[0].promote(incoming);\n          } else if (puller.stopLoadingOnNull(r, field)){\n            promotedType[0] = TypePromoter.getIdentityPromoter(); // set to identity to return null\n            stop = true;\n          }\n          slices.add(new DocValuesSlice(d, base, r.maxDoc()));\n        }\n      }.run();\n      \n      // return null if no docvalues encountered anywhere\n      if (promotedType[0] == TypePromoter.getIdentityPromoter()) {\n        return null;\n      }\n           \n      // populate starts and fill gaps with empty docvalues \n      int starts[] = new int[slices.size()];\n      for (int i = 0; i < slices.size(); i++) {\n        DocValuesSlice slice = slices.get(i);\n        starts[i] = slice.start;\n        if (slice.docValues == null) {\n          Type promoted = promotedType[0].type();\n          switch(promoted) {\n            case BYTES_FIXED_DEREF:\n            case BYTES_FIXED_STRAIGHT:\n            case BYTES_FIXED_SORTED:\n              assert promotedType[0].getValueSize() >= 0;\n              slice.docValues = new EmptyFixedDocValues(slice.length, promoted, promotedType[0].getValueSize());\n              break;\n            default:\n              slice.docValues = new EmptyDocValues(slice.length, promoted);\n          }\n        }\n      }\n      \n      return new MultiDocValues(slices.toArray(new DocValuesSlice[slices.size()]), starts, promotedType[0]);\n    }\n  }\n\n","sourceOld":"  private static DocValues getDocValues(IndexReader r, final String field, final DocValuesPuller puller) throws IOException {\n    if (r instanceof AtomicReader) {\n      // already an atomic reader\n      return puller.pull((AtomicReader) r, field);\n    }\n    assert r instanceof CompositeReader;\n    final IndexReader[] subs = ((CompositeReader) r).getSequentialSubReaders();\n    if (subs.length == 0) {\n      // no fields\n      return null;\n    } else if (subs.length == 1) {\n      return getDocValues(subs[0], field, puller);\n    } else {      \n      final List<DocValuesSlice> slices = new ArrayList<DocValuesSlice>();\n      \n      final TypePromoter promotedType[] = new TypePromoter[1];\n      promotedType[0] = TypePromoter.getIdentityPromoter();\n      \n      // gather all docvalues fields, accumulating a promoted type across \n      // potentially incompatible types\n      \n      new ReaderUtil.Gather(r) {\n        boolean stop = false;\n        @Override\n        protected void add(int base, AtomicReader r) throws IOException {\n          if (stop) {\n            return;\n          }\n          final DocValues d = puller.pull(r, field);\n          if (d != null) {\n            TypePromoter incoming = TypePromoter.create(d.type(), d.getValueSize());\n            promotedType[0] = promotedType[0].promote(incoming);\n          } else if (puller.stopLoadingOnNull(r, field)){\n            promotedType[0] = TypePromoter.getIdentityPromoter(); // set to identity to return null\n            stop = true;\n          }\n          slices.add(new DocValuesSlice(d, base, r.maxDoc()));\n        }\n      }.run();\n      \n      // return null if no docvalues encountered anywhere\n      if (promotedType[0] == TypePromoter.getIdentityPromoter()) {\n        return null;\n      }\n           \n      // populate starts and fill gaps with empty docvalues \n      int starts[] = new int[slices.size()];\n      for (int i = 0; i < slices.size(); i++) {\n        DocValuesSlice slice = slices.get(i);\n        starts[i] = slice.start;\n        if (slice.docValues == null) {\n          Type promoted = promotedType[0].type();\n          switch(promoted) {\n            case BYTES_FIXED_DEREF:\n            case BYTES_FIXED_STRAIGHT:\n            case BYTES_FIXED_SORTED:\n              assert promotedType[0].getValueSize() >= 0;\n              slice.docValues = new EmptyFixedDocValues(slice.length, promoted, promotedType[0].getValueSize());\n              break;\n            default:\n              slice.docValues = new EmptyDocValues(slice.length, promoted);\n          }\n        }\n      }\n      \n      return new MultiDocValues(slices.toArray(new DocValuesSlice[slices.size()]), starts, promotedType[0]);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"38e3b736c7ca086d61b7dbb841c905ee115490da","date":1331657018,"type":3,"author":"Ryan McKinley","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/MultiDocValues#getDocValues(IndexReader,String,DocValuesPuller).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/MultiDocValues#getDocValues(IndexReader,String,DocValuesPuller).mjava","sourceNew":"  private static DocValues getDocValues(IndexReader r, final String field, final DocValuesPuller puller) throws IOException {\n    if (r instanceof AtomicReader) {\n      // already an atomic reader\n      return puller.pull((AtomicReader) r, field);\n    }\n    assert r instanceof CompositeReader;\n    final IndexReader[] subs = ((CompositeReader) r).getSequentialSubReaders();\n    if (subs.length == 0) {\n      // no fields\n      return null;\n    } else if (subs.length == 1) {\n      return getDocValues(subs[0], field, puller);\n    } else {      \n      final List<DocValuesSlice> slices = new ArrayList<DocValuesSlice>();\n      \n      final TypePromoter promotedType[] = new TypePromoter[1];\n      promotedType[0] = TypePromoter.getIdentityPromoter();\n      \n      // gather all docvalues fields, accumulating a promoted type across \n      // potentially incompatible types\n      \n      new ReaderUtil.Gather(r) {\n        boolean stop = false;\n        @Override\n        protected void add(int base, AtomicReader r) throws IOException {\n          if (stop) {\n            return;\n          }\n          final DocValues d = puller.pull(r, field);\n          if (d != null) {\n            TypePromoter incoming = TypePromoter.create(d.getType(), d.getValueSize());\n            promotedType[0] = promotedType[0].promote(incoming);\n          } else if (puller.stopLoadingOnNull(r, field)){\n            promotedType[0] = TypePromoter.getIdentityPromoter(); // set to identity to return null\n            stop = true;\n          }\n          slices.add(new DocValuesSlice(d, base, r.maxDoc()));\n        }\n      }.run();\n      \n      // return null if no docvalues encountered anywhere\n      if (promotedType[0] == TypePromoter.getIdentityPromoter()) {\n        return null;\n      }\n           \n      // populate starts and fill gaps with empty docvalues \n      int starts[] = new int[slices.size()];\n      for (int i = 0; i < slices.size(); i++) {\n        DocValuesSlice slice = slices.get(i);\n        starts[i] = slice.start;\n        if (slice.docValues == null) {\n          Type promoted = promotedType[0].type();\n          switch(promoted) {\n            case BYTES_FIXED_DEREF:\n            case BYTES_FIXED_STRAIGHT:\n            case BYTES_FIXED_SORTED:\n              assert promotedType[0].getValueSize() >= 0;\n              slice.docValues = new EmptyFixedDocValues(slice.length, promoted, promotedType[0].getValueSize());\n              break;\n            default:\n              slice.docValues = new EmptyDocValues(slice.length, promoted);\n          }\n        }\n      }\n      \n      return new MultiDocValues(slices.toArray(new DocValuesSlice[slices.size()]), starts, promotedType[0]);\n    }\n  }\n\n","sourceOld":"  private static DocValues getDocValues(IndexReader r, final String field, final DocValuesPuller puller) throws IOException {\n    if (r instanceof AtomicReader) {\n      // already an atomic reader\n      return puller.pull((AtomicReader) r, field);\n    }\n    assert r instanceof CompositeReader;\n    final IndexReader[] subs = ((CompositeReader) r).getSequentialSubReaders();\n    if (subs.length == 0) {\n      // no fields\n      return null;\n    } else if (subs.length == 1) {\n      return getDocValues(subs[0], field, puller);\n    } else {      \n      final List<DocValuesSlice> slices = new ArrayList<DocValuesSlice>();\n      \n      final TypePromoter promotedType[] = new TypePromoter[1];\n      promotedType[0] = TypePromoter.getIdentityPromoter();\n      \n      // gather all docvalues fields, accumulating a promoted type across \n      // potentially incompatible types\n      \n      new ReaderUtil.Gather(r) {\n        boolean stop = false;\n        @Override\n        protected void add(int base, AtomicReader r) throws IOException {\n          if (stop) {\n            return;\n          }\n          final DocValues d = puller.pull(r, field);\n          if (d != null) {\n            TypePromoter incoming = TypePromoter.create(d.type(), d.getValueSize());\n            promotedType[0] = promotedType[0].promote(incoming);\n          } else if (puller.stopLoadingOnNull(r, field)){\n            promotedType[0] = TypePromoter.getIdentityPromoter(); // set to identity to return null\n            stop = true;\n          }\n          slices.add(new DocValuesSlice(d, base, r.maxDoc()));\n        }\n      }.run();\n      \n      // return null if no docvalues encountered anywhere\n      if (promotedType[0] == TypePromoter.getIdentityPromoter()) {\n        return null;\n      }\n           \n      // populate starts and fill gaps with empty docvalues \n      int starts[] = new int[slices.size()];\n      for (int i = 0; i < slices.size(); i++) {\n        DocValuesSlice slice = slices.get(i);\n        starts[i] = slice.start;\n        if (slice.docValues == null) {\n          Type promoted = promotedType[0].type();\n          switch(promoted) {\n            case BYTES_FIXED_DEREF:\n            case BYTES_FIXED_STRAIGHT:\n            case BYTES_FIXED_SORTED:\n              assert promotedType[0].getValueSize() >= 0;\n              slice.docValues = new EmptyFixedDocValues(slice.length, promoted, promotedType[0].getValueSize());\n              break;\n            default:\n              slice.docValues = new EmptyDocValues(slice.length, promoted);\n          }\n        }\n      }\n      \n      return new MultiDocValues(slices.toArray(new DocValuesSlice[slices.size()]), starts, promotedType[0]);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4c5ae929ce8aa0c4856f0d6bfd4c196bc2d3eb9c","date":1340090669,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/MultiDocValues#getDocValues(IndexReader,String,DocValuesPuller).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/MultiDocValues#getDocValues(IndexReader,String,DocValuesPuller).mjava","sourceNew":"  private static DocValues getDocValues(IndexReader reader, final String field, final DocValuesPuller puller) throws IOException {\n    if (reader instanceof AtomicReader) {\n      // already an atomic reader\n      return puller.pull((AtomicReader) reader, field);\n    }\n    assert reader instanceof CompositeReader;\n    final List<AtomicReaderContext> leaves = reader.getTopReaderContext().leaves();\n    switch (leaves.size()) {\n      case 0:\n        // no fields\n        return null;\n      case 1:\n        // already an atomic reader / reader with one leave\n        return getDocValues(leaves.get(0).reader(), field, puller);\n      default:\n        final List<DocValuesSlice> slices = new ArrayList<DocValuesSlice>();\n        \n        TypePromoter promotedType =  TypePromoter.getIdentityPromoter();\n        \n        // gather all docvalues fields, accumulating a promoted type across \n        // potentially incompatible types\n        for (final AtomicReaderContext ctx : leaves) {\n          final AtomicReader r = ctx.reader();\n          final DocValues d = puller.pull(r, field);\n          if (d != null) {\n            TypePromoter incoming = TypePromoter.create(d.getType(), d.getValueSize());\n            promotedType = promotedType.promote(incoming);\n          } else if (puller.stopLoadingOnNull(r, field)){\n            return null;\n          }\n          slices.add(new DocValuesSlice(d, ctx.docBase, r.maxDoc()));\n        }\n        \n        // return null if no docvalues encountered anywhere\n        if (promotedType == TypePromoter.getIdentityPromoter()) {\n          return null;\n        }\n             \n        // populate starts and fill gaps with empty docvalues \n        int starts[] = new int[slices.size()];\n        for (int i = 0; i < slices.size(); i++) {\n          DocValuesSlice slice = slices.get(i);\n          starts[i] = slice.start;\n          if (slice.docValues == null) {\n            Type promoted = promotedType.type();\n            switch(promoted) {\n              case BYTES_FIXED_DEREF:\n              case BYTES_FIXED_STRAIGHT:\n              case BYTES_FIXED_SORTED:\n                assert promotedType.getValueSize() >= 0;\n                slice.docValues = new EmptyFixedDocValues(slice.length, promoted, promotedType.getValueSize());\n                break;\n              default:\n                slice.docValues = new EmptyDocValues(slice.length, promoted);\n            }\n          }\n        }\n        \n        return new MultiDocValues(slices.toArray(new DocValuesSlice[slices.size()]), starts, promotedType);\n    }\n  }\n\n","sourceOld":"  private static DocValues getDocValues(IndexReader r, final String field, final DocValuesPuller puller) throws IOException {\n    if (r instanceof AtomicReader) {\n      // already an atomic reader\n      return puller.pull((AtomicReader) r, field);\n    }\n    assert r instanceof CompositeReader;\n    final IndexReader[] subs = ((CompositeReader) r).getSequentialSubReaders();\n    if (subs.length == 0) {\n      // no fields\n      return null;\n    } else if (subs.length == 1) {\n      return getDocValues(subs[0], field, puller);\n    } else {      \n      final List<DocValuesSlice> slices = new ArrayList<DocValuesSlice>();\n      \n      final TypePromoter promotedType[] = new TypePromoter[1];\n      promotedType[0] = TypePromoter.getIdentityPromoter();\n      \n      // gather all docvalues fields, accumulating a promoted type across \n      // potentially incompatible types\n      \n      new ReaderUtil.Gather(r) {\n        boolean stop = false;\n        @Override\n        protected void add(int base, AtomicReader r) throws IOException {\n          if (stop) {\n            return;\n          }\n          final DocValues d = puller.pull(r, field);\n          if (d != null) {\n            TypePromoter incoming = TypePromoter.create(d.getType(), d.getValueSize());\n            promotedType[0] = promotedType[0].promote(incoming);\n          } else if (puller.stopLoadingOnNull(r, field)){\n            promotedType[0] = TypePromoter.getIdentityPromoter(); // set to identity to return null\n            stop = true;\n          }\n          slices.add(new DocValuesSlice(d, base, r.maxDoc()));\n        }\n      }.run();\n      \n      // return null if no docvalues encountered anywhere\n      if (promotedType[0] == TypePromoter.getIdentityPromoter()) {\n        return null;\n      }\n           \n      // populate starts and fill gaps with empty docvalues \n      int starts[] = new int[slices.size()];\n      for (int i = 0; i < slices.size(); i++) {\n        DocValuesSlice slice = slices.get(i);\n        starts[i] = slice.start;\n        if (slice.docValues == null) {\n          Type promoted = promotedType[0].type();\n          switch(promoted) {\n            case BYTES_FIXED_DEREF:\n            case BYTES_FIXED_STRAIGHT:\n            case BYTES_FIXED_SORTED:\n              assert promotedType[0].getValueSize() >= 0;\n              slice.docValues = new EmptyFixedDocValues(slice.length, promoted, promotedType[0].getValueSize());\n              break;\n            default:\n              slice.docValues = new EmptyDocValues(slice.length, promoted);\n          }\n        }\n      }\n      \n      return new MultiDocValues(slices.toArray(new DocValuesSlice[slices.size()]), starts, promotedType[0]);\n    }\n  }\n\n","bugFix":null,"bugIntro":["d743dbdc40bef0a47a5d54d99623ef0c2eb5923e"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d743dbdc40bef0a47a5d54d99623ef0c2eb5923e","date":1344896544,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/MultiDocValues#getDocValues(IndexReader,String,DocValuesPuller).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/MultiDocValues#getDocValues(IndexReader,String,DocValuesPuller).mjava","sourceNew":"  private static DocValues getDocValues(IndexReader reader, final String field, final DocValuesPuller puller) throws IOException {\n    if (reader instanceof AtomicReader) {\n      // already an atomic reader\n      return puller.pull((AtomicReader) reader, field);\n    }\n    assert reader instanceof CompositeReader;\n    final List<AtomicReaderContext> leaves = reader.leaves();\n    switch (leaves.size()) {\n      case 0:\n        // no fields\n        return null;\n      case 1:\n        // already an atomic reader / reader with one leave\n        return getDocValues(leaves.get(0).reader(), field, puller);\n      default:\n        final List<DocValuesSlice> slices = new ArrayList<DocValuesSlice>();\n        \n        TypePromoter promotedType =  TypePromoter.getIdentityPromoter();\n        \n        // gather all docvalues fields, accumulating a promoted type across \n        // potentially incompatible types\n        for (final AtomicReaderContext ctx : leaves) {\n          final AtomicReader r = ctx.reader();\n          final DocValues d = puller.pull(r, field);\n          if (d != null) {\n            TypePromoter incoming = TypePromoter.create(d.getType(), d.getValueSize());\n            promotedType = promotedType.promote(incoming);\n          } else if (puller.stopLoadingOnNull(r, field)){\n            return null;\n          }\n          slices.add(new DocValuesSlice(d, ctx.docBase, r.maxDoc()));\n        }\n        \n        // return null if no docvalues encountered anywhere\n        if (promotedType == TypePromoter.getIdentityPromoter()) {\n          return null;\n        }\n             \n        // populate starts and fill gaps with empty docvalues \n        int starts[] = new int[slices.size()];\n        for (int i = 0; i < slices.size(); i++) {\n          DocValuesSlice slice = slices.get(i);\n          starts[i] = slice.start;\n          if (slice.docValues == null) {\n            Type promoted = promotedType.type();\n            switch(promoted) {\n              case BYTES_FIXED_DEREF:\n              case BYTES_FIXED_STRAIGHT:\n              case BYTES_FIXED_SORTED:\n                assert promotedType.getValueSize() >= 0;\n                slice.docValues = new EmptyFixedDocValues(slice.length, promoted, promotedType.getValueSize());\n                break;\n              default:\n                slice.docValues = new EmptyDocValues(slice.length, promoted);\n            }\n          }\n        }\n        \n        return new MultiDocValues(slices.toArray(new DocValuesSlice[slices.size()]), starts, promotedType);\n    }\n  }\n\n","sourceOld":"  private static DocValues getDocValues(IndexReader reader, final String field, final DocValuesPuller puller) throws IOException {\n    if (reader instanceof AtomicReader) {\n      // already an atomic reader\n      return puller.pull((AtomicReader) reader, field);\n    }\n    assert reader instanceof CompositeReader;\n    final List<AtomicReaderContext> leaves = reader.getTopReaderContext().leaves();\n    switch (leaves.size()) {\n      case 0:\n        // no fields\n        return null;\n      case 1:\n        // already an atomic reader / reader with one leave\n        return getDocValues(leaves.get(0).reader(), field, puller);\n      default:\n        final List<DocValuesSlice> slices = new ArrayList<DocValuesSlice>();\n        \n        TypePromoter promotedType =  TypePromoter.getIdentityPromoter();\n        \n        // gather all docvalues fields, accumulating a promoted type across \n        // potentially incompatible types\n        for (final AtomicReaderContext ctx : leaves) {\n          final AtomicReader r = ctx.reader();\n          final DocValues d = puller.pull(r, field);\n          if (d != null) {\n            TypePromoter incoming = TypePromoter.create(d.getType(), d.getValueSize());\n            promotedType = promotedType.promote(incoming);\n          } else if (puller.stopLoadingOnNull(r, field)){\n            return null;\n          }\n          slices.add(new DocValuesSlice(d, ctx.docBase, r.maxDoc()));\n        }\n        \n        // return null if no docvalues encountered anywhere\n        if (promotedType == TypePromoter.getIdentityPromoter()) {\n          return null;\n        }\n             \n        // populate starts and fill gaps with empty docvalues \n        int starts[] = new int[slices.size()];\n        for (int i = 0; i < slices.size(); i++) {\n          DocValuesSlice slice = slices.get(i);\n          starts[i] = slice.start;\n          if (slice.docValues == null) {\n            Type promoted = promotedType.type();\n            switch(promoted) {\n              case BYTES_FIXED_DEREF:\n              case BYTES_FIXED_STRAIGHT:\n              case BYTES_FIXED_SORTED:\n                assert promotedType.getValueSize() >= 0;\n                slice.docValues = new EmptyFixedDocValues(slice.length, promoted, promotedType.getValueSize());\n                break;\n              default:\n                slice.docValues = new EmptyDocValues(slice.length, promoted);\n            }\n          }\n        }\n        \n        return new MultiDocValues(slices.toArray(new DocValuesSlice[slices.size()]), starts, promotedType);\n    }\n  }\n\n","bugFix":["4c5ae929ce8aa0c4856f0d6bfd4c196bc2d3eb9c"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c1fe8ee1a5a1ef00a9c4793ec26f17bd90342198","date":1345029782,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/MultiDocValues#getDocValues(IndexReader,String,DocValuesPuller).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/MultiDocValues#getDocValues(IndexReader,String,DocValuesPuller).mjava","sourceNew":"  private static DocValues getDocValues(IndexReader reader, final String field, final DocValuesPuller puller) throws IOException {\n    if (reader instanceof AtomicReader) {\n      // already an atomic reader\n      return puller.pull((AtomicReader) reader, field);\n    }\n    assert reader instanceof CompositeReader;\n    final List<AtomicReaderContext> leaves = reader.leaves();\n    switch (leaves.size()) {\n      case 0:\n        // no fields\n        return null;\n      case 1:\n        // already an atomic reader / reader with one leave\n        return getDocValues(leaves.get(0).reader(), field, puller);\n      default:\n        final List<DocValuesSlice> slices = new ArrayList<DocValuesSlice>();\n        \n        TypePromoter promotedType =  TypePromoter.getIdentityPromoter();\n        \n        // gather all docvalues fields, accumulating a promoted type across \n        // potentially incompatible types\n        for (final AtomicReaderContext ctx : leaves) {\n          final AtomicReader r = ctx.reader();\n          final DocValues d = puller.pull(r, field);\n          if (d != null) {\n            TypePromoter incoming = TypePromoter.create(d.getType(), d.getValueSize());\n            promotedType = promotedType.promote(incoming);\n          } else if (puller.stopLoadingOnNull(r, field)){\n            return null;\n          }\n          slices.add(new DocValuesSlice(d, ctx.docBase, r.maxDoc()));\n        }\n        \n        // return null if no docvalues encountered anywhere\n        if (promotedType == TypePromoter.getIdentityPromoter()) {\n          return null;\n        }\n             \n        // populate starts and fill gaps with empty docvalues \n        int starts[] = new int[slices.size()];\n        for (int i = 0; i < slices.size(); i++) {\n          DocValuesSlice slice = slices.get(i);\n          starts[i] = slice.start;\n          if (slice.docValues == null) {\n            Type promoted = promotedType.type();\n            switch(promoted) {\n              case BYTES_FIXED_DEREF:\n              case BYTES_FIXED_STRAIGHT:\n              case BYTES_FIXED_SORTED:\n                assert promotedType.getValueSize() >= 0;\n                slice.docValues = new EmptyFixedDocValues(slice.length, promoted, promotedType.getValueSize());\n                break;\n              default:\n                slice.docValues = new EmptyDocValues(slice.length, promoted);\n            }\n          }\n        }\n        \n        return new MultiDocValues(slices.toArray(new DocValuesSlice[slices.size()]), starts, promotedType);\n    }\n  }\n\n","sourceOld":"  private static DocValues getDocValues(IndexReader reader, final String field, final DocValuesPuller puller) throws IOException {\n    if (reader instanceof AtomicReader) {\n      // already an atomic reader\n      return puller.pull((AtomicReader) reader, field);\n    }\n    assert reader instanceof CompositeReader;\n    final List<AtomicReaderContext> leaves = reader.getTopReaderContext().leaves();\n    switch (leaves.size()) {\n      case 0:\n        // no fields\n        return null;\n      case 1:\n        // already an atomic reader / reader with one leave\n        return getDocValues(leaves.get(0).reader(), field, puller);\n      default:\n        final List<DocValuesSlice> slices = new ArrayList<DocValuesSlice>();\n        \n        TypePromoter promotedType =  TypePromoter.getIdentityPromoter();\n        \n        // gather all docvalues fields, accumulating a promoted type across \n        // potentially incompatible types\n        for (final AtomicReaderContext ctx : leaves) {\n          final AtomicReader r = ctx.reader();\n          final DocValues d = puller.pull(r, field);\n          if (d != null) {\n            TypePromoter incoming = TypePromoter.create(d.getType(), d.getValueSize());\n            promotedType = promotedType.promote(incoming);\n          } else if (puller.stopLoadingOnNull(r, field)){\n            return null;\n          }\n          slices.add(new DocValuesSlice(d, ctx.docBase, r.maxDoc()));\n        }\n        \n        // return null if no docvalues encountered anywhere\n        if (promotedType == TypePromoter.getIdentityPromoter()) {\n          return null;\n        }\n             \n        // populate starts and fill gaps with empty docvalues \n        int starts[] = new int[slices.size()];\n        for (int i = 0; i < slices.size(); i++) {\n          DocValuesSlice slice = slices.get(i);\n          starts[i] = slice.start;\n          if (slice.docValues == null) {\n            Type promoted = promotedType.type();\n            switch(promoted) {\n              case BYTES_FIXED_DEREF:\n              case BYTES_FIXED_STRAIGHT:\n              case BYTES_FIXED_SORTED:\n                assert promotedType.getValueSize() >= 0;\n                slice.docValues = new EmptyFixedDocValues(slice.length, promoted, promotedType.getValueSize());\n                break;\n              default:\n                slice.docValues = new EmptyDocValues(slice.length, promoted);\n            }\n          }\n        }\n        \n        return new MultiDocValues(slices.toArray(new DocValuesSlice[slices.size()]), starts, promotedType);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3c188105a9aae04f56c24996f98f8333fc825d2e","date":1345031914,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/MultiDocValues#getDocValues(IndexReader,String,DocValuesPuller).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/MultiDocValues#getDocValues(IndexReader,String,DocValuesPuller).mjava","sourceNew":"  private static DocValues getDocValues(IndexReader reader, final String field, final DocValuesPuller puller) throws IOException {\n    if (reader instanceof AtomicReader) {\n      // already an atomic reader\n      return puller.pull((AtomicReader) reader, field);\n    }\n    assert reader instanceof CompositeReader;\n    final List<AtomicReaderContext> leaves = reader.leaves();\n    switch (leaves.size()) {\n      case 0:\n        // no fields\n        return null;\n      case 1:\n        // already an atomic reader / reader with one leave\n        return getDocValues(leaves.get(0).reader(), field, puller);\n      default:\n        final List<DocValuesSlice> slices = new ArrayList<DocValuesSlice>();\n        \n        TypePromoter promotedType =  TypePromoter.getIdentityPromoter();\n        \n        // gather all docvalues fields, accumulating a promoted type across \n        // potentially incompatible types\n        for (final AtomicReaderContext ctx : leaves) {\n          final AtomicReader r = ctx.reader();\n          final DocValues d = puller.pull(r, field);\n          if (d != null) {\n            TypePromoter incoming = TypePromoter.create(d.getType(), d.getValueSize());\n            promotedType = promotedType.promote(incoming);\n          } else if (puller.stopLoadingOnNull(r, field)){\n            return null;\n          }\n          slices.add(new DocValuesSlice(d, ctx.docBase, r.maxDoc()));\n        }\n        \n        // return null if no docvalues encountered anywhere\n        if (promotedType == TypePromoter.getIdentityPromoter()) {\n          return null;\n        }\n             \n        // populate starts and fill gaps with empty docvalues \n        int starts[] = new int[slices.size()];\n        for (int i = 0; i < slices.size(); i++) {\n          DocValuesSlice slice = slices.get(i);\n          starts[i] = slice.start;\n          if (slice.docValues == null) {\n            Type promoted = promotedType.type();\n            switch(promoted) {\n              case BYTES_FIXED_DEREF:\n              case BYTES_FIXED_STRAIGHT:\n              case BYTES_FIXED_SORTED:\n                assert promotedType.getValueSize() >= 0;\n                slice.docValues = new EmptyFixedDocValues(slice.length, promoted, promotedType.getValueSize());\n                break;\n              default:\n                slice.docValues = new EmptyDocValues(slice.length, promoted);\n            }\n          }\n        }\n        \n        return new MultiDocValues(slices.toArray(new DocValuesSlice[slices.size()]), starts, promotedType);\n    }\n  }\n\n","sourceOld":"  private static DocValues getDocValues(IndexReader reader, final String field, final DocValuesPuller puller) throws IOException {\n    if (reader instanceof AtomicReader) {\n      // already an atomic reader\n      return puller.pull((AtomicReader) reader, field);\n    }\n    assert reader instanceof CompositeReader;\n    final List<AtomicReaderContext> leaves = reader.getTopReaderContext().leaves();\n    switch (leaves.size()) {\n      case 0:\n        // no fields\n        return null;\n      case 1:\n        // already an atomic reader / reader with one leave\n        return getDocValues(leaves.get(0).reader(), field, puller);\n      default:\n        final List<DocValuesSlice> slices = new ArrayList<DocValuesSlice>();\n        \n        TypePromoter promotedType =  TypePromoter.getIdentityPromoter();\n        \n        // gather all docvalues fields, accumulating a promoted type across \n        // potentially incompatible types\n        for (final AtomicReaderContext ctx : leaves) {\n          final AtomicReader r = ctx.reader();\n          final DocValues d = puller.pull(r, field);\n          if (d != null) {\n            TypePromoter incoming = TypePromoter.create(d.getType(), d.getValueSize());\n            promotedType = promotedType.promote(incoming);\n          } else if (puller.stopLoadingOnNull(r, field)){\n            return null;\n          }\n          slices.add(new DocValuesSlice(d, ctx.docBase, r.maxDoc()));\n        }\n        \n        // return null if no docvalues encountered anywhere\n        if (promotedType == TypePromoter.getIdentityPromoter()) {\n          return null;\n        }\n             \n        // populate starts and fill gaps with empty docvalues \n        int starts[] = new int[slices.size()];\n        for (int i = 0; i < slices.size(); i++) {\n          DocValuesSlice slice = slices.get(i);\n          starts[i] = slice.start;\n          if (slice.docValues == null) {\n            Type promoted = promotedType.type();\n            switch(promoted) {\n              case BYTES_FIXED_DEREF:\n              case BYTES_FIXED_STRAIGHT:\n              case BYTES_FIXED_SORTED:\n                assert promotedType.getValueSize() >= 0;\n                slice.docValues = new EmptyFixedDocValues(slice.length, promoted, promotedType.getValueSize());\n                break;\n              default:\n                slice.docValues = new EmptyDocValues(slice.length, promoted);\n            }\n          }\n        }\n        \n        return new MultiDocValues(slices.toArray(new DocValuesSlice[slices.size()]), starts, promotedType);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"1c93396a1df03720cb20e2c2f513a6fa59b21e4c","date":1345032673,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/MultiDocValues#getDocValues(IndexReader,String,DocValuesPuller).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/MultiDocValues#getDocValues(IndexReader,String,DocValuesPuller).mjava","sourceNew":"  private static DocValues getDocValues(IndexReader reader, final String field, final DocValuesPuller puller) throws IOException {\n    if (reader instanceof AtomicReader) {\n      // already an atomic reader\n      return puller.pull((AtomicReader) reader, field);\n    }\n    assert reader instanceof CompositeReader;\n    final List<AtomicReaderContext> leaves = reader.getTopReaderContext().leaves();\n    switch (leaves.size()) {\n      case 0:\n        // no fields\n        return null;\n      case 1:\n        // already an atomic reader / reader with one leave\n        return getDocValues(leaves.get(0).reader(), field, puller);\n      default:\n        final List<DocValuesSlice> slices = new ArrayList<DocValuesSlice>();\n        \n        TypePromoter promotedType =  TypePromoter.getIdentityPromoter();\n        \n        // gather all docvalues fields, accumulating a promoted type across \n        // potentially incompatible types\n        for (final AtomicReaderContext ctx : leaves) {\n          final AtomicReader r = ctx.reader();\n          final DocValues d = puller.pull(r, field);\n          if (d != null) {\n            TypePromoter incoming = TypePromoter.create(d.getType(), d.getValueSize());\n            promotedType = promotedType.promote(incoming);\n          } else if (puller.stopLoadingOnNull(r, field)){\n            return null;\n          }\n          slices.add(new DocValuesSlice(d, ctx.docBase, r.maxDoc()));\n        }\n        \n        // return null if no docvalues encountered anywhere\n        if (promotedType == TypePromoter.getIdentityPromoter()) {\n          return null;\n        }\n             \n        // populate starts and fill gaps with empty docvalues \n        int starts[] = new int[slices.size()];\n        for (int i = 0; i < slices.size(); i++) {\n          DocValuesSlice slice = slices.get(i);\n          starts[i] = slice.start;\n          if (slice.docValues == null) {\n            Type promoted = promotedType.type();\n            switch(promoted) {\n              case BYTES_FIXED_DEREF:\n              case BYTES_FIXED_STRAIGHT:\n              case BYTES_FIXED_SORTED:\n                assert promotedType.getValueSize() >= 0;\n                slice.docValues = new EmptyFixedDocValues(slice.length, promoted, promotedType.getValueSize());\n                break;\n              default:\n                slice.docValues = new EmptyDocValues(slice.length, promoted);\n            }\n          }\n        }\n        \n        return new MultiDocValues(slices.toArray(new DocValuesSlice[slices.size()]), starts, promotedType);\n    }\n  }\n\n","sourceOld":"  private static DocValues getDocValues(IndexReader reader, final String field, final DocValuesPuller puller) throws IOException {\n    if (reader instanceof AtomicReader) {\n      // already an atomic reader\n      return puller.pull((AtomicReader) reader, field);\n    }\n    assert reader instanceof CompositeReader;\n    final List<AtomicReaderContext> leaves = reader.leaves();\n    switch (leaves.size()) {\n      case 0:\n        // no fields\n        return null;\n      case 1:\n        // already an atomic reader / reader with one leave\n        return getDocValues(leaves.get(0).reader(), field, puller);\n      default:\n        final List<DocValuesSlice> slices = new ArrayList<DocValuesSlice>();\n        \n        TypePromoter promotedType =  TypePromoter.getIdentityPromoter();\n        \n        // gather all docvalues fields, accumulating a promoted type across \n        // potentially incompatible types\n        for (final AtomicReaderContext ctx : leaves) {\n          final AtomicReader r = ctx.reader();\n          final DocValues d = puller.pull(r, field);\n          if (d != null) {\n            TypePromoter incoming = TypePromoter.create(d.getType(), d.getValueSize());\n            promotedType = promotedType.promote(incoming);\n          } else if (puller.stopLoadingOnNull(r, field)){\n            return null;\n          }\n          slices.add(new DocValuesSlice(d, ctx.docBase, r.maxDoc()));\n        }\n        \n        // return null if no docvalues encountered anywhere\n        if (promotedType == TypePromoter.getIdentityPromoter()) {\n          return null;\n        }\n             \n        // populate starts and fill gaps with empty docvalues \n        int starts[] = new int[slices.size()];\n        for (int i = 0; i < slices.size(); i++) {\n          DocValuesSlice slice = slices.get(i);\n          starts[i] = slice.start;\n          if (slice.docValues == null) {\n            Type promoted = promotedType.type();\n            switch(promoted) {\n              case BYTES_FIXED_DEREF:\n              case BYTES_FIXED_STRAIGHT:\n              case BYTES_FIXED_SORTED:\n                assert promotedType.getValueSize() >= 0;\n                slice.docValues = new EmptyFixedDocValues(slice.length, promoted, promotedType.getValueSize());\n                break;\n              default:\n                slice.docValues = new EmptyDocValues(slice.length, promoted);\n            }\n          }\n        }\n        \n        return new MultiDocValues(slices.toArray(new DocValuesSlice[slices.size()]), starts, promotedType);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b05c56a41b733e02a189c48895922b5bd8c7f3d1","date":1345033322,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/MultiDocValues#getDocValues(IndexReader,String,DocValuesPuller).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/MultiDocValues#getDocValues(IndexReader,String,DocValuesPuller).mjava","sourceNew":"  private static DocValues getDocValues(IndexReader reader, final String field, final DocValuesPuller puller) throws IOException {\n    if (reader instanceof AtomicReader) {\n      // already an atomic reader\n      return puller.pull((AtomicReader) reader, field);\n    }\n    assert reader instanceof CompositeReader;\n    final List<AtomicReaderContext> leaves = reader.leaves();\n    switch (leaves.size()) {\n      case 0:\n        // no fields\n        return null;\n      case 1:\n        // already an atomic reader / reader with one leave\n        return getDocValues(leaves.get(0).reader(), field, puller);\n      default:\n        final List<DocValuesSlice> slices = new ArrayList<DocValuesSlice>();\n        \n        TypePromoter promotedType =  TypePromoter.getIdentityPromoter();\n        \n        // gather all docvalues fields, accumulating a promoted type across \n        // potentially incompatible types\n        for (final AtomicReaderContext ctx : leaves) {\n          final AtomicReader r = ctx.reader();\n          final DocValues d = puller.pull(r, field);\n          if (d != null) {\n            TypePromoter incoming = TypePromoter.create(d.getType(), d.getValueSize());\n            promotedType = promotedType.promote(incoming);\n          } else if (puller.stopLoadingOnNull(r, field)){\n            return null;\n          }\n          slices.add(new DocValuesSlice(d, ctx.docBase, r.maxDoc()));\n        }\n        \n        // return null if no docvalues encountered anywhere\n        if (promotedType == TypePromoter.getIdentityPromoter()) {\n          return null;\n        }\n             \n        // populate starts and fill gaps with empty docvalues \n        int starts[] = new int[slices.size()];\n        for (int i = 0; i < slices.size(); i++) {\n          DocValuesSlice slice = slices.get(i);\n          starts[i] = slice.start;\n          if (slice.docValues == null) {\n            Type promoted = promotedType.type();\n            switch(promoted) {\n              case BYTES_FIXED_DEREF:\n              case BYTES_FIXED_STRAIGHT:\n              case BYTES_FIXED_SORTED:\n                assert promotedType.getValueSize() >= 0;\n                slice.docValues = new EmptyFixedDocValues(slice.length, promoted, promotedType.getValueSize());\n                break;\n              default:\n                slice.docValues = new EmptyDocValues(slice.length, promoted);\n            }\n          }\n        }\n        \n        return new MultiDocValues(slices.toArray(new DocValuesSlice[slices.size()]), starts, promotedType);\n    }\n  }\n\n","sourceOld":"  private static DocValues getDocValues(IndexReader reader, final String field, final DocValuesPuller puller) throws IOException {\n    if (reader instanceof AtomicReader) {\n      // already an atomic reader\n      return puller.pull((AtomicReader) reader, field);\n    }\n    assert reader instanceof CompositeReader;\n    final List<AtomicReaderContext> leaves = reader.getTopReaderContext().leaves();\n    switch (leaves.size()) {\n      case 0:\n        // no fields\n        return null;\n      case 1:\n        // already an atomic reader / reader with one leave\n        return getDocValues(leaves.get(0).reader(), field, puller);\n      default:\n        final List<DocValuesSlice> slices = new ArrayList<DocValuesSlice>();\n        \n        TypePromoter promotedType =  TypePromoter.getIdentityPromoter();\n        \n        // gather all docvalues fields, accumulating a promoted type across \n        // potentially incompatible types\n        for (final AtomicReaderContext ctx : leaves) {\n          final AtomicReader r = ctx.reader();\n          final DocValues d = puller.pull(r, field);\n          if (d != null) {\n            TypePromoter incoming = TypePromoter.create(d.getType(), d.getValueSize());\n            promotedType = promotedType.promote(incoming);\n          } else if (puller.stopLoadingOnNull(r, field)){\n            return null;\n          }\n          slices.add(new DocValuesSlice(d, ctx.docBase, r.maxDoc()));\n        }\n        \n        // return null if no docvalues encountered anywhere\n        if (promotedType == TypePromoter.getIdentityPromoter()) {\n          return null;\n        }\n             \n        // populate starts and fill gaps with empty docvalues \n        int starts[] = new int[slices.size()];\n        for (int i = 0; i < slices.size(); i++) {\n          DocValuesSlice slice = slices.get(i);\n          starts[i] = slice.start;\n          if (slice.docValues == null) {\n            Type promoted = promotedType.type();\n            switch(promoted) {\n              case BYTES_FIXED_DEREF:\n              case BYTES_FIXED_STRAIGHT:\n              case BYTES_FIXED_SORTED:\n                assert promotedType.getValueSize() >= 0;\n                slice.docValues = new EmptyFixedDocValues(slice.length, promoted, promotedType.getValueSize());\n                break;\n              default:\n                slice.docValues = new EmptyDocValues(slice.length, promoted);\n            }\n          }\n        }\n        \n        return new MultiDocValues(slices.toArray(new DocValuesSlice[slices.size()]), starts, promotedType);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0837ab0472feecb3a54260729d845f839e1cbd72","date":1358283639,"type":4,"author":"Robert Muir","isMerge":false,"pathNew":"/dev/null","pathOld":"lucene/core/src/java/org/apache/lucene/index/MultiDocValues#getDocValues(IndexReader,String,DocValuesPuller).mjava","sourceNew":null,"sourceOld":"  private static DocValues getDocValues(IndexReader reader, final String field, final DocValuesPuller puller) throws IOException {\n    if (reader instanceof AtomicReader) {\n      // already an atomic reader\n      return puller.pull((AtomicReader) reader, field);\n    }\n    assert reader instanceof CompositeReader;\n    final List<AtomicReaderContext> leaves = reader.leaves();\n    switch (leaves.size()) {\n      case 0:\n        // no fields\n        return null;\n      case 1:\n        // already an atomic reader / reader with one leave\n        return getDocValues(leaves.get(0).reader(), field, puller);\n      default:\n        final List<DocValuesSlice> slices = new ArrayList<DocValuesSlice>();\n        \n        TypePromoter promotedType =  TypePromoter.getIdentityPromoter();\n        \n        // gather all docvalues fields, accumulating a promoted type across \n        // potentially incompatible types\n        for (final AtomicReaderContext ctx : leaves) {\n          final AtomicReader r = ctx.reader();\n          final DocValues d = puller.pull(r, field);\n          if (d != null) {\n            TypePromoter incoming = TypePromoter.create(d.getType(), d.getValueSize());\n            promotedType = promotedType.promote(incoming);\n          } else if (puller.stopLoadingOnNull(r, field)){\n            return null;\n          }\n          slices.add(new DocValuesSlice(d, ctx.docBase, r.maxDoc()));\n        }\n        \n        // return null if no docvalues encountered anywhere\n        if (promotedType == TypePromoter.getIdentityPromoter()) {\n          return null;\n        }\n             \n        // populate starts and fill gaps with empty docvalues \n        int starts[] = new int[slices.size()];\n        for (int i = 0; i < slices.size(); i++) {\n          DocValuesSlice slice = slices.get(i);\n          starts[i] = slice.start;\n          if (slice.docValues == null) {\n            Type promoted = promotedType.type();\n            switch(promoted) {\n              case BYTES_FIXED_DEREF:\n              case BYTES_FIXED_STRAIGHT:\n              case BYTES_FIXED_SORTED:\n                assert promotedType.getValueSize() >= 0;\n                slice.docValues = new EmptyFixedDocValues(slice.length, promoted, promotedType.getValueSize());\n                break;\n              default:\n                slice.docValues = new EmptyDocValues(slice.length, promoted);\n            }\n          }\n        }\n        \n        return new MultiDocValues(slices.toArray(new DocValuesSlice[slices.size()]), starts, promotedType);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d4d69c535930b5cce125cff868d40f6373dc27d4","date":1360270101,"type":4,"author":"Robert Muir","isMerge":true,"pathNew":"/dev/null","pathOld":"lucene/core/src/java/org/apache/lucene/index/MultiDocValues#getDocValues(IndexReader,String,DocValuesPuller).mjava","sourceNew":null,"sourceOld":"  private static DocValues getDocValues(IndexReader reader, final String field, final DocValuesPuller puller) throws IOException {\n    if (reader instanceof AtomicReader) {\n      // already an atomic reader\n      return puller.pull((AtomicReader) reader, field);\n    }\n    assert reader instanceof CompositeReader;\n    final List<AtomicReaderContext> leaves = reader.leaves();\n    switch (leaves.size()) {\n      case 0:\n        // no fields\n        return null;\n      case 1:\n        // already an atomic reader / reader with one leave\n        return getDocValues(leaves.get(0).reader(), field, puller);\n      default:\n        final List<DocValuesSlice> slices = new ArrayList<DocValuesSlice>();\n        \n        TypePromoter promotedType =  TypePromoter.getIdentityPromoter();\n        \n        // gather all docvalues fields, accumulating a promoted type across \n        // potentially incompatible types\n        for (final AtomicReaderContext ctx : leaves) {\n          final AtomicReader r = ctx.reader();\n          final DocValues d = puller.pull(r, field);\n          if (d != null) {\n            TypePromoter incoming = TypePromoter.create(d.getType(), d.getValueSize());\n            promotedType = promotedType.promote(incoming);\n          } else if (puller.stopLoadingOnNull(r, field)){\n            return null;\n          }\n          slices.add(new DocValuesSlice(d, ctx.docBase, r.maxDoc()));\n        }\n        \n        // return null if no docvalues encountered anywhere\n        if (promotedType == TypePromoter.getIdentityPromoter()) {\n          return null;\n        }\n             \n        // populate starts and fill gaps with empty docvalues \n        int starts[] = new int[slices.size()];\n        for (int i = 0; i < slices.size(); i++) {\n          DocValuesSlice slice = slices.get(i);\n          starts[i] = slice.start;\n          if (slice.docValues == null) {\n            Type promoted = promotedType.type();\n            switch(promoted) {\n              case BYTES_FIXED_DEREF:\n              case BYTES_FIXED_STRAIGHT:\n              case BYTES_FIXED_SORTED:\n                assert promotedType.getValueSize() >= 0;\n                slice.docValues = new EmptyFixedDocValues(slice.length, promoted, promotedType.getValueSize());\n                break;\n              default:\n                slice.docValues = new EmptyDocValues(slice.length, promoted);\n            }\n          }\n        }\n        \n        return new MultiDocValues(slices.toArray(new DocValuesSlice[slices.size()]), starts, promotedType);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"38e3b736c7ca086d61b7dbb841c905ee115490da":["3a119bbc8703c10faa329ec201c654b3a35a1e3e","cd0f953fbccd59aa346f280fe7e30a698f5ecb04"],"3c188105a9aae04f56c24996f98f8333fc825d2e":["4c5ae929ce8aa0c4856f0d6bfd4c196bc2d3eb9c"],"4c5ae929ce8aa0c4856f0d6bfd4c196bc2d3eb9c":["cd0f953fbccd59aa346f280fe7e30a698f5ecb04"],"b05c56a41b733e02a189c48895922b5bd8c7f3d1":["1c93396a1df03720cb20e2c2f513a6fa59b21e4c","d743dbdc40bef0a47a5d54d99623ef0c2eb5923e"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"1c93396a1df03720cb20e2c2f513a6fa59b21e4c":["3c188105a9aae04f56c24996f98f8333fc825d2e"],"c1fe8ee1a5a1ef00a9c4793ec26f17bd90342198":["4c5ae929ce8aa0c4856f0d6bfd4c196bc2d3eb9c","d743dbdc40bef0a47a5d54d99623ef0c2eb5923e"],"d4d69c535930b5cce125cff868d40f6373dc27d4":["d743dbdc40bef0a47a5d54d99623ef0c2eb5923e","0837ab0472feecb3a54260729d845f839e1cbd72"],"cd0f953fbccd59aa346f280fe7e30a698f5ecb04":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"d743dbdc40bef0a47a5d54d99623ef0c2eb5923e":["4c5ae929ce8aa0c4856f0d6bfd4c196bc2d3eb9c"],"0837ab0472feecb3a54260729d845f839e1cbd72":["d743dbdc40bef0a47a5d54d99623ef0c2eb5923e"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["d4d69c535930b5cce125cff868d40f6373dc27d4"]},"commit2Childs":{"38e3b736c7ca086d61b7dbb841c905ee115490da":[],"3c188105a9aae04f56c24996f98f8333fc825d2e":["1c93396a1df03720cb20e2c2f513a6fa59b21e4c"],"4c5ae929ce8aa0c4856f0d6bfd4c196bc2d3eb9c":["3c188105a9aae04f56c24996f98f8333fc825d2e","c1fe8ee1a5a1ef00a9c4793ec26f17bd90342198","d743dbdc40bef0a47a5d54d99623ef0c2eb5923e"],"b05c56a41b733e02a189c48895922b5bd8c7f3d1":[],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["38e3b736c7ca086d61b7dbb841c905ee115490da","cd0f953fbccd59aa346f280fe7e30a698f5ecb04"],"1c93396a1df03720cb20e2c2f513a6fa59b21e4c":["b05c56a41b733e02a189c48895922b5bd8c7f3d1"],"c1fe8ee1a5a1ef00a9c4793ec26f17bd90342198":[],"d4d69c535930b5cce125cff868d40f6373dc27d4":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"cd0f953fbccd59aa346f280fe7e30a698f5ecb04":["38e3b736c7ca086d61b7dbb841c905ee115490da","4c5ae929ce8aa0c4856f0d6bfd4c196bc2d3eb9c"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"d743dbdc40bef0a47a5d54d99623ef0c2eb5923e":["b05c56a41b733e02a189c48895922b5bd8c7f3d1","c1fe8ee1a5a1ef00a9c4793ec26f17bd90342198","d4d69c535930b5cce125cff868d40f6373dc27d4","0837ab0472feecb3a54260729d845f839e1cbd72"],"0837ab0472feecb3a54260729d845f839e1cbd72":["d4d69c535930b5cce125cff868d40f6373dc27d4"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["38e3b736c7ca086d61b7dbb841c905ee115490da","b05c56a41b733e02a189c48895922b5bd8c7f3d1","c1fe8ee1a5a1ef00a9c4793ec26f17bd90342198","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}