{"path":"lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestLucene47WordDelimiterFilter#testOffsets().mjava","commits":[{"id":"c85fa43e6918808743daa7847ba0264373af687f","date":1395166336,"type":0,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestLucene47WordDelimiterFilter#testOffsets().mjava","pathOld":"/dev/null","sourceNew":"  /***\n  public void testPerformance() throws IOException {\n    String s = \"now is the time-for all good men to come to-the aid of their country.\";\n    Token tok = new Token();\n    long start = System.currentTimeMillis();\n    int ret=0;\n    for (int i=0; i<1000000; i++) {\n      StringReader r = new StringReader(s);\n      TokenStream ts = new WhitespaceTokenizer(r);\n      ts = new WordDelimiterFilter(ts, 1,1,1,1,0);\n\n      while (ts.next(tok) != null) ret++;\n    }\n\n    System.out.println(\"ret=\"+ret+\" time=\"+(System.currentTimeMillis()-start));\n  }\n  ***/\n\n  @Test\n  public void testOffsets() throws IOException {\n    int flags = GENERATE_WORD_PARTS | GENERATE_NUMBER_PARTS | CATENATE_ALL | SPLIT_ON_CASE_CHANGE | SPLIT_ON_NUMERICS | STEM_ENGLISH_POSSESSIVE;\n    // test that subwords and catenated subwords have\n    // the correct offsets.\n    TokenFilter wdf = new Lucene47WordDelimiterFilter(new SingleTokenTokenStream(new Token(\"foo-bar\", 5, 12)), DEFAULT_WORD_DELIM_TABLE, flags, null);\n\n    assertTokenStreamContents(wdf, \n        new String[] { \"foo\", \"bar\", \"foobar\" },\n        new int[] { 5, 9, 5 }, \n        new int[] { 8, 12, 12 },\n        null, null, null, null, false);\n\n    wdf = new Lucene47WordDelimiterFilter(new SingleTokenTokenStream(new Token(\"foo-bar\", 5, 6)), DEFAULT_WORD_DELIM_TABLE, flags, null);\n    \n    assertTokenStreamContents(wdf,\n        new String[] { \"foo\", \"bar\", \"foobar\" },\n        new int[] { 5, 5, 5 },\n        new int[] { 6, 6, 6 },\n        null, null, null, null, false);\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"71387d8cb6923eb831b17a8b734608ba2e21c653","date":1414126093,"type":4,"author":"Robert Muir","isMerge":false,"pathNew":"/dev/null","pathOld":"lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestLucene47WordDelimiterFilter#testOffsets().mjava","sourceNew":null,"sourceOld":"  /***\n  public void testPerformance() throws IOException {\n    String s = \"now is the time-for all good men to come to-the aid of their country.\";\n    Token tok = new Token();\n    long start = System.currentTimeMillis();\n    int ret=0;\n    for (int i=0; i<1000000; i++) {\n      StringReader r = new StringReader(s);\n      TokenStream ts = new WhitespaceTokenizer(r);\n      ts = new WordDelimiterFilter(ts, 1,1,1,1,0);\n\n      while (ts.next(tok) != null) ret++;\n    }\n\n    System.out.println(\"ret=\"+ret+\" time=\"+(System.currentTimeMillis()-start));\n  }\n  ***/\n\n  @Test\n  public void testOffsets() throws IOException {\n    int flags = GENERATE_WORD_PARTS | GENERATE_NUMBER_PARTS | CATENATE_ALL | SPLIT_ON_CASE_CHANGE | SPLIT_ON_NUMERICS | STEM_ENGLISH_POSSESSIVE;\n    // test that subwords and catenated subwords have\n    // the correct offsets.\n    TokenFilter wdf = new Lucene47WordDelimiterFilter(new SingleTokenTokenStream(new Token(\"foo-bar\", 5, 12)), DEFAULT_WORD_DELIM_TABLE, flags, null);\n\n    assertTokenStreamContents(wdf, \n        new String[] { \"foo\", \"bar\", \"foobar\" },\n        new int[] { 5, 9, 5 }, \n        new int[] { 8, 12, 12 },\n        null, null, null, null, false);\n\n    wdf = new Lucene47WordDelimiterFilter(new SingleTokenTokenStream(new Token(\"foo-bar\", 5, 6)), DEFAULT_WORD_DELIM_TABLE, flags, null);\n    \n    assertTokenStreamContents(wdf,\n        new String[] { \"foo\", \"bar\", \"foobar\" },\n        new int[] { 5, 5, 5 },\n        new int[] { 6, 6, 6 },\n        null, null, null, null, false);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"71387d8cb6923eb831b17a8b734608ba2e21c653":["c85fa43e6918808743daa7847ba0264373af687f"],"c85fa43e6918808743daa7847ba0264373af687f":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["71387d8cb6923eb831b17a8b734608ba2e21c653"]},"commit2Childs":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["c85fa43e6918808743daa7847ba0264373af687f"],"71387d8cb6923eb831b17a8b734608ba2e21c653":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"c85fa43e6918808743daa7847ba0264373af687f":["71387d8cb6923eb831b17a8b734608ba2e21c653"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}