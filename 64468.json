{"path":"solr/core/src/test/org/apache/solr/update/TestInPlaceUpdatesDistrib#delayedReorderingFetchesMissingUpdateFromLeaderTest().mjava","commits":[{"id":"415bbbe7da8065dd3c477bdc3c703c6425622998","date":1485393793,"type":0,"author":"Ishan Chattopadhyaya","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/update/TestInPlaceUpdatesDistrib#delayedReorderingFetchesMissingUpdateFromLeaderTest().mjava","pathOld":"/dev/null","sourceNew":"  private void delayedReorderingFetchesMissingUpdateFromLeaderTest() throws Exception {\n    del(\"*:*\");\n    commit();\n    \n    float inplace_updatable_float = 1F;\n    buildRandomIndex(inplace_updatable_float, Collections.singletonList(1));\n\n    float newinplace_updatable_float = 100F;\n    List<UpdateRequest> updates = new ArrayList<>();\n    updates.add(regularUpdateRequest(\"id\", 1, \"title_s\", \"title1_new\", \"id_i\", 1, \"inplace_updatable_float\", newinplace_updatable_float));\n    updates.add(regularUpdateRequest(\"id\", 1, \"inplace_updatable_float\", map(\"inc\", 1)));\n    updates.add(regularUpdateRequest(\"id\", 1, \"inplace_updatable_float\", map(\"inc\", 1)));\n\n    // The next request to replica2 will be delayed by 6 secs (timeout is 5s)\n    shardToJetty.get(SHARD1).get(1).jetty.getDebugFilter().addDelay(\n        \"Waiting for dependant update to timeout\", 1, 6000);\n\n    ExecutorService threadpool =\n        ExecutorUtil.newMDCAwareFixedThreadPool(updates.size() + 1, new DefaultSolrThreadFactory(getTestName()));\n    for (UpdateRequest update : updates) {\n      AsyncUpdateWithRandomCommit task = new AsyncUpdateWithRandomCommit(update, cloudClient,\n                                                                         random().nextLong());\n      threadpool.submit(task);\n\n      // while we can't guarantee/trust what order the updates are executed in, since multiple threads\n      // are involved, but we're trying to bias the thread scheduling to run them in the order submitted\n      Thread.sleep(100); \n    }\n\n    threadpool.shutdown();\n    assertTrue(\"Thread pool didn't terminate within 10 secs\", threadpool.awaitTermination(10, TimeUnit.SECONDS));\n\n    commit();\n\n    // TODO: Could try checking ZK for LIR flags to ensure LIR has not kicked in\n    // Check every 10ms, 100 times, for a replica to go down (& assert that it doesn't)\n    for (int i=0; i<100; i++) {\n      Thread.sleep(10);\n      cloudClient.getZkStateReader().forceUpdateCollection(DEFAULT_COLLECTION);\n      ClusterState state = cloudClient.getZkStateReader().getClusterState();\n\n      int numActiveReplicas = 0;\n      for (Replica rep: state.getCollection(DEFAULT_COLLECTION).getSlice(SHARD1).getReplicas())\n        if (rep.getState().equals(Replica.State.ACTIVE))\n          numActiveReplicas++;\n\n      assertEquals(\"The replica receiving reordered updates must not have gone down\", 3, numActiveReplicas);\n    }\n\n    for (SolrClient client : clients) {\n      log.info(\"Testing client (Fetch missing test): \" + ((HttpSolrClient)client).getBaseURL());\n      log.info(\"Version at \" + ((HttpSolrClient)client).getBaseURL() + \" is: \" + getReplicaValue(client, 1, \"_version_\"));\n\n      assertReplicaValue(client, 1, \"inplace_updatable_float\", (newinplace_updatable_float + 2.0f), \n          \"inplace_updatable_float didn't match for replica at client: \" + ((HttpSolrClient)client).getBaseURL());\n      assertReplicaValue(client, 1, \"title_s\", \"title1_new\", \n          \"Title didn't match for replica at client: \" + ((HttpSolrClient)client).getBaseURL());\n    }\n    \n    // Try another round of these updates, this time with a delete request at the end.\n    // This is to ensure that the fetch missing update from leader doesn't bomb out if the \n    // document has been deleted on the leader later on\n    {\n      del(\"*:*\");\n      commit();\n      shardToJetty.get(SHARD1).get(1).jetty.getDebugFilter().unsetDelay();\n      \n      updates.add(regularDeleteRequest(1));\n\n      shardToJetty.get(SHARD1).get(1).jetty.getDebugFilter().addDelay(\"Waiting for dependant update to timeout\", 1, 5999); // the first update\n      shardToJetty.get(SHARD1).get(1).jetty.getDebugFilter().addDelay(\"Waiting for dependant update to timeout\", 4, 5998); // the delete update\n\n      threadpool =\n          ExecutorUtil.newMDCAwareFixedThreadPool(updates.size() + 1, new DefaultSolrThreadFactory(getTestName()));\n      for (UpdateRequest update : updates) {\n        AsyncUpdateWithRandomCommit task = new AsyncUpdateWithRandomCommit(update, cloudClient,\n                                                                           random().nextLong());\n        threadpool.submit(task);\n        \n        // while we can't guarantee/trust what order the updates are executed in, since multiple threads\n        // are involved, but we're trying to bias the thread scheduling to run them in the order submitted\n        Thread.sleep(100);\n      }\n\n      threadpool.shutdown();\n      assertTrue(\"Thread pool didn't terminate within 15 secs\", threadpool.awaitTermination(15, TimeUnit.SECONDS));\n\n      commit();\n\n      // TODO: Could try checking ZK for LIR flags to ensure LIR has not kicked in\n      // Check every 10ms, 100 times, for a replica to go down (& assert that it doesn't)\n      ZkController zkController = shardToLeaderJetty.get(SHARD1).jetty.getCoreContainer().getZkController();\n      String lirPath = zkController.getLeaderInitiatedRecoveryZnodePath(DEFAULT_TEST_COLLECTION_NAME, SHARD1);\n      assertFalse (zkController.getZkClient().exists(lirPath, true));\n\n      for (int i=0; i<100; i++) {\n        Thread.sleep(10);\n        cloudClient.getZkStateReader().forceUpdateCollection(DEFAULT_COLLECTION);\n        ClusterState state = cloudClient.getZkStateReader().getClusterState();\n\n        int numActiveReplicas = 0;\n        for (Replica rep: state.getCollection(DEFAULT_COLLECTION).getSlice(SHARD1).getReplicas())\n          if (rep.getState().equals(Replica.State.ACTIVE))\n            numActiveReplicas++;\n\n        assertEquals(\"The replica receiving reordered updates must not have gone down\", 3, numActiveReplicas);\n      }\n\n      for (SolrClient client: new SolrClient[] {LEADER, NONLEADERS.get(0), \n          NONLEADERS.get(1)}) { // nonleader 0 re-ordered replica, nonleader 1 well-ordered replica\n        SolrDocument doc = client.getById(String.valueOf(1), params(\"distrib\", \"false\"));\n        assertNull(\"This doc was supposed to have been deleted, but was: \" + doc, doc);\n      }\n\n    }\n    log.info(\"delayedReorderingFetchesMissingUpdateFromLeaderTest: This test passed fine...\");\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["bb222a3f9d9421d5c95afce73013fbd8de07ea1f"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"598b5d23aa7c9732bf473c21a9cd309c44599394","date":1485530378,"type":0,"author":"Kevin Risden","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/update/TestInPlaceUpdatesDistrib#delayedReorderingFetchesMissingUpdateFromLeaderTest().mjava","pathOld":"/dev/null","sourceNew":"  private void delayedReorderingFetchesMissingUpdateFromLeaderTest() throws Exception {\n    del(\"*:*\");\n    commit();\n    \n    float inplace_updatable_float = 1F;\n    buildRandomIndex(inplace_updatable_float, Collections.singletonList(1));\n\n    float newinplace_updatable_float = 100F;\n    List<UpdateRequest> updates = new ArrayList<>();\n    updates.add(regularUpdateRequest(\"id\", 1, \"title_s\", \"title1_new\", \"id_i\", 1, \"inplace_updatable_float\", newinplace_updatable_float));\n    updates.add(regularUpdateRequest(\"id\", 1, \"inplace_updatable_float\", map(\"inc\", 1)));\n    updates.add(regularUpdateRequest(\"id\", 1, \"inplace_updatable_float\", map(\"inc\", 1)));\n\n    // The next request to replica2 will be delayed by 6 secs (timeout is 5s)\n    shardToJetty.get(SHARD1).get(1).jetty.getDebugFilter().addDelay(\n        \"Waiting for dependant update to timeout\", 1, 6000);\n\n    ExecutorService threadpool =\n        ExecutorUtil.newMDCAwareFixedThreadPool(updates.size() + 1, new DefaultSolrThreadFactory(getTestName()));\n    for (UpdateRequest update : updates) {\n      AsyncUpdateWithRandomCommit task = new AsyncUpdateWithRandomCommit(update, cloudClient,\n                                                                         random().nextLong());\n      threadpool.submit(task);\n\n      // while we can't guarantee/trust what order the updates are executed in, since multiple threads\n      // are involved, but we're trying to bias the thread scheduling to run them in the order submitted\n      Thread.sleep(100); \n    }\n\n    threadpool.shutdown();\n    assertTrue(\"Thread pool didn't terminate within 10 secs\", threadpool.awaitTermination(10, TimeUnit.SECONDS));\n\n    commit();\n\n    // TODO: Could try checking ZK for LIR flags to ensure LIR has not kicked in\n    // Check every 10ms, 100 times, for a replica to go down (& assert that it doesn't)\n    for (int i=0; i<100; i++) {\n      Thread.sleep(10);\n      cloudClient.getZkStateReader().forceUpdateCollection(DEFAULT_COLLECTION);\n      ClusterState state = cloudClient.getZkStateReader().getClusterState();\n\n      int numActiveReplicas = 0;\n      for (Replica rep: state.getCollection(DEFAULT_COLLECTION).getSlice(SHARD1).getReplicas())\n        if (rep.getState().equals(Replica.State.ACTIVE))\n          numActiveReplicas++;\n\n      assertEquals(\"The replica receiving reordered updates must not have gone down\", 3, numActiveReplicas);\n    }\n\n    for (SolrClient client : clients) {\n      log.info(\"Testing client (Fetch missing test): \" + ((HttpSolrClient)client).getBaseURL());\n      log.info(\"Version at \" + ((HttpSolrClient)client).getBaseURL() + \" is: \" + getReplicaValue(client, 1, \"_version_\"));\n\n      assertReplicaValue(client, 1, \"inplace_updatable_float\", (newinplace_updatable_float + 2.0f), \n          \"inplace_updatable_float didn't match for replica at client: \" + ((HttpSolrClient)client).getBaseURL());\n      assertReplicaValue(client, 1, \"title_s\", \"title1_new\", \n          \"Title didn't match for replica at client: \" + ((HttpSolrClient)client).getBaseURL());\n    }\n    \n    // Try another round of these updates, this time with a delete request at the end.\n    // This is to ensure that the fetch missing update from leader doesn't bomb out if the \n    // document has been deleted on the leader later on\n    {\n      del(\"*:*\");\n      commit();\n      shardToJetty.get(SHARD1).get(1).jetty.getDebugFilter().unsetDelay();\n      \n      updates.add(regularDeleteRequest(1));\n\n      shardToJetty.get(SHARD1).get(1).jetty.getDebugFilter().addDelay(\"Waiting for dependant update to timeout\", 1, 5999); // the first update\n      shardToJetty.get(SHARD1).get(1).jetty.getDebugFilter().addDelay(\"Waiting for dependant update to timeout\", 4, 5998); // the delete update\n\n      threadpool =\n          ExecutorUtil.newMDCAwareFixedThreadPool(updates.size() + 1, new DefaultSolrThreadFactory(getTestName()));\n      for (UpdateRequest update : updates) {\n        AsyncUpdateWithRandomCommit task = new AsyncUpdateWithRandomCommit(update, cloudClient,\n                                                                           random().nextLong());\n        threadpool.submit(task);\n        \n        // while we can't guarantee/trust what order the updates are executed in, since multiple threads\n        // are involved, but we're trying to bias the thread scheduling to run them in the order submitted\n        Thread.sleep(100);\n      }\n\n      threadpool.shutdown();\n      assertTrue(\"Thread pool didn't terminate within 15 secs\", threadpool.awaitTermination(15, TimeUnit.SECONDS));\n\n      commit();\n\n      // TODO: Could try checking ZK for LIR flags to ensure LIR has not kicked in\n      // Check every 10ms, 100 times, for a replica to go down (& assert that it doesn't)\n      ZkController zkController = shardToLeaderJetty.get(SHARD1).jetty.getCoreContainer().getZkController();\n      String lirPath = zkController.getLeaderInitiatedRecoveryZnodePath(DEFAULT_TEST_COLLECTION_NAME, SHARD1);\n      assertFalse (zkController.getZkClient().exists(lirPath, true));\n\n      for (int i=0; i<100; i++) {\n        Thread.sleep(10);\n        cloudClient.getZkStateReader().forceUpdateCollection(DEFAULT_COLLECTION);\n        ClusterState state = cloudClient.getZkStateReader().getClusterState();\n\n        int numActiveReplicas = 0;\n        for (Replica rep: state.getCollection(DEFAULT_COLLECTION).getSlice(SHARD1).getReplicas())\n          if (rep.getState().equals(Replica.State.ACTIVE))\n            numActiveReplicas++;\n\n        assertEquals(\"The replica receiving reordered updates must not have gone down\", 3, numActiveReplicas);\n      }\n\n      for (SolrClient client: new SolrClient[] {LEADER, NONLEADERS.get(0), \n          NONLEADERS.get(1)}) { // nonleader 0 re-ordered replica, nonleader 1 well-ordered replica\n        SolrDocument doc = client.getById(String.valueOf(1), params(\"distrib\", \"false\"));\n        assertNull(\"This doc was supposed to have been deleted, but was: \" + doc, doc);\n      }\n\n    }\n    log.info(\"delayedReorderingFetchesMissingUpdateFromLeaderTest: This test passed fine...\");\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5048c558f8802f1689d38203111379406b171418","date":1486467652,"type":3,"author":"Ishan Chattopadhyaya","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/update/TestInPlaceUpdatesDistrib#delayedReorderingFetchesMissingUpdateFromLeaderTest().mjava","pathOld":"solr/core/src/test/org/apache/solr/update/TestInPlaceUpdatesDistrib#delayedReorderingFetchesMissingUpdateFromLeaderTest().mjava","sourceNew":"  private void delayedReorderingFetchesMissingUpdateFromLeaderTest() throws Exception {\n    clearIndex();\n    commit();\n    \n    float inplace_updatable_float = 1F;\n    buildRandomIndex(inplace_updatable_float, Collections.singletonList(1));\n\n    float newinplace_updatable_float = 100F;\n    List<UpdateRequest> updates = new ArrayList<>();\n    updates.add(regularUpdateRequest(\"id\", 1, \"title_s\", \"title1_new\", \"id_i\", 1, \"inplace_updatable_float\", newinplace_updatable_float));\n    updates.add(regularUpdateRequest(\"id\", 1, \"inplace_updatable_float\", map(\"inc\", 1)));\n    updates.add(regularUpdateRequest(\"id\", 1, \"inplace_updatable_float\", map(\"inc\", 1)));\n\n    // The next request to replica2 will be delayed by 6 secs (timeout is 5s)\n    shardToJetty.get(SHARD1).get(1).jetty.getDebugFilter().addDelay(\n        \"Waiting for dependant update to timeout\", 1, 6000);\n\n    ExecutorService threadpool =\n        ExecutorUtil.newMDCAwareFixedThreadPool(updates.size() + 1, new DefaultSolrThreadFactory(getTestName()));\n    for (UpdateRequest update : updates) {\n      AsyncUpdateWithRandomCommit task = new AsyncUpdateWithRandomCommit(update, cloudClient,\n                                                                         random().nextLong());\n      threadpool.submit(task);\n\n      // while we can't guarantee/trust what order the updates are executed in, since multiple threads\n      // are involved, but we're trying to bias the thread scheduling to run them in the order submitted\n      Thread.sleep(100); \n    }\n\n    threadpool.shutdown();\n    assertTrue(\"Thread pool didn't terminate within 10 secs\", threadpool.awaitTermination(10, TimeUnit.SECONDS));\n\n    commit();\n\n    // TODO: Could try checking ZK for LIR flags to ensure LIR has not kicked in\n    // Check every 10ms, 100 times, for a replica to go down (& assert that it doesn't)\n    for (int i=0; i<100; i++) {\n      Thread.sleep(10);\n      cloudClient.getZkStateReader().forceUpdateCollection(DEFAULT_COLLECTION);\n      ClusterState state = cloudClient.getZkStateReader().getClusterState();\n\n      int numActiveReplicas = 0;\n      for (Replica rep: state.getCollection(DEFAULT_COLLECTION).getSlice(SHARD1).getReplicas())\n        if (rep.getState().equals(Replica.State.ACTIVE))\n          numActiveReplicas++;\n\n      assertEquals(\"The replica receiving reordered updates must not have gone down\", 3, numActiveReplicas);\n    }\n\n    for (SolrClient client : clients) {\n      log.info(\"Testing client (Fetch missing test): \" + ((HttpSolrClient)client).getBaseURL());\n      log.info(\"Version at \" + ((HttpSolrClient)client).getBaseURL() + \" is: \" + getReplicaValue(client, 1, \"_version_\"));\n\n      assertReplicaValue(client, 1, \"inplace_updatable_float\", (newinplace_updatable_float + 2.0f), \n          \"inplace_updatable_float didn't match for replica at client: \" + ((HttpSolrClient)client).getBaseURL());\n      assertReplicaValue(client, 1, \"title_s\", \"title1_new\", \n          \"Title didn't match for replica at client: \" + ((HttpSolrClient)client).getBaseURL());\n    }\n    \n    // Try another round of these updates, this time with a delete request at the end.\n    // This is to ensure that the fetch missing update from leader doesn't bomb out if the \n    // document has been deleted on the leader later on\n    {\n      clearIndex();\n      commit();\n      shardToJetty.get(SHARD1).get(1).jetty.getDebugFilter().unsetDelay();\n      \n      updates.add(regularDeleteRequest(1));\n\n      shardToJetty.get(SHARD1).get(1).jetty.getDebugFilter().addDelay(\"Waiting for dependant update to timeout\", 1, 5999); // the first update\n      shardToJetty.get(SHARD1).get(1).jetty.getDebugFilter().addDelay(\"Waiting for dependant update to timeout\", 4, 5998); // the delete update\n\n      threadpool =\n          ExecutorUtil.newMDCAwareFixedThreadPool(updates.size() + 1, new DefaultSolrThreadFactory(getTestName()));\n      for (UpdateRequest update : updates) {\n        AsyncUpdateWithRandomCommit task = new AsyncUpdateWithRandomCommit(update, cloudClient,\n                                                                           random().nextLong());\n        threadpool.submit(task);\n        \n        // while we can't guarantee/trust what order the updates are executed in, since multiple threads\n        // are involved, but we're trying to bias the thread scheduling to run them in the order submitted\n        Thread.sleep(100);\n      }\n\n      threadpool.shutdown();\n      assertTrue(\"Thread pool didn't terminate within 15 secs\", threadpool.awaitTermination(15, TimeUnit.SECONDS));\n\n      commit();\n\n      // TODO: Could try checking ZK for LIR flags to ensure LIR has not kicked in\n      // Check every 10ms, 100 times, for a replica to go down (& assert that it doesn't)\n      ZkController zkController = shardToLeaderJetty.get(SHARD1).jetty.getCoreContainer().getZkController();\n      String lirPath = zkController.getLeaderInitiatedRecoveryZnodePath(DEFAULT_TEST_COLLECTION_NAME, SHARD1);\n      assertFalse (zkController.getZkClient().exists(lirPath, true));\n\n      for (int i=0; i<100; i++) {\n        Thread.sleep(10);\n        cloudClient.getZkStateReader().forceUpdateCollection(DEFAULT_COLLECTION);\n        ClusterState state = cloudClient.getZkStateReader().getClusterState();\n\n        int numActiveReplicas = 0;\n        for (Replica rep: state.getCollection(DEFAULT_COLLECTION).getSlice(SHARD1).getReplicas())\n          if (rep.getState().equals(Replica.State.ACTIVE))\n            numActiveReplicas++;\n\n        assertEquals(\"The replica receiving reordered updates must not have gone down\", 3, numActiveReplicas);\n      }\n\n      for (SolrClient client: new SolrClient[] {LEADER, NONLEADERS.get(0), \n          NONLEADERS.get(1)}) { // nonleader 0 re-ordered replica, nonleader 1 well-ordered replica\n        SolrDocument doc = client.getById(String.valueOf(1), params(\"distrib\", \"false\"));\n        assertNull(\"This doc was supposed to have been deleted, but was: \" + doc, doc);\n      }\n\n    }\n    log.info(\"delayedReorderingFetchesMissingUpdateFromLeaderTest: This test passed fine...\");\n  }\n\n","sourceOld":"  private void delayedReorderingFetchesMissingUpdateFromLeaderTest() throws Exception {\n    del(\"*:*\");\n    commit();\n    \n    float inplace_updatable_float = 1F;\n    buildRandomIndex(inplace_updatable_float, Collections.singletonList(1));\n\n    float newinplace_updatable_float = 100F;\n    List<UpdateRequest> updates = new ArrayList<>();\n    updates.add(regularUpdateRequest(\"id\", 1, \"title_s\", \"title1_new\", \"id_i\", 1, \"inplace_updatable_float\", newinplace_updatable_float));\n    updates.add(regularUpdateRequest(\"id\", 1, \"inplace_updatable_float\", map(\"inc\", 1)));\n    updates.add(regularUpdateRequest(\"id\", 1, \"inplace_updatable_float\", map(\"inc\", 1)));\n\n    // The next request to replica2 will be delayed by 6 secs (timeout is 5s)\n    shardToJetty.get(SHARD1).get(1).jetty.getDebugFilter().addDelay(\n        \"Waiting for dependant update to timeout\", 1, 6000);\n\n    ExecutorService threadpool =\n        ExecutorUtil.newMDCAwareFixedThreadPool(updates.size() + 1, new DefaultSolrThreadFactory(getTestName()));\n    for (UpdateRequest update : updates) {\n      AsyncUpdateWithRandomCommit task = new AsyncUpdateWithRandomCommit(update, cloudClient,\n                                                                         random().nextLong());\n      threadpool.submit(task);\n\n      // while we can't guarantee/trust what order the updates are executed in, since multiple threads\n      // are involved, but we're trying to bias the thread scheduling to run them in the order submitted\n      Thread.sleep(100); \n    }\n\n    threadpool.shutdown();\n    assertTrue(\"Thread pool didn't terminate within 10 secs\", threadpool.awaitTermination(10, TimeUnit.SECONDS));\n\n    commit();\n\n    // TODO: Could try checking ZK for LIR flags to ensure LIR has not kicked in\n    // Check every 10ms, 100 times, for a replica to go down (& assert that it doesn't)\n    for (int i=0; i<100; i++) {\n      Thread.sleep(10);\n      cloudClient.getZkStateReader().forceUpdateCollection(DEFAULT_COLLECTION);\n      ClusterState state = cloudClient.getZkStateReader().getClusterState();\n\n      int numActiveReplicas = 0;\n      for (Replica rep: state.getCollection(DEFAULT_COLLECTION).getSlice(SHARD1).getReplicas())\n        if (rep.getState().equals(Replica.State.ACTIVE))\n          numActiveReplicas++;\n\n      assertEquals(\"The replica receiving reordered updates must not have gone down\", 3, numActiveReplicas);\n    }\n\n    for (SolrClient client : clients) {\n      log.info(\"Testing client (Fetch missing test): \" + ((HttpSolrClient)client).getBaseURL());\n      log.info(\"Version at \" + ((HttpSolrClient)client).getBaseURL() + \" is: \" + getReplicaValue(client, 1, \"_version_\"));\n\n      assertReplicaValue(client, 1, \"inplace_updatable_float\", (newinplace_updatable_float + 2.0f), \n          \"inplace_updatable_float didn't match for replica at client: \" + ((HttpSolrClient)client).getBaseURL());\n      assertReplicaValue(client, 1, \"title_s\", \"title1_new\", \n          \"Title didn't match for replica at client: \" + ((HttpSolrClient)client).getBaseURL());\n    }\n    \n    // Try another round of these updates, this time with a delete request at the end.\n    // This is to ensure that the fetch missing update from leader doesn't bomb out if the \n    // document has been deleted on the leader later on\n    {\n      del(\"*:*\");\n      commit();\n      shardToJetty.get(SHARD1).get(1).jetty.getDebugFilter().unsetDelay();\n      \n      updates.add(regularDeleteRequest(1));\n\n      shardToJetty.get(SHARD1).get(1).jetty.getDebugFilter().addDelay(\"Waiting for dependant update to timeout\", 1, 5999); // the first update\n      shardToJetty.get(SHARD1).get(1).jetty.getDebugFilter().addDelay(\"Waiting for dependant update to timeout\", 4, 5998); // the delete update\n\n      threadpool =\n          ExecutorUtil.newMDCAwareFixedThreadPool(updates.size() + 1, new DefaultSolrThreadFactory(getTestName()));\n      for (UpdateRequest update : updates) {\n        AsyncUpdateWithRandomCommit task = new AsyncUpdateWithRandomCommit(update, cloudClient,\n                                                                           random().nextLong());\n        threadpool.submit(task);\n        \n        // while we can't guarantee/trust what order the updates are executed in, since multiple threads\n        // are involved, but we're trying to bias the thread scheduling to run them in the order submitted\n        Thread.sleep(100);\n      }\n\n      threadpool.shutdown();\n      assertTrue(\"Thread pool didn't terminate within 15 secs\", threadpool.awaitTermination(15, TimeUnit.SECONDS));\n\n      commit();\n\n      // TODO: Could try checking ZK for LIR flags to ensure LIR has not kicked in\n      // Check every 10ms, 100 times, for a replica to go down (& assert that it doesn't)\n      ZkController zkController = shardToLeaderJetty.get(SHARD1).jetty.getCoreContainer().getZkController();\n      String lirPath = zkController.getLeaderInitiatedRecoveryZnodePath(DEFAULT_TEST_COLLECTION_NAME, SHARD1);\n      assertFalse (zkController.getZkClient().exists(lirPath, true));\n\n      for (int i=0; i<100; i++) {\n        Thread.sleep(10);\n        cloudClient.getZkStateReader().forceUpdateCollection(DEFAULT_COLLECTION);\n        ClusterState state = cloudClient.getZkStateReader().getClusterState();\n\n        int numActiveReplicas = 0;\n        for (Replica rep: state.getCollection(DEFAULT_COLLECTION).getSlice(SHARD1).getReplicas())\n          if (rep.getState().equals(Replica.State.ACTIVE))\n            numActiveReplicas++;\n\n        assertEquals(\"The replica receiving reordered updates must not have gone down\", 3, numActiveReplicas);\n      }\n\n      for (SolrClient client: new SolrClient[] {LEADER, NONLEADERS.get(0), \n          NONLEADERS.get(1)}) { // nonleader 0 re-ordered replica, nonleader 1 well-ordered replica\n        SolrDocument doc = client.getById(String.valueOf(1), params(\"distrib\", \"false\"));\n        assertNull(\"This doc was supposed to have been deleted, but was: \" + doc, doc);\n      }\n\n    }\n    log.info(\"delayedReorderingFetchesMissingUpdateFromLeaderTest: This test passed fine...\");\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"5d7c1fb576b8c66316bde8f8a5309353434da7f3","date":1488254129,"type":3,"author":"markrmiller","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/update/TestInPlaceUpdatesDistrib#delayedReorderingFetchesMissingUpdateFromLeaderTest().mjava","pathOld":"solr/core/src/test/org/apache/solr/update/TestInPlaceUpdatesDistrib#delayedReorderingFetchesMissingUpdateFromLeaderTest().mjava","sourceNew":"  private void delayedReorderingFetchesMissingUpdateFromLeaderTest() throws Exception {\n    clearIndex();\n    commit();\n    \n    float inplace_updatable_float = 1F;\n    buildRandomIndex(inplace_updatable_float, Collections.singletonList(1));\n\n    float newinplace_updatable_float = 100F;\n    List<UpdateRequest> updates = new ArrayList<>();\n    updates.add(regularUpdateRequest(\"id\", 1, \"title_s\", \"title1_new\", \"id_i\", 1, \"inplace_updatable_float\", newinplace_updatable_float));\n    updates.add(regularUpdateRequest(\"id\", 1, \"inplace_updatable_float\", map(\"inc\", 1)));\n    updates.add(regularUpdateRequest(\"id\", 1, \"inplace_updatable_float\", map(\"inc\", 1)));\n\n    // The next request to replica2 will be delayed by 6 secs (timeout is 5s)\n    shardToJetty.get(SHARD1).get(1).jetty.getDebugFilter().addDelay(\n        \"Waiting for dependant update to timeout\", 1, 6000);\n\n    ExecutorService threadpool =\n        ExecutorUtil.newMDCAwareFixedThreadPool(updates.size() + 1, new DefaultSolrThreadFactory(getTestName()));\n    for (UpdateRequest update : updates) {\n      AsyncUpdateWithRandomCommit task = new AsyncUpdateWithRandomCommit(update, cloudClient,\n                                                                         random().nextLong());\n      threadpool.submit(task);\n\n      // while we can't guarantee/trust what order the updates are executed in, since multiple threads\n      // are involved, but we're trying to bias the thread scheduling to run them in the order submitted\n      Thread.sleep(100); \n    }\n\n    threadpool.shutdown();\n    assertTrue(\"Thread pool didn't terminate within 10 secs\", threadpool.awaitTermination(15, TimeUnit.SECONDS));\n\n    commit();\n\n    // TODO: Could try checking ZK for LIR flags to ensure LIR has not kicked in\n    // Check every 10ms, 100 times, for a replica to go down (& assert that it doesn't)\n    for (int i=0; i<100; i++) {\n      Thread.sleep(10);\n      cloudClient.getZkStateReader().forceUpdateCollection(DEFAULT_COLLECTION);\n      ClusterState state = cloudClient.getZkStateReader().getClusterState();\n\n      int numActiveReplicas = 0;\n      for (Replica rep: state.getCollection(DEFAULT_COLLECTION).getSlice(SHARD1).getReplicas())\n        if (rep.getState().equals(Replica.State.ACTIVE))\n          numActiveReplicas++;\n\n      assertEquals(\"The replica receiving reordered updates must not have gone down\", 3, numActiveReplicas);\n    }\n\n    for (SolrClient client : clients) {\n      log.info(\"Testing client (Fetch missing test): \" + ((HttpSolrClient)client).getBaseURL());\n      log.info(\"Version at \" + ((HttpSolrClient)client).getBaseURL() + \" is: \" + getReplicaValue(client, 1, \"_version_\"));\n\n      assertReplicaValue(client, 1, \"inplace_updatable_float\", (newinplace_updatable_float + 2.0f), \n          \"inplace_updatable_float didn't match for replica at client: \" + ((HttpSolrClient)client).getBaseURL());\n      assertReplicaValue(client, 1, \"title_s\", \"title1_new\", \n          \"Title didn't match for replica at client: \" + ((HttpSolrClient)client).getBaseURL());\n    }\n    \n    // Try another round of these updates, this time with a delete request at the end.\n    // This is to ensure that the fetch missing update from leader doesn't bomb out if the \n    // document has been deleted on the leader later on\n    {\n      clearIndex();\n      commit();\n      shardToJetty.get(SHARD1).get(1).jetty.getDebugFilter().unsetDelay();\n      \n      updates.add(regularDeleteRequest(1));\n\n      shardToJetty.get(SHARD1).get(1).jetty.getDebugFilter().addDelay(\"Waiting for dependant update to timeout\", 1, 5999); // the first update\n      shardToJetty.get(SHARD1).get(1).jetty.getDebugFilter().addDelay(\"Waiting for dependant update to timeout\", 4, 5998); // the delete update\n\n      threadpool =\n          ExecutorUtil.newMDCAwareFixedThreadPool(updates.size() + 1, new DefaultSolrThreadFactory(getTestName()));\n      for (UpdateRequest update : updates) {\n        AsyncUpdateWithRandomCommit task = new AsyncUpdateWithRandomCommit(update, cloudClient,\n                                                                           random().nextLong());\n        threadpool.submit(task);\n        \n        // while we can't guarantee/trust what order the updates are executed in, since multiple threads\n        // are involved, but we're trying to bias the thread scheduling to run them in the order submitted\n        Thread.sleep(100);\n      }\n\n      threadpool.shutdown();\n      assertTrue(\"Thread pool didn't terminate within 15 secs\", threadpool.awaitTermination(15, TimeUnit.SECONDS));\n\n      commit();\n\n      // TODO: Could try checking ZK for LIR flags to ensure LIR has not kicked in\n      // Check every 10ms, 100 times, for a replica to go down (& assert that it doesn't)\n      ZkController zkController = shardToLeaderJetty.get(SHARD1).jetty.getCoreContainer().getZkController();\n      String lirPath = zkController.getLeaderInitiatedRecoveryZnodePath(DEFAULT_TEST_COLLECTION_NAME, SHARD1);\n      assertFalse (zkController.getZkClient().exists(lirPath, true));\n\n      for (int i=0; i<100; i++) {\n        Thread.sleep(10);\n        cloudClient.getZkStateReader().forceUpdateCollection(DEFAULT_COLLECTION);\n        ClusterState state = cloudClient.getZkStateReader().getClusterState();\n\n        int numActiveReplicas = 0;\n        for (Replica rep: state.getCollection(DEFAULT_COLLECTION).getSlice(SHARD1).getReplicas())\n          if (rep.getState().equals(Replica.State.ACTIVE))\n            numActiveReplicas++;\n\n        assertEquals(\"The replica receiving reordered updates must not have gone down\", 3, numActiveReplicas);\n      }\n\n      for (SolrClient client: new SolrClient[] {LEADER, NONLEADERS.get(0), \n          NONLEADERS.get(1)}) { // nonleader 0 re-ordered replica, nonleader 1 well-ordered replica\n        SolrDocument doc = client.getById(String.valueOf(1), params(\"distrib\", \"false\"));\n        assertNull(\"This doc was supposed to have been deleted, but was: \" + doc, doc);\n      }\n\n    }\n    log.info(\"delayedReorderingFetchesMissingUpdateFromLeaderTest: This test passed fine...\");\n  }\n\n","sourceOld":"  private void delayedReorderingFetchesMissingUpdateFromLeaderTest() throws Exception {\n    clearIndex();\n    commit();\n    \n    float inplace_updatable_float = 1F;\n    buildRandomIndex(inplace_updatable_float, Collections.singletonList(1));\n\n    float newinplace_updatable_float = 100F;\n    List<UpdateRequest> updates = new ArrayList<>();\n    updates.add(regularUpdateRequest(\"id\", 1, \"title_s\", \"title1_new\", \"id_i\", 1, \"inplace_updatable_float\", newinplace_updatable_float));\n    updates.add(regularUpdateRequest(\"id\", 1, \"inplace_updatable_float\", map(\"inc\", 1)));\n    updates.add(regularUpdateRequest(\"id\", 1, \"inplace_updatable_float\", map(\"inc\", 1)));\n\n    // The next request to replica2 will be delayed by 6 secs (timeout is 5s)\n    shardToJetty.get(SHARD1).get(1).jetty.getDebugFilter().addDelay(\n        \"Waiting for dependant update to timeout\", 1, 6000);\n\n    ExecutorService threadpool =\n        ExecutorUtil.newMDCAwareFixedThreadPool(updates.size() + 1, new DefaultSolrThreadFactory(getTestName()));\n    for (UpdateRequest update : updates) {\n      AsyncUpdateWithRandomCommit task = new AsyncUpdateWithRandomCommit(update, cloudClient,\n                                                                         random().nextLong());\n      threadpool.submit(task);\n\n      // while we can't guarantee/trust what order the updates are executed in, since multiple threads\n      // are involved, but we're trying to bias the thread scheduling to run them in the order submitted\n      Thread.sleep(100); \n    }\n\n    threadpool.shutdown();\n    assertTrue(\"Thread pool didn't terminate within 10 secs\", threadpool.awaitTermination(10, TimeUnit.SECONDS));\n\n    commit();\n\n    // TODO: Could try checking ZK for LIR flags to ensure LIR has not kicked in\n    // Check every 10ms, 100 times, for a replica to go down (& assert that it doesn't)\n    for (int i=0; i<100; i++) {\n      Thread.sleep(10);\n      cloudClient.getZkStateReader().forceUpdateCollection(DEFAULT_COLLECTION);\n      ClusterState state = cloudClient.getZkStateReader().getClusterState();\n\n      int numActiveReplicas = 0;\n      for (Replica rep: state.getCollection(DEFAULT_COLLECTION).getSlice(SHARD1).getReplicas())\n        if (rep.getState().equals(Replica.State.ACTIVE))\n          numActiveReplicas++;\n\n      assertEquals(\"The replica receiving reordered updates must not have gone down\", 3, numActiveReplicas);\n    }\n\n    for (SolrClient client : clients) {\n      log.info(\"Testing client (Fetch missing test): \" + ((HttpSolrClient)client).getBaseURL());\n      log.info(\"Version at \" + ((HttpSolrClient)client).getBaseURL() + \" is: \" + getReplicaValue(client, 1, \"_version_\"));\n\n      assertReplicaValue(client, 1, \"inplace_updatable_float\", (newinplace_updatable_float + 2.0f), \n          \"inplace_updatable_float didn't match for replica at client: \" + ((HttpSolrClient)client).getBaseURL());\n      assertReplicaValue(client, 1, \"title_s\", \"title1_new\", \n          \"Title didn't match for replica at client: \" + ((HttpSolrClient)client).getBaseURL());\n    }\n    \n    // Try another round of these updates, this time with a delete request at the end.\n    // This is to ensure that the fetch missing update from leader doesn't bomb out if the \n    // document has been deleted on the leader later on\n    {\n      clearIndex();\n      commit();\n      shardToJetty.get(SHARD1).get(1).jetty.getDebugFilter().unsetDelay();\n      \n      updates.add(regularDeleteRequest(1));\n\n      shardToJetty.get(SHARD1).get(1).jetty.getDebugFilter().addDelay(\"Waiting for dependant update to timeout\", 1, 5999); // the first update\n      shardToJetty.get(SHARD1).get(1).jetty.getDebugFilter().addDelay(\"Waiting for dependant update to timeout\", 4, 5998); // the delete update\n\n      threadpool =\n          ExecutorUtil.newMDCAwareFixedThreadPool(updates.size() + 1, new DefaultSolrThreadFactory(getTestName()));\n      for (UpdateRequest update : updates) {\n        AsyncUpdateWithRandomCommit task = new AsyncUpdateWithRandomCommit(update, cloudClient,\n                                                                           random().nextLong());\n        threadpool.submit(task);\n        \n        // while we can't guarantee/trust what order the updates are executed in, since multiple threads\n        // are involved, but we're trying to bias the thread scheduling to run them in the order submitted\n        Thread.sleep(100);\n      }\n\n      threadpool.shutdown();\n      assertTrue(\"Thread pool didn't terminate within 15 secs\", threadpool.awaitTermination(15, TimeUnit.SECONDS));\n\n      commit();\n\n      // TODO: Could try checking ZK for LIR flags to ensure LIR has not kicked in\n      // Check every 10ms, 100 times, for a replica to go down (& assert that it doesn't)\n      ZkController zkController = shardToLeaderJetty.get(SHARD1).jetty.getCoreContainer().getZkController();\n      String lirPath = zkController.getLeaderInitiatedRecoveryZnodePath(DEFAULT_TEST_COLLECTION_NAME, SHARD1);\n      assertFalse (zkController.getZkClient().exists(lirPath, true));\n\n      for (int i=0; i<100; i++) {\n        Thread.sleep(10);\n        cloudClient.getZkStateReader().forceUpdateCollection(DEFAULT_COLLECTION);\n        ClusterState state = cloudClient.getZkStateReader().getClusterState();\n\n        int numActiveReplicas = 0;\n        for (Replica rep: state.getCollection(DEFAULT_COLLECTION).getSlice(SHARD1).getReplicas())\n          if (rep.getState().equals(Replica.State.ACTIVE))\n            numActiveReplicas++;\n\n        assertEquals(\"The replica receiving reordered updates must not have gone down\", 3, numActiveReplicas);\n      }\n\n      for (SolrClient client: new SolrClient[] {LEADER, NONLEADERS.get(0), \n          NONLEADERS.get(1)}) { // nonleader 0 re-ordered replica, nonleader 1 well-ordered replica\n        SolrDocument doc = client.getById(String.valueOf(1), params(\"distrib\", \"false\"));\n        assertNull(\"This doc was supposed to have been deleted, but was: \" + doc, doc);\n      }\n\n    }\n    log.info(\"delayedReorderingFetchesMissingUpdateFromLeaderTest: This test passed fine...\");\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"2e11e54ce6015434b2aaadb49ca5071dbe7be50c","date":1489404389,"type":3,"author":"Ishan Chattopadhyaya","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/update/TestInPlaceUpdatesDistrib#delayedReorderingFetchesMissingUpdateFromLeaderTest().mjava","pathOld":"solr/core/src/test/org/apache/solr/update/TestInPlaceUpdatesDistrib#delayedReorderingFetchesMissingUpdateFromLeaderTest().mjava","sourceNew":"  private void delayedReorderingFetchesMissingUpdateFromLeaderTest() throws Exception {\n    clearIndex();\n    commit();\n    \n    float inplace_updatable_float = 1F;\n    buildRandomIndex(inplace_updatable_float, Collections.singletonList(1));\n\n    float newinplace_updatable_float = 100F;\n    List<UpdateRequest> updates = new ArrayList<>();\n    updates.add(regularUpdateRequest(\"id\", 1, \"title_s\", \"title1_new\", \"id_i\", 1, \"inplace_updatable_float\", newinplace_updatable_float));\n    updates.add(regularUpdateRequest(\"id\", 1, \"inplace_updatable_float\", map(\"inc\", 1)));\n    updates.add(regularUpdateRequest(\"id\", 1, \"inplace_updatable_float\", map(\"inc\", 1)));\n\n    // The next request to replica2 will be delayed by 6 secs (timeout is 5s)\n    shardToJetty.get(SHARD1).get(1).jetty.getDebugFilter().addDelay(\n        \"Waiting for dependant update to timeout\", 1, 6000);\n\n    ExecutorService threadpool =\n        ExecutorUtil.newMDCAwareFixedThreadPool(updates.size() + 1, new DefaultSolrThreadFactory(getTestName()));\n    for (UpdateRequest update : updates) {\n      AsyncUpdateWithRandomCommit task = new AsyncUpdateWithRandomCommit(update, cloudClient,\n                                                                         random().nextLong());\n      threadpool.submit(task);\n\n      // while we can't guarantee/trust what order the updates are executed in, since multiple threads\n      // are involved, but we're trying to bias the thread scheduling to run them in the order submitted\n      Thread.sleep(100); \n    }\n\n    threadpool.shutdown();\n    assertTrue(\"Thread pool didn't terminate within 15 secs\", threadpool.awaitTermination(15, TimeUnit.SECONDS));\n\n    commit();\n\n    // TODO: Could try checking ZK for LIR flags to ensure LIR has not kicked in\n    // Check every 10ms, 100 times, for a replica to go down (& assert that it doesn't)\n    for (int i=0; i<100; i++) {\n      Thread.sleep(10);\n      cloudClient.getZkStateReader().forceUpdateCollection(DEFAULT_COLLECTION);\n      ClusterState state = cloudClient.getZkStateReader().getClusterState();\n\n      int numActiveReplicas = 0;\n      for (Replica rep: state.getCollection(DEFAULT_COLLECTION).getSlice(SHARD1).getReplicas())\n        if (rep.getState().equals(Replica.State.ACTIVE))\n          numActiveReplicas++;\n\n      assertEquals(\"The replica receiving reordered updates must not have gone down\", 3, numActiveReplicas);\n    }\n\n    for (SolrClient client : clients) {\n      log.info(\"Testing client (Fetch missing test): \" + ((HttpSolrClient)client).getBaseURL());\n      log.info(\"Version at \" + ((HttpSolrClient)client).getBaseURL() + \" is: \" + getReplicaValue(client, 1, \"_version_\"));\n\n      assertReplicaValue(client, 1, \"inplace_updatable_float\", (newinplace_updatable_float + 2.0f), \n          \"inplace_updatable_float didn't match for replica at client: \" + ((HttpSolrClient)client).getBaseURL());\n      assertReplicaValue(client, 1, \"title_s\", \"title1_new\", \n          \"Title didn't match for replica at client: \" + ((HttpSolrClient)client).getBaseURL());\n    }\n    \n    // Try another round of these updates, this time with a delete request at the end.\n    // This is to ensure that the fetch missing update from leader doesn't bomb out if the \n    // document has been deleted on the leader later on\n    {\n      clearIndex();\n      commit();\n      shardToJetty.get(SHARD1).get(1).jetty.getDebugFilter().unsetDelay();\n      \n      updates.add(regularDeleteRequest(1));\n\n      shardToJetty.get(SHARD1).get(1).jetty.getDebugFilter().addDelay(\"Waiting for dependant update to timeout\", 1, 5999); // the first update\n      shardToJetty.get(SHARD1).get(1).jetty.getDebugFilter().addDelay(\"Waiting for dependant update to timeout\", 4, 5998); // the delete update\n\n      threadpool =\n          ExecutorUtil.newMDCAwareFixedThreadPool(updates.size() + 1, new DefaultSolrThreadFactory(getTestName()));\n      for (UpdateRequest update : updates) {\n        AsyncUpdateWithRandomCommit task = new AsyncUpdateWithRandomCommit(update, cloudClient,\n                                                                           random().nextLong());\n        threadpool.submit(task);\n        \n        // while we can't guarantee/trust what order the updates are executed in, since multiple threads\n        // are involved, but we're trying to bias the thread scheduling to run them in the order submitted\n        Thread.sleep(100);\n      }\n\n      threadpool.shutdown();\n      assertTrue(\"Thread pool didn't terminate within 15 secs\", threadpool.awaitTermination(15, TimeUnit.SECONDS));\n\n      commit();\n\n      // TODO: Could try checking ZK for LIR flags to ensure LIR has not kicked in\n      // Check every 10ms, 100 times, for a replica to go down (& assert that it doesn't)\n      ZkController zkController = shardToLeaderJetty.get(SHARD1).jetty.getCoreContainer().getZkController();\n      String lirPath = zkController.getLeaderInitiatedRecoveryZnodePath(DEFAULT_TEST_COLLECTION_NAME, SHARD1);\n      assertFalse (zkController.getZkClient().exists(lirPath, true));\n\n      for (int i=0; i<100; i++) {\n        Thread.sleep(10);\n        cloudClient.getZkStateReader().forceUpdateCollection(DEFAULT_COLLECTION);\n        ClusterState state = cloudClient.getZkStateReader().getClusterState();\n\n        int numActiveReplicas = 0;\n        for (Replica rep: state.getCollection(DEFAULT_COLLECTION).getSlice(SHARD1).getReplicas())\n          if (rep.getState().equals(Replica.State.ACTIVE))\n            numActiveReplicas++;\n\n        assertEquals(\"The replica receiving reordered updates must not have gone down\", 3, numActiveReplicas);\n      }\n\n      for (SolrClient client: new SolrClient[] {LEADER, NONLEADERS.get(0), \n          NONLEADERS.get(1)}) { // nonleader 0 re-ordered replica, nonleader 1 well-ordered replica\n        SolrDocument doc = client.getById(String.valueOf(1), params(\"distrib\", \"false\"));\n        assertNull(\"This doc was supposed to have been deleted, but was: \" + doc, doc);\n      }\n\n    }\n    log.info(\"delayedReorderingFetchesMissingUpdateFromLeaderTest: This test passed fine...\");\n  }\n\n","sourceOld":"  private void delayedReorderingFetchesMissingUpdateFromLeaderTest() throws Exception {\n    clearIndex();\n    commit();\n    \n    float inplace_updatable_float = 1F;\n    buildRandomIndex(inplace_updatable_float, Collections.singletonList(1));\n\n    float newinplace_updatable_float = 100F;\n    List<UpdateRequest> updates = new ArrayList<>();\n    updates.add(regularUpdateRequest(\"id\", 1, \"title_s\", \"title1_new\", \"id_i\", 1, \"inplace_updatable_float\", newinplace_updatable_float));\n    updates.add(regularUpdateRequest(\"id\", 1, \"inplace_updatable_float\", map(\"inc\", 1)));\n    updates.add(regularUpdateRequest(\"id\", 1, \"inplace_updatable_float\", map(\"inc\", 1)));\n\n    // The next request to replica2 will be delayed by 6 secs (timeout is 5s)\n    shardToJetty.get(SHARD1).get(1).jetty.getDebugFilter().addDelay(\n        \"Waiting for dependant update to timeout\", 1, 6000);\n\n    ExecutorService threadpool =\n        ExecutorUtil.newMDCAwareFixedThreadPool(updates.size() + 1, new DefaultSolrThreadFactory(getTestName()));\n    for (UpdateRequest update : updates) {\n      AsyncUpdateWithRandomCommit task = new AsyncUpdateWithRandomCommit(update, cloudClient,\n                                                                         random().nextLong());\n      threadpool.submit(task);\n\n      // while we can't guarantee/trust what order the updates are executed in, since multiple threads\n      // are involved, but we're trying to bias the thread scheduling to run them in the order submitted\n      Thread.sleep(100); \n    }\n\n    threadpool.shutdown();\n    assertTrue(\"Thread pool didn't terminate within 10 secs\", threadpool.awaitTermination(15, TimeUnit.SECONDS));\n\n    commit();\n\n    // TODO: Could try checking ZK for LIR flags to ensure LIR has not kicked in\n    // Check every 10ms, 100 times, for a replica to go down (& assert that it doesn't)\n    for (int i=0; i<100; i++) {\n      Thread.sleep(10);\n      cloudClient.getZkStateReader().forceUpdateCollection(DEFAULT_COLLECTION);\n      ClusterState state = cloudClient.getZkStateReader().getClusterState();\n\n      int numActiveReplicas = 0;\n      for (Replica rep: state.getCollection(DEFAULT_COLLECTION).getSlice(SHARD1).getReplicas())\n        if (rep.getState().equals(Replica.State.ACTIVE))\n          numActiveReplicas++;\n\n      assertEquals(\"The replica receiving reordered updates must not have gone down\", 3, numActiveReplicas);\n    }\n\n    for (SolrClient client : clients) {\n      log.info(\"Testing client (Fetch missing test): \" + ((HttpSolrClient)client).getBaseURL());\n      log.info(\"Version at \" + ((HttpSolrClient)client).getBaseURL() + \" is: \" + getReplicaValue(client, 1, \"_version_\"));\n\n      assertReplicaValue(client, 1, \"inplace_updatable_float\", (newinplace_updatable_float + 2.0f), \n          \"inplace_updatable_float didn't match for replica at client: \" + ((HttpSolrClient)client).getBaseURL());\n      assertReplicaValue(client, 1, \"title_s\", \"title1_new\", \n          \"Title didn't match for replica at client: \" + ((HttpSolrClient)client).getBaseURL());\n    }\n    \n    // Try another round of these updates, this time with a delete request at the end.\n    // This is to ensure that the fetch missing update from leader doesn't bomb out if the \n    // document has been deleted on the leader later on\n    {\n      clearIndex();\n      commit();\n      shardToJetty.get(SHARD1).get(1).jetty.getDebugFilter().unsetDelay();\n      \n      updates.add(regularDeleteRequest(1));\n\n      shardToJetty.get(SHARD1).get(1).jetty.getDebugFilter().addDelay(\"Waiting for dependant update to timeout\", 1, 5999); // the first update\n      shardToJetty.get(SHARD1).get(1).jetty.getDebugFilter().addDelay(\"Waiting for dependant update to timeout\", 4, 5998); // the delete update\n\n      threadpool =\n          ExecutorUtil.newMDCAwareFixedThreadPool(updates.size() + 1, new DefaultSolrThreadFactory(getTestName()));\n      for (UpdateRequest update : updates) {\n        AsyncUpdateWithRandomCommit task = new AsyncUpdateWithRandomCommit(update, cloudClient,\n                                                                           random().nextLong());\n        threadpool.submit(task);\n        \n        // while we can't guarantee/trust what order the updates are executed in, since multiple threads\n        // are involved, but we're trying to bias the thread scheduling to run them in the order submitted\n        Thread.sleep(100);\n      }\n\n      threadpool.shutdown();\n      assertTrue(\"Thread pool didn't terminate within 15 secs\", threadpool.awaitTermination(15, TimeUnit.SECONDS));\n\n      commit();\n\n      // TODO: Could try checking ZK for LIR flags to ensure LIR has not kicked in\n      // Check every 10ms, 100 times, for a replica to go down (& assert that it doesn't)\n      ZkController zkController = shardToLeaderJetty.get(SHARD1).jetty.getCoreContainer().getZkController();\n      String lirPath = zkController.getLeaderInitiatedRecoveryZnodePath(DEFAULT_TEST_COLLECTION_NAME, SHARD1);\n      assertFalse (zkController.getZkClient().exists(lirPath, true));\n\n      for (int i=0; i<100; i++) {\n        Thread.sleep(10);\n        cloudClient.getZkStateReader().forceUpdateCollection(DEFAULT_COLLECTION);\n        ClusterState state = cloudClient.getZkStateReader().getClusterState();\n\n        int numActiveReplicas = 0;\n        for (Replica rep: state.getCollection(DEFAULT_COLLECTION).getSlice(SHARD1).getReplicas())\n          if (rep.getState().equals(Replica.State.ACTIVE))\n            numActiveReplicas++;\n\n        assertEquals(\"The replica receiving reordered updates must not have gone down\", 3, numActiveReplicas);\n      }\n\n      for (SolrClient client: new SolrClient[] {LEADER, NONLEADERS.get(0), \n          NONLEADERS.get(1)}) { // nonleader 0 re-ordered replica, nonleader 1 well-ordered replica\n        SolrDocument doc = client.getById(String.valueOf(1), params(\"distrib\", \"false\"));\n        assertNull(\"This doc was supposed to have been deleted, but was: \" + doc, doc);\n      }\n\n    }\n    log.info(\"delayedReorderingFetchesMissingUpdateFromLeaderTest: This test passed fine...\");\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"84f20f331d8001864545c7021812d8c6509c7593","date":1517216128,"type":3,"author":"Cao Manh Dat","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/update/TestInPlaceUpdatesDistrib#delayedReorderingFetchesMissingUpdateFromLeaderTest().mjava","pathOld":"solr/core/src/test/org/apache/solr/update/TestInPlaceUpdatesDistrib#delayedReorderingFetchesMissingUpdateFromLeaderTest().mjava","sourceNew":"  private void delayedReorderingFetchesMissingUpdateFromLeaderTest() throws Exception {\n    clearIndex();\n    commit();\n    \n    float inplace_updatable_float = 1F;\n    buildRandomIndex(inplace_updatable_float, Collections.singletonList(1));\n\n    float newinplace_updatable_float = 100F;\n    List<UpdateRequest> updates = new ArrayList<>();\n    updates.add(regularUpdateRequest(\"id\", 1, \"title_s\", \"title1_new\", \"id_i\", 1, \"inplace_updatable_float\", newinplace_updatable_float));\n    updates.add(regularUpdateRequest(\"id\", 1, \"inplace_updatable_float\", map(\"inc\", 1)));\n    updates.add(regularUpdateRequest(\"id\", 1, \"inplace_updatable_float\", map(\"inc\", 1)));\n\n    // The next request to replica2 will be delayed by 6 secs (timeout is 5s)\n    shardToJetty.get(SHARD1).get(1).jetty.getDebugFilter().addDelay(\n        \"Waiting for dependant update to timeout\", 1, 6000);\n\n    ExecutorService threadpool =\n        ExecutorUtil.newMDCAwareFixedThreadPool(updates.size() + 1, new DefaultSolrThreadFactory(getTestName()));\n    for (UpdateRequest update : updates) {\n      AsyncUpdateWithRandomCommit task = new AsyncUpdateWithRandomCommit(update, cloudClient,\n                                                                         random().nextLong());\n      threadpool.submit(task);\n\n      // while we can't guarantee/trust what order the updates are executed in, since multiple threads\n      // are involved, but we're trying to bias the thread scheduling to run them in the order submitted\n      Thread.sleep(100); \n    }\n\n    threadpool.shutdown();\n    assertTrue(\"Thread pool didn't terminate within 15 secs\", threadpool.awaitTermination(15, TimeUnit.SECONDS));\n\n    commit();\n\n    // TODO: Could try checking ZK for LIR flags to ensure LIR has not kicked in\n    // Check every 10ms, 100 times, for a replica to go down (& assert that it doesn't)\n    for (int i=0; i<100; i++) {\n      Thread.sleep(10);\n      cloudClient.getZkStateReader().forceUpdateCollection(DEFAULT_COLLECTION);\n      ClusterState state = cloudClient.getZkStateReader().getClusterState();\n\n      int numActiveReplicas = 0;\n      for (Replica rep: state.getCollection(DEFAULT_COLLECTION).getSlice(SHARD1).getReplicas())\n        if (rep.getState().equals(Replica.State.ACTIVE))\n          numActiveReplicas++;\n\n      assertEquals(\"The replica receiving reordered updates must not have gone down\", 3, numActiveReplicas);\n    }\n\n    for (SolrClient client : clients) {\n      log.info(\"Testing client (Fetch missing test): \" + ((HttpSolrClient)client).getBaseURL());\n      log.info(\"Version at \" + ((HttpSolrClient)client).getBaseURL() + \" is: \" + getReplicaValue(client, 1, \"_version_\"));\n\n      assertReplicaValue(client, 1, \"inplace_updatable_float\", (newinplace_updatable_float + 2.0f), \n          \"inplace_updatable_float didn't match for replica at client: \" + ((HttpSolrClient)client).getBaseURL());\n      assertReplicaValue(client, 1, \"title_s\", \"title1_new\", \n          \"Title didn't match for replica at client: \" + ((HttpSolrClient)client).getBaseURL());\n    }\n    \n    // Try another round of these updates, this time with a delete request at the end.\n    // This is to ensure that the fetch missing update from leader doesn't bomb out if the \n    // document has been deleted on the leader later on\n    {\n      clearIndex();\n      commit();\n      shardToJetty.get(SHARD1).get(1).jetty.getDebugFilter().unsetDelay();\n      \n      updates.add(regularDeleteRequest(1));\n\n      shardToJetty.get(SHARD1).get(1).jetty.getDebugFilter().addDelay(\"Waiting for dependant update to timeout\", 1, 5999); // the first update\n      shardToJetty.get(SHARD1).get(1).jetty.getDebugFilter().addDelay(\"Waiting for dependant update to timeout\", 4, 5998); // the delete update\n\n      threadpool =\n          ExecutorUtil.newMDCAwareFixedThreadPool(updates.size() + 1, new DefaultSolrThreadFactory(getTestName()));\n      for (UpdateRequest update : updates) {\n        AsyncUpdateWithRandomCommit task = new AsyncUpdateWithRandomCommit(update, cloudClient,\n                                                                           random().nextLong());\n        threadpool.submit(task);\n        \n        // while we can't guarantee/trust what order the updates are executed in, since multiple threads\n        // are involved, but we're trying to bias the thread scheduling to run them in the order submitted\n        Thread.sleep(100);\n      }\n\n      threadpool.shutdown();\n      assertTrue(\"Thread pool didn't terminate within 15 secs\", threadpool.awaitTermination(15, TimeUnit.SECONDS));\n\n      commit();\n\n      try (ZkShardTerms zkShardTerms = new ZkShardTerms(DEFAULT_COLLECTION, SHARD1, cloudClient.getZkStateReader().getZkClient())) {\n        for (int i=0; i<100; i++) {\n          Thread.sleep(10);\n          cloudClient.getZkStateReader().forceUpdateCollection(DEFAULT_COLLECTION);\n          ClusterState state = cloudClient.getZkStateReader().getClusterState();\n\n          int numActiveReplicas = 0;\n          for (Replica rep: state.getCollection(DEFAULT_COLLECTION).getSlice(SHARD1).getReplicas()) {\n            assertTrue(zkShardTerms.canBecomeLeader(rep.getName()));\n            if (rep.getState().equals(Replica.State.ACTIVE))\n              numActiveReplicas++;\n          }\n          assertEquals(\"The replica receiving reordered updates must not have gone down\", 3, numActiveReplicas);\n        }\n      }\n\n      for (SolrClient client: new SolrClient[] {LEADER, NONLEADERS.get(0), \n          NONLEADERS.get(1)}) { // nonleader 0 re-ordered replica, nonleader 1 well-ordered replica\n        SolrDocument doc = client.getById(String.valueOf(1), params(\"distrib\", \"false\"));\n        assertNull(\"This doc was supposed to have been deleted, but was: \" + doc, doc);\n      }\n\n    }\n    log.info(\"delayedReorderingFetchesMissingUpdateFromLeaderTest: This test passed fine...\");\n  }\n\n","sourceOld":"  private void delayedReorderingFetchesMissingUpdateFromLeaderTest() throws Exception {\n    clearIndex();\n    commit();\n    \n    float inplace_updatable_float = 1F;\n    buildRandomIndex(inplace_updatable_float, Collections.singletonList(1));\n\n    float newinplace_updatable_float = 100F;\n    List<UpdateRequest> updates = new ArrayList<>();\n    updates.add(regularUpdateRequest(\"id\", 1, \"title_s\", \"title1_new\", \"id_i\", 1, \"inplace_updatable_float\", newinplace_updatable_float));\n    updates.add(regularUpdateRequest(\"id\", 1, \"inplace_updatable_float\", map(\"inc\", 1)));\n    updates.add(regularUpdateRequest(\"id\", 1, \"inplace_updatable_float\", map(\"inc\", 1)));\n\n    // The next request to replica2 will be delayed by 6 secs (timeout is 5s)\n    shardToJetty.get(SHARD1).get(1).jetty.getDebugFilter().addDelay(\n        \"Waiting for dependant update to timeout\", 1, 6000);\n\n    ExecutorService threadpool =\n        ExecutorUtil.newMDCAwareFixedThreadPool(updates.size() + 1, new DefaultSolrThreadFactory(getTestName()));\n    for (UpdateRequest update : updates) {\n      AsyncUpdateWithRandomCommit task = new AsyncUpdateWithRandomCommit(update, cloudClient,\n                                                                         random().nextLong());\n      threadpool.submit(task);\n\n      // while we can't guarantee/trust what order the updates are executed in, since multiple threads\n      // are involved, but we're trying to bias the thread scheduling to run them in the order submitted\n      Thread.sleep(100); \n    }\n\n    threadpool.shutdown();\n    assertTrue(\"Thread pool didn't terminate within 15 secs\", threadpool.awaitTermination(15, TimeUnit.SECONDS));\n\n    commit();\n\n    // TODO: Could try checking ZK for LIR flags to ensure LIR has not kicked in\n    // Check every 10ms, 100 times, for a replica to go down (& assert that it doesn't)\n    for (int i=0; i<100; i++) {\n      Thread.sleep(10);\n      cloudClient.getZkStateReader().forceUpdateCollection(DEFAULT_COLLECTION);\n      ClusterState state = cloudClient.getZkStateReader().getClusterState();\n\n      int numActiveReplicas = 0;\n      for (Replica rep: state.getCollection(DEFAULT_COLLECTION).getSlice(SHARD1).getReplicas())\n        if (rep.getState().equals(Replica.State.ACTIVE))\n          numActiveReplicas++;\n\n      assertEquals(\"The replica receiving reordered updates must not have gone down\", 3, numActiveReplicas);\n    }\n\n    for (SolrClient client : clients) {\n      log.info(\"Testing client (Fetch missing test): \" + ((HttpSolrClient)client).getBaseURL());\n      log.info(\"Version at \" + ((HttpSolrClient)client).getBaseURL() + \" is: \" + getReplicaValue(client, 1, \"_version_\"));\n\n      assertReplicaValue(client, 1, \"inplace_updatable_float\", (newinplace_updatable_float + 2.0f), \n          \"inplace_updatable_float didn't match for replica at client: \" + ((HttpSolrClient)client).getBaseURL());\n      assertReplicaValue(client, 1, \"title_s\", \"title1_new\", \n          \"Title didn't match for replica at client: \" + ((HttpSolrClient)client).getBaseURL());\n    }\n    \n    // Try another round of these updates, this time with a delete request at the end.\n    // This is to ensure that the fetch missing update from leader doesn't bomb out if the \n    // document has been deleted on the leader later on\n    {\n      clearIndex();\n      commit();\n      shardToJetty.get(SHARD1).get(1).jetty.getDebugFilter().unsetDelay();\n      \n      updates.add(regularDeleteRequest(1));\n\n      shardToJetty.get(SHARD1).get(1).jetty.getDebugFilter().addDelay(\"Waiting for dependant update to timeout\", 1, 5999); // the first update\n      shardToJetty.get(SHARD1).get(1).jetty.getDebugFilter().addDelay(\"Waiting for dependant update to timeout\", 4, 5998); // the delete update\n\n      threadpool =\n          ExecutorUtil.newMDCAwareFixedThreadPool(updates.size() + 1, new DefaultSolrThreadFactory(getTestName()));\n      for (UpdateRequest update : updates) {\n        AsyncUpdateWithRandomCommit task = new AsyncUpdateWithRandomCommit(update, cloudClient,\n                                                                           random().nextLong());\n        threadpool.submit(task);\n        \n        // while we can't guarantee/trust what order the updates are executed in, since multiple threads\n        // are involved, but we're trying to bias the thread scheduling to run them in the order submitted\n        Thread.sleep(100);\n      }\n\n      threadpool.shutdown();\n      assertTrue(\"Thread pool didn't terminate within 15 secs\", threadpool.awaitTermination(15, TimeUnit.SECONDS));\n\n      commit();\n\n      // TODO: Could try checking ZK for LIR flags to ensure LIR has not kicked in\n      // Check every 10ms, 100 times, for a replica to go down (& assert that it doesn't)\n      ZkController zkController = shardToLeaderJetty.get(SHARD1).jetty.getCoreContainer().getZkController();\n      String lirPath = zkController.getLeaderInitiatedRecoveryZnodePath(DEFAULT_TEST_COLLECTION_NAME, SHARD1);\n      assertFalse (zkController.getZkClient().exists(lirPath, true));\n\n      for (int i=0; i<100; i++) {\n        Thread.sleep(10);\n        cloudClient.getZkStateReader().forceUpdateCollection(DEFAULT_COLLECTION);\n        ClusterState state = cloudClient.getZkStateReader().getClusterState();\n\n        int numActiveReplicas = 0;\n        for (Replica rep: state.getCollection(DEFAULT_COLLECTION).getSlice(SHARD1).getReplicas())\n          if (rep.getState().equals(Replica.State.ACTIVE))\n            numActiveReplicas++;\n\n        assertEquals(\"The replica receiving reordered updates must not have gone down\", 3, numActiveReplicas);\n      }\n\n      for (SolrClient client: new SolrClient[] {LEADER, NONLEADERS.get(0), \n          NONLEADERS.get(1)}) { // nonleader 0 re-ordered replica, nonleader 1 well-ordered replica\n        SolrDocument doc = client.getById(String.valueOf(1), params(\"distrib\", \"false\"));\n        assertNull(\"This doc was supposed to have been deleted, but was: \" + doc, doc);\n      }\n\n    }\n    log.info(\"delayedReorderingFetchesMissingUpdateFromLeaderTest: This test passed fine...\");\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"bb222a3f9d9421d5c95afce73013fbd8de07ea1f","date":1543514331,"type":3,"author":"markrmiller","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/update/TestInPlaceUpdatesDistrib#delayedReorderingFetchesMissingUpdateFromLeaderTest().mjava","pathOld":"solr/core/src/test/org/apache/solr/update/TestInPlaceUpdatesDistrib#delayedReorderingFetchesMissingUpdateFromLeaderTest().mjava","sourceNew":"  private void delayedReorderingFetchesMissingUpdateFromLeaderTest() throws Exception {\n    clearIndex();\n    commit();\n    \n    float inplace_updatable_float = 1F;\n    buildRandomIndex(inplace_updatable_float, Collections.singletonList(1));\n\n    float newinplace_updatable_float = 100F;\n    List<UpdateRequest> updates = new ArrayList<>();\n    updates.add(regularUpdateRequest(\"id\", 1, \"title_s\", \"title1_new\", \"id_i\", 1, \"inplace_updatable_float\", newinplace_updatable_float));\n    updates.add(regularUpdateRequest(\"id\", 1, \"inplace_updatable_float\", map(\"inc\", 1)));\n    updates.add(regularUpdateRequest(\"id\", 1, \"inplace_updatable_float\", map(\"inc\", 1)));\n\n    // The next request to replica2 will be delayed (timeout is 5s)\n    shardToJetty.get(SHARD1).get(1).jetty.getDebugFilter().addDelay(\n        \"Waiting for dependant update to timeout\", 1, 6000);\n\n    ExecutorService threadpool =\n        ExecutorUtil.newMDCAwareFixedThreadPool(updates.size() + 1, new DefaultSolrThreadFactory(getTestName()));\n    for (UpdateRequest update : updates) {\n      AsyncUpdateWithRandomCommit task = new AsyncUpdateWithRandomCommit(update, cloudClient,\n                                                                         random().nextLong());\n      threadpool.submit(task);\n\n      // while we can't guarantee/trust what order the updates are executed in, since multiple threads\n      // are involved, but we're trying to bias the thread scheduling to run them in the order submitted\n      Thread.sleep(100); \n    }\n\n    threadpool.shutdown();\n    assertTrue(\"Thread pool didn't terminate within 15 secs\", threadpool.awaitTermination(15, TimeUnit.SECONDS));\n\n    commit();\n\n    // TODO: Could try checking ZK for LIR flags to ensure LIR has not kicked in\n    // Check every 10ms, 100 times, for a replica to go down (& assert that it doesn't)\n    for (int i=0; i<100; i++) {\n      Thread.sleep(10);\n      cloudClient.getZkStateReader().forceUpdateCollection(DEFAULT_COLLECTION);\n      ClusterState state = cloudClient.getZkStateReader().getClusterState();\n\n      int numActiveReplicas = 0;\n      for (Replica rep: state.getCollection(DEFAULT_COLLECTION).getSlice(SHARD1).getReplicas())\n        if (rep.getState().equals(Replica.State.ACTIVE))\n          numActiveReplicas++;\n\n      assertEquals(\"The replica receiving reordered updates must not have gone down\", 3, numActiveReplicas);\n    }\n    \n    for (SolrClient client : clients) {\n      TimeOut timeout = new TimeOut(30, TimeUnit.SECONDS, TimeSource.NANO_TIME);\n      try {\n        timeout.waitFor(\"Timeout\", () -> {\n          try {\n            return (float) getReplicaValue(client, 1, \"inplace_updatable_float\") == newinplace_updatable_float + 2.0f;\n          } catch (SolrServerException e) {\n            throw new RuntimeException(e);\n          } catch (IOException e) {\n            throw new RuntimeException(e);\n          }\n        });\n      } catch (TimeoutException e) {\n\n      }\n    }\n    \n    for (SolrClient client : clients) {\n      log.info(\"Testing client (Fetch missing test): \" + ((HttpSolrClient) client).getBaseURL());\n      log.info(\n          \"Version at \" + ((HttpSolrClient) client).getBaseURL() + \" is: \" + getReplicaValue(client, 1, \"_version_\"));\n\n      assertReplicaValue(client, 1, \"inplace_updatable_float\", (newinplace_updatable_float + 2.0f),\n          \"inplace_updatable_float didn't match for replica at client: \" + ((HttpSolrClient) client).getBaseURL());\n      assertReplicaValue(client, 1, \"title_s\", \"title1_new\",\n          \"Title didn't match for replica at client: \" + ((HttpSolrClient) client).getBaseURL());\n    }\n    \n    // Try another round of these updates, this time with a delete request at the end.\n    // This is to ensure that the fetch missing update from leader doesn't bomb out if the \n    // document has been deleted on the leader later on\n    {\n      clearIndex();\n      commit();\n      shardToJetty.get(SHARD1).get(1).jetty.getDebugFilter().unsetDelay();\n      \n      updates.add(regularDeleteRequest(1));\n\n      shardToJetty.get(SHARD1).get(1).jetty.getDebugFilter().addDelay(\"Waiting for dependant update to timeout\", 1, 5999); // the first update\n      shardToJetty.get(SHARD1).get(1).jetty.getDebugFilter().addDelay(\"Waiting for dependant update to timeout\", 4, 5998); // the delete update\n\n      threadpool =\n          ExecutorUtil.newMDCAwareFixedThreadPool(updates.size() + 1, new DefaultSolrThreadFactory(getTestName()));\n      for (UpdateRequest update : updates) {\n        AsyncUpdateWithRandomCommit task = new AsyncUpdateWithRandomCommit(update, cloudClient,\n                                                                           random().nextLong());\n        threadpool.submit(task);\n        \n        // while we can't guarantee/trust what order the updates are executed in, since multiple threads\n        // are involved, but we're trying to bias the thread scheduling to run them in the order submitted\n        Thread.sleep(100);\n      }\n\n      threadpool.shutdown();\n      assertTrue(\"Thread pool didn't terminate within 15 secs\", threadpool.awaitTermination(15, TimeUnit.SECONDS));\n\n      commit();\n\n      try (ZkShardTerms zkShardTerms = new ZkShardTerms(DEFAULT_COLLECTION, SHARD1, cloudClient.getZkStateReader().getZkClient())) {\n        for (int i=0; i<100; i++) {\n          Thread.sleep(10);\n          cloudClient.getZkStateReader().forceUpdateCollection(DEFAULT_COLLECTION);\n          ClusterState state = cloudClient.getZkStateReader().getClusterState();\n\n          int numActiveReplicas = 0;\n          for (Replica rep: state.getCollection(DEFAULT_COLLECTION).getSlice(SHARD1).getReplicas()) {\n            assertTrue(zkShardTerms.canBecomeLeader(rep.getName()));\n            if (rep.getState().equals(Replica.State.ACTIVE))\n              numActiveReplicas++;\n          }\n          assertEquals(\"The replica receiving reordered updates must not have gone down\", 3, numActiveReplicas);\n        }\n      }\n\n      for (SolrClient client: new SolrClient[] {LEADER, NONLEADERS.get(0), \n          NONLEADERS.get(1)}) { // nonleader 0 re-ordered replica, nonleader 1 well-ordered replica\n        SolrDocument doc = client.getById(String.valueOf(1), params(\"distrib\", \"false\"));\n        assertNull(\"This doc was supposed to have been deleted, but was: \" + doc, doc);\n      }\n\n    }\n    log.info(\"delayedReorderingFetchesMissingUpdateFromLeaderTest: This test passed fine...\");\n  }\n\n","sourceOld":"  private void delayedReorderingFetchesMissingUpdateFromLeaderTest() throws Exception {\n    clearIndex();\n    commit();\n    \n    float inplace_updatable_float = 1F;\n    buildRandomIndex(inplace_updatable_float, Collections.singletonList(1));\n\n    float newinplace_updatable_float = 100F;\n    List<UpdateRequest> updates = new ArrayList<>();\n    updates.add(regularUpdateRequest(\"id\", 1, \"title_s\", \"title1_new\", \"id_i\", 1, \"inplace_updatable_float\", newinplace_updatable_float));\n    updates.add(regularUpdateRequest(\"id\", 1, \"inplace_updatable_float\", map(\"inc\", 1)));\n    updates.add(regularUpdateRequest(\"id\", 1, \"inplace_updatable_float\", map(\"inc\", 1)));\n\n    // The next request to replica2 will be delayed by 6 secs (timeout is 5s)\n    shardToJetty.get(SHARD1).get(1).jetty.getDebugFilter().addDelay(\n        \"Waiting for dependant update to timeout\", 1, 6000);\n\n    ExecutorService threadpool =\n        ExecutorUtil.newMDCAwareFixedThreadPool(updates.size() + 1, new DefaultSolrThreadFactory(getTestName()));\n    for (UpdateRequest update : updates) {\n      AsyncUpdateWithRandomCommit task = new AsyncUpdateWithRandomCommit(update, cloudClient,\n                                                                         random().nextLong());\n      threadpool.submit(task);\n\n      // while we can't guarantee/trust what order the updates are executed in, since multiple threads\n      // are involved, but we're trying to bias the thread scheduling to run them in the order submitted\n      Thread.sleep(100); \n    }\n\n    threadpool.shutdown();\n    assertTrue(\"Thread pool didn't terminate within 15 secs\", threadpool.awaitTermination(15, TimeUnit.SECONDS));\n\n    commit();\n\n    // TODO: Could try checking ZK for LIR flags to ensure LIR has not kicked in\n    // Check every 10ms, 100 times, for a replica to go down (& assert that it doesn't)\n    for (int i=0; i<100; i++) {\n      Thread.sleep(10);\n      cloudClient.getZkStateReader().forceUpdateCollection(DEFAULT_COLLECTION);\n      ClusterState state = cloudClient.getZkStateReader().getClusterState();\n\n      int numActiveReplicas = 0;\n      for (Replica rep: state.getCollection(DEFAULT_COLLECTION).getSlice(SHARD1).getReplicas())\n        if (rep.getState().equals(Replica.State.ACTIVE))\n          numActiveReplicas++;\n\n      assertEquals(\"The replica receiving reordered updates must not have gone down\", 3, numActiveReplicas);\n    }\n\n    for (SolrClient client : clients) {\n      log.info(\"Testing client (Fetch missing test): \" + ((HttpSolrClient)client).getBaseURL());\n      log.info(\"Version at \" + ((HttpSolrClient)client).getBaseURL() + \" is: \" + getReplicaValue(client, 1, \"_version_\"));\n\n      assertReplicaValue(client, 1, \"inplace_updatable_float\", (newinplace_updatable_float + 2.0f), \n          \"inplace_updatable_float didn't match for replica at client: \" + ((HttpSolrClient)client).getBaseURL());\n      assertReplicaValue(client, 1, \"title_s\", \"title1_new\", \n          \"Title didn't match for replica at client: \" + ((HttpSolrClient)client).getBaseURL());\n    }\n    \n    // Try another round of these updates, this time with a delete request at the end.\n    // This is to ensure that the fetch missing update from leader doesn't bomb out if the \n    // document has been deleted on the leader later on\n    {\n      clearIndex();\n      commit();\n      shardToJetty.get(SHARD1).get(1).jetty.getDebugFilter().unsetDelay();\n      \n      updates.add(regularDeleteRequest(1));\n\n      shardToJetty.get(SHARD1).get(1).jetty.getDebugFilter().addDelay(\"Waiting for dependant update to timeout\", 1, 5999); // the first update\n      shardToJetty.get(SHARD1).get(1).jetty.getDebugFilter().addDelay(\"Waiting for dependant update to timeout\", 4, 5998); // the delete update\n\n      threadpool =\n          ExecutorUtil.newMDCAwareFixedThreadPool(updates.size() + 1, new DefaultSolrThreadFactory(getTestName()));\n      for (UpdateRequest update : updates) {\n        AsyncUpdateWithRandomCommit task = new AsyncUpdateWithRandomCommit(update, cloudClient,\n                                                                           random().nextLong());\n        threadpool.submit(task);\n        \n        // while we can't guarantee/trust what order the updates are executed in, since multiple threads\n        // are involved, but we're trying to bias the thread scheduling to run them in the order submitted\n        Thread.sleep(100);\n      }\n\n      threadpool.shutdown();\n      assertTrue(\"Thread pool didn't terminate within 15 secs\", threadpool.awaitTermination(15, TimeUnit.SECONDS));\n\n      commit();\n\n      try (ZkShardTerms zkShardTerms = new ZkShardTerms(DEFAULT_COLLECTION, SHARD1, cloudClient.getZkStateReader().getZkClient())) {\n        for (int i=0; i<100; i++) {\n          Thread.sleep(10);\n          cloudClient.getZkStateReader().forceUpdateCollection(DEFAULT_COLLECTION);\n          ClusterState state = cloudClient.getZkStateReader().getClusterState();\n\n          int numActiveReplicas = 0;\n          for (Replica rep: state.getCollection(DEFAULT_COLLECTION).getSlice(SHARD1).getReplicas()) {\n            assertTrue(zkShardTerms.canBecomeLeader(rep.getName()));\n            if (rep.getState().equals(Replica.State.ACTIVE))\n              numActiveReplicas++;\n          }\n          assertEquals(\"The replica receiving reordered updates must not have gone down\", 3, numActiveReplicas);\n        }\n      }\n\n      for (SolrClient client: new SolrClient[] {LEADER, NONLEADERS.get(0), \n          NONLEADERS.get(1)}) { // nonleader 0 re-ordered replica, nonleader 1 well-ordered replica\n        SolrDocument doc = client.getById(String.valueOf(1), params(\"distrib\", \"false\"));\n        assertNull(\"This doc was supposed to have been deleted, but was: \" + doc, doc);\n      }\n\n    }\n    log.info(\"delayedReorderingFetchesMissingUpdateFromLeaderTest: This test passed fine...\");\n  }\n\n","bugFix":["415bbbe7da8065dd3c477bdc3c703c6425622998"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fb03700c9690d16b15fb4f56f6ec36b128fd894e","date":1586745995,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/update/TestInPlaceUpdatesDistrib#delayedReorderingFetchesMissingUpdateFromLeaderTest().mjava","pathOld":"solr/core/src/test/org/apache/solr/update/TestInPlaceUpdatesDistrib#delayedReorderingFetchesMissingUpdateFromLeaderTest().mjava","sourceNew":"  private void delayedReorderingFetchesMissingUpdateFromLeaderTest() throws Exception {\n    clearIndex();\n    commit();\n    \n    float inplace_updatable_float = 1F;\n    buildRandomIndex(inplace_updatable_float, Collections.singletonList(1));\n\n    float newinplace_updatable_float = 100F;\n    List<UpdateRequest> updates = new ArrayList<>();\n    updates.add(regularUpdateRequest(\"id\", 1, \"title_s\", \"title1_new\", \"id_i\", 1, \"inplace_updatable_float\", newinplace_updatable_float));\n    updates.add(regularUpdateRequest(\"id\", 1, \"inplace_updatable_float\", map(\"inc\", 1)));\n    updates.add(regularUpdateRequest(\"id\", 1, \"inplace_updatable_float\", map(\"inc\", 1)));\n\n    // The next request to replica2 will be delayed (timeout is 5s)\n    shardToJetty.get(SHARD1).get(1).jetty.getDebugFilter().addDelay(\n        \"Waiting for dependant update to timeout\", 1, 6000);\n\n    ExecutorService threadpool =\n        ExecutorUtil.newMDCAwareFixedThreadPool(updates.size() + 1, new SolrNamedThreadFactory(getTestName()));\n    for (UpdateRequest update : updates) {\n      AsyncUpdateWithRandomCommit task = new AsyncUpdateWithRandomCommit(update, cloudClient,\n                                                                         random().nextLong());\n      threadpool.submit(task);\n\n      // while we can't guarantee/trust what order the updates are executed in, since multiple threads\n      // are involved, but we're trying to bias the thread scheduling to run them in the order submitted\n      Thread.sleep(100); \n    }\n\n    threadpool.shutdown();\n    assertTrue(\"Thread pool didn't terminate within 15 secs\", threadpool.awaitTermination(15, TimeUnit.SECONDS));\n\n    commit();\n\n    // TODO: Could try checking ZK for LIR flags to ensure LIR has not kicked in\n    // Check every 10ms, 100 times, for a replica to go down (& assert that it doesn't)\n    for (int i=0; i<100; i++) {\n      Thread.sleep(10);\n      cloudClient.getZkStateReader().forceUpdateCollection(DEFAULT_COLLECTION);\n      ClusterState state = cloudClient.getZkStateReader().getClusterState();\n\n      int numActiveReplicas = 0;\n      for (Replica rep: state.getCollection(DEFAULT_COLLECTION).getSlice(SHARD1).getReplicas())\n        if (rep.getState().equals(Replica.State.ACTIVE))\n          numActiveReplicas++;\n\n      assertEquals(\"The replica receiving reordered updates must not have gone down\", 3, numActiveReplicas);\n    }\n    \n    for (SolrClient client : clients) {\n      TimeOut timeout = new TimeOut(30, TimeUnit.SECONDS, TimeSource.NANO_TIME);\n      try {\n        timeout.waitFor(\"Timeout\", () -> {\n          try {\n            return (float) getReplicaValue(client, 1, \"inplace_updatable_float\") == newinplace_updatable_float + 2.0f;\n          } catch (SolrServerException e) {\n            throw new RuntimeException(e);\n          } catch (IOException e) {\n            throw new RuntimeException(e);\n          }\n        });\n      } catch (TimeoutException e) {\n\n      }\n    }\n    \n    for (SolrClient client : clients) {\n      log.info(\"Testing client (Fetch missing test): \" + ((HttpSolrClient) client).getBaseURL());\n      log.info(\n          \"Version at \" + ((HttpSolrClient) client).getBaseURL() + \" is: \" + getReplicaValue(client, 1, \"_version_\"));\n\n      assertReplicaValue(client, 1, \"inplace_updatable_float\", (newinplace_updatable_float + 2.0f),\n          \"inplace_updatable_float didn't match for replica at client: \" + ((HttpSolrClient) client).getBaseURL());\n      assertReplicaValue(client, 1, \"title_s\", \"title1_new\",\n          \"Title didn't match for replica at client: \" + ((HttpSolrClient) client).getBaseURL());\n    }\n    \n    // Try another round of these updates, this time with a delete request at the end.\n    // This is to ensure that the fetch missing update from leader doesn't bomb out if the \n    // document has been deleted on the leader later on\n    {\n      clearIndex();\n      commit();\n      shardToJetty.get(SHARD1).get(1).jetty.getDebugFilter().unsetDelay();\n      \n      updates.add(regularDeleteRequest(1));\n\n      shardToJetty.get(SHARD1).get(1).jetty.getDebugFilter().addDelay(\"Waiting for dependant update to timeout\", 1, 5999); // the first update\n      shardToJetty.get(SHARD1).get(1).jetty.getDebugFilter().addDelay(\"Waiting for dependant update to timeout\", 4, 5998); // the delete update\n\n      threadpool =\n          ExecutorUtil.newMDCAwareFixedThreadPool(updates.size() + 1, new SolrNamedThreadFactory(getTestName()));\n      for (UpdateRequest update : updates) {\n        AsyncUpdateWithRandomCommit task = new AsyncUpdateWithRandomCommit(update, cloudClient,\n                                                                           random().nextLong());\n        threadpool.submit(task);\n        \n        // while we can't guarantee/trust what order the updates are executed in, since multiple threads\n        // are involved, but we're trying to bias the thread scheduling to run them in the order submitted\n        Thread.sleep(100);\n      }\n\n      threadpool.shutdown();\n      assertTrue(\"Thread pool didn't terminate within 15 secs\", threadpool.awaitTermination(15, TimeUnit.SECONDS));\n\n      commit();\n\n      try (ZkShardTerms zkShardTerms = new ZkShardTerms(DEFAULT_COLLECTION, SHARD1, cloudClient.getZkStateReader().getZkClient())) {\n        for (int i=0; i<100; i++) {\n          Thread.sleep(10);\n          cloudClient.getZkStateReader().forceUpdateCollection(DEFAULT_COLLECTION);\n          ClusterState state = cloudClient.getZkStateReader().getClusterState();\n\n          int numActiveReplicas = 0;\n          for (Replica rep: state.getCollection(DEFAULT_COLLECTION).getSlice(SHARD1).getReplicas()) {\n            assertTrue(zkShardTerms.canBecomeLeader(rep.getName()));\n            if (rep.getState().equals(Replica.State.ACTIVE))\n              numActiveReplicas++;\n          }\n          assertEquals(\"The replica receiving reordered updates must not have gone down\", 3, numActiveReplicas);\n        }\n      }\n\n      for (SolrClient client: new SolrClient[] {LEADER, NONLEADERS.get(0), \n          NONLEADERS.get(1)}) { // nonleader 0 re-ordered replica, nonleader 1 well-ordered replica\n        SolrDocument doc = client.getById(String.valueOf(1), params(\"distrib\", \"false\"));\n        assertNull(\"This doc was supposed to have been deleted, but was: \" + doc, doc);\n      }\n\n    }\n    log.info(\"delayedReorderingFetchesMissingUpdateFromLeaderTest: This test passed fine...\");\n  }\n\n","sourceOld":"  private void delayedReorderingFetchesMissingUpdateFromLeaderTest() throws Exception {\n    clearIndex();\n    commit();\n    \n    float inplace_updatable_float = 1F;\n    buildRandomIndex(inplace_updatable_float, Collections.singletonList(1));\n\n    float newinplace_updatable_float = 100F;\n    List<UpdateRequest> updates = new ArrayList<>();\n    updates.add(regularUpdateRequest(\"id\", 1, \"title_s\", \"title1_new\", \"id_i\", 1, \"inplace_updatable_float\", newinplace_updatable_float));\n    updates.add(regularUpdateRequest(\"id\", 1, \"inplace_updatable_float\", map(\"inc\", 1)));\n    updates.add(regularUpdateRequest(\"id\", 1, \"inplace_updatable_float\", map(\"inc\", 1)));\n\n    // The next request to replica2 will be delayed (timeout is 5s)\n    shardToJetty.get(SHARD1).get(1).jetty.getDebugFilter().addDelay(\n        \"Waiting for dependant update to timeout\", 1, 6000);\n\n    ExecutorService threadpool =\n        ExecutorUtil.newMDCAwareFixedThreadPool(updates.size() + 1, new DefaultSolrThreadFactory(getTestName()));\n    for (UpdateRequest update : updates) {\n      AsyncUpdateWithRandomCommit task = new AsyncUpdateWithRandomCommit(update, cloudClient,\n                                                                         random().nextLong());\n      threadpool.submit(task);\n\n      // while we can't guarantee/trust what order the updates are executed in, since multiple threads\n      // are involved, but we're trying to bias the thread scheduling to run them in the order submitted\n      Thread.sleep(100); \n    }\n\n    threadpool.shutdown();\n    assertTrue(\"Thread pool didn't terminate within 15 secs\", threadpool.awaitTermination(15, TimeUnit.SECONDS));\n\n    commit();\n\n    // TODO: Could try checking ZK for LIR flags to ensure LIR has not kicked in\n    // Check every 10ms, 100 times, for a replica to go down (& assert that it doesn't)\n    for (int i=0; i<100; i++) {\n      Thread.sleep(10);\n      cloudClient.getZkStateReader().forceUpdateCollection(DEFAULT_COLLECTION);\n      ClusterState state = cloudClient.getZkStateReader().getClusterState();\n\n      int numActiveReplicas = 0;\n      for (Replica rep: state.getCollection(DEFAULT_COLLECTION).getSlice(SHARD1).getReplicas())\n        if (rep.getState().equals(Replica.State.ACTIVE))\n          numActiveReplicas++;\n\n      assertEquals(\"The replica receiving reordered updates must not have gone down\", 3, numActiveReplicas);\n    }\n    \n    for (SolrClient client : clients) {\n      TimeOut timeout = new TimeOut(30, TimeUnit.SECONDS, TimeSource.NANO_TIME);\n      try {\n        timeout.waitFor(\"Timeout\", () -> {\n          try {\n            return (float) getReplicaValue(client, 1, \"inplace_updatable_float\") == newinplace_updatable_float + 2.0f;\n          } catch (SolrServerException e) {\n            throw new RuntimeException(e);\n          } catch (IOException e) {\n            throw new RuntimeException(e);\n          }\n        });\n      } catch (TimeoutException e) {\n\n      }\n    }\n    \n    for (SolrClient client : clients) {\n      log.info(\"Testing client (Fetch missing test): \" + ((HttpSolrClient) client).getBaseURL());\n      log.info(\n          \"Version at \" + ((HttpSolrClient) client).getBaseURL() + \" is: \" + getReplicaValue(client, 1, \"_version_\"));\n\n      assertReplicaValue(client, 1, \"inplace_updatable_float\", (newinplace_updatable_float + 2.0f),\n          \"inplace_updatable_float didn't match for replica at client: \" + ((HttpSolrClient) client).getBaseURL());\n      assertReplicaValue(client, 1, \"title_s\", \"title1_new\",\n          \"Title didn't match for replica at client: \" + ((HttpSolrClient) client).getBaseURL());\n    }\n    \n    // Try another round of these updates, this time with a delete request at the end.\n    // This is to ensure that the fetch missing update from leader doesn't bomb out if the \n    // document has been deleted on the leader later on\n    {\n      clearIndex();\n      commit();\n      shardToJetty.get(SHARD1).get(1).jetty.getDebugFilter().unsetDelay();\n      \n      updates.add(regularDeleteRequest(1));\n\n      shardToJetty.get(SHARD1).get(1).jetty.getDebugFilter().addDelay(\"Waiting for dependant update to timeout\", 1, 5999); // the first update\n      shardToJetty.get(SHARD1).get(1).jetty.getDebugFilter().addDelay(\"Waiting for dependant update to timeout\", 4, 5998); // the delete update\n\n      threadpool =\n          ExecutorUtil.newMDCAwareFixedThreadPool(updates.size() + 1, new DefaultSolrThreadFactory(getTestName()));\n      for (UpdateRequest update : updates) {\n        AsyncUpdateWithRandomCommit task = new AsyncUpdateWithRandomCommit(update, cloudClient,\n                                                                           random().nextLong());\n        threadpool.submit(task);\n        \n        // while we can't guarantee/trust what order the updates are executed in, since multiple threads\n        // are involved, but we're trying to bias the thread scheduling to run them in the order submitted\n        Thread.sleep(100);\n      }\n\n      threadpool.shutdown();\n      assertTrue(\"Thread pool didn't terminate within 15 secs\", threadpool.awaitTermination(15, TimeUnit.SECONDS));\n\n      commit();\n\n      try (ZkShardTerms zkShardTerms = new ZkShardTerms(DEFAULT_COLLECTION, SHARD1, cloudClient.getZkStateReader().getZkClient())) {\n        for (int i=0; i<100; i++) {\n          Thread.sleep(10);\n          cloudClient.getZkStateReader().forceUpdateCollection(DEFAULT_COLLECTION);\n          ClusterState state = cloudClient.getZkStateReader().getClusterState();\n\n          int numActiveReplicas = 0;\n          for (Replica rep: state.getCollection(DEFAULT_COLLECTION).getSlice(SHARD1).getReplicas()) {\n            assertTrue(zkShardTerms.canBecomeLeader(rep.getName()));\n            if (rep.getState().equals(Replica.State.ACTIVE))\n              numActiveReplicas++;\n          }\n          assertEquals(\"The replica receiving reordered updates must not have gone down\", 3, numActiveReplicas);\n        }\n      }\n\n      for (SolrClient client: new SolrClient[] {LEADER, NONLEADERS.get(0), \n          NONLEADERS.get(1)}) { // nonleader 0 re-ordered replica, nonleader 1 well-ordered replica\n        SolrDocument doc = client.getById(String.valueOf(1), params(\"distrib\", \"false\"));\n        assertNull(\"This doc was supposed to have been deleted, but was: \" + doc, doc);\n      }\n\n    }\n    log.info(\"delayedReorderingFetchesMissingUpdateFromLeaderTest: This test passed fine...\");\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a966532d92cf9ba2856f15a8140151bb6b518e4b","date":1588290631,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/update/TestInPlaceUpdatesDistrib#delayedReorderingFetchesMissingUpdateFromLeaderTest().mjava","pathOld":"solr/core/src/test/org/apache/solr/update/TestInPlaceUpdatesDistrib#delayedReorderingFetchesMissingUpdateFromLeaderTest().mjava","sourceNew":"  private void delayedReorderingFetchesMissingUpdateFromLeaderTest() throws Exception {\n    clearIndex();\n    commit();\n    \n    float inplace_updatable_float = 1F;\n    buildRandomIndex(inplace_updatable_float, Collections.singletonList(1));\n\n    float newinplace_updatable_float = 100F;\n    List<UpdateRequest> updates = new ArrayList<>();\n    updates.add(regularUpdateRequest(\"id\", 1, \"title_s\", \"title1_new\", \"id_i\", 1, \"inplace_updatable_float\", newinplace_updatable_float));\n    updates.add(regularUpdateRequest(\"id\", 1, \"inplace_updatable_float\", map(\"inc\", 1)));\n    updates.add(regularUpdateRequest(\"id\", 1, \"inplace_updatable_float\", map(\"inc\", 1)));\n\n    // The next request to replica2 will be delayed (timeout is 5s)\n    shardToJetty.get(SHARD1).get(1).jetty.getDebugFilter().addDelay(\n        \"Waiting for dependant update to timeout\", 1, 6000);\n\n    ExecutorService threadpool =\n        ExecutorUtil.newMDCAwareFixedThreadPool(updates.size() + 1, new SolrNamedThreadFactory(getTestName()));\n    for (UpdateRequest update : updates) {\n      AsyncUpdateWithRandomCommit task = new AsyncUpdateWithRandomCommit(update, cloudClient,\n                                                                         random().nextLong());\n      threadpool.submit(task);\n\n      // while we can't guarantee/trust what order the updates are executed in, since multiple threads\n      // are involved, but we're trying to bias the thread scheduling to run them in the order submitted\n      Thread.sleep(100); \n    }\n\n    threadpool.shutdown();\n    assertTrue(\"Thread pool didn't terminate within 15 secs\", threadpool.awaitTermination(15, TimeUnit.SECONDS));\n\n    commit();\n\n    // TODO: Could try checking ZK for LIR flags to ensure LIR has not kicked in\n    // Check every 10ms, 100 times, for a replica to go down (& assert that it doesn't)\n    for (int i=0; i<100; i++) {\n      Thread.sleep(10);\n      cloudClient.getZkStateReader().forceUpdateCollection(DEFAULT_COLLECTION);\n      ClusterState state = cloudClient.getZkStateReader().getClusterState();\n\n      int numActiveReplicas = 0;\n      for (Replica rep: state.getCollection(DEFAULT_COLLECTION).getSlice(SHARD1).getReplicas())\n        if (rep.getState().equals(Replica.State.ACTIVE))\n          numActiveReplicas++;\n\n      assertEquals(\"The replica receiving reordered updates must not have gone down\", 3, numActiveReplicas);\n    }\n    \n    for (SolrClient client : clients) {\n      TimeOut timeout = new TimeOut(30, TimeUnit.SECONDS, TimeSource.NANO_TIME);\n      try {\n        timeout.waitFor(\"Timeout\", () -> {\n          try {\n            return (float) getReplicaValue(client, 1, \"inplace_updatable_float\") == newinplace_updatable_float + 2.0f;\n          } catch (SolrServerException e) {\n            throw new RuntimeException(e);\n          } catch (IOException e) {\n            throw new RuntimeException(e);\n          }\n        });\n      } catch (TimeoutException e) {\n\n      }\n    }\n    \n    for (SolrClient client : clients) {\n      if (log.isInfoEnabled()) {\n        log.info(\"Testing client (Fetch missing test): {}\", ((HttpSolrClient) client).getBaseURL());\n        log.info(\"Version at {} is: {}\"\n            , ((HttpSolrClient) client).getBaseURL(), getReplicaValue(client, 1, \"_version_\")); // logOk\n      }\n      assertReplicaValue(client, 1, \"inplace_updatable_float\", (newinplace_updatable_float + 2.0f),\n          \"inplace_updatable_float didn't match for replica at client: \" + ((HttpSolrClient) client).getBaseURL());\n      assertReplicaValue(client, 1, \"title_s\", \"title1_new\",\n          \"Title didn't match for replica at client: \" + ((HttpSolrClient) client).getBaseURL());\n    }\n    \n    // Try another round of these updates, this time with a delete request at the end.\n    // This is to ensure that the fetch missing update from leader doesn't bomb out if the \n    // document has been deleted on the leader later on\n    {\n      clearIndex();\n      commit();\n      shardToJetty.get(SHARD1).get(1).jetty.getDebugFilter().unsetDelay();\n      \n      updates.add(regularDeleteRequest(1));\n\n      shardToJetty.get(SHARD1).get(1).jetty.getDebugFilter().addDelay(\"Waiting for dependant update to timeout\", 1, 5999); // the first update\n      shardToJetty.get(SHARD1).get(1).jetty.getDebugFilter().addDelay(\"Waiting for dependant update to timeout\", 4, 5998); // the delete update\n\n      threadpool =\n          ExecutorUtil.newMDCAwareFixedThreadPool(updates.size() + 1, new SolrNamedThreadFactory(getTestName()));\n      for (UpdateRequest update : updates) {\n        AsyncUpdateWithRandomCommit task = new AsyncUpdateWithRandomCommit(update, cloudClient,\n                                                                           random().nextLong());\n        threadpool.submit(task);\n        \n        // while we can't guarantee/trust what order the updates are executed in, since multiple threads\n        // are involved, but we're trying to bias the thread scheduling to run them in the order submitted\n        Thread.sleep(100);\n      }\n\n      threadpool.shutdown();\n      assertTrue(\"Thread pool didn't terminate within 15 secs\", threadpool.awaitTermination(15, TimeUnit.SECONDS));\n\n      commit();\n\n      try (ZkShardTerms zkShardTerms = new ZkShardTerms(DEFAULT_COLLECTION, SHARD1, cloudClient.getZkStateReader().getZkClient())) {\n        for (int i=0; i<100; i++) {\n          Thread.sleep(10);\n          cloudClient.getZkStateReader().forceUpdateCollection(DEFAULT_COLLECTION);\n          ClusterState state = cloudClient.getZkStateReader().getClusterState();\n\n          int numActiveReplicas = 0;\n          for (Replica rep: state.getCollection(DEFAULT_COLLECTION).getSlice(SHARD1).getReplicas()) {\n            assertTrue(zkShardTerms.canBecomeLeader(rep.getName()));\n            if (rep.getState().equals(Replica.State.ACTIVE))\n              numActiveReplicas++;\n          }\n          assertEquals(\"The replica receiving reordered updates must not have gone down\", 3, numActiveReplicas);\n        }\n      }\n\n      for (SolrClient client: new SolrClient[] {LEADER, NONLEADERS.get(0), \n          NONLEADERS.get(1)}) { // nonleader 0 re-ordered replica, nonleader 1 well-ordered replica\n        SolrDocument doc = client.getById(String.valueOf(1), params(\"distrib\", \"false\"));\n        assertNull(\"This doc was supposed to have been deleted, but was: \" + doc, doc);\n      }\n\n    }\n    log.info(\"delayedReorderingFetchesMissingUpdateFromLeaderTest: This test passed fine...\");\n  }\n\n","sourceOld":"  private void delayedReorderingFetchesMissingUpdateFromLeaderTest() throws Exception {\n    clearIndex();\n    commit();\n    \n    float inplace_updatable_float = 1F;\n    buildRandomIndex(inplace_updatable_float, Collections.singletonList(1));\n\n    float newinplace_updatable_float = 100F;\n    List<UpdateRequest> updates = new ArrayList<>();\n    updates.add(regularUpdateRequest(\"id\", 1, \"title_s\", \"title1_new\", \"id_i\", 1, \"inplace_updatable_float\", newinplace_updatable_float));\n    updates.add(regularUpdateRequest(\"id\", 1, \"inplace_updatable_float\", map(\"inc\", 1)));\n    updates.add(regularUpdateRequest(\"id\", 1, \"inplace_updatable_float\", map(\"inc\", 1)));\n\n    // The next request to replica2 will be delayed (timeout is 5s)\n    shardToJetty.get(SHARD1).get(1).jetty.getDebugFilter().addDelay(\n        \"Waiting for dependant update to timeout\", 1, 6000);\n\n    ExecutorService threadpool =\n        ExecutorUtil.newMDCAwareFixedThreadPool(updates.size() + 1, new SolrNamedThreadFactory(getTestName()));\n    for (UpdateRequest update : updates) {\n      AsyncUpdateWithRandomCommit task = new AsyncUpdateWithRandomCommit(update, cloudClient,\n                                                                         random().nextLong());\n      threadpool.submit(task);\n\n      // while we can't guarantee/trust what order the updates are executed in, since multiple threads\n      // are involved, but we're trying to bias the thread scheduling to run them in the order submitted\n      Thread.sleep(100); \n    }\n\n    threadpool.shutdown();\n    assertTrue(\"Thread pool didn't terminate within 15 secs\", threadpool.awaitTermination(15, TimeUnit.SECONDS));\n\n    commit();\n\n    // TODO: Could try checking ZK for LIR flags to ensure LIR has not kicked in\n    // Check every 10ms, 100 times, for a replica to go down (& assert that it doesn't)\n    for (int i=0; i<100; i++) {\n      Thread.sleep(10);\n      cloudClient.getZkStateReader().forceUpdateCollection(DEFAULT_COLLECTION);\n      ClusterState state = cloudClient.getZkStateReader().getClusterState();\n\n      int numActiveReplicas = 0;\n      for (Replica rep: state.getCollection(DEFAULT_COLLECTION).getSlice(SHARD1).getReplicas())\n        if (rep.getState().equals(Replica.State.ACTIVE))\n          numActiveReplicas++;\n\n      assertEquals(\"The replica receiving reordered updates must not have gone down\", 3, numActiveReplicas);\n    }\n    \n    for (SolrClient client : clients) {\n      TimeOut timeout = new TimeOut(30, TimeUnit.SECONDS, TimeSource.NANO_TIME);\n      try {\n        timeout.waitFor(\"Timeout\", () -> {\n          try {\n            return (float) getReplicaValue(client, 1, \"inplace_updatable_float\") == newinplace_updatable_float + 2.0f;\n          } catch (SolrServerException e) {\n            throw new RuntimeException(e);\n          } catch (IOException e) {\n            throw new RuntimeException(e);\n          }\n        });\n      } catch (TimeoutException e) {\n\n      }\n    }\n    \n    for (SolrClient client : clients) {\n      log.info(\"Testing client (Fetch missing test): \" + ((HttpSolrClient) client).getBaseURL());\n      log.info(\n          \"Version at \" + ((HttpSolrClient) client).getBaseURL() + \" is: \" + getReplicaValue(client, 1, \"_version_\"));\n\n      assertReplicaValue(client, 1, \"inplace_updatable_float\", (newinplace_updatable_float + 2.0f),\n          \"inplace_updatable_float didn't match for replica at client: \" + ((HttpSolrClient) client).getBaseURL());\n      assertReplicaValue(client, 1, \"title_s\", \"title1_new\",\n          \"Title didn't match for replica at client: \" + ((HttpSolrClient) client).getBaseURL());\n    }\n    \n    // Try another round of these updates, this time with a delete request at the end.\n    // This is to ensure that the fetch missing update from leader doesn't bomb out if the \n    // document has been deleted on the leader later on\n    {\n      clearIndex();\n      commit();\n      shardToJetty.get(SHARD1).get(1).jetty.getDebugFilter().unsetDelay();\n      \n      updates.add(regularDeleteRequest(1));\n\n      shardToJetty.get(SHARD1).get(1).jetty.getDebugFilter().addDelay(\"Waiting for dependant update to timeout\", 1, 5999); // the first update\n      shardToJetty.get(SHARD1).get(1).jetty.getDebugFilter().addDelay(\"Waiting for dependant update to timeout\", 4, 5998); // the delete update\n\n      threadpool =\n          ExecutorUtil.newMDCAwareFixedThreadPool(updates.size() + 1, new SolrNamedThreadFactory(getTestName()));\n      for (UpdateRequest update : updates) {\n        AsyncUpdateWithRandomCommit task = new AsyncUpdateWithRandomCommit(update, cloudClient,\n                                                                           random().nextLong());\n        threadpool.submit(task);\n        \n        // while we can't guarantee/trust what order the updates are executed in, since multiple threads\n        // are involved, but we're trying to bias the thread scheduling to run them in the order submitted\n        Thread.sleep(100);\n      }\n\n      threadpool.shutdown();\n      assertTrue(\"Thread pool didn't terminate within 15 secs\", threadpool.awaitTermination(15, TimeUnit.SECONDS));\n\n      commit();\n\n      try (ZkShardTerms zkShardTerms = new ZkShardTerms(DEFAULT_COLLECTION, SHARD1, cloudClient.getZkStateReader().getZkClient())) {\n        for (int i=0; i<100; i++) {\n          Thread.sleep(10);\n          cloudClient.getZkStateReader().forceUpdateCollection(DEFAULT_COLLECTION);\n          ClusterState state = cloudClient.getZkStateReader().getClusterState();\n\n          int numActiveReplicas = 0;\n          for (Replica rep: state.getCollection(DEFAULT_COLLECTION).getSlice(SHARD1).getReplicas()) {\n            assertTrue(zkShardTerms.canBecomeLeader(rep.getName()));\n            if (rep.getState().equals(Replica.State.ACTIVE))\n              numActiveReplicas++;\n          }\n          assertEquals(\"The replica receiving reordered updates must not have gone down\", 3, numActiveReplicas);\n        }\n      }\n\n      for (SolrClient client: new SolrClient[] {LEADER, NONLEADERS.get(0), \n          NONLEADERS.get(1)}) { // nonleader 0 re-ordered replica, nonleader 1 well-ordered replica\n        SolrDocument doc = client.getById(String.valueOf(1), params(\"distrib\", \"false\"));\n        assertNull(\"This doc was supposed to have been deleted, but was: \" + doc, doc);\n      }\n\n    }\n    log.info(\"delayedReorderingFetchesMissingUpdateFromLeaderTest: This test passed fine...\");\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b2d19164145b2a65acf62a657c75f4a249b649c0","date":1601732857,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/update/TestInPlaceUpdatesDistrib#delayedReorderingFetchesMissingUpdateFromLeaderTest().mjava","pathOld":"solr/core/src/test/org/apache/solr/update/TestInPlaceUpdatesDistrib#delayedReorderingFetchesMissingUpdateFromLeaderTest().mjava","sourceNew":"  private void delayedReorderingFetchesMissingUpdateFromLeaderTest() throws Exception {\n    clearIndex();\n    commit();\n    \n    float inplace_updatable_float = 1F;\n    buildRandomIndex(inplace_updatable_float, Collections.singletonList(1));\n\n    float newinplace_updatable_float = 100F;\n    List<UpdateRequest> updates = new ArrayList<>();\n    updates.add(regularUpdateRequest(\"id\", 1, \"title_s\", \"title1_new\", \"id_i\", 1, \"inplace_updatable_float\", newinplace_updatable_float));\n    updates.add(regularUpdateRequest(\"id\", 1, \"inplace_updatable_float\", map(\"inc\", 1)));\n    updates.add(regularUpdateRequest(\"id\", 1, \"inplace_updatable_float\", map(\"inc\", 1)));\n\n    // The next request to replica2 will be delayed (timeout is 5s)\n    shardToJetty.get(SHARD1).get(1).jetty.getDebugFilter().addDelay(\n        \"Waiting for dependant update to timeout\", 1, 6000);\n\n    ExecutorService threadpool =\n        ExecutorUtil.newMDCAwareFixedThreadPool(updates.size() + 1, new SolrNamedThreadFactory(getTestName()));\n    for (UpdateRequest update : updates) {\n      AsyncUpdateWithRandomCommit task = new AsyncUpdateWithRandomCommit(update, cloudClient,\n                                                                         random().nextLong());\n      threadpool.submit(task);\n\n      // while we can't guarantee/trust what order the updates are executed in, since multiple threads\n      // are involved, but we're trying to bias the thread scheduling to run them in the order submitted\n      Thread.sleep(100); \n    }\n\n    threadpool.shutdown();\n    assertTrue(\"Thread pool didn't terminate within 15 secs\", threadpool.awaitTermination(15, TimeUnit.SECONDS));\n\n    commit();\n\n    // TODO: Could try checking ZK for LIR flags to ensure LIR has not kicked in\n    // Check every 10ms, 100 times, for a replica to go down (& assert that it doesn't)\n    for (int i=0; i<100; i++) {\n      Thread.sleep(10);\n      cloudClient.getZkStateReader().forceUpdateCollection(DEFAULT_COLLECTION);\n      ClusterState state = cloudClient.getZkStateReader().getClusterState();\n\n      int numActiveReplicas = 0;\n      for (Replica rep: state.getCollection(DEFAULT_COLLECTION).getSlice(SHARD1).getReplicas())\n        if (rep.getState().equals(Replica.State.ACTIVE))\n          numActiveReplicas++;\n\n      assertEquals(\"The replica receiving reordered updates must not have gone down\", 3, numActiveReplicas);\n    }\n    \n    for (SolrClient client : clients) {\n      TimeOut timeout = new TimeOut(30, TimeUnit.SECONDS, TimeSource.NANO_TIME);\n      try {\n        timeout.waitFor(\"Timeout\", () -> {\n          try {\n            return (float) getReplicaValue(client, 1, \"inplace_updatable_float\") == newinplace_updatable_float + 2.0f;\n          } catch (SolrServerException e) {\n            throw new RuntimeException(e);\n          } catch (IOException e) {\n            throw new RuntimeException(e);\n          }\n        });\n      } catch (TimeoutException e) {\n\n      }\n    }\n    \n    for (SolrClient client : clients) {\n      if (log.isInfoEnabled()) {\n        log.info(\"Testing client (Fetch missing test): {}\", ((HttpSolrClient) client).getBaseURL());\n        log.info(\"Version at {} is: {}\"\n            , ((HttpSolrClient) client).getBaseURL(), getReplicaValue(client, 1, \"_version_\")); // nowarn\n      }\n      assertReplicaValue(client, 1, \"inplace_updatable_float\", (newinplace_updatable_float + 2.0f),\n          \"inplace_updatable_float didn't match for replica at client: \" + ((HttpSolrClient) client).getBaseURL());\n      assertReplicaValue(client, 1, \"title_s\", \"title1_new\",\n          \"Title didn't match for replica at client: \" + ((HttpSolrClient) client).getBaseURL());\n    }\n    \n    // Try another round of these updates, this time with a delete request at the end.\n    // This is to ensure that the fetch missing update from leader doesn't bomb out if the \n    // document has been deleted on the leader later on\n    {\n      clearIndex();\n      commit();\n      shardToJetty.get(SHARD1).get(1).jetty.getDebugFilter().unsetDelay();\n      \n      updates.add(regularDeleteRequest(1));\n\n      shardToJetty.get(SHARD1).get(1).jetty.getDebugFilter().addDelay(\"Waiting for dependant update to timeout\", 1, 5999); // the first update\n      shardToJetty.get(SHARD1).get(1).jetty.getDebugFilter().addDelay(\"Waiting for dependant update to timeout\", 4, 5998); // the delete update\n\n      threadpool =\n          ExecutorUtil.newMDCAwareFixedThreadPool(updates.size() + 1, new SolrNamedThreadFactory(getTestName()));\n      for (UpdateRequest update : updates) {\n        AsyncUpdateWithRandomCommit task = new AsyncUpdateWithRandomCommit(update, cloudClient,\n                                                                           random().nextLong());\n        threadpool.submit(task);\n        \n        // while we can't guarantee/trust what order the updates are executed in, since multiple threads\n        // are involved, but we're trying to bias the thread scheduling to run them in the order submitted\n        Thread.sleep(100);\n      }\n\n      threadpool.shutdown();\n      assertTrue(\"Thread pool didn't terminate within 15 secs\", threadpool.awaitTermination(15, TimeUnit.SECONDS));\n\n      commit();\n\n      try (ZkShardTerms zkShardTerms = new ZkShardTerms(DEFAULT_COLLECTION, SHARD1, cloudClient.getZkStateReader().getZkClient())) {\n        for (int i=0; i<100; i++) {\n          Thread.sleep(10);\n          cloudClient.getZkStateReader().forceUpdateCollection(DEFAULT_COLLECTION);\n          ClusterState state = cloudClient.getZkStateReader().getClusterState();\n\n          int numActiveReplicas = 0;\n          for (Replica rep: state.getCollection(DEFAULT_COLLECTION).getSlice(SHARD1).getReplicas()) {\n            assertTrue(zkShardTerms.canBecomeLeader(rep.getName()));\n            if (rep.getState().equals(Replica.State.ACTIVE))\n              numActiveReplicas++;\n          }\n          assertEquals(\"The replica receiving reordered updates must not have gone down\", 3, numActiveReplicas);\n        }\n      }\n\n      for (SolrClient client: new SolrClient[] {LEADER, NONLEADERS.get(0), \n          NONLEADERS.get(1)}) { // nonleader 0 re-ordered replica, nonleader 1 well-ordered replica\n        SolrDocument doc = client.getById(String.valueOf(1), params(\"distrib\", \"false\"));\n        assertNull(\"This doc was supposed to have been deleted, but was: \" + doc, doc);\n      }\n\n    }\n    log.info(\"delayedReorderingFetchesMissingUpdateFromLeaderTest: This test passed fine...\");\n  }\n\n","sourceOld":"  private void delayedReorderingFetchesMissingUpdateFromLeaderTest() throws Exception {\n    clearIndex();\n    commit();\n    \n    float inplace_updatable_float = 1F;\n    buildRandomIndex(inplace_updatable_float, Collections.singletonList(1));\n\n    float newinplace_updatable_float = 100F;\n    List<UpdateRequest> updates = new ArrayList<>();\n    updates.add(regularUpdateRequest(\"id\", 1, \"title_s\", \"title1_new\", \"id_i\", 1, \"inplace_updatable_float\", newinplace_updatable_float));\n    updates.add(regularUpdateRequest(\"id\", 1, \"inplace_updatable_float\", map(\"inc\", 1)));\n    updates.add(regularUpdateRequest(\"id\", 1, \"inplace_updatable_float\", map(\"inc\", 1)));\n\n    // The next request to replica2 will be delayed (timeout is 5s)\n    shardToJetty.get(SHARD1).get(1).jetty.getDebugFilter().addDelay(\n        \"Waiting for dependant update to timeout\", 1, 6000);\n\n    ExecutorService threadpool =\n        ExecutorUtil.newMDCAwareFixedThreadPool(updates.size() + 1, new SolrNamedThreadFactory(getTestName()));\n    for (UpdateRequest update : updates) {\n      AsyncUpdateWithRandomCommit task = new AsyncUpdateWithRandomCommit(update, cloudClient,\n                                                                         random().nextLong());\n      threadpool.submit(task);\n\n      // while we can't guarantee/trust what order the updates are executed in, since multiple threads\n      // are involved, but we're trying to bias the thread scheduling to run them in the order submitted\n      Thread.sleep(100); \n    }\n\n    threadpool.shutdown();\n    assertTrue(\"Thread pool didn't terminate within 15 secs\", threadpool.awaitTermination(15, TimeUnit.SECONDS));\n\n    commit();\n\n    // TODO: Could try checking ZK for LIR flags to ensure LIR has not kicked in\n    // Check every 10ms, 100 times, for a replica to go down (& assert that it doesn't)\n    for (int i=0; i<100; i++) {\n      Thread.sleep(10);\n      cloudClient.getZkStateReader().forceUpdateCollection(DEFAULT_COLLECTION);\n      ClusterState state = cloudClient.getZkStateReader().getClusterState();\n\n      int numActiveReplicas = 0;\n      for (Replica rep: state.getCollection(DEFAULT_COLLECTION).getSlice(SHARD1).getReplicas())\n        if (rep.getState().equals(Replica.State.ACTIVE))\n          numActiveReplicas++;\n\n      assertEquals(\"The replica receiving reordered updates must not have gone down\", 3, numActiveReplicas);\n    }\n    \n    for (SolrClient client : clients) {\n      TimeOut timeout = new TimeOut(30, TimeUnit.SECONDS, TimeSource.NANO_TIME);\n      try {\n        timeout.waitFor(\"Timeout\", () -> {\n          try {\n            return (float) getReplicaValue(client, 1, \"inplace_updatable_float\") == newinplace_updatable_float + 2.0f;\n          } catch (SolrServerException e) {\n            throw new RuntimeException(e);\n          } catch (IOException e) {\n            throw new RuntimeException(e);\n          }\n        });\n      } catch (TimeoutException e) {\n\n      }\n    }\n    \n    for (SolrClient client : clients) {\n      if (log.isInfoEnabled()) {\n        log.info(\"Testing client (Fetch missing test): {}\", ((HttpSolrClient) client).getBaseURL());\n        log.info(\"Version at {} is: {}\"\n            , ((HttpSolrClient) client).getBaseURL(), getReplicaValue(client, 1, \"_version_\")); // logOk\n      }\n      assertReplicaValue(client, 1, \"inplace_updatable_float\", (newinplace_updatable_float + 2.0f),\n          \"inplace_updatable_float didn't match for replica at client: \" + ((HttpSolrClient) client).getBaseURL());\n      assertReplicaValue(client, 1, \"title_s\", \"title1_new\",\n          \"Title didn't match for replica at client: \" + ((HttpSolrClient) client).getBaseURL());\n    }\n    \n    // Try another round of these updates, this time with a delete request at the end.\n    // This is to ensure that the fetch missing update from leader doesn't bomb out if the \n    // document has been deleted on the leader later on\n    {\n      clearIndex();\n      commit();\n      shardToJetty.get(SHARD1).get(1).jetty.getDebugFilter().unsetDelay();\n      \n      updates.add(regularDeleteRequest(1));\n\n      shardToJetty.get(SHARD1).get(1).jetty.getDebugFilter().addDelay(\"Waiting for dependant update to timeout\", 1, 5999); // the first update\n      shardToJetty.get(SHARD1).get(1).jetty.getDebugFilter().addDelay(\"Waiting for dependant update to timeout\", 4, 5998); // the delete update\n\n      threadpool =\n          ExecutorUtil.newMDCAwareFixedThreadPool(updates.size() + 1, new SolrNamedThreadFactory(getTestName()));\n      for (UpdateRequest update : updates) {\n        AsyncUpdateWithRandomCommit task = new AsyncUpdateWithRandomCommit(update, cloudClient,\n                                                                           random().nextLong());\n        threadpool.submit(task);\n        \n        // while we can't guarantee/trust what order the updates are executed in, since multiple threads\n        // are involved, but we're trying to bias the thread scheduling to run them in the order submitted\n        Thread.sleep(100);\n      }\n\n      threadpool.shutdown();\n      assertTrue(\"Thread pool didn't terminate within 15 secs\", threadpool.awaitTermination(15, TimeUnit.SECONDS));\n\n      commit();\n\n      try (ZkShardTerms zkShardTerms = new ZkShardTerms(DEFAULT_COLLECTION, SHARD1, cloudClient.getZkStateReader().getZkClient())) {\n        for (int i=0; i<100; i++) {\n          Thread.sleep(10);\n          cloudClient.getZkStateReader().forceUpdateCollection(DEFAULT_COLLECTION);\n          ClusterState state = cloudClient.getZkStateReader().getClusterState();\n\n          int numActiveReplicas = 0;\n          for (Replica rep: state.getCollection(DEFAULT_COLLECTION).getSlice(SHARD1).getReplicas()) {\n            assertTrue(zkShardTerms.canBecomeLeader(rep.getName()));\n            if (rep.getState().equals(Replica.State.ACTIVE))\n              numActiveReplicas++;\n          }\n          assertEquals(\"The replica receiving reordered updates must not have gone down\", 3, numActiveReplicas);\n        }\n      }\n\n      for (SolrClient client: new SolrClient[] {LEADER, NONLEADERS.get(0), \n          NONLEADERS.get(1)}) { // nonleader 0 re-ordered replica, nonleader 1 well-ordered replica\n        SolrDocument doc = client.getById(String.valueOf(1), params(\"distrib\", \"false\"));\n        assertNull(\"This doc was supposed to have been deleted, but was: \" + doc, doc);\n      }\n\n    }\n    log.info(\"delayedReorderingFetchesMissingUpdateFromLeaderTest: This test passed fine...\");\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"415bbbe7da8065dd3c477bdc3c703c6425622998":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"598b5d23aa7c9732bf473c21a9cd309c44599394":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","415bbbe7da8065dd3c477bdc3c703c6425622998"],"5d7c1fb576b8c66316bde8f8a5309353434da7f3":["5048c558f8802f1689d38203111379406b171418"],"bb222a3f9d9421d5c95afce73013fbd8de07ea1f":["84f20f331d8001864545c7021812d8c6509c7593"],"2e11e54ce6015434b2aaadb49ca5071dbe7be50c":["5d7c1fb576b8c66316bde8f8a5309353434da7f3"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"fb03700c9690d16b15fb4f56f6ec36b128fd894e":["bb222a3f9d9421d5c95afce73013fbd8de07ea1f"],"b2d19164145b2a65acf62a657c75f4a249b649c0":["a966532d92cf9ba2856f15a8140151bb6b518e4b"],"5048c558f8802f1689d38203111379406b171418":["415bbbe7da8065dd3c477bdc3c703c6425622998"],"84f20f331d8001864545c7021812d8c6509c7593":["2e11e54ce6015434b2aaadb49ca5071dbe7be50c"],"a966532d92cf9ba2856f15a8140151bb6b518e4b":["fb03700c9690d16b15fb4f56f6ec36b128fd894e"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["b2d19164145b2a65acf62a657c75f4a249b649c0"]},"commit2Childs":{"415bbbe7da8065dd3c477bdc3c703c6425622998":["598b5d23aa7c9732bf473c21a9cd309c44599394","5048c558f8802f1689d38203111379406b171418"],"598b5d23aa7c9732bf473c21a9cd309c44599394":[],"5d7c1fb576b8c66316bde8f8a5309353434da7f3":["2e11e54ce6015434b2aaadb49ca5071dbe7be50c"],"bb222a3f9d9421d5c95afce73013fbd8de07ea1f":["fb03700c9690d16b15fb4f56f6ec36b128fd894e"],"2e11e54ce6015434b2aaadb49ca5071dbe7be50c":["84f20f331d8001864545c7021812d8c6509c7593"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["415bbbe7da8065dd3c477bdc3c703c6425622998","598b5d23aa7c9732bf473c21a9cd309c44599394"],"fb03700c9690d16b15fb4f56f6ec36b128fd894e":["a966532d92cf9ba2856f15a8140151bb6b518e4b"],"5048c558f8802f1689d38203111379406b171418":["5d7c1fb576b8c66316bde8f8a5309353434da7f3"],"b2d19164145b2a65acf62a657c75f4a249b649c0":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"84f20f331d8001864545c7021812d8c6509c7593":["bb222a3f9d9421d5c95afce73013fbd8de07ea1f"],"a966532d92cf9ba2856f15a8140151bb6b518e4b":["b2d19164145b2a65acf62a657c75f4a249b649c0"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["598b5d23aa7c9732bf473c21a9cd309c44599394","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}