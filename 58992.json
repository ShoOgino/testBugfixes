{"path":"lucene/sandbox/src/java/org/apache/lucene/search/TokenStreamToTermAutomatonQuery#toQuery(String,TokenStream).mjava","commits":[{"id":"06a4493f0c732d2928d1a4f773f15d19434aa8ba","date":1405856163,"type":0,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/sandbox/src/java/org/apache/lucene/search/TokenStreamToTermAutomatonQuery#toQuery(String,TokenStream).mjava","pathOld":"/dev/null","sourceNew":"  /** Pulls the graph (including {@link\n   *  PositionLengthAttribute}) from the provided {@link\n   *  TokenStream}, and creates the corresponding\n   *  automaton where arcs are bytes (or Unicode code points \n   *  if unicodeArcs = true) from each term. */\n  public TermAutomatonQuery toQuery(String field, TokenStream in) throws IOException {\n\n    final TermToBytesRefAttribute termBytesAtt = in.addAttribute(TermToBytesRefAttribute.class);\n    final PositionIncrementAttribute posIncAtt = in.addAttribute(PositionIncrementAttribute.class);\n    final PositionLengthAttribute posLengthAtt = in.addAttribute(PositionLengthAttribute.class);\n    final OffsetAttribute offsetAtt = in.addAttribute(OffsetAttribute.class);\n\n    final BytesRef term = termBytesAtt.getBytesRef();\n\n    in.reset();\n\n    TermAutomatonQuery query = new TermAutomatonQuery(field);\n\n    int pos = -1;\n    int lastPos = 0;\n    int maxOffset = 0;\n    int maxPos = -1;\n    int state = -1;\n    while (in.incrementToken()) {\n      int posInc = posIncAtt.getPositionIncrement();\n      if (preservePositionIncrements == false && posInc > 1) {\n        posInc = 1;\n      }\n      assert pos > -1 || posInc > 0;\n\n      if (posInc > 1) {\n        throw new IllegalArgumentException(\"cannot handle holes; to accept any term, use '*' term\");\n      }\n\n      if (posInc > 0) {\n        // New node:\n        pos += posInc;\n      }\n\n      int endPos = pos + posLengthAtt.getPositionLength();\n      while (state < endPos) {\n        state = query.createState();\n      }\n\n      termBytesAtt.fillBytesRef();\n      //System.out.println(pos + \"-\" + endPos + \": \" + term.utf8ToString() + \": posInc=\" + posInc);\n      if (term.length == 1 && term.bytes[term.offset] == (byte) '*') {\n        query.addAnyTransition(pos, endPos);\n      } else {\n        query.addTransition(pos, endPos, term);\n      }\n\n      maxOffset = Math.max(maxOffset, offsetAtt.endOffset());\n      maxPos = Math.max(maxPos, endPos);\n    }\n\n    in.end();\n\n    // TODO: look at endOffset?  ts2a did...\n\n    // TODO: this (setting \"last\" state as the only accept state) may be too simplistic?\n    query.setAccept(state, true);\n    query.finish();\n\n    return query;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"804b857d1066ab5185b3b9101bde41b0b71426ec","date":1435846169,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/sandbox/src/java/org/apache/lucene/search/TokenStreamToTermAutomatonQuery#toQuery(String,TokenStream).mjava","pathOld":"lucene/sandbox/src/java/org/apache/lucene/search/TokenStreamToTermAutomatonQuery#toQuery(String,TokenStream).mjava","sourceNew":"  /** Pulls the graph (including {@link\n   *  PositionLengthAttribute}) from the provided {@link\n   *  TokenStream}, and creates the corresponding\n   *  automaton where arcs are bytes (or Unicode code points \n   *  if unicodeArcs = true) from each term. */\n  public TermAutomatonQuery toQuery(String field, TokenStream in) throws IOException {\n\n    final TermToBytesRefAttribute termBytesAtt = in.addAttribute(TermToBytesRefAttribute.class);\n    final PositionIncrementAttribute posIncAtt = in.addAttribute(PositionIncrementAttribute.class);\n    final PositionLengthAttribute posLengthAtt = in.addAttribute(PositionLengthAttribute.class);\n    final OffsetAttribute offsetAtt = in.addAttribute(OffsetAttribute.class);\n\n    in.reset();\n\n    TermAutomatonQuery query = new TermAutomatonQuery(field);\n\n    int pos = -1;\n    int lastPos = 0;\n    int maxOffset = 0;\n    int maxPos = -1;\n    int state = -1;\n    while (in.incrementToken()) {\n      int posInc = posIncAtt.getPositionIncrement();\n      if (preservePositionIncrements == false && posInc > 1) {\n        posInc = 1;\n      }\n      assert pos > -1 || posInc > 0;\n\n      if (posInc > 1) {\n        throw new IllegalArgumentException(\"cannot handle holes; to accept any term, use '*' term\");\n      }\n\n      if (posInc > 0) {\n        // New node:\n        pos += posInc;\n      }\n\n      int endPos = pos + posLengthAtt.getPositionLength();\n      while (state < endPos) {\n        state = query.createState();\n      }\n\n      BytesRef term = termBytesAtt.getBytesRef();\n      //System.out.println(pos + \"-\" + endPos + \": \" + term.utf8ToString() + \": posInc=\" + posInc);\n      if (term.length == 1 && term.bytes[term.offset] == (byte) '*') {\n        query.addAnyTransition(pos, endPos);\n      } else {\n        query.addTransition(pos, endPos, term);\n      }\n\n      maxOffset = Math.max(maxOffset, offsetAtt.endOffset());\n      maxPos = Math.max(maxPos, endPos);\n    }\n\n    in.end();\n\n    // TODO: look at endOffset?  ts2a did...\n\n    // TODO: this (setting \"last\" state as the only accept state) may be too simplistic?\n    query.setAccept(state, true);\n    query.finish();\n\n    return query;\n  }\n\n","sourceOld":"  /** Pulls the graph (including {@link\n   *  PositionLengthAttribute}) from the provided {@link\n   *  TokenStream}, and creates the corresponding\n   *  automaton where arcs are bytes (or Unicode code points \n   *  if unicodeArcs = true) from each term. */\n  public TermAutomatonQuery toQuery(String field, TokenStream in) throws IOException {\n\n    final TermToBytesRefAttribute termBytesAtt = in.addAttribute(TermToBytesRefAttribute.class);\n    final PositionIncrementAttribute posIncAtt = in.addAttribute(PositionIncrementAttribute.class);\n    final PositionLengthAttribute posLengthAtt = in.addAttribute(PositionLengthAttribute.class);\n    final OffsetAttribute offsetAtt = in.addAttribute(OffsetAttribute.class);\n\n    final BytesRef term = termBytesAtt.getBytesRef();\n\n    in.reset();\n\n    TermAutomatonQuery query = new TermAutomatonQuery(field);\n\n    int pos = -1;\n    int lastPos = 0;\n    int maxOffset = 0;\n    int maxPos = -1;\n    int state = -1;\n    while (in.incrementToken()) {\n      int posInc = posIncAtt.getPositionIncrement();\n      if (preservePositionIncrements == false && posInc > 1) {\n        posInc = 1;\n      }\n      assert pos > -1 || posInc > 0;\n\n      if (posInc > 1) {\n        throw new IllegalArgumentException(\"cannot handle holes; to accept any term, use '*' term\");\n      }\n\n      if (posInc > 0) {\n        // New node:\n        pos += posInc;\n      }\n\n      int endPos = pos + posLengthAtt.getPositionLength();\n      while (state < endPos) {\n        state = query.createState();\n      }\n\n      termBytesAtt.fillBytesRef();\n      //System.out.println(pos + \"-\" + endPos + \": \" + term.utf8ToString() + \": posInc=\" + posInc);\n      if (term.length == 1 && term.bytes[term.offset] == (byte) '*') {\n        query.addAnyTransition(pos, endPos);\n      } else {\n        query.addTransition(pos, endPos, term);\n      }\n\n      maxOffset = Math.max(maxOffset, offsetAtt.endOffset());\n      maxPos = Math.max(maxPos, endPos);\n    }\n\n    in.end();\n\n    // TODO: look at endOffset?  ts2a did...\n\n    // TODO: this (setting \"last\" state as the only accept state) may be too simplistic?\n    query.setAccept(state, true);\n    query.finish();\n\n    return query;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"804b857d1066ab5185b3b9101bde41b0b71426ec":["06a4493f0c732d2928d1a4f773f15d19434aa8ba"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"06a4493f0c732d2928d1a4f773f15d19434aa8ba":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["804b857d1066ab5185b3b9101bde41b0b71426ec"]},"commit2Childs":{"804b857d1066ab5185b3b9101bde41b0b71426ec":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["06a4493f0c732d2928d1a4f773f15d19434aa8ba"],"06a4493f0c732d2928d1a4f773f15d19434aa8ba":["804b857d1066ab5185b3b9101bde41b0b71426ec"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}