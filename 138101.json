{"path":"solr/core/src/java/org/apache/solr/search/ExtendedDismaxQParser[ExtendedDismaxQParserPlugin].ExtendedSolrQueryParser#noStopwordFilterAnalyzer(String).mjava","commits":[{"id":"97a1d065fbe56cbf9eaf80cd3f8d4477203dda70","date":1315971416,"type":0,"author":"Christopher John Male","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/ExtendedDismaxQParser[ExtendedDismaxQParserPlugin].ExtendedSolrQueryParser#noStopwordFilterAnalyzer(String).mjava","pathOld":"/dev/null","sourceNew":"    private Analyzer noStopwordFilterAnalyzer(String fieldName) {\n      FieldType ft = parser.getReq().getSchema().getFieldType(fieldName);\n      Analyzer qa = ft.getQueryAnalyzer();\n      if (!(qa instanceof TokenizerChain)) {\n        return qa;\n      }\n\n      TokenizerChain tcq = (TokenizerChain) qa;\n      Analyzer ia = ft.getAnalyzer();\n      if (ia == qa || !(ia instanceof TokenizerChain)) {\n        return qa;\n      }\n      TokenizerChain tci = (TokenizerChain) ia;\n\n      // make sure that there isn't a stop filter in the indexer\n      for (TokenFilterFactory tf : tci.getTokenFilterFactories()) {\n        if (tf instanceof StopFilterFactory) {\n          return qa;\n        }\n      }\n\n      // now if there is a stop filter in the query analyzer, remove it\n      int stopIdx = -1;\n      TokenFilterFactory[] facs = tcq.getTokenFilterFactories();\n\n      for (int i = 0; i < facs.length; i++) {\n        TokenFilterFactory tf = facs[i];\n        if (tf instanceof StopFilterFactory) {\n          stopIdx = i;\n          break;\n        }\n      }\n\n      if (stopIdx == -1) {\n        // no stop filter exists\n        return qa;\n      }\n\n      TokenFilterFactory[] newtf = new TokenFilterFactory[facs.length - 1];\n      for (int i = 0, j = 0; i < facs.length; i++) {\n        if (i == stopIdx) continue;\n        newtf[j++] = facs[i];\n      }\n\n      TokenizerChain newa = new TokenizerChain(tcq.getTokenizerFactory(), newtf);\n      newa.setPositionIncrementGap(tcq.getPositionIncrementGap(fieldName));\n      return newa;\n    }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["829fd6c12636f3099b6a266518d961b41e7c5b45","829fd6c12636f3099b6a266518d961b41e7c5b45"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"c7e79e31f55cbb444e3023d430a340658755aa31","date":1357666399,"type":5,"author":"Chris M. Hostetter","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/ExtendedDismaxQParser.ExtendedSolrQueryParser#noStopwordFilterAnalyzer(String).mjava","pathOld":"solr/core/src/java/org/apache/solr/search/ExtendedDismaxQParser[ExtendedDismaxQParserPlugin].ExtendedSolrQueryParser#noStopwordFilterAnalyzer(String).mjava","sourceNew":"    private Analyzer noStopwordFilterAnalyzer(String fieldName) {\n      FieldType ft = parser.getReq().getSchema().getFieldType(fieldName);\n      Analyzer qa = ft.getQueryAnalyzer();\n      if (!(qa instanceof TokenizerChain)) {\n        return qa;\n      }\n      \n      TokenizerChain tcq = (TokenizerChain) qa;\n      Analyzer ia = ft.getAnalyzer();\n      if (ia == qa || !(ia instanceof TokenizerChain)) {\n        return qa;\n      }\n      TokenizerChain tci = (TokenizerChain) ia;\n      \n      // make sure that there isn't a stop filter in the indexer\n      for (TokenFilterFactory tf : tci.getTokenFilterFactories()) {\n        if (tf instanceof StopFilterFactory) {\n          return qa;\n        }\n      }\n      \n      // now if there is a stop filter in the query analyzer, remove it\n      int stopIdx = -1;\n      TokenFilterFactory[] facs = tcq.getTokenFilterFactories();\n      \n      for (int i = 0; i < facs.length; i++) {\n        TokenFilterFactory tf = facs[i];\n        if (tf instanceof StopFilterFactory) {\n          stopIdx = i;\n          break;\n        }\n      }\n      \n      if (stopIdx == -1) {\n        // no stop filter exists\n        return qa;\n      }\n      \n      TokenFilterFactory[] newtf = new TokenFilterFactory[facs.length - 1];\n      for (int i = 0, j = 0; i < facs.length; i++) {\n        if (i == stopIdx) continue;\n        newtf[j++] = facs[i];\n      }\n      \n      TokenizerChain newa = new TokenizerChain(tcq.getTokenizerFactory(), newtf);\n      newa.setPositionIncrementGap(tcq.getPositionIncrementGap(fieldName));\n      return newa;\n    }\n\n","sourceOld":"    private Analyzer noStopwordFilterAnalyzer(String fieldName) {\n      FieldType ft = parser.getReq().getSchema().getFieldType(fieldName);\n      Analyzer qa = ft.getQueryAnalyzer();\n      if (!(qa instanceof TokenizerChain)) {\n        return qa;\n      }\n\n      TokenizerChain tcq = (TokenizerChain) qa;\n      Analyzer ia = ft.getAnalyzer();\n      if (ia == qa || !(ia instanceof TokenizerChain)) {\n        return qa;\n      }\n      TokenizerChain tci = (TokenizerChain) ia;\n\n      // make sure that there isn't a stop filter in the indexer\n      for (TokenFilterFactory tf : tci.getTokenFilterFactories()) {\n        if (tf instanceof StopFilterFactory) {\n          return qa;\n        }\n      }\n\n      // now if there is a stop filter in the query analyzer, remove it\n      int stopIdx = -1;\n      TokenFilterFactory[] facs = tcq.getTokenFilterFactories();\n\n      for (int i = 0; i < facs.length; i++) {\n        TokenFilterFactory tf = facs[i];\n        if (tf instanceof StopFilterFactory) {\n          stopIdx = i;\n          break;\n        }\n      }\n\n      if (stopIdx == -1) {\n        // no stop filter exists\n        return qa;\n      }\n\n      TokenFilterFactory[] newtf = new TokenFilterFactory[facs.length - 1];\n      for (int i = 0, j = 0; i < facs.length; i++) {\n        if (i == stopIdx) continue;\n        newtf[j++] = facs[i];\n      }\n\n      TokenizerChain newa = new TokenizerChain(tcq.getTokenizerFactory(), newtf);\n      newa.setPositionIncrementGap(tcq.getPositionIncrementGap(fieldName));\n      return newa;\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"4e6354dd7c71fe122926fc53d7d29f715b1283db","date":1357915185,"type":5,"author":"Robert Muir","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/search/ExtendedDismaxQParser.ExtendedSolrQueryParser#noStopwordFilterAnalyzer(String).mjava","pathOld":"solr/core/src/java/org/apache/solr/search/ExtendedDismaxQParser[ExtendedDismaxQParserPlugin].ExtendedSolrQueryParser#noStopwordFilterAnalyzer(String).mjava","sourceNew":"    private Analyzer noStopwordFilterAnalyzer(String fieldName) {\n      FieldType ft = parser.getReq().getSchema().getFieldType(fieldName);\n      Analyzer qa = ft.getQueryAnalyzer();\n      if (!(qa instanceof TokenizerChain)) {\n        return qa;\n      }\n      \n      TokenizerChain tcq = (TokenizerChain) qa;\n      Analyzer ia = ft.getAnalyzer();\n      if (ia == qa || !(ia instanceof TokenizerChain)) {\n        return qa;\n      }\n      TokenizerChain tci = (TokenizerChain) ia;\n      \n      // make sure that there isn't a stop filter in the indexer\n      for (TokenFilterFactory tf : tci.getTokenFilterFactories()) {\n        if (tf instanceof StopFilterFactory) {\n          return qa;\n        }\n      }\n      \n      // now if there is a stop filter in the query analyzer, remove it\n      int stopIdx = -1;\n      TokenFilterFactory[] facs = tcq.getTokenFilterFactories();\n      \n      for (int i = 0; i < facs.length; i++) {\n        TokenFilterFactory tf = facs[i];\n        if (tf instanceof StopFilterFactory) {\n          stopIdx = i;\n          break;\n        }\n      }\n      \n      if (stopIdx == -1) {\n        // no stop filter exists\n        return qa;\n      }\n      \n      TokenFilterFactory[] newtf = new TokenFilterFactory[facs.length - 1];\n      for (int i = 0, j = 0; i < facs.length; i++) {\n        if (i == stopIdx) continue;\n        newtf[j++] = facs[i];\n      }\n      \n      TokenizerChain newa = new TokenizerChain(tcq.getTokenizerFactory(), newtf);\n      newa.setPositionIncrementGap(tcq.getPositionIncrementGap(fieldName));\n      return newa;\n    }\n\n","sourceOld":"    private Analyzer noStopwordFilterAnalyzer(String fieldName) {\n      FieldType ft = parser.getReq().getSchema().getFieldType(fieldName);\n      Analyzer qa = ft.getQueryAnalyzer();\n      if (!(qa instanceof TokenizerChain)) {\n        return qa;\n      }\n\n      TokenizerChain tcq = (TokenizerChain) qa;\n      Analyzer ia = ft.getAnalyzer();\n      if (ia == qa || !(ia instanceof TokenizerChain)) {\n        return qa;\n      }\n      TokenizerChain tci = (TokenizerChain) ia;\n\n      // make sure that there isn't a stop filter in the indexer\n      for (TokenFilterFactory tf : tci.getTokenFilterFactories()) {\n        if (tf instanceof StopFilterFactory) {\n          return qa;\n        }\n      }\n\n      // now if there is a stop filter in the query analyzer, remove it\n      int stopIdx = -1;\n      TokenFilterFactory[] facs = tcq.getTokenFilterFactories();\n\n      for (int i = 0; i < facs.length; i++) {\n        TokenFilterFactory tf = facs[i];\n        if (tf instanceof StopFilterFactory) {\n          stopIdx = i;\n          break;\n        }\n      }\n\n      if (stopIdx == -1) {\n        // no stop filter exists\n        return qa;\n      }\n\n      TokenFilterFactory[] newtf = new TokenFilterFactory[facs.length - 1];\n      for (int i = 0, j = 0; i < facs.length; i++) {\n        if (i == stopIdx) continue;\n        newtf[j++] = facs[i];\n      }\n\n      TokenizerChain newa = new TokenizerChain(tcq.getTokenizerFactory(), newtf);\n      newa.setPositionIncrementGap(tcq.getPositionIncrementGap(fieldName));\n      return newa;\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"c7e79e31f55cbb444e3023d430a340658755aa31":["97a1d065fbe56cbf9eaf80cd3f8d4477203dda70"],"97a1d065fbe56cbf9eaf80cd3f8d4477203dda70":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"4e6354dd7c71fe122926fc53d7d29f715b1283db":["97a1d065fbe56cbf9eaf80cd3f8d4477203dda70","c7e79e31f55cbb444e3023d430a340658755aa31"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["c7e79e31f55cbb444e3023d430a340658755aa31"]},"commit2Childs":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["97a1d065fbe56cbf9eaf80cd3f8d4477203dda70"],"c7e79e31f55cbb444e3023d430a340658755aa31":["4e6354dd7c71fe122926fc53d7d29f715b1283db","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"97a1d065fbe56cbf9eaf80cd3f8d4477203dda70":["c7e79e31f55cbb444e3023d430a340658755aa31","4e6354dd7c71fe122926fc53d7d29f715b1283db"],"4e6354dd7c71fe122926fc53d7d29f715b1283db":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["4e6354dd7c71fe122926fc53d7d29f715b1283db","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}