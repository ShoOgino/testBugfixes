{"path":"lucene/codecs/src/java/org/apache/lucene/codecs/simpletext/SimpleTextPointWriter#writeField(FieldInfo,PointReader).mjava","commits":[{"id":"cab7a79353f33d1a94cd307bf33aa5148601ebe6","date":1453391888,"type":1,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/codecs/src/java/org/apache/lucene/codecs/simpletext/SimpleTextPointWriter#writeField(FieldInfo,PointReader).mjava","pathOld":"lucene/codecs/src/java/org/apache/lucene/codecs/simpletext/SimpleTextDimensionalWriter#writeField(FieldInfo,DimensionalReader).mjava","sourceNew":"  @Override\n  public void writeField(FieldInfo fieldInfo, PointReader values) throws IOException {\n\n    // We use the normal BKDWriter, but subclass to customize how it writes the index and blocks to disk:\n    BKDWriter writer = new BKDWriter(writeState.directory,\n                                     writeState.segmentInfo.name,\n                                     fieldInfo.getPointDimensionCount(),\n                                     fieldInfo.getPointNumBytes(),\n                                     BKDWriter.DEFAULT_MAX_POINTS_IN_LEAF_NODE,\n                                     BKDWriter.DEFAULT_MAX_MB_SORT_IN_HEAP) {\n\n        @Override\n        protected void writeIndex(IndexOutput out, long[] leafBlockFPs, byte[] splitPackedValues) throws IOException {\n          write(out, NUM_DIMS);\n          writeInt(out, numDims);\n          newline(out);\n\n          write(out, BYTES_PER_DIM);\n          writeInt(out, bytesPerDim);\n          newline(out);\n\n          write(out, MAX_LEAF_POINTS);\n          writeInt(out, maxPointsInLeafNode);\n          newline(out);\n\n          write(out, INDEX_COUNT);\n          writeInt(out, leafBlockFPs.length);\n          newline(out);\n\n          write(out, MIN_VALUE);\n          BytesRef br = new BytesRef(minPackedValue, 0, minPackedValue.length);\n          write(out, br.toString());\n          newline(out);\n\n          write(out, MAX_VALUE);\n          br = new BytesRef(maxPackedValue, 0, maxPackedValue.length);\n          write(out, br.toString());\n          newline(out);\n\n          for(int i=0;i<leafBlockFPs.length;i++) {\n            write(out, BLOCK_FP);\n            writeLong(out, leafBlockFPs[i]);\n            newline(out);\n          }\n\n          assert (splitPackedValues.length % (1 + fieldInfo.getPointNumBytes())) == 0;\n          int count = splitPackedValues.length / (1 + fieldInfo.getPointNumBytes());\n          assert count == leafBlockFPs.length;\n\n          write(out, SPLIT_COUNT);\n          writeInt(out, count);\n          newline(out);\n\n          for(int i=0;i<count;i++) {\n            write(out, SPLIT_DIM);\n            writeInt(out, splitPackedValues[i * (1 + fieldInfo.getPointNumBytes())] & 0xff);\n            newline(out);\n            write(out, SPLIT_VALUE);\n            br = new BytesRef(splitPackedValues, 1+(i * (1+fieldInfo.getPointNumBytes())), fieldInfo.getPointNumBytes());\n            write(out, br.toString());\n            newline(out);\n          }\n        }\n\n        @Override\n        protected void writeLeafBlockDocs(IndexOutput out, int[] docIDs, int start, int count) throws IOException {\n          write(out, BLOCK_COUNT);\n          writeInt(out, count);\n          newline(out);\n          for(int i=0;i<count;i++) {\n            write(out, BLOCK_DOC_ID);\n            writeInt(out, docIDs[start+i]);\n            newline(out);\n          }\n        }\n\n        @Override\n        protected void writeCommonPrefixes(IndexOutput out, int[] commonPrefixLengths, byte[] packedValue) {\n          // NOTE: we don't do prefix coding, so we ignore commonPrefixLengths\n        }\n\n        @Override\n        protected void writeLeafBlockPackedValue(IndexOutput out, int[] commonPrefixLengths, byte[] bytes) throws IOException {\n          // NOTE: we don't do prefix coding, so we ignore commonPrefixLengths\n          assert bytes.length == packedBytesLength;\n          write(out, BLOCK_VALUE);\n          write(out, new BytesRef(bytes, 0, bytes.length).toString());\n          newline(out);\n        }          \n      };\n\n    values.intersect(fieldInfo.name, new IntersectVisitor() {\n        @Override\n        public void visit(int docID) {\n          throw new IllegalStateException();\n        }\n\n        public void visit(int docID, byte[] packedValue) throws IOException {\n          writer.add(packedValue, docID);\n        }\n\n        @Override\n        public Relation compare(byte[] minPackedValue, byte[] maxPackedValue) {\n          return Relation.CELL_CROSSES_QUERY;\n        }\n      });\n\n    // We could have 0 points on merge since all docs with points may be deleted:\n    if (writer.getPointCount() > 0) {\n      indexFPs.put(fieldInfo.name, writer.finish(dataOut));\n    }\n  }\n\n","sourceOld":"  @Override\n  public void writeField(FieldInfo fieldInfo, DimensionalReader values) throws IOException {\n\n    // We use the normal BKDWriter, but subclass to customize how it writes the index and blocks to disk:\n    BKDWriter writer = new BKDWriter(writeState.directory,\n                                     writeState.segmentInfo.name,\n                                     fieldInfo.getDimensionCount(),\n                                     fieldInfo.getDimensionNumBytes(),\n                                     BKDWriter.DEFAULT_MAX_POINTS_IN_LEAF_NODE,\n                                     BKDWriter.DEFAULT_MAX_MB_SORT_IN_HEAP) {\n\n        @Override\n        protected void writeIndex(IndexOutput out, long[] leafBlockFPs, byte[] splitPackedValues) throws IOException {\n          write(out, NUM_DIMS);\n          writeInt(out, numDims);\n          newline(out);\n\n          write(out, BYTES_PER_DIM);\n          writeInt(out, bytesPerDim);\n          newline(out);\n\n          write(out, MAX_LEAF_POINTS);\n          writeInt(out, maxPointsInLeafNode);\n          newline(out);\n\n          write(out, INDEX_COUNT);\n          writeInt(out, leafBlockFPs.length);\n          newline(out);\n\n          write(out, MIN_VALUE);\n          BytesRef br = new BytesRef(minPackedValue, 0, minPackedValue.length);\n          write(out, br.toString());\n          newline(out);\n\n          write(out, MAX_VALUE);\n          br = new BytesRef(maxPackedValue, 0, maxPackedValue.length);\n          write(out, br.toString());\n          newline(out);\n\n          for(int i=0;i<leafBlockFPs.length;i++) {\n            write(out, BLOCK_FP);\n            writeLong(out, leafBlockFPs[i]);\n            newline(out);\n          }\n\n          assert (splitPackedValues.length % (1 + fieldInfo.getDimensionNumBytes())) == 0;\n          int count = splitPackedValues.length / (1 + fieldInfo.getDimensionNumBytes());\n          assert count == leafBlockFPs.length;\n\n          write(out, SPLIT_COUNT);\n          writeInt(out, count);\n          newline(out);\n\n          for(int i=0;i<count;i++) {\n            write(out, SPLIT_DIM);\n            writeInt(out, splitPackedValues[i * (1 + fieldInfo.getDimensionNumBytes())] & 0xff);\n            newline(out);\n            write(out, SPLIT_VALUE);\n            br = new BytesRef(splitPackedValues, 1+(i * (1+fieldInfo.getDimensionNumBytes())), fieldInfo.getDimensionNumBytes());\n            write(out, br.toString());\n            newline(out);\n          }\n        }\n\n        @Override\n        protected void writeLeafBlockDocs(IndexOutput out, int[] docIDs, int start, int count) throws IOException {\n          write(out, BLOCK_COUNT);\n          writeInt(out, count);\n          newline(out);\n          for(int i=0;i<count;i++) {\n            write(out, BLOCK_DOC_ID);\n            writeInt(out, docIDs[start+i]);\n            newline(out);\n          }\n        }\n\n        @Override\n        protected void writeCommonPrefixes(IndexOutput out, int[] commonPrefixLengths, byte[] packedValue) {\n          // NOTE: we don't do prefix coding, so we ignore commonPrefixLengths\n        }\n\n        @Override\n        protected void writeLeafBlockPackedValue(IndexOutput out, int[] commonPrefixLengths, byte[] bytes) throws IOException {\n          // NOTE: we don't do prefix coding, so we ignore commonPrefixLengths\n          assert bytes.length == packedBytesLength;\n          write(out, BLOCK_VALUE);\n          write(out, new BytesRef(bytes, 0, bytes.length).toString());\n          newline(out);\n        }          \n      };\n\n    values.intersect(fieldInfo.name, new IntersectVisitor() {\n        @Override\n        public void visit(int docID) {\n          throw new IllegalStateException();\n        }\n\n        public void visit(int docID, byte[] packedValue) throws IOException {\n          writer.add(packedValue, docID);\n        }\n\n        @Override\n        public Relation compare(byte[] minPackedValue, byte[] maxPackedValue) {\n          return Relation.CELL_CROSSES_QUERY;\n        }\n      });\n\n    // We could have 0 points on merge since all docs with dimensional fields may be deleted:\n    if (writer.getPointCount() > 0) {\n      indexFPs.put(fieldInfo.name, writer.finish(dataOut));\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d2d93e80a51ae7994e1639fbd83763acdef9beb1","date":1454512766,"type":3,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/codecs/src/java/org/apache/lucene/codecs/simpletext/SimpleTextPointWriter#writeField(FieldInfo,PointReader).mjava","pathOld":"lucene/codecs/src/java/org/apache/lucene/codecs/simpletext/SimpleTextPointWriter#writeField(FieldInfo,PointReader).mjava","sourceNew":"  @Override\n  public void writeField(FieldInfo fieldInfo, PointReader values) throws IOException {\n\n    // We use the normal BKDWriter, but subclass to customize how it writes the index and blocks to disk:\n    try (BKDWriter writer = new BKDWriter(writeState.directory,\n                                     writeState.segmentInfo.name,\n                                     fieldInfo.getPointDimensionCount(),\n                                     fieldInfo.getPointNumBytes(),\n                                     BKDWriter.DEFAULT_MAX_POINTS_IN_LEAF_NODE,\n                                     BKDWriter.DEFAULT_MAX_MB_SORT_IN_HEAP) {\n\n        @Override\n        protected void writeIndex(IndexOutput out, long[] leafBlockFPs, byte[] splitPackedValues) throws IOException {\n          write(out, NUM_DIMS);\n          writeInt(out, numDims);\n          newline(out);\n\n          write(out, BYTES_PER_DIM);\n          writeInt(out, bytesPerDim);\n          newline(out);\n\n          write(out, MAX_LEAF_POINTS);\n          writeInt(out, maxPointsInLeafNode);\n          newline(out);\n\n          write(out, INDEX_COUNT);\n          writeInt(out, leafBlockFPs.length);\n          newline(out);\n\n          write(out, MIN_VALUE);\n          BytesRef br = new BytesRef(minPackedValue, 0, minPackedValue.length);\n          write(out, br.toString());\n          newline(out);\n\n          write(out, MAX_VALUE);\n          br = new BytesRef(maxPackedValue, 0, maxPackedValue.length);\n          write(out, br.toString());\n          newline(out);\n\n          for(int i=0;i<leafBlockFPs.length;i++) {\n            write(out, BLOCK_FP);\n            writeLong(out, leafBlockFPs[i]);\n            newline(out);\n          }\n\n          assert (splitPackedValues.length % (1 + fieldInfo.getPointNumBytes())) == 0;\n          int count = splitPackedValues.length / (1 + fieldInfo.getPointNumBytes());\n          assert count == leafBlockFPs.length;\n\n          write(out, SPLIT_COUNT);\n          writeInt(out, count);\n          newline(out);\n\n          for(int i=0;i<count;i++) {\n            write(out, SPLIT_DIM);\n            writeInt(out, splitPackedValues[i * (1 + fieldInfo.getPointNumBytes())] & 0xff);\n            newline(out);\n            write(out, SPLIT_VALUE);\n            br = new BytesRef(splitPackedValues, 1+(i * (1+fieldInfo.getPointNumBytes())), fieldInfo.getPointNumBytes());\n            write(out, br.toString());\n            newline(out);\n          }\n        }\n\n        @Override\n        protected void writeLeafBlockDocs(IndexOutput out, int[] docIDs, int start, int count) throws IOException {\n          write(out, BLOCK_COUNT);\n          writeInt(out, count);\n          newline(out);\n          for(int i=0;i<count;i++) {\n            write(out, BLOCK_DOC_ID);\n            writeInt(out, docIDs[start+i]);\n            newline(out);\n          }\n        }\n\n        @Override\n        protected void writeCommonPrefixes(IndexOutput out, int[] commonPrefixLengths, byte[] packedValue) {\n          // NOTE: we don't do prefix coding, so we ignore commonPrefixLengths\n        }\n\n        @Override\n        protected void writeLeafBlockPackedValue(IndexOutput out, int[] commonPrefixLengths, byte[] bytes) throws IOException {\n          // NOTE: we don't do prefix coding, so we ignore commonPrefixLengths\n          assert bytes.length == packedBytesLength;\n          write(out, BLOCK_VALUE);\n          write(out, new BytesRef(bytes, 0, bytes.length).toString());\n          newline(out);\n        }          \n      }) {\n\n      values.intersect(fieldInfo.name, new IntersectVisitor() {\n          @Override\n          public void visit(int docID) {\n            throw new IllegalStateException();\n          }\n\n          public void visit(int docID, byte[] packedValue) throws IOException {\n            writer.add(packedValue, docID);\n          }\n\n          @Override\n          public Relation compare(byte[] minPackedValue, byte[] maxPackedValue) {\n            return Relation.CELL_CROSSES_QUERY;\n          }\n        });\n\n      // We could have 0 points on merge since all docs with points may be deleted:\n      if (writer.getPointCount() > 0) {\n        indexFPs.put(fieldInfo.name, writer.finish(dataOut));\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  public void writeField(FieldInfo fieldInfo, PointReader values) throws IOException {\n\n    // We use the normal BKDWriter, but subclass to customize how it writes the index and blocks to disk:\n    BKDWriter writer = new BKDWriter(writeState.directory,\n                                     writeState.segmentInfo.name,\n                                     fieldInfo.getPointDimensionCount(),\n                                     fieldInfo.getPointNumBytes(),\n                                     BKDWriter.DEFAULT_MAX_POINTS_IN_LEAF_NODE,\n                                     BKDWriter.DEFAULT_MAX_MB_SORT_IN_HEAP) {\n\n        @Override\n        protected void writeIndex(IndexOutput out, long[] leafBlockFPs, byte[] splitPackedValues) throws IOException {\n          write(out, NUM_DIMS);\n          writeInt(out, numDims);\n          newline(out);\n\n          write(out, BYTES_PER_DIM);\n          writeInt(out, bytesPerDim);\n          newline(out);\n\n          write(out, MAX_LEAF_POINTS);\n          writeInt(out, maxPointsInLeafNode);\n          newline(out);\n\n          write(out, INDEX_COUNT);\n          writeInt(out, leafBlockFPs.length);\n          newline(out);\n\n          write(out, MIN_VALUE);\n          BytesRef br = new BytesRef(minPackedValue, 0, minPackedValue.length);\n          write(out, br.toString());\n          newline(out);\n\n          write(out, MAX_VALUE);\n          br = new BytesRef(maxPackedValue, 0, maxPackedValue.length);\n          write(out, br.toString());\n          newline(out);\n\n          for(int i=0;i<leafBlockFPs.length;i++) {\n            write(out, BLOCK_FP);\n            writeLong(out, leafBlockFPs[i]);\n            newline(out);\n          }\n\n          assert (splitPackedValues.length % (1 + fieldInfo.getPointNumBytes())) == 0;\n          int count = splitPackedValues.length / (1 + fieldInfo.getPointNumBytes());\n          assert count == leafBlockFPs.length;\n\n          write(out, SPLIT_COUNT);\n          writeInt(out, count);\n          newline(out);\n\n          for(int i=0;i<count;i++) {\n            write(out, SPLIT_DIM);\n            writeInt(out, splitPackedValues[i * (1 + fieldInfo.getPointNumBytes())] & 0xff);\n            newline(out);\n            write(out, SPLIT_VALUE);\n            br = new BytesRef(splitPackedValues, 1+(i * (1+fieldInfo.getPointNumBytes())), fieldInfo.getPointNumBytes());\n            write(out, br.toString());\n            newline(out);\n          }\n        }\n\n        @Override\n        protected void writeLeafBlockDocs(IndexOutput out, int[] docIDs, int start, int count) throws IOException {\n          write(out, BLOCK_COUNT);\n          writeInt(out, count);\n          newline(out);\n          for(int i=0;i<count;i++) {\n            write(out, BLOCK_DOC_ID);\n            writeInt(out, docIDs[start+i]);\n            newline(out);\n          }\n        }\n\n        @Override\n        protected void writeCommonPrefixes(IndexOutput out, int[] commonPrefixLengths, byte[] packedValue) {\n          // NOTE: we don't do prefix coding, so we ignore commonPrefixLengths\n        }\n\n        @Override\n        protected void writeLeafBlockPackedValue(IndexOutput out, int[] commonPrefixLengths, byte[] bytes) throws IOException {\n          // NOTE: we don't do prefix coding, so we ignore commonPrefixLengths\n          assert bytes.length == packedBytesLength;\n          write(out, BLOCK_VALUE);\n          write(out, new BytesRef(bytes, 0, bytes.length).toString());\n          newline(out);\n        }          \n      };\n\n    values.intersect(fieldInfo.name, new IntersectVisitor() {\n        @Override\n        public void visit(int docID) {\n          throw new IllegalStateException();\n        }\n\n        public void visit(int docID, byte[] packedValue) throws IOException {\n          writer.add(packedValue, docID);\n        }\n\n        @Override\n        public Relation compare(byte[] minPackedValue, byte[] maxPackedValue) {\n          return Relation.CELL_CROSSES_QUERY;\n        }\n      });\n\n    // We could have 0 points on merge since all docs with points may be deleted:\n    if (writer.getPointCount() > 0) {\n      indexFPs.put(fieldInfo.name, writer.finish(dataOut));\n    }\n  }\n\n","bugFix":["1904709ea0185dc04e3d77ea01c79e909caf2796","d0c44765ee347f8c49bc6c0ffe1cdfb42738bd6a","cab7a79353f33d1a94cd307bf33aa5148601ebe6","ca792c26af46bd6c4a08d81117c60440cf6a7e3d"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"acd1f5a977dc3b97799ed300423294e2c457774f","date":1454537003,"type":3,"author":"Mike McCandless","isMerge":true,"pathNew":"lucene/codecs/src/java/org/apache/lucene/codecs/simpletext/SimpleTextPointWriter#writeField(FieldInfo,PointReader).mjava","pathOld":"lucene/codecs/src/java/org/apache/lucene/codecs/simpletext/SimpleTextPointWriter#writeField(FieldInfo,PointReader).mjava","sourceNew":"  @Override\n  public void writeField(FieldInfo fieldInfo, PointReader values) throws IOException {\n\n    // We use the normal BKDWriter, but subclass to customize how it writes the index and blocks to disk:\n    try (BKDWriter writer = new BKDWriter(writeState.directory,\n                                     writeState.segmentInfo.name,\n                                     fieldInfo.getPointDimensionCount(),\n                                     fieldInfo.getPointNumBytes(),\n                                     BKDWriter.DEFAULT_MAX_POINTS_IN_LEAF_NODE,\n                                     BKDWriter.DEFAULT_MAX_MB_SORT_IN_HEAP) {\n\n        @Override\n        protected void writeIndex(IndexOutput out, long[] leafBlockFPs, byte[] splitPackedValues) throws IOException {\n          write(out, NUM_DIMS);\n          writeInt(out, numDims);\n          newline(out);\n\n          write(out, BYTES_PER_DIM);\n          writeInt(out, bytesPerDim);\n          newline(out);\n\n          write(out, MAX_LEAF_POINTS);\n          writeInt(out, maxPointsInLeafNode);\n          newline(out);\n\n          write(out, INDEX_COUNT);\n          writeInt(out, leafBlockFPs.length);\n          newline(out);\n\n          write(out, MIN_VALUE);\n          BytesRef br = new BytesRef(minPackedValue, 0, minPackedValue.length);\n          write(out, br.toString());\n          newline(out);\n\n          write(out, MAX_VALUE);\n          br = new BytesRef(maxPackedValue, 0, maxPackedValue.length);\n          write(out, br.toString());\n          newline(out);\n\n          for(int i=0;i<leafBlockFPs.length;i++) {\n            write(out, BLOCK_FP);\n            writeLong(out, leafBlockFPs[i]);\n            newline(out);\n          }\n\n          assert (splitPackedValues.length % (1 + fieldInfo.getPointNumBytes())) == 0;\n          int count = splitPackedValues.length / (1 + fieldInfo.getPointNumBytes());\n          assert count == leafBlockFPs.length;\n\n          write(out, SPLIT_COUNT);\n          writeInt(out, count);\n          newline(out);\n\n          for(int i=0;i<count;i++) {\n            write(out, SPLIT_DIM);\n            writeInt(out, splitPackedValues[i * (1 + fieldInfo.getPointNumBytes())] & 0xff);\n            newline(out);\n            write(out, SPLIT_VALUE);\n            br = new BytesRef(splitPackedValues, 1+(i * (1+fieldInfo.getPointNumBytes())), fieldInfo.getPointNumBytes());\n            write(out, br.toString());\n            newline(out);\n          }\n        }\n\n        @Override\n        protected void writeLeafBlockDocs(IndexOutput out, int[] docIDs, int start, int count) throws IOException {\n          write(out, BLOCK_COUNT);\n          writeInt(out, count);\n          newline(out);\n          for(int i=0;i<count;i++) {\n            write(out, BLOCK_DOC_ID);\n            writeInt(out, docIDs[start+i]);\n            newline(out);\n          }\n        }\n\n        @Override\n        protected void writeCommonPrefixes(IndexOutput out, int[] commonPrefixLengths, byte[] packedValue) {\n          // NOTE: we don't do prefix coding, so we ignore commonPrefixLengths\n        }\n\n        @Override\n        protected void writeLeafBlockPackedValue(IndexOutput out, int[] commonPrefixLengths, byte[] bytes) throws IOException {\n          // NOTE: we don't do prefix coding, so we ignore commonPrefixLengths\n          assert bytes.length == packedBytesLength;\n          write(out, BLOCK_VALUE);\n          write(out, new BytesRef(bytes, 0, bytes.length).toString());\n          newline(out);\n        }          \n      }) {\n\n      values.intersect(fieldInfo.name, new IntersectVisitor() {\n          @Override\n          public void visit(int docID) {\n            throw new IllegalStateException();\n          }\n\n          public void visit(int docID, byte[] packedValue) throws IOException {\n            writer.add(packedValue, docID);\n          }\n\n          @Override\n          public Relation compare(byte[] minPackedValue, byte[] maxPackedValue) {\n            return Relation.CELL_CROSSES_QUERY;\n          }\n        });\n\n      // We could have 0 points on merge since all docs with points may be deleted:\n      if (writer.getPointCount() > 0) {\n        indexFPs.put(fieldInfo.name, writer.finish(dataOut));\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  public void writeField(FieldInfo fieldInfo, PointReader values) throws IOException {\n\n    // We use the normal BKDWriter, but subclass to customize how it writes the index and blocks to disk:\n    BKDWriter writer = new BKDWriter(writeState.directory,\n                                     writeState.segmentInfo.name,\n                                     fieldInfo.getPointDimensionCount(),\n                                     fieldInfo.getPointNumBytes(),\n                                     BKDWriter.DEFAULT_MAX_POINTS_IN_LEAF_NODE,\n                                     BKDWriter.DEFAULT_MAX_MB_SORT_IN_HEAP) {\n\n        @Override\n        protected void writeIndex(IndexOutput out, long[] leafBlockFPs, byte[] splitPackedValues) throws IOException {\n          write(out, NUM_DIMS);\n          writeInt(out, numDims);\n          newline(out);\n\n          write(out, BYTES_PER_DIM);\n          writeInt(out, bytesPerDim);\n          newline(out);\n\n          write(out, MAX_LEAF_POINTS);\n          writeInt(out, maxPointsInLeafNode);\n          newline(out);\n\n          write(out, INDEX_COUNT);\n          writeInt(out, leafBlockFPs.length);\n          newline(out);\n\n          write(out, MIN_VALUE);\n          BytesRef br = new BytesRef(minPackedValue, 0, minPackedValue.length);\n          write(out, br.toString());\n          newline(out);\n\n          write(out, MAX_VALUE);\n          br = new BytesRef(maxPackedValue, 0, maxPackedValue.length);\n          write(out, br.toString());\n          newline(out);\n\n          for(int i=0;i<leafBlockFPs.length;i++) {\n            write(out, BLOCK_FP);\n            writeLong(out, leafBlockFPs[i]);\n            newline(out);\n          }\n\n          assert (splitPackedValues.length % (1 + fieldInfo.getPointNumBytes())) == 0;\n          int count = splitPackedValues.length / (1 + fieldInfo.getPointNumBytes());\n          assert count == leafBlockFPs.length;\n\n          write(out, SPLIT_COUNT);\n          writeInt(out, count);\n          newline(out);\n\n          for(int i=0;i<count;i++) {\n            write(out, SPLIT_DIM);\n            writeInt(out, splitPackedValues[i * (1 + fieldInfo.getPointNumBytes())] & 0xff);\n            newline(out);\n            write(out, SPLIT_VALUE);\n            br = new BytesRef(splitPackedValues, 1+(i * (1+fieldInfo.getPointNumBytes())), fieldInfo.getPointNumBytes());\n            write(out, br.toString());\n            newline(out);\n          }\n        }\n\n        @Override\n        protected void writeLeafBlockDocs(IndexOutput out, int[] docIDs, int start, int count) throws IOException {\n          write(out, BLOCK_COUNT);\n          writeInt(out, count);\n          newline(out);\n          for(int i=0;i<count;i++) {\n            write(out, BLOCK_DOC_ID);\n            writeInt(out, docIDs[start+i]);\n            newline(out);\n          }\n        }\n\n        @Override\n        protected void writeCommonPrefixes(IndexOutput out, int[] commonPrefixLengths, byte[] packedValue) {\n          // NOTE: we don't do prefix coding, so we ignore commonPrefixLengths\n        }\n\n        @Override\n        protected void writeLeafBlockPackedValue(IndexOutput out, int[] commonPrefixLengths, byte[] bytes) throws IOException {\n          // NOTE: we don't do prefix coding, so we ignore commonPrefixLengths\n          assert bytes.length == packedBytesLength;\n          write(out, BLOCK_VALUE);\n          write(out, new BytesRef(bytes, 0, bytes.length).toString());\n          newline(out);\n        }          \n      };\n\n    values.intersect(fieldInfo.name, new IntersectVisitor() {\n        @Override\n        public void visit(int docID) {\n          throw new IllegalStateException();\n        }\n\n        public void visit(int docID, byte[] packedValue) throws IOException {\n          writer.add(packedValue, docID);\n        }\n\n        @Override\n        public Relation compare(byte[] minPackedValue, byte[] maxPackedValue) {\n          return Relation.CELL_CROSSES_QUERY;\n        }\n      });\n\n    // We could have 0 points on merge since all docs with points may be deleted:\n    if (writer.getPointCount() > 0) {\n      indexFPs.put(fieldInfo.name, writer.finish(dataOut));\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1e6acbaae7af722f17204ceccf0f7db5753eccf3","date":1454775255,"type":3,"author":"Mike McCandless","isMerge":true,"pathNew":"lucene/codecs/src/java/org/apache/lucene/codecs/simpletext/SimpleTextPointWriter#writeField(FieldInfo,PointReader).mjava","pathOld":"lucene/codecs/src/java/org/apache/lucene/codecs/simpletext/SimpleTextPointWriter#writeField(FieldInfo,PointReader).mjava","sourceNew":"  @Override\n  public void writeField(FieldInfo fieldInfo, PointReader values) throws IOException {\n\n    // We use the normal BKDWriter, but subclass to customize how it writes the index and blocks to disk:\n    try (BKDWriter writer = new BKDWriter(writeState.directory,\n                                     writeState.segmentInfo.name,\n                                     fieldInfo.getPointDimensionCount(),\n                                     fieldInfo.getPointNumBytes(),\n                                     BKDWriter.DEFAULT_MAX_POINTS_IN_LEAF_NODE,\n                                     BKDWriter.DEFAULT_MAX_MB_SORT_IN_HEAP) {\n\n        @Override\n        protected void writeIndex(IndexOutput out, long[] leafBlockFPs, byte[] splitPackedValues) throws IOException {\n          write(out, NUM_DIMS);\n          writeInt(out, numDims);\n          newline(out);\n\n          write(out, BYTES_PER_DIM);\n          writeInt(out, bytesPerDim);\n          newline(out);\n\n          write(out, MAX_LEAF_POINTS);\n          writeInt(out, maxPointsInLeafNode);\n          newline(out);\n\n          write(out, INDEX_COUNT);\n          writeInt(out, leafBlockFPs.length);\n          newline(out);\n\n          write(out, MIN_VALUE);\n          BytesRef br = new BytesRef(minPackedValue, 0, minPackedValue.length);\n          write(out, br.toString());\n          newline(out);\n\n          write(out, MAX_VALUE);\n          br = new BytesRef(maxPackedValue, 0, maxPackedValue.length);\n          write(out, br.toString());\n          newline(out);\n\n          for(int i=0;i<leafBlockFPs.length;i++) {\n            write(out, BLOCK_FP);\n            writeLong(out, leafBlockFPs[i]);\n            newline(out);\n          }\n\n          assert (splitPackedValues.length % (1 + fieldInfo.getPointNumBytes())) == 0;\n          int count = splitPackedValues.length / (1 + fieldInfo.getPointNumBytes());\n          assert count == leafBlockFPs.length;\n\n          write(out, SPLIT_COUNT);\n          writeInt(out, count);\n          newline(out);\n\n          for(int i=0;i<count;i++) {\n            write(out, SPLIT_DIM);\n            writeInt(out, splitPackedValues[i * (1 + fieldInfo.getPointNumBytes())] & 0xff);\n            newline(out);\n            write(out, SPLIT_VALUE);\n            br = new BytesRef(splitPackedValues, 1+(i * (1+fieldInfo.getPointNumBytes())), fieldInfo.getPointNumBytes());\n            write(out, br.toString());\n            newline(out);\n          }\n        }\n\n        @Override\n        protected void writeLeafBlockDocs(IndexOutput out, int[] docIDs, int start, int count) throws IOException {\n          write(out, BLOCK_COUNT);\n          writeInt(out, count);\n          newline(out);\n          for(int i=0;i<count;i++) {\n            write(out, BLOCK_DOC_ID);\n            writeInt(out, docIDs[start+i]);\n            newline(out);\n          }\n        }\n\n        @Override\n        protected void writeCommonPrefixes(IndexOutput out, int[] commonPrefixLengths, byte[] packedValue) {\n          // NOTE: we don't do prefix coding, so we ignore commonPrefixLengths\n        }\n\n        @Override\n        protected void writeLeafBlockPackedValue(IndexOutput out, int[] commonPrefixLengths, byte[] bytes) throws IOException {\n          // NOTE: we don't do prefix coding, so we ignore commonPrefixLengths\n          assert bytes.length == packedBytesLength;\n          write(out, BLOCK_VALUE);\n          write(out, new BytesRef(bytes, 0, bytes.length).toString());\n          newline(out);\n        }          \n      }) {\n\n      values.intersect(fieldInfo.name, new IntersectVisitor() {\n          @Override\n          public void visit(int docID) {\n            throw new IllegalStateException();\n          }\n\n          public void visit(int docID, byte[] packedValue) throws IOException {\n            writer.add(packedValue, docID);\n          }\n\n          @Override\n          public Relation compare(byte[] minPackedValue, byte[] maxPackedValue) {\n            return Relation.CELL_CROSSES_QUERY;\n          }\n        });\n\n      // We could have 0 points on merge since all docs with points may be deleted:\n      if (writer.getPointCount() > 0) {\n        indexFPs.put(fieldInfo.name, writer.finish(dataOut));\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  public void writeField(FieldInfo fieldInfo, PointReader values) throws IOException {\n\n    // We use the normal BKDWriter, but subclass to customize how it writes the index and blocks to disk:\n    BKDWriter writer = new BKDWriter(writeState.directory,\n                                     writeState.segmentInfo.name,\n                                     fieldInfo.getPointDimensionCount(),\n                                     fieldInfo.getPointNumBytes(),\n                                     BKDWriter.DEFAULT_MAX_POINTS_IN_LEAF_NODE,\n                                     BKDWriter.DEFAULT_MAX_MB_SORT_IN_HEAP) {\n\n        @Override\n        protected void writeIndex(IndexOutput out, long[] leafBlockFPs, byte[] splitPackedValues) throws IOException {\n          write(out, NUM_DIMS);\n          writeInt(out, numDims);\n          newline(out);\n\n          write(out, BYTES_PER_DIM);\n          writeInt(out, bytesPerDim);\n          newline(out);\n\n          write(out, MAX_LEAF_POINTS);\n          writeInt(out, maxPointsInLeafNode);\n          newline(out);\n\n          write(out, INDEX_COUNT);\n          writeInt(out, leafBlockFPs.length);\n          newline(out);\n\n          write(out, MIN_VALUE);\n          BytesRef br = new BytesRef(minPackedValue, 0, minPackedValue.length);\n          write(out, br.toString());\n          newline(out);\n\n          write(out, MAX_VALUE);\n          br = new BytesRef(maxPackedValue, 0, maxPackedValue.length);\n          write(out, br.toString());\n          newline(out);\n\n          for(int i=0;i<leafBlockFPs.length;i++) {\n            write(out, BLOCK_FP);\n            writeLong(out, leafBlockFPs[i]);\n            newline(out);\n          }\n\n          assert (splitPackedValues.length % (1 + fieldInfo.getPointNumBytes())) == 0;\n          int count = splitPackedValues.length / (1 + fieldInfo.getPointNumBytes());\n          assert count == leafBlockFPs.length;\n\n          write(out, SPLIT_COUNT);\n          writeInt(out, count);\n          newline(out);\n\n          for(int i=0;i<count;i++) {\n            write(out, SPLIT_DIM);\n            writeInt(out, splitPackedValues[i * (1 + fieldInfo.getPointNumBytes())] & 0xff);\n            newline(out);\n            write(out, SPLIT_VALUE);\n            br = new BytesRef(splitPackedValues, 1+(i * (1+fieldInfo.getPointNumBytes())), fieldInfo.getPointNumBytes());\n            write(out, br.toString());\n            newline(out);\n          }\n        }\n\n        @Override\n        protected void writeLeafBlockDocs(IndexOutput out, int[] docIDs, int start, int count) throws IOException {\n          write(out, BLOCK_COUNT);\n          writeInt(out, count);\n          newline(out);\n          for(int i=0;i<count;i++) {\n            write(out, BLOCK_DOC_ID);\n            writeInt(out, docIDs[start+i]);\n            newline(out);\n          }\n        }\n\n        @Override\n        protected void writeCommonPrefixes(IndexOutput out, int[] commonPrefixLengths, byte[] packedValue) {\n          // NOTE: we don't do prefix coding, so we ignore commonPrefixLengths\n        }\n\n        @Override\n        protected void writeLeafBlockPackedValue(IndexOutput out, int[] commonPrefixLengths, byte[] bytes) throws IOException {\n          // NOTE: we don't do prefix coding, so we ignore commonPrefixLengths\n          assert bytes.length == packedBytesLength;\n          write(out, BLOCK_VALUE);\n          write(out, new BytesRef(bytes, 0, bytes.length).toString());\n          newline(out);\n        }          \n      };\n\n    values.intersect(fieldInfo.name, new IntersectVisitor() {\n        @Override\n        public void visit(int docID) {\n          throw new IllegalStateException();\n        }\n\n        public void visit(int docID, byte[] packedValue) throws IOException {\n          writer.add(packedValue, docID);\n        }\n\n        @Override\n        public Relation compare(byte[] minPackedValue, byte[] maxPackedValue) {\n          return Relation.CELL_CROSSES_QUERY;\n        }\n      });\n\n    // We could have 0 points on merge since all docs with points may be deleted:\n    if (writer.getPointCount() > 0) {\n      indexFPs.put(fieldInfo.name, writer.finish(dataOut));\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"879e8cf5ab626b9bf29f1ef603e3a28601fcb1a7","date":1456959208,"type":3,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/codecs/src/java/org/apache/lucene/codecs/simpletext/SimpleTextPointWriter#writeField(FieldInfo,PointReader).mjava","pathOld":"lucene/codecs/src/java/org/apache/lucene/codecs/simpletext/SimpleTextPointWriter#writeField(FieldInfo,PointReader).mjava","sourceNew":"  @Override\n  public void writeField(FieldInfo fieldInfo, PointReader values) throws IOException {\n\n    // We use the normal BKDWriter, but subclass to customize how it writes the index and blocks to disk:\n    try (BKDWriter writer = new BKDWriter(writeState.directory,\n                                     writeState.segmentInfo.name,\n                                     fieldInfo.getPointDimensionCount(),\n                                     fieldInfo.getPointNumBytes(),\n                                     BKDWriter.DEFAULT_MAX_POINTS_IN_LEAF_NODE,\n                                     BKDWriter.DEFAULT_MAX_MB_SORT_IN_HEAP) {\n\n        @Override\n        protected void writeIndex(IndexOutput out, long[] leafBlockFPs, byte[] splitPackedValues) throws IOException {\n          write(out, NUM_DIMS);\n          writeInt(out, numDims);\n          newline(out);\n\n          write(out, BYTES_PER_DIM);\n          writeInt(out, bytesPerDim);\n          newline(out);\n\n          write(out, MAX_LEAF_POINTS);\n          writeInt(out, maxPointsInLeafNode);\n          newline(out);\n\n          write(out, INDEX_COUNT);\n          writeInt(out, leafBlockFPs.length);\n          newline(out);\n\n          write(out, MIN_VALUE);\n          BytesRef br = new BytesRef(minPackedValue, 0, minPackedValue.length);\n          write(out, br.toString());\n          newline(out);\n\n          write(out, MAX_VALUE);\n          br = new BytesRef(maxPackedValue, 0, maxPackedValue.length);\n          write(out, br.toString());\n          newline(out);\n\n          write(out, POINT_COUNT);\n          writeLong(out, pointCount);\n          newline(out);\n\n          for(int i=0;i<leafBlockFPs.length;i++) {\n            write(out, BLOCK_FP);\n            writeLong(out, leafBlockFPs[i]);\n            newline(out);\n          }\n\n          assert (splitPackedValues.length % (1 + fieldInfo.getPointNumBytes())) == 0;\n          int count = splitPackedValues.length / (1 + fieldInfo.getPointNumBytes());\n          assert count == leafBlockFPs.length;\n\n          write(out, SPLIT_COUNT);\n          writeInt(out, count);\n          newline(out);\n\n          for(int i=0;i<count;i++) {\n            write(out, SPLIT_DIM);\n            writeInt(out, splitPackedValues[i * (1 + fieldInfo.getPointNumBytes())] & 0xff);\n            newline(out);\n            write(out, SPLIT_VALUE);\n            br = new BytesRef(splitPackedValues, 1+(i * (1+fieldInfo.getPointNumBytes())), fieldInfo.getPointNumBytes());\n            write(out, br.toString());\n            newline(out);\n          }\n        }\n\n        @Override\n        protected void writeLeafBlockDocs(IndexOutput out, int[] docIDs, int start, int count) throws IOException {\n          write(out, BLOCK_COUNT);\n          writeInt(out, count);\n          newline(out);\n          for(int i=0;i<count;i++) {\n            write(out, BLOCK_DOC_ID);\n            writeInt(out, docIDs[start+i]);\n            newline(out);\n          }\n        }\n\n        @Override\n        protected void writeCommonPrefixes(IndexOutput out, int[] commonPrefixLengths, byte[] packedValue) {\n          // NOTE: we don't do prefix coding, so we ignore commonPrefixLengths\n        }\n\n        @Override\n        protected void writeLeafBlockPackedValue(IndexOutput out, int[] commonPrefixLengths, byte[] bytes) throws IOException {\n          // NOTE: we don't do prefix coding, so we ignore commonPrefixLengths\n          assert bytes.length == packedBytesLength;\n          write(out, BLOCK_VALUE);\n          write(out, new BytesRef(bytes, 0, bytes.length).toString());\n          newline(out);\n        }          \n      }) {\n\n      values.intersect(fieldInfo.name, new IntersectVisitor() {\n          @Override\n          public void visit(int docID) {\n            throw new IllegalStateException();\n          }\n\n          public void visit(int docID, byte[] packedValue) throws IOException {\n            writer.add(packedValue, docID);\n          }\n\n          @Override\n          public Relation compare(byte[] minPackedValue, byte[] maxPackedValue) {\n            return Relation.CELL_CROSSES_QUERY;\n          }\n        });\n\n      // We could have 0 points on merge since all docs with points may be deleted:\n      if (writer.getPointCount() > 0) {\n        indexFPs.put(fieldInfo.name, writer.finish(dataOut));\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  public void writeField(FieldInfo fieldInfo, PointReader values) throws IOException {\n\n    // We use the normal BKDWriter, but subclass to customize how it writes the index and blocks to disk:\n    try (BKDWriter writer = new BKDWriter(writeState.directory,\n                                     writeState.segmentInfo.name,\n                                     fieldInfo.getPointDimensionCount(),\n                                     fieldInfo.getPointNumBytes(),\n                                     BKDWriter.DEFAULT_MAX_POINTS_IN_LEAF_NODE,\n                                     BKDWriter.DEFAULT_MAX_MB_SORT_IN_HEAP) {\n\n        @Override\n        protected void writeIndex(IndexOutput out, long[] leafBlockFPs, byte[] splitPackedValues) throws IOException {\n          write(out, NUM_DIMS);\n          writeInt(out, numDims);\n          newline(out);\n\n          write(out, BYTES_PER_DIM);\n          writeInt(out, bytesPerDim);\n          newline(out);\n\n          write(out, MAX_LEAF_POINTS);\n          writeInt(out, maxPointsInLeafNode);\n          newline(out);\n\n          write(out, INDEX_COUNT);\n          writeInt(out, leafBlockFPs.length);\n          newline(out);\n\n          write(out, MIN_VALUE);\n          BytesRef br = new BytesRef(minPackedValue, 0, minPackedValue.length);\n          write(out, br.toString());\n          newline(out);\n\n          write(out, MAX_VALUE);\n          br = new BytesRef(maxPackedValue, 0, maxPackedValue.length);\n          write(out, br.toString());\n          newline(out);\n\n          for(int i=0;i<leafBlockFPs.length;i++) {\n            write(out, BLOCK_FP);\n            writeLong(out, leafBlockFPs[i]);\n            newline(out);\n          }\n\n          assert (splitPackedValues.length % (1 + fieldInfo.getPointNumBytes())) == 0;\n          int count = splitPackedValues.length / (1 + fieldInfo.getPointNumBytes());\n          assert count == leafBlockFPs.length;\n\n          write(out, SPLIT_COUNT);\n          writeInt(out, count);\n          newline(out);\n\n          for(int i=0;i<count;i++) {\n            write(out, SPLIT_DIM);\n            writeInt(out, splitPackedValues[i * (1 + fieldInfo.getPointNumBytes())] & 0xff);\n            newline(out);\n            write(out, SPLIT_VALUE);\n            br = new BytesRef(splitPackedValues, 1+(i * (1+fieldInfo.getPointNumBytes())), fieldInfo.getPointNumBytes());\n            write(out, br.toString());\n            newline(out);\n          }\n        }\n\n        @Override\n        protected void writeLeafBlockDocs(IndexOutput out, int[] docIDs, int start, int count) throws IOException {\n          write(out, BLOCK_COUNT);\n          writeInt(out, count);\n          newline(out);\n          for(int i=0;i<count;i++) {\n            write(out, BLOCK_DOC_ID);\n            writeInt(out, docIDs[start+i]);\n            newline(out);\n          }\n        }\n\n        @Override\n        protected void writeCommonPrefixes(IndexOutput out, int[] commonPrefixLengths, byte[] packedValue) {\n          // NOTE: we don't do prefix coding, so we ignore commonPrefixLengths\n        }\n\n        @Override\n        protected void writeLeafBlockPackedValue(IndexOutput out, int[] commonPrefixLengths, byte[] bytes) throws IOException {\n          // NOTE: we don't do prefix coding, so we ignore commonPrefixLengths\n          assert bytes.length == packedBytesLength;\n          write(out, BLOCK_VALUE);\n          write(out, new BytesRef(bytes, 0, bytes.length).toString());\n          newline(out);\n        }          \n      }) {\n\n      values.intersect(fieldInfo.name, new IntersectVisitor() {\n          @Override\n          public void visit(int docID) {\n            throw new IllegalStateException();\n          }\n\n          public void visit(int docID, byte[] packedValue) throws IOException {\n            writer.add(packedValue, docID);\n          }\n\n          @Override\n          public Relation compare(byte[] minPackedValue, byte[] maxPackedValue) {\n            return Relation.CELL_CROSSES_QUERY;\n          }\n        });\n\n      // We could have 0 points on merge since all docs with points may be deleted:\n      if (writer.getPointCount() > 0) {\n        indexFPs.put(fieldInfo.name, writer.finish(dataOut));\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"251c5b33f0a2c8988550b63c78ed22b0e84524e5","date":1456961997,"type":3,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/codecs/src/java/org/apache/lucene/codecs/simpletext/SimpleTextPointWriter#writeField(FieldInfo,PointReader).mjava","pathOld":"lucene/codecs/src/java/org/apache/lucene/codecs/simpletext/SimpleTextPointWriter#writeField(FieldInfo,PointReader).mjava","sourceNew":"  @Override\n  public void writeField(FieldInfo fieldInfo, PointReader values) throws IOException {\n\n    // We use the normal BKDWriter, but subclass to customize how it writes the index and blocks to disk:\n    try (BKDWriter writer = new BKDWriter(writeState.segmentInfo.maxDoc(),\n                                          writeState.directory,\n                                          writeState.segmentInfo.name,\n                                          fieldInfo.getPointDimensionCount(),\n                                          fieldInfo.getPointNumBytes(),\n                                          BKDWriter.DEFAULT_MAX_POINTS_IN_LEAF_NODE,\n                                          BKDWriter.DEFAULT_MAX_MB_SORT_IN_HEAP) {\n\n        @Override\n        protected void writeIndex(IndexOutput out, long[] leafBlockFPs, byte[] splitPackedValues) throws IOException {\n          write(out, NUM_DIMS);\n          writeInt(out, numDims);\n          newline(out);\n\n          write(out, BYTES_PER_DIM);\n          writeInt(out, bytesPerDim);\n          newline(out);\n\n          write(out, MAX_LEAF_POINTS);\n          writeInt(out, maxPointsInLeafNode);\n          newline(out);\n\n          write(out, INDEX_COUNT);\n          writeInt(out, leafBlockFPs.length);\n          newline(out);\n\n          write(out, MIN_VALUE);\n          BytesRef br = new BytesRef(minPackedValue, 0, minPackedValue.length);\n          write(out, br.toString());\n          newline(out);\n\n          write(out, MAX_VALUE);\n          br = new BytesRef(maxPackedValue, 0, maxPackedValue.length);\n          write(out, br.toString());\n          newline(out);\n\n          write(out, POINT_COUNT);\n          writeLong(out, pointCount);\n          newline(out);\n\n          write(out, DOC_COUNT);\n          writeInt(out, docsSeen.cardinality());\n          newline(out);\n\n          for(int i=0;i<leafBlockFPs.length;i++) {\n            write(out, BLOCK_FP);\n            writeLong(out, leafBlockFPs[i]);\n            newline(out);\n          }\n\n          assert (splitPackedValues.length % (1 + fieldInfo.getPointNumBytes())) == 0;\n          int count = splitPackedValues.length / (1 + fieldInfo.getPointNumBytes());\n          assert count == leafBlockFPs.length;\n\n          write(out, SPLIT_COUNT);\n          writeInt(out, count);\n          newline(out);\n\n          for(int i=0;i<count;i++) {\n            write(out, SPLIT_DIM);\n            writeInt(out, splitPackedValues[i * (1 + fieldInfo.getPointNumBytes())] & 0xff);\n            newline(out);\n            write(out, SPLIT_VALUE);\n            br = new BytesRef(splitPackedValues, 1+(i * (1+fieldInfo.getPointNumBytes())), fieldInfo.getPointNumBytes());\n            write(out, br.toString());\n            newline(out);\n          }\n        }\n\n        @Override\n        protected void writeLeafBlockDocs(IndexOutput out, int[] docIDs, int start, int count) throws IOException {\n          write(out, BLOCK_COUNT);\n          writeInt(out, count);\n          newline(out);\n          for(int i=0;i<count;i++) {\n            write(out, BLOCK_DOC_ID);\n            writeInt(out, docIDs[start+i]);\n            newline(out);\n          }\n        }\n\n        @Override\n        protected void writeCommonPrefixes(IndexOutput out, int[] commonPrefixLengths, byte[] packedValue) {\n          // NOTE: we don't do prefix coding, so we ignore commonPrefixLengths\n        }\n\n        @Override\n        protected void writeLeafBlockPackedValue(IndexOutput out, int[] commonPrefixLengths, byte[] bytes) throws IOException {\n          // NOTE: we don't do prefix coding, so we ignore commonPrefixLengths\n          assert bytes.length == packedBytesLength;\n          write(out, BLOCK_VALUE);\n          write(out, new BytesRef(bytes, 0, bytes.length).toString());\n          newline(out);\n        }          \n      }) {\n\n      values.intersect(fieldInfo.name, new IntersectVisitor() {\n          @Override\n          public void visit(int docID) {\n            throw new IllegalStateException();\n          }\n\n          public void visit(int docID, byte[] packedValue) throws IOException {\n            writer.add(packedValue, docID);\n          }\n\n          @Override\n          public Relation compare(byte[] minPackedValue, byte[] maxPackedValue) {\n            return Relation.CELL_CROSSES_QUERY;\n          }\n        });\n\n      // We could have 0 points on merge since all docs with points may be deleted:\n      if (writer.getPointCount() > 0) {\n        indexFPs.put(fieldInfo.name, writer.finish(dataOut));\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  public void writeField(FieldInfo fieldInfo, PointReader values) throws IOException {\n\n    // We use the normal BKDWriter, but subclass to customize how it writes the index and blocks to disk:\n    try (BKDWriter writer = new BKDWriter(writeState.directory,\n                                     writeState.segmentInfo.name,\n                                     fieldInfo.getPointDimensionCount(),\n                                     fieldInfo.getPointNumBytes(),\n                                     BKDWriter.DEFAULT_MAX_POINTS_IN_LEAF_NODE,\n                                     BKDWriter.DEFAULT_MAX_MB_SORT_IN_HEAP) {\n\n        @Override\n        protected void writeIndex(IndexOutput out, long[] leafBlockFPs, byte[] splitPackedValues) throws IOException {\n          write(out, NUM_DIMS);\n          writeInt(out, numDims);\n          newline(out);\n\n          write(out, BYTES_PER_DIM);\n          writeInt(out, bytesPerDim);\n          newline(out);\n\n          write(out, MAX_LEAF_POINTS);\n          writeInt(out, maxPointsInLeafNode);\n          newline(out);\n\n          write(out, INDEX_COUNT);\n          writeInt(out, leafBlockFPs.length);\n          newline(out);\n\n          write(out, MIN_VALUE);\n          BytesRef br = new BytesRef(minPackedValue, 0, minPackedValue.length);\n          write(out, br.toString());\n          newline(out);\n\n          write(out, MAX_VALUE);\n          br = new BytesRef(maxPackedValue, 0, maxPackedValue.length);\n          write(out, br.toString());\n          newline(out);\n\n          write(out, POINT_COUNT);\n          writeLong(out, pointCount);\n          newline(out);\n\n          for(int i=0;i<leafBlockFPs.length;i++) {\n            write(out, BLOCK_FP);\n            writeLong(out, leafBlockFPs[i]);\n            newline(out);\n          }\n\n          assert (splitPackedValues.length % (1 + fieldInfo.getPointNumBytes())) == 0;\n          int count = splitPackedValues.length / (1 + fieldInfo.getPointNumBytes());\n          assert count == leafBlockFPs.length;\n\n          write(out, SPLIT_COUNT);\n          writeInt(out, count);\n          newline(out);\n\n          for(int i=0;i<count;i++) {\n            write(out, SPLIT_DIM);\n            writeInt(out, splitPackedValues[i * (1 + fieldInfo.getPointNumBytes())] & 0xff);\n            newline(out);\n            write(out, SPLIT_VALUE);\n            br = new BytesRef(splitPackedValues, 1+(i * (1+fieldInfo.getPointNumBytes())), fieldInfo.getPointNumBytes());\n            write(out, br.toString());\n            newline(out);\n          }\n        }\n\n        @Override\n        protected void writeLeafBlockDocs(IndexOutput out, int[] docIDs, int start, int count) throws IOException {\n          write(out, BLOCK_COUNT);\n          writeInt(out, count);\n          newline(out);\n          for(int i=0;i<count;i++) {\n            write(out, BLOCK_DOC_ID);\n            writeInt(out, docIDs[start+i]);\n            newline(out);\n          }\n        }\n\n        @Override\n        protected void writeCommonPrefixes(IndexOutput out, int[] commonPrefixLengths, byte[] packedValue) {\n          // NOTE: we don't do prefix coding, so we ignore commonPrefixLengths\n        }\n\n        @Override\n        protected void writeLeafBlockPackedValue(IndexOutput out, int[] commonPrefixLengths, byte[] bytes) throws IOException {\n          // NOTE: we don't do prefix coding, so we ignore commonPrefixLengths\n          assert bytes.length == packedBytesLength;\n          write(out, BLOCK_VALUE);\n          write(out, new BytesRef(bytes, 0, bytes.length).toString());\n          newline(out);\n        }          \n      }) {\n\n      values.intersect(fieldInfo.name, new IntersectVisitor() {\n          @Override\n          public void visit(int docID) {\n            throw new IllegalStateException();\n          }\n\n          public void visit(int docID, byte[] packedValue) throws IOException {\n            writer.add(packedValue, docID);\n          }\n\n          @Override\n          public Relation compare(byte[] minPackedValue, byte[] maxPackedValue) {\n            return Relation.CELL_CROSSES_QUERY;\n          }\n        });\n\n      // We could have 0 points on merge since all docs with points may be deleted:\n      if (writer.getPointCount() > 0) {\n        indexFPs.put(fieldInfo.name, writer.finish(dataOut));\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"cf1a614098b46c9c22afebd7b898ae4d1d2fc273","date":1457088850,"type":3,"author":"Noble Paul","isMerge":true,"pathNew":"lucene/codecs/src/java/org/apache/lucene/codecs/simpletext/SimpleTextPointWriter#writeField(FieldInfo,PointReader).mjava","pathOld":"lucene/codecs/src/java/org/apache/lucene/codecs/simpletext/SimpleTextPointWriter#writeField(FieldInfo,PointReader).mjava","sourceNew":"  @Override\n  public void writeField(FieldInfo fieldInfo, PointReader values) throws IOException {\n\n    // We use the normal BKDWriter, but subclass to customize how it writes the index and blocks to disk:\n    try (BKDWriter writer = new BKDWriter(writeState.segmentInfo.maxDoc(),\n                                          writeState.directory,\n                                          writeState.segmentInfo.name,\n                                          fieldInfo.getPointDimensionCount(),\n                                          fieldInfo.getPointNumBytes(),\n                                          BKDWriter.DEFAULT_MAX_POINTS_IN_LEAF_NODE,\n                                          BKDWriter.DEFAULT_MAX_MB_SORT_IN_HEAP) {\n\n        @Override\n        protected void writeIndex(IndexOutput out, long[] leafBlockFPs, byte[] splitPackedValues) throws IOException {\n          write(out, NUM_DIMS);\n          writeInt(out, numDims);\n          newline(out);\n\n          write(out, BYTES_PER_DIM);\n          writeInt(out, bytesPerDim);\n          newline(out);\n\n          write(out, MAX_LEAF_POINTS);\n          writeInt(out, maxPointsInLeafNode);\n          newline(out);\n\n          write(out, INDEX_COUNT);\n          writeInt(out, leafBlockFPs.length);\n          newline(out);\n\n          write(out, MIN_VALUE);\n          BytesRef br = new BytesRef(minPackedValue, 0, minPackedValue.length);\n          write(out, br.toString());\n          newline(out);\n\n          write(out, MAX_VALUE);\n          br = new BytesRef(maxPackedValue, 0, maxPackedValue.length);\n          write(out, br.toString());\n          newline(out);\n\n          write(out, POINT_COUNT);\n          writeLong(out, pointCount);\n          newline(out);\n\n          write(out, DOC_COUNT);\n          writeInt(out, docsSeen.cardinality());\n          newline(out);\n\n          for(int i=0;i<leafBlockFPs.length;i++) {\n            write(out, BLOCK_FP);\n            writeLong(out, leafBlockFPs[i]);\n            newline(out);\n          }\n\n          assert (splitPackedValues.length % (1 + fieldInfo.getPointNumBytes())) == 0;\n          int count = splitPackedValues.length / (1 + fieldInfo.getPointNumBytes());\n          assert count == leafBlockFPs.length;\n\n          write(out, SPLIT_COUNT);\n          writeInt(out, count);\n          newline(out);\n\n          for(int i=0;i<count;i++) {\n            write(out, SPLIT_DIM);\n            writeInt(out, splitPackedValues[i * (1 + fieldInfo.getPointNumBytes())] & 0xff);\n            newline(out);\n            write(out, SPLIT_VALUE);\n            br = new BytesRef(splitPackedValues, 1+(i * (1+fieldInfo.getPointNumBytes())), fieldInfo.getPointNumBytes());\n            write(out, br.toString());\n            newline(out);\n          }\n        }\n\n        @Override\n        protected void writeLeafBlockDocs(IndexOutput out, int[] docIDs, int start, int count) throws IOException {\n          write(out, BLOCK_COUNT);\n          writeInt(out, count);\n          newline(out);\n          for(int i=0;i<count;i++) {\n            write(out, BLOCK_DOC_ID);\n            writeInt(out, docIDs[start+i]);\n            newline(out);\n          }\n        }\n\n        @Override\n        protected void writeCommonPrefixes(IndexOutput out, int[] commonPrefixLengths, byte[] packedValue) {\n          // NOTE: we don't do prefix coding, so we ignore commonPrefixLengths\n        }\n\n        @Override\n        protected void writeLeafBlockPackedValue(IndexOutput out, int[] commonPrefixLengths, byte[] bytes) throws IOException {\n          // NOTE: we don't do prefix coding, so we ignore commonPrefixLengths\n          assert bytes.length == packedBytesLength;\n          write(out, BLOCK_VALUE);\n          write(out, new BytesRef(bytes, 0, bytes.length).toString());\n          newline(out);\n        }          \n      }) {\n\n      values.intersect(fieldInfo.name, new IntersectVisitor() {\n          @Override\n          public void visit(int docID) {\n            throw new IllegalStateException();\n          }\n\n          public void visit(int docID, byte[] packedValue) throws IOException {\n            writer.add(packedValue, docID);\n          }\n\n          @Override\n          public Relation compare(byte[] minPackedValue, byte[] maxPackedValue) {\n            return Relation.CELL_CROSSES_QUERY;\n          }\n        });\n\n      // We could have 0 points on merge since all docs with points may be deleted:\n      if (writer.getPointCount() > 0) {\n        indexFPs.put(fieldInfo.name, writer.finish(dataOut));\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  public void writeField(FieldInfo fieldInfo, PointReader values) throws IOException {\n\n    // We use the normal BKDWriter, but subclass to customize how it writes the index and blocks to disk:\n    try (BKDWriter writer = new BKDWriter(writeState.directory,\n                                     writeState.segmentInfo.name,\n                                     fieldInfo.getPointDimensionCount(),\n                                     fieldInfo.getPointNumBytes(),\n                                     BKDWriter.DEFAULT_MAX_POINTS_IN_LEAF_NODE,\n                                     BKDWriter.DEFAULT_MAX_MB_SORT_IN_HEAP) {\n\n        @Override\n        protected void writeIndex(IndexOutput out, long[] leafBlockFPs, byte[] splitPackedValues) throws IOException {\n          write(out, NUM_DIMS);\n          writeInt(out, numDims);\n          newline(out);\n\n          write(out, BYTES_PER_DIM);\n          writeInt(out, bytesPerDim);\n          newline(out);\n\n          write(out, MAX_LEAF_POINTS);\n          writeInt(out, maxPointsInLeafNode);\n          newline(out);\n\n          write(out, INDEX_COUNT);\n          writeInt(out, leafBlockFPs.length);\n          newline(out);\n\n          write(out, MIN_VALUE);\n          BytesRef br = new BytesRef(minPackedValue, 0, minPackedValue.length);\n          write(out, br.toString());\n          newline(out);\n\n          write(out, MAX_VALUE);\n          br = new BytesRef(maxPackedValue, 0, maxPackedValue.length);\n          write(out, br.toString());\n          newline(out);\n\n          for(int i=0;i<leafBlockFPs.length;i++) {\n            write(out, BLOCK_FP);\n            writeLong(out, leafBlockFPs[i]);\n            newline(out);\n          }\n\n          assert (splitPackedValues.length % (1 + fieldInfo.getPointNumBytes())) == 0;\n          int count = splitPackedValues.length / (1 + fieldInfo.getPointNumBytes());\n          assert count == leafBlockFPs.length;\n\n          write(out, SPLIT_COUNT);\n          writeInt(out, count);\n          newline(out);\n\n          for(int i=0;i<count;i++) {\n            write(out, SPLIT_DIM);\n            writeInt(out, splitPackedValues[i * (1 + fieldInfo.getPointNumBytes())] & 0xff);\n            newline(out);\n            write(out, SPLIT_VALUE);\n            br = new BytesRef(splitPackedValues, 1+(i * (1+fieldInfo.getPointNumBytes())), fieldInfo.getPointNumBytes());\n            write(out, br.toString());\n            newline(out);\n          }\n        }\n\n        @Override\n        protected void writeLeafBlockDocs(IndexOutput out, int[] docIDs, int start, int count) throws IOException {\n          write(out, BLOCK_COUNT);\n          writeInt(out, count);\n          newline(out);\n          for(int i=0;i<count;i++) {\n            write(out, BLOCK_DOC_ID);\n            writeInt(out, docIDs[start+i]);\n            newline(out);\n          }\n        }\n\n        @Override\n        protected void writeCommonPrefixes(IndexOutput out, int[] commonPrefixLengths, byte[] packedValue) {\n          // NOTE: we don't do prefix coding, so we ignore commonPrefixLengths\n        }\n\n        @Override\n        protected void writeLeafBlockPackedValue(IndexOutput out, int[] commonPrefixLengths, byte[] bytes) throws IOException {\n          // NOTE: we don't do prefix coding, so we ignore commonPrefixLengths\n          assert bytes.length == packedBytesLength;\n          write(out, BLOCK_VALUE);\n          write(out, new BytesRef(bytes, 0, bytes.length).toString());\n          newline(out);\n        }          \n      }) {\n\n      values.intersect(fieldInfo.name, new IntersectVisitor() {\n          @Override\n          public void visit(int docID) {\n            throw new IllegalStateException();\n          }\n\n          public void visit(int docID, byte[] packedValue) throws IOException {\n            writer.add(packedValue, docID);\n          }\n\n          @Override\n          public Relation compare(byte[] minPackedValue, byte[] maxPackedValue) {\n            return Relation.CELL_CROSSES_QUERY;\n          }\n        });\n\n      // We could have 0 points on merge since all docs with points may be deleted:\n      if (writer.getPointCount() > 0) {\n        indexFPs.put(fieldInfo.name, writer.finish(dataOut));\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4522ffca5a1f420c6a02198c9332d7c596a30ca5","date":1457270822,"type":5,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/codecs/src/java/org/apache/lucene/codecs/simpletext/SimpleTextPointsWriter#writeField(FieldInfo,PointsReader).mjava","pathOld":"lucene/codecs/src/java/org/apache/lucene/codecs/simpletext/SimpleTextPointWriter#writeField(FieldInfo,PointReader).mjava","sourceNew":"  @Override\n  public void writeField(FieldInfo fieldInfo, PointsReader values) throws IOException {\n\n    // We use the normal BKDWriter, but subclass to customize how it writes the index and blocks to disk:\n    try (BKDWriter writer = new BKDWriter(writeState.segmentInfo.maxDoc(),\n                                          writeState.directory,\n                                          writeState.segmentInfo.name,\n                                          fieldInfo.getPointDimensionCount(),\n                                          fieldInfo.getPointNumBytes(),\n                                          BKDWriter.DEFAULT_MAX_POINTS_IN_LEAF_NODE,\n                                          BKDWriter.DEFAULT_MAX_MB_SORT_IN_HEAP) {\n\n        @Override\n        protected void writeIndex(IndexOutput out, long[] leafBlockFPs, byte[] splitPackedValues) throws IOException {\n          write(out, NUM_DIMS);\n          writeInt(out, numDims);\n          newline(out);\n\n          write(out, BYTES_PER_DIM);\n          writeInt(out, bytesPerDim);\n          newline(out);\n\n          write(out, MAX_LEAF_POINTS);\n          writeInt(out, maxPointsInLeafNode);\n          newline(out);\n\n          write(out, INDEX_COUNT);\n          writeInt(out, leafBlockFPs.length);\n          newline(out);\n\n          write(out, MIN_VALUE);\n          BytesRef br = new BytesRef(minPackedValue, 0, minPackedValue.length);\n          write(out, br.toString());\n          newline(out);\n\n          write(out, MAX_VALUE);\n          br = new BytesRef(maxPackedValue, 0, maxPackedValue.length);\n          write(out, br.toString());\n          newline(out);\n\n          write(out, POINT_COUNT);\n          writeLong(out, pointCount);\n          newline(out);\n\n          write(out, DOC_COUNT);\n          writeInt(out, docsSeen.cardinality());\n          newline(out);\n\n          for(int i=0;i<leafBlockFPs.length;i++) {\n            write(out, BLOCK_FP);\n            writeLong(out, leafBlockFPs[i]);\n            newline(out);\n          }\n\n          assert (splitPackedValues.length % (1 + fieldInfo.getPointNumBytes())) == 0;\n          int count = splitPackedValues.length / (1 + fieldInfo.getPointNumBytes());\n          assert count == leafBlockFPs.length;\n\n          write(out, SPLIT_COUNT);\n          writeInt(out, count);\n          newline(out);\n\n          for(int i=0;i<count;i++) {\n            write(out, SPLIT_DIM);\n            writeInt(out, splitPackedValues[i * (1 + fieldInfo.getPointNumBytes())] & 0xff);\n            newline(out);\n            write(out, SPLIT_VALUE);\n            br = new BytesRef(splitPackedValues, 1+(i * (1+fieldInfo.getPointNumBytes())), fieldInfo.getPointNumBytes());\n            write(out, br.toString());\n            newline(out);\n          }\n        }\n\n        @Override\n        protected void writeLeafBlockDocs(IndexOutput out, int[] docIDs, int start, int count) throws IOException {\n          write(out, BLOCK_COUNT);\n          writeInt(out, count);\n          newline(out);\n          for(int i=0;i<count;i++) {\n            write(out, BLOCK_DOC_ID);\n            writeInt(out, docIDs[start+i]);\n            newline(out);\n          }\n        }\n\n        @Override\n        protected void writeCommonPrefixes(IndexOutput out, int[] commonPrefixLengths, byte[] packedValue) {\n          // NOTE: we don't do prefix coding, so we ignore commonPrefixLengths\n        }\n\n        @Override\n        protected void writeLeafBlockPackedValue(IndexOutput out, int[] commonPrefixLengths, byte[] bytes) throws IOException {\n          // NOTE: we don't do prefix coding, so we ignore commonPrefixLengths\n          assert bytes.length == packedBytesLength;\n          write(out, BLOCK_VALUE);\n          write(out, new BytesRef(bytes, 0, bytes.length).toString());\n          newline(out);\n        }          \n      }) {\n\n      values.intersect(fieldInfo.name, new IntersectVisitor() {\n          @Override\n          public void visit(int docID) {\n            throw new IllegalStateException();\n          }\n\n          public void visit(int docID, byte[] packedValue) throws IOException {\n            writer.add(packedValue, docID);\n          }\n\n          @Override\n          public Relation compare(byte[] minPackedValue, byte[] maxPackedValue) {\n            return Relation.CELL_CROSSES_QUERY;\n          }\n        });\n\n      // We could have 0 points on merge since all docs with points may be deleted:\n      if (writer.getPointCount() > 0) {\n        indexFPs.put(fieldInfo.name, writer.finish(dataOut));\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  public void writeField(FieldInfo fieldInfo, PointReader values) throws IOException {\n\n    // We use the normal BKDWriter, but subclass to customize how it writes the index and blocks to disk:\n    try (BKDWriter writer = new BKDWriter(writeState.segmentInfo.maxDoc(),\n                                          writeState.directory,\n                                          writeState.segmentInfo.name,\n                                          fieldInfo.getPointDimensionCount(),\n                                          fieldInfo.getPointNumBytes(),\n                                          BKDWriter.DEFAULT_MAX_POINTS_IN_LEAF_NODE,\n                                          BKDWriter.DEFAULT_MAX_MB_SORT_IN_HEAP) {\n\n        @Override\n        protected void writeIndex(IndexOutput out, long[] leafBlockFPs, byte[] splitPackedValues) throws IOException {\n          write(out, NUM_DIMS);\n          writeInt(out, numDims);\n          newline(out);\n\n          write(out, BYTES_PER_DIM);\n          writeInt(out, bytesPerDim);\n          newline(out);\n\n          write(out, MAX_LEAF_POINTS);\n          writeInt(out, maxPointsInLeafNode);\n          newline(out);\n\n          write(out, INDEX_COUNT);\n          writeInt(out, leafBlockFPs.length);\n          newline(out);\n\n          write(out, MIN_VALUE);\n          BytesRef br = new BytesRef(minPackedValue, 0, minPackedValue.length);\n          write(out, br.toString());\n          newline(out);\n\n          write(out, MAX_VALUE);\n          br = new BytesRef(maxPackedValue, 0, maxPackedValue.length);\n          write(out, br.toString());\n          newline(out);\n\n          write(out, POINT_COUNT);\n          writeLong(out, pointCount);\n          newline(out);\n\n          write(out, DOC_COUNT);\n          writeInt(out, docsSeen.cardinality());\n          newline(out);\n\n          for(int i=0;i<leafBlockFPs.length;i++) {\n            write(out, BLOCK_FP);\n            writeLong(out, leafBlockFPs[i]);\n            newline(out);\n          }\n\n          assert (splitPackedValues.length % (1 + fieldInfo.getPointNumBytes())) == 0;\n          int count = splitPackedValues.length / (1 + fieldInfo.getPointNumBytes());\n          assert count == leafBlockFPs.length;\n\n          write(out, SPLIT_COUNT);\n          writeInt(out, count);\n          newline(out);\n\n          for(int i=0;i<count;i++) {\n            write(out, SPLIT_DIM);\n            writeInt(out, splitPackedValues[i * (1 + fieldInfo.getPointNumBytes())] & 0xff);\n            newline(out);\n            write(out, SPLIT_VALUE);\n            br = new BytesRef(splitPackedValues, 1+(i * (1+fieldInfo.getPointNumBytes())), fieldInfo.getPointNumBytes());\n            write(out, br.toString());\n            newline(out);\n          }\n        }\n\n        @Override\n        protected void writeLeafBlockDocs(IndexOutput out, int[] docIDs, int start, int count) throws IOException {\n          write(out, BLOCK_COUNT);\n          writeInt(out, count);\n          newline(out);\n          for(int i=0;i<count;i++) {\n            write(out, BLOCK_DOC_ID);\n            writeInt(out, docIDs[start+i]);\n            newline(out);\n          }\n        }\n\n        @Override\n        protected void writeCommonPrefixes(IndexOutput out, int[] commonPrefixLengths, byte[] packedValue) {\n          // NOTE: we don't do prefix coding, so we ignore commonPrefixLengths\n        }\n\n        @Override\n        protected void writeLeafBlockPackedValue(IndexOutput out, int[] commonPrefixLengths, byte[] bytes) throws IOException {\n          // NOTE: we don't do prefix coding, so we ignore commonPrefixLengths\n          assert bytes.length == packedBytesLength;\n          write(out, BLOCK_VALUE);\n          write(out, new BytesRef(bytes, 0, bytes.length).toString());\n          newline(out);\n        }          \n      }) {\n\n      values.intersect(fieldInfo.name, new IntersectVisitor() {\n          @Override\n          public void visit(int docID) {\n            throw new IllegalStateException();\n          }\n\n          public void visit(int docID, byte[] packedValue) throws IOException {\n            writer.add(packedValue, docID);\n          }\n\n          @Override\n          public Relation compare(byte[] minPackedValue, byte[] maxPackedValue) {\n            return Relation.CELL_CROSSES_QUERY;\n          }\n        });\n\n      // We could have 0 points on merge since all docs with points may be deleted:\n      if (writer.getPointCount() > 0) {\n        indexFPs.put(fieldInfo.name, writer.finish(dataOut));\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"251c5b33f0a2c8988550b63c78ed22b0e84524e5":["879e8cf5ab626b9bf29f1ef603e3a28601fcb1a7"],"4522ffca5a1f420c6a02198c9332d7c596a30ca5":["cf1a614098b46c9c22afebd7b898ae4d1d2fc273"],"d2d93e80a51ae7994e1639fbd83763acdef9beb1":["cab7a79353f33d1a94cd307bf33aa5148601ebe6"],"cab7a79353f33d1a94cd307bf33aa5148601ebe6":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"acd1f5a977dc3b97799ed300423294e2c457774f":["cab7a79353f33d1a94cd307bf33aa5148601ebe6","d2d93e80a51ae7994e1639fbd83763acdef9beb1"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"1e6acbaae7af722f17204ceccf0f7db5753eccf3":["cab7a79353f33d1a94cd307bf33aa5148601ebe6","d2d93e80a51ae7994e1639fbd83763acdef9beb1"],"879e8cf5ab626b9bf29f1ef603e3a28601fcb1a7":["d2d93e80a51ae7994e1639fbd83763acdef9beb1"],"cf1a614098b46c9c22afebd7b898ae4d1d2fc273":["d2d93e80a51ae7994e1639fbd83763acdef9beb1","251c5b33f0a2c8988550b63c78ed22b0e84524e5"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["4522ffca5a1f420c6a02198c9332d7c596a30ca5"]},"commit2Childs":{"251c5b33f0a2c8988550b63c78ed22b0e84524e5":["cf1a614098b46c9c22afebd7b898ae4d1d2fc273"],"4522ffca5a1f420c6a02198c9332d7c596a30ca5":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"d2d93e80a51ae7994e1639fbd83763acdef9beb1":["acd1f5a977dc3b97799ed300423294e2c457774f","1e6acbaae7af722f17204ceccf0f7db5753eccf3","879e8cf5ab626b9bf29f1ef603e3a28601fcb1a7","cf1a614098b46c9c22afebd7b898ae4d1d2fc273"],"cab7a79353f33d1a94cd307bf33aa5148601ebe6":["d2d93e80a51ae7994e1639fbd83763acdef9beb1","acd1f5a977dc3b97799ed300423294e2c457774f","1e6acbaae7af722f17204ceccf0f7db5753eccf3"],"acd1f5a977dc3b97799ed300423294e2c457774f":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["cab7a79353f33d1a94cd307bf33aa5148601ebe6"],"1e6acbaae7af722f17204ceccf0f7db5753eccf3":[],"879e8cf5ab626b9bf29f1ef603e3a28601fcb1a7":["251c5b33f0a2c8988550b63c78ed22b0e84524e5"],"cf1a614098b46c9c22afebd7b898ae4d1d2fc273":["4522ffca5a1f420c6a02198c9332d7c596a30ca5"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["acd1f5a977dc3b97799ed300423294e2c457774f","1e6acbaae7af722f17204ceccf0f7db5753eccf3","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}