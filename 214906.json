{"path":"lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestConditionalTokenFilter#testFilteredTokenFilters().mjava","commits":[{"id":"57e34488c685935a055be1bc57b850be1e8c850d","date":1526645499,"type":0,"author":"Alan Woodward","isMerge":false,"pathNew":"lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestConditionalTokenFilter#testFilteredTokenFilters().mjava","pathOld":"/dev/null","sourceNew":"  public void testFilteredTokenFilters() throws IOException {\n\n    CharArraySet exclusions = new CharArraySet(2, true);\n    exclusions.add(\"foobar\");\n\n    TokenStream ts = whitespaceMockTokenizer(\"wuthering foobar abc\");\n    ts = new TermExclusionFilter(exclusions, ts, in -> new LengthFilter(in, 1, 4));\n    assertTokenStreamContents(ts, new String[]{ \"foobar\", \"abc\" });\n\n    ts = whitespaceMockTokenizer(\"foobar abc\");\n    ts = new TermExclusionFilter(exclusions, ts, in -> new LengthFilter(in, 1, 4));\n    assertTokenStreamContents(ts, new String[]{ \"foobar\", \"abc\" });\n\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9809bf55e3bf03659b8b93fd16170aaa7eb92012","date":1526860327,"type":3,"author":"Steve Rowe","isMerge":false,"pathNew":"lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestConditionalTokenFilter#testFilteredTokenFilters().mjava","pathOld":"lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestConditionalTokenFilter#testFilteredTokenFilters().mjava","sourceNew":"  public void testFilteredTokenFilters() throws IOException {\n\n    CharArraySet protectedTerms = new CharArraySet(2, true);\n    protectedTerms.add(\"foobar\");\n\n    TokenStream ts = whitespaceMockTokenizer(\"wuthering foobar abc\");\n    ts = new ProtectedTermFilter(protectedTerms, ts, in -> new LengthFilter(in, 1, 4));\n    assertTokenStreamContents(ts, new String[]{ \"foobar\", \"abc\" });\n\n    ts = whitespaceMockTokenizer(\"foobar abc\");\n    ts = new ProtectedTermFilter(protectedTerms, ts, in -> new LengthFilter(in, 1, 4));\n    assertTokenStreamContents(ts, new String[]{ \"foobar\", \"abc\" });\n\n  }\n\n","sourceOld":"  public void testFilteredTokenFilters() throws IOException {\n\n    CharArraySet exclusions = new CharArraySet(2, true);\n    exclusions.add(\"foobar\");\n\n    TokenStream ts = whitespaceMockTokenizer(\"wuthering foobar abc\");\n    ts = new TermExclusionFilter(exclusions, ts, in -> new LengthFilter(in, 1, 4));\n    assertTokenStreamContents(ts, new String[]{ \"foobar\", \"abc\" });\n\n    ts = whitespaceMockTokenizer(\"foobar abc\");\n    ts = new TermExclusionFilter(exclusions, ts, in -> new LengthFilter(in, 1, 4));\n    assertTokenStreamContents(ts, new String[]{ \"foobar\", \"abc\" });\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"9809bf55e3bf03659b8b93fd16170aaa7eb92012":["57e34488c685935a055be1bc57b850be1e8c850d"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"57e34488c685935a055be1bc57b850be1e8c850d":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["9809bf55e3bf03659b8b93fd16170aaa7eb92012"]},"commit2Childs":{"9809bf55e3bf03659b8b93fd16170aaa7eb92012":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["57e34488c685935a055be1bc57b850be1e8c850d"],"57e34488c685935a055be1bc57b850be1e8c850d":["9809bf55e3bf03659b8b93fd16170aaa7eb92012"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}