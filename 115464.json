{"path":"lucene/core/src/test/org/apache/lucene/index/TestDirectoryReader#testTermVectors().mjava","commits":[{"id":"83e99d44c4a660a48c0fcc7a0108ad0a56dc2f87","date":1328967626,"type":0,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDirectoryReader#testTermVectors().mjava","pathOld":"/dev/null","sourceNew":"public void testTermVectors() throws Exception {\n  Directory d = newDirectory();\n  // set up writer\n  IndexWriter writer = new IndexWriter(\n      d,\n      newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n          setMergePolicy(newLogMergePolicy())\n  );\n  // want to get some more segments here\n  // new termvector fields\n  int mergeFactor = ((LogMergePolicy) writer.getConfig().getMergePolicy()).getMergeFactor();\n  FieldType customType5 = new FieldType(TextField.TYPE_STORED);\n  customType5.setStoreTermVectors(true);\n  FieldType customType6 = new FieldType(TextField.TYPE_STORED);\n  customType6.setStoreTermVectors(true);\n  customType6.setStoreTermVectorOffsets(true);\n  FieldType customType7 = new FieldType(TextField.TYPE_STORED);\n  customType7.setStoreTermVectors(true);\n  customType7.setStoreTermVectorPositions(true);\n  FieldType customType8 = new FieldType(TextField.TYPE_STORED);\n  customType8.setStoreTermVectors(true);\n  customType8.setStoreTermVectorOffsets(true);\n  customType8.setStoreTermVectorPositions(true);\n  for (int i = 0; i < 5 * mergeFactor; i++) {\n    Document doc = new Document();\n      doc.add(new Field(\"tvnot\", \"one two two three three three\", TextField.TYPE_STORED));\n      doc.add(new Field(\"termvector\", \"one two two three three three\", customType5));\n      doc.add(new Field(\"tvoffset\", \"one two two three three three\", customType6));\n      doc.add(new Field(\"tvposition\", \"one two two three three three\", customType7));\n      doc.add(new Field(\"tvpositionoffset\", \"one two two three three three\", customType8));\n      \n      writer.addDocument(doc);\n  }\n  writer.close();\n  d.close();\n}\n\n","sourceOld":null,"bugFix":null,"bugIntro":["04f07771a2a7dd3a395700665ed839c3dae2def2"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"629c38c4ae4e303d0617e05fbfe508140b32f0a3","date":1334500904,"type":3,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDirectoryReader#testTermVectors().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDirectoryReader#testTermVectors().mjava","sourceNew":"public void testTermVectors() throws Exception {\n  Directory d = newDirectory();\n  // set up writer\n  IndexWriter writer = new IndexWriter(\n      d,\n      newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).\n          setMergePolicy(newLogMergePolicy())\n  );\n  // want to get some more segments here\n  // new termvector fields\n  int mergeFactor = ((LogMergePolicy) writer.getConfig().getMergePolicy()).getMergeFactor();\n  FieldType customType5 = new FieldType(TextField.TYPE_STORED);\n  customType5.setStoreTermVectors(true);\n  FieldType customType6 = new FieldType(TextField.TYPE_STORED);\n  customType6.setStoreTermVectors(true);\n  customType6.setStoreTermVectorOffsets(true);\n  FieldType customType7 = new FieldType(TextField.TYPE_STORED);\n  customType7.setStoreTermVectors(true);\n  customType7.setStoreTermVectorPositions(true);\n  FieldType customType8 = new FieldType(TextField.TYPE_STORED);\n  customType8.setStoreTermVectors(true);\n  customType8.setStoreTermVectorOffsets(true);\n  customType8.setStoreTermVectorPositions(true);\n  for (int i = 0; i < 5 * mergeFactor; i++) {\n    Document doc = new Document();\n      doc.add(new Field(\"tvnot\", \"one two two three three three\", TextField.TYPE_STORED));\n      doc.add(new Field(\"termvector\", \"one two two three three three\", customType5));\n      doc.add(new Field(\"tvoffset\", \"one two two three three three\", customType6));\n      doc.add(new Field(\"tvposition\", \"one two two three three three\", customType7));\n      doc.add(new Field(\"tvpositionoffset\", \"one two two three three three\", customType8));\n      \n      writer.addDocument(doc);\n  }\n  writer.close();\n  d.close();\n}\n\n","sourceOld":"public void testTermVectors() throws Exception {\n  Directory d = newDirectory();\n  // set up writer\n  IndexWriter writer = new IndexWriter(\n      d,\n      newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n          setMergePolicy(newLogMergePolicy())\n  );\n  // want to get some more segments here\n  // new termvector fields\n  int mergeFactor = ((LogMergePolicy) writer.getConfig().getMergePolicy()).getMergeFactor();\n  FieldType customType5 = new FieldType(TextField.TYPE_STORED);\n  customType5.setStoreTermVectors(true);\n  FieldType customType6 = new FieldType(TextField.TYPE_STORED);\n  customType6.setStoreTermVectors(true);\n  customType6.setStoreTermVectorOffsets(true);\n  FieldType customType7 = new FieldType(TextField.TYPE_STORED);\n  customType7.setStoreTermVectors(true);\n  customType7.setStoreTermVectorPositions(true);\n  FieldType customType8 = new FieldType(TextField.TYPE_STORED);\n  customType8.setStoreTermVectors(true);\n  customType8.setStoreTermVectorOffsets(true);\n  customType8.setStoreTermVectorPositions(true);\n  for (int i = 0; i < 5 * mergeFactor; i++) {\n    Document doc = new Document();\n      doc.add(new Field(\"tvnot\", \"one two two three three three\", TextField.TYPE_STORED));\n      doc.add(new Field(\"termvector\", \"one two two three three three\", customType5));\n      doc.add(new Field(\"tvoffset\", \"one two two three three three\", customType6));\n      doc.add(new Field(\"tvposition\", \"one two two three three three\", customType7));\n      doc.add(new Field(\"tvpositionoffset\", \"one two two three three three\", customType8));\n      \n      writer.addDocument(doc);\n  }\n  writer.close();\n  d.close();\n}\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"04f07771a2a7dd3a395700665ed839c3dae2def2","date":1339350139,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDirectoryReader#testTermVectors().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDirectoryReader#testTermVectors().mjava","sourceNew":"public void testTermVectors() throws Exception {\n  Directory d = newDirectory();\n  // set up writer\n  IndexWriter writer = new IndexWriter(\n      d,\n      newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).\n          setMergePolicy(newLogMergePolicy())\n  );\n  // want to get some more segments here\n  // new termvector fields\n  int mergeFactor = ((LogMergePolicy) writer.getConfig().getMergePolicy()).getMergeFactor();\n  FieldType customType5 = new FieldType(TextField.TYPE_STORED);\n  customType5.setStoreTermVectors(true);\n  FieldType customType6 = new FieldType(TextField.TYPE_STORED);\n  customType6.setStoreTermVectors(true);\n  customType6.setStoreTermVectorOffsets(true);\n  FieldType customType7 = new FieldType(TextField.TYPE_STORED);\n  customType7.setStoreTermVectors(true);\n  customType7.setStoreTermVectorPositions(true);\n  FieldType customType8 = new FieldType(TextField.TYPE_STORED);\n  customType8.setStoreTermVectors(true);\n  customType8.setStoreTermVectorOffsets(true);\n  customType8.setStoreTermVectorPositions(true);\n  for (int i = 0; i < 5 * mergeFactor; i++) {\n    Document doc = new Document();\n      doc.add(new TextField(\"tvnot\", \"one two two three three three\", Field.Store.YES));\n      doc.add(new Field(\"termvector\", \"one two two three three three\", customType5));\n      doc.add(new Field(\"tvoffset\", \"one two two three three three\", customType6));\n      doc.add(new Field(\"tvposition\", \"one two two three three three\", customType7));\n      doc.add(new Field(\"tvpositionoffset\", \"one two two three three three\", customType8));\n      \n      writer.addDocument(doc);\n  }\n  writer.close();\n  d.close();\n}\n\n","sourceOld":"public void testTermVectors() throws Exception {\n  Directory d = newDirectory();\n  // set up writer\n  IndexWriter writer = new IndexWriter(\n      d,\n      newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).\n          setMergePolicy(newLogMergePolicy())\n  );\n  // want to get some more segments here\n  // new termvector fields\n  int mergeFactor = ((LogMergePolicy) writer.getConfig().getMergePolicy()).getMergeFactor();\n  FieldType customType5 = new FieldType(TextField.TYPE_STORED);\n  customType5.setStoreTermVectors(true);\n  FieldType customType6 = new FieldType(TextField.TYPE_STORED);\n  customType6.setStoreTermVectors(true);\n  customType6.setStoreTermVectorOffsets(true);\n  FieldType customType7 = new FieldType(TextField.TYPE_STORED);\n  customType7.setStoreTermVectors(true);\n  customType7.setStoreTermVectorPositions(true);\n  FieldType customType8 = new FieldType(TextField.TYPE_STORED);\n  customType8.setStoreTermVectors(true);\n  customType8.setStoreTermVectorOffsets(true);\n  customType8.setStoreTermVectorPositions(true);\n  for (int i = 0; i < 5 * mergeFactor; i++) {\n    Document doc = new Document();\n      doc.add(new Field(\"tvnot\", \"one two two three three three\", TextField.TYPE_STORED));\n      doc.add(new Field(\"termvector\", \"one two two three three three\", customType5));\n      doc.add(new Field(\"tvoffset\", \"one two two three three three\", customType6));\n      doc.add(new Field(\"tvposition\", \"one two two three three three\", customType7));\n      doc.add(new Field(\"tvpositionoffset\", \"one two two three three three\", customType8));\n      \n      writer.addDocument(doc);\n  }\n  writer.close();\n  d.close();\n}\n\n","bugFix":["83e99d44c4a660a48c0fcc7a0108ad0a56dc2f87"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ae14298f4eec6d5faee6a149f88ba57d14a6f21a","date":1396971290,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDirectoryReader#testTermVectors().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDirectoryReader#testTermVectors().mjava","sourceNew":"public void testTermVectors() throws Exception {\n  Directory d = newDirectory();\n  // set up writer\n  IndexWriter writer = new IndexWriter(\n      d,\n      newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).\n          setMergePolicy(newLogMergePolicy())\n  );\n  // want to get some more segments here\n  // new termvector fields\n  int mergeFactor = ((LogMergePolicy) writer.getConfig().getMergePolicy()).getMergeFactor();\n  FieldType customType5 = new FieldType(TextField.TYPE_STORED);\n  customType5.setStoreTermVectors(true);\n  FieldType customType6 = new FieldType(TextField.TYPE_STORED);\n  customType6.setStoreTermVectors(true);\n  customType6.setStoreTermVectorOffsets(true);\n  FieldType customType7 = new FieldType(TextField.TYPE_STORED);\n  customType7.setStoreTermVectors(true);\n  customType7.setStoreTermVectorPositions(true);\n  FieldType customType8 = new FieldType(TextField.TYPE_STORED);\n  customType8.setStoreTermVectors(true);\n  customType8.setStoreTermVectorOffsets(true);\n  customType8.setStoreTermVectorPositions(true);\n  for (int i = 0; i < 5 * mergeFactor; i++) {\n    Document doc = new Document();\n      doc.add(new TextField(\"tvnot\", \"one two two three three three\", Field.Store.YES));\n      doc.add(new Field(\"termvector\", \"one two two three three three\", customType5));\n      doc.add(new Field(\"tvoffset\", \"one two two three three three\", customType6));\n      doc.add(new Field(\"tvposition\", \"one two two three three three\", customType7));\n      doc.add(new Field(\"tvpositionoffset\", \"one two two three three three\", customType8));\n      \n      writer.addDocument(doc);\n  }\n  writer.shutdown();\n  d.close();\n}\n\n","sourceOld":"public void testTermVectors() throws Exception {\n  Directory d = newDirectory();\n  // set up writer\n  IndexWriter writer = new IndexWriter(\n      d,\n      newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).\n          setMergePolicy(newLogMergePolicy())\n  );\n  // want to get some more segments here\n  // new termvector fields\n  int mergeFactor = ((LogMergePolicy) writer.getConfig().getMergePolicy()).getMergeFactor();\n  FieldType customType5 = new FieldType(TextField.TYPE_STORED);\n  customType5.setStoreTermVectors(true);\n  FieldType customType6 = new FieldType(TextField.TYPE_STORED);\n  customType6.setStoreTermVectors(true);\n  customType6.setStoreTermVectorOffsets(true);\n  FieldType customType7 = new FieldType(TextField.TYPE_STORED);\n  customType7.setStoreTermVectors(true);\n  customType7.setStoreTermVectorPositions(true);\n  FieldType customType8 = new FieldType(TextField.TYPE_STORED);\n  customType8.setStoreTermVectors(true);\n  customType8.setStoreTermVectorOffsets(true);\n  customType8.setStoreTermVectorPositions(true);\n  for (int i = 0; i < 5 * mergeFactor; i++) {\n    Document doc = new Document();\n      doc.add(new TextField(\"tvnot\", \"one two two three three three\", Field.Store.YES));\n      doc.add(new Field(\"termvector\", \"one two two three three three\", customType5));\n      doc.add(new Field(\"tvoffset\", \"one two two three three three\", customType6));\n      doc.add(new Field(\"tvposition\", \"one two two three three three\", customType7));\n      doc.add(new Field(\"tvpositionoffset\", \"one two two three three three\", customType8));\n      \n      writer.addDocument(doc);\n  }\n  writer.close();\n  d.close();\n}\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e","date":1406737224,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDirectoryReader#testTermVectors().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDirectoryReader#testTermVectors().mjava","sourceNew":"public void testTermVectors() throws Exception {\n  Directory d = newDirectory();\n  // set up writer\n  IndexWriter writer = new IndexWriter(\n      d,\n      newIndexWriterConfig(new MockAnalyzer(random()))\n          .setMergePolicy(newLogMergePolicy())\n  );\n  // want to get some more segments here\n  // new termvector fields\n  int mergeFactor = ((LogMergePolicy) writer.getConfig().getMergePolicy()).getMergeFactor();\n  FieldType customType5 = new FieldType(TextField.TYPE_STORED);\n  customType5.setStoreTermVectors(true);\n  FieldType customType6 = new FieldType(TextField.TYPE_STORED);\n  customType6.setStoreTermVectors(true);\n  customType6.setStoreTermVectorOffsets(true);\n  FieldType customType7 = new FieldType(TextField.TYPE_STORED);\n  customType7.setStoreTermVectors(true);\n  customType7.setStoreTermVectorPositions(true);\n  FieldType customType8 = new FieldType(TextField.TYPE_STORED);\n  customType8.setStoreTermVectors(true);\n  customType8.setStoreTermVectorOffsets(true);\n  customType8.setStoreTermVectorPositions(true);\n  for (int i = 0; i < 5 * mergeFactor; i++) {\n    Document doc = new Document();\n      doc.add(new TextField(\"tvnot\", \"one two two three three three\", Field.Store.YES));\n      doc.add(new Field(\"termvector\", \"one two two three three three\", customType5));\n      doc.add(new Field(\"tvoffset\", \"one two two three three three\", customType6));\n      doc.add(new Field(\"tvposition\", \"one two two three three three\", customType7));\n      doc.add(new Field(\"tvpositionoffset\", \"one two two three three three\", customType8));\n      \n      writer.addDocument(doc);\n  }\n  writer.shutdown();\n  d.close();\n}\n\n","sourceOld":"public void testTermVectors() throws Exception {\n  Directory d = newDirectory();\n  // set up writer\n  IndexWriter writer = new IndexWriter(\n      d,\n      newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).\n          setMergePolicy(newLogMergePolicy())\n  );\n  // want to get some more segments here\n  // new termvector fields\n  int mergeFactor = ((LogMergePolicy) writer.getConfig().getMergePolicy()).getMergeFactor();\n  FieldType customType5 = new FieldType(TextField.TYPE_STORED);\n  customType5.setStoreTermVectors(true);\n  FieldType customType6 = new FieldType(TextField.TYPE_STORED);\n  customType6.setStoreTermVectors(true);\n  customType6.setStoreTermVectorOffsets(true);\n  FieldType customType7 = new FieldType(TextField.TYPE_STORED);\n  customType7.setStoreTermVectors(true);\n  customType7.setStoreTermVectorPositions(true);\n  FieldType customType8 = new FieldType(TextField.TYPE_STORED);\n  customType8.setStoreTermVectors(true);\n  customType8.setStoreTermVectorOffsets(true);\n  customType8.setStoreTermVectorPositions(true);\n  for (int i = 0; i < 5 * mergeFactor; i++) {\n    Document doc = new Document();\n      doc.add(new TextField(\"tvnot\", \"one two two three three three\", Field.Store.YES));\n      doc.add(new Field(\"termvector\", \"one two two three three three\", customType5));\n      doc.add(new Field(\"tvoffset\", \"one two two three three three\", customType6));\n      doc.add(new Field(\"tvposition\", \"one two two three three three\", customType7));\n      doc.add(new Field(\"tvpositionoffset\", \"one two two three three three\", customType8));\n      \n      writer.addDocument(doc);\n  }\n  writer.shutdown();\n  d.close();\n}\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d0ef034a4f10871667ae75181537775ddcf8ade4","date":1407610475,"type":3,"author":"Ryan Ernst","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDirectoryReader#testTermVectors().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDirectoryReader#testTermVectors().mjava","sourceNew":"public void testTermVectors() throws Exception {\n  Directory d = newDirectory();\n  // set up writer\n  IndexWriter writer = new IndexWriter(\n      d,\n      newIndexWriterConfig(new MockAnalyzer(random()))\n          .setMergePolicy(newLogMergePolicy())\n  );\n  // want to get some more segments here\n  // new termvector fields\n  int mergeFactor = ((LogMergePolicy) writer.getConfig().getMergePolicy()).getMergeFactor();\n  FieldType customType5 = new FieldType(TextField.TYPE_STORED);\n  customType5.setStoreTermVectors(true);\n  FieldType customType6 = new FieldType(TextField.TYPE_STORED);\n  customType6.setStoreTermVectors(true);\n  customType6.setStoreTermVectorOffsets(true);\n  FieldType customType7 = new FieldType(TextField.TYPE_STORED);\n  customType7.setStoreTermVectors(true);\n  customType7.setStoreTermVectorPositions(true);\n  FieldType customType8 = new FieldType(TextField.TYPE_STORED);\n  customType8.setStoreTermVectors(true);\n  customType8.setStoreTermVectorOffsets(true);\n  customType8.setStoreTermVectorPositions(true);\n  for (int i = 0; i < 5 * mergeFactor; i++) {\n    Document doc = new Document();\n      doc.add(new TextField(\"tvnot\", \"one two two three three three\", Field.Store.YES));\n      doc.add(new Field(\"termvector\", \"one two two three three three\", customType5));\n      doc.add(new Field(\"tvoffset\", \"one two two three three three\", customType6));\n      doc.add(new Field(\"tvposition\", \"one two two three three three\", customType7));\n      doc.add(new Field(\"tvpositionoffset\", \"one two two three three three\", customType8));\n      \n      writer.addDocument(doc);\n  }\n  writer.close();\n  d.close();\n}\n\n","sourceOld":"public void testTermVectors() throws Exception {\n  Directory d = newDirectory();\n  // set up writer\n  IndexWriter writer = new IndexWriter(\n      d,\n      newIndexWriterConfig(new MockAnalyzer(random()))\n          .setMergePolicy(newLogMergePolicy())\n  );\n  // want to get some more segments here\n  // new termvector fields\n  int mergeFactor = ((LogMergePolicy) writer.getConfig().getMergePolicy()).getMergeFactor();\n  FieldType customType5 = new FieldType(TextField.TYPE_STORED);\n  customType5.setStoreTermVectors(true);\n  FieldType customType6 = new FieldType(TextField.TYPE_STORED);\n  customType6.setStoreTermVectors(true);\n  customType6.setStoreTermVectorOffsets(true);\n  FieldType customType7 = new FieldType(TextField.TYPE_STORED);\n  customType7.setStoreTermVectors(true);\n  customType7.setStoreTermVectorPositions(true);\n  FieldType customType8 = new FieldType(TextField.TYPE_STORED);\n  customType8.setStoreTermVectors(true);\n  customType8.setStoreTermVectorOffsets(true);\n  customType8.setStoreTermVectorPositions(true);\n  for (int i = 0; i < 5 * mergeFactor; i++) {\n    Document doc = new Document();\n      doc.add(new TextField(\"tvnot\", \"one two two three three three\", Field.Store.YES));\n      doc.add(new Field(\"termvector\", \"one two two three three three\", customType5));\n      doc.add(new Field(\"tvoffset\", \"one two two three three three\", customType6));\n      doc.add(new Field(\"tvposition\", \"one two two three three three\", customType7));\n      doc.add(new Field(\"tvpositionoffset\", \"one two two three three three\", customType8));\n      \n      writer.addDocument(doc);\n  }\n  writer.shutdown();\n  d.close();\n}\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"34d6426cef006e0c3625cabe7a7ec1c2b08bc501","date":1454683374,"type":3,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDirectoryReader#testTermVectors().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDirectoryReader#testTermVectors().mjava","sourceNew":"  public void testTermVectors() throws Exception {\n    Directory d = newDirectory();\n    // set up writer\n    IndexWriter writer = new IndexWriter(\n                                         d,\n                                         newIndexWriterConfig(new MockAnalyzer(random()))\n                                         .setMergePolicy(newLogMergePolicy())\n                                         );\n    // want to get some more segments here\n    // new termvector fields\n    int mergeFactor = ((LogMergePolicy) writer.getConfig().getMergePolicy()).getMergeFactor();\n    FieldType customType5 = new FieldType(TextField.TYPE_STORED);\n    customType5.setStoreTermVectors(true);\n    FieldType customType6 = new FieldType(TextField.TYPE_STORED);\n    customType6.setStoreTermVectors(true);\n    customType6.setStoreTermVectorOffsets(true);\n    FieldType customType7 = new FieldType(TextField.TYPE_STORED);\n    customType7.setStoreTermVectors(true);\n    customType7.setStoreTermVectorPositions(true);\n    FieldType customType8 = new FieldType(TextField.TYPE_STORED);\n    customType8.setStoreTermVectors(true);\n    customType8.setStoreTermVectorOffsets(true);\n    customType8.setStoreTermVectorPositions(true);\n    for (int i = 0; i < 5 * mergeFactor; i++) {\n      Document doc = new Document();\n      doc.add(new TextField(\"tvnot\", \"one two two three three three\", Field.Store.YES));\n      doc.add(new Field(\"termvector\", \"one two two three three three\", customType5));\n      doc.add(new Field(\"tvoffset\", \"one two two three three three\", customType6));\n      doc.add(new Field(\"tvposition\", \"one two two three three three\", customType7));\n      doc.add(new Field(\"tvpositionoffset\", \"one two two three three three\", customType8));\n      \n      writer.addDocument(doc);\n    }\n    writer.close();\n    d.close();\n  }\n\n","sourceOld":"public void testTermVectors() throws Exception {\n  Directory d = newDirectory();\n  // set up writer\n  IndexWriter writer = new IndexWriter(\n      d,\n      newIndexWriterConfig(new MockAnalyzer(random()))\n          .setMergePolicy(newLogMergePolicy())\n  );\n  // want to get some more segments here\n  // new termvector fields\n  int mergeFactor = ((LogMergePolicy) writer.getConfig().getMergePolicy()).getMergeFactor();\n  FieldType customType5 = new FieldType(TextField.TYPE_STORED);\n  customType5.setStoreTermVectors(true);\n  FieldType customType6 = new FieldType(TextField.TYPE_STORED);\n  customType6.setStoreTermVectors(true);\n  customType6.setStoreTermVectorOffsets(true);\n  FieldType customType7 = new FieldType(TextField.TYPE_STORED);\n  customType7.setStoreTermVectors(true);\n  customType7.setStoreTermVectorPositions(true);\n  FieldType customType8 = new FieldType(TextField.TYPE_STORED);\n  customType8.setStoreTermVectors(true);\n  customType8.setStoreTermVectorOffsets(true);\n  customType8.setStoreTermVectorPositions(true);\n  for (int i = 0; i < 5 * mergeFactor; i++) {\n    Document doc = new Document();\n      doc.add(new TextField(\"tvnot\", \"one two two three three three\", Field.Store.YES));\n      doc.add(new Field(\"termvector\", \"one two two three three three\", customType5));\n      doc.add(new Field(\"tvoffset\", \"one two two three three three\", customType6));\n      doc.add(new Field(\"tvposition\", \"one two two three three three\", customType7));\n      doc.add(new Field(\"tvpositionoffset\", \"one two two three three three\", customType8));\n      \n      writer.addDocument(doc);\n  }\n  writer.close();\n  d.close();\n}\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b470f36a9372c97283360b1304eacbde22df6c0d","date":1454765175,"type":3,"author":"Mike McCandless","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDirectoryReader#testTermVectors().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDirectoryReader#testTermVectors().mjava","sourceNew":"  public void testTermVectors() throws Exception {\n    Directory d = newDirectory();\n    // set up writer\n    IndexWriter writer = new IndexWriter(\n                                         d,\n                                         newIndexWriterConfig(new MockAnalyzer(random()))\n                                         .setMergePolicy(newLogMergePolicy())\n                                         );\n    // want to get some more segments here\n    // new termvector fields\n    int mergeFactor = ((LogMergePolicy) writer.getConfig().getMergePolicy()).getMergeFactor();\n    FieldType customType5 = new FieldType(TextField.TYPE_STORED);\n    customType5.setStoreTermVectors(true);\n    FieldType customType6 = new FieldType(TextField.TYPE_STORED);\n    customType6.setStoreTermVectors(true);\n    customType6.setStoreTermVectorOffsets(true);\n    FieldType customType7 = new FieldType(TextField.TYPE_STORED);\n    customType7.setStoreTermVectors(true);\n    customType7.setStoreTermVectorPositions(true);\n    FieldType customType8 = new FieldType(TextField.TYPE_STORED);\n    customType8.setStoreTermVectors(true);\n    customType8.setStoreTermVectorOffsets(true);\n    customType8.setStoreTermVectorPositions(true);\n    for (int i = 0; i < 5 * mergeFactor; i++) {\n      Document doc = new Document();\n      doc.add(new TextField(\"tvnot\", \"one two two three three three\", Field.Store.YES));\n      doc.add(new Field(\"termvector\", \"one two two three three three\", customType5));\n      doc.add(new Field(\"tvoffset\", \"one two two three three three\", customType6));\n      doc.add(new Field(\"tvposition\", \"one two two three three three\", customType7));\n      doc.add(new Field(\"tvpositionoffset\", \"one two two three three three\", customType8));\n      \n      writer.addDocument(doc);\n    }\n    writer.close();\n    d.close();\n  }\n\n","sourceOld":"public void testTermVectors() throws Exception {\n  Directory d = newDirectory();\n  // set up writer\n  IndexWriter writer = new IndexWriter(\n      d,\n      newIndexWriterConfig(new MockAnalyzer(random()))\n          .setMergePolicy(newLogMergePolicy())\n  );\n  // want to get some more segments here\n  // new termvector fields\n  int mergeFactor = ((LogMergePolicy) writer.getConfig().getMergePolicy()).getMergeFactor();\n  FieldType customType5 = new FieldType(TextField.TYPE_STORED);\n  customType5.setStoreTermVectors(true);\n  FieldType customType6 = new FieldType(TextField.TYPE_STORED);\n  customType6.setStoreTermVectors(true);\n  customType6.setStoreTermVectorOffsets(true);\n  FieldType customType7 = new FieldType(TextField.TYPE_STORED);\n  customType7.setStoreTermVectors(true);\n  customType7.setStoreTermVectorPositions(true);\n  FieldType customType8 = new FieldType(TextField.TYPE_STORED);\n  customType8.setStoreTermVectors(true);\n  customType8.setStoreTermVectorOffsets(true);\n  customType8.setStoreTermVectorPositions(true);\n  for (int i = 0; i < 5 * mergeFactor; i++) {\n    Document doc = new Document();\n      doc.add(new TextField(\"tvnot\", \"one two two three three three\", Field.Store.YES));\n      doc.add(new Field(\"termvector\", \"one two two three three three\", customType5));\n      doc.add(new Field(\"tvoffset\", \"one two two three three three\", customType6));\n      doc.add(new Field(\"tvposition\", \"one two two three three three\", customType7));\n      doc.add(new Field(\"tvpositionoffset\", \"one two two three three three\", customType8));\n      \n      writer.addDocument(doc);\n  }\n  writer.close();\n  d.close();\n}\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1e6acbaae7af722f17204ceccf0f7db5753eccf3","date":1454775255,"type":3,"author":"Mike McCandless","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDirectoryReader#testTermVectors().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDirectoryReader#testTermVectors().mjava","sourceNew":"  public void testTermVectors() throws Exception {\n    Directory d = newDirectory();\n    // set up writer\n    IndexWriter writer = new IndexWriter(\n                                         d,\n                                         newIndexWriterConfig(new MockAnalyzer(random()))\n                                         .setMergePolicy(newLogMergePolicy())\n                                         );\n    // want to get some more segments here\n    // new termvector fields\n    int mergeFactor = ((LogMergePolicy) writer.getConfig().getMergePolicy()).getMergeFactor();\n    FieldType customType5 = new FieldType(TextField.TYPE_STORED);\n    customType5.setStoreTermVectors(true);\n    FieldType customType6 = new FieldType(TextField.TYPE_STORED);\n    customType6.setStoreTermVectors(true);\n    customType6.setStoreTermVectorOffsets(true);\n    FieldType customType7 = new FieldType(TextField.TYPE_STORED);\n    customType7.setStoreTermVectors(true);\n    customType7.setStoreTermVectorPositions(true);\n    FieldType customType8 = new FieldType(TextField.TYPE_STORED);\n    customType8.setStoreTermVectors(true);\n    customType8.setStoreTermVectorOffsets(true);\n    customType8.setStoreTermVectorPositions(true);\n    for (int i = 0; i < 5 * mergeFactor; i++) {\n      Document doc = new Document();\n      doc.add(new TextField(\"tvnot\", \"one two two three three three\", Field.Store.YES));\n      doc.add(new Field(\"termvector\", \"one two two three three three\", customType5));\n      doc.add(new Field(\"tvoffset\", \"one two two three three three\", customType6));\n      doc.add(new Field(\"tvposition\", \"one two two three three three\", customType7));\n      doc.add(new Field(\"tvpositionoffset\", \"one two two three three three\", customType8));\n      \n      writer.addDocument(doc);\n    }\n    writer.close();\n    d.close();\n  }\n\n","sourceOld":"public void testTermVectors() throws Exception {\n  Directory d = newDirectory();\n  // set up writer\n  IndexWriter writer = new IndexWriter(\n      d,\n      newIndexWriterConfig(new MockAnalyzer(random()))\n          .setMergePolicy(newLogMergePolicy())\n  );\n  // want to get some more segments here\n  // new termvector fields\n  int mergeFactor = ((LogMergePolicy) writer.getConfig().getMergePolicy()).getMergeFactor();\n  FieldType customType5 = new FieldType(TextField.TYPE_STORED);\n  customType5.setStoreTermVectors(true);\n  FieldType customType6 = new FieldType(TextField.TYPE_STORED);\n  customType6.setStoreTermVectors(true);\n  customType6.setStoreTermVectorOffsets(true);\n  FieldType customType7 = new FieldType(TextField.TYPE_STORED);\n  customType7.setStoreTermVectors(true);\n  customType7.setStoreTermVectorPositions(true);\n  FieldType customType8 = new FieldType(TextField.TYPE_STORED);\n  customType8.setStoreTermVectors(true);\n  customType8.setStoreTermVectorOffsets(true);\n  customType8.setStoreTermVectorPositions(true);\n  for (int i = 0; i < 5 * mergeFactor; i++) {\n    Document doc = new Document();\n      doc.add(new TextField(\"tvnot\", \"one two two three three three\", Field.Store.YES));\n      doc.add(new Field(\"termvector\", \"one two two three three three\", customType5));\n      doc.add(new Field(\"tvoffset\", \"one two two three three three\", customType6));\n      doc.add(new Field(\"tvposition\", \"one two two three three three\", customType7));\n      doc.add(new Field(\"tvpositionoffset\", \"one two two three three three\", customType8));\n      \n      writer.addDocument(doc);\n  }\n  writer.close();\n  d.close();\n}\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5a207d19eac354d649c3f0e2cce070017c78125e","date":1454776470,"type":3,"author":"Erick Erickson","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDirectoryReader#testTermVectors().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDirectoryReader#testTermVectors().mjava","sourceNew":"  public void testTermVectors() throws Exception {\n    Directory d = newDirectory();\n    // set up writer\n    IndexWriter writer = new IndexWriter(\n                                         d,\n                                         newIndexWriterConfig(new MockAnalyzer(random()))\n                                         .setMergePolicy(newLogMergePolicy())\n                                         );\n    // want to get some more segments here\n    // new termvector fields\n    int mergeFactor = ((LogMergePolicy) writer.getConfig().getMergePolicy()).getMergeFactor();\n    FieldType customType5 = new FieldType(TextField.TYPE_STORED);\n    customType5.setStoreTermVectors(true);\n    FieldType customType6 = new FieldType(TextField.TYPE_STORED);\n    customType6.setStoreTermVectors(true);\n    customType6.setStoreTermVectorOffsets(true);\n    FieldType customType7 = new FieldType(TextField.TYPE_STORED);\n    customType7.setStoreTermVectors(true);\n    customType7.setStoreTermVectorPositions(true);\n    FieldType customType8 = new FieldType(TextField.TYPE_STORED);\n    customType8.setStoreTermVectors(true);\n    customType8.setStoreTermVectorOffsets(true);\n    customType8.setStoreTermVectorPositions(true);\n    for (int i = 0; i < 5 * mergeFactor; i++) {\n      Document doc = new Document();\n      doc.add(new TextField(\"tvnot\", \"one two two three three three\", Field.Store.YES));\n      doc.add(new Field(\"termvector\", \"one two two three three three\", customType5));\n      doc.add(new Field(\"tvoffset\", \"one two two three three three\", customType6));\n      doc.add(new Field(\"tvposition\", \"one two two three three three\", customType7));\n      doc.add(new Field(\"tvpositionoffset\", \"one two two three three three\", customType8));\n      \n      writer.addDocument(doc);\n    }\n    writer.close();\n    d.close();\n  }\n\n","sourceOld":"public void testTermVectors() throws Exception {\n  Directory d = newDirectory();\n  // set up writer\n  IndexWriter writer = new IndexWriter(\n      d,\n      newIndexWriterConfig(new MockAnalyzer(random()))\n          .setMergePolicy(newLogMergePolicy())\n  );\n  // want to get some more segments here\n  // new termvector fields\n  int mergeFactor = ((LogMergePolicy) writer.getConfig().getMergePolicy()).getMergeFactor();\n  FieldType customType5 = new FieldType(TextField.TYPE_STORED);\n  customType5.setStoreTermVectors(true);\n  FieldType customType6 = new FieldType(TextField.TYPE_STORED);\n  customType6.setStoreTermVectors(true);\n  customType6.setStoreTermVectorOffsets(true);\n  FieldType customType7 = new FieldType(TextField.TYPE_STORED);\n  customType7.setStoreTermVectors(true);\n  customType7.setStoreTermVectorPositions(true);\n  FieldType customType8 = new FieldType(TextField.TYPE_STORED);\n  customType8.setStoreTermVectors(true);\n  customType8.setStoreTermVectorOffsets(true);\n  customType8.setStoreTermVectorPositions(true);\n  for (int i = 0; i < 5 * mergeFactor; i++) {\n    Document doc = new Document();\n      doc.add(new TextField(\"tvnot\", \"one two two three three three\", Field.Store.YES));\n      doc.add(new Field(\"termvector\", \"one two two three three three\", customType5));\n      doc.add(new Field(\"tvoffset\", \"one two two three three three\", customType6));\n      doc.add(new Field(\"tvposition\", \"one two two three three three\", customType7));\n      doc.add(new Field(\"tvpositionoffset\", \"one two two three three three\", customType8));\n      \n      writer.addDocument(doc);\n  }\n  writer.close();\n  d.close();\n}\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"04f07771a2a7dd3a395700665ed839c3dae2def2":["629c38c4ae4e303d0617e05fbfe508140b32f0a3"],"34d6426cef006e0c3625cabe7a7ec1c2b08bc501":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e":["ae14298f4eec6d5faee6a149f88ba57d14a6f21a"],"83e99d44c4a660a48c0fcc7a0108ad0a56dc2f87":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"5a207d19eac354d649c3f0e2cce070017c78125e":["d0ef034a4f10871667ae75181537775ddcf8ade4","b470f36a9372c97283360b1304eacbde22df6c0d"],"b470f36a9372c97283360b1304eacbde22df6c0d":["d0ef034a4f10871667ae75181537775ddcf8ade4","34d6426cef006e0c3625cabe7a7ec1c2b08bc501"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"1e6acbaae7af722f17204ceccf0f7db5753eccf3":["d0ef034a4f10871667ae75181537775ddcf8ade4","b470f36a9372c97283360b1304eacbde22df6c0d"],"d0ef034a4f10871667ae75181537775ddcf8ade4":["54a6bea0b991120a99ad0e2f72ae853fd5ecae0e"],"ae14298f4eec6d5faee6a149f88ba57d14a6f21a":["04f07771a2a7dd3a395700665ed839c3dae2def2"],"629c38c4ae4e303d0617e05fbfe508140b32f0a3":["83e99d44c4a660a48c0fcc7a0108ad0a56dc2f87"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["5a207d19eac354d649c3f0e2cce070017c78125e"]},"commit2Childs":{"04f07771a2a7dd3a395700665ed839c3dae2def2":["ae14298f4eec6d5faee6a149f88ba57d14a6f21a"],"34d6426cef006e0c3625cabe7a7ec1c2b08bc501":["b470f36a9372c97283360b1304eacbde22df6c0d"],"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"83e99d44c4a660a48c0fcc7a0108ad0a56dc2f87":["629c38c4ae4e303d0617e05fbfe508140b32f0a3"],"5a207d19eac354d649c3f0e2cce070017c78125e":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"b470f36a9372c97283360b1304eacbde22df6c0d":["5a207d19eac354d649c3f0e2cce070017c78125e","1e6acbaae7af722f17204ceccf0f7db5753eccf3"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["83e99d44c4a660a48c0fcc7a0108ad0a56dc2f87"],"1e6acbaae7af722f17204ceccf0f7db5753eccf3":[],"d0ef034a4f10871667ae75181537775ddcf8ade4":["34d6426cef006e0c3625cabe7a7ec1c2b08bc501","5a207d19eac354d649c3f0e2cce070017c78125e","b470f36a9372c97283360b1304eacbde22df6c0d","1e6acbaae7af722f17204ceccf0f7db5753eccf3"],"ae14298f4eec6d5faee6a149f88ba57d14a6f21a":["54a6bea0b991120a99ad0e2f72ae853fd5ecae0e"],"629c38c4ae4e303d0617e05fbfe508140b32f0a3":["04f07771a2a7dd3a395700665ed839c3dae2def2"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["1e6acbaae7af722f17204ceccf0f7db5753eccf3","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}