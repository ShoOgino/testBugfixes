{"path":"solr/solrj/src/test/org/apache/solr/common/util/TestJavaBinCodec#doDecodePerf(String[]).mjava","commits":[{"id":"2d29e71be37a0f12cb2e7a55eac52341af2e5f18","date":1428955161,"type":0,"author":"Yonik Seeley","isMerge":false,"pathNew":"solr/solrj/src/test/org/apache/solr/common/util/TestJavaBinCodec#doDecodePerf(String[]).mjava","pathOld":"/dev/null","sourceNew":"  public static void doDecodePerf(String[] args) throws Exception {\n    int arg=0;\n    int nThreads = Integer.parseInt(args[arg++]);\n    int nBuffers = Integer.parseInt(args[arg++]);\n    long iter = Long.parseLong(args[arg++]);\n    int cacheSz = Integer.parseInt(args[arg++]);\n\n    Random r = new Random(0);\n\n    byte[][] buffers = new byte[nBuffers][];\n\n    for (int bufnum=0; bufnum<nBuffers; bufnum++) {\n      SolrDocument sdoc = new SolrDocument();\n      sdoc.put(\"id\", \"my_id_\" + bufnum);\n      sdoc.put(\"author\", str(r, 10 + r.nextInt(10)));\n      sdoc.put(\"address\", str(r, 20 + r.nextInt(20)));\n      sdoc.put(\"license\", str(r, 10));\n      sdoc.put(\"title\", str(r, 5 + r.nextInt(10)));\n      sdoc.put(\"modified_dt\", r.nextInt(1000000));\n      sdoc.put(\"creation_dt\", r.nextInt(1000000));\n      sdoc.put(\"birthdate_dt\", r.nextInt(1000000));\n      sdoc.put(\"clean\", r.nextBoolean());\n      sdoc.put(\"dirty\", r.nextBoolean());\n      sdoc.put(\"employed\", r.nextBoolean());\n      sdoc.put(\"priority\", r.nextInt(100));\n      sdoc.put(\"dependents\", r.nextInt(6));\n      sdoc.put(\"level\", r.nextInt(101));\n      sdoc.put(\"education_level\", r.nextInt(10));\n      // higher level of reuse for string values\n      sdoc.put(\"state\", \"S\"+r.nextInt(50));\n      sdoc.put(\"country\", \"Country\"+r.nextInt(20));\n      sdoc.put(\"some_boolean\", \"\"+r.nextBoolean());\n      sdoc.put(\"another_boolean\", \"\"+r.nextBoolean());\n\n\n      JavaBinCodec javabin = new JavaBinCodec();\n      ByteArrayOutputStream os = new ByteArrayOutputStream();\n      javabin.marshal(sdoc, os);\n      os.toByteArray();\n      buffers[bufnum] = os.toByteArray();\n    }\n\n    int ret = 0;\n    long start = System.currentTimeMillis();\n    ConcurrentLRUCache underlyingCache = cacheSz > 0 ? new ConcurrentLRUCache<>(cacheSz,cacheSz-cacheSz/10,cacheSz,cacheSz/10,false,true,null) : null;  // the cache in the first version of the patch was 10000,9000,10000,1000,false,true,null\n    JavaBinCodec.StringCache stringCache = underlyingCache==null ? null : new JavaBinCodec.StringCache(underlyingCache);\n    if (nThreads <= 0) {\n      ret += doDecode(buffers, iter, stringCache);\n    } else {\n      runInThreads(nThreads, new Runnable() {\n        @Override\n        public void run() {\n          try {\n            doDecode(buffers, iter, stringCache);\n          } catch (IOException e) {\n            e.printStackTrace();\n          }\n        }\n      });\n    }\n    long end = System.currentTimeMillis();\n\n    long n = iter * Math.max(1,nThreads);\n    System.out.println(\"ret=\" + ret + \" THROUGHPUT=\" + (n*1000 / (end-start)));\n    if (underlyingCache != null) System.out.println(\"cache: hits=\" + underlyingCache.getStats().getCumulativeHits() + \" lookups=\" + underlyingCache.getStats().getCumulativeLookups() + \" size=\" + underlyingCache.getStats().getCurrentSize());\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"93c4a0fd70c7b102c0dcc58e54802670eb4ee728","date":1428956153,"type":3,"author":"Yonik Seeley","isMerge":false,"pathNew":"solr/solrj/src/test/org/apache/solr/common/util/TestJavaBinCodec#doDecodePerf(String[]).mjava","pathOld":"solr/solrj/src/test/org/apache/solr/common/util/TestJavaBinCodec#doDecodePerf(String[]).mjava","sourceNew":"  public static void doDecodePerf(String[] args) throws Exception {\n    int arg=0;\n    int nThreads = Integer.parseInt(args[arg++]);\n    int nBuffers = Integer.parseInt(args[arg++]);\n    final long iter = Long.parseLong(args[arg++]);\n    int cacheSz = Integer.parseInt(args[arg++]);\n\n    Random r = new Random(0);\n\n    final byte[][] buffers = new byte[nBuffers][];\n\n    for (int bufnum=0; bufnum<nBuffers; bufnum++) {\n      SolrDocument sdoc = new SolrDocument();\n      sdoc.put(\"id\", \"my_id_\" + bufnum);\n      sdoc.put(\"author\", str(r, 10 + r.nextInt(10)));\n      sdoc.put(\"address\", str(r, 20 + r.nextInt(20)));\n      sdoc.put(\"license\", str(r, 10));\n      sdoc.put(\"title\", str(r, 5 + r.nextInt(10)));\n      sdoc.put(\"modified_dt\", r.nextInt(1000000));\n      sdoc.put(\"creation_dt\", r.nextInt(1000000));\n      sdoc.put(\"birthdate_dt\", r.nextInt(1000000));\n      sdoc.put(\"clean\", r.nextBoolean());\n      sdoc.put(\"dirty\", r.nextBoolean());\n      sdoc.put(\"employed\", r.nextBoolean());\n      sdoc.put(\"priority\", r.nextInt(100));\n      sdoc.put(\"dependents\", r.nextInt(6));\n      sdoc.put(\"level\", r.nextInt(101));\n      sdoc.put(\"education_level\", r.nextInt(10));\n      // higher level of reuse for string values\n      sdoc.put(\"state\", \"S\"+r.nextInt(50));\n      sdoc.put(\"country\", \"Country\"+r.nextInt(20));\n      sdoc.put(\"some_boolean\", \"\"+r.nextBoolean());\n      sdoc.put(\"another_boolean\", \"\"+r.nextBoolean());\n\n\n      JavaBinCodec javabin = new JavaBinCodec();\n      ByteArrayOutputStream os = new ByteArrayOutputStream();\n      javabin.marshal(sdoc, os);\n      os.toByteArray();\n      buffers[bufnum] = os.toByteArray();\n    }\n\n    int ret = 0;\n    long start = System.currentTimeMillis();\n    ConcurrentLRUCache underlyingCache = cacheSz > 0 ? new ConcurrentLRUCache<>(cacheSz,cacheSz-cacheSz/10,cacheSz,cacheSz/10,false,true,null) : null;  // the cache in the first version of the patch was 10000,9000,10000,1000,false,true,null\n    final JavaBinCodec.StringCache stringCache = underlyingCache==null ? null : new JavaBinCodec.StringCache(underlyingCache);\n    if (nThreads <= 0) {\n      ret += doDecode(buffers, iter, stringCache);\n    } else {\n      runInThreads(nThreads, new Runnable() {\n        @Override\n        public void run() {\n          try {\n            doDecode(buffers, iter, stringCache);\n          } catch (IOException e) {\n            e.printStackTrace();\n          }\n        }\n      });\n    }\n    long end = System.currentTimeMillis();\n\n    long n = iter * Math.max(1,nThreads);\n    System.out.println(\"ret=\" + ret + \" THROUGHPUT=\" + (n*1000 / (end-start)));\n    if (underlyingCache != null) System.out.println(\"cache: hits=\" + underlyingCache.getStats().getCumulativeHits() + \" lookups=\" + underlyingCache.getStats().getCumulativeLookups() + \" size=\" + underlyingCache.getStats().getCurrentSize());\n  }\n\n","sourceOld":"  public static void doDecodePerf(String[] args) throws Exception {\n    int arg=0;\n    int nThreads = Integer.parseInt(args[arg++]);\n    int nBuffers = Integer.parseInt(args[arg++]);\n    long iter = Long.parseLong(args[arg++]);\n    int cacheSz = Integer.parseInt(args[arg++]);\n\n    Random r = new Random(0);\n\n    byte[][] buffers = new byte[nBuffers][];\n\n    for (int bufnum=0; bufnum<nBuffers; bufnum++) {\n      SolrDocument sdoc = new SolrDocument();\n      sdoc.put(\"id\", \"my_id_\" + bufnum);\n      sdoc.put(\"author\", str(r, 10 + r.nextInt(10)));\n      sdoc.put(\"address\", str(r, 20 + r.nextInt(20)));\n      sdoc.put(\"license\", str(r, 10));\n      sdoc.put(\"title\", str(r, 5 + r.nextInt(10)));\n      sdoc.put(\"modified_dt\", r.nextInt(1000000));\n      sdoc.put(\"creation_dt\", r.nextInt(1000000));\n      sdoc.put(\"birthdate_dt\", r.nextInt(1000000));\n      sdoc.put(\"clean\", r.nextBoolean());\n      sdoc.put(\"dirty\", r.nextBoolean());\n      sdoc.put(\"employed\", r.nextBoolean());\n      sdoc.put(\"priority\", r.nextInt(100));\n      sdoc.put(\"dependents\", r.nextInt(6));\n      sdoc.put(\"level\", r.nextInt(101));\n      sdoc.put(\"education_level\", r.nextInt(10));\n      // higher level of reuse for string values\n      sdoc.put(\"state\", \"S\"+r.nextInt(50));\n      sdoc.put(\"country\", \"Country\"+r.nextInt(20));\n      sdoc.put(\"some_boolean\", \"\"+r.nextBoolean());\n      sdoc.put(\"another_boolean\", \"\"+r.nextBoolean());\n\n\n      JavaBinCodec javabin = new JavaBinCodec();\n      ByteArrayOutputStream os = new ByteArrayOutputStream();\n      javabin.marshal(sdoc, os);\n      os.toByteArray();\n      buffers[bufnum] = os.toByteArray();\n    }\n\n    int ret = 0;\n    long start = System.currentTimeMillis();\n    ConcurrentLRUCache underlyingCache = cacheSz > 0 ? new ConcurrentLRUCache<>(cacheSz,cacheSz-cacheSz/10,cacheSz,cacheSz/10,false,true,null) : null;  // the cache in the first version of the patch was 10000,9000,10000,1000,false,true,null\n    JavaBinCodec.StringCache stringCache = underlyingCache==null ? null : new JavaBinCodec.StringCache(underlyingCache);\n    if (nThreads <= 0) {\n      ret += doDecode(buffers, iter, stringCache);\n    } else {\n      runInThreads(nThreads, new Runnable() {\n        @Override\n        public void run() {\n          try {\n            doDecode(buffers, iter, stringCache);\n          } catch (IOException e) {\n            e.printStackTrace();\n          }\n        }\n      });\n    }\n    long end = System.currentTimeMillis();\n\n    long n = iter * Math.max(1,nThreads);\n    System.out.println(\"ret=\" + ret + \" THROUGHPUT=\" + (n*1000 / (end-start)));\n    if (underlyingCache != null) System.out.println(\"cache: hits=\" + underlyingCache.getStats().getCumulativeHits() + \" lookups=\" + underlyingCache.getStats().getCumulativeLookups() + \" size=\" + underlyingCache.getStats().getCurrentSize());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"bcf9886c8ff537aafde14de48ebf744f5673f08b","date":1439041198,"type":3,"author":"Ramkumar Aiyengar","isMerge":false,"pathNew":"solr/solrj/src/test/org/apache/solr/common/util/TestJavaBinCodec#doDecodePerf(String[]).mjava","pathOld":"solr/solrj/src/test/org/apache/solr/common/util/TestJavaBinCodec#doDecodePerf(String[]).mjava","sourceNew":"  public static void doDecodePerf(String[] args) throws Exception {\n    int arg=0;\n    int nThreads = Integer.parseInt(args[arg++]);\n    int nBuffers = Integer.parseInt(args[arg++]);\n    final long iter = Long.parseLong(args[arg++]);\n    int cacheSz = Integer.parseInt(args[arg++]);\n\n    Random r = new Random(0);\n\n    final byte[][] buffers = new byte[nBuffers][];\n\n    for (int bufnum=0; bufnum<nBuffers; bufnum++) {\n      SolrDocument sdoc = new SolrDocument();\n      sdoc.put(\"id\", \"my_id_\" + bufnum);\n      sdoc.put(\"author\", str(r, 10 + r.nextInt(10)));\n      sdoc.put(\"address\", str(r, 20 + r.nextInt(20)));\n      sdoc.put(\"license\", str(r, 10));\n      sdoc.put(\"title\", str(r, 5 + r.nextInt(10)));\n      sdoc.put(\"modified_dt\", r.nextInt(1000000));\n      sdoc.put(\"creation_dt\", r.nextInt(1000000));\n      sdoc.put(\"birthdate_dt\", r.nextInt(1000000));\n      sdoc.put(\"clean\", r.nextBoolean());\n      sdoc.put(\"dirty\", r.nextBoolean());\n      sdoc.put(\"employed\", r.nextBoolean());\n      sdoc.put(\"priority\", r.nextInt(100));\n      sdoc.put(\"dependents\", r.nextInt(6));\n      sdoc.put(\"level\", r.nextInt(101));\n      sdoc.put(\"education_level\", r.nextInt(10));\n      // higher level of reuse for string values\n      sdoc.put(\"state\", \"S\"+r.nextInt(50));\n      sdoc.put(\"country\", \"Country\"+r.nextInt(20));\n      sdoc.put(\"some_boolean\", \"\"+r.nextBoolean());\n      sdoc.put(\"another_boolean\", \"\"+r.nextBoolean());\n\n\n      JavaBinCodec javabin = new JavaBinCodec();\n      ByteArrayOutputStream os = new ByteArrayOutputStream();\n      javabin.marshal(sdoc, os);\n      os.toByteArray();\n      buffers[bufnum] = os.toByteArray();\n    }\n\n    int ret = 0;\n    final RTimer timer = new RTimer();\n    ConcurrentLRUCache underlyingCache = cacheSz > 0 ? new ConcurrentLRUCache<>(cacheSz,cacheSz-cacheSz/10,cacheSz,cacheSz/10,false,true,null) : null;  // the cache in the first version of the patch was 10000,9000,10000,1000,false,true,null\n    final JavaBinCodec.StringCache stringCache = underlyingCache==null ? null : new JavaBinCodec.StringCache(underlyingCache);\n    if (nThreads <= 0) {\n      ret += doDecode(buffers, iter, stringCache);\n    } else {\n      runInThreads(nThreads, new Runnable() {\n        @Override\n        public void run() {\n          try {\n            doDecode(buffers, iter, stringCache);\n          } catch (IOException e) {\n            e.printStackTrace();\n          }\n        }\n      });\n    }\n\n    long n = iter * Math.max(1,nThreads);\n    System.out.println(\"ret=\" + ret + \" THROUGHPUT=\" + (n*1000 / timer.getTime()));\n    if (underlyingCache != null) System.out.println(\"cache: hits=\" + underlyingCache.getStats().getCumulativeHits() + \" lookups=\" + underlyingCache.getStats().getCumulativeLookups() + \" size=\" + underlyingCache.getStats().getCurrentSize());\n  }\n\n","sourceOld":"  public static void doDecodePerf(String[] args) throws Exception {\n    int arg=0;\n    int nThreads = Integer.parseInt(args[arg++]);\n    int nBuffers = Integer.parseInt(args[arg++]);\n    final long iter = Long.parseLong(args[arg++]);\n    int cacheSz = Integer.parseInt(args[arg++]);\n\n    Random r = new Random(0);\n\n    final byte[][] buffers = new byte[nBuffers][];\n\n    for (int bufnum=0; bufnum<nBuffers; bufnum++) {\n      SolrDocument sdoc = new SolrDocument();\n      sdoc.put(\"id\", \"my_id_\" + bufnum);\n      sdoc.put(\"author\", str(r, 10 + r.nextInt(10)));\n      sdoc.put(\"address\", str(r, 20 + r.nextInt(20)));\n      sdoc.put(\"license\", str(r, 10));\n      sdoc.put(\"title\", str(r, 5 + r.nextInt(10)));\n      sdoc.put(\"modified_dt\", r.nextInt(1000000));\n      sdoc.put(\"creation_dt\", r.nextInt(1000000));\n      sdoc.put(\"birthdate_dt\", r.nextInt(1000000));\n      sdoc.put(\"clean\", r.nextBoolean());\n      sdoc.put(\"dirty\", r.nextBoolean());\n      sdoc.put(\"employed\", r.nextBoolean());\n      sdoc.put(\"priority\", r.nextInt(100));\n      sdoc.put(\"dependents\", r.nextInt(6));\n      sdoc.put(\"level\", r.nextInt(101));\n      sdoc.put(\"education_level\", r.nextInt(10));\n      // higher level of reuse for string values\n      sdoc.put(\"state\", \"S\"+r.nextInt(50));\n      sdoc.put(\"country\", \"Country\"+r.nextInt(20));\n      sdoc.put(\"some_boolean\", \"\"+r.nextBoolean());\n      sdoc.put(\"another_boolean\", \"\"+r.nextBoolean());\n\n\n      JavaBinCodec javabin = new JavaBinCodec();\n      ByteArrayOutputStream os = new ByteArrayOutputStream();\n      javabin.marshal(sdoc, os);\n      os.toByteArray();\n      buffers[bufnum] = os.toByteArray();\n    }\n\n    int ret = 0;\n    long start = System.currentTimeMillis();\n    ConcurrentLRUCache underlyingCache = cacheSz > 0 ? new ConcurrentLRUCache<>(cacheSz,cacheSz-cacheSz/10,cacheSz,cacheSz/10,false,true,null) : null;  // the cache in the first version of the patch was 10000,9000,10000,1000,false,true,null\n    final JavaBinCodec.StringCache stringCache = underlyingCache==null ? null : new JavaBinCodec.StringCache(underlyingCache);\n    if (nThreads <= 0) {\n      ret += doDecode(buffers, iter, stringCache);\n    } else {\n      runInThreads(nThreads, new Runnable() {\n        @Override\n        public void run() {\n          try {\n            doDecode(buffers, iter, stringCache);\n          } catch (IOException e) {\n            e.printStackTrace();\n          }\n        }\n      });\n    }\n    long end = System.currentTimeMillis();\n\n    long n = iter * Math.max(1,nThreads);\n    System.out.println(\"ret=\" + ret + \" THROUGHPUT=\" + (n*1000 / (end-start)));\n    if (underlyingCache != null) System.out.println(\"cache: hits=\" + underlyingCache.getStats().getCumulativeHits() + \" lookups=\" + underlyingCache.getStats().getCumulativeLookups() + \" size=\" + underlyingCache.getStats().getCurrentSize());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3a0c04b71951333291abc7f317109a6a5957bd28","date":1457097827,"type":3,"author":"Noble Paul","isMerge":false,"pathNew":"solr/solrj/src/test/org/apache/solr/common/util/TestJavaBinCodec#doDecodePerf(String[]).mjava","pathOld":"solr/solrj/src/test/org/apache/solr/common/util/TestJavaBinCodec#doDecodePerf(String[]).mjava","sourceNew":"  public static void doDecodePerf(String[] args) throws Exception {\n    int arg=0;\n    int nThreads = Integer.parseInt(args[arg++]);\n    int nBuffers = Integer.parseInt(args[arg++]);\n    final long iter = Long.parseLong(args[arg++]);\n    int cacheSz = Integer.parseInt(args[arg++]);\n\n    Random r = new Random(0);\n\n    final byte[][] buffers = new byte[nBuffers][];\n\n    for (int bufnum=0; bufnum<nBuffers; bufnum++) {\n      SolrDocument sdoc = new SolrDocument();\n      sdoc.put(\"id\", \"my_id_\" + bufnum);\n      sdoc.put(\"author\", str(r, 10 + r.nextInt(10)));\n      sdoc.put(\"address\", str(r, 20 + r.nextInt(20)));\n      sdoc.put(\"license\", str(r, 10));\n      sdoc.put(\"title\", str(r, 5 + r.nextInt(10)));\n      sdoc.put(\"modified_dt\", r.nextInt(1000000));\n      sdoc.put(\"creation_dt\", r.nextInt(1000000));\n      sdoc.put(\"birthdate_dt\", r.nextInt(1000000));\n      sdoc.put(\"clean\", r.nextBoolean());\n      sdoc.put(\"dirty\", r.nextBoolean());\n      sdoc.put(\"employed\", r.nextBoolean());\n      sdoc.put(\"priority\", r.nextInt(100));\n      sdoc.put(\"dependents\", r.nextInt(6));\n      sdoc.put(\"level\", r.nextInt(101));\n      sdoc.put(\"education_level\", r.nextInt(10));\n      // higher level of reuse for string values\n      sdoc.put(\"state\", \"S\"+r.nextInt(50));\n      sdoc.put(\"country\", \"Country\"+r.nextInt(20));\n      sdoc.put(\"some_boolean\", \"\"+r.nextBoolean());\n      sdoc.put(\"another_boolean\", \"\"+r.nextBoolean());\n\n\n      JavaBinCodec javabin = new JavaBinCodec();\n      ByteArrayOutputStream os = new ByteArrayOutputStream();\n      javabin.marshal(sdoc, os);\n      os.toByteArray();\n      buffers[bufnum] = os.toByteArray();\n    }\n\n    int ret = 0;\n    final RTimer timer = new RTimer();\n    ConcurrentLRUCache underlyingCache = cacheSz > 0 ? new ConcurrentLRUCache<>(cacheSz,cacheSz-cacheSz/10,cacheSz,cacheSz/10,false,true,null) : null;  // the cache in the first version of the patch was 10000,9000,10000,1000,false,true,null\n    final JavaBinCodec.StringCache stringCache = underlyingCache==null ? null : new JavaBinCodec.StringCache(underlyingCache);\n    if (nThreads <= 0) {\n      ret += doDecode(buffers, iter, stringCache);\n    } else {\n      runInThreads(nThreads, () -> {\n        try {\n          doDecode(buffers, iter, stringCache);\n        } catch (IOException e) {\n          e.printStackTrace();\n        }\n      });\n    }\n\n    long n = iter * Math.max(1,nThreads);\n    System.out.println(\"ret=\" + ret + \" THROUGHPUT=\" + (n*1000 / timer.getTime()));\n    if (underlyingCache != null) System.out.println(\"cache: hits=\" + underlyingCache.getStats().getCumulativeHits() + \" lookups=\" + underlyingCache.getStats().getCumulativeLookups() + \" size=\" + underlyingCache.getStats().getCurrentSize());\n  }\n\n","sourceOld":"  public static void doDecodePerf(String[] args) throws Exception {\n    int arg=0;\n    int nThreads = Integer.parseInt(args[arg++]);\n    int nBuffers = Integer.parseInt(args[arg++]);\n    final long iter = Long.parseLong(args[arg++]);\n    int cacheSz = Integer.parseInt(args[arg++]);\n\n    Random r = new Random(0);\n\n    final byte[][] buffers = new byte[nBuffers][];\n\n    for (int bufnum=0; bufnum<nBuffers; bufnum++) {\n      SolrDocument sdoc = new SolrDocument();\n      sdoc.put(\"id\", \"my_id_\" + bufnum);\n      sdoc.put(\"author\", str(r, 10 + r.nextInt(10)));\n      sdoc.put(\"address\", str(r, 20 + r.nextInt(20)));\n      sdoc.put(\"license\", str(r, 10));\n      sdoc.put(\"title\", str(r, 5 + r.nextInt(10)));\n      sdoc.put(\"modified_dt\", r.nextInt(1000000));\n      sdoc.put(\"creation_dt\", r.nextInt(1000000));\n      sdoc.put(\"birthdate_dt\", r.nextInt(1000000));\n      sdoc.put(\"clean\", r.nextBoolean());\n      sdoc.put(\"dirty\", r.nextBoolean());\n      sdoc.put(\"employed\", r.nextBoolean());\n      sdoc.put(\"priority\", r.nextInt(100));\n      sdoc.put(\"dependents\", r.nextInt(6));\n      sdoc.put(\"level\", r.nextInt(101));\n      sdoc.put(\"education_level\", r.nextInt(10));\n      // higher level of reuse for string values\n      sdoc.put(\"state\", \"S\"+r.nextInt(50));\n      sdoc.put(\"country\", \"Country\"+r.nextInt(20));\n      sdoc.put(\"some_boolean\", \"\"+r.nextBoolean());\n      sdoc.put(\"another_boolean\", \"\"+r.nextBoolean());\n\n\n      JavaBinCodec javabin = new JavaBinCodec();\n      ByteArrayOutputStream os = new ByteArrayOutputStream();\n      javabin.marshal(sdoc, os);\n      os.toByteArray();\n      buffers[bufnum] = os.toByteArray();\n    }\n\n    int ret = 0;\n    final RTimer timer = new RTimer();\n    ConcurrentLRUCache underlyingCache = cacheSz > 0 ? new ConcurrentLRUCache<>(cacheSz,cacheSz-cacheSz/10,cacheSz,cacheSz/10,false,true,null) : null;  // the cache in the first version of the patch was 10000,9000,10000,1000,false,true,null\n    final JavaBinCodec.StringCache stringCache = underlyingCache==null ? null : new JavaBinCodec.StringCache(underlyingCache);\n    if (nThreads <= 0) {\n      ret += doDecode(buffers, iter, stringCache);\n    } else {\n      runInThreads(nThreads, new Runnable() {\n        @Override\n        public void run() {\n          try {\n            doDecode(buffers, iter, stringCache);\n          } catch (IOException e) {\n            e.printStackTrace();\n          }\n        }\n      });\n    }\n\n    long n = iter * Math.max(1,nThreads);\n    System.out.println(\"ret=\" + ret + \" THROUGHPUT=\" + (n*1000 / timer.getTime()));\n    if (underlyingCache != null) System.out.println(\"cache: hits=\" + underlyingCache.getStats().getCumulativeHits() + \" lookups=\" + underlyingCache.getStats().getCumulativeLookups() + \" size=\" + underlyingCache.getStats().getCurrentSize());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"04aef18a25f8e0d1832199f0cc7607773de5a229","date":1473142144,"type":3,"author":"Noble Paul","isMerge":false,"pathNew":"solr/solrj/src/test/org/apache/solr/common/util/TestJavaBinCodec#doDecodePerf(String[]).mjava","pathOld":"solr/solrj/src/test/org/apache/solr/common/util/TestJavaBinCodec#doDecodePerf(String[]).mjava","sourceNew":"  public static void doDecodePerf(String[] args) throws Exception {\n    int arg=0;\n    int nThreads = Integer.parseInt(args[arg++]);\n    int nBuffers = Integer.parseInt(args[arg++]);\n    final long iter = Long.parseLong(args[arg++]);\n    int cacheSz = Integer.parseInt(args[arg++]);\n\n    Random r = new Random(0);\n\n    final byte[][] buffers = new byte[nBuffers][];\n\n    for (int bufnum=0; bufnum<nBuffers; bufnum++) {\n      SolrDocument sdoc = new SolrDocument();\n      sdoc.put(\"id\", \"my_id_\" + bufnum);\n      sdoc.put(\"author\", str(r, 10 + r.nextInt(10)));\n      sdoc.put(\"address\", str(r, 20 + r.nextInt(20)));\n      sdoc.put(\"license\", str(r, 10));\n      sdoc.put(\"title\", str(r, 5 + r.nextInt(10)));\n      sdoc.put(\"modified_dt\", r.nextInt(1000000));\n      sdoc.put(\"creation_dt\", r.nextInt(1000000));\n      sdoc.put(\"birthdate_dt\", r.nextInt(1000000));\n      sdoc.put(\"clean\", r.nextBoolean());\n      sdoc.put(\"dirty\", r.nextBoolean());\n      sdoc.put(\"employed\", r.nextBoolean());\n      sdoc.put(\"priority\", r.nextInt(100));\n      sdoc.put(\"dependents\", r.nextInt(6));\n      sdoc.put(\"level\", r.nextInt(101));\n      sdoc.put(\"education_level\", r.nextInt(10));\n      // higher level of reuse for string values\n      sdoc.put(\"state\", \"S\"+r.nextInt(50));\n      sdoc.put(\"country\", \"Country\"+r.nextInt(20));\n      sdoc.put(\"some_boolean\", \"\"+r.nextBoolean());\n      sdoc.put(\"another_boolean\", \"\"+r.nextBoolean());\n\n      buffers[bufnum] = getBytes(sdoc);\n    }\n\n    int ret = 0;\n    final RTimer timer = new RTimer();\n    ConcurrentLRUCache underlyingCache = cacheSz > 0 ? new ConcurrentLRUCache<>(cacheSz,cacheSz-cacheSz/10,cacheSz,cacheSz/10,false,true,null) : null;  // the cache in the first version of the patch was 10000,9000,10000,1000,false,true,null\n    final JavaBinCodec.StringCache stringCache = underlyingCache==null ? null : new JavaBinCodec.StringCache(underlyingCache);\n    if (nThreads <= 0) {\n      ret += doDecode(buffers, iter, stringCache);\n    } else {\n      runInThreads(nThreads, () -> {\n        try {\n          doDecode(buffers, iter, stringCache);\n        } catch (IOException e) {\n          e.printStackTrace();\n        }\n      });\n    }\n\n    long n = iter * Math.max(1,nThreads);\n    System.out.println(\"ret=\" + ret + \" THROUGHPUT=\" + (n*1000 / timer.getTime()));\n    if (underlyingCache != null) System.out.println(\"cache: hits=\" + underlyingCache.getStats().getCumulativeHits() + \" lookups=\" + underlyingCache.getStats().getCumulativeLookups() + \" size=\" + underlyingCache.getStats().getCurrentSize());\n  }\n\n","sourceOld":"  public static void doDecodePerf(String[] args) throws Exception {\n    int arg=0;\n    int nThreads = Integer.parseInt(args[arg++]);\n    int nBuffers = Integer.parseInt(args[arg++]);\n    final long iter = Long.parseLong(args[arg++]);\n    int cacheSz = Integer.parseInt(args[arg++]);\n\n    Random r = new Random(0);\n\n    final byte[][] buffers = new byte[nBuffers][];\n\n    for (int bufnum=0; bufnum<nBuffers; bufnum++) {\n      SolrDocument sdoc = new SolrDocument();\n      sdoc.put(\"id\", \"my_id_\" + bufnum);\n      sdoc.put(\"author\", str(r, 10 + r.nextInt(10)));\n      sdoc.put(\"address\", str(r, 20 + r.nextInt(20)));\n      sdoc.put(\"license\", str(r, 10));\n      sdoc.put(\"title\", str(r, 5 + r.nextInt(10)));\n      sdoc.put(\"modified_dt\", r.nextInt(1000000));\n      sdoc.put(\"creation_dt\", r.nextInt(1000000));\n      sdoc.put(\"birthdate_dt\", r.nextInt(1000000));\n      sdoc.put(\"clean\", r.nextBoolean());\n      sdoc.put(\"dirty\", r.nextBoolean());\n      sdoc.put(\"employed\", r.nextBoolean());\n      sdoc.put(\"priority\", r.nextInt(100));\n      sdoc.put(\"dependents\", r.nextInt(6));\n      sdoc.put(\"level\", r.nextInt(101));\n      sdoc.put(\"education_level\", r.nextInt(10));\n      // higher level of reuse for string values\n      sdoc.put(\"state\", \"S\"+r.nextInt(50));\n      sdoc.put(\"country\", \"Country\"+r.nextInt(20));\n      sdoc.put(\"some_boolean\", \"\"+r.nextBoolean());\n      sdoc.put(\"another_boolean\", \"\"+r.nextBoolean());\n\n\n      JavaBinCodec javabin = new JavaBinCodec();\n      ByteArrayOutputStream os = new ByteArrayOutputStream();\n      javabin.marshal(sdoc, os);\n      os.toByteArray();\n      buffers[bufnum] = os.toByteArray();\n    }\n\n    int ret = 0;\n    final RTimer timer = new RTimer();\n    ConcurrentLRUCache underlyingCache = cacheSz > 0 ? new ConcurrentLRUCache<>(cacheSz,cacheSz-cacheSz/10,cacheSz,cacheSz/10,false,true,null) : null;  // the cache in the first version of the patch was 10000,9000,10000,1000,false,true,null\n    final JavaBinCodec.StringCache stringCache = underlyingCache==null ? null : new JavaBinCodec.StringCache(underlyingCache);\n    if (nThreads <= 0) {\n      ret += doDecode(buffers, iter, stringCache);\n    } else {\n      runInThreads(nThreads, () -> {\n        try {\n          doDecode(buffers, iter, stringCache);\n        } catch (IOException e) {\n          e.printStackTrace();\n        }\n      });\n    }\n\n    long n = iter * Math.max(1,nThreads);\n    System.out.println(\"ret=\" + ret + \" THROUGHPUT=\" + (n*1000 / timer.getTime()));\n    if (underlyingCache != null) System.out.println(\"cache: hits=\" + underlyingCache.getStats().getCumulativeHits() + \" lookups=\" + underlyingCache.getStats().getCumulativeLookups() + \" size=\" + underlyingCache.getStats().getCurrentSize());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"89424def13674ea17829b41c5883c54ecc31a132","date":1473767373,"type":3,"author":"Noble Paul","isMerge":true,"pathNew":"solr/solrj/src/test/org/apache/solr/common/util/TestJavaBinCodec#doDecodePerf(String[]).mjava","pathOld":"solr/solrj/src/test/org/apache/solr/common/util/TestJavaBinCodec#doDecodePerf(String[]).mjava","sourceNew":"  public static void doDecodePerf(String[] args) throws Exception {\n    int arg=0;\n    int nThreads = Integer.parseInt(args[arg++]);\n    int nBuffers = Integer.parseInt(args[arg++]);\n    final long iter = Long.parseLong(args[arg++]);\n    int cacheSz = Integer.parseInt(args[arg++]);\n\n    Random r = new Random(0);\n\n    final byte[][] buffers = new byte[nBuffers][];\n\n    for (int bufnum=0; bufnum<nBuffers; bufnum++) {\n      SolrDocument sdoc = new SolrDocument();\n      sdoc.put(\"id\", \"my_id_\" + bufnum);\n      sdoc.put(\"author\", str(r, 10 + r.nextInt(10)));\n      sdoc.put(\"address\", str(r, 20 + r.nextInt(20)));\n      sdoc.put(\"license\", str(r, 10));\n      sdoc.put(\"title\", str(r, 5 + r.nextInt(10)));\n      sdoc.put(\"modified_dt\", r.nextInt(1000000));\n      sdoc.put(\"creation_dt\", r.nextInt(1000000));\n      sdoc.put(\"birthdate_dt\", r.nextInt(1000000));\n      sdoc.put(\"clean\", r.nextBoolean());\n      sdoc.put(\"dirty\", r.nextBoolean());\n      sdoc.put(\"employed\", r.nextBoolean());\n      sdoc.put(\"priority\", r.nextInt(100));\n      sdoc.put(\"dependents\", r.nextInt(6));\n      sdoc.put(\"level\", r.nextInt(101));\n      sdoc.put(\"education_level\", r.nextInt(10));\n      // higher level of reuse for string values\n      sdoc.put(\"state\", \"S\"+r.nextInt(50));\n      sdoc.put(\"country\", \"Country\"+r.nextInt(20));\n      sdoc.put(\"some_boolean\", \"\"+r.nextBoolean());\n      sdoc.put(\"another_boolean\", \"\"+r.nextBoolean());\n\n      buffers[bufnum] = getBytes(sdoc);\n    }\n\n    int ret = 0;\n    final RTimer timer = new RTimer();\n    ConcurrentLRUCache underlyingCache = cacheSz > 0 ? new ConcurrentLRUCache<>(cacheSz,cacheSz-cacheSz/10,cacheSz,cacheSz/10,false,true,null) : null;  // the cache in the first version of the patch was 10000,9000,10000,1000,false,true,null\n    final JavaBinCodec.StringCache stringCache = underlyingCache==null ? null : new JavaBinCodec.StringCache(underlyingCache);\n    if (nThreads <= 0) {\n      ret += doDecode(buffers, iter, stringCache);\n    } else {\n      runInThreads(nThreads, () -> {\n        try {\n          doDecode(buffers, iter, stringCache);\n        } catch (IOException e) {\n          e.printStackTrace();\n        }\n      });\n    }\n\n    long n = iter * Math.max(1,nThreads);\n    System.out.println(\"ret=\" + ret + \" THROUGHPUT=\" + (n*1000 / timer.getTime()));\n    if (underlyingCache != null) System.out.println(\"cache: hits=\" + underlyingCache.getStats().getCumulativeHits() + \" lookups=\" + underlyingCache.getStats().getCumulativeLookups() + \" size=\" + underlyingCache.getStats().getCurrentSize());\n  }\n\n","sourceOld":"  public static void doDecodePerf(String[] args) throws Exception {\n    int arg=0;\n    int nThreads = Integer.parseInt(args[arg++]);\n    int nBuffers = Integer.parseInt(args[arg++]);\n    final long iter = Long.parseLong(args[arg++]);\n    int cacheSz = Integer.parseInt(args[arg++]);\n\n    Random r = new Random(0);\n\n    final byte[][] buffers = new byte[nBuffers][];\n\n    for (int bufnum=0; bufnum<nBuffers; bufnum++) {\n      SolrDocument sdoc = new SolrDocument();\n      sdoc.put(\"id\", \"my_id_\" + bufnum);\n      sdoc.put(\"author\", str(r, 10 + r.nextInt(10)));\n      sdoc.put(\"address\", str(r, 20 + r.nextInt(20)));\n      sdoc.put(\"license\", str(r, 10));\n      sdoc.put(\"title\", str(r, 5 + r.nextInt(10)));\n      sdoc.put(\"modified_dt\", r.nextInt(1000000));\n      sdoc.put(\"creation_dt\", r.nextInt(1000000));\n      sdoc.put(\"birthdate_dt\", r.nextInt(1000000));\n      sdoc.put(\"clean\", r.nextBoolean());\n      sdoc.put(\"dirty\", r.nextBoolean());\n      sdoc.put(\"employed\", r.nextBoolean());\n      sdoc.put(\"priority\", r.nextInt(100));\n      sdoc.put(\"dependents\", r.nextInt(6));\n      sdoc.put(\"level\", r.nextInt(101));\n      sdoc.put(\"education_level\", r.nextInt(10));\n      // higher level of reuse for string values\n      sdoc.put(\"state\", \"S\"+r.nextInt(50));\n      sdoc.put(\"country\", \"Country\"+r.nextInt(20));\n      sdoc.put(\"some_boolean\", \"\"+r.nextBoolean());\n      sdoc.put(\"another_boolean\", \"\"+r.nextBoolean());\n\n\n      JavaBinCodec javabin = new JavaBinCodec();\n      ByteArrayOutputStream os = new ByteArrayOutputStream();\n      javabin.marshal(sdoc, os);\n      os.toByteArray();\n      buffers[bufnum] = os.toByteArray();\n    }\n\n    int ret = 0;\n    final RTimer timer = new RTimer();\n    ConcurrentLRUCache underlyingCache = cacheSz > 0 ? new ConcurrentLRUCache<>(cacheSz,cacheSz-cacheSz/10,cacheSz,cacheSz/10,false,true,null) : null;  // the cache in the first version of the patch was 10000,9000,10000,1000,false,true,null\n    final JavaBinCodec.StringCache stringCache = underlyingCache==null ? null : new JavaBinCodec.StringCache(underlyingCache);\n    if (nThreads <= 0) {\n      ret += doDecode(buffers, iter, stringCache);\n    } else {\n      runInThreads(nThreads, () -> {\n        try {\n          doDecode(buffers, iter, stringCache);\n        } catch (IOException e) {\n          e.printStackTrace();\n        }\n      });\n    }\n\n    long n = iter * Math.max(1,nThreads);\n    System.out.println(\"ret=\" + ret + \" THROUGHPUT=\" + (n*1000 / timer.getTime()));\n    if (underlyingCache != null) System.out.println(\"cache: hits=\" + underlyingCache.getStats().getCumulativeHits() + \" lookups=\" + underlyingCache.getStats().getCumulativeLookups() + \" size=\" + underlyingCache.getStats().getCurrentSize());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"17e5da53e4e5bd659e22add9bba1cfa222e7e30d","date":1475435902,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"solr/solrj/src/test/org/apache/solr/common/util/TestJavaBinCodec#doDecodePerf(String[]).mjava","pathOld":"solr/solrj/src/test/org/apache/solr/common/util/TestJavaBinCodec#doDecodePerf(String[]).mjava","sourceNew":"  public static void doDecodePerf(String[] args) throws Exception {\n    int arg=0;\n    int nThreads = Integer.parseInt(args[arg++]);\n    int nBuffers = Integer.parseInt(args[arg++]);\n    final long iter = Long.parseLong(args[arg++]);\n    int cacheSz = Integer.parseInt(args[arg++]);\n\n    Random r = new Random(0);\n\n    final byte[][] buffers = new byte[nBuffers][];\n\n    for (int bufnum=0; bufnum<nBuffers; bufnum++) {\n      SolrDocument sdoc = new SolrDocument();\n      sdoc.put(\"id\", \"my_id_\" + bufnum);\n      sdoc.put(\"author\", str(r, 10 + r.nextInt(10)));\n      sdoc.put(\"address\", str(r, 20 + r.nextInt(20)));\n      sdoc.put(\"license\", str(r, 10));\n      sdoc.put(\"title\", str(r, 5 + r.nextInt(10)));\n      sdoc.put(\"modified_dt\", r.nextInt(1000000));\n      sdoc.put(\"creation_dt\", r.nextInt(1000000));\n      sdoc.put(\"birthdate_dt\", r.nextInt(1000000));\n      sdoc.put(\"clean\", r.nextBoolean());\n      sdoc.put(\"dirty\", r.nextBoolean());\n      sdoc.put(\"employed\", r.nextBoolean());\n      sdoc.put(\"priority\", r.nextInt(100));\n      sdoc.put(\"dependents\", r.nextInt(6));\n      sdoc.put(\"level\", r.nextInt(101));\n      sdoc.put(\"education_level\", r.nextInt(10));\n      // higher level of reuse for string values\n      sdoc.put(\"state\", \"S\"+r.nextInt(50));\n      sdoc.put(\"country\", \"Country\"+r.nextInt(20));\n      sdoc.put(\"some_boolean\", \"\"+r.nextBoolean());\n      sdoc.put(\"another_boolean\", \"\"+r.nextBoolean());\n\n      buffers[bufnum] = getBytes(sdoc);\n    }\n\n    int ret = 0;\n    final RTimer timer = new RTimer();\n    ConcurrentLRUCache underlyingCache = cacheSz > 0 ? new ConcurrentLRUCache<>(cacheSz,cacheSz-cacheSz/10,cacheSz,cacheSz/10,false,true,null) : null;  // the cache in the first version of the patch was 10000,9000,10000,1000,false,true,null\n    final JavaBinCodec.StringCache stringCache = underlyingCache==null ? null : new JavaBinCodec.StringCache(underlyingCache);\n    if (nThreads <= 0) {\n      ret += doDecode(buffers, iter, stringCache);\n    } else {\n      runInThreads(nThreads, () -> {\n        try {\n          doDecode(buffers, iter, stringCache);\n        } catch (IOException e) {\n          e.printStackTrace();\n        }\n      });\n    }\n\n    long n = iter * Math.max(1,nThreads);\n    System.out.println(\"ret=\" + ret + \" THROUGHPUT=\" + (n*1000 / timer.getTime()));\n    if (underlyingCache != null) System.out.println(\"cache: hits=\" + underlyingCache.getStats().getCumulativeHits() + \" lookups=\" + underlyingCache.getStats().getCumulativeLookups() + \" size=\" + underlyingCache.getStats().getCurrentSize());\n  }\n\n","sourceOld":"  public static void doDecodePerf(String[] args) throws Exception {\n    int arg=0;\n    int nThreads = Integer.parseInt(args[arg++]);\n    int nBuffers = Integer.parseInt(args[arg++]);\n    final long iter = Long.parseLong(args[arg++]);\n    int cacheSz = Integer.parseInt(args[arg++]);\n\n    Random r = new Random(0);\n\n    final byte[][] buffers = new byte[nBuffers][];\n\n    for (int bufnum=0; bufnum<nBuffers; bufnum++) {\n      SolrDocument sdoc = new SolrDocument();\n      sdoc.put(\"id\", \"my_id_\" + bufnum);\n      sdoc.put(\"author\", str(r, 10 + r.nextInt(10)));\n      sdoc.put(\"address\", str(r, 20 + r.nextInt(20)));\n      sdoc.put(\"license\", str(r, 10));\n      sdoc.put(\"title\", str(r, 5 + r.nextInt(10)));\n      sdoc.put(\"modified_dt\", r.nextInt(1000000));\n      sdoc.put(\"creation_dt\", r.nextInt(1000000));\n      sdoc.put(\"birthdate_dt\", r.nextInt(1000000));\n      sdoc.put(\"clean\", r.nextBoolean());\n      sdoc.put(\"dirty\", r.nextBoolean());\n      sdoc.put(\"employed\", r.nextBoolean());\n      sdoc.put(\"priority\", r.nextInt(100));\n      sdoc.put(\"dependents\", r.nextInt(6));\n      sdoc.put(\"level\", r.nextInt(101));\n      sdoc.put(\"education_level\", r.nextInt(10));\n      // higher level of reuse for string values\n      sdoc.put(\"state\", \"S\"+r.nextInt(50));\n      sdoc.put(\"country\", \"Country\"+r.nextInt(20));\n      sdoc.put(\"some_boolean\", \"\"+r.nextBoolean());\n      sdoc.put(\"another_boolean\", \"\"+r.nextBoolean());\n\n\n      JavaBinCodec javabin = new JavaBinCodec();\n      ByteArrayOutputStream os = new ByteArrayOutputStream();\n      javabin.marshal(sdoc, os);\n      os.toByteArray();\n      buffers[bufnum] = os.toByteArray();\n    }\n\n    int ret = 0;\n    final RTimer timer = new RTimer();\n    ConcurrentLRUCache underlyingCache = cacheSz > 0 ? new ConcurrentLRUCache<>(cacheSz,cacheSz-cacheSz/10,cacheSz,cacheSz/10,false,true,null) : null;  // the cache in the first version of the patch was 10000,9000,10000,1000,false,true,null\n    final JavaBinCodec.StringCache stringCache = underlyingCache==null ? null : new JavaBinCodec.StringCache(underlyingCache);\n    if (nThreads <= 0) {\n      ret += doDecode(buffers, iter, stringCache);\n    } else {\n      runInThreads(nThreads, () -> {\n        try {\n          doDecode(buffers, iter, stringCache);\n        } catch (IOException e) {\n          e.printStackTrace();\n        }\n      });\n    }\n\n    long n = iter * Math.max(1,nThreads);\n    System.out.println(\"ret=\" + ret + \" THROUGHPUT=\" + (n*1000 / timer.getTime()));\n    if (underlyingCache != null) System.out.println(\"cache: hits=\" + underlyingCache.getStats().getCumulativeHits() + \" lookups=\" + underlyingCache.getStats().getCumulativeLookups() + \" size=\" + underlyingCache.getStats().getCurrentSize());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4cce5816ef15a48a0bc11e5d400497ee4301dd3b","date":1476991456,"type":3,"author":"Kevin Risden","isMerge":true,"pathNew":"solr/solrj/src/test/org/apache/solr/common/util/TestJavaBinCodec#doDecodePerf(String[]).mjava","pathOld":"solr/solrj/src/test/org/apache/solr/common/util/TestJavaBinCodec#doDecodePerf(String[]).mjava","sourceNew":"  public static void doDecodePerf(String[] args) throws Exception {\n    int arg=0;\n    int nThreads = Integer.parseInt(args[arg++]);\n    int nBuffers = Integer.parseInt(args[arg++]);\n    final long iter = Long.parseLong(args[arg++]);\n    int cacheSz = Integer.parseInt(args[arg++]);\n\n    Random r = new Random(0);\n\n    final byte[][] buffers = new byte[nBuffers][];\n\n    for (int bufnum=0; bufnum<nBuffers; bufnum++) {\n      SolrDocument sdoc = new SolrDocument();\n      sdoc.put(\"id\", \"my_id_\" + bufnum);\n      sdoc.put(\"author\", str(r, 10 + r.nextInt(10)));\n      sdoc.put(\"address\", str(r, 20 + r.nextInt(20)));\n      sdoc.put(\"license\", str(r, 10));\n      sdoc.put(\"title\", str(r, 5 + r.nextInt(10)));\n      sdoc.put(\"modified_dt\", r.nextInt(1000000));\n      sdoc.put(\"creation_dt\", r.nextInt(1000000));\n      sdoc.put(\"birthdate_dt\", r.nextInt(1000000));\n      sdoc.put(\"clean\", r.nextBoolean());\n      sdoc.put(\"dirty\", r.nextBoolean());\n      sdoc.put(\"employed\", r.nextBoolean());\n      sdoc.put(\"priority\", r.nextInt(100));\n      sdoc.put(\"dependents\", r.nextInt(6));\n      sdoc.put(\"level\", r.nextInt(101));\n      sdoc.put(\"education_level\", r.nextInt(10));\n      // higher level of reuse for string values\n      sdoc.put(\"state\", \"S\"+r.nextInt(50));\n      sdoc.put(\"country\", \"Country\"+r.nextInt(20));\n      sdoc.put(\"some_boolean\", \"\"+r.nextBoolean());\n      sdoc.put(\"another_boolean\", \"\"+r.nextBoolean());\n\n      buffers[bufnum] = getBytes(sdoc);\n    }\n\n    int ret = 0;\n    final RTimer timer = new RTimer();\n    ConcurrentLRUCache underlyingCache = cacheSz > 0 ? new ConcurrentLRUCache<>(cacheSz,cacheSz-cacheSz/10,cacheSz,cacheSz/10,false,true,null) : null;  // the cache in the first version of the patch was 10000,9000,10000,1000,false,true,null\n    final JavaBinCodec.StringCache stringCache = underlyingCache==null ? null : new JavaBinCodec.StringCache(underlyingCache);\n    if (nThreads <= 0) {\n      ret += doDecode(buffers, iter, stringCache);\n    } else {\n      runInThreads(nThreads, () -> {\n        try {\n          doDecode(buffers, iter, stringCache);\n        } catch (IOException e) {\n          e.printStackTrace();\n        }\n      });\n    }\n\n    long n = iter * Math.max(1,nThreads);\n    System.out.println(\"ret=\" + ret + \" THROUGHPUT=\" + (n*1000 / timer.getTime()));\n    if (underlyingCache != null) System.out.println(\"cache: hits=\" + underlyingCache.getStats().getCumulativeHits() + \" lookups=\" + underlyingCache.getStats().getCumulativeLookups() + \" size=\" + underlyingCache.getStats().getCurrentSize());\n  }\n\n","sourceOld":"  public static void doDecodePerf(String[] args) throws Exception {\n    int arg=0;\n    int nThreads = Integer.parseInt(args[arg++]);\n    int nBuffers = Integer.parseInt(args[arg++]);\n    final long iter = Long.parseLong(args[arg++]);\n    int cacheSz = Integer.parseInt(args[arg++]);\n\n    Random r = new Random(0);\n\n    final byte[][] buffers = new byte[nBuffers][];\n\n    for (int bufnum=0; bufnum<nBuffers; bufnum++) {\n      SolrDocument sdoc = new SolrDocument();\n      sdoc.put(\"id\", \"my_id_\" + bufnum);\n      sdoc.put(\"author\", str(r, 10 + r.nextInt(10)));\n      sdoc.put(\"address\", str(r, 20 + r.nextInt(20)));\n      sdoc.put(\"license\", str(r, 10));\n      sdoc.put(\"title\", str(r, 5 + r.nextInt(10)));\n      sdoc.put(\"modified_dt\", r.nextInt(1000000));\n      sdoc.put(\"creation_dt\", r.nextInt(1000000));\n      sdoc.put(\"birthdate_dt\", r.nextInt(1000000));\n      sdoc.put(\"clean\", r.nextBoolean());\n      sdoc.put(\"dirty\", r.nextBoolean());\n      sdoc.put(\"employed\", r.nextBoolean());\n      sdoc.put(\"priority\", r.nextInt(100));\n      sdoc.put(\"dependents\", r.nextInt(6));\n      sdoc.put(\"level\", r.nextInt(101));\n      sdoc.put(\"education_level\", r.nextInt(10));\n      // higher level of reuse for string values\n      sdoc.put(\"state\", \"S\"+r.nextInt(50));\n      sdoc.put(\"country\", \"Country\"+r.nextInt(20));\n      sdoc.put(\"some_boolean\", \"\"+r.nextBoolean());\n      sdoc.put(\"another_boolean\", \"\"+r.nextBoolean());\n\n\n      JavaBinCodec javabin = new JavaBinCodec();\n      ByteArrayOutputStream os = new ByteArrayOutputStream();\n      javabin.marshal(sdoc, os);\n      os.toByteArray();\n      buffers[bufnum] = os.toByteArray();\n    }\n\n    int ret = 0;\n    final RTimer timer = new RTimer();\n    ConcurrentLRUCache underlyingCache = cacheSz > 0 ? new ConcurrentLRUCache<>(cacheSz,cacheSz-cacheSz/10,cacheSz,cacheSz/10,false,true,null) : null;  // the cache in the first version of the patch was 10000,9000,10000,1000,false,true,null\n    final JavaBinCodec.StringCache stringCache = underlyingCache==null ? null : new JavaBinCodec.StringCache(underlyingCache);\n    if (nThreads <= 0) {\n      ret += doDecode(buffers, iter, stringCache);\n    } else {\n      runInThreads(nThreads, () -> {\n        try {\n          doDecode(buffers, iter, stringCache);\n        } catch (IOException e) {\n          e.printStackTrace();\n        }\n      });\n    }\n\n    long n = iter * Math.max(1,nThreads);\n    System.out.println(\"ret=\" + ret + \" THROUGHPUT=\" + (n*1000 / timer.getTime()));\n    if (underlyingCache != null) System.out.println(\"cache: hits=\" + underlyingCache.getStats().getCumulativeHits() + \" lookups=\" + underlyingCache.getStats().getCumulativeLookups() + \" size=\" + underlyingCache.getStats().getCurrentSize());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9ba1b632c041956c93c41aa1143d16a567014891","date":1592328473,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/solrj/src/test/org/apache/solr/common/util/TestJavaBinCodec#doDecodePerf(String[]).mjava","pathOld":"solr/solrj/src/test/org/apache/solr/common/util/TestJavaBinCodec#doDecodePerf(String[]).mjava","sourceNew":"  @SuppressWarnings({\"unchecked\"})\n  public static void doDecodePerf(String[] args) throws Exception {\n    int arg=0;\n    int nThreads = Integer.parseInt(args[arg++]);\n    int nBuffers = Integer.parseInt(args[arg++]);\n    final long iter = Long.parseLong(args[arg++]);\n    int cacheSz = Integer.parseInt(args[arg++]);\n\n    Random r = new Random(0);\n\n    final byte[][] buffers = new byte[nBuffers][];\n\n    for (int bufnum=0; bufnum<nBuffers; bufnum++) {\n      SolrDocument sdoc = new SolrDocument();\n      sdoc.put(\"id\", \"my_id_\" + bufnum);\n      sdoc.put(\"author\", str(r, 10 + r.nextInt(10)));\n      sdoc.put(\"address\", str(r, 20 + r.nextInt(20)));\n      sdoc.put(\"license\", str(r, 10));\n      sdoc.put(\"title\", str(r, 5 + r.nextInt(10)));\n      sdoc.put(\"modified_dt\", r.nextInt(1000000));\n      sdoc.put(\"creation_dt\", r.nextInt(1000000));\n      sdoc.put(\"birthdate_dt\", r.nextInt(1000000));\n      sdoc.put(\"clean\", r.nextBoolean());\n      sdoc.put(\"dirty\", r.nextBoolean());\n      sdoc.put(\"employed\", r.nextBoolean());\n      sdoc.put(\"priority\", r.nextInt(100));\n      sdoc.put(\"dependents\", r.nextInt(6));\n      sdoc.put(\"level\", r.nextInt(101));\n      sdoc.put(\"education_level\", r.nextInt(10));\n      // higher level of reuse for string values\n      sdoc.put(\"state\", \"S\"+r.nextInt(50));\n      sdoc.put(\"country\", \"Country\"+r.nextInt(20));\n      sdoc.put(\"some_boolean\", \"\"+r.nextBoolean());\n      sdoc.put(\"another_boolean\", \"\"+r.nextBoolean());\n\n      buffers[bufnum] = getBytes(sdoc);\n    }\n\n    int ret = 0;\n    final RTimer timer = new RTimer();\n    @SuppressWarnings({\"rawtypes\"})\n    ConcurrentLRUCache underlyingCache = cacheSz > 0 ? new ConcurrentLRUCache<>(cacheSz,cacheSz-cacheSz/10,cacheSz,cacheSz/10,false,true,null) : null;  // the cache in the first version of the patch was 10000,9000,10000,1000,false,true,null\n    final JavaBinCodec.StringCache stringCache = underlyingCache==null ? null : new JavaBinCodec.StringCache(underlyingCache);\n    if (nThreads <= 0) {\n      ret += doDecode(buffers, iter, stringCache);\n    } else {\n      runInThreads(nThreads, () -> {\n        try {\n          doDecode(buffers, iter, stringCache);\n        } catch (IOException e) {\n          e.printStackTrace();\n        }\n      });\n    }\n\n    long n = iter * Math.max(1,nThreads);\n    System.out.println(\"ret=\" + ret + \" THROUGHPUT=\" + (n*1000 / timer.getTime()));\n    if (underlyingCache != null) System.out.println(\"cache: hits=\" + underlyingCache.getStats().getCumulativeHits() + \" lookups=\" + underlyingCache.getStats().getCumulativeLookups() + \" size=\" + underlyingCache.getStats().getCurrentSize());\n  }\n\n","sourceOld":"  public static void doDecodePerf(String[] args) throws Exception {\n    int arg=0;\n    int nThreads = Integer.parseInt(args[arg++]);\n    int nBuffers = Integer.parseInt(args[arg++]);\n    final long iter = Long.parseLong(args[arg++]);\n    int cacheSz = Integer.parseInt(args[arg++]);\n\n    Random r = new Random(0);\n\n    final byte[][] buffers = new byte[nBuffers][];\n\n    for (int bufnum=0; bufnum<nBuffers; bufnum++) {\n      SolrDocument sdoc = new SolrDocument();\n      sdoc.put(\"id\", \"my_id_\" + bufnum);\n      sdoc.put(\"author\", str(r, 10 + r.nextInt(10)));\n      sdoc.put(\"address\", str(r, 20 + r.nextInt(20)));\n      sdoc.put(\"license\", str(r, 10));\n      sdoc.put(\"title\", str(r, 5 + r.nextInt(10)));\n      sdoc.put(\"modified_dt\", r.nextInt(1000000));\n      sdoc.put(\"creation_dt\", r.nextInt(1000000));\n      sdoc.put(\"birthdate_dt\", r.nextInt(1000000));\n      sdoc.put(\"clean\", r.nextBoolean());\n      sdoc.put(\"dirty\", r.nextBoolean());\n      sdoc.put(\"employed\", r.nextBoolean());\n      sdoc.put(\"priority\", r.nextInt(100));\n      sdoc.put(\"dependents\", r.nextInt(6));\n      sdoc.put(\"level\", r.nextInt(101));\n      sdoc.put(\"education_level\", r.nextInt(10));\n      // higher level of reuse for string values\n      sdoc.put(\"state\", \"S\"+r.nextInt(50));\n      sdoc.put(\"country\", \"Country\"+r.nextInt(20));\n      sdoc.put(\"some_boolean\", \"\"+r.nextBoolean());\n      sdoc.put(\"another_boolean\", \"\"+r.nextBoolean());\n\n      buffers[bufnum] = getBytes(sdoc);\n    }\n\n    int ret = 0;\n    final RTimer timer = new RTimer();\n    ConcurrentLRUCache underlyingCache = cacheSz > 0 ? new ConcurrentLRUCache<>(cacheSz,cacheSz-cacheSz/10,cacheSz,cacheSz/10,false,true,null) : null;  // the cache in the first version of the patch was 10000,9000,10000,1000,false,true,null\n    final JavaBinCodec.StringCache stringCache = underlyingCache==null ? null : new JavaBinCodec.StringCache(underlyingCache);\n    if (nThreads <= 0) {\n      ret += doDecode(buffers, iter, stringCache);\n    } else {\n      runInThreads(nThreads, () -> {\n        try {\n          doDecode(buffers, iter, stringCache);\n        } catch (IOException e) {\n          e.printStackTrace();\n        }\n      });\n    }\n\n    long n = iter * Math.max(1,nThreads);\n    System.out.println(\"ret=\" + ret + \" THROUGHPUT=\" + (n*1000 / timer.getTime()));\n    if (underlyingCache != null) System.out.println(\"cache: hits=\" + underlyingCache.getStats().getCumulativeHits() + \" lookups=\" + underlyingCache.getStats().getCumulativeLookups() + \" size=\" + underlyingCache.getStats().getCurrentSize());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"9ba1b632c041956c93c41aa1143d16a567014891":["17e5da53e4e5bd659e22add9bba1cfa222e7e30d"],"04aef18a25f8e0d1832199f0cc7607773de5a229":["3a0c04b71951333291abc7f317109a6a5957bd28"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"17e5da53e4e5bd659e22add9bba1cfa222e7e30d":["3a0c04b71951333291abc7f317109a6a5957bd28","89424def13674ea17829b41c5883c54ecc31a132"],"bcf9886c8ff537aafde14de48ebf744f5673f08b":["93c4a0fd70c7b102c0dcc58e54802670eb4ee728"],"2d29e71be37a0f12cb2e7a55eac52341af2e5f18":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"3a0c04b71951333291abc7f317109a6a5957bd28":["bcf9886c8ff537aafde14de48ebf744f5673f08b"],"93c4a0fd70c7b102c0dcc58e54802670eb4ee728":["2d29e71be37a0f12cb2e7a55eac52341af2e5f18"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["3a0c04b71951333291abc7f317109a6a5957bd28","17e5da53e4e5bd659e22add9bba1cfa222e7e30d"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["9ba1b632c041956c93c41aa1143d16a567014891"],"89424def13674ea17829b41c5883c54ecc31a132":["3a0c04b71951333291abc7f317109a6a5957bd28","04aef18a25f8e0d1832199f0cc7607773de5a229"]},"commit2Childs":{"9ba1b632c041956c93c41aa1143d16a567014891":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"04aef18a25f8e0d1832199f0cc7607773de5a229":["89424def13674ea17829b41c5883c54ecc31a132"],"17e5da53e4e5bd659e22add9bba1cfa222e7e30d":["9ba1b632c041956c93c41aa1143d16a567014891","4cce5816ef15a48a0bc11e5d400497ee4301dd3b"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["2d29e71be37a0f12cb2e7a55eac52341af2e5f18"],"bcf9886c8ff537aafde14de48ebf744f5673f08b":["3a0c04b71951333291abc7f317109a6a5957bd28"],"2d29e71be37a0f12cb2e7a55eac52341af2e5f18":["93c4a0fd70c7b102c0dcc58e54802670eb4ee728"],"3a0c04b71951333291abc7f317109a6a5957bd28":["04aef18a25f8e0d1832199f0cc7607773de5a229","17e5da53e4e5bd659e22add9bba1cfa222e7e30d","4cce5816ef15a48a0bc11e5d400497ee4301dd3b","89424def13674ea17829b41c5883c54ecc31a132"],"93c4a0fd70c7b102c0dcc58e54802670eb4ee728":["bcf9886c8ff537aafde14de48ebf744f5673f08b"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":[],"89424def13674ea17829b41c5883c54ecc31a132":["17e5da53e4e5bd659e22add9bba1cfa222e7e30d"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}