{"path":"lucene/analysis/common/src/test/org/apache/lucene/analysis/hunspell2/TestHunspell2StemFilter#testKeywordAttribute().mjava","commits":[{"id":"c214bc712d04c78c4d434119d560d0a4dd2fce4f","date":1393216863,"type":0,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/analysis/common/src/test/org/apache/lucene/analysis/hunspell2/TestHunspell2StemFilter#testKeywordAttribute().mjava","pathOld":"/dev/null","sourceNew":"  /** Simple test for KeywordAttribute */\n  public void testKeywordAttribute() throws IOException {\n    MockTokenizer tokenizer = whitespaceMockTokenizer(\"lucene is awesome\");\n    tokenizer.setEnableChecks(true);\n    Hunspell2StemFilter filter = new Hunspell2StemFilter(tokenizer, dictionary, TestUtil.nextInt(random(), 1, 3));\n    assertTokenStreamContents(filter, new String[]{\"lucene\", \"lucen\", \"is\", \"awesome\"}, new int[] {1, 0, 1, 1});\n    \n    // assert with keyword marker\n    tokenizer = whitespaceMockTokenizer(\"lucene is awesome\");\n    CharArraySet set = new CharArraySet(TEST_VERSION_CURRENT, Arrays.asList(\"Lucene\"), true);\n    filter = new Hunspell2StemFilter(new SetKeywordMarkerFilter(tokenizer, set), dictionary, TestUtil.nextInt(random(), 1, 3));\n    assertTokenStreamContents(filter, new String[]{\"lucene\", \"is\", \"awesome\"}, new int[] {1, 1, 1});\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"dc3f094cafa4a87b4066e1d6710fa4e6afe6260e","date":1393532367,"type":4,"author":"Robert Muir","isMerge":false,"pathNew":"/dev/null","pathOld":"lucene/analysis/common/src/test/org/apache/lucene/analysis/hunspell2/TestHunspell2StemFilter#testKeywordAttribute().mjava","sourceNew":null,"sourceOld":"  /** Simple test for KeywordAttribute */\n  public void testKeywordAttribute() throws IOException {\n    MockTokenizer tokenizer = whitespaceMockTokenizer(\"lucene is awesome\");\n    tokenizer.setEnableChecks(true);\n    Hunspell2StemFilter filter = new Hunspell2StemFilter(tokenizer, dictionary, TestUtil.nextInt(random(), 1, 3));\n    assertTokenStreamContents(filter, new String[]{\"lucene\", \"lucen\", \"is\", \"awesome\"}, new int[] {1, 0, 1, 1});\n    \n    // assert with keyword marker\n    tokenizer = whitespaceMockTokenizer(\"lucene is awesome\");\n    CharArraySet set = new CharArraySet(TEST_VERSION_CURRENT, Arrays.asList(\"Lucene\"), true);\n    filter = new Hunspell2StemFilter(new SetKeywordMarkerFilter(tokenizer, set), dictionary, TestUtil.nextInt(random(), 1, 3));\n    assertTokenStreamContents(filter, new String[]{\"lucene\", \"is\", \"awesome\"}, new int[] {1, 1, 1});\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"dc3f094cafa4a87b4066e1d6710fa4e6afe6260e":["c214bc712d04c78c4d434119d560d0a4dd2fce4f"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"c214bc712d04c78c4d434119d560d0a4dd2fce4f":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"dc3f094cafa4a87b4066e1d6710fa4e6afe6260e":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["c214bc712d04c78c4d434119d560d0a4dd2fce4f","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"c214bc712d04c78c4d434119d560d0a4dd2fce4f":["dc3f094cafa4a87b4066e1d6710fa4e6afe6260e"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["dc3f094cafa4a87b4066e1d6710fa4e6afe6260e","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}