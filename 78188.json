{"path":"lucene/core/src/java/org/apache/lucene/index/BufferedDeletesStream#applyNumericDocValuesUpdates(Iterable[NumericUpdate],ReadersAndLiveDocs,SegmentReader,Map[String,NumericFieldUpdates]).mjava","commits":[{"id":"1bae040fd1d5e03e0d8d695a9c25cf4f402e7ffe","date":1381909398,"type":0,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/BufferedDeletesStream#applyNumericDocValuesUpdates(Iterable[NumericUpdate],ReadersAndLiveDocs,SegmentReader,Map[String,NumericFieldUpdates]).mjava","pathOld":"/dev/null","sourceNew":"  // NumericDocValues Updates\n  // If otherFieldUpdates != null, we need to merge the updates into them\n  private synchronized Map<String,NumericFieldUpdates> applyNumericDocValuesUpdates(Iterable<NumericUpdate> updates, \n      ReadersAndLiveDocs rld, SegmentReader reader, Map<String,NumericFieldUpdates> otherFieldUpdates) throws IOException {\n    Fields fields = reader.fields();\n    if (fields == null) {\n      // This reader has no postings\n      return Collections.emptyMap();\n    }\n\n    // TODO: we can process the updates per DV field, from last to first so that\n    // if multiple terms affect same document for the same field, we add an update\n    // only once (that of the last term). To do that, we can keep a bitset which\n    // marks which documents have already been updated. So e.g. if term T1\n    // updates doc 7, and then we process term T2 and it updates doc 7 as well,\n    // we don't apply the update since we know T1 came last and therefore wins\n    // the update.\n    // We can also use that bitset as 'liveDocs' to pass to TermEnum.docs(), so\n    // that these documents aren't even returned.\n    \n    String currentField = null;\n    TermsEnum termsEnum = null;\n    DocsEnum docs = null;\n    final Map<String,NumericFieldUpdates> result = otherFieldUpdates == null ? new HashMap<String,NumericFieldUpdates>() : otherFieldUpdates;\n    //System.out.println(Thread.currentThread().getName() + \" numericDVUpdate reader=\" + reader);\n    for (NumericUpdate update : updates) {\n      Term term = update.term;\n      int limit = update.docIDUpto;\n      \n      // TODO: we traverse the terms in update order (not term order) so that we\n      // apply the updates in the correct order, i.e. if two terms udpate the\n      // same document, the last one that came in wins, irrespective of the\n      // terms lexical order.\n      // we can apply the updates in terms order if we keep an updatesGen (and\n      // increment it with every update) and attach it to each NumericUpdate. Note\n      // that we cannot rely only on docIDUpto because an app may send two updates\n      // which will get same docIDUpto, yet will still need to respect the order\n      // those updates arrived.\n      \n      if (!term.field().equals(currentField)) {\n        // if we change the code to process updates in terms order, enable this assert\n//        assert currentField == null || currentField.compareTo(term.field()) < 0;\n        currentField = term.field();\n        Terms terms = fields.terms(currentField);\n        if (terms != null) {\n          termsEnum = terms.iterator(termsEnum);\n        } else {\n          termsEnum = null;\n          continue; // no terms in that field\n        }\n      }\n\n      if (termsEnum == null) {\n        continue;\n      }\n      // System.out.println(\"  term=\" + term);\n\n      if (termsEnum.seekExact(term.bytes())) {\n        // we don't need term frequencies for this\n        DocsEnum docsEnum = termsEnum.docs(rld.getLiveDocs(), docs, DocsEnum.FLAG_NONE);\n      \n        //System.out.println(\"BDS: got docsEnum=\" + docsEnum);\n\n        NumericFieldUpdates fieldUpdates = result.get(update.field);\n        if (fieldUpdates == null) {\n          fieldUpdates = new NumericFieldUpdates.PackedNumericFieldUpdates(reader.maxDoc());\n          result.put(update.field, fieldUpdates);\n        }\n        int doc;\n        while ((doc = docsEnum.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {\n          //System.out.println(Thread.currentThread().getName() + \" numericDVUpdate term=\" + term + \" doc=\" + docID);\n          if (doc >= limit) {\n            break; // no more docs that can be updated for this term\n          }\n          fieldUpdates.add(doc, update.value);\n        }\n      }\n    }\n    return result;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["8028ab7a24273833d53d35eb160dba5b57283cf5"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"73b0a97ef3bd519a5e43398ea9eabe6eed97f6b0","date":1383367127,"type":5,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/BufferedUpdatesStream#applyNumericDocValuesUpdates(Iterable[NumericUpdate],ReadersAndUpdates,SegmentReader,Map[String,NumericFieldUpdates]).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/BufferedDeletesStream#applyNumericDocValuesUpdates(Iterable[NumericUpdate],ReadersAndLiveDocs,SegmentReader,Map[String,NumericFieldUpdates]).mjava","sourceNew":"  // NumericDocValues Updates\n  // If otherFieldUpdates != null, we need to merge the updates into them\n  private synchronized Map<String,NumericFieldUpdates> applyNumericDocValuesUpdates(Iterable<NumericUpdate> updates, \n      ReadersAndUpdates rld, SegmentReader reader, Map<String,NumericFieldUpdates> otherFieldUpdates) throws IOException {\n    Fields fields = reader.fields();\n    if (fields == null) {\n      // This reader has no postings\n      return Collections.emptyMap();\n    }\n\n    // TODO: we can process the updates per DV field, from last to first so that\n    // if multiple terms affect same document for the same field, we add an update\n    // only once (that of the last term). To do that, we can keep a bitset which\n    // marks which documents have already been updated. So e.g. if term T1\n    // updates doc 7, and then we process term T2 and it updates doc 7 as well,\n    // we don't apply the update since we know T1 came last and therefore wins\n    // the update.\n    // We can also use that bitset as 'liveDocs' to pass to TermEnum.docs(), so\n    // that these documents aren't even returned.\n    \n    String currentField = null;\n    TermsEnum termsEnum = null;\n    DocsEnum docs = null;\n    final Map<String,NumericFieldUpdates> result = otherFieldUpdates == null ? new HashMap<String,NumericFieldUpdates>() : otherFieldUpdates;\n    //System.out.println(Thread.currentThread().getName() + \" numericDVUpdate reader=\" + reader);\n    for (NumericUpdate update : updates) {\n      Term term = update.term;\n      int limit = update.docIDUpto;\n      \n      // TODO: we traverse the terms in update order (not term order) so that we\n      // apply the updates in the correct order, i.e. if two terms udpate the\n      // same document, the last one that came in wins, irrespective of the\n      // terms lexical order.\n      // we can apply the updates in terms order if we keep an updatesGen (and\n      // increment it with every update) and attach it to each NumericUpdate. Note\n      // that we cannot rely only on docIDUpto because an app may send two updates\n      // which will get same docIDUpto, yet will still need to respect the order\n      // those updates arrived.\n      \n      if (!term.field().equals(currentField)) {\n        // if we change the code to process updates in terms order, enable this assert\n//        assert currentField == null || currentField.compareTo(term.field()) < 0;\n        currentField = term.field();\n        Terms terms = fields.terms(currentField);\n        if (terms != null) {\n          termsEnum = terms.iterator(termsEnum);\n        } else {\n          termsEnum = null;\n          continue; // no terms in that field\n        }\n      }\n\n      if (termsEnum == null) {\n        continue;\n      }\n      // System.out.println(\"  term=\" + term);\n\n      if (termsEnum.seekExact(term.bytes())) {\n        // we don't need term frequencies for this\n        DocsEnum docsEnum = termsEnum.docs(rld.getLiveDocs(), docs, DocsEnum.FLAG_NONE);\n      \n        //System.out.println(\"BDS: got docsEnum=\" + docsEnum);\n\n        NumericFieldUpdates fieldUpdates = result.get(update.field);\n        if (fieldUpdates == null) {\n          fieldUpdates = new NumericFieldUpdates.PackedNumericFieldUpdates(reader.maxDoc());\n          result.put(update.field, fieldUpdates);\n        }\n        int doc;\n        while ((doc = docsEnum.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {\n          //System.out.println(Thread.currentThread().getName() + \" numericDVUpdate term=\" + term + \" doc=\" + docID);\n          if (doc >= limit) {\n            break; // no more docs that can be updated for this term\n          }\n          fieldUpdates.add(doc, update.value);\n        }\n      }\n    }\n    return result;\n  }\n\n","sourceOld":"  // NumericDocValues Updates\n  // If otherFieldUpdates != null, we need to merge the updates into them\n  private synchronized Map<String,NumericFieldUpdates> applyNumericDocValuesUpdates(Iterable<NumericUpdate> updates, \n      ReadersAndLiveDocs rld, SegmentReader reader, Map<String,NumericFieldUpdates> otherFieldUpdates) throws IOException {\n    Fields fields = reader.fields();\n    if (fields == null) {\n      // This reader has no postings\n      return Collections.emptyMap();\n    }\n\n    // TODO: we can process the updates per DV field, from last to first so that\n    // if multiple terms affect same document for the same field, we add an update\n    // only once (that of the last term). To do that, we can keep a bitset which\n    // marks which documents have already been updated. So e.g. if term T1\n    // updates doc 7, and then we process term T2 and it updates doc 7 as well,\n    // we don't apply the update since we know T1 came last and therefore wins\n    // the update.\n    // We can also use that bitset as 'liveDocs' to pass to TermEnum.docs(), so\n    // that these documents aren't even returned.\n    \n    String currentField = null;\n    TermsEnum termsEnum = null;\n    DocsEnum docs = null;\n    final Map<String,NumericFieldUpdates> result = otherFieldUpdates == null ? new HashMap<String,NumericFieldUpdates>() : otherFieldUpdates;\n    //System.out.println(Thread.currentThread().getName() + \" numericDVUpdate reader=\" + reader);\n    for (NumericUpdate update : updates) {\n      Term term = update.term;\n      int limit = update.docIDUpto;\n      \n      // TODO: we traverse the terms in update order (not term order) so that we\n      // apply the updates in the correct order, i.e. if two terms udpate the\n      // same document, the last one that came in wins, irrespective of the\n      // terms lexical order.\n      // we can apply the updates in terms order if we keep an updatesGen (and\n      // increment it with every update) and attach it to each NumericUpdate. Note\n      // that we cannot rely only on docIDUpto because an app may send two updates\n      // which will get same docIDUpto, yet will still need to respect the order\n      // those updates arrived.\n      \n      if (!term.field().equals(currentField)) {\n        // if we change the code to process updates in terms order, enable this assert\n//        assert currentField == null || currentField.compareTo(term.field()) < 0;\n        currentField = term.field();\n        Terms terms = fields.terms(currentField);\n        if (terms != null) {\n          termsEnum = terms.iterator(termsEnum);\n        } else {\n          termsEnum = null;\n          continue; // no terms in that field\n        }\n      }\n\n      if (termsEnum == null) {\n        continue;\n      }\n      // System.out.println(\"  term=\" + term);\n\n      if (termsEnum.seekExact(term.bytes())) {\n        // we don't need term frequencies for this\n        DocsEnum docsEnum = termsEnum.docs(rld.getLiveDocs(), docs, DocsEnum.FLAG_NONE);\n      \n        //System.out.println(\"BDS: got docsEnum=\" + docsEnum);\n\n        NumericFieldUpdates fieldUpdates = result.get(update.field);\n        if (fieldUpdates == null) {\n          fieldUpdates = new NumericFieldUpdates.PackedNumericFieldUpdates(reader.maxDoc());\n          result.put(update.field, fieldUpdates);\n        }\n        int doc;\n        while ((doc = docsEnum.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {\n          //System.out.println(Thread.currentThread().getName() + \" numericDVUpdate term=\" + term + \" doc=\" + docID);\n          if (doc >= limit) {\n            break; // no more docs that can be updated for this term\n          }\n          fieldUpdates.add(doc, update.value);\n        }\n      }\n    }\n    return result;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"73b0a97ef3bd519a5e43398ea9eabe6eed97f6b0":["1bae040fd1d5e03e0d8d695a9c25cf4f402e7ffe"],"1bae040fd1d5e03e0d8d695a9c25cf4f402e7ffe":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["73b0a97ef3bd519a5e43398ea9eabe6eed97f6b0"]},"commit2Childs":{"73b0a97ef3bd519a5e43398ea9eabe6eed97f6b0":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"1bae040fd1d5e03e0d8d695a9c25cf4f402e7ffe":["73b0a97ef3bd519a5e43398ea9eabe6eed97f6b0"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["1bae040fd1d5e03e0d8d695a9c25cf4f402e7ffe"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}