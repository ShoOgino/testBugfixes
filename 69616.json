{"path":"lucene/classification/src/test/org/apache/lucene/classification/Test20NewsgroupsClassification#test20Newsgroups().mjava","commits":[{"id":"33bfee30277584028170135002def66f9d57732b","date":1547842233,"type":0,"author":"Tommaso Teofili","isMerge":false,"pathNew":"lucene/classification/src/test/org/apache/lucene/classification/Test20NewsgroupsClassification#test20Newsgroups().mjava","pathOld":"/dev/null","sourceNew":"  @Test\n  public void test20Newsgroups() throws Exception {\n\n    String indexProperty = System.getProperty(\"index\");\n    if (indexProperty != null) {\n      try {\n        index = Boolean.valueOf(indexProperty);\n      } catch (Exception e) {\n        // ignore\n      }\n    }\n\n    String splitProperty = System.getProperty(\"split\");\n    if (splitProperty != null) {\n      try {\n        split = Boolean.valueOf(splitProperty);\n      } catch (Exception e) {\n        // ignore\n      }\n    }\n\n    Path mainIndexPath = Paths.get(INDEX + \"/original\");\n    Directory directory = FSDirectory.open(mainIndexPath);\n    Path trainPath = Paths.get(INDEX + \"/train\");\n    Path testPath = Paths.get(INDEX + \"/test\");\n    Path cvPath = Paths.get(INDEX + \"/cv\");\n    FSDirectory cv = null;\n    FSDirectory test = null;\n    FSDirectory train = null;\n    IndexReader testReader = null;\n    if (split) {\n      cv = FSDirectory.open(cvPath);\n      test = FSDirectory.open(testPath);\n      train = FSDirectory.open(trainPath);\n    }\n\n    if (index) {\n      delete(mainIndexPath);\n      if (split) {\n        delete(trainPath, testPath, cvPath);\n      }\n    }\n\n    IndexReader reader = null;\n    List<Classifier<BytesRef>> classifiers = new LinkedList<>();\n    try {\n      Analyzer analyzer = new StandardAnalyzer();\n      if (index) {\n\n        System.out.format(\"Indexing 20 Newsgroups...%n\");\n\n        long startIndex = System.currentTimeMillis();\n        IndexWriter indexWriter = new IndexWriter(directory, new IndexWriterConfig(analyzer));\n\n        int docsIndexed = buildIndex(new File(PATH_TO_20N), indexWriter);\n\n        long endIndex = System.currentTimeMillis();\n        System.out.format(\"Indexed %d pages in %ds %n\", docsIndexed, (endIndex - startIndex) / 1000);\n\n        indexWriter.close();\n\n      }\n\n      if (split && !index) {\n        reader = DirectoryReader.open(train);\n      } else {\n        reader = DirectoryReader.open(directory);\n      }\n\n      if (index && split) {\n        // split the index\n        System.out.format(\"Splitting the index...%n\");\n\n        long startSplit = System.currentTimeMillis();\n        DatasetSplitter datasetSplitter = new DatasetSplitter(0.2, 0);\n        datasetSplitter.split(reader, train, test, cv, analyzer, false, CATEGORY_FIELD, BODY_FIELD, SUBJECT_FIELD, CATEGORY_FIELD);\n        reader.close();\n        reader = DirectoryReader.open(train); // using the train index from now on\n        long endSplit = System.currentTimeMillis();\n        System.out.format(\"Splitting done in %ds %n\", (endSplit - startSplit) / 1000);\n      }\n\n      final long startTime = System.currentTimeMillis();\n\n\n      classifiers.add(new KNearestNeighborClassifier(reader, new ClassicSimilarity(), analyzer, null, 1, 0, 0, CATEGORY_FIELD, BODY_FIELD));\n      classifiers.add(new KNearestNeighborClassifier(reader, null, analyzer, null, 1, 0, 0, CATEGORY_FIELD, BODY_FIELD));\n      classifiers.add(new KNearestNeighborClassifier(reader, new ClassicSimilarity(), analyzer, null, 3, 0, 0, CATEGORY_FIELD, BODY_FIELD));\n      classifiers.add(new KNearestNeighborClassifier(reader, new AxiomaticF1EXP(), analyzer, null, 3, 0, 0, CATEGORY_FIELD, BODY_FIELD));\n      classifiers.add(new KNearestNeighborClassifier(reader, new AxiomaticF1LOG(), analyzer, null, 3, 0, 0, CATEGORY_FIELD, BODY_FIELD));\n      classifiers.add(new KNearestNeighborClassifier(reader, new LMDirichletSimilarity(), analyzer, null, 3, 1, 1, CATEGORY_FIELD, BODY_FIELD));\n      classifiers.add(new KNearestNeighborClassifier(reader, new LMJelinekMercerSimilarity(0.3f), analyzer, null, 3, 1, 1, CATEGORY_FIELD, BODY_FIELD));\n      classifiers.add(new KNearestNeighborClassifier(reader, null, analyzer, null, 3, 1, 1, CATEGORY_FIELD, BODY_FIELD));\n      classifiers.add(new KNearestNeighborClassifier(reader, new DFRSimilarity(new BasicModelG(), new AfterEffectB(), new NormalizationH1()), analyzer, null, 3, 1, 1, CATEGORY_FIELD, BODY_FIELD));\n      classifiers.add(new KNearestNeighborClassifier(reader, new IBSimilarity(new DistributionSPL(), new LambdaDF(), new Normalization.NoNormalization()), analyzer, null, 3, 1, 1, CATEGORY_FIELD, BODY_FIELD));\n      classifiers.add(new KNearestNeighborClassifier(reader, new IBSimilarity(new DistributionLL(), new LambdaTTF(), new NormalizationH1()), analyzer, null, 3, 1, 1, CATEGORY_FIELD, BODY_FIELD));\n      classifiers.add(new KNearestFuzzyClassifier(reader, new LMJelinekMercerSimilarity(0.3f), analyzer, null, 1, CATEGORY_FIELD, BODY_FIELD));\n      classifiers.add(new KNearestFuzzyClassifier(reader, new IBSimilarity(new DistributionLL(), new LambdaTTF(), new NormalizationH1()), analyzer, null, 1, CATEGORY_FIELD, BODY_FIELD));\n      classifiers.add(new KNearestFuzzyClassifier(reader, new ClassicSimilarity(), analyzer, null, 1, CATEGORY_FIELD, BODY_FIELD));\n      classifiers.add(new KNearestFuzzyClassifier(reader, new ClassicSimilarity(), analyzer, null, 3, CATEGORY_FIELD, BODY_FIELD));\n      classifiers.add(new KNearestFuzzyClassifier(reader, null, analyzer, null, 1, CATEGORY_FIELD, BODY_FIELD));\n      classifiers.add(new KNearestFuzzyClassifier(reader, null, analyzer, null, 3, CATEGORY_FIELD, BODY_FIELD));\n      classifiers.add(new KNearestFuzzyClassifier(reader, new AxiomaticF1EXP(), analyzer, null, 3, CATEGORY_FIELD, BODY_FIELD));\n      classifiers.add(new KNearestFuzzyClassifier(reader, new AxiomaticF1LOG(), analyzer, null, 3, CATEGORY_FIELD, BODY_FIELD));\n      classifiers.add(new BM25NBClassifier(reader, analyzer, null, CATEGORY_FIELD, BODY_FIELD));\n      classifiers.add(new CachingNaiveBayesClassifier(reader, analyzer, null, CATEGORY_FIELD, BODY_FIELD));\n      classifiers.add(new SimpleNaiveBayesClassifier(reader, analyzer, null, CATEGORY_FIELD, BODY_FIELD));\n\n      int maxdoc;\n\n      if (split) {\n        testReader = DirectoryReader.open(test);\n        maxdoc = testReader.maxDoc();\n      } else {\n        maxdoc = reader.maxDoc();\n      }\n\n      System.out.format(\"Starting evaluation on %d docs...%n\", maxdoc);\n\n      ExecutorService service = Executors.newCachedThreadPool();\n      List<Future<String>> futures = new LinkedList<>();\n      for (Classifier<BytesRef> classifier : classifiers) {\n        testClassifier(reader, startTime, testReader, service, futures, classifier);\n      }\n      for (Future<String> f : futures) {\n        System.out.println(f.get());\n      }\n\n      Thread.sleep(10000);\n      service.shutdown();\n\n    } finally {\n      if (reader != null) {\n        reader.close();\n      }\n      directory.close();\n      if (test != null) {\n        test.close();\n      }\n      if (train != null) {\n        train.close();\n      }\n      if (cv != null) {\n        cv.close();\n      }\n      if (testReader != null) {\n        testReader.close();\n      }\n\n      for (Classifier c : classifiers) {\n        if (c instanceof Closeable) {\n          ((Closeable) c).close();\n        }\n      }\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"887f38f1943e88ac7f468b18be6f5d42b4a70add","date":1547972665,"type":3,"author":"Tommaso Teofili","isMerge":false,"pathNew":"lucene/classification/src/test/org/apache/lucene/classification/Test20NewsgroupsClassification#test20Newsgroups().mjava","pathOld":"lucene/classification/src/test/org/apache/lucene/classification/Test20NewsgroupsClassification#test20Newsgroups().mjava","sourceNew":"  @Test\n  public void test20Newsgroups() throws Exception {\n\n    String indexProperty = System.getProperty(\"index\");\n    if (indexProperty != null) {\n      try {\n        index = Boolean.valueOf(indexProperty);\n      } catch (Exception e) {\n        // ignore\n      }\n    }\n\n    String splitProperty = System.getProperty(\"split\");\n    if (splitProperty != null) {\n      try {\n        split = Boolean.valueOf(splitProperty);\n      } catch (Exception e) {\n        // ignore\n      }\n    }\n\n    Path mainIndexPath = Paths.get(INDEX + \"/original\");\n    Directory directory = FSDirectory.open(mainIndexPath);\n    Path trainPath = Paths.get(INDEX + \"/train\");\n    Path testPath = Paths.get(INDEX + \"/test\");\n    Path cvPath = Paths.get(INDEX + \"/cv\");\n    FSDirectory cv = null;\n    FSDirectory test = null;\n    FSDirectory train = null;\n    IndexReader testReader = null;\n    if (split) {\n      cv = FSDirectory.open(cvPath);\n      test = FSDirectory.open(testPath);\n      train = FSDirectory.open(trainPath);\n    }\n\n    if (index) {\n      delete(mainIndexPath);\n      if (split) {\n        delete(trainPath, testPath, cvPath);\n      }\n    }\n\n    IndexReader reader = null;\n    List<Classifier<BytesRef>> classifiers = new LinkedList<>();\n    try {\n      Analyzer analyzer = new StandardAnalyzer();\n      if (index) {\n\n        System.out.println(\"Indexing 20 Newsgroups...\");\n\n        long startIndex = System.currentTimeMillis();\n        IndexWriter indexWriter = new IndexWriter(directory, new IndexWriterConfig(analyzer));\n\n        int docsIndexed = buildIndex(Paths.get(PATH_TO_20N).getParent(), indexWriter);\n\n        long endIndex = System.currentTimeMillis();\n        System.out.println(\"Indexed \" + docsIndexed + \" docs in \" + (endIndex - startIndex) / 1000 + \"s\");\n\n        indexWriter.close();\n\n      }\n\n      if (split && !index) {\n        reader = DirectoryReader.open(train);\n      } else {\n        reader = DirectoryReader.open(directory);\n      }\n\n      if (index && split) {\n        // split the index\n        System.out.println(\"Splitting the index...\");\n\n        long startSplit = System.currentTimeMillis();\n        DatasetSplitter datasetSplitter = new DatasetSplitter(0.2, 0);\n        datasetSplitter.split(reader, train, test, cv, analyzer, false, CATEGORY_FIELD, BODY_FIELD, SUBJECT_FIELD, CATEGORY_FIELD);\n        reader.close();\n        reader = DirectoryReader.open(train); // using the train index from now on\n        long endSplit = System.currentTimeMillis();\n        System.out.println(\"Splitting done in \" + (endSplit - startSplit) / 1000 + \"s\");\n      }\n\n      classifiers.add(new KNearestNeighborClassifier(reader, new ClassicSimilarity(), analyzer, null, 1, 0, 0, CATEGORY_FIELD, BODY_FIELD));\n      classifiers.add(new KNearestNeighborClassifier(reader, null, analyzer, null, 1, 0, 0, CATEGORY_FIELD, BODY_FIELD));\n      classifiers.add(new KNearestNeighborClassifier(reader, new ClassicSimilarity(), analyzer, null, 3, 0, 0, CATEGORY_FIELD, BODY_FIELD));\n      classifiers.add(new KNearestNeighborClassifier(reader, new AxiomaticF1EXP(), analyzer, null, 3, 0, 0, CATEGORY_FIELD, BODY_FIELD));\n      classifiers.add(new KNearestNeighborClassifier(reader, new AxiomaticF1LOG(), analyzer, null, 3, 0, 0, CATEGORY_FIELD, BODY_FIELD));\n      classifiers.add(new KNearestNeighborClassifier(reader, new LMDirichletSimilarity(), analyzer, null, 3, 1, 1, CATEGORY_FIELD, BODY_FIELD));\n      classifiers.add(new KNearestNeighborClassifier(reader, new LMJelinekMercerSimilarity(0.3f), analyzer, null, 3, 1, 1, CATEGORY_FIELD, BODY_FIELD));\n      classifiers.add(new KNearestNeighborClassifier(reader, null, analyzer, null, 3, 1, 1, CATEGORY_FIELD, BODY_FIELD));\n      classifiers.add(new KNearestNeighborClassifier(reader, new DFRSimilarity(new BasicModelG(), new AfterEffectB(), new NormalizationH1()), analyzer, null, 3, 1, 1, CATEGORY_FIELD, BODY_FIELD));\n      classifiers.add(new KNearestNeighborClassifier(reader, new IBSimilarity(new DistributionSPL(), new LambdaDF(), new Normalization.NoNormalization()), analyzer, null, 3, 1, 1, CATEGORY_FIELD, BODY_FIELD));\n      classifiers.add(new KNearestNeighborClassifier(reader, new IBSimilarity(new DistributionLL(), new LambdaTTF(), new NormalizationH1()), analyzer, null, 3, 1, 1, CATEGORY_FIELD, BODY_FIELD));\n      classifiers.add(new KNearestFuzzyClassifier(reader, new LMJelinekMercerSimilarity(0.3f), analyzer, null, 1, CATEGORY_FIELD, BODY_FIELD));\n      classifiers.add(new KNearestFuzzyClassifier(reader, new IBSimilarity(new DistributionLL(), new LambdaTTF(), new NormalizationH1()), analyzer, null, 1, CATEGORY_FIELD, BODY_FIELD));\n      classifiers.add(new KNearestFuzzyClassifier(reader, new ClassicSimilarity(), analyzer, null, 1, CATEGORY_FIELD, BODY_FIELD));\n      classifiers.add(new KNearestFuzzyClassifier(reader, new ClassicSimilarity(), analyzer, null, 3, CATEGORY_FIELD, BODY_FIELD));\n      classifiers.add(new KNearestFuzzyClassifier(reader, null, analyzer, null, 1, CATEGORY_FIELD, BODY_FIELD));\n      classifiers.add(new KNearestFuzzyClassifier(reader, null, analyzer, null, 3, CATEGORY_FIELD, BODY_FIELD));\n      classifiers.add(new KNearestFuzzyClassifier(reader, new AxiomaticF1EXP(), analyzer, null, 3, CATEGORY_FIELD, BODY_FIELD));\n      classifiers.add(new KNearestFuzzyClassifier(reader, new AxiomaticF1LOG(), analyzer, null, 3, CATEGORY_FIELD, BODY_FIELD));\n      classifiers.add(new BM25NBClassifier(reader, analyzer, null, CATEGORY_FIELD, BODY_FIELD));\n      classifiers.add(new CachingNaiveBayesClassifier(reader, analyzer, null, CATEGORY_FIELD, BODY_FIELD));\n      classifiers.add(new SimpleNaiveBayesClassifier(reader, analyzer, null, CATEGORY_FIELD, BODY_FIELD));\n\n      int maxdoc;\n\n      if (split) {\n        testReader = DirectoryReader.open(test);\n        maxdoc = testReader.maxDoc();\n      } else {\n        maxdoc = reader.maxDoc();\n      }\n\n      System.out.println(\"Starting evaluation on \" + maxdoc + \" docs...\");\n\n      ExecutorService service = new ThreadPoolExecutor(1, TestUtil.nextInt(random(), 2, 6), Long.MAX_VALUE, TimeUnit.MILLISECONDS,\n          new LinkedBlockingQueue<>(),\n          new NamedThreadFactory(getClass().getName()));\n      List<Future<String>> futures = new LinkedList<>();\n      for (Classifier<BytesRef> classifier : classifiers) {\n        testClassifier(reader, testReader, service, futures, classifier);\n      }\n      for (Future<String> f : futures) {\n        System.out.println(f.get());\n      }\n\n      Thread.sleep(10000);\n      service.shutdown();\n\n    } finally {\n      if (reader != null) {\n        reader.close();\n      }\n      directory.close();\n      if (test != null) {\n        test.close();\n      }\n      if (train != null) {\n        train.close();\n      }\n      if (cv != null) {\n        cv.close();\n      }\n      if (testReader != null) {\n        testReader.close();\n      }\n\n      for (Classifier<BytesRef> c : classifiers) {\n        if (c instanceof Closeable) {\n          ((Closeable) c).close();\n        }\n      }\n    }\n  }\n\n","sourceOld":"  @Test\n  public void test20Newsgroups() throws Exception {\n\n    String indexProperty = System.getProperty(\"index\");\n    if (indexProperty != null) {\n      try {\n        index = Boolean.valueOf(indexProperty);\n      } catch (Exception e) {\n        // ignore\n      }\n    }\n\n    String splitProperty = System.getProperty(\"split\");\n    if (splitProperty != null) {\n      try {\n        split = Boolean.valueOf(splitProperty);\n      } catch (Exception e) {\n        // ignore\n      }\n    }\n\n    Path mainIndexPath = Paths.get(INDEX + \"/original\");\n    Directory directory = FSDirectory.open(mainIndexPath);\n    Path trainPath = Paths.get(INDEX + \"/train\");\n    Path testPath = Paths.get(INDEX + \"/test\");\n    Path cvPath = Paths.get(INDEX + \"/cv\");\n    FSDirectory cv = null;\n    FSDirectory test = null;\n    FSDirectory train = null;\n    IndexReader testReader = null;\n    if (split) {\n      cv = FSDirectory.open(cvPath);\n      test = FSDirectory.open(testPath);\n      train = FSDirectory.open(trainPath);\n    }\n\n    if (index) {\n      delete(mainIndexPath);\n      if (split) {\n        delete(trainPath, testPath, cvPath);\n      }\n    }\n\n    IndexReader reader = null;\n    List<Classifier<BytesRef>> classifiers = new LinkedList<>();\n    try {\n      Analyzer analyzer = new StandardAnalyzer();\n      if (index) {\n\n        System.out.format(\"Indexing 20 Newsgroups...%n\");\n\n        long startIndex = System.currentTimeMillis();\n        IndexWriter indexWriter = new IndexWriter(directory, new IndexWriterConfig(analyzer));\n\n        int docsIndexed = buildIndex(new File(PATH_TO_20N), indexWriter);\n\n        long endIndex = System.currentTimeMillis();\n        System.out.format(\"Indexed %d pages in %ds %n\", docsIndexed, (endIndex - startIndex) / 1000);\n\n        indexWriter.close();\n\n      }\n\n      if (split && !index) {\n        reader = DirectoryReader.open(train);\n      } else {\n        reader = DirectoryReader.open(directory);\n      }\n\n      if (index && split) {\n        // split the index\n        System.out.format(\"Splitting the index...%n\");\n\n        long startSplit = System.currentTimeMillis();\n        DatasetSplitter datasetSplitter = new DatasetSplitter(0.2, 0);\n        datasetSplitter.split(reader, train, test, cv, analyzer, false, CATEGORY_FIELD, BODY_FIELD, SUBJECT_FIELD, CATEGORY_FIELD);\n        reader.close();\n        reader = DirectoryReader.open(train); // using the train index from now on\n        long endSplit = System.currentTimeMillis();\n        System.out.format(\"Splitting done in %ds %n\", (endSplit - startSplit) / 1000);\n      }\n\n      final long startTime = System.currentTimeMillis();\n\n\n      classifiers.add(new KNearestNeighborClassifier(reader, new ClassicSimilarity(), analyzer, null, 1, 0, 0, CATEGORY_FIELD, BODY_FIELD));\n      classifiers.add(new KNearestNeighborClassifier(reader, null, analyzer, null, 1, 0, 0, CATEGORY_FIELD, BODY_FIELD));\n      classifiers.add(new KNearestNeighborClassifier(reader, new ClassicSimilarity(), analyzer, null, 3, 0, 0, CATEGORY_FIELD, BODY_FIELD));\n      classifiers.add(new KNearestNeighborClassifier(reader, new AxiomaticF1EXP(), analyzer, null, 3, 0, 0, CATEGORY_FIELD, BODY_FIELD));\n      classifiers.add(new KNearestNeighborClassifier(reader, new AxiomaticF1LOG(), analyzer, null, 3, 0, 0, CATEGORY_FIELD, BODY_FIELD));\n      classifiers.add(new KNearestNeighborClassifier(reader, new LMDirichletSimilarity(), analyzer, null, 3, 1, 1, CATEGORY_FIELD, BODY_FIELD));\n      classifiers.add(new KNearestNeighborClassifier(reader, new LMJelinekMercerSimilarity(0.3f), analyzer, null, 3, 1, 1, CATEGORY_FIELD, BODY_FIELD));\n      classifiers.add(new KNearestNeighborClassifier(reader, null, analyzer, null, 3, 1, 1, CATEGORY_FIELD, BODY_FIELD));\n      classifiers.add(new KNearestNeighborClassifier(reader, new DFRSimilarity(new BasicModelG(), new AfterEffectB(), new NormalizationH1()), analyzer, null, 3, 1, 1, CATEGORY_FIELD, BODY_FIELD));\n      classifiers.add(new KNearestNeighborClassifier(reader, new IBSimilarity(new DistributionSPL(), new LambdaDF(), new Normalization.NoNormalization()), analyzer, null, 3, 1, 1, CATEGORY_FIELD, BODY_FIELD));\n      classifiers.add(new KNearestNeighborClassifier(reader, new IBSimilarity(new DistributionLL(), new LambdaTTF(), new NormalizationH1()), analyzer, null, 3, 1, 1, CATEGORY_FIELD, BODY_FIELD));\n      classifiers.add(new KNearestFuzzyClassifier(reader, new LMJelinekMercerSimilarity(0.3f), analyzer, null, 1, CATEGORY_FIELD, BODY_FIELD));\n      classifiers.add(new KNearestFuzzyClassifier(reader, new IBSimilarity(new DistributionLL(), new LambdaTTF(), new NormalizationH1()), analyzer, null, 1, CATEGORY_FIELD, BODY_FIELD));\n      classifiers.add(new KNearestFuzzyClassifier(reader, new ClassicSimilarity(), analyzer, null, 1, CATEGORY_FIELD, BODY_FIELD));\n      classifiers.add(new KNearestFuzzyClassifier(reader, new ClassicSimilarity(), analyzer, null, 3, CATEGORY_FIELD, BODY_FIELD));\n      classifiers.add(new KNearestFuzzyClassifier(reader, null, analyzer, null, 1, CATEGORY_FIELD, BODY_FIELD));\n      classifiers.add(new KNearestFuzzyClassifier(reader, null, analyzer, null, 3, CATEGORY_FIELD, BODY_FIELD));\n      classifiers.add(new KNearestFuzzyClassifier(reader, new AxiomaticF1EXP(), analyzer, null, 3, CATEGORY_FIELD, BODY_FIELD));\n      classifiers.add(new KNearestFuzzyClassifier(reader, new AxiomaticF1LOG(), analyzer, null, 3, CATEGORY_FIELD, BODY_FIELD));\n      classifiers.add(new BM25NBClassifier(reader, analyzer, null, CATEGORY_FIELD, BODY_FIELD));\n      classifiers.add(new CachingNaiveBayesClassifier(reader, analyzer, null, CATEGORY_FIELD, BODY_FIELD));\n      classifiers.add(new SimpleNaiveBayesClassifier(reader, analyzer, null, CATEGORY_FIELD, BODY_FIELD));\n\n      int maxdoc;\n\n      if (split) {\n        testReader = DirectoryReader.open(test);\n        maxdoc = testReader.maxDoc();\n      } else {\n        maxdoc = reader.maxDoc();\n      }\n\n      System.out.format(\"Starting evaluation on %d docs...%n\", maxdoc);\n\n      ExecutorService service = Executors.newCachedThreadPool();\n      List<Future<String>> futures = new LinkedList<>();\n      for (Classifier<BytesRef> classifier : classifiers) {\n        testClassifier(reader, startTime, testReader, service, futures, classifier);\n      }\n      for (Future<String> f : futures) {\n        System.out.println(f.get());\n      }\n\n      Thread.sleep(10000);\n      service.shutdown();\n\n    } finally {\n      if (reader != null) {\n        reader.close();\n      }\n      directory.close();\n      if (test != null) {\n        test.close();\n      }\n      if (train != null) {\n        train.close();\n      }\n      if (cv != null) {\n        cv.close();\n      }\n      if (testReader != null) {\n        testReader.close();\n      }\n\n      for (Classifier c : classifiers) {\n        if (c instanceof Closeable) {\n          ((Closeable) c).close();\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3b1c563070b3e39608e88ba0702a6b5ec9cd928e","date":1548321892,"type":3,"author":"Tommaso Teofili","isMerge":false,"pathNew":"lucene/classification/src/test/org/apache/lucene/classification/Test20NewsgroupsClassification#test20Newsgroups().mjava","pathOld":"lucene/classification/src/test/org/apache/lucene/classification/Test20NewsgroupsClassification#test20Newsgroups().mjava","sourceNew":"  @Test\n  public void test20Newsgroups() throws Exception {\n\n    String indexProperty = System.getProperty(\"index\");\n    if (indexProperty != null) {\n      try {\n        index = Boolean.valueOf(indexProperty);\n      } catch (Exception e) {\n        // ignore\n      }\n    }\n\n    String splitProperty = System.getProperty(\"split\");\n    if (splitProperty != null) {\n      try {\n        split = Boolean.valueOf(splitProperty);\n      } catch (Exception e) {\n        // ignore\n      }\n    }\n\n    Directory directory = newDirectory();\n    Directory cv = null;\n    Directory test = null;\n    Directory train = null;\n    IndexReader testReader = null;\n    if (split) {\n      cv = newDirectory();\n      test = newDirectory();\n      train = newDirectory();\n    }\n\n    IndexReader reader = null;\n    List<Classifier<BytesRef>> classifiers = new LinkedList<>();\n    try {\n      Analyzer analyzer = new StandardAnalyzer();\n      if (index) {\n\n        System.out.println(\"Indexing 20 Newsgroups...\");\n\n        long startIndex = System.currentTimeMillis();\n        IndexWriter indexWriter = new IndexWriter(directory, new IndexWriterConfig(analyzer));\n\n        Path indexDir = Paths.get(INDEX_DIR);\n        int docsIndexed = buildIndex(indexDir, indexWriter);\n\n        long endIndex = System.currentTimeMillis();\n        System.out.println(\"Indexed \" + docsIndexed + \" docs in \" + (endIndex - startIndex) / 1000 + \"s\");\n\n        indexWriter.close();\n\n      }\n\n      if (split && !index) {\n        reader = DirectoryReader.open(train);\n      } else {\n        reader = DirectoryReader.open(directory);\n      }\n\n      if (index && split) {\n        System.out.println(\"Splitting the index...\");\n\n        long startSplit = System.currentTimeMillis();\n        DatasetSplitter datasetSplitter = new DatasetSplitter(0.2, 0);\n        datasetSplitter.split(reader, train, test, cv, analyzer, false, CATEGORY_FIELD, BODY_FIELD, SUBJECT_FIELD, CATEGORY_FIELD);\n        reader.close();\n        reader = DirectoryReader.open(train); // using the train index from now on\n        long endSplit = System.currentTimeMillis();\n        System.out.println(\"Splitting done in \" + (endSplit - startSplit) / 1000 + \"s\");\n      }\n\n      classifiers.add(new KNearestNeighborClassifier(reader, new ClassicSimilarity(), analyzer, null, 1, 0, 0, CATEGORY_FIELD, BODY_FIELD));\n      classifiers.add(new KNearestNeighborClassifier(reader, null, analyzer, null, 1, 0, 0, CATEGORY_FIELD, BODY_FIELD));\n      classifiers.add(new KNearestNeighborClassifier(reader, new ClassicSimilarity(), analyzer, null, 3, 0, 0, CATEGORY_FIELD, BODY_FIELD));\n      classifiers.add(new KNearestNeighborClassifier(reader, new AxiomaticF1EXP(), analyzer, null, 3, 0, 0, CATEGORY_FIELD, BODY_FIELD));\n      classifiers.add(new KNearestNeighborClassifier(reader, new AxiomaticF1LOG(), analyzer, null, 3, 0, 0, CATEGORY_FIELD, BODY_FIELD));\n      classifiers.add(new KNearestNeighborClassifier(reader, new LMDirichletSimilarity(), analyzer, null, 3, 1, 1, CATEGORY_FIELD, BODY_FIELD));\n      classifiers.add(new KNearestNeighborClassifier(reader, new LMJelinekMercerSimilarity(0.3f), analyzer, null, 3, 1, 1, CATEGORY_FIELD, BODY_FIELD));\n      classifiers.add(new KNearestNeighborClassifier(reader, null, analyzer, null, 3, 1, 1, CATEGORY_FIELD, BODY_FIELD));\n      classifiers.add(new KNearestNeighborClassifier(reader, new DFRSimilarity(new BasicModelG(), new AfterEffectB(), new NormalizationH1()), analyzer, null, 3, 1, 1, CATEGORY_FIELD, BODY_FIELD));\n      classifiers.add(new KNearestNeighborClassifier(reader, new IBSimilarity(new DistributionSPL(), new LambdaDF(), new Normalization.NoNormalization()), analyzer, null, 3, 1, 1, CATEGORY_FIELD, BODY_FIELD));\n      classifiers.add(new KNearestNeighborClassifier(reader, new IBSimilarity(new DistributionLL(), new LambdaTTF(), new NormalizationH1()), analyzer, null, 3, 1, 1, CATEGORY_FIELD, BODY_FIELD));\n      classifiers.add(new KNearestFuzzyClassifier(reader, new LMJelinekMercerSimilarity(0.3f), analyzer, null, 1, CATEGORY_FIELD, BODY_FIELD));\n      classifiers.add(new KNearestFuzzyClassifier(reader, new IBSimilarity(new DistributionLL(), new LambdaTTF(), new NormalizationH1()), analyzer, null, 1, CATEGORY_FIELD, BODY_FIELD));\n      classifiers.add(new KNearestFuzzyClassifier(reader, new ClassicSimilarity(), analyzer, null, 1, CATEGORY_FIELD, BODY_FIELD));\n      classifiers.add(new KNearestFuzzyClassifier(reader, new ClassicSimilarity(), analyzer, null, 3, CATEGORY_FIELD, BODY_FIELD));\n      classifiers.add(new KNearestFuzzyClassifier(reader, null, analyzer, null, 1, CATEGORY_FIELD, BODY_FIELD));\n      classifiers.add(new KNearestFuzzyClassifier(reader, null, analyzer, null, 3, CATEGORY_FIELD, BODY_FIELD));\n      classifiers.add(new KNearestFuzzyClassifier(reader, new AxiomaticF1EXP(), analyzer, null, 3, CATEGORY_FIELD, BODY_FIELD));\n      classifiers.add(new KNearestFuzzyClassifier(reader, new AxiomaticF1LOG(), analyzer, null, 3, CATEGORY_FIELD, BODY_FIELD));\n      classifiers.add(new BM25NBClassifier(reader, analyzer, null, CATEGORY_FIELD, BODY_FIELD));\n      classifiers.add(new CachingNaiveBayesClassifier(reader, analyzer, null, CATEGORY_FIELD, BODY_FIELD));\n      classifiers.add(new SimpleNaiveBayesClassifier(reader, analyzer, null, CATEGORY_FIELD, BODY_FIELD));\n\n      int maxdoc;\n\n      if (split) {\n        testReader = DirectoryReader.open(test);\n        maxdoc = testReader.maxDoc();\n      } else {\n        maxdoc = reader.maxDoc();\n      }\n\n      System.out.println(\"Starting evaluation on \" + maxdoc + \" docs...\");\n\n      ExecutorService service = new ThreadPoolExecutor(1, TestUtil.nextInt(random(), 2, 6), Long.MAX_VALUE, TimeUnit.MILLISECONDS,\n          new LinkedBlockingQueue<>(),\n          new NamedThreadFactory(getClass().getName()));\n      List<Future<String>> futures = new LinkedList<>();\n      for (Classifier<BytesRef> classifier : classifiers) {\n        testClassifier(reader, testReader, service, futures, classifier);\n      }\n      for (Future<String> f : futures) {\n        System.out.println(f.get());\n      }\n\n      Thread.sleep(10000);\n      service.shutdown();\n\n    } finally {\n      if (reader != null) {\n        reader.close();\n      }\n      directory.close();\n      if (testReader != null) {\n        testReader.close();\n      }\n      if (test != null) {\n        test.close();\n      }\n      if (train != null) {\n        train.close();\n      }\n      if (cv != null) {\n        cv.close();\n      }\n\n      for (Classifier<BytesRef> c : classifiers) {\n        if (c instanceof Closeable) {\n          ((Closeable) c).close();\n        }\n      }\n    }\n  }\n\n","sourceOld":"  @Test\n  public void test20Newsgroups() throws Exception {\n\n    String indexProperty = System.getProperty(\"index\");\n    if (indexProperty != null) {\n      try {\n        index = Boolean.valueOf(indexProperty);\n      } catch (Exception e) {\n        // ignore\n      }\n    }\n\n    String splitProperty = System.getProperty(\"split\");\n    if (splitProperty != null) {\n      try {\n        split = Boolean.valueOf(splitProperty);\n      } catch (Exception e) {\n        // ignore\n      }\n    }\n\n    Path mainIndexPath = Paths.get(INDEX + \"/original\");\n    Directory directory = FSDirectory.open(mainIndexPath);\n    Path trainPath = Paths.get(INDEX + \"/train\");\n    Path testPath = Paths.get(INDEX + \"/test\");\n    Path cvPath = Paths.get(INDEX + \"/cv\");\n    FSDirectory cv = null;\n    FSDirectory test = null;\n    FSDirectory train = null;\n    IndexReader testReader = null;\n    if (split) {\n      cv = FSDirectory.open(cvPath);\n      test = FSDirectory.open(testPath);\n      train = FSDirectory.open(trainPath);\n    }\n\n    if (index) {\n      delete(mainIndexPath);\n      if (split) {\n        delete(trainPath, testPath, cvPath);\n      }\n    }\n\n    IndexReader reader = null;\n    List<Classifier<BytesRef>> classifiers = new LinkedList<>();\n    try {\n      Analyzer analyzer = new StandardAnalyzer();\n      if (index) {\n\n        System.out.println(\"Indexing 20 Newsgroups...\");\n\n        long startIndex = System.currentTimeMillis();\n        IndexWriter indexWriter = new IndexWriter(directory, new IndexWriterConfig(analyzer));\n\n        int docsIndexed = buildIndex(Paths.get(PATH_TO_20N).getParent(), indexWriter);\n\n        long endIndex = System.currentTimeMillis();\n        System.out.println(\"Indexed \" + docsIndexed + \" docs in \" + (endIndex - startIndex) / 1000 + \"s\");\n\n        indexWriter.close();\n\n      }\n\n      if (split && !index) {\n        reader = DirectoryReader.open(train);\n      } else {\n        reader = DirectoryReader.open(directory);\n      }\n\n      if (index && split) {\n        // split the index\n        System.out.println(\"Splitting the index...\");\n\n        long startSplit = System.currentTimeMillis();\n        DatasetSplitter datasetSplitter = new DatasetSplitter(0.2, 0);\n        datasetSplitter.split(reader, train, test, cv, analyzer, false, CATEGORY_FIELD, BODY_FIELD, SUBJECT_FIELD, CATEGORY_FIELD);\n        reader.close();\n        reader = DirectoryReader.open(train); // using the train index from now on\n        long endSplit = System.currentTimeMillis();\n        System.out.println(\"Splitting done in \" + (endSplit - startSplit) / 1000 + \"s\");\n      }\n\n      classifiers.add(new KNearestNeighborClassifier(reader, new ClassicSimilarity(), analyzer, null, 1, 0, 0, CATEGORY_FIELD, BODY_FIELD));\n      classifiers.add(new KNearestNeighborClassifier(reader, null, analyzer, null, 1, 0, 0, CATEGORY_FIELD, BODY_FIELD));\n      classifiers.add(new KNearestNeighborClassifier(reader, new ClassicSimilarity(), analyzer, null, 3, 0, 0, CATEGORY_FIELD, BODY_FIELD));\n      classifiers.add(new KNearestNeighborClassifier(reader, new AxiomaticF1EXP(), analyzer, null, 3, 0, 0, CATEGORY_FIELD, BODY_FIELD));\n      classifiers.add(new KNearestNeighborClassifier(reader, new AxiomaticF1LOG(), analyzer, null, 3, 0, 0, CATEGORY_FIELD, BODY_FIELD));\n      classifiers.add(new KNearestNeighborClassifier(reader, new LMDirichletSimilarity(), analyzer, null, 3, 1, 1, CATEGORY_FIELD, BODY_FIELD));\n      classifiers.add(new KNearestNeighborClassifier(reader, new LMJelinekMercerSimilarity(0.3f), analyzer, null, 3, 1, 1, CATEGORY_FIELD, BODY_FIELD));\n      classifiers.add(new KNearestNeighborClassifier(reader, null, analyzer, null, 3, 1, 1, CATEGORY_FIELD, BODY_FIELD));\n      classifiers.add(new KNearestNeighborClassifier(reader, new DFRSimilarity(new BasicModelG(), new AfterEffectB(), new NormalizationH1()), analyzer, null, 3, 1, 1, CATEGORY_FIELD, BODY_FIELD));\n      classifiers.add(new KNearestNeighborClassifier(reader, new IBSimilarity(new DistributionSPL(), new LambdaDF(), new Normalization.NoNormalization()), analyzer, null, 3, 1, 1, CATEGORY_FIELD, BODY_FIELD));\n      classifiers.add(new KNearestNeighborClassifier(reader, new IBSimilarity(new DistributionLL(), new LambdaTTF(), new NormalizationH1()), analyzer, null, 3, 1, 1, CATEGORY_FIELD, BODY_FIELD));\n      classifiers.add(new KNearestFuzzyClassifier(reader, new LMJelinekMercerSimilarity(0.3f), analyzer, null, 1, CATEGORY_FIELD, BODY_FIELD));\n      classifiers.add(new KNearestFuzzyClassifier(reader, new IBSimilarity(new DistributionLL(), new LambdaTTF(), new NormalizationH1()), analyzer, null, 1, CATEGORY_FIELD, BODY_FIELD));\n      classifiers.add(new KNearestFuzzyClassifier(reader, new ClassicSimilarity(), analyzer, null, 1, CATEGORY_FIELD, BODY_FIELD));\n      classifiers.add(new KNearestFuzzyClassifier(reader, new ClassicSimilarity(), analyzer, null, 3, CATEGORY_FIELD, BODY_FIELD));\n      classifiers.add(new KNearestFuzzyClassifier(reader, null, analyzer, null, 1, CATEGORY_FIELD, BODY_FIELD));\n      classifiers.add(new KNearestFuzzyClassifier(reader, null, analyzer, null, 3, CATEGORY_FIELD, BODY_FIELD));\n      classifiers.add(new KNearestFuzzyClassifier(reader, new AxiomaticF1EXP(), analyzer, null, 3, CATEGORY_FIELD, BODY_FIELD));\n      classifiers.add(new KNearestFuzzyClassifier(reader, new AxiomaticF1LOG(), analyzer, null, 3, CATEGORY_FIELD, BODY_FIELD));\n      classifiers.add(new BM25NBClassifier(reader, analyzer, null, CATEGORY_FIELD, BODY_FIELD));\n      classifiers.add(new CachingNaiveBayesClassifier(reader, analyzer, null, CATEGORY_FIELD, BODY_FIELD));\n      classifiers.add(new SimpleNaiveBayesClassifier(reader, analyzer, null, CATEGORY_FIELD, BODY_FIELD));\n\n      int maxdoc;\n\n      if (split) {\n        testReader = DirectoryReader.open(test);\n        maxdoc = testReader.maxDoc();\n      } else {\n        maxdoc = reader.maxDoc();\n      }\n\n      System.out.println(\"Starting evaluation on \" + maxdoc + \" docs...\");\n\n      ExecutorService service = new ThreadPoolExecutor(1, TestUtil.nextInt(random(), 2, 6), Long.MAX_VALUE, TimeUnit.MILLISECONDS,\n          new LinkedBlockingQueue<>(),\n          new NamedThreadFactory(getClass().getName()));\n      List<Future<String>> futures = new LinkedList<>();\n      for (Classifier<BytesRef> classifier : classifiers) {\n        testClassifier(reader, testReader, service, futures, classifier);\n      }\n      for (Future<String> f : futures) {\n        System.out.println(f.get());\n      }\n\n      Thread.sleep(10000);\n      service.shutdown();\n\n    } finally {\n      if (reader != null) {\n        reader.close();\n      }\n      directory.close();\n      if (test != null) {\n        test.close();\n      }\n      if (train != null) {\n        train.close();\n      }\n      if (cv != null) {\n        cv.close();\n      }\n      if (testReader != null) {\n        testReader.close();\n      }\n\n      for (Classifier<BytesRef> c : classifiers) {\n        if (c instanceof Closeable) {\n          ((Closeable) c).close();\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"52ec154a31cf63bc47d2cc0b49e171a4e75aa99d","date":1548322018,"type":0,"author":"Tommaso Teofili","isMerge":true,"pathNew":"lucene/classification/src/test/org/apache/lucene/classification/Test20NewsgroupsClassification#test20Newsgroups().mjava","pathOld":"/dev/null","sourceNew":"  @Test\n  public void test20Newsgroups() throws Exception {\n\n    String indexProperty = System.getProperty(\"index\");\n    if (indexProperty != null) {\n      try {\n        index = Boolean.valueOf(indexProperty);\n      } catch (Exception e) {\n        // ignore\n      }\n    }\n\n    String splitProperty = System.getProperty(\"split\");\n    if (splitProperty != null) {\n      try {\n        split = Boolean.valueOf(splitProperty);\n      } catch (Exception e) {\n        // ignore\n      }\n    }\n\n    Directory directory = newDirectory();\n    Directory cv = null;\n    Directory test = null;\n    Directory train = null;\n    IndexReader testReader = null;\n    if (split) {\n      cv = newDirectory();\n      test = newDirectory();\n      train = newDirectory();\n    }\n\n    IndexReader reader = null;\n    List<Classifier<BytesRef>> classifiers = new LinkedList<>();\n    try {\n      Analyzer analyzer = new StandardAnalyzer();\n      if (index) {\n\n        System.out.println(\"Indexing 20 Newsgroups...\");\n\n        long startIndex = System.currentTimeMillis();\n        IndexWriter indexWriter = new IndexWriter(directory, new IndexWriterConfig(analyzer));\n\n        Path indexDir = Paths.get(INDEX_DIR);\n        int docsIndexed = buildIndex(indexDir, indexWriter);\n\n        long endIndex = System.currentTimeMillis();\n        System.out.println(\"Indexed \" + docsIndexed + \" docs in \" + (endIndex - startIndex) / 1000 + \"s\");\n\n        indexWriter.close();\n\n      }\n\n      if (split && !index) {\n        reader = DirectoryReader.open(train);\n      } else {\n        reader = DirectoryReader.open(directory);\n      }\n\n      if (index && split) {\n        System.out.println(\"Splitting the index...\");\n\n        long startSplit = System.currentTimeMillis();\n        DatasetSplitter datasetSplitter = new DatasetSplitter(0.2, 0);\n        datasetSplitter.split(reader, train, test, cv, analyzer, false, CATEGORY_FIELD, BODY_FIELD, SUBJECT_FIELD, CATEGORY_FIELD);\n        reader.close();\n        reader = DirectoryReader.open(train); // using the train index from now on\n        long endSplit = System.currentTimeMillis();\n        System.out.println(\"Splitting done in \" + (endSplit - startSplit) / 1000 + \"s\");\n      }\n\n      classifiers.add(new KNearestNeighborClassifier(reader, new ClassicSimilarity(), analyzer, null, 1, 0, 0, CATEGORY_FIELD, BODY_FIELD));\n      classifiers.add(new KNearestNeighborClassifier(reader, null, analyzer, null, 1, 0, 0, CATEGORY_FIELD, BODY_FIELD));\n      classifiers.add(new KNearestNeighborClassifier(reader, new ClassicSimilarity(), analyzer, null, 3, 0, 0, CATEGORY_FIELD, BODY_FIELD));\n      classifiers.add(new KNearestNeighborClassifier(reader, new AxiomaticF1EXP(), analyzer, null, 3, 0, 0, CATEGORY_FIELD, BODY_FIELD));\n      classifiers.add(new KNearestNeighborClassifier(reader, new AxiomaticF1LOG(), analyzer, null, 3, 0, 0, CATEGORY_FIELD, BODY_FIELD));\n      classifiers.add(new KNearestNeighborClassifier(reader, new LMDirichletSimilarity(), analyzer, null, 3, 1, 1, CATEGORY_FIELD, BODY_FIELD));\n      classifiers.add(new KNearestNeighborClassifier(reader, new LMJelinekMercerSimilarity(0.3f), analyzer, null, 3, 1, 1, CATEGORY_FIELD, BODY_FIELD));\n      classifiers.add(new KNearestNeighborClassifier(reader, null, analyzer, null, 3, 1, 1, CATEGORY_FIELD, BODY_FIELD));\n      classifiers.add(new KNearestNeighborClassifier(reader, new DFRSimilarity(new BasicModelG(), new AfterEffectB(), new NormalizationH1()), analyzer, null, 3, 1, 1, CATEGORY_FIELD, BODY_FIELD));\n      classifiers.add(new KNearestNeighborClassifier(reader, new IBSimilarity(new DistributionSPL(), new LambdaDF(), new Normalization.NoNormalization()), analyzer, null, 3, 1, 1, CATEGORY_FIELD, BODY_FIELD));\n      classifiers.add(new KNearestNeighborClassifier(reader, new IBSimilarity(new DistributionLL(), new LambdaTTF(), new NormalizationH1()), analyzer, null, 3, 1, 1, CATEGORY_FIELD, BODY_FIELD));\n      classifiers.add(new KNearestFuzzyClassifier(reader, new LMJelinekMercerSimilarity(0.3f), analyzer, null, 1, CATEGORY_FIELD, BODY_FIELD));\n      classifiers.add(new KNearestFuzzyClassifier(reader, new IBSimilarity(new DistributionLL(), new LambdaTTF(), new NormalizationH1()), analyzer, null, 1, CATEGORY_FIELD, BODY_FIELD));\n      classifiers.add(new KNearestFuzzyClassifier(reader, new ClassicSimilarity(), analyzer, null, 1, CATEGORY_FIELD, BODY_FIELD));\n      classifiers.add(new KNearestFuzzyClassifier(reader, new ClassicSimilarity(), analyzer, null, 3, CATEGORY_FIELD, BODY_FIELD));\n      classifiers.add(new KNearestFuzzyClassifier(reader, null, analyzer, null, 1, CATEGORY_FIELD, BODY_FIELD));\n      classifiers.add(new KNearestFuzzyClassifier(reader, null, analyzer, null, 3, CATEGORY_FIELD, BODY_FIELD));\n      classifiers.add(new KNearestFuzzyClassifier(reader, new AxiomaticF1EXP(), analyzer, null, 3, CATEGORY_FIELD, BODY_FIELD));\n      classifiers.add(new KNearestFuzzyClassifier(reader, new AxiomaticF1LOG(), analyzer, null, 3, CATEGORY_FIELD, BODY_FIELD));\n      classifiers.add(new BM25NBClassifier(reader, analyzer, null, CATEGORY_FIELD, BODY_FIELD));\n      classifiers.add(new CachingNaiveBayesClassifier(reader, analyzer, null, CATEGORY_FIELD, BODY_FIELD));\n      classifiers.add(new SimpleNaiveBayesClassifier(reader, analyzer, null, CATEGORY_FIELD, BODY_FIELD));\n\n      int maxdoc;\n\n      if (split) {\n        testReader = DirectoryReader.open(test);\n        maxdoc = testReader.maxDoc();\n      } else {\n        maxdoc = reader.maxDoc();\n      }\n\n      System.out.println(\"Starting evaluation on \" + maxdoc + \" docs...\");\n\n      ExecutorService service = new ThreadPoolExecutor(1, TestUtil.nextInt(random(), 2, 6), Long.MAX_VALUE, TimeUnit.MILLISECONDS,\n          new LinkedBlockingQueue<>(),\n          new NamedThreadFactory(getClass().getName()));\n      List<Future<String>> futures = new LinkedList<>();\n      for (Classifier<BytesRef> classifier : classifiers) {\n        testClassifier(reader, testReader, service, futures, classifier);\n      }\n      for (Future<String> f : futures) {\n        System.out.println(f.get());\n      }\n\n      Thread.sleep(10000);\n      service.shutdown();\n\n    } finally {\n      if (reader != null) {\n        reader.close();\n      }\n      directory.close();\n      if (testReader != null) {\n        testReader.close();\n      }\n      if (test != null) {\n        test.close();\n      }\n      if (train != null) {\n        train.close();\n      }\n      if (cv != null) {\n        cv.close();\n      }\n\n      for (Classifier<BytesRef> c : classifiers) {\n        if (c instanceof Closeable) {\n          ((Closeable) c).close();\n        }\n      }\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"52ec154a31cf63bc47d2cc0b49e171a4e75aa99d":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","3b1c563070b3e39608e88ba0702a6b5ec9cd928e"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"887f38f1943e88ac7f468b18be6f5d42b4a70add":["33bfee30277584028170135002def66f9d57732b"],"33bfee30277584028170135002def66f9d57732b":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"3b1c563070b3e39608e88ba0702a6b5ec9cd928e":["887f38f1943e88ac7f468b18be6f5d42b4a70add"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["52ec154a31cf63bc47d2cc0b49e171a4e75aa99d"]},"commit2Childs":{"52ec154a31cf63bc47d2cc0b49e171a4e75aa99d":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["52ec154a31cf63bc47d2cc0b49e171a4e75aa99d","33bfee30277584028170135002def66f9d57732b"],"887f38f1943e88ac7f468b18be6f5d42b4a70add":["3b1c563070b3e39608e88ba0702a6b5ec9cd928e"],"33bfee30277584028170135002def66f9d57732b":["887f38f1943e88ac7f468b18be6f5d42b4a70add"],"3b1c563070b3e39608e88ba0702a6b5ec9cd928e":["52ec154a31cf63bc47d2cc0b49e171a4e75aa99d"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}