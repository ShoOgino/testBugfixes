{"path":"solr/core/src/java/org/apache/solr/cloud/Assign#getNodesForNewShard(ClusterState,String,String,int,String,CoreContainer).mjava","commits":[{"id":"ec4fc24ecd353171e03bd016c1681cd97476015f","date":1432214672,"type":1,"author":"Noble Paul","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/Assign#getNodesForNewShard(ClusterState,String,String,int,String,CoreContainer).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/Assign#getNodesForNewShard(ClusterState,String,int,int,int,String).mjava","sourceNew":"  public static List<Node> getNodesForNewShard(ClusterState clusterState, String collectionName,String shard,int numberOfNodes,\n                                                    String createNodeSetStr, CoreContainer cc) {\n    DocCollection coll = clusterState.getCollection(collectionName);\n    Integer maxShardsPerNode = coll.getInt(MAX_SHARDS_PER_NODE, 1);\n    Integer repFactor = coll.getInt(REPLICATION_FACTOR, 1);\n    int numSlices = coll.getSlices().size();\n    List<String> createNodeList = createNodeSetStr  == null ? null: StrUtils.splitSmart(createNodeSetStr, \",\", true);\n\n    Set<String> nodes = clusterState.getLiveNodes();\n\n    List<String> nodeList = new ArrayList<>(nodes.size());\n    nodeList.addAll(nodes);\n    if (createNodeList != null) nodeList.retainAll(createNodeList);\n\n\n    HashMap<String,Node> nodeNameVsShardCount =  new HashMap<>();\n    for (String s : nodeList) nodeNameVsShardCount.put(s,new Node(s));\n    for (String s : clusterState.getCollections()) {\n      DocCollection c = clusterState.getCollection(s);\n      //identify suitable nodes  by checking the no:of cores in each of them\n      for (Slice slice : c.getSlices()) {\n        Collection<Replica> replicas = slice.getReplicas();\n        for (Replica replica : replicas) {\n          Node count = nodeNameVsShardCount.get(replica.getNodeName());\n          if (count != null) {\n            count.totalNodes++;\n            if (s.equals(collectionName)) {\n              count.thisCollectionNodes++;\n              if (count.thisCollectionNodes >= maxShardsPerNode) nodeNameVsShardCount.remove(replica.getNodeName());\n            }\n          }\n        }\n      }\n    }\n\n    if (nodeNameVsShardCount.size() <= 0) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName\n          + \". No live Solr-instances\" + ((createNodeList != null)?\" among Solr-instances specified in \" + CREATE_NODE_SET + \":\" + createNodeSetStr:\"\"));\n    }\n\n    if (repFactor > nodeNameVsShardCount.size()) {\n      log.warn(\"Specified \"\n          + ZkStateReader.REPLICATION_FACTOR\n          + \" of \"\n          + repFactor\n          + \" on collection \"\n          + collectionName\n          + \" is higher than or equal to the number of Solr instances currently live or part of your \" + CREATE_NODE_SET + \"(\"\n          + nodeList.size()\n          + \"). It's unusual to run two replica of the same slice on the same Solr-instance.\");\n    }\n\n    int maxCoresAllowedToCreate = maxShardsPerNode * nodeList.size();\n    int requestedCoresToCreate = numSlices * repFactor;\n    int minCoresToCreate = requestedCoresToCreate;\n    if (maxCoresAllowedToCreate < minCoresToCreate) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Cannot create shards \" + collectionName + \". Value of \"\n          + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n          + \", and the number of live nodes is \" + nodeList.size()\n          + \". This allows a maximum of \" + maxCoresAllowedToCreate\n          + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n          + \" and value of \" + ZkStateReader.REPLICATION_FACTOR + \" is \" + repFactor\n          + \". This requires \" + requestedCoresToCreate\n          + \" shards to be created (higher than the allowed number)\");\n    }\n\n    List l = (List) coll.get(DocCollection.RULE);\n    if(l != null) {\n      ArrayList<Rule> rules = new ArrayList<>();\n      for (Object o : l) rules.add(new Rule((Map) o));\n      Map<String, Map<String,Integer>> shardVsNodes = new LinkedHashMap<>();\n      for (Slice slice : coll.getSlices()) {\n        LinkedHashMap<String, Integer> n = new LinkedHashMap<>();\n        shardVsNodes.put(slice.getName(), n);\n        for (Replica replica : slice.getReplicas()) {\n          Integer count = n.get(replica.getNodeName());\n          if(count == null) count = 0;\n          n.put(replica.getNodeName(),++count);\n        }\n      }\n      List snitches = (List) coll.get(DocCollection.SNITCH);\n      List<String> nodesList = createNodeList == null ?\n          new ArrayList<>(clusterState.getLiveNodes()) :\n          createNodeList ;\n      Map<ReplicaAssigner.Position, String> positions = new ReplicaAssigner(\n          rules,\n          Collections.singletonMap(shard, numberOfNodes),\n          snitches,\n          shardVsNodes,\n          nodesList, cc, clusterState).getNodeMappings();\n\n      List<Node> n = new ArrayList<>();\n      for (String s : positions.values()) n.add(new Node(s));\n      return n;\n\n    }else {\n\n      ArrayList<Node> sortedNodeList = new ArrayList<>(nodeNameVsShardCount.values());\n      Collections.sort(sortedNodeList, new Comparator<Node>() {\n        @Override\n        public int compare(Node x, Node y) {\n          return (x.weight() < y.weight()) ? -1 : ((x.weight() == y.weight()) ? 0 : 1);\n        }\n      });\n      return sortedNodeList;\n    }\n  }\n\n","sourceOld":"  public static ArrayList<Node> getNodesForNewShard(ClusterState clusterState, String collectionName, int numSlices, int maxShardsPerNode, int repFactor, String createNodeSetStr) {\n    List<String> createNodeList = createNodeSetStr  == null ? null: StrUtils.splitSmart(createNodeSetStr, \",\", true);\n\n\n    Set<String> nodes = clusterState.getLiveNodes();\n\n    List<String> nodeList = new ArrayList<>(nodes.size());\n    nodeList.addAll(nodes);\n    if (createNodeList != null) nodeList.retainAll(createNodeList);\n\n\n    HashMap<String,Node> nodeNameVsShardCount =  new HashMap<>();\n    for (String s : nodeList) nodeNameVsShardCount.put(s,new Node(s));\n    for (String s : clusterState.getCollections()) {\n      DocCollection c = clusterState.getCollection(s);\n      //identify suitable nodes  by checking the no:of cores in each of them\n      for (Slice slice : c.getSlices()) {\n        Collection<Replica> replicas = slice.getReplicas();\n        for (Replica replica : replicas) {\n          Node count = nodeNameVsShardCount.get(replica.getNodeName());\n          if (count != null) {\n            count.totalNodes++;\n            if (s.equals(collectionName)) {\n              count.thisCollectionNodes++;\n              if (count.thisCollectionNodes >= maxShardsPerNode) nodeNameVsShardCount.remove(replica.getNodeName());\n            }\n          }\n        }\n      }\n    }\n\n    if (nodeNameVsShardCount.size() <= 0) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName\n          + \". No live Solr-instances\" + ((createNodeList != null)?\" among Solr-instances specified in \" + CREATE_NODE_SET + \":\" + createNodeSetStr:\"\"));\n    }\n\n    if (repFactor > nodeNameVsShardCount.size()) {\n      log.warn(\"Specified \"\n          + ZkStateReader.REPLICATION_FACTOR\n          + \" of \"\n          + repFactor\n          + \" on collection \"\n          + collectionName\n          + \" is higher than or equal to the number of Solr instances currently live or part of your \" + CREATE_NODE_SET + \"(\"\n          + nodeList.size()\n          + \"). It's unusual to run two replica of the same slice on the same Solr-instance.\");\n    }\n\n    int maxCoresAllowedToCreate = maxShardsPerNode * nodeList.size();\n    int requestedCoresToCreate = numSlices * repFactor;\n    int minCoresToCreate = requestedCoresToCreate;\n    if (maxCoresAllowedToCreate < minCoresToCreate) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Cannot create shards \" + collectionName + \". Value of \"\n          + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n          + \", and the number of live nodes is \" + nodeList.size()\n          + \". This allows a maximum of \" + maxCoresAllowedToCreate\n          + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n          + \" and value of \" + ZkStateReader.REPLICATION_FACTOR + \" is \" + repFactor\n          + \". This requires \" + requestedCoresToCreate\n          + \" shards to be created (higher than the allowed number)\");\n    }\n\n    ArrayList<Node> sortedNodeList = new ArrayList<>(nodeNameVsShardCount.values());\n    Collections.sort(sortedNodeList, new Comparator<Node>() {\n      @Override\n      public int compare(Node x, Node y) {\n        return (x.weight() < y.weight()) ? -1 : ((x.weight() == y.weight()) ? 0 : 1);\n      }\n    });\n    return sortedNodeList;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3fd3cdfbce4b551bb8ca4678682a5a891d0890ca","date":1436588269,"type":4,"author":"Erick Erickson","isMerge":false,"pathNew":"/dev/null","pathOld":"solr/core/src/java/org/apache/solr/cloud/Assign#getNodesForNewShard(ClusterState,String,String,int,String,CoreContainer).mjava","sourceNew":null,"sourceOld":"  public static List<Node> getNodesForNewShard(ClusterState clusterState, String collectionName,String shard,int numberOfNodes,\n                                                    String createNodeSetStr, CoreContainer cc) {\n    DocCollection coll = clusterState.getCollection(collectionName);\n    Integer maxShardsPerNode = coll.getInt(MAX_SHARDS_PER_NODE, 1);\n    Integer repFactor = coll.getInt(REPLICATION_FACTOR, 1);\n    int numSlices = coll.getSlices().size();\n    List<String> createNodeList = createNodeSetStr  == null ? null: StrUtils.splitSmart(createNodeSetStr, \",\", true);\n\n    Set<String> nodes = clusterState.getLiveNodes();\n\n    List<String> nodeList = new ArrayList<>(nodes.size());\n    nodeList.addAll(nodes);\n    if (createNodeList != null) nodeList.retainAll(createNodeList);\n\n\n    HashMap<String,Node> nodeNameVsShardCount =  new HashMap<>();\n    for (String s : nodeList) nodeNameVsShardCount.put(s,new Node(s));\n    for (String s : clusterState.getCollections()) {\n      DocCollection c = clusterState.getCollection(s);\n      //identify suitable nodes  by checking the no:of cores in each of them\n      for (Slice slice : c.getSlices()) {\n        Collection<Replica> replicas = slice.getReplicas();\n        for (Replica replica : replicas) {\n          Node count = nodeNameVsShardCount.get(replica.getNodeName());\n          if (count != null) {\n            count.totalNodes++;\n            if (s.equals(collectionName)) {\n              count.thisCollectionNodes++;\n              if (count.thisCollectionNodes >= maxShardsPerNode) nodeNameVsShardCount.remove(replica.getNodeName());\n            }\n          }\n        }\n      }\n    }\n\n    if (nodeNameVsShardCount.size() <= 0) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Cannot create collection \" + collectionName\n          + \". No live Solr-instances\" + ((createNodeList != null)?\" among Solr-instances specified in \" + CREATE_NODE_SET + \":\" + createNodeSetStr:\"\"));\n    }\n\n    if (repFactor > nodeNameVsShardCount.size()) {\n      log.warn(\"Specified \"\n          + ZkStateReader.REPLICATION_FACTOR\n          + \" of \"\n          + repFactor\n          + \" on collection \"\n          + collectionName\n          + \" is higher than or equal to the number of Solr instances currently live or part of your \" + CREATE_NODE_SET + \"(\"\n          + nodeList.size()\n          + \"). It's unusual to run two replica of the same slice on the same Solr-instance.\");\n    }\n\n    int maxCoresAllowedToCreate = maxShardsPerNode * nodeList.size();\n    int requestedCoresToCreate = numSlices * repFactor;\n    int minCoresToCreate = requestedCoresToCreate;\n    if (maxCoresAllowedToCreate < minCoresToCreate) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Cannot create shards \" + collectionName + \". Value of \"\n          + MAX_SHARDS_PER_NODE + \" is \" + maxShardsPerNode\n          + \", and the number of live nodes is \" + nodeList.size()\n          + \". This allows a maximum of \" + maxCoresAllowedToCreate\n          + \" to be created. Value of \" + NUM_SLICES + \" is \" + numSlices\n          + \" and value of \" + ZkStateReader.REPLICATION_FACTOR + \" is \" + repFactor\n          + \". This requires \" + requestedCoresToCreate\n          + \" shards to be created (higher than the allowed number)\");\n    }\n\n    List l = (List) coll.get(DocCollection.RULE);\n    if(l != null) {\n      ArrayList<Rule> rules = new ArrayList<>();\n      for (Object o : l) rules.add(new Rule((Map) o));\n      Map<String, Map<String,Integer>> shardVsNodes = new LinkedHashMap<>();\n      for (Slice slice : coll.getSlices()) {\n        LinkedHashMap<String, Integer> n = new LinkedHashMap<>();\n        shardVsNodes.put(slice.getName(), n);\n        for (Replica replica : slice.getReplicas()) {\n          Integer count = n.get(replica.getNodeName());\n          if(count == null) count = 0;\n          n.put(replica.getNodeName(),++count);\n        }\n      }\n      List snitches = (List) coll.get(DocCollection.SNITCH);\n      List<String> nodesList = createNodeList == null ?\n          new ArrayList<>(clusterState.getLiveNodes()) :\n          createNodeList ;\n      Map<ReplicaAssigner.Position, String> positions = new ReplicaAssigner(\n          rules,\n          Collections.singletonMap(shard, numberOfNodes),\n          snitches,\n          shardVsNodes,\n          nodesList, cc, clusterState).getNodeMappings();\n\n      List<Node> n = new ArrayList<>();\n      for (String s : positions.values()) n.add(new Node(s));\n      return n;\n\n    }else {\n\n      ArrayList<Node> sortedNodeList = new ArrayList<>(nodeNameVsShardCount.values());\n      Collections.sort(sortedNodeList, new Comparator<Node>() {\n        @Override\n        public int compare(Node x, Node y) {\n          return (x.weight() < y.weight()) ? -1 : ((x.weight() == y.weight()) ? 0 : 1);\n        }\n      });\n      return sortedNodeList;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"ec4fc24ecd353171e03bd016c1681cd97476015f":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"3fd3cdfbce4b551bb8ca4678682a5a891d0890ca":["ec4fc24ecd353171e03bd016c1681cd97476015f"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["3fd3cdfbce4b551bb8ca4678682a5a891d0890ca"]},"commit2Childs":{"ec4fc24ecd353171e03bd016c1681cd97476015f":["3fd3cdfbce4b551bb8ca4678682a5a891d0890ca"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["ec4fc24ecd353171e03bd016c1681cd97476015f"],"3fd3cdfbce4b551bb8ca4678682a5a891d0890ca":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}