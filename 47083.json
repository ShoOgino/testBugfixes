{"path":"lucene/sandbox/src/test/org/apache/lucene/search/BaseRangeFieldQueryTestCase#verify(Box[][]).mjava","commits":[{"id":"05f4c28bc6a6df30868753f35eb802cbff28ce5c","date":1469068146,"type":0,"author":"Nicholas Knize","isMerge":false,"pathNew":"lucene/sandbox/src/test/org/apache/lucene/search/BaseRangeFieldQueryTestCase#verify(Box[][]).mjava","pathOld":"/dev/null","sourceNew":"  private void verify(Box[][] boxes) throws Exception {\n    IndexWriterConfig iwc = newIndexWriterConfig();\n    // Else seeds may not reproduce:\n    iwc.setMergeScheduler(new SerialMergeScheduler());\n    // Else we can get O(N^2) merging\n    int mbd = iwc.getMaxBufferedDocs();\n    if (mbd != -1 && mbd < boxes.length/100) {\n      iwc.setMaxBufferedDocs(boxes.length/100);\n    }\n    Directory dir;\n    if (boxes.length > 50000) {\n      dir = newFSDirectory(createTempDir(getClass().getSimpleName()));\n    } else {\n      dir = newDirectory();\n    }\n\n    Set<Integer> deleted = new HashSet<>();\n    IndexWriter w = new IndexWriter(dir, iwc);\n    for (int id=0; id < boxes.length; ++id) {\n      Document doc = new Document();\n      doc.add(newStringField(\"id\", \"\"+id, Field.Store.NO));\n      doc.add(new NumericDocValuesField(\"id\", id));\n      if (Double.isNaN(boxes[id][0].min[0]) == false) {\n        for (int n=0; n<boxes[id].length; ++n) {\n          doc.add(newRangeField(boxes[id][n].min, boxes[id][n].max));\n        }\n      }\n      w.addDocument(doc);\n      if (id > 0 && random().nextInt(100) == 1) {\n        int idToDelete = random().nextInt(id);\n        w.deleteDocuments(new Term(\"id\", \"\"+idToDelete));\n        deleted.add(idToDelete);\n        if (VERBOSE) {\n          System.out.println(\"  delete id=\" + idToDelete);\n        }\n      }\n    }\n\n    if (random().nextBoolean()) {\n      w.forceMerge(1);\n    }\n    final IndexReader r = DirectoryReader.open(w);\n    w.close();\n    IndexSearcher s = newSearcher(r);\n\n    int dimensions = boxes[0][0].min.length;\n    int iters = atLeast(25);\n    NumericDocValues docIDToID = MultiDocValues.getNumericValues(r, \"id\");\n    Bits liveDocs = MultiFields.getLiveDocs(s.getIndexReader());\n    int maxDoc = s.getIndexReader().maxDoc();\n\n    for (int iter=0; iter<iters; ++iter) {\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: iter=\" + iter + \" s=\" + s);\n      }\n\n      // occasionally test open ended bounding boxes\n      Box queryBox = nextBox(dimensions);\n      int rv = random().nextInt(3);\n      Query query;\n      Box.QueryType queryType;\n      if (rv == 0) {\n        queryType = Box.QueryType.INTERSECTS;\n        query = newIntersectsQuery(queryBox.min, queryBox.max);\n      } else if (rv == 1)  {\n        queryType = Box.QueryType.CONTAINS;\n        query = newContainsQuery(queryBox.min, queryBox.max);\n      } else {\n        queryType = Box.QueryType.WITHIN;\n        query = newWithinQuery(queryBox.min, queryBox.max);\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  query=\" + query);\n      }\n\n      final FixedBitSet hits = new FixedBitSet(maxDoc);\n      s.search(query, new SimpleCollector() {\n        private int docBase;\n\n        @Override\n        public void collect(int doc) {\n          hits.set(docBase + doc);\n        }\n\n        @Override\n        protected void doSetNextReader(LeafReaderContext context) throws IOException {\n          docBase = context.docBase;\n        }\n\n        @Override\n        public boolean needsScores() { return false; }\n      });\n\n      for (int docID=0; docID<maxDoc; ++docID) {\n        int id = (int) docIDToID.get(docID);\n        boolean expected;\n        if (liveDocs != null && liveDocs.get(docID) == false) {\n          // document is deleted\n          expected = false;\n        } else if (Double.isNaN(boxes[id][0].min[0])) {\n          expected = false;\n        } else {\n          expected = expectedResult(queryBox, boxes[id], queryType);\n        }\n\n        if (hits.get(docID) != expected) {\n          StringBuilder b = new StringBuilder();\n          if (expected == true) {\n            b.append(\"FAILS: id=\" + id + (boxes[id].length > 1 ? \" (MultiValue) \" : \" \") + \"should match but did not\\n\");\n          } else {\n            b.append(\"FAIL: id=\" + id + \" should not match but did\\n\");\n          }\n          b.append(\" queryBox=\" + queryBox + \"\\n\");\n          b.append(\" box\" + ((boxes[id].length > 1) ? \"es=\" : \"=\" ) + boxes[id][0]);\n          for (int n=1; n<boxes[id].length; ++n) {\n            b.append(\", \");\n            b.append(boxes[id][n]);\n          }\n          b.append(\"\\n queryType=\" + queryType + \"\\n\");\n          b.append(\" deleted?=\" + (liveDocs != null && liveDocs.get(docID) == false));\n          fail(\"wrong hit (first of possibly more):\\n\\n\" + b);\n        }\n      }\n    }\n    IOUtils.close(r, dir);\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3c738d774d160362ecfdc9887a5fa4beb421872b","date":1469112991,"type":0,"author":"Noble Paul","isMerge":true,"pathNew":"lucene/sandbox/src/test/org/apache/lucene/search/BaseRangeFieldQueryTestCase#verify(Box[][]).mjava","pathOld":"/dev/null","sourceNew":"  private void verify(Box[][] boxes) throws Exception {\n    IndexWriterConfig iwc = newIndexWriterConfig();\n    // Else seeds may not reproduce:\n    iwc.setMergeScheduler(new SerialMergeScheduler());\n    // Else we can get O(N^2) merging\n    int mbd = iwc.getMaxBufferedDocs();\n    if (mbd != -1 && mbd < boxes.length/100) {\n      iwc.setMaxBufferedDocs(boxes.length/100);\n    }\n    Directory dir;\n    if (boxes.length > 50000) {\n      dir = newFSDirectory(createTempDir(getClass().getSimpleName()));\n    } else {\n      dir = newDirectory();\n    }\n\n    Set<Integer> deleted = new HashSet<>();\n    IndexWriter w = new IndexWriter(dir, iwc);\n    for (int id=0; id < boxes.length; ++id) {\n      Document doc = new Document();\n      doc.add(newStringField(\"id\", \"\"+id, Field.Store.NO));\n      doc.add(new NumericDocValuesField(\"id\", id));\n      if (Double.isNaN(boxes[id][0].min[0]) == false) {\n        for (int n=0; n<boxes[id].length; ++n) {\n          doc.add(newRangeField(boxes[id][n].min, boxes[id][n].max));\n        }\n      }\n      w.addDocument(doc);\n      if (id > 0 && random().nextInt(100) == 1) {\n        int idToDelete = random().nextInt(id);\n        w.deleteDocuments(new Term(\"id\", \"\"+idToDelete));\n        deleted.add(idToDelete);\n        if (VERBOSE) {\n          System.out.println(\"  delete id=\" + idToDelete);\n        }\n      }\n    }\n\n    if (random().nextBoolean()) {\n      w.forceMerge(1);\n    }\n    final IndexReader r = DirectoryReader.open(w);\n    w.close();\n    IndexSearcher s = newSearcher(r);\n\n    int dimensions = boxes[0][0].min.length;\n    int iters = atLeast(25);\n    NumericDocValues docIDToID = MultiDocValues.getNumericValues(r, \"id\");\n    Bits liveDocs = MultiFields.getLiveDocs(s.getIndexReader());\n    int maxDoc = s.getIndexReader().maxDoc();\n\n    for (int iter=0; iter<iters; ++iter) {\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: iter=\" + iter + \" s=\" + s);\n      }\n\n      // occasionally test open ended bounding boxes\n      Box queryBox = nextBox(dimensions);\n      int rv = random().nextInt(3);\n      Query query;\n      Box.QueryType queryType;\n      if (rv == 0) {\n        queryType = Box.QueryType.INTERSECTS;\n        query = newIntersectsQuery(queryBox.min, queryBox.max);\n      } else if (rv == 1)  {\n        queryType = Box.QueryType.CONTAINS;\n        query = newContainsQuery(queryBox.min, queryBox.max);\n      } else {\n        queryType = Box.QueryType.WITHIN;\n        query = newWithinQuery(queryBox.min, queryBox.max);\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  query=\" + query);\n      }\n\n      final FixedBitSet hits = new FixedBitSet(maxDoc);\n      s.search(query, new SimpleCollector() {\n        private int docBase;\n\n        @Override\n        public void collect(int doc) {\n          hits.set(docBase + doc);\n        }\n\n        @Override\n        protected void doSetNextReader(LeafReaderContext context) throws IOException {\n          docBase = context.docBase;\n        }\n\n        @Override\n        public boolean needsScores() { return false; }\n      });\n\n      for (int docID=0; docID<maxDoc; ++docID) {\n        int id = (int) docIDToID.get(docID);\n        boolean expected;\n        if (liveDocs != null && liveDocs.get(docID) == false) {\n          // document is deleted\n          expected = false;\n        } else if (Double.isNaN(boxes[id][0].min[0])) {\n          expected = false;\n        } else {\n          expected = expectedResult(queryBox, boxes[id], queryType);\n        }\n\n        if (hits.get(docID) != expected) {\n          StringBuilder b = new StringBuilder();\n          if (expected == true) {\n            b.append(\"FAILS: id=\" + id + (boxes[id].length > 1 ? \" (MultiValue) \" : \" \") + \"should match but did not\\n\");\n          } else {\n            b.append(\"FAIL: id=\" + id + \" should not match but did\\n\");\n          }\n          b.append(\" queryBox=\" + queryBox + \"\\n\");\n          b.append(\" box\" + ((boxes[id].length > 1) ? \"es=\" : \"=\" ) + boxes[id][0]);\n          for (int n=1; n<boxes[id].length; ++n) {\n            b.append(\", \");\n            b.append(boxes[id][n]);\n          }\n          b.append(\"\\n queryType=\" + queryType + \"\\n\");\n          b.append(\" deleted?=\" + (liveDocs != null && liveDocs.get(docID) == false));\n          fail(\"wrong hit (first of possibly more):\\n\\n\" + b);\n        }\n      }\n    }\n    IOUtils.close(r, dir);\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4e6bfc2c1eac33d890bf4d5638c8e149e1dcbcca","date":1469204477,"type":3,"author":"Nicholas Knize","isMerge":false,"pathNew":"lucene/sandbox/src/test/org/apache/lucene/search/BaseRangeFieldQueryTestCase#verify(Box[][]).mjava","pathOld":"lucene/sandbox/src/test/org/apache/lucene/search/BaseRangeFieldQueryTestCase#verify(Box[][]).mjava","sourceNew":"  private void verify(Box[][] boxes) throws Exception {\n    IndexWriterConfig iwc = newIndexWriterConfig();\n    // Else seeds may not reproduce:\n    iwc.setMergeScheduler(new SerialMergeScheduler());\n    // Else we can get O(N^2) merging\n    int mbd = iwc.getMaxBufferedDocs();\n    if (mbd != -1 && mbd < boxes.length/100) {\n      iwc.setMaxBufferedDocs(boxes.length/100);\n    }\n    Directory dir;\n    if (boxes.length > 50000) {\n      dir = newFSDirectory(createTempDir(getClass().getSimpleName()));\n    } else {\n      dir = newDirectory();\n    }\n\n    Set<Integer> deleted = new HashSet<>();\n    IndexWriter w = new IndexWriter(dir, iwc);\n    for (int id=0; id < boxes.length; ++id) {\n      Document doc = new Document();\n      doc.add(newStringField(\"id\", \"\"+id, Field.Store.NO));\n      doc.add(new NumericDocValuesField(\"id\", id));\n      if (Double.isNaN(boxes[id][0].min[0]) == false) {\n        for (int n=0; n<boxes[id].length; ++n) {\n          doc.add(newRangeField(boxes[id][n].min, boxes[id][n].max));\n        }\n      }\n      w.addDocument(doc);\n      if (id > 0 && random().nextInt(100) == 1) {\n        int idToDelete = random().nextInt(id);\n        w.deleteDocuments(new Term(\"id\", \"\"+idToDelete));\n        deleted.add(idToDelete);\n        if (VERBOSE) {\n          System.out.println(\"  delete id=\" + idToDelete);\n        }\n      }\n    }\n\n    if (random().nextBoolean()) {\n      w.forceMerge(1);\n    }\n    final IndexReader r = DirectoryReader.open(w);\n    w.close();\n    IndexSearcher s = newSearcher(r);\n\n    int dimensions = boxes[0][0].min.length;\n    int iters = atLeast(25);\n    NumericDocValues docIDToID = MultiDocValues.getNumericValues(r, \"id\");\n    Bits liveDocs = MultiFields.getLiveDocs(s.getIndexReader());\n    int maxDoc = s.getIndexReader().maxDoc();\n\n    for (int iter=0; iter<iters; ++iter) {\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: iter=\" + iter + \" s=\" + s);\n      }\n\n      // occasionally test open ended bounding boxes\n      Box queryBox = nextBox(dimensions);\n      int rv = random().nextInt(3);\n      Query query;\n      Box.QueryType queryType;\n      if (rv == 0) {\n        queryType = Box.QueryType.INTERSECTS;\n        query = newIntersectsQuery(queryBox.min, queryBox.max);\n      } else if (rv == 1)  {\n        queryType = Box.QueryType.CONTAINS;\n        query = newContainsQuery(queryBox.min, queryBox.max);\n      } else {\n        queryType = Box.QueryType.WITHIN;\n        query = newWithinQuery(queryBox.min, queryBox.max);\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  query=\" + query);\n      }\n\n      final FixedBitSet hits = new FixedBitSet(maxDoc);\n      s.search(query, new SimpleCollector() {\n        private int docBase;\n\n        @Override\n        public void collect(int doc) {\n          hits.set(docBase + doc);\n        }\n\n        @Override\n        protected void doSetNextReader(LeafReaderContext context) throws IOException {\n          docBase = context.docBase;\n        }\n\n        @Override\n        public boolean needsScores() { return false; }\n      });\n\n      for (int docID=0; docID<maxDoc; ++docID) {\n        int id = (int) docIDToID.get(docID);\n        boolean expected;\n        if (liveDocs != null && liveDocs.get(docID) == false) {\n          // document is deleted\n          expected = false;\n        } else if (Double.isNaN(boxes[id][0].min[0])) {\n          expected = false;\n        } else {\n          expected = expectedResult(queryBox, boxes[id], queryType);\n        }\n\n        if (hits.get(docID) != expected) {\n          StringBuilder b = new StringBuilder();\n          b.append(\"FAIL (iter \" + iter + \"): \");\n          if (expected == true) {\n            b.append(\"id=\" + id + (boxes[id].length > 1 ? \" (MultiValue) \" : \" \") + \"should match but did not\\n\");\n          } else {\n            b.append(\"id=\" + id + \" should not match but did\\n\");\n          }\n          b.append(\" queryBox=\" + queryBox + \"\\n\");\n          b.append(\" box\" + ((boxes[id].length > 1) ? \"es=\" : \"=\" ) + boxes[id][0]);\n          for (int n=1; n<boxes[id].length; ++n) {\n            b.append(\", \");\n            b.append(boxes[id][n]);\n          }\n          b.append(\"\\n queryType=\" + queryType + \"\\n\");\n          b.append(\" deleted?=\" + (liveDocs != null && liveDocs.get(docID) == false));\n          fail(\"wrong hit (first of possibly more):\\n\\n\" + b);\n        }\n      }\n    }\n    IOUtils.close(r, dir);\n  }\n\n","sourceOld":"  private void verify(Box[][] boxes) throws Exception {\n    IndexWriterConfig iwc = newIndexWriterConfig();\n    // Else seeds may not reproduce:\n    iwc.setMergeScheduler(new SerialMergeScheduler());\n    // Else we can get O(N^2) merging\n    int mbd = iwc.getMaxBufferedDocs();\n    if (mbd != -1 && mbd < boxes.length/100) {\n      iwc.setMaxBufferedDocs(boxes.length/100);\n    }\n    Directory dir;\n    if (boxes.length > 50000) {\n      dir = newFSDirectory(createTempDir(getClass().getSimpleName()));\n    } else {\n      dir = newDirectory();\n    }\n\n    Set<Integer> deleted = new HashSet<>();\n    IndexWriter w = new IndexWriter(dir, iwc);\n    for (int id=0; id < boxes.length; ++id) {\n      Document doc = new Document();\n      doc.add(newStringField(\"id\", \"\"+id, Field.Store.NO));\n      doc.add(new NumericDocValuesField(\"id\", id));\n      if (Double.isNaN(boxes[id][0].min[0]) == false) {\n        for (int n=0; n<boxes[id].length; ++n) {\n          doc.add(newRangeField(boxes[id][n].min, boxes[id][n].max));\n        }\n      }\n      w.addDocument(doc);\n      if (id > 0 && random().nextInt(100) == 1) {\n        int idToDelete = random().nextInt(id);\n        w.deleteDocuments(new Term(\"id\", \"\"+idToDelete));\n        deleted.add(idToDelete);\n        if (VERBOSE) {\n          System.out.println(\"  delete id=\" + idToDelete);\n        }\n      }\n    }\n\n    if (random().nextBoolean()) {\n      w.forceMerge(1);\n    }\n    final IndexReader r = DirectoryReader.open(w);\n    w.close();\n    IndexSearcher s = newSearcher(r);\n\n    int dimensions = boxes[0][0].min.length;\n    int iters = atLeast(25);\n    NumericDocValues docIDToID = MultiDocValues.getNumericValues(r, \"id\");\n    Bits liveDocs = MultiFields.getLiveDocs(s.getIndexReader());\n    int maxDoc = s.getIndexReader().maxDoc();\n\n    for (int iter=0; iter<iters; ++iter) {\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: iter=\" + iter + \" s=\" + s);\n      }\n\n      // occasionally test open ended bounding boxes\n      Box queryBox = nextBox(dimensions);\n      int rv = random().nextInt(3);\n      Query query;\n      Box.QueryType queryType;\n      if (rv == 0) {\n        queryType = Box.QueryType.INTERSECTS;\n        query = newIntersectsQuery(queryBox.min, queryBox.max);\n      } else if (rv == 1)  {\n        queryType = Box.QueryType.CONTAINS;\n        query = newContainsQuery(queryBox.min, queryBox.max);\n      } else {\n        queryType = Box.QueryType.WITHIN;\n        query = newWithinQuery(queryBox.min, queryBox.max);\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  query=\" + query);\n      }\n\n      final FixedBitSet hits = new FixedBitSet(maxDoc);\n      s.search(query, new SimpleCollector() {\n        private int docBase;\n\n        @Override\n        public void collect(int doc) {\n          hits.set(docBase + doc);\n        }\n\n        @Override\n        protected void doSetNextReader(LeafReaderContext context) throws IOException {\n          docBase = context.docBase;\n        }\n\n        @Override\n        public boolean needsScores() { return false; }\n      });\n\n      for (int docID=0; docID<maxDoc; ++docID) {\n        int id = (int) docIDToID.get(docID);\n        boolean expected;\n        if (liveDocs != null && liveDocs.get(docID) == false) {\n          // document is deleted\n          expected = false;\n        } else if (Double.isNaN(boxes[id][0].min[0])) {\n          expected = false;\n        } else {\n          expected = expectedResult(queryBox, boxes[id], queryType);\n        }\n\n        if (hits.get(docID) != expected) {\n          StringBuilder b = new StringBuilder();\n          if (expected == true) {\n            b.append(\"FAILS: id=\" + id + (boxes[id].length > 1 ? \" (MultiValue) \" : \" \") + \"should match but did not\\n\");\n          } else {\n            b.append(\"FAIL: id=\" + id + \" should not match but did\\n\");\n          }\n          b.append(\" queryBox=\" + queryBox + \"\\n\");\n          b.append(\" box\" + ((boxes[id].length > 1) ? \"es=\" : \"=\" ) + boxes[id][0]);\n          for (int n=1; n<boxes[id].length; ++n) {\n            b.append(\", \");\n            b.append(boxes[id][n]);\n          }\n          b.append(\"\\n queryType=\" + queryType + \"\\n\");\n          b.append(\" deleted?=\" + (liveDocs != null && liveDocs.get(docID) == false));\n          fail(\"wrong hit (first of possibly more):\\n\\n\" + b);\n        }\n      }\n    }\n    IOUtils.close(r, dir);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7825da0fed0bd08a466fec72f7c6a18a2abb303d","date":1471466888,"type":5,"author":"Nicholas Knize","isMerge":false,"pathNew":"lucene/sandbox/src/test/org/apache/lucene/search/BaseRangeFieldQueryTestCase#verify(Range[][]).mjava","pathOld":"lucene/sandbox/src/test/org/apache/lucene/search/BaseRangeFieldQueryTestCase#verify(Box[][]).mjava","sourceNew":"  private void verify(Range[][] ranges) throws Exception {\n    IndexWriterConfig iwc = newIndexWriterConfig();\n    // Else seeds may not reproduce:\n    iwc.setMergeScheduler(new SerialMergeScheduler());\n    // Else we can get O(N^2) merging\n    int mbd = iwc.getMaxBufferedDocs();\n    if (mbd != -1 && mbd < ranges.length/100) {\n      iwc.setMaxBufferedDocs(ranges.length/100);\n    }\n    Directory dir;\n    if (ranges.length > 50000) {\n      dir = newFSDirectory(createTempDir(getClass().getSimpleName()));\n    } else {\n      dir = newDirectory();\n    }\n\n    Set<Integer> deleted = new HashSet<>();\n    IndexWriter w = new IndexWriter(dir, iwc);\n    for (int id=0; id < ranges.length; ++id) {\n      Document doc = new Document();\n      doc.add(newStringField(\"id\", \"\"+id, Field.Store.NO));\n      doc.add(new NumericDocValuesField(\"id\", id));\n      if (ranges[id][0].isMissing == false) {\n        for (int n=0; n<ranges[id].length; ++n) {\n          doc.add(newRangeField(ranges[id][n]));\n        }\n      }\n      w.addDocument(doc);\n      if (id > 0 && random().nextInt(100) == 1) {\n        int idToDelete = random().nextInt(id);\n        w.deleteDocuments(new Term(\"id\", \"\"+idToDelete));\n        deleted.add(idToDelete);\n        if (VERBOSE) {\n          System.out.println(\"  delete id=\" + idToDelete);\n        }\n      }\n    }\n\n    if (random().nextBoolean()) {\n      w.forceMerge(1);\n    }\n    final IndexReader r = DirectoryReader.open(w);\n    w.close();\n    IndexSearcher s = newSearcher(r);\n\n    int dimensions = ranges[0][0].numDimensions();\n    int iters = atLeast(25);\n    NumericDocValues docIDToID = MultiDocValues.getNumericValues(r, \"id\");\n    Bits liveDocs = MultiFields.getLiveDocs(s.getIndexReader());\n    int maxDoc = s.getIndexReader().maxDoc();\n\n    for (int iter=0; iter<iters; ++iter) {\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: iter=\" + iter + \" s=\" + s);\n      }\n\n      // occasionally test open ended bounding ranges\n      Range queryRange = nextRange(dimensions);\n      int rv = random().nextInt(3);\n      Query query;\n      Range.QueryType queryType;\n      if (rv == 0) {\n        queryType = Range.QueryType.INTERSECTS;\n        query = newIntersectsQuery(queryRange);\n      } else if (rv == 1)  {\n        queryType = Range.QueryType.CONTAINS;\n        query = newContainsQuery(queryRange);\n      } else {\n        queryType = Range.QueryType.WITHIN;\n        query = newWithinQuery(queryRange);\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  query=\" + query);\n      }\n\n      final FixedBitSet hits = new FixedBitSet(maxDoc);\n      s.search(query, new SimpleCollector() {\n        private int docBase;\n\n        @Override\n        public void collect(int doc) {\n          hits.set(docBase + doc);\n        }\n\n        @Override\n        protected void doSetNextReader(LeafReaderContext context) throws IOException {\n          docBase = context.docBase;\n        }\n\n        @Override\n        public boolean needsScores() { return false; }\n      });\n\n      for (int docID=0; docID<maxDoc; ++docID) {\n        int id = (int) docIDToID.get(docID);\n        boolean expected;\n        if (liveDocs != null && liveDocs.get(docID) == false) {\n          // document is deleted\n          expected = false;\n        } else if (ranges[id][0].isMissing) {\n          expected = false;\n        } else {\n          expected = expectedResult(queryRange, ranges[id], queryType);\n        }\n\n        if (hits.get(docID) != expected) {\n          StringBuilder b = new StringBuilder();\n          b.append(\"FAIL (iter \" + iter + \"): \");\n          if (expected == true) {\n            b.append(\"id=\" + id + (ranges[id].length > 1 ? \" (MultiValue) \" : \" \") + \"should match but did not\\n\");\n          } else {\n            b.append(\"id=\" + id + \" should not match but did\\n\");\n          }\n          b.append(\" queryRange=\" + queryRange + \"\\n\");\n          b.append(\" box\" + ((ranges[id].length > 1) ? \"es=\" : \"=\" ) + ranges[id][0]);\n          for (int n=1; n<ranges[id].length; ++n) {\n            b.append(\", \");\n            b.append(ranges[id][n]);\n          }\n          b.append(\"\\n queryType=\" + queryType + \"\\n\");\n          b.append(\" deleted?=\" + (liveDocs != null && liveDocs.get(docID) == false));\n          fail(\"wrong hit (first of possibly more):\\n\\n\" + b);\n        }\n      }\n    }\n    IOUtils.close(r, dir);\n  }\n\n","sourceOld":"  private void verify(Box[][] boxes) throws Exception {\n    IndexWriterConfig iwc = newIndexWriterConfig();\n    // Else seeds may not reproduce:\n    iwc.setMergeScheduler(new SerialMergeScheduler());\n    // Else we can get O(N^2) merging\n    int mbd = iwc.getMaxBufferedDocs();\n    if (mbd != -1 && mbd < boxes.length/100) {\n      iwc.setMaxBufferedDocs(boxes.length/100);\n    }\n    Directory dir;\n    if (boxes.length > 50000) {\n      dir = newFSDirectory(createTempDir(getClass().getSimpleName()));\n    } else {\n      dir = newDirectory();\n    }\n\n    Set<Integer> deleted = new HashSet<>();\n    IndexWriter w = new IndexWriter(dir, iwc);\n    for (int id=0; id < boxes.length; ++id) {\n      Document doc = new Document();\n      doc.add(newStringField(\"id\", \"\"+id, Field.Store.NO));\n      doc.add(new NumericDocValuesField(\"id\", id));\n      if (Double.isNaN(boxes[id][0].min[0]) == false) {\n        for (int n=0; n<boxes[id].length; ++n) {\n          doc.add(newRangeField(boxes[id][n].min, boxes[id][n].max));\n        }\n      }\n      w.addDocument(doc);\n      if (id > 0 && random().nextInt(100) == 1) {\n        int idToDelete = random().nextInt(id);\n        w.deleteDocuments(new Term(\"id\", \"\"+idToDelete));\n        deleted.add(idToDelete);\n        if (VERBOSE) {\n          System.out.println(\"  delete id=\" + idToDelete);\n        }\n      }\n    }\n\n    if (random().nextBoolean()) {\n      w.forceMerge(1);\n    }\n    final IndexReader r = DirectoryReader.open(w);\n    w.close();\n    IndexSearcher s = newSearcher(r);\n\n    int dimensions = boxes[0][0].min.length;\n    int iters = atLeast(25);\n    NumericDocValues docIDToID = MultiDocValues.getNumericValues(r, \"id\");\n    Bits liveDocs = MultiFields.getLiveDocs(s.getIndexReader());\n    int maxDoc = s.getIndexReader().maxDoc();\n\n    for (int iter=0; iter<iters; ++iter) {\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: iter=\" + iter + \" s=\" + s);\n      }\n\n      // occasionally test open ended bounding boxes\n      Box queryBox = nextBox(dimensions);\n      int rv = random().nextInt(3);\n      Query query;\n      Box.QueryType queryType;\n      if (rv == 0) {\n        queryType = Box.QueryType.INTERSECTS;\n        query = newIntersectsQuery(queryBox.min, queryBox.max);\n      } else if (rv == 1)  {\n        queryType = Box.QueryType.CONTAINS;\n        query = newContainsQuery(queryBox.min, queryBox.max);\n      } else {\n        queryType = Box.QueryType.WITHIN;\n        query = newWithinQuery(queryBox.min, queryBox.max);\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  query=\" + query);\n      }\n\n      final FixedBitSet hits = new FixedBitSet(maxDoc);\n      s.search(query, new SimpleCollector() {\n        private int docBase;\n\n        @Override\n        public void collect(int doc) {\n          hits.set(docBase + doc);\n        }\n\n        @Override\n        protected void doSetNextReader(LeafReaderContext context) throws IOException {\n          docBase = context.docBase;\n        }\n\n        @Override\n        public boolean needsScores() { return false; }\n      });\n\n      for (int docID=0; docID<maxDoc; ++docID) {\n        int id = (int) docIDToID.get(docID);\n        boolean expected;\n        if (liveDocs != null && liveDocs.get(docID) == false) {\n          // document is deleted\n          expected = false;\n        } else if (Double.isNaN(boxes[id][0].min[0])) {\n          expected = false;\n        } else {\n          expected = expectedResult(queryBox, boxes[id], queryType);\n        }\n\n        if (hits.get(docID) != expected) {\n          StringBuilder b = new StringBuilder();\n          b.append(\"FAIL (iter \" + iter + \"): \");\n          if (expected == true) {\n            b.append(\"id=\" + id + (boxes[id].length > 1 ? \" (MultiValue) \" : \" \") + \"should match but did not\\n\");\n          } else {\n            b.append(\"id=\" + id + \" should not match but did\\n\");\n          }\n          b.append(\" queryBox=\" + queryBox + \"\\n\");\n          b.append(\" box\" + ((boxes[id].length > 1) ? \"es=\" : \"=\" ) + boxes[id][0]);\n          for (int n=1; n<boxes[id].length; ++n) {\n            b.append(\", \");\n            b.append(boxes[id][n]);\n          }\n          b.append(\"\\n queryType=\" + queryType + \"\\n\");\n          b.append(\" deleted?=\" + (liveDocs != null && liveDocs.get(docID) == false));\n          fail(\"wrong hit (first of possibly more):\\n\\n\" + b);\n        }\n      }\n    }\n    IOUtils.close(r, dir);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2c8bedceb91e64a3f0e831450058fc4a76d2c0a6","date":1471496851,"type":5,"author":"Noble Paul","isMerge":true,"pathNew":"lucene/sandbox/src/test/org/apache/lucene/search/BaseRangeFieldQueryTestCase#verify(Range[][]).mjava","pathOld":"lucene/sandbox/src/test/org/apache/lucene/search/BaseRangeFieldQueryTestCase#verify(Box[][]).mjava","sourceNew":"  private void verify(Range[][] ranges) throws Exception {\n    IndexWriterConfig iwc = newIndexWriterConfig();\n    // Else seeds may not reproduce:\n    iwc.setMergeScheduler(new SerialMergeScheduler());\n    // Else we can get O(N^2) merging\n    int mbd = iwc.getMaxBufferedDocs();\n    if (mbd != -1 && mbd < ranges.length/100) {\n      iwc.setMaxBufferedDocs(ranges.length/100);\n    }\n    Directory dir;\n    if (ranges.length > 50000) {\n      dir = newFSDirectory(createTempDir(getClass().getSimpleName()));\n    } else {\n      dir = newDirectory();\n    }\n\n    Set<Integer> deleted = new HashSet<>();\n    IndexWriter w = new IndexWriter(dir, iwc);\n    for (int id=0; id < ranges.length; ++id) {\n      Document doc = new Document();\n      doc.add(newStringField(\"id\", \"\"+id, Field.Store.NO));\n      doc.add(new NumericDocValuesField(\"id\", id));\n      if (ranges[id][0].isMissing == false) {\n        for (int n=0; n<ranges[id].length; ++n) {\n          doc.add(newRangeField(ranges[id][n]));\n        }\n      }\n      w.addDocument(doc);\n      if (id > 0 && random().nextInt(100) == 1) {\n        int idToDelete = random().nextInt(id);\n        w.deleteDocuments(new Term(\"id\", \"\"+idToDelete));\n        deleted.add(idToDelete);\n        if (VERBOSE) {\n          System.out.println(\"  delete id=\" + idToDelete);\n        }\n      }\n    }\n\n    if (random().nextBoolean()) {\n      w.forceMerge(1);\n    }\n    final IndexReader r = DirectoryReader.open(w);\n    w.close();\n    IndexSearcher s = newSearcher(r);\n\n    int dimensions = ranges[0][0].numDimensions();\n    int iters = atLeast(25);\n    NumericDocValues docIDToID = MultiDocValues.getNumericValues(r, \"id\");\n    Bits liveDocs = MultiFields.getLiveDocs(s.getIndexReader());\n    int maxDoc = s.getIndexReader().maxDoc();\n\n    for (int iter=0; iter<iters; ++iter) {\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: iter=\" + iter + \" s=\" + s);\n      }\n\n      // occasionally test open ended bounding ranges\n      Range queryRange = nextRange(dimensions);\n      int rv = random().nextInt(3);\n      Query query;\n      Range.QueryType queryType;\n      if (rv == 0) {\n        queryType = Range.QueryType.INTERSECTS;\n        query = newIntersectsQuery(queryRange);\n      } else if (rv == 1)  {\n        queryType = Range.QueryType.CONTAINS;\n        query = newContainsQuery(queryRange);\n      } else {\n        queryType = Range.QueryType.WITHIN;\n        query = newWithinQuery(queryRange);\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  query=\" + query);\n      }\n\n      final FixedBitSet hits = new FixedBitSet(maxDoc);\n      s.search(query, new SimpleCollector() {\n        private int docBase;\n\n        @Override\n        public void collect(int doc) {\n          hits.set(docBase + doc);\n        }\n\n        @Override\n        protected void doSetNextReader(LeafReaderContext context) throws IOException {\n          docBase = context.docBase;\n        }\n\n        @Override\n        public boolean needsScores() { return false; }\n      });\n\n      for (int docID=0; docID<maxDoc; ++docID) {\n        int id = (int) docIDToID.get(docID);\n        boolean expected;\n        if (liveDocs != null && liveDocs.get(docID) == false) {\n          // document is deleted\n          expected = false;\n        } else if (ranges[id][0].isMissing) {\n          expected = false;\n        } else {\n          expected = expectedResult(queryRange, ranges[id], queryType);\n        }\n\n        if (hits.get(docID) != expected) {\n          StringBuilder b = new StringBuilder();\n          b.append(\"FAIL (iter \" + iter + \"): \");\n          if (expected == true) {\n            b.append(\"id=\" + id + (ranges[id].length > 1 ? \" (MultiValue) \" : \" \") + \"should match but did not\\n\");\n          } else {\n            b.append(\"id=\" + id + \" should not match but did\\n\");\n          }\n          b.append(\" queryRange=\" + queryRange + \"\\n\");\n          b.append(\" box\" + ((ranges[id].length > 1) ? \"es=\" : \"=\" ) + ranges[id][0]);\n          for (int n=1; n<ranges[id].length; ++n) {\n            b.append(\", \");\n            b.append(ranges[id][n]);\n          }\n          b.append(\"\\n queryType=\" + queryType + \"\\n\");\n          b.append(\" deleted?=\" + (liveDocs != null && liveDocs.get(docID) == false));\n          fail(\"wrong hit (first of possibly more):\\n\\n\" + b);\n        }\n      }\n    }\n    IOUtils.close(r, dir);\n  }\n\n","sourceOld":"  private void verify(Box[][] boxes) throws Exception {\n    IndexWriterConfig iwc = newIndexWriterConfig();\n    // Else seeds may not reproduce:\n    iwc.setMergeScheduler(new SerialMergeScheduler());\n    // Else we can get O(N^2) merging\n    int mbd = iwc.getMaxBufferedDocs();\n    if (mbd != -1 && mbd < boxes.length/100) {\n      iwc.setMaxBufferedDocs(boxes.length/100);\n    }\n    Directory dir;\n    if (boxes.length > 50000) {\n      dir = newFSDirectory(createTempDir(getClass().getSimpleName()));\n    } else {\n      dir = newDirectory();\n    }\n\n    Set<Integer> deleted = new HashSet<>();\n    IndexWriter w = new IndexWriter(dir, iwc);\n    for (int id=0; id < boxes.length; ++id) {\n      Document doc = new Document();\n      doc.add(newStringField(\"id\", \"\"+id, Field.Store.NO));\n      doc.add(new NumericDocValuesField(\"id\", id));\n      if (Double.isNaN(boxes[id][0].min[0]) == false) {\n        for (int n=0; n<boxes[id].length; ++n) {\n          doc.add(newRangeField(boxes[id][n].min, boxes[id][n].max));\n        }\n      }\n      w.addDocument(doc);\n      if (id > 0 && random().nextInt(100) == 1) {\n        int idToDelete = random().nextInt(id);\n        w.deleteDocuments(new Term(\"id\", \"\"+idToDelete));\n        deleted.add(idToDelete);\n        if (VERBOSE) {\n          System.out.println(\"  delete id=\" + idToDelete);\n        }\n      }\n    }\n\n    if (random().nextBoolean()) {\n      w.forceMerge(1);\n    }\n    final IndexReader r = DirectoryReader.open(w);\n    w.close();\n    IndexSearcher s = newSearcher(r);\n\n    int dimensions = boxes[0][0].min.length;\n    int iters = atLeast(25);\n    NumericDocValues docIDToID = MultiDocValues.getNumericValues(r, \"id\");\n    Bits liveDocs = MultiFields.getLiveDocs(s.getIndexReader());\n    int maxDoc = s.getIndexReader().maxDoc();\n\n    for (int iter=0; iter<iters; ++iter) {\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: iter=\" + iter + \" s=\" + s);\n      }\n\n      // occasionally test open ended bounding boxes\n      Box queryBox = nextBox(dimensions);\n      int rv = random().nextInt(3);\n      Query query;\n      Box.QueryType queryType;\n      if (rv == 0) {\n        queryType = Box.QueryType.INTERSECTS;\n        query = newIntersectsQuery(queryBox.min, queryBox.max);\n      } else if (rv == 1)  {\n        queryType = Box.QueryType.CONTAINS;\n        query = newContainsQuery(queryBox.min, queryBox.max);\n      } else {\n        queryType = Box.QueryType.WITHIN;\n        query = newWithinQuery(queryBox.min, queryBox.max);\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  query=\" + query);\n      }\n\n      final FixedBitSet hits = new FixedBitSet(maxDoc);\n      s.search(query, new SimpleCollector() {\n        private int docBase;\n\n        @Override\n        public void collect(int doc) {\n          hits.set(docBase + doc);\n        }\n\n        @Override\n        protected void doSetNextReader(LeafReaderContext context) throws IOException {\n          docBase = context.docBase;\n        }\n\n        @Override\n        public boolean needsScores() { return false; }\n      });\n\n      for (int docID=0; docID<maxDoc; ++docID) {\n        int id = (int) docIDToID.get(docID);\n        boolean expected;\n        if (liveDocs != null && liveDocs.get(docID) == false) {\n          // document is deleted\n          expected = false;\n        } else if (Double.isNaN(boxes[id][0].min[0])) {\n          expected = false;\n        } else {\n          expected = expectedResult(queryBox, boxes[id], queryType);\n        }\n\n        if (hits.get(docID) != expected) {\n          StringBuilder b = new StringBuilder();\n          b.append(\"FAIL (iter \" + iter + \"): \");\n          if (expected == true) {\n            b.append(\"id=\" + id + (boxes[id].length > 1 ? \" (MultiValue) \" : \" \") + \"should match but did not\\n\");\n          } else {\n            b.append(\"id=\" + id + \" should not match but did\\n\");\n          }\n          b.append(\" queryBox=\" + queryBox + \"\\n\");\n          b.append(\" box\" + ((boxes[id].length > 1) ? \"es=\" : \"=\" ) + boxes[id][0]);\n          for (int n=1; n<boxes[id].length; ++n) {\n            b.append(\", \");\n            b.append(boxes[id][n]);\n          }\n          b.append(\"\\n queryType=\" + queryType + \"\\n\");\n          b.append(\" deleted?=\" + (liveDocs != null && liveDocs.get(docID) == false));\n          fail(\"wrong hit (first of possibly more):\\n\\n\" + b);\n        }\n      }\n    }\n    IOUtils.close(r, dir);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"403d05f7f8d69b65659157eff1bc1d2717f04c66","date":1471692961,"type":5,"author":"Karl Wright","isMerge":true,"pathNew":"lucene/sandbox/src/test/org/apache/lucene/search/BaseRangeFieldQueryTestCase#verify(Range[][]).mjava","pathOld":"lucene/sandbox/src/test/org/apache/lucene/search/BaseRangeFieldQueryTestCase#verify(Box[][]).mjava","sourceNew":"  private void verify(Range[][] ranges) throws Exception {\n    IndexWriterConfig iwc = newIndexWriterConfig();\n    // Else seeds may not reproduce:\n    iwc.setMergeScheduler(new SerialMergeScheduler());\n    // Else we can get O(N^2) merging\n    int mbd = iwc.getMaxBufferedDocs();\n    if (mbd != -1 && mbd < ranges.length/100) {\n      iwc.setMaxBufferedDocs(ranges.length/100);\n    }\n    Directory dir;\n    if (ranges.length > 50000) {\n      dir = newFSDirectory(createTempDir(getClass().getSimpleName()));\n    } else {\n      dir = newDirectory();\n    }\n\n    Set<Integer> deleted = new HashSet<>();\n    IndexWriter w = new IndexWriter(dir, iwc);\n    for (int id=0; id < ranges.length; ++id) {\n      Document doc = new Document();\n      doc.add(newStringField(\"id\", \"\"+id, Field.Store.NO));\n      doc.add(new NumericDocValuesField(\"id\", id));\n      if (ranges[id][0].isMissing == false) {\n        for (int n=0; n<ranges[id].length; ++n) {\n          doc.add(newRangeField(ranges[id][n]));\n        }\n      }\n      w.addDocument(doc);\n      if (id > 0 && random().nextInt(100) == 1) {\n        int idToDelete = random().nextInt(id);\n        w.deleteDocuments(new Term(\"id\", \"\"+idToDelete));\n        deleted.add(idToDelete);\n        if (VERBOSE) {\n          System.out.println(\"  delete id=\" + idToDelete);\n        }\n      }\n    }\n\n    if (random().nextBoolean()) {\n      w.forceMerge(1);\n    }\n    final IndexReader r = DirectoryReader.open(w);\n    w.close();\n    IndexSearcher s = newSearcher(r);\n\n    int dimensions = ranges[0][0].numDimensions();\n    int iters = atLeast(25);\n    NumericDocValues docIDToID = MultiDocValues.getNumericValues(r, \"id\");\n    Bits liveDocs = MultiFields.getLiveDocs(s.getIndexReader());\n    int maxDoc = s.getIndexReader().maxDoc();\n\n    for (int iter=0; iter<iters; ++iter) {\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: iter=\" + iter + \" s=\" + s);\n      }\n\n      // occasionally test open ended bounding ranges\n      Range queryRange = nextRange(dimensions);\n      int rv = random().nextInt(3);\n      Query query;\n      Range.QueryType queryType;\n      if (rv == 0) {\n        queryType = Range.QueryType.INTERSECTS;\n        query = newIntersectsQuery(queryRange);\n      } else if (rv == 1)  {\n        queryType = Range.QueryType.CONTAINS;\n        query = newContainsQuery(queryRange);\n      } else {\n        queryType = Range.QueryType.WITHIN;\n        query = newWithinQuery(queryRange);\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  query=\" + query);\n      }\n\n      final FixedBitSet hits = new FixedBitSet(maxDoc);\n      s.search(query, new SimpleCollector() {\n        private int docBase;\n\n        @Override\n        public void collect(int doc) {\n          hits.set(docBase + doc);\n        }\n\n        @Override\n        protected void doSetNextReader(LeafReaderContext context) throws IOException {\n          docBase = context.docBase;\n        }\n\n        @Override\n        public boolean needsScores() { return false; }\n      });\n\n      for (int docID=0; docID<maxDoc; ++docID) {\n        int id = (int) docIDToID.get(docID);\n        boolean expected;\n        if (liveDocs != null && liveDocs.get(docID) == false) {\n          // document is deleted\n          expected = false;\n        } else if (ranges[id][0].isMissing) {\n          expected = false;\n        } else {\n          expected = expectedResult(queryRange, ranges[id], queryType);\n        }\n\n        if (hits.get(docID) != expected) {\n          StringBuilder b = new StringBuilder();\n          b.append(\"FAIL (iter \" + iter + \"): \");\n          if (expected == true) {\n            b.append(\"id=\" + id + (ranges[id].length > 1 ? \" (MultiValue) \" : \" \") + \"should match but did not\\n\");\n          } else {\n            b.append(\"id=\" + id + \" should not match but did\\n\");\n          }\n          b.append(\" queryRange=\" + queryRange + \"\\n\");\n          b.append(\" box\" + ((ranges[id].length > 1) ? \"es=\" : \"=\" ) + ranges[id][0]);\n          for (int n=1; n<ranges[id].length; ++n) {\n            b.append(\", \");\n            b.append(ranges[id][n]);\n          }\n          b.append(\"\\n queryType=\" + queryType + \"\\n\");\n          b.append(\" deleted?=\" + (liveDocs != null && liveDocs.get(docID) == false));\n          fail(\"wrong hit (first of possibly more):\\n\\n\" + b);\n        }\n      }\n    }\n    IOUtils.close(r, dir);\n  }\n\n","sourceOld":"  private void verify(Box[][] boxes) throws Exception {\n    IndexWriterConfig iwc = newIndexWriterConfig();\n    // Else seeds may not reproduce:\n    iwc.setMergeScheduler(new SerialMergeScheduler());\n    // Else we can get O(N^2) merging\n    int mbd = iwc.getMaxBufferedDocs();\n    if (mbd != -1 && mbd < boxes.length/100) {\n      iwc.setMaxBufferedDocs(boxes.length/100);\n    }\n    Directory dir;\n    if (boxes.length > 50000) {\n      dir = newFSDirectory(createTempDir(getClass().getSimpleName()));\n    } else {\n      dir = newDirectory();\n    }\n\n    Set<Integer> deleted = new HashSet<>();\n    IndexWriter w = new IndexWriter(dir, iwc);\n    for (int id=0; id < boxes.length; ++id) {\n      Document doc = new Document();\n      doc.add(newStringField(\"id\", \"\"+id, Field.Store.NO));\n      doc.add(new NumericDocValuesField(\"id\", id));\n      if (Double.isNaN(boxes[id][0].min[0]) == false) {\n        for (int n=0; n<boxes[id].length; ++n) {\n          doc.add(newRangeField(boxes[id][n].min, boxes[id][n].max));\n        }\n      }\n      w.addDocument(doc);\n      if (id > 0 && random().nextInt(100) == 1) {\n        int idToDelete = random().nextInt(id);\n        w.deleteDocuments(new Term(\"id\", \"\"+idToDelete));\n        deleted.add(idToDelete);\n        if (VERBOSE) {\n          System.out.println(\"  delete id=\" + idToDelete);\n        }\n      }\n    }\n\n    if (random().nextBoolean()) {\n      w.forceMerge(1);\n    }\n    final IndexReader r = DirectoryReader.open(w);\n    w.close();\n    IndexSearcher s = newSearcher(r);\n\n    int dimensions = boxes[0][0].min.length;\n    int iters = atLeast(25);\n    NumericDocValues docIDToID = MultiDocValues.getNumericValues(r, \"id\");\n    Bits liveDocs = MultiFields.getLiveDocs(s.getIndexReader());\n    int maxDoc = s.getIndexReader().maxDoc();\n\n    for (int iter=0; iter<iters; ++iter) {\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: iter=\" + iter + \" s=\" + s);\n      }\n\n      // occasionally test open ended bounding boxes\n      Box queryBox = nextBox(dimensions);\n      int rv = random().nextInt(3);\n      Query query;\n      Box.QueryType queryType;\n      if (rv == 0) {\n        queryType = Box.QueryType.INTERSECTS;\n        query = newIntersectsQuery(queryBox.min, queryBox.max);\n      } else if (rv == 1)  {\n        queryType = Box.QueryType.CONTAINS;\n        query = newContainsQuery(queryBox.min, queryBox.max);\n      } else {\n        queryType = Box.QueryType.WITHIN;\n        query = newWithinQuery(queryBox.min, queryBox.max);\n      }\n\n      if (VERBOSE) {\n        System.out.println(\"  query=\" + query);\n      }\n\n      final FixedBitSet hits = new FixedBitSet(maxDoc);\n      s.search(query, new SimpleCollector() {\n        private int docBase;\n\n        @Override\n        public void collect(int doc) {\n          hits.set(docBase + doc);\n        }\n\n        @Override\n        protected void doSetNextReader(LeafReaderContext context) throws IOException {\n          docBase = context.docBase;\n        }\n\n        @Override\n        public boolean needsScores() { return false; }\n      });\n\n      for (int docID=0; docID<maxDoc; ++docID) {\n        int id = (int) docIDToID.get(docID);\n        boolean expected;\n        if (liveDocs != null && liveDocs.get(docID) == false) {\n          // document is deleted\n          expected = false;\n        } else if (Double.isNaN(boxes[id][0].min[0])) {\n          expected = false;\n        } else {\n          expected = expectedResult(queryBox, boxes[id], queryType);\n        }\n\n        if (hits.get(docID) != expected) {\n          StringBuilder b = new StringBuilder();\n          b.append(\"FAIL (iter \" + iter + \"): \");\n          if (expected == true) {\n            b.append(\"id=\" + id + (boxes[id].length > 1 ? \" (MultiValue) \" : \" \") + \"should match but did not\\n\");\n          } else {\n            b.append(\"id=\" + id + \" should not match but did\\n\");\n          }\n          b.append(\" queryBox=\" + queryBox + \"\\n\");\n          b.append(\" box\" + ((boxes[id].length > 1) ? \"es=\" : \"=\" ) + boxes[id][0]);\n          for (int n=1; n<boxes[id].length; ++n) {\n            b.append(\", \");\n            b.append(boxes[id][n]);\n          }\n          b.append(\"\\n queryType=\" + queryType + \"\\n\");\n          b.append(\" deleted?=\" + (liveDocs != null && liveDocs.get(docID) == false));\n          fail(\"wrong hit (first of possibly more):\\n\\n\" + b);\n        }\n      }\n    }\n    IOUtils.close(r, dir);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"3c738d774d160362ecfdc9887a5fa4beb421872b":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","05f4c28bc6a6df30868753f35eb802cbff28ce5c"],"403d05f7f8d69b65659157eff1bc1d2717f04c66":["4e6bfc2c1eac33d890bf4d5638c8e149e1dcbcca","2c8bedceb91e64a3f0e831450058fc4a76d2c0a6"],"7825da0fed0bd08a466fec72f7c6a18a2abb303d":["4e6bfc2c1eac33d890bf4d5638c8e149e1dcbcca"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"05f4c28bc6a6df30868753f35eb802cbff28ce5c":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"2c8bedceb91e64a3f0e831450058fc4a76d2c0a6":["4e6bfc2c1eac33d890bf4d5638c8e149e1dcbcca","7825da0fed0bd08a466fec72f7c6a18a2abb303d"],"4e6bfc2c1eac33d890bf4d5638c8e149e1dcbcca":["3c738d774d160362ecfdc9887a5fa4beb421872b"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["403d05f7f8d69b65659157eff1bc1d2717f04c66"]},"commit2Childs":{"3c738d774d160362ecfdc9887a5fa4beb421872b":["4e6bfc2c1eac33d890bf4d5638c8e149e1dcbcca"],"403d05f7f8d69b65659157eff1bc1d2717f04c66":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"7825da0fed0bd08a466fec72f7c6a18a2abb303d":["2c8bedceb91e64a3f0e831450058fc4a76d2c0a6"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["3c738d774d160362ecfdc9887a5fa4beb421872b","05f4c28bc6a6df30868753f35eb802cbff28ce5c"],"05f4c28bc6a6df30868753f35eb802cbff28ce5c":["3c738d774d160362ecfdc9887a5fa4beb421872b"],"2c8bedceb91e64a3f0e831450058fc4a76d2c0a6":["403d05f7f8d69b65659157eff1bc1d2717f04c66"],"4e6bfc2c1eac33d890bf4d5638c8e149e1dcbcca":["403d05f7f8d69b65659157eff1bc1d2717f04c66","7825da0fed0bd08a466fec72f7c6a18a2abb303d","2c8bedceb91e64a3f0e831450058fc4a76d2c0a6"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}