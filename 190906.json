{"path":"lucene/core/src/test/org/apache/lucene/index/TestParallelReaderEmptyIndex#testEmptyIndexWithVectors().mjava","commits":[{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":1,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestParallelReaderEmptyIndex#testEmptyIndexWithVectors().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestParallelReaderEmptyIndex#testEmptyIndexWithVectors().mjava","sourceNew":"  /**\n   * This method creates an empty index (numFields=0, numDocs=0) but is marked\n   * to have TermVectors. Adding this index to another index should not throw\n   * any exception.\n   */\n  public void testEmptyIndexWithVectors() throws IOException {\n    Directory rd1 = newDirectory();\n    {\n      IndexWriter iw = new IndexWriter(rd1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n      Document doc = new Document();\n      Field idField = newField(\"id\", \"\", TextField.TYPE_UNSTORED);\n      doc.add(idField);\n      FieldType customType = new FieldType(TextField.TYPE_UNSTORED);\n      customType.setStoreTermVectors(true);\n      doc.add(newField(\"test\", \"\", customType));\n      idField.setValue(\"1\");\n      iw.addDocument(doc);\n      doc.add(newField(\"test\", \"\", TextField.TYPE_UNSTORED));\n      idField.setValue(\"2\");\n      iw.addDocument(doc);\n      iw.close();\n\n      IndexWriterConfig dontMergeConfig = new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random))\n        .setMergePolicy(NoMergePolicy.COMPOUND_FILES);\n      IndexWriter writer = new IndexWriter(rd1, dontMergeConfig);\n      \n      writer.deleteDocuments(new Term(\"id\", \"1\"));\n      writer.close();\n      IndexReader ir = IndexReader.open(rd1);\n      assertEquals(2, ir.maxDoc());\n      assertEquals(1, ir.numDocs());\n      ir.close();\n\n      iw = new IndexWriter(rd1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)).setOpenMode(OpenMode.APPEND));\n      iw.forceMerge(1);\n      iw.close();\n    }\n\n    Directory rd2 = newDirectory();\n    {\n      IndexWriter iw = new IndexWriter(rd2, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n      Document doc = new Document();\n      iw.addDocument(doc);\n      iw.close();\n    }\n\n    Directory rdOut = newDirectory();\n\n    IndexWriter iwOut = new IndexWriter(rdOut, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    ParallelReader pr = new ParallelReader();\n    pr.add(SlowCompositeReaderWrapper.wrap(DirectoryReader.open(rd1)));\n    pr.add(SlowCompositeReaderWrapper.wrap(DirectoryReader.open(rd2)));\n\n    // When unpatched, Lucene crashes here with an ArrayIndexOutOfBoundsException (caused by TermVectorsWriter)\n    iwOut.addIndexes(pr);\n\n    // ParallelReader closes any IndexReader you added to it:\n    pr.close();\n\n    rd1.close();\n    rd2.close();\n\t\t\n    iwOut.forceMerge(1);\n    iwOut.close();\n    \n    rdOut.close();\n  }\n\n","sourceOld":"  /**\n   * This method creates an empty index (numFields=0, numDocs=0) but is marked\n   * to have TermVectors. Adding this index to another index should not throw\n   * any exception.\n   */\n  public void testEmptyIndexWithVectors() throws IOException {\n    Directory rd1 = newDirectory();\n    {\n      IndexWriter iw = new IndexWriter(rd1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n      Document doc = new Document();\n      Field idField = newField(\"id\", \"\", TextField.TYPE_UNSTORED);\n      doc.add(idField);\n      FieldType customType = new FieldType(TextField.TYPE_UNSTORED);\n      customType.setStoreTermVectors(true);\n      doc.add(newField(\"test\", \"\", customType));\n      idField.setValue(\"1\");\n      iw.addDocument(doc);\n      doc.add(newField(\"test\", \"\", TextField.TYPE_UNSTORED));\n      idField.setValue(\"2\");\n      iw.addDocument(doc);\n      iw.close();\n\n      IndexWriterConfig dontMergeConfig = new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random))\n        .setMergePolicy(NoMergePolicy.COMPOUND_FILES);\n      IndexWriter writer = new IndexWriter(rd1, dontMergeConfig);\n      \n      writer.deleteDocuments(new Term(\"id\", \"1\"));\n      writer.close();\n      IndexReader ir = IndexReader.open(rd1);\n      assertEquals(2, ir.maxDoc());\n      assertEquals(1, ir.numDocs());\n      ir.close();\n\n      iw = new IndexWriter(rd1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)).setOpenMode(OpenMode.APPEND));\n      iw.forceMerge(1);\n      iw.close();\n    }\n\n    Directory rd2 = newDirectory();\n    {\n      IndexWriter iw = new IndexWriter(rd2, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n      Document doc = new Document();\n      iw.addDocument(doc);\n      iw.close();\n    }\n\n    Directory rdOut = newDirectory();\n\n    IndexWriter iwOut = new IndexWriter(rdOut, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    ParallelReader pr = new ParallelReader();\n    pr.add(SlowCompositeReaderWrapper.wrap(DirectoryReader.open(rd1)));\n    pr.add(SlowCompositeReaderWrapper.wrap(DirectoryReader.open(rd2)));\n\n    // When unpatched, Lucene crashes here with an ArrayIndexOutOfBoundsException (caused by TermVectorsWriter)\n    iwOut.addIndexes(pr);\n\n    // ParallelReader closes any IndexReader you added to it:\n    pr.close();\n\n    rd1.close();\n    rd2.close();\n\t\t\n    iwOut.forceMerge(1);\n    iwOut.close();\n    \n    rdOut.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6e09a3a223be07d75777515a717312813221fe58","date":1328908385,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestParallelReaderEmptyIndex#testEmptyIndexWithVectors().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestParallelReaderEmptyIndex#testEmptyIndexWithVectors().mjava","sourceNew":"  /**\n   * This method creates an empty index (numFields=0, numDocs=0) but is marked\n   * to have TermVectors. Adding this index to another index should not throw\n   * any exception.\n   */\n  public void testEmptyIndexWithVectors() throws IOException {\n    Directory rd1 = newDirectory();\n    {\n      IndexWriter iw = new IndexWriter(rd1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n      Document doc = new Document();\n      Field idField = newField(\"id\", \"\", TextField.TYPE_UNSTORED);\n      doc.add(idField);\n      FieldType customType = new FieldType(TextField.TYPE_UNSTORED);\n      customType.setStoreTermVectors(true);\n      doc.add(newField(\"test\", \"\", customType));\n      idField.setValue(\"1\");\n      iw.addDocument(doc);\n      doc.add(newField(\"test\", \"\", TextField.TYPE_UNSTORED));\n      idField.setValue(\"2\");\n      iw.addDocument(doc);\n      iw.close();\n\n      IndexWriterConfig dontMergeConfig = new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random))\n        .setMergePolicy(NoMergePolicy.COMPOUND_FILES);\n      IndexWriter writer = new IndexWriter(rd1, dontMergeConfig);\n      \n      writer.deleteDocuments(new Term(\"id\", \"1\"));\n      writer.close();\n      IndexReader ir = IndexReader.open(rd1);\n      assertEquals(2, ir.maxDoc());\n      assertEquals(1, ir.numDocs());\n      ir.close();\n\n      iw = new IndexWriter(rd1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)).setOpenMode(OpenMode.APPEND));\n      iw.forceMerge(1);\n      iw.close();\n    }\n\n    Directory rd2 = newDirectory();\n    {\n      IndexWriter iw = new IndexWriter(rd2, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n      Document doc = new Document();\n      iw.addDocument(doc);\n      iw.close();\n    }\n\n    Directory rdOut = newDirectory();\n\n    IndexWriter iwOut = new IndexWriter(rdOut, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    final DirectoryReader reader1, reader2;\n    ParallelAtomicReader pr = new ParallelAtomicReader(\n        SlowCompositeReaderWrapper.wrap(reader1 = DirectoryReader.open(rd1)),\n        SlowCompositeReaderWrapper.wrap(reader2 = DirectoryReader.open(rd2)));\n\n    // When unpatched, Lucene crashes here with an ArrayIndexOutOfBoundsException (caused by TermVectorsWriter)\n    iwOut.addIndexes(pr);\n\n    // ParallelReader closes any IndexReader you added to it:\n    pr.close();\n    \n    // assert subreaders were closed\n    assertEquals(0, reader1.getRefCount());\n    assertEquals(0, reader2.getRefCount());\n\n    rd1.close();\n    rd2.close();\n\t\t\n    iwOut.forceMerge(1);\n    iwOut.close();\n    \n    rdOut.close();\n  }\n\n","sourceOld":"  /**\n   * This method creates an empty index (numFields=0, numDocs=0) but is marked\n   * to have TermVectors. Adding this index to another index should not throw\n   * any exception.\n   */\n  public void testEmptyIndexWithVectors() throws IOException {\n    Directory rd1 = newDirectory();\n    {\n      IndexWriter iw = new IndexWriter(rd1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n      Document doc = new Document();\n      Field idField = newField(\"id\", \"\", TextField.TYPE_UNSTORED);\n      doc.add(idField);\n      FieldType customType = new FieldType(TextField.TYPE_UNSTORED);\n      customType.setStoreTermVectors(true);\n      doc.add(newField(\"test\", \"\", customType));\n      idField.setValue(\"1\");\n      iw.addDocument(doc);\n      doc.add(newField(\"test\", \"\", TextField.TYPE_UNSTORED));\n      idField.setValue(\"2\");\n      iw.addDocument(doc);\n      iw.close();\n\n      IndexWriterConfig dontMergeConfig = new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random))\n        .setMergePolicy(NoMergePolicy.COMPOUND_FILES);\n      IndexWriter writer = new IndexWriter(rd1, dontMergeConfig);\n      \n      writer.deleteDocuments(new Term(\"id\", \"1\"));\n      writer.close();\n      IndexReader ir = IndexReader.open(rd1);\n      assertEquals(2, ir.maxDoc());\n      assertEquals(1, ir.numDocs());\n      ir.close();\n\n      iw = new IndexWriter(rd1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)).setOpenMode(OpenMode.APPEND));\n      iw.forceMerge(1);\n      iw.close();\n    }\n\n    Directory rd2 = newDirectory();\n    {\n      IndexWriter iw = new IndexWriter(rd2, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n      Document doc = new Document();\n      iw.addDocument(doc);\n      iw.close();\n    }\n\n    Directory rdOut = newDirectory();\n\n    IndexWriter iwOut = new IndexWriter(rdOut, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    ParallelReader pr = new ParallelReader();\n    pr.add(SlowCompositeReaderWrapper.wrap(DirectoryReader.open(rd1)));\n    pr.add(SlowCompositeReaderWrapper.wrap(DirectoryReader.open(rd2)));\n\n    // When unpatched, Lucene crashes here with an ArrayIndexOutOfBoundsException (caused by TermVectorsWriter)\n    iwOut.addIndexes(pr);\n\n    // ParallelReader closes any IndexReader you added to it:\n    pr.close();\n\n    rd1.close();\n    rd2.close();\n\t\t\n    iwOut.forceMerge(1);\n    iwOut.close();\n    \n    rdOut.close();\n  }\n\n","bugFix":null,"bugIntro":["0bdb67d0b49ddf963c3bfc4975fce171ad3aacb1"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"a78a90fc9701e511308346ea29f4f5e548bb39fe","date":1329489995,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestParallelReaderEmptyIndex#testEmptyIndexWithVectors().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestParallelReaderEmptyIndex#testEmptyIndexWithVectors().mjava","sourceNew":"  /**\n   * This method creates an empty index (numFields=0, numDocs=0) but is marked\n   * to have TermVectors. Adding this index to another index should not throw\n   * any exception.\n   */\n  public void testEmptyIndexWithVectors() throws IOException {\n    Directory rd1 = newDirectory();\n    {\n      IndexWriter iw = new IndexWriter(rd1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n      Document doc = new Document();\n      Field idField = newField(\"id\", \"\", TextField.TYPE_UNSTORED);\n      doc.add(idField);\n      FieldType customType = new FieldType(TextField.TYPE_UNSTORED);\n      customType.setStoreTermVectors(true);\n      doc.add(newField(\"test\", \"\", customType));\n      idField.setStringValue(\"1\");\n      iw.addDocument(doc);\n      doc.add(newField(\"test\", \"\", TextField.TYPE_UNSTORED));\n      idField.setStringValue(\"2\");\n      iw.addDocument(doc);\n      iw.close();\n\n      IndexWriterConfig dontMergeConfig = new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random))\n        .setMergePolicy(NoMergePolicy.COMPOUND_FILES);\n      IndexWriter writer = new IndexWriter(rd1, dontMergeConfig);\n      \n      writer.deleteDocuments(new Term(\"id\", \"1\"));\n      writer.close();\n      IndexReader ir = IndexReader.open(rd1);\n      assertEquals(2, ir.maxDoc());\n      assertEquals(1, ir.numDocs());\n      ir.close();\n\n      iw = new IndexWriter(rd1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)).setOpenMode(OpenMode.APPEND));\n      iw.forceMerge(1);\n      iw.close();\n    }\n\n    Directory rd2 = newDirectory();\n    {\n      IndexWriter iw = new IndexWriter(rd2, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n      Document doc = new Document();\n      iw.addDocument(doc);\n      iw.close();\n    }\n\n    Directory rdOut = newDirectory();\n\n    IndexWriter iwOut = new IndexWriter(rdOut, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    final DirectoryReader reader1, reader2;\n    ParallelAtomicReader pr = new ParallelAtomicReader(\n        SlowCompositeReaderWrapper.wrap(reader1 = DirectoryReader.open(rd1)),\n        SlowCompositeReaderWrapper.wrap(reader2 = DirectoryReader.open(rd2)));\n\n    // When unpatched, Lucene crashes here with an ArrayIndexOutOfBoundsException (caused by TermVectorsWriter)\n    iwOut.addIndexes(pr);\n\n    // ParallelReader closes any IndexReader you added to it:\n    pr.close();\n    \n    // assert subreaders were closed\n    assertEquals(0, reader1.getRefCount());\n    assertEquals(0, reader2.getRefCount());\n\n    rd1.close();\n    rd2.close();\n\t\t\n    iwOut.forceMerge(1);\n    iwOut.close();\n    \n    rdOut.close();\n  }\n\n","sourceOld":"  /**\n   * This method creates an empty index (numFields=0, numDocs=0) but is marked\n   * to have TermVectors. Adding this index to another index should not throw\n   * any exception.\n   */\n  public void testEmptyIndexWithVectors() throws IOException {\n    Directory rd1 = newDirectory();\n    {\n      IndexWriter iw = new IndexWriter(rd1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n      Document doc = new Document();\n      Field idField = newField(\"id\", \"\", TextField.TYPE_UNSTORED);\n      doc.add(idField);\n      FieldType customType = new FieldType(TextField.TYPE_UNSTORED);\n      customType.setStoreTermVectors(true);\n      doc.add(newField(\"test\", \"\", customType));\n      idField.setValue(\"1\");\n      iw.addDocument(doc);\n      doc.add(newField(\"test\", \"\", TextField.TYPE_UNSTORED));\n      idField.setValue(\"2\");\n      iw.addDocument(doc);\n      iw.close();\n\n      IndexWriterConfig dontMergeConfig = new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random))\n        .setMergePolicy(NoMergePolicy.COMPOUND_FILES);\n      IndexWriter writer = new IndexWriter(rd1, dontMergeConfig);\n      \n      writer.deleteDocuments(new Term(\"id\", \"1\"));\n      writer.close();\n      IndexReader ir = IndexReader.open(rd1);\n      assertEquals(2, ir.maxDoc());\n      assertEquals(1, ir.numDocs());\n      ir.close();\n\n      iw = new IndexWriter(rd1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)).setOpenMode(OpenMode.APPEND));\n      iw.forceMerge(1);\n      iw.close();\n    }\n\n    Directory rd2 = newDirectory();\n    {\n      IndexWriter iw = new IndexWriter(rd2, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n      Document doc = new Document();\n      iw.addDocument(doc);\n      iw.close();\n    }\n\n    Directory rdOut = newDirectory();\n\n    IndexWriter iwOut = new IndexWriter(rdOut, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    final DirectoryReader reader1, reader2;\n    ParallelAtomicReader pr = new ParallelAtomicReader(\n        SlowCompositeReaderWrapper.wrap(reader1 = DirectoryReader.open(rd1)),\n        SlowCompositeReaderWrapper.wrap(reader2 = DirectoryReader.open(rd2)));\n\n    // When unpatched, Lucene crashes here with an ArrayIndexOutOfBoundsException (caused by TermVectorsWriter)\n    iwOut.addIndexes(pr);\n\n    // ParallelReader closes any IndexReader you added to it:\n    pr.close();\n    \n    // assert subreaders were closed\n    assertEquals(0, reader1.getRefCount());\n    assertEquals(0, reader2.getRefCount());\n\n    rd1.close();\n    rd2.close();\n\t\t\n    iwOut.forceMerge(1);\n    iwOut.close();\n    \n    rdOut.close();\n  }\n\n","bugFix":["74ea7c90f97ad0b2d091b6e143f88b3c2c2c939f"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"629c38c4ae4e303d0617e05fbfe508140b32f0a3","date":1334500904,"type":3,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestParallelReaderEmptyIndex#testEmptyIndexWithVectors().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestParallelReaderEmptyIndex#testEmptyIndexWithVectors().mjava","sourceNew":"  /**\n   * This method creates an empty index (numFields=0, numDocs=0) but is marked\n   * to have TermVectors. Adding this index to another index should not throw\n   * any exception.\n   */\n  public void testEmptyIndexWithVectors() throws IOException {\n    Directory rd1 = newDirectory();\n    {\n      IndexWriter iw = new IndexWriter(rd1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n      Document doc = new Document();\n      Field idField = newField(\"id\", \"\", TextField.TYPE_UNSTORED);\n      doc.add(idField);\n      FieldType customType = new FieldType(TextField.TYPE_UNSTORED);\n      customType.setStoreTermVectors(true);\n      doc.add(newField(\"test\", \"\", customType));\n      idField.setStringValue(\"1\");\n      iw.addDocument(doc);\n      doc.add(newField(\"test\", \"\", TextField.TYPE_UNSTORED));\n      idField.setStringValue(\"2\");\n      iw.addDocument(doc);\n      iw.close();\n\n      IndexWriterConfig dontMergeConfig = new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n        .setMergePolicy(NoMergePolicy.COMPOUND_FILES);\n      IndexWriter writer = new IndexWriter(rd1, dontMergeConfig);\n      \n      writer.deleteDocuments(new Term(\"id\", \"1\"));\n      writer.close();\n      IndexReader ir = IndexReader.open(rd1);\n      assertEquals(2, ir.maxDoc());\n      assertEquals(1, ir.numDocs());\n      ir.close();\n\n      iw = new IndexWriter(rd1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())).setOpenMode(OpenMode.APPEND));\n      iw.forceMerge(1);\n      iw.close();\n    }\n\n    Directory rd2 = newDirectory();\n    {\n      IndexWriter iw = new IndexWriter(rd2, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n      Document doc = new Document();\n      iw.addDocument(doc);\n      iw.close();\n    }\n\n    Directory rdOut = newDirectory();\n\n    IndexWriter iwOut = new IndexWriter(rdOut, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    final DirectoryReader reader1, reader2;\n    ParallelAtomicReader pr = new ParallelAtomicReader(\n        SlowCompositeReaderWrapper.wrap(reader1 = DirectoryReader.open(rd1)),\n        SlowCompositeReaderWrapper.wrap(reader2 = DirectoryReader.open(rd2)));\n\n    // When unpatched, Lucene crashes here with an ArrayIndexOutOfBoundsException (caused by TermVectorsWriter)\n    iwOut.addIndexes(pr);\n\n    // ParallelReader closes any IndexReader you added to it:\n    pr.close();\n    \n    // assert subreaders were closed\n    assertEquals(0, reader1.getRefCount());\n    assertEquals(0, reader2.getRefCount());\n\n    rd1.close();\n    rd2.close();\n\t\t\n    iwOut.forceMerge(1);\n    iwOut.close();\n    \n    rdOut.close();\n  }\n\n","sourceOld":"  /**\n   * This method creates an empty index (numFields=0, numDocs=0) but is marked\n   * to have TermVectors. Adding this index to another index should not throw\n   * any exception.\n   */\n  public void testEmptyIndexWithVectors() throws IOException {\n    Directory rd1 = newDirectory();\n    {\n      IndexWriter iw = new IndexWriter(rd1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n      Document doc = new Document();\n      Field idField = newField(\"id\", \"\", TextField.TYPE_UNSTORED);\n      doc.add(idField);\n      FieldType customType = new FieldType(TextField.TYPE_UNSTORED);\n      customType.setStoreTermVectors(true);\n      doc.add(newField(\"test\", \"\", customType));\n      idField.setStringValue(\"1\");\n      iw.addDocument(doc);\n      doc.add(newField(\"test\", \"\", TextField.TYPE_UNSTORED));\n      idField.setStringValue(\"2\");\n      iw.addDocument(doc);\n      iw.close();\n\n      IndexWriterConfig dontMergeConfig = new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random))\n        .setMergePolicy(NoMergePolicy.COMPOUND_FILES);\n      IndexWriter writer = new IndexWriter(rd1, dontMergeConfig);\n      \n      writer.deleteDocuments(new Term(\"id\", \"1\"));\n      writer.close();\n      IndexReader ir = IndexReader.open(rd1);\n      assertEquals(2, ir.maxDoc());\n      assertEquals(1, ir.numDocs());\n      ir.close();\n\n      iw = new IndexWriter(rd1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)).setOpenMode(OpenMode.APPEND));\n      iw.forceMerge(1);\n      iw.close();\n    }\n\n    Directory rd2 = newDirectory();\n    {\n      IndexWriter iw = new IndexWriter(rd2, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n      Document doc = new Document();\n      iw.addDocument(doc);\n      iw.close();\n    }\n\n    Directory rdOut = newDirectory();\n\n    IndexWriter iwOut = new IndexWriter(rdOut, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    final DirectoryReader reader1, reader2;\n    ParallelAtomicReader pr = new ParallelAtomicReader(\n        SlowCompositeReaderWrapper.wrap(reader1 = DirectoryReader.open(rd1)),\n        SlowCompositeReaderWrapper.wrap(reader2 = DirectoryReader.open(rd2)));\n\n    // When unpatched, Lucene crashes here with an ArrayIndexOutOfBoundsException (caused by TermVectorsWriter)\n    iwOut.addIndexes(pr);\n\n    // ParallelReader closes any IndexReader you added to it:\n    pr.close();\n    \n    // assert subreaders were closed\n    assertEquals(0, reader1.getRefCount());\n    assertEquals(0, reader2.getRefCount());\n\n    rd1.close();\n    rd2.close();\n\t\t\n    iwOut.forceMerge(1);\n    iwOut.close();\n    \n    rdOut.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"4356000e349e38c9fb48034695b7c309abd54557","date":1337460341,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestParallelReaderEmptyIndex#testEmptyIndexWithVectors().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestParallelReaderEmptyIndex#testEmptyIndexWithVectors().mjava","sourceNew":"  /**\n   * This method creates an empty index (numFields=0, numDocs=0) but is marked\n   * to have TermVectors. Adding this index to another index should not throw\n   * any exception.\n   */\n  public void testEmptyIndexWithVectors() throws IOException {\n    Directory rd1 = newDirectory();\n    {\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: make 1st writer\");\n      }\n      IndexWriter iw = new IndexWriter(rd1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n      Document doc = new Document();\n      Field idField = newField(\"id\", \"\", TextField.TYPE_UNSTORED);\n      doc.add(idField);\n      FieldType customType = new FieldType(TextField.TYPE_UNSTORED);\n      customType.setStoreTermVectors(true);\n      doc.add(newField(\"test\", \"\", customType));\n      idField.setStringValue(\"1\");\n      iw.addDocument(doc);\n      doc.add(newField(\"test\", \"\", TextField.TYPE_UNSTORED));\n      idField.setStringValue(\"2\");\n      iw.addDocument(doc);\n      iw.close();\n\n      // nocommit\n      _TestUtil.checkIndex(rd1);\n\n      IndexWriterConfig dontMergeConfig = new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n        .setMergePolicy(NoMergePolicy.COMPOUND_FILES);\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: make 2nd writer\");\n      }\n      IndexWriter writer = new IndexWriter(rd1, dontMergeConfig);\n      \n      writer.deleteDocuments(new Term(\"id\", \"1\"));\n      writer.close();\n      IndexReader ir = IndexReader.open(rd1);\n      assertEquals(2, ir.maxDoc());\n      assertEquals(1, ir.numDocs());\n      ir.close();\n\n      iw = new IndexWriter(rd1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())).setOpenMode(OpenMode.APPEND));\n      iw.forceMerge(1);\n      iw.close();\n    }\n\n    Directory rd2 = newDirectory();\n    {\n      IndexWriter iw = new IndexWriter(rd2, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n      Document doc = new Document();\n      iw.addDocument(doc);\n      iw.close();\n    }\n\n    Directory rdOut = newDirectory();\n\n    IndexWriter iwOut = new IndexWriter(rdOut, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    final DirectoryReader reader1, reader2;\n    ParallelAtomicReader pr = new ParallelAtomicReader(\n        SlowCompositeReaderWrapper.wrap(reader1 = DirectoryReader.open(rd1)),\n        SlowCompositeReaderWrapper.wrap(reader2 = DirectoryReader.open(rd2)));\n\n    // When unpatched, Lucene crashes here with an ArrayIndexOutOfBoundsException (caused by TermVectorsWriter)\n    iwOut.addIndexes(pr);\n\n    // ParallelReader closes any IndexReader you added to it:\n    pr.close();\n    \n    // assert subreaders were closed\n    assertEquals(0, reader1.getRefCount());\n    assertEquals(0, reader2.getRefCount());\n\n    rd1.close();\n    rd2.close();\n\t\t\n    iwOut.forceMerge(1);\n    iwOut.close();\n    \n    rdOut.close();\n  }\n\n","sourceOld":"  /**\n   * This method creates an empty index (numFields=0, numDocs=0) but is marked\n   * to have TermVectors. Adding this index to another index should not throw\n   * any exception.\n   */\n  public void testEmptyIndexWithVectors() throws IOException {\n    Directory rd1 = newDirectory();\n    {\n      IndexWriter iw = new IndexWriter(rd1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n      Document doc = new Document();\n      Field idField = newField(\"id\", \"\", TextField.TYPE_UNSTORED);\n      doc.add(idField);\n      FieldType customType = new FieldType(TextField.TYPE_UNSTORED);\n      customType.setStoreTermVectors(true);\n      doc.add(newField(\"test\", \"\", customType));\n      idField.setStringValue(\"1\");\n      iw.addDocument(doc);\n      doc.add(newField(\"test\", \"\", TextField.TYPE_UNSTORED));\n      idField.setStringValue(\"2\");\n      iw.addDocument(doc);\n      iw.close();\n\n      IndexWriterConfig dontMergeConfig = new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n        .setMergePolicy(NoMergePolicy.COMPOUND_FILES);\n      IndexWriter writer = new IndexWriter(rd1, dontMergeConfig);\n      \n      writer.deleteDocuments(new Term(\"id\", \"1\"));\n      writer.close();\n      IndexReader ir = IndexReader.open(rd1);\n      assertEquals(2, ir.maxDoc());\n      assertEquals(1, ir.numDocs());\n      ir.close();\n\n      iw = new IndexWriter(rd1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())).setOpenMode(OpenMode.APPEND));\n      iw.forceMerge(1);\n      iw.close();\n    }\n\n    Directory rd2 = newDirectory();\n    {\n      IndexWriter iw = new IndexWriter(rd2, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n      Document doc = new Document();\n      iw.addDocument(doc);\n      iw.close();\n    }\n\n    Directory rdOut = newDirectory();\n\n    IndexWriter iwOut = new IndexWriter(rdOut, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    final DirectoryReader reader1, reader2;\n    ParallelAtomicReader pr = new ParallelAtomicReader(\n        SlowCompositeReaderWrapper.wrap(reader1 = DirectoryReader.open(rd1)),\n        SlowCompositeReaderWrapper.wrap(reader2 = DirectoryReader.open(rd2)));\n\n    // When unpatched, Lucene crashes here with an ArrayIndexOutOfBoundsException (caused by TermVectorsWriter)\n    iwOut.addIndexes(pr);\n\n    // ParallelReader closes any IndexReader you added to it:\n    pr.close();\n    \n    // assert subreaders were closed\n    assertEquals(0, reader1.getRefCount());\n    assertEquals(0, reader2.getRefCount());\n\n    rd1.close();\n    rd2.close();\n\t\t\n    iwOut.forceMerge(1);\n    iwOut.close();\n    \n    rdOut.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"352763be0465236f8e2ac188aa1b761cb3e1c9ee","date":1337516554,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestParallelReaderEmptyIndex#testEmptyIndexWithVectors().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestParallelReaderEmptyIndex#testEmptyIndexWithVectors().mjava","sourceNew":"  /**\n   * This method creates an empty index (numFields=0, numDocs=0) but is marked\n   * to have TermVectors. Adding this index to another index should not throw\n   * any exception.\n   */\n  public void testEmptyIndexWithVectors() throws IOException {\n    Directory rd1 = newDirectory();\n    {\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: make 1st writer\");\n      }\n      IndexWriter iw = new IndexWriter(rd1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n      Document doc = new Document();\n      Field idField = newField(\"id\", \"\", TextField.TYPE_UNSTORED);\n      doc.add(idField);\n      FieldType customType = new FieldType(TextField.TYPE_UNSTORED);\n      customType.setStoreTermVectors(true);\n      doc.add(newField(\"test\", \"\", customType));\n      idField.setStringValue(\"1\");\n      iw.addDocument(doc);\n      doc.add(newField(\"test\", \"\", TextField.TYPE_UNSTORED));\n      idField.setStringValue(\"2\");\n      iw.addDocument(doc);\n      iw.close();\n\n      IndexWriterConfig dontMergeConfig = new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n        .setMergePolicy(NoMergePolicy.COMPOUND_FILES);\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: make 2nd writer\");\n      }\n      IndexWriter writer = new IndexWriter(rd1, dontMergeConfig);\n      \n      writer.deleteDocuments(new Term(\"id\", \"1\"));\n      writer.close();\n      IndexReader ir = IndexReader.open(rd1);\n      assertEquals(2, ir.maxDoc());\n      assertEquals(1, ir.numDocs());\n      ir.close();\n\n      iw = new IndexWriter(rd1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())).setOpenMode(OpenMode.APPEND));\n      iw.forceMerge(1);\n      iw.close();\n    }\n\n    Directory rd2 = newDirectory();\n    {\n      IndexWriter iw = new IndexWriter(rd2, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n      Document doc = new Document();\n      iw.addDocument(doc);\n      iw.close();\n    }\n\n    Directory rdOut = newDirectory();\n\n    IndexWriter iwOut = new IndexWriter(rdOut, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    final DirectoryReader reader1, reader2;\n    ParallelAtomicReader pr = new ParallelAtomicReader(\n        SlowCompositeReaderWrapper.wrap(reader1 = DirectoryReader.open(rd1)),\n        SlowCompositeReaderWrapper.wrap(reader2 = DirectoryReader.open(rd2)));\n\n    // When unpatched, Lucene crashes here with an ArrayIndexOutOfBoundsException (caused by TermVectorsWriter)\n    iwOut.addIndexes(pr);\n\n    // ParallelReader closes any IndexReader you added to it:\n    pr.close();\n    \n    // assert subreaders were closed\n    assertEquals(0, reader1.getRefCount());\n    assertEquals(0, reader2.getRefCount());\n\n    rd1.close();\n    rd2.close();\n\t\t\n    iwOut.forceMerge(1);\n    iwOut.close();\n    \n    rdOut.close();\n  }\n\n","sourceOld":"  /**\n   * This method creates an empty index (numFields=0, numDocs=0) but is marked\n   * to have TermVectors. Adding this index to another index should not throw\n   * any exception.\n   */\n  public void testEmptyIndexWithVectors() throws IOException {\n    Directory rd1 = newDirectory();\n    {\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: make 1st writer\");\n      }\n      IndexWriter iw = new IndexWriter(rd1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n      Document doc = new Document();\n      Field idField = newField(\"id\", \"\", TextField.TYPE_UNSTORED);\n      doc.add(idField);\n      FieldType customType = new FieldType(TextField.TYPE_UNSTORED);\n      customType.setStoreTermVectors(true);\n      doc.add(newField(\"test\", \"\", customType));\n      idField.setStringValue(\"1\");\n      iw.addDocument(doc);\n      doc.add(newField(\"test\", \"\", TextField.TYPE_UNSTORED));\n      idField.setStringValue(\"2\");\n      iw.addDocument(doc);\n      iw.close();\n\n      // nocommit\n      _TestUtil.checkIndex(rd1);\n\n      IndexWriterConfig dontMergeConfig = new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n        .setMergePolicy(NoMergePolicy.COMPOUND_FILES);\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: make 2nd writer\");\n      }\n      IndexWriter writer = new IndexWriter(rd1, dontMergeConfig);\n      \n      writer.deleteDocuments(new Term(\"id\", \"1\"));\n      writer.close();\n      IndexReader ir = IndexReader.open(rd1);\n      assertEquals(2, ir.maxDoc());\n      assertEquals(1, ir.numDocs());\n      ir.close();\n\n      iw = new IndexWriter(rd1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())).setOpenMode(OpenMode.APPEND));\n      iw.forceMerge(1);\n      iw.close();\n    }\n\n    Directory rd2 = newDirectory();\n    {\n      IndexWriter iw = new IndexWriter(rd2, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n      Document doc = new Document();\n      iw.addDocument(doc);\n      iw.close();\n    }\n\n    Directory rdOut = newDirectory();\n\n    IndexWriter iwOut = new IndexWriter(rdOut, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    final DirectoryReader reader1, reader2;\n    ParallelAtomicReader pr = new ParallelAtomicReader(\n        SlowCompositeReaderWrapper.wrap(reader1 = DirectoryReader.open(rd1)),\n        SlowCompositeReaderWrapper.wrap(reader2 = DirectoryReader.open(rd2)));\n\n    // When unpatched, Lucene crashes here with an ArrayIndexOutOfBoundsException (caused by TermVectorsWriter)\n    iwOut.addIndexes(pr);\n\n    // ParallelReader closes any IndexReader you added to it:\n    pr.close();\n    \n    // assert subreaders were closed\n    assertEquals(0, reader1.getRefCount());\n    assertEquals(0, reader2.getRefCount());\n\n    rd1.close();\n    rd2.close();\n\t\t\n    iwOut.forceMerge(1);\n    iwOut.close();\n    \n    rdOut.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"615ddbd81799980d0fdd95e0238e1c498b6f47b0","date":1338233290,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestParallelReaderEmptyIndex#testEmptyIndexWithVectors().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestParallelReaderEmptyIndex#testEmptyIndexWithVectors().mjava","sourceNew":"  /**\n   * This method creates an empty index (numFields=0, numDocs=0) but is marked\n   * to have TermVectors. Adding this index to another index should not throw\n   * any exception.\n   */\n  public void testEmptyIndexWithVectors() throws IOException {\n    Directory rd1 = newDirectory();\n    {\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: make 1st writer\");\n      }\n      IndexWriter iw = new IndexWriter(rd1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n      Document doc = new Document();\n      Field idField = newField(\"id\", \"\", TextField.TYPE_UNSTORED);\n      doc.add(idField);\n      FieldType customType = new FieldType(TextField.TYPE_UNSTORED);\n      customType.setStoreTermVectors(true);\n      doc.add(newField(\"test\", \"\", customType));\n      idField.setStringValue(\"1\");\n      iw.addDocument(doc);\n      doc.add(newField(\"test\", \"\", TextField.TYPE_UNSTORED));\n      idField.setStringValue(\"2\");\n      iw.addDocument(doc);\n      iw.close();\n\n      IndexWriterConfig dontMergeConfig = new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n        .setMergePolicy(NoMergePolicy.COMPOUND_FILES);\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: make 2nd writer\");\n      }\n      IndexWriter writer = new IndexWriter(rd1, dontMergeConfig);\n      \n      writer.deleteDocuments(new Term(\"id\", \"1\"));\n      writer.close();\n      IndexReader ir = IndexReader.open(rd1);\n      assertEquals(2, ir.maxDoc());\n      assertEquals(1, ir.numDocs());\n      ir.close();\n\n      iw = new IndexWriter(rd1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())).setOpenMode(OpenMode.APPEND));\n      iw.forceMerge(1);\n      iw.close();\n    }\n\n    Directory rd2 = newDirectory();\n    {\n      IndexWriter iw = new IndexWriter(rd2, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n      Document doc = new Document();\n      iw.addDocument(doc);\n      iw.close();\n    }\n\n    Directory rdOut = newDirectory();\n\n    IndexWriter iwOut = new IndexWriter(rdOut, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    final DirectoryReader reader1, reader2;\n    ParallelAtomicReader pr = new ParallelAtomicReader(\n        SlowCompositeReaderWrapper.wrap(reader1 = DirectoryReader.open(rd1)),\n        SlowCompositeReaderWrapper.wrap(reader2 = DirectoryReader.open(rd2)));\n\n    // When unpatched, Lucene crashes here with an ArrayIndexOutOfBoundsException (caused by TermVectorsWriter)\n    iwOut.addIndexes(pr);\n\n    // ParallelReader closes any IndexReader you added to it:\n    pr.close();\n    \n    // assert subreaders were closed\n    assertEquals(0, reader1.getRefCount());\n    assertEquals(0, reader2.getRefCount());\n\n    rd1.close();\n    rd2.close();\n\t\t\n    iwOut.forceMerge(1);\n    iwOut.close();\n    \n    rdOut.close();\n  }\n\n","sourceOld":"  /**\n   * This method creates an empty index (numFields=0, numDocs=0) but is marked\n   * to have TermVectors. Adding this index to another index should not throw\n   * any exception.\n   */\n  public void testEmptyIndexWithVectors() throws IOException {\n    Directory rd1 = newDirectory();\n    {\n      IndexWriter iw = new IndexWriter(rd1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n      Document doc = new Document();\n      Field idField = newField(\"id\", \"\", TextField.TYPE_UNSTORED);\n      doc.add(idField);\n      FieldType customType = new FieldType(TextField.TYPE_UNSTORED);\n      customType.setStoreTermVectors(true);\n      doc.add(newField(\"test\", \"\", customType));\n      idField.setStringValue(\"1\");\n      iw.addDocument(doc);\n      doc.add(newField(\"test\", \"\", TextField.TYPE_UNSTORED));\n      idField.setStringValue(\"2\");\n      iw.addDocument(doc);\n      iw.close();\n\n      IndexWriterConfig dontMergeConfig = new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n        .setMergePolicy(NoMergePolicy.COMPOUND_FILES);\n      IndexWriter writer = new IndexWriter(rd1, dontMergeConfig);\n      \n      writer.deleteDocuments(new Term(\"id\", \"1\"));\n      writer.close();\n      IndexReader ir = IndexReader.open(rd1);\n      assertEquals(2, ir.maxDoc());\n      assertEquals(1, ir.numDocs());\n      ir.close();\n\n      iw = new IndexWriter(rd1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())).setOpenMode(OpenMode.APPEND));\n      iw.forceMerge(1);\n      iw.close();\n    }\n\n    Directory rd2 = newDirectory();\n    {\n      IndexWriter iw = new IndexWriter(rd2, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n      Document doc = new Document();\n      iw.addDocument(doc);\n      iw.close();\n    }\n\n    Directory rdOut = newDirectory();\n\n    IndexWriter iwOut = new IndexWriter(rdOut, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    final DirectoryReader reader1, reader2;\n    ParallelAtomicReader pr = new ParallelAtomicReader(\n        SlowCompositeReaderWrapper.wrap(reader1 = DirectoryReader.open(rd1)),\n        SlowCompositeReaderWrapper.wrap(reader2 = DirectoryReader.open(rd2)));\n\n    // When unpatched, Lucene crashes here with an ArrayIndexOutOfBoundsException (caused by TermVectorsWriter)\n    iwOut.addIndexes(pr);\n\n    // ParallelReader closes any IndexReader you added to it:\n    pr.close();\n    \n    // assert subreaders were closed\n    assertEquals(0, reader1.getRefCount());\n    assertEquals(0, reader2.getRefCount());\n\n    rd1.close();\n    rd2.close();\n\t\t\n    iwOut.forceMerge(1);\n    iwOut.close();\n    \n    rdOut.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"e7e8d6f15900ee22ac3cb0a503f15dc952a3580f","date":1338430031,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestParallelReaderEmptyIndex#testEmptyIndexWithVectors().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestParallelReaderEmptyIndex#testEmptyIndexWithVectors().mjava","sourceNew":"  /**\n   * This method creates an empty index (numFields=0, numDocs=0) but is marked\n   * to have TermVectors. Adding this index to another index should not throw\n   * any exception.\n   */\n  public void testEmptyIndexWithVectors() throws IOException {\n    Directory rd1 = newDirectory();\n    {\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: make 1st writer\");\n      }\n      IndexWriter iw = new IndexWriter(rd1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n      Document doc = new Document();\n      Field idField = newField(\"id\", \"\", TextField.TYPE_UNSTORED);\n      doc.add(idField);\n      FieldType customType = new FieldType(TextField.TYPE_UNSTORED);\n      customType.setStoreTermVectors(true);\n      doc.add(newField(\"test\", \"\", customType));\n      idField.setStringValue(\"1\");\n      iw.addDocument(doc);\n      doc.add(newField(\"test\", \"\", TextField.TYPE_UNSTORED));\n      idField.setStringValue(\"2\");\n      iw.addDocument(doc);\n      iw.close();\n\n      IndexWriterConfig dontMergeConfig = new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n        .setMergePolicy(NoMergePolicy.COMPOUND_FILES);\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: make 2nd writer\");\n      }\n      IndexWriter writer = new IndexWriter(rd1, dontMergeConfig);\n      \n      writer.deleteDocuments(new Term(\"id\", \"1\"));\n      writer.close();\n      IndexReader ir = DirectoryReader.open(rd1);\n      assertEquals(2, ir.maxDoc());\n      assertEquals(1, ir.numDocs());\n      ir.close();\n\n      iw = new IndexWriter(rd1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())).setOpenMode(OpenMode.APPEND));\n      iw.forceMerge(1);\n      iw.close();\n    }\n\n    Directory rd2 = newDirectory();\n    {\n      IndexWriter iw = new IndexWriter(rd2, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n      Document doc = new Document();\n      iw.addDocument(doc);\n      iw.close();\n    }\n\n    Directory rdOut = newDirectory();\n\n    IndexWriter iwOut = new IndexWriter(rdOut, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    final DirectoryReader reader1, reader2;\n    ParallelAtomicReader pr = new ParallelAtomicReader(\n        SlowCompositeReaderWrapper.wrap(reader1 = DirectoryReader.open(rd1)),\n        SlowCompositeReaderWrapper.wrap(reader2 = DirectoryReader.open(rd2)));\n\n    // When unpatched, Lucene crashes here with an ArrayIndexOutOfBoundsException (caused by TermVectorsWriter)\n    iwOut.addIndexes(pr);\n\n    // ParallelReader closes any IndexReader you added to it:\n    pr.close();\n    \n    // assert subreaders were closed\n    assertEquals(0, reader1.getRefCount());\n    assertEquals(0, reader2.getRefCount());\n\n    rd1.close();\n    rd2.close();\n\t\t\n    iwOut.forceMerge(1);\n    iwOut.close();\n    \n    rdOut.close();\n  }\n\n","sourceOld":"  /**\n   * This method creates an empty index (numFields=0, numDocs=0) but is marked\n   * to have TermVectors. Adding this index to another index should not throw\n   * any exception.\n   */\n  public void testEmptyIndexWithVectors() throws IOException {\n    Directory rd1 = newDirectory();\n    {\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: make 1st writer\");\n      }\n      IndexWriter iw = new IndexWriter(rd1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n      Document doc = new Document();\n      Field idField = newField(\"id\", \"\", TextField.TYPE_UNSTORED);\n      doc.add(idField);\n      FieldType customType = new FieldType(TextField.TYPE_UNSTORED);\n      customType.setStoreTermVectors(true);\n      doc.add(newField(\"test\", \"\", customType));\n      idField.setStringValue(\"1\");\n      iw.addDocument(doc);\n      doc.add(newField(\"test\", \"\", TextField.TYPE_UNSTORED));\n      idField.setStringValue(\"2\");\n      iw.addDocument(doc);\n      iw.close();\n\n      IndexWriterConfig dontMergeConfig = new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n        .setMergePolicy(NoMergePolicy.COMPOUND_FILES);\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: make 2nd writer\");\n      }\n      IndexWriter writer = new IndexWriter(rd1, dontMergeConfig);\n      \n      writer.deleteDocuments(new Term(\"id\", \"1\"));\n      writer.close();\n      IndexReader ir = IndexReader.open(rd1);\n      assertEquals(2, ir.maxDoc());\n      assertEquals(1, ir.numDocs());\n      ir.close();\n\n      iw = new IndexWriter(rd1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())).setOpenMode(OpenMode.APPEND));\n      iw.forceMerge(1);\n      iw.close();\n    }\n\n    Directory rd2 = newDirectory();\n    {\n      IndexWriter iw = new IndexWriter(rd2, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n      Document doc = new Document();\n      iw.addDocument(doc);\n      iw.close();\n    }\n\n    Directory rdOut = newDirectory();\n\n    IndexWriter iwOut = new IndexWriter(rdOut, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    final DirectoryReader reader1, reader2;\n    ParallelAtomicReader pr = new ParallelAtomicReader(\n        SlowCompositeReaderWrapper.wrap(reader1 = DirectoryReader.open(rd1)),\n        SlowCompositeReaderWrapper.wrap(reader2 = DirectoryReader.open(rd2)));\n\n    // When unpatched, Lucene crashes here with an ArrayIndexOutOfBoundsException (caused by TermVectorsWriter)\n    iwOut.addIndexes(pr);\n\n    // ParallelReader closes any IndexReader you added to it:\n    pr.close();\n    \n    // assert subreaders were closed\n    assertEquals(0, reader1.getRefCount());\n    assertEquals(0, reader2.getRefCount());\n\n    rd1.close();\n    rd2.close();\n\t\t\n    iwOut.forceMerge(1);\n    iwOut.close();\n    \n    rdOut.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"04f07771a2a7dd3a395700665ed839c3dae2def2","date":1339350139,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestParallelReaderEmptyIndex#testEmptyIndexWithVectors().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestParallelReaderEmptyIndex#testEmptyIndexWithVectors().mjava","sourceNew":"  /**\n   * This method creates an empty index (numFields=0, numDocs=0) but is marked\n   * to have TermVectors. Adding this index to another index should not throw\n   * any exception.\n   */\n  public void testEmptyIndexWithVectors() throws IOException {\n    Directory rd1 = newDirectory();\n    {\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: make 1st writer\");\n      }\n      IndexWriter iw = new IndexWriter(rd1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n      Document doc = new Document();\n      Field idField = newTextField(\"id\", \"\", Field.Store.NO);\n      doc.add(idField);\n      FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n      customType.setStoreTermVectors(true);\n      doc.add(newField(\"test\", \"\", customType));\n      idField.setStringValue(\"1\");\n      iw.addDocument(doc);\n      doc.add(newTextField(\"test\", \"\", Field.Store.NO));\n      idField.setStringValue(\"2\");\n      iw.addDocument(doc);\n      iw.close();\n\n      IndexWriterConfig dontMergeConfig = new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n        .setMergePolicy(NoMergePolicy.COMPOUND_FILES);\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: make 2nd writer\");\n      }\n      IndexWriter writer = new IndexWriter(rd1, dontMergeConfig);\n      \n      writer.deleteDocuments(new Term(\"id\", \"1\"));\n      writer.close();\n      IndexReader ir = DirectoryReader.open(rd1);\n      assertEquals(2, ir.maxDoc());\n      assertEquals(1, ir.numDocs());\n      ir.close();\n\n      iw = new IndexWriter(rd1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())).setOpenMode(OpenMode.APPEND));\n      iw.forceMerge(1);\n      iw.close();\n    }\n\n    Directory rd2 = newDirectory();\n    {\n      IndexWriter iw = new IndexWriter(rd2, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n      Document doc = new Document();\n      iw.addDocument(doc);\n      iw.close();\n    }\n\n    Directory rdOut = newDirectory();\n\n    IndexWriter iwOut = new IndexWriter(rdOut, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    final DirectoryReader reader1, reader2;\n    ParallelAtomicReader pr = new ParallelAtomicReader(\n        SlowCompositeReaderWrapper.wrap(reader1 = DirectoryReader.open(rd1)),\n        SlowCompositeReaderWrapper.wrap(reader2 = DirectoryReader.open(rd2)));\n\n    // When unpatched, Lucene crashes here with an ArrayIndexOutOfBoundsException (caused by TermVectorsWriter)\n    iwOut.addIndexes(pr);\n\n    // ParallelReader closes any IndexReader you added to it:\n    pr.close();\n    \n    // assert subreaders were closed\n    assertEquals(0, reader1.getRefCount());\n    assertEquals(0, reader2.getRefCount());\n\n    rd1.close();\n    rd2.close();\n\t\t\n    iwOut.forceMerge(1);\n    iwOut.close();\n    \n    rdOut.close();\n  }\n\n","sourceOld":"  /**\n   * This method creates an empty index (numFields=0, numDocs=0) but is marked\n   * to have TermVectors. Adding this index to another index should not throw\n   * any exception.\n   */\n  public void testEmptyIndexWithVectors() throws IOException {\n    Directory rd1 = newDirectory();\n    {\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: make 1st writer\");\n      }\n      IndexWriter iw = new IndexWriter(rd1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n      Document doc = new Document();\n      Field idField = newField(\"id\", \"\", TextField.TYPE_UNSTORED);\n      doc.add(idField);\n      FieldType customType = new FieldType(TextField.TYPE_UNSTORED);\n      customType.setStoreTermVectors(true);\n      doc.add(newField(\"test\", \"\", customType));\n      idField.setStringValue(\"1\");\n      iw.addDocument(doc);\n      doc.add(newField(\"test\", \"\", TextField.TYPE_UNSTORED));\n      idField.setStringValue(\"2\");\n      iw.addDocument(doc);\n      iw.close();\n\n      IndexWriterConfig dontMergeConfig = new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n        .setMergePolicy(NoMergePolicy.COMPOUND_FILES);\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: make 2nd writer\");\n      }\n      IndexWriter writer = new IndexWriter(rd1, dontMergeConfig);\n      \n      writer.deleteDocuments(new Term(\"id\", \"1\"));\n      writer.close();\n      IndexReader ir = DirectoryReader.open(rd1);\n      assertEquals(2, ir.maxDoc());\n      assertEquals(1, ir.numDocs());\n      ir.close();\n\n      iw = new IndexWriter(rd1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())).setOpenMode(OpenMode.APPEND));\n      iw.forceMerge(1);\n      iw.close();\n    }\n\n    Directory rd2 = newDirectory();\n    {\n      IndexWriter iw = new IndexWriter(rd2, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n      Document doc = new Document();\n      iw.addDocument(doc);\n      iw.close();\n    }\n\n    Directory rdOut = newDirectory();\n\n    IndexWriter iwOut = new IndexWriter(rdOut, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    final DirectoryReader reader1, reader2;\n    ParallelAtomicReader pr = new ParallelAtomicReader(\n        SlowCompositeReaderWrapper.wrap(reader1 = DirectoryReader.open(rd1)),\n        SlowCompositeReaderWrapper.wrap(reader2 = DirectoryReader.open(rd2)));\n\n    // When unpatched, Lucene crashes here with an ArrayIndexOutOfBoundsException (caused by TermVectorsWriter)\n    iwOut.addIndexes(pr);\n\n    // ParallelReader closes any IndexReader you added to it:\n    pr.close();\n    \n    // assert subreaders were closed\n    assertEquals(0, reader1.getRefCount());\n    assertEquals(0, reader2.getRefCount());\n\n    rd1.close();\n    rd2.close();\n\t\t\n    iwOut.forceMerge(1);\n    iwOut.close();\n    \n    rdOut.close();\n  }\n\n","bugFix":["74ea7c90f97ad0b2d091b6e143f88b3c2c2c939f"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"4093b270ba337f9c25a4c0e6cb2ae2c07f697376","date":1347897716,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestParallelReaderEmptyIndex#testEmptyIndexWithVectors().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestParallelReaderEmptyIndex#testEmptyIndexWithVectors().mjava","sourceNew":"  /**\n   * This method creates an empty index (numFields=0, numDocs=0) but is marked\n   * to have TermVectors. Adding this index to another index should not throw\n   * any exception.\n   */\n  public void testEmptyIndexWithVectors() throws IOException {\n    Directory rd1 = newDirectory();\n    {\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: make 1st writer\");\n      }\n      IndexWriter iw = new IndexWriter(rd1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n      Document doc = new Document();\n      Field idField = newTextField(\"id\", \"\", Field.Store.NO);\n      doc.add(idField);\n      FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n      customType.setStoreTermVectors(true);\n      doc.add(newField(\"test\", \"\", customType));\n      idField.setStringValue(\"1\");\n      iw.addDocument(doc);\n      doc.add(newTextField(\"test\", \"\", Field.Store.NO));\n      idField.setStringValue(\"2\");\n      iw.addDocument(doc);\n      iw.close();\n\n      IndexWriterConfig dontMergeConfig = new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n        .setMergePolicy(NoMergePolicy.COMPOUND_FILES);\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: make 2nd writer\");\n      }\n      IndexWriter writer = new IndexWriter(rd1, dontMergeConfig);\n      \n      writer.deleteDocuments(new Term(\"id\", \"1\"));\n      writer.close();\n      IndexReader ir = DirectoryReader.open(rd1);\n      assertEquals(2, ir.maxDoc());\n      assertEquals(1, ir.numDocs());\n      ir.close();\n\n      iw = new IndexWriter(rd1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())).setOpenMode(OpenMode.APPEND));\n      iw.forceMerge(1);\n      iw.close();\n    }\n\n    Directory rd2 = newDirectory();\n    {\n      IndexWriter iw = new IndexWriter(rd2, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n      Document doc = new Document();\n      iw.addDocument(doc);\n      iw.close();\n    }\n\n    Directory rdOut = newDirectory();\n\n    IndexWriter iwOut = new IndexWriter(rdOut, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    final DirectoryReader reader1, reader2;\n    ParallelAtomicReader pr = new ParallelAtomicReader(\n        SlowCompositeReaderWrapper.wrap(reader1 = DirectoryReader.open(rd1)),\n        SlowCompositeReaderWrapper.wrap(reader2 = DirectoryReader.open(rd2)));\n\n    // When unpatched, Lucene crashes here with an ArrayIndexOutOfBoundsException (caused by TermVectorsWriter)\n    iwOut.addIndexes(pr);\n\n    // ParallelReader closes any IndexReader you added to it:\n    pr.close();\n    \n    // assert subreaders were closed\n    assertEquals(0, reader1.getRefCount());\n    assertEquals(0, reader2.getRefCount());\n\n    rd1.close();\n    rd2.close();\n\n    iwOut.forceMerge(1);\n    iwOut.close();\n    \n    rdOut.close();\n  }\n\n","sourceOld":"  /**\n   * This method creates an empty index (numFields=0, numDocs=0) but is marked\n   * to have TermVectors. Adding this index to another index should not throw\n   * any exception.\n   */\n  public void testEmptyIndexWithVectors() throws IOException {\n    Directory rd1 = newDirectory();\n    {\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: make 1st writer\");\n      }\n      IndexWriter iw = new IndexWriter(rd1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n      Document doc = new Document();\n      Field idField = newTextField(\"id\", \"\", Field.Store.NO);\n      doc.add(idField);\n      FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n      customType.setStoreTermVectors(true);\n      doc.add(newField(\"test\", \"\", customType));\n      idField.setStringValue(\"1\");\n      iw.addDocument(doc);\n      doc.add(newTextField(\"test\", \"\", Field.Store.NO));\n      idField.setStringValue(\"2\");\n      iw.addDocument(doc);\n      iw.close();\n\n      IndexWriterConfig dontMergeConfig = new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n        .setMergePolicy(NoMergePolicy.COMPOUND_FILES);\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: make 2nd writer\");\n      }\n      IndexWriter writer = new IndexWriter(rd1, dontMergeConfig);\n      \n      writer.deleteDocuments(new Term(\"id\", \"1\"));\n      writer.close();\n      IndexReader ir = DirectoryReader.open(rd1);\n      assertEquals(2, ir.maxDoc());\n      assertEquals(1, ir.numDocs());\n      ir.close();\n\n      iw = new IndexWriter(rd1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())).setOpenMode(OpenMode.APPEND));\n      iw.forceMerge(1);\n      iw.close();\n    }\n\n    Directory rd2 = newDirectory();\n    {\n      IndexWriter iw = new IndexWriter(rd2, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n      Document doc = new Document();\n      iw.addDocument(doc);\n      iw.close();\n    }\n\n    Directory rdOut = newDirectory();\n\n    IndexWriter iwOut = new IndexWriter(rdOut, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    final DirectoryReader reader1, reader2;\n    ParallelAtomicReader pr = new ParallelAtomicReader(\n        SlowCompositeReaderWrapper.wrap(reader1 = DirectoryReader.open(rd1)),\n        SlowCompositeReaderWrapper.wrap(reader2 = DirectoryReader.open(rd2)));\n\n    // When unpatched, Lucene crashes here with an ArrayIndexOutOfBoundsException (caused by TermVectorsWriter)\n    iwOut.addIndexes(pr);\n\n    // ParallelReader closes any IndexReader you added to it:\n    pr.close();\n    \n    // assert subreaders were closed\n    assertEquals(0, reader1.getRefCount());\n    assertEquals(0, reader2.getRefCount());\n\n    rd1.close();\n    rd2.close();\n\t\t\n    iwOut.forceMerge(1);\n    iwOut.close();\n    \n    rdOut.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"ae14298f4eec6d5faee6a149f88ba57d14a6f21a","date":1396971290,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestParallelReaderEmptyIndex#testEmptyIndexWithVectors().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestParallelReaderEmptyIndex#testEmptyIndexWithVectors().mjava","sourceNew":"  /**\n   * This method creates an empty index (numFields=0, numDocs=0) but is marked\n   * to have TermVectors. Adding this index to another index should not throw\n   * any exception.\n   */\n  public void testEmptyIndexWithVectors() throws IOException {\n    Directory rd1 = newDirectory();\n    {\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: make 1st writer\");\n      }\n      IndexWriter iw = new IndexWriter(rd1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n      Document doc = new Document();\n      Field idField = newTextField(\"id\", \"\", Field.Store.NO);\n      doc.add(idField);\n      FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n      customType.setStoreTermVectors(true);\n      doc.add(newField(\"test\", \"\", customType));\n      idField.setStringValue(\"1\");\n      iw.addDocument(doc);\n      doc.add(newTextField(\"test\", \"\", Field.Store.NO));\n      idField.setStringValue(\"2\");\n      iw.addDocument(doc);\n      iw.shutdown();\n\n      IndexWriterConfig dontMergeConfig = new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n        .setMergePolicy(NoMergePolicy.COMPOUND_FILES);\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: make 2nd writer\");\n      }\n      IndexWriter writer = new IndexWriter(rd1, dontMergeConfig);\n      \n      writer.deleteDocuments(new Term(\"id\", \"1\"));\n      writer.shutdown();\n      IndexReader ir = DirectoryReader.open(rd1);\n      assertEquals(2, ir.maxDoc());\n      assertEquals(1, ir.numDocs());\n      ir.close();\n\n      iw = new IndexWriter(rd1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())).setOpenMode(OpenMode.APPEND));\n      iw.forceMerge(1);\n      iw.shutdown();\n    }\n\n    Directory rd2 = newDirectory();\n    {\n      IndexWriter iw = new IndexWriter(rd2, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n      Document doc = new Document();\n      iw.addDocument(doc);\n      iw.shutdown();\n    }\n\n    Directory rdOut = newDirectory();\n\n    IndexWriter iwOut = new IndexWriter(rdOut, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    final DirectoryReader reader1, reader2;\n    ParallelAtomicReader pr = new ParallelAtomicReader(\n        SlowCompositeReaderWrapper.wrap(reader1 = DirectoryReader.open(rd1)),\n        SlowCompositeReaderWrapper.wrap(reader2 = DirectoryReader.open(rd2)));\n\n    // When unpatched, Lucene crashes here with an ArrayIndexOutOfBoundsException (caused by TermVectorsWriter)\n    iwOut.addIndexes(pr);\n\n    // ParallelReader closes any IndexReader you added to it:\n    pr.close();\n    \n    // assert subreaders were closed\n    assertEquals(0, reader1.getRefCount());\n    assertEquals(0, reader2.getRefCount());\n\n    rd1.close();\n    rd2.close();\n\n    iwOut.forceMerge(1);\n    iwOut.shutdown();\n    \n    rdOut.close();\n  }\n\n","sourceOld":"  /**\n   * This method creates an empty index (numFields=0, numDocs=0) but is marked\n   * to have TermVectors. Adding this index to another index should not throw\n   * any exception.\n   */\n  public void testEmptyIndexWithVectors() throws IOException {\n    Directory rd1 = newDirectory();\n    {\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: make 1st writer\");\n      }\n      IndexWriter iw = new IndexWriter(rd1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n      Document doc = new Document();\n      Field idField = newTextField(\"id\", \"\", Field.Store.NO);\n      doc.add(idField);\n      FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n      customType.setStoreTermVectors(true);\n      doc.add(newField(\"test\", \"\", customType));\n      idField.setStringValue(\"1\");\n      iw.addDocument(doc);\n      doc.add(newTextField(\"test\", \"\", Field.Store.NO));\n      idField.setStringValue(\"2\");\n      iw.addDocument(doc);\n      iw.close();\n\n      IndexWriterConfig dontMergeConfig = new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n        .setMergePolicy(NoMergePolicy.COMPOUND_FILES);\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: make 2nd writer\");\n      }\n      IndexWriter writer = new IndexWriter(rd1, dontMergeConfig);\n      \n      writer.deleteDocuments(new Term(\"id\", \"1\"));\n      writer.close();\n      IndexReader ir = DirectoryReader.open(rd1);\n      assertEquals(2, ir.maxDoc());\n      assertEquals(1, ir.numDocs());\n      ir.close();\n\n      iw = new IndexWriter(rd1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())).setOpenMode(OpenMode.APPEND));\n      iw.forceMerge(1);\n      iw.close();\n    }\n\n    Directory rd2 = newDirectory();\n    {\n      IndexWriter iw = new IndexWriter(rd2, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n      Document doc = new Document();\n      iw.addDocument(doc);\n      iw.close();\n    }\n\n    Directory rdOut = newDirectory();\n\n    IndexWriter iwOut = new IndexWriter(rdOut, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    final DirectoryReader reader1, reader2;\n    ParallelAtomicReader pr = new ParallelAtomicReader(\n        SlowCompositeReaderWrapper.wrap(reader1 = DirectoryReader.open(rd1)),\n        SlowCompositeReaderWrapper.wrap(reader2 = DirectoryReader.open(rd2)));\n\n    // When unpatched, Lucene crashes here with an ArrayIndexOutOfBoundsException (caused by TermVectorsWriter)\n    iwOut.addIndexes(pr);\n\n    // ParallelReader closes any IndexReader you added to it:\n    pr.close();\n    \n    // assert subreaders were closed\n    assertEquals(0, reader1.getRefCount());\n    assertEquals(0, reader2.getRefCount());\n\n    rd1.close();\n    rd2.close();\n\n    iwOut.forceMerge(1);\n    iwOut.close();\n    \n    rdOut.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"52c7e49be259508735752fba88085255014a6ecf","date":1398706273,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestParallelReaderEmptyIndex#testEmptyIndexWithVectors().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestParallelReaderEmptyIndex#testEmptyIndexWithVectors().mjava","sourceNew":"  /**\n   * This method creates an empty index (numFields=0, numDocs=0) but is marked\n   * to have TermVectors. Adding this index to another index should not throw\n   * any exception.\n   */\n  public void testEmptyIndexWithVectors() throws IOException {\n    Directory rd1 = newDirectory();\n    {\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: make 1st writer\");\n      }\n      IndexWriter iw = new IndexWriter(rd1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n      Document doc = new Document();\n      Field idField = newTextField(\"id\", \"\", Field.Store.NO);\n      doc.add(idField);\n      FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n      customType.setStoreTermVectors(true);\n      doc.add(newField(\"test\", \"\", customType));\n      idField.setStringValue(\"1\");\n      iw.addDocument(doc);\n      doc.add(newField(\"test\", \"\", customType));\n      idField.setStringValue(\"2\");\n      iw.addDocument(doc);\n      iw.shutdown();\n\n      IndexWriterConfig dontMergeConfig = new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n        .setMergePolicy(NoMergePolicy.COMPOUND_FILES);\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: make 2nd writer\");\n      }\n      IndexWriter writer = new IndexWriter(rd1, dontMergeConfig);\n      \n      writer.deleteDocuments(new Term(\"id\", \"1\"));\n      writer.shutdown();\n      IndexReader ir = DirectoryReader.open(rd1);\n      assertEquals(2, ir.maxDoc());\n      assertEquals(1, ir.numDocs());\n      ir.close();\n\n      iw = new IndexWriter(rd1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())).setOpenMode(OpenMode.APPEND));\n      iw.forceMerge(1);\n      iw.shutdown();\n    }\n\n    Directory rd2 = newDirectory();\n    {\n      IndexWriter iw = new IndexWriter(rd2, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n      Document doc = new Document();\n      iw.addDocument(doc);\n      iw.shutdown();\n    }\n\n    Directory rdOut = newDirectory();\n\n    IndexWriter iwOut = new IndexWriter(rdOut, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    final DirectoryReader reader1, reader2;\n    ParallelAtomicReader pr = new ParallelAtomicReader(\n        SlowCompositeReaderWrapper.wrap(reader1 = DirectoryReader.open(rd1)),\n        SlowCompositeReaderWrapper.wrap(reader2 = DirectoryReader.open(rd2)));\n\n    // When unpatched, Lucene crashes here with an ArrayIndexOutOfBoundsException (caused by TermVectorsWriter)\n    iwOut.addIndexes(pr);\n\n    // ParallelReader closes any IndexReader you added to it:\n    pr.close();\n    \n    // assert subreaders were closed\n    assertEquals(0, reader1.getRefCount());\n    assertEquals(0, reader2.getRefCount());\n\n    rd1.close();\n    rd2.close();\n\n    iwOut.forceMerge(1);\n    iwOut.shutdown();\n    \n    rdOut.close();\n  }\n\n","sourceOld":"  /**\n   * This method creates an empty index (numFields=0, numDocs=0) but is marked\n   * to have TermVectors. Adding this index to another index should not throw\n   * any exception.\n   */\n  public void testEmptyIndexWithVectors() throws IOException {\n    Directory rd1 = newDirectory();\n    {\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: make 1st writer\");\n      }\n      IndexWriter iw = new IndexWriter(rd1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n      Document doc = new Document();\n      Field idField = newTextField(\"id\", \"\", Field.Store.NO);\n      doc.add(idField);\n      FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n      customType.setStoreTermVectors(true);\n      doc.add(newField(\"test\", \"\", customType));\n      idField.setStringValue(\"1\");\n      iw.addDocument(doc);\n      doc.add(newTextField(\"test\", \"\", Field.Store.NO));\n      idField.setStringValue(\"2\");\n      iw.addDocument(doc);\n      iw.shutdown();\n\n      IndexWriterConfig dontMergeConfig = new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n        .setMergePolicy(NoMergePolicy.COMPOUND_FILES);\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: make 2nd writer\");\n      }\n      IndexWriter writer = new IndexWriter(rd1, dontMergeConfig);\n      \n      writer.deleteDocuments(new Term(\"id\", \"1\"));\n      writer.shutdown();\n      IndexReader ir = DirectoryReader.open(rd1);\n      assertEquals(2, ir.maxDoc());\n      assertEquals(1, ir.numDocs());\n      ir.close();\n\n      iw = new IndexWriter(rd1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())).setOpenMode(OpenMode.APPEND));\n      iw.forceMerge(1);\n      iw.shutdown();\n    }\n\n    Directory rd2 = newDirectory();\n    {\n      IndexWriter iw = new IndexWriter(rd2, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n      Document doc = new Document();\n      iw.addDocument(doc);\n      iw.shutdown();\n    }\n\n    Directory rdOut = newDirectory();\n\n    IndexWriter iwOut = new IndexWriter(rdOut, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    final DirectoryReader reader1, reader2;\n    ParallelAtomicReader pr = new ParallelAtomicReader(\n        SlowCompositeReaderWrapper.wrap(reader1 = DirectoryReader.open(rd1)),\n        SlowCompositeReaderWrapper.wrap(reader2 = DirectoryReader.open(rd2)));\n\n    // When unpatched, Lucene crashes here with an ArrayIndexOutOfBoundsException (caused by TermVectorsWriter)\n    iwOut.addIndexes(pr);\n\n    // ParallelReader closes any IndexReader you added to it:\n    pr.close();\n    \n    // assert subreaders were closed\n    assertEquals(0, reader1.getRefCount());\n    assertEquals(0, reader2.getRefCount());\n\n    rd1.close();\n    rd2.close();\n\n    iwOut.forceMerge(1);\n    iwOut.shutdown();\n    \n    rdOut.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"3394716f52b34ab259ad5247e7595d9f9db6e935","date":1398791921,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestParallelReaderEmptyIndex#testEmptyIndexWithVectors().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestParallelReaderEmptyIndex#testEmptyIndexWithVectors().mjava","sourceNew":"  /**\n   * This method creates an empty index (numFields=0, numDocs=0) but is marked\n   * to have TermVectors. Adding this index to another index should not throw\n   * any exception.\n   */\n  public void testEmptyIndexWithVectors() throws IOException {\n    Directory rd1 = newDirectory();\n    {\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: make 1st writer\");\n      }\n      IndexWriter iw = new IndexWriter(rd1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n      Document doc = new Document();\n      Field idField = newTextField(\"id\", \"\", Field.Store.NO);\n      doc.add(idField);\n      FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n      customType.setStoreTermVectors(true);\n      doc.add(newField(\"test\", \"\", customType));\n      idField.setStringValue(\"1\");\n      iw.addDocument(doc);\n      doc.add(newField(\"test\", \"\", customType));\n      idField.setStringValue(\"2\");\n      iw.addDocument(doc);\n      iw.shutdown();\n\n      IndexWriterConfig dontMergeConfig = new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n        .setMergePolicy(NoMergePolicy.COMPOUND_FILES);\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: make 2nd writer\");\n      }\n      IndexWriter writer = new IndexWriter(rd1, dontMergeConfig);\n      \n      writer.deleteDocuments(new Term(\"id\", \"1\"));\n      writer.shutdown();\n      IndexReader ir = DirectoryReader.open(rd1);\n      assertEquals(2, ir.maxDoc());\n      assertEquals(1, ir.numDocs());\n      ir.close();\n\n      iw = new IndexWriter(rd1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())).setOpenMode(OpenMode.APPEND));\n      iw.forceMerge(1);\n      iw.shutdown();\n    }\n\n    Directory rd2 = newDirectory();\n    {\n      IndexWriter iw = new IndexWriter(rd2, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n      Document doc = new Document();\n      iw.addDocument(doc);\n      iw.shutdown();\n    }\n\n    Directory rdOut = newDirectory();\n\n    IndexWriter iwOut = new IndexWriter(rdOut, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    final DirectoryReader reader1, reader2;\n    ParallelAtomicReader pr = new ParallelAtomicReader(\n        SlowCompositeReaderWrapper.wrap(reader1 = DirectoryReader.open(rd1)),\n        SlowCompositeReaderWrapper.wrap(reader2 = DirectoryReader.open(rd2)));\n\n    // When unpatched, Lucene crashes here with an ArrayIndexOutOfBoundsException (caused by TermVectorsWriter)\n    iwOut.addIndexes(pr);\n\n    // ParallelReader closes any IndexReader you added to it:\n    pr.close();\n    \n    // assert subreaders were closed\n    assertEquals(0, reader1.getRefCount());\n    assertEquals(0, reader2.getRefCount());\n\n    rd1.close();\n    rd2.close();\n\n    iwOut.forceMerge(1);\n    iwOut.shutdown();\n    \n    rdOut.close();\n  }\n\n","sourceOld":"  /**\n   * This method creates an empty index (numFields=0, numDocs=0) but is marked\n   * to have TermVectors. Adding this index to another index should not throw\n   * any exception.\n   */\n  public void testEmptyIndexWithVectors() throws IOException {\n    Directory rd1 = newDirectory();\n    {\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: make 1st writer\");\n      }\n      IndexWriter iw = new IndexWriter(rd1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n      Document doc = new Document();\n      Field idField = newTextField(\"id\", \"\", Field.Store.NO);\n      doc.add(idField);\n      FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n      customType.setStoreTermVectors(true);\n      doc.add(newField(\"test\", \"\", customType));\n      idField.setStringValue(\"1\");\n      iw.addDocument(doc);\n      doc.add(newTextField(\"test\", \"\", Field.Store.NO));\n      idField.setStringValue(\"2\");\n      iw.addDocument(doc);\n      iw.shutdown();\n\n      IndexWriterConfig dontMergeConfig = new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n        .setMergePolicy(NoMergePolicy.COMPOUND_FILES);\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: make 2nd writer\");\n      }\n      IndexWriter writer = new IndexWriter(rd1, dontMergeConfig);\n      \n      writer.deleteDocuments(new Term(\"id\", \"1\"));\n      writer.shutdown();\n      IndexReader ir = DirectoryReader.open(rd1);\n      assertEquals(2, ir.maxDoc());\n      assertEquals(1, ir.numDocs());\n      ir.close();\n\n      iw = new IndexWriter(rd1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())).setOpenMode(OpenMode.APPEND));\n      iw.forceMerge(1);\n      iw.shutdown();\n    }\n\n    Directory rd2 = newDirectory();\n    {\n      IndexWriter iw = new IndexWriter(rd2, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n      Document doc = new Document();\n      iw.addDocument(doc);\n      iw.shutdown();\n    }\n\n    Directory rdOut = newDirectory();\n\n    IndexWriter iwOut = new IndexWriter(rdOut, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    final DirectoryReader reader1, reader2;\n    ParallelAtomicReader pr = new ParallelAtomicReader(\n        SlowCompositeReaderWrapper.wrap(reader1 = DirectoryReader.open(rd1)),\n        SlowCompositeReaderWrapper.wrap(reader2 = DirectoryReader.open(rd2)));\n\n    // When unpatched, Lucene crashes here with an ArrayIndexOutOfBoundsException (caused by TermVectorsWriter)\n    iwOut.addIndexes(pr);\n\n    // ParallelReader closes any IndexReader you added to it:\n    pr.close();\n    \n    // assert subreaders were closed\n    assertEquals(0, reader1.getRefCount());\n    assertEquals(0, reader2.getRefCount());\n\n    rd1.close();\n    rd2.close();\n\n    iwOut.forceMerge(1);\n    iwOut.shutdown();\n    \n    rdOut.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"c0cd85fde84cb318b4dc97710dcf15e2959a1bbe","date":1398844771,"type":3,"author":"Dawid Weiss","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestParallelReaderEmptyIndex#testEmptyIndexWithVectors().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestParallelReaderEmptyIndex#testEmptyIndexWithVectors().mjava","sourceNew":"  /**\n   * This method creates an empty index (numFields=0, numDocs=0) but is marked\n   * to have TermVectors. Adding this index to another index should not throw\n   * any exception.\n   */\n  public void testEmptyIndexWithVectors() throws IOException {\n    Directory rd1 = newDirectory();\n    {\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: make 1st writer\");\n      }\n      IndexWriter iw = new IndexWriter(rd1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n      Document doc = new Document();\n      Field idField = newTextField(\"id\", \"\", Field.Store.NO);\n      doc.add(idField);\n      FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n      customType.setStoreTermVectors(true);\n      doc.add(newField(\"test\", \"\", customType));\n      idField.setStringValue(\"1\");\n      iw.addDocument(doc);\n      doc.add(newField(\"test\", \"\", customType));\n      idField.setStringValue(\"2\");\n      iw.addDocument(doc);\n      iw.shutdown();\n\n      IndexWriterConfig dontMergeConfig = new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n        .setMergePolicy(NoMergePolicy.COMPOUND_FILES);\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: make 2nd writer\");\n      }\n      IndexWriter writer = new IndexWriter(rd1, dontMergeConfig);\n      \n      writer.deleteDocuments(new Term(\"id\", \"1\"));\n      writer.shutdown();\n      IndexReader ir = DirectoryReader.open(rd1);\n      assertEquals(2, ir.maxDoc());\n      assertEquals(1, ir.numDocs());\n      ir.close();\n\n      iw = new IndexWriter(rd1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())).setOpenMode(OpenMode.APPEND));\n      iw.forceMerge(1);\n      iw.shutdown();\n    }\n\n    Directory rd2 = newDirectory();\n    {\n      IndexWriter iw = new IndexWriter(rd2, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n      Document doc = new Document();\n      iw.addDocument(doc);\n      iw.shutdown();\n    }\n\n    Directory rdOut = newDirectory();\n\n    IndexWriter iwOut = new IndexWriter(rdOut, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    final DirectoryReader reader1, reader2;\n    ParallelAtomicReader pr = new ParallelAtomicReader(\n        SlowCompositeReaderWrapper.wrap(reader1 = DirectoryReader.open(rd1)),\n        SlowCompositeReaderWrapper.wrap(reader2 = DirectoryReader.open(rd2)));\n\n    // When unpatched, Lucene crashes here with an ArrayIndexOutOfBoundsException (caused by TermVectorsWriter)\n    iwOut.addIndexes(pr);\n\n    // ParallelReader closes any IndexReader you added to it:\n    pr.close();\n    \n    // assert subreaders were closed\n    assertEquals(0, reader1.getRefCount());\n    assertEquals(0, reader2.getRefCount());\n\n    rd1.close();\n    rd2.close();\n\n    iwOut.forceMerge(1);\n    iwOut.shutdown();\n    \n    rdOut.close();\n  }\n\n","sourceOld":"  /**\n   * This method creates an empty index (numFields=0, numDocs=0) but is marked\n   * to have TermVectors. Adding this index to another index should not throw\n   * any exception.\n   */\n  public void testEmptyIndexWithVectors() throws IOException {\n    Directory rd1 = newDirectory();\n    {\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: make 1st writer\");\n      }\n      IndexWriter iw = new IndexWriter(rd1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n      Document doc = new Document();\n      Field idField = newTextField(\"id\", \"\", Field.Store.NO);\n      doc.add(idField);\n      FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n      customType.setStoreTermVectors(true);\n      doc.add(newField(\"test\", \"\", customType));\n      idField.setStringValue(\"1\");\n      iw.addDocument(doc);\n      doc.add(newTextField(\"test\", \"\", Field.Store.NO));\n      idField.setStringValue(\"2\");\n      iw.addDocument(doc);\n      iw.shutdown();\n\n      IndexWriterConfig dontMergeConfig = new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n        .setMergePolicy(NoMergePolicy.COMPOUND_FILES);\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: make 2nd writer\");\n      }\n      IndexWriter writer = new IndexWriter(rd1, dontMergeConfig);\n      \n      writer.deleteDocuments(new Term(\"id\", \"1\"));\n      writer.shutdown();\n      IndexReader ir = DirectoryReader.open(rd1);\n      assertEquals(2, ir.maxDoc());\n      assertEquals(1, ir.numDocs());\n      ir.close();\n\n      iw = new IndexWriter(rd1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())).setOpenMode(OpenMode.APPEND));\n      iw.forceMerge(1);\n      iw.shutdown();\n    }\n\n    Directory rd2 = newDirectory();\n    {\n      IndexWriter iw = new IndexWriter(rd2, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n      Document doc = new Document();\n      iw.addDocument(doc);\n      iw.shutdown();\n    }\n\n    Directory rdOut = newDirectory();\n\n    IndexWriter iwOut = new IndexWriter(rdOut, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    final DirectoryReader reader1, reader2;\n    ParallelAtomicReader pr = new ParallelAtomicReader(\n        SlowCompositeReaderWrapper.wrap(reader1 = DirectoryReader.open(rd1)),\n        SlowCompositeReaderWrapper.wrap(reader2 = DirectoryReader.open(rd2)));\n\n    // When unpatched, Lucene crashes here with an ArrayIndexOutOfBoundsException (caused by TermVectorsWriter)\n    iwOut.addIndexes(pr);\n\n    // ParallelReader closes any IndexReader you added to it:\n    pr.close();\n    \n    // assert subreaders were closed\n    assertEquals(0, reader1.getRefCount());\n    assertEquals(0, reader2.getRefCount());\n\n    rd1.close();\n    rd2.close();\n\n    iwOut.forceMerge(1);\n    iwOut.shutdown();\n    \n    rdOut.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7e2fb55c0777755badd3b46d8140f3d4301febed","date":1398881584,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestParallelReaderEmptyIndex#testEmptyIndexWithVectors().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestParallelReaderEmptyIndex#testEmptyIndexWithVectors().mjava","sourceNew":"  /**\n   * This method creates an empty index (numFields=0, numDocs=0) but is marked\n   * to have TermVectors. Adding this index to another index should not throw\n   * any exception.\n   */\n  public void testEmptyIndexWithVectors() throws IOException {\n    Directory rd1 = newDirectory();\n    {\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: make 1st writer\");\n      }\n      IndexWriter iw = new IndexWriter(rd1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n      Document doc = new Document();\n      Field idField = newTextField(\"id\", \"\", Field.Store.NO);\n      doc.add(idField);\n      FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n      customType.setStoreTermVectors(true);\n      doc.add(newField(\"test\", \"\", customType));\n      idField.setStringValue(\"1\");\n      iw.addDocument(doc);\n      doc.add(newField(\"test\", \"\", customType));\n      idField.setStringValue(\"2\");\n      iw.addDocument(doc);\n      iw.shutdown();\n\n      IndexWriterConfig dontMergeConfig = new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n        .setMergePolicy(NoMergePolicy.INSTANCE);\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: make 2nd writer\");\n      }\n      IndexWriter writer = new IndexWriter(rd1, dontMergeConfig);\n      \n      writer.deleteDocuments(new Term(\"id\", \"1\"));\n      writer.shutdown();\n      IndexReader ir = DirectoryReader.open(rd1);\n      assertEquals(2, ir.maxDoc());\n      assertEquals(1, ir.numDocs());\n      ir.close();\n\n      iw = new IndexWriter(rd1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())).setOpenMode(OpenMode.APPEND));\n      iw.forceMerge(1);\n      iw.shutdown();\n    }\n\n    Directory rd2 = newDirectory();\n    {\n      IndexWriter iw = new IndexWriter(rd2, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n      Document doc = new Document();\n      iw.addDocument(doc);\n      iw.shutdown();\n    }\n\n    Directory rdOut = newDirectory();\n\n    IndexWriter iwOut = new IndexWriter(rdOut, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    final DirectoryReader reader1, reader2;\n    ParallelAtomicReader pr = new ParallelAtomicReader(\n        SlowCompositeReaderWrapper.wrap(reader1 = DirectoryReader.open(rd1)),\n        SlowCompositeReaderWrapper.wrap(reader2 = DirectoryReader.open(rd2)));\n\n    // When unpatched, Lucene crashes here with an ArrayIndexOutOfBoundsException (caused by TermVectorsWriter)\n    iwOut.addIndexes(pr);\n\n    // ParallelReader closes any IndexReader you added to it:\n    pr.close();\n    \n    // assert subreaders were closed\n    assertEquals(0, reader1.getRefCount());\n    assertEquals(0, reader2.getRefCount());\n\n    rd1.close();\n    rd2.close();\n\n    iwOut.forceMerge(1);\n    iwOut.shutdown();\n    \n    rdOut.close();\n  }\n\n","sourceOld":"  /**\n   * This method creates an empty index (numFields=0, numDocs=0) but is marked\n   * to have TermVectors. Adding this index to another index should not throw\n   * any exception.\n   */\n  public void testEmptyIndexWithVectors() throws IOException {\n    Directory rd1 = newDirectory();\n    {\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: make 1st writer\");\n      }\n      IndexWriter iw = new IndexWriter(rd1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n      Document doc = new Document();\n      Field idField = newTextField(\"id\", \"\", Field.Store.NO);\n      doc.add(idField);\n      FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n      customType.setStoreTermVectors(true);\n      doc.add(newField(\"test\", \"\", customType));\n      idField.setStringValue(\"1\");\n      iw.addDocument(doc);\n      doc.add(newField(\"test\", \"\", customType));\n      idField.setStringValue(\"2\");\n      iw.addDocument(doc);\n      iw.shutdown();\n\n      IndexWriterConfig dontMergeConfig = new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n        .setMergePolicy(NoMergePolicy.COMPOUND_FILES);\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: make 2nd writer\");\n      }\n      IndexWriter writer = new IndexWriter(rd1, dontMergeConfig);\n      \n      writer.deleteDocuments(new Term(\"id\", \"1\"));\n      writer.shutdown();\n      IndexReader ir = DirectoryReader.open(rd1);\n      assertEquals(2, ir.maxDoc());\n      assertEquals(1, ir.numDocs());\n      ir.close();\n\n      iw = new IndexWriter(rd1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())).setOpenMode(OpenMode.APPEND));\n      iw.forceMerge(1);\n      iw.shutdown();\n    }\n\n    Directory rd2 = newDirectory();\n    {\n      IndexWriter iw = new IndexWriter(rd2, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n      Document doc = new Document();\n      iw.addDocument(doc);\n      iw.shutdown();\n    }\n\n    Directory rdOut = newDirectory();\n\n    IndexWriter iwOut = new IndexWriter(rdOut, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    final DirectoryReader reader1, reader2;\n    ParallelAtomicReader pr = new ParallelAtomicReader(\n        SlowCompositeReaderWrapper.wrap(reader1 = DirectoryReader.open(rd1)),\n        SlowCompositeReaderWrapper.wrap(reader2 = DirectoryReader.open(rd2)));\n\n    // When unpatched, Lucene crashes here with an ArrayIndexOutOfBoundsException (caused by TermVectorsWriter)\n    iwOut.addIndexes(pr);\n\n    // ParallelReader closes any IndexReader you added to it:\n    pr.close();\n    \n    // assert subreaders were closed\n    assertEquals(0, reader1.getRefCount());\n    assertEquals(0, reader2.getRefCount());\n\n    rd1.close();\n    rd2.close();\n\n    iwOut.forceMerge(1);\n    iwOut.shutdown();\n    \n    rdOut.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e","date":1406737224,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestParallelReaderEmptyIndex#testEmptyIndexWithVectors().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestParallelReaderEmptyIndex#testEmptyIndexWithVectors().mjava","sourceNew":"  /**\n   * This method creates an empty index (numFields=0, numDocs=0) but is marked\n   * to have TermVectors. Adding this index to another index should not throw\n   * any exception.\n   */\n  public void testEmptyIndexWithVectors() throws IOException {\n    Directory rd1 = newDirectory();\n    {\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: make 1st writer\");\n      }\n      IndexWriter iw = new IndexWriter(rd1, newIndexWriterConfig(new MockAnalyzer(random())));\n      Document doc = new Document();\n      Field idField = newTextField(\"id\", \"\", Field.Store.NO);\n      doc.add(idField);\n      FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n      customType.setStoreTermVectors(true);\n      doc.add(newField(\"test\", \"\", customType));\n      idField.setStringValue(\"1\");\n      iw.addDocument(doc);\n      doc.add(newField(\"test\", \"\", customType));\n      idField.setStringValue(\"2\");\n      iw.addDocument(doc);\n      iw.shutdown();\n\n      IndexWriterConfig dontMergeConfig = new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n        .setMergePolicy(NoMergePolicy.INSTANCE);\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: make 2nd writer\");\n      }\n      IndexWriter writer = new IndexWriter(rd1, dontMergeConfig);\n      \n      writer.deleteDocuments(new Term(\"id\", \"1\"));\n      writer.shutdown();\n      IndexReader ir = DirectoryReader.open(rd1);\n      assertEquals(2, ir.maxDoc());\n      assertEquals(1, ir.numDocs());\n      ir.close();\n\n      iw = new IndexWriter(rd1, newIndexWriterConfig(new MockAnalyzer(random()))\n                                  .setOpenMode(OpenMode.APPEND));\n      iw.forceMerge(1);\n      iw.shutdown();\n    }\n\n    Directory rd2 = newDirectory();\n    {\n      IndexWriter iw = new IndexWriter(rd2, newIndexWriterConfig(new MockAnalyzer(random())));\n      Document doc = new Document();\n      iw.addDocument(doc);\n      iw.shutdown();\n    }\n\n    Directory rdOut = newDirectory();\n\n    IndexWriter iwOut = new IndexWriter(rdOut, newIndexWriterConfig(new MockAnalyzer(random())));\n    final DirectoryReader reader1, reader2;\n    ParallelAtomicReader pr = new ParallelAtomicReader(\n        SlowCompositeReaderWrapper.wrap(reader1 = DirectoryReader.open(rd1)),\n        SlowCompositeReaderWrapper.wrap(reader2 = DirectoryReader.open(rd2)));\n\n    // When unpatched, Lucene crashes here with an ArrayIndexOutOfBoundsException (caused by TermVectorsWriter)\n    iwOut.addIndexes(pr);\n\n    // ParallelReader closes any IndexReader you added to it:\n    pr.close();\n    \n    // assert subreaders were closed\n    assertEquals(0, reader1.getRefCount());\n    assertEquals(0, reader2.getRefCount());\n\n    rd1.close();\n    rd2.close();\n\n    iwOut.forceMerge(1);\n    iwOut.shutdown();\n    \n    rdOut.close();\n  }\n\n","sourceOld":"  /**\n   * This method creates an empty index (numFields=0, numDocs=0) but is marked\n   * to have TermVectors. Adding this index to another index should not throw\n   * any exception.\n   */\n  public void testEmptyIndexWithVectors() throws IOException {\n    Directory rd1 = newDirectory();\n    {\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: make 1st writer\");\n      }\n      IndexWriter iw = new IndexWriter(rd1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n      Document doc = new Document();\n      Field idField = newTextField(\"id\", \"\", Field.Store.NO);\n      doc.add(idField);\n      FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n      customType.setStoreTermVectors(true);\n      doc.add(newField(\"test\", \"\", customType));\n      idField.setStringValue(\"1\");\n      iw.addDocument(doc);\n      doc.add(newField(\"test\", \"\", customType));\n      idField.setStringValue(\"2\");\n      iw.addDocument(doc);\n      iw.shutdown();\n\n      IndexWriterConfig dontMergeConfig = new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n        .setMergePolicy(NoMergePolicy.INSTANCE);\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: make 2nd writer\");\n      }\n      IndexWriter writer = new IndexWriter(rd1, dontMergeConfig);\n      \n      writer.deleteDocuments(new Term(\"id\", \"1\"));\n      writer.shutdown();\n      IndexReader ir = DirectoryReader.open(rd1);\n      assertEquals(2, ir.maxDoc());\n      assertEquals(1, ir.numDocs());\n      ir.close();\n\n      iw = new IndexWriter(rd1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())).setOpenMode(OpenMode.APPEND));\n      iw.forceMerge(1);\n      iw.shutdown();\n    }\n\n    Directory rd2 = newDirectory();\n    {\n      IndexWriter iw = new IndexWriter(rd2, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n      Document doc = new Document();\n      iw.addDocument(doc);\n      iw.shutdown();\n    }\n\n    Directory rdOut = newDirectory();\n\n    IndexWriter iwOut = new IndexWriter(rdOut, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    final DirectoryReader reader1, reader2;\n    ParallelAtomicReader pr = new ParallelAtomicReader(\n        SlowCompositeReaderWrapper.wrap(reader1 = DirectoryReader.open(rd1)),\n        SlowCompositeReaderWrapper.wrap(reader2 = DirectoryReader.open(rd2)));\n\n    // When unpatched, Lucene crashes here with an ArrayIndexOutOfBoundsException (caused by TermVectorsWriter)\n    iwOut.addIndexes(pr);\n\n    // ParallelReader closes any IndexReader you added to it:\n    pr.close();\n    \n    // assert subreaders were closed\n    assertEquals(0, reader1.getRefCount());\n    assertEquals(0, reader2.getRefCount());\n\n    rd1.close();\n    rd2.close();\n\n    iwOut.forceMerge(1);\n    iwOut.shutdown();\n    \n    rdOut.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d0ef034a4f10871667ae75181537775ddcf8ade4","date":1407610475,"type":3,"author":"Ryan Ernst","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestParallelReaderEmptyIndex#testEmptyIndexWithVectors().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestParallelReaderEmptyIndex#testEmptyIndexWithVectors().mjava","sourceNew":"  /**\n   * This method creates an empty index (numFields=0, numDocs=0) but is marked\n   * to have TermVectors. Adding this index to another index should not throw\n   * any exception.\n   */\n  public void testEmptyIndexWithVectors() throws IOException {\n    Directory rd1 = newDirectory();\n    {\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: make 1st writer\");\n      }\n      IndexWriter iw = new IndexWriter(rd1, newIndexWriterConfig(new MockAnalyzer(random())));\n      Document doc = new Document();\n      Field idField = newTextField(\"id\", \"\", Field.Store.NO);\n      doc.add(idField);\n      FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n      customType.setStoreTermVectors(true);\n      doc.add(newField(\"test\", \"\", customType));\n      idField.setStringValue(\"1\");\n      iw.addDocument(doc);\n      doc.add(newField(\"test\", \"\", customType));\n      idField.setStringValue(\"2\");\n      iw.addDocument(doc);\n      iw.close();\n\n      IndexWriterConfig dontMergeConfig = new IndexWriterConfig(new MockAnalyzer(random()))\n        .setMergePolicy(NoMergePolicy.INSTANCE);\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: make 2nd writer\");\n      }\n      IndexWriter writer = new IndexWriter(rd1, dontMergeConfig);\n      \n      writer.deleteDocuments(new Term(\"id\", \"1\"));\n      writer.close();\n      IndexReader ir = DirectoryReader.open(rd1);\n      assertEquals(2, ir.maxDoc());\n      assertEquals(1, ir.numDocs());\n      ir.close();\n\n      iw = new IndexWriter(rd1, newIndexWriterConfig(new MockAnalyzer(random()))\n                                  .setOpenMode(OpenMode.APPEND));\n      iw.forceMerge(1);\n      iw.close();\n    }\n\n    Directory rd2 = newDirectory();\n    {\n      IndexWriter iw = new IndexWriter(rd2, newIndexWriterConfig(new MockAnalyzer(random())));\n      Document doc = new Document();\n      iw.addDocument(doc);\n      iw.close();\n    }\n\n    Directory rdOut = newDirectory();\n\n    IndexWriter iwOut = new IndexWriter(rdOut, newIndexWriterConfig(new MockAnalyzer(random())));\n    final DirectoryReader reader1, reader2;\n    ParallelAtomicReader pr = new ParallelAtomicReader(\n        SlowCompositeReaderWrapper.wrap(reader1 = DirectoryReader.open(rd1)),\n        SlowCompositeReaderWrapper.wrap(reader2 = DirectoryReader.open(rd2)));\n\n    // When unpatched, Lucene crashes here with an ArrayIndexOutOfBoundsException (caused by TermVectorsWriter)\n    iwOut.addIndexes(pr);\n\n    // ParallelReader closes any IndexReader you added to it:\n    pr.close();\n    \n    // assert subreaders were closed\n    assertEquals(0, reader1.getRefCount());\n    assertEquals(0, reader2.getRefCount());\n\n    rd1.close();\n    rd2.close();\n\n    iwOut.forceMerge(1);\n    iwOut.close();\n    \n    rdOut.close();\n  }\n\n","sourceOld":"  /**\n   * This method creates an empty index (numFields=0, numDocs=0) but is marked\n   * to have TermVectors. Adding this index to another index should not throw\n   * any exception.\n   */\n  public void testEmptyIndexWithVectors() throws IOException {\n    Directory rd1 = newDirectory();\n    {\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: make 1st writer\");\n      }\n      IndexWriter iw = new IndexWriter(rd1, newIndexWriterConfig(new MockAnalyzer(random())));\n      Document doc = new Document();\n      Field idField = newTextField(\"id\", \"\", Field.Store.NO);\n      doc.add(idField);\n      FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n      customType.setStoreTermVectors(true);\n      doc.add(newField(\"test\", \"\", customType));\n      idField.setStringValue(\"1\");\n      iw.addDocument(doc);\n      doc.add(newField(\"test\", \"\", customType));\n      idField.setStringValue(\"2\");\n      iw.addDocument(doc);\n      iw.shutdown();\n\n      IndexWriterConfig dontMergeConfig = new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n        .setMergePolicy(NoMergePolicy.INSTANCE);\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: make 2nd writer\");\n      }\n      IndexWriter writer = new IndexWriter(rd1, dontMergeConfig);\n      \n      writer.deleteDocuments(new Term(\"id\", \"1\"));\n      writer.shutdown();\n      IndexReader ir = DirectoryReader.open(rd1);\n      assertEquals(2, ir.maxDoc());\n      assertEquals(1, ir.numDocs());\n      ir.close();\n\n      iw = new IndexWriter(rd1, newIndexWriterConfig(new MockAnalyzer(random()))\n                                  .setOpenMode(OpenMode.APPEND));\n      iw.forceMerge(1);\n      iw.shutdown();\n    }\n\n    Directory rd2 = newDirectory();\n    {\n      IndexWriter iw = new IndexWriter(rd2, newIndexWriterConfig(new MockAnalyzer(random())));\n      Document doc = new Document();\n      iw.addDocument(doc);\n      iw.shutdown();\n    }\n\n    Directory rdOut = newDirectory();\n\n    IndexWriter iwOut = new IndexWriter(rdOut, newIndexWriterConfig(new MockAnalyzer(random())));\n    final DirectoryReader reader1, reader2;\n    ParallelAtomicReader pr = new ParallelAtomicReader(\n        SlowCompositeReaderWrapper.wrap(reader1 = DirectoryReader.open(rd1)),\n        SlowCompositeReaderWrapper.wrap(reader2 = DirectoryReader.open(rd2)));\n\n    // When unpatched, Lucene crashes here with an ArrayIndexOutOfBoundsException (caused by TermVectorsWriter)\n    iwOut.addIndexes(pr);\n\n    // ParallelReader closes any IndexReader you added to it:\n    pr.close();\n    \n    // assert subreaders were closed\n    assertEquals(0, reader1.getRefCount());\n    assertEquals(0, reader2.getRefCount());\n\n    rd1.close();\n    rd2.close();\n\n    iwOut.forceMerge(1);\n    iwOut.shutdown();\n    \n    rdOut.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"c9fb5f46e264daf5ba3860defe623a89d202dd87","date":1411516315,"type":3,"author":"Ryan Ernst","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestParallelReaderEmptyIndex#testEmptyIndexWithVectors().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestParallelReaderEmptyIndex#testEmptyIndexWithVectors().mjava","sourceNew":"  /**\n   * This method creates an empty index (numFields=0, numDocs=0) but is marked\n   * to have TermVectors. Adding this index to another index should not throw\n   * any exception.\n   */\n  public void testEmptyIndexWithVectors() throws IOException {\n    Directory rd1 = newDirectory();\n    {\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: make 1st writer\");\n      }\n      IndexWriter iw = new IndexWriter(rd1, newIndexWriterConfig(new MockAnalyzer(random())));\n      Document doc = new Document();\n      Field idField = newTextField(\"id\", \"\", Field.Store.NO);\n      doc.add(idField);\n      FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n      customType.setStoreTermVectors(true);\n      doc.add(newField(\"test\", \"\", customType));\n      idField.setStringValue(\"1\");\n      iw.addDocument(doc);\n      doc.add(newField(\"test\", \"\", customType));\n      idField.setStringValue(\"2\");\n      iw.addDocument(doc);\n      iw.close();\n\n      IndexWriterConfig dontMergeConfig = new IndexWriterConfig(new MockAnalyzer(random()))\n        .setMergePolicy(NoMergePolicy.INSTANCE);\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: make 2nd writer\");\n      }\n      IndexWriter writer = new IndexWriter(rd1, dontMergeConfig);\n      \n      writer.deleteDocuments(new Term(\"id\", \"1\"));\n      writer.close();\n      IndexReader ir = DirectoryReader.open(rd1);\n      assertEquals(2, ir.maxDoc());\n      assertEquals(1, ir.numDocs());\n      ir.close();\n\n      iw = new IndexWriter(rd1, newIndexWriterConfig(new MockAnalyzer(random()))\n                                  .setOpenMode(OpenMode.APPEND));\n      iw.forceMerge(1);\n      iw.close();\n    }\n\n    Directory rd2 = newDirectory();\n    {\n      IndexWriter iw = new IndexWriter(rd2, newIndexWriterConfig(new MockAnalyzer(random())));\n      Document doc = new Document();\n      iw.addDocument(doc);\n      iw.close();\n    }\n\n    Directory rdOut = newDirectory();\n\n    IndexWriter iwOut = new IndexWriter(rdOut, newIndexWriterConfig(new MockAnalyzer(random())));\n    final DirectoryReader reader1, reader2;\n    ParallelLeafReader pr = new ParallelLeafReader(\n        SlowCompositeReaderWrapper.wrap(reader1 = DirectoryReader.open(rd1)),\n        SlowCompositeReaderWrapper.wrap(reader2 = DirectoryReader.open(rd2)));\n\n    // When unpatched, Lucene crashes here with an ArrayIndexOutOfBoundsException (caused by TermVectorsWriter)\n    iwOut.addIndexes(pr);\n\n    // ParallelReader closes any IndexReader you added to it:\n    pr.close();\n    \n    // assert subreaders were closed\n    assertEquals(0, reader1.getRefCount());\n    assertEquals(0, reader2.getRefCount());\n\n    rd1.close();\n    rd2.close();\n\n    iwOut.forceMerge(1);\n    iwOut.close();\n    \n    rdOut.close();\n  }\n\n","sourceOld":"  /**\n   * This method creates an empty index (numFields=0, numDocs=0) but is marked\n   * to have TermVectors. Adding this index to another index should not throw\n   * any exception.\n   */\n  public void testEmptyIndexWithVectors() throws IOException {\n    Directory rd1 = newDirectory();\n    {\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: make 1st writer\");\n      }\n      IndexWriter iw = new IndexWriter(rd1, newIndexWriterConfig(new MockAnalyzer(random())));\n      Document doc = new Document();\n      Field idField = newTextField(\"id\", \"\", Field.Store.NO);\n      doc.add(idField);\n      FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n      customType.setStoreTermVectors(true);\n      doc.add(newField(\"test\", \"\", customType));\n      idField.setStringValue(\"1\");\n      iw.addDocument(doc);\n      doc.add(newField(\"test\", \"\", customType));\n      idField.setStringValue(\"2\");\n      iw.addDocument(doc);\n      iw.close();\n\n      IndexWriterConfig dontMergeConfig = new IndexWriterConfig(new MockAnalyzer(random()))\n        .setMergePolicy(NoMergePolicy.INSTANCE);\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: make 2nd writer\");\n      }\n      IndexWriter writer = new IndexWriter(rd1, dontMergeConfig);\n      \n      writer.deleteDocuments(new Term(\"id\", \"1\"));\n      writer.close();\n      IndexReader ir = DirectoryReader.open(rd1);\n      assertEquals(2, ir.maxDoc());\n      assertEquals(1, ir.numDocs());\n      ir.close();\n\n      iw = new IndexWriter(rd1, newIndexWriterConfig(new MockAnalyzer(random()))\n                                  .setOpenMode(OpenMode.APPEND));\n      iw.forceMerge(1);\n      iw.close();\n    }\n\n    Directory rd2 = newDirectory();\n    {\n      IndexWriter iw = new IndexWriter(rd2, newIndexWriterConfig(new MockAnalyzer(random())));\n      Document doc = new Document();\n      iw.addDocument(doc);\n      iw.close();\n    }\n\n    Directory rdOut = newDirectory();\n\n    IndexWriter iwOut = new IndexWriter(rdOut, newIndexWriterConfig(new MockAnalyzer(random())));\n    final DirectoryReader reader1, reader2;\n    ParallelAtomicReader pr = new ParallelAtomicReader(\n        SlowCompositeReaderWrapper.wrap(reader1 = DirectoryReader.open(rd1)),\n        SlowCompositeReaderWrapper.wrap(reader2 = DirectoryReader.open(rd2)));\n\n    // When unpatched, Lucene crashes here with an ArrayIndexOutOfBoundsException (caused by TermVectorsWriter)\n    iwOut.addIndexes(pr);\n\n    // ParallelReader closes any IndexReader you added to it:\n    pr.close();\n    \n    // assert subreaders were closed\n    assertEquals(0, reader1.getRefCount());\n    assertEquals(0, reader2.getRefCount());\n\n    rd1.close();\n    rd2.close();\n\n    iwOut.forceMerge(1);\n    iwOut.close();\n    \n    rdOut.close();\n  }\n\n","bugFix":null,"bugIntro":["0bdb67d0b49ddf963c3bfc4975fce171ad3aacb1"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"505bff044e47a553f461b6f4484d1d08faf4ac85","date":1420728783,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestParallelReaderEmptyIndex#testEmptyIndexWithVectors().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestParallelReaderEmptyIndex#testEmptyIndexWithVectors().mjava","sourceNew":"  /**\n   * This method creates an empty index (numFields=0, numDocs=0) but is marked\n   * to have TermVectors. Adding this index to another index should not throw\n   * any exception.\n   */\n  public void testEmptyIndexWithVectors() throws IOException {\n    Directory rd1 = newDirectory();\n    {\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: make 1st writer\");\n      }\n      IndexWriter iw = new IndexWriter(rd1, newIndexWriterConfig(new MockAnalyzer(random())));\n      Document doc = new Document();\n      Field idField = newTextField(\"id\", \"\", Field.Store.NO);\n      doc.add(idField);\n      FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n      customType.setStoreTermVectors(true);\n      doc.add(newField(\"test\", \"\", customType));\n      idField.setStringValue(\"1\");\n      iw.addDocument(doc);\n      doc.add(newField(\"test\", \"\", customType));\n      idField.setStringValue(\"2\");\n      iw.addDocument(doc);\n      iw.close();\n\n      IndexWriterConfig dontMergeConfig = new IndexWriterConfig(new MockAnalyzer(random()))\n        .setMergePolicy(NoMergePolicy.INSTANCE);\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: make 2nd writer\");\n      }\n      IndexWriter writer = new IndexWriter(rd1, dontMergeConfig);\n      \n      writer.deleteDocuments(new Term(\"id\", \"1\"));\n      writer.close();\n      IndexReader ir = DirectoryReader.open(rd1);\n      assertEquals(2, ir.maxDoc());\n      assertEquals(1, ir.numDocs());\n      ir.close();\n\n      iw = new IndexWriter(rd1, newIndexWriterConfig(new MockAnalyzer(random()))\n                                  .setOpenMode(OpenMode.APPEND));\n      iw.forceMerge(1);\n      iw.close();\n    }\n\n    Directory rd2 = newDirectory();\n    {\n      IndexWriter iw = new IndexWriter(rd2, newIndexWriterConfig(new MockAnalyzer(random())));\n      Document doc = new Document();\n      iw.addDocument(doc);\n      iw.close();\n    }\n\n    Directory rdOut = newDirectory();\n\n    IndexWriter iwOut = new IndexWriter(rdOut, newIndexWriterConfig(new MockAnalyzer(random())));\n    final DirectoryReader reader1, reader2;\n    ParallelLeafReader pr = new ParallelLeafReader(\n        SlowCompositeReaderWrapper.wrap(reader1 = DirectoryReader.open(rd1)),\n        SlowCompositeReaderWrapper.wrap(reader2 = DirectoryReader.open(rd2)));\n\n    // When unpatched, Lucene crashes here with an ArrayIndexOutOfBoundsException (caused by TermVectorsWriter)\n    iwOut.addIndexes(SlowCodecReaderWrapper.wrap(pr));\n\n    // ParallelReader closes any IndexReader you added to it:\n    pr.close();\n    \n    // assert subreaders were closed\n    assertEquals(0, reader1.getRefCount());\n    assertEquals(0, reader2.getRefCount());\n\n    rd1.close();\n    rd2.close();\n\n    iwOut.forceMerge(1);\n    iwOut.close();\n    \n    rdOut.close();\n  }\n\n","sourceOld":"  /**\n   * This method creates an empty index (numFields=0, numDocs=0) but is marked\n   * to have TermVectors. Adding this index to another index should not throw\n   * any exception.\n   */\n  public void testEmptyIndexWithVectors() throws IOException {\n    Directory rd1 = newDirectory();\n    {\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: make 1st writer\");\n      }\n      IndexWriter iw = new IndexWriter(rd1, newIndexWriterConfig(new MockAnalyzer(random())));\n      Document doc = new Document();\n      Field idField = newTextField(\"id\", \"\", Field.Store.NO);\n      doc.add(idField);\n      FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n      customType.setStoreTermVectors(true);\n      doc.add(newField(\"test\", \"\", customType));\n      idField.setStringValue(\"1\");\n      iw.addDocument(doc);\n      doc.add(newField(\"test\", \"\", customType));\n      idField.setStringValue(\"2\");\n      iw.addDocument(doc);\n      iw.close();\n\n      IndexWriterConfig dontMergeConfig = new IndexWriterConfig(new MockAnalyzer(random()))\n        .setMergePolicy(NoMergePolicy.INSTANCE);\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: make 2nd writer\");\n      }\n      IndexWriter writer = new IndexWriter(rd1, dontMergeConfig);\n      \n      writer.deleteDocuments(new Term(\"id\", \"1\"));\n      writer.close();\n      IndexReader ir = DirectoryReader.open(rd1);\n      assertEquals(2, ir.maxDoc());\n      assertEquals(1, ir.numDocs());\n      ir.close();\n\n      iw = new IndexWriter(rd1, newIndexWriterConfig(new MockAnalyzer(random()))\n                                  .setOpenMode(OpenMode.APPEND));\n      iw.forceMerge(1);\n      iw.close();\n    }\n\n    Directory rd2 = newDirectory();\n    {\n      IndexWriter iw = new IndexWriter(rd2, newIndexWriterConfig(new MockAnalyzer(random())));\n      Document doc = new Document();\n      iw.addDocument(doc);\n      iw.close();\n    }\n\n    Directory rdOut = newDirectory();\n\n    IndexWriter iwOut = new IndexWriter(rdOut, newIndexWriterConfig(new MockAnalyzer(random())));\n    final DirectoryReader reader1, reader2;\n    ParallelLeafReader pr = new ParallelLeafReader(\n        SlowCompositeReaderWrapper.wrap(reader1 = DirectoryReader.open(rd1)),\n        SlowCompositeReaderWrapper.wrap(reader2 = DirectoryReader.open(rd2)));\n\n    // When unpatched, Lucene crashes here with an ArrayIndexOutOfBoundsException (caused by TermVectorsWriter)\n    iwOut.addIndexes(pr);\n\n    // ParallelReader closes any IndexReader you added to it:\n    pr.close();\n    \n    // assert subreaders were closed\n    assertEquals(0, reader1.getRefCount());\n    assertEquals(0, reader2.getRefCount());\n\n    rd1.close();\n    rd2.close();\n\n    iwOut.forceMerge(1);\n    iwOut.close();\n    \n    rdOut.close();\n  }\n\n","bugFix":["74ea7c90f97ad0b2d091b6e143f88b3c2c2c939f"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"0bdb67d0b49ddf963c3bfc4975fce171ad3aacb1","date":1457644139,"type":3,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestParallelReaderEmptyIndex#testEmptyIndexWithVectors().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestParallelReaderEmptyIndex#testEmptyIndexWithVectors().mjava","sourceNew":"  /**\n   * This method creates an empty index (numFields=0, numDocs=0) but is marked\n   * to have TermVectors. Adding this index to another index should not throw\n   * any exception.\n   */\n  public void testEmptyIndexWithVectors() throws IOException {\n    Directory rd1 = newDirectory();\n    {\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: make 1st writer\");\n      }\n      IndexWriter iw = new IndexWriter(rd1, newIndexWriterConfig(new MockAnalyzer(random())));\n      Document doc = new Document();\n      Field idField = newTextField(\"id\", \"\", Field.Store.NO);\n      doc.add(idField);\n      FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n      customType.setStoreTermVectors(true);\n      doc.add(newField(\"test\", \"\", customType));\n      idField.setStringValue(\"1\");\n      iw.addDocument(doc);\n      doc.add(newField(\"test\", \"\", customType));\n      idField.setStringValue(\"2\");\n      iw.addDocument(doc);\n      iw.close();\n\n      IndexWriterConfig dontMergeConfig = new IndexWriterConfig(new MockAnalyzer(random()))\n        .setMergePolicy(NoMergePolicy.INSTANCE);\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: make 2nd writer\");\n      }\n      IndexWriter writer = new IndexWriter(rd1, dontMergeConfig);\n      \n      writer.deleteDocuments(new Term(\"id\", \"1\"));\n      writer.close();\n      IndexReader ir = DirectoryReader.open(rd1);\n      assertEquals(2, ir.maxDoc());\n      assertEquals(1, ir.numDocs());\n      ir.close();\n\n      iw = new IndexWriter(rd1, newIndexWriterConfig(new MockAnalyzer(random()))\n                                  .setOpenMode(OpenMode.APPEND));\n      iw.forceMerge(1);\n      iw.close();\n    }\n\n    Directory rd2 = newDirectory();\n    {\n      IndexWriter iw = new IndexWriter(rd2, newIndexWriterConfig(new MockAnalyzer(random())));\n      Document doc = new Document();\n      iw.addDocument(doc);\n      iw.close();\n    }\n\n    Directory rdOut = newDirectory();\n\n    IndexWriter iwOut = new IndexWriter(rdOut, newIndexWriterConfig(new MockAnalyzer(random())));\n    DirectoryReader reader1 = DirectoryReader.open(rd1);\n    DirectoryReader reader2 = DirectoryReader.open(rd2);\n    ParallelLeafReader pr = new ParallelLeafReader(false,\n                                                   getOnlyLeafReader(reader1),\n                                                   getOnlyLeafReader(reader2));\n\n    // When unpatched, Lucene crashes here with an ArrayIndexOutOfBoundsException (caused by TermVectorsWriter)\n    iwOut.addIndexes(SlowCodecReaderWrapper.wrap(pr));\n\n    pr.close();\n    reader1.close();\n    reader2.close();\n    \n    // assert subreaders were closed\n    assertEquals(0, reader1.getRefCount());\n    assertEquals(0, reader2.getRefCount());\n\n    rd1.close();\n    rd2.close();\n\n    iwOut.forceMerge(1);\n    iwOut.close();\n    \n    rdOut.close();\n  }\n\n","sourceOld":"  /**\n   * This method creates an empty index (numFields=0, numDocs=0) but is marked\n   * to have TermVectors. Adding this index to another index should not throw\n   * any exception.\n   */\n  public void testEmptyIndexWithVectors() throws IOException {\n    Directory rd1 = newDirectory();\n    {\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: make 1st writer\");\n      }\n      IndexWriter iw = new IndexWriter(rd1, newIndexWriterConfig(new MockAnalyzer(random())));\n      Document doc = new Document();\n      Field idField = newTextField(\"id\", \"\", Field.Store.NO);\n      doc.add(idField);\n      FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n      customType.setStoreTermVectors(true);\n      doc.add(newField(\"test\", \"\", customType));\n      idField.setStringValue(\"1\");\n      iw.addDocument(doc);\n      doc.add(newField(\"test\", \"\", customType));\n      idField.setStringValue(\"2\");\n      iw.addDocument(doc);\n      iw.close();\n\n      IndexWriterConfig dontMergeConfig = new IndexWriterConfig(new MockAnalyzer(random()))\n        .setMergePolicy(NoMergePolicy.INSTANCE);\n      if (VERBOSE) {\n        System.out.println(\"\\nTEST: make 2nd writer\");\n      }\n      IndexWriter writer = new IndexWriter(rd1, dontMergeConfig);\n      \n      writer.deleteDocuments(new Term(\"id\", \"1\"));\n      writer.close();\n      IndexReader ir = DirectoryReader.open(rd1);\n      assertEquals(2, ir.maxDoc());\n      assertEquals(1, ir.numDocs());\n      ir.close();\n\n      iw = new IndexWriter(rd1, newIndexWriterConfig(new MockAnalyzer(random()))\n                                  .setOpenMode(OpenMode.APPEND));\n      iw.forceMerge(1);\n      iw.close();\n    }\n\n    Directory rd2 = newDirectory();\n    {\n      IndexWriter iw = new IndexWriter(rd2, newIndexWriterConfig(new MockAnalyzer(random())));\n      Document doc = new Document();\n      iw.addDocument(doc);\n      iw.close();\n    }\n\n    Directory rdOut = newDirectory();\n\n    IndexWriter iwOut = new IndexWriter(rdOut, newIndexWriterConfig(new MockAnalyzer(random())));\n    final DirectoryReader reader1, reader2;\n    ParallelLeafReader pr = new ParallelLeafReader(\n        SlowCompositeReaderWrapper.wrap(reader1 = DirectoryReader.open(rd1)),\n        SlowCompositeReaderWrapper.wrap(reader2 = DirectoryReader.open(rd2)));\n\n    // When unpatched, Lucene crashes here with an ArrayIndexOutOfBoundsException (caused by TermVectorsWriter)\n    iwOut.addIndexes(SlowCodecReaderWrapper.wrap(pr));\n\n    // ParallelReader closes any IndexReader you added to it:\n    pr.close();\n    \n    // assert subreaders were closed\n    assertEquals(0, reader1.getRefCount());\n    assertEquals(0, reader2.getRefCount());\n\n    rd1.close();\n    rd2.close();\n\n    iwOut.forceMerge(1);\n    iwOut.close();\n    \n    rdOut.close();\n  }\n\n","bugFix":["c9fb5f46e264daf5ba3860defe623a89d202dd87","74ea7c90f97ad0b2d091b6e143f88b3c2c2c939f","6e09a3a223be07d75777515a717312813221fe58"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"7e2fb55c0777755badd3b46d8140f3d4301febed":["3394716f52b34ab259ad5247e7595d9f9db6e935"],"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e":["7e2fb55c0777755badd3b46d8140f3d4301febed"],"c0cd85fde84cb318b4dc97710dcf15e2959a1bbe":["ae14298f4eec6d5faee6a149f88ba57d14a6f21a","3394716f52b34ab259ad5247e7595d9f9db6e935"],"352763be0465236f8e2ac188aa1b761cb3e1c9ee":["4356000e349e38c9fb48034695b7c309abd54557"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"6e09a3a223be07d75777515a717312813221fe58":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"505bff044e47a553f461b6f4484d1d08faf4ac85":["c9fb5f46e264daf5ba3860defe623a89d202dd87"],"c9fb5f46e264daf5ba3860defe623a89d202dd87":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"0bdb67d0b49ddf963c3bfc4975fce171ad3aacb1":["505bff044e47a553f461b6f4484d1d08faf4ac85"],"04f07771a2a7dd3a395700665ed839c3dae2def2":["e7e8d6f15900ee22ac3cb0a503f15dc952a3580f"],"3394716f52b34ab259ad5247e7595d9f9db6e935":["ae14298f4eec6d5faee6a149f88ba57d14a6f21a","52c7e49be259508735752fba88085255014a6ecf"],"a78a90fc9701e511308346ea29f4f5e548bb39fe":["6e09a3a223be07d75777515a717312813221fe58"],"615ddbd81799980d0fdd95e0238e1c498b6f47b0":["629c38c4ae4e303d0617e05fbfe508140b32f0a3","352763be0465236f8e2ac188aa1b761cb3e1c9ee"],"4356000e349e38c9fb48034695b7c309abd54557":["629c38c4ae4e303d0617e05fbfe508140b32f0a3"],"e7e8d6f15900ee22ac3cb0a503f15dc952a3580f":["615ddbd81799980d0fdd95e0238e1c498b6f47b0"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"d0ef034a4f10871667ae75181537775ddcf8ade4":["54a6bea0b991120a99ad0e2f72ae853fd5ecae0e"],"ae14298f4eec6d5faee6a149f88ba57d14a6f21a":["4093b270ba337f9c25a4c0e6cb2ae2c07f697376"],"629c38c4ae4e303d0617e05fbfe508140b32f0a3":["a78a90fc9701e511308346ea29f4f5e548bb39fe"],"52c7e49be259508735752fba88085255014a6ecf":["ae14298f4eec6d5faee6a149f88ba57d14a6f21a"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["0bdb67d0b49ddf963c3bfc4975fce171ad3aacb1"],"4093b270ba337f9c25a4c0e6cb2ae2c07f697376":["04f07771a2a7dd3a395700665ed839c3dae2def2"]},"commit2Childs":{"7e2fb55c0777755badd3b46d8140f3d4301febed":["54a6bea0b991120a99ad0e2f72ae853fd5ecae0e"],"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"c0cd85fde84cb318b4dc97710dcf15e2959a1bbe":[],"352763be0465236f8e2ac188aa1b761cb3e1c9ee":["615ddbd81799980d0fdd95e0238e1c498b6f47b0"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["6e09a3a223be07d75777515a717312813221fe58"],"6e09a3a223be07d75777515a717312813221fe58":["a78a90fc9701e511308346ea29f4f5e548bb39fe"],"505bff044e47a553f461b6f4484d1d08faf4ac85":["0bdb67d0b49ddf963c3bfc4975fce171ad3aacb1"],"c9fb5f46e264daf5ba3860defe623a89d202dd87":["505bff044e47a553f461b6f4484d1d08faf4ac85"],"3394716f52b34ab259ad5247e7595d9f9db6e935":["7e2fb55c0777755badd3b46d8140f3d4301febed","c0cd85fde84cb318b4dc97710dcf15e2959a1bbe"],"0bdb67d0b49ddf963c3bfc4975fce171ad3aacb1":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"04f07771a2a7dd3a395700665ed839c3dae2def2":["4093b270ba337f9c25a4c0e6cb2ae2c07f697376"],"a78a90fc9701e511308346ea29f4f5e548bb39fe":["629c38c4ae4e303d0617e05fbfe508140b32f0a3"],"4356000e349e38c9fb48034695b7c309abd54557":["352763be0465236f8e2ac188aa1b761cb3e1c9ee"],"615ddbd81799980d0fdd95e0238e1c498b6f47b0":["e7e8d6f15900ee22ac3cb0a503f15dc952a3580f"],"e7e8d6f15900ee22ac3cb0a503f15dc952a3580f":["04f07771a2a7dd3a395700665ed839c3dae2def2"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"d0ef034a4f10871667ae75181537775ddcf8ade4":["c9fb5f46e264daf5ba3860defe623a89d202dd87"],"ae14298f4eec6d5faee6a149f88ba57d14a6f21a":["c0cd85fde84cb318b4dc97710dcf15e2959a1bbe","3394716f52b34ab259ad5247e7595d9f9db6e935","52c7e49be259508735752fba88085255014a6ecf"],"629c38c4ae4e303d0617e05fbfe508140b32f0a3":["615ddbd81799980d0fdd95e0238e1c498b6f47b0","4356000e349e38c9fb48034695b7c309abd54557"],"52c7e49be259508735752fba88085255014a6ecf":["3394716f52b34ab259ad5247e7595d9f9db6e935"],"4093b270ba337f9c25a4c0e6cb2ae2c07f697376":["ae14298f4eec6d5faee6a149f88ba57d14a6f21a"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["c0cd85fde84cb318b4dc97710dcf15e2959a1bbe","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}