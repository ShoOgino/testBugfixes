{"path":"lucene/analysis/icu/src/java/org/apache/lucene/analysis/icu/segmentation/ICUTokenizer#incrementTokenBuffer().mjava","commits":[{"id":"b89678825b68eccaf09e6ab71675fc0b0af1e099","date":1334669779,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/analysis/icu/src/java/org/apache/lucene/analysis/icu/segmentation/ICUTokenizer#incrementTokenBuffer().mjava","pathOld":"modules/analysis/icu/src/java/org/apache/lucene/analysis/icu/segmentation/ICUTokenizer#incrementTokenBuffer().mjava","sourceNew":"  /*\n   * return true if there is a token from the buffer, or null if it is\n   * exhausted.\n   */\n  private boolean incrementTokenBuffer() {\n    int start = breaker.current();\n    if (start == BreakIterator.DONE)\n      return false; // BreakIterator exhausted\n\n    // find the next set of boundaries, skipping over non-tokens (rule status 0)\n    int end = breaker.next();\n    while (start != BreakIterator.DONE && breaker.getRuleStatus() == 0) {\n      start = end;\n      end = breaker.next();\n    }\n\n    if (start == BreakIterator.DONE)\n      return false; // BreakIterator exhausted\n\n    termAtt.copyBuffer(buffer, start, end - start);\n    offsetAtt.setOffset(correctOffset(offset + start), correctOffset(offset + end));\n    typeAtt.setType(config.getType(breaker.getScriptCode(), breaker.getRuleStatus()));\n    scriptAtt.setCode(breaker.getScriptCode());\n\n    return true;\n  }\n\n","sourceOld":"  /*\n   * return true if there is a token from the buffer, or null if it is\n   * exhausted.\n   */\n  private boolean incrementTokenBuffer() {\n    int start = breaker.current();\n    if (start == BreakIterator.DONE)\n      return false; // BreakIterator exhausted\n\n    // find the next set of boundaries, skipping over non-tokens (rule status 0)\n    int end = breaker.next();\n    while (start != BreakIterator.DONE && breaker.getRuleStatus() == 0) {\n      start = end;\n      end = breaker.next();\n    }\n\n    if (start == BreakIterator.DONE)\n      return false; // BreakIterator exhausted\n\n    termAtt.copyBuffer(buffer, start, end - start);\n    offsetAtt.setOffset(correctOffset(offset + start), correctOffset(offset + end));\n    typeAtt.setType(config.getType(breaker.getScriptCode(), breaker.getRuleStatus()));\n    scriptAtt.setCode(breaker.getScriptCode());\n\n    return true;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"722893cd7922a6a37879d3270e75adf2ca58dfc3","date":1515447218,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/analysis/icu/src/java/org/apache/lucene/analysis/icu/segmentation/ICUTokenizer#incrementTokenBuffer().mjava","pathOld":"lucene/analysis/icu/src/java/org/apache/lucene/analysis/icu/segmentation/ICUTokenizer#incrementTokenBuffer().mjava","sourceNew":"  /*\n   * return true if there is a token from the buffer, or null if it is\n   * exhausted.\n   */\n  private boolean incrementTokenBuffer() {\n    int start = breaker.current();\n    assert start != BreakIterator.DONE;\n\n    // find the next set of boundaries, skipping over non-tokens (rule status 0)\n    int end = breaker.next();\n    while (end != BreakIterator.DONE && breaker.getRuleStatus() == 0) {\n      start = end;\n      end = breaker.next();\n    }\n\n    if (end == BreakIterator.DONE) {\n      return false; // BreakIterator exhausted\n    }\n\n    termAtt.copyBuffer(buffer, start, end - start);\n    offsetAtt.setOffset(correctOffset(offset + start), correctOffset(offset + end));\n    typeAtt.setType(config.getType(breaker.getScriptCode(), breaker.getRuleStatus()));\n    scriptAtt.setCode(breaker.getScriptCode());\n\n    return true;\n  }\n\n","sourceOld":"  /*\n   * return true if there is a token from the buffer, or null if it is\n   * exhausted.\n   */\n  private boolean incrementTokenBuffer() {\n    int start = breaker.current();\n    if (start == BreakIterator.DONE)\n      return false; // BreakIterator exhausted\n\n    // find the next set of boundaries, skipping over non-tokens (rule status 0)\n    int end = breaker.next();\n    while (start != BreakIterator.DONE && breaker.getRuleStatus() == 0) {\n      start = end;\n      end = breaker.next();\n    }\n\n    if (start == BreakIterator.DONE)\n      return false; // BreakIterator exhausted\n\n    termAtt.copyBuffer(buffer, start, end - start);\n    offsetAtt.setOffset(correctOffset(offset + start), correctOffset(offset + end));\n    typeAtt.setType(config.getType(breaker.getScriptCode(), breaker.getRuleStatus()));\n    scriptAtt.setCode(breaker.getScriptCode());\n\n    return true;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b94236357aaa22b76c10629851fe4e376e0cea82","date":1516710914,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"lucene/analysis/icu/src/java/org/apache/lucene/analysis/icu/segmentation/ICUTokenizer#incrementTokenBuffer().mjava","pathOld":"lucene/analysis/icu/src/java/org/apache/lucene/analysis/icu/segmentation/ICUTokenizer#incrementTokenBuffer().mjava","sourceNew":"  /*\n   * return true if there is a token from the buffer, or null if it is\n   * exhausted.\n   */\n  private boolean incrementTokenBuffer() {\n    int start = breaker.current();\n    assert start != BreakIterator.DONE;\n\n    // find the next set of boundaries, skipping over non-tokens (rule status 0)\n    int end = breaker.next();\n    while (end != BreakIterator.DONE && breaker.getRuleStatus() == 0) {\n      start = end;\n      end = breaker.next();\n    }\n\n    if (end == BreakIterator.DONE) {\n      return false; // BreakIterator exhausted\n    }\n\n    termAtt.copyBuffer(buffer, start, end - start);\n    offsetAtt.setOffset(correctOffset(offset + start), correctOffset(offset + end));\n    typeAtt.setType(config.getType(breaker.getScriptCode(), breaker.getRuleStatus()));\n    scriptAtt.setCode(breaker.getScriptCode());\n\n    return true;\n  }\n\n","sourceOld":"  /*\n   * return true if there is a token from the buffer, or null if it is\n   * exhausted.\n   */\n  private boolean incrementTokenBuffer() {\n    int start = breaker.current();\n    if (start == BreakIterator.DONE)\n      return false; // BreakIterator exhausted\n\n    // find the next set of boundaries, skipping over non-tokens (rule status 0)\n    int end = breaker.next();\n    while (start != BreakIterator.DONE && breaker.getRuleStatus() == 0) {\n      start = end;\n      end = breaker.next();\n    }\n\n    if (start == BreakIterator.DONE)\n      return false; // BreakIterator exhausted\n\n    termAtt.copyBuffer(buffer, start, end - start);\n    offsetAtt.setOffset(correctOffset(offset + start), correctOffset(offset + end));\n    typeAtt.setType(config.getType(breaker.getScriptCode(), breaker.getRuleStatus()));\n    scriptAtt.setCode(breaker.getScriptCode());\n\n    return true;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0929dd484d5e43b1f6fc997a8fa3d9aade7abdd7","date":1519134053,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/analysis/icu/src/java/org/apache/lucene/analysis/icu/segmentation/ICUTokenizer#incrementTokenBuffer().mjava","pathOld":"lucene/analysis/icu/src/java/org/apache/lucene/analysis/icu/segmentation/ICUTokenizer#incrementTokenBuffer().mjava","sourceNew":"  /*\n   * return true if there is a token from the buffer, or null if it is\n   * exhausted.\n   */\n  private boolean incrementTokenBuffer() {\n    int start = breaker.current();\n    if (start == BreakIterator.DONE)\n      return false; // BreakIterator exhausted\n\n    // find the next set of boundaries, skipping over non-tokens (rule status 0)\n    int end = breaker.next();\n    while (start != BreakIterator.DONE && breaker.getRuleStatus() == 0) {\n      start = end;\n      end = breaker.next();\n    }\n\n    if (start == BreakIterator.DONE)\n      return false; // BreakIterator exhausted\n\n    termAtt.copyBuffer(buffer, start, end - start);\n    offsetAtt.setOffset(correctOffset(offset + start), correctOffset(offset + end));\n    typeAtt.setType(config.getType(breaker.getScriptCode(), breaker.getRuleStatus()));\n    scriptAtt.setCode(breaker.getScriptCode());\n\n    return true;\n  }\n\n","sourceOld":"  /*\n   * return true if there is a token from the buffer, or null if it is\n   * exhausted.\n   */\n  private boolean incrementTokenBuffer() {\n    int start = breaker.current();\n    assert start != BreakIterator.DONE;\n\n    // find the next set of boundaries, skipping over non-tokens (rule status 0)\n    int end = breaker.next();\n    while (end != BreakIterator.DONE && breaker.getRuleStatus() == 0) {\n      start = end;\n      end = breaker.next();\n    }\n\n    if (end == BreakIterator.DONE) {\n      return false; // BreakIterator exhausted\n    }\n\n    termAtt.copyBuffer(buffer, start, end - start);\n    offsetAtt.setOffset(correctOffset(offset + start), correctOffset(offset + end));\n    typeAtt.setType(config.getType(breaker.getScriptCode(), breaker.getRuleStatus()));\n    scriptAtt.setCode(breaker.getScriptCode());\n\n    return true;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"90eb4a8104c0af1def85ddb5144fd29ad6baf38c","date":1522103232,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/analysis/icu/src/java/org/apache/lucene/analysis/icu/segmentation/ICUTokenizer#incrementTokenBuffer().mjava","pathOld":"lucene/analysis/icu/src/java/org/apache/lucene/analysis/icu/segmentation/ICUTokenizer#incrementTokenBuffer().mjava","sourceNew":"  /*\n   * return true if there is a token from the buffer, or null if it is\n   * exhausted.\n   */\n  private boolean incrementTokenBuffer() {\n    int start = breaker.current();\n    assert start != BreakIterator.DONE;\n\n    // find the next set of boundaries, skipping over non-tokens (rule status 0)\n    int end = breaker.next();\n    while (end != BreakIterator.DONE && breaker.getRuleStatus() == 0) {\n      start = end;\n      end = breaker.next();\n    }\n\n    if (end == BreakIterator.DONE) {\n      return false; // BreakIterator exhausted\n    }\n\n    termAtt.copyBuffer(buffer, start, end - start);\n    offsetAtt.setOffset(correctOffset(offset + start), correctOffset(offset + end));\n    typeAtt.setType(config.getType(breaker.getScriptCode(), breaker.getRuleStatus()));\n    scriptAtt.setCode(breaker.getScriptCode());\n\n    return true;\n  }\n\n","sourceOld":"  /*\n   * return true if there is a token from the buffer, or null if it is\n   * exhausted.\n   */\n  private boolean incrementTokenBuffer() {\n    int start = breaker.current();\n    if (start == BreakIterator.DONE)\n      return false; // BreakIterator exhausted\n\n    // find the next set of boundaries, skipping over non-tokens (rule status 0)\n    int end = breaker.next();\n    while (start != BreakIterator.DONE && breaker.getRuleStatus() == 0) {\n      start = end;\n      end = breaker.next();\n    }\n\n    if (start == BreakIterator.DONE)\n      return false; // BreakIterator exhausted\n\n    termAtt.copyBuffer(buffer, start, end - start);\n    offsetAtt.setOffset(correctOffset(offset + start), correctOffset(offset + end));\n    typeAtt.setType(config.getType(breaker.getScriptCode(), breaker.getRuleStatus()));\n    scriptAtt.setCode(breaker.getScriptCode());\n\n    return true;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d61a3e0821ed080b9b21e1328bbaa91dcf79f7d7","date":1522191940,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"lucene/analysis/icu/src/java/org/apache/lucene/analysis/icu/segmentation/ICUTokenizer#incrementTokenBuffer().mjava","pathOld":"lucene/analysis/icu/src/java/org/apache/lucene/analysis/icu/segmentation/ICUTokenizer#incrementTokenBuffer().mjava","sourceNew":"  /*\n   * return true if there is a token from the buffer, or null if it is\n   * exhausted.\n   */\n  private boolean incrementTokenBuffer() {\n    int start = breaker.current();\n    assert start != BreakIterator.DONE;\n\n    // find the next set of boundaries, skipping over non-tokens (rule status 0)\n    int end = breaker.next();\n    while (end != BreakIterator.DONE && breaker.getRuleStatus() == 0) {\n      start = end;\n      end = breaker.next();\n    }\n\n    if (end == BreakIterator.DONE) {\n      return false; // BreakIterator exhausted\n    }\n\n    termAtt.copyBuffer(buffer, start, end - start);\n    offsetAtt.setOffset(correctOffset(offset + start), correctOffset(offset + end));\n    typeAtt.setType(config.getType(breaker.getScriptCode(), breaker.getRuleStatus()));\n    scriptAtt.setCode(breaker.getScriptCode());\n\n    return true;\n  }\n\n","sourceOld":"  /*\n   * return true if there is a token from the buffer, or null if it is\n   * exhausted.\n   */\n  private boolean incrementTokenBuffer() {\n    int start = breaker.current();\n    if (start == BreakIterator.DONE)\n      return false; // BreakIterator exhausted\n\n    // find the next set of boundaries, skipping over non-tokens (rule status 0)\n    int end = breaker.next();\n    while (start != BreakIterator.DONE && breaker.getRuleStatus() == 0) {\n      start = end;\n      end = breaker.next();\n    }\n\n    if (start == BreakIterator.DONE)\n      return false; // BreakIterator exhausted\n\n    termAtt.copyBuffer(buffer, start, end - start);\n    offsetAtt.setOffset(correctOffset(offset + start), correctOffset(offset + end));\n    typeAtt.setType(config.getType(breaker.getScriptCode(), breaker.getRuleStatus()));\n    scriptAtt.setCode(breaker.getScriptCode());\n\n    return true;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"b94236357aaa22b76c10629851fe4e376e0cea82":["b89678825b68eccaf09e6ab71675fc0b0af1e099","722893cd7922a6a37879d3270e75adf2ca58dfc3"],"b89678825b68eccaf09e6ab71675fc0b0af1e099":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"0929dd484d5e43b1f6fc997a8fa3d9aade7abdd7":["b94236357aaa22b76c10629851fe4e376e0cea82"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"d61a3e0821ed080b9b21e1328bbaa91dcf79f7d7":["0929dd484d5e43b1f6fc997a8fa3d9aade7abdd7","90eb4a8104c0af1def85ddb5144fd29ad6baf38c"],"90eb4a8104c0af1def85ddb5144fd29ad6baf38c":["0929dd484d5e43b1f6fc997a8fa3d9aade7abdd7"],"722893cd7922a6a37879d3270e75adf2ca58dfc3":["b89678825b68eccaf09e6ab71675fc0b0af1e099"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["d61a3e0821ed080b9b21e1328bbaa91dcf79f7d7"]},"commit2Childs":{"b94236357aaa22b76c10629851fe4e376e0cea82":["0929dd484d5e43b1f6fc997a8fa3d9aade7abdd7"],"b89678825b68eccaf09e6ab71675fc0b0af1e099":["b94236357aaa22b76c10629851fe4e376e0cea82","722893cd7922a6a37879d3270e75adf2ca58dfc3"],"0929dd484d5e43b1f6fc997a8fa3d9aade7abdd7":["d61a3e0821ed080b9b21e1328bbaa91dcf79f7d7","90eb4a8104c0af1def85ddb5144fd29ad6baf38c"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["b89678825b68eccaf09e6ab71675fc0b0af1e099"],"d61a3e0821ed080b9b21e1328bbaa91dcf79f7d7":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"90eb4a8104c0af1def85ddb5144fd29ad6baf38c":["d61a3e0821ed080b9b21e1328bbaa91dcf79f7d7"],"722893cd7922a6a37879d3270e75adf2ca58dfc3":["b94236357aaa22b76c10629851fe4e376e0cea82"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}