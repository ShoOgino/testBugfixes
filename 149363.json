{"path":"lucene/benchmark/src/test/org/apache/lucene/benchmark/quality/TestQualityRun#testTrecQuality().mjava","commits":[{"id":"b89678825b68eccaf09e6ab71675fc0b0af1e099","date":1334669779,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/benchmark/src/test/org/apache/lucene/benchmark/quality/TestQualityRun#testTrecQuality().mjava","pathOld":"modules/benchmark/src/test/org/apache/lucene/benchmark/quality/TestQualityRun#testTrecQuality().mjava","sourceNew":"  public void testTrecQuality() throws Exception {\n    // first create the partial reuters index\n    createReutersIndex();\n    \n    int maxResults = 1000;\n    String docNameField = \"doctitle\"; // orig docID is in the linedoc format title \n    \n    PrintWriter logger = VERBOSE ? new PrintWriter(System.out,true) : null;\n   \n    // prepare topics\n    InputStream topics = getClass().getResourceAsStream(\"trecTopics.txt\");\n    TrecTopicsReader qReader = new TrecTopicsReader();\n    QualityQuery qqs[] = qReader.readQueries(new BufferedReader(new InputStreamReader(topics, \"UTF-8\")));\n    \n    // prepare judge\n    InputStream qrels = getClass().getResourceAsStream(\"trecQRels.txt\");\n    Judge judge = new TrecJudge(new BufferedReader(new InputStreamReader(qrels, \"UTF-8\")));\n    \n    // validate topics & judgments match each other\n    judge.validateData(qqs, logger);\n    \n    Directory dir = newFSDirectory(new File(getWorkDir(),\"index\"));\n    IndexReader reader = IndexReader.open(dir);\n    IndexSearcher searcher = new IndexSearcher(reader);\n\n    QualityQueryParser qqParser = new SimpleQQParser(\"title\",\"body\");\n    QualityBenchmark qrun = new QualityBenchmark(qqs, qqParser, searcher, docNameField);\n    \n    SubmissionReport submitLog = VERBOSE ? new SubmissionReport(logger, \"TestRun\") : null;\n    qrun.setMaxResults(maxResults);\n    QualityStats stats[] = qrun.execute(judge, submitLog, logger);\n    \n    // --------- verify by the way judgments were altered for this test:\n    // for some queries, depending on m = qnum % 8\n    // m==0: avg_precision and recall are hurt, by marking fake docs as relevant\n    // m==1: precision_at_n and avg_precision are hurt, by unmarking relevant docs\n    // m==2: all precision, precision_at_n and recall are hurt.\n    // m>=3: these queries remain perfect\n    for (int i = 0; i < stats.length; i++) {\n      QualityStats s = stats[i];\n      switch (i%8) {\n\n      case 0:\n        assertTrue(\"avg-p should be hurt: \"+s.getAvp(), 1.0 > s.getAvp());\n        assertTrue(\"recall should be hurt: \"+s.getRecall(), 1.0 > s.getRecall());\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertEquals(\"p_at_\"+j+\" should be perfect: \"+s.getPrecisionAt(j), 1.0, s.getPrecisionAt(j), 1E-2);\n        }\n        break;\n      \n      case 1:\n        assertTrue(\"avg-p should be hurt\", 1.0 > s.getAvp());\n        assertEquals(\"recall should be perfect: \"+s.getRecall(), 1.0, s.getRecall(), 1E-2);\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertTrue(\"p_at_\"+j+\" should be hurt: \"+s.getPrecisionAt(j), 1.0 > s.getPrecisionAt(j));\n        }\n        break;\n\n      case 2:\n        assertTrue(\"avg-p should be hurt: \"+s.getAvp(), 1.0 > s.getAvp());\n        assertTrue(\"recall should be hurt: \"+s.getRecall(), 1.0 > s.getRecall());\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertTrue(\"p_at_\"+j+\" should be hurt: \"+s.getPrecisionAt(j), 1.0 > s.getPrecisionAt(j));\n        }\n        break;\n\n      default: {\n        assertEquals(\"avg-p should be perfect: \"+s.getAvp(), 1.0, s.getAvp(), 1E-2);\n        assertEquals(\"recall should be perfect: \"+s.getRecall(), 1.0, s.getRecall(), 1E-2);\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertEquals(\"p_at_\"+j+\" should be perfect: \"+s.getPrecisionAt(j), 1.0, s.getPrecisionAt(j), 1E-2);\n        }\n      }\n      \n      }\n    }\n    \n    QualityStats avg = QualityStats.average(stats);\n    if (logger!=null) {\n      avg.log(\"Average statistis:\",1,logger,\"  \");\n    }\n    \n    assertTrue(\"mean avg-p should be hurt: \"+avg.getAvp(), 1.0 > avg.getAvp());\n    assertTrue(\"avg recall should be hurt: \"+avg.getRecall(), 1.0 > avg.getRecall());\n    for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n      assertTrue(\"avg p_at_\"+j+\" should be hurt: \"+avg.getPrecisionAt(j), 1.0 > avg.getPrecisionAt(j));\n    }\n    \n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testTrecQuality() throws Exception {\n    // first create the partial reuters index\n    createReutersIndex();\n    \n    int maxResults = 1000;\n    String docNameField = \"doctitle\"; // orig docID is in the linedoc format title \n    \n    PrintWriter logger = VERBOSE ? new PrintWriter(System.out,true) : null;\n   \n    // prepare topics\n    InputStream topics = getClass().getResourceAsStream(\"trecTopics.txt\");\n    TrecTopicsReader qReader = new TrecTopicsReader();\n    QualityQuery qqs[] = qReader.readQueries(new BufferedReader(new InputStreamReader(topics, \"UTF-8\")));\n    \n    // prepare judge\n    InputStream qrels = getClass().getResourceAsStream(\"trecQRels.txt\");\n    Judge judge = new TrecJudge(new BufferedReader(new InputStreamReader(qrels, \"UTF-8\")));\n    \n    // validate topics & judgments match each other\n    judge.validateData(qqs, logger);\n    \n    Directory dir = newFSDirectory(new File(getWorkDir(),\"index\"));\n    IndexReader reader = IndexReader.open(dir);\n    IndexSearcher searcher = new IndexSearcher(reader);\n\n    QualityQueryParser qqParser = new SimpleQQParser(\"title\",\"body\");\n    QualityBenchmark qrun = new QualityBenchmark(qqs, qqParser, searcher, docNameField);\n    \n    SubmissionReport submitLog = VERBOSE ? new SubmissionReport(logger, \"TestRun\") : null;\n    qrun.setMaxResults(maxResults);\n    QualityStats stats[] = qrun.execute(judge, submitLog, logger);\n    \n    // --------- verify by the way judgments were altered for this test:\n    // for some queries, depending on m = qnum % 8\n    // m==0: avg_precision and recall are hurt, by marking fake docs as relevant\n    // m==1: precision_at_n and avg_precision are hurt, by unmarking relevant docs\n    // m==2: all precision, precision_at_n and recall are hurt.\n    // m>=3: these queries remain perfect\n    for (int i = 0; i < stats.length; i++) {\n      QualityStats s = stats[i];\n      switch (i%8) {\n\n      case 0:\n        assertTrue(\"avg-p should be hurt: \"+s.getAvp(), 1.0 > s.getAvp());\n        assertTrue(\"recall should be hurt: \"+s.getRecall(), 1.0 > s.getRecall());\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertEquals(\"p_at_\"+j+\" should be perfect: \"+s.getPrecisionAt(j), 1.0, s.getPrecisionAt(j), 1E-2);\n        }\n        break;\n      \n      case 1:\n        assertTrue(\"avg-p should be hurt\", 1.0 > s.getAvp());\n        assertEquals(\"recall should be perfect: \"+s.getRecall(), 1.0, s.getRecall(), 1E-2);\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertTrue(\"p_at_\"+j+\" should be hurt: \"+s.getPrecisionAt(j), 1.0 > s.getPrecisionAt(j));\n        }\n        break;\n\n      case 2:\n        assertTrue(\"avg-p should be hurt: \"+s.getAvp(), 1.0 > s.getAvp());\n        assertTrue(\"recall should be hurt: \"+s.getRecall(), 1.0 > s.getRecall());\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertTrue(\"p_at_\"+j+\" should be hurt: \"+s.getPrecisionAt(j), 1.0 > s.getPrecisionAt(j));\n        }\n        break;\n\n      default: {\n        assertEquals(\"avg-p should be perfect: \"+s.getAvp(), 1.0, s.getAvp(), 1E-2);\n        assertEquals(\"recall should be perfect: \"+s.getRecall(), 1.0, s.getRecall(), 1E-2);\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertEquals(\"p_at_\"+j+\" should be perfect: \"+s.getPrecisionAt(j), 1.0, s.getPrecisionAt(j), 1E-2);\n        }\n      }\n      \n      }\n    }\n    \n    QualityStats avg = QualityStats.average(stats);\n    if (logger!=null) {\n      avg.log(\"Average statistis:\",1,logger,\"  \");\n    }\n    \n    assertTrue(\"mean avg-p should be hurt: \"+avg.getAvp(), 1.0 > avg.getAvp());\n    assertTrue(\"avg recall should be hurt: \"+avg.getRecall(), 1.0 > avg.getRecall());\n    for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n      assertTrue(\"avg p_at_\"+j+\" should be hurt: \"+avg.getPrecisionAt(j), 1.0 > avg.getPrecisionAt(j));\n    }\n    \n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e7e8d6f15900ee22ac3cb0a503f15dc952a3580f","date":1338430031,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/benchmark/src/test/org/apache/lucene/benchmark/quality/TestQualityRun#testTrecQuality().mjava","pathOld":"lucene/benchmark/src/test/org/apache/lucene/benchmark/quality/TestQualityRun#testTrecQuality().mjava","sourceNew":"  public void testTrecQuality() throws Exception {\n    // first create the partial reuters index\n    createReutersIndex();\n    \n    int maxResults = 1000;\n    String docNameField = \"doctitle\"; // orig docID is in the linedoc format title \n    \n    PrintWriter logger = VERBOSE ? new PrintWriter(System.out,true) : null;\n   \n    // prepare topics\n    InputStream topics = getClass().getResourceAsStream(\"trecTopics.txt\");\n    TrecTopicsReader qReader = new TrecTopicsReader();\n    QualityQuery qqs[] = qReader.readQueries(new BufferedReader(new InputStreamReader(topics, \"UTF-8\")));\n    \n    // prepare judge\n    InputStream qrels = getClass().getResourceAsStream(\"trecQRels.txt\");\n    Judge judge = new TrecJudge(new BufferedReader(new InputStreamReader(qrels, \"UTF-8\")));\n    \n    // validate topics & judgments match each other\n    judge.validateData(qqs, logger);\n    \n    Directory dir = newFSDirectory(new File(getWorkDir(),\"index\"));\n    IndexReader reader = DirectoryReader.open(dir);\n    IndexSearcher searcher = new IndexSearcher(reader);\n\n    QualityQueryParser qqParser = new SimpleQQParser(\"title\",\"body\");\n    QualityBenchmark qrun = new QualityBenchmark(qqs, qqParser, searcher, docNameField);\n    \n    SubmissionReport submitLog = VERBOSE ? new SubmissionReport(logger, \"TestRun\") : null;\n    qrun.setMaxResults(maxResults);\n    QualityStats stats[] = qrun.execute(judge, submitLog, logger);\n    \n    // --------- verify by the way judgments were altered for this test:\n    // for some queries, depending on m = qnum % 8\n    // m==0: avg_precision and recall are hurt, by marking fake docs as relevant\n    // m==1: precision_at_n and avg_precision are hurt, by unmarking relevant docs\n    // m==2: all precision, precision_at_n and recall are hurt.\n    // m>=3: these queries remain perfect\n    for (int i = 0; i < stats.length; i++) {\n      QualityStats s = stats[i];\n      switch (i%8) {\n\n      case 0:\n        assertTrue(\"avg-p should be hurt: \"+s.getAvp(), 1.0 > s.getAvp());\n        assertTrue(\"recall should be hurt: \"+s.getRecall(), 1.0 > s.getRecall());\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertEquals(\"p_at_\"+j+\" should be perfect: \"+s.getPrecisionAt(j), 1.0, s.getPrecisionAt(j), 1E-2);\n        }\n        break;\n      \n      case 1:\n        assertTrue(\"avg-p should be hurt\", 1.0 > s.getAvp());\n        assertEquals(\"recall should be perfect: \"+s.getRecall(), 1.0, s.getRecall(), 1E-2);\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertTrue(\"p_at_\"+j+\" should be hurt: \"+s.getPrecisionAt(j), 1.0 > s.getPrecisionAt(j));\n        }\n        break;\n\n      case 2:\n        assertTrue(\"avg-p should be hurt: \"+s.getAvp(), 1.0 > s.getAvp());\n        assertTrue(\"recall should be hurt: \"+s.getRecall(), 1.0 > s.getRecall());\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertTrue(\"p_at_\"+j+\" should be hurt: \"+s.getPrecisionAt(j), 1.0 > s.getPrecisionAt(j));\n        }\n        break;\n\n      default: {\n        assertEquals(\"avg-p should be perfect: \"+s.getAvp(), 1.0, s.getAvp(), 1E-2);\n        assertEquals(\"recall should be perfect: \"+s.getRecall(), 1.0, s.getRecall(), 1E-2);\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertEquals(\"p_at_\"+j+\" should be perfect: \"+s.getPrecisionAt(j), 1.0, s.getPrecisionAt(j), 1E-2);\n        }\n      }\n      \n      }\n    }\n    \n    QualityStats avg = QualityStats.average(stats);\n    if (logger!=null) {\n      avg.log(\"Average statistis:\",1,logger,\"  \");\n    }\n    \n    assertTrue(\"mean avg-p should be hurt: \"+avg.getAvp(), 1.0 > avg.getAvp());\n    assertTrue(\"avg recall should be hurt: \"+avg.getRecall(), 1.0 > avg.getRecall());\n    for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n      assertTrue(\"avg p_at_\"+j+\" should be hurt: \"+avg.getPrecisionAt(j), 1.0 > avg.getPrecisionAt(j));\n    }\n    \n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testTrecQuality() throws Exception {\n    // first create the partial reuters index\n    createReutersIndex();\n    \n    int maxResults = 1000;\n    String docNameField = \"doctitle\"; // orig docID is in the linedoc format title \n    \n    PrintWriter logger = VERBOSE ? new PrintWriter(System.out,true) : null;\n   \n    // prepare topics\n    InputStream topics = getClass().getResourceAsStream(\"trecTopics.txt\");\n    TrecTopicsReader qReader = new TrecTopicsReader();\n    QualityQuery qqs[] = qReader.readQueries(new BufferedReader(new InputStreamReader(topics, \"UTF-8\")));\n    \n    // prepare judge\n    InputStream qrels = getClass().getResourceAsStream(\"trecQRels.txt\");\n    Judge judge = new TrecJudge(new BufferedReader(new InputStreamReader(qrels, \"UTF-8\")));\n    \n    // validate topics & judgments match each other\n    judge.validateData(qqs, logger);\n    \n    Directory dir = newFSDirectory(new File(getWorkDir(),\"index\"));\n    IndexReader reader = IndexReader.open(dir);\n    IndexSearcher searcher = new IndexSearcher(reader);\n\n    QualityQueryParser qqParser = new SimpleQQParser(\"title\",\"body\");\n    QualityBenchmark qrun = new QualityBenchmark(qqs, qqParser, searcher, docNameField);\n    \n    SubmissionReport submitLog = VERBOSE ? new SubmissionReport(logger, \"TestRun\") : null;\n    qrun.setMaxResults(maxResults);\n    QualityStats stats[] = qrun.execute(judge, submitLog, logger);\n    \n    // --------- verify by the way judgments were altered for this test:\n    // for some queries, depending on m = qnum % 8\n    // m==0: avg_precision and recall are hurt, by marking fake docs as relevant\n    // m==1: precision_at_n and avg_precision are hurt, by unmarking relevant docs\n    // m==2: all precision, precision_at_n and recall are hurt.\n    // m>=3: these queries remain perfect\n    for (int i = 0; i < stats.length; i++) {\n      QualityStats s = stats[i];\n      switch (i%8) {\n\n      case 0:\n        assertTrue(\"avg-p should be hurt: \"+s.getAvp(), 1.0 > s.getAvp());\n        assertTrue(\"recall should be hurt: \"+s.getRecall(), 1.0 > s.getRecall());\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertEquals(\"p_at_\"+j+\" should be perfect: \"+s.getPrecisionAt(j), 1.0, s.getPrecisionAt(j), 1E-2);\n        }\n        break;\n      \n      case 1:\n        assertTrue(\"avg-p should be hurt\", 1.0 > s.getAvp());\n        assertEquals(\"recall should be perfect: \"+s.getRecall(), 1.0, s.getRecall(), 1E-2);\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertTrue(\"p_at_\"+j+\" should be hurt: \"+s.getPrecisionAt(j), 1.0 > s.getPrecisionAt(j));\n        }\n        break;\n\n      case 2:\n        assertTrue(\"avg-p should be hurt: \"+s.getAvp(), 1.0 > s.getAvp());\n        assertTrue(\"recall should be hurt: \"+s.getRecall(), 1.0 > s.getRecall());\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertTrue(\"p_at_\"+j+\" should be hurt: \"+s.getPrecisionAt(j), 1.0 > s.getPrecisionAt(j));\n        }\n        break;\n\n      default: {\n        assertEquals(\"avg-p should be perfect: \"+s.getAvp(), 1.0, s.getAvp(), 1E-2);\n        assertEquals(\"recall should be perfect: \"+s.getRecall(), 1.0, s.getRecall(), 1E-2);\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertEquals(\"p_at_\"+j+\" should be perfect: \"+s.getPrecisionAt(j), 1.0, s.getPrecisionAt(j), 1E-2);\n        }\n      }\n      \n      }\n    }\n    \n    QualityStats avg = QualityStats.average(stats);\n    if (logger!=null) {\n      avg.log(\"Average statistis:\",1,logger,\"  \");\n    }\n    \n    assertTrue(\"mean avg-p should be hurt: \"+avg.getAvp(), 1.0 > avg.getAvp());\n    assertTrue(\"avg recall should be hurt: \"+avg.getRecall(), 1.0 > avg.getRecall());\n    for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n      assertTrue(\"avg p_at_\"+j+\" should be hurt: \"+avg.getPrecisionAt(j), 1.0 > avg.getPrecisionAt(j));\n    }\n    \n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"714058a3bd900646d4df5e21af2d4e109ed3e4bc","date":1341692336,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/benchmark/src/test/org/apache/lucene/benchmark/quality/TestQualityRun#testTrecQuality().mjava","pathOld":"lucene/benchmark/src/test/org/apache/lucene/benchmark/quality/TestQualityRun#testTrecQuality().mjava","sourceNew":"  public void testTrecQuality() throws Exception {\n    // first create the partial reuters index\n    createReutersIndex();\n    \n    int maxResults = 1000;\n    String docNameField = \"doctitle\"; // orig docID is in the linedoc format title \n    \n    PrintWriter logger = VERBOSE ? new PrintWriter(new OutputStreamWriter(System.out, Charset.defaultCharset()),true) : null;\n   \n    // prepare topics\n    InputStream topics = getClass().getResourceAsStream(\"trecTopics.txt\");\n    TrecTopicsReader qReader = new TrecTopicsReader();\n    QualityQuery qqs[] = qReader.readQueries(new BufferedReader(new InputStreamReader(topics, \"UTF-8\")));\n    \n    // prepare judge\n    InputStream qrels = getClass().getResourceAsStream(\"trecQRels.txt\");\n    Judge judge = new TrecJudge(new BufferedReader(new InputStreamReader(qrels, \"UTF-8\")));\n    \n    // validate topics & judgments match each other\n    judge.validateData(qqs, logger);\n    \n    Directory dir = newFSDirectory(new File(getWorkDir(),\"index\"));\n    IndexReader reader = DirectoryReader.open(dir);\n    IndexSearcher searcher = new IndexSearcher(reader);\n\n    QualityQueryParser qqParser = new SimpleQQParser(\"title\",\"body\");\n    QualityBenchmark qrun = new QualityBenchmark(qqs, qqParser, searcher, docNameField);\n    \n    SubmissionReport submitLog = VERBOSE ? new SubmissionReport(logger, \"TestRun\") : null;\n    qrun.setMaxResults(maxResults);\n    QualityStats stats[] = qrun.execute(judge, submitLog, logger);\n    \n    // --------- verify by the way judgments were altered for this test:\n    // for some queries, depending on m = qnum % 8\n    // m==0: avg_precision and recall are hurt, by marking fake docs as relevant\n    // m==1: precision_at_n and avg_precision are hurt, by unmarking relevant docs\n    // m==2: all precision, precision_at_n and recall are hurt.\n    // m>=3: these queries remain perfect\n    for (int i = 0; i < stats.length; i++) {\n      QualityStats s = stats[i];\n      switch (i%8) {\n\n      case 0:\n        assertTrue(\"avg-p should be hurt: \"+s.getAvp(), 1.0 > s.getAvp());\n        assertTrue(\"recall should be hurt: \"+s.getRecall(), 1.0 > s.getRecall());\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertEquals(\"p_at_\"+j+\" should be perfect: \"+s.getPrecisionAt(j), 1.0, s.getPrecisionAt(j), 1E-2);\n        }\n        break;\n      \n      case 1:\n        assertTrue(\"avg-p should be hurt\", 1.0 > s.getAvp());\n        assertEquals(\"recall should be perfect: \"+s.getRecall(), 1.0, s.getRecall(), 1E-2);\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertTrue(\"p_at_\"+j+\" should be hurt: \"+s.getPrecisionAt(j), 1.0 > s.getPrecisionAt(j));\n        }\n        break;\n\n      case 2:\n        assertTrue(\"avg-p should be hurt: \"+s.getAvp(), 1.0 > s.getAvp());\n        assertTrue(\"recall should be hurt: \"+s.getRecall(), 1.0 > s.getRecall());\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertTrue(\"p_at_\"+j+\" should be hurt: \"+s.getPrecisionAt(j), 1.0 > s.getPrecisionAt(j));\n        }\n        break;\n\n      default: {\n        assertEquals(\"avg-p should be perfect: \"+s.getAvp(), 1.0, s.getAvp(), 1E-2);\n        assertEquals(\"recall should be perfect: \"+s.getRecall(), 1.0, s.getRecall(), 1E-2);\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertEquals(\"p_at_\"+j+\" should be perfect: \"+s.getPrecisionAt(j), 1.0, s.getPrecisionAt(j), 1E-2);\n        }\n      }\n      \n      }\n    }\n    \n    QualityStats avg = QualityStats.average(stats);\n    if (logger!=null) {\n      avg.log(\"Average statistis:\",1,logger,\"  \");\n    }\n    \n    assertTrue(\"mean avg-p should be hurt: \"+avg.getAvp(), 1.0 > avg.getAvp());\n    assertTrue(\"avg recall should be hurt: \"+avg.getRecall(), 1.0 > avg.getRecall());\n    for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n      assertTrue(\"avg p_at_\"+j+\" should be hurt: \"+avg.getPrecisionAt(j), 1.0 > avg.getPrecisionAt(j));\n    }\n    \n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testTrecQuality() throws Exception {\n    // first create the partial reuters index\n    createReutersIndex();\n    \n    int maxResults = 1000;\n    String docNameField = \"doctitle\"; // orig docID is in the linedoc format title \n    \n    PrintWriter logger = VERBOSE ? new PrintWriter(System.out,true) : null;\n   \n    // prepare topics\n    InputStream topics = getClass().getResourceAsStream(\"trecTopics.txt\");\n    TrecTopicsReader qReader = new TrecTopicsReader();\n    QualityQuery qqs[] = qReader.readQueries(new BufferedReader(new InputStreamReader(topics, \"UTF-8\")));\n    \n    // prepare judge\n    InputStream qrels = getClass().getResourceAsStream(\"trecQRels.txt\");\n    Judge judge = new TrecJudge(new BufferedReader(new InputStreamReader(qrels, \"UTF-8\")));\n    \n    // validate topics & judgments match each other\n    judge.validateData(qqs, logger);\n    \n    Directory dir = newFSDirectory(new File(getWorkDir(),\"index\"));\n    IndexReader reader = DirectoryReader.open(dir);\n    IndexSearcher searcher = new IndexSearcher(reader);\n\n    QualityQueryParser qqParser = new SimpleQQParser(\"title\",\"body\");\n    QualityBenchmark qrun = new QualityBenchmark(qqs, qqParser, searcher, docNameField);\n    \n    SubmissionReport submitLog = VERBOSE ? new SubmissionReport(logger, \"TestRun\") : null;\n    qrun.setMaxResults(maxResults);\n    QualityStats stats[] = qrun.execute(judge, submitLog, logger);\n    \n    // --------- verify by the way judgments were altered for this test:\n    // for some queries, depending on m = qnum % 8\n    // m==0: avg_precision and recall are hurt, by marking fake docs as relevant\n    // m==1: precision_at_n and avg_precision are hurt, by unmarking relevant docs\n    // m==2: all precision, precision_at_n and recall are hurt.\n    // m>=3: these queries remain perfect\n    for (int i = 0; i < stats.length; i++) {\n      QualityStats s = stats[i];\n      switch (i%8) {\n\n      case 0:\n        assertTrue(\"avg-p should be hurt: \"+s.getAvp(), 1.0 > s.getAvp());\n        assertTrue(\"recall should be hurt: \"+s.getRecall(), 1.0 > s.getRecall());\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertEquals(\"p_at_\"+j+\" should be perfect: \"+s.getPrecisionAt(j), 1.0, s.getPrecisionAt(j), 1E-2);\n        }\n        break;\n      \n      case 1:\n        assertTrue(\"avg-p should be hurt\", 1.0 > s.getAvp());\n        assertEquals(\"recall should be perfect: \"+s.getRecall(), 1.0, s.getRecall(), 1E-2);\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertTrue(\"p_at_\"+j+\" should be hurt: \"+s.getPrecisionAt(j), 1.0 > s.getPrecisionAt(j));\n        }\n        break;\n\n      case 2:\n        assertTrue(\"avg-p should be hurt: \"+s.getAvp(), 1.0 > s.getAvp());\n        assertTrue(\"recall should be hurt: \"+s.getRecall(), 1.0 > s.getRecall());\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertTrue(\"p_at_\"+j+\" should be hurt: \"+s.getPrecisionAt(j), 1.0 > s.getPrecisionAt(j));\n        }\n        break;\n\n      default: {\n        assertEquals(\"avg-p should be perfect: \"+s.getAvp(), 1.0, s.getAvp(), 1E-2);\n        assertEquals(\"recall should be perfect: \"+s.getRecall(), 1.0, s.getRecall(), 1E-2);\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertEquals(\"p_at_\"+j+\" should be perfect: \"+s.getPrecisionAt(j), 1.0, s.getPrecisionAt(j), 1E-2);\n        }\n      }\n      \n      }\n    }\n    \n    QualityStats avg = QualityStats.average(stats);\n    if (logger!=null) {\n      avg.log(\"Average statistis:\",1,logger,\"  \");\n    }\n    \n    assertTrue(\"mean avg-p should be hurt: \"+avg.getAvp(), 1.0 > avg.getAvp());\n    assertTrue(\"avg recall should be hurt: \"+avg.getRecall(), 1.0 > avg.getRecall());\n    for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n      assertTrue(\"avg p_at_\"+j+\" should be hurt: \"+avg.getPrecisionAt(j), 1.0 > avg.getPrecisionAt(j));\n    }\n    \n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2acf500f78aa12b92e371fd89c719291986b6b90","date":1341846236,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/benchmark/src/test/org/apache/lucene/benchmark/quality/TestQualityRun#testTrecQuality().mjava","pathOld":"lucene/benchmark/src/test/org/apache/lucene/benchmark/quality/TestQualityRun#testTrecQuality().mjava","sourceNew":"  public void testTrecQuality() throws Exception {\n    // first create the partial reuters index\n    createReutersIndex();\n    \n    int maxResults = 1000;\n    String docNameField = \"doctitle\"; // orig docID is in the linedoc format title \n    \n    PrintWriter logger = VERBOSE ? new PrintWriter(new OutputStreamWriter(System.out, Charset.defaultCharset()),true) : null;\n   \n    // prepare topics\n    InputStream topics = getClass().getResourceAsStream(\"trecTopics.txt\");\n    TrecTopicsReader qReader = new TrecTopicsReader();\n    QualityQuery qqs[] = qReader.readQueries(new BufferedReader(new InputStreamReader(topics, \"UTF-8\")));\n    \n    // prepare judge\n    InputStream qrels = getClass().getResourceAsStream(\"trecQRels.txt\");\n    Judge judge = new TrecJudge(new BufferedReader(new InputStreamReader(qrels, \"UTF-8\")));\n    \n    // validate topics & judgments match each other\n    judge.validateData(qqs, logger);\n    \n    Directory dir = newFSDirectory(new File(getWorkDir(),\"index\"));\n    IndexReader reader = DirectoryReader.open(dir);\n    IndexSearcher searcher = new IndexSearcher(reader);\n\n    QualityQueryParser qqParser = new SimpleQQParser(\"title\",\"body\");\n    QualityBenchmark qrun = new QualityBenchmark(qqs, qqParser, searcher, docNameField);\n    \n    SubmissionReport submitLog = VERBOSE ? new SubmissionReport(logger, \"TestRun\") : null;\n    qrun.setMaxResults(maxResults);\n    QualityStats stats[] = qrun.execute(judge, submitLog, logger);\n    \n    // --------- verify by the way judgments were altered for this test:\n    // for some queries, depending on m = qnum % 8\n    // m==0: avg_precision and recall are hurt, by marking fake docs as relevant\n    // m==1: precision_at_n and avg_precision are hurt, by unmarking relevant docs\n    // m==2: all precision, precision_at_n and recall are hurt.\n    // m>=3: these queries remain perfect\n    for (int i = 0; i < stats.length; i++) {\n      QualityStats s = stats[i];\n      switch (i%8) {\n\n      case 0:\n        assertTrue(\"avg-p should be hurt: \"+s.getAvp(), 1.0 > s.getAvp());\n        assertTrue(\"recall should be hurt: \"+s.getRecall(), 1.0 > s.getRecall());\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertEquals(\"p_at_\"+j+\" should be perfect: \"+s.getPrecisionAt(j), 1.0, s.getPrecisionAt(j), 1E-2);\n        }\n        break;\n      \n      case 1:\n        assertTrue(\"avg-p should be hurt\", 1.0 > s.getAvp());\n        assertEquals(\"recall should be perfect: \"+s.getRecall(), 1.0, s.getRecall(), 1E-2);\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertTrue(\"p_at_\"+j+\" should be hurt: \"+s.getPrecisionAt(j), 1.0 > s.getPrecisionAt(j));\n        }\n        break;\n\n      case 2:\n        assertTrue(\"avg-p should be hurt: \"+s.getAvp(), 1.0 > s.getAvp());\n        assertTrue(\"recall should be hurt: \"+s.getRecall(), 1.0 > s.getRecall());\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertTrue(\"p_at_\"+j+\" should be hurt: \"+s.getPrecisionAt(j), 1.0 > s.getPrecisionAt(j));\n        }\n        break;\n\n      default: {\n        assertEquals(\"avg-p should be perfect: \"+s.getAvp(), 1.0, s.getAvp(), 1E-2);\n        assertEquals(\"recall should be perfect: \"+s.getRecall(), 1.0, s.getRecall(), 1E-2);\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertEquals(\"p_at_\"+j+\" should be perfect: \"+s.getPrecisionAt(j), 1.0, s.getPrecisionAt(j), 1E-2);\n        }\n      }\n      \n      }\n    }\n    \n    QualityStats avg = QualityStats.average(stats);\n    if (logger!=null) {\n      avg.log(\"Average statistis:\",1,logger,\"  \");\n    }\n    \n    assertTrue(\"mean avg-p should be hurt: \"+avg.getAvp(), 1.0 > avg.getAvp());\n    assertTrue(\"avg recall should be hurt: \"+avg.getRecall(), 1.0 > avg.getRecall());\n    for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n      assertTrue(\"avg p_at_\"+j+\" should be hurt: \"+avg.getPrecisionAt(j), 1.0 > avg.getPrecisionAt(j));\n    }\n    \n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testTrecQuality() throws Exception {\n    // first create the partial reuters index\n    createReutersIndex();\n    \n    int maxResults = 1000;\n    String docNameField = \"doctitle\"; // orig docID is in the linedoc format title \n    \n    PrintWriter logger = VERBOSE ? new PrintWriter(System.out,true) : null;\n   \n    // prepare topics\n    InputStream topics = getClass().getResourceAsStream(\"trecTopics.txt\");\n    TrecTopicsReader qReader = new TrecTopicsReader();\n    QualityQuery qqs[] = qReader.readQueries(new BufferedReader(new InputStreamReader(topics, \"UTF-8\")));\n    \n    // prepare judge\n    InputStream qrels = getClass().getResourceAsStream(\"trecQRels.txt\");\n    Judge judge = new TrecJudge(new BufferedReader(new InputStreamReader(qrels, \"UTF-8\")));\n    \n    // validate topics & judgments match each other\n    judge.validateData(qqs, logger);\n    \n    Directory dir = newFSDirectory(new File(getWorkDir(),\"index\"));\n    IndexReader reader = DirectoryReader.open(dir);\n    IndexSearcher searcher = new IndexSearcher(reader);\n\n    QualityQueryParser qqParser = new SimpleQQParser(\"title\",\"body\");\n    QualityBenchmark qrun = new QualityBenchmark(qqs, qqParser, searcher, docNameField);\n    \n    SubmissionReport submitLog = VERBOSE ? new SubmissionReport(logger, \"TestRun\") : null;\n    qrun.setMaxResults(maxResults);\n    QualityStats stats[] = qrun.execute(judge, submitLog, logger);\n    \n    // --------- verify by the way judgments were altered for this test:\n    // for some queries, depending on m = qnum % 8\n    // m==0: avg_precision and recall are hurt, by marking fake docs as relevant\n    // m==1: precision_at_n and avg_precision are hurt, by unmarking relevant docs\n    // m==2: all precision, precision_at_n and recall are hurt.\n    // m>=3: these queries remain perfect\n    for (int i = 0; i < stats.length; i++) {\n      QualityStats s = stats[i];\n      switch (i%8) {\n\n      case 0:\n        assertTrue(\"avg-p should be hurt: \"+s.getAvp(), 1.0 > s.getAvp());\n        assertTrue(\"recall should be hurt: \"+s.getRecall(), 1.0 > s.getRecall());\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertEquals(\"p_at_\"+j+\" should be perfect: \"+s.getPrecisionAt(j), 1.0, s.getPrecisionAt(j), 1E-2);\n        }\n        break;\n      \n      case 1:\n        assertTrue(\"avg-p should be hurt\", 1.0 > s.getAvp());\n        assertEquals(\"recall should be perfect: \"+s.getRecall(), 1.0, s.getRecall(), 1E-2);\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertTrue(\"p_at_\"+j+\" should be hurt: \"+s.getPrecisionAt(j), 1.0 > s.getPrecisionAt(j));\n        }\n        break;\n\n      case 2:\n        assertTrue(\"avg-p should be hurt: \"+s.getAvp(), 1.0 > s.getAvp());\n        assertTrue(\"recall should be hurt: \"+s.getRecall(), 1.0 > s.getRecall());\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertTrue(\"p_at_\"+j+\" should be hurt: \"+s.getPrecisionAt(j), 1.0 > s.getPrecisionAt(j));\n        }\n        break;\n\n      default: {\n        assertEquals(\"avg-p should be perfect: \"+s.getAvp(), 1.0, s.getAvp(), 1E-2);\n        assertEquals(\"recall should be perfect: \"+s.getRecall(), 1.0, s.getRecall(), 1E-2);\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertEquals(\"p_at_\"+j+\" should be perfect: \"+s.getPrecisionAt(j), 1.0, s.getPrecisionAt(j), 1E-2);\n        }\n      }\n      \n      }\n    }\n    \n    QualityStats avg = QualityStats.average(stats);\n    if (logger!=null) {\n      avg.log(\"Average statistis:\",1,logger,\"  \");\n    }\n    \n    assertTrue(\"mean avg-p should be hurt: \"+avg.getAvp(), 1.0 > avg.getAvp());\n    assertTrue(\"avg recall should be hurt: \"+avg.getRecall(), 1.0 > avg.getRecall());\n    for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n      assertTrue(\"avg p_at_\"+j+\" should be hurt: \"+avg.getPrecisionAt(j), 1.0 > avg.getPrecisionAt(j));\n    }\n    \n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"46d8ada1fff8d18cb197c38c7983225162599948","date":1341853497,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/benchmark/src/test/org/apache/lucene/benchmark/quality/TestQualityRun#testTrecQuality().mjava","pathOld":"lucene/benchmark/src/test/org/apache/lucene/benchmark/quality/TestQualityRun#testTrecQuality().mjava","sourceNew":"  public void testTrecQuality() throws Exception {\n    // first create the partial reuters index\n    createReutersIndex();\n    \n    int maxResults = 1000;\n    String docNameField = \"doctitle\"; // orig docID is in the linedoc format title \n    \n    PrintWriter logger = VERBOSE ? new PrintWriter(new OutputStreamWriter(System.out, Charset.defaultCharset()),true) : null;\n   \n    // prepare topics\n    InputStream topics = getClass().getResourceAsStream(\"trecTopics.txt\");\n    TrecTopicsReader qReader = new TrecTopicsReader();\n    QualityQuery qqs[] = qReader.readQueries(new BufferedReader(new InputStreamReader(topics, \"UTF-8\")));\n    \n    // prepare judge\n    InputStream qrels = getClass().getResourceAsStream(\"trecQRels.txt\");\n    Judge judge = new TrecJudge(new BufferedReader(new InputStreamReader(qrels, \"UTF-8\")));\n    \n    // validate topics & judgments match each other\n    judge.validateData(qqs, logger);\n    \n    Directory dir = newFSDirectory(new File(getWorkDir(),\"index\"));\n    IndexReader reader = DirectoryReader.open(dir);\n    IndexSearcher searcher = new IndexSearcher(reader);\n\n    QualityQueryParser qqParser = new SimpleQQParser(\"title\",\"body\");\n    QualityBenchmark qrun = new QualityBenchmark(qqs, qqParser, searcher, docNameField);\n    \n    SubmissionReport submitLog = VERBOSE ? new SubmissionReport(logger, \"TestRun\") : null;\n    qrun.setMaxResults(maxResults);\n    QualityStats stats[] = qrun.execute(judge, submitLog, logger);\n    \n    // --------- verify by the way judgments were altered for this test:\n    // for some queries, depending on m = qnum % 8\n    // m==0: avg_precision and recall are hurt, by marking fake docs as relevant\n    // m==1: precision_at_n and avg_precision are hurt, by unmarking relevant docs\n    // m==2: all precision, precision_at_n and recall are hurt.\n    // m>=3: these queries remain perfect\n    for (int i = 0; i < stats.length; i++) {\n      QualityStats s = stats[i];\n      switch (i%8) {\n\n      case 0:\n        assertTrue(\"avg-p should be hurt: \"+s.getAvp(), 1.0 > s.getAvp());\n        assertTrue(\"recall should be hurt: \"+s.getRecall(), 1.0 > s.getRecall());\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertEquals(\"p_at_\"+j+\" should be perfect: \"+s.getPrecisionAt(j), 1.0, s.getPrecisionAt(j), 1E-2);\n        }\n        break;\n      \n      case 1:\n        assertTrue(\"avg-p should be hurt\", 1.0 > s.getAvp());\n        assertEquals(\"recall should be perfect: \"+s.getRecall(), 1.0, s.getRecall(), 1E-2);\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertTrue(\"p_at_\"+j+\" should be hurt: \"+s.getPrecisionAt(j), 1.0 > s.getPrecisionAt(j));\n        }\n        break;\n\n      case 2:\n        assertTrue(\"avg-p should be hurt: \"+s.getAvp(), 1.0 > s.getAvp());\n        assertTrue(\"recall should be hurt: \"+s.getRecall(), 1.0 > s.getRecall());\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertTrue(\"p_at_\"+j+\" should be hurt: \"+s.getPrecisionAt(j), 1.0 > s.getPrecisionAt(j));\n        }\n        break;\n\n      default: {\n        assertEquals(\"avg-p should be perfect: \"+s.getAvp(), 1.0, s.getAvp(), 1E-2);\n        assertEquals(\"recall should be perfect: \"+s.getRecall(), 1.0, s.getRecall(), 1E-2);\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertEquals(\"p_at_\"+j+\" should be perfect: \"+s.getPrecisionAt(j), 1.0, s.getPrecisionAt(j), 1E-2);\n        }\n      }\n      \n      }\n    }\n    \n    QualityStats avg = QualityStats.average(stats);\n    if (logger!=null) {\n      avg.log(\"Average statistis:\",1,logger,\"  \");\n    }\n    \n    assertTrue(\"mean avg-p should be hurt: \"+avg.getAvp(), 1.0 > avg.getAvp());\n    assertTrue(\"avg recall should be hurt: \"+avg.getRecall(), 1.0 > avg.getRecall());\n    for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n      assertTrue(\"avg p_at_\"+j+\" should be hurt: \"+avg.getPrecisionAt(j), 1.0 > avg.getPrecisionAt(j));\n    }\n    \n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testTrecQuality() throws Exception {\n    // first create the partial reuters index\n    createReutersIndex();\n    \n    int maxResults = 1000;\n    String docNameField = \"doctitle\"; // orig docID is in the linedoc format title \n    \n    PrintWriter logger = VERBOSE ? new PrintWriter(System.out,true) : null;\n   \n    // prepare topics\n    InputStream topics = getClass().getResourceAsStream(\"trecTopics.txt\");\n    TrecTopicsReader qReader = new TrecTopicsReader();\n    QualityQuery qqs[] = qReader.readQueries(new BufferedReader(new InputStreamReader(topics, \"UTF-8\")));\n    \n    // prepare judge\n    InputStream qrels = getClass().getResourceAsStream(\"trecQRels.txt\");\n    Judge judge = new TrecJudge(new BufferedReader(new InputStreamReader(qrels, \"UTF-8\")));\n    \n    // validate topics & judgments match each other\n    judge.validateData(qqs, logger);\n    \n    Directory dir = newFSDirectory(new File(getWorkDir(),\"index\"));\n    IndexReader reader = DirectoryReader.open(dir);\n    IndexSearcher searcher = new IndexSearcher(reader);\n\n    QualityQueryParser qqParser = new SimpleQQParser(\"title\",\"body\");\n    QualityBenchmark qrun = new QualityBenchmark(qqs, qqParser, searcher, docNameField);\n    \n    SubmissionReport submitLog = VERBOSE ? new SubmissionReport(logger, \"TestRun\") : null;\n    qrun.setMaxResults(maxResults);\n    QualityStats stats[] = qrun.execute(judge, submitLog, logger);\n    \n    // --------- verify by the way judgments were altered for this test:\n    // for some queries, depending on m = qnum % 8\n    // m==0: avg_precision and recall are hurt, by marking fake docs as relevant\n    // m==1: precision_at_n and avg_precision are hurt, by unmarking relevant docs\n    // m==2: all precision, precision_at_n and recall are hurt.\n    // m>=3: these queries remain perfect\n    for (int i = 0; i < stats.length; i++) {\n      QualityStats s = stats[i];\n      switch (i%8) {\n\n      case 0:\n        assertTrue(\"avg-p should be hurt: \"+s.getAvp(), 1.0 > s.getAvp());\n        assertTrue(\"recall should be hurt: \"+s.getRecall(), 1.0 > s.getRecall());\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertEquals(\"p_at_\"+j+\" should be perfect: \"+s.getPrecisionAt(j), 1.0, s.getPrecisionAt(j), 1E-2);\n        }\n        break;\n      \n      case 1:\n        assertTrue(\"avg-p should be hurt\", 1.0 > s.getAvp());\n        assertEquals(\"recall should be perfect: \"+s.getRecall(), 1.0, s.getRecall(), 1E-2);\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertTrue(\"p_at_\"+j+\" should be hurt: \"+s.getPrecisionAt(j), 1.0 > s.getPrecisionAt(j));\n        }\n        break;\n\n      case 2:\n        assertTrue(\"avg-p should be hurt: \"+s.getAvp(), 1.0 > s.getAvp());\n        assertTrue(\"recall should be hurt: \"+s.getRecall(), 1.0 > s.getRecall());\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertTrue(\"p_at_\"+j+\" should be hurt: \"+s.getPrecisionAt(j), 1.0 > s.getPrecisionAt(j));\n        }\n        break;\n\n      default: {\n        assertEquals(\"avg-p should be perfect: \"+s.getAvp(), 1.0, s.getAvp(), 1E-2);\n        assertEquals(\"recall should be perfect: \"+s.getRecall(), 1.0, s.getRecall(), 1E-2);\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertEquals(\"p_at_\"+j+\" should be perfect: \"+s.getPrecisionAt(j), 1.0, s.getPrecisionAt(j), 1E-2);\n        }\n      }\n      \n      }\n    }\n    \n    QualityStats avg = QualityStats.average(stats);\n    if (logger!=null) {\n      avg.log(\"Average statistis:\",1,logger,\"  \");\n    }\n    \n    assertTrue(\"mean avg-p should be hurt: \"+avg.getAvp(), 1.0 > avg.getAvp());\n    assertTrue(\"avg recall should be hurt: \"+avg.getRecall(), 1.0 > avg.getRecall());\n    for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n      assertTrue(\"avg p_at_\"+j+\" should be hurt: \"+avg.getPrecisionAt(j), 1.0 > avg.getPrecisionAt(j));\n    }\n    \n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fe33227f6805edab2036cbb80645cc4e2d1fa424","date":1342713534,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/benchmark/src/test/org/apache/lucene/benchmark/quality/TestQualityRun#testTrecQuality().mjava","pathOld":"lucene/benchmark/src/test/org/apache/lucene/benchmark/quality/TestQualityRun#testTrecQuality().mjava","sourceNew":"  public void testTrecQuality() throws Exception {\n    // first create the partial reuters index\n    createReutersIndex();\n    \n    int maxResults = 1000;\n    String docNameField = \"doctitle\"; // orig docID is in the linedoc format title \n    \n    PrintWriter logger = VERBOSE ? new PrintWriter(new OutputStreamWriter(System.out, Charset.defaultCharset()),true) : null;\n   \n    // prepare topics\n    InputStream topics = getClass().getResourceAsStream(\"trecTopics.txt\");\n    TrecTopicsReader qReader = new TrecTopicsReader();\n    QualityQuery qqs[] = qReader.readQueries(new BufferedReader(new InputStreamReader(topics, \"UTF-8\")));\n    \n    // prepare judge\n    InputStream qrels = getClass().getResourceAsStream(\"trecQRels.txt\");\n    Judge judge = new TrecJudge(new BufferedReader(new InputStreamReader(qrels, \"UTF-8\")));\n    \n    // validate topics & judgments match each other\n    judge.validateData(qqs, logger);\n    \n    Directory dir = newFSDirectory(new File(getWorkDir(),\"index\"));\n    IndexReader reader = DirectoryReader.open(dir);\n    IndexSearcher searcher = new IndexSearcher(reader);\n\n    QualityQueryParser qqParser = new SimpleQQParser(\"title\",\"body\");\n    QualityBenchmark qrun = new QualityBenchmark(qqs, qqParser, searcher, docNameField);\n    \n    SubmissionReport submitLog = VERBOSE ? new SubmissionReport(logger, \"TestRun\") : null;\n    qrun.setMaxResults(maxResults);\n    QualityStats stats[] = qrun.execute(judge, submitLog, logger);\n    \n    // --------- verify by the way judgments were altered for this test:\n    // for some queries, depending on m = qnum % 8\n    // m==0: avg_precision and recall are hurt, by marking fake docs as relevant\n    // m==1: precision_at_n and avg_precision are hurt, by unmarking relevant docs\n    // m==2: all precision, precision_at_n and recall are hurt.\n    // m>=3: these queries remain perfect\n    for (int i = 0; i < stats.length; i++) {\n      QualityStats s = stats[i];\n      switch (i%8) {\n\n      case 0:\n        assertTrue(\"avg-p should be hurt: \"+s.getAvp(), 1.0 > s.getAvp());\n        assertTrue(\"recall should be hurt: \"+s.getRecall(), 1.0 > s.getRecall());\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertEquals(\"p_at_\"+j+\" should be perfect: \"+s.getPrecisionAt(j), 1.0, s.getPrecisionAt(j), 1E-2);\n        }\n        break;\n      \n      case 1:\n        assertTrue(\"avg-p should be hurt\", 1.0 > s.getAvp());\n        assertEquals(\"recall should be perfect: \"+s.getRecall(), 1.0, s.getRecall(), 1E-2);\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertTrue(\"p_at_\"+j+\" should be hurt: \"+s.getPrecisionAt(j), 1.0 > s.getPrecisionAt(j));\n        }\n        break;\n\n      case 2:\n        assertTrue(\"avg-p should be hurt: \"+s.getAvp(), 1.0 > s.getAvp());\n        assertTrue(\"recall should be hurt: \"+s.getRecall(), 1.0 > s.getRecall());\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertTrue(\"p_at_\"+j+\" should be hurt: \"+s.getPrecisionAt(j), 1.0 > s.getPrecisionAt(j));\n        }\n        break;\n\n      default: {\n        assertEquals(\"avg-p should be perfect: \"+s.getAvp(), 1.0, s.getAvp(), 1E-2);\n        assertEquals(\"recall should be perfect: \"+s.getRecall(), 1.0, s.getRecall(), 1E-2);\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertEquals(\"p_at_\"+j+\" should be perfect: \"+s.getPrecisionAt(j), 1.0, s.getPrecisionAt(j), 1E-2);\n        }\n      }\n      \n      }\n    }\n    \n    QualityStats avg = QualityStats.average(stats);\n    if (logger!=null) {\n      avg.log(\"Average statistis:\",1,logger,\"  \");\n    }\n    \n    assertTrue(\"mean avg-p should be hurt: \"+avg.getAvp(), 1.0 > avg.getAvp());\n    assertTrue(\"avg recall should be hurt: \"+avg.getRecall(), 1.0 > avg.getRecall());\n    for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n      assertTrue(\"avg p_at_\"+j+\" should be hurt: \"+avg.getPrecisionAt(j), 1.0 > avg.getPrecisionAt(j));\n    }\n    \n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testTrecQuality() throws Exception {\n    // first create the partial reuters index\n    createReutersIndex();\n    \n    int maxResults = 1000;\n    String docNameField = \"doctitle\"; // orig docID is in the linedoc format title \n    \n    PrintWriter logger = VERBOSE ? new PrintWriter(System.out,true) : null;\n   \n    // prepare topics\n    InputStream topics = getClass().getResourceAsStream(\"trecTopics.txt\");\n    TrecTopicsReader qReader = new TrecTopicsReader();\n    QualityQuery qqs[] = qReader.readQueries(new BufferedReader(new InputStreamReader(topics, \"UTF-8\")));\n    \n    // prepare judge\n    InputStream qrels = getClass().getResourceAsStream(\"trecQRels.txt\");\n    Judge judge = new TrecJudge(new BufferedReader(new InputStreamReader(qrels, \"UTF-8\")));\n    \n    // validate topics & judgments match each other\n    judge.validateData(qqs, logger);\n    \n    Directory dir = newFSDirectory(new File(getWorkDir(),\"index\"));\n    IndexReader reader = DirectoryReader.open(dir);\n    IndexSearcher searcher = new IndexSearcher(reader);\n\n    QualityQueryParser qqParser = new SimpleQQParser(\"title\",\"body\");\n    QualityBenchmark qrun = new QualityBenchmark(qqs, qqParser, searcher, docNameField);\n    \n    SubmissionReport submitLog = VERBOSE ? new SubmissionReport(logger, \"TestRun\") : null;\n    qrun.setMaxResults(maxResults);\n    QualityStats stats[] = qrun.execute(judge, submitLog, logger);\n    \n    // --------- verify by the way judgments were altered for this test:\n    // for some queries, depending on m = qnum % 8\n    // m==0: avg_precision and recall are hurt, by marking fake docs as relevant\n    // m==1: precision_at_n and avg_precision are hurt, by unmarking relevant docs\n    // m==2: all precision, precision_at_n and recall are hurt.\n    // m>=3: these queries remain perfect\n    for (int i = 0; i < stats.length; i++) {\n      QualityStats s = stats[i];\n      switch (i%8) {\n\n      case 0:\n        assertTrue(\"avg-p should be hurt: \"+s.getAvp(), 1.0 > s.getAvp());\n        assertTrue(\"recall should be hurt: \"+s.getRecall(), 1.0 > s.getRecall());\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertEquals(\"p_at_\"+j+\" should be perfect: \"+s.getPrecisionAt(j), 1.0, s.getPrecisionAt(j), 1E-2);\n        }\n        break;\n      \n      case 1:\n        assertTrue(\"avg-p should be hurt\", 1.0 > s.getAvp());\n        assertEquals(\"recall should be perfect: \"+s.getRecall(), 1.0, s.getRecall(), 1E-2);\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertTrue(\"p_at_\"+j+\" should be hurt: \"+s.getPrecisionAt(j), 1.0 > s.getPrecisionAt(j));\n        }\n        break;\n\n      case 2:\n        assertTrue(\"avg-p should be hurt: \"+s.getAvp(), 1.0 > s.getAvp());\n        assertTrue(\"recall should be hurt: \"+s.getRecall(), 1.0 > s.getRecall());\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertTrue(\"p_at_\"+j+\" should be hurt: \"+s.getPrecisionAt(j), 1.0 > s.getPrecisionAt(j));\n        }\n        break;\n\n      default: {\n        assertEquals(\"avg-p should be perfect: \"+s.getAvp(), 1.0, s.getAvp(), 1E-2);\n        assertEquals(\"recall should be perfect: \"+s.getRecall(), 1.0, s.getRecall(), 1E-2);\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertEquals(\"p_at_\"+j+\" should be perfect: \"+s.getPrecisionAt(j), 1.0, s.getPrecisionAt(j), 1E-2);\n        }\n      }\n      \n      }\n    }\n    \n    QualityStats avg = QualityStats.average(stats);\n    if (logger!=null) {\n      avg.log(\"Average statistis:\",1,logger,\"  \");\n    }\n    \n    assertTrue(\"mean avg-p should be hurt: \"+avg.getAvp(), 1.0 > avg.getAvp());\n    assertTrue(\"avg recall should be hurt: \"+avg.getRecall(), 1.0 > avg.getRecall());\n    for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n      assertTrue(\"avg p_at_\"+j+\" should be hurt: \"+avg.getPrecisionAt(j), 1.0 > avg.getPrecisionAt(j));\n    }\n    \n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7d89d7e4e5101347833eea558851bf4209218619","date":1396265641,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/benchmark/src/test/org/apache/lucene/benchmark/quality/TestQualityRun#testTrecQuality().mjava","pathOld":"lucene/benchmark/src/test/org/apache/lucene/benchmark/quality/TestQualityRun#testTrecQuality().mjava","sourceNew":"  public void testTrecQuality() throws Exception {\n    // first create the partial reuters index\n    createReutersIndex();\n    \n    int maxResults = 1000;\n    String docNameField = \"doctitle\"; // orig docID is in the linedoc format title \n    \n    PrintWriter logger = VERBOSE ? new PrintWriter(new OutputStreamWriter(System.out, Charset.defaultCharset()),true) : null;\n   \n    // prepare topics\n    InputStream topics = getClass().getResourceAsStream(\"trecTopics.txt\");\n    TrecTopicsReader qReader = new TrecTopicsReader();\n    QualityQuery qqs[] = qReader.readQueries(new BufferedReader(new InputStreamReader(topics, StandardCharsets.UTF_8)));\n    \n    // prepare judge\n    InputStream qrels = getClass().getResourceAsStream(\"trecQRels.txt\");\n    Judge judge = new TrecJudge(new BufferedReader(new InputStreamReader(qrels, StandardCharsets.UTF_8)));\n    \n    // validate topics & judgments match each other\n    judge.validateData(qqs, logger);\n    \n    Directory dir = newFSDirectory(new File(getWorkDir(),\"index\"));\n    IndexReader reader = DirectoryReader.open(dir);\n    IndexSearcher searcher = new IndexSearcher(reader);\n\n    QualityQueryParser qqParser = new SimpleQQParser(\"title\",\"body\");\n    QualityBenchmark qrun = new QualityBenchmark(qqs, qqParser, searcher, docNameField);\n    \n    SubmissionReport submitLog = VERBOSE ? new SubmissionReport(logger, \"TestRun\") : null;\n    qrun.setMaxResults(maxResults);\n    QualityStats stats[] = qrun.execute(judge, submitLog, logger);\n    \n    // --------- verify by the way judgments were altered for this test:\n    // for some queries, depending on m = qnum % 8\n    // m==0: avg_precision and recall are hurt, by marking fake docs as relevant\n    // m==1: precision_at_n and avg_precision are hurt, by unmarking relevant docs\n    // m==2: all precision, precision_at_n and recall are hurt.\n    // m>=3: these queries remain perfect\n    for (int i = 0; i < stats.length; i++) {\n      QualityStats s = stats[i];\n      switch (i%8) {\n\n      case 0:\n        assertTrue(\"avg-p should be hurt: \"+s.getAvp(), 1.0 > s.getAvp());\n        assertTrue(\"recall should be hurt: \"+s.getRecall(), 1.0 > s.getRecall());\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertEquals(\"p_at_\"+j+\" should be perfect: \"+s.getPrecisionAt(j), 1.0, s.getPrecisionAt(j), 1E-2);\n        }\n        break;\n      \n      case 1:\n        assertTrue(\"avg-p should be hurt\", 1.0 > s.getAvp());\n        assertEquals(\"recall should be perfect: \"+s.getRecall(), 1.0, s.getRecall(), 1E-2);\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertTrue(\"p_at_\"+j+\" should be hurt: \"+s.getPrecisionAt(j), 1.0 > s.getPrecisionAt(j));\n        }\n        break;\n\n      case 2:\n        assertTrue(\"avg-p should be hurt: \"+s.getAvp(), 1.0 > s.getAvp());\n        assertTrue(\"recall should be hurt: \"+s.getRecall(), 1.0 > s.getRecall());\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertTrue(\"p_at_\"+j+\" should be hurt: \"+s.getPrecisionAt(j), 1.0 > s.getPrecisionAt(j));\n        }\n        break;\n\n      default: {\n        assertEquals(\"avg-p should be perfect: \"+s.getAvp(), 1.0, s.getAvp(), 1E-2);\n        assertEquals(\"recall should be perfect: \"+s.getRecall(), 1.0, s.getRecall(), 1E-2);\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertEquals(\"p_at_\"+j+\" should be perfect: \"+s.getPrecisionAt(j), 1.0, s.getPrecisionAt(j), 1E-2);\n        }\n      }\n      \n      }\n    }\n    \n    QualityStats avg = QualityStats.average(stats);\n    if (logger!=null) {\n      avg.log(\"Average statistis:\",1,logger,\"  \");\n    }\n    \n    assertTrue(\"mean avg-p should be hurt: \"+avg.getAvp(), 1.0 > avg.getAvp());\n    assertTrue(\"avg recall should be hurt: \"+avg.getRecall(), 1.0 > avg.getRecall());\n    for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n      assertTrue(\"avg p_at_\"+j+\" should be hurt: \"+avg.getPrecisionAt(j), 1.0 > avg.getPrecisionAt(j));\n    }\n    \n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testTrecQuality() throws Exception {\n    // first create the partial reuters index\n    createReutersIndex();\n    \n    int maxResults = 1000;\n    String docNameField = \"doctitle\"; // orig docID is in the linedoc format title \n    \n    PrintWriter logger = VERBOSE ? new PrintWriter(new OutputStreamWriter(System.out, Charset.defaultCharset()),true) : null;\n   \n    // prepare topics\n    InputStream topics = getClass().getResourceAsStream(\"trecTopics.txt\");\n    TrecTopicsReader qReader = new TrecTopicsReader();\n    QualityQuery qqs[] = qReader.readQueries(new BufferedReader(new InputStreamReader(topics, \"UTF-8\")));\n    \n    // prepare judge\n    InputStream qrels = getClass().getResourceAsStream(\"trecQRels.txt\");\n    Judge judge = new TrecJudge(new BufferedReader(new InputStreamReader(qrels, \"UTF-8\")));\n    \n    // validate topics & judgments match each other\n    judge.validateData(qqs, logger);\n    \n    Directory dir = newFSDirectory(new File(getWorkDir(),\"index\"));\n    IndexReader reader = DirectoryReader.open(dir);\n    IndexSearcher searcher = new IndexSearcher(reader);\n\n    QualityQueryParser qqParser = new SimpleQQParser(\"title\",\"body\");\n    QualityBenchmark qrun = new QualityBenchmark(qqs, qqParser, searcher, docNameField);\n    \n    SubmissionReport submitLog = VERBOSE ? new SubmissionReport(logger, \"TestRun\") : null;\n    qrun.setMaxResults(maxResults);\n    QualityStats stats[] = qrun.execute(judge, submitLog, logger);\n    \n    // --------- verify by the way judgments were altered for this test:\n    // for some queries, depending on m = qnum % 8\n    // m==0: avg_precision and recall are hurt, by marking fake docs as relevant\n    // m==1: precision_at_n and avg_precision are hurt, by unmarking relevant docs\n    // m==2: all precision, precision_at_n and recall are hurt.\n    // m>=3: these queries remain perfect\n    for (int i = 0; i < stats.length; i++) {\n      QualityStats s = stats[i];\n      switch (i%8) {\n\n      case 0:\n        assertTrue(\"avg-p should be hurt: \"+s.getAvp(), 1.0 > s.getAvp());\n        assertTrue(\"recall should be hurt: \"+s.getRecall(), 1.0 > s.getRecall());\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertEquals(\"p_at_\"+j+\" should be perfect: \"+s.getPrecisionAt(j), 1.0, s.getPrecisionAt(j), 1E-2);\n        }\n        break;\n      \n      case 1:\n        assertTrue(\"avg-p should be hurt\", 1.0 > s.getAvp());\n        assertEquals(\"recall should be perfect: \"+s.getRecall(), 1.0, s.getRecall(), 1E-2);\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertTrue(\"p_at_\"+j+\" should be hurt: \"+s.getPrecisionAt(j), 1.0 > s.getPrecisionAt(j));\n        }\n        break;\n\n      case 2:\n        assertTrue(\"avg-p should be hurt: \"+s.getAvp(), 1.0 > s.getAvp());\n        assertTrue(\"recall should be hurt: \"+s.getRecall(), 1.0 > s.getRecall());\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertTrue(\"p_at_\"+j+\" should be hurt: \"+s.getPrecisionAt(j), 1.0 > s.getPrecisionAt(j));\n        }\n        break;\n\n      default: {\n        assertEquals(\"avg-p should be perfect: \"+s.getAvp(), 1.0, s.getAvp(), 1E-2);\n        assertEquals(\"recall should be perfect: \"+s.getRecall(), 1.0, s.getRecall(), 1E-2);\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertEquals(\"p_at_\"+j+\" should be perfect: \"+s.getPrecisionAt(j), 1.0, s.getPrecisionAt(j), 1E-2);\n        }\n      }\n      \n      }\n    }\n    \n    QualityStats avg = QualityStats.average(stats);\n    if (logger!=null) {\n      avg.log(\"Average statistis:\",1,logger,\"  \");\n    }\n    \n    assertTrue(\"mean avg-p should be hurt: \"+avg.getAvp(), 1.0 > avg.getAvp());\n    assertTrue(\"avg recall should be hurt: \"+avg.getRecall(), 1.0 > avg.getRecall());\n    for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n      assertTrue(\"avg p_at_\"+j+\" should be hurt: \"+avg.getPrecisionAt(j), 1.0 > avg.getPrecisionAt(j));\n    }\n    \n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5eb2511ababf862ea11e10761c70ee560cd84510","date":1396607225,"type":3,"author":"Dawid Weiss","isMerge":true,"pathNew":"lucene/benchmark/src/test/org/apache/lucene/benchmark/quality/TestQualityRun#testTrecQuality().mjava","pathOld":"lucene/benchmark/src/test/org/apache/lucene/benchmark/quality/TestQualityRun#testTrecQuality().mjava","sourceNew":"  public void testTrecQuality() throws Exception {\n    // first create the partial reuters index\n    createReutersIndex();\n    \n    int maxResults = 1000;\n    String docNameField = \"doctitle\"; // orig docID is in the linedoc format title \n    \n    PrintWriter logger = VERBOSE ? new PrintWriter(new OutputStreamWriter(System.out, Charset.defaultCharset()),true) : null;\n   \n    // prepare topics\n    InputStream topics = getClass().getResourceAsStream(\"trecTopics.txt\");\n    TrecTopicsReader qReader = new TrecTopicsReader();\n    QualityQuery qqs[] = qReader.readQueries(new BufferedReader(new InputStreamReader(topics, StandardCharsets.UTF_8)));\n    \n    // prepare judge\n    InputStream qrels = getClass().getResourceAsStream(\"trecQRels.txt\");\n    Judge judge = new TrecJudge(new BufferedReader(new InputStreamReader(qrels, StandardCharsets.UTF_8)));\n    \n    // validate topics & judgments match each other\n    judge.validateData(qqs, logger);\n    \n    Directory dir = newFSDirectory(new File(getWorkDir(),\"index\"));\n    IndexReader reader = DirectoryReader.open(dir);\n    IndexSearcher searcher = new IndexSearcher(reader);\n\n    QualityQueryParser qqParser = new SimpleQQParser(\"title\",\"body\");\n    QualityBenchmark qrun = new QualityBenchmark(qqs, qqParser, searcher, docNameField);\n    \n    SubmissionReport submitLog = VERBOSE ? new SubmissionReport(logger, \"TestRun\") : null;\n    qrun.setMaxResults(maxResults);\n    QualityStats stats[] = qrun.execute(judge, submitLog, logger);\n    \n    // --------- verify by the way judgments were altered for this test:\n    // for some queries, depending on m = qnum % 8\n    // m==0: avg_precision and recall are hurt, by marking fake docs as relevant\n    // m==1: precision_at_n and avg_precision are hurt, by unmarking relevant docs\n    // m==2: all precision, precision_at_n and recall are hurt.\n    // m>=3: these queries remain perfect\n    for (int i = 0; i < stats.length; i++) {\n      QualityStats s = stats[i];\n      switch (i%8) {\n\n      case 0:\n        assertTrue(\"avg-p should be hurt: \"+s.getAvp(), 1.0 > s.getAvp());\n        assertTrue(\"recall should be hurt: \"+s.getRecall(), 1.0 > s.getRecall());\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertEquals(\"p_at_\"+j+\" should be perfect: \"+s.getPrecisionAt(j), 1.0, s.getPrecisionAt(j), 1E-2);\n        }\n        break;\n      \n      case 1:\n        assertTrue(\"avg-p should be hurt\", 1.0 > s.getAvp());\n        assertEquals(\"recall should be perfect: \"+s.getRecall(), 1.0, s.getRecall(), 1E-2);\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertTrue(\"p_at_\"+j+\" should be hurt: \"+s.getPrecisionAt(j), 1.0 > s.getPrecisionAt(j));\n        }\n        break;\n\n      case 2:\n        assertTrue(\"avg-p should be hurt: \"+s.getAvp(), 1.0 > s.getAvp());\n        assertTrue(\"recall should be hurt: \"+s.getRecall(), 1.0 > s.getRecall());\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertTrue(\"p_at_\"+j+\" should be hurt: \"+s.getPrecisionAt(j), 1.0 > s.getPrecisionAt(j));\n        }\n        break;\n\n      default: {\n        assertEquals(\"avg-p should be perfect: \"+s.getAvp(), 1.0, s.getAvp(), 1E-2);\n        assertEquals(\"recall should be perfect: \"+s.getRecall(), 1.0, s.getRecall(), 1E-2);\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertEquals(\"p_at_\"+j+\" should be perfect: \"+s.getPrecisionAt(j), 1.0, s.getPrecisionAt(j), 1E-2);\n        }\n      }\n      \n      }\n    }\n    \n    QualityStats avg = QualityStats.average(stats);\n    if (logger!=null) {\n      avg.log(\"Average statistis:\",1,logger,\"  \");\n    }\n    \n    assertTrue(\"mean avg-p should be hurt: \"+avg.getAvp(), 1.0 > avg.getAvp());\n    assertTrue(\"avg recall should be hurt: \"+avg.getRecall(), 1.0 > avg.getRecall());\n    for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n      assertTrue(\"avg p_at_\"+j+\" should be hurt: \"+avg.getPrecisionAt(j), 1.0 > avg.getPrecisionAt(j));\n    }\n    \n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testTrecQuality() throws Exception {\n    // first create the partial reuters index\n    createReutersIndex();\n    \n    int maxResults = 1000;\n    String docNameField = \"doctitle\"; // orig docID is in the linedoc format title \n    \n    PrintWriter logger = VERBOSE ? new PrintWriter(new OutputStreamWriter(System.out, Charset.defaultCharset()),true) : null;\n   \n    // prepare topics\n    InputStream topics = getClass().getResourceAsStream(\"trecTopics.txt\");\n    TrecTopicsReader qReader = new TrecTopicsReader();\n    QualityQuery qqs[] = qReader.readQueries(new BufferedReader(new InputStreamReader(topics, \"UTF-8\")));\n    \n    // prepare judge\n    InputStream qrels = getClass().getResourceAsStream(\"trecQRels.txt\");\n    Judge judge = new TrecJudge(new BufferedReader(new InputStreamReader(qrels, \"UTF-8\")));\n    \n    // validate topics & judgments match each other\n    judge.validateData(qqs, logger);\n    \n    Directory dir = newFSDirectory(new File(getWorkDir(),\"index\"));\n    IndexReader reader = DirectoryReader.open(dir);\n    IndexSearcher searcher = new IndexSearcher(reader);\n\n    QualityQueryParser qqParser = new SimpleQQParser(\"title\",\"body\");\n    QualityBenchmark qrun = new QualityBenchmark(qqs, qqParser, searcher, docNameField);\n    \n    SubmissionReport submitLog = VERBOSE ? new SubmissionReport(logger, \"TestRun\") : null;\n    qrun.setMaxResults(maxResults);\n    QualityStats stats[] = qrun.execute(judge, submitLog, logger);\n    \n    // --------- verify by the way judgments were altered for this test:\n    // for some queries, depending on m = qnum % 8\n    // m==0: avg_precision and recall are hurt, by marking fake docs as relevant\n    // m==1: precision_at_n and avg_precision are hurt, by unmarking relevant docs\n    // m==2: all precision, precision_at_n and recall are hurt.\n    // m>=3: these queries remain perfect\n    for (int i = 0; i < stats.length; i++) {\n      QualityStats s = stats[i];\n      switch (i%8) {\n\n      case 0:\n        assertTrue(\"avg-p should be hurt: \"+s.getAvp(), 1.0 > s.getAvp());\n        assertTrue(\"recall should be hurt: \"+s.getRecall(), 1.0 > s.getRecall());\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertEquals(\"p_at_\"+j+\" should be perfect: \"+s.getPrecisionAt(j), 1.0, s.getPrecisionAt(j), 1E-2);\n        }\n        break;\n      \n      case 1:\n        assertTrue(\"avg-p should be hurt\", 1.0 > s.getAvp());\n        assertEquals(\"recall should be perfect: \"+s.getRecall(), 1.0, s.getRecall(), 1E-2);\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertTrue(\"p_at_\"+j+\" should be hurt: \"+s.getPrecisionAt(j), 1.0 > s.getPrecisionAt(j));\n        }\n        break;\n\n      case 2:\n        assertTrue(\"avg-p should be hurt: \"+s.getAvp(), 1.0 > s.getAvp());\n        assertTrue(\"recall should be hurt: \"+s.getRecall(), 1.0 > s.getRecall());\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertTrue(\"p_at_\"+j+\" should be hurt: \"+s.getPrecisionAt(j), 1.0 > s.getPrecisionAt(j));\n        }\n        break;\n\n      default: {\n        assertEquals(\"avg-p should be perfect: \"+s.getAvp(), 1.0, s.getAvp(), 1E-2);\n        assertEquals(\"recall should be perfect: \"+s.getRecall(), 1.0, s.getRecall(), 1E-2);\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertEquals(\"p_at_\"+j+\" should be perfect: \"+s.getPrecisionAt(j), 1.0, s.getPrecisionAt(j), 1E-2);\n        }\n      }\n      \n      }\n    }\n    \n    QualityStats avg = QualityStats.average(stats);\n    if (logger!=null) {\n      avg.log(\"Average statistis:\",1,logger,\"  \");\n    }\n    \n    assertTrue(\"mean avg-p should be hurt: \"+avg.getAvp(), 1.0 > avg.getAvp());\n    assertTrue(\"avg recall should be hurt: \"+avg.getRecall(), 1.0 > avg.getRecall());\n    for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n      assertTrue(\"avg p_at_\"+j+\" should be hurt: \"+avg.getPrecisionAt(j), 1.0 > avg.getPrecisionAt(j));\n    }\n    \n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f4abec28b874149a7223e32cc7a01704c27790de","date":1410644789,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/benchmark/src/test/org/apache/lucene/benchmark/quality/TestQualityRun#testTrecQuality().mjava","pathOld":"lucene/benchmark/src/test/org/apache/lucene/benchmark/quality/TestQualityRun#testTrecQuality().mjava","sourceNew":"  public void testTrecQuality() throws Exception {\n    // first create the partial reuters index\n    createReutersIndex();\n    \n    int maxResults = 1000;\n    String docNameField = \"doctitle\"; // orig docID is in the linedoc format title \n    \n    PrintWriter logger = VERBOSE ? new PrintWriter(new OutputStreamWriter(System.out, Charset.defaultCharset()),true) : null;\n   \n    // prepare topics\n    InputStream topics = getClass().getResourceAsStream(\"trecTopics.txt\");\n    TrecTopicsReader qReader = new TrecTopicsReader();\n    QualityQuery qqs[] = qReader.readQueries(new BufferedReader(new InputStreamReader(topics, StandardCharsets.UTF_8)));\n    \n    // prepare judge\n    InputStream qrels = getClass().getResourceAsStream(\"trecQRels.txt\");\n    Judge judge = new TrecJudge(new BufferedReader(new InputStreamReader(qrels, StandardCharsets.UTF_8)));\n    \n    // validate topics & judgments match each other\n    judge.validateData(qqs, logger);\n    \n    Directory dir = newFSDirectory(getWorkDir().resolve(\"index\"));\n    IndexReader reader = DirectoryReader.open(dir);\n    IndexSearcher searcher = new IndexSearcher(reader);\n\n    QualityQueryParser qqParser = new SimpleQQParser(\"title\",\"body\");\n    QualityBenchmark qrun = new QualityBenchmark(qqs, qqParser, searcher, docNameField);\n    \n    SubmissionReport submitLog = VERBOSE ? new SubmissionReport(logger, \"TestRun\") : null;\n    qrun.setMaxResults(maxResults);\n    QualityStats stats[] = qrun.execute(judge, submitLog, logger);\n    \n    // --------- verify by the way judgments were altered for this test:\n    // for some queries, depending on m = qnum % 8\n    // m==0: avg_precision and recall are hurt, by marking fake docs as relevant\n    // m==1: precision_at_n and avg_precision are hurt, by unmarking relevant docs\n    // m==2: all precision, precision_at_n and recall are hurt.\n    // m>=3: these queries remain perfect\n    for (int i = 0; i < stats.length; i++) {\n      QualityStats s = stats[i];\n      switch (i%8) {\n\n      case 0:\n        assertTrue(\"avg-p should be hurt: \"+s.getAvp(), 1.0 > s.getAvp());\n        assertTrue(\"recall should be hurt: \"+s.getRecall(), 1.0 > s.getRecall());\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertEquals(\"p_at_\"+j+\" should be perfect: \"+s.getPrecisionAt(j), 1.0, s.getPrecisionAt(j), 1E-2);\n        }\n        break;\n      \n      case 1:\n        assertTrue(\"avg-p should be hurt\", 1.0 > s.getAvp());\n        assertEquals(\"recall should be perfect: \"+s.getRecall(), 1.0, s.getRecall(), 1E-2);\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertTrue(\"p_at_\"+j+\" should be hurt: \"+s.getPrecisionAt(j), 1.0 > s.getPrecisionAt(j));\n        }\n        break;\n\n      case 2:\n        assertTrue(\"avg-p should be hurt: \"+s.getAvp(), 1.0 > s.getAvp());\n        assertTrue(\"recall should be hurt: \"+s.getRecall(), 1.0 > s.getRecall());\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertTrue(\"p_at_\"+j+\" should be hurt: \"+s.getPrecisionAt(j), 1.0 > s.getPrecisionAt(j));\n        }\n        break;\n\n      default: {\n        assertEquals(\"avg-p should be perfect: \"+s.getAvp(), 1.0, s.getAvp(), 1E-2);\n        assertEquals(\"recall should be perfect: \"+s.getRecall(), 1.0, s.getRecall(), 1E-2);\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertEquals(\"p_at_\"+j+\" should be perfect: \"+s.getPrecisionAt(j), 1.0, s.getPrecisionAt(j), 1E-2);\n        }\n      }\n      \n      }\n    }\n    \n    QualityStats avg = QualityStats.average(stats);\n    if (logger!=null) {\n      avg.log(\"Average statistis:\",1,logger,\"  \");\n    }\n    \n    assertTrue(\"mean avg-p should be hurt: \"+avg.getAvp(), 1.0 > avg.getAvp());\n    assertTrue(\"avg recall should be hurt: \"+avg.getRecall(), 1.0 > avg.getRecall());\n    for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n      assertTrue(\"avg p_at_\"+j+\" should be hurt: \"+avg.getPrecisionAt(j), 1.0 > avg.getPrecisionAt(j));\n    }\n    \n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testTrecQuality() throws Exception {\n    // first create the partial reuters index\n    createReutersIndex();\n    \n    int maxResults = 1000;\n    String docNameField = \"doctitle\"; // orig docID is in the linedoc format title \n    \n    PrintWriter logger = VERBOSE ? new PrintWriter(new OutputStreamWriter(System.out, Charset.defaultCharset()),true) : null;\n   \n    // prepare topics\n    InputStream topics = getClass().getResourceAsStream(\"trecTopics.txt\");\n    TrecTopicsReader qReader = new TrecTopicsReader();\n    QualityQuery qqs[] = qReader.readQueries(new BufferedReader(new InputStreamReader(topics, StandardCharsets.UTF_8)));\n    \n    // prepare judge\n    InputStream qrels = getClass().getResourceAsStream(\"trecQRels.txt\");\n    Judge judge = new TrecJudge(new BufferedReader(new InputStreamReader(qrels, StandardCharsets.UTF_8)));\n    \n    // validate topics & judgments match each other\n    judge.validateData(qqs, logger);\n    \n    Directory dir = newFSDirectory(new File(getWorkDir(),\"index\"));\n    IndexReader reader = DirectoryReader.open(dir);\n    IndexSearcher searcher = new IndexSearcher(reader);\n\n    QualityQueryParser qqParser = new SimpleQQParser(\"title\",\"body\");\n    QualityBenchmark qrun = new QualityBenchmark(qqs, qqParser, searcher, docNameField);\n    \n    SubmissionReport submitLog = VERBOSE ? new SubmissionReport(logger, \"TestRun\") : null;\n    qrun.setMaxResults(maxResults);\n    QualityStats stats[] = qrun.execute(judge, submitLog, logger);\n    \n    // --------- verify by the way judgments were altered for this test:\n    // for some queries, depending on m = qnum % 8\n    // m==0: avg_precision and recall are hurt, by marking fake docs as relevant\n    // m==1: precision_at_n and avg_precision are hurt, by unmarking relevant docs\n    // m==2: all precision, precision_at_n and recall are hurt.\n    // m>=3: these queries remain perfect\n    for (int i = 0; i < stats.length; i++) {\n      QualityStats s = stats[i];\n      switch (i%8) {\n\n      case 0:\n        assertTrue(\"avg-p should be hurt: \"+s.getAvp(), 1.0 > s.getAvp());\n        assertTrue(\"recall should be hurt: \"+s.getRecall(), 1.0 > s.getRecall());\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertEquals(\"p_at_\"+j+\" should be perfect: \"+s.getPrecisionAt(j), 1.0, s.getPrecisionAt(j), 1E-2);\n        }\n        break;\n      \n      case 1:\n        assertTrue(\"avg-p should be hurt\", 1.0 > s.getAvp());\n        assertEquals(\"recall should be perfect: \"+s.getRecall(), 1.0, s.getRecall(), 1E-2);\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertTrue(\"p_at_\"+j+\" should be hurt: \"+s.getPrecisionAt(j), 1.0 > s.getPrecisionAt(j));\n        }\n        break;\n\n      case 2:\n        assertTrue(\"avg-p should be hurt: \"+s.getAvp(), 1.0 > s.getAvp());\n        assertTrue(\"recall should be hurt: \"+s.getRecall(), 1.0 > s.getRecall());\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertTrue(\"p_at_\"+j+\" should be hurt: \"+s.getPrecisionAt(j), 1.0 > s.getPrecisionAt(j));\n        }\n        break;\n\n      default: {\n        assertEquals(\"avg-p should be perfect: \"+s.getAvp(), 1.0, s.getAvp(), 1E-2);\n        assertEquals(\"recall should be perfect: \"+s.getRecall(), 1.0, s.getRecall(), 1E-2);\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertEquals(\"p_at_\"+j+\" should be perfect: \"+s.getPrecisionAt(j), 1.0, s.getPrecisionAt(j), 1E-2);\n        }\n      }\n      \n      }\n    }\n    \n    QualityStats avg = QualityStats.average(stats);\n    if (logger!=null) {\n      avg.log(\"Average statistis:\",1,logger,\"  \");\n    }\n    \n    assertTrue(\"mean avg-p should be hurt: \"+avg.getAvp(), 1.0 > avg.getAvp());\n    assertTrue(\"avg recall should be hurt: \"+avg.getRecall(), 1.0 > avg.getRecall());\n    for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n      assertTrue(\"avg p_at_\"+j+\" should be hurt: \"+avg.getPrecisionAt(j), 1.0 > avg.getPrecisionAt(j));\n    }\n    \n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"81d0720146de53dd3a4a023d2a3d1089d86d748d","date":1442268215,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/benchmark/src/test/org/apache/lucene/benchmark/quality/TestQualityRun#testTrecQuality().mjava","pathOld":"lucene/benchmark/src/test/org/apache/lucene/benchmark/quality/TestQualityRun#testTrecQuality().mjava","sourceNew":"  public void testTrecQuality() throws Exception {\n    // first create the partial reuters index\n    createReutersIndex();\n    \n    int maxResults = 1000;\n    String docNameField = \"doctitle\"; // orig docID is in the linedoc format title \n    \n    PrintWriter logger = VERBOSE ? new PrintWriter(new OutputStreamWriter(System.out, Charset.defaultCharset()),true) : null;\n   \n    // prepare topics\n    InputStream topics = getClass().getResourceAsStream(\"trecTopics.txt\");\n    TrecTopicsReader qReader = new TrecTopicsReader();\n    QualityQuery qqs[] = qReader.readQueries(new BufferedReader(new InputStreamReader(topics, StandardCharsets.UTF_8)));\n    \n    // prepare judge\n    InputStream qrels = getClass().getResourceAsStream(\"trecQRels.txt\");\n    Judge judge = new TrecJudge(new BufferedReader(new InputStreamReader(qrels, StandardCharsets.UTF_8)));\n    \n    // validate topics & judgments match each other\n    judge.validateData(qqs, logger);\n    \n    Directory dir = newFSDirectory(getWorkDir().resolve(\"index\"));\n    IndexReader reader = DirectoryReader.open(dir);\n    IndexSearcher searcher = new IndexSearcher(reader);\n    // TODO: adapt this test data to bm25\n    searcher.setSimilarity(new ClassicSimilarity());\n\n    QualityQueryParser qqParser = new SimpleQQParser(\"title\",\"body\");\n    QualityBenchmark qrun = new QualityBenchmark(qqs, qqParser, searcher, docNameField);\n    \n    SubmissionReport submitLog = VERBOSE ? new SubmissionReport(logger, \"TestRun\") : null;\n    qrun.setMaxResults(maxResults);\n    QualityStats stats[] = qrun.execute(judge, submitLog, logger);\n    \n    // --------- verify by the way judgments were altered for this test:\n    // for some queries, depending on m = qnum % 8\n    // m==0: avg_precision and recall are hurt, by marking fake docs as relevant\n    // m==1: precision_at_n and avg_precision are hurt, by unmarking relevant docs\n    // m==2: all precision, precision_at_n and recall are hurt.\n    // m>=3: these queries remain perfect\n    for (int i = 0; i < stats.length; i++) {\n      QualityStats s = stats[i];\n      switch (i%8) {\n\n      case 0:\n        assertTrue(\"avg-p should be hurt: \"+s.getAvp(), 1.0 > s.getAvp());\n        assertTrue(\"recall should be hurt: \"+s.getRecall(), 1.0 > s.getRecall());\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertEquals(\"p_at_\"+j+\" should be perfect: \"+s.getPrecisionAt(j), 1.0, s.getPrecisionAt(j), 1E-2);\n        }\n        break;\n      \n      case 1:\n        assertTrue(\"avg-p should be hurt\", 1.0 > s.getAvp());\n        assertEquals(\"recall should be perfect: \"+s.getRecall(), 1.0, s.getRecall(), 1E-2);\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertTrue(\"p_at_\"+j+\" should be hurt: \"+s.getPrecisionAt(j), 1.0 > s.getPrecisionAt(j));\n        }\n        break;\n\n      case 2:\n        assertTrue(\"avg-p should be hurt: \"+s.getAvp(), 1.0 > s.getAvp());\n        assertTrue(\"recall should be hurt: \"+s.getRecall(), 1.0 > s.getRecall());\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertTrue(\"p_at_\"+j+\" should be hurt: \"+s.getPrecisionAt(j), 1.0 > s.getPrecisionAt(j));\n        }\n        break;\n\n      default: {\n        assertEquals(\"avg-p should be perfect: \"+s.getAvp(), 1.0, s.getAvp(), 1E-2);\n        assertEquals(\"recall should be perfect: \"+s.getRecall(), 1.0, s.getRecall(), 1E-2);\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertEquals(\"p_at_\"+j+\" should be perfect: \"+s.getPrecisionAt(j), 1.0, s.getPrecisionAt(j), 1E-2);\n        }\n      }\n      \n      }\n    }\n    \n    QualityStats avg = QualityStats.average(stats);\n    if (logger!=null) {\n      avg.log(\"Average statistis:\",1,logger,\"  \");\n    }\n    \n    assertTrue(\"mean avg-p should be hurt: \"+avg.getAvp(), 1.0 > avg.getAvp());\n    assertTrue(\"avg recall should be hurt: \"+avg.getRecall(), 1.0 > avg.getRecall());\n    for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n      assertTrue(\"avg p_at_\"+j+\" should be hurt: \"+avg.getPrecisionAt(j), 1.0 > avg.getPrecisionAt(j));\n    }\n    \n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testTrecQuality() throws Exception {\n    // first create the partial reuters index\n    createReutersIndex();\n    \n    int maxResults = 1000;\n    String docNameField = \"doctitle\"; // orig docID is in the linedoc format title \n    \n    PrintWriter logger = VERBOSE ? new PrintWriter(new OutputStreamWriter(System.out, Charset.defaultCharset()),true) : null;\n   \n    // prepare topics\n    InputStream topics = getClass().getResourceAsStream(\"trecTopics.txt\");\n    TrecTopicsReader qReader = new TrecTopicsReader();\n    QualityQuery qqs[] = qReader.readQueries(new BufferedReader(new InputStreamReader(topics, StandardCharsets.UTF_8)));\n    \n    // prepare judge\n    InputStream qrels = getClass().getResourceAsStream(\"trecQRels.txt\");\n    Judge judge = new TrecJudge(new BufferedReader(new InputStreamReader(qrels, StandardCharsets.UTF_8)));\n    \n    // validate topics & judgments match each other\n    judge.validateData(qqs, logger);\n    \n    Directory dir = newFSDirectory(getWorkDir().resolve(\"index\"));\n    IndexReader reader = DirectoryReader.open(dir);\n    IndexSearcher searcher = new IndexSearcher(reader);\n\n    QualityQueryParser qqParser = new SimpleQQParser(\"title\",\"body\");\n    QualityBenchmark qrun = new QualityBenchmark(qqs, qqParser, searcher, docNameField);\n    \n    SubmissionReport submitLog = VERBOSE ? new SubmissionReport(logger, \"TestRun\") : null;\n    qrun.setMaxResults(maxResults);\n    QualityStats stats[] = qrun.execute(judge, submitLog, logger);\n    \n    // --------- verify by the way judgments were altered for this test:\n    // for some queries, depending on m = qnum % 8\n    // m==0: avg_precision and recall are hurt, by marking fake docs as relevant\n    // m==1: precision_at_n and avg_precision are hurt, by unmarking relevant docs\n    // m==2: all precision, precision_at_n and recall are hurt.\n    // m>=3: these queries remain perfect\n    for (int i = 0; i < stats.length; i++) {\n      QualityStats s = stats[i];\n      switch (i%8) {\n\n      case 0:\n        assertTrue(\"avg-p should be hurt: \"+s.getAvp(), 1.0 > s.getAvp());\n        assertTrue(\"recall should be hurt: \"+s.getRecall(), 1.0 > s.getRecall());\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertEquals(\"p_at_\"+j+\" should be perfect: \"+s.getPrecisionAt(j), 1.0, s.getPrecisionAt(j), 1E-2);\n        }\n        break;\n      \n      case 1:\n        assertTrue(\"avg-p should be hurt\", 1.0 > s.getAvp());\n        assertEquals(\"recall should be perfect: \"+s.getRecall(), 1.0, s.getRecall(), 1E-2);\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertTrue(\"p_at_\"+j+\" should be hurt: \"+s.getPrecisionAt(j), 1.0 > s.getPrecisionAt(j));\n        }\n        break;\n\n      case 2:\n        assertTrue(\"avg-p should be hurt: \"+s.getAvp(), 1.0 > s.getAvp());\n        assertTrue(\"recall should be hurt: \"+s.getRecall(), 1.0 > s.getRecall());\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertTrue(\"p_at_\"+j+\" should be hurt: \"+s.getPrecisionAt(j), 1.0 > s.getPrecisionAt(j));\n        }\n        break;\n\n      default: {\n        assertEquals(\"avg-p should be perfect: \"+s.getAvp(), 1.0, s.getAvp(), 1E-2);\n        assertEquals(\"recall should be perfect: \"+s.getRecall(), 1.0, s.getRecall(), 1E-2);\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertEquals(\"p_at_\"+j+\" should be perfect: \"+s.getPrecisionAt(j), 1.0, s.getPrecisionAt(j), 1E-2);\n        }\n      }\n      \n      }\n    }\n    \n    QualityStats avg = QualityStats.average(stats);\n    if (logger!=null) {\n      avg.log(\"Average statistis:\",1,logger,\"  \");\n    }\n    \n    assertTrue(\"mean avg-p should be hurt: \"+avg.getAvp(), 1.0 > avg.getAvp());\n    assertTrue(\"avg recall should be hurt: \"+avg.getRecall(), 1.0 > avg.getRecall());\n    for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n      assertTrue(\"avg p_at_\"+j+\" should be hurt: \"+avg.getPrecisionAt(j), 1.0 > avg.getPrecisionAt(j));\n    }\n    \n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a424b3e10945beb87ffa486a0793b0b5c17a6397","date":1467616137,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/benchmark/src/test/org/apache/lucene/benchmark/quality/TestQualityRun#testTrecQuality().mjava","pathOld":"lucene/benchmark/src/test/org/apache/lucene/benchmark/quality/TestQualityRun#testTrecQuality().mjava","sourceNew":"  public void testTrecQuality() throws Exception {\n    // first create the partial reuters index\n    createReutersIndex();\n    \n    int maxResults = 1000;\n    String docNameField = \"doctitle\"; // orig docID is in the linedoc format title \n    \n    PrintWriter logger = VERBOSE ? new PrintWriter(new OutputStreamWriter(System.out, Charset.defaultCharset()),true) : null;\n   \n    // prepare topics\n    InputStream topics = getClass().getResourceAsStream(\"trecTopics.txt\");\n    TrecTopicsReader qReader = new TrecTopicsReader();\n    QualityQuery qqs[] = qReader.readQueries(new BufferedReader(new InputStreamReader(topics, StandardCharsets.UTF_8)));\n    \n    // prepare judge\n    InputStream qrels = getClass().getResourceAsStream(\"trecQRels.txt\");\n    Judge judge = new TrecJudge(new BufferedReader(new InputStreamReader(qrels, StandardCharsets.UTF_8)));\n    \n    // validate topics & judgments match each other\n    judge.validateData(qqs, logger);\n    \n    Directory dir = newFSDirectory(getWorkDir().resolve(\"index\"));\n    IndexReader reader = DirectoryReader.open(dir);\n    IndexSearcher searcher = new IndexSearcher(reader);\n\n    QualityQueryParser qqParser = new SimpleQQParser(\"title\",\"body\");\n    QualityBenchmark qrun = new QualityBenchmark(qqs, qqParser, searcher, docNameField);\n    \n    SubmissionReport submitLog = VERBOSE ? new SubmissionReport(logger, \"TestRun\") : null;\n    qrun.setMaxResults(maxResults);\n    QualityStats stats[] = qrun.execute(judge, submitLog, logger);\n    \n    // --------- verify by the way judgments were altered for this test:\n    // for some queries, depending on m = qnum % 8\n    // m==0: avg_precision and recall are hurt, by marking fake docs as relevant\n    // m==1: precision_at_n and avg_precision are hurt, by unmarking relevant docs\n    // m==2: all precision, precision_at_n and recall are hurt.\n    // m>=3: these queries remain perfect\n    for (int i = 0; i < stats.length; i++) {\n      QualityStats s = stats[i];\n      switch (i%8) {\n\n      case 0:\n        assertTrue(\"avg-p should be hurt: \"+s.getAvp(), 1.0 > s.getAvp());\n        assertTrue(\"recall should be hurt: \"+s.getRecall(), 1.0 > s.getRecall());\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertEquals(\"p_at_\"+j+\" should be perfect: \"+s.getPrecisionAt(j), 1.0, s.getPrecisionAt(j), 1E-2);\n        }\n        break;\n      \n      case 1:\n        assertTrue(\"avg-p should be hurt\", 1.0 > s.getAvp());\n        assertEquals(\"recall should be perfect: \"+s.getRecall(), 1.0, s.getRecall(), 1E-2);\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertTrue(\"p_at_\"+j+\" should be hurt: \"+s.getPrecisionAt(j), 1.0 > s.getPrecisionAt(j));\n        }\n        break;\n\n      case 2:\n        assertTrue(\"avg-p should be hurt: \"+s.getAvp(), 1.0 > s.getAvp());\n        assertTrue(\"recall should be hurt: \"+s.getRecall(), 1.0 > s.getRecall());\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertTrue(\"p_at_\"+j+\" should be hurt: \"+s.getPrecisionAt(j), 1.0 > s.getPrecisionAt(j));\n        }\n        break;\n\n      default: {\n        assertEquals(\"avg-p should be perfect: \"+s.getAvp(), 1.0, s.getAvp(), 1E-2);\n        assertEquals(\"recall should be perfect: \"+s.getRecall(), 1.0, s.getRecall(), 1E-2);\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertEquals(\"p_at_\"+j+\" should be perfect: \"+s.getPrecisionAt(j), 1.0, s.getPrecisionAt(j), 1E-2);\n        }\n      }\n      \n      }\n    }\n    \n    QualityStats avg = QualityStats.average(stats);\n    if (logger!=null) {\n      avg.log(\"Average statistis:\",1,logger,\"  \");\n    }\n    \n    assertTrue(\"mean avg-p should be hurt: \"+avg.getAvp(), 1.0 > avg.getAvp());\n    assertTrue(\"avg recall should be hurt: \"+avg.getRecall(), 1.0 > avg.getRecall());\n    for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n      assertTrue(\"avg p_at_\"+j+\" should be hurt: \"+avg.getPrecisionAt(j), 1.0 > avg.getPrecisionAt(j));\n    }\n    \n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testTrecQuality() throws Exception {\n    // first create the partial reuters index\n    createReutersIndex();\n    \n    int maxResults = 1000;\n    String docNameField = \"doctitle\"; // orig docID is in the linedoc format title \n    \n    PrintWriter logger = VERBOSE ? new PrintWriter(new OutputStreamWriter(System.out, Charset.defaultCharset()),true) : null;\n   \n    // prepare topics\n    InputStream topics = getClass().getResourceAsStream(\"trecTopics.txt\");\n    TrecTopicsReader qReader = new TrecTopicsReader();\n    QualityQuery qqs[] = qReader.readQueries(new BufferedReader(new InputStreamReader(topics, StandardCharsets.UTF_8)));\n    \n    // prepare judge\n    InputStream qrels = getClass().getResourceAsStream(\"trecQRels.txt\");\n    Judge judge = new TrecJudge(new BufferedReader(new InputStreamReader(qrels, StandardCharsets.UTF_8)));\n    \n    // validate topics & judgments match each other\n    judge.validateData(qqs, logger);\n    \n    Directory dir = newFSDirectory(getWorkDir().resolve(\"index\"));\n    IndexReader reader = DirectoryReader.open(dir);\n    IndexSearcher searcher = new IndexSearcher(reader);\n    // TODO: adapt this test data to bm25\n    searcher.setSimilarity(new ClassicSimilarity());\n\n    QualityQueryParser qqParser = new SimpleQQParser(\"title\",\"body\");\n    QualityBenchmark qrun = new QualityBenchmark(qqs, qqParser, searcher, docNameField);\n    \n    SubmissionReport submitLog = VERBOSE ? new SubmissionReport(logger, \"TestRun\") : null;\n    qrun.setMaxResults(maxResults);\n    QualityStats stats[] = qrun.execute(judge, submitLog, logger);\n    \n    // --------- verify by the way judgments were altered for this test:\n    // for some queries, depending on m = qnum % 8\n    // m==0: avg_precision and recall are hurt, by marking fake docs as relevant\n    // m==1: precision_at_n and avg_precision are hurt, by unmarking relevant docs\n    // m==2: all precision, precision_at_n and recall are hurt.\n    // m>=3: these queries remain perfect\n    for (int i = 0; i < stats.length; i++) {\n      QualityStats s = stats[i];\n      switch (i%8) {\n\n      case 0:\n        assertTrue(\"avg-p should be hurt: \"+s.getAvp(), 1.0 > s.getAvp());\n        assertTrue(\"recall should be hurt: \"+s.getRecall(), 1.0 > s.getRecall());\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertEquals(\"p_at_\"+j+\" should be perfect: \"+s.getPrecisionAt(j), 1.0, s.getPrecisionAt(j), 1E-2);\n        }\n        break;\n      \n      case 1:\n        assertTrue(\"avg-p should be hurt\", 1.0 > s.getAvp());\n        assertEquals(\"recall should be perfect: \"+s.getRecall(), 1.0, s.getRecall(), 1E-2);\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertTrue(\"p_at_\"+j+\" should be hurt: \"+s.getPrecisionAt(j), 1.0 > s.getPrecisionAt(j));\n        }\n        break;\n\n      case 2:\n        assertTrue(\"avg-p should be hurt: \"+s.getAvp(), 1.0 > s.getAvp());\n        assertTrue(\"recall should be hurt: \"+s.getRecall(), 1.0 > s.getRecall());\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertTrue(\"p_at_\"+j+\" should be hurt: \"+s.getPrecisionAt(j), 1.0 > s.getPrecisionAt(j));\n        }\n        break;\n\n      default: {\n        assertEquals(\"avg-p should be perfect: \"+s.getAvp(), 1.0, s.getAvp(), 1E-2);\n        assertEquals(\"recall should be perfect: \"+s.getRecall(), 1.0, s.getRecall(), 1E-2);\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertEquals(\"p_at_\"+j+\" should be perfect: \"+s.getPrecisionAt(j), 1.0, s.getPrecisionAt(j), 1E-2);\n        }\n      }\n      \n      }\n    }\n    \n    QualityStats avg = QualityStats.average(stats);\n    if (logger!=null) {\n      avg.log(\"Average statistis:\",1,logger,\"  \");\n    }\n    \n    assertTrue(\"mean avg-p should be hurt: \"+avg.getAvp(), 1.0 > avg.getAvp());\n    assertTrue(\"avg recall should be hurt: \"+avg.getRecall(), 1.0 > avg.getRecall());\n    for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n      assertTrue(\"avg p_at_\"+j+\" should be hurt: \"+avg.getPrecisionAt(j), 1.0 > avg.getPrecisionAt(j));\n    }\n    \n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4cce5816ef15a48a0bc11e5d400497ee4301dd3b","date":1476991456,"type":3,"author":"Kevin Risden","isMerge":true,"pathNew":"lucene/benchmark/src/test/org/apache/lucene/benchmark/quality/TestQualityRun#testTrecQuality().mjava","pathOld":"lucene/benchmark/src/test/org/apache/lucene/benchmark/quality/TestQualityRun#testTrecQuality().mjava","sourceNew":"  public void testTrecQuality() throws Exception {\n    // first create the partial reuters index\n    createReutersIndex();\n    \n    int maxResults = 1000;\n    String docNameField = \"doctitle\"; // orig docID is in the linedoc format title \n    \n    PrintWriter logger = VERBOSE ? new PrintWriter(new OutputStreamWriter(System.out, Charset.defaultCharset()),true) : null;\n   \n    // prepare topics\n    InputStream topics = getClass().getResourceAsStream(\"trecTopics.txt\");\n    TrecTopicsReader qReader = new TrecTopicsReader();\n    QualityQuery qqs[] = qReader.readQueries(new BufferedReader(new InputStreamReader(topics, StandardCharsets.UTF_8)));\n    \n    // prepare judge\n    InputStream qrels = getClass().getResourceAsStream(\"trecQRels.txt\");\n    Judge judge = new TrecJudge(new BufferedReader(new InputStreamReader(qrels, StandardCharsets.UTF_8)));\n    \n    // validate topics & judgments match each other\n    judge.validateData(qqs, logger);\n    \n    Directory dir = newFSDirectory(getWorkDir().resolve(\"index\"));\n    IndexReader reader = DirectoryReader.open(dir);\n    IndexSearcher searcher = new IndexSearcher(reader);\n\n    QualityQueryParser qqParser = new SimpleQQParser(\"title\",\"body\");\n    QualityBenchmark qrun = new QualityBenchmark(qqs, qqParser, searcher, docNameField);\n    \n    SubmissionReport submitLog = VERBOSE ? new SubmissionReport(logger, \"TestRun\") : null;\n    qrun.setMaxResults(maxResults);\n    QualityStats stats[] = qrun.execute(judge, submitLog, logger);\n    \n    // --------- verify by the way judgments were altered for this test:\n    // for some queries, depending on m = qnum % 8\n    // m==0: avg_precision and recall are hurt, by marking fake docs as relevant\n    // m==1: precision_at_n and avg_precision are hurt, by unmarking relevant docs\n    // m==2: all precision, precision_at_n and recall are hurt.\n    // m>=3: these queries remain perfect\n    for (int i = 0; i < stats.length; i++) {\n      QualityStats s = stats[i];\n      switch (i%8) {\n\n      case 0:\n        assertTrue(\"avg-p should be hurt: \"+s.getAvp(), 1.0 > s.getAvp());\n        assertTrue(\"recall should be hurt: \"+s.getRecall(), 1.0 > s.getRecall());\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertEquals(\"p_at_\"+j+\" should be perfect: \"+s.getPrecisionAt(j), 1.0, s.getPrecisionAt(j), 1E-2);\n        }\n        break;\n      \n      case 1:\n        assertTrue(\"avg-p should be hurt\", 1.0 > s.getAvp());\n        assertEquals(\"recall should be perfect: \"+s.getRecall(), 1.0, s.getRecall(), 1E-2);\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertTrue(\"p_at_\"+j+\" should be hurt: \"+s.getPrecisionAt(j), 1.0 > s.getPrecisionAt(j));\n        }\n        break;\n\n      case 2:\n        assertTrue(\"avg-p should be hurt: \"+s.getAvp(), 1.0 > s.getAvp());\n        assertTrue(\"recall should be hurt: \"+s.getRecall(), 1.0 > s.getRecall());\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertTrue(\"p_at_\"+j+\" should be hurt: \"+s.getPrecisionAt(j), 1.0 > s.getPrecisionAt(j));\n        }\n        break;\n\n      default: {\n        assertEquals(\"avg-p should be perfect: \"+s.getAvp(), 1.0, s.getAvp(), 1E-2);\n        assertEquals(\"recall should be perfect: \"+s.getRecall(), 1.0, s.getRecall(), 1E-2);\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertEquals(\"p_at_\"+j+\" should be perfect: \"+s.getPrecisionAt(j), 1.0, s.getPrecisionAt(j), 1E-2);\n        }\n      }\n      \n      }\n    }\n    \n    QualityStats avg = QualityStats.average(stats);\n    if (logger!=null) {\n      avg.log(\"Average statistis:\",1,logger,\"  \");\n    }\n    \n    assertTrue(\"mean avg-p should be hurt: \"+avg.getAvp(), 1.0 > avg.getAvp());\n    assertTrue(\"avg recall should be hurt: \"+avg.getRecall(), 1.0 > avg.getRecall());\n    for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n      assertTrue(\"avg p_at_\"+j+\" should be hurt: \"+avg.getPrecisionAt(j), 1.0 > avg.getPrecisionAt(j));\n    }\n    \n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testTrecQuality() throws Exception {\n    // first create the partial reuters index\n    createReutersIndex();\n    \n    int maxResults = 1000;\n    String docNameField = \"doctitle\"; // orig docID is in the linedoc format title \n    \n    PrintWriter logger = VERBOSE ? new PrintWriter(new OutputStreamWriter(System.out, Charset.defaultCharset()),true) : null;\n   \n    // prepare topics\n    InputStream topics = getClass().getResourceAsStream(\"trecTopics.txt\");\n    TrecTopicsReader qReader = new TrecTopicsReader();\n    QualityQuery qqs[] = qReader.readQueries(new BufferedReader(new InputStreamReader(topics, StandardCharsets.UTF_8)));\n    \n    // prepare judge\n    InputStream qrels = getClass().getResourceAsStream(\"trecQRels.txt\");\n    Judge judge = new TrecJudge(new BufferedReader(new InputStreamReader(qrels, StandardCharsets.UTF_8)));\n    \n    // validate topics & judgments match each other\n    judge.validateData(qqs, logger);\n    \n    Directory dir = newFSDirectory(getWorkDir().resolve(\"index\"));\n    IndexReader reader = DirectoryReader.open(dir);\n    IndexSearcher searcher = new IndexSearcher(reader);\n    // TODO: adapt this test data to bm25\n    searcher.setSimilarity(new ClassicSimilarity());\n\n    QualityQueryParser qqParser = new SimpleQQParser(\"title\",\"body\");\n    QualityBenchmark qrun = new QualityBenchmark(qqs, qqParser, searcher, docNameField);\n    \n    SubmissionReport submitLog = VERBOSE ? new SubmissionReport(logger, \"TestRun\") : null;\n    qrun.setMaxResults(maxResults);\n    QualityStats stats[] = qrun.execute(judge, submitLog, logger);\n    \n    // --------- verify by the way judgments were altered for this test:\n    // for some queries, depending on m = qnum % 8\n    // m==0: avg_precision and recall are hurt, by marking fake docs as relevant\n    // m==1: precision_at_n and avg_precision are hurt, by unmarking relevant docs\n    // m==2: all precision, precision_at_n and recall are hurt.\n    // m>=3: these queries remain perfect\n    for (int i = 0; i < stats.length; i++) {\n      QualityStats s = stats[i];\n      switch (i%8) {\n\n      case 0:\n        assertTrue(\"avg-p should be hurt: \"+s.getAvp(), 1.0 > s.getAvp());\n        assertTrue(\"recall should be hurt: \"+s.getRecall(), 1.0 > s.getRecall());\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertEquals(\"p_at_\"+j+\" should be perfect: \"+s.getPrecisionAt(j), 1.0, s.getPrecisionAt(j), 1E-2);\n        }\n        break;\n      \n      case 1:\n        assertTrue(\"avg-p should be hurt\", 1.0 > s.getAvp());\n        assertEquals(\"recall should be perfect: \"+s.getRecall(), 1.0, s.getRecall(), 1E-2);\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertTrue(\"p_at_\"+j+\" should be hurt: \"+s.getPrecisionAt(j), 1.0 > s.getPrecisionAt(j));\n        }\n        break;\n\n      case 2:\n        assertTrue(\"avg-p should be hurt: \"+s.getAvp(), 1.0 > s.getAvp());\n        assertTrue(\"recall should be hurt: \"+s.getRecall(), 1.0 > s.getRecall());\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertTrue(\"p_at_\"+j+\" should be hurt: \"+s.getPrecisionAt(j), 1.0 > s.getPrecisionAt(j));\n        }\n        break;\n\n      default: {\n        assertEquals(\"avg-p should be perfect: \"+s.getAvp(), 1.0, s.getAvp(), 1E-2);\n        assertEquals(\"recall should be perfect: \"+s.getRecall(), 1.0, s.getRecall(), 1E-2);\n        for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n          assertEquals(\"p_at_\"+j+\" should be perfect: \"+s.getPrecisionAt(j), 1.0, s.getPrecisionAt(j), 1E-2);\n        }\n      }\n      \n      }\n    }\n    \n    QualityStats avg = QualityStats.average(stats);\n    if (logger!=null) {\n      avg.log(\"Average statistis:\",1,logger,\"  \");\n    }\n    \n    assertTrue(\"mean avg-p should be hurt: \"+avg.getAvp(), 1.0 > avg.getAvp());\n    assertTrue(\"avg recall should be hurt: \"+avg.getRecall(), 1.0 > avg.getRecall());\n    for (int j = 1; j <= QualityStats.MAX_POINTS; j++) {\n      assertTrue(\"avg p_at_\"+j+\" should be hurt: \"+avg.getPrecisionAt(j), 1.0 > avg.getPrecisionAt(j));\n    }\n    \n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"5eb2511ababf862ea11e10761c70ee560cd84510":["2acf500f78aa12b92e371fd89c719291986b6b90","7d89d7e4e5101347833eea558851bf4209218619"],"2acf500f78aa12b92e371fd89c719291986b6b90":["e7e8d6f15900ee22ac3cb0a503f15dc952a3580f","714058a3bd900646d4df5e21af2d4e109ed3e4bc"],"f4abec28b874149a7223e32cc7a01704c27790de":["7d89d7e4e5101347833eea558851bf4209218619"],"7d89d7e4e5101347833eea558851bf4209218619":["2acf500f78aa12b92e371fd89c719291986b6b90"],"81d0720146de53dd3a4a023d2a3d1089d86d748d":["f4abec28b874149a7223e32cc7a01704c27790de"],"a424b3e10945beb87ffa486a0793b0b5c17a6397":["81d0720146de53dd3a4a023d2a3d1089d86d748d"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["81d0720146de53dd3a4a023d2a3d1089d86d748d","a424b3e10945beb87ffa486a0793b0b5c17a6397"],"46d8ada1fff8d18cb197c38c7983225162599948":["e7e8d6f15900ee22ac3cb0a503f15dc952a3580f","2acf500f78aa12b92e371fd89c719291986b6b90"],"714058a3bd900646d4df5e21af2d4e109ed3e4bc":["e7e8d6f15900ee22ac3cb0a503f15dc952a3580f"],"b89678825b68eccaf09e6ab71675fc0b0af1e099":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"e7e8d6f15900ee22ac3cb0a503f15dc952a3580f":["b89678825b68eccaf09e6ab71675fc0b0af1e099"],"fe33227f6805edab2036cbb80645cc4e2d1fa424":["e7e8d6f15900ee22ac3cb0a503f15dc952a3580f","2acf500f78aa12b92e371fd89c719291986b6b90"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["a424b3e10945beb87ffa486a0793b0b5c17a6397"]},"commit2Childs":{"5eb2511ababf862ea11e10761c70ee560cd84510":[],"2acf500f78aa12b92e371fd89c719291986b6b90":["5eb2511ababf862ea11e10761c70ee560cd84510","7d89d7e4e5101347833eea558851bf4209218619","46d8ada1fff8d18cb197c38c7983225162599948","fe33227f6805edab2036cbb80645cc4e2d1fa424"],"7d89d7e4e5101347833eea558851bf4209218619":["5eb2511ababf862ea11e10761c70ee560cd84510","f4abec28b874149a7223e32cc7a01704c27790de"],"f4abec28b874149a7223e32cc7a01704c27790de":["81d0720146de53dd3a4a023d2a3d1089d86d748d"],"81d0720146de53dd3a4a023d2a3d1089d86d748d":["a424b3e10945beb87ffa486a0793b0b5c17a6397","4cce5816ef15a48a0bc11e5d400497ee4301dd3b"],"a424b3e10945beb87ffa486a0793b0b5c17a6397":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":[],"46d8ada1fff8d18cb197c38c7983225162599948":[],"714058a3bd900646d4df5e21af2d4e109ed3e4bc":["2acf500f78aa12b92e371fd89c719291986b6b90"],"b89678825b68eccaf09e6ab71675fc0b0af1e099":["e7e8d6f15900ee22ac3cb0a503f15dc952a3580f"],"e7e8d6f15900ee22ac3cb0a503f15dc952a3580f":["2acf500f78aa12b92e371fd89c719291986b6b90","46d8ada1fff8d18cb197c38c7983225162599948","714058a3bd900646d4df5e21af2d4e109ed3e4bc","fe33227f6805edab2036cbb80645cc4e2d1fa424"],"fe33227f6805edab2036cbb80645cc4e2d1fa424":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["b89678825b68eccaf09e6ab71675fc0b0af1e099"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["5eb2511ababf862ea11e10761c70ee560cd84510","4cce5816ef15a48a0bc11e5d400497ee4301dd3b","46d8ada1fff8d18cb197c38c7983225162599948","fe33227f6805edab2036cbb80645cc4e2d1fa424","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}