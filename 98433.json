{"path":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/SimClusterStateProvider#getCollectionStates().mjava","commits":[{"id":"1d4bf9d5308dfef350829c28f2b3b2648df1e9b1","date":1513252583,"type":0,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/SimClusterStateProvider#getCollectionStates().mjava","pathOld":"/dev/null","sourceNew":"  private Map<String, DocCollection> getCollectionStates() {\n    Map<String, DocCollection> collectionStates = collectionsStatesRef.get();\n    if (collectionStates != null) {\n      return collectionStates;\n    }\n    lock.lock();\n    collectionsStatesRef.set(null);\n    clusterStateVersion++;\n    saveClusterState.set(true);\n    try {\n      Map<String, Map<String, Map<String, Replica>>> collMap = new HashMap<>();\n      nodeReplicaMap.forEach((n, replicas) -> {\n        replicas.forEach(ri -> {\n          Map<String, Object> props;\n          synchronized (ri) {\n            props = new HashMap<>(ri.getVariables());\n          }\n          props.put(ZkStateReader.NODE_NAME_PROP, n);\n          props.put(ZkStateReader.CORE_NAME_PROP, ri.getCore());\n          props.put(ZkStateReader.REPLICA_TYPE, ri.getType().toString());\n          props.put(ZkStateReader.STATE_PROP, ri.getState().toString());\n          Replica r = new Replica(ri.getName(), props);\n          collMap.computeIfAbsent(ri.getCollection(), c -> new HashMap<>())\n              .computeIfAbsent(ri.getShard(), s -> new HashMap<>())\n              .put(ri.getName(), r);\n        });\n      });\n\n      // add empty slices\n      sliceProperties.forEach((c, perSliceProps) -> {\n        perSliceProps.forEach((slice, props) -> {\n          collMap.computeIfAbsent(c, co -> new ConcurrentHashMap<>()).computeIfAbsent(slice, s -> new ConcurrentHashMap<>());\n        });\n      });\n      // add empty collections\n      collProperties.keySet().forEach(c -> {\n        collMap.computeIfAbsent(c, co -> new ConcurrentHashMap<>());\n      });\n\n      Map<String, DocCollection> res = new HashMap<>();\n      collMap.forEach((coll, shards) -> {\n        Map<String, Slice> slices = new HashMap<>();\n        shards.forEach((s, replicas) -> {\n          Map<String, Object> sliceProps = sliceProperties.computeIfAbsent(coll, c -> new ConcurrentHashMap<>()).computeIfAbsent(s, sl -> new ConcurrentHashMap<>());\n          Slice slice = new Slice(s, replicas, sliceProps);\n          slices.put(s, slice);\n        });\n        Map<String, Object> collProps = collProperties.computeIfAbsent(coll, c -> new ConcurrentHashMap<>());\n        DocCollection dc = new DocCollection(coll, slices, collProps, DocRouter.DEFAULT, clusterStateVersion, ZkStateReader.CLUSTER_STATE);\n        res.put(coll, dc);\n      });\n      collectionsStatesRef.set(res);\n      return res;\n    } finally {\n      lock.unlock();\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a4422b331d00607258b0ed3e43934306e67764aa","date":1513943901,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/SimClusterStateProvider#getCollectionStates().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/SimClusterStateProvider#getCollectionStates().mjava","sourceNew":"  private Map<String, DocCollection> getCollectionStates() {\n    Map<String, DocCollection> collectionStates = collectionsStatesRef.get();\n    if (collectionStates != null) {\n      return collectionStates;\n    }\n    lock.lock();\n    collectionsStatesRef.set(null);\n    saveClusterState.set(true);\n    try {\n      Map<String, Map<String, Map<String, Replica>>> collMap = new HashMap<>();\n      nodeReplicaMap.forEach((n, replicas) -> {\n        replicas.forEach(ri -> {\n          Map<String, Object> props;\n          synchronized (ri) {\n            props = new HashMap<>(ri.getVariables());\n          }\n          props.put(ZkStateReader.NODE_NAME_PROP, n);\n          props.put(ZkStateReader.CORE_NAME_PROP, ri.getCore());\n          props.put(ZkStateReader.REPLICA_TYPE, ri.getType().toString());\n          props.put(ZkStateReader.STATE_PROP, ri.getState().toString());\n          Replica r = new Replica(ri.getName(), props);\n          collMap.computeIfAbsent(ri.getCollection(), c -> new HashMap<>())\n              .computeIfAbsent(ri.getShard(), s -> new HashMap<>())\n              .put(ri.getName(), r);\n        });\n      });\n\n      // add empty slices\n      sliceProperties.forEach((c, perSliceProps) -> {\n        perSliceProps.forEach((slice, props) -> {\n          collMap.computeIfAbsent(c, co -> new ConcurrentHashMap<>()).computeIfAbsent(slice, s -> new ConcurrentHashMap<>());\n        });\n      });\n      // add empty collections\n      collProperties.keySet().forEach(c -> {\n        collMap.computeIfAbsent(c, co -> new ConcurrentHashMap<>());\n      });\n\n      Map<String, DocCollection> res = new HashMap<>();\n      collMap.forEach((coll, shards) -> {\n        Map<String, Slice> slices = new HashMap<>();\n        shards.forEach((s, replicas) -> {\n          Map<String, Object> sliceProps = sliceProperties.computeIfAbsent(coll, c -> new ConcurrentHashMap<>()).computeIfAbsent(s, sl -> new ConcurrentHashMap<>());\n          Slice slice = new Slice(s, replicas, sliceProps);\n          slices.put(s, slice);\n        });\n        Map<String, Object> collProps = collProperties.computeIfAbsent(coll, c -> new ConcurrentHashMap<>());\n        DocCollection dc = new DocCollection(coll, slices, collProps, DocRouter.DEFAULT, clusterStateVersion, ZkStateReader.CLUSTER_STATE);\n        res.put(coll, dc);\n      });\n      collectionsStatesRef.set(res);\n      return res;\n    } finally {\n      lock.unlock();\n    }\n  }\n\n","sourceOld":"  private Map<String, DocCollection> getCollectionStates() {\n    Map<String, DocCollection> collectionStates = collectionsStatesRef.get();\n    if (collectionStates != null) {\n      return collectionStates;\n    }\n    lock.lock();\n    collectionsStatesRef.set(null);\n    clusterStateVersion++;\n    saveClusterState.set(true);\n    try {\n      Map<String, Map<String, Map<String, Replica>>> collMap = new HashMap<>();\n      nodeReplicaMap.forEach((n, replicas) -> {\n        replicas.forEach(ri -> {\n          Map<String, Object> props;\n          synchronized (ri) {\n            props = new HashMap<>(ri.getVariables());\n          }\n          props.put(ZkStateReader.NODE_NAME_PROP, n);\n          props.put(ZkStateReader.CORE_NAME_PROP, ri.getCore());\n          props.put(ZkStateReader.REPLICA_TYPE, ri.getType().toString());\n          props.put(ZkStateReader.STATE_PROP, ri.getState().toString());\n          Replica r = new Replica(ri.getName(), props);\n          collMap.computeIfAbsent(ri.getCollection(), c -> new HashMap<>())\n              .computeIfAbsent(ri.getShard(), s -> new HashMap<>())\n              .put(ri.getName(), r);\n        });\n      });\n\n      // add empty slices\n      sliceProperties.forEach((c, perSliceProps) -> {\n        perSliceProps.forEach((slice, props) -> {\n          collMap.computeIfAbsent(c, co -> new ConcurrentHashMap<>()).computeIfAbsent(slice, s -> new ConcurrentHashMap<>());\n        });\n      });\n      // add empty collections\n      collProperties.keySet().forEach(c -> {\n        collMap.computeIfAbsent(c, co -> new ConcurrentHashMap<>());\n      });\n\n      Map<String, DocCollection> res = new HashMap<>();\n      collMap.forEach((coll, shards) -> {\n        Map<String, Slice> slices = new HashMap<>();\n        shards.forEach((s, replicas) -> {\n          Map<String, Object> sliceProps = sliceProperties.computeIfAbsent(coll, c -> new ConcurrentHashMap<>()).computeIfAbsent(s, sl -> new ConcurrentHashMap<>());\n          Slice slice = new Slice(s, replicas, sliceProps);\n          slices.put(s, slice);\n        });\n        Map<String, Object> collProps = collProperties.computeIfAbsent(coll, c -> new ConcurrentHashMap<>());\n        DocCollection dc = new DocCollection(coll, slices, collProps, DocRouter.DEFAULT, clusterStateVersion, ZkStateReader.CLUSTER_STATE);\n        res.put(coll, dc);\n      });\n      collectionsStatesRef.set(res);\n      return res;\n    } finally {\n      lock.unlock();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ce71a9836bf1eba34a0ab31884e9eb8ad3f1cef1","date":1523453934,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/SimClusterStateProvider#getCollectionStates().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/SimClusterStateProvider#getCollectionStates().mjava","sourceNew":"  // this method uses a simple cache in collectionsStatesRef. Operations that modify\n  // cluster state should always reset this cache so that the changes become visible\n  private Map<String, DocCollection> getCollectionStates() {\n    Map<String, DocCollection> collectionStates = collectionsStatesRef.get();\n    if (collectionStates != null) {\n      return collectionStates;\n    }\n    lock.lock();\n    collectionsStatesRef.set(null);\n    saveClusterState.set(true);\n    try {\n      Map<String, Map<String, Map<String, Replica>>> collMap = new HashMap<>();\n      nodeReplicaMap.forEach((n, replicas) -> {\n        replicas.forEach(ri -> {\n          Map<String, Object> props;\n          synchronized (ri) {\n            props = new HashMap<>(ri.getVariables());\n          }\n          props.put(ZkStateReader.NODE_NAME_PROP, n);\n          props.put(ZkStateReader.CORE_NAME_PROP, ri.getCore());\n          props.put(ZkStateReader.REPLICA_TYPE, ri.getType().toString());\n          props.put(ZkStateReader.STATE_PROP, ri.getState().toString());\n          Replica r = new Replica(ri.getName(), props);\n          collMap.computeIfAbsent(ri.getCollection(), c -> new HashMap<>())\n              .computeIfAbsent(ri.getShard(), s -> new HashMap<>())\n              .put(ri.getName(), r);\n        });\n      });\n\n      // add empty slices\n      sliceProperties.forEach((c, perSliceProps) -> {\n        perSliceProps.forEach((slice, props) -> {\n          collMap.computeIfAbsent(c, co -> new ConcurrentHashMap<>()).computeIfAbsent(slice, s -> new ConcurrentHashMap<>());\n        });\n      });\n      // add empty collections\n      collProperties.keySet().forEach(c -> {\n        collMap.computeIfAbsent(c, co -> new ConcurrentHashMap<>());\n      });\n\n      Map<String, DocCollection> res = new HashMap<>();\n      collMap.forEach((coll, shards) -> {\n        Map<String, Slice> slices = new HashMap<>();\n        shards.forEach((s, replicas) -> {\n          Map<String, Object> sliceProps = sliceProperties.computeIfAbsent(coll, c -> new ConcurrentHashMap<>()).computeIfAbsent(s, sl -> new ConcurrentHashMap<>());\n          Slice slice = new Slice(s, replicas, sliceProps);\n          slices.put(s, slice);\n        });\n        Map<String, Object> collProps = collProperties.computeIfAbsent(coll, c -> new ConcurrentHashMap<>());\n        Map<String, Object> routerProp = (Map<String, Object>) collProps.getOrDefault(DocCollection.DOC_ROUTER, Collections.singletonMap(\"name\", DocRouter.DEFAULT_NAME));\n        DocRouter router = DocRouter.getDocRouter((String)routerProp.getOrDefault(\"name\", DocRouter.DEFAULT_NAME));\n        DocCollection dc = new DocCollection(coll, slices, collProps, router, clusterStateVersion, ZkStateReader.CLUSTER_STATE);\n        res.put(coll, dc);\n      });\n      collectionsStatesRef.set(res);\n      return res;\n    } finally {\n      lock.unlock();\n    }\n  }\n\n","sourceOld":"  private Map<String, DocCollection> getCollectionStates() {\n    Map<String, DocCollection> collectionStates = collectionsStatesRef.get();\n    if (collectionStates != null) {\n      return collectionStates;\n    }\n    lock.lock();\n    collectionsStatesRef.set(null);\n    saveClusterState.set(true);\n    try {\n      Map<String, Map<String, Map<String, Replica>>> collMap = new HashMap<>();\n      nodeReplicaMap.forEach((n, replicas) -> {\n        replicas.forEach(ri -> {\n          Map<String, Object> props;\n          synchronized (ri) {\n            props = new HashMap<>(ri.getVariables());\n          }\n          props.put(ZkStateReader.NODE_NAME_PROP, n);\n          props.put(ZkStateReader.CORE_NAME_PROP, ri.getCore());\n          props.put(ZkStateReader.REPLICA_TYPE, ri.getType().toString());\n          props.put(ZkStateReader.STATE_PROP, ri.getState().toString());\n          Replica r = new Replica(ri.getName(), props);\n          collMap.computeIfAbsent(ri.getCollection(), c -> new HashMap<>())\n              .computeIfAbsent(ri.getShard(), s -> new HashMap<>())\n              .put(ri.getName(), r);\n        });\n      });\n\n      // add empty slices\n      sliceProperties.forEach((c, perSliceProps) -> {\n        perSliceProps.forEach((slice, props) -> {\n          collMap.computeIfAbsent(c, co -> new ConcurrentHashMap<>()).computeIfAbsent(slice, s -> new ConcurrentHashMap<>());\n        });\n      });\n      // add empty collections\n      collProperties.keySet().forEach(c -> {\n        collMap.computeIfAbsent(c, co -> new ConcurrentHashMap<>());\n      });\n\n      Map<String, DocCollection> res = new HashMap<>();\n      collMap.forEach((coll, shards) -> {\n        Map<String, Slice> slices = new HashMap<>();\n        shards.forEach((s, replicas) -> {\n          Map<String, Object> sliceProps = sliceProperties.computeIfAbsent(coll, c -> new ConcurrentHashMap<>()).computeIfAbsent(s, sl -> new ConcurrentHashMap<>());\n          Slice slice = new Slice(s, replicas, sliceProps);\n          slices.put(s, slice);\n        });\n        Map<String, Object> collProps = collProperties.computeIfAbsent(coll, c -> new ConcurrentHashMap<>());\n        DocCollection dc = new DocCollection(coll, slices, collProps, DocRouter.DEFAULT, clusterStateVersion, ZkStateReader.CLUSTER_STATE);\n        res.put(coll, dc);\n      });\n      collectionsStatesRef.set(res);\n      return res;\n    } finally {\n      lock.unlock();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"43345f1452f9510f8aaadae6156fe0c834e7d957","date":1523483670,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/SimClusterStateProvider#getCollectionStates().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/SimClusterStateProvider#getCollectionStates().mjava","sourceNew":"  // this method uses a simple cache in collectionsStatesRef. Operations that modify\n  // cluster state should always reset this cache so that the changes become visible\n  private Map<String, DocCollection> getCollectionStates() {\n    Map<String, DocCollection> collectionStates = collectionsStatesRef.get();\n    if (collectionStates != null) {\n      return collectionStates;\n    }\n    lock.lock();\n    collectionsStatesRef.set(null);\n    saveClusterState.set(true);\n    try {\n      Map<String, Map<String, Map<String, Replica>>> collMap = new HashMap<>();\n      nodeReplicaMap.forEach((n, replicas) -> {\n        replicas.forEach(ri -> {\n          Map<String, Object> props;\n          synchronized (ri) {\n            props = new HashMap<>(ri.getVariables());\n          }\n          props.put(ZkStateReader.NODE_NAME_PROP, n);\n          props.put(ZkStateReader.CORE_NAME_PROP, ri.getCore());\n          props.put(ZkStateReader.REPLICA_TYPE, ri.getType().toString());\n          props.put(ZkStateReader.STATE_PROP, ri.getState().toString());\n          Replica r = new Replica(ri.getName(), props);\n          collMap.computeIfAbsent(ri.getCollection(), c -> new HashMap<>())\n              .computeIfAbsent(ri.getShard(), s -> new HashMap<>())\n              .put(ri.getName(), r);\n        });\n      });\n\n      // add empty slices\n      sliceProperties.forEach((c, perSliceProps) -> {\n        perSliceProps.forEach((slice, props) -> {\n          collMap.computeIfAbsent(c, co -> new ConcurrentHashMap<>()).computeIfAbsent(slice, s -> new ConcurrentHashMap<>());\n        });\n      });\n      // add empty collections\n      collProperties.keySet().forEach(c -> {\n        collMap.computeIfAbsent(c, co -> new ConcurrentHashMap<>());\n      });\n\n      Map<String, DocCollection> res = new HashMap<>();\n      collMap.forEach((coll, shards) -> {\n        Map<String, Slice> slices = new HashMap<>();\n        shards.forEach((s, replicas) -> {\n          Map<String, Object> sliceProps = sliceProperties.computeIfAbsent(coll, c -> new ConcurrentHashMap<>()).computeIfAbsent(s, sl -> new ConcurrentHashMap<>());\n          Slice slice = new Slice(s, replicas, sliceProps);\n          slices.put(s, slice);\n        });\n        Map<String, Object> collProps = collProperties.computeIfAbsent(coll, c -> new ConcurrentHashMap<>());\n        Map<String, Object> routerProp = (Map<String, Object>) collProps.getOrDefault(DocCollection.DOC_ROUTER, Collections.singletonMap(\"name\", DocRouter.DEFAULT_NAME));\n        DocRouter router = DocRouter.getDocRouter((String)routerProp.getOrDefault(\"name\", DocRouter.DEFAULT_NAME));\n        DocCollection dc = new DocCollection(coll, slices, collProps, router, clusterStateVersion, ZkStateReader.CLUSTER_STATE);\n        res.put(coll, dc);\n      });\n      collectionsStatesRef.set(res);\n      return res;\n    } finally {\n      lock.unlock();\n    }\n  }\n\n","sourceOld":"  private Map<String, DocCollection> getCollectionStates() {\n    Map<String, DocCollection> collectionStates = collectionsStatesRef.get();\n    if (collectionStates != null) {\n      return collectionStates;\n    }\n    lock.lock();\n    collectionsStatesRef.set(null);\n    saveClusterState.set(true);\n    try {\n      Map<String, Map<String, Map<String, Replica>>> collMap = new HashMap<>();\n      nodeReplicaMap.forEach((n, replicas) -> {\n        replicas.forEach(ri -> {\n          Map<String, Object> props;\n          synchronized (ri) {\n            props = new HashMap<>(ri.getVariables());\n          }\n          props.put(ZkStateReader.NODE_NAME_PROP, n);\n          props.put(ZkStateReader.CORE_NAME_PROP, ri.getCore());\n          props.put(ZkStateReader.REPLICA_TYPE, ri.getType().toString());\n          props.put(ZkStateReader.STATE_PROP, ri.getState().toString());\n          Replica r = new Replica(ri.getName(), props);\n          collMap.computeIfAbsent(ri.getCollection(), c -> new HashMap<>())\n              .computeIfAbsent(ri.getShard(), s -> new HashMap<>())\n              .put(ri.getName(), r);\n        });\n      });\n\n      // add empty slices\n      sliceProperties.forEach((c, perSliceProps) -> {\n        perSliceProps.forEach((slice, props) -> {\n          collMap.computeIfAbsent(c, co -> new ConcurrentHashMap<>()).computeIfAbsent(slice, s -> new ConcurrentHashMap<>());\n        });\n      });\n      // add empty collections\n      collProperties.keySet().forEach(c -> {\n        collMap.computeIfAbsent(c, co -> new ConcurrentHashMap<>());\n      });\n\n      Map<String, DocCollection> res = new HashMap<>();\n      collMap.forEach((coll, shards) -> {\n        Map<String, Slice> slices = new HashMap<>();\n        shards.forEach((s, replicas) -> {\n          Map<String, Object> sliceProps = sliceProperties.computeIfAbsent(coll, c -> new ConcurrentHashMap<>()).computeIfAbsent(s, sl -> new ConcurrentHashMap<>());\n          Slice slice = new Slice(s, replicas, sliceProps);\n          slices.put(s, slice);\n        });\n        Map<String, Object> collProps = collProperties.computeIfAbsent(coll, c -> new ConcurrentHashMap<>());\n        DocCollection dc = new DocCollection(coll, slices, collProps, DocRouter.DEFAULT, clusterStateVersion, ZkStateReader.CLUSTER_STATE);\n        res.put(coll, dc);\n      });\n      collectionsStatesRef.set(res);\n      return res;\n    } finally {\n      lock.unlock();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fc18bc8ea2e2c1e308757ff50671c774438e9f3e","date":1538052583,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/SimClusterStateProvider#getCollectionStates().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/SimClusterStateProvider#getCollectionStates().mjava","sourceNew":"  // this method uses a simple cache in collectionsStatesRef. Operations that modify\n  // cluster state should always reset this cache so that the changes become visible\n  private Map<String, DocCollection> getCollectionStates() {\n    Map<String, DocCollection> collectionStates = collectionsStatesRef.get();\n    if (collectionStates != null) {\n      return collectionStates;\n    }\n    lock.lock();\n    collectionsStatesRef.set(null);\n    saveClusterState.set(true);\n    log.debug(\"** creating new collection states\");\n    try {\n      Map<String, Map<String, Map<String, Replica>>> collMap = new HashMap<>();\n      nodeReplicaMap.forEach((n, replicas) -> {\n        replicas.forEach(ri -> {\n          Map<String, Object> props;\n          synchronized (ri) {\n            props = new HashMap<>(ri.getVariables());\n          }\n          props.put(ZkStateReader.NODE_NAME_PROP, n);\n          props.put(ZkStateReader.CORE_NAME_PROP, ri.getCore());\n          props.put(ZkStateReader.REPLICA_TYPE, ri.getType().toString());\n          props.put(ZkStateReader.STATE_PROP, ri.getState().toString());\n          Replica r = new Replica(ri.getName(), props);\n          collMap.computeIfAbsent(ri.getCollection(), c -> new HashMap<>())\n              .computeIfAbsent(ri.getShard(), s -> new HashMap<>())\n              .put(ri.getName(), r);\n        });\n      });\n\n      // add empty slices\n      sliceProperties.forEach((c, perSliceProps) -> {\n        perSliceProps.forEach((slice, props) -> {\n          collMap.computeIfAbsent(c, co -> new ConcurrentHashMap<>()).computeIfAbsent(slice, s -> new ConcurrentHashMap<>());\n        });\n      });\n      // add empty collections\n      collProperties.keySet().forEach(c -> {\n        collMap.computeIfAbsent(c, co -> new ConcurrentHashMap<>());\n      });\n\n      Map<String, DocCollection> res = new HashMap<>();\n      collMap.forEach((coll, shards) -> {\n        Map<String, Slice> slices = new HashMap<>();\n        shards.forEach((s, replicas) -> {\n          Map<String, Object> sliceProps = sliceProperties.computeIfAbsent(coll, c -> new ConcurrentHashMap<>()).computeIfAbsent(s, sl -> new ConcurrentHashMap<>());\n          Slice slice = new Slice(s, replicas, sliceProps);\n          slices.put(s, slice);\n        });\n        Map<String, Object> collProps = collProperties.computeIfAbsent(coll, c -> new ConcurrentHashMap<>());\n        Map<String, Object> routerProp = (Map<String, Object>) collProps.getOrDefault(DocCollection.DOC_ROUTER, Collections.singletonMap(\"name\", DocRouter.DEFAULT_NAME));\n        DocRouter router = DocRouter.getDocRouter((String)routerProp.getOrDefault(\"name\", DocRouter.DEFAULT_NAME));\n        DocCollection dc = new DocCollection(coll, slices, collProps, router, clusterStateVersion + 1, ZkStateReader.CLUSTER_STATE);\n        res.put(coll, dc);\n      });\n      collectionsStatesRef.set(res);\n      return res;\n    } finally {\n      lock.unlock();\n    }\n  }\n\n","sourceOld":"  // this method uses a simple cache in collectionsStatesRef. Operations that modify\n  // cluster state should always reset this cache so that the changes become visible\n  private Map<String, DocCollection> getCollectionStates() {\n    Map<String, DocCollection> collectionStates = collectionsStatesRef.get();\n    if (collectionStates != null) {\n      return collectionStates;\n    }\n    lock.lock();\n    collectionsStatesRef.set(null);\n    saveClusterState.set(true);\n    try {\n      Map<String, Map<String, Map<String, Replica>>> collMap = new HashMap<>();\n      nodeReplicaMap.forEach((n, replicas) -> {\n        replicas.forEach(ri -> {\n          Map<String, Object> props;\n          synchronized (ri) {\n            props = new HashMap<>(ri.getVariables());\n          }\n          props.put(ZkStateReader.NODE_NAME_PROP, n);\n          props.put(ZkStateReader.CORE_NAME_PROP, ri.getCore());\n          props.put(ZkStateReader.REPLICA_TYPE, ri.getType().toString());\n          props.put(ZkStateReader.STATE_PROP, ri.getState().toString());\n          Replica r = new Replica(ri.getName(), props);\n          collMap.computeIfAbsent(ri.getCollection(), c -> new HashMap<>())\n              .computeIfAbsent(ri.getShard(), s -> new HashMap<>())\n              .put(ri.getName(), r);\n        });\n      });\n\n      // add empty slices\n      sliceProperties.forEach((c, perSliceProps) -> {\n        perSliceProps.forEach((slice, props) -> {\n          collMap.computeIfAbsent(c, co -> new ConcurrentHashMap<>()).computeIfAbsent(slice, s -> new ConcurrentHashMap<>());\n        });\n      });\n      // add empty collections\n      collProperties.keySet().forEach(c -> {\n        collMap.computeIfAbsent(c, co -> new ConcurrentHashMap<>());\n      });\n\n      Map<String, DocCollection> res = new HashMap<>();\n      collMap.forEach((coll, shards) -> {\n        Map<String, Slice> slices = new HashMap<>();\n        shards.forEach((s, replicas) -> {\n          Map<String, Object> sliceProps = sliceProperties.computeIfAbsent(coll, c -> new ConcurrentHashMap<>()).computeIfAbsent(s, sl -> new ConcurrentHashMap<>());\n          Slice slice = new Slice(s, replicas, sliceProps);\n          slices.put(s, slice);\n        });\n        Map<String, Object> collProps = collProperties.computeIfAbsent(coll, c -> new ConcurrentHashMap<>());\n        Map<String, Object> routerProp = (Map<String, Object>) collProps.getOrDefault(DocCollection.DOC_ROUTER, Collections.singletonMap(\"name\", DocRouter.DEFAULT_NAME));\n        DocRouter router = DocRouter.getDocRouter((String)routerProp.getOrDefault(\"name\", DocRouter.DEFAULT_NAME));\n        DocCollection dc = new DocCollection(coll, slices, collProps, router, clusterStateVersion, ZkStateReader.CLUSTER_STATE);\n        res.put(coll, dc);\n      });\n      collectionsStatesRef.set(res);\n      return res;\n    } finally {\n      lock.unlock();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8254aa20264eb7a88d556bbe0346667937ed9c2a","date":1538494545,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/SimClusterStateProvider#getCollectionStates().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/SimClusterStateProvider#getCollectionStates().mjava","sourceNew":"  // this method uses a simple cache in collectionsStatesRef. Operations that modify\n  // cluster state should always reset this cache so that the changes become visible\n  private Map<String, DocCollection> getCollectionStates() throws IOException {\n    Map<String, DocCollection> collectionStates = collectionsStatesRef.get();\n    if (collectionStates != null) {\n      return collectionStates;\n    }\n    lock.lock();\n    collectionsStatesRef.set(null);\n    log.debug(\"** creating new collection states, currentVersion={}\", clusterStateVersion);\n    try {\n      Map<String, Map<String, Map<String, Replica>>> collMap = new HashMap<>();\n      nodeReplicaMap.forEach((n, replicas) -> {\n        replicas.forEach(ri -> {\n          Map<String, Object> props;\n          synchronized (ri) {\n            props = new HashMap<>(ri.getVariables());\n          }\n          props.put(ZkStateReader.NODE_NAME_PROP, n);\n          props.put(ZkStateReader.CORE_NAME_PROP, ri.getCore());\n          props.put(ZkStateReader.REPLICA_TYPE, ri.getType().toString());\n          props.put(ZkStateReader.STATE_PROP, ri.getState().toString());\n          Replica r = new Replica(ri.getName(), props);\n          collMap.computeIfAbsent(ri.getCollection(), c -> new HashMap<>())\n              .computeIfAbsent(ri.getShard(), s -> new HashMap<>())\n              .put(ri.getName(), r);\n        });\n      });\n\n      // add empty slices\n      sliceProperties.forEach((c, perSliceProps) -> {\n        perSliceProps.forEach((slice, props) -> {\n          collMap.computeIfAbsent(c, co -> new ConcurrentHashMap<>()).computeIfAbsent(slice, s -> new ConcurrentHashMap<>());\n        });\n      });\n      // add empty collections\n      collProperties.keySet().forEach(c -> {\n        collMap.computeIfAbsent(c, co -> new ConcurrentHashMap<>());\n      });\n\n      Map<String, DocCollection> res = new HashMap<>();\n      collMap.forEach((coll, shards) -> {\n        Map<String, Slice> slices = new HashMap<>();\n        shards.forEach((s, replicas) -> {\n          Map<String, Object> sliceProps = sliceProperties.computeIfAbsent(coll, c -> new ConcurrentHashMap<>()).computeIfAbsent(s, sl -> new ConcurrentHashMap<>());\n          Slice slice = new Slice(s, replicas, sliceProps);\n          slices.put(s, slice);\n        });\n        Map<String, Object> collProps = collProperties.computeIfAbsent(coll, c -> new ConcurrentHashMap<>());\n        Map<String, Object> routerProp = (Map<String, Object>) collProps.getOrDefault(DocCollection.DOC_ROUTER, Collections.singletonMap(\"name\", DocRouter.DEFAULT_NAME));\n        DocRouter router = DocRouter.getDocRouter((String)routerProp.getOrDefault(\"name\", DocRouter.DEFAULT_NAME));\n        DocCollection dc = new DocCollection(coll, slices, collProps, router, clusterStateVersion, ZkStateReader.CLUSTER_STATE);\n        res.put(coll, dc);\n      });\n      saveClusterState(new ClusterState(clusterStateVersion, liveNodes.get(), res));\n      collectionsStatesRef.set(res);\n      return res;\n    } finally {\n      lock.unlock();\n    }\n  }\n\n","sourceOld":"  // this method uses a simple cache in collectionsStatesRef. Operations that modify\n  // cluster state should always reset this cache so that the changes become visible\n  private Map<String, DocCollection> getCollectionStates() {\n    Map<String, DocCollection> collectionStates = collectionsStatesRef.get();\n    if (collectionStates != null) {\n      return collectionStates;\n    }\n    lock.lock();\n    collectionsStatesRef.set(null);\n    saveClusterState.set(true);\n    log.debug(\"** creating new collection states\");\n    try {\n      Map<String, Map<String, Map<String, Replica>>> collMap = new HashMap<>();\n      nodeReplicaMap.forEach((n, replicas) -> {\n        replicas.forEach(ri -> {\n          Map<String, Object> props;\n          synchronized (ri) {\n            props = new HashMap<>(ri.getVariables());\n          }\n          props.put(ZkStateReader.NODE_NAME_PROP, n);\n          props.put(ZkStateReader.CORE_NAME_PROP, ri.getCore());\n          props.put(ZkStateReader.REPLICA_TYPE, ri.getType().toString());\n          props.put(ZkStateReader.STATE_PROP, ri.getState().toString());\n          Replica r = new Replica(ri.getName(), props);\n          collMap.computeIfAbsent(ri.getCollection(), c -> new HashMap<>())\n              .computeIfAbsent(ri.getShard(), s -> new HashMap<>())\n              .put(ri.getName(), r);\n        });\n      });\n\n      // add empty slices\n      sliceProperties.forEach((c, perSliceProps) -> {\n        perSliceProps.forEach((slice, props) -> {\n          collMap.computeIfAbsent(c, co -> new ConcurrentHashMap<>()).computeIfAbsent(slice, s -> new ConcurrentHashMap<>());\n        });\n      });\n      // add empty collections\n      collProperties.keySet().forEach(c -> {\n        collMap.computeIfAbsent(c, co -> new ConcurrentHashMap<>());\n      });\n\n      Map<String, DocCollection> res = new HashMap<>();\n      collMap.forEach((coll, shards) -> {\n        Map<String, Slice> slices = new HashMap<>();\n        shards.forEach((s, replicas) -> {\n          Map<String, Object> sliceProps = sliceProperties.computeIfAbsent(coll, c -> new ConcurrentHashMap<>()).computeIfAbsent(s, sl -> new ConcurrentHashMap<>());\n          Slice slice = new Slice(s, replicas, sliceProps);\n          slices.put(s, slice);\n        });\n        Map<String, Object> collProps = collProperties.computeIfAbsent(coll, c -> new ConcurrentHashMap<>());\n        Map<String, Object> routerProp = (Map<String, Object>) collProps.getOrDefault(DocCollection.DOC_ROUTER, Collections.singletonMap(\"name\", DocRouter.DEFAULT_NAME));\n        DocRouter router = DocRouter.getDocRouter((String)routerProp.getOrDefault(\"name\", DocRouter.DEFAULT_NAME));\n        DocCollection dc = new DocCollection(coll, slices, collProps, router, clusterStateVersion + 1, ZkStateReader.CLUSTER_STATE);\n        res.put(coll, dc);\n      });\n      collectionsStatesRef.set(res);\n      return res;\n    } finally {\n      lock.unlock();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"66b87d86427dfa19b2ef36b66de83aa9655cea33","date":1552627668,"type":3,"author":"Chris Hostetter","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/SimClusterStateProvider#getCollectionStates().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/SimClusterStateProvider#getCollectionStates().mjava","sourceNew":"  // this method uses a simple cache in collectionsStatesRef. Operations that modify\n  // cluster state should always reset this cache so that the changes become visible\n  private Map<String, DocCollection> getCollectionStates() throws IOException {\n    lock.lock();\n    try {\n      Map<String, DocCollection> collectionStates = collectionsStatesRef.get();\n      if (collectionStates != null) {\n        return collectionStates;\n      }\n      collectionsStatesRef.set(null);\n      log.debug(\"** creating new collection states, currentVersion={}\", clusterStateVersion);\n      Map<String, Map<String, Map<String, Replica>>> collMap = new HashMap<>();\n      nodeReplicaMap.forEach((n, replicas) -> {\n          synchronized (replicas) {\n            replicas.forEach(ri -> {\n                Map<String, Object> props;\n                synchronized (ri) {\n                  props = new HashMap<>(ri.getVariables());\n                }\n                props.put(ZkStateReader.NODE_NAME_PROP, n);\n                props.put(ZkStateReader.CORE_NAME_PROP, ri.getCore());\n                props.put(ZkStateReader.REPLICA_TYPE, ri.getType().toString());\n                props.put(ZkStateReader.STATE_PROP, ri.getState().toString());\n                Replica r = new Replica(ri.getName(), props);\n                collMap.computeIfAbsent(ri.getCollection(), c -> new HashMap<>())\n                  .computeIfAbsent(ri.getShard(), s -> new HashMap<>())\n                  .put(ri.getName(), r);\n              });\n          }\n        });\n\n      // add empty slices\n      sliceProperties.forEach((c, perSliceProps) -> {\n        perSliceProps.forEach((slice, props) -> {\n          collMap.computeIfAbsent(c, co -> new ConcurrentHashMap<>()).computeIfAbsent(slice, s -> new ConcurrentHashMap<>());\n        });\n      });\n      // add empty collections\n      collProperties.keySet().forEach(c -> {\n        collMap.computeIfAbsent(c, co -> new ConcurrentHashMap<>());\n      });\n\n      Map<String, DocCollection> res = new HashMap<>();\n      collMap.forEach((coll, shards) -> {\n        Map<String, Slice> slices = new HashMap<>();\n        shards.forEach((s, replicas) -> {\n          Map<String, Object> sliceProps = sliceProperties.computeIfAbsent(coll, c -> new ConcurrentHashMap<>()).computeIfAbsent(s, sl -> new ConcurrentHashMap<>());\n          Slice slice = new Slice(s, replicas, sliceProps);\n          slices.put(s, slice);\n        });\n        Map<String, Object> collProps = collProperties.computeIfAbsent(coll, c -> new ConcurrentHashMap<>());\n        Map<String, Object> routerProp = (Map<String, Object>) collProps.getOrDefault(DocCollection.DOC_ROUTER, Collections.singletonMap(\"name\", DocRouter.DEFAULT_NAME));\n        DocRouter router = DocRouter.getDocRouter((String)routerProp.getOrDefault(\"name\", DocRouter.DEFAULT_NAME));\n        DocCollection dc = new DocCollection(coll, slices, collProps, router, clusterStateVersion, ZkStateReader.CLUSTER_STATE);\n        res.put(coll, dc);\n      });\n      saveClusterState(new ClusterState(clusterStateVersion, liveNodes.get(), res));\n      collectionsStatesRef.set(res);\n      return res;\n    } finally {\n      lock.unlock();\n    }\n  }\n\n","sourceOld":"  // this method uses a simple cache in collectionsStatesRef. Operations that modify\n  // cluster state should always reset this cache so that the changes become visible\n  private Map<String, DocCollection> getCollectionStates() throws IOException {\n    Map<String, DocCollection> collectionStates = collectionsStatesRef.get();\n    if (collectionStates != null) {\n      return collectionStates;\n    }\n    lock.lock();\n    collectionsStatesRef.set(null);\n    log.debug(\"** creating new collection states, currentVersion={}\", clusterStateVersion);\n    try {\n      Map<String, Map<String, Map<String, Replica>>> collMap = new HashMap<>();\n      nodeReplicaMap.forEach((n, replicas) -> {\n        replicas.forEach(ri -> {\n          Map<String, Object> props;\n          synchronized (ri) {\n            props = new HashMap<>(ri.getVariables());\n          }\n          props.put(ZkStateReader.NODE_NAME_PROP, n);\n          props.put(ZkStateReader.CORE_NAME_PROP, ri.getCore());\n          props.put(ZkStateReader.REPLICA_TYPE, ri.getType().toString());\n          props.put(ZkStateReader.STATE_PROP, ri.getState().toString());\n          Replica r = new Replica(ri.getName(), props);\n          collMap.computeIfAbsent(ri.getCollection(), c -> new HashMap<>())\n              .computeIfAbsent(ri.getShard(), s -> new HashMap<>())\n              .put(ri.getName(), r);\n        });\n      });\n\n      // add empty slices\n      sliceProperties.forEach((c, perSliceProps) -> {\n        perSliceProps.forEach((slice, props) -> {\n          collMap.computeIfAbsent(c, co -> new ConcurrentHashMap<>()).computeIfAbsent(slice, s -> new ConcurrentHashMap<>());\n        });\n      });\n      // add empty collections\n      collProperties.keySet().forEach(c -> {\n        collMap.computeIfAbsent(c, co -> new ConcurrentHashMap<>());\n      });\n\n      Map<String, DocCollection> res = new HashMap<>();\n      collMap.forEach((coll, shards) -> {\n        Map<String, Slice> slices = new HashMap<>();\n        shards.forEach((s, replicas) -> {\n          Map<String, Object> sliceProps = sliceProperties.computeIfAbsent(coll, c -> new ConcurrentHashMap<>()).computeIfAbsent(s, sl -> new ConcurrentHashMap<>());\n          Slice slice = new Slice(s, replicas, sliceProps);\n          slices.put(s, slice);\n        });\n        Map<String, Object> collProps = collProperties.computeIfAbsent(coll, c -> new ConcurrentHashMap<>());\n        Map<String, Object> routerProp = (Map<String, Object>) collProps.getOrDefault(DocCollection.DOC_ROUTER, Collections.singletonMap(\"name\", DocRouter.DEFAULT_NAME));\n        DocRouter router = DocRouter.getDocRouter((String)routerProp.getOrDefault(\"name\", DocRouter.DEFAULT_NAME));\n        DocCollection dc = new DocCollection(coll, slices, collProps, router, clusterStateVersion, ZkStateReader.CLUSTER_STATE);\n        res.put(coll, dc);\n      });\n      saveClusterState(new ClusterState(clusterStateVersion, liveNodes.get(), res));\n      collectionsStatesRef.set(res);\n      return res;\n    } finally {\n      lock.unlock();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"76ebb8ccd9ce24bddddc5bec621183fdec375769","date":1552676813,"type":3,"author":"Chris Hostetter","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/SimClusterStateProvider#getCollectionStates().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/SimClusterStateProvider#getCollectionStates().mjava","sourceNew":"  // this method uses a simple cache in collectionsStatesRef. Operations that modify\n  // cluster state should always reset this cache so that the changes become visible\n  private Map<String, DocCollection> getCollectionStates() throws IOException, InterruptedException {\n    lock.lockInterruptibly();\n    try {\n      Map<String, DocCollection> collectionStates = collectionsStatesRef.get();\n      if (collectionStates != null) {\n        return collectionStates;\n      }\n      collectionsStatesRef.set(null);\n      log.debug(\"** creating new collection states, currentVersion={}\", clusterStateVersion);\n      Map<String, Map<String, Map<String, Replica>>> collMap = new HashMap<>();\n      nodeReplicaMap.forEach((n, replicas) -> {\n          synchronized (replicas) {\n            replicas.forEach(ri -> {\n                Map<String, Object> props;\n                synchronized (ri) {\n                  props = new HashMap<>(ri.getVariables());\n                }\n                props.put(ZkStateReader.NODE_NAME_PROP, n);\n                props.put(ZkStateReader.CORE_NAME_PROP, ri.getCore());\n                props.put(ZkStateReader.REPLICA_TYPE, ri.getType().toString());\n                props.put(ZkStateReader.STATE_PROP, ri.getState().toString());\n                Replica r = new Replica(ri.getName(), props);\n                collMap.computeIfAbsent(ri.getCollection(), c -> new HashMap<>())\n                  .computeIfAbsent(ri.getShard(), s -> new HashMap<>())\n                  .put(ri.getName(), r);\n              });\n          }\n        });\n\n      // add empty slices\n      sliceProperties.forEach((c, perSliceProps) -> {\n        perSliceProps.forEach((slice, props) -> {\n          collMap.computeIfAbsent(c, co -> new ConcurrentHashMap<>()).computeIfAbsent(slice, s -> new ConcurrentHashMap<>());\n        });\n      });\n      // add empty collections\n      collProperties.keySet().forEach(c -> {\n        collMap.computeIfAbsent(c, co -> new ConcurrentHashMap<>());\n      });\n\n      Map<String, DocCollection> res = new HashMap<>();\n      collMap.forEach((coll, shards) -> {\n        Map<String, Slice> slices = new HashMap<>();\n        shards.forEach((s, replicas) -> {\n          Map<String, Object> sliceProps = sliceProperties.computeIfAbsent(coll, c -> new ConcurrentHashMap<>()).computeIfAbsent(s, sl -> new ConcurrentHashMap<>());\n          Slice slice = new Slice(s, replicas, sliceProps);\n          slices.put(s, slice);\n        });\n        Map<String, Object> collProps = collProperties.computeIfAbsent(coll, c -> new ConcurrentHashMap<>());\n        Map<String, Object> routerProp = (Map<String, Object>) collProps.getOrDefault(DocCollection.DOC_ROUTER, Collections.singletonMap(\"name\", DocRouter.DEFAULT_NAME));\n        DocRouter router = DocRouter.getDocRouter((String)routerProp.getOrDefault(\"name\", DocRouter.DEFAULT_NAME));\n        DocCollection dc = new DocCollection(coll, slices, collProps, router, clusterStateVersion, ZkStateReader.CLUSTER_STATE);\n        res.put(coll, dc);\n      });\n      saveClusterState(new ClusterState(clusterStateVersion, liveNodes.get(), res));\n      collectionsStatesRef.set(res);\n      return res;\n    } finally {\n      lock.unlock();\n    }\n  }\n\n","sourceOld":"  // this method uses a simple cache in collectionsStatesRef. Operations that modify\n  // cluster state should always reset this cache so that the changes become visible\n  private Map<String, DocCollection> getCollectionStates() throws IOException {\n    lock.lock();\n    try {\n      Map<String, DocCollection> collectionStates = collectionsStatesRef.get();\n      if (collectionStates != null) {\n        return collectionStates;\n      }\n      collectionsStatesRef.set(null);\n      log.debug(\"** creating new collection states, currentVersion={}\", clusterStateVersion);\n      Map<String, Map<String, Map<String, Replica>>> collMap = new HashMap<>();\n      nodeReplicaMap.forEach((n, replicas) -> {\n          synchronized (replicas) {\n            replicas.forEach(ri -> {\n                Map<String, Object> props;\n                synchronized (ri) {\n                  props = new HashMap<>(ri.getVariables());\n                }\n                props.put(ZkStateReader.NODE_NAME_PROP, n);\n                props.put(ZkStateReader.CORE_NAME_PROP, ri.getCore());\n                props.put(ZkStateReader.REPLICA_TYPE, ri.getType().toString());\n                props.put(ZkStateReader.STATE_PROP, ri.getState().toString());\n                Replica r = new Replica(ri.getName(), props);\n                collMap.computeIfAbsent(ri.getCollection(), c -> new HashMap<>())\n                  .computeIfAbsent(ri.getShard(), s -> new HashMap<>())\n                  .put(ri.getName(), r);\n              });\n          }\n        });\n\n      // add empty slices\n      sliceProperties.forEach((c, perSliceProps) -> {\n        perSliceProps.forEach((slice, props) -> {\n          collMap.computeIfAbsent(c, co -> new ConcurrentHashMap<>()).computeIfAbsent(slice, s -> new ConcurrentHashMap<>());\n        });\n      });\n      // add empty collections\n      collProperties.keySet().forEach(c -> {\n        collMap.computeIfAbsent(c, co -> new ConcurrentHashMap<>());\n      });\n\n      Map<String, DocCollection> res = new HashMap<>();\n      collMap.forEach((coll, shards) -> {\n        Map<String, Slice> slices = new HashMap<>();\n        shards.forEach((s, replicas) -> {\n          Map<String, Object> sliceProps = sliceProperties.computeIfAbsent(coll, c -> new ConcurrentHashMap<>()).computeIfAbsent(s, sl -> new ConcurrentHashMap<>());\n          Slice slice = new Slice(s, replicas, sliceProps);\n          slices.put(s, slice);\n        });\n        Map<String, Object> collProps = collProperties.computeIfAbsent(coll, c -> new ConcurrentHashMap<>());\n        Map<String, Object> routerProp = (Map<String, Object>) collProps.getOrDefault(DocCollection.DOC_ROUTER, Collections.singletonMap(\"name\", DocRouter.DEFAULT_NAME));\n        DocRouter router = DocRouter.getDocRouter((String)routerProp.getOrDefault(\"name\", DocRouter.DEFAULT_NAME));\n        DocCollection dc = new DocCollection(coll, slices, collProps, router, clusterStateVersion, ZkStateReader.CLUSTER_STATE);\n        res.put(coll, dc);\n      });\n      saveClusterState(new ClusterState(clusterStateVersion, liveNodes.get(), res));\n      collectionsStatesRef.set(res);\n      return res;\n    } finally {\n      lock.unlock();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9ef8d00dbfbeb534eba8a219a5df9d99b2de6ab5","date":1556572478,"type":5,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/autoscaling/sim/SimClusterStateProvider#getCollectionStates().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/SimClusterStateProvider#getCollectionStates().mjava","sourceNew":"  // this method uses a simple cache in collectionsStatesRef. Operations that modify\n  // cluster state should always reset this cache so that the changes become visible\n  private Map<String, DocCollection> getCollectionStates() throws IOException, InterruptedException {\n    lock.lockInterruptibly();\n    try {\n      Map<String, DocCollection> collectionStates = collectionsStatesRef.get();\n      if (collectionStates != null) {\n        return collectionStates;\n      }\n      collectionsStatesRef.set(null);\n      log.debug(\"** creating new collection states, currentVersion={}\", clusterStateVersion);\n      Map<String, Map<String, Map<String, Replica>>> collMap = new HashMap<>();\n      nodeReplicaMap.forEach((n, replicas) -> {\n          synchronized (replicas) {\n            replicas.forEach(ri -> {\n                Map<String, Object> props;\n                synchronized (ri) {\n                  props = new HashMap<>(ri.getVariables());\n                }\n                props.put(ZkStateReader.NODE_NAME_PROP, n);\n                props.put(ZkStateReader.CORE_NAME_PROP, ri.getCore());\n                props.put(ZkStateReader.REPLICA_TYPE, ri.getType().toString());\n                props.put(ZkStateReader.STATE_PROP, ri.getState().toString());\n                Replica r = new Replica(ri.getName(), props);\n                collMap.computeIfAbsent(ri.getCollection(), c -> new HashMap<>())\n                  .computeIfAbsent(ri.getShard(), s -> new HashMap<>())\n                  .put(ri.getName(), r);\n              });\n          }\n        });\n\n      // add empty slices\n      sliceProperties.forEach((c, perSliceProps) -> {\n        perSliceProps.forEach((slice, props) -> {\n          collMap.computeIfAbsent(c, co -> new ConcurrentHashMap<>()).computeIfAbsent(slice, s -> new ConcurrentHashMap<>());\n        });\n      });\n      // add empty collections\n      collProperties.keySet().forEach(c -> {\n        collMap.computeIfAbsent(c, co -> new ConcurrentHashMap<>());\n      });\n\n      Map<String, DocCollection> res = new HashMap<>();\n      collMap.forEach((coll, shards) -> {\n        Map<String, Slice> slices = new HashMap<>();\n        shards.forEach((s, replicas) -> {\n          Map<String, Object> sliceProps = sliceProperties.computeIfAbsent(coll, c -> new ConcurrentHashMap<>()).computeIfAbsent(s, sl -> new ConcurrentHashMap<>());\n          Slice slice = new Slice(s, replicas, sliceProps);\n          slices.put(s, slice);\n        });\n        Map<String, Object> collProps = collProperties.computeIfAbsent(coll, c -> new ConcurrentHashMap<>());\n        Map<String, Object> routerProp = (Map<String, Object>) collProps.getOrDefault(DocCollection.DOC_ROUTER, Collections.singletonMap(\"name\", DocRouter.DEFAULT_NAME));\n        DocRouter router = DocRouter.getDocRouter((String)routerProp.getOrDefault(\"name\", DocRouter.DEFAULT_NAME));\n        DocCollection dc = new DocCollection(coll, slices, collProps, router, clusterStateVersion, ZkStateReader.CLUSTER_STATE);\n        res.put(coll, dc);\n      });\n      saveClusterState(new ClusterState(clusterStateVersion, liveNodes.get(), res));\n      collectionsStatesRef.set(res);\n      return res;\n    } finally {\n      lock.unlock();\n    }\n  }\n\n","sourceOld":"  // this method uses a simple cache in collectionsStatesRef. Operations that modify\n  // cluster state should always reset this cache so that the changes become visible\n  private Map<String, DocCollection> getCollectionStates() throws IOException, InterruptedException {\n    lock.lockInterruptibly();\n    try {\n      Map<String, DocCollection> collectionStates = collectionsStatesRef.get();\n      if (collectionStates != null) {\n        return collectionStates;\n      }\n      collectionsStatesRef.set(null);\n      log.debug(\"** creating new collection states, currentVersion={}\", clusterStateVersion);\n      Map<String, Map<String, Map<String, Replica>>> collMap = new HashMap<>();\n      nodeReplicaMap.forEach((n, replicas) -> {\n          synchronized (replicas) {\n            replicas.forEach(ri -> {\n                Map<String, Object> props;\n                synchronized (ri) {\n                  props = new HashMap<>(ri.getVariables());\n                }\n                props.put(ZkStateReader.NODE_NAME_PROP, n);\n                props.put(ZkStateReader.CORE_NAME_PROP, ri.getCore());\n                props.put(ZkStateReader.REPLICA_TYPE, ri.getType().toString());\n                props.put(ZkStateReader.STATE_PROP, ri.getState().toString());\n                Replica r = new Replica(ri.getName(), props);\n                collMap.computeIfAbsent(ri.getCollection(), c -> new HashMap<>())\n                  .computeIfAbsent(ri.getShard(), s -> new HashMap<>())\n                  .put(ri.getName(), r);\n              });\n          }\n        });\n\n      // add empty slices\n      sliceProperties.forEach((c, perSliceProps) -> {\n        perSliceProps.forEach((slice, props) -> {\n          collMap.computeIfAbsent(c, co -> new ConcurrentHashMap<>()).computeIfAbsent(slice, s -> new ConcurrentHashMap<>());\n        });\n      });\n      // add empty collections\n      collProperties.keySet().forEach(c -> {\n        collMap.computeIfAbsent(c, co -> new ConcurrentHashMap<>());\n      });\n\n      Map<String, DocCollection> res = new HashMap<>();\n      collMap.forEach((coll, shards) -> {\n        Map<String, Slice> slices = new HashMap<>();\n        shards.forEach((s, replicas) -> {\n          Map<String, Object> sliceProps = sliceProperties.computeIfAbsent(coll, c -> new ConcurrentHashMap<>()).computeIfAbsent(s, sl -> new ConcurrentHashMap<>());\n          Slice slice = new Slice(s, replicas, sliceProps);\n          slices.put(s, slice);\n        });\n        Map<String, Object> collProps = collProperties.computeIfAbsent(coll, c -> new ConcurrentHashMap<>());\n        Map<String, Object> routerProp = (Map<String, Object>) collProps.getOrDefault(DocCollection.DOC_ROUTER, Collections.singletonMap(\"name\", DocRouter.DEFAULT_NAME));\n        DocRouter router = DocRouter.getDocRouter((String)routerProp.getOrDefault(\"name\", DocRouter.DEFAULT_NAME));\n        DocCollection dc = new DocCollection(coll, slices, collProps, router, clusterStateVersion, ZkStateReader.CLUSTER_STATE);\n        res.put(coll, dc);\n      });\n      saveClusterState(new ClusterState(clusterStateVersion, liveNodes.get(), res));\n      collectionsStatesRef.set(res);\n      return res;\n    } finally {\n      lock.unlock();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"76ebb8ccd9ce24bddddc5bec621183fdec375769":["66b87d86427dfa19b2ef36b66de83aa9655cea33"],"fc18bc8ea2e2c1e308757ff50671c774438e9f3e":["43345f1452f9510f8aaadae6156fe0c834e7d957"],"ce71a9836bf1eba34a0ab31884e9eb8ad3f1cef1":["a4422b331d00607258b0ed3e43934306e67764aa"],"66b87d86427dfa19b2ef36b66de83aa9655cea33":["8254aa20264eb7a88d556bbe0346667937ed9c2a"],"8254aa20264eb7a88d556bbe0346667937ed9c2a":["fc18bc8ea2e2c1e308757ff50671c774438e9f3e"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"a4422b331d00607258b0ed3e43934306e67764aa":["1d4bf9d5308dfef350829c28f2b3b2648df1e9b1"],"9ef8d00dbfbeb534eba8a219a5df9d99b2de6ab5":["76ebb8ccd9ce24bddddc5bec621183fdec375769"],"1d4bf9d5308dfef350829c28f2b3b2648df1e9b1":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"43345f1452f9510f8aaadae6156fe0c834e7d957":["a4422b331d00607258b0ed3e43934306e67764aa","ce71a9836bf1eba34a0ab31884e9eb8ad3f1cef1"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["9ef8d00dbfbeb534eba8a219a5df9d99b2de6ab5"]},"commit2Childs":{"76ebb8ccd9ce24bddddc5bec621183fdec375769":["9ef8d00dbfbeb534eba8a219a5df9d99b2de6ab5"],"fc18bc8ea2e2c1e308757ff50671c774438e9f3e":["8254aa20264eb7a88d556bbe0346667937ed9c2a"],"ce71a9836bf1eba34a0ab31884e9eb8ad3f1cef1":["43345f1452f9510f8aaadae6156fe0c834e7d957"],"66b87d86427dfa19b2ef36b66de83aa9655cea33":["76ebb8ccd9ce24bddddc5bec621183fdec375769"],"8254aa20264eb7a88d556bbe0346667937ed9c2a":["66b87d86427dfa19b2ef36b66de83aa9655cea33"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["1d4bf9d5308dfef350829c28f2b3b2648df1e9b1"],"a4422b331d00607258b0ed3e43934306e67764aa":["ce71a9836bf1eba34a0ab31884e9eb8ad3f1cef1","43345f1452f9510f8aaadae6156fe0c834e7d957"],"9ef8d00dbfbeb534eba8a219a5df9d99b2de6ab5":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"1d4bf9d5308dfef350829c28f2b3b2648df1e9b1":["a4422b331d00607258b0ed3e43934306e67764aa"],"43345f1452f9510f8aaadae6156fe0c834e7d957":["fc18bc8ea2e2c1e308757ff50671c774438e9f3e"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}