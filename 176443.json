{"path":"solr/core/src/test/org/apache/solr/core/snapshots/TestSolrCoreSnapshots#testBackupRestore().mjava","commits":[{"id":"91e2345fb81b6c1c7faefa550ee5eaafadc54486","date":1469730189,"type":0,"author":"David Smiley","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/core/snapshots/TestSolrCoreSnapshots#testBackupRestore().mjava","pathOld":"/dev/null","sourceNew":"  @Test\n  public void testBackupRestore() throws Exception {\n    CloudSolrClient solrClient = cluster.getSolrClient();\n    String collectionName = \"SolrCoreSnapshots\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName, \"conf1\", 1, 1);\n    create.process(solrClient);\n\n    String location = createTempDir().toFile().getAbsolutePath();\n    int nDocs = BackupRestoreUtils.indexDocs(cluster.getSolrClient(), collectionName, docsSeed);\n\n    DocCollection collectionState = solrClient.getZkStateReader().getClusterState().getCollection(collectionName);\n    assertEquals(1, collectionState.getActiveSlices().size());\n    Slice shard = collectionState.getActiveSlices().iterator().next();\n    assertEquals(1, shard.getReplicas().size());\n    Replica replica = shard.getReplicas().iterator().next();\n\n    String replicaBaseUrl = replica.getStr(BASE_URL_PROP);\n    String coreName = replica.getStr(ZkStateReader.CORE_NAME_PROP);\n    String backupName = TestUtil.randomSimpleString(random(), 1, 5);\n    String commitName = TestUtil.randomSimpleString(random(), 1, 5);\n    String duplicateName = commitName.concat(\"_duplicate\");\n\n    try (\n        SolrClient adminClient = getHttpSolrClient(cluster.getJettySolrRunners().get(0).getBaseUrl().toString());\n        SolrClient masterClient = getHttpSolrClient(replica.getCoreUrl())) {\n\n      SnapshotMetaData metaData = createSnapshot(adminClient, coreName, commitName);\n      // Create another snapshot referring to the same index commit to verify the\n      // reference counting implementation during snapshot deletion.\n      SnapshotMetaData duplicateCommit = createSnapshot(adminClient, coreName, duplicateName);\n\n      assertEquals (metaData.getIndexDirPath(), duplicateCommit.getIndexDirPath());\n      assertEquals (metaData.getGenerationNumber(), duplicateCommit.getGenerationNumber());\n\n      // Delete all documents\n      masterClient.deleteByQuery(\"*:*\");\n      masterClient.commit();\n      BackupRestoreUtils.verifyDocs(0, cluster.getSolrClient(), collectionName);\n\n      // Verify that the index directory contains at least 2 index commits - one referred by the snapshots\n      // and the other containing document deletions.\n      {\n        List<IndexCommit> commits = listCommits(metaData.getIndexDirPath());\n        assertTrue(2 <= commits.size());\n      }\n\n      // Backup the earlier created snapshot.\n      {\n        Map<String,String> params = new HashMap<>();\n        params.put(\"name\", backupName);\n        params.put(\"commitName\", commitName);\n        params.put(\"location\", location);\n        BackupRestoreUtils.runCoreAdminCommand(replicaBaseUrl, coreName, CoreAdminAction.BACKUPCORE.toString(), params);\n      }\n\n      // Restore the backup\n      {\n        Map<String,String> params = new HashMap<>();\n        params.put(\"name\", \"snapshot.\" + backupName);\n        params.put(\"location\", location);\n        BackupRestoreUtils.runCoreAdminCommand(replicaBaseUrl, coreName, CoreAdminAction.RESTORECORE.toString(), params);\n        BackupRestoreUtils.verifyDocs(nDocs, cluster.getSolrClient(), collectionName);\n      }\n\n      // Verify that the old index directory (before restore) contains only those index commits referred by snapshots.\n      {\n        List<IndexCommit> commits = listCommits(metaData.getIndexDirPath());\n        assertEquals(1, commits.size());\n        assertEquals(metaData.getGenerationNumber(), commits.get(0).getGeneration());\n      }\n\n      // Delete first snapshot\n      deleteSnapshot(adminClient, coreName, commitName);\n\n      // Verify that corresponding index files have NOT been deleted (due to reference counting).\n      assertFalse(listCommits(metaData.getIndexDirPath()).isEmpty());\n\n      // Delete second snapshot\n      deleteSnapshot(adminClient, coreName, duplicateCommit.getName());\n\n      // Verify that corresponding index files have been deleted.\n      assertTrue(listCommits(duplicateCommit.getIndexDirPath()).isEmpty());\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3b013574eedcdbac35dc7e35b0ee616ffc38895d","date":1470897818,"type":0,"author":"Noble Paul","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/core/snapshots/TestSolrCoreSnapshots#testBackupRestore().mjava","pathOld":"/dev/null","sourceNew":"  @Test\n  public void testBackupRestore() throws Exception {\n    CloudSolrClient solrClient = cluster.getSolrClient();\n    String collectionName = \"SolrCoreSnapshots\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName, \"conf1\", 1, 1);\n    create.process(solrClient);\n\n    String location = createTempDir().toFile().getAbsolutePath();\n    int nDocs = BackupRestoreUtils.indexDocs(cluster.getSolrClient(), collectionName, docsSeed);\n\n    DocCollection collectionState = solrClient.getZkStateReader().getClusterState().getCollection(collectionName);\n    assertEquals(1, collectionState.getActiveSlices().size());\n    Slice shard = collectionState.getActiveSlices().iterator().next();\n    assertEquals(1, shard.getReplicas().size());\n    Replica replica = shard.getReplicas().iterator().next();\n\n    String replicaBaseUrl = replica.getStr(BASE_URL_PROP);\n    String coreName = replica.getStr(ZkStateReader.CORE_NAME_PROP);\n    String backupName = TestUtil.randomSimpleString(random(), 1, 5);\n    String commitName = TestUtil.randomSimpleString(random(), 1, 5);\n    String duplicateName = commitName.concat(\"_duplicate\");\n\n    try (\n        SolrClient adminClient = getHttpSolrClient(cluster.getJettySolrRunners().get(0).getBaseUrl().toString());\n        SolrClient masterClient = getHttpSolrClient(replica.getCoreUrl())) {\n\n      SnapshotMetaData metaData = createSnapshot(adminClient, coreName, commitName);\n      // Create another snapshot referring to the same index commit to verify the\n      // reference counting implementation during snapshot deletion.\n      SnapshotMetaData duplicateCommit = createSnapshot(adminClient, coreName, duplicateName);\n\n      assertEquals (metaData.getIndexDirPath(), duplicateCommit.getIndexDirPath());\n      assertEquals (metaData.getGenerationNumber(), duplicateCommit.getGenerationNumber());\n\n      // Delete all documents\n      masterClient.deleteByQuery(\"*:*\");\n      masterClient.commit();\n      BackupRestoreUtils.verifyDocs(0, cluster.getSolrClient(), collectionName);\n\n      // Verify that the index directory contains at least 2 index commits - one referred by the snapshots\n      // and the other containing document deletions.\n      {\n        List<IndexCommit> commits = listCommits(metaData.getIndexDirPath());\n        assertTrue(2 <= commits.size());\n      }\n\n      // Backup the earlier created snapshot.\n      {\n        Map<String,String> params = new HashMap<>();\n        params.put(\"name\", backupName);\n        params.put(\"commitName\", commitName);\n        params.put(\"location\", location);\n        BackupRestoreUtils.runCoreAdminCommand(replicaBaseUrl, coreName, CoreAdminAction.BACKUPCORE.toString(), params);\n      }\n\n      // Restore the backup\n      {\n        Map<String,String> params = new HashMap<>();\n        params.put(\"name\", \"snapshot.\" + backupName);\n        params.put(\"location\", location);\n        BackupRestoreUtils.runCoreAdminCommand(replicaBaseUrl, coreName, CoreAdminAction.RESTORECORE.toString(), params);\n        BackupRestoreUtils.verifyDocs(nDocs, cluster.getSolrClient(), collectionName);\n      }\n\n      // Verify that the old index directory (before restore) contains only those index commits referred by snapshots.\n      {\n        List<IndexCommit> commits = listCommits(metaData.getIndexDirPath());\n        assertEquals(1, commits.size());\n        assertEquals(metaData.getGenerationNumber(), commits.get(0).getGeneration());\n      }\n\n      // Delete first snapshot\n      deleteSnapshot(adminClient, coreName, commitName);\n\n      // Verify that corresponding index files have NOT been deleted (due to reference counting).\n      assertFalse(listCommits(metaData.getIndexDirPath()).isEmpty());\n\n      // Delete second snapshot\n      deleteSnapshot(adminClient, coreName, duplicateCommit.getName());\n\n      // Verify that corresponding index files have been deleted.\n      assertTrue(listCommits(duplicateCommit.getIndexDirPath()).isEmpty());\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3e13696c44d3e2405098726359ab81dab178e7bc","date":1476726926,"type":3,"author":"Hrishikesh Gadre","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/core/snapshots/TestSolrCoreSnapshots#testBackupRestore().mjava","pathOld":"solr/core/src/test/org/apache/solr/core/snapshots/TestSolrCoreSnapshots#testBackupRestore().mjava","sourceNew":"  @Test\n  public void testBackupRestore() throws Exception {\n    CloudSolrClient solrClient = cluster.getSolrClient();\n    String collectionName = \"SolrCoreSnapshots\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName, \"conf1\", 1, 1);\n    create.process(solrClient);\n\n    String location = createTempDir().toFile().getAbsolutePath();\n    int nDocs = BackupRestoreUtils.indexDocs(cluster.getSolrClient(), collectionName, docsSeed);\n\n    DocCollection collectionState = solrClient.getZkStateReader().getClusterState().getCollection(collectionName);\n    assertEquals(1, collectionState.getActiveSlices().size());\n    Slice shard = collectionState.getActiveSlices().iterator().next();\n    assertEquals(1, shard.getReplicas().size());\n    Replica replica = shard.getReplicas().iterator().next();\n\n    String replicaBaseUrl = replica.getStr(BASE_URL_PROP);\n    String coreName = replica.getStr(ZkStateReader.CORE_NAME_PROP);\n    String backupName = TestUtil.randomSimpleString(random(), 1, 5);\n    String commitName = TestUtil.randomSimpleString(random(), 1, 5);\n    String duplicateName = commitName.concat(\"_duplicate\");\n\n    try (\n        SolrClient adminClient = getHttpSolrClient(cluster.getJettySolrRunners().get(0).getBaseUrl().toString());\n        SolrClient masterClient = getHttpSolrClient(replica.getCoreUrl())) {\n\n      SnapshotMetaData metaData = createSnapshot(adminClient, coreName, commitName);\n      // Create another snapshot referring to the same index commit to verify the\n      // reference counting implementation during snapshot deletion.\n      SnapshotMetaData duplicateCommit = createSnapshot(adminClient, coreName, duplicateName);\n\n      assertEquals (metaData.getIndexDirPath(), duplicateCommit.getIndexDirPath());\n      assertEquals (metaData.getGenerationNumber(), duplicateCommit.getGenerationNumber());\n\n      // Delete all documents\n      masterClient.deleteByQuery(\"*:*\");\n      masterClient.commit();\n      BackupRestoreUtils.verifyDocs(0, cluster.getSolrClient(), collectionName);\n\n      // Verify that the index directory contains at least 2 index commits - one referred by the snapshots\n      // and the other containing document deletions.\n      {\n        List<IndexCommit> commits = listCommits(metaData.getIndexDirPath());\n        assertTrue(commits.size() >= 2);\n      }\n\n      // Backup the earlier created snapshot.\n      {\n        Map<String,String> params = new HashMap<>();\n        params.put(\"name\", backupName);\n        params.put(\"commitName\", commitName);\n        params.put(\"location\", location);\n        BackupRestoreUtils.runCoreAdminCommand(replicaBaseUrl, coreName, CoreAdminAction.BACKUPCORE.toString(), params);\n      }\n\n      // Restore the backup\n      {\n        Map<String,String> params = new HashMap<>();\n        params.put(\"name\", \"snapshot.\" + backupName);\n        params.put(\"location\", location);\n        BackupRestoreUtils.runCoreAdminCommand(replicaBaseUrl, coreName, CoreAdminAction.RESTORECORE.toString(), params);\n        BackupRestoreUtils.verifyDocs(nDocs, cluster.getSolrClient(), collectionName);\n      }\n\n      // Verify that the old index directory (before restore) contains only those index commits referred by snapshots.\n      // The IndexWriter (used to cleanup index files) creates an additional commit during closing. Hence we expect 2 commits (instead\n      // of 1).\n      {\n        List<IndexCommit> commits = listCommits(metaData.getIndexDirPath());\n        assertEquals(2, commits.size());\n        assertEquals(metaData.getGenerationNumber(), commits.get(0).getGeneration());\n      }\n\n      // Delete first snapshot\n      deleteSnapshot(adminClient, coreName, commitName);\n\n      // Verify that corresponding index files have NOT been deleted (due to reference counting).\n      assertFalse(listCommits(metaData.getIndexDirPath()).isEmpty());\n\n      // Delete second snapshot\n      deleteSnapshot(adminClient, coreName, duplicateCommit.getName());\n\n      // Verify that corresponding index files have been deleted. Ideally this directory should\n      // be removed immediately. But the current DirectoryFactory impl waits until the\n      // closing the core (or the directoryFactory) for actual removal. Since the IndexWriter\n      // (used to cleanup index files) creates an additional commit during closing, we expect a single\n      // commit (instead of 0).\n      assertEquals(1, listCommits(duplicateCommit.getIndexDirPath()).size());\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testBackupRestore() throws Exception {\n    CloudSolrClient solrClient = cluster.getSolrClient();\n    String collectionName = \"SolrCoreSnapshots\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName, \"conf1\", 1, 1);\n    create.process(solrClient);\n\n    String location = createTempDir().toFile().getAbsolutePath();\n    int nDocs = BackupRestoreUtils.indexDocs(cluster.getSolrClient(), collectionName, docsSeed);\n\n    DocCollection collectionState = solrClient.getZkStateReader().getClusterState().getCollection(collectionName);\n    assertEquals(1, collectionState.getActiveSlices().size());\n    Slice shard = collectionState.getActiveSlices().iterator().next();\n    assertEquals(1, shard.getReplicas().size());\n    Replica replica = shard.getReplicas().iterator().next();\n\n    String replicaBaseUrl = replica.getStr(BASE_URL_PROP);\n    String coreName = replica.getStr(ZkStateReader.CORE_NAME_PROP);\n    String backupName = TestUtil.randomSimpleString(random(), 1, 5);\n    String commitName = TestUtil.randomSimpleString(random(), 1, 5);\n    String duplicateName = commitName.concat(\"_duplicate\");\n\n    try (\n        SolrClient adminClient = getHttpSolrClient(cluster.getJettySolrRunners().get(0).getBaseUrl().toString());\n        SolrClient masterClient = getHttpSolrClient(replica.getCoreUrl())) {\n\n      SnapshotMetaData metaData = createSnapshot(adminClient, coreName, commitName);\n      // Create another snapshot referring to the same index commit to verify the\n      // reference counting implementation during snapshot deletion.\n      SnapshotMetaData duplicateCommit = createSnapshot(adminClient, coreName, duplicateName);\n\n      assertEquals (metaData.getIndexDirPath(), duplicateCommit.getIndexDirPath());\n      assertEquals (metaData.getGenerationNumber(), duplicateCommit.getGenerationNumber());\n\n      // Delete all documents\n      masterClient.deleteByQuery(\"*:*\");\n      masterClient.commit();\n      BackupRestoreUtils.verifyDocs(0, cluster.getSolrClient(), collectionName);\n\n      // Verify that the index directory contains at least 2 index commits - one referred by the snapshots\n      // and the other containing document deletions.\n      {\n        List<IndexCommit> commits = listCommits(metaData.getIndexDirPath());\n        assertTrue(2 <= commits.size());\n      }\n\n      // Backup the earlier created snapshot.\n      {\n        Map<String,String> params = new HashMap<>();\n        params.put(\"name\", backupName);\n        params.put(\"commitName\", commitName);\n        params.put(\"location\", location);\n        BackupRestoreUtils.runCoreAdminCommand(replicaBaseUrl, coreName, CoreAdminAction.BACKUPCORE.toString(), params);\n      }\n\n      // Restore the backup\n      {\n        Map<String,String> params = new HashMap<>();\n        params.put(\"name\", \"snapshot.\" + backupName);\n        params.put(\"location\", location);\n        BackupRestoreUtils.runCoreAdminCommand(replicaBaseUrl, coreName, CoreAdminAction.RESTORECORE.toString(), params);\n        BackupRestoreUtils.verifyDocs(nDocs, cluster.getSolrClient(), collectionName);\n      }\n\n      // Verify that the old index directory (before restore) contains only those index commits referred by snapshots.\n      {\n        List<IndexCommit> commits = listCommits(metaData.getIndexDirPath());\n        assertEquals(1, commits.size());\n        assertEquals(metaData.getGenerationNumber(), commits.get(0).getGeneration());\n      }\n\n      // Delete first snapshot\n      deleteSnapshot(adminClient, coreName, commitName);\n\n      // Verify that corresponding index files have NOT been deleted (due to reference counting).\n      assertFalse(listCommits(metaData.getIndexDirPath()).isEmpty());\n\n      // Delete second snapshot\n      deleteSnapshot(adminClient, coreName, duplicateCommit.getName());\n\n      // Verify that corresponding index files have been deleted.\n      assertTrue(listCommits(duplicateCommit.getIndexDirPath()).isEmpty());\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4cce5816ef15a48a0bc11e5d400497ee4301dd3b","date":1476991456,"type":0,"author":"Kevin Risden","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/core/snapshots/TestSolrCoreSnapshots#testBackupRestore().mjava","pathOld":"/dev/null","sourceNew":"  @Test\n  public void testBackupRestore() throws Exception {\n    CloudSolrClient solrClient = cluster.getSolrClient();\n    String collectionName = \"SolrCoreSnapshots\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName, \"conf1\", 1, 1);\n    create.process(solrClient);\n\n    String location = createTempDir().toFile().getAbsolutePath();\n    int nDocs = BackupRestoreUtils.indexDocs(cluster.getSolrClient(), collectionName, docsSeed);\n\n    DocCollection collectionState = solrClient.getZkStateReader().getClusterState().getCollection(collectionName);\n    assertEquals(1, collectionState.getActiveSlices().size());\n    Slice shard = collectionState.getActiveSlices().iterator().next();\n    assertEquals(1, shard.getReplicas().size());\n    Replica replica = shard.getReplicas().iterator().next();\n\n    String replicaBaseUrl = replica.getStr(BASE_URL_PROP);\n    String coreName = replica.getStr(ZkStateReader.CORE_NAME_PROP);\n    String backupName = TestUtil.randomSimpleString(random(), 1, 5);\n    String commitName = TestUtil.randomSimpleString(random(), 1, 5);\n    String duplicateName = commitName.concat(\"_duplicate\");\n\n    try (\n        SolrClient adminClient = getHttpSolrClient(cluster.getJettySolrRunners().get(0).getBaseUrl().toString());\n        SolrClient masterClient = getHttpSolrClient(replica.getCoreUrl())) {\n\n      SnapshotMetaData metaData = createSnapshot(adminClient, coreName, commitName);\n      // Create another snapshot referring to the same index commit to verify the\n      // reference counting implementation during snapshot deletion.\n      SnapshotMetaData duplicateCommit = createSnapshot(adminClient, coreName, duplicateName);\n\n      assertEquals (metaData.getIndexDirPath(), duplicateCommit.getIndexDirPath());\n      assertEquals (metaData.getGenerationNumber(), duplicateCommit.getGenerationNumber());\n\n      // Delete all documents\n      masterClient.deleteByQuery(\"*:*\");\n      masterClient.commit();\n      BackupRestoreUtils.verifyDocs(0, cluster.getSolrClient(), collectionName);\n\n      // Verify that the index directory contains at least 2 index commits - one referred by the snapshots\n      // and the other containing document deletions.\n      {\n        List<IndexCommit> commits = listCommits(metaData.getIndexDirPath());\n        assertTrue(commits.size() >= 2);\n      }\n\n      // Backup the earlier created snapshot.\n      {\n        Map<String,String> params = new HashMap<>();\n        params.put(\"name\", backupName);\n        params.put(\"commitName\", commitName);\n        params.put(\"location\", location);\n        BackupRestoreUtils.runCoreAdminCommand(replicaBaseUrl, coreName, CoreAdminAction.BACKUPCORE.toString(), params);\n      }\n\n      // Restore the backup\n      {\n        Map<String,String> params = new HashMap<>();\n        params.put(\"name\", \"snapshot.\" + backupName);\n        params.put(\"location\", location);\n        BackupRestoreUtils.runCoreAdminCommand(replicaBaseUrl, coreName, CoreAdminAction.RESTORECORE.toString(), params);\n        BackupRestoreUtils.verifyDocs(nDocs, cluster.getSolrClient(), collectionName);\n      }\n\n      // Verify that the old index directory (before restore) contains only those index commits referred by snapshots.\n      // The IndexWriter (used to cleanup index files) creates an additional commit during closing. Hence we expect 2 commits (instead\n      // of 1).\n      {\n        List<IndexCommit> commits = listCommits(metaData.getIndexDirPath());\n        assertEquals(2, commits.size());\n        assertEquals(metaData.getGenerationNumber(), commits.get(0).getGeneration());\n      }\n\n      // Delete first snapshot\n      deleteSnapshot(adminClient, coreName, commitName);\n\n      // Verify that corresponding index files have NOT been deleted (due to reference counting).\n      assertFalse(listCommits(metaData.getIndexDirPath()).isEmpty());\n\n      // Delete second snapshot\n      deleteSnapshot(adminClient, coreName, duplicateCommit.getName());\n\n      // Verify that corresponding index files have been deleted. Ideally this directory should\n      // be removed immediately. But the current DirectoryFactory impl waits until the\n      // closing the core (or the directoryFactory) for actual removal. Since the IndexWriter\n      // (used to cleanup index files) creates an additional commit during closing, we expect a single\n      // commit (instead of 0).\n      assertEquals(1, listCommits(duplicateCommit.getIndexDirPath()).size());\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"65a5d87a40f9143cd55be76eb1dde1b32a8dae5e","date":1596664368,"type":3,"author":"Marcus","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/core/snapshots/TestSolrCoreSnapshots#testBackupRestore().mjava","pathOld":"solr/core/src/test/org/apache/solr/core/snapshots/TestSolrCoreSnapshots#testBackupRestore().mjava","sourceNew":"  @Test\n  public void testBackupRestore() throws Exception {\n    CloudSolrClient solrClient = cluster.getSolrClient();\n    String collectionName = \"SolrCoreSnapshots\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName, \"conf1\", 1, 1);\n    create.process(solrClient);\n\n    String location = createTempDir().toFile().getAbsolutePath();\n    int nDocs = BackupRestoreUtils.indexDocs(cluster.getSolrClient(), collectionName, docsSeed);\n\n    DocCollection collectionState = solrClient.getZkStateReader().getClusterState().getCollection(collectionName);\n    assertEquals(1, collectionState.getActiveSlices().size());\n    Slice shard = collectionState.getActiveSlices().iterator().next();\n    assertEquals(1, shard.getReplicas().size());\n    Replica replica = shard.getReplicas().iterator().next();\n\n    String replicaBaseUrl = replica.getStr(BASE_URL_PROP);\n    String coreName = replica.getStr(ZkStateReader.CORE_NAME_PROP);\n    String backupName = TestUtil.randomSimpleString(random(), 1, 5);\n    String commitName = TestUtil.randomSimpleString(random(), 1, 5);\n    String duplicateName = commitName.concat(\"_duplicate\");\n\n    try (\n        SolrClient adminClient = getHttpSolrClient(cluster.getJettySolrRunners().get(0).getBaseUrl().toString());\n        SolrClient leaderClient = getHttpSolrClient(replica.getCoreUrl())) {\n\n      SnapshotMetaData metaData = createSnapshot(adminClient, coreName, commitName);\n      // Create another snapshot referring to the same index commit to verify the\n      // reference counting implementation during snapshot deletion.\n      SnapshotMetaData duplicateCommit = createSnapshot(adminClient, coreName, duplicateName);\n\n      assertEquals (metaData.getIndexDirPath(), duplicateCommit.getIndexDirPath());\n      assertEquals (metaData.getGenerationNumber(), duplicateCommit.getGenerationNumber());\n\n      // Delete all documents\n      leaderClient.deleteByQuery(\"*:*\");\n      leaderClient.commit();\n      BackupRestoreUtils.verifyDocs(0, cluster.getSolrClient(), collectionName);\n\n      // Verify that the index directory contains at least 2 index commits - one referred by the snapshots\n      // and the other containing document deletions.\n      {\n        List<IndexCommit> commits = listCommits(metaData.getIndexDirPath());\n        assertTrue(commits.size() >= 2);\n      }\n\n      // Backup the earlier created snapshot.\n      {\n        Map<String,String> params = new HashMap<>();\n        params.put(\"name\", backupName);\n        params.put(\"commitName\", commitName);\n        params.put(\"location\", location);\n        BackupRestoreUtils.runCoreAdminCommand(replicaBaseUrl, coreName, CoreAdminAction.BACKUPCORE.toString(), params);\n      }\n\n      // Restore the backup\n      {\n        Map<String,String> params = new HashMap<>();\n        params.put(\"name\", \"snapshot.\" + backupName);\n        params.put(\"location\", location);\n        BackupRestoreUtils.runCoreAdminCommand(replicaBaseUrl, coreName, CoreAdminAction.RESTORECORE.toString(), params);\n        BackupRestoreUtils.verifyDocs(nDocs, cluster.getSolrClient(), collectionName);\n      }\n\n      // Verify that the old index directory (before restore) contains only those index commits referred by snapshots.\n      // The IndexWriter (used to cleanup index files) creates an additional commit during closing. Hence we expect 2 commits (instead\n      // of 1).\n      {\n        List<IndexCommit> commits = listCommits(metaData.getIndexDirPath());\n        assertEquals(2, commits.size());\n        assertEquals(metaData.getGenerationNumber(), commits.get(0).getGeneration());\n      }\n\n      // Delete first snapshot\n      deleteSnapshot(adminClient, coreName, commitName);\n\n      // Verify that corresponding index files have NOT been deleted (due to reference counting).\n      assertFalse(listCommits(metaData.getIndexDirPath()).isEmpty());\n\n      // Delete second snapshot\n      deleteSnapshot(adminClient, coreName, duplicateCommit.getName());\n\n      // Verify that corresponding index files have been deleted. Ideally this directory should\n      // be removed immediately. But the current DirectoryFactory impl waits until the\n      // closing the core (or the directoryFactory) for actual removal. Since the IndexWriter\n      // (used to cleanup index files) creates an additional commit during closing, we expect a single\n      // commit (instead of 0).\n      assertEquals(1, listCommits(duplicateCommit.getIndexDirPath()).size());\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testBackupRestore() throws Exception {\n    CloudSolrClient solrClient = cluster.getSolrClient();\n    String collectionName = \"SolrCoreSnapshots\";\n    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName, \"conf1\", 1, 1);\n    create.process(solrClient);\n\n    String location = createTempDir().toFile().getAbsolutePath();\n    int nDocs = BackupRestoreUtils.indexDocs(cluster.getSolrClient(), collectionName, docsSeed);\n\n    DocCollection collectionState = solrClient.getZkStateReader().getClusterState().getCollection(collectionName);\n    assertEquals(1, collectionState.getActiveSlices().size());\n    Slice shard = collectionState.getActiveSlices().iterator().next();\n    assertEquals(1, shard.getReplicas().size());\n    Replica replica = shard.getReplicas().iterator().next();\n\n    String replicaBaseUrl = replica.getStr(BASE_URL_PROP);\n    String coreName = replica.getStr(ZkStateReader.CORE_NAME_PROP);\n    String backupName = TestUtil.randomSimpleString(random(), 1, 5);\n    String commitName = TestUtil.randomSimpleString(random(), 1, 5);\n    String duplicateName = commitName.concat(\"_duplicate\");\n\n    try (\n        SolrClient adminClient = getHttpSolrClient(cluster.getJettySolrRunners().get(0).getBaseUrl().toString());\n        SolrClient masterClient = getHttpSolrClient(replica.getCoreUrl())) {\n\n      SnapshotMetaData metaData = createSnapshot(adminClient, coreName, commitName);\n      // Create another snapshot referring to the same index commit to verify the\n      // reference counting implementation during snapshot deletion.\n      SnapshotMetaData duplicateCommit = createSnapshot(adminClient, coreName, duplicateName);\n\n      assertEquals (metaData.getIndexDirPath(), duplicateCommit.getIndexDirPath());\n      assertEquals (metaData.getGenerationNumber(), duplicateCommit.getGenerationNumber());\n\n      // Delete all documents\n      masterClient.deleteByQuery(\"*:*\");\n      masterClient.commit();\n      BackupRestoreUtils.verifyDocs(0, cluster.getSolrClient(), collectionName);\n\n      // Verify that the index directory contains at least 2 index commits - one referred by the snapshots\n      // and the other containing document deletions.\n      {\n        List<IndexCommit> commits = listCommits(metaData.getIndexDirPath());\n        assertTrue(commits.size() >= 2);\n      }\n\n      // Backup the earlier created snapshot.\n      {\n        Map<String,String> params = new HashMap<>();\n        params.put(\"name\", backupName);\n        params.put(\"commitName\", commitName);\n        params.put(\"location\", location);\n        BackupRestoreUtils.runCoreAdminCommand(replicaBaseUrl, coreName, CoreAdminAction.BACKUPCORE.toString(), params);\n      }\n\n      // Restore the backup\n      {\n        Map<String,String> params = new HashMap<>();\n        params.put(\"name\", \"snapshot.\" + backupName);\n        params.put(\"location\", location);\n        BackupRestoreUtils.runCoreAdminCommand(replicaBaseUrl, coreName, CoreAdminAction.RESTORECORE.toString(), params);\n        BackupRestoreUtils.verifyDocs(nDocs, cluster.getSolrClient(), collectionName);\n      }\n\n      // Verify that the old index directory (before restore) contains only those index commits referred by snapshots.\n      // The IndexWriter (used to cleanup index files) creates an additional commit during closing. Hence we expect 2 commits (instead\n      // of 1).\n      {\n        List<IndexCommit> commits = listCommits(metaData.getIndexDirPath());\n        assertEquals(2, commits.size());\n        assertEquals(metaData.getGenerationNumber(), commits.get(0).getGeneration());\n      }\n\n      // Delete first snapshot\n      deleteSnapshot(adminClient, coreName, commitName);\n\n      // Verify that corresponding index files have NOT been deleted (due to reference counting).\n      assertFalse(listCommits(metaData.getIndexDirPath()).isEmpty());\n\n      // Delete second snapshot\n      deleteSnapshot(adminClient, coreName, duplicateCommit.getName());\n\n      // Verify that corresponding index files have been deleted. Ideally this directory should\n      // be removed immediately. But the current DirectoryFactory impl waits until the\n      // closing the core (or the directoryFactory) for actual removal. Since the IndexWriter\n      // (used to cleanup index files) creates an additional commit during closing, we expect a single\n      // commit (instead of 0).\n      assertEquals(1, listCommits(duplicateCommit.getIndexDirPath()).size());\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"3e13696c44d3e2405098726359ab81dab178e7bc":["91e2345fb81b6c1c7faefa550ee5eaafadc54486"],"65a5d87a40f9143cd55be76eb1dde1b32a8dae5e":["3e13696c44d3e2405098726359ab81dab178e7bc"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","3e13696c44d3e2405098726359ab81dab178e7bc"],"3b013574eedcdbac35dc7e35b0ee616ffc38895d":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","91e2345fb81b6c1c7faefa550ee5eaafadc54486"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["65a5d87a40f9143cd55be76eb1dde1b32a8dae5e"],"91e2345fb81b6c1c7faefa550ee5eaafadc54486":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"3e13696c44d3e2405098726359ab81dab178e7bc":["65a5d87a40f9143cd55be76eb1dde1b32a8dae5e","4cce5816ef15a48a0bc11e5d400497ee4301dd3b"],"65a5d87a40f9143cd55be76eb1dde1b32a8dae5e":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b","3b013574eedcdbac35dc7e35b0ee616ffc38895d","91e2345fb81b6c1c7faefa550ee5eaafadc54486"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":[],"3b013574eedcdbac35dc7e35b0ee616ffc38895d":[],"91e2345fb81b6c1c7faefa550ee5eaafadc54486":["3e13696c44d3e2405098726359ab81dab178e7bc","3b013574eedcdbac35dc7e35b0ee616ffc38895d"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b","3b013574eedcdbac35dc7e35b0ee616ffc38895d","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}