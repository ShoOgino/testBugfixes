{"path":"solr/core/src/java/org/apache/solr/cloud/autoscaling/MetricTrigger#run().mjava","commits":[{"id":"35a328e6f64355319d0b316956c260b0be251aca","date":1513957730,"type":0,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/autoscaling/MetricTrigger#run().mjava","pathOld":"/dev/null","sourceNew":"  @Override\n  public void run() {\n    AutoScaling.TriggerEventProcessor processor = processorRef.get();\n    if (processor == null) {\n      return;\n    }\n\n    Set<String> liveNodes = null;\n    if (node.equals(Policy.ANY)) {\n      if (collection.equals(Policy.ANY)) {\n        liveNodes = cloudManager.getClusterStateProvider().getLiveNodes();\n      } else {\n        final Set<String> nodes = new HashSet<>();\n        ClusterState.CollectionRef ref = cloudManager.getClusterStateProvider().getState(collection);\n        DocCollection docCollection;\n        if (ref == null || (docCollection = ref.get()) == null) {\n          log.warn(\"MetricTrigger could not find collection: {}\", collection);\n          return;\n        }\n        if (shard.equals(Policy.ANY)) {\n          docCollection.getReplicas().forEach(replica -> {\n            nodes.add(replica.getNodeName());\n          });\n        } else {\n          Slice slice = docCollection.getSlice(shard);\n          if (slice == null) {\n            log.warn(\"MetricTrigger could not find collection: {} shard: {}\", collection, shard);\n            return;\n          }\n          slice.getReplicas().forEach(replica -> nodes.add(replica.getNodeName()));\n        }\n        liveNodes = nodes;\n      }\n    } else {\n      liveNodes = Collections.singleton(node);\n    }\n\n    Map<String, Number> rates = new HashMap<>(liveNodes.size());\n    for (String node : liveNodes) {\n      Map<String, Object> values = cloudManager.getNodeStateProvider().getNodeValues(node, Collections.singletonList(metric));\n      values.forEach((tag, rate) -> rates.computeIfAbsent(node, s -> (Number) rate));\n    }\n\n    long now = cloudManager.getTimeSource().getTime();\n    // check for exceeded rates and filter out those with less than waitFor from previous events\n    Map<String, Number> hotNodes = rates.entrySet().stream()\n        .filter(entry -> waitForElapsed(entry.getKey(), now, lastNodeEvent))\n        .filter(entry -> (below != null && Double.compare(entry.getValue().doubleValue(), below.doubleValue()) < 0) || (above != null && Double.compare(entry.getValue().doubleValue(), above.doubleValue()) > 0))\n        .collect(Collectors.toMap(Map.Entry::getKey, Map.Entry::getValue));\n\n    if (hotNodes.isEmpty()) return;\n\n    final AtomicLong eventTime = new AtomicLong(now);\n    hotNodes.forEach((n, r) -> {\n      long time = lastNodeEvent.get(n);\n      if (eventTime.get() > time) {\n        eventTime.set(time);\n      }\n    });\n\n    if (processor.process(new MetricBreachedEvent(getName(), collection, shard, preferredOp, eventTime.get(), metric, hotNodes))) {\n      hotNodes.keySet().forEach(node -> lastNodeEvent.put(node, now));\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d4412883c12067d8a4e2a354aa8adc58c32be1d6","date":1521129281,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/autoscaling/MetricTrigger#run().mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/autoscaling/MetricTrigger#run().mjava","sourceNew":"  @Override\n  public void run() {\n    AutoScaling.TriggerEventProcessor processor = processorRef.get();\n    if (processor == null) {\n      return;\n    }\n\n    Set<String> liveNodes = null;\n    if (node.equals(Policy.ANY)) {\n      if (collection.equals(Policy.ANY)) {\n        liveNodes = cloudManager.getClusterStateProvider().getLiveNodes();\n      } else {\n        final Set<String> nodes = new HashSet<>();\n        ClusterState.CollectionRef ref = cloudManager.getClusterStateProvider().getState(collection);\n        DocCollection docCollection;\n        if (ref == null || (docCollection = ref.get()) == null) {\n          log.warn(\"MetricTrigger could not find collection: {}\", collection);\n          return;\n        }\n        if (shard.equals(Policy.ANY)) {\n          docCollection.getReplicas().forEach(replica -> {\n            nodes.add(replica.getNodeName());\n          });\n        } else {\n          Slice slice = docCollection.getSlice(shard);\n          if (slice == null) {\n            log.warn(\"MetricTrigger could not find collection: {} shard: {}\", collection, shard);\n            return;\n          }\n          slice.getReplicas().forEach(replica -> nodes.add(replica.getNodeName()));\n        }\n        liveNodes = nodes;\n      }\n    } else {\n      liveNodes = Collections.singleton(node);\n    }\n\n    Map<String, Number> rates = new HashMap<>(liveNodes.size());\n    for (String node : liveNodes) {\n      Map<String, Object> values = cloudManager.getNodeStateProvider().getNodeValues(node, Collections.singletonList(metric));\n      values.forEach((tag, rate) -> rates.computeIfAbsent(node, s -> (Number) rate));\n    }\n\n    long now = cloudManager.getTimeSource().getTimeNs();\n    // check for exceeded rates and filter out those with less than waitFor from previous events\n    Map<String, Number> hotNodes = rates.entrySet().stream()\n        .filter(entry -> waitForElapsed(entry.getKey(), now, lastNodeEvent))\n        .filter(entry -> (below != null && Double.compare(entry.getValue().doubleValue(), below.doubleValue()) < 0) || (above != null && Double.compare(entry.getValue().doubleValue(), above.doubleValue()) > 0))\n        .collect(Collectors.toMap(Map.Entry::getKey, Map.Entry::getValue));\n\n    if (hotNodes.isEmpty()) return;\n\n    final AtomicLong eventTime = new AtomicLong(now);\n    hotNodes.forEach((n, r) -> {\n      long time = lastNodeEvent.get(n);\n      if (eventTime.get() > time) {\n        eventTime.set(time);\n      }\n    });\n\n    if (processor.process(new MetricBreachedEvent(getName(), collection, shard, preferredOp, eventTime.get(), metric, hotNodes))) {\n      hotNodes.keySet().forEach(node -> lastNodeEvent.put(node, now));\n    }\n  }\n\n","sourceOld":"  @Override\n  public void run() {\n    AutoScaling.TriggerEventProcessor processor = processorRef.get();\n    if (processor == null) {\n      return;\n    }\n\n    Set<String> liveNodes = null;\n    if (node.equals(Policy.ANY)) {\n      if (collection.equals(Policy.ANY)) {\n        liveNodes = cloudManager.getClusterStateProvider().getLiveNodes();\n      } else {\n        final Set<String> nodes = new HashSet<>();\n        ClusterState.CollectionRef ref = cloudManager.getClusterStateProvider().getState(collection);\n        DocCollection docCollection;\n        if (ref == null || (docCollection = ref.get()) == null) {\n          log.warn(\"MetricTrigger could not find collection: {}\", collection);\n          return;\n        }\n        if (shard.equals(Policy.ANY)) {\n          docCollection.getReplicas().forEach(replica -> {\n            nodes.add(replica.getNodeName());\n          });\n        } else {\n          Slice slice = docCollection.getSlice(shard);\n          if (slice == null) {\n            log.warn(\"MetricTrigger could not find collection: {} shard: {}\", collection, shard);\n            return;\n          }\n          slice.getReplicas().forEach(replica -> nodes.add(replica.getNodeName()));\n        }\n        liveNodes = nodes;\n      }\n    } else {\n      liveNodes = Collections.singleton(node);\n    }\n\n    Map<String, Number> rates = new HashMap<>(liveNodes.size());\n    for (String node : liveNodes) {\n      Map<String, Object> values = cloudManager.getNodeStateProvider().getNodeValues(node, Collections.singletonList(metric));\n      values.forEach((tag, rate) -> rates.computeIfAbsent(node, s -> (Number) rate));\n    }\n\n    long now = cloudManager.getTimeSource().getTime();\n    // check for exceeded rates and filter out those with less than waitFor from previous events\n    Map<String, Number> hotNodes = rates.entrySet().stream()\n        .filter(entry -> waitForElapsed(entry.getKey(), now, lastNodeEvent))\n        .filter(entry -> (below != null && Double.compare(entry.getValue().doubleValue(), below.doubleValue()) < 0) || (above != null && Double.compare(entry.getValue().doubleValue(), above.doubleValue()) > 0))\n        .collect(Collectors.toMap(Map.Entry::getKey, Map.Entry::getValue));\n\n    if (hotNodes.isEmpty()) return;\n\n    final AtomicLong eventTime = new AtomicLong(now);\n    hotNodes.forEach((n, r) -> {\n      long time = lastNodeEvent.get(n);\n      if (eventTime.get() > time) {\n        eventTime.set(time);\n      }\n    });\n\n    if (processor.process(new MetricBreachedEvent(getName(), collection, shard, preferredOp, eventTime.get(), metric, hotNodes))) {\n      hotNodes.keySet().forEach(node -> lastNodeEvent.put(node, now));\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3f504512a03d978990cbff30db0522b354e846db","date":1595247421,"type":4,"author":"Ishan Chattopadhyaya","isMerge":false,"pathNew":"/dev/null","pathOld":"solr/core/src/java/org/apache/solr/cloud/autoscaling/MetricTrigger#run().mjava","sourceNew":null,"sourceOld":"  @Override\n  public void run() {\n    AutoScaling.TriggerEventProcessor processor = processorRef.get();\n    if (processor == null) {\n      return;\n    }\n\n    Set<String> liveNodes = null;\n    if (node.equals(Policy.ANY)) {\n      if (collection.equals(Policy.ANY)) {\n        liveNodes = cloudManager.getClusterStateProvider().getLiveNodes();\n      } else {\n        final Set<String> nodes = new HashSet<>();\n        ClusterState.CollectionRef ref = cloudManager.getClusterStateProvider().getState(collection);\n        DocCollection docCollection;\n        if (ref == null || (docCollection = ref.get()) == null) {\n          log.warn(\"MetricTrigger could not find collection: {}\", collection);\n          return;\n        }\n        if (shard.equals(Policy.ANY)) {\n          docCollection.getReplicas().forEach(replica -> {\n            nodes.add(replica.getNodeName());\n          });\n        } else {\n          Slice slice = docCollection.getSlice(shard);\n          if (slice == null) {\n            log.warn(\"MetricTrigger could not find collection: {} shard: {}\", collection, shard);\n            return;\n          }\n          slice.getReplicas().forEach(replica -> nodes.add(replica.getNodeName()));\n        }\n        liveNodes = nodes;\n      }\n    } else {\n      liveNodes = Collections.singleton(node);\n    }\n\n    Map<String, Number> rates = new HashMap<>(liveNodes.size());\n    for (String node : liveNodes) {\n      Map<String, Object> values = cloudManager.getNodeStateProvider().getNodeValues(node, Collections.singletonList(metric));\n      values.forEach((tag, rate) -> rates.computeIfAbsent(node, s -> (Number) rate));\n    }\n\n    long now = cloudManager.getTimeSource().getTimeNs();\n    // check for exceeded rates and filter out those with less than waitFor from previous events\n    Map<String, Number> hotNodes = rates.entrySet().stream()\n        .filter(entry -> waitForElapsed(entry.getKey(), now, lastNodeEvent))\n        .filter(entry -> (below != null && Double.compare(entry.getValue().doubleValue(), below.doubleValue()) < 0) || (above != null && Double.compare(entry.getValue().doubleValue(), above.doubleValue()) > 0))\n        .collect(Collectors.toMap(Map.Entry::getKey, Map.Entry::getValue));\n\n    if (hotNodes.isEmpty()) return;\n\n    final AtomicLong eventTime = new AtomicLong(now);\n    hotNodes.forEach((n, r) -> {\n      long time = lastNodeEvent.get(n);\n      if (eventTime.get() > time) {\n        eventTime.set(time);\n      }\n    });\n\n    if (processor.process(new MetricBreachedEvent(getName(), collection, shard, preferredOp, eventTime.get(), metric, hotNodes))) {\n      hotNodes.keySet().forEach(node -> lastNodeEvent.put(node, now));\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"3f504512a03d978990cbff30db0522b354e846db":["d4412883c12067d8a4e2a354aa8adc58c32be1d6"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"d4412883c12067d8a4e2a354aa8adc58c32be1d6":["35a328e6f64355319d0b316956c260b0be251aca"],"35a328e6f64355319d0b316956c260b0be251aca":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["3f504512a03d978990cbff30db0522b354e846db"]},"commit2Childs":{"3f504512a03d978990cbff30db0522b354e846db":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["35a328e6f64355319d0b316956c260b0be251aca"],"d4412883c12067d8a4e2a354aa8adc58c32be1d6":["3f504512a03d978990cbff30db0522b354e846db"],"35a328e6f64355319d0b316956c260b0be251aca":["d4412883c12067d8a4e2a354aa8adc58c32be1d6"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}