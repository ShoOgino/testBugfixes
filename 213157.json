{"path":"lucene/highlighter/src/java/org/apache/lucene/search/postingshighlight/MultiTermHighlighting#getDocsEnum(TokenStream,CharacterRunAutomaton[]).mjava","commits":[{"id":"dd81b1d062b9688a18721a1adfc489577479856a","date":1390711758,"type":0,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/highlighter/src/java/org/apache/lucene/search/postingshighlight/MultiTermHighlighting#getDocsEnum(TokenStream,CharacterRunAutomaton[]).mjava","pathOld":"/dev/null","sourceNew":"  /** \n   * Returns a \"fake\" DocsAndPositionsEnum over the tokenstream, returning offsets where {@code matchers}\n   * matches tokens.\n   * <p>\n   * This is solely used internally by PostingsHighlighter: <b>DO NOT USE THIS METHOD!</b>\n   */\n  static DocsAndPositionsEnum getDocsEnum(final TokenStream ts, final CharacterRunAutomaton[] matchers) throws IOException {\n    final CharTermAttribute charTermAtt = ts.addAttribute(CharTermAttribute.class);\n    final OffsetAttribute offsetAtt = ts.addAttribute(OffsetAttribute.class);\n    ts.reset();\n    \n    // TODO: we could use CachingWrapperFilter, (or consume twice) to allow us to have a true freq()\n    // but this would have a performance cost for likely little gain in the user experience, it\n    // would only serve to make this method less bogus.\n    // instead, we always return freq() = Integer.MAX_VALUE and let PH terminate based on offset...\n    \n    return new DocsAndPositionsEnum() {\n      int currentDoc = -1;\n      int currentMatch = -1;\n      int currentStartOffset = -1;\n      int currentEndOffset = -1;\n      TokenStream stream = ts;\n      \n      final BytesRef matchDescriptions[] = new BytesRef[matchers.length];\n      \n      @Override\n      public int nextPosition() throws IOException {\n        if (stream != null) {\n          while (stream.incrementToken()) {\n            for (int i = 0; i < matchers.length; i++) {\n              if (matchers[i].run(charTermAtt.buffer(), 0, charTermAtt.length())) {\n                currentStartOffset = offsetAtt.startOffset();\n                currentEndOffset = offsetAtt.endOffset();\n                currentMatch = i;\n                return 0;\n              }\n            }\n          }\n          stream.end();\n          stream.close();\n          stream = null;\n        }\n        // exhausted\n        currentStartOffset = currentEndOffset = Integer.MAX_VALUE;\n        return Integer.MAX_VALUE;\n      }\n      \n      @Override\n      public int freq() throws IOException {\n        return Integer.MAX_VALUE; // lie\n      }\n\n      @Override\n      public int startOffset() throws IOException {\n        assert currentStartOffset >= 0;\n        return currentStartOffset;\n      }\n\n      @Override\n      public int endOffset() throws IOException {\n        assert currentEndOffset >= 0;\n        return currentEndOffset;\n      }\n\n      @Override\n      public BytesRef getPayload() throws IOException {\n        if (matchDescriptions[currentMatch] == null) {\n          matchDescriptions[currentMatch] = new BytesRef(matchers[currentMatch].toString());\n        }\n        return matchDescriptions[currentMatch];\n      }\n\n      @Override\n      public int docID() {\n        return currentDoc;\n      }\n\n      @Override\n      public int nextDoc() throws IOException {\n        throw new UnsupportedOperationException();\n      }\n\n      @Override\n      public int advance(int target) throws IOException {\n        return currentDoc = target;\n      }\n\n      @Override\n      public long cost() {\n        return 0;\n      }\n    };\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"51f5280f31484820499077f41fcdfe92d527d9dc","date":1423229122,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"lucene/highlighter/src/java/org/apache/lucene/search/postingshighlight/MultiTermHighlighting#getDocsEnum(TokenStream,CharacterRunAutomaton[]).mjava","pathOld":"lucene/highlighter/src/java/org/apache/lucene/search/postingshighlight/MultiTermHighlighting#getDocsEnum(TokenStream,CharacterRunAutomaton[]).mjava","sourceNew":"  /** \n   * Returns a \"fake\" DocsAndPositionsEnum over the tokenstream, returning offsets where {@code matchers}\n   * matches tokens.\n   * <p>\n   * This is solely used internally by PostingsHighlighter: <b>DO NOT USE THIS METHOD!</b>\n   */\n  static PostingsEnum getDocsEnum(final TokenStream ts, final CharacterRunAutomaton[] matchers) throws IOException {\n    final CharTermAttribute charTermAtt = ts.addAttribute(CharTermAttribute.class);\n    final OffsetAttribute offsetAtt = ts.addAttribute(OffsetAttribute.class);\n    ts.reset();\n    \n    // TODO: we could use CachingWrapperFilter, (or consume twice) to allow us to have a true freq()\n    // but this would have a performance cost for likely little gain in the user experience, it\n    // would only serve to make this method less bogus.\n    // instead, we always return freq() = Integer.MAX_VALUE and let PH terminate based on offset...\n    \n    return new PostingsEnum() {\n      int currentDoc = -1;\n      int currentMatch = -1;\n      int currentStartOffset = -1;\n      int currentEndOffset = -1;\n      TokenStream stream = ts;\n      \n      final BytesRef matchDescriptions[] = new BytesRef[matchers.length];\n      \n      @Override\n      public int nextPosition() throws IOException {\n        if (stream != null) {\n          while (stream.incrementToken()) {\n            for (int i = 0; i < matchers.length; i++) {\n              if (matchers[i].run(charTermAtt.buffer(), 0, charTermAtt.length())) {\n                currentStartOffset = offsetAtt.startOffset();\n                currentEndOffset = offsetAtt.endOffset();\n                currentMatch = i;\n                return 0;\n              }\n            }\n          }\n          stream.end();\n          stream.close();\n          stream = null;\n        }\n        // exhausted\n        currentStartOffset = currentEndOffset = Integer.MAX_VALUE;\n        return Integer.MAX_VALUE;\n      }\n\n      @Override\n      public int freq() throws IOException {\n        return Integer.MAX_VALUE; // lie\n      }\n\n      @Override\n      public int startOffset() throws IOException {\n        assert currentStartOffset >= 0;\n        return currentStartOffset;\n      }\n\n      @Override\n      public int endOffset() throws IOException {\n        assert currentEndOffset >= 0;\n        return currentEndOffset;\n      }\n\n      @Override\n      public BytesRef getPayload() throws IOException {\n        if (matchDescriptions[currentMatch] == null) {\n          matchDescriptions[currentMatch] = new BytesRef(matchers[currentMatch].toString());\n        }\n        return matchDescriptions[currentMatch];\n      }\n\n      @Override\n      public int docID() {\n        return currentDoc;\n      }\n\n      @Override\n      public int nextDoc() throws IOException {\n        throw new UnsupportedOperationException();\n      }\n\n      @Override\n      public int advance(int target) throws IOException {\n        return currentDoc = target;\n      }\n\n      @Override\n      public long cost() {\n        return 0;\n      }\n    };\n  }\n\n","sourceOld":"  /** \n   * Returns a \"fake\" DocsAndPositionsEnum over the tokenstream, returning offsets where {@code matchers}\n   * matches tokens.\n   * <p>\n   * This is solely used internally by PostingsHighlighter: <b>DO NOT USE THIS METHOD!</b>\n   */\n  static DocsAndPositionsEnum getDocsEnum(final TokenStream ts, final CharacterRunAutomaton[] matchers) throws IOException {\n    final CharTermAttribute charTermAtt = ts.addAttribute(CharTermAttribute.class);\n    final OffsetAttribute offsetAtt = ts.addAttribute(OffsetAttribute.class);\n    ts.reset();\n    \n    // TODO: we could use CachingWrapperFilter, (or consume twice) to allow us to have a true freq()\n    // but this would have a performance cost for likely little gain in the user experience, it\n    // would only serve to make this method less bogus.\n    // instead, we always return freq() = Integer.MAX_VALUE and let PH terminate based on offset...\n    \n    return new DocsAndPositionsEnum() {\n      int currentDoc = -1;\n      int currentMatch = -1;\n      int currentStartOffset = -1;\n      int currentEndOffset = -1;\n      TokenStream stream = ts;\n      \n      final BytesRef matchDescriptions[] = new BytesRef[matchers.length];\n      \n      @Override\n      public int nextPosition() throws IOException {\n        if (stream != null) {\n          while (stream.incrementToken()) {\n            for (int i = 0; i < matchers.length; i++) {\n              if (matchers[i].run(charTermAtt.buffer(), 0, charTermAtt.length())) {\n                currentStartOffset = offsetAtt.startOffset();\n                currentEndOffset = offsetAtt.endOffset();\n                currentMatch = i;\n                return 0;\n              }\n            }\n          }\n          stream.end();\n          stream.close();\n          stream = null;\n        }\n        // exhausted\n        currentStartOffset = currentEndOffset = Integer.MAX_VALUE;\n        return Integer.MAX_VALUE;\n      }\n      \n      @Override\n      public int freq() throws IOException {\n        return Integer.MAX_VALUE; // lie\n      }\n\n      @Override\n      public int startOffset() throws IOException {\n        assert currentStartOffset >= 0;\n        return currentStartOffset;\n      }\n\n      @Override\n      public int endOffset() throws IOException {\n        assert currentEndOffset >= 0;\n        return currentEndOffset;\n      }\n\n      @Override\n      public BytesRef getPayload() throws IOException {\n        if (matchDescriptions[currentMatch] == null) {\n          matchDescriptions[currentMatch] = new BytesRef(matchers[currentMatch].toString());\n        }\n        return matchDescriptions[currentMatch];\n      }\n\n      @Override\n      public int docID() {\n        return currentDoc;\n      }\n\n      @Override\n      public int nextDoc() throws IOException {\n        throw new UnsupportedOperationException();\n      }\n\n      @Override\n      public int advance(int target) throws IOException {\n        return currentDoc = target;\n      }\n\n      @Override\n      public long cost() {\n        return 0;\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"381618eac2691bb34ab9a3fca76ad55c6274517e","date":1495564791,"type":4,"author":"David Smiley","isMerge":false,"pathNew":"/dev/null","pathOld":"lucene/highlighter/src/java/org/apache/lucene/search/postingshighlight/MultiTermHighlighting#getDocsEnum(TokenStream,CharacterRunAutomaton[]).mjava","sourceNew":null,"sourceOld":"  /** \n   * Returns a \"fake\" DocsAndPositionsEnum over the tokenstream, returning offsets where {@code matchers}\n   * matches tokens.\n   * <p>\n   * This is solely used internally by PostingsHighlighter: <b>DO NOT USE THIS METHOD!</b>\n   */\n  static PostingsEnum getDocsEnum(final TokenStream ts, final CharacterRunAutomaton[] matchers) throws IOException {\n    final CharTermAttribute charTermAtt = ts.addAttribute(CharTermAttribute.class);\n    final OffsetAttribute offsetAtt = ts.addAttribute(OffsetAttribute.class);\n    ts.reset();\n    \n    // TODO: we could use CachingWrapperFilter, (or consume twice) to allow us to have a true freq()\n    // but this would have a performance cost for likely little gain in the user experience, it\n    // would only serve to make this method less bogus.\n    // instead, we always return freq() = Integer.MAX_VALUE and let PH terminate based on offset...\n    \n    return new PostingsEnum() {\n      int currentDoc = -1;\n      int currentMatch = -1;\n      int currentStartOffset = -1;\n      int currentEndOffset = -1;\n      TokenStream stream = ts;\n      \n      final BytesRef matchDescriptions[] = new BytesRef[matchers.length];\n      \n      @Override\n      public int nextPosition() throws IOException {\n        if (stream != null) {\n          while (stream.incrementToken()) {\n            for (int i = 0; i < matchers.length; i++) {\n              if (matchers[i].run(charTermAtt.buffer(), 0, charTermAtt.length())) {\n                currentStartOffset = offsetAtt.startOffset();\n                currentEndOffset = offsetAtt.endOffset();\n                currentMatch = i;\n                return 0;\n              }\n            }\n          }\n          stream.end();\n          stream.close();\n          stream = null;\n        }\n        // exhausted\n        currentStartOffset = currentEndOffset = Integer.MAX_VALUE;\n        return Integer.MAX_VALUE;\n      }\n\n      @Override\n      public int freq() throws IOException {\n        return Integer.MAX_VALUE; // lie\n      }\n\n      @Override\n      public int startOffset() throws IOException {\n        assert currentStartOffset >= 0;\n        return currentStartOffset;\n      }\n\n      @Override\n      public int endOffset() throws IOException {\n        assert currentEndOffset >= 0;\n        return currentEndOffset;\n      }\n\n      @Override\n      public BytesRef getPayload() throws IOException {\n        if (matchDescriptions[currentMatch] == null) {\n          matchDescriptions[currentMatch] = new BytesRef(matchers[currentMatch].toString());\n        }\n        return matchDescriptions[currentMatch];\n      }\n\n      @Override\n      public int docID() {\n        return currentDoc;\n      }\n\n      @Override\n      public int nextDoc() throws IOException {\n        throw new UnsupportedOperationException();\n      }\n\n      @Override\n      public int advance(int target) throws IOException {\n        return currentDoc = target;\n      }\n\n      @Override\n      public long cost() {\n        return 0;\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e9017cf144952056066919f1ebc7897ff9bd71b1","date":1496757600,"type":4,"author":"Shalin Shekhar Mangar","isMerge":true,"pathNew":"/dev/null","pathOld":"lucene/highlighter/src/java/org/apache/lucene/search/postingshighlight/MultiTermHighlighting#getDocsEnum(TokenStream,CharacterRunAutomaton[]).mjava","sourceNew":null,"sourceOld":"  /** \n   * Returns a \"fake\" DocsAndPositionsEnum over the tokenstream, returning offsets where {@code matchers}\n   * matches tokens.\n   * <p>\n   * This is solely used internally by PostingsHighlighter: <b>DO NOT USE THIS METHOD!</b>\n   */\n  static PostingsEnum getDocsEnum(final TokenStream ts, final CharacterRunAutomaton[] matchers) throws IOException {\n    final CharTermAttribute charTermAtt = ts.addAttribute(CharTermAttribute.class);\n    final OffsetAttribute offsetAtt = ts.addAttribute(OffsetAttribute.class);\n    ts.reset();\n    \n    // TODO: we could use CachingWrapperFilter, (or consume twice) to allow us to have a true freq()\n    // but this would have a performance cost for likely little gain in the user experience, it\n    // would only serve to make this method less bogus.\n    // instead, we always return freq() = Integer.MAX_VALUE and let PH terminate based on offset...\n    \n    return new PostingsEnum() {\n      int currentDoc = -1;\n      int currentMatch = -1;\n      int currentStartOffset = -1;\n      int currentEndOffset = -1;\n      TokenStream stream = ts;\n      \n      final BytesRef matchDescriptions[] = new BytesRef[matchers.length];\n      \n      @Override\n      public int nextPosition() throws IOException {\n        if (stream != null) {\n          while (stream.incrementToken()) {\n            for (int i = 0; i < matchers.length; i++) {\n              if (matchers[i].run(charTermAtt.buffer(), 0, charTermAtt.length())) {\n                currentStartOffset = offsetAtt.startOffset();\n                currentEndOffset = offsetAtt.endOffset();\n                currentMatch = i;\n                return 0;\n              }\n            }\n          }\n          stream.end();\n          stream.close();\n          stream = null;\n        }\n        // exhausted\n        currentStartOffset = currentEndOffset = Integer.MAX_VALUE;\n        return Integer.MAX_VALUE;\n      }\n\n      @Override\n      public int freq() throws IOException {\n        return Integer.MAX_VALUE; // lie\n      }\n\n      @Override\n      public int startOffset() throws IOException {\n        assert currentStartOffset >= 0;\n        return currentStartOffset;\n      }\n\n      @Override\n      public int endOffset() throws IOException {\n        assert currentEndOffset >= 0;\n        return currentEndOffset;\n      }\n\n      @Override\n      public BytesRef getPayload() throws IOException {\n        if (matchDescriptions[currentMatch] == null) {\n          matchDescriptions[currentMatch] = new BytesRef(matchers[currentMatch].toString());\n        }\n        return matchDescriptions[currentMatch];\n      }\n\n      @Override\n      public int docID() {\n        return currentDoc;\n      }\n\n      @Override\n      public int nextDoc() throws IOException {\n        throw new UnsupportedOperationException();\n      }\n\n      @Override\n      public int advance(int target) throws IOException {\n        return currentDoc = target;\n      }\n\n      @Override\n      public long cost() {\n        return 0;\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"381618eac2691bb34ab9a3fca76ad55c6274517e":["51f5280f31484820499077f41fcdfe92d527d9dc"],"e9017cf144952056066919f1ebc7897ff9bd71b1":["51f5280f31484820499077f41fcdfe92d527d9dc","381618eac2691bb34ab9a3fca76ad55c6274517e"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"51f5280f31484820499077f41fcdfe92d527d9dc":["dd81b1d062b9688a18721a1adfc489577479856a"],"dd81b1d062b9688a18721a1adfc489577479856a":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["381618eac2691bb34ab9a3fca76ad55c6274517e"]},"commit2Childs":{"381618eac2691bb34ab9a3fca76ad55c6274517e":["e9017cf144952056066919f1ebc7897ff9bd71b1","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"e9017cf144952056066919f1ebc7897ff9bd71b1":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["dd81b1d062b9688a18721a1adfc489577479856a"],"51f5280f31484820499077f41fcdfe92d527d9dc":["381618eac2691bb34ab9a3fca76ad55c6274517e","e9017cf144952056066919f1ebc7897ff9bd71b1"],"dd81b1d062b9688a18721a1adfc489577479856a":["51f5280f31484820499077f41fcdfe92d527d9dc"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["e9017cf144952056066919f1ebc7897ff9bd71b1","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}