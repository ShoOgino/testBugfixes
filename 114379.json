{"path":"src/java/org/apache/solr/handler/component/FacetComponent#distributedProcess(ResponseBuilder).mjava","commits":[{"id":"5bb29c260c4bbaf4ce8a95d362844ebf77ec1f76","date":1204055227,"type":0,"author":"Yonik Seeley","isMerge":false,"pathNew":"src/java/org/apache/solr/handler/component/FacetComponent#distributedProcess(ResponseBuilder).mjava","pathOld":"/dev/null","sourceNew":"  @Override\n  public int distributedProcess(ResponseBuilder rb) throws IOException {\n    if (!rb.doFacets) {\n      return ResponseBuilder.STAGE_DONE;\n    }\n\n    if (rb.stage == ResponseBuilder.STAGE_GET_FIELDS) {\n      // overlap facet refinement requests (those shards that we need a count for\n      // particular facet values from), where possible, with\n      // the requests to get fields (because we know that is the\n      // only other required phase).\n      // We do this in distributedProcess so we can look at all of the\n      // requests in the outgoing queue at once.\n\n      for (int shardNum=0; shardNum<rb.shards.length; shardNum++) {\n        List<String> fqueries = rb._facetInfo._toRefine[shardNum];\n        if (fqueries == null || fqueries.size()==0) continue;\n\n        String shard = rb.shards[shardNum];\n\n        ShardRequest refine = null;\n        boolean newRequest = false;\n\n        // try to find a request that is already going out to that shard.\n        // If nshards becomes to great, we way want to move to hashing for better\n        // scalability.\n        for (ShardRequest sreq : rb.outgoing) {\n          if ((sreq.purpose & ShardRequest.PURPOSE_GET_FIELDS)!=0\n                  && sreq.shards != null & sreq.shards.length==1\n                  && sreq.shards[0].equals(shard))\n          {\n            refine = sreq;\n            break;\n          }\n        }\n\n        if (refine == null) {\n          // we didn't find any other suitable requests going out to that shard, so\n          // create one ourselves.\n          newRequest = true;\n          refine = new ShardRequest();\n          refine.shards = new String[]{rb.shards[shardNum]};\n          refine.params = new ModifiableSolrParams(rb.req.getParams());\n          // don't request any documents\n          refine.params.remove(\"start\");\n          refine.params.set(\"rows\",\"0\");\n        }\n\n        refine.purpose |= ShardRequest.PURPOSE_REFINE_FACETS;\n        refine.params.set(FacetParams.FACET,\"true\");\n        refine.params.remove(FacetParams.FACET_FIELD);\n        // TODO: perhaps create a more compact facet.terms method?\n        refine.params.set(FacetParams.FACET_QUERY, fqueries.toArray(new String[fqueries.size()]));\n\n        if (newRequest) {\n          rb.addRequest(this, refine);\n        }\n      }\n    }\n\n    return ResponseBuilder.STAGE_DONE;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["8ad363a5abc5bb509031f433f753c91d372e21ea"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"a6c6e4e06160d2ad231072e8743988a623ab14c9","date":1213500516,"type":3,"author":"Otis Gospodnetic","isMerge":false,"pathNew":"src/java/org/apache/solr/handler/component/FacetComponent#distributedProcess(ResponseBuilder).mjava","pathOld":"src/java/org/apache/solr/handler/component/FacetComponent#distributedProcess(ResponseBuilder).mjava","sourceNew":"  @Override\n  public int distributedProcess(ResponseBuilder rb) throws IOException {\n    if (!rb.doFacets) {\n      return ResponseBuilder.STAGE_DONE;\n    }\n\n    if (rb.stage == ResponseBuilder.STAGE_GET_FIELDS) {\n      // overlap facet refinement requests (those shards that we need a count for\n      // particular facet values from), where possible, with\n      // the requests to get fields (because we know that is the\n      // only other required phase).\n      // We do this in distributedProcess so we can look at all of the\n      // requests in the outgoing queue at once.\n\n      for (int shardNum=0; shardNum<rb.shards.length; shardNum++) {\n        List<String> fqueries = rb._facetInfo._toRefine[shardNum];\n        if (fqueries == null || fqueries.size()==0) continue;\n\n        String shard = rb.shards[shardNum];\n\n        ShardRequest refine = null;\n        boolean newRequest = false;\n\n        // try to find a request that is already going out to that shard.\n        // If nshards becomes to great, we way want to move to hashing for better\n        // scalability.\n        for (ShardRequest sreq : rb.outgoing) {\n          if ((sreq.purpose & ShardRequest.PURPOSE_GET_FIELDS)!=0\n                  && sreq.shards != null & sreq.shards.length==1\n                  && sreq.shards[0].equals(shard))\n          {\n            refine = sreq;\n            break;\n          }\n        }\n\n        if (refine == null) {\n          // we didn't find any other suitable requests going out to that shard, so\n          // create one ourselves.\n          newRequest = true;\n          refine = new ShardRequest();\n          refine.shards = new String[]{rb.shards[shardNum]};\n          refine.params = new ModifiableSolrParams(rb.req.getParams());\n          // don't request any documents\n          refine.params.remove(CommonParams.START);\n          refine.params.set(CommonParams.ROWS,\"0\");\n        }\n\n        refine.purpose |= ShardRequest.PURPOSE_REFINE_FACETS;\n        refine.params.set(FacetParams.FACET,\"true\");\n        refine.params.remove(FacetParams.FACET_FIELD);\n        // TODO: perhaps create a more compact facet.terms method?\n        refine.params.set(FacetParams.FACET_QUERY, fqueries.toArray(new String[fqueries.size()]));\n\n        if (newRequest) {\n          rb.addRequest(this, refine);\n        }\n      }\n    }\n\n    return ResponseBuilder.STAGE_DONE;\n  }\n\n","sourceOld":"  @Override\n  public int distributedProcess(ResponseBuilder rb) throws IOException {\n    if (!rb.doFacets) {\n      return ResponseBuilder.STAGE_DONE;\n    }\n\n    if (rb.stage == ResponseBuilder.STAGE_GET_FIELDS) {\n      // overlap facet refinement requests (those shards that we need a count for\n      // particular facet values from), where possible, with\n      // the requests to get fields (because we know that is the\n      // only other required phase).\n      // We do this in distributedProcess so we can look at all of the\n      // requests in the outgoing queue at once.\n\n      for (int shardNum=0; shardNum<rb.shards.length; shardNum++) {\n        List<String> fqueries = rb._facetInfo._toRefine[shardNum];\n        if (fqueries == null || fqueries.size()==0) continue;\n\n        String shard = rb.shards[shardNum];\n\n        ShardRequest refine = null;\n        boolean newRequest = false;\n\n        // try to find a request that is already going out to that shard.\n        // If nshards becomes to great, we way want to move to hashing for better\n        // scalability.\n        for (ShardRequest sreq : rb.outgoing) {\n          if ((sreq.purpose & ShardRequest.PURPOSE_GET_FIELDS)!=0\n                  && sreq.shards != null & sreq.shards.length==1\n                  && sreq.shards[0].equals(shard))\n          {\n            refine = sreq;\n            break;\n          }\n        }\n\n        if (refine == null) {\n          // we didn't find any other suitable requests going out to that shard, so\n          // create one ourselves.\n          newRequest = true;\n          refine = new ShardRequest();\n          refine.shards = new String[]{rb.shards[shardNum]};\n          refine.params = new ModifiableSolrParams(rb.req.getParams());\n          // don't request any documents\n          refine.params.remove(\"start\");\n          refine.params.set(\"rows\",\"0\");\n        }\n\n        refine.purpose |= ShardRequest.PURPOSE_REFINE_FACETS;\n        refine.params.set(FacetParams.FACET,\"true\");\n        refine.params.remove(FacetParams.FACET_FIELD);\n        // TODO: perhaps create a more compact facet.terms method?\n        refine.params.set(FacetParams.FACET_QUERY, fqueries.toArray(new String[fqueries.size()]));\n\n        if (newRequest) {\n          rb.addRequest(this, refine);\n        }\n      }\n    }\n\n    return ResponseBuilder.STAGE_DONE;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"8ad363a5abc5bb509031f433f753c91d372e21ea","date":1223336152,"type":3,"author":"Ryan McKinley","isMerge":false,"pathNew":"src/java/org/apache/solr/handler/component/FacetComponent#distributedProcess(ResponseBuilder).mjava","pathOld":"src/java/org/apache/solr/handler/component/FacetComponent#distributedProcess(ResponseBuilder).mjava","sourceNew":"  @Override\n  public int distributedProcess(ResponseBuilder rb) throws IOException {\n    if (!rb.doFacets) {\n      return ResponseBuilder.STAGE_DONE;\n    }\n\n    if (rb.stage == ResponseBuilder.STAGE_GET_FIELDS) {\n      // overlap facet refinement requests (those shards that we need a count for\n      // particular facet values from), where possible, with\n      // the requests to get fields (because we know that is the\n      // only other required phase).\n      // We do this in distributedProcess so we can look at all of the\n      // requests in the outgoing queue at once.\n\n      for (int shardNum=0; shardNum<rb.shards.length; shardNum++) {\n        List<String> fqueries = rb._facetInfo._toRefine[shardNum];\n        if (fqueries == null || fqueries.size()==0) continue;\n\n        String shard = rb.shards[shardNum];\n\n        ShardRequest refine = null;\n        boolean newRequest = false;\n\n        // try to find a request that is already going out to that shard.\n        // If nshards becomes to great, we way want to move to hashing for better\n        // scalability.\n        for (ShardRequest sreq : rb.outgoing) {\n          if ((sreq.purpose & ShardRequest.PURPOSE_GET_FIELDS)!=0\n                  && sreq.shards != null \n                  && sreq.shards.length==1\n                  && sreq.shards[0].equals(shard))\n          {\n            refine = sreq;\n            break;\n          }\n        }\n\n        if (refine == null) {\n          // we didn't find any other suitable requests going out to that shard, so\n          // create one ourselves.\n          newRequest = true;\n          refine = new ShardRequest();\n          refine.shards = new String[]{rb.shards[shardNum]};\n          refine.params = new ModifiableSolrParams(rb.req.getParams());\n          // don't request any documents\n          refine.params.remove(CommonParams.START);\n          refine.params.set(CommonParams.ROWS,\"0\");\n        }\n\n        refine.purpose |= ShardRequest.PURPOSE_REFINE_FACETS;\n        refine.params.set(FacetParams.FACET,\"true\");\n        refine.params.remove(FacetParams.FACET_FIELD);\n        // TODO: perhaps create a more compact facet.terms method?\n        refine.params.set(FacetParams.FACET_QUERY, fqueries.toArray(new String[fqueries.size()]));\n\n        if (newRequest) {\n          rb.addRequest(this, refine);\n        }\n      }\n    }\n\n    return ResponseBuilder.STAGE_DONE;\n  }\n\n","sourceOld":"  @Override\n  public int distributedProcess(ResponseBuilder rb) throws IOException {\n    if (!rb.doFacets) {\n      return ResponseBuilder.STAGE_DONE;\n    }\n\n    if (rb.stage == ResponseBuilder.STAGE_GET_FIELDS) {\n      // overlap facet refinement requests (those shards that we need a count for\n      // particular facet values from), where possible, with\n      // the requests to get fields (because we know that is the\n      // only other required phase).\n      // We do this in distributedProcess so we can look at all of the\n      // requests in the outgoing queue at once.\n\n      for (int shardNum=0; shardNum<rb.shards.length; shardNum++) {\n        List<String> fqueries = rb._facetInfo._toRefine[shardNum];\n        if (fqueries == null || fqueries.size()==0) continue;\n\n        String shard = rb.shards[shardNum];\n\n        ShardRequest refine = null;\n        boolean newRequest = false;\n\n        // try to find a request that is already going out to that shard.\n        // If nshards becomes to great, we way want to move to hashing for better\n        // scalability.\n        for (ShardRequest sreq : rb.outgoing) {\n          if ((sreq.purpose & ShardRequest.PURPOSE_GET_FIELDS)!=0\n                  && sreq.shards != null & sreq.shards.length==1\n                  && sreq.shards[0].equals(shard))\n          {\n            refine = sreq;\n            break;\n          }\n        }\n\n        if (refine == null) {\n          // we didn't find any other suitable requests going out to that shard, so\n          // create one ourselves.\n          newRequest = true;\n          refine = new ShardRequest();\n          refine.shards = new String[]{rb.shards[shardNum]};\n          refine.params = new ModifiableSolrParams(rb.req.getParams());\n          // don't request any documents\n          refine.params.remove(CommonParams.START);\n          refine.params.set(CommonParams.ROWS,\"0\");\n        }\n\n        refine.purpose |= ShardRequest.PURPOSE_REFINE_FACETS;\n        refine.params.set(FacetParams.FACET,\"true\");\n        refine.params.remove(FacetParams.FACET_FIELD);\n        // TODO: perhaps create a more compact facet.terms method?\n        refine.params.set(FacetParams.FACET_QUERY, fqueries.toArray(new String[fqueries.size()]));\n\n        if (newRequest) {\n          rb.addRequest(this, refine);\n        }\n      }\n    }\n\n    return ResponseBuilder.STAGE_DONE;\n  }\n\n","bugFix":["5bb29c260c4bbaf4ce8a95d362844ebf77ec1f76"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e5a95ce1d7a3779af6db59b6b39d3b89172d7445","date":1228620032,"type":3,"author":"Yonik Seeley","isMerge":false,"pathNew":"src/java/org/apache/solr/handler/component/FacetComponent#distributedProcess(ResponseBuilder).mjava","pathOld":"src/java/org/apache/solr/handler/component/FacetComponent#distributedProcess(ResponseBuilder).mjava","sourceNew":"  @Override\n  public int distributedProcess(ResponseBuilder rb) throws IOException {\n    if (!rb.doFacets) {\n      return ResponseBuilder.STAGE_DONE;\n    }\n\n    if (rb.stage == ResponseBuilder.STAGE_GET_FIELDS) {\n      // overlap facet refinement requests (those shards that we need a count for\n      // particular facet values from), where possible, with\n      // the requests to get fields (because we know that is the\n      // only other required phase).\n      // We do this in distributedProcess so we can look at all of the\n      // requests in the outgoing queue at once.\n\n      for (int shardNum=0; shardNum<rb.shards.length; shardNum++) {\n        List<String> fqueries = rb._facetInfo._toRefine[shardNum];\n        if (fqueries == null || fqueries.size()==0) continue;\n\n        String shard = rb.shards[shardNum];\n\n        ShardRequest refine = null;\n        boolean newRequest = false;\n\n        // try to find a request that is already going out to that shard.\n        // If nshards becomes to great, we way want to move to hashing for better\n        // scalability.\n        for (ShardRequest sreq : rb.outgoing) {\n          if ((sreq.purpose & ShardRequest.PURPOSE_GET_FIELDS)!=0\n                  && sreq.shards != null \n                  && sreq.shards.length==1\n                  && sreq.shards[0].equals(shard))\n          {\n            refine = sreq;\n            break;\n          }\n        }\n\n        if (refine == null) {\n          // we didn't find any other suitable requests going out to that shard, so\n          // create one ourselves.\n          newRequest = true;\n          refine = new ShardRequest();\n          refine.shards = new String[]{rb.shards[shardNum]};\n          refine.params = new ModifiableSolrParams(rb.req.getParams());\n          // don't request any documents\n          refine.params.remove(CommonParams.START);\n          refine.params.set(CommonParams.ROWS,\"0\");\n        }\n\n        refine.purpose |= ShardRequest.PURPOSE_REFINE_FACETS;\n        refine.params.set(FacetParams.FACET,FacetParams.FACET_SORT_COUNT_LEGACY);\n        refine.params.remove(FacetParams.FACET_FIELD);\n        // TODO: perhaps create a more compact facet.terms method?\n        refine.params.set(FacetParams.FACET_QUERY, fqueries.toArray(new String[fqueries.size()]));\n\n        if (newRequest) {\n          rb.addRequest(this, refine);\n        }\n      }\n    }\n\n    return ResponseBuilder.STAGE_DONE;\n  }\n\n","sourceOld":"  @Override\n  public int distributedProcess(ResponseBuilder rb) throws IOException {\n    if (!rb.doFacets) {\n      return ResponseBuilder.STAGE_DONE;\n    }\n\n    if (rb.stage == ResponseBuilder.STAGE_GET_FIELDS) {\n      // overlap facet refinement requests (those shards that we need a count for\n      // particular facet values from), where possible, with\n      // the requests to get fields (because we know that is the\n      // only other required phase).\n      // We do this in distributedProcess so we can look at all of the\n      // requests in the outgoing queue at once.\n\n      for (int shardNum=0; shardNum<rb.shards.length; shardNum++) {\n        List<String> fqueries = rb._facetInfo._toRefine[shardNum];\n        if (fqueries == null || fqueries.size()==0) continue;\n\n        String shard = rb.shards[shardNum];\n\n        ShardRequest refine = null;\n        boolean newRequest = false;\n\n        // try to find a request that is already going out to that shard.\n        // If nshards becomes to great, we way want to move to hashing for better\n        // scalability.\n        for (ShardRequest sreq : rb.outgoing) {\n          if ((sreq.purpose & ShardRequest.PURPOSE_GET_FIELDS)!=0\n                  && sreq.shards != null \n                  && sreq.shards.length==1\n                  && sreq.shards[0].equals(shard))\n          {\n            refine = sreq;\n            break;\n          }\n        }\n\n        if (refine == null) {\n          // we didn't find any other suitable requests going out to that shard, so\n          // create one ourselves.\n          newRequest = true;\n          refine = new ShardRequest();\n          refine.shards = new String[]{rb.shards[shardNum]};\n          refine.params = new ModifiableSolrParams(rb.req.getParams());\n          // don't request any documents\n          refine.params.remove(CommonParams.START);\n          refine.params.set(CommonParams.ROWS,\"0\");\n        }\n\n        refine.purpose |= ShardRequest.PURPOSE_REFINE_FACETS;\n        refine.params.set(FacetParams.FACET,\"true\");\n        refine.params.remove(FacetParams.FACET_FIELD);\n        // TODO: perhaps create a more compact facet.terms method?\n        refine.params.set(FacetParams.FACET_QUERY, fqueries.toArray(new String[fqueries.size()]));\n\n        if (newRequest) {\n          rb.addRequest(this, refine);\n        }\n      }\n    }\n\n    return ResponseBuilder.STAGE_DONE;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9397de64b7287396e2394079a925761a83ceeca2","date":1228629999,"type":3,"author":"Yonik Seeley","isMerge":false,"pathNew":"src/java/org/apache/solr/handler/component/FacetComponent#distributedProcess(ResponseBuilder).mjava","pathOld":"src/java/org/apache/solr/handler/component/FacetComponent#distributedProcess(ResponseBuilder).mjava","sourceNew":"  @Override\n  public int distributedProcess(ResponseBuilder rb) throws IOException {\n    if (!rb.doFacets) {\n      return ResponseBuilder.STAGE_DONE;\n    }\n\n    if (rb.stage == ResponseBuilder.STAGE_GET_FIELDS) {\n      // overlap facet refinement requests (those shards that we need a count for\n      // particular facet values from), where possible, with\n      // the requests to get fields (because we know that is the\n      // only other required phase).\n      // We do this in distributedProcess so we can look at all of the\n      // requests in the outgoing queue at once.\n\n      for (int shardNum=0; shardNum<rb.shards.length; shardNum++) {\n        List<String> fqueries = rb._facetInfo._toRefine[shardNum];\n        if (fqueries == null || fqueries.size()==0) continue;\n\n        String shard = rb.shards[shardNum];\n\n        ShardRequest refine = null;\n        boolean newRequest = false;\n\n        // try to find a request that is already going out to that shard.\n        // If nshards becomes to great, we way want to move to hashing for better\n        // scalability.\n        for (ShardRequest sreq : rb.outgoing) {\n          if ((sreq.purpose & ShardRequest.PURPOSE_GET_FIELDS)!=0\n                  && sreq.shards != null \n                  && sreq.shards.length==1\n                  && sreq.shards[0].equals(shard))\n          {\n            refine = sreq;\n            break;\n          }\n        }\n\n        if (refine == null) {\n          // we didn't find any other suitable requests going out to that shard, so\n          // create one ourselves.\n          newRequest = true;\n          refine = new ShardRequest();\n          refine.shards = new String[]{rb.shards[shardNum]};\n          refine.params = new ModifiableSolrParams(rb.req.getParams());\n          // don't request any documents\n          refine.params.remove(CommonParams.START);\n          refine.params.set(CommonParams.ROWS,\"0\");\n        }\n\n        refine.purpose |= ShardRequest.PURPOSE_REFINE_FACETS;\n        refine.params.set(FacetParams.FACET, \"true\");\n        refine.params.remove(FacetParams.FACET_FIELD);\n        // TODO: perhaps create a more compact facet.terms method?\n        refine.params.set(FacetParams.FACET_QUERY, fqueries.toArray(new String[fqueries.size()]));\n\n        if (newRequest) {\n          rb.addRequest(this, refine);\n        }\n      }\n    }\n\n    return ResponseBuilder.STAGE_DONE;\n  }\n\n","sourceOld":"  @Override\n  public int distributedProcess(ResponseBuilder rb) throws IOException {\n    if (!rb.doFacets) {\n      return ResponseBuilder.STAGE_DONE;\n    }\n\n    if (rb.stage == ResponseBuilder.STAGE_GET_FIELDS) {\n      // overlap facet refinement requests (those shards that we need a count for\n      // particular facet values from), where possible, with\n      // the requests to get fields (because we know that is the\n      // only other required phase).\n      // We do this in distributedProcess so we can look at all of the\n      // requests in the outgoing queue at once.\n\n      for (int shardNum=0; shardNum<rb.shards.length; shardNum++) {\n        List<String> fqueries = rb._facetInfo._toRefine[shardNum];\n        if (fqueries == null || fqueries.size()==0) continue;\n\n        String shard = rb.shards[shardNum];\n\n        ShardRequest refine = null;\n        boolean newRequest = false;\n\n        // try to find a request that is already going out to that shard.\n        // If nshards becomes to great, we way want to move to hashing for better\n        // scalability.\n        for (ShardRequest sreq : rb.outgoing) {\n          if ((sreq.purpose & ShardRequest.PURPOSE_GET_FIELDS)!=0\n                  && sreq.shards != null \n                  && sreq.shards.length==1\n                  && sreq.shards[0].equals(shard))\n          {\n            refine = sreq;\n            break;\n          }\n        }\n\n        if (refine == null) {\n          // we didn't find any other suitable requests going out to that shard, so\n          // create one ourselves.\n          newRequest = true;\n          refine = new ShardRequest();\n          refine.shards = new String[]{rb.shards[shardNum]};\n          refine.params = new ModifiableSolrParams(rb.req.getParams());\n          // don't request any documents\n          refine.params.remove(CommonParams.START);\n          refine.params.set(CommonParams.ROWS,\"0\");\n        }\n\n        refine.purpose |= ShardRequest.PURPOSE_REFINE_FACETS;\n        refine.params.set(FacetParams.FACET,FacetParams.FACET_SORT_COUNT_LEGACY);\n        refine.params.remove(FacetParams.FACET_FIELD);\n        // TODO: perhaps create a more compact facet.terms method?\n        refine.params.set(FacetParams.FACET_QUERY, fqueries.toArray(new String[fqueries.size()]));\n\n        if (newRequest) {\n          rb.addRequest(this, refine);\n        }\n      }\n    }\n\n    return ResponseBuilder.STAGE_DONE;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9cb179b2fab2183d2f6041e450ff8022c592ecf0","date":1229553695,"type":3,"author":"Yonik Seeley","isMerge":false,"pathNew":"src/java/org/apache/solr/handler/component/FacetComponent#distributedProcess(ResponseBuilder).mjava","pathOld":"src/java/org/apache/solr/handler/component/FacetComponent#distributedProcess(ResponseBuilder).mjava","sourceNew":"  @Override\n  public int distributedProcess(ResponseBuilder rb) throws IOException {\n    if (!rb.doFacets) {\n      return ResponseBuilder.STAGE_DONE;\n    }\n\n    if (rb.stage == ResponseBuilder.STAGE_GET_FIELDS) {\n      // overlap facet refinement requests (those shards that we need a count for\n      // particular facet values from), where possible, with\n      // the requests to get fields (because we know that is the\n      // only other required phase).\n      // We do this in distributedProcess so we can look at all of the\n      // requests in the outgoing queue at once.\n\n\n\n      for (int shardNum=0; shardNum<rb.shards.length; shardNum++) {\n        List<String> refinements = null;\n\n        for (DistribFieldFacet dff : rb._facetInfo.facets.values()) {\n          if (!dff.needRefinements) continue;\n          List<String> refList = dff._toRefine[shardNum];\n          if (refList == null | refList.size()==0) continue;\n\n          String key = dff.getKey();  // reuse the same key that was used for the main facet\n          String termsKey = key + \"__terms\";\n          String termsVal = StrUtils.join(refList, ',');\n\n          String facetCommand;\n          // add terms into the original facet.field command\n          // do it via parameter reference to avoid another layer of encoding.\n          if (dff.localParams != null) {\n            facetCommand = commandPrefix+termsKey+dff.facetStr.substring(2);\n          } else {\n            facetCommand = commandPrefix+termsKey+'}'+dff.field;\n          }\n\n          if (refinements == null) {\n            refinements = new ArrayList<String>();\n          }\n\n          refinements.add(facetCommand);\n          refinements.add(termsKey);\n          refinements.add(termsVal);\n        }\n\n        if (refinements == null) continue;\n\n\n        String shard = rb.shards[shardNum];\n        ShardRequest refine = null;\n        boolean newRequest = false;\n\n        // try to find a request that is already going out to that shard.\n        // If nshards becomes to great, we way want to move to hashing for better\n        // scalability.\n        for (ShardRequest sreq : rb.outgoing) {\n          if ((sreq.purpose & ShardRequest.PURPOSE_GET_FIELDS)!=0\n                  && sreq.shards != null\n                  && sreq.shards.length==1\n                  && sreq.shards[0].equals(shard))\n          {\n            refine = sreq;\n            break;\n          }\n        }\n\n        if (refine == null) {\n          // we didn't find any other suitable requests going out to that shard, so\n          // create one ourselves.\n          newRequest = true;\n          refine = new ShardRequest();\n          refine.shards = new String[]{rb.shards[shardNum]};\n          refine.params = new ModifiableSolrParams(rb.req.getParams());\n          // don't request any documents\n          refine.params.remove(CommonParams.START);\n          refine.params.set(CommonParams.ROWS,\"0\");\n        }\n\n        refine.purpose |= ShardRequest.PURPOSE_REFINE_FACETS;\n        refine.params.set(FacetParams.FACET, \"true\");\n        refine.params.remove(FacetParams.FACET_FIELD);\n        refine.params.remove(FacetParams.FACET_QUERY);\n\n        for (int i=0; i<refinements.size();) {\n          String facetCommand=refinements.get(i++);\n          String termsKey=refinements.get(i++);\n          String termsVal=refinements.get(i++);\n\n          refine.params.add(FacetParams.FACET_FIELD, facetCommand);\n          refine.params.set(termsKey, termsVal);\n        }\n\n        if (newRequest) {\n          rb.addRequest(this, refine);\n        }\n      }\n    }\n\n    return ResponseBuilder.STAGE_DONE;\n  }\n\n","sourceOld":"  @Override\n  public int distributedProcess(ResponseBuilder rb) throws IOException {\n    if (!rb.doFacets) {\n      return ResponseBuilder.STAGE_DONE;\n    }\n\n    if (rb.stage == ResponseBuilder.STAGE_GET_FIELDS) {\n      // overlap facet refinement requests (those shards that we need a count for\n      // particular facet values from), where possible, with\n      // the requests to get fields (because we know that is the\n      // only other required phase).\n      // We do this in distributedProcess so we can look at all of the\n      // requests in the outgoing queue at once.\n\n      for (int shardNum=0; shardNum<rb.shards.length; shardNum++) {\n        List<String> fqueries = rb._facetInfo._toRefine[shardNum];\n        if (fqueries == null || fqueries.size()==0) continue;\n\n        String shard = rb.shards[shardNum];\n\n        ShardRequest refine = null;\n        boolean newRequest = false;\n\n        // try to find a request that is already going out to that shard.\n        // If nshards becomes to great, we way want to move to hashing for better\n        // scalability.\n        for (ShardRequest sreq : rb.outgoing) {\n          if ((sreq.purpose & ShardRequest.PURPOSE_GET_FIELDS)!=0\n                  && sreq.shards != null \n                  && sreq.shards.length==1\n                  && sreq.shards[0].equals(shard))\n          {\n            refine = sreq;\n            break;\n          }\n        }\n\n        if (refine == null) {\n          // we didn't find any other suitable requests going out to that shard, so\n          // create one ourselves.\n          newRequest = true;\n          refine = new ShardRequest();\n          refine.shards = new String[]{rb.shards[shardNum]};\n          refine.params = new ModifiableSolrParams(rb.req.getParams());\n          // don't request any documents\n          refine.params.remove(CommonParams.START);\n          refine.params.set(CommonParams.ROWS,\"0\");\n        }\n\n        refine.purpose |= ShardRequest.PURPOSE_REFINE_FACETS;\n        refine.params.set(FacetParams.FACET, \"true\");\n        refine.params.remove(FacetParams.FACET_FIELD);\n        // TODO: perhaps create a more compact facet.terms method?\n        refine.params.set(FacetParams.FACET_QUERY, fqueries.toArray(new String[fqueries.size()]));\n\n        if (newRequest) {\n          rb.addRequest(this, refine);\n        }\n      }\n    }\n\n    return ResponseBuilder.STAGE_DONE;\n  }\n\n","bugFix":null,"bugIntro":["95c18944ff53ae8d9f26822b93473fb5621d320e"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"3f9d6c462aec4bef2ca17ce01764848282b30f11","date":1231498710,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"src/java/org/apache/solr/handler/component/FacetComponent#distributedProcess(ResponseBuilder).mjava","pathOld":"src/java/org/apache/solr/handler/component/FacetComponent#distributedProcess(ResponseBuilder).mjava","sourceNew":"  @Override\n  public int distributedProcess(ResponseBuilder rb) throws IOException {\n    if (!rb.doFacets) {\n      return ResponseBuilder.STAGE_DONE;\n    }\n\n    if (rb.stage == ResponseBuilder.STAGE_GET_FIELDS) {\n      // overlap facet refinement requests (those shards that we need a count for\n      // particular facet values from), where possible, with\n      // the requests to get fields (because we know that is the\n      // only other required phase).\n      // We do this in distributedProcess so we can look at all of the\n      // requests in the outgoing queue at once.\n\n\n\n      for (int shardNum=0; shardNum<rb.shards.length; shardNum++) {\n        List<String> refinements = null;\n\n        for (DistribFieldFacet dff : rb._facetInfo.facets.values()) {\n          if (!dff.needRefinements) continue;\n          List<String> refList = dff._toRefine[shardNum];\n          if (refList == null || refList.size()==0) continue;\n\n          String key = dff.getKey();  // reuse the same key that was used for the main facet\n          String termsKey = key + \"__terms\";\n          String termsVal = StrUtils.join(refList, ',');\n\n          String facetCommand;\n          // add terms into the original facet.field command\n          // do it via parameter reference to avoid another layer of encoding.\n          if (dff.localParams != null) {\n            facetCommand = commandPrefix+termsKey+dff.facetStr.substring(2);\n          } else {\n            facetCommand = commandPrefix+termsKey+'}'+dff.field;\n          }\n\n          if (refinements == null) {\n            refinements = new ArrayList<String>();\n          }\n\n          refinements.add(facetCommand);\n          refinements.add(termsKey);\n          refinements.add(termsVal);\n        }\n\n        if (refinements == null) continue;\n\n\n        String shard = rb.shards[shardNum];\n        ShardRequest refine = null;\n        boolean newRequest = false;\n\n        // try to find a request that is already going out to that shard.\n        // If nshards becomes to great, we way want to move to hashing for better\n        // scalability.\n        for (ShardRequest sreq : rb.outgoing) {\n          if ((sreq.purpose & ShardRequest.PURPOSE_GET_FIELDS)!=0\n                  && sreq.shards != null\n                  && sreq.shards.length==1\n                  && sreq.shards[0].equals(shard))\n          {\n            refine = sreq;\n            break;\n          }\n        }\n\n        if (refine == null) {\n          // we didn't find any other suitable requests going out to that shard, so\n          // create one ourselves.\n          newRequest = true;\n          refine = new ShardRequest();\n          refine.shards = new String[]{rb.shards[shardNum]};\n          refine.params = new ModifiableSolrParams(rb.req.getParams());\n          // don't request any documents\n          refine.params.remove(CommonParams.START);\n          refine.params.set(CommonParams.ROWS,\"0\");\n        }\n\n        refine.purpose |= ShardRequest.PURPOSE_REFINE_FACETS;\n        refine.params.set(FacetParams.FACET, \"true\");\n        refine.params.remove(FacetParams.FACET_FIELD);\n        refine.params.remove(FacetParams.FACET_QUERY);\n\n        for (int i=0; i<refinements.size();) {\n          String facetCommand=refinements.get(i++);\n          String termsKey=refinements.get(i++);\n          String termsVal=refinements.get(i++);\n\n          refine.params.add(FacetParams.FACET_FIELD, facetCommand);\n          refine.params.set(termsKey, termsVal);\n        }\n\n        if (newRequest) {\n          rb.addRequest(this, refine);\n        }\n      }\n    }\n\n    return ResponseBuilder.STAGE_DONE;\n  }\n\n","sourceOld":"  @Override\n  public int distributedProcess(ResponseBuilder rb) throws IOException {\n    if (!rb.doFacets) {\n      return ResponseBuilder.STAGE_DONE;\n    }\n\n    if (rb.stage == ResponseBuilder.STAGE_GET_FIELDS) {\n      // overlap facet refinement requests (those shards that we need a count for\n      // particular facet values from), where possible, with\n      // the requests to get fields (because we know that is the\n      // only other required phase).\n      // We do this in distributedProcess so we can look at all of the\n      // requests in the outgoing queue at once.\n\n\n\n      for (int shardNum=0; shardNum<rb.shards.length; shardNum++) {\n        List<String> refinements = null;\n\n        for (DistribFieldFacet dff : rb._facetInfo.facets.values()) {\n          if (!dff.needRefinements) continue;\n          List<String> refList = dff._toRefine[shardNum];\n          if (refList == null | refList.size()==0) continue;\n\n          String key = dff.getKey();  // reuse the same key that was used for the main facet\n          String termsKey = key + \"__terms\";\n          String termsVal = StrUtils.join(refList, ',');\n\n          String facetCommand;\n          // add terms into the original facet.field command\n          // do it via parameter reference to avoid another layer of encoding.\n          if (dff.localParams != null) {\n            facetCommand = commandPrefix+termsKey+dff.facetStr.substring(2);\n          } else {\n            facetCommand = commandPrefix+termsKey+'}'+dff.field;\n          }\n\n          if (refinements == null) {\n            refinements = new ArrayList<String>();\n          }\n\n          refinements.add(facetCommand);\n          refinements.add(termsKey);\n          refinements.add(termsVal);\n        }\n\n        if (refinements == null) continue;\n\n\n        String shard = rb.shards[shardNum];\n        ShardRequest refine = null;\n        boolean newRequest = false;\n\n        // try to find a request that is already going out to that shard.\n        // If nshards becomes to great, we way want to move to hashing for better\n        // scalability.\n        for (ShardRequest sreq : rb.outgoing) {\n          if ((sreq.purpose & ShardRequest.PURPOSE_GET_FIELDS)!=0\n                  && sreq.shards != null\n                  && sreq.shards.length==1\n                  && sreq.shards[0].equals(shard))\n          {\n            refine = sreq;\n            break;\n          }\n        }\n\n        if (refine == null) {\n          // we didn't find any other suitable requests going out to that shard, so\n          // create one ourselves.\n          newRequest = true;\n          refine = new ShardRequest();\n          refine.shards = new String[]{rb.shards[shardNum]};\n          refine.params = new ModifiableSolrParams(rb.req.getParams());\n          // don't request any documents\n          refine.params.remove(CommonParams.START);\n          refine.params.set(CommonParams.ROWS,\"0\");\n        }\n\n        refine.purpose |= ShardRequest.PURPOSE_REFINE_FACETS;\n        refine.params.set(FacetParams.FACET, \"true\");\n        refine.params.remove(FacetParams.FACET_FIELD);\n        refine.params.remove(FacetParams.FACET_QUERY);\n\n        for (int i=0; i<refinements.size();) {\n          String facetCommand=refinements.get(i++);\n          String termsKey=refinements.get(i++);\n          String termsVal=refinements.get(i++);\n\n          refine.params.add(FacetParams.FACET_FIELD, facetCommand);\n          refine.params.set(termsKey, termsVal);\n        }\n\n        if (newRequest) {\n          rb.addRequest(this, refine);\n        }\n      }\n    }\n\n    return ResponseBuilder.STAGE_DONE;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"95c18944ff53ae8d9f26822b93473fb5621d320e","date":1231751360,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"src/java/org/apache/solr/handler/component/FacetComponent#distributedProcess(ResponseBuilder).mjava","pathOld":"src/java/org/apache/solr/handler/component/FacetComponent#distributedProcess(ResponseBuilder).mjava","sourceNew":"  @Override\n  public int distributedProcess(ResponseBuilder rb) throws IOException {\n    if (!rb.doFacets) {\n      return ResponseBuilder.STAGE_DONE;\n    }\n\n    if (rb.stage == ResponseBuilder.STAGE_GET_FIELDS) {\n      // overlap facet refinement requests (those shards that we need a count for\n      // particular facet values from), where possible, with\n      // the requests to get fields (because we know that is the\n      // only other required phase).\n      // We do this in distributedProcess so we can look at all of the\n      // requests in the outgoing queue at once.\n\n\n\n      for (int shardNum=0; shardNum<rb.shards.length; shardNum++) {\n        List<String> refinements = null;\n\n        for (DistribFieldFacet dff : rb._facetInfo.facets.values()) {\n          if (!dff.needRefinements) continue;\n          List<String> refList = dff._toRefine[shardNum];\n          if (refList == null || refList.size()==0) continue;\n\n          String key = dff.getKey();  // reuse the same key that was used for the main facet\n          String termsKey = key + \"__terms\";\n          String termsVal = StrUtils.join(refList, ',');\n\n          String facetCommand;\n          // add terms into the original facet.field command\n          // do it via parameter reference to avoid another layer of encoding.\n          if (dff.localParams != null) {\n            facetCommand = commandPrefix+termsKey + \" \" + dff.facetStr.substring(2);\n          } else {\n            facetCommand = commandPrefix+termsKey+'}'+dff.field;\n          }\n\n          if (refinements == null) {\n            refinements = new ArrayList<String>();\n          }\n\n          refinements.add(facetCommand);\n          refinements.add(termsKey);\n          refinements.add(termsVal);\n        }\n\n        if (refinements == null) continue;\n\n\n        String shard = rb.shards[shardNum];\n        ShardRequest refine = null;\n        boolean newRequest = false;\n\n        // try to find a request that is already going out to that shard.\n        // If nshards becomes to great, we way want to move to hashing for better\n        // scalability.\n        for (ShardRequest sreq : rb.outgoing) {\n          if ((sreq.purpose & ShardRequest.PURPOSE_GET_FIELDS)!=0\n                  && sreq.shards != null\n                  && sreq.shards.length==1\n                  && sreq.shards[0].equals(shard))\n          {\n            refine = sreq;\n            break;\n          }\n        }\n\n        if (refine == null) {\n          // we didn't find any other suitable requests going out to that shard, so\n          // create one ourselves.\n          newRequest = true;\n          refine = new ShardRequest();\n          refine.shards = new String[]{rb.shards[shardNum]};\n          refine.params = new ModifiableSolrParams(rb.req.getParams());\n          // don't request any documents\n          refine.params.remove(CommonParams.START);\n          refine.params.set(CommonParams.ROWS,\"0\");\n        }\n\n        refine.purpose |= ShardRequest.PURPOSE_REFINE_FACETS;\n        refine.params.set(FacetParams.FACET, \"true\");\n        refine.params.remove(FacetParams.FACET_FIELD);\n        refine.params.remove(FacetParams.FACET_QUERY);\n\n        for (int i=0; i<refinements.size();) {\n          String facetCommand=refinements.get(i++);\n          String termsKey=refinements.get(i++);\n          String termsVal=refinements.get(i++);\n\n          refine.params.add(FacetParams.FACET_FIELD, facetCommand);\n          refine.params.set(termsKey, termsVal);\n        }\n\n        if (newRequest) {\n          rb.addRequest(this, refine);\n        }\n      }\n    }\n\n    return ResponseBuilder.STAGE_DONE;\n  }\n\n","sourceOld":"  @Override\n  public int distributedProcess(ResponseBuilder rb) throws IOException {\n    if (!rb.doFacets) {\n      return ResponseBuilder.STAGE_DONE;\n    }\n\n    if (rb.stage == ResponseBuilder.STAGE_GET_FIELDS) {\n      // overlap facet refinement requests (those shards that we need a count for\n      // particular facet values from), where possible, with\n      // the requests to get fields (because we know that is the\n      // only other required phase).\n      // We do this in distributedProcess so we can look at all of the\n      // requests in the outgoing queue at once.\n\n\n\n      for (int shardNum=0; shardNum<rb.shards.length; shardNum++) {\n        List<String> refinements = null;\n\n        for (DistribFieldFacet dff : rb._facetInfo.facets.values()) {\n          if (!dff.needRefinements) continue;\n          List<String> refList = dff._toRefine[shardNum];\n          if (refList == null || refList.size()==0) continue;\n\n          String key = dff.getKey();  // reuse the same key that was used for the main facet\n          String termsKey = key + \"__terms\";\n          String termsVal = StrUtils.join(refList, ',');\n\n          String facetCommand;\n          // add terms into the original facet.field command\n          // do it via parameter reference to avoid another layer of encoding.\n          if (dff.localParams != null) {\n            facetCommand = commandPrefix+termsKey+dff.facetStr.substring(2);\n          } else {\n            facetCommand = commandPrefix+termsKey+'}'+dff.field;\n          }\n\n          if (refinements == null) {\n            refinements = new ArrayList<String>();\n          }\n\n          refinements.add(facetCommand);\n          refinements.add(termsKey);\n          refinements.add(termsVal);\n        }\n\n        if (refinements == null) continue;\n\n\n        String shard = rb.shards[shardNum];\n        ShardRequest refine = null;\n        boolean newRequest = false;\n\n        // try to find a request that is already going out to that shard.\n        // If nshards becomes to great, we way want to move to hashing for better\n        // scalability.\n        for (ShardRequest sreq : rb.outgoing) {\n          if ((sreq.purpose & ShardRequest.PURPOSE_GET_FIELDS)!=0\n                  && sreq.shards != null\n                  && sreq.shards.length==1\n                  && sreq.shards[0].equals(shard))\n          {\n            refine = sreq;\n            break;\n          }\n        }\n\n        if (refine == null) {\n          // we didn't find any other suitable requests going out to that shard, so\n          // create one ourselves.\n          newRequest = true;\n          refine = new ShardRequest();\n          refine.shards = new String[]{rb.shards[shardNum]};\n          refine.params = new ModifiableSolrParams(rb.req.getParams());\n          // don't request any documents\n          refine.params.remove(CommonParams.START);\n          refine.params.set(CommonParams.ROWS,\"0\");\n        }\n\n        refine.purpose |= ShardRequest.PURPOSE_REFINE_FACETS;\n        refine.params.set(FacetParams.FACET, \"true\");\n        refine.params.remove(FacetParams.FACET_FIELD);\n        refine.params.remove(FacetParams.FACET_QUERY);\n\n        for (int i=0; i<refinements.size();) {\n          String facetCommand=refinements.get(i++);\n          String termsKey=refinements.get(i++);\n          String termsVal=refinements.get(i++);\n\n          refine.params.add(FacetParams.FACET_FIELD, facetCommand);\n          refine.params.set(termsKey, termsVal);\n        }\n\n        if (newRequest) {\n          rb.addRequest(this, refine);\n        }\n      }\n    }\n\n    return ResponseBuilder.STAGE_DONE;\n  }\n\n","bugFix":["9cb179b2fab2183d2f6041e450ff8022c592ecf0"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ad94625fb8d088209f46650c8097196fec67f00c","date":1453508319,"type":5,"author":"Dawid Weiss","isMerge":false,"pathNew":"solr/src/java/org/apache/solr/handler/component/FacetComponent#distributedProcess(ResponseBuilder).mjava","pathOld":"src/java/org/apache/solr/handler/component/FacetComponent#distributedProcess(ResponseBuilder).mjava","sourceNew":"  @Override\n  public int distributedProcess(ResponseBuilder rb) throws IOException {\n    if (!rb.doFacets) {\n      return ResponseBuilder.STAGE_DONE;\n    }\n\n    if (rb.stage == ResponseBuilder.STAGE_GET_FIELDS) {\n      // overlap facet refinement requests (those shards that we need a count for\n      // particular facet values from), where possible, with\n      // the requests to get fields (because we know that is the\n      // only other required phase).\n      // We do this in distributedProcess so we can look at all of the\n      // requests in the outgoing queue at once.\n\n\n\n      for (int shardNum=0; shardNum<rb.shards.length; shardNum++) {\n        List<String> refinements = null;\n\n        for (DistribFieldFacet dff : rb._facetInfo.facets.values()) {\n          if (!dff.needRefinements) continue;\n          List<String> refList = dff._toRefine[shardNum];\n          if (refList == null || refList.size()==0) continue;\n\n          String key = dff.getKey();  // reuse the same key that was used for the main facet\n          String termsKey = key + \"__terms\";\n          String termsVal = StrUtils.join(refList, ',');\n\n          String facetCommand;\n          // add terms into the original facet.field command\n          // do it via parameter reference to avoid another layer of encoding.\n          if (dff.localParams != null) {\n            facetCommand = commandPrefix+termsKey + \" \" + dff.facetStr.substring(2);\n          } else {\n            facetCommand = commandPrefix+termsKey+'}'+dff.field;\n          }\n\n          if (refinements == null) {\n            refinements = new ArrayList<String>();\n          }\n\n          refinements.add(facetCommand);\n          refinements.add(termsKey);\n          refinements.add(termsVal);\n        }\n\n        if (refinements == null) continue;\n\n\n        String shard = rb.shards[shardNum];\n        ShardRequest refine = null;\n        boolean newRequest = false;\n\n        // try to find a request that is already going out to that shard.\n        // If nshards becomes to great, we way want to move to hashing for better\n        // scalability.\n        for (ShardRequest sreq : rb.outgoing) {\n          if ((sreq.purpose & ShardRequest.PURPOSE_GET_FIELDS)!=0\n                  && sreq.shards != null\n                  && sreq.shards.length==1\n                  && sreq.shards[0].equals(shard))\n          {\n            refine = sreq;\n            break;\n          }\n        }\n\n        if (refine == null) {\n          // we didn't find any other suitable requests going out to that shard, so\n          // create one ourselves.\n          newRequest = true;\n          refine = new ShardRequest();\n          refine.shards = new String[]{rb.shards[shardNum]};\n          refine.params = new ModifiableSolrParams(rb.req.getParams());\n          // don't request any documents\n          refine.params.remove(CommonParams.START);\n          refine.params.set(CommonParams.ROWS,\"0\");\n        }\n\n        refine.purpose |= ShardRequest.PURPOSE_REFINE_FACETS;\n        refine.params.set(FacetParams.FACET, \"true\");\n        refine.params.remove(FacetParams.FACET_FIELD);\n        refine.params.remove(FacetParams.FACET_QUERY);\n\n        for (int i=0; i<refinements.size();) {\n          String facetCommand=refinements.get(i++);\n          String termsKey=refinements.get(i++);\n          String termsVal=refinements.get(i++);\n\n          refine.params.add(FacetParams.FACET_FIELD, facetCommand);\n          refine.params.set(termsKey, termsVal);\n        }\n\n        if (newRequest) {\n          rb.addRequest(this, refine);\n        }\n      }\n    }\n\n    return ResponseBuilder.STAGE_DONE;\n  }\n\n","sourceOld":"  @Override\n  public int distributedProcess(ResponseBuilder rb) throws IOException {\n    if (!rb.doFacets) {\n      return ResponseBuilder.STAGE_DONE;\n    }\n\n    if (rb.stage == ResponseBuilder.STAGE_GET_FIELDS) {\n      // overlap facet refinement requests (those shards that we need a count for\n      // particular facet values from), where possible, with\n      // the requests to get fields (because we know that is the\n      // only other required phase).\n      // We do this in distributedProcess so we can look at all of the\n      // requests in the outgoing queue at once.\n\n\n\n      for (int shardNum=0; shardNum<rb.shards.length; shardNum++) {\n        List<String> refinements = null;\n\n        for (DistribFieldFacet dff : rb._facetInfo.facets.values()) {\n          if (!dff.needRefinements) continue;\n          List<String> refList = dff._toRefine[shardNum];\n          if (refList == null || refList.size()==0) continue;\n\n          String key = dff.getKey();  // reuse the same key that was used for the main facet\n          String termsKey = key + \"__terms\";\n          String termsVal = StrUtils.join(refList, ',');\n\n          String facetCommand;\n          // add terms into the original facet.field command\n          // do it via parameter reference to avoid another layer of encoding.\n          if (dff.localParams != null) {\n            facetCommand = commandPrefix+termsKey + \" \" + dff.facetStr.substring(2);\n          } else {\n            facetCommand = commandPrefix+termsKey+'}'+dff.field;\n          }\n\n          if (refinements == null) {\n            refinements = new ArrayList<String>();\n          }\n\n          refinements.add(facetCommand);\n          refinements.add(termsKey);\n          refinements.add(termsVal);\n        }\n\n        if (refinements == null) continue;\n\n\n        String shard = rb.shards[shardNum];\n        ShardRequest refine = null;\n        boolean newRequest = false;\n\n        // try to find a request that is already going out to that shard.\n        // If nshards becomes to great, we way want to move to hashing for better\n        // scalability.\n        for (ShardRequest sreq : rb.outgoing) {\n          if ((sreq.purpose & ShardRequest.PURPOSE_GET_FIELDS)!=0\n                  && sreq.shards != null\n                  && sreq.shards.length==1\n                  && sreq.shards[0].equals(shard))\n          {\n            refine = sreq;\n            break;\n          }\n        }\n\n        if (refine == null) {\n          // we didn't find any other suitable requests going out to that shard, so\n          // create one ourselves.\n          newRequest = true;\n          refine = new ShardRequest();\n          refine.shards = new String[]{rb.shards[shardNum]};\n          refine.params = new ModifiableSolrParams(rb.req.getParams());\n          // don't request any documents\n          refine.params.remove(CommonParams.START);\n          refine.params.set(CommonParams.ROWS,\"0\");\n        }\n\n        refine.purpose |= ShardRequest.PURPOSE_REFINE_FACETS;\n        refine.params.set(FacetParams.FACET, \"true\");\n        refine.params.remove(FacetParams.FACET_FIELD);\n        refine.params.remove(FacetParams.FACET_QUERY);\n\n        for (int i=0; i<refinements.size();) {\n          String facetCommand=refinements.get(i++);\n          String termsKey=refinements.get(i++);\n          String termsVal=refinements.get(i++);\n\n          refine.params.add(FacetParams.FACET_FIELD, facetCommand);\n          refine.params.set(termsKey, termsVal);\n        }\n\n        if (newRequest) {\n          rb.addRequest(this, refine);\n        }\n      }\n    }\n\n    return ResponseBuilder.STAGE_DONE;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"3f9d6c462aec4bef2ca17ce01764848282b30f11":["9cb179b2fab2183d2f6041e450ff8022c592ecf0"],"8ad363a5abc5bb509031f433f753c91d372e21ea":["a6c6e4e06160d2ad231072e8743988a623ab14c9"],"a6c6e4e06160d2ad231072e8743988a623ab14c9":["5bb29c260c4bbaf4ce8a95d362844ebf77ec1f76"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b":[],"9cb179b2fab2183d2f6041e450ff8022c592ecf0":["9397de64b7287396e2394079a925761a83ceeca2"],"ad94625fb8d088209f46650c8097196fec67f00c":["95c18944ff53ae8d9f26822b93473fb5621d320e"],"95c18944ff53ae8d9f26822b93473fb5621d320e":["3f9d6c462aec4bef2ca17ce01764848282b30f11"],"5bb29c260c4bbaf4ce8a95d362844ebf77ec1f76":["3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b"],"9397de64b7287396e2394079a925761a83ceeca2":["e5a95ce1d7a3779af6db59b6b39d3b89172d7445"],"e5a95ce1d7a3779af6db59b6b39d3b89172d7445":["8ad363a5abc5bb509031f433f753c91d372e21ea"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"3f9d6c462aec4bef2ca17ce01764848282b30f11":["95c18944ff53ae8d9f26822b93473fb5621d320e"],"8ad363a5abc5bb509031f433f753c91d372e21ea":["e5a95ce1d7a3779af6db59b6b39d3b89172d7445"],"a6c6e4e06160d2ad231072e8743988a623ab14c9":["8ad363a5abc5bb509031f433f753c91d372e21ea"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b":["5bb29c260c4bbaf4ce8a95d362844ebf77ec1f76"],"9cb179b2fab2183d2f6041e450ff8022c592ecf0":["3f9d6c462aec4bef2ca17ce01764848282b30f11"],"ad94625fb8d088209f46650c8097196fec67f00c":[],"95c18944ff53ae8d9f26822b93473fb5621d320e":["ad94625fb8d088209f46650c8097196fec67f00c"],"5bb29c260c4bbaf4ce8a95d362844ebf77ec1f76":["a6c6e4e06160d2ad231072e8743988a623ab14c9"],"9397de64b7287396e2394079a925761a83ceeca2":["9cb179b2fab2183d2f6041e450ff8022c592ecf0"],"e5a95ce1d7a3779af6db59b6b39d3b89172d7445":["9397de64b7287396e2394079a925761a83ceeca2"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["ad94625fb8d088209f46650c8097196fec67f00c","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b"],"pathCommit":null}