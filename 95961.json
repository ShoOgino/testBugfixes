{"path":"lucene/test-framework/src/java/org/apache/lucene/index/BaseDocValuesFormatTestCase#doTestNumericsVsStoredFields(double,LongSupplier).mjava","commits":[{"id":"11134e449dabe11d6d0ff6a564d84b82cbe93722","date":1477299083,"type":1,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/index/BaseDocValuesFormatTestCase#doTestNumericsVsStoredFields(double,LongSupplier).mjava","pathOld":"lucene/test-framework/src/java/org/apache/lucene/index/BaseDocValuesFormatTestCase#doTestNumericsVsStoredFields(LongProducer).mjava","sourceNew":"  private void doTestNumericsVsStoredFields(double density, LongSupplier longs) throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig conf = newIndexWriterConfig(new MockAnalyzer(random()));\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, conf);\n    Document doc = new Document();\n    Field idField = new StringField(\"id\", \"\", Field.Store.NO);\n    Field storedField = newStringField(\"stored\", \"\", Field.Store.YES);\n    Field dvField = new NumericDocValuesField(\"dv\", 0);\n    doc.add(idField);\n    doc.add(storedField);\n    doc.add(dvField);\n    \n    // index some docs\n    int numDocs = atLeast(300);\n    // numDocs should be always > 256 so that in case of a codec that optimizes\n    // for numbers of values <= 256, all storage layouts are tested\n    assert numDocs > 256;\n    for (int i = 0; i < numDocs; i++) {\n      if (random().nextDouble() > density) {\n        writer.addDocument(new Document());\n        continue;\n      }\n      idField.setStringValue(Integer.toString(i));\n      long value = longs.getAsLong();\n      storedField.setStringValue(Long.toString(value));\n      dvField.setLongValue(value);\n      writer.addDocument(doc);\n      if (random().nextInt(31) == 0) {\n        writer.commit();\n      }\n    }\n    \n    // delete some docs\n    int numDeletions = random().nextInt(numDocs/10);\n    for (int i = 0; i < numDeletions; i++) {\n      int id = random().nextInt(numDocs);\n      writer.deleteDocuments(new Term(\"id\", Integer.toString(id)));\n    }\n\n    // merge some segments and ensure that at least one of them has more than\n    // 256 values\n    writer.forceMerge(numDocs / 256);\n\n    writer.close();\n    \n    // compare\n    DirectoryReader ir = DirectoryReader.open(dir);\n    TestUtil.checkReader(ir);\n    for (LeafReaderContext context : ir.leaves()) {\n      LeafReader r = context.reader();\n      NumericDocValues docValues = DocValues.getNumeric(r, \"dv\");\n      docValues.nextDoc();\n      for (int i = 0; i < r.maxDoc(); i++) {\n        String storedValue = r.document(i).get(\"stored\");\n        if (storedValue == null) {\n          assertTrue(docValues.docID() > i);\n        } else {\n          assertEquals(i, docValues.docID());\n          assertEquals(Long.parseLong(storedValue), docValues.longValue());\n          docValues.nextDoc();\n        }\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, docValues.docID());\n    }\n    ir.close();\n    dir.close();\n  }\n\n","sourceOld":"  private void doTestNumericsVsStoredFields(LongProducer longs) throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig conf = newIndexWriterConfig(new MockAnalyzer(random()));\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, conf);\n    Document doc = new Document();\n    Field idField = new StringField(\"id\", \"\", Field.Store.NO);\n    Field storedField = newStringField(\"stored\", \"\", Field.Store.YES);\n    Field dvField = new NumericDocValuesField(\"dv\", 0);\n    doc.add(idField);\n    doc.add(storedField);\n    doc.add(dvField);\n    \n    // index some docs\n    int numDocs = atLeast(300);\n    // numDocs should be always > 256 so that in case of a codec that optimizes\n    // for numbers of values <= 256, all storage layouts are tested\n    assert numDocs > 256;\n    for (int i = 0; i < numDocs; i++) {\n      idField.setStringValue(Integer.toString(i));\n      long value = longs.next();\n      storedField.setStringValue(Long.toString(value));\n      dvField.setLongValue(value);\n      writer.addDocument(doc);\n      if (random().nextInt(31) == 0) {\n        writer.commit();\n      }\n    }\n    \n    // delete some docs\n    int numDeletions = random().nextInt(numDocs/10);\n    for (int i = 0; i < numDeletions; i++) {\n      int id = random().nextInt(numDocs);\n      writer.deleteDocuments(new Term(\"id\", Integer.toString(id)));\n    }\n\n    // merge some segments and ensure that at least one of them has more than\n    // 256 values\n    writer.forceMerge(numDocs / 256);\n\n    writer.close();\n    \n    // compare\n    DirectoryReader ir = DirectoryReader.open(dir);\n    for (LeafReaderContext context : ir.leaves()) {\n      LeafReader r = context.reader();\n      NumericDocValues docValues = r.getNumericDocValues(\"dv\");\n      for (int i = 0; i < r.maxDoc(); i++) {\n        long storedValue = Long.parseLong(r.document(i).get(\"stored\"));\n        assertEquals(i, docValues.nextDoc());\n        assertEquals(storedValue, docValues.longValue());\n      }\n    }\n    ir.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d2714c85633b642b29871cf5ff8d17d3ba7bfd76","date":1477307753,"type":1,"author":"Noble Paul","isMerge":true,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/index/BaseDocValuesFormatTestCase#doTestNumericsVsStoredFields(double,LongSupplier).mjava","pathOld":"lucene/test-framework/src/java/org/apache/lucene/index/BaseDocValuesFormatTestCase#doTestNumericsVsStoredFields(LongProducer).mjava","sourceNew":"  private void doTestNumericsVsStoredFields(double density, LongSupplier longs) throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig conf = newIndexWriterConfig(new MockAnalyzer(random()));\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, conf);\n    Document doc = new Document();\n    Field idField = new StringField(\"id\", \"\", Field.Store.NO);\n    Field storedField = newStringField(\"stored\", \"\", Field.Store.YES);\n    Field dvField = new NumericDocValuesField(\"dv\", 0);\n    doc.add(idField);\n    doc.add(storedField);\n    doc.add(dvField);\n    \n    // index some docs\n    int numDocs = atLeast(300);\n    // numDocs should be always > 256 so that in case of a codec that optimizes\n    // for numbers of values <= 256, all storage layouts are tested\n    assert numDocs > 256;\n    for (int i = 0; i < numDocs; i++) {\n      if (random().nextDouble() > density) {\n        writer.addDocument(new Document());\n        continue;\n      }\n      idField.setStringValue(Integer.toString(i));\n      long value = longs.getAsLong();\n      storedField.setStringValue(Long.toString(value));\n      dvField.setLongValue(value);\n      writer.addDocument(doc);\n      if (random().nextInt(31) == 0) {\n        writer.commit();\n      }\n    }\n    \n    // delete some docs\n    int numDeletions = random().nextInt(numDocs/10);\n    for (int i = 0; i < numDeletions; i++) {\n      int id = random().nextInt(numDocs);\n      writer.deleteDocuments(new Term(\"id\", Integer.toString(id)));\n    }\n\n    // merge some segments and ensure that at least one of them has more than\n    // 256 values\n    writer.forceMerge(numDocs / 256);\n\n    writer.close();\n    \n    // compare\n    DirectoryReader ir = DirectoryReader.open(dir);\n    TestUtil.checkReader(ir);\n    for (LeafReaderContext context : ir.leaves()) {\n      LeafReader r = context.reader();\n      NumericDocValues docValues = DocValues.getNumeric(r, \"dv\");\n      docValues.nextDoc();\n      for (int i = 0; i < r.maxDoc(); i++) {\n        String storedValue = r.document(i).get(\"stored\");\n        if (storedValue == null) {\n          assertTrue(docValues.docID() > i);\n        } else {\n          assertEquals(i, docValues.docID());\n          assertEquals(Long.parseLong(storedValue), docValues.longValue());\n          docValues.nextDoc();\n        }\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, docValues.docID());\n    }\n    ir.close();\n    dir.close();\n  }\n\n","sourceOld":"  private void doTestNumericsVsStoredFields(LongProducer longs) throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig conf = newIndexWriterConfig(new MockAnalyzer(random()));\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, conf);\n    Document doc = new Document();\n    Field idField = new StringField(\"id\", \"\", Field.Store.NO);\n    Field storedField = newStringField(\"stored\", \"\", Field.Store.YES);\n    Field dvField = new NumericDocValuesField(\"dv\", 0);\n    doc.add(idField);\n    doc.add(storedField);\n    doc.add(dvField);\n    \n    // index some docs\n    int numDocs = atLeast(300);\n    // numDocs should be always > 256 so that in case of a codec that optimizes\n    // for numbers of values <= 256, all storage layouts are tested\n    assert numDocs > 256;\n    for (int i = 0; i < numDocs; i++) {\n      idField.setStringValue(Integer.toString(i));\n      long value = longs.next();\n      storedField.setStringValue(Long.toString(value));\n      dvField.setLongValue(value);\n      writer.addDocument(doc);\n      if (random().nextInt(31) == 0) {\n        writer.commit();\n      }\n    }\n    \n    // delete some docs\n    int numDeletions = random().nextInt(numDocs/10);\n    for (int i = 0; i < numDeletions; i++) {\n      int id = random().nextInt(numDocs);\n      writer.deleteDocuments(new Term(\"id\", Integer.toString(id)));\n    }\n\n    // merge some segments and ensure that at least one of them has more than\n    // 256 values\n    writer.forceMerge(numDocs / 256);\n\n    writer.close();\n    \n    // compare\n    DirectoryReader ir = DirectoryReader.open(dir);\n    for (LeafReaderContext context : ir.leaves()) {\n      LeafReader r = context.reader();\n      NumericDocValues docValues = r.getNumericDocValues(\"dv\");\n      for (int i = 0; i < r.maxDoc(); i++) {\n        long storedValue = Long.parseLong(r.document(i).get(\"stored\"));\n        assertEquals(i, docValues.nextDoc());\n        assertEquals(storedValue, docValues.longValue());\n      }\n    }\n    ir.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"80d0e6d59ae23f4a6f30eaf40bfb40742300287f","date":1477598926,"type":1,"author":"Kevin Risden","isMerge":true,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/index/BaseDocValuesFormatTestCase#doTestNumericsVsStoredFields(double,LongSupplier).mjava","pathOld":"lucene/test-framework/src/java/org/apache/lucene/index/BaseDocValuesFormatTestCase#doTestNumericsVsStoredFields(LongProducer).mjava","sourceNew":"  private void doTestNumericsVsStoredFields(double density, LongSupplier longs) throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig conf = newIndexWriterConfig(new MockAnalyzer(random()));\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, conf);\n    Document doc = new Document();\n    Field idField = new StringField(\"id\", \"\", Field.Store.NO);\n    Field storedField = newStringField(\"stored\", \"\", Field.Store.YES);\n    Field dvField = new NumericDocValuesField(\"dv\", 0);\n    doc.add(idField);\n    doc.add(storedField);\n    doc.add(dvField);\n    \n    // index some docs\n    int numDocs = atLeast(300);\n    // numDocs should be always > 256 so that in case of a codec that optimizes\n    // for numbers of values <= 256, all storage layouts are tested\n    assert numDocs > 256;\n    for (int i = 0; i < numDocs; i++) {\n      if (random().nextDouble() > density) {\n        writer.addDocument(new Document());\n        continue;\n      }\n      idField.setStringValue(Integer.toString(i));\n      long value = longs.getAsLong();\n      storedField.setStringValue(Long.toString(value));\n      dvField.setLongValue(value);\n      writer.addDocument(doc);\n      if (random().nextInt(31) == 0) {\n        writer.commit();\n      }\n    }\n    \n    // delete some docs\n    int numDeletions = random().nextInt(numDocs/10);\n    for (int i = 0; i < numDeletions; i++) {\n      int id = random().nextInt(numDocs);\n      writer.deleteDocuments(new Term(\"id\", Integer.toString(id)));\n    }\n\n    // merge some segments and ensure that at least one of them has more than\n    // 256 values\n    writer.forceMerge(numDocs / 256);\n\n    writer.close();\n    \n    // compare\n    DirectoryReader ir = DirectoryReader.open(dir);\n    TestUtil.checkReader(ir);\n    for (LeafReaderContext context : ir.leaves()) {\n      LeafReader r = context.reader();\n      NumericDocValues docValues = DocValues.getNumeric(r, \"dv\");\n      docValues.nextDoc();\n      for (int i = 0; i < r.maxDoc(); i++) {\n        String storedValue = r.document(i).get(\"stored\");\n        if (storedValue == null) {\n          assertTrue(docValues.docID() > i);\n        } else {\n          assertEquals(i, docValues.docID());\n          assertEquals(Long.parseLong(storedValue), docValues.longValue());\n          docValues.nextDoc();\n        }\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, docValues.docID());\n    }\n    ir.close();\n    dir.close();\n  }\n\n","sourceOld":"  private void doTestNumericsVsStoredFields(LongProducer longs) throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig conf = newIndexWriterConfig(new MockAnalyzer(random()));\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, conf);\n    Document doc = new Document();\n    Field idField = new StringField(\"id\", \"\", Field.Store.NO);\n    Field storedField = newStringField(\"stored\", \"\", Field.Store.YES);\n    Field dvField = new NumericDocValuesField(\"dv\", 0);\n    doc.add(idField);\n    doc.add(storedField);\n    doc.add(dvField);\n    \n    // index some docs\n    int numDocs = atLeast(300);\n    // numDocs should be always > 256 so that in case of a codec that optimizes\n    // for numbers of values <= 256, all storage layouts are tested\n    assert numDocs > 256;\n    for (int i = 0; i < numDocs; i++) {\n      idField.setStringValue(Integer.toString(i));\n      long value = longs.next();\n      storedField.setStringValue(Long.toString(value));\n      dvField.setLongValue(value);\n      writer.addDocument(doc);\n      if (random().nextInt(31) == 0) {\n        writer.commit();\n      }\n    }\n    \n    // delete some docs\n    int numDeletions = random().nextInt(numDocs/10);\n    for (int i = 0; i < numDeletions; i++) {\n      int id = random().nextInt(numDocs);\n      writer.deleteDocuments(new Term(\"id\", Integer.toString(id)));\n    }\n\n    // merge some segments and ensure that at least one of them has more than\n    // 256 values\n    writer.forceMerge(numDocs / 256);\n\n    writer.close();\n    \n    // compare\n    DirectoryReader ir = DirectoryReader.open(dir);\n    for (LeafReaderContext context : ir.leaves()) {\n      LeafReader r = context.reader();\n      NumericDocValues docValues = r.getNumericDocValues(\"dv\");\n      for (int i = 0; i < r.maxDoc(); i++) {\n        long storedValue = Long.parseLong(r.document(i).get(\"stored\"));\n        assertEquals(i, docValues.nextDoc());\n        assertEquals(storedValue, docValues.longValue());\n      }\n    }\n    ir.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"03e17b020972a0d6e8d6823f545571a66646a167","date":1547847724,"type":3,"author":"Toke Eskildsen","isMerge":false,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/index/BaseDocValuesFormatTestCase#doTestNumericsVsStoredFields(double,LongSupplier).mjava","pathOld":"lucene/test-framework/src/java/org/apache/lucene/index/BaseDocValuesFormatTestCase#doTestNumericsVsStoredFields(double,LongSupplier).mjava","sourceNew":"  private void doTestNumericsVsStoredFields(double density, LongSupplier longs) throws Exception {\n    doTestNumericsVsStoredFields(density, longs, 256);\n  }\n\n","sourceOld":"  private void doTestNumericsVsStoredFields(double density, LongSupplier longs) throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig conf = newIndexWriterConfig(new MockAnalyzer(random()));\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, conf);\n    Document doc = new Document();\n    Field idField = new StringField(\"id\", \"\", Field.Store.NO);\n    Field storedField = newStringField(\"stored\", \"\", Field.Store.YES);\n    Field dvField = new NumericDocValuesField(\"dv\", 0);\n    doc.add(idField);\n    doc.add(storedField);\n    doc.add(dvField);\n    \n    // index some docs\n    int numDocs = atLeast(300);\n    // numDocs should be always > 256 so that in case of a codec that optimizes\n    // for numbers of values <= 256, all storage layouts are tested\n    assert numDocs > 256;\n    for (int i = 0; i < numDocs; i++) {\n      if (random().nextDouble() > density) {\n        writer.addDocument(new Document());\n        continue;\n      }\n      idField.setStringValue(Integer.toString(i));\n      long value = longs.getAsLong();\n      storedField.setStringValue(Long.toString(value));\n      dvField.setLongValue(value);\n      writer.addDocument(doc);\n      if (random().nextInt(31) == 0) {\n        writer.commit();\n      }\n    }\n    \n    // delete some docs\n    int numDeletions = random().nextInt(numDocs/10);\n    for (int i = 0; i < numDeletions; i++) {\n      int id = random().nextInt(numDocs);\n      writer.deleteDocuments(new Term(\"id\", Integer.toString(id)));\n    }\n\n    // merge some segments and ensure that at least one of them has more than\n    // 256 values\n    writer.forceMerge(numDocs / 256);\n\n    writer.close();\n    \n    // compare\n    DirectoryReader ir = DirectoryReader.open(dir);\n    TestUtil.checkReader(ir);\n    for (LeafReaderContext context : ir.leaves()) {\n      LeafReader r = context.reader();\n      NumericDocValues docValues = DocValues.getNumeric(r, \"dv\");\n      docValues.nextDoc();\n      for (int i = 0; i < r.maxDoc(); i++) {\n        String storedValue = r.document(i).get(\"stored\");\n        if (storedValue == null) {\n          assertTrue(docValues.docID() > i);\n        } else {\n          assertEquals(i, docValues.docID());\n          assertEquals(Long.parseLong(storedValue), docValues.longValue());\n          docValues.nextDoc();\n        }\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, docValues.docID());\n    }\n    ir.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c89f1ef80a9432f4eabaeda9a1e135cd72e60836","date":1547972642,"type":3,"author":"Tommaso Teofili","isMerge":true,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/index/BaseDocValuesFormatTestCase#doTestNumericsVsStoredFields(double,LongSupplier).mjava","pathOld":"lucene/test-framework/src/java/org/apache/lucene/index/BaseDocValuesFormatTestCase#doTestNumericsVsStoredFields(double,LongSupplier).mjava","sourceNew":"  private void doTestNumericsVsStoredFields(double density, LongSupplier longs) throws Exception {\n    doTestNumericsVsStoredFields(density, longs, 256);\n  }\n\n","sourceOld":"  private void doTestNumericsVsStoredFields(double density, LongSupplier longs) throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig conf = newIndexWriterConfig(new MockAnalyzer(random()));\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, conf);\n    Document doc = new Document();\n    Field idField = new StringField(\"id\", \"\", Field.Store.NO);\n    Field storedField = newStringField(\"stored\", \"\", Field.Store.YES);\n    Field dvField = new NumericDocValuesField(\"dv\", 0);\n    doc.add(idField);\n    doc.add(storedField);\n    doc.add(dvField);\n    \n    // index some docs\n    int numDocs = atLeast(300);\n    // numDocs should be always > 256 so that in case of a codec that optimizes\n    // for numbers of values <= 256, all storage layouts are tested\n    assert numDocs > 256;\n    for (int i = 0; i < numDocs; i++) {\n      if (random().nextDouble() > density) {\n        writer.addDocument(new Document());\n        continue;\n      }\n      idField.setStringValue(Integer.toString(i));\n      long value = longs.getAsLong();\n      storedField.setStringValue(Long.toString(value));\n      dvField.setLongValue(value);\n      writer.addDocument(doc);\n      if (random().nextInt(31) == 0) {\n        writer.commit();\n      }\n    }\n    \n    // delete some docs\n    int numDeletions = random().nextInt(numDocs/10);\n    for (int i = 0; i < numDeletions; i++) {\n      int id = random().nextInt(numDocs);\n      writer.deleteDocuments(new Term(\"id\", Integer.toString(id)));\n    }\n\n    // merge some segments and ensure that at least one of them has more than\n    // 256 values\n    writer.forceMerge(numDocs / 256);\n\n    writer.close();\n    \n    // compare\n    DirectoryReader ir = DirectoryReader.open(dir);\n    TestUtil.checkReader(ir);\n    for (LeafReaderContext context : ir.leaves()) {\n      LeafReader r = context.reader();\n      NumericDocValues docValues = DocValues.getNumeric(r, \"dv\");\n      docValues.nextDoc();\n      for (int i = 0; i < r.maxDoc(); i++) {\n        String storedValue = r.document(i).get(\"stored\");\n        if (storedValue == null) {\n          assertTrue(docValues.docID() > i);\n        } else {\n          assertEquals(i, docValues.docID());\n          assertEquals(Long.parseLong(storedValue), docValues.longValue());\n          docValues.nextDoc();\n        }\n      }\n      assertEquals(DocIdSetIterator.NO_MORE_DOCS, docValues.docID());\n    }\n    ir.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"03e17b020972a0d6e8d6823f545571a66646a167":["d2714c85633b642b29871cf5ff8d17d3ba7bfd76"],"c89f1ef80a9432f4eabaeda9a1e135cd72e60836":["d2714c85633b642b29871cf5ff8d17d3ba7bfd76","03e17b020972a0d6e8d6823f545571a66646a167"],"11134e449dabe11d6d0ff6a564d84b82cbe93722":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"80d0e6d59ae23f4a6f30eaf40bfb40742300287f":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","d2714c85633b642b29871cf5ff8d17d3ba7bfd76"],"d2714c85633b642b29871cf5ff8d17d3ba7bfd76":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","11134e449dabe11d6d0ff6a564d84b82cbe93722"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["03e17b020972a0d6e8d6823f545571a66646a167"]},"commit2Childs":{"03e17b020972a0d6e8d6823f545571a66646a167":["c89f1ef80a9432f4eabaeda9a1e135cd72e60836","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"c89f1ef80a9432f4eabaeda9a1e135cd72e60836":[],"11134e449dabe11d6d0ff6a564d84b82cbe93722":["d2714c85633b642b29871cf5ff8d17d3ba7bfd76"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["11134e449dabe11d6d0ff6a564d84b82cbe93722","80d0e6d59ae23f4a6f30eaf40bfb40742300287f","d2714c85633b642b29871cf5ff8d17d3ba7bfd76"],"80d0e6d59ae23f4a6f30eaf40bfb40742300287f":[],"d2714c85633b642b29871cf5ff8d17d3ba7bfd76":["03e17b020972a0d6e8d6823f545571a66646a167","c89f1ef80a9432f4eabaeda9a1e135cd72e60836","80d0e6d59ae23f4a6f30eaf40bfb40742300287f"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["c89f1ef80a9432f4eabaeda9a1e135cd72e60836","80d0e6d59ae23f4a6f30eaf40bfb40742300287f","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}