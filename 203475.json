{"path":"solr/core/src/java/org/apache/solr/cloud/ShardLeaderElectionContext[ElectionContext]#waitForReplicasToComeUp(boolean).mjava","commits":[{"id":"6013b4c7388f1627659c8f96c44abd10a294d3a6","date":1346343796,"type":0,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ShardLeaderElectionContext[ElectionContext]#waitForReplicasToComeUp(boolean).mjava","pathOld":"/dev/null","sourceNew":"  private void waitForReplicasToComeUp(boolean weAreReplacement)\n      throws InterruptedException {\n    int retries = 300; // ~ 5 min\n    boolean tryAgain = true;\n    Slice slices = zkController.getClusterState().getSlice(collection, shardId);\n    log.info(\"Running the leader process. afterExperiation=\" + afterExpiration);\n    while (tryAgain || slices == null) {\n      \n      // wait for everyone to be up\n      if (slices != null) {\n        Map<String,ZkNodeProps> shards = slices.getShards();\n        Set<Entry<String,ZkNodeProps>> entrySet = shards.entrySet();\n        int found = 0;\n        tryAgain = false;\n        for (Entry<String,ZkNodeProps> entry : entrySet) {\n          ZkCoreNodeProps props = new ZkCoreNodeProps(entry.getValue());\n          if (props.getState().equals(ZkStateReader.ACTIVE)\n              && zkController.getClusterState().liveNodesContain(\n                  props.getNodeName())) {\n            found++;\n          }\n        }\n        \n        // on startup and after connection timeout, wait for all known shards\n        if ((afterExpiration || !weAreReplacement)\n            && found >= slices.getShards().size()) {\n          log.info(\"Enough replicas found to continue.\");\n          tryAgain = false;\n        } else if (!afterExpiration && found >= slices.getShards().size() - 1) {\n          // a previous leader went down - wait for one less than the total\n          // known shards\n          log.info(\"Enough replicas found to continue.\");\n          tryAgain = false;\n        } else {\n          log.info(\"Waiting until we see more replicas up\");\n        }\n        \n        retries--;\n        if (retries == 0) {\n          log.info(\"Was waiting for replicas to come up, but they are taking too long - assuming they won't come back till later\");\n          break;\n        }\n      }\n      if (tryAgain) {\n        Thread.sleep(1000);\n        slices = zkController.getClusterState().getSlice(collection, shardId);\n      }\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["a6378064655e76cd7b908b1cab4ce425b384b508","344b0840364d990b29b97467bfcc766ff8325d11","344b0840364d990b29b97467bfcc766ff8325d11","344b0840364d990b29b97467bfcc766ff8325d11","344b0840364d990b29b97467bfcc766ff8325d11"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"05a14b2611ead08655a2b2bdc61632eb31316e57","date":1346366621,"type":0,"author":"Uwe Schindler","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ShardLeaderElectionContext[ElectionContext]#waitForReplicasToComeUp(boolean).mjava","pathOld":"/dev/null","sourceNew":"  private void waitForReplicasToComeUp(boolean weAreReplacement)\n      throws InterruptedException {\n    int retries = 300; // ~ 5 min\n    boolean tryAgain = true;\n    Slice slices = zkController.getClusterState().getSlice(collection, shardId);\n    log.info(\"Running the leader process. afterExperiation=\" + afterExpiration);\n    while (tryAgain || slices == null) {\n      \n      // wait for everyone to be up\n      if (slices != null) {\n        Map<String,ZkNodeProps> shards = slices.getShards();\n        Set<Entry<String,ZkNodeProps>> entrySet = shards.entrySet();\n        int found = 0;\n        tryAgain = false;\n        for (Entry<String,ZkNodeProps> entry : entrySet) {\n          ZkCoreNodeProps props = new ZkCoreNodeProps(entry.getValue());\n          if (props.getState().equals(ZkStateReader.ACTIVE)\n              && zkController.getClusterState().liveNodesContain(\n                  props.getNodeName())) {\n            found++;\n          }\n        }\n        \n        // on startup and after connection timeout, wait for all known shards\n        if ((afterExpiration || !weAreReplacement)\n            && found >= slices.getShards().size()) {\n          log.info(\"Enough replicas found to continue.\");\n          tryAgain = false;\n        } else if (!afterExpiration && found >= slices.getShards().size() - 1) {\n          // a previous leader went down - wait for one less than the total\n          // known shards\n          log.info(\"Enough replicas found to continue.\");\n          tryAgain = false;\n        } else {\n          log.info(\"Waiting until we see more replicas up\");\n        }\n        \n        retries--;\n        if (retries == 0) {\n          log.info(\"Was waiting for replicas to come up, but they are taking too long - assuming they won't come back till later\");\n          break;\n        }\n      }\n      if (tryAgain) {\n        Thread.sleep(1000);\n        slices = zkController.getClusterState().getSlice(collection, shardId);\n      }\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7157fdda82ae1a1cb77b012ef0eb72249ee2f3d6","date":1346692465,"type":5,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ShardLeaderElectionContext[ElectionContext]#waitForReplicasToComeUp(boolean,String).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/ShardLeaderElectionContext[ElectionContext]#waitForReplicasToComeUp(boolean).mjava","sourceNew":"  private void waitForReplicasToComeUp(boolean weAreReplacement, String leaderVoteWait)\n      throws InterruptedException {\n    int timeout = Integer.parseInt(leaderVoteWait);\n    long timeoutAt = System.currentTimeMillis() + timeout;\n\n    boolean tryAgain = true;\n    Slice slices = zkController.getClusterState().getSlice(collection, shardId);\n    while (true && !isClosed) {\n      // wait for everyone to be up\n      if (slices != null) {\n        Map<String,ZkNodeProps> shards = slices.getShards();\n        Set<Entry<String,ZkNodeProps>> entrySet = shards.entrySet();\n        int found = 0;\n        tryAgain = false;\n        for (Entry<String,ZkNodeProps> entry : entrySet) {\n          ZkCoreNodeProps props = new ZkCoreNodeProps(entry.getValue());\n          if (props.getState().equals(ZkStateReader.ACTIVE)\n              && zkController.getClusterState().liveNodesContain(\n                  props.getNodeName())) {\n            found++;\n          }\n        }\n        \n        // on startup and after connection timeout, wait for all known shards\n        if ((afterExpiration || !weAreReplacement)\n            && found >= slices.getShards().size()) {\n          log.info(\"Enough replicas found to continue.\");\n          break;\n        } else if (!afterExpiration && found >= slices.getShards().size() - 1) {\n          // a previous leader went down - wait for one less than the total\n          // known shards\n          log.info(\"Enough replicas found to continue.\");\n          break;\n        } else {\n          log.info(\"Waiting until we see more replicas up: total=\" + slices.getShards().size() + \" found=\" + found + \" timeoutin=\" + (timeoutAt - System.currentTimeMillis()));\n        }\n  \n        if (System.currentTimeMillis() > timeoutAt) {\n          log.info(\"Was waiting for replicas to come up, but they are taking too long - assuming they won't come back till later\");\n          break;\n        }\n      }\n      if (tryAgain) {\n        Thread.sleep(500);\n        slices = zkController.getClusterState().getSlice(collection, shardId);\n      }\n    }\n  }\n\n","sourceOld":"  private void waitForReplicasToComeUp(boolean weAreReplacement)\n      throws InterruptedException {\n    int retries = 300; // ~ 5 min\n    boolean tryAgain = true;\n    Slice slices = zkController.getClusterState().getSlice(collection, shardId);\n    log.info(\"Running the leader process. afterExperiation=\" + afterExpiration);\n    while (tryAgain || slices == null) {\n      \n      // wait for everyone to be up\n      if (slices != null) {\n        Map<String,ZkNodeProps> shards = slices.getShards();\n        Set<Entry<String,ZkNodeProps>> entrySet = shards.entrySet();\n        int found = 0;\n        tryAgain = false;\n        for (Entry<String,ZkNodeProps> entry : entrySet) {\n          ZkCoreNodeProps props = new ZkCoreNodeProps(entry.getValue());\n          if (props.getState().equals(ZkStateReader.ACTIVE)\n              && zkController.getClusterState().liveNodesContain(\n                  props.getNodeName())) {\n            found++;\n          }\n        }\n        \n        // on startup and after connection timeout, wait for all known shards\n        if ((afterExpiration || !weAreReplacement)\n            && found >= slices.getShards().size()) {\n          log.info(\"Enough replicas found to continue.\");\n          tryAgain = false;\n        } else if (!afterExpiration && found >= slices.getShards().size() - 1) {\n          // a previous leader went down - wait for one less than the total\n          // known shards\n          log.info(\"Enough replicas found to continue.\");\n          tryAgain = false;\n        } else {\n          log.info(\"Waiting until we see more replicas up\");\n        }\n        \n        retries--;\n        if (retries == 0) {\n          log.info(\"Was waiting for replicas to come up, but they are taking too long - assuming they won't come back till later\");\n          break;\n        }\n      }\n      if (tryAgain) {\n        Thread.sleep(1000);\n        slices = zkController.getClusterState().getSlice(collection, shardId);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":["a6378064655e76cd7b908b1cab4ce425b384b508"],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"7157fdda82ae1a1cb77b012ef0eb72249ee2f3d6":["6013b4c7388f1627659c8f96c44abd10a294d3a6"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"05a14b2611ead08655a2b2bdc61632eb31316e57":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","6013b4c7388f1627659c8f96c44abd10a294d3a6"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["7157fdda82ae1a1cb77b012ef0eb72249ee2f3d6"],"6013b4c7388f1627659c8f96c44abd10a294d3a6":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"7157fdda82ae1a1cb77b012ef0eb72249ee2f3d6":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["05a14b2611ead08655a2b2bdc61632eb31316e57","6013b4c7388f1627659c8f96c44abd10a294d3a6"],"05a14b2611ead08655a2b2bdc61632eb31316e57":[],"6013b4c7388f1627659c8f96c44abd10a294d3a6":["7157fdda82ae1a1cb77b012ef0eb72249ee2f3d6","05a14b2611ead08655a2b2bdc61632eb31316e57"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["05a14b2611ead08655a2b2bdc61632eb31316e57","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}