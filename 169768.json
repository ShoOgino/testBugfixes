{"path":"lucene/core/src/test/org/apache/lucene/index/TestBackwardsCompatibility#searchIndex(Directory,String).mjava","commits":[{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":1,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestBackwardsCompatibility#searchIndex(Directory,String).mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestBackwardsCompatibility#searchIndex(Directory,String).mjava","sourceNew":"  public void searchIndex(Directory dir, String oldName) throws IOException {\n    //QueryParser parser = new QueryParser(\"contents\", new MockAnalyzer(random));\n    //Query query = parser.parse(\"handle:1\");\n\n    IndexReader reader = IndexReader.open(dir);\n    IndexSearcher searcher = new IndexSearcher(reader);\n\n    _TestUtil.checkIndex(dir);\n\n    final Bits liveDocs = MultiFields.getLiveDocs(reader);\n\n    for(int i=0;i<35;i++) {\n      if (liveDocs.get(i)) {\n        Document d = reader.document(i);\n        List<IndexableField> fields = d.getFields();\n        if (d.getField(\"content3\") == null) {\n          final int numFields = 5;\n          assertEquals(numFields, fields.size());\n          IndexableField f =  d.getField(\"id\");\n          assertEquals(\"\"+i, f.stringValue());\n\n          f = d.getField(\"utf8\");\n          assertEquals(\"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne \\u0000 \\u2620 ab\\ud917\\udc17cd\", f.stringValue());\n\n          f =  d.getField(\"autf8\");\n          assertEquals(\"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne \\u0000 \\u2620 ab\\ud917\\udc17cd\", f.stringValue());\n      \n          f = d.getField(\"content2\");\n          assertEquals(\"here is more content with aaa aaa aaa\", f.stringValue());\n\n          f = d.getField(\"fie\\u2C77ld\");\n          assertEquals(\"field with non-ascii name\", f.stringValue());\n        }\n\n        Terms tfv = reader.getTermVectors(i).terms(\"utf8\");\n        assertNotNull(\"docID=\" + i + \" index=\" + oldName, tfv);\n      } else\n        // Only ID 7 is deleted\n        assertEquals(7, i);\n    }\n    \n    ScoreDoc[] hits = searcher.search(new TermQuery(new Term(\"content\", \"aaa\")), null, 1000).scoreDocs;\n\n    // First document should be #21 since it's norm was\n    // increased:\n    Document d = searcher.getIndexReader().document(hits[0].doc);\n    assertEquals(\"didn't get the right document first\", \"21\", d.get(\"id\"));\n\n    doTestHits(hits, 34, searcher.getIndexReader());\n\n    hits = searcher.search(new TermQuery(new Term(\"utf8\", \"\\u0000\")), null, 1000).scoreDocs;\n    assertEquals(34, hits.length);\n    hits = searcher.search(new TermQuery(new Term(\"utf8\", \"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne\")), null, 1000).scoreDocs;\n    assertEquals(34, hits.length);\n    hits = searcher.search(new TermQuery(new Term(\"utf8\", \"ab\\ud917\\udc17cd\")), null, 1000).scoreDocs;\n    assertEquals(34, hits.length);\n\n    reader.close();\n  }\n\n","sourceOld":"  public void searchIndex(Directory dir, String oldName) throws IOException {\n    //QueryParser parser = new QueryParser(\"contents\", new MockAnalyzer(random));\n    //Query query = parser.parse(\"handle:1\");\n\n    IndexReader reader = IndexReader.open(dir);\n    IndexSearcher searcher = new IndexSearcher(reader);\n\n    _TestUtil.checkIndex(dir);\n\n    final Bits liveDocs = MultiFields.getLiveDocs(reader);\n\n    for(int i=0;i<35;i++) {\n      if (liveDocs.get(i)) {\n        Document d = reader.document(i);\n        List<IndexableField> fields = d.getFields();\n        if (d.getField(\"content3\") == null) {\n          final int numFields = 5;\n          assertEquals(numFields, fields.size());\n          IndexableField f =  d.getField(\"id\");\n          assertEquals(\"\"+i, f.stringValue());\n\n          f = d.getField(\"utf8\");\n          assertEquals(\"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne \\u0000 \\u2620 ab\\ud917\\udc17cd\", f.stringValue());\n\n          f =  d.getField(\"autf8\");\n          assertEquals(\"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne \\u0000 \\u2620 ab\\ud917\\udc17cd\", f.stringValue());\n      \n          f = d.getField(\"content2\");\n          assertEquals(\"here is more content with aaa aaa aaa\", f.stringValue());\n\n          f = d.getField(\"fie\\u2C77ld\");\n          assertEquals(\"field with non-ascii name\", f.stringValue());\n        }\n\n        Terms tfv = reader.getTermVectors(i).terms(\"utf8\");\n        assertNotNull(\"docID=\" + i + \" index=\" + oldName, tfv);\n      } else\n        // Only ID 7 is deleted\n        assertEquals(7, i);\n    }\n    \n    ScoreDoc[] hits = searcher.search(new TermQuery(new Term(\"content\", \"aaa\")), null, 1000).scoreDocs;\n\n    // First document should be #21 since it's norm was\n    // increased:\n    Document d = searcher.getIndexReader().document(hits[0].doc);\n    assertEquals(\"didn't get the right document first\", \"21\", d.get(\"id\"));\n\n    doTestHits(hits, 34, searcher.getIndexReader());\n\n    hits = searcher.search(new TermQuery(new Term(\"utf8\", \"\\u0000\")), null, 1000).scoreDocs;\n    assertEquals(34, hits.length);\n    hits = searcher.search(new TermQuery(new Term(\"utf8\", \"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne\")), null, 1000).scoreDocs;\n    assertEquals(34, hits.length);\n    hits = searcher.search(new TermQuery(new Term(\"utf8\", \"ab\\ud917\\udc17cd\")), null, 1000).scoreDocs;\n    assertEquals(34, hits.length);\n\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4a8b14bc4241c302311422d5c6f7627f8febb86e","date":1337291675,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestBackwardsCompatibility#searchIndex(Directory,String).mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestBackwardsCompatibility#searchIndex(Directory,String).mjava","sourceNew":"  public void searchIndex(Directory dir, String oldName) throws IOException {\n    //QueryParser parser = new QueryParser(\"contents\", new MockAnalyzer(random));\n    //Query query = parser.parse(\"handle:1\");\n\n    IndexReader reader = IndexReader.open(dir);\n    IndexSearcher searcher = new IndexSearcher(reader);\n\n    _TestUtil.checkIndex(dir);\n\n    final Bits liveDocs = MultiFields.getLiveDocs(reader);\n\n    for(int i=0;i<35;i++) {\n      if (liveDocs.get(i)) {\n        Document d = reader.document(i);\n        List<IndexableField> fields = d.getFields();\n        if (d.getField(\"content3\") == null) {\n          final int numFields = 5;\n          assertEquals(numFields, fields.size());\n          IndexableField f =  d.getField(\"id\");\n          assertEquals(\"\"+i, f.stringValue());\n\n          f = d.getField(\"utf8\");\n          assertEquals(\"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne \\u0000 \\u2620 ab\\ud917\\udc17cd\", f.stringValue());\n\n          f =  d.getField(\"autf8\");\n          assertEquals(\"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne \\u0000 \\u2620 ab\\ud917\\udc17cd\", f.stringValue());\n      \n          f = d.getField(\"content2\");\n          assertEquals(\"here is more content with aaa aaa aaa\", f.stringValue());\n\n          f = d.getField(\"fie\\u2C77ld\");\n          assertEquals(\"field with non-ascii name\", f.stringValue());\n        }\n\n        Fields tfvFields = reader.getTermVectors(i);\n        assertNotNull(\"i=\" + i, tfvFields);\n        Terms tfv = tfvFields.terms(\"utf8\");\n        assertNotNull(\"docID=\" + i + \" index=\" + oldName, tfv);\n      } else {\n        // Only ID 7 is deleted\n        assertEquals(7, i);\n      }\n    }\n    \n    ScoreDoc[] hits = searcher.search(new TermQuery(new Term(\"content\", \"aaa\")), null, 1000).scoreDocs;\n\n    // First document should be #21 since it's norm was\n    // increased:\n    Document d = searcher.getIndexReader().document(hits[0].doc);\n    assertEquals(\"didn't get the right document first\", \"21\", d.get(\"id\"));\n\n    doTestHits(hits, 34, searcher.getIndexReader());\n\n    hits = searcher.search(new TermQuery(new Term(\"utf8\", \"\\u0000\")), null, 1000).scoreDocs;\n    assertEquals(34, hits.length);\n    hits = searcher.search(new TermQuery(new Term(\"utf8\", \"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne\")), null, 1000).scoreDocs;\n    assertEquals(34, hits.length);\n    hits = searcher.search(new TermQuery(new Term(\"utf8\", \"ab\\ud917\\udc17cd\")), null, 1000).scoreDocs;\n    assertEquals(34, hits.length);\n\n    reader.close();\n  }\n\n","sourceOld":"  public void searchIndex(Directory dir, String oldName) throws IOException {\n    //QueryParser parser = new QueryParser(\"contents\", new MockAnalyzer(random));\n    //Query query = parser.parse(\"handle:1\");\n\n    IndexReader reader = IndexReader.open(dir);\n    IndexSearcher searcher = new IndexSearcher(reader);\n\n    _TestUtil.checkIndex(dir);\n\n    final Bits liveDocs = MultiFields.getLiveDocs(reader);\n\n    for(int i=0;i<35;i++) {\n      if (liveDocs.get(i)) {\n        Document d = reader.document(i);\n        List<IndexableField> fields = d.getFields();\n        if (d.getField(\"content3\") == null) {\n          final int numFields = 5;\n          assertEquals(numFields, fields.size());\n          IndexableField f =  d.getField(\"id\");\n          assertEquals(\"\"+i, f.stringValue());\n\n          f = d.getField(\"utf8\");\n          assertEquals(\"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne \\u0000 \\u2620 ab\\ud917\\udc17cd\", f.stringValue());\n\n          f =  d.getField(\"autf8\");\n          assertEquals(\"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne \\u0000 \\u2620 ab\\ud917\\udc17cd\", f.stringValue());\n      \n          f = d.getField(\"content2\");\n          assertEquals(\"here is more content with aaa aaa aaa\", f.stringValue());\n\n          f = d.getField(\"fie\\u2C77ld\");\n          assertEquals(\"field with non-ascii name\", f.stringValue());\n        }\n\n        Terms tfv = reader.getTermVectors(i).terms(\"utf8\");\n        assertNotNull(\"docID=\" + i + \" index=\" + oldName, tfv);\n      } else\n        // Only ID 7 is deleted\n        assertEquals(7, i);\n    }\n    \n    ScoreDoc[] hits = searcher.search(new TermQuery(new Term(\"content\", \"aaa\")), null, 1000).scoreDocs;\n\n    // First document should be #21 since it's norm was\n    // increased:\n    Document d = searcher.getIndexReader().document(hits[0].doc);\n    assertEquals(\"didn't get the right document first\", \"21\", d.get(\"id\"));\n\n    doTestHits(hits, 34, searcher.getIndexReader());\n\n    hits = searcher.search(new TermQuery(new Term(\"utf8\", \"\\u0000\")), null, 1000).scoreDocs;\n    assertEquals(34, hits.length);\n    hits = searcher.search(new TermQuery(new Term(\"utf8\", \"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne\")), null, 1000).scoreDocs;\n    assertEquals(34, hits.length);\n    hits = searcher.search(new TermQuery(new Term(\"utf8\", \"ab\\ud917\\udc17cd\")), null, 1000).scoreDocs;\n    assertEquals(34, hits.length);\n\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b11100924615fd39ef80bc5cd463a565129b0533","date":1337695217,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestBackwardsCompatibility#searchIndex(Directory,String).mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestBackwardsCompatibility#searchIndex(Directory,String).mjava","sourceNew":"  public void searchIndex(Directory dir, String oldName) throws IOException {\n    //QueryParser parser = new QueryParser(\"contents\", new MockAnalyzer(random));\n    //Query query = parser.parse(\"handle:1\");\n\n    IndexReader reader = IndexReader.open(dir);\n    IndexSearcher searcher = new IndexSearcher(reader);\n\n    _TestUtil.checkIndex(dir);\n\n    final Bits liveDocs = MultiFields.getLiveDocs(reader);\n\n    for(int i=0;i<35;i++) {\n      if (liveDocs.get(i)) {\n        Document d = reader.document(i);\n        List<IndexableField> fields = d.getFields();\n        if (d.getField(\"content3\") == null) {\n          final int numFields = 5;\n          assertEquals(numFields, fields.size());\n          IndexableField f =  d.getField(\"id\");\n          assertEquals(\"\"+i, f.stringValue());\n\n          f = d.getField(\"utf8\");\n          assertEquals(\"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne \\u0000 \\u2620 ab\\ud917\\udc17cd\", f.stringValue());\n\n          f =  d.getField(\"autf8\");\n          assertEquals(\"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne \\u0000 \\u2620 ab\\ud917\\udc17cd\", f.stringValue());\n      \n          f = d.getField(\"content2\");\n          assertEquals(\"here is more content with aaa aaa aaa\", f.stringValue());\n\n          f = d.getField(\"fie\\u2C77ld\");\n          assertEquals(\"field with non-ascii name\", f.stringValue());\n        }\n\n        Terms tfv = reader.getTermVectors(i).terms(\"utf8\");\n        assertNotNull(\"docID=\" + i + \" index=\" + oldName, tfv);\n      } else\n        // Only ID 7 is deleted\n        assertEquals(7, i);\n    }\n    \n    ScoreDoc[] hits = searcher.search(new TermQuery(new Term(new String(\"content\"), \"aaa\")), null, 1000).scoreDocs;\n\n    // First document should be #21 since it's norm was\n    // increased:\n    Document d = searcher.getIndexReader().document(hits[0].doc);\n    assertEquals(\"didn't get the right document first\", \"21\", d.get(\"id\"));\n\n    doTestHits(hits, 34, searcher.getIndexReader());\n\n    hits = searcher.search(new TermQuery(new Term(\"utf8\", \"\\u0000\")), null, 1000).scoreDocs;\n    assertEquals(34, hits.length);\n    hits = searcher.search(new TermQuery(new Term(new String(\"utf8\"), \"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne\")), null, 1000).scoreDocs;\n    assertEquals(34, hits.length);\n    hits = searcher.search(new TermQuery(new Term(\"utf8\", \"ab\\ud917\\udc17cd\")), null, 1000).scoreDocs;\n    assertEquals(34, hits.length);\n\n    reader.close();\n  }\n\n","sourceOld":"  public void searchIndex(Directory dir, String oldName) throws IOException {\n    //QueryParser parser = new QueryParser(\"contents\", new MockAnalyzer(random));\n    //Query query = parser.parse(\"handle:1\");\n\n    IndexReader reader = IndexReader.open(dir);\n    IndexSearcher searcher = new IndexSearcher(reader);\n\n    _TestUtil.checkIndex(dir);\n\n    final Bits liveDocs = MultiFields.getLiveDocs(reader);\n\n    for(int i=0;i<35;i++) {\n      if (liveDocs.get(i)) {\n        Document d = reader.document(i);\n        List<IndexableField> fields = d.getFields();\n        if (d.getField(\"content3\") == null) {\n          final int numFields = 5;\n          assertEquals(numFields, fields.size());\n          IndexableField f =  d.getField(\"id\");\n          assertEquals(\"\"+i, f.stringValue());\n\n          f = d.getField(\"utf8\");\n          assertEquals(\"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne \\u0000 \\u2620 ab\\ud917\\udc17cd\", f.stringValue());\n\n          f =  d.getField(\"autf8\");\n          assertEquals(\"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne \\u0000 \\u2620 ab\\ud917\\udc17cd\", f.stringValue());\n      \n          f = d.getField(\"content2\");\n          assertEquals(\"here is more content with aaa aaa aaa\", f.stringValue());\n\n          f = d.getField(\"fie\\u2C77ld\");\n          assertEquals(\"field with non-ascii name\", f.stringValue());\n        }\n\n        Terms tfv = reader.getTermVectors(i).terms(\"utf8\");\n        assertNotNull(\"docID=\" + i + \" index=\" + oldName, tfv);\n      } else\n        // Only ID 7 is deleted\n        assertEquals(7, i);\n    }\n    \n    ScoreDoc[] hits = searcher.search(new TermQuery(new Term(\"content\", \"aaa\")), null, 1000).scoreDocs;\n\n    // First document should be #21 since it's norm was\n    // increased:\n    Document d = searcher.getIndexReader().document(hits[0].doc);\n    assertEquals(\"didn't get the right document first\", \"21\", d.get(\"id\"));\n\n    doTestHits(hits, 34, searcher.getIndexReader());\n\n    hits = searcher.search(new TermQuery(new Term(\"utf8\", \"\\u0000\")), null, 1000).scoreDocs;\n    assertEquals(34, hits.length);\n    hits = searcher.search(new TermQuery(new Term(\"utf8\", \"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne\")), null, 1000).scoreDocs;\n    assertEquals(34, hits.length);\n    hits = searcher.search(new TermQuery(new Term(\"utf8\", \"ab\\ud917\\udc17cd\")), null, 1000).scoreDocs;\n    assertEquals(34, hits.length);\n\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"3599646b4d4c346cf74d334813488b8b337b5bf5","date":1337790261,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestBackwardsCompatibility#searchIndex(Directory,String).mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestBackwardsCompatibility#searchIndex(Directory,String).mjava","sourceNew":"  public void searchIndex(Directory dir, String oldName) throws IOException {\n    //QueryParser parser = new QueryParser(\"contents\", new MockAnalyzer(random));\n    //Query query = parser.parse(\"handle:1\");\n\n    IndexReader reader = IndexReader.open(dir);\n    IndexSearcher searcher = new IndexSearcher(reader);\n\n    _TestUtil.checkIndex(dir);\n\n    final Bits liveDocs = MultiFields.getLiveDocs(reader);\n\n    for(int i=0;i<35;i++) {\n      if (liveDocs.get(i)) {\n        Document d = reader.document(i);\n        List<IndexableField> fields = d.getFields();\n        if (d.getField(\"content3\") == null) {\n          final int numFields = 5;\n          assertEquals(numFields, fields.size());\n          IndexableField f =  d.getField(\"id\");\n          assertEquals(\"\"+i, f.stringValue());\n\n          f = d.getField(\"utf8\");\n          assertEquals(\"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne \\u0000 \\u2620 ab\\ud917\\udc17cd\", f.stringValue());\n\n          f =  d.getField(\"autf8\");\n          assertEquals(\"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne \\u0000 \\u2620 ab\\ud917\\udc17cd\", f.stringValue());\n      \n          f = d.getField(\"content2\");\n          assertEquals(\"here is more content with aaa aaa aaa\", f.stringValue());\n\n          f = d.getField(\"fie\\u2C77ld\");\n          assertEquals(\"field with non-ascii name\", f.stringValue());\n        }\n\n        Fields tfvFields = reader.getTermVectors(i);\n        assertNotNull(\"i=\" + i, tfvFields);\n        Terms tfv = tfvFields.terms(\"utf8\");\n        assertNotNull(\"docID=\" + i + \" index=\" + oldName, tfv);\n      } else {\n        // Only ID 7 is deleted\n        assertEquals(7, i);\n      }\n    }\n    \n    ScoreDoc[] hits = searcher.search(new TermQuery(new Term(new String(\"content\"), \"aaa\")), null, 1000).scoreDocs;\n\n    // First document should be #21 since it's norm was\n    // increased:\n    Document d = searcher.getIndexReader().document(hits[0].doc);\n    assertEquals(\"didn't get the right document first\", \"21\", d.get(\"id\"));\n\n    doTestHits(hits, 34, searcher.getIndexReader());\n\n    hits = searcher.search(new TermQuery(new Term(\"utf8\", \"\\u0000\")), null, 1000).scoreDocs;\n    assertEquals(34, hits.length);\n    hits = searcher.search(new TermQuery(new Term(new String(\"utf8\"), \"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne\")), null, 1000).scoreDocs;\n    assertEquals(34, hits.length);\n    hits = searcher.search(new TermQuery(new Term(\"utf8\", \"ab\\ud917\\udc17cd\")), null, 1000).scoreDocs;\n    assertEquals(34, hits.length);\n\n    reader.close();\n  }\n\n","sourceOld":"  public void searchIndex(Directory dir, String oldName) throws IOException {\n    //QueryParser parser = new QueryParser(\"contents\", new MockAnalyzer(random));\n    //Query query = parser.parse(\"handle:1\");\n\n    IndexReader reader = IndexReader.open(dir);\n    IndexSearcher searcher = new IndexSearcher(reader);\n\n    _TestUtil.checkIndex(dir);\n\n    final Bits liveDocs = MultiFields.getLiveDocs(reader);\n\n    for(int i=0;i<35;i++) {\n      if (liveDocs.get(i)) {\n        Document d = reader.document(i);\n        List<IndexableField> fields = d.getFields();\n        if (d.getField(\"content3\") == null) {\n          final int numFields = 5;\n          assertEquals(numFields, fields.size());\n          IndexableField f =  d.getField(\"id\");\n          assertEquals(\"\"+i, f.stringValue());\n\n          f = d.getField(\"utf8\");\n          assertEquals(\"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne \\u0000 \\u2620 ab\\ud917\\udc17cd\", f.stringValue());\n\n          f =  d.getField(\"autf8\");\n          assertEquals(\"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne \\u0000 \\u2620 ab\\ud917\\udc17cd\", f.stringValue());\n      \n          f = d.getField(\"content2\");\n          assertEquals(\"here is more content with aaa aaa aaa\", f.stringValue());\n\n          f = d.getField(\"fie\\u2C77ld\");\n          assertEquals(\"field with non-ascii name\", f.stringValue());\n        }\n\n        Fields tfvFields = reader.getTermVectors(i);\n        assertNotNull(\"i=\" + i, tfvFields);\n        Terms tfv = tfvFields.terms(\"utf8\");\n        assertNotNull(\"docID=\" + i + \" index=\" + oldName, tfv);\n      } else {\n        // Only ID 7 is deleted\n        assertEquals(7, i);\n      }\n    }\n    \n    ScoreDoc[] hits = searcher.search(new TermQuery(new Term(\"content\", \"aaa\")), null, 1000).scoreDocs;\n\n    // First document should be #21 since it's norm was\n    // increased:\n    Document d = searcher.getIndexReader().document(hits[0].doc);\n    assertEquals(\"didn't get the right document first\", \"21\", d.get(\"id\"));\n\n    doTestHits(hits, 34, searcher.getIndexReader());\n\n    hits = searcher.search(new TermQuery(new Term(\"utf8\", \"\\u0000\")), null, 1000).scoreDocs;\n    assertEquals(34, hits.length);\n    hits = searcher.search(new TermQuery(new Term(\"utf8\", \"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne\")), null, 1000).scoreDocs;\n    assertEquals(34, hits.length);\n    hits = searcher.search(new TermQuery(new Term(\"utf8\", \"ab\\ud917\\udc17cd\")), null, 1000).scoreDocs;\n    assertEquals(34, hits.length);\n\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"615ddbd81799980d0fdd95e0238e1c498b6f47b0","date":1338233290,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestBackwardsCompatibility#searchIndex(Directory,String).mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestBackwardsCompatibility#searchIndex(Directory,String).mjava","sourceNew":"  public void searchIndex(Directory dir, String oldName) throws IOException {\n    //QueryParser parser = new QueryParser(\"contents\", new MockAnalyzer(random));\n    //Query query = parser.parse(\"handle:1\");\n\n    IndexReader reader = IndexReader.open(dir);\n    IndexSearcher searcher = new IndexSearcher(reader);\n\n    _TestUtil.checkIndex(dir);\n\n    final Bits liveDocs = MultiFields.getLiveDocs(reader);\n\n    for(int i=0;i<35;i++) {\n      if (liveDocs.get(i)) {\n        Document d = reader.document(i);\n        List<IndexableField> fields = d.getFields();\n        if (d.getField(\"content3\") == null) {\n          final int numFields = 5;\n          assertEquals(numFields, fields.size());\n          IndexableField f =  d.getField(\"id\");\n          assertEquals(\"\"+i, f.stringValue());\n\n          f = d.getField(\"utf8\");\n          assertEquals(\"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne \\u0000 \\u2620 ab\\ud917\\udc17cd\", f.stringValue());\n\n          f =  d.getField(\"autf8\");\n          assertEquals(\"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne \\u0000 \\u2620 ab\\ud917\\udc17cd\", f.stringValue());\n      \n          f = d.getField(\"content2\");\n          assertEquals(\"here is more content with aaa aaa aaa\", f.stringValue());\n\n          f = d.getField(\"fie\\u2C77ld\");\n          assertEquals(\"field with non-ascii name\", f.stringValue());\n        }\n\n        Fields tfvFields = reader.getTermVectors(i);\n        assertNotNull(\"i=\" + i, tfvFields);\n        Terms tfv = tfvFields.terms(\"utf8\");\n        assertNotNull(\"docID=\" + i + \" index=\" + oldName, tfv);\n      } else {\n        // Only ID 7 is deleted\n        assertEquals(7, i);\n      }\n    }\n    \n    ScoreDoc[] hits = searcher.search(new TermQuery(new Term(new String(\"content\"), \"aaa\")), null, 1000).scoreDocs;\n\n    // First document should be #21 since it's norm was\n    // increased:\n    Document d = searcher.getIndexReader().document(hits[0].doc);\n    assertEquals(\"didn't get the right document first\", \"21\", d.get(\"id\"));\n\n    doTestHits(hits, 34, searcher.getIndexReader());\n\n    hits = searcher.search(new TermQuery(new Term(\"utf8\", \"\\u0000\")), null, 1000).scoreDocs;\n    assertEquals(34, hits.length);\n    hits = searcher.search(new TermQuery(new Term(new String(\"utf8\"), \"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne\")), null, 1000).scoreDocs;\n    assertEquals(34, hits.length);\n    hits = searcher.search(new TermQuery(new Term(\"utf8\", \"ab\\ud917\\udc17cd\")), null, 1000).scoreDocs;\n    assertEquals(34, hits.length);\n\n    reader.close();\n  }\n\n","sourceOld":"  public void searchIndex(Directory dir, String oldName) throws IOException {\n    //QueryParser parser = new QueryParser(\"contents\", new MockAnalyzer(random));\n    //Query query = parser.parse(\"handle:1\");\n\n    IndexReader reader = IndexReader.open(dir);\n    IndexSearcher searcher = new IndexSearcher(reader);\n\n    _TestUtil.checkIndex(dir);\n\n    final Bits liveDocs = MultiFields.getLiveDocs(reader);\n\n    for(int i=0;i<35;i++) {\n      if (liveDocs.get(i)) {\n        Document d = reader.document(i);\n        List<IndexableField> fields = d.getFields();\n        if (d.getField(\"content3\") == null) {\n          final int numFields = 5;\n          assertEquals(numFields, fields.size());\n          IndexableField f =  d.getField(\"id\");\n          assertEquals(\"\"+i, f.stringValue());\n\n          f = d.getField(\"utf8\");\n          assertEquals(\"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne \\u0000 \\u2620 ab\\ud917\\udc17cd\", f.stringValue());\n\n          f =  d.getField(\"autf8\");\n          assertEquals(\"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne \\u0000 \\u2620 ab\\ud917\\udc17cd\", f.stringValue());\n      \n          f = d.getField(\"content2\");\n          assertEquals(\"here is more content with aaa aaa aaa\", f.stringValue());\n\n          f = d.getField(\"fie\\u2C77ld\");\n          assertEquals(\"field with non-ascii name\", f.stringValue());\n        }\n\n        Terms tfv = reader.getTermVectors(i).terms(\"utf8\");\n        assertNotNull(\"docID=\" + i + \" index=\" + oldName, tfv);\n      } else\n        // Only ID 7 is deleted\n        assertEquals(7, i);\n    }\n    \n    ScoreDoc[] hits = searcher.search(new TermQuery(new Term(new String(\"content\"), \"aaa\")), null, 1000).scoreDocs;\n\n    // First document should be #21 since it's norm was\n    // increased:\n    Document d = searcher.getIndexReader().document(hits[0].doc);\n    assertEquals(\"didn't get the right document first\", \"21\", d.get(\"id\"));\n\n    doTestHits(hits, 34, searcher.getIndexReader());\n\n    hits = searcher.search(new TermQuery(new Term(\"utf8\", \"\\u0000\")), null, 1000).scoreDocs;\n    assertEquals(34, hits.length);\n    hits = searcher.search(new TermQuery(new Term(new String(\"utf8\"), \"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne\")), null, 1000).scoreDocs;\n    assertEquals(34, hits.length);\n    hits = searcher.search(new TermQuery(new Term(\"utf8\", \"ab\\ud917\\udc17cd\")), null, 1000).scoreDocs;\n    assertEquals(34, hits.length);\n\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"57ae3024996ccdb3c36c42cb890e1efb37df4ce8","date":1338343651,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestBackwardsCompatibility#searchIndex(Directory,String).mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestBackwardsCompatibility#searchIndex(Directory,String).mjava","sourceNew":"  public void searchIndex(Directory dir, String oldName) throws IOException {\n    //QueryParser parser = new QueryParser(\"contents\", new MockAnalyzer(random));\n    //Query query = parser.parse(\"handle:1\");\n\n    IndexReader reader = IndexReader.open(dir);\n    IndexSearcher searcher = new IndexSearcher(reader);\n\n    _TestUtil.checkIndex(dir);\n\n    final Bits liveDocs = MultiFields.getLiveDocs(reader);\n\n    for(int i=0;i<35;i++) {\n      if (liveDocs.get(i)) {\n        Document d = reader.document(i);\n        List<IndexableField> fields = d.getFields();\n        if (d.getField(\"content3\") == null) {\n          final int numFields = 5;\n          assertEquals(numFields, fields.size());\n          IndexableField f =  d.getField(\"id\");\n          assertEquals(\"\"+i, f.stringValue());\n\n          f = d.getField(\"utf8\");\n          assertEquals(\"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne \\u0000 \\u2620 ab\\ud917\\udc17cd\", f.stringValue());\n\n          f =  d.getField(\"autf8\");\n          assertEquals(\"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne \\u0000 \\u2620 ab\\ud917\\udc17cd\", f.stringValue());\n      \n          f = d.getField(\"content2\");\n          assertEquals(\"here is more content with aaa aaa aaa\", f.stringValue());\n\n          f = d.getField(\"fie\\u2C77ld\");\n          assertEquals(\"field with non-ascii name\", f.stringValue());\n        }\n\n        Fields tfvFields = reader.getTermVectors(i);\n        assertNotNull(\"i=\" + i, tfvFields);\n        Terms tfv = tfvFields.terms(\"utf8\");\n        assertNotNull(\"docID=\" + i + \" index=\" + oldName, tfv);\n      } else {\n        // Only ID 7 is deleted\n        assertEquals(7, i);\n      }\n    }\n    \n    ScoreDoc[] hits = searcher.search(new TermQuery(new Term(new String(\"content\"), \"aaa\")), null, 1000).scoreDocs;\n\n    // First document should be #0\n    Document d = searcher.getIndexReader().document(hits[0].doc);\n    assertEquals(\"didn't get the right document first\", \"0\", d.get(\"id\"));\n\n    doTestHits(hits, 34, searcher.getIndexReader());\n\n    hits = searcher.search(new TermQuery(new Term(\"utf8\", \"\\u0000\")), null, 1000).scoreDocs;\n    assertEquals(34, hits.length);\n    hits = searcher.search(new TermQuery(new Term(new String(\"utf8\"), \"lu\\uD834\\uDD1Ece\\uD834\\uDD60ne\")), null, 1000).scoreDocs;\n    assertEquals(34, hits.length);\n    hits = searcher.search(new TermQuery(new Term(\"utf8\", \"ab\\ud917\\udc17cd\")), null, 1000).scoreDocs;\n    assertEquals(34, hits.length);\n\n    reader.close();\n  }\n\n","sourceOld":"  public void searchIndex(Directory dir, String oldName) throws IOException {\n    //QueryParser parser = new QueryParser(\"contents\", new MockAnalyzer(random));\n    //Query query = parser.parse(\"handle:1\");\n\n    IndexReader reader = IndexReader.open(dir);\n    IndexSearcher searcher = new IndexSearcher(reader);\n\n    _TestUtil.checkIndex(dir);\n\n    final Bits liveDocs = MultiFields.getLiveDocs(reader);\n\n    for(int i=0;i<35;i++) {\n      if (liveDocs.get(i)) {\n        Document d = reader.document(i);\n        List<IndexableField> fields = d.getFields();\n        if (d.getField(\"content3\") == null) {\n          final int numFields = 5;\n          assertEquals(numFields, fields.size());\n          IndexableField f =  d.getField(\"id\");\n          assertEquals(\"\"+i, f.stringValue());\n\n          f = d.getField(\"utf8\");\n          assertEquals(\"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne \\u0000 \\u2620 ab\\ud917\\udc17cd\", f.stringValue());\n\n          f =  d.getField(\"autf8\");\n          assertEquals(\"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne \\u0000 \\u2620 ab\\ud917\\udc17cd\", f.stringValue());\n      \n          f = d.getField(\"content2\");\n          assertEquals(\"here is more content with aaa aaa aaa\", f.stringValue());\n\n          f = d.getField(\"fie\\u2C77ld\");\n          assertEquals(\"field with non-ascii name\", f.stringValue());\n        }\n\n        Fields tfvFields = reader.getTermVectors(i);\n        assertNotNull(\"i=\" + i, tfvFields);\n        Terms tfv = tfvFields.terms(\"utf8\");\n        assertNotNull(\"docID=\" + i + \" index=\" + oldName, tfv);\n      } else {\n        // Only ID 7 is deleted\n        assertEquals(7, i);\n      }\n    }\n    \n    ScoreDoc[] hits = searcher.search(new TermQuery(new Term(new String(\"content\"), \"aaa\")), null, 1000).scoreDocs;\n\n    // First document should be #21 since it's norm was\n    // increased:\n    Document d = searcher.getIndexReader().document(hits[0].doc);\n    assertEquals(\"didn't get the right document first\", \"21\", d.get(\"id\"));\n\n    doTestHits(hits, 34, searcher.getIndexReader());\n\n    hits = searcher.search(new TermQuery(new Term(\"utf8\", \"\\u0000\")), null, 1000).scoreDocs;\n    assertEquals(34, hits.length);\n    hits = searcher.search(new TermQuery(new Term(new String(\"utf8\"), \"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne\")), null, 1000).scoreDocs;\n    assertEquals(34, hits.length);\n    hits = searcher.search(new TermQuery(new Term(\"utf8\", \"ab\\ud917\\udc17cd\")), null, 1000).scoreDocs;\n    assertEquals(34, hits.length);\n\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"e7e8d6f15900ee22ac3cb0a503f15dc952a3580f","date":1338430031,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestBackwardsCompatibility#searchIndex(Directory,String).mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestBackwardsCompatibility#searchIndex(Directory,String).mjava","sourceNew":"  public void searchIndex(Directory dir, String oldName) throws IOException {\n    //QueryParser parser = new QueryParser(\"contents\", new MockAnalyzer(random));\n    //Query query = parser.parse(\"handle:1\");\n\n    IndexReader reader = DirectoryReader.open(dir);\n    IndexSearcher searcher = new IndexSearcher(reader);\n\n    _TestUtil.checkIndex(dir);\n\n    final Bits liveDocs = MultiFields.getLiveDocs(reader);\n\n    for(int i=0;i<35;i++) {\n      if (liveDocs.get(i)) {\n        Document d = reader.document(i);\n        List<IndexableField> fields = d.getFields();\n        if (d.getField(\"content3\") == null) {\n          final int numFields = 5;\n          assertEquals(numFields, fields.size());\n          IndexableField f =  d.getField(\"id\");\n          assertEquals(\"\"+i, f.stringValue());\n\n          f = d.getField(\"utf8\");\n          assertEquals(\"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne \\u0000 \\u2620 ab\\ud917\\udc17cd\", f.stringValue());\n\n          f =  d.getField(\"autf8\");\n          assertEquals(\"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne \\u0000 \\u2620 ab\\ud917\\udc17cd\", f.stringValue());\n      \n          f = d.getField(\"content2\");\n          assertEquals(\"here is more content with aaa aaa aaa\", f.stringValue());\n\n          f = d.getField(\"fie\\u2C77ld\");\n          assertEquals(\"field with non-ascii name\", f.stringValue());\n        }\n\n        Fields tfvFields = reader.getTermVectors(i);\n        assertNotNull(\"i=\" + i, tfvFields);\n        Terms tfv = tfvFields.terms(\"utf8\");\n        assertNotNull(\"docID=\" + i + \" index=\" + oldName, tfv);\n      } else {\n        // Only ID 7 is deleted\n        assertEquals(7, i);\n      }\n    }\n    \n    ScoreDoc[] hits = searcher.search(new TermQuery(new Term(new String(\"content\"), \"aaa\")), null, 1000).scoreDocs;\n\n    // First document should be #0\n    Document d = searcher.getIndexReader().document(hits[0].doc);\n    assertEquals(\"didn't get the right document first\", \"0\", d.get(\"id\"));\n\n    doTestHits(hits, 34, searcher.getIndexReader());\n\n    hits = searcher.search(new TermQuery(new Term(\"utf8\", \"\\u0000\")), null, 1000).scoreDocs;\n    assertEquals(34, hits.length);\n    hits = searcher.search(new TermQuery(new Term(new String(\"utf8\"), \"lu\\uD834\\uDD1Ece\\uD834\\uDD60ne\")), null, 1000).scoreDocs;\n    assertEquals(34, hits.length);\n    hits = searcher.search(new TermQuery(new Term(\"utf8\", \"ab\\ud917\\udc17cd\")), null, 1000).scoreDocs;\n    assertEquals(34, hits.length);\n\n    reader.close();\n  }\n\n","sourceOld":"  public void searchIndex(Directory dir, String oldName) throws IOException {\n    //QueryParser parser = new QueryParser(\"contents\", new MockAnalyzer(random));\n    //Query query = parser.parse(\"handle:1\");\n\n    IndexReader reader = IndexReader.open(dir);\n    IndexSearcher searcher = new IndexSearcher(reader);\n\n    _TestUtil.checkIndex(dir);\n\n    final Bits liveDocs = MultiFields.getLiveDocs(reader);\n\n    for(int i=0;i<35;i++) {\n      if (liveDocs.get(i)) {\n        Document d = reader.document(i);\n        List<IndexableField> fields = d.getFields();\n        if (d.getField(\"content3\") == null) {\n          final int numFields = 5;\n          assertEquals(numFields, fields.size());\n          IndexableField f =  d.getField(\"id\");\n          assertEquals(\"\"+i, f.stringValue());\n\n          f = d.getField(\"utf8\");\n          assertEquals(\"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne \\u0000 \\u2620 ab\\ud917\\udc17cd\", f.stringValue());\n\n          f =  d.getField(\"autf8\");\n          assertEquals(\"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne \\u0000 \\u2620 ab\\ud917\\udc17cd\", f.stringValue());\n      \n          f = d.getField(\"content2\");\n          assertEquals(\"here is more content with aaa aaa aaa\", f.stringValue());\n\n          f = d.getField(\"fie\\u2C77ld\");\n          assertEquals(\"field with non-ascii name\", f.stringValue());\n        }\n\n        Fields tfvFields = reader.getTermVectors(i);\n        assertNotNull(\"i=\" + i, tfvFields);\n        Terms tfv = tfvFields.terms(\"utf8\");\n        assertNotNull(\"docID=\" + i + \" index=\" + oldName, tfv);\n      } else {\n        // Only ID 7 is deleted\n        assertEquals(7, i);\n      }\n    }\n    \n    ScoreDoc[] hits = searcher.search(new TermQuery(new Term(new String(\"content\"), \"aaa\")), null, 1000).scoreDocs;\n\n    // First document should be #0\n    Document d = searcher.getIndexReader().document(hits[0].doc);\n    assertEquals(\"didn't get the right document first\", \"0\", d.get(\"id\"));\n\n    doTestHits(hits, 34, searcher.getIndexReader());\n\n    hits = searcher.search(new TermQuery(new Term(\"utf8\", \"\\u0000\")), null, 1000).scoreDocs;\n    assertEquals(34, hits.length);\n    hits = searcher.search(new TermQuery(new Term(new String(\"utf8\"), \"lu\\uD834\\uDD1Ece\\uD834\\uDD60ne\")), null, 1000).scoreDocs;\n    assertEquals(34, hits.length);\n    hits = searcher.search(new TermQuery(new Term(\"utf8\", \"ab\\ud917\\udc17cd\")), null, 1000).scoreDocs;\n    assertEquals(34, hits.length);\n\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"5a3b444707abab6c7f63c331b3f44971c53b0f07","date":1339533739,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestBackwardsCompatibility#searchIndex(Directory,String).mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestBackwardsCompatibility#searchIndex(Directory,String).mjava","sourceNew":"  public void searchIndex(Directory dir, String oldName) throws IOException {\n    //QueryParser parser = new QueryParser(\"contents\", new MockAnalyzer(random));\n    //Query query = parser.parse(\"handle:1\");\n\n    IndexReader reader = DirectoryReader.open(dir);\n    IndexSearcher searcher = new IndexSearcher(reader);\n\n    _TestUtil.checkIndex(dir);\n    \n    // true if this is a 4.0+ index\n    final boolean is40Index = MultiFields.getMergedFieldInfos(reader).fieldInfo(\"content5\") != null;\n    assert is40Index; // NOTE: currently we can only do this on trunk!\n\n    final Bits liveDocs = MultiFields.getLiveDocs(reader);\n\n    for(int i=0;i<35;i++) {\n      if (liveDocs.get(i)) {\n        Document d = reader.document(i);\n        List<IndexableField> fields = d.getFields();\n        boolean isProxDoc = d.getField(\"content3\") == null;\n        if (isProxDoc) {\n          final int numFields = is40Index ? 7 : 5;\n          assertEquals(numFields, fields.size());\n          IndexableField f =  d.getField(\"id\");\n          assertEquals(\"\"+i, f.stringValue());\n\n          f = d.getField(\"utf8\");\n          assertEquals(\"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne \\u0000 \\u2620 ab\\ud917\\udc17cd\", f.stringValue());\n\n          f =  d.getField(\"autf8\");\n          assertEquals(\"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne \\u0000 \\u2620 ab\\ud917\\udc17cd\", f.stringValue());\n      \n          f = d.getField(\"content2\");\n          assertEquals(\"here is more content with aaa aaa aaa\", f.stringValue());\n\n          f = d.getField(\"fie\\u2C77ld\");\n          assertEquals(\"field with non-ascii name\", f.stringValue());\n        }\n\n        Fields tfvFields = reader.getTermVectors(i);\n        assertNotNull(\"i=\" + i, tfvFields);\n        Terms tfv = tfvFields.terms(\"utf8\");\n        assertNotNull(\"docID=\" + i + \" index=\" + oldName, tfv);\n      } else {\n        // Only ID 7 is deleted\n        assertEquals(7, i);\n      }\n    }\n    \n    if (is40Index) {\n      // check docvalues fields\n      Source dvByte = MultiDocValues.getDocValues(reader, \"dvByte\").getSource();\n      Source dvBytesDerefFixed = MultiDocValues.getDocValues(reader, \"dvBytesDerefFixed\").getSource();\n      Source dvBytesDerefVar = MultiDocValues.getDocValues(reader, \"dvBytesDerefVar\").getSource();\n      Source dvBytesSortedFixed = MultiDocValues.getDocValues(reader, \"dvBytesSortedFixed\").getSource();\n      Source dvBytesSortedVar = MultiDocValues.getDocValues(reader, \"dvBytesSortedVar\").getSource();\n      Source dvBytesStraightFixed = MultiDocValues.getDocValues(reader, \"dvBytesStraightFixed\").getSource();\n      Source dvBytesStraightVar = MultiDocValues.getDocValues(reader, \"dvBytesStraightVar\").getSource();\n      Source dvDouble = MultiDocValues.getDocValues(reader, \"dvDouble\").getSource();\n      Source dvFloat = MultiDocValues.getDocValues(reader, \"dvFloat\").getSource();\n      Source dvInt = MultiDocValues.getDocValues(reader, \"dvInt\").getSource();\n      Source dvLong = MultiDocValues.getDocValues(reader, \"dvLong\").getSource();\n      Source dvPacked = MultiDocValues.getDocValues(reader, \"dvPacked\").getSource();\n      Source dvShort = MultiDocValues.getDocValues(reader, \"dvShort\").getSource();\n      \n      for (int i=0;i<35;i++) {\n        int id = Integer.parseInt(reader.document(i).get(\"id\"));\n        assertEquals((byte)id, dvByte.getInt(i));\n        \n        byte bytes[] = new byte[] {\n            (byte)(id >>> 24), (byte)(id >>> 16),(byte)(id >>> 8),(byte)id\n        };\n        BytesRef expectedRef = new BytesRef(bytes);\n        BytesRef scratch = new BytesRef();\n        \n        assertEquals(expectedRef, dvBytesDerefFixed.getBytes(i, scratch));\n        assertEquals(expectedRef, dvBytesDerefVar.getBytes(i, scratch));\n        assertEquals(expectedRef, dvBytesSortedFixed.getBytes(i, scratch));\n        assertEquals(expectedRef, dvBytesSortedVar.getBytes(i, scratch));\n        assertEquals(expectedRef, dvBytesStraightFixed.getBytes(i, scratch));\n        assertEquals(expectedRef, dvBytesStraightVar.getBytes(i, scratch));\n        \n        assertEquals((double)id, dvDouble.getFloat(i), 0D);\n        assertEquals((float)id, dvFloat.getFloat(i), 0F);\n        assertEquals(id, dvInt.getInt(i));\n        assertEquals(id, dvLong.getInt(i));\n        assertEquals(id, dvPacked.getInt(i));\n        assertEquals(id, dvShort.getInt(i));\n      }\n    }\n    \n    ScoreDoc[] hits = searcher.search(new TermQuery(new Term(new String(\"content\"), \"aaa\")), null, 1000).scoreDocs;\n\n    // First document should be #0\n    Document d = searcher.getIndexReader().document(hits[0].doc);\n    assertEquals(\"didn't get the right document first\", \"0\", d.get(\"id\"));\n\n    doTestHits(hits, 34, searcher.getIndexReader());\n    \n    if (is40Index) {\n      hits = searcher.search(new TermQuery(new Term(new String(\"content5\"), \"aaa\")), null, 1000).scoreDocs;\n\n      doTestHits(hits, 34, searcher.getIndexReader());\n    \n      hits = searcher.search(new TermQuery(new Term(new String(\"content6\"), \"aaa\")), null, 1000).scoreDocs;\n\n      doTestHits(hits, 34, searcher.getIndexReader());\n    }\n\n    hits = searcher.search(new TermQuery(new Term(\"utf8\", \"\\u0000\")), null, 1000).scoreDocs;\n    assertEquals(34, hits.length);\n    hits = searcher.search(new TermQuery(new Term(new String(\"utf8\"), \"lu\\uD834\\uDD1Ece\\uD834\\uDD60ne\")), null, 1000).scoreDocs;\n    assertEquals(34, hits.length);\n    hits = searcher.search(new TermQuery(new Term(\"utf8\", \"ab\\ud917\\udc17cd\")), null, 1000).scoreDocs;\n    assertEquals(34, hits.length);\n\n    reader.close();\n  }\n\n","sourceOld":"  public void searchIndex(Directory dir, String oldName) throws IOException {\n    //QueryParser parser = new QueryParser(\"contents\", new MockAnalyzer(random));\n    //Query query = parser.parse(\"handle:1\");\n\n    IndexReader reader = DirectoryReader.open(dir);\n    IndexSearcher searcher = new IndexSearcher(reader);\n\n    _TestUtil.checkIndex(dir);\n\n    final Bits liveDocs = MultiFields.getLiveDocs(reader);\n\n    for(int i=0;i<35;i++) {\n      if (liveDocs.get(i)) {\n        Document d = reader.document(i);\n        List<IndexableField> fields = d.getFields();\n        if (d.getField(\"content3\") == null) {\n          final int numFields = 5;\n          assertEquals(numFields, fields.size());\n          IndexableField f =  d.getField(\"id\");\n          assertEquals(\"\"+i, f.stringValue());\n\n          f = d.getField(\"utf8\");\n          assertEquals(\"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne \\u0000 \\u2620 ab\\ud917\\udc17cd\", f.stringValue());\n\n          f =  d.getField(\"autf8\");\n          assertEquals(\"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne \\u0000 \\u2620 ab\\ud917\\udc17cd\", f.stringValue());\n      \n          f = d.getField(\"content2\");\n          assertEquals(\"here is more content with aaa aaa aaa\", f.stringValue());\n\n          f = d.getField(\"fie\\u2C77ld\");\n          assertEquals(\"field with non-ascii name\", f.stringValue());\n        }\n\n        Fields tfvFields = reader.getTermVectors(i);\n        assertNotNull(\"i=\" + i, tfvFields);\n        Terms tfv = tfvFields.terms(\"utf8\");\n        assertNotNull(\"docID=\" + i + \" index=\" + oldName, tfv);\n      } else {\n        // Only ID 7 is deleted\n        assertEquals(7, i);\n      }\n    }\n    \n    ScoreDoc[] hits = searcher.search(new TermQuery(new Term(new String(\"content\"), \"aaa\")), null, 1000).scoreDocs;\n\n    // First document should be #0\n    Document d = searcher.getIndexReader().document(hits[0].doc);\n    assertEquals(\"didn't get the right document first\", \"0\", d.get(\"id\"));\n\n    doTestHits(hits, 34, searcher.getIndexReader());\n\n    hits = searcher.search(new TermQuery(new Term(\"utf8\", \"\\u0000\")), null, 1000).scoreDocs;\n    assertEquals(34, hits.length);\n    hits = searcher.search(new TermQuery(new Term(new String(\"utf8\"), \"lu\\uD834\\uDD1Ece\\uD834\\uDD60ne\")), null, 1000).scoreDocs;\n    assertEquals(34, hits.length);\n    hits = searcher.search(new TermQuery(new Term(\"utf8\", \"ab\\ud917\\udc17cd\")), null, 1000).scoreDocs;\n    assertEquals(34, hits.length);\n\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":["d4d69c535930b5cce125cff868d40f6373dc27d4"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"8f0e28f2a7f0f3f0fca1a2ffedaa10c7ac9536c4","date":1341839195,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestBackwardsCompatibility#searchIndex(Directory,String).mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestBackwardsCompatibility#searchIndex(Directory,String).mjava","sourceNew":"  public void searchIndex(Directory dir, String oldName) throws IOException {\n    //QueryParser parser = new QueryParser(\"contents\", new MockAnalyzer(random));\n    //Query query = parser.parse(\"handle:1\");\n\n    IndexReader reader = DirectoryReader.open(dir);\n    IndexSearcher searcher = new IndexSearcher(reader);\n\n    _TestUtil.checkIndex(dir);\n    \n    // true if this is a 4.0+ index\n    final boolean is40Index = MultiFields.getMergedFieldInfos(reader).fieldInfo(\"content5\") != null;\n    assert is40Index; // NOTE: currently we can only do this on trunk!\n\n    final Bits liveDocs = MultiFields.getLiveDocs(reader);\n\n    for(int i=0;i<35;i++) {\n      if (liveDocs.get(i)) {\n        StoredDocument d = reader.document(i);\n        List<StorableField> fields = d.getFields();\n        boolean isProxDoc = d.getField(\"content3\") == null;\n        if (isProxDoc) {\n          final int numFields = is40Index ? 7 : 5;\n          assertEquals(numFields, fields.size());\n          StorableField f =  d.getField(\"id\");\n          assertEquals(\"\"+i, f.stringValue());\n\n          f = d.getField(\"utf8\");\n          assertEquals(\"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne \\u0000 \\u2620 ab\\ud917\\udc17cd\", f.stringValue());\n\n          f =  d.getField(\"autf8\");\n          assertEquals(\"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne \\u0000 \\u2620 ab\\ud917\\udc17cd\", f.stringValue());\n      \n          f = d.getField(\"content2\");\n          assertEquals(\"here is more content with aaa aaa aaa\", f.stringValue());\n\n          f = d.getField(\"fie\\u2C77ld\");\n          assertEquals(\"field with non-ascii name\", f.stringValue());\n        }\n\n        Fields tfvFields = reader.getTermVectors(i);\n        assertNotNull(\"i=\" + i, tfvFields);\n        Terms tfv = tfvFields.terms(\"utf8\");\n        assertNotNull(\"docID=\" + i + \" index=\" + oldName, tfv);\n      } else {\n        // Only ID 7 is deleted\n        assertEquals(7, i);\n      }\n    }\n    \n    if (is40Index) {\n      // check docvalues fields\n      Source dvByte = MultiDocValues.getDocValues(reader, \"dvByte\").getSource();\n      Source dvBytesDerefFixed = MultiDocValues.getDocValues(reader, \"dvBytesDerefFixed\").getSource();\n      Source dvBytesDerefVar = MultiDocValues.getDocValues(reader, \"dvBytesDerefVar\").getSource();\n      Source dvBytesSortedFixed = MultiDocValues.getDocValues(reader, \"dvBytesSortedFixed\").getSource();\n      Source dvBytesSortedVar = MultiDocValues.getDocValues(reader, \"dvBytesSortedVar\").getSource();\n      Source dvBytesStraightFixed = MultiDocValues.getDocValues(reader, \"dvBytesStraightFixed\").getSource();\n      Source dvBytesStraightVar = MultiDocValues.getDocValues(reader, \"dvBytesStraightVar\").getSource();\n      Source dvDouble = MultiDocValues.getDocValues(reader, \"dvDouble\").getSource();\n      Source dvFloat = MultiDocValues.getDocValues(reader, \"dvFloat\").getSource();\n      Source dvInt = MultiDocValues.getDocValues(reader, \"dvInt\").getSource();\n      Source dvLong = MultiDocValues.getDocValues(reader, \"dvLong\").getSource();\n      Source dvPacked = MultiDocValues.getDocValues(reader, \"dvPacked\").getSource();\n      Source dvShort = MultiDocValues.getDocValues(reader, \"dvShort\").getSource();\n      \n      for (int i=0;i<35;i++) {\n        int id = Integer.parseInt(reader.document(i).get(\"id\"));\n        assertEquals((byte)id, dvByte.getInt(i));\n        \n        byte bytes[] = new byte[] {\n            (byte)(id >>> 24), (byte)(id >>> 16),(byte)(id >>> 8),(byte)id\n        };\n        BytesRef expectedRef = new BytesRef(bytes);\n        BytesRef scratch = new BytesRef();\n        \n        assertEquals(expectedRef, dvBytesDerefFixed.getBytes(i, scratch));\n        assertEquals(expectedRef, dvBytesDerefVar.getBytes(i, scratch));\n        assertEquals(expectedRef, dvBytesSortedFixed.getBytes(i, scratch));\n        assertEquals(expectedRef, dvBytesSortedVar.getBytes(i, scratch));\n        assertEquals(expectedRef, dvBytesStraightFixed.getBytes(i, scratch));\n        assertEquals(expectedRef, dvBytesStraightVar.getBytes(i, scratch));\n        \n        assertEquals((double)id, dvDouble.getFloat(i), 0D);\n        assertEquals((float)id, dvFloat.getFloat(i), 0F);\n        assertEquals(id, dvInt.getInt(i));\n        assertEquals(id, dvLong.getInt(i));\n        assertEquals(id, dvPacked.getInt(i));\n        assertEquals(id, dvShort.getInt(i));\n      }\n    }\n    \n    ScoreDoc[] hits = searcher.search(new TermQuery(new Term(new String(\"content\"), \"aaa\")), null, 1000).scoreDocs;\n\n    // First document should be #0\n    StoredDocument d = searcher.getIndexReader().document(hits[0].doc);\n    assertEquals(\"didn't get the right document first\", \"0\", d.get(\"id\"));\n\n    doTestHits(hits, 34, searcher.getIndexReader());\n    \n    if (is40Index) {\n      hits = searcher.search(new TermQuery(new Term(new String(\"content5\"), \"aaa\")), null, 1000).scoreDocs;\n\n      doTestHits(hits, 34, searcher.getIndexReader());\n    \n      hits = searcher.search(new TermQuery(new Term(new String(\"content6\"), \"aaa\")), null, 1000).scoreDocs;\n\n      doTestHits(hits, 34, searcher.getIndexReader());\n    }\n\n    hits = searcher.search(new TermQuery(new Term(\"utf8\", \"\\u0000\")), null, 1000).scoreDocs;\n    assertEquals(34, hits.length);\n    hits = searcher.search(new TermQuery(new Term(new String(\"utf8\"), \"lu\\uD834\\uDD1Ece\\uD834\\uDD60ne\")), null, 1000).scoreDocs;\n    assertEquals(34, hits.length);\n    hits = searcher.search(new TermQuery(new Term(\"utf8\", \"ab\\ud917\\udc17cd\")), null, 1000).scoreDocs;\n    assertEquals(34, hits.length);\n\n    reader.close();\n  }\n\n","sourceOld":"  public void searchIndex(Directory dir, String oldName) throws IOException {\n    //QueryParser parser = new QueryParser(\"contents\", new MockAnalyzer(random));\n    //Query query = parser.parse(\"handle:1\");\n\n    IndexReader reader = DirectoryReader.open(dir);\n    IndexSearcher searcher = new IndexSearcher(reader);\n\n    _TestUtil.checkIndex(dir);\n    \n    // true if this is a 4.0+ index\n    final boolean is40Index = MultiFields.getMergedFieldInfos(reader).fieldInfo(\"content5\") != null;\n    assert is40Index; // NOTE: currently we can only do this on trunk!\n\n    final Bits liveDocs = MultiFields.getLiveDocs(reader);\n\n    for(int i=0;i<35;i++) {\n      if (liveDocs.get(i)) {\n        Document d = reader.document(i);\n        List<IndexableField> fields = d.getFields();\n        boolean isProxDoc = d.getField(\"content3\") == null;\n        if (isProxDoc) {\n          final int numFields = is40Index ? 7 : 5;\n          assertEquals(numFields, fields.size());\n          IndexableField f =  d.getField(\"id\");\n          assertEquals(\"\"+i, f.stringValue());\n\n          f = d.getField(\"utf8\");\n          assertEquals(\"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne \\u0000 \\u2620 ab\\ud917\\udc17cd\", f.stringValue());\n\n          f =  d.getField(\"autf8\");\n          assertEquals(\"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne \\u0000 \\u2620 ab\\ud917\\udc17cd\", f.stringValue());\n      \n          f = d.getField(\"content2\");\n          assertEquals(\"here is more content with aaa aaa aaa\", f.stringValue());\n\n          f = d.getField(\"fie\\u2C77ld\");\n          assertEquals(\"field with non-ascii name\", f.stringValue());\n        }\n\n        Fields tfvFields = reader.getTermVectors(i);\n        assertNotNull(\"i=\" + i, tfvFields);\n        Terms tfv = tfvFields.terms(\"utf8\");\n        assertNotNull(\"docID=\" + i + \" index=\" + oldName, tfv);\n      } else {\n        // Only ID 7 is deleted\n        assertEquals(7, i);\n      }\n    }\n    \n    if (is40Index) {\n      // check docvalues fields\n      Source dvByte = MultiDocValues.getDocValues(reader, \"dvByte\").getSource();\n      Source dvBytesDerefFixed = MultiDocValues.getDocValues(reader, \"dvBytesDerefFixed\").getSource();\n      Source dvBytesDerefVar = MultiDocValues.getDocValues(reader, \"dvBytesDerefVar\").getSource();\n      Source dvBytesSortedFixed = MultiDocValues.getDocValues(reader, \"dvBytesSortedFixed\").getSource();\n      Source dvBytesSortedVar = MultiDocValues.getDocValues(reader, \"dvBytesSortedVar\").getSource();\n      Source dvBytesStraightFixed = MultiDocValues.getDocValues(reader, \"dvBytesStraightFixed\").getSource();\n      Source dvBytesStraightVar = MultiDocValues.getDocValues(reader, \"dvBytesStraightVar\").getSource();\n      Source dvDouble = MultiDocValues.getDocValues(reader, \"dvDouble\").getSource();\n      Source dvFloat = MultiDocValues.getDocValues(reader, \"dvFloat\").getSource();\n      Source dvInt = MultiDocValues.getDocValues(reader, \"dvInt\").getSource();\n      Source dvLong = MultiDocValues.getDocValues(reader, \"dvLong\").getSource();\n      Source dvPacked = MultiDocValues.getDocValues(reader, \"dvPacked\").getSource();\n      Source dvShort = MultiDocValues.getDocValues(reader, \"dvShort\").getSource();\n      \n      for (int i=0;i<35;i++) {\n        int id = Integer.parseInt(reader.document(i).get(\"id\"));\n        assertEquals((byte)id, dvByte.getInt(i));\n        \n        byte bytes[] = new byte[] {\n            (byte)(id >>> 24), (byte)(id >>> 16),(byte)(id >>> 8),(byte)id\n        };\n        BytesRef expectedRef = new BytesRef(bytes);\n        BytesRef scratch = new BytesRef();\n        \n        assertEquals(expectedRef, dvBytesDerefFixed.getBytes(i, scratch));\n        assertEquals(expectedRef, dvBytesDerefVar.getBytes(i, scratch));\n        assertEquals(expectedRef, dvBytesSortedFixed.getBytes(i, scratch));\n        assertEquals(expectedRef, dvBytesSortedVar.getBytes(i, scratch));\n        assertEquals(expectedRef, dvBytesStraightFixed.getBytes(i, scratch));\n        assertEquals(expectedRef, dvBytesStraightVar.getBytes(i, scratch));\n        \n        assertEquals((double)id, dvDouble.getFloat(i), 0D);\n        assertEquals((float)id, dvFloat.getFloat(i), 0F);\n        assertEquals(id, dvInt.getInt(i));\n        assertEquals(id, dvLong.getInt(i));\n        assertEquals(id, dvPacked.getInt(i));\n        assertEquals(id, dvShort.getInt(i));\n      }\n    }\n    \n    ScoreDoc[] hits = searcher.search(new TermQuery(new Term(new String(\"content\"), \"aaa\")), null, 1000).scoreDocs;\n\n    // First document should be #0\n    Document d = searcher.getIndexReader().document(hits[0].doc);\n    assertEquals(\"didn't get the right document first\", \"0\", d.get(\"id\"));\n\n    doTestHits(hits, 34, searcher.getIndexReader());\n    \n    if (is40Index) {\n      hits = searcher.search(new TermQuery(new Term(new String(\"content5\"), \"aaa\")), null, 1000).scoreDocs;\n\n      doTestHits(hits, 34, searcher.getIndexReader());\n    \n      hits = searcher.search(new TermQuery(new Term(new String(\"content6\"), \"aaa\")), null, 1000).scoreDocs;\n\n      doTestHits(hits, 34, searcher.getIndexReader());\n    }\n\n    hits = searcher.search(new TermQuery(new Term(\"utf8\", \"\\u0000\")), null, 1000).scoreDocs;\n    assertEquals(34, hits.length);\n    hits = searcher.search(new TermQuery(new Term(new String(\"utf8\"), \"lu\\uD834\\uDD1Ece\\uD834\\uDD60ne\")), null, 1000).scoreDocs;\n    assertEquals(34, hits.length);\n    hits = searcher.search(new TermQuery(new Term(\"utf8\", \"ab\\ud917\\udc17cd\")), null, 1000).scoreDocs;\n    assertEquals(34, hits.length);\n\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"1d028314cced5858683a1bb4741423d0f934257b","date":1346596535,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestBackwardsCompatibility#searchIndex(Directory,String).mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestBackwardsCompatibility#searchIndex(Directory,String).mjava","sourceNew":"  public void searchIndex(Directory dir, String oldName) throws IOException {\n    //QueryParser parser = new QueryParser(\"contents\", new MockAnalyzer(random));\n    //Query query = parser.parse(\"handle:1\");\n\n    IndexReader reader = DirectoryReader.open(dir);\n    IndexSearcher searcher = new IndexSearcher(reader);\n\n    _TestUtil.checkIndex(dir);\n    \n    // true if this is a 4.0+ index\n    final boolean is40Index = MultiFields.getMergedFieldInfos(reader).fieldInfo(\"content5\") != null;\n    assert is40Index; // NOTE: currently we can only do this on trunk!\n\n    final Bits liveDocs = MultiFields.getLiveDocs(reader);\n\n    for(int i=0;i<35;i++) {\n      if (liveDocs.get(i)) {\n        StoredDocument d = reader.document(i);\n        List<StorableField> fields = d.getFields();\n        boolean isProxDoc = d.getField(\"content3\") == null;\n        if (isProxDoc) {\n          final int numFields = is40Index ? 7 : 5;\n          assertEquals(numFields, fields.size());\n          StorableField f =  d.getField(\"id\");\n          assertEquals(\"\"+i, f.stringValue());\n\n          f = d.getField(\"utf8\");\n          assertEquals(\"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne \\u0000 \\u2620 ab\\ud917\\udc17cd\", f.stringValue());\n\n          f =  d.getField(\"autf8\");\n          assertEquals(\"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne \\u0000 \\u2620 ab\\ud917\\udc17cd\", f.stringValue());\n      \n          f = d.getField(\"content2\");\n          assertEquals(\"here is more content with aaa aaa aaa\", f.stringValue());\n\n          f = d.getField(\"fie\\u2C77ld\");\n          assertEquals(\"field with non-ascii name\", f.stringValue());\n        }\n\n        Fields tfvFields = reader.getTermVectors(i);\n        assertNotNull(\"i=\" + i, tfvFields);\n        Terms tfv = tfvFields.terms(\"utf8\");\n        assertNotNull(\"docID=\" + i + \" index=\" + oldName, tfv);\n      } else {\n        // Only ID 7 is deleted\n        assertEquals(7, i);\n      }\n    }\n    \n    if (is40Index) {\n      // check docvalues fields\n      Source dvByte = MultiDocValues.getDocValues(reader, \"dvByte\").getSource();\n      Source dvBytesDerefFixed = MultiDocValues.getDocValues(reader, \"dvBytesDerefFixed\").getSource();\n      Source dvBytesDerefVar = MultiDocValues.getDocValues(reader, \"dvBytesDerefVar\").getSource();\n      Source dvBytesSortedFixed = MultiDocValues.getDocValues(reader, \"dvBytesSortedFixed\").getSource();\n      Source dvBytesSortedVar = MultiDocValues.getDocValues(reader, \"dvBytesSortedVar\").getSource();\n      Source dvBytesStraightFixed = MultiDocValues.getDocValues(reader, \"dvBytesStraightFixed\").getSource();\n      Source dvBytesStraightVar = MultiDocValues.getDocValues(reader, \"dvBytesStraightVar\").getSource();\n      Source dvDouble = MultiDocValues.getDocValues(reader, \"dvDouble\").getSource();\n      Source dvFloat = MultiDocValues.getDocValues(reader, \"dvFloat\").getSource();\n      Source dvInt = MultiDocValues.getDocValues(reader, \"dvInt\").getSource();\n      Source dvLong = MultiDocValues.getDocValues(reader, \"dvLong\").getSource();\n      Source dvPacked = MultiDocValues.getDocValues(reader, \"dvPacked\").getSource();\n      Source dvShort = MultiDocValues.getDocValues(reader, \"dvShort\").getSource();\n      \n      for (int i=0;i<35;i++) {\n        int id = Integer.parseInt(reader.document(i).get(\"id\"));\n        assertEquals((byte)id, dvByte.getInt(i));\n        \n        byte bytes[] = new byte[] {\n            (byte)(id >>> 24), (byte)(id >>> 16),(byte)(id >>> 8),(byte)id\n        };\n        BytesRef expectedRef = new BytesRef(bytes);\n        BytesRef scratch = new BytesRef();\n        \n        assertEquals(expectedRef, dvBytesDerefFixed.getBytes(i, scratch));\n        assertEquals(expectedRef, dvBytesDerefVar.getBytes(i, scratch));\n        assertEquals(expectedRef, dvBytesSortedFixed.getBytes(i, scratch));\n        assertEquals(expectedRef, dvBytesSortedVar.getBytes(i, scratch));\n        assertEquals(expectedRef, dvBytesStraightFixed.getBytes(i, scratch));\n        assertEquals(expectedRef, dvBytesStraightVar.getBytes(i, scratch));\n        \n        assertEquals((double)id, dvDouble.getFloat(i), 0D);\n        assertEquals((float)id, dvFloat.getFloat(i), 0F);\n        assertEquals(id, dvInt.getInt(i));\n        assertEquals(id, dvLong.getInt(i));\n        assertEquals(id, dvPacked.getInt(i));\n        assertEquals(id, dvShort.getInt(i));\n      }\n    }\n    \n    ScoreDoc[] hits = searcher.search(new TermQuery(new Term(new String(\"content\"), \"aaa\")), null, 1000).scoreDocs;\n\n    // First document should be #0\n    StoredDocument d = searcher.getIndexReader().document(hits[0].doc);\n    assertEquals(\"didn't get the right document first\", \"0\", d.get(\"id\"));\n\n    doTestHits(hits, 34, searcher.getIndexReader());\n    \n    if (is40Index) {\n      hits = searcher.search(new TermQuery(new Term(new String(\"content5\"), \"aaa\")), null, 1000).scoreDocs;\n\n      doTestHits(hits, 34, searcher.getIndexReader());\n    \n      hits = searcher.search(new TermQuery(new Term(new String(\"content6\"), \"aaa\")), null, 1000).scoreDocs;\n\n      doTestHits(hits, 34, searcher.getIndexReader());\n    }\n\n    hits = searcher.search(new TermQuery(new Term(\"utf8\", \"\\u0000\")), null, 1000).scoreDocs;\n    assertEquals(34, hits.length);\n    hits = searcher.search(new TermQuery(new Term(new String(\"utf8\"), \"lu\\uD834\\uDD1Ece\\uD834\\uDD60ne\")), null, 1000).scoreDocs;\n    assertEquals(34, hits.length);\n    hits = searcher.search(new TermQuery(new Term(\"utf8\", \"ab\\ud917\\udc17cd\")), null, 1000).scoreDocs;\n    assertEquals(34, hits.length);\n\n    reader.close();\n  }\n\n","sourceOld":"  public void searchIndex(Directory dir, String oldName) throws IOException {\n    //QueryParser parser = new QueryParser(\"contents\", new MockAnalyzer(random));\n    //Query query = parser.parse(\"handle:1\");\n\n    IndexReader reader = DirectoryReader.open(dir);\n    IndexSearcher searcher = new IndexSearcher(reader);\n\n    _TestUtil.checkIndex(dir);\n    \n    // true if this is a 4.0+ index\n    final boolean is40Index = MultiFields.getMergedFieldInfos(reader).fieldInfo(\"content5\") != null;\n    assert is40Index; // NOTE: currently we can only do this on trunk!\n\n    final Bits liveDocs = MultiFields.getLiveDocs(reader);\n\n    for(int i=0;i<35;i++) {\n      if (liveDocs.get(i)) {\n        Document d = reader.document(i);\n        List<IndexableField> fields = d.getFields();\n        boolean isProxDoc = d.getField(\"content3\") == null;\n        if (isProxDoc) {\n          final int numFields = is40Index ? 7 : 5;\n          assertEquals(numFields, fields.size());\n          IndexableField f =  d.getField(\"id\");\n          assertEquals(\"\"+i, f.stringValue());\n\n          f = d.getField(\"utf8\");\n          assertEquals(\"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne \\u0000 \\u2620 ab\\ud917\\udc17cd\", f.stringValue());\n\n          f =  d.getField(\"autf8\");\n          assertEquals(\"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne \\u0000 \\u2620 ab\\ud917\\udc17cd\", f.stringValue());\n      \n          f = d.getField(\"content2\");\n          assertEquals(\"here is more content with aaa aaa aaa\", f.stringValue());\n\n          f = d.getField(\"fie\\u2C77ld\");\n          assertEquals(\"field with non-ascii name\", f.stringValue());\n        }\n\n        Fields tfvFields = reader.getTermVectors(i);\n        assertNotNull(\"i=\" + i, tfvFields);\n        Terms tfv = tfvFields.terms(\"utf8\");\n        assertNotNull(\"docID=\" + i + \" index=\" + oldName, tfv);\n      } else {\n        // Only ID 7 is deleted\n        assertEquals(7, i);\n      }\n    }\n    \n    if (is40Index) {\n      // check docvalues fields\n      Source dvByte = MultiDocValues.getDocValues(reader, \"dvByte\").getSource();\n      Source dvBytesDerefFixed = MultiDocValues.getDocValues(reader, \"dvBytesDerefFixed\").getSource();\n      Source dvBytesDerefVar = MultiDocValues.getDocValues(reader, \"dvBytesDerefVar\").getSource();\n      Source dvBytesSortedFixed = MultiDocValues.getDocValues(reader, \"dvBytesSortedFixed\").getSource();\n      Source dvBytesSortedVar = MultiDocValues.getDocValues(reader, \"dvBytesSortedVar\").getSource();\n      Source dvBytesStraightFixed = MultiDocValues.getDocValues(reader, \"dvBytesStraightFixed\").getSource();\n      Source dvBytesStraightVar = MultiDocValues.getDocValues(reader, \"dvBytesStraightVar\").getSource();\n      Source dvDouble = MultiDocValues.getDocValues(reader, \"dvDouble\").getSource();\n      Source dvFloat = MultiDocValues.getDocValues(reader, \"dvFloat\").getSource();\n      Source dvInt = MultiDocValues.getDocValues(reader, \"dvInt\").getSource();\n      Source dvLong = MultiDocValues.getDocValues(reader, \"dvLong\").getSource();\n      Source dvPacked = MultiDocValues.getDocValues(reader, \"dvPacked\").getSource();\n      Source dvShort = MultiDocValues.getDocValues(reader, \"dvShort\").getSource();\n      \n      for (int i=0;i<35;i++) {\n        int id = Integer.parseInt(reader.document(i).get(\"id\"));\n        assertEquals((byte)id, dvByte.getInt(i));\n        \n        byte bytes[] = new byte[] {\n            (byte)(id >>> 24), (byte)(id >>> 16),(byte)(id >>> 8),(byte)id\n        };\n        BytesRef expectedRef = new BytesRef(bytes);\n        BytesRef scratch = new BytesRef();\n        \n        assertEquals(expectedRef, dvBytesDerefFixed.getBytes(i, scratch));\n        assertEquals(expectedRef, dvBytesDerefVar.getBytes(i, scratch));\n        assertEquals(expectedRef, dvBytesSortedFixed.getBytes(i, scratch));\n        assertEquals(expectedRef, dvBytesSortedVar.getBytes(i, scratch));\n        assertEquals(expectedRef, dvBytesStraightFixed.getBytes(i, scratch));\n        assertEquals(expectedRef, dvBytesStraightVar.getBytes(i, scratch));\n        \n        assertEquals((double)id, dvDouble.getFloat(i), 0D);\n        assertEquals((float)id, dvFloat.getFloat(i), 0F);\n        assertEquals(id, dvInt.getInt(i));\n        assertEquals(id, dvLong.getInt(i));\n        assertEquals(id, dvPacked.getInt(i));\n        assertEquals(id, dvShort.getInt(i));\n      }\n    }\n    \n    ScoreDoc[] hits = searcher.search(new TermQuery(new Term(new String(\"content\"), \"aaa\")), null, 1000).scoreDocs;\n\n    // First document should be #0\n    Document d = searcher.getIndexReader().document(hits[0].doc);\n    assertEquals(\"didn't get the right document first\", \"0\", d.get(\"id\"));\n\n    doTestHits(hits, 34, searcher.getIndexReader());\n    \n    if (is40Index) {\n      hits = searcher.search(new TermQuery(new Term(new String(\"content5\"), \"aaa\")), null, 1000).scoreDocs;\n\n      doTestHits(hits, 34, searcher.getIndexReader());\n    \n      hits = searcher.search(new TermQuery(new Term(new String(\"content6\"), \"aaa\")), null, 1000).scoreDocs;\n\n      doTestHits(hits, 34, searcher.getIndexReader());\n    }\n\n    hits = searcher.search(new TermQuery(new Term(\"utf8\", \"\\u0000\")), null, 1000).scoreDocs;\n    assertEquals(34, hits.length);\n    hits = searcher.search(new TermQuery(new Term(new String(\"utf8\"), \"lu\\uD834\\uDD1Ece\\uD834\\uDD60ne\")), null, 1000).scoreDocs;\n    assertEquals(34, hits.length);\n    hits = searcher.search(new TermQuery(new Term(\"utf8\", \"ab\\ud917\\udc17cd\")), null, 1000).scoreDocs;\n    assertEquals(34, hits.length);\n\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"ad7de846867bd14c63f9dd19df082f72c5ea9c54","date":1355517454,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestBackwardsCompatibility#searchIndex(Directory,String).mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestBackwardsCompatibility#searchIndex(Directory,String).mjava","sourceNew":"  public void searchIndex(Directory dir, String oldName) throws IOException {\n    //QueryParser parser = new QueryParser(\"contents\", new MockAnalyzer(random));\n    //Query query = parser.parse(\"handle:1\");\n\n    IndexReader reader = DirectoryReader.open(dir);\n    IndexSearcher searcher = new IndexSearcher(reader);\n\n    _TestUtil.checkIndex(dir);\n    \n    // true if this is a 4.0+ index\n    final boolean is40Index = MultiFields.getMergedFieldInfos(reader).fieldInfo(\"content5\") != null;\n    assert is40Index; // NOTE: currently we can only do this on trunk!\n\n    final Bits liveDocs = MultiFields.getLiveDocs(reader);\n\n    for(int i=0;i<35;i++) {\n      if (liveDocs.get(i)) {\n        StoredDocument d = reader.document(i);\n        List<StorableField> fields = d.getFields();\n        boolean isProxDoc = d.getField(\"content3\") == null;\n        if (isProxDoc) {\n          final int numFields = is40Index ? 7 : 5;\n          assertEquals(numFields, fields.size());\n          StorableField f =  d.getField(\"id\");\n          assertEquals(\"\"+i, f.stringValue());\n\n          f = d.getField(\"utf8\");\n          assertEquals(\"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne \\u0000 \\u2620 ab\\ud917\\udc17cd\", f.stringValue());\n\n          f =  d.getField(\"autf8\");\n          assertEquals(\"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne \\u0000 \\u2620 ab\\ud917\\udc17cd\", f.stringValue());\n      \n          f = d.getField(\"content2\");\n          assertEquals(\"here is more content with aaa aaa aaa\", f.stringValue());\n\n          f = d.getField(\"fie\\u2C77ld\");\n          assertEquals(\"field with non-ascii name\", f.stringValue());\n        }\n\n        Fields tfvFields = reader.getTermVectors(i);\n        assertNotNull(\"i=\" + i, tfvFields);\n        Terms tfv = tfvFields.terms(\"utf8\");\n        assertNotNull(\"docID=\" + i + \" index=\" + oldName, tfv);\n      } else {\n        // Only ID 7 is deleted\n        assertEquals(7, i);\n      }\n    }\n\n    // nocommit re-enable if/when we backport DV 2.0 to 4.0\n    /*\n    if (is40Index) {\n      // check docvalues fields\n      Source dvByte = MultiDocValues.getDocValues(reader, \"dvByte\").getSource();\n      Source dvBytesDerefFixed = MultiDocValues.getDocValues(reader, \"dvBytesDerefFixed\").getSource();\n      Source dvBytesDerefVar = MultiDocValues.getDocValues(reader, \"dvBytesDerefVar\").getSource();\n      Source dvBytesSortedFixed = MultiDocValues.getDocValues(reader, \"dvBytesSortedFixed\").getSource();\n      Source dvBytesSortedVar = MultiDocValues.getDocValues(reader, \"dvBytesSortedVar\").getSource();\n      Source dvBytesStraightFixed = MultiDocValues.getDocValues(reader, \"dvBytesStraightFixed\").getSource();\n      Source dvBytesStraightVar = MultiDocValues.getDocValues(reader, \"dvBytesStraightVar\").getSource();\n      Source dvDouble = MultiDocValues.getDocValues(reader, \"dvDouble\").getSource();\n      Source dvFloat = MultiDocValues.getDocValues(reader, \"dvFloat\").getSource();\n      Source dvInt = MultiDocValues.getDocValues(reader, \"dvInt\").getSource();\n      Source dvLong = MultiDocValues.getDocValues(reader, \"dvLong\").getSource();\n      Source dvPacked = MultiDocValues.getDocValues(reader, \"dvPacked\").getSource();\n      Source dvShort = MultiDocValues.getDocValues(reader, \"dvShort\").getSource();\n      \n      for (int i=0;i<35;i++) {\n        int id = Integer.parseInt(reader.document(i).get(\"id\"));\n        assertEquals((byte)id, dvByte.getInt(i));\n        \n        byte bytes[] = new byte[] {\n            (byte)(id >>> 24), (byte)(id >>> 16),(byte)(id >>> 8),(byte)id\n        };\n        BytesRef expectedRef = new BytesRef(bytes);\n        BytesRef scratch = new BytesRef();\n        \n        assertEquals(expectedRef, dvBytesDerefFixed.getBytes(i, scratch));\n        assertEquals(expectedRef, dvBytesDerefVar.getBytes(i, scratch));\n        assertEquals(expectedRef, dvBytesSortedFixed.getBytes(i, scratch));\n        assertEquals(expectedRef, dvBytesSortedVar.getBytes(i, scratch));\n        assertEquals(expectedRef, dvBytesStraightFixed.getBytes(i, scratch));\n        assertEquals(expectedRef, dvBytesStraightVar.getBytes(i, scratch));\n        \n        assertEquals((double)id, dvDouble.getFloat(i), 0D);\n        assertEquals((float)id, dvFloat.getFloat(i), 0F);\n        assertEquals(id, dvInt.getInt(i));\n        assertEquals(id, dvLong.getInt(i));\n        assertEquals(id, dvPacked.getInt(i));\n        assertEquals(id, dvShort.getInt(i));\n      }\n    }\n    */\n    \n    ScoreDoc[] hits = searcher.search(new TermQuery(new Term(new String(\"content\"), \"aaa\")), null, 1000).scoreDocs;\n\n    // First document should be #0\n    StoredDocument d = searcher.getIndexReader().document(hits[0].doc);\n    assertEquals(\"didn't get the right document first\", \"0\", d.get(\"id\"));\n\n    doTestHits(hits, 34, searcher.getIndexReader());\n    \n    if (is40Index) {\n      hits = searcher.search(new TermQuery(new Term(new String(\"content5\"), \"aaa\")), null, 1000).scoreDocs;\n\n      doTestHits(hits, 34, searcher.getIndexReader());\n    \n      hits = searcher.search(new TermQuery(new Term(new String(\"content6\"), \"aaa\")), null, 1000).scoreDocs;\n\n      doTestHits(hits, 34, searcher.getIndexReader());\n    }\n\n    hits = searcher.search(new TermQuery(new Term(\"utf8\", \"\\u0000\")), null, 1000).scoreDocs;\n    assertEquals(34, hits.length);\n    hits = searcher.search(new TermQuery(new Term(new String(\"utf8\"), \"lu\\uD834\\uDD1Ece\\uD834\\uDD60ne\")), null, 1000).scoreDocs;\n    assertEquals(34, hits.length);\n    hits = searcher.search(new TermQuery(new Term(\"utf8\", \"ab\\ud917\\udc17cd\")), null, 1000).scoreDocs;\n    assertEquals(34, hits.length);\n\n    reader.close();\n  }\n\n","sourceOld":"  public void searchIndex(Directory dir, String oldName) throws IOException {\n    //QueryParser parser = new QueryParser(\"contents\", new MockAnalyzer(random));\n    //Query query = parser.parse(\"handle:1\");\n\n    IndexReader reader = DirectoryReader.open(dir);\n    IndexSearcher searcher = new IndexSearcher(reader);\n\n    _TestUtil.checkIndex(dir);\n    \n    // true if this is a 4.0+ index\n    final boolean is40Index = MultiFields.getMergedFieldInfos(reader).fieldInfo(\"content5\") != null;\n    assert is40Index; // NOTE: currently we can only do this on trunk!\n\n    final Bits liveDocs = MultiFields.getLiveDocs(reader);\n\n    for(int i=0;i<35;i++) {\n      if (liveDocs.get(i)) {\n        StoredDocument d = reader.document(i);\n        List<StorableField> fields = d.getFields();\n        boolean isProxDoc = d.getField(\"content3\") == null;\n        if (isProxDoc) {\n          final int numFields = is40Index ? 7 : 5;\n          assertEquals(numFields, fields.size());\n          StorableField f =  d.getField(\"id\");\n          assertEquals(\"\"+i, f.stringValue());\n\n          f = d.getField(\"utf8\");\n          assertEquals(\"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne \\u0000 \\u2620 ab\\ud917\\udc17cd\", f.stringValue());\n\n          f =  d.getField(\"autf8\");\n          assertEquals(\"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne \\u0000 \\u2620 ab\\ud917\\udc17cd\", f.stringValue());\n      \n          f = d.getField(\"content2\");\n          assertEquals(\"here is more content with aaa aaa aaa\", f.stringValue());\n\n          f = d.getField(\"fie\\u2C77ld\");\n          assertEquals(\"field with non-ascii name\", f.stringValue());\n        }\n\n        Fields tfvFields = reader.getTermVectors(i);\n        assertNotNull(\"i=\" + i, tfvFields);\n        Terms tfv = tfvFields.terms(\"utf8\");\n        assertNotNull(\"docID=\" + i + \" index=\" + oldName, tfv);\n      } else {\n        // Only ID 7 is deleted\n        assertEquals(7, i);\n      }\n    }\n    \n    if (is40Index) {\n      // check docvalues fields\n      Source dvByte = MultiDocValues.getDocValues(reader, \"dvByte\").getSource();\n      Source dvBytesDerefFixed = MultiDocValues.getDocValues(reader, \"dvBytesDerefFixed\").getSource();\n      Source dvBytesDerefVar = MultiDocValues.getDocValues(reader, \"dvBytesDerefVar\").getSource();\n      Source dvBytesSortedFixed = MultiDocValues.getDocValues(reader, \"dvBytesSortedFixed\").getSource();\n      Source dvBytesSortedVar = MultiDocValues.getDocValues(reader, \"dvBytesSortedVar\").getSource();\n      Source dvBytesStraightFixed = MultiDocValues.getDocValues(reader, \"dvBytesStraightFixed\").getSource();\n      Source dvBytesStraightVar = MultiDocValues.getDocValues(reader, \"dvBytesStraightVar\").getSource();\n      Source dvDouble = MultiDocValues.getDocValues(reader, \"dvDouble\").getSource();\n      Source dvFloat = MultiDocValues.getDocValues(reader, \"dvFloat\").getSource();\n      Source dvInt = MultiDocValues.getDocValues(reader, \"dvInt\").getSource();\n      Source dvLong = MultiDocValues.getDocValues(reader, \"dvLong\").getSource();\n      Source dvPacked = MultiDocValues.getDocValues(reader, \"dvPacked\").getSource();\n      Source dvShort = MultiDocValues.getDocValues(reader, \"dvShort\").getSource();\n      \n      for (int i=0;i<35;i++) {\n        int id = Integer.parseInt(reader.document(i).get(\"id\"));\n        assertEquals((byte)id, dvByte.getInt(i));\n        \n        byte bytes[] = new byte[] {\n            (byte)(id >>> 24), (byte)(id >>> 16),(byte)(id >>> 8),(byte)id\n        };\n        BytesRef expectedRef = new BytesRef(bytes);\n        BytesRef scratch = new BytesRef();\n        \n        assertEquals(expectedRef, dvBytesDerefFixed.getBytes(i, scratch));\n        assertEquals(expectedRef, dvBytesDerefVar.getBytes(i, scratch));\n        assertEquals(expectedRef, dvBytesSortedFixed.getBytes(i, scratch));\n        assertEquals(expectedRef, dvBytesSortedVar.getBytes(i, scratch));\n        assertEquals(expectedRef, dvBytesStraightFixed.getBytes(i, scratch));\n        assertEquals(expectedRef, dvBytesStraightVar.getBytes(i, scratch));\n        \n        assertEquals((double)id, dvDouble.getFloat(i), 0D);\n        assertEquals((float)id, dvFloat.getFloat(i), 0F);\n        assertEquals(id, dvInt.getInt(i));\n        assertEquals(id, dvLong.getInt(i));\n        assertEquals(id, dvPacked.getInt(i));\n        assertEquals(id, dvShort.getInt(i));\n      }\n    }\n    \n    ScoreDoc[] hits = searcher.search(new TermQuery(new Term(new String(\"content\"), \"aaa\")), null, 1000).scoreDocs;\n\n    // First document should be #0\n    StoredDocument d = searcher.getIndexReader().document(hits[0].doc);\n    assertEquals(\"didn't get the right document first\", \"0\", d.get(\"id\"));\n\n    doTestHits(hits, 34, searcher.getIndexReader());\n    \n    if (is40Index) {\n      hits = searcher.search(new TermQuery(new Term(new String(\"content5\"), \"aaa\")), null, 1000).scoreDocs;\n\n      doTestHits(hits, 34, searcher.getIndexReader());\n    \n      hits = searcher.search(new TermQuery(new Term(new String(\"content6\"), \"aaa\")), null, 1000).scoreDocs;\n\n      doTestHits(hits, 34, searcher.getIndexReader());\n    }\n\n    hits = searcher.search(new TermQuery(new Term(\"utf8\", \"\\u0000\")), null, 1000).scoreDocs;\n    assertEquals(34, hits.length);\n    hits = searcher.search(new TermQuery(new Term(new String(\"utf8\"), \"lu\\uD834\\uDD1Ece\\uD834\\uDD60ne\")), null, 1000).scoreDocs;\n    assertEquals(34, hits.length);\n    hits = searcher.search(new TermQuery(new Term(\"utf8\", \"ab\\ud917\\udc17cd\")), null, 1000).scoreDocs;\n    assertEquals(34, hits.length);\n\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"e865135253d3ad47840f06992c7c801e3fd71907","date":1359057708,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestBackwardsCompatibility#searchIndex(Directory,String).mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestBackwardsCompatibility#searchIndex(Directory,String).mjava","sourceNew":"  public void searchIndex(Directory dir, String oldName) throws IOException {\n    //QueryParser parser = new QueryParser(\"contents\", new MockAnalyzer(random));\n    //Query query = parser.parse(\"handle:1\");\n\n    IndexReader reader = DirectoryReader.open(dir);\n    IndexSearcher searcher = new IndexSearcher(reader);\n\n    _TestUtil.checkIndex(dir);\n    \n    // true if this is a 4.0+ index\n    final boolean is40Index = MultiFields.getMergedFieldInfos(reader).fieldInfo(\"content5\") != null;\n    assert is40Index; // NOTE: currently we can only do this on trunk!\n\n    final Bits liveDocs = MultiFields.getLiveDocs(reader);\n\n    for(int i=0;i<35;i++) {\n      if (liveDocs.get(i)) {\n        StoredDocument d = reader.document(i);\n        List<StorableField> fields = d.getFields();\n        boolean isProxDoc = d.getField(\"content3\") == null;\n        if (isProxDoc) {\n          final int numFields = is40Index ? 7 : 5;\n          assertEquals(numFields, fields.size());\n          StorableField f =  d.getField(\"id\");\n          assertEquals(\"\"+i, f.stringValue());\n\n          f = d.getField(\"utf8\");\n          assertEquals(\"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne \\u0000 \\u2620 ab\\ud917\\udc17cd\", f.stringValue());\n\n          f =  d.getField(\"autf8\");\n          assertEquals(\"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne \\u0000 \\u2620 ab\\ud917\\udc17cd\", f.stringValue());\n      \n          f = d.getField(\"content2\");\n          assertEquals(\"here is more content with aaa aaa aaa\", f.stringValue());\n\n          f = d.getField(\"fie\\u2C77ld\");\n          assertEquals(\"field with non-ascii name\", f.stringValue());\n        }\n\n        Fields tfvFields = reader.getTermVectors(i);\n        assertNotNull(\"i=\" + i, tfvFields);\n        Terms tfv = tfvFields.terms(\"utf8\");\n        assertNotNull(\"docID=\" + i + \" index=\" + oldName, tfv);\n      } else {\n        // Only ID 7 is deleted\n        assertEquals(7, i);\n      }\n    }\n\n    if (is40Index) {\n      // check docvalues fields\n      NumericDocValues dvByte = MultiDocValues.getNumericValues(reader, \"dvByte\");\n      BinaryDocValues dvBytesDerefFixed = MultiDocValues.getBinaryValues(reader, \"dvBytesDerefFixed\");\n      BinaryDocValues dvBytesDerefVar = MultiDocValues.getBinaryValues(reader, \"dvBytesDerefVar\");\n      SortedDocValues dvBytesSortedFixed = MultiDocValues.getSortedValues(reader, \"dvBytesSortedFixed\");\n      SortedDocValues dvBytesSortedVar = MultiDocValues.getSortedValues(reader, \"dvBytesSortedVar\");\n      BinaryDocValues dvBytesStraightFixed = MultiDocValues.getBinaryValues(reader, \"dvBytesStraightFixed\");\n      BinaryDocValues dvBytesStraightVar = MultiDocValues.getBinaryValues(reader, \"dvBytesStraightVar\");\n      NumericDocValues dvDouble = MultiDocValues.getNumericValues(reader, \"dvDouble\");\n      NumericDocValues dvFloat = MultiDocValues.getNumericValues(reader, \"dvFloat\");\n      NumericDocValues dvInt = MultiDocValues.getNumericValues(reader, \"dvInt\");\n      NumericDocValues dvLong = MultiDocValues.getNumericValues(reader, \"dvLong\");\n      NumericDocValues dvPacked = MultiDocValues.getNumericValues(reader, \"dvPacked\");\n      NumericDocValues dvShort = MultiDocValues.getNumericValues(reader, \"dvShort\");\n      \n      for (int i=0;i<35;i++) {\n        int id = Integer.parseInt(reader.document(i).get(\"id\"));\n        assertEquals(id, dvByte.get(i));\n        \n        byte bytes[] = new byte[] {\n            (byte)(id >>> 24), (byte)(id >>> 16),(byte)(id >>> 8),(byte)id\n        };\n        BytesRef expectedRef = new BytesRef(bytes);\n        BytesRef scratch = new BytesRef();\n        \n        dvBytesDerefFixed.get(i, scratch);\n        assertEquals(expectedRef, scratch);\n        dvBytesDerefVar.get(i, scratch);\n        assertEquals(expectedRef, scratch);\n        dvBytesSortedFixed.get(i, scratch);\n        assertEquals(expectedRef, scratch);\n        dvBytesSortedVar.get(i, scratch);\n        assertEquals(expectedRef, scratch);\n        dvBytesStraightFixed.get(i, scratch);\n        assertEquals(expectedRef, scratch);\n        dvBytesStraightVar.get(i, scratch);\n        assertEquals(expectedRef, scratch);\n        \n        assertEquals((double)id, Double.longBitsToDouble(dvDouble.get(i)), 0D);\n        assertEquals((float)id, Float.intBitsToFloat((int)dvFloat.get(i)), 0F);\n        assertEquals(id, dvInt.get(i));\n        assertEquals(id, dvLong.get(i));\n        assertEquals(id, dvPacked.get(i));\n        assertEquals(id, dvShort.get(i));\n      }\n    }\n    \n    ScoreDoc[] hits = searcher.search(new TermQuery(new Term(new String(\"content\"), \"aaa\")), null, 1000).scoreDocs;\n\n    // First document should be #0\n    StoredDocument d = searcher.getIndexReader().document(hits[0].doc);\n    assertEquals(\"didn't get the right document first\", \"0\", d.get(\"id\"));\n\n    doTestHits(hits, 34, searcher.getIndexReader());\n    \n    if (is40Index) {\n      hits = searcher.search(new TermQuery(new Term(new String(\"content5\"), \"aaa\")), null, 1000).scoreDocs;\n\n      doTestHits(hits, 34, searcher.getIndexReader());\n    \n      hits = searcher.search(new TermQuery(new Term(new String(\"content6\"), \"aaa\")), null, 1000).scoreDocs;\n\n      doTestHits(hits, 34, searcher.getIndexReader());\n    }\n\n    hits = searcher.search(new TermQuery(new Term(\"utf8\", \"\\u0000\")), null, 1000).scoreDocs;\n    assertEquals(34, hits.length);\n    hits = searcher.search(new TermQuery(new Term(new String(\"utf8\"), \"lu\\uD834\\uDD1Ece\\uD834\\uDD60ne\")), null, 1000).scoreDocs;\n    assertEquals(34, hits.length);\n    hits = searcher.search(new TermQuery(new Term(\"utf8\", \"ab\\ud917\\udc17cd\")), null, 1000).scoreDocs;\n    assertEquals(34, hits.length);\n\n    reader.close();\n  }\n\n","sourceOld":"  public void searchIndex(Directory dir, String oldName) throws IOException {\n    //QueryParser parser = new QueryParser(\"contents\", new MockAnalyzer(random));\n    //Query query = parser.parse(\"handle:1\");\n\n    IndexReader reader = DirectoryReader.open(dir);\n    IndexSearcher searcher = new IndexSearcher(reader);\n\n    _TestUtil.checkIndex(dir);\n    \n    // true if this is a 4.0+ index\n    final boolean is40Index = MultiFields.getMergedFieldInfos(reader).fieldInfo(\"content5\") != null;\n    assert is40Index; // NOTE: currently we can only do this on trunk!\n\n    final Bits liveDocs = MultiFields.getLiveDocs(reader);\n\n    for(int i=0;i<35;i++) {\n      if (liveDocs.get(i)) {\n        StoredDocument d = reader.document(i);\n        List<StorableField> fields = d.getFields();\n        boolean isProxDoc = d.getField(\"content3\") == null;\n        if (isProxDoc) {\n          final int numFields = is40Index ? 7 : 5;\n          assertEquals(numFields, fields.size());\n          StorableField f =  d.getField(\"id\");\n          assertEquals(\"\"+i, f.stringValue());\n\n          f = d.getField(\"utf8\");\n          assertEquals(\"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne \\u0000 \\u2620 ab\\ud917\\udc17cd\", f.stringValue());\n\n          f =  d.getField(\"autf8\");\n          assertEquals(\"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne \\u0000 \\u2620 ab\\ud917\\udc17cd\", f.stringValue());\n      \n          f = d.getField(\"content2\");\n          assertEquals(\"here is more content with aaa aaa aaa\", f.stringValue());\n\n          f = d.getField(\"fie\\u2C77ld\");\n          assertEquals(\"field with non-ascii name\", f.stringValue());\n        }\n\n        Fields tfvFields = reader.getTermVectors(i);\n        assertNotNull(\"i=\" + i, tfvFields);\n        Terms tfv = tfvFields.terms(\"utf8\");\n        assertNotNull(\"docID=\" + i + \" index=\" + oldName, tfv);\n      } else {\n        // Only ID 7 is deleted\n        assertEquals(7, i);\n      }\n    }\n\n    // nocommit re-enable if/when we backport DV 2.0 to 4.0\n    /*\n    if (is40Index) {\n      // check docvalues fields\n      Source dvByte = MultiDocValues.getDocValues(reader, \"dvByte\").getSource();\n      Source dvBytesDerefFixed = MultiDocValues.getDocValues(reader, \"dvBytesDerefFixed\").getSource();\n      Source dvBytesDerefVar = MultiDocValues.getDocValues(reader, \"dvBytesDerefVar\").getSource();\n      Source dvBytesSortedFixed = MultiDocValues.getDocValues(reader, \"dvBytesSortedFixed\").getSource();\n      Source dvBytesSortedVar = MultiDocValues.getDocValues(reader, \"dvBytesSortedVar\").getSource();\n      Source dvBytesStraightFixed = MultiDocValues.getDocValues(reader, \"dvBytesStraightFixed\").getSource();\n      Source dvBytesStraightVar = MultiDocValues.getDocValues(reader, \"dvBytesStraightVar\").getSource();\n      Source dvDouble = MultiDocValues.getDocValues(reader, \"dvDouble\").getSource();\n      Source dvFloat = MultiDocValues.getDocValues(reader, \"dvFloat\").getSource();\n      Source dvInt = MultiDocValues.getDocValues(reader, \"dvInt\").getSource();\n      Source dvLong = MultiDocValues.getDocValues(reader, \"dvLong\").getSource();\n      Source dvPacked = MultiDocValues.getDocValues(reader, \"dvPacked\").getSource();\n      Source dvShort = MultiDocValues.getDocValues(reader, \"dvShort\").getSource();\n      \n      for (int i=0;i<35;i++) {\n        int id = Integer.parseInt(reader.document(i).get(\"id\"));\n        assertEquals((byte)id, dvByte.getInt(i));\n        \n        byte bytes[] = new byte[] {\n            (byte)(id >>> 24), (byte)(id >>> 16),(byte)(id >>> 8),(byte)id\n        };\n        BytesRef expectedRef = new BytesRef(bytes);\n        BytesRef scratch = new BytesRef();\n        \n        assertEquals(expectedRef, dvBytesDerefFixed.getBytes(i, scratch));\n        assertEquals(expectedRef, dvBytesDerefVar.getBytes(i, scratch));\n        assertEquals(expectedRef, dvBytesSortedFixed.getBytes(i, scratch));\n        assertEquals(expectedRef, dvBytesSortedVar.getBytes(i, scratch));\n        assertEquals(expectedRef, dvBytesStraightFixed.getBytes(i, scratch));\n        assertEquals(expectedRef, dvBytesStraightVar.getBytes(i, scratch));\n        \n        assertEquals((double)id, dvDouble.getFloat(i), 0D);\n        assertEquals((float)id, dvFloat.getFloat(i), 0F);\n        assertEquals(id, dvInt.getInt(i));\n        assertEquals(id, dvLong.getInt(i));\n        assertEquals(id, dvPacked.getInt(i));\n        assertEquals(id, dvShort.getInt(i));\n      }\n    }\n    */\n    \n    ScoreDoc[] hits = searcher.search(new TermQuery(new Term(new String(\"content\"), \"aaa\")), null, 1000).scoreDocs;\n\n    // First document should be #0\n    StoredDocument d = searcher.getIndexReader().document(hits[0].doc);\n    assertEquals(\"didn't get the right document first\", \"0\", d.get(\"id\"));\n\n    doTestHits(hits, 34, searcher.getIndexReader());\n    \n    if (is40Index) {\n      hits = searcher.search(new TermQuery(new Term(new String(\"content5\"), \"aaa\")), null, 1000).scoreDocs;\n\n      doTestHits(hits, 34, searcher.getIndexReader());\n    \n      hits = searcher.search(new TermQuery(new Term(new String(\"content6\"), \"aaa\")), null, 1000).scoreDocs;\n\n      doTestHits(hits, 34, searcher.getIndexReader());\n    }\n\n    hits = searcher.search(new TermQuery(new Term(\"utf8\", \"\\u0000\")), null, 1000).scoreDocs;\n    assertEquals(34, hits.length);\n    hits = searcher.search(new TermQuery(new Term(new String(\"utf8\"), \"lu\\uD834\\uDD1Ece\\uD834\\uDD60ne\")), null, 1000).scoreDocs;\n    assertEquals(34, hits.length);\n    hits = searcher.search(new TermQuery(new Term(\"utf8\", \"ab\\ud917\\udc17cd\")), null, 1000).scoreDocs;\n    assertEquals(34, hits.length);\n\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d4d69c535930b5cce125cff868d40f6373dc27d4","date":1360270101,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestBackwardsCompatibility#searchIndex(Directory,String).mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestBackwardsCompatibility#searchIndex(Directory,String).mjava","sourceNew":"  public void searchIndex(Directory dir, String oldName) throws IOException {\n    //QueryParser parser = new QueryParser(\"contents\", new MockAnalyzer(random));\n    //Query query = parser.parse(\"handle:1\");\n\n    IndexReader reader = DirectoryReader.open(dir);\n    IndexSearcher searcher = new IndexSearcher(reader);\n\n    _TestUtil.checkIndex(dir);\n    \n    // true if this is a 4.0+ index\n    final boolean is40Index = MultiFields.getMergedFieldInfos(reader).fieldInfo(\"content5\") != null;\n    assert is40Index; // NOTE: currently we can only do this on trunk!\n\n    final Bits liveDocs = MultiFields.getLiveDocs(reader);\n\n    for(int i=0;i<35;i++) {\n      if (liveDocs.get(i)) {\n        StoredDocument d = reader.document(i);\n        List<StorableField> fields = d.getFields();\n        boolean isProxDoc = d.getField(\"content3\") == null;\n        if (isProxDoc) {\n          final int numFields = is40Index ? 7 : 5;\n          assertEquals(numFields, fields.size());\n          StorableField f =  d.getField(\"id\");\n          assertEquals(\"\"+i, f.stringValue());\n\n          f = d.getField(\"utf8\");\n          assertEquals(\"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne \\u0000 \\u2620 ab\\ud917\\udc17cd\", f.stringValue());\n\n          f =  d.getField(\"autf8\");\n          assertEquals(\"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne \\u0000 \\u2620 ab\\ud917\\udc17cd\", f.stringValue());\n      \n          f = d.getField(\"content2\");\n          assertEquals(\"here is more content with aaa aaa aaa\", f.stringValue());\n\n          f = d.getField(\"fie\\u2C77ld\");\n          assertEquals(\"field with non-ascii name\", f.stringValue());\n        }\n\n        Fields tfvFields = reader.getTermVectors(i);\n        assertNotNull(\"i=\" + i, tfvFields);\n        Terms tfv = tfvFields.terms(\"utf8\");\n        assertNotNull(\"docID=\" + i + \" index=\" + oldName, tfv);\n      } else {\n        // Only ID 7 is deleted\n        assertEquals(7, i);\n      }\n    }\n\n    if (is40Index) {\n      // check docvalues fields\n      NumericDocValues dvByte = MultiDocValues.getNumericValues(reader, \"dvByte\");\n      BinaryDocValues dvBytesDerefFixed = MultiDocValues.getBinaryValues(reader, \"dvBytesDerefFixed\");\n      BinaryDocValues dvBytesDerefVar = MultiDocValues.getBinaryValues(reader, \"dvBytesDerefVar\");\n      SortedDocValues dvBytesSortedFixed = MultiDocValues.getSortedValues(reader, \"dvBytesSortedFixed\");\n      SortedDocValues dvBytesSortedVar = MultiDocValues.getSortedValues(reader, \"dvBytesSortedVar\");\n      BinaryDocValues dvBytesStraightFixed = MultiDocValues.getBinaryValues(reader, \"dvBytesStraightFixed\");\n      BinaryDocValues dvBytesStraightVar = MultiDocValues.getBinaryValues(reader, \"dvBytesStraightVar\");\n      NumericDocValues dvDouble = MultiDocValues.getNumericValues(reader, \"dvDouble\");\n      NumericDocValues dvFloat = MultiDocValues.getNumericValues(reader, \"dvFloat\");\n      NumericDocValues dvInt = MultiDocValues.getNumericValues(reader, \"dvInt\");\n      NumericDocValues dvLong = MultiDocValues.getNumericValues(reader, \"dvLong\");\n      NumericDocValues dvPacked = MultiDocValues.getNumericValues(reader, \"dvPacked\");\n      NumericDocValues dvShort = MultiDocValues.getNumericValues(reader, \"dvShort\");\n      \n      for (int i=0;i<35;i++) {\n        int id = Integer.parseInt(reader.document(i).get(\"id\"));\n        assertEquals(id, dvByte.get(i));\n        \n        byte bytes[] = new byte[] {\n            (byte)(id >>> 24), (byte)(id >>> 16),(byte)(id >>> 8),(byte)id\n        };\n        BytesRef expectedRef = new BytesRef(bytes);\n        BytesRef scratch = new BytesRef();\n        \n        dvBytesDerefFixed.get(i, scratch);\n        assertEquals(expectedRef, scratch);\n        dvBytesDerefVar.get(i, scratch);\n        assertEquals(expectedRef, scratch);\n        dvBytesSortedFixed.get(i, scratch);\n        assertEquals(expectedRef, scratch);\n        dvBytesSortedVar.get(i, scratch);\n        assertEquals(expectedRef, scratch);\n        dvBytesStraightFixed.get(i, scratch);\n        assertEquals(expectedRef, scratch);\n        dvBytesStraightVar.get(i, scratch);\n        assertEquals(expectedRef, scratch);\n        \n        assertEquals((double)id, Double.longBitsToDouble(dvDouble.get(i)), 0D);\n        assertEquals((float)id, Float.intBitsToFloat((int)dvFloat.get(i)), 0F);\n        assertEquals(id, dvInt.get(i));\n        assertEquals(id, dvLong.get(i));\n        assertEquals(id, dvPacked.get(i));\n        assertEquals(id, dvShort.get(i));\n      }\n    }\n    \n    ScoreDoc[] hits = searcher.search(new TermQuery(new Term(new String(\"content\"), \"aaa\")), null, 1000).scoreDocs;\n\n    // First document should be #0\n    StoredDocument d = searcher.getIndexReader().document(hits[0].doc);\n    assertEquals(\"didn't get the right document first\", \"0\", d.get(\"id\"));\n\n    doTestHits(hits, 34, searcher.getIndexReader());\n    \n    if (is40Index) {\n      hits = searcher.search(new TermQuery(new Term(new String(\"content5\"), \"aaa\")), null, 1000).scoreDocs;\n\n      doTestHits(hits, 34, searcher.getIndexReader());\n    \n      hits = searcher.search(new TermQuery(new Term(new String(\"content6\"), \"aaa\")), null, 1000).scoreDocs;\n\n      doTestHits(hits, 34, searcher.getIndexReader());\n    }\n\n    hits = searcher.search(new TermQuery(new Term(\"utf8\", \"\\u0000\")), null, 1000).scoreDocs;\n    assertEquals(34, hits.length);\n    hits = searcher.search(new TermQuery(new Term(new String(\"utf8\"), \"lu\\uD834\\uDD1Ece\\uD834\\uDD60ne\")), null, 1000).scoreDocs;\n    assertEquals(34, hits.length);\n    hits = searcher.search(new TermQuery(new Term(\"utf8\", \"ab\\ud917\\udc17cd\")), null, 1000).scoreDocs;\n    assertEquals(34, hits.length);\n\n    reader.close();\n  }\n\n","sourceOld":"  public void searchIndex(Directory dir, String oldName) throws IOException {\n    //QueryParser parser = new QueryParser(\"contents\", new MockAnalyzer(random));\n    //Query query = parser.parse(\"handle:1\");\n\n    IndexReader reader = DirectoryReader.open(dir);\n    IndexSearcher searcher = new IndexSearcher(reader);\n\n    _TestUtil.checkIndex(dir);\n    \n    // true if this is a 4.0+ index\n    final boolean is40Index = MultiFields.getMergedFieldInfos(reader).fieldInfo(\"content5\") != null;\n    assert is40Index; // NOTE: currently we can only do this on trunk!\n\n    final Bits liveDocs = MultiFields.getLiveDocs(reader);\n\n    for(int i=0;i<35;i++) {\n      if (liveDocs.get(i)) {\n        StoredDocument d = reader.document(i);\n        List<StorableField> fields = d.getFields();\n        boolean isProxDoc = d.getField(\"content3\") == null;\n        if (isProxDoc) {\n          final int numFields = is40Index ? 7 : 5;\n          assertEquals(numFields, fields.size());\n          StorableField f =  d.getField(\"id\");\n          assertEquals(\"\"+i, f.stringValue());\n\n          f = d.getField(\"utf8\");\n          assertEquals(\"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne \\u0000 \\u2620 ab\\ud917\\udc17cd\", f.stringValue());\n\n          f =  d.getField(\"autf8\");\n          assertEquals(\"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne \\u0000 \\u2620 ab\\ud917\\udc17cd\", f.stringValue());\n      \n          f = d.getField(\"content2\");\n          assertEquals(\"here is more content with aaa aaa aaa\", f.stringValue());\n\n          f = d.getField(\"fie\\u2C77ld\");\n          assertEquals(\"field with non-ascii name\", f.stringValue());\n        }\n\n        Fields tfvFields = reader.getTermVectors(i);\n        assertNotNull(\"i=\" + i, tfvFields);\n        Terms tfv = tfvFields.terms(\"utf8\");\n        assertNotNull(\"docID=\" + i + \" index=\" + oldName, tfv);\n      } else {\n        // Only ID 7 is deleted\n        assertEquals(7, i);\n      }\n    }\n    \n    if (is40Index) {\n      // check docvalues fields\n      Source dvByte = MultiDocValues.getDocValues(reader, \"dvByte\").getSource();\n      Source dvBytesDerefFixed = MultiDocValues.getDocValues(reader, \"dvBytesDerefFixed\").getSource();\n      Source dvBytesDerefVar = MultiDocValues.getDocValues(reader, \"dvBytesDerefVar\").getSource();\n      Source dvBytesSortedFixed = MultiDocValues.getDocValues(reader, \"dvBytesSortedFixed\").getSource();\n      Source dvBytesSortedVar = MultiDocValues.getDocValues(reader, \"dvBytesSortedVar\").getSource();\n      Source dvBytesStraightFixed = MultiDocValues.getDocValues(reader, \"dvBytesStraightFixed\").getSource();\n      Source dvBytesStraightVar = MultiDocValues.getDocValues(reader, \"dvBytesStraightVar\").getSource();\n      Source dvDouble = MultiDocValues.getDocValues(reader, \"dvDouble\").getSource();\n      Source dvFloat = MultiDocValues.getDocValues(reader, \"dvFloat\").getSource();\n      Source dvInt = MultiDocValues.getDocValues(reader, \"dvInt\").getSource();\n      Source dvLong = MultiDocValues.getDocValues(reader, \"dvLong\").getSource();\n      Source dvPacked = MultiDocValues.getDocValues(reader, \"dvPacked\").getSource();\n      Source dvShort = MultiDocValues.getDocValues(reader, \"dvShort\").getSource();\n      \n      for (int i=0;i<35;i++) {\n        int id = Integer.parseInt(reader.document(i).get(\"id\"));\n        assertEquals((byte)id, dvByte.getInt(i));\n        \n        byte bytes[] = new byte[] {\n            (byte)(id >>> 24), (byte)(id >>> 16),(byte)(id >>> 8),(byte)id\n        };\n        BytesRef expectedRef = new BytesRef(bytes);\n        BytesRef scratch = new BytesRef();\n        \n        assertEquals(expectedRef, dvBytesDerefFixed.getBytes(i, scratch));\n        assertEquals(expectedRef, dvBytesDerefVar.getBytes(i, scratch));\n        assertEquals(expectedRef, dvBytesSortedFixed.getBytes(i, scratch));\n        assertEquals(expectedRef, dvBytesSortedVar.getBytes(i, scratch));\n        assertEquals(expectedRef, dvBytesStraightFixed.getBytes(i, scratch));\n        assertEquals(expectedRef, dvBytesStraightVar.getBytes(i, scratch));\n        \n        assertEquals((double)id, dvDouble.getFloat(i), 0D);\n        assertEquals((float)id, dvFloat.getFloat(i), 0F);\n        assertEquals(id, dvInt.getInt(i));\n        assertEquals(id, dvLong.getInt(i));\n        assertEquals(id, dvPacked.getInt(i));\n        assertEquals(id, dvShort.getInt(i));\n      }\n    }\n    \n    ScoreDoc[] hits = searcher.search(new TermQuery(new Term(new String(\"content\"), \"aaa\")), null, 1000).scoreDocs;\n\n    // First document should be #0\n    StoredDocument d = searcher.getIndexReader().document(hits[0].doc);\n    assertEquals(\"didn't get the right document first\", \"0\", d.get(\"id\"));\n\n    doTestHits(hits, 34, searcher.getIndexReader());\n    \n    if (is40Index) {\n      hits = searcher.search(new TermQuery(new Term(new String(\"content5\"), \"aaa\")), null, 1000).scoreDocs;\n\n      doTestHits(hits, 34, searcher.getIndexReader());\n    \n      hits = searcher.search(new TermQuery(new Term(new String(\"content6\"), \"aaa\")), null, 1000).scoreDocs;\n\n      doTestHits(hits, 34, searcher.getIndexReader());\n    }\n\n    hits = searcher.search(new TermQuery(new Term(\"utf8\", \"\\u0000\")), null, 1000).scoreDocs;\n    assertEquals(34, hits.length);\n    hits = searcher.search(new TermQuery(new Term(new String(\"utf8\"), \"lu\\uD834\\uDD1Ece\\uD834\\uDD60ne\")), null, 1000).scoreDocs;\n    assertEquals(34, hits.length);\n    hits = searcher.search(new TermQuery(new Term(\"utf8\", \"ab\\ud917\\udc17cd\")), null, 1000).scoreDocs;\n    assertEquals(34, hits.length);\n\n    reader.close();\n  }\n\n","bugFix":["c5c0bd3bf61809aea862d848dcf2119d3b9c38bf","5a3b444707abab6c7f63c331b3f44971c53b0f07"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3fe3b1894255151160e7a26231483e8ab0e310a7","date":1362971493,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestBackwardsCompatibility#searchIndex(Directory,String).mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestBackwardsCompatibility#searchIndex(Directory,String).mjava","sourceNew":"  public void searchIndex(Directory dir, String oldName) throws IOException {\n    //QueryParser parser = new QueryParser(\"contents\", new MockAnalyzer(random));\n    //Query query = parser.parse(\"handle:1\");\n\n    IndexReader reader = DirectoryReader.open(dir);\n    IndexSearcher searcher = new IndexSearcher(reader);\n\n    _TestUtil.checkIndex(dir);\n    \n    // true if this is a 4.0+ index\n    final boolean is40Index = MultiFields.getMergedFieldInfos(reader).fieldInfo(\"content5\") != null;\n    // true if this is a 4.2+ index\n    final boolean is42Index = MultiFields.getMergedFieldInfos(reader).fieldInfo(\"dvSortedSet\") != null;\n\n    assert is40Index; // NOTE: currently we can only do this on trunk!\n\n    final Bits liveDocs = MultiFields.getLiveDocs(reader);\n\n    for(int i=0;i<35;i++) {\n      if (liveDocs.get(i)) {\n        StoredDocument d = reader.document(i);\n        List<StorableField> fields = d.getFields();\n        boolean isProxDoc = d.getField(\"content3\") == null;\n        if (isProxDoc) {\n          final int numFields = is40Index ? 7 : 5;\n          assertEquals(numFields, fields.size());\n          StorableField f =  d.getField(\"id\");\n          assertEquals(\"\"+i, f.stringValue());\n\n          f = d.getField(\"utf8\");\n          assertEquals(\"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne \\u0000 \\u2620 ab\\ud917\\udc17cd\", f.stringValue());\n\n          f =  d.getField(\"autf8\");\n          assertEquals(\"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne \\u0000 \\u2620 ab\\ud917\\udc17cd\", f.stringValue());\n      \n          f = d.getField(\"content2\");\n          assertEquals(\"here is more content with aaa aaa aaa\", f.stringValue());\n\n          f = d.getField(\"fie\\u2C77ld\");\n          assertEquals(\"field with non-ascii name\", f.stringValue());\n        }\n\n        Fields tfvFields = reader.getTermVectors(i);\n        assertNotNull(\"i=\" + i, tfvFields);\n        Terms tfv = tfvFields.terms(\"utf8\");\n        assertNotNull(\"docID=\" + i + \" index=\" + oldName, tfv);\n      } else {\n        // Only ID 7 is deleted\n        assertEquals(7, i);\n      }\n    }\n\n    if (is40Index) {\n      // check docvalues fields\n      NumericDocValues dvByte = MultiDocValues.getNumericValues(reader, \"dvByte\");\n      BinaryDocValues dvBytesDerefFixed = MultiDocValues.getBinaryValues(reader, \"dvBytesDerefFixed\");\n      BinaryDocValues dvBytesDerefVar = MultiDocValues.getBinaryValues(reader, \"dvBytesDerefVar\");\n      SortedDocValues dvBytesSortedFixed = MultiDocValues.getSortedValues(reader, \"dvBytesSortedFixed\");\n      SortedDocValues dvBytesSortedVar = MultiDocValues.getSortedValues(reader, \"dvBytesSortedVar\");\n      BinaryDocValues dvBytesStraightFixed = MultiDocValues.getBinaryValues(reader, \"dvBytesStraightFixed\");\n      BinaryDocValues dvBytesStraightVar = MultiDocValues.getBinaryValues(reader, \"dvBytesStraightVar\");\n      NumericDocValues dvDouble = MultiDocValues.getNumericValues(reader, \"dvDouble\");\n      NumericDocValues dvFloat = MultiDocValues.getNumericValues(reader, \"dvFloat\");\n      NumericDocValues dvInt = MultiDocValues.getNumericValues(reader, \"dvInt\");\n      NumericDocValues dvLong = MultiDocValues.getNumericValues(reader, \"dvLong\");\n      NumericDocValues dvPacked = MultiDocValues.getNumericValues(reader, \"dvPacked\");\n      NumericDocValues dvShort = MultiDocValues.getNumericValues(reader, \"dvShort\");\n      SortedSetDocValues dvSortedSet = null;\n      if (is42Index) {\n        dvSortedSet = MultiDocValues.getSortedSetValues(reader, \"dvSortedSet\");\n      }\n      \n      for (int i=0;i<35;i++) {\n        int id = Integer.parseInt(reader.document(i).get(\"id\"));\n        assertEquals(id, dvByte.get(i));\n        \n        byte bytes[] = new byte[] {\n            (byte)(id >>> 24), (byte)(id >>> 16),(byte)(id >>> 8),(byte)id\n        };\n        BytesRef expectedRef = new BytesRef(bytes);\n        BytesRef scratch = new BytesRef();\n        \n        dvBytesDerefFixed.get(i, scratch);\n        assertEquals(expectedRef, scratch);\n        dvBytesDerefVar.get(i, scratch);\n        assertEquals(expectedRef, scratch);\n        dvBytesSortedFixed.get(i, scratch);\n        assertEquals(expectedRef, scratch);\n        dvBytesSortedVar.get(i, scratch);\n        assertEquals(expectedRef, scratch);\n        dvBytesStraightFixed.get(i, scratch);\n        assertEquals(expectedRef, scratch);\n        dvBytesStraightVar.get(i, scratch);\n        assertEquals(expectedRef, scratch);\n        \n        assertEquals((double)id, Double.longBitsToDouble(dvDouble.get(i)), 0D);\n        assertEquals((float)id, Float.intBitsToFloat((int)dvFloat.get(i)), 0F);\n        assertEquals(id, dvInt.get(i));\n        assertEquals(id, dvLong.get(i));\n        assertEquals(id, dvPacked.get(i));\n        assertEquals(id, dvShort.get(i));\n        if (is42Index) {\n          dvSortedSet.setDocument(i);\n          long ord = dvSortedSet.nextOrd();\n          assertEquals(SortedSetDocValues.NO_MORE_ORDS, dvSortedSet.nextOrd());\n          dvSortedSet.lookupOrd(ord, scratch);\n          assertEquals(expectedRef, scratch);\n        }\n      }\n    }\n    \n    ScoreDoc[] hits = searcher.search(new TermQuery(new Term(new String(\"content\"), \"aaa\")), null, 1000).scoreDocs;\n\n    // First document should be #0\n    StoredDocument d = searcher.getIndexReader().document(hits[0].doc);\n    assertEquals(\"didn't get the right document first\", \"0\", d.get(\"id\"));\n\n    doTestHits(hits, 34, searcher.getIndexReader());\n    \n    if (is40Index) {\n      hits = searcher.search(new TermQuery(new Term(new String(\"content5\"), \"aaa\")), null, 1000).scoreDocs;\n\n      doTestHits(hits, 34, searcher.getIndexReader());\n    \n      hits = searcher.search(new TermQuery(new Term(new String(\"content6\"), \"aaa\")), null, 1000).scoreDocs;\n\n      doTestHits(hits, 34, searcher.getIndexReader());\n    }\n\n    hits = searcher.search(new TermQuery(new Term(\"utf8\", \"\\u0000\")), null, 1000).scoreDocs;\n    assertEquals(34, hits.length);\n    hits = searcher.search(new TermQuery(new Term(new String(\"utf8\"), \"lu\\uD834\\uDD1Ece\\uD834\\uDD60ne\")), null, 1000).scoreDocs;\n    assertEquals(34, hits.length);\n    hits = searcher.search(new TermQuery(new Term(\"utf8\", \"ab\\ud917\\udc17cd\")), null, 1000).scoreDocs;\n    assertEquals(34, hits.length);\n\n    reader.close();\n  }\n\n","sourceOld":"  public void searchIndex(Directory dir, String oldName) throws IOException {\n    //QueryParser parser = new QueryParser(\"contents\", new MockAnalyzer(random));\n    //Query query = parser.parse(\"handle:1\");\n\n    IndexReader reader = DirectoryReader.open(dir);\n    IndexSearcher searcher = new IndexSearcher(reader);\n\n    _TestUtil.checkIndex(dir);\n    \n    // true if this is a 4.0+ index\n    final boolean is40Index = MultiFields.getMergedFieldInfos(reader).fieldInfo(\"content5\") != null;\n    assert is40Index; // NOTE: currently we can only do this on trunk!\n\n    final Bits liveDocs = MultiFields.getLiveDocs(reader);\n\n    for(int i=0;i<35;i++) {\n      if (liveDocs.get(i)) {\n        StoredDocument d = reader.document(i);\n        List<StorableField> fields = d.getFields();\n        boolean isProxDoc = d.getField(\"content3\") == null;\n        if (isProxDoc) {\n          final int numFields = is40Index ? 7 : 5;\n          assertEquals(numFields, fields.size());\n          StorableField f =  d.getField(\"id\");\n          assertEquals(\"\"+i, f.stringValue());\n\n          f = d.getField(\"utf8\");\n          assertEquals(\"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne \\u0000 \\u2620 ab\\ud917\\udc17cd\", f.stringValue());\n\n          f =  d.getField(\"autf8\");\n          assertEquals(\"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne \\u0000 \\u2620 ab\\ud917\\udc17cd\", f.stringValue());\n      \n          f = d.getField(\"content2\");\n          assertEquals(\"here is more content with aaa aaa aaa\", f.stringValue());\n\n          f = d.getField(\"fie\\u2C77ld\");\n          assertEquals(\"field with non-ascii name\", f.stringValue());\n        }\n\n        Fields tfvFields = reader.getTermVectors(i);\n        assertNotNull(\"i=\" + i, tfvFields);\n        Terms tfv = tfvFields.terms(\"utf8\");\n        assertNotNull(\"docID=\" + i + \" index=\" + oldName, tfv);\n      } else {\n        // Only ID 7 is deleted\n        assertEquals(7, i);\n      }\n    }\n\n    if (is40Index) {\n      // check docvalues fields\n      NumericDocValues dvByte = MultiDocValues.getNumericValues(reader, \"dvByte\");\n      BinaryDocValues dvBytesDerefFixed = MultiDocValues.getBinaryValues(reader, \"dvBytesDerefFixed\");\n      BinaryDocValues dvBytesDerefVar = MultiDocValues.getBinaryValues(reader, \"dvBytesDerefVar\");\n      SortedDocValues dvBytesSortedFixed = MultiDocValues.getSortedValues(reader, \"dvBytesSortedFixed\");\n      SortedDocValues dvBytesSortedVar = MultiDocValues.getSortedValues(reader, \"dvBytesSortedVar\");\n      BinaryDocValues dvBytesStraightFixed = MultiDocValues.getBinaryValues(reader, \"dvBytesStraightFixed\");\n      BinaryDocValues dvBytesStraightVar = MultiDocValues.getBinaryValues(reader, \"dvBytesStraightVar\");\n      NumericDocValues dvDouble = MultiDocValues.getNumericValues(reader, \"dvDouble\");\n      NumericDocValues dvFloat = MultiDocValues.getNumericValues(reader, \"dvFloat\");\n      NumericDocValues dvInt = MultiDocValues.getNumericValues(reader, \"dvInt\");\n      NumericDocValues dvLong = MultiDocValues.getNumericValues(reader, \"dvLong\");\n      NumericDocValues dvPacked = MultiDocValues.getNumericValues(reader, \"dvPacked\");\n      NumericDocValues dvShort = MultiDocValues.getNumericValues(reader, \"dvShort\");\n      \n      for (int i=0;i<35;i++) {\n        int id = Integer.parseInt(reader.document(i).get(\"id\"));\n        assertEquals(id, dvByte.get(i));\n        \n        byte bytes[] = new byte[] {\n            (byte)(id >>> 24), (byte)(id >>> 16),(byte)(id >>> 8),(byte)id\n        };\n        BytesRef expectedRef = new BytesRef(bytes);\n        BytesRef scratch = new BytesRef();\n        \n        dvBytesDerefFixed.get(i, scratch);\n        assertEquals(expectedRef, scratch);\n        dvBytesDerefVar.get(i, scratch);\n        assertEquals(expectedRef, scratch);\n        dvBytesSortedFixed.get(i, scratch);\n        assertEquals(expectedRef, scratch);\n        dvBytesSortedVar.get(i, scratch);\n        assertEquals(expectedRef, scratch);\n        dvBytesStraightFixed.get(i, scratch);\n        assertEquals(expectedRef, scratch);\n        dvBytesStraightVar.get(i, scratch);\n        assertEquals(expectedRef, scratch);\n        \n        assertEquals((double)id, Double.longBitsToDouble(dvDouble.get(i)), 0D);\n        assertEquals((float)id, Float.intBitsToFloat((int)dvFloat.get(i)), 0F);\n        assertEquals(id, dvInt.get(i));\n        assertEquals(id, dvLong.get(i));\n        assertEquals(id, dvPacked.get(i));\n        assertEquals(id, dvShort.get(i));\n      }\n    }\n    \n    ScoreDoc[] hits = searcher.search(new TermQuery(new Term(new String(\"content\"), \"aaa\")), null, 1000).scoreDocs;\n\n    // First document should be #0\n    StoredDocument d = searcher.getIndexReader().document(hits[0].doc);\n    assertEquals(\"didn't get the right document first\", \"0\", d.get(\"id\"));\n\n    doTestHits(hits, 34, searcher.getIndexReader());\n    \n    if (is40Index) {\n      hits = searcher.search(new TermQuery(new Term(new String(\"content5\"), \"aaa\")), null, 1000).scoreDocs;\n\n      doTestHits(hits, 34, searcher.getIndexReader());\n    \n      hits = searcher.search(new TermQuery(new Term(new String(\"content6\"), \"aaa\")), null, 1000).scoreDocs;\n\n      doTestHits(hits, 34, searcher.getIndexReader());\n    }\n\n    hits = searcher.search(new TermQuery(new Term(\"utf8\", \"\\u0000\")), null, 1000).scoreDocs;\n    assertEquals(34, hits.length);\n    hits = searcher.search(new TermQuery(new Term(new String(\"utf8\"), \"lu\\uD834\\uDD1Ece\\uD834\\uDD60ne\")), null, 1000).scoreDocs;\n    assertEquals(34, hits.length);\n    hits = searcher.search(new TermQuery(new Term(\"utf8\", \"ab\\ud917\\udc17cd\")), null, 1000).scoreDocs;\n    assertEquals(34, hits.length);\n\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3b0e8c39ca08b5a02de6edcd33d6f3b90b865173","date":1365631993,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestBackwardsCompatibility#searchIndex(Directory,String).mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestBackwardsCompatibility#searchIndex(Directory,String).mjava","sourceNew":"  public void searchIndex(Directory dir, String oldName) throws IOException {\n    //QueryParser parser = new QueryParser(\"contents\", new MockAnalyzer(random));\n    //Query query = parser.parse(\"handle:1\");\n\n    IndexReader reader = DirectoryReader.open(dir);\n    IndexSearcher searcher = newSearcher(reader);\n\n    _TestUtil.checkIndex(dir);\n    \n    // true if this is a 4.0+ index\n    final boolean is40Index = MultiFields.getMergedFieldInfos(reader).fieldInfo(\"content5\") != null;\n    // true if this is a 4.2+ index\n    final boolean is42Index = MultiFields.getMergedFieldInfos(reader).fieldInfo(\"dvSortedSet\") != null;\n\n    assert is40Index; // NOTE: currently we can only do this on trunk!\n\n    final Bits liveDocs = MultiFields.getLiveDocs(reader);\n\n    for(int i=0;i<35;i++) {\n      if (liveDocs.get(i)) {\n        StoredDocument d = reader.document(i);\n        List<StorableField> fields = d.getFields();\n        boolean isProxDoc = d.getField(\"content3\") == null;\n        if (isProxDoc) {\n          final int numFields = is40Index ? 7 : 5;\n          assertEquals(numFields, fields.size());\n          StorableField f =  d.getField(\"id\");\n          assertEquals(\"\"+i, f.stringValue());\n\n          f = d.getField(\"utf8\");\n          assertEquals(\"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne \\u0000 \\u2620 ab\\ud917\\udc17cd\", f.stringValue());\n\n          f =  d.getField(\"autf8\");\n          assertEquals(\"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne \\u0000 \\u2620 ab\\ud917\\udc17cd\", f.stringValue());\n      \n          f = d.getField(\"content2\");\n          assertEquals(\"here is more content with aaa aaa aaa\", f.stringValue());\n\n          f = d.getField(\"fie\\u2C77ld\");\n          assertEquals(\"field with non-ascii name\", f.stringValue());\n        }\n\n        Fields tfvFields = reader.getTermVectors(i);\n        assertNotNull(\"i=\" + i, tfvFields);\n        Terms tfv = tfvFields.terms(\"utf8\");\n        assertNotNull(\"docID=\" + i + \" index=\" + oldName, tfv);\n      } else {\n        // Only ID 7 is deleted\n        assertEquals(7, i);\n      }\n    }\n\n    if (is40Index) {\n      // check docvalues fields\n      NumericDocValues dvByte = MultiDocValues.getNumericValues(reader, \"dvByte\");\n      BinaryDocValues dvBytesDerefFixed = MultiDocValues.getBinaryValues(reader, \"dvBytesDerefFixed\");\n      BinaryDocValues dvBytesDerefVar = MultiDocValues.getBinaryValues(reader, \"dvBytesDerefVar\");\n      SortedDocValues dvBytesSortedFixed = MultiDocValues.getSortedValues(reader, \"dvBytesSortedFixed\");\n      SortedDocValues dvBytesSortedVar = MultiDocValues.getSortedValues(reader, \"dvBytesSortedVar\");\n      BinaryDocValues dvBytesStraightFixed = MultiDocValues.getBinaryValues(reader, \"dvBytesStraightFixed\");\n      BinaryDocValues dvBytesStraightVar = MultiDocValues.getBinaryValues(reader, \"dvBytesStraightVar\");\n      NumericDocValues dvDouble = MultiDocValues.getNumericValues(reader, \"dvDouble\");\n      NumericDocValues dvFloat = MultiDocValues.getNumericValues(reader, \"dvFloat\");\n      NumericDocValues dvInt = MultiDocValues.getNumericValues(reader, \"dvInt\");\n      NumericDocValues dvLong = MultiDocValues.getNumericValues(reader, \"dvLong\");\n      NumericDocValues dvPacked = MultiDocValues.getNumericValues(reader, \"dvPacked\");\n      NumericDocValues dvShort = MultiDocValues.getNumericValues(reader, \"dvShort\");\n      SortedSetDocValues dvSortedSet = null;\n      if (is42Index) {\n        dvSortedSet = MultiDocValues.getSortedSetValues(reader, \"dvSortedSet\");\n      }\n      \n      for (int i=0;i<35;i++) {\n        int id = Integer.parseInt(reader.document(i).get(\"id\"));\n        assertEquals(id, dvByte.get(i));\n        \n        byte bytes[] = new byte[] {\n            (byte)(id >>> 24), (byte)(id >>> 16),(byte)(id >>> 8),(byte)id\n        };\n        BytesRef expectedRef = new BytesRef(bytes);\n        BytesRef scratch = new BytesRef();\n        \n        dvBytesDerefFixed.get(i, scratch);\n        assertEquals(expectedRef, scratch);\n        dvBytesDerefVar.get(i, scratch);\n        assertEquals(expectedRef, scratch);\n        dvBytesSortedFixed.get(i, scratch);\n        assertEquals(expectedRef, scratch);\n        dvBytesSortedVar.get(i, scratch);\n        assertEquals(expectedRef, scratch);\n        dvBytesStraightFixed.get(i, scratch);\n        assertEquals(expectedRef, scratch);\n        dvBytesStraightVar.get(i, scratch);\n        assertEquals(expectedRef, scratch);\n        \n        assertEquals((double)id, Double.longBitsToDouble(dvDouble.get(i)), 0D);\n        assertEquals((float)id, Float.intBitsToFloat((int)dvFloat.get(i)), 0F);\n        assertEquals(id, dvInt.get(i));\n        assertEquals(id, dvLong.get(i));\n        assertEquals(id, dvPacked.get(i));\n        assertEquals(id, dvShort.get(i));\n        if (is42Index) {\n          dvSortedSet.setDocument(i);\n          long ord = dvSortedSet.nextOrd();\n          assertEquals(SortedSetDocValues.NO_MORE_ORDS, dvSortedSet.nextOrd());\n          dvSortedSet.lookupOrd(ord, scratch);\n          assertEquals(expectedRef, scratch);\n        }\n      }\n    }\n    \n    ScoreDoc[] hits = searcher.search(new TermQuery(new Term(new String(\"content\"), \"aaa\")), null, 1000).scoreDocs;\n\n    // First document should be #0\n    StoredDocument d = searcher.getIndexReader().document(hits[0].doc);\n    assertEquals(\"didn't get the right document first\", \"0\", d.get(\"id\"));\n\n    doTestHits(hits, 34, searcher.getIndexReader());\n    \n    if (is40Index) {\n      hits = searcher.search(new TermQuery(new Term(new String(\"content5\"), \"aaa\")), null, 1000).scoreDocs;\n\n      doTestHits(hits, 34, searcher.getIndexReader());\n    \n      hits = searcher.search(new TermQuery(new Term(new String(\"content6\"), \"aaa\")), null, 1000).scoreDocs;\n\n      doTestHits(hits, 34, searcher.getIndexReader());\n    }\n\n    hits = searcher.search(new TermQuery(new Term(\"utf8\", \"\\u0000\")), null, 1000).scoreDocs;\n    assertEquals(34, hits.length);\n    hits = searcher.search(new TermQuery(new Term(new String(\"utf8\"), \"lu\\uD834\\uDD1Ece\\uD834\\uDD60ne\")), null, 1000).scoreDocs;\n    assertEquals(34, hits.length);\n    hits = searcher.search(new TermQuery(new Term(\"utf8\", \"ab\\ud917\\udc17cd\")), null, 1000).scoreDocs;\n    assertEquals(34, hits.length);\n\n    reader.close();\n  }\n\n","sourceOld":"  public void searchIndex(Directory dir, String oldName) throws IOException {\n    //QueryParser parser = new QueryParser(\"contents\", new MockAnalyzer(random));\n    //Query query = parser.parse(\"handle:1\");\n\n    IndexReader reader = DirectoryReader.open(dir);\n    IndexSearcher searcher = new IndexSearcher(reader);\n\n    _TestUtil.checkIndex(dir);\n    \n    // true if this is a 4.0+ index\n    final boolean is40Index = MultiFields.getMergedFieldInfos(reader).fieldInfo(\"content5\") != null;\n    // true if this is a 4.2+ index\n    final boolean is42Index = MultiFields.getMergedFieldInfos(reader).fieldInfo(\"dvSortedSet\") != null;\n\n    assert is40Index; // NOTE: currently we can only do this on trunk!\n\n    final Bits liveDocs = MultiFields.getLiveDocs(reader);\n\n    for(int i=0;i<35;i++) {\n      if (liveDocs.get(i)) {\n        StoredDocument d = reader.document(i);\n        List<StorableField> fields = d.getFields();\n        boolean isProxDoc = d.getField(\"content3\") == null;\n        if (isProxDoc) {\n          final int numFields = is40Index ? 7 : 5;\n          assertEquals(numFields, fields.size());\n          StorableField f =  d.getField(\"id\");\n          assertEquals(\"\"+i, f.stringValue());\n\n          f = d.getField(\"utf8\");\n          assertEquals(\"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne \\u0000 \\u2620 ab\\ud917\\udc17cd\", f.stringValue());\n\n          f =  d.getField(\"autf8\");\n          assertEquals(\"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne \\u0000 \\u2620 ab\\ud917\\udc17cd\", f.stringValue());\n      \n          f = d.getField(\"content2\");\n          assertEquals(\"here is more content with aaa aaa aaa\", f.stringValue());\n\n          f = d.getField(\"fie\\u2C77ld\");\n          assertEquals(\"field with non-ascii name\", f.stringValue());\n        }\n\n        Fields tfvFields = reader.getTermVectors(i);\n        assertNotNull(\"i=\" + i, tfvFields);\n        Terms tfv = tfvFields.terms(\"utf8\");\n        assertNotNull(\"docID=\" + i + \" index=\" + oldName, tfv);\n      } else {\n        // Only ID 7 is deleted\n        assertEquals(7, i);\n      }\n    }\n\n    if (is40Index) {\n      // check docvalues fields\n      NumericDocValues dvByte = MultiDocValues.getNumericValues(reader, \"dvByte\");\n      BinaryDocValues dvBytesDerefFixed = MultiDocValues.getBinaryValues(reader, \"dvBytesDerefFixed\");\n      BinaryDocValues dvBytesDerefVar = MultiDocValues.getBinaryValues(reader, \"dvBytesDerefVar\");\n      SortedDocValues dvBytesSortedFixed = MultiDocValues.getSortedValues(reader, \"dvBytesSortedFixed\");\n      SortedDocValues dvBytesSortedVar = MultiDocValues.getSortedValues(reader, \"dvBytesSortedVar\");\n      BinaryDocValues dvBytesStraightFixed = MultiDocValues.getBinaryValues(reader, \"dvBytesStraightFixed\");\n      BinaryDocValues dvBytesStraightVar = MultiDocValues.getBinaryValues(reader, \"dvBytesStraightVar\");\n      NumericDocValues dvDouble = MultiDocValues.getNumericValues(reader, \"dvDouble\");\n      NumericDocValues dvFloat = MultiDocValues.getNumericValues(reader, \"dvFloat\");\n      NumericDocValues dvInt = MultiDocValues.getNumericValues(reader, \"dvInt\");\n      NumericDocValues dvLong = MultiDocValues.getNumericValues(reader, \"dvLong\");\n      NumericDocValues dvPacked = MultiDocValues.getNumericValues(reader, \"dvPacked\");\n      NumericDocValues dvShort = MultiDocValues.getNumericValues(reader, \"dvShort\");\n      SortedSetDocValues dvSortedSet = null;\n      if (is42Index) {\n        dvSortedSet = MultiDocValues.getSortedSetValues(reader, \"dvSortedSet\");\n      }\n      \n      for (int i=0;i<35;i++) {\n        int id = Integer.parseInt(reader.document(i).get(\"id\"));\n        assertEquals(id, dvByte.get(i));\n        \n        byte bytes[] = new byte[] {\n            (byte)(id >>> 24), (byte)(id >>> 16),(byte)(id >>> 8),(byte)id\n        };\n        BytesRef expectedRef = new BytesRef(bytes);\n        BytesRef scratch = new BytesRef();\n        \n        dvBytesDerefFixed.get(i, scratch);\n        assertEquals(expectedRef, scratch);\n        dvBytesDerefVar.get(i, scratch);\n        assertEquals(expectedRef, scratch);\n        dvBytesSortedFixed.get(i, scratch);\n        assertEquals(expectedRef, scratch);\n        dvBytesSortedVar.get(i, scratch);\n        assertEquals(expectedRef, scratch);\n        dvBytesStraightFixed.get(i, scratch);\n        assertEquals(expectedRef, scratch);\n        dvBytesStraightVar.get(i, scratch);\n        assertEquals(expectedRef, scratch);\n        \n        assertEquals((double)id, Double.longBitsToDouble(dvDouble.get(i)), 0D);\n        assertEquals((float)id, Float.intBitsToFloat((int)dvFloat.get(i)), 0F);\n        assertEquals(id, dvInt.get(i));\n        assertEquals(id, dvLong.get(i));\n        assertEquals(id, dvPacked.get(i));\n        assertEquals(id, dvShort.get(i));\n        if (is42Index) {\n          dvSortedSet.setDocument(i);\n          long ord = dvSortedSet.nextOrd();\n          assertEquals(SortedSetDocValues.NO_MORE_ORDS, dvSortedSet.nextOrd());\n          dvSortedSet.lookupOrd(ord, scratch);\n          assertEquals(expectedRef, scratch);\n        }\n      }\n    }\n    \n    ScoreDoc[] hits = searcher.search(new TermQuery(new Term(new String(\"content\"), \"aaa\")), null, 1000).scoreDocs;\n\n    // First document should be #0\n    StoredDocument d = searcher.getIndexReader().document(hits[0].doc);\n    assertEquals(\"didn't get the right document first\", \"0\", d.get(\"id\"));\n\n    doTestHits(hits, 34, searcher.getIndexReader());\n    \n    if (is40Index) {\n      hits = searcher.search(new TermQuery(new Term(new String(\"content5\"), \"aaa\")), null, 1000).scoreDocs;\n\n      doTestHits(hits, 34, searcher.getIndexReader());\n    \n      hits = searcher.search(new TermQuery(new Term(new String(\"content6\"), \"aaa\")), null, 1000).scoreDocs;\n\n      doTestHits(hits, 34, searcher.getIndexReader());\n    }\n\n    hits = searcher.search(new TermQuery(new Term(\"utf8\", \"\\u0000\")), null, 1000).scoreDocs;\n    assertEquals(34, hits.length);\n    hits = searcher.search(new TermQuery(new Term(new String(\"utf8\"), \"lu\\uD834\\uDD1Ece\\uD834\\uDD60ne\")), null, 1000).scoreDocs;\n    assertEquals(34, hits.length);\n    hits = searcher.search(new TermQuery(new Term(\"utf8\", \"ab\\ud917\\udc17cd\")), null, 1000).scoreDocs;\n    assertEquals(34, hits.length);\n\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6613659748fe4411a7dcf85266e55db1f95f7315","date":1392773913,"type":3,"author":"Benson Margulies","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestBackwardsCompatibility#searchIndex(Directory,String).mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestBackwardsCompatibility#searchIndex(Directory,String).mjava","sourceNew":"  public void searchIndex(Directory dir, String oldName) throws IOException {\n    //QueryParser parser = new QueryParser(\"contents\", new MockAnalyzer(random));\n    //Query query = parser.parse(\"handle:1\");\n\n    IndexReader reader = DirectoryReader.open(dir);\n    IndexSearcher searcher = newSearcher(reader);\n\n    TestUtil.checkIndex(dir);\n    \n    // true if this is a 4.0+ index\n    final boolean is40Index = MultiFields.getMergedFieldInfos(reader).fieldInfo(\"content5\") != null;\n    // true if this is a 4.2+ index\n    final boolean is42Index = MultiFields.getMergedFieldInfos(reader).fieldInfo(\"dvSortedSet\") != null;\n\n    assert is40Index; // NOTE: currently we can only do this on trunk!\n\n    final Bits liveDocs = MultiFields.getLiveDocs(reader);\n\n    for(int i=0;i<35;i++) {\n      if (liveDocs.get(i)) {\n        StoredDocument d = reader.document(i);\n        List<StorableField> fields = d.getFields();\n        boolean isProxDoc = d.getField(\"content3\") == null;\n        if (isProxDoc) {\n          final int numFields = is40Index ? 7 : 5;\n          assertEquals(numFields, fields.size());\n          StorableField f =  d.getField(\"id\");\n          assertEquals(\"\"+i, f.stringValue());\n\n          f = d.getField(\"utf8\");\n          assertEquals(\"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne \\u0000 \\u2620 ab\\ud917\\udc17cd\", f.stringValue());\n\n          f =  d.getField(\"autf8\");\n          assertEquals(\"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne \\u0000 \\u2620 ab\\ud917\\udc17cd\", f.stringValue());\n      \n          f = d.getField(\"content2\");\n          assertEquals(\"here is more content with aaa aaa aaa\", f.stringValue());\n\n          f = d.getField(\"fie\\u2C77ld\");\n          assertEquals(\"field with non-ascii name\", f.stringValue());\n        }\n\n        Fields tfvFields = reader.getTermVectors(i);\n        assertNotNull(\"i=\" + i, tfvFields);\n        Terms tfv = tfvFields.terms(\"utf8\");\n        assertNotNull(\"docID=\" + i + \" index=\" + oldName, tfv);\n      } else {\n        // Only ID 7 is deleted\n        assertEquals(7, i);\n      }\n    }\n\n    if (is40Index) {\n      // check docvalues fields\n      NumericDocValues dvByte = MultiDocValues.getNumericValues(reader, \"dvByte\");\n      BinaryDocValues dvBytesDerefFixed = MultiDocValues.getBinaryValues(reader, \"dvBytesDerefFixed\");\n      BinaryDocValues dvBytesDerefVar = MultiDocValues.getBinaryValues(reader, \"dvBytesDerefVar\");\n      SortedDocValues dvBytesSortedFixed = MultiDocValues.getSortedValues(reader, \"dvBytesSortedFixed\");\n      SortedDocValues dvBytesSortedVar = MultiDocValues.getSortedValues(reader, \"dvBytesSortedVar\");\n      BinaryDocValues dvBytesStraightFixed = MultiDocValues.getBinaryValues(reader, \"dvBytesStraightFixed\");\n      BinaryDocValues dvBytesStraightVar = MultiDocValues.getBinaryValues(reader, \"dvBytesStraightVar\");\n      NumericDocValues dvDouble = MultiDocValues.getNumericValues(reader, \"dvDouble\");\n      NumericDocValues dvFloat = MultiDocValues.getNumericValues(reader, \"dvFloat\");\n      NumericDocValues dvInt = MultiDocValues.getNumericValues(reader, \"dvInt\");\n      NumericDocValues dvLong = MultiDocValues.getNumericValues(reader, \"dvLong\");\n      NumericDocValues dvPacked = MultiDocValues.getNumericValues(reader, \"dvPacked\");\n      NumericDocValues dvShort = MultiDocValues.getNumericValues(reader, \"dvShort\");\n      SortedSetDocValues dvSortedSet = null;\n      if (is42Index) {\n        dvSortedSet = MultiDocValues.getSortedSetValues(reader, \"dvSortedSet\");\n      }\n      \n      for (int i=0;i<35;i++) {\n        int id = Integer.parseInt(reader.document(i).get(\"id\"));\n        assertEquals(id, dvByte.get(i));\n        \n        byte bytes[] = new byte[] {\n            (byte)(id >>> 24), (byte)(id >>> 16),(byte)(id >>> 8),(byte)id\n        };\n        BytesRef expectedRef = new BytesRef(bytes);\n        BytesRef scratch = new BytesRef();\n        \n        dvBytesDerefFixed.get(i, scratch);\n        assertEquals(expectedRef, scratch);\n        dvBytesDerefVar.get(i, scratch);\n        assertEquals(expectedRef, scratch);\n        dvBytesSortedFixed.get(i, scratch);\n        assertEquals(expectedRef, scratch);\n        dvBytesSortedVar.get(i, scratch);\n        assertEquals(expectedRef, scratch);\n        dvBytesStraightFixed.get(i, scratch);\n        assertEquals(expectedRef, scratch);\n        dvBytesStraightVar.get(i, scratch);\n        assertEquals(expectedRef, scratch);\n        \n        assertEquals((double)id, Double.longBitsToDouble(dvDouble.get(i)), 0D);\n        assertEquals((float)id, Float.intBitsToFloat((int)dvFloat.get(i)), 0F);\n        assertEquals(id, dvInt.get(i));\n        assertEquals(id, dvLong.get(i));\n        assertEquals(id, dvPacked.get(i));\n        assertEquals(id, dvShort.get(i));\n        if (is42Index) {\n          dvSortedSet.setDocument(i);\n          long ord = dvSortedSet.nextOrd();\n          assertEquals(SortedSetDocValues.NO_MORE_ORDS, dvSortedSet.nextOrd());\n          dvSortedSet.lookupOrd(ord, scratch);\n          assertEquals(expectedRef, scratch);\n        }\n      }\n    }\n    \n    ScoreDoc[] hits = searcher.search(new TermQuery(new Term(new String(\"content\"), \"aaa\")), null, 1000).scoreDocs;\n\n    // First document should be #0\n    StoredDocument d = searcher.getIndexReader().document(hits[0].doc);\n    assertEquals(\"didn't get the right document first\", \"0\", d.get(\"id\"));\n\n    doTestHits(hits, 34, searcher.getIndexReader());\n    \n    if (is40Index) {\n      hits = searcher.search(new TermQuery(new Term(new String(\"content5\"), \"aaa\")), null, 1000).scoreDocs;\n\n      doTestHits(hits, 34, searcher.getIndexReader());\n    \n      hits = searcher.search(new TermQuery(new Term(new String(\"content6\"), \"aaa\")), null, 1000).scoreDocs;\n\n      doTestHits(hits, 34, searcher.getIndexReader());\n    }\n\n    hits = searcher.search(new TermQuery(new Term(\"utf8\", \"\\u0000\")), null, 1000).scoreDocs;\n    assertEquals(34, hits.length);\n    hits = searcher.search(new TermQuery(new Term(new String(\"utf8\"), \"lu\\uD834\\uDD1Ece\\uD834\\uDD60ne\")), null, 1000).scoreDocs;\n    assertEquals(34, hits.length);\n    hits = searcher.search(new TermQuery(new Term(\"utf8\", \"ab\\ud917\\udc17cd\")), null, 1000).scoreDocs;\n    assertEquals(34, hits.length);\n\n    reader.close();\n  }\n\n","sourceOld":"  public void searchIndex(Directory dir, String oldName) throws IOException {\n    //QueryParser parser = new QueryParser(\"contents\", new MockAnalyzer(random));\n    //Query query = parser.parse(\"handle:1\");\n\n    IndexReader reader = DirectoryReader.open(dir);\n    IndexSearcher searcher = newSearcher(reader);\n\n    _TestUtil.checkIndex(dir);\n    \n    // true if this is a 4.0+ index\n    final boolean is40Index = MultiFields.getMergedFieldInfos(reader).fieldInfo(\"content5\") != null;\n    // true if this is a 4.2+ index\n    final boolean is42Index = MultiFields.getMergedFieldInfos(reader).fieldInfo(\"dvSortedSet\") != null;\n\n    assert is40Index; // NOTE: currently we can only do this on trunk!\n\n    final Bits liveDocs = MultiFields.getLiveDocs(reader);\n\n    for(int i=0;i<35;i++) {\n      if (liveDocs.get(i)) {\n        StoredDocument d = reader.document(i);\n        List<StorableField> fields = d.getFields();\n        boolean isProxDoc = d.getField(\"content3\") == null;\n        if (isProxDoc) {\n          final int numFields = is40Index ? 7 : 5;\n          assertEquals(numFields, fields.size());\n          StorableField f =  d.getField(\"id\");\n          assertEquals(\"\"+i, f.stringValue());\n\n          f = d.getField(\"utf8\");\n          assertEquals(\"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne \\u0000 \\u2620 ab\\ud917\\udc17cd\", f.stringValue());\n\n          f =  d.getField(\"autf8\");\n          assertEquals(\"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne \\u0000 \\u2620 ab\\ud917\\udc17cd\", f.stringValue());\n      \n          f = d.getField(\"content2\");\n          assertEquals(\"here is more content with aaa aaa aaa\", f.stringValue());\n\n          f = d.getField(\"fie\\u2C77ld\");\n          assertEquals(\"field with non-ascii name\", f.stringValue());\n        }\n\n        Fields tfvFields = reader.getTermVectors(i);\n        assertNotNull(\"i=\" + i, tfvFields);\n        Terms tfv = tfvFields.terms(\"utf8\");\n        assertNotNull(\"docID=\" + i + \" index=\" + oldName, tfv);\n      } else {\n        // Only ID 7 is deleted\n        assertEquals(7, i);\n      }\n    }\n\n    if (is40Index) {\n      // check docvalues fields\n      NumericDocValues dvByte = MultiDocValues.getNumericValues(reader, \"dvByte\");\n      BinaryDocValues dvBytesDerefFixed = MultiDocValues.getBinaryValues(reader, \"dvBytesDerefFixed\");\n      BinaryDocValues dvBytesDerefVar = MultiDocValues.getBinaryValues(reader, \"dvBytesDerefVar\");\n      SortedDocValues dvBytesSortedFixed = MultiDocValues.getSortedValues(reader, \"dvBytesSortedFixed\");\n      SortedDocValues dvBytesSortedVar = MultiDocValues.getSortedValues(reader, \"dvBytesSortedVar\");\n      BinaryDocValues dvBytesStraightFixed = MultiDocValues.getBinaryValues(reader, \"dvBytesStraightFixed\");\n      BinaryDocValues dvBytesStraightVar = MultiDocValues.getBinaryValues(reader, \"dvBytesStraightVar\");\n      NumericDocValues dvDouble = MultiDocValues.getNumericValues(reader, \"dvDouble\");\n      NumericDocValues dvFloat = MultiDocValues.getNumericValues(reader, \"dvFloat\");\n      NumericDocValues dvInt = MultiDocValues.getNumericValues(reader, \"dvInt\");\n      NumericDocValues dvLong = MultiDocValues.getNumericValues(reader, \"dvLong\");\n      NumericDocValues dvPacked = MultiDocValues.getNumericValues(reader, \"dvPacked\");\n      NumericDocValues dvShort = MultiDocValues.getNumericValues(reader, \"dvShort\");\n      SortedSetDocValues dvSortedSet = null;\n      if (is42Index) {\n        dvSortedSet = MultiDocValues.getSortedSetValues(reader, \"dvSortedSet\");\n      }\n      \n      for (int i=0;i<35;i++) {\n        int id = Integer.parseInt(reader.document(i).get(\"id\"));\n        assertEquals(id, dvByte.get(i));\n        \n        byte bytes[] = new byte[] {\n            (byte)(id >>> 24), (byte)(id >>> 16),(byte)(id >>> 8),(byte)id\n        };\n        BytesRef expectedRef = new BytesRef(bytes);\n        BytesRef scratch = new BytesRef();\n        \n        dvBytesDerefFixed.get(i, scratch);\n        assertEquals(expectedRef, scratch);\n        dvBytesDerefVar.get(i, scratch);\n        assertEquals(expectedRef, scratch);\n        dvBytesSortedFixed.get(i, scratch);\n        assertEquals(expectedRef, scratch);\n        dvBytesSortedVar.get(i, scratch);\n        assertEquals(expectedRef, scratch);\n        dvBytesStraightFixed.get(i, scratch);\n        assertEquals(expectedRef, scratch);\n        dvBytesStraightVar.get(i, scratch);\n        assertEquals(expectedRef, scratch);\n        \n        assertEquals((double)id, Double.longBitsToDouble(dvDouble.get(i)), 0D);\n        assertEquals((float)id, Float.intBitsToFloat((int)dvFloat.get(i)), 0F);\n        assertEquals(id, dvInt.get(i));\n        assertEquals(id, dvLong.get(i));\n        assertEquals(id, dvPacked.get(i));\n        assertEquals(id, dvShort.get(i));\n        if (is42Index) {\n          dvSortedSet.setDocument(i);\n          long ord = dvSortedSet.nextOrd();\n          assertEquals(SortedSetDocValues.NO_MORE_ORDS, dvSortedSet.nextOrd());\n          dvSortedSet.lookupOrd(ord, scratch);\n          assertEquals(expectedRef, scratch);\n        }\n      }\n    }\n    \n    ScoreDoc[] hits = searcher.search(new TermQuery(new Term(new String(\"content\"), \"aaa\")), null, 1000).scoreDocs;\n\n    // First document should be #0\n    StoredDocument d = searcher.getIndexReader().document(hits[0].doc);\n    assertEquals(\"didn't get the right document first\", \"0\", d.get(\"id\"));\n\n    doTestHits(hits, 34, searcher.getIndexReader());\n    \n    if (is40Index) {\n      hits = searcher.search(new TermQuery(new Term(new String(\"content5\"), \"aaa\")), null, 1000).scoreDocs;\n\n      doTestHits(hits, 34, searcher.getIndexReader());\n    \n      hits = searcher.search(new TermQuery(new Term(new String(\"content6\"), \"aaa\")), null, 1000).scoreDocs;\n\n      doTestHits(hits, 34, searcher.getIndexReader());\n    }\n\n    hits = searcher.search(new TermQuery(new Term(\"utf8\", \"\\u0000\")), null, 1000).scoreDocs;\n    assertEquals(34, hits.length);\n    hits = searcher.search(new TermQuery(new Term(new String(\"utf8\"), \"lu\\uD834\\uDD1Ece\\uD834\\uDD60ne\")), null, 1000).scoreDocs;\n    assertEquals(34, hits.length);\n    hits = searcher.search(new TermQuery(new Term(\"utf8\", \"ab\\ud917\\udc17cd\")), null, 1000).scoreDocs;\n    assertEquals(34, hits.length);\n\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"53fc2f4c5ce4f2053be3d5f5d14d79129ebb4bbf","date":1401983689,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestBackwardsCompatibility#searchIndex(Directory,String).mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestBackwardsCompatibility#searchIndex(Directory,String).mjava","sourceNew":"  public void searchIndex(Directory dir, String oldName) throws IOException {\n    //QueryParser parser = new QueryParser(\"contents\", new MockAnalyzer(random));\n    //Query query = parser.parse(\"handle:1\");\n\n    IndexReader reader = DirectoryReader.open(dir);\n    IndexSearcher searcher = newSearcher(reader);\n\n    TestUtil.checkIndex(dir);\n    \n    // true if this is a 4.0+ index\n    final boolean is40Index = MultiFields.getMergedFieldInfos(reader).fieldInfo(\"content5\") != null;\n    // true if this is a 4.2+ index\n    final boolean is42Index = MultiFields.getMergedFieldInfos(reader).fieldInfo(\"dvSortedSet\") != null;\n\n    assert is40Index; // NOTE: currently we can only do this on trunk!\n\n    final Bits liveDocs = MultiFields.getLiveDocs(reader);\n\n    for(int i=0;i<35;i++) {\n      if (liveDocs.get(i)) {\n        StoredDocument d = reader.document(i);\n        List<StorableField> fields = d.getFields();\n        boolean isProxDoc = d.getField(\"content3\") == null;\n        if (isProxDoc) {\n          final int numFields = is40Index ? 7 : 5;\n          assertEquals(numFields, fields.size());\n          StorableField f =  d.getField(\"id\");\n          assertEquals(\"\"+i, f.stringValue());\n\n          f = d.getField(\"utf8\");\n          assertEquals(\"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne \\u0000 \\u2620 ab\\ud917\\udc17cd\", f.stringValue());\n\n          f =  d.getField(\"autf8\");\n          assertEquals(\"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne \\u0000 \\u2620 ab\\ud917\\udc17cd\", f.stringValue());\n      \n          f = d.getField(\"content2\");\n          assertEquals(\"here is more content with aaa aaa aaa\", f.stringValue());\n\n          f = d.getField(\"fie\\u2C77ld\");\n          assertEquals(\"field with non-ascii name\", f.stringValue());\n        }\n\n        Fields tfvFields = reader.getTermVectors(i);\n        assertNotNull(\"i=\" + i, tfvFields);\n        Terms tfv = tfvFields.terms(\"utf8\");\n        assertNotNull(\"docID=\" + i + \" index=\" + oldName, tfv);\n      } else {\n        // Only ID 7 is deleted\n        assertEquals(7, i);\n      }\n    }\n\n    if (is40Index) {\n      // check docvalues fields\n      NumericDocValues dvByte = MultiDocValues.getNumericValues(reader, \"dvByte\");\n      BinaryDocValues dvBytesDerefFixed = MultiDocValues.getBinaryValues(reader, \"dvBytesDerefFixed\");\n      BinaryDocValues dvBytesDerefVar = MultiDocValues.getBinaryValues(reader, \"dvBytesDerefVar\");\n      SortedDocValues dvBytesSortedFixed = MultiDocValues.getSortedValues(reader, \"dvBytesSortedFixed\");\n      SortedDocValues dvBytesSortedVar = MultiDocValues.getSortedValues(reader, \"dvBytesSortedVar\");\n      BinaryDocValues dvBytesStraightFixed = MultiDocValues.getBinaryValues(reader, \"dvBytesStraightFixed\");\n      BinaryDocValues dvBytesStraightVar = MultiDocValues.getBinaryValues(reader, \"dvBytesStraightVar\");\n      NumericDocValues dvDouble = MultiDocValues.getNumericValues(reader, \"dvDouble\");\n      NumericDocValues dvFloat = MultiDocValues.getNumericValues(reader, \"dvFloat\");\n      NumericDocValues dvInt = MultiDocValues.getNumericValues(reader, \"dvInt\");\n      NumericDocValues dvLong = MultiDocValues.getNumericValues(reader, \"dvLong\");\n      NumericDocValues dvPacked = MultiDocValues.getNumericValues(reader, \"dvPacked\");\n      NumericDocValues dvShort = MultiDocValues.getNumericValues(reader, \"dvShort\");\n      SortedSetDocValues dvSortedSet = null;\n      if (is42Index) {\n        dvSortedSet = MultiDocValues.getSortedSetValues(reader, \"dvSortedSet\");\n      }\n      \n      for (int i=0;i<35;i++) {\n        int id = Integer.parseInt(reader.document(i).get(\"id\"));\n        assertEquals(id, dvByte.get(i));\n        \n        byte bytes[] = new byte[] {\n            (byte)(id >>> 24), (byte)(id >>> 16),(byte)(id >>> 8),(byte)id\n        };\n        BytesRef expectedRef = new BytesRef(bytes);\n        \n        BytesRef term = dvBytesDerefFixed.get(i);\n        assertEquals(expectedRef, term);\n        term = dvBytesDerefVar.get(i);\n        assertEquals(expectedRef, term);\n        term = dvBytesSortedFixed.get(i);\n        assertEquals(expectedRef, term);\n        term = dvBytesSortedVar.get(i);\n        assertEquals(expectedRef, term);\n        term = dvBytesStraightFixed.get(i);\n        assertEquals(expectedRef, term);\n        term = dvBytesStraightVar.get(i);\n        assertEquals(expectedRef, term);\n        \n        assertEquals((double)id, Double.longBitsToDouble(dvDouble.get(i)), 0D);\n        assertEquals((float)id, Float.intBitsToFloat((int)dvFloat.get(i)), 0F);\n        assertEquals(id, dvInt.get(i));\n        assertEquals(id, dvLong.get(i));\n        assertEquals(id, dvPacked.get(i));\n        assertEquals(id, dvShort.get(i));\n        if (is42Index) {\n          dvSortedSet.setDocument(i);\n          long ord = dvSortedSet.nextOrd();\n          assertEquals(SortedSetDocValues.NO_MORE_ORDS, dvSortedSet.nextOrd());\n          term = dvSortedSet.lookupOrd(ord);\n          assertEquals(expectedRef, term);\n        }\n      }\n    }\n    \n    ScoreDoc[] hits = searcher.search(new TermQuery(new Term(new String(\"content\"), \"aaa\")), null, 1000).scoreDocs;\n\n    // First document should be #0\n    StoredDocument d = searcher.getIndexReader().document(hits[0].doc);\n    assertEquals(\"didn't get the right document first\", \"0\", d.get(\"id\"));\n\n    doTestHits(hits, 34, searcher.getIndexReader());\n    \n    if (is40Index) {\n      hits = searcher.search(new TermQuery(new Term(new String(\"content5\"), \"aaa\")), null, 1000).scoreDocs;\n\n      doTestHits(hits, 34, searcher.getIndexReader());\n    \n      hits = searcher.search(new TermQuery(new Term(new String(\"content6\"), \"aaa\")), null, 1000).scoreDocs;\n\n      doTestHits(hits, 34, searcher.getIndexReader());\n    }\n\n    hits = searcher.search(new TermQuery(new Term(\"utf8\", \"\\u0000\")), null, 1000).scoreDocs;\n    assertEquals(34, hits.length);\n    hits = searcher.search(new TermQuery(new Term(new String(\"utf8\"), \"lu\\uD834\\uDD1Ece\\uD834\\uDD60ne\")), null, 1000).scoreDocs;\n    assertEquals(34, hits.length);\n    hits = searcher.search(new TermQuery(new Term(\"utf8\", \"ab\\ud917\\udc17cd\")), null, 1000).scoreDocs;\n    assertEquals(34, hits.length);\n\n    reader.close();\n  }\n\n","sourceOld":"  public void searchIndex(Directory dir, String oldName) throws IOException {\n    //QueryParser parser = new QueryParser(\"contents\", new MockAnalyzer(random));\n    //Query query = parser.parse(\"handle:1\");\n\n    IndexReader reader = DirectoryReader.open(dir);\n    IndexSearcher searcher = newSearcher(reader);\n\n    TestUtil.checkIndex(dir);\n    \n    // true if this is a 4.0+ index\n    final boolean is40Index = MultiFields.getMergedFieldInfos(reader).fieldInfo(\"content5\") != null;\n    // true if this is a 4.2+ index\n    final boolean is42Index = MultiFields.getMergedFieldInfos(reader).fieldInfo(\"dvSortedSet\") != null;\n\n    assert is40Index; // NOTE: currently we can only do this on trunk!\n\n    final Bits liveDocs = MultiFields.getLiveDocs(reader);\n\n    for(int i=0;i<35;i++) {\n      if (liveDocs.get(i)) {\n        StoredDocument d = reader.document(i);\n        List<StorableField> fields = d.getFields();\n        boolean isProxDoc = d.getField(\"content3\") == null;\n        if (isProxDoc) {\n          final int numFields = is40Index ? 7 : 5;\n          assertEquals(numFields, fields.size());\n          StorableField f =  d.getField(\"id\");\n          assertEquals(\"\"+i, f.stringValue());\n\n          f = d.getField(\"utf8\");\n          assertEquals(\"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne \\u0000 \\u2620 ab\\ud917\\udc17cd\", f.stringValue());\n\n          f =  d.getField(\"autf8\");\n          assertEquals(\"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne \\u0000 \\u2620 ab\\ud917\\udc17cd\", f.stringValue());\n      \n          f = d.getField(\"content2\");\n          assertEquals(\"here is more content with aaa aaa aaa\", f.stringValue());\n\n          f = d.getField(\"fie\\u2C77ld\");\n          assertEquals(\"field with non-ascii name\", f.stringValue());\n        }\n\n        Fields tfvFields = reader.getTermVectors(i);\n        assertNotNull(\"i=\" + i, tfvFields);\n        Terms tfv = tfvFields.terms(\"utf8\");\n        assertNotNull(\"docID=\" + i + \" index=\" + oldName, tfv);\n      } else {\n        // Only ID 7 is deleted\n        assertEquals(7, i);\n      }\n    }\n\n    if (is40Index) {\n      // check docvalues fields\n      NumericDocValues dvByte = MultiDocValues.getNumericValues(reader, \"dvByte\");\n      BinaryDocValues dvBytesDerefFixed = MultiDocValues.getBinaryValues(reader, \"dvBytesDerefFixed\");\n      BinaryDocValues dvBytesDerefVar = MultiDocValues.getBinaryValues(reader, \"dvBytesDerefVar\");\n      SortedDocValues dvBytesSortedFixed = MultiDocValues.getSortedValues(reader, \"dvBytesSortedFixed\");\n      SortedDocValues dvBytesSortedVar = MultiDocValues.getSortedValues(reader, \"dvBytesSortedVar\");\n      BinaryDocValues dvBytesStraightFixed = MultiDocValues.getBinaryValues(reader, \"dvBytesStraightFixed\");\n      BinaryDocValues dvBytesStraightVar = MultiDocValues.getBinaryValues(reader, \"dvBytesStraightVar\");\n      NumericDocValues dvDouble = MultiDocValues.getNumericValues(reader, \"dvDouble\");\n      NumericDocValues dvFloat = MultiDocValues.getNumericValues(reader, \"dvFloat\");\n      NumericDocValues dvInt = MultiDocValues.getNumericValues(reader, \"dvInt\");\n      NumericDocValues dvLong = MultiDocValues.getNumericValues(reader, \"dvLong\");\n      NumericDocValues dvPacked = MultiDocValues.getNumericValues(reader, \"dvPacked\");\n      NumericDocValues dvShort = MultiDocValues.getNumericValues(reader, \"dvShort\");\n      SortedSetDocValues dvSortedSet = null;\n      if (is42Index) {\n        dvSortedSet = MultiDocValues.getSortedSetValues(reader, \"dvSortedSet\");\n      }\n      \n      for (int i=0;i<35;i++) {\n        int id = Integer.parseInt(reader.document(i).get(\"id\"));\n        assertEquals(id, dvByte.get(i));\n        \n        byte bytes[] = new byte[] {\n            (byte)(id >>> 24), (byte)(id >>> 16),(byte)(id >>> 8),(byte)id\n        };\n        BytesRef expectedRef = new BytesRef(bytes);\n        BytesRef scratch = new BytesRef();\n        \n        dvBytesDerefFixed.get(i, scratch);\n        assertEquals(expectedRef, scratch);\n        dvBytesDerefVar.get(i, scratch);\n        assertEquals(expectedRef, scratch);\n        dvBytesSortedFixed.get(i, scratch);\n        assertEquals(expectedRef, scratch);\n        dvBytesSortedVar.get(i, scratch);\n        assertEquals(expectedRef, scratch);\n        dvBytesStraightFixed.get(i, scratch);\n        assertEquals(expectedRef, scratch);\n        dvBytesStraightVar.get(i, scratch);\n        assertEquals(expectedRef, scratch);\n        \n        assertEquals((double)id, Double.longBitsToDouble(dvDouble.get(i)), 0D);\n        assertEquals((float)id, Float.intBitsToFloat((int)dvFloat.get(i)), 0F);\n        assertEquals(id, dvInt.get(i));\n        assertEquals(id, dvLong.get(i));\n        assertEquals(id, dvPacked.get(i));\n        assertEquals(id, dvShort.get(i));\n        if (is42Index) {\n          dvSortedSet.setDocument(i);\n          long ord = dvSortedSet.nextOrd();\n          assertEquals(SortedSetDocValues.NO_MORE_ORDS, dvSortedSet.nextOrd());\n          dvSortedSet.lookupOrd(ord, scratch);\n          assertEquals(expectedRef, scratch);\n        }\n      }\n    }\n    \n    ScoreDoc[] hits = searcher.search(new TermQuery(new Term(new String(\"content\"), \"aaa\")), null, 1000).scoreDocs;\n\n    // First document should be #0\n    StoredDocument d = searcher.getIndexReader().document(hits[0].doc);\n    assertEquals(\"didn't get the right document first\", \"0\", d.get(\"id\"));\n\n    doTestHits(hits, 34, searcher.getIndexReader());\n    \n    if (is40Index) {\n      hits = searcher.search(new TermQuery(new Term(new String(\"content5\"), \"aaa\")), null, 1000).scoreDocs;\n\n      doTestHits(hits, 34, searcher.getIndexReader());\n    \n      hits = searcher.search(new TermQuery(new Term(new String(\"content6\"), \"aaa\")), null, 1000).scoreDocs;\n\n      doTestHits(hits, 34, searcher.getIndexReader());\n    }\n\n    hits = searcher.search(new TermQuery(new Term(\"utf8\", \"\\u0000\")), null, 1000).scoreDocs;\n    assertEquals(34, hits.length);\n    hits = searcher.search(new TermQuery(new Term(new String(\"utf8\"), \"lu\\uD834\\uDD1Ece\\uD834\\uDD60ne\")), null, 1000).scoreDocs;\n    assertEquals(34, hits.length);\n    hits = searcher.search(new TermQuery(new Term(\"utf8\", \"ab\\ud917\\udc17cd\")), null, 1000).scoreDocs;\n    assertEquals(34, hits.length);\n\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"cf67308cf3e605faada2e2e5092aff47ae822912","date":1404140785,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestBackwardsCompatibility#searchIndex(Directory,String).mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestBackwardsCompatibility#searchIndex(Directory,String).mjava","sourceNew":"  public void searchIndex(Directory dir, String oldName) throws IOException {\n    //QueryParser parser = new QueryParser(\"contents\", new MockAnalyzer(random));\n    //Query query = parser.parse(\"handle:1\");\n\n    IndexReader reader = DirectoryReader.open(dir);\n    IndexSearcher searcher = newSearcher(reader);\n\n    TestUtil.checkIndex(dir);\n    \n    // true if this is a 4.0+ index\n    final boolean is40Index = MultiFields.getMergedFieldInfos(reader).fieldInfo(\"content5\") != null;\n    // true if this is a 4.2+ index\n    final boolean is42Index = MultiFields.getMergedFieldInfos(reader).fieldInfo(\"dvSortedSet\") != null;\n    // true if this is a 4.9+ index\n    final boolean is49Index = MultiFields.getMergedFieldInfos(reader).fieldInfo(\"dvSortedNumeric\") != null;\n\n    assert is40Index; // NOTE: currently we can only do this on trunk!\n\n    final Bits liveDocs = MultiFields.getLiveDocs(reader);\n\n    for(int i=0;i<35;i++) {\n      if (liveDocs.get(i)) {\n        StoredDocument d = reader.document(i);\n        List<StorableField> fields = d.getFields();\n        boolean isProxDoc = d.getField(\"content3\") == null;\n        if (isProxDoc) {\n          final int numFields = is40Index ? 7 : 5;\n          assertEquals(numFields, fields.size());\n          StorableField f =  d.getField(\"id\");\n          assertEquals(\"\"+i, f.stringValue());\n\n          f = d.getField(\"utf8\");\n          assertEquals(\"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne \\u0000 \\u2620 ab\\ud917\\udc17cd\", f.stringValue());\n\n          f =  d.getField(\"autf8\");\n          assertEquals(\"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne \\u0000 \\u2620 ab\\ud917\\udc17cd\", f.stringValue());\n      \n          f = d.getField(\"content2\");\n          assertEquals(\"here is more content with aaa aaa aaa\", f.stringValue());\n\n          f = d.getField(\"fie\\u2C77ld\");\n          assertEquals(\"field with non-ascii name\", f.stringValue());\n        }\n\n        Fields tfvFields = reader.getTermVectors(i);\n        assertNotNull(\"i=\" + i, tfvFields);\n        Terms tfv = tfvFields.terms(\"utf8\");\n        assertNotNull(\"docID=\" + i + \" index=\" + oldName, tfv);\n      } else {\n        // Only ID 7 is deleted\n        assertEquals(7, i);\n      }\n    }\n\n    if (is40Index) {\n      // check docvalues fields\n      NumericDocValues dvByte = MultiDocValues.getNumericValues(reader, \"dvByte\");\n      BinaryDocValues dvBytesDerefFixed = MultiDocValues.getBinaryValues(reader, \"dvBytesDerefFixed\");\n      BinaryDocValues dvBytesDerefVar = MultiDocValues.getBinaryValues(reader, \"dvBytesDerefVar\");\n      SortedDocValues dvBytesSortedFixed = MultiDocValues.getSortedValues(reader, \"dvBytesSortedFixed\");\n      SortedDocValues dvBytesSortedVar = MultiDocValues.getSortedValues(reader, \"dvBytesSortedVar\");\n      BinaryDocValues dvBytesStraightFixed = MultiDocValues.getBinaryValues(reader, \"dvBytesStraightFixed\");\n      BinaryDocValues dvBytesStraightVar = MultiDocValues.getBinaryValues(reader, \"dvBytesStraightVar\");\n      NumericDocValues dvDouble = MultiDocValues.getNumericValues(reader, \"dvDouble\");\n      NumericDocValues dvFloat = MultiDocValues.getNumericValues(reader, \"dvFloat\");\n      NumericDocValues dvInt = MultiDocValues.getNumericValues(reader, \"dvInt\");\n      NumericDocValues dvLong = MultiDocValues.getNumericValues(reader, \"dvLong\");\n      NumericDocValues dvPacked = MultiDocValues.getNumericValues(reader, \"dvPacked\");\n      NumericDocValues dvShort = MultiDocValues.getNumericValues(reader, \"dvShort\");\n      SortedSetDocValues dvSortedSet = null;\n      if (is42Index) {\n        dvSortedSet = MultiDocValues.getSortedSetValues(reader, \"dvSortedSet\");\n      }\n      SortedNumericDocValues dvSortedNumeric = null;\n      if (is49Index) {\n        dvSortedNumeric = MultiDocValues.getSortedNumericValues(reader, \"dvSortedNumeric\");\n      }\n      \n      for (int i=0;i<35;i++) {\n        int id = Integer.parseInt(reader.document(i).get(\"id\"));\n        assertEquals(id, dvByte.get(i));\n        \n        byte bytes[] = new byte[] {\n            (byte)(id >>> 24), (byte)(id >>> 16),(byte)(id >>> 8),(byte)id\n        };\n        BytesRef expectedRef = new BytesRef(bytes);\n        \n        BytesRef term = dvBytesDerefFixed.get(i);\n        assertEquals(expectedRef, term);\n        term = dvBytesDerefVar.get(i);\n        assertEquals(expectedRef, term);\n        term = dvBytesSortedFixed.get(i);\n        assertEquals(expectedRef, term);\n        term = dvBytesSortedVar.get(i);\n        assertEquals(expectedRef, term);\n        term = dvBytesStraightFixed.get(i);\n        assertEquals(expectedRef, term);\n        term = dvBytesStraightVar.get(i);\n        assertEquals(expectedRef, term);\n        \n        assertEquals((double)id, Double.longBitsToDouble(dvDouble.get(i)), 0D);\n        assertEquals((float)id, Float.intBitsToFloat((int)dvFloat.get(i)), 0F);\n        assertEquals(id, dvInt.get(i));\n        assertEquals(id, dvLong.get(i));\n        assertEquals(id, dvPacked.get(i));\n        assertEquals(id, dvShort.get(i));\n        if (is42Index) {\n          dvSortedSet.setDocument(i);\n          long ord = dvSortedSet.nextOrd();\n          assertEquals(SortedSetDocValues.NO_MORE_ORDS, dvSortedSet.nextOrd());\n          term = dvSortedSet.lookupOrd(ord);\n          assertEquals(expectedRef, term);\n        }\n        if (is49Index) {\n          dvSortedNumeric.setDocument(i);\n          assertEquals(1, dvSortedNumeric.count());\n          assertEquals(id, dvSortedNumeric.valueAt(0));\n        }\n      }\n    }\n    \n    ScoreDoc[] hits = searcher.search(new TermQuery(new Term(new String(\"content\"), \"aaa\")), null, 1000).scoreDocs;\n\n    // First document should be #0\n    StoredDocument d = searcher.getIndexReader().document(hits[0].doc);\n    assertEquals(\"didn't get the right document first\", \"0\", d.get(\"id\"));\n\n    doTestHits(hits, 34, searcher.getIndexReader());\n    \n    if (is40Index) {\n      hits = searcher.search(new TermQuery(new Term(new String(\"content5\"), \"aaa\")), null, 1000).scoreDocs;\n\n      doTestHits(hits, 34, searcher.getIndexReader());\n    \n      hits = searcher.search(new TermQuery(new Term(new String(\"content6\"), \"aaa\")), null, 1000).scoreDocs;\n\n      doTestHits(hits, 34, searcher.getIndexReader());\n    }\n\n    hits = searcher.search(new TermQuery(new Term(\"utf8\", \"\\u0000\")), null, 1000).scoreDocs;\n    assertEquals(34, hits.length);\n    hits = searcher.search(new TermQuery(new Term(new String(\"utf8\"), \"lu\\uD834\\uDD1Ece\\uD834\\uDD60ne\")), null, 1000).scoreDocs;\n    assertEquals(34, hits.length);\n    hits = searcher.search(new TermQuery(new Term(\"utf8\", \"ab\\ud917\\udc17cd\")), null, 1000).scoreDocs;\n    assertEquals(34, hits.length);\n\n    reader.close();\n  }\n\n","sourceOld":"  public void searchIndex(Directory dir, String oldName) throws IOException {\n    //QueryParser parser = new QueryParser(\"contents\", new MockAnalyzer(random));\n    //Query query = parser.parse(\"handle:1\");\n\n    IndexReader reader = DirectoryReader.open(dir);\n    IndexSearcher searcher = newSearcher(reader);\n\n    TestUtil.checkIndex(dir);\n    \n    // true if this is a 4.0+ index\n    final boolean is40Index = MultiFields.getMergedFieldInfos(reader).fieldInfo(\"content5\") != null;\n    // true if this is a 4.2+ index\n    final boolean is42Index = MultiFields.getMergedFieldInfos(reader).fieldInfo(\"dvSortedSet\") != null;\n\n    assert is40Index; // NOTE: currently we can only do this on trunk!\n\n    final Bits liveDocs = MultiFields.getLiveDocs(reader);\n\n    for(int i=0;i<35;i++) {\n      if (liveDocs.get(i)) {\n        StoredDocument d = reader.document(i);\n        List<StorableField> fields = d.getFields();\n        boolean isProxDoc = d.getField(\"content3\") == null;\n        if (isProxDoc) {\n          final int numFields = is40Index ? 7 : 5;\n          assertEquals(numFields, fields.size());\n          StorableField f =  d.getField(\"id\");\n          assertEquals(\"\"+i, f.stringValue());\n\n          f = d.getField(\"utf8\");\n          assertEquals(\"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne \\u0000 \\u2620 ab\\ud917\\udc17cd\", f.stringValue());\n\n          f =  d.getField(\"autf8\");\n          assertEquals(\"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne \\u0000 \\u2620 ab\\ud917\\udc17cd\", f.stringValue());\n      \n          f = d.getField(\"content2\");\n          assertEquals(\"here is more content with aaa aaa aaa\", f.stringValue());\n\n          f = d.getField(\"fie\\u2C77ld\");\n          assertEquals(\"field with non-ascii name\", f.stringValue());\n        }\n\n        Fields tfvFields = reader.getTermVectors(i);\n        assertNotNull(\"i=\" + i, tfvFields);\n        Terms tfv = tfvFields.terms(\"utf8\");\n        assertNotNull(\"docID=\" + i + \" index=\" + oldName, tfv);\n      } else {\n        // Only ID 7 is deleted\n        assertEquals(7, i);\n      }\n    }\n\n    if (is40Index) {\n      // check docvalues fields\n      NumericDocValues dvByte = MultiDocValues.getNumericValues(reader, \"dvByte\");\n      BinaryDocValues dvBytesDerefFixed = MultiDocValues.getBinaryValues(reader, \"dvBytesDerefFixed\");\n      BinaryDocValues dvBytesDerefVar = MultiDocValues.getBinaryValues(reader, \"dvBytesDerefVar\");\n      SortedDocValues dvBytesSortedFixed = MultiDocValues.getSortedValues(reader, \"dvBytesSortedFixed\");\n      SortedDocValues dvBytesSortedVar = MultiDocValues.getSortedValues(reader, \"dvBytesSortedVar\");\n      BinaryDocValues dvBytesStraightFixed = MultiDocValues.getBinaryValues(reader, \"dvBytesStraightFixed\");\n      BinaryDocValues dvBytesStraightVar = MultiDocValues.getBinaryValues(reader, \"dvBytesStraightVar\");\n      NumericDocValues dvDouble = MultiDocValues.getNumericValues(reader, \"dvDouble\");\n      NumericDocValues dvFloat = MultiDocValues.getNumericValues(reader, \"dvFloat\");\n      NumericDocValues dvInt = MultiDocValues.getNumericValues(reader, \"dvInt\");\n      NumericDocValues dvLong = MultiDocValues.getNumericValues(reader, \"dvLong\");\n      NumericDocValues dvPacked = MultiDocValues.getNumericValues(reader, \"dvPacked\");\n      NumericDocValues dvShort = MultiDocValues.getNumericValues(reader, \"dvShort\");\n      SortedSetDocValues dvSortedSet = null;\n      if (is42Index) {\n        dvSortedSet = MultiDocValues.getSortedSetValues(reader, \"dvSortedSet\");\n      }\n      \n      for (int i=0;i<35;i++) {\n        int id = Integer.parseInt(reader.document(i).get(\"id\"));\n        assertEquals(id, dvByte.get(i));\n        \n        byte bytes[] = new byte[] {\n            (byte)(id >>> 24), (byte)(id >>> 16),(byte)(id >>> 8),(byte)id\n        };\n        BytesRef expectedRef = new BytesRef(bytes);\n        \n        BytesRef term = dvBytesDerefFixed.get(i);\n        assertEquals(expectedRef, term);\n        term = dvBytesDerefVar.get(i);\n        assertEquals(expectedRef, term);\n        term = dvBytesSortedFixed.get(i);\n        assertEquals(expectedRef, term);\n        term = dvBytesSortedVar.get(i);\n        assertEquals(expectedRef, term);\n        term = dvBytesStraightFixed.get(i);\n        assertEquals(expectedRef, term);\n        term = dvBytesStraightVar.get(i);\n        assertEquals(expectedRef, term);\n        \n        assertEquals((double)id, Double.longBitsToDouble(dvDouble.get(i)), 0D);\n        assertEquals((float)id, Float.intBitsToFloat((int)dvFloat.get(i)), 0F);\n        assertEquals(id, dvInt.get(i));\n        assertEquals(id, dvLong.get(i));\n        assertEquals(id, dvPacked.get(i));\n        assertEquals(id, dvShort.get(i));\n        if (is42Index) {\n          dvSortedSet.setDocument(i);\n          long ord = dvSortedSet.nextOrd();\n          assertEquals(SortedSetDocValues.NO_MORE_ORDS, dvSortedSet.nextOrd());\n          term = dvSortedSet.lookupOrd(ord);\n          assertEquals(expectedRef, term);\n        }\n      }\n    }\n    \n    ScoreDoc[] hits = searcher.search(new TermQuery(new Term(new String(\"content\"), \"aaa\")), null, 1000).scoreDocs;\n\n    // First document should be #0\n    StoredDocument d = searcher.getIndexReader().document(hits[0].doc);\n    assertEquals(\"didn't get the right document first\", \"0\", d.get(\"id\"));\n\n    doTestHits(hits, 34, searcher.getIndexReader());\n    \n    if (is40Index) {\n      hits = searcher.search(new TermQuery(new Term(new String(\"content5\"), \"aaa\")), null, 1000).scoreDocs;\n\n      doTestHits(hits, 34, searcher.getIndexReader());\n    \n      hits = searcher.search(new TermQuery(new Term(new String(\"content6\"), \"aaa\")), null, 1000).scoreDocs;\n\n      doTestHits(hits, 34, searcher.getIndexReader());\n    }\n\n    hits = searcher.search(new TermQuery(new Term(\"utf8\", \"\\u0000\")), null, 1000).scoreDocs;\n    assertEquals(34, hits.length);\n    hits = searcher.search(new TermQuery(new Term(new String(\"utf8\"), \"lu\\uD834\\uDD1Ece\\uD834\\uDD60ne\")), null, 1000).scoreDocs;\n    assertEquals(34, hits.length);\n    hits = searcher.search(new TermQuery(new Term(\"utf8\", \"ab\\ud917\\udc17cd\")), null, 1000).scoreDocs;\n    assertEquals(34, hits.length);\n\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4cc45c615dbb82bf79d5f9550286098367874fbf","date":1409571423,"type":5,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/backward-codecs/src/test/org/apache/lucene/index/TestBackwardsCompatibility#searchIndex(Directory,String).mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestBackwardsCompatibility#searchIndex(Directory,String).mjava","sourceNew":"  public void searchIndex(Directory dir, String oldName) throws IOException {\n    //QueryParser parser = new QueryParser(\"contents\", new MockAnalyzer(random));\n    //Query query = parser.parse(\"handle:1\");\n\n    IndexReader reader = DirectoryReader.open(dir);\n    IndexSearcher searcher = newSearcher(reader);\n\n    TestUtil.checkIndex(dir);\n    \n    // true if this is a 4.0+ index\n    final boolean is40Index = MultiFields.getMergedFieldInfos(reader).fieldInfo(\"content5\") != null;\n    // true if this is a 4.2+ index\n    final boolean is42Index = MultiFields.getMergedFieldInfos(reader).fieldInfo(\"dvSortedSet\") != null;\n    // true if this is a 4.9+ index\n    final boolean is49Index = MultiFields.getMergedFieldInfos(reader).fieldInfo(\"dvSortedNumeric\") != null;\n\n    assert is40Index; // NOTE: currently we can only do this on trunk!\n\n    final Bits liveDocs = MultiFields.getLiveDocs(reader);\n\n    for(int i=0;i<35;i++) {\n      if (liveDocs.get(i)) {\n        StoredDocument d = reader.document(i);\n        List<StorableField> fields = d.getFields();\n        boolean isProxDoc = d.getField(\"content3\") == null;\n        if (isProxDoc) {\n          final int numFields = is40Index ? 7 : 5;\n          assertEquals(numFields, fields.size());\n          StorableField f =  d.getField(\"id\");\n          assertEquals(\"\"+i, f.stringValue());\n\n          f = d.getField(\"utf8\");\n          assertEquals(\"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne \\u0000 \\u2620 ab\\ud917\\udc17cd\", f.stringValue());\n\n          f =  d.getField(\"autf8\");\n          assertEquals(\"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne \\u0000 \\u2620 ab\\ud917\\udc17cd\", f.stringValue());\n      \n          f = d.getField(\"content2\");\n          assertEquals(\"here is more content with aaa aaa aaa\", f.stringValue());\n\n          f = d.getField(\"fie\\u2C77ld\");\n          assertEquals(\"field with non-ascii name\", f.stringValue());\n        }\n\n        Fields tfvFields = reader.getTermVectors(i);\n        assertNotNull(\"i=\" + i, tfvFields);\n        Terms tfv = tfvFields.terms(\"utf8\");\n        assertNotNull(\"docID=\" + i + \" index=\" + oldName, tfv);\n      } else {\n        // Only ID 7 is deleted\n        assertEquals(7, i);\n      }\n    }\n\n    if (is40Index) {\n      // check docvalues fields\n      NumericDocValues dvByte = MultiDocValues.getNumericValues(reader, \"dvByte\");\n      BinaryDocValues dvBytesDerefFixed = MultiDocValues.getBinaryValues(reader, \"dvBytesDerefFixed\");\n      BinaryDocValues dvBytesDerefVar = MultiDocValues.getBinaryValues(reader, \"dvBytesDerefVar\");\n      SortedDocValues dvBytesSortedFixed = MultiDocValues.getSortedValues(reader, \"dvBytesSortedFixed\");\n      SortedDocValues dvBytesSortedVar = MultiDocValues.getSortedValues(reader, \"dvBytesSortedVar\");\n      BinaryDocValues dvBytesStraightFixed = MultiDocValues.getBinaryValues(reader, \"dvBytesStraightFixed\");\n      BinaryDocValues dvBytesStraightVar = MultiDocValues.getBinaryValues(reader, \"dvBytesStraightVar\");\n      NumericDocValues dvDouble = MultiDocValues.getNumericValues(reader, \"dvDouble\");\n      NumericDocValues dvFloat = MultiDocValues.getNumericValues(reader, \"dvFloat\");\n      NumericDocValues dvInt = MultiDocValues.getNumericValues(reader, \"dvInt\");\n      NumericDocValues dvLong = MultiDocValues.getNumericValues(reader, \"dvLong\");\n      NumericDocValues dvPacked = MultiDocValues.getNumericValues(reader, \"dvPacked\");\n      NumericDocValues dvShort = MultiDocValues.getNumericValues(reader, \"dvShort\");\n      SortedSetDocValues dvSortedSet = null;\n      if (is42Index) {\n        dvSortedSet = MultiDocValues.getSortedSetValues(reader, \"dvSortedSet\");\n      }\n      SortedNumericDocValues dvSortedNumeric = null;\n      if (is49Index) {\n        dvSortedNumeric = MultiDocValues.getSortedNumericValues(reader, \"dvSortedNumeric\");\n      }\n      \n      for (int i=0;i<35;i++) {\n        int id = Integer.parseInt(reader.document(i).get(\"id\"));\n        assertEquals(id, dvByte.get(i));\n        \n        byte bytes[] = new byte[] {\n            (byte)(id >>> 24), (byte)(id >>> 16),(byte)(id >>> 8),(byte)id\n        };\n        BytesRef expectedRef = new BytesRef(bytes);\n        \n        BytesRef term = dvBytesDerefFixed.get(i);\n        assertEquals(expectedRef, term);\n        term = dvBytesDerefVar.get(i);\n        assertEquals(expectedRef, term);\n        term = dvBytesSortedFixed.get(i);\n        assertEquals(expectedRef, term);\n        term = dvBytesSortedVar.get(i);\n        assertEquals(expectedRef, term);\n        term = dvBytesStraightFixed.get(i);\n        assertEquals(expectedRef, term);\n        term = dvBytesStraightVar.get(i);\n        assertEquals(expectedRef, term);\n        \n        assertEquals((double)id, Double.longBitsToDouble(dvDouble.get(i)), 0D);\n        assertEquals((float)id, Float.intBitsToFloat((int)dvFloat.get(i)), 0F);\n        assertEquals(id, dvInt.get(i));\n        assertEquals(id, dvLong.get(i));\n        assertEquals(id, dvPacked.get(i));\n        assertEquals(id, dvShort.get(i));\n        if (is42Index) {\n          dvSortedSet.setDocument(i);\n          long ord = dvSortedSet.nextOrd();\n          assertEquals(SortedSetDocValues.NO_MORE_ORDS, dvSortedSet.nextOrd());\n          term = dvSortedSet.lookupOrd(ord);\n          assertEquals(expectedRef, term);\n        }\n        if (is49Index) {\n          dvSortedNumeric.setDocument(i);\n          assertEquals(1, dvSortedNumeric.count());\n          assertEquals(id, dvSortedNumeric.valueAt(0));\n        }\n      }\n    }\n    \n    ScoreDoc[] hits = searcher.search(new TermQuery(new Term(new String(\"content\"), \"aaa\")), null, 1000).scoreDocs;\n\n    // First document should be #0\n    StoredDocument d = searcher.getIndexReader().document(hits[0].doc);\n    assertEquals(\"didn't get the right document first\", \"0\", d.get(\"id\"));\n\n    doTestHits(hits, 34, searcher.getIndexReader());\n    \n    if (is40Index) {\n      hits = searcher.search(new TermQuery(new Term(new String(\"content5\"), \"aaa\")), null, 1000).scoreDocs;\n\n      doTestHits(hits, 34, searcher.getIndexReader());\n    \n      hits = searcher.search(new TermQuery(new Term(new String(\"content6\"), \"aaa\")), null, 1000).scoreDocs;\n\n      doTestHits(hits, 34, searcher.getIndexReader());\n    }\n\n    hits = searcher.search(new TermQuery(new Term(\"utf8\", \"\\u0000\")), null, 1000).scoreDocs;\n    assertEquals(34, hits.length);\n    hits = searcher.search(new TermQuery(new Term(new String(\"utf8\"), \"lu\\uD834\\uDD1Ece\\uD834\\uDD60ne\")), null, 1000).scoreDocs;\n    assertEquals(34, hits.length);\n    hits = searcher.search(new TermQuery(new Term(\"utf8\", \"ab\\ud917\\udc17cd\")), null, 1000).scoreDocs;\n    assertEquals(34, hits.length);\n\n    reader.close();\n  }\n\n","sourceOld":"  public void searchIndex(Directory dir, String oldName) throws IOException {\n    //QueryParser parser = new QueryParser(\"contents\", new MockAnalyzer(random));\n    //Query query = parser.parse(\"handle:1\");\n\n    IndexReader reader = DirectoryReader.open(dir);\n    IndexSearcher searcher = newSearcher(reader);\n\n    TestUtil.checkIndex(dir);\n    \n    // true if this is a 4.0+ index\n    final boolean is40Index = MultiFields.getMergedFieldInfos(reader).fieldInfo(\"content5\") != null;\n    // true if this is a 4.2+ index\n    final boolean is42Index = MultiFields.getMergedFieldInfos(reader).fieldInfo(\"dvSortedSet\") != null;\n    // true if this is a 4.9+ index\n    final boolean is49Index = MultiFields.getMergedFieldInfos(reader).fieldInfo(\"dvSortedNumeric\") != null;\n\n    assert is40Index; // NOTE: currently we can only do this on trunk!\n\n    final Bits liveDocs = MultiFields.getLiveDocs(reader);\n\n    for(int i=0;i<35;i++) {\n      if (liveDocs.get(i)) {\n        StoredDocument d = reader.document(i);\n        List<StorableField> fields = d.getFields();\n        boolean isProxDoc = d.getField(\"content3\") == null;\n        if (isProxDoc) {\n          final int numFields = is40Index ? 7 : 5;\n          assertEquals(numFields, fields.size());\n          StorableField f =  d.getField(\"id\");\n          assertEquals(\"\"+i, f.stringValue());\n\n          f = d.getField(\"utf8\");\n          assertEquals(\"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne \\u0000 \\u2620 ab\\ud917\\udc17cd\", f.stringValue());\n\n          f =  d.getField(\"autf8\");\n          assertEquals(\"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne \\u0000 \\u2620 ab\\ud917\\udc17cd\", f.stringValue());\n      \n          f = d.getField(\"content2\");\n          assertEquals(\"here is more content with aaa aaa aaa\", f.stringValue());\n\n          f = d.getField(\"fie\\u2C77ld\");\n          assertEquals(\"field with non-ascii name\", f.stringValue());\n        }\n\n        Fields tfvFields = reader.getTermVectors(i);\n        assertNotNull(\"i=\" + i, tfvFields);\n        Terms tfv = tfvFields.terms(\"utf8\");\n        assertNotNull(\"docID=\" + i + \" index=\" + oldName, tfv);\n      } else {\n        // Only ID 7 is deleted\n        assertEquals(7, i);\n      }\n    }\n\n    if (is40Index) {\n      // check docvalues fields\n      NumericDocValues dvByte = MultiDocValues.getNumericValues(reader, \"dvByte\");\n      BinaryDocValues dvBytesDerefFixed = MultiDocValues.getBinaryValues(reader, \"dvBytesDerefFixed\");\n      BinaryDocValues dvBytesDerefVar = MultiDocValues.getBinaryValues(reader, \"dvBytesDerefVar\");\n      SortedDocValues dvBytesSortedFixed = MultiDocValues.getSortedValues(reader, \"dvBytesSortedFixed\");\n      SortedDocValues dvBytesSortedVar = MultiDocValues.getSortedValues(reader, \"dvBytesSortedVar\");\n      BinaryDocValues dvBytesStraightFixed = MultiDocValues.getBinaryValues(reader, \"dvBytesStraightFixed\");\n      BinaryDocValues dvBytesStraightVar = MultiDocValues.getBinaryValues(reader, \"dvBytesStraightVar\");\n      NumericDocValues dvDouble = MultiDocValues.getNumericValues(reader, \"dvDouble\");\n      NumericDocValues dvFloat = MultiDocValues.getNumericValues(reader, \"dvFloat\");\n      NumericDocValues dvInt = MultiDocValues.getNumericValues(reader, \"dvInt\");\n      NumericDocValues dvLong = MultiDocValues.getNumericValues(reader, \"dvLong\");\n      NumericDocValues dvPacked = MultiDocValues.getNumericValues(reader, \"dvPacked\");\n      NumericDocValues dvShort = MultiDocValues.getNumericValues(reader, \"dvShort\");\n      SortedSetDocValues dvSortedSet = null;\n      if (is42Index) {\n        dvSortedSet = MultiDocValues.getSortedSetValues(reader, \"dvSortedSet\");\n      }\n      SortedNumericDocValues dvSortedNumeric = null;\n      if (is49Index) {\n        dvSortedNumeric = MultiDocValues.getSortedNumericValues(reader, \"dvSortedNumeric\");\n      }\n      \n      for (int i=0;i<35;i++) {\n        int id = Integer.parseInt(reader.document(i).get(\"id\"));\n        assertEquals(id, dvByte.get(i));\n        \n        byte bytes[] = new byte[] {\n            (byte)(id >>> 24), (byte)(id >>> 16),(byte)(id >>> 8),(byte)id\n        };\n        BytesRef expectedRef = new BytesRef(bytes);\n        \n        BytesRef term = dvBytesDerefFixed.get(i);\n        assertEquals(expectedRef, term);\n        term = dvBytesDerefVar.get(i);\n        assertEquals(expectedRef, term);\n        term = dvBytesSortedFixed.get(i);\n        assertEquals(expectedRef, term);\n        term = dvBytesSortedVar.get(i);\n        assertEquals(expectedRef, term);\n        term = dvBytesStraightFixed.get(i);\n        assertEquals(expectedRef, term);\n        term = dvBytesStraightVar.get(i);\n        assertEquals(expectedRef, term);\n        \n        assertEquals((double)id, Double.longBitsToDouble(dvDouble.get(i)), 0D);\n        assertEquals((float)id, Float.intBitsToFloat((int)dvFloat.get(i)), 0F);\n        assertEquals(id, dvInt.get(i));\n        assertEquals(id, dvLong.get(i));\n        assertEquals(id, dvPacked.get(i));\n        assertEquals(id, dvShort.get(i));\n        if (is42Index) {\n          dvSortedSet.setDocument(i);\n          long ord = dvSortedSet.nextOrd();\n          assertEquals(SortedSetDocValues.NO_MORE_ORDS, dvSortedSet.nextOrd());\n          term = dvSortedSet.lookupOrd(ord);\n          assertEquals(expectedRef, term);\n        }\n        if (is49Index) {\n          dvSortedNumeric.setDocument(i);\n          assertEquals(1, dvSortedNumeric.count());\n          assertEquals(id, dvSortedNumeric.valueAt(0));\n        }\n      }\n    }\n    \n    ScoreDoc[] hits = searcher.search(new TermQuery(new Term(new String(\"content\"), \"aaa\")), null, 1000).scoreDocs;\n\n    // First document should be #0\n    StoredDocument d = searcher.getIndexReader().document(hits[0].doc);\n    assertEquals(\"didn't get the right document first\", \"0\", d.get(\"id\"));\n\n    doTestHits(hits, 34, searcher.getIndexReader());\n    \n    if (is40Index) {\n      hits = searcher.search(new TermQuery(new Term(new String(\"content5\"), \"aaa\")), null, 1000).scoreDocs;\n\n      doTestHits(hits, 34, searcher.getIndexReader());\n    \n      hits = searcher.search(new TermQuery(new Term(new String(\"content6\"), \"aaa\")), null, 1000).scoreDocs;\n\n      doTestHits(hits, 34, searcher.getIndexReader());\n    }\n\n    hits = searcher.search(new TermQuery(new Term(\"utf8\", \"\\u0000\")), null, 1000).scoreDocs;\n    assertEquals(34, hits.length);\n    hits = searcher.search(new TermQuery(new Term(new String(\"utf8\"), \"lu\\uD834\\uDD1Ece\\uD834\\uDD60ne\")), null, 1000).scoreDocs;\n    assertEquals(34, hits.length);\n    hits = searcher.search(new TermQuery(new Term(\"utf8\", \"ab\\ud917\\udc17cd\")), null, 1000).scoreDocs;\n    assertEquals(34, hits.length);\n\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"402ad3ddc9da7b70da1b167667a60ece6a1381fb","date":1409656478,"type":5,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/backward-codecs/src/test/org/apache/lucene/index/TestBackwardsCompatibility#searchIndex(Directory,String).mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestBackwardsCompatibility#searchIndex(Directory,String).mjava","sourceNew":"  public void searchIndex(Directory dir, String oldName) throws IOException {\n    //QueryParser parser = new QueryParser(\"contents\", new MockAnalyzer(random));\n    //Query query = parser.parse(\"handle:1\");\n\n    IndexReader reader = DirectoryReader.open(dir);\n    IndexSearcher searcher = newSearcher(reader);\n\n    TestUtil.checkIndex(dir);\n    \n    // true if this is a 4.0+ index\n    final boolean is40Index = MultiFields.getMergedFieldInfos(reader).fieldInfo(\"content5\") != null;\n    // true if this is a 4.2+ index\n    final boolean is42Index = MultiFields.getMergedFieldInfos(reader).fieldInfo(\"dvSortedSet\") != null;\n    // true if this is a 4.9+ index\n    final boolean is49Index = MultiFields.getMergedFieldInfos(reader).fieldInfo(\"dvSortedNumeric\") != null;\n\n    assert is40Index; // NOTE: currently we can only do this on trunk!\n\n    final Bits liveDocs = MultiFields.getLiveDocs(reader);\n\n    for(int i=0;i<35;i++) {\n      if (liveDocs.get(i)) {\n        StoredDocument d = reader.document(i);\n        List<StorableField> fields = d.getFields();\n        boolean isProxDoc = d.getField(\"content3\") == null;\n        if (isProxDoc) {\n          final int numFields = is40Index ? 7 : 5;\n          assertEquals(numFields, fields.size());\n          StorableField f =  d.getField(\"id\");\n          assertEquals(\"\"+i, f.stringValue());\n\n          f = d.getField(\"utf8\");\n          assertEquals(\"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne \\u0000 \\u2620 ab\\ud917\\udc17cd\", f.stringValue());\n\n          f =  d.getField(\"autf8\");\n          assertEquals(\"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne \\u0000 \\u2620 ab\\ud917\\udc17cd\", f.stringValue());\n      \n          f = d.getField(\"content2\");\n          assertEquals(\"here is more content with aaa aaa aaa\", f.stringValue());\n\n          f = d.getField(\"fie\\u2C77ld\");\n          assertEquals(\"field with non-ascii name\", f.stringValue());\n        }\n\n        Fields tfvFields = reader.getTermVectors(i);\n        assertNotNull(\"i=\" + i, tfvFields);\n        Terms tfv = tfvFields.terms(\"utf8\");\n        assertNotNull(\"docID=\" + i + \" index=\" + oldName, tfv);\n      } else {\n        // Only ID 7 is deleted\n        assertEquals(7, i);\n      }\n    }\n\n    if (is40Index) {\n      // check docvalues fields\n      NumericDocValues dvByte = MultiDocValues.getNumericValues(reader, \"dvByte\");\n      BinaryDocValues dvBytesDerefFixed = MultiDocValues.getBinaryValues(reader, \"dvBytesDerefFixed\");\n      BinaryDocValues dvBytesDerefVar = MultiDocValues.getBinaryValues(reader, \"dvBytesDerefVar\");\n      SortedDocValues dvBytesSortedFixed = MultiDocValues.getSortedValues(reader, \"dvBytesSortedFixed\");\n      SortedDocValues dvBytesSortedVar = MultiDocValues.getSortedValues(reader, \"dvBytesSortedVar\");\n      BinaryDocValues dvBytesStraightFixed = MultiDocValues.getBinaryValues(reader, \"dvBytesStraightFixed\");\n      BinaryDocValues dvBytesStraightVar = MultiDocValues.getBinaryValues(reader, \"dvBytesStraightVar\");\n      NumericDocValues dvDouble = MultiDocValues.getNumericValues(reader, \"dvDouble\");\n      NumericDocValues dvFloat = MultiDocValues.getNumericValues(reader, \"dvFloat\");\n      NumericDocValues dvInt = MultiDocValues.getNumericValues(reader, \"dvInt\");\n      NumericDocValues dvLong = MultiDocValues.getNumericValues(reader, \"dvLong\");\n      NumericDocValues dvPacked = MultiDocValues.getNumericValues(reader, \"dvPacked\");\n      NumericDocValues dvShort = MultiDocValues.getNumericValues(reader, \"dvShort\");\n      SortedSetDocValues dvSortedSet = null;\n      if (is42Index) {\n        dvSortedSet = MultiDocValues.getSortedSetValues(reader, \"dvSortedSet\");\n      }\n      SortedNumericDocValues dvSortedNumeric = null;\n      if (is49Index) {\n        dvSortedNumeric = MultiDocValues.getSortedNumericValues(reader, \"dvSortedNumeric\");\n      }\n      \n      for (int i=0;i<35;i++) {\n        int id = Integer.parseInt(reader.document(i).get(\"id\"));\n        assertEquals(id, dvByte.get(i));\n        \n        byte bytes[] = new byte[] {\n            (byte)(id >>> 24), (byte)(id >>> 16),(byte)(id >>> 8),(byte)id\n        };\n        BytesRef expectedRef = new BytesRef(bytes);\n        \n        BytesRef term = dvBytesDerefFixed.get(i);\n        assertEquals(expectedRef, term);\n        term = dvBytesDerefVar.get(i);\n        assertEquals(expectedRef, term);\n        term = dvBytesSortedFixed.get(i);\n        assertEquals(expectedRef, term);\n        term = dvBytesSortedVar.get(i);\n        assertEquals(expectedRef, term);\n        term = dvBytesStraightFixed.get(i);\n        assertEquals(expectedRef, term);\n        term = dvBytesStraightVar.get(i);\n        assertEquals(expectedRef, term);\n        \n        assertEquals((double)id, Double.longBitsToDouble(dvDouble.get(i)), 0D);\n        assertEquals((float)id, Float.intBitsToFloat((int)dvFloat.get(i)), 0F);\n        assertEquals(id, dvInt.get(i));\n        assertEquals(id, dvLong.get(i));\n        assertEquals(id, dvPacked.get(i));\n        assertEquals(id, dvShort.get(i));\n        if (is42Index) {\n          dvSortedSet.setDocument(i);\n          long ord = dvSortedSet.nextOrd();\n          assertEquals(SortedSetDocValues.NO_MORE_ORDS, dvSortedSet.nextOrd());\n          term = dvSortedSet.lookupOrd(ord);\n          assertEquals(expectedRef, term);\n        }\n        if (is49Index) {\n          dvSortedNumeric.setDocument(i);\n          assertEquals(1, dvSortedNumeric.count());\n          assertEquals(id, dvSortedNumeric.valueAt(0));\n        }\n      }\n    }\n    \n    ScoreDoc[] hits = searcher.search(new TermQuery(new Term(new String(\"content\"), \"aaa\")), null, 1000).scoreDocs;\n\n    // First document should be #0\n    StoredDocument d = searcher.getIndexReader().document(hits[0].doc);\n    assertEquals(\"didn't get the right document first\", \"0\", d.get(\"id\"));\n\n    doTestHits(hits, 34, searcher.getIndexReader());\n    \n    if (is40Index) {\n      hits = searcher.search(new TermQuery(new Term(new String(\"content5\"), \"aaa\")), null, 1000).scoreDocs;\n\n      doTestHits(hits, 34, searcher.getIndexReader());\n    \n      hits = searcher.search(new TermQuery(new Term(new String(\"content6\"), \"aaa\")), null, 1000).scoreDocs;\n\n      doTestHits(hits, 34, searcher.getIndexReader());\n    }\n\n    hits = searcher.search(new TermQuery(new Term(\"utf8\", \"\\u0000\")), null, 1000).scoreDocs;\n    assertEquals(34, hits.length);\n    hits = searcher.search(new TermQuery(new Term(new String(\"utf8\"), \"lu\\uD834\\uDD1Ece\\uD834\\uDD60ne\")), null, 1000).scoreDocs;\n    assertEquals(34, hits.length);\n    hits = searcher.search(new TermQuery(new Term(\"utf8\", \"ab\\ud917\\udc17cd\")), null, 1000).scoreDocs;\n    assertEquals(34, hits.length);\n\n    reader.close();\n  }\n\n","sourceOld":"  public void searchIndex(Directory dir, String oldName) throws IOException {\n    //QueryParser parser = new QueryParser(\"contents\", new MockAnalyzer(random));\n    //Query query = parser.parse(\"handle:1\");\n\n    IndexReader reader = DirectoryReader.open(dir);\n    IndexSearcher searcher = newSearcher(reader);\n\n    TestUtil.checkIndex(dir);\n    \n    // true if this is a 4.0+ index\n    final boolean is40Index = MultiFields.getMergedFieldInfos(reader).fieldInfo(\"content5\") != null;\n    // true if this is a 4.2+ index\n    final boolean is42Index = MultiFields.getMergedFieldInfos(reader).fieldInfo(\"dvSortedSet\") != null;\n    // true if this is a 4.9+ index\n    final boolean is49Index = MultiFields.getMergedFieldInfos(reader).fieldInfo(\"dvSortedNumeric\") != null;\n\n    assert is40Index; // NOTE: currently we can only do this on trunk!\n\n    final Bits liveDocs = MultiFields.getLiveDocs(reader);\n\n    for(int i=0;i<35;i++) {\n      if (liveDocs.get(i)) {\n        StoredDocument d = reader.document(i);\n        List<StorableField> fields = d.getFields();\n        boolean isProxDoc = d.getField(\"content3\") == null;\n        if (isProxDoc) {\n          final int numFields = is40Index ? 7 : 5;\n          assertEquals(numFields, fields.size());\n          StorableField f =  d.getField(\"id\");\n          assertEquals(\"\"+i, f.stringValue());\n\n          f = d.getField(\"utf8\");\n          assertEquals(\"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne \\u0000 \\u2620 ab\\ud917\\udc17cd\", f.stringValue());\n\n          f =  d.getField(\"autf8\");\n          assertEquals(\"Lu\\uD834\\uDD1Ece\\uD834\\uDD60ne \\u0000 \\u2620 ab\\ud917\\udc17cd\", f.stringValue());\n      \n          f = d.getField(\"content2\");\n          assertEquals(\"here is more content with aaa aaa aaa\", f.stringValue());\n\n          f = d.getField(\"fie\\u2C77ld\");\n          assertEquals(\"field with non-ascii name\", f.stringValue());\n        }\n\n        Fields tfvFields = reader.getTermVectors(i);\n        assertNotNull(\"i=\" + i, tfvFields);\n        Terms tfv = tfvFields.terms(\"utf8\");\n        assertNotNull(\"docID=\" + i + \" index=\" + oldName, tfv);\n      } else {\n        // Only ID 7 is deleted\n        assertEquals(7, i);\n      }\n    }\n\n    if (is40Index) {\n      // check docvalues fields\n      NumericDocValues dvByte = MultiDocValues.getNumericValues(reader, \"dvByte\");\n      BinaryDocValues dvBytesDerefFixed = MultiDocValues.getBinaryValues(reader, \"dvBytesDerefFixed\");\n      BinaryDocValues dvBytesDerefVar = MultiDocValues.getBinaryValues(reader, \"dvBytesDerefVar\");\n      SortedDocValues dvBytesSortedFixed = MultiDocValues.getSortedValues(reader, \"dvBytesSortedFixed\");\n      SortedDocValues dvBytesSortedVar = MultiDocValues.getSortedValues(reader, \"dvBytesSortedVar\");\n      BinaryDocValues dvBytesStraightFixed = MultiDocValues.getBinaryValues(reader, \"dvBytesStraightFixed\");\n      BinaryDocValues dvBytesStraightVar = MultiDocValues.getBinaryValues(reader, \"dvBytesStraightVar\");\n      NumericDocValues dvDouble = MultiDocValues.getNumericValues(reader, \"dvDouble\");\n      NumericDocValues dvFloat = MultiDocValues.getNumericValues(reader, \"dvFloat\");\n      NumericDocValues dvInt = MultiDocValues.getNumericValues(reader, \"dvInt\");\n      NumericDocValues dvLong = MultiDocValues.getNumericValues(reader, \"dvLong\");\n      NumericDocValues dvPacked = MultiDocValues.getNumericValues(reader, \"dvPacked\");\n      NumericDocValues dvShort = MultiDocValues.getNumericValues(reader, \"dvShort\");\n      SortedSetDocValues dvSortedSet = null;\n      if (is42Index) {\n        dvSortedSet = MultiDocValues.getSortedSetValues(reader, \"dvSortedSet\");\n      }\n      SortedNumericDocValues dvSortedNumeric = null;\n      if (is49Index) {\n        dvSortedNumeric = MultiDocValues.getSortedNumericValues(reader, \"dvSortedNumeric\");\n      }\n      \n      for (int i=0;i<35;i++) {\n        int id = Integer.parseInt(reader.document(i).get(\"id\"));\n        assertEquals(id, dvByte.get(i));\n        \n        byte bytes[] = new byte[] {\n            (byte)(id >>> 24), (byte)(id >>> 16),(byte)(id >>> 8),(byte)id\n        };\n        BytesRef expectedRef = new BytesRef(bytes);\n        \n        BytesRef term = dvBytesDerefFixed.get(i);\n        assertEquals(expectedRef, term);\n        term = dvBytesDerefVar.get(i);\n        assertEquals(expectedRef, term);\n        term = dvBytesSortedFixed.get(i);\n        assertEquals(expectedRef, term);\n        term = dvBytesSortedVar.get(i);\n        assertEquals(expectedRef, term);\n        term = dvBytesStraightFixed.get(i);\n        assertEquals(expectedRef, term);\n        term = dvBytesStraightVar.get(i);\n        assertEquals(expectedRef, term);\n        \n        assertEquals((double)id, Double.longBitsToDouble(dvDouble.get(i)), 0D);\n        assertEquals((float)id, Float.intBitsToFloat((int)dvFloat.get(i)), 0F);\n        assertEquals(id, dvInt.get(i));\n        assertEquals(id, dvLong.get(i));\n        assertEquals(id, dvPacked.get(i));\n        assertEquals(id, dvShort.get(i));\n        if (is42Index) {\n          dvSortedSet.setDocument(i);\n          long ord = dvSortedSet.nextOrd();\n          assertEquals(SortedSetDocValues.NO_MORE_ORDS, dvSortedSet.nextOrd());\n          term = dvSortedSet.lookupOrd(ord);\n          assertEquals(expectedRef, term);\n        }\n        if (is49Index) {\n          dvSortedNumeric.setDocument(i);\n          assertEquals(1, dvSortedNumeric.count());\n          assertEquals(id, dvSortedNumeric.valueAt(0));\n        }\n      }\n    }\n    \n    ScoreDoc[] hits = searcher.search(new TermQuery(new Term(new String(\"content\"), \"aaa\")), null, 1000).scoreDocs;\n\n    // First document should be #0\n    StoredDocument d = searcher.getIndexReader().document(hits[0].doc);\n    assertEquals(\"didn't get the right document first\", \"0\", d.get(\"id\"));\n\n    doTestHits(hits, 34, searcher.getIndexReader());\n    \n    if (is40Index) {\n      hits = searcher.search(new TermQuery(new Term(new String(\"content5\"), \"aaa\")), null, 1000).scoreDocs;\n\n      doTestHits(hits, 34, searcher.getIndexReader());\n    \n      hits = searcher.search(new TermQuery(new Term(new String(\"content6\"), \"aaa\")), null, 1000).scoreDocs;\n\n      doTestHits(hits, 34, searcher.getIndexReader());\n    }\n\n    hits = searcher.search(new TermQuery(new Term(\"utf8\", \"\\u0000\")), null, 1000).scoreDocs;\n    assertEquals(34, hits.length);\n    hits = searcher.search(new TermQuery(new Term(new String(\"utf8\"), \"lu\\uD834\\uDD1Ece\\uD834\\uDD60ne\")), null, 1000).scoreDocs;\n    assertEquals(34, hits.length);\n    hits = searcher.search(new TermQuery(new Term(\"utf8\", \"ab\\ud917\\udc17cd\")), null, 1000).scoreDocs;\n    assertEquals(34, hits.length);\n\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"cf67308cf3e605faada2e2e5092aff47ae822912":["53fc2f4c5ce4f2053be3d5f5d14d79129ebb4bbf"],"4a8b14bc4241c302311422d5c6f7627f8febb86e":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"8f0e28f2a7f0f3f0fca1a2ffedaa10c7ac9536c4":["5a3b444707abab6c7f63c331b3f44971c53b0f07"],"53fc2f4c5ce4f2053be3d5f5d14d79129ebb4bbf":["6613659748fe4411a7dcf85266e55db1f95f7315"],"6613659748fe4411a7dcf85266e55db1f95f7315":["3b0e8c39ca08b5a02de6edcd33d6f3b90b865173"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"3b0e8c39ca08b5a02de6edcd33d6f3b90b865173":["3fe3b1894255151160e7a26231483e8ab0e310a7"],"b11100924615fd39ef80bc5cd463a565129b0533":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"402ad3ddc9da7b70da1b167667a60ece6a1381fb":["cf67308cf3e605faada2e2e5092aff47ae822912","4cc45c615dbb82bf79d5f9550286098367874fbf"],"57ae3024996ccdb3c36c42cb890e1efb37df4ce8":["615ddbd81799980d0fdd95e0238e1c498b6f47b0"],"1d028314cced5858683a1bb4741423d0f934257b":["5a3b444707abab6c7f63c331b3f44971c53b0f07","8f0e28f2a7f0f3f0fca1a2ffedaa10c7ac9536c4"],"3fe3b1894255151160e7a26231483e8ab0e310a7":["d4d69c535930b5cce125cff868d40f6373dc27d4"],"615ddbd81799980d0fdd95e0238e1c498b6f47b0":["b11100924615fd39ef80bc5cd463a565129b0533","3599646b4d4c346cf74d334813488b8b337b5bf5"],"e7e8d6f15900ee22ac3cb0a503f15dc952a3580f":["57ae3024996ccdb3c36c42cb890e1efb37df4ce8"],"d4d69c535930b5cce125cff868d40f6373dc27d4":["1d028314cced5858683a1bb4741423d0f934257b","e865135253d3ad47840f06992c7c801e3fd71907"],"ad7de846867bd14c63f9dd19df082f72c5ea9c54":["1d028314cced5858683a1bb4741423d0f934257b"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"3599646b4d4c346cf74d334813488b8b337b5bf5":["4a8b14bc4241c302311422d5c6f7627f8febb86e","b11100924615fd39ef80bc5cd463a565129b0533"],"4cc45c615dbb82bf79d5f9550286098367874fbf":["cf67308cf3e605faada2e2e5092aff47ae822912"],"5a3b444707abab6c7f63c331b3f44971c53b0f07":["e7e8d6f15900ee22ac3cb0a503f15dc952a3580f"],"e865135253d3ad47840f06992c7c801e3fd71907":["ad7de846867bd14c63f9dd19df082f72c5ea9c54"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["402ad3ddc9da7b70da1b167667a60ece6a1381fb"]},"commit2Childs":{"cf67308cf3e605faada2e2e5092aff47ae822912":["402ad3ddc9da7b70da1b167667a60ece6a1381fb","4cc45c615dbb82bf79d5f9550286098367874fbf"],"4a8b14bc4241c302311422d5c6f7627f8febb86e":["3599646b4d4c346cf74d334813488b8b337b5bf5"],"8f0e28f2a7f0f3f0fca1a2ffedaa10c7ac9536c4":["1d028314cced5858683a1bb4741423d0f934257b"],"53fc2f4c5ce4f2053be3d5f5d14d79129ebb4bbf":["cf67308cf3e605faada2e2e5092aff47ae822912"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["4a8b14bc4241c302311422d5c6f7627f8febb86e","b11100924615fd39ef80bc5cd463a565129b0533"],"6613659748fe4411a7dcf85266e55db1f95f7315":["53fc2f4c5ce4f2053be3d5f5d14d79129ebb4bbf"],"3b0e8c39ca08b5a02de6edcd33d6f3b90b865173":["6613659748fe4411a7dcf85266e55db1f95f7315"],"b11100924615fd39ef80bc5cd463a565129b0533":["615ddbd81799980d0fdd95e0238e1c498b6f47b0","3599646b4d4c346cf74d334813488b8b337b5bf5"],"402ad3ddc9da7b70da1b167667a60ece6a1381fb":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"57ae3024996ccdb3c36c42cb890e1efb37df4ce8":["e7e8d6f15900ee22ac3cb0a503f15dc952a3580f"],"1d028314cced5858683a1bb4741423d0f934257b":["d4d69c535930b5cce125cff868d40f6373dc27d4","ad7de846867bd14c63f9dd19df082f72c5ea9c54"],"3fe3b1894255151160e7a26231483e8ab0e310a7":["3b0e8c39ca08b5a02de6edcd33d6f3b90b865173"],"615ddbd81799980d0fdd95e0238e1c498b6f47b0":["57ae3024996ccdb3c36c42cb890e1efb37df4ce8"],"d4d69c535930b5cce125cff868d40f6373dc27d4":["3fe3b1894255151160e7a26231483e8ab0e310a7"],"e7e8d6f15900ee22ac3cb0a503f15dc952a3580f":["5a3b444707abab6c7f63c331b3f44971c53b0f07"],"ad7de846867bd14c63f9dd19df082f72c5ea9c54":["e865135253d3ad47840f06992c7c801e3fd71907"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"4cc45c615dbb82bf79d5f9550286098367874fbf":["402ad3ddc9da7b70da1b167667a60ece6a1381fb"],"3599646b4d4c346cf74d334813488b8b337b5bf5":["615ddbd81799980d0fdd95e0238e1c498b6f47b0"],"5a3b444707abab6c7f63c331b3f44971c53b0f07":["8f0e28f2a7f0f3f0fca1a2ffedaa10c7ac9536c4","1d028314cced5858683a1bb4741423d0f934257b"],"e865135253d3ad47840f06992c7c801e3fd71907":["d4d69c535930b5cce125cff868d40f6373dc27d4"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}