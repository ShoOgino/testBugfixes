{"path":"src/java/org/apache/lucene/index/SegmentMerger#appendPostings(FormatPostingsTermsConsumer,SegmentMergeInfo[],int).mjava","commits":[{"id":"4d17492f26096e19670d947d1be5e9adc52b1d3d","date":1224931200,"type":1,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/SegmentMerger#appendPostings(FormatPostingsTermsConsumer,SegmentMergeInfo[],int).mjava","pathOld":"src/java/org/apache/lucene/index/SegmentMerger#appendPostingsNoTf(SegmentMergeInfo[],int).mjava","sourceNew":"  /** Process postings from multiple segments all positioned on the\n   *  same term. Writes out merged entries into freqOutput and\n   *  the proxOutput streams.\n   *\n   * @param smis array of segments\n   * @param n number of cells in the array actually occupied\n   * @return number of documents across all segments where this term was found\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  private final int appendPostings(final FormatPostingsTermsConsumer termsConsumer, SegmentMergeInfo[] smis, int n)\n        throws CorruptIndexException, IOException {\n\n    final FormatPostingsDocsConsumer docConsumer = termsConsumer.addTerm(smis[0].term.text);\n    int df = 0;\n    for (int i = 0; i < n; i++) {\n      SegmentMergeInfo smi = smis[i];\n      TermPositions postings = smi.getPositions();\n      assert postings != null;\n      int base = smi.base;\n      int[] docMap = smi.getDocMap();\n      postings.seek(smi.termEnum);\n\n      while (postings.next()) {\n        df++;\n        int doc = postings.doc();\n        if (docMap != null)\n          doc = docMap[doc];                      // map around deletions\n        doc += base;                              // convert to merged space\n\n        final int freq = postings.freq();\n        final FormatPostingsPositionsConsumer posConsumer = docConsumer.addDoc(doc, freq);\n\n        if (!omitTF) {\n          for (int j = 0; j < freq; j++) {\n            final int position = postings.nextPosition();\n            final int payloadLength = postings.getPayloadLength();\n            if (payloadLength > 0) {\n              if (payloadBuffer == null || payloadBuffer.length < payloadLength)\n                payloadBuffer = new byte[payloadLength];\n              postings.getPayload(payloadBuffer, 0);\n            }\n            posConsumer.addPosition(position, payloadBuffer, 0, payloadLength);\n          }\n          posConsumer.finish();\n        }\n      }\n    }\n    docConsumer.finish();\n\n    return df;\n  }\n\n","sourceOld":"  /** Process postings from multiple segments without tf, all positioned on the\n   *  same term. Writes out merged entries only into freqOutput, proxOut is not written.\n   *\n   * @param smis array of segments\n   * @param n number of cells in the array actually occupied\n   * @return number of documents across all segments where this term was found\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  private final int appendPostingsNoTf(SegmentMergeInfo[] smis, int n)\n          throws CorruptIndexException, IOException {\n    int lastDoc = 0;\n    int df = 0;           // number of docs w/ term\n    skipListWriter.resetSkip();\n    int lastPayloadLength = -1;   // ensures that we write the first length\n    for (int i = 0; i < n; i++) {\n      SegmentMergeInfo smi = smis[i];\n      TermPositions postings = smi.getPositions();\n      assert postings != null;\n      int base = smi.base;\n      int[] docMap = smi.getDocMap();\n      postings.seek(smi.termEnum);\n      while (postings.next()) {\n        int doc = postings.doc();\n        if (docMap != null)\n          doc = docMap[doc];                      // map around deletions\n        doc += base;                              // convert to merged space\n\n        if (doc < 0 || (df > 0 && doc <= lastDoc))\n          throw new CorruptIndexException(\"docs out of order (\" + doc +\n              \" <= \" + lastDoc + \" )\");\n\n        df++;\n\n        if ((df % skipInterval) == 0) {\n          skipListWriter.setSkipData(lastDoc, false, lastPayloadLength);\n          skipListWriter.bufferSkip(df);\n        }\n\n        int docCode = (doc - lastDoc);   \n        lastDoc = doc;\n        freqOutput.writeVInt(docCode);    // write doc & freq=1\n      }\n    }\n    return df;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"066b6ff5a08e35c3b6880e7c3ddda79526acdab1","date":1237569961,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/SegmentMerger#appendPostings(FormatPostingsTermsConsumer,SegmentMergeInfo[],int).mjava","pathOld":"src/java/org/apache/lucene/index/SegmentMerger#appendPostings(FormatPostingsTermsConsumer,SegmentMergeInfo[],int).mjava","sourceNew":"  /** Process postings from multiple segments all positioned on the\n   *  same term. Writes out merged entries into freqOutput and\n   *  the proxOutput streams.\n   *\n   * @param smis array of segments\n   * @param n number of cells in the array actually occupied\n   * @return number of documents across all segments where this term was found\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  private final int appendPostings(final FormatPostingsTermsConsumer termsConsumer, SegmentMergeInfo[] smis, int n)\n        throws CorruptIndexException, IOException {\n\n    final FormatPostingsDocsConsumer docConsumer = termsConsumer.addTerm(smis[0].term.text);\n    int df = 0;\n    for (int i = 0; i < n; i++) {\n      SegmentMergeInfo smi = smis[i];\n      TermPositions postings = smi.getPositions();\n      assert postings != null;\n      int base = smi.base;\n      int[] docMap = smi.getDocMap();\n      postings.seek(smi.termEnum);\n\n      while (postings.next()) {\n        df++;\n        int doc = postings.doc();\n        if (docMap != null)\n          doc = docMap[doc];                      // map around deletions\n        doc += base;                              // convert to merged space\n\n        final int freq = postings.freq();\n        final FormatPostingsPositionsConsumer posConsumer = docConsumer.addDoc(doc, freq);\n\n        if (!omitTermFreqAndPositions) {\n          for (int j = 0; j < freq; j++) {\n            final int position = postings.nextPosition();\n            final int payloadLength = postings.getPayloadLength();\n            if (payloadLength > 0) {\n              if (payloadBuffer == null || payloadBuffer.length < payloadLength)\n                payloadBuffer = new byte[payloadLength];\n              postings.getPayload(payloadBuffer, 0);\n            }\n            posConsumer.addPosition(position, payloadBuffer, 0, payloadLength);\n          }\n          posConsumer.finish();\n        }\n      }\n    }\n    docConsumer.finish();\n\n    return df;\n  }\n\n","sourceOld":"  /** Process postings from multiple segments all positioned on the\n   *  same term. Writes out merged entries into freqOutput and\n   *  the proxOutput streams.\n   *\n   * @param smis array of segments\n   * @param n number of cells in the array actually occupied\n   * @return number of documents across all segments where this term was found\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  private final int appendPostings(final FormatPostingsTermsConsumer termsConsumer, SegmentMergeInfo[] smis, int n)\n        throws CorruptIndexException, IOException {\n\n    final FormatPostingsDocsConsumer docConsumer = termsConsumer.addTerm(smis[0].term.text);\n    int df = 0;\n    for (int i = 0; i < n; i++) {\n      SegmentMergeInfo smi = smis[i];\n      TermPositions postings = smi.getPositions();\n      assert postings != null;\n      int base = smi.base;\n      int[] docMap = smi.getDocMap();\n      postings.seek(smi.termEnum);\n\n      while (postings.next()) {\n        df++;\n        int doc = postings.doc();\n        if (docMap != null)\n          doc = docMap[doc];                      // map around deletions\n        doc += base;                              // convert to merged space\n\n        final int freq = postings.freq();\n        final FormatPostingsPositionsConsumer posConsumer = docConsumer.addDoc(doc, freq);\n\n        if (!omitTF) {\n          for (int j = 0; j < freq; j++) {\n            final int position = postings.nextPosition();\n            final int payloadLength = postings.getPayloadLength();\n            if (payloadLength > 0) {\n              if (payloadBuffer == null || payloadBuffer.length < payloadLength)\n                payloadBuffer = new byte[payloadLength];\n              postings.getPayload(payloadBuffer, 0);\n            }\n            posConsumer.addPosition(position, payloadBuffer, 0, payloadLength);\n          }\n          posConsumer.finish();\n        }\n      }\n    }\n    docConsumer.finish();\n\n    return df;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9454a6510e2db155fb01faa5c049b06ece95fab9","date":1453508333,"type":5,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/SegmentMerger#appendPostings(FormatPostingsTermsConsumer,SegmentMergeInfo[],int).mjava","pathOld":"src/java/org/apache/lucene/index/SegmentMerger#appendPostings(FormatPostingsTermsConsumer,SegmentMergeInfo[],int).mjava","sourceNew":"  /** Process postings from multiple segments all positioned on the\n   *  same term. Writes out merged entries into freqOutput and\n   *  the proxOutput streams.\n   *\n   * @param smis array of segments\n   * @param n number of cells in the array actually occupied\n   * @return number of documents across all segments where this term was found\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  private final int appendPostings(final FormatPostingsTermsConsumer termsConsumer, SegmentMergeInfo[] smis, int n)\n        throws CorruptIndexException, IOException {\n\n    final FormatPostingsDocsConsumer docConsumer = termsConsumer.addTerm(smis[0].term.text);\n    int df = 0;\n    for (int i = 0; i < n; i++) {\n      SegmentMergeInfo smi = smis[i];\n      TermPositions postings = smi.getPositions();\n      assert postings != null;\n      int base = smi.base;\n      int[] docMap = smi.getDocMap();\n      postings.seek(smi.termEnum);\n\n      while (postings.next()) {\n        df++;\n        int doc = postings.doc();\n        if (docMap != null)\n          doc = docMap[doc];                      // map around deletions\n        doc += base;                              // convert to merged space\n\n        final int freq = postings.freq();\n        final FormatPostingsPositionsConsumer posConsumer = docConsumer.addDoc(doc, freq);\n\n        if (!omitTermFreqAndPositions) {\n          for (int j = 0; j < freq; j++) {\n            final int position = postings.nextPosition();\n            final int payloadLength = postings.getPayloadLength();\n            if (payloadLength > 0) {\n              if (payloadBuffer == null || payloadBuffer.length < payloadLength)\n                payloadBuffer = new byte[payloadLength];\n              postings.getPayload(payloadBuffer, 0);\n            }\n            posConsumer.addPosition(position, payloadBuffer, 0, payloadLength);\n          }\n          posConsumer.finish();\n        }\n      }\n    }\n    docConsumer.finish();\n\n    return df;\n  }\n\n","sourceOld":"  /** Process postings from multiple segments all positioned on the\n   *  same term. Writes out merged entries into freqOutput and\n   *  the proxOutput streams.\n   *\n   * @param smis array of segments\n   * @param n number of cells in the array actually occupied\n   * @return number of documents across all segments where this term was found\n   * @throws CorruptIndexException if the index is corrupt\n   * @throws IOException if there is a low-level IO error\n   */\n  private final int appendPostings(final FormatPostingsTermsConsumer termsConsumer, SegmentMergeInfo[] smis, int n)\n        throws CorruptIndexException, IOException {\n\n    final FormatPostingsDocsConsumer docConsumer = termsConsumer.addTerm(smis[0].term.text);\n    int df = 0;\n    for (int i = 0; i < n; i++) {\n      SegmentMergeInfo smi = smis[i];\n      TermPositions postings = smi.getPositions();\n      assert postings != null;\n      int base = smi.base;\n      int[] docMap = smi.getDocMap();\n      postings.seek(smi.termEnum);\n\n      while (postings.next()) {\n        df++;\n        int doc = postings.doc();\n        if (docMap != null)\n          doc = docMap[doc];                      // map around deletions\n        doc += base;                              // convert to merged space\n\n        final int freq = postings.freq();\n        final FormatPostingsPositionsConsumer posConsumer = docConsumer.addDoc(doc, freq);\n\n        if (!omitTermFreqAndPositions) {\n          for (int j = 0; j < freq; j++) {\n            final int position = postings.nextPosition();\n            final int payloadLength = postings.getPayloadLength();\n            if (payloadLength > 0) {\n              if (payloadBuffer == null || payloadBuffer.length < payloadLength)\n                payloadBuffer = new byte[payloadLength];\n              postings.getPayload(payloadBuffer, 0);\n            }\n            posConsumer.addPosition(position, payloadBuffer, 0, payloadLength);\n          }\n          posConsumer.finish();\n        }\n      }\n    }\n    docConsumer.finish();\n\n    return df;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"066b6ff5a08e35c3b6880e7c3ddda79526acdab1":["4d17492f26096e19670d947d1be5e9adc52b1d3d"],"4d17492f26096e19670d947d1be5e9adc52b1d3d":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["066b6ff5a08e35c3b6880e7c3ddda79526acdab1"]},"commit2Childs":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["4d17492f26096e19670d947d1be5e9adc52b1d3d"],"066b6ff5a08e35c3b6880e7c3ddda79526acdab1":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"4d17492f26096e19670d947d1be5e9adc52b1d3d":["066b6ff5a08e35c3b6880e7c3ddda79526acdab1"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"9454a6510e2db155fb01faa5c049b06ece95fab9":["cd5edd1f2b162a5cfa08efd17851a07373a96817"]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}