{"path":"lucene/core/src/java/org/apache/lucene/index/IndexingChain#getOrAddField(String,IndexableFieldType,boolean).mjava","commits":[{"id":"7a6f8af01d9b3067b143bbdc0a492720e2af97cf","date":1600157724,"type":1,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexingChain#getOrAddField(String,IndexableFieldType,boolean).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/DefaultIndexingChain#getOrAddField(String,IndexableFieldType,boolean).mjava","sourceNew":"  /** Returns a previously created {@link PerField},\n   *  absorbing the type information from {@link FieldType},\n   *  and creates a new {@link PerField} if this field name\n   *  wasn't seen yet. */\n  private PerField getOrAddField(String name, IndexableFieldType fieldType, boolean invert) {\n\n    // Make sure we have a PerField allocated\n    final int hashPos = name.hashCode() & hashMask;\n    PerField fp = fieldHash[hashPos];\n    while (fp != null && !fp.fieldInfo.name.equals(name)) {\n      fp = fp.next;\n    }\n\n    if (fp == null) {\n      // First time we are seeing this field in this segment\n\n      FieldInfo fi = fieldInfos.getOrAdd(name);\n      initIndexOptions(fi, fieldType.indexOptions());\n      Map<String, String> attributes = fieldType.getAttributes();\n      if (attributes != null) {\n        attributes.forEach((k, v) -> fi.putAttribute(k, v));\n      }\n\n      fp = new PerField(indexCreatedVersionMajor, fi, invert,\n          indexWriterConfig.getSimilarity(), indexWriterConfig.getInfoStream(), indexWriterConfig.getAnalyzer());\n      fp.next = fieldHash[hashPos];\n      fieldHash[hashPos] = fp;\n      totalFieldCount++;\n\n      // At most 50% load factor:\n      if (totalFieldCount >= fieldHash.length/2) {\n        rehash();\n      }\n\n      if (totalFieldCount > fields.length) {\n        PerField[] newFields = new PerField[ArrayUtil.oversize(totalFieldCount, RamUsageEstimator.NUM_BYTES_OBJECT_REF)];\n        System.arraycopy(fields, 0, newFields, 0, fields.length);\n        fields = newFields;\n      }\n\n    } else if (invert && fp.invertState == null) {\n      initIndexOptions(fp.fieldInfo, fieldType.indexOptions());\n      fp.setInvertState();\n    }\n\n    return fp;\n  }\n\n","sourceOld":"  /** Returns a previously created {@link PerField},\n   *  absorbing the type information from {@link FieldType},\n   *  and creates a new {@link PerField} if this field name\n   *  wasn't seen yet. */\n  private PerField getOrAddField(String name, IndexableFieldType fieldType, boolean invert) {\n\n    // Make sure we have a PerField allocated\n    final int hashPos = name.hashCode() & hashMask;\n    PerField fp = fieldHash[hashPos];\n    while (fp != null && !fp.fieldInfo.name.equals(name)) {\n      fp = fp.next;\n    }\n\n    if (fp == null) {\n      // First time we are seeing this field in this segment\n\n      FieldInfo fi = fieldInfos.getOrAdd(name);\n      initIndexOptions(fi, fieldType.indexOptions());\n      Map<String, String> attributes = fieldType.getAttributes();\n      if (attributes != null) {\n        attributes.forEach((k, v) -> fi.putAttribute(k, v));\n      }\n\n      fp = new PerField(indexCreatedVersionMajor, fi, invert,\n          indexWriterConfig.getSimilarity(), indexWriterConfig.getInfoStream(), indexWriterConfig.getAnalyzer());\n      fp.next = fieldHash[hashPos];\n      fieldHash[hashPos] = fp;\n      totalFieldCount++;\n\n      // At most 50% load factor:\n      if (totalFieldCount >= fieldHash.length/2) {\n        rehash();\n      }\n\n      if (totalFieldCount > fields.length) {\n        PerField[] newFields = new PerField[ArrayUtil.oversize(totalFieldCount, RamUsageEstimator.NUM_BYTES_OBJECT_REF)];\n        System.arraycopy(fields, 0, newFields, 0, fields.length);\n        fields = newFields;\n      }\n\n    } else if (invert && fp.invertState == null) {\n      initIndexOptions(fp.fieldInfo, fieldType.indexOptions());\n      fp.setInvertState();\n    }\n\n    return fp;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"680b6449f09827f58fe987aff279e014c311d966","date":1600247985,"type":1,"author":"noblepaul","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/IndexingChain#getOrAddField(String,IndexableFieldType,boolean).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/DefaultIndexingChain#getOrAddField(String,IndexableFieldType,boolean).mjava","sourceNew":"  /** Returns a previously created {@link PerField},\n   *  absorbing the type information from {@link FieldType},\n   *  and creates a new {@link PerField} if this field name\n   *  wasn't seen yet. */\n  private PerField getOrAddField(String name, IndexableFieldType fieldType, boolean invert) {\n\n    // Make sure we have a PerField allocated\n    final int hashPos = name.hashCode() & hashMask;\n    PerField fp = fieldHash[hashPos];\n    while (fp != null && !fp.fieldInfo.name.equals(name)) {\n      fp = fp.next;\n    }\n\n    if (fp == null) {\n      // First time we are seeing this field in this segment\n\n      FieldInfo fi = fieldInfos.getOrAdd(name);\n      initIndexOptions(fi, fieldType.indexOptions());\n      Map<String, String> attributes = fieldType.getAttributes();\n      if (attributes != null) {\n        attributes.forEach((k, v) -> fi.putAttribute(k, v));\n      }\n\n      fp = new PerField(indexCreatedVersionMajor, fi, invert,\n          indexWriterConfig.getSimilarity(), indexWriterConfig.getInfoStream(), indexWriterConfig.getAnalyzer());\n      fp.next = fieldHash[hashPos];\n      fieldHash[hashPos] = fp;\n      totalFieldCount++;\n\n      // At most 50% load factor:\n      if (totalFieldCount >= fieldHash.length/2) {\n        rehash();\n      }\n\n      if (totalFieldCount > fields.length) {\n        PerField[] newFields = new PerField[ArrayUtil.oversize(totalFieldCount, RamUsageEstimator.NUM_BYTES_OBJECT_REF)];\n        System.arraycopy(fields, 0, newFields, 0, fields.length);\n        fields = newFields;\n      }\n\n    } else if (invert && fp.invertState == null) {\n      initIndexOptions(fp.fieldInfo, fieldType.indexOptions());\n      fp.setInvertState();\n    }\n\n    return fp;\n  }\n\n","sourceOld":"  /** Returns a previously created {@link PerField},\n   *  absorbing the type information from {@link FieldType},\n   *  and creates a new {@link PerField} if this field name\n   *  wasn't seen yet. */\n  private PerField getOrAddField(String name, IndexableFieldType fieldType, boolean invert) {\n\n    // Make sure we have a PerField allocated\n    final int hashPos = name.hashCode() & hashMask;\n    PerField fp = fieldHash[hashPos];\n    while (fp != null && !fp.fieldInfo.name.equals(name)) {\n      fp = fp.next;\n    }\n\n    if (fp == null) {\n      // First time we are seeing this field in this segment\n\n      FieldInfo fi = fieldInfos.getOrAdd(name);\n      initIndexOptions(fi, fieldType.indexOptions());\n      Map<String, String> attributes = fieldType.getAttributes();\n      if (attributes != null) {\n        attributes.forEach((k, v) -> fi.putAttribute(k, v));\n      }\n\n      fp = new PerField(indexCreatedVersionMajor, fi, invert,\n          indexWriterConfig.getSimilarity(), indexWriterConfig.getInfoStream(), indexWriterConfig.getAnalyzer());\n      fp.next = fieldHash[hashPos];\n      fieldHash[hashPos] = fp;\n      totalFieldCount++;\n\n      // At most 50% load factor:\n      if (totalFieldCount >= fieldHash.length/2) {\n        rehash();\n      }\n\n      if (totalFieldCount > fields.length) {\n        PerField[] newFields = new PerField[ArrayUtil.oversize(totalFieldCount, RamUsageEstimator.NUM_BYTES_OBJECT_REF)];\n        System.arraycopy(fields, 0, newFields, 0, fields.length);\n        fields = newFields;\n      }\n\n    } else if (invert && fp.invertState == null) {\n      initIndexOptions(fp.fieldInfo, fieldType.indexOptions());\n      fp.setInvertState();\n    }\n\n    return fp;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"680b6449f09827f58fe987aff279e014c311d966":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","7a6f8af01d9b3067b143bbdc0a492720e2af97cf"],"7a6f8af01d9b3067b143bbdc0a492720e2af97cf":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["680b6449f09827f58fe987aff279e014c311d966"]},"commit2Childs":{"680b6449f09827f58fe987aff279e014c311d966":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"7a6f8af01d9b3067b143bbdc0a492720e2af97cf":["680b6449f09827f58fe987aff279e014c311d966"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["680b6449f09827f58fe987aff279e014c311d966","7a6f8af01d9b3067b143bbdc0a492720e2af97cf"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}