{"path":"src/java/org/apache/lucene/index/CheckIndex#check(Directory,boolean,List).mjava","commits":[{"id":"a64db7380e46c730a4ff0f00ebd7b29219312c14","date":1201253781,"type":0,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/CheckIndex#check(Directory,boolean,List).mjava","pathOld":"/dev/null","sourceNew":"  /** Returns true if index is clean, else false.*/\n  public static boolean check(Directory dir, boolean doFix, List onlySegments) throws IOException {\n    NumberFormat nf = NumberFormat.getInstance();\n    SegmentInfos sis = new SegmentInfos();\n    \n    try {\n      sis.read(dir);\n    } catch (Throwable t) {\n      out.println(\"ERROR: could not read any segments file in directory\");\n      t.printStackTrace(out);\n      return false;\n    }\n\n    final int numSegments = sis.size();\n    final String segmentsFileName = sis.getCurrentSegmentFileName();\n    IndexInput input = null;\n    try {\n      input = dir.openInput(segmentsFileName);\n    } catch (Throwable t) {\n      out.println(\"ERROR: could not open segments file in directory\");\n      t.printStackTrace(out);\n      return false;\n    }\n    int format = 0;\n    try {\n      format = input.readInt();\n    } catch (Throwable t) {\n      out.println(\"ERROR: could not read segment file version in directory\");\n      t.printStackTrace(out);\n      return false;\n    } finally {\n      if (input != null)\n        input.close();\n    }\n\n    String sFormat = \"\";\n    boolean skip = false;\n\n    if (format == SegmentInfos.FORMAT)\n      sFormat = \"FORMAT [Lucene Pre-2.1]\";\n    if (format == SegmentInfos.FORMAT_LOCKLESS)\n      sFormat = \"FORMAT_LOCKLESS [Lucene 2.1]\";\n    else if (format == SegmentInfos.FORMAT_SINGLE_NORM_FILE)\n      sFormat = \"FORMAT_SINGLE_NORM_FILE [Lucene 2.2]\";\n    else if (format == SegmentInfos.FORMAT_SHARED_DOC_STORE)\n      sFormat = \"FORMAT_SHARED_DOC_STORE [Lucene 2.3]\";\n    else if (format < SegmentInfos.FORMAT_SHARED_DOC_STORE) {\n      sFormat = \"int=\" + format + \" [newer version of Lucene than this tool]\";\n      skip = true;\n    } else {\n      sFormat = format + \" [Lucene 1.3 or prior]\";\n    }\n\n    out.println(\"Segments file=\" + segmentsFileName + \" numSegments=\" + numSegments + \" version=\" + sFormat);\n\n    if (onlySegments != null) {\n      out.print(\"\\nChecking only these segments:\");\n      Iterator it = onlySegments.iterator();\n      while (it.hasNext()) {\n        out.print(\" \" + it.next());\n      }\n      out.println(\":\");\n    }\n\n    if (skip) {\n      out.println(\"\\nERROR: this index appears to be created by a newer version of Lucene than this tool was compiled on; please re-compile this tool on the matching version of Lucene; exiting\");\n      return false;\n    }\n\n    SegmentInfos newSIS = (SegmentInfos) sis.clone();\n    newSIS.clear();\n    boolean changed = false;\n    int totLoseDocCount = 0;\n    int numBadSegments = 0;\n    for(int i=0;i<numSegments;i++) {\n      final SegmentInfo info = sis.info(i);\n      if (onlySegments != null && !onlySegments.contains(info.name))\n        continue;\n      out.println(\"  \" + (1+i) + \" of \" + numSegments + \": name=\" + info.name + \" docCount=\" + info.docCount);\n      int toLoseDocCount = info.docCount;\n\n      SegmentReader reader = null;\n\n      try {\n        out.println(\"    compound=\" + info.getUseCompoundFile());\n        out.println(\"    numFiles=\" + info.files().size());\n        out.println(\"    size (MB)=\" + nf.format(info.sizeInBytes()/(1024.*1024.)));\n        final int docStoreOffset = info.getDocStoreOffset();\n        if (docStoreOffset != -1) {\n          out.println(\"    docStoreOffset=\" + docStoreOffset);\n          out.println(\"    docStoreSegment=\" + info.getDocStoreSegment());\n          out.println(\"    docStoreIsCompoundFile=\" + info.getDocStoreIsCompoundFile());\n        }\n        final String delFileName = info.getDelFileName();\n        if (delFileName == null)\n          out.println(\"    no deletions\");\n        else\n          out.println(\"    has deletions [delFileName=\" + delFileName + \"]\");\n        out.print(\"    test: open reader.........\");\n        reader = SegmentReader.get(info);\n        final int numDocs = reader.numDocs();\n        toLoseDocCount = numDocs;\n        if (reader.hasDeletions())\n          out.println(\"OK [\" + (info.docCount - numDocs) + \" deleted docs]\");\n        else\n          out.println(\"OK\");\n\n        out.print(\"    test: fields, norms.......\");\n        Collection fieldNames = reader.getFieldNames(IndexReader.FieldOption.ALL);\n        Iterator it = fieldNames.iterator();\n        while(it.hasNext()) {\n          final String fieldName = (String) it.next();\n          byte[] b = reader.norms(fieldName);\n          if (b.length != info.docCount)\n            throw new RuntimeException(\"norms for field \\\"\" + fieldName + \"\\\" is length \" + b.length + \" != maxDoc \" + info.docCount);\n\n        }\n        out.println(\"OK [\" + fieldNames.size() + \" fields]\");\n\n        out.print(\"    test: terms, freq, prox...\");\n        final TermEnum termEnum = reader.terms();\n        final TermPositions termPositions = reader.termPositions();\n\n        // Used only to count up # deleted docs for this\n        // term\n        final MySegmentTermDocs myTermDocs = new MySegmentTermDocs(reader);\n\n        long termCount = 0;\n        long totFreq = 0;\n        long totPos = 0;\n        while(termEnum.next()) {\n          termCount++;\n          final Term term = termEnum.term();\n          final int docFreq = termEnum.docFreq();\n          termPositions.seek(term);\n          int lastDoc = -1;\n          int freq0 = 0;\n          totFreq += docFreq;\n          while(termPositions.next()) {\n            freq0++;\n            final int doc = termPositions.doc();\n            final int freq = termPositions.freq();\n            if (doc <= lastDoc)\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" < lastDoc \" + lastDoc);\n            lastDoc = doc;\n            if (freq <= 0)\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" is out of bounds\");\n            \n            int lastPos = -1;\n            totPos += freq;\n            for(int j=0;j<freq;j++) {\n              final int pos = termPositions.nextPosition();\n              if (pos < 0)\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" is out of bounds\");\n              if (pos <= lastPos)\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" < lastPos \" + lastPos);\n            }\n          }\n\n          // Now count how many deleted docs occurred in\n          // this term:\n          final int delCount;\n          if (reader.hasDeletions()) {\n            myTermDocs.seek(term);\n            while(myTermDocs.next()) {\n            }\n            delCount = myTermDocs.delCount;\n          } else\n            delCount = 0;\n\n          if (freq0 + delCount != docFreq)\n            throw new RuntimeException(\"term \" + term + \" docFreq=\" + docFreq + \" != num docs seen \" + freq0 + \" + num docs deleted \" + delCount);\n        }\n\n        out.println(\"OK [\" + termCount + \" terms; \" + totFreq + \" terms/docs pairs; \" + totPos + \" tokens]\");\n\n        out.print(\"    test: stored fields.......\");\n        int docCount = 0;\n        long totFields = 0;\n        for(int j=0;j<info.docCount;j++)\n          if (!reader.isDeleted(j)) {\n            docCount++;\n            Document doc = reader.document(j);\n            totFields += doc.getFields().size();\n          }\n\n        if (docCount != reader.numDocs())\n          throw new RuntimeException(\"docCount=\" + docCount + \" but saw \" + docCount + \" undeleted docs\");\n\n        out.println(\"OK [\" + totFields + \" total field count; avg \" + nf.format((((float) totFields)/docCount)) + \" fields per doc]\");\n\n        out.print(\"    test: term vectors........\");\n        int totVectors = 0;\n        for(int j=0;j<info.docCount;j++)\n          if (!reader.isDeleted(j)) {\n            TermFreqVector[] tfv = reader.getTermFreqVectors(j);\n            if (tfv != null)\n              totVectors += tfv.length;\n          }\n\n        out.println(\"OK [\" + totVectors + \" total vector count; avg \" + nf.format((((float) totVectors)/docCount)) + \" term/freq vector fields per doc]\");\n        out.println(\"\");\n\n      } catch (Throwable t) {\n        out.println(\"FAILED\");\n        String comment;\n        if (doFix)\n          comment = \"will remove reference to this segment (-fix is specified)\";\n        else\n          comment = \"would remove reference to this segment (-fix was not specified)\";\n        out.println(\"    WARNING: \" + comment + \"; full exception:\");\n        t.printStackTrace(out);\n        out.println(\"\");\n        totLoseDocCount += toLoseDocCount;\n        numBadSegments++;\n        changed = true;\n        continue;\n      } finally {\n        if (reader != null)\n          reader.close();\n      }\n\n      // Keeper\n      newSIS.add(info.clone());\n    }\n\n    if (!changed) {\n      out.println(\"No problems were detected with this index.\\n\");\n      return true;\n    } else {\n      out.println(\"WARNING: \" + numBadSegments + \" broken segments detected\");\n      if (doFix)\n        out.println(\"WARNING: \" + totLoseDocCount + \" documents will be lost\");\n      else\n        out.println(\"WARNING: \" + totLoseDocCount + \" documents would be lost if -fix were specified\");\n      out.println();\n    }\n\n    if (doFix) {\n      out.println(\"NOTE: will write new segments file in 5 seconds; this will remove \" + totLoseDocCount + \" docs from the index. THIS IS YOUR LAST CHANCE TO CTRL+C!\");\n      for(int i=0;i<5;i++) {\n        try {\n          Thread.sleep(1000);\n        } catch (InterruptedException ie) {\n          Thread.currentThread().interrupt();\n          i--;\n          continue;\n        }\n          \n        out.println(\"  \" + (5-i) + \"...\");\n      }\n      out.print(\"Writing...\");\n      try {\n        newSIS.write(dir);\n      } catch (Throwable t) {\n        out.println(\"FAILED; exiting\");\n        t.printStackTrace(out);\n        return false;\n      }\n      out.println(\"OK\");\n      out.println(\"Wrote new segments file \\\"\" + newSIS.getCurrentSegmentFileName() + \"\\\"\");\n    } else {\n      out.println(\"NOTE: would write new segments file [-fix was not specified]\");\n    }\n    out.println(\"\");\n\n    return false;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["7391c1f4ab1a6817de8a262f5c1b3de3cf190785"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"e82780afe6097066eb5befb86e9432f077667e3d","date":1202756169,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/CheckIndex#check(Directory,boolean,List).mjava","pathOld":"src/java/org/apache/lucene/index/CheckIndex#check(Directory,boolean,List).mjava","sourceNew":"  /** Returns true if index is clean, else false.*/\n  public static boolean check(Directory dir, boolean doFix, List onlySegments) throws IOException {\n    NumberFormat nf = NumberFormat.getInstance();\n    SegmentInfos sis = new SegmentInfos();\n    \n    try {\n      sis.read(dir);\n    } catch (Throwable t) {\n      out.println(\"ERROR: could not read any segments file in directory\");\n      t.printStackTrace(out);\n      return false;\n    }\n\n    final int numSegments = sis.size();\n    final String segmentsFileName = sis.getCurrentSegmentFileName();\n    IndexInput input = null;\n    try {\n      input = dir.openInput(segmentsFileName);\n    } catch (Throwable t) {\n      out.println(\"ERROR: could not open segments file in directory\");\n      t.printStackTrace(out);\n      return false;\n    }\n    int format = 0;\n    try {\n      format = input.readInt();\n    } catch (Throwable t) {\n      out.println(\"ERROR: could not read segment file version in directory\");\n      t.printStackTrace(out);\n      return false;\n    } finally {\n      if (input != null)\n        input.close();\n    }\n\n    String sFormat = \"\";\n    boolean skip = false;\n\n    if (format == SegmentInfos.FORMAT)\n      sFormat = \"FORMAT [Lucene Pre-2.1]\";\n    if (format == SegmentInfos.FORMAT_LOCKLESS)\n      sFormat = \"FORMAT_LOCKLESS [Lucene 2.1]\";\n    else if (format == SegmentInfos.FORMAT_SINGLE_NORM_FILE)\n      sFormat = \"FORMAT_SINGLE_NORM_FILE [Lucene 2.2]\";\n    else if (format == SegmentInfos.FORMAT_SHARED_DOC_STORE)\n      sFormat = \"FORMAT_SHARED_DOC_STORE [Lucene 2.3]\";\n    else if (format < SegmentInfos.FORMAT_CHECKSUM) {\n      sFormat = \"FORMAT_CHECKSUM [Lucene 2.4]\";\n      skip = true;\n    } else if (format < SegmentInfos.FORMAT_CHECKSUM) {\n      sFormat = \"int=\" + format + \" [newer version of Lucene than this tool]\";\n      skip = true;\n    } else {\n      sFormat = format + \" [Lucene 1.3 or prior]\";\n    }\n\n    out.println(\"Segments file=\" + segmentsFileName + \" numSegments=\" + numSegments + \" version=\" + sFormat);\n\n    if (onlySegments != null) {\n      out.print(\"\\nChecking only these segments:\");\n      Iterator it = onlySegments.iterator();\n      while (it.hasNext()) {\n        out.print(\" \" + it.next());\n      }\n      out.println(\":\");\n    }\n\n    if (skip) {\n      out.println(\"\\nERROR: this index appears to be created by a newer version of Lucene than this tool was compiled on; please re-compile this tool on the matching version of Lucene; exiting\");\n      return false;\n    }\n\n    SegmentInfos newSIS = (SegmentInfos) sis.clone();\n    newSIS.clear();\n    boolean changed = false;\n    int totLoseDocCount = 0;\n    int numBadSegments = 0;\n    for(int i=0;i<numSegments;i++) {\n      final SegmentInfo info = sis.info(i);\n      if (onlySegments != null && !onlySegments.contains(info.name))\n        continue;\n      out.println(\"  \" + (1+i) + \" of \" + numSegments + \": name=\" + info.name + \" docCount=\" + info.docCount);\n      int toLoseDocCount = info.docCount;\n\n      SegmentReader reader = null;\n\n      try {\n        out.println(\"    compound=\" + info.getUseCompoundFile());\n        out.println(\"    numFiles=\" + info.files().size());\n        out.println(\"    size (MB)=\" + nf.format(info.sizeInBytes()/(1024.*1024.)));\n        final int docStoreOffset = info.getDocStoreOffset();\n        if (docStoreOffset != -1) {\n          out.println(\"    docStoreOffset=\" + docStoreOffset);\n          out.println(\"    docStoreSegment=\" + info.getDocStoreSegment());\n          out.println(\"    docStoreIsCompoundFile=\" + info.getDocStoreIsCompoundFile());\n        }\n        final String delFileName = info.getDelFileName();\n        if (delFileName == null)\n          out.println(\"    no deletions\");\n        else\n          out.println(\"    has deletions [delFileName=\" + delFileName + \"]\");\n        out.print(\"    test: open reader.........\");\n        reader = SegmentReader.get(info);\n        final int numDocs = reader.numDocs();\n        toLoseDocCount = numDocs;\n        if (reader.hasDeletions())\n          out.println(\"OK [\" + (info.docCount - numDocs) + \" deleted docs]\");\n        else\n          out.println(\"OK\");\n\n        out.print(\"    test: fields, norms.......\");\n        Collection fieldNames = reader.getFieldNames(IndexReader.FieldOption.ALL);\n        Iterator it = fieldNames.iterator();\n        while(it.hasNext()) {\n          final String fieldName = (String) it.next();\n          byte[] b = reader.norms(fieldName);\n          if (b.length != info.docCount)\n            throw new RuntimeException(\"norms for field \\\"\" + fieldName + \"\\\" is length \" + b.length + \" != maxDoc \" + info.docCount);\n\n        }\n        out.println(\"OK [\" + fieldNames.size() + \" fields]\");\n\n        out.print(\"    test: terms, freq, prox...\");\n        final TermEnum termEnum = reader.terms();\n        final TermPositions termPositions = reader.termPositions();\n\n        // Used only to count up # deleted docs for this\n        // term\n        final MySegmentTermDocs myTermDocs = new MySegmentTermDocs(reader);\n\n        long termCount = 0;\n        long totFreq = 0;\n        long totPos = 0;\n        while(termEnum.next()) {\n          termCount++;\n          final Term term = termEnum.term();\n          final int docFreq = termEnum.docFreq();\n          termPositions.seek(term);\n          int lastDoc = -1;\n          int freq0 = 0;\n          totFreq += docFreq;\n          while(termPositions.next()) {\n            freq0++;\n            final int doc = termPositions.doc();\n            final int freq = termPositions.freq();\n            if (doc <= lastDoc)\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" < lastDoc \" + lastDoc);\n            lastDoc = doc;\n            if (freq <= 0)\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" is out of bounds\");\n            \n            int lastPos = -1;\n            totPos += freq;\n            for(int j=0;j<freq;j++) {\n              final int pos = termPositions.nextPosition();\n              if (pos < 0)\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" is out of bounds\");\n              if (pos <= lastPos)\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" < lastPos \" + lastPos);\n            }\n          }\n\n          // Now count how many deleted docs occurred in\n          // this term:\n          final int delCount;\n          if (reader.hasDeletions()) {\n            myTermDocs.seek(term);\n            while(myTermDocs.next()) {\n            }\n            delCount = myTermDocs.delCount;\n          } else\n            delCount = 0;\n\n          if (freq0 + delCount != docFreq)\n            throw new RuntimeException(\"term \" + term + \" docFreq=\" + docFreq + \" != num docs seen \" + freq0 + \" + num docs deleted \" + delCount);\n        }\n\n        out.println(\"OK [\" + termCount + \" terms; \" + totFreq + \" terms/docs pairs; \" + totPos + \" tokens]\");\n\n        out.print(\"    test: stored fields.......\");\n        int docCount = 0;\n        long totFields = 0;\n        for(int j=0;j<info.docCount;j++)\n          if (!reader.isDeleted(j)) {\n            docCount++;\n            Document doc = reader.document(j);\n            totFields += doc.getFields().size();\n          }\n\n        if (docCount != reader.numDocs())\n          throw new RuntimeException(\"docCount=\" + docCount + \" but saw \" + docCount + \" undeleted docs\");\n\n        out.println(\"OK [\" + totFields + \" total field count; avg \" + nf.format((((float) totFields)/docCount)) + \" fields per doc]\");\n\n        out.print(\"    test: term vectors........\");\n        int totVectors = 0;\n        for(int j=0;j<info.docCount;j++)\n          if (!reader.isDeleted(j)) {\n            TermFreqVector[] tfv = reader.getTermFreqVectors(j);\n            if (tfv != null)\n              totVectors += tfv.length;\n          }\n\n        out.println(\"OK [\" + totVectors + \" total vector count; avg \" + nf.format((((float) totVectors)/docCount)) + \" term/freq vector fields per doc]\");\n        out.println(\"\");\n\n      } catch (Throwable t) {\n        out.println(\"FAILED\");\n        String comment;\n        if (doFix)\n          comment = \"will remove reference to this segment (-fix is specified)\";\n        else\n          comment = \"would remove reference to this segment (-fix was not specified)\";\n        out.println(\"    WARNING: \" + comment + \"; full exception:\");\n        t.printStackTrace(out);\n        out.println(\"\");\n        totLoseDocCount += toLoseDocCount;\n        numBadSegments++;\n        changed = true;\n        continue;\n      } finally {\n        if (reader != null)\n          reader.close();\n      }\n\n      // Keeper\n      newSIS.add(info.clone());\n    }\n\n    if (!changed) {\n      out.println(\"No problems were detected with this index.\\n\");\n      return true;\n    } else {\n      out.println(\"WARNING: \" + numBadSegments + \" broken segments detected\");\n      if (doFix)\n        out.println(\"WARNING: \" + totLoseDocCount + \" documents will be lost\");\n      else\n        out.println(\"WARNING: \" + totLoseDocCount + \" documents would be lost if -fix were specified\");\n      out.println();\n    }\n\n    if (doFix) {\n      out.println(\"NOTE: will write new segments file in 5 seconds; this will remove \" + totLoseDocCount + \" docs from the index. THIS IS YOUR LAST CHANCE TO CTRL+C!\");\n      for(int i=0;i<5;i++) {\n        try {\n          Thread.sleep(1000);\n        } catch (InterruptedException ie) {\n          Thread.currentThread().interrupt();\n          i--;\n          continue;\n        }\n          \n        out.println(\"  \" + (5-i) + \"...\");\n      }\n      out.print(\"Writing...\");\n      try {\n        newSIS.commit(dir);\n      } catch (Throwable t) {\n        out.println(\"FAILED; exiting\");\n        t.printStackTrace(out);\n        return false;\n      }\n      out.println(\"OK\");\n      out.println(\"Wrote new segments file \\\"\" + newSIS.getCurrentSegmentFileName() + \"\\\"\");\n    } else {\n      out.println(\"NOTE: would write new segments file [-fix was not specified]\");\n    }\n    out.println(\"\");\n\n    return false;\n  }\n\n","sourceOld":"  /** Returns true if index is clean, else false.*/\n  public static boolean check(Directory dir, boolean doFix, List onlySegments) throws IOException {\n    NumberFormat nf = NumberFormat.getInstance();\n    SegmentInfos sis = new SegmentInfos();\n    \n    try {\n      sis.read(dir);\n    } catch (Throwable t) {\n      out.println(\"ERROR: could not read any segments file in directory\");\n      t.printStackTrace(out);\n      return false;\n    }\n\n    final int numSegments = sis.size();\n    final String segmentsFileName = sis.getCurrentSegmentFileName();\n    IndexInput input = null;\n    try {\n      input = dir.openInput(segmentsFileName);\n    } catch (Throwable t) {\n      out.println(\"ERROR: could not open segments file in directory\");\n      t.printStackTrace(out);\n      return false;\n    }\n    int format = 0;\n    try {\n      format = input.readInt();\n    } catch (Throwable t) {\n      out.println(\"ERROR: could not read segment file version in directory\");\n      t.printStackTrace(out);\n      return false;\n    } finally {\n      if (input != null)\n        input.close();\n    }\n\n    String sFormat = \"\";\n    boolean skip = false;\n\n    if (format == SegmentInfos.FORMAT)\n      sFormat = \"FORMAT [Lucene Pre-2.1]\";\n    if (format == SegmentInfos.FORMAT_LOCKLESS)\n      sFormat = \"FORMAT_LOCKLESS [Lucene 2.1]\";\n    else if (format == SegmentInfos.FORMAT_SINGLE_NORM_FILE)\n      sFormat = \"FORMAT_SINGLE_NORM_FILE [Lucene 2.2]\";\n    else if (format == SegmentInfos.FORMAT_SHARED_DOC_STORE)\n      sFormat = \"FORMAT_SHARED_DOC_STORE [Lucene 2.3]\";\n    else if (format < SegmentInfos.FORMAT_SHARED_DOC_STORE) {\n      sFormat = \"int=\" + format + \" [newer version of Lucene than this tool]\";\n      skip = true;\n    } else {\n      sFormat = format + \" [Lucene 1.3 or prior]\";\n    }\n\n    out.println(\"Segments file=\" + segmentsFileName + \" numSegments=\" + numSegments + \" version=\" + sFormat);\n\n    if (onlySegments != null) {\n      out.print(\"\\nChecking only these segments:\");\n      Iterator it = onlySegments.iterator();\n      while (it.hasNext()) {\n        out.print(\" \" + it.next());\n      }\n      out.println(\":\");\n    }\n\n    if (skip) {\n      out.println(\"\\nERROR: this index appears to be created by a newer version of Lucene than this tool was compiled on; please re-compile this tool on the matching version of Lucene; exiting\");\n      return false;\n    }\n\n    SegmentInfos newSIS = (SegmentInfos) sis.clone();\n    newSIS.clear();\n    boolean changed = false;\n    int totLoseDocCount = 0;\n    int numBadSegments = 0;\n    for(int i=0;i<numSegments;i++) {\n      final SegmentInfo info = sis.info(i);\n      if (onlySegments != null && !onlySegments.contains(info.name))\n        continue;\n      out.println(\"  \" + (1+i) + \" of \" + numSegments + \": name=\" + info.name + \" docCount=\" + info.docCount);\n      int toLoseDocCount = info.docCount;\n\n      SegmentReader reader = null;\n\n      try {\n        out.println(\"    compound=\" + info.getUseCompoundFile());\n        out.println(\"    numFiles=\" + info.files().size());\n        out.println(\"    size (MB)=\" + nf.format(info.sizeInBytes()/(1024.*1024.)));\n        final int docStoreOffset = info.getDocStoreOffset();\n        if (docStoreOffset != -1) {\n          out.println(\"    docStoreOffset=\" + docStoreOffset);\n          out.println(\"    docStoreSegment=\" + info.getDocStoreSegment());\n          out.println(\"    docStoreIsCompoundFile=\" + info.getDocStoreIsCompoundFile());\n        }\n        final String delFileName = info.getDelFileName();\n        if (delFileName == null)\n          out.println(\"    no deletions\");\n        else\n          out.println(\"    has deletions [delFileName=\" + delFileName + \"]\");\n        out.print(\"    test: open reader.........\");\n        reader = SegmentReader.get(info);\n        final int numDocs = reader.numDocs();\n        toLoseDocCount = numDocs;\n        if (reader.hasDeletions())\n          out.println(\"OK [\" + (info.docCount - numDocs) + \" deleted docs]\");\n        else\n          out.println(\"OK\");\n\n        out.print(\"    test: fields, norms.......\");\n        Collection fieldNames = reader.getFieldNames(IndexReader.FieldOption.ALL);\n        Iterator it = fieldNames.iterator();\n        while(it.hasNext()) {\n          final String fieldName = (String) it.next();\n          byte[] b = reader.norms(fieldName);\n          if (b.length != info.docCount)\n            throw new RuntimeException(\"norms for field \\\"\" + fieldName + \"\\\" is length \" + b.length + \" != maxDoc \" + info.docCount);\n\n        }\n        out.println(\"OK [\" + fieldNames.size() + \" fields]\");\n\n        out.print(\"    test: terms, freq, prox...\");\n        final TermEnum termEnum = reader.terms();\n        final TermPositions termPositions = reader.termPositions();\n\n        // Used only to count up # deleted docs for this\n        // term\n        final MySegmentTermDocs myTermDocs = new MySegmentTermDocs(reader);\n\n        long termCount = 0;\n        long totFreq = 0;\n        long totPos = 0;\n        while(termEnum.next()) {\n          termCount++;\n          final Term term = termEnum.term();\n          final int docFreq = termEnum.docFreq();\n          termPositions.seek(term);\n          int lastDoc = -1;\n          int freq0 = 0;\n          totFreq += docFreq;\n          while(termPositions.next()) {\n            freq0++;\n            final int doc = termPositions.doc();\n            final int freq = termPositions.freq();\n            if (doc <= lastDoc)\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" < lastDoc \" + lastDoc);\n            lastDoc = doc;\n            if (freq <= 0)\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" is out of bounds\");\n            \n            int lastPos = -1;\n            totPos += freq;\n            for(int j=0;j<freq;j++) {\n              final int pos = termPositions.nextPosition();\n              if (pos < 0)\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" is out of bounds\");\n              if (pos <= lastPos)\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" < lastPos \" + lastPos);\n            }\n          }\n\n          // Now count how many deleted docs occurred in\n          // this term:\n          final int delCount;\n          if (reader.hasDeletions()) {\n            myTermDocs.seek(term);\n            while(myTermDocs.next()) {\n            }\n            delCount = myTermDocs.delCount;\n          } else\n            delCount = 0;\n\n          if (freq0 + delCount != docFreq)\n            throw new RuntimeException(\"term \" + term + \" docFreq=\" + docFreq + \" != num docs seen \" + freq0 + \" + num docs deleted \" + delCount);\n        }\n\n        out.println(\"OK [\" + termCount + \" terms; \" + totFreq + \" terms/docs pairs; \" + totPos + \" tokens]\");\n\n        out.print(\"    test: stored fields.......\");\n        int docCount = 0;\n        long totFields = 0;\n        for(int j=0;j<info.docCount;j++)\n          if (!reader.isDeleted(j)) {\n            docCount++;\n            Document doc = reader.document(j);\n            totFields += doc.getFields().size();\n          }\n\n        if (docCount != reader.numDocs())\n          throw new RuntimeException(\"docCount=\" + docCount + \" but saw \" + docCount + \" undeleted docs\");\n\n        out.println(\"OK [\" + totFields + \" total field count; avg \" + nf.format((((float) totFields)/docCount)) + \" fields per doc]\");\n\n        out.print(\"    test: term vectors........\");\n        int totVectors = 0;\n        for(int j=0;j<info.docCount;j++)\n          if (!reader.isDeleted(j)) {\n            TermFreqVector[] tfv = reader.getTermFreqVectors(j);\n            if (tfv != null)\n              totVectors += tfv.length;\n          }\n\n        out.println(\"OK [\" + totVectors + \" total vector count; avg \" + nf.format((((float) totVectors)/docCount)) + \" term/freq vector fields per doc]\");\n        out.println(\"\");\n\n      } catch (Throwable t) {\n        out.println(\"FAILED\");\n        String comment;\n        if (doFix)\n          comment = \"will remove reference to this segment (-fix is specified)\";\n        else\n          comment = \"would remove reference to this segment (-fix was not specified)\";\n        out.println(\"    WARNING: \" + comment + \"; full exception:\");\n        t.printStackTrace(out);\n        out.println(\"\");\n        totLoseDocCount += toLoseDocCount;\n        numBadSegments++;\n        changed = true;\n        continue;\n      } finally {\n        if (reader != null)\n          reader.close();\n      }\n\n      // Keeper\n      newSIS.add(info.clone());\n    }\n\n    if (!changed) {\n      out.println(\"No problems were detected with this index.\\n\");\n      return true;\n    } else {\n      out.println(\"WARNING: \" + numBadSegments + \" broken segments detected\");\n      if (doFix)\n        out.println(\"WARNING: \" + totLoseDocCount + \" documents will be lost\");\n      else\n        out.println(\"WARNING: \" + totLoseDocCount + \" documents would be lost if -fix were specified\");\n      out.println();\n    }\n\n    if (doFix) {\n      out.println(\"NOTE: will write new segments file in 5 seconds; this will remove \" + totLoseDocCount + \" docs from the index. THIS IS YOUR LAST CHANCE TO CTRL+C!\");\n      for(int i=0;i<5;i++) {\n        try {\n          Thread.sleep(1000);\n        } catch (InterruptedException ie) {\n          Thread.currentThread().interrupt();\n          i--;\n          continue;\n        }\n          \n        out.println(\"  \" + (5-i) + \"...\");\n      }\n      out.print(\"Writing...\");\n      try {\n        newSIS.write(dir);\n      } catch (Throwable t) {\n        out.println(\"FAILED; exiting\");\n        t.printStackTrace(out);\n        return false;\n      }\n      out.println(\"OK\");\n      out.println(\"Wrote new segments file \\\"\" + newSIS.getCurrentSegmentFileName() + \"\\\"\");\n    } else {\n      out.println(\"NOTE: would write new segments file [-fix was not specified]\");\n    }\n    out.println(\"\");\n\n    return false;\n  }\n\n","bugFix":null,"bugIntro":["e99bed41006619061fcbe6431544a7eeeee2d9f1"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"e99bed41006619061fcbe6431544a7eeeee2d9f1","date":1202893474,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/CheckIndex#check(Directory,boolean,List).mjava","pathOld":"src/java/org/apache/lucene/index/CheckIndex#check(Directory,boolean,List).mjava","sourceNew":"  /** Returns true if index is clean, else false.*/\n  public static boolean check(Directory dir, boolean doFix, List onlySegments) throws IOException {\n    NumberFormat nf = NumberFormat.getInstance();\n    SegmentInfos sis = new SegmentInfos();\n    \n    try {\n      sis.read(dir);\n    } catch (Throwable t) {\n      out.println(\"ERROR: could not read any segments file in directory\");\n      t.printStackTrace(out);\n      return false;\n    }\n\n    final int numSegments = sis.size();\n    final String segmentsFileName = sis.getCurrentSegmentFileName();\n    IndexInput input = null;\n    try {\n      input = dir.openInput(segmentsFileName);\n    } catch (Throwable t) {\n      out.println(\"ERROR: could not open segments file in directory\");\n      t.printStackTrace(out);\n      return false;\n    }\n    int format = 0;\n    try {\n      format = input.readInt();\n    } catch (Throwable t) {\n      out.println(\"ERROR: could not read segment file version in directory\");\n      t.printStackTrace(out);\n      return false;\n    } finally {\n      if (input != null)\n        input.close();\n    }\n\n    String sFormat = \"\";\n    boolean skip = false;\n\n    if (format == SegmentInfos.FORMAT)\n      sFormat = \"FORMAT [Lucene Pre-2.1]\";\n    if (format == SegmentInfos.FORMAT_LOCKLESS)\n      sFormat = \"FORMAT_LOCKLESS [Lucene 2.1]\";\n    else if (format == SegmentInfos.FORMAT_SINGLE_NORM_FILE)\n      sFormat = \"FORMAT_SINGLE_NORM_FILE [Lucene 2.2]\";\n    else if (format == SegmentInfos.FORMAT_SHARED_DOC_STORE)\n      sFormat = \"FORMAT_SHARED_DOC_STORE [Lucene 2.3]\";\n    else if (format == SegmentInfos.FORMAT_CHECKSUM) {\n      sFormat = \"FORMAT_CHECKSUM [Lucene 2.4]\";\n    } else if (format < SegmentInfos.FORMAT_CHECKSUM) {\n      sFormat = \"int=\" + format + \" [newer version of Lucene than this tool]\";\n      skip = true;\n    } else {\n      sFormat = format + \" [Lucene 1.3 or prior]\";\n    }\n\n    out.println(\"Segments file=\" + segmentsFileName + \" numSegments=\" + numSegments + \" version=\" + sFormat);\n\n    if (onlySegments != null) {\n      out.print(\"\\nChecking only these segments:\");\n      Iterator it = onlySegments.iterator();\n      while (it.hasNext()) {\n        out.print(\" \" + it.next());\n      }\n      out.println(\":\");\n    }\n\n    if (skip) {\n      out.println(\"\\nERROR: this index appears to be created by a newer version of Lucene than this tool was compiled on; please re-compile this tool on the matching version of Lucene; exiting\");\n      return false;\n    }\n\n    SegmentInfos newSIS = (SegmentInfos) sis.clone();\n    newSIS.clear();\n    boolean changed = false;\n    int totLoseDocCount = 0;\n    int numBadSegments = 0;\n    for(int i=0;i<numSegments;i++) {\n      final SegmentInfo info = sis.info(i);\n      if (onlySegments != null && !onlySegments.contains(info.name))\n        continue;\n      out.println(\"  \" + (1+i) + \" of \" + numSegments + \": name=\" + info.name + \" docCount=\" + info.docCount);\n      int toLoseDocCount = info.docCount;\n\n      SegmentReader reader = null;\n\n      try {\n        out.println(\"    compound=\" + info.getUseCompoundFile());\n        out.println(\"    numFiles=\" + info.files().size());\n        out.println(\"    size (MB)=\" + nf.format(info.sizeInBytes()/(1024.*1024.)));\n        final int docStoreOffset = info.getDocStoreOffset();\n        if (docStoreOffset != -1) {\n          out.println(\"    docStoreOffset=\" + docStoreOffset);\n          out.println(\"    docStoreSegment=\" + info.getDocStoreSegment());\n          out.println(\"    docStoreIsCompoundFile=\" + info.getDocStoreIsCompoundFile());\n        }\n        final String delFileName = info.getDelFileName();\n        if (delFileName == null)\n          out.println(\"    no deletions\");\n        else\n          out.println(\"    has deletions [delFileName=\" + delFileName + \"]\");\n        out.print(\"    test: open reader.........\");\n        reader = SegmentReader.get(info);\n        final int numDocs = reader.numDocs();\n        toLoseDocCount = numDocs;\n        if (reader.hasDeletions())\n          out.println(\"OK [\" + (info.docCount - numDocs) + \" deleted docs]\");\n        else\n          out.println(\"OK\");\n\n        out.print(\"    test: fields, norms.......\");\n        Collection fieldNames = reader.getFieldNames(IndexReader.FieldOption.ALL);\n        Iterator it = fieldNames.iterator();\n        while(it.hasNext()) {\n          final String fieldName = (String) it.next();\n          byte[] b = reader.norms(fieldName);\n          if (b.length != info.docCount)\n            throw new RuntimeException(\"norms for field \\\"\" + fieldName + \"\\\" is length \" + b.length + \" != maxDoc \" + info.docCount);\n\n        }\n        out.println(\"OK [\" + fieldNames.size() + \" fields]\");\n\n        out.print(\"    test: terms, freq, prox...\");\n        final TermEnum termEnum = reader.terms();\n        final TermPositions termPositions = reader.termPositions();\n\n        // Used only to count up # deleted docs for this\n        // term\n        final MySegmentTermDocs myTermDocs = new MySegmentTermDocs(reader);\n\n        long termCount = 0;\n        long totFreq = 0;\n        long totPos = 0;\n        while(termEnum.next()) {\n          termCount++;\n          final Term term = termEnum.term();\n          final int docFreq = termEnum.docFreq();\n          termPositions.seek(term);\n          int lastDoc = -1;\n          int freq0 = 0;\n          totFreq += docFreq;\n          while(termPositions.next()) {\n            freq0++;\n            final int doc = termPositions.doc();\n            final int freq = termPositions.freq();\n            if (doc <= lastDoc)\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" < lastDoc \" + lastDoc);\n            lastDoc = doc;\n            if (freq <= 0)\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" is out of bounds\");\n            \n            int lastPos = -1;\n            totPos += freq;\n            for(int j=0;j<freq;j++) {\n              final int pos = termPositions.nextPosition();\n              if (pos < 0)\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" is out of bounds\");\n              if (pos <= lastPos)\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" < lastPos \" + lastPos);\n            }\n          }\n\n          // Now count how many deleted docs occurred in\n          // this term:\n          final int delCount;\n          if (reader.hasDeletions()) {\n            myTermDocs.seek(term);\n            while(myTermDocs.next()) {\n            }\n            delCount = myTermDocs.delCount;\n          } else\n            delCount = 0;\n\n          if (freq0 + delCount != docFreq)\n            throw new RuntimeException(\"term \" + term + \" docFreq=\" + docFreq + \" != num docs seen \" + freq0 + \" + num docs deleted \" + delCount);\n        }\n\n        out.println(\"OK [\" + termCount + \" terms; \" + totFreq + \" terms/docs pairs; \" + totPos + \" tokens]\");\n\n        out.print(\"    test: stored fields.......\");\n        int docCount = 0;\n        long totFields = 0;\n        for(int j=0;j<info.docCount;j++)\n          if (!reader.isDeleted(j)) {\n            docCount++;\n            Document doc = reader.document(j);\n            totFields += doc.getFields().size();\n          }\n\n        if (docCount != reader.numDocs())\n          throw new RuntimeException(\"docCount=\" + docCount + \" but saw \" + docCount + \" undeleted docs\");\n\n        out.println(\"OK [\" + totFields + \" total field count; avg \" + nf.format((((float) totFields)/docCount)) + \" fields per doc]\");\n\n        out.print(\"    test: term vectors........\");\n        int totVectors = 0;\n        for(int j=0;j<info.docCount;j++)\n          if (!reader.isDeleted(j)) {\n            TermFreqVector[] tfv = reader.getTermFreqVectors(j);\n            if (tfv != null)\n              totVectors += tfv.length;\n          }\n\n        out.println(\"OK [\" + totVectors + \" total vector count; avg \" + nf.format((((float) totVectors)/docCount)) + \" term/freq vector fields per doc]\");\n        out.println(\"\");\n\n      } catch (Throwable t) {\n        out.println(\"FAILED\");\n        String comment;\n        if (doFix)\n          comment = \"will remove reference to this segment (-fix is specified)\";\n        else\n          comment = \"would remove reference to this segment (-fix was not specified)\";\n        out.println(\"    WARNING: \" + comment + \"; full exception:\");\n        t.printStackTrace(out);\n        out.println(\"\");\n        totLoseDocCount += toLoseDocCount;\n        numBadSegments++;\n        changed = true;\n        continue;\n      } finally {\n        if (reader != null)\n          reader.close();\n      }\n\n      // Keeper\n      newSIS.add(info.clone());\n    }\n\n    if (!changed) {\n      out.println(\"No problems were detected with this index.\\n\");\n      return true;\n    } else {\n      out.println(\"WARNING: \" + numBadSegments + \" broken segments detected\");\n      if (doFix)\n        out.println(\"WARNING: \" + totLoseDocCount + \" documents will be lost\");\n      else\n        out.println(\"WARNING: \" + totLoseDocCount + \" documents would be lost if -fix were specified\");\n      out.println();\n    }\n\n    if (doFix) {\n      out.println(\"NOTE: will write new segments file in 5 seconds; this will remove \" + totLoseDocCount + \" docs from the index. THIS IS YOUR LAST CHANCE TO CTRL+C!\");\n      for(int i=0;i<5;i++) {\n        try {\n          Thread.sleep(1000);\n        } catch (InterruptedException ie) {\n          Thread.currentThread().interrupt();\n          i--;\n          continue;\n        }\n          \n        out.println(\"  \" + (5-i) + \"...\");\n      }\n      out.print(\"Writing...\");\n      try {\n        newSIS.commit(dir);\n      } catch (Throwable t) {\n        out.println(\"FAILED; exiting\");\n        t.printStackTrace(out);\n        return false;\n      }\n      out.println(\"OK\");\n      out.println(\"Wrote new segments file \\\"\" + newSIS.getCurrentSegmentFileName() + \"\\\"\");\n    } else {\n      out.println(\"NOTE: would write new segments file [-fix was not specified]\");\n    }\n    out.println(\"\");\n\n    return false;\n  }\n\n","sourceOld":"  /** Returns true if index is clean, else false.*/\n  public static boolean check(Directory dir, boolean doFix, List onlySegments) throws IOException {\n    NumberFormat nf = NumberFormat.getInstance();\n    SegmentInfos sis = new SegmentInfos();\n    \n    try {\n      sis.read(dir);\n    } catch (Throwable t) {\n      out.println(\"ERROR: could not read any segments file in directory\");\n      t.printStackTrace(out);\n      return false;\n    }\n\n    final int numSegments = sis.size();\n    final String segmentsFileName = sis.getCurrentSegmentFileName();\n    IndexInput input = null;\n    try {\n      input = dir.openInput(segmentsFileName);\n    } catch (Throwable t) {\n      out.println(\"ERROR: could not open segments file in directory\");\n      t.printStackTrace(out);\n      return false;\n    }\n    int format = 0;\n    try {\n      format = input.readInt();\n    } catch (Throwable t) {\n      out.println(\"ERROR: could not read segment file version in directory\");\n      t.printStackTrace(out);\n      return false;\n    } finally {\n      if (input != null)\n        input.close();\n    }\n\n    String sFormat = \"\";\n    boolean skip = false;\n\n    if (format == SegmentInfos.FORMAT)\n      sFormat = \"FORMAT [Lucene Pre-2.1]\";\n    if (format == SegmentInfos.FORMAT_LOCKLESS)\n      sFormat = \"FORMAT_LOCKLESS [Lucene 2.1]\";\n    else if (format == SegmentInfos.FORMAT_SINGLE_NORM_FILE)\n      sFormat = \"FORMAT_SINGLE_NORM_FILE [Lucene 2.2]\";\n    else if (format == SegmentInfos.FORMAT_SHARED_DOC_STORE)\n      sFormat = \"FORMAT_SHARED_DOC_STORE [Lucene 2.3]\";\n    else if (format < SegmentInfos.FORMAT_CHECKSUM) {\n      sFormat = \"FORMAT_CHECKSUM [Lucene 2.4]\";\n      skip = true;\n    } else if (format < SegmentInfos.FORMAT_CHECKSUM) {\n      sFormat = \"int=\" + format + \" [newer version of Lucene than this tool]\";\n      skip = true;\n    } else {\n      sFormat = format + \" [Lucene 1.3 or prior]\";\n    }\n\n    out.println(\"Segments file=\" + segmentsFileName + \" numSegments=\" + numSegments + \" version=\" + sFormat);\n\n    if (onlySegments != null) {\n      out.print(\"\\nChecking only these segments:\");\n      Iterator it = onlySegments.iterator();\n      while (it.hasNext()) {\n        out.print(\" \" + it.next());\n      }\n      out.println(\":\");\n    }\n\n    if (skip) {\n      out.println(\"\\nERROR: this index appears to be created by a newer version of Lucene than this tool was compiled on; please re-compile this tool on the matching version of Lucene; exiting\");\n      return false;\n    }\n\n    SegmentInfos newSIS = (SegmentInfos) sis.clone();\n    newSIS.clear();\n    boolean changed = false;\n    int totLoseDocCount = 0;\n    int numBadSegments = 0;\n    for(int i=0;i<numSegments;i++) {\n      final SegmentInfo info = sis.info(i);\n      if (onlySegments != null && !onlySegments.contains(info.name))\n        continue;\n      out.println(\"  \" + (1+i) + \" of \" + numSegments + \": name=\" + info.name + \" docCount=\" + info.docCount);\n      int toLoseDocCount = info.docCount;\n\n      SegmentReader reader = null;\n\n      try {\n        out.println(\"    compound=\" + info.getUseCompoundFile());\n        out.println(\"    numFiles=\" + info.files().size());\n        out.println(\"    size (MB)=\" + nf.format(info.sizeInBytes()/(1024.*1024.)));\n        final int docStoreOffset = info.getDocStoreOffset();\n        if (docStoreOffset != -1) {\n          out.println(\"    docStoreOffset=\" + docStoreOffset);\n          out.println(\"    docStoreSegment=\" + info.getDocStoreSegment());\n          out.println(\"    docStoreIsCompoundFile=\" + info.getDocStoreIsCompoundFile());\n        }\n        final String delFileName = info.getDelFileName();\n        if (delFileName == null)\n          out.println(\"    no deletions\");\n        else\n          out.println(\"    has deletions [delFileName=\" + delFileName + \"]\");\n        out.print(\"    test: open reader.........\");\n        reader = SegmentReader.get(info);\n        final int numDocs = reader.numDocs();\n        toLoseDocCount = numDocs;\n        if (reader.hasDeletions())\n          out.println(\"OK [\" + (info.docCount - numDocs) + \" deleted docs]\");\n        else\n          out.println(\"OK\");\n\n        out.print(\"    test: fields, norms.......\");\n        Collection fieldNames = reader.getFieldNames(IndexReader.FieldOption.ALL);\n        Iterator it = fieldNames.iterator();\n        while(it.hasNext()) {\n          final String fieldName = (String) it.next();\n          byte[] b = reader.norms(fieldName);\n          if (b.length != info.docCount)\n            throw new RuntimeException(\"norms for field \\\"\" + fieldName + \"\\\" is length \" + b.length + \" != maxDoc \" + info.docCount);\n\n        }\n        out.println(\"OK [\" + fieldNames.size() + \" fields]\");\n\n        out.print(\"    test: terms, freq, prox...\");\n        final TermEnum termEnum = reader.terms();\n        final TermPositions termPositions = reader.termPositions();\n\n        // Used only to count up # deleted docs for this\n        // term\n        final MySegmentTermDocs myTermDocs = new MySegmentTermDocs(reader);\n\n        long termCount = 0;\n        long totFreq = 0;\n        long totPos = 0;\n        while(termEnum.next()) {\n          termCount++;\n          final Term term = termEnum.term();\n          final int docFreq = termEnum.docFreq();\n          termPositions.seek(term);\n          int lastDoc = -1;\n          int freq0 = 0;\n          totFreq += docFreq;\n          while(termPositions.next()) {\n            freq0++;\n            final int doc = termPositions.doc();\n            final int freq = termPositions.freq();\n            if (doc <= lastDoc)\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" < lastDoc \" + lastDoc);\n            lastDoc = doc;\n            if (freq <= 0)\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" is out of bounds\");\n            \n            int lastPos = -1;\n            totPos += freq;\n            for(int j=0;j<freq;j++) {\n              final int pos = termPositions.nextPosition();\n              if (pos < 0)\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" is out of bounds\");\n              if (pos <= lastPos)\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" < lastPos \" + lastPos);\n            }\n          }\n\n          // Now count how many deleted docs occurred in\n          // this term:\n          final int delCount;\n          if (reader.hasDeletions()) {\n            myTermDocs.seek(term);\n            while(myTermDocs.next()) {\n            }\n            delCount = myTermDocs.delCount;\n          } else\n            delCount = 0;\n\n          if (freq0 + delCount != docFreq)\n            throw new RuntimeException(\"term \" + term + \" docFreq=\" + docFreq + \" != num docs seen \" + freq0 + \" + num docs deleted \" + delCount);\n        }\n\n        out.println(\"OK [\" + termCount + \" terms; \" + totFreq + \" terms/docs pairs; \" + totPos + \" tokens]\");\n\n        out.print(\"    test: stored fields.......\");\n        int docCount = 0;\n        long totFields = 0;\n        for(int j=0;j<info.docCount;j++)\n          if (!reader.isDeleted(j)) {\n            docCount++;\n            Document doc = reader.document(j);\n            totFields += doc.getFields().size();\n          }\n\n        if (docCount != reader.numDocs())\n          throw new RuntimeException(\"docCount=\" + docCount + \" but saw \" + docCount + \" undeleted docs\");\n\n        out.println(\"OK [\" + totFields + \" total field count; avg \" + nf.format((((float) totFields)/docCount)) + \" fields per doc]\");\n\n        out.print(\"    test: term vectors........\");\n        int totVectors = 0;\n        for(int j=0;j<info.docCount;j++)\n          if (!reader.isDeleted(j)) {\n            TermFreqVector[] tfv = reader.getTermFreqVectors(j);\n            if (tfv != null)\n              totVectors += tfv.length;\n          }\n\n        out.println(\"OK [\" + totVectors + \" total vector count; avg \" + nf.format((((float) totVectors)/docCount)) + \" term/freq vector fields per doc]\");\n        out.println(\"\");\n\n      } catch (Throwable t) {\n        out.println(\"FAILED\");\n        String comment;\n        if (doFix)\n          comment = \"will remove reference to this segment (-fix is specified)\";\n        else\n          comment = \"would remove reference to this segment (-fix was not specified)\";\n        out.println(\"    WARNING: \" + comment + \"; full exception:\");\n        t.printStackTrace(out);\n        out.println(\"\");\n        totLoseDocCount += toLoseDocCount;\n        numBadSegments++;\n        changed = true;\n        continue;\n      } finally {\n        if (reader != null)\n          reader.close();\n      }\n\n      // Keeper\n      newSIS.add(info.clone());\n    }\n\n    if (!changed) {\n      out.println(\"No problems were detected with this index.\\n\");\n      return true;\n    } else {\n      out.println(\"WARNING: \" + numBadSegments + \" broken segments detected\");\n      if (doFix)\n        out.println(\"WARNING: \" + totLoseDocCount + \" documents will be lost\");\n      else\n        out.println(\"WARNING: \" + totLoseDocCount + \" documents would be lost if -fix were specified\");\n      out.println();\n    }\n\n    if (doFix) {\n      out.println(\"NOTE: will write new segments file in 5 seconds; this will remove \" + totLoseDocCount + \" docs from the index. THIS IS YOUR LAST CHANCE TO CTRL+C!\");\n      for(int i=0;i<5;i++) {\n        try {\n          Thread.sleep(1000);\n        } catch (InterruptedException ie) {\n          Thread.currentThread().interrupt();\n          i--;\n          continue;\n        }\n          \n        out.println(\"  \" + (5-i) + \"...\");\n      }\n      out.print(\"Writing...\");\n      try {\n        newSIS.commit(dir);\n      } catch (Throwable t) {\n        out.println(\"FAILED; exiting\");\n        t.printStackTrace(out);\n        return false;\n      }\n      out.println(\"OK\");\n      out.println(\"Wrote new segments file \\\"\" + newSIS.getCurrentSegmentFileName() + \"\\\"\");\n    } else {\n      out.println(\"NOTE: would write new segments file [-fix was not specified]\");\n    }\n    out.println(\"\");\n\n    return false;\n  }\n\n","bugFix":["e82780afe6097066eb5befb86e9432f077667e3d"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"f51cb06175d6fae01dc608dd7ab884973354e4bf","date":1207240926,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/CheckIndex#check(Directory,boolean,List).mjava","pathOld":"src/java/org/apache/lucene/index/CheckIndex#check(Directory,boolean,List).mjava","sourceNew":"  /** Returns true if index is clean, else false.*/\n  public static boolean check(Directory dir, boolean doFix, List onlySegments) throws IOException {\n    NumberFormat nf = NumberFormat.getInstance();\n    SegmentInfos sis = new SegmentInfos();\n    \n    try {\n      sis.read(dir);\n    } catch (Throwable t) {\n      out.println(\"ERROR: could not read any segments file in directory\");\n      t.printStackTrace(out);\n      return false;\n    }\n\n    final int numSegments = sis.size();\n    final String segmentsFileName = sis.getCurrentSegmentFileName();\n    IndexInput input = null;\n    try {\n      input = dir.openInput(segmentsFileName);\n    } catch (Throwable t) {\n      out.println(\"ERROR: could not open segments file in directory\");\n      t.printStackTrace(out);\n      return false;\n    }\n    int format = 0;\n    try {\n      format = input.readInt();\n    } catch (Throwable t) {\n      out.println(\"ERROR: could not read segment file version in directory\");\n      t.printStackTrace(out);\n      return false;\n    } finally {\n      if (input != null)\n        input.close();\n    }\n\n    String sFormat = \"\";\n    boolean skip = false;\n\n    if (format == SegmentInfos.FORMAT)\n      sFormat = \"FORMAT [Lucene Pre-2.1]\";\n    if (format == SegmentInfos.FORMAT_LOCKLESS)\n      sFormat = \"FORMAT_LOCKLESS [Lucene 2.1]\";\n    else if (format == SegmentInfos.FORMAT_SINGLE_NORM_FILE)\n      sFormat = \"FORMAT_SINGLE_NORM_FILE [Lucene 2.2]\";\n    else if (format == SegmentInfos.FORMAT_SHARED_DOC_STORE)\n      sFormat = \"FORMAT_SHARED_DOC_STORE [Lucene 2.3]\";\n    else if (format == SegmentInfos.FORMAT_CHECKSUM) {\n      sFormat = \"FORMAT_CHECKSUM [Lucene 2.4]\";\n    } else if (format < SegmentInfos.FORMAT_CHECKSUM) {\n      sFormat = \"int=\" + format + \" [newer version of Lucene than this tool]\";\n      skip = true;\n    } else {\n      sFormat = format + \" [Lucene 1.3 or prior]\";\n    }\n\n    out.println(\"Segments file=\" + segmentsFileName + \" numSegments=\" + numSegments + \" version=\" + sFormat);\n\n    if (onlySegments != null) {\n      out.print(\"\\nChecking only these segments:\");\n      Iterator it = onlySegments.iterator();\n      while (it.hasNext()) {\n        out.print(\" \" + it.next());\n      }\n      out.println(\":\");\n    }\n\n    if (skip) {\n      out.println(\"\\nERROR: this index appears to be created by a newer version of Lucene than this tool was compiled on; please re-compile this tool on the matching version of Lucene; exiting\");\n      return false;\n    }\n\n    SegmentInfos newSIS = (SegmentInfos) sis.clone();\n    newSIS.clear();\n    boolean changed = false;\n    int totLoseDocCount = 0;\n    int numBadSegments = 0;\n    for(int i=0;i<numSegments;i++) {\n      final SegmentInfo info = sis.info(i);\n      if (onlySegments != null && !onlySegments.contains(info.name))\n        continue;\n      out.println(\"  \" + (1+i) + \" of \" + numSegments + \": name=\" + info.name + \" docCount=\" + info.docCount);\n      int toLoseDocCount = info.docCount;\n\n      SegmentReader reader = null;\n\n      try {\n        out.println(\"    compound=\" + info.getUseCompoundFile());\n        out.println(\"    numFiles=\" + info.files().size());\n        out.println(\"    size (MB)=\" + nf.format(info.sizeInBytes()/(1024.*1024.)));\n        final int docStoreOffset = info.getDocStoreOffset();\n        if (docStoreOffset != -1) {\n          out.println(\"    docStoreOffset=\" + docStoreOffset);\n          out.println(\"    docStoreSegment=\" + info.getDocStoreSegment());\n          out.println(\"    docStoreIsCompoundFile=\" + info.getDocStoreIsCompoundFile());\n        }\n        final String delFileName = info.getDelFileName();\n        if (delFileName == null)\n          out.println(\"    no deletions\");\n        else\n          out.println(\"    has deletions [delFileName=\" + delFileName + \"]\");\n        out.print(\"    test: open reader.........\");\n        reader = SegmentReader.get(info);\n        final int numDocs = reader.numDocs();\n        toLoseDocCount = numDocs;\n        if (reader.hasDeletions())\n          out.println(\"OK [\" + (info.docCount - numDocs) + \" deleted docs]\");\n        else\n          out.println(\"OK\");\n\n        out.print(\"    test: fields, norms.......\");\n        Collection fieldNames = reader.getFieldNames(IndexReader.FieldOption.ALL);\n        Iterator it = fieldNames.iterator();\n        while(it.hasNext()) {\n          final String fieldName = (String) it.next();\n          byte[] b = reader.norms(fieldName);\n          if (b.length != info.docCount)\n            throw new RuntimeException(\"norms for field \\\"\" + fieldName + \"\\\" is length \" + b.length + \" != maxDoc \" + info.docCount);\n\n        }\n        out.println(\"OK [\" + fieldNames.size() + \" fields]\");\n\n        out.print(\"    test: terms, freq, prox...\");\n        final TermEnum termEnum = reader.terms();\n        final TermPositions termPositions = reader.termPositions();\n\n        // Used only to count up # deleted docs for this\n        // term\n        final MySegmentTermDocs myTermDocs = new MySegmentTermDocs(reader);\n\n        long termCount = 0;\n        long totFreq = 0;\n        long totPos = 0;\n        while(termEnum.next()) {\n          termCount++;\n          final Term term = termEnum.term();\n          final int docFreq = termEnum.docFreq();\n          termPositions.seek(term);\n          int lastDoc = -1;\n          int freq0 = 0;\n          totFreq += docFreq;\n          while(termPositions.next()) {\n            freq0++;\n            final int doc = termPositions.doc();\n            final int freq = termPositions.freq();\n            if (doc <= lastDoc)\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" < lastDoc \" + lastDoc);\n            lastDoc = doc;\n            if (freq <= 0)\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" is out of bounds\");\n            \n            int lastPos = -1;\n            totPos += freq;\n            for(int j=0;j<freq;j++) {\n              final int pos = termPositions.nextPosition();\n              if (pos < 0)\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" is out of bounds\");\n              if (pos < lastPos)\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" < lastPos \" + lastPos);\n            }\n          }\n\n          // Now count how many deleted docs occurred in\n          // this term:\n          final int delCount;\n          if (reader.hasDeletions()) {\n            myTermDocs.seek(term);\n            while(myTermDocs.next()) {\n            }\n            delCount = myTermDocs.delCount;\n          } else\n            delCount = 0;\n\n          if (freq0 + delCount != docFreq)\n            throw new RuntimeException(\"term \" + term + \" docFreq=\" + docFreq + \" != num docs seen \" + freq0 + \" + num docs deleted \" + delCount);\n        }\n\n        out.println(\"OK [\" + termCount + \" terms; \" + totFreq + \" terms/docs pairs; \" + totPos + \" tokens]\");\n\n        out.print(\"    test: stored fields.......\");\n        int docCount = 0;\n        long totFields = 0;\n        for(int j=0;j<info.docCount;j++)\n          if (!reader.isDeleted(j)) {\n            docCount++;\n            Document doc = reader.document(j);\n            totFields += doc.getFields().size();\n          }\n\n        if (docCount != reader.numDocs())\n          throw new RuntimeException(\"docCount=\" + docCount + \" but saw \" + docCount + \" undeleted docs\");\n\n        out.println(\"OK [\" + totFields + \" total field count; avg \" + nf.format((((float) totFields)/docCount)) + \" fields per doc]\");\n\n        out.print(\"    test: term vectors........\");\n        int totVectors = 0;\n        for(int j=0;j<info.docCount;j++)\n          if (!reader.isDeleted(j)) {\n            TermFreqVector[] tfv = reader.getTermFreqVectors(j);\n            if (tfv != null)\n              totVectors += tfv.length;\n          }\n\n        out.println(\"OK [\" + totVectors + \" total vector count; avg \" + nf.format((((float) totVectors)/docCount)) + \" term/freq vector fields per doc]\");\n        out.println(\"\");\n\n      } catch (Throwable t) {\n        out.println(\"FAILED\");\n        String comment;\n        if (doFix)\n          comment = \"will remove reference to this segment (-fix is specified)\";\n        else\n          comment = \"would remove reference to this segment (-fix was not specified)\";\n        out.println(\"    WARNING: \" + comment + \"; full exception:\");\n        t.printStackTrace(out);\n        out.println(\"\");\n        totLoseDocCount += toLoseDocCount;\n        numBadSegments++;\n        changed = true;\n        continue;\n      } finally {\n        if (reader != null)\n          reader.close();\n      }\n\n      // Keeper\n      newSIS.add(info.clone());\n    }\n\n    if (!changed) {\n      out.println(\"No problems were detected with this index.\\n\");\n      return true;\n    } else {\n      out.println(\"WARNING: \" + numBadSegments + \" broken segments detected\");\n      if (doFix)\n        out.println(\"WARNING: \" + totLoseDocCount + \" documents will be lost\");\n      else\n        out.println(\"WARNING: \" + totLoseDocCount + \" documents would be lost if -fix were specified\");\n      out.println();\n    }\n\n    if (doFix) {\n      out.println(\"NOTE: will write new segments file in 5 seconds; this will remove \" + totLoseDocCount + \" docs from the index. THIS IS YOUR LAST CHANCE TO CTRL+C!\");\n      for(int i=0;i<5;i++) {\n        try {\n          Thread.sleep(1000);\n        } catch (InterruptedException ie) {\n          Thread.currentThread().interrupt();\n          i--;\n          continue;\n        }\n          \n        out.println(\"  \" + (5-i) + \"...\");\n      }\n      out.print(\"Writing...\");\n      try {\n        newSIS.commit(dir);\n      } catch (Throwable t) {\n        out.println(\"FAILED; exiting\");\n        t.printStackTrace(out);\n        return false;\n      }\n      out.println(\"OK\");\n      out.println(\"Wrote new segments file \\\"\" + newSIS.getCurrentSegmentFileName() + \"\\\"\");\n    } else {\n      out.println(\"NOTE: would write new segments file [-fix was not specified]\");\n    }\n    out.println(\"\");\n\n    return false;\n  }\n\n","sourceOld":"  /** Returns true if index is clean, else false.*/\n  public static boolean check(Directory dir, boolean doFix, List onlySegments) throws IOException {\n    NumberFormat nf = NumberFormat.getInstance();\n    SegmentInfos sis = new SegmentInfos();\n    \n    try {\n      sis.read(dir);\n    } catch (Throwable t) {\n      out.println(\"ERROR: could not read any segments file in directory\");\n      t.printStackTrace(out);\n      return false;\n    }\n\n    final int numSegments = sis.size();\n    final String segmentsFileName = sis.getCurrentSegmentFileName();\n    IndexInput input = null;\n    try {\n      input = dir.openInput(segmentsFileName);\n    } catch (Throwable t) {\n      out.println(\"ERROR: could not open segments file in directory\");\n      t.printStackTrace(out);\n      return false;\n    }\n    int format = 0;\n    try {\n      format = input.readInt();\n    } catch (Throwable t) {\n      out.println(\"ERROR: could not read segment file version in directory\");\n      t.printStackTrace(out);\n      return false;\n    } finally {\n      if (input != null)\n        input.close();\n    }\n\n    String sFormat = \"\";\n    boolean skip = false;\n\n    if (format == SegmentInfos.FORMAT)\n      sFormat = \"FORMAT [Lucene Pre-2.1]\";\n    if (format == SegmentInfos.FORMAT_LOCKLESS)\n      sFormat = \"FORMAT_LOCKLESS [Lucene 2.1]\";\n    else if (format == SegmentInfos.FORMAT_SINGLE_NORM_FILE)\n      sFormat = \"FORMAT_SINGLE_NORM_FILE [Lucene 2.2]\";\n    else if (format == SegmentInfos.FORMAT_SHARED_DOC_STORE)\n      sFormat = \"FORMAT_SHARED_DOC_STORE [Lucene 2.3]\";\n    else if (format == SegmentInfos.FORMAT_CHECKSUM) {\n      sFormat = \"FORMAT_CHECKSUM [Lucene 2.4]\";\n    } else if (format < SegmentInfos.FORMAT_CHECKSUM) {\n      sFormat = \"int=\" + format + \" [newer version of Lucene than this tool]\";\n      skip = true;\n    } else {\n      sFormat = format + \" [Lucene 1.3 or prior]\";\n    }\n\n    out.println(\"Segments file=\" + segmentsFileName + \" numSegments=\" + numSegments + \" version=\" + sFormat);\n\n    if (onlySegments != null) {\n      out.print(\"\\nChecking only these segments:\");\n      Iterator it = onlySegments.iterator();\n      while (it.hasNext()) {\n        out.print(\" \" + it.next());\n      }\n      out.println(\":\");\n    }\n\n    if (skip) {\n      out.println(\"\\nERROR: this index appears to be created by a newer version of Lucene than this tool was compiled on; please re-compile this tool on the matching version of Lucene; exiting\");\n      return false;\n    }\n\n    SegmentInfos newSIS = (SegmentInfos) sis.clone();\n    newSIS.clear();\n    boolean changed = false;\n    int totLoseDocCount = 0;\n    int numBadSegments = 0;\n    for(int i=0;i<numSegments;i++) {\n      final SegmentInfo info = sis.info(i);\n      if (onlySegments != null && !onlySegments.contains(info.name))\n        continue;\n      out.println(\"  \" + (1+i) + \" of \" + numSegments + \": name=\" + info.name + \" docCount=\" + info.docCount);\n      int toLoseDocCount = info.docCount;\n\n      SegmentReader reader = null;\n\n      try {\n        out.println(\"    compound=\" + info.getUseCompoundFile());\n        out.println(\"    numFiles=\" + info.files().size());\n        out.println(\"    size (MB)=\" + nf.format(info.sizeInBytes()/(1024.*1024.)));\n        final int docStoreOffset = info.getDocStoreOffset();\n        if (docStoreOffset != -1) {\n          out.println(\"    docStoreOffset=\" + docStoreOffset);\n          out.println(\"    docStoreSegment=\" + info.getDocStoreSegment());\n          out.println(\"    docStoreIsCompoundFile=\" + info.getDocStoreIsCompoundFile());\n        }\n        final String delFileName = info.getDelFileName();\n        if (delFileName == null)\n          out.println(\"    no deletions\");\n        else\n          out.println(\"    has deletions [delFileName=\" + delFileName + \"]\");\n        out.print(\"    test: open reader.........\");\n        reader = SegmentReader.get(info);\n        final int numDocs = reader.numDocs();\n        toLoseDocCount = numDocs;\n        if (reader.hasDeletions())\n          out.println(\"OK [\" + (info.docCount - numDocs) + \" deleted docs]\");\n        else\n          out.println(\"OK\");\n\n        out.print(\"    test: fields, norms.......\");\n        Collection fieldNames = reader.getFieldNames(IndexReader.FieldOption.ALL);\n        Iterator it = fieldNames.iterator();\n        while(it.hasNext()) {\n          final String fieldName = (String) it.next();\n          byte[] b = reader.norms(fieldName);\n          if (b.length != info.docCount)\n            throw new RuntimeException(\"norms for field \\\"\" + fieldName + \"\\\" is length \" + b.length + \" != maxDoc \" + info.docCount);\n\n        }\n        out.println(\"OK [\" + fieldNames.size() + \" fields]\");\n\n        out.print(\"    test: terms, freq, prox...\");\n        final TermEnum termEnum = reader.terms();\n        final TermPositions termPositions = reader.termPositions();\n\n        // Used only to count up # deleted docs for this\n        // term\n        final MySegmentTermDocs myTermDocs = new MySegmentTermDocs(reader);\n\n        long termCount = 0;\n        long totFreq = 0;\n        long totPos = 0;\n        while(termEnum.next()) {\n          termCount++;\n          final Term term = termEnum.term();\n          final int docFreq = termEnum.docFreq();\n          termPositions.seek(term);\n          int lastDoc = -1;\n          int freq0 = 0;\n          totFreq += docFreq;\n          while(termPositions.next()) {\n            freq0++;\n            final int doc = termPositions.doc();\n            final int freq = termPositions.freq();\n            if (doc <= lastDoc)\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" < lastDoc \" + lastDoc);\n            lastDoc = doc;\n            if (freq <= 0)\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" is out of bounds\");\n            \n            int lastPos = -1;\n            totPos += freq;\n            for(int j=0;j<freq;j++) {\n              final int pos = termPositions.nextPosition();\n              if (pos < 0)\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" is out of bounds\");\n              if (pos <= lastPos)\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" < lastPos \" + lastPos);\n            }\n          }\n\n          // Now count how many deleted docs occurred in\n          // this term:\n          final int delCount;\n          if (reader.hasDeletions()) {\n            myTermDocs.seek(term);\n            while(myTermDocs.next()) {\n            }\n            delCount = myTermDocs.delCount;\n          } else\n            delCount = 0;\n\n          if (freq0 + delCount != docFreq)\n            throw new RuntimeException(\"term \" + term + \" docFreq=\" + docFreq + \" != num docs seen \" + freq0 + \" + num docs deleted \" + delCount);\n        }\n\n        out.println(\"OK [\" + termCount + \" terms; \" + totFreq + \" terms/docs pairs; \" + totPos + \" tokens]\");\n\n        out.print(\"    test: stored fields.......\");\n        int docCount = 0;\n        long totFields = 0;\n        for(int j=0;j<info.docCount;j++)\n          if (!reader.isDeleted(j)) {\n            docCount++;\n            Document doc = reader.document(j);\n            totFields += doc.getFields().size();\n          }\n\n        if (docCount != reader.numDocs())\n          throw new RuntimeException(\"docCount=\" + docCount + \" but saw \" + docCount + \" undeleted docs\");\n\n        out.println(\"OK [\" + totFields + \" total field count; avg \" + nf.format((((float) totFields)/docCount)) + \" fields per doc]\");\n\n        out.print(\"    test: term vectors........\");\n        int totVectors = 0;\n        for(int j=0;j<info.docCount;j++)\n          if (!reader.isDeleted(j)) {\n            TermFreqVector[] tfv = reader.getTermFreqVectors(j);\n            if (tfv != null)\n              totVectors += tfv.length;\n          }\n\n        out.println(\"OK [\" + totVectors + \" total vector count; avg \" + nf.format((((float) totVectors)/docCount)) + \" term/freq vector fields per doc]\");\n        out.println(\"\");\n\n      } catch (Throwable t) {\n        out.println(\"FAILED\");\n        String comment;\n        if (doFix)\n          comment = \"will remove reference to this segment (-fix is specified)\";\n        else\n          comment = \"would remove reference to this segment (-fix was not specified)\";\n        out.println(\"    WARNING: \" + comment + \"; full exception:\");\n        t.printStackTrace(out);\n        out.println(\"\");\n        totLoseDocCount += toLoseDocCount;\n        numBadSegments++;\n        changed = true;\n        continue;\n      } finally {\n        if (reader != null)\n          reader.close();\n      }\n\n      // Keeper\n      newSIS.add(info.clone());\n    }\n\n    if (!changed) {\n      out.println(\"No problems were detected with this index.\\n\");\n      return true;\n    } else {\n      out.println(\"WARNING: \" + numBadSegments + \" broken segments detected\");\n      if (doFix)\n        out.println(\"WARNING: \" + totLoseDocCount + \" documents will be lost\");\n      else\n        out.println(\"WARNING: \" + totLoseDocCount + \" documents would be lost if -fix were specified\");\n      out.println();\n    }\n\n    if (doFix) {\n      out.println(\"NOTE: will write new segments file in 5 seconds; this will remove \" + totLoseDocCount + \" docs from the index. THIS IS YOUR LAST CHANCE TO CTRL+C!\");\n      for(int i=0;i<5;i++) {\n        try {\n          Thread.sleep(1000);\n        } catch (InterruptedException ie) {\n          Thread.currentThread().interrupt();\n          i--;\n          continue;\n        }\n          \n        out.println(\"  \" + (5-i) + \"...\");\n      }\n      out.print(\"Writing...\");\n      try {\n        newSIS.commit(dir);\n      } catch (Throwable t) {\n        out.println(\"FAILED; exiting\");\n        t.printStackTrace(out);\n        return false;\n      }\n      out.println(\"OK\");\n      out.println(\"Wrote new segments file \\\"\" + newSIS.getCurrentSegmentFileName() + \"\\\"\");\n    } else {\n      out.println(\"NOTE: would write new segments file [-fix was not specified]\");\n    }\n    out.println(\"\");\n\n    return false;\n  }\n\n","bugFix":null,"bugIntro":["7391c1f4ab1a6817de8a262f5c1b3de3cf190785"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"9cb1313e01866149ff8dde7e80345a5476de305e","date":1208975167,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/CheckIndex#check(Directory,boolean,List).mjava","pathOld":"src/java/org/apache/lucene/index/CheckIndex#check(Directory,boolean,List).mjava","sourceNew":"  /** Returns true if index is clean, else false.*/\n  public static boolean check(Directory dir, boolean doFix, List onlySegments) throws IOException {\n    NumberFormat nf = NumberFormat.getInstance();\n    SegmentInfos sis = new SegmentInfos();\n    \n    try {\n      sis.read(dir);\n    } catch (Throwable t) {\n      out.println(\"ERROR: could not read any segments file in directory\");\n      t.printStackTrace(out);\n      return false;\n    }\n\n    final int numSegments = sis.size();\n    final String segmentsFileName = sis.getCurrentSegmentFileName();\n    IndexInput input = null;\n    try {\n      input = dir.openInput(segmentsFileName);\n    } catch (Throwable t) {\n      out.println(\"ERROR: could not open segments file in directory\");\n      t.printStackTrace(out);\n      return false;\n    }\n    int format = 0;\n    try {\n      format = input.readInt();\n    } catch (Throwable t) {\n      out.println(\"ERROR: could not read segment file version in directory\");\n      t.printStackTrace(out);\n      return false;\n    } finally {\n      if (input != null)\n        input.close();\n    }\n\n    String sFormat = \"\";\n    boolean skip = false;\n    boolean allowMinusOnePosition = true;\n\n    if (format == SegmentInfos.FORMAT)\n      sFormat = \"FORMAT [Lucene Pre-2.1]\";\n    if (format == SegmentInfos.FORMAT_LOCKLESS)\n      sFormat = \"FORMAT_LOCKLESS [Lucene 2.1]\";\n    else if (format == SegmentInfos.FORMAT_SINGLE_NORM_FILE)\n      sFormat = \"FORMAT_SINGLE_NORM_FILE [Lucene 2.2]\";\n    else if (format == SegmentInfos.FORMAT_SHARED_DOC_STORE)\n      sFormat = \"FORMAT_SHARED_DOC_STORE [Lucene 2.3]\";\n    else {\n      // LUCENE-1255: All versions before 2.3.2/2.4 were\n      // able to create position=-1 when the very first\n      // Token has positionIncrement 0\n      allowMinusOnePosition = false;\n      if (format == SegmentInfos.FORMAT_CHECKSUM) {\n        sFormat = \"FORMAT_CHECKSUM [Lucene 2.4]\";\n      } else if (format < SegmentInfos.FORMAT_CHECKSUM) {\n        sFormat = \"int=\" + format + \" [newer version of Lucene than this tool]\";\n        skip = true;\n      } else {\n        sFormat = format + \" [Lucene 1.3 or prior]\";\n      }\n    }\n\n    out.println(\"Segments file=\" + segmentsFileName + \" numSegments=\" + numSegments + \" version=\" + sFormat);\n\n    if (onlySegments != null) {\n      out.print(\"\\nChecking only these segments:\");\n      Iterator it = onlySegments.iterator();\n      while (it.hasNext()) {\n        out.print(\" \" + it.next());\n      }\n      out.println(\":\");\n    }\n\n    if (skip) {\n      out.println(\"\\nERROR: this index appears to be created by a newer version of Lucene than this tool was compiled on; please re-compile this tool on the matching version of Lucene; exiting\");\n      return false;\n    }\n\n    SegmentInfos newSIS = (SegmentInfos) sis.clone();\n    newSIS.clear();\n    boolean changed = false;\n    int totLoseDocCount = 0;\n    int numBadSegments = 0;\n    for(int i=0;i<numSegments;i++) {\n      final SegmentInfo info = sis.info(i);\n      if (onlySegments != null && !onlySegments.contains(info.name))\n        continue;\n      out.println(\"  \" + (1+i) + \" of \" + numSegments + \": name=\" + info.name + \" docCount=\" + info.docCount);\n      int toLoseDocCount = info.docCount;\n\n      SegmentReader reader = null;\n\n      try {\n        out.println(\"    compound=\" + info.getUseCompoundFile());\n        out.println(\"    numFiles=\" + info.files().size());\n        out.println(\"    size (MB)=\" + nf.format(info.sizeInBytes()/(1024.*1024.)));\n        final int docStoreOffset = info.getDocStoreOffset();\n        if (docStoreOffset != -1) {\n          out.println(\"    docStoreOffset=\" + docStoreOffset);\n          out.println(\"    docStoreSegment=\" + info.getDocStoreSegment());\n          out.println(\"    docStoreIsCompoundFile=\" + info.getDocStoreIsCompoundFile());\n        }\n        final String delFileName = info.getDelFileName();\n        if (delFileName == null)\n          out.println(\"    no deletions\");\n        else\n          out.println(\"    has deletions [delFileName=\" + delFileName + \"]\");\n        out.print(\"    test: open reader.........\");\n        reader = SegmentReader.get(info);\n        final int numDocs = reader.numDocs();\n        toLoseDocCount = numDocs;\n        if (reader.hasDeletions())\n          out.println(\"OK [\" + (info.docCount - numDocs) + \" deleted docs]\");\n        else\n          out.println(\"OK\");\n\n        out.print(\"    test: fields, norms.......\");\n        Collection fieldNames = reader.getFieldNames(IndexReader.FieldOption.ALL);\n        Iterator it = fieldNames.iterator();\n        while(it.hasNext()) {\n          final String fieldName = (String) it.next();\n          byte[] b = reader.norms(fieldName);\n          if (b.length != info.docCount)\n            throw new RuntimeException(\"norms for field \\\"\" + fieldName + \"\\\" is length \" + b.length + \" != maxDoc \" + info.docCount);\n\n        }\n        out.println(\"OK [\" + fieldNames.size() + \" fields]\");\n\n        out.print(\"    test: terms, freq, prox...\");\n        final TermEnum termEnum = reader.terms();\n        final TermPositions termPositions = reader.termPositions();\n\n        // Used only to count up # deleted docs for this\n        // term\n        final MySegmentTermDocs myTermDocs = new MySegmentTermDocs(reader);\n\n        long termCount = 0;\n        long totFreq = 0;\n        long totPos = 0;\n        while(termEnum.next()) {\n          termCount++;\n          final Term term = termEnum.term();\n          final int docFreq = termEnum.docFreq();\n          termPositions.seek(term);\n          int lastDoc = -1;\n          int freq0 = 0;\n          totFreq += docFreq;\n          while(termPositions.next()) {\n            freq0++;\n            final int doc = termPositions.doc();\n            final int freq = termPositions.freq();\n            if (doc <= lastDoc)\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" < lastDoc \" + lastDoc);\n            lastDoc = doc;\n            if (freq <= 0)\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" is out of bounds\");\n            \n            int lastPos = -1;\n            totPos += freq;\n            for(int j=0;j<freq;j++) {\n              final int pos = termPositions.nextPosition();\n              if (pos < -1 || (pos == -1 && !allowMinusOnePosition))\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" is out of bounds\");\n              if (pos < lastPos)\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" < lastPos \" + lastPos);\n            }\n          }\n\n          // Now count how many deleted docs occurred in\n          // this term:\n          final int delCount;\n          if (reader.hasDeletions()) {\n            myTermDocs.seek(term);\n            while(myTermDocs.next()) {\n            }\n            delCount = myTermDocs.delCount;\n          } else\n            delCount = 0;\n\n          if (freq0 + delCount != docFreq)\n            throw new RuntimeException(\"term \" + term + \" docFreq=\" + docFreq + \" != num docs seen \" + freq0 + \" + num docs deleted \" + delCount);\n        }\n\n        out.println(\"OK [\" + termCount + \" terms; \" + totFreq + \" terms/docs pairs; \" + totPos + \" tokens]\");\n\n        out.print(\"    test: stored fields.......\");\n        int docCount = 0;\n        long totFields = 0;\n        for(int j=0;j<info.docCount;j++)\n          if (!reader.isDeleted(j)) {\n            docCount++;\n            Document doc = reader.document(j);\n            totFields += doc.getFields().size();\n          }\n\n        if (docCount != reader.numDocs())\n          throw new RuntimeException(\"docCount=\" + docCount + \" but saw \" + docCount + \" undeleted docs\");\n\n        out.println(\"OK [\" + totFields + \" total field count; avg \" + nf.format((((float) totFields)/docCount)) + \" fields per doc]\");\n\n        out.print(\"    test: term vectors........\");\n        int totVectors = 0;\n        for(int j=0;j<info.docCount;j++)\n          if (!reader.isDeleted(j)) {\n            TermFreqVector[] tfv = reader.getTermFreqVectors(j);\n            if (tfv != null)\n              totVectors += tfv.length;\n          }\n\n        out.println(\"OK [\" + totVectors + \" total vector count; avg \" + nf.format((((float) totVectors)/docCount)) + \" term/freq vector fields per doc]\");\n        out.println(\"\");\n\n      } catch (Throwable t) {\n        out.println(\"FAILED\");\n        String comment;\n        if (doFix)\n          comment = \"will remove reference to this segment (-fix is specified)\";\n        else\n          comment = \"would remove reference to this segment (-fix was not specified)\";\n        out.println(\"    WARNING: \" + comment + \"; full exception:\");\n        t.printStackTrace(out);\n        out.println(\"\");\n        totLoseDocCount += toLoseDocCount;\n        numBadSegments++;\n        changed = true;\n        continue;\n      } finally {\n        if (reader != null)\n          reader.close();\n      }\n\n      // Keeper\n      newSIS.add(info.clone());\n    }\n\n    if (!changed) {\n      out.println(\"No problems were detected with this index.\\n\");\n      return true;\n    } else {\n      out.println(\"WARNING: \" + numBadSegments + \" broken segments detected\");\n      if (doFix)\n        out.println(\"WARNING: \" + totLoseDocCount + \" documents will be lost\");\n      else\n        out.println(\"WARNING: \" + totLoseDocCount + \" documents would be lost if -fix were specified\");\n      out.println();\n    }\n\n    if (doFix) {\n      out.println(\"NOTE: will write new segments file in 5 seconds; this will remove \" + totLoseDocCount + \" docs from the index. THIS IS YOUR LAST CHANCE TO CTRL+C!\");\n      for(int i=0;i<5;i++) {\n        try {\n          Thread.sleep(1000);\n        } catch (InterruptedException ie) {\n          Thread.currentThread().interrupt();\n          i--;\n          continue;\n        }\n          \n        out.println(\"  \" + (5-i) + \"...\");\n      }\n      out.print(\"Writing...\");\n      try {\n        newSIS.commit(dir);\n      } catch (Throwable t) {\n        out.println(\"FAILED; exiting\");\n        t.printStackTrace(out);\n        return false;\n      }\n      out.println(\"OK\");\n      out.println(\"Wrote new segments file \\\"\" + newSIS.getCurrentSegmentFileName() + \"\\\"\");\n    } else {\n      out.println(\"NOTE: would write new segments file [-fix was not specified]\");\n    }\n    out.println(\"\");\n\n    return false;\n  }\n\n","sourceOld":"  /** Returns true if index is clean, else false.*/\n  public static boolean check(Directory dir, boolean doFix, List onlySegments) throws IOException {\n    NumberFormat nf = NumberFormat.getInstance();\n    SegmentInfos sis = new SegmentInfos();\n    \n    try {\n      sis.read(dir);\n    } catch (Throwable t) {\n      out.println(\"ERROR: could not read any segments file in directory\");\n      t.printStackTrace(out);\n      return false;\n    }\n\n    final int numSegments = sis.size();\n    final String segmentsFileName = sis.getCurrentSegmentFileName();\n    IndexInput input = null;\n    try {\n      input = dir.openInput(segmentsFileName);\n    } catch (Throwable t) {\n      out.println(\"ERROR: could not open segments file in directory\");\n      t.printStackTrace(out);\n      return false;\n    }\n    int format = 0;\n    try {\n      format = input.readInt();\n    } catch (Throwable t) {\n      out.println(\"ERROR: could not read segment file version in directory\");\n      t.printStackTrace(out);\n      return false;\n    } finally {\n      if (input != null)\n        input.close();\n    }\n\n    String sFormat = \"\";\n    boolean skip = false;\n\n    if (format == SegmentInfos.FORMAT)\n      sFormat = \"FORMAT [Lucene Pre-2.1]\";\n    if (format == SegmentInfos.FORMAT_LOCKLESS)\n      sFormat = \"FORMAT_LOCKLESS [Lucene 2.1]\";\n    else if (format == SegmentInfos.FORMAT_SINGLE_NORM_FILE)\n      sFormat = \"FORMAT_SINGLE_NORM_FILE [Lucene 2.2]\";\n    else if (format == SegmentInfos.FORMAT_SHARED_DOC_STORE)\n      sFormat = \"FORMAT_SHARED_DOC_STORE [Lucene 2.3]\";\n    else if (format == SegmentInfos.FORMAT_CHECKSUM) {\n      sFormat = \"FORMAT_CHECKSUM [Lucene 2.4]\";\n    } else if (format < SegmentInfos.FORMAT_CHECKSUM) {\n      sFormat = \"int=\" + format + \" [newer version of Lucene than this tool]\";\n      skip = true;\n    } else {\n      sFormat = format + \" [Lucene 1.3 or prior]\";\n    }\n\n    out.println(\"Segments file=\" + segmentsFileName + \" numSegments=\" + numSegments + \" version=\" + sFormat);\n\n    if (onlySegments != null) {\n      out.print(\"\\nChecking only these segments:\");\n      Iterator it = onlySegments.iterator();\n      while (it.hasNext()) {\n        out.print(\" \" + it.next());\n      }\n      out.println(\":\");\n    }\n\n    if (skip) {\n      out.println(\"\\nERROR: this index appears to be created by a newer version of Lucene than this tool was compiled on; please re-compile this tool on the matching version of Lucene; exiting\");\n      return false;\n    }\n\n    SegmentInfos newSIS = (SegmentInfos) sis.clone();\n    newSIS.clear();\n    boolean changed = false;\n    int totLoseDocCount = 0;\n    int numBadSegments = 0;\n    for(int i=0;i<numSegments;i++) {\n      final SegmentInfo info = sis.info(i);\n      if (onlySegments != null && !onlySegments.contains(info.name))\n        continue;\n      out.println(\"  \" + (1+i) + \" of \" + numSegments + \": name=\" + info.name + \" docCount=\" + info.docCount);\n      int toLoseDocCount = info.docCount;\n\n      SegmentReader reader = null;\n\n      try {\n        out.println(\"    compound=\" + info.getUseCompoundFile());\n        out.println(\"    numFiles=\" + info.files().size());\n        out.println(\"    size (MB)=\" + nf.format(info.sizeInBytes()/(1024.*1024.)));\n        final int docStoreOffset = info.getDocStoreOffset();\n        if (docStoreOffset != -1) {\n          out.println(\"    docStoreOffset=\" + docStoreOffset);\n          out.println(\"    docStoreSegment=\" + info.getDocStoreSegment());\n          out.println(\"    docStoreIsCompoundFile=\" + info.getDocStoreIsCompoundFile());\n        }\n        final String delFileName = info.getDelFileName();\n        if (delFileName == null)\n          out.println(\"    no deletions\");\n        else\n          out.println(\"    has deletions [delFileName=\" + delFileName + \"]\");\n        out.print(\"    test: open reader.........\");\n        reader = SegmentReader.get(info);\n        final int numDocs = reader.numDocs();\n        toLoseDocCount = numDocs;\n        if (reader.hasDeletions())\n          out.println(\"OK [\" + (info.docCount - numDocs) + \" deleted docs]\");\n        else\n          out.println(\"OK\");\n\n        out.print(\"    test: fields, norms.......\");\n        Collection fieldNames = reader.getFieldNames(IndexReader.FieldOption.ALL);\n        Iterator it = fieldNames.iterator();\n        while(it.hasNext()) {\n          final String fieldName = (String) it.next();\n          byte[] b = reader.norms(fieldName);\n          if (b.length != info.docCount)\n            throw new RuntimeException(\"norms for field \\\"\" + fieldName + \"\\\" is length \" + b.length + \" != maxDoc \" + info.docCount);\n\n        }\n        out.println(\"OK [\" + fieldNames.size() + \" fields]\");\n\n        out.print(\"    test: terms, freq, prox...\");\n        final TermEnum termEnum = reader.terms();\n        final TermPositions termPositions = reader.termPositions();\n\n        // Used only to count up # deleted docs for this\n        // term\n        final MySegmentTermDocs myTermDocs = new MySegmentTermDocs(reader);\n\n        long termCount = 0;\n        long totFreq = 0;\n        long totPos = 0;\n        while(termEnum.next()) {\n          termCount++;\n          final Term term = termEnum.term();\n          final int docFreq = termEnum.docFreq();\n          termPositions.seek(term);\n          int lastDoc = -1;\n          int freq0 = 0;\n          totFreq += docFreq;\n          while(termPositions.next()) {\n            freq0++;\n            final int doc = termPositions.doc();\n            final int freq = termPositions.freq();\n            if (doc <= lastDoc)\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" < lastDoc \" + lastDoc);\n            lastDoc = doc;\n            if (freq <= 0)\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" is out of bounds\");\n            \n            int lastPos = -1;\n            totPos += freq;\n            for(int j=0;j<freq;j++) {\n              final int pos = termPositions.nextPosition();\n              if (pos < 0)\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" is out of bounds\");\n              if (pos < lastPos)\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" < lastPos \" + lastPos);\n            }\n          }\n\n          // Now count how many deleted docs occurred in\n          // this term:\n          final int delCount;\n          if (reader.hasDeletions()) {\n            myTermDocs.seek(term);\n            while(myTermDocs.next()) {\n            }\n            delCount = myTermDocs.delCount;\n          } else\n            delCount = 0;\n\n          if (freq0 + delCount != docFreq)\n            throw new RuntimeException(\"term \" + term + \" docFreq=\" + docFreq + \" != num docs seen \" + freq0 + \" + num docs deleted \" + delCount);\n        }\n\n        out.println(\"OK [\" + termCount + \" terms; \" + totFreq + \" terms/docs pairs; \" + totPos + \" tokens]\");\n\n        out.print(\"    test: stored fields.......\");\n        int docCount = 0;\n        long totFields = 0;\n        for(int j=0;j<info.docCount;j++)\n          if (!reader.isDeleted(j)) {\n            docCount++;\n            Document doc = reader.document(j);\n            totFields += doc.getFields().size();\n          }\n\n        if (docCount != reader.numDocs())\n          throw new RuntimeException(\"docCount=\" + docCount + \" but saw \" + docCount + \" undeleted docs\");\n\n        out.println(\"OK [\" + totFields + \" total field count; avg \" + nf.format((((float) totFields)/docCount)) + \" fields per doc]\");\n\n        out.print(\"    test: term vectors........\");\n        int totVectors = 0;\n        for(int j=0;j<info.docCount;j++)\n          if (!reader.isDeleted(j)) {\n            TermFreqVector[] tfv = reader.getTermFreqVectors(j);\n            if (tfv != null)\n              totVectors += tfv.length;\n          }\n\n        out.println(\"OK [\" + totVectors + \" total vector count; avg \" + nf.format((((float) totVectors)/docCount)) + \" term/freq vector fields per doc]\");\n        out.println(\"\");\n\n      } catch (Throwable t) {\n        out.println(\"FAILED\");\n        String comment;\n        if (doFix)\n          comment = \"will remove reference to this segment (-fix is specified)\";\n        else\n          comment = \"would remove reference to this segment (-fix was not specified)\";\n        out.println(\"    WARNING: \" + comment + \"; full exception:\");\n        t.printStackTrace(out);\n        out.println(\"\");\n        totLoseDocCount += toLoseDocCount;\n        numBadSegments++;\n        changed = true;\n        continue;\n      } finally {\n        if (reader != null)\n          reader.close();\n      }\n\n      // Keeper\n      newSIS.add(info.clone());\n    }\n\n    if (!changed) {\n      out.println(\"No problems were detected with this index.\\n\");\n      return true;\n    } else {\n      out.println(\"WARNING: \" + numBadSegments + \" broken segments detected\");\n      if (doFix)\n        out.println(\"WARNING: \" + totLoseDocCount + \" documents will be lost\");\n      else\n        out.println(\"WARNING: \" + totLoseDocCount + \" documents would be lost if -fix were specified\");\n      out.println();\n    }\n\n    if (doFix) {\n      out.println(\"NOTE: will write new segments file in 5 seconds; this will remove \" + totLoseDocCount + \" docs from the index. THIS IS YOUR LAST CHANCE TO CTRL+C!\");\n      for(int i=0;i<5;i++) {\n        try {\n          Thread.sleep(1000);\n        } catch (InterruptedException ie) {\n          Thread.currentThread().interrupt();\n          i--;\n          continue;\n        }\n          \n        out.println(\"  \" + (5-i) + \"...\");\n      }\n      out.print(\"Writing...\");\n      try {\n        newSIS.commit(dir);\n      } catch (Throwable t) {\n        out.println(\"FAILED; exiting\");\n        t.printStackTrace(out);\n        return false;\n      }\n      out.println(\"OK\");\n      out.println(\"Wrote new segments file \\\"\" + newSIS.getCurrentSegmentFileName() + \"\\\"\");\n    } else {\n      out.println(\"NOTE: would write new segments file [-fix was not specified]\");\n    }\n    out.println(\"\");\n\n    return false;\n  }\n\n","bugFix":null,"bugIntro":["abfdd5170b43f046dfac9dafd6e12c1a65f3018c","7391c1f4ab1a6817de8a262f5c1b3de3cf190785"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"34e2c71b6406443562df54db233fde0728502f64","date":1209294850,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/CheckIndex#check(Directory,boolean,List).mjava","pathOld":"src/java/org/apache/lucene/index/CheckIndex#check(Directory,boolean,List).mjava","sourceNew":"  /** Returns true if index is clean, else false.*/\n  public static boolean check(Directory dir, boolean doFix, List onlySegments) throws IOException {\n    NumberFormat nf = NumberFormat.getInstance();\n    SegmentInfos sis = new SegmentInfos();\n    \n    try {\n      sis.read(dir);\n    } catch (Throwable t) {\n      out.println(\"ERROR: could not read any segments file in directory\");\n      t.printStackTrace(out);\n      return false;\n    }\n\n    final int numSegments = sis.size();\n    final String segmentsFileName = sis.getCurrentSegmentFileName();\n    IndexInput input = null;\n    try {\n      input = dir.openInput(segmentsFileName);\n    } catch (Throwable t) {\n      out.println(\"ERROR: could not open segments file in directory\");\n      t.printStackTrace(out);\n      return false;\n    }\n    int format = 0;\n    try {\n      format = input.readInt();\n    } catch (Throwable t) {\n      out.println(\"ERROR: could not read segment file version in directory\");\n      t.printStackTrace(out);\n      return false;\n    } finally {\n      if (input != null)\n        input.close();\n    }\n\n    String sFormat = \"\";\n    boolean skip = false;\n    boolean allowMinusOnePosition = true;\n\n    if (format == SegmentInfos.FORMAT)\n      sFormat = \"FORMAT [Lucene Pre-2.1]\";\n    if (format == SegmentInfos.FORMAT_LOCKLESS)\n      sFormat = \"FORMAT_LOCKLESS [Lucene 2.1]\";\n    else if (format == SegmentInfos.FORMAT_SINGLE_NORM_FILE)\n      sFormat = \"FORMAT_SINGLE_NORM_FILE [Lucene 2.2]\";\n    else if (format == SegmentInfos.FORMAT_SHARED_DOC_STORE)\n      sFormat = \"FORMAT_SHARED_DOC_STORE [Lucene 2.3]\";\n    else {\n      // LUCENE-1255: All versions before 2.3.2/2.4 were\n      // able to create position=-1 when the very first\n      // Token has positionIncrement 0\n      allowMinusOnePosition = false;\n      if (format == SegmentInfos.FORMAT_CHECKSUM)\n        sFormat = \"FORMAT_CHECKSUM [Lucene 2.4]\";\n      else if (format == SegmentInfos.FORMAT_DEL_COUNT)\n          sFormat = \"FORMAT_DEL_COUNT [Lucene 2.4]\";\n      else if (format < SegmentInfos.CURRENT_FORMAT) {\n        sFormat = \"int=\" + format + \" [newer version of Lucene than this tool]\";\n        skip = true;\n      } else {\n        sFormat = format + \" [Lucene 1.3 or prior]\";\n      }\n    }\n\n    out.println(\"Segments file=\" + segmentsFileName + \" numSegments=\" + numSegments + \" version=\" + sFormat);\n\n    if (onlySegments != null) {\n      out.print(\"\\nChecking only these segments:\");\n      Iterator it = onlySegments.iterator();\n      while (it.hasNext()) {\n        out.print(\" \" + it.next());\n      }\n      out.println(\":\");\n    }\n\n    if (skip) {\n      out.println(\"\\nERROR: this index appears to be created by a newer version of Lucene than this tool was compiled on; please re-compile this tool on the matching version of Lucene; exiting\");\n      return false;\n    }\n\n    SegmentInfos newSIS = (SegmentInfos) sis.clone();\n    newSIS.clear();\n    boolean changed = false;\n    int totLoseDocCount = 0;\n    int numBadSegments = 0;\n    for(int i=0;i<numSegments;i++) {\n      final SegmentInfo info = sis.info(i);\n      if (onlySegments != null && !onlySegments.contains(info.name))\n        continue;\n      out.println(\"  \" + (1+i) + \" of \" + numSegments + \": name=\" + info.name + \" docCount=\" + info.docCount);\n      int toLoseDocCount = info.docCount;\n\n      SegmentReader reader = null;\n\n      try {\n        out.println(\"    compound=\" + info.getUseCompoundFile());\n        out.println(\"    numFiles=\" + info.files().size());\n        out.println(\"    size (MB)=\" + nf.format(info.sizeInBytes()/(1024.*1024.)));\n        final int docStoreOffset = info.getDocStoreOffset();\n        if (docStoreOffset != -1) {\n          out.println(\"    docStoreOffset=\" + docStoreOffset);\n          out.println(\"    docStoreSegment=\" + info.getDocStoreSegment());\n          out.println(\"    docStoreIsCompoundFile=\" + info.getDocStoreIsCompoundFile());\n        }\n        final String delFileName = info.getDelFileName();\n        if (delFileName == null)\n          out.println(\"    no deletions\");\n        else\n          out.println(\"    has deletions [delFileName=\" + delFileName + \"]\");\n        out.print(\"    test: open reader.........\");\n        reader = SegmentReader.get(info);\n        final int numDocs = reader.numDocs();\n        toLoseDocCount = numDocs;\n        if (reader.hasDeletions()) {\n          if (info.docCount - numDocs != info.getDelCount())\n            throw new RuntimeException(\"delete count mismatch: info=\" + info.getDelCount() + \" vs reader=\" + (info.docCount - numDocs));\n          out.println(\"OK [\" + (info.docCount - numDocs) + \" deleted docs]\");\n        } else {\n          if (info.getDelCount() != 0)\n            throw new RuntimeException(\"delete count mismatch: info=\" + info.getDelCount() + \" vs reader=\" + (info.docCount - numDocs));\n          out.println(\"OK\");\n        }\n\n        out.print(\"    test: fields, norms.......\");\n        Collection fieldNames = reader.getFieldNames(IndexReader.FieldOption.ALL);\n        Iterator it = fieldNames.iterator();\n        while(it.hasNext()) {\n          final String fieldName = (String) it.next();\n          byte[] b = reader.norms(fieldName);\n          if (b.length != info.docCount)\n            throw new RuntimeException(\"norms for field \\\"\" + fieldName + \"\\\" is length \" + b.length + \" != maxDoc \" + info.docCount);\n\n        }\n        out.println(\"OK [\" + fieldNames.size() + \" fields]\");\n\n        out.print(\"    test: terms, freq, prox...\");\n        final TermEnum termEnum = reader.terms();\n        final TermPositions termPositions = reader.termPositions();\n\n        // Used only to count up # deleted docs for this\n        // term\n        final MySegmentTermDocs myTermDocs = new MySegmentTermDocs(reader);\n\n        long termCount = 0;\n        long totFreq = 0;\n        long totPos = 0;\n        while(termEnum.next()) {\n          termCount++;\n          final Term term = termEnum.term();\n          final int docFreq = termEnum.docFreq();\n          termPositions.seek(term);\n          int lastDoc = -1;\n          int freq0 = 0;\n          totFreq += docFreq;\n          while(termPositions.next()) {\n            freq0++;\n            final int doc = termPositions.doc();\n            final int freq = termPositions.freq();\n            if (doc <= lastDoc)\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" < lastDoc \" + lastDoc);\n            lastDoc = doc;\n            if (freq <= 0)\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" is out of bounds\");\n            \n            int lastPos = -1;\n            totPos += freq;\n            for(int j=0;j<freq;j++) {\n              final int pos = termPositions.nextPosition();\n              if (pos < -1 || (pos == -1 && !allowMinusOnePosition))\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" is out of bounds\");\n              if (pos < lastPos)\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" < lastPos \" + lastPos);\n            }\n          }\n\n          // Now count how many deleted docs occurred in\n          // this term:\n          final int delCount;\n          if (reader.hasDeletions()) {\n            myTermDocs.seek(term);\n            while(myTermDocs.next()) {\n            }\n            delCount = myTermDocs.delCount;\n          } else\n            delCount = 0;\n\n          if (freq0 + delCount != docFreq)\n            throw new RuntimeException(\"term \" + term + \" docFreq=\" + docFreq + \" != num docs seen \" + freq0 + \" + num docs deleted \" + delCount);\n        }\n\n        out.println(\"OK [\" + termCount + \" terms; \" + totFreq + \" terms/docs pairs; \" + totPos + \" tokens]\");\n\n        out.print(\"    test: stored fields.......\");\n        int docCount = 0;\n        long totFields = 0;\n        for(int j=0;j<info.docCount;j++)\n          if (!reader.isDeleted(j)) {\n            docCount++;\n            Document doc = reader.document(j);\n            totFields += doc.getFields().size();\n          }\n\n        if (docCount != reader.numDocs())\n          throw new RuntimeException(\"docCount=\" + docCount + \" but saw \" + docCount + \" undeleted docs\");\n\n        out.println(\"OK [\" + totFields + \" total field count; avg \" + nf.format((((float) totFields)/docCount)) + \" fields per doc]\");\n\n        out.print(\"    test: term vectors........\");\n        int totVectors = 0;\n        for(int j=0;j<info.docCount;j++)\n          if (!reader.isDeleted(j)) {\n            TermFreqVector[] tfv = reader.getTermFreqVectors(j);\n            if (tfv != null)\n              totVectors += tfv.length;\n          }\n\n        out.println(\"OK [\" + totVectors + \" total vector count; avg \" + nf.format((((float) totVectors)/docCount)) + \" term/freq vector fields per doc]\");\n        out.println(\"\");\n\n      } catch (Throwable t) {\n        out.println(\"FAILED\");\n        String comment;\n        if (doFix)\n          comment = \"will remove reference to this segment (-fix is specified)\";\n        else\n          comment = \"would remove reference to this segment (-fix was not specified)\";\n        out.println(\"    WARNING: \" + comment + \"; full exception:\");\n        t.printStackTrace(out);\n        out.println(\"\");\n        totLoseDocCount += toLoseDocCount;\n        numBadSegments++;\n        changed = true;\n        continue;\n      } finally {\n        if (reader != null)\n          reader.close();\n      }\n\n      // Keeper\n      newSIS.add(info.clone());\n    }\n\n    if (!changed) {\n      out.println(\"No problems were detected with this index.\\n\");\n      return true;\n    } else {\n      out.println(\"WARNING: \" + numBadSegments + \" broken segments detected\");\n      if (doFix)\n        out.println(\"WARNING: \" + totLoseDocCount + \" documents will be lost\");\n      else\n        out.println(\"WARNING: \" + totLoseDocCount + \" documents would be lost if -fix were specified\");\n      out.println();\n    }\n\n    if (doFix) {\n      out.println(\"NOTE: will write new segments file in 5 seconds; this will remove \" + totLoseDocCount + \" docs from the index. THIS IS YOUR LAST CHANCE TO CTRL+C!\");\n      for(int i=0;i<5;i++) {\n        try {\n          Thread.sleep(1000);\n        } catch (InterruptedException ie) {\n          Thread.currentThread().interrupt();\n          i--;\n          continue;\n        }\n          \n        out.println(\"  \" + (5-i) + \"...\");\n      }\n      out.print(\"Writing...\");\n      try {\n        newSIS.commit(dir);\n      } catch (Throwable t) {\n        out.println(\"FAILED; exiting\");\n        t.printStackTrace(out);\n        return false;\n      }\n      out.println(\"OK\");\n      out.println(\"Wrote new segments file \\\"\" + newSIS.getCurrentSegmentFileName() + \"\\\"\");\n    } else {\n      out.println(\"NOTE: would write new segments file [-fix was not specified]\");\n    }\n    out.println(\"\");\n\n    return false;\n  }\n\n","sourceOld":"  /** Returns true if index is clean, else false.*/\n  public static boolean check(Directory dir, boolean doFix, List onlySegments) throws IOException {\n    NumberFormat nf = NumberFormat.getInstance();\n    SegmentInfos sis = new SegmentInfos();\n    \n    try {\n      sis.read(dir);\n    } catch (Throwable t) {\n      out.println(\"ERROR: could not read any segments file in directory\");\n      t.printStackTrace(out);\n      return false;\n    }\n\n    final int numSegments = sis.size();\n    final String segmentsFileName = sis.getCurrentSegmentFileName();\n    IndexInput input = null;\n    try {\n      input = dir.openInput(segmentsFileName);\n    } catch (Throwable t) {\n      out.println(\"ERROR: could not open segments file in directory\");\n      t.printStackTrace(out);\n      return false;\n    }\n    int format = 0;\n    try {\n      format = input.readInt();\n    } catch (Throwable t) {\n      out.println(\"ERROR: could not read segment file version in directory\");\n      t.printStackTrace(out);\n      return false;\n    } finally {\n      if (input != null)\n        input.close();\n    }\n\n    String sFormat = \"\";\n    boolean skip = false;\n    boolean allowMinusOnePosition = true;\n\n    if (format == SegmentInfos.FORMAT)\n      sFormat = \"FORMAT [Lucene Pre-2.1]\";\n    if (format == SegmentInfos.FORMAT_LOCKLESS)\n      sFormat = \"FORMAT_LOCKLESS [Lucene 2.1]\";\n    else if (format == SegmentInfos.FORMAT_SINGLE_NORM_FILE)\n      sFormat = \"FORMAT_SINGLE_NORM_FILE [Lucene 2.2]\";\n    else if (format == SegmentInfos.FORMAT_SHARED_DOC_STORE)\n      sFormat = \"FORMAT_SHARED_DOC_STORE [Lucene 2.3]\";\n    else {\n      // LUCENE-1255: All versions before 2.3.2/2.4 were\n      // able to create position=-1 when the very first\n      // Token has positionIncrement 0\n      allowMinusOnePosition = false;\n      if (format == SegmentInfos.FORMAT_CHECKSUM) {\n        sFormat = \"FORMAT_CHECKSUM [Lucene 2.4]\";\n      } else if (format < SegmentInfos.FORMAT_CHECKSUM) {\n        sFormat = \"int=\" + format + \" [newer version of Lucene than this tool]\";\n        skip = true;\n      } else {\n        sFormat = format + \" [Lucene 1.3 or prior]\";\n      }\n    }\n\n    out.println(\"Segments file=\" + segmentsFileName + \" numSegments=\" + numSegments + \" version=\" + sFormat);\n\n    if (onlySegments != null) {\n      out.print(\"\\nChecking only these segments:\");\n      Iterator it = onlySegments.iterator();\n      while (it.hasNext()) {\n        out.print(\" \" + it.next());\n      }\n      out.println(\":\");\n    }\n\n    if (skip) {\n      out.println(\"\\nERROR: this index appears to be created by a newer version of Lucene than this tool was compiled on; please re-compile this tool on the matching version of Lucene; exiting\");\n      return false;\n    }\n\n    SegmentInfos newSIS = (SegmentInfos) sis.clone();\n    newSIS.clear();\n    boolean changed = false;\n    int totLoseDocCount = 0;\n    int numBadSegments = 0;\n    for(int i=0;i<numSegments;i++) {\n      final SegmentInfo info = sis.info(i);\n      if (onlySegments != null && !onlySegments.contains(info.name))\n        continue;\n      out.println(\"  \" + (1+i) + \" of \" + numSegments + \": name=\" + info.name + \" docCount=\" + info.docCount);\n      int toLoseDocCount = info.docCount;\n\n      SegmentReader reader = null;\n\n      try {\n        out.println(\"    compound=\" + info.getUseCompoundFile());\n        out.println(\"    numFiles=\" + info.files().size());\n        out.println(\"    size (MB)=\" + nf.format(info.sizeInBytes()/(1024.*1024.)));\n        final int docStoreOffset = info.getDocStoreOffset();\n        if (docStoreOffset != -1) {\n          out.println(\"    docStoreOffset=\" + docStoreOffset);\n          out.println(\"    docStoreSegment=\" + info.getDocStoreSegment());\n          out.println(\"    docStoreIsCompoundFile=\" + info.getDocStoreIsCompoundFile());\n        }\n        final String delFileName = info.getDelFileName();\n        if (delFileName == null)\n          out.println(\"    no deletions\");\n        else\n          out.println(\"    has deletions [delFileName=\" + delFileName + \"]\");\n        out.print(\"    test: open reader.........\");\n        reader = SegmentReader.get(info);\n        final int numDocs = reader.numDocs();\n        toLoseDocCount = numDocs;\n        if (reader.hasDeletions())\n          out.println(\"OK [\" + (info.docCount - numDocs) + \" deleted docs]\");\n        else\n          out.println(\"OK\");\n\n        out.print(\"    test: fields, norms.......\");\n        Collection fieldNames = reader.getFieldNames(IndexReader.FieldOption.ALL);\n        Iterator it = fieldNames.iterator();\n        while(it.hasNext()) {\n          final String fieldName = (String) it.next();\n          byte[] b = reader.norms(fieldName);\n          if (b.length != info.docCount)\n            throw new RuntimeException(\"norms for field \\\"\" + fieldName + \"\\\" is length \" + b.length + \" != maxDoc \" + info.docCount);\n\n        }\n        out.println(\"OK [\" + fieldNames.size() + \" fields]\");\n\n        out.print(\"    test: terms, freq, prox...\");\n        final TermEnum termEnum = reader.terms();\n        final TermPositions termPositions = reader.termPositions();\n\n        // Used only to count up # deleted docs for this\n        // term\n        final MySegmentTermDocs myTermDocs = new MySegmentTermDocs(reader);\n\n        long termCount = 0;\n        long totFreq = 0;\n        long totPos = 0;\n        while(termEnum.next()) {\n          termCount++;\n          final Term term = termEnum.term();\n          final int docFreq = termEnum.docFreq();\n          termPositions.seek(term);\n          int lastDoc = -1;\n          int freq0 = 0;\n          totFreq += docFreq;\n          while(termPositions.next()) {\n            freq0++;\n            final int doc = termPositions.doc();\n            final int freq = termPositions.freq();\n            if (doc <= lastDoc)\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" < lastDoc \" + lastDoc);\n            lastDoc = doc;\n            if (freq <= 0)\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" is out of bounds\");\n            \n            int lastPos = -1;\n            totPos += freq;\n            for(int j=0;j<freq;j++) {\n              final int pos = termPositions.nextPosition();\n              if (pos < -1 || (pos == -1 && !allowMinusOnePosition))\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" is out of bounds\");\n              if (pos < lastPos)\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" < lastPos \" + lastPos);\n            }\n          }\n\n          // Now count how many deleted docs occurred in\n          // this term:\n          final int delCount;\n          if (reader.hasDeletions()) {\n            myTermDocs.seek(term);\n            while(myTermDocs.next()) {\n            }\n            delCount = myTermDocs.delCount;\n          } else\n            delCount = 0;\n\n          if (freq0 + delCount != docFreq)\n            throw new RuntimeException(\"term \" + term + \" docFreq=\" + docFreq + \" != num docs seen \" + freq0 + \" + num docs deleted \" + delCount);\n        }\n\n        out.println(\"OK [\" + termCount + \" terms; \" + totFreq + \" terms/docs pairs; \" + totPos + \" tokens]\");\n\n        out.print(\"    test: stored fields.......\");\n        int docCount = 0;\n        long totFields = 0;\n        for(int j=0;j<info.docCount;j++)\n          if (!reader.isDeleted(j)) {\n            docCount++;\n            Document doc = reader.document(j);\n            totFields += doc.getFields().size();\n          }\n\n        if (docCount != reader.numDocs())\n          throw new RuntimeException(\"docCount=\" + docCount + \" but saw \" + docCount + \" undeleted docs\");\n\n        out.println(\"OK [\" + totFields + \" total field count; avg \" + nf.format((((float) totFields)/docCount)) + \" fields per doc]\");\n\n        out.print(\"    test: term vectors........\");\n        int totVectors = 0;\n        for(int j=0;j<info.docCount;j++)\n          if (!reader.isDeleted(j)) {\n            TermFreqVector[] tfv = reader.getTermFreqVectors(j);\n            if (tfv != null)\n              totVectors += tfv.length;\n          }\n\n        out.println(\"OK [\" + totVectors + \" total vector count; avg \" + nf.format((((float) totVectors)/docCount)) + \" term/freq vector fields per doc]\");\n        out.println(\"\");\n\n      } catch (Throwable t) {\n        out.println(\"FAILED\");\n        String comment;\n        if (doFix)\n          comment = \"will remove reference to this segment (-fix is specified)\";\n        else\n          comment = \"would remove reference to this segment (-fix was not specified)\";\n        out.println(\"    WARNING: \" + comment + \"; full exception:\");\n        t.printStackTrace(out);\n        out.println(\"\");\n        totLoseDocCount += toLoseDocCount;\n        numBadSegments++;\n        changed = true;\n        continue;\n      } finally {\n        if (reader != null)\n          reader.close();\n      }\n\n      // Keeper\n      newSIS.add(info.clone());\n    }\n\n    if (!changed) {\n      out.println(\"No problems were detected with this index.\\n\");\n      return true;\n    } else {\n      out.println(\"WARNING: \" + numBadSegments + \" broken segments detected\");\n      if (doFix)\n        out.println(\"WARNING: \" + totLoseDocCount + \" documents will be lost\");\n      else\n        out.println(\"WARNING: \" + totLoseDocCount + \" documents would be lost if -fix were specified\");\n      out.println();\n    }\n\n    if (doFix) {\n      out.println(\"NOTE: will write new segments file in 5 seconds; this will remove \" + totLoseDocCount + \" docs from the index. THIS IS YOUR LAST CHANCE TO CTRL+C!\");\n      for(int i=0;i<5;i++) {\n        try {\n          Thread.sleep(1000);\n        } catch (InterruptedException ie) {\n          Thread.currentThread().interrupt();\n          i--;\n          continue;\n        }\n          \n        out.println(\"  \" + (5-i) + \"...\");\n      }\n      out.print(\"Writing...\");\n      try {\n        newSIS.commit(dir);\n      } catch (Throwable t) {\n        out.println(\"FAILED; exiting\");\n        t.printStackTrace(out);\n        return false;\n      }\n      out.println(\"OK\");\n      out.println(\"Wrote new segments file \\\"\" + newSIS.getCurrentSegmentFileName() + \"\\\"\");\n    } else {\n      out.println(\"NOTE: would write new segments file [-fix was not specified]\");\n    }\n    out.println(\"\");\n\n    return false;\n  }\n\n","bugFix":null,"bugIntro":["7391c1f4ab1a6817de8a262f5c1b3de3cf190785"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"abfdd5170b43f046dfac9dafd6e12c1a65f3018c","date":1209502915,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/CheckIndex#check(Directory,boolean,List).mjava","pathOld":"src/java/org/apache/lucene/index/CheckIndex#check(Directory,boolean,List).mjava","sourceNew":"  /** Returns true if index is clean, else false.*/\n  public static boolean check(Directory dir, boolean doFix, List onlySegments) throws IOException {\n    NumberFormat nf = NumberFormat.getInstance();\n    SegmentInfos sis = new SegmentInfos();\n    \n    try {\n      sis.read(dir);\n    } catch (Throwable t) {\n      out.println(\"ERROR: could not read any segments file in directory\");\n      t.printStackTrace(out);\n      return false;\n    }\n\n    final int numSegments = sis.size();\n    final String segmentsFileName = sis.getCurrentSegmentFileName();\n    IndexInput input = null;\n    try {\n      input = dir.openInput(segmentsFileName);\n    } catch (Throwable t) {\n      out.println(\"ERROR: could not open segments file in directory\");\n      t.printStackTrace(out);\n      return false;\n    }\n    int format = 0;\n    try {\n      format = input.readInt();\n    } catch (Throwable t) {\n      out.println(\"ERROR: could not read segment file version in directory\");\n      t.printStackTrace(out);\n      return false;\n    } finally {\n      if (input != null)\n        input.close();\n    }\n\n    String sFormat = \"\";\n    boolean skip = false;\n\n    if (format == SegmentInfos.FORMAT)\n      sFormat = \"FORMAT [Lucene Pre-2.1]\";\n    if (format == SegmentInfos.FORMAT_LOCKLESS)\n      sFormat = \"FORMAT_LOCKLESS [Lucene 2.1]\";\n    else if (format == SegmentInfos.FORMAT_SINGLE_NORM_FILE)\n      sFormat = \"FORMAT_SINGLE_NORM_FILE [Lucene 2.2]\";\n    else if (format == SegmentInfos.FORMAT_SHARED_DOC_STORE)\n      sFormat = \"FORMAT_SHARED_DOC_STORE [Lucene 2.3]\";\n    else {\n      // LUCENE-1255: All versions before 2.3.2/2.4 were\n      // able to create position=-1 when the very first\n      // Token has positionIncrement 0\n      if (format == SegmentInfos.FORMAT_CHECKSUM)\n        sFormat = \"FORMAT_CHECKSUM [Lucene 2.4]\";\n      else if (format == SegmentInfos.FORMAT_DEL_COUNT)\n          sFormat = \"FORMAT_DEL_COUNT [Lucene 2.4]\";\n      else if (format < SegmentInfos.CURRENT_FORMAT) {\n        sFormat = \"int=\" + format + \" [newer version of Lucene than this tool]\";\n        skip = true;\n      } else {\n        sFormat = format + \" [Lucene 1.3 or prior]\";\n      }\n    }\n\n    out.println(\"Segments file=\" + segmentsFileName + \" numSegments=\" + numSegments + \" version=\" + sFormat);\n\n    if (onlySegments != null) {\n      out.print(\"\\nChecking only these segments:\");\n      Iterator it = onlySegments.iterator();\n      while (it.hasNext()) {\n        out.print(\" \" + it.next());\n      }\n      out.println(\":\");\n    }\n\n    if (skip) {\n      out.println(\"\\nERROR: this index appears to be created by a newer version of Lucene than this tool was compiled on; please re-compile this tool on the matching version of Lucene; exiting\");\n      return false;\n    }\n\n    SegmentInfos newSIS = (SegmentInfos) sis.clone();\n    newSIS.clear();\n    boolean changed = false;\n    int totLoseDocCount = 0;\n    int numBadSegments = 0;\n    for(int i=0;i<numSegments;i++) {\n      final SegmentInfo info = sis.info(i);\n      if (onlySegments != null && !onlySegments.contains(info.name))\n        continue;\n      out.println(\"  \" + (1+i) + \" of \" + numSegments + \": name=\" + info.name + \" docCount=\" + info.docCount);\n      int toLoseDocCount = info.docCount;\n\n      SegmentReader reader = null;\n\n      try {\n        out.println(\"    compound=\" + info.getUseCompoundFile());\n        out.println(\"    numFiles=\" + info.files().size());\n        out.println(\"    size (MB)=\" + nf.format(info.sizeInBytes()/(1024.*1024.)));\n        final int docStoreOffset = info.getDocStoreOffset();\n        if (docStoreOffset != -1) {\n          out.println(\"    docStoreOffset=\" + docStoreOffset);\n          out.println(\"    docStoreSegment=\" + info.getDocStoreSegment());\n          out.println(\"    docStoreIsCompoundFile=\" + info.getDocStoreIsCompoundFile());\n        }\n        final String delFileName = info.getDelFileName();\n        if (delFileName == null)\n          out.println(\"    no deletions\");\n        else\n          out.println(\"    has deletions [delFileName=\" + delFileName + \"]\");\n        out.print(\"    test: open reader.........\");\n        reader = SegmentReader.get(info);\n        final int numDocs = reader.numDocs();\n        toLoseDocCount = numDocs;\n        if (reader.hasDeletions()) {\n          if (info.docCount - numDocs != info.getDelCount())\n            throw new RuntimeException(\"delete count mismatch: info=\" + info.getDelCount() + \" vs reader=\" + (info.docCount - numDocs));\n          out.println(\"OK [\" + (info.docCount - numDocs) + \" deleted docs]\");\n        } else {\n          if (info.getDelCount() != 0)\n            throw new RuntimeException(\"delete count mismatch: info=\" + info.getDelCount() + \" vs reader=\" + (info.docCount - numDocs));\n          out.println(\"OK\");\n        }\n\n        out.print(\"    test: fields, norms.......\");\n        Collection fieldNames = reader.getFieldNames(IndexReader.FieldOption.ALL);\n        Iterator it = fieldNames.iterator();\n        while(it.hasNext()) {\n          final String fieldName = (String) it.next();\n          byte[] b = reader.norms(fieldName);\n          if (b.length != info.docCount)\n            throw new RuntimeException(\"norms for field \\\"\" + fieldName + \"\\\" is length \" + b.length + \" != maxDoc \" + info.docCount);\n\n        }\n        out.println(\"OK [\" + fieldNames.size() + \" fields]\");\n\n        out.print(\"    test: terms, freq, prox...\");\n        final TermEnum termEnum = reader.terms();\n        final TermPositions termPositions = reader.termPositions();\n\n        // Used only to count up # deleted docs for this\n        // term\n        final MySegmentTermDocs myTermDocs = new MySegmentTermDocs(reader);\n\n        long termCount = 0;\n        long totFreq = 0;\n        long totPos = 0;\n        while(termEnum.next()) {\n          termCount++;\n          final Term term = termEnum.term();\n          final int docFreq = termEnum.docFreq();\n          termPositions.seek(term);\n          int lastDoc = -1;\n          int freq0 = 0;\n          totFreq += docFreq;\n          while(termPositions.next()) {\n            freq0++;\n            final int doc = termPositions.doc();\n            final int freq = termPositions.freq();\n            if (doc <= lastDoc)\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" < lastDoc \" + lastDoc);\n            lastDoc = doc;\n            if (freq <= 0)\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" is out of bounds\");\n            \n            int lastPos = -1;\n            totPos += freq;\n            for(int j=0;j<freq;j++) {\n              final int pos = termPositions.nextPosition();\n              if (pos < -1)\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" is out of bounds\");\n              if (pos < lastPos)\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" < lastPos \" + lastPos);\n            }\n          }\n\n          // Now count how many deleted docs occurred in\n          // this term:\n          final int delCount;\n          if (reader.hasDeletions()) {\n            myTermDocs.seek(term);\n            while(myTermDocs.next()) {\n            }\n            delCount = myTermDocs.delCount;\n          } else\n            delCount = 0;\n\n          if (freq0 + delCount != docFreq)\n            throw new RuntimeException(\"term \" + term + \" docFreq=\" + docFreq + \" != num docs seen \" + freq0 + \" + num docs deleted \" + delCount);\n        }\n\n        out.println(\"OK [\" + termCount + \" terms; \" + totFreq + \" terms/docs pairs; \" + totPos + \" tokens]\");\n\n        out.print(\"    test: stored fields.......\");\n        int docCount = 0;\n        long totFields = 0;\n        for(int j=0;j<info.docCount;j++)\n          if (!reader.isDeleted(j)) {\n            docCount++;\n            Document doc = reader.document(j);\n            totFields += doc.getFields().size();\n          }\n\n        if (docCount != reader.numDocs())\n          throw new RuntimeException(\"docCount=\" + docCount + \" but saw \" + docCount + \" undeleted docs\");\n\n        out.println(\"OK [\" + totFields + \" total field count; avg \" + nf.format((((float) totFields)/docCount)) + \" fields per doc]\");\n\n        out.print(\"    test: term vectors........\");\n        int totVectors = 0;\n        for(int j=0;j<info.docCount;j++)\n          if (!reader.isDeleted(j)) {\n            TermFreqVector[] tfv = reader.getTermFreqVectors(j);\n            if (tfv != null)\n              totVectors += tfv.length;\n          }\n\n        out.println(\"OK [\" + totVectors + \" total vector count; avg \" + nf.format((((float) totVectors)/docCount)) + \" term/freq vector fields per doc]\");\n        out.println(\"\");\n\n      } catch (Throwable t) {\n        out.println(\"FAILED\");\n        String comment;\n        if (doFix)\n          comment = \"will remove reference to this segment (-fix is specified)\";\n        else\n          comment = \"would remove reference to this segment (-fix was not specified)\";\n        out.println(\"    WARNING: \" + comment + \"; full exception:\");\n        t.printStackTrace(out);\n        out.println(\"\");\n        totLoseDocCount += toLoseDocCount;\n        numBadSegments++;\n        changed = true;\n        continue;\n      } finally {\n        if (reader != null)\n          reader.close();\n      }\n\n      // Keeper\n      newSIS.add(info.clone());\n    }\n\n    if (!changed) {\n      out.println(\"No problems were detected with this index.\\n\");\n      return true;\n    } else {\n      out.println(\"WARNING: \" + numBadSegments + \" broken segments detected\");\n      if (doFix)\n        out.println(\"WARNING: \" + totLoseDocCount + \" documents will be lost\");\n      else\n        out.println(\"WARNING: \" + totLoseDocCount + \" documents would be lost if -fix were specified\");\n      out.println();\n    }\n\n    if (doFix) {\n      out.println(\"NOTE: will write new segments file in 5 seconds; this will remove \" + totLoseDocCount + \" docs from the index. THIS IS YOUR LAST CHANCE TO CTRL+C!\");\n      for(int i=0;i<5;i++) {\n        try {\n          Thread.sleep(1000);\n        } catch (InterruptedException ie) {\n          Thread.currentThread().interrupt();\n          i--;\n          continue;\n        }\n          \n        out.println(\"  \" + (5-i) + \"...\");\n      }\n      out.print(\"Writing...\");\n      try {\n        newSIS.commit(dir);\n      } catch (Throwable t) {\n        out.println(\"FAILED; exiting\");\n        t.printStackTrace(out);\n        return false;\n      }\n      out.println(\"OK\");\n      out.println(\"Wrote new segments file \\\"\" + newSIS.getCurrentSegmentFileName() + \"\\\"\");\n    } else {\n      out.println(\"NOTE: would write new segments file [-fix was not specified]\");\n    }\n    out.println(\"\");\n\n    return false;\n  }\n\n","sourceOld":"  /** Returns true if index is clean, else false.*/\n  public static boolean check(Directory dir, boolean doFix, List onlySegments) throws IOException {\n    NumberFormat nf = NumberFormat.getInstance();\n    SegmentInfos sis = new SegmentInfos();\n    \n    try {\n      sis.read(dir);\n    } catch (Throwable t) {\n      out.println(\"ERROR: could not read any segments file in directory\");\n      t.printStackTrace(out);\n      return false;\n    }\n\n    final int numSegments = sis.size();\n    final String segmentsFileName = sis.getCurrentSegmentFileName();\n    IndexInput input = null;\n    try {\n      input = dir.openInput(segmentsFileName);\n    } catch (Throwable t) {\n      out.println(\"ERROR: could not open segments file in directory\");\n      t.printStackTrace(out);\n      return false;\n    }\n    int format = 0;\n    try {\n      format = input.readInt();\n    } catch (Throwable t) {\n      out.println(\"ERROR: could not read segment file version in directory\");\n      t.printStackTrace(out);\n      return false;\n    } finally {\n      if (input != null)\n        input.close();\n    }\n\n    String sFormat = \"\";\n    boolean skip = false;\n    boolean allowMinusOnePosition = true;\n\n    if (format == SegmentInfos.FORMAT)\n      sFormat = \"FORMAT [Lucene Pre-2.1]\";\n    if (format == SegmentInfos.FORMAT_LOCKLESS)\n      sFormat = \"FORMAT_LOCKLESS [Lucene 2.1]\";\n    else if (format == SegmentInfos.FORMAT_SINGLE_NORM_FILE)\n      sFormat = \"FORMAT_SINGLE_NORM_FILE [Lucene 2.2]\";\n    else if (format == SegmentInfos.FORMAT_SHARED_DOC_STORE)\n      sFormat = \"FORMAT_SHARED_DOC_STORE [Lucene 2.3]\";\n    else {\n      // LUCENE-1255: All versions before 2.3.2/2.4 were\n      // able to create position=-1 when the very first\n      // Token has positionIncrement 0\n      allowMinusOnePosition = false;\n      if (format == SegmentInfos.FORMAT_CHECKSUM)\n        sFormat = \"FORMAT_CHECKSUM [Lucene 2.4]\";\n      else if (format == SegmentInfos.FORMAT_DEL_COUNT)\n          sFormat = \"FORMAT_DEL_COUNT [Lucene 2.4]\";\n      else if (format < SegmentInfos.CURRENT_FORMAT) {\n        sFormat = \"int=\" + format + \" [newer version of Lucene than this tool]\";\n        skip = true;\n      } else {\n        sFormat = format + \" [Lucene 1.3 or prior]\";\n      }\n    }\n\n    out.println(\"Segments file=\" + segmentsFileName + \" numSegments=\" + numSegments + \" version=\" + sFormat);\n\n    if (onlySegments != null) {\n      out.print(\"\\nChecking only these segments:\");\n      Iterator it = onlySegments.iterator();\n      while (it.hasNext()) {\n        out.print(\" \" + it.next());\n      }\n      out.println(\":\");\n    }\n\n    if (skip) {\n      out.println(\"\\nERROR: this index appears to be created by a newer version of Lucene than this tool was compiled on; please re-compile this tool on the matching version of Lucene; exiting\");\n      return false;\n    }\n\n    SegmentInfos newSIS = (SegmentInfos) sis.clone();\n    newSIS.clear();\n    boolean changed = false;\n    int totLoseDocCount = 0;\n    int numBadSegments = 0;\n    for(int i=0;i<numSegments;i++) {\n      final SegmentInfo info = sis.info(i);\n      if (onlySegments != null && !onlySegments.contains(info.name))\n        continue;\n      out.println(\"  \" + (1+i) + \" of \" + numSegments + \": name=\" + info.name + \" docCount=\" + info.docCount);\n      int toLoseDocCount = info.docCount;\n\n      SegmentReader reader = null;\n\n      try {\n        out.println(\"    compound=\" + info.getUseCompoundFile());\n        out.println(\"    numFiles=\" + info.files().size());\n        out.println(\"    size (MB)=\" + nf.format(info.sizeInBytes()/(1024.*1024.)));\n        final int docStoreOffset = info.getDocStoreOffset();\n        if (docStoreOffset != -1) {\n          out.println(\"    docStoreOffset=\" + docStoreOffset);\n          out.println(\"    docStoreSegment=\" + info.getDocStoreSegment());\n          out.println(\"    docStoreIsCompoundFile=\" + info.getDocStoreIsCompoundFile());\n        }\n        final String delFileName = info.getDelFileName();\n        if (delFileName == null)\n          out.println(\"    no deletions\");\n        else\n          out.println(\"    has deletions [delFileName=\" + delFileName + \"]\");\n        out.print(\"    test: open reader.........\");\n        reader = SegmentReader.get(info);\n        final int numDocs = reader.numDocs();\n        toLoseDocCount = numDocs;\n        if (reader.hasDeletions()) {\n          if (info.docCount - numDocs != info.getDelCount())\n            throw new RuntimeException(\"delete count mismatch: info=\" + info.getDelCount() + \" vs reader=\" + (info.docCount - numDocs));\n          out.println(\"OK [\" + (info.docCount - numDocs) + \" deleted docs]\");\n        } else {\n          if (info.getDelCount() != 0)\n            throw new RuntimeException(\"delete count mismatch: info=\" + info.getDelCount() + \" vs reader=\" + (info.docCount - numDocs));\n          out.println(\"OK\");\n        }\n\n        out.print(\"    test: fields, norms.......\");\n        Collection fieldNames = reader.getFieldNames(IndexReader.FieldOption.ALL);\n        Iterator it = fieldNames.iterator();\n        while(it.hasNext()) {\n          final String fieldName = (String) it.next();\n          byte[] b = reader.norms(fieldName);\n          if (b.length != info.docCount)\n            throw new RuntimeException(\"norms for field \\\"\" + fieldName + \"\\\" is length \" + b.length + \" != maxDoc \" + info.docCount);\n\n        }\n        out.println(\"OK [\" + fieldNames.size() + \" fields]\");\n\n        out.print(\"    test: terms, freq, prox...\");\n        final TermEnum termEnum = reader.terms();\n        final TermPositions termPositions = reader.termPositions();\n\n        // Used only to count up # deleted docs for this\n        // term\n        final MySegmentTermDocs myTermDocs = new MySegmentTermDocs(reader);\n\n        long termCount = 0;\n        long totFreq = 0;\n        long totPos = 0;\n        while(termEnum.next()) {\n          termCount++;\n          final Term term = termEnum.term();\n          final int docFreq = termEnum.docFreq();\n          termPositions.seek(term);\n          int lastDoc = -1;\n          int freq0 = 0;\n          totFreq += docFreq;\n          while(termPositions.next()) {\n            freq0++;\n            final int doc = termPositions.doc();\n            final int freq = termPositions.freq();\n            if (doc <= lastDoc)\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" < lastDoc \" + lastDoc);\n            lastDoc = doc;\n            if (freq <= 0)\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" is out of bounds\");\n            \n            int lastPos = -1;\n            totPos += freq;\n            for(int j=0;j<freq;j++) {\n              final int pos = termPositions.nextPosition();\n              if (pos < -1 || (pos == -1 && !allowMinusOnePosition))\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" is out of bounds\");\n              if (pos < lastPos)\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" < lastPos \" + lastPos);\n            }\n          }\n\n          // Now count how many deleted docs occurred in\n          // this term:\n          final int delCount;\n          if (reader.hasDeletions()) {\n            myTermDocs.seek(term);\n            while(myTermDocs.next()) {\n            }\n            delCount = myTermDocs.delCount;\n          } else\n            delCount = 0;\n\n          if (freq0 + delCount != docFreq)\n            throw new RuntimeException(\"term \" + term + \" docFreq=\" + docFreq + \" != num docs seen \" + freq0 + \" + num docs deleted \" + delCount);\n        }\n\n        out.println(\"OK [\" + termCount + \" terms; \" + totFreq + \" terms/docs pairs; \" + totPos + \" tokens]\");\n\n        out.print(\"    test: stored fields.......\");\n        int docCount = 0;\n        long totFields = 0;\n        for(int j=0;j<info.docCount;j++)\n          if (!reader.isDeleted(j)) {\n            docCount++;\n            Document doc = reader.document(j);\n            totFields += doc.getFields().size();\n          }\n\n        if (docCount != reader.numDocs())\n          throw new RuntimeException(\"docCount=\" + docCount + \" but saw \" + docCount + \" undeleted docs\");\n\n        out.println(\"OK [\" + totFields + \" total field count; avg \" + nf.format((((float) totFields)/docCount)) + \" fields per doc]\");\n\n        out.print(\"    test: term vectors........\");\n        int totVectors = 0;\n        for(int j=0;j<info.docCount;j++)\n          if (!reader.isDeleted(j)) {\n            TermFreqVector[] tfv = reader.getTermFreqVectors(j);\n            if (tfv != null)\n              totVectors += tfv.length;\n          }\n\n        out.println(\"OK [\" + totVectors + \" total vector count; avg \" + nf.format((((float) totVectors)/docCount)) + \" term/freq vector fields per doc]\");\n        out.println(\"\");\n\n      } catch (Throwable t) {\n        out.println(\"FAILED\");\n        String comment;\n        if (doFix)\n          comment = \"will remove reference to this segment (-fix is specified)\";\n        else\n          comment = \"would remove reference to this segment (-fix was not specified)\";\n        out.println(\"    WARNING: \" + comment + \"; full exception:\");\n        t.printStackTrace(out);\n        out.println(\"\");\n        totLoseDocCount += toLoseDocCount;\n        numBadSegments++;\n        changed = true;\n        continue;\n      } finally {\n        if (reader != null)\n          reader.close();\n      }\n\n      // Keeper\n      newSIS.add(info.clone());\n    }\n\n    if (!changed) {\n      out.println(\"No problems were detected with this index.\\n\");\n      return true;\n    } else {\n      out.println(\"WARNING: \" + numBadSegments + \" broken segments detected\");\n      if (doFix)\n        out.println(\"WARNING: \" + totLoseDocCount + \" documents will be lost\");\n      else\n        out.println(\"WARNING: \" + totLoseDocCount + \" documents would be lost if -fix were specified\");\n      out.println();\n    }\n\n    if (doFix) {\n      out.println(\"NOTE: will write new segments file in 5 seconds; this will remove \" + totLoseDocCount + \" docs from the index. THIS IS YOUR LAST CHANCE TO CTRL+C!\");\n      for(int i=0;i<5;i++) {\n        try {\n          Thread.sleep(1000);\n        } catch (InterruptedException ie) {\n          Thread.currentThread().interrupt();\n          i--;\n          continue;\n        }\n          \n        out.println(\"  \" + (5-i) + \"...\");\n      }\n      out.print(\"Writing...\");\n      try {\n        newSIS.commit(dir);\n      } catch (Throwable t) {\n        out.println(\"FAILED; exiting\");\n        t.printStackTrace(out);\n        return false;\n      }\n      out.println(\"OK\");\n      out.println(\"Wrote new segments file \\\"\" + newSIS.getCurrentSegmentFileName() + \"\\\"\");\n    } else {\n      out.println(\"NOTE: would write new segments file [-fix was not specified]\");\n    }\n    out.println(\"\");\n\n    return false;\n  }\n\n","bugFix":["9cb1313e01866149ff8dde7e80345a5476de305e"],"bugIntro":["7391c1f4ab1a6817de8a262f5c1b3de3cf190785"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"902ba79f4590a41c663c447756d2e5041cbbdda9","date":1217956662,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/CheckIndex#check(Directory,boolean,List).mjava","pathOld":"src/java/org/apache/lucene/index/CheckIndex#check(Directory,boolean,List).mjava","sourceNew":"  /** Returns true if index is clean, else false.*/\n  public static boolean check(Directory dir, boolean doFix, List onlySegments) throws IOException {\n    NumberFormat nf = NumberFormat.getInstance();\n    SegmentInfos sis = new SegmentInfos();\n    \n    try {\n      sis.read(dir);\n    } catch (Throwable t) {\n      out.println(\"ERROR: could not read any segments file in directory\");\n      t.printStackTrace(out);\n      return false;\n    }\n\n    final int numSegments = sis.size();\n    final String segmentsFileName = sis.getCurrentSegmentFileName();\n    IndexInput input = null;\n    try {\n      input = dir.openInput(segmentsFileName);\n    } catch (Throwable t) {\n      out.println(\"ERROR: could not open segments file in directory\");\n      t.printStackTrace(out);\n      return false;\n    }\n    int format = 0;\n    try {\n      format = input.readInt();\n    } catch (Throwable t) {\n      out.println(\"ERROR: could not read segment file version in directory\");\n      t.printStackTrace(out);\n      return false;\n    } finally {\n      if (input != null)\n        input.close();\n    }\n\n    String sFormat = \"\";\n    boolean skip = false;\n\n    if (format == SegmentInfos.FORMAT)\n      sFormat = \"FORMAT [Lucene Pre-2.1]\";\n    if (format == SegmentInfos.FORMAT_LOCKLESS)\n      sFormat = \"FORMAT_LOCKLESS [Lucene 2.1]\";\n    else if (format == SegmentInfos.FORMAT_SINGLE_NORM_FILE)\n      sFormat = \"FORMAT_SINGLE_NORM_FILE [Lucene 2.2]\";\n    else if (format == SegmentInfos.FORMAT_SHARED_DOC_STORE)\n      sFormat = \"FORMAT_SHARED_DOC_STORE [Lucene 2.3]\";\n    else {\n      if (format == SegmentInfos.FORMAT_CHECKSUM)\n        sFormat = \"FORMAT_CHECKSUM [Lucene 2.4]\";\n      else if (format == SegmentInfos.FORMAT_DEL_COUNT)\n        sFormat = \"FORMAT_DEL_COUNT [Lucene 2.4]\";\n      else if (format == SegmentInfos.FORMAT_HAS_PROX)\n        sFormat = \"FORMAT_HAS_PROX [Lucene 2.4]\";\n      else if (format < SegmentInfos.CURRENT_FORMAT) {\n        sFormat = \"int=\" + format + \" [newer version of Lucene than this tool]\";\n        skip = true;\n      } else {\n        sFormat = format + \" [Lucene 1.3 or prior]\";\n      }\n    }\n\n    out.println(\"Segments file=\" + segmentsFileName + \" numSegments=\" + numSegments + \" version=\" + sFormat);\n\n    if (onlySegments != null) {\n      out.print(\"\\nChecking only these segments:\");\n      Iterator it = onlySegments.iterator();\n      while (it.hasNext()) {\n        out.print(\" \" + it.next());\n      }\n      out.println(\":\");\n    }\n\n    if (skip) {\n      out.println(\"\\nERROR: this index appears to be created by a newer version of Lucene than this tool was compiled on; please re-compile this tool on the matching version of Lucene; exiting\");\n      return false;\n    }\n\n    SegmentInfos newSIS = (SegmentInfos) sis.clone();\n    newSIS.clear();\n    boolean changed = false;\n    int totLoseDocCount = 0;\n    int numBadSegments = 0;\n    for(int i=0;i<numSegments;i++) {\n      final SegmentInfo info = sis.info(i);\n      if (onlySegments != null && !onlySegments.contains(info.name))\n        continue;\n      out.println(\"  \" + (1+i) + \" of \" + numSegments + \": name=\" + info.name + \" docCount=\" + info.docCount);\n      int toLoseDocCount = info.docCount;\n\n      SegmentReader reader = null;\n\n      try {\n        out.println(\"    compound=\" + info.getUseCompoundFile());\n        out.println(\"    hasProx=\" + info.getHasProx());\n        out.println(\"    numFiles=\" + info.files().size());\n        out.println(\"    size (MB)=\" + nf.format(info.sizeInBytes()/(1024.*1024.)));\n        final int docStoreOffset = info.getDocStoreOffset();\n        if (docStoreOffset != -1) {\n          out.println(\"    docStoreOffset=\" + docStoreOffset);\n          out.println(\"    docStoreSegment=\" + info.getDocStoreSegment());\n          out.println(\"    docStoreIsCompoundFile=\" + info.getDocStoreIsCompoundFile());\n        }\n        final String delFileName = info.getDelFileName();\n        if (delFileName == null)\n          out.println(\"    no deletions\");\n        else\n          out.println(\"    has deletions [delFileName=\" + delFileName + \"]\");\n        out.print(\"    test: open reader.........\");\n        reader = SegmentReader.get(info);\n        final int numDocs = reader.numDocs();\n        toLoseDocCount = numDocs;\n        if (reader.hasDeletions()) {\n          if (info.docCount - numDocs != info.getDelCount())\n            throw new RuntimeException(\"delete count mismatch: info=\" + info.getDelCount() + \" vs reader=\" + (info.docCount - numDocs));\n          out.println(\"OK [\" + (info.docCount - numDocs) + \" deleted docs]\");\n        } else {\n          if (info.getDelCount() != 0)\n            throw new RuntimeException(\"delete count mismatch: info=\" + info.getDelCount() + \" vs reader=\" + (info.docCount - numDocs));\n          out.println(\"OK\");\n        }\n\n        out.print(\"    test: fields, norms.......\");\n        Collection fieldNames = reader.getFieldNames(IndexReader.FieldOption.ALL);\n        Iterator it = fieldNames.iterator();\n        while(it.hasNext()) {\n          final String fieldName = (String) it.next();\n          byte[] b = reader.norms(fieldName);\n          if (b.length != info.docCount)\n            throw new RuntimeException(\"norms for field \\\"\" + fieldName + \"\\\" is length \" + b.length + \" != maxDoc \" + info.docCount);\n\n        }\n        out.println(\"OK [\" + fieldNames.size() + \" fields]\");\n\n        out.print(\"    test: terms, freq, prox...\");\n        final TermEnum termEnum = reader.terms();\n        final TermPositions termPositions = reader.termPositions();\n\n        // Used only to count up # deleted docs for this\n        // term\n        final MySegmentTermDocs myTermDocs = new MySegmentTermDocs(reader);\n\n        long termCount = 0;\n        long totFreq = 0;\n        long totPos = 0;\n        while(termEnum.next()) {\n          termCount++;\n          final Term term = termEnum.term();\n          final int docFreq = termEnum.docFreq();\n          termPositions.seek(term);\n          int lastDoc = -1;\n          int freq0 = 0;\n          totFreq += docFreq;\n          while(termPositions.next()) {\n            freq0++;\n            final int doc = termPositions.doc();\n            final int freq = termPositions.freq();\n            if (doc <= lastDoc)\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" <= lastDoc \" + lastDoc);\n            lastDoc = doc;\n            if (freq <= 0)\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" is out of bounds\");\n            \n            int lastPos = -1;\n            totPos += freq;\n            for(int j=0;j<freq;j++) {\n              final int pos = termPositions.nextPosition();\n              if (pos < -1)\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" is out of bounds\");\n              if (pos < lastPos)\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" < lastPos \" + lastPos);\n            }\n          }\n\n          // Now count how many deleted docs occurred in\n          // this term:\n          final int delCount;\n          if (reader.hasDeletions()) {\n            myTermDocs.seek(term);\n            while(myTermDocs.next()) {\n            }\n            delCount = myTermDocs.delCount;\n          } else\n            delCount = 0;\n\n          if (freq0 + delCount != docFreq)\n            throw new RuntimeException(\"term \" + term + \" docFreq=\" + docFreq + \" != num docs seen \" + freq0 + \" + num docs deleted \" + delCount);\n        }\n\n        out.println(\"OK [\" + termCount + \" terms; \" + totFreq + \" terms/docs pairs; \" + totPos + \" tokens]\");\n\n        out.print(\"    test: stored fields.......\");\n        int docCount = 0;\n        long totFields = 0;\n        for(int j=0;j<info.docCount;j++)\n          if (!reader.isDeleted(j)) {\n            docCount++;\n            Document doc = reader.document(j);\n            totFields += doc.getFields().size();\n          }\n\n        if (docCount != reader.numDocs())\n          throw new RuntimeException(\"docCount=\" + docCount + \" but saw \" + docCount + \" undeleted docs\");\n\n        out.println(\"OK [\" + totFields + \" total field count; avg \" + nf.format((((float) totFields)/docCount)) + \" fields per doc]\");\n\n        out.print(\"    test: term vectors........\");\n        int totVectors = 0;\n        for(int j=0;j<info.docCount;j++)\n          if (!reader.isDeleted(j)) {\n            TermFreqVector[] tfv = reader.getTermFreqVectors(j);\n            if (tfv != null)\n              totVectors += tfv.length;\n          }\n\n        out.println(\"OK [\" + totVectors + \" total vector count; avg \" + nf.format((((float) totVectors)/docCount)) + \" term/freq vector fields per doc]\");\n        out.println(\"\");\n\n      } catch (Throwable t) {\n        out.println(\"FAILED\");\n        String comment;\n        if (doFix)\n          comment = \"will remove reference to this segment (-fix is specified)\";\n        else\n          comment = \"would remove reference to this segment (-fix was not specified)\";\n        out.println(\"    WARNING: \" + comment + \"; full exception:\");\n        t.printStackTrace(out);\n        out.println(\"\");\n        totLoseDocCount += toLoseDocCount;\n        numBadSegments++;\n        changed = true;\n        continue;\n      } finally {\n        if (reader != null)\n          reader.close();\n      }\n\n      // Keeper\n      newSIS.add(info.clone());\n    }\n\n    if (!changed) {\n      out.println(\"No problems were detected with this index.\\n\");\n      return true;\n    } else {\n      out.println(\"WARNING: \" + numBadSegments + \" broken segments detected\");\n      if (doFix)\n        out.println(\"WARNING: \" + totLoseDocCount + \" documents will be lost\");\n      else\n        out.println(\"WARNING: \" + totLoseDocCount + \" documents would be lost if -fix were specified\");\n      out.println();\n    }\n\n    if (doFix) {\n      out.println(\"NOTE: will write new segments file in 5 seconds; this will remove \" + totLoseDocCount + \" docs from the index. THIS IS YOUR LAST CHANCE TO CTRL+C!\");\n      for(int i=0;i<5;i++) {\n        try {\n          Thread.sleep(1000);\n        } catch (InterruptedException ie) {\n          Thread.currentThread().interrupt();\n          i--;\n          continue;\n        }\n          \n        out.println(\"  \" + (5-i) + \"...\");\n      }\n      out.print(\"Writing...\");\n      try {\n        newSIS.commit(dir);\n      } catch (Throwable t) {\n        out.println(\"FAILED; exiting\");\n        t.printStackTrace(out);\n        return false;\n      }\n      out.println(\"OK\");\n      out.println(\"Wrote new segments file \\\"\" + newSIS.getCurrentSegmentFileName() + \"\\\"\");\n    } else {\n      out.println(\"NOTE: would write new segments file [-fix was not specified]\");\n    }\n    out.println(\"\");\n\n    return false;\n  }\n\n","sourceOld":"  /** Returns true if index is clean, else false.*/\n  public static boolean check(Directory dir, boolean doFix, List onlySegments) throws IOException {\n    NumberFormat nf = NumberFormat.getInstance();\n    SegmentInfos sis = new SegmentInfos();\n    \n    try {\n      sis.read(dir);\n    } catch (Throwable t) {\n      out.println(\"ERROR: could not read any segments file in directory\");\n      t.printStackTrace(out);\n      return false;\n    }\n\n    final int numSegments = sis.size();\n    final String segmentsFileName = sis.getCurrentSegmentFileName();\n    IndexInput input = null;\n    try {\n      input = dir.openInput(segmentsFileName);\n    } catch (Throwable t) {\n      out.println(\"ERROR: could not open segments file in directory\");\n      t.printStackTrace(out);\n      return false;\n    }\n    int format = 0;\n    try {\n      format = input.readInt();\n    } catch (Throwable t) {\n      out.println(\"ERROR: could not read segment file version in directory\");\n      t.printStackTrace(out);\n      return false;\n    } finally {\n      if (input != null)\n        input.close();\n    }\n\n    String sFormat = \"\";\n    boolean skip = false;\n\n    if (format == SegmentInfos.FORMAT)\n      sFormat = \"FORMAT [Lucene Pre-2.1]\";\n    if (format == SegmentInfos.FORMAT_LOCKLESS)\n      sFormat = \"FORMAT_LOCKLESS [Lucene 2.1]\";\n    else if (format == SegmentInfos.FORMAT_SINGLE_NORM_FILE)\n      sFormat = \"FORMAT_SINGLE_NORM_FILE [Lucene 2.2]\";\n    else if (format == SegmentInfos.FORMAT_SHARED_DOC_STORE)\n      sFormat = \"FORMAT_SHARED_DOC_STORE [Lucene 2.3]\";\n    else {\n      // LUCENE-1255: All versions before 2.3.2/2.4 were\n      // able to create position=-1 when the very first\n      // Token has positionIncrement 0\n      if (format == SegmentInfos.FORMAT_CHECKSUM)\n        sFormat = \"FORMAT_CHECKSUM [Lucene 2.4]\";\n      else if (format == SegmentInfos.FORMAT_DEL_COUNT)\n          sFormat = \"FORMAT_DEL_COUNT [Lucene 2.4]\";\n      else if (format < SegmentInfos.CURRENT_FORMAT) {\n        sFormat = \"int=\" + format + \" [newer version of Lucene than this tool]\";\n        skip = true;\n      } else {\n        sFormat = format + \" [Lucene 1.3 or prior]\";\n      }\n    }\n\n    out.println(\"Segments file=\" + segmentsFileName + \" numSegments=\" + numSegments + \" version=\" + sFormat);\n\n    if (onlySegments != null) {\n      out.print(\"\\nChecking only these segments:\");\n      Iterator it = onlySegments.iterator();\n      while (it.hasNext()) {\n        out.print(\" \" + it.next());\n      }\n      out.println(\":\");\n    }\n\n    if (skip) {\n      out.println(\"\\nERROR: this index appears to be created by a newer version of Lucene than this tool was compiled on; please re-compile this tool on the matching version of Lucene; exiting\");\n      return false;\n    }\n\n    SegmentInfos newSIS = (SegmentInfos) sis.clone();\n    newSIS.clear();\n    boolean changed = false;\n    int totLoseDocCount = 0;\n    int numBadSegments = 0;\n    for(int i=0;i<numSegments;i++) {\n      final SegmentInfo info = sis.info(i);\n      if (onlySegments != null && !onlySegments.contains(info.name))\n        continue;\n      out.println(\"  \" + (1+i) + \" of \" + numSegments + \": name=\" + info.name + \" docCount=\" + info.docCount);\n      int toLoseDocCount = info.docCount;\n\n      SegmentReader reader = null;\n\n      try {\n        out.println(\"    compound=\" + info.getUseCompoundFile());\n        out.println(\"    numFiles=\" + info.files().size());\n        out.println(\"    size (MB)=\" + nf.format(info.sizeInBytes()/(1024.*1024.)));\n        final int docStoreOffset = info.getDocStoreOffset();\n        if (docStoreOffset != -1) {\n          out.println(\"    docStoreOffset=\" + docStoreOffset);\n          out.println(\"    docStoreSegment=\" + info.getDocStoreSegment());\n          out.println(\"    docStoreIsCompoundFile=\" + info.getDocStoreIsCompoundFile());\n        }\n        final String delFileName = info.getDelFileName();\n        if (delFileName == null)\n          out.println(\"    no deletions\");\n        else\n          out.println(\"    has deletions [delFileName=\" + delFileName + \"]\");\n        out.print(\"    test: open reader.........\");\n        reader = SegmentReader.get(info);\n        final int numDocs = reader.numDocs();\n        toLoseDocCount = numDocs;\n        if (reader.hasDeletions()) {\n          if (info.docCount - numDocs != info.getDelCount())\n            throw new RuntimeException(\"delete count mismatch: info=\" + info.getDelCount() + \" vs reader=\" + (info.docCount - numDocs));\n          out.println(\"OK [\" + (info.docCount - numDocs) + \" deleted docs]\");\n        } else {\n          if (info.getDelCount() != 0)\n            throw new RuntimeException(\"delete count mismatch: info=\" + info.getDelCount() + \" vs reader=\" + (info.docCount - numDocs));\n          out.println(\"OK\");\n        }\n\n        out.print(\"    test: fields, norms.......\");\n        Collection fieldNames = reader.getFieldNames(IndexReader.FieldOption.ALL);\n        Iterator it = fieldNames.iterator();\n        while(it.hasNext()) {\n          final String fieldName = (String) it.next();\n          byte[] b = reader.norms(fieldName);\n          if (b.length != info.docCount)\n            throw new RuntimeException(\"norms for field \\\"\" + fieldName + \"\\\" is length \" + b.length + \" != maxDoc \" + info.docCount);\n\n        }\n        out.println(\"OK [\" + fieldNames.size() + \" fields]\");\n\n        out.print(\"    test: terms, freq, prox...\");\n        final TermEnum termEnum = reader.terms();\n        final TermPositions termPositions = reader.termPositions();\n\n        // Used only to count up # deleted docs for this\n        // term\n        final MySegmentTermDocs myTermDocs = new MySegmentTermDocs(reader);\n\n        long termCount = 0;\n        long totFreq = 0;\n        long totPos = 0;\n        while(termEnum.next()) {\n          termCount++;\n          final Term term = termEnum.term();\n          final int docFreq = termEnum.docFreq();\n          termPositions.seek(term);\n          int lastDoc = -1;\n          int freq0 = 0;\n          totFreq += docFreq;\n          while(termPositions.next()) {\n            freq0++;\n            final int doc = termPositions.doc();\n            final int freq = termPositions.freq();\n            if (doc <= lastDoc)\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" < lastDoc \" + lastDoc);\n            lastDoc = doc;\n            if (freq <= 0)\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" is out of bounds\");\n            \n            int lastPos = -1;\n            totPos += freq;\n            for(int j=0;j<freq;j++) {\n              final int pos = termPositions.nextPosition();\n              if (pos < -1)\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" is out of bounds\");\n              if (pos < lastPos)\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" < lastPos \" + lastPos);\n            }\n          }\n\n          // Now count how many deleted docs occurred in\n          // this term:\n          final int delCount;\n          if (reader.hasDeletions()) {\n            myTermDocs.seek(term);\n            while(myTermDocs.next()) {\n            }\n            delCount = myTermDocs.delCount;\n          } else\n            delCount = 0;\n\n          if (freq0 + delCount != docFreq)\n            throw new RuntimeException(\"term \" + term + \" docFreq=\" + docFreq + \" != num docs seen \" + freq0 + \" + num docs deleted \" + delCount);\n        }\n\n        out.println(\"OK [\" + termCount + \" terms; \" + totFreq + \" terms/docs pairs; \" + totPos + \" tokens]\");\n\n        out.print(\"    test: stored fields.......\");\n        int docCount = 0;\n        long totFields = 0;\n        for(int j=0;j<info.docCount;j++)\n          if (!reader.isDeleted(j)) {\n            docCount++;\n            Document doc = reader.document(j);\n            totFields += doc.getFields().size();\n          }\n\n        if (docCount != reader.numDocs())\n          throw new RuntimeException(\"docCount=\" + docCount + \" but saw \" + docCount + \" undeleted docs\");\n\n        out.println(\"OK [\" + totFields + \" total field count; avg \" + nf.format((((float) totFields)/docCount)) + \" fields per doc]\");\n\n        out.print(\"    test: term vectors........\");\n        int totVectors = 0;\n        for(int j=0;j<info.docCount;j++)\n          if (!reader.isDeleted(j)) {\n            TermFreqVector[] tfv = reader.getTermFreqVectors(j);\n            if (tfv != null)\n              totVectors += tfv.length;\n          }\n\n        out.println(\"OK [\" + totVectors + \" total vector count; avg \" + nf.format((((float) totVectors)/docCount)) + \" term/freq vector fields per doc]\");\n        out.println(\"\");\n\n      } catch (Throwable t) {\n        out.println(\"FAILED\");\n        String comment;\n        if (doFix)\n          comment = \"will remove reference to this segment (-fix is specified)\";\n        else\n          comment = \"would remove reference to this segment (-fix was not specified)\";\n        out.println(\"    WARNING: \" + comment + \"; full exception:\");\n        t.printStackTrace(out);\n        out.println(\"\");\n        totLoseDocCount += toLoseDocCount;\n        numBadSegments++;\n        changed = true;\n        continue;\n      } finally {\n        if (reader != null)\n          reader.close();\n      }\n\n      // Keeper\n      newSIS.add(info.clone());\n    }\n\n    if (!changed) {\n      out.println(\"No problems were detected with this index.\\n\");\n      return true;\n    } else {\n      out.println(\"WARNING: \" + numBadSegments + \" broken segments detected\");\n      if (doFix)\n        out.println(\"WARNING: \" + totLoseDocCount + \" documents will be lost\");\n      else\n        out.println(\"WARNING: \" + totLoseDocCount + \" documents would be lost if -fix were specified\");\n      out.println();\n    }\n\n    if (doFix) {\n      out.println(\"NOTE: will write new segments file in 5 seconds; this will remove \" + totLoseDocCount + \" docs from the index. THIS IS YOUR LAST CHANCE TO CTRL+C!\");\n      for(int i=0;i<5;i++) {\n        try {\n          Thread.sleep(1000);\n        } catch (InterruptedException ie) {\n          Thread.currentThread().interrupt();\n          i--;\n          continue;\n        }\n          \n        out.println(\"  \" + (5-i) + \"...\");\n      }\n      out.print(\"Writing...\");\n      try {\n        newSIS.commit(dir);\n      } catch (Throwable t) {\n        out.println(\"FAILED; exiting\");\n        t.printStackTrace(out);\n        return false;\n      }\n      out.println(\"OK\");\n      out.println(\"Wrote new segments file \\\"\" + newSIS.getCurrentSegmentFileName() + \"\\\"\");\n    } else {\n      out.println(\"NOTE: would write new segments file [-fix was not specified]\");\n    }\n    out.println(\"\");\n\n    return false;\n  }\n\n","bugFix":null,"bugIntro":["7391c1f4ab1a6817de8a262f5c1b3de3cf190785"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"cba44a7c8f0e3eb449bcdbd53960b7705c0bf902","date":1220978058,"type":3,"author":"Grant Ingersoll","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/CheckIndex#check(Directory,boolean,List).mjava","pathOld":"src/java/org/apache/lucene/index/CheckIndex#check(Directory,boolean,List).mjava","sourceNew":"  /** Returns true if index is clean, else false.*/\n  public static CheckIndexStatus check(Directory dir, boolean doFix, List onlySegments) throws IOException {\n    NumberFormat nf = NumberFormat.getInstance();\n    SegmentInfos sis = new SegmentInfos();\n    CheckIndexStatus result = new CheckIndexStatus();\n    result.dir = dir;\n    try {\n      sis.read(dir);\n    } catch (Throwable t) {\n      msg(\"ERROR: could not read any segments file in directory\");\n      result.missingSegments = true;\n      t.printStackTrace(out);\n      return result;\n    }\n\n    final int numSegments = sis.size();\n    final String segmentsFileName = sis.getCurrentSegmentFileName();\n    IndexInput input = null;\n    try {\n      input = dir.openInput(segmentsFileName);\n    } catch (Throwable t) {\n      msg(\"ERROR: could not open segments file in directory\");\n      t.printStackTrace(out);\n      result.cantOpenSegments = true;\n      return result;\n    }\n    int format = 0;\n    try {\n      format = input.readInt();\n    } catch (Throwable t) {\n      msg(\"ERROR: could not read segment file version in directory\");\n      t.printStackTrace(out);\n      result.missingSegmentVersion = true;\n      return result;\n    } finally {\n      if (input != null)\n        input.close();\n    }\n\n    String sFormat = \"\";\n    boolean skip = false;\n\n    if (format == SegmentInfos.FORMAT)\n      sFormat = \"FORMAT [Lucene Pre-2.1]\";\n    if (format == SegmentInfos.FORMAT_LOCKLESS)\n      sFormat = \"FORMAT_LOCKLESS [Lucene 2.1]\";\n    else if (format == SegmentInfos.FORMAT_SINGLE_NORM_FILE)\n      sFormat = \"FORMAT_SINGLE_NORM_FILE [Lucene 2.2]\";\n    else if (format == SegmentInfos.FORMAT_SHARED_DOC_STORE)\n      sFormat = \"FORMAT_SHARED_DOC_STORE [Lucene 2.3]\";\n    else {\n      if (format == SegmentInfos.FORMAT_CHECKSUM)\n        sFormat = \"FORMAT_CHECKSUM [Lucene 2.4]\";\n      else if (format == SegmentInfos.FORMAT_DEL_COUNT)\n        sFormat = \"FORMAT_DEL_COUNT [Lucene 2.4]\";\n      else if (format == SegmentInfos.FORMAT_HAS_PROX)\n        sFormat = \"FORMAT_HAS_PROX [Lucene 2.4]\";\n      else if (format < SegmentInfos.CURRENT_FORMAT) {\n        sFormat = \"int=\" + format + \" [newer version of Lucene than this tool]\";\n        skip = true;\n      } else {\n        sFormat = format + \" [Lucene 1.3 or prior]\";\n      }\n    }\n\n    msg(\"Segments file=\" + segmentsFileName + \" numSegments=\" + numSegments + \" version=\" + sFormat);\n    result.segmentsFileName = segmentsFileName;\n    result.numSegments = numSegments;\n    result.segmentFormat = sFormat;\n\n    if (onlySegments != null) {\n      out.print(\"\\nChecking only these segments:\");\n      Iterator it = onlySegments.iterator();\n      while (it.hasNext()) {\n        out.print(\" \" + it.next());\n      }\n      result.segmentsChecked.addAll(onlySegments);\n      msg(\":\");\n    }\n\n    if (skip) {\n      msg(\"\\nERROR: this index appears to be created by a newer version of Lucene than this tool was compiled on; please re-compile this tool on the matching version of Lucene; exiting\");\n      result.toolOutOfDate = true;\n      return result;\n    }\n\n\n    result.newSegments = (SegmentInfos) sis.clone();\n    result.newSegments.clear();\n\n    for(int i=0;i<numSegments;i++) {\n      final SegmentInfo info = sis.info(i);\n      if (onlySegments != null && !onlySegments.contains(info.name))\n        continue;\n      CheckIndexStatus.SegmentInfoStatus segInfoStat = new CheckIndexStatus.SegmentInfoStatus();\n      result.segmentInfos.add(segInfoStat);\n      msg(\"  \" + (1+i) + \" of \" + numSegments + \": name=\" + info.name + \" docCount=\" + info.docCount);\n      segInfoStat.name = info.name;\n      segInfoStat.docCount = info.docCount;\n\n      int toLoseDocCount = info.docCount;\n\n      SegmentReader reader = null;\n\n      try {\n        msg(\"    compound=\" + info.getUseCompoundFile());\n        segInfoStat.compound = info.getUseCompoundFile();\n        msg(\"    hasProx=\" + info.getHasProx());\n        segInfoStat.hasProx = info.getHasProx();\n        msg(\"    numFiles=\" + info.files().size());\n        segInfoStat.numFiles = info.files().size();\n        msg(\"    size (MB)=\" + nf.format(info.sizeInBytes()/(1024.*1024.)));\n        segInfoStat.sizeMB = info.sizeInBytes()/(1024.*1024.);\n\n\n        final int docStoreOffset = info.getDocStoreOffset();\n        if (docStoreOffset != -1) {\n          msg(\"    docStoreOffset=\" + docStoreOffset);\n          segInfoStat.docStoreOffset = docStoreOffset;\n          msg(\"    docStoreSegment=\" + info.getDocStoreSegment());\n          segInfoStat.docStoreSegment = info.getDocStoreSegment();\n          msg(\"    docStoreIsCompoundFile=\" + info.getDocStoreIsCompoundFile());\n          segInfoStat.docStoreCompoundFile = info.getDocStoreIsCompoundFile();\n        }\n        final String delFileName = info.getDelFileName();\n        if (delFileName == null){\n          msg(\"    no deletions\");\n          segInfoStat.hasDeletions = false;\n        }\n        else{\n          msg(\"    has deletions [delFileName=\" + delFileName + \"]\");\n          segInfoStat.hasDeletions = true;\n          segInfoStat.deletionsFileName = delFileName;\n\n        }\n        out.print(\"    test: open reader.........\");\n        reader = SegmentReader.get(info);\n        final int numDocs = reader.numDocs();\n        toLoseDocCount = numDocs;\n        if (reader.hasDeletions()) {\n          if (info.docCount - numDocs != info.getDelCount()){\n            throw new RuntimeException(\"delete count mismatch: info=\" + info.getDelCount() + \" vs reader=\" + (info.docCount - numDocs));\n          }\n          segInfoStat.numDeleted = info.docCount - numDocs;\n          msg(\"OK [\" + (segInfoStat.numDeleted) + \" deleted docs]\");\n        } else {\n          if (info.getDelCount() != 0){\n            throw new RuntimeException(\"delete count mismatch: info=\" + info.getDelCount() + \" vs reader=\" + (info.docCount - numDocs));\n          }\n          msg(\"OK\");\n        }\n\n        out.print(\"    test: fields, norms.......\");\n        Collection fieldNames = reader.getFieldNames(IndexReader.FieldOption.ALL);\n        Iterator it = fieldNames.iterator();\n        while(it.hasNext()) {\n          final String fieldName = (String) it.next();\n          byte[] b = reader.norms(fieldName);\n          if (b.length != info.docCount)\n            throw new RuntimeException(\"norms for field \\\"\" + fieldName + \"\\\" is length \" + b.length + \" != maxDoc \" + info.docCount);\n\n        }\n        msg(\"OK [\" + fieldNames.size() + \" fields]\");\n        segInfoStat.numFields = fieldNames.size();\n        out.print(\"    test: terms, freq, prox...\");\n        final TermEnum termEnum = reader.terms();\n        final TermPositions termPositions = reader.termPositions();\n\n        // Used only to count up # deleted docs for this\n        // term\n        final MySegmentTermDocs myTermDocs = new MySegmentTermDocs(reader);\n\n        long termCount = 0;\n        long totFreq = 0;\n        long totPos = 0;\n        while(termEnum.next()) {\n          termCount++;\n          final Term term = termEnum.term();\n          final int docFreq = termEnum.docFreq();\n          termPositions.seek(term);\n          int lastDoc = -1;\n          int freq0 = 0;\n          totFreq += docFreq;\n          while(termPositions.next()) {\n            freq0++;\n            final int doc = termPositions.doc();\n            final int freq = termPositions.freq();\n            if (doc <= lastDoc)\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" <= lastDoc \" + lastDoc);\n            lastDoc = doc;\n            if (freq <= 0)\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" is out of bounds\");\n            \n            int lastPos = -1;\n            totPos += freq;\n            for(int j=0;j<freq;j++) {\n              final int pos = termPositions.nextPosition();\n              if (pos < -1)\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" is out of bounds\");\n              if (pos < lastPos)\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" < lastPos \" + lastPos);\n            }\n          }\n\n          // Now count how many deleted docs occurred in\n          // this term:\n          final int delCount;\n          if (reader.hasDeletions()) {\n            myTermDocs.seek(term);\n            while(myTermDocs.next()) {\n            }\n            delCount = myTermDocs.delCount;\n          } else\n            delCount = 0;\n\n          if (freq0 + delCount != docFreq)\n            throw new RuntimeException(\"term \" + term + \" docFreq=\" + docFreq + \" != num docs seen \" + freq0 + \" + num docs deleted \" + delCount);\n        }\n\n        msg(\"OK [\" + termCount + \" terms; \" + totFreq + \" terms/docs pairs; \" + totPos + \" tokens]\");\n\n        out.print(\"    test: stored fields.......\");\n        int docCount = 0;\n        long totFields = 0;\n        for(int j=0;j<info.docCount;j++)\n          if (!reader.isDeleted(j)) {\n            docCount++;\n            Document doc = reader.document(j);\n            totFields += doc.getFields().size();\n          }\n\n        if (docCount != reader.numDocs())\n          throw new RuntimeException(\"docCount=\" + docCount + \" but saw \" + docCount + \" undeleted docs\");\n\n        msg(\"OK [\" + totFields + \" total field count; avg \" + nf.format((((float) totFields)/docCount)) + \" fields per doc]\");\n\n        out.print(\"    test: term vectors........\");\n        int totVectors = 0;\n        for(int j=0;j<info.docCount;j++)\n          if (!reader.isDeleted(j)) {\n            TermFreqVector[] tfv = reader.getTermFreqVectors(j);\n            if (tfv != null)\n              totVectors += tfv.length;\n          }\n\n        msg(\"OK [\" + totVectors + \" total vector count; avg \" + nf.format((((float) totVectors)/docCount)) + \" term/freq vector fields per doc]\");\n        msg(\"\");\n\n      } catch (Throwable t) {\n        msg(\"FAILED\");\n        String comment;\n        if (doFix)\n          comment = \"will remove reference to this segment (-fix is specified)\";\n        else\n          comment = \"would remove reference to this segment (-fix was not specified)\";\n        msg(\"    WARNING: \" + comment + \"; full exception:\");\n        t.printStackTrace(out);\n        msg(\"\");\n        result.totLoseDocCount += toLoseDocCount;\n        result.numBadSegments++;\n        continue;\n      } finally {\n        if (reader != null)\n          reader.close();\n      }\n\n      // Keeper\n      result.newSegments.add(info.clone());\n    }\n\n    if (0 == result.numBadSegments) {\n      result.clean = true;\n      msg(\"No problems were detected with this index.\\n\");\n    } else\n      msg(\"WARNING: \" + result.numBadSegments + \" broken segments (containing \" + result.totLoseDocCount + \" documents) detected\");\n\n    return result;\n  }\n\n","sourceOld":"  /** Returns true if index is clean, else false.*/\n  public static boolean check(Directory dir, boolean doFix, List onlySegments) throws IOException {\n    NumberFormat nf = NumberFormat.getInstance();\n    SegmentInfos sis = new SegmentInfos();\n    \n    try {\n      sis.read(dir);\n    } catch (Throwable t) {\n      out.println(\"ERROR: could not read any segments file in directory\");\n      t.printStackTrace(out);\n      return false;\n    }\n\n    final int numSegments = sis.size();\n    final String segmentsFileName = sis.getCurrentSegmentFileName();\n    IndexInput input = null;\n    try {\n      input = dir.openInput(segmentsFileName);\n    } catch (Throwable t) {\n      out.println(\"ERROR: could not open segments file in directory\");\n      t.printStackTrace(out);\n      return false;\n    }\n    int format = 0;\n    try {\n      format = input.readInt();\n    } catch (Throwable t) {\n      out.println(\"ERROR: could not read segment file version in directory\");\n      t.printStackTrace(out);\n      return false;\n    } finally {\n      if (input != null)\n        input.close();\n    }\n\n    String sFormat = \"\";\n    boolean skip = false;\n\n    if (format == SegmentInfos.FORMAT)\n      sFormat = \"FORMAT [Lucene Pre-2.1]\";\n    if (format == SegmentInfos.FORMAT_LOCKLESS)\n      sFormat = \"FORMAT_LOCKLESS [Lucene 2.1]\";\n    else if (format == SegmentInfos.FORMAT_SINGLE_NORM_FILE)\n      sFormat = \"FORMAT_SINGLE_NORM_FILE [Lucene 2.2]\";\n    else if (format == SegmentInfos.FORMAT_SHARED_DOC_STORE)\n      sFormat = \"FORMAT_SHARED_DOC_STORE [Lucene 2.3]\";\n    else {\n      if (format == SegmentInfos.FORMAT_CHECKSUM)\n        sFormat = \"FORMAT_CHECKSUM [Lucene 2.4]\";\n      else if (format == SegmentInfos.FORMAT_DEL_COUNT)\n        sFormat = \"FORMAT_DEL_COUNT [Lucene 2.4]\";\n      else if (format == SegmentInfos.FORMAT_HAS_PROX)\n        sFormat = \"FORMAT_HAS_PROX [Lucene 2.4]\";\n      else if (format < SegmentInfos.CURRENT_FORMAT) {\n        sFormat = \"int=\" + format + \" [newer version of Lucene than this tool]\";\n        skip = true;\n      } else {\n        sFormat = format + \" [Lucene 1.3 or prior]\";\n      }\n    }\n\n    out.println(\"Segments file=\" + segmentsFileName + \" numSegments=\" + numSegments + \" version=\" + sFormat);\n\n    if (onlySegments != null) {\n      out.print(\"\\nChecking only these segments:\");\n      Iterator it = onlySegments.iterator();\n      while (it.hasNext()) {\n        out.print(\" \" + it.next());\n      }\n      out.println(\":\");\n    }\n\n    if (skip) {\n      out.println(\"\\nERROR: this index appears to be created by a newer version of Lucene than this tool was compiled on; please re-compile this tool on the matching version of Lucene; exiting\");\n      return false;\n    }\n\n    SegmentInfos newSIS = (SegmentInfos) sis.clone();\n    newSIS.clear();\n    boolean changed = false;\n    int totLoseDocCount = 0;\n    int numBadSegments = 0;\n    for(int i=0;i<numSegments;i++) {\n      final SegmentInfo info = sis.info(i);\n      if (onlySegments != null && !onlySegments.contains(info.name))\n        continue;\n      out.println(\"  \" + (1+i) + \" of \" + numSegments + \": name=\" + info.name + \" docCount=\" + info.docCount);\n      int toLoseDocCount = info.docCount;\n\n      SegmentReader reader = null;\n\n      try {\n        out.println(\"    compound=\" + info.getUseCompoundFile());\n        out.println(\"    hasProx=\" + info.getHasProx());\n        out.println(\"    numFiles=\" + info.files().size());\n        out.println(\"    size (MB)=\" + nf.format(info.sizeInBytes()/(1024.*1024.)));\n        final int docStoreOffset = info.getDocStoreOffset();\n        if (docStoreOffset != -1) {\n          out.println(\"    docStoreOffset=\" + docStoreOffset);\n          out.println(\"    docStoreSegment=\" + info.getDocStoreSegment());\n          out.println(\"    docStoreIsCompoundFile=\" + info.getDocStoreIsCompoundFile());\n        }\n        final String delFileName = info.getDelFileName();\n        if (delFileName == null)\n          out.println(\"    no deletions\");\n        else\n          out.println(\"    has deletions [delFileName=\" + delFileName + \"]\");\n        out.print(\"    test: open reader.........\");\n        reader = SegmentReader.get(info);\n        final int numDocs = reader.numDocs();\n        toLoseDocCount = numDocs;\n        if (reader.hasDeletions()) {\n          if (info.docCount - numDocs != info.getDelCount())\n            throw new RuntimeException(\"delete count mismatch: info=\" + info.getDelCount() + \" vs reader=\" + (info.docCount - numDocs));\n          out.println(\"OK [\" + (info.docCount - numDocs) + \" deleted docs]\");\n        } else {\n          if (info.getDelCount() != 0)\n            throw new RuntimeException(\"delete count mismatch: info=\" + info.getDelCount() + \" vs reader=\" + (info.docCount - numDocs));\n          out.println(\"OK\");\n        }\n\n        out.print(\"    test: fields, norms.......\");\n        Collection fieldNames = reader.getFieldNames(IndexReader.FieldOption.ALL);\n        Iterator it = fieldNames.iterator();\n        while(it.hasNext()) {\n          final String fieldName = (String) it.next();\n          byte[] b = reader.norms(fieldName);\n          if (b.length != info.docCount)\n            throw new RuntimeException(\"norms for field \\\"\" + fieldName + \"\\\" is length \" + b.length + \" != maxDoc \" + info.docCount);\n\n        }\n        out.println(\"OK [\" + fieldNames.size() + \" fields]\");\n\n        out.print(\"    test: terms, freq, prox...\");\n        final TermEnum termEnum = reader.terms();\n        final TermPositions termPositions = reader.termPositions();\n\n        // Used only to count up # deleted docs for this\n        // term\n        final MySegmentTermDocs myTermDocs = new MySegmentTermDocs(reader);\n\n        long termCount = 0;\n        long totFreq = 0;\n        long totPos = 0;\n        while(termEnum.next()) {\n          termCount++;\n          final Term term = termEnum.term();\n          final int docFreq = termEnum.docFreq();\n          termPositions.seek(term);\n          int lastDoc = -1;\n          int freq0 = 0;\n          totFreq += docFreq;\n          while(termPositions.next()) {\n            freq0++;\n            final int doc = termPositions.doc();\n            final int freq = termPositions.freq();\n            if (doc <= lastDoc)\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" <= lastDoc \" + lastDoc);\n            lastDoc = doc;\n            if (freq <= 0)\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" is out of bounds\");\n            \n            int lastPos = -1;\n            totPos += freq;\n            for(int j=0;j<freq;j++) {\n              final int pos = termPositions.nextPosition();\n              if (pos < -1)\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" is out of bounds\");\n              if (pos < lastPos)\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" < lastPos \" + lastPos);\n            }\n          }\n\n          // Now count how many deleted docs occurred in\n          // this term:\n          final int delCount;\n          if (reader.hasDeletions()) {\n            myTermDocs.seek(term);\n            while(myTermDocs.next()) {\n            }\n            delCount = myTermDocs.delCount;\n          } else\n            delCount = 0;\n\n          if (freq0 + delCount != docFreq)\n            throw new RuntimeException(\"term \" + term + \" docFreq=\" + docFreq + \" != num docs seen \" + freq0 + \" + num docs deleted \" + delCount);\n        }\n\n        out.println(\"OK [\" + termCount + \" terms; \" + totFreq + \" terms/docs pairs; \" + totPos + \" tokens]\");\n\n        out.print(\"    test: stored fields.......\");\n        int docCount = 0;\n        long totFields = 0;\n        for(int j=0;j<info.docCount;j++)\n          if (!reader.isDeleted(j)) {\n            docCount++;\n            Document doc = reader.document(j);\n            totFields += doc.getFields().size();\n          }\n\n        if (docCount != reader.numDocs())\n          throw new RuntimeException(\"docCount=\" + docCount + \" but saw \" + docCount + \" undeleted docs\");\n\n        out.println(\"OK [\" + totFields + \" total field count; avg \" + nf.format((((float) totFields)/docCount)) + \" fields per doc]\");\n\n        out.print(\"    test: term vectors........\");\n        int totVectors = 0;\n        for(int j=0;j<info.docCount;j++)\n          if (!reader.isDeleted(j)) {\n            TermFreqVector[] tfv = reader.getTermFreqVectors(j);\n            if (tfv != null)\n              totVectors += tfv.length;\n          }\n\n        out.println(\"OK [\" + totVectors + \" total vector count; avg \" + nf.format((((float) totVectors)/docCount)) + \" term/freq vector fields per doc]\");\n        out.println(\"\");\n\n      } catch (Throwable t) {\n        out.println(\"FAILED\");\n        String comment;\n        if (doFix)\n          comment = \"will remove reference to this segment (-fix is specified)\";\n        else\n          comment = \"would remove reference to this segment (-fix was not specified)\";\n        out.println(\"    WARNING: \" + comment + \"; full exception:\");\n        t.printStackTrace(out);\n        out.println(\"\");\n        totLoseDocCount += toLoseDocCount;\n        numBadSegments++;\n        changed = true;\n        continue;\n      } finally {\n        if (reader != null)\n          reader.close();\n      }\n\n      // Keeper\n      newSIS.add(info.clone());\n    }\n\n    if (!changed) {\n      out.println(\"No problems were detected with this index.\\n\");\n      return true;\n    } else {\n      out.println(\"WARNING: \" + numBadSegments + \" broken segments detected\");\n      if (doFix)\n        out.println(\"WARNING: \" + totLoseDocCount + \" documents will be lost\");\n      else\n        out.println(\"WARNING: \" + totLoseDocCount + \" documents would be lost if -fix were specified\");\n      out.println();\n    }\n\n    if (doFix) {\n      out.println(\"NOTE: will write new segments file in 5 seconds; this will remove \" + totLoseDocCount + \" docs from the index. THIS IS YOUR LAST CHANCE TO CTRL+C!\");\n      for(int i=0;i<5;i++) {\n        try {\n          Thread.sleep(1000);\n        } catch (InterruptedException ie) {\n          Thread.currentThread().interrupt();\n          i--;\n          continue;\n        }\n          \n        out.println(\"  \" + (5-i) + \"...\");\n      }\n      out.print(\"Writing...\");\n      try {\n        newSIS.commit(dir);\n      } catch (Throwable t) {\n        out.println(\"FAILED; exiting\");\n        t.printStackTrace(out);\n        return false;\n      }\n      out.println(\"OK\");\n      out.println(\"Wrote new segments file \\\"\" + newSIS.getCurrentSegmentFileName() + \"\\\"\");\n    } else {\n      out.println(\"NOTE: would write new segments file [-fix was not specified]\");\n    }\n    out.println(\"\");\n\n    return false;\n  }\n\n","bugFix":null,"bugIntro":["7391c1f4ab1a6817de8a262f5c1b3de3cf190785"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"7391c1f4ab1a6817de8a262f5c1b3de3cf190785","date":1222335791,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/CheckIndex#check(Directory,boolean,List).mjava","pathOld":"src/java/org/apache/lucene/index/CheckIndex#check(Directory,boolean,List).mjava","sourceNew":"  /** Returns true if index is clean, else false.\n   *  @deprecated Please instantiate a CheckIndex and then use {@link #checkIndex(List)} instead */\n  public static boolean check(Directory dir, boolean doFix, List onlySegments) throws IOException {\n    CheckIndex checker = new CheckIndex(dir);\n    Status status = checker.checkIndex(onlySegments);\n    if (doFix && !status.clean)\n      checker.fixIndex(status);\n\n    return status.clean;\n  }\n\n","sourceOld":"  /** Returns true if index is clean, else false.*/\n  public static CheckIndexStatus check(Directory dir, boolean doFix, List onlySegments) throws IOException {\n    NumberFormat nf = NumberFormat.getInstance();\n    SegmentInfos sis = new SegmentInfos();\n    CheckIndexStatus result = new CheckIndexStatus();\n    result.dir = dir;\n    try {\n      sis.read(dir);\n    } catch (Throwable t) {\n      msg(\"ERROR: could not read any segments file in directory\");\n      result.missingSegments = true;\n      t.printStackTrace(out);\n      return result;\n    }\n\n    final int numSegments = sis.size();\n    final String segmentsFileName = sis.getCurrentSegmentFileName();\n    IndexInput input = null;\n    try {\n      input = dir.openInput(segmentsFileName);\n    } catch (Throwable t) {\n      msg(\"ERROR: could not open segments file in directory\");\n      t.printStackTrace(out);\n      result.cantOpenSegments = true;\n      return result;\n    }\n    int format = 0;\n    try {\n      format = input.readInt();\n    } catch (Throwable t) {\n      msg(\"ERROR: could not read segment file version in directory\");\n      t.printStackTrace(out);\n      result.missingSegmentVersion = true;\n      return result;\n    } finally {\n      if (input != null)\n        input.close();\n    }\n\n    String sFormat = \"\";\n    boolean skip = false;\n\n    if (format == SegmentInfos.FORMAT)\n      sFormat = \"FORMAT [Lucene Pre-2.1]\";\n    if (format == SegmentInfos.FORMAT_LOCKLESS)\n      sFormat = \"FORMAT_LOCKLESS [Lucene 2.1]\";\n    else if (format == SegmentInfos.FORMAT_SINGLE_NORM_FILE)\n      sFormat = \"FORMAT_SINGLE_NORM_FILE [Lucene 2.2]\";\n    else if (format == SegmentInfos.FORMAT_SHARED_DOC_STORE)\n      sFormat = \"FORMAT_SHARED_DOC_STORE [Lucene 2.3]\";\n    else {\n      if (format == SegmentInfos.FORMAT_CHECKSUM)\n        sFormat = \"FORMAT_CHECKSUM [Lucene 2.4]\";\n      else if (format == SegmentInfos.FORMAT_DEL_COUNT)\n        sFormat = \"FORMAT_DEL_COUNT [Lucene 2.4]\";\n      else if (format == SegmentInfos.FORMAT_HAS_PROX)\n        sFormat = \"FORMAT_HAS_PROX [Lucene 2.4]\";\n      else if (format < SegmentInfos.CURRENT_FORMAT) {\n        sFormat = \"int=\" + format + \" [newer version of Lucene than this tool]\";\n        skip = true;\n      } else {\n        sFormat = format + \" [Lucene 1.3 or prior]\";\n      }\n    }\n\n    msg(\"Segments file=\" + segmentsFileName + \" numSegments=\" + numSegments + \" version=\" + sFormat);\n    result.segmentsFileName = segmentsFileName;\n    result.numSegments = numSegments;\n    result.segmentFormat = sFormat;\n\n    if (onlySegments != null) {\n      out.print(\"\\nChecking only these segments:\");\n      Iterator it = onlySegments.iterator();\n      while (it.hasNext()) {\n        out.print(\" \" + it.next());\n      }\n      result.segmentsChecked.addAll(onlySegments);\n      msg(\":\");\n    }\n\n    if (skip) {\n      msg(\"\\nERROR: this index appears to be created by a newer version of Lucene than this tool was compiled on; please re-compile this tool on the matching version of Lucene; exiting\");\n      result.toolOutOfDate = true;\n      return result;\n    }\n\n\n    result.newSegments = (SegmentInfos) sis.clone();\n    result.newSegments.clear();\n\n    for(int i=0;i<numSegments;i++) {\n      final SegmentInfo info = sis.info(i);\n      if (onlySegments != null && !onlySegments.contains(info.name))\n        continue;\n      CheckIndexStatus.SegmentInfoStatus segInfoStat = new CheckIndexStatus.SegmentInfoStatus();\n      result.segmentInfos.add(segInfoStat);\n      msg(\"  \" + (1+i) + \" of \" + numSegments + \": name=\" + info.name + \" docCount=\" + info.docCount);\n      segInfoStat.name = info.name;\n      segInfoStat.docCount = info.docCount;\n\n      int toLoseDocCount = info.docCount;\n\n      SegmentReader reader = null;\n\n      try {\n        msg(\"    compound=\" + info.getUseCompoundFile());\n        segInfoStat.compound = info.getUseCompoundFile();\n        msg(\"    hasProx=\" + info.getHasProx());\n        segInfoStat.hasProx = info.getHasProx();\n        msg(\"    numFiles=\" + info.files().size());\n        segInfoStat.numFiles = info.files().size();\n        msg(\"    size (MB)=\" + nf.format(info.sizeInBytes()/(1024.*1024.)));\n        segInfoStat.sizeMB = info.sizeInBytes()/(1024.*1024.);\n\n\n        final int docStoreOffset = info.getDocStoreOffset();\n        if (docStoreOffset != -1) {\n          msg(\"    docStoreOffset=\" + docStoreOffset);\n          segInfoStat.docStoreOffset = docStoreOffset;\n          msg(\"    docStoreSegment=\" + info.getDocStoreSegment());\n          segInfoStat.docStoreSegment = info.getDocStoreSegment();\n          msg(\"    docStoreIsCompoundFile=\" + info.getDocStoreIsCompoundFile());\n          segInfoStat.docStoreCompoundFile = info.getDocStoreIsCompoundFile();\n        }\n        final String delFileName = info.getDelFileName();\n        if (delFileName == null){\n          msg(\"    no deletions\");\n          segInfoStat.hasDeletions = false;\n        }\n        else{\n          msg(\"    has deletions [delFileName=\" + delFileName + \"]\");\n          segInfoStat.hasDeletions = true;\n          segInfoStat.deletionsFileName = delFileName;\n\n        }\n        out.print(\"    test: open reader.........\");\n        reader = SegmentReader.get(info);\n        final int numDocs = reader.numDocs();\n        toLoseDocCount = numDocs;\n        if (reader.hasDeletions()) {\n          if (info.docCount - numDocs != info.getDelCount()){\n            throw new RuntimeException(\"delete count mismatch: info=\" + info.getDelCount() + \" vs reader=\" + (info.docCount - numDocs));\n          }\n          segInfoStat.numDeleted = info.docCount - numDocs;\n          msg(\"OK [\" + (segInfoStat.numDeleted) + \" deleted docs]\");\n        } else {\n          if (info.getDelCount() != 0){\n            throw new RuntimeException(\"delete count mismatch: info=\" + info.getDelCount() + \" vs reader=\" + (info.docCount - numDocs));\n          }\n          msg(\"OK\");\n        }\n\n        out.print(\"    test: fields, norms.......\");\n        Collection fieldNames = reader.getFieldNames(IndexReader.FieldOption.ALL);\n        Iterator it = fieldNames.iterator();\n        while(it.hasNext()) {\n          final String fieldName = (String) it.next();\n          byte[] b = reader.norms(fieldName);\n          if (b.length != info.docCount)\n            throw new RuntimeException(\"norms for field \\\"\" + fieldName + \"\\\" is length \" + b.length + \" != maxDoc \" + info.docCount);\n\n        }\n        msg(\"OK [\" + fieldNames.size() + \" fields]\");\n        segInfoStat.numFields = fieldNames.size();\n        out.print(\"    test: terms, freq, prox...\");\n        final TermEnum termEnum = reader.terms();\n        final TermPositions termPositions = reader.termPositions();\n\n        // Used only to count up # deleted docs for this\n        // term\n        final MySegmentTermDocs myTermDocs = new MySegmentTermDocs(reader);\n\n        long termCount = 0;\n        long totFreq = 0;\n        long totPos = 0;\n        while(termEnum.next()) {\n          termCount++;\n          final Term term = termEnum.term();\n          final int docFreq = termEnum.docFreq();\n          termPositions.seek(term);\n          int lastDoc = -1;\n          int freq0 = 0;\n          totFreq += docFreq;\n          while(termPositions.next()) {\n            freq0++;\n            final int doc = termPositions.doc();\n            final int freq = termPositions.freq();\n            if (doc <= lastDoc)\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \" <= lastDoc \" + lastDoc);\n            lastDoc = doc;\n            if (freq <= 0)\n              throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": freq \" + freq + \" is out of bounds\");\n            \n            int lastPos = -1;\n            totPos += freq;\n            for(int j=0;j<freq;j++) {\n              final int pos = termPositions.nextPosition();\n              if (pos < -1)\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" is out of bounds\");\n              if (pos < lastPos)\n                throw new RuntimeException(\"term \" + term + \": doc \" + doc + \": pos \" + pos + \" < lastPos \" + lastPos);\n            }\n          }\n\n          // Now count how many deleted docs occurred in\n          // this term:\n          final int delCount;\n          if (reader.hasDeletions()) {\n            myTermDocs.seek(term);\n            while(myTermDocs.next()) {\n            }\n            delCount = myTermDocs.delCount;\n          } else\n            delCount = 0;\n\n          if (freq0 + delCount != docFreq)\n            throw new RuntimeException(\"term \" + term + \" docFreq=\" + docFreq + \" != num docs seen \" + freq0 + \" + num docs deleted \" + delCount);\n        }\n\n        msg(\"OK [\" + termCount + \" terms; \" + totFreq + \" terms/docs pairs; \" + totPos + \" tokens]\");\n\n        out.print(\"    test: stored fields.......\");\n        int docCount = 0;\n        long totFields = 0;\n        for(int j=0;j<info.docCount;j++)\n          if (!reader.isDeleted(j)) {\n            docCount++;\n            Document doc = reader.document(j);\n            totFields += doc.getFields().size();\n          }\n\n        if (docCount != reader.numDocs())\n          throw new RuntimeException(\"docCount=\" + docCount + \" but saw \" + docCount + \" undeleted docs\");\n\n        msg(\"OK [\" + totFields + \" total field count; avg \" + nf.format((((float) totFields)/docCount)) + \" fields per doc]\");\n\n        out.print(\"    test: term vectors........\");\n        int totVectors = 0;\n        for(int j=0;j<info.docCount;j++)\n          if (!reader.isDeleted(j)) {\n            TermFreqVector[] tfv = reader.getTermFreqVectors(j);\n            if (tfv != null)\n              totVectors += tfv.length;\n          }\n\n        msg(\"OK [\" + totVectors + \" total vector count; avg \" + nf.format((((float) totVectors)/docCount)) + \" term/freq vector fields per doc]\");\n        msg(\"\");\n\n      } catch (Throwable t) {\n        msg(\"FAILED\");\n        String comment;\n        if (doFix)\n          comment = \"will remove reference to this segment (-fix is specified)\";\n        else\n          comment = \"would remove reference to this segment (-fix was not specified)\";\n        msg(\"    WARNING: \" + comment + \"; full exception:\");\n        t.printStackTrace(out);\n        msg(\"\");\n        result.totLoseDocCount += toLoseDocCount;\n        result.numBadSegments++;\n        continue;\n      } finally {\n        if (reader != null)\n          reader.close();\n      }\n\n      // Keeper\n      result.newSegments.add(info.clone());\n    }\n\n    if (0 == result.numBadSegments) {\n      result.clean = true;\n      msg(\"No problems were detected with this index.\\n\");\n    } else\n      msg(\"WARNING: \" + result.numBadSegments + \" broken segments (containing \" + result.totLoseDocCount + \" documents) detected\");\n\n    return result;\n  }\n\n","bugFix":["34e2c71b6406443562df54db233fde0728502f64","abfdd5170b43f046dfac9dafd6e12c1a65f3018c","a64db7380e46c730a4ff0f00ebd7b29219312c14","f51cb06175d6fae01dc608dd7ab884973354e4bf","cba44a7c8f0e3eb449bcdbd53960b7705c0bf902","902ba79f4590a41c663c447756d2e5041cbbdda9","9cb1313e01866149ff8dde7e80345a5476de305e"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"be2419774ad2eb3c65ca1cb035c3a2ccc6ae7da1","date":1255502337,"type":4,"author":"Michael Busch","isMerge":false,"pathNew":"/dev/null","pathOld":"src/java/org/apache/lucene/index/CheckIndex#check(Directory,boolean,List).mjava","sourceNew":null,"sourceOld":"  /** Returns true if index is clean, else false.\n   *  @deprecated Please instantiate a CheckIndex and then use {@link #checkIndex(List)} instead */\n  public static boolean check(Directory dir, boolean doFix, List onlySegments) throws IOException {\n    CheckIndex checker = new CheckIndex(dir);\n    Status status = checker.checkIndex(onlySegments);\n    if (doFix && !status.clean)\n      checker.fixIndex(status);\n\n    return status.clean;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"34e2c71b6406443562df54db233fde0728502f64":["9cb1313e01866149ff8dde7e80345a5476de305e"],"e99bed41006619061fcbe6431544a7eeeee2d9f1":["e82780afe6097066eb5befb86e9432f077667e3d"],"abfdd5170b43f046dfac9dafd6e12c1a65f3018c":["34e2c71b6406443562df54db233fde0728502f64"],"be2419774ad2eb3c65ca1cb035c3a2ccc6ae7da1":["7391c1f4ab1a6817de8a262f5c1b3de3cf190785"],"902ba79f4590a41c663c447756d2e5041cbbdda9":["abfdd5170b43f046dfac9dafd6e12c1a65f3018c"],"f51cb06175d6fae01dc608dd7ab884973354e4bf":["e99bed41006619061fcbe6431544a7eeeee2d9f1"],"7391c1f4ab1a6817de8a262f5c1b3de3cf190785":["cba44a7c8f0e3eb449bcdbd53960b7705c0bf902"],"9cb1313e01866149ff8dde7e80345a5476de305e":["f51cb06175d6fae01dc608dd7ab884973354e4bf"],"a64db7380e46c730a4ff0f00ebd7b29219312c14":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cba44a7c8f0e3eb449bcdbd53960b7705c0bf902":["902ba79f4590a41c663c447756d2e5041cbbdda9"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"e82780afe6097066eb5befb86e9432f077667e3d":["a64db7380e46c730a4ff0f00ebd7b29219312c14"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["be2419774ad2eb3c65ca1cb035c3a2ccc6ae7da1"]},"commit2Childs":{"34e2c71b6406443562df54db233fde0728502f64":["abfdd5170b43f046dfac9dafd6e12c1a65f3018c"],"e99bed41006619061fcbe6431544a7eeeee2d9f1":["f51cb06175d6fae01dc608dd7ab884973354e4bf"],"abfdd5170b43f046dfac9dafd6e12c1a65f3018c":["902ba79f4590a41c663c447756d2e5041cbbdda9"],"be2419774ad2eb3c65ca1cb035c3a2ccc6ae7da1":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"902ba79f4590a41c663c447756d2e5041cbbdda9":["cba44a7c8f0e3eb449bcdbd53960b7705c0bf902"],"f51cb06175d6fae01dc608dd7ab884973354e4bf":["9cb1313e01866149ff8dde7e80345a5476de305e"],"7391c1f4ab1a6817de8a262f5c1b3de3cf190785":["be2419774ad2eb3c65ca1cb035c3a2ccc6ae7da1"],"9cb1313e01866149ff8dde7e80345a5476de305e":["34e2c71b6406443562df54db233fde0728502f64"],"a64db7380e46c730a4ff0f00ebd7b29219312c14":["e82780afe6097066eb5befb86e9432f077667e3d"],"cba44a7c8f0e3eb449bcdbd53960b7705c0bf902":["7391c1f4ab1a6817de8a262f5c1b3de3cf190785"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["a64db7380e46c730a4ff0f00ebd7b29219312c14"],"e82780afe6097066eb5befb86e9432f077667e3d":["e99bed41006619061fcbe6431544a7eeeee2d9f1"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}