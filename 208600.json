{"path":"contrib/analyzers/src/java/org/apache/lucene/analysis/shingle/ShingleMatrixFilter#calculateShingleWeight(Token,List[Token],int,List[Matrix.Column.Row],List[Token]).mjava","commits":[{"id":"660fdd379b3fe276cd3a63d9c5852cef6dd5d54f","date":1215042831,"type":0,"author":"Karl-Johan Wettin","isMerge":false,"pathNew":"contrib/analyzers/src/java/org/apache/lucene/analysis/shingle/ShingleMatrixFilter#calculateShingleWeight(Token,List[Token],int,List[Matrix.Column.Row],List[Token]).mjava","pathOld":"/dev/null","sourceNew":"  /**\n   * Evaluates the new shingle token weight.\n   *\n   * for (shingle part token in shingle)\n   * weight +=  shingle part token weight * (1 / sqrt(all shingle part token weights summed))\n   *\n   * This algorithm gives a slightly greater score for longer shingles\n   * and is rather penalising to great shingle token part weights.  \n   *\n   * @param shingleToken token returned to consumer\n   * @param shingle tokens the tokens used to produce the shingle token.\n   * @param currentPermutationStartOffset start offset in parameter currentPermutationRows and currentPermutationTokens.\n   * @param currentPermutationRows an index to what matrix row a token in parameter currentPermutationTokens exist.\n   * @param currentPermuationTokens all tokens in the current row permutation of the matrix. A sub list (parameter offset, parameter shingle.size) equals parameter shingle.\n   * @return weight to be set for parameter shingleToken\n   */\n  public float calculateShingleWeight(Token shingleToken, List<Token> shingle, int currentPermutationStartOffset, List<Matrix.Column.Row> currentPermutationRows, List<Token> currentPermuationTokens) {\n    double[] weights = new double[shingle.size()];\n\n    double total = 0f;\n    double top = 0d;\n\n\n    for (int i=0; i<weights.length; i++) {\n      weights[i] = settingsCodec.getWeight(shingle.get(i));\n\n      double tmp = weights[i];\n      if (tmp > top) {\n        top = tmp;\n      }\n      total += tmp;\n    }\n\n    double factor = 1d / Math.sqrt(total);\n\n    double weight = 0d;\n    for (double partWeight : weights) {\n      weight += partWeight * factor;\n    }\n\n    return (float) weight;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"cbf0bdceb2051d3f9cb24580a849c9cd8b17ea56","date":1221157398,"type":5,"author":"Karl-Johan Wettin","isMerge":false,"pathNew":"contrib/analyzers/src/java/org/apache/lucene/analysis/shingle/ShingleMatrixFilter#calculateShingleWeight(Token,List,int,List,List).mjava","pathOld":"contrib/analyzers/src/java/org/apache/lucene/analysis/shingle/ShingleMatrixFilter#calculateShingleWeight(Token,List[Token],int,List[Matrix.Column.Row],List[Token]).mjava","sourceNew":"  /**\n   * Evaluates the new shingle token weight.\n   *\n   * for (shingle part token in shingle)\n   * weight +=  shingle part token weight * (1 / sqrt(all shingle part token weights summed))\n   *\n   * This algorithm gives a slightly greater score for longer shingles\n   * and is rather penalising to great shingle token part weights.  \n   *\n   * @param shingleToken token returned to consumer\n   * @param shingle tokens the tokens used to produce the shingle token.\n   * @param currentPermutationStartOffset start offset in parameter currentPermutationRows and currentPermutationTokens.\n   * @param currentPermutationRows an index to what matrix row a token in parameter currentPermutationTokens exist.\n   * @param currentPermuationTokens all tokens in the current row permutation of the matrix. A sub list (parameter offset, parameter shingle.size) equals parameter shingle.\n   * @return weight to be set for parameter shingleToken\n   */\n  public float calculateShingleWeight(Token shingleToken, List shingle, int currentPermutationStartOffset, List currentPermutationRows, List currentPermuationTokens) {\n    double[] weights = new double[shingle.size()];\n\n    double total = 0f;\n    double top = 0d;\n\n\n    for (int i=0; i<weights.length; i++) {\n      weights[i] = settingsCodec.getWeight((Token) shingle.get(i));\n\n      double tmp = weights[i];\n      if (tmp > top) {\n        top = tmp;\n      }\n      total += tmp;\n    }\n\n    double factor = 1d / Math.sqrt(total);\n\n    double weight = 0d;\n    for (int i = 0; i < weights.length; i++) {\n      double partWeight = weights[i];\n      weight += partWeight * factor;\n    }\n\n    return (float) weight;\n  }\n\n","sourceOld":"  /**\n   * Evaluates the new shingle token weight.\n   *\n   * for (shingle part token in shingle)\n   * weight +=  shingle part token weight * (1 / sqrt(all shingle part token weights summed))\n   *\n   * This algorithm gives a slightly greater score for longer shingles\n   * and is rather penalising to great shingle token part weights.  \n   *\n   * @param shingleToken token returned to consumer\n   * @param shingle tokens the tokens used to produce the shingle token.\n   * @param currentPermutationStartOffset start offset in parameter currentPermutationRows and currentPermutationTokens.\n   * @param currentPermutationRows an index to what matrix row a token in parameter currentPermutationTokens exist.\n   * @param currentPermuationTokens all tokens in the current row permutation of the matrix. A sub list (parameter offset, parameter shingle.size) equals parameter shingle.\n   * @return weight to be set for parameter shingleToken\n   */\n  public float calculateShingleWeight(Token shingleToken, List<Token> shingle, int currentPermutationStartOffset, List<Matrix.Column.Row> currentPermutationRows, List<Token> currentPermuationTokens) {\n    double[] weights = new double[shingle.size()];\n\n    double total = 0f;\n    double top = 0d;\n\n\n    for (int i=0; i<weights.length; i++) {\n      weights[i] = settingsCodec.getWeight(shingle.get(i));\n\n      double tmp = weights[i];\n      if (tmp > top) {\n        top = tmp;\n      }\n      total += tmp;\n    }\n\n    double factor = 1d / Math.sqrt(total);\n\n    double weight = 0d;\n    for (double partWeight : weights) {\n      weight += partWeight * factor;\n    }\n\n    return (float) weight;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"660fdd379b3fe276cd3a63d9c5852cef6dd5d54f":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cbf0bdceb2051d3f9cb24580a849c9cd8b17ea56":["660fdd379b3fe276cd3a63d9c5852cef6dd5d54f"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["cbf0bdceb2051d3f9cb24580a849c9cd8b17ea56"]},"commit2Childs":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["660fdd379b3fe276cd3a63d9c5852cef6dd5d54f"],"660fdd379b3fe276cd3a63d9c5852cef6dd5d54f":["cbf0bdceb2051d3f9cb24580a849c9cd8b17ea56"],"cbf0bdceb2051d3f9cb24580a849c9cd8b17ea56":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}