{"path":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggester#build(InputIterator).mjava","commits":[{"id":"41aee74b5f91a096e3fd950f4a336bc763f0e7a7","date":1381772070,"type":1,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggester#build(InputIterator).mjava","pathOld":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggester#build(TermFreqPayloadIterator).mjava","sourceNew":"  @Override\n  public void build(InputIterator iter) throws IOException {\n\n    if (searcher != null) {\n      searcher.getIndexReader().close();\n      searcher = null;\n    }\n\n\n    Directory dirTmp = getDirectory(new File(indexPath.toString() + \".tmp\"));\n\n    IndexWriter w = null;\n    IndexWriter w2 = null;\n    AtomicReader r = null;\n    boolean success = false;\n    try {\n      Analyzer gramAnalyzer = new AnalyzerWrapper(Analyzer.PER_FIELD_REUSE_STRATEGY) {\n          @Override\n          protected Analyzer getWrappedAnalyzer(String fieldName) {\n            return indexAnalyzer;\n          }\n\n          @Override\n          protected TokenStreamComponents wrapComponents(String fieldName, TokenStreamComponents components) {\n            if (fieldName.equals(\"textgrams\") && minPrefixChars > 0) {\n              return new TokenStreamComponents(components.getTokenizer(),\n                                               new EdgeNGramTokenFilter(matchVersion,\n                                                                        components.getTokenStream(),\n                                                                        1, minPrefixChars));\n            } else {\n              return components;\n            }\n          }\n        };\n\n      w = new IndexWriter(dirTmp,\n                          getIndexWriterConfig(matchVersion, gramAnalyzer));\n      BytesRef text;\n      Document doc = new Document();\n      FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n      ft.setIndexOptions(IndexOptions.DOCS_ONLY);\n      ft.setOmitNorms(true);\n      Field textField = new Field(TEXT_FIELD_NAME, \"\", ft);\n      doc.add(textField);\n\n      Field textGramField = new Field(\"textgrams\", \"\", ft);\n      doc.add(textGramField);\n\n      Field textDVField = new BinaryDocValuesField(TEXT_FIELD_NAME, new BytesRef());\n      doc.add(textDVField);\n\n      // TODO: use threads...?\n      Field weightField = new NumericDocValuesField(\"weight\", 0);\n      doc.add(weightField);\n\n      Field payloadField;\n      if (iter.hasPayloads()) {\n        payloadField = new BinaryDocValuesField(\"payloads\", new BytesRef());\n        doc.add(payloadField);\n      } else {\n        payloadField = null;\n      }\n\n      //long t0 = System.nanoTime();\n      while ((text = iter.next()) != null) {\n        String textString = text.utf8ToString();\n        textField.setStringValue(textString);\n        textGramField.setStringValue(textString);\n        textDVField.setBytesValue(text);\n        weightField.setLongValue(iter.weight());\n        if (iter.hasPayloads()) {\n          payloadField.setBytesValue(iter.payload());\n        }\n        w.addDocument(doc);\n      }\n      //System.out.println(\"initial indexing time: \" + ((System.nanoTime()-t0)/1000000) + \" msec\");\n\n      r = SlowCompositeReaderWrapper.wrap(DirectoryReader.open(w, false));\n      //long t1 = System.nanoTime();\n      w.rollback();\n\n      final int maxDoc = r.maxDoc();\n\n      final NumericDocValues weights = r.getNumericDocValues(\"weight\");\n\n      final Sorter.DocComparator comparator = new Sorter.DocComparator() {\n          @Override\n          public int compare(int docID1, int docID2) {\n            final long v1 = weights.get(docID1);\n            final long v2 = weights.get(docID2);\n            // Reverse sort (highest weight first);\n            // java7 only:\n            //return Long.compare(v2, v1);\n            if (v1 > v2) {\n              return -1;\n            } else if (v1 < v2) {\n              return 1;\n            } else {\n              return 0;\n            }\n          }\n        };\n\n      r = SortingAtomicReader.wrap(r, new Sorter() {\n          @Override\n          public Sorter.DocMap sort(AtomicReader reader) throws IOException {\n            return Sorter.sort(maxDoc, comparator);\n          }\n\n          @Override\n          public String getID() {\n            return \"Weight\";\n          }\n        });\n      \n      w2 = new IndexWriter(dir,\n                           getIndexWriterConfig(matchVersion, indexAnalyzer));\n      w2.addIndexes(new IndexReader[] {r});\n      r.close();\n\n      //System.out.println(\"sort time: \" + ((System.nanoTime()-t1)/1000000) + \" msec\");\n\n      searcher = new IndexSearcher(DirectoryReader.open(w2, false));\n      w2.close();\n\n      payloadsDV = MultiDocValues.getBinaryValues(searcher.getIndexReader(), \"payloads\");\n      weightsDV = MultiDocValues.getNumericValues(searcher.getIndexReader(), \"weight\");\n      textDV = MultiDocValues.getBinaryValues(searcher.getIndexReader(), TEXT_FIELD_NAME);\n      assert textDV != null;\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(w, w2, r, dirTmp);\n      } else {\n        IOUtils.closeWhileHandlingException(w, w2, r, dirTmp);\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  public void build(TermFreqPayloadIterator iter) throws IOException {\n\n    if (searcher != null) {\n      searcher.getIndexReader().close();\n      searcher = null;\n    }\n\n\n    Directory dirTmp = getDirectory(new File(indexPath.toString() + \".tmp\"));\n\n    IndexWriter w = null;\n    IndexWriter w2 = null;\n    AtomicReader r = null;\n    boolean success = false;\n    try {\n      Analyzer gramAnalyzer = new AnalyzerWrapper(Analyzer.PER_FIELD_REUSE_STRATEGY) {\n          @Override\n          protected Analyzer getWrappedAnalyzer(String fieldName) {\n            return indexAnalyzer;\n          }\n\n          @Override\n          protected TokenStreamComponents wrapComponents(String fieldName, TokenStreamComponents components) {\n            if (fieldName.equals(\"textgrams\") && minPrefixChars > 0) {\n              return new TokenStreamComponents(components.getTokenizer(),\n                                               new EdgeNGramTokenFilter(matchVersion,\n                                                                        components.getTokenStream(),\n                                                                        1, minPrefixChars));\n            } else {\n              return components;\n            }\n          }\n        };\n\n      w = new IndexWriter(dirTmp,\n                          getIndexWriterConfig(matchVersion, gramAnalyzer));\n      BytesRef text;\n      Document doc = new Document();\n      FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n      ft.setIndexOptions(IndexOptions.DOCS_ONLY);\n      ft.setOmitNorms(true);\n      Field textField = new Field(TEXT_FIELD_NAME, \"\", ft);\n      doc.add(textField);\n\n      Field textGramField = new Field(\"textgrams\", \"\", ft);\n      doc.add(textGramField);\n\n      Field textDVField = new BinaryDocValuesField(TEXT_FIELD_NAME, new BytesRef());\n      doc.add(textDVField);\n\n      // TODO: use threads...?\n      Field weightField = new NumericDocValuesField(\"weight\", 0);\n      doc.add(weightField);\n\n      Field payloadField;\n      if (iter.hasPayloads()) {\n        payloadField = new BinaryDocValuesField(\"payloads\", new BytesRef());\n        doc.add(payloadField);\n      } else {\n        payloadField = null;\n      }\n\n      //long t0 = System.nanoTime();\n      while ((text = iter.next()) != null) {\n        String textString = text.utf8ToString();\n        textField.setStringValue(textString);\n        textGramField.setStringValue(textString);\n        textDVField.setBytesValue(text);\n        weightField.setLongValue(iter.weight());\n        if (iter.hasPayloads()) {\n          payloadField.setBytesValue(iter.payload());\n        }\n        w.addDocument(doc);\n      }\n      //System.out.println(\"initial indexing time: \" + ((System.nanoTime()-t0)/1000000) + \" msec\");\n\n      r = SlowCompositeReaderWrapper.wrap(DirectoryReader.open(w, false));\n      //long t1 = System.nanoTime();\n      w.rollback();\n\n      final int maxDoc = r.maxDoc();\n\n      final NumericDocValues weights = r.getNumericDocValues(\"weight\");\n\n      final Sorter.DocComparator comparator = new Sorter.DocComparator() {\n          @Override\n          public int compare(int docID1, int docID2) {\n            final long v1 = weights.get(docID1);\n            final long v2 = weights.get(docID2);\n            // Reverse sort (highest weight first);\n            // java7 only:\n            //return Long.compare(v2, v1);\n            if (v1 > v2) {\n              return -1;\n            } else if (v1 < v2) {\n              return 1;\n            } else {\n              return 0;\n            }\n          }\n        };\n\n      r = SortingAtomicReader.wrap(r, new Sorter() {\n          @Override\n          public Sorter.DocMap sort(AtomicReader reader) throws IOException {\n            return Sorter.sort(maxDoc, comparator);\n          }\n\n          @Override\n          public String getID() {\n            return \"Weight\";\n          }\n        });\n      \n      w2 = new IndexWriter(dir,\n                           getIndexWriterConfig(matchVersion, indexAnalyzer));\n      w2.addIndexes(new IndexReader[] {r});\n      r.close();\n\n      //System.out.println(\"sort time: \" + ((System.nanoTime()-t1)/1000000) + \" msec\");\n\n      searcher = new IndexSearcher(DirectoryReader.open(w2, false));\n      w2.close();\n\n      payloadsDV = MultiDocValues.getBinaryValues(searcher.getIndexReader(), \"payloads\");\n      weightsDV = MultiDocValues.getNumericValues(searcher.getIndexReader(), \"weight\");\n      textDV = MultiDocValues.getBinaryValues(searcher.getIndexReader(), TEXT_FIELD_NAME);\n      assert textDV != null;\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(w, w2, r, dirTmp);\n      } else {\n        IOUtils.closeWhileHandlingException(w, w2, r, dirTmp);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f13ec1b606a28789743a563929e7c556e8218297","date":1389302034,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggester#build(InputIterator).mjava","pathOld":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggester#build(InputIterator).mjava","sourceNew":"  @Override\n  public void build(InputIterator iter) throws IOException {\n\n    if (searcher != null) {\n      searcher.getIndexReader().close();\n      searcher = null;\n    }\n\n\n    Directory dirTmp = getDirectory(new File(indexPath.toString() + \".tmp\"));\n\n    IndexWriter w = null;\n    IndexWriter w2 = null;\n    AtomicReader r = null;\n    boolean success = false;\n    try {\n      Analyzer gramAnalyzer = new AnalyzerWrapper(Analyzer.PER_FIELD_REUSE_STRATEGY) {\n          @Override\n          protected Analyzer getWrappedAnalyzer(String fieldName) {\n            return indexAnalyzer;\n          }\n\n          @Override\n          protected TokenStreamComponents wrapComponents(String fieldName, TokenStreamComponents components) {\n            if (fieldName.equals(\"textgrams\") && minPrefixChars > 0) {\n              return new TokenStreamComponents(components.getTokenizer(),\n                                               new EdgeNGramTokenFilter(matchVersion,\n                                                                        components.getTokenStream(),\n                                                                        1, minPrefixChars));\n            } else {\n              return components;\n            }\n          }\n        };\n\n      w = new IndexWriter(dirTmp,\n                          getIndexWriterConfig(matchVersion, gramAnalyzer));\n      BytesRef text;\n      Document doc = new Document();\n      FieldType ft = getTextFieldType();\n      Field textField = new Field(TEXT_FIELD_NAME, \"\", ft);\n      doc.add(textField);\n\n      Field textGramField = new Field(\"textgrams\", \"\", ft);\n      doc.add(textGramField);\n\n      Field textDVField = new BinaryDocValuesField(TEXT_FIELD_NAME, new BytesRef());\n      doc.add(textDVField);\n\n      // TODO: use threads...?\n      Field weightField = new NumericDocValuesField(\"weight\", 0);\n      doc.add(weightField);\n\n      Field payloadField;\n      if (iter.hasPayloads()) {\n        payloadField = new BinaryDocValuesField(\"payloads\", new BytesRef());\n        doc.add(payloadField);\n      } else {\n        payloadField = null;\n      }\n\n      //long t0 = System.nanoTime();\n      while ((text = iter.next()) != null) {\n        String textString = text.utf8ToString();\n        textField.setStringValue(textString);\n        textGramField.setStringValue(textString);\n        textDVField.setBytesValue(text);\n        weightField.setLongValue(iter.weight());\n        if (iter.hasPayloads()) {\n          payloadField.setBytesValue(iter.payload());\n        }\n        w.addDocument(doc);\n      }\n      //System.out.println(\"initial indexing time: \" + ((System.nanoTime()-t0)/1000000) + \" msec\");\n\n      r = SlowCompositeReaderWrapper.wrap(DirectoryReader.open(w, false));\n      //long t1 = System.nanoTime();\n      w.rollback();\n\n      final int maxDoc = r.maxDoc();\n\n      final NumericDocValues weights = r.getNumericDocValues(\"weight\");\n\n      final Sorter.DocComparator comparator = new Sorter.DocComparator() {\n          @Override\n          public int compare(int docID1, int docID2) {\n            final long v1 = weights.get(docID1);\n            final long v2 = weights.get(docID2);\n            // Reverse sort (highest weight first);\n            // java7 only:\n            //return Long.compare(v2, v1);\n            if (v1 > v2) {\n              return -1;\n            } else if (v1 < v2) {\n              return 1;\n            } else {\n              return 0;\n            }\n          }\n        };\n\n      r = SortingAtomicReader.wrap(r, new Sorter() {\n          @Override\n          public Sorter.DocMap sort(AtomicReader reader) throws IOException {\n            return Sorter.sort(maxDoc, comparator);\n          }\n\n          @Override\n          public String getID() {\n            return \"Weight\";\n          }\n        });\n      \n      w2 = new IndexWriter(dir,\n                           getIndexWriterConfig(matchVersion, indexAnalyzer));\n      w2.addIndexes(new IndexReader[] {r});\n      r.close();\n\n      //System.out.println(\"sort time: \" + ((System.nanoTime()-t1)/1000000) + \" msec\");\n\n      searcher = new IndexSearcher(DirectoryReader.open(w2, false));\n      w2.close();\n\n      payloadsDV = MultiDocValues.getBinaryValues(searcher.getIndexReader(), \"payloads\");\n      weightsDV = MultiDocValues.getNumericValues(searcher.getIndexReader(), \"weight\");\n      textDV = MultiDocValues.getBinaryValues(searcher.getIndexReader(), TEXT_FIELD_NAME);\n      assert textDV != null;\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(w, w2, r, dirTmp);\n      } else {\n        IOUtils.closeWhileHandlingException(w, w2, r, dirTmp);\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  public void build(InputIterator iter) throws IOException {\n\n    if (searcher != null) {\n      searcher.getIndexReader().close();\n      searcher = null;\n    }\n\n\n    Directory dirTmp = getDirectory(new File(indexPath.toString() + \".tmp\"));\n\n    IndexWriter w = null;\n    IndexWriter w2 = null;\n    AtomicReader r = null;\n    boolean success = false;\n    try {\n      Analyzer gramAnalyzer = new AnalyzerWrapper(Analyzer.PER_FIELD_REUSE_STRATEGY) {\n          @Override\n          protected Analyzer getWrappedAnalyzer(String fieldName) {\n            return indexAnalyzer;\n          }\n\n          @Override\n          protected TokenStreamComponents wrapComponents(String fieldName, TokenStreamComponents components) {\n            if (fieldName.equals(\"textgrams\") && minPrefixChars > 0) {\n              return new TokenStreamComponents(components.getTokenizer(),\n                                               new EdgeNGramTokenFilter(matchVersion,\n                                                                        components.getTokenStream(),\n                                                                        1, minPrefixChars));\n            } else {\n              return components;\n            }\n          }\n        };\n\n      w = new IndexWriter(dirTmp,\n                          getIndexWriterConfig(matchVersion, gramAnalyzer));\n      BytesRef text;\n      Document doc = new Document();\n      FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n      ft.setIndexOptions(IndexOptions.DOCS_ONLY);\n      ft.setOmitNorms(true);\n      Field textField = new Field(TEXT_FIELD_NAME, \"\", ft);\n      doc.add(textField);\n\n      Field textGramField = new Field(\"textgrams\", \"\", ft);\n      doc.add(textGramField);\n\n      Field textDVField = new BinaryDocValuesField(TEXT_FIELD_NAME, new BytesRef());\n      doc.add(textDVField);\n\n      // TODO: use threads...?\n      Field weightField = new NumericDocValuesField(\"weight\", 0);\n      doc.add(weightField);\n\n      Field payloadField;\n      if (iter.hasPayloads()) {\n        payloadField = new BinaryDocValuesField(\"payloads\", new BytesRef());\n        doc.add(payloadField);\n      } else {\n        payloadField = null;\n      }\n\n      //long t0 = System.nanoTime();\n      while ((text = iter.next()) != null) {\n        String textString = text.utf8ToString();\n        textField.setStringValue(textString);\n        textGramField.setStringValue(textString);\n        textDVField.setBytesValue(text);\n        weightField.setLongValue(iter.weight());\n        if (iter.hasPayloads()) {\n          payloadField.setBytesValue(iter.payload());\n        }\n        w.addDocument(doc);\n      }\n      //System.out.println(\"initial indexing time: \" + ((System.nanoTime()-t0)/1000000) + \" msec\");\n\n      r = SlowCompositeReaderWrapper.wrap(DirectoryReader.open(w, false));\n      //long t1 = System.nanoTime();\n      w.rollback();\n\n      final int maxDoc = r.maxDoc();\n\n      final NumericDocValues weights = r.getNumericDocValues(\"weight\");\n\n      final Sorter.DocComparator comparator = new Sorter.DocComparator() {\n          @Override\n          public int compare(int docID1, int docID2) {\n            final long v1 = weights.get(docID1);\n            final long v2 = weights.get(docID2);\n            // Reverse sort (highest weight first);\n            // java7 only:\n            //return Long.compare(v2, v1);\n            if (v1 > v2) {\n              return -1;\n            } else if (v1 < v2) {\n              return 1;\n            } else {\n              return 0;\n            }\n          }\n        };\n\n      r = SortingAtomicReader.wrap(r, new Sorter() {\n          @Override\n          public Sorter.DocMap sort(AtomicReader reader) throws IOException {\n            return Sorter.sort(maxDoc, comparator);\n          }\n\n          @Override\n          public String getID() {\n            return \"Weight\";\n          }\n        });\n      \n      w2 = new IndexWriter(dir,\n                           getIndexWriterConfig(matchVersion, indexAnalyzer));\n      w2.addIndexes(new IndexReader[] {r});\n      r.close();\n\n      //System.out.println(\"sort time: \" + ((System.nanoTime()-t1)/1000000) + \" msec\");\n\n      searcher = new IndexSearcher(DirectoryReader.open(w2, false));\n      w2.close();\n\n      payloadsDV = MultiDocValues.getBinaryValues(searcher.getIndexReader(), \"payloads\");\n      weightsDV = MultiDocValues.getNumericValues(searcher.getIndexReader(), \"weight\");\n      textDV = MultiDocValues.getBinaryValues(searcher.getIndexReader(), TEXT_FIELD_NAME);\n      assert textDV != null;\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(w, w2, r, dirTmp);\n      } else {\n        IOUtils.closeWhileHandlingException(w, w2, r, dirTmp);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"a645276cbaf5dc96a42fd473b9019bde352996c8","date":1391806699,"type":3,"author":"Areek Zillur","isMerge":false,"pathNew":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggester#build(InputIterator).mjava","pathOld":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggester#build(InputIterator).mjava","sourceNew":"  @Override\n  public void build(InputIterator iter) throws IOException {\n\n    if (searcher != null) {\n      searcher.getIndexReader().close();\n      searcher = null;\n    }\n\n\n    Directory dirTmp = getDirectory(new File(indexPath.toString() + \".tmp\"));\n\n    IndexWriter w = null;\n    IndexWriter w2 = null;\n    AtomicReader r = null;\n    boolean success = false;\n    count = 0;\n    try {\n      Analyzer gramAnalyzer = new AnalyzerWrapper(Analyzer.PER_FIELD_REUSE_STRATEGY) {\n          @Override\n          protected Analyzer getWrappedAnalyzer(String fieldName) {\n            return indexAnalyzer;\n          }\n\n          @Override\n          protected TokenStreamComponents wrapComponents(String fieldName, TokenStreamComponents components) {\n            if (fieldName.equals(\"textgrams\") && minPrefixChars > 0) {\n              return new TokenStreamComponents(components.getTokenizer(),\n                                               new EdgeNGramTokenFilter(matchVersion,\n                                                                        components.getTokenStream(),\n                                                                        1, minPrefixChars));\n            } else {\n              return components;\n            }\n          }\n        };\n\n      w = new IndexWriter(dirTmp,\n                          getIndexWriterConfig(matchVersion, gramAnalyzer));\n      BytesRef text;\n      Document doc = new Document();\n      FieldType ft = getTextFieldType();\n      Field textField = new Field(TEXT_FIELD_NAME, \"\", ft);\n      doc.add(textField);\n\n      Field textGramField = new Field(\"textgrams\", \"\", ft);\n      doc.add(textGramField);\n\n      Field textDVField = new BinaryDocValuesField(TEXT_FIELD_NAME, new BytesRef());\n      doc.add(textDVField);\n\n      // TODO: use threads...?\n      Field weightField = new NumericDocValuesField(\"weight\", 0);\n      doc.add(weightField);\n\n      Field payloadField;\n      if (iter.hasPayloads()) {\n        payloadField = new BinaryDocValuesField(\"payloads\", new BytesRef());\n        doc.add(payloadField);\n      } else {\n        payloadField = null;\n      }\n      //long t0 = System.nanoTime();\n      while ((text = iter.next()) != null) {\n        String textString = text.utf8ToString();\n        textField.setStringValue(textString);\n        textGramField.setStringValue(textString);\n        textDVField.setBytesValue(text);\n        weightField.setLongValue(iter.weight());\n        if (iter.hasPayloads()) {\n          payloadField.setBytesValue(iter.payload());\n        }\n        w.addDocument(doc);\n        count++;\n      }\n      //System.out.println(\"initial indexing time: \" + ((System.nanoTime()-t0)/1000000) + \" msec\");\n\n      r = SlowCompositeReaderWrapper.wrap(DirectoryReader.open(w, false));\n      //long t1 = System.nanoTime();\n      w.rollback();\n\n      final int maxDoc = r.maxDoc();\n\n      final NumericDocValues weights = r.getNumericDocValues(\"weight\");\n\n      final Sorter.DocComparator comparator = new Sorter.DocComparator() {\n          @Override\n          public int compare(int docID1, int docID2) {\n            final long v1 = weights.get(docID1);\n            final long v2 = weights.get(docID2);\n            // Reverse sort (highest weight first);\n            // java7 only:\n            //return Long.compare(v2, v1);\n            if (v1 > v2) {\n              return -1;\n            } else if (v1 < v2) {\n              return 1;\n            } else {\n              return 0;\n            }\n          }\n        };\n\n      r = SortingAtomicReader.wrap(r, new Sorter() {\n          @Override\n          public Sorter.DocMap sort(AtomicReader reader) throws IOException {\n            return Sorter.sort(maxDoc, comparator);\n          }\n\n          @Override\n          public String getID() {\n            return \"Weight\";\n          }\n        });\n      \n      w2 = new IndexWriter(dir,\n                           getIndexWriterConfig(matchVersion, indexAnalyzer));\n      w2.addIndexes(new IndexReader[] {r});\n      r.close();\n\n      //System.out.println(\"sort time: \" + ((System.nanoTime()-t1)/1000000) + \" msec\");\n\n      searcher = new IndexSearcher(DirectoryReader.open(w2, false));\n      w2.close();\n\n      payloadsDV = MultiDocValues.getBinaryValues(searcher.getIndexReader(), \"payloads\");\n      weightsDV = MultiDocValues.getNumericValues(searcher.getIndexReader(), \"weight\");\n      textDV = MultiDocValues.getBinaryValues(searcher.getIndexReader(), TEXT_FIELD_NAME);\n      assert textDV != null;\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(w, w2, r, dirTmp);\n      } else {\n        IOUtils.closeWhileHandlingException(w, w2, r, dirTmp);\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  public void build(InputIterator iter) throws IOException {\n\n    if (searcher != null) {\n      searcher.getIndexReader().close();\n      searcher = null;\n    }\n\n\n    Directory dirTmp = getDirectory(new File(indexPath.toString() + \".tmp\"));\n\n    IndexWriter w = null;\n    IndexWriter w2 = null;\n    AtomicReader r = null;\n    boolean success = false;\n    try {\n      Analyzer gramAnalyzer = new AnalyzerWrapper(Analyzer.PER_FIELD_REUSE_STRATEGY) {\n          @Override\n          protected Analyzer getWrappedAnalyzer(String fieldName) {\n            return indexAnalyzer;\n          }\n\n          @Override\n          protected TokenStreamComponents wrapComponents(String fieldName, TokenStreamComponents components) {\n            if (fieldName.equals(\"textgrams\") && minPrefixChars > 0) {\n              return new TokenStreamComponents(components.getTokenizer(),\n                                               new EdgeNGramTokenFilter(matchVersion,\n                                                                        components.getTokenStream(),\n                                                                        1, minPrefixChars));\n            } else {\n              return components;\n            }\n          }\n        };\n\n      w = new IndexWriter(dirTmp,\n                          getIndexWriterConfig(matchVersion, gramAnalyzer));\n      BytesRef text;\n      Document doc = new Document();\n      FieldType ft = getTextFieldType();\n      Field textField = new Field(TEXT_FIELD_NAME, \"\", ft);\n      doc.add(textField);\n\n      Field textGramField = new Field(\"textgrams\", \"\", ft);\n      doc.add(textGramField);\n\n      Field textDVField = new BinaryDocValuesField(TEXT_FIELD_NAME, new BytesRef());\n      doc.add(textDVField);\n\n      // TODO: use threads...?\n      Field weightField = new NumericDocValuesField(\"weight\", 0);\n      doc.add(weightField);\n\n      Field payloadField;\n      if (iter.hasPayloads()) {\n        payloadField = new BinaryDocValuesField(\"payloads\", new BytesRef());\n        doc.add(payloadField);\n      } else {\n        payloadField = null;\n      }\n\n      //long t0 = System.nanoTime();\n      while ((text = iter.next()) != null) {\n        String textString = text.utf8ToString();\n        textField.setStringValue(textString);\n        textGramField.setStringValue(textString);\n        textDVField.setBytesValue(text);\n        weightField.setLongValue(iter.weight());\n        if (iter.hasPayloads()) {\n          payloadField.setBytesValue(iter.payload());\n        }\n        w.addDocument(doc);\n      }\n      //System.out.println(\"initial indexing time: \" + ((System.nanoTime()-t0)/1000000) + \" msec\");\n\n      r = SlowCompositeReaderWrapper.wrap(DirectoryReader.open(w, false));\n      //long t1 = System.nanoTime();\n      w.rollback();\n\n      final int maxDoc = r.maxDoc();\n\n      final NumericDocValues weights = r.getNumericDocValues(\"weight\");\n\n      final Sorter.DocComparator comparator = new Sorter.DocComparator() {\n          @Override\n          public int compare(int docID1, int docID2) {\n            final long v1 = weights.get(docID1);\n            final long v2 = weights.get(docID2);\n            // Reverse sort (highest weight first);\n            // java7 only:\n            //return Long.compare(v2, v1);\n            if (v1 > v2) {\n              return -1;\n            } else if (v1 < v2) {\n              return 1;\n            } else {\n              return 0;\n            }\n          }\n        };\n\n      r = SortingAtomicReader.wrap(r, new Sorter() {\n          @Override\n          public Sorter.DocMap sort(AtomicReader reader) throws IOException {\n            return Sorter.sort(maxDoc, comparator);\n          }\n\n          @Override\n          public String getID() {\n            return \"Weight\";\n          }\n        });\n      \n      w2 = new IndexWriter(dir,\n                           getIndexWriterConfig(matchVersion, indexAnalyzer));\n      w2.addIndexes(new IndexReader[] {r});\n      r.close();\n\n      //System.out.println(\"sort time: \" + ((System.nanoTime()-t1)/1000000) + \" msec\");\n\n      searcher = new IndexSearcher(DirectoryReader.open(w2, false));\n      w2.close();\n\n      payloadsDV = MultiDocValues.getBinaryValues(searcher.getIndexReader(), \"payloads\");\n      weightsDV = MultiDocValues.getNumericValues(searcher.getIndexReader(), \"weight\");\n      textDV = MultiDocValues.getBinaryValues(searcher.getIndexReader(), TEXT_FIELD_NAME);\n      assert textDV != null;\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(w, w2, r, dirTmp);\n      } else {\n        IOUtils.closeWhileHandlingException(w, w2, r, dirTmp);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"a371aa649cc243e82cb8677ca960a1e0232ecedf","date":1393605574,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggester#build(InputIterator).mjava","pathOld":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggester#build(InputIterator).mjava","sourceNew":"  @Override\n  public void build(InputIterator iter) throws IOException {\n\n    if (searcherMgr != null) {\n      searcherMgr.close();\n      searcherMgr = null;\n    }\n\n    if (writer != null) {\n      writer.close();\n      writer = null;\n    }\n\n    Directory dirTmp = getDirectory(new File(indexPath.toString() + \".tmp\"));\n\n    IndexWriter w = null;\n    AtomicReader r = null;\n    boolean success = false;\n    try {\n      // First pass: build a temporary normal Lucene index,\n      // just indexing the suggestions as they iterate:\n      w = new IndexWriter(dirTmp,\n                          getIndexWriterConfig(matchVersion, getGramAnalyzer(), null, IndexWriterConfig.OpenMode.CREATE));\n      BytesRef text;\n      Document doc = new Document();\n      FieldType ft = getTextFieldType();\n      Field textField = new Field(TEXT_FIELD_NAME, \"\", ft);\n      doc.add(textField);\n\n      Field textGramField = new Field(\"textgrams\", \"\", ft);\n      doc.add(textGramField);\n\n      Field exactTextField = new StringField(EXACT_TEXT_FIELD_NAME, \"\", Field.Store.NO);\n      doc.add(exactTextField);\n\n      Field textDVField = new BinaryDocValuesField(TEXT_FIELD_NAME, new BytesRef());\n      doc.add(textDVField);\n\n      // TODO: use threads...?\n      Field weightField = new NumericDocValuesField(\"weight\", 0L);\n      doc.add(weightField);\n\n      Field payloadField;\n      if (iter.hasPayloads()) {\n        payloadField = new BinaryDocValuesField(\"payloads\", new BytesRef());\n        doc.add(payloadField);\n      } else {\n        payloadField = null;\n      }\n      //long t0 = System.nanoTime();\n      while ((text = iter.next()) != null) {\n        String textString = text.utf8ToString();\n        textField.setStringValue(textString);\n        exactTextField.setStringValue(textString);\n        textGramField.setStringValue(textString);\n        textDVField.setBytesValue(text);\n        weightField.setLongValue(iter.weight());\n        if (iter.hasPayloads()) {\n          payloadField.setBytesValue(iter.payload());\n        }\n        w.addDocument(doc);\n      }\n      //System.out.println(\"initial indexing time: \" + ((System.nanoTime()-t0)/1000000) + \" msec\");\n\n      // Second pass: sort the entire index:\n      r = SlowCompositeReaderWrapper.wrap(DirectoryReader.open(w, false));\n      //long t1 = System.nanoTime();\n\n      // We can rollback the first pass, now that have have\n      // the reader open, because we will discard it anyway\n      // (no sense in fsync'ing it):\n      w.rollback();\n\n      initSorter();\n\n      r = SortingAtomicReader.wrap(r, sorter);\n      \n      writer = new IndexWriter(dir,\n                               getIndexWriterConfig(matchVersion, getGramAnalyzer(), sorter, IndexWriterConfig.OpenMode.CREATE));\n      writer.addIndexes(new IndexReader[] {r});\n      r.close();\n\n      //System.out.println(\"sort time: \" + ((System.nanoTime()-t1)/1000000) + \" msec\");\n\n      searcherMgr = new SearcherManager(writer, true, null);\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(w, r, dirTmp);\n      } else {\n        IOUtils.closeWhileHandlingException(w, writer, r, dirTmp);\n        writer = null;\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  public void build(InputIterator iter) throws IOException {\n\n    if (searcher != null) {\n      searcher.getIndexReader().close();\n      searcher = null;\n    }\n\n\n    Directory dirTmp = getDirectory(new File(indexPath.toString() + \".tmp\"));\n\n    IndexWriter w = null;\n    IndexWriter w2 = null;\n    AtomicReader r = null;\n    boolean success = false;\n    count = 0;\n    try {\n      Analyzer gramAnalyzer = new AnalyzerWrapper(Analyzer.PER_FIELD_REUSE_STRATEGY) {\n          @Override\n          protected Analyzer getWrappedAnalyzer(String fieldName) {\n            return indexAnalyzer;\n          }\n\n          @Override\n          protected TokenStreamComponents wrapComponents(String fieldName, TokenStreamComponents components) {\n            if (fieldName.equals(\"textgrams\") && minPrefixChars > 0) {\n              return new TokenStreamComponents(components.getTokenizer(),\n                                               new EdgeNGramTokenFilter(matchVersion,\n                                                                        components.getTokenStream(),\n                                                                        1, minPrefixChars));\n            } else {\n              return components;\n            }\n          }\n        };\n\n      w = new IndexWriter(dirTmp,\n                          getIndexWriterConfig(matchVersion, gramAnalyzer));\n      BytesRef text;\n      Document doc = new Document();\n      FieldType ft = getTextFieldType();\n      Field textField = new Field(TEXT_FIELD_NAME, \"\", ft);\n      doc.add(textField);\n\n      Field textGramField = new Field(\"textgrams\", \"\", ft);\n      doc.add(textGramField);\n\n      Field textDVField = new BinaryDocValuesField(TEXT_FIELD_NAME, new BytesRef());\n      doc.add(textDVField);\n\n      // TODO: use threads...?\n      Field weightField = new NumericDocValuesField(\"weight\", 0);\n      doc.add(weightField);\n\n      Field payloadField;\n      if (iter.hasPayloads()) {\n        payloadField = new BinaryDocValuesField(\"payloads\", new BytesRef());\n        doc.add(payloadField);\n      } else {\n        payloadField = null;\n      }\n      //long t0 = System.nanoTime();\n      while ((text = iter.next()) != null) {\n        String textString = text.utf8ToString();\n        textField.setStringValue(textString);\n        textGramField.setStringValue(textString);\n        textDVField.setBytesValue(text);\n        weightField.setLongValue(iter.weight());\n        if (iter.hasPayloads()) {\n          payloadField.setBytesValue(iter.payload());\n        }\n        w.addDocument(doc);\n        count++;\n      }\n      //System.out.println(\"initial indexing time: \" + ((System.nanoTime()-t0)/1000000) + \" msec\");\n\n      r = SlowCompositeReaderWrapper.wrap(DirectoryReader.open(w, false));\n      //long t1 = System.nanoTime();\n      w.rollback();\n\n      final int maxDoc = r.maxDoc();\n\n      final NumericDocValues weights = r.getNumericDocValues(\"weight\");\n\n      final Sorter.DocComparator comparator = new Sorter.DocComparator() {\n          @Override\n          public int compare(int docID1, int docID2) {\n            final long v1 = weights.get(docID1);\n            final long v2 = weights.get(docID2);\n            // Reverse sort (highest weight first);\n            // java7 only:\n            //return Long.compare(v2, v1);\n            if (v1 > v2) {\n              return -1;\n            } else if (v1 < v2) {\n              return 1;\n            } else {\n              return 0;\n            }\n          }\n        };\n\n      r = SortingAtomicReader.wrap(r, new Sorter() {\n          @Override\n          public Sorter.DocMap sort(AtomicReader reader) throws IOException {\n            return Sorter.sort(maxDoc, comparator);\n          }\n\n          @Override\n          public String getID() {\n            return \"Weight\";\n          }\n        });\n      \n      w2 = new IndexWriter(dir,\n                           getIndexWriterConfig(matchVersion, indexAnalyzer));\n      w2.addIndexes(new IndexReader[] {r});\n      r.close();\n\n      //System.out.println(\"sort time: \" + ((System.nanoTime()-t1)/1000000) + \" msec\");\n\n      searcher = new IndexSearcher(DirectoryReader.open(w2, false));\n      w2.close();\n\n      payloadsDV = MultiDocValues.getBinaryValues(searcher.getIndexReader(), \"payloads\");\n      weightsDV = MultiDocValues.getNumericValues(searcher.getIndexReader(), \"weight\");\n      textDV = MultiDocValues.getBinaryValues(searcher.getIndexReader(), TEXT_FIELD_NAME);\n      assert textDV != null;\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(w, w2, r, dirTmp);\n      } else {\n        IOUtils.closeWhileHandlingException(w, w2, r, dirTmp);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":["4637747f71df783fc2014ef1f1e0418466e3bed6"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b638f37b6d00b06fa8d6875cea1df4b274d6e87a","date":1394120449,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggester#build(InputIterator).mjava","pathOld":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggester#build(InputIterator).mjava","sourceNew":"  @Override\n  public void build(InputIterator iter) throws IOException {\n\n    if (searcherMgr != null) {\n      searcherMgr.close();\n      searcherMgr = null;\n    }\n\n    if (writer != null) {\n      writer.close();\n      writer = null;\n    }\n\n    Directory dirTmp = getDirectory(new File(indexPath.toString() + \".tmp\"));\n\n    IndexWriter w = null;\n    AtomicReader r = null;\n    boolean success = false;\n    try {\n      // First pass: build a temporary normal Lucene index,\n      // just indexing the suggestions as they iterate:\n      w = new IndexWriter(dirTmp,\n                          getIndexWriterConfig(matchVersion, getGramAnalyzer(), null, IndexWriterConfig.OpenMode.CREATE));\n      BytesRef text;\n      Document doc = new Document();\n      FieldType ft = getTextFieldType();\n      Field textField = new Field(TEXT_FIELD_NAME, \"\", ft);\n      doc.add(textField);\n\n      Field textGramField = new Field(\"textgrams\", \"\", ft);\n      doc.add(textGramField);\n\n      Field exactTextField = new StringField(EXACT_TEXT_FIELD_NAME, \"\", Field.Store.NO);\n      doc.add(exactTextField);\n\n      Field textDVField = new BinaryDocValuesField(TEXT_FIELD_NAME, new BytesRef());\n      doc.add(textDVField);\n\n      // TODO: use threads...?\n      Field weightField = new NumericDocValuesField(\"weight\", 0L);\n      doc.add(weightField);\n\n      Field payloadField;\n      if (iter.hasPayloads()) {\n        payloadField = new BinaryDocValuesField(\"payloads\", new BytesRef());\n        doc.add(payloadField);\n      } else {\n        payloadField = null;\n      }\n      //long t0 = System.nanoTime();\n      while ((text = iter.next()) != null) {\n        String textString = text.utf8ToString();\n        textField.setStringValue(textString);\n        exactTextField.setStringValue(textString);\n        textGramField.setStringValue(textString);\n        textDVField.setBytesValue(text);\n        weightField.setLongValue(iter.weight());\n        if (iter.hasPayloads()) {\n          payloadField.setBytesValue(iter.payload());\n        }\n        w.addDocument(doc);\n      }\n      //System.out.println(\"initial indexing time: \" + ((System.nanoTime()-t0)/1000000) + \" msec\");\n\n      // Second pass: sort the entire index:\n      r = SlowCompositeReaderWrapper.wrap(DirectoryReader.open(w, false));\n      //long t1 = System.nanoTime();\n\n      // We can rollback the first pass, now that have have\n      // the reader open, because we will discard it anyway\n      // (no sense in fsync'ing it):\n      w.rollback();\n\n      r = SortingAtomicReader.wrap(r, SORT);\n      \n      writer = new IndexWriter(dir,\n                               getIndexWriterConfig(matchVersion, getGramAnalyzer(), SORT, IndexWriterConfig.OpenMode.CREATE));\n      writer.addIndexes(new IndexReader[] {r});\n      r.close();\n\n      //System.out.println(\"sort time: \" + ((System.nanoTime()-t1)/1000000) + \" msec\");\n\n      searcherMgr = new SearcherManager(writer, true, null);\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(w, r, dirTmp);\n      } else {\n        IOUtils.closeWhileHandlingException(w, writer, r, dirTmp);\n        writer = null;\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  public void build(InputIterator iter) throws IOException {\n\n    if (searcherMgr != null) {\n      searcherMgr.close();\n      searcherMgr = null;\n    }\n\n    if (writer != null) {\n      writer.close();\n      writer = null;\n    }\n\n    Directory dirTmp = getDirectory(new File(indexPath.toString() + \".tmp\"));\n\n    IndexWriter w = null;\n    AtomicReader r = null;\n    boolean success = false;\n    try {\n      // First pass: build a temporary normal Lucene index,\n      // just indexing the suggestions as they iterate:\n      w = new IndexWriter(dirTmp,\n                          getIndexWriterConfig(matchVersion, getGramAnalyzer(), null, IndexWriterConfig.OpenMode.CREATE));\n      BytesRef text;\n      Document doc = new Document();\n      FieldType ft = getTextFieldType();\n      Field textField = new Field(TEXT_FIELD_NAME, \"\", ft);\n      doc.add(textField);\n\n      Field textGramField = new Field(\"textgrams\", \"\", ft);\n      doc.add(textGramField);\n\n      Field exactTextField = new StringField(EXACT_TEXT_FIELD_NAME, \"\", Field.Store.NO);\n      doc.add(exactTextField);\n\n      Field textDVField = new BinaryDocValuesField(TEXT_FIELD_NAME, new BytesRef());\n      doc.add(textDVField);\n\n      // TODO: use threads...?\n      Field weightField = new NumericDocValuesField(\"weight\", 0L);\n      doc.add(weightField);\n\n      Field payloadField;\n      if (iter.hasPayloads()) {\n        payloadField = new BinaryDocValuesField(\"payloads\", new BytesRef());\n        doc.add(payloadField);\n      } else {\n        payloadField = null;\n      }\n      //long t0 = System.nanoTime();\n      while ((text = iter.next()) != null) {\n        String textString = text.utf8ToString();\n        textField.setStringValue(textString);\n        exactTextField.setStringValue(textString);\n        textGramField.setStringValue(textString);\n        textDVField.setBytesValue(text);\n        weightField.setLongValue(iter.weight());\n        if (iter.hasPayloads()) {\n          payloadField.setBytesValue(iter.payload());\n        }\n        w.addDocument(doc);\n      }\n      //System.out.println(\"initial indexing time: \" + ((System.nanoTime()-t0)/1000000) + \" msec\");\n\n      // Second pass: sort the entire index:\n      r = SlowCompositeReaderWrapper.wrap(DirectoryReader.open(w, false));\n      //long t1 = System.nanoTime();\n\n      // We can rollback the first pass, now that have have\n      // the reader open, because we will discard it anyway\n      // (no sense in fsync'ing it):\n      w.rollback();\n\n      initSorter();\n\n      r = SortingAtomicReader.wrap(r, sorter);\n      \n      writer = new IndexWriter(dir,\n                               getIndexWriterConfig(matchVersion, getGramAnalyzer(), sorter, IndexWriterConfig.OpenMode.CREATE));\n      writer.addIndexes(new IndexReader[] {r});\n      r.close();\n\n      //System.out.println(\"sort time: \" + ((System.nanoTime()-t1)/1000000) + \" msec\");\n\n      searcherMgr = new SearcherManager(writer, true, null);\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(w, r, dirTmp);\n      } else {\n        IOUtils.closeWhileHandlingException(w, writer, r, dirTmp);\n        writer = null;\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"f1e7da8a91a92330e8f04b171b83e655a4a25c31","date":1394125906,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggester#build(InputIterator).mjava","pathOld":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggester#build(InputIterator).mjava","sourceNew":"  @Override\n  public void build(InputIterator iter) throws IOException {\n\n    if (searcherMgr != null) {\n      searcherMgr.close();\n      searcherMgr = null;\n    }\n\n    if (writer != null) {\n      writer.close();\n      writer = null;\n    }\n\n    AtomicReader r = null;\n    boolean success = false;\n    try {\n      // First pass: build a temporary normal Lucene index,\n      // just indexing the suggestions as they iterate:\n      writer = new IndexWriter(dir,\n                               getIndexWriterConfig(matchVersion, getGramAnalyzer(), IndexWriterConfig.OpenMode.CREATE));\n      BytesRef text;\n      Document doc = new Document();\n      FieldType ft = getTextFieldType();\n      Field textField = new Field(TEXT_FIELD_NAME, \"\", ft);\n      doc.add(textField);\n\n      Field textGramField = new Field(\"textgrams\", \"\", ft);\n      doc.add(textGramField);\n\n      Field exactTextField = new StringField(EXACT_TEXT_FIELD_NAME, \"\", Field.Store.NO);\n      doc.add(exactTextField);\n\n      Field textDVField = new BinaryDocValuesField(TEXT_FIELD_NAME, new BytesRef());\n      doc.add(textDVField);\n\n      // TODO: use threads...?\n      Field weightField = new NumericDocValuesField(\"weight\", 0L);\n      doc.add(weightField);\n\n      Field payloadField;\n      if (iter.hasPayloads()) {\n        payloadField = new BinaryDocValuesField(\"payloads\", new BytesRef());\n        doc.add(payloadField);\n      } else {\n        payloadField = null;\n      }\n      //long t0 = System.nanoTime();\n      while ((text = iter.next()) != null) {\n        String textString = text.utf8ToString();\n        textField.setStringValue(textString);\n        exactTextField.setStringValue(textString);\n        textGramField.setStringValue(textString);\n        textDVField.setBytesValue(text);\n        weightField.setLongValue(iter.weight());\n        if (iter.hasPayloads()) {\n          payloadField.setBytesValue(iter.payload());\n        }\n        writer.addDocument(doc);\n      }\n      //System.out.println(\"initial indexing time: \" + ((System.nanoTime()-t0)/1000000) + \" msec\");\n\n      searcherMgr = new SearcherManager(writer, true, null);\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(r);\n      } else {\n        IOUtils.closeWhileHandlingException(writer, r);\n        writer = null;\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  public void build(InputIterator iter) throws IOException {\n\n    if (searcherMgr != null) {\n      searcherMgr.close();\n      searcherMgr = null;\n    }\n\n    if (writer != null) {\n      writer.close();\n      writer = null;\n    }\n\n    Directory dirTmp = getDirectory(new File(indexPath.toString() + \".tmp\"));\n\n    IndexWriter w = null;\n    AtomicReader r = null;\n    boolean success = false;\n    try {\n      // First pass: build a temporary normal Lucene index,\n      // just indexing the suggestions as they iterate:\n      w = new IndexWriter(dirTmp,\n                          getIndexWriterConfig(matchVersion, getGramAnalyzer(), null, IndexWriterConfig.OpenMode.CREATE));\n      BytesRef text;\n      Document doc = new Document();\n      FieldType ft = getTextFieldType();\n      Field textField = new Field(TEXT_FIELD_NAME, \"\", ft);\n      doc.add(textField);\n\n      Field textGramField = new Field(\"textgrams\", \"\", ft);\n      doc.add(textGramField);\n\n      Field exactTextField = new StringField(EXACT_TEXT_FIELD_NAME, \"\", Field.Store.NO);\n      doc.add(exactTextField);\n\n      Field textDVField = new BinaryDocValuesField(TEXT_FIELD_NAME, new BytesRef());\n      doc.add(textDVField);\n\n      // TODO: use threads...?\n      Field weightField = new NumericDocValuesField(\"weight\", 0L);\n      doc.add(weightField);\n\n      Field payloadField;\n      if (iter.hasPayloads()) {\n        payloadField = new BinaryDocValuesField(\"payloads\", new BytesRef());\n        doc.add(payloadField);\n      } else {\n        payloadField = null;\n      }\n      //long t0 = System.nanoTime();\n      while ((text = iter.next()) != null) {\n        String textString = text.utf8ToString();\n        textField.setStringValue(textString);\n        exactTextField.setStringValue(textString);\n        textGramField.setStringValue(textString);\n        textDVField.setBytesValue(text);\n        weightField.setLongValue(iter.weight());\n        if (iter.hasPayloads()) {\n          payloadField.setBytesValue(iter.payload());\n        }\n        w.addDocument(doc);\n      }\n      //System.out.println(\"initial indexing time: \" + ((System.nanoTime()-t0)/1000000) + \" msec\");\n\n      // Second pass: sort the entire index:\n      r = SlowCompositeReaderWrapper.wrap(DirectoryReader.open(w, false));\n      //long t1 = System.nanoTime();\n\n      // We can rollback the first pass, now that have have\n      // the reader open, because we will discard it anyway\n      // (no sense in fsync'ing it):\n      w.rollback();\n\n      r = SortingAtomicReader.wrap(r, SORT);\n      \n      writer = new IndexWriter(dir,\n                               getIndexWriterConfig(matchVersion, getGramAnalyzer(), SORT, IndexWriterConfig.OpenMode.CREATE));\n      writer.addIndexes(new IndexReader[] {r});\n      r.close();\n\n      //System.out.println(\"sort time: \" + ((System.nanoTime()-t1)/1000000) + \" msec\");\n\n      searcherMgr = new SearcherManager(writer, true, null);\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(w, r, dirTmp);\n      } else {\n        IOUtils.closeWhileHandlingException(w, writer, r, dirTmp);\n        writer = null;\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"4637747f71df783fc2014ef1f1e0418466e3bed6","date":1394196311,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggester#build(InputIterator).mjava","pathOld":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggester#build(InputIterator).mjava","sourceNew":"  @Override\n  public void build(InputIterator iter) throws IOException {\n\n    if (searcherMgr != null) {\n      searcherMgr.close();\n      searcherMgr = null;\n    }\n\n    if (writer != null) {\n      writer.close();\n      writer = null;\n    }\n\n    AtomicReader r = null;\n    boolean success = false;\n    try {\n      // First pass: build a temporary normal Lucene index,\n      // just indexing the suggestions as they iterate:\n      writer = new IndexWriter(dir,\n                               getIndexWriterConfig(matchVersion, getGramAnalyzer(), IndexWriterConfig.OpenMode.CREATE));\n      BytesRef text;\n      Document doc = new Document();\n      FieldType ft = getTextFieldType();\n      Field textField = new Field(TEXT_FIELD_NAME, \"\", ft);\n      doc.add(textField);\n\n      Field textGramField = new Field(\"textgrams\", \"\", ft);\n      doc.add(textGramField);\n\n      Field exactTextField = new StringField(EXACT_TEXT_FIELD_NAME, \"\", Field.Store.NO);\n      doc.add(exactTextField);\n\n      Field textDVField = new BinaryDocValuesField(TEXT_FIELD_NAME, new BytesRef());\n      doc.add(textDVField);\n\n      // TODO: use threads...?\n      Field weightField = new NumericDocValuesField(\"weight\", 0L);\n      doc.add(weightField);\n\n      Field payloadField;\n      if (iter.hasPayloads()) {\n        payloadField = new BinaryDocValuesField(\"payloads\", new BytesRef());\n        doc.add(payloadField);\n      } else {\n        payloadField = null;\n      }\n      //long t0 = System.nanoTime();\n      while ((text = iter.next()) != null) {\n        String textString = text.utf8ToString();\n        textField.setStringValue(textString);\n        exactTextField.setStringValue(textString);\n        textGramField.setStringValue(textString);\n        textDVField.setBytesValue(text);\n        weightField.setLongValue(iter.weight());\n        if (iter.hasPayloads()) {\n          payloadField.setBytesValue(iter.payload());\n        }\n        writer.addDocument(doc);\n      }\n      //System.out.println(\"initial indexing time: \" + ((System.nanoTime()-t0)/1000000) + \" msec\");\n\n      searcherMgr = new SearcherManager(writer, true, null);\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(r);\n      } else {\n        IOUtils.closeWhileHandlingException(writer, r);\n        writer = null;\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  public void build(InputIterator iter) throws IOException {\n\n    if (searcherMgr != null) {\n      searcherMgr.close();\n      searcherMgr = null;\n    }\n\n    if (writer != null) {\n      writer.close();\n      writer = null;\n    }\n\n    Directory dirTmp = getDirectory(new File(indexPath.toString() + \".tmp\"));\n\n    IndexWriter w = null;\n    AtomicReader r = null;\n    boolean success = false;\n    try {\n      // First pass: build a temporary normal Lucene index,\n      // just indexing the suggestions as they iterate:\n      w = new IndexWriter(dirTmp,\n                          getIndexWriterConfig(matchVersion, getGramAnalyzer(), null, IndexWriterConfig.OpenMode.CREATE));\n      BytesRef text;\n      Document doc = new Document();\n      FieldType ft = getTextFieldType();\n      Field textField = new Field(TEXT_FIELD_NAME, \"\", ft);\n      doc.add(textField);\n\n      Field textGramField = new Field(\"textgrams\", \"\", ft);\n      doc.add(textGramField);\n\n      Field exactTextField = new StringField(EXACT_TEXT_FIELD_NAME, \"\", Field.Store.NO);\n      doc.add(exactTextField);\n\n      Field textDVField = new BinaryDocValuesField(TEXT_FIELD_NAME, new BytesRef());\n      doc.add(textDVField);\n\n      // TODO: use threads...?\n      Field weightField = new NumericDocValuesField(\"weight\", 0L);\n      doc.add(weightField);\n\n      Field payloadField;\n      if (iter.hasPayloads()) {\n        payloadField = new BinaryDocValuesField(\"payloads\", new BytesRef());\n        doc.add(payloadField);\n      } else {\n        payloadField = null;\n      }\n      //long t0 = System.nanoTime();\n      while ((text = iter.next()) != null) {\n        String textString = text.utf8ToString();\n        textField.setStringValue(textString);\n        exactTextField.setStringValue(textString);\n        textGramField.setStringValue(textString);\n        textDVField.setBytesValue(text);\n        weightField.setLongValue(iter.weight());\n        if (iter.hasPayloads()) {\n          payloadField.setBytesValue(iter.payload());\n        }\n        w.addDocument(doc);\n      }\n      //System.out.println(\"initial indexing time: \" + ((System.nanoTime()-t0)/1000000) + \" msec\");\n\n      // Second pass: sort the entire index:\n      r = SlowCompositeReaderWrapper.wrap(DirectoryReader.open(w, false));\n      //long t1 = System.nanoTime();\n\n      // We can rollback the first pass, now that have have\n      // the reader open, because we will discard it anyway\n      // (no sense in fsync'ing it):\n      w.rollback();\n\n      initSorter();\n\n      r = SortingAtomicReader.wrap(r, sorter);\n      \n      writer = new IndexWriter(dir,\n                               getIndexWriterConfig(matchVersion, getGramAnalyzer(), sorter, IndexWriterConfig.OpenMode.CREATE));\n      writer.addIndexes(new IndexReader[] {r});\n      r.close();\n\n      //System.out.println(\"sort time: \" + ((System.nanoTime()-t1)/1000000) + \" msec\");\n\n      searcherMgr = new SearcherManager(writer, true, null);\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(w, r, dirTmp);\n      } else {\n        IOUtils.closeWhileHandlingException(w, writer, r, dirTmp);\n        writer = null;\n      }\n    }\n  }\n\n","bugFix":["b3aad8246db872dc16fbe6109f893457496b0240","33ba398fa7984fdcb45fd76b87504d5adf7ca5e3","df9bf66ed405ee5c7d32b47bdb36c2e36d2c1392","a371aa649cc243e82cb8677ca960a1e0232ecedf"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"96ea64d994d340044e0d57aeb6a5871539d10ca5","date":1394225445,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggester#build(InputIterator).mjava","pathOld":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggester#build(InputIterator).mjava","sourceNew":"  @Override\n  public void build(InputIterator iter) throws IOException {\n\n    if (searcherMgr != null) {\n      searcherMgr.close();\n      searcherMgr = null;\n    }\n\n    if (writer != null) {\n      writer.close();\n      writer = null;\n    }\n\n    AtomicReader r = null;\n    boolean success = false;\n    try {\n      // First pass: build a temporary normal Lucene index,\n      // just indexing the suggestions as they iterate:\n      writer = new IndexWriter(dir,\n                               getIndexWriterConfig(matchVersion, getGramAnalyzer(), IndexWriterConfig.OpenMode.CREATE));\n      BytesRef text;\n      Document doc = new Document();\n      FieldType ft = getTextFieldType();\n      Field textField = new Field(TEXT_FIELD_NAME, \"\", ft);\n      doc.add(textField);\n\n      Field textGramField = new Field(\"textgrams\", \"\", ft);\n      doc.add(textGramField);\n\n      Field exactTextField = new StringField(EXACT_TEXT_FIELD_NAME, \"\", Field.Store.NO);\n      doc.add(exactTextField);\n\n      Field textDVField = new BinaryDocValuesField(TEXT_FIELD_NAME, new BytesRef());\n      doc.add(textDVField);\n\n      // TODO: use threads...?\n      Field weightField = new NumericDocValuesField(\"weight\", 0L);\n      doc.add(weightField);\n\n      Field payloadField;\n      if (iter.hasPayloads()) {\n        payloadField = new BinaryDocValuesField(\"payloads\", new BytesRef());\n        doc.add(payloadField);\n      } else {\n        payloadField = null;\n      }\n      //long t0 = System.nanoTime();\n      while ((text = iter.next()) != null) {\n        String textString = text.utf8ToString();\n        textField.setStringValue(textString);\n        exactTextField.setStringValue(textString);\n        textGramField.setStringValue(textString);\n        textDVField.setBytesValue(text);\n        weightField.setLongValue(iter.weight());\n        if (iter.hasPayloads()) {\n          payloadField.setBytesValue(iter.payload());\n        }\n        writer.addDocument(doc);\n      }\n      //System.out.println(\"initial indexing time: \" + ((System.nanoTime()-t0)/1000000) + \" msec\");\n\n      searcherMgr = new SearcherManager(writer, true, null);\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(r);\n      } else {\n        IOUtils.closeWhileHandlingException(writer, r);\n        writer = null;\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  public void build(InputIterator iter) throws IOException {\n\n    if (searcherMgr != null) {\n      searcherMgr.close();\n      searcherMgr = null;\n    }\n\n    if (writer != null) {\n      writer.close();\n      writer = null;\n    }\n\n    Directory dirTmp = getDirectory(new File(indexPath.toString() + \".tmp\"));\n\n    IndexWriter w = null;\n    AtomicReader r = null;\n    boolean success = false;\n    try {\n      // First pass: build a temporary normal Lucene index,\n      // just indexing the suggestions as they iterate:\n      w = new IndexWriter(dirTmp,\n                          getIndexWriterConfig(matchVersion, getGramAnalyzer(), null, IndexWriterConfig.OpenMode.CREATE));\n      BytesRef text;\n      Document doc = new Document();\n      FieldType ft = getTextFieldType();\n      Field textField = new Field(TEXT_FIELD_NAME, \"\", ft);\n      doc.add(textField);\n\n      Field textGramField = new Field(\"textgrams\", \"\", ft);\n      doc.add(textGramField);\n\n      Field exactTextField = new StringField(EXACT_TEXT_FIELD_NAME, \"\", Field.Store.NO);\n      doc.add(exactTextField);\n\n      Field textDVField = new BinaryDocValuesField(TEXT_FIELD_NAME, new BytesRef());\n      doc.add(textDVField);\n\n      // TODO: use threads...?\n      Field weightField = new NumericDocValuesField(\"weight\", 0L);\n      doc.add(weightField);\n\n      Field payloadField;\n      if (iter.hasPayloads()) {\n        payloadField = new BinaryDocValuesField(\"payloads\", new BytesRef());\n        doc.add(payloadField);\n      } else {\n        payloadField = null;\n      }\n      //long t0 = System.nanoTime();\n      while ((text = iter.next()) != null) {\n        String textString = text.utf8ToString();\n        textField.setStringValue(textString);\n        exactTextField.setStringValue(textString);\n        textGramField.setStringValue(textString);\n        textDVField.setBytesValue(text);\n        weightField.setLongValue(iter.weight());\n        if (iter.hasPayloads()) {\n          payloadField.setBytesValue(iter.payload());\n        }\n        w.addDocument(doc);\n      }\n      //System.out.println(\"initial indexing time: \" + ((System.nanoTime()-t0)/1000000) + \" msec\");\n\n      // Second pass: sort the entire index:\n      r = SlowCompositeReaderWrapper.wrap(DirectoryReader.open(w, false));\n      //long t1 = System.nanoTime();\n\n      // We can rollback the first pass, now that have have\n      // the reader open, because we will discard it anyway\n      // (no sense in fsync'ing it):\n      w.rollback();\n\n      initSorter();\n\n      r = SortingAtomicReader.wrap(r, sorter);\n      \n      writer = new IndexWriter(dir,\n                               getIndexWriterConfig(matchVersion, getGramAnalyzer(), sorter, IndexWriterConfig.OpenMode.CREATE));\n      writer.addIndexes(new IndexReader[] {r});\n      r.close();\n\n      //System.out.println(\"sort time: \" + ((System.nanoTime()-t1)/1000000) + \" msec\");\n\n      searcherMgr = new SearcherManager(writer, true, null);\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(w, r, dirTmp);\n      } else {\n        IOUtils.closeWhileHandlingException(w, writer, r, dirTmp);\n        writer = null;\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"58d0345a28bb6b4be59c38e6a77e2cc0e615ee4b","date":1395588343,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggester#build(InputIterator).mjava","pathOld":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggester#build(InputIterator).mjava","sourceNew":"  @Override\n  public void build(InputIterator iter) throws IOException {\n    \n    if (searcherMgr != null) {\n      searcherMgr.close();\n      searcherMgr = null;\n    }\n\n    if (writer != null) {\n      writer.close();\n      writer = null;\n    }\n\n    AtomicReader r = null;\n    boolean success = false;\n    try {\n      // First pass: build a temporary normal Lucene index,\n      // just indexing the suggestions as they iterate:\n      writer = new IndexWriter(dir,\n                               getIndexWriterConfig(matchVersion, getGramAnalyzer(), IndexWriterConfig.OpenMode.CREATE));\n      //long t0 = System.nanoTime();\n\n      // TODO: use threads?\n      BytesRef text;\n      while ((text = iter.next()) != null) {\n        BytesRef payload;\n        if (iter.hasPayloads()) {\n          payload = iter.payload();\n        } else {\n          payload = null;\n        }\n\n        add(text, iter.contexts(), iter.weight(), payload);\n      }\n\n      //System.out.println(\"initial indexing time: \" + ((System.nanoTime()-t0)/1000000) + \" msec\");\n\n      searcherMgr = new SearcherManager(writer, true, null);\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(r);\n      } else {\n        IOUtils.closeWhileHandlingException(writer, r);\n        writer = null;\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  public void build(InputIterator iter) throws IOException {\n\n    if (searcherMgr != null) {\n      searcherMgr.close();\n      searcherMgr = null;\n    }\n\n    if (writer != null) {\n      writer.close();\n      writer = null;\n    }\n\n    AtomicReader r = null;\n    boolean success = false;\n    try {\n      // First pass: build a temporary normal Lucene index,\n      // just indexing the suggestions as they iterate:\n      writer = new IndexWriter(dir,\n                               getIndexWriterConfig(matchVersion, getGramAnalyzer(), IndexWriterConfig.OpenMode.CREATE));\n      BytesRef text;\n      Document doc = new Document();\n      FieldType ft = getTextFieldType();\n      Field textField = new Field(TEXT_FIELD_NAME, \"\", ft);\n      doc.add(textField);\n\n      Field textGramField = new Field(\"textgrams\", \"\", ft);\n      doc.add(textGramField);\n\n      Field exactTextField = new StringField(EXACT_TEXT_FIELD_NAME, \"\", Field.Store.NO);\n      doc.add(exactTextField);\n\n      Field textDVField = new BinaryDocValuesField(TEXT_FIELD_NAME, new BytesRef());\n      doc.add(textDVField);\n\n      // TODO: use threads...?\n      Field weightField = new NumericDocValuesField(\"weight\", 0L);\n      doc.add(weightField);\n\n      Field payloadField;\n      if (iter.hasPayloads()) {\n        payloadField = new BinaryDocValuesField(\"payloads\", new BytesRef());\n        doc.add(payloadField);\n      } else {\n        payloadField = null;\n      }\n      //long t0 = System.nanoTime();\n      while ((text = iter.next()) != null) {\n        String textString = text.utf8ToString();\n        textField.setStringValue(textString);\n        exactTextField.setStringValue(textString);\n        textGramField.setStringValue(textString);\n        textDVField.setBytesValue(text);\n        weightField.setLongValue(iter.weight());\n        if (iter.hasPayloads()) {\n          payloadField.setBytesValue(iter.payload());\n        }\n        writer.addDocument(doc);\n      }\n      //System.out.println(\"initial indexing time: \" + ((System.nanoTime()-t0)/1000000) + \" msec\");\n\n      searcherMgr = new SearcherManager(writer, true, null);\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(r);\n      } else {\n        IOUtils.closeWhileHandlingException(writer, r);\n        writer = null;\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ae14298f4eec6d5faee6a149f88ba57d14a6f21a","date":1396971290,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggester#build(InputIterator).mjava","pathOld":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggester#build(InputIterator).mjava","sourceNew":"  @Override\n  public void build(InputIterator iter) throws IOException {\n    \n    if (searcherMgr != null) {\n      searcherMgr.close();\n      searcherMgr = null;\n    }\n\n    if (writer != null) {\n      writer.shutdown();\n      writer = null;\n    }\n\n    boolean success = false;\n    try {\n      // First pass: build a temporary normal Lucene index,\n      // just indexing the suggestions as they iterate:\n      writer = new IndexWriter(dir,\n                               getIndexWriterConfig(matchVersion, getGramAnalyzer(), IndexWriterConfig.OpenMode.CREATE));\n      //long t0 = System.nanoTime();\n\n      // TODO: use threads?\n      BytesRef text;\n      while ((text = iter.next()) != null) {\n        BytesRef payload;\n        if (iter.hasPayloads()) {\n          payload = iter.payload();\n        } else {\n          payload = null;\n        }\n\n        add(text, iter.contexts(), iter.weight(), payload);\n      }\n\n      //System.out.println(\"initial indexing time: \" + ((System.nanoTime()-t0)/1000000) + \" msec\");\n\n      searcherMgr = new SearcherManager(writer, true, null);\n      success = true;\n    } finally {\n      if (success == false) {\n        writer.rollback();\n        writer = null;\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  public void build(InputIterator iter) throws IOException {\n    \n    if (searcherMgr != null) {\n      searcherMgr.close();\n      searcherMgr = null;\n    }\n\n    if (writer != null) {\n      writer.close();\n      writer = null;\n    }\n\n    AtomicReader r = null;\n    boolean success = false;\n    try {\n      // First pass: build a temporary normal Lucene index,\n      // just indexing the suggestions as they iterate:\n      writer = new IndexWriter(dir,\n                               getIndexWriterConfig(matchVersion, getGramAnalyzer(), IndexWriterConfig.OpenMode.CREATE));\n      //long t0 = System.nanoTime();\n\n      // TODO: use threads?\n      BytesRef text;\n      while ((text = iter.next()) != null) {\n        BytesRef payload;\n        if (iter.hasPayloads()) {\n          payload = iter.payload();\n        } else {\n          payload = null;\n        }\n\n        add(text, iter.contexts(), iter.weight(), payload);\n      }\n\n      //System.out.println(\"initial indexing time: \" + ((System.nanoTime()-t0)/1000000) + \" msec\");\n\n      searcherMgr = new SearcherManager(writer, true, null);\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(r);\n      } else {\n        IOUtils.closeWhileHandlingException(writer, r);\n        writer = null;\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4a9c941a7004ea2e95b10aa67dafa319ff8d8c19","date":1400739326,"type":3,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggester#build(InputIterator).mjava","pathOld":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggester#build(InputIterator).mjava","sourceNew":"  @Override\n  public void build(InputIterator iter) throws IOException {\n    \n    if (searcherMgr != null) {\n      searcherMgr.close();\n      searcherMgr = null;\n    }\n\n    if (writer != null) {\n      writer.shutdown();\n      writer = null;\n    }\n\n    boolean success = false;\n    try {\n      // First pass: build a temporary normal Lucene index,\n      // just indexing the suggestions as they iterate:\n      writer = new IndexWriter(dir,\n                               getIndexWriterConfig(matchVersion, getGramAnalyzer(), IndexWriterConfig.OpenMode.CREATE));\n      //long t0 = System.nanoTime();\n\n      // TODO: use threads?\n      BytesRef text;\n      while ((text = iter.next()) != null) {\n        BytesRef payload;\n        if (iter.hasPayloads()) {\n          payload = iter.payload();\n        } else {\n          payload = null;\n        }\n\n        add(text, iter.contexts(), iter.weight(), payload);\n      }\n\n      //System.out.println(\"initial indexing time: \" + ((System.nanoTime()-t0)/1000000) + \" msec\");\n\n      searcherMgr = new SearcherManager(writer, true, null);\n      success = true;\n    } finally {\n      if (success == false && writer != null) {\n        writer.rollback();\n        writer = null;\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  public void build(InputIterator iter) throws IOException {\n    \n    if (searcherMgr != null) {\n      searcherMgr.close();\n      searcherMgr = null;\n    }\n\n    if (writer != null) {\n      writer.shutdown();\n      writer = null;\n    }\n\n    boolean success = false;\n    try {\n      // First pass: build a temporary normal Lucene index,\n      // just indexing the suggestions as they iterate:\n      writer = new IndexWriter(dir,\n                               getIndexWriterConfig(matchVersion, getGramAnalyzer(), IndexWriterConfig.OpenMode.CREATE));\n      //long t0 = System.nanoTime();\n\n      // TODO: use threads?\n      BytesRef text;\n      while ((text = iter.next()) != null) {\n        BytesRef payload;\n        if (iter.hasPayloads()) {\n          payload = iter.payload();\n        } else {\n          payload = null;\n        }\n\n        add(text, iter.contexts(), iter.weight(), payload);\n      }\n\n      //System.out.println(\"initial indexing time: \" + ((System.nanoTime()-t0)/1000000) + \" msec\");\n\n      searcherMgr = new SearcherManager(writer, true, null);\n      success = true;\n    } finally {\n      if (success == false) {\n        writer.rollback();\n        writer = null;\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b7605579001505896d48b07160075a5c8b8e128e","date":1400758727,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggester#build(InputIterator).mjava","pathOld":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggester#build(InputIterator).mjava","sourceNew":"  @Override\n  public void build(InputIterator iter) throws IOException {\n    \n    if (searcherMgr != null) {\n      searcherMgr.close();\n      searcherMgr = null;\n    }\n\n    if (writer != null) {\n      writer.shutdown();\n      writer = null;\n    }\n\n    boolean success = false;\n    try {\n      // First pass: build a temporary normal Lucene index,\n      // just indexing the suggestions as they iterate:\n      writer = new IndexWriter(dir,\n                               getIndexWriterConfig(matchVersion, getGramAnalyzer(), IndexWriterConfig.OpenMode.CREATE));\n      //long t0 = System.nanoTime();\n\n      // TODO: use threads?\n      BytesRef text;\n      while ((text = iter.next()) != null) {\n        BytesRef payload;\n        if (iter.hasPayloads()) {\n          payload = iter.payload();\n        } else {\n          payload = null;\n        }\n\n        add(text, iter.contexts(), iter.weight(), payload);\n      }\n\n      //System.out.println(\"initial indexing time: \" + ((System.nanoTime()-t0)/1000000) + \" msec\");\n\n      searcherMgr = new SearcherManager(writer, true, null);\n      success = true;\n    } finally {\n      if (success == false && writer != null) {\n        writer.rollback();\n        writer = null;\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  public void build(InputIterator iter) throws IOException {\n    \n    if (searcherMgr != null) {\n      searcherMgr.close();\n      searcherMgr = null;\n    }\n\n    if (writer != null) {\n      writer.shutdown();\n      writer = null;\n    }\n\n    boolean success = false;\n    try {\n      // First pass: build a temporary normal Lucene index,\n      // just indexing the suggestions as they iterate:\n      writer = new IndexWriter(dir,\n                               getIndexWriterConfig(matchVersion, getGramAnalyzer(), IndexWriterConfig.OpenMode.CREATE));\n      //long t0 = System.nanoTime();\n\n      // TODO: use threads?\n      BytesRef text;\n      while ((text = iter.next()) != null) {\n        BytesRef payload;\n        if (iter.hasPayloads()) {\n          payload = iter.payload();\n        } else {\n          payload = null;\n        }\n\n        add(text, iter.contexts(), iter.weight(), payload);\n      }\n\n      //System.out.println(\"initial indexing time: \" + ((System.nanoTime()-t0)/1000000) + \" msec\");\n\n      searcherMgr = new SearcherManager(writer, true, null);\n      success = true;\n    } finally {\n      if (success == false) {\n        writer.rollback();\n        writer = null;\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d0ef034a4f10871667ae75181537775ddcf8ade4","date":1407610475,"type":3,"author":"Ryan Ernst","isMerge":false,"pathNew":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggester#build(InputIterator).mjava","pathOld":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggester#build(InputIterator).mjava","sourceNew":"  @Override\n  public void build(InputIterator iter) throws IOException {\n    \n    if (searcherMgr != null) {\n      searcherMgr.close();\n      searcherMgr = null;\n    }\n\n    if (writer != null) {\n      writer.close();\n      writer = null;\n    }\n\n    boolean success = false;\n    try {\n      // First pass: build a temporary normal Lucene index,\n      // just indexing the suggestions as they iterate:\n      writer = new IndexWriter(dir,\n                               getIndexWriterConfig(getGramAnalyzer(), IndexWriterConfig.OpenMode.CREATE));\n      //long t0 = System.nanoTime();\n\n      // TODO: use threads?\n      BytesRef text;\n      while ((text = iter.next()) != null) {\n        BytesRef payload;\n        if (iter.hasPayloads()) {\n          payload = iter.payload();\n        } else {\n          payload = null;\n        }\n\n        add(text, iter.contexts(), iter.weight(), payload);\n      }\n\n      //System.out.println(\"initial indexing time: \" + ((System.nanoTime()-t0)/1000000) + \" msec\");\n\n      searcherMgr = new SearcherManager(writer, true, null);\n      success = true;\n    } finally {\n      if (success == false && writer != null) {\n        writer.rollback();\n        writer = null;\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  public void build(InputIterator iter) throws IOException {\n    \n    if (searcherMgr != null) {\n      searcherMgr.close();\n      searcherMgr = null;\n    }\n\n    if (writer != null) {\n      writer.shutdown();\n      writer = null;\n    }\n\n    boolean success = false;\n    try {\n      // First pass: build a temporary normal Lucene index,\n      // just indexing the suggestions as they iterate:\n      writer = new IndexWriter(dir,\n                               getIndexWriterConfig(matchVersion, getGramAnalyzer(), IndexWriterConfig.OpenMode.CREATE));\n      //long t0 = System.nanoTime();\n\n      // TODO: use threads?\n      BytesRef text;\n      while ((text = iter.next()) != null) {\n        BytesRef payload;\n        if (iter.hasPayloads()) {\n          payload = iter.payload();\n        } else {\n          payload = null;\n        }\n\n        add(text, iter.contexts(), iter.weight(), payload);\n      }\n\n      //System.out.println(\"initial indexing time: \" + ((System.nanoTime()-t0)/1000000) + \" msec\");\n\n      searcherMgr = new SearcherManager(writer, true, null);\n      success = true;\n    } finally {\n      if (success == false && writer != null) {\n        writer.rollback();\n        writer = null;\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6549d5ea6b7b25525309b981de3ec92b4dff99d1","date":1408666035,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggester#build(InputIterator).mjava","pathOld":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggester#build(InputIterator).mjava","sourceNew":"  @Override\n  public void build(InputIterator iter) throws IOException {\n    \n    if (searcherMgr != null) {\n      searcherMgr.close();\n      searcherMgr = null;\n    }\n\n    if (writer != null) {\n      writer.close();\n      writer = null;\n    }\n\n    boolean success = false;\n    try {\n      // First pass: build a temporary normal Lucene index,\n      // just indexing the suggestions as they iterate:\n      writer = new IndexWriter(dir,\n                               getIndexWriterConfig(getGramAnalyzer(), IndexWriterConfig.OpenMode.CREATE));\n      //long t0 = System.nanoTime();\n\n      // TODO: use threads?\n      BytesRef text;\n      while ((text = iter.next()) != null) {\n        BytesRef payload;\n        if (iter.hasPayloads()) {\n          payload = iter.payload();\n        } else {\n          payload = null;\n        }\n\n        add(text, iter.contexts(), iter.weight(), payload);\n      }\n\n      //System.out.println(\"initial indexing time: \" + ((System.nanoTime()-t0)/1000000) + \" msec\");\n      if (commitOnBuild) {\n        commit();\n      }\n      searcherMgr = new SearcherManager(writer, true, null);\n      success = true;\n    } finally {\n      if (success == false && writer != null) {\n        writer.rollback();\n        writer = null;\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  public void build(InputIterator iter) throws IOException {\n    \n    if (searcherMgr != null) {\n      searcherMgr.close();\n      searcherMgr = null;\n    }\n\n    if (writer != null) {\n      writer.close();\n      writer = null;\n    }\n\n    boolean success = false;\n    try {\n      // First pass: build a temporary normal Lucene index,\n      // just indexing the suggestions as they iterate:\n      writer = new IndexWriter(dir,\n                               getIndexWriterConfig(getGramAnalyzer(), IndexWriterConfig.OpenMode.CREATE));\n      //long t0 = System.nanoTime();\n\n      // TODO: use threads?\n      BytesRef text;\n      while ((text = iter.next()) != null) {\n        BytesRef payload;\n        if (iter.hasPayloads()) {\n          payload = iter.payload();\n        } else {\n          payload = null;\n        }\n\n        add(text, iter.contexts(), iter.weight(), payload);\n      }\n\n      //System.out.println(\"initial indexing time: \" + ((System.nanoTime()-t0)/1000000) + \" msec\");\n\n      searcherMgr = new SearcherManager(writer, true, null);\n      success = true;\n    } finally {\n      if (success == false && writer != null) {\n        writer.rollback();\n        writer = null;\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7b516a692d03225c8f0e81a13ceed2dc32bb457d","date":1453411951,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggester#build(InputIterator).mjava","pathOld":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggester#build(InputIterator).mjava","sourceNew":"  @Override\n  public void build(InputIterator iter) throws IOException {\n    \n    if (searcherMgr != null) {\n      searcherMgr.close();\n      searcherMgr = null;\n    }\n\n    if (writer != null) {\n      writer.close();\n      writer = null;\n    }\n\n    boolean success = false;\n    try {\n      // First pass: build a temporary normal Lucene index,\n      // just indexing the suggestions as they iterate:\n      writer = new IndexWriter(dir,\n                               getIndexWriterConfig(getGramAnalyzer(), IndexWriterConfig.OpenMode.CREATE));\n      //long t0 = System.nanoTime();\n\n      // TODO: use threads?\n      BytesRef text;\n      while ((text = iter.next()) != null) {\n        BytesRef payload;\n        if (iter.hasPayloads()) {\n          payload = iter.payload();\n        } else {\n          payload = null;\n        }\n\n        add(text, iter.contexts(), iter.weight(), payload);\n      }\n\n      //System.out.println(\"initial indexing time: \" + ((System.nanoTime()-t0)/1000000) + \" msec\");\n      if (commitOnBuild) {\n        commit();\n      }\n      searcherMgr = new SearcherManager(writer, null);\n      success = true;\n    } finally {\n      if (success == false && writer != null) {\n        writer.rollback();\n        writer = null;\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  public void build(InputIterator iter) throws IOException {\n    \n    if (searcherMgr != null) {\n      searcherMgr.close();\n      searcherMgr = null;\n    }\n\n    if (writer != null) {\n      writer.close();\n      writer = null;\n    }\n\n    boolean success = false;\n    try {\n      // First pass: build a temporary normal Lucene index,\n      // just indexing the suggestions as they iterate:\n      writer = new IndexWriter(dir,\n                               getIndexWriterConfig(getGramAnalyzer(), IndexWriterConfig.OpenMode.CREATE));\n      //long t0 = System.nanoTime();\n\n      // TODO: use threads?\n      BytesRef text;\n      while ((text = iter.next()) != null) {\n        BytesRef payload;\n        if (iter.hasPayloads()) {\n          payload = iter.payload();\n        } else {\n          payload = null;\n        }\n\n        add(text, iter.contexts(), iter.weight(), payload);\n      }\n\n      //System.out.println(\"initial indexing time: \" + ((System.nanoTime()-t0)/1000000) + \" msec\");\n      if (commitOnBuild) {\n        commit();\n      }\n      searcherMgr = new SearcherManager(writer, true, null);\n      success = true;\n    } finally {\n      if (success == false && writer != null) {\n        writer.rollback();\n        writer = null;\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e15af9ab52794c4f3888b19ff3cf55ccea043db2","date":1479337431,"type":3,"author":"Steve Rowe","isMerge":false,"pathNew":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggester#build(InputIterator).mjava","pathOld":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggester#build(InputIterator).mjava","sourceNew":"  @Override\n  public void build(InputIterator iter) throws IOException {\n    \n    if (searcherMgr != null) {\n      searcherMgr.close();\n      searcherMgr = null;\n    }\n\n    if (writer != null) {\n      writer.close();\n      writer = null;\n    }\n\n    boolean success = false;\n    try {\n      // First pass: build a temporary normal Lucene index,\n      // just indexing the suggestions as they iterate:\n      writer = new IndexWriter(dir,\n                               getIndexWriterConfig(getGramAnalyzer(), IndexWriterConfig.OpenMode.CREATE));\n      //long t0 = System.nanoTime();\n\n      // TODO: use threads?\n      BytesRef text;\n      while ((text = iter.next()) != null) {\n        BytesRef payload;\n        if (iter.hasPayloads()) {\n          payload = iter.payload();\n        } else {\n          payload = null;\n        }\n\n        add(text, iter.contexts(), iter.weight(), payload);\n      }\n\n      //System.out.println(\"initial indexing time: \" + ((System.nanoTime()-t0)/1000000) + \" msec\");\n      if (commitOnBuild || closeIndexWriterOnBuild) {\n        commit();\n      }\n      searcherMgr = new SearcherManager(writer, null);\n      success = true;\n    } finally {\n      if (success) {\n        if (closeIndexWriterOnBuild) {\n          writer.close();\n          writer = null;\n        }\n      } else {  // failure\n        if (writer != null) {\n          writer.rollback();\n          writer = null;\n        }\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  public void build(InputIterator iter) throws IOException {\n    \n    if (searcherMgr != null) {\n      searcherMgr.close();\n      searcherMgr = null;\n    }\n\n    if (writer != null) {\n      writer.close();\n      writer = null;\n    }\n\n    boolean success = false;\n    try {\n      // First pass: build a temporary normal Lucene index,\n      // just indexing the suggestions as they iterate:\n      writer = new IndexWriter(dir,\n                               getIndexWriterConfig(getGramAnalyzer(), IndexWriterConfig.OpenMode.CREATE));\n      //long t0 = System.nanoTime();\n\n      // TODO: use threads?\n      BytesRef text;\n      while ((text = iter.next()) != null) {\n        BytesRef payload;\n        if (iter.hasPayloads()) {\n          payload = iter.payload();\n        } else {\n          payload = null;\n        }\n\n        add(text, iter.contexts(), iter.weight(), payload);\n      }\n\n      //System.out.println(\"initial indexing time: \" + ((System.nanoTime()-t0)/1000000) + \" msec\");\n      if (commitOnBuild) {\n        commit();\n      }\n      searcherMgr = new SearcherManager(writer, null);\n      success = true;\n    } finally {\n      if (success == false && writer != null) {\n        writer.rollback();\n        writer = null;\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2e859e664a65796dadf8aaf65db6f66f3a885368","date":1479487334,"type":3,"author":"Kevin Risden","isMerge":true,"pathNew":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggester#build(InputIterator).mjava","pathOld":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggester#build(InputIterator).mjava","sourceNew":"  @Override\n  public void build(InputIterator iter) throws IOException {\n    \n    if (searcherMgr != null) {\n      searcherMgr.close();\n      searcherMgr = null;\n    }\n\n    if (writer != null) {\n      writer.close();\n      writer = null;\n    }\n\n    boolean success = false;\n    try {\n      // First pass: build a temporary normal Lucene index,\n      // just indexing the suggestions as they iterate:\n      writer = new IndexWriter(dir,\n                               getIndexWriterConfig(getGramAnalyzer(), IndexWriterConfig.OpenMode.CREATE));\n      //long t0 = System.nanoTime();\n\n      // TODO: use threads?\n      BytesRef text;\n      while ((text = iter.next()) != null) {\n        BytesRef payload;\n        if (iter.hasPayloads()) {\n          payload = iter.payload();\n        } else {\n          payload = null;\n        }\n\n        add(text, iter.contexts(), iter.weight(), payload);\n      }\n\n      //System.out.println(\"initial indexing time: \" + ((System.nanoTime()-t0)/1000000) + \" msec\");\n      if (commitOnBuild || closeIndexWriterOnBuild) {\n        commit();\n      }\n      searcherMgr = new SearcherManager(writer, null);\n      success = true;\n    } finally {\n      if (success) {\n        if (closeIndexWriterOnBuild) {\n          writer.close();\n          writer = null;\n        }\n      } else {  // failure\n        if (writer != null) {\n          writer.rollback();\n          writer = null;\n        }\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  public void build(InputIterator iter) throws IOException {\n    \n    if (searcherMgr != null) {\n      searcherMgr.close();\n      searcherMgr = null;\n    }\n\n    if (writer != null) {\n      writer.close();\n      writer = null;\n    }\n\n    boolean success = false;\n    try {\n      // First pass: build a temporary normal Lucene index,\n      // just indexing the suggestions as they iterate:\n      writer = new IndexWriter(dir,\n                               getIndexWriterConfig(getGramAnalyzer(), IndexWriterConfig.OpenMode.CREATE));\n      //long t0 = System.nanoTime();\n\n      // TODO: use threads?\n      BytesRef text;\n      while ((text = iter.next()) != null) {\n        BytesRef payload;\n        if (iter.hasPayloads()) {\n          payload = iter.payload();\n        } else {\n          payload = null;\n        }\n\n        add(text, iter.contexts(), iter.weight(), payload);\n      }\n\n      //System.out.println(\"initial indexing time: \" + ((System.nanoTime()-t0)/1000000) + \" msec\");\n      if (commitOnBuild) {\n        commit();\n      }\n      searcherMgr = new SearcherManager(writer, null);\n      success = true;\n    } finally {\n      if (success == false && writer != null) {\n        writer.rollback();\n        writer = null;\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5cbf4928b28a4db03465b529b38a64ef29c91735","date":1483044697,"type":3,"author":"Steve Rowe","isMerge":false,"pathNew":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggester#build(InputIterator).mjava","pathOld":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggester#build(InputIterator).mjava","sourceNew":"  @Override\n  public void build(InputIterator iter) throws IOException {\n    \n    synchronized (searcherMgrLock) {\n      if (searcherMgr != null) {\n        searcherMgr.close();\n        searcherMgr = null;\n      }\n\n      if (writer != null) {\n        writer.close();\n        writer = null;\n      }\n\n      boolean success = false;\n      try {\n        // First pass: build a temporary normal Lucene index,\n        // just indexing the suggestions as they iterate:\n        writer = new IndexWriter(dir,\n            getIndexWriterConfig(getGramAnalyzer(), IndexWriterConfig.OpenMode.CREATE));\n        //long t0 = System.nanoTime();\n\n        // TODO: use threads?\n        BytesRef text;\n        while ((text = iter.next()) != null) {\n          BytesRef payload;\n          if (iter.hasPayloads()) {\n            payload = iter.payload();\n          } else {\n            payload = null;\n          }\n\n          add(text, iter.contexts(), iter.weight(), payload);\n        }\n\n        //System.out.println(\"initial indexing time: \" + ((System.nanoTime()-t0)/1000000) + \" msec\");\n        if (commitOnBuild || closeIndexWriterOnBuild) {\n          commit();\n        }\n        searcherMgr = new SearcherManager(writer, null);\n        success = true;\n      } finally {\n        if (success) {\n          if (closeIndexWriterOnBuild) {\n            writer.close();\n            writer = null;\n          }\n        } else {  // failure\n          if (writer != null) {\n            writer.rollback();\n            writer = null;\n          }\n        }\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  public void build(InputIterator iter) throws IOException {\n    \n    if (searcherMgr != null) {\n      searcherMgr.close();\n      searcherMgr = null;\n    }\n\n    if (writer != null) {\n      writer.close();\n      writer = null;\n    }\n\n    boolean success = false;\n    try {\n      // First pass: build a temporary normal Lucene index,\n      // just indexing the suggestions as they iterate:\n      writer = new IndexWriter(dir,\n                               getIndexWriterConfig(getGramAnalyzer(), IndexWriterConfig.OpenMode.CREATE));\n      //long t0 = System.nanoTime();\n\n      // TODO: use threads?\n      BytesRef text;\n      while ((text = iter.next()) != null) {\n        BytesRef payload;\n        if (iter.hasPayloads()) {\n          payload = iter.payload();\n        } else {\n          payload = null;\n        }\n\n        add(text, iter.contexts(), iter.weight(), payload);\n      }\n\n      //System.out.println(\"initial indexing time: \" + ((System.nanoTime()-t0)/1000000) + \" msec\");\n      if (commitOnBuild || closeIndexWriterOnBuild) {\n        commit();\n      }\n      searcherMgr = new SearcherManager(writer, null);\n      success = true;\n    } finally {\n      if (success) {\n        if (closeIndexWriterOnBuild) {\n          writer.close();\n          writer = null;\n        }\n      } else {  // failure\n        if (writer != null) {\n          writer.rollback();\n          writer = null;\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"de0b5d8cac74be1676bcc2f805bc0d0630176659","date":1483048659,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggester#build(InputIterator).mjava","pathOld":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggester#build(InputIterator).mjava","sourceNew":"  @Override\n  public void build(InputIterator iter) throws IOException {\n    \n    synchronized (searcherMgrLock) {\n      if (searcherMgr != null) {\n        searcherMgr.close();\n        searcherMgr = null;\n      }\n\n      if (writer != null) {\n        writer.close();\n        writer = null;\n      }\n\n      boolean success = false;\n      try {\n        // First pass: build a temporary normal Lucene index,\n        // just indexing the suggestions as they iterate:\n        writer = new IndexWriter(dir,\n            getIndexWriterConfig(getGramAnalyzer(), IndexWriterConfig.OpenMode.CREATE));\n        //long t0 = System.nanoTime();\n\n        // TODO: use threads?\n        BytesRef text;\n        while ((text = iter.next()) != null) {\n          BytesRef payload;\n          if (iter.hasPayloads()) {\n            payload = iter.payload();\n          } else {\n            payload = null;\n          }\n\n          add(text, iter.contexts(), iter.weight(), payload);\n        }\n\n        //System.out.println(\"initial indexing time: \" + ((System.nanoTime()-t0)/1000000) + \" msec\");\n        if (commitOnBuild || closeIndexWriterOnBuild) {\n          commit();\n        }\n        searcherMgr = new SearcherManager(writer, null);\n        success = true;\n      } finally {\n        if (success) {\n          if (closeIndexWriterOnBuild) {\n            writer.close();\n            writer = null;\n          }\n        } else {  // failure\n          if (writer != null) {\n            writer.rollback();\n            writer = null;\n          }\n        }\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  public void build(InputIterator iter) throws IOException {\n    \n    if (searcherMgr != null) {\n      searcherMgr.close();\n      searcherMgr = null;\n    }\n\n    if (writer != null) {\n      writer.close();\n      writer = null;\n    }\n\n    boolean success = false;\n    try {\n      // First pass: build a temporary normal Lucene index,\n      // just indexing the suggestions as they iterate:\n      writer = new IndexWriter(dir,\n                               getIndexWriterConfig(getGramAnalyzer(), IndexWriterConfig.OpenMode.CREATE));\n      //long t0 = System.nanoTime();\n\n      // TODO: use threads?\n      BytesRef text;\n      while ((text = iter.next()) != null) {\n        BytesRef payload;\n        if (iter.hasPayloads()) {\n          payload = iter.payload();\n        } else {\n          payload = null;\n        }\n\n        add(text, iter.contexts(), iter.weight(), payload);\n      }\n\n      //System.out.println(\"initial indexing time: \" + ((System.nanoTime()-t0)/1000000) + \" msec\");\n      if (commitOnBuild || closeIndexWriterOnBuild) {\n        commit();\n      }\n      searcherMgr = new SearcherManager(writer, null);\n      success = true;\n    } finally {\n      if (success) {\n        if (closeIndexWriterOnBuild) {\n          writer.close();\n          writer = null;\n        }\n      } else {  // failure\n        if (writer != null) {\n          writer.rollback();\n          writer = null;\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f03e4bed5023ec3ef93a771b8888cae991cf448d","date":1483469262,"type":3,"author":"Kevin Risden","isMerge":true,"pathNew":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggester#build(InputIterator).mjava","pathOld":"lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/AnalyzingInfixSuggester#build(InputIterator).mjava","sourceNew":"  @Override\n  public void build(InputIterator iter) throws IOException {\n    \n    synchronized (searcherMgrLock) {\n      if (searcherMgr != null) {\n        searcherMgr.close();\n        searcherMgr = null;\n      }\n\n      if (writer != null) {\n        writer.close();\n        writer = null;\n      }\n\n      boolean success = false;\n      try {\n        // First pass: build a temporary normal Lucene index,\n        // just indexing the suggestions as they iterate:\n        writer = new IndexWriter(dir,\n            getIndexWriterConfig(getGramAnalyzer(), IndexWriterConfig.OpenMode.CREATE));\n        //long t0 = System.nanoTime();\n\n        // TODO: use threads?\n        BytesRef text;\n        while ((text = iter.next()) != null) {\n          BytesRef payload;\n          if (iter.hasPayloads()) {\n            payload = iter.payload();\n          } else {\n            payload = null;\n          }\n\n          add(text, iter.contexts(), iter.weight(), payload);\n        }\n\n        //System.out.println(\"initial indexing time: \" + ((System.nanoTime()-t0)/1000000) + \" msec\");\n        if (commitOnBuild || closeIndexWriterOnBuild) {\n          commit();\n        }\n        searcherMgr = new SearcherManager(writer, null);\n        success = true;\n      } finally {\n        if (success) {\n          if (closeIndexWriterOnBuild) {\n            writer.close();\n            writer = null;\n          }\n        } else {  // failure\n          if (writer != null) {\n            writer.rollback();\n            writer = null;\n          }\n        }\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  public void build(InputIterator iter) throws IOException {\n    \n    if (searcherMgr != null) {\n      searcherMgr.close();\n      searcherMgr = null;\n    }\n\n    if (writer != null) {\n      writer.close();\n      writer = null;\n    }\n\n    boolean success = false;\n    try {\n      // First pass: build a temporary normal Lucene index,\n      // just indexing the suggestions as they iterate:\n      writer = new IndexWriter(dir,\n                               getIndexWriterConfig(getGramAnalyzer(), IndexWriterConfig.OpenMode.CREATE));\n      //long t0 = System.nanoTime();\n\n      // TODO: use threads?\n      BytesRef text;\n      while ((text = iter.next()) != null) {\n        BytesRef payload;\n        if (iter.hasPayloads()) {\n          payload = iter.payload();\n        } else {\n          payload = null;\n        }\n\n        add(text, iter.contexts(), iter.weight(), payload);\n      }\n\n      //System.out.println(\"initial indexing time: \" + ((System.nanoTime()-t0)/1000000) + \" msec\");\n      if (commitOnBuild || closeIndexWriterOnBuild) {\n        commit();\n      }\n      searcherMgr = new SearcherManager(writer, null);\n      success = true;\n    } finally {\n      if (success) {\n        if (closeIndexWriterOnBuild) {\n          writer.close();\n          writer = null;\n        }\n      } else {  // failure\n        if (writer != null) {\n          writer.rollback();\n          writer = null;\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"de0b5d8cac74be1676bcc2f805bc0d0630176659":["e15af9ab52794c4f3888b19ff3cf55ccea043db2","5cbf4928b28a4db03465b529b38a64ef29c91735"],"96ea64d994d340044e0d57aeb6a5871539d10ca5":["a371aa649cc243e82cb8677ca960a1e0232ecedf","4637747f71df783fc2014ef1f1e0418466e3bed6"],"58d0345a28bb6b4be59c38e6a77e2cc0e615ee4b":["4637747f71df783fc2014ef1f1e0418466e3bed6"],"41aee74b5f91a096e3fd950f4a336bc763f0e7a7":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"f13ec1b606a28789743a563929e7c556e8218297":["41aee74b5f91a096e3fd950f4a336bc763f0e7a7"],"6549d5ea6b7b25525309b981de3ec92b4dff99d1":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"7b516a692d03225c8f0e81a13ceed2dc32bb457d":["6549d5ea6b7b25525309b981de3ec92b4dff99d1"],"b7605579001505896d48b07160075a5c8b8e128e":["ae14298f4eec6d5faee6a149f88ba57d14a6f21a","4a9c941a7004ea2e95b10aa67dafa319ff8d8c19"],"a371aa649cc243e82cb8677ca960a1e0232ecedf":["a645276cbaf5dc96a42fd473b9019bde352996c8"],"a645276cbaf5dc96a42fd473b9019bde352996c8":["f13ec1b606a28789743a563929e7c556e8218297"],"f1e7da8a91a92330e8f04b171b83e655a4a25c31":["b638f37b6d00b06fa8d6875cea1df4b274d6e87a"],"5cbf4928b28a4db03465b529b38a64ef29c91735":["e15af9ab52794c4f3888b19ff3cf55ccea043db2"],"4a9c941a7004ea2e95b10aa67dafa319ff8d8c19":["ae14298f4eec6d5faee6a149f88ba57d14a6f21a"],"f03e4bed5023ec3ef93a771b8888cae991cf448d":["2e859e664a65796dadf8aaf65db6f66f3a885368","de0b5d8cac74be1676bcc2f805bc0d0630176659"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"d0ef034a4f10871667ae75181537775ddcf8ade4":["4a9c941a7004ea2e95b10aa67dafa319ff8d8c19"],"b638f37b6d00b06fa8d6875cea1df4b274d6e87a":["a371aa649cc243e82cb8677ca960a1e0232ecedf"],"e15af9ab52794c4f3888b19ff3cf55ccea043db2":["7b516a692d03225c8f0e81a13ceed2dc32bb457d"],"ae14298f4eec6d5faee6a149f88ba57d14a6f21a":["58d0345a28bb6b4be59c38e6a77e2cc0e615ee4b"],"2e859e664a65796dadf8aaf65db6f66f3a885368":["7b516a692d03225c8f0e81a13ceed2dc32bb457d","e15af9ab52794c4f3888b19ff3cf55ccea043db2"],"4637747f71df783fc2014ef1f1e0418466e3bed6":["a371aa649cc243e82cb8677ca960a1e0232ecedf","f1e7da8a91a92330e8f04b171b83e655a4a25c31"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["de0b5d8cac74be1676bcc2f805bc0d0630176659"]},"commit2Childs":{"de0b5d8cac74be1676bcc2f805bc0d0630176659":["f03e4bed5023ec3ef93a771b8888cae991cf448d","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"96ea64d994d340044e0d57aeb6a5871539d10ca5":[],"58d0345a28bb6b4be59c38e6a77e2cc0e615ee4b":["ae14298f4eec6d5faee6a149f88ba57d14a6f21a"],"41aee74b5f91a096e3fd950f4a336bc763f0e7a7":["f13ec1b606a28789743a563929e7c556e8218297"],"f13ec1b606a28789743a563929e7c556e8218297":["a645276cbaf5dc96a42fd473b9019bde352996c8"],"6549d5ea6b7b25525309b981de3ec92b4dff99d1":["7b516a692d03225c8f0e81a13ceed2dc32bb457d"],"7b516a692d03225c8f0e81a13ceed2dc32bb457d":["e15af9ab52794c4f3888b19ff3cf55ccea043db2","2e859e664a65796dadf8aaf65db6f66f3a885368"],"b7605579001505896d48b07160075a5c8b8e128e":[],"a371aa649cc243e82cb8677ca960a1e0232ecedf":["96ea64d994d340044e0d57aeb6a5871539d10ca5","b638f37b6d00b06fa8d6875cea1df4b274d6e87a","4637747f71df783fc2014ef1f1e0418466e3bed6"],"a645276cbaf5dc96a42fd473b9019bde352996c8":["a371aa649cc243e82cb8677ca960a1e0232ecedf"],"5cbf4928b28a4db03465b529b38a64ef29c91735":["de0b5d8cac74be1676bcc2f805bc0d0630176659"],"f1e7da8a91a92330e8f04b171b83e655a4a25c31":["4637747f71df783fc2014ef1f1e0418466e3bed6"],"4a9c941a7004ea2e95b10aa67dafa319ff8d8c19":["b7605579001505896d48b07160075a5c8b8e128e","d0ef034a4f10871667ae75181537775ddcf8ade4"],"f03e4bed5023ec3ef93a771b8888cae991cf448d":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["41aee74b5f91a096e3fd950f4a336bc763f0e7a7"],"d0ef034a4f10871667ae75181537775ddcf8ade4":["6549d5ea6b7b25525309b981de3ec92b4dff99d1"],"b638f37b6d00b06fa8d6875cea1df4b274d6e87a":["f1e7da8a91a92330e8f04b171b83e655a4a25c31"],"e15af9ab52794c4f3888b19ff3cf55ccea043db2":["de0b5d8cac74be1676bcc2f805bc0d0630176659","5cbf4928b28a4db03465b529b38a64ef29c91735","2e859e664a65796dadf8aaf65db6f66f3a885368"],"ae14298f4eec6d5faee6a149f88ba57d14a6f21a":["b7605579001505896d48b07160075a5c8b8e128e","4a9c941a7004ea2e95b10aa67dafa319ff8d8c19"],"2e859e664a65796dadf8aaf65db6f66f3a885368":["f03e4bed5023ec3ef93a771b8888cae991cf448d"],"4637747f71df783fc2014ef1f1e0418466e3bed6":["96ea64d994d340044e0d57aeb6a5871539d10ca5","58d0345a28bb6b4be59c38e6a77e2cc0e615ee4b"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["96ea64d994d340044e0d57aeb6a5871539d10ca5","b7605579001505896d48b07160075a5c8b8e128e","f03e4bed5023ec3ef93a771b8888cae991cf448d","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}