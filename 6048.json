{"path":"lucene/core/src/test/org/apache/lucene/index/TestPostingsOffsets#testLegalbutVeryLargeOffsets().mjava","commits":[{"id":"6cb561f6dba584c4fbf382d252ada6cbff219bee","date":1339549325,"type":0,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestPostingsOffsets#testLegalbutVeryLargeOffsets().mjava","pathOld":"/dev/null","sourceNew":"  public void testLegalbutVeryLargeOffsets() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriter iw = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, null));\n    Document doc = new Document();\n    Token t1 = new Token(\"foo\", 0, Integer.MAX_VALUE-500);\n    if (random().nextBoolean()) {\n      t1.setPayload(new BytesRef(\"test\"));\n    }\n    Token t2 = new Token(\"foo\", Integer.MAX_VALUE-500, Integer.MAX_VALUE);\n    TokenStream tokenStream = new CannedTokenStream(\n        new Token[] { t1, t2 }\n    );\n    FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n    ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    // store some term vectors for the checkindex cross-check\n    ft.setStoreTermVectors(true);\n    ft.setStoreTermVectorPositions(true);\n    ft.setStoreTermVectorOffsets(true);\n    Field field = new Field(\"foo\", tokenStream, ft);\n    doc.add(field);\n    iw.addDocument(doc);\n    iw.close();\n    dir.close();\n  }\n  // TODO: more tests with other possibilities\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ae14298f4eec6d5faee6a149f88ba57d14a6f21a","date":1396971290,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestPostingsOffsets#testLegalbutVeryLargeOffsets().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestPostingsOffsets#testLegalbutVeryLargeOffsets().mjava","sourceNew":"  public void testLegalbutVeryLargeOffsets() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriter iw = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, null));\n    Document doc = new Document();\n    Token t1 = new Token(\"foo\", 0, Integer.MAX_VALUE-500);\n    if (random().nextBoolean()) {\n      t1.setPayload(new BytesRef(\"test\"));\n    }\n    Token t2 = new Token(\"foo\", Integer.MAX_VALUE-500, Integer.MAX_VALUE);\n    TokenStream tokenStream = new CannedTokenStream(\n        new Token[] { t1, t2 }\n    );\n    FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n    ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    // store some term vectors for the checkindex cross-check\n    ft.setStoreTermVectors(true);\n    ft.setStoreTermVectorPositions(true);\n    ft.setStoreTermVectorOffsets(true);\n    Field field = new Field(\"foo\", tokenStream, ft);\n    doc.add(field);\n    iw.addDocument(doc);\n    iw.shutdown();\n    dir.close();\n  }\n  // TODO: more tests with other possibilities\n\n","sourceOld":"  public void testLegalbutVeryLargeOffsets() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriter iw = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, null));\n    Document doc = new Document();\n    Token t1 = new Token(\"foo\", 0, Integer.MAX_VALUE-500);\n    if (random().nextBoolean()) {\n      t1.setPayload(new BytesRef(\"test\"));\n    }\n    Token t2 = new Token(\"foo\", Integer.MAX_VALUE-500, Integer.MAX_VALUE);\n    TokenStream tokenStream = new CannedTokenStream(\n        new Token[] { t1, t2 }\n    );\n    FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n    ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    // store some term vectors for the checkindex cross-check\n    ft.setStoreTermVectors(true);\n    ft.setStoreTermVectorPositions(true);\n    ft.setStoreTermVectorOffsets(true);\n    Field field = new Field(\"foo\", tokenStream, ft);\n    doc.add(field);\n    iw.addDocument(doc);\n    iw.close();\n    dir.close();\n  }\n  // TODO: more tests with other possibilities\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e","date":1406737224,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestPostingsOffsets#testLegalbutVeryLargeOffsets().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestPostingsOffsets#testLegalbutVeryLargeOffsets().mjava","sourceNew":"  public void testLegalbutVeryLargeOffsets() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriter iw = new IndexWriter(dir, newIndexWriterConfig(null));\n    Document doc = new Document();\n    Token t1 = new Token(\"foo\", 0, Integer.MAX_VALUE-500);\n    if (random().nextBoolean()) {\n      t1.setPayload(new BytesRef(\"test\"));\n    }\n    Token t2 = new Token(\"foo\", Integer.MAX_VALUE-500, Integer.MAX_VALUE);\n    TokenStream tokenStream = new CannedTokenStream(\n        new Token[] { t1, t2 }\n    );\n    FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n    ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    // store some term vectors for the checkindex cross-check\n    ft.setStoreTermVectors(true);\n    ft.setStoreTermVectorPositions(true);\n    ft.setStoreTermVectorOffsets(true);\n    Field field = new Field(\"foo\", tokenStream, ft);\n    doc.add(field);\n    iw.addDocument(doc);\n    iw.shutdown();\n    dir.close();\n  }\n  // TODO: more tests with other possibilities\n\n","sourceOld":"  public void testLegalbutVeryLargeOffsets() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriter iw = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, null));\n    Document doc = new Document();\n    Token t1 = new Token(\"foo\", 0, Integer.MAX_VALUE-500);\n    if (random().nextBoolean()) {\n      t1.setPayload(new BytesRef(\"test\"));\n    }\n    Token t2 = new Token(\"foo\", Integer.MAX_VALUE-500, Integer.MAX_VALUE);\n    TokenStream tokenStream = new CannedTokenStream(\n        new Token[] { t1, t2 }\n    );\n    FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n    ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    // store some term vectors for the checkindex cross-check\n    ft.setStoreTermVectors(true);\n    ft.setStoreTermVectorPositions(true);\n    ft.setStoreTermVectorOffsets(true);\n    Field field = new Field(\"foo\", tokenStream, ft);\n    doc.add(field);\n    iw.addDocument(doc);\n    iw.shutdown();\n    dir.close();\n  }\n  // TODO: more tests with other possibilities\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d0ef034a4f10871667ae75181537775ddcf8ade4","date":1407610475,"type":3,"author":"Ryan Ernst","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestPostingsOffsets#testLegalbutVeryLargeOffsets().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestPostingsOffsets#testLegalbutVeryLargeOffsets().mjava","sourceNew":"  public void testLegalbutVeryLargeOffsets() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriter iw = new IndexWriter(dir, newIndexWriterConfig(null));\n    Document doc = new Document();\n    Token t1 = new Token(\"foo\", 0, Integer.MAX_VALUE-500);\n    if (random().nextBoolean()) {\n      t1.setPayload(new BytesRef(\"test\"));\n    }\n    Token t2 = new Token(\"foo\", Integer.MAX_VALUE-500, Integer.MAX_VALUE);\n    TokenStream tokenStream = new CannedTokenStream(\n        new Token[] { t1, t2 }\n    );\n    FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n    ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    // store some term vectors for the checkindex cross-check\n    ft.setStoreTermVectors(true);\n    ft.setStoreTermVectorPositions(true);\n    ft.setStoreTermVectorOffsets(true);\n    Field field = new Field(\"foo\", tokenStream, ft);\n    doc.add(field);\n    iw.addDocument(doc);\n    iw.close();\n    dir.close();\n  }\n  // TODO: more tests with other possibilities\n\n","sourceOld":"  public void testLegalbutVeryLargeOffsets() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriter iw = new IndexWriter(dir, newIndexWriterConfig(null));\n    Document doc = new Document();\n    Token t1 = new Token(\"foo\", 0, Integer.MAX_VALUE-500);\n    if (random().nextBoolean()) {\n      t1.setPayload(new BytesRef(\"test\"));\n    }\n    Token t2 = new Token(\"foo\", Integer.MAX_VALUE-500, Integer.MAX_VALUE);\n    TokenStream tokenStream = new CannedTokenStream(\n        new Token[] { t1, t2 }\n    );\n    FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);\n    ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    // store some term vectors for the checkindex cross-check\n    ft.setStoreTermVectors(true);\n    ft.setStoreTermVectorPositions(true);\n    ft.setStoreTermVectorOffsets(true);\n    Field field = new Field(\"foo\", tokenStream, ft);\n    doc.add(field);\n    iw.addDocument(doc);\n    iw.shutdown();\n    dir.close();\n  }\n  // TODO: more tests with other possibilities\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e":["ae14298f4eec6d5faee6a149f88ba57d14a6f21a"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"d0ef034a4f10871667ae75181537775ddcf8ade4":["54a6bea0b991120a99ad0e2f72ae853fd5ecae0e"],"ae14298f4eec6d5faee6a149f88ba57d14a6f21a":["6cb561f6dba584c4fbf382d252ada6cbff219bee"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"6cb561f6dba584c4fbf382d252ada6cbff219bee":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["6cb561f6dba584c4fbf382d252ada6cbff219bee"],"d0ef034a4f10871667ae75181537775ddcf8ade4":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"ae14298f4eec6d5faee6a149f88ba57d14a6f21a":["54a6bea0b991120a99ad0e2f72ae853fd5ecae0e"],"6cb561f6dba584c4fbf382d252ada6cbff219bee":["ae14298f4eec6d5faee6a149f88ba57d14a6f21a"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}