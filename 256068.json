{"path":"lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestRandomChains.MockRandomAnalyzer#toString().mjava","commits":[{"id":"b89678825b68eccaf09e6ab71675fc0b0af1e099","date":1334669779,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestRandomChains.MockRandomAnalyzer#toString().mjava","pathOld":"modules/analysis/common/src/test/org/apache/lucene/analysis/core/TestRandomChains.MockRandomAnalyzer#toString().mjava","sourceNew":"    @Override\n    public String toString() {\n      Random random = new Random(seed);\n      StringBuilder sb = new StringBuilder();\n      CharFilterSpec charFilterSpec = newCharFilterChain(random, new StringReader(\"\"));\n      sb.append(\"\\ncharfilters=\");\n      sb.append(charFilterSpec.toString);\n      // intentional: initReader gets its own separate random\n      random = new Random(seed);\n      TokenizerSpec tokenizerSpec = newTokenizer(random, charFilterSpec.reader);\n      sb.append(\"\\n\");\n      sb.append(\"tokenizer=\");\n      sb.append(tokenizerSpec.toString);\n      TokenFilterSpec tokenFilterSpec = newFilterChain(random, tokenizerSpec.tokenizer, tokenizerSpec.offsetsAreCorrect);\n      sb.append(\"\\n\");\n      sb.append(\"filters=\");\n      sb.append(tokenFilterSpec.toString);\n      sb.append(\"\\n\");\n      sb.append(\"offsetsAreCorrect=\" + tokenFilterSpec.offsetsAreCorrect);\n      return sb.toString();\n    }\n\n","sourceOld":"    @Override\n    public String toString() {\n      Random random = new Random(seed);\n      StringBuilder sb = new StringBuilder();\n      CharFilterSpec charFilterSpec = newCharFilterChain(random, new StringReader(\"\"));\n      sb.append(\"\\ncharfilters=\");\n      sb.append(charFilterSpec.toString);\n      // intentional: initReader gets its own separate random\n      random = new Random(seed);\n      TokenizerSpec tokenizerSpec = newTokenizer(random, charFilterSpec.reader);\n      sb.append(\"\\n\");\n      sb.append(\"tokenizer=\");\n      sb.append(tokenizerSpec.toString);\n      TokenFilterSpec tokenFilterSpec = newFilterChain(random, tokenizerSpec.tokenizer, tokenizerSpec.offsetsAreCorrect);\n      sb.append(\"\\n\");\n      sb.append(\"filters=\");\n      sb.append(tokenFilterSpec.toString);\n      sb.append(\"\\n\");\n      sb.append(\"offsetsAreCorrect=\" + tokenFilterSpec.offsetsAreCorrect);\n      return sb.toString();\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ae889fd5c8a69f6b5d130d3c895bfa5b04d07338","date":1389274049,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestRandomChains.MockRandomAnalyzer#toString().mjava","pathOld":"lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestRandomChains.MockRandomAnalyzer#toString().mjava","sourceNew":"    @Override\n    public String toString() {\n      Random random = new Random(seed);\n      StringBuilder sb = new StringBuilder();\n      CharFilterSpec charFilterSpec = newCharFilterChain(random, new StringReader(\"\"));\n      sb.append(\"\\ncharfilters=\");\n      sb.append(charFilterSpec.toString);\n      // intentional: initReader gets its own separate random\n      random = new Random(seed);\n      TokenizerSpec tokenizerSpec = newTokenizer(random);\n      sb.append(\"\\n\");\n      sb.append(\"tokenizer=\");\n      sb.append(tokenizerSpec.toString);\n      TokenFilterSpec tokenFilterSpec = newFilterChain(random, tokenizerSpec.tokenizer, tokenizerSpec.offsetsAreCorrect);\n      sb.append(\"\\n\");\n      sb.append(\"filters=\");\n      sb.append(tokenFilterSpec.toString);\n      sb.append(\"\\n\");\n      sb.append(\"offsetsAreCorrect=\" + tokenFilterSpec.offsetsAreCorrect);\n      return sb.toString();\n    }\n\n","sourceOld":"    @Override\n    public String toString() {\n      Random random = new Random(seed);\n      StringBuilder sb = new StringBuilder();\n      CharFilterSpec charFilterSpec = newCharFilterChain(random, new StringReader(\"\"));\n      sb.append(\"\\ncharfilters=\");\n      sb.append(charFilterSpec.toString);\n      // intentional: initReader gets its own separate random\n      random = new Random(seed);\n      TokenizerSpec tokenizerSpec = newTokenizer(random, charFilterSpec.reader);\n      sb.append(\"\\n\");\n      sb.append(\"tokenizer=\");\n      sb.append(tokenizerSpec.toString);\n      TokenFilterSpec tokenFilterSpec = newFilterChain(random, tokenizerSpec.tokenizer, tokenizerSpec.offsetsAreCorrect);\n      sb.append(\"\\n\");\n      sb.append(\"filters=\");\n      sb.append(tokenFilterSpec.toString);\n      sb.append(\"\\n\");\n      sb.append(\"offsetsAreCorrect=\" + tokenFilterSpec.offsetsAreCorrect);\n      return sb.toString();\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"1bb78b03a4010509ef504f049857b42aeea7b3f5","date":1482349496,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestRandomChains.MockRandomAnalyzer#toString().mjava","pathOld":"lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestRandomChains.MockRandomAnalyzer#toString().mjava","sourceNew":"    @Override\n    public String toString() {\n      Random random = new Random(seed);\n      StringBuilder sb = new StringBuilder();\n      CharFilterSpec charFilterSpec = newCharFilterChain(random, new StringReader(\"\"));\n      sb.append(\"\\ncharfilters=\");\n      sb.append(charFilterSpec.toString);\n      // intentional: initReader gets its own separate random\n      random = new Random(seed);\n      TokenizerSpec tokenizerSpec = newTokenizer(random);\n      sb.append(\"\\n\");\n      sb.append(\"tokenizer=\");\n      sb.append(tokenizerSpec.toString);\n      TokenFilterSpec tokenFilterSpec = newFilterChain(random, tokenizerSpec.tokenizer, tokenizerSpec.offsetsAreCorrect);\n      sb.append(\"\\n\");\n      sb.append(\"filters=\");\n      sb.append(tokenFilterSpec.toString);\n      sb.append(\"\\n\");\n      sb.append(\"offsetsAreCorrect=\");\n      sb.append(tokenFilterSpec.offsetsAreCorrect);\n      return sb.toString();\n    }\n\n","sourceOld":"    @Override\n    public String toString() {\n      Random random = new Random(seed);\n      StringBuilder sb = new StringBuilder();\n      CharFilterSpec charFilterSpec = newCharFilterChain(random, new StringReader(\"\"));\n      sb.append(\"\\ncharfilters=\");\n      sb.append(charFilterSpec.toString);\n      // intentional: initReader gets its own separate random\n      random = new Random(seed);\n      TokenizerSpec tokenizerSpec = newTokenizer(random);\n      sb.append(\"\\n\");\n      sb.append(\"tokenizer=\");\n      sb.append(tokenizerSpec.toString);\n      TokenFilterSpec tokenFilterSpec = newFilterChain(random, tokenizerSpec.tokenizer, tokenizerSpec.offsetsAreCorrect);\n      sb.append(\"\\n\");\n      sb.append(\"filters=\");\n      sb.append(tokenFilterSpec.toString);\n      sb.append(\"\\n\");\n      sb.append(\"offsetsAreCorrect=\" + tokenFilterSpec.offsetsAreCorrect);\n      return sb.toString();\n    }\n\n","bugFix":null,"bugIntro":["ad55dd51ee5593c207639943b98a58782872b232"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"f03e4bed5023ec3ef93a771b8888cae991cf448d","date":1483469262,"type":3,"author":"Kevin Risden","isMerge":true,"pathNew":"lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestRandomChains.MockRandomAnalyzer#toString().mjava","pathOld":"lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestRandomChains.MockRandomAnalyzer#toString().mjava","sourceNew":"    @Override\n    public String toString() {\n      Random random = new Random(seed);\n      StringBuilder sb = new StringBuilder();\n      CharFilterSpec charFilterSpec = newCharFilterChain(random, new StringReader(\"\"));\n      sb.append(\"\\ncharfilters=\");\n      sb.append(charFilterSpec.toString);\n      // intentional: initReader gets its own separate random\n      random = new Random(seed);\n      TokenizerSpec tokenizerSpec = newTokenizer(random);\n      sb.append(\"\\n\");\n      sb.append(\"tokenizer=\");\n      sb.append(tokenizerSpec.toString);\n      TokenFilterSpec tokenFilterSpec = newFilterChain(random, tokenizerSpec.tokenizer, tokenizerSpec.offsetsAreCorrect);\n      sb.append(\"\\n\");\n      sb.append(\"filters=\");\n      sb.append(tokenFilterSpec.toString);\n      sb.append(\"\\n\");\n      sb.append(\"offsetsAreCorrect=\");\n      sb.append(tokenFilterSpec.offsetsAreCorrect);\n      return sb.toString();\n    }\n\n","sourceOld":"    @Override\n    public String toString() {\n      Random random = new Random(seed);\n      StringBuilder sb = new StringBuilder();\n      CharFilterSpec charFilterSpec = newCharFilterChain(random, new StringReader(\"\"));\n      sb.append(\"\\ncharfilters=\");\n      sb.append(charFilterSpec.toString);\n      // intentional: initReader gets its own separate random\n      random = new Random(seed);\n      TokenizerSpec tokenizerSpec = newTokenizer(random);\n      sb.append(\"\\n\");\n      sb.append(\"tokenizer=\");\n      sb.append(tokenizerSpec.toString);\n      TokenFilterSpec tokenFilterSpec = newFilterChain(random, tokenizerSpec.tokenizer, tokenizerSpec.offsetsAreCorrect);\n      sb.append(\"\\n\");\n      sb.append(\"filters=\");\n      sb.append(tokenFilterSpec.toString);\n      sb.append(\"\\n\");\n      sb.append(\"offsetsAreCorrect=\" + tokenFilterSpec.offsetsAreCorrect);\n      return sb.toString();\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ad55dd51ee5593c207639943b98a58782872b232","date":1520180625,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestRandomChains.MockRandomAnalyzer#toString().mjava","pathOld":"lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestRandomChains.MockRandomAnalyzer#toString().mjava","sourceNew":"    @Override\n    public String toString() {\n      Random random = new Random(seed);\n      StringBuilder sb = new StringBuilder();\n      CharFilterSpec charFilterSpec = newCharFilterChain(random, new StringReader(\"\"));\n      sb.append(\"\\ncharfilters=\");\n      sb.append(charFilterSpec.toString);\n      // intentional: initReader gets its own separate random\n      random = new Random(seed);\n      TokenizerSpec tokenizerSpec = newTokenizer(random);\n      sb.append(\"\\n\");\n      sb.append(\"tokenizer=\");\n      sb.append(tokenizerSpec.toString);\n      TokenFilterSpec tokenFilterSpec = newFilterChain(random, tokenizerSpec.tokenizer);\n      sb.append(\"\\n\");\n      sb.append(\"filters=\");\n      sb.append(tokenFilterSpec.toString);\n      return sb.toString();\n    }\n\n","sourceOld":"    @Override\n    public String toString() {\n      Random random = new Random(seed);\n      StringBuilder sb = new StringBuilder();\n      CharFilterSpec charFilterSpec = newCharFilterChain(random, new StringReader(\"\"));\n      sb.append(\"\\ncharfilters=\");\n      sb.append(charFilterSpec.toString);\n      // intentional: initReader gets its own separate random\n      random = new Random(seed);\n      TokenizerSpec tokenizerSpec = newTokenizer(random);\n      sb.append(\"\\n\");\n      sb.append(\"tokenizer=\");\n      sb.append(tokenizerSpec.toString);\n      TokenFilterSpec tokenFilterSpec = newFilterChain(random, tokenizerSpec.tokenizer, tokenizerSpec.offsetsAreCorrect);\n      sb.append(\"\\n\");\n      sb.append(\"filters=\");\n      sb.append(tokenFilterSpec.toString);\n      sb.append(\"\\n\");\n      sb.append(\"offsetsAreCorrect=\");\n      sb.append(tokenFilterSpec.offsetsAreCorrect);\n      return sb.toString();\n    }\n\n","bugFix":["888c2d6bca1edd8d9293631d6e1d188b036e0f05","1bb78b03a4010509ef504f049857b42aeea7b3f5"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"ad55dd51ee5593c207639943b98a58782872b232":["1bb78b03a4010509ef504f049857b42aeea7b3f5"],"b89678825b68eccaf09e6ab71675fc0b0af1e099":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"ae889fd5c8a69f6b5d130d3c895bfa5b04d07338":["b89678825b68eccaf09e6ab71675fc0b0af1e099"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"1bb78b03a4010509ef504f049857b42aeea7b3f5":["ae889fd5c8a69f6b5d130d3c895bfa5b04d07338"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["ad55dd51ee5593c207639943b98a58782872b232"],"f03e4bed5023ec3ef93a771b8888cae991cf448d":["ae889fd5c8a69f6b5d130d3c895bfa5b04d07338","1bb78b03a4010509ef504f049857b42aeea7b3f5"]},"commit2Childs":{"ad55dd51ee5593c207639943b98a58782872b232":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"b89678825b68eccaf09e6ab71675fc0b0af1e099":["ae889fd5c8a69f6b5d130d3c895bfa5b04d07338"],"ae889fd5c8a69f6b5d130d3c895bfa5b04d07338":["1bb78b03a4010509ef504f049857b42aeea7b3f5","f03e4bed5023ec3ef93a771b8888cae991cf448d"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["b89678825b68eccaf09e6ab71675fc0b0af1e099"],"1bb78b03a4010509ef504f049857b42aeea7b3f5":["ad55dd51ee5593c207639943b98a58782872b232","f03e4bed5023ec3ef93a771b8888cae991cf448d"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"f03e4bed5023ec3ef93a771b8888cae991cf448d":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817","f03e4bed5023ec3ef93a771b8888cae991cf448d"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}