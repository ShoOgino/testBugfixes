{"path":"solr/core/src/java/org/apache/solr/handler/IndexFetcher#fetchLatestIndex(SolrCore,boolean,boolean).mjava","commits":[{"id":"6c94d2661bc1c14426980ec7882e951fdcff08d0","date":1427167177,"type":0,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/IndexFetcher#fetchLatestIndex(SolrCore,boolean,boolean).mjava","pathOld":"/dev/null","sourceNew":"  /**\n   * This command downloads all the necessary files from master to install a index commit point. Only changed files are\n   * downloaded. It also downloads the conf files (if they are modified).\n   *\n   * @param core the SolrCore\n   * @param forceReplication force a replication in all cases \n   * @param forceCoreReload force a core reload in all cases\n   * @return true on success, false if slave is already in sync\n   * @throws IOException if an exception occurs\n   */\n   boolean fetchLatestIndex(final SolrCore core, boolean forceReplication, boolean forceCoreReload) throws IOException, InterruptedException {\n    boolean cleanupDone = false;\n    boolean successfulInstall = false;\n    replicationStartTime = System.currentTimeMillis();\n    Directory tmpIndexDir = null;\n    String tmpIndex = null;\n    Directory indexDir = null;\n    String indexDirPath = null;\n    boolean deleteTmpIdxDir = true;\n    \n    if (!core.getSolrCoreState().getLastReplicateIndexSuccess()) {\n      // if the last replication was not a success, we force a full replication\n      // when we are a bit more confident we may want to try a partial replication\n      // if the error is connection related or something, but we have to be careful\n      forceReplication = true;\n    }\n    \n    try {\n      //get the current 'replicateable' index version in the master\n      NamedList response = null;\n      try {\n        response = getLatestVersion();\n      } catch (Exception e) {\n        LOG.error(\"Master at: \" + masterUrl + \" is not available. Index fetch failed. Exception: \" + e.getMessage());\n        return false;\n      }\n      long latestVersion = (Long) response.get(CMD_INDEX_VERSION);\n      long latestGeneration = (Long) response.get(GENERATION);\n\n      // TODO: make sure that getLatestCommit only returns commit points for the main index (i.e. no side-car indexes)\n      IndexCommit commit = core.getDeletionPolicy().getLatestCommit();\n      if (commit == null) {\n        // Presumably the IndexWriter hasn't been opened yet, and hence the deletion policy hasn't been updated with commit points\n        RefCounted<SolrIndexSearcher> searcherRefCounted = null;\n        try {\n          searcherRefCounted = core.getNewestSearcher(false);\n          if (searcherRefCounted == null) {\n            LOG.warn(\"No open searcher found - fetch aborted\");\n            return false;\n          }\n          commit = searcherRefCounted.get().getIndexReader().getIndexCommit();\n        } finally {\n          if (searcherRefCounted != null)\n            searcherRefCounted.decref();\n        }\n      }\n\n\n      if (latestVersion == 0L) {\n        if (forceReplication && commit.getGeneration() != 0) {\n          // since we won't get the files for an empty index,\n          // we just clear ours and commit\n          RefCounted<IndexWriter> iw = core.getUpdateHandler().getSolrCoreState().getIndexWriter(core);\n          try {\n            iw.get().deleteAll();\n          } finally {\n            iw.decref();\n          }\n          SolrQueryRequest req = new LocalSolrQueryRequest(core,\n              new ModifiableSolrParams());\n          core.getUpdateHandler().commit(new CommitUpdateCommand(req, false));\n        }\n        \n        //there is nothing to be replicated\n        successfulInstall = true;\n        return true;\n      }\n      \n      if (!forceReplication && IndexDeletionPolicyWrapper.getCommitTimestamp(commit) == latestVersion) {\n        //master and slave are already in sync just return\n        LOG.info(\"Slave in sync with master.\");\n        successfulInstall = true;\n        return true;\n      }\n      LOG.info(\"Master's generation: \" + latestGeneration);\n      LOG.info(\"Slave's generation: \" + commit.getGeneration());\n      LOG.info(\"Starting replication process\");\n      // get the list of files first\n      fetchFileList(latestGeneration);\n      // this can happen if the commit point is deleted before we fetch the file list.\n      if(filesToDownload.isEmpty()) return false;\n      LOG.info(\"Number of files in latest index in master: \" + filesToDownload.size());\n\n      // Create the sync service\n      fsyncService = Executors.newSingleThreadExecutor(new DefaultSolrThreadFactory(\"fsyncService\"));\n      // use a synchronized list because the list is read by other threads (to show details)\n      filesDownloaded = Collections.synchronizedList(new ArrayList<Map<String, Object>>());\n      // if the generation of master is older than that of the slave , it means they are not compatible to be copied\n      // then a new index directory to be created and all the files need to be copied\n      boolean isFullCopyNeeded = IndexDeletionPolicyWrapper\n          .getCommitTimestamp(commit) >= latestVersion\n          || commit.getGeneration() >= latestGeneration || forceReplication;\n\n      String tmpIdxDirName = \"index.\" + new SimpleDateFormat(SnapShooter.DATE_FMT, Locale.ROOT).format(new Date());\n      tmpIndex = createTempindexDir(core, tmpIdxDirName);\n\n      tmpIndexDir = core.getDirectoryFactory().get(tmpIndex, DirContext.DEFAULT, core.getSolrConfig().indexConfig.lockType);\n      \n      // cindex dir...\n      indexDirPath = core.getIndexDir();\n      indexDir = core.getDirectoryFactory().get(indexDirPath, DirContext.DEFAULT, core.getSolrConfig().indexConfig.lockType);\n\n      try {\n        \n        if (isIndexStale(indexDir)) {\n          isFullCopyNeeded = true;\n        }\n        \n        if (!isFullCopyNeeded) {\n          // a searcher might be using some flushed but not committed segments\n          // because of soft commits (which open a searcher on IW's data)\n          // so we need to close the existing searcher on the last commit\n          // and wait until we are able to clean up all unused lucene files\n          if (solrCore.getCoreDescriptor().getCoreContainer().isZooKeeperAware()) {\n            solrCore.closeSearcher();\n          }\n\n          // rollback and reopen index writer and wait until all unused files\n          // are successfully deleted\n          solrCore.getUpdateHandler().newIndexWriter(true);\n          RefCounted<IndexWriter> writer = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n          try {\n            IndexWriter indexWriter = writer.get();\n            int c = 0;\n            indexWriter.deleteUnusedFiles();\n            while (hasUnusedFiles(indexDir, commit)) {\n              indexWriter.deleteUnusedFiles();\n              LOG.info(\"Sleeping for 1000ms to wait for unused lucene index files to be delete-able\");\n              Thread.sleep(1000);\n              c++;\n              if (c >= 30)  {\n                LOG.warn(\"IndexFetcher unable to cleanup unused lucene index files so we must do a full copy instead\");\n                isFullCopyNeeded = true;\n                break;\n              }\n            }\n            if (c > 0)  {\n              LOG.info(\"IndexFetcher slept for \" + (c * 1000) + \"ms for unused lucene index files to be delete-able\");\n            }\n          } finally {\n            writer.decref();\n          }\n          solrCore.getUpdateHandler().getSolrCoreState().closeIndexWriter(core, true);\n        }\n        boolean reloadCore = false;\n        \n        try {\n          LOG.info(\"Starting download to \" + tmpIndexDir + \" fullCopy=\"\n              + isFullCopyNeeded);\n          successfulInstall = false;\n          \n          downloadIndexFiles(isFullCopyNeeded, indexDir, tmpIndexDir, latestGeneration);\n          LOG.info(\"Total time taken for download : \"\n              + ((System.currentTimeMillis() - replicationStartTime) / 1000)\n              + \" secs\");\n          Collection<Map<String,Object>> modifiedConfFiles = getModifiedConfFiles(confFilesToDownload);\n          if (!modifiedConfFiles.isEmpty()) {\n            reloadCore = true;\n            downloadConfFiles(confFilesToDownload, latestGeneration);\n            if (isFullCopyNeeded) {\n              successfulInstall = modifyIndexProps(tmpIdxDirName);\n              deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (successfulInstall) {\n              if (isFullCopyNeeded) {\n                // let the system know we are changing dir's and the old one\n                // may be closed\n                if (indexDir != null) {\n                  LOG.info(\"removing old index directory \" + indexDir);\n                  core.getDirectoryFactory().doneWithDirectory(indexDir);\n                  core.getDirectoryFactory().remove(indexDir);\n                }\n              }\n              \n              LOG.info(\"Configuration files are modified, core will be reloaded\");\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);// write to a file time of replication and\n                                     // conf files.\n            }\n          } else {\n            terminateAndWaitFsyncService();\n            if (isFullCopyNeeded) {\n              successfulInstall = modifyIndexProps(tmpIdxDirName);\n              deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (successfulInstall) {\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);\n            }\n          }\n        } finally {\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().openIndexWriter(core);\n          }\n        }\n        \n        // we must reload the core after we open the IW back up\n       if (successfulInstall && (reloadCore || forceCoreReload)) {\n          LOG.info(\"Reloading SolrCore {}\", core.getName());\n          reloadCore();\n        }\n\n        if (successfulInstall) {\n          if (isFullCopyNeeded) {\n            // let the system know we are changing dir's and the old one\n            // may be closed\n            if (indexDir != null) {\n              LOG.info(\"removing old index directory \" + indexDir);\n              core.getDirectoryFactory().doneWithDirectory(indexDir);\n              core.getDirectoryFactory().remove(indexDir);\n            }\n          }\n          if (isFullCopyNeeded) {\n            solrCore.getUpdateHandler().newIndexWriter(isFullCopyNeeded);\n          }\n          \n          openNewSearcherAndUpdateCommitPoint();\n        }\n        \n        if (!isFullCopyNeeded && !forceReplication && !successfulInstall) {\n          cleanup(core, tmpIndexDir, indexDir, deleteTmpIdxDir, successfulInstall);\n          cleanupDone = true;\n          // we try with a full copy of the index\n          LOG.warn(\n              \"Replication attempt was not successful - trying a full index replication reloadCore={}\",\n              reloadCore);\n          successfulInstall = fetchLatestIndex(core, true, reloadCore);\n        }\n        \n        replicationStartTime = 0;\n        return successfulInstall;\n      } catch (ReplicationHandlerException e) {\n        LOG.error(\"User aborted Replication\");\n        return false;\n      } catch (SolrException e) {\n        throw e;\n      } catch (InterruptedException e) {\n        throw new InterruptedException(\"Index fetch interrupted\");\n      } catch (Exception e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Index fetch failed : \", e);\n      }\n    } finally {\n      if (!cleanupDone) {\n        cleanup(core, tmpIndexDir, indexDir, deleteTmpIdxDir, successfulInstall);\n      }\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["ad28156288ac00b91352582904d97e6653205757","ad28156288ac00b91352582904d97e6653205757","04ecf884544ff74add5faa452748f160c4af904b","04ecf884544ff74add5faa452748f160c4af904b"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","date":1427779360,"type":0,"author":"Ryan Ernst","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/handler/IndexFetcher#fetchLatestIndex(SolrCore,boolean,boolean).mjava","pathOld":"/dev/null","sourceNew":"  /**\n   * This command downloads all the necessary files from master to install a index commit point. Only changed files are\n   * downloaded. It also downloads the conf files (if they are modified).\n   *\n   * @param core the SolrCore\n   * @param forceReplication force a replication in all cases \n   * @param forceCoreReload force a core reload in all cases\n   * @return true on success, false if slave is already in sync\n   * @throws IOException if an exception occurs\n   */\n   boolean fetchLatestIndex(final SolrCore core, boolean forceReplication, boolean forceCoreReload) throws IOException, InterruptedException {\n    boolean cleanupDone = false;\n    boolean successfulInstall = false;\n    replicationStartTime = System.currentTimeMillis();\n    Directory tmpIndexDir = null;\n    String tmpIndex = null;\n    Directory indexDir = null;\n    String indexDirPath = null;\n    boolean deleteTmpIdxDir = true;\n    \n    if (!core.getSolrCoreState().getLastReplicateIndexSuccess()) {\n      // if the last replication was not a success, we force a full replication\n      // when we are a bit more confident we may want to try a partial replication\n      // if the error is connection related or something, but we have to be careful\n      forceReplication = true;\n    }\n    \n    try {\n      //get the current 'replicateable' index version in the master\n      NamedList response = null;\n      try {\n        response = getLatestVersion();\n      } catch (Exception e) {\n        LOG.error(\"Master at: \" + masterUrl + \" is not available. Index fetch failed. Exception: \" + e.getMessage());\n        return false;\n      }\n      long latestVersion = (Long) response.get(CMD_INDEX_VERSION);\n      long latestGeneration = (Long) response.get(GENERATION);\n\n      // TODO: make sure that getLatestCommit only returns commit points for the main index (i.e. no side-car indexes)\n      IndexCommit commit = core.getDeletionPolicy().getLatestCommit();\n      if (commit == null) {\n        // Presumably the IndexWriter hasn't been opened yet, and hence the deletion policy hasn't been updated with commit points\n        RefCounted<SolrIndexSearcher> searcherRefCounted = null;\n        try {\n          searcherRefCounted = core.getNewestSearcher(false);\n          if (searcherRefCounted == null) {\n            LOG.warn(\"No open searcher found - fetch aborted\");\n            return false;\n          }\n          commit = searcherRefCounted.get().getIndexReader().getIndexCommit();\n        } finally {\n          if (searcherRefCounted != null)\n            searcherRefCounted.decref();\n        }\n      }\n\n\n      if (latestVersion == 0L) {\n        if (forceReplication && commit.getGeneration() != 0) {\n          // since we won't get the files for an empty index,\n          // we just clear ours and commit\n          RefCounted<IndexWriter> iw = core.getUpdateHandler().getSolrCoreState().getIndexWriter(core);\n          try {\n            iw.get().deleteAll();\n          } finally {\n            iw.decref();\n          }\n          SolrQueryRequest req = new LocalSolrQueryRequest(core,\n              new ModifiableSolrParams());\n          core.getUpdateHandler().commit(new CommitUpdateCommand(req, false));\n        }\n        \n        //there is nothing to be replicated\n        successfulInstall = true;\n        return true;\n      }\n      \n      if (!forceReplication && IndexDeletionPolicyWrapper.getCommitTimestamp(commit) == latestVersion) {\n        //master and slave are already in sync just return\n        LOG.info(\"Slave in sync with master.\");\n        successfulInstall = true;\n        return true;\n      }\n      LOG.info(\"Master's generation: \" + latestGeneration);\n      LOG.info(\"Slave's generation: \" + commit.getGeneration());\n      LOG.info(\"Starting replication process\");\n      // get the list of files first\n      fetchFileList(latestGeneration);\n      // this can happen if the commit point is deleted before we fetch the file list.\n      if(filesToDownload.isEmpty()) return false;\n      LOG.info(\"Number of files in latest index in master: \" + filesToDownload.size());\n\n      // Create the sync service\n      fsyncService = Executors.newSingleThreadExecutor(new DefaultSolrThreadFactory(\"fsyncService\"));\n      // use a synchronized list because the list is read by other threads (to show details)\n      filesDownloaded = Collections.synchronizedList(new ArrayList<Map<String, Object>>());\n      // if the generation of master is older than that of the slave , it means they are not compatible to be copied\n      // then a new index directory to be created and all the files need to be copied\n      boolean isFullCopyNeeded = IndexDeletionPolicyWrapper\n          .getCommitTimestamp(commit) >= latestVersion\n          || commit.getGeneration() >= latestGeneration || forceReplication;\n\n      String tmpIdxDirName = \"index.\" + new SimpleDateFormat(SnapShooter.DATE_FMT, Locale.ROOT).format(new Date());\n      tmpIndex = createTempindexDir(core, tmpIdxDirName);\n\n      tmpIndexDir = core.getDirectoryFactory().get(tmpIndex, DirContext.DEFAULT, core.getSolrConfig().indexConfig.lockType);\n      \n      // cindex dir...\n      indexDirPath = core.getIndexDir();\n      indexDir = core.getDirectoryFactory().get(indexDirPath, DirContext.DEFAULT, core.getSolrConfig().indexConfig.lockType);\n\n      try {\n        \n        if (isIndexStale(indexDir)) {\n          isFullCopyNeeded = true;\n        }\n        \n        if (!isFullCopyNeeded) {\n          // a searcher might be using some flushed but not committed segments\n          // because of soft commits (which open a searcher on IW's data)\n          // so we need to close the existing searcher on the last commit\n          // and wait until we are able to clean up all unused lucene files\n          if (solrCore.getCoreDescriptor().getCoreContainer().isZooKeeperAware()) {\n            solrCore.closeSearcher();\n          }\n\n          // rollback and reopen index writer and wait until all unused files\n          // are successfully deleted\n          solrCore.getUpdateHandler().newIndexWriter(true);\n          RefCounted<IndexWriter> writer = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n          try {\n            IndexWriter indexWriter = writer.get();\n            int c = 0;\n            indexWriter.deleteUnusedFiles();\n            while (hasUnusedFiles(indexDir, commit)) {\n              indexWriter.deleteUnusedFiles();\n              LOG.info(\"Sleeping for 1000ms to wait for unused lucene index files to be delete-able\");\n              Thread.sleep(1000);\n              c++;\n              if (c >= 30)  {\n                LOG.warn(\"IndexFetcher unable to cleanup unused lucene index files so we must do a full copy instead\");\n                isFullCopyNeeded = true;\n                break;\n              }\n            }\n            if (c > 0)  {\n              LOG.info(\"IndexFetcher slept for \" + (c * 1000) + \"ms for unused lucene index files to be delete-able\");\n            }\n          } finally {\n            writer.decref();\n          }\n          solrCore.getUpdateHandler().getSolrCoreState().closeIndexWriter(core, true);\n        }\n        boolean reloadCore = false;\n        \n        try {\n          LOG.info(\"Starting download to \" + tmpIndexDir + \" fullCopy=\"\n              + isFullCopyNeeded);\n          successfulInstall = false;\n          \n          downloadIndexFiles(isFullCopyNeeded, indexDir, tmpIndexDir, latestGeneration);\n          LOG.info(\"Total time taken for download : \"\n              + ((System.currentTimeMillis() - replicationStartTime) / 1000)\n              + \" secs\");\n          Collection<Map<String,Object>> modifiedConfFiles = getModifiedConfFiles(confFilesToDownload);\n          if (!modifiedConfFiles.isEmpty()) {\n            reloadCore = true;\n            downloadConfFiles(confFilesToDownload, latestGeneration);\n            if (isFullCopyNeeded) {\n              successfulInstall = modifyIndexProps(tmpIdxDirName);\n              deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (successfulInstall) {\n              if (isFullCopyNeeded) {\n                // let the system know we are changing dir's and the old one\n                // may be closed\n                if (indexDir != null) {\n                  LOG.info(\"removing old index directory \" + indexDir);\n                  core.getDirectoryFactory().doneWithDirectory(indexDir);\n                  core.getDirectoryFactory().remove(indexDir);\n                }\n              }\n              \n              LOG.info(\"Configuration files are modified, core will be reloaded\");\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);// write to a file time of replication and\n                                     // conf files.\n            }\n          } else {\n            terminateAndWaitFsyncService();\n            if (isFullCopyNeeded) {\n              successfulInstall = modifyIndexProps(tmpIdxDirName);\n              deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (successfulInstall) {\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);\n            }\n          }\n        } finally {\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().openIndexWriter(core);\n          }\n        }\n        \n        // we must reload the core after we open the IW back up\n       if (successfulInstall && (reloadCore || forceCoreReload)) {\n          LOG.info(\"Reloading SolrCore {}\", core.getName());\n          reloadCore();\n        }\n\n        if (successfulInstall) {\n          if (isFullCopyNeeded) {\n            // let the system know we are changing dir's and the old one\n            // may be closed\n            if (indexDir != null) {\n              LOG.info(\"removing old index directory \" + indexDir);\n              core.getDirectoryFactory().doneWithDirectory(indexDir);\n              core.getDirectoryFactory().remove(indexDir);\n            }\n          }\n          if (isFullCopyNeeded) {\n            solrCore.getUpdateHandler().newIndexWriter(isFullCopyNeeded);\n          }\n          \n          openNewSearcherAndUpdateCommitPoint();\n        }\n        \n        if (!isFullCopyNeeded && !forceReplication && !successfulInstall) {\n          cleanup(core, tmpIndexDir, indexDir, deleteTmpIdxDir, successfulInstall);\n          cleanupDone = true;\n          // we try with a full copy of the index\n          LOG.warn(\n              \"Replication attempt was not successful - trying a full index replication reloadCore={}\",\n              reloadCore);\n          successfulInstall = fetchLatestIndex(core, true, reloadCore);\n        }\n        \n        replicationStartTime = 0;\n        return successfulInstall;\n      } catch (ReplicationHandlerException e) {\n        LOG.error(\"User aborted Replication\");\n        return false;\n      } catch (SolrException e) {\n        throw e;\n      } catch (InterruptedException e) {\n        throw new InterruptedException(\"Index fetch interrupted\");\n      } catch (Exception e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Index fetch failed : \", e);\n      }\n    } finally {\n      if (!cleanupDone) {\n        cleanup(core, tmpIndexDir, indexDir, deleteTmpIdxDir, successfulInstall);\n      }\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4137ef43bfa25c1b6749fa22fa4ee05f36779eea","date":1427814249,"type":3,"author":"Varun Thacker","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/IndexFetcher#fetchLatestIndex(SolrCore,boolean,boolean).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/IndexFetcher#fetchLatestIndex(SolrCore,boolean,boolean).mjava","sourceNew":"  /**\n   * This command downloads all the necessary files from master to install a index commit point. Only changed files are\n   * downloaded. It also downloads the conf files (if they are modified).\n   *\n   * @param core the SolrCore\n   * @param forceReplication force a replication in all cases \n   * @param forceCoreReload force a core reload in all cases\n   * @return true on success, false if slave is already in sync\n   * @throws IOException if an exception occurs\n   */\n   boolean fetchLatestIndex(final SolrCore core, boolean forceReplication, boolean forceCoreReload) throws IOException, InterruptedException {\n    boolean cleanupDone = false;\n    boolean successfulInstall = false;\n    replicationStartTime = System.currentTimeMillis();\n    Directory tmpIndexDir = null;\n    String tmpIndex = null;\n    Directory indexDir = null;\n    String indexDirPath = null;\n    boolean deleteTmpIdxDir = true;\n    \n    if (!core.getSolrCoreState().getLastReplicateIndexSuccess()) {\n      // if the last replication was not a success, we force a full replication\n      // when we are a bit more confident we may want to try a partial replication\n      // if the error is connection related or something, but we have to be careful\n      forceReplication = true;\n    }\n    \n    try {\n      //get the current 'replicateable' index version in the master\n      NamedList response = null;\n      try {\n        response = getLatestVersion();\n      } catch (Exception e) {\n        LOG.error(\"Master at: \" + masterUrl + \" is not available. Index fetch failed. Exception: \" + e.getMessage());\n        return false;\n      }\n      long latestVersion = (Long) response.get(CMD_INDEX_VERSION);\n      long latestGeneration = (Long) response.get(GENERATION);\n\n      // TODO: make sure that getLatestCommit only returns commit points for the main index (i.e. no side-car indexes)\n      IndexCommit commit = core.getDeletionPolicy().getLatestCommit();\n      if (commit == null) {\n        // Presumably the IndexWriter hasn't been opened yet, and hence the deletion policy hasn't been updated with commit points\n        RefCounted<SolrIndexSearcher> searcherRefCounted = null;\n        try {\n          searcherRefCounted = core.getNewestSearcher(false);\n          if (searcherRefCounted == null) {\n            LOG.warn(\"No open searcher found - fetch aborted\");\n            return false;\n          }\n          commit = searcherRefCounted.get().getIndexReader().getIndexCommit();\n        } finally {\n          if (searcherRefCounted != null)\n            searcherRefCounted.decref();\n        }\n      }\n\n\n      if (latestVersion == 0L) {\n        if (forceReplication && commit.getGeneration() != 0) {\n          // since we won't get the files for an empty index,\n          // we just clear ours and commit\n          RefCounted<IndexWriter> iw = core.getUpdateHandler().getSolrCoreState().getIndexWriter(core);\n          try {\n            iw.get().deleteAll();\n          } finally {\n            iw.decref();\n          }\n          SolrQueryRequest req = new LocalSolrQueryRequest(core,\n              new ModifiableSolrParams());\n          core.getUpdateHandler().commit(new CommitUpdateCommand(req, false));\n        }\n        \n        //there is nothing to be replicated\n        successfulInstall = true;\n        return true;\n      }\n      \n      if (!forceReplication && IndexDeletionPolicyWrapper.getCommitTimestamp(commit) == latestVersion) {\n        //master and slave are already in sync just return\n        LOG.info(\"Slave in sync with master.\");\n        successfulInstall = true;\n        return true;\n      }\n      LOG.info(\"Master's generation: \" + latestGeneration);\n      LOG.info(\"Slave's generation: \" + commit.getGeneration());\n      LOG.info(\"Starting replication process\");\n      // get the list of files first\n      fetchFileList(latestGeneration);\n      // this can happen if the commit point is deleted before we fetch the file list.\n      if(filesToDownload.isEmpty()) return false;\n      LOG.info(\"Number of files in latest index in master: \" + filesToDownload.size());\n\n      // Create the sync service\n      fsyncService = Executors.newSingleThreadExecutor(new DefaultSolrThreadFactory(\"fsyncService\"));\n      // use a synchronized list because the list is read by other threads (to show details)\n      filesDownloaded = Collections.synchronizedList(new ArrayList<Map<String, Object>>());\n      // if the generation of master is older than that of the slave , it means they are not compatible to be copied\n      // then a new index directory to be created and all the files need to be copied\n      boolean isFullCopyNeeded = IndexDeletionPolicyWrapper\n          .getCommitTimestamp(commit) >= latestVersion\n          || commit.getGeneration() >= latestGeneration || forceReplication;\n\n      String tmpIdxDirName = \"index.\" + new SimpleDateFormat(SnapShooter.DATE_FMT, Locale.ROOT).format(new Date());\n      tmpIndex = createTempindexDir(core, tmpIdxDirName);\n\n      tmpIndexDir = core.getDirectoryFactory().get(tmpIndex, DirContext.DEFAULT, core.getSolrConfig().indexConfig.lockType);\n      \n      // cindex dir...\n      indexDirPath = core.getIndexDir();\n      indexDir = core.getDirectoryFactory().get(indexDirPath, DirContext.DEFAULT, core.getSolrConfig().indexConfig.lockType);\n\n      try {\n\n        //We will compare all the index files from the master vs the index files on disk to see if there is a mismatch\n        //in the metadata. If there is a mismatch for the same index file then we download the entire index again.\n        if (!isFullCopyNeeded && isIndexStale(indexDir)) {\n          isFullCopyNeeded = true;\n        }\n        \n        if (!isFullCopyNeeded) {\n          // a searcher might be using some flushed but not committed segments\n          // because of soft commits (which open a searcher on IW's data)\n          // so we need to close the existing searcher on the last commit\n          // and wait until we are able to clean up all unused lucene files\n          if (solrCore.getCoreDescriptor().getCoreContainer().isZooKeeperAware()) {\n            solrCore.closeSearcher();\n          }\n\n          // rollback and reopen index writer and wait until all unused files\n          // are successfully deleted\n          solrCore.getUpdateHandler().newIndexWriter(true);\n          RefCounted<IndexWriter> writer = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n          try {\n            IndexWriter indexWriter = writer.get();\n            int c = 0;\n            indexWriter.deleteUnusedFiles();\n            while (hasUnusedFiles(indexDir, commit)) {\n              indexWriter.deleteUnusedFiles();\n              LOG.info(\"Sleeping for 1000ms to wait for unused lucene index files to be delete-able\");\n              Thread.sleep(1000);\n              c++;\n              if (c >= 30)  {\n                LOG.warn(\"IndexFetcher unable to cleanup unused lucene index files so we must do a full copy instead\");\n                isFullCopyNeeded = true;\n                break;\n              }\n            }\n            if (c > 0)  {\n              LOG.info(\"IndexFetcher slept for \" + (c * 1000) + \"ms for unused lucene index files to be delete-able\");\n            }\n          } finally {\n            writer.decref();\n          }\n          solrCore.getUpdateHandler().getSolrCoreState().closeIndexWriter(core, true);\n        }\n        boolean reloadCore = false;\n        \n        try {\n          LOG.info(\"Starting download to \" + tmpIndexDir + \" fullCopy=\"\n              + isFullCopyNeeded);\n          successfulInstall = false;\n          \n          downloadIndexFiles(isFullCopyNeeded, indexDir, tmpIndexDir, latestGeneration);\n          LOG.info(\"Total time taken for download : \"\n              + ((System.currentTimeMillis() - replicationStartTime) / 1000)\n              + \" secs\");\n          Collection<Map<String,Object>> modifiedConfFiles = getModifiedConfFiles(confFilesToDownload);\n          if (!modifiedConfFiles.isEmpty()) {\n            reloadCore = true;\n            downloadConfFiles(confFilesToDownload, latestGeneration);\n            if (isFullCopyNeeded) {\n              successfulInstall = modifyIndexProps(tmpIdxDirName);\n              deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (successfulInstall) {\n              if (isFullCopyNeeded) {\n                // let the system know we are changing dir's and the old one\n                // may be closed\n                if (indexDir != null) {\n                  LOG.info(\"removing old index directory \" + indexDir);\n                  core.getDirectoryFactory().doneWithDirectory(indexDir);\n                  core.getDirectoryFactory().remove(indexDir);\n                }\n              }\n              \n              LOG.info(\"Configuration files are modified, core will be reloaded\");\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);// write to a file time of replication and\n                                     // conf files.\n            }\n          } else {\n            terminateAndWaitFsyncService();\n            if (isFullCopyNeeded) {\n              successfulInstall = modifyIndexProps(tmpIdxDirName);\n              deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (successfulInstall) {\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);\n            }\n          }\n        } finally {\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().openIndexWriter(core);\n          }\n        }\n        \n        // we must reload the core after we open the IW back up\n       if (successfulInstall && (reloadCore || forceCoreReload)) {\n          LOG.info(\"Reloading SolrCore {}\", core.getName());\n          reloadCore();\n        }\n\n        if (successfulInstall) {\n          if (isFullCopyNeeded) {\n            // let the system know we are changing dir's and the old one\n            // may be closed\n            if (indexDir != null) {\n              LOG.info(\"removing old index directory \" + indexDir);\n              core.getDirectoryFactory().doneWithDirectory(indexDir);\n              core.getDirectoryFactory().remove(indexDir);\n            }\n          }\n          if (isFullCopyNeeded) {\n            solrCore.getUpdateHandler().newIndexWriter(isFullCopyNeeded);\n          }\n          \n          openNewSearcherAndUpdateCommitPoint();\n        }\n        \n        if (!isFullCopyNeeded && !forceReplication && !successfulInstall) {\n          cleanup(core, tmpIndexDir, indexDir, deleteTmpIdxDir, successfulInstall);\n          cleanupDone = true;\n          // we try with a full copy of the index\n          LOG.warn(\n              \"Replication attempt was not successful - trying a full index replication reloadCore={}\",\n              reloadCore);\n          successfulInstall = fetchLatestIndex(core, true, reloadCore);\n        }\n        \n        replicationStartTime = 0;\n        return successfulInstall;\n      } catch (ReplicationHandlerException e) {\n        LOG.error(\"User aborted Replication\");\n        return false;\n      } catch (SolrException e) {\n        throw e;\n      } catch (InterruptedException e) {\n        throw new InterruptedException(\"Index fetch interrupted\");\n      } catch (Exception e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Index fetch failed : \", e);\n      }\n    } finally {\n      if (!cleanupDone) {\n        cleanup(core, tmpIndexDir, indexDir, deleteTmpIdxDir, successfulInstall);\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * This command downloads all the necessary files from master to install a index commit point. Only changed files are\n   * downloaded. It also downloads the conf files (if they are modified).\n   *\n   * @param core the SolrCore\n   * @param forceReplication force a replication in all cases \n   * @param forceCoreReload force a core reload in all cases\n   * @return true on success, false if slave is already in sync\n   * @throws IOException if an exception occurs\n   */\n   boolean fetchLatestIndex(final SolrCore core, boolean forceReplication, boolean forceCoreReload) throws IOException, InterruptedException {\n    boolean cleanupDone = false;\n    boolean successfulInstall = false;\n    replicationStartTime = System.currentTimeMillis();\n    Directory tmpIndexDir = null;\n    String tmpIndex = null;\n    Directory indexDir = null;\n    String indexDirPath = null;\n    boolean deleteTmpIdxDir = true;\n    \n    if (!core.getSolrCoreState().getLastReplicateIndexSuccess()) {\n      // if the last replication was not a success, we force a full replication\n      // when we are a bit more confident we may want to try a partial replication\n      // if the error is connection related or something, but we have to be careful\n      forceReplication = true;\n    }\n    \n    try {\n      //get the current 'replicateable' index version in the master\n      NamedList response = null;\n      try {\n        response = getLatestVersion();\n      } catch (Exception e) {\n        LOG.error(\"Master at: \" + masterUrl + \" is not available. Index fetch failed. Exception: \" + e.getMessage());\n        return false;\n      }\n      long latestVersion = (Long) response.get(CMD_INDEX_VERSION);\n      long latestGeneration = (Long) response.get(GENERATION);\n\n      // TODO: make sure that getLatestCommit only returns commit points for the main index (i.e. no side-car indexes)\n      IndexCommit commit = core.getDeletionPolicy().getLatestCommit();\n      if (commit == null) {\n        // Presumably the IndexWriter hasn't been opened yet, and hence the deletion policy hasn't been updated with commit points\n        RefCounted<SolrIndexSearcher> searcherRefCounted = null;\n        try {\n          searcherRefCounted = core.getNewestSearcher(false);\n          if (searcherRefCounted == null) {\n            LOG.warn(\"No open searcher found - fetch aborted\");\n            return false;\n          }\n          commit = searcherRefCounted.get().getIndexReader().getIndexCommit();\n        } finally {\n          if (searcherRefCounted != null)\n            searcherRefCounted.decref();\n        }\n      }\n\n\n      if (latestVersion == 0L) {\n        if (forceReplication && commit.getGeneration() != 0) {\n          // since we won't get the files for an empty index,\n          // we just clear ours and commit\n          RefCounted<IndexWriter> iw = core.getUpdateHandler().getSolrCoreState().getIndexWriter(core);\n          try {\n            iw.get().deleteAll();\n          } finally {\n            iw.decref();\n          }\n          SolrQueryRequest req = new LocalSolrQueryRequest(core,\n              new ModifiableSolrParams());\n          core.getUpdateHandler().commit(new CommitUpdateCommand(req, false));\n        }\n        \n        //there is nothing to be replicated\n        successfulInstall = true;\n        return true;\n      }\n      \n      if (!forceReplication && IndexDeletionPolicyWrapper.getCommitTimestamp(commit) == latestVersion) {\n        //master and slave are already in sync just return\n        LOG.info(\"Slave in sync with master.\");\n        successfulInstall = true;\n        return true;\n      }\n      LOG.info(\"Master's generation: \" + latestGeneration);\n      LOG.info(\"Slave's generation: \" + commit.getGeneration());\n      LOG.info(\"Starting replication process\");\n      // get the list of files first\n      fetchFileList(latestGeneration);\n      // this can happen if the commit point is deleted before we fetch the file list.\n      if(filesToDownload.isEmpty()) return false;\n      LOG.info(\"Number of files in latest index in master: \" + filesToDownload.size());\n\n      // Create the sync service\n      fsyncService = Executors.newSingleThreadExecutor(new DefaultSolrThreadFactory(\"fsyncService\"));\n      // use a synchronized list because the list is read by other threads (to show details)\n      filesDownloaded = Collections.synchronizedList(new ArrayList<Map<String, Object>>());\n      // if the generation of master is older than that of the slave , it means they are not compatible to be copied\n      // then a new index directory to be created and all the files need to be copied\n      boolean isFullCopyNeeded = IndexDeletionPolicyWrapper\n          .getCommitTimestamp(commit) >= latestVersion\n          || commit.getGeneration() >= latestGeneration || forceReplication;\n\n      String tmpIdxDirName = \"index.\" + new SimpleDateFormat(SnapShooter.DATE_FMT, Locale.ROOT).format(new Date());\n      tmpIndex = createTempindexDir(core, tmpIdxDirName);\n\n      tmpIndexDir = core.getDirectoryFactory().get(tmpIndex, DirContext.DEFAULT, core.getSolrConfig().indexConfig.lockType);\n      \n      // cindex dir...\n      indexDirPath = core.getIndexDir();\n      indexDir = core.getDirectoryFactory().get(indexDirPath, DirContext.DEFAULT, core.getSolrConfig().indexConfig.lockType);\n\n      try {\n        \n        if (isIndexStale(indexDir)) {\n          isFullCopyNeeded = true;\n        }\n        \n        if (!isFullCopyNeeded) {\n          // a searcher might be using some flushed but not committed segments\n          // because of soft commits (which open a searcher on IW's data)\n          // so we need to close the existing searcher on the last commit\n          // and wait until we are able to clean up all unused lucene files\n          if (solrCore.getCoreDescriptor().getCoreContainer().isZooKeeperAware()) {\n            solrCore.closeSearcher();\n          }\n\n          // rollback and reopen index writer and wait until all unused files\n          // are successfully deleted\n          solrCore.getUpdateHandler().newIndexWriter(true);\n          RefCounted<IndexWriter> writer = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n          try {\n            IndexWriter indexWriter = writer.get();\n            int c = 0;\n            indexWriter.deleteUnusedFiles();\n            while (hasUnusedFiles(indexDir, commit)) {\n              indexWriter.deleteUnusedFiles();\n              LOG.info(\"Sleeping for 1000ms to wait for unused lucene index files to be delete-able\");\n              Thread.sleep(1000);\n              c++;\n              if (c >= 30)  {\n                LOG.warn(\"IndexFetcher unable to cleanup unused lucene index files so we must do a full copy instead\");\n                isFullCopyNeeded = true;\n                break;\n              }\n            }\n            if (c > 0)  {\n              LOG.info(\"IndexFetcher slept for \" + (c * 1000) + \"ms for unused lucene index files to be delete-able\");\n            }\n          } finally {\n            writer.decref();\n          }\n          solrCore.getUpdateHandler().getSolrCoreState().closeIndexWriter(core, true);\n        }\n        boolean reloadCore = false;\n        \n        try {\n          LOG.info(\"Starting download to \" + tmpIndexDir + \" fullCopy=\"\n              + isFullCopyNeeded);\n          successfulInstall = false;\n          \n          downloadIndexFiles(isFullCopyNeeded, indexDir, tmpIndexDir, latestGeneration);\n          LOG.info(\"Total time taken for download : \"\n              + ((System.currentTimeMillis() - replicationStartTime) / 1000)\n              + \" secs\");\n          Collection<Map<String,Object>> modifiedConfFiles = getModifiedConfFiles(confFilesToDownload);\n          if (!modifiedConfFiles.isEmpty()) {\n            reloadCore = true;\n            downloadConfFiles(confFilesToDownload, latestGeneration);\n            if (isFullCopyNeeded) {\n              successfulInstall = modifyIndexProps(tmpIdxDirName);\n              deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (successfulInstall) {\n              if (isFullCopyNeeded) {\n                // let the system know we are changing dir's and the old one\n                // may be closed\n                if (indexDir != null) {\n                  LOG.info(\"removing old index directory \" + indexDir);\n                  core.getDirectoryFactory().doneWithDirectory(indexDir);\n                  core.getDirectoryFactory().remove(indexDir);\n                }\n              }\n              \n              LOG.info(\"Configuration files are modified, core will be reloaded\");\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);// write to a file time of replication and\n                                     // conf files.\n            }\n          } else {\n            terminateAndWaitFsyncService();\n            if (isFullCopyNeeded) {\n              successfulInstall = modifyIndexProps(tmpIdxDirName);\n              deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (successfulInstall) {\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);\n            }\n          }\n        } finally {\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().openIndexWriter(core);\n          }\n        }\n        \n        // we must reload the core after we open the IW back up\n       if (successfulInstall && (reloadCore || forceCoreReload)) {\n          LOG.info(\"Reloading SolrCore {}\", core.getName());\n          reloadCore();\n        }\n\n        if (successfulInstall) {\n          if (isFullCopyNeeded) {\n            // let the system know we are changing dir's and the old one\n            // may be closed\n            if (indexDir != null) {\n              LOG.info(\"removing old index directory \" + indexDir);\n              core.getDirectoryFactory().doneWithDirectory(indexDir);\n              core.getDirectoryFactory().remove(indexDir);\n            }\n          }\n          if (isFullCopyNeeded) {\n            solrCore.getUpdateHandler().newIndexWriter(isFullCopyNeeded);\n          }\n          \n          openNewSearcherAndUpdateCommitPoint();\n        }\n        \n        if (!isFullCopyNeeded && !forceReplication && !successfulInstall) {\n          cleanup(core, tmpIndexDir, indexDir, deleteTmpIdxDir, successfulInstall);\n          cleanupDone = true;\n          // we try with a full copy of the index\n          LOG.warn(\n              \"Replication attempt was not successful - trying a full index replication reloadCore={}\",\n              reloadCore);\n          successfulInstall = fetchLatestIndex(core, true, reloadCore);\n        }\n        \n        replicationStartTime = 0;\n        return successfulInstall;\n      } catch (ReplicationHandlerException e) {\n        LOG.error(\"User aborted Replication\");\n        return false;\n      } catch (SolrException e) {\n        throw e;\n      } catch (InterruptedException e) {\n        throw new InterruptedException(\"Index fetch interrupted\");\n      } catch (Exception e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Index fetch failed : \", e);\n      }\n    } finally {\n      if (!cleanupDone) {\n        cleanup(core, tmpIndexDir, indexDir, deleteTmpIdxDir, successfulInstall);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"fab172655716b96f7e42376116235017a922de3a","date":1427850611,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/handler/IndexFetcher#fetchLatestIndex(SolrCore,boolean,boolean).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/IndexFetcher#fetchLatestIndex(SolrCore,boolean,boolean).mjava","sourceNew":"  /**\n   * This command downloads all the necessary files from master to install a index commit point. Only changed files are\n   * downloaded. It also downloads the conf files (if they are modified).\n   *\n   * @param core the SolrCore\n   * @param forceReplication force a replication in all cases \n   * @param forceCoreReload force a core reload in all cases\n   * @return true on success, false if slave is already in sync\n   * @throws IOException if an exception occurs\n   */\n   boolean fetchLatestIndex(final SolrCore core, boolean forceReplication, boolean forceCoreReload) throws IOException, InterruptedException {\n    boolean cleanupDone = false;\n    boolean successfulInstall = false;\n    replicationStartTime = System.currentTimeMillis();\n    Directory tmpIndexDir = null;\n    String tmpIndex = null;\n    Directory indexDir = null;\n    String indexDirPath = null;\n    boolean deleteTmpIdxDir = true;\n    \n    if (!core.getSolrCoreState().getLastReplicateIndexSuccess()) {\n      // if the last replication was not a success, we force a full replication\n      // when we are a bit more confident we may want to try a partial replication\n      // if the error is connection related or something, but we have to be careful\n      forceReplication = true;\n    }\n    \n    try {\n      //get the current 'replicateable' index version in the master\n      NamedList response = null;\n      try {\n        response = getLatestVersion();\n      } catch (Exception e) {\n        LOG.error(\"Master at: \" + masterUrl + \" is not available. Index fetch failed. Exception: \" + e.getMessage());\n        return false;\n      }\n      long latestVersion = (Long) response.get(CMD_INDEX_VERSION);\n      long latestGeneration = (Long) response.get(GENERATION);\n\n      // TODO: make sure that getLatestCommit only returns commit points for the main index (i.e. no side-car indexes)\n      IndexCommit commit = core.getDeletionPolicy().getLatestCommit();\n      if (commit == null) {\n        // Presumably the IndexWriter hasn't been opened yet, and hence the deletion policy hasn't been updated with commit points\n        RefCounted<SolrIndexSearcher> searcherRefCounted = null;\n        try {\n          searcherRefCounted = core.getNewestSearcher(false);\n          if (searcherRefCounted == null) {\n            LOG.warn(\"No open searcher found - fetch aborted\");\n            return false;\n          }\n          commit = searcherRefCounted.get().getIndexReader().getIndexCommit();\n        } finally {\n          if (searcherRefCounted != null)\n            searcherRefCounted.decref();\n        }\n      }\n\n\n      if (latestVersion == 0L) {\n        if (forceReplication && commit.getGeneration() != 0) {\n          // since we won't get the files for an empty index,\n          // we just clear ours and commit\n          RefCounted<IndexWriter> iw = core.getUpdateHandler().getSolrCoreState().getIndexWriter(core);\n          try {\n            iw.get().deleteAll();\n          } finally {\n            iw.decref();\n          }\n          SolrQueryRequest req = new LocalSolrQueryRequest(core,\n              new ModifiableSolrParams());\n          core.getUpdateHandler().commit(new CommitUpdateCommand(req, false));\n        }\n        \n        //there is nothing to be replicated\n        successfulInstall = true;\n        return true;\n      }\n      \n      if (!forceReplication && IndexDeletionPolicyWrapper.getCommitTimestamp(commit) == latestVersion) {\n        //master and slave are already in sync just return\n        LOG.info(\"Slave in sync with master.\");\n        successfulInstall = true;\n        return true;\n      }\n      LOG.info(\"Master's generation: \" + latestGeneration);\n      LOG.info(\"Slave's generation: \" + commit.getGeneration());\n      LOG.info(\"Starting replication process\");\n      // get the list of files first\n      fetchFileList(latestGeneration);\n      // this can happen if the commit point is deleted before we fetch the file list.\n      if(filesToDownload.isEmpty()) return false;\n      LOG.info(\"Number of files in latest index in master: \" + filesToDownload.size());\n\n      // Create the sync service\n      fsyncService = Executors.newSingleThreadExecutor(new DefaultSolrThreadFactory(\"fsyncService\"));\n      // use a synchronized list because the list is read by other threads (to show details)\n      filesDownloaded = Collections.synchronizedList(new ArrayList<Map<String, Object>>());\n      // if the generation of master is older than that of the slave , it means they are not compatible to be copied\n      // then a new index directory to be created and all the files need to be copied\n      boolean isFullCopyNeeded = IndexDeletionPolicyWrapper\n          .getCommitTimestamp(commit) >= latestVersion\n          || commit.getGeneration() >= latestGeneration || forceReplication;\n\n      String tmpIdxDirName = \"index.\" + new SimpleDateFormat(SnapShooter.DATE_FMT, Locale.ROOT).format(new Date());\n      tmpIndex = createTempindexDir(core, tmpIdxDirName);\n\n      tmpIndexDir = core.getDirectoryFactory().get(tmpIndex, DirContext.DEFAULT, core.getSolrConfig().indexConfig.lockType);\n      \n      // cindex dir...\n      indexDirPath = core.getIndexDir();\n      indexDir = core.getDirectoryFactory().get(indexDirPath, DirContext.DEFAULT, core.getSolrConfig().indexConfig.lockType);\n\n      try {\n\n        //We will compare all the index files from the master vs the index files on disk to see if there is a mismatch\n        //in the metadata. If there is a mismatch for the same index file then we download the entire index again.\n        if (!isFullCopyNeeded && isIndexStale(indexDir)) {\n          isFullCopyNeeded = true;\n        }\n        \n        if (!isFullCopyNeeded) {\n          // a searcher might be using some flushed but not committed segments\n          // because of soft commits (which open a searcher on IW's data)\n          // so we need to close the existing searcher on the last commit\n          // and wait until we are able to clean up all unused lucene files\n          if (solrCore.getCoreDescriptor().getCoreContainer().isZooKeeperAware()) {\n            solrCore.closeSearcher();\n          }\n\n          // rollback and reopen index writer and wait until all unused files\n          // are successfully deleted\n          solrCore.getUpdateHandler().newIndexWriter(true);\n          RefCounted<IndexWriter> writer = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n          try {\n            IndexWriter indexWriter = writer.get();\n            int c = 0;\n            indexWriter.deleteUnusedFiles();\n            while (hasUnusedFiles(indexDir, commit)) {\n              indexWriter.deleteUnusedFiles();\n              LOG.info(\"Sleeping for 1000ms to wait for unused lucene index files to be delete-able\");\n              Thread.sleep(1000);\n              c++;\n              if (c >= 30)  {\n                LOG.warn(\"IndexFetcher unable to cleanup unused lucene index files so we must do a full copy instead\");\n                isFullCopyNeeded = true;\n                break;\n              }\n            }\n            if (c > 0)  {\n              LOG.info(\"IndexFetcher slept for \" + (c * 1000) + \"ms for unused lucene index files to be delete-able\");\n            }\n          } finally {\n            writer.decref();\n          }\n          solrCore.getUpdateHandler().getSolrCoreState().closeIndexWriter(core, true);\n        }\n        boolean reloadCore = false;\n        \n        try {\n          LOG.info(\"Starting download to \" + tmpIndexDir + \" fullCopy=\"\n              + isFullCopyNeeded);\n          successfulInstall = false;\n          \n          downloadIndexFiles(isFullCopyNeeded, indexDir, tmpIndexDir, latestGeneration);\n          LOG.info(\"Total time taken for download : \"\n              + ((System.currentTimeMillis() - replicationStartTime) / 1000)\n              + \" secs\");\n          Collection<Map<String,Object>> modifiedConfFiles = getModifiedConfFiles(confFilesToDownload);\n          if (!modifiedConfFiles.isEmpty()) {\n            reloadCore = true;\n            downloadConfFiles(confFilesToDownload, latestGeneration);\n            if (isFullCopyNeeded) {\n              successfulInstall = modifyIndexProps(tmpIdxDirName);\n              deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (successfulInstall) {\n              if (isFullCopyNeeded) {\n                // let the system know we are changing dir's and the old one\n                // may be closed\n                if (indexDir != null) {\n                  LOG.info(\"removing old index directory \" + indexDir);\n                  core.getDirectoryFactory().doneWithDirectory(indexDir);\n                  core.getDirectoryFactory().remove(indexDir);\n                }\n              }\n              \n              LOG.info(\"Configuration files are modified, core will be reloaded\");\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);// write to a file time of replication and\n                                     // conf files.\n            }\n          } else {\n            terminateAndWaitFsyncService();\n            if (isFullCopyNeeded) {\n              successfulInstall = modifyIndexProps(tmpIdxDirName);\n              deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (successfulInstall) {\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);\n            }\n          }\n        } finally {\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().openIndexWriter(core);\n          }\n        }\n        \n        // we must reload the core after we open the IW back up\n       if (successfulInstall && (reloadCore || forceCoreReload)) {\n          LOG.info(\"Reloading SolrCore {}\", core.getName());\n          reloadCore();\n        }\n\n        if (successfulInstall) {\n          if (isFullCopyNeeded) {\n            // let the system know we are changing dir's and the old one\n            // may be closed\n            if (indexDir != null) {\n              LOG.info(\"removing old index directory \" + indexDir);\n              core.getDirectoryFactory().doneWithDirectory(indexDir);\n              core.getDirectoryFactory().remove(indexDir);\n            }\n          }\n          if (isFullCopyNeeded) {\n            solrCore.getUpdateHandler().newIndexWriter(isFullCopyNeeded);\n          }\n          \n          openNewSearcherAndUpdateCommitPoint();\n        }\n        \n        if (!isFullCopyNeeded && !forceReplication && !successfulInstall) {\n          cleanup(core, tmpIndexDir, indexDir, deleteTmpIdxDir, successfulInstall);\n          cleanupDone = true;\n          // we try with a full copy of the index\n          LOG.warn(\n              \"Replication attempt was not successful - trying a full index replication reloadCore={}\",\n              reloadCore);\n          successfulInstall = fetchLatestIndex(core, true, reloadCore);\n        }\n        \n        replicationStartTime = 0;\n        return successfulInstall;\n      } catch (ReplicationHandlerException e) {\n        LOG.error(\"User aborted Replication\");\n        return false;\n      } catch (SolrException e) {\n        throw e;\n      } catch (InterruptedException e) {\n        throw new InterruptedException(\"Index fetch interrupted\");\n      } catch (Exception e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Index fetch failed : \", e);\n      }\n    } finally {\n      if (!cleanupDone) {\n        cleanup(core, tmpIndexDir, indexDir, deleteTmpIdxDir, successfulInstall);\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * This command downloads all the necessary files from master to install a index commit point. Only changed files are\n   * downloaded. It also downloads the conf files (if they are modified).\n   *\n   * @param core the SolrCore\n   * @param forceReplication force a replication in all cases \n   * @param forceCoreReload force a core reload in all cases\n   * @return true on success, false if slave is already in sync\n   * @throws IOException if an exception occurs\n   */\n   boolean fetchLatestIndex(final SolrCore core, boolean forceReplication, boolean forceCoreReload) throws IOException, InterruptedException {\n    boolean cleanupDone = false;\n    boolean successfulInstall = false;\n    replicationStartTime = System.currentTimeMillis();\n    Directory tmpIndexDir = null;\n    String tmpIndex = null;\n    Directory indexDir = null;\n    String indexDirPath = null;\n    boolean deleteTmpIdxDir = true;\n    \n    if (!core.getSolrCoreState().getLastReplicateIndexSuccess()) {\n      // if the last replication was not a success, we force a full replication\n      // when we are a bit more confident we may want to try a partial replication\n      // if the error is connection related or something, but we have to be careful\n      forceReplication = true;\n    }\n    \n    try {\n      //get the current 'replicateable' index version in the master\n      NamedList response = null;\n      try {\n        response = getLatestVersion();\n      } catch (Exception e) {\n        LOG.error(\"Master at: \" + masterUrl + \" is not available. Index fetch failed. Exception: \" + e.getMessage());\n        return false;\n      }\n      long latestVersion = (Long) response.get(CMD_INDEX_VERSION);\n      long latestGeneration = (Long) response.get(GENERATION);\n\n      // TODO: make sure that getLatestCommit only returns commit points for the main index (i.e. no side-car indexes)\n      IndexCommit commit = core.getDeletionPolicy().getLatestCommit();\n      if (commit == null) {\n        // Presumably the IndexWriter hasn't been opened yet, and hence the deletion policy hasn't been updated with commit points\n        RefCounted<SolrIndexSearcher> searcherRefCounted = null;\n        try {\n          searcherRefCounted = core.getNewestSearcher(false);\n          if (searcherRefCounted == null) {\n            LOG.warn(\"No open searcher found - fetch aborted\");\n            return false;\n          }\n          commit = searcherRefCounted.get().getIndexReader().getIndexCommit();\n        } finally {\n          if (searcherRefCounted != null)\n            searcherRefCounted.decref();\n        }\n      }\n\n\n      if (latestVersion == 0L) {\n        if (forceReplication && commit.getGeneration() != 0) {\n          // since we won't get the files for an empty index,\n          // we just clear ours and commit\n          RefCounted<IndexWriter> iw = core.getUpdateHandler().getSolrCoreState().getIndexWriter(core);\n          try {\n            iw.get().deleteAll();\n          } finally {\n            iw.decref();\n          }\n          SolrQueryRequest req = new LocalSolrQueryRequest(core,\n              new ModifiableSolrParams());\n          core.getUpdateHandler().commit(new CommitUpdateCommand(req, false));\n        }\n        \n        //there is nothing to be replicated\n        successfulInstall = true;\n        return true;\n      }\n      \n      if (!forceReplication && IndexDeletionPolicyWrapper.getCommitTimestamp(commit) == latestVersion) {\n        //master and slave are already in sync just return\n        LOG.info(\"Slave in sync with master.\");\n        successfulInstall = true;\n        return true;\n      }\n      LOG.info(\"Master's generation: \" + latestGeneration);\n      LOG.info(\"Slave's generation: \" + commit.getGeneration());\n      LOG.info(\"Starting replication process\");\n      // get the list of files first\n      fetchFileList(latestGeneration);\n      // this can happen if the commit point is deleted before we fetch the file list.\n      if(filesToDownload.isEmpty()) return false;\n      LOG.info(\"Number of files in latest index in master: \" + filesToDownload.size());\n\n      // Create the sync service\n      fsyncService = Executors.newSingleThreadExecutor(new DefaultSolrThreadFactory(\"fsyncService\"));\n      // use a synchronized list because the list is read by other threads (to show details)\n      filesDownloaded = Collections.synchronizedList(new ArrayList<Map<String, Object>>());\n      // if the generation of master is older than that of the slave , it means they are not compatible to be copied\n      // then a new index directory to be created and all the files need to be copied\n      boolean isFullCopyNeeded = IndexDeletionPolicyWrapper\n          .getCommitTimestamp(commit) >= latestVersion\n          || commit.getGeneration() >= latestGeneration || forceReplication;\n\n      String tmpIdxDirName = \"index.\" + new SimpleDateFormat(SnapShooter.DATE_FMT, Locale.ROOT).format(new Date());\n      tmpIndex = createTempindexDir(core, tmpIdxDirName);\n\n      tmpIndexDir = core.getDirectoryFactory().get(tmpIndex, DirContext.DEFAULT, core.getSolrConfig().indexConfig.lockType);\n      \n      // cindex dir...\n      indexDirPath = core.getIndexDir();\n      indexDir = core.getDirectoryFactory().get(indexDirPath, DirContext.DEFAULT, core.getSolrConfig().indexConfig.lockType);\n\n      try {\n        \n        if (isIndexStale(indexDir)) {\n          isFullCopyNeeded = true;\n        }\n        \n        if (!isFullCopyNeeded) {\n          // a searcher might be using some flushed but not committed segments\n          // because of soft commits (which open a searcher on IW's data)\n          // so we need to close the existing searcher on the last commit\n          // and wait until we are able to clean up all unused lucene files\n          if (solrCore.getCoreDescriptor().getCoreContainer().isZooKeeperAware()) {\n            solrCore.closeSearcher();\n          }\n\n          // rollback and reopen index writer and wait until all unused files\n          // are successfully deleted\n          solrCore.getUpdateHandler().newIndexWriter(true);\n          RefCounted<IndexWriter> writer = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n          try {\n            IndexWriter indexWriter = writer.get();\n            int c = 0;\n            indexWriter.deleteUnusedFiles();\n            while (hasUnusedFiles(indexDir, commit)) {\n              indexWriter.deleteUnusedFiles();\n              LOG.info(\"Sleeping for 1000ms to wait for unused lucene index files to be delete-able\");\n              Thread.sleep(1000);\n              c++;\n              if (c >= 30)  {\n                LOG.warn(\"IndexFetcher unable to cleanup unused lucene index files so we must do a full copy instead\");\n                isFullCopyNeeded = true;\n                break;\n              }\n            }\n            if (c > 0)  {\n              LOG.info(\"IndexFetcher slept for \" + (c * 1000) + \"ms for unused lucene index files to be delete-able\");\n            }\n          } finally {\n            writer.decref();\n          }\n          solrCore.getUpdateHandler().getSolrCoreState().closeIndexWriter(core, true);\n        }\n        boolean reloadCore = false;\n        \n        try {\n          LOG.info(\"Starting download to \" + tmpIndexDir + \" fullCopy=\"\n              + isFullCopyNeeded);\n          successfulInstall = false;\n          \n          downloadIndexFiles(isFullCopyNeeded, indexDir, tmpIndexDir, latestGeneration);\n          LOG.info(\"Total time taken for download : \"\n              + ((System.currentTimeMillis() - replicationStartTime) / 1000)\n              + \" secs\");\n          Collection<Map<String,Object>> modifiedConfFiles = getModifiedConfFiles(confFilesToDownload);\n          if (!modifiedConfFiles.isEmpty()) {\n            reloadCore = true;\n            downloadConfFiles(confFilesToDownload, latestGeneration);\n            if (isFullCopyNeeded) {\n              successfulInstall = modifyIndexProps(tmpIdxDirName);\n              deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (successfulInstall) {\n              if (isFullCopyNeeded) {\n                // let the system know we are changing dir's and the old one\n                // may be closed\n                if (indexDir != null) {\n                  LOG.info(\"removing old index directory \" + indexDir);\n                  core.getDirectoryFactory().doneWithDirectory(indexDir);\n                  core.getDirectoryFactory().remove(indexDir);\n                }\n              }\n              \n              LOG.info(\"Configuration files are modified, core will be reloaded\");\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);// write to a file time of replication and\n                                     // conf files.\n            }\n          } else {\n            terminateAndWaitFsyncService();\n            if (isFullCopyNeeded) {\n              successfulInstall = modifyIndexProps(tmpIdxDirName);\n              deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (successfulInstall) {\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);\n            }\n          }\n        } finally {\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().openIndexWriter(core);\n          }\n        }\n        \n        // we must reload the core after we open the IW back up\n       if (successfulInstall && (reloadCore || forceCoreReload)) {\n          LOG.info(\"Reloading SolrCore {}\", core.getName());\n          reloadCore();\n        }\n\n        if (successfulInstall) {\n          if (isFullCopyNeeded) {\n            // let the system know we are changing dir's and the old one\n            // may be closed\n            if (indexDir != null) {\n              LOG.info(\"removing old index directory \" + indexDir);\n              core.getDirectoryFactory().doneWithDirectory(indexDir);\n              core.getDirectoryFactory().remove(indexDir);\n            }\n          }\n          if (isFullCopyNeeded) {\n            solrCore.getUpdateHandler().newIndexWriter(isFullCopyNeeded);\n          }\n          \n          openNewSearcherAndUpdateCommitPoint();\n        }\n        \n        if (!isFullCopyNeeded && !forceReplication && !successfulInstall) {\n          cleanup(core, tmpIndexDir, indexDir, deleteTmpIdxDir, successfulInstall);\n          cleanupDone = true;\n          // we try with a full copy of the index\n          LOG.warn(\n              \"Replication attempt was not successful - trying a full index replication reloadCore={}\",\n              reloadCore);\n          successfulInstall = fetchLatestIndex(core, true, reloadCore);\n        }\n        \n        replicationStartTime = 0;\n        return successfulInstall;\n      } catch (ReplicationHandlerException e) {\n        LOG.error(\"User aborted Replication\");\n        return false;\n      } catch (SolrException e) {\n        throw e;\n      } catch (InterruptedException e) {\n        throw new InterruptedException(\"Index fetch interrupted\");\n      } catch (Exception e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Index fetch failed : \", e);\n      }\n    } finally {\n      if (!cleanupDone) {\n        cleanup(core, tmpIndexDir, indexDir, deleteTmpIdxDir, successfulInstall);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7b13106276bb5ea342253dbf6aae7b675adb38d3","date":1428054414,"type":5,"author":"Varun Thacker","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/IndexFetcher#fetchLatestIndex(boolean,boolean).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/IndexFetcher#fetchLatestIndex(SolrCore,boolean,boolean).mjava","sourceNew":"  /**\n   * This command downloads all the necessary files from master to install a index commit point. Only changed files are\n   * downloaded. It also downloads the conf files (if they are modified).\n   *\n   * @param forceReplication force a replication in all cases \n   * @param forceCoreReload force a core reload in all cases\n   * @return true on success, false if slave is already in sync\n   * @throws IOException if an exception occurs\n   */\n  boolean fetchLatestIndex(boolean forceReplication, boolean forceCoreReload) throws IOException, InterruptedException {\n    \n    boolean cleanupDone = false;\n    boolean successfulInstall = false;\n    replicationStartTime = System.currentTimeMillis();\n    Directory tmpIndexDir = null;\n    String tmpIndex;\n    Directory indexDir = null;\n    String indexDirPath;\n    boolean deleteTmpIdxDir = true;\n    \n    if (!solrCore.getSolrCoreState().getLastReplicateIndexSuccess()) {\n      // if the last replication was not a success, we force a full replication\n      // when we are a bit more confident we may want to try a partial replication\n      // if the error is connection related or something, but we have to be careful\n      forceReplication = true;\n    }\n    \n    try {\n      //get the current 'replicateable' index version in the master\n      NamedList response;\n      try {\n        response = getLatestVersion();\n      } catch (Exception e) {\n        LOG.error(\"Master at: \" + masterUrl + \" is not available. Index fetch failed. Exception: \" + e.getMessage());\n        return false;\n      }\n      long latestVersion = (Long) response.get(CMD_INDEX_VERSION);\n      long latestGeneration = (Long) response.get(GENERATION);\n\n      // TODO: make sure that getLatestCommit only returns commit points for the main index (i.e. no side-car indexes)\n      IndexCommit commit = solrCore.getDeletionPolicy().getLatestCommit();\n      if (commit == null) {\n        // Presumably the IndexWriter hasn't been opened yet, and hence the deletion policy hasn't been updated with commit points\n        RefCounted<SolrIndexSearcher> searcherRefCounted = null;\n        try {\n          searcherRefCounted = solrCore.getNewestSearcher(false);\n          if (searcherRefCounted == null) {\n            LOG.warn(\"No open searcher found - fetch aborted\");\n            return false;\n          }\n          commit = searcherRefCounted.get().getIndexReader().getIndexCommit();\n        } finally {\n          if (searcherRefCounted != null)\n            searcherRefCounted.decref();\n        }\n      }\n\n\n      if (latestVersion == 0L) {\n        if (forceReplication && commit.getGeneration() != 0) {\n          // since we won't get the files for an empty index,\n          // we just clear ours and commit\n          RefCounted<IndexWriter> iw = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(solrCore);\n          try {\n            iw.get().deleteAll();\n          } finally {\n            iw.decref();\n          }\n          SolrQueryRequest req = new LocalSolrQueryRequest(solrCore, new ModifiableSolrParams());\n          solrCore.getUpdateHandler().commit(new CommitUpdateCommand(req, false));\n        }\n        \n        //there is nothing to be replicated\n        successfulInstall = true;\n        return true;\n      }\n      \n      if (!forceReplication && IndexDeletionPolicyWrapper.getCommitTimestamp(commit) == latestVersion) {\n        //master and slave are already in sync just return\n        LOG.info(\"Slave in sync with master.\");\n        successfulInstall = true;\n        return true;\n      }\n      LOG.info(\"Master's generation: \" + latestGeneration);\n      LOG.info(\"Slave's generation: \" + commit.getGeneration());\n      LOG.info(\"Starting replication process\");\n      // get the list of files first\n      fetchFileList(latestGeneration);\n      // this can happen if the commit point is deleted before we fetch the file list.\n      if (filesToDownload.isEmpty()) {\n        return false;\n      }\n      LOG.info(\"Number of files in latest index in master: \" + filesToDownload.size());\n\n      // Create the sync service\n      fsyncService = Executors.newSingleThreadExecutor(new DefaultSolrThreadFactory(\"fsyncService\"));\n      // use a synchronized list because the list is read by other threads (to show details)\n      filesDownloaded = Collections.synchronizedList(new ArrayList<Map<String, Object>>());\n      // if the generation of master is older than that of the slave , it means they are not compatible to be copied\n      // then a new index directory to be created and all the files need to be copied\n      boolean isFullCopyNeeded = IndexDeletionPolicyWrapper\n          .getCommitTimestamp(commit) >= latestVersion\n          || commit.getGeneration() >= latestGeneration || forceReplication;\n\n      String tmpIdxDirName = \"index.\" + new SimpleDateFormat(SnapShooter.DATE_FMT, Locale.ROOT).format(new Date());\n      tmpIndex = Paths.get(solrCore.getDataDir(), tmpIdxDirName).toString();\n\n      tmpIndexDir = solrCore.getDirectoryFactory().get(tmpIndex, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n      \n      // cindex dir...\n      indexDirPath = solrCore.getIndexDir();\n      indexDir = solrCore.getDirectoryFactory().get(indexDirPath, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      try {\n\n        //We will compare all the index files from the master vs the index files on disk to see if there is a mismatch\n        //in the metadata. If there is a mismatch for the same index file then we download the entire index again.\n        if (!isFullCopyNeeded && isIndexStale(indexDir)) {\n          isFullCopyNeeded = true;\n        }\n        \n        if (!isFullCopyNeeded) {\n          // a searcher might be using some flushed but not committed segments\n          // because of soft commits (which open a searcher on IW's data)\n          // so we need to close the existing searcher on the last commit\n          // and wait until we are able to clean up all unused lucene files\n          if (solrCore.getCoreDescriptor().getCoreContainer().isZooKeeperAware()) {\n            solrCore.closeSearcher();\n          }\n\n          // rollback and reopen index writer and wait until all unused files\n          // are successfully deleted\n          solrCore.getUpdateHandler().newIndexWriter(true);\n          RefCounted<IndexWriter> writer = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n          try {\n            IndexWriter indexWriter = writer.get();\n            int c = 0;\n            indexWriter.deleteUnusedFiles();\n            while (hasUnusedFiles(indexDir, commit)) {\n              indexWriter.deleteUnusedFiles();\n              LOG.info(\"Sleeping for 1000ms to wait for unused lucene index files to be delete-able\");\n              Thread.sleep(1000);\n              c++;\n              if (c >= 30)  {\n                LOG.warn(\"IndexFetcher unable to cleanup unused lucene index files so we must do a full copy instead\");\n                isFullCopyNeeded = true;\n                break;\n              }\n            }\n            if (c > 0)  {\n              LOG.info(\"IndexFetcher slept for \" + (c * 1000) + \"ms for unused lucene index files to be delete-able\");\n            }\n          } finally {\n            writer.decref();\n          }\n          solrCore.getUpdateHandler().getSolrCoreState().closeIndexWriter(solrCore, true);\n        }\n        boolean reloadCore = false;\n        \n        try {\n          LOG.info(\"Starting download to \" + tmpIndexDir + \" fullCopy=\"\n              + isFullCopyNeeded);\n          successfulInstall = false;\n          \n          downloadIndexFiles(isFullCopyNeeded, indexDir, tmpIndexDir, latestGeneration);\n          LOG.info(\"Total time taken for download : \"\n              + ((System.currentTimeMillis() - replicationStartTime) / 1000)\n              + \" secs\");\n          Collection<Map<String,Object>> modifiedConfFiles = getModifiedConfFiles(confFilesToDownload);\n          if (!modifiedConfFiles.isEmpty()) {\n            reloadCore = true;\n            downloadConfFiles(confFilesToDownload, latestGeneration);\n            if (isFullCopyNeeded) {\n              successfulInstall = IndexFetcher.modifyIndexProps(solrCore, tmpIdxDirName);\n              deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (successfulInstall) {\n              if (isFullCopyNeeded) {\n                // let the system know we are changing dir's and the old one\n                // may be closed\n                if (indexDir != null) {\n                  LOG.info(\"removing old index directory \" + indexDir);\n                  solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n                  solrCore.getDirectoryFactory().remove(indexDir);\n                }\n              }\n              \n              LOG.info(\"Configuration files are modified, core will be reloaded\");\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);// write to a file time of replication and\n                                     // conf files.\n            }\n          } else {\n            terminateAndWaitFsyncService();\n            if (isFullCopyNeeded) {\n              successfulInstall = IndexFetcher.modifyIndexProps(solrCore, tmpIdxDirName);\n              deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (successfulInstall) {\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);\n            }\n          }\n        } finally {\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().openIndexWriter(solrCore);\n          }\n        }\n        \n        // we must reload the core after we open the IW back up\n       if (successfulInstall && (reloadCore || forceCoreReload)) {\n          LOG.info(\"Reloading SolrCore {}\", solrCore.getName());\n          reloadCore();\n        }\n\n        if (successfulInstall) {\n          if (isFullCopyNeeded) {\n            // let the system know we are changing dir's and the old one\n            // may be closed\n            if (indexDir != null) {\n              LOG.info(\"removing old index directory \" + indexDir);\n              solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n              solrCore.getDirectoryFactory().remove(indexDir);\n            }\n          }\n          if (isFullCopyNeeded) {\n            solrCore.getUpdateHandler().newIndexWriter(isFullCopyNeeded);\n          }\n          \n          openNewSearcherAndUpdateCommitPoint();\n        }\n        \n        if (!isFullCopyNeeded && !forceReplication && !successfulInstall) {\n          cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, successfulInstall);\n          cleanupDone = true;\n          // we try with a full copy of the index\n          LOG.warn(\n              \"Replication attempt was not successful - trying a full index replication reloadCore={}\",\n              reloadCore);\n          successfulInstall = fetchLatestIndex(true, reloadCore);\n        }\n        \n        replicationStartTime = 0;\n        return successfulInstall;\n      } catch (ReplicationHandlerException e) {\n        LOG.error(\"User aborted Replication\");\n        return false;\n      } catch (SolrException e) {\n        throw e;\n      } catch (InterruptedException e) {\n        throw new InterruptedException(\"Index fetch interrupted\");\n      } catch (Exception e) {\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Index fetch failed : \", e);\n      }\n    } finally {\n      if (!cleanupDone) {\n        cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, successfulInstall);\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * This command downloads all the necessary files from master to install a index commit point. Only changed files are\n   * downloaded. It also downloads the conf files (if they are modified).\n   *\n   * @param core the SolrCore\n   * @param forceReplication force a replication in all cases \n   * @param forceCoreReload force a core reload in all cases\n   * @return true on success, false if slave is already in sync\n   * @throws IOException if an exception occurs\n   */\n   boolean fetchLatestIndex(final SolrCore core, boolean forceReplication, boolean forceCoreReload) throws IOException, InterruptedException {\n    boolean cleanupDone = false;\n    boolean successfulInstall = false;\n    replicationStartTime = System.currentTimeMillis();\n    Directory tmpIndexDir = null;\n    String tmpIndex = null;\n    Directory indexDir = null;\n    String indexDirPath = null;\n    boolean deleteTmpIdxDir = true;\n    \n    if (!core.getSolrCoreState().getLastReplicateIndexSuccess()) {\n      // if the last replication was not a success, we force a full replication\n      // when we are a bit more confident we may want to try a partial replication\n      // if the error is connection related or something, but we have to be careful\n      forceReplication = true;\n    }\n    \n    try {\n      //get the current 'replicateable' index version in the master\n      NamedList response = null;\n      try {\n        response = getLatestVersion();\n      } catch (Exception e) {\n        LOG.error(\"Master at: \" + masterUrl + \" is not available. Index fetch failed. Exception: \" + e.getMessage());\n        return false;\n      }\n      long latestVersion = (Long) response.get(CMD_INDEX_VERSION);\n      long latestGeneration = (Long) response.get(GENERATION);\n\n      // TODO: make sure that getLatestCommit only returns commit points for the main index (i.e. no side-car indexes)\n      IndexCommit commit = core.getDeletionPolicy().getLatestCommit();\n      if (commit == null) {\n        // Presumably the IndexWriter hasn't been opened yet, and hence the deletion policy hasn't been updated with commit points\n        RefCounted<SolrIndexSearcher> searcherRefCounted = null;\n        try {\n          searcherRefCounted = core.getNewestSearcher(false);\n          if (searcherRefCounted == null) {\n            LOG.warn(\"No open searcher found - fetch aborted\");\n            return false;\n          }\n          commit = searcherRefCounted.get().getIndexReader().getIndexCommit();\n        } finally {\n          if (searcherRefCounted != null)\n            searcherRefCounted.decref();\n        }\n      }\n\n\n      if (latestVersion == 0L) {\n        if (forceReplication && commit.getGeneration() != 0) {\n          // since we won't get the files for an empty index,\n          // we just clear ours and commit\n          RefCounted<IndexWriter> iw = core.getUpdateHandler().getSolrCoreState().getIndexWriter(core);\n          try {\n            iw.get().deleteAll();\n          } finally {\n            iw.decref();\n          }\n          SolrQueryRequest req = new LocalSolrQueryRequest(core,\n              new ModifiableSolrParams());\n          core.getUpdateHandler().commit(new CommitUpdateCommand(req, false));\n        }\n        \n        //there is nothing to be replicated\n        successfulInstall = true;\n        return true;\n      }\n      \n      if (!forceReplication && IndexDeletionPolicyWrapper.getCommitTimestamp(commit) == latestVersion) {\n        //master and slave are already in sync just return\n        LOG.info(\"Slave in sync with master.\");\n        successfulInstall = true;\n        return true;\n      }\n      LOG.info(\"Master's generation: \" + latestGeneration);\n      LOG.info(\"Slave's generation: \" + commit.getGeneration());\n      LOG.info(\"Starting replication process\");\n      // get the list of files first\n      fetchFileList(latestGeneration);\n      // this can happen if the commit point is deleted before we fetch the file list.\n      if(filesToDownload.isEmpty()) return false;\n      LOG.info(\"Number of files in latest index in master: \" + filesToDownload.size());\n\n      // Create the sync service\n      fsyncService = Executors.newSingleThreadExecutor(new DefaultSolrThreadFactory(\"fsyncService\"));\n      // use a synchronized list because the list is read by other threads (to show details)\n      filesDownloaded = Collections.synchronizedList(new ArrayList<Map<String, Object>>());\n      // if the generation of master is older than that of the slave , it means they are not compatible to be copied\n      // then a new index directory to be created and all the files need to be copied\n      boolean isFullCopyNeeded = IndexDeletionPolicyWrapper\n          .getCommitTimestamp(commit) >= latestVersion\n          || commit.getGeneration() >= latestGeneration || forceReplication;\n\n      String tmpIdxDirName = \"index.\" + new SimpleDateFormat(SnapShooter.DATE_FMT, Locale.ROOT).format(new Date());\n      tmpIndex = createTempindexDir(core, tmpIdxDirName);\n\n      tmpIndexDir = core.getDirectoryFactory().get(tmpIndex, DirContext.DEFAULT, core.getSolrConfig().indexConfig.lockType);\n      \n      // cindex dir...\n      indexDirPath = core.getIndexDir();\n      indexDir = core.getDirectoryFactory().get(indexDirPath, DirContext.DEFAULT, core.getSolrConfig().indexConfig.lockType);\n\n      try {\n\n        //We will compare all the index files from the master vs the index files on disk to see if there is a mismatch\n        //in the metadata. If there is a mismatch for the same index file then we download the entire index again.\n        if (!isFullCopyNeeded && isIndexStale(indexDir)) {\n          isFullCopyNeeded = true;\n        }\n        \n        if (!isFullCopyNeeded) {\n          // a searcher might be using some flushed but not committed segments\n          // because of soft commits (which open a searcher on IW's data)\n          // so we need to close the existing searcher on the last commit\n          // and wait until we are able to clean up all unused lucene files\n          if (solrCore.getCoreDescriptor().getCoreContainer().isZooKeeperAware()) {\n            solrCore.closeSearcher();\n          }\n\n          // rollback and reopen index writer and wait until all unused files\n          // are successfully deleted\n          solrCore.getUpdateHandler().newIndexWriter(true);\n          RefCounted<IndexWriter> writer = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n          try {\n            IndexWriter indexWriter = writer.get();\n            int c = 0;\n            indexWriter.deleteUnusedFiles();\n            while (hasUnusedFiles(indexDir, commit)) {\n              indexWriter.deleteUnusedFiles();\n              LOG.info(\"Sleeping for 1000ms to wait for unused lucene index files to be delete-able\");\n              Thread.sleep(1000);\n              c++;\n              if (c >= 30)  {\n                LOG.warn(\"IndexFetcher unable to cleanup unused lucene index files so we must do a full copy instead\");\n                isFullCopyNeeded = true;\n                break;\n              }\n            }\n            if (c > 0)  {\n              LOG.info(\"IndexFetcher slept for \" + (c * 1000) + \"ms for unused lucene index files to be delete-able\");\n            }\n          } finally {\n            writer.decref();\n          }\n          solrCore.getUpdateHandler().getSolrCoreState().closeIndexWriter(core, true);\n        }\n        boolean reloadCore = false;\n        \n        try {\n          LOG.info(\"Starting download to \" + tmpIndexDir + \" fullCopy=\"\n              + isFullCopyNeeded);\n          successfulInstall = false;\n          \n          downloadIndexFiles(isFullCopyNeeded, indexDir, tmpIndexDir, latestGeneration);\n          LOG.info(\"Total time taken for download : \"\n              + ((System.currentTimeMillis() - replicationStartTime) / 1000)\n              + \" secs\");\n          Collection<Map<String,Object>> modifiedConfFiles = getModifiedConfFiles(confFilesToDownload);\n          if (!modifiedConfFiles.isEmpty()) {\n            reloadCore = true;\n            downloadConfFiles(confFilesToDownload, latestGeneration);\n            if (isFullCopyNeeded) {\n              successfulInstall = modifyIndexProps(tmpIdxDirName);\n              deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (successfulInstall) {\n              if (isFullCopyNeeded) {\n                // let the system know we are changing dir's and the old one\n                // may be closed\n                if (indexDir != null) {\n                  LOG.info(\"removing old index directory \" + indexDir);\n                  core.getDirectoryFactory().doneWithDirectory(indexDir);\n                  core.getDirectoryFactory().remove(indexDir);\n                }\n              }\n              \n              LOG.info(\"Configuration files are modified, core will be reloaded\");\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);// write to a file time of replication and\n                                     // conf files.\n            }\n          } else {\n            terminateAndWaitFsyncService();\n            if (isFullCopyNeeded) {\n              successfulInstall = modifyIndexProps(tmpIdxDirName);\n              deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (successfulInstall) {\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);\n            }\n          }\n        } finally {\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().openIndexWriter(core);\n          }\n        }\n        \n        // we must reload the core after we open the IW back up\n       if (successfulInstall && (reloadCore || forceCoreReload)) {\n          LOG.info(\"Reloading SolrCore {}\", core.getName());\n          reloadCore();\n        }\n\n        if (successfulInstall) {\n          if (isFullCopyNeeded) {\n            // let the system know we are changing dir's and the old one\n            // may be closed\n            if (indexDir != null) {\n              LOG.info(\"removing old index directory \" + indexDir);\n              core.getDirectoryFactory().doneWithDirectory(indexDir);\n              core.getDirectoryFactory().remove(indexDir);\n            }\n          }\n          if (isFullCopyNeeded) {\n            solrCore.getUpdateHandler().newIndexWriter(isFullCopyNeeded);\n          }\n          \n          openNewSearcherAndUpdateCommitPoint();\n        }\n        \n        if (!isFullCopyNeeded && !forceReplication && !successfulInstall) {\n          cleanup(core, tmpIndexDir, indexDir, deleteTmpIdxDir, successfulInstall);\n          cleanupDone = true;\n          // we try with a full copy of the index\n          LOG.warn(\n              \"Replication attempt was not successful - trying a full index replication reloadCore={}\",\n              reloadCore);\n          successfulInstall = fetchLatestIndex(core, true, reloadCore);\n        }\n        \n        replicationStartTime = 0;\n        return successfulInstall;\n      } catch (ReplicationHandlerException e) {\n        LOG.error(\"User aborted Replication\");\n        return false;\n      } catch (SolrException e) {\n        throw e;\n      } catch (InterruptedException e) {\n        throw new InterruptedException(\"Index fetch interrupted\");\n      } catch (Exception e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Index fetch failed : \", e);\n      }\n    } finally {\n      if (!cleanupDone) {\n        cleanup(core, tmpIndexDir, indexDir, deleteTmpIdxDir, successfulInstall);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":["04ecf884544ff74add5faa452748f160c4af904b","04ecf884544ff74add5faa452748f160c4af904b","b39b1b02e442aaf736cc87417e93552cbd8ef1da","b39b1b02e442aaf736cc87417e93552cbd8ef1da"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"6c757ac42dd1f3f893db5c4d89c61cbe1a9fab6c","date":1428091986,"type":5,"author":"Robert Muir","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/handler/IndexFetcher#fetchLatestIndex(boolean,boolean).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/IndexFetcher#fetchLatestIndex(SolrCore,boolean,boolean).mjava","sourceNew":"  /**\n   * This command downloads all the necessary files from master to install a index commit point. Only changed files are\n   * downloaded. It also downloads the conf files (if they are modified).\n   *\n   * @param forceReplication force a replication in all cases \n   * @param forceCoreReload force a core reload in all cases\n   * @return true on success, false if slave is already in sync\n   * @throws IOException if an exception occurs\n   */\n  boolean fetchLatestIndex(boolean forceReplication, boolean forceCoreReload) throws IOException, InterruptedException {\n    \n    boolean cleanupDone = false;\n    boolean successfulInstall = false;\n    replicationStartTime = System.currentTimeMillis();\n    Directory tmpIndexDir = null;\n    String tmpIndex;\n    Directory indexDir = null;\n    String indexDirPath;\n    boolean deleteTmpIdxDir = true;\n    \n    if (!solrCore.getSolrCoreState().getLastReplicateIndexSuccess()) {\n      // if the last replication was not a success, we force a full replication\n      // when we are a bit more confident we may want to try a partial replication\n      // if the error is connection related or something, but we have to be careful\n      forceReplication = true;\n    }\n    \n    try {\n      //get the current 'replicateable' index version in the master\n      NamedList response;\n      try {\n        response = getLatestVersion();\n      } catch (Exception e) {\n        LOG.error(\"Master at: \" + masterUrl + \" is not available. Index fetch failed. Exception: \" + e.getMessage());\n        return false;\n      }\n      long latestVersion = (Long) response.get(CMD_INDEX_VERSION);\n      long latestGeneration = (Long) response.get(GENERATION);\n\n      // TODO: make sure that getLatestCommit only returns commit points for the main index (i.e. no side-car indexes)\n      IndexCommit commit = solrCore.getDeletionPolicy().getLatestCommit();\n      if (commit == null) {\n        // Presumably the IndexWriter hasn't been opened yet, and hence the deletion policy hasn't been updated with commit points\n        RefCounted<SolrIndexSearcher> searcherRefCounted = null;\n        try {\n          searcherRefCounted = solrCore.getNewestSearcher(false);\n          if (searcherRefCounted == null) {\n            LOG.warn(\"No open searcher found - fetch aborted\");\n            return false;\n          }\n          commit = searcherRefCounted.get().getIndexReader().getIndexCommit();\n        } finally {\n          if (searcherRefCounted != null)\n            searcherRefCounted.decref();\n        }\n      }\n\n\n      if (latestVersion == 0L) {\n        if (forceReplication && commit.getGeneration() != 0) {\n          // since we won't get the files for an empty index,\n          // we just clear ours and commit\n          RefCounted<IndexWriter> iw = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(solrCore);\n          try {\n            iw.get().deleteAll();\n          } finally {\n            iw.decref();\n          }\n          SolrQueryRequest req = new LocalSolrQueryRequest(solrCore, new ModifiableSolrParams());\n          solrCore.getUpdateHandler().commit(new CommitUpdateCommand(req, false));\n        }\n        \n        //there is nothing to be replicated\n        successfulInstall = true;\n        return true;\n      }\n      \n      if (!forceReplication && IndexDeletionPolicyWrapper.getCommitTimestamp(commit) == latestVersion) {\n        //master and slave are already in sync just return\n        LOG.info(\"Slave in sync with master.\");\n        successfulInstall = true;\n        return true;\n      }\n      LOG.info(\"Master's generation: \" + latestGeneration);\n      LOG.info(\"Slave's generation: \" + commit.getGeneration());\n      LOG.info(\"Starting replication process\");\n      // get the list of files first\n      fetchFileList(latestGeneration);\n      // this can happen if the commit point is deleted before we fetch the file list.\n      if (filesToDownload.isEmpty()) {\n        return false;\n      }\n      LOG.info(\"Number of files in latest index in master: \" + filesToDownload.size());\n\n      // Create the sync service\n      fsyncService = Executors.newSingleThreadExecutor(new DefaultSolrThreadFactory(\"fsyncService\"));\n      // use a synchronized list because the list is read by other threads (to show details)\n      filesDownloaded = Collections.synchronizedList(new ArrayList<Map<String, Object>>());\n      // if the generation of master is older than that of the slave , it means they are not compatible to be copied\n      // then a new index directory to be created and all the files need to be copied\n      boolean isFullCopyNeeded = IndexDeletionPolicyWrapper\n          .getCommitTimestamp(commit) >= latestVersion\n          || commit.getGeneration() >= latestGeneration || forceReplication;\n\n      String tmpIdxDirName = \"index.\" + new SimpleDateFormat(SnapShooter.DATE_FMT, Locale.ROOT).format(new Date());\n      tmpIndex = Paths.get(solrCore.getDataDir(), tmpIdxDirName).toString();\n\n      tmpIndexDir = solrCore.getDirectoryFactory().get(tmpIndex, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n      \n      // cindex dir...\n      indexDirPath = solrCore.getIndexDir();\n      indexDir = solrCore.getDirectoryFactory().get(indexDirPath, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      try {\n\n        //We will compare all the index files from the master vs the index files on disk to see if there is a mismatch\n        //in the metadata. If there is a mismatch for the same index file then we download the entire index again.\n        if (!isFullCopyNeeded && isIndexStale(indexDir)) {\n          isFullCopyNeeded = true;\n        }\n        \n        if (!isFullCopyNeeded) {\n          // a searcher might be using some flushed but not committed segments\n          // because of soft commits (which open a searcher on IW's data)\n          // so we need to close the existing searcher on the last commit\n          // and wait until we are able to clean up all unused lucene files\n          if (solrCore.getCoreDescriptor().getCoreContainer().isZooKeeperAware()) {\n            solrCore.closeSearcher();\n          }\n\n          // rollback and reopen index writer and wait until all unused files\n          // are successfully deleted\n          solrCore.getUpdateHandler().newIndexWriter(true);\n          RefCounted<IndexWriter> writer = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n          try {\n            IndexWriter indexWriter = writer.get();\n            int c = 0;\n            indexWriter.deleteUnusedFiles();\n            while (hasUnusedFiles(indexDir, commit)) {\n              indexWriter.deleteUnusedFiles();\n              LOG.info(\"Sleeping for 1000ms to wait for unused lucene index files to be delete-able\");\n              Thread.sleep(1000);\n              c++;\n              if (c >= 30)  {\n                LOG.warn(\"IndexFetcher unable to cleanup unused lucene index files so we must do a full copy instead\");\n                isFullCopyNeeded = true;\n                break;\n              }\n            }\n            if (c > 0)  {\n              LOG.info(\"IndexFetcher slept for \" + (c * 1000) + \"ms for unused lucene index files to be delete-able\");\n            }\n          } finally {\n            writer.decref();\n          }\n          solrCore.getUpdateHandler().getSolrCoreState().closeIndexWriter(solrCore, true);\n        }\n        boolean reloadCore = false;\n        \n        try {\n          LOG.info(\"Starting download to \" + tmpIndexDir + \" fullCopy=\"\n              + isFullCopyNeeded);\n          successfulInstall = false;\n          \n          downloadIndexFiles(isFullCopyNeeded, indexDir, tmpIndexDir, latestGeneration);\n          LOG.info(\"Total time taken for download : \"\n              + ((System.currentTimeMillis() - replicationStartTime) / 1000)\n              + \" secs\");\n          Collection<Map<String,Object>> modifiedConfFiles = getModifiedConfFiles(confFilesToDownload);\n          if (!modifiedConfFiles.isEmpty()) {\n            reloadCore = true;\n            downloadConfFiles(confFilesToDownload, latestGeneration);\n            if (isFullCopyNeeded) {\n              successfulInstall = IndexFetcher.modifyIndexProps(solrCore, tmpIdxDirName);\n              deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (successfulInstall) {\n              if (isFullCopyNeeded) {\n                // let the system know we are changing dir's and the old one\n                // may be closed\n                if (indexDir != null) {\n                  LOG.info(\"removing old index directory \" + indexDir);\n                  solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n                  solrCore.getDirectoryFactory().remove(indexDir);\n                }\n              }\n              \n              LOG.info(\"Configuration files are modified, core will be reloaded\");\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);// write to a file time of replication and\n                                     // conf files.\n            }\n          } else {\n            terminateAndWaitFsyncService();\n            if (isFullCopyNeeded) {\n              successfulInstall = IndexFetcher.modifyIndexProps(solrCore, tmpIdxDirName);\n              deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (successfulInstall) {\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);\n            }\n          }\n        } finally {\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().openIndexWriter(solrCore);\n          }\n        }\n        \n        // we must reload the core after we open the IW back up\n       if (successfulInstall && (reloadCore || forceCoreReload)) {\n          LOG.info(\"Reloading SolrCore {}\", solrCore.getName());\n          reloadCore();\n        }\n\n        if (successfulInstall) {\n          if (isFullCopyNeeded) {\n            // let the system know we are changing dir's and the old one\n            // may be closed\n            if (indexDir != null) {\n              LOG.info(\"removing old index directory \" + indexDir);\n              solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n              solrCore.getDirectoryFactory().remove(indexDir);\n            }\n          }\n          if (isFullCopyNeeded) {\n            solrCore.getUpdateHandler().newIndexWriter(isFullCopyNeeded);\n          }\n          \n          openNewSearcherAndUpdateCommitPoint();\n        }\n        \n        if (!isFullCopyNeeded && !forceReplication && !successfulInstall) {\n          cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, successfulInstall);\n          cleanupDone = true;\n          // we try with a full copy of the index\n          LOG.warn(\n              \"Replication attempt was not successful - trying a full index replication reloadCore={}\",\n              reloadCore);\n          successfulInstall = fetchLatestIndex(true, reloadCore);\n        }\n        \n        replicationStartTime = 0;\n        return successfulInstall;\n      } catch (ReplicationHandlerException e) {\n        LOG.error(\"User aborted Replication\");\n        return false;\n      } catch (SolrException e) {\n        throw e;\n      } catch (InterruptedException e) {\n        throw new InterruptedException(\"Index fetch interrupted\");\n      } catch (Exception e) {\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Index fetch failed : \", e);\n      }\n    } finally {\n      if (!cleanupDone) {\n        cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, successfulInstall);\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * This command downloads all the necessary files from master to install a index commit point. Only changed files are\n   * downloaded. It also downloads the conf files (if they are modified).\n   *\n   * @param core the SolrCore\n   * @param forceReplication force a replication in all cases \n   * @param forceCoreReload force a core reload in all cases\n   * @return true on success, false if slave is already in sync\n   * @throws IOException if an exception occurs\n   */\n   boolean fetchLatestIndex(final SolrCore core, boolean forceReplication, boolean forceCoreReload) throws IOException, InterruptedException {\n    boolean cleanupDone = false;\n    boolean successfulInstall = false;\n    replicationStartTime = System.currentTimeMillis();\n    Directory tmpIndexDir = null;\n    String tmpIndex = null;\n    Directory indexDir = null;\n    String indexDirPath = null;\n    boolean deleteTmpIdxDir = true;\n    \n    if (!core.getSolrCoreState().getLastReplicateIndexSuccess()) {\n      // if the last replication was not a success, we force a full replication\n      // when we are a bit more confident we may want to try a partial replication\n      // if the error is connection related or something, but we have to be careful\n      forceReplication = true;\n    }\n    \n    try {\n      //get the current 'replicateable' index version in the master\n      NamedList response = null;\n      try {\n        response = getLatestVersion();\n      } catch (Exception e) {\n        LOG.error(\"Master at: \" + masterUrl + \" is not available. Index fetch failed. Exception: \" + e.getMessage());\n        return false;\n      }\n      long latestVersion = (Long) response.get(CMD_INDEX_VERSION);\n      long latestGeneration = (Long) response.get(GENERATION);\n\n      // TODO: make sure that getLatestCommit only returns commit points for the main index (i.e. no side-car indexes)\n      IndexCommit commit = core.getDeletionPolicy().getLatestCommit();\n      if (commit == null) {\n        // Presumably the IndexWriter hasn't been opened yet, and hence the deletion policy hasn't been updated with commit points\n        RefCounted<SolrIndexSearcher> searcherRefCounted = null;\n        try {\n          searcherRefCounted = core.getNewestSearcher(false);\n          if (searcherRefCounted == null) {\n            LOG.warn(\"No open searcher found - fetch aborted\");\n            return false;\n          }\n          commit = searcherRefCounted.get().getIndexReader().getIndexCommit();\n        } finally {\n          if (searcherRefCounted != null)\n            searcherRefCounted.decref();\n        }\n      }\n\n\n      if (latestVersion == 0L) {\n        if (forceReplication && commit.getGeneration() != 0) {\n          // since we won't get the files for an empty index,\n          // we just clear ours and commit\n          RefCounted<IndexWriter> iw = core.getUpdateHandler().getSolrCoreState().getIndexWriter(core);\n          try {\n            iw.get().deleteAll();\n          } finally {\n            iw.decref();\n          }\n          SolrQueryRequest req = new LocalSolrQueryRequest(core,\n              new ModifiableSolrParams());\n          core.getUpdateHandler().commit(new CommitUpdateCommand(req, false));\n        }\n        \n        //there is nothing to be replicated\n        successfulInstall = true;\n        return true;\n      }\n      \n      if (!forceReplication && IndexDeletionPolicyWrapper.getCommitTimestamp(commit) == latestVersion) {\n        //master and slave are already in sync just return\n        LOG.info(\"Slave in sync with master.\");\n        successfulInstall = true;\n        return true;\n      }\n      LOG.info(\"Master's generation: \" + latestGeneration);\n      LOG.info(\"Slave's generation: \" + commit.getGeneration());\n      LOG.info(\"Starting replication process\");\n      // get the list of files first\n      fetchFileList(latestGeneration);\n      // this can happen if the commit point is deleted before we fetch the file list.\n      if(filesToDownload.isEmpty()) return false;\n      LOG.info(\"Number of files in latest index in master: \" + filesToDownload.size());\n\n      // Create the sync service\n      fsyncService = Executors.newSingleThreadExecutor(new DefaultSolrThreadFactory(\"fsyncService\"));\n      // use a synchronized list because the list is read by other threads (to show details)\n      filesDownloaded = Collections.synchronizedList(new ArrayList<Map<String, Object>>());\n      // if the generation of master is older than that of the slave , it means they are not compatible to be copied\n      // then a new index directory to be created and all the files need to be copied\n      boolean isFullCopyNeeded = IndexDeletionPolicyWrapper\n          .getCommitTimestamp(commit) >= latestVersion\n          || commit.getGeneration() >= latestGeneration || forceReplication;\n\n      String tmpIdxDirName = \"index.\" + new SimpleDateFormat(SnapShooter.DATE_FMT, Locale.ROOT).format(new Date());\n      tmpIndex = createTempindexDir(core, tmpIdxDirName);\n\n      tmpIndexDir = core.getDirectoryFactory().get(tmpIndex, DirContext.DEFAULT, core.getSolrConfig().indexConfig.lockType);\n      \n      // cindex dir...\n      indexDirPath = core.getIndexDir();\n      indexDir = core.getDirectoryFactory().get(indexDirPath, DirContext.DEFAULT, core.getSolrConfig().indexConfig.lockType);\n\n      try {\n\n        //We will compare all the index files from the master vs the index files on disk to see if there is a mismatch\n        //in the metadata. If there is a mismatch for the same index file then we download the entire index again.\n        if (!isFullCopyNeeded && isIndexStale(indexDir)) {\n          isFullCopyNeeded = true;\n        }\n        \n        if (!isFullCopyNeeded) {\n          // a searcher might be using some flushed but not committed segments\n          // because of soft commits (which open a searcher on IW's data)\n          // so we need to close the existing searcher on the last commit\n          // and wait until we are able to clean up all unused lucene files\n          if (solrCore.getCoreDescriptor().getCoreContainer().isZooKeeperAware()) {\n            solrCore.closeSearcher();\n          }\n\n          // rollback and reopen index writer and wait until all unused files\n          // are successfully deleted\n          solrCore.getUpdateHandler().newIndexWriter(true);\n          RefCounted<IndexWriter> writer = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n          try {\n            IndexWriter indexWriter = writer.get();\n            int c = 0;\n            indexWriter.deleteUnusedFiles();\n            while (hasUnusedFiles(indexDir, commit)) {\n              indexWriter.deleteUnusedFiles();\n              LOG.info(\"Sleeping for 1000ms to wait for unused lucene index files to be delete-able\");\n              Thread.sleep(1000);\n              c++;\n              if (c >= 30)  {\n                LOG.warn(\"IndexFetcher unable to cleanup unused lucene index files so we must do a full copy instead\");\n                isFullCopyNeeded = true;\n                break;\n              }\n            }\n            if (c > 0)  {\n              LOG.info(\"IndexFetcher slept for \" + (c * 1000) + \"ms for unused lucene index files to be delete-able\");\n            }\n          } finally {\n            writer.decref();\n          }\n          solrCore.getUpdateHandler().getSolrCoreState().closeIndexWriter(core, true);\n        }\n        boolean reloadCore = false;\n        \n        try {\n          LOG.info(\"Starting download to \" + tmpIndexDir + \" fullCopy=\"\n              + isFullCopyNeeded);\n          successfulInstall = false;\n          \n          downloadIndexFiles(isFullCopyNeeded, indexDir, tmpIndexDir, latestGeneration);\n          LOG.info(\"Total time taken for download : \"\n              + ((System.currentTimeMillis() - replicationStartTime) / 1000)\n              + \" secs\");\n          Collection<Map<String,Object>> modifiedConfFiles = getModifiedConfFiles(confFilesToDownload);\n          if (!modifiedConfFiles.isEmpty()) {\n            reloadCore = true;\n            downloadConfFiles(confFilesToDownload, latestGeneration);\n            if (isFullCopyNeeded) {\n              successfulInstall = modifyIndexProps(tmpIdxDirName);\n              deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (successfulInstall) {\n              if (isFullCopyNeeded) {\n                // let the system know we are changing dir's and the old one\n                // may be closed\n                if (indexDir != null) {\n                  LOG.info(\"removing old index directory \" + indexDir);\n                  core.getDirectoryFactory().doneWithDirectory(indexDir);\n                  core.getDirectoryFactory().remove(indexDir);\n                }\n              }\n              \n              LOG.info(\"Configuration files are modified, core will be reloaded\");\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);// write to a file time of replication and\n                                     // conf files.\n            }\n          } else {\n            terminateAndWaitFsyncService();\n            if (isFullCopyNeeded) {\n              successfulInstall = modifyIndexProps(tmpIdxDirName);\n              deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (successfulInstall) {\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);\n            }\n          }\n        } finally {\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().openIndexWriter(core);\n          }\n        }\n        \n        // we must reload the core after we open the IW back up\n       if (successfulInstall && (reloadCore || forceCoreReload)) {\n          LOG.info(\"Reloading SolrCore {}\", core.getName());\n          reloadCore();\n        }\n\n        if (successfulInstall) {\n          if (isFullCopyNeeded) {\n            // let the system know we are changing dir's and the old one\n            // may be closed\n            if (indexDir != null) {\n              LOG.info(\"removing old index directory \" + indexDir);\n              core.getDirectoryFactory().doneWithDirectory(indexDir);\n              core.getDirectoryFactory().remove(indexDir);\n            }\n          }\n          if (isFullCopyNeeded) {\n            solrCore.getUpdateHandler().newIndexWriter(isFullCopyNeeded);\n          }\n          \n          openNewSearcherAndUpdateCommitPoint();\n        }\n        \n        if (!isFullCopyNeeded && !forceReplication && !successfulInstall) {\n          cleanup(core, tmpIndexDir, indexDir, deleteTmpIdxDir, successfulInstall);\n          cleanupDone = true;\n          // we try with a full copy of the index\n          LOG.warn(\n              \"Replication attempt was not successful - trying a full index replication reloadCore={}\",\n              reloadCore);\n          successfulInstall = fetchLatestIndex(core, true, reloadCore);\n        }\n        \n        replicationStartTime = 0;\n        return successfulInstall;\n      } catch (ReplicationHandlerException e) {\n        LOG.error(\"User aborted Replication\");\n        return false;\n      } catch (SolrException e) {\n        throw e;\n      } catch (InterruptedException e) {\n        throw new InterruptedException(\"Index fetch interrupted\");\n      } catch (Exception e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Index fetch failed : \", e);\n      }\n    } finally {\n      if (!cleanupDone) {\n        cleanup(core, tmpIndexDir, indexDir, deleteTmpIdxDir, successfulInstall);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","6c94d2661bc1c14426980ec7882e951fdcff08d0"],"6c94d2661bc1c14426980ec7882e951fdcff08d0":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"4137ef43bfa25c1b6749fa22fa4ee05f36779eea":["6c94d2661bc1c14426980ec7882e951fdcff08d0"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"6c757ac42dd1f3f893db5c4d89c61cbe1a9fab6c":["fab172655716b96f7e42376116235017a922de3a","7b13106276bb5ea342253dbf6aae7b675adb38d3"],"fab172655716b96f7e42376116235017a922de3a":["a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","4137ef43bfa25c1b6749fa22fa4ee05f36779eea"],"7b13106276bb5ea342253dbf6aae7b675adb38d3":["4137ef43bfa25c1b6749fa22fa4ee05f36779eea"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["7b13106276bb5ea342253dbf6aae7b675adb38d3"]},"commit2Childs":{"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae":["fab172655716b96f7e42376116235017a922de3a"],"6c94d2661bc1c14426980ec7882e951fdcff08d0":["a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","4137ef43bfa25c1b6749fa22fa4ee05f36779eea"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","6c94d2661bc1c14426980ec7882e951fdcff08d0"],"4137ef43bfa25c1b6749fa22fa4ee05f36779eea":["fab172655716b96f7e42376116235017a922de3a","7b13106276bb5ea342253dbf6aae7b675adb38d3"],"6c757ac42dd1f3f893db5c4d89c61cbe1a9fab6c":[],"fab172655716b96f7e42376116235017a922de3a":["6c757ac42dd1f3f893db5c4d89c61cbe1a9fab6c"],"7b13106276bb5ea342253dbf6aae7b675adb38d3":["6c757ac42dd1f3f893db5c4d89c61cbe1a9fab6c","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["6c757ac42dd1f3f893db5c4d89c61cbe1a9fab6c","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}