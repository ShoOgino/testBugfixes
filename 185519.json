{"path":"lucene/core/src/test/org/apache/lucene/index/TestNorms#testCustomEncoder().mjava","commits":[{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":1,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestNorms#testCustomEncoder().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestNorms#testCustomEncoder().mjava","sourceNew":"  // LUCENE-1260\n  public void testCustomEncoder() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig config = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random));\n    config.setSimilarity(new CustomNormEncodingSimilarity());\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, config);\n    Document doc = new Document();\n    Field foo = newField(\"foo\", \"\", TextField.TYPE_UNSTORED);\n    Field bar = newField(\"bar\", \"\", TextField.TYPE_UNSTORED);\n    doc.add(foo);\n    doc.add(bar);\n    \n    for (int i = 0; i < 100; i++) {\n      bar.setValue(\"singleton\");\n      writer.addDocument(doc);\n    }\n    \n    IndexReader reader = writer.getReader();\n    writer.close();\n    \n    byte fooNorms[] = (byte[]) MultiDocValues.getNormDocValues(reader, \"foo\").getSource().getArray();\n    for (int i = 0; i < reader.maxDoc(); i++)\n      assertEquals(0, fooNorms[i]);\n    \n    byte barNorms[] = (byte[]) MultiDocValues.getNormDocValues(reader, \"bar\").getSource().getArray();\n    for (int i = 0; i < reader.maxDoc(); i++)\n      assertEquals(1, barNorms[i]);\n    \n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-1260\n  public void testCustomEncoder() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig config = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random));\n    config.setSimilarity(new CustomNormEncodingSimilarity());\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, config);\n    Document doc = new Document();\n    Field foo = newField(\"foo\", \"\", TextField.TYPE_UNSTORED);\n    Field bar = newField(\"bar\", \"\", TextField.TYPE_UNSTORED);\n    doc.add(foo);\n    doc.add(bar);\n    \n    for (int i = 0; i < 100; i++) {\n      bar.setValue(\"singleton\");\n      writer.addDocument(doc);\n    }\n    \n    IndexReader reader = writer.getReader();\n    writer.close();\n    \n    byte fooNorms[] = (byte[]) MultiDocValues.getNormDocValues(reader, \"foo\").getSource().getArray();\n    for (int i = 0; i < reader.maxDoc(); i++)\n      assertEquals(0, fooNorms[i]);\n    \n    byte barNorms[] = (byte[]) MultiDocValues.getNormDocValues(reader, \"bar\").getSource().getArray();\n    for (int i = 0; i < reader.maxDoc(); i++)\n      assertEquals(1, barNorms[i]);\n    \n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a78a90fc9701e511308346ea29f4f5e548bb39fe","date":1329489995,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestNorms#testCustomEncoder().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestNorms#testCustomEncoder().mjava","sourceNew":"  // LUCENE-1260\n  public void testCustomEncoder() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig config = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random));\n    config.setSimilarity(new CustomNormEncodingSimilarity());\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, config);\n    Document doc = new Document();\n    Field foo = newField(\"foo\", \"\", TextField.TYPE_UNSTORED);\n    Field bar = newField(\"bar\", \"\", TextField.TYPE_UNSTORED);\n    doc.add(foo);\n    doc.add(bar);\n    \n    for (int i = 0; i < 100; i++) {\n      bar.setStringValue(\"singleton\");\n      writer.addDocument(doc);\n    }\n    \n    IndexReader reader = writer.getReader();\n    writer.close();\n    \n    byte fooNorms[] = (byte[]) MultiDocValues.getNormDocValues(reader, \"foo\").getSource().getArray();\n    for (int i = 0; i < reader.maxDoc(); i++)\n      assertEquals(0, fooNorms[i]);\n    \n    byte barNorms[] = (byte[]) MultiDocValues.getNormDocValues(reader, \"bar\").getSource().getArray();\n    for (int i = 0; i < reader.maxDoc(); i++)\n      assertEquals(1, barNorms[i]);\n    \n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-1260\n  public void testCustomEncoder() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig config = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random));\n    config.setSimilarity(new CustomNormEncodingSimilarity());\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, config);\n    Document doc = new Document();\n    Field foo = newField(\"foo\", \"\", TextField.TYPE_UNSTORED);\n    Field bar = newField(\"bar\", \"\", TextField.TYPE_UNSTORED);\n    doc.add(foo);\n    doc.add(bar);\n    \n    for (int i = 0; i < 100; i++) {\n      bar.setValue(\"singleton\");\n      writer.addDocument(doc);\n    }\n    \n    IndexReader reader = writer.getReader();\n    writer.close();\n    \n    byte fooNorms[] = (byte[]) MultiDocValues.getNormDocValues(reader, \"foo\").getSource().getArray();\n    for (int i = 0; i < reader.maxDoc(); i++)\n      assertEquals(0, fooNorms[i]);\n    \n    byte barNorms[] = (byte[]) MultiDocValues.getNormDocValues(reader, \"bar\").getSource().getArray();\n    for (int i = 0; i < reader.maxDoc(); i++)\n      assertEquals(1, barNorms[i]);\n    \n    reader.close();\n    dir.close();\n  }\n\n","bugFix":["fb065b657ee556326e3666d83aae3150249aeaa3"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"629c38c4ae4e303d0617e05fbfe508140b32f0a3","date":1334500904,"type":3,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestNorms#testCustomEncoder().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestNorms#testCustomEncoder().mjava","sourceNew":"  // LUCENE-1260\n  public void testCustomEncoder() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig config = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n    config.setSimilarity(new CustomNormEncodingSimilarity());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, config);\n    Document doc = new Document();\n    Field foo = newField(\"foo\", \"\", TextField.TYPE_UNSTORED);\n    Field bar = newField(\"bar\", \"\", TextField.TYPE_UNSTORED);\n    doc.add(foo);\n    doc.add(bar);\n    \n    for (int i = 0; i < 100; i++) {\n      bar.setStringValue(\"singleton\");\n      writer.addDocument(doc);\n    }\n    \n    IndexReader reader = writer.getReader();\n    writer.close();\n    \n    byte fooNorms[] = (byte[]) MultiDocValues.getNormDocValues(reader, \"foo\").getSource().getArray();\n    for (int i = 0; i < reader.maxDoc(); i++)\n      assertEquals(0, fooNorms[i]);\n    \n    byte barNorms[] = (byte[]) MultiDocValues.getNormDocValues(reader, \"bar\").getSource().getArray();\n    for (int i = 0; i < reader.maxDoc(); i++)\n      assertEquals(1, barNorms[i]);\n    \n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-1260\n  public void testCustomEncoder() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig config = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random));\n    config.setSimilarity(new CustomNormEncodingSimilarity());\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir, config);\n    Document doc = new Document();\n    Field foo = newField(\"foo\", \"\", TextField.TYPE_UNSTORED);\n    Field bar = newField(\"bar\", \"\", TextField.TYPE_UNSTORED);\n    doc.add(foo);\n    doc.add(bar);\n    \n    for (int i = 0; i < 100; i++) {\n      bar.setStringValue(\"singleton\");\n      writer.addDocument(doc);\n    }\n    \n    IndexReader reader = writer.getReader();\n    writer.close();\n    \n    byte fooNorms[] = (byte[]) MultiDocValues.getNormDocValues(reader, \"foo\").getSource().getArray();\n    for (int i = 0; i < reader.maxDoc(); i++)\n      assertEquals(0, fooNorms[i]);\n    \n    byte barNorms[] = (byte[]) MultiDocValues.getNormDocValues(reader, \"bar\").getSource().getArray();\n    for (int i = 0; i < reader.maxDoc(); i++)\n      assertEquals(1, barNorms[i]);\n    \n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"04f07771a2a7dd3a395700665ed839c3dae2def2","date":1339350139,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestNorms#testCustomEncoder().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestNorms#testCustomEncoder().mjava","sourceNew":"  // LUCENE-1260\n  public void testCustomEncoder() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig config = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n    config.setSimilarity(new CustomNormEncodingSimilarity());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, config);\n    Document doc = new Document();\n    Field foo = newTextField(\"foo\", \"\", Field.Store.NO);\n    Field bar = newTextField(\"bar\", \"\", Field.Store.NO);\n    doc.add(foo);\n    doc.add(bar);\n    \n    for (int i = 0; i < 100; i++) {\n      bar.setStringValue(\"singleton\");\n      writer.addDocument(doc);\n    }\n    \n    IndexReader reader = writer.getReader();\n    writer.close();\n    \n    byte fooNorms[] = (byte[]) MultiDocValues.getNormDocValues(reader, \"foo\").getSource().getArray();\n    for (int i = 0; i < reader.maxDoc(); i++)\n      assertEquals(0, fooNorms[i]);\n    \n    byte barNorms[] = (byte[]) MultiDocValues.getNormDocValues(reader, \"bar\").getSource().getArray();\n    for (int i = 0; i < reader.maxDoc(); i++)\n      assertEquals(1, barNorms[i]);\n    \n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-1260\n  public void testCustomEncoder() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig config = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n    config.setSimilarity(new CustomNormEncodingSimilarity());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, config);\n    Document doc = new Document();\n    Field foo = newField(\"foo\", \"\", TextField.TYPE_UNSTORED);\n    Field bar = newField(\"bar\", \"\", TextField.TYPE_UNSTORED);\n    doc.add(foo);\n    doc.add(bar);\n    \n    for (int i = 0; i < 100; i++) {\n      bar.setStringValue(\"singleton\");\n      writer.addDocument(doc);\n    }\n    \n    IndexReader reader = writer.getReader();\n    writer.close();\n    \n    byte fooNorms[] = (byte[]) MultiDocValues.getNormDocValues(reader, \"foo\").getSource().getArray();\n    for (int i = 0; i < reader.maxDoc(); i++)\n      assertEquals(0, fooNorms[i]);\n    \n    byte barNorms[] = (byte[]) MultiDocValues.getNormDocValues(reader, \"bar\").getSource().getArray();\n    for (int i = 0; i < reader.maxDoc(); i++)\n      assertEquals(1, barNorms[i]);\n    \n    reader.close();\n    dir.close();\n  }\n\n","bugFix":["1509f151d7692d84fae414b2b799ac06ba60fcb4"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"ad7de846867bd14c63f9dd19df082f72c5ea9c54","date":1355517454,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestNorms#testCustomEncoder().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestNorms#testCustomEncoder().mjava","sourceNew":"  // LUCENE-1260\n  public void testCustomEncoder() throws Exception {\n    // nocommit remove:\n    Assume.assumeTrue(_TestUtil.canUseSimpleNorms());\n    Directory dir = newDirectory();\n    IndexWriterConfig config = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n    config.setSimilarity(new CustomNormEncodingSimilarity());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, config);\n    Document doc = new Document();\n    Field foo = newTextField(\"foo\", \"\", Field.Store.NO);\n    Field bar = newTextField(\"bar\", \"\", Field.Store.NO);\n    doc.add(foo);\n    doc.add(bar);\n    \n    for (int i = 0; i < 100; i++) {\n      bar.setStringValue(\"singleton\");\n      writer.addDocument(doc);\n    }\n    \n    IndexReader reader = writer.getReader();\n    writer.close();\n    \n    NumericDocValues fooNorms = MultiSimpleDocValues.simpleNormValues(reader, \"foo\");\n    for (int i = 0; i < reader.maxDoc(); i++) {\n      assertEquals(0, fooNorms.get(i));\n    }\n    \n    NumericDocValues barNorms = MultiSimpleDocValues.simpleNormValues(reader, \"bar\");\n    for (int i = 0; i < reader.maxDoc(); i++) {\n      assertEquals(1, barNorms.get(i));\n    }\n    \n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-1260\n  public void testCustomEncoder() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig config = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n    config.setSimilarity(new CustomNormEncodingSimilarity());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, config);\n    Document doc = new Document();\n    Field foo = newTextField(\"foo\", \"\", Field.Store.NO);\n    Field bar = newTextField(\"bar\", \"\", Field.Store.NO);\n    doc.add(foo);\n    doc.add(bar);\n    \n    for (int i = 0; i < 100; i++) {\n      bar.setStringValue(\"singleton\");\n      writer.addDocument(doc);\n    }\n    \n    IndexReader reader = writer.getReader();\n    writer.close();\n    \n    byte fooNorms[] = (byte[]) MultiDocValues.getNormDocValues(reader, \"foo\").getSource().getArray();\n    for (int i = 0; i < reader.maxDoc(); i++)\n      assertEquals(0, fooNorms[i]);\n    \n    byte barNorms[] = (byte[]) MultiDocValues.getNormDocValues(reader, \"bar\").getSource().getArray();\n    for (int i = 0; i < reader.maxDoc(); i++)\n      assertEquals(1, barNorms[i]);\n    \n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"0837ab0472feecb3a54260729d845f839e1cbd72","date":1358283639,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestNorms#testCustomEncoder().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestNorms#testCustomEncoder().mjava","sourceNew":"  // LUCENE-1260\n  public void testCustomEncoder() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig config = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n    config.setSimilarity(new CustomNormEncodingSimilarity());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, config);\n    Document doc = new Document();\n    Field foo = newTextField(\"foo\", \"\", Field.Store.NO);\n    Field bar = newTextField(\"bar\", \"\", Field.Store.NO);\n    doc.add(foo);\n    doc.add(bar);\n    \n    for (int i = 0; i < 100; i++) {\n      bar.setStringValue(\"singleton\");\n      writer.addDocument(doc);\n    }\n    \n    IndexReader reader = writer.getReader();\n    writer.close();\n    \n    NumericDocValues fooNorms = MultiSimpleDocValues.simpleNormValues(reader, \"foo\");\n    for (int i = 0; i < reader.maxDoc(); i++) {\n      assertEquals(0, fooNorms.get(i));\n    }\n    \n    NumericDocValues barNorms = MultiSimpleDocValues.simpleNormValues(reader, \"bar\");\n    for (int i = 0; i < reader.maxDoc(); i++) {\n      assertEquals(1, barNorms.get(i));\n    }\n    \n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-1260\n  public void testCustomEncoder() throws Exception {\n    // nocommit remove:\n    Assume.assumeTrue(_TestUtil.canUseSimpleNorms());\n    Directory dir = newDirectory();\n    IndexWriterConfig config = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n    config.setSimilarity(new CustomNormEncodingSimilarity());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, config);\n    Document doc = new Document();\n    Field foo = newTextField(\"foo\", \"\", Field.Store.NO);\n    Field bar = newTextField(\"bar\", \"\", Field.Store.NO);\n    doc.add(foo);\n    doc.add(bar);\n    \n    for (int i = 0; i < 100; i++) {\n      bar.setStringValue(\"singleton\");\n      writer.addDocument(doc);\n    }\n    \n    IndexReader reader = writer.getReader();\n    writer.close();\n    \n    NumericDocValues fooNorms = MultiSimpleDocValues.simpleNormValues(reader, \"foo\");\n    for (int i = 0; i < reader.maxDoc(); i++) {\n      assertEquals(0, fooNorms.get(i));\n    }\n    \n    NumericDocValues barNorms = MultiSimpleDocValues.simpleNormValues(reader, \"bar\");\n    for (int i = 0; i < reader.maxDoc(); i++) {\n      assertEquals(1, barNorms.get(i));\n    }\n    \n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b8acf0807ca5f38beda8e0f7d5ab46ff39f81200","date":1358521790,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestNorms#testCustomEncoder().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestNorms#testCustomEncoder().mjava","sourceNew":"  // LUCENE-1260\n  public void testCustomEncoder() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig config = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n    config.setSimilarity(new CustomNormEncodingSimilarity());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, config);\n    Document doc = new Document();\n    Field foo = newTextField(\"foo\", \"\", Field.Store.NO);\n    Field bar = newTextField(\"bar\", \"\", Field.Store.NO);\n    doc.add(foo);\n    doc.add(bar);\n    \n    for (int i = 0; i < 100; i++) {\n      bar.setStringValue(\"singleton\");\n      writer.addDocument(doc);\n    }\n    \n    IndexReader reader = writer.getReader();\n    writer.close();\n    \n    NumericDocValues fooNorms = MultiDocValues.getNormValues(reader, \"foo\");\n    for (int i = 0; i < reader.maxDoc(); i++) {\n      assertEquals(0, fooNorms.get(i));\n    }\n    \n    NumericDocValues barNorms = MultiDocValues.getNormValues(reader, \"bar\");\n    for (int i = 0; i < reader.maxDoc(); i++) {\n      assertEquals(1, barNorms.get(i));\n    }\n    \n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-1260\n  public void testCustomEncoder() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig config = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n    config.setSimilarity(new CustomNormEncodingSimilarity());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, config);\n    Document doc = new Document();\n    Field foo = newTextField(\"foo\", \"\", Field.Store.NO);\n    Field bar = newTextField(\"bar\", \"\", Field.Store.NO);\n    doc.add(foo);\n    doc.add(bar);\n    \n    for (int i = 0; i < 100; i++) {\n      bar.setStringValue(\"singleton\");\n      writer.addDocument(doc);\n    }\n    \n    IndexReader reader = writer.getReader();\n    writer.close();\n    \n    NumericDocValues fooNorms = MultiSimpleDocValues.simpleNormValues(reader, \"foo\");\n    for (int i = 0; i < reader.maxDoc(); i++) {\n      assertEquals(0, fooNorms.get(i));\n    }\n    \n    NumericDocValues barNorms = MultiSimpleDocValues.simpleNormValues(reader, \"bar\");\n    for (int i = 0; i < reader.maxDoc(); i++) {\n      assertEquals(1, barNorms.get(i));\n    }\n    \n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d4d69c535930b5cce125cff868d40f6373dc27d4","date":1360270101,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestNorms#testCustomEncoder().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestNorms#testCustomEncoder().mjava","sourceNew":"  // LUCENE-1260\n  public void testCustomEncoder() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig config = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n    config.setSimilarity(new CustomNormEncodingSimilarity());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, config);\n    Document doc = new Document();\n    Field foo = newTextField(\"foo\", \"\", Field.Store.NO);\n    Field bar = newTextField(\"bar\", \"\", Field.Store.NO);\n    doc.add(foo);\n    doc.add(bar);\n    \n    for (int i = 0; i < 100; i++) {\n      bar.setStringValue(\"singleton\");\n      writer.addDocument(doc);\n    }\n    \n    IndexReader reader = writer.getReader();\n    writer.close();\n    \n    NumericDocValues fooNorms = MultiDocValues.getNormValues(reader, \"foo\");\n    for (int i = 0; i < reader.maxDoc(); i++) {\n      assertEquals(0, fooNorms.get(i));\n    }\n    \n    NumericDocValues barNorms = MultiDocValues.getNormValues(reader, \"bar\");\n    for (int i = 0; i < reader.maxDoc(); i++) {\n      assertEquals(1, barNorms.get(i));\n    }\n    \n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-1260\n  public void testCustomEncoder() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig config = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n    config.setSimilarity(new CustomNormEncodingSimilarity());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, config);\n    Document doc = new Document();\n    Field foo = newTextField(\"foo\", \"\", Field.Store.NO);\n    Field bar = newTextField(\"bar\", \"\", Field.Store.NO);\n    doc.add(foo);\n    doc.add(bar);\n    \n    for (int i = 0; i < 100; i++) {\n      bar.setStringValue(\"singleton\");\n      writer.addDocument(doc);\n    }\n    \n    IndexReader reader = writer.getReader();\n    writer.close();\n    \n    byte fooNorms[] = (byte[]) MultiDocValues.getNormDocValues(reader, \"foo\").getSource().getArray();\n    for (int i = 0; i < reader.maxDoc(); i++)\n      assertEquals(0, fooNorms[i]);\n    \n    byte barNorms[] = (byte[]) MultiDocValues.getNormDocValues(reader, \"bar\").getSource().getArray();\n    for (int i = 0; i < reader.maxDoc(); i++)\n      assertEquals(1, barNorms[i]);\n    \n    reader.close();\n    dir.close();\n  }\n\n","bugFix":["0f4b223b56d0c7927ae8baced5e1b1dd4c693b1d","fb065b657ee556326e3666d83aae3150249aeaa3"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"19275ba31e621f6da1b83bf13af75233876fd3d4","date":1374846698,"type":3,"author":"Han Jiang","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestNorms#testCustomEncoder().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestNorms#testCustomEncoder().mjava","sourceNew":"  // LUCENE-1260\n  public void testCustomEncoder() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig config = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n    config.setSimilarity(new CustomNormEncodingSimilarity());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, config);\n    Document doc = new Document();\n    Field foo = newTextField(\"foo\", \"\", Field.Store.NO);\n    Field bar = newTextField(\"bar\", \"\", Field.Store.NO);\n    doc.add(foo);\n    doc.add(bar);\n    \n    for (int i = 0; i < 100; i++) {\n      bar.setStringValue(\"singleton\");\n      writer.addDocument(doc);\n    }\n    \n    IndexReader reader = writer.getReader();\n    writer.close();\n    \n    NumericDocValues fooNorms = MultiDocValues.getNormValues(reader, \"foo\");\n    for (int i = 0; i < reader.maxDoc(); i++) {\n      assertEquals(0, fooNorms.get(i));\n    }\n    \n    NumericDocValues barNorms = MultiDocValues.getNormValues(reader, \"bar\");\n    for (int i = 0; i < reader.maxDoc(); i++) {\n      assertEquals(1, barNorms.get(i));\n    }\n    \n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-1260\n  public void testCustomEncoder() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig config = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n    config.setSimilarity(new CustomNormEncodingSimilarity());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, config);\n    Document doc = new Document();\n    Field foo = newTextField(\"foo\", \"\", Field.Store.NO);\n    Field bar = newTextField(\"bar\", \"\", Field.Store.NO);\n    doc.add(foo);\n    doc.add(bar);\n    \n    for (int i = 0; i < 100; i++) {\n      bar.setStringValue(\"singleton\");\n      writer.addDocument(doc);\n    }\n    \n    IndexReader reader = writer.getReader();\n    writer.close();\n    \n    NumericDocValues fooNorms = MultiDocValues.getNormValues(reader, \"foo\");\n    for (int i = 0; i < reader.maxDoc(); i++) {\n      assertEquals(0, fooNorms.get(i));\n    }\n    \n    NumericDocValues barNorms = MultiDocValues.getNormValues(reader, \"bar\");\n    for (int i = 0; i < reader.maxDoc(); i++) {\n      assertEquals(1, barNorms.get(i));\n    }\n    \n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee","date":1376366778,"type":3,"author":"Han Jiang","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestNorms#testCustomEncoder().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestNorms#testCustomEncoder().mjava","sourceNew":"  // LUCENE-1260\n  public void testCustomEncoder() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig config = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n    config.setSimilarity(new CustomNormEncodingSimilarity());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, config);\n    Document doc = new Document();\n    Field foo = newTextField(\"foo\", \"\", Field.Store.NO);\n    Field bar = newTextField(\"bar\", \"\", Field.Store.NO);\n    doc.add(foo);\n    doc.add(bar);\n    \n    for (int i = 0; i < 100; i++) {\n      bar.setStringValue(\"singleton\");\n      writer.addDocument(doc);\n    }\n    \n    IndexReader reader = writer.getReader();\n    writer.close();\n    \n    NumericDocValues fooNorms = MultiDocValues.getNormValues(reader, \"foo\");\n    for (int i = 0; i < reader.maxDoc(); i++) {\n      assertEquals(0, fooNorms.get(i));\n    }\n    \n    NumericDocValues barNorms = MultiDocValues.getNormValues(reader, \"bar\");\n    for (int i = 0; i < reader.maxDoc(); i++) {\n      assertEquals(1, barNorms.get(i));\n    }\n    \n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-1260\n  public void testCustomEncoder() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig config = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n    config.setSimilarity(new CustomNormEncodingSimilarity());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, config);\n    Document doc = new Document();\n    Field foo = newTextField(\"foo\", \"\", Field.Store.NO);\n    Field bar = newTextField(\"bar\", \"\", Field.Store.NO);\n    doc.add(foo);\n    doc.add(bar);\n    \n    for (int i = 0; i < 100; i++) {\n      bar.setStringValue(\"singleton\");\n      writer.addDocument(doc);\n    }\n    \n    IndexReader reader = writer.getReader();\n    writer.close();\n    \n    NumericDocValues fooNorms = MultiDocValues.getNormValues(reader, \"foo\");\n    for (int i = 0; i < reader.maxDoc(); i++) {\n      assertEquals(0, fooNorms.get(i));\n    }\n    \n    NumericDocValues barNorms = MultiDocValues.getNormValues(reader, \"bar\");\n    for (int i = 0; i < reader.maxDoc(); i++) {\n      assertEquals(1, barNorms.get(i));\n    }\n    \n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e1151ecb4798f5c31137aec032c241638018ed20","date":1394284367,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestNorms#testCustomEncoder().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestNorms#testCustomEncoder().mjava","sourceNew":"  // LUCENE-1260\n  public void testCustomEncoder() throws Exception {\n    Directory dir = newDirectory();\n    MockAnalyzer analyzer = new MockAnalyzer(random());\n    analyzer.setMaxTokenLength(TestUtil.nextInt(random(), 1, IndexWriter.MAX_TERM_LENGTH));\n\n    IndexWriterConfig config = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n    config.setSimilarity(new CustomNormEncodingSimilarity());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, config);\n    Document doc = new Document();\n    Field foo = newTextField(\"foo\", \"\", Field.Store.NO);\n    Field bar = newTextField(\"bar\", \"\", Field.Store.NO);\n    doc.add(foo);\n    doc.add(bar);\n    \n    for (int i = 0; i < 100; i++) {\n      bar.setStringValue(\"singleton\");\n      writer.addDocument(doc);\n    }\n    \n    IndexReader reader = writer.getReader();\n    writer.close();\n    \n    NumericDocValues fooNorms = MultiDocValues.getNormValues(reader, \"foo\");\n    for (int i = 0; i < reader.maxDoc(); i++) {\n      assertEquals(0, fooNorms.get(i));\n    }\n    \n    NumericDocValues barNorms = MultiDocValues.getNormValues(reader, \"bar\");\n    for (int i = 0; i < reader.maxDoc(); i++) {\n      assertEquals(1, barNorms.get(i));\n    }\n    \n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-1260\n  public void testCustomEncoder() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig config = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n    config.setSimilarity(new CustomNormEncodingSimilarity());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, config);\n    Document doc = new Document();\n    Field foo = newTextField(\"foo\", \"\", Field.Store.NO);\n    Field bar = newTextField(\"bar\", \"\", Field.Store.NO);\n    doc.add(foo);\n    doc.add(bar);\n    \n    for (int i = 0; i < 100; i++) {\n      bar.setStringValue(\"singleton\");\n      writer.addDocument(doc);\n    }\n    \n    IndexReader reader = writer.getReader();\n    writer.close();\n    \n    NumericDocValues fooNorms = MultiDocValues.getNormValues(reader, \"foo\");\n    for (int i = 0; i < reader.maxDoc(); i++) {\n      assertEquals(0, fooNorms.get(i));\n    }\n    \n    NumericDocValues barNorms = MultiDocValues.getNormValues(reader, \"bar\");\n    for (int i = 0; i < reader.maxDoc(); i++) {\n      assertEquals(1, barNorms.get(i));\n    }\n    \n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a58bbbe1c866963764d3f15d3a26a6a85f6c6af4","date":1394564625,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestNorms#testCustomEncoder().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestNorms#testCustomEncoder().mjava","sourceNew":"  // LUCENE-1260\n  public void testCustomEncoder() throws Exception {\n    Directory dir = newDirectory();\n    MockAnalyzer analyzer = new MockAnalyzer(random());\n    analyzer.setMaxTokenLength(TestUtil.nextInt(random(), 1, IndexWriter.MAX_TERM_LENGTH));\n\n    IndexWriterConfig config = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n    config.setSimilarity(new CustomNormEncodingSimilarity());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, config);\n    Document doc = new Document();\n    Field foo = newTextField(\"foo\", \"\", Field.Store.NO);\n    Field bar = newTextField(\"bar\", \"\", Field.Store.NO);\n    doc.add(foo);\n    doc.add(bar);\n    \n    for (int i = 0; i < 100; i++) {\n      bar.setStringValue(\"singleton\");\n      writer.addDocument(doc);\n    }\n    \n    IndexReader reader = writer.getReader();\n    writer.close();\n    \n    NumericDocValues fooNorms = MultiDocValues.getNormValues(reader, \"foo\");\n    for (int i = 0; i < reader.maxDoc(); i++) {\n      assertEquals(0, fooNorms.get(i));\n    }\n    \n    NumericDocValues barNorms = MultiDocValues.getNormValues(reader, \"bar\");\n    for (int i = 0; i < reader.maxDoc(); i++) {\n      assertEquals(1, barNorms.get(i));\n    }\n    \n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-1260\n  public void testCustomEncoder() throws Exception {\n    Directory dir = newDirectory();\n    IndexWriterConfig config = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n    config.setSimilarity(new CustomNormEncodingSimilarity());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, config);\n    Document doc = new Document();\n    Field foo = newTextField(\"foo\", \"\", Field.Store.NO);\n    Field bar = newTextField(\"bar\", \"\", Field.Store.NO);\n    doc.add(foo);\n    doc.add(bar);\n    \n    for (int i = 0; i < 100; i++) {\n      bar.setStringValue(\"singleton\");\n      writer.addDocument(doc);\n    }\n    \n    IndexReader reader = writer.getReader();\n    writer.close();\n    \n    NumericDocValues fooNorms = MultiDocValues.getNormValues(reader, \"foo\");\n    for (int i = 0; i < reader.maxDoc(); i++) {\n      assertEquals(0, fooNorms.get(i));\n    }\n    \n    NumericDocValues barNorms = MultiDocValues.getNormValues(reader, \"bar\");\n    for (int i = 0; i < reader.maxDoc(); i++) {\n      assertEquals(1, barNorms.get(i));\n    }\n    \n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a35eacdf375caefe49026c56463dd8cea3f7a06d","date":1395954828,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestNorms#testCustomEncoder().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestNorms#testCustomEncoder().mjava","sourceNew":"  // LUCENE-1260\n  public void testCustomEncoder() throws Exception {\n    Directory dir = newDirectory();\n    MockAnalyzer analyzer = new MockAnalyzer(random());\n\n    IndexWriterConfig config = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n    config.setSimilarity(new CustomNormEncodingSimilarity());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, config);\n    Document doc = new Document();\n    Field foo = newTextField(\"foo\", \"\", Field.Store.NO);\n    Field bar = newTextField(\"bar\", \"\", Field.Store.NO);\n    doc.add(foo);\n    doc.add(bar);\n    \n    for (int i = 0; i < 100; i++) {\n      bar.setStringValue(\"singleton\");\n      writer.addDocument(doc);\n    }\n    \n    IndexReader reader = writer.getReader();\n    writer.close();\n    \n    NumericDocValues fooNorms = MultiDocValues.getNormValues(reader, \"foo\");\n    for (int i = 0; i < reader.maxDoc(); i++) {\n      assertEquals(0, fooNorms.get(i));\n    }\n    \n    NumericDocValues barNorms = MultiDocValues.getNormValues(reader, \"bar\");\n    for (int i = 0; i < reader.maxDoc(); i++) {\n      assertEquals(1, barNorms.get(i));\n    }\n    \n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-1260\n  public void testCustomEncoder() throws Exception {\n    Directory dir = newDirectory();\n    MockAnalyzer analyzer = new MockAnalyzer(random());\n    analyzer.setMaxTokenLength(TestUtil.nextInt(random(), 1, IndexWriter.MAX_TERM_LENGTH));\n\n    IndexWriterConfig config = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n    config.setSimilarity(new CustomNormEncodingSimilarity());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, config);\n    Document doc = new Document();\n    Field foo = newTextField(\"foo\", \"\", Field.Store.NO);\n    Field bar = newTextField(\"bar\", \"\", Field.Store.NO);\n    doc.add(foo);\n    doc.add(bar);\n    \n    for (int i = 0; i < 100; i++) {\n      bar.setStringValue(\"singleton\");\n      writer.addDocument(doc);\n    }\n    \n    IndexReader reader = writer.getReader();\n    writer.close();\n    \n    NumericDocValues fooNorms = MultiDocValues.getNormValues(reader, \"foo\");\n    for (int i = 0; i < reader.maxDoc(); i++) {\n      assertEquals(0, fooNorms.get(i));\n    }\n    \n    NumericDocValues barNorms = MultiDocValues.getNormValues(reader, \"bar\");\n    for (int i = 0; i < reader.maxDoc(); i++) {\n      assertEquals(1, barNorms.get(i));\n    }\n    \n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5eb2511ababf862ea11e10761c70ee560cd84510","date":1396607225,"type":3,"author":"Dawid Weiss","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestNorms#testCustomEncoder().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestNorms#testCustomEncoder().mjava","sourceNew":"  // LUCENE-1260\n  public void testCustomEncoder() throws Exception {\n    Directory dir = newDirectory();\n    MockAnalyzer analyzer = new MockAnalyzer(random());\n\n    IndexWriterConfig config = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n    config.setSimilarity(new CustomNormEncodingSimilarity());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, config);\n    Document doc = new Document();\n    Field foo = newTextField(\"foo\", \"\", Field.Store.NO);\n    Field bar = newTextField(\"bar\", \"\", Field.Store.NO);\n    doc.add(foo);\n    doc.add(bar);\n    \n    for (int i = 0; i < 100; i++) {\n      bar.setStringValue(\"singleton\");\n      writer.addDocument(doc);\n    }\n    \n    IndexReader reader = writer.getReader();\n    writer.close();\n    \n    NumericDocValues fooNorms = MultiDocValues.getNormValues(reader, \"foo\");\n    for (int i = 0; i < reader.maxDoc(); i++) {\n      assertEquals(0, fooNorms.get(i));\n    }\n    \n    NumericDocValues barNorms = MultiDocValues.getNormValues(reader, \"bar\");\n    for (int i = 0; i < reader.maxDoc(); i++) {\n      assertEquals(1, barNorms.get(i));\n    }\n    \n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-1260\n  public void testCustomEncoder() throws Exception {\n    Directory dir = newDirectory();\n    MockAnalyzer analyzer = new MockAnalyzer(random());\n    analyzer.setMaxTokenLength(TestUtil.nextInt(random(), 1, IndexWriter.MAX_TERM_LENGTH));\n\n    IndexWriterConfig config = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n    config.setSimilarity(new CustomNormEncodingSimilarity());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, config);\n    Document doc = new Document();\n    Field foo = newTextField(\"foo\", \"\", Field.Store.NO);\n    Field bar = newTextField(\"bar\", \"\", Field.Store.NO);\n    doc.add(foo);\n    doc.add(bar);\n    \n    for (int i = 0; i < 100; i++) {\n      bar.setStringValue(\"singleton\");\n      writer.addDocument(doc);\n    }\n    \n    IndexReader reader = writer.getReader();\n    writer.close();\n    \n    NumericDocValues fooNorms = MultiDocValues.getNormValues(reader, \"foo\");\n    for (int i = 0; i < reader.maxDoc(); i++) {\n      assertEquals(0, fooNorms.get(i));\n    }\n    \n    NumericDocValues barNorms = MultiDocValues.getNormValues(reader, \"bar\");\n    for (int i = 0; i < reader.maxDoc(); i++) {\n      assertEquals(1, barNorms.get(i));\n    }\n    \n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ae14298f4eec6d5faee6a149f88ba57d14a6f21a","date":1396971290,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestNorms#testCustomEncoder().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestNorms#testCustomEncoder().mjava","sourceNew":"  // LUCENE-1260\n  public void testCustomEncoder() throws Exception {\n    Directory dir = newDirectory();\n    MockAnalyzer analyzer = new MockAnalyzer(random());\n\n    IndexWriterConfig config = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n    config.setSimilarity(new CustomNormEncodingSimilarity());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, config);\n    Document doc = new Document();\n    Field foo = newTextField(\"foo\", \"\", Field.Store.NO);\n    Field bar = newTextField(\"bar\", \"\", Field.Store.NO);\n    doc.add(foo);\n    doc.add(bar);\n    \n    for (int i = 0; i < 100; i++) {\n      bar.setStringValue(\"singleton\");\n      writer.addDocument(doc);\n    }\n    \n    IndexReader reader = writer.getReader();\n    writer.shutdown();\n    \n    NumericDocValues fooNorms = MultiDocValues.getNormValues(reader, \"foo\");\n    for (int i = 0; i < reader.maxDoc(); i++) {\n      assertEquals(0, fooNorms.get(i));\n    }\n    \n    NumericDocValues barNorms = MultiDocValues.getNormValues(reader, \"bar\");\n    for (int i = 0; i < reader.maxDoc(); i++) {\n      assertEquals(1, barNorms.get(i));\n    }\n    \n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-1260\n  public void testCustomEncoder() throws Exception {\n    Directory dir = newDirectory();\n    MockAnalyzer analyzer = new MockAnalyzer(random());\n\n    IndexWriterConfig config = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n    config.setSimilarity(new CustomNormEncodingSimilarity());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, config);\n    Document doc = new Document();\n    Field foo = newTextField(\"foo\", \"\", Field.Store.NO);\n    Field bar = newTextField(\"bar\", \"\", Field.Store.NO);\n    doc.add(foo);\n    doc.add(bar);\n    \n    for (int i = 0; i < 100; i++) {\n      bar.setStringValue(\"singleton\");\n      writer.addDocument(doc);\n    }\n    \n    IndexReader reader = writer.getReader();\n    writer.close();\n    \n    NumericDocValues fooNorms = MultiDocValues.getNormValues(reader, \"foo\");\n    for (int i = 0; i < reader.maxDoc(); i++) {\n      assertEquals(0, fooNorms.get(i));\n    }\n    \n    NumericDocValues barNorms = MultiDocValues.getNormValues(reader, \"bar\");\n    for (int i = 0; i < reader.maxDoc(); i++) {\n      assertEquals(1, barNorms.get(i));\n    }\n    \n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e","date":1406737224,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestNorms#testCustomEncoder().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestNorms#testCustomEncoder().mjava","sourceNew":"  // LUCENE-1260\n  public void testCustomEncoder() throws Exception {\n    Directory dir = newDirectory();\n    MockAnalyzer analyzer = new MockAnalyzer(random());\n\n    IndexWriterConfig config = newIndexWriterConfig(analyzer);\n    config.setSimilarity(new CustomNormEncodingSimilarity());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, config);\n    Document doc = new Document();\n    Field foo = newTextField(\"foo\", \"\", Field.Store.NO);\n    Field bar = newTextField(\"bar\", \"\", Field.Store.NO);\n    doc.add(foo);\n    doc.add(bar);\n    \n    for (int i = 0; i < 100; i++) {\n      bar.setStringValue(\"singleton\");\n      writer.addDocument(doc);\n    }\n    \n    IndexReader reader = writer.getReader();\n    writer.shutdown();\n    \n    NumericDocValues fooNorms = MultiDocValues.getNormValues(reader, \"foo\");\n    for (int i = 0; i < reader.maxDoc(); i++) {\n      assertEquals(0, fooNorms.get(i));\n    }\n    \n    NumericDocValues barNorms = MultiDocValues.getNormValues(reader, \"bar\");\n    for (int i = 0; i < reader.maxDoc(); i++) {\n      assertEquals(1, barNorms.get(i));\n    }\n    \n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-1260\n  public void testCustomEncoder() throws Exception {\n    Directory dir = newDirectory();\n    MockAnalyzer analyzer = new MockAnalyzer(random());\n\n    IndexWriterConfig config = newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer);\n    config.setSimilarity(new CustomNormEncodingSimilarity());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, config);\n    Document doc = new Document();\n    Field foo = newTextField(\"foo\", \"\", Field.Store.NO);\n    Field bar = newTextField(\"bar\", \"\", Field.Store.NO);\n    doc.add(foo);\n    doc.add(bar);\n    \n    for (int i = 0; i < 100; i++) {\n      bar.setStringValue(\"singleton\");\n      writer.addDocument(doc);\n    }\n    \n    IndexReader reader = writer.getReader();\n    writer.shutdown();\n    \n    NumericDocValues fooNorms = MultiDocValues.getNormValues(reader, \"foo\");\n    for (int i = 0; i < reader.maxDoc(); i++) {\n      assertEquals(0, fooNorms.get(i));\n    }\n    \n    NumericDocValues barNorms = MultiDocValues.getNormValues(reader, \"bar\");\n    for (int i = 0; i < reader.maxDoc(); i++) {\n      assertEquals(1, barNorms.get(i));\n    }\n    \n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d0ef034a4f10871667ae75181537775ddcf8ade4","date":1407610475,"type":3,"author":"Ryan Ernst","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestNorms#testCustomEncoder().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestNorms#testCustomEncoder().mjava","sourceNew":"  // LUCENE-1260\n  public void testCustomEncoder() throws Exception {\n    Directory dir = newDirectory();\n    MockAnalyzer analyzer = new MockAnalyzer(random());\n\n    IndexWriterConfig config = newIndexWriterConfig(analyzer);\n    config.setSimilarity(new CustomNormEncodingSimilarity());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, config);\n    Document doc = new Document();\n    Field foo = newTextField(\"foo\", \"\", Field.Store.NO);\n    Field bar = newTextField(\"bar\", \"\", Field.Store.NO);\n    doc.add(foo);\n    doc.add(bar);\n    \n    for (int i = 0; i < 100; i++) {\n      bar.setStringValue(\"singleton\");\n      writer.addDocument(doc);\n    }\n    \n    IndexReader reader = writer.getReader();\n    writer.close();\n    \n    NumericDocValues fooNorms = MultiDocValues.getNormValues(reader, \"foo\");\n    for (int i = 0; i < reader.maxDoc(); i++) {\n      assertEquals(0, fooNorms.get(i));\n    }\n    \n    NumericDocValues barNorms = MultiDocValues.getNormValues(reader, \"bar\");\n    for (int i = 0; i < reader.maxDoc(); i++) {\n      assertEquals(1, barNorms.get(i));\n    }\n    \n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-1260\n  public void testCustomEncoder() throws Exception {\n    Directory dir = newDirectory();\n    MockAnalyzer analyzer = new MockAnalyzer(random());\n\n    IndexWriterConfig config = newIndexWriterConfig(analyzer);\n    config.setSimilarity(new CustomNormEncodingSimilarity());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, config);\n    Document doc = new Document();\n    Field foo = newTextField(\"foo\", \"\", Field.Store.NO);\n    Field bar = newTextField(\"bar\", \"\", Field.Store.NO);\n    doc.add(foo);\n    doc.add(bar);\n    \n    for (int i = 0; i < 100; i++) {\n      bar.setStringValue(\"singleton\");\n      writer.addDocument(doc);\n    }\n    \n    IndexReader reader = writer.getReader();\n    writer.shutdown();\n    \n    NumericDocValues fooNorms = MultiDocValues.getNormValues(reader, \"foo\");\n    for (int i = 0; i < reader.maxDoc(); i++) {\n      assertEquals(0, fooNorms.get(i));\n    }\n    \n    NumericDocValues barNorms = MultiDocValues.getNormValues(reader, \"bar\");\n    for (int i = 0; i < reader.maxDoc(); i++) {\n      assertEquals(1, barNorms.get(i));\n    }\n    \n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6652c74b2358a0b13223817a6a793bf1c9d0749d","date":1474465301,"type":3,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestNorms#testCustomEncoder().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestNorms#testCustomEncoder().mjava","sourceNew":"  // LUCENE-1260\n  public void testCustomEncoder() throws Exception {\n    Directory dir = newDirectory();\n    MockAnalyzer analyzer = new MockAnalyzer(random());\n\n    IndexWriterConfig config = newIndexWriterConfig(analyzer);\n    config.setSimilarity(new CustomNormEncodingSimilarity());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, config);\n    Document doc = new Document();\n    Field foo = newTextField(\"foo\", \"\", Field.Store.NO);\n    Field bar = newTextField(\"bar\", \"\", Field.Store.NO);\n    doc.add(foo);\n    doc.add(bar);\n    \n    for (int i = 0; i < 100; i++) {\n      bar.setStringValue(\"singleton\");\n      writer.addDocument(doc);\n    }\n    \n    IndexReader reader = writer.getReader();\n    writer.close();\n    \n    NumericDocValues fooNorms = MultiDocValues.getNormValues(reader, \"foo\");\n    for (int i = 0; i < reader.maxDoc(); i++) {\n      assertEquals(i, fooNorms.nextDoc());\n      assertEquals(0, fooNorms.longValue());\n    }\n    \n    NumericDocValues barNorms = MultiDocValues.getNormValues(reader, \"bar\");\n    for (int i = 0; i < reader.maxDoc(); i++) {\n      assertEquals(i, barNorms.nextDoc());\n      assertEquals(1, barNorms.longValue());\n    }\n    \n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-1260\n  public void testCustomEncoder() throws Exception {\n    Directory dir = newDirectory();\n    MockAnalyzer analyzer = new MockAnalyzer(random());\n\n    IndexWriterConfig config = newIndexWriterConfig(analyzer);\n    config.setSimilarity(new CustomNormEncodingSimilarity());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, config);\n    Document doc = new Document();\n    Field foo = newTextField(\"foo\", \"\", Field.Store.NO);\n    Field bar = newTextField(\"bar\", \"\", Field.Store.NO);\n    doc.add(foo);\n    doc.add(bar);\n    \n    for (int i = 0; i < 100; i++) {\n      bar.setStringValue(\"singleton\");\n      writer.addDocument(doc);\n    }\n    \n    IndexReader reader = writer.getReader();\n    writer.close();\n    \n    NumericDocValues fooNorms = MultiDocValues.getNormValues(reader, \"foo\");\n    for (int i = 0; i < reader.maxDoc(); i++) {\n      assertEquals(0, fooNorms.get(i));\n    }\n    \n    NumericDocValues barNorms = MultiDocValues.getNormValues(reader, \"bar\");\n    for (int i = 0; i < reader.maxDoc(); i++) {\n      assertEquals(1, barNorms.get(i));\n    }\n    \n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"17e5da53e4e5bd659e22add9bba1cfa222e7e30d","date":1475435902,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestNorms#testCustomEncoder().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestNorms#testCustomEncoder().mjava","sourceNew":"  // LUCENE-1260\n  public void testCustomEncoder() throws Exception {\n    Directory dir = newDirectory();\n    MockAnalyzer analyzer = new MockAnalyzer(random());\n\n    IndexWriterConfig config = newIndexWriterConfig(analyzer);\n    config.setSimilarity(new CustomNormEncodingSimilarity());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, config);\n    Document doc = new Document();\n    Field foo = newTextField(\"foo\", \"\", Field.Store.NO);\n    Field bar = newTextField(\"bar\", \"\", Field.Store.NO);\n    doc.add(foo);\n    doc.add(bar);\n    \n    for (int i = 0; i < 100; i++) {\n      bar.setStringValue(\"singleton\");\n      writer.addDocument(doc);\n    }\n    \n    IndexReader reader = writer.getReader();\n    writer.close();\n    \n    NumericDocValues fooNorms = MultiDocValues.getNormValues(reader, \"foo\");\n    for (int i = 0; i < reader.maxDoc(); i++) {\n      assertEquals(i, fooNorms.nextDoc());\n      assertEquals(0, fooNorms.longValue());\n    }\n    \n    NumericDocValues barNorms = MultiDocValues.getNormValues(reader, \"bar\");\n    for (int i = 0; i < reader.maxDoc(); i++) {\n      assertEquals(i, barNorms.nextDoc());\n      assertEquals(1, barNorms.longValue());\n    }\n    \n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-1260\n  public void testCustomEncoder() throws Exception {\n    Directory dir = newDirectory();\n    MockAnalyzer analyzer = new MockAnalyzer(random());\n\n    IndexWriterConfig config = newIndexWriterConfig(analyzer);\n    config.setSimilarity(new CustomNormEncodingSimilarity());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, config);\n    Document doc = new Document();\n    Field foo = newTextField(\"foo\", \"\", Field.Store.NO);\n    Field bar = newTextField(\"bar\", \"\", Field.Store.NO);\n    doc.add(foo);\n    doc.add(bar);\n    \n    for (int i = 0; i < 100; i++) {\n      bar.setStringValue(\"singleton\");\n      writer.addDocument(doc);\n    }\n    \n    IndexReader reader = writer.getReader();\n    writer.close();\n    \n    NumericDocValues fooNorms = MultiDocValues.getNormValues(reader, \"foo\");\n    for (int i = 0; i < reader.maxDoc(); i++) {\n      assertEquals(0, fooNorms.get(i));\n    }\n    \n    NumericDocValues barNorms = MultiDocValues.getNormValues(reader, \"bar\");\n    for (int i = 0; i < reader.maxDoc(); i++) {\n      assertEquals(1, barNorms.get(i));\n    }\n    \n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4cce5816ef15a48a0bc11e5d400497ee4301dd3b","date":1476991456,"type":3,"author":"Kevin Risden","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestNorms#testCustomEncoder().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestNorms#testCustomEncoder().mjava","sourceNew":"  // LUCENE-1260\n  public void testCustomEncoder() throws Exception {\n    Directory dir = newDirectory();\n    MockAnalyzer analyzer = new MockAnalyzer(random());\n\n    IndexWriterConfig config = newIndexWriterConfig(analyzer);\n    config.setSimilarity(new CustomNormEncodingSimilarity());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, config);\n    Document doc = new Document();\n    Field foo = newTextField(\"foo\", \"\", Field.Store.NO);\n    Field bar = newTextField(\"bar\", \"\", Field.Store.NO);\n    doc.add(foo);\n    doc.add(bar);\n    \n    for (int i = 0; i < 100; i++) {\n      bar.setStringValue(\"singleton\");\n      writer.addDocument(doc);\n    }\n    \n    IndexReader reader = writer.getReader();\n    writer.close();\n    \n    NumericDocValues fooNorms = MultiDocValues.getNormValues(reader, \"foo\");\n    for (int i = 0; i < reader.maxDoc(); i++) {\n      assertEquals(i, fooNorms.nextDoc());\n      assertEquals(0, fooNorms.longValue());\n    }\n    \n    NumericDocValues barNorms = MultiDocValues.getNormValues(reader, \"bar\");\n    for (int i = 0; i < reader.maxDoc(); i++) {\n      assertEquals(i, barNorms.nextDoc());\n      assertEquals(1, barNorms.longValue());\n    }\n    \n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-1260\n  public void testCustomEncoder() throws Exception {\n    Directory dir = newDirectory();\n    MockAnalyzer analyzer = new MockAnalyzer(random());\n\n    IndexWriterConfig config = newIndexWriterConfig(analyzer);\n    config.setSimilarity(new CustomNormEncodingSimilarity());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, config);\n    Document doc = new Document();\n    Field foo = newTextField(\"foo\", \"\", Field.Store.NO);\n    Field bar = newTextField(\"bar\", \"\", Field.Store.NO);\n    doc.add(foo);\n    doc.add(bar);\n    \n    for (int i = 0; i < 100; i++) {\n      bar.setStringValue(\"singleton\");\n      writer.addDocument(doc);\n    }\n    \n    IndexReader reader = writer.getReader();\n    writer.close();\n    \n    NumericDocValues fooNorms = MultiDocValues.getNormValues(reader, \"foo\");\n    for (int i = 0; i < reader.maxDoc(); i++) {\n      assertEquals(0, fooNorms.get(i));\n    }\n    \n    NumericDocValues barNorms = MultiDocValues.getNormValues(reader, \"bar\");\n    for (int i = 0; i < reader.maxDoc(); i++) {\n      assertEquals(1, barNorms.get(i));\n    }\n    \n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"615370d2b876c3435773b5174df2e2242ad7981a","date":1495117651,"type":4,"author":"Adrien Grand","isMerge":false,"pathNew":"/dev/null","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestNorms#testCustomEncoder().mjava","sourceNew":null,"sourceOld":"  // LUCENE-1260\n  public void testCustomEncoder() throws Exception {\n    Directory dir = newDirectory();\n    MockAnalyzer analyzer = new MockAnalyzer(random());\n\n    IndexWriterConfig config = newIndexWriterConfig(analyzer);\n    config.setSimilarity(new CustomNormEncodingSimilarity());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, config);\n    Document doc = new Document();\n    Field foo = newTextField(\"foo\", \"\", Field.Store.NO);\n    Field bar = newTextField(\"bar\", \"\", Field.Store.NO);\n    doc.add(foo);\n    doc.add(bar);\n    \n    for (int i = 0; i < 100; i++) {\n      bar.setStringValue(\"singleton\");\n      writer.addDocument(doc);\n    }\n    \n    IndexReader reader = writer.getReader();\n    writer.close();\n    \n    NumericDocValues fooNorms = MultiDocValues.getNormValues(reader, \"foo\");\n    for (int i = 0; i < reader.maxDoc(); i++) {\n      assertEquals(i, fooNorms.nextDoc());\n      assertEquals(0, fooNorms.longValue());\n    }\n    \n    NumericDocValues barNorms = MultiDocValues.getNormValues(reader, \"bar\");\n    for (int i = 0; i < reader.maxDoc(); i++) {\n      assertEquals(i, barNorms.nextDoc());\n      assertEquals(1, barNorms.longValue());\n    }\n    \n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e9017cf144952056066919f1ebc7897ff9bd71b1","date":1496757600,"type":4,"author":"Shalin Shekhar Mangar","isMerge":true,"pathNew":"/dev/null","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestNorms#testCustomEncoder().mjava","sourceNew":null,"sourceOld":"  // LUCENE-1260\n  public void testCustomEncoder() throws Exception {\n    Directory dir = newDirectory();\n    MockAnalyzer analyzer = new MockAnalyzer(random());\n\n    IndexWriterConfig config = newIndexWriterConfig(analyzer);\n    config.setSimilarity(new CustomNormEncodingSimilarity());\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir, config);\n    Document doc = new Document();\n    Field foo = newTextField(\"foo\", \"\", Field.Store.NO);\n    Field bar = newTextField(\"bar\", \"\", Field.Store.NO);\n    doc.add(foo);\n    doc.add(bar);\n    \n    for (int i = 0; i < 100; i++) {\n      bar.setStringValue(\"singleton\");\n      writer.addDocument(doc);\n    }\n    \n    IndexReader reader = writer.getReader();\n    writer.close();\n    \n    NumericDocValues fooNorms = MultiDocValues.getNormValues(reader, \"foo\");\n    for (int i = 0; i < reader.maxDoc(); i++) {\n      assertEquals(i, fooNorms.nextDoc());\n      assertEquals(0, fooNorms.longValue());\n    }\n    \n    NumericDocValues barNorms = MultiDocValues.getNormValues(reader, \"bar\");\n    for (int i = 0; i < reader.maxDoc(); i++) {\n      assertEquals(i, barNorms.nextDoc());\n      assertEquals(1, barNorms.longValue());\n    }\n    \n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"5eb2511ababf862ea11e10761c70ee560cd84510":["e1151ecb4798f5c31137aec032c241638018ed20","a35eacdf375caefe49026c56463dd8cea3f7a06d"],"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e":["ae14298f4eec6d5faee6a149f88ba57d14a6f21a"],"a58bbbe1c866963764d3f15d3a26a6a85f6c6af4":["19275ba31e621f6da1b83bf13af75233876fd3d4","e1151ecb4798f5c31137aec032c241638018ed20"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"19275ba31e621f6da1b83bf13af75233876fd3d4":["d4d69c535930b5cce125cff868d40f6373dc27d4"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["d0ef034a4f10871667ae75181537775ddcf8ade4","17e5da53e4e5bd659e22add9bba1cfa222e7e30d"],"e1151ecb4798f5c31137aec032c241638018ed20":["19275ba31e621f6da1b83bf13af75233876fd3d4"],"04f07771a2a7dd3a395700665ed839c3dae2def2":["629c38c4ae4e303d0617e05fbfe508140b32f0a3"],"a78a90fc9701e511308346ea29f4f5e548bb39fe":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"e9017cf144952056066919f1ebc7897ff9bd71b1":["17e5da53e4e5bd659e22add9bba1cfa222e7e30d","615370d2b876c3435773b5174df2e2242ad7981a"],"b8acf0807ca5f38beda8e0f7d5ab46ff39f81200":["0837ab0472feecb3a54260729d845f839e1cbd72"],"615370d2b876c3435773b5174df2e2242ad7981a":["17e5da53e4e5bd659e22add9bba1cfa222e7e30d"],"d4d69c535930b5cce125cff868d40f6373dc27d4":["04f07771a2a7dd3a395700665ed839c3dae2def2","b8acf0807ca5f38beda8e0f7d5ab46ff39f81200"],"ad7de846867bd14c63f9dd19df082f72c5ea9c54":["04f07771a2a7dd3a395700665ed839c3dae2def2"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"17e5da53e4e5bd659e22add9bba1cfa222e7e30d":["d0ef034a4f10871667ae75181537775ddcf8ade4","6652c74b2358a0b13223817a6a793bf1c9d0749d"],"6652c74b2358a0b13223817a6a793bf1c9d0749d":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"d0ef034a4f10871667ae75181537775ddcf8ade4":["54a6bea0b991120a99ad0e2f72ae853fd5ecae0e"],"8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee":["d4d69c535930b5cce125cff868d40f6373dc27d4"],"0837ab0472feecb3a54260729d845f839e1cbd72":["ad7de846867bd14c63f9dd19df082f72c5ea9c54"],"ae14298f4eec6d5faee6a149f88ba57d14a6f21a":["a35eacdf375caefe49026c56463dd8cea3f7a06d"],"a35eacdf375caefe49026c56463dd8cea3f7a06d":["e1151ecb4798f5c31137aec032c241638018ed20"],"629c38c4ae4e303d0617e05fbfe508140b32f0a3":["a78a90fc9701e511308346ea29f4f5e548bb39fe"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["615370d2b876c3435773b5174df2e2242ad7981a"]},"commit2Childs":{"5eb2511ababf862ea11e10761c70ee560cd84510":[],"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"a58bbbe1c866963764d3f15d3a26a6a85f6c6af4":[],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["a78a90fc9701e511308346ea29f4f5e548bb39fe"],"19275ba31e621f6da1b83bf13af75233876fd3d4":["a58bbbe1c866963764d3f15d3a26a6a85f6c6af4","e1151ecb4798f5c31137aec032c241638018ed20"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":[],"e1151ecb4798f5c31137aec032c241638018ed20":["5eb2511ababf862ea11e10761c70ee560cd84510","a58bbbe1c866963764d3f15d3a26a6a85f6c6af4","a35eacdf375caefe49026c56463dd8cea3f7a06d"],"04f07771a2a7dd3a395700665ed839c3dae2def2":["d4d69c535930b5cce125cff868d40f6373dc27d4","ad7de846867bd14c63f9dd19df082f72c5ea9c54"],"a78a90fc9701e511308346ea29f4f5e548bb39fe":["629c38c4ae4e303d0617e05fbfe508140b32f0a3"],"e9017cf144952056066919f1ebc7897ff9bd71b1":[],"b8acf0807ca5f38beda8e0f7d5ab46ff39f81200":["d4d69c535930b5cce125cff868d40f6373dc27d4"],"d4d69c535930b5cce125cff868d40f6373dc27d4":["19275ba31e621f6da1b83bf13af75233876fd3d4","8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee"],"615370d2b876c3435773b5174df2e2242ad7981a":["e9017cf144952056066919f1ebc7897ff9bd71b1","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"ad7de846867bd14c63f9dd19df082f72c5ea9c54":["0837ab0472feecb3a54260729d845f839e1cbd72"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"17e5da53e4e5bd659e22add9bba1cfa222e7e30d":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b","e9017cf144952056066919f1ebc7897ff9bd71b1","615370d2b876c3435773b5174df2e2242ad7981a"],"6652c74b2358a0b13223817a6a793bf1c9d0749d":["17e5da53e4e5bd659e22add9bba1cfa222e7e30d"],"d0ef034a4f10871667ae75181537775ddcf8ade4":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b","17e5da53e4e5bd659e22add9bba1cfa222e7e30d","6652c74b2358a0b13223817a6a793bf1c9d0749d"],"8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee":[],"0837ab0472feecb3a54260729d845f839e1cbd72":["b8acf0807ca5f38beda8e0f7d5ab46ff39f81200"],"ae14298f4eec6d5faee6a149f88ba57d14a6f21a":["54a6bea0b991120a99ad0e2f72ae853fd5ecae0e"],"a35eacdf375caefe49026c56463dd8cea3f7a06d":["5eb2511ababf862ea11e10761c70ee560cd84510","ae14298f4eec6d5faee6a149f88ba57d14a6f21a"],"629c38c4ae4e303d0617e05fbfe508140b32f0a3":["04f07771a2a7dd3a395700665ed839c3dae2def2"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["5eb2511ababf862ea11e10761c70ee560cd84510","a58bbbe1c866963764d3f15d3a26a6a85f6c6af4","4cce5816ef15a48a0bc11e5d400497ee4301dd3b","e9017cf144952056066919f1ebc7897ff9bd71b1","8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}