{"path":"solr/src/java/org/apache/solr/analysis/PatternTokenizer#incrementToken().mjava","commits":[{"id":"893269407f5c988a4b2ee13c7ffc01ec43136c1d","date":1268598046,"type":0,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/src/java/org/apache/solr/analysis/PatternTokenizer#incrementToken().mjava","pathOld":"/dev/null","sourceNew":"  @Override\n  public boolean incrementToken() throws IOException {\n    if (index >= str.length()) return false;\n    clearAttributes();\n    if (group >= 0) {\n    \n      // match a specific group\n      while (matcher.find()) {\n        final String match = matcher.group(group);\n        if (match.length() == 0) continue;\n        termAtt.setTermBuffer(match);\n        index = matcher.start(group);\n        offsetAtt.setOffset(correctOffset(index), correctOffset(matcher.end(group)));\n        return true;\n      }\n      \n      index = Integer.MAX_VALUE; // mark exhausted\n      return false;\n      \n    } else {\n    \n      // String.split() functionality\n      while (matcher.find()) {\n        if (matcher.start() - index > 0) {\n          // found a non-zero-length token\n          termAtt.setTermBuffer(str, index, matcher.start() - index);\n          offsetAtt.setOffset(correctOffset(index), correctOffset(matcher.start()));\n          index = matcher.end();\n          return true;\n        }\n        \n        index = matcher.end();\n      }\n      \n      if (str.length() - index == 0) {\n        index = Integer.MAX_VALUE; // mark exhausted\n        return false;\n      }\n      \n      termAtt.setTermBuffer(str, index, str.length() - index);\n      offsetAtt.setOffset(correctOffset(index), correctOffset(str.length()));\n      index = Integer.MAX_VALUE; // mark exhausted\n      return true;\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a89acb2b4321b599bbfa1e802c00c4dbbc8ee6b8","date":1268599006,"type":4,"author":"Mark Robert Miller","isMerge":false,"pathNew":"/dev/null","pathOld":"solr/src/java/org/apache/solr/analysis/PatternTokenizer#incrementToken().mjava","sourceNew":null,"sourceOld":"  @Override\n  public boolean incrementToken() throws IOException {\n    if (index >= str.length()) return false;\n    clearAttributes();\n    if (group >= 0) {\n    \n      // match a specific group\n      while (matcher.find()) {\n        final String match = matcher.group(group);\n        if (match.length() == 0) continue;\n        termAtt.setTermBuffer(match);\n        index = matcher.start(group);\n        offsetAtt.setOffset(correctOffset(index), correctOffset(matcher.end(group)));\n        return true;\n      }\n      \n      index = Integer.MAX_VALUE; // mark exhausted\n      return false;\n      \n    } else {\n    \n      // String.split() functionality\n      while (matcher.find()) {\n        if (matcher.start() - index > 0) {\n          // found a non-zero-length token\n          termAtt.setTermBuffer(str, index, matcher.start() - index);\n          offsetAtt.setOffset(correctOffset(index), correctOffset(matcher.start()));\n          index = matcher.end();\n          return true;\n        }\n        \n        index = matcher.end();\n      }\n      \n      if (str.length() - index == 0) {\n        index = Integer.MAX_VALUE; // mark exhausted\n        return false;\n      }\n      \n      termAtt.setTermBuffer(str, index, str.length() - index);\n      offsetAtt.setOffset(correctOffset(index), correctOffset(str.length()));\n      index = Integer.MAX_VALUE; // mark exhausted\n      return true;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ad94625fb8d088209f46650c8097196fec67f00c","date":1453508319,"type":1,"author":"Dawid Weiss","isMerge":false,"pathNew":"solr/src/java/org/apache/solr/analysis/PatternTokenizer#incrementToken().mjava","pathOld":"src/java/org/apache/solr/analysis/PatternTokenizer#incrementToken().mjava","sourceNew":"  @Override\n  public boolean incrementToken() throws IOException {\n    if (index >= str.length()) return false;\n    clearAttributes();\n    if (group >= 0) {\n    \n      // match a specific group\n      while (matcher.find()) {\n        final String match = matcher.group(group);\n        if (match.length() == 0) continue;\n        termAtt.setTermBuffer(match);\n        index = matcher.start(group);\n        offsetAtt.setOffset(correctOffset(index), correctOffset(matcher.end(group)));\n        return true;\n      }\n      \n      index = Integer.MAX_VALUE; // mark exhausted\n      return false;\n      \n    } else {\n    \n      // String.split() functionality\n      while (matcher.find()) {\n        if (matcher.start() - index > 0) {\n          // found a non-zero-length token\n          termAtt.setTermBuffer(str, index, matcher.start() - index);\n          offsetAtt.setOffset(correctOffset(index), correctOffset(matcher.start()));\n          index = matcher.end();\n          return true;\n        }\n        \n        index = matcher.end();\n      }\n      \n      if (str.length() - index == 0) {\n        index = Integer.MAX_VALUE; // mark exhausted\n        return false;\n      }\n      \n      termAtt.setTermBuffer(str, index, str.length() - index);\n      offsetAtt.setOffset(correctOffset(index), correctOffset(str.length()));\n      index = Integer.MAX_VALUE; // mark exhausted\n      return true;\n    }\n  }\n\n","sourceOld":"  @Override\n  public boolean incrementToken() throws IOException {\n    if (index >= str.length()) return false;\n    clearAttributes();\n    if (group >= 0) {\n    \n      // match a specific group\n      while (matcher.find()) {\n        final String match = matcher.group(group);\n        if (match.length() == 0) continue;\n        termAtt.setTermBuffer(match);\n        index = matcher.start(group);\n        offsetAtt.setOffset(correctOffset(index), correctOffset(matcher.end(group)));\n        return true;\n      }\n      \n      index = Integer.MAX_VALUE; // mark exhausted\n      return false;\n      \n    } else {\n    \n      // String.split() functionality\n      while (matcher.find()) {\n        if (matcher.start() - index > 0) {\n          // found a non-zero-length token\n          termAtt.setTermBuffer(str, index, matcher.start() - index);\n          offsetAtt.setOffset(correctOffset(index), correctOffset(matcher.start()));\n          index = matcher.end();\n          return true;\n        }\n        \n        index = matcher.end();\n      }\n      \n      if (str.length() - index == 0) {\n        index = Integer.MAX_VALUE; // mark exhausted\n        return false;\n      }\n      \n      termAtt.setTermBuffer(str, index, str.length() - index);\n      offsetAtt.setOffset(correctOffset(index), correctOffset(str.length()));\n      index = Integer.MAX_VALUE; // mark exhausted\n      return true;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1da8d55113b689b06716246649de6f62430f15c0","date":1453508340,"type":0,"author":"Dawid Weiss","isMerge":true,"pathNew":"solr/src/java/org/apache/solr/analysis/PatternTokenizer#incrementToken().mjava","pathOld":"/dev/null","sourceNew":"  @Override\n  public boolean incrementToken() throws IOException {\n    if (index >= str.length()) return false;\n    clearAttributes();\n    if (group >= 0) {\n    \n      // match a specific group\n      while (matcher.find()) {\n        final String match = matcher.group(group);\n        if (match.length() == 0) continue;\n        termAtt.setTermBuffer(match);\n        index = matcher.start(group);\n        offsetAtt.setOffset(correctOffset(index), correctOffset(matcher.end(group)));\n        return true;\n      }\n      \n      index = Integer.MAX_VALUE; // mark exhausted\n      return false;\n      \n    } else {\n    \n      // String.split() functionality\n      while (matcher.find()) {\n        if (matcher.start() - index > 0) {\n          // found a non-zero-length token\n          termAtt.setTermBuffer(str, index, matcher.start() - index);\n          offsetAtt.setOffset(correctOffset(index), correctOffset(matcher.start()));\n          index = matcher.end();\n          return true;\n        }\n        \n        index = matcher.end();\n      }\n      \n      if (str.length() - index == 0) {\n        index = Integer.MAX_VALUE; // mark exhausted\n        return false;\n      }\n      \n      termAtt.setTermBuffer(str, index, str.length() - index);\n      offsetAtt.setOffset(correctOffset(index), correctOffset(str.length()));\n      index = Integer.MAX_VALUE; // mark exhausted\n      return true;\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d085fb336a7208eea2214e5ffcc803960819b60b","date":1270981894,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"solr/src/java/org/apache/solr/analysis/PatternTokenizer#incrementToken().mjava","pathOld":"solr/src/java/org/apache/solr/analysis/PatternTokenizer#incrementToken().mjava","sourceNew":"  @Override\n  public boolean incrementToken() throws IOException {\n    if (index >= str.length()) return false;\n    clearAttributes();\n    if (group >= 0) {\n    \n      // match a specific group\n      while (matcher.find()) {\n        final String match = matcher.group(group);\n        if (match.length() == 0) continue;\n        termAtt.setEmpty().append(match);\n        index = matcher.start(group);\n        offsetAtt.setOffset(correctOffset(index), correctOffset(matcher.end(group)));\n        return true;\n      }\n      \n      index = Integer.MAX_VALUE; // mark exhausted\n      return false;\n      \n    } else {\n    \n      // String.split() functionality\n      while (matcher.find()) {\n        if (matcher.start() - index > 0) {\n          // found a non-zero-length token\n          termAtt.setEmpty().append(str, index, matcher.start());\n          offsetAtt.setOffset(correctOffset(index), correctOffset(matcher.start()));\n          index = matcher.end();\n          return true;\n        }\n        \n        index = matcher.end();\n      }\n      \n      if (str.length() - index == 0) {\n        index = Integer.MAX_VALUE; // mark exhausted\n        return false;\n      }\n      \n      termAtt.setEmpty().append(str, index, str.length());\n      offsetAtt.setOffset(correctOffset(index), correctOffset(str.length()));\n      index = Integer.MAX_VALUE; // mark exhausted\n      return true;\n    }\n  }\n\n","sourceOld":"  @Override\n  public boolean incrementToken() throws IOException {\n    if (index >= str.length()) return false;\n    clearAttributes();\n    if (group >= 0) {\n    \n      // match a specific group\n      while (matcher.find()) {\n        final String match = matcher.group(group);\n        if (match.length() == 0) continue;\n        termAtt.setTermBuffer(match);\n        index = matcher.start(group);\n        offsetAtt.setOffset(correctOffset(index), correctOffset(matcher.end(group)));\n        return true;\n      }\n      \n      index = Integer.MAX_VALUE; // mark exhausted\n      return false;\n      \n    } else {\n    \n      // String.split() functionality\n      while (matcher.find()) {\n        if (matcher.start() - index > 0) {\n          // found a non-zero-length token\n          termAtt.setTermBuffer(str, index, matcher.start() - index);\n          offsetAtt.setOffset(correctOffset(index), correctOffset(matcher.start()));\n          index = matcher.end();\n          return true;\n        }\n        \n        index = matcher.end();\n      }\n      \n      if (str.length() - index == 0) {\n        index = Integer.MAX_VALUE; // mark exhausted\n        return false;\n      }\n      \n      termAtt.setTermBuffer(str, index, str.length() - index);\n      offsetAtt.setOffset(correctOffset(index), correctOffset(str.length()));\n      index = Integer.MAX_VALUE; // mark exhausted\n      return true;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"540f57ba7d9d46ccc6f0157e8b8021a4c969770d","date":1272974241,"type":5,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/pattern/PatternTokenizer#incrementToken().mjava","pathOld":"solr/src/java/org/apache/solr/analysis/PatternTokenizer#incrementToken().mjava","sourceNew":"  @Override\n  public boolean incrementToken() throws IOException {\n    if (index >= str.length()) return false;\n    clearAttributes();\n    if (group >= 0) {\n    \n      // match a specific group\n      while (matcher.find()) {\n        index = matcher.start(group);\n        final int endIndex = matcher.end(group);\n        if (index == endIndex) continue;       \n        termAtt.setEmpty().append(str, index, endIndex);\n        offsetAtt.setOffset(correctOffset(index), correctOffset(endIndex));\n        return true;\n      }\n      \n      index = Integer.MAX_VALUE; // mark exhausted\n      return false;\n      \n    } else {\n    \n      // String.split() functionality\n      while (matcher.find()) {\n        if (matcher.start() - index > 0) {\n          // found a non-zero-length token\n          termAtt.setEmpty().append(str, index, matcher.start());\n          offsetAtt.setOffset(correctOffset(index), correctOffset(matcher.start()));\n          index = matcher.end();\n          return true;\n        }\n        \n        index = matcher.end();\n      }\n      \n      if (str.length() - index == 0) {\n        index = Integer.MAX_VALUE; // mark exhausted\n        return false;\n      }\n      \n      termAtt.setEmpty().append(str, index, str.length());\n      offsetAtt.setOffset(correctOffset(index), correctOffset(str.length()));\n      index = Integer.MAX_VALUE; // mark exhausted\n      return true;\n    }\n  }\n\n","sourceOld":"  @Override\n  public boolean incrementToken() throws IOException {\n    if (index >= str.length()) return false;\n    clearAttributes();\n    if (group >= 0) {\n    \n      // match a specific group\n      while (matcher.find()) {\n        final String match = matcher.group(group);\n        if (match.length() == 0) continue;\n        termAtt.setEmpty().append(match);\n        index = matcher.start(group);\n        offsetAtt.setOffset(correctOffset(index), correctOffset(matcher.end(group)));\n        return true;\n      }\n      \n      index = Integer.MAX_VALUE; // mark exhausted\n      return false;\n      \n    } else {\n    \n      // String.split() functionality\n      while (matcher.find()) {\n        if (matcher.start() - index > 0) {\n          // found a non-zero-length token\n          termAtt.setEmpty().append(str, index, matcher.start());\n          offsetAtt.setOffset(correctOffset(index), correctOffset(matcher.start()));\n          index = matcher.end();\n          return true;\n        }\n        \n        index = matcher.end();\n      }\n      \n      if (str.length() - index == 0) {\n        index = Integer.MAX_VALUE; // mark exhausted\n        return false;\n      }\n      \n      termAtt.setEmpty().append(str, index, str.length());\n      offsetAtt.setOffset(correctOffset(index), correctOffset(str.length()));\n      index = Integer.MAX_VALUE; // mark exhausted\n      return true;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"1da8d55113b689b06716246649de6f62430f15c0":["a89acb2b4321b599bbfa1e802c00c4dbbc8ee6b8","ad94625fb8d088209f46650c8097196fec67f00c"],"893269407f5c988a4b2ee13c7ffc01ec43136c1d":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a89acb2b4321b599bbfa1e802c00c4dbbc8ee6b8":["893269407f5c988a4b2ee13c7ffc01ec43136c1d"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b":[],"540f57ba7d9d46ccc6f0157e8b8021a4c969770d":["d085fb336a7208eea2214e5ffcc803960819b60b"],"ad94625fb8d088209f46650c8097196fec67f00c":["3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b"],"d085fb336a7208eea2214e5ffcc803960819b60b":["1da8d55113b689b06716246649de6f62430f15c0"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["540f57ba7d9d46ccc6f0157e8b8021a4c969770d"]},"commit2Childs":{"1da8d55113b689b06716246649de6f62430f15c0":["d085fb336a7208eea2214e5ffcc803960819b60b"],"893269407f5c988a4b2ee13c7ffc01ec43136c1d":["a89acb2b4321b599bbfa1e802c00c4dbbc8ee6b8"],"a89acb2b4321b599bbfa1e802c00c4dbbc8ee6b8":["1da8d55113b689b06716246649de6f62430f15c0"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["893269407f5c988a4b2ee13c7ffc01ec43136c1d"],"3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b":["ad94625fb8d088209f46650c8097196fec67f00c"],"540f57ba7d9d46ccc6f0157e8b8021a4c969770d":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"ad94625fb8d088209f46650c8097196fec67f00c":["1da8d55113b689b06716246649de6f62430f15c0"],"d085fb336a7208eea2214e5ffcc803960819b60b":["540f57ba7d9d46ccc6f0157e8b8021a4c969770d"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b"],"pathCommit":null}