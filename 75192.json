{"path":"lucene/src/java/org/apache/lucene/index/codecs/lucene40/values/VarDerefBytesImpl.Writer#finishInternal(int).mjava","commits":[{"id":"f9efc72acdea22f5285be0a808f8bba51bb8e367","date":1323217280,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/codecs/lucene40/values/VarDerefBytesImpl.Writer#finishInternal(int).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/values/VarDerefBytesImpl.Writer#finishInternal(int).mjava","sourceNew":"    // Important that we get docCount, in case there were\n    // some last docs that we didn't see\n    @Override\n    public void finishInternal(int docCount) throws IOException {\n      fillDefault(docCount);\n      final int size = hash.size();\n      final long[] addresses = new long[size];\n      final IndexOutput datOut = getOrCreateDataOut();\n      int addr = 0;\n      final BytesRef bytesRef = new BytesRef();\n      for (int i = 0; i < size; i++) {\n        hash.get(i, bytesRef);\n        addresses[i] = addr;\n        addr += writePrefixLength(datOut, bytesRef) + bytesRef.length;\n        datOut.writeBytes(bytesRef.bytes, bytesRef.offset, bytesRef.length);\n      }\n\n      final IndexOutput idxOut = getOrCreateIndexOut();\n      // write the max address to read directly on source load\n      idxOut.writeLong(addr);\n      writeIndex(idxOut, docCount, addresses[addresses.length-1], addresses, docToEntry);\n    }\n\n","sourceOld":"    // Important that we get docCount, in case there were\n    // some last docs that we didn't see\n    @Override\n    public void finishInternal(int docCount) throws IOException {\n      fillDefault(docCount);\n      final int size = hash.size();\n      final long[] addresses = new long[size];\n      final IndexOutput datOut = getOrCreateDataOut();\n      int addr = 0;\n      final BytesRef bytesRef = new BytesRef();\n      for (int i = 0; i < size; i++) {\n        hash.get(i, bytesRef);\n        addresses[i] = addr;\n        addr += writePrefixLength(datOut, bytesRef) + bytesRef.length;\n        datOut.writeBytes(bytesRef.bytes, bytesRef.offset, bytesRef.length);\n      }\n\n      final IndexOutput idxOut = getOrCreateIndexOut();\n      // write the max address to read directly on source load\n      idxOut.writeLong(addr);\n      writeIndex(idxOut, docCount, addresses[addresses.length-1], addresses, docToEntry);\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d638301ad1cfcae567b681b893bc8781f0ee48a5","date":1323801546,"type":1,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/index/codecs/lucene40/values/VarDerefBytesImpl.Writer#finishInternal(int).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/values/VarDerefBytesImpl.Writer#finishInternal(int).mjava","sourceNew":"    // Important that we get docCount, in case there were\n    // some last docs that we didn't see\n    @Override\n    public void finishInternal(int docCount) throws IOException {\n      fillDefault(docCount);\n      final int size = hash.size();\n      final long[] addresses = new long[size];\n      final IndexOutput datOut = getOrCreateDataOut();\n      int addr = 0;\n      final BytesRef bytesRef = new BytesRef();\n      for (int i = 0; i < size; i++) {\n        hash.get(i, bytesRef);\n        addresses[i] = addr;\n        addr += writePrefixLength(datOut, bytesRef) + bytesRef.length;\n        datOut.writeBytes(bytesRef.bytes, bytesRef.offset, bytesRef.length);\n      }\n\n      final IndexOutput idxOut = getOrCreateIndexOut();\n      // write the max address to read directly on source load\n      idxOut.writeLong(addr);\n      writeIndex(idxOut, docCount, addresses[addresses.length-1], addresses, docToEntry);\n    }\n\n","sourceOld":"    // Important that we get docCount, in case there were\n    // some last docs that we didn't see\n    @Override\n    public void finishInternal(int docCount) throws IOException {\n      fillDefault(docCount);\n      final int size = hash.size();\n      final long[] addresses = new long[size];\n      final IndexOutput datOut = getOrCreateDataOut();\n      int addr = 0;\n      final BytesRef bytesRef = new BytesRef();\n      for (int i = 0; i < size; i++) {\n        hash.get(i, bytesRef);\n        addresses[i] = addr;\n        addr += writePrefixLength(datOut, bytesRef) + bytesRef.length;\n        datOut.writeBytes(bytesRef.bytes, bytesRef.offset, bytesRef.length);\n      }\n\n      final IndexOutput idxOut = getOrCreateIndexOut();\n      // write the max address to read directly on source load\n      idxOut.writeLong(addr);\n      writeIndex(idxOut, docCount, addresses[addresses.length-1], addresses, docToEntry);\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a0ae5e3ed1232483b7b8a014f175a5fe43595982","date":1324062192,"type":5,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/codecs/lucene40/values/VarDerefBytesImpl.Writer#finishInternal(int).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/codecs/lucene40/values/VarDerefBytesImpl.Writer#finishInternal(int).mjava","sourceNew":"    // Important that we get docCount, in case there were\n    // some last docs that we didn't see\n    @Override\n    public void finishInternal(int docCount) throws IOException {\n      fillDefault(docCount);\n      final int size = hash.size();\n      final long[] addresses = new long[size];\n      final IndexOutput datOut = getOrCreateDataOut();\n      int addr = 0;\n      final BytesRef bytesRef = new BytesRef();\n      for (int i = 0; i < size; i++) {\n        hash.get(i, bytesRef);\n        addresses[i] = addr;\n        addr += writePrefixLength(datOut, bytesRef) + bytesRef.length;\n        datOut.writeBytes(bytesRef.bytes, bytesRef.offset, bytesRef.length);\n      }\n\n      final IndexOutput idxOut = getOrCreateIndexOut();\n      // write the max address to read directly on source load\n      idxOut.writeLong(addr);\n      writeIndex(idxOut, docCount, addresses[addresses.length-1], addresses, docToEntry);\n    }\n\n","sourceOld":"    // Important that we get docCount, in case there were\n    // some last docs that we didn't see\n    @Override\n    public void finishInternal(int docCount) throws IOException {\n      fillDefault(docCount);\n      final int size = hash.size();\n      final long[] addresses = new long[size];\n      final IndexOutput datOut = getOrCreateDataOut();\n      int addr = 0;\n      final BytesRef bytesRef = new BytesRef();\n      for (int i = 0; i < size; i++) {\n        hash.get(i, bytesRef);\n        addresses[i] = addr;\n        addr += writePrefixLength(datOut, bytesRef) + bytesRef.length;\n        datOut.writeBytes(bytesRef.bytes, bytesRef.offset, bytesRef.length);\n      }\n\n      final IndexOutput idxOut = getOrCreateIndexOut();\n      // write the max address to read directly on source load\n      idxOut.writeLong(addr);\n      writeIndex(idxOut, docCount, addresses[addresses.length-1], addresses, docToEntry);\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"f9efc72acdea22f5285be0a808f8bba51bb8e367":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0ae5e3ed1232483b7b8a014f175a5fe43595982":["d638301ad1cfcae567b681b893bc8781f0ee48a5"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["a0ae5e3ed1232483b7b8a014f175a5fe43595982"],"d638301ad1cfcae567b681b893bc8781f0ee48a5":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","f9efc72acdea22f5285be0a808f8bba51bb8e367"]},"commit2Childs":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["f9efc72acdea22f5285be0a808f8bba51bb8e367","d638301ad1cfcae567b681b893bc8781f0ee48a5"],"f9efc72acdea22f5285be0a808f8bba51bb8e367":["d638301ad1cfcae567b681b893bc8781f0ee48a5"],"a0ae5e3ed1232483b7b8a014f175a5fe43595982":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"d638301ad1cfcae567b681b893bc8781f0ee48a5":["a0ae5e3ed1232483b7b8a014f175a5fe43595982"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}