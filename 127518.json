{"path":"solr/contrib/clustering/src/java/org/apache/solr/handler/clustering/carrot2/LuceneCarrot2TokenizerFactory.ChineseTokenizerFactory.ChineseTokenizer#reset(Reader).mjava","commits":[{"id":"5128b7b3b73fedff05fdc5ea2e6be53c1020bb91","date":1306767085,"type":1,"author":"Steven Rowe","isMerge":true,"pathNew":"solr/contrib/clustering/src/java/org/apache/solr/handler/clustering/carrot2/LuceneCarrot2TokenizerFactory.ChineseTokenizerFactory.ChineseTokenizer#reset(Reader).mjava","pathOld":"solr/contrib/clustering/src/main/java/org/apache/solr/handler/clustering/carrot2/LuceneCarrot2TokenizerFactory.ChineseTokenizerFactory.ChineseTokenizer#reset(Reader).mjava","sourceNew":"\t\t\tpublic void reset(Reader input) throws IOException {\r\n\t\t\t\ttry {\r\n\t\t\t\t\tsentenceTokenizer.reset(input);\r\n\t\t\t\t\twordTokenFilter = (TokenStream) tokenFilterClass.getConstructor(\r\n\t\t\t\t\t\t\tTokenStream.class).newInstance(sentenceTokenizer);\r\n          term = wordTokenFilter.addAttribute(CharTermAttribute.class);\r\n\t\t\t\t} catch (Exception e) {\r\n\t\t\t\t\tthrow ExceptionUtils.wrapAsRuntimeException(e);\r\n\t\t\t\t}\r\n\t\t\t}\r\n\n","sourceOld":"\t\t\tpublic void reset(Reader input) throws IOException {\r\n\t\t\t\ttry {\r\n\t\t\t\t\tsentenceTokenizer.reset(input);\r\n\t\t\t\t\twordTokenFilter = (TokenStream) tokenFilterClass.getConstructor(\r\n\t\t\t\t\t\t\tTokenStream.class).newInstance(sentenceTokenizer);\r\n          term = wordTokenFilter.addAttribute(CharTermAttribute.class);\r\n\t\t\t\t} catch (Exception e) {\r\n\t\t\t\t\tthrow ExceptionUtils.wrapAsRuntimeException(e);\r\n\t\t\t\t}\r\n\t\t\t}\r\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c26f00b574427b55127e869b935845554afde1fa","date":1310252513,"type":1,"author":"Steven Rowe","isMerge":true,"pathNew":"solr/contrib/clustering/src/java/org/apache/solr/handler/clustering/carrot2/LuceneCarrot2TokenizerFactory.ChineseTokenizerFactory.ChineseTokenizer#reset(Reader).mjava","pathOld":"solr/contrib/clustering/src/main/java/org/apache/solr/handler/clustering/carrot2/LuceneCarrot2TokenizerFactory.ChineseTokenizerFactory.ChineseTokenizer#reset(Reader).mjava","sourceNew":"\t\t\tpublic void reset(Reader input) throws IOException {\r\n\t\t\t\ttry {\r\n\t\t\t\t\tsentenceTokenizer.reset(input);\r\n\t\t\t\t\twordTokenFilter = (TokenStream) tokenFilterClass.getConstructor(\r\n\t\t\t\t\t\t\tTokenStream.class).newInstance(sentenceTokenizer);\r\n          term = wordTokenFilter.addAttribute(CharTermAttribute.class);\r\n\t\t\t\t} catch (Exception e) {\r\n\t\t\t\t\tthrow ExceptionUtils.wrapAsRuntimeException(e);\r\n\t\t\t\t}\r\n\t\t\t}\r\n\n","sourceOld":"\t\t\tpublic void reset(Reader input) throws IOException {\r\n\t\t\t\ttry {\r\n\t\t\t\t\tsentenceTokenizer.reset(input);\r\n\t\t\t\t\twordTokenFilter = (TokenStream) tokenFilterClass.getConstructor(\r\n\t\t\t\t\t\t\tTokenStream.class).newInstance(sentenceTokenizer);\r\n          term = wordTokenFilter.addAttribute(CharTermAttribute.class);\r\n\t\t\t\t} catch (Exception e) {\r\n\t\t\t\t\tthrow ExceptionUtils.wrapAsRuntimeException(e);\r\n\t\t\t\t}\r\n\t\t\t}\r\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ef9e7ba08c124ce913ef60415c21ae1ca833d211","date":1323446079,"type":3,"author":"Stanisław Osiński","isMerge":false,"pathNew":"solr/contrib/clustering/src/java/org/apache/solr/handler/clustering/carrot2/LuceneCarrot2TokenizerFactory.ChineseTokenizerFactory.ChineseTokenizer#reset(Reader).mjava","pathOld":"solr/contrib/clustering/src/java/org/apache/solr/handler/clustering/carrot2/LuceneCarrot2TokenizerFactory.ChineseTokenizerFactory.ChineseTokenizer#reset(Reader).mjava","sourceNew":"      public void reset(Reader input) throws IOException {\r\n        try {\r\n          sentenceTokenizer.reset(input);\r\n          wordTokenFilter = (TokenStream) tokenFilterClass.getConstructor(\r\n              TokenStream.class).newInstance(sentenceTokenizer);\r\n          term = wordTokenFilter.addAttribute(CharTermAttribute.class);\r\n        } catch (Exception e) {\r\n          throw ExceptionUtils.wrapAsRuntimeException(e);\r\n        }\r\n      }\r\n\n","sourceOld":"\t\t\tpublic void reset(Reader input) throws IOException {\r\n\t\t\t\ttry {\r\n\t\t\t\t\tsentenceTokenizer.reset(input);\r\n\t\t\t\t\twordTokenFilter = (TokenStream) tokenFilterClass.getConstructor(\r\n\t\t\t\t\t\t\tTokenStream.class).newInstance(sentenceTokenizer);\r\n          term = wordTokenFilter.addAttribute(CharTermAttribute.class);\r\n\t\t\t\t} catch (Exception e) {\r\n\t\t\t\t\tthrow ExceptionUtils.wrapAsRuntimeException(e);\r\n\t\t\t\t}\r\n\t\t\t}\r\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ff99371bc1f34bf1a2ccdb754940ee5fe5cc2565","date":1323540308,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"solr/contrib/clustering/src/java/org/apache/solr/handler/clustering/carrot2/LuceneCarrot2TokenizerFactory.ChineseTokenizerFactory.ChineseTokenizer#reset(Reader).mjava","pathOld":"solr/contrib/clustering/src/java/org/apache/solr/handler/clustering/carrot2/LuceneCarrot2TokenizerFactory.ChineseTokenizerFactory.ChineseTokenizer#reset(Reader).mjava","sourceNew":"      public void reset(Reader input) throws IOException {\r\n        try {\r\n          sentenceTokenizer.reset(input);\r\n          wordTokenFilter = (TokenStream) tokenFilterClass.getConstructor(\r\n              TokenStream.class).newInstance(sentenceTokenizer);\r\n          term = wordTokenFilter.addAttribute(CharTermAttribute.class);\r\n        } catch (Exception e) {\r\n          throw ExceptionUtils.wrapAsRuntimeException(e);\r\n        }\r\n      }\r\n\n","sourceOld":"\t\t\tpublic void reset(Reader input) throws IOException {\r\n\t\t\t\ttry {\r\n\t\t\t\t\tsentenceTokenizer.reset(input);\r\n\t\t\t\t\twordTokenFilter = (TokenStream) tokenFilterClass.getConstructor(\r\n\t\t\t\t\t\t\tTokenStream.class).newInstance(sentenceTokenizer);\r\n          term = wordTokenFilter.addAttribute(CharTermAttribute.class);\r\n\t\t\t\t} catch (Exception e) {\r\n\t\t\t\t\tthrow ExceptionUtils.wrapAsRuntimeException(e);\r\n\t\t\t\t}\r\n\t\t\t}\r\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5a002afd8b1e0d1bbf0debb2ff740b5e77ed8b23","date":1332766738,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"solr/contrib/clustering/src/java/org/apache/solr/handler/clustering/carrot2/LuceneCarrot2TokenizerFactory.ChineseTokenizerFactory.ChineseTokenizer#reset(Reader).mjava","pathOld":"solr/contrib/clustering/src/java/org/apache/solr/handler/clustering/carrot2/LuceneCarrot2TokenizerFactory.ChineseTokenizerFactory.ChineseTokenizer#reset(Reader).mjava","sourceNew":"      public void reset(Reader input) throws IOException {\n        try {\n          sentenceTokenizer.reset(input);\n          wordTokenFilter = (TokenStream) tokenFilterClass.getConstructor(\n              TokenStream.class).newInstance(sentenceTokenizer);\n          term = wordTokenFilter.addAttribute(CharTermAttribute.class);\n        } catch (Exception e) {\n          throw ExceptionUtils.wrapAsRuntimeException(e);\n        }\n      }\n\n","sourceOld":"      public void reset(Reader input) throws IOException {\r\n        try {\r\n          sentenceTokenizer.reset(input);\r\n          wordTokenFilter = (TokenStream) tokenFilterClass.getConstructor(\r\n              TokenStream.class).newInstance(sentenceTokenizer);\r\n          term = wordTokenFilter.addAttribute(CharTermAttribute.class);\r\n        } catch (Exception e) {\r\n          throw ExceptionUtils.wrapAsRuntimeException(e);\r\n        }\r\n      }\r\n\n","bugFix":null,"bugIntro":["4d3e8520fd031bab31fd0e4d480e55958bc45efe"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"4d3e8520fd031bab31fd0e4d480e55958bc45efe","date":1340901565,"type":3,"author":"Steven Rowe","isMerge":false,"pathNew":"solr/contrib/clustering/src/java/org/apache/solr/handler/clustering/carrot2/LuceneCarrot2TokenizerFactory.ChineseTokenizerFactory.ChineseTokenizer#reset(Reader).mjava","pathOld":"solr/contrib/clustering/src/java/org/apache/solr/handler/clustering/carrot2/LuceneCarrot2TokenizerFactory.ChineseTokenizerFactory.ChineseTokenizer#reset(Reader).mjava","sourceNew":"      public void reset(Reader input) {\n        try {\n          sentenceTokenizer.reset(input);\n          wordTokenFilter = (TokenStream) tokenFilterClass.getConstructor(\n              TokenStream.class).newInstance(sentenceTokenizer);\n          term = wordTokenFilter.addAttribute(CharTermAttribute.class);\n        } catch (Exception e) {\n          throw ExceptionUtils.wrapAsRuntimeException(e);\n        }\n      }\n\n","sourceOld":"      public void reset(Reader input) throws IOException {\n        try {\n          sentenceTokenizer.reset(input);\n          wordTokenFilter = (TokenStream) tokenFilterClass.getConstructor(\n              TokenStream.class).newInstance(sentenceTokenizer);\n          term = wordTokenFilter.addAttribute(CharTermAttribute.class);\n        } catch (Exception e) {\n          throw ExceptionUtils.wrapAsRuntimeException(e);\n        }\n      }\n\n","bugFix":["5a002afd8b1e0d1bbf0debb2ff740b5e77ed8b23"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b893541afcaa76dcbac2fcd24bbfa05ca6b41129","date":1342450620,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"solr/contrib/clustering/src/java/org/apache/solr/handler/clustering/carrot2/LuceneCarrot2TokenizerFactory.ChineseTokenizerFactory.ChineseTokenizer#reset(Reader).mjava","pathOld":"solr/contrib/clustering/src/java/org/apache/solr/handler/clustering/carrot2/LuceneCarrot2TokenizerFactory.ChineseTokenizerFactory.ChineseTokenizer#reset(Reader).mjava","sourceNew":"      public void reset(Reader input) {\n        try {\n          sentenceTokenizer.setReader(input);\n          wordTokenFilter = (TokenStream) tokenFilterClass.getConstructor(\n              TokenStream.class).newInstance(sentenceTokenizer);\n          term = wordTokenFilter.addAttribute(CharTermAttribute.class);\n        } catch (Exception e) {\n          throw ExceptionUtils.wrapAsRuntimeException(e);\n        }\n      }\n\n","sourceOld":"      public void reset(Reader input) {\n        try {\n          sentenceTokenizer.reset(input);\n          wordTokenFilter = (TokenStream) tokenFilterClass.getConstructor(\n              TokenStream.class).newInstance(sentenceTokenizer);\n          term = wordTokenFilter.addAttribute(CharTermAttribute.class);\n        } catch (Exception e) {\n          throw ExceptionUtils.wrapAsRuntimeException(e);\n        }\n      }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fe33227f6805edab2036cbb80645cc4e2d1fa424","date":1342713534,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"solr/contrib/clustering/src/java/org/apache/solr/handler/clustering/carrot2/LuceneCarrot2TokenizerFactory.ChineseTokenizerFactory.ChineseTokenizer#reset(Reader).mjava","pathOld":"solr/contrib/clustering/src/java/org/apache/solr/handler/clustering/carrot2/LuceneCarrot2TokenizerFactory.ChineseTokenizerFactory.ChineseTokenizer#reset(Reader).mjava","sourceNew":"      public void reset(Reader input) {\n        try {\n          sentenceTokenizer.setReader(input);\n          wordTokenFilter = (TokenStream) tokenFilterClass.getConstructor(\n              TokenStream.class).newInstance(sentenceTokenizer);\n          term = wordTokenFilter.addAttribute(CharTermAttribute.class);\n        } catch (Exception e) {\n          throw ExceptionUtils.wrapAsRuntimeException(e);\n        }\n      }\n\n","sourceOld":"      public void reset(Reader input) throws IOException {\n        try {\n          sentenceTokenizer.reset(input);\n          wordTokenFilter = (TokenStream) tokenFilterClass.getConstructor(\n              TokenStream.class).newInstance(sentenceTokenizer);\n          term = wordTokenFilter.addAttribute(CharTermAttribute.class);\n        } catch (Exception e) {\n          throw ExceptionUtils.wrapAsRuntimeException(e);\n        }\n      }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"aba371508186796cc6151d8223a5b4e16d02e26e","date":1343474871,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"solr/contrib/clustering/src/java/org/apache/solr/handler/clustering/carrot2/LuceneCarrot2TokenizerFactory.ChineseTokenizerFactory.ChineseTokenizer#reset(Reader).mjava","pathOld":"solr/contrib/clustering/src/java/org/apache/solr/handler/clustering/carrot2/LuceneCarrot2TokenizerFactory.ChineseTokenizerFactory.ChineseTokenizer#reset(Reader).mjava","sourceNew":"      public void reset(Reader input) {\n        try {\n          sentenceTokenizer.setReader(input);\n          wordTokenFilter = (TokenStream) tokenFilterClass.getConstructor(\n              TokenStream.class).newInstance(sentenceTokenizer);\n          term = wordTokenFilter.addAttribute(CharTermAttribute.class);\n        } catch (Exception e) {\n          throw ExceptionUtils.wrapAsRuntimeException(e);\n        }\n      }\n\n","sourceOld":"      public void reset(Reader input) {\n        try {\n          sentenceTokenizer.reset(input);\n          wordTokenFilter = (TokenStream) tokenFilterClass.getConstructor(\n              TokenStream.class).newInstance(sentenceTokenizer);\n          term = wordTokenFilter.addAttribute(CharTermAttribute.class);\n        } catch (Exception e) {\n          throw ExceptionUtils.wrapAsRuntimeException(e);\n        }\n      }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7530de27b87b961b51f01bd1299b7004d46e8823","date":1355236261,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"solr/contrib/clustering/src/java/org/apache/solr/handler/clustering/carrot2/LuceneCarrot2TokenizerFactory.ChineseTokenizerFactory.ChineseTokenizer#reset(Reader).mjava","pathOld":"solr/contrib/clustering/src/java/org/apache/solr/handler/clustering/carrot2/LuceneCarrot2TokenizerFactory.ChineseTokenizerFactory.ChineseTokenizer#reset(Reader).mjava","sourceNew":"      @Override\n      public void reset(Reader input) {\n        try {\n          sentenceTokenizer.setReader(input);\n          wordTokenFilter = (TokenStream) tokenFilterClass.getConstructor(\n              TokenStream.class).newInstance(sentenceTokenizer);\n          term = wordTokenFilter.addAttribute(CharTermAttribute.class);\n        } catch (Exception e) {\n          throw ExceptionUtils.wrapAsRuntimeException(e);\n        }\n      }\n\n","sourceOld":"      public void reset(Reader input) {\n        try {\n          sentenceTokenizer.setReader(input);\n          wordTokenFilter = (TokenStream) tokenFilterClass.getConstructor(\n              TokenStream.class).newInstance(sentenceTokenizer);\n          term = wordTokenFilter.addAttribute(CharTermAttribute.class);\n        } catch (Exception e) {\n          throw ExceptionUtils.wrapAsRuntimeException(e);\n        }\n      }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d3fcb70cf561547c7bb1506e0cf32ca7b1287064","date":1357616416,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"solr/contrib/clustering/src/java/org/apache/solr/handler/clustering/carrot2/LuceneCarrot2TokenizerFactory.ChineseTokenizerFactory.ChineseTokenizer#reset(Reader).mjava","pathOld":"solr/contrib/clustering/src/java/org/apache/solr/handler/clustering/carrot2/LuceneCarrot2TokenizerFactory.ChineseTokenizerFactory.ChineseTokenizer#reset(Reader).mjava","sourceNew":"      @Override\n      public void reset(Reader input) {\n        try {\n          sentenceTokenizer.setReader(input);\n          wordTokenFilter = (TokenStream) tokenFilterClass.getConstructor(\n              TokenStream.class).newInstance(sentenceTokenizer);\n          term = wordTokenFilter.addAttribute(CharTermAttribute.class);\n        } catch (Exception e) {\n          throw ExceptionUtils.wrapAsRuntimeException(e);\n        }\n      }\n\n","sourceOld":"      public void reset(Reader input) {\n        try {\n          sentenceTokenizer.setReader(input);\n          wordTokenFilter = (TokenStream) tokenFilterClass.getConstructor(\n              TokenStream.class).newInstance(sentenceTokenizer);\n          term = wordTokenFilter.addAttribute(CharTermAttribute.class);\n        } catch (Exception e) {\n          throw ExceptionUtils.wrapAsRuntimeException(e);\n        }\n      }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"d3fcb70cf561547c7bb1506e0cf32ca7b1287064":["b893541afcaa76dcbac2fcd24bbfa05ca6b41129","7530de27b87b961b51f01bd1299b7004d46e8823"],"5a002afd8b1e0d1bbf0debb2ff740b5e77ed8b23":["ef9e7ba08c124ce913ef60415c21ae1ca833d211"],"c26f00b574427b55127e869b935845554afde1fa":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","5128b7b3b73fedff05fdc5ea2e6be53c1020bb91"],"ef9e7ba08c124ce913ef60415c21ae1ca833d211":["c26f00b574427b55127e869b935845554afde1fa"],"b893541afcaa76dcbac2fcd24bbfa05ca6b41129":["4d3e8520fd031bab31fd0e4d480e55958bc45efe"],"aba371508186796cc6151d8223a5b4e16d02e26e":["4d3e8520fd031bab31fd0e4d480e55958bc45efe","b893541afcaa76dcbac2fcd24bbfa05ca6b41129"],"5128b7b3b73fedff05fdc5ea2e6be53c1020bb91":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"fe33227f6805edab2036cbb80645cc4e2d1fa424":["5a002afd8b1e0d1bbf0debb2ff740b5e77ed8b23","b893541afcaa76dcbac2fcd24bbfa05ca6b41129"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"ff99371bc1f34bf1a2ccdb754940ee5fe5cc2565":["c26f00b574427b55127e869b935845554afde1fa","ef9e7ba08c124ce913ef60415c21ae1ca833d211"],"4d3e8520fd031bab31fd0e4d480e55958bc45efe":["5a002afd8b1e0d1bbf0debb2ff740b5e77ed8b23"],"7530de27b87b961b51f01bd1299b7004d46e8823":["b893541afcaa76dcbac2fcd24bbfa05ca6b41129"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["7530de27b87b961b51f01bd1299b7004d46e8823"]},"commit2Childs":{"d3fcb70cf561547c7bb1506e0cf32ca7b1287064":[],"5a002afd8b1e0d1bbf0debb2ff740b5e77ed8b23":["fe33227f6805edab2036cbb80645cc4e2d1fa424","4d3e8520fd031bab31fd0e4d480e55958bc45efe"],"c26f00b574427b55127e869b935845554afde1fa":["ef9e7ba08c124ce913ef60415c21ae1ca833d211","ff99371bc1f34bf1a2ccdb754940ee5fe5cc2565"],"ef9e7ba08c124ce913ef60415c21ae1ca833d211":["5a002afd8b1e0d1bbf0debb2ff740b5e77ed8b23","ff99371bc1f34bf1a2ccdb754940ee5fe5cc2565"],"b893541afcaa76dcbac2fcd24bbfa05ca6b41129":["d3fcb70cf561547c7bb1506e0cf32ca7b1287064","aba371508186796cc6151d8223a5b4e16d02e26e","fe33227f6805edab2036cbb80645cc4e2d1fa424","7530de27b87b961b51f01bd1299b7004d46e8823"],"aba371508186796cc6151d8223a5b4e16d02e26e":[],"5128b7b3b73fedff05fdc5ea2e6be53c1020bb91":["c26f00b574427b55127e869b935845554afde1fa"],"fe33227f6805edab2036cbb80645cc4e2d1fa424":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["c26f00b574427b55127e869b935845554afde1fa","5128b7b3b73fedff05fdc5ea2e6be53c1020bb91"],"ff99371bc1f34bf1a2ccdb754940ee5fe5cc2565":[],"4d3e8520fd031bab31fd0e4d480e55958bc45efe":["b893541afcaa76dcbac2fcd24bbfa05ca6b41129","aba371508186796cc6151d8223a5b4e16d02e26e"],"7530de27b87b961b51f01bd1299b7004d46e8823":["d3fcb70cf561547c7bb1506e0cf32ca7b1287064","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["d3fcb70cf561547c7bb1506e0cf32ca7b1287064","aba371508186796cc6151d8223a5b4e16d02e26e","fe33227f6805edab2036cbb80645cc4e2d1fa424","ff99371bc1f34bf1a2ccdb754940ee5fe5cc2565","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}