{"path":"solr/core/src/java/org/apache/solr/util/ExportTool.MultiThreadedRunner#exportDocs().mjava","commits":[{"id":"b373db031e25f03ad6783efcfb77809dcd963565","date":1565686445,"type":0,"author":"noble","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/util/ExportTool.MultiThreadedRunner#exportDocs().mjava","pathOld":"/dev/null","sourceNew":"    @Override\n    void exportDocs() throws Exception {\n      sink = getSink();\n      fetchUniqueKey();\n      ClusterStateProvider stateProvider = solrClient.getClusterStateProvider();\n      DocCollection coll = stateProvider.getCollection(this.coll);\n      Map<String, Slice> m = coll.getSlicesMap();\n      producerThreadpool = ExecutorUtil.newMDCAwareFixedThreadPool(m.size(),\n          new DefaultSolrThreadFactory(\"solrcli-exporter-producers\"));\n      consumerThreadpool = ExecutorUtil.newMDCAwareFixedThreadPool(1,\n          new DefaultSolrThreadFactory(\"solrcli-exporter-consumer\"));\n      sink.start();\n      CountDownLatch consumerlatch = new CountDownLatch(1);\n      try {\n        addConsumer(consumerlatch);\n        addProducers(m);\n        if (output != null) {\n          output.println(\"NO of shards : \" + corehandlers.size());\n        }\n        CountDownLatch producerLatch = new CountDownLatch(corehandlers.size());\n        corehandlers.forEach((s, coreHandler) -> producerThreadpool.submit(() -> {\n          try {\n            coreHandler.exportDocsFromCore();\n          } catch (Exception e) {\n            if(output != null) output.println(\"Error exporting docs from : \"+s);\n\n          }\n          producerLatch.countDown();\n        }));\n\n        producerLatch.await();\n        queue.offer(EOFDOC, 10, TimeUnit.SECONDS);\n        consumerlatch.await();\n      } finally {\n        sink.end();\n        solrClient.close();\n        producerThreadpool.shutdownNow();\n        consumerThreadpool.shutdownNow();\n        if (failed) {\n          try {\n            Files.delete(new File(out).toPath());\n          } catch (IOException e) {\n            //ignore\n          }\n        }\n      }\n    }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"161e330a2c1ea9c6baa3615ab380472a4ae80749","date":1582252910,"type":3,"author":"Noble Paul","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/util/ExportTool.MultiThreadedRunner#exportDocs().mjava","pathOld":"solr/core/src/java/org/apache/solr/util/ExportTool.MultiThreadedRunner#exportDocs().mjava","sourceNew":"    @Override\n    @SuppressForbidden(reason = \"Need to print out time\")\n    void exportDocs() throws Exception {\n      sink = getSink();\n      fetchUniqueKey();\n      ClusterStateProvider stateProvider = solrClient.getClusterStateProvider();\n      DocCollection coll = stateProvider.getCollection(this.coll);\n      Map<String, Slice> m = coll.getSlicesMap();\n      producerThreadpool = ExecutorUtil.newMDCAwareFixedThreadPool(m.size(),\n          new DefaultSolrThreadFactory(\"solrcli-exporter-producers\"));\n      consumerThreadpool = ExecutorUtil.newMDCAwareFixedThreadPool(1,\n          new DefaultSolrThreadFactory(\"solrcli-exporter-consumer\"));\n      sink.start();\n      CountDownLatch consumerlatch = new CountDownLatch(1);\n      try {\n        addConsumer(consumerlatch);\n        addProducers(m);\n        if (output != null) {\n          output.println(\"NO: of shards : \" + corehandlers.size());\n        }\n        CountDownLatch producerLatch = new CountDownLatch(corehandlers.size());\n        corehandlers.forEach((s, coreHandler) -> producerThreadpool.submit(() -> {\n          try {\n            coreHandler.exportDocsFromCore();\n          } catch (Exception e) {\n            if(output != null) output.println(\"Error exporting docs from : \"+s);\n\n          }\n          producerLatch.countDown();\n        }));\n\n        producerLatch.await();\n        queue.offer(EOFDOC, 10, TimeUnit.SECONDS);\n        consumerlatch.await();\n      } finally {\n        sink.end();\n        solrClient.close();\n        producerThreadpool.shutdownNow();\n        consumerThreadpool.shutdownNow();\n        if (failed) {\n          try {\n            Files.delete(new File(out).toPath());\n          } catch (IOException e) {\n            //ignore\n          }\n        }\n        System.out.println(\"\\nTotal Docs exported: \"+ (docsWritten.get() -1)+\n            \". Time taken: \"+( (System.currentTimeMillis() - startTime)/1000) + \"secs\");\n      }\n    }\n\n","sourceOld":"    @Override\n    void exportDocs() throws Exception {\n      sink = getSink();\n      fetchUniqueKey();\n      ClusterStateProvider stateProvider = solrClient.getClusterStateProvider();\n      DocCollection coll = stateProvider.getCollection(this.coll);\n      Map<String, Slice> m = coll.getSlicesMap();\n      producerThreadpool = ExecutorUtil.newMDCAwareFixedThreadPool(m.size(),\n          new DefaultSolrThreadFactory(\"solrcli-exporter-producers\"));\n      consumerThreadpool = ExecutorUtil.newMDCAwareFixedThreadPool(1,\n          new DefaultSolrThreadFactory(\"solrcli-exporter-consumer\"));\n      sink.start();\n      CountDownLatch consumerlatch = new CountDownLatch(1);\n      try {\n        addConsumer(consumerlatch);\n        addProducers(m);\n        if (output != null) {\n          output.println(\"NO of shards : \" + corehandlers.size());\n        }\n        CountDownLatch producerLatch = new CountDownLatch(corehandlers.size());\n        corehandlers.forEach((s, coreHandler) -> producerThreadpool.submit(() -> {\n          try {\n            coreHandler.exportDocsFromCore();\n          } catch (Exception e) {\n            if(output != null) output.println(\"Error exporting docs from : \"+s);\n\n          }\n          producerLatch.countDown();\n        }));\n\n        producerLatch.await();\n        queue.offer(EOFDOC, 10, TimeUnit.SECONDS);\n        consumerlatch.await();\n      } finally {\n        sink.end();\n        solrClient.close();\n        producerThreadpool.shutdownNow();\n        consumerThreadpool.shutdownNow();\n        if (failed) {\n          try {\n            Files.delete(new File(out).toPath());\n          } catch (IOException e) {\n            //ignore\n          }\n        }\n      }\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fb03700c9690d16b15fb4f56f6ec36b128fd894e","date":1586745995,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/util/ExportTool.MultiThreadedRunner#exportDocs().mjava","pathOld":"solr/core/src/java/org/apache/solr/util/ExportTool.MultiThreadedRunner#exportDocs().mjava","sourceNew":"    @Override\n    @SuppressForbidden(reason = \"Need to print out time\")\n    void exportDocs() throws Exception {\n      sink = getSink();\n      fetchUniqueKey();\n      ClusterStateProvider stateProvider = solrClient.getClusterStateProvider();\n      DocCollection coll = stateProvider.getCollection(this.coll);\n      Map<String, Slice> m = coll.getSlicesMap();\n      producerThreadpool = ExecutorUtil.newMDCAwareFixedThreadPool(m.size(),\n          new SolrNamedThreadFactory(\"solrcli-exporter-producers\"));\n      consumerThreadpool = ExecutorUtil.newMDCAwareFixedThreadPool(1,\n          new SolrNamedThreadFactory(\"solrcli-exporter-consumer\"));\n      sink.start();\n      CountDownLatch consumerlatch = new CountDownLatch(1);\n      try {\n        addConsumer(consumerlatch);\n        addProducers(m);\n        if (output != null) {\n          output.println(\"NO: of shards : \" + corehandlers.size());\n        }\n        CountDownLatch producerLatch = new CountDownLatch(corehandlers.size());\n        corehandlers.forEach((s, coreHandler) -> producerThreadpool.submit(() -> {\n          try {\n            coreHandler.exportDocsFromCore();\n          } catch (Exception e) {\n            if(output != null) output.println(\"Error exporting docs from : \"+s);\n\n          }\n          producerLatch.countDown();\n        }));\n\n        producerLatch.await();\n        queue.offer(EOFDOC, 10, TimeUnit.SECONDS);\n        consumerlatch.await();\n      } finally {\n        sink.end();\n        solrClient.close();\n        producerThreadpool.shutdownNow();\n        consumerThreadpool.shutdownNow();\n        if (failed) {\n          try {\n            Files.delete(new File(out).toPath());\n          } catch (IOException e) {\n            //ignore\n          }\n        }\n        System.out.println(\"\\nTotal Docs exported: \"+ (docsWritten.get() -1)+\n            \". Time taken: \"+( (System.currentTimeMillis() - startTime)/1000) + \"secs\");\n      }\n    }\n\n","sourceOld":"    @Override\n    @SuppressForbidden(reason = \"Need to print out time\")\n    void exportDocs() throws Exception {\n      sink = getSink();\n      fetchUniqueKey();\n      ClusterStateProvider stateProvider = solrClient.getClusterStateProvider();\n      DocCollection coll = stateProvider.getCollection(this.coll);\n      Map<String, Slice> m = coll.getSlicesMap();\n      producerThreadpool = ExecutorUtil.newMDCAwareFixedThreadPool(m.size(),\n          new DefaultSolrThreadFactory(\"solrcli-exporter-producers\"));\n      consumerThreadpool = ExecutorUtil.newMDCAwareFixedThreadPool(1,\n          new DefaultSolrThreadFactory(\"solrcli-exporter-consumer\"));\n      sink.start();\n      CountDownLatch consumerlatch = new CountDownLatch(1);\n      try {\n        addConsumer(consumerlatch);\n        addProducers(m);\n        if (output != null) {\n          output.println(\"NO: of shards : \" + corehandlers.size());\n        }\n        CountDownLatch producerLatch = new CountDownLatch(corehandlers.size());\n        corehandlers.forEach((s, coreHandler) -> producerThreadpool.submit(() -> {\n          try {\n            coreHandler.exportDocsFromCore();\n          } catch (Exception e) {\n            if(output != null) output.println(\"Error exporting docs from : \"+s);\n\n          }\n          producerLatch.countDown();\n        }));\n\n        producerLatch.await();\n        queue.offer(EOFDOC, 10, TimeUnit.SECONDS);\n        consumerlatch.await();\n      } finally {\n        sink.end();\n        solrClient.close();\n        producerThreadpool.shutdownNow();\n        consumerThreadpool.shutdownNow();\n        if (failed) {\n          try {\n            Files.delete(new File(out).toPath());\n          } catch (IOException e) {\n            //ignore\n          }\n        }\n        System.out.println(\"\\nTotal Docs exported: \"+ (docsWritten.get() -1)+\n            \". Time taken: \"+( (System.currentTimeMillis() - startTime)/1000) + \"secs\");\n      }\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"b373db031e25f03ad6783efcfb77809dcd963565":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"fb03700c9690d16b15fb4f56f6ec36b128fd894e":["161e330a2c1ea9c6baa3615ab380472a4ae80749"],"161e330a2c1ea9c6baa3615ab380472a4ae80749":["b373db031e25f03ad6783efcfb77809dcd963565"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["fb03700c9690d16b15fb4f56f6ec36b128fd894e"]},"commit2Childs":{"b373db031e25f03ad6783efcfb77809dcd963565":["161e330a2c1ea9c6baa3615ab380472a4ae80749"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["b373db031e25f03ad6783efcfb77809dcd963565"],"fb03700c9690d16b15fb4f56f6ec36b128fd894e":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"161e330a2c1ea9c6baa3615ab380472a4ae80749":["fb03700c9690d16b15fb4f56f6ec36b128fd894e"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}