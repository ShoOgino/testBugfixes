{"path":"solr/core/src/test/org/apache/solr/cloud/SliceStateUpdateTest#testSliceStateUpdate().mjava","commits":[{"id":"630b72110afca0a13a755e07ef8a4d764afb52aa","date":1361202100,"type":0,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/SliceStateUpdateTest#testSliceStateUpdate().mjava","pathOld":"/dev/null","sourceNew":"  @Test\n  public void testSliceStateUpdate() throws Exception {\n    System.setProperty(\"solrcloud.update.delay\", \"1\");\n    \n    /* Get ClusterState, update slice state and publish it to Zookeeper */\n\n    ClusterState clusterState = container1.getZkController().getClusterState();\n    Map<String, DocCollection> collectionStates =\n        new LinkedHashMap<String, DocCollection>(clusterState.getCollectionStates());\n\n    Map<String, Slice> slicesMap = clusterState.getSlicesMap(\"collection1\");\n    Map<String, Object> props = new HashMap<String, Object>(1);\n    Slice slice = slicesMap.get(\"shard1\");\n    Map<String, Object> prop = slice.getProperties();\n    prop.put(\"state\", \"inactive\");\n    Slice newSlice = new Slice(slice.getName(), slice.getReplicasMap(), prop);\n    slicesMap.put(newSlice.getName(), newSlice);\n    props.put(DocCollection.DOC_ROUTER, ImplicitDocRouter.NAME);\n\n    DocCollection coll = new DocCollection(\"collection1\", slicesMap, props, DocRouter.DEFAULT);\n    collectionStates.put(\"collection1\", coll);\n    SolrZkClient zkClient = new SolrZkClient(zkServer.getZkAddress(),\n        AbstractZkTestCase.TIMEOUT);\n\n    ClusterState newState = new ClusterState(clusterState.getLiveNodes(), collectionStates);\n    zkClient.setData(ZkStateReader.CLUSTER_STATE,\n        ZkStateReader.toJSON(newState), true);\n    zkClient.close();\n    \n    /* Read state from another container and confirm the change */\n    ZkController zkController2 = container2.getZkController();\n    ClusterState clusterState2 = null;\n    Map<String, Slice> slices = null;\n    for (int i = 75; i > 0; i--) {\n      clusterState2 = zkController2.getClusterState();\n      slices = clusterState2.getAllSlicesMap(\"collection1\");\n      if (slices != null && slices.containsKey(\"shard1\")\n          && slices.get(\"shard1\").getState().equals(\"inactive\")) {\n        break;\n      }\n      Thread.sleep(500);\n    }\n\n    assertNotNull(slices);\n\n    assertEquals(\"shard1\", slices.get(\"shard1\").getName());\n    assertEquals(\"inactive\", slices.get(\"shard1\").getState());\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3dea5c39096a2ee9e162e41aff22e4d608743435","date":1363178722,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/SliceStateUpdateTest#testSliceStateUpdate().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/SliceStateUpdateTest#testSliceStateUpdate().mjava","sourceNew":"  @Test\n  public void testSliceStateUpdate() throws Exception {\n    System.setProperty(\"solrcloud.update.delay\", \"1\");\n    \n    /* Get ClusterState, update slice state and publish it to Zookeeper */\n\n    ClusterState clusterState = container1.getZkController().getClusterState();\n    Map<String, DocCollection> collectionStates =\n        new LinkedHashMap<String, DocCollection>(clusterState.getCollectionStates());\n\n    Map<String, Slice> slicesMap = clusterState.getSlicesMap(\"collection1\");\n    Map<String, Object> props = new HashMap<String, Object>(1);\n    Slice slice = slicesMap.get(\"shard1\");\n    Map<String, Object> prop = slice.getProperties();\n    prop.put(\"state\", \"inactive\");\n    Slice newSlice = new Slice(slice.getName(), slice.getReplicasMap(), prop);\n    slicesMap.put(newSlice.getName(), newSlice);\n    props.put(DocCollection.DOC_ROUTER, ImplicitDocRouter.NAME);\n\n    DocCollection coll = new DocCollection(\"collection1\", slicesMap, props, DocRouter.DEFAULT);\n    collectionStates.put(\"collection1\", coll);\n    SolrZkClient zkClient = new SolrZkClient(zkServer.getZkAddress(),\n        AbstractZkTestCase.TIMEOUT);\n\n    ClusterState newState = new ClusterState(clusterState.getLiveNodes(), collectionStates);\n    zkClient.setData(ZkStateReader.CLUSTER_STATE,\n        ZkStateReader.toJSON(newState), true);\n    zkClient.close();\n    \n    /* Read state from another container and confirm the change */\n    ZkController zkController2 = container2.getZkController();\n    ClusterState clusterState2 = null;\n    Map<String, Slice> slices = null;\n    for (int i = 75; i > 0; i--) {\n      clusterState2 = zkController2.getClusterState();\n      slices = clusterState2.getSlicesMap(\"collection1\");\n      if (slices != null && slices.containsKey(\"shard1\")\n          && slices.get(\"shard1\").getState().equals(\"inactive\")) {\n        break;\n      }\n      Thread.sleep(500);\n    }\n\n    assertNotNull(slices);\n\n    assertEquals(\"shard1\", slices.get(\"shard1\").getName());\n    assertEquals(\"inactive\", slices.get(\"shard1\").getState());\n  }\n\n","sourceOld":"  @Test\n  public void testSliceStateUpdate() throws Exception {\n    System.setProperty(\"solrcloud.update.delay\", \"1\");\n    \n    /* Get ClusterState, update slice state and publish it to Zookeeper */\n\n    ClusterState clusterState = container1.getZkController().getClusterState();\n    Map<String, DocCollection> collectionStates =\n        new LinkedHashMap<String, DocCollection>(clusterState.getCollectionStates());\n\n    Map<String, Slice> slicesMap = clusterState.getSlicesMap(\"collection1\");\n    Map<String, Object> props = new HashMap<String, Object>(1);\n    Slice slice = slicesMap.get(\"shard1\");\n    Map<String, Object> prop = slice.getProperties();\n    prop.put(\"state\", \"inactive\");\n    Slice newSlice = new Slice(slice.getName(), slice.getReplicasMap(), prop);\n    slicesMap.put(newSlice.getName(), newSlice);\n    props.put(DocCollection.DOC_ROUTER, ImplicitDocRouter.NAME);\n\n    DocCollection coll = new DocCollection(\"collection1\", slicesMap, props, DocRouter.DEFAULT);\n    collectionStates.put(\"collection1\", coll);\n    SolrZkClient zkClient = new SolrZkClient(zkServer.getZkAddress(),\n        AbstractZkTestCase.TIMEOUT);\n\n    ClusterState newState = new ClusterState(clusterState.getLiveNodes(), collectionStates);\n    zkClient.setData(ZkStateReader.CLUSTER_STATE,\n        ZkStateReader.toJSON(newState), true);\n    zkClient.close();\n    \n    /* Read state from another container and confirm the change */\n    ZkController zkController2 = container2.getZkController();\n    ClusterState clusterState2 = null;\n    Map<String, Slice> slices = null;\n    for (int i = 75; i > 0; i--) {\n      clusterState2 = zkController2.getClusterState();\n      slices = clusterState2.getAllSlicesMap(\"collection1\");\n      if (slices != null && slices.containsKey(\"shard1\")\n          && slices.get(\"shard1\").getState().equals(\"inactive\")) {\n        break;\n      }\n      Thread.sleep(500);\n    }\n\n    assertNotNull(slices);\n\n    assertEquals(\"shard1\", slices.get(\"shard1\").getName());\n    assertEquals(\"inactive\", slices.get(\"shard1\").getState());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8289f39d5383ee10f1ab15486657badbc1c970ee","date":1363183232,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/SliceStateUpdateTest#testSliceStateUpdate().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/SliceStateUpdateTest#testSliceStateUpdate().mjava","sourceNew":"  @Test\n  public void testSliceStateUpdate() throws Exception {\n    System.setProperty(\"solrcloud.update.delay\", \"1\");\n    \n    /* Get ClusterState, update slice state and publish it to Zookeeper */\n\n    ClusterState clusterState = container1.getZkController().getClusterState();\n    Map<String, DocCollection> collectionStates =\n        new LinkedHashMap<String, DocCollection>(clusterState.getCollectionStates());\n\n    Map<String, Slice> slicesMap = clusterState.getSlicesMap(\"collection1\");\n    Map<String, Object> props = new HashMap<String, Object>(1);\n    Slice slice = slicesMap.get(\"shard1\");\n    Map<String, Object> prop = slice.getProperties();\n    prop.put(\"state\", \"inactive\");\n    Slice newSlice = new Slice(slice.getName(), slice.getReplicasMap(), prop);\n    slicesMap.put(newSlice.getName(), newSlice);\n    props.put(DocCollection.DOC_ROUTER, ImplicitDocRouter.NAME);\n\n    DocCollection coll = new DocCollection(\"collection1\", slicesMap, props, DocRouter.DEFAULT);\n    collectionStates.put(\"collection1\", coll);\n    SolrZkClient zkClient = new SolrZkClient(zkServer.getZkAddress(),\n        AbstractZkTestCase.TIMEOUT);\n\n    ClusterState newState = new ClusterState(clusterState.getLiveNodes(), collectionStates);\n    zkClient.setData(ZkStateReader.CLUSTER_STATE,\n        ZkStateReader.toJSON(newState), true);\n    zkClient.close();\n    \n    /* Read state from another container and confirm the change */\n    ZkController zkController2 = container2.getZkController();\n    ClusterState clusterState2 = null;\n    Map<String, Slice> slices = null;\n    for (int i = 75; i > 0; i--) {\n      clusterState2 = zkController2.getClusterState();\n      slices = clusterState2.getAllSlicesMap(\"collection1\");\n      if (slices != null && slices.containsKey(\"shard1\")\n          && slices.get(\"shard1\").getState().equals(\"inactive\")) {\n        break;\n      }\n      Thread.sleep(500);\n    }\n\n    assertNotNull(slices);\n\n    assertEquals(\"shard1\", slices.get(\"shard1\").getName());\n    assertEquals(\"inactive\", slices.get(\"shard1\").getState());\n  }\n\n","sourceOld":"  @Test\n  public void testSliceStateUpdate() throws Exception {\n    System.setProperty(\"solrcloud.update.delay\", \"1\");\n    \n    /* Get ClusterState, update slice state and publish it to Zookeeper */\n\n    ClusterState clusterState = container1.getZkController().getClusterState();\n    Map<String, DocCollection> collectionStates =\n        new LinkedHashMap<String, DocCollection>(clusterState.getCollectionStates());\n\n    Map<String, Slice> slicesMap = clusterState.getSlicesMap(\"collection1\");\n    Map<String, Object> props = new HashMap<String, Object>(1);\n    Slice slice = slicesMap.get(\"shard1\");\n    Map<String, Object> prop = slice.getProperties();\n    prop.put(\"state\", \"inactive\");\n    Slice newSlice = new Slice(slice.getName(), slice.getReplicasMap(), prop);\n    slicesMap.put(newSlice.getName(), newSlice);\n    props.put(DocCollection.DOC_ROUTER, ImplicitDocRouter.NAME);\n\n    DocCollection coll = new DocCollection(\"collection1\", slicesMap, props, DocRouter.DEFAULT);\n    collectionStates.put(\"collection1\", coll);\n    SolrZkClient zkClient = new SolrZkClient(zkServer.getZkAddress(),\n        AbstractZkTestCase.TIMEOUT);\n\n    ClusterState newState = new ClusterState(clusterState.getLiveNodes(), collectionStates);\n    zkClient.setData(ZkStateReader.CLUSTER_STATE,\n        ZkStateReader.toJSON(newState), true);\n    zkClient.close();\n    \n    /* Read state from another container and confirm the change */\n    ZkController zkController2 = container2.getZkController();\n    ClusterState clusterState2 = null;\n    Map<String, Slice> slices = null;\n    for (int i = 75; i > 0; i--) {\n      clusterState2 = zkController2.getClusterState();\n      slices = clusterState2.getSlicesMap(\"collection1\");\n      if (slices != null && slices.containsKey(\"shard1\")\n          && slices.get(\"shard1\").getState().equals(\"inactive\")) {\n        break;\n      }\n      Thread.sleep(500);\n    }\n\n    assertNotNull(slices);\n\n    assertEquals(\"shard1\", slices.get(\"shard1\").getName());\n    assertEquals(\"inactive\", slices.get(\"shard1\").getState());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0beaed456aa3358e5e4a99ea2aea994ef6c81de3","date":1365434191,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/SliceStateUpdateTest#testSliceStateUpdate().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/SliceStateUpdateTest#testSliceStateUpdate().mjava","sourceNew":"  @Test\n  public void testSliceStateUpdate() throws Exception {\n    System.setProperty(\"solrcloud.update.delay\", \"1\");\n    \n    /* Get ClusterState, update slice state and publish it to Zookeeper */\n\n    ClusterState clusterState = container1.getZkController().getClusterState();\n    Map<String, DocCollection> collectionStates =\n        new LinkedHashMap<String, DocCollection>(clusterState.getCollectionStates());\n\n    Map<String, Slice> slicesMap = clusterState.getSlicesMap(\"collection1\");\n    Map<String, Object> props = new HashMap<String, Object>(1);\n    Slice slice = slicesMap.get(\"shard1\");\n    Map<String, Object> prop = slice.getProperties();\n    prop.put(\"state\", \"inactive\");\n    Slice newSlice = new Slice(slice.getName(), slice.getReplicasMap(), prop);\n    slicesMap.put(newSlice.getName(), newSlice);\n    props.put(DocCollection.DOC_ROUTER, ImplicitDocRouter.NAME);\n\n    DocCollection coll = new DocCollection(\"collection1\", slicesMap, props, DocRouter.DEFAULT);\n    collectionStates.put(\"collection1\", coll);\n    SolrZkClient zkClient = new SolrZkClient(zkServer.getZkAddress(),\n        AbstractZkTestCase.TIMEOUT);\n\n    ClusterState newState = new ClusterState(clusterState.getLiveNodes(), collectionStates);\n    zkClient.setData(ZkStateReader.CLUSTER_STATE,\n        ZkStateReader.toJSON(newState), true);\n    zkClient.close();\n    \n    /* Read state from another container and confirm the change */\n    ZkController zkController2 = container2.getZkController();\n    ClusterState clusterState2 = null;\n    Map<String, Slice> slices = null;\n    for (int i = 75; i > 0; i--) {\n      clusterState2 = zkController2.getClusterState();\n      slices = clusterState2.getSlicesMap(\"collection1\");\n      if (slices != null && slices.containsKey(\"shard1\")\n          && slices.get(\"shard1\").getState().equals(\"inactive\")) {\n        break;\n      }\n      Thread.sleep(500);\n    }\n\n    assertNotNull(slices);\n\n    assertEquals(\"shard1\", slices.get(\"shard1\").getName());\n    assertEquals(\"inactive\", slices.get(\"shard1\").getState());\n  }\n\n","sourceOld":"  @Test\n  public void testSliceStateUpdate() throws Exception {\n    System.setProperty(\"solrcloud.update.delay\", \"1\");\n    \n    /* Get ClusterState, update slice state and publish it to Zookeeper */\n\n    ClusterState clusterState = container1.getZkController().getClusterState();\n    Map<String, DocCollection> collectionStates =\n        new LinkedHashMap<String, DocCollection>(clusterState.getCollectionStates());\n\n    Map<String, Slice> slicesMap = clusterState.getSlicesMap(\"collection1\");\n    Map<String, Object> props = new HashMap<String, Object>(1);\n    Slice slice = slicesMap.get(\"shard1\");\n    Map<String, Object> prop = slice.getProperties();\n    prop.put(\"state\", \"inactive\");\n    Slice newSlice = new Slice(slice.getName(), slice.getReplicasMap(), prop);\n    slicesMap.put(newSlice.getName(), newSlice);\n    props.put(DocCollection.DOC_ROUTER, ImplicitDocRouter.NAME);\n\n    DocCollection coll = new DocCollection(\"collection1\", slicesMap, props, DocRouter.DEFAULT);\n    collectionStates.put(\"collection1\", coll);\n    SolrZkClient zkClient = new SolrZkClient(zkServer.getZkAddress(),\n        AbstractZkTestCase.TIMEOUT);\n\n    ClusterState newState = new ClusterState(clusterState.getLiveNodes(), collectionStates);\n    zkClient.setData(ZkStateReader.CLUSTER_STATE,\n        ZkStateReader.toJSON(newState), true);\n    zkClient.close();\n    \n    /* Read state from another container and confirm the change */\n    ZkController zkController2 = container2.getZkController();\n    ClusterState clusterState2 = null;\n    Map<String, Slice> slices = null;\n    for (int i = 75; i > 0; i--) {\n      clusterState2 = zkController2.getClusterState();\n      slices = clusterState2.getAllSlicesMap(\"collection1\");\n      if (slices != null && slices.containsKey(\"shard1\")\n          && slices.get(\"shard1\").getState().equals(\"inactive\")) {\n        break;\n      }\n      Thread.sleep(500);\n    }\n\n    assertNotNull(slices);\n\n    assertEquals(\"shard1\", slices.get(\"shard1\").getName());\n    assertEquals(\"inactive\", slices.get(\"shard1\").getState());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e187a371a1d09379bb452c2c13a7b9221525dff8","date":1379517004,"type":3,"author":"Noble Paul","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/SliceStateUpdateTest#testSliceStateUpdate().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/SliceStateUpdateTest#testSliceStateUpdate().mjava","sourceNew":"  @Test\n  public void testSliceStateUpdate() throws Exception {\n    System.setProperty(\"solrcloud.update.delay\", \"1\");\n    \n    /* Get ClusterState, update slice state and publish it to Zookeeper */\n\n    ClusterState clusterState = container1.getZkController().getClusterState();\n    Map<String, DocCollection> collectionStates =\n        new LinkedHashMap<String, DocCollection>(clusterState.getCollectionStates());\n\n    Map<String, Slice> slicesMap = clusterState.getSlicesMap(\"collection1\");\n    Map<String, Object> props = new HashMap<String, Object>(1);\n    Slice slice = slicesMap.get(\"shard1\");\n    Map<String, Object> prop = slice.getProperties();\n    prop.put(\"state\", \"inactive\");\n    Slice newSlice = new Slice(slice.getName(), slice.getReplicasMap(), prop);\n    slicesMap.put(newSlice.getName(), newSlice);\n    props.put(DocCollection.DOC_ROUTER, ZkNodeProps.makeMap(\"name\", ImplicitDocRouter.NAME));\n\n    DocCollection coll = new DocCollection(\"collection1\", slicesMap, props, DocRouter.DEFAULT);\n    collectionStates.put(\"collection1\", coll);\n    SolrZkClient zkClient = new SolrZkClient(zkServer.getZkAddress(),\n        AbstractZkTestCase.TIMEOUT);\n\n    ClusterState newState = new ClusterState(clusterState.getLiveNodes(), collectionStates);\n    zkClient.setData(ZkStateReader.CLUSTER_STATE,\n        ZkStateReader.toJSON(newState), true);\n    zkClient.close();\n    \n    /* Read state from another container and confirm the change */\n    ZkController zkController2 = container2.getZkController();\n    ClusterState clusterState2 = null;\n    Map<String, Slice> slices = null;\n    for (int i = 75; i > 0; i--) {\n      clusterState2 = zkController2.getClusterState();\n      slices = clusterState2.getSlicesMap(\"collection1\");\n      if (slices != null && slices.containsKey(\"shard1\")\n          && slices.get(\"shard1\").getState().equals(\"inactive\")) {\n        break;\n      }\n      Thread.sleep(500);\n    }\n\n    assertNotNull(slices);\n\n    assertEquals(\"shard1\", slices.get(\"shard1\").getName());\n    assertEquals(\"inactive\", slices.get(\"shard1\").getState());\n  }\n\n","sourceOld":"  @Test\n  public void testSliceStateUpdate() throws Exception {\n    System.setProperty(\"solrcloud.update.delay\", \"1\");\n    \n    /* Get ClusterState, update slice state and publish it to Zookeeper */\n\n    ClusterState clusterState = container1.getZkController().getClusterState();\n    Map<String, DocCollection> collectionStates =\n        new LinkedHashMap<String, DocCollection>(clusterState.getCollectionStates());\n\n    Map<String, Slice> slicesMap = clusterState.getSlicesMap(\"collection1\");\n    Map<String, Object> props = new HashMap<String, Object>(1);\n    Slice slice = slicesMap.get(\"shard1\");\n    Map<String, Object> prop = slice.getProperties();\n    prop.put(\"state\", \"inactive\");\n    Slice newSlice = new Slice(slice.getName(), slice.getReplicasMap(), prop);\n    slicesMap.put(newSlice.getName(), newSlice);\n    props.put(DocCollection.DOC_ROUTER, ImplicitDocRouter.NAME);\n\n    DocCollection coll = new DocCollection(\"collection1\", slicesMap, props, DocRouter.DEFAULT);\n    collectionStates.put(\"collection1\", coll);\n    SolrZkClient zkClient = new SolrZkClient(zkServer.getZkAddress(),\n        AbstractZkTestCase.TIMEOUT);\n\n    ClusterState newState = new ClusterState(clusterState.getLiveNodes(), collectionStates);\n    zkClient.setData(ZkStateReader.CLUSTER_STATE,\n        ZkStateReader.toJSON(newState), true);\n    zkClient.close();\n    \n    /* Read state from another container and confirm the change */\n    ZkController zkController2 = container2.getZkController();\n    ClusterState clusterState2 = null;\n    Map<String, Slice> slices = null;\n    for (int i = 75; i > 0; i--) {\n      clusterState2 = zkController2.getClusterState();\n      slices = clusterState2.getSlicesMap(\"collection1\");\n      if (slices != null && slices.containsKey(\"shard1\")\n          && slices.get(\"shard1\").getState().equals(\"inactive\")) {\n        break;\n      }\n      Thread.sleep(500);\n    }\n\n    assertNotNull(slices);\n\n    assertEquals(\"shard1\", slices.get(\"shard1\").getName());\n    assertEquals(\"inactive\", slices.get(\"shard1\").getState());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5db19429ed0ca68af0062aef668cd695634d80b7","date":1382291613,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/SliceStateUpdateTest#testSliceStateUpdate().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/SliceStateUpdateTest#testSliceStateUpdate().mjava","sourceNew":"  @Test\n  public void testSliceStateUpdate() throws Exception {\n    System.setProperty(\"solrcloud.update.delay\", \"1\");\n    \n    /* Get ClusterState, update slice state and publish it to Zookeeper */\n\n    ClusterState clusterState = container1.getZkController().getClusterState();\n    Map<String, DocCollection> collectionStates =\n        new LinkedHashMap<String, DocCollection>(clusterState.getCollectionStates());\n\n    Map<String, Slice> slicesMap = clusterState.getSlicesMap(\"collection1\");\n    Map<String, Object> props = new HashMap<String, Object>(1);\n    Slice slice = slicesMap.get(\"shard1\");\n    Map<String, Object> prop = slice.getProperties();\n    prop.put(\"state\", \"inactive\");\n    Slice newSlice = new Slice(slice.getName(), slice.getReplicasMap(), prop);\n    slicesMap.put(newSlice.getName(), newSlice);\n    props.put(DocCollection.DOC_ROUTER, ZkNodeProps.makeMap(\"name\", ImplicitDocRouter.NAME));\n\n    DocCollection coll = new DocCollection(\"collection1\", slicesMap, props, DocRouter.DEFAULT);\n    collectionStates.put(\"collection1\", coll);\n    SolrZkClient zkClient = new SolrZkClient(zkServer.getZkAddress(),\n        AbstractZkTestCase.TIMEOUT);\n\n    ClusterState newState = new ClusterState(clusterState.getLiveNodes(), collectionStates);\n    zkClient.setData(ZkStateReader.CLUSTER_STATE,\n        ZkStateReader.toJSON(newState), true);\n    zkClient.close();\n    \n    /* Read state from another container and confirm the change */\n    ZkController zkController2 = container2.getZkController();\n    ClusterState clusterState2 = null;\n    Map<String, Slice> slices = null;\n    for (int i = 100; i > 0; i--) {\n      clusterState2 = zkController2.getClusterState();\n      slices = clusterState2.getSlicesMap(\"collection1\");\n      if (slices != null && slices.containsKey(\"shard1\")\n          && slices.get(\"shard1\").getState().equals(\"inactive\")) {\n        break;\n      }\n      Thread.sleep(500);\n    }\n\n    assertNotNull(slices);\n\n    assertEquals(\"shard1\", slices.get(\"shard1\").getName());\n    assertEquals(\"inactive\", slices.get(\"shard1\").getState());\n  }\n\n","sourceOld":"  @Test\n  public void testSliceStateUpdate() throws Exception {\n    System.setProperty(\"solrcloud.update.delay\", \"1\");\n    \n    /* Get ClusterState, update slice state and publish it to Zookeeper */\n\n    ClusterState clusterState = container1.getZkController().getClusterState();\n    Map<String, DocCollection> collectionStates =\n        new LinkedHashMap<String, DocCollection>(clusterState.getCollectionStates());\n\n    Map<String, Slice> slicesMap = clusterState.getSlicesMap(\"collection1\");\n    Map<String, Object> props = new HashMap<String, Object>(1);\n    Slice slice = slicesMap.get(\"shard1\");\n    Map<String, Object> prop = slice.getProperties();\n    prop.put(\"state\", \"inactive\");\n    Slice newSlice = new Slice(slice.getName(), slice.getReplicasMap(), prop);\n    slicesMap.put(newSlice.getName(), newSlice);\n    props.put(DocCollection.DOC_ROUTER, ZkNodeProps.makeMap(\"name\", ImplicitDocRouter.NAME));\n\n    DocCollection coll = new DocCollection(\"collection1\", slicesMap, props, DocRouter.DEFAULT);\n    collectionStates.put(\"collection1\", coll);\n    SolrZkClient zkClient = new SolrZkClient(zkServer.getZkAddress(),\n        AbstractZkTestCase.TIMEOUT);\n\n    ClusterState newState = new ClusterState(clusterState.getLiveNodes(), collectionStates);\n    zkClient.setData(ZkStateReader.CLUSTER_STATE,\n        ZkStateReader.toJSON(newState), true);\n    zkClient.close();\n    \n    /* Read state from another container and confirm the change */\n    ZkController zkController2 = container2.getZkController();\n    ClusterState clusterState2 = null;\n    Map<String, Slice> slices = null;\n    for (int i = 75; i > 0; i--) {\n      clusterState2 = zkController2.getClusterState();\n      slices = clusterState2.getSlicesMap(\"collection1\");\n      if (slices != null && slices.containsKey(\"shard1\")\n          && slices.get(\"shard1\").getState().equals(\"inactive\")) {\n        break;\n      }\n      Thread.sleep(500);\n    }\n\n    assertNotNull(slices);\n\n    assertEquals(\"shard1\", slices.get(\"shard1\").getName());\n    assertEquals(\"inactive\", slices.get(\"shard1\").getState());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d5c24895cc40015d3ec6e42b234fe0953de6ebc3","date":1385000683,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/SliceStateUpdateTest#testSliceStateUpdate().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/SliceStateUpdateTest#testSliceStateUpdate().mjava","sourceNew":"  @Test\n  public void testSliceStateUpdate() throws Exception {\n    System.setProperty(\"solrcloud.update.delay\", \"1\");\n    \n    /* Get ClusterState, update slice state and publish it to Zookeeper */\n    container1.getZkController().getZkStateReader().updateClusterState(true);\n    \n    // we don't want to race with legit overseer updates\n    OverseerThread updaterThread = container1.getZkController().getOverseer().getUpdaterThread();\n    closeThread(updaterThread);\n    updaterThread = container2.getZkController().getOverseer().getUpdaterThread();\n    closeThread(updaterThread);\n    \n    ClusterState clusterState = container1.getZkController().getClusterState();\n    Map<String, DocCollection> collectionStates =\n        new LinkedHashMap<String, DocCollection>(clusterState.getCollectionStates());\n\n    Map<String, Slice> slicesMap = clusterState.getSlicesMap(\"collection1\");\n    Map<String, Object> props = new HashMap<String, Object>(1);\n    Slice slice = slicesMap.get(\"shard1\");\n    Map<String, Object> prop = slice.getProperties();\n    prop.put(\"state\", \"inactive\");\n    Slice newSlice = new Slice(slice.getName(), slice.getReplicasMap(), prop);\n    slicesMap.put(newSlice.getName(), newSlice);\n    props.put(DocCollection.DOC_ROUTER, ZkNodeProps.makeMap(\"name\", ImplicitDocRouter.NAME));\n\n    DocCollection coll = new DocCollection(\"collection1\", slicesMap, props, DocRouter.DEFAULT);\n    collectionStates.put(\"collection1\", coll);\n    SolrZkClient zkClient = new SolrZkClient(zkServer.getZkAddress(),\n        AbstractZkTestCase.TIMEOUT);\n\n    ClusterState newState = new ClusterState(clusterState.getLiveNodes(), collectionStates);\n    zkClient.setData(ZkStateReader.CLUSTER_STATE,\n        ZkStateReader.toJSON(newState), true);\n    zkClient.close();\n    \n    /* Read state from another container and confirm the change */\n    ZkController zkController2 = container2.getZkController();\n    ClusterState clusterState2 = null;\n    Map<String, Slice> slices = null;\n    for (int i = 60; i > 0; i--) {\n      clusterState2 = zkController2.getClusterState();\n      slices = clusterState2.getSlicesMap(\"collection1\");\n      if (slices != null && slices.containsKey(\"shard1\")\n          && slices.get(\"shard1\").getState().equals(\"inactive\")) {\n        break;\n      }\n      Thread.sleep(500);\n    }\n\n    assertNotNull(slices);\n\n    assertEquals(\"shard1\", slices.get(\"shard1\").getName());\n    assertEquals(\"inactive\", slices.get(\"shard1\").getState());\n\n    container1.getZkController().getOverseerElector().getContext().cancelElection();\n    container2.getZkController().getOverseerElector().getContext().cancelElection();\n  }\n\n","sourceOld":"  @Test\n  public void testSliceStateUpdate() throws Exception {\n    System.setProperty(\"solrcloud.update.delay\", \"1\");\n    \n    /* Get ClusterState, update slice state and publish it to Zookeeper */\n\n    ClusterState clusterState = container1.getZkController().getClusterState();\n    Map<String, DocCollection> collectionStates =\n        new LinkedHashMap<String, DocCollection>(clusterState.getCollectionStates());\n\n    Map<String, Slice> slicesMap = clusterState.getSlicesMap(\"collection1\");\n    Map<String, Object> props = new HashMap<String, Object>(1);\n    Slice slice = slicesMap.get(\"shard1\");\n    Map<String, Object> prop = slice.getProperties();\n    prop.put(\"state\", \"inactive\");\n    Slice newSlice = new Slice(slice.getName(), slice.getReplicasMap(), prop);\n    slicesMap.put(newSlice.getName(), newSlice);\n    props.put(DocCollection.DOC_ROUTER, ZkNodeProps.makeMap(\"name\", ImplicitDocRouter.NAME));\n\n    DocCollection coll = new DocCollection(\"collection1\", slicesMap, props, DocRouter.DEFAULT);\n    collectionStates.put(\"collection1\", coll);\n    SolrZkClient zkClient = new SolrZkClient(zkServer.getZkAddress(),\n        AbstractZkTestCase.TIMEOUT);\n\n    ClusterState newState = new ClusterState(clusterState.getLiveNodes(), collectionStates);\n    zkClient.setData(ZkStateReader.CLUSTER_STATE,\n        ZkStateReader.toJSON(newState), true);\n    zkClient.close();\n    \n    /* Read state from another container and confirm the change */\n    ZkController zkController2 = container2.getZkController();\n    ClusterState clusterState2 = null;\n    Map<String, Slice> slices = null;\n    for (int i = 100; i > 0; i--) {\n      clusterState2 = zkController2.getClusterState();\n      slices = clusterState2.getSlicesMap(\"collection1\");\n      if (slices != null && slices.containsKey(\"shard1\")\n          && slices.get(\"shard1\").getState().equals(\"inactive\")) {\n        break;\n      }\n      Thread.sleep(500);\n    }\n\n    assertNotNull(slices);\n\n    assertEquals(\"shard1\", slices.get(\"shard1\").getName());\n    assertEquals(\"inactive\", slices.get(\"shard1\").getState());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ce7cfca1a733d2ed1f7089b339faf006bdcc7b70","date":1386334715,"type":3,"author":"Noble Paul","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/SliceStateUpdateTest#testSliceStateUpdate().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/SliceStateUpdateTest#testSliceStateUpdate().mjava","sourceNew":"  @Test\n  public void testSliceStateUpdate() throws Exception {\n    System.setProperty(\"solrcloud.update.delay\", \"1\");\n    \n    /* Get ClusterState, update slice state and publish it to Zookeeper */\n    container1.getZkController().getZkStateReader().updateClusterState(true);\n    \n    // we don't want to race with legit overseer updates\n    OverseerThread updaterThread = container1.getZkController().getOverseer().getUpdaterThread();\n    closeThread(updaterThread);\n    updaterThread = container2.getZkController().getOverseer().getUpdaterThread();\n    closeThread(updaterThread);\n    \n    ClusterState clusterState = container1.getZkController().getClusterState();\n//    Map<String, DocCollection> collectionStates =\n//        new LinkedHashMap<String, DocCollection>(clusterState.getCollectionStates());\n\n    Map<String, Slice> slicesMap = clusterState.getSlicesMap(\"collection1\");\n    Map<String, Object> props = new HashMap<String, Object>(1);\n    Slice slice = slicesMap.get(\"shard1\");\n    Map<String, Object> prop = slice.getProperties();\n    prop.put(\"state\", \"inactive\");\n    Slice newSlice = new Slice(slice.getName(), slice.getReplicasMap(), prop);\n    slicesMap.put(newSlice.getName(), newSlice);\n    props.put(DocCollection.DOC_ROUTER, ZkNodeProps.makeMap(\"name\", ImplicitDocRouter.NAME));\n\n    DocCollection coll = new DocCollection(\"collection1\", slicesMap, props, DocRouter.DEFAULT);\n//    collectionStates.put(\"collection1\", coll);\n    SolrZkClient zkClient = new SolrZkClient(zkServer.getZkAddress(),\n        AbstractZkTestCase.TIMEOUT);\n\n    ClusterState newState = clusterState.copyWith(Collections.singletonMap(coll.getName(), coll) );\n    zkClient.setData(ZkStateReader.CLUSTER_STATE,\n        ZkStateReader.toJSON(newState), true);\n    zkClient.close();\n    \n    /* Read state from another container and confirm the change */\n    ZkController zkController2 = container2.getZkController();\n    ClusterState clusterState2 = null;\n    Map<String, Slice> slices = null;\n    for (int i = 60; i > 0; i--) {\n      clusterState2 = zkController2.getClusterState();\n      slices = clusterState2.getSlicesMap(\"collection1\");\n      if (slices != null && slices.containsKey(\"shard1\")\n          && slices.get(\"shard1\").getState().equals(\"inactive\")) {\n        break;\n      }\n      Thread.sleep(500);\n    }\n\n    assertNotNull(slices);\n\n    assertEquals(\"shard1\", slices.get(\"shard1\").getName());\n    assertEquals(\"inactive\", slices.get(\"shard1\").getState());\n\n    container1.getZkController().getOverseerElector().getContext().cancelElection();\n    container2.getZkController().getOverseerElector().getContext().cancelElection();\n  }\n\n","sourceOld":"  @Test\n  public void testSliceStateUpdate() throws Exception {\n    System.setProperty(\"solrcloud.update.delay\", \"1\");\n    \n    /* Get ClusterState, update slice state and publish it to Zookeeper */\n    container1.getZkController().getZkStateReader().updateClusterState(true);\n    \n    // we don't want to race with legit overseer updates\n    OverseerThread updaterThread = container1.getZkController().getOverseer().getUpdaterThread();\n    closeThread(updaterThread);\n    updaterThread = container2.getZkController().getOverseer().getUpdaterThread();\n    closeThread(updaterThread);\n    \n    ClusterState clusterState = container1.getZkController().getClusterState();\n    Map<String, DocCollection> collectionStates =\n        new LinkedHashMap<String, DocCollection>(clusterState.getCollectionStates());\n\n    Map<String, Slice> slicesMap = clusterState.getSlicesMap(\"collection1\");\n    Map<String, Object> props = new HashMap<String, Object>(1);\n    Slice slice = slicesMap.get(\"shard1\");\n    Map<String, Object> prop = slice.getProperties();\n    prop.put(\"state\", \"inactive\");\n    Slice newSlice = new Slice(slice.getName(), slice.getReplicasMap(), prop);\n    slicesMap.put(newSlice.getName(), newSlice);\n    props.put(DocCollection.DOC_ROUTER, ZkNodeProps.makeMap(\"name\", ImplicitDocRouter.NAME));\n\n    DocCollection coll = new DocCollection(\"collection1\", slicesMap, props, DocRouter.DEFAULT);\n    collectionStates.put(\"collection1\", coll);\n    SolrZkClient zkClient = new SolrZkClient(zkServer.getZkAddress(),\n        AbstractZkTestCase.TIMEOUT);\n\n    ClusterState newState = new ClusterState(clusterState.getLiveNodes(), collectionStates);\n    zkClient.setData(ZkStateReader.CLUSTER_STATE,\n        ZkStateReader.toJSON(newState), true);\n    zkClient.close();\n    \n    /* Read state from another container and confirm the change */\n    ZkController zkController2 = container2.getZkController();\n    ClusterState clusterState2 = null;\n    Map<String, Slice> slices = null;\n    for (int i = 60; i > 0; i--) {\n      clusterState2 = zkController2.getClusterState();\n      slices = clusterState2.getSlicesMap(\"collection1\");\n      if (slices != null && slices.containsKey(\"shard1\")\n          && slices.get(\"shard1\").getState().equals(\"inactive\")) {\n        break;\n      }\n      Thread.sleep(500);\n    }\n\n    assertNotNull(slices);\n\n    assertEquals(\"shard1\", slices.get(\"shard1\").getName());\n    assertEquals(\"inactive\", slices.get(\"shard1\").getState());\n\n    container1.getZkController().getOverseerElector().getContext().cancelElection();\n    container2.getZkController().getOverseerElector().getContext().cancelElection();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"74f45af4339b0daf7a95c820ab88c1aea74fbce0","date":1387475327,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/SliceStateUpdateTest#testSliceStateUpdate().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/SliceStateUpdateTest#testSliceStateUpdate().mjava","sourceNew":"  @Test\n  public void testSliceStateUpdate() throws Exception {\n    System.setProperty(\"solrcloud.update.delay\", \"1\");\n    \n    /* Get ClusterState, update slice state and publish it to Zookeeper */\n    container1.getZkController().getZkStateReader().updateClusterState(true);\n    \n    // we don't want to race with legit overseer updates\n    OverseerThread updaterThread = container1.getZkController().getOverseer().getUpdaterThread();\n    closeThread(updaterThread);\n    updaterThread = container2.getZkController().getOverseer().getUpdaterThread();\n    closeThread(updaterThread);\n    \n    ClusterState clusterState = container1.getZkController().getClusterState();\n//    Map<String, DocCollection> collectionStates =\n//        new LinkedHashMap<String, DocCollection>(clusterState.getCollectionStates());\n\n    Map<String, Slice> slicesMap = clusterState.getSlicesMap(\"collection1\");\n    Map<String, Object> props = new HashMap<String, Object>(1);\n    Slice slice = slicesMap.get(\"shard1\");\n    Map<String, Object> prop = slice.getProperties();\n    prop.put(\"state\", \"inactive\");\n    Slice newSlice = new Slice(slice.getName(), slice.getReplicasMap(), prop);\n    slicesMap.put(newSlice.getName(), newSlice);\n    props.put(DocCollection.DOC_ROUTER, ZkNodeProps.makeMap(\"name\", ImplicitDocRouter.NAME));\n\n    DocCollection coll = new DocCollection(\"collection1\", slicesMap, props, DocRouter.DEFAULT);\n//    collectionStates.put(\"collection1\", coll);\n    SolrZkClient zkClient = new SolrZkClient(zkServer.getZkAddress(),\n        AbstractZkTestCase.TIMEOUT);\n\n    ClusterState newState = clusterState.copyWith(Collections.singletonMap(coll.getName(), coll) );\n    zkClient.setData(ZkStateReader.CLUSTER_STATE,\n        ZkStateReader.toJSON(newState), true);\n    zkClient.close();\n    \n    /* Read state from another container and confirm the change */\n    ZkController zkController2 = container2.getZkController();\n    ClusterState clusterState2 = null;\n    Map<String, Slice> slices = null;\n    for (int i = 60; i > 0; i--) {\n      clusterState2 = zkController2.getClusterState();\n      slices = clusterState2.getSlicesMap(\"collection1\");\n      if (slices != null && slices.containsKey(\"shard1\")\n          && slices.get(\"shard1\").getState().equals(\"inactive\")) {\n        break;\n      }\n      Thread.sleep(500);\n    }\n\n    assertNotNull(slices);\n\n    assertEquals(\"shard1\", slices.get(\"shard1\").getName());\n    assertEquals(\"inactive\", slices.get(\"shard1\").getState());\n\n    container1.getZkController().getOverseerElector().getContext().cancelElection();\n    container2.getZkController().getOverseerElector().getContext().cancelElection();\n  }\n\n","sourceOld":"  @Test\n  public void testSliceStateUpdate() throws Exception {\n    System.setProperty(\"solrcloud.update.delay\", \"1\");\n    \n    /* Get ClusterState, update slice state and publish it to Zookeeper */\n\n    ClusterState clusterState = container1.getZkController().getClusterState();\n    Map<String, DocCollection> collectionStates =\n        new LinkedHashMap<String, DocCollection>(clusterState.getCollectionStates());\n\n    Map<String, Slice> slicesMap = clusterState.getSlicesMap(\"collection1\");\n    Map<String, Object> props = new HashMap<String, Object>(1);\n    Slice slice = slicesMap.get(\"shard1\");\n    Map<String, Object> prop = slice.getProperties();\n    prop.put(\"state\", \"inactive\");\n    Slice newSlice = new Slice(slice.getName(), slice.getReplicasMap(), prop);\n    slicesMap.put(newSlice.getName(), newSlice);\n    props.put(DocCollection.DOC_ROUTER, ZkNodeProps.makeMap(\"name\", ImplicitDocRouter.NAME));\n\n    DocCollection coll = new DocCollection(\"collection1\", slicesMap, props, DocRouter.DEFAULT);\n    collectionStates.put(\"collection1\", coll);\n    SolrZkClient zkClient = new SolrZkClient(zkServer.getZkAddress(),\n        AbstractZkTestCase.TIMEOUT);\n\n    ClusterState newState = new ClusterState(clusterState.getLiveNodes(), collectionStates);\n    zkClient.setData(ZkStateReader.CLUSTER_STATE,\n        ZkStateReader.toJSON(newState), true);\n    zkClient.close();\n    \n    /* Read state from another container and confirm the change */\n    ZkController zkController2 = container2.getZkController();\n    ClusterState clusterState2 = null;\n    Map<String, Slice> slices = null;\n    for (int i = 100; i > 0; i--) {\n      clusterState2 = zkController2.getClusterState();\n      slices = clusterState2.getSlicesMap(\"collection1\");\n      if (slices != null && slices.containsKey(\"shard1\")\n          && slices.get(\"shard1\").getState().equals(\"inactive\")) {\n        break;\n      }\n      Thread.sleep(500);\n    }\n\n    assertNotNull(slices);\n\n    assertEquals(\"shard1\", slices.get(\"shard1\").getName());\n    assertEquals(\"inactive\", slices.get(\"shard1\").getState());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"634f330c54fd3f9f491d52036dc3f40b4f4d8934","date":1394635157,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/SliceStateUpdateTest#testSliceStateUpdate().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/SliceStateUpdateTest#testSliceStateUpdate().mjava","sourceNew":"  @Test\n  public void testSliceStateUpdate() throws Exception {\n    System.setProperty(\"solrcloud.update.delay\", \"1\");\n    \n    /* Get ClusterState, update slice state and publish it to Zookeeper */\n    container1.getZkController().getZkStateReader().updateClusterState(true);\n    \n    // we don't want to race with legit overseer updates\n    OverseerThread updaterThread = container1.getZkController().getOverseer().getUpdaterThread();\n    closeThread(updaterThread);\n    updaterThread = container2.getZkController().getOverseer().getUpdaterThread();\n    closeThread(updaterThread);\n    \n    ClusterState clusterState = container1.getZkController().getClusterState();\n//    Map<String, DocCollection> collectionStates =\n//        new LinkedHashMap<String, DocCollection>(clusterState.getCollectionStates());\n\n    Map<String, Slice> slicesMap = clusterState.getSlicesMap(\"collection1\");\n    Map<String, Object> props = new HashMap<>(1);\n    Slice slice = slicesMap.get(\"shard1\");\n    Map<String, Object> prop = slice.getProperties();\n    prop.put(\"state\", \"inactive\");\n    Slice newSlice = new Slice(slice.getName(), slice.getReplicasMap(), prop);\n    slicesMap.put(newSlice.getName(), newSlice);\n    props.put(DocCollection.DOC_ROUTER, ZkNodeProps.makeMap(\"name\", ImplicitDocRouter.NAME));\n\n    DocCollection coll = new DocCollection(\"collection1\", slicesMap, props, DocRouter.DEFAULT);\n//    collectionStates.put(\"collection1\", coll);\n    SolrZkClient zkClient = new SolrZkClient(zkServer.getZkAddress(),\n        AbstractZkTestCase.TIMEOUT);\n\n    ClusterState newState = clusterState.copyWith(Collections.singletonMap(coll.getName(), coll) );\n    zkClient.setData(ZkStateReader.CLUSTER_STATE,\n        ZkStateReader.toJSON(newState), true);\n    zkClient.close();\n    \n    /* Read state from another container and confirm the change */\n    ZkController zkController2 = container2.getZkController();\n    ClusterState clusterState2 = null;\n    Map<String, Slice> slices = null;\n    for (int i = 60; i > 0; i--) {\n      clusterState2 = zkController2.getClusterState();\n      slices = clusterState2.getSlicesMap(\"collection1\");\n      if (slices != null && slices.containsKey(\"shard1\")\n          && slices.get(\"shard1\").getState().equals(\"inactive\")) {\n        break;\n      }\n      Thread.sleep(500);\n    }\n\n    assertNotNull(slices);\n\n    assertEquals(\"shard1\", slices.get(\"shard1\").getName());\n    assertEquals(\"inactive\", slices.get(\"shard1\").getState());\n\n    container1.getZkController().getOverseerElector().getContext().cancelElection();\n    container2.getZkController().getOverseerElector().getContext().cancelElection();\n  }\n\n","sourceOld":"  @Test\n  public void testSliceStateUpdate() throws Exception {\n    System.setProperty(\"solrcloud.update.delay\", \"1\");\n    \n    /* Get ClusterState, update slice state and publish it to Zookeeper */\n    container1.getZkController().getZkStateReader().updateClusterState(true);\n    \n    // we don't want to race with legit overseer updates\n    OverseerThread updaterThread = container1.getZkController().getOverseer().getUpdaterThread();\n    closeThread(updaterThread);\n    updaterThread = container2.getZkController().getOverseer().getUpdaterThread();\n    closeThread(updaterThread);\n    \n    ClusterState clusterState = container1.getZkController().getClusterState();\n//    Map<String, DocCollection> collectionStates =\n//        new LinkedHashMap<String, DocCollection>(clusterState.getCollectionStates());\n\n    Map<String, Slice> slicesMap = clusterState.getSlicesMap(\"collection1\");\n    Map<String, Object> props = new HashMap<String, Object>(1);\n    Slice slice = slicesMap.get(\"shard1\");\n    Map<String, Object> prop = slice.getProperties();\n    prop.put(\"state\", \"inactive\");\n    Slice newSlice = new Slice(slice.getName(), slice.getReplicasMap(), prop);\n    slicesMap.put(newSlice.getName(), newSlice);\n    props.put(DocCollection.DOC_ROUTER, ZkNodeProps.makeMap(\"name\", ImplicitDocRouter.NAME));\n\n    DocCollection coll = new DocCollection(\"collection1\", slicesMap, props, DocRouter.DEFAULT);\n//    collectionStates.put(\"collection1\", coll);\n    SolrZkClient zkClient = new SolrZkClient(zkServer.getZkAddress(),\n        AbstractZkTestCase.TIMEOUT);\n\n    ClusterState newState = clusterState.copyWith(Collections.singletonMap(coll.getName(), coll) );\n    zkClient.setData(ZkStateReader.CLUSTER_STATE,\n        ZkStateReader.toJSON(newState), true);\n    zkClient.close();\n    \n    /* Read state from another container and confirm the change */\n    ZkController zkController2 = container2.getZkController();\n    ClusterState clusterState2 = null;\n    Map<String, Slice> slices = null;\n    for (int i = 60; i > 0; i--) {\n      clusterState2 = zkController2.getClusterState();\n      slices = clusterState2.getSlicesMap(\"collection1\");\n      if (slices != null && slices.containsKey(\"shard1\")\n          && slices.get(\"shard1\").getState().equals(\"inactive\")) {\n        break;\n      }\n      Thread.sleep(500);\n    }\n\n    assertNotNull(slices);\n\n    assertEquals(\"shard1\", slices.get(\"shard1\").getName());\n    assertEquals(\"inactive\", slices.get(\"shard1\").getState());\n\n    container1.getZkController().getOverseerElector().getContext().cancelElection();\n    container2.getZkController().getOverseerElector().getContext().cancelElection();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"17045e3d73e7d9231725a5db1f8a7416681c746c","date":1403936574,"type":4,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"/dev/null","pathOld":"solr/core/src/test/org/apache/solr/cloud/SliceStateUpdateTest#testSliceStateUpdate().mjava","sourceNew":null,"sourceOld":"  @Test\n  public void testSliceStateUpdate() throws Exception {\n    System.setProperty(\"solrcloud.update.delay\", \"1\");\n    \n    /* Get ClusterState, update slice state and publish it to Zookeeper */\n    container1.getZkController().getZkStateReader().updateClusterState(true);\n    \n    // we don't want to race with legit overseer updates\n    OverseerThread updaterThread = container1.getZkController().getOverseer().getUpdaterThread();\n    closeThread(updaterThread);\n    updaterThread = container2.getZkController().getOverseer().getUpdaterThread();\n    closeThread(updaterThread);\n    \n    ClusterState clusterState = container1.getZkController().getClusterState();\n//    Map<String, DocCollection> collectionStates =\n//        new LinkedHashMap<String, DocCollection>(clusterState.getCollectionStates());\n\n    Map<String, Slice> slicesMap = clusterState.getSlicesMap(\"collection1\");\n    Map<String, Object> props = new HashMap<>(1);\n    Slice slice = slicesMap.get(\"shard1\");\n    Map<String, Object> prop = slice.getProperties();\n    prop.put(\"state\", \"inactive\");\n    Slice newSlice = new Slice(slice.getName(), slice.getReplicasMap(), prop);\n    slicesMap.put(newSlice.getName(), newSlice);\n    props.put(DocCollection.DOC_ROUTER, ZkNodeProps.makeMap(\"name\", ImplicitDocRouter.NAME));\n\n    DocCollection coll = new DocCollection(\"collection1\", slicesMap, props, DocRouter.DEFAULT);\n//    collectionStates.put(\"collection1\", coll);\n    SolrZkClient zkClient = new SolrZkClient(zkServer.getZkAddress(),\n        AbstractZkTestCase.TIMEOUT);\n\n    ClusterState newState = clusterState.copyWith(Collections.singletonMap(coll.getName(), coll) );\n    zkClient.setData(ZkStateReader.CLUSTER_STATE,\n        ZkStateReader.toJSON(newState), true);\n    zkClient.close();\n    \n    /* Read state from another container and confirm the change */\n    ZkController zkController2 = container2.getZkController();\n    ClusterState clusterState2 = null;\n    Map<String, Slice> slices = null;\n    for (int i = 60; i > 0; i--) {\n      clusterState2 = zkController2.getClusterState();\n      slices = clusterState2.getSlicesMap(\"collection1\");\n      if (slices != null && slices.containsKey(\"shard1\")\n          && slices.get(\"shard1\").getState().equals(\"inactive\")) {\n        break;\n      }\n      Thread.sleep(500);\n    }\n\n    assertNotNull(slices);\n\n    assertEquals(\"shard1\", slices.get(\"shard1\").getName());\n    assertEquals(\"inactive\", slices.get(\"shard1\").getState());\n\n    container1.getZkController().getOverseerElector().getContext().cancelElection();\n    container2.getZkController().getOverseerElector().getContext().cancelElection();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["ce7cfca1a733d2ed1f7089b339faf006bdcc7b70"],"ce7cfca1a733d2ed1f7089b339faf006bdcc7b70":["d5c24895cc40015d3ec6e42b234fe0953de6ebc3"],"17045e3d73e7d9231725a5db1f8a7416681c746c":["634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"5db19429ed0ca68af0062aef668cd695634d80b7":["e187a371a1d09379bb452c2c13a7b9221525dff8"],"0beaed456aa3358e5e4a99ea2aea994ef6c81de3":["8289f39d5383ee10f1ab15486657badbc1c970ee"],"630b72110afca0a13a755e07ef8a4d764afb52aa":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"8289f39d5383ee10f1ab15486657badbc1c970ee":["3dea5c39096a2ee9e162e41aff22e4d608743435"],"3dea5c39096a2ee9e162e41aff22e4d608743435":["630b72110afca0a13a755e07ef8a4d764afb52aa"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"d5c24895cc40015d3ec6e42b234fe0953de6ebc3":["5db19429ed0ca68af0062aef668cd695634d80b7"],"e187a371a1d09379bb452c2c13a7b9221525dff8":["0beaed456aa3358e5e4a99ea2aea994ef6c81de3"],"74f45af4339b0daf7a95c820ab88c1aea74fbce0":["5db19429ed0ca68af0062aef668cd695634d80b7","ce7cfca1a733d2ed1f7089b339faf006bdcc7b70"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["17045e3d73e7d9231725a5db1f8a7416681c746c"]},"commit2Childs":{"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["17045e3d73e7d9231725a5db1f8a7416681c746c"],"ce7cfca1a733d2ed1f7089b339faf006bdcc7b70":["634f330c54fd3f9f491d52036dc3f40b4f4d8934","74f45af4339b0daf7a95c820ab88c1aea74fbce0"],"17045e3d73e7d9231725a5db1f8a7416681c746c":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"5db19429ed0ca68af0062aef668cd695634d80b7":["d5c24895cc40015d3ec6e42b234fe0953de6ebc3","74f45af4339b0daf7a95c820ab88c1aea74fbce0"],"0beaed456aa3358e5e4a99ea2aea994ef6c81de3":["e187a371a1d09379bb452c2c13a7b9221525dff8"],"630b72110afca0a13a755e07ef8a4d764afb52aa":["3dea5c39096a2ee9e162e41aff22e4d608743435"],"8289f39d5383ee10f1ab15486657badbc1c970ee":["0beaed456aa3358e5e4a99ea2aea994ef6c81de3"],"3dea5c39096a2ee9e162e41aff22e4d608743435":["8289f39d5383ee10f1ab15486657badbc1c970ee"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["630b72110afca0a13a755e07ef8a4d764afb52aa"],"d5c24895cc40015d3ec6e42b234fe0953de6ebc3":["ce7cfca1a733d2ed1f7089b339faf006bdcc7b70"],"e187a371a1d09379bb452c2c13a7b9221525dff8":["5db19429ed0ca68af0062aef668cd695634d80b7"],"74f45af4339b0daf7a95c820ab88c1aea74fbce0":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["74f45af4339b0daf7a95c820ab88c1aea74fbce0","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}