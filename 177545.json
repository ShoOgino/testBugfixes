{"path":"lucene/highlighter/src/java/org/apache/lucene/search/uhighlight/MultiValueTokenStream#incrementToken().mjava","commits":[{"id":"1f5ce59aaf4a055cc9ec62c15a89c263a05ff4b2","date":1475611903,"type":0,"author":"David Smiley","isMerge":false,"pathNew":"lucene/highlighter/src/java/org/apache/lucene/search/uhighlight/MultiValueTokenStream#incrementToken().mjava","pathOld":"/dev/null","sourceNew":"    @Override\n    public boolean incrementToken() throws IOException {\n        while (true) {\n\n            if (input.incrementToken()) {\n                // Position tracking:\n                if (remainingPosInc > 0) {//usually true first token of additional values (not first val)\n                    posIncAtt.setPositionIncrement(remainingPosInc + posIncAtt.getPositionIncrement());\n                    remainingPosInc = 0;//reset\n                }\n                // Offset tracking:\n                offsetAtt.setOffset(\n                        startValIdx + offsetAtt.startOffset(),\n                        startValIdx + offsetAtt.endOffset()\n                                         );\n                return true;\n            }\n\n            if (endValIdx == content.length()) {//no more\n                return false;\n            }\n\n            input.end(); // might adjust position increment\n            remainingPosInc += posIncAtt.getPositionIncrement();\n            input.close();\n            remainingPosInc += indexAnalyzer.getPositionIncrementGap(fieldName);\n\n            // Get new tokenStream based on next segment divided by the splitChar\n            startValIdx = endValIdx + 1;\n            endValIdx = content.indexOf(splitChar, startValIdx);\n            if (endValIdx == -1) {//EOF\n                endValIdx = content.length();\n            }\n            TokenStream tokenStream = indexAnalyzer.tokenStream(fieldName, content.substring(startValIdx, endValIdx));\n            if (tokenStream != input) {// (input is defined in TokenFilter set in the constructor)\n                // This is a grand trick we do -- knowing that the analyzer's re-use strategy is going to produce the\n                // very same tokenStream instance and thus have the same AttributeSource as this wrapping TokenStream\n                // since we used it as our input in the constructor.\n                // Were this not the case, we'd have to copy every attribute of interest since we can't alter the\n                // AttributeSource of this wrapping TokenStream post-construction (it's all private/final).\n                // If this is a problem, we could do that instead; maybe with a custom CharTermAttribute that allows\n                // us to easily set the char[] reference without literally copying char by char.\n                throw new IllegalStateException(\"Require TokenStream re-use.  Unsupported re-use strategy?: \" +\n                                                indexAnalyzer.getReuseStrategy());\n            }\n            tokenStream.reset();\n        } // while loop to increment token of this new value\n    }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4cce5816ef15a48a0bc11e5d400497ee4301dd3b","date":1476991456,"type":0,"author":"Kevin Risden","isMerge":true,"pathNew":"lucene/highlighter/src/java/org/apache/lucene/search/uhighlight/MultiValueTokenStream#incrementToken().mjava","pathOld":"/dev/null","sourceNew":"    @Override\n    public boolean incrementToken() throws IOException {\n        while (true) {\n\n            if (input.incrementToken()) {\n                // Position tracking:\n                if (remainingPosInc > 0) {//usually true first token of additional values (not first val)\n                    posIncAtt.setPositionIncrement(remainingPosInc + posIncAtt.getPositionIncrement());\n                    remainingPosInc = 0;//reset\n                }\n                // Offset tracking:\n                offsetAtt.setOffset(\n                        startValIdx + offsetAtt.startOffset(),\n                        startValIdx + offsetAtt.endOffset()\n                                         );\n                return true;\n            }\n\n            if (endValIdx == content.length()) {//no more\n                return false;\n            }\n\n            input.end(); // might adjust position increment\n            remainingPosInc += posIncAtt.getPositionIncrement();\n            input.close();\n            remainingPosInc += indexAnalyzer.getPositionIncrementGap(fieldName);\n\n            // Get new tokenStream based on next segment divided by the splitChar\n            startValIdx = endValIdx + 1;\n            endValIdx = content.indexOf(splitChar, startValIdx);\n            if (endValIdx == -1) {//EOF\n                endValIdx = content.length();\n            }\n            TokenStream tokenStream = indexAnalyzer.tokenStream(fieldName, content.substring(startValIdx, endValIdx));\n            if (tokenStream != input) {// (input is defined in TokenFilter set in the constructor)\n                // This is a grand trick we do -- knowing that the analyzer's re-use strategy is going to produce the\n                // very same tokenStream instance and thus have the same AttributeSource as this wrapping TokenStream\n                // since we used it as our input in the constructor.\n                // Were this not the case, we'd have to copy every attribute of interest since we can't alter the\n                // AttributeSource of this wrapping TokenStream post-construction (it's all private/final).\n                // If this is a problem, we could do that instead; maybe with a custom CharTermAttribute that allows\n                // us to easily set the char[] reference without literally copying char by char.\n                throw new IllegalStateException(\"Require TokenStream re-use.  Unsupported re-use strategy?: \" +\n                                                indexAnalyzer.getReuseStrategy());\n            }\n            tokenStream.reset();\n        } // while loop to increment token of this new value\n    }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f2e9861e4a2b724d9fc51b618714c579491b78d7","date":1479244606,"type":4,"author":"David Smiley","isMerge":false,"pathNew":"/dev/null","pathOld":"lucene/highlighter/src/java/org/apache/lucene/search/uhighlight/MultiValueTokenStream#incrementToken().mjava","sourceNew":null,"sourceOld":"    @Override\n    public boolean incrementToken() throws IOException {\n        while (true) {\n\n            if (input.incrementToken()) {\n                // Position tracking:\n                if (remainingPosInc > 0) {//usually true first token of additional values (not first val)\n                    posIncAtt.setPositionIncrement(remainingPosInc + posIncAtt.getPositionIncrement());\n                    remainingPosInc = 0;//reset\n                }\n                // Offset tracking:\n                offsetAtt.setOffset(\n                        startValIdx + offsetAtt.startOffset(),\n                        startValIdx + offsetAtt.endOffset()\n                                         );\n                return true;\n            }\n\n            if (endValIdx == content.length()) {//no more\n                return false;\n            }\n\n            input.end(); // might adjust position increment\n            remainingPosInc += posIncAtt.getPositionIncrement();\n            input.close();\n            remainingPosInc += indexAnalyzer.getPositionIncrementGap(fieldName);\n\n            // Get new tokenStream based on next segment divided by the splitChar\n            startValIdx = endValIdx + 1;\n            endValIdx = content.indexOf(splitChar, startValIdx);\n            if (endValIdx == -1) {//EOF\n                endValIdx = content.length();\n            }\n            TokenStream tokenStream = indexAnalyzer.tokenStream(fieldName, content.substring(startValIdx, endValIdx));\n            if (tokenStream != input) {// (input is defined in TokenFilter set in the constructor)\n                // This is a grand trick we do -- knowing that the analyzer's re-use strategy is going to produce the\n                // very same tokenStream instance and thus have the same AttributeSource as this wrapping TokenStream\n                // since we used it as our input in the constructor.\n                // Were this not the case, we'd have to copy every attribute of interest since we can't alter the\n                // AttributeSource of this wrapping TokenStream post-construction (it's all private/final).\n                // If this is a problem, we could do that instead; maybe with a custom CharTermAttribute that allows\n                // us to easily set the char[] reference without literally copying char by char.\n                throw new IllegalStateException(\"Require TokenStream re-use.  Unsupported re-use strategy?: \" +\n                                                indexAnalyzer.getReuseStrategy());\n            }\n            tokenStream.reset();\n        } // while loop to increment token of this new value\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a1ef55e1fff7ff44354432770ad8bc19be1fcc75","date":1479266056,"type":4,"author":"Kevin Risden","isMerge":true,"pathNew":"/dev/null","pathOld":"lucene/highlighter/src/java/org/apache/lucene/search/uhighlight/MultiValueTokenStream#incrementToken().mjava","sourceNew":null,"sourceOld":"    @Override\n    public boolean incrementToken() throws IOException {\n        while (true) {\n\n            if (input.incrementToken()) {\n                // Position tracking:\n                if (remainingPosInc > 0) {//usually true first token of additional values (not first val)\n                    posIncAtt.setPositionIncrement(remainingPosInc + posIncAtt.getPositionIncrement());\n                    remainingPosInc = 0;//reset\n                }\n                // Offset tracking:\n                offsetAtt.setOffset(\n                        startValIdx + offsetAtt.startOffset(),\n                        startValIdx + offsetAtt.endOffset()\n                                         );\n                return true;\n            }\n\n            if (endValIdx == content.length()) {//no more\n                return false;\n            }\n\n            input.end(); // might adjust position increment\n            remainingPosInc += posIncAtt.getPositionIncrement();\n            input.close();\n            remainingPosInc += indexAnalyzer.getPositionIncrementGap(fieldName);\n\n            // Get new tokenStream based on next segment divided by the splitChar\n            startValIdx = endValIdx + 1;\n            endValIdx = content.indexOf(splitChar, startValIdx);\n            if (endValIdx == -1) {//EOF\n                endValIdx = content.length();\n            }\n            TokenStream tokenStream = indexAnalyzer.tokenStream(fieldName, content.substring(startValIdx, endValIdx));\n            if (tokenStream != input) {// (input is defined in TokenFilter set in the constructor)\n                // This is a grand trick we do -- knowing that the analyzer's re-use strategy is going to produce the\n                // very same tokenStream instance and thus have the same AttributeSource as this wrapping TokenStream\n                // since we used it as our input in the constructor.\n                // Were this not the case, we'd have to copy every attribute of interest since we can't alter the\n                // AttributeSource of this wrapping TokenStream post-construction (it's all private/final).\n                // If this is a problem, we could do that instead; maybe with a custom CharTermAttribute that allows\n                // us to easily set the char[] reference without literally copying char by char.\n                throw new IllegalStateException(\"Require TokenStream re-use.  Unsupported re-use strategy?: \" +\n                                                indexAnalyzer.getReuseStrategy());\n            }\n            tokenStream.reset();\n        } // while loop to increment token of this new value\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"f2e9861e4a2b724d9fc51b618714c579491b78d7":["1f5ce59aaf4a055cc9ec62c15a89c263a05ff4b2"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"a1ef55e1fff7ff44354432770ad8bc19be1fcc75":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b","f2e9861e4a2b724d9fc51b618714c579491b78d7"],"1f5ce59aaf4a055cc9ec62c15a89c263a05ff4b2":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","1f5ce59aaf4a055cc9ec62c15a89c263a05ff4b2"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["f2e9861e4a2b724d9fc51b618714c579491b78d7"]},"commit2Childs":{"f2e9861e4a2b724d9fc51b618714c579491b78d7":["a1ef55e1fff7ff44354432770ad8bc19be1fcc75","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["1f5ce59aaf4a055cc9ec62c15a89c263a05ff4b2","4cce5816ef15a48a0bc11e5d400497ee4301dd3b"],"a1ef55e1fff7ff44354432770ad8bc19be1fcc75":[],"1f5ce59aaf4a055cc9ec62c15a89c263a05ff4b2":["f2e9861e4a2b724d9fc51b618714c579491b78d7","4cce5816ef15a48a0bc11e5d400497ee4301dd3b"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["a1ef55e1fff7ff44354432770ad8bc19be1fcc75"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["a1ef55e1fff7ff44354432770ad8bc19be1fcc75","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}