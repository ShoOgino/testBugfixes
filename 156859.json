{"path":"lucene/codecs/src/java/org/apache/lucene/codecs/compressing/CompressingStoredFieldsWriter#flush().mjava","commits":[{"id":"7d1467e0527cb2aeb9d7a05c26948ac9d82d81fa","date":1349450075,"type":0,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/codecs/src/java/org/apache/lucene/codecs/compressing/CompressingStoredFieldsWriter#flush().mjava","pathOld":"/dev/null","sourceNew":"  private void flush() throws IOException {\n    indexWriter.writeIndex(numBufferedDocs, fieldsStream.getFilePointer());\n\n    // transform end offsets into lengths\n    final int[] lengths = endOffsets;\n    for (int i = numBufferedDocs - 1; i > 0; --i) {\n      lengths[i] = endOffsets[i] - endOffsets[i - 1];\n      assert lengths[i] > 0;\n    }\n    writeHeader(docBase, numBufferedDocs, lengths);\n\n    // compress stored fields to fieldsStream\n    compressor.compress(bufferedDocs.bytes, 0, bufferedDocs.length, fieldsStream);\n\n    // reset\n    docBase += numBufferedDocs;\n    numBufferedDocs = 0;\n    bufferedDocs.length = 0;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"eba3cb2a268b9fb6f5be011fbaaf698699dcf24c","date":1352305464,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/codecs/src/java/org/apache/lucene/codecs/compressing/CompressingStoredFieldsWriter#flush().mjava","pathOld":"lucene/codecs/src/java/org/apache/lucene/codecs/compressing/CompressingStoredFieldsWriter#flush().mjava","sourceNew":"  private void flush() throws IOException {\n    indexWriter.writeIndex(numBufferedDocs, fieldsStream.getFilePointer());\n\n    // transform end offsets into lengths\n    final int[] lengths = endOffsets;\n    for (int i = numBufferedDocs - 1; i > 0; --i) {\n      lengths[i] = endOffsets[i] - endOffsets[i - 1];\n      assert lengths[i] >= 0;\n    }\n    writeHeader(docBase, numBufferedDocs, numStoredFields, lengths);\n\n    // compress stored fields to fieldsStream\n    compressor.compress(bufferedDocs.bytes, 0, bufferedDocs.length, fieldsStream);\n\n    // reset\n    docBase += numBufferedDocs;\n    numBufferedDocs = 0;\n    bufferedDocs.length = 0;\n  }\n\n","sourceOld":"  private void flush() throws IOException {\n    indexWriter.writeIndex(numBufferedDocs, fieldsStream.getFilePointer());\n\n    // transform end offsets into lengths\n    final int[] lengths = endOffsets;\n    for (int i = numBufferedDocs - 1; i > 0; --i) {\n      lengths[i] = endOffsets[i] - endOffsets[i - 1];\n      assert lengths[i] > 0;\n    }\n    writeHeader(docBase, numBufferedDocs, lengths);\n\n    // compress stored fields to fieldsStream\n    compressor.compress(bufferedDocs.bytes, 0, bufferedDocs.length, fieldsStream);\n\n    // reset\n    docBase += numBufferedDocs;\n    numBufferedDocs = 0;\n    bufferedDocs.length = 0;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5e04b732c631a77cbbd25b6ce43c2a8abb1e9e69","date":1352818449,"type":5,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingStoredFieldsWriter#flush().mjava","pathOld":"lucene/codecs/src/java/org/apache/lucene/codecs/compressing/CompressingStoredFieldsWriter#flush().mjava","sourceNew":"  private void flush() throws IOException {\n    indexWriter.writeIndex(numBufferedDocs, fieldsStream.getFilePointer());\n\n    // transform end offsets into lengths\n    final int[] lengths = endOffsets;\n    for (int i = numBufferedDocs - 1; i > 0; --i) {\n      lengths[i] = endOffsets[i] - endOffsets[i - 1];\n      assert lengths[i] >= 0;\n    }\n    writeHeader(docBase, numBufferedDocs, numStoredFields, lengths);\n\n    // compress stored fields to fieldsStream\n    compressor.compress(bufferedDocs.bytes, 0, bufferedDocs.length, fieldsStream);\n\n    // reset\n    docBase += numBufferedDocs;\n    numBufferedDocs = 0;\n    bufferedDocs.length = 0;\n  }\n\n","sourceOld":"  private void flush() throws IOException {\n    indexWriter.writeIndex(numBufferedDocs, fieldsStream.getFilePointer());\n\n    // transform end offsets into lengths\n    final int[] lengths = endOffsets;\n    for (int i = numBufferedDocs - 1; i > 0; --i) {\n      lengths[i] = endOffsets[i] - endOffsets[i - 1];\n      assert lengths[i] >= 0;\n    }\n    writeHeader(docBase, numBufferedDocs, numStoredFields, lengths);\n\n    // compress stored fields to fieldsStream\n    compressor.compress(bufferedDocs.bytes, 0, bufferedDocs.length, fieldsStream);\n\n    // reset\n    docBase += numBufferedDocs;\n    numBufferedDocs = 0;\n    bufferedDocs.length = 0;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"407687e67faf6e1f02a211ca078d8e3eed631027","date":1355157407,"type":5,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/compressing/CompressingStoredFieldsWriter#flush().mjava","pathOld":"lucene/codecs/src/java/org/apache/lucene/codecs/compressing/CompressingStoredFieldsWriter#flush().mjava","sourceNew":"  private void flush() throws IOException {\n    indexWriter.writeIndex(numBufferedDocs, fieldsStream.getFilePointer());\n\n    // transform end offsets into lengths\n    final int[] lengths = endOffsets;\n    for (int i = numBufferedDocs - 1; i > 0; --i) {\n      lengths[i] = endOffsets[i] - endOffsets[i - 1];\n      assert lengths[i] >= 0;\n    }\n    writeHeader(docBase, numBufferedDocs, numStoredFields, lengths);\n\n    // compress stored fields to fieldsStream\n    compressor.compress(bufferedDocs.bytes, 0, bufferedDocs.length, fieldsStream);\n\n    // reset\n    docBase += numBufferedDocs;\n    numBufferedDocs = 0;\n    bufferedDocs.length = 0;\n  }\n\n","sourceOld":"  private void flush() throws IOException {\n    indexWriter.writeIndex(numBufferedDocs, fieldsStream.getFilePointer());\n\n    // transform end offsets into lengths\n    final int[] lengths = endOffsets;\n    for (int i = numBufferedDocs - 1; i > 0; --i) {\n      lengths[i] = endOffsets[i] - endOffsets[i - 1];\n      assert lengths[i] >= 0;\n    }\n    writeHeader(docBase, numBufferedDocs, numStoredFields, lengths);\n\n    // compress stored fields to fieldsStream\n    compressor.compress(bufferedDocs.bytes, 0, bufferedDocs.length, fieldsStream);\n\n    // reset\n    docBase += numBufferedDocs;\n    numBufferedDocs = 0;\n    bufferedDocs.length = 0;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"5e04b732c631a77cbbd25b6ce43c2a8abb1e9e69":["eba3cb2a268b9fb6f5be011fbaaf698699dcf24c"],"7d1467e0527cb2aeb9d7a05c26948ac9d82d81fa":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"407687e67faf6e1f02a211ca078d8e3eed631027":["eba3cb2a268b9fb6f5be011fbaaf698699dcf24c","5e04b732c631a77cbbd25b6ce43c2a8abb1e9e69"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["5e04b732c631a77cbbd25b6ce43c2a8abb1e9e69"],"eba3cb2a268b9fb6f5be011fbaaf698699dcf24c":["7d1467e0527cb2aeb9d7a05c26948ac9d82d81fa"]},"commit2Childs":{"5e04b732c631a77cbbd25b6ce43c2a8abb1e9e69":["407687e67faf6e1f02a211ca078d8e3eed631027","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"7d1467e0527cb2aeb9d7a05c26948ac9d82d81fa":["eba3cb2a268b9fb6f5be011fbaaf698699dcf24c"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["7d1467e0527cb2aeb9d7a05c26948ac9d82d81fa"],"407687e67faf6e1f02a211ca078d8e3eed631027":[],"eba3cb2a268b9fb6f5be011fbaaf698699dcf24c":["5e04b732c631a77cbbd25b6ce43c2a8abb1e9e69","407687e67faf6e1f02a211ca078d8e3eed631027"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["407687e67faf6e1f02a211ca078d8e3eed631027","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}