{"path":"lucene/contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/feeds/SimpleSloppyPhraseQueryMaker#prepareQueries().mjava","commits":[{"id":"9454a6510e2db155fb01faa5c049b06ece95fab9","date":1453508333,"type":1,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/feeds/SimpleSloppyPhraseQueryMaker#prepareQueries().mjava","pathOld":"contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/feeds/SimpleSloppyPhraseQueryMaker#prepareQueries().mjava","sourceNew":"  /* (non-Javadoc)\n   * @see org.apache.lucene.benchmark.byTask.feeds.SimpleQueryMaker#prepareQueries()\n   */\n  @Override\n  protected Query[] prepareQueries() throws Exception {\n    // extract some 100 words from doc text to an array\n    String words[];\n    ArrayList<String> w = new ArrayList<String>();\n    StringTokenizer st = new StringTokenizer(SingleDocSource.DOC_TEXT);\n    while (st.hasMoreTokens() && w.size()<100) {\n      w.add(st.nextToken());\n    }\n    words = w.toArray(new String[0]);\n\n    // create queries (that would find stuff) with varying slops\n    ArrayList<Query> queries = new ArrayList<Query>(); \n    for (int slop=0; slop<8; slop++) {\n      for (int qlen=2; qlen<6; qlen++) {\n        for (int wd=0; wd<words.length-qlen-slop; wd++) {\n          // ordered\n          int remainedSlop = slop;\n          PhraseQuery q = new PhraseQuery();\n          q.setSlop(slop);\n          int wind = wd;\n          for (int i=0; i<qlen; i++) {\n            q.add(new Term(DocMaker.BODY_FIELD,words[wind++]));\n            if (remainedSlop>0) {\n              remainedSlop--;\n              wind++;\n            }\n          }\n          queries.add(q);\n          // reversed\n          remainedSlop = slop;\n          q = new PhraseQuery();\n          q.setSlop(slop+2*qlen);\n          wind = wd+qlen+remainedSlop-1;\n          for (int i=0; i<qlen; i++) {\n            q.add(new Term(DocMaker.BODY_FIELD,words[wind--]));\n            if (remainedSlop>0) {\n              remainedSlop--;\n              wind--;\n            }\n          }\n          queries.add(q);\n        }\n      }\n    }\n    return queries.toArray(new Query[0]);\n  }\n\n","sourceOld":"  /* (non-Javadoc)\n   * @see org.apache.lucene.benchmark.byTask.feeds.SimpleQueryMaker#prepareQueries()\n   */\n  @Override\n  protected Query[] prepareQueries() throws Exception {\n    // extract some 100 words from doc text to an array\n    String words[];\n    ArrayList<String> w = new ArrayList<String>();\n    StringTokenizer st = new StringTokenizer(SingleDocSource.DOC_TEXT);\n    while (st.hasMoreTokens() && w.size()<100) {\n      w.add(st.nextToken());\n    }\n    words = w.toArray(new String[0]);\n\n    // create queries (that would find stuff) with varying slops\n    ArrayList<Query> queries = new ArrayList<Query>(); \n    for (int slop=0; slop<8; slop++) {\n      for (int qlen=2; qlen<6; qlen++) {\n        for (int wd=0; wd<words.length-qlen-slop; wd++) {\n          // ordered\n          int remainedSlop = slop;\n          PhraseQuery q = new PhraseQuery();\n          q.setSlop(slop);\n          int wind = wd;\n          for (int i=0; i<qlen; i++) {\n            q.add(new Term(DocMaker.BODY_FIELD,words[wind++]));\n            if (remainedSlop>0) {\n              remainedSlop--;\n              wind++;\n            }\n          }\n          queries.add(q);\n          // reversed\n          remainedSlop = slop;\n          q = new PhraseQuery();\n          q.setSlop(slop+2*qlen);\n          wind = wd+qlen+remainedSlop-1;\n          for (int i=0; i<qlen; i++) {\n            q.add(new Term(DocMaker.BODY_FIELD,words[wind--]));\n            if (remainedSlop>0) {\n              remainedSlop--;\n              wind--;\n            }\n          }\n          queries.add(q);\n        }\n      }\n    }\n    return queries.toArray(new Query[0]);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ecc11368dc265bfdad90214f8bf5da99016ab1e2","date":1294144090,"type":5,"author":"Robert Muir","isMerge":false,"pathNew":"modules/benchmark/src/java/org/apache/lucene/benchmark/byTask/feeds/SimpleSloppyPhraseQueryMaker#prepareQueries().mjava","pathOld":"lucene/contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/feeds/SimpleSloppyPhraseQueryMaker#prepareQueries().mjava","sourceNew":"  /* (non-Javadoc)\n   * @see org.apache.lucene.benchmark.byTask.feeds.SimpleQueryMaker#prepareQueries()\n   */\n  @Override\n  protected Query[] prepareQueries() throws Exception {\n    // extract some 100 words from doc text to an array\n    String words[];\n    ArrayList<String> w = new ArrayList<String>();\n    StringTokenizer st = new StringTokenizer(SingleDocSource.DOC_TEXT);\n    while (st.hasMoreTokens() && w.size()<100) {\n      w.add(st.nextToken());\n    }\n    words = w.toArray(new String[0]);\n\n    // create queries (that would find stuff) with varying slops\n    ArrayList<Query> queries = new ArrayList<Query>(); \n    for (int slop=0; slop<8; slop++) {\n      for (int qlen=2; qlen<6; qlen++) {\n        for (int wd=0; wd<words.length-qlen-slop; wd++) {\n          // ordered\n          int remainedSlop = slop;\n          PhraseQuery q = new PhraseQuery();\n          q.setSlop(slop);\n          int wind = wd;\n          for (int i=0; i<qlen; i++) {\n            q.add(new Term(DocMaker.BODY_FIELD,words[wind++]));\n            if (remainedSlop>0) {\n              remainedSlop--;\n              wind++;\n            }\n          }\n          queries.add(q);\n          // reversed\n          remainedSlop = slop;\n          q = new PhraseQuery();\n          q.setSlop(slop+2*qlen);\n          wind = wd+qlen+remainedSlop-1;\n          for (int i=0; i<qlen; i++) {\n            q.add(new Term(DocMaker.BODY_FIELD,words[wind--]));\n            if (remainedSlop>0) {\n              remainedSlop--;\n              wind--;\n            }\n          }\n          queries.add(q);\n        }\n      }\n    }\n    return queries.toArray(new Query[0]);\n  }\n\n","sourceOld":"  /* (non-Javadoc)\n   * @see org.apache.lucene.benchmark.byTask.feeds.SimpleQueryMaker#prepareQueries()\n   */\n  @Override\n  protected Query[] prepareQueries() throws Exception {\n    // extract some 100 words from doc text to an array\n    String words[];\n    ArrayList<String> w = new ArrayList<String>();\n    StringTokenizer st = new StringTokenizer(SingleDocSource.DOC_TEXT);\n    while (st.hasMoreTokens() && w.size()<100) {\n      w.add(st.nextToken());\n    }\n    words = w.toArray(new String[0]);\n\n    // create queries (that would find stuff) with varying slops\n    ArrayList<Query> queries = new ArrayList<Query>(); \n    for (int slop=0; slop<8; slop++) {\n      for (int qlen=2; qlen<6; qlen++) {\n        for (int wd=0; wd<words.length-qlen-slop; wd++) {\n          // ordered\n          int remainedSlop = slop;\n          PhraseQuery q = new PhraseQuery();\n          q.setSlop(slop);\n          int wind = wd;\n          for (int i=0; i<qlen; i++) {\n            q.add(new Term(DocMaker.BODY_FIELD,words[wind++]));\n            if (remainedSlop>0) {\n              remainedSlop--;\n              wind++;\n            }\n          }\n          queries.add(q);\n          // reversed\n          remainedSlop = slop;\n          q = new PhraseQuery();\n          q.setSlop(slop+2*qlen);\n          wind = wd+qlen+remainedSlop-1;\n          for (int i=0; i<qlen; i++) {\n            q.add(new Term(DocMaker.BODY_FIELD,words[wind--]));\n            if (remainedSlop>0) {\n              remainedSlop--;\n              wind--;\n            }\n          }\n          queries.add(q);\n        }\n      }\n    }\n    return queries.toArray(new Query[0]);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"70ad682703b8585f5d0a637efec044d57ec05efb","date":1294259117,"type":5,"author":"Simon Willnauer","isMerge":true,"pathNew":"modules/benchmark/src/java/org/apache/lucene/benchmark/byTask/feeds/SimpleSloppyPhraseQueryMaker#prepareQueries().mjava","pathOld":"lucene/contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/feeds/SimpleSloppyPhraseQueryMaker#prepareQueries().mjava","sourceNew":"  /* (non-Javadoc)\n   * @see org.apache.lucene.benchmark.byTask.feeds.SimpleQueryMaker#prepareQueries()\n   */\n  @Override\n  protected Query[] prepareQueries() throws Exception {\n    // extract some 100 words from doc text to an array\n    String words[];\n    ArrayList<String> w = new ArrayList<String>();\n    StringTokenizer st = new StringTokenizer(SingleDocSource.DOC_TEXT);\n    while (st.hasMoreTokens() && w.size()<100) {\n      w.add(st.nextToken());\n    }\n    words = w.toArray(new String[0]);\n\n    // create queries (that would find stuff) with varying slops\n    ArrayList<Query> queries = new ArrayList<Query>(); \n    for (int slop=0; slop<8; slop++) {\n      for (int qlen=2; qlen<6; qlen++) {\n        for (int wd=0; wd<words.length-qlen-slop; wd++) {\n          // ordered\n          int remainedSlop = slop;\n          PhraseQuery q = new PhraseQuery();\n          q.setSlop(slop);\n          int wind = wd;\n          for (int i=0; i<qlen; i++) {\n            q.add(new Term(DocMaker.BODY_FIELD,words[wind++]));\n            if (remainedSlop>0) {\n              remainedSlop--;\n              wind++;\n            }\n          }\n          queries.add(q);\n          // reversed\n          remainedSlop = slop;\n          q = new PhraseQuery();\n          q.setSlop(slop+2*qlen);\n          wind = wd+qlen+remainedSlop-1;\n          for (int i=0; i<qlen; i++) {\n            q.add(new Term(DocMaker.BODY_FIELD,words[wind--]));\n            if (remainedSlop>0) {\n              remainedSlop--;\n              wind--;\n            }\n          }\n          queries.add(q);\n        }\n      }\n    }\n    return queries.toArray(new Query[0]);\n  }\n\n","sourceOld":"  /* (non-Javadoc)\n   * @see org.apache.lucene.benchmark.byTask.feeds.SimpleQueryMaker#prepareQueries()\n   */\n  @Override\n  protected Query[] prepareQueries() throws Exception {\n    // extract some 100 words from doc text to an array\n    String words[];\n    ArrayList<String> w = new ArrayList<String>();\n    StringTokenizer st = new StringTokenizer(SingleDocSource.DOC_TEXT);\n    while (st.hasMoreTokens() && w.size()<100) {\n      w.add(st.nextToken());\n    }\n    words = w.toArray(new String[0]);\n\n    // create queries (that would find stuff) with varying slops\n    ArrayList<Query> queries = new ArrayList<Query>(); \n    for (int slop=0; slop<8; slop++) {\n      for (int qlen=2; qlen<6; qlen++) {\n        for (int wd=0; wd<words.length-qlen-slop; wd++) {\n          // ordered\n          int remainedSlop = slop;\n          PhraseQuery q = new PhraseQuery();\n          q.setSlop(slop);\n          int wind = wd;\n          for (int i=0; i<qlen; i++) {\n            q.add(new Term(DocMaker.BODY_FIELD,words[wind++]));\n            if (remainedSlop>0) {\n              remainedSlop--;\n              wind++;\n            }\n          }\n          queries.add(q);\n          // reversed\n          remainedSlop = slop;\n          q = new PhraseQuery();\n          q.setSlop(slop+2*qlen);\n          wind = wd+qlen+remainedSlop-1;\n          for (int i=0; i<qlen; i++) {\n            q.add(new Term(DocMaker.BODY_FIELD,words[wind--]));\n            if (remainedSlop>0) {\n              remainedSlop--;\n              wind--;\n            }\n          }\n          queries.add(q);\n        }\n      }\n    }\n    return queries.toArray(new Query[0]);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"868da859b43505d9d2a023bfeae6dd0c795f5295","date":1294948401,"type":5,"author":"Michael Busch","isMerge":true,"pathNew":"modules/benchmark/src/java/org/apache/lucene/benchmark/byTask/feeds/SimpleSloppyPhraseQueryMaker#prepareQueries().mjava","pathOld":"lucene/contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/feeds/SimpleSloppyPhraseQueryMaker#prepareQueries().mjava","sourceNew":"  /* (non-Javadoc)\n   * @see org.apache.lucene.benchmark.byTask.feeds.SimpleQueryMaker#prepareQueries()\n   */\n  @Override\n  protected Query[] prepareQueries() throws Exception {\n    // extract some 100 words from doc text to an array\n    String words[];\n    ArrayList<String> w = new ArrayList<String>();\n    StringTokenizer st = new StringTokenizer(SingleDocSource.DOC_TEXT);\n    while (st.hasMoreTokens() && w.size()<100) {\n      w.add(st.nextToken());\n    }\n    words = w.toArray(new String[0]);\n\n    // create queries (that would find stuff) with varying slops\n    ArrayList<Query> queries = new ArrayList<Query>(); \n    for (int slop=0; slop<8; slop++) {\n      for (int qlen=2; qlen<6; qlen++) {\n        for (int wd=0; wd<words.length-qlen-slop; wd++) {\n          // ordered\n          int remainedSlop = slop;\n          PhraseQuery q = new PhraseQuery();\n          q.setSlop(slop);\n          int wind = wd;\n          for (int i=0; i<qlen; i++) {\n            q.add(new Term(DocMaker.BODY_FIELD,words[wind++]));\n            if (remainedSlop>0) {\n              remainedSlop--;\n              wind++;\n            }\n          }\n          queries.add(q);\n          // reversed\n          remainedSlop = slop;\n          q = new PhraseQuery();\n          q.setSlop(slop+2*qlen);\n          wind = wd+qlen+remainedSlop-1;\n          for (int i=0; i<qlen; i++) {\n            q.add(new Term(DocMaker.BODY_FIELD,words[wind--]));\n            if (remainedSlop>0) {\n              remainedSlop--;\n              wind--;\n            }\n          }\n          queries.add(q);\n        }\n      }\n    }\n    return queries.toArray(new Query[0]);\n  }\n\n","sourceOld":"  /* (non-Javadoc)\n   * @see org.apache.lucene.benchmark.byTask.feeds.SimpleQueryMaker#prepareQueries()\n   */\n  @Override\n  protected Query[] prepareQueries() throws Exception {\n    // extract some 100 words from doc text to an array\n    String words[];\n    ArrayList<String> w = new ArrayList<String>();\n    StringTokenizer st = new StringTokenizer(SingleDocSource.DOC_TEXT);\n    while (st.hasMoreTokens() && w.size()<100) {\n      w.add(st.nextToken());\n    }\n    words = w.toArray(new String[0]);\n\n    // create queries (that would find stuff) with varying slops\n    ArrayList<Query> queries = new ArrayList<Query>(); \n    for (int slop=0; slop<8; slop++) {\n      for (int qlen=2; qlen<6; qlen++) {\n        for (int wd=0; wd<words.length-qlen-slop; wd++) {\n          // ordered\n          int remainedSlop = slop;\n          PhraseQuery q = new PhraseQuery();\n          q.setSlop(slop);\n          int wind = wd;\n          for (int i=0; i<qlen; i++) {\n            q.add(new Term(DocMaker.BODY_FIELD,words[wind++]));\n            if (remainedSlop>0) {\n              remainedSlop--;\n              wind++;\n            }\n          }\n          queries.add(q);\n          // reversed\n          remainedSlop = slop;\n          q = new PhraseQuery();\n          q.setSlop(slop+2*qlen);\n          wind = wd+qlen+remainedSlop-1;\n          for (int i=0; i<qlen; i++) {\n            q.add(new Term(DocMaker.BODY_FIELD,words[wind--]));\n            if (remainedSlop>0) {\n              remainedSlop--;\n              wind--;\n            }\n          }\n          queries.add(q);\n        }\n      }\n    }\n    return queries.toArray(new Query[0]);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"70ad682703b8585f5d0a637efec044d57ec05efb":["9454a6510e2db155fb01faa5c049b06ece95fab9","ecc11368dc265bfdad90214f8bf5da99016ab1e2"],"ecc11368dc265bfdad90214f8bf5da99016ab1e2":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"868da859b43505d9d2a023bfeae6dd0c795f5295":["9454a6510e2db155fb01faa5c049b06ece95fab9","ecc11368dc265bfdad90214f8bf5da99016ab1e2"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["ecc11368dc265bfdad90214f8bf5da99016ab1e2"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"70ad682703b8585f5d0a637efec044d57ec05efb":[],"ecc11368dc265bfdad90214f8bf5da99016ab1e2":["70ad682703b8585f5d0a637efec044d57ec05efb","868da859b43505d9d2a023bfeae6dd0c795f5295","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"868da859b43505d9d2a023bfeae6dd0c795f5295":[],"9454a6510e2db155fb01faa5c049b06ece95fab9":["70ad682703b8585f5d0a637efec044d57ec05efb","ecc11368dc265bfdad90214f8bf5da99016ab1e2","868da859b43505d9d2a023bfeae6dd0c795f5295"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["70ad682703b8585f5d0a637efec044d57ec05efb","868da859b43505d9d2a023bfeae6dd0c795f5295","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}