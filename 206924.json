{"path":"lucene/memory/src/test/org/apache/lucene/index/memory/MemoryIndexTest#testDocsEnumStart().mjava","commits":[{"id":"b89678825b68eccaf09e6ab71675fc0b0af1e099","date":1334669779,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/memory/src/test/org/apache/lucene/index/memory/MemoryIndexTest#testDocsEnumStart().mjava","pathOld":"lucene/contrib/memory/src/test/org/apache/lucene/index/memory/MemoryIndexTest#testDocsEnumStart().mjava","sourceNew":"  public void testDocsEnumStart() throws Exception {\n    Analyzer analyzer = new MockAnalyzer(random());\n    MemoryIndex memory = new MemoryIndex();\n    memory.addField(\"foo\", \"bar\", analyzer);\n    AtomicReader reader = (AtomicReader) memory.createSearcher().getIndexReader();\n    DocsEnum disi = _TestUtil.docs(random(), reader, \"foo\", new BytesRef(\"bar\"), null, null, false);\n    int docid = disi.docID();\n    assertTrue(docid == -1 || docid == DocIdSetIterator.NO_MORE_DOCS);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    \n    // now reuse and check again\n    TermsEnum te = reader.terms(\"foo\").iterator(null);\n    assertTrue(te.seekExact(new BytesRef(\"bar\"), true));\n    disi = te.docs(null, disi, false);\n    docid = disi.docID();\n    assertTrue(docid == -1 || docid == DocIdSetIterator.NO_MORE_DOCS);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    reader.close();\n  }\n\n","sourceOld":"  public void testDocsEnumStart() throws Exception {\n    Analyzer analyzer = new MockAnalyzer(random());\n    MemoryIndex memory = new MemoryIndex();\n    memory.addField(\"foo\", \"bar\", analyzer);\n    AtomicReader reader = (AtomicReader) memory.createSearcher().getIndexReader();\n    DocsEnum disi = _TestUtil.docs(random(), reader, \"foo\", new BytesRef(\"bar\"), null, null, false);\n    int docid = disi.docID();\n    assertTrue(docid == -1 || docid == DocIdSetIterator.NO_MORE_DOCS);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    \n    // now reuse and check again\n    TermsEnum te = reader.terms(\"foo\").iterator(null);\n    assertTrue(te.seekExact(new BytesRef(\"bar\"), true));\n    disi = te.docs(null, disi, false);\n    docid = disi.docID();\n    assertTrue(docid == -1 || docid == DocIdSetIterator.NO_MORE_DOCS);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"02331260bb246364779cb6f04919ca47900d01bb","date":1343749884,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/memory/src/test/org/apache/lucene/index/memory/MemoryIndexTest#testDocsEnumStart().mjava","pathOld":"lucene/memory/src/test/org/apache/lucene/index/memory/MemoryIndexTest#testDocsEnumStart().mjava","sourceNew":"  public void testDocsEnumStart() throws Exception {\n    Analyzer analyzer = new MockAnalyzer(random());\n    MemoryIndex memory = new MemoryIndex();\n    memory.addField(\"foo\", \"bar\", analyzer);\n    AtomicReader reader = (AtomicReader) memory.createSearcher().getIndexReader();\n    DocsEnum disi = _TestUtil.docs(random(), reader, \"foo\", new BytesRef(\"bar\"), null, null, 0);\n    int docid = disi.docID();\n    assertTrue(docid == -1 || docid == DocIdSetIterator.NO_MORE_DOCS);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    \n    // now reuse and check again\n    TermsEnum te = reader.terms(\"foo\").iterator(null);\n    assertTrue(te.seekExact(new BytesRef(\"bar\"), true));\n    disi = te.docs(null, disi, 0);\n    docid = disi.docID();\n    assertTrue(docid == -1 || docid == DocIdSetIterator.NO_MORE_DOCS);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    reader.close();\n  }\n\n","sourceOld":"  public void testDocsEnumStart() throws Exception {\n    Analyzer analyzer = new MockAnalyzer(random());\n    MemoryIndex memory = new MemoryIndex();\n    memory.addField(\"foo\", \"bar\", analyzer);\n    AtomicReader reader = (AtomicReader) memory.createSearcher().getIndexReader();\n    DocsEnum disi = _TestUtil.docs(random(), reader, \"foo\", new BytesRef(\"bar\"), null, null, false);\n    int docid = disi.docID();\n    assertTrue(docid == -1 || docid == DocIdSetIterator.NO_MORE_DOCS);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    \n    // now reuse and check again\n    TermsEnum te = reader.terms(\"foo\").iterator(null);\n    assertTrue(te.seekExact(new BytesRef(\"bar\"), true));\n    disi = te.docs(null, disi, false);\n    docid = disi.docID();\n    assertTrue(docid == -1 || docid == DocIdSetIterator.NO_MORE_DOCS);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    reader.close();\n  }\n\n","bugFix":["629c38c4ae4e303d0617e05fbfe508140b32f0a3","872cff1d3a554e0cd64014cd97f88d3002b0f491"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f","date":1343768312,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/memory/src/test/org/apache/lucene/index/memory/MemoryIndexTest#testDocsEnumStart().mjava","pathOld":"lucene/memory/src/test/org/apache/lucene/index/memory/MemoryIndexTest#testDocsEnumStart().mjava","sourceNew":"  public void testDocsEnumStart() throws Exception {\n    Analyzer analyzer = new MockAnalyzer(random());\n    MemoryIndex memory = new MemoryIndex();\n    memory.addField(\"foo\", \"bar\", analyzer);\n    AtomicReader reader = (AtomicReader) memory.createSearcher().getIndexReader();\n    DocsEnum disi = _TestUtil.docs(random(), reader, \"foo\", new BytesRef(\"bar\"), null, null, 0);\n    int docid = disi.docID();\n    assertTrue(docid == -1 || docid == DocIdSetIterator.NO_MORE_DOCS);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    \n    // now reuse and check again\n    TermsEnum te = reader.terms(\"foo\").iterator(null);\n    assertTrue(te.seekExact(new BytesRef(\"bar\"), true));\n    disi = te.docs(null, disi, 0);\n    docid = disi.docID();\n    assertTrue(docid == -1 || docid == DocIdSetIterator.NO_MORE_DOCS);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    reader.close();\n  }\n\n","sourceOld":"  public void testDocsEnumStart() throws Exception {\n    Analyzer analyzer = new MockAnalyzer(random());\n    MemoryIndex memory = new MemoryIndex();\n    memory.addField(\"foo\", \"bar\", analyzer);\n    AtomicReader reader = (AtomicReader) memory.createSearcher().getIndexReader();\n    DocsEnum disi = _TestUtil.docs(random(), reader, \"foo\", new BytesRef(\"bar\"), null, null, false);\n    int docid = disi.docID();\n    assertTrue(docid == -1 || docid == DocIdSetIterator.NO_MORE_DOCS);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    \n    // now reuse and check again\n    TermsEnum te = reader.terms(\"foo\").iterator(null);\n    assertTrue(te.seekExact(new BytesRef(\"bar\"), true));\n    disi = te.docs(null, disi, false);\n    docid = disi.docID();\n    assertTrue(docid == -1 || docid == DocIdSetIterator.NO_MORE_DOCS);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d6f074e73200c07d54f242d3880a8da5a35ff97b","date":1344507653,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/memory/src/test/org/apache/lucene/index/memory/MemoryIndexTest#testDocsEnumStart().mjava","pathOld":"lucene/memory/src/test/org/apache/lucene/index/memory/MemoryIndexTest#testDocsEnumStart().mjava","sourceNew":"  public void testDocsEnumStart() throws Exception {\n    Analyzer analyzer = new MockAnalyzer(random());\n    MemoryIndex memory = new MemoryIndex();\n    memory.addField(\"foo\", \"bar\", analyzer);\n    AtomicReader reader = (AtomicReader) memory.createSearcher().getIndexReader();\n    DocsEnum disi = _TestUtil.docs(random(), reader, \"foo\", new BytesRef(\"bar\"), null, null, 0);\n    int docid = disi.docID();\n    assertTrue(docid == -1 || docid == DocIdSetIterator.NO_MORE_DOCS);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    \n    // now reuse and check again\n    TermsEnum te = reader.terms(\"foo\").iterator(null);\n    assertTrue(te.seekExact(new BytesRef(\"bar\"), true));\n    disi = te.docs(null, disi, 0);\n    docid = disi.docID();\n    assertTrue(docid == -1 || docid == DocIdSetIterator.NO_MORE_DOCS);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    reader.close();\n  }\n\n","sourceOld":"  public void testDocsEnumStart() throws Exception {\n    Analyzer analyzer = new MockAnalyzer(random());\n    MemoryIndex memory = new MemoryIndex();\n    memory.addField(\"foo\", \"bar\", analyzer);\n    AtomicReader reader = (AtomicReader) memory.createSearcher().getIndexReader();\n    DocsEnum disi = _TestUtil.docs(random(), reader, \"foo\", new BytesRef(\"bar\"), null, null, false);\n    int docid = disi.docID();\n    assertTrue(docid == -1 || docid == DocIdSetIterator.NO_MORE_DOCS);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    \n    // now reuse and check again\n    TermsEnum te = reader.terms(\"foo\").iterator(null);\n    assertTrue(te.seekExact(new BytesRef(\"bar\"), true));\n    disi = te.docs(null, disi, false);\n    docid = disi.docID();\n    assertTrue(docid == -1 || docid == DocIdSetIterator.NO_MORE_DOCS);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"30fd30bfbfa6b9e036bcd99c8339712e965d4a63","date":1351859294,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/memory/src/test/org/apache/lucene/index/memory/MemoryIndexTest#testDocsEnumStart().mjava","pathOld":"lucene/memory/src/test/org/apache/lucene/index/memory/MemoryIndexTest#testDocsEnumStart().mjava","sourceNew":"  public void testDocsEnumStart() throws Exception {\n    Analyzer analyzer = new MockAnalyzer(random());\n    MemoryIndex memory = new MemoryIndex(random().nextBoolean(),  random().nextInt(50) * 1024 * 1024);\n    memory.addField(\"foo\", \"bar\", analyzer);\n    AtomicReader reader = (AtomicReader) memory.createSearcher().getIndexReader();\n    DocsEnum disi = _TestUtil.docs(random(), reader, \"foo\", new BytesRef(\"bar\"), null, null, 0);\n    int docid = disi.docID();\n    assertTrue(docid == -1 || docid == DocIdSetIterator.NO_MORE_DOCS);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    \n    // now reuse and check again\n    TermsEnum te = reader.terms(\"foo\").iterator(null);\n    assertTrue(te.seekExact(new BytesRef(\"bar\"), true));\n    disi = te.docs(null, disi, 0);\n    docid = disi.docID();\n    assertTrue(docid == -1 || docid == DocIdSetIterator.NO_MORE_DOCS);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    reader.close();\n  }\n\n","sourceOld":"  public void testDocsEnumStart() throws Exception {\n    Analyzer analyzer = new MockAnalyzer(random());\n    MemoryIndex memory = new MemoryIndex();\n    memory.addField(\"foo\", \"bar\", analyzer);\n    AtomicReader reader = (AtomicReader) memory.createSearcher().getIndexReader();\n    DocsEnum disi = _TestUtil.docs(random(), reader, \"foo\", new BytesRef(\"bar\"), null, null, 0);\n    int docid = disi.docID();\n    assertTrue(docid == -1 || docid == DocIdSetIterator.NO_MORE_DOCS);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    \n    // now reuse and check again\n    TermsEnum te = reader.terms(\"foo\").iterator(null);\n    assertTrue(te.seekExact(new BytesRef(\"bar\"), true));\n    disi = te.docs(null, disi, 0);\n    docid = disi.docID();\n    assertTrue(docid == -1 || docid == DocIdSetIterator.NO_MORE_DOCS);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"15250ca94ba8ab3bcdd476daf6bf3f3febb92640","date":1355200097,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/memory/src/test/org/apache/lucene/index/memory/MemoryIndexTest#testDocsEnumStart().mjava","pathOld":"lucene/memory/src/test/org/apache/lucene/index/memory/MemoryIndexTest#testDocsEnumStart().mjava","sourceNew":"  public void testDocsEnumStart() throws Exception {\n    Analyzer analyzer = new MockAnalyzer(random());\n    MemoryIndex memory = new MemoryIndex(random().nextBoolean(),  random().nextInt(50) * 1024 * 1024);\n    memory.addField(\"foo\", \"bar\", analyzer);\n    AtomicReader reader = (AtomicReader) memory.createSearcher().getIndexReader();\n    DocsEnum disi = _TestUtil.docs(random(), reader, \"foo\", new BytesRef(\"bar\"), null, null, DocsEnum.FLAG_NONE);\n    int docid = disi.docID();\n    assertTrue(docid == -1 || docid == DocIdSetIterator.NO_MORE_DOCS);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    \n    // now reuse and check again\n    TermsEnum te = reader.terms(\"foo\").iterator(null);\n    assertTrue(te.seekExact(new BytesRef(\"bar\"), true));\n    disi = te.docs(null, disi, DocsEnum.FLAG_NONE);\n    docid = disi.docID();\n    assertTrue(docid == -1 || docid == DocIdSetIterator.NO_MORE_DOCS);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    reader.close();\n  }\n\n","sourceOld":"  public void testDocsEnumStart() throws Exception {\n    Analyzer analyzer = new MockAnalyzer(random());\n    MemoryIndex memory = new MemoryIndex(random().nextBoolean(),  random().nextInt(50) * 1024 * 1024);\n    memory.addField(\"foo\", \"bar\", analyzer);\n    AtomicReader reader = (AtomicReader) memory.createSearcher().getIndexReader();\n    DocsEnum disi = _TestUtil.docs(random(), reader, \"foo\", new BytesRef(\"bar\"), null, null, 0);\n    int docid = disi.docID();\n    assertTrue(docid == -1 || docid == DocIdSetIterator.NO_MORE_DOCS);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    \n    // now reuse and check again\n    TermsEnum te = reader.terms(\"foo\").iterator(null);\n    assertTrue(te.seekExact(new BytesRef(\"bar\"), true));\n    disi = te.docs(null, disi, 0);\n    docid = disi.docID();\n    assertTrue(docid == -1 || docid == DocIdSetIterator.NO_MORE_DOCS);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d3fcb70cf561547c7bb1506e0cf32ca7b1287064","date":1357616416,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/memory/src/test/org/apache/lucene/index/memory/MemoryIndexTest#testDocsEnumStart().mjava","pathOld":"lucene/memory/src/test/org/apache/lucene/index/memory/MemoryIndexTest#testDocsEnumStart().mjava","sourceNew":"  public void testDocsEnumStart() throws Exception {\n    Analyzer analyzer = new MockAnalyzer(random());\n    MemoryIndex memory = new MemoryIndex(random().nextBoolean(),  random().nextInt(50) * 1024 * 1024);\n    memory.addField(\"foo\", \"bar\", analyzer);\n    AtomicReader reader = (AtomicReader) memory.createSearcher().getIndexReader();\n    DocsEnum disi = _TestUtil.docs(random(), reader, \"foo\", new BytesRef(\"bar\"), null, null, DocsEnum.FLAG_NONE);\n    int docid = disi.docID();\n    assertTrue(docid == -1 || docid == DocIdSetIterator.NO_MORE_DOCS);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    \n    // now reuse and check again\n    TermsEnum te = reader.terms(\"foo\").iterator(null);\n    assertTrue(te.seekExact(new BytesRef(\"bar\"), true));\n    disi = te.docs(null, disi, DocsEnum.FLAG_NONE);\n    docid = disi.docID();\n    assertTrue(docid == -1 || docid == DocIdSetIterator.NO_MORE_DOCS);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    reader.close();\n  }\n\n","sourceOld":"  public void testDocsEnumStart() throws Exception {\n    Analyzer analyzer = new MockAnalyzer(random());\n    MemoryIndex memory = new MemoryIndex(random().nextBoolean(),  random().nextInt(50) * 1024 * 1024);\n    memory.addField(\"foo\", \"bar\", analyzer);\n    AtomicReader reader = (AtomicReader) memory.createSearcher().getIndexReader();\n    DocsEnum disi = _TestUtil.docs(random(), reader, \"foo\", new BytesRef(\"bar\"), null, null, 0);\n    int docid = disi.docID();\n    assertTrue(docid == -1 || docid == DocIdSetIterator.NO_MORE_DOCS);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    \n    // now reuse and check again\n    TermsEnum te = reader.terms(\"foo\").iterator(null);\n    assertTrue(te.seekExact(new BytesRef(\"bar\"), true));\n    disi = te.docs(null, disi, 0);\n    docid = disi.docID();\n    assertTrue(docid == -1 || docid == DocIdSetIterator.NO_MORE_DOCS);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"af527d067afb6ca5bd58afc7b9a5fbc0f80979af","date":1366034882,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/memory/src/test/org/apache/lucene/index/memory/MemoryIndexTest#testDocsEnumStart().mjava","pathOld":"lucene/memory/src/test/org/apache/lucene/index/memory/MemoryIndexTest#testDocsEnumStart().mjava","sourceNew":"  public void testDocsEnumStart() throws Exception {\n    Analyzer analyzer = new MockAnalyzer(random());\n    MemoryIndex memory = new MemoryIndex(random().nextBoolean(),  random().nextInt(50) * 1024 * 1024);\n    memory.addField(\"foo\", \"bar\", analyzer);\n    AtomicReader reader = (AtomicReader) memory.createSearcher().getIndexReader();\n    DocsEnum disi = _TestUtil.docs(random(), reader, \"foo\", new BytesRef(\"bar\"), null, null, DocsEnum.FLAG_NONE);\n    int docid = disi.docID();\n    assertEquals(-1, docid);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    \n    // now reuse and check again\n    TermsEnum te = reader.terms(\"foo\").iterator(null);\n    assertTrue(te.seekExact(new BytesRef(\"bar\"), true));\n    disi = te.docs(null, disi, DocsEnum.FLAG_NONE);\n    docid = disi.docID();\n    assertEquals(-1, docid);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    reader.close();\n  }\n\n","sourceOld":"  public void testDocsEnumStart() throws Exception {\n    Analyzer analyzer = new MockAnalyzer(random());\n    MemoryIndex memory = new MemoryIndex(random().nextBoolean(),  random().nextInt(50) * 1024 * 1024);\n    memory.addField(\"foo\", \"bar\", analyzer);\n    AtomicReader reader = (AtomicReader) memory.createSearcher().getIndexReader();\n    DocsEnum disi = _TestUtil.docs(random(), reader, \"foo\", new BytesRef(\"bar\"), null, null, DocsEnum.FLAG_NONE);\n    int docid = disi.docID();\n    assertTrue(docid == -1 || docid == DocIdSetIterator.NO_MORE_DOCS);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    \n    // now reuse and check again\n    TermsEnum te = reader.terms(\"foo\").iterator(null);\n    assertTrue(te.seekExact(new BytesRef(\"bar\"), true));\n    disi = te.docs(null, disi, DocsEnum.FLAG_NONE);\n    docid = disi.docID();\n    assertTrue(docid == -1 || docid == DocIdSetIterator.NO_MORE_DOCS);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"eee5f2a24465d2c9a5f86ab84b7c35041a30fda8","date":1373996650,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/memory/src/test/org/apache/lucene/index/memory/MemoryIndexTest#testDocsEnumStart().mjava","pathOld":"lucene/memory/src/test/org/apache/lucene/index/memory/MemoryIndexTest#testDocsEnumStart().mjava","sourceNew":"  public void testDocsEnumStart() throws Exception {\n    Analyzer analyzer = new MockAnalyzer(random());\n    MemoryIndex memory = new MemoryIndex(random().nextBoolean(),  random().nextInt(50) * 1024 * 1024);\n    memory.addField(\"foo\", \"bar\", analyzer);\n    AtomicReader reader = (AtomicReader) memory.createSearcher().getIndexReader();\n    DocsEnum disi = _TestUtil.docs(random(), reader, \"foo\", new BytesRef(\"bar\"), null, null, DocsEnum.FLAG_NONE);\n    int docid = disi.docID();\n    assertEquals(-1, docid);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    \n    // now reuse and check again\n    TermsEnum te = reader.terms(\"foo\").iterator(null);\n    assertTrue(te.seekExact(new BytesRef(\"bar\")));\n    disi = te.docs(null, disi, DocsEnum.FLAG_NONE);\n    docid = disi.docID();\n    assertEquals(-1, docid);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    reader.close();\n  }\n\n","sourceOld":"  public void testDocsEnumStart() throws Exception {\n    Analyzer analyzer = new MockAnalyzer(random());\n    MemoryIndex memory = new MemoryIndex(random().nextBoolean(),  random().nextInt(50) * 1024 * 1024);\n    memory.addField(\"foo\", \"bar\", analyzer);\n    AtomicReader reader = (AtomicReader) memory.createSearcher().getIndexReader();\n    DocsEnum disi = _TestUtil.docs(random(), reader, \"foo\", new BytesRef(\"bar\"), null, null, DocsEnum.FLAG_NONE);\n    int docid = disi.docID();\n    assertEquals(-1, docid);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    \n    // now reuse and check again\n    TermsEnum te = reader.terms(\"foo\").iterator(null);\n    assertTrue(te.seekExact(new BytesRef(\"bar\"), true));\n    disi = te.docs(null, disi, DocsEnum.FLAG_NONE);\n    docid = disi.docID();\n    assertEquals(-1, docid);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee","date":1376366778,"type":3,"author":"Han Jiang","isMerge":false,"pathNew":"lucene/memory/src/test/org/apache/lucene/index/memory/MemoryIndexTest#testDocsEnumStart().mjava","pathOld":"lucene/memory/src/test/org/apache/lucene/index/memory/MemoryIndexTest#testDocsEnumStart().mjava","sourceNew":"  public void testDocsEnumStart() throws Exception {\n    Analyzer analyzer = new MockAnalyzer(random());\n    MemoryIndex memory = new MemoryIndex(random().nextBoolean(),  random().nextInt(50) * 1024 * 1024);\n    memory.addField(\"foo\", \"bar\", analyzer);\n    AtomicReader reader = (AtomicReader) memory.createSearcher().getIndexReader();\n    DocsEnum disi = _TestUtil.docs(random(), reader, \"foo\", new BytesRef(\"bar\"), null, null, DocsEnum.FLAG_NONE);\n    int docid = disi.docID();\n    assertEquals(-1, docid);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    \n    // now reuse and check again\n    TermsEnum te = reader.terms(\"foo\").iterator(null);\n    assertTrue(te.seekExact(new BytesRef(\"bar\")));\n    disi = te.docs(null, disi, DocsEnum.FLAG_NONE);\n    docid = disi.docID();\n    assertEquals(-1, docid);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    reader.close();\n  }\n\n","sourceOld":"  public void testDocsEnumStart() throws Exception {\n    Analyzer analyzer = new MockAnalyzer(random());\n    MemoryIndex memory = new MemoryIndex(random().nextBoolean(),  random().nextInt(50) * 1024 * 1024);\n    memory.addField(\"foo\", \"bar\", analyzer);\n    AtomicReader reader = (AtomicReader) memory.createSearcher().getIndexReader();\n    DocsEnum disi = _TestUtil.docs(random(), reader, \"foo\", new BytesRef(\"bar\"), null, null, DocsEnum.FLAG_NONE);\n    int docid = disi.docID();\n    assertEquals(-1, docid);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    \n    // now reuse and check again\n    TermsEnum te = reader.terms(\"foo\").iterator(null);\n    assertTrue(te.seekExact(new BytesRef(\"bar\"), true));\n    disi = te.docs(null, disi, DocsEnum.FLAG_NONE);\n    docid = disi.docID();\n    assertEquals(-1, docid);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6613659748fe4411a7dcf85266e55db1f95f7315","date":1392773913,"type":3,"author":"Benson Margulies","isMerge":false,"pathNew":"lucene/memory/src/test/org/apache/lucene/index/memory/MemoryIndexTest#testDocsEnumStart().mjava","pathOld":"lucene/memory/src/test/org/apache/lucene/index/memory/MemoryIndexTest#testDocsEnumStart().mjava","sourceNew":"  public void testDocsEnumStart() throws Exception {\n    Analyzer analyzer = new MockAnalyzer(random());\n    MemoryIndex memory = new MemoryIndex(random().nextBoolean(),  random().nextInt(50) * 1024 * 1024);\n    memory.addField(\"foo\", \"bar\", analyzer);\n    AtomicReader reader = (AtomicReader) memory.createSearcher().getIndexReader();\n    DocsEnum disi = TestUtil.docs(random(), reader, \"foo\", new BytesRef(\"bar\"), null, null, DocsEnum.FLAG_NONE);\n    int docid = disi.docID();\n    assertEquals(-1, docid);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    \n    // now reuse and check again\n    TermsEnum te = reader.terms(\"foo\").iterator(null);\n    assertTrue(te.seekExact(new BytesRef(\"bar\")));\n    disi = te.docs(null, disi, DocsEnum.FLAG_NONE);\n    docid = disi.docID();\n    assertEquals(-1, docid);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    reader.close();\n  }\n\n","sourceOld":"  public void testDocsEnumStart() throws Exception {\n    Analyzer analyzer = new MockAnalyzer(random());\n    MemoryIndex memory = new MemoryIndex(random().nextBoolean(),  random().nextInt(50) * 1024 * 1024);\n    memory.addField(\"foo\", \"bar\", analyzer);\n    AtomicReader reader = (AtomicReader) memory.createSearcher().getIndexReader();\n    DocsEnum disi = _TestUtil.docs(random(), reader, \"foo\", new BytesRef(\"bar\"), null, null, DocsEnum.FLAG_NONE);\n    int docid = disi.docID();\n    assertEquals(-1, docid);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    \n    // now reuse and check again\n    TermsEnum te = reader.terms(\"foo\").iterator(null);\n    assertTrue(te.seekExact(new BytesRef(\"bar\")));\n    disi = te.docs(null, disi, DocsEnum.FLAG_NONE);\n    docid = disi.docID();\n    assertEquals(-1, docid);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c9fb5f46e264daf5ba3860defe623a89d202dd87","date":1411516315,"type":3,"author":"Ryan Ernst","isMerge":false,"pathNew":"lucene/memory/src/test/org/apache/lucene/index/memory/MemoryIndexTest#testDocsEnumStart().mjava","pathOld":"lucene/memory/src/test/org/apache/lucene/index/memory/MemoryIndexTest#testDocsEnumStart().mjava","sourceNew":"  public void testDocsEnumStart() throws Exception {\n    Analyzer analyzer = new MockAnalyzer(random());\n    MemoryIndex memory = new MemoryIndex(random().nextBoolean(),  random().nextInt(50) * 1024 * 1024);\n    memory.addField(\"foo\", \"bar\", analyzer);\n    LeafReader reader = (LeafReader) memory.createSearcher().getIndexReader();\n    DocsEnum disi = TestUtil.docs(random(), reader, \"foo\", new BytesRef(\"bar\"), null, null, DocsEnum.FLAG_NONE);\n    int docid = disi.docID();\n    assertEquals(-1, docid);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    \n    // now reuse and check again\n    TermsEnum te = reader.terms(\"foo\").iterator(null);\n    assertTrue(te.seekExact(new BytesRef(\"bar\")));\n    disi = te.docs(null, disi, DocsEnum.FLAG_NONE);\n    docid = disi.docID();\n    assertEquals(-1, docid);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    reader.close();\n  }\n\n","sourceOld":"  public void testDocsEnumStart() throws Exception {\n    Analyzer analyzer = new MockAnalyzer(random());\n    MemoryIndex memory = new MemoryIndex(random().nextBoolean(),  random().nextInt(50) * 1024 * 1024);\n    memory.addField(\"foo\", \"bar\", analyzer);\n    AtomicReader reader = (AtomicReader) memory.createSearcher().getIndexReader();\n    DocsEnum disi = TestUtil.docs(random(), reader, \"foo\", new BytesRef(\"bar\"), null, null, DocsEnum.FLAG_NONE);\n    int docid = disi.docID();\n    assertEquals(-1, docid);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    \n    // now reuse and check again\n    TermsEnum te = reader.terms(\"foo\").iterator(null);\n    assertTrue(te.seekExact(new BytesRef(\"bar\")));\n    disi = te.docs(null, disi, DocsEnum.FLAG_NONE);\n    docid = disi.docID();\n    assertEquals(-1, docid);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"761333d77c7f29123c00c93b107b743f32f012e6","date":1411986072,"type":5,"author":"Alan Woodward","isMerge":false,"pathNew":"lucene/memory/src/test/org/apache/lucene/index/memory/TestMemoryIndexAgainstRAMDir#testDocsEnumStart().mjava","pathOld":"lucene/memory/src/test/org/apache/lucene/index/memory/MemoryIndexTest#testDocsEnumStart().mjava","sourceNew":"  public void testDocsEnumStart() throws Exception {\n    Analyzer analyzer = new MockAnalyzer(random());\n    MemoryIndex memory = new MemoryIndex(random().nextBoolean(),  random().nextInt(50) * 1024 * 1024);\n    memory.addField(\"foo\", \"bar\", analyzer);\n    LeafReader reader = (LeafReader) memory.createSearcher().getIndexReader();\n    DocsEnum disi = TestUtil.docs(random(), reader, \"foo\", new BytesRef(\"bar\"), null, null, DocsEnum.FLAG_NONE);\n    int docid = disi.docID();\n    assertEquals(-1, docid);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    \n    // now reuse and check again\n    TermsEnum te = reader.terms(\"foo\").iterator(null);\n    assertTrue(te.seekExact(new BytesRef(\"bar\")));\n    disi = te.docs(null, disi, DocsEnum.FLAG_NONE);\n    docid = disi.docID();\n    assertEquals(-1, docid);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    reader.close();\n  }\n\n","sourceOld":"  public void testDocsEnumStart() throws Exception {\n    Analyzer analyzer = new MockAnalyzer(random());\n    MemoryIndex memory = new MemoryIndex(random().nextBoolean(),  random().nextInt(50) * 1024 * 1024);\n    memory.addField(\"foo\", \"bar\", analyzer);\n    LeafReader reader = (LeafReader) memory.createSearcher().getIndexReader();\n    DocsEnum disi = TestUtil.docs(random(), reader, \"foo\", new BytesRef(\"bar\"), null, null, DocsEnum.FLAG_NONE);\n    int docid = disi.docID();\n    assertEquals(-1, docid);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    \n    // now reuse and check again\n    TermsEnum te = reader.terms(\"foo\").iterator(null);\n    assertTrue(te.seekExact(new BytesRef(\"bar\")));\n    disi = te.docs(null, disi, DocsEnum.FLAG_NONE);\n    docid = disi.docID();\n    assertEquals(-1, docid);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d9a47902d6207303f5ed3e7aaca62ca33433af66","date":1412435312,"type":5,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/memory/src/test/org/apache/lucene/index/memory/TestMemoryIndexAgainstRAMDir#testDocsEnumStart().mjava","pathOld":"lucene/memory/src/test/org/apache/lucene/index/memory/MemoryIndexTest#testDocsEnumStart().mjava","sourceNew":"  public void testDocsEnumStart() throws Exception {\n    Analyzer analyzer = new MockAnalyzer(random());\n    MemoryIndex memory = new MemoryIndex(random().nextBoolean(),  random().nextInt(50) * 1024 * 1024);\n    memory.addField(\"foo\", \"bar\", analyzer);\n    LeafReader reader = (LeafReader) memory.createSearcher().getIndexReader();\n    DocsEnum disi = TestUtil.docs(random(), reader, \"foo\", new BytesRef(\"bar\"), null, null, DocsEnum.FLAG_NONE);\n    int docid = disi.docID();\n    assertEquals(-1, docid);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    \n    // now reuse and check again\n    TermsEnum te = reader.terms(\"foo\").iterator(null);\n    assertTrue(te.seekExact(new BytesRef(\"bar\")));\n    disi = te.docs(null, disi, DocsEnum.FLAG_NONE);\n    docid = disi.docID();\n    assertEquals(-1, docid);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    reader.close();\n  }\n\n","sourceOld":"  public void testDocsEnumStart() throws Exception {\n    Analyzer analyzer = new MockAnalyzer(random());\n    MemoryIndex memory = new MemoryIndex(random().nextBoolean(),  random().nextInt(50) * 1024 * 1024);\n    memory.addField(\"foo\", \"bar\", analyzer);\n    LeafReader reader = (LeafReader) memory.createSearcher().getIndexReader();\n    DocsEnum disi = TestUtil.docs(random(), reader, \"foo\", new BytesRef(\"bar\"), null, null, DocsEnum.FLAG_NONE);\n    int docid = disi.docID();\n    assertEquals(-1, docid);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    \n    // now reuse and check again\n    TermsEnum te = reader.terms(\"foo\").iterator(null);\n    assertTrue(te.seekExact(new BytesRef(\"bar\")));\n    disi = te.docs(null, disi, DocsEnum.FLAG_NONE);\n    docid = disi.docID();\n    assertEquals(-1, docid);\n    assertTrue(disi.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"d3fcb70cf561547c7bb1506e0cf32ca7b1287064":["30fd30bfbfa6b9e036bcd99c8339712e965d4a63","15250ca94ba8ab3bcdd476daf6bf3f3febb92640"],"af527d067afb6ca5bd58afc7b9a5fbc0f80979af":["15250ca94ba8ab3bcdd476daf6bf3f3febb92640"],"6613659748fe4411a7dcf85266e55db1f95f7315":["eee5f2a24465d2c9a5f86ab84b7c35041a30fda8"],"d9a47902d6207303f5ed3e7aaca62ca33433af66":["c9fb5f46e264daf5ba3860defe623a89d202dd87","761333d77c7f29123c00c93b107b743f32f012e6"],"c9fb5f46e264daf5ba3860defe623a89d202dd87":["6613659748fe4411a7dcf85266e55db1f95f7315"],"b89678825b68eccaf09e6ab71675fc0b0af1e099":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"15250ca94ba8ab3bcdd476daf6bf3f3febb92640":["30fd30bfbfa6b9e036bcd99c8339712e965d4a63"],"30fd30bfbfa6b9e036bcd99c8339712e965d4a63":["02331260bb246364779cb6f04919ca47900d01bb"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f":["b89678825b68eccaf09e6ab71675fc0b0af1e099","02331260bb246364779cb6f04919ca47900d01bb"],"8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee":["af527d067afb6ca5bd58afc7b9a5fbc0f80979af"],"d6f074e73200c07d54f242d3880a8da5a35ff97b":["b89678825b68eccaf09e6ab71675fc0b0af1e099","02331260bb246364779cb6f04919ca47900d01bb"],"761333d77c7f29123c00c93b107b743f32f012e6":["c9fb5f46e264daf5ba3860defe623a89d202dd87"],"eee5f2a24465d2c9a5f86ab84b7c35041a30fda8":["af527d067afb6ca5bd58afc7b9a5fbc0f80979af"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["761333d77c7f29123c00c93b107b743f32f012e6"],"02331260bb246364779cb6f04919ca47900d01bb":["b89678825b68eccaf09e6ab71675fc0b0af1e099"]},"commit2Childs":{"d3fcb70cf561547c7bb1506e0cf32ca7b1287064":[],"af527d067afb6ca5bd58afc7b9a5fbc0f80979af":["8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee","eee5f2a24465d2c9a5f86ab84b7c35041a30fda8"],"6613659748fe4411a7dcf85266e55db1f95f7315":["c9fb5f46e264daf5ba3860defe623a89d202dd87"],"d9a47902d6207303f5ed3e7aaca62ca33433af66":[],"c9fb5f46e264daf5ba3860defe623a89d202dd87":["d9a47902d6207303f5ed3e7aaca62ca33433af66","761333d77c7f29123c00c93b107b743f32f012e6"],"b89678825b68eccaf09e6ab71675fc0b0af1e099":["b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f","d6f074e73200c07d54f242d3880a8da5a35ff97b","02331260bb246364779cb6f04919ca47900d01bb"],"15250ca94ba8ab3bcdd476daf6bf3f3febb92640":["d3fcb70cf561547c7bb1506e0cf32ca7b1287064","af527d067afb6ca5bd58afc7b9a5fbc0f80979af"],"30fd30bfbfa6b9e036bcd99c8339712e965d4a63":["d3fcb70cf561547c7bb1506e0cf32ca7b1287064","15250ca94ba8ab3bcdd476daf6bf3f3febb92640"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["b89678825b68eccaf09e6ab71675fc0b0af1e099"],"b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f":[],"8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee":[],"d6f074e73200c07d54f242d3880a8da5a35ff97b":[],"eee5f2a24465d2c9a5f86ab84b7c35041a30fda8":["6613659748fe4411a7dcf85266e55db1f95f7315"],"761333d77c7f29123c00c93b107b743f32f012e6":["d9a47902d6207303f5ed3e7aaca62ca33433af66","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"02331260bb246364779cb6f04919ca47900d01bb":["30fd30bfbfa6b9e036bcd99c8339712e965d4a63","b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f","d6f074e73200c07d54f242d3880a8da5a35ff97b"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["d3fcb70cf561547c7bb1506e0cf32ca7b1287064","d9a47902d6207303f5ed3e7aaca62ca33433af66","b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f","8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee","d6f074e73200c07d54f242d3880a8da5a35ff97b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}