{"path":"lucene/queryparser/src/test/org/apache/lucene/queryparser/xml/TestCoreParser#beforeClass().mjava","commits":[{"id":"f054843acc706da8f2f007c842699d62e4af736c","date":1450870707,"type":1,"author":"Christine Poerschke","isMerge":false,"pathNew":"lucene/queryparser/src/test/org/apache/lucene/queryparser/xml/TestCoreParser#beforeClass().mjava","pathOld":"lucene/queryparser/src/test/org/apache/lucene/queryparser/xml/TestParser#beforeClass().mjava","sourceNew":"  @BeforeClass\n  public static void beforeClass() throws Exception {\n    // TODO: rewrite test (this needs to set QueryParser.enablePositionIncrements, too, for work with CURRENT):\n    analyzer = new MockAnalyzer(random(), MockTokenizer.WHITESPACE, true, MockTokenFilter.ENGLISH_STOPSET);\n    //initialize the parser\n    coreParser = new CoreParser(defaultField, analyzer);\n\n    BufferedReader d = new BufferedReader(new InputStreamReader(\n        TestCoreParser.class.getResourceAsStream(\"reuters21578.txt\"), StandardCharsets.US_ASCII));\n    dir = newDirectory();\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(analyzer));\n    String line = d.readLine();\n    while (line != null) {\n      int endOfDate = line.indexOf('\\t');\n      String date = line.substring(0, endOfDate).trim();\n      String content = line.substring(endOfDate).trim();\n      Document doc = new Document();\n      doc.add(newTextField(\"date\", date, Field.Store.YES));\n      doc.add(newTextField(\"contents\", content, Field.Store.YES));\n      doc.add(new LegacyIntField(\"date2\", Integer.valueOf(date), Field.Store.NO));\n      writer.addDocument(doc);\n      line = d.readLine();\n    }\n    d.close();\n    writer.close();\n    reader = DirectoryReader.open(dir);\n    searcher = newSearcher(reader);\n\n  }\n\n","sourceOld":"  @BeforeClass\n  public static void beforeClass() throws Exception {\n    // TODO: rewrite test (this needs to set QueryParser.enablePositionIncrements, too, for work with CURRENT):\n    analyzer = new MockAnalyzer(random(), MockTokenizer.WHITESPACE, true, MockTokenFilter.ENGLISH_STOPSET);\n    //initialize the parser\n    coreParser = new CoreParser(defaultField, analyzer);\n\n    BufferedReader d = new BufferedReader(new InputStreamReader(\n        TestParser.class.getResourceAsStream(\"reuters21578.txt\"), StandardCharsets.US_ASCII));\n    dir = newDirectory();\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(analyzer));\n    String line = d.readLine();\n    while (line != null) {\n      int endOfDate = line.indexOf('\\t');\n      String date = line.substring(0, endOfDate).trim();\n      String content = line.substring(endOfDate).trim();\n      Document doc = new Document();\n      doc.add(newTextField(\"date\", date, Field.Store.YES));\n      doc.add(newTextField(\"contents\", content, Field.Store.YES));\n      doc.add(new LegacyIntField(\"date2\", Integer.valueOf(date), Field.Store.NO));\n      writer.addDocument(doc);\n      line = d.readLine();\n    }\n    d.close();\n    writer.close();\n    reader = DirectoryReader.open(dir);\n    searcher = newSearcher(reader);\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3057b45cc5245d8fd8999a4bbe04da2c59511b75","date":1457536053,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/queryparser/src/test/org/apache/lucene/queryparser/xml/TestCoreParser#beforeClass().mjava","pathOld":"lucene/queryparser/src/test/org/apache/lucene/queryparser/xml/TestCoreParser#beforeClass().mjava","sourceNew":"  @BeforeClass\n  public static void beforeClass() throws Exception {\n    // TODO: rewrite test (this needs to set QueryParser.enablePositionIncrements, too, for work with CURRENT):\n    analyzer = new MockAnalyzer(random(), MockTokenizer.WHITESPACE, true, MockTokenFilter.ENGLISH_STOPSET);\n    //initialize the parser\n    coreParser = new CoreParser(defaultField, analyzer);\n\n    BufferedReader d = new BufferedReader(new InputStreamReader(\n        TestCoreParser.class.getResourceAsStream(\"reuters21578.txt\"), StandardCharsets.US_ASCII));\n    dir = newDirectory();\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(analyzer));\n    String line = d.readLine();\n    while (line != null) {\n      int endOfDate = line.indexOf('\\t');\n      String date = line.substring(0, endOfDate).trim();\n      String content = line.substring(endOfDate).trim();\n      Document doc = new Document();\n      doc.add(newTextField(\"date\", date, Field.Store.YES));\n      doc.add(newTextField(\"contents\", content, Field.Store.YES));\n      doc.add(new LegacyIntField(\"date2\", Integer.valueOf(date), Field.Store.NO));\n      doc.add(new IntPoint(\"date3\", Integer.valueOf(date)));\n      writer.addDocument(doc);\n      line = d.readLine();\n    }\n    d.close();\n    writer.close();\n    reader = DirectoryReader.open(dir);\n    searcher = newSearcher(reader);\n\n  }\n\n","sourceOld":"  @BeforeClass\n  public static void beforeClass() throws Exception {\n    // TODO: rewrite test (this needs to set QueryParser.enablePositionIncrements, too, for work with CURRENT):\n    analyzer = new MockAnalyzer(random(), MockTokenizer.WHITESPACE, true, MockTokenFilter.ENGLISH_STOPSET);\n    //initialize the parser\n    coreParser = new CoreParser(defaultField, analyzer);\n\n    BufferedReader d = new BufferedReader(new InputStreamReader(\n        TestCoreParser.class.getResourceAsStream(\"reuters21578.txt\"), StandardCharsets.US_ASCII));\n    dir = newDirectory();\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(analyzer));\n    String line = d.readLine();\n    while (line != null) {\n      int endOfDate = line.indexOf('\\t');\n      String date = line.substring(0, endOfDate).trim();\n      String content = line.substring(endOfDate).trim();\n      Document doc = new Document();\n      doc.add(newTextField(\"date\", date, Field.Store.YES));\n      doc.add(newTextField(\"contents\", content, Field.Store.YES));\n      doc.add(new LegacyIntField(\"date2\", Integer.valueOf(date), Field.Store.NO));\n      writer.addDocument(doc);\n      line = d.readLine();\n    }\n    d.close();\n    writer.close();\n    reader = DirectoryReader.open(dir);\n    searcher = newSearcher(reader);\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8d3c6656a576996d73c1ac211d08e3f7a8fc02a4","date":1457550664,"type":3,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/queryparser/src/test/org/apache/lucene/queryparser/xml/TestCoreParser#beforeClass().mjava","pathOld":"lucene/queryparser/src/test/org/apache/lucene/queryparser/xml/TestCoreParser#beforeClass().mjava","sourceNew":"  @BeforeClass\n  public static void beforeClass() throws Exception {\n    // TODO: rewrite test (this needs to set QueryParser.enablePositionIncrements, too, for work with CURRENT):\n    analyzer = new MockAnalyzer(random(), MockTokenizer.WHITESPACE, true, MockTokenFilter.ENGLISH_STOPSET);\n    //initialize the parser\n    coreParser = new CoreParser(defaultField, analyzer);\n\n    BufferedReader d = new BufferedReader(new InputStreamReader(\n        TestCoreParser.class.getResourceAsStream(\"reuters21578.txt\"), StandardCharsets.US_ASCII));\n    dir = newDirectory();\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(analyzer));\n    String line = d.readLine();\n    while (line != null) {\n      int endOfDate = line.indexOf('\\t');\n      String date = line.substring(0, endOfDate).trim();\n      String content = line.substring(endOfDate).trim();\n      Document doc = new Document();\n      doc.add(newTextField(\"date\", date, Field.Store.YES));\n      doc.add(newTextField(\"contents\", content, Field.Store.YES));\n      doc.add(new LegacyIntField(\"date2\", Integer.valueOf(date), Field.Store.NO));\n      doc.add(new IntPoint(\"date3\", Integer.valueOf(date)));\n      writer.addDocument(doc);\n      line = d.readLine();\n    }\n    d.close();\n    writer.close();\n    reader = DirectoryReader.open(dir);\n    searcher = newSearcher(reader, false);\n\n  }\n\n","sourceOld":"  @BeforeClass\n  public static void beforeClass() throws Exception {\n    // TODO: rewrite test (this needs to set QueryParser.enablePositionIncrements, too, for work with CURRENT):\n    analyzer = new MockAnalyzer(random(), MockTokenizer.WHITESPACE, true, MockTokenFilter.ENGLISH_STOPSET);\n    //initialize the parser\n    coreParser = new CoreParser(defaultField, analyzer);\n\n    BufferedReader d = new BufferedReader(new InputStreamReader(\n        TestCoreParser.class.getResourceAsStream(\"reuters21578.txt\"), StandardCharsets.US_ASCII));\n    dir = newDirectory();\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(analyzer));\n    String line = d.readLine();\n    while (line != null) {\n      int endOfDate = line.indexOf('\\t');\n      String date = line.substring(0, endOfDate).trim();\n      String content = line.substring(endOfDate).trim();\n      Document doc = new Document();\n      doc.add(newTextField(\"date\", date, Field.Store.YES));\n      doc.add(newTextField(\"contents\", content, Field.Store.YES));\n      doc.add(new LegacyIntField(\"date2\", Integer.valueOf(date), Field.Store.NO));\n      doc.add(new IntPoint(\"date3\", Integer.valueOf(date)));\n      writer.addDocument(doc);\n      line = d.readLine();\n    }\n    d.close();\n    writer.close();\n    reader = DirectoryReader.open(dir);\n    searcher = newSearcher(reader);\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5e72e8538028609e81884b15cfd41af2fa71115b","date":1460646191,"type":5,"author":"Christine Poerschke","isMerge":false,"pathNew":"lucene/queryparser/src/test/org/apache/lucene/queryparser/xml/CoreParserTestIndexData#CoreParserTestIndexData(Analyzer).mjava","pathOld":"lucene/queryparser/src/test/org/apache/lucene/queryparser/xml/TestCoreParser#beforeClass().mjava","sourceNew":"  CoreParserTestIndexData(Analyzer analyzer) throws Exception {\n    BufferedReader d = new BufferedReader(new InputStreamReader(\n        TestCoreParser.class.getResourceAsStream(\"reuters21578.txt\"), StandardCharsets.US_ASCII));\n    dir = LuceneTestCase.newDirectory();\n    IndexWriter writer = new IndexWriter(dir, LuceneTestCase.newIndexWriterConfig(analyzer));\n    String line = d.readLine();\n    while (line != null) {\n      int endOfDate = line.indexOf('\\t');\n      String date = line.substring(0, endOfDate).trim();\n      String content = line.substring(endOfDate).trim();\n      Document doc = new Document();\n      doc.add(LuceneTestCase.newTextField(\"date\", date, Field.Store.YES));\n      doc.add(LuceneTestCase.newTextField(\"contents\", content, Field.Store.YES));\n      doc.add(new LegacyIntField(\"date2\", Integer.valueOf(date), Field.Store.NO));\n      doc.add(new IntPoint(\"date3\", Integer.valueOf(date)));\n      writer.addDocument(doc);\n      line = d.readLine();\n    }\n    d.close();\n    writer.close();\n    reader = DirectoryReader.open(dir);\n    searcher = LuceneTestCase.newSearcher(reader, false);\n  }\n\n","sourceOld":"  @BeforeClass\n  public static void beforeClass() throws Exception {\n    // TODO: rewrite test (this needs to set QueryParser.enablePositionIncrements, too, for work with CURRENT):\n    analyzer = new MockAnalyzer(random(), MockTokenizer.WHITESPACE, true, MockTokenFilter.ENGLISH_STOPSET);\n    //initialize the parser\n    coreParser = new CoreParser(defaultField, analyzer);\n\n    BufferedReader d = new BufferedReader(new InputStreamReader(\n        TestCoreParser.class.getResourceAsStream(\"reuters21578.txt\"), StandardCharsets.US_ASCII));\n    dir = newDirectory();\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(analyzer));\n    String line = d.readLine();\n    while (line != null) {\n      int endOfDate = line.indexOf('\\t');\n      String date = line.substring(0, endOfDate).trim();\n      String content = line.substring(endOfDate).trim();\n      Document doc = new Document();\n      doc.add(newTextField(\"date\", date, Field.Store.YES));\n      doc.add(newTextField(\"contents\", content, Field.Store.YES));\n      doc.add(new LegacyIntField(\"date2\", Integer.valueOf(date), Field.Store.NO));\n      doc.add(new IntPoint(\"date3\", Integer.valueOf(date)));\n      writer.addDocument(doc);\n      line = d.readLine();\n    }\n    d.close();\n    writer.close();\n    reader = DirectoryReader.open(dir);\n    searcher = newSearcher(reader, false);\n\n  }\n\n","bugFix":null,"bugIntro":["50b8410419cbbe9d8e1a96c918a951976bffe680"],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"f054843acc706da8f2f007c842699d62e4af736c":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"5e72e8538028609e81884b15cfd41af2fa71115b":["8d3c6656a576996d73c1ac211d08e3f7a8fc02a4"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"8d3c6656a576996d73c1ac211d08e3f7a8fc02a4":["3057b45cc5245d8fd8999a4bbe04da2c59511b75"],"3057b45cc5245d8fd8999a4bbe04da2c59511b75":["f054843acc706da8f2f007c842699d62e4af736c"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["5e72e8538028609e81884b15cfd41af2fa71115b"]},"commit2Childs":{"f054843acc706da8f2f007c842699d62e4af736c":["3057b45cc5245d8fd8999a4bbe04da2c59511b75"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["f054843acc706da8f2f007c842699d62e4af736c"],"5e72e8538028609e81884b15cfd41af2fa71115b":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"8d3c6656a576996d73c1ac211d08e3f7a8fc02a4":["5e72e8538028609e81884b15cfd41af2fa71115b"],"3057b45cc5245d8fd8999a4bbe04da2c59511b75":["8d3c6656a576996d73c1ac211d08e3f7a8fc02a4"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}