{"path":"modules/facet/src/java/org/apache/lucene/facet/taxonomy/directory/DirectoryTaxonomyReader#refresh().mjava","commits":[{"id":"ea469eab8fd0f3032f4fcde1c644a721e8309d3b","date":1320301582,"type":1,"author":"Shai Erera","isMerge":false,"pathNew":"modules/facet/src/java/org/apache/lucene/facet/taxonomy/directory/DirectoryTaxonomyReader#refresh().mjava","pathOld":"modules/facet/src/java/org/apache/lucene/facet/taxonomy/lucene/LuceneTaxonomyReader#refresh().mjava","sourceNew":"  // Note that refresh() is synchronized (it is the only synchronized\n  // method in this class) to ensure that it never gets called concurrently\n  // with itself.\n  public synchronized void refresh() throws IOException {\n    ensureOpen();\n    /*\n     * Since refresh() can be a lengthy operation, it is very important that we\n     * avoid locking out all readers for its duration. This is why we don't hold\n     * the indexReaderLock write lock for the entire duration of this method. In\n     * fact, it is enough to hold it only during a single assignment! Other\n     * comments in this method will explain this.\n     */\n\n    // note that the lengthy operation indexReader.reopen() does not\n    // modify the reader, so we can do it without holding a lock. We can\n    // safely read indexReader without holding the write lock, because\n    // no other thread can be writing at this time (this method is the\n    // only possible writer, and it is \"synchronized\" to avoid this case).\n    IndexReader r2 = IndexReader.openIfChanged(indexReader);\n    if (r2 != null) {\n      IndexReader oldreader = indexReader;\n      // we can close the old searcher, but need to synchronize this\n      // so that we don't close it in the middle that another routine\n      // is reading from it.\n      indexReaderLock.writeLock().lock();\n      indexReader = r2;\n      indexReaderLock.writeLock().unlock();\n      // We can close the old reader, but need to be certain that we\n      // don't close it while another method is reading from it.\n      // Luckily, we can be certain of that even without putting the\n      // oldreader.close() in the locked section. The reason is that\n      // after lock() succeeded above, we know that all existing readers\n      // had finished (this is what a read-write lock ensures). New\n      // readers, starting after the unlock() we just did, already got\n      // the new indexReader we set above. So nobody can be possibly\n      // using the old indexReader, and we can close it:\n      oldreader.close();\n\n      // We prefetch some of the arrays to make requests much faster.\n      // Let's refresh these prefetched arrays; This refresh is much\n      // is made more efficient by assuming that it is enough to read\n      // the values for new categories (old categories could not have been\n      // changed or deleted)\n      // Note that this this done without the write lock being held,\n      // which means that it is possible that during a refresh(), a\n      // reader will have some methods (like getOrdinal and getCategory)\n      // return fresh information, while getParent()\n      // (only to be prefetched now) still return older information.\n      // We consider this to be acceptable. The important thing,\n      // however, is that refreshPrefetchArrays() itself writes to\n      // the arrays in a correct manner (see discussion there)\n      parentArray.refresh(indexReader);\n\n      // Remove any INVALID_ORDINAL values from the ordinal cache,\n      // because it is possible those are now answered by the new data!\n      Iterator<Entry<String, Integer>> i = ordinalCache.entrySet().iterator();\n      while (i.hasNext()) {\n        Entry<String, Integer> e = i.next();\n        if (e.getValue().intValue() == INVALID_ORDINAL) {\n          i.remove();\n        }\n      }\n    }\n  }\n\n","sourceOld":"  // Note that refresh() is synchronized (it is the only synchronized\n  // method in this class) to ensure that it never gets called concurrently\n  // with itself.\n  public synchronized void refresh() throws IOException {\n    ensureOpen();\n    /*\n     * Since refresh() can be a lengthy operation, it is very important that we\n     * avoid locking out all readers for its duration. This is why we don't hold\n     * the indexReaderLock write lock for the entire duration of this method. In\n     * fact, it is enough to hold it only during a single assignment! Other\n     * comments in this method will explain this.\n     */\n\n    // note that the lengthy operation indexReader.reopen() does not\n    // modify the reader, so we can do it without holding a lock. We can\n    // safely read indexReader without holding the write lock, because\n    // no other thread can be writing at this time (this method is the\n    // only possible writer, and it is \"synchronized\" to avoid this case).\n    IndexReader r2 = IndexReader.openIfChanged(indexReader);\n    if (r2 != null) {\n      IndexReader oldreader = indexReader;\n      // we can close the old searcher, but need to synchronize this\n      // so that we don't close it in the middle that another routine\n      // is reading from it.\n      indexReaderLock.writeLock().lock();\n      indexReader = r2;\n      indexReaderLock.writeLock().unlock();\n      // We can close the old reader, but need to be certain that we\n      // don't close it while another method is reading from it.\n      // Luckily, we can be certain of that even without putting the\n      // oldreader.close() in the locked section. The reason is that\n      // after lock() succeeded above, we know that all existing readers\n      // had finished (this is what a read-write lock ensures). New\n      // readers, starting after the unlock() we just did, already got\n      // the new indexReader we set above. So nobody can be possibly\n      // using the old indexReader, and we can close it:\n      oldreader.close();\n\n      // We prefetch some of the arrays to make requests much faster.\n      // Let's refresh these prefetched arrays; This refresh is much\n      // is made more efficient by assuming that it is enough to read\n      // the values for new categories (old categories could not have been\n      // changed or deleted)\n      // Note that this this done without the write lock being held,\n      // which means that it is possible that during a refresh(), a\n      // reader will have some methods (like getOrdinal and getCategory)\n      // return fresh information, while getParent()\n      // (only to be prefetched now) still return older information.\n      // We consider this to be acceptable. The important thing,\n      // however, is that refreshPrefetchArrays() itself writes to\n      // the arrays in a correct manner (see discussion there)\n      parentArray.refresh(indexReader);\n\n      // Remove any INVALID_ORDINAL values from the ordinal cache,\n      // because it is possible those are now answered by the new data!\n      Iterator<Entry<String, Integer>> i = ordinalCache.entrySet().iterator();\n      while (i.hasNext()) {\n        Entry<String, Integer> e = i.next();\n        if (e.getValue().intValue() == INVALID_ORDINAL) {\n          i.remove();\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"233afcf63b8d53faa9a7993e911cc9873b0106d1","date":1321459183,"type":3,"author":"Doron Cohen","isMerge":false,"pathNew":"modules/facet/src/java/org/apache/lucene/facet/taxonomy/directory/DirectoryTaxonomyReader#refresh().mjava","pathOld":"modules/facet/src/java/org/apache/lucene/facet/taxonomy/directory/DirectoryTaxonomyReader#refresh().mjava","sourceNew":"  // Note that refresh() is synchronized (it is the only synchronized\n  // method in this class) to ensure that it never gets called concurrently\n  // with itself.\n  public synchronized boolean refresh() throws IOException, InconsistentTaxonomyException {\n    ensureOpen();\n    /*\n     * Since refresh() can be a lengthy operation, it is very important that we\n     * avoid locking out all readers for its duration. This is why we don't hold\n     * the indexReaderLock write lock for the entire duration of this method. In\n     * fact, it is enough to hold it only during a single assignment! Other\n     * comments in this method will explain this.\n     */\n\n    // note that the lengthy operation indexReader.reopen() does not\n    // modify the reader, so we can do it without holding a lock. We can\n    // safely read indexReader without holding the write lock, because\n    // no other thread can be writing at this time (this method is the\n    // only possible writer, and it is \"synchronized\" to avoid this case).\n    IndexReader r2 = IndexReader.openIfChanged(indexReader);\n    if (r2 == null) {\n    \treturn false; // no changes, nothing to do\n    } \n    \n    // validate that a refresh is valid at this point, i.e. that the taxonomy \n    // was not recreated since this reader was last opened or refresshed.\n    String t1 = indexReader.getCommitUserData().get(DirectoryTaxonomyWriter.INDEX_CREATE_TIME);\n    String t2 = r2.getCommitUserData().get(DirectoryTaxonomyWriter.INDEX_CREATE_TIME);\n    if (t1==null) {\n    \tif (t2!=null) {\n    \t\tr2.close();\n    \t\tthrow new InconsistentTaxonomyException(\"Taxonomy was recreated at: \"+t2);\n    \t}\n    } else if (!t1.equals(t2)) {\n    \tr2.close();\n    \tthrow new InconsistentTaxonomyException(\"Taxonomy was recreated at: \"+t2+\"  !=  \"+t1);\n    }\n    \n      IndexReader oldreader = indexReader;\n      // we can close the old searcher, but need to synchronize this\n      // so that we don't close it in the middle that another routine\n      // is reading from it.\n      indexReaderLock.writeLock().lock();\n      indexReader = r2;\n      indexReaderLock.writeLock().unlock();\n      // We can close the old reader, but need to be certain that we\n      // don't close it while another method is reading from it.\n      // Luckily, we can be certain of that even without putting the\n      // oldreader.close() in the locked section. The reason is that\n      // after lock() succeeded above, we know that all existing readers\n      // had finished (this is what a read-write lock ensures). New\n      // readers, starting after the unlock() we just did, already got\n      // the new indexReader we set above. So nobody can be possibly\n      // using the old indexReader, and we can close it:\n      oldreader.close();\n\n      // We prefetch some of the arrays to make requests much faster.\n      // Let's refresh these prefetched arrays; This refresh is much\n      // is made more efficient by assuming that it is enough to read\n      // the values for new categories (old categories could not have been\n      // changed or deleted)\n      // Note that this this done without the write lock being held,\n      // which means that it is possible that during a refresh(), a\n      // reader will have some methods (like getOrdinal and getCategory)\n      // return fresh information, while getParent()\n      // (only to be prefetched now) still return older information.\n      // We consider this to be acceptable. The important thing,\n      // however, is that refreshPrefetchArrays() itself writes to\n      // the arrays in a correct manner (see discussion there)\n      parentArray.refresh(indexReader);\n\n      // Remove any INVALID_ORDINAL values from the ordinal cache,\n      // because it is possible those are now answered by the new data!\n      Iterator<Entry<String, Integer>> i = ordinalCache.entrySet().iterator();\n      while (i.hasNext()) {\n        Entry<String, Integer> e = i.next();\n        if (e.getValue().intValue() == INVALID_ORDINAL) {\n          i.remove();\n        }\n      }\n      return true;\n    }\n\n","sourceOld":"  // Note that refresh() is synchronized (it is the only synchronized\n  // method in this class) to ensure that it never gets called concurrently\n  // with itself.\n  public synchronized void refresh() throws IOException {\n    ensureOpen();\n    /*\n     * Since refresh() can be a lengthy operation, it is very important that we\n     * avoid locking out all readers for its duration. This is why we don't hold\n     * the indexReaderLock write lock for the entire duration of this method. In\n     * fact, it is enough to hold it only during a single assignment! Other\n     * comments in this method will explain this.\n     */\n\n    // note that the lengthy operation indexReader.reopen() does not\n    // modify the reader, so we can do it without holding a lock. We can\n    // safely read indexReader without holding the write lock, because\n    // no other thread can be writing at this time (this method is the\n    // only possible writer, and it is \"synchronized\" to avoid this case).\n    IndexReader r2 = IndexReader.openIfChanged(indexReader);\n    if (r2 != null) {\n      IndexReader oldreader = indexReader;\n      // we can close the old searcher, but need to synchronize this\n      // so that we don't close it in the middle that another routine\n      // is reading from it.\n      indexReaderLock.writeLock().lock();\n      indexReader = r2;\n      indexReaderLock.writeLock().unlock();\n      // We can close the old reader, but need to be certain that we\n      // don't close it while another method is reading from it.\n      // Luckily, we can be certain of that even without putting the\n      // oldreader.close() in the locked section. The reason is that\n      // after lock() succeeded above, we know that all existing readers\n      // had finished (this is what a read-write lock ensures). New\n      // readers, starting after the unlock() we just did, already got\n      // the new indexReader we set above. So nobody can be possibly\n      // using the old indexReader, and we can close it:\n      oldreader.close();\n\n      // We prefetch some of the arrays to make requests much faster.\n      // Let's refresh these prefetched arrays; This refresh is much\n      // is made more efficient by assuming that it is enough to read\n      // the values for new categories (old categories could not have been\n      // changed or deleted)\n      // Note that this this done without the write lock being held,\n      // which means that it is possible that during a refresh(), a\n      // reader will have some methods (like getOrdinal and getCategory)\n      // return fresh information, while getParent()\n      // (only to be prefetched now) still return older information.\n      // We consider this to be acceptable. The important thing,\n      // however, is that refreshPrefetchArrays() itself writes to\n      // the arrays in a correct manner (see discussion there)\n      parentArray.refresh(indexReader);\n\n      // Remove any INVALID_ORDINAL values from the ordinal cache,\n      // because it is possible those are now answered by the new data!\n      Iterator<Entry<String, Integer>> i = ordinalCache.entrySet().iterator();\n      while (i.hasNext()) {\n        Entry<String, Integer> e = i.next();\n        if (e.getValue().intValue() == INVALID_ORDINAL) {\n          i.remove();\n        }\n      }\n    }\n  }\n\n","bugFix":["8a8259c922a83abc544609227a60d48e5ee93e7e","89f15687f60bd49cd3d9de427e85c17fd9397d61"],"bugIntro":["78e3613d9274c0d98ca67d976e415c82e9f9cf46"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"20b26030b0883b7f045e3350bb97bee7146f1efd","date":1327854897,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"modules/facet/src/java/org/apache/lucene/facet/taxonomy/directory/DirectoryTaxonomyReader#refresh().mjava","pathOld":"modules/facet/src/java/org/apache/lucene/facet/taxonomy/directory/DirectoryTaxonomyReader#refresh().mjava","sourceNew":"  // Note that refresh() is synchronized (it is the only synchronized\n  // method in this class) to ensure that it never gets called concurrently\n  // with itself.\n  public synchronized boolean refresh() throws IOException, InconsistentTaxonomyException {\n    ensureOpen();\n    /*\n     * Since refresh() can be a lengthy operation, it is very important that we\n     * avoid locking out all readers for its duration. This is why we don't hold\n     * the indexReaderLock write lock for the entire duration of this method. In\n     * fact, it is enough to hold it only during a single assignment! Other\n     * comments in this method will explain this.\n     */\n\n    // note that the lengthy operation indexReader.reopen() does not\n    // modify the reader, so we can do it without holding a lock. We can\n    // safely read indexReader without holding the write lock, because\n    // no other thread can be writing at this time (this method is the\n    // only possible writer, and it is \"synchronized\" to avoid this case).\n    DirectoryReader r2 = DirectoryReader.openIfChanged(indexReader);\n    if (r2 == null) {\n    \treturn false; // no changes, nothing to do\n    } \n    \n    // validate that a refresh is valid at this point, i.e. that the taxonomy \n    // was not recreated since this reader was last opened or refresshed.\n    String t1 = indexReader.getCommitUserData().get(DirectoryTaxonomyWriter.INDEX_CREATE_TIME);\n    String t2 = r2.getCommitUserData().get(DirectoryTaxonomyWriter.INDEX_CREATE_TIME);\n    if (t1==null) {\n    \tif (t2!=null) {\n    \t\tr2.close();\n    \t\tthrow new InconsistentTaxonomyException(\"Taxonomy was recreated at: \"+t2);\n    \t}\n    } else if (!t1.equals(t2)) {\n    \tr2.close();\n    \tthrow new InconsistentTaxonomyException(\"Taxonomy was recreated at: \"+t2+\"  !=  \"+t1);\n    }\n    \n      IndexReader oldreader = indexReader;\n      // we can close the old searcher, but need to synchronize this\n      // so that we don't close it in the middle that another routine\n      // is reading from it.\n      indexReaderLock.writeLock().lock();\n      indexReader = r2;\n      indexReaderLock.writeLock().unlock();\n      // We can close the old reader, but need to be certain that we\n      // don't close it while another method is reading from it.\n      // Luckily, we can be certain of that even without putting the\n      // oldreader.close() in the locked section. The reason is that\n      // after lock() succeeded above, we know that all existing readers\n      // had finished (this is what a read-write lock ensures). New\n      // readers, starting after the unlock() we just did, already got\n      // the new indexReader we set above. So nobody can be possibly\n      // using the old indexReader, and we can close it:\n      oldreader.close();\n\n      // We prefetch some of the arrays to make requests much faster.\n      // Let's refresh these prefetched arrays; This refresh is much\n      // is made more efficient by assuming that it is enough to read\n      // the values for new categories (old categories could not have been\n      // changed or deleted)\n      // Note that this this done without the write lock being held,\n      // which means that it is possible that during a refresh(), a\n      // reader will have some methods (like getOrdinal and getCategory)\n      // return fresh information, while getParent()\n      // (only to be prefetched now) still return older information.\n      // We consider this to be acceptable. The important thing,\n      // however, is that refreshPrefetchArrays() itself writes to\n      // the arrays in a correct manner (see discussion there)\n      parentArray.refresh(indexReader);\n\n      // Remove any INVALID_ORDINAL values from the ordinal cache,\n      // because it is possible those are now answered by the new data!\n      Iterator<Entry<String, Integer>> i = ordinalCache.entrySet().iterator();\n      while (i.hasNext()) {\n        Entry<String, Integer> e = i.next();\n        if (e.getValue().intValue() == INVALID_ORDINAL) {\n          i.remove();\n        }\n      }\n      return true;\n    }\n\n","sourceOld":"  // Note that refresh() is synchronized (it is the only synchronized\n  // method in this class) to ensure that it never gets called concurrently\n  // with itself.\n  public synchronized boolean refresh() throws IOException, InconsistentTaxonomyException {\n    ensureOpen();\n    /*\n     * Since refresh() can be a lengthy operation, it is very important that we\n     * avoid locking out all readers for its duration. This is why we don't hold\n     * the indexReaderLock write lock for the entire duration of this method. In\n     * fact, it is enough to hold it only during a single assignment! Other\n     * comments in this method will explain this.\n     */\n\n    // note that the lengthy operation indexReader.reopen() does not\n    // modify the reader, so we can do it without holding a lock. We can\n    // safely read indexReader without holding the write lock, because\n    // no other thread can be writing at this time (this method is the\n    // only possible writer, and it is \"synchronized\" to avoid this case).\n    IndexReader r2 = IndexReader.openIfChanged(indexReader);\n    if (r2 == null) {\n    \treturn false; // no changes, nothing to do\n    } \n    \n    // validate that a refresh is valid at this point, i.e. that the taxonomy \n    // was not recreated since this reader was last opened or refresshed.\n    String t1 = indexReader.getCommitUserData().get(DirectoryTaxonomyWriter.INDEX_CREATE_TIME);\n    String t2 = r2.getCommitUserData().get(DirectoryTaxonomyWriter.INDEX_CREATE_TIME);\n    if (t1==null) {\n    \tif (t2!=null) {\n    \t\tr2.close();\n    \t\tthrow new InconsistentTaxonomyException(\"Taxonomy was recreated at: \"+t2);\n    \t}\n    } else if (!t1.equals(t2)) {\n    \tr2.close();\n    \tthrow new InconsistentTaxonomyException(\"Taxonomy was recreated at: \"+t2+\"  !=  \"+t1);\n    }\n    \n      IndexReader oldreader = indexReader;\n      // we can close the old searcher, but need to synchronize this\n      // so that we don't close it in the middle that another routine\n      // is reading from it.\n      indexReaderLock.writeLock().lock();\n      indexReader = r2;\n      indexReaderLock.writeLock().unlock();\n      // We can close the old reader, but need to be certain that we\n      // don't close it while another method is reading from it.\n      // Luckily, we can be certain of that even without putting the\n      // oldreader.close() in the locked section. The reason is that\n      // after lock() succeeded above, we know that all existing readers\n      // had finished (this is what a read-write lock ensures). New\n      // readers, starting after the unlock() we just did, already got\n      // the new indexReader we set above. So nobody can be possibly\n      // using the old indexReader, and we can close it:\n      oldreader.close();\n\n      // We prefetch some of the arrays to make requests much faster.\n      // Let's refresh these prefetched arrays; This refresh is much\n      // is made more efficient by assuming that it is enough to read\n      // the values for new categories (old categories could not have been\n      // changed or deleted)\n      // Note that this this done without the write lock being held,\n      // which means that it is possible that during a refresh(), a\n      // reader will have some methods (like getOrdinal and getCategory)\n      // return fresh information, while getParent()\n      // (only to be prefetched now) still return older information.\n      // We consider this to be acceptable. The important thing,\n      // however, is that refreshPrefetchArrays() itself writes to\n      // the arrays in a correct manner (see discussion there)\n      parentArray.refresh(indexReader);\n\n      // Remove any INVALID_ORDINAL values from the ordinal cache,\n      // because it is possible those are now answered by the new data!\n      Iterator<Entry<String, Integer>> i = ordinalCache.entrySet().iterator();\n      while (i.hasNext()) {\n        Entry<String, Integer> e = i.next();\n        if (e.getValue().intValue() == INVALID_ORDINAL) {\n          i.remove();\n        }\n      }\n      return true;\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"5cab9a86bd67202d20b6adc463008c8e982b070a","date":1327966443,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"modules/facet/src/java/org/apache/lucene/facet/taxonomy/directory/DirectoryTaxonomyReader#refresh().mjava","pathOld":"modules/facet/src/java/org/apache/lucene/facet/taxonomy/directory/DirectoryTaxonomyReader#refresh().mjava","sourceNew":"  // Note that refresh() is synchronized (it is the only synchronized\n  // method in this class) to ensure that it never gets called concurrently\n  // with itself.\n  public synchronized boolean refresh() throws IOException, InconsistentTaxonomyException {\n    ensureOpen();\n    /*\n     * Since refresh() can be a lengthy operation, it is very important that we\n     * avoid locking out all readers for its duration. This is why we don't hold\n     * the indexReaderLock write lock for the entire duration of this method. In\n     * fact, it is enough to hold it only during a single assignment! Other\n     * comments in this method will explain this.\n     */\n\n    // note that the lengthy operation indexReader.reopen() does not\n    // modify the reader, so we can do it without holding a lock. We can\n    // safely read indexReader without holding the write lock, because\n    // no other thread can be writing at this time (this method is the\n    // only possible writer, and it is \"synchronized\" to avoid this case).\n    DirectoryReader r2 = DirectoryReader.openIfChanged(indexReader);\n    if (r2 == null) {\n    \treturn false; // no changes, nothing to do\n    } \n    \n    // validate that a refresh is valid at this point, i.e. that the taxonomy \n    // was not recreated since this reader was last opened or refresshed.\n    String t1 = indexReader.getCommitUserData().get(DirectoryTaxonomyWriter.INDEX_CREATE_TIME);\n    String t2 = r2.getCommitUserData().get(DirectoryTaxonomyWriter.INDEX_CREATE_TIME);\n    if (t1==null) {\n    \tif (t2!=null) {\n    \t\tr2.close();\n    \t\tthrow new InconsistentTaxonomyException(\"Taxonomy was recreated at: \"+t2);\n    \t}\n    } else if (!t1.equals(t2)) {\n    \tr2.close();\n    \tthrow new InconsistentTaxonomyException(\"Taxonomy was recreated at: \"+t2+\"  !=  \"+t1);\n    }\n    \n      IndexReader oldreader = indexReader;\n      // we can close the old searcher, but need to synchronize this\n      // so that we don't close it in the middle that another routine\n      // is reading from it.\n      indexReaderLock.writeLock().lock();\n      indexReader = r2;\n      indexReaderLock.writeLock().unlock();\n      // We can close the old reader, but need to be certain that we\n      // don't close it while another method is reading from it.\n      // Luckily, we can be certain of that even without putting the\n      // oldreader.close() in the locked section. The reason is that\n      // after lock() succeeded above, we know that all existing readers\n      // had finished (this is what a read-write lock ensures). New\n      // readers, starting after the unlock() we just did, already got\n      // the new indexReader we set above. So nobody can be possibly\n      // using the old indexReader, and we can close it:\n      oldreader.close();\n\n      // We prefetch some of the arrays to make requests much faster.\n      // Let's refresh these prefetched arrays; This refresh is much\n      // is made more efficient by assuming that it is enough to read\n      // the values for new categories (old categories could not have been\n      // changed or deleted)\n      // Note that this this done without the write lock being held,\n      // which means that it is possible that during a refresh(), a\n      // reader will have some methods (like getOrdinal and getCategory)\n      // return fresh information, while getParent()\n      // (only to be prefetched now) still return older information.\n      // We consider this to be acceptable. The important thing,\n      // however, is that refreshPrefetchArrays() itself writes to\n      // the arrays in a correct manner (see discussion there)\n      parentArray.refresh(indexReader);\n\n      // Remove any INVALID_ORDINAL values from the ordinal cache,\n      // because it is possible those are now answered by the new data!\n      Iterator<Entry<String, Integer>> i = ordinalCache.entrySet().iterator();\n      while (i.hasNext()) {\n        Entry<String, Integer> e = i.next();\n        if (e.getValue().intValue() == INVALID_ORDINAL) {\n          i.remove();\n        }\n      }\n      return true;\n    }\n\n","sourceOld":"  // Note that refresh() is synchronized (it is the only synchronized\n  // method in this class) to ensure that it never gets called concurrently\n  // with itself.\n  public synchronized boolean refresh() throws IOException, InconsistentTaxonomyException {\n    ensureOpen();\n    /*\n     * Since refresh() can be a lengthy operation, it is very important that we\n     * avoid locking out all readers for its duration. This is why we don't hold\n     * the indexReaderLock write lock for the entire duration of this method. In\n     * fact, it is enough to hold it only during a single assignment! Other\n     * comments in this method will explain this.\n     */\n\n    // note that the lengthy operation indexReader.reopen() does not\n    // modify the reader, so we can do it without holding a lock. We can\n    // safely read indexReader without holding the write lock, because\n    // no other thread can be writing at this time (this method is the\n    // only possible writer, and it is \"synchronized\" to avoid this case).\n    IndexReader r2 = IndexReader.openIfChanged(indexReader);\n    if (r2 == null) {\n    \treturn false; // no changes, nothing to do\n    } \n    \n    // validate that a refresh is valid at this point, i.e. that the taxonomy \n    // was not recreated since this reader was last opened or refresshed.\n    String t1 = indexReader.getCommitUserData().get(DirectoryTaxonomyWriter.INDEX_CREATE_TIME);\n    String t2 = r2.getCommitUserData().get(DirectoryTaxonomyWriter.INDEX_CREATE_TIME);\n    if (t1==null) {\n    \tif (t2!=null) {\n    \t\tr2.close();\n    \t\tthrow new InconsistentTaxonomyException(\"Taxonomy was recreated at: \"+t2);\n    \t}\n    } else if (!t1.equals(t2)) {\n    \tr2.close();\n    \tthrow new InconsistentTaxonomyException(\"Taxonomy was recreated at: \"+t2+\"  !=  \"+t1);\n    }\n    \n      IndexReader oldreader = indexReader;\n      // we can close the old searcher, but need to synchronize this\n      // so that we don't close it in the middle that another routine\n      // is reading from it.\n      indexReaderLock.writeLock().lock();\n      indexReader = r2;\n      indexReaderLock.writeLock().unlock();\n      // We can close the old reader, but need to be certain that we\n      // don't close it while another method is reading from it.\n      // Luckily, we can be certain of that even without putting the\n      // oldreader.close() in the locked section. The reason is that\n      // after lock() succeeded above, we know that all existing readers\n      // had finished (this is what a read-write lock ensures). New\n      // readers, starting after the unlock() we just did, already got\n      // the new indexReader we set above. So nobody can be possibly\n      // using the old indexReader, and we can close it:\n      oldreader.close();\n\n      // We prefetch some of the arrays to make requests much faster.\n      // Let's refresh these prefetched arrays; This refresh is much\n      // is made more efficient by assuming that it is enough to read\n      // the values for new categories (old categories could not have been\n      // changed or deleted)\n      // Note that this this done without the write lock being held,\n      // which means that it is possible that during a refresh(), a\n      // reader will have some methods (like getOrdinal and getCategory)\n      // return fresh information, while getParent()\n      // (only to be prefetched now) still return older information.\n      // We consider this to be acceptable. The important thing,\n      // however, is that refreshPrefetchArrays() itself writes to\n      // the arrays in a correct manner (see discussion there)\n      parentArray.refresh(indexReader);\n\n      // Remove any INVALID_ORDINAL values from the ordinal cache,\n      // because it is possible those are now answered by the new data!\n      Iterator<Entry<String, Integer>> i = ordinalCache.entrySet().iterator();\n      while (i.hasNext()) {\n        Entry<String, Integer> e = i.next();\n        if (e.getValue().intValue() == INVALID_ORDINAL) {\n          i.remove();\n        }\n      }\n      return true;\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"438e995b4e32916f631722aab36254146830fefb","date":1328903827,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"modules/facet/src/java/org/apache/lucene/facet/taxonomy/directory/DirectoryTaxonomyReader#refresh().mjava","pathOld":"modules/facet/src/java/org/apache/lucene/facet/taxonomy/directory/DirectoryTaxonomyReader#refresh().mjava","sourceNew":"  // Note that refresh() is synchronized (it is the only synchronized\n  // method in this class) to ensure that it never gets called concurrently\n  // with itself.\n  public synchronized boolean refresh() throws IOException, InconsistentTaxonomyException {\n    ensureOpen();\n    /*\n     * Since refresh() can be a lengthy operation, it is very important that we\n     * avoid locking out all readers for its duration. This is why we don't hold\n     * the indexReaderLock write lock for the entire duration of this method. In\n     * fact, it is enough to hold it only during a single assignment! Other\n     * comments in this method will explain this.\n     */\n\n    // note that the lengthy operation indexReader.reopen() does not\n    // modify the reader, so we can do it without holding a lock. We can\n    // safely read indexReader without holding the write lock, because\n    // no other thread can be writing at this time (this method is the\n    // only possible writer, and it is \"synchronized\" to avoid this case).\n    DirectoryReader r2 = DirectoryReader.openIfChanged(indexReader);\n    if (r2 == null) {\n    \treturn false; // no changes, nothing to do\n    } \n    \n    // validate that a refresh is valid at this point, i.e. that the taxonomy \n    // was not recreated since this reader was last opened or refresshed.\n    String t1 = indexReader.getIndexCommit().getUserData().get(DirectoryTaxonomyWriter.INDEX_CREATE_TIME);\n    String t2 = r2.getIndexCommit().getUserData().get(DirectoryTaxonomyWriter.INDEX_CREATE_TIME);\n    if (t1==null) {\n    \tif (t2!=null) {\n    \t\tr2.close();\n    \t\tthrow new InconsistentTaxonomyException(\"Taxonomy was recreated at: \"+t2);\n    \t}\n    } else if (!t1.equals(t2)) {\n    \tr2.close();\n    \tthrow new InconsistentTaxonomyException(\"Taxonomy was recreated at: \"+t2+\"  !=  \"+t1);\n    }\n    \n      IndexReader oldreader = indexReader;\n      // we can close the old searcher, but need to synchronize this\n      // so that we don't close it in the middle that another routine\n      // is reading from it.\n      indexReaderLock.writeLock().lock();\n      indexReader = r2;\n      indexReaderLock.writeLock().unlock();\n      // We can close the old reader, but need to be certain that we\n      // don't close it while another method is reading from it.\n      // Luckily, we can be certain of that even without putting the\n      // oldreader.close() in the locked section. The reason is that\n      // after lock() succeeded above, we know that all existing readers\n      // had finished (this is what a read-write lock ensures). New\n      // readers, starting after the unlock() we just did, already got\n      // the new indexReader we set above. So nobody can be possibly\n      // using the old indexReader, and we can close it:\n      oldreader.close();\n\n      // We prefetch some of the arrays to make requests much faster.\n      // Let's refresh these prefetched arrays; This refresh is much\n      // is made more efficient by assuming that it is enough to read\n      // the values for new categories (old categories could not have been\n      // changed or deleted)\n      // Note that this this done without the write lock being held,\n      // which means that it is possible that during a refresh(), a\n      // reader will have some methods (like getOrdinal and getCategory)\n      // return fresh information, while getParent()\n      // (only to be prefetched now) still return older information.\n      // We consider this to be acceptable. The important thing,\n      // however, is that refreshPrefetchArrays() itself writes to\n      // the arrays in a correct manner (see discussion there)\n      parentArray.refresh(indexReader);\n\n      // Remove any INVALID_ORDINAL values from the ordinal cache,\n      // because it is possible those are now answered by the new data!\n      Iterator<Entry<String, Integer>> i = ordinalCache.entrySet().iterator();\n      while (i.hasNext()) {\n        Entry<String, Integer> e = i.next();\n        if (e.getValue().intValue() == INVALID_ORDINAL) {\n          i.remove();\n        }\n      }\n      return true;\n    }\n\n","sourceOld":"  // Note that refresh() is synchronized (it is the only synchronized\n  // method in this class) to ensure that it never gets called concurrently\n  // with itself.\n  public synchronized boolean refresh() throws IOException, InconsistentTaxonomyException {\n    ensureOpen();\n    /*\n     * Since refresh() can be a lengthy operation, it is very important that we\n     * avoid locking out all readers for its duration. This is why we don't hold\n     * the indexReaderLock write lock for the entire duration of this method. In\n     * fact, it is enough to hold it only during a single assignment! Other\n     * comments in this method will explain this.\n     */\n\n    // note that the lengthy operation indexReader.reopen() does not\n    // modify the reader, so we can do it without holding a lock. We can\n    // safely read indexReader without holding the write lock, because\n    // no other thread can be writing at this time (this method is the\n    // only possible writer, and it is \"synchronized\" to avoid this case).\n    DirectoryReader r2 = DirectoryReader.openIfChanged(indexReader);\n    if (r2 == null) {\n    \treturn false; // no changes, nothing to do\n    } \n    \n    // validate that a refresh is valid at this point, i.e. that the taxonomy \n    // was not recreated since this reader was last opened or refresshed.\n    String t1 = indexReader.getCommitUserData().get(DirectoryTaxonomyWriter.INDEX_CREATE_TIME);\n    String t2 = r2.getCommitUserData().get(DirectoryTaxonomyWriter.INDEX_CREATE_TIME);\n    if (t1==null) {\n    \tif (t2!=null) {\n    \t\tr2.close();\n    \t\tthrow new InconsistentTaxonomyException(\"Taxonomy was recreated at: \"+t2);\n    \t}\n    } else if (!t1.equals(t2)) {\n    \tr2.close();\n    \tthrow new InconsistentTaxonomyException(\"Taxonomy was recreated at: \"+t2+\"  !=  \"+t1);\n    }\n    \n      IndexReader oldreader = indexReader;\n      // we can close the old searcher, but need to synchronize this\n      // so that we don't close it in the middle that another routine\n      // is reading from it.\n      indexReaderLock.writeLock().lock();\n      indexReader = r2;\n      indexReaderLock.writeLock().unlock();\n      // We can close the old reader, but need to be certain that we\n      // don't close it while another method is reading from it.\n      // Luckily, we can be certain of that even without putting the\n      // oldreader.close() in the locked section. The reason is that\n      // after lock() succeeded above, we know that all existing readers\n      // had finished (this is what a read-write lock ensures). New\n      // readers, starting after the unlock() we just did, already got\n      // the new indexReader we set above. So nobody can be possibly\n      // using the old indexReader, and we can close it:\n      oldreader.close();\n\n      // We prefetch some of the arrays to make requests much faster.\n      // Let's refresh these prefetched arrays; This refresh is much\n      // is made more efficient by assuming that it is enough to read\n      // the values for new categories (old categories could not have been\n      // changed or deleted)\n      // Note that this this done without the write lock being held,\n      // which means that it is possible that during a refresh(), a\n      // reader will have some methods (like getOrdinal and getCategory)\n      // return fresh information, while getParent()\n      // (only to be prefetched now) still return older information.\n      // We consider this to be acceptable. The important thing,\n      // however, is that refreshPrefetchArrays() itself writes to\n      // the arrays in a correct manner (see discussion there)\n      parentArray.refresh(indexReader);\n\n      // Remove any INVALID_ORDINAL values from the ordinal cache,\n      // because it is possible those are now answered by the new data!\n      Iterator<Entry<String, Integer>> i = ordinalCache.entrySet().iterator();\n      while (i.hasNext()) {\n        Entry<String, Integer> e = i.next();\n        if (e.getValue().intValue() == INVALID_ORDINAL) {\n          i.remove();\n        }\n      }\n      return true;\n    }\n\n","bugFix":null,"bugIntro":["78e3613d9274c0d98ca67d976e415c82e9f9cf46"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b89678825b68eccaf09e6ab71675fc0b0af1e099","date":1334669779,"type":5,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/facet/src/java/org/apache/lucene/facet/taxonomy/directory/DirectoryTaxonomyReader#refresh().mjava","pathOld":"modules/facet/src/java/org/apache/lucene/facet/taxonomy/directory/DirectoryTaxonomyReader#refresh().mjava","sourceNew":"  // Note that refresh() is synchronized (it is the only synchronized\n  // method in this class) to ensure that it never gets called concurrently\n  // with itself.\n  public synchronized boolean refresh() throws IOException, InconsistentTaxonomyException {\n    ensureOpen();\n    /*\n     * Since refresh() can be a lengthy operation, it is very important that we\n     * avoid locking out all readers for its duration. This is why we don't hold\n     * the indexReaderLock write lock for the entire duration of this method. In\n     * fact, it is enough to hold it only during a single assignment! Other\n     * comments in this method will explain this.\n     */\n\n    // note that the lengthy operation indexReader.reopen() does not\n    // modify the reader, so we can do it without holding a lock. We can\n    // safely read indexReader without holding the write lock, because\n    // no other thread can be writing at this time (this method is the\n    // only possible writer, and it is \"synchronized\" to avoid this case).\n    DirectoryReader r2 = DirectoryReader.openIfChanged(indexReader);\n    if (r2 == null) {\n    \treturn false; // no changes, nothing to do\n    } \n    \n    // validate that a refresh is valid at this point, i.e. that the taxonomy \n    // was not recreated since this reader was last opened or refresshed.\n    String t1 = indexReader.getIndexCommit().getUserData().get(DirectoryTaxonomyWriter.INDEX_CREATE_TIME);\n    String t2 = r2.getIndexCommit().getUserData().get(DirectoryTaxonomyWriter.INDEX_CREATE_TIME);\n    if (t1==null) {\n    \tif (t2!=null) {\n    \t\tr2.close();\n    \t\tthrow new InconsistentTaxonomyException(\"Taxonomy was recreated at: \"+t2);\n    \t}\n    } else if (!t1.equals(t2)) {\n    \tr2.close();\n    \tthrow new InconsistentTaxonomyException(\"Taxonomy was recreated at: \"+t2+\"  !=  \"+t1);\n    }\n    \n      IndexReader oldreader = indexReader;\n      // we can close the old searcher, but need to synchronize this\n      // so that we don't close it in the middle that another routine\n      // is reading from it.\n      indexReaderLock.writeLock().lock();\n      indexReader = r2;\n      indexReaderLock.writeLock().unlock();\n      // We can close the old reader, but need to be certain that we\n      // don't close it while another method is reading from it.\n      // Luckily, we can be certain of that even without putting the\n      // oldreader.close() in the locked section. The reason is that\n      // after lock() succeeded above, we know that all existing readers\n      // had finished (this is what a read-write lock ensures). New\n      // readers, starting after the unlock() we just did, already got\n      // the new indexReader we set above. So nobody can be possibly\n      // using the old indexReader, and we can close it:\n      oldreader.close();\n\n      // We prefetch some of the arrays to make requests much faster.\n      // Let's refresh these prefetched arrays; This refresh is much\n      // is made more efficient by assuming that it is enough to read\n      // the values for new categories (old categories could not have been\n      // changed or deleted)\n      // Note that this this done without the write lock being held,\n      // which means that it is possible that during a refresh(), a\n      // reader will have some methods (like getOrdinal and getCategory)\n      // return fresh information, while getParent()\n      // (only to be prefetched now) still return older information.\n      // We consider this to be acceptable. The important thing,\n      // however, is that refreshPrefetchArrays() itself writes to\n      // the arrays in a correct manner (see discussion there)\n      parentArray.refresh(indexReader);\n\n      // Remove any INVALID_ORDINAL values from the ordinal cache,\n      // because it is possible those are now answered by the new data!\n      Iterator<Entry<String, Integer>> i = ordinalCache.entrySet().iterator();\n      while (i.hasNext()) {\n        Entry<String, Integer> e = i.next();\n        if (e.getValue().intValue() == INVALID_ORDINAL) {\n          i.remove();\n        }\n      }\n      return true;\n    }\n\n","sourceOld":"  // Note that refresh() is synchronized (it is the only synchronized\n  // method in this class) to ensure that it never gets called concurrently\n  // with itself.\n  public synchronized boolean refresh() throws IOException, InconsistentTaxonomyException {\n    ensureOpen();\n    /*\n     * Since refresh() can be a lengthy operation, it is very important that we\n     * avoid locking out all readers for its duration. This is why we don't hold\n     * the indexReaderLock write lock for the entire duration of this method. In\n     * fact, it is enough to hold it only during a single assignment! Other\n     * comments in this method will explain this.\n     */\n\n    // note that the lengthy operation indexReader.reopen() does not\n    // modify the reader, so we can do it without holding a lock. We can\n    // safely read indexReader without holding the write lock, because\n    // no other thread can be writing at this time (this method is the\n    // only possible writer, and it is \"synchronized\" to avoid this case).\n    DirectoryReader r2 = DirectoryReader.openIfChanged(indexReader);\n    if (r2 == null) {\n    \treturn false; // no changes, nothing to do\n    } \n    \n    // validate that a refresh is valid at this point, i.e. that the taxonomy \n    // was not recreated since this reader was last opened or refresshed.\n    String t1 = indexReader.getIndexCommit().getUserData().get(DirectoryTaxonomyWriter.INDEX_CREATE_TIME);\n    String t2 = r2.getIndexCommit().getUserData().get(DirectoryTaxonomyWriter.INDEX_CREATE_TIME);\n    if (t1==null) {\n    \tif (t2!=null) {\n    \t\tr2.close();\n    \t\tthrow new InconsistentTaxonomyException(\"Taxonomy was recreated at: \"+t2);\n    \t}\n    } else if (!t1.equals(t2)) {\n    \tr2.close();\n    \tthrow new InconsistentTaxonomyException(\"Taxonomy was recreated at: \"+t2+\"  !=  \"+t1);\n    }\n    \n      IndexReader oldreader = indexReader;\n      // we can close the old searcher, but need to synchronize this\n      // so that we don't close it in the middle that another routine\n      // is reading from it.\n      indexReaderLock.writeLock().lock();\n      indexReader = r2;\n      indexReaderLock.writeLock().unlock();\n      // We can close the old reader, but need to be certain that we\n      // don't close it while another method is reading from it.\n      // Luckily, we can be certain of that even without putting the\n      // oldreader.close() in the locked section. The reason is that\n      // after lock() succeeded above, we know that all existing readers\n      // had finished (this is what a read-write lock ensures). New\n      // readers, starting after the unlock() we just did, already got\n      // the new indexReader we set above. So nobody can be possibly\n      // using the old indexReader, and we can close it:\n      oldreader.close();\n\n      // We prefetch some of the arrays to make requests much faster.\n      // Let's refresh these prefetched arrays; This refresh is much\n      // is made more efficient by assuming that it is enough to read\n      // the values for new categories (old categories could not have been\n      // changed or deleted)\n      // Note that this this done without the write lock being held,\n      // which means that it is possible that during a refresh(), a\n      // reader will have some methods (like getOrdinal and getCategory)\n      // return fresh information, while getParent()\n      // (only to be prefetched now) still return older information.\n      // We consider this to be acceptable. The important thing,\n      // however, is that refreshPrefetchArrays() itself writes to\n      // the arrays in a correct manner (see discussion there)\n      parentArray.refresh(indexReader);\n\n      // Remove any INVALID_ORDINAL values from the ordinal cache,\n      // because it is possible those are now answered by the new data!\n      Iterator<Entry<String, Integer>> i = ordinalCache.entrySet().iterator();\n      while (i.hasNext()) {\n        Entry<String, Integer> e = i.next();\n        if (e.getValue().intValue() == INVALID_ORDINAL) {\n          i.remove();\n        }\n      }\n      return true;\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"b89678825b68eccaf09e6ab71675fc0b0af1e099":["438e995b4e32916f631722aab36254146830fefb"],"ea469eab8fd0f3032f4fcde1c644a721e8309d3b":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"20b26030b0883b7f045e3350bb97bee7146f1efd":["233afcf63b8d53faa9a7993e911cc9873b0106d1"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"438e995b4e32916f631722aab36254146830fefb":["5cab9a86bd67202d20b6adc463008c8e982b070a"],"233afcf63b8d53faa9a7993e911cc9873b0106d1":["ea469eab8fd0f3032f4fcde1c644a721e8309d3b"],"5cab9a86bd67202d20b6adc463008c8e982b070a":["233afcf63b8d53faa9a7993e911cc9873b0106d1","20b26030b0883b7f045e3350bb97bee7146f1efd"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["b89678825b68eccaf09e6ab71675fc0b0af1e099"]},"commit2Childs":{"b89678825b68eccaf09e6ab71675fc0b0af1e099":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"ea469eab8fd0f3032f4fcde1c644a721e8309d3b":["233afcf63b8d53faa9a7993e911cc9873b0106d1"],"20b26030b0883b7f045e3350bb97bee7146f1efd":["5cab9a86bd67202d20b6adc463008c8e982b070a"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["ea469eab8fd0f3032f4fcde1c644a721e8309d3b"],"438e995b4e32916f631722aab36254146830fefb":["b89678825b68eccaf09e6ab71675fc0b0af1e099"],"233afcf63b8d53faa9a7993e911cc9873b0106d1":["20b26030b0883b7f045e3350bb97bee7146f1efd","5cab9a86bd67202d20b6adc463008c8e982b070a"],"5cab9a86bd67202d20b6adc463008c8e982b070a":["438e995b4e32916f631722aab36254146830fefb"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}