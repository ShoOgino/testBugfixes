{"path":"lucene/core/src/test/org/apache/lucene/search/TestCachingWrapperFilter#testEnforceDeletions().mjava","commits":[{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":1,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestCachingWrapperFilter#testEnforceDeletions().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestCachingWrapperFilter#testEnforceDeletions().mjava","sourceNew":"  public void testEnforceDeletions() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(\n        random,\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setMergeScheduler(new SerialMergeScheduler()).\n            // asserts below requires no unexpected merges:\n            setMergePolicy(newLogMergePolicy(10))\n    );\n    _TestUtil.keepFullyDeletedSegments(writer.w);\n\n    // NOTE: cannot use writer.getReader because RIW (on\n    // flipping a coin) may give us a newly opened reader,\n    // but we use .reopen on this reader below and expect to\n    // (must) get an NRT reader:\n    DirectoryReader reader = IndexReader.open(writer.w, true);\n    // same reason we don't wrap?\n    IndexSearcher searcher = newSearcher(reader, false);\n\n    // add a doc, refresh the reader, and check that it's there\n    Document doc = new Document();\n    doc.add(newField(\"id\", \"1\", StringField.TYPE_STORED));\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    TopDocs docs = searcher.search(new MatchAllDocsQuery(), 1);\n    assertEquals(\"Should find a hit...\", 1, docs.totalHits);\n\n    final Filter startFilter = new QueryWrapperFilter(new TermQuery(new Term(\"id\", \"1\")));\n\n    // force cache to regenerate after deletions:\n    CachingWrapperFilter filter = new CachingWrapperFilter(startFilter, true);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n\n    Query constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // make sure we get a cache hit when we reopen reader\n    // that had no change to deletions\n\n    // fake delete (deletes nothing):\n    writer.deleteDocuments(new Term(\"foo\", \"bar\"));\n\n    IndexReader oldReader = reader;\n    reader = refreshReader(reader);\n    assertTrue(reader == oldReader);\n    int missCount = filter.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // cache hit:\n    assertEquals(missCount, filter.missCount);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    oldReader = reader;\n    reader = refreshReader(reader);\n\n    searcher = newSearcher(reader, false);\n\n    missCount = filter.missCount;\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    // cache miss, because we asked CWF to recache when\n    // deletes changed:\n    assertEquals(missCount+1, filter.missCount);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    // apply deletes dynamically:\n    filter = new CachingWrapperFilter(startFilter);\n    writer.addDocument(doc);\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    missCount = filter.missCount;\n    assertTrue(missCount > 0);\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    writer.addDocument(doc);\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    oldReader = reader;\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find 2 hits...\", 2, docs.totalHits);\n    assertTrue(filter.missCount > missCount);\n    missCount = filter.missCount;\n\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 2, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n    // CWF reused the same entry (it dynamically applied the deletes):\n    assertEquals(missCount, filter.missCount);\n\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n    // CWF reused the same entry (it dynamically applied the deletes):\n    assertEquals(missCount, filter.missCount);\n\n    // NOTE: silliness to make sure JRE does not eliminate\n    // our holding onto oldReader to prevent\n    // CachingWrapperFilter's WeakHashMap from dropping the\n    // entry:\n    assertTrue(oldReader != null);\n\n    reader.close();\n    writer.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testEnforceDeletions() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(\n        random,\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setMergeScheduler(new SerialMergeScheduler()).\n            // asserts below requires no unexpected merges:\n            setMergePolicy(newLogMergePolicy(10))\n    );\n    _TestUtil.keepFullyDeletedSegments(writer.w);\n\n    // NOTE: cannot use writer.getReader because RIW (on\n    // flipping a coin) may give us a newly opened reader,\n    // but we use .reopen on this reader below and expect to\n    // (must) get an NRT reader:\n    DirectoryReader reader = IndexReader.open(writer.w, true);\n    // same reason we don't wrap?\n    IndexSearcher searcher = newSearcher(reader, false);\n\n    // add a doc, refresh the reader, and check that it's there\n    Document doc = new Document();\n    doc.add(newField(\"id\", \"1\", StringField.TYPE_STORED));\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    TopDocs docs = searcher.search(new MatchAllDocsQuery(), 1);\n    assertEquals(\"Should find a hit...\", 1, docs.totalHits);\n\n    final Filter startFilter = new QueryWrapperFilter(new TermQuery(new Term(\"id\", \"1\")));\n\n    // force cache to regenerate after deletions:\n    CachingWrapperFilter filter = new CachingWrapperFilter(startFilter, true);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n\n    Query constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // make sure we get a cache hit when we reopen reader\n    // that had no change to deletions\n\n    // fake delete (deletes nothing):\n    writer.deleteDocuments(new Term(\"foo\", \"bar\"));\n\n    IndexReader oldReader = reader;\n    reader = refreshReader(reader);\n    assertTrue(reader == oldReader);\n    int missCount = filter.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // cache hit:\n    assertEquals(missCount, filter.missCount);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    oldReader = reader;\n    reader = refreshReader(reader);\n\n    searcher = newSearcher(reader, false);\n\n    missCount = filter.missCount;\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    // cache miss, because we asked CWF to recache when\n    // deletes changed:\n    assertEquals(missCount+1, filter.missCount);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    // apply deletes dynamically:\n    filter = new CachingWrapperFilter(startFilter);\n    writer.addDocument(doc);\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    missCount = filter.missCount;\n    assertTrue(missCount > 0);\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    writer.addDocument(doc);\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    oldReader = reader;\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find 2 hits...\", 2, docs.totalHits);\n    assertTrue(filter.missCount > missCount);\n    missCount = filter.missCount;\n\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 2, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n    // CWF reused the same entry (it dynamically applied the deletes):\n    assertEquals(missCount, filter.missCount);\n\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n    // CWF reused the same entry (it dynamically applied the deletes):\n    assertEquals(missCount, filter.missCount);\n\n    // NOTE: silliness to make sure JRE does not eliminate\n    // our holding onto oldReader to prevent\n    // CachingWrapperFilter's WeakHashMap from dropping the\n    // entry:\n    assertTrue(oldReader != null);\n\n    reader.close();\n    writer.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"629c38c4ae4e303d0617e05fbfe508140b32f0a3","date":1334500904,"type":3,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestCachingWrapperFilter#testEnforceDeletions().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestCachingWrapperFilter#testEnforceDeletions().mjava","sourceNew":"  public void testEnforceDeletions() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(\n        random(),\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).\n            setMergeScheduler(new SerialMergeScheduler()).\n            // asserts below requires no unexpected merges:\n            setMergePolicy(newLogMergePolicy(10))\n    );\n    _TestUtil.keepFullyDeletedSegments(writer.w);\n\n    // NOTE: cannot use writer.getReader because RIW (on\n    // flipping a coin) may give us a newly opened reader,\n    // but we use .reopen on this reader below and expect to\n    // (must) get an NRT reader:\n    DirectoryReader reader = IndexReader.open(writer.w, true);\n    // same reason we don't wrap?\n    IndexSearcher searcher = newSearcher(reader, false);\n\n    // add a doc, refresh the reader, and check that it's there\n    Document doc = new Document();\n    doc.add(newField(\"id\", \"1\", StringField.TYPE_STORED));\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    TopDocs docs = searcher.search(new MatchAllDocsQuery(), 1);\n    assertEquals(\"Should find a hit...\", 1, docs.totalHits);\n\n    final Filter startFilter = new QueryWrapperFilter(new TermQuery(new Term(\"id\", \"1\")));\n\n    // force cache to regenerate after deletions:\n    CachingWrapperFilter filter = new CachingWrapperFilter(startFilter, true);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n\n    Query constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // make sure we get a cache hit when we reopen reader\n    // that had no change to deletions\n\n    // fake delete (deletes nothing):\n    writer.deleteDocuments(new Term(\"foo\", \"bar\"));\n\n    IndexReader oldReader = reader;\n    reader = refreshReader(reader);\n    assertTrue(reader == oldReader);\n    int missCount = filter.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // cache hit:\n    assertEquals(missCount, filter.missCount);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    oldReader = reader;\n    reader = refreshReader(reader);\n\n    searcher = newSearcher(reader, false);\n\n    missCount = filter.missCount;\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    // cache miss, because we asked CWF to recache when\n    // deletes changed:\n    assertEquals(missCount+1, filter.missCount);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    // apply deletes dynamically:\n    filter = new CachingWrapperFilter(startFilter);\n    writer.addDocument(doc);\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    missCount = filter.missCount;\n    assertTrue(missCount > 0);\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    writer.addDocument(doc);\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    oldReader = reader;\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find 2 hits...\", 2, docs.totalHits);\n    assertTrue(filter.missCount > missCount);\n    missCount = filter.missCount;\n\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 2, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n    // CWF reused the same entry (it dynamically applied the deletes):\n    assertEquals(missCount, filter.missCount);\n\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n    // CWF reused the same entry (it dynamically applied the deletes):\n    assertEquals(missCount, filter.missCount);\n\n    // NOTE: silliness to make sure JRE does not eliminate\n    // our holding onto oldReader to prevent\n    // CachingWrapperFilter's WeakHashMap from dropping the\n    // entry:\n    assertTrue(oldReader != null);\n\n    reader.close();\n    writer.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testEnforceDeletions() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(\n        random,\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setMergeScheduler(new SerialMergeScheduler()).\n            // asserts below requires no unexpected merges:\n            setMergePolicy(newLogMergePolicy(10))\n    );\n    _TestUtil.keepFullyDeletedSegments(writer.w);\n\n    // NOTE: cannot use writer.getReader because RIW (on\n    // flipping a coin) may give us a newly opened reader,\n    // but we use .reopen on this reader below and expect to\n    // (must) get an NRT reader:\n    DirectoryReader reader = IndexReader.open(writer.w, true);\n    // same reason we don't wrap?\n    IndexSearcher searcher = newSearcher(reader, false);\n\n    // add a doc, refresh the reader, and check that it's there\n    Document doc = new Document();\n    doc.add(newField(\"id\", \"1\", StringField.TYPE_STORED));\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    TopDocs docs = searcher.search(new MatchAllDocsQuery(), 1);\n    assertEquals(\"Should find a hit...\", 1, docs.totalHits);\n\n    final Filter startFilter = new QueryWrapperFilter(new TermQuery(new Term(\"id\", \"1\")));\n\n    // force cache to regenerate after deletions:\n    CachingWrapperFilter filter = new CachingWrapperFilter(startFilter, true);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n\n    Query constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // make sure we get a cache hit when we reopen reader\n    // that had no change to deletions\n\n    // fake delete (deletes nothing):\n    writer.deleteDocuments(new Term(\"foo\", \"bar\"));\n\n    IndexReader oldReader = reader;\n    reader = refreshReader(reader);\n    assertTrue(reader == oldReader);\n    int missCount = filter.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // cache hit:\n    assertEquals(missCount, filter.missCount);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    oldReader = reader;\n    reader = refreshReader(reader);\n\n    searcher = newSearcher(reader, false);\n\n    missCount = filter.missCount;\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    // cache miss, because we asked CWF to recache when\n    // deletes changed:\n    assertEquals(missCount+1, filter.missCount);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    // apply deletes dynamically:\n    filter = new CachingWrapperFilter(startFilter);\n    writer.addDocument(doc);\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    missCount = filter.missCount;\n    assertTrue(missCount > 0);\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    writer.addDocument(doc);\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    oldReader = reader;\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find 2 hits...\", 2, docs.totalHits);\n    assertTrue(filter.missCount > missCount);\n    missCount = filter.missCount;\n\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 2, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n    // CWF reused the same entry (it dynamically applied the deletes):\n    assertEquals(missCount, filter.missCount);\n\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n    // CWF reused the same entry (it dynamically applied the deletes):\n    assertEquals(missCount, filter.missCount);\n\n    // NOTE: silliness to make sure JRE does not eliminate\n    // our holding onto oldReader to prevent\n    // CachingWrapperFilter's WeakHashMap from dropping the\n    // entry:\n    assertTrue(oldReader != null);\n\n    reader.close();\n    writer.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"e7e8d6f15900ee22ac3cb0a503f15dc952a3580f","date":1338430031,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestCachingWrapperFilter#testEnforceDeletions().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestCachingWrapperFilter#testEnforceDeletions().mjava","sourceNew":"  public void testEnforceDeletions() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(\n        random(),\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).\n            setMergeScheduler(new SerialMergeScheduler()).\n            // asserts below requires no unexpected merges:\n            setMergePolicy(newLogMergePolicy(10))\n    );\n    _TestUtil.keepFullyDeletedSegments(writer.w);\n\n    // NOTE: cannot use writer.getReader because RIW (on\n    // flipping a coin) may give us a newly opened reader,\n    // but we use .reopen on this reader below and expect to\n    // (must) get an NRT reader:\n    DirectoryReader reader = DirectoryReader.open(writer.w, true);\n    // same reason we don't wrap?\n    IndexSearcher searcher = newSearcher(reader, false);\n\n    // add a doc, refresh the reader, and check that it's there\n    Document doc = new Document();\n    doc.add(newField(\"id\", \"1\", StringField.TYPE_STORED));\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    TopDocs docs = searcher.search(new MatchAllDocsQuery(), 1);\n    assertEquals(\"Should find a hit...\", 1, docs.totalHits);\n\n    final Filter startFilter = new QueryWrapperFilter(new TermQuery(new Term(\"id\", \"1\")));\n\n    // force cache to regenerate after deletions:\n    CachingWrapperFilter filter = new CachingWrapperFilter(startFilter, true);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n\n    Query constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // make sure we get a cache hit when we reopen reader\n    // that had no change to deletions\n\n    // fake delete (deletes nothing):\n    writer.deleteDocuments(new Term(\"foo\", \"bar\"));\n\n    IndexReader oldReader = reader;\n    reader = refreshReader(reader);\n    assertTrue(reader == oldReader);\n    int missCount = filter.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // cache hit:\n    assertEquals(missCount, filter.missCount);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    oldReader = reader;\n    reader = refreshReader(reader);\n\n    searcher = newSearcher(reader, false);\n\n    missCount = filter.missCount;\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    // cache miss, because we asked CWF to recache when\n    // deletes changed:\n    assertEquals(missCount+1, filter.missCount);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    // apply deletes dynamically:\n    filter = new CachingWrapperFilter(startFilter);\n    writer.addDocument(doc);\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    missCount = filter.missCount;\n    assertTrue(missCount > 0);\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    writer.addDocument(doc);\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    oldReader = reader;\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find 2 hits...\", 2, docs.totalHits);\n    assertTrue(filter.missCount > missCount);\n    missCount = filter.missCount;\n\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 2, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n    // CWF reused the same entry (it dynamically applied the deletes):\n    assertEquals(missCount, filter.missCount);\n\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n    // CWF reused the same entry (it dynamically applied the deletes):\n    assertEquals(missCount, filter.missCount);\n\n    // NOTE: silliness to make sure JRE does not eliminate\n    // our holding onto oldReader to prevent\n    // CachingWrapperFilter's WeakHashMap from dropping the\n    // entry:\n    assertTrue(oldReader != null);\n\n    reader.close();\n    writer.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testEnforceDeletions() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(\n        random(),\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).\n            setMergeScheduler(new SerialMergeScheduler()).\n            // asserts below requires no unexpected merges:\n            setMergePolicy(newLogMergePolicy(10))\n    );\n    _TestUtil.keepFullyDeletedSegments(writer.w);\n\n    // NOTE: cannot use writer.getReader because RIW (on\n    // flipping a coin) may give us a newly opened reader,\n    // but we use .reopen on this reader below and expect to\n    // (must) get an NRT reader:\n    DirectoryReader reader = IndexReader.open(writer.w, true);\n    // same reason we don't wrap?\n    IndexSearcher searcher = newSearcher(reader, false);\n\n    // add a doc, refresh the reader, and check that it's there\n    Document doc = new Document();\n    doc.add(newField(\"id\", \"1\", StringField.TYPE_STORED));\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    TopDocs docs = searcher.search(new MatchAllDocsQuery(), 1);\n    assertEquals(\"Should find a hit...\", 1, docs.totalHits);\n\n    final Filter startFilter = new QueryWrapperFilter(new TermQuery(new Term(\"id\", \"1\")));\n\n    // force cache to regenerate after deletions:\n    CachingWrapperFilter filter = new CachingWrapperFilter(startFilter, true);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n\n    Query constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // make sure we get a cache hit when we reopen reader\n    // that had no change to deletions\n\n    // fake delete (deletes nothing):\n    writer.deleteDocuments(new Term(\"foo\", \"bar\"));\n\n    IndexReader oldReader = reader;\n    reader = refreshReader(reader);\n    assertTrue(reader == oldReader);\n    int missCount = filter.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // cache hit:\n    assertEquals(missCount, filter.missCount);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    oldReader = reader;\n    reader = refreshReader(reader);\n\n    searcher = newSearcher(reader, false);\n\n    missCount = filter.missCount;\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    // cache miss, because we asked CWF to recache when\n    // deletes changed:\n    assertEquals(missCount+1, filter.missCount);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    // apply deletes dynamically:\n    filter = new CachingWrapperFilter(startFilter);\n    writer.addDocument(doc);\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    missCount = filter.missCount;\n    assertTrue(missCount > 0);\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    writer.addDocument(doc);\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    oldReader = reader;\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find 2 hits...\", 2, docs.totalHits);\n    assertTrue(filter.missCount > missCount);\n    missCount = filter.missCount;\n\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 2, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n    // CWF reused the same entry (it dynamically applied the deletes):\n    assertEquals(missCount, filter.missCount);\n\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n    // CWF reused the same entry (it dynamically applied the deletes):\n    assertEquals(missCount, filter.missCount);\n\n    // NOTE: silliness to make sure JRE does not eliminate\n    // our holding onto oldReader to prevent\n    // CachingWrapperFilter's WeakHashMap from dropping the\n    // entry:\n    assertTrue(oldReader != null);\n\n    reader.close();\n    writer.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"04f07771a2a7dd3a395700665ed839c3dae2def2","date":1339350139,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestCachingWrapperFilter#testEnforceDeletions().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestCachingWrapperFilter#testEnforceDeletions().mjava","sourceNew":"  public void testEnforceDeletions() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(\n        random(),\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).\n            setMergeScheduler(new SerialMergeScheduler()).\n            // asserts below requires no unexpected merges:\n            setMergePolicy(newLogMergePolicy(10))\n    );\n    _TestUtil.keepFullyDeletedSegments(writer.w);\n\n    // NOTE: cannot use writer.getReader because RIW (on\n    // flipping a coin) may give us a newly opened reader,\n    // but we use .reopen on this reader below and expect to\n    // (must) get an NRT reader:\n    DirectoryReader reader = DirectoryReader.open(writer.w, true);\n    // same reason we don't wrap?\n    IndexSearcher searcher = newSearcher(reader, false);\n\n    // add a doc, refresh the reader, and check that it's there\n    Document doc = new Document();\n    doc.add(newStringField(\"id\", \"1\", Field.Store.YES));\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    TopDocs docs = searcher.search(new MatchAllDocsQuery(), 1);\n    assertEquals(\"Should find a hit...\", 1, docs.totalHits);\n\n    final Filter startFilter = new QueryWrapperFilter(new TermQuery(new Term(\"id\", \"1\")));\n\n    // force cache to regenerate after deletions:\n    CachingWrapperFilter filter = new CachingWrapperFilter(startFilter, true);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n\n    Query constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // make sure we get a cache hit when we reopen reader\n    // that had no change to deletions\n\n    // fake delete (deletes nothing):\n    writer.deleteDocuments(new Term(\"foo\", \"bar\"));\n\n    IndexReader oldReader = reader;\n    reader = refreshReader(reader);\n    assertTrue(reader == oldReader);\n    int missCount = filter.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // cache hit:\n    assertEquals(missCount, filter.missCount);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    oldReader = reader;\n    reader = refreshReader(reader);\n\n    searcher = newSearcher(reader, false);\n\n    missCount = filter.missCount;\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    // cache miss, because we asked CWF to recache when\n    // deletes changed:\n    assertEquals(missCount+1, filter.missCount);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    // apply deletes dynamically:\n    filter = new CachingWrapperFilter(startFilter);\n    writer.addDocument(doc);\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    missCount = filter.missCount;\n    assertTrue(missCount > 0);\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    writer.addDocument(doc);\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    oldReader = reader;\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find 2 hits...\", 2, docs.totalHits);\n    assertTrue(filter.missCount > missCount);\n    missCount = filter.missCount;\n\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 2, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n    // CWF reused the same entry (it dynamically applied the deletes):\n    assertEquals(missCount, filter.missCount);\n\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n    // CWF reused the same entry (it dynamically applied the deletes):\n    assertEquals(missCount, filter.missCount);\n\n    // NOTE: silliness to make sure JRE does not eliminate\n    // our holding onto oldReader to prevent\n    // CachingWrapperFilter's WeakHashMap from dropping the\n    // entry:\n    assertTrue(oldReader != null);\n\n    reader.close();\n    writer.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testEnforceDeletions() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(\n        random(),\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).\n            setMergeScheduler(new SerialMergeScheduler()).\n            // asserts below requires no unexpected merges:\n            setMergePolicy(newLogMergePolicy(10))\n    );\n    _TestUtil.keepFullyDeletedSegments(writer.w);\n\n    // NOTE: cannot use writer.getReader because RIW (on\n    // flipping a coin) may give us a newly opened reader,\n    // but we use .reopen on this reader below and expect to\n    // (must) get an NRT reader:\n    DirectoryReader reader = DirectoryReader.open(writer.w, true);\n    // same reason we don't wrap?\n    IndexSearcher searcher = newSearcher(reader, false);\n\n    // add a doc, refresh the reader, and check that it's there\n    Document doc = new Document();\n    doc.add(newField(\"id\", \"1\", StringField.TYPE_STORED));\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    TopDocs docs = searcher.search(new MatchAllDocsQuery(), 1);\n    assertEquals(\"Should find a hit...\", 1, docs.totalHits);\n\n    final Filter startFilter = new QueryWrapperFilter(new TermQuery(new Term(\"id\", \"1\")));\n\n    // force cache to regenerate after deletions:\n    CachingWrapperFilter filter = new CachingWrapperFilter(startFilter, true);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n\n    Query constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // make sure we get a cache hit when we reopen reader\n    // that had no change to deletions\n\n    // fake delete (deletes nothing):\n    writer.deleteDocuments(new Term(\"foo\", \"bar\"));\n\n    IndexReader oldReader = reader;\n    reader = refreshReader(reader);\n    assertTrue(reader == oldReader);\n    int missCount = filter.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // cache hit:\n    assertEquals(missCount, filter.missCount);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    oldReader = reader;\n    reader = refreshReader(reader);\n\n    searcher = newSearcher(reader, false);\n\n    missCount = filter.missCount;\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    // cache miss, because we asked CWF to recache when\n    // deletes changed:\n    assertEquals(missCount+1, filter.missCount);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    // apply deletes dynamically:\n    filter = new CachingWrapperFilter(startFilter);\n    writer.addDocument(doc);\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    missCount = filter.missCount;\n    assertTrue(missCount > 0);\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    writer.addDocument(doc);\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    oldReader = reader;\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find 2 hits...\", 2, docs.totalHits);\n    assertTrue(filter.missCount > missCount);\n    missCount = filter.missCount;\n\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 2, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n    // CWF reused the same entry (it dynamically applied the deletes):\n    assertEquals(missCount, filter.missCount);\n\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n    // CWF reused the same entry (it dynamically applied the deletes):\n    assertEquals(missCount, filter.missCount);\n\n    // NOTE: silliness to make sure JRE does not eliminate\n    // our holding onto oldReader to prevent\n    // CachingWrapperFilter's WeakHashMap from dropping the\n    // entry:\n    assertTrue(oldReader != null);\n\n    reader.close();\n    writer.close();\n    dir.close();\n  }\n\n","bugFix":["1509f151d7692d84fae414b2b799ac06ba60fcb4"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9a3bd393140af58401b6bcd1d1f6bdc896c718c8","date":1354060578,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestCachingWrapperFilter#testEnforceDeletions().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestCachingWrapperFilter#testEnforceDeletions().mjava","sourceNew":"  public void testEnforceDeletions() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(\n        random(),\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).\n            setMergeScheduler(new SerialMergeScheduler()).\n            // asserts below requires no unexpected merges:\n            setMergePolicy(newLogMergePolicy(10))\n    );\n    _TestUtil.keepFullyDeletedSegments(writer.w);\n\n    // NOTE: cannot use writer.getReader because RIW (on\n    // flipping a coin) may give us a newly opened reader,\n    // but we use .reopen on this reader below and expect to\n    // (must) get an NRT reader:\n    DirectoryReader reader = DirectoryReader.open(writer.w, true);\n    // same reason we don't wrap?\n    IndexSearcher searcher = newSearcher(reader, false);\n\n    // add a doc, refresh the reader, and check that it's there\n    Document doc = new Document();\n    doc.add(newStringField(\"id\", \"1\", Field.Store.YES));\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    TopDocs docs = searcher.search(new MatchAllDocsQuery(), 1);\n    assertEquals(\"Should find a hit...\", 1, docs.totalHits);\n\n    final Filter startFilter = new QueryWrapperFilter(new TermQuery(new Term(\"id\", \"1\")));\n\n    CachingWrapperFilter filter = new CachingWrapperFilter(startFilter);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n\n    Query constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // make sure we get a cache hit when we reopen reader\n    // that had no change to deletions\n\n    // fake delete (deletes nothing):\n    writer.deleteDocuments(new Term(\"foo\", \"bar\"));\n\n    IndexReader oldReader = reader;\n    reader = refreshReader(reader);\n    assertTrue(reader == oldReader);\n    int missCount = filter.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // cache hit:\n    assertEquals(missCount, filter.missCount);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    oldReader = reader;\n    reader = refreshReader(reader);\n\n    searcher = newSearcher(reader, false);\n\n    missCount = filter.missCount;\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    // cache hit\n    assertEquals(missCount, filter.missCount);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    // apply deletes dynamically:\n    filter = new CachingWrapperFilter(startFilter);\n    writer.addDocument(doc);\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    missCount = filter.missCount;\n    assertTrue(missCount > 0);\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    writer.addDocument(doc);\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    oldReader = reader;\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find 2 hits...\", 2, docs.totalHits);\n    assertTrue(filter.missCount > missCount);\n    missCount = filter.missCount;\n\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 2, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n    // CWF reused the same entry (it dynamically applied the deletes):\n    assertEquals(missCount, filter.missCount);\n\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n    // CWF reused the same entry (it dynamically applied the deletes):\n    assertEquals(missCount, filter.missCount);\n\n    // NOTE: silliness to make sure JRE does not eliminate\n    // our holding onto oldReader to prevent\n    // CachingWrapperFilter's WeakHashMap from dropping the\n    // entry:\n    assertTrue(oldReader != null);\n\n    reader.close();\n    writer.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testEnforceDeletions() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(\n        random(),\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).\n            setMergeScheduler(new SerialMergeScheduler()).\n            // asserts below requires no unexpected merges:\n            setMergePolicy(newLogMergePolicy(10))\n    );\n    _TestUtil.keepFullyDeletedSegments(writer.w);\n\n    // NOTE: cannot use writer.getReader because RIW (on\n    // flipping a coin) may give us a newly opened reader,\n    // but we use .reopen on this reader below and expect to\n    // (must) get an NRT reader:\n    DirectoryReader reader = DirectoryReader.open(writer.w, true);\n    // same reason we don't wrap?\n    IndexSearcher searcher = newSearcher(reader, false);\n\n    // add a doc, refresh the reader, and check that it's there\n    Document doc = new Document();\n    doc.add(newStringField(\"id\", \"1\", Field.Store.YES));\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    TopDocs docs = searcher.search(new MatchAllDocsQuery(), 1);\n    assertEquals(\"Should find a hit...\", 1, docs.totalHits);\n\n    final Filter startFilter = new QueryWrapperFilter(new TermQuery(new Term(\"id\", \"1\")));\n\n    // force cache to regenerate after deletions:\n    CachingWrapperFilter filter = new CachingWrapperFilter(startFilter, true);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n\n    Query constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // make sure we get a cache hit when we reopen reader\n    // that had no change to deletions\n\n    // fake delete (deletes nothing):\n    writer.deleteDocuments(new Term(\"foo\", \"bar\"));\n\n    IndexReader oldReader = reader;\n    reader = refreshReader(reader);\n    assertTrue(reader == oldReader);\n    int missCount = filter.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // cache hit:\n    assertEquals(missCount, filter.missCount);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    oldReader = reader;\n    reader = refreshReader(reader);\n\n    searcher = newSearcher(reader, false);\n\n    missCount = filter.missCount;\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    // cache miss, because we asked CWF to recache when\n    // deletes changed:\n    assertEquals(missCount+1, filter.missCount);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    // apply deletes dynamically:\n    filter = new CachingWrapperFilter(startFilter);\n    writer.addDocument(doc);\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    missCount = filter.missCount;\n    assertTrue(missCount > 0);\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    writer.addDocument(doc);\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    oldReader = reader;\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find 2 hits...\", 2, docs.totalHits);\n    assertTrue(filter.missCount > missCount);\n    missCount = filter.missCount;\n\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 2, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n    // CWF reused the same entry (it dynamically applied the deletes):\n    assertEquals(missCount, filter.missCount);\n\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n    // CWF reused the same entry (it dynamically applied the deletes):\n    assertEquals(missCount, filter.missCount);\n\n    // NOTE: silliness to make sure JRE does not eliminate\n    // our holding onto oldReader to prevent\n    // CachingWrapperFilter's WeakHashMap from dropping the\n    // entry:\n    assertTrue(oldReader != null);\n\n    reader.close();\n    writer.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"407687e67faf6e1f02a211ca078d8e3eed631027","date":1355157407,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestCachingWrapperFilter#testEnforceDeletions().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestCachingWrapperFilter#testEnforceDeletions().mjava","sourceNew":"  public void testEnforceDeletions() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(\n        random(),\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).\n            setMergeScheduler(new SerialMergeScheduler()).\n            // asserts below requires no unexpected merges:\n            setMergePolicy(newLogMergePolicy(10))\n    );\n    _TestUtil.keepFullyDeletedSegments(writer.w);\n\n    // NOTE: cannot use writer.getReader because RIW (on\n    // flipping a coin) may give us a newly opened reader,\n    // but we use .reopen on this reader below and expect to\n    // (must) get an NRT reader:\n    DirectoryReader reader = DirectoryReader.open(writer.w, true);\n    // same reason we don't wrap?\n    IndexSearcher searcher = newSearcher(reader, false);\n\n    // add a doc, refresh the reader, and check that it's there\n    Document doc = new Document();\n    doc.add(newStringField(\"id\", \"1\", Field.Store.YES));\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    TopDocs docs = searcher.search(new MatchAllDocsQuery(), 1);\n    assertEquals(\"Should find a hit...\", 1, docs.totalHits);\n\n    final Filter startFilter = new QueryWrapperFilter(new TermQuery(new Term(\"id\", \"1\")));\n\n    CachingWrapperFilter filter = new CachingWrapperFilter(startFilter);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n\n    Query constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // make sure we get a cache hit when we reopen reader\n    // that had no change to deletions\n\n    // fake delete (deletes nothing):\n    writer.deleteDocuments(new Term(\"foo\", \"bar\"));\n\n    IndexReader oldReader = reader;\n    reader = refreshReader(reader);\n    assertTrue(reader == oldReader);\n    int missCount = filter.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // cache hit:\n    assertEquals(missCount, filter.missCount);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    oldReader = reader;\n    reader = refreshReader(reader);\n\n    searcher = newSearcher(reader, false);\n\n    missCount = filter.missCount;\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    // cache hit\n    assertEquals(missCount, filter.missCount);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    // apply deletes dynamically:\n    filter = new CachingWrapperFilter(startFilter);\n    writer.addDocument(doc);\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    missCount = filter.missCount;\n    assertTrue(missCount > 0);\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    writer.addDocument(doc);\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    oldReader = reader;\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find 2 hits...\", 2, docs.totalHits);\n    assertTrue(filter.missCount > missCount);\n    missCount = filter.missCount;\n\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 2, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n    // CWF reused the same entry (it dynamically applied the deletes):\n    assertEquals(missCount, filter.missCount);\n\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n    // CWF reused the same entry (it dynamically applied the deletes):\n    assertEquals(missCount, filter.missCount);\n\n    // NOTE: silliness to make sure JRE does not eliminate\n    // our holding onto oldReader to prevent\n    // CachingWrapperFilter's WeakHashMap from dropping the\n    // entry:\n    assertTrue(oldReader != null);\n\n    reader.close();\n    writer.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testEnforceDeletions() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(\n        random(),\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).\n            setMergeScheduler(new SerialMergeScheduler()).\n            // asserts below requires no unexpected merges:\n            setMergePolicy(newLogMergePolicy(10))\n    );\n    _TestUtil.keepFullyDeletedSegments(writer.w);\n\n    // NOTE: cannot use writer.getReader because RIW (on\n    // flipping a coin) may give us a newly opened reader,\n    // but we use .reopen on this reader below and expect to\n    // (must) get an NRT reader:\n    DirectoryReader reader = DirectoryReader.open(writer.w, true);\n    // same reason we don't wrap?\n    IndexSearcher searcher = newSearcher(reader, false);\n\n    // add a doc, refresh the reader, and check that it's there\n    Document doc = new Document();\n    doc.add(newStringField(\"id\", \"1\", Field.Store.YES));\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    TopDocs docs = searcher.search(new MatchAllDocsQuery(), 1);\n    assertEquals(\"Should find a hit...\", 1, docs.totalHits);\n\n    final Filter startFilter = new QueryWrapperFilter(new TermQuery(new Term(\"id\", \"1\")));\n\n    // force cache to regenerate after deletions:\n    CachingWrapperFilter filter = new CachingWrapperFilter(startFilter, true);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n\n    Query constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // make sure we get a cache hit when we reopen reader\n    // that had no change to deletions\n\n    // fake delete (deletes nothing):\n    writer.deleteDocuments(new Term(\"foo\", \"bar\"));\n\n    IndexReader oldReader = reader;\n    reader = refreshReader(reader);\n    assertTrue(reader == oldReader);\n    int missCount = filter.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // cache hit:\n    assertEquals(missCount, filter.missCount);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    oldReader = reader;\n    reader = refreshReader(reader);\n\n    searcher = newSearcher(reader, false);\n\n    missCount = filter.missCount;\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    // cache miss, because we asked CWF to recache when\n    // deletes changed:\n    assertEquals(missCount+1, filter.missCount);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    // apply deletes dynamically:\n    filter = new CachingWrapperFilter(startFilter);\n    writer.addDocument(doc);\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    missCount = filter.missCount;\n    assertTrue(missCount > 0);\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    writer.addDocument(doc);\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    oldReader = reader;\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find 2 hits...\", 2, docs.totalHits);\n    assertTrue(filter.missCount > missCount);\n    missCount = filter.missCount;\n\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 2, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n    // CWF reused the same entry (it dynamically applied the deletes):\n    assertEquals(missCount, filter.missCount);\n\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n    // CWF reused the same entry (it dynamically applied the deletes):\n    assertEquals(missCount, filter.missCount);\n\n    // NOTE: silliness to make sure JRE does not eliminate\n    // our holding onto oldReader to prevent\n    // CachingWrapperFilter's WeakHashMap from dropping the\n    // entry:\n    assertTrue(oldReader != null);\n\n    reader.close();\n    writer.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"269301b6df4ea742a519a0cd7d9beb95cd6860e3","date":1367270590,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestCachingWrapperFilter#testEnforceDeletions().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestCachingWrapperFilter#testEnforceDeletions().mjava","sourceNew":"  public void testEnforceDeletions() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(\n        random(),\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).\n            setMergeScheduler(new SerialMergeScheduler()).\n            // asserts below requires no unexpected merges:\n            setMergePolicy(newLogMergePolicy(10))\n    );\n    _TestUtil.keepFullyDeletedSegments(writer.w);\n\n    // NOTE: cannot use writer.getReader because RIW (on\n    // flipping a coin) may give us a newly opened reader,\n    // but we use .reopen on this reader below and expect to\n    // (must) get an NRT reader:\n    DirectoryReader reader = DirectoryReader.open(writer.w, true);\n    // same reason we don't wrap?\n    IndexSearcher searcher = newSearcher(reader, false);\n\n    // add a doc, refresh the reader, and check that it's there\n    Document doc = new Document();\n    doc.add(newStringField(\"id\", \"1\", Field.Store.YES));\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    TopDocs docs = searcher.search(new MatchAllDocsQuery(), 1);\n    assertEquals(\"Should find a hit...\", 1, docs.totalHits);\n\n    final Filter startFilter = new QueryWrapperFilter(new TermQuery(new Term(\"id\", \"1\")));\n\n    CachingWrapperFilter filter = new CachingWrapperFilter(startFilter);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertTrue(filter.sizeInBytes() > 0);\n\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n\n    Query constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // make sure we get a cache hit when we reopen reader\n    // that had no change to deletions\n\n    // fake delete (deletes nothing):\n    writer.deleteDocuments(new Term(\"foo\", \"bar\"));\n\n    IndexReader oldReader = reader;\n    reader = refreshReader(reader);\n    assertTrue(reader == oldReader);\n    int missCount = filter.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // cache hit:\n    assertEquals(missCount, filter.missCount);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    oldReader = reader;\n    reader = refreshReader(reader);\n\n    searcher = newSearcher(reader, false);\n\n    missCount = filter.missCount;\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    // cache hit\n    assertEquals(missCount, filter.missCount);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    // apply deletes dynamically:\n    filter = new CachingWrapperFilter(startFilter);\n    writer.addDocument(doc);\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    missCount = filter.missCount;\n    assertTrue(missCount > 0);\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    writer.addDocument(doc);\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    oldReader = reader;\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find 2 hits...\", 2, docs.totalHits);\n    assertTrue(filter.missCount > missCount);\n    missCount = filter.missCount;\n\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 2, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n    // CWF reused the same entry (it dynamically applied the deletes):\n    assertEquals(missCount, filter.missCount);\n\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n    // CWF reused the same entry (it dynamically applied the deletes):\n    assertEquals(missCount, filter.missCount);\n\n    // NOTE: silliness to make sure JRE does not eliminate\n    // our holding onto oldReader to prevent\n    // CachingWrapperFilter's WeakHashMap from dropping the\n    // entry:\n    assertTrue(oldReader != null);\n\n    reader.close();\n    writer.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testEnforceDeletions() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(\n        random(),\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).\n            setMergeScheduler(new SerialMergeScheduler()).\n            // asserts below requires no unexpected merges:\n            setMergePolicy(newLogMergePolicy(10))\n    );\n    _TestUtil.keepFullyDeletedSegments(writer.w);\n\n    // NOTE: cannot use writer.getReader because RIW (on\n    // flipping a coin) may give us a newly opened reader,\n    // but we use .reopen on this reader below and expect to\n    // (must) get an NRT reader:\n    DirectoryReader reader = DirectoryReader.open(writer.w, true);\n    // same reason we don't wrap?\n    IndexSearcher searcher = newSearcher(reader, false);\n\n    // add a doc, refresh the reader, and check that it's there\n    Document doc = new Document();\n    doc.add(newStringField(\"id\", \"1\", Field.Store.YES));\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    TopDocs docs = searcher.search(new MatchAllDocsQuery(), 1);\n    assertEquals(\"Should find a hit...\", 1, docs.totalHits);\n\n    final Filter startFilter = new QueryWrapperFilter(new TermQuery(new Term(\"id\", \"1\")));\n\n    CachingWrapperFilter filter = new CachingWrapperFilter(startFilter);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n\n    Query constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // make sure we get a cache hit when we reopen reader\n    // that had no change to deletions\n\n    // fake delete (deletes nothing):\n    writer.deleteDocuments(new Term(\"foo\", \"bar\"));\n\n    IndexReader oldReader = reader;\n    reader = refreshReader(reader);\n    assertTrue(reader == oldReader);\n    int missCount = filter.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // cache hit:\n    assertEquals(missCount, filter.missCount);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    oldReader = reader;\n    reader = refreshReader(reader);\n\n    searcher = newSearcher(reader, false);\n\n    missCount = filter.missCount;\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    // cache hit\n    assertEquals(missCount, filter.missCount);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    // apply deletes dynamically:\n    filter = new CachingWrapperFilter(startFilter);\n    writer.addDocument(doc);\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    missCount = filter.missCount;\n    assertTrue(missCount > 0);\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    writer.addDocument(doc);\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    oldReader = reader;\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find 2 hits...\", 2, docs.totalHits);\n    assertTrue(filter.missCount > missCount);\n    missCount = filter.missCount;\n\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 2, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n    // CWF reused the same entry (it dynamically applied the deletes):\n    assertEquals(missCount, filter.missCount);\n\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n    // CWF reused the same entry (it dynamically applied the deletes):\n    assertEquals(missCount, filter.missCount);\n\n    // NOTE: silliness to make sure JRE does not eliminate\n    // our holding onto oldReader to prevent\n    // CachingWrapperFilter's WeakHashMap from dropping the\n    // entry:\n    assertTrue(oldReader != null);\n\n    reader.close();\n    writer.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":["8405d98acebb7e287bf7ac40e937ba05b8661285"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"da6a6dcc9fdd946001f6161fb9c16afdb5ed84c5","date":1376515204,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestCachingWrapperFilter#testEnforceDeletions().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestCachingWrapperFilter#testEnforceDeletions().mjava","sourceNew":"  public void testEnforceDeletions() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(\n        random(),\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).\n            setMergeScheduler(new SerialMergeScheduler()).\n            // asserts below requires no unexpected merges:\n            setMergePolicy(newLogMergePolicy(10))\n    );\n\n    // NOTE: cannot use writer.getReader because RIW (on\n    // flipping a coin) may give us a newly opened reader,\n    // but we use .reopen on this reader below and expect to\n    // (must) get an NRT reader:\n    DirectoryReader reader = DirectoryReader.open(writer.w, true);\n    // same reason we don't wrap?\n    IndexSearcher searcher = newSearcher(reader, false);\n\n    // add a doc, refresh the reader, and check that it's there\n    Document doc = new Document();\n    doc.add(newStringField(\"id\", \"1\", Field.Store.YES));\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    TopDocs docs = searcher.search(new MatchAllDocsQuery(), 1);\n    assertEquals(\"Should find a hit...\", 1, docs.totalHits);\n\n    final Filter startFilter = new QueryWrapperFilter(new TermQuery(new Term(\"id\", \"1\")));\n\n    CachingWrapperFilter filter = new CachingWrapperFilter(startFilter);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertTrue(filter.sizeInBytes() > 0);\n\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n\n    Query constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // make sure we get a cache hit when we reopen reader\n    // that had no change to deletions\n\n    // fake delete (deletes nothing):\n    writer.deleteDocuments(new Term(\"foo\", \"bar\"));\n\n    IndexReader oldReader = reader;\n    reader = refreshReader(reader);\n    assertTrue(reader == oldReader);\n    int missCount = filter.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // cache hit:\n    assertEquals(missCount, filter.missCount);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    oldReader = reader;\n    reader = refreshReader(reader);\n\n    searcher = newSearcher(reader, false);\n\n    missCount = filter.missCount;\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    // cache hit\n    assertEquals(missCount, filter.missCount);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    // apply deletes dynamically:\n    filter = new CachingWrapperFilter(startFilter);\n    writer.addDocument(doc);\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    missCount = filter.missCount;\n    assertTrue(missCount > 0);\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    writer.addDocument(doc);\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    oldReader = reader;\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find 2 hits...\", 2, docs.totalHits);\n    assertTrue(filter.missCount > missCount);\n    missCount = filter.missCount;\n\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 2, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n    // CWF reused the same entry (it dynamically applied the deletes):\n    assertEquals(missCount, filter.missCount);\n\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n    // CWF reused the same entry (it dynamically applied the deletes):\n    assertEquals(missCount, filter.missCount);\n\n    // NOTE: silliness to make sure JRE does not eliminate\n    // our holding onto oldReader to prevent\n    // CachingWrapperFilter's WeakHashMap from dropping the\n    // entry:\n    assertTrue(oldReader != null);\n\n    reader.close();\n    writer.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testEnforceDeletions() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(\n        random(),\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).\n            setMergeScheduler(new SerialMergeScheduler()).\n            // asserts below requires no unexpected merges:\n            setMergePolicy(newLogMergePolicy(10))\n    );\n    _TestUtil.keepFullyDeletedSegments(writer.w);\n\n    // NOTE: cannot use writer.getReader because RIW (on\n    // flipping a coin) may give us a newly opened reader,\n    // but we use .reopen on this reader below and expect to\n    // (must) get an NRT reader:\n    DirectoryReader reader = DirectoryReader.open(writer.w, true);\n    // same reason we don't wrap?\n    IndexSearcher searcher = newSearcher(reader, false);\n\n    // add a doc, refresh the reader, and check that it's there\n    Document doc = new Document();\n    doc.add(newStringField(\"id\", \"1\", Field.Store.YES));\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    TopDocs docs = searcher.search(new MatchAllDocsQuery(), 1);\n    assertEquals(\"Should find a hit...\", 1, docs.totalHits);\n\n    final Filter startFilter = new QueryWrapperFilter(new TermQuery(new Term(\"id\", \"1\")));\n\n    CachingWrapperFilter filter = new CachingWrapperFilter(startFilter);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertTrue(filter.sizeInBytes() > 0);\n\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n\n    Query constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // make sure we get a cache hit when we reopen reader\n    // that had no change to deletions\n\n    // fake delete (deletes nothing):\n    writer.deleteDocuments(new Term(\"foo\", \"bar\"));\n\n    IndexReader oldReader = reader;\n    reader = refreshReader(reader);\n    assertTrue(reader == oldReader);\n    int missCount = filter.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // cache hit:\n    assertEquals(missCount, filter.missCount);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    oldReader = reader;\n    reader = refreshReader(reader);\n\n    searcher = newSearcher(reader, false);\n\n    missCount = filter.missCount;\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    // cache hit\n    assertEquals(missCount, filter.missCount);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    // apply deletes dynamically:\n    filter = new CachingWrapperFilter(startFilter);\n    writer.addDocument(doc);\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    missCount = filter.missCount;\n    assertTrue(missCount > 0);\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    writer.addDocument(doc);\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    oldReader = reader;\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find 2 hits...\", 2, docs.totalHits);\n    assertTrue(filter.missCount > missCount);\n    missCount = filter.missCount;\n\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 2, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n    // CWF reused the same entry (it dynamically applied the deletes):\n    assertEquals(missCount, filter.missCount);\n\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n    // CWF reused the same entry (it dynamically applied the deletes):\n    assertEquals(missCount, filter.missCount);\n\n    // NOTE: silliness to make sure JRE does not eliminate\n    // our holding onto oldReader to prevent\n    // CachingWrapperFilter's WeakHashMap from dropping the\n    // entry:\n    assertTrue(oldReader != null);\n\n    reader.close();\n    writer.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"3dffec77fb8f7d0e9ca4869dddd6af94528b4576","date":1377875202,"type":3,"author":"Han Jiang","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestCachingWrapperFilter#testEnforceDeletions().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestCachingWrapperFilter#testEnforceDeletions().mjava","sourceNew":"  public void testEnforceDeletions() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(\n        random(),\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).\n            setMergeScheduler(new SerialMergeScheduler()).\n            // asserts below requires no unexpected merges:\n            setMergePolicy(newLogMergePolicy(10))\n    );\n\n    // NOTE: cannot use writer.getReader because RIW (on\n    // flipping a coin) may give us a newly opened reader,\n    // but we use .reopen on this reader below and expect to\n    // (must) get an NRT reader:\n    DirectoryReader reader = DirectoryReader.open(writer.w, true);\n    // same reason we don't wrap?\n    IndexSearcher searcher = newSearcher(reader, false);\n\n    // add a doc, refresh the reader, and check that it's there\n    Document doc = new Document();\n    doc.add(newStringField(\"id\", \"1\", Field.Store.YES));\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    TopDocs docs = searcher.search(new MatchAllDocsQuery(), 1);\n    assertEquals(\"Should find a hit...\", 1, docs.totalHits);\n\n    final Filter startFilter = new QueryWrapperFilter(new TermQuery(new Term(\"id\", \"1\")));\n\n    CachingWrapperFilter filter = new CachingWrapperFilter(startFilter);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertTrue(filter.sizeInBytes() > 0);\n\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n\n    Query constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // make sure we get a cache hit when we reopen reader\n    // that had no change to deletions\n\n    // fake delete (deletes nothing):\n    writer.deleteDocuments(new Term(\"foo\", \"bar\"));\n\n    IndexReader oldReader = reader;\n    reader = refreshReader(reader);\n    assertTrue(reader == oldReader);\n    int missCount = filter.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // cache hit:\n    assertEquals(missCount, filter.missCount);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    oldReader = reader;\n    reader = refreshReader(reader);\n\n    searcher = newSearcher(reader, false);\n\n    missCount = filter.missCount;\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    // cache hit\n    assertEquals(missCount, filter.missCount);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    // apply deletes dynamically:\n    filter = new CachingWrapperFilter(startFilter);\n    writer.addDocument(doc);\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    missCount = filter.missCount;\n    assertTrue(missCount > 0);\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    writer.addDocument(doc);\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    oldReader = reader;\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find 2 hits...\", 2, docs.totalHits);\n    assertTrue(filter.missCount > missCount);\n    missCount = filter.missCount;\n\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 2, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n    // CWF reused the same entry (it dynamically applied the deletes):\n    assertEquals(missCount, filter.missCount);\n\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n    // CWF reused the same entry (it dynamically applied the deletes):\n    assertEquals(missCount, filter.missCount);\n\n    // NOTE: silliness to make sure JRE does not eliminate\n    // our holding onto oldReader to prevent\n    // CachingWrapperFilter's WeakHashMap from dropping the\n    // entry:\n    assertTrue(oldReader != null);\n\n    reader.close();\n    writer.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testEnforceDeletions() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(\n        random(),\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).\n            setMergeScheduler(new SerialMergeScheduler()).\n            // asserts below requires no unexpected merges:\n            setMergePolicy(newLogMergePolicy(10))\n    );\n    _TestUtil.keepFullyDeletedSegments(writer.w);\n\n    // NOTE: cannot use writer.getReader because RIW (on\n    // flipping a coin) may give us a newly opened reader,\n    // but we use .reopen on this reader below and expect to\n    // (must) get an NRT reader:\n    DirectoryReader reader = DirectoryReader.open(writer.w, true);\n    // same reason we don't wrap?\n    IndexSearcher searcher = newSearcher(reader, false);\n\n    // add a doc, refresh the reader, and check that it's there\n    Document doc = new Document();\n    doc.add(newStringField(\"id\", \"1\", Field.Store.YES));\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    TopDocs docs = searcher.search(new MatchAllDocsQuery(), 1);\n    assertEquals(\"Should find a hit...\", 1, docs.totalHits);\n\n    final Filter startFilter = new QueryWrapperFilter(new TermQuery(new Term(\"id\", \"1\")));\n\n    CachingWrapperFilter filter = new CachingWrapperFilter(startFilter);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertTrue(filter.sizeInBytes() > 0);\n\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n\n    Query constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // make sure we get a cache hit when we reopen reader\n    // that had no change to deletions\n\n    // fake delete (deletes nothing):\n    writer.deleteDocuments(new Term(\"foo\", \"bar\"));\n\n    IndexReader oldReader = reader;\n    reader = refreshReader(reader);\n    assertTrue(reader == oldReader);\n    int missCount = filter.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // cache hit:\n    assertEquals(missCount, filter.missCount);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    oldReader = reader;\n    reader = refreshReader(reader);\n\n    searcher = newSearcher(reader, false);\n\n    missCount = filter.missCount;\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    // cache hit\n    assertEquals(missCount, filter.missCount);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    // apply deletes dynamically:\n    filter = new CachingWrapperFilter(startFilter);\n    writer.addDocument(doc);\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    missCount = filter.missCount;\n    assertTrue(missCount > 0);\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    writer.addDocument(doc);\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    oldReader = reader;\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find 2 hits...\", 2, docs.totalHits);\n    assertTrue(filter.missCount > missCount);\n    missCount = filter.missCount;\n\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 2, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n    // CWF reused the same entry (it dynamically applied the deletes):\n    assertEquals(missCount, filter.missCount);\n\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n    // CWF reused the same entry (it dynamically applied the deletes):\n    assertEquals(missCount, filter.missCount);\n\n    // NOTE: silliness to make sure JRE does not eliminate\n    // our holding onto oldReader to prevent\n    // CachingWrapperFilter's WeakHashMap from dropping the\n    // entry:\n    assertTrue(oldReader != null);\n\n    reader.close();\n    writer.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ae14298f4eec6d5faee6a149f88ba57d14a6f21a","date":1396971290,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestCachingWrapperFilter#testEnforceDeletions().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestCachingWrapperFilter#testEnforceDeletions().mjava","sourceNew":"  public void testEnforceDeletions() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(\n        random(),\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).\n            setMergeScheduler(new SerialMergeScheduler()).\n            // asserts below requires no unexpected merges:\n            setMergePolicy(newLogMergePolicy(10))\n    );\n\n    // NOTE: cannot use writer.getReader because RIW (on\n    // flipping a coin) may give us a newly opened reader,\n    // but we use .reopen on this reader below and expect to\n    // (must) get an NRT reader:\n    DirectoryReader reader = DirectoryReader.open(writer.w, true);\n    // same reason we don't wrap?\n    IndexSearcher searcher = newSearcher(reader, false);\n\n    // add a doc, refresh the reader, and check that it's there\n    Document doc = new Document();\n    doc.add(newStringField(\"id\", \"1\", Field.Store.YES));\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    TopDocs docs = searcher.search(new MatchAllDocsQuery(), 1);\n    assertEquals(\"Should find a hit...\", 1, docs.totalHits);\n\n    final Filter startFilter = new QueryWrapperFilter(new TermQuery(new Term(\"id\", \"1\")));\n\n    CachingWrapperFilter filter = new CachingWrapperFilter(startFilter);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertTrue(filter.sizeInBytes() > 0);\n\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n\n    Query constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // make sure we get a cache hit when we reopen reader\n    // that had no change to deletions\n\n    // fake delete (deletes nothing):\n    writer.deleteDocuments(new Term(\"foo\", \"bar\"));\n\n    IndexReader oldReader = reader;\n    reader = refreshReader(reader);\n    assertTrue(reader == oldReader);\n    int missCount = filter.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // cache hit:\n    assertEquals(missCount, filter.missCount);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    oldReader = reader;\n    reader = refreshReader(reader);\n\n    searcher = newSearcher(reader, false);\n\n    missCount = filter.missCount;\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    // cache hit\n    assertEquals(missCount, filter.missCount);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    // apply deletes dynamically:\n    filter = new CachingWrapperFilter(startFilter);\n    writer.addDocument(doc);\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    missCount = filter.missCount;\n    assertTrue(missCount > 0);\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    writer.addDocument(doc);\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    oldReader = reader;\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find 2 hits...\", 2, docs.totalHits);\n    assertTrue(filter.missCount > missCount);\n    missCount = filter.missCount;\n\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 2, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n    // CWF reused the same entry (it dynamically applied the deletes):\n    assertEquals(missCount, filter.missCount);\n\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n    // CWF reused the same entry (it dynamically applied the deletes):\n    assertEquals(missCount, filter.missCount);\n\n    // NOTE: silliness to make sure JRE does not eliminate\n    // our holding onto oldReader to prevent\n    // CachingWrapperFilter's WeakHashMap from dropping the\n    // entry:\n    assertTrue(oldReader != null);\n\n    reader.close();\n    writer.shutdown();\n    dir.close();\n  }\n\n","sourceOld":"  public void testEnforceDeletions() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(\n        random(),\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).\n            setMergeScheduler(new SerialMergeScheduler()).\n            // asserts below requires no unexpected merges:\n            setMergePolicy(newLogMergePolicy(10))\n    );\n\n    // NOTE: cannot use writer.getReader because RIW (on\n    // flipping a coin) may give us a newly opened reader,\n    // but we use .reopen on this reader below and expect to\n    // (must) get an NRT reader:\n    DirectoryReader reader = DirectoryReader.open(writer.w, true);\n    // same reason we don't wrap?\n    IndexSearcher searcher = newSearcher(reader, false);\n\n    // add a doc, refresh the reader, and check that it's there\n    Document doc = new Document();\n    doc.add(newStringField(\"id\", \"1\", Field.Store.YES));\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    TopDocs docs = searcher.search(new MatchAllDocsQuery(), 1);\n    assertEquals(\"Should find a hit...\", 1, docs.totalHits);\n\n    final Filter startFilter = new QueryWrapperFilter(new TermQuery(new Term(\"id\", \"1\")));\n\n    CachingWrapperFilter filter = new CachingWrapperFilter(startFilter);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertTrue(filter.sizeInBytes() > 0);\n\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n\n    Query constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // make sure we get a cache hit when we reopen reader\n    // that had no change to deletions\n\n    // fake delete (deletes nothing):\n    writer.deleteDocuments(new Term(\"foo\", \"bar\"));\n\n    IndexReader oldReader = reader;\n    reader = refreshReader(reader);\n    assertTrue(reader == oldReader);\n    int missCount = filter.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // cache hit:\n    assertEquals(missCount, filter.missCount);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    oldReader = reader;\n    reader = refreshReader(reader);\n\n    searcher = newSearcher(reader, false);\n\n    missCount = filter.missCount;\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    // cache hit\n    assertEquals(missCount, filter.missCount);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    // apply deletes dynamically:\n    filter = new CachingWrapperFilter(startFilter);\n    writer.addDocument(doc);\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    missCount = filter.missCount;\n    assertTrue(missCount > 0);\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    writer.addDocument(doc);\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    oldReader = reader;\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find 2 hits...\", 2, docs.totalHits);\n    assertTrue(filter.missCount > missCount);\n    missCount = filter.missCount;\n\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 2, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n    // CWF reused the same entry (it dynamically applied the deletes):\n    assertEquals(missCount, filter.missCount);\n\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n    // CWF reused the same entry (it dynamically applied the deletes):\n    assertEquals(missCount, filter.missCount);\n\n    // NOTE: silliness to make sure JRE does not eliminate\n    // our holding onto oldReader to prevent\n    // CachingWrapperFilter's WeakHashMap from dropping the\n    // entry:\n    assertTrue(oldReader != null);\n\n    reader.close();\n    writer.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"8405d98acebb7e287bf7ac40e937ba05b8661285","date":1401433291,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestCachingWrapperFilter#testEnforceDeletions().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestCachingWrapperFilter#testEnforceDeletions().mjava","sourceNew":"  public void testEnforceDeletions() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(\n        random(),\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).\n            setMergeScheduler(new SerialMergeScheduler()).\n            // asserts below requires no unexpected merges:\n            setMergePolicy(newLogMergePolicy(10))\n    );\n\n    // NOTE: cannot use writer.getReader because RIW (on\n    // flipping a coin) may give us a newly opened reader,\n    // but we use .reopen on this reader below and expect to\n    // (must) get an NRT reader:\n    DirectoryReader reader = DirectoryReader.open(writer.w, true);\n    // same reason we don't wrap?\n    IndexSearcher searcher = newSearcher(reader, false);\n\n    // add a doc, refresh the reader, and check that it's there\n    Document doc = new Document();\n    doc.add(newStringField(\"id\", \"1\", Field.Store.YES));\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    TopDocs docs = searcher.search(new MatchAllDocsQuery(), 1);\n    assertEquals(\"Should find a hit...\", 1, docs.totalHits);\n\n    final Filter startFilter = new QueryWrapperFilter(new TermQuery(new Term(\"id\", \"1\")));\n\n    CachingWrapperFilter filter = new CachingWrapperFilter(startFilter);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertTrue(filter.ramBytesUsed() > 0);\n\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n\n    Query constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // make sure we get a cache hit when we reopen reader\n    // that had no change to deletions\n\n    // fake delete (deletes nothing):\n    writer.deleteDocuments(new Term(\"foo\", \"bar\"));\n\n    IndexReader oldReader = reader;\n    reader = refreshReader(reader);\n    assertTrue(reader == oldReader);\n    int missCount = filter.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // cache hit:\n    assertEquals(missCount, filter.missCount);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    oldReader = reader;\n    reader = refreshReader(reader);\n\n    searcher = newSearcher(reader, false);\n\n    missCount = filter.missCount;\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    // cache hit\n    assertEquals(missCount, filter.missCount);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    // apply deletes dynamically:\n    filter = new CachingWrapperFilter(startFilter);\n    writer.addDocument(doc);\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    missCount = filter.missCount;\n    assertTrue(missCount > 0);\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    writer.addDocument(doc);\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    oldReader = reader;\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find 2 hits...\", 2, docs.totalHits);\n    assertTrue(filter.missCount > missCount);\n    missCount = filter.missCount;\n\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 2, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n    // CWF reused the same entry (it dynamically applied the deletes):\n    assertEquals(missCount, filter.missCount);\n\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n    // CWF reused the same entry (it dynamically applied the deletes):\n    assertEquals(missCount, filter.missCount);\n\n    // NOTE: silliness to make sure JRE does not eliminate\n    // our holding onto oldReader to prevent\n    // CachingWrapperFilter's WeakHashMap from dropping the\n    // entry:\n    assertTrue(oldReader != null);\n\n    reader.close();\n    writer.shutdown();\n    dir.close();\n  }\n\n","sourceOld":"  public void testEnforceDeletions() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(\n        random(),\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).\n            setMergeScheduler(new SerialMergeScheduler()).\n            // asserts below requires no unexpected merges:\n            setMergePolicy(newLogMergePolicy(10))\n    );\n\n    // NOTE: cannot use writer.getReader because RIW (on\n    // flipping a coin) may give us a newly opened reader,\n    // but we use .reopen on this reader below and expect to\n    // (must) get an NRT reader:\n    DirectoryReader reader = DirectoryReader.open(writer.w, true);\n    // same reason we don't wrap?\n    IndexSearcher searcher = newSearcher(reader, false);\n\n    // add a doc, refresh the reader, and check that it's there\n    Document doc = new Document();\n    doc.add(newStringField(\"id\", \"1\", Field.Store.YES));\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    TopDocs docs = searcher.search(new MatchAllDocsQuery(), 1);\n    assertEquals(\"Should find a hit...\", 1, docs.totalHits);\n\n    final Filter startFilter = new QueryWrapperFilter(new TermQuery(new Term(\"id\", \"1\")));\n\n    CachingWrapperFilter filter = new CachingWrapperFilter(startFilter);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertTrue(filter.sizeInBytes() > 0);\n\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n\n    Query constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // make sure we get a cache hit when we reopen reader\n    // that had no change to deletions\n\n    // fake delete (deletes nothing):\n    writer.deleteDocuments(new Term(\"foo\", \"bar\"));\n\n    IndexReader oldReader = reader;\n    reader = refreshReader(reader);\n    assertTrue(reader == oldReader);\n    int missCount = filter.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // cache hit:\n    assertEquals(missCount, filter.missCount);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    oldReader = reader;\n    reader = refreshReader(reader);\n\n    searcher = newSearcher(reader, false);\n\n    missCount = filter.missCount;\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    // cache hit\n    assertEquals(missCount, filter.missCount);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    // apply deletes dynamically:\n    filter = new CachingWrapperFilter(startFilter);\n    writer.addDocument(doc);\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    missCount = filter.missCount;\n    assertTrue(missCount > 0);\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    writer.addDocument(doc);\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    oldReader = reader;\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find 2 hits...\", 2, docs.totalHits);\n    assertTrue(filter.missCount > missCount);\n    missCount = filter.missCount;\n\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 2, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n    // CWF reused the same entry (it dynamically applied the deletes):\n    assertEquals(missCount, filter.missCount);\n\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n    // CWF reused the same entry (it dynamically applied the deletes):\n    assertEquals(missCount, filter.missCount);\n\n    // NOTE: silliness to make sure JRE does not eliminate\n    // our holding onto oldReader to prevent\n    // CachingWrapperFilter's WeakHashMap from dropping the\n    // entry:\n    assertTrue(oldReader != null);\n\n    reader.close();\n    writer.shutdown();\n    dir.close();\n  }\n\n","bugFix":["269301b6df4ea742a519a0cd7d9beb95cd6860e3"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e","date":1406737224,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestCachingWrapperFilter#testEnforceDeletions().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestCachingWrapperFilter#testEnforceDeletions().mjava","sourceNew":"  public void testEnforceDeletions() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(\n        random(),\n        dir,\n        newIndexWriterConfig(new MockAnalyzer(random())).\n            setMergeScheduler(new SerialMergeScheduler()).\n            // asserts below requires no unexpected merges:\n            setMergePolicy(newLogMergePolicy(10))\n    );\n\n    // NOTE: cannot use writer.getReader because RIW (on\n    // flipping a coin) may give us a newly opened reader,\n    // but we use .reopen on this reader below and expect to\n    // (must) get an NRT reader:\n    DirectoryReader reader = DirectoryReader.open(writer.w, true);\n    // same reason we don't wrap?\n    IndexSearcher searcher = newSearcher(reader, false);\n\n    // add a doc, refresh the reader, and check that it's there\n    Document doc = new Document();\n    doc.add(newStringField(\"id\", \"1\", Field.Store.YES));\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    TopDocs docs = searcher.search(new MatchAllDocsQuery(), 1);\n    assertEquals(\"Should find a hit...\", 1, docs.totalHits);\n\n    final Filter startFilter = new QueryWrapperFilter(new TermQuery(new Term(\"id\", \"1\")));\n\n    CachingWrapperFilter filter = new CachingWrapperFilter(startFilter);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertTrue(filter.ramBytesUsed() > 0);\n\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n\n    Query constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // make sure we get a cache hit when we reopen reader\n    // that had no change to deletions\n\n    // fake delete (deletes nothing):\n    writer.deleteDocuments(new Term(\"foo\", \"bar\"));\n\n    IndexReader oldReader = reader;\n    reader = refreshReader(reader);\n    assertTrue(reader == oldReader);\n    int missCount = filter.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // cache hit:\n    assertEquals(missCount, filter.missCount);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    oldReader = reader;\n    reader = refreshReader(reader);\n\n    searcher = newSearcher(reader, false);\n\n    missCount = filter.missCount;\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    // cache hit\n    assertEquals(missCount, filter.missCount);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    // apply deletes dynamically:\n    filter = new CachingWrapperFilter(startFilter);\n    writer.addDocument(doc);\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    missCount = filter.missCount;\n    assertTrue(missCount > 0);\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    writer.addDocument(doc);\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    oldReader = reader;\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find 2 hits...\", 2, docs.totalHits);\n    assertTrue(filter.missCount > missCount);\n    missCount = filter.missCount;\n\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 2, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n    // CWF reused the same entry (it dynamically applied the deletes):\n    assertEquals(missCount, filter.missCount);\n\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n    // CWF reused the same entry (it dynamically applied the deletes):\n    assertEquals(missCount, filter.missCount);\n\n    // NOTE: silliness to make sure JRE does not eliminate\n    // our holding onto oldReader to prevent\n    // CachingWrapperFilter's WeakHashMap from dropping the\n    // entry:\n    assertTrue(oldReader != null);\n\n    reader.close();\n    writer.shutdown();\n    dir.close();\n  }\n\n","sourceOld":"  public void testEnforceDeletions() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(\n        random(),\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).\n            setMergeScheduler(new SerialMergeScheduler()).\n            // asserts below requires no unexpected merges:\n            setMergePolicy(newLogMergePolicy(10))\n    );\n\n    // NOTE: cannot use writer.getReader because RIW (on\n    // flipping a coin) may give us a newly opened reader,\n    // but we use .reopen on this reader below and expect to\n    // (must) get an NRT reader:\n    DirectoryReader reader = DirectoryReader.open(writer.w, true);\n    // same reason we don't wrap?\n    IndexSearcher searcher = newSearcher(reader, false);\n\n    // add a doc, refresh the reader, and check that it's there\n    Document doc = new Document();\n    doc.add(newStringField(\"id\", \"1\", Field.Store.YES));\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    TopDocs docs = searcher.search(new MatchAllDocsQuery(), 1);\n    assertEquals(\"Should find a hit...\", 1, docs.totalHits);\n\n    final Filter startFilter = new QueryWrapperFilter(new TermQuery(new Term(\"id\", \"1\")));\n\n    CachingWrapperFilter filter = new CachingWrapperFilter(startFilter);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertTrue(filter.ramBytesUsed() > 0);\n\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n\n    Query constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // make sure we get a cache hit when we reopen reader\n    // that had no change to deletions\n\n    // fake delete (deletes nothing):\n    writer.deleteDocuments(new Term(\"foo\", \"bar\"));\n\n    IndexReader oldReader = reader;\n    reader = refreshReader(reader);\n    assertTrue(reader == oldReader);\n    int missCount = filter.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // cache hit:\n    assertEquals(missCount, filter.missCount);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    oldReader = reader;\n    reader = refreshReader(reader);\n\n    searcher = newSearcher(reader, false);\n\n    missCount = filter.missCount;\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    // cache hit\n    assertEquals(missCount, filter.missCount);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    // apply deletes dynamically:\n    filter = new CachingWrapperFilter(startFilter);\n    writer.addDocument(doc);\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    missCount = filter.missCount;\n    assertTrue(missCount > 0);\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    writer.addDocument(doc);\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    oldReader = reader;\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find 2 hits...\", 2, docs.totalHits);\n    assertTrue(filter.missCount > missCount);\n    missCount = filter.missCount;\n\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 2, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n    // CWF reused the same entry (it dynamically applied the deletes):\n    assertEquals(missCount, filter.missCount);\n\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n    // CWF reused the same entry (it dynamically applied the deletes):\n    assertEquals(missCount, filter.missCount);\n\n    // NOTE: silliness to make sure JRE does not eliminate\n    // our holding onto oldReader to prevent\n    // CachingWrapperFilter's WeakHashMap from dropping the\n    // entry:\n    assertTrue(oldReader != null);\n\n    reader.close();\n    writer.shutdown();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d0ef034a4f10871667ae75181537775ddcf8ade4","date":1407610475,"type":3,"author":"Ryan Ernst","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestCachingWrapperFilter#testEnforceDeletions().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestCachingWrapperFilter#testEnforceDeletions().mjava","sourceNew":"  public void testEnforceDeletions() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(\n        random(),\n        dir,\n        newIndexWriterConfig(new MockAnalyzer(random())).\n            setMergeScheduler(new SerialMergeScheduler()).\n            // asserts below requires no unexpected merges:\n            setMergePolicy(newLogMergePolicy(10))\n    );\n\n    // NOTE: cannot use writer.getReader because RIW (on\n    // flipping a coin) may give us a newly opened reader,\n    // but we use .reopen on this reader below and expect to\n    // (must) get an NRT reader:\n    DirectoryReader reader = DirectoryReader.open(writer.w, true);\n    // same reason we don't wrap?\n    IndexSearcher searcher = newSearcher(reader, false);\n\n    // add a doc, refresh the reader, and check that it's there\n    Document doc = new Document();\n    doc.add(newStringField(\"id\", \"1\", Field.Store.YES));\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    TopDocs docs = searcher.search(new MatchAllDocsQuery(), 1);\n    assertEquals(\"Should find a hit...\", 1, docs.totalHits);\n\n    final Filter startFilter = new QueryWrapperFilter(new TermQuery(new Term(\"id\", \"1\")));\n\n    CachingWrapperFilter filter = new CachingWrapperFilter(startFilter);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertTrue(filter.ramBytesUsed() > 0);\n\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n\n    Query constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // make sure we get a cache hit when we reopen reader\n    // that had no change to deletions\n\n    // fake delete (deletes nothing):\n    writer.deleteDocuments(new Term(\"foo\", \"bar\"));\n\n    IndexReader oldReader = reader;\n    reader = refreshReader(reader);\n    assertTrue(reader == oldReader);\n    int missCount = filter.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // cache hit:\n    assertEquals(missCount, filter.missCount);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    oldReader = reader;\n    reader = refreshReader(reader);\n\n    searcher = newSearcher(reader, false);\n\n    missCount = filter.missCount;\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    // cache hit\n    assertEquals(missCount, filter.missCount);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    // apply deletes dynamically:\n    filter = new CachingWrapperFilter(startFilter);\n    writer.addDocument(doc);\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    missCount = filter.missCount;\n    assertTrue(missCount > 0);\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    writer.addDocument(doc);\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    oldReader = reader;\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find 2 hits...\", 2, docs.totalHits);\n    assertTrue(filter.missCount > missCount);\n    missCount = filter.missCount;\n\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 2, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n    // CWF reused the same entry (it dynamically applied the deletes):\n    assertEquals(missCount, filter.missCount);\n\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n    // CWF reused the same entry (it dynamically applied the deletes):\n    assertEquals(missCount, filter.missCount);\n\n    // NOTE: silliness to make sure JRE does not eliminate\n    // our holding onto oldReader to prevent\n    // CachingWrapperFilter's WeakHashMap from dropping the\n    // entry:\n    assertTrue(oldReader != null);\n\n    reader.close();\n    writer.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testEnforceDeletions() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(\n        random(),\n        dir,\n        newIndexWriterConfig(new MockAnalyzer(random())).\n            setMergeScheduler(new SerialMergeScheduler()).\n            // asserts below requires no unexpected merges:\n            setMergePolicy(newLogMergePolicy(10))\n    );\n\n    // NOTE: cannot use writer.getReader because RIW (on\n    // flipping a coin) may give us a newly opened reader,\n    // but we use .reopen on this reader below and expect to\n    // (must) get an NRT reader:\n    DirectoryReader reader = DirectoryReader.open(writer.w, true);\n    // same reason we don't wrap?\n    IndexSearcher searcher = newSearcher(reader, false);\n\n    // add a doc, refresh the reader, and check that it's there\n    Document doc = new Document();\n    doc.add(newStringField(\"id\", \"1\", Field.Store.YES));\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    TopDocs docs = searcher.search(new MatchAllDocsQuery(), 1);\n    assertEquals(\"Should find a hit...\", 1, docs.totalHits);\n\n    final Filter startFilter = new QueryWrapperFilter(new TermQuery(new Term(\"id\", \"1\")));\n\n    CachingWrapperFilter filter = new CachingWrapperFilter(startFilter);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertTrue(filter.ramBytesUsed() > 0);\n\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n\n    Query constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // make sure we get a cache hit when we reopen reader\n    // that had no change to deletions\n\n    // fake delete (deletes nothing):\n    writer.deleteDocuments(new Term(\"foo\", \"bar\"));\n\n    IndexReader oldReader = reader;\n    reader = refreshReader(reader);\n    assertTrue(reader == oldReader);\n    int missCount = filter.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // cache hit:\n    assertEquals(missCount, filter.missCount);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    oldReader = reader;\n    reader = refreshReader(reader);\n\n    searcher = newSearcher(reader, false);\n\n    missCount = filter.missCount;\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    // cache hit\n    assertEquals(missCount, filter.missCount);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    // apply deletes dynamically:\n    filter = new CachingWrapperFilter(startFilter);\n    writer.addDocument(doc);\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    missCount = filter.missCount;\n    assertTrue(missCount > 0);\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    writer.addDocument(doc);\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    oldReader = reader;\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find 2 hits...\", 2, docs.totalHits);\n    assertTrue(filter.missCount > missCount);\n    missCount = filter.missCount;\n\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 2, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n    // CWF reused the same entry (it dynamically applied the deletes):\n    assertEquals(missCount, filter.missCount);\n\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n    // CWF reused the same entry (it dynamically applied the deletes):\n    assertEquals(missCount, filter.missCount);\n\n    // NOTE: silliness to make sure JRE does not eliminate\n    // our holding onto oldReader to prevent\n    // CachingWrapperFilter's WeakHashMap from dropping the\n    // entry:\n    assertTrue(oldReader != null);\n\n    reader.close();\n    writer.shutdown();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e5eed7b3a60b52b9f1c32db9c49da397e06f88af","date":1417105424,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestCachingWrapperFilter#testEnforceDeletions().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestCachingWrapperFilter#testEnforceDeletions().mjava","sourceNew":"  public void testEnforceDeletions() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(\n        random(),\n        dir,\n        newIndexWriterConfig(new MockAnalyzer(random())).\n            setMergeScheduler(new SerialMergeScheduler()).\n            // asserts below requires no unexpected merges:\n            setMergePolicy(newLogMergePolicy(10))\n    );\n\n    // NOTE: cannot use writer.getReader because RIW (on\n    // flipping a coin) may give us a newly opened reader,\n    // but we use .reopen on this reader below and expect to\n    // (must) get an NRT reader:\n    DirectoryReader reader = DirectoryReader.open(writer.w, true);\n    // same reason we don't wrap?\n    IndexSearcher searcher = newSearcher(reader, false);\n\n    // add a doc, refresh the reader, and check that it's there\n    Document doc = new Document();\n    doc.add(newStringField(\"id\", \"1\", Field.Store.YES));\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    TopDocs docs = searcher.search(new MatchAllDocsQuery(), 1);\n    assertEquals(\"Should find a hit...\", 1, docs.totalHits);\n\n    final Filter startFilter = new QueryWrapperFilter(new TermQuery(new Term(\"id\", \"1\")));\n\n    CachingWrapperFilter filter = new CachingWrapperFilter(startFilter, FilterCachingPolicy.ALWAYS_CACHE);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertTrue(filter.ramBytesUsed() > 0);\n\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n\n    Query constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // make sure we get a cache hit when we reopen reader\n    // that had no change to deletions\n\n    // fake delete (deletes nothing):\n    writer.deleteDocuments(new Term(\"foo\", \"bar\"));\n\n    IndexReader oldReader = reader;\n    reader = refreshReader(reader);\n    assertTrue(reader == oldReader);\n    int missCount = filter.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // cache hit:\n    assertEquals(missCount, filter.missCount);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    oldReader = reader;\n    reader = refreshReader(reader);\n\n    searcher = newSearcher(reader, false);\n\n    missCount = filter.missCount;\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    // cache hit\n    assertEquals(missCount, filter.missCount);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    // apply deletes dynamically:\n    filter = new CachingWrapperFilter(startFilter, FilterCachingPolicy.ALWAYS_CACHE);\n    writer.addDocument(doc);\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    missCount = filter.missCount;\n    assertTrue(missCount > 0);\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    writer.addDocument(doc);\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    oldReader = reader;\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find 2 hits...\", 2, docs.totalHits);\n    assertTrue(filter.missCount > missCount);\n    missCount = filter.missCount;\n\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 2, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n    // CWF reused the same entry (it dynamically applied the deletes):\n    assertEquals(missCount, filter.missCount);\n\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n    // CWF reused the same entry (it dynamically applied the deletes):\n    assertEquals(missCount, filter.missCount);\n\n    // NOTE: silliness to make sure JRE does not eliminate\n    // our holding onto oldReader to prevent\n    // CachingWrapperFilter's WeakHashMap from dropping the\n    // entry:\n    assertTrue(oldReader != null);\n\n    reader.close();\n    writer.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testEnforceDeletions() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(\n        random(),\n        dir,\n        newIndexWriterConfig(new MockAnalyzer(random())).\n            setMergeScheduler(new SerialMergeScheduler()).\n            // asserts below requires no unexpected merges:\n            setMergePolicy(newLogMergePolicy(10))\n    );\n\n    // NOTE: cannot use writer.getReader because RIW (on\n    // flipping a coin) may give us a newly opened reader,\n    // but we use .reopen on this reader below and expect to\n    // (must) get an NRT reader:\n    DirectoryReader reader = DirectoryReader.open(writer.w, true);\n    // same reason we don't wrap?\n    IndexSearcher searcher = newSearcher(reader, false);\n\n    // add a doc, refresh the reader, and check that it's there\n    Document doc = new Document();\n    doc.add(newStringField(\"id\", \"1\", Field.Store.YES));\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    TopDocs docs = searcher.search(new MatchAllDocsQuery(), 1);\n    assertEquals(\"Should find a hit...\", 1, docs.totalHits);\n\n    final Filter startFilter = new QueryWrapperFilter(new TermQuery(new Term(\"id\", \"1\")));\n\n    CachingWrapperFilter filter = new CachingWrapperFilter(startFilter);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertTrue(filter.ramBytesUsed() > 0);\n\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n\n    Query constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // make sure we get a cache hit when we reopen reader\n    // that had no change to deletions\n\n    // fake delete (deletes nothing):\n    writer.deleteDocuments(new Term(\"foo\", \"bar\"));\n\n    IndexReader oldReader = reader;\n    reader = refreshReader(reader);\n    assertTrue(reader == oldReader);\n    int missCount = filter.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // cache hit:\n    assertEquals(missCount, filter.missCount);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    oldReader = reader;\n    reader = refreshReader(reader);\n\n    searcher = newSearcher(reader, false);\n\n    missCount = filter.missCount;\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    // cache hit\n    assertEquals(missCount, filter.missCount);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    // apply deletes dynamically:\n    filter = new CachingWrapperFilter(startFilter);\n    writer.addDocument(doc);\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    missCount = filter.missCount;\n    assertTrue(missCount > 0);\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    writer.addDocument(doc);\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    oldReader = reader;\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find 2 hits...\", 2, docs.totalHits);\n    assertTrue(filter.missCount > missCount);\n    missCount = filter.missCount;\n\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 2, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n    // CWF reused the same entry (it dynamically applied the deletes):\n    assertEquals(missCount, filter.missCount);\n\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n    // CWF reused the same entry (it dynamically applied the deletes):\n    assertEquals(missCount, filter.missCount);\n\n    // NOTE: silliness to make sure JRE does not eliminate\n    // our holding onto oldReader to prevent\n    // CachingWrapperFilter's WeakHashMap from dropping the\n    // entry:\n    assertTrue(oldReader != null);\n\n    reader.close();\n    writer.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f8ec642b0195d666cf3b5a6a6c2a80bdd3b756bc","date":1424799790,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestCachingWrapperFilter#testEnforceDeletions().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestCachingWrapperFilter#testEnforceDeletions().mjava","sourceNew":"  public void testEnforceDeletions() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(\n        random(),\n        dir,\n        newIndexWriterConfig(new MockAnalyzer(random())).\n            setMergeScheduler(new SerialMergeScheduler()).\n            // asserts below requires no unexpected merges:\n            setMergePolicy(newLogMergePolicy(10))\n    );\n\n    // NOTE: cannot use writer.getReader because RIW (on\n    // flipping a coin) may give us a newly opened reader,\n    // but we use .reopen on this reader below and expect to\n    // (must) get an NRT reader:\n    DirectoryReader reader = DirectoryReader.open(writer.w, true);\n    // same reason we don't wrap?\n    IndexSearcher searcher = newSearcher(reader, false);\n\n    // add a doc, refresh the reader, and check that it's there\n    Document doc = new Document();\n    doc.add(newStringField(\"id\", \"1\", Field.Store.YES));\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    TopDocs docs = searcher.search(new MatchAllDocsQuery(), 1);\n    assertEquals(\"Should find a hit...\", 1, docs.totalHits);\n\n    final Filter startFilter = new QueryWrapperFilter(new TermQuery(new Term(\"id\", \"1\")));\n\n    CachingWrapperFilter filter = new CachingWrapperFilter(startFilter, FilterCachingPolicy.ALWAYS_CACHE);\n\n    docs = searcher.search(new FilteredQuery(new MatchAllDocsQuery(), filter), 1);\n    assertTrue(filter.ramBytesUsed() > 0);\n\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n\n    Query constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // make sure we get a cache hit when we reopen reader\n    // that had no change to deletions\n\n    // fake delete (deletes nothing):\n    writer.deleteDocuments(new Term(\"foo\", \"bar\"));\n\n    IndexReader oldReader = reader;\n    reader = refreshReader(reader);\n    assertTrue(reader == oldReader);\n    int missCount = filter.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // cache hit:\n    assertEquals(missCount, filter.missCount);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    oldReader = reader;\n    reader = refreshReader(reader);\n\n    searcher = newSearcher(reader, false);\n\n    missCount = filter.missCount;\n    docs = searcher.search(new FilteredQuery(new MatchAllDocsQuery(), filter), 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    // cache hit\n    assertEquals(missCount, filter.missCount);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    // apply deletes dynamically:\n    filter = new CachingWrapperFilter(startFilter, FilterCachingPolicy.ALWAYS_CACHE);\n    writer.addDocument(doc);\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    docs = searcher.search(new FilteredQuery(new MatchAllDocsQuery(), filter), 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    missCount = filter.missCount;\n    assertTrue(missCount > 0);\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    writer.addDocument(doc);\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    oldReader = reader;\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n        \n    docs = searcher.search(new FilteredQuery(new MatchAllDocsQuery(), filter), 1);\n    assertEquals(\"[query + filter] Should find 2 hits...\", 2, docs.totalHits);\n    assertTrue(filter.missCount > missCount);\n    missCount = filter.missCount;\n\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 2, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    docs = searcher.search(new FilteredQuery(new MatchAllDocsQuery(), filter), 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n    // CWF reused the same entry (it dynamically applied the deletes):\n    assertEquals(missCount, filter.missCount);\n\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n    // CWF reused the same entry (it dynamically applied the deletes):\n    assertEquals(missCount, filter.missCount);\n\n    // NOTE: silliness to make sure JRE does not eliminate\n    // our holding onto oldReader to prevent\n    // CachingWrapperFilter's WeakHashMap from dropping the\n    // entry:\n    assertTrue(oldReader != null);\n\n    reader.close();\n    writer.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testEnforceDeletions() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(\n        random(),\n        dir,\n        newIndexWriterConfig(new MockAnalyzer(random())).\n            setMergeScheduler(new SerialMergeScheduler()).\n            // asserts below requires no unexpected merges:\n            setMergePolicy(newLogMergePolicy(10))\n    );\n\n    // NOTE: cannot use writer.getReader because RIW (on\n    // flipping a coin) may give us a newly opened reader,\n    // but we use .reopen on this reader below and expect to\n    // (must) get an NRT reader:\n    DirectoryReader reader = DirectoryReader.open(writer.w, true);\n    // same reason we don't wrap?\n    IndexSearcher searcher = newSearcher(reader, false);\n\n    // add a doc, refresh the reader, and check that it's there\n    Document doc = new Document();\n    doc.add(newStringField(\"id\", \"1\", Field.Store.YES));\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    TopDocs docs = searcher.search(new MatchAllDocsQuery(), 1);\n    assertEquals(\"Should find a hit...\", 1, docs.totalHits);\n\n    final Filter startFilter = new QueryWrapperFilter(new TermQuery(new Term(\"id\", \"1\")));\n\n    CachingWrapperFilter filter = new CachingWrapperFilter(startFilter, FilterCachingPolicy.ALWAYS_CACHE);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertTrue(filter.ramBytesUsed() > 0);\n\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n\n    Query constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // make sure we get a cache hit when we reopen reader\n    // that had no change to deletions\n\n    // fake delete (deletes nothing):\n    writer.deleteDocuments(new Term(\"foo\", \"bar\"));\n\n    IndexReader oldReader = reader;\n    reader = refreshReader(reader);\n    assertTrue(reader == oldReader);\n    int missCount = filter.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // cache hit:\n    assertEquals(missCount, filter.missCount);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    oldReader = reader;\n    reader = refreshReader(reader);\n\n    searcher = newSearcher(reader, false);\n\n    missCount = filter.missCount;\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    // cache hit\n    assertEquals(missCount, filter.missCount);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    // apply deletes dynamically:\n    filter = new CachingWrapperFilter(startFilter, FilterCachingPolicy.ALWAYS_CACHE);\n    writer.addDocument(doc);\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    missCount = filter.missCount;\n    assertTrue(missCount > 0);\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    writer.addDocument(doc);\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    oldReader = reader;\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n        \n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should find 2 hits...\", 2, docs.totalHits);\n    assertTrue(filter.missCount > missCount);\n    missCount = filter.missCount;\n\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 2, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    docs = searcher.search(new MatchAllDocsQuery(), filter, 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n    // CWF reused the same entry (it dynamically applied the deletes):\n    assertEquals(missCount, filter.missCount);\n\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n    // CWF reused the same entry (it dynamically applied the deletes):\n    assertEquals(missCount, filter.missCount);\n\n    // NOTE: silliness to make sure JRE does not eliminate\n    // our holding onto oldReader to prevent\n    // CachingWrapperFilter's WeakHashMap from dropping the\n    // entry:\n    assertTrue(oldReader != null);\n\n    reader.close();\n    writer.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"60596f28be69b10c37a56a303c2dbea07b2ca4ba","date":1425060541,"type":5,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestCachingWrapperQuery#testEnforceDeletions().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestCachingWrapperFilter#testEnforceDeletions().mjava","sourceNew":"  public void testEnforceDeletions() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(\n        random(),\n        dir,\n        newIndexWriterConfig(new MockAnalyzer(random())).\n            setMergeScheduler(new SerialMergeScheduler()).\n            // asserts below requires no unexpected merges:\n            setMergePolicy(newLogMergePolicy(10))\n    );\n\n    // NOTE: cannot use writer.getReader because RIW (on\n    // flipping a coin) may give us a newly opened reader,\n    // but we use .reopen on this reader below and expect to\n    // (must) get an NRT reader:\n    DirectoryReader reader = DirectoryReader.open(writer.w, true);\n    // same reason we don't wrap?\n    IndexSearcher searcher = newSearcher(reader, false);\n\n    // add a doc, refresh the reader, and check that it's there\n    Document doc = new Document();\n    doc.add(newStringField(\"id\", \"1\", Field.Store.YES));\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    TopDocs docs = searcher.search(new MatchAllDocsQuery(), 1);\n    assertEquals(\"Should find a hit...\", 1, docs.totalHits);\n\n    final Query startQuery = new TermQuery(new Term(\"id\", \"1\"));\n\n    CachingWrapperQuery query = new CachingWrapperQuery(startQuery, QueryCachingPolicy.ALWAYS_CACHE);\n\n    docs = searcher.search(new ConstantScoreQuery(query), 1);\n    assertTrue(query.ramBytesUsed() > 0);\n\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n\n    Query constantScore = new ConstantScoreQuery(query);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // make sure we get a cache hit when we reopen reader\n    // that had no change to deletions\n\n    // fake delete (deletes nothing):\n    writer.deleteDocuments(new Term(\"foo\", \"bar\"));\n\n    IndexReader oldReader = reader;\n    reader = refreshReader(reader);\n    assertTrue(reader == oldReader);\n    int missCount = query.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // cache hit:\n    assertEquals(missCount, query.missCount);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    oldReader = reader;\n    reader = refreshReader(reader);\n\n    searcher = newSearcher(reader, false);\n\n    missCount = query.missCount;\n    docs = searcher.search(new ConstantScoreQuery(query), 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    // cache hit\n    assertEquals(missCount, query.missCount);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    // apply deletes dynamically:\n    query = new CachingWrapperQuery(startQuery, QueryCachingPolicy.ALWAYS_CACHE);\n    writer.addDocument(doc);\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    docs = searcher.search(new ConstantScoreQuery(query), 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    missCount = query.missCount;\n    assertTrue(missCount > 0);\n    constantScore = new ConstantScoreQuery(query);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n    assertEquals(missCount, query.missCount);\n\n    writer.addDocument(doc);\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    oldReader = reader;\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n        \n    docs = searcher.search(new ConstantScoreQuery(query), 1);\n    assertEquals(\"[query + filter] Should find 2 hits...\", 2, docs.totalHits);\n    assertTrue(query.missCount > missCount);\n    missCount = query.missCount;\n\n    constantScore = new ConstantScoreQuery(query);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 2, docs.totalHits);\n    assertEquals(missCount, query.missCount);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    docs = searcher.search(new ConstantScoreQuery(query), 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n    // CWF reused the same entry (it dynamically applied the deletes):\n    assertEquals(missCount, query.missCount);\n\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n    // CWF reused the same entry (it dynamically applied the deletes):\n    assertEquals(missCount, query.missCount);\n\n    // NOTE: silliness to make sure JRE does not eliminate\n    // our holding onto oldReader to prevent\n    // CachingWrapperFilter's WeakHashMap from dropping the\n    // entry:\n    assertTrue(oldReader != null);\n\n    reader.close();\n    writer.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testEnforceDeletions() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(\n        random(),\n        dir,\n        newIndexWriterConfig(new MockAnalyzer(random())).\n            setMergeScheduler(new SerialMergeScheduler()).\n            // asserts below requires no unexpected merges:\n            setMergePolicy(newLogMergePolicy(10))\n    );\n\n    // NOTE: cannot use writer.getReader because RIW (on\n    // flipping a coin) may give us a newly opened reader,\n    // but we use .reopen on this reader below and expect to\n    // (must) get an NRT reader:\n    DirectoryReader reader = DirectoryReader.open(writer.w, true);\n    // same reason we don't wrap?\n    IndexSearcher searcher = newSearcher(reader, false);\n\n    // add a doc, refresh the reader, and check that it's there\n    Document doc = new Document();\n    doc.add(newStringField(\"id\", \"1\", Field.Store.YES));\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    TopDocs docs = searcher.search(new MatchAllDocsQuery(), 1);\n    assertEquals(\"Should find a hit...\", 1, docs.totalHits);\n\n    final Filter startFilter = new QueryWrapperFilter(new TermQuery(new Term(\"id\", \"1\")));\n\n    CachingWrapperFilter filter = new CachingWrapperFilter(startFilter, FilterCachingPolicy.ALWAYS_CACHE);\n\n    docs = searcher.search(new FilteredQuery(new MatchAllDocsQuery(), filter), 1);\n    assertTrue(filter.ramBytesUsed() > 0);\n\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n\n    Query constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // make sure we get a cache hit when we reopen reader\n    // that had no change to deletions\n\n    // fake delete (deletes nothing):\n    writer.deleteDocuments(new Term(\"foo\", \"bar\"));\n\n    IndexReader oldReader = reader;\n    reader = refreshReader(reader);\n    assertTrue(reader == oldReader);\n    int missCount = filter.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // cache hit:\n    assertEquals(missCount, filter.missCount);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    oldReader = reader;\n    reader = refreshReader(reader);\n\n    searcher = newSearcher(reader, false);\n\n    missCount = filter.missCount;\n    docs = searcher.search(new FilteredQuery(new MatchAllDocsQuery(), filter), 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    // cache hit\n    assertEquals(missCount, filter.missCount);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    // apply deletes dynamically:\n    filter = new CachingWrapperFilter(startFilter, FilterCachingPolicy.ALWAYS_CACHE);\n    writer.addDocument(doc);\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    docs = searcher.search(new FilteredQuery(new MatchAllDocsQuery(), filter), 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    missCount = filter.missCount;\n    assertTrue(missCount > 0);\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    writer.addDocument(doc);\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    oldReader = reader;\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n        \n    docs = searcher.search(new FilteredQuery(new MatchAllDocsQuery(), filter), 1);\n    assertEquals(\"[query + filter] Should find 2 hits...\", 2, docs.totalHits);\n    assertTrue(filter.missCount > missCount);\n    missCount = filter.missCount;\n\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 2, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    docs = searcher.search(new FilteredQuery(new MatchAllDocsQuery(), filter), 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n    // CWF reused the same entry (it dynamically applied the deletes):\n    assertEquals(missCount, filter.missCount);\n\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n    // CWF reused the same entry (it dynamically applied the deletes):\n    assertEquals(missCount, filter.missCount);\n\n    // NOTE: silliness to make sure JRE does not eliminate\n    // our holding onto oldReader to prevent\n    // CachingWrapperFilter's WeakHashMap from dropping the\n    // entry:\n    assertTrue(oldReader != null);\n\n    reader.close();\n    writer.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","date":1427779360,"type":4,"author":"Ryan Ernst","isMerge":true,"pathNew":"/dev/null","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestCachingWrapperFilter#testEnforceDeletions().mjava","sourceNew":null,"sourceOld":"  public void testEnforceDeletions() throws Exception {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(\n        random(),\n        dir,\n        newIndexWriterConfig(new MockAnalyzer(random())).\n            setMergeScheduler(new SerialMergeScheduler()).\n            // asserts below requires no unexpected merges:\n            setMergePolicy(newLogMergePolicy(10))\n    );\n\n    // NOTE: cannot use writer.getReader because RIW (on\n    // flipping a coin) may give us a newly opened reader,\n    // but we use .reopen on this reader below and expect to\n    // (must) get an NRT reader:\n    DirectoryReader reader = DirectoryReader.open(writer.w, true);\n    // same reason we don't wrap?\n    IndexSearcher searcher = newSearcher(reader, false);\n\n    // add a doc, refresh the reader, and check that it's there\n    Document doc = new Document();\n    doc.add(newStringField(\"id\", \"1\", Field.Store.YES));\n    writer.addDocument(doc);\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    TopDocs docs = searcher.search(new MatchAllDocsQuery(), 1);\n    assertEquals(\"Should find a hit...\", 1, docs.totalHits);\n\n    final Filter startFilter = new QueryWrapperFilter(new TermQuery(new Term(\"id\", \"1\")));\n\n    CachingWrapperFilter filter = new CachingWrapperFilter(startFilter, FilterCachingPolicy.ALWAYS_CACHE);\n\n    docs = searcher.search(new FilteredQuery(new MatchAllDocsQuery(), filter), 1);\n    assertTrue(filter.ramBytesUsed() > 0);\n\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n\n    Query constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // make sure we get a cache hit when we reopen reader\n    // that had no change to deletions\n\n    // fake delete (deletes nothing):\n    writer.deleteDocuments(new Term(\"foo\", \"bar\"));\n\n    IndexReader oldReader = reader;\n    reader = refreshReader(reader);\n    assertTrue(reader == oldReader);\n    int missCount = filter.missCount;\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n\n    // cache hit:\n    assertEquals(missCount, filter.missCount);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    oldReader = reader;\n    reader = refreshReader(reader);\n\n    searcher = newSearcher(reader, false);\n\n    missCount = filter.missCount;\n    docs = searcher.search(new FilteredQuery(new MatchAllDocsQuery(), filter), 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    // cache hit\n    assertEquals(missCount, filter.missCount);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n\n    // apply deletes dynamically:\n    filter = new CachingWrapperFilter(startFilter, FilterCachingPolicy.ALWAYS_CACHE);\n    writer.addDocument(doc);\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    docs = searcher.search(new FilteredQuery(new MatchAllDocsQuery(), filter), 1);\n    assertEquals(\"[query + filter] Should find a hit...\", 1, docs.totalHits);\n    missCount = filter.missCount;\n    assertTrue(missCount > 0);\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 1, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    writer.addDocument(doc);\n\n    // NOTE: important to hold ref here so GC doesn't clear\n    // the cache entry!  Else the assert below may sometimes\n    // fail:\n    oldReader = reader;\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n        \n    docs = searcher.search(new FilteredQuery(new MatchAllDocsQuery(), filter), 1);\n    assertEquals(\"[query + filter] Should find 2 hits...\", 2, docs.totalHits);\n    assertTrue(filter.missCount > missCount);\n    missCount = filter.missCount;\n\n    constantScore = new ConstantScoreQuery(filter);\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should find a hit...\", 2, docs.totalHits);\n    assertEquals(missCount, filter.missCount);\n\n    // now delete the doc, refresh the reader, and see that it's not there\n    writer.deleteDocuments(new Term(\"id\", \"1\"));\n\n    reader = refreshReader(reader);\n    searcher = newSearcher(reader, false);\n\n    docs = searcher.search(new FilteredQuery(new MatchAllDocsQuery(), filter), 1);\n    assertEquals(\"[query + filter] Should *not* find a hit...\", 0, docs.totalHits);\n    // CWF reused the same entry (it dynamically applied the deletes):\n    assertEquals(missCount, filter.missCount);\n\n    docs = searcher.search(constantScore, 1);\n    assertEquals(\"[just filter] Should *not* find a hit...\", 0, docs.totalHits);\n    // CWF reused the same entry (it dynamically applied the deletes):\n    assertEquals(missCount, filter.missCount);\n\n    // NOTE: silliness to make sure JRE does not eliminate\n    // our holding onto oldReader to prevent\n    // CachingWrapperFilter's WeakHashMap from dropping the\n    // entry:\n    assertTrue(oldReader != null);\n\n    reader.close();\n    writer.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"da6a6dcc9fdd946001f6161fb9c16afdb5ed84c5":["269301b6df4ea742a519a0cd7d9beb95cd6860e3"],"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e":["8405d98acebb7e287bf7ac40e937ba05b8661285"],"8405d98acebb7e287bf7ac40e937ba05b8661285":["ae14298f4eec6d5faee6a149f88ba57d14a6f21a"],"60596f28be69b10c37a56a303c2dbea07b2ca4ba":["f8ec642b0195d666cf3b5a6a6c2a80bdd3b756bc"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"3dffec77fb8f7d0e9ca4869dddd6af94528b4576":["269301b6df4ea742a519a0cd7d9beb95cd6860e3","da6a6dcc9fdd946001f6161fb9c16afdb5ed84c5"],"e5eed7b3a60b52b9f1c32db9c49da397e06f88af":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"407687e67faf6e1f02a211ca078d8e3eed631027":["04f07771a2a7dd3a395700665ed839c3dae2def2","9a3bd393140af58401b6bcd1d1f6bdc896c718c8"],"269301b6df4ea742a519a0cd7d9beb95cd6860e3":["9a3bd393140af58401b6bcd1d1f6bdc896c718c8"],"9a3bd393140af58401b6bcd1d1f6bdc896c718c8":["04f07771a2a7dd3a395700665ed839c3dae2def2"],"04f07771a2a7dd3a395700665ed839c3dae2def2":["e7e8d6f15900ee22ac3cb0a503f15dc952a3580f"],"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae":["f8ec642b0195d666cf3b5a6a6c2a80bdd3b756bc","60596f28be69b10c37a56a303c2dbea07b2ca4ba"],"e7e8d6f15900ee22ac3cb0a503f15dc952a3580f":["629c38c4ae4e303d0617e05fbfe508140b32f0a3"],"f8ec642b0195d666cf3b5a6a6c2a80bdd3b756bc":["e5eed7b3a60b52b9f1c32db9c49da397e06f88af"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"d0ef034a4f10871667ae75181537775ddcf8ade4":["54a6bea0b991120a99ad0e2f72ae853fd5ecae0e"],"ae14298f4eec6d5faee6a149f88ba57d14a6f21a":["da6a6dcc9fdd946001f6161fb9c16afdb5ed84c5"],"629c38c4ae4e303d0617e05fbfe508140b32f0a3":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["60596f28be69b10c37a56a303c2dbea07b2ca4ba"]},"commit2Childs":{"da6a6dcc9fdd946001f6161fb9c16afdb5ed84c5":["3dffec77fb8f7d0e9ca4869dddd6af94528b4576","ae14298f4eec6d5faee6a149f88ba57d14a6f21a"],"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"8405d98acebb7e287bf7ac40e937ba05b8661285":["54a6bea0b991120a99ad0e2f72ae853fd5ecae0e"],"60596f28be69b10c37a56a303c2dbea07b2ca4ba":["a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["629c38c4ae4e303d0617e05fbfe508140b32f0a3"],"3dffec77fb8f7d0e9ca4869dddd6af94528b4576":[],"e5eed7b3a60b52b9f1c32db9c49da397e06f88af":["f8ec642b0195d666cf3b5a6a6c2a80bdd3b756bc"],"407687e67faf6e1f02a211ca078d8e3eed631027":[],"269301b6df4ea742a519a0cd7d9beb95cd6860e3":["da6a6dcc9fdd946001f6161fb9c16afdb5ed84c5","3dffec77fb8f7d0e9ca4869dddd6af94528b4576"],"9a3bd393140af58401b6bcd1d1f6bdc896c718c8":["407687e67faf6e1f02a211ca078d8e3eed631027","269301b6df4ea742a519a0cd7d9beb95cd6860e3"],"04f07771a2a7dd3a395700665ed839c3dae2def2":["407687e67faf6e1f02a211ca078d8e3eed631027","9a3bd393140af58401b6bcd1d1f6bdc896c718c8"],"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae":[],"e7e8d6f15900ee22ac3cb0a503f15dc952a3580f":["04f07771a2a7dd3a395700665ed839c3dae2def2"],"f8ec642b0195d666cf3b5a6a6c2a80bdd3b756bc":["60596f28be69b10c37a56a303c2dbea07b2ca4ba","a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"d0ef034a4f10871667ae75181537775ddcf8ade4":["e5eed7b3a60b52b9f1c32db9c49da397e06f88af"],"ae14298f4eec6d5faee6a149f88ba57d14a6f21a":["8405d98acebb7e287bf7ac40e937ba05b8661285"],"629c38c4ae4e303d0617e05fbfe508140b32f0a3":["e7e8d6f15900ee22ac3cb0a503f15dc952a3580f"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["3dffec77fb8f7d0e9ca4869dddd6af94528b4576","407687e67faf6e1f02a211ca078d8e3eed631027","a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}