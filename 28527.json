{"path":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriter#testSoftUpdatesConcurrently().mjava","commits":[{"id":"110125c995236a7f61057dd04b039ed2d267f3a1","date":1521014987,"type":0,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriter#testSoftUpdatesConcurrently().mjava","pathOld":"/dev/null","sourceNew":"  public void testSoftUpdatesConcurrently() throws IOException, InterruptedException {\n    Directory dir = newDirectory();\n    IndexWriterConfig indexWriterConfig = newIndexWriterConfig();\n    AtomicBoolean mergeAwaySoftDeletes = new AtomicBoolean(random().nextBoolean());\n\n    indexWriterConfig.setMergePolicy(new OneMergeWrappingMergePolicy(indexWriterConfig.getMergePolicy(), towrap ->\n      new MergePolicy.OneMerge(towrap.segments) {\n        @Override\n        public CodecReader wrapForMerge(CodecReader reader) throws IOException {\n          if (mergeAwaySoftDeletes.get() == false) {\n            return towrap.wrapForMerge(reader);\n          }\n          Bits softDeletesLiveDocs = getSoftDeletesLiveDocs(reader, \"soft_delete\");\n          int numDocs = getNumDocs(reader, softDeletesLiveDocs);\n          CodecReader wrapped = towrap.wrapForMerge(reader);\n          return new FilterCodecReader(wrapped) {\n            @Override\n            public CacheHelper getCoreCacheHelper() {\n              return in.getCoreCacheHelper();\n            }\n\n            @Override\n            public CacheHelper getReaderCacheHelper() {\n              return in.getReaderCacheHelper();\n            }\n\n            @Override\n            public Bits getLiveDocs() {\n              return softDeletesLiveDocs;\n            }\n\n            @Override\n            public int numDocs() {\n              return numDocs;\n            }\n          };\n        }\n      }\n    ));\n    IndexWriter writer = new IndexWriter(dir, indexWriterConfig);\n    Thread[] threads = new Thread[2 + random().nextInt(3)];\n    CountDownLatch startLatch = new CountDownLatch(1);\n    CountDownLatch started = new CountDownLatch(threads.length);\n    boolean updateSeveralDocs = random().nextBoolean();\n    Set<String> ids = Collections.synchronizedSet(new HashSet<>());\n    for (int i = 0; i < threads.length; i++) {\n      threads[i] = new Thread(() -> {\n        try {\n          started.countDown();\n          startLatch.await();\n          for (int d = 0;  d < 100; d++) {\n            String id = String.valueOf(random().nextInt(10));\n            if (updateSeveralDocs) {\n              Document doc = new Document();\n              doc.add(new StringField(\"id\", id, Field.Store.YES));\n              writer.softUpdateDocuments(new Term(\"id\", id), Arrays.asList(doc, doc),\n                  new NumericDocValuesField(\"soft_delete\", 1));\n            } else {\n              Document doc = new Document();\n              doc.add(new StringField(\"id\", id, Field.Store.YES));\n              writer.softUpdateDocument(new Term(\"id\", id), doc,\n                  new NumericDocValuesField(\"soft_delete\", 1));\n            }\n            ids.add(id);\n          }\n        } catch (IOException | InterruptedException e) {\n          throw new AssertionError(e);\n        }\n      });\n      threads[i].start();\n    }\n    started.await();\n    startLatch.countDown();\n\n    for (int i = 0; i < threads.length; i++) {\n      threads[i].join();\n    }\n    DirectoryReader reader = wrapSoftDeletes(DirectoryReader.open(writer), \"soft_delete\");\n    IndexSearcher searcher = new IndexSearcher(reader);\n    for (String id : ids) {\n      TopDocs topDocs = searcher.search(new TermQuery(new Term(\"id\", id)), 10);\n      if (updateSeveralDocs) {\n        assertEquals(2, topDocs.totalHits);\n        assertEquals(Math.abs(topDocs.scoreDocs[0].doc - topDocs.scoreDocs[1].doc), 1);\n      } else {\n        assertEquals(1, topDocs.totalHits);\n      }\n    }\n    mergeAwaySoftDeletes.set(true);\n    writer.forceMerge(1);\n    DirectoryReader oldReader = reader;\n    reader = DirectoryReader.openIfChanged(reader, writer);\n    assertNotSame(oldReader, reader);\n    oldReader.close();\n    for (String id : ids) {\n      if (updateSeveralDocs) {\n        assertEquals(2, reader.docFreq(new Term(\"id\", id)));\n      } else {\n        assertEquals(1, reader.docFreq(new Term(\"id\", id)));\n      }\n    }\n\n    IOUtils.close(reader, writer, dir);\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"014ddb64cdf92cc8d862881e0f45b70eeaee5411","date":1521044766,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriter#testSoftUpdatesConcurrently().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriter#testSoftUpdatesConcurrently().mjava","sourceNew":"  public void testSoftUpdatesConcurrently() throws IOException, InterruptedException {\n    Directory dir = newDirectory();\n    IndexWriterConfig indexWriterConfig = newIndexWriterConfig();\n    AtomicBoolean mergeAwaySoftDeletes = new AtomicBoolean(random().nextBoolean());\n\n    indexWriterConfig.setMergePolicy(new OneMergeWrappingMergePolicy(indexWriterConfig.getMergePolicy(), towrap ->\n      new MergePolicy.OneMerge(towrap.segments) {\n        @Override\n        public CodecReader wrapForMerge(CodecReader reader) throws IOException {\n          if (mergeAwaySoftDeletes.get() == false) {\n            return towrap.wrapForMerge(reader);\n          }\n          Bits softDeletesLiveDocs = getSoftDeletesLiveDocs(reader, \"soft_delete\");\n          int numDocs = getNumDocs(reader, softDeletesLiveDocs);\n          CodecReader wrapped = towrap.wrapForMerge(reader);\n          return new FilterCodecReader(wrapped) {\n            @Override\n            public CacheHelper getCoreCacheHelper() {\n              return in.getCoreCacheHelper();\n            }\n\n            @Override\n            public CacheHelper getReaderCacheHelper() {\n              return in.getReaderCacheHelper();\n            }\n\n            @Override\n            public Bits getLiveDocs() {\n              return softDeletesLiveDocs;\n            }\n\n            @Override\n            public int numDocs() {\n              return numDocs;\n            }\n          };\n        }\n      }\n    ));\n    IndexWriter writer = new IndexWriter(dir, indexWriterConfig);\n    Thread[] threads = new Thread[2 + random().nextInt(3)];\n    CountDownLatch startLatch = new CountDownLatch(1);\n    CountDownLatch started = new CountDownLatch(threads.length);\n    boolean updateSeveralDocs = random().nextBoolean();\n    Set<String> ids = Collections.synchronizedSet(new HashSet<>());\n    for (int i = 0; i < threads.length; i++) {\n      threads[i] = new Thread(() -> {\n        try {\n          started.countDown();\n          startLatch.await();\n          for (int d = 0;  d < 100; d++) {\n            String id = String.valueOf(random().nextInt(10));\n            if (updateSeveralDocs) {\n              Document doc = new Document();\n              doc.add(new StringField(\"id\", id, Field.Store.YES));\n              writer.softUpdateDocuments(new Term(\"id\", id), Arrays.asList(doc, doc),\n                  new NumericDocValuesField(\"soft_delete\", 1));\n            } else {\n              Document doc = new Document();\n              doc.add(new StringField(\"id\", id, Field.Store.YES));\n              writer.softUpdateDocument(new Term(\"id\", id), doc,\n                  new NumericDocValuesField(\"soft_delete\", 1));\n            }\n            ids.add(id);\n          }\n        } catch (IOException | InterruptedException e) {\n          throw new AssertionError(e);\n        }\n      });\n      threads[i].start();\n    }\n    started.await();\n    startLatch.countDown();\n\n    for (int i = 0; i < threads.length; i++) {\n      threads[i].join();\n    }\n    DirectoryReader reader = wrapSoftDeletes(DirectoryReader.open(writer), \"soft_delete\");\n    IndexSearcher searcher = new IndexSearcher(reader);\n    for (String id : ids) {\n      TopDocs topDocs = searcher.search(new TermQuery(new Term(\"id\", id)), 10);\n      if (updateSeveralDocs) {\n        assertEquals(2, topDocs.totalHits);\n        assertEquals(Math.abs(topDocs.scoreDocs[0].doc - topDocs.scoreDocs[1].doc), 1);\n      } else {\n        assertEquals(1, topDocs.totalHits);\n      }\n    }\n    mergeAwaySoftDeletes.set(true);\n    writer.forceMerge(1);\n    DirectoryReader oldReader = reader;\n    reader = DirectoryReader.openIfChanged(reader, writer);\n    if (reader != null) {\n      oldReader.close();\n      assertNotSame(oldReader, reader);\n    } else {\n      reader = oldReader;\n    }\n    for (String id : ids) {\n      if (updateSeveralDocs) {\n        assertEquals(2, reader.docFreq(new Term(\"id\", id)));\n      } else {\n        assertEquals(1, reader.docFreq(new Term(\"id\", id)));\n      }\n    }\n\n    IOUtils.close(reader, writer, dir);\n  }\n\n","sourceOld":"  public void testSoftUpdatesConcurrently() throws IOException, InterruptedException {\n    Directory dir = newDirectory();\n    IndexWriterConfig indexWriterConfig = newIndexWriterConfig();\n    AtomicBoolean mergeAwaySoftDeletes = new AtomicBoolean(random().nextBoolean());\n\n    indexWriterConfig.setMergePolicy(new OneMergeWrappingMergePolicy(indexWriterConfig.getMergePolicy(), towrap ->\n      new MergePolicy.OneMerge(towrap.segments) {\n        @Override\n        public CodecReader wrapForMerge(CodecReader reader) throws IOException {\n          if (mergeAwaySoftDeletes.get() == false) {\n            return towrap.wrapForMerge(reader);\n          }\n          Bits softDeletesLiveDocs = getSoftDeletesLiveDocs(reader, \"soft_delete\");\n          int numDocs = getNumDocs(reader, softDeletesLiveDocs);\n          CodecReader wrapped = towrap.wrapForMerge(reader);\n          return new FilterCodecReader(wrapped) {\n            @Override\n            public CacheHelper getCoreCacheHelper() {\n              return in.getCoreCacheHelper();\n            }\n\n            @Override\n            public CacheHelper getReaderCacheHelper() {\n              return in.getReaderCacheHelper();\n            }\n\n            @Override\n            public Bits getLiveDocs() {\n              return softDeletesLiveDocs;\n            }\n\n            @Override\n            public int numDocs() {\n              return numDocs;\n            }\n          };\n        }\n      }\n    ));\n    IndexWriter writer = new IndexWriter(dir, indexWriterConfig);\n    Thread[] threads = new Thread[2 + random().nextInt(3)];\n    CountDownLatch startLatch = new CountDownLatch(1);\n    CountDownLatch started = new CountDownLatch(threads.length);\n    boolean updateSeveralDocs = random().nextBoolean();\n    Set<String> ids = Collections.synchronizedSet(new HashSet<>());\n    for (int i = 0; i < threads.length; i++) {\n      threads[i] = new Thread(() -> {\n        try {\n          started.countDown();\n          startLatch.await();\n          for (int d = 0;  d < 100; d++) {\n            String id = String.valueOf(random().nextInt(10));\n            if (updateSeveralDocs) {\n              Document doc = new Document();\n              doc.add(new StringField(\"id\", id, Field.Store.YES));\n              writer.softUpdateDocuments(new Term(\"id\", id), Arrays.asList(doc, doc),\n                  new NumericDocValuesField(\"soft_delete\", 1));\n            } else {\n              Document doc = new Document();\n              doc.add(new StringField(\"id\", id, Field.Store.YES));\n              writer.softUpdateDocument(new Term(\"id\", id), doc,\n                  new NumericDocValuesField(\"soft_delete\", 1));\n            }\n            ids.add(id);\n          }\n        } catch (IOException | InterruptedException e) {\n          throw new AssertionError(e);\n        }\n      });\n      threads[i].start();\n    }\n    started.await();\n    startLatch.countDown();\n\n    for (int i = 0; i < threads.length; i++) {\n      threads[i].join();\n    }\n    DirectoryReader reader = wrapSoftDeletes(DirectoryReader.open(writer), \"soft_delete\");\n    IndexSearcher searcher = new IndexSearcher(reader);\n    for (String id : ids) {\n      TopDocs topDocs = searcher.search(new TermQuery(new Term(\"id\", id)), 10);\n      if (updateSeveralDocs) {\n        assertEquals(2, topDocs.totalHits);\n        assertEquals(Math.abs(topDocs.scoreDocs[0].doc - topDocs.scoreDocs[1].doc), 1);\n      } else {\n        assertEquals(1, topDocs.totalHits);\n      }\n    }\n    mergeAwaySoftDeletes.set(true);\n    writer.forceMerge(1);\n    DirectoryReader oldReader = reader;\n    reader = DirectoryReader.openIfChanged(reader, writer);\n    assertNotSame(oldReader, reader);\n    oldReader.close();\n    for (String id : ids) {\n      if (updateSeveralDocs) {\n        assertEquals(2, reader.docFreq(new Term(\"id\", id)));\n      } else {\n        assertEquals(1, reader.docFreq(new Term(\"id\", id)));\n      }\n    }\n\n    IOUtils.close(reader, writer, dir);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2f3b17ff927f0c6f30423d70da7357df498c691a","date":1521117669,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriter#testSoftUpdatesConcurrently().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriter#testSoftUpdatesConcurrently().mjava","sourceNew":"  public void testSoftUpdatesConcurrently() throws IOException, InterruptedException {\n    Directory dir = newDirectory();\n    IndexWriterConfig indexWriterConfig = newIndexWriterConfig();\n    AtomicBoolean mergeAwaySoftDeletes = new AtomicBoolean(random().nextBoolean());\n    indexWriterConfig.setMergePolicy(new OneMergeWrappingMergePolicy(indexWriterConfig.getMergePolicy(), towrap ->\n      new MergePolicy.OneMerge(towrap.segments) {\n        @Override\n        public CodecReader wrapForMerge(CodecReader reader) throws IOException {\n          if (mergeAwaySoftDeletes.get() == false) {\n            return towrap.wrapForMerge(reader);\n          }\n          Bits softDeletesLiveDocs = getSoftDeletesLiveDocs(reader, \"soft_delete\");\n          int numDocs = getNumDocs(reader, softDeletesLiveDocs);\n          CodecReader wrapped = towrap.wrapForMerge(reader);\n          return new FilterCodecReader(wrapped) {\n            @Override\n            public CacheHelper getCoreCacheHelper() {\n              return in.getCoreCacheHelper();\n            }\n\n            @Override\n            public CacheHelper getReaderCacheHelper() {\n              return in.getReaderCacheHelper();\n            }\n\n            @Override\n            public Bits getLiveDocs() {\n              return softDeletesLiveDocs;\n            }\n\n            @Override\n            public int numDocs() {\n              return numDocs;\n            }\n          };\n        }\n      }\n    ));\n    IndexWriter writer = new IndexWriter(dir, indexWriterConfig);\n    Thread[] threads = new Thread[2 + random().nextInt(3)];\n    CountDownLatch startLatch = new CountDownLatch(1);\n    CountDownLatch started = new CountDownLatch(threads.length);\n    boolean updateSeveralDocs = random().nextBoolean();\n    Set<String> ids = Collections.synchronizedSet(new HashSet<>());\n    for (int i = 0; i < threads.length; i++) {\n      threads[i] = new Thread(() -> {\n        try {\n          started.countDown();\n          startLatch.await();\n          for (int d = 0;  d < 100; d++) {\n            String id = String.valueOf(random().nextInt(10));\n            if (updateSeveralDocs) {\n              Document doc = new Document();\n              doc.add(new StringField(\"id\", id, Field.Store.YES));\n              writer.softUpdateDocuments(new Term(\"id\", id), Arrays.asList(doc, doc),\n                  new NumericDocValuesField(\"soft_delete\", 1));\n            } else {\n              Document doc = new Document();\n              doc.add(new StringField(\"id\", id, Field.Store.YES));\n              writer.softUpdateDocument(new Term(\"id\", id), doc,\n                  new NumericDocValuesField(\"soft_delete\", 1));\n            }\n            ids.add(id);\n          }\n        } catch (IOException | InterruptedException e) {\n          throw new AssertionError(e);\n        }\n      });\n      threads[i].start();\n    }\n    started.await();\n    startLatch.countDown();\n\n    for (int i = 0; i < threads.length; i++) {\n      threads[i].join();\n    }\n    DirectoryReader reader = wrapSoftDeletes(DirectoryReader.open(writer), \"soft_delete\");\n    IndexSearcher searcher = new IndexSearcher(reader);\n    for (String id : ids) {\n      TopDocs topDocs = searcher.search(new TermQuery(new Term(\"id\", id)), 10);\n      if (updateSeveralDocs) {\n        assertEquals(2, topDocs.totalHits);\n        assertEquals(Math.abs(topDocs.scoreDocs[0].doc - topDocs.scoreDocs[1].doc), 1);\n      } else {\n        assertEquals(1, topDocs.totalHits);\n      }\n    }\n    mergeAwaySoftDeletes.set(true);\n    writer.addDocument(new Document()); // add a dummy doc to trigger a segment here\n    writer.flush();\n    writer.forceMerge(1);\n    DirectoryReader oldReader = reader;\n    reader = DirectoryReader.openIfChanged(reader, writer);\n    if (reader != null) {\n      oldReader.close();\n      assertNotSame(oldReader, reader);\n    } else {\n      reader = oldReader;\n    }\n    for (String id : ids) {\n      if (updateSeveralDocs) {\n        assertEquals(2, reader.docFreq(new Term(\"id\", id)));\n      } else {\n        assertEquals(1, reader.docFreq(new Term(\"id\", id)));\n      }\n    }\n\n    IOUtils.close(reader, writer, dir);\n  }\n\n","sourceOld":"  public void testSoftUpdatesConcurrently() throws IOException, InterruptedException {\n    Directory dir = newDirectory();\n    IndexWriterConfig indexWriterConfig = newIndexWriterConfig();\n    AtomicBoolean mergeAwaySoftDeletes = new AtomicBoolean(random().nextBoolean());\n\n    indexWriterConfig.setMergePolicy(new OneMergeWrappingMergePolicy(indexWriterConfig.getMergePolicy(), towrap ->\n      new MergePolicy.OneMerge(towrap.segments) {\n        @Override\n        public CodecReader wrapForMerge(CodecReader reader) throws IOException {\n          if (mergeAwaySoftDeletes.get() == false) {\n            return towrap.wrapForMerge(reader);\n          }\n          Bits softDeletesLiveDocs = getSoftDeletesLiveDocs(reader, \"soft_delete\");\n          int numDocs = getNumDocs(reader, softDeletesLiveDocs);\n          CodecReader wrapped = towrap.wrapForMerge(reader);\n          return new FilterCodecReader(wrapped) {\n            @Override\n            public CacheHelper getCoreCacheHelper() {\n              return in.getCoreCacheHelper();\n            }\n\n            @Override\n            public CacheHelper getReaderCacheHelper() {\n              return in.getReaderCacheHelper();\n            }\n\n            @Override\n            public Bits getLiveDocs() {\n              return softDeletesLiveDocs;\n            }\n\n            @Override\n            public int numDocs() {\n              return numDocs;\n            }\n          };\n        }\n      }\n    ));\n    IndexWriter writer = new IndexWriter(dir, indexWriterConfig);\n    Thread[] threads = new Thread[2 + random().nextInt(3)];\n    CountDownLatch startLatch = new CountDownLatch(1);\n    CountDownLatch started = new CountDownLatch(threads.length);\n    boolean updateSeveralDocs = random().nextBoolean();\n    Set<String> ids = Collections.synchronizedSet(new HashSet<>());\n    for (int i = 0; i < threads.length; i++) {\n      threads[i] = new Thread(() -> {\n        try {\n          started.countDown();\n          startLatch.await();\n          for (int d = 0;  d < 100; d++) {\n            String id = String.valueOf(random().nextInt(10));\n            if (updateSeveralDocs) {\n              Document doc = new Document();\n              doc.add(new StringField(\"id\", id, Field.Store.YES));\n              writer.softUpdateDocuments(new Term(\"id\", id), Arrays.asList(doc, doc),\n                  new NumericDocValuesField(\"soft_delete\", 1));\n            } else {\n              Document doc = new Document();\n              doc.add(new StringField(\"id\", id, Field.Store.YES));\n              writer.softUpdateDocument(new Term(\"id\", id), doc,\n                  new NumericDocValuesField(\"soft_delete\", 1));\n            }\n            ids.add(id);\n          }\n        } catch (IOException | InterruptedException e) {\n          throw new AssertionError(e);\n        }\n      });\n      threads[i].start();\n    }\n    started.await();\n    startLatch.countDown();\n\n    for (int i = 0; i < threads.length; i++) {\n      threads[i].join();\n    }\n    DirectoryReader reader = wrapSoftDeletes(DirectoryReader.open(writer), \"soft_delete\");\n    IndexSearcher searcher = new IndexSearcher(reader);\n    for (String id : ids) {\n      TopDocs topDocs = searcher.search(new TermQuery(new Term(\"id\", id)), 10);\n      if (updateSeveralDocs) {\n        assertEquals(2, topDocs.totalHits);\n        assertEquals(Math.abs(topDocs.scoreDocs[0].doc - topDocs.scoreDocs[1].doc), 1);\n      } else {\n        assertEquals(1, topDocs.totalHits);\n      }\n    }\n    mergeAwaySoftDeletes.set(true);\n    writer.forceMerge(1);\n    DirectoryReader oldReader = reader;\n    reader = DirectoryReader.openIfChanged(reader, writer);\n    if (reader != null) {\n      oldReader.close();\n      assertNotSame(oldReader, reader);\n    } else {\n      reader = oldReader;\n    }\n    for (String id : ids) {\n      if (updateSeveralDocs) {\n        assertEquals(2, reader.docFreq(new Term(\"id\", id)));\n      } else {\n        assertEquals(1, reader.docFreq(new Term(\"id\", id)));\n      }\n    }\n\n    IOUtils.close(reader, writer, dir);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5ee0394b8176abd7c90a4be8c05465be1879db79","date":1522842314,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriter#testSoftUpdatesConcurrently().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriter#testSoftUpdatesConcurrently().mjava","sourceNew":"  public void testSoftUpdatesConcurrently() throws IOException, InterruptedException {\n    softUpdatesConcurrently(false);\n  }\n\n","sourceOld":"  public void testSoftUpdatesConcurrently() throws IOException, InterruptedException {\n    Directory dir = newDirectory();\n    IndexWriterConfig indexWriterConfig = newIndexWriterConfig();\n    AtomicBoolean mergeAwaySoftDeletes = new AtomicBoolean(random().nextBoolean());\n    indexWriterConfig.setMergePolicy(new OneMergeWrappingMergePolicy(indexWriterConfig.getMergePolicy(), towrap ->\n      new MergePolicy.OneMerge(towrap.segments) {\n        @Override\n        public CodecReader wrapForMerge(CodecReader reader) throws IOException {\n          if (mergeAwaySoftDeletes.get() == false) {\n            return towrap.wrapForMerge(reader);\n          }\n          Bits softDeletesLiveDocs = getSoftDeletesLiveDocs(reader, \"soft_delete\");\n          int numDocs = getNumDocs(reader, softDeletesLiveDocs);\n          CodecReader wrapped = towrap.wrapForMerge(reader);\n          return new FilterCodecReader(wrapped) {\n            @Override\n            public CacheHelper getCoreCacheHelper() {\n              return in.getCoreCacheHelper();\n            }\n\n            @Override\n            public CacheHelper getReaderCacheHelper() {\n              return in.getReaderCacheHelper();\n            }\n\n            @Override\n            public Bits getLiveDocs() {\n              return softDeletesLiveDocs;\n            }\n\n            @Override\n            public int numDocs() {\n              return numDocs;\n            }\n          };\n        }\n      }\n    ));\n    IndexWriter writer = new IndexWriter(dir, indexWriterConfig);\n    Thread[] threads = new Thread[2 + random().nextInt(3)];\n    CountDownLatch startLatch = new CountDownLatch(1);\n    CountDownLatch started = new CountDownLatch(threads.length);\n    boolean updateSeveralDocs = random().nextBoolean();\n    Set<String> ids = Collections.synchronizedSet(new HashSet<>());\n    for (int i = 0; i < threads.length; i++) {\n      threads[i] = new Thread(() -> {\n        try {\n          started.countDown();\n          startLatch.await();\n          for (int d = 0;  d < 100; d++) {\n            String id = String.valueOf(random().nextInt(10));\n            if (updateSeveralDocs) {\n              Document doc = new Document();\n              doc.add(new StringField(\"id\", id, Field.Store.YES));\n              writer.softUpdateDocuments(new Term(\"id\", id), Arrays.asList(doc, doc),\n                  new NumericDocValuesField(\"soft_delete\", 1));\n            } else {\n              Document doc = new Document();\n              doc.add(new StringField(\"id\", id, Field.Store.YES));\n              writer.softUpdateDocument(new Term(\"id\", id), doc,\n                  new NumericDocValuesField(\"soft_delete\", 1));\n            }\n            ids.add(id);\n          }\n        } catch (IOException | InterruptedException e) {\n          throw new AssertionError(e);\n        }\n      });\n      threads[i].start();\n    }\n    started.await();\n    startLatch.countDown();\n\n    for (int i = 0; i < threads.length; i++) {\n      threads[i].join();\n    }\n    DirectoryReader reader = wrapSoftDeletes(DirectoryReader.open(writer), \"soft_delete\");\n    IndexSearcher searcher = new IndexSearcher(reader);\n    for (String id : ids) {\n      TopDocs topDocs = searcher.search(new TermQuery(new Term(\"id\", id)), 10);\n      if (updateSeveralDocs) {\n        assertEquals(2, topDocs.totalHits);\n        assertEquals(Math.abs(topDocs.scoreDocs[0].doc - topDocs.scoreDocs[1].doc), 1);\n      } else {\n        assertEquals(1, topDocs.totalHits);\n      }\n    }\n    mergeAwaySoftDeletes.set(true);\n    writer.addDocument(new Document()); // add a dummy doc to trigger a segment here\n    writer.flush();\n    writer.forceMerge(1);\n    DirectoryReader oldReader = reader;\n    reader = DirectoryReader.openIfChanged(reader, writer);\n    if (reader != null) {\n      oldReader.close();\n      assertNotSame(oldReader, reader);\n    } else {\n      reader = oldReader;\n    }\n    for (String id : ids) {\n      if (updateSeveralDocs) {\n        assertEquals(2, reader.docFreq(new Term(\"id\", id)));\n      } else {\n        assertEquals(1, reader.docFreq(new Term(\"id\", id)));\n      }\n    }\n\n    IOUtils.close(reader, writer, dir);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"2f3b17ff927f0c6f30423d70da7357df498c691a":["014ddb64cdf92cc8d862881e0f45b70eeaee5411"],"014ddb64cdf92cc8d862881e0f45b70eeaee5411":["110125c995236a7f61057dd04b039ed2d267f3a1"],"5ee0394b8176abd7c90a4be8c05465be1879db79":["2f3b17ff927f0c6f30423d70da7357df498c691a"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"110125c995236a7f61057dd04b039ed2d267f3a1":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["5ee0394b8176abd7c90a4be8c05465be1879db79"]},"commit2Childs":{"2f3b17ff927f0c6f30423d70da7357df498c691a":["5ee0394b8176abd7c90a4be8c05465be1879db79"],"014ddb64cdf92cc8d862881e0f45b70eeaee5411":["2f3b17ff927f0c6f30423d70da7357df498c691a"],"5ee0394b8176abd7c90a4be8c05465be1879db79":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["110125c995236a7f61057dd04b039ed2d267f3a1"],"110125c995236a7f61057dd04b039ed2d267f3a1":["014ddb64cdf92cc8d862881e0f45b70eeaee5411"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}