{"path":"contrib/analyzers/src/test/org/apache/lucene/analysis/ru/TestRussianAnalyzer#testUnicode().mjava","commits":[{"id":"043c298cb215f13ba7b9b81d20760704e8f93d66","date":1107566743,"type":1,"author":"Erik Hatcher","isMerge":false,"pathNew":"contrib/analyzers/src/test/org/apache/lucene/analysis/ru/TestRussianAnalyzer#testUnicode().mjava","pathOld":"sandbox/contributions/analyzers/src/test/org/apache/lucene/analysis/ru/TestRussianAnalyzer#testUnicode().mjava","sourceNew":"    public void testUnicode() throws IOException\n    {\n        RussianAnalyzer ra = new RussianAnalyzer(RussianCharsets.UnicodeRussian);\n        inWords =\n            new InputStreamReader(\n                new FileInputStream(new File(dataDir, \"/org/apache/lucene/analysis/ru/testUnicode.txt\")),\n                \"Unicode\");\n\n        sampleUnicode =\n            new InputStreamReader(\n                new FileInputStream(new File(dataDir, \"/org/apache/lucene/analysis/ru/resUnicode.htm\")),\n                \"Unicode\");\n\n        TokenStream in = ra.tokenStream(\"all\", inWords);\n\n        RussianLetterTokenizer sample =\n            new RussianLetterTokenizer(\n                sampleUnicode,\n                RussianCharsets.UnicodeRussian);\n\n        for (;;)\n        {\n            Token token = in.next();\n\n            if (token == null)\n            {\n                break;\n            }\n\n            Token sampleToken = sample.next();\n            assertEquals(\n                \"Unicode\",\n                token.termText(),\n                sampleToken == null\n                ? null\n                : sampleToken.termText());\n        }\n\n        inWords.close();\n        sampleUnicode.close();\n    }\n\n","sourceOld":"    public void testUnicode() throws IOException\n    {\n        RussianAnalyzer ra = new RussianAnalyzer(RussianCharsets.UnicodeRussian);\n        inWords =\n            new InputStreamReader(\n                new FileInputStream(new File(dataDir, \"/org/apache/lucene/analysis/ru/testUnicode.txt\")),\n                \"Unicode\");\n\n        sampleUnicode =\n            new InputStreamReader(\n                new FileInputStream(new File(dataDir, \"/org/apache/lucene/analysis/ru/resUnicode.htm\")),\n                \"Unicode\");\n\n        TokenStream in = ra.tokenStream(\"all\", inWords);\n\n        RussianLetterTokenizer sample =\n            new RussianLetterTokenizer(\n                sampleUnicode,\n                RussianCharsets.UnicodeRussian);\n\n        for (;;)\n        {\n            Token token = in.next();\n\n            if (token == null)\n            {\n                break;\n            }\n\n            Token sampleToken = sample.next();\n            assertEquals(\n                \"Unicode\",\n                token.termText(),\n                sampleToken == null\n                ? null\n                : sampleToken.termText());\n        }\n\n        inWords.close();\n        sampleUnicode.close();\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7e2cb543b41c145f33390f460ee743d6693c9c6c","date":1219243087,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"contrib/analyzers/src/test/org/apache/lucene/analysis/ru/TestRussianAnalyzer#testUnicode().mjava","pathOld":"contrib/analyzers/src/test/org/apache/lucene/analysis/ru/TestRussianAnalyzer#testUnicode().mjava","sourceNew":"    public void testUnicode() throws IOException\n    {\n        RussianAnalyzer ra = new RussianAnalyzer(RussianCharsets.UnicodeRussian);\n        inWords =\n            new InputStreamReader(\n                new FileInputStream(new File(dataDir, \"/org/apache/lucene/analysis/ru/testUnicode.txt\")),\n                \"Unicode\");\n\n        sampleUnicode =\n            new InputStreamReader(\n                new FileInputStream(new File(dataDir, \"/org/apache/lucene/analysis/ru/resUnicode.htm\")),\n                \"Unicode\");\n\n        TokenStream in = ra.tokenStream(\"all\", inWords);\n\n        RussianLetterTokenizer sample =\n            new RussianLetterTokenizer(\n                sampleUnicode,\n                RussianCharsets.UnicodeRussian);\n\n        final Token reusableToken = new Token();\n        final Token reusableSampleToken = new Token();\n        Token nextToken;\n        Token nextSampleToken;\n        for (;;)\n        {\n            nextToken = in.next(reusableToken);\n\n            if (nextToken == null)\n            {\n                break;\n            }\n\n            nextSampleToken = sample.next(reusableSampleToken);\n            assertEquals(\n                \"Unicode\",\n                nextToken.term(),\n                nextSampleToken == null\n                ? null\n                : nextSampleToken.term());\n        }\n\n        inWords.close();\n        sampleUnicode.close();\n    }\n\n","sourceOld":"    public void testUnicode() throws IOException\n    {\n        RussianAnalyzer ra = new RussianAnalyzer(RussianCharsets.UnicodeRussian);\n        inWords =\n            new InputStreamReader(\n                new FileInputStream(new File(dataDir, \"/org/apache/lucene/analysis/ru/testUnicode.txt\")),\n                \"Unicode\");\n\n        sampleUnicode =\n            new InputStreamReader(\n                new FileInputStream(new File(dataDir, \"/org/apache/lucene/analysis/ru/resUnicode.htm\")),\n                \"Unicode\");\n\n        TokenStream in = ra.tokenStream(\"all\", inWords);\n\n        RussianLetterTokenizer sample =\n            new RussianLetterTokenizer(\n                sampleUnicode,\n                RussianCharsets.UnicodeRussian);\n\n        for (;;)\n        {\n            Token token = in.next();\n\n            if (token == null)\n            {\n                break;\n            }\n\n            Token sampleToken = sample.next();\n            assertEquals(\n                \"Unicode\",\n                token.termText(),\n                sampleToken == null\n                ? null\n                : sampleToken.termText());\n        }\n\n        inWords.close();\n        sampleUnicode.close();\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6cb858a08d9285320591728f5b85c55f1ff2b944","date":1246888217,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"contrib/analyzers/src/test/org/apache/lucene/analysis/ru/TestRussianAnalyzer#testUnicode().mjava","pathOld":"contrib/analyzers/src/test/org/apache/lucene/analysis/ru/TestRussianAnalyzer#testUnicode().mjava","sourceNew":"    public void testUnicode() throws IOException\n    {\n        RussianAnalyzer ra = new RussianAnalyzer(RussianCharsets.UnicodeRussian);\n        inWords =\n            new InputStreamReader(\n                new FileInputStream(new File(dataDir, \"/org/apache/lucene/analysis/ru/testUTF8.txt\")),\n                \"UTF-8\");\n\n        sampleUnicode =\n            new InputStreamReader(\n                new FileInputStream(new File(dataDir, \"/org/apache/lucene/analysis/ru/resUTF8.htm\")),\n                \"UTF-8\");\n\n        TokenStream in = ra.tokenStream(\"all\", inWords);\n\n        RussianLetterTokenizer sample =\n            new RussianLetterTokenizer(\n                sampleUnicode,\n                RussianCharsets.UnicodeRussian);\n\n        final Token reusableToken = new Token();\n        final Token reusableSampleToken = new Token();\n        Token nextToken;\n        Token nextSampleToken;\n        for (;;)\n        {\n            nextToken = in.next(reusableToken);\n\n            if (nextToken == null)\n            {\n                break;\n            }\n\n            nextSampleToken = sample.next(reusableSampleToken);\n            assertEquals(\n                \"Unicode\",\n                nextToken.term(),\n                nextSampleToken == null\n                ? null\n                : nextSampleToken.term());\n        }\n\n        inWords.close();\n        sampleUnicode.close();\n    }\n\n","sourceOld":"    public void testUnicode() throws IOException\n    {\n        RussianAnalyzer ra = new RussianAnalyzer(RussianCharsets.UnicodeRussian);\n        inWords =\n            new InputStreamReader(\n                new FileInputStream(new File(dataDir, \"/org/apache/lucene/analysis/ru/testUnicode.txt\")),\n                \"Unicode\");\n\n        sampleUnicode =\n            new InputStreamReader(\n                new FileInputStream(new File(dataDir, \"/org/apache/lucene/analysis/ru/resUnicode.htm\")),\n                \"Unicode\");\n\n        TokenStream in = ra.tokenStream(\"all\", inWords);\n\n        RussianLetterTokenizer sample =\n            new RussianLetterTokenizer(\n                sampleUnicode,\n                RussianCharsets.UnicodeRussian);\n\n        final Token reusableToken = new Token();\n        final Token reusableSampleToken = new Token();\n        Token nextToken;\n        Token nextSampleToken;\n        for (;;)\n        {\n            nextToken = in.next(reusableToken);\n\n            if (nextToken == null)\n            {\n                break;\n            }\n\n            nextSampleToken = sample.next(reusableSampleToken);\n            assertEquals(\n                \"Unicode\",\n                nextToken.term(),\n                nextSampleToken == null\n                ? null\n                : nextSampleToken.term());\n        }\n\n        inWords.close();\n        sampleUnicode.close();\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"dd745d580729e528151b58aeda87ef82f1b95c9b","date":1248369082,"type":5,"author":"Simon Willnauer","isMerge":false,"pathNew":"contrib/analyzers/common/src/test/org/apache/lucene/analysis/ru/TestRussianAnalyzer#testUnicode().mjava","pathOld":"contrib/analyzers/src/test/org/apache/lucene/analysis/ru/TestRussianAnalyzer#testUnicode().mjava","sourceNew":"    public void testUnicode() throws IOException\n    {\n        RussianAnalyzer ra = new RussianAnalyzer(RussianCharsets.UnicodeRussian);\n        inWords =\n            new InputStreamReader(\n                new FileInputStream(new File(dataDir, \"/org/apache/lucene/analysis/ru/testUTF8.txt\")),\n                \"UTF-8\");\n\n        sampleUnicode =\n            new InputStreamReader(\n                new FileInputStream(new File(dataDir, \"/org/apache/lucene/analysis/ru/resUTF8.htm\")),\n                \"UTF-8\");\n\n        TokenStream in = ra.tokenStream(\"all\", inWords);\n\n        RussianLetterTokenizer sample =\n            new RussianLetterTokenizer(\n                sampleUnicode,\n                RussianCharsets.UnicodeRussian);\n\n        final Token reusableToken = new Token();\n        final Token reusableSampleToken = new Token();\n        Token nextToken;\n        Token nextSampleToken;\n        for (;;)\n        {\n            nextToken = in.next(reusableToken);\n\n            if (nextToken == null)\n            {\n                break;\n            }\n\n            nextSampleToken = sample.next(reusableSampleToken);\n            assertEquals(\n                \"Unicode\",\n                nextToken.term(),\n                nextSampleToken == null\n                ? null\n                : nextSampleToken.term());\n        }\n\n        inWords.close();\n        sampleUnicode.close();\n    }\n\n","sourceOld":"    public void testUnicode() throws IOException\n    {\n        RussianAnalyzer ra = new RussianAnalyzer(RussianCharsets.UnicodeRussian);\n        inWords =\n            new InputStreamReader(\n                new FileInputStream(new File(dataDir, \"/org/apache/lucene/analysis/ru/testUTF8.txt\")),\n                \"UTF-8\");\n\n        sampleUnicode =\n            new InputStreamReader(\n                new FileInputStream(new File(dataDir, \"/org/apache/lucene/analysis/ru/resUTF8.htm\")),\n                \"UTF-8\");\n\n        TokenStream in = ra.tokenStream(\"all\", inWords);\n\n        RussianLetterTokenizer sample =\n            new RussianLetterTokenizer(\n                sampleUnicode,\n                RussianCharsets.UnicodeRussian);\n\n        final Token reusableToken = new Token();\n        final Token reusableSampleToken = new Token();\n        Token nextToken;\n        Token nextSampleToken;\n        for (;;)\n        {\n            nextToken = in.next(reusableToken);\n\n            if (nextToken == null)\n            {\n                break;\n            }\n\n            nextSampleToken = sample.next(reusableSampleToken);\n            assertEquals(\n                \"Unicode\",\n                nextToken.term(),\n                nextSampleToken == null\n                ? null\n                : nextSampleToken.term());\n        }\n\n        inWords.close();\n        sampleUnicode.close();\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"7e2cb543b41c145f33390f460ee743d6693c9c6c":["043c298cb215f13ba7b9b81d20760704e8f93d66"],"dd745d580729e528151b58aeda87ef82f1b95c9b":["6cb858a08d9285320591728f5b85c55f1ff2b944"],"043c298cb215f13ba7b9b81d20760704e8f93d66":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"6cb858a08d9285320591728f5b85c55f1ff2b944":["7e2cb543b41c145f33390f460ee743d6693c9c6c"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["dd745d580729e528151b58aeda87ef82f1b95c9b"]},"commit2Childs":{"7e2cb543b41c145f33390f460ee743d6693c9c6c":["6cb858a08d9285320591728f5b85c55f1ff2b944"],"043c298cb215f13ba7b9b81d20760704e8f93d66":["7e2cb543b41c145f33390f460ee743d6693c9c6c"],"dd745d580729e528151b58aeda87ef82f1b95c9b":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"6cb858a08d9285320591728f5b85c55f1ff2b944":["dd745d580729e528151b58aeda87ef82f1b95c9b"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["043c298cb215f13ba7b9b81d20760704e8f93d66"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}